PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Shin, E; Yu, YF; Bies, RR; Ramanathan, M				Shin, Euibeom; Yu, Yifan; Bies, Robert R.; Ramanathan, Murali			Evaluation of ChatGPT and Gemini large language models for pharmacometrics with NONMEM	JOURNAL OF PHARMACOKINETICS AND PHARMACODYNAMICS			English	Article						Pharmacometrics; ChatGPT; Pharmacokinetics; Drug Development; Artificial intelligence; Generative AI; Modeling; Nonlinear mixed effects; NONMEM		To assess ChatGPT 4.0 (ChatGPT) and Gemini Ultra 1.0 (Gemini) large language models on NONMEM coding tasks relevant to pharmacometrics and clinical pharmacology. ChatGPT and Gemini were assessed on tasks mimicking real-world applications of NONMEM. The tasks ranged from providing a curriculum for learning NONMEM, an overview of NONMEM code structure to generating code. Prompts in lay language to elicit NONMEM code for a linear pharmacokinetic (PK) model with oral administration and a more complex model with two parallel first-order absorption mechanisms were investigated. Reproducibility and the impact of "temperature" hyperparameter settings were assessed. The code was reviewed by two NONMEM experts. ChatGPT and Gemini provided NONMEM curriculum structures combining foundational knowledge with advanced concepts (e.g., covariate modeling and Bayesian approaches) and practical skills including NONMEM code structure and syntax. ChatGPT provided an informative summary of the NONMEM control stream structure and outlined the key NONMEM Translator (NM-TRAN) records needed. ChatGPT and Gemini were able to generate code blocks for the NONMEM control stream from the lay language prompts for the two coding tasks. The control streams contained focal structural and syntax errors that required revision before they could be executed without errors and warnings. The code output from ChatGPT and Gemini was not reproducible, and varying the temperature hyperparameter did not reduce the errors and omissions substantively. Large language models may be useful in pharmacometrics for efficiently generating an initial coding template for modeling projects. However, the output can contain errors and omissions that require correction.	[Shin, Euibeom; Yu, Yifan; Bies, Robert R.; Ramanathan, Murali] SUNY Buffalo, Univ Buffalo, Dept Pharmaceut Sci, Buffalo, NY 14214 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Ramanathan, M (corresponding author), SUNY Buffalo, Univ Buffalo, Dept Pharmaceut Sci, Buffalo, NY 14214 USA.	Murali@Buffalo.Edu			Department of Defense Multiple Sclerosis Research Program for the Office of the Congressionally Directed Medical Research Programs (CDMRP) [MS190096]	Department of Defense Multiple Sclerosis Research Program for the Office of the Congressionally Directed Medical Research Programs (CDMRP)(United States Department of Defense)	This is unfunded research. Support from Grant MS190096 from the Department of Defense Multiple Sclerosis Research Program for the Office of the Congressionally Directed Medical Research Programs (CDMRP) to the Ramanathan laboratory is gratefully acknowledged.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anil R., 2024, ARXIV, p2312.11805, DOI [10.48550/arXiv.2312.11805, DOI 10.48550/ARXIV.2312.11805]; [Anonymous], 2011, STAN REFERENCE MANUA; [Anonymous], 2024, LLAMA 2 OPEN SOURCE; [Anonymous], LIXOFT SIMULATIONS P; [Anonymous], 2023, BARD LARGE LANGUAGE; [Anonymous], 2024, MRGSOLVE SIMULATE OD; [Anonymous], 2024, CHATGPT VERSION JAN; [Anonymous], 2024, MEET CLAUDE; [Anonymous], 2019, NLMIXR R PACKAGE POP; Bauer RJ, 2019, CPT-PHARMACOMET SYST, V8, P525, DOI 10.1002/psp4.12404; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Bonate PL, 2024, J PHARMACOKINET PHAR, V51, P5, DOI 10.1007/s10928-023-09878-4; Cloesmeijer ME, 2024, BRIT J CLIN PHARMACO, V90, P360, DOI 10.1111/bcp.15895; Fidler M, 2021, CPT-PHARMACOMET SYST, V10, P283, DOI 10.1002/psp4.12618; Fidler M, 2019, CPT-PHARMACOMET SYST, V8, P621, DOI 10.1002/psp4.12445; Frieder S, 2023, ARXIV; Orrù G, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1199350; Owen JS, 2014, INTRODUCTION TO POPULATION PHARMACOKINETIC/PHARMACODYNAMIC ANALYSIS WITH NONLINEAR MIXED EFFECTS MODELS, P1, DOI 10.1002/9781118784860; Petricoul O., 2007, Pharmacometrics: The Science of Quantitative Pharmacology, P345; Radford A., 2018, IMPROVING LANGUAGE U; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Shin E, 2024, J PHARMACOKINET PHAR, V51, P101, DOI 10.1007/s10928-023-09892-6; Sun H, 1999, CLIN PHARMACOKINET, V37, P41, DOI 10.2165/00003088-199937010-00003; Touvron H., 2023, ARXIV, p2307.09288, DOI [10.48550/arXiv.2307.09288, DOI 10.48550/ARXIV.2307.09288]; Yuan Z., 2023, ARXIV	26	1	1	2	2	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1567-567X	1573-8744		J PHARMACOKINET PHAR	J. Pharmacokinet. Pharmacodyn.	JUN	2024	51	3					187	197		10.1007/s10928-024-09921-y	http://dx.doi.org/10.1007/s10928-024-09921-y		APR 2024	11	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	SM3A0	38656706				2024-07-03	WOS:001207610200001
J	Wodecki, A				Wodecki, Andrzej			Generative technologies in higher education - assessment of the current state, essential skills, and a proposal for a didactic method	E-MENTOR			Polish	Article						generative technologies; language models; knowledge management; teaching methodology; evaluation		This article proposes the application of generative technologies, specifically large language models, in higher education. While such technologies present novel opportunities, at the same time, they raise concerns, including potential cognitive degradation, job displacement, and intellectual property issues. The first section of this paper introduces the essential concepts and methods of generative technologies, coupled with a discussion on the necessary competencies to fully harness their potential. The next section suggests an addition to usual teaching methods, using the 'Artificial Intelligence in Business' course as an example. This proposed enhancement incorporates a review of student work outcomes by systems powered by large language models. The underlying didactic principles of the course, sample system reports, and an illustrative diagram of the teaching process are presented. The paper concludes by contemplating the possible advantages and challenges posed by these technologies in pedagogy, along with recommendations for future research.	[Wodecki, Andrzej] Politechn Warszawska, Warsaw, Poland	Warsaw University of Technology	Wodecki, A (corresponding author), Politechn Warszawska, Warsaw, Poland.			Wodecki, Andrzej/0000-0002-9077-3191				Bulathwela S., 2023, Artificial Intelligence in Education, P327, DOI [10.1007/978-3-031-36272-9_27, DOI 10.1007/978-3-031-36272-9_27]; Cai YZ, 2024, Arxiv, DOI arXiv:2304.08103; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Cheng DX, 2023, Arxiv, DOI [arXiv:2303.08518, 10.48550/arXiv.2303.08518, DOI 10.48550/ARXIV.2303.08518]; Ge T, 2023, Arxiv, DOI [arXiv:2212.00616, 10.48550/arXiv.2212.00616, DOI 10.48550/ARXIV.2212.00616]; Kasneci E., 2023, CHATGPT GOOD OPPORTU, DOI [10.35542/osf.io/5er8f, DOI 10.35542/OSF.IO/5ER8F]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; MetaAI, 2023, Introducing LLaMA: A foundational, 65 -billion -parameter language model; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; The Vicuna Team, 2023, Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446	11	1	1	5	5	WARSAW SCH ECONOMICS	WARSAW	AL NIEPODLEGLOSCI 162, WARSAW, 02554, POLAND	1731-6758	1731-7428		E-MENTOR	E-Mentor		2023		3					51	60		10.15219/em100.1617	http://dx.doi.org/10.15219/em100.1617			10	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	JN9L0					2024-07-03	WOS:001173963300005
J	Ge, J; Lai, JC				Ge, Jin; Lai, Jennifer C.			Artificial intelligence-based text generators in hepatology: ChatGPT is just the beginning	HEPATOLOGY COMMUNICATIONS			English	Article								Since its release as a "research preview" in November 2022, ChatGPT, the conversational interface to the Generative Pretrained Transformer 3 large language model built by OpenAI, has garnered significant publicity for its ability to generate detailed responses to a variety of questions. ChatGPT and other large language models generate sentences and paragraphs in response to word patterns in training data that they have previously seen. By allowing users to communicate with an artificial intelligence model in a human-like way, however, ChatGPT has crossed the technological adoption barrier into the mainstream. Existing examples of ChatGPT use-cases, such as negotiating bills, debugging programing code, and writing essays, indicate that ChatGPT and similar models have the potential to have profound (and yet unknown) impacts on clinical research and practice in hepatology. In this special article, we discuss the general background and potential pitfalls of ChatGPT and associated technologies-and then we explore its uses in hepatology with specific examples.	[Ge, Jin; Lai, Jennifer C.] Univ Calif San Francisco, Div Gastroenterol & Hepatol, Dept Med, San Francisco, CA USA	University of California System; University of California San Francisco	Ge, J (corresponding author), 513 Parnassus Ave,S-357, San Francisco, CA 94143 USA.	jin.ge@ucsf.edu; jennifer.lai@ucsf.edu	Ge, Jin/AAV-9835-2020	Ge, Jin/0000-0003-1574-1525; Lai, Jennifer/0000-0003-2092-6380	National Center for Advancing Translational Sciences [KL2TR001870]	National Center for Advancing Translational Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS))	The authors of this editorial were supported by KL2TR001870 (National Center for Advancing Translational Sciences, Jin Ge), AASLD Anna S. Lok Advanced/Transplant Hepatology Award AHL21-104606 (AASLD Foundation, Jin Ge), P30DK026743 (UCSF Liver Center Grant, Jin Ge and Jennifer C. Lai), and R01AG059183 (National Institute on Aging, Jennifer C. Lai). The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health or any other funding agencies. The funding agencies played no role in the analysis of the data or the preparation of this manuscript.	Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Amer Eslam, 2021, 2021 International Mobile, Intelligent, and Ubiquitous Computing Conference (MIUCC), P263, DOI 10.1109/MIUCC52538.2021.9447652; [Anonymous], 2012, The New York Times; [Anonymous], 2012, MIT News; [Anonymous], NVIDIA expands large language models to biology; [Anonymous], 1999, Wired; arstechnica, Ars Technica; Bhatnagar R, 2022, JAMIA OPEN, V5, DOI 10.1093/jamiaopen/ooac043; Brown H., 2022, arXiv; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N., 2020, arXiv; Carrell DS, 2017, J AM MED INFORM ASSN, V24, P986, DOI 10.1093/jamia/ocx039; ChatGPT could transform academia, But it's not an A+ student yet: NPR; Devlin J., 2018, BERT PRE TRAINING DE; fastcompany, OpenAI ChatGPT is easily tricked. Here's how; Fernández J, 2016, HEPATOLOGY, V63, P2019, DOI 10.1002/hep.28330; Fine JP, 1999, J AM STAT ASSOC, V94, P496, DOI 10.2307/2670170; Frye BL., 2022, Fordham Intell Prop Media Ent Law J; hai.stanford.edu, How large language models will transform science, society, and AI; Haque M.U., 2022, ARXIV; hbr, ChatGPT is a tipping point for AI; healthcareitnews, Healthcare IT News; huggingface, Large language models: a new Moore's law?; Karita S, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P449, DOI [10.1109/asru46091.2019.9003750, 10.1109/ASRU46091.2019.9003750]; Kung T. H., 2022, medRxiv; Lin C, 2020, J AM MED INFORM ASSN, V27, P584, DOI 10.1093/jamia/ocaa001; Liu K, 2017, LIVER INT, V37, P442, DOI 10.1111/liv.13328; Liu Y., 2019, CoRR abs/1907.11692; lww, Official journal of the American College of Gastroenterology; microsoft, Turing-NLG: a 17-billion-parameter language model by Microsoft-Microsoft Research; microsoft, Using DeepSpeed and Megatron to Train Megatron-Turing NLG 530B, the World's Largest and Most Powerful Generative Language Model-Microsoft Research; Open Sourcing BERT, State-of-the-Art Pre-training for Natural Language Processing-Google AI Blog; openai, Better language models and their implications Internet; openai, ChatGPT: Optimizing language models for dialogue; Radford A., 2018, IMPROVING LANGUAGE U; Romero A., GPT-4 will have 100 trillion parameters-500x the size of GPT-3; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Shoeybi M., 2019, Megatron-lm: Training multibillion parameter language models using model parallelism; Smith S, 2022, ARXIV; stpp, What's in the Chatterbox? Large Language Models, Why They Matter, and What We Should Do About Them; Tamkin A., 2021, arXiv; thenextweb, Large language models like GPT-3 aren't good enough for pharma and finance; Thoppilan R, 2022, ARXIV; Van Noorden R, 2022, NATURE, V605, P21, DOI 10.1038/d41586-022-01191-3; Vaswani A, 2017, ADV NEUR IN, V30; vox, OpenAI's ChatGPT is a fascinating glimpse into the scary power of AI-Vox; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Yang X, 2022, ARXIV	48	24	24	9	9	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA		2471-254X		HEPATOL COMMUN	Hepatol. Commun.	APR	2023	7	4							e0097	10.1097/HC9.0000000000000097	http://dx.doi.org/10.1097/HC9.0000000000000097			11	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	T9JX9	36972383	Green Published, gold			2024-07-03	WOS:001081085000025
C	Yang, D; Kommineni, A; Alshehri, M; Mohanty, N; Modi, V; Gratch, J; Narayanan, S			IEEE	Yang, Daniel; Kommineni, Aditya; Alshehri, Mohammad; Mohanty, Nilamadhab; Modi, Vedant; Gratch, Jonathan; Narayanan, Shrikanth			Context Unlocks Emotions: Text-based Emotion Classification Dataset Auditing with Large Language Models	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, ACII	International Conference on Affective Computing and Intelligent Interaction		English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			emotion classification; natural language processing; large language models; prompting		The lack of contextual information in text data can make the annotation process of text-based emotion classification datasets challenging. As a result, such datasets often contain labels that fail to consider all the relevant emotions in the vocabulary. This misalignment between text inputs and labels can degrade the performance of machine learning models trained on top of them. As re-annotating entire datasets is a costly and time-consuming task that cannot be done at scale, we propose to use the expressive capabilities of large language models to synthesize additional context for input text to increase its alignment with the annotated emotional labels. In this work, we propose a formal definition of textual context to motivate a prompting strategy to enhance such contextual information. We provide both human and empirical evaluation to demonstrate the efficacy of the enhanced context. Our method improves alignment between inputs and their human-annotated labels from both an empirical and human-evaluated standpoint.	[Yang, Daniel; Kommineni, Aditya; Alshehri, Mohammad; Mohanty, Nilamadhab; Modi, Vedant; Gratch, Jonathan; Narayanan, Shrikanth] Univ Southern Calif, Los Angeles, CA 90007 USA; [Alshehri, Mohammad] Saudi Aramco, Dhahran, Saudi Arabia	University of Southern California	Yang, D (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	dyang165@usc.edu; akommine@usc.edu; mohammed.shehri.32@aramco.com; nmohanty@usc.edu; vkmodi@usc.edu; gratch@ict.usc.edu; shri@ee.usc.edu			National Science Foundation Graduate Research Fellowship [DGE-1842487]	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1842487. We would like to James Hale for providing us with Amazon MTurk account for completion of our evaluation.	Barbieri F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1644; Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chatterjee A., 2019, P 13 INT WORKSHOP SE, P39, DOI [10.18653/, DOI 10.18653/V1/S19-2005]; Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040; Deng JW, 2023, IEEE T AFFECT COMPUT, V14, P49, DOI 10.1109/TAFFC.2021.3053275; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041; GIFFORD R, 1994, J PERS SOC PSYCHOL, V66, P398, DOI 10.1037/0022-3514.66.2.398; Gilardi F, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2305016120; Haynes W., 2013, Encyclopedia of Systems Biology, P78, DOI DOI 10.1007/978-1-4419-9863-7_1215; Huang Y.-H., 2022, Emotionx-idea: Emotion bert-an affectional model for conversation; Kocon Jan, 2023, "ChatGPT: Jack of all trades, master of none,; Kosti R, 2017, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2017.212; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534; Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024; Li Y., 2017, P 8 INT JOINT C NATU, P986; Liscombe J., 2005, Using context to improve emotion detection in spoken dialog systems; Mittal Trisha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14222, DOI 10.1109/CVPR42600.2020.01424; Northcutt CG, 2021, J ARTIF INTELL RES, V70, P1373; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Aligning language models to follow instructions; Radford A, 2021, PR MACH LEARN RES, V139; Rosenthal S., 2017, P 11 INT WORKSHOP SE, P502; SCHERER KR, 1994, J PERS SOC PSYCHOL, V66, P310, DOI 10.1037/0022-3514.66.2.310; Schuhmann Christoph, 2022, 36 C NEUR INF PROC S; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Vaswani A, 2017, ADV NEUR IN, V30; Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5415; Zhao J, 2021, MEMOBERT PRETRAINING	31	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2156-8103		979-8-3503-2743-4	INT CONF AFFECT			2023										10.1109/ACIIW59127.2023.10388131	http://dx.doi.org/10.1109/ACIIW59127.2023.10388131			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IH					2024-07-03	WOS:001161369900018
J	Sobieszek, A; Price, T				Sobieszek, Adam; Price, Tadeusz			Playing Games with Ais: The Limits of GPT-3 and Similar Large Language Models	MINDS AND MACHINES			English	Article						GPT-3; Artificial Intelligence; Psychometrics; Language Games; Turing test		This article contributes to the debate around the abilities of large language models such as GPT-3, dealing with: firstly, evaluating how well GPT does in the Turing Test, secondly the limits of such models, especially their tendency to generate falsehoods, and thirdly the social consequences of the problems these models have with truth-telling. We start by formalising the recently proposed notion of reversible questions, which Floridi & Chiriatti (2020) propose allow one to 'identify the nature of the source of their answers', as a probabilistic measure based on Item Response Theory from psychometrics. Following a critical assessment of the methodology which led previous scholars to dismiss GPT's abilities, we argue against claims that GPT-3 completely lacks semantic ability. Using ideas of compression, priming, distributional semantics and semantic webs we offer our own theory of the limits of large language models like GPT-3, and argue that GPT can competently engage in various semantic tasks. The real reason GPT's answers seem senseless being that truth-telling is not amongst them. We claim that these kinds of models cannot be forced into producing only true continuation, but rather to maximise their objective function they strategize to be plausible instead of truthful. This, we moreover claim, can hijack our intuitive capacity to evaluate the accuracy of its outputs. Finally, we show how this analysis predicts that a widespread adoption of language generators as tools for writing could result in permanent pollution of our informational ecosystem with massive amounts of very plausible but often untrue texts.	[Sobieszek, Adam] Univ Warsaw, Dept Psychol, Warsaw, Poland; [Price, Tadeusz] Univ Nottingham, Dept Philosophy, Nottingham, England	University of Warsaw; University of Nottingham	Price, T (corresponding author), Univ Nottingham, Dept Philosophy, Nottingham, England.	apytp2@nottingham.ac.uk		Price, Tadeusz/0000-0003-1264-7103				Almeida F., 2019, ARXIV190109069; [Anonymous], 2017, Philosophy & Technology, DOI DOI 10.1007/S13347-017-0259-1; [Anonymous], 2018, ACL; Bartolucci F, 2007, PSYCHOMETRIKA, V72, P141, DOI 10.1007/s11336-005-1376-9; Bernstein J., 2021, ARXIV PREPRINT ARXIV; Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303; Branwen G., 2020, Gpt-3 creative fiction; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brzezinska Justyna, 2016, Folia Oeconomica Stetinensia, V16, P163, DOI DOI 10.1515/FOLI-2016-0032; Chen M., 2021, ARXIV; COLLINS AM, 1975, PSYCHOL REV, V82, P407, DOI 10.1037/0033-295X.82.6.407; COLLINS AM, 1969, J VERB LEARN VERB BE, V8, P240, DOI 10.1016/S0022-5371(69)80069-1; DAMASSINO N, 2020, MIND MACH, V30; Embretson S.E., 2013, ITEM RESPONSE THEORY; ERICKSON TD, 1981, J VERB LEARN VERB BE, V20, P540, DOI 10.1016/S0022-5371(81)90165-1; Finnie-Ansley J., 2022, AUSTR COMP ED C, P1019; Firth J., 1957, Stud. Linguist. Anal, P1; Floridi L., 2019, Philos Technol, V32, P1, DOI DOI 10.1007/S13347-019-00345-Y; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Floridi L, 2011, METAPHILOSOPHY, V42, P282, DOI 10.1111/j.1467-9973.2011.01693.x; Floridi L, 2011, ERKENNTNIS, V74, P147, DOI 10.1007/s10670-010-9249-8; GILBERT DT, 1991, AM PSYCHOL, V46, P107, DOI 10.1037/0003-066X.46.2.107; Heller F., 1957, WHATS MY LINE; Hendrycks Dan, 2021, arXiv; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hutson M., 2021, ROBO WRITERS RISE RI; Kaminska, 2020, GPT 3 LANGUAGE TOOL; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Lample G., 2018, ARXIV PREPRINT ARXIV; Leibniz GottfriedWilhelm., 1666, Dissertatio de Arte Combinatoria; Lewis, 1986, PLURALITY WORLDS; Mahoney M., 2006, RATIONALE LARGE TEXT; Marcus G., 2020, Technology Review; McDonell K., 2021, 2021 CHI C HUM FACT; Mercier H., 2021, Royal Inst. Philos. Supple, V89, P257, DOI DOI 10.1017/S1358246121000096; Mercier H, 2020, NOT BORN YESTERDAY; MERCIER H., 2017, The enigma of reason; Montemayor C, 2021, MIND MACH, V31, P471, DOI 10.1007/s11023-021-09568-5; Mulder J, 2009, PSYCHOMETRIKA, V74, P273, DOI 10.1007/s11336-008-9097-5; Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592; OpenAI, 2021, Examples; Pal D., 2021, GENERATES CODE USING; Pearl J, 2002, AI MAG, V23, P95; Pearl J., 2019, The Book of Why; Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2; Peregrin J, 2021, MIND MACH, V31, P305, DOI 10.1007/s11023-021-09564-9; Prenner, 2021, ARXIV PREPRINT ARXIV; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ronen Ruth., 1994, Possible Worlds in Literary Theory; Russell, 2019, HUMAN COMPATIBLE ART; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, DOI 10.1002/J.1538-7305.1948.TB00917.X]; Shin Taylor, 2020, ARXIV PREPRINT ARXIV; Shmilovici A, 2009, COMPUT ECON, V33, P131, DOI 10.1007/s10614-008-9153-3; Sperber D, 2010, MIND LANG, V25, P359, DOI 10.1111/j.1468-0017.2010.01394.x; Umanath S, 2014, PERSPECT PSYCHOL SCI, V9, P408, DOI 10.1177/1745691614535933; Wang C., 2020, INT C LEARNING REPRE; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zimmerman A., 2020, DAILY NOUS      0730	59	26	28	8	67	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-6495	1572-8641		MIND MACH	Minds Mach.	JUN	2022	32	2					341	364		10.1007/s11023-022-09602-0	http://dx.doi.org/10.1007/s11023-022-09602-0		MAY 2022	24	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	1U7HG		hybrid			2024-07-03	WOS:000790126500001
C	Hua, WY; Li, L; Xu, SY; Chen, L; Zhang, YF			ACM	Hua, Wenyue; Li, Lei; Xu, Shuyuan; Chen, Li; Zhang, Yongfeng			Tutorial on Large Language Models for Recommendation	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Recommendation; Large Language Models; Foundation Models		Foundation Models such as Large Language Models (LLMs) have significantly advanced many research areas. In particular, LLMs offer significant advantages for recommender systems, making them valuable tools for personalized recommendations. For example, by formulating various recommendation tasks such as rating prediction, sequential recommendation, straightforward recommendation, and explanation generation into language instructions, LLMs make it possible to build universal recommendation engines that can handle different recommendation tasks. Additionally, LLMs have a remarkable capacity for understanding natural language, enabling them to comprehend user preferences, item descriptions, and contextual information to generate more accurate and relevant recommendations, leading to improved user satisfaction and engagement. This tutorial introduces Foundation Models such as LLMs for recommendation. We will introduce how recommender system advanced from shallow models to deep models and to large models, how LLMs enable generative recommendation in contrast to traditional discriminative recommendation, and how to build LLM-based recommender systems. We will cover multiple perspectives of LLM-based recommendation, including data preparation, model design, model pre-training, fine-tuning and prompting, multi-modality and multi-task learning, as well as trustworthy perspectives of LLM-based recommender systems such as fairness and transparency.	[Hua, Wenyue; Xu, Shuyuan; Zhang, Yongfeng] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08854 USA; [Li, Lei; Chen, Li] Hong Kong Baptist Univ, Dept Comp Sci, Hong Kong, Peoples R China	Rutgers University System; Rutgers University New Brunswick; Hong Kong Baptist University	Hua, WY (corresponding author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08854 USA.	wenyue.hua@rutgers.edu; csleili@comp.hkbu.edu.hk; shuyuan.xu@rutgers.edu; lichen@comp.hkbu.edu.hk; yongfeng.zhang@rutgers.edu		Chen, Li/0000-0002-5842-838X; Hua, Wenyue/0009-0008-2043-2704; Zhang, Yongfeng/0000-0003-2633-8555; Xu, Shuyuan/0000-0003-0865-5223				Geng SJ, 2023, Arxiv, DOI arXiv:2305.14302; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Geng SJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P244; Geng SJ, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P946, DOI 10.1145/3485447.3511937; Geng Shijie, 2023, 11 INT C LEARNING RE; Hua WY, 2024, Arxiv, DOI arXiv:2305.12090; Hua WY, 2023, Arxiv, DOI arXiv:2305.06569; Li L, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3580488; Li L, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4947; Li L, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P755, DOI 10.1145/3340531.3411992; Li L, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P198, DOI 10.1145/3366424.3383540; Lin G, 2023, Arxiv, DOI arXiv:2305.04518; Xu SY, 2024, Arxiv, DOI [arXiv:2306.11134, 10.48550/ARXIV.2306.11134]	13	1	1	25	25	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1281	1283		10.1145/3604915.3609494	http://dx.doi.org/10.1145/3604915.3609494			3	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ					2024-07-03	WOS:001156630300176
C	Pinna, G; Ravalico, D; Rovito, L; Manzoni, L; De Lorenzo, A		Giacobini, M; Xue, B; Manzoni, L		Pinna, Giovanni; Ravalico, Damiano; Rovito, Luigi; Manzoni, Luca; De Lorenzo, Andrea			Enhancing Large Language Models-Based Code Generation by Leveraging Genetic Improvement	GENETIC PROGRAMMING, EUROGP 2024	Lecture Notes in Computer Science		English	Proceedings Paper	27th European Conference on Genetic Programming (EuroGP) Held as Part of EvoStar Conference	APR 03-05, 2024	Aberystwyth, WALES			Evolutionary Computation; Evolutionary Algorithms; Large Language Models; Artificial Intelligence; Machine Learning; Neural Networks; Code Generation; Genetic Improvement; Grammatical Evolution; Genetic Programming		In recent years, the rapid advances in neural networks for Natural Language Processing (NLP) have led to the development of Large Language Models (LLMs), able to substantially improve the state-of-the-art in many NLP tasks, such as question answering and text summarization. Among them, one particularly interesting application is automatic code generation based only on the problem description. However, it has been shown that even the most effective LLMs available often fail to produce correct code. To address this issue, we propose an evolutionary-based approach using Genetic Improvement (GI) to improve the code generated by an LLM using a collection of user-provided test cases. Specifically, we employ Grammatical Evolution (GE) using a grammar that we automatically specialize-starting from a general one-for the output of the LLM. We test 25 different problems and 5 different LLMs, showing that the proposed method is able to improve in a statistically significant way the code generated by LLMs. This is a first step in showing that the combination of LLMs and evolutionary techniques can be a fruitful avenue of research.	[Pinna, Giovanni; Ravalico, Damiano; Rovito, Luigi; Manzoni, Luca; De Lorenzo, Andrea] Univ Trieste, I-34127 Trieste, TS, Italy	University of Trieste	Rovito, L (corresponding author), Univ Trieste, I-34127 Trieste, TS, Italy.	giovanni.pinna@phd.units.it; damiano.ravalico@phd.units.it; luigi.rovito@phd.units.it; lmanzoni@units.it; andrea.delorenzo@units.it		Ravalico, Damiano/0009-0001-9631-4252				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; An G, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P1100, DOI 10.1145/3338906.3341184; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bahrini Aram, 2023, 2023 Systems and Information Engineering Design Symposium (SIEDS), P274, DOI 10.1109/SIEDS58326.2023.10137850; BIBEL W, 1980, ARTIF INTELL, V14, P243, DOI 10.1016/0004-3702(80)90050-8; Blot A., 2022, arXiv, DOI [10.48550/arxiv.2208.02811, DOI 10.48550/ARXIV.2208.02811]; Budinsky FJ, 1996, IBM SYST J, V35, P151, DOI 10.1147/sj.352.0151; Chen M., 2021, arXiv; Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fenton M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO'17 COMPANION), P1194, DOI 10.1145/3067695.3082469; Fernando C, 2023, Arxiv, DOI arXiv:2309.16797; Serruto WF, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), P279, DOI 10.1109/CSCI.2017.47; Grootendorst M., 2020, Keybert: Minimal keyword extraction with bert; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Guo QY, 2024, Arxiv, DOI arXiv:2309.08532; Helmuth T, 2022, GENET PROGRAM EVOL M, V23, P375, DOI 10.1007/s10710-022-09434-y; Helmuth T, 2021, PROCEEDINGS OF THE 2021 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'21), P785, DOI 10.1145/3449639.3459285; HOLM S, 1979, SCAND J STAT, V6, P65; Karpuzcu U.R., 2005, Proceedings of the 7th Annual Workshop on Genetic and Evolutionary Computation, P394; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; Langdon WB, 2014, INT SYMP SYMB NUMERI, P14, DOI 10.1109/SYNASC.2014.10; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu ZJ, 2024, Arxiv, DOI arXiv:2308.04838; Liu ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P61, DOI 10.1109/FPT.2016.7929190; Liventsev V, 2023, PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, GECCO 2023, P1146, DOI 10.1145/3583131.3590481; Löppenberg M, 2023, Arxiv, DOI arXiv:2304.05638; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; MANNA Z, 1975, ARTIF INTELL, V6, P175, DOI 10.1016/0004-3702(75)90008-9; Marino F, 2016, LECT NOTES COMPUT SC, V9921, P345, DOI 10.1007/978-3-319-45823-6_32; Menabrea L.F., 1843, Ada's Legacy: Cultures of Computing from the Victorian to the Digital Age; Mery D., 2011, P 2 S INF COMM TECHN, P179; Miller Julian Francis., 2008, Proceedings of the 10th Annual Conference Companion on Genetic and Evolutionary Computation, P2701; Moreira Tomas G., 2010, 2010 8th IEEE International Conference on Industrial Informatics (INDIN 2010), P1085, DOI 10.1109/INDIN.2010.5549590; O'Neill M, 2001, IEEE T EVOLUT COMPUT, V5, P349, DOI 10.1109/4235.942529; Ouyang SY, 2023, Arxiv, DOI arXiv:2308.02828; Paolone G, 2020, COMPUTERS, V9, DOI 10.3390/computers9030056; Petke Justyna, 2014, Genetic Programming. 17th European Conference (EuroGP 2014). Revised Selected Papers: LNCS 8599, P137, DOI 10.1007/978-3-662-44303-3_12; Pluhacek M, 2023, PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION, GECCO 2023 COMPANION, P1812, DOI 10.1145/3583133.3596401; Rugina E., 2008, DASIA 2008 Data SystemsIn Aerospace, V665, P28; Ryan C., 1998, Genetic Programming. First European Workshop, EuroGP'98. Proceedings, P83, DOI 10.1007/BFb0055930; Sandnes F. E., 1996, Proceedings of the Eighth Euromicro Workshop on Real-Time Systems, P70, DOI 10.1109/EMWRTS.1996.557799; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Sun Hanwen, 2022, 2022 7th IEEE International Conference on Data Science in Cyberspace (DSC), P383, DOI 10.1109/DSC55868.2022.00059; Taori Rohan, 2023, Stanford Center for Research on Foundation Models, V3, P7; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vaswani A, 2017, ADV NEUR IN, V30; Walker JA, 2010, LECT NOTES COMPUT SC, V6274, P238, DOI 10.1007/978-3-642-15323-5_21; Wang X., 2023, 3 INT SEM ART INT NE, V12587, P488; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Ward M., 1989, Ph.D. thesis; Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863	57	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56956-2; 978-3-031-56957-9	LECT NOTES COMPUT SC			2024	14631						108	124		10.1007/978-3-031-56957-9_7	http://dx.doi.org/10.1007/978-3-031-56957-9_7			17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9FD					2024-07-03	WOS:001212387300007
C	Freire, SK; Foosherian, M; Wang, C; Niforatos, E			ACM	Freire, S. Kernan; Foosherian, Mina; Wang, C.; Niforatos, E.			Harnessing Large Language Models for Cognitive Assistants in Factories	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023			English	Proceedings Paper	5th International Conference on Conversational User Interfaces (CUI)	JUL 19-21, 2023	Eindhoven Univ Technol, Eindhoven, NETHERLANDS	Assoc Comp Machinery, ACM SIGCHI, Bold Insight UK, Eindhoven Univ Technol, Eindhoven AI Syst Inst, HMD Res	Eindhoven Univ Technol	cognitive assistant; conversational user interfaces; knowledge management; industry 5.0; human-centered AI; knowledge sharing	SYSTEM	As agile manufacturing expands and workforce mobility increases, the importance of efficient knowledge transfer among factory workers grows. Cognitive Assistants (CAs) with Large Language Models (LLMs), like GPT-3.5, can bridge knowledge gaps and improve worker performance in manufacturing settings. This study investigates the opportunities, risks, and user acceptance of LLM-powered CAs in two factory contexts: textile and detergent production. Several opportunities and risks are identified through a literature review, proof-of-concept implementation, and focus group sessions. Factory representatives raise concerns regarding data security, privacy, and the reliability of LLMs in high-stake environments. By following design guidelines regarding persistent memory, realtime data integration, security, privacy, and ethical concerns, LLM-powered CAs can become valuable assets in manufacturing settings and other industries.	[Freire, S. Kernan; Wang, C.; Niforatos, E.] Delft Univ Technol, Delft, Netherlands; [Foosherian, Mina] BIBA Bremer Inst Prod & Logist GmbH, Bremen, Germany	Delft University of Technology; BIBA - Bremer Institut fur Produktion & Logistik	Freire, SK (corresponding author), Delft Univ Technol, Delft, Netherlands.	s.kernanfreire@tudelft.nl; fos@biba.uni-bremen.de; c.wang-16@tudelft.nl; e.niforatos@tudelft.nl		Niforatos, Evangelos/0000-0002-0484-4214; Kernan Freire, Samuel/0000-0001-8684-0585; Wang, Chaofan/0000-0001-8213-6582	European Union's Horizon 2020 research and innovation program via the project COALA "COgnitive Assisted agile manufacturing for a LAbor force supported by trustworthy Artificial Intelligence" [957296]; H2020 - Industrial Leadership [957296] Funding Source: H2020 - Industrial Leadership	European Union's Horizon 2020 research and innovation program via the project COALA "COgnitive Assisted agile manufacturing for a LAbor force supported by trustworthy Artificial Intelligence"; H2020 - Industrial Leadership(European Union (EU)H2020 - Industrial Leadership)	This work was supported by the European Union's Horizon 2020 research and innovation program via the project COALA "COgnitive Assisted agile manufacturing for a LAbor force supported by trustworthy Artificial Intelligence" (Grant agreement 957296).	Abner B, 2020, IFIP ADV INF COMM TE, V592, P19, DOI 10.1007/978-3-030-57997-5_3; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2018, INT COGN ASS WORKSH; [Anonymous], 2016, Intelligent Cognitive Assistants: Workshop Summary and Recommendations; Basic Z, 2023, Arxiv, DOI [arXiv:2302.04536, 10.48550/arXiv.2302.04536, DOI 10.48550/ARXIV.2302.04536]; Belkadi F, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.02.046; Bradesko L, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3086686; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Büttner S, 2017, LECT NOTES COMPUT SC, V10217, P33, DOI 10.1007/978-3-319-56997-0_3; Faldu K, 2021, Arxiv, DOI [arXiv:2104.08145, DOI 10.48550/ARXIV.2104.08145]; Fenoglio E., 2022, Discov Artif Intell. 10 mars, V2, P6, DOI DOI 10.1007/S44163-022-00020-W; Freire SK, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544516; Freire SK, 2023, IEEE PERVAS COMPUT, V22, P50, DOI 10.1109/MPRV.2022.3218600; Funk M., 2015, ADJ P 2015 ACM INT J, P1269, DOI DOI 10.1145/2800835.2807942; Hoerner L, 2023, COMPUT SUPP COOP W J, V32, P55, DOI 10.1007/s10606-022-09445-4; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Josifovska K., 2019, HUMAN COMPUTER INTER, P398, DOI DOI 10.1007/978-3-030-22636-7_30; Kimani E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925488, 10.1109/ACII.2019.8925488]; Listl FG, 2021, IEEE INT C EMERG, DOI 10.1109/ETFA45728.2021.9613681; Luo B, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1434; Malinka K, 2023, Arxiv, DOI [arXiv:2303.11146, 10.48550/arXiv.2303.11146, DOI 10.1145/3587102.3588827, DOI 10.48550/ARXIV.2303.11146]; Le NT, 2018, INT J HUM-COMPUT ST, V117, P45, DOI 10.1016/j.ijhcs.2018.02.005; Nov Oded, 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.1003537428540; OpenAI, 2023, GPT-4 Technical Report; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Rabelo RJ, 2019, IFIP ADV INF COMM TE, P55, DOI 10.1007/978-3-030-28464-0_6; Rietzler A, 2019, Arxiv, DOI arXiv:1908.11860; Rodriguez L, 2015, PROCEDIA COMPUT SCI, V75, P327, DOI 10.1016/j.procs.2015.12.254; Soliman Yehya, 2020, Advances in Human Factors, Business Management and Leadership. Proceedings of the AHFE 2019 International Conference on Human Factors, Business Management and Society, and the AHFE International Conference on Human Factors in Management and Leadership. Advances in Intelligent Systems and Computing (AISC 961), P141, DOI 10.1007/978-3-030-20154-8_14; Tang Quy, 2023, Integrating ChatGPT with internal knowledge base and question- answer platform; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Tao WJ, 2019, MANUF LETT, V21, P45, DOI 10.1016/j.mfglet.2019.08.003; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wellsandt S, 2022, IFIP ADV INF COMM TE, V664, P511, DOI 10.1007/978-3-031-16411-8_59; Wellsandt S, 2021, IFIP ADV INF COMM TE, V633, P321, DOI 10.1007/978-3-030-85910-7_34; Xu X, 2021, J MANUF SYST, V61, P530, DOI 10.1016/j.jmsy.2021.10.006; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517553	40	1	1	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0014-9				2023									44	10.1145/3571884.3604313	http://dx.doi.org/10.1145/3571884.3604313			6	Computer Science, Cybernetics; Psychology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Psychology	BW2OK		Green Published			2024-07-03	WOS:001122710800044
C	Hong, YN; Zhen, HY; Chen, PH; Zheng, SH; Du, YL; Chen, ZF; Gan, C		Oh, A; Neumann, T; Globerson, A; Saenko, K; Hardt, M; Levine, S		Hong, Yining; Zhen, Haoyu; Chen, Peihao; Zheng, Shuhong; Du, Yilun; Chen, Zhenfang; Gan, Chuang			3D-LLM: Injecting the 3D World into Large Language Models	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 36, NEURIPS 2023	Advances in Neural Information Processing Systems		English	Proceedings Paper	37th Conference on Neural Information Processing Systems (NeurIPS)	DEC 10-16, 2023	New Orleans, LA					Large language models (LLMs) and Vision-Language Models (VLMs) have been proven to excel at multiple tasks, such as commonsense reasoning. Powerful as these models can be, they are not grounded in the 3D physical world, which involves richer concepts such as spatial relationships, affordances, physics, layout, and so on. In this work, we propose to inject the 3D world into large language models and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. Using three types of prompting mechanisms that we design, we are able to collect over 1M 3D-language data covering these tasks. To efficiently train 3D-LLMs, we first utilize a 3D feature extractor that obtains 3D features from rendered multi-view images. Then, we use 2D VLMs as our backbones to train our 3D-LLMs. By introducing a 3D localization mechanism, 3D-LLMs can better capture 3D spatial information. Experiments on held-out evaluation dataset, ScanQA, SQA3D and 3DMV-VQA, outperform state-of-the-art baselines. In particular, experiments on ScanQA show that our model outperforms state-of-the-art baselines by a large margin (e.g., the BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore, experiments on our held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative examples also show that our model could perform more tasks beyond the scope of existing LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.	[Hong, Yining] Univ Calif Los Angeles, Los Angeles, CA 90024 USA; [Zhen, Haoyu] Shanghai Jiao Tong Univ, Shanghai, Peoples R China; [Chen, Peihao] South China Univ Technol, Guangzhou, Peoples R China; [Zheng, Shuhong] Univ Illinois, Urbana, IL USA; [Du, Yilun] MIT, Cambridge, MA 02139 USA; [Chen, Zhenfang; Gan, Chuang] MIT IBM Watson AI Lab, Cambridge, MA USA; [Gan, Chuang] UMass Amherst, Amherst, MA USA	University of California System; University of California Los Angeles; Shanghai Jiao Tong University; South China University of Technology; University of Illinois System; University of Illinois Urbana-Champaign; Massachusetts Institute of Technology (MIT); University of Massachusetts System; University of Massachusetts Amherst	Hong, YN (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90024 USA.				MIT-IBM Watson AI Lab; DARPA MCS; Cisco; DSO [DSOCO21072]; MERL; Sony; Amazon	MIT-IBM Watson AI Lab(International Business Machines (IBM)); DARPA MCS(United States Department of Defense); Cisco; DSO; MERL; Sony; Amazon	This work was supported by the MIT-IBM Watson AI Lab, DARPA MCS, DSO grant DSOCO21072, and gift funding from MERL, Cisco, Sony, and Amazon. We would also like to thank the computation support from AiMOS, a server cluster for the IBM Research AI Hardware Center.	Achlioptas Panos, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P422, DOI 10.1007/978-3-030-58452-8_25; [Anonymous], 2022, FLAMINGO VISUAL LANG; Awadalla A., 2023, OPENFLAMINGO; Azuma L, 2022, PROC CVPR IEEE, P19107, DOI 10.1109/CVPR52688.2022.01854; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen D.Z., 2020, EUROPEAN C COMPUTER, P202; Chen DZ, 2021, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR46437.2021.00321; Chen Ting, 2021, PIX2SEQ LANGUAGE MOD; Chen Xinlei, 2015, MICROSOFT COCO CAPTI; Cheng B., 2021, Mask2Former for video instance segmentation; Chowdhery A., 2022, ARXIV220402311; Chung Hyung Won, 2022, ARXIV221011416; Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261; Databricks, 2023, FREE DOLL INTR WORLD; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng MT, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3702, DOI 10.1109/ICCV48922.2021.00370; Gadre S. Y., 2022, CLIP WHEELS ZERO SHO; Gong T., 2023, ARXIV230504790; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Hong Y., 2023, 3D CONCEPT LEARNING; Huang C., 2023, VISUAL LANGUAGE MAPS; Huang Pin-Hao, 2021, AAAI, P2021; Jaegle A., 2021, INT C MACH LEARN; Jatavallabhula K. M., 2023, CONCEPTFUSION OPENSE; Jia C, 2021, PR MACH LEARN RES, V139; Kirillov A, 2023, IEEE I CONF COMP VIS, P3992, DOI 10.1109/ICCV51070.2023.00371; Krishna Murthy J., 2020, GRADSLAM DENSE SLAM; Li D., 2022, LAVIS LIB LANGUAGEVI; Li J., 2023, BLIP 2 BOOTSTRAPPING; Li Junnan, 2023, ARXIV230112597; Liu H., 2023, ARXIV230408485; Ma X., 2023, SQA3D SITUATED QUEST; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel Colin, 2020, J MACHINE LEARNING R, V21, P5485, DOI [DOI 10.48550/ARXIV.1910.10683, 10.48550/arxiv.1910.10683]; Ramakrishnan S. K., 2021, 35 C NEUR INF PROC S; Sun C, 2022, PROC CVPR IEEE, P5449, DOI 10.1109/CVPR52688.2022.00538; Sun Q., 2023, EVA CLIP IMPROVED TR; Sun Z., 2023, ARXIV E PRINTS; Wang P., 2022, INT C MACH LEARN; Yadav K., 2022, ARXIV221005633; Ye Shuquan, 2021, IEEE T VISUALIZATION, P2; Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5; Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542; Zhu D., 2023, CHATGPT ASKS BLIP 2	47	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258			ADV NEUR IN			2023														13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8HB					2024-07-03	WOS:001202273400006
J	Bai, JW; Kamatchinathan, S; Kundu, DJ; Bandla, C; Vizcaino, JA; Perez-Riverol, Y				Bai, Jingwen; Kamatchinathan, Selvakumar; Kundu, Deepti J.; Bandla, Chakradhar; Vizcaino, Juan Antonio; Perez-Riverol, Yasset			Open-source large language models in action: A bioinformatics chatbot for PRIDE database	PROTEOMICS			English	Article; Early Access						bioinformatics; dataset discoverability; documentation; large language models; proteomics; public data; software architectures; training	SPECTROMETRY-BASED PROTEOMICS	We here present a chatbot assistant infrastructure () that simplifies user interactions with the PRIDE database's documentation and dataset search functionality. The framework utilizes multiple Large Language Models (LLM): llama2, chatglm, mixtral (mistral), and openhermes. It also includes a web service API (Application Programming Interface), web interface, and components for indexing and managing vector databases. An Elo-ranking system-based benchmark component is included in the framework as well, which allows for evaluating the performance of each LLM and for improving PRIDE documentation. The chatbot not only allows users to interact with PRIDE documentation but can also be used to search and find PRIDE datasets using an LLM-based recommendation system, enabling dataset discoverability. Importantly, while our infrastructure is exemplified through its application in the PRIDE database context, the modular and adaptable nature of our approach positions it as a valuable tool for improving user experiences across a spectrum of bioinformatics and proteomics tools and resources, among other domains. The integration of advanced LLMs, innovative vector-based construction, the benchmarking framework, and optimized documentation collectively form a robust and transferable chatbot assistant infrastructure. The framework is open-source ().	[Bai, Jingwen; Kamatchinathan, Selvakumar; Kundu, Deepti J.; Bandla, Chakradhar; Vizcaino, Juan Antonio; Perez-Riverol, Yasset] European Mol Biol Lab European Bioinformat Inst EM, Wellcome Trust Genome Campus, Cambridge, England; [Perez-Riverol, Yasset] European Mol Biol Lab European Bioinformat Inst EM, Wellcome Trust Genome Campus, Cambridge CB10 1SD, England	Wellcome Trust Sanger Institute; Wellcome Trust Sanger Institute	Perez-Riverol, Y (corresponding author), European Mol Biol Lab European Bioinformat Inst EM, Wellcome Trust Genome Campus, Cambridge CB10 1SD, England.	yperez@ebi.ac.uk	Perez-Riverol, Yasset/H-2873-2019; Vizcaino, Juan Antonio/C-3691-2009	Perez-Riverol, Yasset/0000-0001-6579-6941; Vizcaino, Juan Antonio/0000-0002-3905-4335	Wellcome Trust [223745/Z/21/Z]; Wellcome [BB/S01781X/1, BB/T019670/1, BB/V018779/1, BB/X001911/1]; BBSRC; EMBL; Wellcome Trust [223745/Z/21/Z] Funding Source: Wellcome Trust	Wellcome Trust(Wellcome Trust); Wellcome(Wellcome Trust); BBSRC(UK Research & Innovation (UKRI)Biotechnology and Biological Sciences Research Council (BBSRC)); EMBL; Wellcome Trust(Wellcome Trust)	The authors of the manuscript acknowledge funding from Wellcome [grant number 223745/Z/21/Z], BBSRC grants "PTMeXchange" [BB/S01781X/1], "GRAPPA" [BB/T019670/1]; "3D-Proteomics" [BB/V018779/1], and "DIA-eXchange" [BB/X001911/1], and EMBL core funding.	Cellucci CJ, 2003, PHYS REV E, V67, DOI 10.1103/PhysRevE.67.066210; Chen JW, 2023, Arxiv, DOI arXiv:2309.01431; Cox J, 2008, NAT BIOTECHNOL, V26, P1367, DOI 10.1038/nbt.1511; Dai C., 2023, quantms: A cloud-based pipeline for proteomics reanalysis enables the quantification of 17521 proteins in 9.502 human samples; Dai CX, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26111-3; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Deutsch EW, 2023, J PROTEOME RES, DOI 10.1021/acs.jproteome.2c00637; Deutsch EW, 2023, NUCLEIC ACIDS RES, V51, pD1539, DOI 10.1093/nar/gkac1040; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Huang T, 2023, INNOVATION-AMSTERDAM, V4, DOI 10.1016/j.xinn.2023.100446; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Karimzadeh M, 2018, BRIEF BIOINFORM, V19, P693, DOI 10.1093/bib/bbw134; Le NQK, 2023, PROTEOMICS, V23, DOI 10.1002/pmic.202300011; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li RS, 2023, Arxiv, DOI arXiv:2307.02762; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Le NQK, 2022, PROTEOMICS, V22, DOI 10.1002/pmic.202100232; Perez-Riverol Y, 2022, EXPERT REV PROTEOMIC, V19, P297, DOI 10.1080/14789450.2022.2160324; Perez-Riverol Y, 2022, NUCLEIC ACIDS RES, V50, pD543, DOI 10.1093/nar/gkab1038; Perez-Riverol Y, 2017, NAT BIOTECHNOL, V35, P406, DOI 10.1038/nbt.3790; Perez-Riverol Y, 2014, BBA-PROTEINS PROTEOM, V1844, P63, DOI 10.1016/j.bbapap.2013.02.032; Qin CY, 2021, J PROTEOMICS, V232, DOI 10.1016/j.jprot.2020.104070; Rehfeldt TG, 2023, J PROTEOME RES, DOI 10.1021/acs.jproteome.2c00629; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang W., 2020, P 34 INT C NEURAL IN, V33, P5776; Williams JJ, 2017, ANN NY ACAD SCI, V1387, P54, DOI 10.1111/nyas.13207; Yilmaz M., 2023, BIORXIV	29	0	0	9	9	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1615-9853	1615-9861		PROTEOMICS	Proteomics	2024 MAR 31	2024										10.1002/pmic.202400005	http://dx.doi.org/10.1002/pmic.202400005		MAR 2024	7	Biochemical Research Methods; Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	MM0T7	38556628	Green Submitted, hybrid			2024-07-03	WOS:001193927800001
J	Liu, C; Wang, C; Peng, Y; Li, ZX				Liu, Cheng; Wang, Chao; Peng, Yan; Li, Zhixu			ZVQAF: Zero-shot visual question answering with feedback from large language models	NEUROCOMPUTING			English	Article						Feedback; Large language model; Visual question answering		Due to the prominent zero-shot generalization in new language tasks shown by large language models (LLMs), applying LLMs for zero-shot visual question answering (VQA) has been a new trend. However, most prior approaches directly use off-the-shelf captioning models to generate captions that compose in-context examples for LLMs, and such generated captions may be uninformative, thus leading the LLMs to give false predictions. To address this, we propose zero-shot VQA with feedback from LLMs (ZVQAF), a framework that applies LLMs to discriminate the quality of generated captions and leverages this feedback to train the captioning model. ZVQAF consists of two stages: the first stage is the training with feedback, which enables the captioning model to recognize the task objective and information requirements from the LLM, and the second stage is utilizing the optimized captioning model and LLM for inference. Extensive experiments show that ZVQAF achieves zero-shot VQA performance that is comparable or even superior to those previous zero-shot, few-shot, and end -to -end training approaches. For example, on VQAv2 test dataset, ZVQAF outperforms Flamingo (Alayrac et al., 2022) which employs end -to -end training by a large margin of 8.0%. In addition, on A-OKVQA dataset, ZVQAF outperforms zero-shot method Img2LLM (Guo et al., 2023) by 3.8% when employing LLMs with similar scales.	[Liu, Cheng; Wang, Chao; Peng, Yan] Shanghai Univ, Sch Future Technol, Shanghai, Peoples R China; [Liu, Cheng; Wang, Chao; Peng, Yan] Shanghai Univ, Inst Artificial Intelligence, Shanghai, Peoples R China; [Li, Zhixu] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China	Shanghai University; Shanghai University; Fudan University	Wang, C (corresponding author), Shanghai Univ, Sch Future Technol, Shanghai, Peoples R China.; Wang, C (corresponding author), Shanghai Univ, Inst Artificial Intelligence, Shanghai, Peoples R China.	563295220@shu.edu.cn; cwang@shu.edu.cn; pengyan@shu.edu.cn; zhixuli@fudan.edu.cn			Natural Science Foundation of Shang-hai [23ZR1422800]; National Key Research and Develop-ment Program of China [2022ZD0160603]	Natural Science Foundation of Shang-hai(Natural Science Foundation of Shanghai); National Key Research and Develop-ment Program of China	We thank the anonymous reviewers for their valuable comments. This work was supported by the Natural Science Foundation of Shang-hai (No. 23ZR1422800) , and the National Key Research and Develop-ment Program of China (Grant No. 2022ZD0160603) .	Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Banerjee P, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3420; Bian YC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P930; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Changpinyo S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1947; Chen Z, 2021, LECT NOTES COMPUT SC, V12922, P146, DOI 10.1007/978-3-030-88361-4_9; Cho J, 2021, PR MACH LEARN RES, V139; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai WL, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2383; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Gao F, 2022, PROC CVPR IEEE, P5057, DOI 10.1109/CVPR52688.2022.00501; Gardères F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P489; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Gui LK, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P956; Guo JX, 2023, PROC CVPR IEEE, P10867, DOI 10.1109/CVPR52729.2023.01046; Hu Y, 2023, Arxiv, DOI arXiv:2211.09699; Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045; Jin W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2763; Khashabi Daniel, 2018, P 2018 C N AM CHAPT, V1, P252, DOI 10.18653/v1/N18-1023; Lee H, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4631; Li JN, 2022, PR MACH LEARN RES; Lin Y., 2022, Advances in Neural Information Processing Systems, V35, P10560; Luo Z., 2022, arXiv; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Mokady A., 2021, arXiv; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784; Schwenk D, 2022, LECT NOTES COMPUT SC, V13668, P146, DOI 10.1007/978-3-031-20074-8_9; Shah S, 2019, AAAI CONF ARTIF INTE, P8876; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Su WJ, 2019, ANN NUTR METAB, V75, P31, DOI 10.1159/000501710; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Tiong AMH., 2022, FINDINGS ASS COMPUTA, V2022, P951; Tsimpoukelli M, 2021, ADV NEUR IN, V34; Wang P, 2022, 39 INT C MACHINE LEA; Wang Z., 2021, INT C LEARN REPR; Wei J., 2021, INT C LEAR REPR; Wei JS, 2022, ADV NEUR IN; Wu JL, 2022, AAAI CONF ARTIF INTE, P2712; Xing X., 2023, 37 C NEUR INF PROC S; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yu JH, 2022, Arxiv, DOI arXiv:2205.01917; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553	51	1	1	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	MAY 1	2024	580								127505	10.1016/j.neucom.2024.127505	http://dx.doi.org/10.1016/j.neucom.2024.127505			11	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	SB2Q8					2024-07-03	WOS:001231939000001
J	Sarstedt, M; Adler, SJ; Rau, L; Schmitt, B				Sarstedt, Marko; Adler, Susanne J.; Rau, Lea; Schmitt, Bernd			Using large language models to generate silicon samples in consumer and marketing research: Challenges, opportunities, and guidelines	PSYCHOLOGY & MARKETING			English	Review; Early Access						generative AI; GPT; large language models; silicon samples; synthetic datasets	MEASUREMENT INVARIANCE	Should consumer researchers employ silicon samples and artificially generated data based on large language models, such as GPT, to mimic human respondents' behavior? In this paper, we review recent research that has compared result patterns from silicon and human samples, finding that results vary considerably across different domains. Based on these results, we present specific recommendations for silicon sample use in consumer and marketing research. We argue that silicon samples hold particular promise in upstream parts of the research process such as qualitative pretesting and pilot studies, where researchers collect external information to safeguard follow-up design choices. We also provide a critical assessment and recommendations for using silicon samples in main studies. Finally, we discuss ethical issues of silicon sample use and present future research avenues.	[Sarstedt, Marko; Adler, Susanne J.; Rau, Lea] Ludwig Maximilians Univ Munchen, Inst Mkt, LMU Munich Sch Management, Munich, Germany; [Sarstedt, Marko] Babes Bolyai Univ, Fac Econ & Business Adm, Mkt Dept, Cluj Napoca, Romania; [Schmitt, Bernd] Columbia Univ, Columbia Business Sch, Int Business, New York, NY USA	University of Munich; Babes Bolyai University from Cluj; Columbia University	Sarstedt, M (corresponding author), Ludwig Maximilians Univ Munchen, Inst Mkt, LMU Munich Sch Management, Munich, Germany.	sarstedt@lmu.de	Adler, Susanne Jana/HTS-0120-2023; Sarstedt, Marko/G-5188-2013	Adler, Susanne Jana/0000-0002-3211-6871; Sarstedt, Marko/0000-0002-5424-4268	Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL.	Aarts AA, 2015, SCIENCE, V349, DOI 10.1126/science.aac4716; Abdurahman S., 2023, OSF preprint, DOI [10.31219/osf.io/tg79n, DOI 10.31219/OSF.IO/TG79N]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adler SJ, 2023, J BUS RES, V167, DOI 10.1016/j.jbusres.2023.114189; Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46222; Aher G, 2022, Arxiv, DOI arXiv:2208.10264; Anderson BS, 2022, BUS HORIZONS, V65, P379, DOI 10.1016/j.bushor.2021.05.001; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Atari M., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/5B26T; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brand J., 2023, Harvard Business School Marketing Unit Working Paper No. 23-062, DOI DOI 10.2139/SSRN.4395751; Candal-Pedreira C, 2022, BMJ-BRIT MED J, V379, DOI 10.1136/bmj-2022-071517; Caron Graham., 2022, arXiv; Carstensen LL, 2006, SCIENCE, V312, P1913, DOI 10.1126/science.1127488; Chang CC, 2023, Arxiv, DOI arXiv:2306.01286; Chen Y., 2023, A manager and an AI walk into a bar: Does ChatGPT make biased decisions like we do?, DOI DOI 10.2139/SSRN.4380365; Day A, 2022, SCIENTOMETRICS, V127, P5965, DOI 10.1007/s11192-022-04504-5; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Earley P.Christopher., 2003, Cultural Intelligence: Individual Interactions across Cultures, DOI DOI 10.1515/9780804766005; Fiore K, 2023, Medpagetoday; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gonzalez C, 2023, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916231196766; Guo DH, 2022, TEACH STAT, V44, P68, DOI 10.1111/test.12305; Hagendorff T, 2023, NAT COMPUT SCI, V3, P833, DOI 10.1038/s43588-023-00527-x; Hair JF, 2021, J MARKET THEORY PRAC, V29, P65, DOI 10.1080/10696679.2020.1860683; Hamilton L, 2023, INT J QUAL METH, V22, DOI 10.1177/16094069231201504; Hao K., 2022, TECHNOLOGY REV; Hollebeek LD, 2024, PSYCHOL MARKET, V41, P880, DOI 10.1002/mar.21957; Hutson M, 2023, SCIENCE, V381, P121, DOI 10.1126/science.adj6791; Imschloss M., 2023, Journal of Business Economics, DOI [10.1007/s11573-023-01189-x, DOI 10.1007/S11573-023-01189-X]; Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124; JCGM, 2012, International vocabulary of metrology-Basic and general concepts and associated terms, V3; Jeon J, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2204343; Jiang H, 2024, Arxiv, DOI [arXiv:2305.02547, 10.48550/arXiv.2305.02547]; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Kirshner SN, 2024, J RETAIL CONSUM SERV, V76, DOI 10.1016/j.jretconser.2023.103580; Klein RA, 2018, ADV METH PRACT PSYCH, V1, P443, DOI 10.1177/2515245918810225; Krefeld-Schwalb A, 2023, MARKET LETT, V34, DOI 10.1007/s11002-022-09662-3; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Lietz P, 2010, INT J MARKET RES, V52, P249, DOI 10.2501/S147078530920120X; Lozic E., 2023, arXiv, DOI [10.3390/fi15100336, DOI 10.3390/FI15100336]; Luo B, 2022, WIRES DATA MIN KNOWL, V12, DOI 10.1002/widm.1434; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; McCoy RT, 2023, Arxiv, DOI [arXiv:2309.13638, 10.48550/arXiv.2309.13638]; Memarian B., 2023, Computers and Education: Artificial Intelligence, V5, P100152, DOI DOI 10.1016/J.CAEAI.2023.100152; Miller J, 2022, ANNU REV PSYCHOL, V73, P691, DOI 10.1146/annurev-psych-020821-094927; Ooi KB, 2023, J COMPUT INFORM SYST, DOI 10.1080/08874417.2023.2261010; Park P.S., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2302.07267, 10.48550/arXiv.2302.07267]; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Pérez-Neri I, 2022, CLIN RHEUMATOL, V41, P2241, DOI 10.1007/s10067-022-06198-9; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Rigdon E.E., 2022, Review of Marketing Research: Measurement in Marketing, P53, DOI 10.1108/S1548-643520220000019003; Rigdon E, 2023, INT J CONSUM STUD, V47, P1596, DOI 10.1111/ijcs.12906; Rigdon EE, 2020, NAT HUM BEHAV, V4, P329, DOI 10.1038/s41562-019-0806-0; Roseler L., 2022, ReD: Replication Database; Santurkar S, 2023, Arxiv, DOI arXiv:2303.17548; Sarstedt M, 2023, J BUS RES, V163, DOI 10.1016/j.jbusres.2023.113942; Schlägel C, 2016, EUR MANAG J, V34, P633, DOI 10.1016/j.emj.2016.06.002; Simonsohn U, 2014, J EXP PSYCHOL GEN, V143, P534, DOI 10.1037/a0033242; Stahl BC., 2022, AI and Ethics, V2, P65, DOI DOI 10.1007/S43681-021-00080-1; Stahl BC, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102700; Susarl A, 2023, INFORM SYST RES, V34, P399, DOI 10.1287/isre.2023.ed.v34.n2; Taleb N. N., 2023, Enjoy #AI [@nntaleb] [Tweet]. Twitter; Taloni A, 2023, JAMA OPHTHALMOL, V141, P1174, DOI 10.1001/jamaophthalmol.2023.5162; Ton LAN, 2024, J MARKETING, V88, P121, DOI 10.1177/00222429231192049; Vandenberg RJ, 2000, ORGAN RES METHODS, V3, P4, DOI 10.1177/109442810031002; Wagenmakers EJ, 2007, PSYCHON B REV, V14, P779, DOI 10.3758/BF03194105; Wu S, 2023, Arxiv, DOI arXiv:2308.04709	72	1	1	44	44	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0742-6046	1520-6793		PSYCHOL MARKET	Psychol. Mark.	2024 FEB 10	2024										10.1002/mar.21982	http://dx.doi.org/10.1002/mar.21982		FEB 2024	17	Business; Psychology, Applied	Social Science Citation Index (SSCI)	Business & Economics; Psychology	HN5A9		hybrid			2024-07-03	WOS:001160184300001
J	Rozado, D				Rozado, David			The Political Biases of ChatGPT	SOCIAL SCIENCES-BASEL			English	Article						algorithmic bias; political bias; AI; large language models; LLMs; ChatGPT; OpenAI		Recent advancements in Large Language Models (LLMs) suggest imminent commercial applications of such AI systems where they will serve as gateways to interact with technology and the accumulated body of human knowledge. The possibility of political biases embedded in these models raises concerns about their potential misusage. In this work, we report the results of administering 15 different political orientation tests (14 in English, 1 in Spanish) to a state-of-the-art Large Language Model, the popular ChatGPT from OpenAI. The results are consistent across tests; 14 of the 15 instruments diagnose ChatGPT answers to their questions as manifesting a preference for left-leaning viewpoints. When asked explicitly about its political preferences, ChatGPT often claims to hold no political opinions and to just strive to provide factual and neutral information. It is desirable that public facing artificial intelligence systems provide accurate and factual information about empirically verifiable issues, but such systems should strive for political neutrality on largely normative questions for which there is no straightforward way to empirically validate a viewpoint. Thus, ethical AI systems should present users with balanced arguments on the issue at hand and avoid claiming neutrality while displaying clear signs of political bias in their content.	[Rozado, David] Te Pukenga New Zealand Inst Skills & Technol, Hamilton 3244, New Zealand		Rozado, D (corresponding author), Te Pukenga New Zealand Inst Skills & Technol, Hamilton 3244, New Zealand.	david.rozado@op.ac.nz	Rozado, David/O-6934-2014	Rozado, David/0000-0001-6849-4746				Adamopoulou Eleni, 2020, MACHINE LEARNING APP, V2, DOI DOI 10.1016/J.MLWA.2020.100006; Ain QT, 2017, INT J ADV COMPUT SC, V8, P424; American Enterprise Institute-AEI (blog), AR COLL U TOO LIB WH; [Anonymous], 2006, POLITICAL IDEOLOGY S; [Anonymous], Political Spectrum Quiz-Your Political Label; [Anonymous], ?About us"; [Anonymous], POLITICS TEST SURVEY; Archive View Author and Get Author RSS Feed, 2021, TWITT EMPL GIV DEM W; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Cowgill Bo, 2017, Working Paper: NSF Trustworthy Algorithms; Dabre R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3406095; Garcia M., 2016, World Policy Journal, V33, P111, DOI 10.1215/07402775-3813015; Hajian S, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2125, DOI 10.1145/2939672.2945386; Hopmann D. N., 2010, JOURNALISM, V11, P661, DOI [10.1177/1464884910379706, DOI 10.1177/1464884910379706]; IDRlabs, 8 Values Political Test; IDRlabs, TEST COORD POL; IDRlabs, ID TEST; IDRlabs, POL BIAS TEST; IDRlabs, POL COORD TEST; IDRlabs, EYS POL TEST; ISideWith, ISIDEWITH 2023 POL Q; Kirkpatrick K, 2016, COMMUN ACM, V59, P16, DOI 10.1145/2983270; Kühl N, 2022, COGN SYST RES, V76, P78, DOI 10.1016/j.cogsys.2022.09.002; Langbert M., 2018, ACAD QUESTIONS, V31, P186, DOI DOI 10.1007/S12129-018-9700-X; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Nissim M, 2019, Arxiv, DOI arXiv:1905.09866; O'Mahony N, 2020, ADV INTELL SYST COMP, V943, P128, DOI 10.1007/978-3-030-17795-9_10; Pew Research Center-U.S. Politics & Policy (blog), POL TYP QUIZ; Political Quiz, POL QUIZ DO YOU STAN; ProProfs Quiz, POLITICAL IDEOLOGY T; Reuters Institute for the Study of Journalism, JOURN UK; Rozado D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231189; Schoffstall Joe, 2022, FOX NEWS 0427; The Advocates for Self-Government, WORLDS SMALL POL QUI; The Harvard Crimson, MOR 80 PERC SURV HAR; Vaswani A, 2017, ADV NEUR IN, V30; Weaver DH, 2019, J MASS COMMUN Q, V96, P101, DOI 10.1177/1077699018778242; Wikipedia, 2023, STABL DIFF; Wikipedia, 2022, GPT 2; Wikipedia, 2023, ALG BIAS; Wikipedia, 2023, ChatGPT; Zhou, 2022, ARXIV	42	41	43	18	87	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-0760		SOC SCI-BASEL	Soc. Sci.-Basel	MAR	2023	12	3							148	10.3390/socsci12030148	http://dx.doi.org/10.3390/socsci12030148			8	Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	D4DW4		gold			2024-07-03	WOS:000968261800001
J	Munyer, T; Tanvir, AA; Das, A; Zhong, X				Munyer, Travis; Tanvir, Abdullah All; Das, Arjon; Zhong, Xin			DeepTextMark: A Deep Learning-Driven Text Watermarking Approach for Identifying Large Language Model Generated Text	IEEE ACCESS			English	Article						Text source detection; large language model text detection; text watermarking; deep learning		The rapid advancement of Large Language Models (LLMs) has significantly enhanced the capabilities of text generators. With the potential for misuse escalating, the importance of discerning whether texts are human-authored or generated by LLMs has become paramount. Several preceding studies have ventured to address this challenge by employing binary classifiers to differentiate between human-written and LLM-generated text. Nevertheless, the reliability of these classifiers has been subject to question. Given that consequential decisions may hinge on the outcome of such classification, it is imperative that text source detection is of high caliber. In light of this, the present paper introduces DeepTextMark, a deep learning-driven text watermarking methodology devised for text source identification. By leveraging Word2Vec and Sentence Encoding for watermark insertion, alongside a transformer-based classifier for watermark detection, DeepTextMark epitomizes a blend of blindness, robustness, imperceptibility, and reliability. As elaborated within the paper, these attributes are crucial for universal text source detection, with a particular emphasis in this paper on text produced by LLMs. DeepTextMark offers a viable "add-on" solution to prevailing text generation frameworks, requiring no direct access or alterations to the underlying text generation mechanism. Experimental evaluations underscore the high imperceptibility, elevated detection accuracy, augmented robustness, reliability, and swift execution of DeepTextMark.	[Munyer, Travis; Tanvir, Abdullah All; Das, Arjon; Zhong, Xin] Univ Nebraska Omaha, Dept Comp Sci, Omaha, NE 68182 USA	University of Nebraska System; University of Nebraska Omaha	Zhong, X (corresponding author), Univ Nebraska Omaha, Dept Comp Sci, Omaha, NE 68182 USA.	xzhong@unomaha.edu		Tanvir, Abdullah All/0000-0003-4153-1281				Bird S., 2009, NATURAL LANGUAGE PRO; Cer D, 2018, ARXIV; Databrickslab, 2023, Dolly 15k Dataset; Dyson P., Inflect; Fang H, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2267, DOI 10.1145/3503161.3548049; Ghag KV, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND CONTROL (IC4); GPTZero, 2023, About us; Hugging Face, Hugging Face Datasets; Kamaruddin NS, 2018, IEEE ACCESS, V6, P8011, DOI 10.1109/ACCESS.2018.2796585; Kingma, 2015, P 3 INT C LEARN REPR, V500; Kirchenbauer J., 2023, P MACHINE LEARNING R, V202, P17061; medium, 2023, Testing Gptzero: A Trending CHATGPT Detection Tool; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mitchell E., 2023, INT C MACHINE LEARNI, P24950; nerdschalk, 2023, Is Gptzero Accurate? Can It Detect Chatgpt? Here's What Our Tests Revealed; Onan A, 2024, IEEE ACCESS, V12, P4413, DOI 10.1109/ACCESS.2024.3349971; Onan A, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101611; Onan A, 2023, EXPERT SYST APPL, V232, DOI 10.1016/j.eswa.2023.120908; Onan A, 2022, J KING SAUD UNIV-COM, V34, P2098, DOI 10.1016/j.jksuci.2022.02.025; openai, 2023, New AI Classifier for Indicating AI-Written Text; openai, 2023, ChatGPT; Ou C., 2003, Comput. Sci., V725; Rizzo SG, 2019, EURASIP J INF SECUR, DOI 10.1186/s13635-019-0094-2; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; searchenginejournal, 2023, How the ChatGPT Watermark Works and Why It Could Be Defeated; Vaswani A, 2017, ADV NEUR IN, V30; Wan WB, 2022, NEUROCOMPUTING, V488, P226, DOI 10.1016/j.neucom.2022.02.083	28	0	0	8	8	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						40508	40520		10.1109/ACCESS.2024.3376693	http://dx.doi.org/10.1109/ACCESS.2024.3376693			13	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	LU6I7		gold, Green Submitted			2024-07-03	WOS:001189350200001
C	Sarsa, S; Denny, P; Hellas, A; Leinonen, J			ACM	Sarsa, Sami; Denny, Paul; Hellas, Arto; Leinonen, Juho			Automatic Generation of Programming Exercises and Code Explanations Using Large Language Models	PROCEEDINGS OF THE 2022 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, ICER 2022, VOL. 1			English	Proceedings Paper	18th Annual ACM Conference on International Computing Education Research (ICER)	AUG 07-11, 2022	ELECTR NETWORK	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		Natural language generation; OpenAI Codex; GPT-3; CS1; Programming; exercises; Code explanations; Robosourcing; Exercise generation; Resource generation; Automated feedback; Large language; models	INSTRUCTION	This article explores the natural language generation capabilities of large language models with application to the production of two types of learning resources common in programming courses. Using OpenAI Codex as the large language model, we create programming exercises (including sample solutions and test cases) and code explanations, assessing these qualitatively and quantitatively. Our results suggest that the majority of the automatically generated content is both novel and sensible, and in some cases ready to use as is. When creating exercises we find that it is remarkably easy to influence both the programming concepts and the contextual themes they contain, simply by supplying keywords as input to the model. Our analysis suggests that there is significant value in massive generative machine learning models as a tool for instructors, although there remains a need for some oversight to ensure the quality of the generated content before it is delivered to students. We further discuss the implications of OpenAI Codex and similar tools for introductory programming education and highlight future research streams that have the potential to improve the quality of the educational experience for both teachers and students alike.	[Sarsa, Sami; Hellas, Arto; Leinonen, Juho] Aalto Univ, Espoo, Finland; [Denny, Paul] Univ Auckland, Auckland, New Zealand	Aalto University; University of Auckland	Sarsa, S (corresponding author), Aalto Univ, Espoo, Finland.	sami.sarsa@aalto.fi; paul@cs.auckland.ac.nz; arto.hellas@aalto.fi; juho.2.1einonen@aalto.fi	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449				Aarne O, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P759, DOI 10.1145/3159450.3159493; Ala-Mutka KM, 2005, COMPUT SCI EDUC, V15, P83, DOI 10.1080/08993400500150747; Albluwi I, 2020, ACM T COMPUT EDUC, V20, DOI 10.1145/3371156; Allen JM., 2018, 2018 ASEE ANN C EXPO; Althoff Cory, 2022, The Self Taught Programmer: The Definitive Guide to Programming Professionally; [Anonymous], 2014, P 10 ANN C INT COMPU; BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191; Baniassad Elisa, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P1062, DOI 10.1145/3408877.3432430; Biggs John B., 1982, Evaluating the quality of learning: the SOLO taxonomy (structure of the observed learning outcome), Vxiii; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen BL, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P563, DOI 10.1145/3328778.3366879; Chen M., 2021, arXiv; Ciniselli Matteo, 2022, arXiv; Crouch CH, 2001, AM J PHYS, V69, P970, DOI 10.1119/1.1374249; Denny P, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P146, DOI 10.1145/3059009.3059033; Denny P, 2011, SIGCSE 11: PROCEEDINGS OF THE 42ND ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P471; Denny Paul, 2015, P 15 KOL CALL C COMP, P13, DOI DOI 10.1145/2828959.2828967; Drori I, 2022, Arxiv, DOI [arXiv:2112.15594, 10.48550/ARXIV.2112.15594, DOI 10.48550/ARXIV.2112.15594]; Du YM, 2020, PROCEEDINGS OF THE TWENTY-SECOND AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE'20, P195, DOI 10.1145/3373165.3373187; Duckworth A., 2013, Observer, V26; Duran Rodrigo, 2021, PREPRINT; Edwards John, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P216, DOI 10.1145/3372782.3406259; Edwards Stephen H., 2008, SIGCSE Bulletin, V40, P167, DOI 10.1145/1473195.1473240; ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363; Ettles Andrew, 2018, P 20 AUSTR COMP ED C, P83, DOI 10.1145/3160489.3160493; Falkner K, 2019, CAMB HANDB PSYCHOL, P445; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Fisler Kathi, 2014, P 10 ANN C INT COMP, P35, DOI [DOI 10.1145/2632320.2632346, 10.1145/2632320.2632346]; Fowler Max, 2021, P 52 ACM TECHNICAL S, P1163, DOI [10.1145/3408877.3432539, DOI 10.1145/3408877.3432539]; Hanks B, 2011, COMPUT SCI EDUC, V21, P135, DOI 10.1080/08993408.2011.579808; Hassan M, 2021, ICER 2021: PROCEEDINGS OF THE 17TH ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P115, DOI 10.1145/3446871.3469765; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Hellas A, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P238, DOI 10.1145/3059009.3059065; Hovemeyer David., 2013, Proceeding of the 44th ACM technical symposium on Computer science education, P742, DOI 10.1145/2445196.2445451; Ihantola P., 2010, P KOLI CALLING, P86, DOI 10.1145/1930464.1930480; Izu C, 2018, PR IEEE INT CONF TEA, P965, DOI 10.1109/TALE.2018.8615375; Jenkins MA, 1967, An algorithm for an automatic general polynomial solver; Jia Y, 2011, IEEE T SOFTWARE ENG, V37, P649, DOI 10.1109/TSE.2010.62; Kennedy Cazembe, 2020, P 2020 ACM C INNOVAT, P166, DOI [10.1145/3341525.3387392, DOI 10.1145/3341525]; Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711; Kim Juho, 2015, Learnersourcing: improving learning with collective learner activity; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lehtinen T, 2021, INT C PROGRAM COMPRE, P467, DOI 10.1109/ICPC52881.2021.00054; Leinonen Juho, 2021, ACE '21:Proceedings of the 23rd Australasian Computing Education Conference, P30, DOI 10.1145/3441636.3442302; Leinonen Juho, 2020, ITiCSE '20: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, P349, DOI 10.1145/3341525.3387385; Leinonen J, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P885, DOI 10.1145/3478431.3499372; Leinonen Juho, 2016, Proceedings of the 2016 ACM Conference on Innovation and Technology in Computer Science Education, P160, DOI [DOI 10.1145/2899415.2899472, 10.1145/2899415.2899472]; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lister R., 2004, SIGCSE Bulletin, V36, P119, DOI 10.1145/1041624.1041673; Lister R., 2006, SIGCSE Bulletin, V38, P118, DOI 10.1145/1140123.1140157; Lister R, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P161, DOI 10.1145/1595496.1562930; Lister Raymond, 2020, P 9 COMPUTER SCI ED, DOI DOI 10.1145/3442481.3442498; Lobb Richard, 2016, ACM Inroads, V7, P47, DOI 10.1145/2810041; Longi Krista, 2015, P 15 KOLI CALLING C, P60; McCauley R, 2008, COMPUT SCI EDUC, V18, P67, DOI 10.1080/08993400802114581; Murphy Laurie, 2012, PROC 9 ANN INT C INT, P111, DOI DOI 10.1145/2361276.2361299; Nip T, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P568, DOI 10.1145/3159450.3159500; Nygren H, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P44, DOI 10.1145/3304221.3319768; Nygren Henrik, 2019, P 1 UK IRELAND COMPU, P1; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Pearce Hammond, 2022, arXiv, DOI [10.48550/arXiv.2202.01142, DOI 10.48550/ARXIV.2202.01142]; Perkins D. N., 1986, Journal of Educational Computing Research, V2, P37, DOI 10.2190/GUJT-JCBJ-Q6QU-Q9PL; Phillips R., 2013, Interactions, V20, P74, DOI [10.1145/2505290, DOI 10.1145/2505290]; Pirttinen N, 2022, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2022, VOL 1, P12, DOI 10.1145/3502718.3524762; Pirttinen N, 2018, ITICSE'18: PROCEEDINGS OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P326, DOI 10.1145/3197091.3197117; Porter L, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P858, DOI 10.1145/3159450.3159457; Qi RX, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P427, DOI 10.1145/3328778.3366939; Rosenzweig EQ, 2019, CAMB HANDB PSYCHOL, P617; Saarinen S, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P606, DOI 10.1145/3287324.3287504; Sanders K., 2013, Proceedings of the ITiCSE Working Group Reports Conference on Innovation and Technology in Computer Science Education-Working Group Reports, ITiCSE -WGR'13, P33, DOI DOI 10.1145/2543882.2543885; Sanders K, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P145, DOI 10.1145/3105726.3106192; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Seppala Otto, 2015, P 15 KOL CALL C COMP, P87; Sheard J, 2008, ITICSE '08: PROCEEDINGS OF THE 13TH ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P209; Shulman LS, 2005, DAEDALUS-US, V134, P52, DOI 10.1162/0011526054622015; Shute VJ, 2008, REV EDUC RES, V78, P153, DOI 10.3102/0034654307313795; Singh Anjali, 2021, P 8 ACM C LEARNING S, P221; SOLOWAY E, 1984, IEEE T SOFTWARE ENG, V10, P595, DOI 10.1109/TSE.1984.5010283; SOLOWAY E, 1986, COMMUN ACM, V29, P850, DOI 10.1145/6592.6594; Stephenson B, 2018, PROCEEDINGS OF THE 23RD WESTERN CANADIAN CONFERENCE ON COMPUTING EDUCATION (WCCCE '18), DOI 10.1145/3209635.3209639; Ullah Z, 2018, COMPUT APPL ENG EDUC, V26, P2328, DOI 10.1002/cae.21974; Venables A, 2009, FIFTH INTERNATIONAL COMPUTING EDUCATION RESEARCH WORKSHOP - ICER 2009, P117; Vihavainen A, 2011, SIGCSE 11: PROCEEDINGS OF THE 42ND ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P93; Vollmeyer R, 2005, LEARN INSTR, V15, P589, DOI 10.1016/j.learninstruc.2005.08.001; Vygotsky L., 1978, Mind in society: The development of higher psychological processes, DOI [DOI 10.2307/J.CTVJF9VZ4, 10.2307/j.ctvjf9vz4]; Whalley Jacqueline L., 2006, ACE '06, V52, P243; Williams JJ, 2016, PROCEEDINGS OF THE THIRD (2016) ACM CONFERENCE ON LEARNING @ SCALE (L@S 2016), P379, DOI 10.1145/2876034.2876042; Williams L, 2000, IEEE SOFTWARE, V17, P19, DOI 10.1109/52.854064; Wrenn J, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P51, DOI 10.1145/3230977.3230999; Xie B, 2019, COMPUT SCI EDUC, V29, P205, DOI 10.1080/08993408.2019.1565235; Xie B, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P344, DOI 10.1145/3159450.3159527; Yan L, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P253, DOI 10.1145/3287324.3287483	94	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9194-8				2023							27	43						17	Education & Educational Research; Education, Scientific Disciplines; Literary Theory & Criticism	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research; Literature	BW3UJ					2024-07-03	WOS:001143762100004
J	Zuber, N; Gogoll, J				Zuber, Niina; Gogoll, Jan			Vox Populi, Vox ChatGPT: Large Language Models, Education and Democracy	PHILOSOPHIES			English	Article						large language models; AI; ethics; democracy; education; generative AI	AI	In the era of generative AI and specifically large language models (LLMs), exemplified by ChatGPT, the intersection of artificial intelligence and human reasoning has become a focal point of global attention. Unlike conventional search engines, LLMs go beyond mere information retrieval, entering into the realm of discourse culture. Their outputs mimic well-considered, independent opinions or statements of facts, presenting a pretense of wisdom. This paper explores the potential transformative impact of LLMs on democratic societies. It delves into the concerns regarding the difficulty in distinguishing ChatGPT-generated texts from human output. The discussion emphasizes the essence of authorship, rooted in the unique human capacity for reason-a quality indispensable for democratic discourse and successful collaboration within free societies. Highlighting the potential threats to democracy, this paper presents three arguments: the Substitution argument, the Authenticity argument, and the Facts argument. These arguments highlight the potential risks that are associated with an overreliance on LLMs. The central thesis posits that widespread deployment of LLMs may adversely affect the fabric of a democracy if not comprehended and addressed proactively and properly. In proposing a solution, we advocate for an emphasis on education as a means to mitigate risks. We suggest cultivating thinking skills in children, fostering coherent thought formulation, and distinguishing between machine-generated output and genuine, i.e., human, reasoning. The focus should be on the responsible development and usage of LLMs, with the goal of augmenting human capacities in thinking, deliberating and decision-making rather than substituting them.	[Zuber, Niina; Gogoll, Jan] Bavarian Res Inst Digital Transformat, D-80333 Munich, Germany		Gogoll, J (corresponding author), Bavarian Res Inst Digital Transformat, D-80333 Munich, Germany.	niina.zuber@bidt.digital; jan.gogoll@bidt.digital			Research Institute for Digital Transformation	Research Institute for Digital Transformation	No Statement Available	Adam M., 2023, PE 751.478 Artificial Intelligence, Democracy and Elections, P4; AGAR N., 2019, BE HUMAN DIGITAL EC; Aichholzer G., 2020, European E-Democracy in Practice, P93; [Anonymous], 2023, CNN Business; Aral S, 2019, SCIENCE, V365, P858, DOI 10.1126/science.aaw8243; Arguedas AR., 2023, Automating Democracy: Generative AI, Journalism, and the Future of Democracy; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Arthur W, 1998, HUM PERFORM, V11, P57, DOI 10.1207/s15327043hup1101_3; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bengio Y, 2023, J DEMOCR, V34, P111, DOI 10.1353/jod.2023.a907692; Bostrom N., 1998, Int. J. Futures Stud., V2, P12; Brinkmann M., 2021, Die Wiederkehr des Ubens: Praxis und Theorie Eines Padagogischen Grundphanomens; Carr Nicholas., 2014, The Glass Cage: Automation and Us; Coeckelbergh Mark., 2013, HUMAN BEING RISK ENH; Cohen Joshua., 1999, RATIO JURIS, V12, P385, DOI DOI 10.1111/1467-9337.00132; Deb A, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P237, DOI 10.1145/3308560.3316486; Dewey J., 1998, WE THINK; Dewey J, 1903, ELEM SCH TEACH, V4, P193, DOI 10.1086/453309; Dewey John., 1988, The Later Works, 1925-1953; Duffy C., 2023, CNN Business; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Feier T, 2022, SCI ENG ETHICS, V28, DOI 10.1007/s11948-022-00372-7; Gogoll J., 2021, Philosophy & Technology, DOI DOI 10.1007/S13347-021-00451-W; Gogoll J, 2018, J BEHAV EXP ECON, V74, P97, DOI 10.1016/j.socec.2018.04.003; Habermas Jrgen., 2022, Ein neuer Strukturwandel der ffentlichkeit und die deliberative Politik; Habermas Jurgen., 1981, THEORIE KOMMUNIKATIV; Heidegger Martin., 1971, On the Way to Language; Heikkila M., 2023, This New Data Poisoning Tool Lets Artists Fight Back Against Generative AI; HOBBES Thomas., 1998, Leviathan, Oxford World's Classics; Hutton JS, 2020, JAMA PEDIATR, V174, DOI 10.1001/jamapediatrics.2019.3869; Jowett Benjamin, Phaedrus, VIII; KANT I., 1987, Critique of Judgment; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kreps S, 2023, J DEMOCR, V34, P122, DOI 10.1353/jod.2023.a907693; Kripke, 1982, WITTGENSTEIN RULES P; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Krügel S, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107483; Larson Erik., 2021, The Myth of Artificial Intelligence: Why Computers Cant Think the Way We Do; Loor M., 2023, ChatGPT Cannot Do Democracy; Luckner A., 2007, Freies Selbstsein. Authentizitat und Regression; Mead George Herbert, 1934, MIND SELF SOC, DOI DOI 10.7208/CHICAGO/9780226112879.001.0001; Mickle T., 2023, New York Times23 November; Nida-Rumelin J., 2022, Digital Humanism: For a Humane Transformation of Democracy, Economy and Culture in the Digital Age, P127; Nida-Rumelin J., 2020, Die Gefahrdete Rationalitat der Demokratie: Ein Politischer Traktat; Nida-Rumelin J., 2023, Introduction to Digital Humanism: A Textbook, P17; Nida-Rumelin J., 1999, Demokratie als Kooperation; Nida-Rumelin J., 2023, A Theory of Practical Reason; Nietzsche Friedrich., 2009, Ecce Homo: How to Become What You Are; Nyholm Sven, 2024, Camb Q Healthc Ethics, V33, P76, DOI 10.1017/S0963180123000464; O'Connor Flannery., 1979, The Habit of Being; Putra FW, 2023, J PUBLIC HEALTH-UK, V45, pe840, DOI 10.1093/pubmed/fdad120; Rawls John., 1993, Political liberalism; Rawls John., 1971, A theory of justice, DOI [10.2307/j.ctvjf9z6v, DOI 10.2307/J.CTVJF9Z6V, DOI 10.4159/9780674042605]; Rawte V, 2023, Arxiv, DOI arXiv:2309.05922; Rowlands I, 2008, ASLIB PROC, V60, P290, DOI 10.1108/00012530810887953; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Specian P., 1980, PREPRINT; Stahl BC, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102700; Strawson Peter., 2008, FREEDOM RESENTMENT O, DOI [10.4324/9780203882566, DOI 10.4324/9780203882566, 10.4324/9780203882566-7]; Vallor Shannon., 2016, Technology and the Virtues: A Philosophical Guide to a Future Worth Wanting, DOI [10.1093/acprof:oso/9780190498511.001.0001, DOI 10.1093/ACPROF:OSO/9780190498511.001.0001]; Wedgwood R., 2017, The value of rationality; Wilson E.O., 1975, P1; Yesilyurt E, 2023, EDUC INF TECHNOL, V28, P9885, DOI 10.1007/s10639-022-11311-1; Zuber N., 2023, Introduction to Digital Humanism: A Textbook, P339; Zuber N, 2022, HUM SOC SCI COMMUN, V9, DOI 10.1057/s41599-022-01206-4	65	1	1	7	7	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2409-9287		PHILOSOPHIES	Philosophies	FEB	2024	9	1							13	10.3390/philosophies9010013	http://dx.doi.org/10.3390/philosophies9010013			18	History & Philosophy Of Science; Philosophy	Emerging Sources Citation Index (ESCI)	History & Philosophy of Science; Philosophy	IT1B8		Green Submitted, gold			2024-07-03	WOS:001168481500001
C	Kirova, VD; Ku, CS; Laracy, JR; Marlowe, TJ			Assoc Computing Machinery	Kirova, Vassilka D.; Ku, Cyril S.; Laracy, Joseph R.; Marlowe, Thomas J.			Software Engineering Education Must Adapt and Evolve for an LLM (Large Language Model) Environment	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		Software engineering; software engineering education; generative AI; large language models (LLMs); responsible AI; ChatGPT; software ethics; software engineering ethics		In the era of artificial intelligence (AI), generative AI, and Large Language Models (LLMs) in particular, have become increasingly significant in various sectors. LLMs such as GPT expand their applications, from content creation to advanced code completion. They offer unmatched opportunities but pose unique challenges to the software engineering domain. This paper discusses the necessity and urgency for software engineering education to adapt and evolve to prepare software engineers for the emerging LLM environment. While existing literature and social media have investigated AI's integration into various educational spheres, there is a conspicuous gap in examining the specifics of LLMs' implications for software engineering education. We explore the goals of software engineering education, and changes to software engineering, software engineering education, course pedagogy, and ethics. We argue that a holistic approach is needed, combining technical skills, ethical awareness, and adaptable learning strategies. This paper seeks to contribute to the ongoing conversation about the future of software engineering education, emphasizing the importance of adapting and evolving to remain in sync with rapid advancements in AI and LLMs. It is hoped that this exploration will provide valuable insights for educators, curriculum developers, and policymakers in software engineering.	[Kirova, Vassilka D.] Bell Labs Consulting, Nokia, New Providence, NJ 07974 USA; [Ku, Cyril S.] William Paterson Univ, Wayne, NJ USA; [Laracy, Joseph R.; Marlowe, Thomas J.] Seton Hall Univ, S Orange, NJ USA	Nokia Corporation; Nokia Bell Labs; Seton Hall University	Kirova, VD (corresponding author), Bell Labs Consulting, Nokia, New Providence, NJ 07974 USA.	vassilka.kirova@bell-labs-consulting.com; kuc@wpunj.edu; joseph.laracy@shu.edu; thomas.marlowe@shu.edu						Ahmad A, 2023, 27TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, EASE 2023, P279, DOI 10.1145/3593434.3593468; Anderson J.M., 2020, Journal of Systemics, Cybernetics, and Informatics, V18, P41; [Anonymous], 2011, Engenharia de Software; [Anonymous], 2022, 16th State of Agile Report; [Anonymous], 2016, Software engineering: modern approaches; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Banerjee P., 2023, PREPRINT, DOI [10.36227/techrxiv.22639705.v1, DOI 10.36227/TECHRXIV.22639705.V1]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bartels M., 2023, Scientific AmericanMay 25,; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Booch G., 1999, The UML Users Guide; Caballar R.D., 2022, IEEE Spectrum; Cho A., HypothesisDriven Development; Daun M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P110, DOI 10.1145/3587102.3588815; Ebert C, 2023, IEEE SOFTWARE, V40, P30, DOI 10.1109/MS.2023.3265877; Feldt R, 2018, INT WORK REAL ARTIF, P35, DOI 10.1145/3194104.3194109; Fowler M., 2001, Software Development, V9, P28; Fowler M., 1999, REFACTORING IMPROVIN; Gadiraju V, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P205, DOI 10.1145/3593013.3593989; Gamma E., 1995, DESIGN PATTERNS ELEM; Gordon R., 2023, MIT CSAILMarch 3,; Ha Y. J., Exploring the impact of generative AI on the future of teaching and learning; Hajian S, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2125, DOI 10.1145/2939672.2945386; Harris C.E., 2019, Engineering Ethics: Concepts and Cases; Havazík O, 2020, INT C CONTROL DECISI, P331, DOI 10.1109/CoDIT49905.2020.9263937; Institute of Electrical and Electronics Engineers (IEEE), Software Engineering Body of Knowledge (SWEBOK); Jacobson I., 1999, AW OBJ TECHNOL S, V1; Jastroch N., 2011, PROC 17 INT C CONCUR, P1; Joint Task Force on Computing Curricula, 2015, Software Engineering 2014: Curriculum Guidelines for Undergraduate Degree Programs in Software Engineering; Joint Task Force on Computing Curricula, CS2023: ACM/ IEEECS/ AAAI Computer Science Curricula. CC2023: Software Engineering; Kernbach S, 2022, IEEE INT CONF INF VI, P227, DOI 10.1109/IV56949.2022.00046; Kirova V. D., Interactive Large Language Models and Software Engineering Workflows: Interactions and Implications; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Luckin R, 2019, BRIT J EDUC TECHNOL, V50, P2824, DOI 10.1111/bjet.12861; Mittelstadt BD, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716679679; Pressman R.S., 2014, Software Engineering: A Practitioner's Approach; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rocha FG, 2021, IEEE GLOB ENG EDUC C, P1122, DOI 10.1109/EDUCON46332.2021.9453916; Schach S.R., 2011, Object-oriented and classical software engineering; Schwaber K., 2002, AGILE SOFTWARE DEV S; Smith C. S., 2023, IEEE SpectrumMarch 13,; Uche A., 2023, 5 Reasons Why Companies Are Banning ChatGPT; Wickens E., 2023, Hidden LayerMarch 24,	44	0	0	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							666	672		10.1145/3626252.3630927	http://dx.doi.org/10.1145/3626252.3630927			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		hybrid			2024-07-03	WOS:001181240800098
C	Cox, SR; Abdul, A; Ooi, WT			ACM	Cox, Samuel Rhys; Abdul, Ashraf; Ooi, Wei Tsang			Prompting a Large Language Model to Generate Diverse Motivational Messages A Comparison with Human-Written Messages	PROCEEDINGS OF THE 11TH CONFERENCE ON HUMAN-AGENT INTERACTION, HAI 2023			English	Proceedings Paper	11th International Conference on Human-Agent Interaction (HAI)	DEC 04-07, 2023	Chalmers Univ Technol, Gothenburg, SWEDEN	Assoc Comp Machinery, ACM SIGCHI	Chalmers Univ Technol	Large Language Models; Crowdsourcing; Prompt Engineering; Creativity		Large language models (LLMs) are increasingly capable and prevalent, and can be used to produce creative content. The quality of content is influenced by the prompt used, with more specific prompts that incorporate examples generally producing better results. On from this, it could be seen that using instructions written for crowdsourcing tasks (that are specific and include examples to guide workers) could prove effective LLM prompts. To explore this, we used a previous crowdsourcing pipeline that gave examples to people to help them generate a collectively diverse corpus of motivational messages. We then used this same pipeline to generate messages using GPT-4, and compared the collective diversity of messages from: (1) crowd-writers, (2) GPT-4 using the pipeline, and (3 & 4) two baseline GPT-4 prompts. We found that the LLM prompts using the crowdsourcing pipeline caused GPT-4 to produce more diverse messages than the two baseline prompts. We also discuss implications from messages generated by both human writers and LLMs.	[Cox, Samuel Rhys; Ooi, Wei Tsang] Natl Univ Singapore, Singapore, Singapore	National University of Singapore	Cox, SR (corresponding author), Natl Univ Singapore, Singapore, Singapore.	samcox@comp.nus.edu.sg; ashrafabdul@pm.me; ooiwt@comp.nus.edu.sg		Cox, Samuel Rhys/0000-0002-4558-6610; Abdul, Ashraf/0000-0002-3383-6440	National Research Foundation, Prime Minister's Office, Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) programme	National Research Foundation, Prime Minister's Office, Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) programme(National Research Foundation, Singapore)	This research is part of the programme DesCartes and is supported by the National Research Foundation, Prime Minister's Office, Singapore under its Campus for Research Excellence and Technological Enterprise (CREATE) programme.	Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cegin J, 2023, Arxiv, DOI [arXiv:2305.12947, DOI 10.48550/ARXIV.2305.12947, 10.48550/arXiv.2305.12947]; Chen S, 2023, medRxiv, DOI [10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316, DOI 10.1101/2023.03.16.23287316V1, DOI 10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316v1]; Coley HL, 2013, AM J PREV MED, V45, P543, DOI 10.1016/j.amepre.2013.07.004; Cox Samuel Rhys, 2021, P 2021 CHI C HUMAN F, DOI DOI 10.1145/3411764.3445782; de Vries RAJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P297, DOI 10.1145/2858036.2858229; Dow SP, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1879831.1879836; Durmus E, 2024, Arxiv, DOI arXiv:2306.16388; Feng SB, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11737; Gilardi F, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2305016120; Hämäläinen P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580688; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jentzsch S, 2023, Arxiv, DOI [arXiv:2306.04563, 10.48550/arXiv.2306.04563]; Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720; Karinshak Elise, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579592; Lampinen AK, 2022, Arxiv, DOI [arXiv:2210.15303, DOI 10.48550/ARXIV.2210.15303]; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lim S, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1129082; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Oktay Ozan, 2018, PREPRINT, DOI [DOI 10.48550/ARXIV, 10.48550/arxiv]; OpenAI, 2023, Api reference-openai api; Siangliulue P, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P609, DOI 10.1145/2984511.2984578; Stevenson C, 2022, Arxiv, DOI [arXiv:2206.08932, 10.48550/arXiv.2206.08932, DOI 10.48550/ARXIV.2206.08932]; Taylor R, 2022, arXiv; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Webson A, 2023, Arxiv, DOI [arXiv:2301.07085, 10.48550/arXiv.2301.07085, DOI 10.48550/ARXIV.2301.07085]; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582	29	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0824-4				2023							378	380		10.1145/3623809.3623931	http://dx.doi.org/10.1145/3623809.3623931			3	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW4HI		Green Submitted			2024-07-03	WOS:001148034200051
C	Jiang, C; Yang, XL			ACM	Jiang, Cong; Yang, Xiaolei			Legal Syllogism Prompting: Teaching Large Language Models for Legal Judgment Prediction	PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023			English	Proceedings Paper	19th International Conference on Artificial Intelligence and Law (ICAIL)	JUN 19-23, 2023	Univ Minho Law Sch, Braga, PORTUGAL	Int Assoc Artificial Intelligence & Law, Univ Minho Informat Dept Engn Sch, JUSGOV Res Ctr Justice & Governance, Centro Algoritmi, Intelligent Syst Associated Lab, Thomson Reuters, Centro Juridico Minho, Antas da Cunha ECIJA Soc Advogados, Visionware, Simplexico, Assoc Advancement Artificial Intelligence, ACM SIGAI	Univ Minho Law Sch	large language models; legal syllogism; legal judgment prediction; chain of thought		Legal syllogism is a form of deductive reasoning commonly used by legal professionals to analyze cases. In this paper, we propose legal syllogism prompting (LoT), a simple prompting method to teach large language models (LLMs) for legal judgment prediction. LoT teaches only that in the legal syllogism the major premise is law, the minor premise is the fact, and the conclusion is judgment. Then the models can produce a syllogism reasoning of the case and give the judgment without any learning, fine-tuning, or examples. On CAIL2018, a Chinese criminal case dataset, we performed zero-shot judgment prediction experiments with GPT-3 models. Our results show that LLMs with LoT achieve better performance than the baseline and chain of thought prompting, the state-of-art prompting method on diverse reasoning tasks. LoT enables the model to concentrate on the key information relevant to the judgment and to correctly understand the legal meaning of acts, as compared to other methods. Our method enables LLMs to predict judgment along with law articles and justification, which significantly enhances the explainability of models.	[Jiang, Cong; Yang, Xiaolei] Peking Univ, Peking Univ Law Sch, Inst Artificial Intelligence, Beijing, Peoples R China; [Jiang, Cong; Yang, Xiaolei] PKU WUHAN Inst Artificial Intelligence, Wuhan, Hubei, Peoples R China	Peking University	Jiang, C (corresponding author), Peking Univ, Peking Univ Law Sch, Inst Artificial Intelligence, Beijing, Peoples R China.; Jiang, C (corresponding author), PKU WUHAN Inst Artificial Intelligence, Wuhan, Hubei, Peoples R China.	jiangcong@pku.edu.cn; yangxiaolei@pku.edu.cn			Peking University - Wuhan East Lake Intelligent Social Governance Opening Program titled "Intelligent public legal consulting service system of East Lake High-Tech Development Zone" [ZX2222M]	Peking University - Wuhan East Lake Intelligent Social Governance Opening Program titled "Intelligent public legal consulting service system of East Lake High-Tech Development Zone"	We appreciate the valuable feedback by the anonymous reviewers. This work was supported by Peking University - Wuhan East Lake Intelligent Social Governance Opening Program titled "Intelligent public legal consulting service system of East Lake High-Tech Development Zone" (ZX2222M).	An Zhenwei, 2022, arXiv; Ashley K. D., 2019, Law Context: A Socio-Legal J., V36, P93; Atkinson K, 2020, ARTIF INTELL, V289, DOI 10.1016/j.artint.2020.103387; Bench-Capon T, 2020, COMPUTATIONAL MODELS, V2669, P74; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Feng Y., 2022, P 31 INT JOINT C ART, P5461, DOI DOI 10.24963/IJCAI.2022/765; Gorski Lukasz, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P60, DOI 10.1145/3462757.3466145; Governatori G, 2022, ARTIF INTELL LAW, V30, P481, DOI 10.1007/s10506-022-09329-4; Huhn Wilson, 2001, Santa Clara L. Rev., V42, P813; Katz DM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174698; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Luo BF, 2017, Arxiv, DOI arXiv:1707.09168; Medvedeva M., 2018, P C EMPIRICAL LEGAL, P1; Posner R.A., 2001, The Problems of Jurisprudence; Saha Swarnadeep, 2022, arXiv; Santosh TYS, 2022, arXiv; Sartor Giovanni, 2022, Artif. Intell. Law, V2022, P1; Shi F, 2023, Arxiv, DOI arXiv:2302.00093; Shuster Kurt, 2022, PREPRINT; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xiao CJ, 2018, Arxiv, DOI arXiv:1807.02478; Yu FY, 2022, Arxiv, DOI arXiv:2212.01326; Zhong HX, 2018, Arxiv, DOI arXiv:1810.05851	26	1	1	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0197-9				2023							417	421		10.1145/3594536.3595170	http://dx.doi.org/10.1145/3594536.3595170			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Government & Law	BW3KK					2024-07-03	WOS:001139079400047
J	Pressman, SM; Borna, S; Gomez-Cabello, CA; Haider, SA; Forte, AJ				Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed Ali; Forte, Antonio Jorge			AI in Hand Surgery: Assessing Large Language Models in the Classification and Management of Hand Injuries	JOURNAL OF CLINICAL MEDICINE			English	Article						artificial intelligence (AI); ChatGPT; Gemini; deep learning; machine learning; hand surgery; hand trauma; management	OPEN FRACTURES; THUMB	Background: OpenAI's ChatGPT (San Francisco, CA, USA) and Google's Gemini (Mountain View, CA, USA) are two large language models that show promise in improving and expediting medical decision making in hand surgery. Evaluating the applications of these models within the field of hand surgery is warranted. This study aims to evaluate ChatGPT-4 and Gemini in classifying hand injuries and recommending treatment. Methods: Gemini and ChatGPT were given 68 fictionalized clinical vignettes of hand injuries twice. The models were asked to use a specific classification system and recommend surgical or nonsurgical treatment. Classifications were scored based on correctness. Results were analyzed using descriptive statistics, a paired two-tailed t-test, and sensitivity testing. Results: Gemini, correctly classifying 70.6% hand injuries, demonstrated superior classification ability over ChatGPT (mean score 1.46 vs. 0.87, p-value < 0.001). For management, ChatGPT demonstrated higher sensitivity in recommending surgical intervention compared to Gemini (98.0% vs. 88.8%), but lower specificity (68.4% vs. 94.7%). When compared to ChatGPT, Gemini demonstrated greater response replicability. Conclusions: Large language models like ChatGPT and Gemini show promise in assisting medical decision making, particularly in hand surgery, with Gemini generally outperforming ChatGPT. These findings emphasize the importance of considering the strengths and limitations of different models when integrating them into clinical practice.	[Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed Ali; Forte, Antonio Jorge] Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA; [Forte, Antonio Jorge] Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA	Mayo Clinic; Mayo Clinic	Forte, AJ (corresponding author), Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA.; Forte, AJ (corresponding author), Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA.	sophiampressman1@gmail.com; saharborna2021@gmail.com; abrahamgomezcabello@gmail.com; dr.s.alihaider@gmail.com; ajvforte@yahoo.com.br	Forte, Antonio/I-2970-2019	Forte, Antonio/0000-0003-2004-7538; Pressman, Sophia/0009-0000-0398-8024; Borna, Sahar/0000-0002-7845-7356; Gomez Cabello, Cesar Abraham/0009-0008-0603-3192				Abi-Rafeh J, 2024, AESTHET SURG J, V44, P329, DOI 10.1093/asj/sjad260; Al Rawi ZM, 2024, HAND-AM ASSOC HAND S, DOI 10.1177/15589447241238372; Angly B, 2012, WORLD J SURG, V36, P826, DOI 10.1007/s00268-012-1455-x; Barash Y, 2023, J AM COLL RADIOL, V20, P998, DOI 10.1016/j.jacr.2023.06.009; Botero SS, 2016, ARCH PLAST SURG-APS, V43, P134, DOI 10.5999/aps.2016.43.2.134; Carlà MM, 2024, GRAEF ARCH CLIN EXP, DOI 10.1007/s00417-024-06470-5; Carlà MM, 2024, BRIT J OPHTHALMOL, DOI 10.1136/bjo-2023-325143; Cooney William P 3rd, 2003, Instr Course Lect, V52, P197; COONEY WP, 1980, CLIN ORTHOP RELAT R, P90; Crook BS, 2023, J HAND SURG-AM, V48, P1122, DOI 10.1016/j.jhsa.2023.08.003; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; del Piñal F, 2007, J PLAST RECONSTR AES, V60, P816, DOI 10.1016/j.bjps.2007.02.019; EATON RG, 1980, J HAND SURG-AM, V5, P260, DOI 10.1016/S0363-5023(80)80011-6; Franc JM, 2024, CAN J EMERG MED, V26, P40, DOI 10.1007/s43678-023-00616-w; Fraser H, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/49995; Funk PF, 2024, EUR J INVEST HEALTH, V14, P657, DOI 10.3390/ejihpe14030043; Gan RK, 2024, AM J EMERG MED, V75, P72, DOI 10.1016/j.ajem.2023.10.034; Geissler WB, 2013, J WRIST SURG, V2, P129, DOI 10.1055/s-0033-1343354; Ghanem Diane, 2024, Hand Surg Rehabil, V43, P101688, DOI 10.1016/j.hansur.2024.101688; google, Google Gemini; GREEN DP, 1972, SOUTHERN MED J, V65, P807, DOI 10.1097/00007611-197207000-00007; Gummesson C, 2006, BMC MUSCULOSKEL DIS, V7, DOI 10.1186/1471-2474-7-44; Günay S, 2024, AM J EMERG MED, V80, P51, DOI 10.1016/j.ajem.2024.03.017; GUSTILO RB, 1984, J TRAUMA, V24, P742, DOI 10.1097/00005373-198408000-00009; GUSTILO RB, 1976, J BONE JOINT SURG AM, V58, P453, DOI 10.2106/00004623-197658040-00004; HERBERT TJ, 1984, J BONE JOINT SURG BR, V66, P114, DOI 10.1302/0301-620X.66B1.6693468; HINTERMANN B, 1993, AM J SPORT MED, V21, P800, DOI 10.1177/036354659302100607; Jin Ziwen, 2023, 2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P1755, DOI 10.1109/ICIBA56860.2023.10165540; Keller M, 2023, INT J COMPUT ASS RAD, V18, P1393, DOI 10.1007/s11548-023-02831-3; Keskinbora KH, 2019, J CLIN NEUROSCI, V64, P277, DOI 10.1016/j.jocn.2019.03.001; KLEINERT HE, 1983, J HAND SURG-AM, V8, P794, DOI 10.1016/S0363-5023(83)80275-5; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Leddy J P, 1977, J Hand Surg Am, V2, P66; Leypold T, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005471; Li WB, 2023, ANN BIOMED ENG, V51, P1892, DOI 10.1007/s10439-023-03232-y; Lichtman DM, 2017, J WRIST SURG, V6, P2, DOI 10.1055/s-0036-1593734; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; MAYFIELD JK, 1980, J HAND SURG-AM, V5, P226, DOI 10.1016/S0363-5023(80)80007-4; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Miller R, 2023, J HAND SURG-EUR VOL, V48, P396, DOI 10.1177/17531934231152592; Oleck NC, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005290; openai, OpenAI ChatGPT; Poerbodipoero SJ, 2007, HAND THER, V12, P40; Pressman SM, 2024, HEALTHCARE-BASEL, V12, DOI 10.3390/healthcare12080825; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rizwan A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43106; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schier JS, 2007, J HAND THER, V20, P57, DOI 10.1197/j.jht.2006.10.005; Seth I, 2023, J HAND SURG-AM, V48, P1025, DOI 10.1016/j.jhsa.2023.07.003; SMITH ME, 1985, J HAND SURG-BRIT EUR, V10B, P288, DOI 10.1016/S0266-7681(85)80045-0; Sun YX, 2023, AESTHET SURG J, V43, pNP670, DOI 10.1093/asj/sjad134; ten Berg H, 2024, ANN EMERG MED, V83, P83, DOI 10.1016/j.annemergmed.2023.08.003; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Ulusoy I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46662; van Leerdam RH, 2022, EUR J TRAUMA EMERG S, V48, P4327, DOI 10.1007/s00068-021-01732-x; Wong K, 2011, J HAND SURG-AM, V36A, P1471, DOI 10.1016/j.jhsa.2011.06.016; Yoong P, 2011, EUR J EMERG MED, V18, P186, DOI 10.1097/MEJ.0b013e328342f252	60	1	1	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-0383		J CLIN MED	J. Clin. Med.	MAY	2024	13	10							2832	10.3390/jcm13102832	http://dx.doi.org/10.3390/jcm13102832			14	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	SG4F7	38792374	gold			2024-07-03	WOS:001233283700001
J	Feng, RJ; Zhang, C; Zhang, Y				Feng, Ruijun; Zhang, Chi; Zhang, Yang			Large language models for biomolecular analysis: From methods to applications	TRAC-TRENDS IN ANALYTICAL CHEMISTRY			English	Review						Large language model; Biomolecular analysis; Fine-tuning; Prompt engineering; Parameter -efficient fine-tuning; In -context learning; Protein structure analysis; Protein sequence generation; Gene sequence analysis; Molecular representation learning		Large language models (LLMs) are proving to be very useful in many fields, especially chemistry and biology, because of their amazing capabilities. Biomolecular data is often represented sequentially, much like textual data used to train LLMs. However, developing LLMs from scratch requires a substantial amount of data and computational resources, which may not be feasible for most researchers. A more workable solution to this problem is to change the inputs or parameters so that the previously trained general LLMs can pick up the specific knowledge needed for biomolecular analysis. These adaption strategies lower the amount of data and hardware needed, providing a more affordable option. This review provides the introduction of two popular LLM adaptation techniques: fine-tuning and prompt engineering, along with their uses in the analysis of molecules, proteins, and genes. A thorough overview of current common datasets and pre-trained models is also provided. This review outlines the possible advantages and difficulties of LLMs for biomolecular analysis, opening the door for chemists and biologists to effectively utilize LLMs in their future studies.	[Feng, Ruijun; Zhang, Chi; Zhang, Yang] Harbin Inst Technol Shenzhen, Coll Sci, Shenzhen 518055, Guangdong, Peoples R China; [Feng, Ruijun] Univ New South Wales, Sch Comp Sci & Engn, Sydney 1466, Australia; [Zhang, Chi] Hong Kong Polytech Univ, Dept Hlth Technol & Informat, Hong Kong, Peoples R China	Harbin Institute of Technology; University of New South Wales Sydney; Hong Kong Polytechnic University	Zhang, Y (corresponding author), Harbin Inst Technol Shenzhen, Coll Sci, Shenzhen 518055, Guangdong, Peoples R China.	zhangyang07@hit.edu.cn	Feng, Ruijun/HLP-9488-2023	Feng, Ruijun/0000-0003-2167-2968; ZHANG, Chi/0009-0002-9743-8959	National Natural Science Foundation of China [82273890]; Basic and Applied Basic Research Foundation of Guangdong Province [2021A1515220115]; Project of Educational Commission of Guangdong Province of China [2022KTSCX210]; Shenzhen Stable Support Grant [GXWD 20231130103401001]; Royal Society of Chemistry Researcher Collaborations Grant;  [C23-1700660928]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Basic and Applied Basic Research Foundation of Guangdong Province; Project of Educational Commission of Guangdong Province of China; Shenzhen Stable Support Grant; Royal Society of Chemistry Researcher Collaborations Grant(Royal Society); 	This work was supported by the National Natural Science Foundation of China (82273890); Basic and Applied Basic Research Foundation of Guangdong Province (2021A1515220115); Project of Educational Commission of Guangdong Province of China (2022KTSCX210), Shenzhen Stable Support Grant (GXWD 20231130103401001) and Royal Society of Chemistry Researcher Collaborations Grant (C23-1700660928).	Avsec Z, 2021, NAT METHODS, V18, P1196, DOI 10.1038/s41592-021-01252-x; Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Black S., 2022, PREPRINT; Bran A.M., 2023, P 37 C NEUR INF SYST; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Donahue J, 2014, PR MACH LEARN RES, V32; Du YL, 2023, Arxiv, DOI arXiv:2305.14325; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Fang TR, 2024, Arxiv, DOI arXiv:2209.15240; Fang XM, 2022, NAT MACH INTELL, V4, P127, DOI 10.1038/s42256-021-00438-4; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Hie BL, 2024, NAT BIOTECHNOL, V42, DOI 10.1038/s41587-023-01763-2; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu E. J., 2022, P 10 INT C LEARN REP, P1; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kroll A, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-38347-2; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Luo Y.Z., 2023, arXiv; Luo YZ, 2023, Arxiv, DOI arXiv:2308.09442; Lv K, 2024, Arxiv, DOI arXiv:2306.09782; Lyu XX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P2304; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Meier J, 2021, ADV NEUR IN, V34; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Mosbach M., 2023, FINDINGS ASS COMPUTA, P12284; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Peng B, 2023, Arxiv, DOI arXiv:2305.13048; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Ross J, 2022, NAT MACH INTELL, V4, DOI 10.1038/s42256-022-00580-7; Schick T., 2023, arXiv; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sriram A., 2022, P 10 INT C LEARN REP, P1; Sun K.L., 2021, P 35 C NEUR INF PROC, P8444; Sung YL, 2021, ADV NEUR IN; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Theodoris CV, 2023, NATURE, V618, DOI 10.1038/s41586-023-06139-9; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Vaswani A, 2017, ADV NEUR IN, V30; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang G, 2024, Arxiv, DOI arXiv:2309.11235; Wei JS, 2022, ADV NEUR IN; Wong F, 2022, MOL SYST BIOL, V18, DOI 10.15252/msb.202211081; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yang F, 2022, NAT MACH INTELL, V4, P852, DOI 10.1038/s42256-022-00534-z; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhang OD, 2023, NAT MACH INTELL, V5, P1020, DOI 10.1038/s42256-023-00712-7; Zhang Z.S., 2023, P 11 INT C LEARN REP, P1; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhou G., 2023, P 11 INT C LEARN REP; Zvyagin M, 2023, INT J HIGH PERFORM C, V37, P683, DOI 10.1177/10943420231201154	56	0	0	15	15	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0165-9936	1879-3142		TRAC-TREND ANAL CHEM	Trac-Trends Anal. Chem.	FEB	2024	171								117540	10.1016/j.trac.2024.117540	http://dx.doi.org/10.1016/j.trac.2024.117540		JAN 2024	9	Chemistry, Analytical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	JT0I4					2024-07-03	WOS:001175292200001
C	Pluhacek, M; Kazikova, A; Kadavy, T; Viktorin, A; Senkerik, R			ACM	Pluhacek, Michal; Kazikova, Anezka; Kadavy, Tomas; Viktorin, Adam; Senkerik, Roman			Leveraging Large Language Models for the Generation of Novel Metaheuristic Optimization Algorithms	PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION, GECCO 2023 COMPANION			English	Proceedings Paper	Genetic and Evolutionary Computation Conference (GECCO)	JUL 15-19, 2023	Lisbon, PORTUGAL	Assoc Comp Machinery, ACM, Special Interest Grp Genet & Evolutionary Computat		Large Language Models; Metaheuristic Optimization; Swarm Algorithms; Algorithm Generation; Decomposition and Construction; GPT-4		In this paper, we investigate the potential of using Large Language Models (LLMs) such as GPT-4 to generate novel hybrid swarm intelligence optimization algorithms. We use the LLM to identify and decompose six well-performing swarm algorithms for continuous optimization: Particle Swarm Optimization (PSO), Cuckoo Search (CS), Artificial Bee Colony (ABC), Grey Wolf Optimizer (GWO), Self-Organizing Migrating Algorithm (SOMA), and Whale Optimization Algorithm (WOA). We leverage GPT-4 to propose a hybrid algorithm that combines the strengths of these techniques for two distinct use-case scenarios. Our focus is on the process itself and various challenges that emerge during the use of GPT-4 to fulfill a series of set tasks. Furthermore, we discuss the potential impact of LLM-generated algorithms in the metaheuristics domain and explore future research directions.	[Pluhacek, Michal; Kazikova, Anezka; Kadavy, Tomas; Viktorin, Adam; Senkerik, Roman] Tomas Bata Univ Zlin, Zlin, Czech Republic	Tomas Bata University Zlin	Pluhacek, M (corresponding author), Tomas Bata Univ Zlin, Zlin, Czech Republic.	pluhacek@utb.cz; kazikova@utb.cz; kadavy@utb.cz; aviktorin@utb.cz; senkerik@utb.cz	; Kadavy, Tomas/A-6914-2018	Pluhacek, Michal/0000-0002-3692-2838; Kadavy, Tomas/0000-0002-3341-4336	Internal Grant Agency of the Tomas Bata University in Zlin [IGA/CebiaTech/2023/004]	Internal Grant Agency of the Tomas Bata University in Zlin	The research presented in this paper was partially supported by the Internal Grant Agency of the Tomas Bata University in Zlin, under project number IGA/CebiaTech/2023/004, and resources of A.I.Lab at the Faculty of Applied Informatics, Tomas Bata University in Zlin (ailab.fai.utb.cz).	Blum C, 2003, ACM COMPUT SURV, V35, P268, DOI 10.1145/937503.937505; Brown P. F., 1992, Computational Linguistics, V18, P467; Camacho-Villalon Christian L., 2022, InternationalTransactions in Operational Research; Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692; Davendra D., 2016, Self-Organizing Migrating Algorithm: Methodology and Implementation, Vol, V626; Ezugwu AE, 2021, ARTIF INTELL REV, V54, P4237, DOI 10.1007/s10462-020-09952-0; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Karaboga D., 2005, TR06 ERC U; Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Medsker L., 1999, Recurrent neural networks: design and applications; Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008; Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007; OpenAI, 2023, OpenAI: GPT-4; Raidl G.R., 2019, Handbook of Metaheuristics, P385, DOI 10.1007/978-3-319-91086-4_12; Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1; Vaswani A, 2017, ADV NEUR IN, V30; Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690	18	1	1	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0120-7				2023							1812	1820		10.1145/3583133.3596401	http://dx.doi.org/10.1145/3583133.3596401			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2KQ					2024-07-03	WOS:001117972600294
C	Shi, WQ; Zhuang, YC; Zhu, YD; Iwinski, HJ; Wattenbarger, JM; Wang, MD			ACM	Shi, Wenqi; Zhuang, Yuchen; Zhu, Yuanda; Iwinski, Henry J.; Wattenbarger, J. Michael; Wang, May D.			Retrieval-Augmented Large Language Models for Adolescent Idiopathic Scoliosis Patients in Shared Decision-Making	14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, BCB 2023			English	Proceedings Paper	14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB)	SEP 03-06, 2023	Houston, TX	Assoc Comp Machinery, ACM Special Interest Grp Bioinformat, Computat Biol, & Biomed Informat		large language models; information retrieval; pediatric healthcare; shared decision-making; adolescent idiopathic scoliosis	NATURAL-HISTORY; FUSION	As health-related decision-making evolves, patients increasingly seek help from additional online resources such as "Dr. Google" and ChatGPT. Despite their potential, these tools encounter limitations, including the risk of potentially inaccurate information, a lack of specialized medical knowledge, the risk of generating unrealistic outputs (hallucinations), and significant computational demands. In this study, we develop and validate an innovative shared decision-making (SDM) tool, Chat-Orthopedist, for adolescent idiopathic scoliosis (AIS) patients and families to prepare a meaningful discussion with clinicians based on retrieval-augmented large language models. Firstly, we establish an external knowledge base with information on AIS disease and treatment options. Secondly, we develop a retrieval-augmented ChatGPT to feed LLMs with AIS domain knowledge, providing accurate and comprehensible responses to patient inquiries. In addition, we perform a cyclical process of human-in-the-loop evaluations for system validation and improvement. Chat-Orthopedist may optimize SDM workflow by enabling better interactive learning experiences, more effective clinical visits, and better-informed treatment decision-making.	[Shi, Wenqi; Zhuang, Yuchen; Zhu, Yuanda; Wang, May D.] Georgia Tech, Atlanta, GA 30332 USA; [Iwinski, Henry J.] Shriners Childrens Lexington, Lexington, KY USA; [Wattenbarger, J. Michael] Shriners Childrens Greenville, Greenville, SC USA	University System of Georgia; Georgia Institute of Technology	Shi, WQ (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.	wshi83@gatech.edu; yzhuang43@gatech.edu; yzhu94@gatech.edu; hiwinski@shrinenet.org; mwattenbarger@shrinenet.org; maywang@gatech.edu	Wang, May Dongmei/AAF-2065-2021	Wang, May Dongmei/0000-0003-3961-3608; Zhu, Yuanda/0000-0001-7812-9216	Accelerate Foundation Models Academic Research Initiative from Microsoft Research; Shriners Children's Hospital; Georgia Institute of Technology in Greenville-Lexington Shriner Multi-site AI-enabled Rehabilitation Technology for Scoliosis Patients Care (GL-SMART) project; Wallace H. Coulter Distinguished Faculty Fellowship; Petit Institute Faculty Fellowship; Amazon; Microsoft Research	Accelerate Foundation Models Academic Research Initiative from Microsoft Research; Shriners Children's Hospital; Georgia Institute of Technology in Greenville-Lexington Shriner Multi-site AI-enabled Rehabilitation Technology for Scoliosis Patients Care (GL-SMART) project; Wallace H. Coulter Distinguished Faculty Fellowship; Petit Institute Faculty Fellowship; Amazon; Microsoft Research(Microsoft)	This research has been supported by Accelerate Foundation Models Academic Research Initiative from Microsoft Research. It has been also supported by Shriners Children's Hospital and Georgia Institute of Technology in Greenville-Lexington Shriner Multi-site AI-enabled Rehabilitation Technology for Scoliosis Patients Care (GL-SMART) project. In addition, this work has been supported by a Wallace H. Coulter Distinguished Faculty Fellowship, a Petit Institute Faculty Fellowship, and research funding from Amazon and Microsoft Research to Professor May D. Wang.	AARO S, 1984, SPINE, V9, P220, DOI 10.1097/00007632-198403000-00015; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bejarano C., 2015, Clinical Practice in Pediatric Psychology, V3, P25, DOI DOI 10.1037/CPP0000086; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Butler AM, 2015, MATERN CHILD HLTH J, V19, P410, DOI 10.1007/s10995-014-1523-y; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giuste F, 2023, IEEE REV BIOMED ENG, V16, P5, DOI 10.1109/RBME.2022.3185953; Golovneva O, 2023, Arxiv, DOI arXiv:2212.07919; Grier R.A., 2013, P HUM FACT ERG SOC A, V57, P187, DOI [10.1177/1541931213571042, DOI 10.1177/1541931213571042]; Han TY, 2023, Arxiv, DOI [arXiv:2304.08247, DOI 10.48550/ARXIV.2304.08247]; Ifelayo OI, 2021, J PEDIATR ORTHOPED, V41, pS70, DOI 10.1097/BPO.0000000000001800; Isgut M, 2023, IEEE REV BIOMED ENG, V16, P53, DOI 10.1109/RBME.2022.3216531; Izacard Gautier, 2022, Atlas: Few-shot learning with retrieval augmented language models; Janicki JA, 2007, PAED CHILD HEALT-CAN, V12, P771, DOI 10.1093/pch/12.9.771; Karol LA, 2019, J PEDIATR ORTHOPED, V39, pS38, DOI 10.1097/BPO.0000000000001351; Lark Robert K, 2022, Pediatrics, V149, P4; Lee CSS, 2020, PEDIATR DRUGS, V22, P575, DOI 10.1007/s40272-020-00423-1; Li GH, 2023, Arxiv, DOI arXiv:2303.17760; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Lykissas MG, 2013, SPINE, V38, pE113, DOI 10.1097/BRS.0b013e31827ae3d0; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Mallen A, 2023, Arxiv, DOI arXiv:2212.10511; Newton PO, 2003, SPINE, V28, pS217, DOI 10.1097/01.BRS.0000092461.11181.CD; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, Introducing ChatGPT; Shi WJ, 2023, Arxiv, DOI [arXiv:2301.12652, DOI 10.48550/ARXIV.2301.12652]; Shi WQ, 2021, IEEE J BIOMED HEALTH, V25, P2376, DOI 10.1109/JBHI.2021.3074893; Song K., 2020, Adv. Neural Inf. Process. Syst, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297; Sun HT, 2023, Arxiv, DOI arXiv:2305.16653; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weinstein S L, 1989, Instr Course Lect, V38, P115; Weinstein SL, 2008, LANCET, V371, P1527, DOI 10.1016/S0140-6736(08)60658-3; Weinstein SL, 2019, J PEDIATR ORTHOPED, V39, pS44, DOI 10.1097/BPO.0000000000001350; Wenqi Shi, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1524, DOI 10.1109/BIBM52615.2021.9669649; Wu PY, 2017, IEEE T BIO-MED ENG, V64, P263, DOI 10.1109/TBME.2016.2573285; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yu Y, 2023, Arxiv, DOI [arXiv:2306.15895, DOI 10.48550/ARXIV.2306.15895]; Zhou WS, 2023, Arxiv, DOI [arXiv:2305.11170, 10.48550/arXiv.2305.11170]; Zhuang Y., 2023, arXiv	42	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0126-9				2023										10.1145/3584371.3612956	http://dx.doi.org/10.1145/3584371.3612956			10	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Mathematical & Computational Biology; Medical Informatics	BW3UZ		hybrid			2024-07-03	WOS:001143941200014
J	Dunn, AG; Shih, I; Ayre, J; Spallek, H				Dunn, Adam G.; Shih, Ivy; Ayre, Julie; Spallek, Heiko			What generative AI means for trust in health communications	JOURNAL OF COMMUNICATION IN HEALTHCARE			English	Article						Natural language processing; health communication; trust; artificial intelligence; search engines; conversational agents		Large language models are fundamental technologies used in interfaces like ChatGPT and are poised to change the way people access and make sense of health information. The speed of uptake and investment suggests that these will be transformative technologies, but it is not yet clear what the implications might be for health communications. In this viewpoint, we draw on research about the adoption of new information technologies to focus on the ways that generative artificial intelligence (AI) tools like large language models might change how health information is produced, what health information people see, how marketing and misinformation might be mixed with evidence, and what people trust. We conclude that transparency and explainability in this space must be carefully considered to avoid unanticipated consequences.	[Dunn, Adam G.] Univ Sydney, Fac Med & Hlth Biomed Informat & Digital Hlth, Sch Med Sci, 128 RC Mills Bldg, Sydney, 2006, Australia; [Shih, Ivy] Univ Sydney, Media Off, Sydney, Australia; [Ayre, Julie] Univ Sydney, Fac Med & Heath, Sydney Sch Publ Hlth, Sydney Hlth Literacy Lab, Sydney, Australia; [Spallek, Heiko] Univ Sydney, Fac Med & Heath, Sydney Dent Sch, Sydney, Australia	University of Sydney; University of Sydney; University of Sydney; University of Sydney	Dunn, AG (corresponding author), Univ Sydney, Fac Med & Hlth Biomed Informat & Digital Hlth, Sch Med Sci, 128 RC Mills Bldg, Sydney, 2006, Australia.	adam.dunn@sydney.edu.au	Dunn, Adam/E-6828-2011	Dunn, Adam/0000-0002-1720-8209				Ash JS, 2004, J AM MED INFORM ASSN, V11, P104, DOI 10.1197/jamia.M1471; Ayre J., 2023, J Gen Intern Med; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Lee K, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4345; Lewandowsky S., 2020, Technology and democracy: understanding the influence of online technologies on political behaviour and decision-making, DOI [DOI 10.2760/709177, https://dx.doi.org/10.2760/709177]; Matz SC, 2017, P NATL ACAD SCI USA, V114, P12714, DOI 10.1073/pnas.1710966114; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745; Sun YL, 2019, J MED INTERNET RES, V21, DOI 10.2196/12522; Taba M, 2022, BMC PUBLIC HEALTH, V22, DOI 10.1186/s12889-022-13599-7	13	0	0	12	12	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1753-8068	1753-8076		J COMMUN HEALTHC	J. Commun. Healthc.	OCT 2	2023	16	4			SI		385	388		10.1080/17538068.2023.2277489	http://dx.doi.org/10.1080/17538068.2023.2277489			4	Communication; Health Policy & Services	Emerging Sources Citation Index (ESCI)	Communication; Health Care Sciences & Services	TV7U8	37921509				2024-07-03	WOS:001244108900006
J	Rodriguez, JA; Alsentzer, E; Bates, DW				Rodriguez, Jorge A.; Alsentzer, Emily; Bates, David W.			Leveraging large language models to foster equity in healthcare	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Editorial Material; Early Access						health equity; health disparities; digital inclusion; artificial intelligence		Objectives Large language models (LLMs) are poised to change care delivery, but their impact on health equity is unclear. While marginalized populations have been historically excluded from early technology developments, LLMs present an opportunity to change our approach to developing, evaluating, and implementing new technologies. In this perspective, we describe the role of LLMs in supporting health equity. Materials and Methods We apply the National Institute on Minority Health and Health Disparities (NIMHD) research framework to explore the use of LLMs for health equity. Results We present opportunities for how LLMs can improve health equity across individual, family and organizational, community, and population health. We describe emerging concerns including biased data, limited technology diffusion, and privacy. Finally, we highlight recommendations focused on prompt engineering, retrieval augmentation, digital inclusion, transparency, and bias mitigation. Conclusion The potential of LLMs to support health equity depends on making health equity a focus from the start.	[Rodriguez, Jorge A.; Alsentzer, Emily; Bates, David W.] Brigham & Womens Hosp, Div Gen Internal Med & Primary Care, Boston, MA 02115 USA; [Rodriguez, Jorge A.; Alsentzer, Emily; Bates, David W.] Harvard Med Sch, Boston, MA 02115 USA; [Rodriguez, Jorge A.] Harvard Med Sch, Brigham & Womens Hosp, Div Gen Internal Med, 1620 Tremont St, Boston, MA 02120 USA	Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School; Harvard University; Brigham & Women's Hospital; Harvard Medical School	Rodriguez, JA (corresponding author), Harvard Med Sch, Brigham & Womens Hosp, Div Gen Internal Med, 1620 Tremont St, Boston, MA 02120 USA.	jarodriguez1@mgb.org		Bates, David/0000-0001-6268-1540; Rodriguez, Jorge/0000-0002-1833-6819	National Institute of Minority Health and Health Disparities [K23MD016439]	National Institute of Minority Health and Health Disparities(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Minority Health & Health Disparities (NIMHD))	J.A.R. receives funding for this research from the National Institute of Minority Health and Health Disparities grant number K23MD016439. The views expressed in this article are those of the authors and do not necessarily reflect the views and policy of the National Institutes of Health	[Anonymous], 2015, Use the Teach-Back Method: Tool #5; [Anonymous], QuestionBuilder App; [Anonymous], 2017, NIMHD Research Framework; Attridge M, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006424.pub3; Benda NC, 2021, J AM MED INFORM ASSN, V29, P207, DOI 10.1093/jamia/ocab238; Centers for Medicare & Medicaid Services, Diabetes Prevention Programs: Equity Tailored Resources; Centers for Medicare & Medicaid Services, CMS Framework for Health Equity 2022-2023; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Diabetes Self-Management Education and Support (DSMES) Toolkit, 2022, Diabetes; Docs GPT, Doximity; ElSayed NA, 2023, DIABETES CARE, V46, pS68, DOI 10.2337/dc23-S005; Epic, Epic and microsoft bring GPT-4 to EHRs; Essien UR., 2021, STAT, V28; Guevara M, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-023-00970-0; Khoong EC, 2019, JAMA INTERN MED, V179, P580, DOI 10.1001/jamainternmed.2018.7653; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Mirza FN., 2024, NEJM AI, V1, pAIcs2300145, DOI [10.1056/AIcs2300145, DOI 10.1056/AICS2300145]; Navigli R, 2023, ACM J DATA INF QUAL, V15, DOI 10.1145/3597307; Office of Science and Technology Policy, 2022, Blueprint for an AI bill of rights; Omiye JA, 2024, ANN INTERN MED, V177, DOI 10.7326/M23-2772; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Park J, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.17052; Rajani N, 2023, Red-Teaming Large Language Models; Richardson S, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00663-0; Rodriguez JA, 2020, JAMA-J AM MED ASSOC, V323, P2381, DOI 10.1001/jama.2020.7858; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; University of Wisconsin Population Health Institute, 2020, Culturally Adapted Health Care. County Health Rankings & Roadmaps; Veinot TC, 2018, J AM MED INFORM ASSN, V25, P1080, DOI 10.1093/jamia/ocy052; Zack Travis, 2024, Lancet Digit Health, V6, pe12, DOI 10.1016/S2589-7500(23)00225-X	32	1	1	13	13	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 MAR 20	2024										10.1093/jamia/ocae055	http://dx.doi.org/10.1093/jamia/ocae055		MAR 2024	4	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	LQ6G9	38511501				2024-07-03	WOS:001188301700001
J	Williams, T; Matuszek, C; Mead, R; Depalma, N				Williams, Tom; Matuszek, Cynthia; Mead, Ross; Depalma, Nick			Scarecrows in Oz: The Use of Large Language Models in HRI	ACM TRANSACTIONS ON HUMAN-ROBOT INTERACTION			English	Article						Large Language Models; robot cognitive architectures; Robot Ethics	ROBOTS	The proliferation of Large Language Models (LLMs) presents both a critical design challenge and a remarkable opportunity for the field of Human-Robot Interaction (HRI). While the direct deployment of LLMs on interactive robots may be unsuitable for reasons of ethics, safety, and control, LLMs might nevertheless provide a promising baseline technique for many elements of HRI. Specifically, in this article, we argue for the use of LLMs as Scarecrows: "brainless," straw-man black-box modules integrated into robot architectures for the purpose of quickly enabling full-pipeline solutions, much like the use of "Wizard of Oz" (WoZ) and other human-in-the-loop approaches. We explicitly acknowledge that these Scarecrows, rather than providing a satisfying or scientifically complete solution, incorporate a form of the wisdom of the crowd and, in at least some cases, will ultimately need to be replaced or supplemented by a robust and theoretically motivated solution. We provide examples of how Scarecrows could be used in language-capable robot architectures as useful placeholders and suggest initial reporting guidelines for authors, mirroring existing guidelines for the use and reporting of WoZ techniques.	[Williams, Tom] Colorado Sch Mines, 1600 Illinois St, Golden, CO 80212 USA; [Matuszek, Cynthia] Univ Maryland Baltimore Cty, 1000 Hilltop Circle, Baltimore, MD 21250 USA; [Mead, Ross] Semio Inc, 123 South Figueroa St, Los Angeles, CA 90012 USA; [Depalma, Nick] Plus One Robot, 122 Meyran Ave, Pittsburgh, PA 15213 USA	Colorado School of Mines; University System of Maryland; University of Maryland Baltimore County	Williams, T (corresponding author), Colorado Sch Mines, 1600 Illinois St, Golden, CO 80212 USA.	twilliams@mines.edu; cmat@umbc.edu; ross@semio.ai; ndepalma@alum.mit.edu			US Office of Naval Research [N00014-21-1-2418]; United States Air Force Office of Scientific Research [FA9550-20-1-0089]; NSF [IIS-2024878, IIS-2145642]	US Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research); United States Air Force Office of Scientific Research(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)); NSF(National Science Foundation (NSF))	Tom Williams' work on this article was funded in part by grant N00014-21-1-2418 from the US Office of Naval Research and Young Investigator Award FA9550-20-1-0089 from the United States Air Force Office of Scientific Research. Cynthia Matuszek's work on this article was supported in part by NSF grants IIS-2024878 and IIS-2145642.	Abercrombie G, 2021, GEBNLP 2021: THE 3RD WORKSHOP ON GENDER BIAS IN NATURAL LANGUAGE PROCESSING, P24; ACL 2023 Program Chairs, 2023, ACL 2023 Policy on AI Writing Assistance; Addison A, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P493, DOI 10.1145/3306618.3314272; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Ahn M., 2022, P 6 C ROB LEARN, P287; Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7; Banks J, 2021, INT J SOC ROBOT, V13, P2021, DOI 10.1007/s12369-020-00692-3; Barfield Jessica, 2023, CHIIR '23: Proceedings of the 2023 Conference on Human Information Interaction and Retrieval, P463, DOI 10.1145/3576840.3578303; Bartneck C, 2018, ACMIEEE INT CONF HUM, P196, DOI 10.1145/3171221.3171260; Baum L.Frank., 1900, WONDERFUL WIZARD OZ; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berlin M, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P1229, DOI 10.1109/IROS.2008.4651180; Breazeal C, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P383, DOI 10.1109/IROS.2005.1545011; Brick T., 2007, 2007 2nd Annual Conference on Human-Robot Interaction (HRI), P263; Briggs G, 2022, ACMIEEE INT CONF HUM, P383, DOI 10.1109/HRI53351.2022.9889499; Cantrell R, 2012, ACMIEEE INT CONF HUM, P471; Cantrell R, 2010, ACMIEEE INT CONF HUM, P275, DOI 10.1109/HRI.2010.5453184; Cave Stephen, 2020, Philosophy & Technology, V33, P685, DOI [10.1007/s13347-020-00415-6, DOI 10.1007/S13347-020-00415-6]; Deshpande A, 2023, Arxiv, DOI arXiv:2304.05335; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Floridi L, 2004, MIND MACH, V14, P349, DOI 10.1023/B:MIND.0000035461.63578.9d; Frankfurt HG, 2005, ON BULLSHIT, P1; Gehman S., 2020, FINDINGS ASS COMPUTA, P3356; GENT EDD, 2023, The stickle-brick approach to big AI; Huang W., 2022, PROC INT C MACHINE L, P9118; ICML, 2023, Program Chairs. 2023. Clarification on Large Language Model Policy LLM; Jackson RB, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.687726; Jackson RB, 2019, ACMIEEE INT CONF HUM, P401, DOI [10.1109/hri.2019.8673123, 10.1109/HRI.2019.8673123]; Jung Malte F, 2013, Proceedings of the 2013 Conference on Computer Supported Cooperative Work, P1555, DOI DOI 10.1145/2441776.2441954; Keijsers M, 2022, INT J SOC ROBOT, V14, P499, DOI 10.1007/s12369-021-00799-1; KELLEY JF, 1984, ACM T OFF INF SYST, V2, P26, DOI 10.1145/357417.357420; Lacey C, 2019, ACMIEEE INT CONF HUM, P374, DOI 10.1109/HRI.2019.8673274; Liang Jacky, 2022, WORKSH LANG ROB CORL; Madaan Aman, 2022, P C EMPIRICAL METHOD; Malle Bertram F., 2020, Human-Robot Interaction: Control, Analysis, and Design, P1; Mead R, 2016, J HUM-ROBOT INTERACT, V5, P48, DOI 10.5898/JHRI.5.2.Mead; Mees O, 2023, IEEE INT CONF ROBOT, P11576, DOI 10.1109/ICRA48891.2023.10160396; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Mott T, 2023, COMPANION OF THE ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI 2023, P634, DOI 10.1145/3568294.3580163; Mumm J, 2011, ACMIEEE INT CONF HUM, P331, DOI 10.1145/1957656.1957786; Mutlu B., 2012, ACM T INTERACT INTEL, V1, P1, DOI DOI 10.1145/2070719.2070725; Oosterveld B, 2017, ACMIEEE INT CONF HUM, P415, DOI 10.1145/3029798.3036652; Pan Jiayi, 2023, P IEEE INT C ROB AUT; Perugia G, 2022, ACMIEEE INT CONF HUM, P110, DOI 10.1109/HRI53351.2022.9889366; Reiter Ehud, 2019, Generated Texts Must Be Accurate!; Richards Toran Bruce, 2023, Auto-GPT; Riek LD, 2012, J HUM-ROBOT INTERACT, V1, P119, DOI 10.5898/JHRI.1.1.Riek; Rogers Anna, 2023, Closed AI Models Make Bad Baselines; Schermerhorn P., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P263; Scheutz M., 2006, P 1 ACM SIGCHI SIGAR, V2, P226, DOI DOI 10.1145/1121241.1121281; Scheutz M, 2019, INTEL SYST CONTR AUT, V94, P165, DOI 10.1007/978-3-319-97550-4_11; Scheutz M, 2012, INTELL ROBOT AUTON, P205; Scheutz Matthias, 2013, P AAAI WORKSH INT RO; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Silva RS, 2023, COMPANION OF THE ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI 2023, P730, DOI 10.1145/3568294.3579967; Steedman M, 2011, NON-TRANSFORMATIONAL SYNTAX: FORMAL AND EXPLICIT MODELS OF GRAMMAR, P181; Vemprala S., 2023, CHATGPT ROBOTICS DES; Wen RC, 2022, ACMIEEE INT CONF HUM, P353, DOI 10.1109/HRI53351.2022.9889594; Williams T, 2020, ACMIEEE INT CONF HUM, P25, DOI 10.1145/3371382.3380740; Williams T, 2018, ACMIEEE INT CONF HUM, P298, DOI 10.1145/3171221.3171246; Williams T, 2016, ACMIEEE INT CONF HUM, P311, DOI 10.1109/HRI.2016.7451767; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Young J, 2021, SCI ROBOT, V6, DOI 10.1126/scirobotics.abk3479; Yu C, 2010, ACMIEEE INT CONF HUM, P309, DOI 10.1109/HRI.2010.5453181; Zhang BW, 2023, Arxiv, DOI arXiv:2303.03548	66	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2573-9522		ACM T HUM-ROBOT INTE	ACM Trans. Hum.-Robot Interact.	MAR	2024	13	1							1	10.1145/3606261	http://dx.doi.org/10.1145/3606261			11	Robotics	Emerging Sources Citation Index (ESCI)	Robotics	OP8M8		Bronze			2024-07-03	WOS:001208571200001
J	Hu, SG; Xu, JW; Li, MY; Cui, TJ; Li, LL				Hu, Shengguo; Xu, Jiawen; Li, Mingyi; Cui, Tie Jun; Li, Lianlin			Language-controllable programmable metasurface empowered by large language models	NANOPHOTONICS			English	Article						programmable metasurface; large language models; EM manipulation	SURFACE	Programmable metasurface has become a prominent tool in various areas including control, communication, computing, and so on, due to its unique capability in the electromagnetic (EM) manipulation. However, it is lack of the intelligence in the sense that it usually requires the manual intervention, and thus makes it hard to behavior as the human process. To endow the programmable metasurface with the intelligence, we here proposed the concept of the language-controllable programmable metasurface for autonomous EM manipulations by exploring the notable capability of large language models (LLMs) in attaining the human-like intelligence. We have established a proof-of-principle system of language-controllable programmable metasurface, where, for illustration, the programmable metasurface is designed to have 32 x 24 binary electronically controllable meta-atoms and work at around 5.5 GHz. In addition, we have constructed a visual-semantic map to facilitate the language-controllable EM manipulation in three-dimensional (3D) physical environments. We have experimentally demonstrated that our language-controllable programmable metasurface is capable of decomposing autonomously an ambiguous task of EM manipulation into a sequence of executable ones and implementing them individually in real-world indoor settings. We expect that the presented strategy could hold promising potential in pushing programmable metasurfaces towards human-level autonomous agents, which are capable of accomplishing the smart EM-involved multi-modality manipulations through self-directed planning and actions.	[Cui, Tie Jun] Southeast Univ, State Key Lab Millimeter Waves, Nanjing 210096, Peoples R China; [Hu, Shengguo; Xu, Jiawen; Li, Mingyi; Li, Lianlin] Peking Univ, Sch Elect, State Key Lab Adv Opt Commun Syst & Networks, Beijing 100871, Peoples R China; [Cui, Tie Jun; Li, Lianlin] Pazhou Lab Huangpu, Guangzhou 510555, Guangdong, Peoples R China	Southeast University - China; Peking University; Pazhou Lab	Li, LL (corresponding author), Peking Univ, Sch Elect, State Key Lab Adv Opt Commun Syst & Networks, Beijing 100871, Peoples R China.; Li, LL (corresponding author), Pazhou Lab Huangpu, Guangzhou 510555, Guangdong, Peoples R China.	lianlin.li@pku.edu.cn	xu, jiawen/KGK-4238-2024; li, lian/HSG-2194-2023; Cui, Tiejun/AGI-4109-2022	li, lianlin/0000-0002-2295-4425	Development Program of China	Development Program of China	No Statement Available	Arbabi E, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03155-6; Basar E, 2020, IEEE T COMMUN, V68, P3187, DOI 10.1109/TCOMM.2020.2971486; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang Y., 2023, arXiv; Colas C., 2023, ARXIV; Cui TJ, 2019, RESEARCH-CHINA, V2019, DOI 10.34133/2019/2584509; Cui TJ, 2014, LIGHT-SCI APPL, V3, DOI 10.1038/lsa.2014.99; Devlin J., 2018, BERT PRE TRAINING DE; Elzanaty A, 2021, IEEE T SIGNAL PROCES, V69, P5386, DOI 10.1109/TSP.2021.3101644; Garcia N, 2002, APPL PHYS LETT, V80, P1120, DOI 10.1063/1.1449529; Huang C, 2017, ADV OPT MATER, V5, DOI 10.1002/adom.201700485; Li LL, 2022, ELIGHT, V2, DOI 10.1186/s43593-022-00013-3; Li LL, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0209-z; Liu R., 2022, arXiv; Ma Q, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0205-3; Michael A., 2022, ARXIV; Penedo G., 2023, arXiv; Radford A., 2018, IMPROVING LANGUAGE U; Schurig D, 2006, SCIENCE, V314, P977, DOI 10.1126/science.1133628; Shen Y, 2023, arXiv; Touvron H., 2023, arXiv; Wang XY, 2021, IEEE T VEH TECHNOL, V70, P5131, DOI 10.1109/TVT.2021.3075497; Wang Z, 2022, NANOPHOTONICS-BERLIN, V11, P2011, DOI 10.1515/nanoph-2021-0665; Wei ML, 2023, NAT ELECTRON, V6, P610, DOI 10.1038/s41928-023-01011-0; Wong L., 2023, ARXIV; Wu RY, 2019, ADV OPT MATER, V7, DOI 10.1002/adom.201801429; Xi Z., 2023, ARXIV; Xu J., 2023, JIIS, V1, P217; Zangeneh-Nejad F, 2021, NAT REV MATER, V6, P207, DOI 10.1038/s41578-020-00243-2; Zhang N, 2020, IEEE J EM SEL TOP C, V10, P20, DOI 10.1109/JETCAS.2020.2973310; Zhang YW, 2022, IEEE J-STSP, V16, P967, DOI 10.1109/JSTSP.2022.3176479; Zhao HT, 2023, NATL SCI REV, V10, DOI 10.1093/nsr/nwac266; Zhao HT, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17808-y	33	1	1	41	41	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2192-8606	2192-8614		NANOPHOTONICS-BERLIN	Nanophotonics	MAY 20	2024	13	12					2213	2222		10.1515/nanoph-2023-0646	http://dx.doi.org/10.1515/nanoph-2023-0646		JAN 2024	10	Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Optics; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics; Materials Science; Optics; Physics	RK7A6		gold			2024-07-03	WOS:001136593400001
J	Zhu, J; Dang, P; Cao, YG; Lai, JB; Guo, YK; Wang, P; Li, WL				Zhu, Jun; Dang, Pei; Cao, Yungang; Lai, Jianbo; Guo, Yukun; Wang, Ping; Li, Weilian			A flood knowledge-constrained large language model interactable with GIS: enhancing public risk perception of floods	INTERNATIONAL JOURNAL OF GEOGRAPHICAL INFORMATION SCIENCE			English	Article						Large language models; flood risk perception; knowledge graph; disaster visualization	MANAGEMENT; AWARENESS; ISSUES; RIVER	Public's rational flood mitigation behaviors depend on accurate perception of flood risks. The use of natural language for flood risk perception is an effective approach, and it is critical to ensure the accuracy and comprehensibility of the flood information provided by the system in natural language dialogues. This study presents a framework for large language model (LLM) that is constrained by flood knowledge and can interact with geographic information system (GIS), aimed at enhancing the public's perception of flood risks. We tested the performance of LLM within this framework and the results demonstrate that LLM can generate accurate information about floods under the constraints of entities and relationships in the knowledge graph, and interact with GIS to produce personalized knowledge through real-time coding. Furthermore, we conducted flood risk perception experiments on users with different cognitive levels. The results indicate that using natural language dialogue can narrow the differences brought about by cognitive levels, allowing the public to equally access knowledge related to flood events.	[Zhu, Jun; Dang, Pei; Cao, Yungang; Lai, Jianbo; Guo, Yukun; Wang, Ping; Li, Weilian] Southwest Jiaotong Univ, Fac Geosci & Environm Engn, Chengdu, Peoples R China	Southwest Jiaotong University	Dang, P (corresponding author), Southwest Jiaotong Univ, Fac Geosci & Environm Engn, Chengdu, Peoples R China.	dangpei@my.swjtu.edu.cn			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Ambridge B, 2008, COGNITION, V106, P87, DOI 10.1016/j.cognition.2006.12.015; Armas I, 2015, NAT HAZARDS, V79, P1913, DOI 10.1007/s11069-015-1939-8; Bawden D, 2009, J INF SCI, V35, P180, DOI 10.1177/0165551508095781; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Botzen WJW, 2009, WATER RESOUR RES, V45, DOI 10.1029/2009WR007743; Bradford RA, 2012, NAT HAZARD EARTH SYS, V12, P2299, DOI 10.5194/nhess-12-2299-2012; Brown G, 2014, APPL GEOGR, V46, P122, DOI 10.1016/j.apgeog.2013.11.004; Bubeck P, 2012, RISK ANAL, V32, P1481, DOI 10.1111/j.1539-6924.2011.01783.x; Burningham K, 2008, DISASTERS, V32, P216, DOI 10.1111/j.1467-7717.2007.01036.x; Cali D., 2011, PROCEDIA COMPUTER SC, V5, P920, DOI DOI 10.1016/J.PROCS.2011.07.128; Chen J, 2009, J HYDROL, V373, P184, DOI 10.1016/j.jhydrol.2009.04.021; CLEVELAND WS, 1984, J AM STAT ASSOC, V79, P531, DOI 10.2307/2288400; Dang P, 2023, CARTOGR GEOGR INF SC, V50, P272, DOI 10.1080/15230406.2023.2176928; de Jager S, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01643-9; Dottori F, 2018, NAT CLIM CHANGE, V8, P781, DOI 10.1038/s41558-018-0257-z; Duzí B, 2017, J FLOOD RISK MANAG, V10, P253, DOI 10.1111/jfr3.12132; Fakhruddin SHM, 2015, INT J DISAST RISK RE, V14, P323, DOI 10.1016/j.ijdrr.2015.08.004; Grothmann T, 2006, NAT HAZARDS, V38, P101, DOI 10.1007/s11069-005-8604-6; He K, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118927; Iadanza C, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10020089; Kellens W, 2012, RISK ANAL, V32, P1369, DOI 10.1111/j.1539-6924.2011.01743.x; Kellens W, 2011, RISK ANAL, V31, P1055, DOI 10.1111/j.1539-6924.2010.01571.x; Kourgialas NN, 2011, HYDROLOG SCI J, V56, P212, DOI 10.1080/02626667.2011.555836; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li WL, 2021, INT J GEOGR INF SCI, V35, P1521, DOI 10.1080/13658816.2020.1833016; Lo AY, 2017, NAT HAZARDS, V88, P367, DOI 10.1007/s11069-017-2870-y; MacEachren A. M., 2004, How maps work: Representation, visualization, and design; Morss RE, 2008, WEATHER FORECAST, V23, P974, DOI 10.1175/2008WAF2007088.1; Pappenberger F, 2015, ENVIRON SCI POLICY, V51, P278, DOI 10.1016/j.envsci.2015.04.016; Phelps EA, 2006, ANNU REV PSYCHOL, V57, P27, DOI 10.1146/annurev.psych.56.091103.070234; Sel B., 2023, ARXIV; Sieber R, 2006, ANN ASSOC AM GEOGR, V96, P491, DOI 10.1111/j.1467-8306.2006.00702.x; Son J, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13050124; Terpstra T, 2009, RISK ANAL, V29, P1141, DOI 10.1111/j.1539-6924.2009.01252.x; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Towe R, 2020, J FLOOD RISK MANAG, V13, DOI 10.1111/jfr3.12652; Van Kerkvoorde Maaike, 2018, International Journal of Cartography, V4, P49, DOI 10.1080/23729333.2017.1371411; Vaswani A, 2017, ADV NEUR IN, V30; Xing Y, 2022, NAT HAZARDS, V112, P2313, DOI 10.1007/s11069-022-05267-1; Yang BY, 2016, APPL GEOGR, V76, P85, DOI 10.1016/j.apgeog.2016.09.006; Ye XY, 2021, COMPUT URBAN SCI, V1, DOI 10.1007/s43762-021-00011-0; Zerger A, 2004, NAT HAZARDS, V33, P191, DOI 10.1023/B:NHAZ.0000037040.72866.92	42	5	5	66	66	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1365-8816	1362-3087		INT J GEOGR INF SCI	Int. J. Geogr. Inf. Sci.	APR 2	2024	38	4					603	625		10.1080/13658816.2024.2306167	http://dx.doi.org/10.1080/13658816.2024.2306167		FEB 2024	23	Computer Science, Information Systems; Geography; Geography, Physical; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Geography; Physical Geography; Information Science & Library Science	MA3S2		hybrid, Green Submitted			2024-07-03	WOS:001157160800001
C	Liu, MJ; Pinckney, N; Khailany, B; Ren, HX			IEEE	Liu, Mingjie; Pinckney, Nathaniel; Khailany, Brucek; Ren, Haoxing			Invited Paper: VerilogEval: Evaluating Large Language Models for Verilog Code Generation	2023 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD	ICCAD-IEEE ACM International Conference on Computer-Aided Design		English	Proceedings Paper	42nd IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	OCT 28-NOV 02, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, Cadence, Synopsys, Futurewei Technologies, AMD, EMPYREAN, DoraHacks, Singular Med, JP Morgan Chase & Co				The increasing popularity of large language models (LLMs) has paved the way for their application in diverse domains. This paper proposes a benchmarking framework tailored specifically for evaluating LLM performance in the context of Verilog code generation for hardware design and verification. We present a comprehensive evaluation dataset consisting of 156 problems from the Verilog instructional website HDLBits. The evaluation set consists of a diverse set of Verilog code generation tasks, ranging from simple combinational circuits to complex finite state machines. The Verilog code completions can be automatically tested for functional correctness by comparing the transient simulation outputs of the generated design with a golden solution. We also demonstrate that the Verilog code generation capability of pretrained language models could be improved with supervised fine-tuning by bootstrapping with LLM generated synthetic problem-code pairs.	[Liu, Mingjie; Pinckney, Nathaniel; Khailany, Brucek; Ren, Haoxing] NVIDIA Corp, Santa Clara, CA 95051 USA	Nvidia Corporation	Liu, MJ (corresponding author), NVIDIA Corp, Santa Clara, CA 95051 USA.	mingjiel@nvidia.com; npinckney@nvidia.com; bkhailany@nvidia.com; haoxingr@nvidia.com						Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Blocklove J, 2023, Arxiv, DOI [arXiv:2305.13243, 10.48550/arXiv.2305.13243, DOI 10.48550/ARXIV.2305.13243]; Bolton E., BioMedLM; Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chang KY, 2023, Arxiv, DOI arXiv:2305.14019; Chen M., 2021, arXiv; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gunasekar S, 2023, Arxiv, DOI arXiv:2306.11644; Hendrycks D, 2021, Arxiv, DOI arXiv:2105.09938; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Kulal S, 2019, ADV NEUR IN, V32; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Lu Y, 2023, Arxiv, DOI arXiv:2308.05345; Luo ZY, 2023, Arxiv, DOI [arXiv:2306.08568, 10.48550/arXiv.2306.08568, DOI 10.48550/ARXIV.2306.08568]; Mastropaolo A, 2023, Arxiv, DOI [arXiv:2302.00438, DOI 10.48550/ARXIV.2302.00438]; Nijkamp Erik, 2023, ICLR; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, OpenAI models api; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Shin HC, 2020, Arxiv, DOI arXiv:2010.06060; Takamaeda-Yamazaki S., 2015, P APPL REC COMP 11 I, P451; Taylor R, 2022, arXiv; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Williams Stephen, 2023, The ICARUS Verilog Compilation System; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xu C, 2023, Arxiv, DOI arXiv:2304.12244; Yu H., 2023, Codereval: A benchmark of pragmatic code generation with generative pre trained models	34	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1933-7760		979-8-3503-2225-5	ICCAD-IEEE ACM INT			2023										10.1109/ICCAD57390.2023.10323812	http://dx.doi.org/10.1109/ICCAD57390.2023.10323812			8	Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2HI					2024-07-03	WOS:001116715100118
C	Liu, QJ; Chen, N; Sakai, T; Wu, XM			Assoc computing machinery	Liu, Qijiong; Chen, Nuo; Sakai, Tetsuya; Wu, Xiao-Ming			ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		large language model; content-based recommendation		Personalized content-based recommender systems have become indispensable tools for users to navigate through the vast amount of content available on platforms like daily news websites and book recommendation services. However, existing recommenders face significant challenges in understanding the content of items. Large language models (LLMs), which possess deep semantic comprehension and extensive knowledge from pretraining, have proven to be effective in various natural language processing tasks. In this study, we explore the potential of leveraging both open- and closed-source LLMs to enhance content-based recommendation. With open-source LLMs, we utilize their deep layers as content encoders, enriching the representation of content at the embedding level. For closed-source LLMs, we employ prompting techniques to enrich the training data at the token level. Through comprehensive experiments, we demonstrate the high effectiveness of both types of LLMs and show the synergistic relationship between them. Notably, we observed a significant relative improvement of up to 19.32% compared to existing state-of-the-art recommendation models. These findings highlight the immense potential of both openand closed-source of LLMs in enhancing content-based recommendation systems. We have made our code and LLM-generated data available1 for other researchers to reproduce our results.	[Liu, Qijiong; Wu, Xiao-Ming] Hong Kong Polytech Univ, Hong Kong, Peoples R China; [Chen, Nuo; Sakai, Tetsuya] Waseda Univ, Tokyo, Japan	Hong Kong Polytechnic University; Waseda University	Wu, XM (corresponding author), Hong Kong Polytech Univ, Hong Kong, Peoples R China.	liu@qijiong.work; pleviumtan@toki.waseda.jp; tetsuyasakai@acm.org; xiao-ming.wu@polyu.edu.hk		Liu, Qijiong/0000-0001-6087-383X; Sakai, Tetsuya/0000-0002-6720-963X				An MX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P336; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Borisov Vadim, 2022, 11 INT C LEARN REPR; Bu Jiajun, 2010, Proceedings of the 18th International Conference on Multimedia 2010, Firenze, Italy, October 25-29, 2010, P391, DOI [10.1145/ 1873951.1874005, DOI 10.1145/1873951.1874005, 10.1145/1873951.1874005]; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Dai SH, 2023, Arxiv, DOI arXiv:2305.02182; Davidson J., 2010, P 4 ACM C RECOMMENDE, P293, DOI DOI 10.1145/1864708.1864770; Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9; Devlin J., 2018, BERT PRE TRAINING DE; Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010; Garcin Florent, 2013, RECSYS 2013 P 7 ACM, P105; He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Kingma D. P., 2017, ARXIV; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Lee J, 2017, IEEE INT CONF COMP V, P987, DOI 10.1109/ICCVW.2017.121; Li J, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P343; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Lin JH, 2024, Arxiv, DOI arXiv:2306.05817; Liu G, 2022, Arxiv, DOI arXiv:2209.08060; Liu J, 2010, IUI 2010, P31; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Liu Q., 2022, COLING, P2823; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Qureshi B, 2023, Arxiv, DOI arXiv:2304.11214; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Salemi A, 2024, Arxiv, DOI arXiv:2304.11406; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Ubani S, 2023, Arxiv, DOI [arXiv:2304.14334, 10.48550/arXiv.2304.14334]; Van Den Oord A., 2013, Advances in neural information processing systems, V26, P1, DOI DOI 10.1109/MMUL.2011.34.VAN; Vaswani A, 2017, ADV NEUR IN, V30; Voorhees E.M., 1999, Proceedings of TREC; Wan MT, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P86, DOI 10.1145/3240323.3240369; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang XX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P627, DOI 10.1145/2647868.2654940; Wei J, 2022, Trans. Mach. Learn. Res.; Wu CH, 2021, Arxiv, DOI [arXiv:2108.09084, DOI 10.48550/ARXIV.2108.09084]; Wu CH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6389; Wu CH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1652, DOI 10.1145/3404835.3463069; Wu CH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3863; Wu CH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2576, DOI 10.1145/3292500.3330665; Wu FZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3597; Wu JH, 2024, Arxiv, DOI arXiv:2310.09874; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yuan Z, 2023, Arxiv, DOI arXiv:2303.13835; Zhang Q., 2021, P 30 INT JOINT C ART, P3356; Zhang Qi, 2021, INT JOINT C ART INT	49	1	1	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							452	461		10.1145/3616855.3635845	http://dx.doi.org/10.1145/3616855.3635845			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN		Green Submitted			2024-07-03	WOS:001182230100053
J	Trott, S				Trott, Sean			Can large language models help augment English psycholinguistic datasets?	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						Dataset; Psycholinguistic resource; Large language models; ChatGPT	NORMS; RATINGS; ACQUISITION; AGE; CONCRETENESS; ICONICITY	Research on language and cognition relies extensively on psycholinguistic datasets or "norms". These datasets contain judgments of lexical properties like concreteness and age of acquisition, and can be used to norm experimental stimuli, discover empirical relationships in the lexicon, and stress-test computational models. However, collecting human judgments at scale is both time-consuming and expensive. This issue of scale is compounded for multi-dimensional norms and those incorporating context. The current work asks whether large language models (LLMs) can be leveraged to augment the creation of large, psycholinguistic datasets in English. I use GPT-4 to collect multiple kinds of semantic judgments (e.g., word similarity, contextualized sensorimotor associations, iconicity) for English words and compare these judgments against the human "gold standard". For each dataset, I find that GPT-4's judgments are positively correlated with human judgments, in some cases rivaling or even exceeding the average inter-annotator agreement displayed by humans. I then identify several ways in which LLM-generated norms differ from human-generated norms systematically. I also perform several "substitution analyses", which demonstrate that replacing human-generated norms with LLM-generated norms in a statistical model does not change the sign of parameter estimates (though in select cases, there are significant changes to their magnitude). I conclude by discussing the considerations and limitations associated with LLM-generated norms in general, including concerns of data contamination, the choice of LLM, external validity, construct validity, and data quality. Additionally, all of GPT-4's judgments (over 30,000 in total) are made available online for further analysis.	[Trott, Sean] Univ Calif San Diego, Dept Cognit Sci, 9500 Gilman Dr, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Trott, S (corresponding author), Univ Calif San Diego, Dept Cognit Sci, 9500 Gilman Dr, La Jolla, CA 92093 USA.	sttrott@ucsd.edu		Trott, Sean/0000-0002-6003-3731				Aher G, 2022, Arxiv, DOI arXiv:2208.10264; Anand P., 2020, Response to NSF SBE; Awad E, 2020, P NATL ACAD SCI USA, V117, P2332, DOI 10.1073/pnas.1911517117; Bender E. M., 2009, P EACL 2009 WORKSHOP, P26; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bestgen Y, 2012, BEHAV RES METHODS, V44, P998, DOI 10.3758/s13428-012-0195-z; Binder JR, 2016, COGN NEUROPSYCHOL, V33, P130, DOI 10.1080/02643294.2016.1147426; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Blasi DE, 2022, TRENDS COGN SCI, V26, P1153, DOI 10.1016/j.tics.2022.09.015; Bradley Margaret M., 1999, Technical report C-1, DOI DOI 10.1109/MIC.2008.114; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Brysbaert M, 2014, ACTA PSYCHOL, V150, P80, DOI 10.1016/j.actpsy.2014.04.010; Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Chang TA, 2023, Arxiv, DOI arXiv:2303.11504; CLOGG CC, 1995, AM J SOCIOL, V100, P1261, DOI 10.1086/230638; Coda-Forno J, 2023, Arxiv, DOI [arXiv:2304.11111, 10.48550/arXiv.2304.11111, DOI 10.48550/ARXIV.2304.11111]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Dingemanse M, 2020, LANG COGN, V12, P203, DOI 10.1017/langcog.2019.49; Dingemanse M, 2015, TRENDS COGN SCI, V19, P603, DOI 10.1016/j.tics.2015.07.013; Doerig A, 2023, NAT REV NEUROSCI, V24, P431, DOI 10.1038/s41583-023-00705-w; Dou ZH, 2018, LECT NOTES ARTIF INT, V11109, P67, DOI 10.1007/978-3-319-99501-4_6; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Engelthaler T, 2018, BEHAV RES METHODS, V50, P1116, DOI 10.3758/s13428-017-0930-6; Firth J.R., 1968, Selected Papers of J. R. Firth 1952-1959. Ed. by, P1; Forbes M, 2019, Arxiv, DOI arXiv:1908.02899; Gerz D, 2016, Arxiv, DOI arXiv:1608.00869; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Golchin S, 2024, Arxiv, DOI arXiv:2308.08493; Groenwold S, 2020, Arxiv, DOI arXiv:2010.02510; Haber J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2663; Hagendorff T, 2023, Arxiv, DOI [arXiv:2303.13988, 10.48550/arXiv.2303.13988, DOI 10.48550/ARXIV.2303.13988]; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hatzivassiloglou V, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P174, DOI 10.3115/976909.979640; Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X; Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237; Hoes E., 2023, Leveraging ChatGPT for efficient fact-checking; Hu J, 2023, Arxiv, DOI [arXiv:2305.13264, 10.48550/arXiv.2305.13264]; Hu J, 2023, Arxiv, DOI [arXiv:2212.06801, DOI 10.48550/ARXIV.2212.06801]; Imai M, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0298; Jain S., 2023, Neurobiology of Language, P1; Jones C.R., 2022, P ANN M COGN SCI SOC, V44; Juhasz BJ, 2013, BEHAV RES METHODS, V45, P160, DOI 10.3758/s13428-012-0242-9; Katz D. M., 2023, GPT-4 Passes the Bar Exam; Kaushal A., 2022, arXiv, DOI [10.48550/arXiv.2206.02608, DOI 10.48550/ARXIV.2206.02608]; Kiros JR, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P922; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008; Kuperman V, 2012, BEHAV RES METHODS, V44, P978, DOI 10.3758/s13428-012-0210-4; Lewis M, 2019, P NATL ACAD SCI USA, V116, P19237, DOI 10.1073/pnas.1910148116; Li JT, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12955; Lynott D, 2020, BEHAV RES METHODS, V52, P1271, DOI 10.3758/s13428-019-01316-z; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; MARR DC, 1977, NEUROSCI RES PROG B, V15, P470; McDonald Scott., 2001, P 23 ANN C COGNITIVE, P611; Michaelov J. A., 2022, IEEE Transactions on Cognitive and Developmental Systems; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Mollo DC, 2023, Arxiv, DOI arXiv:2304.01481; Ollion E., 2023, ChatGPT for Text Annotation? Mind the Hype!; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Argyle LP, 2022, Arxiv, DOI [arXiv:2209.06899, DOI 10.48550/ARXIV.2209.06899]; Paternoster R, 1998, CRIMINOLOGY, V36, P859, DOI 10.1111/j.1745-9125.1998.tb01268.x; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Perlman M, 2015, ROY SOC OPEN SCI, V2, DOI 10.1098/rsos.150152; Piantadosi S. T., 2022, NEURIPS 2022 WORKSH; Ramezani A, 2023, Arxiv, DOI arXiv:2306.01857; Rathje S., 2023, Gpt is an effective tool for multilingual psychological text analysis; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Scott GG, 2019, BEHAV RES METHODS, V51, P1258, DOI 10.3758/s13428-018-1099-3; Shain C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4086; Shaoul C, 2010, BEHAV RES METHODS, V42, P393, DOI 10.3758/BRM.42.2.393; Stroop JR, 1932, J EXP PSYCHOL, V15, P550, DOI 10.1037/h0070482; Tenney I., 2019, arXiv, DOI DOI 10.48550/ARXIV.1905.05950; Thompson B., 2018, 40 ANN C COGN SCI SO, P1122; Thompson RL, 2012, PSYCHOL SCI, V23, P1443, DOI 10.1177/0956797612459763; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Trott S., 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, P7077; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Trott S, 2023, PSYCHOL REV, V130, P1239, DOI 10.1037/rev0000420; Trott Sean, 2022, arXiv; Utsumi A, 2020, COGNITIVE SCI, V44, DOI 10.1111/cogs.12844; Veselovsky V, 2023, Arxiv, DOI [arXiv:2306.07899, 10.48550/arXiv.2306.07899, DOI 10.48550/ARXIV.2306.07899]; Vinson DP, 2008, BEHAV RES METHODS, V40, P1079, DOI 10.3758/BRM.40.4.1079; Webb MA, 2022, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916221120027; Wingfield C, 2023, BEHAV RES METHODS, V55, P3416, DOI 10.3758/s13428-022-01965-7; Winter B, 2024, BEHAV RES METHODS, V56, P1640, DOI 10.3758/s13428-023-02112-6; Xu Y, 2020, COGNITION, V201, DOI 10.1016/j.cognition.2020.104280; Yee E, 2016, PSYCHON B REV, V23, P1015, DOI 10.3758/s13423-015-0948-7; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	94	0	0	17	17	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 JAN 23	2024										10.3758/s13428-024-02337-z	http://dx.doi.org/10.3758/s13428-024-02337-z		JAN 2024	19	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	FP1A2	38261264	Green Submitted, hybrid			2024-07-03	WOS:001146940900001
C	Bengtsson, M; D'Cruze, RS; Ahmed, MU; Sakao, T; Funk, P; Sohlberg, R		Andersson, J; Joshi, S; Malmskold, L; Hanning, F		Bengtsson, Marcus; D'Cruze, Ricky Stanley; Ahmed, Mobyen Uddin; Sakao, Tomohiko; Funk, Peter; Sohlberg, Rickard			Combining Ontology and Large Language Models to Identify Recurring Machine Failures in Free-Text Fields	SUSTAINABLE PRODUCTION THROUGH ADVANCED MANUFACTURING, INTELLIGENT AUTOMATION AND WORK INTEGRATED LEARNING, SPS 2024	Advances in Transdisciplinary Engineering		English	Proceedings Paper	11th Swedish Production Symposium (SPS)	APR 23-26, 2024	Univ West, Trollhattan, SWEDEN		Univ West	Industrial Maintenance; Artificial Intelligence; Natural Language; Processing; Large Language Models; Experience Reuse	CIRCULAR ECONOMY	Companies must enhance total maintenance effectiveness to stay competitive, focusing on both digitalization and basic maintenance procedures. Digitalization offers technologies for data-driven decision-making, but many maintenance decisions still lack a factual basis. Prioritizing efficiency and effectiveness require analyzing equipment history, facilitated by using Computerized Maintenance Management Systems (CMMS). However, CMMS data often contains unstructured free-text, leading to manual analysis, which is resourceintensive and reactive, focusing on short time periods and specific equipment. Two approaches are available to solve the issue: minimizing free-text entries or using advanced methods for processing them. Free-text allows detailed descriptions but may lack completeness, while structured reporting aids automated analysis but may limit fault description richness. As knowledge and experience are vital assets for companies this research uses a hybrid approach by combining Natural Language Processing with domain specific ontology and Large Language Models to extract information from free-text entries, enabling the possibility of real-time analysis e.g., identifying recurring failure and knowledge sharing across global sites.	[Bengtsson, Marcus] Volvo Construct Equipment Operat, Eskilstuna, Sweden; [Bengtsson, Marcus; D'Cruze, Ricky Stanley; Ahmed, Mobyen Uddin; Funk, Peter; Sohlberg, Rickard] Malardalen Univ, Sch Innovat Design & Engn, Vasteras, Sweden; [Sakao, Tomohiko] Linkoping Univ, Dept Management & Engn, Linkoping, Sweden	Volvo; Malardalen University; Linkoping University	Bengtsson, M (corresponding author), Volvo Construct Equipment Operat, Eskilstuna, Sweden.; Bengtsson, M (corresponding author), Malardalen Univ, Sch Innovat Design & Engn, Vasteras, Sweden.	marcus.bengtsson@mdu.se			Adapt 2030 project (Adaptive lifecycle design by applying digitalization and AI techniques to production) under Vinnova (Sweden's innovation agency) [2019-05589]; XPRES	Adapt 2030 project (Adaptive lifecycle design by applying digitalization and AI techniques to production) under Vinnova (Sweden's innovation agency); XPRES	This work was supported by the Adapt 2030 project (Adaptive lifecycle design by applying digitalization and AI techniques to production) under Vinnova (Sweden's innovation agency) project grant 2019-05589 within the strategic innovation programme for Production2030 as well as part of the XPRES framework at Malardalen University.	Ahmed MU, 2022, LECT N MECH ENG, P40, DOI 10.1007/978-3-030-93639-6_4; [Anonymous], 2023, SBERT GitHub page Internet; [Anonymous], 2023, Sentence Transformers Documentation Internet; Bengtsson M, 2018, PROCEDIA MANUF, V25, P118, DOI 10.1016/j.promfg.2018.06.065; Chirumalla K, 2015, P 22 EUR OP MAN ASS, DOI [10.13140/RG.2.1.4939.7924, DOI 10.13140/RG.2.1.4939.7924]; DCruze RS, Lecture Notes in Mechanical Engineering, DOI [10.1007/978-3-031-39619-951, DOI 10.1007/978-3-031-39619-951]; Duffuaa S., 2015, Planning and control of maintenance systems, P1, DOI DOI 10.1007/978-3-319-19803-3; Edvinsson L., 1996, European Management Journal, V14, P356, DOI [10.1016/0263-2373(96)00022-9, DOI 10.1016/0263-2373(96)00022-9]; Franciosi C, 2020, J CLEAN PROD, V260, DOI 10.1016/j.jclepro.2020.121065; Geng Y, 2023, NATURE, V619, P248, DOI 10.1038/d41586-023-02153-z; Gopalakrishnan M., 2018, PhD diss; Kans M, 2017, Journal of Maintenance Engineering, V2, P147; Labib A. W., 2004, Journal of Quality in Maintenance Engineering, V10, P191, DOI 10.1108/13552510410553244; Pires A, 2019, WASTE MANAGE, V95, P298, DOI 10.1016/j.wasman.2019.06.014; Rahman H, 2022, IEEE ACCESS, V10, P133001, DOI 10.1109/ACCESS.2022.3230637; Rausand M, 1996, RELIAB ENG SYST SAFE, V53, P73, DOI 10.1016/0951-8320(96)00010-5; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Salonen A, 2020, ADV TRANSDISCIPL ENG, V13, P249, DOI 10.3233/ATDE200163; Stenstrom C., 2015, International Journal of COMADEM, V18, P33	19	0	0	0	0	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	2352-7528		978-1-64368-511-3; 978-1-64368-510-6	ADV TRANSDISCIPL ENG			2024	52						27	38		10.3233/ATDE240151	http://dx.doi.org/10.3233/ATDE240151			12	Automation & Control Systems; Computer Science, Interdisciplinary Applications; Engineering, Manufacturing	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BX0FI		gold			2024-07-03	WOS:001229990300003
J	Tripathi, S; Sukumaran, R; Cook, TS				Tripathi, Satvik; Sukumaran, Rithvik; Cook, Tessa S.			Efficient healthcare with large language models: optimizing clinical workflow and enhancing patient care	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Editorial Material						large language models; clinical workflow; patient care; automation; electronic medical records; privacy and security	READABILITY	Purpose: This article explores the potential of large language models (LLMs) to automate administrative tasks in healthcare, alleviating the burden on clinicians caused by electronic medical records. Potential: LLMs offer opportunities in clinical documentation, prior authorization, patient education, and access to care. They can personalize patient scheduling, improve documentation accuracy, streamline insurance prior authorization, increase patient engagement, and address barriers to healthcare access. Caution: However, integrating LLMs requires careful attention to security and privacy concerns, protecting patient data, and complying with regulations like the Health Insurance Portability and Accountability Act (HIPAA). It is crucial to acknowledge that LLMs should supplement, not replace, the human connection and care provided by healthcare professionals. Conclusion: By prudently utilizing LLMs alongside human expertise, healthcare organizations can improve patient care and outcomes. Implementation should be approached with caution and consideration to ensure the safe and effective use of LLMs in the clinical setting.	[Tripathi, Satvik; Sukumaran, Rithvik; Cook, Tessa S.] Univ Penn, Perelman Sch Med, Dept Radiol, Philadelphia, PA 19104 USA	University of Pennsylvania	Cook, TS (corresponding author), Univ Penn, Perelman Sch Med, Dept Radiol, Philadelphia, PA 19104 USA.	tessa.cook@pennmedicine.upenn.edu						Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Barash Y, 2023, J AM COLL RADIOL, V20, P998, DOI 10.1016/j.jacr.2023.06.009; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Castaldi M, 2019, J HEALTHC QUAL, V41, pE21, DOI 10.1097/JHQ.0000000000000146; Cohen KB, 2014, Biomedical Natural Language Processing; Dutruel SP, 2024, J AM COLL RADIOL, V21, P7, DOI 10.1016/j.jacr.2023.10.009; Fossa AJ, 2018, J AM MED INFORM ASSN, V25, P1153, DOI 10.1093/jamia/ocy083; Hansberry DR, 2014, AM J ROENTGENOL, V202, P566, DOI 10.2214/AJR.13.11223; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Heuer AJ, 2022, INT J HEALTH POLICY, V11, P536, DOI 10.34172/ijhpm.2021.129; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Horwitz LI, 2013, JAMA-J AM MED ASSOC, V310, P2255, DOI 10.1001/jama.2013.281827; Jha S, 2023, JAMA-J AM MED ASSOC, V330, P1615, DOI 10.1001/jama.2023.16049; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Martin-Carreras T, 2019, CLIN IMAG, V54, P116, DOI 10.1016/j.clinimag.2018.12.006; Microsoft News Center, 2023, STORIES; Moy AJ, 2021, J AM MED INFORM ASSN, V28, P998, DOI 10.1093/jamia/ocaa325; OpenAI, 2023, ArXiv; Pape-Haugaard LB., 2020, DIGITAL PERSONALIZED; Psotka MA, 2020, CIRC-CARDIOVASC QUAL, V13, P474, DOI 10.1161/CIRCOUTCOMES.120.006564; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sebastian G., 2023, IJSPPC, V15, P1, DOI [10.4018/IJSPPC.325475, DOI 10.4018/IJSPPC.325475]; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Sykes D, 2021, NAT LANG ENG, V27, P203, DOI 10.1017/S1351324920000509; Tajirian T, 2020, J MED INTERNET RES, V22, DOI 10.2196/19274; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tripathi S., 2023, Research Anthology on Improving Medical Imaging Techniques for Analysis and Intervention, P79, DOI DOI 10.4018/978-1-6684-7544-7.CH005; Tripathi S, 2023, J AM COLL RADIOL, V20, P836, DOI 10.1016/j.jacr.2023.06.015	33	1	1	16	16	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1436	1440		10.1093/jamia/ocad258	http://dx.doi.org/10.1093/jamia/ocad258		JAN 2024	5	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38273739				2024-07-03	WOS:001151346500001
C	Jo, E; Epstein, DA; Jung, H; Kim, YH			ACM	Jo, Eunkyung; Epstein, Daniel A.; Jung, Hyunhoon; Kim, Young -Ho			Understanding the Benefits and Challenges of Deploying Conversational AI Leveraging Large Language Models for Public Health Intervention	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023)			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Chatbot; Large language model; Open-domain dialog system; Public health; Check-up calls; Social isolation		Recent large language models (LLMs) have advanced the quality of open-ended conversations with chatbots. Although LLM-driven chatbots have the potential to support public health interventions by monitoring populations at scale through empathetic interactions, their use in real-world settings is underexplored. We thus examine the case of CareCall, an open-domain chatbot that aims to support socially isolated individuals via check-up phone calls and monitoring by teleoperators. Through focus group observations and interviews with 34 people from three stakeholder groups, including the users, the teleoperators, and the developers, we found CareCall ofered a holistic understanding of each individual while ofoading the public health workload and helped mitigate loneliness and emotional burdens. However, our fndings highlight that traits of LLM-driven chatbots led to challenges in supporting public and personal health needs. We discuss considerations of designing and deploying LLM-driven chatbots for public health intervention, including tensions among stakeholders around system expectations.	[Jo, Eunkyung; Epstein, Daniel A.] Univ Calif Irvine, Irvine, CA 92697 USA; [Jung, Hyunhoon] NAVER CLOUD, Seongnam, Gyeonggi, South Korea; [Jo, Eunkyung; Kim, Young -Ho] NAVER AI Lab, Seongnam, Gyeonggi, South Korea	University of California System; University of California Irvine; Naver	Jo, E (corresponding author), Univ Calif Irvine, Irvine, CA 92697 USA.; Jo, E (corresponding author), NAVER AI Lab, Seongnam, Gyeonggi, South Korea.	eunkyuj@uci.edu; epstein@ics.uci.edu; hyunhoon.j@navercorp.com; yghokim@younghokim.net		Jo, Eunkyung/0000-0002-6494-3396; Kim, Young-Ho/0000-0002-2681-2774; Epstein, Daniel/0000-0002-2657-6345	NAVER AI Lab	NAVER AI Lab	We thank our participants for their sincere participation. We are also grateful to Sang-houn Ok and HaYeon Kang at NAVER for helping us recruit study participants. JingWei gave feedback on the early version of this paper. This work was supported as a research internship at NAVER AI Lab.	[Anonymous], P 33 ANN ACM C HUM F; [Anonymous], 2015, Heat Wave: A Social Autopsy of Disaster in Chicago; Arreola I, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1933, DOI 10.1145/2556288.2557084; Bae S., 2022, P FINDINGS ASS COMPU, P3769; BAE S, 2022, P 2022 C N AM CHAPT, P2128, DOI DOI 10.18653/V1/2022.NAACL-MAIN.155; Bartle V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517683; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Byun Hye-jin, 2022, THE KOREA HERALD; Chen Mark, 2021, EVALUATING LARGE LAN, DOI [10.43550,ARXIV.2107.0337.1, DOI 10.43550/ARXIV.2107.03374]; Chowdhery Aakanksha, 2022, PALM SCALING LANGUAG, DOI [10.48550;ARM,/220402311, DOI 10.48550/ARXIV.2204.02311]; Chung JJY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501819; Coghlan Simon, 2021, Proc ACM Hum Comput Interact, V5, DOI 10.1145/3449178; Consolvo S, 2004, LECT NOTES COMPUT SC, V3205, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Diasso D, 2021, GLOBAL HEALTH ACTION, V14, DOI 10.1080/16549716.2021.1979279; Donovan NJ, 2020, AM J GERIAT PSYCHIAT, V28, P1233, DOI 10.1016/j.jagp.2020.08.005; Eric M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P422; Eunkyung Jo, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3512939; Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183; Garrido-Muñoz I, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073184; Gehman S, 2020, FINDINGS ASS COMPUTA, P3356; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Huber B, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173851; Huber LL, 2013, INT J HUM-COMPUT INT, V29, P441, DOI 10.1080/10447318.2012.715990; Hyeyoung Ryu, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415223; Ismail Azra, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274344; Ismail A, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445130; Kim B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3405; Kim T, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376743; Kim YH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517457; Kim Young-Ho, 2022, NAACL 22 2 WORKSH BR, DOI [10.48550/ARMV:22-05.15503, DOI 10.48550/ARXIV.2205.15503]; Korea Law Translation Center, 2020, ACT PREV MAN LON DEA; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kuoppamäki S, 2021, BMC HEALTH SERV RES, V21, DOI 10.1186/s12913-021-06944-w; Lazar Amanda, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274372; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Lee M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300932; Lee YC, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376175; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu BJ, 2018, CYBERPSYCH BEH SOC N, V21, P625, DOI 10.1089/cyber.2018.0110; Liu Pengfei, 2021, PRETRAIN PROMPT PRED, DOI [10.48550/ARM:2107.13586, DOI 10.48550/ARXIV.2107.13586]; Lu Xi, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555569; Luo YH, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P606, DOI 10.1145/3461778.3462074; Luo YH, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376616; Maeng W, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517629; Moghe N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2322; Munikar M, 2019, 2019 ARTIFICIAL INTE, V1, P1, DOI [DOI 10.1109/AITB48515.2019.8947435, 10.1109/AITB48515.2019.8947435]; Mynatt ED, 2000, CUU 2000 CONFERENCE PROCEEDINGS, P65, DOI 10.1145/355460.355475; National Academies of Sciences Engineering and Medicine, 2020, Social Isolation and Loneliness in Older Adults: Opportunities for the Health Care System, DOI DOI 10.17226/25663; Nirmala V., 2019, SCI TECHNOLOGY J, V7, P22, DOI [10.22232/stj.2019.07.0103, DOI 10.22232/STJ.2019.07.01.03]; Olmo Alberto, 2021, ICAPS 21 WORKSH KNOW, DOI [10.485505ARXIV.210607131, DOI 10.48550/ARXIV.2106.07131]; Park S, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P926, DOI 10.1145/3461778.3462143; Pendse SR, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445410; Pichon Adrienne, 2021, Proc ACM Hum Comput Interact, V4, DOI 10.1145/3434170; Pradhan Alisha, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359316; Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341; Ramachandran D., 2010, Proceedings of the 28th international conference on Human factors in computing systems, P1889, DOI DOI 10.1145/1753326.1753610; Richards Olivia K., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449095; Roberts C, 2012, SOCIOLOGY, V46, P490, DOI 10.1177/0038038511422551; Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300; Rowan J., 2005, P SIGCHI C HUMAN FAC, DOI [DOI 10.1145/1054972.1055044, 10.1145/1054972.1055044]; Sharkey A, 2012, ETHICS INF TECHNOL, V14, P27, DOI 10.1007/s10676-010-9234-6; Sheng EM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4275; Shwartz V., 2020, P 28 INT C COMP LING, P6863, DOI 10.18653/v1/2020.coling-main.605; Simpson E, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6171, DOI 10.1145/3025453.3025881; Stowell E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173589; Thakkar D, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501868; Vaswani A., 2017, Advances in neural information processing systems, P6000; Veinot TC, 2019, MED CARE, V57, pS108, DOI 10.1097/MLR.0000000000001032; Vines J, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P607, DOI 10.1145/2493432.2493469; Wang L., 2021, Autonomous Intelligent Systems, V1, P1; Wang Lu, 2021, EVALUATION GENERATIV, DOI [10.48550/ARXIV.2107.13115, DOI 10.48550/ARXIV.2107.13115]; Welleck Sean, 2019, NEURAL TEXT GENERATI, DOI [10.48550/ARXIV.1908.04319, DOI 10.48550/ARXIV.1908.04319]; White G, 2015, INT CONF PER COMP, P121, DOI 10.4108/icst.pervasivehealth.2015.259095; Xu J, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5180; Xu XC, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2639; Yadav Deepika, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359272; Yang JC, 2020, AAAI CONF ARTIF INTE, V34, P9378; Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836; Yonhap, 2017, THE KOREA HERALD; Zhang S., 2022, OPT OPEN PRETRAINED, DOI DOI 10.48550/ARXIV.2205.01068; Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204; Zhou H, 2018, AAAI CONF ARTIF INTE, P730	85	9	9	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3581503	http://dx.doi.org/10.1145/3544548.3581503			16	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV5HH		Green Published, Bronze			2024-07-03	WOS:001048393806032
C	Du, RF; Li, N; Jin, J; Carney, M; Yuan, XX; Wright, K; Sherwood, M; Mayes, J; Chen, L; Jiang, J; Zhou, JT; Zhou, ZY; Yu, P; Iyengar, R; Kowdle, A; Olwal, A			ACM	Du, Ruofei; Li, Na; Jin, Jing; Carney, Michelle; Yuan, Xiuxiu; Wright, Kristen; Sherwood, Mark; Mayes, Jason; Chen, Lin; Jiang, Jun; Zhou, Jingtao; Zhou, Zhongyi; Yu, Ping; Iyengar, Ram; Kowdle, Adarsh; Olwal, Alex			Experiencing Visual Blocks for ML: Visual Prototyping of AI Pipelines	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		visual programming; large language models; visual prototyping; multi-modal models; node-graph editor; deep neural networks; data augmentation; deep learning; visual analytics		We demonstrate Visual Blocks for ML, a visual programming platform that facilitates rapid prototyping of ML-based multimedia applications. As the public version of Rapsai [3], we further integrated large language models and custom APIs into the platform. In this demonstration, we will showcase how to build interactive AI pipelines in a few drag-and-drops, how to perform interactive data augmentation, and how to integrate pipelines into Colabs. In addition, we demonstrate a wide range of community-contributed pipelines in Visual Blocks for ML, covering various aspects including interactive graphics, chains of large language models, computer vision, and multi-modal applications. Finally, we encourage students, designers, and ML practitioners to contribute ML pipelines through https://github.com/google/visualblocks/tree/main/pipelines to inspire creative use cases. Visual Blocks for ML is available at http://visualblocks.withgoogle.com.	[Du, Ruofei; Kowdle, Adarsh] Google Res, San Francisco, CA 94105 USA; [Li, Na; Jin, Jing; Carney, Michelle; Yuan, Xiuxiu; Wright, Kristen; Sherwood, Mark; Mayes, Jason; Chen, Lin; Jiang, Jun; Zhou, Jingtao; Zhou, Zhongyi; Yu, Ping; Iyengar, Ram; Olwal, Alex] Google Res, Mountain View, CA USA	Google Incorporated; Google Incorporated	Du, RF (corresponding author), Google Res, San Francisco, CA 94105 USA.		Zhou, Zhongyi/KII-1729-2024; Du, Ruofei/Q-6245-2017	Jin, Jing/0000-0002-4734-7058; Du, Ruofei/0000-0003-2471-9776; Jiang, Jun/0009-0000-4814-6912				Carney M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382839; Chung JJY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501819; Du RF, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581338; Gleicher M, 2020, COMPUT GRAPH FORUM, V39, P181, DOI 10.1111/cgf.13972; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Spinner T, 2020, IEEE T VIS COMPUT GR, V26, P1064, DOI 10.1109/TVCG.2019.2934629; Wu BY, 2022, IMAGE VISION COMPUT, V125, DOI 10.1016/j.imavis.2022.104520; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729	8	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									76	10.1145/3586182.3615817	http://dx.doi.org/10.1145/3586182.3615817			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000075
J	Kieser, F; Wulff, P; Kuhn, J; Küchemann, S				Kieser, Fabian; Wulff, Peter; Kuhn, Jochen; Kuechemann, Stefan			Educational data augmentation in physics education research using ChatGPT	PHYSICAL REVIEW PHYSICS EDUCATION RESEARCH			English	Article								Generative AI technologies such as large language models show novel potential to enhance educational research. For example, generative large language models were shown to be capable of solving quantitative reasoning tasks in physics and concept tests such as the Force Concept Inventory (FCI). Given the importance of such concept inventories for physics education research, and the challenges in developing them such as field testing with representative populations, this study seeks to examine to what extent a generative large language model could be utilized to generate a synthetic dataset for the FCI that exhibits content-related variability in responses. We use the recently introduced ChatGPT based on the GPT 4 generative large language model and investigate to what extent ChatGPT could solve the FCI accurately (RQ1) and could be prompted to solve the FCI as if it were a student belonging to a different cohort (RQ2). Furthermore, we study, to what extent ChatGPT could be prompted to solve the FCI as if it were a student having a different force- and mechanics-related preconception (RQ3). In alignment with other research, we found that ChatGPT could accurately solve the FCI. We furthermore found that prompting ChatGPT to respond to the inventory as if it belonged to a different cohort yielded no variance in responses, however, responding as if it had a certain preconception introduced much variance in responses that approximate real human responses on the FCI in some regards.	[Kieser, Fabian; Wulff, Peter] Heidelberg Univ Educ, Phys & Phys Educ Res, Neuenheimer Feld 561, D-69120 Heidelberg, Germany; [Kuhn, Jochen; Kuechemann, Stefan] Ludwig Maximilians Univ Munchen LMU Munich, Fac Phys, Chair Phys Educ, Geschwister Scholl Pl 1, D-80539 Munich, Germany	Ruprecht Karls University Heidelberg; University of Munich	Küchemann, S (corresponding author), Ludwig Maximilians Univ Munchen LMU Munich, Fac Phys, Chair Phys Educ, Geschwister Scholl Pl 1, D-80539 Munich, Germany.		Wulff, Peter/GSI-9069-2022; Kuhn, Jochen/K-4031-2014	Wulff, Peter/0000-0002-5471-7977; Kuchemann, Stefan/0000-0003-2729-1592; Kuhn, Jochen/0000-0002-6985-3218	LMUexcellent - Federal Ministry of Education and Research (BMBF); Free State of Bavaria; Lander	LMUexcellent - Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); Free State of Bavaria; Lander	This research was supported by LMUexcellent, funded by the Federal Ministry of Education and Research (BMBF) and the Free State of Bavaria under the Excellence Strategy of the Federal Government and the Lander.	Adams WK, 2011, INT J SCI EDUC, V33, P1289, DOI 10.1080/09500693.2010.512369; [Anonymous], 2008, US; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bommasani, 2022, OPPORTUNITIES RISKS; Bowman, 2023, 8 THINGS KNOW LARGE; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; columbia, About us; DeepL, US; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DISESSA AA, 1993, COGNITION INSTRUCT, V10, P105, DOI 10.1080/07370008.1985.9649008; Dodge Jesse, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1877, DOI 10.1145/3531146.3533234; Eaton P, 2021, PHYS REV PHYS EDUC R, V17, DOI 10.1103/PhysRevPhysEducRes.17.010130; Gregorcic B., 2023, PHYS EDUC, V58; Hake RR, 1998, AM J PHYS, V66, P64, DOI 10.1119/1.18809; Hammer D, 2000, AM J PHYS, V68, pS52, DOI 10.1119/1.19520; Hestenes D., 1992, PHYS TEACH, V30, P141, DOI [DOI 10.1119/1.2343497, 10.1119/1.2343497]; Huang J., 2023, Towards reasoning in large language models: A survey; Iwana BK, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254841; Kaplan Jared, 2020, Scaling laws for neural language models; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; Kieser F., Machine Learning in Educational Sciences: Approaches, Applications and Advances; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Koponen IT, 2010, SCI EDUC-NETHERLANDS, V19, P259, DOI 10.1007/s11191-009-9200-z; Kortemeyer G, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010132; Krupp L, 2023, Arxiv, DOI arXiv:2309.03087; KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441; Kuchemann S., 2023, Phys. Rev. Phys. Educ. Res., V19; Küchemann S, 2020, PHYS REV PHYS EDUC R, V16, DOI 10.1103/PhysRevPhysEducRes.16.010112; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; Lewkowycz Aitor, 2022, Solving quantitative reasoning problems with language models; Liu Pengfei, 2021, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing; Liu X, 2010, USING AND DEVELOPING MEASUREMENT INSTRUMENTS IN SCIENCE EDUCATION: A RASCH MODELING APPROACH, P1; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Nehm RH, 2012, J SCI EDUC TECHNOL, V21, P56, DOI 10.1007/s10956-011-9282-7; openfoam, ABOUT US; Porter L., 2014, P 2014 C INN TECHN C, P243, DOI DOI 10.1145/2591708.2591722; Rosenbaum R, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266102; Ruggieri C, 2020, PHYS REV PHYS EDUC R, V16, DOI 10.1103/PhysRevPhysEducRes.16.020123; Schubatzky T., 2023, Z. Didakt. Nat. Wiss., V29, P10; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; van de Schoot R, 2021, NAT MACH INTELL, V3, P125, DOI 10.1038/s42256-020-00287-7; van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584; Vaswani A, 2017, ADV NEUR IN, V30; Wang J, 2023, AM J PHYS, V91, P255, DOI 10.1119/5.0145897; West CG, 2023, Arxiv, DOI [arXiv:2303.17012, 10.48550/arXiv.2303.17012]; West CG, 2023, Arxiv, DOI arXiv:2303.01067; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Wulff P, 2023, EDUC INF TECHNOL, V28, P14325, DOI 10.1007/s10639-022-11531-5; Yeadon W., 2023, Phys. Educ., V58	55	8	8	60	69	AMER PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	2469-9896			PHYS REV PHYS EDUC R	Phys. Rev. Phys. Educ. Res.	OCT 25	2023	19	2							020150	10.1103/PhysRevPhysEducRes.19.020150	http://dx.doi.org/10.1103/PhysRevPhysEducRes.19.020150			13	Education & Educational Research; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Education & Educational Research	CB8V3		Green Submitted, gold			2024-07-03	WOS:001122891200001
J	Yeung, JA; Kraljevic, Z; Luintel, A; Balston, A; Idowu, E; Dobson, RJ; Teo, JT				Au Yeung, Joshua; Kraljevic, Zeljko; Luintel, Akish; Balston, Alfred; Idowu, Esther; Dobson, Richard J. J.; Teo, James T. T.			AI chatbots not yet ready for clinical use	FRONTIERS IN DIGITAL HEALTH			English	Article						large language models; chatbot; natural language processing (computer science); digital health; AI safety; transformer		As large language models (LLMs) expand and become more advanced, so do the natural language processing capabilities of conversational AI, or "chatbots". OpenAI's recent release, ChatGPT, uses a transformer-based model to enable human-like text generation and question-answering on general domain knowledge, while a healthcare-specific Large Language Model (LLM) such as GatorTron has focused on the real-world healthcare domain knowledge. As LLMs advance to achieve near human-level performances on medical question and answering benchmarks, it is probable that Conversational AI will soon be developed for use in healthcare. In this article we discuss the potential and compare the performance of two different approaches to generative pretrained transformers-ChatGPT, the most widely used general conversational LLM, and Foresight, a GPT (generative pretrained transformer) based model focused on modelling patients and disorders. The comparison is conducted on the task of forecasting relevant diagnoses based on clinical vignettes. We also discuss important considerations and limitations of transformer-based chatbots for clinical use.	[Au Yeung, Joshua; Luintel, Akish; Teo, James T. T.] Kings Coll Hosp London, Dept Neurosci, London, England; [Au Yeung, Joshua; Balston, Alfred; Idowu, Esther; Teo, James T. T.] Guys & St Thomas Hosp, London, England; [Kraljevic, Zeljko; Dobson, Richard J. J.] Kings Coll London, Dept Biostat, London, England; [Dobson, Richard J. J.] South London & Maudsley NHS Fdn Trust, NIHR Biomed Res Ctr, London, England; [Dobson, Richard J. J.] Kings Coll London, London, England	King's College Hospital NHS Foundation Trust; King's College Hospital; Guy's & St Thomas' NHS Foundation Trust; University of London; King's College London; South London & Maudsley NHS Trust; University of London; King's College London	Yeung, JA (corresponding author), Kings Coll Hosp London, Dept Neurosci, London, England.; Yeung, JA (corresponding author), Guys & St Thomas Hosp, London, England.	j.auyeung@nhs.net	Teo, James/D-9696-2011; dobson, richard/C-9269-2011	Teo, James/0000-0002-6899-8319; Au Yeung, Joshua/0000-0002-9428-2146; dobson, richard/0000-0003-4224-9245				[Anonymous], CHATGPT: Optimizing language models for dialogue; Baker A, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.543405; Blagec K, 2023, J BIOMED INFORM, V137, DOI 10.1016/j.jbi.2022.104274; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Huang PS, 2020, Arxiv, DOI arXiv:1911.03064; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Kim Y, 2012, COMPUT HUM BEHAV, V28, P241, DOI 10.1016/j.chb.2011.09.006; Kraljevic Z, 2023, Arxiv, DOI arXiv:2212.08072; Li YK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62922-y; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; mosaicml, PUBMED GPT DOM SPEC; Pal A., 2022, C HLTH INFERENCE LEA, V174, P248; Singhal A, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159224; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Taylor R, 2022, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]	23	38	38	12	32	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-253X		FRONT DIGIT HEALTH	Front. Digit. Health	APR 12	2023	5								1161098	10.3389/fdgth.2023.1161098	http://dx.doi.org/10.3389/fdgth.2023.1161098			5	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	M4UI6	37122812	Green Submitted, gold			2024-07-03	WOS:001030174600001
J	de Winter, J				de Winter, Joost			Can ChatGPT be used to predict citation counts, readership, and social media interaction? An exploration among 2222 scientific abstracts	SCIENTOMETRICS			English	Article						Citation prediction; Scientometrics; Altmetrics; ChatGPT; GPT-4; Scientific abstracts; Artificial intelligence		This study explores the potential of ChatGPT, a large language model, in scientometrics by assessing its ability to predict citation counts, Mendeley readers, and social media engagement. In this study, 2222 abstracts from PLOS ONE articles published during the initial months of 2022 were analyzed using ChatGPT-4, which used a set of 60 criteria to assess each abstract. Using a principal component analysis, three components were identified: Quality and Reliability, Accessibility and Understandability, and Novelty and Engagement. The Accessibility and Understandability of the abstracts correlated with higher Mendeley readership, while Novelty and Engagement and Accessibility and Understandability were linked to citation counts (Dimensions, Scopus, Google Scholar) and social media attention. Quality and Reliability showed minimal correlation with citation and altmetrics outcomes. Finally, it was found that the predictive correlations of ChatGPT-based assessments surpassed traditional readability metrics. The findings highlight the potential of large language models in scientometrics and possibly pave the way for AI-assisted peer review.	[de Winter, Joost] Delft Univ Technol, Fac Mech Engn, Dept Cognit Robot, Delft, Netherlands	Delft University of Technology	de Winter, J (corresponding author), Delft Univ Technol, Fac Mech Engn, Dept Cognit Robot, Delft, Netherlands.	j.c.f.dewinter@tudelft.nl		de Winter, Joost/0000-0002-1281-8200				Aiyappa R., 2023, P 3 WORKSH TRUSTW NA, P47, DOI DOI 10.18653/V1/2023.TRUSTNLP-1.5; Akcan D, 2013, SCIENTOMETRICS, V96, P297, DOI 10.1007/s11192-013-0949-0; Akella AP, 2021, J INFORMETR, V15, DOI 10.1016/j.joi.2020.101128; Aksnes DW, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019829575; Altmetric, 2023, ALTMETRIC; [Anonymous], 1967, Report No. AMRL-TR-66-220; Ante L, 2022, J INFORMETR, V16, DOI 10.1016/j.joi.2022.101252; Antonakis J, 2014, LEADERSHIP QUART, V25, P152, DOI 10.1016/j.leaqua.2013.10.014; Baldwin C, 2002, J PROF NURS, V18, P8, DOI 10.1053/jpnu.2002.30896; Bornmann L, 2015, SCIENTOMETRICS, V103, P1123, DOI 10.1007/s11192-015-1565-y; Bornmann L, 2014, J INFORMETR, V8, P895, DOI 10.1016/j.joi.2014.09.005; Bubeck S., 2023, arXiv; Caon M, 2020, PHYS ENG SCI MED, V43, P1145, DOI 10.1007/s13246-020-00941-9; CATTELL RB, 1966, MULTIVAR BEHAV RES, V1, P245, DOI 10.1207/s15327906mbr0102_10; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; Croux C, 2010, STAT METHOD APPL-GER, V19, P497, DOI 10.1007/s10260-010-0142-z; de Winter JCF, 2015, SCIENTOMETRICS, V102, P1773, DOI 10.1007/s11192-014-1445-x; de Winter JCF, 2023, INT J ARTIF INTELL E, DOI 10.1007/s40593-023-00372-z; de Winter JCF, 2016, PSYCHOL METHODS, V21, P273, DOI 10.1037/met0000079; de Winter JCF, 2015, PEERJ, V3, DOI 10.7717/peerj.733; Dimensions, 2023, DIMENSIONS; Dowling M, 2018, ECON LETT, V173, P100, DOI 10.1016/j.econlet.2018.09.023; Ferguson CJ, 2009, PROF PSYCHOL-RES PR, V40, P532, DOI 10.1037/a0015808; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gignac GE, 2016, PERS INDIV DIFFER, V102, P74, DOI 10.1016/j.paid.2016.06.069; Gunning R., 1952, TECHNIQUE CLEAR WRIT, P36; HANCOCK PA, IN PRESS; Hardwicke TE, 2021, ADV METH PRACT PSYCH, V4, DOI 10.1177/25152459211040837; Hartley J, 2016, SCIENTOMETRICS, V107, P1523, DOI 10.1007/s11192-016-1920-7; Harzing A.-W., 2023, PUBLISH PERISH VERSI; Haustein Stefanie, 2015, PLoS One, V10, pe0120495, DOI 10.1371/journal.pone.0120495; Haustein S, 2014, SCIENTOMETRICS, V101, P1145, DOI 10.1007/s11192-013-1221-3; Hu HT, 2021, ONLINE INFORM REV, V45, P1290, DOI 10.1108/OIR-05-2020-0188; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Ioannidis JPA, 2019, AM STAT, V73, P20, DOI 10.1080/00031305.2018.1447512; Ipeirotis P., 2023, READABILITY METRICS; Jimenez S, 2020, SCIENTOMETRICS, V125, P3187, DOI 10.1007/s11192-020-03526-1; Katz DM, 2024, PHILOS T R SOC A, V382, DOI 10.1098/rsta.2023.0254; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Kousha K., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2212.06574; Liu XY, 2023, SCIENTOMETRICS, V128, P3107, DOI 10.1007/s11192-023-04679-5; Lu C, 2019, J INFORMETR, V13, P817, DOI 10.1016/j.joi.2019.07.004; Ma AQ, 2021, SCIENTOMETRICS, V126, P6803, DOI 10.1007/s11192-021-04033-7; MCLAUGHLIN GH, 1969, J READING, V12, P639; Mendeley, 2023, MENDELEY; Murray R, 2008, J FURTH HIGHER EDUC, V32, P119, DOI 10.1080/03098770701851854; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, TEXT COMPL; OpenAI, 2022, OpenA I; Pei ZR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-022-35766-5; Peterson R.A., 2000, MARKET LETT, V11, P261, DOI [10.1023/A:1008191211004, DOI 10.1023/A:1008191211004]; Pulido CM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203117; Saeed-Ul Hassan, 2020, KNOWL-BASED SYST, V192, DOI 10.1016/j.knosys.2019.105383; Saeed-Ul Hassan, 2017, SCIENTOMETRICS, V113, P1037, DOI 10.1007/s11192-017-2512-x; Sand-Jensen K, 2007, OIKOS, V116, P723, DOI 10.1111/j.2007.0030-1299.15674.x; Scopus, 2023, SCOPUS; Sienkiewicz J, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.160140; Sommer V, 2017, APPL ECON LETT, V24, P809, DOI 10.1080/13504851.2016.1229410; Tabone W, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.231053; Tahamtan Iman, 2016, Scientometrics, V107, P1195, DOI 10.1007/s11192-016-1889-2; Thelwall M, 2018, SCIENTOMETRICS, V115, P1231, DOI 10.1007/s11192-018-2715-9; Wang S, 2022, SCIENTOMETRICS, V127, P4697, DOI 10.1007/s11192-022-04427-1; Warren HR, 2017, JAMA-J AM MED ASSOC, V317, P131, DOI 10.1001/jama.2016.18346; Weijters B, 2012, J MARKETING RES, V49, P737, DOI 10.1509/jmr.11.0368; Xie J, 2019, SCIENTOMETRICS, V118, P763, DOI 10.1007/s11192-019-03015-0; Yang X., 2023, ARXIV, DOI [10.48550/arXiv.2302.08081, DOI 10.48550/ARXIV.2302.08081]; Zhang B., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2212.14548; Zhong Q., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.10198	70	2	2	48	48	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0138-9130	1588-2861		SCIENTOMETRICS	Scientometrics	APR	2024	129	4					2469	2487		10.1007/s11192-024-04939-y	http://dx.doi.org/10.1007/s11192-024-04939-y		FEB 2024	19	Computer Science, Interdisciplinary Applications; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	QV6H9		hybrid			2024-07-03	WOS:001162583700002
C	Wang, RS; Duan, YF; Lam, CT; Chen, JX; Xu, JS; Chen, HM; Liu, XH; Pang, PCI; Tan, T		Fang, L; Pei, J; Zhai, G; Wang, R		Wang, Rongsheng; Duan, Yaofei; Lam, ChanTong; Chen, Jiexin; Xu, Jiangsheng; Chen, Haoming; Liu, Xiaohong; Pang, Patrick Cheong-Iao; Tan, Tao			IvyGPT: InteractiVe Chinese Pathway Language Model in Medical Domain	ARTIFICIAL INTELLIGENCE, CICAI 2023, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	3rd CAAI International Conference on Artificial Intelligence (CICAI)	JUL 22-23, 2023	Chinese Assoc Artificial Intelligence, Fuzhou, PEOPLES R CHINA		Chinese Assoc Artificial Intelligence	Large language models; Medical; Reinforcement Learning		General large language models (LLMs) such as ChatGPT have shown remarkable success. However, such LLMs have not been widely adopted for medical purposes, due to poor accuracy and inability to provide medical advice. We propose IvyGPT, an LLM based on LLaMA that is trained and fine-tuned with high-quality medical question-answer (QA) instances and Reinforcement Learning from Human Feedback (RLHF). In the training, we used QLoRA to handle 33 billion parameters on a small number of NVIDIA A100 (80 GB) GPUs. Experimental results show that IvyGPT has outperformed other medical GPT models. The online demo is available at http://81.71.71.157:52022. Our demo video can be found at https://youtu.be/O4D74pQh8Is.	[Wang, Rongsheng; Duan, Yaofei; Lam, ChanTong; Chen, Jiexin; Chen, Haoming; Pang, Patrick Cheong-Iao; Tan, Tao] Macao Polytechn Univ, Fac Sci Appl, Rua Luis Gonzaga Gomes, Macau 999078, Peoples R China; [Xu, Jiangsheng] Opera Inc, Beijing, Peoples R China; [Liu, Xiaohong] Shanghai Jiao Tong Univ, John Hopcroft Ctr, Shanghai 200240, Peoples R China	Macao Polytechnic University; Shanghai Jiao Tong University	Tan, T (corresponding author), Macao Polytechn Univ, Fac Sci Appl, Rua Luis Gonzaga Gomes, Macau 999078, Peoples R China.	taotanjs@gmail.com			Science and Technology Development Fund of Macau SAR [0105/2022/A, 0041/2023/RIB2]	Science and Technology Development Fund of Macau SAR	This work was funded by the Science and Technology Development Fund of Macau SAR (Grant Number 0105/2022/A and File Number 0041/2023/RIB2).	Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Li JX, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph192013446; Liu H., 2023, MedicalGPT-zh; Ouyang L., 2022, NEURIPS; Touvron H., 2023, Llama: Open and efficient foundation language models; Wang H., 2023, HUATUO TUNING LLAMA; Zhang H., 2023, HuatuoGPT, towards taming language model to be a doctor; Zhu W., 2023, ChatMed: a Chinese medical large language model; Zhu W., 2023, ShenNong-TCM-LLM	10	0	0	0	0	SPRINGER-VERLAG SINGAPORE PTE LTD	SINGAPORE	152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE	2945-9133	1611-3349	978-981-99-9118-1; 978-981-99-9119-8	LECT NOTES ARTIF INT			2024	14474						378	382		10.1007/978-981-99-9119-8_34	http://dx.doi.org/10.1007/978-981-99-9119-8_34			5	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8RL					2024-07-03	WOS:001206024900034
C	Melo, R; Santos, PA; Dias, J		Moniz, N; Vale, Z; Cascalho, J; Silva, C; Sebastiao, R		Melo, Rui; Santos, Pedro A.; Dias, Joao			A Semantic Search System for the Supremo Tribunal de Justica	PROGRESS IN ARTIFICIAL INTELLIGENCE, EPIA 2023, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	22nd EPIA Conference on Artificial Intelligence (EPIA)	SEP 05-08, 2023	Azores, PORTUGAL	EPIA, Associacao Portuguesa Inteligencia Artificial, Springer, Elsevier, Artificial Intelligence Journal, Fundacao Ciencia & Tecnologia, Governo Acores, Assembleia Legislativa Regiao Autonoma Acores, Camara Municipal Horta, NOS, INESCTEC, GRIA, LIACC, OKEANOS UAC, Univ Acores, Res Grp Intelligent Engn & Comp Adv Innovat & Dev, CISUC, Inst Engn Electronica Telematica Aveiro, Intelligent Syst Associate Lab, Dev Scope		Legal information retrieval; Semantic search; Large language models; BERT		Many information retrieval systems use lexical approaches to retrieve information. Such approaches have multiple limitations, and these constraints are exacerbated when tied to specific domains, such as the legal one. Large language models, such as BERT, deeply understand a language and may overcome the limitations of older methodologies, such as BM25. This work investigated and developed a prototype of a Semantic Search System to assist the Supremo Tribunal de Justica (Portuguese Supreme Court of Justice) in its decision-making process. We built a Semantic Search System that uses specially trained BERT models (Legal-BERTimbau variants) and a Hybrid Search System that incorporates both lexical and semantic techniques by combining the capabilities of BM25 and the potential of Legal-BERTimbau. In this context, we obtained a 335% increase on the discovery metric when compared to BM25 for the first query result. This work also provides information on the most relevant techniques for training a Large Language Model adapted to Portuguese jurisprudence and introduces a new technique of Metadata Knowledge Distillation.	[Melo, Rui; Santos, Pedro A.] Univ Lisbon, Inst Super Tecn, Lisbon, Portugal; [Melo, Rui; Santos, Pedro A.; Dias, Joao] INESC ID, Lisbon, Portugal; [Dias, Joao] Univ Algarve, Fac Ciencias & Tecnol, Faro, Portugal; [Dias, Joao] CCMAR, Faro, Portugal	Universidade de Lisboa; Universidade de Lisboa; INESC-ID; Universidade do Algarve	Melo, R (corresponding author), Univ Lisbon, Inst Super Tecn, Lisbon, Portugal.; Melo, R (corresponding author), INESC ID, Lisbon, Portugal.	rui.melo@tecnico.ulisboa.pt; pedro.santos@tecnico.ulisboa.pt; jmdias@ualg.pt	Santos, Pedro A/C-6773-2011	Santos, Pedro A/0000-0002-1369-0085; Dias, Joao/0000-0002-1653-1821; Melo, Rui/0009-0007-0009-0463	Fundacao para a Ciencia e a Tecnologia (FCT) [UIDB/50021/2020, UIDB/04326/2020, UIDP/04326/2020, LA/P/0101/2020]; STJ	Fundacao para a Ciencia e a Tecnologia (FCT)(Fundacao para a Ciencia e a Tecnologia (FCT)); STJ	The presented work was done as part of INESC-ID's project "Sumarizacao e Informacao de decisoes: Aplicacao de Tecnicas de Inteligencia Artificial no Supremo Tribunal de Justica" (IRIS), in collaboration with STJ. This work was partially supported by STJ and by national funds through Fundacao para a Ciencia e a Tecnologia (FCT) through projects UIDB/50021/2020, UIDB/04326/2020, UIDP/04326/2020 and LA/P/0101/2020.	Boos R, 2014, LECT NOTES COMPUT SC, V8775, P201, DOI 10.1007/978-3-319-09761-9_22; Choi J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2192, DOI 10.1145/3404835.3463076; Cordeiro N., 2022, NLP Applied To Portuguese Consumer Law; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fonseca E, 2016, COMPUTATIONAL PROCES, P13; Kim M., 2021, P COLIEE WORKSH ICAI; May P., 2021, Machine translated multilingual sts benchmark dataset; Nguyen H, 2020, Arxiv, DOI arXiv:2011.08071; OpenAI, 2023, GPT-4 Technical Report; Raffel C, 2020, J MACH LEARN RES, V21; Real L, 2020, LECT NOTES ARTIF INT, V12037, P406, DOI 10.1007/978-3-030-41505-1_39; Reimers N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4512; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Souza F, 2020, Arxiv, DOI [arXiv:1909.10649, 10.48550/arXiv.1909.10649, DOI 10.48550/ARXIV.1909.10649]; Thakur Nandan, 2021, 35 C NEURAL INFORM P; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Wang KX, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2345; Wang KX, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P671; Zhelezniak V, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P951	21	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-49010-1; 978-3-031-49011-8	LECT NOTES ARTIF INT			2023	14116						142	154		10.1007/978-3-031-49011-8_12	http://dx.doi.org/10.1007/978-3-031-49011-8_12			13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5HA					2024-07-03	WOS:001160568000012
J	Bhardwaj, RG; Bedi, HS				Bhardwaj, Ravindra Giriraj; Bedi, Harpreet Singh			ChatGPT as an education and learning tool for engineering, technology and general studies: performance analysis of ChatGPT 3.0 on CSE, GATE and JEE examinations of India	INTERACTIVE LEARNING ENVIRONMENTS			English	Article; Early Access						ChatGPT; generative pre-trained transformer; artificial intelligence; education technology; large language model		The quantitative and qualitative performance analysis of ChatGPT-3.0, a large language model, is carried out on three important and highly competitive examinations held in India: civil services examination (CSE, prelims), graduate aptitude test in engineering (GATE), and joint entrance examination (JEE). These examinations cover general knowledge, current affairs, history, geography, Indian polity, economics, mathematics, physics, chemistry, engineering, and technology aspects at the undergraduate and graduate levels. The Accuracy, Concordance, and Insight (ACI) criteria is used to analyze the performance of ChatGPT. ChatGPT passed CSE without much specialized training and reinforcement, however, underperformed in GATE and JEE. Overall, the average accuracy rate of ChatGPT is 48.71%, with a 44.45% concordance for all explanations. However, the concordance for accurate explanations is found to be 91.87% with a high level of insights given in the explanations. Moreover, the average accuracy of ChatGPT improves to 77.69% after training. The results suggest that large language models have great potential to assist with education technology and act as an instructor for the preparation of technical, aptitude and general studies topics for competitive examinations. Drawing insights from the findings of the current research, some limitations in the present study and possible future research directions are suggested.	[Bhardwaj, Ravindra Giriraj; Bedi, Harpreet Singh] Birla Inst Technol & Sci Pilani, Dept Mech Engn, Dubai, U Arab Emirates		Bhardwaj, RG (corresponding author), Birla Inst Technol & Sci Pilani, Dept Mech Engn, Dubai, U Arab Emirates.	ravindra.waj@gmail.com		BHARDWAJ, RAVINDRA/0000-0003-3816-9437				Adeshola I, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2253858; Amberkar A., 2018, 2018 INT C CURRENT T; [Anonymous], 2020, TIME'S UP Now; [Anonymous], News18.; [Anonymous], INDIA TODAY; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Chiu TKF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2253861; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gokhale S. R., 1976, Indian Journal of Public Administration, V22, P260, DOI [https://doi.org/10.1177/0019556119760210, DOI 10.1177/0019556119760210]; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kurian N, 2023, BRIT DENT J, V234, P73, DOI 10.1038/s41415-023-5461-1; Ladousa C, 2020, SIGNS SOC, V8, P155, DOI 10.1086/706035; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lund B. D., 2023, Library Hi Tech News; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Misra P. K., 2018, Indian women's leadership in the government sector; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perez-Castro A, 2023, TECHNOL FORECAST SOC, V189, DOI 10.1016/j.techfore.2023.122380; Rajan K, 2017, ARTIF INTELL, V247, P1, DOI 10.1016/j.artint.2017.03.003; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Russell SJ., 2016, ARTIF INTELL; Reddy JS, 2023, INDIAN J SURG, V85, P1524, DOI 10.1007/s12262-023-03776-2; Shazhaev I., 2023, At. Indones. J., V28, P1; Strzelecki A, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2209881; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhilenkov AA, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P1032, DOI 10.1109/EIConRus.2018.8317265	31	0	0	12	12	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1049-4820	1744-5191		INTERACT LEARN ENVIR	Interact. Learn. Environ.	2024 MAY 1	2024										10.1080/10494820.2024.2344054	http://dx.doi.org/10.1080/10494820.2024.2344054		MAY 2024	14	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	OY2F8					2024-07-03	WOS:001210765300001
J	Tang, L				Tang, Lin			Large models for genomics	NATURE METHODS			English	Editorial Material								Large language models are learning the language of genomics.	[Tang, Lin] Nat & Nat Methods, London, England		Tang, L (corresponding author), Nat & Nat Methods, London, England.	lin.tang@nature.com							0	1	1	18	20	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1548-7091	1548-7105		NAT METHODS	Nat. Methods	DEC	2023	20	12								10.1038/s41592-023-02105-5	http://dx.doi.org/10.1038/s41592-023-02105-5		DEC 2023	20	Biochemical Research Methods	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	GJ1H3	38057514				2024-07-03	WOS:001115409000006
J	Piñeiro-Martín, A; García-Mateo, C; Docío-Fernández, L; López-Pérez, MD				Pineiro-Martin, Andres; Garcia-Mateo, Carmen; Docio-Fernandez, Laura; Lopez-Perez, Maria del Carmen			Ethical Challenges in the Development of Virtual Assistants Powered by Large Language Models	ELECTRONICS			English	Article						ethical challenges; virtual assistants; Large Language Models; ethical AI; ethical guidelines; data privacy; bias mitigation; public services; AI regulation		Virtual assistants (VAs) have gained widespread popularity across a wide range of applications, and the integration of Large Language Models (LLMs), such as ChatGPT, has opened up new possibilities for developing even more sophisticated VAs. However, this integration poses new ethical issues and challenges that must be carefully considered, particularly as these systems are increasingly used in public services: transfer of personal data, decision-making transparency, potential biases, and privacy risks. This paper, an extension of the work presented at IberSPEECH 2022, analyzes the current regulatory framework for AI-based VAs in Europe and delves into ethical issues in depth, examining potential benefits and drawbacks of integrating LLMs with VAs. Based on the analysis, this paper argues that the development and use of VAs powered by LLMs should be guided by a set of ethical principles that prioritize transparency, fairness, and harm prevention. The paper presents specific guidelines for the ethical use and development of this technology, including recommendations for data privacy, bias mitigation, and user control. By implementing these guidelines, the potential benefits of VAs powered by LLMs can be fully realized while minimizing the risks of harm and ensuring that ethical considerations are at the forefront of the development process.	[Pineiro-Martin, Andres] Balidea Consulting & Programming SL, Witland Bldg,Caminos Vida St, Santiago De Compostela 15701, Spain; [Pineiro-Martin, Andres; Garcia-Mateo, Carmen; Docio-Fernandez, Laura; Lopez-Perez, Maria del Carmen] Univ Vigo, AtlanTTic Res Ctr, GTM Res Grp, Maxwell St, Vigo 36310, Spain	Universidade de Vigo; atlanTTic	Piñeiro-Martín, A (corresponding author), Balidea Consulting & Programming SL, Witland Bldg,Caminos Vida St, Santiago De Compostela 15701, Spain.; Piñeiro-Martín, A (corresponding author), Univ Vigo, AtlanTTic Res Ctr, GTM Res Grp, Maxwell St, Vigo 36310, Spain.	andres.pineiro@balidea.com; carmen.garcia@uvigo.es; ldocio@gts.uvigo.es; carmen.lopez@balidea.com	; Garcia-Mateo, Carmen/I-4144-2015	Pineiro-Martin, Andres/0009-0000-3708-6862; Garcia-Mateo, Carmen/0000-0001-6856-939X	Galician Innovation Agency (GAIN); Axudas para a consolidacion e estructuracion de unidades de investigacion competitivas do Sistema Universitario de Galicia [ED431B 2021/24]; European Union for the "European Regional Development Fund-ERDF"; European Regional Development Fund-ERDF"; Conselleria de Cultura, Educacion, Formacion profesional e Universidades of the Xunta de Galicia for the "Centro singular de investigacion de Galicia"	Galician Innovation Agency (GAIN); Axudas para a consolidacion e estructuracion de unidades de investigacion competitivas do Sistema Universitario de Galicia; European Union for the "European Regional Development Fund-ERDF"(European Union (EU)Marie Curie Actions); European Regional Development Fund-ERDF"(European Union (EU)); Conselleria de Cultura, Educacion, Formacion profesional e Universidades of the Xunta de Galicia for the "Centro singular de investigacion de Galicia"	This work is funded by the Galician Innovation Agency (GAIN) and the Conselleria de Cultura, Educacion, Formacion profesional e Universidades of the Xunta de Galicia through the program: Doutoramento Industrial [55]. It has also received funding from the Conselleria de Cultura, Educacion, Formacion profesional e Universidades of the Xunta de Galicia for the "Centro singular de investigacion de Galicia" accreditation 2019-2022 and by the "Axudas para a consolidacion e estructuracion de unidades de investigacion competitivas do Sistema Universitario de Galicia -ED431B 2021/24", and the European Union for the "European Regional Development Fund-ERDF".	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ala-Pietila P., 2020, ASSESSMENT LIST TRUS; Amazon re:MARS, 2022, US; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], CLOUD NATIVE BIOMETR; Ardila R, 2020, Arxiv, DOI arXiv:1912.06670; Artificial Intelligence Act, 2021, EURLEX 2021PC0206; Attard-Frost B., 2023, AI Ethics, V3, P389, DOI [10.1007/s43681-022-00156-6, DOI 10.1007/S43681-022-00156-6]; Babu A, 2021, Arxiv, DOI arXiv:2111.09296; Banga E.R., 2008, DESCRIPCION SINTETIZ; Bocklisch T, 2017, Arxiv, DOI arXiv:1712.05181; Brey P., 2021, SIENNA PROJECT STAKE; Bunk T, 2020, Arxiv, DOI [arXiv:2004.09936, DOI 10.48550/ARXIV.2004.09936]; Cervantes JA, 2020, SCI ENG ETHICS, V26, P501, DOI 10.1007/s11948-019-00151-x; Charisi V, 2017, Arxiv, DOI arXiv:1703.04741; Chatila Raja, 2018, Technical Report; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dainow B., 2021, EUROPEAN COMMISSION; Danielescu A., 2020, P 2 C CONVERSATIONAL, P1; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dignum V, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P60, DOI 10.1145/3278721.3278745; Ernst C. P. H., 2020, AMCIS; European Commission, 2022, EURLEX52022PC0496; European Parliament, 2023, DRAFT Compromise Amendments on the Draft Report; Geramifard A., 2022, PROJECT CAIRAOKE BUI; Gubareva R, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P97, DOI 10.5220/0009417600970103; Habler F., 2019, P MENSCH COMPUTER, P469; Hleg A., 2019, EUROPEAN COMMISSIONS; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kang C., 2023, NEW YORK TIMES 0516; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kieslich K, 2022, BIG DATA SOC, V9, DOI 10.1177/20539517221092956; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Kumar K, 2023, Arxiv, DOI arXiv:2304.02138; Lopez M.d.C., 2023, FSTP PROJECT REPORT; Martin A. P., 2022, P IBERSPEECH, P121, DOI 10.21437/IberSPEECH.2022-25; Mökander J, 2021, MIND MACH, V31, P323, DOI 10.1007/s11023-021-09557-8; Nass C. I., 2005, Wired for speech: How voice activates and advances the human-computer relationship; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Pazo F.J.M., TEXTO VOZ GALLEGO CA; Peters Dorian, 2020, IEEE Transactions on Technology and Society, V1, P34, DOI 10.1109/TTS.2020.2974991; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Raji ID, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P33, DOI 10.1145/3351095.3372873; Rehm G, 2020, Arxiv, DOI arXiv:2003.13551; Rubeis G, 2020, ARCH GERONTOL GERIAT, V91, DOI 10.1016/j.archger.2020.104186; Samoili S., 2020, AI Watch. Defining Artificial Intelligence. Towards an operational definition and taxonomy of artificial intelligence; Schulman John, 2022, Chatgpt: Optimizing language models for dialogue; The United Nations Educational Scientific and Cultural Organization, 2021, REC ETH ART INT; Vaishya R, 2020, DIABETES METAB SYND, V14, P337, DOI 10.1016/j.dsx.2020.04.012; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vlasov V, 2020, Arxiv, DOI arXiv:1910.00486; Vona F, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399845; US	54	9	9	12	33	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUL	2023	12	14							3170	10.3390/electronics12143170	http://dx.doi.org/10.3390/electronics12143170			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	N6IL7		gold			2024-07-03	WOS:001038024600001
J	Villa, L; Carneros-Prado, D; Dobrescu, CC; Sánchez-Miguel, A; Cubero, G; Hervás, R				Villa, Laura; Carneros-Prado, David; Dobrescu, Cosmin C.; Sanchez-Miguel, Adrian; Cubero, Guillermo; Hervas, Ramon			Comparative Analysis of Generic and Fine-Tuned Large Language Models for Conversational Agent Systems	ROBOTICS			English	Article						large language model; dialog model design; conversational agents; chatbot; chatbot development platform; intent classification; entity recognition		In the rapidly evolving domain of conversational agents, the integration of Large Language Models (LLMs) into Chatbot Development Platforms (CDPs) is a significant innovation. This study compares the efficacy of employing generic and fine-tuned GPT-3.5-turbo models for designing dialog flows, focusing on the intent and entity recognition crucial for dynamic conversational interactions. Two distinct approaches are introduced: a generic GPT-based system (G-GPT) leveraging the pre-trained model with complex prompts for intent and entity detection, and a fine-tuned GPT-based system (FT-GPT) employing customized models for enhanced specificity and efficiency. The evaluation encompassed the systems' ability to accurately classify intents and recognize named entities, contrasting their adaptability, operational efficiency, and customization capabilities. The results revealed that, while the G-GPT system offers ease of deployment and versatility across various contexts, the FT-GPT system demonstrates superior precision, efficiency, and customization, although it requires initial training and dataset preparation. This research highlights the versatility of LLMs in enriching conversational features for talking assistants, from social robots to interactive chatbots. By tailoring these advanced models, the fluidity and responsiveness of conversational agents can be enhanced, making them more adaptable and effective in a variety of settings, from customer service to interactive learning environments.	[Villa, Laura; Carneros-Prado, David; Dobrescu, Cosmin C.; Sanchez-Miguel, Adrian; Cubero, Guillermo; Hervas, Ramon] Univ Castilla La Mancha, Dept Technol & Informat Syst, Ciudad Real 13071, Spain	Universidad de Castilla-La Mancha	Hervás, R (corresponding author), Univ Castilla La Mancha, Dept Technol & Informat Syst, Ciudad Real 13071, Spain.	laura.villa@uclm.es; david.carneros@uclm.es; cosmin.dobrescu@uclm.es; adrian.sortega@uclm.es; guillermo.cubero@uclm.es; ramon.hlucas@uclm.es	Carneros Prado, David/KRP-9253-2024; Hervas, Ramon/Y-7843-2019	Cubero Charco, Guillermo/0009-0000-9392-1658; Hervas, Ramon/0000-0001-9924-5443; Carneros Prado, David/0000-0003-4042-3713; Villa, Laura/0000-0001-9928-8945	JUNTA DE COMUNIDADES DE CASTILLA-LA MANCHA	JUNTA DE COMUNIDADES DE CASTILLA-LA MANCHA(Junta de Comunidades de Castilla-La Mancha)	No Statement Available	Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Astorga M, 2023, ROBOTICS, V12, DOI 10.3390/robotics12010029; Bocklisch T, 2017, Arxiv, DOI arXiv:1712.05181; Daniel G, 2020, IEEE ACCESS, V8, P15332, DOI 10.1109/ACCESS.2020.2966919; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gupta Jahnvi, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P504, DOI 10.1109/ICACCS51430.2021.9442006; Husak V, 2020, CEUR WORKSHOP PROCEE, V2604; iso, ISO 8601: Date and Time Format; Li MH, 2023, PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON SYSTEMS FOR ENERGY-EFFICIENT BUILDINGS, CITIES, AND TRANSPORTATION, BUILDSYS 2023, P208, DOI 10.1145/3600100.3623719; Lins L.F., 2022, Lecture Notes in Business Information Processing, V436, P312, DOI [10.1007/978-3-030-94343-124, DOI 10.1007/978-3-030-94343-124]; Liu C, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-56874-w; Macedo P, 2019, PROCEDIA COMPUT SCI, V160, P402, DOI 10.1016/j.procs.2019.11.074; Malamas N, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010099; Mir Y.O.V., 2024, Stud. Comput. Intell, V1134, P213, DOI [10.1007/978-3-031-50495-28, DOI 10.1007/978-3-031-50495-28]; Motger Q, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527450; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Ralston Kennedy, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P1924, DOI 10.1109/ICMLA.2019.00309; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127; Samuel Isaac, 2020, 2020 International Conference on Decision Aid Sciences and Application (DASA), P104, DOI 10.1109/DASA51403.2020.9317214; Sidogi T, 2021, IEEE SYS MAN CYBERN, P46, DOI 10.1109/SMC52423.2021.9659283; Tamagnone N., 2023, P 32 INT JOINT C ART, P6219, DOI [10.24963/ijcai.2023/690, DOI 10.24963/IJCAI.2023/690]; Villa Laura, 2023, Proceedings of the 15th International Conference on Ubiquitous Computing & Ambient Intelligence (UCAmI 2023). Lecture Notes in Networks and Systems (835), P286, DOI 10.1007/978-3-031-48306-6_29; Villa Laura, 2022, HCI International 2022 - Late Breaking Posters: 24th International Conference on Human-Computer Interaction, HCII 2022, Virtual Event, Proceedings. Communications in Computer and Information Science (1655), P568, DOI 10.1007/978-3-031-19682-9_72; Villa L, 2023, LECT NOTE NETW SYST, V594, P234, DOI 10.1007/978-3-031-21333-5_23; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	26	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2218-6581		ROBOTICS	Robotics	MAY	2024	13	5							68	10.3390/robotics13050068	http://dx.doi.org/10.3390/robotics13050068			20	Robotics	Emerging Sources Citation Index (ESCI)	Robotics	RZ5R0		gold			2024-07-03	WOS:001231497200001
J	Amin, KS; Forman, HP; Davis, MA				Amin, Kanhai S.; Forman, Howard P.; Davis, Melissa A.			Even with ChatGPT, race matters	CLINICAL IMAGING			English	Article						ChatGPT; Large language models; Health equity; Radiology report; Implicit bias		Background: Applications of large language models such as ChatGPT are increasingly being studied. Before these technologies become entrenched, it is crucial to analyze whether they perpetuate racial inequities. Methods: We asked Open AI's ChatGPT-3.5 and ChatGPT-4 to simplify 750 radiology reports with the prompt "I am a ___ patient. Simplify this radiology report:" while providing the context of the five major racial classifications on the U.S. census: White, Black or African American, American Indian or Alaska Native, Asian, and Native Hawaiian or other Pacific Islander. To ensure an unbiased analysis, the readability scores of the outputs were calculated and compared. Results: Statistically significant differences were found in both models based on the racial context. For ChatGPT3.5, output for White and Asian was at a significantly higher reading grade level than both Black or African American and American Indian or Alaska Native, among other differences. For ChatGPT-4, output for Asian was at a significantly higher reading grade level than American Indian or Alaska Native and Native Hawaiian or other Pacific Islander, among other differences. Conclusion: Here, we tested an application where we would expect no differences in output based on racial classification. Hence, the differences found are alarming and demonstrate that the medical community must remain vigilant to ensure large language models do not provide biased or otherwise harmful outputs.	[Amin, Kanhai S.] Yale Coll, New Haven, CT USA; [Forman, Howard P.; Davis, Melissa A.] Yale Sch Med, Dept Radiol & Biomed Imaging, New Haven, CT 06510 USA	Yale University; Yale University	Davis, MA (corresponding author), Yale Sch Med, Dept Radiol & Biomed Imaging, New Haven, CT 06510 USA.	melissa.a.davis@yale.edu						Amin K, 2024, HEALTHCARE-J DEL SCI, V12, DOI 10.1016/j.hjdsi.2023.100731; Amin K, 2023, YALE J BIOL MED, V96, P407, DOI 10.59249/NKOY5498; Amin Kanhai S, 2023, Radiology, V309, pe232561, DOI 10.1148/radiol.232561; [Anonymous], Bard Privacy Health Hub; [Anonymous], PRIVACY POLICY; Dorr DA, 2023, JAMA-J AM MED ASSOC, V329, P1347, DOI 10.1001/jama.2023.2771; Doshi R., 2023, medRxiv; Hanna J.J., 2023, medRxiv, DOI DOI 10.1101/2023.08.28.23294730; Zhang A, 2023, medRxiv, DOI [10.1101/2023.11.14.23298525, DOI 10.1101/2023.11.14.23298525]	9	3	3	2	2	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0899-7071	1873-4499		CLIN IMAG	Clin. Imaging	MAY	2024	109								110113	10.1016/j.clinimag.2024.110113	http://dx.doi.org/10.1016/j.clinimag.2024.110113		MAR 2024	4	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	QD8U8	38552383				2024-07-03	WOS:001219040700001
C	Madani, P			IEEE	Madani, Pooria			Metamorphic Malware Evolution: The Potential and Peril of Large Language Models	2023 5TH IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS, TPS-ISA			English	Proceedings Paper	5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)	NOV 01-03, 2023	Atlanta, GA	IEEE, IEEE Comp Soc		Metamorphic Malware; Large Language Models; Program Synthesis; Code Cloning; Malware Detection; Code Mutation		Code metamorphism refers to a computer programming exercise wherein the program modifies its own code (partial or entire) consistently and automatically while retaining its core functionality. This technique is often used for online performance optimization and automated crash recovery in certain mission-critical applications. However, the technique has been misappropriated by malware creators to bypass signature-based detection measures instituted by anti-malware engines. However, current code mutation engines used by threat actors offer only a limited degree of mutation, which is frequently detectable via static code analysis. The advent of large language models (LLMs), such as ChatGPT 4.0 and Google Bart may lead to a significant evolution in this landscape. These models have demonstrated a level of algorithm comprehension and code synthesis capability that closely resembles human abilities. This advancement has sparked concerns among experts that such models could be exploited by threat actors to generate sophisticated metamorphic malware. This paper explores the potential of several prominent LLMs for software code mutation that may be used to reconstruct (with mutation) existing malware code bases or create new forms of embedded mutation engines for next-gen metamorphic malwares. In this work, we introduce a framework for creating self-testing program mutation engines based on LLM/Transformer-based models. The proposed framework serves as an essential tool in testing next-gen metamorphic malware detection engines.	[Madani, Pooria] Ontario Tech Univ, Business & Informat Technol, Oshawa, ON, Canada		Madani, P (corresponding author), Ontario Tech Univ, Business & Informat Technol, Oshawa, ON, Canada.	p.madani@ieee.org						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Allal LB, 2023, Arxiv, DOI [arXiv:2301.03988, 10.48550/arXiv.2301.03988]; Brown TB., 2020, ADV NEURAL INF PROCE, V2020; Chen M., 2021, arXiv; Constable R. L., 2006, On the Computational Complexity of Program Scheme Equivalence, V9, P396, DOI [10.1137/0209031, DOI 10.1137/0209031]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eddy SR, 2004, NAT BIOTECHNOL, V22, P1315, DOI 10.1038/nbt1004-1315; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Gunasekar S, 2023, Arxiv, DOI arXiv:2306.11644; huggingface, codeparrot/codeparrot Hugging Face; Kulal S, 2019, ADV NEUR IN, V32; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Luo ZY, 2023, Arxiv, DOI [arXiv:2306.08568, 10.48550/arXiv.2306.08568, DOI 10.48550/ARXIV.2306.08568]; Mikolov T, 2011, INT CONF ACOUST SPEE, P5528; Newsome J, 2005, P IEEE S SECUR PRIV, P226, DOI 10.1109/SP.2005.15; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Openai A. R., IMPROVING LANGUAGE U; Papineni K, Bleu: a method for automatic evaluation of machine translation; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Roziere B., 2020, Adv Neural Inf Process Syst, V2020; Sun C., Finding Compiler Bugs via Live Code Mutation, DOI [10.1145/2983990.2984038, DOI 10.1145/2983990.2984038]; Theis L., 2015, 4 INT C LEARN REPR I, P1; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922; You I., 2010, P 2010 INT C BROADB, P297, DOI [10.1109/BWCCA.2010.85, DOI 10.1109/BWCCA.2010.85]; Zan D., 2022, P 31 INT JOINT C ART, P2369; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	30	0	0	2	2	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2385-6				2023							74	81		10.1109/TPS-ISA58951.2023.00019	http://dx.doi.org/10.1109/TPS-ISA58951.2023.00019			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6HT					2024-07-03	WOS:001174354000009
J	Jahan, I; Laskar, MTR; Peng, C; Huang, JX				Jahan, Israt; Laskar, Md Tahmid Rahman; Peng, Chun; Huang, Jimmy Xiangji			A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Large language models; ChatGPT; PaLM; LLaMA; Claude; Transformer; Natural language processing; LLM evaluation	DISEASE; CORPUS	Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero -shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre -training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.	[Jahan, Israt; Peng, Chun] York Univ, Dept Biol, Toronto, ON, Canada; [Laskar, Md Tahmid Rahman; Huang, Jimmy Xiangji] York Univ, Sch Informat Technol, Toronto, ON, Canada; [Jahan, Israt; Laskar, Md Tahmid Rahman; Huang, Jimmy Xiangji] York Univ, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada; [Laskar, Md Tahmid Rahman] Dialpad Inc, Vancouver, BC, Canada; [Huang, Jimmy Xiangji] York Univ, 3048 Victor Phillip Dahdaleh Bldg DB, Toronto, ON, Canada	York University - Canada; York University - Canada; York University - Canada; York University - Canada	Huang, JX (corresponding author), York Univ, 3048 Victor Phillip Dahdaleh Bldg DB, Toronto, ON, Canada.	israt18@yorku.ca; tahmid20@yorku.ca; cpeng@yorku.ca; jhuang@yorku.ca		Huang, Jimmy Xiangji/0000-0003-1292-1491	Natural Sciences and Engineering Research Council (NSERC) of Canada [RGPIN-2020-07157]; York Research Chairs (YRC) program; Generic research fund of York University, Canada	Natural Sciences and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)); York Research Chairs (YRC) program; Generic research fund of York University, Canada	We would like to thank the handling editor and all the five reviewers for their excellent review comments. This research is supported by the research grant (RGPIN-2020-07157) from the Natural Sciences and Engineering Research Council (NSERC) of Canada, the York Research Chairs (YRC) program, and the generic research fund of York University, Canada. We also acknowledge Compute Canada for providing us with the computing resources to conduct experiments, as well as Anthropic for providing us early access to the Claude-2 API.	Ali MM, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104672; Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2023, 22 WORKSH BIOM NAT L, P629; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baker S, 2016, BIOINFORMATICS, V32, P432, DOI 10.1093/bioinformatics/btv585; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Basaldella M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3122; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Ben A.A., 2021, P 20 WORKSHOP BIOMED, P74; Ben Abacha A, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P370; Ben Abacha A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2228; Chen Chao-Yi, 2023, 22 WORKSH BIOM NAT L, P586; Chen QY, 2021, NUCLEIC ACIDS RES, V49, pD1534, DOI 10.1093/nar/gkaa952; Chen RB, 2023, Arxiv, DOI arXiv:2310.18498; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung H., 2022, arXiv; Cohen AM, 2005, BRIEF BIOINFORM, V6, P57, DOI 10.1093/bib/6.1.57; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006; El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679; Gerner M, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-85; Goldsack Tomas, 2023, 22 WORKSH BIOM NAT L, P468; Goldsack Tomas, 2022, P 2022 C EMP METH NA, P10589; Gu Y., 2020, arXiv; Gutierrez Bernal Jimenez, 2020, FINDINGS ASS COMPUTA, P3715; He Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4604; Herrero-Zazo M, 2013, J BIOMED INFORM, V46, P914, DOI 10.1016/j.jbi.2013.07.011; Hou YT, 2022, BIOINFORMATICS, V38, P5100, DOI 10.1093/bioinformatics/btac648; Huang J.X., 2023, 22 WORKSH BIOM NAT L, P326, DOI DOI 10.18653/V1/2023.BIONLP-1.30; Huang XJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P307, DOI 10.1145/1571941.1571995; Ji SX, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104998; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Jin Q, 2019, arXiv; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; Kalyan KS, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103982; Kanakarajan KR., 2021, P 20 WORKSH BIOM LAN, P143, DOI [DOI 10.18653/V1/2021.BIONLP-1.16, 10.18653/v1, DOI 10.18653/V1]; Khalid N, 2023, COMPUT BIOL MED, V158, DOI 10.1016/j.compbiomed.2023.106848; Kim Jin-Dong, 2004, P INT JOINT WORKSHOP, P70; Krallinger M, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/1758-2946-7-S1-S2; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Laskar M. T. R., 2023, FINDINGS ASS COMPUTA, P431, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.29; Laskar MTR, 2022, COMPUT LINGUIST, V48, P279, DOI 10.1162/coli_a_00434; Laskar MTR, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3363, DOI 10.1145/3477495.3536322; Laskar MTR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5505; Laskar Md Tahmid Rahman, 2023, P 2023 C EMP METH NA, P343; Laskar TR, 2022, 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2022, P344; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li CM, 2023, Arxiv, DOI arXiv:2312.16337; Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Y., 2019, CoRR abs/1907.11692; Liu ZS, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107268; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Luo Zheheng, 2022, FINDINGS ASS COMPUTA, P4667; Martinelli DD, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105403; Monteiro NRC, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107285; Moor M., 2023, MACHINE LEARNING HLT, P353; Morid MA, 2021, COMPUT BIOL MED, V128, DOI 10.1016/j.compbiomed.2020.104115; Mrini K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1505; O'Brien J, 2018, FRONT ENDOCRINOL, V9, DOI 10.3389/fendo.2018.00402; OpenAI, 2023, : GPT-4 technical report.; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pafilis E, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0065390; Pandiyan S, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106140; Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58; Phan Long, 2023, P 17 C EUR CHAPT ASS, P3123; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Savery M, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00667-z; Shah SMA, 2021, COMPUT BIOL MED, V131, DOI 10.1016/j.compbiomed.2021.104259; Shaker B, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104851; Singhal Karan, 2023, Nature, P1; Smith L, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-S2-S2; Soleymani S, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105057; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Voorhees E.M., 2005, NIST Special Publication; Nguyen VHL, 2019, J OVARIAN RES, V12, DOI 10.1186/s13048-019-0596-z; Wang B., 2021, ACM Comput. Surv.; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Xiao W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5245; Yadav Vikas, 2018, Proceedings of the 27th International Conference on Computational Linguistics, P2145; Yang XJ, 2023, Arxiv, DOI arXiv:2302.08081; Ye Junjie, 2023, arXiv; Yin XS, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P901; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan HY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4038; Yuan HY, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P97; Zeng GT, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9241; Zhang S, 2024, Arxiv, DOI [arXiv:2303.00915, DOI 10.48550/ARXIV.2303.00915]; Zhang T., 2019, INT C LEARNING REPRE; Zhang XM, 2023, Arxiv, DOI arXiv:2305.10415; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P50	104	2	2	14	14	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	MAR	2024	171								108189	10.1016/j.compbiomed.2024.108189	http://dx.doi.org/10.1016/j.compbiomed.2024.108189		MAR 2024	23	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	NX7B9	38447502	hybrid, Green Submitted			2024-07-03	WOS:001203807100001
C	Seo, J; Zhang, N; Rong, C			IEEE Comp Soc	Seo, Jungwon; Zhang, Nan; Rong, Chunming			Flexible and Secure Code Deployment in Federated Learning using Large Language Models: Prompt Engineering to Enhance Malicious Code Detection	2023 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY AND SCIENCE, CLOUDCOM 2023	International Conference on Cloud Computing Technology and Science		English	Proceedings Paper	14th IEEE International Conference on Cloud Computing Technology and Science (CloudCom)	DEC 04-06, 2023	Naples, ITALY	IEEE		Software Engineering; Federated Learning; Large Language Models; Security		Federated Learning is a machine learning methodology that emphasizes data privacy, involving minimal interaction with each other's systems, primarily exchanging model parameters. However, this approach can introduce challenges in system development and operation because it inherently faces statistical and system heterogeneity issues. The diverse data storage formats and system environments across clients limit the feasibility of training with a uniform code. To distribute a new code to each environment, active participation of Federated Learning collaborators is necessary, incurring time and cost. Moreover, it impedes adopting modern automated development and deployment paradigms such as DevOps or MLOps. This study investigates how Large Language Models (LLMs) can automatically tailor a single code to individual client environments in heterogeneous scenarios without human intervention. Moreover, to enable the automatic adaptation of the deployed code for conducting new experiments within the system, it is imperative to assess the presence of potentially malicious code that could jeopardize data security. To address this challenge, we introduce a novel prompt engineering technique to enhance LLMs' detection capabilities, thereby bolstering our ability to detect malicious code effectively.	[Seo, Jungwon; Zhang, Nan; Rong, Chunming] Univ Stavanger, Stavanger, Norway	Universitetet i Stavanger	Seo, J (corresponding author), Univ Stavanger, Stavanger, Norway.	jungwon.seo@uis.no; nan.zhang@uis.no; chunming.rong@uis.no			Research Council of Norway [331644]	Research Council of Norway(Research Council of Norway)	This work is funded by NCS2030, RCN#331644, a national research center financed by the Research Council of Norway, the industry sponsors, and the academic partners.	Chan Aaron, 2023, ARXIV230601754; [陈全润 Chen Quanrun], 2022, [中国管理科学, Chinese Journal of Management Science], V30, P12; Chen Y., 2020, Federated Learning: Privacy and Incentive, P108; Chen Yizheng, 2023, ARXIV230400409; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ebert C, 2016, IEEE SOFTWARE, V33, P94, DOI 10.1109/MS.2016.68; Friedman N., 2021, Introducing github copilot: your ai pair programmer; Garg Siddharth, 2023, ARXIV220809727; Greshake Kai, 2023, ARXIV230212173; Hard Andrew, 2018, ARXIV181103604; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou Xinyi, 2023, ARXIV230810620; Huang Chao, 2022, ARXIV220612949; Jana Prithwish, 2023, ARXIV230606755; Karimireddy S. P., 2021, P ADV NEUR INF PROC, V34, P28663; Li Zonghang, 2020, IEEE TSC, V15, P2261; Liu Yi, 2023, ARXIV230513860; Lo SK, 2022, J SYST SOFTWARE, V191, DOI 10.1016/j.jss.2022.111357; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Radford A., 2018, IMPROVING LANGUAGE U; Rong CM, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00285-7; Rozi`ere Baptiste, 2023, ARXIV230812950; Sandoval Gustavo, 2022, ARXIV220809727; Sculley D, 2015, ADV NEUR IN, V28; Shingi G, 2020, INT CONF DAT MIN WOR, P362, DOI 10.1109/ICDMW51313.2020.00057; Sobolev Boris, 2023, ARXIV230803109; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; Touvron Hugo, 2023, ARXIV230709288; Vaswani A, 2017, ADV NEUR IN, V30; Xu CH, 2023, COMPUT SCI REV, V50, DOI 10.1016/j.cosrev.2023.100595; Yang CX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P935, DOI 10.1145/3442381.3449851; Zhu HY, 2021, NEUROCOMPUTING, V465, P371, DOI 10.1016/j.neucom.2021.07.098	34	0	0	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2330-2194		979-8-3503-3982-6	INT CONF CLOUD COMP			2023							341	349		10.1109/CloudCom59040.2023.00062	http://dx.doi.org/10.1109/CloudCom59040.2023.00062			9	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7SQ					2024-07-03	WOS:001195989900048
J	Cox, E; Shirani, F; Rouse, P				Cox, Emily; Shirani, Fiona; Rouse, Paul			Voices from the algorithm: Large language models in social research	ENERGY RESEARCH & SOCIAL SCIENCE			English	Article						ChatGPT; Artificial intelligence; Deliberative methods; Novel technologies; Public perceptions	INTERVIEWS	Research on energy and society often relies on online data collection. In particular, there has been an increase in the use of online techniques such as video software for qualitative research since the pandemic. We suggest that the rapid growth in generative AI and Large Language Models such as Chat-GPT mean that they may be utilised by research participants; particularly in research where participants may be less knowledgeable about the topic under discussion, such as emerging energy technologies. Drawing on examples from recent research, we argue that social scientists need to be cautious in assuming that the voices of our participants are genuinely theirs.	[Cox, Emily] Univ Oxford, Smith Sch Enterprise & Environm, Sch Geog & Environm, Oxford, England; [Cox, Emily] Cardiff Univ, Dept Psychol, Understanding Risk Grp, Cardiff, Wales; [Shirani, Fiona] Cardiff Univ, Sch Social Sci, Cardiff, Wales; [Rouse, Paul] Imperial Coll London, Grantham Inst Climate Change & Environm, London, England; [Rouse, Paul] CO2RE Greenhouse Gas Removal Hub, Oxford, England	University of Oxford; Cardiff University; Cardiff University; Imperial College London	Cox, E (corresponding author), Univ Oxford, Smith Sch Enterprise & Environm, Sch Geog & Environm, Oxford, England.	Emily.cox@smithschool.ox.ac.uk; fionashirani@cardiff.ac.uk; p.rouse@imperial.ac.uk		Cox, Emily/0000-0002-8169-3691	Research Council (NERC) [NE/V013106/1]; Leverhulme Trust [RC-2015-029]; Engineering and Physical Sciences Research Council NEUPA project [EP/T023031/1]	Research Council (NERC); Leverhulme Trust(Leverhulme Trust); Engineering and Physical Sciences Research Council NEUPA project(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	Research Council (NERC) , grant code NE/V013106/1, which additionally funded EC and PR. Additional funding for EC came from the Leverhulme Trust, grant no. RC-2015-029. FS time was supported by the Engineering and Physical Sciences Research Council NEUPA project [EP/T023031/1] .	Ashby C., 2011, DISABILITY STUDIES Q, V31; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bampton R., 2013, ADV RES METHODS NEW, P329, DOI DOI 10.4018/978-1-4666-3918-8.CH019; Boyko J, 2023, Arxiv, DOI arXiv:2311.04929; Cherry C, 2022, ENERGY RES SOC SCI, V87, DOI 10.1016/j.erss.2021.102455; De Man J, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-043866; Deakin H, 2014, QUAL RES, V14, P603, DOI 10.1177/1468794113488126; Dengel A, 2023, INFORMATICS-BASEL, V10, DOI 10.3390/informatics10040078; Duarte F., 2023, Exploding TopicsDec; Fell M.J., 2024, SSRN Scholarly Paper at, DOI [10.2139/ssrn.4686345, DOI 10.2139/SSRN.4686345]; Flick U., 2018, DESIGNING QUALITATIV; Gregg M, 2024, ENERGY RES SOC SCI, V108, DOI 10.1016/j.erss.2023.103397; Hadi M.U., 2023, PREPRINT, DOI [10.36227/techrxiv.23589741.v1, DOI 10.36227/TECHRXIV.23589741.V1]; Howlett M, 2022, QUAL RES, V22, P387, DOI 10.1177/1468794120985691; Jansen B. J., 2023, Natural Language Processing Journal, V4; Kara H., 2020, Impact of Social Sciences; OpenAI, 2024, ChatGPT; Prillaman McKenzie, 2023, Nature, DOI 10.1038/d41586-023-03479-4; Rattle I, 2020, ENERGY RES SOC SCI, V64, DOI 10.1016/j.erss.2020.101427; Reeves Stuart, 2022, The SAGE Handbook of Digital Society.; Reid L, 2017, ENERGY RES SOC SCI, V34, P191, DOI 10.1016/j.erss.2017.07.010; Roelich K, 2020, LOCAL ENVIRON, V25, P872, DOI 10.1080/13549839.2020.1845131; Smith SM, 2023, The state of carbon dioxide removal, V1st, DOI [10.17605/OSF.IO/W3B4Z, DOI 10.17605/OSF.IO/W3B4Z]; Sood E, 2021, J PEDIATR PSYCHOL, V46, P189, DOI 10.1093/jpepsy/jsaa096; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Weller S, 2017, INT J SOC RES METHOD, V20, P613, DOI 10.1080/13645579.2016.1269505; Willis R, 2023, QUAL RES, V23, P921, DOI 10.1177/14687941211063483; Zoom, 2023, Meet zoom AI companion, your new AI assistant! Unlock the benefits with a paid zoom account	28	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2214-6296	2214-6326		ENERGY RES SOC SCI	Energy Res. Soc. Sci.	JUL	2024	113								103559	10.1016/j.erss.2024.103559	http://dx.doi.org/10.1016/j.erss.2024.103559			3	Environmental Studies	Social Science Citation Index (SSCI)	Environmental Sciences & Ecology	SE4R2		hybrid			2024-07-03	WOS:001232773300001
J	Burtch, G; Lee, D; Chen, ZC				Burtch, Gordon; Lee, Dokyun; Chen, Zhichen			Generative AI Degrades Online Communities	COMMUNICATIONS OF THE ACM			English	Editorial Material								How large language models are influencing online communities.	[Burtch, Gordon] Boston Univ, Digital Business Inst, Questrom Sch Business, Boston, MA 02215 USA; [Lee, Dokyun; Chen, Zhichen] Boston Univ, Questrom Sch Business, Boston, MA USA	Boston University; Boston University	Burtch, G (corresponding author), Boston Univ, Digital Business Inst, Questrom Sch Business, Boston, MA 02215 USA.	gburtch@bu.edu; dokyun@bu.edu; zhichenc@bu.edu						Antelmi A, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P1218, DOI 10.1145/3543873.3587673; Burtch G, 2022, MANAGE SCI, V68, P3488, DOI 10.1287/mnsc.2021.4040; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Faraj S, 2016, INFORM SYST RES, V27, P668, DOI 10.1287/isre.2016.0682; Hwang EH, 2015, ORGAN SCI, V26, P1593, DOI 10.1287/orsc.2015.1009; Katz JE, 2002, SOCIAL CONSEQUENCES; Kraut RE, 2011, BUILDING SUCCESSFUL ONLINE COMMUNITIES: EVIDENCE-BASED SOCIAL DESIGN, P1; Ren YQ, 2007, ORGAN STUD, V28, P377, DOI 10.1177/0170840607076007; Sarkar S, 2020, INFORM SYST RES, V31, P1240, DOI 10.1287/isre.2020.0941; Sengupta Subhasree, 2020, CSCW '20: 23rd Conference on Computer-Supported Cooperative Work and Social Computing, P389, DOI 10.1145/3406865.3418319; Serenko A, 2016, J KNOWL MANAG, V20, P1199, DOI 10.1108/JKM-05-2016-0203; Shumailov I, 2024, Arxiv, DOI [arXiv:2305.17493, DOI 10.48550/ARXIV.2305.17493]	12	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0001-0782	1557-7317		COMMUN ACM	Commun. ACM	MAR	2024	67	3					40	42		10.1145/3624732	http://dx.doi.org/10.1145/3624732			3	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MK3P4		Bronze			2024-07-03	WOS:001193478900007
C	Muneeswaran, I; Shankar, A; Varun, V; Gopalakrishnan, S; Vaddina, V			Assoc computing machinery	Muneeswaran, I; Shankar, Advaith; Varun, V.; Gopalakrishnan, Saisubramaniam; Vaddina, Vishal			Mitigating Factual Inconsistency and Hallucination in Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Large Language Models; Hallucinations; Information Retrieval		Large Language Models (LLMs) have demonstrated remarkable capabilities in various language-related tasks enabling applications in various fields such as healthcare, education, financial services etc. However, they are prone to producing factually incorrect responses or "hallucinations" which can have detrimental consequences such as loss of credibility, diminished customer trust etc. In this presentation, we showcase a solution that addresses the challenge of minimizing hallucinations. Our solution provides accurate responses and generates detailed explanations, thereby enabling the users to know how the model arrived at the final response. Additionally, it verifies if the explanations are factually correct and offers insights into whether the generated explanations are directly derived from the provided context or if they are inferred from it. We also systematically assess the quality of generated responses using an LLM-based evaluation technique. We present empirical results on benchmark datasets to demonstrate the effectiveness of our approach. Our presentation also examines the impact of individual components in the solution, enhancing the factual correctness of the final response. This research is vital for industries utilizing LLMs, as it provides a means to enhance the reliability of responses and mitigate the risks associated with factual hallucinations. Researchers and practitioners seeking to enhance the reliability of LLM responses will find valuable insights in this presentation.	[Muneeswaran, I; Shankar, Advaith; Varun, V.; Gopalakrishnan, Saisubramaniam] Quantiphi Analyt Solut Pvt Ltd, Mumbai, Maharashtra, India; [Vaddina, Vishal] Quantiphi Inc, Toronto, ON, Canada		Gopalakrishnan, S (corresponding author), Quantiphi Analyt Solut Pvt Ltd, Mumbai, Maharashtra, India.; Vaddina, V (corresponding author), Quantiphi Inc, Toronto, ON, Canada.	muneeswaran.i@quantiphi.com; advaith.shankar@quantiphi.com; varun.v@quantiphi.com; gopalakrishnan.saisubramaniam@quantiphi.com; vishal.vaddina@quantiphi.com		I, Muneeswaran/0009-0002-0206-0077				Fan AEL, 2019, Arxiv, DOI arXiv:1907.09190; Jin Q, 2019, arXiv; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Muneeswaran I, 2023, Arxiv, DOI arXiv:2311.13878; Yang ZL, 2018, Arxiv, DOI arXiv:1809.09600; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219	6	0	0	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1169	1170		10.1145/3616855.3635744	http://dx.doi.org/10.1145/3616855.3635744			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100152
J	Xu, RX; Sun, YF; Ren, MJ; Guo, SG; Pan, RT; Lin, HY; Sun, L; Han, XP				Xu, Ruoxi; Sun, Yingfei; Ren, Mengjie; Guo, Shiguang; Pan, Ruotong; Lin, Hongyu; Sun, Le; Han, Xianpei			AI for social science and social science of AI: A survey	INFORMATION PROCESSING & MANAGEMENT			English	Article						Social science; Large language models; AI simulation	CHATGPT	Recent advancements in artificial intelligence, particularly with the emergence of large language models (LLMs), have sparked a rethinking of artificial general intelligence possibilities. The increasing human-like capabilities of AI are also attracting attention in social science research, leading to various studies exploring the combination of these two fields. In this survey, we systematically categorize previous explorations in the combination of AI and social science into two directions that share common technical approaches but differ in their research objectives. The first direction is focused on AI for social science, where AI is utilized as a powerful tool to enhance various stages of social science research. While the second direction is the social science of AI, which examines AI agents as social entities with their human-like cognitive and linguistic capabilities. By conducting a thorough review, particularly on the substantial progress facilitated by recent advancements in large language models, this paper introduces a fresh perspective to reassess the relationship between AI and social science, provides a cohesive framework that allows researchers to understand the distinctions and connections between AI for social science and social science of AI, and also summarizes state-of-art experiment simulation platforms to facilitate research in these two directions. We believe that with the ongoing advancement of AI technology and the increasing integration of intelligent agents into our daily lives, the significance of the combination of AI and social science will become even more prominent.	[Xu, Ruoxi; Sun, Yingfei] Univ Chinese Acad Sci, Sch Elect Elect & Commun Engn, Beijing, Peoples R China; [Xu, Ruoxi; Ren, Mengjie; Guo, Shiguang; Pan, Ruotong; Lin, Hongyu; Sun, Le; Han, Xianpei] Chinese Acad Sci, Chinese Informat Proc Lab, Inst Software, Beijing, Peoples R China; [Sun, Le; Han, Xianpei] Chinese Acad Sci, State Key Lab Comp Sci, Inst Software, Beijing, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; Institute of Software, CAS	Lin, HY (corresponding author), Chinese Acad Sci, Chinese Informat Proc Lab, Inst Software, Beijing, Peoples R China.	ruoxi2021@iscas.ac.cn; hongyu@iscas.ac.cn		Han, Xianpei/0000-0002-1304-6302	National Natural Science Foundation of China [62122077, 62106251, 62306303]; CCF-BaiChuan-Ebtech Foundation Model Fund	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCF-BaiChuan-Ebtech Foundation Model Fund	We sincerely thank all reviewers for their insightful comments and valuable suggestions. This research work is supported by the National Natural Science Foundation of China under Grants no. 62122077, 62106251, 62306303. Xianpei Han is sponsored by CCF-BaiChuan-Ebtech Foundation Model Fund.	Abbas M., 2023, Uses and misuses of ChatGPT by academic community: An overview and guidelines; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aggarwal CharuC., 2012, MINING TEXT DATA, DOI 10.1007/978-1-4614-3223-4_6; Aher GV, 2023, INT C MACHINE LEARNI, P337; Al Amin A, 2022, Arxiv, DOI [arXiv:2206.11993, 10.48550/arXiv.2206.11993, DOI 10.48550/ARXIV.2206.11993]; Alvarado J. C. S., 2015, P AUSTRALASIAN LANGU, P84; Andreas J, 2022, FINDINGS ASS COMPUTA, P5769; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Ashton MC, 2009, J PERS ASSESS, V91, P340, DOI 10.1080/00223890902935878; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Backhouse R., 2002, PENGUIN HIST EC; Bail C. A., 2023, SocArXiv; Banker S., 2023, arXiv; Barro R.J., 1997, MACROECONOMICS, V5th; Besanko D., 2020, Microeconomics; Bhattacherjee A., 2012, Social science research: Principles, methods, and practices, V2nd; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Bisbee J., 2023, arXiv; Black Sid, 2021, Zenodo; Bojic L., 2023, Signs of consciousness in ai: can Gpt-3 tell how smart it really is?, DOI [10.2139/ssrn.4399438, DOI 10.2139/SSRN.4399438]; Bommarito J., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2301.04408, 10.48550/arXiv.2301.04408]; Brand J., 2023, Harvard Business School Marketing Unit Working Paper No. 23-062, DOI DOI 10.2139/SSRN.4395751; Bryman A., 2016, Social Research Methods; Bybee JL, 2023, Arxiv, DOI [arXiv:2305.02823, DOI 10.48550/ARXIV.2305.02823, 10.48550/arXiv.2305.02823]; Cai ZG, 2024, Arxiv, DOI arXiv:2303.08014; Castillo-Eslava F, 2023, Arxiv, DOI [arXiv:2304.06030, 10.48550/arXiv.2304.06030, DOI 10.48550/ARXIV.2304.06030]; Chakrabarty T., 2022, C EMP METH NAT LANG; Chen C., 2023, Press Circles; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Chen Y., 2023, A manager and an AI walk into a bar: Does ChatGPT make biased decisions like we do?, DOI DOI 10.2139/SSRN.4380365; Chen Z., 2022, P 2022 C EMPIRICAL M, P6279; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chu E, 2023, Arxiv, DOI arXiv:2303.16779; Collins KM, 2022, Arxiv, DOI [arXiv:2205.05718, 10.48550/arXiv.2205.05718]; Coppersmith G., 2015, P 2 WORKSHOP COMPUTA, P31, DOI [DOI 10.3115/V1/W15-1204, 10.3115/v1/w15-1204, 10.3115/v1/W15-1204]; Cribben I., 2023, Operations Management and Data Analytics; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Danling P., 2019, General psychology, V5th; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Diamond J, 2023, Arxiv, DOI [arXiv:2304.12191, 10.48550/arXiv.2304.12191, DOI 10.48550/ARXIV.2304.12191]; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Donovan T., 2013, The elements of social scientific thinking; Dou Z, 2023, Exploring GPT-3 model's capability in passing the sally-anne test a preliminary study in two languages, DOI [10.31219/osf.io/8r3ma, DOI 10.31219/OSF.IO/8R3MA]; ElSherief M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P345; Evans J, 2010, SCIENCE, V329, P399, DOI 10.1126/science.1189416; Farmer A. K., 2010, A linguistics workbook: companion to linguistics, Vsixth; Feng SB, 2023, Arxiv, DOI [arXiv:2305.08283, 10.48550/arXiv.2305.08283]; Feng XR, 2023, bioRxiv, DOI [10.1101/2023.03.20.533336, 10.1101/2023.03.20.533336, DOI 10.1101/2023.03.20.533336]; Fischer R, 2023, Arxiv, DOI [arXiv:2304.03612, DOI 10.48550/ARXIV.2304.03612, 10.48550/arXiv.2304.03612]; Frackiewicz M., 2023, How ChatGPT is transforming the landscape of social network analysis and community building.; Frank MR, 2019, NAT MACH INTELL, V1, P79, DOI 10.1038/s42256-019-0024-5; Fu Y, 2023, Arxiv, DOI arXiv:2305.10142; Gabriel S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3108; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Giddens A., 2007, INTRO SOCIOLOGY; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Goertzel Ben, 2014, Journal of Artificial General Intelligence, V5, P1, DOI 10.2478/jagi-2014-0001; Goli A., 2023, Time preferences, and consumer behavior: evidence from large language models; Gover L, 2023, The Commons: Puget Sound Journal of Politics, V4, P2; Griffin LD, 2023, Arxiv, DOI [arXiv:2303.06074, 10.48550/arXiv.2303.06074]; Gu H., 2023, SSRN Electronic Journal, DOI [10.2139/ssrn.4444763, DOI 10.2139/SSRN.4444763]; Guo FL, 2023, Arxiv, DOI [arXiv:2305.05516, 10.48550/arXiv.2305.05516]; Hagendorff T, 2023, Arxiv, DOI [arXiv:2303.13988, 10.48550/arXiv.2303.13988, DOI 10.48550/ARXIV.2303.13988]; Hagendorff T, 2023, Arxiv, DOI [arXiv:2212.05206, 10.48550/arXiv.2212.05206, DOI 10.48550/ARXIV.2212.05206]; Halliday M.A. K., 2006, On language and linguistics; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Han S. J., 2022, P ANN M COGN SCI SOC, V44; Hartmann J, 2023, Arxiv, DOI [arXiv:2301.01768, 10.48550/ARXIV.2301.01768, DOI 10.48550/ARXIV.2301.01768]; Hoes E., 2023, arXiv; Horton JJ., 2023, LARGE LANGUAGE MODEL; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P90, DOI 10.1145/3543873.3587320; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Irving G, 2018, Arxiv, DOI arXiv:1805.00899; Iyyer M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1113; Jaccard J., 2010, Theory construction and model-building skills: A practical guide for social scientists; Jha K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P843, DOI 10.1145/3292500.3330977; Jiang GY, 2023, Arxiv, DOI [arXiv:2206.07550, 10.48550/arXiv.2206.07550]; Jiang H., 2022, P 29 INT C COMPUTATI, P6818; Jiang H, 2024, Arxiv, DOI [arXiv:2305.02547, 10.48550/arXiv.2305.02547]; Jin Z., 2022, Advances in Neural Information Processing Systems, P28458; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Johnson T, 2023, Arxiv, DOI [arXiv:2301.02330, 10.48550/arXiv.2301.02330, DOI 10.48550/ARXIV.2301.02330]; Jones E., 2022, Advances in Neural Information Processing Systems, V35, P11785; Joyce K, 2021, SOCIUS, V7, DOI 10.1177/2378023121999581; Jungwirth D., 2023, PREPRINT; Juren Lin Y. L, 2017, Social science research methods; Kalinin K., 2023, Predictioneer's game and GPT-3; Karra SR, 2023, Arxiv, DOI [arXiv:2204.12000, 10.48550/arXiv.2204.12000]; Kieval HJ, 1997, MOD JUDAISM, V17, P1; King M., 2023, Engineering Archive, DOI [10.31224/2974, DOI 10.31224/2974]; Kjell O., 2023, arXiv; Kjell ONE, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07520-w; Klein HK, 2002, SCI TECHNOL HUM VAL, V27, P28, DOI 10.1177/016224390202700102; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kosoy E, 2022, Arxiv, DOI [arXiv:2206.08353, 10.48550/arXiv.2206.08353, DOI 10.48550/ARXIV.2206.08353]; Krenn M, 2020, P NATL ACAD SCI USA, V117, P1910, DOI 10.1073/pnas.1914370116; Krishna R, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2115730119; Krugman P., 2009, Economics; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Leippold M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2022.103617; Li CY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1866; Li XX, 2024, Arxiv, DOI [arXiv:2212.10529, DOI 10.48550/ARXIV.2212.10529, 10.48550/arXiv.2212.10529]; Liu RB, 2021, AAAI CONF ARTIF INTE, V35, P14857; Lopez-Lira A., 2023, SSRN Electronic Journal, DOI [10.2139/ssrn.4412788, DOI 10.2139/SSRN.4412788]; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Magid HM, 1955, ETHICS, V65, P201, DOI 10.1086/291002; Maia M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1941, DOI 10.1145/3184558.3192301; Malo P., 2013, Journal of the Association for Information Science and Technology, V65; Mauriello M. L., 2021, 2021 CHI C HUM FACT; McCorduck P., 2004, MACHINES WHO THINK P; McGee R. W, 2023, J Bus Ethics, V95, P165, DOI DOI 10.13140/RG.2.2.18784.97282; McGee R. W., 2023, Is ChatGPT biased against conservatives? An empirical study, DOI DOI 10.2139/SSRN.4359405; Mialon G., 2023, arXiv; Miotto M., 2022, P 5 WORKSHOP NATURAL, P218; Misra R, 2022, Politifact fact check dataset, DOI [10.13140/RG.2.2.29923.22566, DOI 10.13140/RG.2.2.29923.22566]; Mohammad S., 2016, P 10 INT WORKSH SEM, P31, DOI [DOI 10.18653/V1/S16-1003, 10.18653/v1/S16-1003]; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Niszczota P., 2023, Gpt as a financial advisor; OpenAI, 2023, How Should AI Systems Behave, and Who Should Decide?; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Park JS, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545616; Park YJ, 2023, Arxiv, DOI arXiv:2304.12208; Pellert M., 2022, PsyArXiv, DOI [10.31234/osf.io/jv5dt, DOI 10.31234/OSF.IO/JV5DT]; Phelps S, 2023, Arxiv, DOI [arXiv:2305.07970, 10.48550/arXiv.2305.07970, DOI 10.48550/ARXIV.2305.07970]; Pirina Inna, 2018, P 2018 EMNLP WORKSHO, P9; Pollin BurtonR., 1965, Comparative Literature, V17, P97; Prystawski B, 2022, Arxiv, DOI [arXiv:2209.08141, 10.48550/arXiv.2209.08141, DOI 10.48550/ARXIV.2209.08141]; Raffel C, 2020, J MACH LEARN RES, V21; Rao HC, 2023, Arxiv, DOI arXiv:2303.01248; Rathje S., 2023, PsyArXiv; Rivas P, 2023, AI-BASEL, V4, P375, DOI 10.3390/ai4020019; Rodríguez-Ibánez M, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119862; Rubin A., 1997, Research methods for social work, V3rd; Russell SJ., 2016, ARTIF INTELL; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Salehi P, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6020062; Santurkar S, 2023, Arxiv, DOI arXiv:2303.17548; Sap M., 2022, P 2022 C EMPIRICAL M, P3762, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.248; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Sifatkaur, 2023, Arxiv, DOI [arXiv:2303.11436, 10.48550/arXiv.2303.11436, DOI 10.48550/ARXIV.2303.11436]; Sinha Ankur, 2021, Advances in Information and Communication. Proceedings of the 2021 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1364), P589, DOI 10.1007/978-3-030-73103-8_41; Son G, 2023, Arxiv, DOI [arXiv:2305.01505, 10.48550/arXiv.2305.01505]; Soun Y., 2022, 2022 IEEE INT C BIG, P1691, DOI 10.1109/BigData55660.2022.10020720; Stevenson C, 2022, Arxiv, DOI [arXiv:2206.08932, 10.48550/arXiv.2206.08932, DOI 10.48550/ARXIV.2206.08932]; Tang L., 2023, P 61 ANN M ASS COMP, V1; Terwiesch C., 2023, A prediction based on its performance in the operations management course; Tiku N, 2023, Washington Post; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trochim W. M. K., 2001, RES METHODS KNOWLEDG; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Tu SQ, 2024, Arxiv, DOI [arXiv:2304.14106, 10.48550/arXiv.2304.14106]; Turcan E., 2019, C EMP METH NAT LANG; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Uludag K., 2023, ChatGPT can distinguish paranoid thoughts in patients with schizophrenia; van den Broek M., 2023, ChatGPT's left-leaning liberal bias; Wang L, 2024, Arxiv, DOI arXiv:2308.11432; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Wei JS, 2022, ADV NEUR IN; Willer David., 2007, Building Experiments: Testing Social Theory; Wilson S. J., 2018, bioRxiv, DOI [10.1101/403667, DOI 10.1101/403667]; Wood DA, 2023, ISS ACCOUNT EDUC, V38, P81, DOI 10.2308/ISSUES-2023-013; WOOLGAR S, 1985, SOCIOLOGY, V19, P557, DOI 10.1177/0038038585019004005; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wright JD, 2010, HANDBOOK OF SURVEY RESEARCH, 2ND EDITION, P3; Wu HZ, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1627, DOI 10.1145/3269206.3269290; Wu PY, 2023, Arxiv, DOI [arXiv:2303.12057, 10.48550/arXiv.2303.12057, DOI 10.48550/ARXIV.2303.12057]; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xie QQ, 2023, Arxiv, DOI arXiv:2306.05443; Xie QQ, 2023, Arxiv, DOI arXiv:2304.05351; Xu YM, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1970; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Yuan F, 2013, Tutorial on social research methods; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou WCS, 2023, Arxiv, DOI arXiv:2309.07870; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]; Zimbardo PG., 1971, STANFORD PRISON EXPT	185	1	1	94	94	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-4573	1873-5371		INFORM PROCESS MANAG	Inf. Process. Manage.	MAY	2024	61	3							103665	10.1016/j.ipm.2024.103665	http://dx.doi.org/10.1016/j.ipm.2024.103665		FEB 2024	25	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	KY1U5		Green Submitted			2024-07-03	WOS:001183443600001
J	Holland, M; Chaudhari, K				Holland, Maximilian; Chaudhari, Kunal			Large language model based agent for process planning of fiber composite structures	MANUFACTURING LETTERS			English	Article						Large language model; Generative AI; Planning agent; Process planning; Fiber composites; LangChain; OpenAI		Process planning is a crucial activity, connecting product development and manufacturing of fiber composite structures. Recently published Large Language Models (LLM) promise more flexible and autonomous workflows compared to state of the art automation methods. An autonomous agent for process planning of fiber composite structures is implemented with the LangChain framework, based on OpenAI's GPT-4 language model. The agent is equipped with deterministic tools which encode a-priori process planning knowledge. It can handle different process planning problems, such as cycle time estimation and resource allocation. Combinations thereof are solved through executing a multi-step solution path. (c) 2024 The Authors. Published by Elsevier Ltd on behalf of Society of Manufacturing Engineers (SME). This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	[Holland, Maximilian; Chaudhari, Kunal] Fraunhofer Inst Casting Composite & Proc Technol I, Am Technol Zentrum 2, D-86159 Augsburg, Germany		Holland, M (corresponding author), Fraunhofer Inst Casting Composite & Proc Technol I, Am Technol Zentrum 2, D-86159 Augsburg, Germany.	maximilian.holland@igcv.fraunhofer.de			Regierung von Schwaben, the Bavarian Ministry of Economic Affairs, Regional Development and Energy; Bavarian State Ministry of Sciences and the Arts, within the KI Produktionsnetzwerk Augsburg [RvS-SG20-3451-1/47/6]	Regierung von Schwaben, the Bavarian Ministry of Economic Affairs, Regional Development and Energy; Bavarian State Ministry of Sciences and the Arts, within the KI Produktionsnetzwerk Augsburg	We gratefully acknowledge the financial support received by the Regierung von Schwaben , the Bavarian Ministry of Economic Affairs, Regional Development and Energy, and by the Bavarian State Ministry of Sciences and the Arts, within the KI Produktionsnetzwerk Augsburg (RvS-SG20-3451-1/47/6) .	Al-wswasi M, 2018, INT J ADV MANUF TECH, V97, P809, DOI 10.1007/s00170-018-1966-1; Andreadis G, 2014, PROCEDIA ENGINEER, V69, P282, DOI 10.1016/j.proeng.2014.02.233; Brown N., 2023, C ROBOT LEARNING, P287; Coriolis Composites, Coriolis C1; ElMaraghy HA, 2016, CIRP Encyclopedia Prod Eng, DOI [10.1007/978-3-642-35950-7_6551-4, DOI 10.1007/978-3-642-35950-7_6551-4]; Feng SC, 2005, ADV ENG INFORM, V19, P135, DOI 10.1016/j.aei.2005.05.010; Giusti F., 1989, CIRP ANN-MANUF TECHN, V38/, P481, DOI DOI 10.1016/S0007-8506(07)62750-4; Gonnermann C, 2022, INT J ADV MANUF TECH, V122, P2645, DOI 10.1007/s00170-022-09931-5; Haffner SM, 2002, Cost modeling and design for manufacturing guidelines for advanced composite fabrication; Holland M, 2023, P SAMPE EUR C 2023 M; Jia HZ, 2004, ROBOT CIM-INT MANUF, V20, P79, DOI 10.1016/j.rcim.2003.08.001; Lang S, 2020, WINT SIMUL C PROC, P3057, DOI 10.1109/WSC48552.2020.9383997; LangChainAI, LangChain; Li XL, 2018, INT J ADV MANUF TECH, V96, P4173, DOI 10.1007/s00170-018-1862-8; Márquez CRH, 2022, INT T OPER RES, V29, P3237, DOI 10.1111/itor.13108; Nejad HTN, 2011, INT J PROD RES, V49, P1373, DOI 10.1080/00207543.2010.518741; Pravin Luthada, 2023, Automated fiber placement process: design cycle, benefits, and applications; Shen WM, 2006, IEEE T SYST MAN CY C, V36, P563, DOI 10.1109/TSMCC.2006.874022; Singh I, 2022, Arxiv, DOI arXiv:2209.11302; Tong A, 2023, Insight: Race towards 'autonomous' AI agents grips Silicon Valley; Zafirov R, 2014, Modellbasierte virtuelle Produktentwicklung	21	0	0	5	5	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2213-8463			MANUF LETT	Manuf. Lett.	JUL	2024	40						100	103		10.1016/j.mfglet.2024.03.010	http://dx.doi.org/10.1016/j.mfglet.2024.03.010			4	Engineering, Manufacturing; Materials Science, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Engineering; Materials Science	RE7B1					2024-07-03	WOS:001226046300001
J	Ghim, JL; Ahn, S				Ghim, Jong-Lyul; Ahn, Sangzin			Transforming clinical trials: the emerging roles of large language models	TRANSLATIONAL AND CLINICAL PHARMACOLOGY			English	Review						Clinical Trial; Natural Language Processing; Artificial Intelligence; Informed Consent; Medical Writing		Clinical trials are essential for medical research, but they often face challenges in matching patients to trials and planning. Large language models (LLMs) offer a promising solution, signaling a transformative shift in the field of clinical trials. This review explores the multifaceted applications of LLMs within clinical trials, focusing on five main areas expected to be implemented in the near future: enhancing patient-trial matching, streamlining clinical trial planning, analyzing free text narratives for coding and classification, assisting in technical writing tasks, and providing cognizant consent via LLM-powered chatbots. While the application of LLMs is promising, it poses challenges such as accuracy validation and legal concerns. The convergence of LLMs with clinical trials has the potential to revolutionize the efficiency of clinical trials, paving the way for innovative methodologies and enhancing patient engagement. However, this development requires careful consideration and investment to overcome potential hurdles.	[Ghim, Jong-Lyul] Inje Univ, Busan Paik Hosp, Dept Clin Pharmacol, Busan 47392, South Korea; [Ghim, Jong-Lyul; Ahn, Sangzin] Inje Univ, Coll Med, Ctr Personalized Precis Med TB, Busan 47392, South Korea; [Ahn, Sangzin] Inje Univ, Coll Med, Dept Pharmacol, Busan 47392, South Korea; [Ahn, Sangzin] Inje Univ, Coll Med, Pharmacogen Res Ctr, Busan 47392, South Korea; [Ahn, Sangzin] Inje Univ, Coll Med, Ctr Personalized Precis Med TB, Dept Pharmacol, 75 Bokji Ro, Busan 47392, South Korea; [Ahn, Sangzin] Inje Univ, Coll Med, Pharmacogen Res Ctr, Ctr Personalized Precis Med TB, 75 Bokji Ro, Busan 47392, South Korea	Inje University; Inje University; Inje University; Inje University; Inje University; Inje University	Ahn, S (corresponding author), Inje Univ, Coll Med, Ctr Personalized Precis Med TB, Dept Pharmacol, 75 Bokji Ro, Busan 47392, South Korea.; Ahn, S (corresponding author), Inje Univ, Coll Med, Pharmacogen Res Ctr, Ctr Personalized Precis Med TB, 75 Bokji Ro, Busan 47392, South Korea.	sangzinahn@inje.ac.kr	Ahn, Sangzin/E-8807-2016	Ahn, Sangzin/0000-0003-2749-0014	National Research Foundation of Korea (NRF) - Korean government (MSIT) [2018R1A5A2021242]	National Research Foundation of Korea (NRF) - Korean government (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of Korea)	Funding This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No. 2018R1A5A2021242) .	Ahn Sangzin, 2023, Korean J Med Educ, V35, P103, DOI 10.3946/kjme.2023.253; Atallah SB, 2023, TECH COLOPROCTOL, V27, P609, DOI 10.1007/s10151-023-02837-8; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Berendsen S, 2020, J AFFECT DISORDERS, V276, P748, DOI 10.1016/j.jad.2020.07.080; Chen WH, 2022, Arxiv, DOI arXiv:2210.06710; Cheung KS, 2024, J PROP INVEST FINANC, V42, P200, DOI 10.1108/JPIF-06-2023-0053; Circi R, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.858273; den Hamer DM, 2023, Arxiv, DOI arXiv:2304.07396; Djurisic S, 2017, TRIALS, V18, DOI 10.1186/s13063-017-2099-9; Doshi R, 2023, medRxiv, DOI [10.1101/2023.06.04.23290786.CROSSREF, DOI 10.1101/2023.06.04.23290786.CROSSREF]; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gray M, 2023, CHEM RES TOXICOL, V36, P1290, DOI 10.1021/acs.chemrestox.3c00028; Huang CW, 2022, Arxiv, DOI [arXiv:2207.05289, 10.48550/arXiv.2207.05289]; Idnay B, 2021, J AM MED INFORM ASSN, V29, P197, DOI 10.1093/jamia/ocab228; Jin Q, 2024, Arxiv, DOI [arXiv:2307.15051, DOI 10.48550/ARXIV.2307.15051.PUBMED|CROSSREF]; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Naseem U, 2021, 2021 INT JOINT C NEU, P1; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Sherlock A, 2014, ANZ J SURG, V84, P207, DOI 10.1111/ans.12555; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Tai RH, 2023, bioRxiv; Wang SY, 2022, J MED INTERNET RES, V24, DOI 10.2196/38859; Wang ZF, 2023, Arxiv, DOI [arXiv:2305.11366, 10.48550/arXiv.2305.11366.CROSSREF, DOI 10.48550/ARXIV.2305.11366.CROSSREF]; Wang ZF, 2023, Arxiv, DOI [arXiv:2304.05352, 10.48550/arXiv.2304.05352.CROSSREF, DOI 10.48550/ARXIV.2304.05352.CROSSREF]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; White RD, 2023, Arxiv, DOI [arXiv:2307.14522, 10.48550/arXiv.2307.14522.CROSSREF, DOI 10.48550/ARXIV.2307.14522.CROSSREF]; Woo M, 2019, NATURE, V573, pS100, DOI 10.1038/d41586-019-02871-3; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhong RQ, 2023, Arxiv, DOI arXiv:2302.14233	31	2	2	7	9	KSCPT	SEOUL	KPX Bld. 15F, mapodaero 137, mapo-gu, SEOUL, SOUTH KOREA	2289-0882	2383-5427		TRANSL CLIN PHARMACO	Transl. Clin. Pharmacol.	SEP	2023	31	3					131	138		10.12793/tcp.2023.31.e16	http://dx.doi.org/10.12793/tcp.2023.31.e16			8	Pharmacology & Pharmacy	Emerging Sources Citation Index (ESCI)	Pharmacology & Pharmacy	T7GY5	37810626	gold, Green Published			2024-07-03	WOS:001079640300002
J	Meyer, JG; Urbanowicz, RJ; Martin, PCN; O'Connor, K; Li, RW; Peng, PC; Bright, TJ; Tatonetti, N; Won, KJ; Gonzalez-Hernandez, G; Moore, JH				Meyer, Jesse G.; Urbanowicz, Ryan J.; Martin, Patrick C. N.; O'Connor, Karen; Li, Ruowang; Peng, Pei-Chen; Bright, Tiffani J.; Tatonetti, Nicholas; Won, Kyoung Jae; Gonzalez-Hernandez, Graciela; Moore, Jason H.			ChatGPT and large language models in academia: opportunities and challenges	BIODATA MINING			English	Editorial Material								The introduction of large language models (LLMs) that allow iterative "chat" in late 2022 is a paradigm shift that enables generation of text often indistinguishable from that written by humans. LLM-based chatbots have immense potential to improve academic work efficiency, but the ethical implications of their fair use and inherent bias must be considered. In this editorial, we discuss this technology from the academic's perspective with regard to its limitations and utility for academic writing, education, and programming. We end with our stance with regard to using LLMs and chatbots in academia, which is summarized as (1) we must find ways to effectively use them, (2) their use does not constitute plagiarism (although they may produce plagiarized text), (3) we must quantify their bias, (4) users must be cautious of their poor accuracy, and (5) the future is bright for their application to research and as an academic tool.	[Meyer, Jesse G.; Urbanowicz, Ryan J.; Martin, Patrick C. N.; Li, Ruowang; Peng, Pei-Chen; Bright, Tiffani J.; Tatonetti, Nicholas; Won, Kyoung Jae; Gonzalez-Hernandez, Graciela; Moore, Jason H.] Cedars Sinai Med Ctr, Dept Computat Biomed, Los Angeles, CA 90048 USA; [O'Connor, Karen] Univ Penn, Dept Biostat Epidemiol & Informat, Philadelphia, PA USA	Cedars Sinai Medical Center; University of Pennsylvania	Meyer, JG; Moore, JH (corresponding author), Cedars Sinai Med Ctr, Dept Computat Biomed, Los Angeles, CA 90048 USA.	jesse.meyer@cshs.org; jason.moore@csmc.edu	Meyer, Jesse/AAC-7591-2019; Martin, Patrick/JXN-0832-2024	Meyer, Jesse/0000-0003-2753-3926; Bright, Tiffani/0000-0002-0894-0107; Peng, Pei-Chen/0000-0002-5004-4322; Martin, Patrick/0000-0002-4093-8277; Urbanowicz, Ryan/0000-0002-0487-5555	NIGMS [R35GM142502]; NLM~ [R01LM011176]; NIA [U01 AG066833]	NIGMS(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); NLM~(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM)); NIA(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	JGM was supported by grant NIGMS R35GM142502. GGH and KO were supported by grant NLM & nbsp;R01LM011176. JHM was supported by grant NIA U01 AG066833.	[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Dijkstra R., 2022, Reading comprehension quiz generation using generative pre-trained transformers; Dodge J, 2022, Arxiv, DOI arXiv:2206.05229; Gijsberts CM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0132321; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gleason N., 2022, Times Higher Education; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim S., 2022, MEDIUM; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Moore S, 2022, LECT NOTES COMPUT SC, V13450, P243, DOI 10.1007/978-3-031-16290-9_18; National Science Foundation, 2020, FOR BORN STUD WORK U; Neeley T, 2022, HARVARD BUSINESS SCH, P422; Neumann M., 2023, "We need to talk about ChatGPT": The future of AI and higher education, DOI DOI 10.25968/OPUS-2467; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; OpenAI, 2022, CHATGPT COMP SOFTW; Park Y., 2022, Healthcare Information Management Systems: Cases, Strategies, and Solutions, P223, DOI DOI 10.1007/978-3-031-07912-2_15; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shidiq M., 2023, Proceeding of International Conference on Education Society and Humanity, V1, P353; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tate T., 2023, Educational research and AI-generated writing: Confronting the coming tsunami; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Trust T., 2023, Contemp Issues Technol Teach Educ, V23, P1; Vyas DA, 2020, NEW ENGL J MED, V383, P874, DOI 10.1056/NEJMms2004740	31	50	50	34	89	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1756-0381			BIODATA MIN	BioData Min.	JUL 13	2023	16	1							20	10.1186/s13040-023-00339-9	http://dx.doi.org/10.1186/s13040-023-00339-9			11	Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology	M4MK7	37443040	gold, Green Published			2024-07-03	WOS:001029961900001
C	Vörös, T; Bergeron, SP; Berlin, K			IEEE	Voros, Tamas; Bergeron, Sean Paul; Berlin, Konstantin			Web Content Filtering through knowledge distillation of Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT			English	Proceedings Paper	22nd IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	OCT 26-29, 2023	Venice, ITALY	Inst Elect & Elect Engineers, IEEE Comp Soc, Web Intelligence Consortium, Ca Foscari Univ Venice, IOS Press		web content filtering; machine learning; large language models		We introduce a state-of-the-art approach for URL categorization that leverages the power of Large Language Models (LLMs) to address the primary objectives of web content filtering: safeguarding organizations from legal and ethical risks, limiting access to high-risk or suspicious websites, and fostering a secure and professional work environment. Our method utilizes LLMs to generate accurate classifications and then employs established knowledge distillation techniques to create smaller, more specialized student models tailored for web content filtering. Distillation results in a student model with a 9% accuracy rate improvement in classifying websites, sourced from customer telemetry data collected by a large security vendor, into 30 distinct content categories based on their URLs, surpassing the current state-of-the-art approach. Our student model matches the performance of the teacher LLM with 175 times less parameters, allowing the model to be used for in-line scanning of large volumes of URLs, and requires 3 orders of magnitude less manually labeled training data than the current state-of-the-art approach. Depending on the specific use case, the output generated by our approach can either be directly returned or employed as a pre-filter for more resource-intensive operations involving website images or HTML.	[Voros, Tamas; Bergeron, Sean Paul] Sophos AI, Budapest, Hungary; [Berlin, Konstantin] Sophos AI, Washington, DC USA		Vörös, T (corresponding author), Sophos AI, Budapest, Hungary.	tamas.voros@sophos.com; sean.bergeron@sophos.com; konstantin.berlin@sophos.com						Ankur Baishya D. S. K., 2022, A review on web content filtering, its technique and prospects; Apruzzese G, 2022, Arxiv, DOI arXiv:2212.14315; Bhargava P., 2021, Generalization in nli: Ways (not) to go beyond simple heuristics; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Q, 2020, Arxiv, DOI arXiv:2005.11910; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Garcia F., 2009, Web content filtering. advances in computers; Haruta S, 2019, ASIA-PAC CONF COMMUN, P280, DOI [10.1109/apcc47188.2019.9026498, 10.1109/APCC47188.2019.9026498]; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Huang CY, 2010, TENCON IEEE REGION, P803, DOI 10.1109/TENCON.2010.5686582; Joulin A, 2016, Arxiv, DOI [arXiv:1612.03651, DOI 10.48550/ARXIV.1612.03651]; Le H, 2018, Arxiv, DOI arXiv:1802.03162; Ma J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1245; Maneriker P, 2021, IEEE MILIT COMMUN C, DOI 10.1109/MILCOM52596.2021.9653028; Raffel C, 2020, J MACH LEARN RES, V21; Saxe J, 2017, Arxiv, DOI arXiv:1702.08568; Sheng S., 2009, ROCEEDINGS 6 C EMAIL; siteefy, 2023, How many websites are there; Tajaddodianfar F, 2020, INT CONF ACOUST SPEE, P2857, DOI [10.1109/ICASSP40776.2020.9053670, 10.1109/icassp40776.2020.9053670]; Turc I, 2019, Arxiv, DOI arXiv:1908.08962; Vaswani A, 2017, ADV NEUR IN, V30; Zhang JJ, 2022, Arxiv, DOI [arXiv:2212.00850, DOI 10.48550/ARXIV.2212.00850]	22	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0918-8				2023							357	361		10.1109/WI-IAT59888.2023.00058	http://dx.doi.org/10.1109/WI-IAT59888.2023.00058			5	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3LB		Green Submitted			2024-07-03	WOS:001139644800051
C	Bopp, C; Foerst, A; Kellogg, B			Assoc Computing Machinery	Bopp, Chris; Foerst, Anne; Kellogg, Brian			The Case for LLMWorkshops: The Responsible Use of Large Language Models by Faculty at Small Liberal Arts Universities	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		large language models; liberal arts universities; workshops; pedagogy; philosophy; ethics		Large Language Models (LLMs) are radically changing the academic landscape. Many professors are unaware of how LLMs work and are therefore unsure how to incorporate them in their teaching. This is problematic as students will use them anyway. In this paper, we outline our institution as a case study for a curricular initiative. We develop an intellectual framework for creating workshops for faculty at small liberal arts universities. We base their development on the literature we have analyzed and discussed as a group. Our approach is to address our colleagues across a variety of different disciplines and teach them the responsible use of LLMs in the classroom. We also teach our colleagues how to modify assignments to make them, to some extent, LLM proof. This includes adding personalized elements, and including LLM designed parts explicitly, such as article summaries. We also design a syllabus policy about the responsible use of LLMs. We present philosophical and ethical challenges and teach a list of other actionable items. We ultimately support the use of LLMs in academia but seek to teach our colleagues how they can guide students to use them mindfully and responsibly.	[Bopp, Chris; Foerst, Anne] St Bonaventure Univ, Comp Sci, St Bonaventure, NY 14778 USA; [Kellogg, Brian] St Bonaventure Univ, Comp Sci & Cybersecur, St Bonaventure, NY 14778 USA		Bopp, C (corresponding author), St Bonaventure Univ, Comp Sci, St Bonaventure, NY 14778 USA.	cbopp@sbu.edu; afoerst@sbu.edu; bkellogg@sbu.edu						[Anonymous], 2023, Using ChatGPT for source citation; [Anonymous], 2023, Generative Models vs Discriminative Models: Which One to Choose?; [Anonymous], Educator considerations for ChatGPT; [Anonymous], 2023, Gpt4; Armstrong Patricia., BLOOMS TAXONOMY; Asare Janice Gassam, 2023, The Dark Side of Chatgpt; Ausat A., 2023, Journal on Education, V5, P04; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bjarnason Baldur, 2023, The poisoning of chatgpt; Bohannon M., 2023, Lawyer used ChatGPT in court-and cited fake cases. A judge is considering sanctions; Chalmers David, 2022, Could a large language model be conscious?; Charles Kerwin Kofi, 2018, Working Paper 24468, DOI [10.3386/w24468, DOI 10.3386/W24468]; Chen Brian X., 2023, Don't Use A. I. to Cheat in School. It's Better for Studying; Cheng Tim, 2021, Supervised, SemiSupervised, Unsupervised, and Self-Supervised Learning; Cosxkun M., 2017, Eur. J. Tech., V7, P165, DOI [DOI 10.23884/EJT.2017.7.2.11, 10.23884/ejt.2017.7.2.11]; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; Dobson Stephen, 2023, Why Universities Should Return to Oral Exams in the AI and ChatGPT Era; Firaina R., 2023, BULETIN EDUKASI INDO, V2, P39, DOI DOI 10.56741/BEI.V2I01.310; Germain Thomas, 2023, Out of control: Study unlocks Chatgpt's inner racist; Gwendolyn Dr. Stripling, 2023, Video; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Han Jieun, 2023, RECIPE: How to Integrate ChatGPT into EFL Writing Education (L@ S '23), P416, DOI [10.1145/3573051, DOI 10.1145/3573051]; Harish SG, 2023, Jail Breaking Chatgpt to write malware; Hurler Kevin, 2023, Chat-GPT pretended to be blind and tricked a human into solving a CAPTCHA; irvingwb, 2023, About us; Kami Arabian, 2023, Arabian: Let's Chat; Lambert N., 2022, Illustrating Reinforcement Learning from Human Feedback (RLHF); Machine Learning Street Talk, 2023, Video; Maeda John, 2023, What are Tokens?; Maeda John, 2023, What are Prompts?; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Mogavi RH, 2023, Arxiv, DOI arXiv:2305.13114; Nguyen Isabelle, 2023, The Beginner's Guide to LLM Prompting; Ramlochan Sunil, 2023, Solving. Reflexion: An Iterative Approach to LLM ProblemRetrieved; Reed Rachel, 2023, Harvard Law Labor expert Sharon Block on the Hollywood Writers Strike, AI, and what comes next; Sajid Haziqa, 2023, WHAT ARE LLM HALLUCI; Scott Inara, 2023, CHATGPT is causing an educational crisis (opinion); Seldon, 2022, Explained; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Vasilatos C, 2023, Arxiv, DOI arXiv:2305.18226; Voss Peter, 2017, Does an AGI need to be conscious?; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?	42	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							130	136		10.1145/3626252.3630941	http://dx.doi.org/10.1145/3626252.3630941			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP					2024-07-03	WOS:001181240800021
C	Al-Kaswan, A; Izadi, M			IEEE	Al-Kaswan, Ali; Izadi, Maliheh			The (ab)use of Open Source Code to Train Large Language Models	2023 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING, NLBSE			English	Proceedings Paper	2nd IEEE/ACM International Workshop on Natural Language-Based Software Engineering (NLBSE)	MAY 20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc				In recent years, Large Language Models (LLMs) have gained significant popularity due to their ability to generate human-like text and their potential applications in various fields, such as Software Engineering. LLMs for Code are commonly trained on large unsanitized corpora of source code scraped from the Internet. The content of these datasets is memorized and emitted by the models, often in a verbatim manner. In this work, we will discuss the security, privacy, and licensing implications of memorization. We argue why the use of copyleft code to train LLMs is a legal and ethical dilemma. Finally, we provide four actionable recommendations to address this issue.	[Al-Kaswan, Ali; Izadi, Maliheh] Delft Univ Technol, Delft, Netherlands	Delft University of Technology	Al-Kaswan, A (corresponding author), Delft Univ Technol, Delft, Netherlands.	a.al-kaswan@tudelft.nl; m.izadi@tudelft.nl		Al-Kaswan, Ali/0000-0001-7338-2044				Al-Kaswan A., 2023, P 30 IEEE INT C SOFT; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Izadi M, 2022, PROC INT CONF SOFTW, P401, DOI 10.1145/3510003.3510172; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Sun ZS, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P652, DOI 10.1145/3485447.3512225	5	1	1	2	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0178-6				2023							9	10		10.1109/NLBSE59153.2023.00008	http://dx.doi.org/10.1109/NLBSE59153.2023.00008			2	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4QQ		Green Submitted			2024-07-03	WOS:001039169700002
C	Bariah, L; Zou, H; Zhao, QY; Mouhouche, B; Bader, F; Debbah, M			IEEE	Bariah, Lina; Zou, Hang; Zhao, Qiyang; Mouhouche, Belkacem; Bader, Faouzi; Debbah, Merouane			Understanding Telecom Language Through Large Language Models	IEEE CONFERENCE ON GLOBAL COMMUNICATIONS, GLOBECOM	IEEE Global Communications Conference		English	Proceedings Paper	IEEE Conference on Global Communications (IEEE GLOBECOM) - Intelligent Communications for Shared Prosperity	DEC 04-08, 2023	Kuala Lumpur, MALAYSIA	IEEE, Huawei, Technol Innovat Inst, ZTE, Intel, Rohde & Schwarz, NL, VLAVI		Generative AI; Large Language Models; Pre-trained Transformer; Telecom Language; 3GPP		The recent progress of artificial intelligence (AI) opens up new frontiers in the possibility of automating many tasks involved in Telecom networks design, implementation, and deployment. This has been further pushed forward with the evolution of generative artificial intelligence (AI), including the emergence of large language models (LLMs), which is believed to be the cornerstone toward realizing self-governed, interactive AI agents. Motivated by this, in this paper, we aim to adapt the paradigm of LLMs to the Telecom domain. In particular, we fine-tune several LLMs including BERT, distilled BERT, RoBERTa and GPT-2, to the Telecom domain languages, and demonstrate a use case for identifying the 3rd Generation Partnership Project (3GPP) standard working groups. We consider training the selected models on 3GPP technical documents (Tdoc) pertinent to years 2009-2019 and predict the Tdoc categories in years 2020-2023. The results demonstrate that fine-tuning BERT and RoBERTa model achieves 84.6% accuracy, while GPT-2 model achieves 83% in identifying 3GPP working groups. The distilled BERT model with around 50% less parameters achieves similar performance as others. This corroborates that fine-tuning pretrained LLM can effectively identify the categories of Telecom language. The developed framework shows a stepping stone towards realizing intent-driven and self-evolving wireless networks from Telecom languages, and paves the way for the implementation of generative AI in the Telecom domain.	[Bariah, Lina; Zou, Hang; Zhao, Qiyang; Mouhouche, Belkacem; Bader, Faouzi] Technol Innovat Inst, 9639 Masdar City, Abu Dhabi, U Arab Emirates; [Debbah, Merouane] Khalifa Univ, Abu Dhabi 127788, U Arab Emirates	Technology Innovation Institute; Khalifa University of Science & Technology	Bariah, L (corresponding author), Technol Innovat Inst, 9639 Masdar City, Abu Dhabi, U Arab Emirates.	Lina.Bariah@tii.ae; Hang.Zou@tii.ae; Qiyang.Zhao@tii.ae; Belkacem.Mouhouche@tii.ae; Faouzi.Bader@tii.ae; merouane.debbah@ku.ac.ae						[Anonymous], AP TIK CONT AN TOOLK; Antoun W., 2020, P 4 WORKSH OP SOURC, P9; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bommasani Rishi, 2021, ARXIV210807258; Chen XY, 2022, IEEE ACCESS, V10, P34046, DOI 10.1109/ACCESS.2022.3162614; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fabien M., 2020, P 17 INT C NAT LANG, P127; He Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4604; Holm H., 2021, BIDIRECTIONAL ENCODE; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Lagutina Ksenia, 2022, 2022 31st Conference of Open Innovations Association (FRUCT), P160, DOI 10.23919/FRUCT54823.2022.9770920; Lee JS, 2020, WORLD PAT INF, V61, DOI 10.1016/j.wpi.2020.101965; Myagmar B, 2019, IEEE ACCESS, V7, P163219, DOI 10.1109/ACCESS.2019.2952360; Park JS, 2023, ARXIV230403442; Prabhu Sumanth, 2021, ARXIV210414289; Puri Raul, 2019, ARXIV191210165; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Wang C., 2023, IEEE Commun. Surveys Tuts., P1	19	1	1	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2334-0983	2576-6813	979-8-3503-1090-0	IEEE GLOB COMM CONF			2023							6542	6547		10.1109/GLOBECOM54140.2023.10437725	http://dx.doi.org/10.1109/GLOBECOM54140.2023.10437725			6	Engineering, Electrical & Electronic; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering; Telecommunications	BW6LH		Green Submitted			2024-07-03	WOS:001178562007019
J	Singh, AK; Lamichhane, B; Devkota, S; Dhakal, U; Dhakal, C				Singh, Aniket Kumar; Lamichhane, Bishal; Devkota, Suman; Dhakal, Uttam; Dhakal, Chandra			Do Large Language Models Show Human-like Biases? Exploring Confidence-Competence Gap in AI	INFORMATION			English	Article						Large Language Models; Dunning-Kruger effects; chat-GPT; BARD; Claude; LLaMA; cognitive biases; artificial intelligence; AI ethics; Natural Language Processing; confidence assessment		This study investigates self-assessment tendencies in Large Language Models (LLMs), examining if patterns resemble human cognitive biases like the Dunning-Kruger effect. LLMs, including GPT, BARD, Claude, and LLaMA, are evaluated using confidence scores on reasoning tasks. The models provide self-assessed confidence levels before and after responding to different questions. The results show cases where high confidence does not correlate with correctness, suggesting overconfidence. Conversely, low confidence despite accurate responses indicates potential underestimation. The confidence scores vary across problem categories and difficulties, reducing confidence for complex queries. GPT-4 displays consistent confidence, while LLaMA and Claude demonstrate more variations. Some of these patterns resemble the Dunning-Kruger effect, where incompetence leads to inflated self-evaluations. While not conclusively evident, these observations parallel this phenomenon and provide a foundation to further explore the alignment of competence and confidence in LLMs. As LLMs continue to expand their societal roles, further research into their self-assessment mechanisms is warranted to fully understand their capabilities and limitations.	[Singh, Aniket Kumar] Youngstown State Univ, Dept Comp Sci & Informat Syst, Youngstown, OH 44555 USA; [Lamichhane, Bishal] Univ Nevada, Dept Math & Stat, Reno, NV 89557 USA; [Devkota, Suman; Dhakal, Uttam] Youngstown State Univ, Dept Elect & Comp Engn, Youngstown, OH 44555 USA; [Dhakal, Chandra] Univ Georgia, Dept Agr & Appl Econ, Athens, GA 30602 USA	University System of Ohio; Youngstown State University; Nevada System of Higher Education (NSHE); University of Nevada Reno; University System of Ohio; Youngstown State University; University System of Georgia; University of Georgia	Dhakal, C (corresponding author), Univ Georgia, Dept Agr & Appl Econ, Athens, GA 30602 USA.	aksingh01@ysu.edu; blamichhane@unr.edu; sdevkota01@student.ysu.edu; udhakal02@student.ysu.edu; chandra.dhakal25@uga.edu	Dhakal, Uttam/JXN-1683-2024; Singh, Aniket Kumar/JDM-9054-2023; Devkota, Suman/JNS-7803-2023; Dhakal, Chandra/AAI-2454-2019	Dhakal, Uttam/0009-0006-6770-4311; Singh, Aniket Kumar/0009-0008-9189-8528; Devkota, Suman/0000-0003-2298-8729; Dhakal, Chandra/0000-0002-1992-6300				Acerbi A, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2313790120; Dunning D, 2011, ADV EXP SOC PSYCHOL, V44, P247, DOI 10.1016/B978-0-12-385522-0.00005-6; Hendrycks D., 2021, P 2021 INT C LEARNIN; Huang J., 2022, arXiv; Huang JT, 2024, Arxiv, DOI arXiv:2308.03656; Jones E, 2022, Arxiv, DOI arXiv:2202.12299; Kraus M, 2023, Arxiv, DOI [arXiv:2304.00116, DOI 10.48550/ARXIV.2304.00116]; Kruger J, 1999, J PERS SOC PSYCHOL, V77, P1121, DOI 10.1037/0022-3514.77.6.1121; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin Z, 2024, Arxiv, DOI [arXiv:2305.19187, 10.48550/arXiv.2305.19187]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Ranaldi L, 2024, Arxiv, DOI arXiv:2311.09410; Sareen S, 2023, Chain of Thoughts vs. Tree of Thoughts for Language Learning Models (LLMs); Schick T., 2023, arXiv; Shiffrin R, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2300963120; Sorin V, 2023, medRxiv, DOI [10.1101/2023.08.07.23293769, 10.1101/2023.08.07.23293769v1, DOI 10.1101/2023.08.07.23293769, 10.1101/2023.08.07.23293769]; Vaswani A, 2017, ADV NEUR IN, V30; Wang L, 2024, Arxiv, DOI arXiv:2308.11432; Wang SY, 2022, IEEE-ACM T AUDIO SPE, V30, P2201, DOI 10.1109/TASLP.2022.3164218; Ye H., 2023, arXiv, DOI DOI 10.48550/ARXIV.2309.06794; Yogatama D, 2019, Arxiv, DOI arXiv:1901.11373; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong WJ, 2021, Arxiv, DOI arXiv:2104.06598; Zhuang Y, 2023, Arxiv, DOI arXiv:2306.10512	24	0	0	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	FEB	2024	15	2							92	10.3390/info15020092	http://dx.doi.org/10.3390/info15020092			20	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	IS4U7		gold			2024-07-03	WOS:001168316300001
J	Gupta, V; Gupta, C				Gupta, Varun; Gupta, Chetna			Navigating Foreign Language-Taught Degrees: Embracing Artificial Intelligence-Driven Language Translators to Overcome Linguistic Challenges	COMPUTER			English	Article								Artificial intelligence-driven language translation tools could be valuable for facilitating knowledge exchanges and overcoming linguistic barriers in foreign language-taught degree programs. Integration with large language models could enhance knowledge exchanges through technological innovations.	[Gupta, Varun] Gisma Univ Appl Sci, Multidisciplinary Res Ctr Innovat SMEs MrciS, D-14469 Potsdam, Germany; [Gupta, Chetna] Jaypee Inst Informat Technol, Dept Comp Sci & Engn & Informat Technol, Noida 201305, India	Jaypee Institute of Information Technology (JIIT)	Gupta, V (corresponding author), Gisma Univ Appl Sci, Multidisciplinary Res Ctr Innovat SMEs MrciS, D-14469 Potsdam, Germany.	varun.iit13@gmail.com; chetnagupta04@gmail.com						Ahmad N, 2023, COMPUTER, V56, P72, DOI 10.1109/MC.2023.3263576; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Zijlmans L, 2020, LANG LEARN HIGH EDUC, V10, P25, DOI 10.1515/cercles-2020-2017	4	0	0	18	30	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	SEP	2023	56	9					71	76		10.1109/MC.2023.3290686	http://dx.doi.org/10.1109/MC.2023.3290686			6	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	P6IV2		Bronze			2024-07-03	WOS:001051701500012
J	Biever, C				Biever, Celeste			ChatGPT broke the Turing test - the race is on for new ways to assess AI	NATURE			English	Editorial Material						Computer science; Mathematics and computing; Technology; Society		Large language models mimic human chatter, but scientists disagree on their ability to reason.										Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chollet F, 2019, Arxiv, DOI arXiv:1911.01547; Jannai D., 2023, arXiv, DOI [10.48550/arXiv.2305.20010, DOI 10.48550/ARXIV.2305.20010]; Johnson A, 2021, Arxiv, DOI arXiv:2103.05823; Li K., 2023, P 11 INT C LEARN REP, P1; Moskvichev A, 2023, Arxiv, DOI arXiv:2305.07141; Xu YD, 2024, Arxiv, DOI arXiv:2305.18354	9	10	11	9	34	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JUL 27	2023	619	7971					686	689		10.1038/d41586-023-02361-7	http://dx.doi.org/10.1038/d41586-023-02361-7			4	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	N5VC3	37491395				2024-07-03	WOS:001037676300014
J	Hasani, AM; Singh, S; Zahergivar, A; Ryan, B; Nethala, D; Bravomontenegro, G; Mendhiratta, N; Ball, M; Farhadi, F; Malayeri, A				Hasani, Amir M.; Singh, Shiva; Zahergivar, Aryan; Ryan, Beth; Nethala, Daniel; Bravomontenegro, Gabriela; Mendhiratta, Neil; Ball, Mark; Farhadi, Faraz; Malayeri, Ashkan			Evaluating the performance of Generative Pre-trained Transformer-4 (GPT-4) in standardizing radiology reports	EUROPEAN RADIOLOGY			English	Article; Early Access						Artificial intelligence; Natural language processing; Digital health; Machine learning		ObjectiveRadiology reporting is an essential component of clinical diagnosis and decision-making. With the advent of advanced artificial intelligence (AI) models like GPT-4 (Generative Pre-trained Transformer 4), there is growing interest in evaluating their potential for optimizing or generating radiology reports. This study aimed to compare the quality and content of radiologist-generated and GPT-4 AI-generated radiology reports.MethodsA comparative study design was employed in the study, where a total of 100 anonymized radiology reports were randomly selected and analyzed. Each report was processed by GPT-4, resulting in the generation of a corresponding AI-generated report. Quantitative and qualitative analysis techniques were utilized to assess similarities and differences between the two sets of reports.ResultsThe AI-generated reports showed comparable quality to radiologist-generated reports in most categories. Significant differences were observed in clarity (p = 0.027), ease of understanding (p = 0.023), and structure (p = 0.050), favoring the AI-generated reports. AI-generated reports were more concise, with 34.53 fewer words and 174.22 fewer characters on average, but had greater variability in sentence length. Content similarity was high, with an average Cosine Similarity of 0.85, Sequence Matcher Similarity of 0.52, BLEU Score of 0.5008, and BERTScore F1 of 0.8775.ConclusionThe results of this proof-of-concept study suggest that GPT-4 can be a reliable tool for generating standardized radiology reports, offering potential benefits such as improved efficiency, better communication, and simplified data extraction and analysis. However, limitations and ethical implications must be addressed to ensure the safe and effective implementation of this technology in clinical practice.Clinical relevance statementThe findings of this study suggest that GPT-4 (Generative Pre-trained Transformer 4), an advanced AI model, has the potential to significantly contribute to the standardization and optimization of radiology reporting, offering improved efficiency and communication in clinical practice.Key Points center dot Large language model-generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.center dot Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.center dot Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.Key Points center dot Large language model-generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.center dot Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports.center dot Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.Key Points center dot Large language model-generated radiology reports exhibited high content similarity and moderate structural resemblance to radiologist-generated reports.center dot Performance metrics highlighted the strong matching of word selection and order, as well as high semantic similarity between AI and radiologist-generated reports. center dot Large language model demonstrated potential for generating standardized radiology reports, improving efficiency and communication in clinical settings.	[Hasani, Amir M.] NHBLI, Lab Translat Res, NIH, Bethesda, MD USA; [Singh, Shiva; Zahergivar, Aryan; Farhadi, Faraz; Malayeri, Ashkan] NIH, Radiol & Imaging Sci Dept, Clin Ctr, Bethesda, MD 20892 USA; [Ryan, Beth; Nethala, Daniel; Bravomontenegro, Gabriela; Mendhiratta, Neil; Ball, Mark] NCI, Urol Oncol Branch, NIH, Bethesda, MD USA	National Institutes of Health (NIH) - USA; NIH National Heart Lung & Blood Institute (NHLBI); National Institutes of Health (NIH) - USA; NIH Clinical Center (CC); National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI)	Malayeri, A (corresponding author), NIH, Radiol & Imaging Sci Dept, Clin Ctr, Bethesda, MD 20892 USA.	Ashkan.Malayeri@nih.gov		Hasani, Amir/0000-0002-8297-9384; Zahergivar, Aryan/0000-0002-1428-4054	National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This study has received funding by National Institutes of Health.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; Alfarghaly O., 2021, INFORM MED UNLOCKED, V24, P100557, DOI [DOI 10.1016/J.IMU.2021.100557, 10.1016/j.imu.2021.100557]; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Babu AS, 2015, RADIOGRAPHICS, V35, P547, DOI 10.1148/rg.352140046; Choudhury A, 2020, JMIR MED INF, V8, DOI 10.2196/18599; Gaube S, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00385-9; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jing B, 2017, ANN M ASS COMP LING; Larson DB, 2018, RADIOGRAPHICS, V38, P1705, DOI 10.1148/rg.2018180040; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li J, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01946-y; Li JY, 2023, Arxiv, DOI arXiv:2305.11747; Lyu Q, 2023, Arxiv, DOI arXiv:2303.09038; Mabotuwana T, 2013, J BIOMED INFORM, V46, P857, DOI 10.1016/j.jbi.2013.06.013; Monshi MMA, 2020, ARTIF INTELL MED, V106, DOI 10.1016/j.artmed.2020.101878; Nishigaki D, 2023, RADIOL-ARTIF INTELL, V5, DOI 10.1148/ryai.220097; Olthof AW, 2021, COMPUT METH PROG BIO, V208, DOI 10.1016/j.cmpb.2021.106304; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Tejani AS, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220007; Wiggins WF, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021210035; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258	23	1	1	12	16	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0938-7994	1432-1084		EUR RADIOL	Eur. Radiol.	2023 NOV 8	2023										10.1007/s00330-023-10384-x	http://dx.doi.org/10.1007/s00330-023-10384-x		NOV 2023	9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	X9XO0	37938381				2024-07-03	WOS:001101905600009
J	Paraschiv, A; Ion, TA; Dascalu, M				Paraschiv, Andrei; Ion, Teodora Andreea; Dascalu, Mihai			Offensive Text Span Detection in Romanian Comments Using Large Language Models	INFORMATION			English	Article						offensive language detection; hate speech dataset; toxicity; Natural Language Processing; deep learning; Transformer models; Large Language Models; online social media	HATE-SPEECH	The advent of online platforms and services has revolutionized communication, enabling users to share opinions and ideas seamlessly. However, this convenience has also brought about a surge in offensive and harmful language across various communication mediums. In response, social platforms have turned to automated methods to identify offensive content. A critical research question emerges when investigating the role of specific text spans within comments in conveying offensive characteristics. This paper conducted a comprehensive investigation into detecting offensive text spans in Romanian language comments using Transformer encoders and Large Language Models (LLMs). We introduced an extensive dataset of 4800 Romanian comments annotated with offensive text spans. Moreover, we explored the impact of varying model sizes, architectures, and training data volumes on the performance of offensive text span detection, providing valuable insights for determining the optimal configuration. The results argue for the effectiveness of BERT pre-trained models for this span-detection task, showcasing their superior performance. We further investigated the impact of different sample-retrieval strategies for few-shot learning using LLMs based on vector text representations. The analysis highlights important insights and trade-offs in leveraging LLMs for offensive-language-detection tasks.	[Paraschiv, Andrei; Dascalu, Mihai] Natl Univ Sci & Technol, Politehn Bucharest, Comp Sci & Engn Dept, 313 Splaiul Independentei, Bucharest 060042, Romania; [Ion, Teodora Andreea; Dascalu, Mihai] Acad Romanian Scientists, Str Ilfov 3, Bucharest 050044, Romania	National University of Science & Technology POLITEHNICA Bucharest; Academy of Romanian Scientists (AOSR)	Dascalu, M (corresponding author), Natl Univ Sci & Technol, Politehn Bucharest, Comp Sci & Engn Dept, 313 Splaiul Independentei, Bucharest 060042, Romania.; Dascalu, M (corresponding author), Acad Romanian Scientists, Str Ilfov 3, Bucharest 050044, Romania.	andrei.paraschiv74@upb.ro; teodora_andreea.ion@stud.acs.upb.ro; mihai.dascalu@upb.ro	Dascalu, Mihai/O-4984-2014	Dascalu, Mihai/0000-0002-4815-9227; Paraschiv, Andrei/0000-0002-7992-4227	Ministry of Research, Innovation and Digitalization	Ministry of Research, Innovation and Digitalization	No Statement Available	Agarwal S, 2015, Arxiv, DOI arXiv:1511.06858; Agarwal S, 2014, 2014 IEEE JOINT INTELLIGENCE AND SECURITY INFORMATICS CONFERENCE (JISIC), P318, DOI 10.1109/JISIC.2014.65; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Alkomah F, 2022, INFORMATION, V13, DOI 10.3390/info13060273; Alshalan R, 2020, J MED INTERNET RES, V22, DOI 10.2196/22609; [Anonymous], TWITTER API; [Anonymous], 1997, Proceedings of the 8th Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-97); Bird S., 2009, NATURAL LANGUAGE PRO; Çöltekin Ç, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6174; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Da San Martino G, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5636; Dai J., 2022, P 20 ANN WORKSHOP AU, P115; Davidson Thomas, 2017, 11 INT AAAI C WEB SO; Del Vigna12 F., 2017, P 1 ITALIAN C CYBERS, P86; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dowlagar S., 2021, arXiv, DOI DOI 10.48550/ARXIV.2101.09007; Fortuna P, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102524; Ghosh K., 2022, P 36 PACIFIC ASIA C, P853; Gibert O. d., 2018, P 2 WORKSH AB LANG O, P11, DOI [10.18653/v1/W18-5102, DOI 10.18653/V1/W18-5102]; Gupta S., 2017, A Comparative Study of Embeddings Methods for Hate Speech Detection From Tweets; Hoang P.G., 2023, ViHOS: Hate Speech Spans Detection for Vietnamese, P652, DOI [10.18653/v1/2023.eacl-main.47, DOI 10.18653/V1/2023.EACL-MAIN.47]; Höfels DC, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2269; Huang ZH, 2015, Arxiv, DOI [arXiv:1508.01991, DOI 10.48550/ARXIV.1508.01991]; INSHR, 2018, Technical Report; Jeong Y., 2022, KOLD: Korean Offensive Language Dataset, P10818, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.744; Jongeling R, 2017, EMPIR SOFTW ENG, V22, P2543, DOI 10.1007/s10664-016-9493-x; Lafferty J., 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.5555/645530.655813; Leite JA, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P914; Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572; Mandl T, 2019, ACM INT CONF PR SER, P14, DOI 10.1145/3368567.3368584; Manolescu M., 2021, P INT C RECENT ADV N, P895; Masala Mihai, 2020, COLING, P6626, DOI DOI 10.18653/V1/2020.COLING-MAIN.581; Mathew B, 2021, AAAI CONF ARTIF INTE, V35, P14867; Meza R.M., 2019, Intersections, V4, P4, DOI [10.17356/ieejsp.v4i4.503, DOI 10.17356/IEEJSP.V4I4.503]; Mohiyaddeen M., 2021, Automatic Hate Speech Detection: A Literature Review; Moon Jihyung, 2020, P 8 INT WORKSHOP NAT, P25, DOI DOI 10.18653/V1/2020.SOCIALNLP-1.4; Mubarak H., 2021, P 6 ARABIC NATURAL L, P126; Müller K, 2021, J EUR ECON ASSOC, V19, P2131, DOI 10.1093/jeea/jvaa045; Pankowski R., 2020, Technical report; Paraschiv A., 2023, Fighting Romanian Offensive Language with RO-Offense: A Dataset and Classification Models for Online Comments; Park Ji Ho, 2017, P 1 WORKSHOP ABUSIVE, P41; Pascanu R., 2013, INT C MACHINE LEARNI, V28, P1310, DOI DOI 10.5555/3042817.3043083; Pavlopoulos J., 2021, P 15 INT WORKSHOP SE, P59, DOI DOI 10.18653/V1/2021.SEMEVAL-1.6; Pavlopoulos J, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3721; Pitenis Z, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5113; Pitsilis GK, 2018, APPL INTELL, V48, P4730, DOI 10.1007/s10489-018-1242-y; Ranasinghe T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P144; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Robinson D, 2018, LECT NOTES COMPUT SC, V11155, P46, DOI 10.1007/978-3-319-98192-5_9; Saker J, 2023, Arxiv, DOI arXiv:2307.03386; Schouten S., 2023, INT C APPL NATURAL L, P533, DOI 10.1007/978-3-031-35320-8_40; Sigurbergsson GI, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3498; Sundararajan M, 2017, PR MACH LEARN RES, V70; Vaswani A, 2017, ADV NEUR IN, V30; Velankar A, 2023, LECT NOTES ARTIF INT, V13739, P121, DOI 10.1007/978-3-031-20650-4_10; Vilar D., 2023, Prompting PaLM for Translation: Assessing Strategies and Performance, P15406, DOI [10.18653/v1/2023.acl-long.859, DOI 10.18653/V1/2023.ACL-LONG.859]; Wang L., 2022, A Fine-Grained Interpretability Evaluation Benchmark for Neural NLP, P70, DOI [10.18653/v1/2022.conll-1.6, DOI 10.18653/V1/2022.CONLL-1.6]; Wang S., 2023, GNN-SL: Sequence Labeling Based on Nearest Examples via GNN, P12679, DOI [10.18653/v1/2023.findings-acl.803, DOI 10.18653/V1/2023.FINDINGS-ACL.803]; Waseem Zeerak, 2017, P 1 WORKSHOP ABUSIVE, P78; Wei JTZ, 2024, Arxiv, DOI arXiv:2305.09601; Williams ML, 2020, BRIT J CRIMINOL, V60, P93, DOI 10.1093/bjc/azz049; Xiang G., 2012, P 21 ACM INT C INFOR, P1980; Zaidan Omar, 2007, HUMAN LANGUAGE TECHN, P260; Zampieri M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1415; Zhao J., 2020, P 37 INT C MACH LEAR, V119, P11365; Zhou LD, 2023, NAT LANG ENG, V29, P1247, DOI 10.1017/S1351324922000262; Zhu Q., 2021, P 15 INT WORKSHOP SE, P521, DOI 10.18653/v1/ 2021.semeval-1.63	67	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	JAN	2024	15	1							8	10.3390/info15010008	http://dx.doi.org/10.3390/info15010008			21	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	GF7X2		gold			2024-07-03	WOS:001151327000001
J	Yavuz, F; Çelik,Ö; Çelik, GY				Yavuz, Fatih; Celik, Ozgur; Celik, Gamze Yavas			Utilizing large language models for EFL essay grading: An examination of reliability and validity in rubric-based assessments	BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY			English	Article; Early Access						AI-based grading; automated essay scoring; generative AI; large language models; reliability; rubric-based grading; validity		This study investigates the validity and reliability of generative large language models (LLMs), specifically ChatGPT and Google's Bard, in grading student essays in higher education based on an analytical grading rubric. A total of 15 experienced English as a foreign language (EFL) instructors and two LLMs were asked to evaluate three student essays of varying quality. The grading scale comprised five domains: grammar, content, organization, style & expression and mechanics. The results revealed that fine-tuned ChatGPT model demonstrated a very high level of reliability with an intraclass correlation (ICC) score of 0.972, Default ChatGPT model exhibited an ICC score of 0.947 and Bard showed a substantial level of reliability with an ICC score of 0.919. Additionally, a significant overlap was observed in certain domains when comparing the grades assigned by LLMs and human raters. In conclusion, the findings suggest that while LLMs demonstrated a notable consistency and potential for grading competency, further fine-tuning and adjustment are needed for a more nuanced understanding of non-objective essay criteria. The study not only offers insights into the potential use of LLMs in grading student essays but also highlights the need for continued development and research.What is already known about this topic Large language models (LLMs), such as OpenAI's ChatGPT and Google's Bard, are known for their ability to generate text that mimics human-like conversation and writing. LLMs can perform various tasks, including essay grading. Intraclass correlation (ICC) is a statistical measure used to assess the reliability of ratings given by different raters (in this case, EFL instructors and LLMs). What this paper adds The study makes a unique contribution by directly comparing the grading performance of expert EFL instructors with two LLMs-ChatGPT and Bard-using an analytical grading scale. It provides robust empirical evidence showing high reliability of LLMs in grading essays, supported by high ICC scores. It specifically highlights that the overall efficacy of LLMs extends to certain domains of essay grading. Implications for practice and/or policy The findings open up potential new avenues for utilizing LLMs in academic settings, particularly for grading student essays, thereby possibly alleviating workload of educators. The paper's insistence on the need for further fine-tuning of LLMs underlines the continual interplay between technological advancement and its practical applications. The results lay down a footprint for future research in advancing the use of AI in essay grading.	[Yavuz, Fatih] Mudanya Univ, Preparatory Dept, Mudanya, Turkiye; [Celik, Ozgur; Celik, Gamze Yavas] Balikesir Univ, Sch Foreign Languages, Balikesir, Turkiye	Balikesir University	Yavuz, F (corresponding author), Mudanya Univ, Preparatory Dept, Mudanya, Turkiye.	yavuzf@hotmail.com; ozgurcelik911@gmail.com; gamzecelik@balikesir.edu.tr	Yavuz, Fatih/N-8426-2019; ÇELİK, Özgür/O-2997-2019	Yavuz, Fatih/0000-0003-2645-2710; ÇELİK, Özgür/0000-0002-0300-9073				ahan ., 2019, Global perspectives on language assessment, V1st ed., P32, DOI [10.4324/9780429437922-3, DOI 10.4324/9780429437922-3]; Bacha N., 2001, SYSTEM, V29, P371, DOI [10.1016/S0346-251X(01)00025-2, DOI 10.1016/S0346-251X(01)00025-2]; Escalante J, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00425-2; Fazal A, 2013, J COMPUT SYST SCI, V79, P1040, DOI 10.1016/j.jcss.2013.01.021; Han T., 2013, The impact of rating methods and rater training on the variability and reliability of EFL students' classroom based writing assessments in Turkish universities: An investigation of problems and solutions; Hussein MA, 2019, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.208; Ifenthaler D., 2023, Handbook ofOpen, Distance and Digital Education, Vpp, P1057; Khademi A., 2023, Journal of Applied Learning Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.28; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kumar V, 2020, FRONT EDUC, V5, DOI 10.3389/feduc.2020.572367; Kumar VS, 2021, INT J ARTIF INTELL E, V31, P538, DOI 10.1007/s40593-020-00211-5; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Madala D. S. V., 2018, An empirical analysis of machine learning models for automated essay grading, DOI [10.7287/peerj.preprints.3518v1, DOI 10.7287/PEERJ.PREPRINTS.3518V1]; Meyer J, 2023, Z PADAGOG PSYCHOL, V37, P203, DOI 10.1024/1010-0652/a000296; Mizumoto A., 2023, Research Methods in Applied Linguistics, V2, P100050, DOI DOI 10.1016/J.RMAL.2023.100050; OpenAI, 2022, Sharing publication policy; Powers D. E., 2002, Journal of Educational Computing Research, V26, P407, DOI 10.2190/CX92-7WKV-N7WC-JL0A; Ramalingam VV, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012030; Shehab A, 2016, ICENCO 2016 - 2016 12TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO) - BOUNDLESS SMART SOCIETIES, P65, DOI 10.1109/ICENCO.2016.7856447; Shermis MD, 2014, ASSESS WRIT, V20, P53, DOI 10.1016/j.asw.2013.04.001; Shin J, 2021, LANG TEST, V38, P247, DOI 10.1177/0265532220937830; Suresh V., 2023, 2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS), P547, DOI 10.1109/ICICCS56967.2023.10142822; Taskiran A, 2022, TURK ONLINE J DISTAN, V23, P120; Uto M., 2021, Behaviormetrika, V48, P459, DOI 10.1007/s41237-021-00142-y; Wu YC, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010150; Yamamoto M, 2018, STUD COMPUT INTELL, V727, P177, DOI 10.1007/978-3-319-64051-8_11; Zhao RB, 2023, EDUC INF TECHNOL, V28, P7031, DOI 10.1007/s10639-022-11473-y	27	0	0	21	21	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1013	1467-8535		BRIT J EDUC TECHNOL	Br. J. Educ. Technol.	2024 JUN 4	2024										10.1111/bjet.13494	http://dx.doi.org/10.1111/bjet.13494		JUN 2024	17	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	SX8Q5		hybrid			2024-07-03	WOS:001237843800001
J	Arcas, BAY				Aguera y Arcas, Blaise			Do Large Language Models Understand Us?	DAEDALUS			English	Article								Large language models (LLMs) represent a major advance in artificial intelligence and, in particular, toward the goal of human-like artificial general intelligence. It is sometimes claimed, though, that machine learning is "just statistics," hence that, in this grander ambition, progress in AI is illusory. Here I take the contrary view that LLMs have a great deal to teach us about the nature of language, understanding, intelligence, sociality, and personhood. Specifically: statistics do amount to understanding, in any falsifiable sense. Furthermore, much of what we consider intelligence is inherently dialogic, hence social; it requires a theory of mind. Complex sequence learning and social interaction may be a sufficient basis for general intelligence, including theory of mind and consciousness. Since the interior state of another being can only be understood through interaction, no objective answer is possible to the question of when an "it" becomes a "who," but for many people, neural nets running on computers are likely to cross this threshold in the very near future.	[Aguera y Arcas, Blaise] Google Res, Mountain View, CA 94043 USA	Google Incorporated	Arcas, BAY (corresponding author), Google Res, Mountain View, CA 94043 USA.							Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; Akbari Hassan, 2021, VATT TRANSFORMERS MU; [Anonymous], 1637, Discours de la methode pour bien conduire sa raison, & chercher la verite dans les sciences. Plus la dioptrique. Les meteores. Et la geometrie. Discourse on the Method of Rightly Conducting One's Reason and of Seeking Truth in the Sciences. Plus the Diopter, Meteors and Geometry; [Anonymous], RESTLESS CLOCK; Bennett Jane., 2010, VIBRANT MATTER POLIT, DOI 10.1215/9780822391623; Chalmers D. J., 1996, The Conscious Mind: In Search of a Fundamental Theory; Collins E., 2021, Google; Frankfurt Harry, 2005, WHO ELABORATED HIS T; Ghirlanda S, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.161011; GRAZIANO MSA, 2013, CONSCIOUSNESS SOCIAL; Keller Helen, 1929, AM MAG; Kirk R., 1974, P ARISTOTELIAN SOC, V48, P135, DOI DOI 10.1093/ARISTOTELIANSUPP/48.1.135; Montessori M., 2012, The 1946 London Lectures, V17; Saunders George, 2001, SWIM POND RAIN; Schurger A, 2016, TRENDS COGN SCI, V20, P77, DOI 10.1016/j.tics.2015.11.003; Smith Kerri, 2008, NATURE; Thoppilan Romal, 2022, Lamda: Language models for dialog applications; Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1; Vaswani A, 2017, ADV NEUR IN, V30	19	17	17	7	32	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	0011-5266	1548-6192		DAEDALUS-US	Daedalus	MAY 1	2022	151	2			SI		183	197		10.1162/daed_a_01909	http://dx.doi.org/10.1162/daed_a_01909			15	Humanities, Multidisciplinary; Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; Social Sciences - Other Topics	0T0ZK		hybrid			2024-07-03	WOS:000786702600013
C	Wu, YH; Jiang, AQ; Li, WD; Rabe, MN; Staats, C; Jamnik, M; Szegedy, C		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Wu, Yuhuai; Jiang, Albert Q.; Li, Wenda; Rabe, Markus N.; Staats, Charles; Jamnik, Mateja; Szegedy, Christian			Autoformalization with Large Language Models	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					Autoformalization is the process of automatically translating from natural language mathematics to formal specifications and proofs. A successful autoformalization system could advance the fields of formal verification, program synthesis, and artificial intelligence. While the long-term goal of autoformalization seemed elusive for a long time, we show large language models provide new prospects towards this goal. We make the surprising observation that LLMs can correctly translate a significant portion (25:.%) of mathematical competition problems perfectly to formal specifications in Isabelle/HOL. We demonstrate the usefulness of this process by improving a previously introduced neural theorem prover via training on these autoformalized theorems. Our methodology results in a new state-of-the-art result on the MiniF2F theorem proving benchmark, improving the proof rate from 29.6% to 35.2%	[Wu, Yuhuai; Rabe, Markus N.; Staats, Charles; Szegedy, Christian] Google Res, Chicago, IL 60607 USA; [Wu, Yuhuai] Stanford Univ, Stanford, CA 94305 USA; [Jiang, Albert Q.; Li, Wenda; Jamnik, Mateja] Univ Cambridge, Cambridge CB2 1TN, England	Google Incorporated; Stanford University; University of Cambridge	Wu, YH (corresponding author), Google Res, Chicago, IL 60607 USA.; Wu, YH (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	yuhuai@google.com			Peterhouse Graduate Research Studentship; ERC Advanced Grant ALEXANDRIA [GA 742178]	Peterhouse Graduate Research Studentship; ERC Advanced Grant ALEXANDRIA(European Research Council (ERC))	AQJ is supported by a Peterhouse Graduate Research Studentship. WL is supported by the ERC Advanced Grant ALEXANDRIA (Project GA 742178).	Alemi AA, 2016, ADV NEUR IN, V29; Andrychowicz M., 2017, ADV NEURAL INFORM PR, V30, P1; [Anonymous], 2022, THOR WIELDING HAMMER; [Anonymous], 2015, Automated Deduction-CADE-25, DOI DOI 10.1007/978-3-319-21401-6_26; Anthony T., 2017, ADV NEURAL INFORM PR, P5366; Aygun Eser, 2021, ABS211210664 CORR; Bansal K, 2019, PR MACH LEARN RES, V97; Bansal Kshitij, 2019, ABS190510501 CORR; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, ARXIV; Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Cobbe Karl, 2021, CoRR, abs/2110.14168; Coq, COQ PROOF ASS; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Gauthier T, 2021, J AUTOM REASONING, V65, P257, DOI 10.1007/s10817-020-09580-x; Goallier G, 2008, LECT NOTES ARTIF INT, V5081, P333; Gonthier G, 2013, LECT NOTES COMPUT SC, V7998, P163, DOI 10.1007/978-3-642-39634-2_14; Goyal Priya, 2017, ARXIV170602677; Hahn Christopher, 2021, ICLR; Hales T, 2017, FORUM MATH PI, V5, DOI 10.1017/fmp.2017.1; Han Jesse Michael, 2022, INT C LEARN REPR; Han Jesse Michael, 2021, ABS211005448 CORR; Harrison J, 1996, LECT NOTES COMPUT SC, V1166, P265, DOI 10.1007/BFb0031814; Hendrycks Dan, 2021, ABS210303874 CORR; Hoffmann J., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2203.15556; Jiang Albert Q., 2021, 6 C ART INT THEOR PR; Klein G, 2018, COMMUN ACM, V61, P68, DOI 10.1145/3230627; Klein G, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P207; Kreber Jens U., 2021, ABS211010054 CORR; Lample G., 2018, INT C LEARNING REPRE; Lederman Gil, 2020, 8 INT C LEARN REPR I; Li Yujia, 2022, DEEPMIND; Loos SM, 2017, EPIC SERIES COMPUTIN, V46, P85, DOI [10.29007/8mwc, DOI 10.29007/8MWC]; Loshchilov I, 2017, INT C LEARNING REPRE; Polu Stanislas, 2022, Formal mathematics statement curriculum learning; Polu Stanislas, 2020, ABS200903393 CORR; Rabe Markus N., 2021, ICLR; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Schmitt Frederik, 2021, NEURAL INFORM PROCES, V34, P15408; Schulz S., 2001, KI 2001: Advances in Artificial Intelligence. Joint German/ Austrian Conference on AI. Proceedings (Lecture Notes in Artificial Intelligence Vol.2174), P320; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shou T, 2021, ACS OMEGA, V6, P30003, DOI 10.1021/acsomega.1c04650; Szegedy Christian, 2020, Intelligent Computer Mathematics. 13th International Conference, CICM 2020. Proceedings. Lecture Notes in Artificial Intelligence. Subseries of Lecture Notes in Computer Science (LNAI 12236), P3, DOI 10.1007/978-3-030-53518-6_1; Urban J, 2004, J AUTOM REASONING, V33, P319, DOI 10.1007/s10817-004-6245-1; Vaswani A, 2017, ADV NEUR IN, V30; Wang Ben, 2021, Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX; Wang QX, 2018, LECT NOTES ARTIF INT, V11006, P255, DOI 10.1007/978-3-319-96812-4_22; Wang Qingxiang, 2020, INT C CERT PROGR PRO; Wenzel M, 2008, LECT NOTES COMPUT SC, V5170, P33, DOI 10.1007/978-3-540-71067-7_7; Wu Minchao, 2021, ABS210209756 CORR; Wu Yuhuai, 2022, ARXIV220308913; Zheng Kunhao, 2021, ARXIV210900110	52	0	0	0	0	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														16	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259101007
C	Shimbo, A; Sugawara, Y; Yamada, H; Tokunaga, T		Spanakis, J; VanDijck, G; Sileno, G		Shimbo, Akito; Sugawara, Yuta; Yamada, Hiroaki; Tokunaga, Takenobu			Nearest Neighbor Search for Summarization of Japanese Judgment Documents	LEGAL KNOWLEDGE AND INFORMATION SYSTEMS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	36th Annual International Conference on Legal Knowledge and Information Systems (JURIX)	DEC 18-20, 2023	Maastricht Univ, Maastricht, NETHERLANDS	JURIX Fdn Legal Knowledge Based Syst	Maastricht Univ	summarization; large language model; nearest neighbor search; Japanese judgment document		With the increasing demand for summarizing Japanese judgment documents, the automatic generation of high-quality summaries by large language models (LLMs) is expected. We propose a method to select exemplars using the nearest neighbor search for the one-shot learning method. The experiments showed our method outperforms baseline methods.	[Shimbo, Akito; Sugawara, Yuta; Yamada, Hiroaki; Tokunaga, Takenobu] Tokyo Inst Technol, Tokyo, Japan	Tokyo Institute of Technology	Shimbo, A (corresponding author), Tokyo Inst Technol, Tokyo, Japan.	shimbo.a.aa@m.titech.ac.jp		Yamada, Hiroaki/0000-0002-1963-958X	LIC Co., Ltd.	LIC Co., Ltd.	This work was supported by LIC Co., Ltd.	Banno S, 2005, tegakari hyogen ni motozuku hanketsubun no jidou youyaku; Deroy A, P 3 INT WORKSH ART I; Patil R, 2022, P MACHINE LEARNING R, V203, P103; Tanikawa K, hanrei jouhou no o-pun de-ta ka; Vadlamannati S, 2023, INLG OR SESS 3 LEV L; Wang L, 2024, Arxiv, DOI arXiv:2212.03533	6	0	0	1	1	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-472-7; 978-1-64368-473-4	FRONT ARTIF INTEL AP			2023	379						335	340		10.3233/FAIA230984	http://dx.doi.org/10.3233/FAIA230984			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Information Science & Library Science; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science; Government & Law	BW6JJ		hybrid			2024-07-03	WOS:001175464100044
J	Torres-Martínez, S				Torres-Martinez, Sergio			Embodied human language models vs. Large Language Models, or why Artificial Intelligence cannot explain the modal <i>be able to</i>	BIOSEMIOTICS			English	Article						Active inference; Agentive Cognitive Construction Grammar; Embodied Human Language Model; Large Language Models; Perplexity; Triadic constructions		This paper explores the challenges posed by the rapid advancement of artificial intelligence specifically Large Language Models (LLMs). I show that traditional linguistic theories and corpus studies are being outpaced by LLMs' computational sophistication and low perplexity levels. In order to address these challenges, I suggest a focus on language as a cognitive tool shaped by embodied-environmental imperatives in the context of Agentive Cognitive Construction Grammar. To that end, I introduce an Embodied Human Language Model (EHLM), inspired by Active Inference research, as a promising alternative that integrates sensory input, embodied representations, and adaptive strategies for contextualized analysis and conceptual utility maximization. By incorporating Active Inference, which sees perception as inferring the world's state from sensory data, the findings reveal that the characterization of the English modal be able to, as a triadic construction encoding biological intelligent agency, introduces a more plausible theoretical basis for the positing of linguistic constructions. This emphasizes the crucial role of embodied human language models in the comprehension of how humans construct preferred futures through language.	[Torres-Martinez, Sergio] Univ Antioquia, Cll 67 53-108, Medellin, Antioquia, Colombia	Universidad de Antioquia	Torres-Martínez, S (corresponding author), Univ Antioquia, Cll 67 53-108, Medellin, Antioquia, Colombia.	surtr_2000@yahoo.es	hu, guangchen/KEI-6324-2024; Torres Martinez, Sergio/D-1461-2016	Torres Martinez, Sergio/0000-0002-8823-1676				Barbieri Mario., 2007, The Codes of Life: The Rules of Macroevoiution; Berto F., 2022, Topics of Thought: The Logic of Knowledge, Belief, Imagination, DOI [10.1093/oso/9780192857491.001.0001, DOI 10.1093/OSO/9780192857491.001.0001]; Boghossian P., 2020, DEBATING PRIORI, DOI [10.1093/oso/9780198851707.001.0001, DOI 10.1093/OSO/9780198851707.001.0001]; Bommasani R., 2022, ARXIV; Cappelle B, 2023, TOP ENGL LINGUIST, V110, P93, DOI 10.1515/9783110734157-004; Cappelle B, 2019, CONSTR FRAMES, V11, P220, DOI 10.1075/cf.00029.cap; Cappelle B, 2016, CONSTR FRAMES, V8, P7, DOI 10.1075/cf.8.1.02cap; Chomsky N, 2019, CATALAN J LINGUIST, P229, DOI 10.5565/rev/catjl.288; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Coghlan S., 2023, Philosophy and Technology, V36, P25, DOI [10.1007/s13347-023-00627-6, DOI 10.1007/S13347-023-00627-6]; Davies M., 2008, The Corpus of Contemporary American English (COCA) Computer software; Depraetere I., 2023, MODELS MODALS PRAGMA, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Divjak D, 2023, LINGUISTICS, V61, P1027, DOI 10.1515/ling-2022-0186; Ez-zizi A, 2024, LANG LEARN, V74, P41, DOI 10.1111/lang.12569; FAVAREAU D, 2010, ESSENTIAL READINGS B, DOI DOI 10.1007/978-1-4020-9650-1; Flach S, 2023, TOP ENGL LINGUIST, V110, P149, DOI 10.1515/9783110734157-006; Friston KJ, 2009, TRENDS COGN SCI, V13, P293, DOI 10.1016/j.tics.2009.04.005; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; GIBSON JAMES J., 1966; Gibson JJ, 1979, ECOLOGICAL APPROACH; Goldberg A., 2006, Constructions at work: The nature of generalization in language; Goldberg Adele E., 1995, CONSTRUCTIONS CONSTR; Grabar N, 2023, TOP ENGL LINGUIST, V110, P199, DOI 10.1515/9783110734157-008; Hilpert M., 2013, Z LITERATURWISSENSCH, V42, P67, DOI DOI 10.1007/BF03379873; Hilpert M, 2023, TOP ENGL LINGUIST, V110, P254, DOI 10.1515/9783110734157-010; Hilpert M, 2022, CONSTR FRAMES, V14, P13, DOI 10.1075/cf.00056.hil; Hoffemeyer J., 2008, BIOSEMIOTICS EXAMINA; Huber E, 2024, NEUROBIOL LANG, V5, P167, DOI 10.1162/nol_a_00121; Hufeld C, 2023, TOP ENGL LINGUIST, V110, P177, DOI 10.1515/9783110734157-007; Jackendoff Ray., 2012, A User's Guide to Thought and Meaning; Jary M., 2022, NOTHING IS SAID UTTE, DOI [10.1093/oso/9780192863188.001.0001, DOI 10.1093/OSO/9780192863188.001.0001]; Jiang N, 2007, MOD LANG J, V91, P433, DOI 10.1111/j.1540-4781.2007.00589.x; Leclercq B, 2022, ENGL LANG LINGUIST, V26, P27, DOI 10.1017/S1360674320000489; Leone Massimo, 2023, Lang Semiot Stud, V9, P1, DOI 10.1515/lass-2022-0006; Lewis David, 2002, Convention: A philosophical study, DOI [DOI 10.1002/9780470693711, 10.1002/9780470693711.]; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Ludlow P., 2022, LANGUAGE FORM LOGIC, DOI [10.1093/oso/9780199591534.001.0001, DOI 10.1093/OSO/9780199591534.001.0001]; Magnani L, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20060430; Nekrasova TM, 2009, LANG LEARN, V59, P647, DOI 10.1111/j.1467-9922.2009.00520.x; Nowakowski PR, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070295; OdlingSmee FJ, 1996, AM NAT, V147, P641, DOI 10.1086/285870; Parfit D., 1984, Reasons and Persons; Peng Y, 2019, LECT NOTES ARTIF INT, V11741, P37, DOI 10.1007/978-3-030-27532-7_4; Petrilli S, 2015, BIOSEMIOTICS-SER, V13, P47, DOI 10.1007/978-3-319-20663-9_4; Piantadosi S., 2023, LingBuzz; Pietarinen AV, 2021, BIOSEMIOTICS-NETH, V14, P499, DOI 10.1007/s12304-021-09432-0; Romanini V, 2023, TRANSDISCIPLINARY J, DOI [10.53987/2178-5368-2023-12-08, DOI 10.53987/2178-5368-2023-12-08]; Romano D, 2019, BIOL CYBERN, V113, P201, DOI 10.1007/s00422-018-0787-5; Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1; Schmid H.-J., 2020, DYNAMICS LINGUISTIC; Sharov A., 2021, SEMIOTIC AGENCY SCI, DOI [10.1007/978-3-030-89484-9, DOI 10.1007/978-3-030-89484-9]; Sharov AA, 2018, J COGN SCI, V19, P195; Silvennoinen O., 2023, CONSTRUCTIONS, V15, DOI [10.24338/cons-544, DOI 10.24338/CONS-544]; Tonnessen M., 2015, JAKOB UEXKULL DISCOV, P1, DOI DOI 10.1007/978-94-017-9688-0_1; Torres-Martinez S., 2018, COGN SEMANT, V4, P1, DOI [10.1163/23526416-00401001, DOI 10.1163/23526416-00401001]; Torres-Martínez S, 2024, SEMIOTICA, V2024, P141, DOI 10.1515/sem-2018-0138; Torres-Martínez S, 2023, BIOSEMIOTICS-NETH, V16, P415, DOI 10.1007/s12304-023-09546-7; Torres-Martinez S, 2023, COGN SEMANT, V9, P132, DOI 10.1163/23526416-bja10035; Torres-Martínez S, 2021, SEMIOTICA, P63, DOI 10.1515/sem-2019-0113; Wang J., 2021, Biomimetic Intell. Robot, V1, DOI DOI 10.1016/J.BIROB.2021.100001; Wilson M., 2022, IMITATION RIGOR ALTE; Winter B, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13254; Wittgenstein L., 1984, WERKAUSGABE BAND 1 T; Woodin G, 2024, CORPUS LINGUIST LING, V20, P123, DOI 10.1515/cllt-2022-0082; Zhou ZY, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e11499	66	1	1	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1875-1342	1875-1350		BIOSEMIOTICS-NETH	Biosemiotics	APR	2024	17	1			SI		185	209		10.1007/s12304-024-09553-2	http://dx.doi.org/10.1007/s12304-024-09553-2		FEB 2024	25	Humanities, Multidisciplinary; History & Philosophy Of Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; History & Philosophy of Science	OX6U7					2024-07-03	WOS:001158259900001
J	Rao, A; Kim, J; Lie, W; Pang, M; Fuh, L; Dreyer, KJ; Succi, MD				Rao, Arya; Kim, John; Lie, Winston; Pang, Michael; Fuh, Lanting; Dreyer, Keith J.; Succi, Marc D.			Proactive Polypharmacy Management Using Large Language Models: Opportunities to Enhance Geriatric Care	JOURNAL OF MEDICAL SYSTEMS			English	Article						Artificial intelligence; Large language models; Polypharmacy; Primary care		Polypharmacy remains an important challenge for patients with extensive medical complexity. Given the primary care shortage and the increasing aging population, effective polypharmacy management is crucial to manage the increasing burden of care. The capacity of large language model (LLM)-based artificial intelligence to aid in polypharmacy management has yet to be evaluated. Here, we evaluate ChatGPT's performance in polypharmacy management via its deprescribing decisions in standardized clinical vignettes. We inputted several clinical vignettes originally from a study of general practicioners' deprescribing decisions into ChatGPT 3.5, a publicly available LLM, and evaluated its capacity for yes/no binary deprescribing decisions as well as list-based prompts in which the model was prompted to choose which of several medications to deprescribe. We recorded ChatGPT responses to yes/no binary deprescribing prompts and the number and types of medications deprescribed. In yes/no binary deprescribing decisions, ChatGPT universally recommended deprescribing medications regardless of ADL status in patients with no overlying CVD history; in patients with CVD history, ChatGPT's answers varied by technical replicate. Total number of medications deprescribed ranged from 2.67 to 3.67 (out of 7) and did not vary with CVD status, but increased linearly with severity of ADL impairment. Among medication types, ChatGPT preferentially deprescribed pain medications. ChatGPT's deprescribing decisions vary along the axes of ADL status, CVD history, and medication type, indicating some concordance of internal logic between general practitioners and the model. These results indicate that specifically trained LLMs may provide useful clinical support in polypharmacy management for primary care physicians.	[Rao, Arya; Kim, John; Lie, Winston; Pang, Michael; Dreyer, Keith J.; Succi, Marc D.] Harvard Med Sch, Boston, MA 02115 USA; [Rao, Arya; Kim, John; Lie, Winston; Pang, Michael; Succi, Marc D.] Massachusetts Gen Hosp, Innovat Operat Res Ctr MESH IO, Medically Engn Solut Healthcare Incubator, Boston, MA 02114 USA; [Rao, Arya; Kim, John; Lie, Winston; Pang, Michael; Fuh, Lanting; Succi, Marc D.] Massachusetts Gen Hosp, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA; [Dreyer, Keith J.] Data Sci Off, Mass Gen Brigham, Boston, MA USA	Harvard University; Harvard Medical School; Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital	Succi, MD (corresponding author), Harvard Med Sch, Boston, MA 02115 USA.; Succi, MD (corresponding author), Massachusetts Gen Hosp, Innovat Operat Res Ctr MESH IO, Medically Engn Solut Healthcare Incubator, Boston, MA 02114 USA.; Succi, MD (corresponding author), Massachusetts Gen Hosp, Dept Radiol, 55 Fruit St, Boston, MA 02114 USA.	msucci@mgh.harvard.edu		Kim, John/0000-0003-4252-5916	National Institute of General Medical Sciences	National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	No Statement Available	Alvis Bret D, 2015, Anesthesiol Clin, V33, P447, DOI 10.1016/j.anclin.2015.05.003; [Anonymous], 2022, Ageing and health; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Barnett ML, 2021, ANN INTERN MED, V174, P1658, DOI 10.7326/M21-1523; Bicket Mark C, 2015, Anesthesiol Clin, V33, P577, DOI 10.1016/j.anclin.2015.05.011; Frantsve LME, 2007, PAIN MED, V8, P25, DOI 10.1111/j.1526-4637.2007.00250.x; Halli-Tierney AD, 2019, AM FAM PHYSICIAN, V100, P32; Herr M, 2017, EUR J CLIN PHARMACOL, V73, P601, DOI 10.1007/s00228-016-2193-z; Huang YH, 2023, Arxiv, DOI arXiv:2307.10236; Jungo KT, 2021, BMC GERIATR, V21, DOI 10.1186/s12877-020-01953-6; Koranteng Erica, 2023, JMIR Med Educ, V9, pe51199, DOI 10.2196/51199; Levine DM, 2020, JAMA INTERN MED, V180, P463, DOI 10.1001/jamainternmed.2019.6282; Mantelli S, 2018, BMC FAM PRACT, V19, DOI 10.1186/s12875-018-0856-9; Molokhia M, 2017, BMC FAM PRACT, V18, DOI 10.1186/s12875-017-0642-0; Morin L, 2018, CLIN EPIDEMIOL, V10, P289, DOI 10.2147/CLEP.S153458; Page AT, 2016, MATURITAS, V91, P115, DOI 10.1016/j.maturitas.2016.06.006; Rao A., 2002, medRxiv. 2023, V2023; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Rao Arya S., 2023, medRxiv	19	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	APR 18	2024	48	1							41	10.1007/s10916-024-02058-y	http://dx.doi.org/10.1007/s10916-024-02058-y			5	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	OB5K4	38632172				2024-07-03	WOS:001204811400001
C	Moiseev, F; Dong, Z; Alfonseca, E; Jaggi, M			ASSOC COMPUTAT LINGUIST	Moiseev, Fedor; Dong, Zhe; Alfonseca, Enrique; Jaggi, Martin			SKILL: Structured Knowledge Infusion for Large Language Models	NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES			English	Proceedings Paper	Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies	JUL 10-15, 2022	Seattle, WA	Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data				Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pretrained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3x improvement of exact match score on MetaQA task compared to T5 baseline. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs.	[Moiseev, Fedor; Jaggi, Martin] Ecole Polytech Fed Lausanne, Lausanne, Switzerland; [Moiseev, Fedor; Dong, Zhe; Alfonseca, Enrique] Google, Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Google Incorporated	Dong, Z (corresponding author), Google, Zurich, Switzerland.	femoiseev@google.com; zhedong@google.com; ealfonseca@google.com; martin.jaggi@epfl.ch		Jaggi, Martin/0000-0003-1579-5558				Agarwal O, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3554; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Brown TS, 2020, NEW APP EUR HIST, P33; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fevry Thibault, 2020, EMNLP, P4937, DOI 10.18653/v1/2020.emnlp-main.400; Guu K., 2020, INT C MACHINE LEARNI, P3929; He B, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2281; Heinzerline B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1772; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jiang K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P318; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Miller A., 2016, P 2016 C EMPIRICAL M, P1400, DOI 10.18653/v1/D16-1147; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Oguz Barlas, 2020, ARXIV201214610; Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43; Raffel Colin, 2019, ABS191010683 CORR; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Ruder S, 2019, P C N AM CHAPT ASS C, P15, DOI [10.18653/v1/N19-5004, DOI 10.18653/V1/N19-5004]; Sap Maarten, 2019, P AAAI C ARTIFICIAL, V33; Shazeer N., 2018, ABS180404235 CORR; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Sun Y., 2021, ARXIV210702137; Vaswani A, 2017, ADV NEUR IN, V30; Verga P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3678; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Welbl J., 2018, T ASS COMPUTATIONAL, V6, P287, DOI DOI 10.1162/TACL_A_00021; Yu Donghan, 2021, ARXIV211004330; Zhang Y, 2018, AAAI CONF ARTIF INTE, P2620	31	4	4	0	5	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-71-1				2022							1581	1588						8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9EE					2024-07-03	WOS:000859869501048
J	Liu, SR; Wright, AP; Patterson, BL; Wanderer, JP; Turer, RW; Nelson, SD; McCoy, AB; Sittig, DF; Wright, A				Liu, Siru; Wright, Aileen P.; Patterson, Barron L.; Wanderer, Jonathan P.; Turer, Robert W.; Nelson, Scott D.; McCoy, Allison B.; Sittig, Dean F.; Wright, Adam			Using AI-generated suggestions from ChatGPT to optimize clinical decision support	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						artificial intelligence; clinical decision support; large language model	ALERTS; DISPARITIES; SYSTEMS	Objective To determine if ChatGPT can generate useful suggestions for improving clinical decision support (CDS) logic and to assess noninferiority compared to human-generated suggestions. Methods We supplied summaries of CDS logic to ChatGPT, an artificial intelligence (AI) tool for question answering that uses a large language model, and asked it to generate suggestions. We asked human clinician reviewers to review the AI-generated suggestions as well as human-generated suggestions for improving the same CDS alerts, and rate the suggestions for their usefulness, acceptance, relevance, understanding, workflow, bias, inversion, and redundancy. Results Five clinicians analyzed 36 AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. The suggestions generated by AI were found to offer unique perspectives and were evaluated as highly understandable and relevant, with moderate usefulness, low acceptance, bias, inversion, redundancy. Conclusion AI-generated suggestions could be an important complementary part of optimizing CDS alerts, can identify potential improvements to alert logic and support their implementation, and may even be able to assist experts in formulating their own suggestions for CDS improvement. ChatGPT shows great potential for using large language models and reinforcement learning from human feedback to improve CDS alert logic and potentially other medical areas involving complex, clinical logic, a key step in the development of an advanced learning health system.	[Liu, Siru; Wright, Aileen P.; Wanderer, Jonathan P.; Nelson, Scott D.; McCoy, Allison B.; Wright, Adam] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN USA; [Wright, Aileen P.] Vanderbilt Univ, Dept Med, Med Ctr, Nashville, TN USA; [Patterson, Barron L.] Vanderbilt Univ, Dept Pediat, Med Ctr, Nashville, TN USA; [Wanderer, Jonathan P.] Vanderbilt Univ, Med Ctr, Dept Anesthesiol, Nashville, TN USA; [Turer, Robert W.] Univ Texas Southwestern Med Ctr, Dept Emergency Med, Dallas, TX USA; [Turer, Robert W.] Univ Texas Southwestern Med Ctr, Clin Informat Ctr, Dallas, TX USA; [Sittig, Dean F.] Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, Houston, TX USA; [Liu, Siru] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA	Vanderbilt University; Vanderbilt University; Vanderbilt University; Vanderbilt University; University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Texas System; University of Texas Health Science Center Houston; Vanderbilt University	Liu, SR (corresponding author), Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA.	siru.liu@vumc.org	Patterson, Barron/KQO-8922-2024; Nelson, Scott/I-7607-2019; Sittig, Dean Forrest/D-2471-2009; McCoy, Allison/I-1951-2013	Patterson, Barron/0000-0001-9155-6220; Nelson, Scott/0000-0002-1941-1817; Sittig, Dean Forrest/0000-0001-5811-8915; Turer, Robert/0000-0003-1387-640X; McCoy, Allison/0000-0003-2292-9147	NIH [K99LM014097-01, R01AG062499-01, R01LM013995-01]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by NIH grant numbers: K99LM014097-01, R01AG062499-01, and R01LM013995-01.	Bright TJ, 2012, ANN INTERN MED, V157, P29, DOI 10.7326/0003-4819-157-1-201207030-00450; Brown TB., ARXIV; Clinical Decision Support (CDS), ABOUT US; Craig KJT, 2020, CARDIOVASC DIGIT HLT, V1, P139, DOI 10.1016/j.cvdhj.2020.11.001; Croskerry P, 2013, NEW ENGL J MED, V368, P2445, DOI 10.1056/NEJMp1303712; Daniels CC, 2019, PEDIATRICS, V143, DOI 10.1542/peds.2017-4111; De Winter JC., 2010, PRACT ASSESS RES EVA, V15, P1, DOI DOI 10.7275/BJ1P-TS64; Dhaliwal G, 2017, BMJ QUAL SAF, V26, P87, DOI 10.1136/bmjqs-2016-005267; Friedman CP, 2009, J AM MED INFORM ASSN, V16, P169, DOI 10.1197/jamia.M3092; Horn J, 2019, ANN PHARMACOTHER, V53, P1087, DOI 10.1177/1060028019863419; Jeblick K., CHATGPT MAKES MED EA; Kane-Gill SL, 2017, CRIT CARE MED, V45, P1481, DOI 10.1097/CCM.0000000000002580; Kawamoto K, 2005, BMJ-BRIT MED J, V330, P765, DOI 10.1136/bmj.38398.500764.8F; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lau BD, 2015, MED CARE, V53, P18, DOI 10.1097/MLR.0000000000000251; Liu SR, 2022, J AM MED INFORM ASSN, V29, P891, DOI 10.1093/jamia/ocab292; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; McCoy AB, 2022, J AM MED INFORM ASSN, V29, P1050, DOI 10.1093/jamia/ocac027; Medenilla A., 2023, PLoS Digital Health, V2; Mitchell J, 2014, J RURAL HEALTH, V30, P186, DOI 10.1111/jrh.12043; Olakotan OO, 2020, J BIOMED INFORM, V106, DOI 10.1016/j.jbi.2020.103453; openai, CHATGPT OPT LANG MOD; Ouyang L., ARXIV; Parke C, 2015, AM J HEALTH-SYST PH, V72, P144, DOI 10.2146/ajhp140095; Paterno MD, 2009, J AM MED INFORM ASSN, V16, P40, DOI 10.1197/jamia.M2808; Powers EM, 2018, J AM MED INFORM ASSN, V25, P1556, DOI 10.1093/jamia/ocy112; Reese T, 2022, AM J HEALTH-SYST PH, V79, P1086, DOI 10.1093/ajhp/zxac045; Seidling HM, 2014, INT J MED INFORM, V83, P285, DOI 10.1016/j.ijmedinf.2013.12.006; Shou Y., 2022, REFERENCE MODULE NEU, P13, DOI [DOI 10.1016/B978-0-12-818697-8.00110-2, 10.1016/B978-0-12-818697-8.00110-2]; Sirajuddin Anwar M, 2009, J Healthc Inf Manag, V23, P38; Sorace J, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2019.104037; Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748; Van der Sijs H, 2006, J AM MED INFORM ASSN, V13, P138, DOI 10.1197/jamia.M1809; Weingart SN, 2003, ARCH INTERN MED, V163, P2625, DOI 10.1001/archinte.163.21.2625; Willits F. K., 2016, Journal of Rural Social Sciences, V31, P126; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Ye Cheng, 2018, AMIA Jt Summits Transl Sci Proc, V2017, P273	38	87	87	92	225	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	JUN 20	2023	30	7					1237	1245		10.1093/jamia/ocad072	http://dx.doi.org/10.1093/jamia/ocad072		APR 2023	9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	K3DM5	37087108	Green Published, hybrid			2024-07-03	WOS:000974348900001
J	Miao, J; Thongprayoon, C; Suppadungsuk, S; Krisanapan, P; Radhakrishnan, Y; Cheungpasitporn, W				Miao, Jing; Thongprayoon, Charat; Suppadungsuk, Supawadee; Krisanapan, Pajaree; Radhakrishnan, Yeshwanter; Cheungpasitporn, Wisit			Chain of Thought Utilization in Large Language Models and Application in Nephrology	MEDICINA-LITHUANIA			English	Review						artificial intelligence; chain-of-thought prompting; large language models (LLMs); enhanced care; nephrology; decision-making process	AI	Chain-of-thought prompting enhances the abilities of large language models (LLMs) significantly. It not only makes these models more specific and context-aware but also impacts the wider field of artificial intelligence (AI). This approach broadens the usability of AI, increases its efficiency, and aligns it more closely with human thinking and decision-making processes. As we improve this method, it is set to become a key element in the future of AI, adding more purpose, precision, and ethical consideration to these technologies. In medicine, the chain-of-thought prompting is especially beneficial. Its capacity to handle complex information, its logical and sequential reasoning, and its suitability for ethically and context-sensitive situations make it an invaluable tool for healthcare professionals. Its role in enhancing medical care and research is expected to grow as we further develop and use this technique. Chain-of-thought prompting bridges the gap between AI's traditionally obscure decision-making process and the clear, accountable standards required in healthcare. It does this by emulating a reasoning style familiar to medical professionals, fitting well into their existing practices and ethical codes. While solving AI transparency is a complex challenge, the chain-of-thought approach is a significant step toward making AI more comprehensible and trustworthy in medicine. This review focuses on understanding the workings of LLMs, particularly how chain-of-thought prompting can be adapted for nephrology's unique requirements. It also aims to thoroughly examine the ethical aspects, clarity, and future possibilities, offering an in-depth view of the exciting convergence of these areas.	[Miao, Jing; Thongprayoon, Charat; Suppadungsuk, Supawadee; Krisanapan, Pajaree; Radhakrishnan, Yeshwanter; Cheungpasitporn, Wisit] Mayo Clin, Div Nephrol & Hypertens, Dept Med, Rochester, MN 55905 USA; [Suppadungsuk, Supawadee] Mahidol Univ, Fac Med, Chakri Naruebodindra Med Inst, Ramathibodi Hosp, Samut Prakan 10540, Thailand; [Krisanapan, Pajaree] Thammasat Univ, Fac Med, Dept Internal Med, Div Nephrol, Pathum Thani 12120, Thailand; [Krisanapan, Pajaree] Thammasat Univ Hosp, Dept Internal Med, Div Nephrol, Pathum Thani 12120, Thailand	Mayo Clinic; Mahidol University; Thammasat University; Thammasat University	Thongprayoon, C (corresponding author), Mayo Clin, Div Nephrol & Hypertens, Dept Med, Rochester, MN 55905 USA.	charat.thongprayoon@gmail.com	Miao, Jing/IWE-2204-2023; Krisanapan, Pajaree/GOH-1278-2022; Thongprayoon, Charat/J-4184-2019; suppadungsuk, supawadee/ISU-2478-2023; Miao, Jing/IWE-2159-2023; Cheungpasitporn, Wisit/H-8194-2019	Krisanapan, Pajaree/0000-0002-2888-881X; Thongprayoon, Charat/0000-0002-8313-3604; Miao, Jing/0000-0003-0642-9740; Cheungpasitporn, Wisit/0000-0001-9954-9711				Aalami O, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad044; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aiumtrakul N, 2023, J PERS MED, V13, DOI 10.3390/jpm13101457; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Buckley T., 2023, arXiv; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Daugirdas JT, 2023, AM J KIDNEY DIS, V82, pA13, DOI 10.1053/j.ajkd.2023.04.006; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; docs.ai21, AI21 Studio Documentation; Duda SN, 2022, J AM MED INFORM ASSN, V29, P1642, DOI 10.1093/jamia/ocac105; Eisenstein M, 2023, NAT BIOTECHNOL, V41, P303, DOI 10.1038/s41587-023-01705-y; Evans R S, 2016, Yearb Med Inform, VSuppl 1, pS48, DOI 10.15265/IYS-2016-s006; Frackiewicz M., ChatGPT for Diagnosis of Kidney Diseases: Advancements and Limitations; Fu CY, 2024, Arxiv, DOI arXiv:2306.13394; Hueso M, 2023, REV INVEST CLIN, V75, P309, DOI 10.24875/RIC.23000162; Jeyaraman Madhan, 2023, World J Methodol, V13, P170, DOI 10.5662/wjm.v13.i4.170; Joshi G, 2023, medRxiv, DOI [10.1101/2022.12.07.22283216, 10.1101/2022.12.07.22283216, DOI 10.1101/2022.12.07.22283216]; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Khawaja R., 2023, Sentiment Analysis: Marketing with Large Language Models (LLMs); Knoppers BM, 2023, ANNU REV GENOM HUM G, V24, P369, DOI 10.1146/annurev-genom-101322-113255; LaMDA, Towards Safe, Grounded, and High-Quality Dialog Models for Everything; Lemley KV, 2024, J AM SOC NEPHROL, V35, P232, DOI 10.1681/ASN.0000000000000237; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mayo M., Unraveling the Power of Chain-of-Thought Prompting in Large Language Models; Miao J, 2023, J PERS MED, V13, DOI 10.3390/jpm13121681; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; Miao J, 2023, KIDNEY INT REP, V8, P1657, DOI 10.1016/j.ekir.2023.05.014; Oeze C., The Importance of Chain-of-Thought Prompting; openai, OpenAI Introducing ChatGPT; Ott S, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02433-3; Pal A, 2023, Arxiv, DOI [arXiv:2307.15343, 10.48550/arXiv.2307.15343]; Perez R, 2023, J CHEM INF MODEL, V63, P5727, DOI 10.1021/acs.jcim.3c00817; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Ramlochan S., Master Prompting Concepts: Zero-Shot and Few-Shot Prompting; Shin E, 2024, J PHARMACOKINET PHAR, V51, P101, DOI 10.1007/s10928-023-09892-6; Shum K, 2024, Arxiv, DOI arXiv:2302.12822; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Suppadungsuk Supawadee, 2023, Medicines (Basel), V10, DOI 10.3390/medicines10100058; Suppadungsuk S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12175550; Sydorenko P., Top 5 Applications Of Large Language Models (Llms) in Legal Practice; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Valencia OAG, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11182518; Valencia OAG, 2023, J PERS MED, V13, DOI 10.3390/jpm13091363; Wadhwa S, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15566, DOI 10.18653/v1/2023.acl-long.868; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wolff T., How to Craft Prompts for Maximum Effectiveness; Wu CK, 2023, Arxiv, DOI arXiv:2307.08922; Yang Rui, 2023, Health Care Sci, V2, P255, DOI 10.1002/hcs2.61; Yano Y, 2024, HYPERTENSION, V81, pE1, DOI 10.1161/HYPERTENSIONAHA.123.22084; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	52	5	5	36	36	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1010-660X	1648-9144		MEDICINA-LITHUANIA	Med. Lith.	JAN	2024	60	1							148	10.3390/medicina60010148	http://dx.doi.org/10.3390/medicina60010148			19	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	GE7R1	38256408	gold			2024-07-03	WOS:001151060000001
J	Rambelli, G; Chersoni, E; Testa, D; Blache, P; Lenci, A				Rambelli, Giulia; Chersoni, Emmanuele; Testa, Davide; Blache, Philippe; Lenci, Alessandro			Neural Generative Models and the Parallel Architecture of Language: A Critical Review and Outlook	TOPICS IN COGNITIVE SCIENCE			English	Article; Early Access						Neural large language models; Statistical learning; Parallel architecture; Syntax-semantics interface; GPT-3 prompting; Enriched composition; Semantic composition		According to the parallel architecture, syntactic and semantic information processing are two separate streams that interact selectively during language comprehension. While considerable effort is put into psycho- and neurolinguistics to understand the interchange of processing mechanisms in human comprehension, the nature of this interaction in recent neural Large Language Models remains elusive. In this article, we revisit influential linguistic and behavioral experiments and evaluate the ability of a large language model, GPT-3, to perform these tasks. The model can solve semantic tasks autonomously from syntactic realization in a manner that resembles human behavior. However, the outcomes present a complex and variegated picture, leaving open the question of how Language Models could learn structured conceptual representations. LLMs like GPT-3 show human-like behavior in solving some semantic tasks autonomously from syntax, exhibiting alignment with the parallel architecture. Yet LLMs struggle with tasks like interpreting elliptical gaps or scrambled sentences, indicating a need to further explore their ability to understand structured conceptual representations.	[Rambelli, Giulia] Univ Bologna, Dept Modern Languages Literatures & Cultures, Bologna, Italy; [Chersoni, Emmanuele] Hong Kong Polytech Univ, Dept Chinese & Bilingual Studies, Hong Kong, Peoples R China; [Testa, Davide] Fdn Bruno Kessler, Trento, Italy; [Blache, Philippe] Lab Parole & Langage, CNRS, Marseille, France; [Lenci, Alessandro] Univ Pisa, Dept Philol Literature & Linguist, Pisa, Italy; [Chersoni, Emmanuele] Hong Kong Polytech Univ, Kowloon, 11 Yuk Choi Kowloon, Hong Kong, Peoples R China	University of Bologna; Hong Kong Polytechnic University; Fondazione Bruno Kessler; Centre National de la Recherche Scientifique (CNRS); Aix-Marseille Universite; University of Pisa; Hong Kong Polytechnic University	Chersoni, E (corresponding author), Hong Kong Polytech Univ, Kowloon, 11 Yuk Choi Kowloon, Hong Kong, Peoples R China.	emmanuele.chersoni@polyu.edu.hk		LENCI, ALESSANDRO/0000-0001-5790-4308; Chersoni, Emmanuele/0000-0001-8742-0451	Research Grants Council, University Grants Committee [15612222]; GRF grant from the Research Grants Council of the Hong Kong Special Administrative Region, China [F-PolyU501/21]; PROCORE France/Hong Kong Joint Research Scheme; European Commission under the NextGeneration EU programme	Research Grants Council, University Grants Committee; GRF grant from the Research Grants Council of the Hong Kong Special Administrative Region, China; PROCORE France/Hong Kong Joint Research Scheme; European Commission under the NextGeneration EU programme	We thank the three anonymous reviewers for their useful comments and suggestions. EC was supported by a GRF grant from the Research Grants Council of the Hong Kong Special Administrative Region, China (Project No. PolyU 15612222) and by a grant from the PROCORE France/Hong Kong Joint Research Scheme (Project No. F-PolyU501/21). This research was also partly funded by PNRR-M4C2-Investimento 1.3, Partenariato Esteso PE00000013-"FAIR-Future Artificial Intelligence Research"-Spoke 1 "Human-centered AI," funded by the European Commission under the NextGeneration EU programme. This work was carried out while DT was enrolled in the Italian National Doctorate on Artificial Intelligence run by Sapienza University of Rome in collaboration with Fondazione Bruno Kessler.	Andreas J, 2022, FINDINGS ASS COMPUTA, P5769; [Anonymous], 2020, Proceedings of AACL-IJCNLP; Baggio G., 2018, MEANING BRAIN, DOI DOI 10.7551/MITPRESS/11265.003.0016; Baggio G, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12949; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bommasani R., 2020, P 58 ANN M ASS COMP, P4758, DOI DOI 10.18653/V1/2020.ACL-MAIN.431; Bowman Samuel R., 2019, INT C LEARN REPR, P1; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buijtelaar L., 2023, Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, P2222; Bybee Joan, 2010, LANGUAGE USAGE COGNI; Chang TA., 2024, Comput. Linguist, V50, P1; Cong Y., 2023, Proceedings of the 12th Joint Conference on Lexical and Computational Semantics, P141; Culicover P., 2005, SIMPLER SYNTAX, DOI DOI 10.1093/ACPROF:OSO/9780199271092.001.0001; Culicover PW, 2006, TRENDS COGN SCI, V10, P413, DOI 10.1016/j.tics.2006.07.007; Dankers V, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3608; Elman J. L., 1996, Rethinking innateness: A connectionist perspective on development, Vvolume 10; Glavas G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3090; Goldberg AE, 2019, EXPLAIN ME THIS: CREATIVITY, COMPETITION, AND THE PARTIAL PRODUCTIVITY OF CONSTRUCTIONS, P1; Goldberg Y., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1901.05287; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Hale J, 2001, 2ND MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P159; Hegel G. W. F., 1807, PHENOMENOLOGY SPIRIT; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hu J, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4194; Jackendoff R., 1997, ARCHITECTURE LANGUAG; Jackendoff R, 2007, BRAIN RES, V1146, P2, DOI 10.1016/j.brainres.2006.08.111; Kauf C, 2024, Arxiv, DOI arXiv:2403.14859; Kauf C, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13386; Kim A, 2005, J MEM LANG, V52, P205, DOI 10.1016/j.jml.2004.10.002; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lenci A., 2023, Distributional semantics; Lenci A, 2023, Arxiv, DOI arXiv:2303.04229; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Li B., 2022, Proceedings of ACL, P7410; Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Liu A., 2023, Proceedings of EMNLP 2023; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; McCoy RT, 2023, Arxiv, DOI [arXiv:2309.13638, 10.48550/arXiv.2309.13638]; McShane M., 2005, A theory of ellipsis; Michaelov J., 2022, NeurIPS 2022 Workshop on Information-Theoretic Principles in Cognitive Systems; Michalon O, 2019, NEUROPSYCHOLOGIA, V131, P171, DOI 10.1016/j.neuropsychologia.2019.05.009; Miletic F, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1499; Mollica F, 2020, NEUROBIOL LANG, V1, P104, DOI 10.1162/nol_a_00005; Nedumpozhimana V, 2021, MWE 2021: THE 17TH WORKSHOP ON MULTIWORD EXPRESSIONS, P57; Ormerod M., 2024, Computational Linguistics, P1; Pedinotti P, 2021, 10TH CONFERENCE ON LEXICAL AND COMPUTATIONAL SEMANTICS (SEM 2021), P1; Pezzelle S, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P12098; Piantadosi S., 2023, Lingbuzz, P7180; Prange J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4375; Pustejovsky J., 1995, GENERATIVE LEXICON; Rambelli G., 2023, Proceedings of the 19th Workshop on Multiword Expressions (MWE 2023), P87; Ruis Laura, 2022, Large language models are not zero-shot communicators; Schlangen D., 2022, Proceedings of the 2022 CLASP Conference on (Dis)embodiment, P62; Testa D, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P3340; Vaswani A, 2017, ADV NEUR IN, V30; Vulie I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7222; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]	60	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1756-8757	1756-8765		TOP COGN SCI	Top. Cogn. Sci.	2024 APR 18	2024										10.1111/tops.12733	http://dx.doi.org/10.1111/tops.12733		APR 2024	14	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	OB7B1	38635667	hybrid			2024-07-03	WOS:001204854200001
J	Yuan, XM; Kong, WX; Luo, ZY; Xu, MR				Yuan, Xiaoming; Kong, Weixuan; Luo, Zhenyu; Xu, Minrui			Efficient Inference Offloading for Mixture-of-Experts Large Language Models in Internet of Medical Things	ELECTRONICS			English	Article						large language models; efficient inference offloading; mixture-of-experts; Internet of Medical Things		Despite recent significant advancements in large language models (LLMs) for medical services, the deployment difficulties of LLMs in e-healthcare hinder complex medical applications in the Internet of Medical Things (IoMT). People are increasingly concerned about e-healthcare risks and privacy protection. Existing LLMs face difficulties in providing accurate medical questions and answers (Q&As) and meeting the deployment resource demands in the IoMT. To address these challenges, we propose MedMixtral 8x7B, a new medical LLM based on the mixture-of-experts (MoE) architecture with an offloading strategy, enabling deployment on the IoMT, improving the privacy protection for users. Additionally, we find that the significant factors affecting latency include the method of device interconnection, the location of offloading servers, and the speed of the disk.	[Yuan, Xiaoming; Kong, Weixuan; Luo, Zhenyu] Northeastern Univ Qinhuangdao, Hebei Key Lab Marine Percept Network & Data Proc, Qinhuangdao 066004, Peoples R China; [Yuan, Xiaoming] Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China; [Xu, Minrui] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore	Northeastern University - China; Xidian University; Nanyang Technological University	Yuan, XM (corresponding author), Northeastern Univ Qinhuangdao, Hebei Key Lab Marine Percept Network & Data Proc, Qinhuangdao 066004, Peoples R China.; Yuan, XM (corresponding author), Xidian Univ, State Key Lab Integrated Serv Networks, Xian 710071, Peoples R China.	yuanxiaoming@neuq.edu.cn; 202112001@stu.neuq.edu.cn; 2272213@stu.neu.edu.cn; minrui001@e.ntu.edu.sg		Yuan, Xiaoming/0000-0001-8006-364X	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	We would like to thank the editors and the anonymous reviewers for their insightful comments and constructive suggestions.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amin SU, 2021, IEEE ACCESS, V9, P45, DOI 10.1109/ACCESS.2020.3045115; Ayed F, 2023, IEEE COMMUN MAG, V61, P104, DOI 10.1109/MCOM.001.2200358; Bariah L, 2023, IEEE GLOB COMM CONF, P6542, DOI 10.1109/GLOBECOM54140.2023.10437725; Bariah L, 2023, Arxiv, DOI arXiv:2306.10249; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du YY, 2023, Arxiv, DOI arXiv:2307.07319; Eliseev A, 2023, Arxiv, DOI arXiv:2312.17238; Fedus W, 2022, J MACH LEARN RES, V23; Gugger S., 2022, Accelerate: Training and inference at scale made simple, efficient and adaptable; Han PC, 2023, Arxiv, DOI arXiv:2312.12863; Han PC, 2020, INT CON DISTR COMP S, P300, DOI 10.1109/ICDCS47774.2020.00026; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Kwon W, 2023, PROCEEDINGS OF THE TWENTY-NINTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, SOSP 2023, P611, DOI 10.1145/3600006.3613165; Le Scao Teven, 2023, BLOOM: A 176B-parameter open-access multilingual language model; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Piovesan N, 2022, IEEE COMMUN MAG, V60, P56, DOI 10.1109/MCOM.001.2200023; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Soman S, 2023, Arxiv, DOI arXiv:2305.13102; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Xu MR, 2024, Arxiv, DOI arXiv:2403.05826; Xu MR, 2024, Arxiv, DOI arXiv:2401.07764; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T, 2023, IEEE J SEL AREA COMM, V41, P3293, DOI 10.1109/JSAC.2023.3310072; Zhang T, 2023, IEEE T INF FOREN SEC, V18, P5735, DOI 10.1109/TIFS.2023.3314219; Zhang T, 2023, IEEE T IND INFORM, V19, P1097, DOI 10.1109/TII.2022.3190556; Zhang ZY, 2021, AI OPEN, V2, P216, DOI 10.1016/j.aiopen.2021.12.003; Zhang ZY, 2021, AI OPEN, V2, P93, DOI 10.1016/j.aiopen.2021.07.001; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao YL, 2023, Arxiv, DOI [arXiv:2304.11277, 10.14778/3611540.3611569]	45	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2077	10.3390/electronics13112077	http://dx.doi.org/10.3390/electronics13112077			17	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UA2X9		gold			2024-07-03	WOS:001245288500001
J	Yu, P; Xu, H; Hu, X; Deng, C				Yu, Ping; Xu, Hua; Hu, Xia; Deng, Chao			Leveraging Generative AI and Large Language Models: A Comprehensive Roadmap for Healthcare Integration	HEALTHCARE			English	Review						generative artificial intelligence; generative AI; large language models; LLM; ethics; healthcare; medicine		Generative artificial intelligence (AI) and large language models (LLMs), exemplified by ChatGPT, are promising for revolutionizing data and information management in healthcare and medicine. However, there is scant literature guiding their integration for non-AI professionals. This study conducts a scoping literature review to address the critical need for guidance on integrating generative AI and LLMs into healthcare and medical practices. It elucidates the distinct mechanisms underpinning these technologies, such as Reinforcement Learning from Human Feedback (RLFH), including few-shot learning and chain-of-thought reasoning, which differentiates them from traditional, rule-based AI systems. It requires an inclusive, collaborative co-design process that engages all pertinent stakeholders, including clinicians and consumers, to achieve these benefits. Although global research is examining both opportunities and challenges, including ethical and legal dimensions, LLMs offer promising advancements in healthcare by enhancing data management, information retrieval, and decision-making processes. Continued innovation in data acquisition, model fine-tuning, prompt strategy development, evaluation, and system implementation is imperative for realizing the full potential of these technologies. Organizations should proactively engage with these technologies to improve healthcare quality, safety, and efficiency, adhering to ethical and legal guidelines for responsible application.	[Yu, Ping] Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia; [Xu, Hua] Yale Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St,Fl 9, New Haven, CT 06510 USA; [Hu, Xia] Rice Univ, Dept Comp Sci, POB 1892, Houston, TX 77251 USA; [Deng, Chao] Univ Wollongong, Sch Med Indigenous & Hlth Sci, Wollongong, NSW 2522, Australia	University of Wollongong; Yale University; Rice University; University of Wollongong	Yu, P (corresponding author), Univ Wollongong, Sch Comp & Informat Technol, Wollongong, NSW 2522, Australia.	ping@uow.edu.au; hua.xu@yale.edu; xia.hu@rice.edu; chao@uow.edu.au	Deng, Chao/F-4417-2016; Yu, Ping/B-1205-2008	Deng, Chao/0000-0003-1147-5741; Yu, Ping/0000-0002-7910-9396				Ahmad W, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-13658-4; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bommasani R., LANGUAGE MODELS ARE; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bumgardner VKC, 2023, Arxiv, DOI arXiv:2308.01727; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Casper S, 2023, Arxiv, DOI [arXiv:2307.15217, 10.48550/arXiv.2307.15217]; cdn.openai, OpenAI Gpt-4 System Card; Chen X, 2023, Arxiv, DOI arXiv:2306.15774; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chowdhury M., 2023, Can Large Language Models Safely Address Patient Questions Following Cataract Surgery, P131; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Du YQ, 2023, Arxiv, DOI arXiv:2302.06692; Duong D., 2023, medRxiv, DOI [10.1038/s41431-023-01396-8, DOI 10.1038/S41431-023-01396-8]; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Ge YQ, 2023, Arxiv, DOI [arXiv:2304.04370, 10.48550/arXiv.2304.04370]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; GOV.UK, 2023, A Pro-Innovation Approach to AI Regulation; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Heikkila M., 2022, MIT Technology Review; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Larsen B., 2023, GENERATIVE GAME CHAN; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu S., 2023, PREPRINT, DOI DOI 10.1101/2023.07.14.23292669; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Liu Y, 2023, Arxiv, DOI arXiv:2303.16634; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Manathunga S, 2023, Arxiv, DOI arXiv:2309.02884; Moy AJ, 2021, J AM MED INFORM ASSN, V28, P998, DOI 10.1093/jamia/ocaa325; OpenAI, 2022, Aligning Language Models to Follow Instructions; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pal A, 2023, Arxiv, DOI [arXiv:2307.15343, 10.48550/arXiv.2307.15343]; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Sorin V, 2021, RADIOLOGY, V301, DOI 10.1148/radiol.2021210566; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Taori R., Alpaca: A strong, replicable instructionfollowing model; The White House, 2023, Whitehouse.govJuly 31; van Eck NJ, 2017, SCIENTOMETRICS, V111, P1053, DOI 10.1007/s11192-017-2300-7; Wang BY, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3611651; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Williams T, 2015, J PATIENT SAF, V11, P52, DOI 10.1097/PTS.0b013e3182948ef9; Xu A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2390; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	60	13	14	106	172	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9032		HEALTHCARE-BASEL	Healthcare	OCT	2023	11	20							2776	10.3390/healthcare11202776	http://dx.doi.org/10.3390/healthcare11202776			19	Health Care Sciences & Services; Health Policy & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services	W2FH4	37893850	gold, Green Published			2024-07-03	WOS:001089835500001
J	Zhang, TY; Ladhak, F; Durmus, E; Liang, P; Mckeown, K; Hashimoto, TB				Zhang, Tianyi; Ladhak, Faisal; Durmus, Esin; Liang, Percy; Mckeown, Kathleen; Hashimoto, Tatsunori B.			Benchmarking Large Language Models for News Summarization	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								Large language models (LLMs) have shown promise for automatic summarization but the reasons behind their successes are poorly understood. By conducting a human evaluation on ten LLMs across different pretraining methods, prompts, and model scales, we make two important observations. First, we find instruction tuning, not model size, is the key to the LLM's zero-shot summarization capability. Second, existing studies have been limited by low-quality references, leading to underestimates of human performance and lower few-shot and finetuning performance. To better evaluate LLMs, we perform human evaluation over high-quality summaries we collect from freelance writers. Despite major stylistic differences such as the amount of paraphrasing, we find that LLM summaries are judged to be on par with human written summaries.	[Zhang, Tianyi; Durmus, Esin; Liang, Percy; Hashimoto, Tatsunori B.] Stanford Univ, Stanford, CA 94305 USA; [Ladhak, Faisal; Mckeown, Kathleen] Columbia Univ, New York, NY 10027 USA	Stanford University; Columbia University	Zhang, TY (corresponding author), Stanford Univ, Stanford, CA 94305 USA.; Ladhak, F (corresponding author), Columbia Univ, New York, NY 10027 USA.	tz58@stanford.edu; faisal@cs.columbia.edu			Open Philanthropy grant	Open Philanthropy grant	This work is supported by an Open Philanthropy grant and partially supported by a gift from Northrup Grumman. We thank the reviewers and editors for their comments, as well as the Stanford NLP group and the Stanford Center for Research on Foundation Models community for their feedback.	[Anonymous], 2022, Introduction to Large Language Models; [Anonymous], 2008, P ANN M ASS COMPUTAT, DOI DOI 10.3115/1557690.1557745; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Barzilay R, 2005, COMPUT LINGUIST, V31, P297, DOI 10.1162/089120105774321091; Barzilay Regina, 1999, P 37 ANN M ASS COMP, P550, DOI DOI 10.1115/10146781014760; Barzilay Regina., 1997, P ISTS ACL 1997; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen YC, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P675; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cohn Trevor, 2008, P 22 INT C COMP LING, V1, P137; Conroy J., 2006, P DOCUMENT UNDERSTAN, DOI [10.12968/sece.2006.11.755s, DOI 10.12968/SECE.2006.11.755S]; Deutsch Daniel, 2021, P 25 C COMP NAT LANG, P300; Dong L, 2019, Arxiv, DOI [arXiv:1905.03197, 10.48550/arXiv.1905.03197]; Durmus Esin., 2022, P 60 ANN M ASS COMPU, DOI [10.18653/v1/2022.acl-long.102, DOI 10.18653/V1/2022.ACL-LONG.102]; Durmus Esin., 2020, ACL, P5055, DOI 10.18653/v1/2020.acl-main.454; Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523; Fabbri A.R., 2021, arXiv; Fabbri AR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2587; Filippova Katja, 2008, Proceedings of the Conference on Empirical Methods in Natural Language Processing, P177, DOI 10.3115/1613715.1613741; Freitag M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P61; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Goyal Tanya, 2020, FINDINGS ASS COMPUTA, P3592; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Hermann KM, 2015, 29 ANN C NEURAL INFO, V28; Hovy E, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P81; Jing Hongyan., 2000, APPL NATURAL LANGUAG, DOI [10.3115/974147.974190, DOI 10.3115/974147.974190]; Jing HY, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA178; Jing HY, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P129, DOI 10.1145/312624.312666; Kang D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P718; Knight K, 2002, ARTIF INTELL, V139, P91, DOI 10.1016/S0004-3702(02)00222-9; Laban P, 2022, T ASSOC COMPUT LING, V10, P163, DOI 10.1162/tacl_a_00453; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin CY, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P457; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2890; Liu YX, 2023, Arxiv, DOI arXiv:2212.07981; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Mani I., 1999, Information Retrieval, V1, P35, DOI 10.1023/A:1009930203452; Marcu Daniel, 1997, Intelligent Scalable Text Summarization; Marsi Erwin., 2005, Proceedings of the European Workshop on Natural Language Generation, P109; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; McDonald R., 2006, 11th Conference of the European Chapter of the Association for Computational Linguistics, P297; Mihalcea Rada., 2005, Proceedings of the First International Conference on Intelligent Analysis Methods and Tools (IA 2005); Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Nenkova A., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P573, DOI 10.1145/1148170.1148269; Nenkova A, 2011, FOUND TRENDS INF RET, V5, P103, DOI 10.1561/1500000015; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Radev DR, 2002, COMPUT LINGUIST, V28, P399, DOI 10.1162/089120102762671927; Radev Dragomir R., 2000, NAACL ANLP 2000 WORK; Rush A. M., 2015, P 2015 C EMP METH NA, P379, DOI DOI 10.18653/V1/D15-1044; Salton G, 1997, INFORM PROCESS MANAG, V33, P193, DOI 10.1016/S0306-4573(96)00062-3; Sanh V, 2022, arXiv; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Silber HG, 2002, COMPUT LINGUIST, V28, P487, DOI 10.1162/089120102762671954; Steinberger J, 2007, INFORM PROCESS MANAG, V43, P1663, DOI 10.1016/j.ipm.2007.01.010; Stiennon N, 2022, Arxiv, DOI arXiv:2009.01325; Sutskever I, 2014, ADV NEUR IN, V27; Thadani Kapil., 2013, Proceedings of IJCNLP; Vasilyev O., 2020, P 1 WORKSHOP EVALUAT, P11; Wang YZ, 2022, Arxiv, DOI arXiv:2204.07705; Whiting M. E., 2019, P AAAI C HUM COMP CR, V7, DOI [10.1609/hcomp.v7i1.5283, DOI 10.1609/HCOMP.V7I1.5283]; Wu J., 2021, arXiv; Yuan WZ, 2021, Arxiv, DOI arXiv:2106.11520; Zhang J., 2020, ICML; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T., 2020, INT C LEARNING REPRE; Zhengxiao Du., 2021, ACL	73	1	1	26	26	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	JAN 31	2024	12						39	57		10.1162/tacl_a_00632	http://dx.doi.org/10.1162/tacl_a_00632			19	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	GV1C9		Green Submitted, gold			2024-07-03	WOS:001155346700003
J	Roh, J; Kim, M; Bae, K				Roh, Jihyeon; Kim, Minho; Bae, Kyoungman			Towards a small language model powered chain-of-reasoning for open-domain question answering	ETRI JOURNAL			English	Article						chain-of-reasoning; data augmentation; language models; open-domain question answering; question decomposition		We focus on open-domain question-answering tasks that involve a chain-of-reasoning, which are primarily implemented using large language models. With an emphasis on cost-effectiveness, we designed EffiChainQA, an architecture centered on the use of small language models. We employed a retrieval-based language model to address the limitations of large language models, such as the hallucination issue and the lack of updated knowledge. To enhance reasoning capabilities, we introduced a question decomposer that leverages a generative language model and serves as a key component in the chain-of-reasoning process. To generate training data for our question decomposer, we leveraged ChatGPT, which is known for its data augmentation ability. Comprehensive experiments were conducted using the HotpotQA dataset. Our method outperformed several established approaches, including the Chain-of-Thoughts approach, which is based on large language models. Moreover, our results are on par with those of state-of-the-art Retrieve-then-Read methods that utilize large language models. The emergence of large language models (LLMs) has led to the development of improved question-answering models. However, LLMs suffer from challenges such as hallucinations and outdated information issues. In response, researchers have developed a new open-domain question-answering model named "EffiChainQA." This architecture uses a novel chain-of-reasoning pipeline relying on small language models with an emphasis on cost-effectiveness. The innovative algorithm can pave the way towards efficient, reliable, and transparent question-answering models. image	[Roh, Jihyeon; Kim, Minho; Bae, Kyoungman] Elect & Telecommun Res Inst, Language Intelligence Res Grp, Daejeon, South Korea	Electronics & Telecommunications Research Institute - Korea (ETRI)	Roh, J; Kim, M (corresponding author), Elect & Telecommun Res Inst, Language Intelligence Res Grp, Daejeon, South Korea.	jihyeon.roh@etri.re.kr; kimmh@etri.re.kr			Institute for Information and Communications Technology Promotion	Institute for Information and Communications Technology Promotion	No Statement Available	Asai A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2226; Bevilacqua M, 2021, AAAI CONF ARTIF INTE, V35, P12564; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chung E, 2017, ETRI J, V39, P455, DOI 10.4218/etrij.17.0116.0074; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Deng ZY, 2022, Arxiv, DOI arXiv:2206.08486; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; He HF, 2022, Arxiv, DOI arXiv:2301.00303; Hofstatter S, 2022, Arxiv, DOI arXiv:2209.14290; Izacard G, 2022, Arxiv, DOI arXiv:2208.03299; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lample G, 2019, Arxiv, DOI arXiv:1901.07291; Lazaridou A, 2022, Arxiv, DOI arXiv:2203.05115; Levine Yoav, 2022, Huge frozen language models as readers for open-domain question answering; Li JW, 2022, Arxiv, DOI arXiv:2203.09073; Liu Y, 2024, Arxiv, DOI arXiv:2305.07789; Lu P, 2023, Arxiv, DOI arXiv:2304.09842; Ma Kaixin, 2022, FINDINGS ASS COMPUTA, P5360; Ma XB, 2023, Arxiv, DOI arXiv:2305.14283; Maynez J, 2020, Arxiv, DOI [arXiv:2005.00661, DOI 10.48550/ARXIV.2005.00661]; Min S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6097; Min Sewon, 2023, Findings of the Association for Computational Linguistics ( ACL'23), P2097, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.132; Perez E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8864; Qin YJ, 2023, Arxiv, DOI arXiv:2304.08354; Schick T., 2023, arXiv; Shi WJ, 2023, Arxiv, DOI [arXiv:2301.12652, DOI 10.48550/ARXIV.2301.12652]; Wang X., 2022, Self-consistency improves chain of thought reasoning in language models; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Yao S., 2022, INT C LEARN REPR; You HX, 2023, Arxiv, DOI arXiv:2305.14985; Yu WH, 2023, Arxiv, DOI arXiv:2305.14002; Yu WH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P52; Zheng S, 2023, Arxiv, DOI [arXiv:2304.10513, 10.48550/arXiv.2304.10513]	35	1	1	5	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1225-6463	2233-7326		ETRI J	ETRI J.	FEB	2024	46	1					11	21		10.4218/etrij.2023-0355	http://dx.doi.org/10.4218/etrij.2023-0355			11	Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Telecommunications	JX5R9		gold			2024-07-03	WOS:001176477800003
J	Alotaibi, FS; Kaur, N				Alotaibi, Fahd Saleh; Kaur, Navdeep			Radiological Report Generation from Chest X-ray Images Using Pre-trained Word Embeddings	WIRELESS PERSONAL COMMUNICATIONS			English	Article						Word embedding; Radiological report generation; BERT; LSTM; VGG19		The deep neural networks have facilitated the radiologists to large extent by automating the process of radiological report generation. Majority of the researchers have focussed on improving the learning focus of the model using attention mechanism, reinforcement learning and other techniques. Most of them, have not considered the textual information present in the ground truth radiological reports. In downstream language tasks like text classification, word embedding has played vital role in extracting textual features. Inspired from the same, we empirically study the impact of different word embedding techniques on radiological report generation tasks. In this work, we have used a convolutional neural network and large language model to extract visual and textual features, respectively. Recurrent neural network is used to generate the reports. The proposed method outperforms most of the state-of-the-art methods by achieving following evaluation metrics scores: BLEU-1 = 0.612, BLEU-2 = 0.610, BLEU-3 = 0.608, BLEU-4 = 0.606, ROUGE = 0.811, and CIDEr = 0.317. This work confirms that pre-trained large language model gives significantly better results that other word embedding techniques.	[Alotaibi, Fahd Saleh] King Abdulaziz Univ, Fac Comp & Informat Technol, Jeddah, Saudi Arabia; [Kaur, Navdeep] Mehr Chand Mahajan DAV Coll Women, Dept Comp Sci & Applicat, Chandigarh, India	King Abdulaziz University	Kaur, N (corresponding author), Mehr Chand Mahajan DAV Coll Women, Dept Comp Sci & Applicat, Chandigarh, India.	aulakh83@gmail.com		Kaur, Navdeep/0000-0002-8159-4749	King Abdulaziz University	King Abdulaziz University	No Statement Available	Alfarghaly O., 2021, INFORM MED UNLOCKED, V24, P100557, DOI [DOI 10.1016/J.IMU.2021.100557, 10.1016/j.imu.2021.100557]; Banerjee I, 2018, J BIOMED INFORM, V77, P11, DOI 10.1016/j.jbi.2017.11.012; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Chen ZT, 2020, PROC INT SYMP SOFTW, P426, DOI 10.1109/ISSRE5003.2020.00047; Cho K., 2014, PROC SSST EMNLP, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179, DOI 10.3115/V1/W14-4012]; Demner-Fushman Dina, 2012, Journal of Computing Science and Engineering, V6, P168, DOI 10.5626/JCSE.2012.6.2.168; Devlin J., 2018, BERT PRE TRAINING DE; Harzig P., 2019, ARXIV; Huang X, 2019, IEEE ACCESS, V7, P154808, DOI 10.1109/ACCESS.2019.2947134; Jing B., 2017, ARXIV; Jing B., 2020, ARXIV; Kalyan KS, 2020, J BIOMED INFORM, V101, DOI 10.1016/j.jbi.2019.103323; Kaur N, 2022, J BIOMED INFORM, V135, DOI 10.1016/j.jbi.2022.104220; Kaur N, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105498; Kaur N, 2022, MULTIMED TOOLS APPL, V81, P13409, DOI 10.1007/s11042-021-11272-6; Krause J, 2017, PROC CVPR IEEE, P3337, DOI 10.1109/CVPR.2017.356; Li C., 2019, arXiv; Li C, 2018, DES AUT CON, DOI 10.1145/3195970.3196091; Li X., 2019, ARXIV; Liu G., 2019, ARXIV; Mikolov T, 2013, COMPUTING RES REPOSI; NHS England and NHS Improvement, 2021, PERFORMANCE ANAL TEA; Nooralahzadeh F., 2021, ARXIV; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131; Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Tubiana M, 1996, B ACAD NAT MED PARIS, V180, P97; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943; Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008; Xiong YX, 2019, LECT NOTES COMPUT SC, V11861, P673, DOI 10.1007/978-3-030-32692-0_77; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Yin CC, 2019, IEEE DATA MINING, P728, DOI 10.1109/ICDM.2019.00083; Yuan JB, 2019, LECT NOTES COMPUT SC, V11769, P721, DOI 10.1007/978-3-030-32226-7_80; Zhang Y., 2020, arXiv; Zhang ZZ, 2017, PROC CVPR IEEE, P3549, DOI 10.1109/CVPR.2017.378	39	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0929-6212	1572-834X		WIRELESS PERS COMMUN	Wirel. Pers. Commun.	DEC	2023	133	4					2525	2540		10.1007/s11277-024-10886-x	http://dx.doi.org/10.1007/s11277-024-10886-x		FEB 2024	16	Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Telecommunications	ME1S1					2024-07-03	WOS:001167929800001
J	Bitzenbauer, P				Bitzenbauer, Philipp			ChatGPT in physics education: A pilot study on easy-to-implement activities	CONTEMPORARY EDUCATIONAL TECHNOLOGY			English	Article						ChatGPT; large language model; physics teaching; critical thinking		Large language models, such as ChatGPT, have great potential to enhance learning and support teachers, but they must be used with care to tackle limitations and biases. This paper presents two easy-to-implement examples of how ChatGPT can be used in physics classrooms to foster critical thinking skills at the secondary school level. A pilot study (n=53) examining the implementation of these examples found that the intervention had a positive impact on students' perceptions of ChatGPT, with an increase in agreement with statements related to its benefits and incorporation into their daily lives.	[Bitzenbauer, Philipp] Univ Leipzig, Fac Phys & Earth Sci, Phys Educ Res, Leipzig, Germany	Leipzig University	Bitzenbauer, P (corresponding author), Univ Leipzig, Fac Phys & Earth Sci, Phys Educ Res, Leipzig, Germany.	philipp.bitzenbauer@uni-leipzig.de						Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Ahuja AS, 2019, PEERJ, V7, DOI 10.7717/peerj.7702; Alsmadi M. A., 2023, European Journal of Educational Research, V12, P1123, DOI [10.12973/eu-jer.12.2.1123, DOI 10.12973/EU-JER.12.2.1123]; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Bitzenbauer P, 2021, PHYS REV PHYS EDUC R, V17, DOI 10.1103/PhysRevPhysEducRes.17.020103; Bogost I., 2022, CHATGPT IS DUMBER YO; Buchholz K., 2023, Statista; Chai CS, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8112089; Dimitrov M., 2023, What business leaders should know about using LLMS like ChatGPT; Ennis R.H., 1996, Informal Logic, V18, P165, DOI [10.22329/il.v18i2.2378, DOI 10.22329/IL.V18I2.2378]; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao J, 2023, Arxiv, DOI [arXiv:2303.03836, DOI 10.48550/ARXIV.2303.03836]; Gregorcic Bor, 2023, Physics Education, DOI 10.1088/1361-6552/acc299; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Hidayat C., 2023, European Journal of Educational Research, V12, P1137, DOI [10.12973/eu-jer.12.2.1137, DOI 10.12973/EU-JER.12.2.1137]; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Kasneci E., 2023, CHATGPT GOOD OPPORTU, DOI [10.35542/osf.io/5er8f, DOI 10.35542/OSF.IO/5ER8F]; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; LIPMAN M, 1988, EDUC LEADERSHIP, V46, P38; Lyman F., 1987, MAA-CIE Cooperative News, V1, P1; McGufe K, 2020, arXiv; Moraga-Caldern T S., 2020, Eur. J. Sci. Mat. Educ, V8, P32, DOI [10.30935/scimath/9545, DOI 10.30935/SCIMATH/9545]; Nasution N. E. A., 2023, Agricultural and Environmental Education, V2, DOI [10.29333/agrenvedu/13071, DOI 10.29333/AGRENVEDU/13071]; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Prahl K, 2017, AM BIOL TEACH, V79, P3, DOI 10.1525/abt.2017.79.1.3; Salas-Pilco SZ, 2022, EDUC SCI, V12, DOI 10.3390/educsci12080569; Salas-Pilco SZ, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00326-w; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Schreiner C., 2004, Acta Didactica, V4; Skrabut S., 2023, 80 ways to use ChatGPT in the classroom: Using AI to enhance teaching and learning; Smith EM, 2020, PHYS REV PHYS EDUC R, V16, DOI 10.1103/PhysRevPhysEducRes.16.020150; Stadermann HKE, 2019, PHYS REV PHYS EDUC R, V15, DOI 10.1103/PhysRevPhysEducRes.15.010130; Van Gelder T., 2005, College Teaching, V53, P41, DOI [DOI 10.3200/CTCH.53.1.41-48, 10.3200/ctch.53.1.41-48, 10.3200/CTCH.53.1.41-48]; Veloso M, 2021, OXFORD REV ECON POL, V37, P564, DOI 10.1093/oxrep/grab019; Wang J, 2023, AM J PHYS, V91, P255, DOI 10.1119/5.0145897; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]	37	18	18	39	39	BASTAS PUBL LTD - UK	London	Bastas Headquarters, 71-75 Shelton St, Convent Garden, London, UNITED KINGDOM		1309-517X		CONTEMP EDUC TECHNOL	Contemp. Educ. Technol.	JUL	2023	15	3							ep430	10.30935/cedtech/13176	http://dx.doi.org/10.30935/cedtech/13176			10	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	EH0X6		hybrid			2024-07-03	WOS:001137924400014
J	Idris, MD; Feng, XH; Dyo, V				Diab Idris, Mohamed; Feng, Xiaohua; Dyo, Vladimir			Revolutionizing Higher Education: Unleashing the Potential of Large Language Models for Strategic Transformation	IEEE ACCESS			English	Article						Challenges of LLMs in higher education; impacts of LLMs in higher education; higher education institutions (HEIs); large language models (LLMs); LLMs in education		This paper investigates the transformative potential of Large Language Models (LLMs) within higher education, highlighting their capacity to reshape the academic landscape. By examining the complex impact of LLMs across critical areas of Higher Education Institutions (HEIs), including the role of HEIs as gatekeepers of knowledge, providers of credentials, research centres, incubators of innovation, drivers of social change and employers. In addition to academic integrity, the future of higher education, intellectual property, and public perception. The findings of this paper indicate that LLMs can empower transformation in HEIs by revolutionising various aspects of academia. The aim is to unveil the profound implications of integrating these cutting-edge technologies. The comprehensive study in this paper reveals the significant impacts and challenges associated with using LLMs in academic settings, which is achieved through a detailed analysis of current literature. The core findings suggest that LLMs hold the promise to trigger significant advancements in higher education. This paper also discusses the innovative potential of LLMs, and it outlines a path for their effective use in HEIs, emphasising the importance of a thoughtful approach to maximise their educational benefits. HEIs must address these challenges thoughtfully, ensuring that the integration of LLMs aligns with their fundamental objectives of promoting education, critical thinking, and personal growth.	[Diab Idris, Mohamed; Feng, Xiaohua] Univ Bedfordshire, Sch Comp Sci & Technol, Luton LU1 3JU, England; [Dyo, Vladimir] Royal Holloway Univ London, Dept Elect Engn, Egham TW20 0EX, Surrey, England	University of Bedfordshire; University of London; Royal Holloway University London	Idris, MD (corresponding author), Univ Bedfordshire, Sch Comp Sci & Technol, Luton LU1 3JU, England.	Mohamed.idris@study.beds.ac.uk		Dyo, Vladimir/0000-0003-4747-0870				Abrenilla E. M., 2023, Excellencia Int. MultidisciplinaryJ. Educ., V1, P124; [Anonymous], 2023, Entrepreneurship at Berkeley.; [Anonymous], Turnitin's; [Anonymous], 2023, Grammarly; Arizona State University, ASU Machine Learning & AIMicroBootCamp; Cavagnaro L. B, 2022, Stanford Digital Education; Gallegos IO, 2024, Arxiv, DOI arXiv:2309.00770; Gan Wensheng, 2023, 2023 IEEE International Conference on Big Data (BigData), P4776, DOI 10.1109/BigData59044.2023.10386291; Goel A., 2020, Georgia Institute of Technology; Goli, Unleashing the Next Chapter of Personalized and Interactive OnlineLearning With Generative AI, Machine Learning, and Virtual Reality; Hart M., 2016, Campus Technology ,Apr. 27,; Harvard University, 2024, Library Innovation Lab; Jacob WJ, 2015, PALGR COMMUN, V1, DOI 10.1057/palcomms.2015.1; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Joshi I, 2023, Arxiv, DOI arXiv:2309.10694; Kachris C, 2024, Arxiv, DOI arXiv:2401.09890; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Karamolegkou J., 2023, P 2023 C EMPIRICAL M, P7403; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Koperniak S, Bringing Artificial Intelligence and MIT To MiddleSchool Classrooms; Koric S., 2023, Utilizing AI and Machine Learning for AcceleratedData Generation and Training in Research Engineering With Computers; Li QY, 2024, Arxiv, DOI arXiv:2401.08664; Li Xuan, 2023, 2023 IEEE 3rd International Conference on Data Science and Computer Application (ICDSCA), P434, DOI 10.1109/ICDSCA59871.2023.10392972; Licht K. D. F., 2023, Comput. Sci. Math. Forum, V8, P65; Liu J, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211060810; Maina MF, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-021-00315-5; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Montenegro R., How AI is Transforming Mental Health: Woebot,Your CBT Coach; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Pirkkalainen H, 2023, EDUC RES-UK, V65, P40, DOI 10.1080/00131881.2022.2157302; Singh NK, 2021, IEEE ACCESS, V9, P143580, DOI 10.1109/ACCESS.2021.3120470; Singh T, 2023, Arxiv, DOI arXiv:2304.06123; Southworth J., 2023, Computers and Education: Artificial Intelligence, P1, DOI [DOI 10.1016/J.CAEAI.2023.100127, 10.1016/j.caeai.2023.100127, 10.1016/j.caeai.2023]; Stapleton A., 2023, Academia Insider; Sun ZX, 2023, Arxiv, DOI arXiv:2303.09136; The Simon Initiative, 2024, Open Learning Initiative; Vaswani A, 2017, ADV NEUR IN, V30; Yan LX, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13370; Yu H. Q., 2024, J. Med. Artif. Intell., V52; Zaleniene I, 2021, GEOGR SUSTAIN, V2, P99, DOI 10.1016/j.geosus.2021.05.001; Zhang JY, 2023, Arxiv, DOI arXiv:2308.02678; Zhou KZ, 2024, Arxiv, DOI arXiv:2401.12453	43	0	0	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						67738	67757		10.1109/ACCESS.2024.3400164	http://dx.doi.org/10.1109/ACCESS.2024.3400164			20	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	RK0R0		gold			2024-07-03	WOS:001227445100001
J	Toma, A; Senkaiahliyan, S; Lawler, PR; Rubin, B; Wang, B				Toma, Augustin; Senkaiahliyan, Senthujan; Lawler, Patrick R.; Rubin, Barry; Wang, Bo			To safely deploy generative AI in health care, models must be open source	NATURE			English	Editorial Material						Machine learning; Health care; Medical research; Technology		Large language models such as that used by ChatGPT could soon become essential tools for diagnosing and treating patients. To protect people's privacy and safety, medical professionals, not commercial interests, must drive their development and deployment.	[Toma, Augustin] Vector Inst, Toronto, ON, Canada; [Toma, Augustin; Wang, Bo] Univ Toronto, Toronto, ON, Canada; [Senkaiahliyan, Senthujan] Univ Toronto, Inst Hlth Policy Management & Evaluat, Dalla Lana Sch Publ Hlth, Toronto, ON, Canada; [Lawler, Patrick R.] McGill Univ Hlth Ctr, Montreal, PQ, Canada; [Rubin, Barry] Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada; [Wang, Bo] Univ Hlth Network, Toronto, ON, Canada	Vector Institute for Artificial Intelligence; University of Toronto; University of Toronto; McGill University; University of Toronto; University Health Network Toronto; Peter Munk Cardiac Centre; University of Toronto; University Health Network Toronto	Wang, B (corresponding author), Univ Toronto, Toronto, ON, Canada.; Wang, B (corresponding author), Univ Hlth Network, Toronto, ON, Canada.	bowang@vectorinstitute.ai	Toma, Augustin/JZT-0737-2024					Ali R, 2023, medRxiv, DOI [10.1101/2023.05.06.23289615, 10.1101/2023.05.06.23289615, DOI 10.1101/2023.05.06.23289615]; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Eriksen A. V., 2023, N. Engl. J. Med; Executive Office of the President, 2023, Federal Register, V88, P75191; Giorgi John, 2023, P 5 CLIN NATURAL LAN, P323; Holmes J, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1219326; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8	19	4	4	23	24	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	DEC 7	2023	624	7990					36	38		10.1038/d41586-023-03803-y	http://dx.doi.org/10.1038/d41586-023-03803-y			3	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	Z4BL4	38036861				2024-07-03	WOS:001111545100001
J	Pais, C; Liu, JF; Voigt, R; Gupta, V; Wade, E; Bayati, M				Pais, Cristobal; Liu, Jianfeng; Voigt, Robert; Gupta, Vin; Wade, Elizabeth; Bayati, Mohsen			Large language models for preventing medication direction errors in online pharmacies	NATURE MEDICINE			English	Article; Early Access							ADVERSE DRUG EVENTS; COMMUNITY PHARMACY; PATIENT SAFETY; HEALTH-CARE; CONSEQUENCES; TECHNOLOGY	Errors in pharmacy medication directions, such as incorrect instructions for dosage or frequency, can increase patient safety risk substantially by raising the chances of adverse drug events. This study explores how integrating domain knowledge with large language models (LLMs)-capable of sophisticated text interpretation and generation-can reduce these errors. We introduce MEDIC (medication direction copilot), a system that emulates the reasoning of pharmacists by prioritizing precise communication of core clinical components of a prescription, such as dosage and frequency. It fine-tunes a first-generation LLM using 1,000 expert-annotated and augmented directions from Amazon Pharmacy to extract the core components and assembles them into complete directions using pharmacy logic and safety guardrails. We compared MEDIC against two LLM-based benchmarks: one leveraging 1.5 million medication directions and the other using state-of-the-art LLMs. On 1,200 expert-reviewed prescriptions, the two benchmarks respectively recorded 1.51 (confidence interval (CI) 1.03, 2.31) and 4.38 (CI 3.13, 6.64) times more near-miss events-errors caught and corrected before reaching the patient-than MEDIC. Additionally, we tested MEDIC by deploying within the production system of an online pharmacy, and during this experimental period, it reduced near-miss events by 33% (CI 26%, 40%). This study shows that LLMs, with domain expertise and safeguards, improve the accuracy and efficiency of pharmacy operations. Tailored to detect and prevent potential medication direction errors in a digital pharmacy data processing pipeline, a large language model is shown to increase efficiency and decrease burden for technicians and pharmacists in a prospective application.	[Pais, Cristobal; Liu, Jianfeng; Voigt, Robert; Gupta, Vin; Wade, Elizabeth; Bayati, Mohsen] Amazon, Seattle, WA 98109 USA; [Gupta, Vin] Univ Washington, Dept Hlth Metr Sci, Seattle, WA USA; [Bayati, Mohsen] Stanford Univ, Grad Sch Business, Operat Informat & Technol, Stanford, CA USA	Amazon.com; University of Washington; University of Washington Seattle; Stanford University	Pais, C (corresponding author), Amazon, Seattle, WA 98109 USA.	crispais@amazon.com	Bayati, Mohsen/R-7729-2017	Bayati, Mohsen/0000-0002-9118-5447				[Anonymous], 2009, ISMP SURVEY HELPS DE; Anthropic, 2023, Introducing claude 2.1; Aronson JK, 2009, QJM-INT J MED, V102, P513, DOI 10.1093/qjmed/hcp052; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Ash JS, 2004, J AM MED INFORM ASSN, V11, P104, DOI 10.1197/jamia.M1471; Ashcroft DM, 2005, QUAL SAF HEALTH CARE, V14, P417, DOI 10.1136/qshc.2005.014332; Aspden P, 2007, PREVENTING MEDICATIO; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Barker KN, 2002, ARCH INTERN MED, V162, P1897, DOI 10.1001/archinte.162.16.1897; Bates DW, 1998, JAMA-J AM MED ASSOC, V280, P1311, DOI 10.1001/jama.280.15.1311; BATES DW, 1995, J GEN INTERN MED, V10, P199, DOI 10.1007/BF02600255; BATES DW, 1995, JAMA-J AM MED ASSOC, V274, P29, DOI 10.1001/jama.274.1.29; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blendon RJ, 2002, NEW ENGL J MED, V347, P1933, DOI 10.1056/NEJMsa022151; Bojar O, 2016, P 1 C MACH TRANSL, V2, P131; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Campbell Patrick J, 2018, BMJ Open Qual, V7, pe000193, DOI 10.1136/bmjoq-2017-000193; Conn AR, 2009, MOS-SIAM SER OPTIMIZ, V8, P1; Cuong J, 2011, J EMERG MED, V40, P485, DOI 10.1016/j.jemermed.2008.02.059; Devlin J., 2018, arXiv, DOI [10.18653/v1/N19-1423, DOI 10.18653/V1/N19-1423, 10.18653/v1/n19-1423]; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Efron B, 1994, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9; Fischer SH, 2020, BMC HEALTH SERV RES, V20, DOI 10.1186/s12913-020-05679-4; Flynn Elizabeth Allan, 2003, J Am Pharm Assoc (Wash), V43, P191; Gandhi TK, 2005, J GEN INTERN MED, V20, P837, DOI 10.1111/j.1525-1497.2005.0194.x; Google, An overview of Bard: an early experiment with generative AI; Holmgren AJ, 2021, JAMA INTERN MED, V181, P251, DOI 10.1001/jamainternmed.2020.7071; Hong K, 2019, RES SOC ADMIN PHARM, V15, P823, DOI 10.1016/j.sapharm.2018.11.014; Hsiao S., Bard gets its biggest upgrade yet with Gemini; Huang Z, 2023, NAT MED, V29, P2307, DOI 10.1038/s41591-023-02504-3; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kass-Hout TA, 2016, J AM MED INFORM ASSN, V23, P596, DOI 10.1093/jamia/ocv153; Kaushal R, 2001, JAMA-J AM MED ASSOC, V285, P2114, DOI 10.1001/jama.285.16.2114; Kohn K.T., 1999, To err is human: Building a safer health system, DOI 10.17226/9728; LEAPE LL, 1995, JAMA-J AM MED ASSOC, V274, P35, DOI 10.1001/jama.1995.03530010049034; Lester CA, 2021, J AM PHARM ASSOC, V61, P484, DOI 10.1016/j.japh.2021.02.006; Li C., 2021, Medication errors in retail pharmacies: wrong patient, wrong instructions; Li J., 2022, PREPRINT, DOI [10.18653/v1/2020.findings-emnlp.251, DOI 10.18653/V1/2020.FINDINGS-EMNLP.251]; Lim AYN, 2005, RHEUMATOLOGY, V44, P1051, DOI 10.1093/rheumatology/keh685; Liu XX, 2023, Arxiv, DOI [arXiv:2311.12785, 10.48550/arXiv.2311.12785, DOI 10.48550/ARXIV.2311.12785]; Liu Y., 2023, MetaRadiology, V1; Mathur N, 2020, Arxiv, DOI [arXiv:2006.06264, DOI 10.48550/ARXIV.2006.06264]; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Napoles C, 2017, Arxiv, DOI [arXiv:1702.04066, 10.48550/arXiv.1702.04066, DOI 10.48550/ARXIV.1702.04066]; Nelson SJ, 2011, J AM MED INFORM ASSN, V18, P441, DOI 10.1136/amiajnl-2011-000116; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Odukoya OK, 2014, INT J MED INFORM, V83, P427, DOI 10.1016/j.ijmedinf.2014.02.004; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Palchuk MB, 2010, J AM MED INFORM ASSN, V17, P472, DOI 10.1136/jamia.2010.003335; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pervanas HC, 2016, J PHARM TECHNOL, V32, P71, DOI 10.1177/8755122515617199; Pham JC., 2005, Jt Comm. J. Qual. Patient Saf, V31, P561; Phillips DP, 1998, LANCET, V351, P643, DOI 10.1016/S0140-6736(98)24009-8; Poon EG, 2006, ANN INTERN MED, V145, P426, DOI 10.7326/0003-4819-145-6-200609190-00006; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Raffel C, 2020, J MACH LEARN RES, V21; Rebedea T, 2023, Arxiv, DOI [arXiv:2310.10501, 10.48550/arXiv.2310.10501, DOI 10.48550/ARXIV.2310.10501]; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Snoek J., 2012, ADV NEURAL INFORM PR, P2951, DOI [10.5555/2999325.2999464, DOI 10.48550/ARXIV.1206.2944]; Sutcliffe KM, 2004, ACAD MED, V79, P186, DOI 10.1097/00001888-200402000-00019; Sutton RT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0221-y; Tariq RA, 2023, Medication Dispensing Errors and Prevention; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Varkey P., 2004, Am. J. Health Syst. Pharm, V61, P1290; Wang X., 2023, 11 INT C LEARNING RE; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wittich CM, 2014, MAYO CLIN PROC, V89, P1116, DOI 10.1016/j.mayocp.2014.05.007; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xiong M, 2024, Arxiv, DOI arXiv:2306.13063; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	75	1	1	9	9	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	2024 APR 25	2024										10.1038/s41591-024-02933-8	http://dx.doi.org/10.1038/s41591-024-02933-8		APR 2024	26	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	OO4H9	38664535				2024-07-03	WOS:001208198300002
J	Xia, YC; Xiao, ZW; Jazdi, N; Weyrich, M				Xia, Yuchen; Xiao, Zhewen; Jazdi, Nasser; Weyrich, Michael			Generation of Asset Administration Shell With Large Language Model Agents: Toward Semantic Interoperability in Digital Twins in the Context of Industry 4.0	IEEE ACCESS			English	Article						Semantics; Data models; Digital twins; Context modeling; Interoperability; Unified modeling language; Fourth Industrial Revolution; Large language models; Information retrieval; Augmented reality; Asset administration shell; large language model; semantic interoperability; digital twin; industry 4.0; generative AI; retrieval-augmented generation	TRANSFORMATION	This research introduces a novel approach for achieving semantic interoperability in digital twins and assisting the creation of Asset Administration Shell (AAS) as digital twin model within the context of Industry 4.0. The foundational idea of our research is that the communication based on semantics and the generation of meaningful textual data are directly linked, and we posit that these processes are equivalent if the exchanged information can be serialized in text form. Based on this, we construct a "semantic node" data structure in our research to capture the semantic essence of textual data. Then, a system powered by large language models is designed and implemented to process the "semantic node" and generate standardized digital twin models (AAS instance models in the context of Industry 4.0) from raw textual data collected from datasheets describing technical assets. Our evaluation demonstrates an effective generation rate of 62-79%, indicating a substantial proportion of the information from the source text can be translated error-free to the target digital twin instance model with the generative capability of large language models. This result has a direct application in the context of Industry 4.0, and the designed system is implemented as a data model generation tool for reducing the manual effort in creating AAS model by automatically translating unstructured textual data into a standardized AAS model. The generated AAS model can be integrated into AAS-compliant digital twin software for seamless information exchange and communication. In our evaluation, a comparative analysis of different LLMs and an in-depth ablation study of Retrieval-Augmented Generation (RAG) mechanisms provide insights into the effectiveness of LLM systems for interpreting technical concepts and translating data. Our findings emphasize LLMs' capability to automate AAS instance creation and contribute to the broader field of semantic interoperability for digital twins in industrial applications. The prototype implementation and evaluation results are presented on our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.	[Xia, Yuchen; Xiao, Zhewen; Jazdi, Nasser; Weyrich, Michael] Univ Stuttgart, Inst Ind Automat & Software Engn, D-70550 Stuttgart, Germany	University of Stuttgart	Xia, YC; Weyrich, M (corresponding author), Univ Stuttgart, Inst Ind Automat & Software Engn, D-70550 Stuttgart, Germany.	yuchen.xia@ias.uni-stuttgart.de; michael.weyrich@ias.uni-stuttgart.de			Stiftung der Deutschen Wirtschaft (SDW)	Stiftung der Deutschen Wirtschaft (SDW)	No Statement Available	Bader S., 2022, Tech. Rep.3.0RC02; Beermann J, 2023, IEEE INTL CONF IND I, DOI 10.1109/INDIN51400.2023.10218154; Bills S., 2023, Language models can explain neurons in language models; Blasek K., 2023, P 13 ENT DES ENG WOR, P1; Both M, 2023, ENERG BUILDINGS, V300, DOI 10.1016/j.enbuild.2023.113635; Both M, 2021, AT-AUTOM, V69, P940, DOI 10.1515/auto-2021-0050; Braunisch N, 2023, IEEE INTL CONF IND I, DOI 10.1109/INDIN51400.2023.10218306; Cartus M., 2022, CLIMA, P1, DOI [10.34641/clima.2022.143, DOI 10.34641/CLIMA.2022.143]; Cavalieri S, 2020, COMPUTERS, V9, DOI 10.3390/computers9020028; Dittler P., 2023, P IEEE 28 INT C EM T, P1, DOI [10.1109/etfa54631.2023.10275384.32Y, DOI 10.1109/ETFA54631.2023.10275384.32Y]; Eichelberger C., 2023, P IEEE 28 INT C EM T, P1, DOI [10.1109/etfa54631.2023.10275339.6N, DOI 10.1109/ETFA54631.2023.10275339.6N]; Fuchs J, 2019, IEEE INT C EMERG, P1243, DOI [10.1109/ETFA.2019.8869255, 10.1109/etfa.2019.8869255]; Gurnee W, 2023, Arxiv, DOI arXiv:2305.01610; Huang YN, 2023, Industrial Cyber Phy, DOI 10.1109/ICPS58381.2023.10128003; Huang YN, 2022, ACM/IEEE 25TH INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS, MODELS 2022 COMPANION, P497, DOI 10.1145/3550356.3561606; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Liu PK, 2024, COMPUTING IN CIVIL ENGINEERING 2023-VISUALIZATION, INFORMATION MODELING, AND SIMULATION, P680, DOI 10.1061/9780784485231.081; Lueder A, 2020, IEEE INT C EMERG, P867, DOI 10.1109/ETFA46521.2020.9212149; Miny T, 2020, IEEE IND ELEC, P2207, DOI [10.1109/iecon43393.2020.9254649, 10.1109/IECON43393.2020.9254649]; Moreno Tomas, 2024, Flexible Automation and Intelligent Manufacturing: Establishing Bridges for More Sustainable Manufacturing Systems: Proceedings of FAIM 2023: Industrial Management. Lecture Notes in Mechanical Engineering, P679, DOI 10.1007/978-3-031-38165-2_79; Ocker F, 2021, IFAC PAPERSONLINE, V54, P837, DOI 10.1016/j.ifacol.2021.08.186; Olah N., 2020, Distill, V5, DOI [10.23915/distill.00024.001.8, DOI 10.23915/DISTILL.00024.001.8]; Platenius-Mohr M, 2020, FUTURE GENER COMP SY, V113, P94, DOI 10.1016/j.future.2020.07.004; Platenius-Mohr M, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS ( IOT 2019), DOI 10.1145/3365871.3365873; Radford A, 2017, Arxiv, DOI arXiv:1704.01444; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rongen S, 2023, COMPUT IND, V148, DOI 10.1016/j.compind.2023.103910; Schmidt C, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23187742; Schnauffer G., 2023, Advances in Automotive Production Technology-Towards Software-Defined Manufacturing and Resilient Supply Chains, P324; Silva Da, 2023, P IEEE 28 INT C EM T, P1, DOI [10.1109/etfa54631.2023.10275459, DOI 10.1109/ETFA54631.2023.10275459]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Xia M., 2023, P IEEE 28 INT C EM T, P1, DOI [10.1109/ETFA54631.2023.10275362, DOI 10.1109/ETFA54631.2023.10275362]; Xia YC, 2024, Arxiv, DOI arXiv:2405.18092; Xia YC, 2022, IEEE INT C EMERG, DOI 10.1109/ETFA52439.2022.9921637; Xu C, 2023, Arxiv, DOI arXiv:2304.12244; Zhao JY, 2023, IFAC PAPERSONLINE, V56, P3673, DOI 10.1016/j.ifacol.2023.10.1532	37	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						84863	84877		10.1109/ACCESS.2024.3415470	http://dx.doi.org/10.1109/ACCESS.2024.3415470			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	WB8Q2		gold, Green Submitted			2024-07-03	WOS:001252503400001
J	Pellert, M; Lechner, CM; Wagner, C; Rammstedt, B; Strohmaier, M				Pellert, Max; Lechner, Clemens M.; Wagner, Claudia; Rammstedt, Beatrice; Strohmaier, Markus			AI Psychometrics: Assessing the Psychological Profiles of Large Language Models Through Psychometric Inventories	PERSPECTIVES ON PSYCHOLOGICAL SCIENCE			English	Article; Early Access						artificial intelligence; psychometrics; large language model; natural language processing; natural language inference; personality; values; moral foundations; gender/sex diversity beliefs	MACHINE	We illustrate how standard psychometric inventories originally designed for assessing noncognitive human traits can be repurposed as diagnostic tools to evaluate analogous traits in large language models (LLMs). We start from the assumption that LLMs, inadvertently yet inevitably, acquire psychological traits (metaphorically speaking) from the vast text corpora on which they are trained. Such corpora contain sediments of the personalities, values, beliefs, and biases of the countless human authors of these texts, which LLMs learn through a complex training process. The traits that LLMs acquire in such a way can potentially influence their behavior, that is, their outputs in downstream tasks and applications in which they are employed, which in turn may have real-world consequences for individuals and social groups. By eliciting LLMs' responses to language-based psychometric inventories, we can bring their traits to light. Psychometric profiling enables researchers to study and compare LLMs in terms of noncognitive characteristics, thereby providing a window into the personalities, values, beliefs, and biases these models exhibit (or mimic). We discuss the history of similar ideas and outline possible psychometric approaches for LLMs. We demonstrate one promising approach, zero-shot classification, for several LLMs and psychometric inventories. We conclude by highlighting open challenges and future avenues of research for AI Psychometrics.	[Pellert, Max; Strohmaier, Markus] Univ Mannheim, Business Sch, Mannheim, Germany; [Lechner, Clemens M.; Wagner, Claudia; Rammstedt, Beatrice; Strohmaier, Markus] GESIS Leibniz Inst Social Sci, Mannheim, Germany; [Wagner, Claudia] Rhein Westfal TH Aachen, Dept Soc Technol & Human Factors, Aachen, Germany; [Wagner, Claudia; Strohmaier, Markus] Complex Sci Hub Vienna, Vienna, Austria	University of Mannheim; Leibniz Institut fur Sozialwissenschaften (GESIS); RWTH Aachen University	Pellert, M (corresponding author), Univ Mannheim, Business Sch, Mannheim, Germany.	max.pellert@uni-mannheim.de	Pellert, Max/AAK-4900-2020; Rammstedt, Beatrice/AHH-2446-2022	Pellert, Max/0000-0002-6557-7607; Strohmaier, Markus/0000-0002-5485-5720				Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Binz M, 2022, Arxiv, DOI arXiv:2206.14576; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Boden MA, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P89; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bowman SR, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7484; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Bringsjord S., 2003, IJCAI, P887; Bringsjord S, 2011, J EXP THEOR ARTIF IN, V23, P271, DOI 10.1080/0952813X.2010.502314; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Camburu OM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4157; Chan B., 2020, P 28 INT C COMPUTATI, P6788, DOI 10.18653/v1/2020.coling-main.598; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; Conneau A, 2018, Arxiv, DOI arXiv:1809.05053; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Dale R, 2017, NAT LANG ENG, V23, P319, DOI 10.1017/S1351324917000018; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1286; Evans Thomas G., 1964, PROC APRIL 21 23 196, DOI [DOI 10.1145/1464122.1464156, 10.1145/1464122.1464156]; Firestone C, 2020, P NATL ACAD SCI USA, V117, P26562, DOI 10.1073/pnas.1905334117; FISKE DW, 1970, ANNU REV PSYCHOL, V21, P49, DOI 10.1146/annurev.ps.21.020170.000405; Fortuna P, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232676; Furr RM., 2014, Psychometrics: An introduction, V2nd ed.; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; García-Cueto E, 2015, INT J CLIN HLTH PSYC, V15, P61, DOI 10.1016/j.ijchp.2014.10.004; Gehman S, 2020, M ASS FOR COMPUTATIO; Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847; Graham J, 2013, ADV EXP SOC PSYCHOL, V47, P55, DOI 10.1016/B978-0-12-407236-7.00002-4; Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141; Haidt J, 2007, SCIENCE, V316, P998, DOI 10.1126/science.1137651; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Hill DB, 2005, SEX ROLES, V53, P531, DOI 10.1007/s11199-005-7140-x; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Hyde JS, 2019, AM PSYCHOL, V74, P171, DOI 10.1037/amp0000307; Jentzsch S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P37, DOI 10.1145/3306618.3314267; John O. P., 2008, Handbook of Personality: Theory and Research, P114, DOI DOI 10.1016/S0191-8869(97)81000-8; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kulkarni S.B., 2019, Journal of International Technology and Information Management, V28, P2; Laurer M., 2022, Less annotating, more classifying-addressing the data scarcity issue of supervised machine learning with deep transfer learning and bert-nli; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li S, 2022, Arxiv, DOI arXiv:2202.01771; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loureiro D., 2022, arXiv; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Mathew B, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1548, DOI 10.1145/3366423.3380227; Mitchell M, 2022, Arxiv, DOI arXiv:2210.13966; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; NEISSER U, 1963, SCIENCE, V139, P193, DOI 10.1126/science.139.3551.193; Newell A., 1973, VISUAL INFORM PROCES, P283, DOI DOI 10.1016/B978-0-12-170150-5.50012-3; Nie YX, 2020, Arxiv, DOI arXiv:1910.14599; Nozza D, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P68; Nozza D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2398; Nunnally J., 1994, Psychometric theory; Osgood C. E., 1957, MEASUREMENT MEANING; OSGOOD CE, 1971, J SOC ISSUES, V27, P5, DOI 10.1111/j.1540-4560.1971.tb00678.x; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paulhus DL, 2021, EUR J PSYCHOL ASSESS, V37, P208, DOI 10.1027/1015-5759/a000602; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Radford A., 2018, IMPROVING LANGUAGE U; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Rammstedt B., 1997, The German version of the Big Five Inventory (BFI): Translation and validation of a questionnaire to measure the five-factor model of personality; Reimers N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4512; Ribeiro MT, 2020, P 58 ANN M ASS COMP, P4902, DOI [DOI 10.18653/V1/2020.ACL-MAIN.442, 10.18653/v1/2020.acl-main.442]; Rozado D., 2023, The political bias of ChatGPT: Extended analysis; Rust J., 2014, MODERN PSYCHOMETRICS, DOI 10.4324/9781315787527; Schick T., 2023, arXiv; Schramowski P., 2019, arXiv; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schudson ZC, 2022, GROUP PROCESS INTERG, V25, P1011, DOI 10.1177/1368430220987595; SCHWARTZ SH, 1992, ADV EXP SOC PSYCHOL, V25, P1, DOI 10.1016/s0065-2601(08)60281-6; Schwartz SH, 2022, ASSESSMENT, V29, P1005, DOI 10.1177/1073191121998760; Schwartz SH, 2012, J PERS SOC PSYCHOL, V103, P663, DOI 10.1037/a0029393; Shleifer S, 2020, Arxiv, DOI arXiv:2010.13002; Simon H. A., 1963, Working Paper No. 55); Simon HA., 1996, The sciences of the artificial, DOI DOI 10.7551/MITPRESS/12107.001.0001; Suarez P.J.O., 2019, P WORKSHOP CHALLENGE, P9, DOI [10.14618/ids-pub-9021, DOI 10.14618/IDS-PUB-9021]; Suárez PJO, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1703; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Vlasceanu M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2204529119; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A., 2020, Proceedings of the 33rd international conference on neural information processing systems; Watson G, 1932, PSYCHOL BULL, V29, P147, DOI 10.1037/h0074588; West S.G., 1997, Handbook of personality psychology, P143, DOI 10.1016/B978-012134645-4/50007-X; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3; Yang Z., 2019, P 33 INT C NEUR INF; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914	93	1	1	23	23	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1745-6916	1745-6924		PERSPECT PSYCHOL SCI	Perspect. Psychol. Sci.	2024 JAN 2	2024										10.1177/17456916231214460	http://dx.doi.org/10.1177/17456916231214460		JAN 2024	19	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	DU9E4	38165766	hybrid, Green Published			2024-07-03	WOS:001134704400001
J	Jablonka, KM; Schwaller, P; Ortega-Guerrero, A; Smit, B				Jablonka, Kevin Maik; Schwaller, Philippe; Ortega-Guerrero, Andres; Smit, Berend			Leveraging large language models for predictive chemistry	NATURE MACHINE INTELLIGENCE			English	Article							PERFORMANCE; KNOWLEDGE	Machine learning has transformed many fields and has recently found applications in chemistry and materials science. The small datasets commonly found in chemistry sparked the development of sophisticated machine learning approaches that incorporate chemical knowledge for each application and, therefore, require specialized expertise to develop. Here we show that GPT-3, a large language model trained on vast amounts of text extracted from the Internet, can easily be adapted to solve various tasks in chemistry and materials science by fine-tuning it to answer chemical questions in natural language with the correct answer. We compared this approach with dedicated machine learning models for many applications spanning the properties of molecules and materials to the yield of chemical reactions. Surprisingly, our fine-tuned version of GPT-3 can perform comparably to or even outperform conventional machine learning techniques, in particular in the low-data limit. In addition, we can perform inverse design by simply inverting the questions. The ease of use and high performance, especially for small datasets, can impact the fundamental approach to using machine learning in the chemical and material sciences. In addition to a literature search, querying a pre-trained large language model might become a routine way to bootstrap a project by leveraging the collective knowledge encoded in these foundation models, or to provide a baseline for predictive tasks. Machine learning techniques are widely employed in chemical science, but are application specific and their development requires dedicated expertise. Jablonka and colleagues fine-tune the GPT-3 model and show that it can provide surprisingly accurate answers to a wide range of chemical questions.	[Jablonka, Kevin Maik; Ortega-Guerrero, Andres; Smit, Berend] Ecole Polytech Fed Lausanne EPFL, Inst Sci & Ingn Chim, Lab Mol Simulat LSMO, Sion, Switzerland; [Jablonka, Kevin Maik] Friedrich Schiller Univ Jena, Ctr Energy & Environm Chem Jena CEEC Jena, Jena, Germany; [Jablonka, Kevin Maik] Friedrich Schiller Univ Jena, Lab Organ & Macromol Chem IOMC, Jena, Germany; [Jablonka, Kevin Maik] Helmholtz Inst Polymers Energy Applicat, Jena, Germany; [Schwaller, Philippe] Ecole Polytech Fed Lausanne EPFL, Lab Artificial Chem Intelligence LIAC, Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Friedrich Schiller University of Jena; Friedrich Schiller University of Jena; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Smit, B (corresponding author), Ecole Polytech Fed Lausanne EPFL, Inst Sci & Ingn Chim, Lab Mol Simulat LSMO, Sion, Switzerland.	berend.smit@epfl.ch	Jablonka, Kevin Maik/AAP-9474-2020; Smit, Berend/B-7580-2009; Schwaller, Philippe/ABG-4328-2021	Jablonka, Kevin Maik/0000-0003-4894-4660; Smit, Berend/0000-0003-4653-8562; Schwaller, Philippe/0000-0003-3046-6576; Ortega Guerrero, Andres Adolfo/0000-0002-0065-0623	MARVEL National Centre for Competence in Research - Swiss National Science Foundation [51NF40-182892]; NCCR Catalysis [180544]; National Centre of Competence in Research - Swiss National Science Foundation; Grantham Foundation for the Protection of the Environment to RMI's climate tech accelerator programme; Carl-Zeiss Foundation	MARVEL National Centre for Competence in Research - Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); NCCR Catalysis; National Centre of Competence in Research - Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); Grantham Foundation for the Protection of the Environment to RMI's climate tech accelerator programme; Carl-Zeiss Foundation	K.M.J., A.O.-G. and B.S. were supported by the MARVEL National Centre for Competence in Research funded by the Swiss National Science Foundation (grant agreement ID 51NF40-182892). P.S. acknowledges support from NCCR Catalysis (grant number 180544), a National Centre of Competence in Research funded by the Swiss National Science Foundation. The research of K.M.J. and B.S. was also supported by the USorb-DAC Project, which is funded by a grant from The Grantham Foundation for the Protection of the Environment to RMI's climate tech accelerator programme, Third Derivative. In addition, the work of K.M.J. was supported by the Carl-Zeiss Foundation.	Bannwarth C, 2019, J CHEM THEORY COMPUT, V15, P1652, DOI 10.1021/acs.jctc.8b01176; Bento AP, 2014, NUCLEIC ACIDS RES, V42, pD1083, DOI 10.1093/nar/gkt1031; Bommasani R., 2021, 2108.07258; Born J, 2023, NAT MACH INTELL, V5, P432, DOI 10.1038/s42256-023-00639-z; Brown N, 2019, J CHEM INF MODEL, V59, P1096, DOI 10.1021/acs.jcim.8b00839; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Choudhary K, 2023, J PHYS CHEM C, V127, P17545, DOI 10.1021/acs.jpcc.3c03106; Chowdhery A, 2023, J MACH LEARN RES, V24; Chung YG, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1600909; Collins SP, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1600954; Dai D., 2022, PREPRINT; De Breuck PP, 2021, J PHYS-CONDENS MAT, V33, DOI 10.1088/1361-648X/ac1280; Delaney JS, 2004, J CHEM INF COMP SCI, V44, P1000, DOI 10.1021/ci034243x; Dettmers T., 2022, Advances in Neural Information Processing Systems, V35, P30318; Dettmers T., 2022, 10 INT C LEARNING RE; Dinh T., 2022, ADV NEURAL INFORM PR, V35, P11763; Dubbeldam D, 2018, MOL SIMULAT, V44, P653, DOI 10.1080/08927022.2018.1426855; Dunn A., 2022, ADV NEURAL INF PROCE, V35, P11763; Dunn A, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-00406-3; Edwards C., 2022, P 2022 C EMPIRICAL M, P375; Ertl P, 2012, J CHEMINFORMATICS, V4, DOI 10.1186/1758-2946-4-12; Ertl P, 2009, J CHEMINFORMATICS, V1, DOI 10.1186/1758-2946-1-8; Estrada JG, 2018, SCIENCE, V362, DOI 10.1126/science.aat8763; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Gao L., 2020, PREPRINT; GAULTON A, 2012, NUCL ACIDS RES, V0040; Goldblum M., 2023, ICLR 2024 C; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Griffiths R.-R., 2022, ICML 2022 2 SCI WORK; Griffiths RR, 2022, CHEM SCI, V13, P13541, DOI 10.1039/d2sc04306h; Grisoni F, 2023, CURR OPIN STRUC BIOL, V79, DOI 10.1016/j.sbi.2023.102527; Guo T., 2023, PREPRINT; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; Hoffmann J., 2022, Advances in Neural Information Processing Systems (NeurIPS), V35, P30016; Hollmann N., 2022, PREPRINT; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Hu E. J., 2021, INT C LEARNING REPRE; Isert C, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01390-7; Jablonka K. M., 2021, PREPRINT; Jablonka K. M., 2023, CHEMLIFT ZENODO, DOI [10.5281/zenodo.10233422, DOI 10.5281/ZENODO.10233422]; Jablonka KM, 2023, DIGIT DISCOV, V2, P1233, DOI 10.1039/d3dd00113j; Jablonka KM, 2022, NAT CHEM, V14, P365, DOI 10.1038/s41557-022-00910-7; Jablonka KM, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22437-0; Karpov P, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00423-w; Kawazoe Y., 2006, NONEQUILIBRIUM PHASE; Kim B, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aax9324; Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Le TT, 2020, BIOINFORMATICS, V36, P250, DOI 10.1093/bioinformatics/btz470; Lee S, 2021, ACS APPL MATER INTER, V13, P23647, DOI 10.1021/acsami.1c02471; Lee S, 2019, J MATER CHEM A, V7, P2709, DOI 10.1039/c8ta12208c; Mitchell J. B. O., 2017, DLS 100 SOLUBILITY D; Mobley DL, 2014, J COMPUT AID MOL DES, V28, P711, DOI 10.1007/s10822-014-9747-x; Moosavi SM, 2022, NAT MATER, V21, P1419, DOI 10.1038/s41563-022-01374-3; Moosavi SM, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17755-8; Nagasawa S, 2018, J PHYS CHEM LETT, V9, P2639, DOI 10.1021/acs.jpclett.8b00635; Nigam A., 2019, ICLR; Pei ZR, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-0308-7; Perera D, 2018, SCIENCE, V359, P429, DOI 10.1126/science.aap9112; Preuer K, 2018, J CHEM INF MODEL, V58, P1736, DOI 10.1021/acs.jcim.8b00234; Probst D, 2022, DIGIT DISCOV, V1, P91, DOI 10.1039/d1dd00006c; Probst D, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-0416-x; Probst D, 2018, J CHEMINFORMATICS, V10, DOI 10.1186/s13321-018-0321-8; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ramos M. C., 2023, PREPRINT; RDKit contributors, 2023, RDKIT OPEN SOURCE CH; Sanchez-Lengeling B, 2018, SCIENCE, V361, P360, DOI 10.1126/science.aat2663; Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576; Taylor R., 2022, PREPRINT; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; van Deursen R, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00425-8; Vaswani A, 2017, ADV NEUR IN, V30; Walters P., 2018, PRACTICAL CHEMINFORM; Wang AYT, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00545-1; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang B., 2021, GITHUB; Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Westermayr J, 2023, NAT COMPUT SCI, V3, P139, DOI 10.1038/s43588-022-00391-1; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Winter Benedikt, 2022, Digit Discov, V1, P859, DOI 10.1039/d2dd00058j; Yao ZP, 2021, NAT MACH INTELL, V3, P76, DOI 10.1038/s42256-020-00271-1; Yüksel A, 2023, MACH LEARN-SCI TECHN, V4, DOI 10.1088/2632-2153/acdb30; Zhuo Y, 2018, J PHYS CHEM LETT, V9, P1668, DOI 10.1021/acs.jpclett.8b00124	86	10	10	57	57	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	FEB	2024	6	2					122	123		10.1038/s42256-023-00788-1	http://dx.doi.org/10.1038/s42256-023-00788-1		FEB 2024	2	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IY2B5		hybrid			2024-07-03	WOS:001157613800002
C	Feng, YH; Vanam, S; Cherukupally, M; Zheng, WJ; Qiu, MK; Chen, HH		Shahriar, H; Teranishi, Y; Cuzzocrea, A; Sharmin, M; Towey, D; Majumder, AKMJA; Kashiwazaki, H; Yang, JJ; Takemoto, M; Sakib, N; Banno, R; Ahamed, SI		Feng, Yunhe; Vanam, Sreecharan; Cherukupally, Manasa; Zheng, Weijian; Qiu, Meikang; Chen, Haihua			Investigating Code Generation Performance of ChatGPT with Crowdsourcing Social Data	2023 IEEE 47TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE, COMPSAC	Proceedings International Computer Software and Applications Conference		English	Proceedings Paper	47th IEEE-Computer-Society Annual International Conference on Computers, Software, and Applications (COMPSAC)	JUN 27-29, 2023	Univ Torino, Torino, ITALY	IEEE, IEEE Comp Soc	Univ Torino	ChatGPT; Coding Generation; Software Engineering; Large Language Models (LLMs); Generative Models; Social Media		The recent advancements in Artificial Intelligence, particularly in large language models and generative models, are reshaping the field of software engineering by enabling innovative ways of performing various tasks, such as programming, debugging, and testing. However, few existing works have thoroughly explored the potential of AI in code generation and users' attitudes toward AI-assisted coding tools. This knowledge gap leaves it unclear how AI is transforming software engineering and programming education. This paper presents a scalable crowdsourcing data-driven framework to investigate the code generation performance of generative large language models from diverse perspectives across multiple social media platforms. Specifically, we utilize ChatGPT, a popular generative large language model, as a representative example to reveal its insights and patterns in code generation. First, we propose a hybrid keyword word expansion method that integrates words suggested by topic modeling and expert knowledge to filter relevant social posts of interest on Twitter and Reddit. Then we collect 316K tweets and 3.2K Reddit posts about ChatGPT's code generation, spanning from Dec. 1, 2022 to January 31, 2023. Our data analytics show that ChatGPT has been used in more than 10 programming languages, with Python and JavaScript being the two most popular, for a diverse range of tasks such as code debugging, interview preparation, and academic assignment solving. Surprisingly, our analysis shows that fear is the dominant emotion associated with ChatGPT's code generation, overshadowing emotions of happiness, anger, surprise, and sadness. Furthermore, we construct a ChatGPT prompt and corresponding code dataset by analyzing the screen-shots of ChatGPT code generation shared on social media. This dataset enables us to evaluate the quality of the generated code, and we have released this dataset to the public. We believe the insights gained from our work will provide valuable guidance for future research on AI-powered code generation.	[Feng, Yunhe; Vanam, Sreecharan; Cherukupally, Manasa; Chen, Haihua] Univ North Texas, Denton, TX 76203 USA; [Zheng, Weijian] Argonne Natl Lab, Argonne, IL 60439 USA; [Qiu, Meikang] Dakota State Univ, Madison, SD USA	University of North Texas System; University of North Texas Denton; United States Department of Energy (DOE); Argonne National Laboratory; Dakota State University	Feng, YH (corresponding author), Univ North Texas, Denton, TX 76203 USA.	yunhe.feng@unt.edu; vanamsreecharan@my.unt.edu; manasacherukupally@my.unt.edu; wzheng@anl.gov; meikang.qiu@dsu.edu; haihua.chen@unt.edu	Feng, Yunhe/AAB-8342-2019	Feng, Yunhe/0000-0001-6577-227X; Chen, Haihua/0000-0002-7088-9752				Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; Avila-Chauvet L., 2023, Chatgpt as a support tool for online behavioral task programming; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Barke S, 2022, Arxiv, DOI [arXiv:2206.15000, DOI 10.48550/ARXIV.2206.15000]; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Chatterjee J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2022.100676; Chen HH, 2021, J MED LIBR ASSOC, V109, P395, DOI 10.5195/jmla.2021.1141; Chen M., 2021, arXiv; Ciniselli M, 2021, IEEE WORK CONF MIN S, P108, DOI 10.1109/MSR52588.2021.00024; Feng Y., 2019, 2019 IEEE GLOBAL COM, P1; Feng Y., 2023, The Impact of ChatGPT on Streaming Media: A Crowdsourced and Data-Driven Analysis using Twitter and Reddit; Feng Y., 2021, ICC 2021 IEEE INT C, P1; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870; Kauffman ME, 2020, SERV ORIENTED COMPUT, V14, P223, DOI 10.1007/s11761-020-00305-x; Li J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4159; Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739; Ni JM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P188; Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI [10.1145/2594291.2594321, 10.1145/2666356.2594321]; Röder M, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P399, DOI 10.1145/2684822.2685324; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984; Sun ZY, 2019, AAAI CONF ARTIF INTE, P7055; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tate T., 2023, Educational research and AI-generated writing: Confronting the coming tsunami; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Xia C.S., 2023, arXiv; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569; Ziade T., 2021, Flake8: Your tool for style guide enforcement	31	6	6	12	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0730-3157		979-8-3503-2697-0	P INT COMP SOFTW APP			2023							876	885		10.1109/COMPSAC57700.2023.00117	http://dx.doi.org/10.1109/COMPSAC57700.2023.00117			10	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5CB					2024-07-03	WOS:001046484100107
J	Buder-Gröndahl, T				Buder-Grondahl, Tommi			The ambiguity of BERTology: what do large language models represent?	SYNTHESE			English	Article						Linguistic representation; Language model; Deep learning; BERTology	DESCRIPTIVE CATEGORIES; NEURAL-NETWORKS; BIOLINGUISTICS	The field of "BERTology" aims to locate linguistic representations in large language models (LLMs). These have commonly been interpreted as representing structural descriptions (SDs) familiar from theoretical linguistics, such as abstract phrase-structures. However, it is unclear how such claims should be interpreted in the first place. This paper identifies six possible readings of "linguistic representation" from philosophical and linguistic literature, concluding that none has a straight-forward application to BERTology. In philosophy, representations are typically analyzed as cognitive vehicles individuated by intentional content. This clashes with a prevalent mentalist interpretation of linguistics, which treats SDs as (narrow) properties of cognitive vehicles themselves. I further distinguish between three readings of both kinds, and discuss challenges each brings for BERTology. In particular, some readings would make it trivially false to assign representations of SDs to LLMs, while others would make it trivially true. I illustrate this with the concrete case study of structural probing: a dominant model-interpretation technique. To improve the present situation, I propose that BERTology should adopt a more "LLM-first" approach instead of relying on pre-existing linguistic theories developed for orthogonal purposes.	[Buder-Grondahl, Tommi] Univ Helsinki, Dept Digital Humanities, Yliopistonkatu 3, Helsinki 00014, Finland	University of Helsinki	Buder-Gröndahl, T (corresponding author), Univ Helsinki, Dept Digital Humanities, Yliopistonkatu 3, Helsinki 00014, Finland.	tommi.grondahl@helsinki.fi		Buder-Grondahl, Tommi/0009-0003-2293-8964	Kulttuurin ja Yhteiskunnan Tutkimuksen Toimikunta	Kulttuurin ja Yhteiskunnan Tutkimuksen Toimikunta	I thank Anna-Mari Rusanen, Otto Lappi, and Jami Pekkanen for valuable discussions, and anonymous reviewers for helpful comments.	Adger D, 2022, MIND LANG, V37, P248, DOI 10.1111/mila.12407; [Anonymous], 1933, Language; Behme C, 2015, LANG SCI, V47, P32, DOI 10.1016/j.langsci.2014.07.012; Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254; Benacerraf P., 1973, Journal of Philosophy, V70, P661, DOI [DOI 10.2307/2025075, 10.2307/2025075]; Blaho S., 2007, The syntax of phonology: A radically substance-free approach; Bloomfield L, 1936, LANGUAGE, V12, P89, DOI 10.2307/408751; Boone W, 2016, PHILOS SCI, V83, P686, DOI 10.1086/687855; Brentano F., 1911, PSYCHOL EMPIRICAL ST; Brunila M, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4403; Buckner C, 2018, SYNTHESE, V195, P5339, DOI 10.1007/s11229-018-01949-1; BURGE T, 1986, PHILOS REV, V95, P3, DOI 10.2307/2185131; Cappelen H., 2021, Making AI intelligible: Philosophical foundations, DOI [10.1093/oso/9780192894724.001.0001, DOI 10.1093/OSO/9780192894724.001.0001]; Chalmers D. J., 1994, Minds and Machines, V4, P391, DOI 10.1007/BF00974166; Chi E.A., 2020, P 58 ANN M ASS COMPU, P5564, DOI [DOI 10.18653/V1/2020.ACL-MAIN.493, 10.18653/v1/2020.acl-main.493]; CHOMSKY N, 1980, BEHAV BRAIN SCI, V3, P1, DOI 10.1017/S0140525X00001515; Chomsky N., 1968, SOUND PATTERNS ENGLI; Chomsky N, 1957, SYNTACTIC STRUCTURES; Chomsky N., 1995, The Minimalist Program; Chomsky N., 1965, Aspects of the Theory of Syntax; Chomsky N., 1986, BARRIERS; Chomsky Noam, 2012, The Science of Language: Interviews with James McGilvray, DOI DOI 10.1017/CBO9781139061018; Chomsky Noam., 1955, The logical structure of linguistic theory; Coenen Andy, 2019, Advances in Neural Information Processing Systems, V32, P8594; Collins J., 2014, Semantics and beyond: Philosophical and linguistic inquiries, P2764; Collins J, 2023, SYNTHESE, V201, DOI 10.1007/s11229-023-04074-w; Collins J, 2021, BLACKW COMPAN PHILOS, P488; Croft W., 2001, Radical Construction Grammar, DOI DOI 10.1093/ACPROF:OSO/9780198299554.001.0001; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; DENNETT DC, 1993, PHILOS PHENOMEN RES, V53, P889, DOI 10.2307/2108259; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DRETSKE F, 1983, BEHAV BRAIN SCI, V6, P55, DOI 10.1017/S0140525X00014631; Dunbar E, 2019, LANGUAGE, V95, pE87, DOI 10.1353/lan.2019.0013; Dupre G., 2022, BJPS Review of Books; Egan F., 2017, Explanation and integration in mind and brain science, P145, DOI DOI 10.1093/OSO/9780199685509.003.0007; Egan F, 2019, ROUTLEDGE HBK PHILOS, P247; Egan F, 2014, PHILOS STUD, V170, P115, DOI 10.1007/s11098-013-0172-0; Egan F, 2010, STUD HIST PHILOS SCI, V41, P253, DOI 10.1016/j.shpsa.2010.07.009; Facchin M, 2022, PHILOS PSYCHOL, DOI 10.1080/09515089.2022.2119952; Favela LH., 2023, Frontiers in Psychology, V5, P14; Fodor J., 1981, Readings in the Philosophy of Psychology, V2, P197; Fodor J. A., 1990, THEORY CONTENT OTHER; Gastaldi JL, 2021, INTERDISCIPL SCI REV, V46, P569, DOI 10.1080/03080188.2021.1890484; Gleitman L, 2021, BLACKW COMPAN PHILOS, P109; Goldberg A., 2006, Constructions at work: The nature of generalization in language; Harris Z.S., 1951, Methods in Structural Linguistics; Haspelmath M, 2020, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.03056; Haspelmath M, 2010, LANGUAGE, V86, P663; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Immer A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1839; Iosad P., 2017, A substance-free framework for phonology: An analysis of the Breton dialect of Bothoa, DOI [10.1515/9781474407380, DOI 10.1515/9781474407380]; Jackson Frank., 1977, PERCEPTION; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Jelinek F, 2005, LANG RESOUR EVAL, V39, P25, DOI 10.1007/s10579-005-2693-4; Kaplan DM, 2011, SYNTHESE, V183, P339, DOI 10.1007/s11229-011-9970-0; Karlsson F., 2006, ADV NATURAL LANGUAGE, P1; Katz Jerrold., 1981, LANGUAGE OTHER ABSTR; Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365; Kripke, 1980, NAMING NECESSITY; Kulmizev A, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.796788; Kulmizev A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4077; Kuokkanen J, 2022, SYNTHESE, V200, DOI 10.1007/s11229-022-03725-8; Kuznetsov I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P171; Lakoff G., 1990, Cognitive Linguistics, V1, P39, DOI 10.1515/cogl.1990.1.1.39; Langacker RW, 1998, NEW PSYCHOLOGY OF LANGUAGE, P1; Lasri K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8818; Laurence S., 2003, Epistemology of language, 2003, P69, DOI 10.1093/oso/9780199250578.003.0003; Levine R, 2018, STUD LANG C, V196, P21, DOI 10.1075/slcs.196.03lev; Levy A, 2013, BIOL PHILOS, V28, P99, DOI 10.1007/s10539-012-9337-z; LEWIS D, 1970, J PHILOS, V67, P427, DOI 10.2307/2023861; Li JD, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1144; Li L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6193; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Marcus GF, 1998, COGNITIVE PSYCHOL, V37, P243, DOI 10.1006/cogp.1998.0694; Marr D., 1982, Vision; Matthews RJ., 2007, MEASURE MIND PROPOSI, DOI [10.1093/acprof:oso/9780199211258.001.0001, DOI 10.1093/ACPROF:OSO/9780199211258.001.0001]; McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Mickus T., 2020, P SOC COMP LING, P350, DOI DOI 10.7275/T778-JA71; Miller PhilipH., 1999, STRONG GENERATIVE CA; Millikan R., 2017, Beyond concepts: Unicepts, language, and natural information, DOI [10.1093/oso/9780198717195.001.0001, DOI 10.1093/OSO/9780198717195.001.0001]; Millikan R., 1993, Spatial Representation, P256; Mueller A, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1352; Nadeem M., 2020, P 59 ANN M ASS COMP, P5356; Neander K, 2017, LIFE MIND-PHILOS ISS, P1; Nefdt RM., 2023, Language, science, and structure: A journey into the philosophy of linguistics, DOI [10.1093/oso/9780197653098.001.0001, DOI 10.1093/OSO/9780197653098.001.0001]; Newmeyer FJ, 2010, LANGUAGE, V86, P688, DOI 10.1353/lan.2010.0000; Odden David., 2013, Nordlyd, V40, P249, DOI [10.7557/12.2476, DOI 10.7557/12.2476]; OpenAI, 2023, GPT-4 Technical Report; Ott D., 2017, Frontiers in Psychology, V7, P8; Pater J, 2019, LANGUAGE, V95, pE41, DOI 10.1353/lan.2019.0009; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Piccinini G., 2015, Physical computation: A mechanistic account, DOI [10.1093/acprof:oso/9780199658855.001.0001, DOI 10.1093/ACPROF:OSO/9780199658855.001.0001]; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; Poeppel D, 2005, TWENTY-FIRST CENTURY PSYCHOLINGUISTICS: FOUR CORNERSTONES, P103; Postal PM, 2003, PHILOS FORUM, V34, P233, DOI 10.1111/1467-9191.00137; Postal PM, 2009, BIOLINGUISTICS, V3, P104; Putnam H., 1988, Representation and Reality; QUINE WV, 1970, SYNTHESE, V21, P386, DOI 10.1007/BF00484806; Rey Georges., 2020, Representation of Language: Philosophical Issues in a Chomskyan Linguistics; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rumelhart DE, 1986, Parallel Distributed Processing vol. 2, V2, P216, DOI [DOI 10.7551/MITPRESS/5236.001.0001, 10.7551/mitpress/5237.003.0008, DOI 10.7551/MITPRESS/5237.003.0008]; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Smith B. C., 2006, Croatian Journal of Philosophy, V6, P431; Soler AG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7371; Sprevak M, 2019, ROUTLEDGE HBK PHILOS, P175; SWOYER C, 1991, SYNTHESE, V87, P449, DOI 10.1007/BF00499820; Tayyar Madabushi Harish., 2020, Proceedings of the 28th International Conference on Computational Linguistics, P4020; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Vaswani A, 2017, ADV NEUR IN, V30; Weiss G., 2021, P MACHINE LEARNING R, P11080	112	0	0	9	9	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0039-7857	1573-0964		SYNTHESE	Synthese	DEC 26	2023	203	1							15	10.1007/s11229-023-04435-5	http://dx.doi.org/10.1007/s11229-023-04435-5			32	History & Philosophy Of Science; Philosophy	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	History & Philosophy of Science; Philosophy	DD8C3		hybrid			2024-07-03	WOS:001130174400001
J	Safranek, CW; Sidamon-Eristoff, AE; Gilson, A; Chartash, D				Safranek, Conrad W.; Sidamon-Eristoff, Anne Elizabeth; Gilson, Aidan; Chartash, David			The Role of Large Language Models in Medical Education: Applications and Implications	JMIR MEDICAL EDUCATION			English	Editorial Material						large language models; ChatGPT; medical education; LLM; artificial intelligence in health care; AI; autoethnography		Large language models (LLMs) such as ChatGPT have sparked extensive discourse within the medical education community, spurring both excitement and apprehension. Written from the perspective of medical students, this editorial offers insights gleaned through immersive interactions with ChatGPT, contextualized by ongoing research into the imminent role of LLMs in health care. Three distinct positive use cases for ChatGPT were identified: facilitating differential diagnosis brainstorming, providing interactive practice cases, and aiding in multiple-choice question review. These use cases can effectively help students learn foundational medical knowledge during the preclinical curriculum while reinforcing the learning of core Entrustable Professional Activities. Simultaneously, we highlight key limitations of LLMs in medical education, including their insufficient ability to teach the integration of contextual and external information, comprehend sensory and nonverbal cues, cultivate rapport and interpersonal interaction, and align with overarching medical education and patient care goals. Through interacting with LLMs to augment learning during medical school, students can gain an understanding of their strengths and weaknesses. This understanding will be pivotal as we navigate a health care landscape increasingly intertwined with LLMs and artificial intelligence.	[Safranek, Conrad W.; Gilson, Aidan; Chartash, David] Yale Univ, Sect Biomed Informat & Data Sci, Sch Med, New Haven, CT USA; [Sidamon-Eristoff, Anne Elizabeth] Yale Univ, Sch Med, New Haven, CT USA; [Chartash, David] Univ Coll Dublin, Natl Univ Ireland, Sch Med, Dublin, Ireland; [Chartash, David] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 9th Fl, 100 Coll St, New Haven, CT 06510 USA	Yale University; Yale University; University College Dublin; Yale University	Chartash, D (corresponding author), Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 9th Fl, 100 Coll St, New Haven, CT 06510 USA.	david.chartash@yale.edu		Gilson, Aidan/0000-0002-4770-4705; Sidamon-Eristoff, Anne Elizabeth/0000-0001-7422-9703; Safranek, Conrad/0000-0003-1985-9432	National Heart, Lung, and Blood Institute of the National Institutes of Health [T35HL007649]; National Institute of General Medical Sciences of the National Institutes of Health [T32GM136651]; National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health [T35DK104689]; Yale School of Medicine Fellowship for Medical Student Research	National Heart, Lung, and Blood Institute of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); National Institute of General Medical Sciences of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK)); Yale School of Medicine Fellowship for Medical Student Research	Research reported in this publication was supported by the National Heart, Lung, and Blood Institute of the National Institutes of Health under award T35HL007649 (CWS) , the National Institute of General Medical Sciences of the National Institutes of Health under award T32GM136651 (AESE) , the National Institute of Diabetes and Digestive and Kidney Diseases of the National Institutes of Health under award T35DK104689 (AG) , and the Yale School of Medicine Fellowship for Medical Student Research (AG) . The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	Adams K., 2023, MedCity News; [Anonymous], 2020, BAS MED ED WFME GLOB; [Anonymous], GPT BEST PRACT; [Anonymous], 2019, CORE ENTRUSTABLE PRO; [Anonymous], CORE ENTRUSTABLE PRO; ASHER R, 1960, BMJ-BRIT MED J, V1, P985, DOI 10.1136/bmj.1.5178.985; Barr K., 2023, Gizmodo; Brants T., 2007, P 2007 JOINT C EMP M, P858; Charlin B, 2000, TEACH LEARN MED, V12, P189, DOI 10.1207/S15328015TLM1204_5; Chartash David, 2022, JMIR Med Educ, V8, pe39794, DOI 10.2196/39794; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Croskerry P, 2002, ACAD EMERG MED, V9, P1184, DOI 10.1197/aemj.9.11.1184; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farrell L, 2015, MED EDUC, V49, P974, DOI 10.1111/medu.12761; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hersh W, 2020, HLTH SYSTEMS SCI, P105; Hersh WR, 2014, ADV MED EDUC PRACT, V5, P205, DOI 10.2147/AMEP.S63903; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Hrynchak P, 2012, MED TEACH, V34, P796, DOI 10.3109/0142159X.2012.687120; Introducing ChatGPT, OpenAI; Johnson D, 2023, PREPRINT, DOI DOI 10.21203/RS.3.RS-2566942/V1; Kost A, 2015, ACAD MED, V90, P20, DOI 10.1097/ACM.0000000000000446; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Landi H., 2023, Fierce Healthcare; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Martin A, 2021, SIMUL HEALTHC, V16, pE129, DOI 10.1097/SIH.0000000000000528; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Olson P., 2023, WASHINGTON POST 0605; OpenAI, 2022, GPT 3 MOD CARD; Ouyang L., 2022, NEURIPS; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singh S, 2021, IEEE ACCESS, V9, P68675, DOI 10.1109/ACCESS.2021.3077350; Talley NJ., 2014, Clinical Examination: A Systematic Guide to Physical Diagnosis; Wijnen-Meijer M, 2013, MED TEACH, V35, P301, DOI 10.3109/0142159X.2012.746449; Xu GZ, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04176-7; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216	38	23	23	20	40	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e50945	10.2023/1/e50945	http://dx.doi.org/10.2023/1/e50945			12	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	P7JF4	37578830				2024-07-03	WOS:001052393000001
J	Westbrook, JI; Wabe, N; Raban, MZ				Westbrook, Johanna I.; Wabe, Nasir; Raban, Magdalena Z.			Using AI to improve medication safety	NATURE MEDICINE			English	Article; Early Access								Large language models can translate the archaic language of pharmacy prescriptions into plain English, but reducing medication errors for patients will require interventions that go further.	[Westbrook, Johanna I.; Wabe, Nasir; Raban, Magdalena Z.] Macquarie Univ, Australian Inst Hlth Innovat, Ctr Hlth Syst & Safety Res, Sydney, NSW, Australia	Macquarie University	Westbrook, JI (corresponding author), Macquarie Univ, Australian Inst Hlth Innovat, Ctr Hlth Syst & Safety Res, Sydney, NSW, Australia.	johanna.westbrook@mq.edu.au	Raban, Magdalena Z/J-8361-2012; Westbrook, Johanna/J-9045-2018	Raban, Magdalena Z/0000-0002-6995-2849; Wabe, Nasir/0000-0002-9740-6319; Westbrook, Johanna/0000-0003-1083-8192				Cirillo D, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0288-5; Davis TC, 2006, ANN INTERN MED, V145, P887, DOI 10.7326/0003-4819-145-12-200612190-00144; Feiner JR, 2007, ANESTH ANALG, V105, pS18, DOI 10.1213/01.ane.0000285988.35174.d9; Huang YM, 2022, HEALTH SOC CARE COMM, V30, P753, DOI 10.1111/hsc.13190; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Lyell D, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0425-5; Manchanayake MGCA, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3252-1; Moore J. E., 2024, World Economic Forum; Murugan M, 2024, J AM MED INFORM ASSN, V31, P1356, DOI 10.1093/jamia/ocae039; Pais C, 2024, NAT MED, DOI 10.1038/s41591-024-02933-8; Wolf MS, 2009, MED CARE, V47, P370, DOI 10.1097/MLR.0b013e31818af91a; Yin HS, 2021, PEDIATRICS, V148, DOI 10.1542/peds.2021-054666	12	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	2024 MAY 8	2024										10.1038/s41591-024-02980-1	http://dx.doi.org/10.1038/s41591-024-02980-1		MAY 2024	2	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	PS4N5	38720001				2024-07-03	WOS:001216060300002
C	Roest, L; Keuning, H; Jeuring, J			ACM	Roest, Lianne; Keuning, Hieke; Jeuring, Johan			Next-Step Hint Generation for Introductory Programming Using Large Language Models	PROCEEDINGS OF THE 26TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2024			English	Proceedings Paper	26th Australasian Computing Education Conference (ACE)	JAN 29-FEB 02, 2024	Sydney, AUSTRALIA			Next-step hints; automated feedback; learning programming; Large Language Models; Generative AI		Large Language Models possess skills such as answering questions, writing essays or solving programming exercises. Since these models are easily accessible, researchers have investigated their capabilities and risks for programming education. This work explores how LLMs can contribute to programming education by supporting students with automated next-step hints. We investigate prompt practices that lead to effective next-step hints and use these insights to build our StAP-tutor. We evaluate this tutor by conducting an experiment with students, and performing expert assessments. Our findings show that most LLM-generated feedback messages describe one specific next step and are personalised to the student ' s code and approach. However, the hints may contain misleading information and lack sufficient detail when students approach the end of the assignment. This work demonstrates the potential for LLM-generated feedback, but further research is required to explore its practical implementation.	[Roest, Lianne; Keuning, Hieke; Jeuring, Johan] Univ Utrecht, Utrecht, Netherlands	Utrecht University	Roest, L (corresponding author), Univ Utrecht, Utrecht, Netherlands.	lianneroest@gmail.com; h.w.keuning@uu.nl; j.t.jeuring@uu.nl		Keuning, Hieke/0000-0001-5778-7519				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anderson John R, 1985, The LISP tutor, V10, P4; [Anonymous], 2008, Handbook of research on educational communications and technology; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Dawson P, 2019, ASSESS EVAL HIGH EDU, V44, P25, DOI 10.1080/02602938.2018.1467877; Deeva G, 2021, COMPUT EDUC, V162, DOI 10.1016/j.compedu.2020.104094; Denny P, 2023, Arxiv, DOI arXiv:2306.02608; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Hao Q, 2022, COMPUT SCI EDUC, V32, P105, DOI 10.1080/08993408.2020.1860408; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Hellas A, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P93, DOI 10.1145/3568813.3600139; Irons A, 2021, Enhancing learning through formative assessment; Jeuring Johan, 2022, ITiCSE-WGR '22: Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education, P95, DOI 10.1145/3571785.3574124; Kazemitabaar M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580919; Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711; Keuning Hieke, 2014, P CSERC, P43; Kiesler N, 2023, Arxiv, DOI arXiv:2309.00029; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Lyulina Elena, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P495, DOI 10.1145/3408877.3432534; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; Malysheva Yana, 2022, P KOL CALL, P1; Marwan S, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P520, DOI 10.1145/3304221.3319759; Mousavinasab E, 2021, INTERACT LEARN ENVIR, V29, P142, DOI 10.1080/10494820.2018.1558257; Paassen Benjamin, 2018, JEDM, V10, P1, DOI 10.5281/zenodo.3554697; Phung T, 2023, Arxiv, DOI arXiv:2302.04662; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prather James, 2023, ACM Trans. Comput.- Hum. Interact.; Price TW, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P127, DOI 10.1145/3105726.3106179; Pricer TW, 2019, INT J ARTIF INTELL E, V29, P368, DOI 10.1007/s40593-019-00177-z; Rivers K, 2017, INT J ARTIF INTELL E, V27, P37, DOI 10.1007/s40593-015-0070-z; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Shute VJ, 2008, REV EDUC RES, V78, P153, DOI 10.3102/0034654307313795; ThomasWPrice Yihuan Dong, 2016, Int. Educ. Data Mining Society; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Zhang J., 2022, arXiv	42	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1619-5				2024							144	153		10.1145/3636243.3636259	http://dx.doi.org/10.1145/3636243.3636259			10	Computer Science, Software Engineering; Computer Science, Theory & Methods; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW5RQ		Green Submitted			2024-07-03	WOS:001166861800016
J	Son, J; Kim, B				Son, Jungha; Kim, Boyoung			Trend Analysis of Large Language Models through a Developer Community: A Focus on Stack Overflow	INFORMATION			English	Article						large language model; Transformer; Hugging Face; Stack Overflow; developer community	TOPICS	In the rapidly advancing field of large language model (LLM) research, platforms like Stack Overflow offer invaluable insights into the developer community's perceptions, challenges, and interactions. This research aims to analyze LLM research and development trends within the professional community. Through the rigorous analysis of Stack Overflow, employing a comprehensive dataset spanning several years, the study identifies the prevailing technologies and frameworks underlining the dominance of models and platforms such as Transformer and Hugging Face. Furthermore, a thematic exploration using Latent Dirichlet Allocation unravels a spectrum of LLM discussion topics. As a result of the analysis, twenty keywords were derived, and a total of five key dimensions, "OpenAI Ecosystem and Challenges", "LLM Training with Frameworks", "APIs, File Handling and App Development", "Programming Constructs and LLM Integration", and "Data Processing and LLM Functionalities", were identified through intertopic distance mapping. This research underscores the notable prevalence of specific Tags and technologies within the LLM discourse, particularly highlighting the influential roles of Transformer models and frameworks like Hugging Face. This dominance not only reflects the preferences and inclinations of the developer community but also illuminates the primary tools and technologies they leverage in the continually evolving field of LLMs.	[Son, Jungha; Kim, Boyoung] aSSIST Univ, Seoul Business Sch, Seoul 03767, South Korea		Kim, B (corresponding author), aSSIST Univ, Seoul Business Sch, Seoul 03767, South Korea.	jhson@stud.assist.ac.kr; bykim2@assist.ac.kr						[Anonymous], 2000, P NEUR INF PROC SYST; archive, Stack exchange data dump: Stack exchange, inc.; Asaduzzaman M, 2013, IEEE WORK CONF MIN S, P97, DOI 10.1109/MSR.2013.6624015; Barua A, 2014, EMPIR SOFTW ENG, V19, P619, DOI 10.1007/s10664-012-9231-y; Bird S., 2006, PAPER PRESENTED COLI, P69, DOI [10.48550/arXiv.cs/0205028, DOI 10.3115/1225403.1225421, 10.3115/1225403.1225421]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Creative Commons, About us; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111332; Ford D, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P846, DOI 10.1145/2950290.2950331; Hagberg A. A., 2008, Proc. of the 7th Python in Science Conf. (SciPy2008), P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003; Han JX, 2020, EMPIR SOFTW ENG, V25, P2694, DOI 10.1007/s10664-020-09819-6; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hussain Z., 2022, P SAI INT SYST C AMS, P424; Ithipathachai V, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1483, DOI 10.1145/3477314.3506985; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; LangChain, About us; Li H, 2022, COMMUN ACM, V65, P56, DOI 10.1145/3490443; Li J, 2022, arXiv; Linares-Vasquez M., 2014, P 22 INT C PROGR COM, P83, DOI DOI 10.1145/2597008.2597155; Omondiagbe OP, 2019, PROCEEDINGS OF EASE 2019 - EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, P101, DOI 10.1145/3319008.3319024; Peruma A, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-021-10045-x; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rehurek R., 2011, Gensim-python framework for vector space modelling., V3, P2; Rodríguez LJ, 2018, IEEE INT CONGR BIG, P219, DOI 10.1109/BigDataCongress.2018.00037; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Singh J., 2022, Int. J. Web Sci., V3, P236; spacy io, Industrial-Strength Natural Language Processing; SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Thakur N, 2022, INFECT DIS REP, V14, P855, DOI 10.3390/idr14060087; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Topsakal O., 2023, INT C APPL ENG NATUR, V1, P1050; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaithilingam P., 2022, P CHI C HUM FACT COM, P1; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Xiao KJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042204; Yazdanian R, 2021, INT J ARTIF INTELL E, V31, P896, DOI 10.1007/s40593-020-00231-1; Zhu WH, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-022-10180-z	46	0	0	8	9	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	NOV	2023	14	11							602	10.3390/info14110602	http://dx.doi.org/10.3390/info14110602			15	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	AK5T1		gold			2024-07-03	WOS:001118379700001
J	Bzdok, D; Thieme, A; Levkovskyy, O; Wren, P; Ray, T; Reddy, S				Bzdok, Danilo; Thieme, Andrew; Levkovskyy, Oleksiy; Wren, Paul; Ray, Thomas; Reddy, Siva			Data science opportunities of large language models for neuroscience and biomedicine	NEURON			English	Article							BRAINMAP; SMILES	Large language models (LLMs) are a new asset class in the machine-learning landscape. Here we offer a primer on defining properties of these modeling techniques. We then reflect on new modes of investigation in which LLMs can be used to reframe classic neuroscience questions to deliver fresh answers. We reason that LLMs have the potential to (1) enrich neuroscience datasets by adding valuable meta-information, such as advanced text sentiment, (2) summarize vast information sources to overcome divides between siloed neuroscience communities, (3) enable previously unthinkable fusion of disparate information sources relevant to the brain, (4) help deconvolve which cognitive concepts most usefully grasp phenomena in the brain, and much more.	[Bzdok, Danilo; Reddy, Siva] Mila Quebec Artificial Intelligence Inst, Montreal, PQ, Canada; [Thieme, Andrew; Levkovskyy, Oleksiy; Wren, Paul; Ray, Thomas] Mindstate Design Labs, San Francisco, CA USA; [Bzdok, Danilo] McGill Univ, Neuro Montreal Neurol Inst MNI, Dept Biomed Engn, Montreal, PQ, Canada; [Reddy, Siva] ServiceNow Res, Montreal, PQ, Canada	McGill University	Bzdok, D (corresponding author), Mila Quebec Artificial Intelligence Inst, Montreal, PQ, Canada.; Bzdok, D (corresponding author), McGill Univ, Neuro Montreal Neurol Inst MNI, Dept Biomed Engn, Montreal, PQ, Canada.	danilobzdok@gmail.com			Brain Canada Foundation, through the Canada Brain Research Fund; Health Canada; National Institutes of Health [NIH R01 AG068563A]; Canadian Institute of Health Research [NIH R01 DA053301-01A1, NIH R01 MH129858-01A1]; Healthy Brains Healthy Lives initiative (Canada First Research Excellence fund); Google; CIFAR Artificial Intelligence Chairs program (Canada Institute for Advanced Research);  [CIHR 438531];  [CIHR 470425]	Brain Canada Foundation, through the Canada Brain Research Fund; Health Canada; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Canadian Institute of Health Research(Canadian Institutes of Health Research (CIHR)); Healthy Brains Healthy Lives initiative (Canada First Research Excellence fund); Google(Google Incorporated); CIFAR Artificial Intelligence Chairs program (Canada Institute for Advanced Research); ; 	D.B. was supported by the Brain Canada Foundation, through the Canada Brain Research Fund, with the financial support of Health Canada, National Institutes of Health (NIH R01 AG068563A, NIH R01 DA053301-01A1, NIH R01 MH129858-01A1) , the Canadian Institute of Health Research (CIHR 438531, CIHR 470425) , the Healthy Brains Healthy Lives initiative (Canada First Research Excellence fund) , Google (Research Award, Teaching Award) , and by the CIFAR Artificial Intelligence Chairs program (Canada Institute for Advanced Research) .	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Anscombe G. E. M., 1958, Philosophical investigations, V2nd; Anttila V, 2018, SCIENCE, V360, P1313, DOI 10.1126/science.aap8757; Ballentine G, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abl6989; Bapna A, 2019, Arxiv, DOI [arXiv:1909.08478, DOI 10.48550/ARXIV.1909.08478]; Beam E, 2021, NAT NEUROSCI, V24, P1733, DOI 10.1038/s41593-021-00948-9; Berglund L, 2024, Arxiv, DOI [arXiv:2309.12288, DOI 10.48550/ARXIV.2309.12288]; Brandes N, 2023, NAT GENET, V55, P1512, DOI 10.1038/s41588-023-01465-0; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bzdok D, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100119; Bzdok D, 2019, TRENDS NEUROSCI, V42, P251, DOI 10.1016/j.tins.2019.02.001; Bzdok D, 2017, NEUROIMAGE, V155, P549, DOI 10.1016/j.neuroimage.2017.04.061; Bzdok D, 2012, BRAIN STRUCT FUNCT, V217, P783, DOI 10.1007/s00429-012-0380-y; Caballero E, 2022, Arxiv, DOI [arXiv:2210.14891, 10.48550/arXiv.2210.14891, DOI 10.48550/ARXIV.2210.14891]; Caucheteux C, 2023, NAT HUM BEHAV, DOI 10.1038/s41562-022-01516-2; Conneau A, 2018, Arxiv, DOI [arXiv:1705.02364, DOI 10.48550/ARXIV.1705.02364]; Cui HT, 2023, bioRxiv, DOI [10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439, DOI 10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439v2, DOI 10.1101/2023.04.30.538439V2]; Dohmatob E, 2020, HUM BRAIN MAPP, V41, P3318, DOI 10.1002/hbm.25019; Dziri N, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204.07931, 10.48550/arXiv.2204.07931]; Fox PT, 2002, NAT REV NEUROSCI, V3, P319, DOI 10.1038/nrn789; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Gyorgy Buzsaki M., 2019, The Brain from Inside Out; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hassid M, 2022, arXiv; Hipp Rachel, 2016, Hosp Pharm, V51, P416, DOI 10.1310/hpj5105-416; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Houlsby N, 2019, PR MACH LEARN RES, V97; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Krakauer JW, 2017, NEURON, V93, P480, DOI 10.1016/j.neuron.2016.12.041; Laird AR, 2011, J COGNITIVE NEUROSCI, V23, P4022, DOI 10.1162/jocn_a_00077; Laird AR, 2005, NEUROINFORMATICS, V3, P65, DOI 10.1385/NI:3:1:065; Liu FY, 2021, Arxiv, DOI [arXiv:2109.13238, DOI 10.48550/ARXIV.2109.13238]; McCann B, 2017, ADV NEUR IN, V30; Mesulam MM, 1998, BRAIN, V121, P1013, DOI 10.1093/brain/121.6.1013; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Naisbitt J., 1988, MEGATRENDS 10 NEW DI; Naselaris T, 2009, NEURON, V63, P902, DOI 10.1016/j.neuron.2009.09.006; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pessoa L, 2008, NAT REV NEUROSCI, V9, P148, DOI 10.1038/nrn2317; Pfeiffer J, 2020, Arxiv, DOI [arXiv:2007.07779, DOI 10.48550/ARXIV.2007.07779]; Poldrack RA, 2006, TRENDS COGN SCI, V10, P59, DOI 10.1016/j.tics.2005.12.004; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Rodziewicz TL., 2023, StatPearls; Schaeffer R, 2023, Arxiv, DOI [arXiv:2304.15004, DOI 10.48550/ARXIV.2304.15004, 10.48550/arXiv.2304.15004]; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Shanahan M, 2023, NATURE, V623, P493, DOI 10.1038/s41586-023-06647-8; Sharma A, 2021, J CHEM INF MODEL, V61, P676, DOI 10.1021/acs.jcim.0c01288; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Spreng RN, 2009, J COGNITIVE NEUROSCI, V21, P489, DOI 10.1162/jocn.2008.21029; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Tay Y, 2020, Arxiv, DOI arXiv:2011.04006; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Van Overwalle F, 2011, NEUROIMAGE, V54, P1589, DOI 10.1016/j.neuroimage.2010.09.043; Vaswani A, 2017, ADV NEUR IN, V30; Voytek B, 2022, NAT METHODS, V19, P1349, DOI 10.1038/s41592-022-01630-z; Wagner SK, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2021-058552; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wu CY, 2023, Arxiv, DOI [arXiv:2304.14454, DOI 10.48550/ARXIV.2304.14454]; Xiang JA, 2023, Arxiv, DOI [arXiv:2305.10626, DOI 10.48550/ARXIV.2305.10626, 10.48550/arXiv.2305.10626]; Yang EN, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-39862-y; Yarkoni T, 2011, NAT METHODS, V8, P665, DOI [10.1038/NMETH.1635, 10.1038/nmeth.1635]; Ye ZY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227620; Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x	73	0	0	6	6	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	0896-6273	1097-4199		NEURON	Neuron	MAR 6	2024	112	5					698	717		10.1016/j.neuron.2024.01.016	http://dx.doi.org/10.1016/j.neuron.2024.01.016		MAR 2024	20	Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	NT9S9	38340718	hybrid			2024-07-03	WOS:001202831200001
C	Ngu, N; Lee, N; Shakarian, P			IEEE	Ngu, Noel; Lee, Nathaniel; Shakarian, Paulo			Diversity Measures: Domain-Independent Proxies for Failure in Language Model Queries	18TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC 2024	IEEE International Conference on Semantic Computing		English	Proceedings Paper	18th IEEE International Conference on Semantic Computing (ICSC)	FEB 05-07, 2024	Laguna Hills, CA	IEEE, IEEE Comp Soc		LLM; error detection; natural language interface; LLM hallucination		Hallucinations and reasoning errors limit the ability of large language models (LLMs) to serve as a natural language interface for various prompts. Meanwhile, error prediction in large language models often relies on domain-specific information. In this paper, we present domain independent measures for quantification of error in the response of a large language model based on the diversity of responses to a given prompt specifically considering components of the response. This results in an approach that is well-suited for prompts where the response can be viewed as an answer set such as semantic prompts, a common natural language interface use-case. We describe how three such measures - based on entropy, Gini impurity, and centroid distance - can be employed. We perform a suite of experiments on multiple datasets and temperature settings to demonstrate that these measures strongly correlate with the probability of failure. Additionally, we present empirical results demonstrating how these measures can be applied to few-shot prompting, chain-of-thought reasoning, and error detection.	[Ngu, Noel; Lee, Nathaniel; Shakarian, Paulo] Arizona State Univ, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe	Ngu, N (corresponding author), Arizona State Univ, Tempe, AZ 85287 USA.	nngu2@asu.edu; nlee51@asu.edu; pshakari@asu.edu			Army Research Office (ARO) [W911NF-24-1-0007]; ASU Fulton Schools of Engineering	Army Research Office (ARO); ASU Fulton Schools of Engineering	This research was funded by Army Research Office (ARO) grant W911NF-24-1-0007 "Reasoning About Machine Learning" as well as internal funding from the ASU Fulton Schools of Engineering.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aditya D., 2023, AAAI SPRING S; Agrawal A, 2024, Arxiv, DOI arXiv:2305.18248; Daftry S, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1743, DOI 10.1109/IROS.2016.7759279; Diao SZ, 2024, Arxiv, DOI arXiv:2302.12246; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Ficler J., 2023, P WORKSHOP, P94; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Holtzman A., 2019, P INT C LEARN REPR; Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209; Kocoń J, 2023, Arxiv, DOI arXiv:2302.10724; Kuhn L., 2023, 11 INT C LEARNING RE; Lin Z, 2024, Arxiv, DOI [arXiv:2305.19187, 10.48550/arXiv.2305.19187]; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu J. X., 2022, WORKSHOP LANGUAGE RO; Manakul P., 2023, Empirical Methods in Natural Language Processing (EMNLP); Pardos Z. A., 2023, arXiv; Ramanagopal MS, 2018, IEEE ROBOT AUTOM LET, V3, P3860, DOI 10.1109/LRA.2018.2857402; Ray P. P., 2023, ChatGPT: A comprehensive review on background, applications, key challenges, bias, ethics, limitations and future scope, V3, P121; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Saha A., 2018, P 32 AAAI C ARTIFICI; Shakarian P., 2023, AAAI SPRING S; Tian K, 2023, Arxiv, DOI arXiv:2305.14975; Tu SQ, 2024, Arxiv, DOI [arXiv:2304.14106, 10.48550/arXiv.2304.14106]; Upadhyay S., 2017, arXiv; Vaithilingam P., CHI C HUMAN FACTORS; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yuan Z, 2023, Arxiv, DOI arXiv:2304.02015; Zhou K., 2023, Empirical Methods in Natural Language Processing (EMNLP); Zhou KY, 2023, IEEE T PATTERN ANAL, V45, P4396, DOI 10.1109/TPAMI.2022.3195549	32	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2325-6516		979-8-3503-8535-9	IEEE INT C SEMANT CO			2024							176	182		10.1109/ICSC59802.2024.00034	http://dx.doi.org/10.1109/ICSC59802.2024.00034			7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7TH		Green Submitted			2024-07-03	WOS:001196221400027
C	Lanciano, G; Stein, M; Hilt, V; Cucinotta, T		VanSteen, M; Pahl, C		Lanciano, Giacomo; Stein, Manuel; Hilt, Volker; Cucinotta, Tommaso			Analyzing Declarative Deployment Code with Large Language Models	PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND SERVICES SCIENCE, CLOSER 2023	CLOSER		English	Proceedings Paper	13th International Conference on Cloud Computing and Services Science (CLOSER)	APR 26-28, 2023	Prague, CZECH REPUBLIC	INSTICC		Large Language Models; Infrastructure-as-Code; DevOps; Kubernetes; Machine Learning; Quality Assurance		In the cloud-native era, developers have at their disposal an unprecedented landscape of services to build scalable distributed systems. The DevOps paradigm emerged as a response to the increasing necessity of better automations, capable of dealing with the complexity of modern cloud systems. For instance, Infrastructure-as-Code tools provide a declarative way to define, track, and automate changes to the infrastructure underlying a cloud application. Assuring the quality of this part of a code base is of utmost importance. However, learning to produce robust deployment specifications is not an easy feat, and for the domain experts it is time-consuming to conduct code-reviews and transfer the appropriate knowledge to novice members of the team. Given the abundance of data generated throughout the DevOps cycle, machine learning (ML) techniques seem a promising way to tackle this problem. In this work, we propose an approach based on Large Language Models to analyze declarative deployment code and automatically provide QA-related recommendations to developers, such that they can benefit of established best practices and design patterns. We developed a prototype of our proposed ML pipeline, and empirically evaluated our approach on a collection of Kubernetes manifests exported from a repository of internal projects at Nokia Bell Labs.	[Lanciano, Giacomo] Scuola Normale Superi, Pisa, Italy; [Stein, Manuel; Hilt, Volker] Nokia Bell Labs, Stuttgart, Germany; [Cucinotta, Tommaso] Scuola Superi St Anna, Pisa, Italy	Nokia Corporation	Lanciano, G (corresponding author), Scuola Normale Superi, Pisa, Italy.			Lanciano, Giacomo/0000-0002-7431-8041				Alnafessah A, 2021, IEEE ACCESS, V9, P44476, DOI 10.1109/ACCESS.2021.3064867; Atanasova P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3256; Bacciu D, 2020, NEURAL NETWORKS, V129, P203, DOI 10.1016/j.neunet.2020.06.006; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Demirci D, 2022, IEEE ACCESS, V10, P58488, DOI 10.1109/ACCESS.2022.3179384; Dettmers T., 2022, Llm.int8(): 8-bit matrix multiplication for transformers at scale; Gao L., 2020, PILE 800GB DATASET D; Heyman Geert, 2021, Onward! 2021: Proceedings of the 2021 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, P39, DOI 10.1145/3486607.3486749; Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Karfakis P, 2018, Institutions, economic freedom and structural transformation in 11 sub-Saharan African countries, P1, DOI DOI 10.1145/3242163.3242164; Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1; Li RY, 2022, IEEE 19TH INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA 2022), P24, DOI 10.1109/ICSA53651.2022.00011; Ma W., 2022, Is Self-Attention Powerful to Learn Code Syntax and Semantics?; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Mishkin G., 2021, Evaluating Large Lan- guage Models Trained on Code.; Mumtaz H, 2021, J SYST SOFTWARE, V173, DOI 10.1016/j.jss.2020.110885; Neri D, 2020, SICS SOFTWARE, V35, P3, DOI 10.1007/s00450-019-00407-8; Ponce F, 2022, J SYST SOFTWARE, V192, DOI 10.1016/j.jss.2022.111393; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajbhandari S, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476205; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Ren PZ, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3472291; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sharma T, 2021, A Survey on Machine Learning Techniques for Source Code Analysis; Shorten Connor, 2023, Deep Learning Applications. Advances in Intelligent Systems and Computing (1434), P135, DOI 10.1007/978-981-19-6153-3_6; Sontakke Ankita Nandkishor, 2022, DEEP LEARN COD WORKS; Tenney I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P107; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Wan Y, 2022, PROC INT CONF SOFTW, P2377, DOI 10.1145/3510003.3510050; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang J., 2021, Can Pre-trained Language Models be Used to Resolve Textual and Semantic Merge Conflicts?	37	0	0	0	0	SCITEPRESS	SETUBAL	AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL	2184-5042		978-989-758-650-7	CLOSER			2023							289	296		10.5220/0011991200003488	http://dx.doi.org/10.5220/0011991200003488			8	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2MG		Green Published, hybrid, Green Submitted			2024-07-03	WOS:001118989400031
C	Lu, JY; Yu, L; Li, XJ; Yang, L; Zuo, C			IEEE	Lu, Junyi; Yu, Lei; Li, Xiaojia; Yang, Li; Zuo, Chun			LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, ISSRE	Proceedings International Symposium on Software Reliability Engineering		English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART		Code Review Automation; Large Language Models (LLMs); Parameter-Efficient Fine-Tuning (PEFT); Deep Learning; LLaMA; Software Quality Assurance		The automation of code review activities, a long-standing pursuit in software engineering, has been primarily addressed by numerous domain-specific pre-trained models. Despite their success, these models frequently demand extensive resources for pre-training from scratch. In contrast, Large Language Models (LLMs) provide an intriguing alternative, given their remarkable capabilities when supplemented with domain-specific knowledge. However, their potential for automating code review tasks remains largely unexplored. In response to this research gap, we present LLaMA-Reviewer, an innovative framework that leverages the capabilities of LLaMA, a popular LLM, in the realm of code review. Mindful of resource constraints, this framework employs parameter-efficient fine-tuning (PEFT) methods, delivering high performance while using less than 1% of trainable parameters. An extensive evaluation of LLaMA-Reviewer is conducted on two diverse, publicly available datasets. Notably, even with the smallest LLaMA base model consisting of 6.7B parameters and a limited number of tuning epochs, LLaMA-Reviewer equals the performance of existing code-review-focused models. The ablation experiments provide insights into the influence of various fine-tuning process components, including input representation, instruction tuning, and different PEFT methods. To foster continuous progress in this field, the code and all PEFT-weight plugins have been made open-source.	[Lu, Junyi; Yu, Lei; Yang, Li] Chinese Acad Sci, Inst Software, Beijing, Peoples R China; [Lu, Junyi; Yu, Lei] Univ Chinese Acad Sci, Beijing, Peoples R China; [Li, Xiaojia] Tsinghua Univ, Sch Software, Beijing, Peoples R China; [Zuo, Chun] Sinosoft Co Ltd, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Tsinghua University	Yang, L (corresponding author), Chinese Acad Sci, Inst Software, Beijing, Peoples R China.	lujunyi21@mails.ucas.ac.cn; yulei21@mails.ucas.ac.cn; lixj21@mails.tsinghua.edu.cn; yangli2017@iscas.ac.cn; zuochun@sinosoft.com.cn			Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan [202016002000032]; Alliance of International Science Organizations [ANSO-CR-KP-2022-03]	Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan; Alliance of International Science Organizations	This work was supported by Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan (No.202016002000032), and Alliance of International Science Organizations (No. ANSO-CR-KP-2022-03).	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; [Anonymous], 2023, LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning, DOI [10.5281/zenodo.7991113, DOI 10.5281/ZENODO.7991113]; Asthana S, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P937, DOI 10.1145/3338906.3340449; Balachandran V, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P931, DOI 10.1109/ICSE.2013.6606642; Chaudhary S., 2023, Code Alpaca: An Instruction-following LLaMA Model Trained on Code Generation Instructions; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chenghao Fan Z. L., 2023, Chinese-vicuna: A chinese instruction-following llama-based model; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chueshev A, 2020, PROC IEEE INT CONF S, P499, DOI 10.1109/ICSME46990.2020.00054; Cui Yiming, 2023, ARXIV230408177; Fagan M, 2002, Software Pioneers, P575; Fried Daniel, 2022, ARXIV220405999; Fu Michael, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P935, DOI 10.1145/3540250.3549098; Gauthier IX, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P30, DOI 10.1109/ASE51524.2021.9678640; Gupta Anshul, 2018, P 24 ACM SIGKDD INT; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; He Junxian, 2021, ARXIV211004366; Hellendoorn VJ, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1479, DOI 10.1145/3468264.3473134; Hijazi H., 2022, IEEE Trans. Softw. Eng., P1; Hijazi H, 2021, PROC INT SYMP SOFTW, P476, DOI 10.1109/ISSRE52982.2021.00056; Hong Yang, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P507, DOI 10.1145/3540250.3549119; Hong Y, 2022, EUR CON SFTWR MTNCE, P1034, DOI 10.1109/SANER53432.2022.00121; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Kong DZ, 2022, EUR CON SFTWR MTNCE, P630, DOI 10.1109/SANER53432.2022.00080; Lester B., 2021, arXiv; Li Lingwei, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1009, DOI 10.1145/3540250.3549099; Li Raymond, 2023, ARXIV230506161; Li Xiang Lisa, 2021, arXiv; Li Zhiyu, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1035, DOI 10.1145/3540250.3549081; Liu Xiao, 2021, ARXIV210310385; Lv ZX, 2023, SMALL STRUCT, V4, DOI 10.1002/sstr.202300158; Mirsaeedi E, 2020, PROC INT CONF SOFTW, P1183, DOI 10.1145/3377811.3380335; Nijkamp Erik, 2022, ARXIV220313474; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pandya Prahar, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P546, DOI 10.1145/3540250.3549115; Peng Baolin, 2023, ARXIV230403277; Pornprasit C., D-act: Towards diff-aware code transformation for code review under a time-wise evaluation; Rebai S, 2020, AUTOMAT SOFTW ENG, V27, P301, DOI 10.1007/s10515-020-00275-6; Rigby PC, 2014, ACM T SOFTW ENG METH, V23, DOI 10.1145/2594458; Rong G., 2022, arXiv; Sadowski C, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING - SOFTWARE ENGINEERING IN PRACTICE TRACK (ICSE-SEIP 2018), P181, DOI 10.1145/3183519.3183525; Shan QH, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P472, DOI 10.1145/3540250.3549104; Shi ST, 2019, AAAI CONF ARTIF INTE, P4910; Siow JK, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20), P284, DOI [10.1109/saner48275.2020.9054794, 10.1109/SANER48275.2020.9054794]; Spadini D, 2020, PROC INT CONF SOFTW, P1171, DOI 10.1145/3377811.3380385; Sülün E, 2021, INFORM SOFTWARE TECH, V130, DOI 10.1016/j.infsof.2020.106455; Sülün E, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P1250, DOI 10.1145/3338906.3342507; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thongtanunam P, 2022, PROC INT CONF SOFTW, P237, DOI 10.1145/3510003.3510067; Touvron Hugo, 2023, ARXIV230213971; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Tufano M, 2019, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2019.00021; Tufano R., 2022, arXiv; Tufano R, 2021, PROC INT CONF SOFTW, P163, DOI 10.1109/ICSE43902.2021.00027; Vaswani A, 2017, ADV NEUR IN, V30; Wang D, 2021, J SYST SOFTWARE, V180, DOI 10.1016/j.jss.2021.111009; Wang E. J., Tloen/alpaca-lora: Instruct-tune llama on consumer hardware; Wang Y., 2021, arXiv preprint arXiv:2109.00859; Wang Y., 2023, arXiv; Wei Jason, 2022, arXiv:2206.07682; Wei Jason, 2021, arXiv preprint arXiv:2109.01652; YizhongWang Yeganeh Kordi, 2022, arXiv; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zhang Renrui, 2023, arXiv:2303.16199; Zhao Wayne Xin, 2023, arXiv; Zhu Deyao, 2023, ARXIV230410592	68	3	3	12	12	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1071-9458		979-8-3503-1594-3	PROC INT SYMP SOFTW			2023							647	658		10.1109/ISSRE59848.2023.00026	http://dx.doi.org/10.1109/ISSRE59848.2023.00026			12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KU		Green Submitted			2024-07-03	WOS:001096886300057
C	Lee, H; Kim, JH; Hwang, EJ; Kim, J; Park, JC			IEEE	Lee, Huije; Kim, Jung-Ho; Hwang, Eui Jun; Kim, Jaewoo; Park, Jong C.			LEVERAGING LARGE LANGUAGE MODELS WITH VOCABULARY SHARING FOR SIGN LANGUAGE TRANSLATION	2023 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING WORKSHOPS, ICASSPW			English	Proceedings Paper	IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)	JUN 04-10, 2023	GREECE	IEEE, IEEE Signal Proc Soc		machine translation; sign language translation; large language model; vocabulary sharing		Sign language translation (SLT) is a task that provides translation between spoken and sign languages used in the same country, which tend to show high lexical similarity but low syntactic similarity. The recent emergence of large language models (LLMs) has been remarkable for all downstream tasks in natural language processing, but they have yet to be applied to SLT. In this paper, we explore how to use an LLM with vocabulary sharing for two gloss-based SLT tasks (text-to-gloss (T2G) and gloss-to-text (G2T)) on the NIASL2021 dataset, which consists of 180,848 preprocessed Korean and Korean Sign Language (KSL) sentence pairs. The experimental results showed that Ko-GPT-Trinity-1.2B+VS, a GPT-3-based SLT model with vocabulary sharing, outperformed other SLT models, achieving BLEU-4 scores of 22.06 and 45.89 on T2G and G2T tasks, respectively. We expect that the adoption of an LLM with vocabulary sharing will significantly lessen the resource scarcity problem of SLT.	[Lee, Huije; Kim, Jung-Ho; Hwang, Eui Jun; Kim, Jaewoo; Park, Jong C.] Korea Adv Inst Sci & Technol, NLP CL Lab, Sch Comp, Daejeon, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Park, JC (corresponding author), Korea Adv Inst Sci & Technol, NLP CL Lab, Sch Comp, Daejeon, South Korea.	park@nlp.kaist.ac.kr			Institute for Information and communications Technology Promotion (IITP) - Korea government (MSIT) [2022-0-00010]; Ministry of Trade, Industry & Energy (MOTIE, Korea) [20014406]	Institute for Information and communications Technology Promotion (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Ministry of Trade, Industry & Energy (MOTIE, Korea)(Ministry of Trade, Industry & Energy (MOTIE), Republic of Korea)	This work was supported in part by the Institute for Information and communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00010, Development of Korean sign language translation service technology for the deaf in medical environment) and in part by the Technology Innovation Program (20014406, Development of interactive sign language interpretation service based on artificial intelligence for the hearing impaired) funded by the Ministry of Trade, Industry & Energy (MOTIE, Korea).	Bowden Richard, 2022, P 7 INT WORKSH SIGN, P117; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camgoz Necati Cihan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10020, DOI 10.1109/CVPR42600.2020.01004; Camgoz NC, 2018, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2018.00812; DE COSTER M., 2021, P 1 INT WORKSHOP AUT, P88; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Huerta-Enochian M., 2022, Proceedings of the 7th International Workshop on Sign Language Translation and Avatar Technology: The Junction of the Visual and the Textual: Challenges and Perspectives, P59; Hwang E., 2021, P 32 BRIT MACHINE VI; Jang JY, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6808; Jiang Z., 2023, FINDINGS 17 C EUROPE; Kim JH, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1519; Kim San, 2021, FINDINGS 2022 C EMPI, P352; Miyazaki T., 2020, WORKSH REPR PROC SIG, P139; Moryossef A., 2021, P 1 INT WORKSH AUT T, P1; Park S., 2021, P 35 C NEURAL INFORM; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Saunders Ben, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P687, DOI 10.1007/978-3-030-58621-8_40; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; SKT-AI, 2020, KOBART; SKT-AI, 2020, KOGPT2; SKT-AI, 2021, KO GPT TRINITY 1 2B; Stoll S., 2018, P 29 BRIT MACHINE VI; Vaswani A, 2017, ADV NEUR IN, V30; Vilar D, 2022, Arxiv, DOI arXiv:2211.09102; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Zhang B., 2023, 11 INT C LEARNING RE	26	0	0	7	23	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0261-5				2023										10.1109/ICASSPW59220.2023.10193533	http://dx.doi.org/10.1109/ICASSPW59220.2023.10193533			5	Acoustics; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Computer Science; Engineering; Imaging Science & Photographic Technology	BV5DK					2024-07-03	WOS:001046933700148
J	Nay, JJ; Karamardian, D; Lawsky, SB; Tao, WT; Bhat, M; Jain, R; Lee, AT; Choi, JH; Kasai, J				Nay, John J.; Karamardian, David; Lawsky, Sarah B.; Tao, Wenting; Bhat, Meghana; Jain, Raghav; Lee, Aaron Travis; Choi, Jonathan H.; Kasai, Jungo			Large language models as tax attorneys: a case study in legal capabilities emergence	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Article						artificial intelligence; large language models; machine learning; computational law; law-informed AI; law informs code		Better understanding of Large Language Models' (LLMs) legal analysis abilities can contribute to improving the efficiency of legal services, governing artificial intelligence and leveraging LLMs to identify inconsistencies in law. This paper explores LLM capabilities in applying tax law. We choose this area of law because it has a structure that allows us to set up automated validation pipelines across thousands of examples, requires logical reasoning and maths skills, and enables us to test LLM capabilities in a manner relevant to real-world economic lives of citizens and companies. Our experiments demonstrate emerging legal understanding capabilities, with improved performance in each subsequent OpenAI model release. We experiment with retrieving and using the relevant legal authority to assess the impact of providing additional legal context to LLMs. Few-shot prompting, presenting examples of question-answer pairs, is also found to significantly enhance the performance of the most advanced model, GPT-4. The findings indicate that LLMs, particularly when combined with prompting enhancements and the correct legal texts, can perform at high levels of accuracy but not yet at expert tax lawyer levels. As LLMs continue to advance, their ability to reason about law autonomously could have significant implications for the legal profession and AI governance.This article is part of the theme issue 'A complexity science approach to law and governance'.	[Nay, John J.] Stanford Univ, Ctr Legal Informat, CodeX, Stanford, CA 94305 USA; [Karamardian, David; Tao, Wenting] Stanford Univ, Stanford, CA USA; [Lawsky, Sarah B.] Northwestern Pritzker Sch Law, Chicago, IL USA; [Bhat, Meghana] Univ Michigan, Engn, Ann Arbor, MI USA; [Jain, Raghav] SimPPL, Faridabad, India; [Lee, Aaron Travis; Choi, Jonathan H.] Univ Southern Calif, Sch Law, Los Angeles, CA USA; [Kasai, Jungo] Univ Washington, Dept Comp Sci, Seattle, WA USA	Stanford University; Stanford University; Northwestern University; University of Michigan System; University of Michigan; University of Southern California; University of Washington; University of Washington Seattle	Nay, JJ (corresponding author), Stanford Univ, Ctr Legal Informat, CodeX, Stanford, CA 94305 USA.	john.j.nay@gmail.com			Mercatus Center at George Mason University	Mercatus Center at George Mason University	The Mercatus Center at George Mason University funded Meghana Bhat's work related to this research, and some of the computing costs for running the experiments.	Andreas Jacob, 2022, arXiv, DOI 10.48550/arXiv.2212.01681; Bakhtin A, 2022, SCIENCE, V378, P1067, DOI 10.1126/science.ade9097; Benaich N., 2022, State of AI Report 2022; Carta T, 2023, Arxiv, DOI arXiv:2302.02662; Chang KK, 2023, Arxiv, DOI arXiv:2305.00118; Chen AELC, 2023, Arxiv, DOI arXiv:2302.14838; Chen D., 2020, P 58 ANN M ASS COMPU, V2020, P34; Diao SZ, 2024, Arxiv, DOI arXiv:2302.12246; Goswami K., 2023, arXiv; Hafner D, 2024, Arxiv, DOI [arXiv:2301.04104, 10.48550/arXiv.2301.04104]; Halawi D., 2023, Overthinking the truth: understanding how language models process false demonstrations; Institute for Human-Centered AI, 2023, STANFORD UNIV; Ishibashi Y., 2023, arXiv; Jean R., 2023, Wyoming lawmakers turn to experts to stay ahead of AI curve, even as ChatGPT4 Passes Bar Exam'; Jin Z., 2022, Adv. Neural Inform. Processing Systems, V35, P28458; Khattab O, 2023, Arxiv, DOI [arXiv:2212.14024, DOI 10.48550/ARXIV.2212.14024]; Kim G, 2023, Arxiv, DOI arXiv:2303.17491; Lawsky S., 2023, Lawsky practice problems; Li AC, 2023, Arxiv, DOI arXiv:2302.14051; Li Belinda Z., 2023, arXiv; Liu A, 2023, Arxiv, DOI arXiv:2304.14399; Liu Y, 2023, Arxiv, DOI arXiv:2303.16634; Lu AL, 2023, Arxiv, DOI arXiv:2302.09185; Magar I., 2022, arXiv; Mialon G., 2023, arXiv; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Nay J. J., 2023, NW J TECH INTELL PRO, V20, P309; Nay JJ., 2023, SSRN30 Jan; Nay JJ., 2024, Figshare, DOI [10.6084/m9.figshare.c.7031271, DOI 10.6084/M9.FIGSHARE.C.7031271]; Nay JJJ, 2023, Arxiv, DOI arXiv:2301.01181; Ni Jianmo, 2022, P 2022 C EMPIRICAL M, P9844; OpenAI, 2019, 2019 Better Language Models and Their Implications; OpenAI, 2023, 2023 GPT-4; Ornes S., 2023, Quanta Magazine; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Press O, 2023, Arxiv, DOI arXiv:2210.03350; Ram O, 2023, Arxiv, DOI arXiv:2302.00083; Reppert J, 2023, Arxiv, DOI arXiv:2301.01751; Schick T., 2023, arXiv; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Sil A, 2023, Arxiv, DOI arXiv:2301.09715; Sun ZQ, 2023, Arxiv, DOI arXiv:2210.01296; The New AI-Powered Bing is Threatening Users, 2023, TIME. 17 February; Valmeekam Karthik, 2023, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang ZH, 2023, Arxiv, DOI [arXiv:2302.01560, 10.48550/arXiv.2302.01560]; Webb T, 2023, Arxiv, DOI [arXiv:2212.09196, 10.48550/arXiv.2212.09196]; Wei J., 2023, Jason Wei Blog; Wei J., 2022, JASONWEI.NET14 November; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; World Economic Forum, 2022, WORLDECON. FORUM6 January; Wu Y, 2023, Arxiv, DOI arXiv:2302.04449; Yang S, 2023, Arxiv, DOI arXiv:2303.04129; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Ye JC, 2023, Arxiv, DOI arXiv:2302.05698; Ye S, 2023, Arxiv, DOI arXiv:2302.14691; Zhang D, 2022, The AI Index 2022 Annual Report; Zhong RQ, 2023, Arxiv, DOI arXiv:2302.14233; Zhou SY, 2023, Arxiv, DOI arXiv:2207.05987; Zhou YH, 2023, Arxiv, DOI arXiv:2302.09236	60	1	1	19	19	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-503X	1471-2962		PHILOS T R SOC A	Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.	APR 15	2024	382	2270							20230159	10.1098/rsta.2023.0159	http://dx.doi.org/10.1098/rsta.2023.0159			15	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	JV6Z5	38403061	hybrid, Green Published, Green Submitted			2024-07-03	WOS:001175989800007
C	Deng, X; Bashlovkina, V; Han, F; Baumgartner, S; Bendersky, M			ACM	Deng, Xiang; Bashlovkina, Vasilisa; Han, Feng; Baumgartner, Simon; Bendersky, Michael			LLMs to the Moon? Reddit Market Sentiment Analysis with Large Language Models	COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023			English	Proceedings Paper	32nd World Wide Web Conference (WWW)	APR 30-MAY 04, 2023	Austin, TX	Assoc Comp Machinery, Amazon Science, Baidu, Megagon Labs, Zhipu AI, Google, Booking Com, eBay, Bloomberg Engn, Netflix, ACM SIGWEB, Univ Texas Austin, Sch Informat, Data World, Inst Fdn Machine Learning		Sentiment Analysis; Social Media; Finance; Large Language Model; Natural Language Processing	TEXTUAL ANALYSIS	Market sentiment analysis on social media content requires knowledge of both financial markets and social media jargon, which makes it a challenging task for human raters. The resulting lack of high-quality labeled data stands in the way of conventional supervised learning methods. In this work, we conduct a case study approaching this problem with semi-supervised learning using a large language model (LLM). We select Reddit as the target social media platform due to its broad coverage of topics and content types. Our pipeline first generates weak financial sentiment labels for Reddit posts with an LLM and then uses that data to train a small model that can be served in production. We find that prompting the LLM to produce Chain-of-Thought summaries and forcing it through several reasoning paths helps generate more stable and accurate labels, while training the student model using a regression loss further improves distillation quality. With only a handful of prompts, the final model performs on par with existing supervised models. Though production applications of our model are limited by ethical considerations, the model's competitive performance points to the great potential of using LLMs for tasks that otherwise require skill-intensive annotation.	[Deng, Xiang] Ohio State Univ, Columbus, OH 43210 USA; [Bashlovkina, Vasilisa; Han, Feng; Baumgartner, Simon] Google Res, NYC, New York, NY USA; [Bendersky, Michael] Google Res, Mountain View, CA USA; [Deng, Xiang] Google, Mountain View, CA 94043 USA	University System of Ohio; Ohio State University; Google Incorporated; Google Incorporated; Google Incorporated	Deng, X (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.	deng.595@buckeyemail.osu.edu; vasilisa@google.com; bladehan@google.com; simonba@google.com; bemike@google.com	Han, Feng/D-1023-2019	Han, Feng/0000-0003-0707-8575				ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Bradley Daniel, 2021, MENDELU Working Papers in Business and Economics 2021-76; Brown Tom B., 2020, Advances in Neural Information Processing Systems; Chen CC, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6106; Chen H. H., 2018, P 1 FIN NARR PROC WO, P37; Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Ficler Jessica, 2017, P WORKSHOP STYLISTIC, P94; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Kadous Kathryn, 2017, WorkingPaper, DOI [10.2139/ssrn.2968407, DOI 10.2139/SSRN.2968407]; Li YF, 2023, Arxiv, DOI arXiv:2206.02336; Liu Z, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4513; Loughran T, 2016, J ACCOUNT RES, V54, P1187, DOI 10.1111/1475-679X.12123; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Maia M, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1941, DOI 10.1145/3184558.3192301; Min Sewon, 2022, P 2022 C EMP METH NA; Oktay Ozan, 2018, PREPRINT, DOI [DOI 10.48550/ARXIV, 10.48550/arxiv]; Qin Zhen, 2022, 10 INT C LEARN REPR; Raffel C, 2020, J MACH LEARN RES, V21; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xie Sang Michael, 2022, 10 INT C LEARN REPR; Yang Y, 2020, Arxiv, DOI arXiv:2006.08097; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	24	1	1	22	25	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9416-1				2023							1014	1019		10.1145/3543873.3587605	http://dx.doi.org/10.1145/3543873.3587605			6	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SF					2024-07-03	WOS:001124276300196
J	Pendyala, VS; Hall, CE				Pendyala, Vishnu S.; Hall, Christopher E.			Explaining Misinformation Detection Using Large Language Models	ELECTRONICS			English	Article						large language models (LLMs); natural language processing; misinformation containment; eXplainable Artificial Intelligence (XAI); Captum model interpretability; LLM quantization; greedy decoding; zero-shot prompting; Matthew's correlation coefficient (MCC); Cohen's Kappa score		Large language models (LLMs) are a compressed repository of a vast corpus of valuable information on which they are trained. Therefore, this work hypothesizes that LLMs such as Llama, Orca, Falcon, and Mistral can be used for misinformation detection by making them cross-check new information with the repository on which they are trained. Accordingly, this paper describes the findings from the investigation of the abilities of LLMs in detecting misinformation on multiple datasets. The results are interpreted using explainable AI techniques such as Local Interpretable Model-Agnostic Explanations (LIME), SHapley Additive exPlanations (SHAP), and Integrated Gradients. The LLMs themselves are also asked to explain their classification. These complementary approaches aid in better understanding the inner workings of misinformation detection using LLMs and lead to conclusions about their effectiveness at the task. The methodology is generic and nothing specific is assumed for any of the LLMs, so the conclusions apply generally. Primarily, when it comes to misinformation detection, the experiments show that the LLMs are limited by the data on which they are trained.	[Pendyala, Vishnu S.] San Jose State Univ, Dept Appl Data Sci, San Jose, CA 95192 USA; [Hall, Christopher E.] San Jose State Univ, Dept Comp Sci, San Jose, CA 95192 USA	California State University System; San Jose State University; California State University System; San Jose State University	Pendyala, VS (corresponding author), San Jose State Univ, Dept Appl Data Sci, San Jose, CA 95192 USA.	vishnu.pendyala@sjsu.edu; christopher.e.hall@sjsu.edu	Pendyala, Vishnu S/AAB-7641-2022	Pendyala, Vishnu S/0000-0001-6494-7832	San Jose State University	San Jose State University	No Statement Available	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Beeching E., 2023, Open llm leaderboard; Bills S., 2023, Language models can explain neurons in language models; Caramancion Kevin Matthe, 2023, 2023 IEEE World AI IoT Congress (AIIoT), P0042, DOI 10.1109/AIIoT58121.2023.10174450; Chicco D, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00322-4; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Das SD, 2021, Arxiv, DOI arXiv:2101.03545; Falcon LLM Team, 2023, Arxiv, DOI [arXiv:2311.16867, DOI 10.48550/ARXIV.2311.16867]; Hu BZ, 2024, Arxiv, DOI [arXiv:2309.12247, 10.1609/aaai.v38i20.30214, DOI 10.48550/ARXIV.2309.12247]; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Kokhlikyan N, 2020, Arxiv, DOI [arXiv:2009.07896, DOI 10.48550/ARXIV.2009.07896]; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Lundberg SM, 2017, ADV NEUR IN, V30; Merrick L, 2019, Arxiv, DOI arXiv:1910.00174; Mesnard T., 2024, Gemma; Mukherjee S, 2023, Arxiv, DOI arXiv:2306.02707; Nan Q, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3343, DOI 10.1145/3459637.3482139; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Patwa P., 2021, Communications in Computer and Information Science, V1402, P21, DOI DOI 10.1007/978-3-030-73696-5_3; Pendyala V.S., 2023, Deep Learning Research Applications for Natural Language Processing, P41; Pendyala V, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13061025; Pendyala VS, 2023, 2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI, P210, DOI 10.1109/CAI54212.2023.00099; Shu K, 2019, Arxiv, DOI arXiv:1809.01286; Sundararajan M, 2017, Arxiv, DOI [arXiv:1703.01365, 10.48550/ARXIV.1703.01365, DOI 10.48550/ARXIV.1703.01365]; Tonmoy STI, 2024, Arxiv, DOI arXiv:2401.01313; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Ribeiro MT, 2016, Arxiv, DOI arXiv:1602.04938; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237	31	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	MAY	2024	13	9							1673	10.3390/electronics13091673	http://dx.doi.org/10.3390/electronics13091673			30	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	QG9U5		gold			2024-07-03	WOS:001219851900001
J	Sanderson, K				Sanderson, Katharine			AI science search engines are exploding in number - are they any good?	NATURE			English	News Item						Research data; Machine learning		Tools powered by large language models are intended to help researchers digest or do science.											0	4	4	4	8	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	APR 27	2023	616	7958					639	640		10.1038/d41586-023-01273-w	http://dx.doi.org/10.1038/d41586-023-01273-w			2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	G7IR6	37069302				2024-07-03	WOS:000990856600015
J	Malik, U; Bernard, S; Pauchet, A; Chatelain, C; Picot-Clémente, R; Cortinovis, J				Malik, Usman; Bernard, Simon; Pauchet, Alexandre; Chatelain, Clement; Picot-Clemente, Romain; Cortinovis, Jerome			Pseudo-Labeling With Large Language Models for Multi-Label Emotion Classification of French Tweets	IEEE ACCESS			English	Article						Multi-label emotion classification; semi-supervised learning; pseudo-labeling; Chat-GPT		This study proposes a novel semi-supervised multi-label emotion classification approach for French tweets based on pseudo-labeling. Human subjectivity in emotional expression makes it difficult for a machine to learn. Therefore, it necessitates training supervised learning models on large datasets annotated by multiple annotators. However, creating such datasets can be costly and time-consuming. Moreover, aggregating annotations from multiple annotators to capture their collective emotional state adds complexity to the task. Semi-supervised learning techniques have shown effectiveness with limited datasets. Furthermore, Large language Models (LLMs), particularly Chat-GPT, have demonstrated superior annotation accuracy compared to annotations obtained from crowdsourcing platforms, when both are evaluated against expert-annotated data. This work introduces a novel approach for multi-label emotion classification of French tweets by leveraging pseudo-labels generated through Chat-GPT, a robust large language model. Using zero-shot, one-shot, and few-shot learning techniques, Chat-GPT annotates the unlabelled part of our dataset. These Chat-GPT-annotated pseudo-labels are then merged with manual annotations, facilitating the training of a multi-label emotion classification model via semi-supervised learning. Furthermore, within the context of our research, we present a new French tweet dataset, containing testimonials from people affected by an urban industrial incident. This dataset features 2,350 tweets, each manually annotated by three human annotators based on 8 pre-identified emotions. Benchmark results are presented for multi-label emotion classification models employing both fully supervised and semi-supervised approaches with pseudo-labeling. Our findings demonstrate the superiority of our approach for multi-label emotion classification over standard pseudo-labeling and an established baseline.	[Malik, Usman; Bernard, Simon] Univ Rouen Normandie, LITIS UR 4108, F-76000 Rouen, France; [Pauchet, Alexandre; Chatelain, Clement] INSA Rouen Normandie, LITIS UR 4108, F-76000 Rouen, France; [Picot-Clemente, Romain] Saagie, F-76140 Rouen, France; [Cortinovis, Jerome] Atmo Normandie, Rouen, France	Universite de Rouen Normandie; Universite de Rouen Normandie	Bernard, S (corresponding author), Univ Rouen Normandie, LITIS UR 4108, F-76000 Rouen, France.	simon.bernard@univ-rouen.fr	chatelain, clement/AAC-7383-2022	chatelain, clement/0000-0001-8377-0630	CATCH research project, recipient of the RA-SIOMRI 2021 funding program	CATCH research project, recipient of the RA-SIOMRI 2021 funding program	No Statement Available	Alzubaidi L, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00727-2; Ameer I, 2023, IEEE ACCESS, V11, P56921, DOI 10.1109/ACCESS.2023.3281544; Ameer I, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118534; Ameer I, 2020, COMPUT SIST, V24, P1159, DOI [10.13053/CyS-24-3-3476, 10.13053/cys-24-3-3476]; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; [Anonymous], 2019, New York Times; [Anonymous], 2019, Reuters Over 5,250 tonnes of chemicals burned in Rouen, France industrial?re; [Anonymous], 2019, The Local France French chemical factory explosion: What we know sofar; [Anonymous], 2019, France 24 French authorities probe Lubrizol factory ?re in Normandy; Arazo E, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207304; Bailey ER, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18539-w; Berthelot D, 2019, ADV NEUR IN, V32; Bose S., 2019, P IEEE 16 IND COUNC, P1; Cascante-Bonilla P, 2021, AAAI CONF ARTIF INTE, V35, P6912; Chandra R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255615; Cheng YS, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105924; Chong YW, 2020, NEUROCOMPUTING, V408, P216, DOI 10.1016/j.neucom.2019.12.130; Dopierre T, 2020, P 28 INT C COMP LING, P4993, DOI 10.18653/v1/2020.coling-main.438; Duarte JM, 2023, ARTIF INTELL REV, V56, P9401, DOI 10.1007/s10462-023-10393-8; Fan Y, 2023, INT J COMPUT VISION, V131, P626, DOI 10.1007/s11263-022-01723-4; Fleiss J.L., 2013, Statistical Methods for Rates and Proportions, DOI DOI 10.1002/0471445428; Gao Yunze, 2017, PREPRINT; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Grandvalet Y., 2005, ADV NEURAL INFORM PR, P529; Gupta R, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5109, DOI 10.1109/ICASSP.2018.8461414; Hayat H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145245; Hwang H., 2021, P C REC ADV NAT LANG, P593; Jabreel M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9061123; Jiang MY, 2018, NEURAL COMPUT APPL, V29, P61, DOI 10.1007/s00521-016-2401-x; Jimenez D, 2022, COMPUT SIST, V26, P183, DOI [10.13053/cys-26-1-4163, 10.13053/CyS-26-1-4163]; Ju W, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P421, DOI 10.1145/3488560.3498429; Kabir M, 2021, Online SocialNetworks And Media; Kang LY, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102717; Kim E, 2022, Arxiv, DOI arXiv:1808.03137; Kingma DP, 2014, ADV NEUR IN, V27; Kokab Tabinda, 2022, Array, V14; Krippendorff K., 2011, Computing; Krippendorff Klaus., 2004, Content analysis: An introduction to its methodology; Krishnamoorthy A, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P86, DOI 10.1109/ICACCI.2018.8554593; Kutlu M, 2020, J ARTIF INTELL RES, V69, P143; Le H, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2479; Le HD, 2023, IEEE ACCESS, V11, P14742, DOI 10.1109/ACCESS.2023.3244390; Lee D.-H., 2013, WORKSH CHALL REPR LE, P896; Lee J., 2019, arXiv, DOI DOI 10.48550/ARXIV.1911.03090; Li AH, 2020, INT CONF ACOUST SPEE, P6164, DOI [10.1109/ICASSP40776.2020.9053565, 10.1109/icassp40776.2020.9053565]; Li CC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5044; Lin NK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103097; Lindquist KA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00444; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lakew SM, 2018, Arxiv, DOI arXiv:1806.06957; Martin L., 2020, P 58 ANN M ASS COMPU, P7203, DOI [DOI 10.18653/V1/2020.ACL-MAIN.645, 10.18653/v1/2020.acl-main.645,Online]; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mekala D, 2022, Arxiv, DOI arXiv:2205.12528; Mekki J., 2021, RANLP 2021 RECENT AD; Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6; Ng LHX, 2021, COMPUT MATH ORGAN TH, V27, P179, DOI 10.1007/s10588-021-09329-w; Nguyen S., 2020, P INT C PATT REC WOR, P1; Oliver A., 2018, P INT C LEARN REPR, P1; Ouali Y, 2020, Arxiv, DOI arXiv:2006.05278; Pan YH, 2020, 2020 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2020), P231, DOI 10.1109/CW49994.2020.00044; Park S, 2019, NEURAL NETWORKS, V119, P139, DOI 10.1016/j.neunet.2019.08.001; PLUTCHIK R, 1982, SOC SCI INFORM, V21, P529, DOI 10.1177/053901882021004003; Sauvayre R, 2022, JMIR MED INF, V10, DOI 10.2196/37831; Shehnepoor S, 2022, IEEE T INF FOREN SEC, V17, P280, DOI 10.1109/TIFS.2021.3139771; Souza de, 2021, P BRAZ C INT SYST, P3; Soyalp Gokhan, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P707, DOI 10.1109/UBMK52708.2021.9558906; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; van Engelen JE, 2020, MACH LEARN, V109, P373, DOI 10.1007/s10994-019-05855-6; Vilhagra LA, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1135, DOI 10.1145/3341105.3374018; Vlasenko B, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1546; Westling A., 2014, Secur. Informat., V2014, P3; Widmann N, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P59, DOI 10.1145/3121050.3121055; Winata GI, 2015, 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATICS 2015, P500, DOI 10.1109/ICEEI.2015.7352552; Wu Huimin, 2023, IEEE Trans Med Imaging, V42, P3244, DOI 10.1109/TMI.2023.3279110; Yang CE, 2022, IEEE T NEUR NET LEAR, V33, P3857, DOI 10.1109/TNNLS.2021.3054665; Yang LD, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13084716; Ye Qiu, 2020, Natural Language Processing and Chinese Computing. 9th CCF International Conference, NLPCC 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12430), P506, DOI 10.1007/978-3-030-60450-9_40; Zhang JY, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233990; Zhang X, 2015, ADV NEUR IN, V28; Zhao HY, 2022, IEEE ACCESS, V10, P11947, DOI 10.1109/ACCESS.2022.3146303; Zhu DH, 2021, J COMPUT SCI TECH-CH, V36, P1420, DOI 10.1007/s11390-020-0142-x; Zou Z., 2023, J. BigData, V10, P1	82	0	0	19	19	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						15902	15916		10.1109/ACCESS.2024.3354705	http://dx.doi.org/10.1109/ACCESS.2024.3354705			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	HE6Z6		gold			2024-07-03	WOS:001157869700001
J	Jeon, J; Lee, SY				Jeon, Jaeho; Lee, Seongyong			Large language models in education: A focus on the complementary relationship between human teachers and ChatGPT	EDUCATION AND INFORMATION TECHNOLOGIES			English	Article						ChatGPT; Large language model; Chatbot; AIEd; Human-computer interaction; Artificial intelligence; Large language model-powered chatbot	COMMUNICATION	Artificial Intelligence (AI) is developing in a manner that blurs the boundaries between specific areas of application and expands its capability to be used in a wide range of applications. The public release of ChatGPT, a generative AI chatbot powered by a large language model (LLM), represents a significant step forward in this direction. Accordingly, professionals predict that this technology will affect education, including the role of teachers. However, despite some assumptions regarding its influence on education, how teachers may actually use the technology and the nature of its relationship with teachers remain under-investigated. Thus, in this study, the relationship between ChatGPT and teachers was explored with a particular focus on identifying the complementary roles of each in education. Eleven language teachers were asked to use ChatGPT for their instruction during a period of two weeks. They then participated in individual interviews regarding their experiences and provided interaction logs produced during their use of the technology. Through qualitative analysis of the data, four ChatGPT roles (interlocutor, content provider, teaching assistant, and evaluator) and three teacher roles (orchestrating different resources with quality pedagogical decisions, making students active investigators, and raising AI ethical awareness) were identified. Based on the findings, an in-depth discussion of teacher-AI collaboration is presented, highlighting the importance of teachers' pedagogical expertise when using AI tools. Implications regarding the future use of LLM-powered chatbots in education are also provided.	[Jeon, Jaeho] Indiana Univ, Dept Literacy Culture & Language Educ, 107 S Indiana Ave, Bloomington, IN 47405 USA; [Lee, Seongyong] Hannam Univ, Dept English Educ, 70 Hannam Ro, Daejeon 34430, South Korea	Indiana University System; Indiana University Bloomington; Hannam University	Lee, SY (corresponding author), Hannam Univ, Dept English Educ, 70 Hannam Ro, Daejeon 34430, South Korea.	seongyonglee77@gmail.com	Lee, Seongyong/H-7230-2013	Lee, Seongyong/0000-0002-9436-4272				Altman S., 2022, Twitter; Bibauw S, 2022, LANG LEARN TECHNOL, V26; Bibauw S, 2019, COMPUT ASSIST LANG L, V32, P827, DOI 10.1080/09588221.2018.1535508; Bower M, 2019, BRIT J EDUC TECHNOL, V50, P1035, DOI 10.1111/bjet.12771; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Celik I, 2023, COMPUT HUM BEHAV, V138, DOI 10.1016/j.chb.2022.107468; Celik I, 2022, TECHTRENDS, V66, P616, DOI 10.1007/s11528-022-00715-y; Choi S, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2194927; Choi S, 2023, INT J HUM-COMPUT INT, V39, P910, DOI 10.1080/10447318.2022.2049145; Creswell J. W, 2005, Educational research: Planning, conducting and evaluating quantitative and qualitative research, upper Saddle River; Dillenbourg P, 2010, NEW SCIENCE OF LEARNING: COGNITION, COMPUTERS AND COLLABORATION IN EDUCATION, P525, DOI 10.1007/978-1-4419-5716-0_26; Dizon G, 2020, LANG LEARN TECHNOL, V24, P16; Fryer LK, 2020, LANG LEARN TECHNOL, V24, P8; Fryer LK, 2019, COMPUT HUM BEHAV, V93, P279, DOI 10.1016/j.chb.2018.12.023; Heidt Amanda., 2023, NATURE; Hew KF, 2023, J COMPUT HIGH EDUC, V35, P40, DOI 10.1007/s12528-022-09338-x; Holstein K., 2019, LECT NOTES ARTIF INT, V11625, DOI [10.1007/978-3-030, DOI 10.1007/978-3-030]; Holstein K, 2022, AI MAG, V43, P239, DOI 10.1002/aaai.12058; Holstein K, 2019, J LEARN ANAL, V6, P27, DOI 10.18608/jla.2019.62.3; Huang WJ, 2022, J COMPUT ASSIST LEAR, V38, P237, DOI 10.1111/jcal.12610; Huang XY, 2023, EDUC TECHNOL SOC, V26, P112, DOI 10.30191/ETS.202301_26(1).0009; Hwang G.-J., 2020, Comput. Educ. Artif. Intell., V1, DOI [DOI 10.1016/J.CAEAI.2020.100001, 10.1016/j.caeai.2020.100001]; Jeon J, 2022, COMPUT EDUC, V190, DOI 10.1016/j.compedu.2022.104620; Jeon J, 2022, EDUC INF TECHNOL, V27, P5767, DOI 10.1007/s10639-021-10839-y; Jeon J, 2024, COMPUT ASSIST LANG L, V37, P1, DOI 10.1080/09588221.2021.2021241; Jeon J, 2023, COMPUT ASSIST LANG L, V36, P1338, DOI 10.1080/09588221.2021.1987272; Ji H, 2023, J RES TECHNOL EDUC, V55, P48, DOI 10.1080/15391523.2022.2142873; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim J, 2022, EDUC INF TECHNOL, V27, P6069, DOI 10.1007/s10639-021-10831-6; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Lee S, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2067182; Lombard M, 2002, HUM COMMUN RES, V28, P587, DOI 10.1111/j.1468-2958.2002.tb00826.x; Luckin R., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100076; OpenAI, 2023, CHATGPT; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Susnjak T., 2022, ArXiv, P1, DOI DOI 10.48550/ARXIV.2212.09292; Timpe-Laughlin V, 2022, COMPUT ASSIST LANG L, V35, P1194, DOI 10.1080/09588221.2020.1774904; Wang XH, 2023, COMPUT EDUC, V194, DOI 10.1016/j.compedu.2022.104703; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Xu WQ, 2022, EDUC INF TECHNOL, V27, P4195, DOI 10.1007/s10639-021-10774-y; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhang Z, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517479	44	55	55	496	982	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1360-2357	1573-7608		EDUC INF TECHNOL	Educ. Inf. Technol.	DEC	2023	28	12					15873	15892		10.1007/s10639-023-11834-1	http://dx.doi.org/10.1007/s10639-023-11834-1		MAY 2023	20	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	AW8S5					2024-07-03	WOS:000984011500002
J	Gross, N				Gross, Nicole			What ChatGPT Tells Us about Gender: A Cautionary Tale about Performativity and Gender Biases in AI	SOCIAL SCIENCES-BASEL			English	Article						gender; gender bias; ChatGPT; large language models; generative AI; performativity; ethical AI	STEREOTYPES; GIRLS; PERFORMANCE	Large language models and generative AI, such as ChatGPT, have gained influence over people's personal lives and work since their launch, and are expected to scale even further. While the promises of generative artificial intelligence are compelling, this technology harbors significant biases, including those related to gender. Gender biases create patterns of behavior and stereotypes that put women, men and gender-diverse people at a disadvantage. Gender inequalities and injustices affect society as a whole. As a social practice, gendering is achieved through the repeated citation of rituals, expectations and norms. Shared understandings are often captured in scripts, including those emerging in and from generative AI, which means that gendered views and gender biases get grafted back into social, political and economic life. This paper's central argument is that large language models work performatively, which means that they perpetuate and perhaps even amplify old and non-inclusive understandings of gender. Examples from ChatGPT are used here to illustrate some gender biases in AI. However, this paper also puts forward that AI can work to mitigate biases and act to 'undo gender'.	[Gross, Nicole] Natl Coll Ireland, Sch Business, Dublin D01Y300, Ireland	National College of Ireland	Gross, N (corresponding author), Natl Coll Ireland, Sch Business, Dublin D01Y300, Ireland.	nicole.gross@ncirl.ie		Gross, Nicole/0000-0001-6047-7714				[Anonymous], 2023, GENDER STEREOTYPING; [Anonymous], 2017, The pursuit of gender equality: An uphill battle, DOI [DOI 10.1787/9789264281318-EN, 10.1787/9789264281318-EN]; Asdal K., 2021, DOING DOCUMENT ANAL; Austin J. L., 1962, DO THINGS WORDS; Banchefsky S., 2018, SOCIAL SCI, V7, P27; Beilock SL, 2010, P NATL ACAD SCI USA, V107, P1860, DOI 10.1073/pnas.0910967107; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bian L, 2017, SCIENCE, V355, P389, DOI 10.1126/science.aah6524; Bozdag E, 2013, ETHICS INF TECHNOL, V15, P209, DOI 10.1007/s10676-013-9321-6; BUTLER J, 1988, THEATRE J, V40, P519, DOI 10.2307/3207893; Butler J., 1990, GENDER TROUBLE FEMIN; Butler J, 2009, AIBR-REV ANTROPOL IB, V4, P321, DOI 10.11156/aibr.040306; Butler Judith., 2004, GENDER STUDIES PHILO; Butler Judith., 1992, BODIES MATTER DISCUR; Butler Judith, 1997, Excitable Speech. A Politics of the Performative; Cave Stephen, 2020, Philosophy & Technology, V33, P685, DOI [10.1007/s13347-020-00415-6, DOI 10.1007/S13347-020-00415-6]; chat.openai, 2023, CHATGPT WHAT DOES NU; chat.openai, CHATGPT DOES CEO DRE; chat.openai, CHATGPT WHAT AR TYP; chat.openai, 2023, CHATGPT I AM 40 YEAR; chat.openai, 2023, CHATGPT WHAT AR TYP; chat.openai, 2023, CHATGPT TELL ME STOR; chat.openai, 2023, WHY DOES GEND EQ MAT; chat.openai, 2023, CHATGPT CONSTR STOR; chat.openai, CHATGPT WHAT DOES EC; ChatGPT, 2023, CREAT STOR PAR SKILL; ChatGPT I, 2023, I AM 40 YEAR OLD MAN; Derrida J., 1992, ACTS LIT, P33; Deshpande A, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P227, DOI 10.1145/3514094.3534187; Deutsch FM, 2007, GENDER SOC, V21, P106, DOI 10.1177/0891243206293577; Dzieza J., 2023, The Verge; EIGE, 2022, ARTIF INTELL; EIGE Artifcial Intelligence, 2022, PLATF WORK GEND EQ; European Parliament, 2023, EU AI act: First regulation on artificial intelligence; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5; Fraser N, 2000, NEW LEFT REV, P107; Fraser Nancy., 2013, FORTUNES FEMINISM WO; Geiger S, 2017, MARKETING THEOR, V17, P435, DOI 10.1177/1470593117692024; Ghosh S, 2023, Arxiv, DOI arXiv:2305.10510; Gutting G., 2015, NEW YORK TIMES; Haggart B., 2023, Here's why ChatGPT raises issues of trust. World Economic Forum; Harris CR, 2006, JUDGM DECIS MAK, V1, P48; Hogenboom Melissa., 2021, BBC 0525; Hoyt CL, 2013, PERS SOC PSYCHOL B, V39, P1306, DOI 10.1177/0146167213493643; Hu K., 2023, Reuters; Ienca Marcello., 2023, PREPRINT, DOI [10.1007/s11245-023-09940-3, DOI 10.1007/S11245-023-09940-3]; Kearner Sean Michael., 2023, TECHTARGET; Lavy V, 2008, J PUBLIC ECON, V92, P2083, DOI 10.1016/j.jpubeco.2008.02.009; Locke Connson., 2019, FORBES MAGAZINE 0705; Maheshwari Rashi., 2023, FORBES MAGAZINE 0411; Manfredi S, 2019, SOC SCI-BASEL, V8, DOI 10.3390/socsci8060168; Marr Bernard., 2023, FORBES MAGAZINE 0301; Meriel Colenutt, 2021, ONE IS NOT BORN BECO; Metz Rachel., 2021, CNN NEWS 0219; National Centre for Transgender Equality, 2023, Understanding nonbinary people: how to Be respectful and supportive; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; OSBORNE P, 1994, RADICAL PHILOS, P32; Pabst J, 2022, SOC SCI-BASEL, V11, DOI 10.3390/socsci11050208; Pegoraro Rob., 2023, FASTCOMPANY 0501; Plant EA, 2000, PSYCHOL WOMEN QUART, V24, P81, DOI 10.1111/j.1471-6402.2000.tb01024.x; POMERLEAU A, 1990, SEX ROLES, V22, P359, DOI 10.1007/BF00288339; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rothchild J., 2014, The Blackwell Encyclopedia of Sociology, DOI DOI 10.1002/9781405165518.WBEOSG011.PUB2; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Sawers Paul., 2019, VENTUREBEAT 1005; Schmidt Sarah., 2023, MARKETRESEARCH 0131; Selby Daniele., 2018, GLOBAL CITIZEN 0918; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816; Shaun Conroy, 2023, WEPC 0220; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Sidorenko EL., 2021, LECT NOTES NETW SYST, DOI [10.1007/978-3-030-47458-4_51, DOI 10.1007/978-3-030-47458-4_51]; SINGH S., 2023, PREPRINT, DOI [10.31219/osf.io/9xkbu, DOI 10.31219/OSF.IO/9XKBU]; Smith G., 2021, Stanford Social Innovation Review, DOI [DOI 10.48558/A179-B138, 10.48558/A179-B138]; Squires Judith., 2007, The New Politics of Gender Equality; Statista, 2023, GLOB US DEM CHATGPT; Tomasetto C, 2011, DEV PSYCHOL, V47, P943, DOI 10.1037/a0024047; UN, 2021, WHAT DOES GEND EQ LO; UN, 2020, GEND EQ WHY IT MATT; World Economic Forum, 2023, AI GOV ALL	80	17	17	30	68	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-0760		SOC SCI-BASEL	Soc. Sci.-Basel	AUG	2023	12	8							435	10.3390/socsci12080435	http://dx.doi.org/10.3390/socsci12080435			15	Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	Q3DB9		Green Accepted, gold			2024-07-03	WOS:001056341800001
J	Lin, ZY; Chen, AP; Wang, XH; Liu, ZH; Piao, SL				Lin, Zhengyang; Chen, Anping; Wang, Xuhui; Liu, Zhihua; Piao, Shilong			Large language models reveal big disparities in current wildfire research	COMMUNICATIONS EARTH & ENVIRONMENT			English	Article							FIRE; SCIENCE	Contemporary fire-human-climate nexus has led to a surge in publication numbers across diverse research disciplines beyond the capability of experts from a single discipline. Here, we employed a generalized large language model to capture the dynamics of wildfire research published between 1980 and 2022. More than 60,000 peer-reviewed papers were scanned and analyzed. Through integrating geographical metadata extracted by the artificial intelligence and satellite wildfire datasets, we found large disparities in geographic patterns and research themes. The hottest spot of wildfire research is western United States, accounting for 15% of publications but only 0.5% of global burnt area, while the world's most widely burnt region, like Siberia and Africa are largely underrepresented by contemporary publications. Similar discrepancies are found between the fuel of wildfire and its ignition and climatic drivers, between socioeconomic development and wildfire mitigation, raising concerns on sustainable wildfire managements and calling for further artificial intelligence-aided transdisciplinary collaborations. Regions such as the United States, the Amazon and Southern Europe are hot spots in wildfire research, while Africa and Siberia with the largest burned areas are largely understudied, according to an analysis of more than 60,000 peer-reviewed articles over 1982-2022 using a large language model.	[Lin, Zhengyang; Wang, Xuhui; Piao, Shilong] Peking Univ, Inst Carbon Neutral, Sino French Inst Earth Syst Sci, Coll Urban & Environm Sci, Beijing, Peoples R China; [Chen, Anping] Colorado State Univ, Dept Biol, Ft Collins, CO 80523 USA; [Chen, Anping] Colorado State Univ, Grad Degree Program Ecol, Ft Collins, CO 80523 USA; [Liu, Zhihua] Chinese Acad Sci, CAS Key Lab Forest Ecol & Management, Inst Appl Ecol, Shenyang, Peoples R China	Peking University; Colorado State University; Colorado State University; Chinese Academy of Sciences; Shenyang Institute of Applied Ecology, CAS	Wang, XH (corresponding author), Peking Univ, Inst Carbon Neutral, Sino French Inst Earth Syst Sci, Coll Urban & Environm Sci, Beijing, Peoples R China.	xuhui.wang@pku.edu.cn	CHEN, AN/KFT-3370-2024; Wang, Xuhui/H-8605-2019; Chen, Anping/H-9960-2014	Wang, Xuhui/0000-0003-0818-9816; Chen, Anping/0000-0003-2085-3863	National Natural Science Foundation of China (National Science Foundation of China) [42041007, 42171096, 42301085]; National Natural Science Foundation of China [G22AC00431-00]; US Geological Survey	National Natural Science Foundation of China (National Science Foundation of China)(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); US Geological Survey(United States Geological Survey)	This study was funded by National Natural Science Foundation of China (42041007, 42171096 & 42301085). We also acknowledge supports by High-performance Computing Platform of Peking University. A.C. acknowledges support from the US Geological Survey (G22AC00431-00).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Andela N, 2017, SCIENCE, V356, P1356, DOI 10.1126/science.aal4108; Andela N, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abd2713; [Anonymous], 2023, NATURE, V621, P444, DOI 10.1038/d41586-023-02847-4; [Anonymous], 2017, NAT CLIM CHANGE, V7, P755, DOI 10.1038/nclimate3432; Bowman DMJS, 2020, NAT REV EARTH ENV, V1, P500, DOI 10.1038/s43017-020-0085-3; Callaghan M, 2021, NAT CLIM CHANGE, V11, P966, DOI 10.1038/s41558-021-01168-6; Center for International Earth Science Information Network-CIESIN-Columbia University, 2018, GRIDDED POPULATION W, DOI DOI 10.1023/A:1009900724172; Chatterjee J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2022.100676; Chen Y, 2021, NAT CLIM CHANGE, V11, P404, DOI 10.1038/s41558-021-01011-y; Chuvieco E, 2020, CURR FOR REP, V6, P81, DOI 10.1007/s40725-020-00116-5; Curtis PG, 2018, SCIENCE, V361, P1108, DOI 10.1126/science.aau3445; Das B, 2020, ENVIRON POLLUT, V266, DOI 10.1016/j.envpol.2020.115069; Fan L, 2023, NAT GEOSCI, V16, P56, DOI 10.1038/s41561-022-01087-x; Gurevitch J, 2018, NATURE, V555, P175, DOI 10.1038/nature25753; He TH, 2018, NATL SCI REV, V5, P237, DOI 10.1093/nsr/nwx041; Hong ZJ, 2023, ENERGY MATER ADV, V4, DOI 10.34133/energymatadv.0026; Kummu M, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.4; Moritz MA, 2005, P NATL ACAD SCI USA, V102, P17912, DOI 10.1073/pnas.0508985102; Otón G, 2021, INT J APPL EARTH OBS, V103, DOI 10.1016/j.jag.2021.102473; Page SE, 2002, NATURE, V420, P61, DOI 10.1038/nature01131; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Petersen OH, 2021, FUNCTION, V2, DOI 10.1093/function/zqab060; Shyamsundar P, 2019, SCIENCE, V365, P536, DOI 10.1126/science.aaw4085; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Turco M, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06358-z; van der Werf GR, 2017, EARTH SYST SCI DATA, V9, P697, DOI 10.5194/essd-9-697-2017; Wang JH, 2022, NAT HUM BEHAV, V6, P349, DOI 10.1038/s41562-022-01312-y; Xu WX, 2021, GEOPHYS RES LETT, V48, DOI 10.1029/2021GL093789; Xu YD, 2022, NAT SUSTAIN, V5, P574, DOI 10.1038/s41893-022-00872-1; Zalles V, 2019, P NATL ACAD SCI USA, V116, P428, DOI 10.1073/pnas.1810301115; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	33	1	1	14	14	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2662-4435		COMMUN EARTH ENVIRON	Commun. Earth Environ.	APR 1	2024	5	1							168	10.1038/s43247-024-01341-7	http://dx.doi.org/10.1038/s43247-024-01341-7			6	Environmental Sciences; Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Geology; Meteorology & Atmospheric Sciences	MR6D0		gold			2024-07-03	WOS:001195389300003
J	Li, YC; Li, LX; Wu, ZZ; Bing, ZS; Zhe, XY; Knoll, AC; Chen, L				Li, Yuchen; Li, Luxi; Wu, Zizhang; Bing, Zhenshan; Zhe, Xuanyuan; Knoll, Alois Christian; Chen, Long			UnstrPrompt: Large Language Model Prompt for Driving in Unstructured Scenarios	IEEE JOURNAL OF RADIO FREQUENCY IDENTIFICATION			English	Article						Task analysis; Visualization; Roads; Autonomous vehicles; Radiofrequency identification; Object detection; Computational modeling; Large language model; unstructured scenarios; segmentation; UnstrPrompt	SYSTEM	The integration of language descriptions or prompts with Large Language Models (LLMs) into visual tasks is currently a focal point in the advancement of autonomous driving. This study has showcased notable advancements across various standard datasets. Nevertheless, the progress in integrating language prompts faces challenges in unstructured scenarios, primarily due to the limited availability of paired data. To address this challenge, we introduce a groundbreaking language prompt set called "UnstrPrompt." This prompt set is derived from three prominent unstructured autonomous driving datasets: IDD, ORFD, and AutoMine, collectively comprising a total of 6K language descriptions. In response to the distinctive features of unstructured scenarios, we have developed a structured approach for prompt generation, encompassing three key components: scene, road, and instance. Additionally, we provide a detailed overview of the language generation process and the validation procedures. We conduct tests on segmentation tasks, and our experiments have demonstrated that text-image fusion can improve accuracy by more than 3% on unstructured data. Additionally, our description architecture outperforms the generic urban architecture by more than 0.1%. This work holds the potential to advance various aspects such as interaction and foundational models in this scenario.	[Li, Yuchen; Li, Luxi; Zhe, Xuanyuan] BNU HKBU United Int Coll, Fac Sci & Technol, Zhuhai 519087, Peoples R China; [Li, Yuchen; Li, Luxi] Hong Kong Baptist Univ, Fac Sci, Hong Kong, Peoples R China; [Li, Yuchen; Li, Luxi; Chen, Long] WAYTOUS Inc, Beijing 100083, Peoples R China; [Li, Yuchen; Bing, Zhenshan; Knoll, Alois Christian] Tech Univ Munich, Dept Informat, Comp Sci, D-85748 Munich, Germany; [Wu, Zizhang] Fudan Univ, Inst Sci & Technol Brain Inspired Intelligence, Shanghai 200433, Peoples R China; [Chen, Long] Chinese Acad Sci, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China; [Chen, Long] Guangdong Lab Artificial Intelligence & Digital Ec, Inst Machine Learning & Intelligent Syst, Shenzhen 518107, Peoples R China	Beijing Normal University - Hong Kong Baptist University United International College; Hong Kong Baptist University; Technical University of Munich; Fudan University; Chinese Academy of Sciences; Guangming Laboratory	Zhe, XY (corresponding author), BNU HKBU United Int Coll, Fac Sci & Technol, Zhuhai 519087, Peoples R China.; Chen, L (corresponding author), Chinese Acad Sci, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China.	liyuchen2016@hotmail.com; zhexuanyuan@uic.edu.cn; long.chen@ia.ac.cn		Li, Yuchen/0000-0002-6732-323X; Bing, Zhenshan/0000-0002-0896-2517; Li, Luxi/0000-0003-4049-1337	National Key Research and Development Program of China	National Key Research and Development Program of China	No Statement Available	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Chen L, 2023, IEEE T INTELL VEHICL, V8, P1046, DOI 10.1109/TIV.2022.3223131; Chen L, 2020, IEEE T IND ELECTRON, V67, P10600, DOI [10.1109/TITS.2020.3004655, 10.1109/TIE.2019.2962413]; Chen L, 2020, P IEEE, V108, P262, DOI 10.1109/JPROC.2019.2952735; Chen L, 2017, IEEE T INTELL TRANSP, V18, P3093, DOI 10.1109/TITS.2017.2680538; Chung DT, 2023, Arxiv, DOI arXiv:2210.14890; Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350; Cui YD, 2024, IEEE T INTELL VEHICL, V9, P1450, DOI 10.1109/TIV.2023.3327715; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deruyttere T., 2019, arXiv; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074; Kazemzadeh S., 2014, P 2014 C EMPIRICAL M, P787, DOI [DOI 10.3115/V1/D14-1086, 10.3115/v1/d14-1086]; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Li JJ, 2023, IEEE-CAA J AUTOMATIC, V10, P2183, DOI 10.1109/JAS.2023.124056; Li LH, 2022, PROC CVPR IEEE, P10955, DOI 10.1109/CVPR52688.2022.01069; Li QQ, 2014, IEEE T VEH TECHNOL, V63, P540, DOI 10.1109/TVT.2013.2281199; Li Y., 2023, P IEEE 3 INT C DIG T, P1; Li YC, 2022, PROC CVPR IEEE, P21276, DOI 10.1109/CVPR52688.2022.02062; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu Q, 2022, IEEE J RADIO FREQ ID, V6, P729, DOI 10.1109/JRFID.2022.3212169; Liu YH, 2022, IEEE J RADIO FREQ ID, V6, P867, DOI 10.1109/JRFID.2022.3203733; Long Chen, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5682, DOI 10.1109/ICRA.2017.7989668; Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028; Meng ZJ, 2022, IEEE J RADIO FREQ ID, V6, P710, DOI 10.1109/JRFID.2022.3211565; Min C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P2532, DOI 10.1109/ICRA46639.2022.9812139; Ouyang L., 2022, NEURIPS; Qian TW, 2024, Arxiv, DOI arXiv:2305.14836; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Teng S., 2023, P IEEE 3 INT C DIG T, P1; Teng SY, 2024, MECH SYST SIGNAL PR, V208, DOI 10.1016/j.ymssp.2023.111051; Teng SY, 2023, IEEE T INTELL VEHICL, V8, P3692, DOI 10.1109/TIV.2023.3274536; Teng SY, 2023, IEEE T INTELL VEHICL, V8, P673, DOI 10.1109/TIV.2022.3225340; Varma G, 2019, IEEE WINT CONF APPL, P1743, DOI 10.1109/WACV.2019.00190; Vasudevan AB, 2018, PROC CVPR IEEE, P4129, DOI 10.1109/CVPR.2018.00434; Veit A., 2016, arXiv; Vinker Y, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530068; Wang SY, 2023, IEEE T INTELL VEHICL, V8, P4706, DOI 10.1109/TIV.2023.3325300; Wang X., 2020, P AS C COMP VIS ACCV, P1; Wolf D, 2015, IEEE INT CONF ROBOT, P4867, DOI 10.1109/ICRA.2015.7139875; Wu DM, 2023, PROC CVPR IEEE, P14633, DOI 10.1109/CVPR52729.2023.01406; Wu DM, 2023, Arxiv, DOI arXiv:2309.04379; Yi MY, 2023, PROC CVPR IEEE, P7071, DOI 10.1109/CVPR52729.2023.00683; Zhou YC, 2022, IEEE J RADIO FREQ ID, V6, P962, DOI 10.1109/JRFID.2022.3207017; Zou Q, 2022, IEEE T INTELL TRANSP, V23, P6907, DOI 10.1109/TITS.2021.3063477	47	2	2	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		2469-7281		IEEE J RADIO FREQ ID	IEEE J. Radio Freq. Identif.		2024	8						367	375		10.1109/JRFID.2024.3367975	http://dx.doi.org/10.1109/JRFID.2024.3367975			9	Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Engineering; Telecommunications	QY4X2					2024-07-03	WOS:001224427400001
J	Spirling, A				Spirling, Arthur			Open generative AI models areaway forward for science	NATURE			English	Editorial Material						Ethics; Machine learning; Technology; Scientific community		Researchers should avoid the lure of proprietary models and develop transparent large language models to ensure reproducibility.	[Spirling, Arthur] NYU, Polit & Data Sci, New York, NY 10012 USA	New York University	Spirling, A (corresponding author), NYU, Polit & Data Sci, New York, NY 10012 USA.	as9934@nyu.edu							0	15	16	25	69	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	APR 20	2023	616	7957					413	413		10.1038/d41586-023-01295-4	http://dx.doi.org/10.1038/d41586-023-01295-4			1	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	K2ZG0	37072520	Bronze			2024-07-03	WOS:001015166000002
J	Zhang, GZ; Chen, LZ; Zhang, Y; Liu, Y; Ge, YY; Cai, XQ				Zhang, Guangzi; Chen, Lizhe; Zhang, Yu; Liu, Yan; Ge, Yuyao; Cai, Xingquan			Translating Words to Worlds: Zero-Shot Synthesis of 3D Terrain from Textual Descriptions Using Large Language Models	APPLIED SCIENCES-BASEL			English	Article						text-to-3D; multiagent; chain-of-thought; large language model; LLM's spatial awareness; terrain synthesis		The current research on text-guided 3D synthesis predominantly utilizes complex diffusion models, posing significant challenges in tasks like terrain generation. This study ventures into the direct synthesis of text-to-3D terrain in a zero-shot fashion, circumventing the need for diffusion models. By exploiting the large language model's inherent spatial awareness, we innovatively formulate a method to update existing 3D models through text, thereby enhancing their accuracy. Specifically, we introduce a Gaussian-Voronoi map data structure that converts simplistic map summaries into detailed terrain heightmaps. Employing a chain-of-thought behavior tree approach, which combines action chains and thought trees, the model is guided to analyze a variety of textual inputs and extract relevant terrain data, effectively bridging the gap between textual descriptions and 3D models. Furthermore, we develop a text-terrain re-editing technique utilizing multiagent reasoning, allowing for the dynamic update of the terrain's representational structure. Our experimental results indicate that this method proficiently interprets the spatial information embedded in the text and generates controllable 3D terrains with superior visual quality.	[Zhang, Guangzi; Chen, Lizhe; Zhang, Yu; Liu, Yan; Ge, Yuyao; Cai, Xingquan] North China Univ Technol, Coll Informat, Beijing 100144, Peoples R China; [Ge, Yuyao] Chinese Acad Sci, Inst Comp Technol, CAS Key Lab AI Secur, Beijing 100190, Peoples R China; [Ge, Yuyao] Univ Chinese Acad Sci, Beijing 101408, Peoples R China	North China University of Technology; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Zhang, GZ; Chen, LZ (corresponding author), North China Univ Technol, Coll Informat, Beijing 100144, Peoples R China.	guangzi@ncut.edu.cn; chenlizhe@mail.ncut.edu.cn; zhangyu@mail.ncut.edu.cn; liuyan@mail.ncut.edu.cn; yuyao.ge.work@gmail.com; caixingquan@ncut.edu.cn		Cai, Xingquan/0000-0002-5996-2728; Zhang, Guangzi/0009-0009-7579-518X	Project of Humanities and Social Sciences of the Ministry of Education in China	Project of Humanities and Social Sciences of the Ministry of Education in China	We would like to express our gratitude to the pioneers in the field, the various research achievements cited in this paper. We extend our thanks to our family members for their unwavering support and encouragement. To the successors, your future citations and references to this work are crucial for broadening the impact of our research and extending its life. We are also grateful to our peers, the companions of our academic journey, whose shared efforts and struggles in learning and striving have left an indelible mark on our hearts.	Aboulaich R, 2008, COMPUT MATH APPL, V56, P874, DOI 10.1016/j.camwa.2008.01.017; Cai Ruojin, 2020, COMPUTER VISION ECCV; Cao YP, 2018, LECT NOTES COMPUT SC, V11213, P626, DOI 10.1007/978-3-030-01240-3_38; Chai ZW, 2023, Arxiv, DOI arXiv:2310.05845; Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Dubois Y., 2024, Adv. Neural Inf. Process. Syst; Fatemi B, 2023, Arxiv, DOI arXiv:2310.04560; Gao L, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480503; Gao L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3355089.3356488; Ge YY, 2024, Arxiv, DOI arXiv:2402.07140; Guédon A, 2023, Arxiv, DOI arXiv:2311.12775; Guo JY, 2023, Arxiv, DOI arXiv:2305.15066; Gupta K., 2020, Adv. Neural Inf. Process. Syst, P1747; Huang ZQ, 2023, Arxiv, DOI arXiv:2303.13495; Jain A, 2022, PROC CVPR IEEE, P857, DOI 10.1109/CVPR52688.2022.00094; Jin FH, 2024, Arxiv, DOI arXiv:2402.05376; Kerbl B, 2023, ACM T GRAPHIC, V42, DOI 10.1145/3592433; KWEON IS, 1994, CVGIP-IMAG UNDERSTAN, V59, P171, DOI 10.1006/ciun.1994.1011; Lee Han-Hung, 2022, arXiv; Li J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073637; Li X., 2023, P IEEECVF INT C COMP; Liu R., 2023, P THE 12 INT C LEARN; Liu ZJ, 2023, Arxiv, DOI arXiv:2310.02170; Luo A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16218, DOI 10.1109/ICCV48922.2021.01593; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127; Park J.S., 2023, P 36 ANN ACM S USER; Perozzi B, 2024, Arxiv, DOI arXiv:2402.05862; Ren JW, 2024, Arxiv, DOI arXiv:2312.17142; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; SULTAN F, 1990, J MARKETING RES, V27, P70, DOI 10.2307/3172552; Tang JX, 2024, Arxiv, DOI arXiv:2309.16653; Tang JX, 2023, Arxiv, DOI arXiv:2303.02091; Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230; Wei JS, 2022, ADV NEUR IN; Wu R., 2020, P IEEECVF C COMPUTER; Wu RD, 2022, Arxiv, DOI [arXiv:2208.02946, 10.1145/3550454.3555480]; Xiang P, 2023, IEEE T PATTERN ANAL, V45, P6320, DOI 10.1109/TPAMI.2022.3217161; Xu JL, 2023, PROC CVPR IEEE, P20908, DOI 10.1109/CVPR52729.2023.02003; Xu ZL, 2024, Arxiv, DOI arXiv:2310.18940; Yang GD, 2019, IEEE I CONF COMP VIS, P4540, DOI 10.1109/ICCV.2019.00464; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yi TR, 2024, Arxiv, DOI arXiv:2310.08529; Zeng X., 2022, ADV NEURAL INF PROCE, V35, P10021; Zheng X, 2022, COMPUT GRAPH FORUM, V41, P51, DOI 10.1111/cgf.14602	47	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	8							3257	10.3390/app14083257	http://dx.doi.org/10.3390/app14083257			19	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	OY1B5		gold			2024-07-03	WOS:001210735000001
J	Leypold, T; Lingens, LF; Beier, JP; Boos, AM				Leypold, Tim; Lingens, Lara F.; Beier, Justus P.; Boos, Anja M.			Integrating AI in Lipedema Management: Assessing the Efficacy of GPT-4 as a Consultation Assistant	LIFE-BASEL			English	Article						lipedema; large language models; artificial intelligence; LLM; AI; ChatGPT; GPT-4; plastic surgery; recommendation; medical history		The role of artificial intelligence (AI) in healthcare is evolving, offering promising avenues for enhancing clinical decision making and patient management. Limited knowledge about lipedema often leads to patients being frequently misdiagnosed with conditions like lymphedema or obesity rather than correctly identifying lipedema. Furthermore, patients with lipedema often present with intricate and extensive medical histories, resulting in significant time consumption during consultations. AI could, therefore, improve the management of these patients. This research investigates the utilization of OpenAI's Generative Pre-Trained Transformer 4 (GPT-4), a sophisticated large language model (LLM), as an assistant in consultations for lipedema patients. Six simulated scenarios were designed to mirror typical patient consultations commonly encountered in a lipedema clinic. GPT-4 was tasked with conducting patient interviews to gather medical histories, presenting its findings, making preliminary diagnoses, and recommending further diagnostic and therapeutic actions. Advanced prompt engineering techniques were employed to refine the efficacy, relevance, and accuracy of GPT-4's responses. A panel of experts in lipedema treatment, using a Likert Scale, evaluated GPT-4's responses across six key criteria. Scoring ranged from 1 (lowest) to 5 (highest), with GPT-4 achieving an average score of 4.24, indicating good reliability and applicability in a clinical setting. This study is one of the initial forays into applying large language models like GPT-4 in specific clinical scenarios, such as lipedema consultations. It demonstrates the potential of AI in supporting clinical practices and emphasizes the continuing importance of human expertise in the medical field, despite ongoing technological advancements.	[Leypold, Tim; Lingens, Lara F.; Beier, Justus P.; Boos, Anja M.] Univ Hosp RWTH Aachen, Hand Surg Burn Ctr, Dept Plast Surg, Pauwelsstr 30, D-52074 Aachen, Germany	RWTH Aachen University; RWTH Aachen University Hospital	Leypold, T (corresponding author), Univ Hosp RWTH Aachen, Hand Surg Burn Ctr, Dept Plast Surg, Pauwelsstr 30, D-52074 Aachen, Germany.	tleypold@ukaachen.de; llingens@ukaachen.de; jbeier@ukaachen.de; aboos@ukaachen.de	Beier, Justus/L-9094-2016	Beier, Justus/0000-0002-0179-1962				Almeida LC, 2024, RADIOL-ARTIF INTELL, V6, DOI 10.1148/ryai.230103; [Anonymous], 2023, OpenAI DALLE 3 is Now Available in ChatGPT Plus and Enterprise; [Anonymous], 2023, OpenAI GPT-4; Bajaj S, 2024, ACAD RADIOL, V31, P1256, DOI 10.1016/j.acra.2023.08.039; Blease C, 2023, BMJ MENTAL HEALTH, V26, DOI 10.1136/bmjment-2023-300884; Buzancic I, 2024, BRIT J CLIN PHARMACO, V90, P662, DOI 10.1111/bcp.15963; Chen BH, 2024, Arxiv, DOI [arXiv:2310.14735, 10.48550/arXiv.2310.14735]; Copeland-Halperin LR, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005226; Duarte Fabio, 2023, Number of chatgpt users; Forner-Cordero I, 2021, INT ANGIOL, V40, P345, DOI 10.23736/S0392-9590.21.04604-6; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Hu Y, 2024, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocad259; Kojima T, 2022, ADV NEUR IN; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Leypold T, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005471; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/52865; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Miao J, 2024, MEDICINA-LITHUANIA, V60, DOI 10.3390/medicina60030445; Najafali D, 2023, AESTHET SURG J, V43, pNP591, DOI 10.1093/asj/sjad056; OpenAI, 2023, ChatGPT can now see, hear, and speak; OpenAI, 2023, Introducing gpts; Reich-Schupke S, 2017, J DTSCH DERMATOL GES, V15, P758, DOI 10.1111/ddg.13036; Savage T, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01010-1; Stoneham S, 2024, CLIN EXP DERMATOL, V49, P707, DOI 10.1093/ced/llad402; Sun YX, 2023, AESTHET SURG J, V43, pNP670, DOI 10.1093/asj/sjad134; Truhn D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-47500-2; Valencia OAG, 2023, J PERS MED, V13, DOI 10.3390/jpm13091363; Wei JS, 2022, ADV NEUR IN; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324; Wójcik S, 2023, CARDIOL J, V30, P1018, DOI 10.5603/cj.97515; Wu S, 2023, Arxiv, DOI arXiv:2307.13339; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7; Zhang Z., 2022, arXiv; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	36	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-1729		LIFE-BASEL	Life-Basel	MAY	2024	14	5							646	10.3390/life14050646	http://dx.doi.org/10.3390/life14050646			10	Biology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Microbiology	SC6M4	38792666	gold			2024-07-03	WOS:001232298600001
C	del Barrio, DA; Gatica-Perez, D			ACM	del Barrio, David Alonso; Gatica-Perez, Daniel			Framing the News: From Human Perception to Large Language Model Inferences	PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2023			English	Proceedings Paper	ACM International Conference on Multimedia Retrieval (ICMR)	JUN 12-15, 2023	Thessaloniki, GREECE	Assoc Comp Machinery		Covid-19 no-vax; news framing; GPT-3; prompt-engineering; transformers; large language models	SENTIMENT ANALYSIS; FRAMES; MEDIA; COMPUTER; PRESS	Identifying the frames of news is important to understand the articles' vision, intention, message to be conveyed, and which aspects of the news are emphasized. Framing is a widely studied concept in journalism, and has emerged as a new topic in computing, with the potential to automate processes and facilitate the work of journalism professionals. In this paper, we study this issue with articles related to the Covid-19 anti-vaccine movement. First, to understand the perspectives used to treat this theme, we developed a protocol for human labeling of frames for 1786 headlines of NoVax movement articles of European newspapers from 5 countries. Headlines are key units in the written press, and worth of analysis as many people only read headlines (or use them to guide their decision for further reading.) Second, considering advances in Natural Language Processing (NLP) with large language models, we investigated two approaches for frame inference of news headlines: first with a GPT-3.5 fine-tuning approach, and second with GPT3.5 prompt-engineering. Our work contributes to the study and analysis of the performance that these models have to facilitate journalistic tasks like classification of frames, while understanding whether the models are able to replicate human perception in the identification of these frames.	[del Barrio, David Alonso; Gatica-Perez, Daniel] Idiap Res Inst, Martigny, Switzerland; [Gatica-Perez, Daniel] Ecole Polytech Fed Lausanne, Lausanne, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	del Barrio, DA (corresponding author), Idiap Res Inst, Martigny, Switzerland.	ddbarrio@idiap.ch; gatica@idiap.ch		Alonso del Barrio, David/0000-0002-6728-6774	European Commission [951911]	European Commission(European Union (EU)European Commission Joint Research Centre)	This work was supported by the AI4Media project, funded by the European Commission (Grant 951911) under the H2020 Programme ICT-48-2020. We also thank the newspapers for sharing their online articles. Finally, we thank our colleagues Haeeun Kim and Emma Bouton-Bessac for their support with annotations, and Victor Bros and Oleksii Polegkyi for discussions.	Adiprasetio J., 2020, Jurnal Ilmu Sosial Dan Ilmu Politik, V24, P153, DOI DOI 10.22146/JSP.56457; Alex N., 2021, arXiv; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Biswal SK, 2020, ALGO INTELL SY, P155, DOI 10.1007/978-981-15-0994-0_10; Bleich E, 2015, J ETHN MIGR STUD, V41, P942, DOI 10.1080/1369183X.2014.1002200; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burscher B, 2014, COMMUN METHODS MEAS, V8, P190, DOI 10.1080/19312458.2014.937527; Burscher B, 2016, SOC SCI COMPUT REV, V34, P530, DOI 10.1177/0894439315596385; Card D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P438; Catalan-Matamoros D, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17218136; Catalán-Matamoros D, 2019, REV LAT COMUN SOC, V74, P786, DOI 10.4185/RLCS-2019-1357; Coddington M, 2015, DIGIT JOURNAL, V3, P331, DOI 10.1080/21670811.2014.976400; Cooper Stephen D., 2010, Doing News Framing Analysis, P151; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; del Barrio David Alonso, 2022, 5 COUNTRY ANAL, P35, DOI DOI 10.1145/3512732.3533588; Dirikx A, 2010, PUBLIC UNDERST SCI, V19, P732, DOI 10.1177/0963662509352044; Dou ZY, 2021, Arxiv, DOI arXiv:2010.08014; Ebrahim S, 2022, HEALTH SA GESONDHEID, V27, P1, DOI 10.4102/hsag.v27i0.1683; ENTMAN RM, 1993, J COMMUN, V43, P51, DOI 10.1111/j.1460-2466.1993.tb01304.x; Gao T., 2020, arXiv; Ghasiya P, 2021, IEEE ACCESS, V9, P36645, DOI 10.1109/ACCESS.2021.3062875; GIFFORD R, 1994, J PERS SOC PSYCHOL, V66, P398, DOI 10.1037/0022-3514.66.2.398; Grail Q, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1792; Gupta Anushka, 2022, Sustainable Advanced Computing: Select Proceedings of ICSAC 2021. Lecture Notes in Electrical Engineering (840), P249, DOI 10.1007/978-981-16-9012-9_21; Trinh TH, 2019, Arxiv, DOI arXiv:1806.02847; Hend Abdelgaber Ahmed El-Behary, 2021, FEVERISH SPRING COMP; Hermida A, 2017, DIGIT JOURNAL, V5, P159, DOI 10.1080/21670811.2016.1162663; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Isoaho K, 2021, POLICY STUD J, V49, P300, DOI 10.1111/psj.12343; Jacobi C, 2016, DIGIT JOURNAL, V4, P89, DOI 10.1080/21670811.2015.1093271; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Khanehzar Shima, 2019, ALTA; Kim J, 2018, COMMUN REV, V21, P89, DOI 10.1080/10714421.2018.1479616; Lamsal Rabindra, 2021, Sentiment Analysis of English Tweets with BERTsent; Lewis SC, 2019, J MASS COMMUN Q, V96, P673, DOI 10.1177/1077699019859901; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu S., 2019, P 23 C COMPUTATIONAL, P504; Matthes J, 2008, J COMMUN, V58, P258, DOI 10.1111/j.1460-2466.2008.00384.x; Meyer Selina, 2022, P 4 C CONVERSATIONAL, P1; Middleton SE, 2018, IEEE INTERNET COMPUT, V22, P83, DOI 10.1109/MIC.2018.112102235; Milosavljevic M, 2021, JOURNALISM, V22, P2203, DOI 10.1177/1464884919861598; Monarch R., 2021, Human -in-the -Loop Machine Learning: Active Learning and Annotation for Human -Centered AI; Nicholls T, 2021, POLIT COMMUN, V38, P159, DOI 10.1080/10584609.2020.1812777; Pan Z., 1993, Political Communication, V10, P55, DOI DOI 10.1080/10584609.1993.9962963; Puri R, 2019, Arxiv, DOI arXiv:1912.10165; Qin GH, 2021, Arxiv, DOI arXiv:2104.06599; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rai N., 2022, Int. J. Cogn. Comput. Eng, V3, P98, DOI DOI 10.1016/J.IJCCE.2022.03.003; Rodelo FV, 2021, CUAD INFO-SANTIAGO, P91, DOI 10.7764/cdi.50.37525; Semetko HA, 2000, J COMMUN, V50, P93, DOI 10.1093/joc/50.2.93; Shin R, 2021, Arxiv, DOI arXiv:2104.08768; Sidiropoulos Efstathios A., 2017, Studies in Media and Communication, V5, P63, DOI DOI 10.11114/SMC.V5I1.2279; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tsimpoukelli M., 2021, Advances in Neural Information Processing Systems, V34, P200; Vannoy SA, 2010, COMMUN ACM, V53, P149, DOI 10.1145/1743546.1743585; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Ylä-Anttila T, 2022, GLOB MEDIA COMMUN, V18, P91, DOI 10.1177/17427665211023984	59	1	1	4	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0178-8				2023							627	635		10.1145/3591106.3592278	http://dx.doi.org/10.1145/3591106.3592278			9	Computer Science, Artificial Intelligence; Computer Science, Hardware & Architecture	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5VA		Green Published, Green Submitted			2024-07-03	WOS:001053911300078
C	Yuan, SY; Chen, JJ; Fu, ZQ; Ge, XY; Shah, S; Jankowski, CR; Xiao, YH; Yang, DQ		Rogers, A; Boyd-Graber, J; Okazaki, N		Yuan, Siyu; Chen, Jiangjie; Fu, Ziquan; Ge, Xuyang; Shah, Soham; Jankowski, Charles Robert; Xiao, Yanghua; Yang, Deqing			Distilling Script Knowledge from Large Language Models for Constrained Language Planning	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				In everyday life, humans often plan their actions by following step-by-step instructions in the form of goal-oriented scripts. Previous work has exploited language models (LMs) to plan for abstract goals of stereotypical activities (e.g., "make a cake"), but leaves more specific goals with multi-facet constraints understudied (e.g., "make a cake for diabetics"). In this paper, we define the task of constrained language planning for the first time. We propose an overgenerate-then-filter approach to improve large language models (LLMs) on this task, and use it to distill a novel constrained language planning dataset, CoScript, which consists of 55,000 scripts. Empirical results demonstrate that our method significantly improves the constrained language planning ability of LLMs, especially on constraint faithfulness. Furthermore, CoScript is demonstrated to be quite effective in endowing smaller LMs with constrained language planning ability. 1	[Yuan, Siyu; Yang, Deqing] Fudan Univ, Sch Data Sci, Shanghai, Peoples R China; [Chen, Jiangjie; Ge, Xuyang; Xiao, Yanghua] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China; [Fu, Ziquan] System Inc, Shanghai, Peoples R China; [Fu, Ziquan; Shah, Soham; Jankowski, Charles Robert] Brain Technol Inc, Shanghai, Peoples R China; [Xiao, Yanghua] Fudan Aishu Cognit Intelligence Joint Res Ctr, Shanghai, Peoples R China	Fudan University; Fudan University	Fu, ZQ (corresponding author), System Inc, Shanghai, Peoples R China.; Fu, ZQ (corresponding author), Brain Technol Inc, Shanghai, Peoples R China.	syyuan21@m.fudan.edu.cn; jjchen19@fudan.edu.cn; frank@system.com; xyge20@fudan.edu.cn; sshah@brain.im; cjankowski@brain.im; shawyh@fudan.edu.cn; yangdeqing@fudan.edu.cn			Chinese NSF Major Research Plan [92270121]; Shanghai Science and Technology Innovation Action Plan [21511100401]; Science and Technology Commission of Shanghai Municipality Grant [22511105902]	Chinese NSF Major Research Plan; Shanghai Science and Technology Innovation Action Plan; Science and Technology Commission of Shanghai Municipality Grant(Science & Technology Commission of Shanghai Municipality (STCSM))	We thank the anonymous reviewers for their valuable comments, and Wei Shi and Shuang Li from Fudan University for their useful suggestions for the manuscript. This work is supported by the Chinese NSF Major Research Plan (No.92270121), Shanghai Science and Technology Innovation Action Plan (No.21511100401) and the Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902).	Abelson Robert P, 1976, SCRIPT PROCESSING AT; [Anonymous], 2007, P 45 ANN M ASS COMP; Chen M., 2021, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Fang BAY, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3481; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Garoufi K, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1573; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Kaiser P, 2014, IEEE INT CONF ROBOT, P3749, DOI 10.1109/ICRA.2014.6907402; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lu YJ, 2023, Arxiv, DOI arXiv:2206.02928; Mishra S, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P589; Narayan S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1319; Olmo Alberto, 2021, FINPLAN 2021, P24; Ousidhoum N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4262; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Regneri M, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P979; Sakaguchi K, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2138; Sanh Victor, 2022, INT C LEARNING REPRE; Schank R. C., 1975, ADV PAPERS 4 INT JOI, V75, P151, DOI DOI 10.1016/B978-1-4832-1446-7.50019-4; Valmeekam Karthik, 2022, NEURIPS; Wanzare LDA, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3494; Wei Jason, 2022, ADV NEURAL INFORM PR; West Peter, 2022, PROCEEDINGS; Wiegreffe S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P632	28	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							4303	4325						23	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086803006
J	Ye, AJ; Maiti, A; Schmidt, M; Pedersen, SJ				Ye, Anjia; Maiti, Ananda; Schmidt, Matthew; Pedersen, Scott J.			A Hybrid Semi-Automated Workflow for Systematic and Literature Review Processes with Large Language Model Analysis	FUTURE INTERNET			English	Article						artificial intelligence; large language model; systematic review; methodology; workflow	AUTOMATION	Systematic reviews (SRs) are a rigorous method for synthesizing empirical evidence to answer specific research questions. However, they are labor-intensive because of their collaborative nature, strict protocols, and typically large number of documents. Large language models (LLMs) and their applications such as gpt-4/ChatGPT have the potential to reduce the human workload of the SR process while maintaining accuracy. We propose a new hybrid methodology that combines the strengths of LLMs and humans using the ability of LLMs to summarize large bodies of text autonomously and extract key information. This is then used by a researcher to make inclusion/exclusion decisions quickly. This process replaces the typical manually performed title/abstract screening, full-text screening, and data extraction steps in an SR while keeping a human in the loop for quality control. We developed a semi-automated LLM-assisted (Gemini-Pro) workflow with a novel innovative prompt development strategy. This involves extracting three categories of information including identifier, verifier, and data field (IVD) from the formatted documents. We present a case study where our hybrid approach reduced errors compared with a human-only SR. The hybrid workflow improved the accuracy of the case study by identifying 6/390 (1.53%) articles that were misclassified by the human-only process. It also matched the human-only decisions completely regarding the rest of the 384 articles. Given the rapid advances in LLM technology, these results will undoubtedly improve over time.	[Ye, Anjia; Pedersen, Scott J.] Univ Tasmania, Sch Educ, Launceston, Tas 7248, Australia; [Maiti, Ananda] Deakin Univ, Sch Informat Technol, Geelong, Vic 3221, Australia; [Schmidt, Matthew] Univ Tasmania, Sch Hlth Sci, Sandy Bay, Tas 7005, Australia	University of Tasmania; Deakin University; University of Tasmania	Ye, AJ (corresponding author), Univ Tasmania, Sch Educ, Launceston, Tas 7248, Australia.; Maiti, A (corresponding author), Deakin Univ, Sch Informat Technol, Geelong, Vic 3221, Australia.	anjia.ye@utas.edu.au; anandamaiti@ieee.org; matthew.schmidt@utas.edu.au; scott.pedersen@utas.edu.au	; Maiti, Ananda/M-3248-2016; Pedersen, Scott/J-7298-2014	Schmidt, Matthew/0000-0001-9844-3296; Maiti, Ananda/0000-0003-0785-5282; YE, ANJIA/0000-0001-5888-4994; Pedersen, Scott/0000-0002-8566-7693				Ahn E, 2018, KOREAN J ANESTHESIOL, V71, P103, DOI 10.4097/kjae.2018.71.2.103; Alshami A, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11070351; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], AMSTAR Checklist; Aromataris E, 2015, INT J EVID-BASED HEA, V13, P132, DOI 10.1097/XEB.0000000000000055; Bannach-Brown A, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-0942-7; Borah R, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2016-012545; CHALMERS I, 1994, BMJ-BRIT MED J, V309, P862, DOI 10.1136/bmj.309.6958.862; Chu X, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2201, DOI 10.1145/2882903.2912574; de la Torre-lopez J, 2023, COMPUTING, V105, P2171, DOI 10.1007/s00607-023-01181-x; Goodyear-Smith FA, 2012, BMC MED RES METHODOL, V12, DOI 10.1186/1471-2288-12-76; Guo ED, 2024, J MED INTERNET RES, V26, DOI 10.2196/48996; Higgins J.P.T., 2008, Cochrane handbook for systematic reviews of interventions: Cocharne Book Series, DOI DOI 10.1002/9780470712184; Horsley T, 2011, COCHRANE DB SYST REV, DOI 10.1002/14651858.MR000026.pub2; Khraisha Q, 2023, Arxiv, DOI [arXiv:2310.17526, DOI 10.48550/ARXIV.2310.17526]; Lusa S, 2020, APPL ERGON, V82, DOI 10.1016/j.apergo.2019.102962; Marshall IJ, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1074-9; Meline T., 2006, CONT ISSUES COMMUNIC, V33, P21, DOI [10.1044/cicsd_33_S_21, 10.1044/cicsd33S21]; Michelson M, 2019, CONT CLIN TRIAL COMM, V16, DOI 10.1016/j.conctc.2019.100443; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Robinson KA, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-60; Syriani E., 2023, arXiv; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850; Tsafnat G, 2014, SYST REV-LONDON, V3, DOI 10.1186/2046-4053-3-74; van de Schoot R, 2021, NAT MACH INTELL, V3, P125, DOI 10.1038/s42256-020-00287-7; van Dijk SHB, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2023-072254; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wei J, 2023, Arxiv, DOI arXiv:2303.03846; Yu Z, 2019, EXPERT SYST APPL, V120, P57, DOI 10.1016/j.eswa.2018.11.021	33	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	MAY	2024	16	5							167	10.3390/fi16050167	http://dx.doi.org/10.3390/fi16050167			22	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	SE6H6		gold			2024-07-03	WOS:001232816200001
J	Luo, L; Ning, JZ; Zhao, YW; Wang, ZJ; Ding, ZY; Chen, P; Fu, WR; Han, QY; Xu, GT; Qiu, YZ; Pan, DH; Li, JR; Li, H; Feng, WD; Tu, SB; Liu, YQ; Yang, ZH; Wang, J; Sun, YY; Lin, HF				Luo, Ling; Ning, Jinzhong; Zhao, Yingwen; Wang, Zhijun; Ding, Zeyuan; Chen, Peng; Fu, Weiru; Han, Qinyu; Xu, Guangtao; Qiu, Yunzhi; Pan, Dinghao; Li, Jiru; Li, Hao; Feng, Wenduo; Tu, Senbo; Liu, Yuqi; Yang, Zhihao; Wang, Jian; Sun, Yuanyuan; Lin, Hongfei			Taiyi: a bilingual fine-tuned large language model for diverse biomedical tasks	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						natural language processing; large language model; supervised fine-tuning; biomedical multitasking		Objective Most existing fine-tuned biomedical large language models (LLMs) focus on enhancing performance in monolingual biomedical question answering and conversation tasks. To investigate the effectiveness of the fine-tuned LLMs on diverse biomedical natural language processing (NLP) tasks in different languages, we present Taiyi, a bilingual fine-tuned LLM for diverse biomedical NLP tasks.Materials and Methods We first curated a comprehensive collection of 140 existing biomedical text mining datasets (102 English and 38 Chinese datasets) across over 10 task types. Subsequently, these corpora were converted to the instruction data used to fine-tune the general LLM. During the supervised fine-tuning phase, a 2-stage strategy is proposed to optimize the model performance across various tasks.Results Experimental results on 13 test sets, which include named entity recognition, relation extraction, text classification, and question answering tasks, demonstrate that Taiyi achieves superior performance compared to general LLMs. The case study involving additional biomedical NLP tasks further shows Taiyi's considerable potential for bilingual biomedical multitasking.Conclusion Leveraging rich high-quality biomedical corpora and developing effective fine-tuning strategies can significantly improve the performance of LLMs within the biomedical domain. Taiyi shows the bilingual multitasking capability through supervised fine-tuning. However, those tasks such as information extraction that are not generation tasks in nature remain challenging for LLM-based generative approaches, and they still underperform the conventional discriminative approaches using smaller language models.	[Luo, Ling; Ning, Jinzhong; Zhao, Yingwen; Wang, Zhijun; Ding, Zeyuan; Chen, Peng; Fu, Weiru; Han, Qinyu; Xu, Guangtao; Qiu, Yunzhi; Pan, Dinghao; Li, Jiru; Li, Hao; Feng, Wenduo; Tu, Senbo; Liu, Yuqi; Yang, Zhihao; Wang, Jian; Sun, Yuanyuan; Lin, Hongfei] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China; [Luo, Ling] Dalian Univ Technol, Sch Comp Sci & Technol, 2 Linggong Rd, Ganjingzi Dist, Dalian 116024, Peoples R China	Dalian University of Technology; Dalian University of Technology	Luo, L (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, 2 Linggong Rd, Ganjingzi Dist, Dalian 116024, Peoples R China.	lingluo@dlut.edu.cn	Luo, Ling/AAA-3476-2019	Luo, Ling/0000-0002-5141-0259; chen, peng/0000-0002-0975-236X	National Natural Science Foundation of China [62302076]; Fundamental Research Funds for the Central Universities [DUT23RC (3)014]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	This research was supported by the National Natural Science Foundation of China (No. 62302076) and the Fundamental Research Funds for the Central Universities (No. DUT23RC (3)014).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Bai JZ, 2023, Arxiv, DOI [arXiv:2309.16609, 10.48550/arXiv.2309.16609, DOI 10.48550/ARXIV.2309.16609]; Baker S, 2016, BIOINFORMATICS, V32, P432, DOI 10.1093/bioinformatics/btv585; Bao Z., 2023, arXiv, DOI DOI 10.48550/ARXIV.2308.14346; Chen Q., 2023, Bioinformatics, V39, pbtad557; Chen Q., 2021, P 7 BIOCREATIVE CHAL; Chen QY, 2024, Arxiv, DOI [arXiv:2305.16326, 10.48550/arXiv.2305.16326, DOI 10.48550/ARXIV.2305.16326]; Chen QY, 2022, DATABASE-OXFORD, V2022, DOI 10.1093/database/baac069; Chowdhery A, 2023, J MACH LEARN RES, V24; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Dettmers T., 2024, Advances in Neural Information Processing Systems, V36; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dogan RI, 2014, J BIOMED INFORM, V47, P1, DOI 10.1016/j.jbi.2013.12.006; Fries J., 2022, Advances in Neural Information Processing Systems, V35, P25792; Han TY, 2023, Arxiv, DOI [arXiv:2304.08247, DOI 10.48550/ARXIV.2304.08247]; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Krallinger M, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/1758-2946-7-S1-S1; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee K., 2022, Long Papers, V1; Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Longpre S, 2023, Arxiv, DOI arXiv:2305.13169; Luo L, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac282; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; OpenAI, 2022, OPENAI INTR CHATGPT; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sun T., 2023, Moss: Training conversational language models from synthetic data; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tian SB, 2024, BRIEF BIOINFORM, V25, DOI 10.1093/bib/bbad493; Tian YH, 2023, Arxiv, DOI arXiv:2311.06025; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang GY, 2023, Arxiv, DOI [arXiv:2306.09968, 10.48550/arXiv.2306.09968]; Wang HC, 2023, Arxiv, DOI [arXiv:2304.06975, DOI 10.48550/ARXIV.2304.06975]; Wang YB, 2023, Arxiv, DOI arXiv:2309.02233; Wei CH, 2015, BIOMED RES INT-UK, V2015, DOI 10.1155/2015/918710; Wei CH, 2013, BIOINFORMATICS, V29, P1433, DOI 10.1093/bioinformatics/btt156; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xiong HL, 2023, Arxiv, DOI arXiv:2304.01097; Yang SH, 2023, Arxiv, DOI arXiv:2308.03549; Zeng A., 2022, 11 INT C LEARN REPR; Zhang HB, 2023, Arxiv, DOI arXiv:2305.15075; Zhang N., 2022, Long Papers, V1; Zhou WX, 2024, Arxiv, DOI arXiv:2308.03279; Zhu W, 2023, Arxiv, DOI arXiv:2310.14151	51	0	0	49	49	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 FEB 29	2024										10.1093/jamia/ocae037	http://dx.doi.org/10.1093/jamia/ocae037		FEB 2024	10	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	KD6G1	38422367	Green Submitted			2024-07-03	WOS:001178054000001
J	Cappelli, O; Aliberti, M; Praino, R				Cappelli, Ottorino; Aliberti, Marco; Praino, Rodrigo			The 'Implicit Intelligence' of artificial intelligence. Investigating the potential of large language models in social science research	POLITICAL RESEARCH EXCHANGE			English	Article						Artificial intelligence; political science research; large language models; space policy; space power		Researchers in 'hard' science disciplines are exploring the transformative potential of Artificial Intelligence (AI) for advancing research in their fields. Their colleagues in 'soft' science, however, have produced thus far a limited number of articles on this subject. This paper addresses this gap. Our main hypothesis is that existing Artificial Intelligence Large Language Models (LLMs) can closely align with human expert assessments in specialized social science surveys. To test this, we compare data from a multi-country expert survey with those collected from the two powerful LLMs created by OpenAI and Google. The statistical difference between the two sets of data is minimal in most cases, supporting our hypothesis, albeit with certain limitations and within specific parameters. The tested language models demonstrate domain-agnostic algorithmic accuracy, indicating an inherent ability to incorporate human knowledge and independently replicate human judgment across various subfields without specific training. We refer to this property as the 'implicit intelligence' of Artificial Intelligence, representing a highly promising advancement for social science research.	[Cappelli, Ottorino] Univ Napoli Orientale, Dipartimento Sci Sociali, Naples, Italy; [Aliberti, Marco] European Space Policy Inst, Vienna, Austria; [Aliberti, Marco; Praino, Rodrigo] Flinders Univ S Australia, Jeff Bleich Ctr Democracy & Disrupt Technol, Adelaide, SA, Australia; [Praino, Rodrigo] Flinders Univ S Australia, Coll Business Govt & Law, GPOB 2100, Adelaide, SA 5001, Australia	University of Naples L'Orientale; Flinders University South Australia; Flinders University South Australia	Praino, R (corresponding author), Flinders Univ S Australia, Coll Business Govt & Law, GPOB 2100, Adelaide, SA 5001, Australia.	rodrigo.praino@flinders.edu.au			Department of Defence, Australian Government10.13039/501100001029; Australian Government	Department of Defence, Australian Government10.13039/501100001029; Australian Government(Australian Government)	This research was supported by the Australian Government through a grant by Defence. The views expressed herein are those of the authors and are not necessarily those of the Australian Government or Defence	Acar O. A., 2023, AI Prompt Engineering Isn't the Future; Aher G, 2022, Arxiv, DOI arXiv:2208.10264; Aliberti M., 2023, Power, State and Space. Conceptualising; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bianchini S, 2022, RES POLICY, V51, DOI 10.1016/j.respol.2022.104604; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; De Paoli S, 2023, Arxiv, DOI [arXiv:2305.13014, 10.48550/arXiv.2305.13014, DOI 10.48550/ARXIV.2305.13014]; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Edwards B., 2023, Art Technica; Hain D, 2023, SCIENTOMETRICS, V128, P1465, DOI 10.1007/s11192-022-04628-8; Hwang E. J., 2023, arXiv; Kim J, 2024, Arxiv, DOI arXiv:2305.09620; Liedtke M., 2024, Tech XploreFebruary 8; Park P.S., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2302.07267, 10.48550/arXiv.2302.07267]; Rytting CM, 2023, Arxiv, DOI arXiv:2306.02177; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]	19	0	0	2	2	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND		2474-736X		POLIT RES EXCHANGE	Polit. Res. Exch.	DEC 31	2024	6	1							2351794	10.1080/2474736X.2024.2351794	http://dx.doi.org/10.1080/2474736X.2024.2351794			20	Political Science	Emerging Sources Citation Index (ESCI)	Government & Law	PZ4B5		gold			2024-07-03	WOS:001217875900001
J	Pool, J; Indulska, M; Sadiq, S				Pool, Javad; Indulska, Marta; Sadiq, Shazia			Large language models and generative AI in telehealth: a responsible use lens	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Review; Early Access						telehealth; artificial intelligence; large language models; ChatGPT; responsible use	HEALTH-CARE; TRUST; IMPACT	Objective This scoping review aims to assess the current research landscape of the application and use of large language models (LLMs) and generative Artificial Intelligence (AI), through tools such as ChatGPT in telehealth. Additionally, the review seeks to identify key areas for future research, with a particular focus on AI ethics considerations for responsible use and ensuring trustworthy AI.Materials and Methods Following the scoping review methodological framework, a search strategy was conducted across 6 databases. To structure our review, we employed AI ethics guidelines and principles, constructing a concept matrix for investigating the responsible use of AI in telehealth. Using the concept matrix in our review enabled the identification of gaps in the literature and informed future research directions.Results Twenty studies were included in the review. Among the included studies, 5 were empirical, and 15 were reviews and perspectives focusing on different telehealth applications and healthcare contexts. Benefit and reliability concepts were frequently discussed in these studies. Privacy, security, and accountability were peripheral themes, with transparency, explainability, human agency, and contestability lacking conceptual or empirical exploration.Conclusion The findings emphasized the potential of LLMs, especially ChatGPT, in telehealth. They provide insights into understanding the use of LLMs, enhancing telehealth services, and taking ethical considerations into account. By proposing three future research directions with a focus on responsible use, this review further contributes to the advancement of this emerging phenomenon of healthcare AI.	[Pool, Javad; Indulska, Marta; Sadiq, Shazia] Univ Queensland, ARC Ind Transformat Training Ctr Informat Resilien, Brisbane 4072, Australia; [Pool, Javad; Sadiq, Shazia] Univ Queensland, Sch Elect Engn & Comp Sci, Brisbane 4072, Australia; [Indulska, Marta] Univ Queensland, Business Sch, Brisbane 4072, Australia; [Pool, Javad] Univ Queensland, ARC Ind Transformat Training Ctr Informat Resilien, Bldg 50,St Lucia, Brisbane, Qld 4072, Australia	University of Queensland; University of Queensland; University of Queensland; University of Queensland	Pool, J (corresponding author), Univ Queensland, ARC Ind Transformat Training Ctr Informat Resilien, Bldg 50,St Lucia, Brisbane, Qld 4072, Australia.	j.pool@uq.edu.au	Sadiq, Shazia/C-8593-2016	Sadiq, Shazia/0000-0001-6739-4145	ARC Industrial Transformation Training Centre for Information Resilience [IC200100022]	ARC Industrial Transformation Training Centre for Information Resilience(Australian Research Council)	This research was partially supported by the ARC Industrial Transformation Training Centre for Information Resilience(project number: IC200100022)	Agarwal R, 2023, HEALTH POLICY TECHN, V12, DOI 10.1016/j.hlpt.2022.100702; Ahmad RW, 2021, INT J MED INFORM, V148, DOI 10.1016/j.ijmedinf.2021.104399; Ahmed SK, 2023, HEALTH SCI REP-US, V6, DOI 10.1002/hsr2.1684; Alanzi TM, 2023, J MULTIDISCIP HEALTH, V16, P2309, DOI 10.2147/JMDH.S419847; Almeida A, 2023, STOCHASTICS, V95, P906, DOI 10.1080/17442508.2023.2176231; Alofi ES, 2023, J Namib Stud, V26, P65, DOI [10.59670/jns.v35i.4253, DOI 10.59670/JNS.V35I.4253]; Arksey H., 2005, INT J SOC RES METHOD, V8, P19, DOI [10.1080/1364557032000119616, DOI 10.1080/1364557032000119616]; Attwooll J., 2023, Secondary 'Extremely unwise': Warning over use of ChatGPT for medical notes; Australian Government, 2019, Australia's AI Ethics Principles; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barki H, 2007, INFORM SYST RES, V18, P173, DOI 10.1287/isre.1070.0122; Baumann J., 2023, ChatGPT poses new regulatory questions for FDA, medical industry; Bawany NZ, 2022, IEEE ACCESS, V10, P36505, DOI 10.1109/ACCESS.2022.3161944; Bublitz FM, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16203847; Burton-Jones A, 2017, INFORM SYST RES, V28, P468, DOI 10.1287/isre.2017.0702; Burton-Jones A, 2013, INFORM SYST RES, V24, P632, DOI 10.1287/isre.1120.0444; Buus N, 2022, J ADV NURS, V78, P2304, DOI 10.1111/jan.15265; Cartolovni A, 2022, INT J MED INFORM, V161, DOI 10.1016/j.ijmedinf.2022.104738; Cheng KM, 2023, ANN BIOMED ENG, V51, P1130, DOI 10.1007/s10439-023-03203-3; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Chou D., 2023, AI Excites Healthcare, Yet It Urgently Needs Regulations; Cloesmeijer ME, 2024, BRIT J CLIN PHARMACO, V90, P360, DOI 10.1111/bcp.15895; Cockrell HC, 2022, J PEDIATR SURG, V57, P865, DOI 10.1016/j.jpedsurg.2022.06.023; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Cutillo CM, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0254-2; Czerniak K, 2023, J AM MED INFORM ASSN, V30, P752, DOI 10.1093/jamia/ocad005; Datta S., 2023, Journal of the American Medical Informatics Association, V31, P375; Díaz-Rodríguez N, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101896; Ding H, 2024, J AM MED INFORM ASSN, V31, P746, DOI 10.1093/jamia/ocad222; Diprose WK, 2020, J AM MED INFORM ASSN, V27, P592, DOI 10.1093/jamia/ocz229; Dolata M, 2022, INFORM SYST J, V32, P754, DOI 10.1111/isj.12370; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Faggioli G, 2023, Arxiv, DOI [arXiv:2304.09161, 10.48550/arXiv.2304.09161]; Ferryman K, 2023, NEW ENGL J MED, V389, P833, DOI 10.1056/NEJMra2214964; Fui-Hoon Nah F, 2023, J. Inf. Technol. Case Appl. Res, V25, P277, DOI [DOI 10.1080/15228053.2023.2233814, 10.1080/15228053.2023.2233814]; High-Level Expert Group on Artificial Intelligence, 2019, Ethics Guidelines for Trustworthy AI; Holmner Å, 2012, GLOBAL HEALTH ACTION, V5, P1, DOI 10.3402/gha.v5i0.18428; Hsieh PJ, 2015, INT J MED INFORM, V84, P1, DOI 10.1016/j.ijmedinf.2014.08.008; Huang JAT, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36100; Jeong Seung Won, 2023, 2023 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT & NCON), P348, DOI 10.1109/ECTIDAMTNCON57770.2023.10139365; Jo E, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581503; Kanter GP, 2023, JAMA-J AM MED ASSOC, V330, P311, DOI 10.1001/jama.2023.9618; Kaplan B, 2020, INT J MED INFORM, V143, DOI 10.1016/j.ijmedinf.2020.104239; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kotlarsky J, 2023, J ASSOC INF SYST, V24, P936, DOI 10.17705/1jais.00825; Lahat A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231155520; Lawson McLean A., J Telemed Telecare, p1357633X231205060; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li ZH, 2023, NAT MACH INTELL, V5, P559, DOI 10.1038/s42256-023-00672-y; Liu CF, 2022, INT J MED INFORM, V168, DOI 10.1016/j.ijmedinf.2022.104884; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu PY, 2023, J AM MED INFORM ASSN, V30, P1573, DOI 10.1093/jamia/ocad111; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Lokmic-Tomkins Z, 2022, J AM MED INFORM ASSN, V29, P2128, DOI 10.1093/jamia/ocac196; Lyons H., 2021, arXiv; Marin HF, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105150; Marks M, 2023, JAMA-J AM MED ASSOC, V330, P309, DOI 10.1001/jama.2023.9458; McKnight DH, 2002, J STRATEGIC INF SYST, V11, P297, DOI 10.1016/S0963-8687(02)00020-3; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/52865; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Mokander J., 2023, AI & Ethics; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Morath B, 2023, EUR J HOSP PHARM, DOI 10.1136/ejhpharm-2023-003750; Ploug T, 2020, ARTIF INTELL MED, V107, DOI 10.1016/j.artmed.2020.101901; Prazeres F, 2023, RURAL REMOTE HEALTH, V23, DOI 10.22605/RRH8445; Purohit Amy, 2021, Future Healthc J, V8, pe85, DOI 10.7861/fhj.2020-0080; R M. Thinking about the security of AI systems, 2023, Secondary Thinking about the security of AI systems; Rahimi-Ardabili H, 2022, J AM MED INFORM ASSN, V29, P2140, DOI 10.1093/jamia/ocac134; Reddy S, 2020, J AM MED INFORM ASSN, V27, P491, DOI 10.1093/jamia/ocz192; Röösli E, 2021, J AM MED INFORM ASSN, V28, P190, DOI 10.1093/jamia/ocaa210; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sand M, 2022, BIOETHICS, V36, P162, DOI 10.1111/bioe.12887; Sarma G., 2023, Indian J Otolaryngol Head Neck Surg, P1; Shin D, 2021, INT J HUM-COMPUT ST, V146, DOI 10.1016/j.ijhcs.2020.102551; Sillcox R, 2023, OBES SURG, V33, P2527, DOI 10.1007/s11695-023-06721-0; Singhal K, 2023, NATURE, DOI 10.1038/s41586-023-06455-0; Snoswell CL, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231169055; Srivastav S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41435; Srivastava M, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2459, DOI 10.1145/3292500.3330664; Srivastava SC, 2018, MIS QUART, V42, P779, DOI 10.25300/MISQ/2018/11914; Subramanian HV, 2024, ARTIF INTELL MED, V149, DOI 10.1016/j.artmed.2024.102780; Susanto AP, 2023, J AM MED INFORM ASSN, V30, P2050, DOI 10.1093/jamia/ocad180; Terranova C, 2024, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1337335; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tian SB, 2023, Arxiv, DOI [arXiv:2306.10070, 10.48550/arXiv.2306.10070]; Vahedifard F, 2023, Arxiv, DOI arXiv:2311.09131; Walling AM, 2023, J AM MED INFORM ASSN, V30, P1333, DOI 10.1093/jamia/ocad086; Wang CL, 2021, INT J INFORM MANAGE, V61, DOI 10.1016/j.ijinfomgt.2021.102401; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wang X., 2023, The Lancet Regional Health-Western Pacific, P41; Wearn OR, 2019, NAT MACH INTELL, V1, P72, DOI 10.1038/s42256-019-0022-7; Webster J, 2002, MIS QUART, V26, pXIII; Whiles BB, 2023, UROLOGY, V180, P278, DOI 10.1016/j.urology.2023.07.010; World Health Organization (WHO), 2021, Ethics and Governance of Artificial Intelligence for Health; Wu X., 2023, J Inf Intell; Wynn D, 2012, MIS QUART, V36, P787; Yang J., 2023, Patterns (N Y), V5, P100887; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang Z, 2023, arXiv, DOI 10.48550/arXiv.2309.09357; Zhu Liming., 2022, Humanity Driven AI: Productivity, Well-being, Sustainability and Partnership, P15, DOI DOI 10.1007/978-3-030-72188-6_2	101	0	0	24	24	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 MAR 4	2024										10.1093/jamia/ocae035	http://dx.doi.org/10.1093/jamia/ocae035		MAR 2024	12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	KE6R9	38441296	hybrid			2024-07-03	WOS:001178326200001
C	Chen, Z; Jiang, ZY; Yang, F; He, ZU; Hou, YP; Cho, E; McAuley, J; Galstyan, A; Hu, XH			ACM	Chen, Zheng; Jiang, Ziyan; Yang, Fan; He, Zhankui; Hou, Yupeng; Cho, Eunah; McAuley, Julian; Galstyan, Aram; Hu, Xiaohua			The First Workshop on Personalized Generative AI @ CIKM 2023: Personalization Meets Large Language Models	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Personalization; Large Language Models; Generative AI		The First Workshop on Personalized Generative AI(1) aims to be a cornerstone event fostering innovation and collaboration in the dynamic field of personalized AI. Leveraging the potent capabilities of Large Language Models (LLMs) to enhance user experiences with tailored responses and recommendations, the workshop is designed to address a range of pressing challenges including knowledge gap bridging, hallucination mitigation, and efficiency optimization in handling extensive user profiles. As a nexus for academics and industry professionals, the event promises rich discussions on a plethora of topics such as the development and fine-tuning of foundational models, strategies for multi-modal personalization, and the imperative ethical and privacy considerations in LLM deployment. Through a curated series of keynote speeches, insightful panel discussions, and hands-on sessions, the workshop aspires to be a catalyst in the development of more precise, contextually relevant, and user-centric AI systems. It aims to foster a landscape where generative AI systems are not only responsive but also anticipatory of individual user needs, marking a significant stride in personalized experiences.	[Chen, Zheng; Jiang, Ziyan; Yang, Fan; Cho, Eunah; Galstyan, Aram] Amazon Alexa, Seattle, WA 98121 USA; [He, Zhankui; Hou, Yupeng; McAuley, Julian] Univ Calif San Diego, San Diego, CA USA; [Hu, Xiaohua] Drexel Univ, Philadelphia, PA USA	University of California System; University of California San Diego; Drexel University	Chen, Z (corresponding author), Amazon Alexa, Seattle, WA 98121 USA.	zgchen@amazon.com; ziyjiang@amazon.com; ffanyang@amazon.com; zhh004@ucsd.edu; yphou@ucsd.edu; eunahch@amazon.com; j.yang-3@tudelft.nl; argalsty@amazon.com; xh29@drexel.edu		McAuley, Julian/0000-0003-0955-7588; Hou, Yupeng/0000-0002-0747-8010				Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Bao Keqin, 2023, ARXIV230500447; Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carter Nicole, 2021, GENERATIVE ARTIFICIA; Chang S, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P175, DOI 10.1145/2959100.2959153; Chen Zheng, 2023, ARXIV230507622; Chen Zheng, 2023, ARXIV230514449CSAI; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cui Zeyu, 2022, ARXIV220508084; Denny JC, 2015, J BIOMED INFORM, V56, P292, DOI 10.1016/j.jbi.2015.06.004; Dettmers T., 2023, arXiv preprint arXiv:2305.14314; Gao Yunfan, 2023, ARXIV230314524; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Ghorab MR, 2013, USER MODEL USER-ADAP, V23, P381, DOI 10.1007/s11257-012-9124-1; Hada DV, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P81, DOI 10.1145/3404835.3462939; He Zhankui, 2023, LARGE LANGUAGE MODEL; Hou Yupeng, 2023, LARGE LANGUAGE MODEL; Hu Chenxu, 2023, CHATDB AUGMENTING LL; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005; Johansson P., 2003, Proceedings of the 3rd UM Workshop "Personalization in Future TV", P27; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kunaver M, 2017, KNOWL-BASED SYST, V123, P154, DOI 10.1016/j.knosys.2017.02.009; Labutov I, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P145; Li Jinming, 2023, ARXIV230403879; Li L, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3580488; Li Xiang Lisa, 2021, arXiv; Lightman Hunter, 2023, ARXIV230520050; Liu Hao, 2023, ARXIV230202676; Liu JJ, 2020, J ASSOC INF SCI TECH, V71, P349, DOI 10.1002/asi.24234; Liu Junling, 2023, ARXIV230410149; Lu X., 2022, Advances in Neural Information Processing Systems (NeurIPS); Mylonas P, 2008, KNOWL ENG REV, V23, P73, DOI 10.1017/S0269888907001282; Naresh Niranjan Uma, 2022, P 2022 C EMP METH NA, P90; Park JS, 2023, ARXIV230403442; Patil Shishir G, 2023, ARXIV230515334; Safdari Mustafa, 2023, ARXIV230700184; Sallam M, 2023, medRxiv; Schick Timo, 2023, ARXIV230204761; Shen Yongliang, 2023, arXiv; Silva AD, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113193; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron Hugo, 2023, ARXIV230213971; Wang Lei, 2023, ARXIV230403153; Wang Lei, 2023, ARXIV230602552; Wang Yancheng, 2023, ARXIV230814296; Xu Zhaozhuo, 2023, ARXIV230511186; Xue GR, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462203; Yan An, 2022, ARXIV220700422; Yang Hongyang, 2023, ARXIV230606031; Yao Shunyu, 2022, ARXIV221003629; Zadrozny W, 2000, COMMUN ACM, V43, P116, DOI 10.1145/345124.345164; Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029; Zhang YJ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7811; Ziems Caleb, 2023, ARXIV230503514CSCL	56	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5267	5270		10.1145/3583780.3615314	http://dx.doi.org/10.1145/3583780.3615314			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		hybrid			2024-07-03	WOS:001161549505066
J	Suri, G; Slater, LR; Ziaee, A; Nguyen, M				Suri, Gaurav; Slater, Lily R.; Ziaee, Ali; Nguyen, Morgan			Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5	JOURNAL OF EXPERIMENTAL PSYCHOLOGY-GENERAL			English	Article; Early Access						natural language processing; Large Language Models; ChatGPT; heuristics	PHYSICIANS; JUDGMENT; CHOICE	A Large Language Model (LLM) is an artificial intelligence system trained on vast amounts of natural language data, enabling it to generate human-like responses to written or spoken language input. Generative Pre-Trained Transformer (GPT)-3.5 is an example of an LLM that supports a conversational agent called ChatGPT. In this work, we used a series of novel prompts to determine whether ChatGPT shows heuristics and other context-sensitive responses. We also tested the same prompts on human participants. Across four studies, we found that ChatGPT was influenced by random anchors in making estimates (anchoring, Study 1); it judged the likelihood of two events occurring together to be higher than the likelihood of either event occurring alone, and it was influenced by anecdotal information (representativeness and availability heuristic, Study 2); it found an item to be more efficacious when its features were presented positively rather than negatively-even though both presentations contained statistically equivalent information (framing effect, Study 3); and it valued an owned item more than a newly found item even though the two items were objectively identical (endowment effect, Study 4). In each study, human participants showed similar effects. Heuristics and context-sensitive responses in humans are thought to be driven by cognitive and affective processes such as loss aversion and effort reduction. The fact that an LLM-which lacks these processes-also shows such responses invites consideration of the possibility that language is sufficiently rich to carry these effects and may play a role in generating these effects in humans.	[Suri, Gaurav; Slater, Lily R.; Ziaee, Ali; Nguyen, Morgan] San Francisco State Univ, Dept Psychol, Mind Brain & Behav, 1600 Holloway Ave, San Francisco, CA 94132 USA	California State University System; San Francisco State University	Suri, G (corresponding author), San Francisco State Univ, Dept Psychol, Mind Brain & Behav, 1600 Holloway Ave, San Francisco, CA 94132 USA.	suri@sfsu.edu	Ziaee, Ali/ISB-8332-2023					Ariely D, 2003, Q J ECON, V118, P73, DOI 10.1162/00335530360535153; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Buhrmester M, 2011, PERSPECT PSYCHOL SCI, V6, P3, DOI 10.1177/1745691610393980; Bui TC, 2015, PSYCHOL REP, V117, P508, DOI 10.2466/13.PR0.117c20z0; CHOMSKY N, 1995, MIND, V104, P1, DOI 10.1093/mind/104.413.1; CHRISTENSEN C, 1995, J BEHAV DECIS MAKING, V8, P169, DOI 10.1002/bdm.3960080303; Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; Cornelissen JP, 2014, ACAD MANAG ANN, V8, P181, DOI 10.1080/19416520.2014.875669; Elman JL, 2004, TRENDS COGN SCI, V8, P301, DOI 10.1016/j.tics.2004.05.003; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Epley N, 2001, PSYCHOL SCI, V12, P391, DOI 10.1111/1467-9280.00372; Frankle J., 2018, arXiv; Fudenberg D, 2012, AM ECON J-MICROECON, V4, P131, DOI 10.1257/mic.4.2.131; Galinsky AD, 2001, J PERS SOC PSYCHOL, V81, P657, DOI 10.1037//0022-3514.81.4.657; Gigerenzer G, 2018, REV BEHAV ECON, V5, P303, DOI 10.1561/105.00000092; Gilovich T., 2002, Heuristics and Biases: The Psychology of Intuitive Judgment; Gong JJ, 2013, PSYCHOL HEALTH MED, V18, P645, DOI 10.1080/13548506.2013.766352; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; KAHNEMAN D, 1984, AM PSYCHOL, V39, P341, DOI 10.1037/0003-066X.39.4.341; KAHNEMAN D, 1990, J POLIT ECON, V98, P1325, DOI 10.1086/261737; KAHNEMAN D, 1982, SCI AM, V246, P160, DOI 10.1038/scientificamerican0182-160; Kahneman D., 2011, THINKING FAST SLOW; Kahneman D., 1981, The simulation heuristic (TR-5); Keysar B, 2012, PSYCHOL SCI, V23, P661, DOI 10.1177/0956797611432178; Kühberger A, 2010, J BEHAV DECIS MAKING, V23, P314, DOI 10.1002/bdm.656; Louwerse MM, 2011, TOP COGN SCI, V3, P273, DOI 10.1111/j.1756-8765.2010.01106.x; Lupyan G., 2022, As a cognitive scientist (trained in the connectionism), I find Large Language Models (LLMs) not just scientifically relevant, but critical to the future of cog sci; Lupyan G, 2007, PSYCHOL SCI, V18, P1077, DOI 10.1111/j.1467-9280.2007.02028.x; Lupyan G, 2016, LANG LEARN, V66, P516, DOI 10.1111/lang.12155; McClelland JL, 2010, TOP COGN SCI, V2, P751, DOI 10.1111/j.1756-8765.2010.01116.x; McKenzie CRM, 2003, PSYCHON B REV, V10, P596, DOI 10.3758/BF03196520; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mitchell M., 2023, On analogy-making in large language models; Morewedge CK, 2009, J EXP SOC PSYCHOL, V45, P947, DOI 10.1016/j.jesp.2009.05.014; PINKER S, 1994, J COGNITIVE NEUROSCI, V6, P92, DOI 10.1162/jocn.1994.6.1.92; Rumelhart D. E., 1979, METAPHOR THOUGHT, P71; Rumelhart D. E., 1986, Foundation, V1; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sedlmeier P, 1998, J EXP PSYCHOL LEARN, V24, P754, DOI 10.1037/0278-7393.24.3.754; Shah AK, 2008, PSYCHOL BULL, V134, P207, DOI 10.1037/0033-2909.134.2.207; Suri G., 2023, Caravan Magazine; Suri G, 2020, PSYCHOL REV, V127, P153, DOI 10.1037/rev0000164; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Thomas AK, 2012, J GERONTOL B-PSYCHOL, V67, P139, DOI 10.1093/geronb/gbr076; Todd P.M., 2012, ECOLOGICAL RATIONALI; Tomasello M, 2009, CAMB HB LANG LINGUIS, P69; TVERSKY A, 1983, PSYCHOL REV, V90, P293, DOI 10.1037/0033-295X.90.4.293; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; van Dijk E, 1998, J ECON PSYCHOL, V19, P485, DOI 10.1016/S0167-4870(98)00020-8; Vaswani A, 2017, ADV NEUR IN, V30; Webb T, 2023, Arxiv, DOI [arXiv:2212.09196, 10.48550/arXiv.2212.09196]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zwaan RA, 2014, TRENDS COGN SCI, V18, P229, DOI 10.1016/j.tics.2014.02.008	55	3	3	58	58	AMER PSYCHOLOGICAL ASSOC	WASHINGTON	750 FIRST ST NE, WASHINGTON, DC 20002-4242 USA	0096-3445	1939-2222		J EXP PSYCHOL GEN	J. Exp. Psychol.-Gen.	2024 FEB 8	2024										10.1037/xge0001547	http://dx.doi.org/10.1037/xge0001547		FEB 2024	11	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	HI0A3	38330366	Green Submitted			2024-07-03	WOS:001158735200001
J	Naqvi, WM; Shaikh, SZ; Mishra, GV				Naqvi, Waqar M.; Shaikh, Summaiya Zareen; Mishra, Gaurav V.			Large language models in physical therapy: time to adapt and adept	FRONTIERS IN PUBLIC HEALTH			English	Article						artificial intelligence; BioMedLM; evidence-based practice; large language models; physical therapy; physical therapy education; rehabilitation	ARTIFICIAL-INTELLIGENCE; LEARNING-MODEL	Healthcare is experiencing a transformative phase, with artificial intelligence (AI) and machine learning (ML). Physical therapists (PTs) stand on the brink of a paradigm shift in education, practice, and research. Rather than visualizing AI as a threat, it presents an opportunity to revolutionize. This paper examines how large language models (LLMs), such as ChatGPT and BioMedLM, driven by deep ML can offer human-like performance but face challenges in accuracy due to vast data in PT and rehabilitation practice. PTs can benefit by developing and training an LLM specifically for streamlining administrative tasks, connecting globally, and customizing treatments using LLMs. However, human touch and creativity remain invaluable. This paper urges PTs to engage in learning and shaping AI models by highlighting the need for ethical use and human supervision to address potential biases. Embracing AI as a contributor, and not just a user, is crucial by integrating AI, fostering collaboration for a future in which AI enriches the PT field provided data accuracy, and the challenges associated with feeding the AI model are sensitively addressed.	[Naqvi, Waqar M.] Datta Meghe Inst Higher Educ & Res, Dept Interdisciplinary Sci, Wardha, India; [Naqvi, Waqar M.] Gulf Med Univ, Coll Hlth Sci, Dept Physiotherapy, Ajman, U Arab Emirates; [Naqvi, Waqar M.] NKP Salve Inst Med Sci & Res Ctr, Nagpur, India; [Shaikh, Summaiya Zareen] SIA Coll Hlth Sci, Coll Physiotherapy, Dept Neurophysiotherapy, Thana, India; [Mishra, Gaurav V.] Datta Meghe Inst Higher Educ & Res, Dept Radiodiag, Wardha, India	Datta Meghe Institute of Higher Education & Research (Deemed to be University); Datta Meghe Institute of Higher Education & Research (Deemed to be University)	Shaikh, SZ (corresponding author), SIA Coll Hlth Sci, Coll Physiotherapy, Dept Neurophysiotherapy, Thana, India.	drzareensummaiya@gmail.com	Shaikh, Summaiya Zareen/AAU-8153-2021; Mishra, Gaurav V/AAY-5998-2020; Naqvi, Waqar M/S-5447-2016	Shaikh, Summaiya Zareen/0000-0003-3146-4337; Mishra, Gaurav V/0000-0003-4957-7479; Naqvi, Waqar M/0000-0003-4484-8225	Datta Meghe Institute of Higher Education and Research, India	Datta Meghe Institute of Higher Education and Research, India	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. The manuscript was supported by Datta Meghe Institute of Higher Education and Research, India to help fund this publication.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Bajwa Junaid, 2021, Future Healthc J, V8, pe188, DOI 10.7861/fhj.2021-0095; Beierle C, 2019, KUNSTL INTELL, V33, P5, DOI 10.1007/s13218-018-00574-x; Bhatnagar R, 2022, JAMIA OPEN, V5, DOI 10.1093/jamiaopen/ooac043; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Buchlak Quinlan D, 2022, Acta Neurochir Suppl, V134, P277, DOI 10.1007/978-3-030-85292-4_32; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chen PF, 2022, JMIR MED INF, V10, DOI 10.2196/41342; Chervenak J, 2023, FERTIL STERIL, V120, P575, DOI 10.1016/j.fertnstert.2023.05.151; Choo Yoo Jin, 2022, Brain Neurorehabil, V15, pe26, DOI 10.12786/bn.2022.15.e26; Currie G, 2023, J NUCL MED TECHNOL, V51, P255, DOI 10.2967/jnmt.123.265864; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Drum B, 2023, ACAD MED, V98, P1278, DOI 10.1097/ACM.0000000000005352; Durve I., 2019, 2019 INT C ADV COMP, DOI [10.1109/ICAC347590.2019.9036783, DOI 10.1109/ICAC347590.2019.9036783]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Glauberman Gary, 2023, Hawaii J Health Soc Welf, V82, P302; Godse S., 2021, Physiotherapy, V10, P77, DOI [10.4018/IJBCE.2021010106, DOI 10.4018/IJBCE.2021010106]; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Hatem R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.44720; Hazarika I, 2020, INT HEALTH, V12, P241, DOI 10.1093/inthealth/ihaa007; Heaton J, 2018, GENET PROGRAM EVOL M, V19, P305, DOI [DOI 10.1007/S10710-017-9314-Z, 10.1007/s10710-017-9314-z]; ICMJE News & Editorials, 2023, About us; Introducing ChatGPT, 2023, OpenAI; Irvin JA, 2022, J THORAC IMAG, V37, P162, DOI 10.1097/RTI.0000000000000622; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Jovanovic M, 2018, STUD HEALTH TECHNOL, V248, P164, DOI 10.3233/978-1-61499-858-7-164; Kanungo Jayneel, 2023, 2023 Second International Conference on Trends in Electrical, Electronics, and Computer Engineering (TEECCON), P218, DOI 10.1109/TEECCON59234.2023.10335844; Kristinsson S, 2021, HUM BRAIN MAPP, V42, P1682, DOI 10.1002/hbm.25321; Leonardi M, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191811321; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Makino M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48263-5; Melvin RL, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.872675; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/52865; Miller DD, 2018, AM J MED, V131, P129, DOI 10.1016/j.amjmed.2017.10.035; Panch T, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0155-4; Pearce J, 2023, MED EDUC, V57, P889, DOI 10.1111/medu.15092; Preiksaitis C, 2023, JMIR MED EDUC, V9, DOI 10.2196/48785; Pustina D, 2017, HUM BRAIN MAPP, V38, P5603, DOI 10.1002/hbm.23752; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ramesh AN, 2004, ANN ROY COLL SURG, V86, P334, DOI 10.1308/147870804290; Rauch A, 2008, EUR J PHYS REHAB MED, V44, P329; Rowe M, 2022, PHYSIOTHER THEOR PR, V38, P2275, DOI 10.1080/09593985.2021.1934924; Russo AG, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21782-4; Salvagno M., Can artificial intelligence help for scientific writing? Critical care; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Sim JA, 2023, ARTIF INTELL MED, V146, DOI 10.1016/j.artmed.2023.102701; Stahl CC, 2021, AM J SURG, V221, P369, DOI 10.1016/j.amjsurg.2020.11.044; Stanford CRFM, 2022, About us; Stewart J, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290642; Tack C, 2019, MUSCULOSKEL SCI PRAC, V39, P164, DOI 10.1016/j.msksp.2018.11.012; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Ullah E, 2024, DIAGN PATHOL, V19, DOI 10.1186/s13000-024-01464-7; Voytovich Leah, 2022, Acta Neurochir Suppl, V134, P207, DOI 10.1007/978-3-030-85292-4_24; Wen A, 2020, JAMIA OPEN, V3, P16, DOI 10.1093/jamiaopen/ooz072; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324	59	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-2565		FRONT PUBLIC HEALTH	Front. Public Health	MAY 24	2024	12								1364660	10.3389/fpubh.2024.1364660	http://dx.doi.org/10.3389/fpubh.2024.1364660			9	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	UM5I3	38887241	gold			2024-07-03	WOS:001248486400001
C	Liu, MXY; Sarkar, A; Negreanu, C; Zorn, B; Williams, J; Toronto, N; Gordon, AD			ACM	Liu, Michael Xieyang; Sarkar, Advait; Negreanu, Carina; Zorn, Benjamin; Williams, Jack; Toronto, Neil; Gordon, Andrew D.			"What It Wants Me To Say": Bridging the Abstraction Gap Between End-User Programmers and Code-Generating Large Language Models	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Natural Language Programming; Spreadsheets; Human-AI Interaction; Large Language Models		Code-generating large language models map natural language to code. However, only a small portion of the infinite space of naturalistic utterances is effective at guiding code generation. For non-expert end-user programmers, learning this is the challenge of abstraction matching. We examine this challenge in the specific context of data analysis in spreadsheets, in a system that maps the user's natural language query to Python code using the Codex generator, executes the code, and shows the result. We propose grounded abstraction matching, which bridges the abstraction gap by translating the code back into a systematic and predictable naturalistic utterance. In a between-subjects, think-aloud study (n=24), we compare grounded abstraction matching to an ungrounded alternative based on previously established query framing principles. We find that the grounded approach improves end-users' understanding of the scope and capabilities of the code-generating model, and the kind of language needed to use it effectively.	[Liu, Michael Xieyang] Carnegie Mellon Univ, Microsoft Res, Pittsburgh, PA 15213 USA; [Sarkar, Advait] Univ Cambridge, Microsoft Res, Cambridge, England; [Sarkar, Advait] UCL, London WC1E 6BT, England; [Negreanu, Carina; Williams, Jack; Toronto, Neil; Gordon, Andrew D.] Microsoft Res, Cambridge, England; [Zorn, Benjamin] Microsoft Res, Redmond, WA USA	Carnegie Mellon University; Microsoft; Microsoft; University of Cambridge; University of London; University College London; Microsoft; Microsoft	Liu, MXY (corresponding author), Carnegie Mellon Univ, Microsoft Res, Pittsburgh, PA 15213 USA.		Liu, Michael Xieyang/AFQ-7384-2022	Williams, Jack/0000-0003-1925-7191; Liu, Michael Xieyang/0000-0002-8246-8736				An Shengnan, 2022, ABS220303131 ARXIV; [Anonymous], 2005, CHI 05 EXTENDED ABST, DOI DOI 10.1145/1056808.1056975; Arsan Deniz, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1089, DOI 10.1145/3472749.3474808; Ashktorab Z, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300484; Bakhtin Mikhail., 2011, LIT CRITICISM, V4, P114; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; BICKERTON D, 1984, BEHAV BRAIN SCI, V7, P173, DOI 10.1017/S0140525X00044149; BICKERTON D, 1983, SCI AM, V249, P116, DOI 10.1038/scientificamerican0783-116; Bommasani Rishi, 2021, ARXIV210807258; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Campbell JL, 2013, SOCIOL METHOD RES, V42, P294, DOI 10.1177/0049124113500475; Carroll John M, 1987, Interfacing Thought: Cognitive Aspects of Human-Computer Interaction, P80; Cassano Federico, 2022, ABS220808227 ARXIV; Chalhoub G, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501833; Charmaz K., 2014, Constructing Grounded Theory, V2nd edition; Chen Mark., 2021, EVALUATING LARGE LAN, P2021, DOI [DOI 10.48550/ARXIV.2107.03374, 10.48550/ARXIV.2107.03374]; Cook William R, 2007, Proc of the third ACM SIGPLAN Conf on History of programming languages, P1; CSIKSZENTMIHALYI M, 1987, J NERV MENT DIS, V175, P526, DOI 10.1097/00005053-198709000-00004; Dijkstra Edsger W, 1979, PROGRAM CONSTRUCTION, P51; Dong HY, 2019, AAAI CONF ARTIF INTE, P69; DOURISH P, 2006, P SIGCHI C HUM FACT, P541, DOI DOI 10.1145/1124772.1124855; Elgohary Ahmed, 2021, NAACL; Endert A., 2011, 2011 IEEE Conference on Visual Analytics Science and Technology, P121, DOI 10.1109/VAST.2011.6102449; Etikan I., 2016, AM J THEORETICAL APP, V5, P1, DOI [DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.atas.20160501.1, 10.11648/j.ajtas.20160501.11]; Evtikhiev Mikhail, 2022, ABS220803133 ARXIV; Finlayson Matthew, 2022, ABS220409148 ARXIV; Fonteyn Marsha E., 1993, QUAL HEALTH RES, V3, P430, DOI [DOI 10.1177/104973239300300403, 10.1177/104973239300300403]; Green T. R. G., 1991, Empirical Studies of Programmers: Fourth Workshop, P121; Green TRG, 1996, J VISUAL LANG COMPUT, V7, P131, DOI 10.1006/jvlc.1996.0009; Gulwani S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI 10.1145/1925844.1926423; Guo Philip J, 2013, Proceedings of the 44th SIGCSE Technical Symposium on Computer Science Education, SIGCSE '13, P579, DOI [10.1145/2445196.2445368, DOI 10.1145/2445196.2445368]; Halpern Mark, 1966, P NOV 7 10 1966 FALL, P639, DOI DOI 10.1145/1464291.1464360; HART S G, 1988, P139; Head A, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P3, DOI 10.1109/VLHCC.2015.7356972; Hendrycks Dan, 2021, ABS210509938 ARXIV; Holzinger Andreas, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P55, DOI 10.1109/DISA.2018.8490530; Honovich Or, 2022, ABS220510782 ARXIV; Horvath A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502095; Hsieh J, 2018, 2018 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P305, DOI 10.1109/VLHCC.2018.8506517; Hutchins E. L., 1985, Human-Computer Interaction, V1, P311, DOI [10.1207/s15327051hci0104_2, DOI 10.1207/S15327051HCI0104_2]; Jain Naman, 2022, INT C SOFTW ENG ICSE; Jayagopal Dhanya, 2022, USER INTERFACE SOFTW; Jiang E, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503564; Joharizadeh Nima, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3382806; Khan Junaed Younus, 2022, ARXIV220902235CS, DOI [10.48550/arXiv.2209.02235, DOI 10.48550/ARXIV.2209.02235]; Khashabi Daniel, 2022, NAACL; Kim TS, 2022, CHI C HUMAN FACTORS, DOI [DOI 10.1145/3491102.3501931, 10.1145/3491102.3501931]; Ko AJ, 2004, 2004 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN CENTRIC COMPUTING: PROCEEDINGS, P199; Ko AJ, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922658; Kocielnik R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300641; Kulesza T., 2015, P 20 INT C INT US IN, P126, DOI DOI 10.1145/2678025.2701399; Kuznia Kirby, 2022, ABS220308597 ARXIV; Lahiri Shuvendu K., 2022, ABS220805950 ARXIV; Lampinen Andrew Kyle, 2022, ABS220402329 ARXIV; Lau Sam, 2022, PANDAS TUTOR VISUALI; Lau T, 2009, AI MAG, V30, P65, DOI 10.1609/aimag.v30i4.2262; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lewis JR, 2018, INT J HUM-COMPUT INT, V34, P577, DOI 10.1080/10447318.2018.1455307; Li TJJ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P577, DOI 10.1145/3332165.3347899; Li TJJ, 2018, 2018 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P105, DOI 10.1109/VLHCC.2018.8506506; Li TJJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6038, DOI 10.1145/3025453.3025483; Li Yujia, 2022, COMPETITION LEVEL CO, DOI [10.48550/ARXIV.2203.07814, DOI 10.48550/ARXIV.2203.07814]; Li Yuntao, 2020, EMNLP; Li Zongjie, 2022, ABS220808289 ARXIV; Lim BY, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P195; Liu Michael Xieyang, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449240; Liu MXY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501968; Liu MX, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P67, DOI 10.1145/3332165.3347908; Liu Pengfei, 2021, ABS210713586 ARXIV; Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; McDonald Nora, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359174; McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243; Mishra S., 2021, ARXIV210907830; Mo Lingbo, 2022, ABS211008345 ARXIV; Mu J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312975; Narayan Avanika, 2022, ABS220509911 ARXIV; Narayan Avanika, 2022, ABS220509911 ARXIV; Necesal P, 2012, LECT NOTES ENG COMP, P271; Nijkamp Erik, 2022, ABS220313474 ARXIV; Özcan F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2629, DOI 10.1145/3318464.3383128; Patel Pruthvi, 2022, ABS220512538 ARXIV; Ragavan SS, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P345, DOI 10.1145/3490099.3511161; Ragavan Sruti Srinivasa, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445634; Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779; RIEMAN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P321; Salda├a┬▒a J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004; SAMMET JE, 1966, COMMUN ACM, V9, P228, DOI 10.1145/365230.365274; Sarkar A, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382807; Sarkar A, 2016, S VIS LANG HUM CEN C, P78, DOI 10.1109/VLHCC.2016.7739668; Sarkar A, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P159, DOI 10.1109/VLHCC.2015.7357211; Sarkar A, 2014, S VIS LANG HUM CEN C, P53, DOI 10.1109/VLHCC.2014.6883022; Sarkar Advait, 2022, CEUR WORKSHOP P, V3124, P192; Sarkar Advait, 2022, 2022 IEEE S VIS LANG, P1; Sarkar Advait, 2022, ARXIV220806213CS, DOI [10.48550/arXiv.2208.06213, DOI 10.48550/ARXIV.2208.06213]; Sarkar Advait, 2015, INTERACTION UNCERTAI, DOI [DOI 10.2312/EUROVISSHORT.20151138, 10.2312/eurovisshort.20151138]; Sarkar Advait, 2018, TECHNICAL REPORT; Sarkar Advait, 2018, P 29 ANN WORKSHOP PS, P28; Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030; Scaffidi C, 2005, 2005 IEEE SYMPOSIUM ON VISUAL LANGUAGE AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P207, DOI 10.1109/VLHCC.2005.34; Schlegel V, 2019, PROCEEDINGS OF IUI 2019, P30, DOI 10.1145/3301275.3302267; Setlur V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501972; Shrivastava Disha, 2022, ABS220612839 ARXIV; Sontakke Ankita Nandkishor, 2022, DEEP LEARN COD WORKS; Stolterman E, 2008, INT J DES, V2, P55; Tennant Harry R., 1983, P SIGCHI C HUM FACT, P154, DOI DOI 10.1145/800045.801601; Thoppilan R., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2201.08239; Trummer Immanuel, 2022, ABS220408941 ARXIV; Vaismoradi M, 2013, NURS HEALTH SCI, V15, P398, DOI 10.1111/nhs.12048; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vaswani A, 2017, ADV NEUR IN, V30; Wang Chaozheng, 2022, ABS220711680 ARXIV; Wang Liwen, 2022, ABS220303903 ARXIV; Wang SI, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P929, DOI 10.18653/v1/P17-1086; Wang Zhiruo, 2022, ABS220308388 ARXIV; Wei Jason, 2022, ABS220111903 ARXIV; Wei Jason, 2022, arXiv:2206.07682; Weisz JD, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P402, DOI 10.1145/3397481.3450656; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Wu Tongshuang, 2022, 2022 CHI C HUM FACT, P1, DOI 10.1145/3491101.3519729; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569; Yao Ziyu, 2019, EMNLP; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Yu Tao, 2019, ARXIV180908887CS, DOI [10. 48550/arXiv.1809.08887, DOI 10.48550/ARXIV.1809.08887]; Zhang X, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P691, DOI 10.1145/3126594.3126663; Zhu Ming, 2022, ABS220608474 ARXIV	128	2	2	0	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580817	http://dx.doi.org/10.1145/3544548.3580817			31	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Submitted			2024-07-03	WOS:001037809502054
J	Fang, X; Che, SK; Mao, MJ; Zhang, HZ; Zhao, M; Zhao, XH				Fang, Xiao; Che, Shangkun; Mao, Minjia; Zhang, Hongzhe; Zhao, Ming; Zhao, Xiaohang			Bias of AI-generated content: an examination of news produced by large language models	SCIENTIFIC REPORTS			English	Article						AI-generated content (AIGC); Large language model (LLM); Generative AI; ChatGPT; Bias; Gender bias; Racial bias; Prompt	GENDER BIAS	Large language models (LLMs) have the potential to transform our lives and work through the content they generate, known as AI-Generated Content (AIGC). To harness this transformation, we need to understand the limitations of LLMs. Here, we investigate the bias of AIGC produced by seven representative LLMs, including ChatGPT and LLaMA. We collect news articles from The New York Times and Reuters, both known for their dedication to provide unbiased news. We then apply each examined LLM to generate news content with headlines of these news articles as prompts, and evaluate the gender and racial biases of the AIGC produced by the LLM by comparing the AIGC and the original news articles. We further analyze the gender bias of each LLM under biased prompts by adding gender-biased messages to prompts constructed from these news headlines. Our study reveals that the AIGC produced by each examined LLM demonstrates substantial gender and racial biases. Moreover, the AIGC generated by each LLM exhibits notable discrimination against females and individuals of the Black race. Among the LLMs, the AIGC generated by ChatGPT demonstrates the lowest level of bias, and ChatGPT is the sole model capable of declining content generation when provided with biased prompts.	[Fang, Xiao; Mao, Minjia; Zhao, Ming] Univ Delaware, Newark, NJ 19716 USA; [Che, Shangkun] Tsinghua Univ, Beijing, Peoples R China; [Zhang, Hongzhe] Chinese Univ Hong Kong, Shenzhen, Peoples R China; [Zhao, Xiaohang] Shanghai Univ Finance & Econ, Shanghai, Peoples R China	University of Delaware; Tsinghua University; The Chinese University of Hong Kong, Shenzhen; Shanghai University of Finance & Economics	Fang, X (corresponding author), Univ Delaware, Newark, NJ 19716 USA.; Che, SK (corresponding author), Tsinghua Univ, Beijing, Peoples R China.	xfang@udel.edu; csk19@mails.tsinghua.edu.cn						Agresti A., 2012, An introduction to categorical data analysis; Baker RS, 2022, INT J ARTIF INTELL E, V32, P1052, DOI 10.1007/s40593-021-00285-9; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Beukeboom CJ, 2019, REV COMMUN RES, V7, P1, DOI 10.12840/issn.2255-4165.017; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bravo G, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-08250-2; Centola D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26905-5; Churchill R, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3507900; Davenport T. H., 2022, Harvard Business Review; Friedman B, 1996, ACM T INFORM SYST, V14, P330, DOI 10.1145/230538.230561; Galos DR, 2023, SCI ADV, V9, DOI 10.1126/sciadv.ade7979; Gonen H, 2019, Arxiv, DOI arXiv:1903.03862; Guglielmi G, 2018, NATURE, V554, P14, DOI 10.1038/d41586-018-01212-0; Hamborg F, 2019, INT J DIGIT LIBRARIE, V20, P391, DOI 10.1007/s00799-018-0261-y; Hannabuss S., 1995, Libr. Manag.; Hanu L., 2021, Sci. Am., V8; Huang PS, 2020, Arxiv, DOI arXiv:1911.03064; Kirk HR, 2021, ADV NEUR IN, V34; Leavy S., 2020, BIAS SOCIAL ASPECTS, P12, DOI DOI 10.1007/978-3-030-52485-2_2; Leppänen L, 2020, MEDIA COMMUN-LISBON, V8, P39, DOI 10.17645/mac.v8i3.3022; Levina E, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P251, DOI 10.1109/ICCV.2001.937632; Li F.-F., 2023, Stanf. HAI Rep.; Liang PP, 2021, PR MACH LEARN RES, V139; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Mahrukh R, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-33734-7; Munoz-Ortiz A, 2023, Arxiv, DOI arXiv:2308.09067; Nadeem A., 2020, ACIS 2020 PROC; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Noor N. B., 2023, 2023 INT C ELECT COM, P1; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pennycook G, 2021, TRENDS COGN SCI, V25, P388, DOI 10.1016/j.tics.2021.02.007; Radford A., 2018, IMPROVING LANGUAGE U; Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847; Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054; Sharpe D., 2015, PRACTICAL ASSESSMENT, V20, P8, DOI [10.7275/tbfa-x148, DOI 10.7275/TBFA-X148]; Sheng EMY, 2019, Arxiv, DOI arXiv:1909.01326; Shor E, 2019, SOCIOL SCI, V6, P526, DOI 10.15195/v6.a20; Sun T., 2019, Assoc. for Comput. Linguist. (ACL 2019); Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Zellers R, 2019, ADV NEUR IN, V32	41	0	0	132	132	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAR 4	2024	14	1							5224	10.1038/s41598-024-55686-2	http://dx.doi.org/10.1038/s41598-024-55686-2			20	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	KI0F7	38433238	Green Submitted, gold			2024-07-03	WOS:001179206700016
J	Kande, R; Pearce, H; Tan, B; Dolan-Gavitt, B; Thakur, S; Karri, R; Rajendran, J				Kande, Rahul; Pearce, Hammond; Tan, Benjamin; Dolan-Gavitt, Brendan; Thakur, Shailja; Karri, Ramesh; Rajendran, Jeyavijayan			(Security) Assertions by Large Language Models	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						LLM; AI; hardware; assertion generation; hardware security; vulnerability detection; ChatGPT; Codex		The security of computer systems typically relies on a hardware root of trust. As vulnerabilities in hardware can have severe implications on a system, there is a need for techniques to support security verification activities. Assertion-based verification is a popular verification technique that involves capturing design intent in a set of assertions that can be used in formal verification or testing-based checking. However, writing security-centric assertions is a challenging task. In this work, we investigate the use of emerging large language models (LLMs) for code generation in hardware assertion generation for security, where primarily natural language prompts, such as those one would see as code comments in assertion files, are used to produce SystemVerilog assertions. We focus our attention on a popular LLM and characterize its ability to write assertions out of the box, given varying levels of detail in the prompt. We design an evaluation framework that generates a variety of prompts, and we create a benchmark suite comprising real-world hardware designs and corresponding golden reference assertions that we want to generate with the LLM.	[Kande, Rahul; Rajendran, Jeyavijayan] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA; [Pearce, Hammond] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia; [Tan, Benjamin] Univ Calgary, Dept Elect & Software Engn, Calgary, AB T2N 1N4, Canada; [Dolan-Gavitt, Brendan; Thakur, Shailja; Karri, Ramesh] NYU, Dept Comp Sci & Engn, New York, NY 10012 USA	Texas A&M University System; Texas A&M University College Station; University of New South Wales Sydney; University of Calgary; New York University; New York University Tandon School of Engineering	Kande, R (corresponding author), Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX 77843 USA.	rahulkande@tamu.edu		Tan, Benjamin/0000-0002-7642-3638	U.S. Office of Naval Research	U.S. Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research)	No Statement Available	Ardeshiricham A, 2017, DES AUT TEST EUROPE, P1691, DOI 10.23919/DATE.2017.7927266; Basu K, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3315574; Chakraborty A, 2020, IEEE T COMPUT AID D, V39, P1952, DOI 10.1109/TCAD.2019.2944586; Chen C, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P1379, DOI 10.1145/3489517.3530638; Chen C, 2023, Arxiv, DOI arXiv:2304.02485; Chen M., 2021, arXiv; Chen YF, 2023, 39TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2023, P366, DOI 10.1145/3627106.3627196; Dessouky G, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P213; Deutschbein C, 2018, INT WORKSHOP MICROPR, P18, DOI 10.1109/MTV.2018.00013; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ender M, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1803; Foster Harry., 2004, ASSERTION BASED DESI, Vsecond; Fu W., 2023, P AS HARDV OR SEC TR, P1; Gage P., 1994, C Users Journal, V12, P23; GitHub, GitHub Copilot Your Al Pair Programmer; Harris CB, 2016, DES AUT TEST EUROPE, P966; Hertz S, 2013, IEEE T COMPUT AID D, V32, P952, DOI 10.1109/TCAD.2013.2241176; Jia JJ, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P82, DOI 10.23919/DATE51398.2021.9474098; Kande R, 2023, arXiv; Kande R, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3219; Kekcze O., 2019, P FOR SPEC DES LANG, P1; Kern C., 1999, ACM Transactions on Design Automation of Electronic Systems, V4, P123, DOI 10.1145/307988.307989; lowRISC Contributors, Open Source Silicon Root of Trust (RoT), Open Titan.; Meng XY, 2023, Arxiv, DOI arXiv:2308.11042; Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenA1, 2022, CharGPT: Optimizing Language Models for Dia logue.; Orenes-Vera M, 2023, Arxiv, DOI arXiv:2309.09437; Paria S, 2023, Arxiv, DOI arXiv:2308.06932; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Pearce H, 2020, PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD '20), P27, DOI 10.1145/3380446.3430634; PRICE D, 1995, IEEE MICRO, V15, P88, DOI 10.1109/40.372360; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajendran J, 2015, DES AUT CON, DOI 10.1145/2744769.2744823; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Ren Z., 2016, P INT C EMB SYST CYB; Rostami M, 2014, P IEEE, V102, P1283, DOI 10.1109/JPROC.2014.2335155; Sadeghi A. R., 2021, P GREAT LAK S VLSI, P95; Schade M., 2023, Understanding Codex Training Data and Outputs.; Semiconductor Industry Association, 2023, Tech Workers in Semiconductor Industry.; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Siemens, 2021, Modelsim.; Tan TS, 2014, J ELECTRON TEST, V30, P255, DOI 10.1007/s10836-014-5449-5; Thakur S., 2022, Finetuned Codegen 28-Verilog Model.; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Trippel T, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3237; Vasudevan S, 2010, DES AUT TEST EUROPE, P626; Vaswani A, 2017, ADV NEUR IN, V30; Wang CG, 2018, ASIA S PACIF DES AUT, P84, DOI 10.1109/ASPDAC.2018.8297287; Witharana H., 2023, ACM J. Emerg. Technol. Comput. Syst., V19, P1; Witharana H, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3510578; Xiao K, 2016, ACM T DES AUTOMAT EL, V22, DOI 10.1145/2906147; Zhang R, 2020, P IEEE S SECUR PRIV, P1713, DOI 10.1109/SP40000.2020.00030; Zhang ZX, 2023, Arxiv, DOI arXiv:2310.04535; Zhong WK, 2022, 13TH ASIA-PACIFIC SYMPOSIUM ON INTERNETWARE, INTERNETWARE 2022, P96, DOI 10.1145/3545258.3545268	56	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.		2024	19						4374	4389		10.1109/TIFS.2024.3372809	http://dx.doi.org/10.1109/TIFS.2024.3372809			16	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PU0K2					2024-07-03	WOS:001216477200036
C	Gay, G		Arcaini, P; Yue, T; Fredericks, EM		Gay, Gregory			Improving the Readability of Generated Tests Using GPT-4 and ChatGPT Code Interpreter	SEARCH-BASED SOFTWARE ENGINEERING, SSBSE 2023	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Symposium on Search-Based Software Engineering (SSBSE)	DEC 08, 2023	San Francisco, CA	Grand Valley State Univ		Automated Test Generation; Search-Based Test Generation; Readability; Large Language Models; Generative AI		A major challenge in automated test generation is the readability of generated tests. Emerging large language models (LLMs) excel at language analysis and transformation tasks. We propose that improving test readability is such a task and explore the capabilities of the GPT-4 LLM in improving readability of tests generated by the Pynguin search-based generation framework. Our initial results are promising. However, there are remaining research and technical challenges.	[Gay, Gregory] Chalmers Gothenburg, Gothenburg, Sweden; [Gay, Gregory] Univ Gothenburg, Gothenburg, Sweden	University of Gothenburg	Gay, G (corresponding author), Chalmers Gothenburg, Gothenburg, Sweden.; Gay, G (corresponding author), Univ Gothenburg, Gothenburg, Sweden.	greg@greggay.com		Gay, Gregory/0000-0001-6794-9585	Vetenskapsradet [2019-05275]; Vinnova [2019-05275] Funding Source: Vinnova; Swedish Research Council [2019-05275] Funding Source: Swedish Research Council	Vetenskapsradet(Swedish Research Council); Vinnova(Vinnova); Swedish Research Council(Swedish Research Council)	Vetenskapsradet Grant 2019-05275.	Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Fontes A., 2023, Optimising the Software Development Process with Artificial Intelligence, P179, DOI [10.1007/978-981-19-9948-2_7, DOI 10.1007/978-981-19-9948-2_7]; Li BY, 2016, IEEE INT CONF SOFTW, P341, DOI 10.1109/ICST.2016.30; Lukasczyk S, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-022-10248-w; OpenAI, 2023, Gpt-4 technical report; Roy D, 2020, IEEE INT CONF AUTOM, P287, DOI 10.1145/3324884.3416622; Winkler D, 2022, EUR CON SFTWR MTNCE, P1167, DOI 10.1109/SANER53432.2022.00135; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207	8	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48795-8; 978-3-031-48796-5	LECT NOTES COMPUT SC			2024	14415						140	146		10.1007/978-3-031-48796-5_11	http://dx.doi.org/10.1007/978-3-031-48796-5_11			7	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5AC					2024-07-03	WOS:001157562200012
J	Cabral, S; Restrepo, D; Kanjee, Z; Wilson, P; Crowe, B; Abdulnour, RE; Rodman, A				Cabral, Stephanie; Restrepo, Daniel; Kanjee, Zahir; Wilson, Philip; Crowe, Byron; Abdulnour, Raja-Elie; Rodman, Adam			Clinical Reasoning of a Generative Artificial Intelligence Model Compared With Physicians	JAMA INTERNAL MEDICINE			English	Article; Early Access								This cross-sectional study assesses the ability of a large language model to process medical data and display clinical reasoning compared with the ability of attending physicians and residents.	[Cabral, Stephanie; Kanjee, Zahir; Wilson, Philip; Crowe, Byron; Rodman, Adam] Beth Israel Deaconess Med Ctr, Dept Med, Boston, MA USA; [Restrepo, Daniel] Massachusetts Gen Hosp, Dept Med, Boston, MA USA; [Abdulnour, Raja-Elie] Brigham & Womens Hosp, Dept Pulm & Crit Care, Boston, MA USA; [Rodman, Adam] Beth Israel Deaconess Med Ctr, Dept Med, W SPAN 2, 330 Brookline Ave, Boston, MA 02215 USA	Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Massachusetts General Hospital; Harvard University; Brigham & Women's Hospital; Harvard University; Beth Israel Deaconess Medical Center	Rodman, A (corresponding author), Beth Israel Deaconess Med Ctr, Dept Med, W SPAN 2, 330 Brookline Ave, Boston, MA 02215 USA.	arodman@bidmc.harvard.edu			Harvard Clinical and Translational Science Center (National Center for Advancing Translational Sciences, National Institutes of Health) [UM1TR004408]; Harvard University	Harvard Clinical and Translational Science Center (National Center for Advancing Translational Sciences, National Institutes of Health); Harvard University	This work was supported by grant UM1TR004408 from the Harvard Clinical and Translational Science Center (National Center for Advancing Translational Sciences, National Institutes of Health) and by financial contributions from Harvard University and its affiliated academic health care centers.	Abdulnour REE, 2022, NEW ENGL J MED, V386, P1946, DOI 10.1056/NEJMe2204540; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; OpenAI, Best practices for prompt engineering with OpenAI API; Schaye V, 2022, J GEN INTERN MED, V37, P507, DOI 10.1007/s11606-021-06805-6; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909	6	2	2	8	8	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6106	2168-6114		JAMA INTERN MED	JAMA Intern. Med.	2024 MAY 6	2024										10.1001/jamainternmed.2024.0295	http://dx.doi.org/10.1001/jamainternmed.2024.0295		MAY 2024	3	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	MZ8T0	38557971				2024-07-03	WOS:001197554900001
J	Jeong, H; Han, SS; Yu, Y; Kim, S; Jeon, KJ				Jeong, Hui; Han, Sang-Sun; Yu, Youngjae; Kim, Saejin; Jeon, Kug Jin			How well do large language model-based chatbots perform in oral and maxillofacial radiology?	DENTOMAXILLOFACIAL RADIOLOGY			English	Article; Early Access						large language model; artificial intelligence; chatbot; education; dental; oral and maxillofacial radiology		Objectives This study evaluated the performance of four large language model (LLM)-based chatbots by comparing their test results with those of dental students on an oral and maxillofacial radiology examination.Methods ChatGPT, ChatGPT Plus, Bard, and Bing Chat were tested on 52 questions from regular dental college examinations. These questions were categorized into three educational content areas: basic knowledge, imaging and equipment, and image interpretation. They were also classified as multiple-choice questions (MCQs) and short-answer questions (SAQs). The accuracy rates of the chatbots were compared with the performance of students, and further analysis was conducted based on the educational content and question type.Results The students' overall accuracy rate was 81.2%, while that of the chatbots varied: 50.0% for ChatGPT, 65.4% for ChatGPT Plus, 50.0% for Bard, and 63.5% for Bing Chat. ChatGPT Plus achieved a higher accuracy rate for basic knowledge than the students (93.8% vs. 78.7%). However, all chatbots performed poorly in image interpretation, with accuracy rates below 35.0%. All chatbots scored less than 60.0% on MCQs, but performed better on SAQs.Conclusions The performance of chatbots in oral and maxillofacial radiology was unsatisfactory. Further training using specific, relevant data derived solely from reliable sources is required. Additionally, the validity of these chatbots' responses must be meticulously verified.	[Jeong, Hui; Han, Sang-Sun; Jeon, Kug Jin] Yonsei Univ, Coll Dent, Dept Oral & Maxillofacial Radiol, 50-1 Yonsei ro, Seoul 03722, South Korea; [Han, Sang-Sun; Jeon, Kug Jin] Yonsei Univ, Inst Innovat Digital Healthcare, Seoul 03722, South Korea; [Han, Sang-Sun] Yonsei Univ, Coll Dent, Oral Sci Res Ctr, Seoul 03722, South Korea; [Kim, Saejin] Yonsei Univ, Coll Comp, Dept Artificial Intelligence, Seoul 03722, South Korea	Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University; Yonsei University Health System; Yonsei University	Jeon, KJ (corresponding author), Yonsei Univ, Coll Dent, Dept Oral & Maxillofacial Radiol, 50-1 Yonsei ro, Seoul 03722, South Korea.	DENTJEON@yuhs.ac		Jeon, Kug Jin/0000-0002-5862-2975	Yonsei University College of Dentistry Fund [6-2023-0063]	Yonsei University College of Dentistry Fund	This study was supported by the Yonsei University College of Dentistry Fund (Grant number: 6-2023-0063).	Aguiar de Sousa Rafael, 2024, J Am Dent Assoc, V155, P227, DOI 10.1016/j.adaj.2023.11.004; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Beam K, 2023, JAMA PEDIATR, V177, P977, DOI 10.1001/jamapediatrics.2023.2373; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Choi JH, 2022, J LEGAL EDUC, V71, P387; Danesh A, 2024, J PERIODONTOL, DOI 10.1002/JPER.23-0514; Danesh A, 2023, J AM DENT ASSOC, V154, P970, DOI 10.1016/j.adaj.2023.07.016; Hatia A, 2024, J CLIN MED, V13, DOI 10.3390/jcm13030735; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; Jo E, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581503; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lin SY, 2024, DIGIT HEALTH, V10, DOI 10.1177/20552076241237678; Morishita M., 2023, J Dent Sci, DOI [10.1016/j.jds.2023.12.007, DOI 10.1016/J.JDS.2023.12.007]; Ohta K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50369; Patil NS, 2024, CAN ASSOC RADIOL J, V75, P344, DOI 10.1177/08465371231193716; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Suárez A, 2024, COMPUT STRUCT BIOTEC, V24, P46, DOI 10.1016/j.csbj.2023.11.058; Taira Kazuya, 2023, JMIR Nurs, V6, pe47305, DOI 10.2196/47305; Terwiesch C., 2023, Would Chat GPT3 get a Wharton MBA. A Prediction Based on its Performance in the Operations Management Course; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2	22	0	0	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0250-832X	1476-542X		DENTOMAXILLOFAC RAD	Dentomaxillofac. Radiol.	2024 JUN 7	2024										10.1093/dmfr/twae021	http://dx.doi.org/10.1093/dmfr/twae021		JUN 2024	6	Dentistry, Oral Surgery & Medicine; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Dentistry, Oral Surgery & Medicine; Radiology, Nuclear Medicine & Medical Imaging	UZ7H7	38848473	hybrid			2024-07-03	WOS:001251947900001
J	Patton, DU; Landau, AY; Mathiyazhagan, S				Patton, Desmond Upton; Landau, Aviv Y.; Mathiyazhagan, Siva			ChatGPT for Social Work Science: Ethical Challenges and Opportunities	JOURNAL OF THE SOCIETY FOR SOCIAL WORK AND RESEARCH			English	Article						generative artificial intelligence; large language models; ChatGPT; social work research; social work ethics		In this invited paper, we describe the potential use of ChatGPT in social work science, exploring opportunities and ethical challenges related to the deployment of large language models (LLM), specifically ChatGPT, for social work science. We offer several preliminary recommendations for the ethical use of ChatGPT in social work science and call on the profession's governing organizations to develop a comprehensive ethical framework for the use of LLMs such as ChatGPT in social work research.	[Patton, Desmond Upton] Univ Penn, Sch Social Policy & Practice, Annenberg Sch Commun, New York, NY 10013 USA; [Landau, Aviv Y.; Mathiyazhagan, Siva] Univ Penn, Sch Social Policy & Practice, New York, NY USA	University of Pennsylvania; University of Pennsylvania	Patton, DU (corresponding author), Univ Penn, Sch Social Policy & Practice, Annenberg Sch Commun, New York, NY 10013 USA.	dupatton@upenn.edu						[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown S., 2021, Machine learning, explained; Caplan R, 2018, BIG DATA SOC, V5, DOI 10.1177/2053951718757253; Chomsky N., 2023, NEW YORK TIMES; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Goings TC, 2023, J SOC SOC WORK RES, DOI 10.1086/720983; Huang Kalley., 2023, NEW YORK TIMES; Marquart M., 2023, 2023 NASW NYC SOCIAL, DOI [10.7916/axhj-x577, DOI 10.7916/AXHJ-X577]; Okerlund J., 2022, TECHNOLOGY ASSESSMEN; OpenAI, 2023, ArXiv; OpenAI, 2023, Terms of use; Roose K., 2023, NEW YORK TIMES; Singer JB, 2023, J SOC WORK EDUC, V59, P294, DOI 10.1080/10437797.2023.2189878; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Victor BG, 2023, RES SOCIAL WORK PRAC, V33, P511, DOI 10.1177/10497315231166125	17	3	3	62	154	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	2334-2315	1948-822X		J SOC SOC WORK RES	J. Soc. Soc. Work Res.	SEP 1	2023	14	3					553	562		10.1086/726042	http://dx.doi.org/10.1086/726042		SEP 2023	10	Social Work	Social Science Citation Index (SSCI)	Social Work	U1CN0					2024-07-03	WOS:001039931900001
J	Zhang, LY; Shu, JH; Hu, JL; Li, FF; He, JJ; Wang, P; Shen, YQ				Zhang, Luyao; Shu, Jianhua; Hu, Jili; Li, Fangfang; He, Junjun; Wang, Peng; Shen, Yiqing			Exploring the Potential of Large Language Models in Radiological Imaging Systems: Improving User Interface Design and Functional Capabilities	ELECTRONICS			English	Article						large language model (LLM); radiological information system (RIS); human-computer interaction	INFORMATION-SYSTEMS	Large language models (LLMs) have demonstrated remarkable capabilities in natural language processing tasks, including conversation, in-context learning, reasoning, and code generation. This paper explores the potential application of LLMs in radiological information systems (RIS) and assesses the impact of integrating LLMs on RIS development and human-computer interaction. We present ChatUI-RIS, a prototype chat-based user interface that leverages LLM capabilities to enhance RIS functionality and user experience. Through an exploratory study involving 26 medical students, we investigate the efficacy of natural language dialogue for learning and operating RIS. Our findings suggest that LLM integration via a chat interface can significantly improve operational efficiency, reduce learning time, and facilitate rapid expansion of RIS capabilities. By interacting with ChatUI-RIS using natural language instructions, medical students can access and retrieve radiology information in a conversational manner. The LLM-powered chat interface not only streamlines user interactions, but also enables more intuitive and efficient navigation of complex RIS functionalities. Furthermore, the natural language processing capabilities of LLMs can be harnessed to automatically generate code snippets and database queries, accelerating RIS development and customization. Preliminary observations indicate that integrating LLMs in RIS has the potential to revolutionize user interface design, enhance system capabilities, and ultimately improve the overall user experience for radiologists and medical professionals.	[Zhang, Luyao; Shu, Jianhua; Hu, Jili; Li, Fangfang] Anhui Univ Chinese Med, Sch Med Informat Engn, Hefei 230031, Peoples R China; [He, Junjun] Shanghai AI Lab, Shanghai 200233, Peoples R China; [Wang, Peng] Anhui Univ Chinese Med, Grad Sch, Hefei 230031, Peoples R China; [Shen, Yiqing] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA	Anhui University of Chinese Medicine; Shanghai Artificial Intelligence Laboratory; Anhui University of Chinese Medicine; Johns Hopkins University	Wang, P (corresponding author), Anhui Univ Chinese Med, Grad Sch, Hefei 230031, Peoples R China.; Shen, YQ (corresponding author), Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD 21218 USA.	anhuiwangpeng@126.com; yshen92@jhu.edu	Shen, Yiqing/AAO-2811-2021	Shen, Yiqing/0000-0001-7866-3339	Central Government's Special Fund for The Inheritance and Development of Traditional Chinese Medicine	Central Government's Special Fund for The Inheritance and Development of Traditional Chinese Medicine	No Statement Available	Amrhein V, 2019, NATURE, V567, P305, DOI 10.1038/d41586-019-00857-9; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Barragan-Montero A, 2021, PHYS MEDICA, V83, P242, DOI 10.1016/j.ejmp.2021.04.016; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Calisto FM, 2022, INT J HUM-COMPUT ST, V168, DOI 10.1016/j.ijhcs.2022.102922; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Cowan IA, 2013, J MED IMAG RADIAT ON, V57, P558, DOI 10.1111/1754-9485.12092; Dias CR, 2017, J BIOMED INFORM, V76, P19, DOI 10.1016/j.jbi.2017.10.004; GERLACH JH, 1991, MIS QUART, V15, P527, DOI 10.2307/249456; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Ishwarya M., 2024, Computational Imaging and Analytics in Biomedical Engineering, P105; Jansson M, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104680; Jayakumar S, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-021-00544-y; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jiang JH, 2023, Arxiv, DOI arXiv:2305.09645; Jiang X, 2024, Arxiv, DOI arXiv:2303.06689; Liang YB, 2023, Arxiv, DOI arXiv:2303.16434; Lin A, 2010, AM J ROENTGENOL, V195, P188, DOI 10.2214/AJR.09.2946; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Mann KS, 2014, PROCEDIA COMPUT SCI, V37, P16, DOI 10.1016/j.procs.2014.08.007; Mervak BM, 2016, J AM COLL RADIOL, V13, P1311, DOI 10.1016/j.jacr.2016.05.022; Mese I, 2023, CLIN IMAG, V103, DOI 10.1016/j.clinimag.2023.109993; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Nabovati E, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0035-z; Nagy PG, 2009, RADIOGRAPHICS, V29, P1897, DOI 10.1148/rg.297095701; Najjar R, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13172760; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nallapati R, 2016, Arxiv, DOI [arXiv:1602.06023, DOI 10.48550/ARXIV.1602.06023]; Nance JW, 2013, AM J ROENTGENOL, V200, P1064, DOI 10.2214/AJR.12.10326; Narayan S, 2018, arXiv; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Orrù G, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1199350; Pellegrini C, 2023, Arxiv, DOI arXiv:2311.18681; Petridis S., 2023, P 2023 CHI C HUM FA, P1; Pianykh OS, 2020, RADIOLOGY, V297, P6, DOI 10.1148/radiol.2020200038; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0; Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Sanh V, 2022, arXiv; Sellam T, 2020, Arxiv, DOI arXiv:2004.04696; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Vallerio KS, 2006, IEEE T MOBILE COMPUT, V5, P846, DOI 10.1109/TMC.2006.97; Wang G, 2016, IEEE ACCESS, V4, P8914, DOI 10.1109/ACCESS.2016.2624938; Wang XY, 2023, Arxiv, DOI arXiv:2309.10691; Wei JS, 2022, ADV NEUR IN; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Zhao Y., 2023, P 11 INT C LEARN REP	48	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2002	10.3390/electronics13112002	http://dx.doi.org/10.3390/electronics13112002			21	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UA2F3		gold			2024-07-03	WOS:001245269900001
C	Janatian, S; Westermann, H; Tan, JZ; Savelka, J; Benyekhlef, K		Spanakis, J; VanDijck, G; Sileno, G		Janatian, Samyar; Westermann, Hannes; Tan, Jinzhe; Savelka, Jaromir; Benyekhlef, Karim			From Text to Structure: Using Large Language Models to Support the Development of Legal Expert Systems	LEGAL KNOWLEDGE AND INFORMATION SYSTEMS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	36th Annual International Conference on Legal Knowledge and Information Systems (JURIX)	DEC 18-20, 2023	Maastricht Univ, Maastricht, NETHERLANDS	JURIX Fdn Legal Knowledge Based Syst	Maastricht Univ	large language models; legal technology; artificial intelligence; semantic legislation analysis; augmented intelligence; legal decision support tools	SEARCH	Encoding legislative text in a formal representation is an important prerequisite to different tasks in the field of AI & Law. For example, rule-based expert systems focused on legislation can support laypeople in understanding how legislation applies to them and provide them with helpful context and information. However, the process of analyzing legislation and other sources to encode it in the desired formal representation can be time-consuming and represents a bottleneck in the development of such systems. Here, we investigate to what degree large language models (LLMs), such as GPT-4, are able to automatically extract structured representations from legislation. We use LLMs to create pathways from legislation, according to the JusticeBot methodology for legal decision support systems, evaluate the pathways and compare them to manually created pathways. The results are promising, with 60% of generated pathways being rated as equivalent or better than manually created ones in a blind comparison. The approach suggests a promising path to leverage the capabilities of LLMs to ease the costly development of systems based on symbolic approaches that are transparent and explainable.	[Janatian, Samyar; Westermann, Hannes; Tan, Jinzhe; Benyekhlef, Karim] Univ Montreal, Cyberjustice Lab, Montreal, PQ, Canada; [Savelka, Jaromir] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Universite de Montreal; Carnegie Mellon University	Janatian, S (corresponding author), Univ Montreal, Cyberjustice Lab, Montreal, PQ, Canada.	samyar.jan10@gmail.com	Savelka, Jaromir/GOK-0488-2022; Benyekhlef, Karim/A-2410-2015	Savelka, Jaromir/0000-0002-3674-5456; Tan, Jinzhe/0000-0002-8259-2630; Benyekhlef, Karim/0000-0001-9390-556X	Autonomy through Cyberjustice Technologies project; Cyberjustice Laboratory, LexUM Chair	Autonomy through Cyberjustice Technologies project; Cyberjustice Laboratory, LexUM Chair	We acknowledge the generous support from the Cyberjustice Laboratory, LexUM Chair, and Autonomy through Cyberjustice Technologies project.	ALLEN LE, 1978, J LEGAL EDUC, V29, P380; Ashley KD, 2017, ARTIFICIAL INTELLIGENCE AND LEGAL ANALYTICS: NEW TOOLS FOR LAW PRACTICE IN THE DIGITAL AGE, P1, DOI 10.1017/9781316761380; BERGEL JL, 1988, LA LAW REV, V48, P1073; Bhuiyan H., 2022, LN2FR, P22; Blair-Stanek A, 2023, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023, P22, DOI 10.1145/3594536.3595163; Branting LK, 2021, ARTIF INTELL LAW, V29, P213, DOI 10.1007/s10506-020-09273-1; Dragoni M., 2016, 1 WORKSH MIN REASONI; Gaur S, 2015, LECT NOTES ARTIF INT, V9067, P259, DOI 10.1007/978-3-662-48119-6_19; Katz DM, 2024, PHILOS T R SOC A, V382, DOI 10.1098/rsta.2023.0254; Long SPN, 2023, Arxiv, DOI arXiv:2303.05279; Nakamura M, 2008, LECT NOTES ARTIF INT, V4914, P349; Nguyen H.T., 2023, WORKSH LOG PROGR LEG; Nguyen H, 2023, Arxiv, DOI arXiv:2309.05501; OpenAI, 2023, GPT-4 Technical Report; PAQUIN LC, 1991, THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE & LAW, P254, DOI 10.1145/112646.112678; Salaun O., 2022, Legal Knowledge and Information Systems, P123; Sasdelli D., 2022, METHODOLOGIES TRANSL, P43; Satoh K., 2010, JSAI ISAI WORKSHOPS, P153; Savelka J., 2023, P ASAIL 23; Savelka J, 2023, Arxiv, DOI arXiv:2306.09525; SERGOT MJ, 1986, COMMUN ACM, V29, P370, DOI 10.1145/5689.5920; Susskind R., 1987, Expert systems in law; Tan J., 2023, ARTIFICIAL INTELLIGE; van Engers T.M., 2004, Legal Knowledge and Information Systems, P49; Walker V. R., 2007, Jurimetrics: Journal of Law, Science and Technology, V47, P193; Walker V.R., 2017, ASAIL/LegalAIIA@ ICAIL; Westermann H., 2023, ASAIL 2023; Westermann H., 2023, Artificial Intelligence for Access to Justice (AI4AJ 2023); Westermann H., 2022, arXiv; Westermann H, 2023, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND LAW, ICAIL 2023, P351, DOI 10.1145/3594536.3595166; Westermann H, 2020, FRONT ARTIF INTEL AP, V334, P164, DOI 10.3233/FAIA200860; Westermann H, 2019, FRONT ARTIF INTEL AP, V322, P123, DOI 10.3233/FAIA190313; Westermann Hannes, 2019, Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law, P133; Wyner A, 2011, FRONT ARTIF INTEL AP, V235, P113, DOI 10.3233/978-1-60750-981-3-113	34	0	0	3	3	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-472-7; 978-1-64368-473-4	FRONT ARTIF INTEL AP			2023	379						167	176		10.3233/FAIA230962	http://dx.doi.org/10.3233/FAIA230962			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Information Science & Library Science; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science; Government & Law	BW6JJ		hybrid, Green Submitted			2024-07-03	WOS:001175464100022
J	Iannantuono, GM; Bracken-Clarke, D; Floudas, CS; Roselli, M; Gulley, JL; Karzai, F				Iannantuono, Giovanni Maria; Bracken-Clarke, Dara; Floudas, Charalampos S.; Roselli, Mario; Gulley, James L.; Karzai, Fatima			Applications of large language models in cancer care: current evidence and future perspectives	FRONTIERS IN ONCOLOGY			English	Review						artificial intelligence; large language models; chatbot; cancer care; ChatGPT	ARTIFICIAL-INTELLIGENCE	The development of large language models (LLMs) is a recent success in the field of generative artificial intelligence (AI). They are computer models able to perform a wide range of natural language processing tasks, including content generation, question answering, or language translation. In recent months, a growing number of studies aimed to assess their potential applications in the field of medicine, including cancer care. In this mini review, we described the present published evidence for using LLMs in oncology. All the available studies assessed ChatGPT, an advanced language model developed by OpenAI, alone or compared to other LLMs, such as Google Bard, Chatsonic, and Perplexity. Although ChatGPT could provide adequate information on the screening or the management of specific solid tumors, it also demonstrated a significant error rate and a tendency toward providing obsolete data. Therefore, an accurate, expert-driven verification process remains mandatory to avoid the potential for misinformation and incorrect evidence. Overall, although this new generative AI-based technology has the potential to revolutionize the field of medicine, including that of cancer care, it will be necessary to develop rules to guide the application of these tools to maximize benefits and minimize risks.	[Iannantuono, Giovanni Maria; Karzai, Fatima] NCI, NIH, Genitourinary Malignancies Branch, Ctr Canc Res, Bethesda, MD 20814 USA; [Iannantuono, Giovanni Maria; Roselli, Mario] Univ Roma Tor Vergata, Med Oncol Unit, Dept Syst Med, Rome, Italy; [Bracken-Clarke, Dara; Floudas, Charalampos S.; Gulley, James L.] NCI, NIH, Ctr Immuno Oncol, Ctr Canc Res, Bethesda, MD USA	National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); University of Rome Tor Vergata; National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI)	Karzai, F (corresponding author), NCI, NIH, Genitourinary Malignancies Branch, Ctr Canc Res, Bethesda, MD 20814 USA.	fatima.karzai@nih.gov	Gulley, James L/K-4139-2016; Roselli, Mario/AAJ-5481-2020		The authors declare financial support was received for the research, authorship, and/or publication of this article. This work was supported by the Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Res; Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research	The authors declare financial support was received for the research, authorship, and/or publication of this article. This work was supported by the Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Res; Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research	The authors declare financial support was received for the research, authorship, and/or publication of this article. This work was supported by the Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research. The interpretation and reporting of these data are the sole responsibility of the authors.	27 July 2023, What Is Natural Language Processing?; [Anonymous], Chatgpt at the Point of Care; [Anonymous], Anthropic-Claude Introducing Claude; Bhinder B, 2021, CANCER DISCOV, V11, P900, DOI 10.1158/2159-8290.CD-21-0090; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao JJ, 2023, AM J ROENTGENOL, V221, P556, DOI 10.2214/AJR.23.29493; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; Google, Try Bard, an Ai Experiment by Google; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hendler J., Avoiding Another Ai Winter; IBM, Ai Vs. Machine Learning Vs. Deep Learning Vs. Neural Networks: What's the Difference?; IBM, What Is Generative Ai?; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Moazzam Z, 2023, ANN SURG ONCOL, V30, P6284, DOI 10.1245/s10434-023-13777-w; O'Hern K, 2023, JAAD INT, V12, P168, DOI 10.1016/j.jdin.2023.06.002; OpenAI, WHAT IS CHATGPT; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Perplexity, Perplexity Ai; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schulte B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37938; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	35	11	11	23	62	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2234-943X			FRONT ONCOL	Front. Oncol.	SEP 4	2023	13								1268915	10.3389/fonc.2023.1268915	http://dx.doi.org/10.3389/fonc.2023.1268915			6	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	R8PZ4	37731643	Green Published, gold			2024-07-03	WOS:001066934300001
J	Jost, G; Taneski, V; Karakatic, S				Jost, Gregor; Taneski, Viktor; Karakatic, Saso			The Impact of Large Language Models on Programming Education and Student Learning Outcomes	APPLIED SCIENCES-BASEL			English	Article						large language models (LLMs); ChatGPT; Copilot; programming education; React; debugging		Recent advancements in Large Language Models (LLMs) like ChatGPT and Copilot have led to their integration into various educational domains, including software development education. Regular use of LLMs in the learning process is still not well-researched; thus, this paper intends to fill this gap. The paper explores the nuanced impact of informal LLM usage on undergraduate students' learning outcomes in software development education, focusing on React applications. We carefully designed an experiment involving thirty-two participants over ten weeks where we examined unrestricted but not specifically encouraged LLM use and their correlation with student performance. Our results reveal a significant negative correlation between increased LLM reliance for critical thinking-intensive tasks such as code generation and debugging and lower final grades. Furthermore, a downward trend in final grades is observed with increased average LLM use across all tasks. However, the correlation between the use of LLMs for seeking additional explanations and final grades was not as strong, indicating that LLMs may serve better as a supplementary learning tool. These findings highlight the importance of balancing LLM integration with the cultivation of independent problem-solving skills in programming education.	[Jost, Gregor; Taneski, Viktor; Karakatic, Saso] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia	University of Maribor	Jost, G (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, Maribor 2000, Slovenia.	gregor.jost@um.si; viktor.taneski@um.si; saso.karakatic@um.si		Karakatic, Saso/0000-0003-4441-9690; Taneski, Viktor/0000-0001-5841-9275	Slovenian Research and Innovation Agency (ARIS)	Slovenian Research and Innovation Agency (ARIS)	No Statement Available	Cambaz D, 2024, PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1, P172, DOI 10.1145/3626252.3630958; Carver McCoy Sharon., 1987, Empirical studies of programmers: Second workshop, P147, DOI DOI 10.5555/54968.54978; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Denny P., 2023, P 54 ACM TECHN S COM; Fuchs K, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1166682; Grassini S, 2023, EDUC SCI, V13, DOI 10.3390/educsci13070692; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Haque M.A., 2023, EAI Endorsed Trans. AI Robot, DOI DOI 10.4108/AIRO.V2I1.3276; Hlis T, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app132413061; Idrisov B, 2024, ALGORITHMS, V17, DOI 10.3390/a17020062; Lazuardy M.F. S., 2022, Research Journal of Advanced Engineering and Science, V7, P132; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Michaeli T, 2019, PROCEEDINGS OF THE 14TH WORKSHOP IN PRIMARY AND SECONDARY COMPUTING EDUCATION (WIPSCE), DOI 10.1145/3361721.3361724; Montenegro-Rueda M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080153; Pudari R, 2023, Arxiv, DOI arXiv:2303.04142; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Tan KH, 2023, Arxiv, DOI arXiv:2305.03433; Vaithilingam Priyan, 2022, CHI EA '22: CHI Conference on Human Factors in Computing Systems Extended Abstracts, DOI 10.1145/3491101.3519665; Vaswani A, 2017, ADV NEUR IN, V30; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830	20	0	0	12	12	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAY	2024	14	10							4115	10.3390/app14104115	http://dx.doi.org/10.3390/app14104115			15	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	SE3Q6		gold			2024-07-03	WOS:001232746700001
J	Pavlick, E				Pavlick, Ellie			Symbols and grounding in large language models	PHILOSOPHICAL TRANSACTIONS OF THE ROYAL SOCIETY A-MATHEMATICAL PHYSICAL AND ENGINEERING SCIENCES			English	Review						natural language processing; cognitive science; language models	NEURAL-NETWORKS	Large language models (LLMs) are one of the most impressive achievements of artificial intelligence in recent years. However, their relevance to the study of language more broadly remains unclear. This article considers the potential of LLMs to serve as models of language understanding in humans. While debate on this question typically centres around models' performance on challenging language understanding tasks, this article argues that the answer depends on models' underlying competence, and thus that the focus of the debate should be on empirical work which seeks to characterize the representations and processing algorithms that underlie model behaviour. From this perspective, the article offers counterarguments to two commonly cited reasons why LLMs cannot serve as plausible models of language in humans: their lack of symbolic structure and their lack of grounding. For each, a case is made that recent empirical trends undermine the common assumptions about LLMs, and thus that it is premature to draw conclusions about LLMs' ability (or lack thereof) to offer insights on human language representation and understanding. This article is part of a discussion meeting issue 'Cognitive artificial intelligence'.	[Pavlick, Ellie] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA	Brown University	Pavlick, E (corresponding author), Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.	ellie_pavlick@brown.edu						Abdou M., 2021, P 25 C COMPUTATIONAL, P109, DOI [10.18653/v1/2021.conll-1.9, DOI 10.18653/V1/2021.CONLL-1.9]; Adi Y., 2017, INT C LEARNING REPRE; Alishahi A, 2019, NAT LANG ENG, V25, P543, DOI 10.1017/S135132491900024X; Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bau A., 2019, ICLR; Bau D, 2020, P NATL ACAD SCI USA, V117, P30071, DOI 10.1073/pnas.1907375117; Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254; Belinkov Yonatan, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, P1, DOI [DOI 10.18653/V1/2020.ACL-TUTORIALS.1, 10.18653/v1/2020.acl-tutorials.1]; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bisk Y, 2020, AAAI CONF ARTIF INTE, V34, P7432; Block N., 1998, ROUTLEDGE ENCYCL PHI, V8, P652; Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303; Bowman Samuel R., 2019, INT C LEARN REPR, P1; Carey S, 2015, CONCEPTUAL MIND: NEW DIRECTIONS IN THE STUDY OF CONCEPTS, P415; CHALMERS DJ, 1990, PROGRAM OF THE TWELFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P340; Chater N., 2023, PHILOS T R SOC A, V381, P20220047, DOI [10.1098/rsta.2022.0047, DOI 10.1098/RSTA.2022.0047]; Collins KM, 2022, Arxiv, DOI [arXiv:2205.05718, 10.48550/arXiv.2205.05718]; Da J., 2019, P 1 WORKSH COMM INF, P1, DOI DOI 10.18653/V1/D19-6001; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eichenberg C, 2021, Arxiv, DOI arXiv:2112.05253; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P160, DOI 10.1162/tacl_a_00359; Ellis K, 2020, Arxiv, DOI [arXiv:2006.08381, DOI 10.48550/ARXIV.2006.08381]; Erk K, 2012, LANG LINGUIST COMPAS, V6, P635, DOI 10.1002/Inc3.362; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; Fodor J. A., 1975, LANGUAGE THOUGHT, V5; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Forbes M, 2019, Arxiv, DOI arXiv:1908.02899; Geiger A., 2021, Advances in Neural Information Processing Systems, V34, P9574; Geva M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5484; Glockner M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P650; Grice P., 1989, STUDIES WAYS WORDS; Harman G., 1982, Notre Dame Journal of Formal Logic, V23, P242, DOI [DOI 10.1305/ndjfl/1093883628, DOI 10.1305/NDJFL/1093883628, 10.1305/ndjfl/1093883628]; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hupkes D, 2018, J ARTIF INTELL RES, V61, P907, DOI 10.1613/jair.1.11196; Jia R, 2017, P 2017 C EMPIRICAL M, P2021, DOI [10.18653/v1/D17-1215, DOI 10.18653/V1/D17-1215, DOI 10.18653/V1/D17-1215.URL]; Kandpal N, 2023, Arxiv, DOI [arXiv:2211.08411, 10.48550/arXiv.2211.08411]; Keil FC., 1992, Concepts, kinds, and cognitive development, DOI [10.7551/mitpress/2065.001.0001, DOI 10.7551/MITPRESS/2065.001.0001]; Kim N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9087; Kratzer A., 1998, Semantics in generative grammar, V1185; Kripke, 1980, NAMING NECESSITY; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Landau B., 2009, Language and experience: Evidence from the blind child, V8; Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343; Lepori MA, 2023, Arxiv, DOI arXiv:2301.10884; Linzen T., 2020, P 58 ANN M ASS COMP, P5210, DOI [DOI 10.18653/V1/2020.ACL-MAIN.465, 10.18653/v1/2020.acl-main.465]; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Lovering C., 2021, Predicting Inductive Biases of Pre-Trained Models; Lovering C, 2022, T ASSOC COMPUT LING, V10, P1193, DOI 10.1162/tacl_a_00514; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Marcus G., 2022, Deep Learning Is Hitting a Wall'; Marcus G., 2022, The Road to AI We Can Trust (blog); McCoy RT, 2021, Arxiv, DOI arXiv:2111.09509; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; MEDIN D, 1989, SIMILARITY AND ANALOGICAL REASONING, P179, DOI 10.1017/CBO9780511529863.009; Meng K, 2022, Arxiv, DOI arXiv:2202.05262; Merrill W, 2021, T ASSOC COMPUT LING, V9, P1047, DOI 10.1162/tacl_a_00412; Merullo J, 2023, Arxiv, DOI arXiv:2209.15162; Misra K, 2022, Arxiv, DOI arXiv:2210.01963; Mollo DC, 2023, Arxiv, DOI arXiv:2304.01481; NEWELL A, 1980, COGNITIVE SCI, V4, P135, DOI 10.1016/S0364-0213(80)80015-2; Olah C., 2020, DISTILL, V5, DOI [10.2 3915/distill.00024.001, DOI 10.23915/DISTILL.00024.001]; Olsson Catherine, 2022, Transformer Circuits; Palangi H, 2018, AAAI CONF ARTIF INTE, P5350; Partee B., 1995, An Invitation to Cognitive Science: Language, V1, P311; Patel R., 2022, INT C LEARNING REPRE; Pavlick E., 2016, Proceedings of the Fifth Joint Conference on Lexical and Computational Semantics, P114; Pavlick E, 2022, ANNU REV LINGUIST, V8, P447, DOI 10.1146/annurev-linguistics-031120-122924; Pavlick E, 2019, T ASSOC COMPUT LING, V7, P677, DOI 10.1162/tacl_a_00293; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Piantasodi S, 2022, Arxiv, DOI [arXiv:2208.02957, 10.48550/arXiv.2208.02957, DOI 10.48550/ARXIV.2208.02957]; Quilty-Dunn J, 2022, BEHAV BRAIN SCI, V46, DOI 10.1017/S0140525X22002849; Radford A., 2020, 2020 BETTER LANGUAGE; Radford A, 2021, PR MACH LEARN RES, V139; Ravfogel Shauli, 2020, P 58 ANN M ASS COMPU, P7237, DOI [10.18653/v1/2020.acl-main.647, DOI 10.18653/V1/2020.ACL-MAIN.647]; Ross A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2230; Sanh V., 2022, INT C LEARNING REPRE; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Scialom T., 2020, P 13 INT C NAT LANG, P327; Simons M., 2010, Semantics and Linguistic Theory (SALT), V20, P309, DOI DOI 10.3765/SALT.V20I0.2584; Srivastava Aarohi, 2022, arXiv; Tenenbaum J., 2019, ICLR DEBATE L KAELBL; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Traylor A., 2021, P 59 ANN M ASS COMP, V2, P158, DOI [10.18653/v1/2021.acl-short.21, DOI 10.18653/V1/2021.ACL-SHORT.21]; Tsimpoukelli M., 2021, Advances in Neural Information Processing Systems, V34, P200; Tucker M, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P862; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vig Jesse, 2020, Advances in neural information processing systems, V33, P12388; Wei J., 2022, INT C LEARN REPR ONL; White AS., 2018, 48 ANN M N E LING SO; Wong C, 2021, PR MACH LEARN RES, V139; Xie SM., 2021, INT C LEARNING REPRE; Yang Y, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2021865119; Yu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4896; Yun T., 2021, Findings of the Association for Computational Linguistics: EMNLP 2021, P4357	96	15	16	16	78	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	1364-503X	1471-2962		PHILOS T R SOC A	Philos. Trans. R. Soc. A-Math. Phys. Eng. Sci.	JUL 24	2023	381	2251							20220041	10.1098/rsta.2022.0041	http://dx.doi.org/10.1098/rsta.2022.0041			19	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	I1QQ4	37271171	hybrid, Green Published			2024-07-03	WOS:001000603200004
C	Basar, E; Balaji, D; He, LW; Hendrickx, I; Krahmer, E; de Bruijn, GJ; Bosse, T			ACM	Basar, Erkan; Balaji, Divyaa; He, Linwei; Hendrickx, Iris; Krahmer, Emiel; de Bruijn, Gert-Jan; Bosse, Tibor			HyLECA: A Framework for Developing Hybrid Long-term Engaging Controlled Conversational Agents	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023			English	Proceedings Paper	5th International Conference on Conversational User Interfaces (CUI)	JUL 19-21, 2023	Eindhoven Univ Technol, Eindhoven, NETHERLANDS	Assoc Comp Machinery, ACM SIGCHI, Bold Insight UK, Eindhoven Univ Technol, Eindhoven AI Syst Inst, HMD Res	Eindhoven Univ Technol	hybrid conversational agents; task-oriented dialogue systems; natural language generation		We present HyLECA, an open-source framework designed for the development of long-term engaging controlled conversational agents. HyLECA's dialogue manager employs a hybrid architecture, combining rule-based methods for controlled dialogue flows with retrieval-based and generation-based approaches to enhance the utterance variability and flexibility. The motivation behind HyLECA lies in enhancing user engagement and enjoyment in task-oriented chatbots by leveraging the natural language generation capabilities of open-domain large language models within the confines of predetermined dialogue flows. Moreover, we discuss the technical capabilities, potential applications, relevance, and adaptability of the system. Lastly, we report preliminary findings from integrating state-of-the-art large language models in simulating a conversation centred on smoking cessation.	[Basar, Erkan; Bosse, Tibor] Radboud Univ Nijmegen, Commun & Media Grp, Behav Sci Inst, Nijmegen, Netherlands; [Balaji, Divyaa] Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands; [He, Linwei; Krahmer, Emiel] Tilburg Univ, Dept Commun & Cognit, TSHD, Tilburg, Netherlands; [Hendrickx, Iris] Radboud Univ Nijmegen, Ctr Language Studies, Ctr Language & Speech Technol, Nijmegen, Netherlands; [de Bruijn, Gert-Jan] Univ Antwerp, Dept Commun Studies, Antwerp, Belgium	Radboud University Nijmegen; University of Amsterdam; Tilburg University; Radboud University Nijmegen; University of Antwerp	Basar, E (corresponding author), Radboud Univ Nijmegen, Commun & Media Grp, Behav Sci Inst, Nijmegen, Netherlands.	erkan.basar@ru.nl; d.balaji@uva.nl; l.he_1@tilburguniversity.edu; iris.hendrickx@ru.nl; e.j.krahmer@tilburguniversity.edu; gert-jan.debruijn@uantwerpen.be; tibor.bosse@ru.nl	de Bruijn, Gert-Jan/GOV-4325-2022	de Bruijn, Gert-Jan/0000-0001-9759-3938; Balaji, Divyaa/0000-0002-0654-467X; Bosse, Tibor/0000-0003-4233-0406; He, Linwei/0000-0002-6593-1661; Basar, Erkan/0000-0003-1948-3551	Dutch Research Council (NWO) [406, DI.19.054]	Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO))	This project is partly financed by the Dutch Research Council (NWO) with project number 406.DI.19.054.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Balaji Divyaa, 2023, Using counselling-inspired relational strategies to facilitate selfdisclosure with a chatbot in a sensitive domain: A qualitative study; Basar E, 2022, ICAART, P401, DOI 10.5220/0010914300003116; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bocklisch Tom, 2017, P CONV WORKSH 31 C N, DOI [10.48550/arXiv.1712.05181, DOI 10.48550/ARXIV.1712.05181]; de Wit Jan, 2023, P 5 C CONVERSATIONAL; He LW, 2023, NICOTINE TOB RES, V25, P1241, DOI 10.1093/ntr/ntac281; He Linwei, 2023, Effectiveness and user experience of a smoking cessation chatbot: A mixed-methods study comparing motivational interviewing and confrontational counselling; MERMELSTEIN R, 1986, J CONSULT CLIN PSYCH, V54, P447, DOI 10.1037/0022-006X.54.4.447; Papaioannou Ioannis, 2017, AL PRIZ SOCIALBOT GR; Rapp A, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102630; See A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1702; Shalyminov I, 2021, IEEE-ACM T AUDIO SPE, V29, P2484, DOI 10.1109/TASLP.2021.3074779; Zamanirad S, 2020, LECT NOTES COMPUT SC, V12127, P199, DOI 10.1007/978-3-030-49435-3_13; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270	15	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0014-9				2023									56	10.1145/3571884.3604404	http://dx.doi.org/10.1145/3571884.3604404			5	Computer Science, Cybernetics; Psychology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Psychology	BW2OK		Green Published			2024-07-03	WOS:001122710800056
J	Zhang, YB; Itani, S; Khanal, K; Okyere, E; Smith, G; Takahashi, K; Zang, JD				Zhang, Yibo; Itani, Suman; Khanal, Kamal; Okyere, Emmanuel; Smith, Gavin; Takahashi, Koichiro; Zang, Jiadong			GPTArticleExtractor: An automated workflow for magnetic material database construction	JOURNAL OF MAGNETISM AND MAGNETIC MATERIALS			English	Article						Magnetic materials; Database; Large language models		A comprehensive database of magnetic materials is valuable for researching the properties of magnetic materials and discovering new ones. This article introduces a novel workflow that leverages large language models for extracting key information from scientific literature. From 22,120 articles in the Journal of Magnetism and Magnetic Materials, a database containing 2,035 magnetic materials was automatically generated, with ferromagnetic materials constituting 76% of the total. Each entry in the database includes the material's chemical compounds, as well as related structures (space group, crystal structure) and magnetic temperatures (Curie, N & eacute;el, and other transitional temperatures). To ensure data accuracy, we meticulously compared each entry in the database against the original literature, verifying the precision and reliability of each entry.	[Zhang, Yibo; Itani, Suman; Khanal, Kamal; Okyere, Emmanuel; Smith, Gavin; Takahashi, Koichiro; Zang, Jiadong] Univ New Hampshire, Dept Phys & Astron, 9 Lib Way, Durham, NH 03824 USA; [Zhang, Yibo] Univ New Hampshire, Dept Chem, 23 Acad Way, Durham, NH 03824 USA	University System Of New Hampshire; University of New Hampshire; University System Of New Hampshire; University of New Hampshire	Zhang, YB; Zang, JD (corresponding author), Univ New Hampshire, Dept Phys & Astron, 9 Lib Way, Durham, NH 03824 USA.; Zhang, YB (corresponding author), Univ New Hampshire, Dept Chem, 23 Acad Way, Durham, NH 03824 USA.	yibo.zhang@unh.edu; jiadong.zang@unh.edu		Takahashi, Koichiro/0009-0009-3972-4704	University of New Hampshire	University of New Hampshire	This work was supported in part by a Collaborative Research Excel- lence (CoRE) , USA grant from the University of New Hampshire.	Alverson M., 2023, Generative adversarial networks and diffusion models in material discovery; ANDERSON PW, 1950, PHYS REV, V79, P350, DOI 10.1103/PhysRev.79.350; Bergerhoff G, 1987, Crystallographic Databases; Blanco JA, 2009, PHYS REV B, V79, DOI 10.1103/PhysRevB.79.216401; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buschow K.J., 2003, Handbook of Magnetic Materials; Byland JK, 2022, PHYS REV MATER, V6, DOI 10.1103/PhysRevMaterials.6.063803; Coey J.M.D., 2010, Magnetism and Magnetic Materials, DOI [DOI 10.1017/CBO9780511845000, 10.1017/CBO9780511845000]; Connolly T F, 2012, Bibliography of Magnetic Materials and Tabulation of Magnetic Transition Temperatures; Court CJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.111; Curtarolo S, 2013, NAT MATER, V12, P191, DOI [10.1038/NMAT3568, 10.1038/nmat3568]; Delétang G, 2024, Arxiv, DOI arXiv:2309.10668; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Nguyen DN, 2019, J PHYS CONF SER, V1290, DOI 10.1088/1742-6596/1290/1/012009; Gallego SV, 2016, J APPL CRYSTALLOGR, V49, P1750, DOI 10.1107/S1600576716012863; Gilligan LPJ, 2023, Arxiv, DOI arXiv:2301.11689; Himanen L, 2020, COMPUT PHYS COMMUN, V247, DOI 10.1016/j.cpc.2019.106949; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; [刘淼 Liu Miao], 2023, [中国科学. 化学, Scientia Sinica Chimica], V53, P19; Nelson J, 2019, PHYS REV MATER, V3, DOI 10.1103/PhysRevMaterials.3.104405; Ouyang L., 2022, NEURIPS; Pavarini E, 2021, RIV NUOVO CIMENTO, V44, P597, DOI 10.1007/s40766-021-00025-8; Ribeiro RAP, 2015, J MAGN MAGN MATER, V391, P166, DOI 10.1016/j.jmmm.2015.04.091; Romero AH, 2018, EUR PHYS J B, V91, DOI 10.1140/epjb/e2018-90275-5; Singh P, 2023, CHEM MATER, V35, P6304, DOI 10.1021/acs.chemmater.3c00892; Spaldin N.A., 2010, Magnetic Materials: Fundamentals and Applications; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Tasaki H., 2020, Physics and Mathematics of Quantum Many-Body Systems, P371; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaitkus A, 2021, J APPL CRYSTALLOGR, V54, P661, DOI 10.1107/S1600576720016532; Vaswani A, 2017, ADV NEUR IN, V30; Villars P, 2004, J ALLOY COMPD, V367, P167, DOI 10.1016/j.jallcom.2003.08.060; Villars P., 2007, PEARSONS CRYSTAL DAT; Wick C, 2018, Arxiv, DOI arXiv:1807.02004; Xu YB, 2011, JPN J APPL PHYS, V50, DOI 10.1143/JJAP.50.11RH02; Xu YF, 2020, NATURE, V586, P702, DOI 10.1038/s41586-020-2837-0; Zagorac D, 2019, J APPL CRYSTALLOGR, V52, P918, DOI 10.1107/S160057671900997X; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	39	0	0	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0304-8853	1873-4766		J MAGN MAGN MATER	J. Magn. Magn. Mater.	MAY 1	2024	597								172001	10.1016/j.jmmm.2024.172001	http://dx.doi.org/10.1016/j.jmmm.2024.172001			5	Materials Science, Multidisciplinary; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science; Physics	QW7X8		Green Submitted			2024-07-03	WOS:001223983400001
C	Bao, KQ; Zhang, JZ; Zhang, Y; Wang, WJ; Feng, FL; He, X			ACM	Bao, Keqin; Zhang, Jizhi; Zhang, Yang; Wang, Wenjie; Feng, Fuli; He, Xiangnan			Large Language Models for Recommendation: Progresses and Future Directions	ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL IN THE ASIA PACIFIC REGION, SIGIR-AP 2023			English	Proceedings Paper	1st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region (SIGIR-AP)	NOV 26-28, 2023	Beijing, PEOPLES R CHINA	Assoc Comp Machinery, ACM SIGIR, Xiaohongshu, Zhipu AI, Kuaishou		Large Language Models; Recommender Systems; Generative Recommendation; Generative Models		The powerful large language models (LLMs) have played a pivotal role in advancing recommender systems. Recently, in both academia and industry, there has been a surge of interest in developing LLMs for recommendation, referred to as LLM4Rec. This includes endeavors like leveraging LLMs for generative item retrieval and ranking, as well as the exciting possibility of building universal LLMs for diverse open-ended recommendation tasks. These developments hold the potential to reshape the traditional recommender paradigm, paving the way for the next-generation recommender systems. In this tutorial, we aim to retrospect the evolution of LLM4Rec and conduct a comprehensive review of existing research. In particular, we will clarify how recommender systems benefit from LLMs through a variety of perspectives, including the model architecture, learning paradigm, and the strong abilities of LLMs such as chatting, generalization, planning, and generation. Furthermore, we will discuss the critical challenges and open problems in this emerging field, for instance, the trustworthiness, efficiency, and model retraining issues. Lastly, we will summarize the implications of previous work and outline future research directions. We believe that this tutorial will assist the audience in better understanding the progress and prospects of LLM4Rec, inspiring them for future exploration. This, in turn, will drive the prosperity of LLM4Rec, possibly fostering a paradigm shift in recommendation systems.	[Bao, Keqin; Zhang, Jizhi; Zhang, Yang; Feng, Fuli; He, Xiangnan] Univ Sci & Technol China, Hefei, Peoples R China; [Wang, Wenjie] Natl Univ Singapore, Singapore, Singapore	Chinese Academy of Sciences; University of Science & Technology of China, CAS; National University of Singapore	Bao, KQ (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	baokq@mail.ustc.edu.cn; cdzhangjizhi@mail.ustc.edu.cn; zy2015@mail.ustc.edu.cn; wenjiewang96@gmail.com; fulifeng93@gmail.com; xiangnanhe@gmail.com	Yang, Zhang/JWP-0075-2024					Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ai Qingyao, 2023, AI Open, V4, P80; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bao KQ, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1007, DOI 10.1145/3604915.3608857; Bao KQ, 2023, Arxiv, DOI [arXiv:2308.08434, 10.48550/arXiv.2308.08434]; Berglund L, 2024, Arxiv, DOI [arXiv:2309.12288, DOI 10.48550/ARXIV.2309.12288]; Bills S., 2023, Language models can explain neurons in language models; Cao BX, 2023, Arxiv, DOI [arXiv:2303.07616, 10.48550/arXiv.2303.07616]; Carranza AG, 2024, Arxiv, DOI arXiv:2305.05973; Chen JW, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P825, DOI 10.1145/3460231.3473321; Chen Wuyang, 2023, INT C MACHINE LEARNI, P5383; Chen X, 2023, Arxiv, DOI arXiv:2303.00168; Cui Z., 2022, arXiv; Dai SH, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1126, DOI 10.1145/3604915.3610646; Dao T., 2022, Advances in Neural Information Processing Systems, V35, P16344, DOI [10.48550/arXiv2205.14135, DOI 10.48550/ARXIV2205.14135]; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Du N, 2022, PR MACH LEARN RES; Feng Y, 2023, Arxiv, DOI arXiv:2308.06212; Friedman L, 2023, Arxiv, DOI arXiv:2305.07961; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; He XN, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/3077136.3080777; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; He ZK, 2023, Arxiv, DOI arXiv:2308.10053; Hou YP, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P585, DOI 10.1145/3534678.3539381; Hua Wenyue, 2023, RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems, P1281, DOI 10.1145/3604915.3609494; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Kwon W, 2023, Arxiv, DOI arXiv:2309.06180; Lei WQ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2425, DOI 10.1145/3397271.3401419; Li Jiacheng, 2023, KDD '23: Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, P1258, DOI 10.1145/3580305.3599519; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Lin JH, 2024, Arxiv, DOI arXiv:2308.11131; Lin JH, 2024, Arxiv, DOI arXiv:2306.05817; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Peng B, 2023, Arxiv, DOI arXiv:2305.13048; Qiu ZP, 2021, AAAI CONF ARTIF INTE, V35, P4320; Ren ZC, 2018, ACM/SIGIR PROCEEDINGS 2018, P1379, DOI 10.1145/3209978.3210185; Shen ZQ, 2024, Arxiv, DOI arXiv:2309.10818; Spillo Giuseppe, 2023, RecSys '23: Proceedings of the 17th ACM Conference on Recommender Systems, P856, DOI 10.1145/3604915.3608840; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang L, 2023, Arxiv, DOI arXiv:2306.02552; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wang X, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P890, DOI 10.1145/3336191.3371873; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wang XD, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P165, DOI 10.1145/3331184.3331267; Wang YC, 2024, Arxiv, DOI arXiv:2308.14296; Wang YF, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3547333; Wu LK, 2023, Arxiv, DOI arXiv:2307.05722; Wu LK, 2024, Arxiv, DOI arXiv:2305.19860; Xi YJ, 2023, Arxiv, DOI arXiv:2306.10933; Xi ZH, 2023, Arxiv, DOI arXiv:2309.07864; Xu J, 2018, ACM/SIGIR PROCEEDINGS 2018, P1365; Xu MR, 2023, Arxiv, DOI [arXiv:2303.16129, DOI 10.48550/ARXIV.2303.16129]; Yuan Z, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2639, DOI 10.1145/3539618.3591932; Zhang JZ, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P993, DOI 10.1145/3604915.3608860; Zhang JJ, 2023, Arxiv, DOI arXiv:2305.07001; Zhang Y, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P11, DOI 10.1145/3404835.3462875; Zhang YF, 2020, FOUND TRENDS INF RET, V14, P1, DOI 10.1561/1500000066; Zhang Yuhui, 2021, Language models as recommender systems: Evaluations and limitations; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao ZH, 2024, Arxiv, DOI arXiv:2307.02046	67	0	0	12	12	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0408-6				2023							306	309		10.1145/3624918.3629550	http://dx.doi.org/10.1145/3624918.3629550			4	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2NW					2024-07-03	WOS:001122582700036
C	Jin, PX; Zhang, SL; Ma, MH; Li, HZ; Kang, Y; Li, LQ; Liu, YD; Qiao, B; Zhang, CY; Zhao, P; He, SL; Sarro, F; Dang, YN; Rajmohan, S; Lin, QW; Zhang, DM		Chandra, S; Blincoe, K; Tonella, P		Jin, Pengxiang; Zhang, Shenglin; Ma, Minghua; Li, Haozhe; Kang, Yu; Li, Liqun; Liu, Yudong; Qiao, Bo; Zhang, Chaoyun; Zhao, Pu; He, Shilin; Sarro, Federica; Dang, Yingnong; Rajmohan, Saravana; Lin, Qingwei; Zhang, Dongmei			Assess and Summarize: Improve Outage Understanding with Large Language Models	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Outage Understanding; Large Language Model; Cloud Systems		Cloud systems have become increasingly popular in recent years due to their flexibility and scalability. Each time cloud computing applications and services hosted on the cloud are affected by a cloud outage, users can experience slow response times, connection issues or total service disruption, resulting in a significant negative business impact. Outages are usually comprised of several concurring events/source causes, and therefore understanding the context of outages is a very challenging yet crucial first step toward mitigating and resolving outages. In current practice, on-call engineers have to manually assess and summarize outages when they happen, which is time-consuming and labor-intensive. In this paper, we first present a large-scale empirical study investigating the way on-call engineers currently deal with cloud outages at Microsoft, and then present and empirically validate a novel approach (dubbed Oasis) to help the engineers in this task. Oasis is able to automatically assess the impact scope of outages as well as to produce human-readable summarization. Specifically, Oasis first assesses the impact scope of an outage by aggregating relevant incidents via multiple techniques. Then, it generates a human-readable summary by leveraging finetuned large language models like GPT-3.x. The impact assessment component of Oasis was introduced in Microsoft over three years ago, and it is now widely adopted, while the outage summarization component has been recently introduced, and in this article we present the results of an empirical evaluation we carried out on 18 real-world cloud systems as well as a human-based evaluation with outage owners. The results obtained show that Oasis can effectively and efficiently summarize outages, and lead Microsoft to deploy its first prototype which is currently under experimental adoption by some of the incident teams.	[Jin, Pengxiang; Zhang, Shenglin] Nankai Univ, Tianjin, Peoples R China; [Ma, Minghua; Kang, Yu; Li, Liqun; Liu, Yudong; Qiao, Bo; Zhang, Chaoyun; Zhao, Pu; He, Shilin; Lin, Qingwei; Zhang, Dongmei] Microsoft, Beijing, Peoples R China; [Li, Haozhe] Peking Univ, Beijing, Peoples R China; [Sarro, Federica] UCL, London, England; [Dang, Yingnong; Rajmohan, Saravana] Microsoft, Redmond, WA USA	Nankai University; Peking University; University of London; University College London; Microsoft	Lin, QW (corresponding author), Microsoft, Beijing, Peoples R China.		Liu, Yudong/JVZ-3491-2024; li, haozhe/JWP-3604-2024; Kang, Yu/L-2912-2013; Ma, Minghua/JFA-3786-2023; Lin, Qingwei/AAZ-3604-2021	Kang, Yu/0000-0002-0999-8802; Ma, Minghua/0000-0002-6303-1731; Kang, Yu/0009-0004-1735-5876	National Natural Science Foundation of China [62272249, 62072264]; Natural Science Foundation of Tianjin [21JCQNJC00180]; European Research Council [741278]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Tianjin(Natural Science Foundation of Tianjin); European Research Council(European Research Council (ERC))	We thank our colleagues in the production teams for the valuable feedback and labeling. Pengxiang Jin, and Shenglin Zhang are supported by the National Natural Science Foundation of China (Grant No. 62272249, 62072264), the Natural Science Foundation of Tianjin (Grant No. 21JCQNJC00180). Federica Sarro is supported by the European Research Council (Grant no. 741278).	Ahmed T, 2023, PROC INT CONF SOFTW, P1737, DOI 10.1109/ICSE48619.2023.00149; Ahmed T, 2022, PROC INT CONF SOFTW, P1443, DOI 10.1145/3510003.3510049; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen J, 2022, PROC INT CONF SOFTW, P1646, DOI 10.1145/3510003.3510055; Chen JJ, 2020, IEEE INT CONF AUTOM, P373, DOI 10.1145/3324884.3416624; Chen JJ, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P364, DOI 10.1109/ASE.2019.00042; Chen JJ, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P111, DOI 10.1109/ICSE-SEIP.2019.00020; Chen YJ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P304, DOI 10.1145/3368089.3409768; Chen YJ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2659, DOI 10.1145/3308558.3313501; Chen ZB, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P430, DOI 10.1109/ASE51524.2021.9678746; Chen ZB, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1487, DOI 10.1145/3368089.3417055; Eisinga R, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1486-2; Fu M, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P935, DOI 10.1145/3540250.3549098; Ghosh S, 2022, PROCEEDINGS OF THE 13TH SYMPOSIUM ON CLOUD COMPUTING, SOCC 2022, P126, DOI 10.1145/3542929.3563482; Gros D, 2020, IEEE INT CONF AUTOM, P746, DOI 10.1145/3324884.3416546; Gu JZ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1296, DOI 10.1145/3368089.3417061; Gu JZ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P292, DOI 10.1145/3368089.3409741; Hadary O, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P845; Jiang JJ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1410, DOI 10.1145/3368089.3417054; Li LQ, 2023, Softw Engg in Pract, P138, DOI 10.1109/ICSE-SEIP58684.2023.00018; Li LQ, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P489; Li TC, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P371, DOI 10.1145/3543873.3584630; Liu HP, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P155, DOI 10.1145/3317550.3321438; Liu ZX, 2018, IEEE INT CONF AUTOM, P373, DOI 10.1145/3238147.3238190; Ma MH, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1453, DOI 10.1145/3540250.3558946; Ma MH, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P413; Ma MH, 2020, PROC VLDB ENDOW, V13, P1176, DOI 10.14778/3389133.3389136; Ma MH, 2018, PROC INT SYMP SOFTW, P13, DOI 10.1109/ISSRE.2018.00013; Mastropaolo A, 2022, PROC INT CONF SOFTW, P2279, DOI 10.1145/3510003.3511561; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Qin XT, 2023, I C DEPEND SYS NETWO, P522, DOI 10.1109/DSN58367.2023.00055; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Vaswani A, 2017, ADV NEUR IN, V30; Wang YH, 2021, PROC INT CONF SOFTW, P885, DOI 10.1109/ICSE43902.2021.00085; Yan XH, 2023, Softw Engg in Pract, P222, DOI 10.1109/ICSE-SEIP58684.2023.00026; Zeng ZR, 2023, Softw Engg in Pract, P258, DOI 10.1109/ICSE-SEIP58684.2023.00029; Zhang JL, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P77, DOI 10.1145/3533767.3534396; Zhang SL, 2023, Arxiv, DOI arXiv:2302.10512; Zhao Chenyu, 2023, P SIGKDD C KNOWLEDGE; Zhao NW, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP), P162, DOI 10.1145/3377813.3381363; Zhong ZY, 2023, Arxiv, DOI [arXiv:2308.00393, 10.48550/arXiv.2308.00393, DOI 10.48550/ARXIV.2308.00393]	41	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							1657	1668		10.1145/3611643.3613891	http://dx.doi.org/10.1145/3611643.3613891			12	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted			2024-07-03	WOS:001148157800133
J	Chen, LL; Lei, YT; Jin, SY; Zhang, Y; Zhang, LJ				Chen, Liangliang; Lei, Yutian; Jin, Shiyu; Zhang, Ying; Zhang, Liangjun			RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						Robots; Task analysis; Complexity theory; Robot motion; Codes; Training; Standards; Reinforcement learning (RL); large language models (LLMs); robotic manipulations; sample complexity		Reinforcement learning (RL) has demonstrated its capability in solving various tasks but is notorious for its low sample efficiency. In this paper, we propose RLingua, a framework that can leverage the internal knowledge of large language models (LLMs) to reduce the sample complexity of RL in robotic manipulations. To this end, we first present a method for extracting the prior knowledge of LLMs by prompt engineering so that a preliminary rule-based robot controller for a specific task can be generated in a user-friendly manner. Despite being imperfect, the LLM-generated robot controller is utilized to produce action samples during rollouts with a decaying probability, thereby improving RL's sample efficiency. We employ TD3, the widely-used RL baseline method, and modify the actor loss to regularize the policy learning towards the LLM-generated controller. RLingua also provides a novel method of improving the imperfect LLM-generated robot controllers by RL. We demonstrate that RLingua can significantly reduce the sample complexity of TD3 in four robot tasks of panda_gym and achieve high success rates in 12 sparsely rewarded robot tasks in RLBench, where the standard TD3 fails. Additionally, we validated RLingua's effectiveness in real-world robot experiments through Sim2Real, demonstrating that the learned policies are effectively transferable to real robot tasks.	[Chen, Liangliang; Lei, Yutian; Jin, Shiyu; Zhang, Liangjun] Baidu Res, Robot & Autonomous Driving Lab, Sunnyvale, CA 94089 USA; [Chen, Liangliang] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA; [Zhang, Ying] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA	Baidu; University System of Georgia; Georgia Institute of Technology; University System of Georgia; Georgia Institute of Technology	Chen, LL (corresponding author), Baidu Res, Robot & Autonomous Driving Lab, Sunnyvale, CA 94089 USA.; Chen, LL (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.	liangliang.chen@gatech.edu; yutianlei@baidu.com; shiyujin@baidu.com; yzhang@gatech.edu; liangjunzhang@baidu.com		Zhang, Liangjun/0000-0001-5737-2540				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahn M., 2022, P 6 C ROB LEARN, P287; Andrychowicz M., 2017, ADV NEURAL INFORM PR, V30, P1; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Dulac-Arnold G., 2019, P INT C MACH LEARN, P1; Fan L., 2018, P C ROB LEARN, P767; Fujimoto S, 2018, PR MACH LEARN RES, V80; Galloudec Q., 2021, arXiv, DOI 10.48550/arXiv.2106.13687; Hasselt H.V, 2010, Advances in neural information processing systems, P2613, DOI DOI 10.5555/2997046.2997187; Hester T, 2018, AAAI CONF ARTIF INTE, P3223; Huang W, 2022, C ROBOT LEARNING P M, P1769; Huang W, 2023, P C ROBOT LEARNING C, P540; Huang WL, 2022, PR MACH LEARN RES; James S, 2020, IEEE ROBOT AUTOM LET, V5, P3019, DOI 10.1109/LRA.2020.2974707; Kwon M., 2023, P INT C LEARN REPR, P1; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Lillicrap T. P., 2016, P INT C LEARN REPR I, P1; Ma Y. J., 2024, P INT C LEARN REPR, P1; Mirchandani S., 2023, P 7 C ROB LEARN, P2498; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Nair A, 2018, IEEE INT CONF ROBOT, P6292; Ouyang L., 2022, NEURIPS; Ross S., 2011, JMLR WORKSHOP C P, P627, DOI DOI 10.48550/ARXIV.1011.0686; Silver D, 2014, PR MACH LEARN RES, V32; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094; Vecerik M, 2018, Arxiv, DOI arXiv:1707.08817; Wake N, 2023, IEEE ACCESS, V11, P95060, DOI 10.1109/ACCESS.2023.3310935; Wei JS, 2022, ADV NEUR IN; Wu ZX, 2024, Arxiv, DOI arXiv:2403.10794; Xie T., 2024, P INT C LEARN REPR, P1; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Yu W., 2023, P 7 C ROB LEARN, P374; Zhang J., 2023, P MACHINE LEARNING R, P302; Zhu ZC, 2024, Arxiv, DOI arXiv:2310.07064	37	0	0	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	JUL	2024	9	7					6075	6082		10.1109/LRA.2024.3400189	http://dx.doi.org/10.1109/LRA.2024.3400189			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	RS2D5		Green Submitted			2024-07-03	WOS:001229576300005
J	DiStefano, PV; Patterson, JD; Beaty, RE				DiStefano, Paul V.; Patterson, John D.; Beaty, Roger E.			Automatic Scoring of Metaphor Creativity with Large Language Models	CREATIVITY RESEARCH JOURNAL			English	Article; Early Access							SEMANTIC DISTANCE; COGNITIVE-ABILITIES; APTNESS; LITERARY; THINKING; FLUENCY; BRAIN	Metaphor is crucial in human cognition and creativity, facilitating abstract thinking, analogical reasoning, and idea generation. Typically, human raters manually score the originality of responses to creative thinking tasks - a laborious and error-prone process. Previous research sought to remedy these risks by scoring creativity tasks automatically using semantic distance and large language models (LLMs). Here, we extend research on automatic creativity scoring to metaphor generation - the ability to creatively describe episodes and concepts using nonliteral language. Metaphor is arguably more abstract and naturalistic than prior targets of automated creativity assessment. We collected 4,589 responses from 1,546 participants to various metaphor prompts and corresponding human creativity ratings. We fine-tuned two open-source LLMs (RoBERTa and GPT-2) - effectively "teaching" them to score metaphors like humans - before testing their ability to accurately assess the creativity of new metaphors. Results showed both models reliably predicted new human creativity ratings (RoBERTa r = .72, GPT-2 r = .70), significantly more strongly than semantic distance (r = .42). Importantly, the fine-tuned models generalized accurately to metaphor prompts they had not been trained on (RoBERTa r = .68, GPT-2 r = .63). We provide open access to the fine-tuned models, allowing researchers to assess metaphor creativity in a reproducible and timely manner.	[DiStefano, Paul V.; Patterson, John D.; Beaty, Roger E.] Penn State Univ, Bellefonte, PA USA; [Beaty, Roger E.] Penn State Univ, Dept Psychol, 140 Moore Bldg, University Pk, PA 16802 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Beaty, RE (corresponding author), Penn State Univ, Dept Psychol, 140 Moore Bldg, University Pk, PA 16802 USA.	rebeaty@psu.edu		DiStefano, Paul/0009-0002-9638-3220	National Science Foundation [DRL-1920653, DUE-2155070]	National Science Foundation(National Science Foundation (NSF))	R.E.B. is supported by grants from the National Science Foundation [DRL-1920653; DUE-2155070].	Acar S, 2024, J EDUC PSYCHOL, DOI 10.1037/edu0000844; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Beaty RE, 2022, CREATIVITY RES J, V34, P245, DOI 10.1080/10400419.2022.2025720; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Beaty RE, 2017, BRAIN COGNITION, V111, P163, DOI 10.1016/j.bandc.2016.12.004; Beaty RE, 2013, MEM COGNITION, V41, P255, DOI 10.3758/s13421-012-0258-5; BILLOW RM, 1977, PSYCHOL BULL, V84, P81, DOI 10.1037/0033-2909.84.1.81; BLASKO DG, 1993, J EXP PSYCHOL LEARN, V19, P295, DOI 10.1037/0278-7393.19.2.295; Buczak P, 2023, J CREATIVE BEHAV, V57, P17, DOI 10.1002/jocb.559; Carbonell J. G., 1982, Strategies for natural language processing, DOI [10.1184/R1/6607250.v1, DOI 10.1184/R1/6607250.V1]; Cardillo ER, 2012, NEUROIMAGE, V59, P3212, DOI 10.1016/j.neuroimage.2011.11.079; Caucheteux C, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-20460-9; Chakrabarty T, 2022, T ASSOC COMPUT LING, V10, P589, DOI 10.1162/tacl_a_00478; CLEVENGER T, 1988, J PSYCHOLINGUIST RES, V17, P211, DOI 10.1007/BF01686356; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dumas D, 2021, J CREATIVE BEHAV, V55, P517, DOI 10.1002/jocb.471; Dumas D, 2021, PSYCHOL AESTHET CREA, V15, P645, DOI 10.1037/aca0000319; Dumas D, 2014, THINK SKILLS CREAT, V14, P56, DOI 10.1016/j.tsc.2014.09.003; Fan L, 2023, PSYCHOPHYSIOLOGY, V60, DOI 10.1111/psyp.14239; Ferreira F, 2021, BRAIN RES, V1770, DOI 10.1016/j.brainres.2021.147632; Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x; Forthmann B, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000518; Forthmann B, 2023, EUR J PSYCHOL ASSESS, V39, P449, DOI 10.1027/1015-5759/a000723; Forthmann B, 2019, J CREATIVE BEHAV, V53, P559, DOI 10.1002/jocb.240; Gibbs R. W., 1994, POETICS MIND FIGURAT; GIBBS RW, 1990, J LITERARY SEMANTICS, V19, P65, DOI 10.1515/jlse.1990.19.2.65; Glucksberg S, 1997, J MEM LANG, V36, P50, DOI 10.1006/jmla.1996.2479; Glucksberg S., 2001, Understanding Figurative Language. From Metaphors to Idioms, DOI [10.1093/acprof:oso/9780195111095.001.0001, DOI 10.1093/ACPROF:OSO/9780195111095.001.0001]; Goldstein T, 2023, PSYCHOL AESTHET CREA, V17, P495, DOI 10.1037/aca0000618; Green AE, 2016, CURR DIR PSYCHOL SCI, V25, P28, DOI 10.1177/0963721415618485; Guilford J. P., 1967, The nature of human intelligence; Hass RW, 2017, MEM COGNITION, V45, P233, DOI 10.3758/s13421-016-0659-y; Heinen DJP, 2018, PSYCHOL AESTHET CREA, V12, P144, DOI 10.1037/aca0000125; Holyoak KJ, 2018, PSYCHOL BULL, V144, P641, DOI 10.1037/bul0000145; Ichien N, 2024, Arxiv, DOI arXiv:2308.01497; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Jia-Li D. U., 2013, International Journal of Advanced Computer Science and Applications (IJACSA), V3, DOI [10.14569/IJACSA.2012.030909, DOI 10.14569/IJACSA.2012.030909]; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; Kasirer A, 2018, CREATIVITY RES J, V30, P205, DOI 10.1080/10400419.2018.1446747; KATZ AN, 1989, J MEM LANG, V28, P486, DOI 10.1016/0749-596X(89)90023-5; KATZ AN, 1992, POETICS TODAY, V13, P607, DOI 10.2307/1773291; KATZ AN, 1988, METAPHOR SYMB ACT, V3, P191, DOI 10.1207/s15327868ms0304_1; Kenett YN, 2019, CURR OPIN BEHAV SCI, V27, P11, DOI 10.1016/j.cobeha.2018.08.010; Lakoff G., 2008, Metaphors we live by; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Lantz B., 2019, MACHINE LEARNING R E; Lin Z, 2024, Arxiv, DOI [arXiv:2305.19187, 10.48550/arXiv.2305.19187]; Liu E, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4437; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Organisciak P, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101356; Parde N, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1535; Patterson J. D., 2023, AuDrA: An automated drawing assessment platform for evaluating creativity, DOI [10.3758/s13428-023-02258-3, DOI 10.3758/S13428-023-02258-3]; Paulus D. H., 1970, Final Report; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Shutova E, 2013, COMPUT LINGUIST, V39, P301, DOI 10.1162/COLI_a_00124; Silvia P. J., 2008, Psychology of Aesthetics, Creativity, and the Arts, V2, P68, DOI [10.1037/1931-3896.2.2.68, DOI 10.1037/1931-3896.2.2.68, 10.1037]; Silvia PJ, 2012, INTELLIGENCE, V40, P343, DOI 10.1016/j.intell.2012.02.005; Stamenkovic D, 2023, METAPHOR SYMBOL, V38, P149, DOI 10.1080/10926488.2021.2006046; Stevenson C, 2022, Arxiv, DOI [arXiv:2206.08932, 10.48550/arXiv.2206.08932, DOI 10.48550/ARXIV.2206.08932]; Taylor JuliaM., 2004, P ANN M COGNITIVE SC, V26; TIBERIUS RG, 1986, BRIT J EDUC TECHNOL, V17, P144, DOI 10.1111/j.1467-8535.1986.tb00504.x; TOURANGEAU R, 1981, COGNITIVE PSYCHOL, V13, P27, DOI 10.1016/0010-0285(81)90003-7; Veale T., 2016, Metaphor: A Computational Perspective; Winter B, 2023, METAPHOR SOC WORLD, V13, P59, DOI 10.1075/msw.00029.win; Yu YH, 2023, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000573; Zhou ZH, 2021, MACH LEARN, P181, DOI DOI 10.1007/978-981-15-1967-3	70	2	2	17	17	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1040-0419	1532-6934		CREATIVITY RES J	Creativ. Res. J.	2024 MAR 24	2024										10.1080/10400419.2024.2326343	http://dx.doi.org/10.1080/10400419.2024.2326343		MAR 2024	15	Psychology, Educational; Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	LV8R1		hybrid			2024-07-03	WOS:001189672000001
C	Weng, GY; Andrzejak, A			IEEE	Weng, Guoyang; Andrzejak, Artur			Automatic Bug Fixing via Deliberate Problem Solving with Large Language Models	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS, ISSREW			English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART				Developers dedicate a significant share of their activities to finding and fixing defects in their code. Automated program repair (APR) attempts to reduce this effort by a set of techniques for automatically fixing errors or vulnerabilities in software systems. Recent Large Language Models (LLMs) such as GPT-4 offer an effective alternative to existing APR methods, featuring out-of-the-box bug fixing performance comparable to even sophisticated deep learning approaches such as CoCoNut. In this work we propose a further extension to LLM-based program repair techniques by leveraging a recently introduced interactive prompting technique called Tree of Thoughts (ToT). Specifically, we ask a LLM to propose multiple hypotheses about the location of a bug, and based on the aggregated response we prompt for bug fixing suggestions. A preliminary evaluation shows that our approach is able to fix multiple complex bugs previously unsolved by GPT-4 even with prompt engineering. This result motivates further exploration of hybrid approaches which combine LLMs with suitable meta-strategies.	[Weng, Guoyang; Andrzejak, Artur] Heidelberg Univ, Heidelberg, Germany; [Weng, Guoyang] SAP SE, Heidelberg, Germany	Ruprecht Karls University Heidelberg	Weng, GY (corresponding author), Heidelberg Univ, Heidelberg, Germany.; Weng, GY (corresponding author), SAP SE, Heidelberg, Germany.	guoyang.weng@sap.com; artur.andrzejak@uni-heidelberg.de						Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen L, 2023, ARXIV230709009; Durr Christoph, 2020, Competitive Programming in Python 128 Algorithms to Develop Your Coding Skills; Le Goues C, 2021, IEEE SOFTWARE, V38, P22, DOI 10.1109/MS.2021.3072577; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; OpenAI, 2023, GPT-4 technical report; Perez A, 2021, IEEE T SOFTWARE ENG, V47, P412, DOI 10.1109/TSE.2019.2895640; Sharma Tushar, 2022, arXiv; Sobania D., 2023, ARXIV230108653; Yao Shunyu, 2023, arXiv	11	0	0	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-1956-9				2023							34	36		10.1109/ISSREW60843.2023.00040	http://dx.doi.org/10.1109/ISSREW60843.2023.00040			3	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KT					2024-07-03	WOS:001096854800009
C	Reif, E; Kahng, M; Petridis, S			IEEE	Reif, Emily; Kahng, Minsuk; Petridis, Savvas			Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models	2023 IEEE VISUALIZATION AND VISUAL ANALYTICS, VIS	IEEE Visualization Conference		English	Proceedings Paper	IEEE Conference on Visualization and Visual Analytics (IEEE VIS)	OCT 22-27, 2023	Melbourne, AUSTRALIA	IEEE, IEEE Comp Soc, IEEE VGTC		Visualization; Text; MLStatsModel		Large language models (LLMs) can be used to generate smaller, more refined datasets via few-shot prompting for benchmarking, fine-tuning or other use cases. However, understanding and evaluating these datasets is difficult, and the failure modes of LLM-generated data are still not well understood. Specifically, the data can be repetitive in surprising ways, not only semantically but also syntactically and lexically. We present LinguisticLens, a novel interactive visualization tool for making sense of and analyzing syntactic diversity of LLM-generated datasets. LinguisticLens clusters text along syntactic, lexical, and semantic axes. It supports hierarchical visualization of a text dataset, allowing users to quickly scan for an overview and inspect individual examples. The live demo is available at https://shorturl.at/zHOUV.	[Reif, Emily; Kahng, Minsuk; Petridis, Savvas] Google Res, Austin, TX 78701 USA	Google Incorporated	Petridis, S (corresponding author), Google Res, Austin, TX 78701 USA.	ereif@google.com; kahng@google.com; petridis@google.com						Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Assogba Y., 2023, arXiv; Bertucci Donald, 2023, IEEE Trans Vis Comput Graph, V29, P320, DOI 10.1109/TVCG.2022.3209425; Borisov V, 2023, Arxiv, DOI [arXiv:2210.06280, 10.48550/arXiv.2210.06280]; Brath R., 2023, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao N, 2010, IEEE T VIS COMPUT GR, V16, P1172, DOI 10.1109/TVCG.2010.154; Chatzimparmpas A, 2020, INFORM VISUAL, V19, P207, DOI 10.1177/1473871620904671; Choo J, 2013, IEEE T VIS COMPUT GR, V19, P1992, DOI 10.1109/TVCG.2013.212; Coenen A, 2019, ADV NEUR IN, V32; Collins C., 2022, VISUAL TEXT ANALYTIC; Fortuna B, 2005, INFORM-J COMPUT INFO, V29, P497; Fryer Z, 2022, Arxiv, DOI arXiv:2206.13757; Goncalves A, 2020, BMC MED RES METHODOL, V20, DOI 10.1186/s12874-020-00977-1; He ZX, 2023, Arxiv, DOI arXiv:2212.09864; Hohman F, 2019, IEEE T VIS COMPUT GR, V25, P2674, DOI 10.1109/TVCG.2018.2843369; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Kucher K, 2015, IEEE PAC VIS SYMP, P117, DOI 10.1109/PACIFICVIS.2015.7156366; Lara H, 2022, Arxiv, DOI arXiv:2212.08167; Pei J, 2001, PROC INT CONF DATA, P215; RAO R, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P318, DOI 10.1145/191666.191776; Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180; Strobelt H, 2018, IEEE T VIS COMPUT GR, V24, P667, DOI 10.1109/TVCG.2017.2744158; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Tenney I., 2020, arXiv; Vijayakumar A., 2022, Evaluating synthetic code-switched data; Wattenberg M, 2008, IEEE T VIS COMPUT GR, V14, P1221, DOI 10.1109/TVCG.2008.172; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yuan Ann, 2021, arXiv; Yuan J, 2021, COMPUT VIS MEDIA, V7, P3, DOI 10.1007/s41095-020-0191-7	30	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2771-9537	2771-9553	979-8-3503-2557-7	IEEE VIS CONF			2023							236	240		10.1109/VIS54172.2023.00056	http://dx.doi.org/10.1109/VIS54172.2023.00056			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3FG		Green Submitted, Bronze			2024-07-03	WOS:001137142800048
C	Yuan, A; Coenen, A; Reif, E; Ippolito, D			Assoc Comp Machinery	Yuan, Ann; Coenen, Andy; Reif, Emily; Ippolito, Daphne			Wordcraft Story Writing With Large Language Models	IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES			English	Proceedings Paper	27th Annual International Conference on Intelligent User Interfaces (ACM IUI)	MAR 21-25, 2022	Univ Helsinki, ELECTR NETWORK	Meta Reality Labs Research, Google, Goldman Sachs, Nokia Bell Labs, Toyota Res Inst, Apple, Nvidia, Silo AI	Univ Helsinki	NLP		The latest generation of large neural language models such as GPT-3 have achieved new levels of performance on benchmarks for language understanding and generation. These models have even demonstrated an ability to perform arbitrary tasks without explicit training. In this work, we sought to learn how people might use such models in the process of creative writing. We built Wordcraft, a text editor in which users collaborate with a generative language model to write a story. We evaluated Wordcraft with a user study in which participants wrote short stories with and without the tool. Our results show that large language models enable novel co-writing experiences. For example, the language model is able to engage in open-ended conversation about the story, respond to writers' custom requests expressed in natural language (such as "rewrite this text to be more Dickensian"), and generate suggestions that serve to unblock writers in the creative process. Based on these results, we discuss design implications for future human-AI co-writing systems.	[Yuan, Ann; Coenen, Andy; Reif, Emily; Ippolito, Daphne] Google Res, Cambridge, MA 02142 USA	Google Incorporated	Yuan, A (corresponding author), Google Res, Cambridge, MA 02142 USA.							Akoury Nader, 2020, EMPIRICAL METHODS NA; Ammanabrolu P, 2020, AAAI CONF ARTIF INTE, V34, P7375; Austin Jacob, 2021, PROGRAM SYNTHESIS LA; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Black Sid, 2021, GPTNeo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, DOI DOI 10.5281/ZENODO.5297715IFYOUUSETHISSOFTWARE; Buschek Daniel, 2021, IMPACT MULTIPLE PARA; Calderwood Alex, 2020, Intelligent User Interfaces; CallisonBurch Chris, 2019, P 1 WORKSHOP NARRATI; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Chen M., 2021, arXiv; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Dass Nathan, 2020, AUTOMATICALLY NEUTRA; Davis N, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P196, DOI 10.1145/2856767.2856795; Dhamala Jwala, 2021, arXiv; Effelsberg Wolfgang, 2020, INT C FDN DIGITAL GA; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Gero Katy, 2019, C C; Gero Katy, 2019, COMPUTER HUMAN INTER; Guzdial M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300854; Huang C.Z.A., 2020, INT SOC MUSIC INFORM; Kannan Anjuli, 2016, INT C KNOWLEDGE DISC; Karimi P, 2019, Arxiv, DOI arXiv:1906.10188; Koch J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300863; Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739; Marjan Ghazvininejad Jay Priyadarshi, 2017, HAFEZ INTERACTIVE PO; Martin Lara J., 2018, INT JOINT C ARTIFICI; Michael Christian Remy, 2019, COMPUTER HUMAN INTER; Michael Terry-Carrie J, 2021, COMPUTER HUMAN INTER; Nichols E., 2020, MIG, P1, DOI [10.48550/arXiv.2011.10208, DOI 10.48550/ARXIV.2011.10208]; Oh C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174223; Osone Hiroyuki, 2021, COMPUTER HUMAN INTER; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Schmitt Oliver., 2021, Creativity and Cognition (CC '21), P1; Shazeer Noam, 2017, ATTENTION IS ALL YOU; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Tan Chenhao, 2018, INTELLIGENT USER INT; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Wu Yonghui., 2018, Smart compose: Using neural networks to help write emails; Zhao TZ, 2021, PR MACH LEARN RES, V139	40	42	46	6	22	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9144-3				2022							841	852		10.1145/3490099.3511105	http://dx.doi.org/10.1145/3490099.3511105			12	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU2ZN		Bronze			2024-07-03	WOS:000889340800059
C	Fu, SH; Liao, Y; Zhou, PY			ACM	Fu, Shuhao; Liao, Yong; Zhou, Pengyuan			Training ChatGPT-like Models with In-network Computation	PROCEEDINGS OF THE 7TH ASIA-PACIFIC WORKSHOP ON NETWORKING, APNET 2023			English	Proceedings Paper	7th Asia-Pacific Workshop on Networking (APNET)	JUN 29-30, 2023	Hong Kong, HONG KONG	Assoc Comp Machinery, Huawei		Large Language Model; ChatGPT; In-network Computation; Pipeline Parallelism		ChatGPT shows the enormous potential of large language models (LLMs). These models can easily reach the size of billions of parameters and create training difficulties for the majority. We propose a paradigm to train LLMs using distributed in-network computation on routers. Our preliminary result shows that our design allows LLMs to be trained at a reasonable learning rate without demanding extensive GPU resources.	[Fu, Shuhao; Liao, Yong; Zhou, Pengyuan] Univ Sci & Technol China, Hefei, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Fu, SH (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	shuhaofu@mail.ustc.edu.cn; yliao@ustc.edu.cn; pyzhou@ustc.edu.cn	Zhou, Pengyuan/AAJ-2139-2021	Zhou, Pengyuan/0000-0002-7909-4059; Fu, Shuhao/0009-0005-3303-3882				Fang JR, 2023, IEEE T PARALL DISTR, V34, P304, DOI 10.1109/TPDS.2022.3219819; fka, 2023, prompts; Rajbhandari S, 2020, Arxiv, DOI arXiv:1910.02054; Saquetti M, 2021, IEEE COMMUN LETT, V25, P3551, DOI 10.1109/LCOMM.2021.3108940; Siracusano G, 2018, Arxiv, DOI arXiv:1801.05731; Xiong ZQ, 2019, PROCEEDINGS OF THE EIGHTEENTH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '19), P25, DOI 10.1145/3365609.3365864	6	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0782-7				2023							206	207		10.1145/3600061.3603136	http://dx.doi.org/10.1145/3600061.3603136			2	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW4GS					2024-07-03	WOS:001147804500045
J	Sosa, BR; Cung, M; Suhardi, VJ; Morse, K; Thomson, A; Yang, HS; Iyer, S; Greenblatt, MB				Sosa, Branden R.; Cung, Michelle; Suhardi, Vincentius J.; Morse, Kyle; Thomson, Andrew; Yang, He S.; Iyer, Sravisht; Greenblatt, Matthew B.			Capacity for large language model chatbots to aid in orthopedic management, research, and patient queries	JOURNAL OF ORTHOPAEDIC RESEARCH			English	Article						artificial intelligence; large language models; orthopedic		Large language model (LLM) chatbots possess a remarkable capacity to synthesize complex information into concise, digestible summaries across a wide range of orthopedic subject matter. As LLM chatbots become widely available they will serve as a powerful, accessible resource that patients, clinicians, and researchers may reference to obtain information about orthopedic science and clinical management. Here, we examined the performance of three well-known and easily accessible chatbots-ChatGPT, Bard, and Bing AI-in responding to inquiries relating to clinical management and orthopedic concepts. Although all three chatbots were found to be capable of generating relevant responses, ChatGPT outperformed Bard and BingAI in each category due to its ability to provide accurate and complete responses to orthopedic queries. Despite their promising applications in clinical management, shortcomings observed included incomplete responses, lack of context, and outdated information. Nonetheless, the ability for these LLM chatbots to address these inquires has largely yet to be evaluated and will be critical for understanding the risks and opportunities of LLM chatbots in orthopedics.	[Sosa, Branden R.; Cung, Michelle; Yang, He S.; Greenblatt, Matthew B.] Weill Cornell Med Coll, Dept Pathol & Lab Med, New York, NY 10065 USA; [Suhardi, Vincentius J.; Thomson, Andrew; Greenblatt, Matthew B.] Hosp Special Surg, Res Div, New York, NY USA; [Suhardi, Vincentius J.; Thomson, Andrew; Greenblatt, Matthew B.] Hosp Special Surg, Dept Orthoped Surg, New York, NY USA; [Morse, Kyle; Iyer, Sravisht] Hosp Special Surg, Dept Spine Surg, New York, NY 10021 USA	Cornell University; Weill Cornell Medicine	Greenblatt, MB (corresponding author), Weill Cornell Med Coll, Dept Pathol & Lab Med, New York, NY 10065 USA.; Iyer, S (corresponding author), Hosp Special Surg, Dept Spine Surg, New York, NY 10021 USA.	IyerS@hss.edu; mag3003@med.cornell.edu		Thomson, Andrew/0009-0003-2884-8353	Pershing Square Sohn Cancer Research Alliance; MIND Prize awards; Irma T. Hirschl Career Scientist Award [R01AR075585]; Burroughs Welcome Foundation; Kellen Scholars Program at HSS funded through the Marina Kellen French Foundation; National Institute of Arthritis and Musculoskeletal and Skin Diseases of the National Institutes of Health [T32-AR078751]	Pershing Square Sohn Cancer Research Alliance(Pershing Square Sohn Cancer Research Alliance); MIND Prize awards; Irma T. Hirschl Career Scientist Award; Burroughs Welcome Foundation(Burroughs Wellcome Fund); Kellen Scholars Program at HSS funded through the Marina Kellen French Foundation; National Institute of Arthritis and Musculoskeletal and Skin Diseases of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Arthritis & Musculoskeletal & Skin Diseases (NIAMS))	Matthew B. Greenblatt is supported by a Pershing Square Sohn Cancer Research Alliance and MIND Prize awards, an Irma T. Hirschl Career Scientist Award, NIH R01AR075585 and a Career Award for Medical Scientists from the Burroughs Welcome Foundation. Sravisht Iyer is supported by the Kellen Scholars Program at HSS funded through the Marina Kellen French Foundation. Kyle Morse was supported by the National Institute of Arthritis and Musculoskeletal and Skin Diseases of the National Institutes of Health under award number T32-AR078751. The content is solely the responsibility of the authors and does not represent the official views of the sources of research support.	Aggarwal VK, 2019, BONE JOINT J, V101B, P646, DOI 10.1302/0301-620X.101B6.BJJ-2018-1474.R1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Farr JN, 2017, NAT MED, V23, P1072, DOI 10.1038/nm.4385; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gomez Pablo F, 2005, Iowa Orthop J, V25, P25; Hui AT, 2022, JBJS REV, V10, DOI 10.2106/JBJS.RVW.22.00086; Janopaul-Naylor JR, 2024, AM J CLIN ONCOL-CANC, V47, P17, DOI 10.1097/COC.0000000000001050; Liu V, 2023, DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2023, P1955, DOI 10.1145/3563657.3596098; Loftus TJ, 2020, JAMA SURG, V155, P148, DOI 10.1001/jamasurg.2019.4917; Lyons Riley J, 2023, Can J Ophthalmol, DOI 10.1016/j.jcjo.2023.07.016; Maslej N., 2023, ARTIF INTELL; Megahed FM., 2023, ARXIV; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Shah Jay, 2014, Am J Robot Surg, V1, P12; Singhal K., 2023, EXPERT LEVEL MEDICAL; Touvron H., 2023, Llama: Open and efficient foundation language models	22	3	3	7	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0736-0266	1554-527X		J ORTHOP RES	J. Orthop. Res.	JUN	2024	42	6					1276	1282		10.1002/jor.25782	http://dx.doi.org/10.1002/jor.25782		JAN 2024	7	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	OR4T3	38245845				2024-07-03	WOS:001145720800001
J	Liévin, V; Hother, CE; Motzfeldt, AG; Winther, O				Lievin, Valentin; Hother, Christoffer Egeberg; Motzfeldt, Andreas Geert; Winther, Ole			Can large language models reason about medical questions?	PATTERNS			English	Article								Although large language models often produce impressive outputs, it remains unclear how they perform in real -world scenarios requiring strong reasoning skills and expert domain knowledge. We set out to investigate whether closed- and open -source models (GPT-3.5, Llama 2, etc.) can be applied to answer and reason about difficult real -world -based questions. We focus on three popular medical benchmarks (MedQA-US Medical Licensing Examination [USMLE], MedMCQA, and PubMedQA) and multiple prompting scenarios: chain of thought (CoT; think step by step), few shot, and retrieval augmentation. Based on an expert annotation of the generated CoTs, we found that InstructGPT can often read, reason, and recall expert knowledge. Last, by leveraging advances in prompt engineering (few -shot and ensemble methods), we demonstrated that GPT-3.5 not only yields calibrated predictive distributions but also reaches the passing score on three datasets: MedQA-USMLE (60.2%), MedMCQA (62.7%), and PubMedQA (78.2%). Open -source models are closing the gap: Llama 2 70B also passed the MedQA-USMLE with 62.5% accuracy.	[Lievin, Valentin; Motzfeldt, Andreas Geert; Winther, Ole] Tech Univ Denmark, Sect Cognit Syst, Anker Engelunds Vej 101, DK-2800 Lyngby, Denmark; [Lievin, Valentin; Winther, Ole] FindZebra, Radvadsvej 36, DK-2400 Copenhagen, Denmark; [Hother, Christoffer Egeberg] Copenhagen Univ Hosp, Dept Clin Immunol, Rigshosp, Inge Lehmanns Vej 107, DK-2100 Copenhagen, Denmark; [Winther, Ole] Copenhagen Univ Hosp, Ctr Genom Med, Rigshosp, Orestads Blvd 5, DK-2300 Copenhagen, Denmark; [Winther, Ole] Univ Copenhagen, Bioinformat Ctr, Dept Biol, Ole Maaloes Vej 5, DK-2200 Copenhagen, Denmark	Technical University of Denmark; Rigshospitalet; University of Copenhagen; University of Copenhagen; Rigshospitalet; University of Copenhagen	Liévin, V (corresponding author), Tech Univ Denmark, Sect Cognit Syst, Anker Engelunds Vej 101, DK-2800 Lyngby, Denmark.; Liévin, V (corresponding author), FindZebra, Radvadsvej 36, DK-2400 Copenhagen, Denmark.	valentin.lievin@gmail.com		Winther, Ole/0000-0002-1966-3205	Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science [NNF20OC0062606]; Pioneer Center for AI, DNRF	Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science(Novo Nordisk Foundation); Pioneer Center for AI, DNRF	<STRONG> </STRONG>We thank OpenAI for granting access to the Codex beta program. We acknowledge the EuroHPC Joint Undertaking for awarding us access to MeluXina at LuxProvide, Luxembourg. V.L.'s work was funded in part by Google DeepMind through a PhD grant. O.W.'s work was funded in partby the Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science (NNF20OC0062606) . V.L., A.G.M., and O.W. acknowledge support from the Pioneer Center for AI, DNRF grant number P1.r by the Novo Nordisk Foundation through the Center for Basic Machine Learning Research in Life Science (NNF20OC0062606) . V.L., A.G.M., and O.W. acknowledge support from the Pioneer Center for AI, DNRF grant num-ber P1.	Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Black S., 2022, PREPRINT; Borgeaud S, 2022, PR MACH LEARN RES; Brown T. B., 2020, Adv. Neural Inf. Process. Syst.; Chen M., 2021, arXiv; Chen ZM, 2023, Arxiv, DOI arXiv:2311.16079; Chowdhery A, 2023, J MACH LEARN RES, V24; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Fedus W, 2022, J MACH LEARN RES, V23; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jin Q, 2019, arXiv; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Karpukhin V, 2020, Arxiv, DOI [arXiv:2004.04906, 10.48550/arXiv.2004.04906]; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Laurencon H., 2022, Advances in Neural Information Processing Systems, V35, P31809; Lazaridou A, 2022, Arxiv, DOI arXiv:2203.05115; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li YF, 2023, Arxiv, DOI arXiv:2206.02336; Lie vin V., 2023, Vlievin/Medical-Reasoning: Official Release (Zenodo), DOI [10.5281/zenodo.10301874, DOI 10.5281/ZENODO.10301874]; Lieber O., 2021, White Paper. AI21 Labs, V1, P9; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Livin V., 2023, PMLR, P20950; Medenilla A., 2023, PLoS Digital Health, V2; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Nye Maxwell, 2021, arXiv; Oktay Ozan, 2018, PREPRINT, DOI [DOI 10.48550/ARXIV, 10.48550/arxiv]; Ott S, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02433-3; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pal A., 2022, C HLTH INFERENCE LEA, V174, P248; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2018, IMPROVING LANGUAGE U; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Smith S, 2022, arXiv; Suzgun Mirac, 2022, arXiv; Team M.N., 2023, Introducing Mpt-30b: Raising the Bar for Open-Source Foundation Models; Thoppilan R., 2022, LaMDA: Language; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang BX, 2022, Arxiv, DOI arXiv:2111.02840; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang YB, 2023, Arxiv, DOI arXiv:2309.02233; Wei JS, 2022, ADV NEUR IN; Yasunaga Michihiro, 2022, LinkBERT: Pretraining Language Models with Document Links; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]; 2022, Arxiv, DOI [arXiv:2209.15003, 10.48550/arXiv.2209.15003]	62	2	2	3	3	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	2666-3899			PATTERNS	Patterns	MAR 8	2024	5	3							100943	10.1016/j.patter.2024.100943	http://dx.doi.org/10.1016/j.patter.2024.100943		MAR 2024	12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NU3A2	38487804	Green Published, Green Submitted, gold			2024-07-03	WOS:001202916500001
J	Romano, MF; Shih, LC; Paschalidis, IC; Au, RD; Kolachalama, VB				Romano, Michael F.; Shih, Ludy C.; Paschalidis, Ioannis C.; Au, Rhoda; Kolachalama, Vijaya B.			Large Language Models in Neurology Research and Future Practice	NEUROLOGY			English	Article							CLASSIFICATION; GPT-4	Recent advancements in generative artificial intelligence, particularly using large language models (LLMs), are gaining increased public attention. We provide a perspective on the potential of LLMs to analyze enormous amounts of data from medical records and gain insights on specific topics in neurology. In addition, we explore use cases for LLMs, such as early diagnosis, supporting patient and caregivers, and acting as an assistant for clinicians. We point to the potential ethical and technical challenges raised by LLMs, such as concerns about privacy and data security, potential biases in the data for model training, and the need for careful validation of results. Researchers must consider these challenges and take steps to address them to ensure that their work is conducted in a safe and responsible manner. Despite these challenges, LLMs offer promising opportunities for improving care and treatment of various neurologic disorders.	[Romano, Michael F.; Au, Rhoda; Kolachalama, Vijaya B.] Boston Univ, Dept Med, Chobanian & Avedisian Sch Med, Boston, MA 02118, Brazil; [Romano, Michael F.] Univ Calif San Francisco, Dept Radiol & Biomed Imaging, San Francisco, CA USA; [Shih, Ludy C.; Au, Rhoda] Boston Univ, Dept Neurol, Chobanian & Avedisian Sch Med, Boston, MA USA; [Paschalidis, Ioannis C.] Boston Univ, Dept Elect & Comp Engn, Div Syst Engn, Boston, MA USA; [Paschalidis, Ioannis C.; Kolachalama, Vijaya B.] Boston Univ, Dept Biomed Engn, Boston, MA USA; [Paschalidis, Ioannis C.; Kolachalama, Vijaya B.] Boston Univ, Fac Comp & Data Sci, Boston, MA 02215 USA; [Au, Rhoda] Boston Univ, Chobanian & Avedisian Sch Med, Dept Anat & Neurobiol, Framingham Heart Study, Boston, MA USA; [Au, Rhoda] Boston Univ, Dept Epidemiol, Sch Publ Hlth, Boston, MA USA; [Au, Rhoda] Boston Univ, Alzheimers Dis Res Ctr, Boston, MA USA; [Kolachalama, Vijaya B.] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA	University of California System; University of California San Francisco; Boston University; Boston University; Boston University; Boston University; Boston University; Framingham Heart Study; Boston University; Boston University; Boston University	Kolachalama, VB (corresponding author), Boston Univ, Dept Med, Chobanian & Avedisian Sch Med, Boston, MA 02118, Brazil.; Kolachalama, VB (corresponding author), Boston Univ, Fac Comp & Data Sci, Boston, MA 02215 USA.; Kolachalama, VB (corresponding author), Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.	vkola@bu.edu	Kolachalama, Vijaya B./AAH-3528-2020	Kolachalama, Vijaya B./0000-0002-5312-8644; Au, Rhoda/0000-0001-7742-4491; Shih, Ludy/0000-0002-6590-8365; Paschalidis, Ioannis/0000-0002-3343-2913; Romano, Michael/0000-0002-7022-9252	Karen Toffler Charitable Trust; American Heart Association [20SFRN35460031]; NIH [RF1-AG062109, R01-HL159620, R21-CA253498, R43-DK134273, RF1-AG072654, U19-AG068753, P30-AG013846]; National Science Foundation [CCF-2200052, DMS-1664644, IIS-1914792]; National Institute on Aging's Artificial Intelligence and Technology Collaboratories (AITC) for Aging Research program	Karen Toffler Charitable Trust; American Heart Association(American Heart Association); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation(National Science Foundation (NSF)); National Institute on Aging's Artificial Intelligence and Technology Collaboratories (AITC) for Aging Research program	This project was supported by grants from the Karen Toffler Charitable Trust, the American Heart Association (20SFRN35460031), the NIH (RF1-AG062109, R01-HL159620, R21-CA253498, R43-DK134273, RF1-AG072654, U19-AG068753, and P30-AG013846), the National Science Foundation under grants CCF-2200052, DMS-1664644, and IIS-1914792, and a pilot award from the National Institute on Aging's Artificial Intelligence and Technology Collaboratories (AITC) for Aging Research program	Abbe A, 2016, INT J METH PSYCH RES, V25, P86, DOI 10.1002/mpr.1481; Agbavor Felix, 2022, PLOS Digit Health, V1, pe0000168, DOI 10.1371/journal.pdig.0000168; Almagro M, 2019, J BIOMED INFORM, V94, DOI 10.1016/j.jbi.2019.103207; Amini S, 2023, ALZHEIMERS DEMENT, V19, P946, DOI 10.1002/alz.12721; Aneja S, 2019, CURR OPIN NEUROL, V32, P850, DOI 10.1097/WCO.0000000000000761; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baldassano SN, 2019, EPILEPSY BEHAV, V101, DOI 10.1016/j.yebeh.2019.106457; Bazoukis G, 2022, CELL REP MED, V3, DOI 10.1016/j.xcrm.2021.100485; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Chai KEK, 2013, J AM MED INFORM ASSN, V20, P980, DOI 10.1136/amiajnl-2012-001409; Chen YP, 2021, J MED INTERNET RES, V23, DOI 10.2196/25113; Crema C, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.946387; Denecke K, 2023, J BIOMED INFORM, V140, DOI 10.1016/j.jbi.2023.104336; Devlin J., 2018, BERT PRE TRAINING DE; Dogra V, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1883698; Evans CS, 2023, ANN EMERG MED, V81, P262, DOI 10.1016/j.annemergmed.2022.08.450; Fernandes MB, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119171; Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Hao B., 2020, P 28 INT C COMP LING, P657, DOI [10.18653/v1/2020.coling-main.57, DOI 10.18653/V1/2020.COLING-MAIN.57]; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Kalyan KS, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103982; Kraljevic Z, 2021, ARTIF INTELL MED, V117, DOI 10.1016/j.artmed.2021.102083; Lai TM, 2023, J BIOMED INFORM, V143, DOI 10.1016/j.jbi.2023.104392; Laparra Egoitz, 2021, Yearb Med Inform, V30, P239, DOI 10.1055/s-0041-1726522; Le Glaz A, 2021, J MED INTERNET RES, V23, DOI 10.2196/15708; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lefkovitz I., 2023, Direct Clinical Applications of Natural Language Processing in Common Neurological Disorders: A Systematic Review (P5-4.005); Luz S., 2021, MEDRXIV; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; Nutter-Upham KE, 2008, ARCH CLIN NEUROPSYCH, V23, P229, DOI 10.1016/j.acn.2008.01.005; OpenAI, 2023, ArXiv; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Rezaii N, 2022, BRIT J PSYCHIAT, V220, P251, DOI 10.1192/bjp.2021.188; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Singhal K, 2023, NATURE, DOI 10.1038/s41586-023-06455-0; Spasic I, 2020, JMIR MED INF, V8, DOI 10.2196/17984; Thapa C, 2021, COMPUT BIOL MED, V129, DOI 10.1016/j.compbiomed.2020.104130; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Valsaraj A, 2021, INT CONF SOFT COMP, P171, DOI 10.1109/ISCMI53840.2021.9654804; Vats Nayan Anand, 2021, IC3 '21: 2021 Thirteenth International Conference on Contemporary Computing (IC3-2021), P267, DOI 10.1145/3474124.3474162; Xie K, 2022, J AM MED INFORM ASSN, V29, P873, DOI 10.1093/jamia/ocac018; Yew ANJ, 2023, EPILEPSIA, V64, P292, DOI 10.1111/epi.17474; Zhao WX, 2023, ARXIV	49	5	5	5	5	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0028-3878	1526-632X		NEUROLOGY	Neurology	DEC 5	2023	101	23					1058	1067		10.1212/WNL.0000000000207967	http://dx.doi.org/10.1212/WNL.0000000000207967			10	Clinical Neurology	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	Z2EX8	37816646	Green Published, hybrid			2024-07-03	WOS:001110273400014
C	de Wit, J		Folstad, A; Araujo, T; Papadopoulos, S; Law, ELC; Luger, E; Goodwin, M; Hobert, S; Brandtzaeg, PB		de Wit, Jan			Leveraging Large Language Models as Simulated Users for Initial, Low-Cost Evaluations of Designed Conversations	CHATBOT RESEARCH AND DESIGN, CONVERSATIONS 2023	Lecture Notes in Computer Science		English	Proceedings Paper	7th Conversations International Workshop (CONVERSATIONS)7th International Workshop on Chatbot Research and Design (CONVERSATIONS)	NOV 22-23, 2023NOV 22-23, 2023	Univ Oslo, Ctr Res Media Innovat, Oslo, NORWAYOslo, NORWAY	SINTEF, Univ Amsterdam, Ctr Res & Technol Hellas, Durham Univ, Univ Edinburgh, Lubeck Univ Technol, Univ Agder	Univ Oslo, Ctr Res Media Innovat	Conversational agents; Large language models; Automatic evaluation		In this paper, we explore the use of large language models, in this case the ChatGPT API, as simulated users to evaluate designed, rule-based conversations. This type of evaluation can be introduced as a low-cost method to identify common usability issues prior to testing conversational agents with actual users. Preliminary findings show that ChatGPT is good at playing the part of a user, providing realistic testing scenarios for designed conversations even if these involve certain background knowledge or context. GPT-4 shows vast improvements over ChatGPT (3.5). In future work, it is important to evaluate the performance of simulated users in a more structured, generalizable manner, for example by comparing their behavior to that of actual users. In addition, ways to fine-tune the LLM could be explored to improve its performance, and the output of simulated conversations could be analyzed to automatically derive usability metrics such as the number of turns needed to reach the goal. Finally, the use of simulated users with open-ended conversational agents could be explored, where the LLM may also be able to reflect on the user experience of the conversation.	[de Wit, Jan] Tilburg Univ, Dept Commun & Cognit, Warandelaan 2, NL-5037 AB Tilburg, Netherlands	Tilburg University	de Wit, J (corresponding author), Tilburg Univ, Dept Commun & Cognit, Warandelaan 2, NL-5037 AB Tilburg, Netherlands.	j.m.s.dewit@tilburguniversity.edu		de Wit, Jan/0000-0002-7299-7992				Afzali J., 2023, P 16 ACM INT C WEB S, P1160, DOI 10.1145/3539597.3573029; Akbar S, 2020, J AM MED INFORM ASSN, V27, P330, DOI 10.1093/jamia/ocz175; Allouch M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248448; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Bell G., 2005, ACM Transactions on Computer-Human Interaction, V12, P149, DOI 10.1145/1067860.1067862; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blythe M, 2014, PROCEEDINGS OF THE NORDICHI'14: THE 8TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION: FUN, FAST, FOUNDATIONAL, P227, DOI 10.1145/2639189.2641212; Bozic J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING (AITEST), P37, DOI 10.1109/AITest.2019.00-10; Bravo-Santos S., 2020, QUAL INF COMM TECHN, P426, DOI [10.1007/978- 3-030- 58793-2 34, DOI 10.1007/978-3-030-58793-234]; Cameron G., 2018, BRIT HCI C 2018; Cockton G., 2002, Interactions, V9, P13, DOI DOI 10.1145/566981.566990; Cowan BR, 2023, HUM-COMPUT INTERACT, V38, P159, DOI 10.1080/07370024.2022.2161905; Dall'Acqua A., 2021, IJCoL. Italian Journal of Computational Linguistics, V7, P191; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; de Wit J, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3604403; Desai S, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3603755; Deshpande A., 2023, arXiv; Diederich S, 2022, J ASSOC INF SYST, V23, P96, DOI 10.17705/1jais.00724; Eckert W, 1997, 1997 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, PROCEEDINGS, P80, DOI 10.1109/ASRU.1997.658991; Engelbrecht KP, 2009, SPEECH COMMUN, V51, P1234, DOI 10.1016/j.specom.2009.06.007; Folstad A., 2020, Quality and User Experience, V5, P3; Folstad A, 2021, COMPUTING, V103, P2915, DOI 10.1007/s00607-021-01016-7; Fuchs A, 2023, ACM T AUTON ADAP SYS, V18, DOI 10.1145/3580492; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Goes F., 2023, 14 INT C COMP CREAT; Guo F., 2017, P CONV AI WORKSH 31; Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331; Holmes S, 2019, PROCEEDINGS OF THE 31ST EUROPEAN CONFERENCE ON COGNITIVE ERGONOMICS: DESIGN FOR COGNITION (ECCE 2019), P207, DOI 10.1145/3335082.3335094; Horton J.J., 2023, NBER Working Paper 31122, DOI [DOI 10.3386/W31122, 10.3386/ w31122]; Janssen A., 2021, 42 INT C INF SYST IC; Keizer S., 2012, User Simulation in the Development of Statistical Spoken Dialogue Systems, P39, DOI [10.1007/978-1-4614-4803-7, DOI 10.1007/978-1-4614-4803-7]; Kicken M., 2022, CONVERSATIONS 2022 6; Kocaballi A.B., 2023, arXiv; Kojima T, 2022, ADV NEUR IN; Langevin R, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445312; Lewandowski T., 2022, Wirtschaftsinformatik 2022 Proceedings; Li X., 2017, ARXIV; Li Z., 2023, arXiv; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu C.W., 2017, arXiv; Liu H., 2022, arXiv; Liu YJ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1; Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103; McTear M., 2022, Conversational ai: Dialogue Systems, Conversational Agents, and Chatbots; Meyer S, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544529; Möller S, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1786; Murad C, 2019, IEEE PERVAS COMPUT, V18, P33, DOI 10.1109/MPRV.2019.2906991; Neustaedter C., 2012, P DES INT SYST C DIS, P514, DOI [10.1145/2317956.2318034, DOI 10.1145/2317956.2318034]; Nielsen J, 1993, International technical guidance on sexuality education: An evidence-informed approach; Paoli S.D., 2023, arXiv; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radziwill NM., 2017, ARXIV PREPRINT ARXIV, V19, P25, DOI 10.48550/arXiv.1704.04579; Sadek M, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3597143; Sambasivan N, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P315, DOI 10.1145/3442188.3445896; Schatzmann J, 2006, KNOWL ENG REV, V21, P97, DOI 10.1017/S0269888906000944; Silva GRS, 2024, INT J HUM-COMPUT INT, V40, P98, DOI 10.1080/10447318.2022.2118244; Sugisaki Kyoko, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P309, DOI 10.1145/3404983.3405505; Tao CY, 2018, AAAI CONF ARTIF INTE, P722; Urban M, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3298821; van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151; Vasconcelos Marisa., 2017, P 16 BRAZILIAN S HUM, P1, DOI DOI 10.1145/3160504.3160584; White J., 2023, arXiv; Wilson C., 2006, Interactions, V13, P46, DOI 10.1145/1167948.1167980; Wilson C., 2013, User Interface Inspection Methods"; Yoonseo Choi, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3432924	65	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-54974-8; 978-3-031-54975-5	LECT NOTES COMPUT SC			2024	14524						77	93		10.1007/978-3-031-54975-5_5	http://dx.doi.org/10.1007/978-3-031-54975-5_5			17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9FF					2024-07-03	WOS:001212393500005
J	Moro, A; Greco, M; Cappa, SF				Moro, Andrea; Greco, Matteo; Cappa, Stefano F.			Large languages, impossible languages and human brains	CORTEX			English	Editorial Material						Large Language Models; Impossible Languages		We aim at offering a contribution to highlight the essential differences between Large Language Models (LLM) and the human language faculty. More explicitly, we claim that the existence of impossible languages for humans does not have any equivalent for LLM making them unsuitable models of the human language faculty, especially for a neurobiological point of view. The core part is preceded by two premises bearing on the distinction between machines and humans and the distinction between competence and performance. (c) 2023 Elsevier Ltd. All rights reserved.	[Moro, Andrea; Greco, Matteo; Cappa, Stefano F.] Scuola Univ Super IUSS, Pavia, Italy; [Cappa, Stefano F.] IRCCS Mondino Fdn, Pavia, Italy; [Cappa, Stefano F.] IRCCS Mondino Fdn, Via Mondino 2, I-27100 Pavia, Italy	IUSS PAVIA; IRCCS Fondazione Casimiro Mondino; IRCCS Fondazione Casimiro Mondino	Cappa, SF (corresponding author), IRCCS Mondino Fdn, Via Mondino 2, I-27100 Pavia, Italy.	stefano.cappa@iusspavia.it	; cappa, stefano/B-1874-2014	greco, matteo/0000-0002-6144-8015; cappa, stefano/0000-0003-1003-3925; moro, andrea/0000-0002-6602-5871				[Anonymous], 1966, Cartesian Linguistics; Berwick RC, 2016, WHY ONLY US: LANGUAGE AND EVOLUTION, P1; Cappa SF, 2012, NEUROIMAGE, V61, P427, DOI 10.1016/j.neuroimage.2011.10.006; Chao ZC, 2018, NEURON, V100, P1252, DOI 10.1016/j.neuron.2018.10.004; Chomsky N, 2005, LINGUIST INQ, V36, P1, DOI 10.1162/0024389052993655; Chomsky N., 2022, The Secrets of Words; Descartes Rene., 2006, A Discourse on the Method; Embick D., 2006, Encyclopedia of Language and Linguistics, V2nd, P484; Everaert M., 2008, BLACKWELL COMPANION; Friederici AD, 2017, NAT HUM BEHAV, V1, P713, DOI 10.1038/s41562-017-0184-4; Greco Matteo., 2023, Frontiers in Language Sciences, V2, DOI [10.3389/flang.2023.1178932, DOI 10.3389/FLANG.2023.1178932]; Jonas E, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005268; Katzir R., 2023, WHY LARGE LANG UNPUB; Lampinen AK, 2022, Arxiv, DOI [arXiv:2210.15303, DOI 10.48550/ARXIV.2210.15303]; Lakretz Y, 2021, COGNITION, V213, DOI 10.1016/j.cognition.2021.104699; Lenneberg E.H., 1967, BIOL FDN LANGUAGE; Lorusso P., 2019, P 6 ITALIAN C COMPUT; Magrassi L, 2015, P NATL ACAD SCI USA, V112, P1868, DOI 10.1073/pnas.1418162112; Mehler J., 2002, NAITRE HUMAIN; Moro A, 2016, IMPOSSIBLE LANGUAGES, P1, DOI 10.7551/mitpress/9780262034890.001.0001; Moro A. C., 2023, SISTEMI INTELLIGENTI, V2; Musso M, 2003, NAT NEUROSCI, V6, P774, DOI 10.1038/nn1077; Nelson MJ, 2017, P NATL ACAD SCI USA, V114, pE3669, DOI 10.1073/pnas.1701590114; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Tettamanti M, 2002, NEUROIMAGE, V17, P700, DOI 10.1006/nimg.2002.1201; Vaswani A, 2017, ADV NEUR IN, V30; Yamins DLK, 2014, P NATL ACAD SCI USA, V111, P8619, DOI 10.1073/pnas.1403112111; Zacharopoulos C.-N., 2022, BIORXIV	28	2	2	21	53	ELSEVIER MASSON, CORP OFF	PARIS	65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE	0010-9452	1973-8102		CORTEX	Cortex	OCT	2023	167						82	85		10.1016/j.cortex.2023.07.003	http://dx.doi.org/10.1016/j.cortex.2023.07.003		AUG 2023	4	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	P7FU2	37540953				2024-07-03	WOS:001052303200001
J	Miao, J; Thongprayoon, C; Suppadungsuk, S; Valencia, OAG; Cheungpasitporn, W				Miao, Jing; Thongprayoon, Charat; Suppadungsuk, Supawadee; Valencia, Oscar A. Garcia; Cheungpasitporn, Wisit			Integrating Retrieval-Augmented Generation with Large Language Models in Nephrology: Advancing Practical Applications	MEDICINA-LITHUANIA			English	Review						large language models (LLMs); nephrology; chronic kidney disease; artificial intelligence; retrieval-augmented generation (RAG)	CHATGPT; PERFORMANCE; GPT-4; AI	The integration of large language models (LLMs) into healthcare, particularly in nephrology, represents a significant advancement in applying advanced technology to patient care, medical research, and education. These advanced models have progressed from simple text processors to tools capable of deep language understanding, offering innovative ways to handle health-related data, thus improving medical practice efficiency and effectiveness. A significant challenge in medical applications of LLMs is their imperfect accuracy and/or tendency to produce hallucinations-outputs that are factually incorrect or irrelevant. This issue is particularly critical in healthcare, where precision is essential, as inaccuracies can undermine the reliability of these models in crucial decision-making processes. To overcome these challenges, various strategies have been developed. One such strategy is prompt engineering, like the chain-of-thought approach, which directs LLMs towards more accurate responses by breaking down the problem into intermediate steps or reasoning sequences. Another one is the retrieval-augmented generation (RAG) strategy, which helps address hallucinations by integrating external data, enhancing output accuracy and relevance. Hence, RAG is favored for tasks requiring up-to-date, comprehensive information, such as in clinical decision making or educational applications. In this article, we showcase the creation of a specialized ChatGPT model integrated with a RAG system, tailored to align with the KDIGO 2023 guidelines for chronic kidney disease. This example demonstrates its potential in providing specialized, accurate medical advice, marking a step towards more reliable and efficient nephrology practices.	[Miao, Jing; Thongprayoon, Charat; Suppadungsuk, Supawadee; Valencia, Oscar A. Garcia; Cheungpasitporn, Wisit] Dept Med, Div Nephrol & Hypertens, Mayo Clin, Rochester, MN 55905 USA; [Suppadungsuk, Supawadee] Mahidol Univ, Ramathibodi Hosp, Chakri Naruebodindra Med Inst, Fac Med, Samut Prakan 10540, Thailand	Mayo Clinic; Mahidol University	Cheungpasitporn, W (corresponding author), Dept Med, Div Nephrol & Hypertens, Mayo Clin, Rochester, MN 55905 USA.	miao.jing@mayo.edu; charat.thongprayoon@gmail.com; s.suppadungsuk@hotmail.com; garciavalencia.oscar@mayo.edu; wcheungpasitporn@gmail.com	Miao, Jing/IWE-2159-2023; Miao, Jing/IWE-2204-2023	Miao, Jing/0000-0003-0642-9740; Suppadungsuk, Supawadee/0000-0003-1597-2411; Cheungpasitporn, Wisit/0000-0001-9954-9711; Garcia Valencia, Oscar/0000-0003-0186-9448				Abdelhady AM., 2023, Mayo Clinic Proceedings: Digital Health, V1, P299; Aiumtrakul N, 2024, J PERS MED, V14, DOI 10.3390/jpm14010107; Aiumtrakul N, 2023, J PERS MED, V13, DOI 10.3390/jpm13101457; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baker HP, 2024, J AM ACAD ORTHOP SUR, V32, P123, DOI 10.5435/JAAOS-D-23-00474; Bard, About us; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chau Reinhard Chun Wang, 2024, Int Dent J, V74, P616, DOI 10.1016/j.identj.2023.12.007; Decker H, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36997; Deebel NA, 2023, UROLOGY, V177, P29, DOI 10.1016/j.urology.2023.05.010; Dumitru M, 2022, MEDICINA-LITHUANIA, V58, DOI 10.3390/medicina58111530; Eriksen AV., 2023, NEJM AI, V1, DOI [DOI 10.1056/AIP2300031, 10.1056/AIp2300031]; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ge J., 2023, medRxiv, DOI [10.1097/HEP.0000000000000834, DOI 10.1097/HEP.0000000000000834]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Guo Y, 2024, J BIOMED INFORM, V149, DOI 10.1016/j.jbi.2023.104580; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Jamal Amr, 2023, Cureus, V15, pe43036, DOI 10.7759/cureus.43036; Joshi G, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13030498; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; KDIGO, 2023, clinical practice guideline for the evaluation and management of chronic kidney disease (PUBLIC REVIEW DRAFT); King MR, 2023, CELL MOL BIOENG, V16, P175, DOI 10.1007/s12195-023-00761-3; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lai UH, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1240915; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li DJ, 2024, PSYCHIAT CLIN NEUROS, DOI 10.1111/pcn.13656; Luu RK, 2024, ADV SCI, V11, DOI 10.1002/advs.202306724; Majnaric LT, 2021, J CLIN MED, V10, DOI 10.3390/jcm10040766; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Mayo M., Unraveling the Power of Chain-of-Thought Prompting in Large Language Models; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Merritt R., What Is Retrieval-Augmented Generation, Aka RAG?; Metze Konradin, 2024, J Pediatr Surg, V59, P158, DOI 10.1016/j.jpedsurg.2023.08.018; Meyer A, 2024, JMIR MED EDUC, V10, DOI 10.2196/50965; Miao J, 2024, MEDICINA-LITHUANIA, V60, DOI 10.3390/medicina60010148; Miao J, 2023, J PERS MED, V13, DOI 10.3390/jpm13121681; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; Michael Kerner S., Large Language Models (LLMs); microsoft, Bing Chat with GPT-4; Mihalache A, 2024, MED TEACH, V46, P366, DOI 10.1080/0142159X.2023.2249588; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; openai, INTRO CHATGPT; openai, OpenAI GPT-4V(ision) System Card; Ott S, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02433-3; Qarajeh A, 2023, CLINICS PRACT, V13, P1160, DOI 10.3390/clinpract13050104; Ramlochan S., Master Prompting Concepts: Zero-Shot and Few-Shot Prompting; Reese JT, 2024, medRxiv, DOI [10.1101/2023.07.13.23292613, 10.1101/2023.07.13.23292613, DOI 10.1101/2023.07.13.23292613]; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sakai D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.49903; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shah D., The Beginner's Guide to Hallucinations in Large Language Models; Shin E, 2024, J PHARMACOKINET PHAR, V51, P101, DOI 10.1007/s10928-023-09892-6; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Su MC, 2024, INT J NURS STUD, V153, DOI 10.1016/j.ijnurstu.2024.104717; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Suppadungsuk S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12175550; Tanaka Yudai, 2024, PLOS Digit Health, V3, pe0000433, DOI 10.1371/journal.pdig.0000433; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Unlu O, 2024, medRxiv, DOI [10.1101/2024.02.08.24302376, 10.1101/2024.02.08.24302376, DOI 10.1101/2024.02.08.24302376]; Wadhwa S, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15566, DOI 10.18653/v1/2023.acl-long.868; Wagner MW, 2024, CAN ASSOC RADIOL J, V75, P69, DOI 10.1177/08465371231171125; Wang Andrew Y, 2024, Arch Pathol Lab Med, DOI 10.5858/arpa.2023-0296-OA; Wang CL, 2024, ANN BIOMED ENG, V52, P1115, DOI 10.1007/s10439-023-03327-6; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wójcik S, 2023, CARDIOL J, DOI 10.5603/cj.97517; Wolff T., How to Craft Prompts for Maximum Effectiveness; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Zakka C., 2024, NEJM AI, V1, DOI 10.1056/AIoa2300068; Zakka Cyril, 2024, NEJM AI, V1, DOI 10.1056/aioa2300068; Zong H, 2024, BMC MED EDUC, V24, DOI 10.1186/s12909-024-05125-7	76	3	3	44	44	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1010-660X	1648-9144		MEDICINA-LITHUANIA	Med. Lith.	MAR	2024	60	3							445	10.3390/medicina60030445	http://dx.doi.org/10.3390/medicina60030445			15	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	MG7G0	38541171	gold			2024-07-03	WOS:001192531600001
J	Francl, M				Francl, Michelle			ChatGPT saves the day	NATURE CHEMISTRY			English	Editorial Material								Large language models such as ChatGPT have been predicted to lighten the load for some workers but make some roles obsolete. Michelle Francl explores what they can do for chemistry professors.	[Francl, Michelle] Bryn Mawr Coll, Dept Chem, Bryn Mawr, PA 19010 USA; [Francl, Michelle] Vatican Observ, Vatican City, Vatican City St, Vatican	Bryn Mawr College; Vatican Observatory	Francl, M (corresponding author), Bryn Mawr Coll, Dept Chem, Bryn Mawr, PA 19010 USA.; Francl, M (corresponding author), Vatican Observ, Vatican City, Vatican City St, Vatican.	mfrancl@brynmawr.edu						Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Felten EW., 2023, SSRN, DOI [10.2139/ssrn.4414065, DOI 10.2139/SSRN.4414065]; Humphry T, 2023, J CHEM EDUC, V100, P1434, DOI 10.1021/acs.jchemed.3c00006; Leon AJ, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-qpzx3, 10.26434/chemrxiv-2023-qpzx3, DOI 10.26434/CHEMRXIV-2023-QPZX3]; MCLAUGHLIN GH, 1969, J READING, V12, P639; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285	6	3	3	13	39	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1755-4330	1755-4349		NAT CHEM	Nat. Chem.	JUL	2023	15	7					890	891		10.1038/s41557-023-01253-7	http://dx.doi.org/10.1038/s41557-023-01253-7		JUN 2023	2	Chemistry, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	L4JQ6	37337114				2024-07-03	WOS:001014982400002
C	Korcz, M; Plaskowski, D; Politycki, M; Stefanowski, J; Terentowicz, A		Morales, GD; Perlich, C; Ruchansky, N; Kourtellis, N; Baralis, E; Bonchi, F		Korcz, Marcin; Plaskowski, Dawid; Politycki, Mateusz; Stefanowski, Jerzy; Terentowicz, Alex			PIQARD System for Experimenting and Testing Language Models with Prompting Strategies	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES: APPLIED DATA SCIENCE AND DEMO TRACK, ECML PKDD 2023, PT VII	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 18-22, 2023	Turin, ITALY	CENTAI, Politecnico Torino, AFC Digital Hub, ASML, ThermoFisher Sci, Volkswagen Grp, AstraZeneca, CRITEO, Google, Mercari, Bosch, KNIME, SoBigData, Two Sigma, SIG Susquehanna		Large language models; Prompting; Information retrieval		Large Language Models (LLMs) have seen a surge in popularity due to their impressive results in natural language processing tasks, but there are still challenges to be addressed. Prompting in the question is a solution for some of them. In this paper, we present PIQARD, an open-source Python library that allows researchers to experiment with prompting techniques and information retrieval, and combine them with LLMs. This library includes pre-implemented components and also allows users to integrate their own methods.	[Korcz, Marcin; Plaskowski, Dawid; Politycki, Mateusz; Stefanowski, Jerzy; Terentowicz, Alex] Poznan Univ Tech, Inst Comp Sci, Poznan, Poland	Poznan University of Technology	Terentowicz, A (corresponding author), Poznan Univ Tech, Inst Comp Sci, Poznan, Poland.	jstefanowski@cs.put.poznan.pl; alex.terentowicz@gmail.com		Stefanowski, Jerzy/0000-0002-4949-8271	 [SBAD/0740]		The research was partially supported by SBAD/0740 grant.	[Anonymous], OpenAI GPT-4 Technical Report; Chase H., 2022, Langchain; Reppert J, 2023, Arxiv, DOI arXiv:2301.01751	3	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-43429-7; 978-3-031-43430-3	LECT NOTES ARTIF INT			2023	14175						320	323		10.1007/978-3-031-43430-3_23	http://dx.doi.org/10.1007/978-3-031-43430-3_23			4	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WF					2024-07-03	WOS:001156145400026
C	MacNeil, S; Denny, P; Tran, A; Leinonen, J; Bernstein, S; Hellas, A; Sarsa, S; Kim, J			ACM	MacNeil, Stephen; Denny, Paul; Tran, Andrew; Leinonen, Juho; Bernstein, Seth; Hellas, Arto; Sarsa, Sami; Kim, Joanne			Decoding Logic Errors: A Comparative Study on Bug Detection by Students and Large Language Models	PROCEEDINGS OF THE 26TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2024			English	Proceedings Paper	26th Australasian Computing Education Conference (ACE)	JAN 29-FEB 02, 2024	Sydney, AUSTRALIA			large language models; generative AI; programming errors; bug; detection; computing education		Identifying and resolving logic errors can be one of the most frustrating challenges for novices programmers. Unlike syntax errors, for which a compiler or interpreter can issue a message, logic errors can be subtle. In certain conditions, buggy code may even exhibit correct behavior - in other cases, the issue might be about how a problem statement has been interpreted. Such errors can be hard to spot when reading the code, and they can also at times be missed by automated tests. There is great educational potential in automatically detecting logic errors, especially when paired with suitable feedback for novices. Large language models (LLMs) have recently demonstrated surprising performance for a range of computing tasks, including generating and explaining code. These capabilities are closely linked to code syntax, which aligns with the next token prediction behavior of LLMs. On the other hand, logic errors relate to the runtime performance of code and thus may not be as well suited to analysis by LLMs. To explore this, we investigate the performance of two popular LLMs, GPT-3 and GPT-4, for detecting and providing a novice-friendly explanation of logic errors. We compare LLM performance with a large cohort of introductory computing students (.. = 964) solving the same error detection task. Through a mixed-methods analysis of student and model responses, we observe significant improvement in logic error identification between the previous and current generation of LLMs, and find that both LLM generations significantly outperform students. We outline how such models could be integrated into computing education tools, and discuss their potential for supporting students when learning programming.	[MacNeil, Stephen; Tran, Andrew; Bernstein, Seth; Kim, Joanne] Temple Univ, Philadelphia, PA 19122 USA; [Denny, Paul; Leinonen, Juho] Univ Auckland, Auckland, New Zealand; [Hellas, Arto; Sarsa, Sami] Aalto Univ, Espoo, Finland	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; University of Auckland; Aalto University	MacNeil, S (corresponding author), Temple Univ, Philadelphia, PA 19122 USA.	stephen.macneil@temple.edu; paul@cs.auckland.ac.nz; andrew.tran10@temple.edu; juho.leinonen@auckland.ac.nz; seth.bernstein@temple.edu; arto.hellas@aalto.fi; sami.sarsa@aalto.fi; joanne.kim@temple.edu	MacNeil, Stephen/HPH-0843-2023; Leinonen, Juho/D-2162-2018	MacNeil, Stephen/0000-0003-2781-6619; Leinonen, Juho/0000-0001-6829-9449	Ulla Tuominen Foundation	Ulla Tuominen Foundation	We are grateful for the grant from the Ulla Tuominen Foundation to Juho Leinonen.	Alqadi BS, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P15, DOI 10.1145/3017680.3017761; Altadmri A., 2015, P 46 ACM TECHN S COM, P522, DOI DOI 10.1145/2676723.2677258; Arora S, 2022, Arxiv, DOI [arXiv:2210.02441, arXiv:2210.02441]; Beck Joseph E., 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P431, DOI 10.1007/978-3-642-39112-5_44; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Brown NCC, 2017, ACM T COMPUT EDUC, V17, DOI 10.1145/2994154; Brown Neil CC, 2014, Proceedings of the Tenth Annual Conference on International Computing Education Research. ICER'14, P43; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Denny P, 2023, Arxiv, DOI arXiv:2307.16364; Denny P, 2023, Arxiv, DOI arXiv:2306.02608; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Denny Paul, 2012, P 17 ACM ANN C INNOV, P75, DOI DOI 10.1145/2325296.2325318; Denny Paul, 2021, PROC 2021 CHI C HUMA, P1; Ettles Andrew, 2018, P 20 AUSTR COMP ED C, P83, DOI 10.1145/3160489.3160493; Fan ZY, 2023, PROC INT CONF SOFTW, P1469, DOI 10.1109/ICSE48619.2023.00128; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Fitzgerald S, 2008, COMPUT SCI EDUC, V18, P93, DOI 10.1080/08993400802114508; Glassman EL, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2699751; Heinonen A, 2023, INFORM SOFTWARE TECH, V164, DOI 10.1016/j.infsof.2023.107300; Hellas A, 2023, Arxiv, DOI arXiv:2306.05715; Hou Irene, 2024, AUSTRALASIAN COMPUTI; Hou IY, 2023, Arxiv, DOI arXiv:2311.04926; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Kabir S, 2024, Arxiv, DOI [arXiv:2308.02312, DOI 10.48550/ARXIV.2308.02312]; Kohn T, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P524, DOI 10.1145/3287324.3287381; Koivisto Teemu, 2022, 2022 IEEE FRONTIERS, P1; Koutcheme Charles, 2023, Artificial Intelligence in Education: 24th International Conference, AIED 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13916), P798, DOI 10.1007/978-3-031-36272-9_74; Lau S, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P106, DOI 10.1145/3568813.3600138; Leinonen J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P124, DOI 10.1145/3587102.3588785; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Lewis Johnson W., 1983, Technical Report; Lister R., 2004, SIGCSE Bulletin, V36, P119, DOI 10.1145/1041624.1041673; Lister R, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P161, DOI 10.1145/1595496.1562930; MacNeil S., 2022, P ACM TECHN S COMP S, P1255, DOI DOI 10.1145/3545947.3573358; MacNeil Stephen, 2023, P 54 ACM TECHNICAL S, V2, P1176, DOI DOI 10.1145/3545947.3569630; MacNeil Stephen, 2023, PROC SIGCSE 23; Malysheva Yana, 2020, 2020 CHI C HUMAN FAC, P1; McCall D, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3335814; McCracken M., 2001, ACM SIGCSE Bull., V33, P125, DOI [DOI 10.1145/572139.572181, 10.1145/572133.572137, DOI 10.1145/572133.572137, 10.1145/]; Murphy L, 2008, SIGCSE'08: PROCEEDINGS OF THE 39TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P163, DOI 10.1145/1352322.1352191; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prather J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL. 2, P561, DOI 10.1145/3587103.3594206; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI [arXiv:2303.09325, DOI 10.48550/ARXIV.2303.09325]; Savelka J, 2023, Arxiv, DOI [arXiv:2303.08033, DOI 10.48550/ARXIV.2303.08033]; Savelka Jaromir, 2023, 19 ACM C INT COMPUTI; Seppala Otto, 2015, P 15 KOL CALL C COMP, P87; Si CL, 2023, Arxiv, DOI arXiv:2210.09150; Smith R, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P538, DOI 10.1145/3287324.3287394; SOLOWAY E, 1983, COMMUN ACM, V26, P853, DOI 10.1145/182.358436; Soloway Elliot, 1982, Directions in human-computer interaction, V6, P27; SPOHRER JC, 1986, COMMUN ACM, V29, P624, DOI 10.1145/6138.6145; Teebagy Sean, 2023, medRxiv; Tran Andrew, 2023, PROC 2023 ACM C INT, V1, P563, DOI [10.1145/3568812.3603482, DOI 10.1145/3568812.3603482]; Vainio V, 2007, ITICSE 2007: 12TH ANNUAL CONFERENCE ON INNOVATION & TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P236, DOI 10.1145/1269900.1268853; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830; Whalley Jacqueline, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P73, DOI 10.1145/3408877.3432374; Whalley Jacqueline, 2007, Bull. of Applied Computing and Information Technology; Whalley Jacqueline L., 2006, ACE '06, V52, P243; Winikoff M, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P301; Zastudil C, 2023, Arxiv, DOI arXiv:2308.04309; Zhao TZ, 2021, PR MACH LEARN RES, V139	63	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1619-5				2024							11	18		10.1145/3636243.3636245	http://dx.doi.org/10.1145/3636243.3636245			8	Computer Science, Software Engineering; Computer Science, Theory & Methods; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW5RQ		hybrid, Green Submitted			2024-07-03	WOS:001166861800002
J	Ma, XL; Zhao, RQ; Liu, Y; Deng, CJ; Du, DQ				Ma, Xiaoliang; Zhao, RuQiang; Liu, Ying; Deng, Congjian; Du, Dequan			Design of a large language model for improving customer service in telecom operators	ELECTRONICS LETTERS			English	Article						artificial intelligence; natural language processing; neural nets		Telecommunications operators are tasked with enhancing service quality, reducing operational costs, and preserving customer privacy. This study presents an innovative application of large language models (LLMs) integrated with the LangChain technology framework, aimed at revolutionizing customer service in the telecom sector. The LangChain framework features a Knowledge Organizing Module and a Knowledge Search Module, both designed to refine customer support operations. The research develops an LLM-based approach to improve the segmentation and organization of knowledge bases, tailored for the telecommunications industry. This approach ensures seamless integration with existing LLMs while preserving distinct knowledge domains, crucial for search accuracy. Additionally, the framework includes an advanced information security protocol with a robust filtering system that effectively excludes sensitive data from the model's outputs, enhancing data security. Empirical findings indicate that the ChatGLM2-6B+LangChain model outperforms the baseline ChatGLM2, demonstrating heightened effectiveness in telecom-specific tasks and outstripping even more sophisticated models like GPT-4. The implementation of this LLM-based framework within telecom customer service systems has significantly sharpened the precision of knowledge recommendations, as reflected by a dramatic increase in acceptance rates from 15% to 70%. This study addresses the inefficiencies of traditional customer service systems in telecom operations, which need help with timely data retrieval and precision. A customized large language model (LLM) is developed using the LangChain framework tailored for telecom customer service. The model's performance is further enhanced through reinforcement learning, significantly reducing the dissemination of incorrect information. The experimental findings demonstrate a substantial increase in the acceptance rate of the model's recommendations, from 15% to 70%, indicating its efficacy and reliability in environments with limited resources. image	[Ma, Xiaoliang] Xian Elect Technol Univ, Xian, Peoples R China; [Ma, Xiaoliang; Liu, Ying; Du, Dequan] China Telecom Corp, Guangzhou Branch, Guangzhou, Peoples R China; [Ma, Xiaoliang; Zhao, RuQiang; Liu, Ying; Deng, Congjian; Du, Dequan] Ma Xiaoliang Innovat Studio Model Workers & Creat, Guangzhou, Peoples R China; [Zhao, RuQiang; Deng, Congjian] YuNqu Technol, Guangzhou, Peoples R China	China Telecom Corp. Ltd.	Liu, Y (corresponding author), China Telecom Corp, Guangzhou Branch, Guangzhou, Peoples R China.; Liu, Y (corresponding author), Ma Xiaoliang Innovat Studio Model Workers & Creat, Guangzhou, Peoples R China.	liuying2.gd@chinatelecom.cn						Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Cavoukian A., 2010, Privacy by Design: The 7 Foundational Principles Revised: Oktober 2010; Chen HC, 2012, MIS QUART, V36, P1165; Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042; Floridi L, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2016.0360; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Huang Zhiheng, 2015, Bidirectional lstm-crf models for sequence tagging; Kumar V, 2016, J MARKETING, V80, P36, DOI 10.1509/jm.15.0414; Mittelstadt BD, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716679679; Pandya K, 2023, Arxiv, DOI arXiv:2310.05421; Pascanu R., 2013, INT C MACHINE LEARNI, V28, P1310, DOI DOI 10.5555/3042817.3043083; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Spinelli I, 2020, Arxiv, DOI arXiv:1905.01907; Vaswani A, 2017, ADV NEUR IN, V30; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Zhang Y., 2019, IEEE Access, V7, P151607; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536	20	0	0	7	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0013-5194	1350-911X		ELECTRON LETT	Electron. Lett.	MAY	2024	60	10							e13218	10.1049/ell2.13218	http://dx.doi.org/10.1049/ell2.13218			7	Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	RI2C4		Green Submitted, gold			2024-07-03	WOS:001226959700001
C	Fu, YG; Zhang, YG; Yu, ZZ; Li, SX; Ye, ZF; Li, CJ; Wan, C; Lin, YY			IEEE	Fu, Yonggan; Zhang, Yongan; Yu, Zhongzhi; Li, Sixu; Ye, Zhifan; Li, Chaojian; Wan, Cheng; Lin, Yingyan (Celine)			GPT4AIGChip: Towards Next-Generation AI Accelerator Design Automation via Large Language Models	2023 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD	ICCAD-IEEE ACM International Conference on Computer-Aided Design		English	Proceedings Paper	42nd IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	OCT 28-NOV 02, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, Cadence, Synopsys, Futurewei Technologies, AMD, EMPYREAN, DoraHacks, Singular Med, JP Morgan Chase & Co		AI Accelerators; Design Automation; Large Language Models		The remarkable capabilities and intricate nature of Artificial Intelligence (AI) have dramatically escalated the imperative for specialized AI accelerators. Nonetheless, designing these accelerators for various AI workloads remains both labor- and time-intensive. While existing design exploration and automation tools can partially alleviate the need for extensive human involvement, they still demand substantial hardware expertise, posing a barrier to non-experts and stifling AI accelerator development. Motivated by the astonishing potential of large language models (LLMs) for generating high-quality content in response to human language instructions, we embark on this work to examine the possibility of harnessing LLMs to automate AI accelerator design. Through this endeavor, we develop GPT4AIGChip, a framework intended to democratize AI accelerator design by leveraging human natural languages instead of domain-specific languages. Specifically, we first perform an in-depth investigation into LLMs' limitations and capabilities for AI accelerator design, thus aiding our understanding of our current position and garnering insights into LLM-powered automated AI accelerator design. Furthermore, drawing inspiration from the above insights, we develop a framework called GPT4AIGChip, which features an automated demo-augmented prompt-generation pipeline utilizing in-context learning to guide LLMs towards creating high-quality AI accelerator design. To our knowledge, this work is the first to demonstrate an effective pipeline for LLM-powered automated AI accelerator generation. Accordingly, we anticipate that our insights and framework can serve as a catalyst for innovations in next-generation LLM-powered design automation tools.	[Fu, Yonggan; Zhang, Yongan; Yu, Zhongzhi; Li, Sixu; Ye, Zhifan; Li, Chaojian; Wan, Cheng; Lin, Yingyan (Celine)] Georgia Inst Technol, Sch Comp Sci, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Fu, YG (corresponding author), Georgia Inst Technol, Sch Comp Sci, Atlanta, GA 30332 USA.	yfu314@gatech.edu; yzhang919@gatech.edu; zyu401@gatech.edu; sli941@gatech.edu; zye327.cli851@gatech.edu; cli851@gatech.edu; cwan39@gatech.edu; celine.lin@gatech.edu	Li, Sixu/GVS-8925-2022	Li, Sixu/0000-0002-9105-9299	National Science Foundation (NSF) through the CCRI program [2016727]; NSF CAREER award [2048183]; DARPA	National Science Foundation (NSF) through the CCRI program(National Science Foundation (NSF)); NSF CAREER award(National Science Foundation (NSF)NSF - Office of the Director (OD)); DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	The work is supported by the National Science Foundation (NSF) through the CCRI program (Award number: 2016727), an NSF CAREER award (Award number: 2048183), and CoCoSys, one of the seven centers in JUMP 2.0, a Semiconductor Research Corporation (SRC) program sponsored by DARPA.	Ahmad B, 2023, Arxiv, DOI [arXiv:2302.01215, 10.48550/arXiv.2302.01215]; [Anonymous], VITIS HIGH LEVEL SYN; [Anonymous], Ds891-zynq-ultrascale-plus-overview; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chan SCY, 2022, Arxiv, DOI [arXiv:2205.05055, DOI 10.48550/ARXIV.2205.05055]; Chen A, 2024, Arxiv, DOI arXiv:2303.16749; Chen M., 2021, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fu YG, 2021, PR MACH LEARN RES, V139; Garg R, 2022, Arxiv, DOI arXiv:2103.07977; Garg S., 2022, Advances in Neural Information Processing Systems, V35, p30 583; Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25; Jia LC, 2021, DES AUT CON, P865, DOI 10.1109/DAC18074.2021.9586329; Khailany B, 2018, DES AUT CON, DOI 10.1145/3195970.3199846; Koubaa A., 2023, GPT-4 vs. GPT-3.5: A concise show; Liang SW, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415645; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Miller B. L., 1995, Complex Systems, V9, P193; Min SW, 2022, Arxiv, DOI arXiv:2108.04106; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Olsson C., 2022, arXiv; OpenAI, GPT-3.5; OpenAI, GPT 4; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Poesia G, 2022, Arxiv, DOI [arXiv:2201.11227, 10.48550/ARXIV.2201.11227]; Qin ER, 2022, Arxiv, DOI arXiv:2201.08916; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Razeghi Y, 2022, Arxiv, DOI [arXiv:2202.07206, 10.48550/arXiv.2202.07206]; Real E, 2019, AAAI CONF ARTIF INTE, P4780; Rong F., 2021, Extrapolating to unnatural language processing with gpt-3's in-context learning: The good, the bad, and the mysterious; Thakur S., 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127; Wang XY, 2023, Arxiv, DOI arXiv:2210.12810; Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003; Wei ZG, 2023, Arxiv, DOI arXiv:2302.10977; Xilinx Inc, Chaidnnv2-hls based dnn accelerator library for xilinx ultrascale+ mpsocs; Xilinx Inc, PYNQ: PYTHON PRODUCTIVITY; Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang X, 2020, Proc. Mach. Learn. Syst., V2, P216; Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801; Zhang Y., 2022, arXiv; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zheng QK, 2023, Arxiv, DOI [arXiv:2303.17568, 10.48550/arXiv.2303.17568]	50	1	1	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1933-7760		979-8-3503-2225-5	ICCAD-IEEE ACM INT			2023										10.1109/ICCAD57390.2023.10323953	http://dx.doi.org/10.1109/ICCAD57390.2023.10323953			9	Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2HI		Green Submitted			2024-07-03	WOS:001116715100184
J	Han, HYM				Han, Hyemin			Potential benefits of employing large language models in research in moral education and development	JOURNAL OF MORAL EDUCATION			English	Article; Early Access						Large language models; artificial intelligence; moral reasoning; moral exemplar; simulation	EVOLUTIONARY CAUSAL MATRICES; ELEVATION; INTERVENTIONS; EMOTIONS; OUTCOMES	Recently, computer scientists have developed large language models (LLMs) by training prediction models with large-scale language corpora and human reinforcements. The LLMs have become one promising way to implement artificial intelligence with accuracy in various fields. Interestingly, recent LLMs possess emergent functional features that emulate sophisticated human cognition, especially in-context learning and the chain of thought, which were unavailable in previous prediction models. In this paper, I will examine how LLMs might contribute to moral education and development research. To achieve this goal, I will review the most recently published conference papers and ArXiv preprints to overview the novel functional features implemented in LLMs. I also intend to conduct brief experiments with ChatGPT to investigate how LLMs behave while addressing ethical dilemmas and external feedback. The results suggest that LLMs might be capable of solving dilemmas based on reasoning and revising their reasoning process with external input. Furthermore, a preliminary experimental result from the moral exemplar test may demonstrate that exemplary stories can elicit moral elevation in LLMs as do they among human participants. I will discuss the potential implications of LLMs on research on moral education and development with the results.	[Han, Hyemin] Univ Alabama, Educ Psychol Program, Tuscaloosa, AL 35487 USA; [Han, Hyemin] Univ Alabama, Box 872031, Tuscaloosa, AL 35487 USA	University of Alabama System; University of Alabama Tuscaloosa; University of Alabama System; University of Alabama Tuscaloosa	Han, HYM (corresponding author), Univ Alabama, Box 872031, Tuscaloosa, AL 35487 USA.	hyemin.han@ua.edu	Han, Hyemin/D-2808-2014	Han, Hyemin/0000-0001-7181-2565				Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; Algoe SB, 2009, J POSIT PSYCHOL, V4, P105, DOI 10.1080/17439760802650519; Blackburn AM, 2023, HEALTH PSYCHOL, V42, P235, DOI 10.1037/hea0001268; BLASI A, 1980, PSYCHOL BULL, V88, P1, DOI 10.1037/0033-2909.88.1.1; Blatt M.M., 1975, J MORAL EDUC, V4, P129, DOI [DOI 10.1080/0305724750040207, 10.1080/0305724750040207]; Chalmers DJ, 2023, Arxiv, DOI [arXiv:2303.07103, DOI 10.48550/ARXIV.2303.07103, 10.48550/arXiv.2303.07103]; Chan HCS, 2019, TRENDS PHARMACOL SCI, V40, P592, DOI 10.1016/j.tips.2019.06.004; Choi YJ, 2019, EUR J DEV PSYCHOL, V16, P622, DOI 10.1080/17405629.2019.1614907; Cohen H, 2024, PHILOS PSYCHOL, V37, P801, DOI 10.1080/09515089.2022.2096430; Darnell C, 2022, PERS INDIV DIFFER, V196, DOI 10.1016/j.paid.2022.111684; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Friston KJ, 2003, NEURAL NETWORKS, V16, P1325, DOI 10.1016/j.neunet.2003.06.005; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Gover AR, 2020, AM J CRIM JUSTICE, V45, P647, DOI 10.1007/s12103-020-09545-1; Grossmann I, 2023, SCIENCE, V380, P1108, DOI 10.1126/science.adi1778; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haidt J., 2000, Prevention Treatment, V3, DOI [10.1037/1522-3736.3.1.33c, DOI 10.1037/1522-3736.3.1.33C, https://doi.org/10.1037/1522-3736.3.1.33c]; Han H., 2020, SN Computer Science, V1, P70, DOI [https://doi.org/10.1007/s42979-020-0075-z, DOI 10.1007/S42979-020-0075-Z]; Han H., 2023, PREPRINT, DOI [10.31234/osf.io/ufg7e, DOI 10.31234/OSF.IO/UFG7E]; Han H, 2024, J MORAL EDUC, V53, P14, DOI 10.1080/03057240.2023.2173158; Han H, 2024, ETHICAL THEORY MORAL, V27, P111, DOI 10.1007/s10677-023-10369-1; Han H, 2022, PHILOS PSYCHOL, V35, P943, DOI 10.1080/09515089.2022.2035343; Han H, 2020, J EXP EDUC, V88, P660, DOI 10.1080/00220973.2019.1574701; Han H, 2018, KNOWL INF SYST, V57, P685, DOI 10.1007/s10115-017-1151-0; Han H, 2016, TRENDS NEUROSCI EDUC, V5, P157, DOI 10.1016/j.tine.2016.11.003; Hosseini M, 2023, RES ETHICS-UK, DOI 10.1177/17470161231180449; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kristjánsson K, 2017, THEORY RES EDUC, V15, P20, DOI 10.1177/1477878517695679; Kristjánsson K, 2010, EDUC PHILOS THEORY, V42, P397, DOI 10.1111/j.1469-5812.2008.00489.x; Li M, 2024, Arxiv, DOI [arXiv:2302.09582, 10.48550/arXiv.2302.09582, DOI 10.48550/ARXIV.2302.09582]; Mathys C, 2011, FRONT HUM NEUROSCI, V5, DOI 10.3389/fnhum.2011.00039; May J., 2018, Regard for Reason in the Moral Mind; McDiarmid AD, 2021, NAT HUM BEHAV, V5, P1663, DOI 10.1038/s41562-021-01220-7; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Mogavi RH, 2023, Arxiv, DOI arXiv:2305.13114; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Mu Y, 2023, Arxiv, DOI arXiv:2305.15021; Narvaez D., 2016, EMBODIED MORALITY PR, DOI [https://doi.org/10.1057/978-1-137-55399-7_1, DOI 10.1057/978-1-137-55399-7_1]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Railton P, 2017, COGNITION, V167, P172, DOI 10.1016/j.cognition.2016.08.015; Rest J.R., 1999, POSTCONVENTIONAL MOR; Samorodnitsky D., 2022, GENETIC ENG BIOTECHN, V42, P26, DOI [https://doi.org/10.1089/gen.42.01.09, DOI 10.1089/GEN.42.01.09]; Sanderse W, 2013, J MORAL EDUC, V42, P28, DOI 10.1080/03057240.2012.690727; Schnall S, 2010, PSYCHOL SCI, V21, P315, DOI 10.1177/0956797609359882; Schwitzgebel E, 2024, MIND LANG, V39, P237, DOI 10.1111/mila.12466; Shapira N, 2023, Arxiv, DOI arXiv:2305.14763; Silvers JA, 2008, EMOTION, V8, P291, DOI 10.1037/1528-3542.8.2.291; Srivastava Aarohi, 2022, arXiv; Vianello M, 2010, J POSIT PSYCHOL, V5, P390, DOI 10.1080/17439760.2010.516764; Volkman R, 2023, SCI ENG ETHICS, V29, DOI 10.1007/s11948-023-00428-2; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu Y, 2023, Arxiv, DOI arXiv:2305.15486; Yeager DS, 2011, REV EDUC RES, V81, P267, DOI 10.3102/0034654311405999; Young L, 2007, P NATL ACAD SCI USA, V104, P8235, DOI 10.1073/pnas.0701408104; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	59	2	2	32	66	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0305-7240	1465-3877		J MORAL EDUC	J. Moral Educ.	2023 SEP 16	2023										10.1080/03057240.2023.2250570	http://dx.doi.org/10.1080/03057240.2023.2250570		SEP 2023	16	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	S0MF1		Green Submitted			2024-07-03	WOS:001068189900001
J	Fatemi, B; Rabbi, F; Opdahl, AL				Fatemi, Bahareh; Rabbi, Fazle; Opdahl, Andreas L.			Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology	IEEE ACCESS			English	Article						Task analysis; Annotations; Ontologies; Adaptation models; Tag clouds; Support vector machines; Sports; IPTC media topics; journalism; large language models; news classification		News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism.	[Fatemi, Bahareh; Rabbi, Fazle; Opdahl, Andreas L.] Univ Bergen, Dept Informat Sci & Media Studies, N-5007 Bergen, Norway	University of Bergen	Fatemi, B; Rabbi, F (corresponding author), Univ Bergen, Dept Informat Sci & Media Studies, N-5007 Bergen, Norway.	Bahareh.Fatemi@uib.no; Fazle.Rabbi@uib.no	Opdahl, Andreas Lothe/B-5508-2015	Opdahl, Andreas Lothe/0000-0002-3141-1385; Fatemi, Bahareh/0000-0002-8944-5051; Rabbi, Fazle/0000-0001-5626-0598	SFI MediaFutures Partners and the Research Council of Norway	SFI MediaFutures Partners and the Research Council of Norway	No Statement Available	[Anonymous], 2020, LinguisticsNetherlands J., V10, P37; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Clercq De, Comput; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Gruppi M, 2020, Arxiv, DOI arXiv:2003.08444; Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818; Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI 10.18653/v1/e17-2068; Logan I., 2021, Findings Assoc. Comput. Linguistics, P2824; Luo Y, 2017, J BIOMED INFORM, V72, P85, DOI 10.1016/j.jbi.2017.07.006; Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Petridis N., 2023, CHI C HUMAN FACTORS, P1; Petukhova A, 2023, DATA, V8, DOI 10.3390/data8050074; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford K., 2018, OpenAI; Raffel C, 2020, J MACH LEARN RES, V21; Rudnik C, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P1232, DOI 10.1145/3308560.3316761; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang GY, 2018, Arxiv, DOI arXiv:1805.04174; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yang KC, 2023, Arxiv, DOI arXiv:2304.00228; Zhang T., 2023, arXiv	28	0	0	26	26	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						145386	145394		10.1109/ACCESS.2023.3345414	http://dx.doi.org/10.1109/ACCESS.2023.3345414			9	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	DL3Q5		Green Submitted, gold			2024-07-03	WOS:001132163200001
C	Hu, SH; Huang, TS; Ilhan, F; Tekin, SF; Liu, L			IEEE	Hu, Sihao; Huang, Tiansheng; Ilhan, Fatih; Tekin, Selim Furkan; Liu, Ling			Large Language Model-Powered Smart Contract Vulnerability Detection: New Perspectives	2023 5TH IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS, TPS-ISA			English	Proceedings Paper	5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)	NOV 01-03, 2023	Atlanta, GA	IEEE, IEEE Comp Soc		Large language model; GPT; smart contract; vulnerability detection		This paper provides a systematic analysis of the opportunities, challenges, and potential solutions of harnessing Large Language Models (LLMs) such as GPT-4 to dig out vulnerabilities within smart contracts based on our ongoing research. For the task of smart contract vulnerability detection, achieving practical usability hinges on identifying as many true vulnerabilities as possible while minimizing the number of false positives. Nonetheless, our empirical study reveals contradictory yet interesting findings: generating more answers with higher randomness largely boosts the likelihood of producing a correct answer but inevitably leads to a higher number of false positives. To mitigate this tension, we propose an adversarial framework dubbed GPTLENS that breaks the conventional one-stage detection into two synergistic stages - generation and discrimination, for progressive detection and refinement, wherein the LLM plays dual roles, i.e., AUDITOR and CRITIC, respectively. The goal of AUDITOR is to yield a broad spectrum of vulnerabilities with the hope of encompassing the correct answer, whereas the goal of CRITIC that evaluates the validity of identified vulnerabilities is to minimize the number of false positives. Experimental results and illustrative examples demonstrate that AUDITOR and CRITIC work together harmoniously to yield pronounced improvements over the conventional one-stage detection. GPTLENS is intuitive, strategic, and entirely LLM-driven without relying on specialist expertise in smart contracts, showcasing its methodical generality and potential to detect a broad spectrum of vulnerabilities. Our code is available at: https://github.com/git-disl/GPTLens.	[Hu, Sihao; Huang, Tiansheng; Ilhan, Fatih; Tekin, Selim Furkan; Liu, Ling] Georgia Inst Technol, Sch Comp Sci, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Hu, SH (corresponding author), Georgia Inst Technol, Sch Comp Sci, Atlanta, GA 30332 USA.	sihaohu@gatech.edu; thuang@gatech.edu; filhan@gatech.edu; stekin6@gatech.edu; ling.liu@gatech.edu			NSF CISE [2038029, 2302720, 2312758]; IBM faculty award; CISCO Edge AI program	NSF CISE; IBM faculty award(International Business Machines (IBM)); CISCO Edge AI program	This research is partially sponsored by the NSF CISE grants 2038029, 2302720, 2312758, an IBM faculty award, and a grant from CISCO Edge AI program.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; AlgoWriting, 2020, A simple guide to setting the gpt- 3 temperature; Anthropic, 2022, Introducing claude; Brent L, 2018, Arxiv, DOI [arXiv:1809.03981, 10.48550/ARXIV.1809.03981]; Brent L, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P454, DOI 10.1145/3385412.3385990; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao Y, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2964, DOI 10.1145/3511808.3557120; Chen C, 2023, Arxiv, DOI arXiv:2309.05520; Chen M., 2021, arXiv; David I, 2023, Arxiv, DOI arXiv:2306.12338; Feist J, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P8, DOI 10.1109/WETSEB.2019.00008; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Grieco Gustavo, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P557, DOI 10.1145/3395363.3404366; Heller J., 1999, Catch-22: A Novel, V4; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Hu S., 2023, P ACM WEB C 2023 WWW, P2189, DOI DOI 10.1145/3543507.3583345; Jeon S, 2021, KDD WORKSH PROGR LAN; Jiang B, 2018, IEEE INT CONF AUTOM, P259, DOI 10.1145/3238147.3238177; Tann WJW, 2019, Arxiv, DOI arXiv:1811.06632; Kalra S, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23082; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liao ZQ, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P752, DOI 10.1145/3533767.3534222; Liu ZG, 2023, IEEE T KNOWL DATA EN, V35, P1296, DOI 10.1109/TKDE.2021.3095196; Liu ZG, 2021, Arxiv, DOI arXiv:2106.09282; Mossberg M, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1186, DOI 10.1109/ASE.2019.00133; Mythril, About us; N. vulnerability database, Common vulnerabilities and exposures (cves); Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Paul R, 2023, Arxiv, DOI arXiv:2304.07840; Permenev A, 2020, P IEEE S SECUR PRIV, P1661, DOI 10.1109/SP40000.2020.00024; Qian C, 2024, Arxiv, DOI arXiv:2307.07924; Qian Peng, 2023, WWW '23: Proceedings of the ACM Web Conference 2023, P2220, DOI 10.1145/3543507.3583367; Qian P, 2020, IEEE ACCESS, V8, P19685, DOI 10.1109/ACCESS.2020.2969429; Radford A, 2016, Arxiv, DOI arXiv:1511.06434; Schick T., 2023, arXiv; Sendner C., 2023, NDSS; Shen D, 2022, Arxiv, DOI arXiv:2210.14473; So S, 2020, P IEEE S SECUR PRIV, P1678, DOI 10.1109/SP40000.2020.00032; Sun XB, 2023, J INF SECUR APPL, V73, DOI 10.1016/j.jisa.2023.103423; Sun YQ, 2024, Arxiv, DOI arXiv:2308.03314; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tsankov P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P67, DOI 10.1145/3243734.3243780; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922; Wei JS, 2022, ADV NEUR IN; Wong D., 2018, Decentralized application security project top 10 of 2018; Wu Y, 2024, Arxiv, DOI arXiv:2305.18607; Wüstholz V, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1398, DOI 10.1145/3368089.3417064; Xi ZH, 2023, Arxiv, DOI arXiv:2309.07864; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xue Y., 2022, IEEE Transactions on Dependable and Secure Computing; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yuhang Sun, 2021, Journal of Physics: Conference Series, V1820, DOI 10.1088/1742-6596/1820/1/012004; Zhang W, 2019, PROC INT SYMP SOFTW, P456, DOI 10.1109/ISSRE.2019.00052; Zhang YF, 2024, Arxiv, DOI arXiv:2308.04371; Zhang Z, 2023, PROC INT CONF SOFTW, P615, DOI 10.1109/ICSE48619.2023.00061; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou LY, 2023, P IEEE S SECUR PRIV, P2444, DOI 10.1109/SP46215.2023.10179435; Zhuang Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3283	59	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2385-6				2023							297	306		10.1109/TPS-ISA58951.2023.00044	http://dx.doi.org/10.1109/TPS-ISA58951.2023.00044			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6HT		Green Submitted			2024-07-03	WOS:001174354000034
C	Jiang, E; Olson, K; Toh, E; Molina, A; Donsbach, A; Terry, M; Cai, CJ			ACM	Jiang, Ellen; Olson, Kristen; Toh, Edwin; Molina, Alejandra; Donsbach, Aaron; Terry, Michael; Cai, Carrie J.			PromptMaker: Prompt-based Prototyping with Large Language Models	EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022			English	Proceedings Paper	CHI Conference on Human Factors in Computing Systems (CHI)	APR 30-MAY 05, 2022	New Orleans, LA	Assoc Comp Machinery, ACM SIGCHI, Google, Bloomberg, Meta, Microsoft, NSF, Yahoo				Prototyping is notoriously difficult to do with machine learning (ML), but recent advances in large language models may lower the barriers to people prototyping with ML, through the use of natural language prompts. This case study reports on the real-world experiences of industry professionals (e.g. designers, program managers, front-end developers) prototyping new ML-powered feature ideas via prompt-based prototyping. Through interviews with eleven practitioners during a three-week sprint and a workshop, we find that prompt-based prototyping reduced barriers of access by substantially broadening who can prototype with ML, sped up the prototyping process, and grounded communication between collaborators. Yet, it also introduced new challenges, such as the need to reverse-engineer prompt designs, source example data, and debug and evaluate prompt effectiveness. Taken together, this case study provides important implications that lay the groundwork toward a new future of prototyping with ML.	[Jiang, Ellen; Olson, Kristen; Toh, Edwin; Molina, Alejandra; Donsbach, Aaron; Terry, Michael; Cai, Carrie J.] Google Res, PAIR team, Mountain View, CA 94043 USA	Google Incorporated	Jiang, E (corresponding author), Google Res, PAIR team, Mountain View, CA 94043 USA.	ellenj@google.com; kolson@google.com; edwintoh@google.com; alemolinata@google.com; donsbach@google.com; michaelterry@google.com; cjcai@google.com						Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; [Anonymous], 2010, Sketching User Experiences: Getting the Design Right and the Right Design; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai Carrie J., 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359206; Carney M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382839; Collins E., 2021, Lamda: Our breakthrough conversation technology; DAHLBACK N, 1993, KNOWL-BASED SYST, V6, P258, DOI 10.1016/0950-7051(93)90017-N; Dow SP, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1879831.1879836; gwern, GPT-3 Creative Fiction; Hong Matthew K, 2021, P 2021 CHI C HUMAN F, P1; John Bonnie E, 2004, CHI 04 EXTENDED ABST, P1723, DOI DOI 10.1145/985921.986201; Lee Charlotte P., 2007, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V16, P307, DOI 10.1007/s10606-007-9044-5; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Qian Yang, 2020, CHI '20: Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3313831.3376301; Star SL, 2015, INFRASTRUCT SER, P243; Yang Q, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300415	17	13	13	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9156-6				2022										10.1145/3491101.3503564	http://dx.doi.org/10.1145/3491101.3503564			8	Computer Science, Cybernetics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LA					2024-07-03	WOS:001118038100017
J	Ghassemi, M				Ghassemi, Marzyeh			Presentation matters for AI-generated clinical advice	NATURE HUMAN BEHAVIOUR			English	Editorial Material; Early Access								If mistakes are made in clinical settings, patients suffer. Artificial intelligence (AI) generally - and large language models specifically - are increasingly used in health settings, but the way that physicians use AI tools in this high-stakes environment depends on how information is delivered. AI toolmakers have a responsibility to present information in a way that minimizes harm.	[Ghassemi, Marzyeh] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02142 USA; [Ghassemi, Marzyeh] MIT, Inst Med Engn & Sci, Cambridge, MA 02142 USA; [Ghassemi, Marzyeh] Vector Inst, Toronto, ON, Canada	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Vector Institute for Artificial Intelligence	Ghassemi, M (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02142 USA.; Ghassemi, M (corresponding author), MIT, Inst Med Engn & Sci, Cambridge, MA 02142 USA.; Ghassemi, M (corresponding author), Vector Inst, Toronto, ON, Canada.	mghassem@mit.edu		Ghassemi, Marzyeh/0000-0001-6349-7251	M.G. is a CIFAR AI Chair, CIFAR Azrieli Global Scholar, Herman L. F. von Helmholtz Career Development Professor, and JameelClinic Affiliate, and acknowledges support from these programmes.	M.G. is a CIFAR AI Chair, CIFAR Azrieli Global Scholar, Herman L. F. von Helmholtz Career Development Professor, and JameelClinic Affiliate, and acknowledges support from these programmes.	M.G. is a CIFAR AI Chair, CIFAR Azrieli Global Scholar, Herman L. F. von Helmholtz Career Development Professor, and JameelClinic Affiliate, and acknowledges support from these programmes.	Adam H, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P7, DOI 10.1145/3514094.3534203; Adam H, 2022, COMMUN MED-LONDON, V2, DOI 10.1038/s43856-022-00214-4; Adashi EY, 2022, NAT MED, V28, P2241, DOI 10.1038/s41591-022-01982-1; Bates DW, 2023, NEW ENGL J MED, V388, P142, DOI 10.1056/NEJMsa2206117; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Gaube S, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00385-9; Ghassemi M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2021.100392; Gichoya JW, 2022, LANCET DIGIT HEALTH, V4, pE406, DOI 10.1016/S2589-7500(22)00063-2; Goodman KE, 2023, NEW ENGL J MED, P483, DOI 10.1056/NEJMp2304839; Haoran Zhang, 2020, CHIL '20: Proceedings of the Conference on Health, Inference, and Learning, P110, DOI 10.1145/3368555.3384448; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Raji Inioluwa Deborah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P959, DOI 10.1145/3531146.3533158; Robinette P, 2016, ACMIEEE INT CONF HUM, P101, DOI 10.1109/HRI.2016.7451740; Seyyed-Kalantari L, 2021, NAT MED, V27, P2176, DOI 10.1038/s41591-021-01595-0; Smallman M, 2019, NATURE, V567, P7, DOI 10.1038/d41586-019-00737-2; Suriyakumar VM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P723, DOI 10.1145/3442188.3445934; Wong A, 2021, JAMA INTERN MED, V181, P1065, DOI 10.1001/jamainternmed.2021.2626	17	0	0	5	6	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2023 NOV 20	2023										10.1038/s41562-023-01721-7	http://dx.doi.org/10.1038/s41562-023-01721-7		NOV 2023	3	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	Y8GD1	37985904				2024-07-03	WOS:001107579600009
J	Xu, XH; Yao, BS; Dong, YZ; Gabriel, SD; Yu, H; Hendler, J; Ghassemi, M; Dey, AK; Wang, D				Xu, Xuhai; Yao, Bingsheng; Dong, Yuanzhe; Gabriel, Saadia; Yu, Hong; Hendler, James; Ghassemi, Marzyeh; Dey, Anind K.; Wang, Dakuo			Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						Mental Health; Large Language Model; Instruction Finetuning	SOCIAL MEDIA; DEPRESSION	Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present a comprehensive evaluation of multiple LLMs on various mental health prediction tasks via online text data, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.	[Xu, Xuhai; Gabriel, Saadia; Ghassemi, Marzyeh] MIT, Cambridge, MA 02139 USA; [Xu, Xuhai; Wang, Dakuo] Univ Washington, Seattle, WA 98195 USA; [Yao, Bingsheng; Hendler, James] Rensselaer Polytechn Inst, Rensselaer, NY USA; [Dong, Yuanzhe] Stanford Univ, Stanford, CA USA; [Yu, Hong] Univ Massachusetts Lowell, Lowell, MA USA; [Wang, Dakuo] Northeastern Univ, Boston, MA USA	Massachusetts Institute of Technology (MIT); University of Washington; University of Washington Seattle; Stanford University; University of Massachusetts System; University of Massachusetts Lowell; Northeastern University	Xu, XH (corresponding author), MIT, Cambridge, MA 02139 USA.; Xu, XH (corresponding author), Univ Washington, Seattle, WA 98195 USA.	xuhaixu@uw.edu		Xu, Xuhai/0000-0001-5930-3899	VWFoundation; Quanta Computing; National Institutes of Health (NIH) [1R01MD018424-01]	VWFoundation(Volkswagen); Quanta Computing; National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work is supported by VWFoundation, Quanta Computing, and the National Institutes of Health (NIH) under Grant No. 1R01MD018424-01.	Abd-Alrazaq AA, 2021, J MED INTERNET RES, V23, DOI 10.2196/17828; Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Ahmed Arfan, 2022, Computer Methods and Programs in Biomedicine Update, V2022; Alhamadani A, 2022, P 2022 IEEE ACM INT, P427, DOI [DOI 10.1109/ASONAM55673, 10.1109/ASONAM55673.2022.10068655]; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; [Anonymous], 2022, Introducing chatgpt; [Anonymous], 2023, Mental Health By the Numbers; [Anonymous], 2023, Mental Illness; Balagopalan A, 2023, SCI ADV, V9, DOI 10.1126/sciadv.abq0701; Bento M. J. N., 2023, ECR 2023 EPOS; Benton A, 2017, Arxiv, DOI arXiv:1712.03538; Birnbaum ML, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.7956; Brants Thorsten, 2007, Large language models in machine translation; Brodersen Kay H., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3121, DOI 10.1109/ICPR.2010.764; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burnap Pete, 2015, P 26 ACM C HYPERTEXT, P75, DOI [10.1145/2700171.2791023, DOI 10.1145/2700171.2791023]; Cameron G, 2019, LECT NOTES COMPUT SC, V11551, P121, DOI 10.1007/978-3-030-17705-8_11; Cameron Gillian, 2017, Towards a chatbot for digital counselling, DOI [10.14236/ewic/HCI2017.24, DOI 10.14236/EWIC/HCI2017.24]; Chancellor S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0233-7; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Chen Irene Y, 2019, AMA J Ethics, V21, pE167, DOI 10.1001/amajethics.2019.167; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Coppersmith G., 2014, ICWSM, P579, DOI [10.1609/icwsm.v8i1.14574, DOI 10.1609/ICWSM.V8I1.14574]; Coppersmith G., 2015, P 2 WORKSHOP COMPUTA, P31, DOI [DOI 10.3115/V1/W15-1204, 10.3115/v1/w15-1204, 10.3115/v1/W15-1204]; Coppersmith G, 2018, BIOMED INFORM INSIGH, V10, DOI 10.1177/1178222618792860; Culotta A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1335, DOI 10.1145/2556288.2557139; Dang H, 2022, Arxiv, DOI arXiv:2209.01390; De Choudhury M., 2013, P INT AAAI C WEB SOC, V7, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998]; De Choudhury M., 2014, Proceedings of the International AAAI Conference on Web and Social Media, V8, P71, DOI [10.1609/icwsm.v8i1.14526, DOI 10.1609/ICWSM.V8I1.14526]; De Choudhury M., 2013, P 5 ANN ACM WEB SCI, P47, DOI 10.1145/2464464; De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207; Denecke K, 2021, IEEE T EMERG TOP COM, V9, P1170, DOI 10.1109/TETC.2020.2974478; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eichstaedt JC, 2018, P NATL ACAD SCI USA, V115, P11203, DOI 10.1073/pnas.1802331115; Franco M, 2023, PROCEEDINGS OF THE 2023 WORKSHOP ON OPEN CHALLENGES IN ONLINE SOCIAL NETWORKS, OASIS 2023/ 34TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, HT 2023, P1, DOI 10.1145/3599696.3612895; Frei Steffen, 2023, PCIM Europe 2023; International Exhibition and Conference for Power Electronics, Intelligent Motion, Renewable Energy and Energy Management, P1, DOI 10.30420/566091296; Gaur M, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P514, DOI 10.1145/3308558.3313698; Gemalmaz Meric Altug, 2021, P 30 INT JOINT C ART, P1729, DOI DOI 10.24963/IJCAI.2021/238; Ghosh S, 2023, Arxiv, DOI arXiv:2305.10510; Gkotsis George, 2016, P 3 WORKSH COMP LING, P63, DOI [10.18653/v1/W16-0307, 10.18653/v1/W16-0307., DOI 10.18653/V1/W16-0307]; Graham S, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1094-0; Gulcehre C, 2017, COMPUT SPEECH LANG, V45, P137, DOI 10.1016/j.csl.2017.01.014; Guntuku SC, 2017, CURR OPIN BEHAV SCI, V18, P43, DOI 10.1016/j.cobeha.2017.07.005; Guntuku Sharath Chandra., 2019, Proceedings of the international AAAI conference on web and social media, V13, P214, DOI DOI 10.1609/ICWSM.V13I01.3223; Han SJ, 2022, Arxiv, DOI arXiv:2209.07494; Haque Ayaan, 2021, arXiv; Harman C., 2015, P 2 WORKSHOP COMPUTA, P1, DOI [DOI 10.3115/V1/W15-1201, 10.3115/v1/w15-1201]; Hoover Amanda, 2023, An eating disorder chatbot is suspended for giving harmful advice; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang J., 2022, arXiv; Jamil Z, 2018, P 4 WORKSHOP COMPUTA, DOI [10.18653/v1/w17-3104, DOI 10.18653/V1/W17, 10.18653/v1/W17-3104, DOI 10.18653/V1/W17-3104]; Ji SX, 2021, Arxiv, DOI arXiv:2110.15621; Ji SX, 2018, COMPLEXITY, DOI 10.1155/2018/6157249; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Jiang Z.P., 2020, P 11 INT WORKSHOP HL, P147, DOI DOI 10.18653/V1/2020.LOUHI-1.16; Jo E, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581503; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kojima T., 2022, 36 C NEURAL INFORM P; Kruzan KP, 2022, INTERNET INTERV, V30, DOI 10.1016/j.invent.2022.100578; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Li YC, 2023, Arxiv, DOI arXiv:2310.06201; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Liu Xin, 2023, arXiv; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Livingston JD, 2014, SOC PSYCH PSYCH EPID, V49, P985, DOI 10.1007/s00127-013-0815-7; Lovejoy CA, 2019, EUR PSYCHIAT, V55, P1, DOI 10.1016/j.eurpsy.2018.08.004; Lupetti ML, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3597128; Mauriello ML, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451799; Mitchell Margaret, 2015, CLPSYCH, P11; Morais Margarida, 2023, 2023 IEEE 20 INT S B, P1; Moreno MA, 2011, DEPRESS ANXIETY, V28, P447, DOI 10.1002/da.20805; Naseem U, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2563, DOI 10.1145/3485447.3512128; Nepal S, 2024, Arxiv, DOI arXiv:2201.03074; Nguyen T., 2022, arXiv; Nijhawan T, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00575-6; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356; Omar Reham, 2023, ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots, DOI DOI 10.48550/ARXIV.2302.06466; Otsuka Norio, Psychiatry and Clinical Neurosciences; Park M., 2021, P INT AAAI C WEB SOC, V7, P476, DOI DOI 10.1609/ICWSM.V7I1.14425; Patel Vivek, 2018, 2018 International Conference on Advances in Computing and Communication Engineering (ICACCE), P384, DOI 10.1109/ICACCE.2018.8441760; Paul M. J., 2011, P INT AAAI C WEB SOC, V20, P265, DOI DOI 10.1609/ICWSM.V5I1.14137; Pessach D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3494672; Posner K., 2008, COLUMBIA SUICIDE SEV, P10, DOI [DOI 10.1037/T52667-000, 10.1037/t52667-000]; Praw-Dev, Praw-dev/PRAW: PRAW, an acronym for "Python reddit api wrapper", is a python package that allows for simple access to Reddit's API; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Raffel C, 2020, J MACH LEARN RES, V21; Regier DA, 2013, WORLD PSYCHIATRY, V12, P92, DOI 10.1002/wps.20050; Reinert M., 2021, The state of mental health in America 2022; Ridout B, 2018, J MED INTERNET RES, V20, DOI 10.2196/12244; Robinson Joshua, 2023, 11 INT C LEARNING RE; Ruder TD, 2011, CRISIS, V32, P280, DOI 10.1027/0227-5910/a000086; Rumshisky A, 2016, TRANSL PSYCHIAT, V6, DOI 10.1038/tp.2015.182; Saha Koustuv, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130960; Saifullah S, 2021, Arxiv, DOI arXiv:2101.06353; Sampath K, 2022, PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022), P331; Sampath Kayalvizhi, 2022, Computational Intelligence in Data Science, V654, P136, DOI DOI 10.1007/978-3-031-16364-7; Sawhney Ramit., 2018, P 9 WORKSHOP COMPUTA, P167, DOI [DOI 10.18653/V1/W18-6223, 10.18653/v1/w18-6223]; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Sharma A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P194, DOI 10.1145/3442381.3450097; Sharma E, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174215; Shen J. H., 2017, Proceedings of the Fourth Workshop on Computational Linguistics and Clinical Psychology-From Linguistic Signal to Clinical Reality, P58, DOI DOI 10.18653/V1/W17-3107; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Tadesse MM, 2019, IEEE ACCESS, V7, P44883, DOI 10.1109/ACCESS.2019.2909180; Tadesse MM, 2020, ALGORITHMS, V13, DOI 10.3390/a13010007; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Nguyen T, 2014, IEEE T AFFECT COMPUT, V5, P217, DOI 10.1109/TAFFC.2014.2315623; Timmons AC, 2023, PERSPECT PSYCHOL SCI, V18, P1062, DOI 10.1177/17456916221134490; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tsugawa S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3187, DOI 10.1145/2702123.2702280; Turcan E, 2019, Arxiv, DOI arXiv:1911.00133; Venktesh V, 2023, Arxiv, DOI arXiv:2310.18371; Wang DK, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3381069; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wu CY, 2023, Arxiv, DOI [arXiv:2304.14454, DOI 10.48550/ARXIV.2304.14454]; Xu RX, 2021, Arxiv, DOI arXiv:2109.05687; Xu XH, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569485; Xu XH, 2021, CCF T PERVAS COMPUT, V3, P344, DOI 10.1007/s42486-021-00072-4; Xu XH, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448107; Xu Xuhai., 2022, THIRTYSIXTH C NEURAL, P18; Xuhai Xu, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3351274; Yang KL, 2024, Arxiv, DOI [arXiv:2309.13567, 10.48550/arXiv.2309.13567, DOI 10.48550/ARXIV.2309.13567]; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	133	1	2	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAR	2024	8	1							31	10.1145/3643540	http://dx.doi.org/10.1145/3643540			32	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	OM1I2		Green Submitted			2024-07-03	WOS:001207594200031
C	Li, SH; Yang, C; Yin, YC; Zhu, XY; Cheng, ZS; Shang, LF; Jiang, X; Liu, Q; Yang, YJ		Boyd-Graber, J; Okazaki, N; Rogers, A		Li, Siheng; Yang, Cheng; Yin, Yichun; Zhu, Xinyu; Cheng, Zesen; Shang, Lifeng; Jiang, Xin; Liu, Qun; Yang, Yujiu			AutoConv: Automatically Generating Information-seeking Conversations with Large Language Models	61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Information-seeking conversation, which aims to help users gather information through conversation, has achieved great progress in recent years. However, the research is still stymied by the scarcity of training data. To alleviate this problem, we propose AutoConv for synthetic conversation generation, which takes advantage of the few-shot learning ability and generation capacity of large language models (LLM). Specifically, we formulate the conversation generation problem as a language modeling task, then finetune an LLM with a few human conversations to capture the characteristics of the information-seeking process and use it for generating synthetic conversations with high quality. Experimental results on two frequently-used datasets verify that AutoConv has substantial improvements over strong baselines and alleviates the dependence on human annotation. In addition, we also provide several analysis studies to promote future research.	[Li, Siheng; Yang, Cheng; Zhu, Xinyu; Yang, Yujiu] Tsinghua Univ, Shenzhen Int Grad Sch, Beijing, Peoples R China; [Li, Siheng; Yin, Yichun; Shang, Lifeng; Jiang, Xin; Liu, Qun] Huawei Noahs Ark Lab, Montreal, PQ, Canada; [Cheng, Zesen] Peking Univ, Beijing, Peoples R China	Tsinghua University; Peking University	Yang, YJ (corresponding author), Tsinghua Univ, Shenzhen Int Grad Sch, Beijing, Peoples R China.	lisiheng21@mails.tsinghua.edu.cn; yangc21@mails.tsinghua.edu.cn; yinyichun@huawei.com; shang.lifeng@huawei.com; jiang.xin@huawei.com; qun.liu@huawei.com; yang.yujiu@sz.tsinghua.edu.cn		Yang, Yujiu/0000-0002-6427-1024	National Key Research and Development Program of China [2020YFB1708200]; "Graph Neural Network Project" of Ping An Technology (Shenzhen) Co., Ltd.; AMiner.Shenzhen SciBrain fund	National Key Research and Development Program of China; "Graph Neural Network Project" of Ping An Technology (Shenzhen) Co., Ltd.; AMiner.Shenzhen SciBrain fund	This work was partly supported by the National Key Research and Development Program of China (No. 2020YFB1708200), the "Graph Neural Network Project" of Ping An Technology (Shenzhen) Co., Ltd. and AMiner.Shenzhen SciBrain fund.	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen JA, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6605; Chen JA, 2021, Arxiv, DOI arXiv:2106.07499; Choi E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2174; Dai Zhuyun, 2022, INT C MACHINE LEARNI, V162, P4558; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Holtzman A., 2019, INT C LEARNING REPRE; Khashabi D, 2022, Arxiv, DOI arXiv:2202.12359; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Kim G, 2022, Arxiv, DOI arXiv:2205.12609; Kingma D. P., 2017, ARXIV; Kobayashi S., 2018, P 2018 C N AM CHAPT, V2, P452, DOI DOI 10.18653/V1/N18-2072; Liang PP, 2021, PR MACH LEARN RES, V139; QingyangWu Song Feng, 2021, arXiv; Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Sanh Victor., 2022, 10 INT C LEARN REPR; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; Stede Manfred, 2004, P CAT 8 WORKSH SEM P; Su YX, 2022, Arxiv, DOI arXiv:2202.06417; Sun H, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3906; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; West P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4602; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xie Qizhe, 2020, Neural Information Processing Systems, V33; Xu J, 2022, Arxiv, DOI arXiv:2206.02369; Xu J, 2021, Arxiv, DOI arXiv:2010.07079; Ye JC, 2022, Arxiv, DOI arXiv:2202.07922; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zheng CJ, 2023, Arxiv, DOI arXiv:2202.13047	36	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-71-5				2023							1751	1762						12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SD					2024-07-03	WOS:001181088800149
C	Awasthi, A; Gupta, N; Samanta, B; Dave, S; Sarawagi, S; Talukdar, P		Vlachos, A; Augenstein, I		Awasthi, Abhijeet; Gupta, Nitish; Samanta, Bidisha; Dave, Shachi; Sarawagi, Sunita; Talukdar, Partha			Bootstrapping Multilingual Semantic Parsers using Large Language Models	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Despite cross-lingual generalization demonstrated by pre-trained multilingual models, the translate-train paradigm of transferring English datasets across multiple languages remains to be a key mechanism for training taskspecific multilingual models. However, for many low-resource languages, the availability of a reliable translation service entails significant amounts of costly human-annotated translation pairs. Further, translation services may continue to be brittle due to domain mismatch between task-specific input text and generalpurpose text used for training translation models. For multilingual semantic parsing, we demonstrate the effectiveness and flexibility offered by large language models (LLMs) for translating English datasets into several languages via few-shot prompting. Through extensive comparisons on two public datasets, MTOP and MASSIVE, spanning 50 languages and several domains, we show that our method of translating data using LLMs outperforms a strong translate-train baseline on 41 out of 50 languages. We study the key design choices that enable more effective multilingual data translation via prompted LLMs.	[Awasthi, Abhijeet; Sarawagi, Sunita] Indian Inst Technol, Mumbai, India; [Gupta, Nitish; Samanta, Bidisha; Dave, Shachi; Talukdar, Partha] Google Res India, Bangalore, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Bombay	Awasthi, A (corresponding author), Indian Inst Technol, Mumbai, India.	awasthi@cse.iitb.ac.in; guptanitish@google.com; bidishasamanta@google.com; shachi@google.com; sunita@cse.iitb.ac.in; partha@google.com						[Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2005, P 21 C UNCERTAINTY A, DOI DOI 10.3115/1690219.1690283; Artetxe M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7674; Bommasani Rishi, 2021, ARXIV210807258; Chowdhery A., 2022, ARXIV220402311; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Fang YW, 2021, AAAI CONF ARTIF INTE, V35, P12776; FitzGerald Jack, 2022, ARXIV220408582; Gritta M, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P4048; Gupta S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2787; Hartrumpf Sven, 2008, WORKSH CORSS LANG EV, P421; Holtzman A., 2019, P INT C LEARN REPR; Hu JJ, 2020, PR MACH LEARN RES, V119; Kumar S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4507; Ladhak F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4034; Le Scao Teven, 2022, ARXIV221105100; Li HR, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2950; Liang YB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6008; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Min Sewon, 2022, ARXIV220212837; Moradshahi M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5970; Moradshahi Mehrad, 2021, ARXIV211102574; Nicosia M, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P3272; Nicosia Massimo, 2022, ARXIV221207223; Price P, 1990, SPEECH NATURAL LANGU; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Roberts Adam, 2022, arXiv preprint arXiv:2203.17189; Rubin O., 2021, ARXIV211208633; Shao Y., 2017, P 2017 C EMP METH NA, P2210, DOI DOI 10.18653/V1/D17-1235; Shazeer N, 2018, PR MACH LEARN RES, V80; Sherborne T, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P499; Smith S., 2022, arXiv preprint arXiv:2201.11990; Soltan Saleh, 2022, ARXIV220801448; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Uhrig S, 2021, IWPT 2021: THE 17TH INTERNATIONAL CONFERENCE ON PARSING TECHNOLOGIES: PROCEEDINGS OF THE CONFERENCE (INCLUDING THE IWPT 2021 SHARED TASK), P58; Vaswani A, 2017, ADV NEUR IN, V30; Vijayakumar A. K., 2016, ARXIV161002424; Wei Jason, 2022, arXiv:2201.11903; Xia Menglin, 2021, 10 JOINT C LEX COMP; Xie Sang Michael, 2021, INT C LEARN REPR; Xu W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5052; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yang Diyi, 2022, P 60 ANN M ASS COMP, P28; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zhang H, 2021, P WORKSH HUM EV NLP, P25; Zhang S., 2022, arXiv; ZhiruoWang Grace Cuenca, 2022, ARXIV220308388; Zhou Denny, 2022, arXiv:2205.10625	50	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							2455	2467						13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056901022
C	Randari, B; Ding, H; Fan, ZW; Yifei; Chen, ZT; Deoras, A; Kveton, B			Assoc computing machinery	Randari, Behnam; Ding, Hao; Fan, Ziwei; Yifei; Chen, Zhuotong; Deoras, Anoop; Kveton, Branislav			Logic-Scaffolding: Personalized Aspect-Instructed Recommendation Explanation Generation using LLMs	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Aspect-Instructed Explanation; Large Language Models		The unique capabilities of Large Language Models (LLMs), such as the natural language text generation ability, position them as strong candidates for providing explanation for recommendations. However, despite the size of the LLM, most existing models struggle to produce zero-shot explanations reliably. To address this issue, we propose a framework called Logic-Scaffolding, that combines the ideas of aspect-based explanation and chain-of-thought prompting to generate explanations through intermediate reasoning steps. In this paper, we share our experience in building the framework and present an interactive demonstration for exploring our results.	[Randari, Behnam] Univ Pittsburgh, Pittsburgh, PA 15261 USA; [Randari, Behnam; Ding, Hao; Fan, Ziwei; Chen, Zhuotong; Kveton, Branislav] AWS AI Labs, Santa Clara, CA 95055 USA; [Yifei; Deoras, Anoop] Amazon, Santa Clara, CA USA; [Chen, Zhuotong] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Amazon.com; University of California System; University of California Santa Barbara	Randari, B (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15261 USA.; Randari, B (corresponding author), AWS AI Labs, Santa Clara, CA 95055 USA.	ber58@pitt.edu; haodin@amazon.com; zwfan@amazon.com; yifeim@amazon.com; ztchen@ucsb.edu; adeoras@amazon.com; bkveton@amazon.com						Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; Tamkin Alex, 2021, Understanding the capabilities, limitations, and societal impact of large language models; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Zhang YF, 2020, FOUND TRENDS INF RET, V14, P1, DOI 10.1561/1500000066	8	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1078	1081		10.1145/3616855.3635689	http://dx.doi.org/10.1145/3616855.3635689			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN		hybrid, Green Submitted			2024-07-03	WOS:001182230100124
C	Zhao, Y; Misra, I; Krähenbühl, P; Girdhar, R			IEEE	Zhao, Yue; Misra, Ishan; Krahenbuhl, Philipp; Girdhar, Rohit			Learning Video Representations from Large Language Models	2023 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, CVPR	IEEE Conference on Computer Vision and Pattern Recognition		English	Proceedings Paper	IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)	JUN 17-24, 2023	Vancouver, CANADA	IEEE, CVF, IEEE Comp Soc				We introduce LAVILA, a new approach to learning video-language representations by leveraging Large Language Models (LLMs). We repurpose pre-trained LLMs to be conditioned on visual input, and finetune them to create automatic video narrators. Our auto-generated narrations offer a number of advantages, including dense coverage of long videos, better temporal synchronization of the visual information and text, and much higher diversity of text. The video-language embedding learned contrastively with these narrations outperforms the previous state-of-the-art on multiple first-person and third-person video tasks, both in zero-shot and finetuned setups. Most notably, LAVILA obtains an absolute gain of 10.1% on EGTEA classification and 5.9% Epic-Kitchens-100 multi-instance retrieval benchmarks. Furthermore, LAVILA trained with only half the narrations from the Ego4D dataset outperforms models trained on the full set, and shows positive scaling behavior on increasing pre-training data and model size.	[Zhao, Yue; Misra, Ishan; Girdhar, Rohit] Meta AI, FAIR, Menlo Pk, CA 94025 USA; [Zhao, Yue; Krahenbuhl, Philipp] Univ Texas Austin, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Zhao, Y (corresponding author), Meta AI, FAIR, Menlo Pk, CA 94025 USA.; Zhao, Y (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.		Zhao, Yue/AAM-2787-2020	Zhao, Yue/0000-0003-3401-4921	National Science Foundation [IIS-1845485]	National Science Foundation(National Science Foundation (NSF))	We thank Naman Goyal, Stephen Roller and Susan Zhang for help with language models, Kevin Qinghong Lin for help with EgoVLP, and the Meta AI team for helpful discussions and feedback. This material is based upon work in-part supported by the National Science Foundation under Grant No. IIS-1845485.	Alayrac Jean-Baptiste, 2022, NeurIPS; [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298698; [Anonymous], 2020, WACV; Arnab Anurag, 2021, ICCV; Ba LJ., 2016, CORR; Bain Max, 2021, ICCV; Bengio Y, 2000, ADV NEUR IN, V12, P400; Bertasius Gedas, 2021, ICML; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502; Chen Yen-Chun, 2020, ECCV; Cho J., 2021, ICML; Courville Aaron, 2017, IJCV; Damen Dima, 2022, IJCV; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101; Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878; Dosovitskiy A., 2020, ICLR; Ego4D Consortium, EG LIV 4D PERC EGO4D, V2; Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090; Feng Steven Y, 2021, ACL FINDINGS; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Girdhar Rohit, 2022, CVPR; Golla Ramsri Goutham, HIGH QUALITY SENTENC; Grauman Kristen, 2022, CVPR; Han T., 2022, CVPR; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hoffmann Jordan, 2022, arXiv; Holtzman A., 2019, INT C LEARNING REPRE; Hu XDC, 2016, ENVIRON SCI TECH LET, V3, P344, DOI 10.1021/acs.estlett.6b00260; Jia Chao, 2021, ICML; Ju Chen, 2022, ECCV; Kazakos Evangelos, 2021, BMVC; Kolesnikov A., 2022, CVPR; Kolesnikov Alexander, 2022, TMLR; Kondratyuk Dan, 2021, CVPR; Kuehne Hildegard, 2011, 2011 International Conference on Computer Vision; Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/978-3-030-01231-1_42, 10.1007/s11263-019-01250-9]; Li YZ, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P998, DOI [10.1007/978-981-15-9746-6_74, 10.1145/3459637.3482257]; Lin K.Q., 2022, NeurIPS; Lin Z., 2022, ECCV; Lorenz DA, 2015, J MATH IMAGING VIS, V51, P311, DOI 10.1007/s10851-014-0523-2; Lu JS, 2019, ADV NEUR IN, V32; Luo Huaishao, 2020, ARXIV200206353; Maluuba. nlg-eval, NLG EV; Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Nagrani Arsha, 2022, ECCV; Ni Bolin, 2022, ECCV; Oord A, 2018, ARXIV; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh Aditya, 2022, ARXIV220406125; Schuhmann Christoph, 2022, NEURIPS D B; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; SEO PH, 2022, CVPR, P1793, DOI DOI 10.1109/CVPR52688.2022.01743; Sigurdsson Gunnar A, 2018, Charades -Ego A Large -Scale Dataset of Paired Third and First Person Videos; Sigurdsson Gunnar A, 2018, CVPR; Sohn K, 2016, ADV NEUR IN, V29; Soomro Khurram, 2012, CTR RES COMPUTER VIS, V2, P11; Su W., 2020, ICLR, P1; Sudhakaran S, 2019, PROC CVPR IEEE, P9946, DOI 10.1109/CVPR.2019.01019; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Tsimpoukelli M., 2021, NeurIPS; Vaswani A, 2017, ADV NEUR IN, V30; Vijayakumar A. K., 2016, ARXIV161002424; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang W. Y, 2015, EMNLP; Wang Wenhui, 2022, ARXIV220810442; Wang Xintao, 2021, ICCV; Wei Jason, 2019, EMNLP; Weston Jason, 2010, MACHINE LEARNING; Wieting John, 2018, ACL; Wray M, 2019, IEEE I CONF COMP VIS, P450, DOI 10.1109/ICCV.2019.00054; Wu Chao-Yuan, 2022, CVPR; Xu H., 2021, EMNLP; Xue H., 2023, ICLR; Yan Shen, 2022, CVPR; Yang Zhuoyi, 2023, ICLR; Yu J., 2022, TMLR; Yuan Lu, 2021, ARXIV211111432; Zellers R, 2021, NEURIPS; Zhang X, 2015, ADV NEUR IN, V28; Zhou LK, 2018, AAAI CONF ARTIF INTE, P571; Zhou Xinyue, 2022, ECCV; Zhu L., 2020, CVPR, P8743, DOI 10.1109/CVPR42600.2020.00877; Zhu X., 2022, CVPR	89	2	3	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1063-6919		979-8-3503-0129-8	PROC CVPR IEEE			2023							6586	6597		10.1109/CVPR52729.2023.00637	http://dx.doi.org/10.1109/CVPR52729.2023.00637			12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV6JX		Green Submitted			2024-07-03	WOS:001058542606090
C	Sayenju, S; Aygun, R; Franks, B; Johnston, S; Lee, G; Choi, H; Modgil, G			IEEE	Sayenju, Sudhashree; Aygun, Ramazan; Franks, Bill; Johnston, Sereres; Lee, George; Choi, Hansook; Modgil, Girish			Quantifying Domain Knowledge in Large Language Models	2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI			English	Proceedings Paper	IEEE Conference on Artificial Intelligence (IEEE CAI)	JUN 05-06, 2023	Santa Clara, CA	IEEE, IEEE Comp Soc, IEEE Signal Proc Soc, IEEE Syst, Man, & Cybernet Soc		Natural Language Processing; BERT; Domain Bias; Domain Knowledge		Transformer based Large language models such as BERT, have demonstrated the ability to derive contextual information from the words surrounding it. However, when these models are applied in specific domains such as medicine, insurance, or scientific disciplines, publicly available models trained on general knowledge sources such as Wikipedia, it may not be as effective in inferring the appropriate context compared to domain-specific models trained on specialized corpora. Given the limited availability of training data for specific domains, pre-trained models can be fine-tuned via transfer learning using relatively small domain-specific corpora. However, there is currently no standardized method for quantifying the effectiveness of these domain-specific models in acquiring the necessary domain knowledge. To address this issue, we explore hidden layer embeddings and introduce domain gain, a measure to quantify the ability of a model to infer the correct context. In this paper, we show how our measure could be utilized to determine whether words with multiple meanings are more likely to be associated with domain-related meanings rather than their colloquial meanings.	[Sayenju, Sudhashree; Aygun, Ramazan; Franks, Bill] Kennesaw State Univ, Kennesaw, GA 30144 USA; [Johnston, Sereres; Lee, George; Choi, Hansook; Modgil, Girish] Travelers Companies Inc, Hartford, CT USA	University System of Georgia; Kennesaw State University	Sayenju, S (corresponding author), Kennesaw State Univ, Kennesaw, GA 30144 USA.	ssayenju@students.kennesaw.edu; raygun@kennesaw.edu; wfranks3@kennesaw.edu; scjohnst@travelers.com; glee2@travelers.com; hchoi@travelers.com; gmodgil@travelers.com			Travelers Indemnity Company	Travelers Indemnity Company	This work was supported primarily by the Travelers Indemnity Company. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect those of the Travelers Indemnity Company.	Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; huggingface, JUSTADVANCETECHONOLO; Wiedemann G, 2019, Arxiv, DOI arXiv:1909.10430; Xu H., 2021, arXiv	5	1	1	0	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3984-0				2023							193	194		10.1109/CAI54212.2023.00091	http://dx.doi.org/10.1109/CAI54212.2023.00091			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5BQ					2024-07-03	WOS:001046447800081
J	Bisbee, J; Clinton, JD; Dorff, C; Kenkel, B; Larson, JM				Bisbee, James; Clinton, Joshua D.; Dorff, Cassy; Kenkel, Brenton; Larson, Jennifer M.			Synthetic Replacements for Human Survey Data? The Perils of Large Language Models	POLITICAL ANALYSIS			English	Article; Early Access						ChatGPT; synthetic data; public opinion; research ethics	POLARIZATION	Large language models (LLMs) offer new research possibilities for social scientists, but their potential as "synthetic data" is still largely unknown. In this paper, we investigate how accurately the popular LLM ChatGPT can recover public opinion, prompting the LLM to adopt different "personas" and then provide feeling thermometer scores for 11 sociopolitical groups. The average scores generated by ChatGPT correspond closely to the averages in our baseline survey, the 2016-2020 American National Election Study (ANES). Nevertheless, sampling by ChatGPT is not reliable for statistical inference: there is less variation in responses than in the real surveys, and regression coefficients often differ significantly from equivalent estimates obtained using ANES data. We also document how the distribution of synthetic responses varies with minor changes in prompt wording, and we show how the same prompt yields significantly different results over a 3-month period. Altogether, our findings raise serious concerns about the quality, reliability, and reproducibility of synthetic survey data generated by LLMs.	[Bisbee, James; Clinton, Joshua D.; Dorff, Cassy; Kenkel, Brenton; Larson, Jennifer M.] Vanderbilt Univ, Polit Sci Dept, Nashville, TN 37235 USA	Vanderbilt University	Bisbee, J (corresponding author), Vanderbilt Univ, Polit Sci Dept, Nashville, TN 37235 USA.	james.h.bisbee@vanderbilt.edu			KDI School of Public Policy and Management; Society for Personality and Social Psychology	KDI School of Public Policy and Management; Society for Personality and Social Psychology	The authors are grateful to audiences at Vanderbilt University, Seoul National University, Korea University, Sungkyunkwan University, Yonsei University, KDI School of Public Policy and Management, and the 2024 annual conference of the Society for Personality and Social Psychology.	Abdulhai M, 2023, Arxiv, DOI arXiv:2310.15337; Aher GV, 2023, INT C MACHINE LEARNI, P337; [Anonymous], 2023, Washington Post; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Bail C., 2022, Breaking the Social Media Prism: How to Make Our Platforms Less Polarizing; Beauchamp N, 2017, AM J POLIT SCI, V61, P490, DOI 10.1111/ajps.12274; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bisbee James, 2024, HarvardDataverse, V1, DOI 10.7910/DVN/VPN481; Bisbee J, 2019, AM POLIT SCI REV, V113, P1060, DOI 10.1017/S0003055419000480; Cao Yong., 2023, P 1 WORKSHOP CROSS C, P53, DOI 10.18653/v1/2023.c3nlp-1.7; Caughey D, 2015, POLIT ANAL, V23, P197, DOI 10.1093/pan/mpu021; Clinton J. D., 2021, American Association of Public Opinion Research Task Force on Pre-Election Polling: An Evaluation of the 2020 General Election Polls; Clinton JD, 2022, PUBLIC OPIN QUART, V86, P247, DOI 10.1093/poq/nfac011; Cowen T., 2022, ChatGPT AI Could Make Democracy Even More Messy; DeBell Matthew., 2009, Computing weights for american national election study survey data; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Druckman JN, 2019, PUBLIC OPIN QUART, V83, P114, DOI 10.1093/poq/nfz003; Gelman A, 2014, AM SCI, V102, P460, DOI 10.1511/2014.111.460; Gelman Andrew, 1997, SURVEY METHODOLOGY, V23, P127; Ghitza Y, 2013, AM J POLIT SCI, V57, P762, DOI 10.1111/ajps.12004; Gilardi F, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2305016120; Goplerud M, 2024, AM POLIT SCI REV, V118, P529, DOI 10.1017/S0003055423000035; Graham D. A., 2023, The Polling Crisis Is a Catastrophe for American Democracy-theatlantic.com; Horton JJ., 2023, LARGE LANGUAGE MODEL; Iyengar S, 2019, ANNU REV POLIT SCI, V22, P129, DOI 10.1146/annurev-polisci-051117-073034; Keeter S., 2017, What low response rates mean for telephone surveys; Kennedy C, 2018, PUBLIC OPIN QUART, V82, P1, DOI 10.1093/poq/nfx047; Lax JR, 2009, AM J POLIT SCI, V53, P107, DOI 10.1111/j.1540-5907.2008.00360.x; Levendusky MS, 2016, PUBLIC OPIN QUART, V80, P378, DOI 10.1093/poq/nfv045; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; OpenAI, 2021, ChatGPT 3.5 Turbo; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Santurkar S., 2023, INT C MACHINE LEARNI, P29971; Shapiro W., 2019, The Polling Industry Is in Crisis; Spirling A, 2023, NATURE, V616, P413, DOI 10.1038/d41586-023-01295-4; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Tucker J., 2017, The Oxford Handbook of Polling and Polling Methods, P1; Waldner D, 2018, ANNU REV POLIT SCI, V21, P93, DOI 10.1146/annurev-polisci-050517-114628; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wu PY, 2023, Arxiv, DOI [arXiv:2303.12057, 10.48550/arXiv.2303.12057, DOI 10.48550/ARXIV.2303.12057]	41	1	1	4	4	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1047-1987	1476-4989		POLIT ANAL	Polit. Anal.	2024 MAY 17	2024										10.1017/pan.2024.5	http://dx.doi.org/10.1017/pan.2024.5		MAY 2024	16	Political Science	Social Science Citation Index (SSCI)	Government & Law	RF1I8		Green Submitted, hybrid			2024-07-03	WOS:001226158000001
J	Hu, ZQ; Li, XY; Pan, XY; Wen, SJ; Bao, JS				Hu, Zhiqiang; Li, Xinyu; Pan, Xinyu; Wen, Sijie; Bao, Jinsong			A question answering system for assembly process of wind turbines based on multi-modal knowledge graph and large language model	JOURNAL OF ENGINEERING DESIGN			English	Article; Early Access						Multi-modal knowledge graph; Wind turbines; Assembly process knowledge; Large language model; Question answering	SUPPORT; FUSION	In the field of wind power generation, wind turbines serve as the foundation for harnessing electrical energy. However, the assembly process information for wind turbines is typically dispersed among various modalities such as 3D models, natural text, and images in the form of process documents. The difficulty in effectively utilising historical process knowledge hampers the efficiency of assembly process design and subsequently affects production efficiency. To address this issue, this paper constructs a Multi-modal Process Knowledge Graph for Wind Turbines, named MPKG-WT. Additionally, a wind turbine assembly process question-answering system combining multi-modal knowledge graphs with large language models (LLMs) is proposed to enable efficient utilisation of historical assembly process knowledge. The proposed approach achieves outstanding results when compared with other state-of-the-art KBQA methods and recent LLMs using a wind turbine assembly process dataset. The effectiveness of the approach is further validated through a visualised assembly process question-answering system. The research findings demonstrate a significant improvement in assembly process design efficiency.	[Hu, Zhiqiang; Li, Xinyu; Pan, Xinyu; Wen, Sijie; Bao, Jinsong] Donghua Univ, Coll Mech Engn, Shanghai, Peoples R China	Donghua University	Li, XY (corresponding author), Donghua Univ, Coll Mech Engn, Shanghai, Peoples R China.	lixinyu@dhu.edu.cn	Hu, Zhiqiang/HIR-5043-2022; LI, XINYU/S-5783-2019	Hu, Zhiqiang/0000-0002-0802-8580; LI, XINYU/0000-0002-4117-9698	National Key Research and Development Program of China [2019YFB1706300]; Shanghai Rising-Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality [22YF1400200]	National Key Research and Development Program of China; Shanghai Rising-Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality	This work was supported by National Key Research and Development Program of China: [grant no 2019YFB1706300]; Shanghai Rising-Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality: [grant no 22YF1400200].	Alberts H., 2021, P WORKSHOP MULTILING, P138, DOI [DOI 10.18653/V1/2021.MRL-1, DOI 10.18653/V1/2021.MRL-1.13]; Asim T, 2022, ENERGIES, V15, DOI 10.3390/en15020579; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Bhutani N, 2020, FIRST WORKSHOP ON NATURAL LANGUAGE INTERFACES, P1; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chatterjee J, 2022, IEEE ACCESS, V10, P84710, DOI 10.1109/ACCESS.2022.3197167; Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202; Dai Z., 2019, 2019 12 INT C IMAGE, P1; Das R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9594; Das SK, 2022, INT J ADV MANUF TECH, V120, P4863, DOI 10.1007/s00170-022-09002-9; Elnozahy WA, 2019, PROCEDIA COMPUT SCI, V164, P56, DOI 10.1016/j.procs.2019.12.154; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Huang X., 2021, FINDINGS ASS COMPUTA, P547; Lan YS, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P969; Li MH, 2022, PROCESSES, V10, DOI 10.3390/pr10081569; Li XL, 2018, INT J ADV MANUF TECH, V96, P4173, DOI 10.1007/s00170-018-1862-8; Li YJ, 2019, PR MACH LEARN RES, V97; Liu Jianhua, 2018, Journal of Mechanical Engineering, V54, P2, DOI 10.3901/JME.2018.11.002; Liu Y, 2019, LECT NOTES COMPUT SC, V11503, P459, DOI 10.1007/978-3-030-21348-0_30; Oliya A., 2021, P 2021 C EMP METH NA, P4193, DOI DOI 10.18653/V1/2021.EMNLP-MAIN.345; Onoro-Rubio D., 2019, Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs; Pan YL, 2022, TECHNOL FORECAST SOC, V176, DOI 10.1016/j.techfore.2022.121475; Qiao Z., 2022, P 29 INT C COMPUTATI, P1813; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Roga S, 2022, SUSTAIN ENERGY TECHN, V52, DOI 10.1016/j.seta.2022.102239; Rudnitckaia J, 2022, IEEE ACCESS, V10, P24203, DOI 10.1109/ACCESS.2022.3152211; Song LJ, 2021, IEEE ACCESS, V9, P41430, DOI 10.1109/ACCESS.2021.3065360; Suchanek FM, 2008, J WEB SEMANT, V6, P203, DOI 10.1016/j.websem.2008.06.001; Sun YW, 2022, J WEB SEMANT, V72, DOI 10.1016/j.websem.2021.100698; Tian YR, 2017, PROC CVPR IEEE, P6128, DOI 10.1109/CVPR.2017.649; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang M, 2020, BIG DATA RES, V22, DOI 10.1016/j.bdr.2020.100159; Wang P, 2022, J MANUF PROCESS, V73, P961, DOI 10.1016/j.jmapro.2021.11.037; Xu LD, 2014, IEEE T AUTOM SCI ENG, V11, P492, DOI 10.1109/TASE.2012.2232652; Yu Qian., 2018, COLING 2018, P2192; Yun W, 2021, INT J INTELL SYST, V36, P1686, DOI 10.1002/int.22357; Zhang PF, 2021, INFORM FUSION, V68, P85, DOI 10.1016/j.inffus.2020.11.004; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao YY, 2022, J IND INF INTEGR, V25, DOI 10.1016/j.jii.2021.100300; Zheng SJ, 2020, NAT MACH INTELL, V2, P134, DOI 10.1038/s42256-020-0152-y; Zhou B, 2022, INT J COMPUT INTEG M, V35, P1151, DOI 10.1080/0951192X.2021.1891572	43	5	5	61	62	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0954-4828	1466-1837		J ENG DESIGN	J. Eng. Des.	2023 OCT 25	2023										10.1080/09544828.2023.2272555	http://dx.doi.org/10.1080/09544828.2023.2272555		OCT 2023	25	Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	CA7Z0					2024-07-03	WOS:001122606800001
J	Yu, J; Li, L; Lan, ZZ				Yu, Jia; Li, Long; Lan, Zhenzhong			Beyond Binary Classification: A Fine-Grained Safety Dataset for Large Language Models	IEEE ACCESS			English	Article						Large language models; LLM safety; automatic safety score		Large Language Models (LLMs) excel in interactive chat scenarios due to their advanced conversational abilities. However, their training process invariably exposes them to a diverse range of harmful or toxic content, posing significant challenges in ensuring that LLM responses align with human ethical values. Consequently, the detection and quantification of adverse content remains a paramount issue in contemporary research. In this paper, we introduce the SAFE dataset, a novel resource designed to advance safety assessment research in LLMs. Our dataset extends beyond the binary categorization of content into "safe" and "unsafe". Drawing upon human interpretations of safety, we further delineate unsafe content into six granular categories: Sensitivity, Harmfulness, Falsehood, Information Corruption, Unnaturalness, and Deviation from Instructions. This refined classification aims to enhance LLMs' ability to discern unsafe data more accurately. In total, we have created a dataset comprising 52,340 instruction-response pairs, each annotated with safety meta-tags. Additionally, we have compiled expert comparative assessments for these indicators. We developed a multi-expert rating model trained on the SAFE dataset, designed to evaluate the responses of LLMs across various dimensions. This approach highlights the potential of our dataset in the realm of safety assessment for LLMs. The model's capability to provide multi-faceted evaluations reflects an advanced understanding of the nuanced requirements in LLM response assessment. We believe this dataset represents a valuable resource for the community, contributing to the safe development and deployment of LLMs. Our findings and resources are poised to fuel future research endeavors in this domain.	[Yu, Jia; Li, Long; Lan, Zhenzhong] Zhejiang Univ, Sch Engn, Hangzhou 310027, Zhejiang, Peoples R China; [Yu, Jia; Lan, Zhenzhong] Westlake Univ, Hangzhou 310024, Peoples R China	Zhejiang University; Westlake University	Lan, ZZ (corresponding author), Zhejiang Univ, Sch Engn, Hangzhou 310027, Zhejiang, Peoples R China.; Lan, ZZ (corresponding author), Westlake Univ, Hangzhou 310024, Peoples R China.	lanzhenzhong@westlake.edu.cn						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Chiang CH, 2023, Arxiv, DOI arXiv:2305.01937; Chowdhery A, 2023, J MACH LEARN RES, V24; Dai J, 2023, Arxiv, DOI arXiv:2310.12773; Deshpande A, 2023, Arxiv, DOI arXiv:2304.05335; Dubois C. X., 2024, Adv. Neural Inf.Process. Syst., V36; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Gehman S, 2020, Arxiv, DOI [arXiv:2009.11462, DOI 10.1017/S1431927621007376]; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Ji M., 2024, Adv. Neural Inf. Process. Syst., V36; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu Y, 2023, Arxiv, DOI arXiv:2303.16634; Radziwill NM, 2017, Arxiv, DOI [arXiv:1704.04579, DOI 10.48550/ARXIV.1704.04579]; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Parrish A, 2022, Arxiv, DOI arXiv:2110.08193; Perez Ethan, 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.03286; Pichai S., 2023, GoogleKeyword (Blog)Feb.; Rogers A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560260; Shah D, 2023, C ROBOT LEARNING, P492; Sugawara A., 2016, P WORKSH UPH BATTL L, P1; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Valentino M., 2020, arXiv; Vemprala S, 2023, Arxiv, DOI arXiv:2306.17582; Wang YD, 2024, Arxiv, DOI arXiv:2306.05087; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zheng W.-L., 2024, Adv. NeuralInf. Process. Syst., V36	28	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						64717	64726		10.1109/ACCESS.2024.3393245	http://dx.doi.org/10.1109/ACCESS.2024.3393245			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	QE9W6		gold			2024-07-03	WOS:001219330200001
C	Zhang, PT; Zhang, JL			ACM	Zhang, Pengtao; Zhang, Junlin			MemoNet: Memorizing All Cross Features' Representations Efficiently via Multi-Hash Codebook Network for CTR Prediction	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Recommender System; Click-Through Rate; Feature Interaction		New findings in natural language processing (NLP) demonstrate that the strong memorization capability contributes a lot to the success of Large Language Models (LLM). This inspires us to explicitly bring an independent memory mechanism into CTR ranking model to learn and memorize cross features' representations. In this paper, we propose multi-Hash Codebook NETwork (HCNet) as the memory mechanism for efficiently learning and memorizing representations of cross features in CTR tasks. HCNet uses a multi-hash codebook as the main memory place and the whole memory procedure consists of three phases: multi-hash addressing, memory restoring, and feature shrinking. We also propose a new CTR model named MemoNet which combines HCNet with a DNN backbone. Extensive experimental results on three public datasets and online test show that MemoNet reaches superior performance over state-of-the-art approaches. Besides, MemoNet shows scaling law of large language model in NLP, which means we can enlarge the size of the codebook in HCNet to sustainably obtain performance gains. Our work demonstrates the importance and feasibility of learning and memorizing representations of cross features, which sheds light on a new promising research direction. The source code is in https://github.com/ptzhangAlg/RecAlg.	[Zhang, Pengtao; Zhang, Junlin] Sina Weibo, Beijing, Peoples R China		Zhang, PT (corresponding author), Sina Weibo, Beijing, Peoples R China.	zpt1986@126.com; junlin6@staff.weibo.com						Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini Nicholas, 2022, ARXIV220207646; Chapelle O, 2015, ACM T INTEL SYST TEC, V5, DOI 10.1145/2532128; Cheng H.-T., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [10.1145/2988450.2988454, DOI 10.1145/2988450.2988454]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gehring J., 2017, P 34 INT C MACH LEAR, V70, P1243; Guo HF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1725; He X., 2014, P 8 INT WORKSH DAT M, P1, DOI [10.1145/2648584.2648589, DOI 10.1145/2648584.2648589, DOI 10.1109/ICSICT.2014.7021269]; He XN, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P355, DOI 10.1145/3077136.3080777; Heinzerling Benjamin, 2020, ARXIV200809036; Huang TW, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P169, DOI 10.1145/3298689.3347043; Kingma D. P, 2015, P INT C LEARN REPR 2; Lian JX, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1754, DOI 10.1145/3219819.3220023; Liu B, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2636, DOI 10.1145/3394486.3403314; Liu B, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P199, DOI 10.1145/3397271.3401082; Magar Inbal, 2022, ARXIV220308242; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Pan JW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1349, DOI 10.1145/3178876.3186040; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127; Song WP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1161, DOI 10.1145/3357384.3357925; Tirumala Kushal, 2022, ARXIV220510770; Wang Peifeng, 2021, ARXIV210611533; Wang RX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1785, DOI 10.1145/3442381.3450078; Wang RX, 2017, ADKDD'17: 23RD ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD 2017), DOI 10.1145/3124749.3124754; Wang Zhiqiang, 2021, P DLP KDD 2021; Webson Albert, 2021, ARXIV210901247; Xiao J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3119; Yang ZL, 2019, ADV NEUR IN, V32; Zhang Pengtao, 2022, FIBINET IMPROVING FI, DOI [10.48550/ARXIV.2209, DOI 10.48550/ARXIV.2209]; Zhang Weinan, 2016, Advances in Information Retrieval, P45; Zhou Guorui, 2020, ARXIV201105625; Zhu Chen, 2020, ARXIV201200363; Zhu Jieming, 2020, ABS200905794 ARXIV	35	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							3154	3163		10.1145/3583780.3614963	http://dx.doi.org/10.1145/3583780.3614963			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Submitted			2024-07-03	WOS:001161549503021
J	Beaulieu-Jones, BK; Villamar, MF; Scordis, P; Bartmann, AP; Ali, W; Wissel, B; Alsentzer, E; de Jong, J; Patra, A; Kohane, I				Beaulieu-Jones, Brett K.; Villamar, Mauricio F.; Scordis, Phil; Bartmann, Ana Paula; Ali, Waqar; Wissel, Benjamin; Alsentzer, Emily; de Jong, Johann; Patra, Arijit; Kohane, Isaac			Predicting seizure recurrence after an initial seizure-like episode from routine clinical notes using large language models: a retrospective cohort study	LANCET DIGITAL HEALTH			English	Article							1ST UNPROVOKED SEIZURE; ANTIEPILEPTIC DRUG-WITHDRAWAL; FEBRILE STATUS EPILEPTICUS; EPILEPSY; RISK; CHILDREN; RECOMMENDATIONS; MANAGEMENT; CHILDHOOD; OUTCOMES	Background The evaluation and management of first-time seizure-like events in children can be difficult because these episodes are not always directly observed and might be epileptic seizures or other conditions (seizure mimics). We aimed to evaluate whether machine learning models using real-world data could predict seizure recurrence after an initial seizure-like event. Methods This retrospective cohort study compared models trained and evaluated on two separate datasets between Jan 1, 2010, and Jan 1, 2020: electronic medical records (EMRs) at Boston Children's Hospital and de-identified, patient-level, administrative claims data from the IBM MarketScan research database. The study population comprised patients with an initial diagnosis of either epilepsy or convulsions before the age of 21 years, based on International Classification of Diseases, Clinical Modification (ICD-CM) codes. We compared machine learning-based predictive modelling using structured data (logistic regression and XGBoost) with emerging techniques in natural language processing by use of large language models. Findings The primary cohort comprised 14 021 patients at Boston Children's Hospital matching inclusion criteria with an initial seizure-like event and the comparison cohort comprised 15 062 patients within the IBM MarketScan research database. Seizure recurrence based on a composite expert-derived definition occurred in 57% of patients at Boston Children's Hospital and 63% of patients within IBM MarketScan. Large language models with additional domain-specific and location-specific pre-training on patients excluded from the study (F1-score 0 center dot 826 [95% CI 0 center dot 817-0 center dot 835], AUC 0 center dot 897 [95% CI 0 center dot 875-0 center dot 913]) performed best. All large language models, including the base model without additional pre-training (F1-score 0 center dot 739 [95% CI 0 center dot 738-0 center dot 741], AUROC 0 center dot 846 [95% CI 0 center dot 826-0 center dot 861]) outperformed models trained with structured data. With structured data only, XGBoost outperformed logistic regression and XGBoost models trained with the Boston Children's Hospital EMR (logistic regression: F1-score 0 center dot 650 [95% CI 0 center dot 643-0 center dot 657], AUC 0 center dot 694 [95% CI 0 center dot 685-0 center dot 705], XGBoost: F1-score 0 center dot 679 [0 center dot 676-0 center dot 683], AUC 0 center dot 725 [0 center dot 717-0 center dot 734]) performed similarly to models trained on the IBM MarketScan database (logistic regression: F1-score 0 center dot 596 [0 center dot 590-0 center dot 601], AUC 0 center dot 670 [0 center dot 664-0 center dot 675], XGBoost: F1-score 0 center dot 678 [0 center dot 668-0 center dot 687], AUC 0 center dot 710 [0 center dot 703-0 center dot 714]). Interpretation Physician's clinical notes about an initial seizure-like event include substantial signals for prediction of seizure recurrence, and additional domain-specific and location-specific pre-training can significantly improve the performance of clinical large language models, even for specialised cohorts. Funding UCB, National Institute of Neurological Disorders and Stroke (US National Institutes of Health). Copyright (c) 2023 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY 4.0 license.	[Beaulieu-Jones, Brett K.] Univ Chicago, Dept Med, Chicago, IL USA; [Beaulieu-Jones, Brett K.; Alsentzer, Emily] Harvard Med Sch, Dept Biomed Informat, Boston, MA 02115 USA; [Villamar, Mauricio F.] Brown Univ, Dept Neurol, Warren Alpert Med Sch, Providence, RI USA; [Bartmann, Ana Paula; Wissel, Benjamin] UCB, Brussels, Belgium; [Wissel, Benjamin] Cincinnati Childrens Hosp Med Ctr, Div Biomed Informat, Cincinnati, OH USA; [de Jong, Johann] UCB Biosci, Monheim, Germany; [Beaulieu-Jones, Brett K.] Univ Chicago, Dept Med, Chicago, IL 60637 USA	University of Chicago; Harvard University; Harvard Medical School; Brown University; UCB Pharma SA; Cincinnati Children's Hospital Medical Center; University of Chicago	Beaulieu-Jones, BK (corresponding author), Univ Chicago, Dept Med, Chicago, IL 60637 USA.	beaulieujones@uchicago.edu			UCB; National Institute ofNeurological Disorders and Stroke (US National Institutes of Health)	UCB(UCB Pharma SA); National Institute ofNeurological Disorders and Stroke (US National Institutes of Health)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Neurological Disorders & Stroke (NINDS))	UCB, National Institute ofNeurological Disorders and Stroke (US National Institutes of Health).	Aaberg KM, 2017, PEDIATRICS, V139, DOI 10.1542/peds.2016-3908; Agniel D, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k1479; Ali S, 2023, DEV MED CHILD NEUROL, V65, P1247, DOI 10.1111/dmcn.15546; [Anonymous], 2018, IBM MarketScan research databases for life sciences researchers; Beaulieu-Jones BK, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00426-3; Beaulieu-Jones BK, 2018, JMIR MED INF, V6, DOI 10.2196/medinform.8960; Bonnett LJ, 2022, SEIZURE-EUR J EPILEP, V94, P26, DOI 10.1016/j.seizure.2021.11.007; Bonnett LJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099063; Chen T, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.02754(PREPRINT; Chu SS, 2021, EPILEPSY BEHAV, V114, DOI 10.1016/j.yebeh.2020.106987; Contento M, 2021, EPILEPSIA, V62, P2159, DOI 10.1111/epi.16993; Fisher RS, 2014, EPILEPSIA, V55, P475, DOI 10.1111/epi.12550; Fitzgerald Z, 2021, EPILEPSIA, V62, P2439, DOI 10.1111/epi.17024; Glauser T, 2013, EPILEPSIA, V54, P551, DOI 10.1111/epi.12074; Hauser WA, 1998, NEW ENGL J MED, V338, P429, DOI 10.1056/NEJM199802123380704; Hawash KY, 2003, J CHILD NEUROL, V18, P331, DOI 10.1177/08830738030180050601; Hirsch LJ, 2018, EPILEPSIA, V59, P739, DOI 10.1111/epi.14016; Hirtz D, 2003, NEUROLOGY, V60, P166, DOI 10.1212/01.WNL.0000033622.27961.B6; Holden E Wayne, 2005, Dis Manag, V8, P1, DOI 10.1089/dis.2005.8.1; Jehi L, 2015, LANCET NEUROL, V14, P283, DOI 10.1016/S1474-4422(14)70325-4; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kim HJ, 2016, BMC NEUROL, V16, DOI 10.1186/s12883-016-0729-6; Kim LG, 2006, LANCET NEUROL, V5, P317, DOI 10.1016/S1474-4422(06)70383-0; Lamberink HJ, 2018, EPILEPSIA, V59, pE28, DOI 10.1111/epi.14020; Lamberink HJ, 2015, EPILEPTIC DISORD, V17, P211, DOI 10.1684/epd.2015.0764; Li Y, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.11838; Lin JH, 2020, EPILEPSIA, V61, P115, DOI 10.1111/epi.16402; Liu GQ, 2017, LANCET NEUROL, V16, P620, DOI 10.1016/S1474-4422(17)30122-9; Liu S., 2005, IT Professional, V7, P17, DOI 10.1109/MITP.2005.122; Lu HX, 2022, BMC MED RES METHODOL, V22, DOI 10.1186/s12874-022-01665-y; Maloney EM, 2020, NEUROLOGY, V95, pE576, DOI 10.1212/WNL.0000000000009980; Mbizvo GK, 2020, EPILEPSIA, V61, P1319, DOI 10.1111/epi.16547; Moosa Ahsan N V, 2019, Continuum (Minneap Minn), V25, P381, DOI 10.1212/CON.0000000000000712; Morgan DJ, 2021, JAMA INTERN MED, V181, P747, DOI 10.1001/jamainternmed.2021.0269; Moura LMVR, 2017, EPILEPSIA, V58, P683, DOI 10.1111/epi.13691; Murphy SN, 2010, J AM MED INFORM ASSN, V17, P124, DOI 10.1136/jamia.2009.000893; Musicco M, 1997, NEUROLOGY, V49, P991, DOI 10.1212/WNL.49.4.991; National Guideline Centre (UK), 2022, NICE GUID 217, V217; Neumann M, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1902.07669; Nordli DR, 2012, NEUROLOGY, V79, P2180, DOI 10.1212/WNL.0b013e3182759766; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pellino G, 2022, EPILEPSY BEHAV, V127, DOI 10.1016/j.yebeh.2021.108498; Pierce JG, 2017, J CHILD NEUROL, V32, P1035, DOI 10.1177/0883073817726461; Podder V, 2022, SOAP NOTES; Rajkomar A, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1801.07860; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Sansevere AJ, 2017, J CHILD NEUROL, V32, P774, DOI 10.1177/0883073817706028; SHINNAR S, 1990, PEDIATRICS, V85, P1076; Shinnar S, 1996, PEDIATRICS, V98, P216; Shinnar S, 2012, NEUROLOGY, V79, P871, DOI 10.1212/WNL.0b013e318266fcc5; St Germaine-Smith C, 2012, NEUROLOGY, V79, P1049, DOI 10.1212/WNL.0b013e3182684707; Stainman RS, 2020, CURR PROB PEDIATR AD, V50, DOI 10.1016/j.cppeds.2020.100894; Stevelink R, 2022, ECLINICALMEDICINE, V53, DOI 10.1016/j.eclinm.2022.101732; van Diessen E, 2018, PEDIATRICS, V142, DOI 10.1542/peds.2018-0931; Vaswani A., 2017, Advances in neural information processing systems, P6000; Villamar Mauricio F, 2022, Neurol Clin Pract, V12, pe49, DOI 10.1212/CPJ.0000000000001178; Wilfong A, 2022, SEIZURES EPILEPSY CH; Wilmshurst JM, 2015, EPILEPSIA, V56, P1185, DOI 10.1111/epi.13057; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wulff P, 2023, INT J ARTIF INTELL E, V33, P439, DOI 10.1007/s40593-022-00290-6	60	2	2	10	11	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2589-7500		LANCET DIGIT HEALTH	Lancet Digit. Health	DEC	2023	5	12					E882	E894		10.1016/S2589-7500(23)00179-6	http://dx.doi.org/10.1016/S2589-7500(23)00179-6			13	Medical Informatics; Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics; General & Internal Medicine	CH4J2	38000873	gold, Green Accepted			2024-07-03	WOS:001124346700001
J	Hao, JA; von Davier, AA; Yaneva, V; Lottridge, S; von Davier, M; Harris, DJ				Hao, Jiangang; von Davier, Alina A.; Yaneva, Victoria; Lottridge, Susan; von Davier, Matthias; Harris, Deborah J.			Transforming Assessment: The Impacts and Implications of Large Language Models and Generative AI	EDUCATIONAL MEASUREMENT-ISSUES AND PRACTICE			English	Article						assessment; generative AI; LLMs	SUPPORT; TIME	The remarkable strides in artificial intelligence (AI), exemplified by ChatGPT, have unveiled a wealth of opportunities and challenges in assessment. Applying cutting-edge large language models (LLMs) and generative AI to assessment holds great promise in boosting efficiency, mitigating bias, and facilitating customized evaluations. Conversely, these innovations raise significant concerns regarding validity, reliability, transparency, fairness, equity, and test security, necessitating careful thinking when applying them in assessments. In this article, we discuss the impacts and implications of LLMs and generative AI on critical dimensions of assessment with example use cases and call for a community effort to equip assessment professionals with the needed AI literacy to harness the potential effectively.	[Hao, Jiangang] Educ Testing Serv, Princeton, NJ 08541 USA; [von Davier, Alina A.] Duolingo Inc, Pittsburgh, PA USA; [Yaneva, Victoria] Natl Board Med Examiners, Philadelphia, PA USA; [Lottridge, Susan] Cambium Assessment Inc, Washington, DC USA; [von Davier, Matthias] Boston Coll, Chestnut Hill, MA 02467 USA; [Harris, Deborah J.] Univ Iowa, Iowa City, IA USA	Educational Testing Service (ETS); Boston College; University of Iowa	Hao, JA (corresponding author), Educ Testing Serv, Princeton, NJ 08541 USA.							ACT, TEST DAY ACT; American Educational Research Association American Psychological Association National Council on Measurement in Education, 2014, STAND ED PSYCH TEST, DOI DOI 10.1037/14855-004; Attali Y., 2006, J TECHNOLOGY LEARNIN, V4; Attali Y, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.903077; Bejar I., 2003, J TECHNOLOGY LEARNIN, V2, DOI DOI 10.1002/J.2333-8504.2002.TB01890.X; BEJAR II, 1983, APPL PSYCH MEAS, V7, P303, DOI 10.1177/014662168300700306; Bezirhan U., 2023, COMPUTERS ED ARTIFIC, V5; Blasi D., 2021, ARXIV; Braun H., 2006, Automated scoring for complex constructed response tasks in computer based testing, P83; Briggs DC, 2022, J EDUC MEAS, V59, P398, DOI 10.1111/jedm.12350; Brittain B, 2023, Reuters; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burkhardt A, 2021, EDUC MEAS-ISSUES PRA, V40, P72, DOI 10.1111/emip.12410; Burstein J., 2023, RESPONSIBLE AI STAND; Burstein J., 2021, THEORETICAL ASSESSME; Choi I., 2021, ETS RES REPORT SERIE, V2021, P1, DOI DOI 10.1002/ETS2.12326; Crossley Scott, 2023, Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners, Doctoral Consortium and Blue Sky: 24th International Conference, AIED 2023, Proceedings. Communications in Computer and Information Science (1831), P422, DOI 10.1007/978-3-031-36336-8_66; Crothers E., 2022, ARXIV ABS221007321; Cu M. A., 2023, SCORES STANFORD STUD; Deane P., 2018, Behavioral differences between retyping, drafting, and editing: A writing process analysis; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; ETS, TEST DAY WHAT EXPECT; ETS, 2020, ETS NEWS INSIGHTS; Fife J. H., 2017, RES MEMORANDUM ETS R; Gierl M.J., 2012, Automatic item generation: Theory and practice; Google, 2023, PATHWAYS LANGUAGE MO; Griffin P, 2014, ASSESSMENT FOR TEACHING, P1; Haberman S. J., 2017, ETS RES REPORT NO RR, V2017, P1, DOI DOI 10.1002/ETS2.12150; Hao J., 2021, Computational Psychometrics: New Methodologies for a New Generation of Digital Learning and Assessment, P133; Hao J., 2023, MACHINE LEARNING NAT; Hao J., 2023, CHATGPT ASSESSMENTS; Hao J., 2019, ETS Research Report Series, V2019, P1, DOI [DOI 10.1002/ETS2.12276, 10.1002/ets2.12276]; Hao J., 2018, ETS RES REP SER, V2018, P1, DOI DOI 10.1002/ETS2.12215; Hao J., 2023, DETECTING CHATGPT GE; Hao JG, 2017, METHOD EDUC MEAS, P135, DOI 10.1007/978-3-319-33261-1_9; Heilman M., 2015, Proceedings of the tenth workshop on innovative use of NLP for building educational applications, P81, DOI DOI 10.3115/V1/W15-0610; Hendy A., 2023, GOOD ARE GPT MODELS; HORNKE LF, 1986, APPL PSYCH MEAS, V10, P369, DOI 10.1177/014662168601000405; Huang HP, 2010, PHYS REV E, V81, DOI 10.1103/PhysRevE.81.036104; Ivanova I., 2023, CBS News; Jafari, 2022, AUTOMATED SPEECH SCO; Jung J., 2023, COMBINING MACHINE TR; Jung J., 2022, PSYCHOL TEST ASSESSM, V64, P471; Jurafsky D., 2021, SPEECH LANGUAGE PROC; Kingston N., 2014, TEST FRAUD STAT DETE; Korn J., 2023, THE CNN; LaFlair G.T., 2023, INTERACTIVE LISTENIN; Ha LA, 2019, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P11; Lee YH, 2021, J EDUC BEHAV STAT, V46, P611, DOI 10.3102/1076998621994563; Lee YH, 2013, PSYCHOMETRIKA, V78, P557, DOI [10.1007/S11336-013-9317-5, 10.1007/s11336-013-9317-5]; Lennon C., 2004, LEXILE FRAMEWORK APP; Liang W., 2023, GPT DETECTORS ARE BI; Liu P., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.13586; Lottridge S., 2023, PAPER PRESENTED NATL; Lottridge S., 2022, ADV NATURAL LANGUAGE, P15; Lottridge S., 2023, NATL COUNCIL MEASURE; Lottridge S., 2022, AUTOMATED SCORING PE; Loukina Anastassia., 2016, P COLING 2016 26 INT, P3245; Maddison L., 2023, SAMSUNG WORKERS MADE; Madhvani N., 2023, 25 BEST GENERATIVE A; Man KW, 2019, J EDUC MEAS, V56, P251, DOI 10.1111/jedm.12208; Markauskaite L., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100056; McCarthy AD, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P883; Meijer R.R., 2006, Detection of advance item knowledge using response times in computer adaptive testing (Law School Admission Council Computerized Testing Report, 03-03); Metz C., 2023, New York Times; Mislevy R.J., 2006, Automated scoring of complex tasks in computer-based testing, P15; Mukherjee S., 2023, EU PROPOSES NEW COPY; Naismith B., 2023, P 18 WORKSHOP INNOVA, P394, DOI DOI 10.18653/V1/2023.BEA-1.32; Nathan M.J., 2022, Foundations of embodied learning: A paradigm for education; Nayyeri P., 2023, OPENAI USING CHATGPT; OECD, 2017, PISA 2015 RESULTS VO, DOI [10.1787/9789264285521-en1, DOI 10.1787/9789264285521-EN1]; OpenAi, 2022, Chatgpt; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ormerod C., 2022, ARXIV; Ouyang L., 2022, TRAINING LANGUAGE MO, DOI DOI 10.48550/ARXIV.2203.02155; Peng S., 2023, IMPACT AI DEVELOPER; Primoli V., 2011, PAPER PRESENTED ANN; Radford A., 2018, IMPROVING LANGUAGE U; Revell E., 2023, GOOGLE OPENAI RESTRI; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Salomon G., 1991, EDUC RESEARCHER, V20, P2, DOI DOI 10.3102/0013189X020003002; Settles B, 2020, T ASSOC COMPUT LING, V8, P247, DOI 10.1162/tacl_a_00310; Shneiderman B, 2021, ISSUES SCI TECHNOL, V37, P56; Sinharay S, 2017, J EDUC MEAS, V54, P200, DOI 10.1111/jedm.12141; Sinharay S, 2017, EDUC PSYCHOL MEAS, V77, P54, DOI 10.1177/0013164416632287; Skorupski W. P., 2011, PAPER PRESENTED ANN; Slashdot, 2023, US; Sotaridona LS, 2003, J EDUC MEAS, V40, P53, DOI 10.1111/j.1745-3984.2003.tb01096.x; Sukkarieh J.Z., 2012, ETS RES REPORT SERIE, DOI [10.1002/j.2333-8504.2012.tb02307.x, DOI 10.1002/J.2333-8504.2012.TB02307.X]; Terry Owen Kichizo., 2023, The Chronicle of Higher EducationMay 12; Tian E., 2023, Gptzero; van der Linden WJ, 2008, PSYCHOMETRIKA, V73, P365, DOI 10.1007/s11336-007-9046-8; van der Linden WJ, 2012, J EDUC BEHAV STAT, V37, P180, DOI 10.3102/1076998610396899; Vaswani A., 2017, Advances in neural information processing systems, P6000; von Davier AA., 2021, Computational Psychometrics: New Methodologies for a New Generation of Digital Learning and Assessment: With Examples in R and Python, DOI [10.1007/978-3-030-74394-9, DOI 10.1007/978-3-030-74394-9]; von Davier AA, 2017, COMPUT HUM BEHAV, V76, P631, DOI 10.1016/j.chb.2017.04.059; von Davier AA, 2017, J EDUC MEAS, V54, P3, DOI 10.1111/jedm.12129; von Davier M., 2022, AUTOMATED SCORING GR; von Davier M., 2019, TRAINING OPTIMUS PRI; von Davier M, 2023, EDUC PSYCHOL MEAS, V83, P556, DOI 10.1177/00131644221098021; von Davier M, 2018, MEAS-INTERDISCIP RES, V16, P59, DOI 10.1080/15366367.2018.1436827; von Davier M, 2018, PSYCHOMETRIKA, V83, P847, DOI 10.1007/s11336-018-9608-y; Wang A., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1911.11763; Waters R., 2023, CHEGG IS HARBINGER A; Wei J., 2023, 36 C NEURAL INFORM P; Wei J., 2022, FINETUNED LANGUAGE M, DOI DOI 10.48550/ARXIV.2109.01652; Wollack J. A., 2013, HDB TEST SECURITY; Wollack JA, 2017, EDUC PSYCHOL HANDB, P214; Wollack JA, 2015, EDUC PSYCHOL MEAS, V75, P931, DOI 10.1177/0013164414568716; Xue K, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P193; Yan D., 2023, PSYCHOL TEST ASSESSM, V65; Yancey K. B., 2023, P 18 WORKSHOP INNOVA, P576; Zhang B, 2022, PR MACH LEARN RES; Zu J., 2023, Psychological Testing and Assessment Modeling, V65, P55	116	0	0	40	40	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0731-1745	1745-3992		EDUC MEAS-ISSUES PRA	Educ. Meas.-Issues Pract.	JUN	2024	43	2					16	29		10.1111/emip.12602	http://dx.doi.org/10.1111/emip.12602		APR 2024	14	Education & Educational Research; Psychology, Educational	Social Science Citation Index (SSCI)	Education & Educational Research; Psychology	RN6Z9					2024-07-03	WOS:001196573900001
J	Tavares, C; Oliveira, L; Duarte, P; da Silva, MM				Tavares, Celia; Oliveira, Luciana; Duarte, Pedro; da Silva, Manuel Moreira			Artificial Intelligence: A Blessing or a Threat for Language Service Providers in Portugal	INFORMATICS-BASEL			English	Article						artificial intelligence; neural machine translation; large language models; language service providers; translators; interpreters		According to a recent study by OpenAI, Open Research, and the University of Pennsylvania, large language models (LLMs) based on artificial intelligence (AI), such as generative pretrained transformers (GPTs), may have potential implications for the job market, specifically regarding occupations that demand writing or programming skills. This research points out that interpreters and translators are one of the main occupations with greater exposure to AI in the US job market (76.5%), in a trend that is expected to affect other regions of the globe. This article, following a mixed-methods survey-based research approach, provides insights into the awareness and knowledge about AI among Portuguese language service providers (LSPs), specifically regarding neural machine translation (NMT) and large language models (LLM), their actual use and usefulness, as well as their potential influence on work performance and the labour market. The results show that most professionals are unable to identify whether AI and/or automation technologies support the tools that are most used in the profession. The usefulness of AI is essentially low to moderate and the professionals who are less familiar with it and less knowledgeable also demonstrate a lack of trust in it. Two thirds of the sample estimate negative or very negative effects of AI in their profession, expressing the devaluation and replacement of experts, the reduction of income, and the reconfiguration of the career of translator to mere post-editors as major concerns.	[Tavares, Celia; Oliveira, Luciana; Duarte, Pedro; da Silva, Manuel Moreira] Polytech Porto, CEOSPP, ISCAP, P-4465004 Porto, Portugal	Instituto Politecnico do Porto; Universidade do Porto; Centre for Organisational & Social Studies of the Polytechnic Institute of Porto (CEOS.PP)	Oliveira, L (corresponding author), Polytech Porto, CEOSPP, ISCAP, P-4465004 Porto, Portugal.	celiat@iscap.ipp.pt; lgo@eu.ipp.pt; pduarte@iscap.ipp.pt; mdasilva@iscap.ipp.pt	Duarte, Pedro/KMX-8533-2024; Oliveira, Luciana/B-8339-2016; Tavares, Célia/HKW-6691-2023; Silva, Manuel/R-9753-2016	Oliveira, Luciana/0000-0003-2419-4332; Tavares, Célia/0000-0002-6201-8690; Duarte, Pedro/0000-0002-1586-2012; Silva, Manuel/0000-0002-5966-4229	FCT-Fundao para a Cincia e Tecnologia	FCT-Fundao para a Cincia e Tecnologia	No Statement Available	amazon, AWS Lex-Amazon Web Services; Blender, Bot 2.0: An Open Source Chatbot That Builds Long-Term Memory and Searches the Internet.; Bowker L, 2020, ROU HBK TRANSL INTER, P453; Castilho Sheila, 2017, Prague Bulletin of Mathematical Linguistics, P109, DOI 10.1515/pralin-2017-0013; DialoGPT, Microsoft Research; Downie Jonathan, 2020, Interpreters vs Machines. Can Interpreters Survive in an AI-Dominated World?; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; FACT, 2022, MR Language Services Market Outlook; googleblog, Towards a Conversational Agent That Can Chat About ... Anything ...; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kirov V, 2022, SOCIETIES, V12, DOI 10.3390/soc12020070; Larson RB, 2019, INT J MARKET RES, V61, P534, DOI 10.1177/1470785318805305; Lee TK, 2023, APPL LINGUIST REV, DOI 10.1515/applirev-2023-0122; Li X.L., 2023, Routledge Encyclopedia of Translation Technology; Jiménez EAL, 2021, J INF COMMUN ETHICS, V19, P249, DOI 10.1108/JICES-03-2020-0034; Mckinsey, The State of AI in 2022-And A Half Decade in Review; Mordor Intelligence, Machine Translation Market Analysis-Industry Report-Trends, Size & Share; Patwardhan N, 2023, INFORMATION, V14, DOI 10.3390/info14040242; Stahlberg F, 2020, J ARTIF INTELL RES, V69, P343, DOI 10.1613/jair.1.12007; Wolf C.T., 2019, XRDS Crossroads ACM Mag. Stud, V25, P8, DOI [10.1145/3312530, DOI 10.1145/3312530]; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Zoph B, 2016, Arxiv, DOI arXiv:1604.02201	22	1	1	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9709		INFORMATICS-BASEL	Informatics-Basel	DEC	2023	10	4							81	10.3390/informatics10040081	http://dx.doi.org/10.3390/informatics10040081			21	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	DG9K4		gold, Green Submitted			2024-07-03	WOS:001130992000001
J	Zhang, ZH; Huang, XM				Zhang, Zhihui; Huang, Xiaomeng			The impact of chatbots based on large language models on second language vocabulary acquisition	HELIYON			English	Article						Large language models; Chatbot; Second language acquisition; Vocabulary learning		In recent years, the integration of artificial intelligence (AI) and machine learning (ML) into education, particularly for Personalized Language Learning (PLL), has garnered significant attention. This approach tailors interventions to address the unique challenges faced by individual learners. Large Language Models (LLMs), including Chatbots, have demonstrated a substantial potential in automating and enhancing educational tasks, effectively capturing the complexity and diversity of human language. In this study, 52 foreign language students were randomly divided into two groups: one with the assistance of a Chatbot based on LLMs and one without. Both groups learned the same series of target words over eight weeks. Post-treatment assessments, including systematic observation and quantitative tests assessing both receptive and productive vocabulary knowledge, were conducted immediately after the study and again two weeks later. The findings demonstrate that employing an AI Chatbot based on LLMs significantly aids students in acquiring both receptive and productive vocabulary knowledge during their second language learning journey. Notably, Chatbots contribute to the long-term retention of productive vocabulary and facilitate incidental vocabulary learning. This study offers valuable insights into the practical benefits of LLM-based tools in language learning, with a specific emphasis on vocabulary development. Chatbots utilizing LLMs emerge as effective language learning aids. It emphasizes the importance of educators understanding the potential of these technologies in L2 vocabulary instruction and encourages the adoption of strategic teaching methods incorporating such tools.	[Zhang, Zhihui] Univ Southern Calif, Rossier Sch Educ, 3551 Trousdale Pkwy, Los Angeles, CA 90089 USA; [Huang, Xiaomeng] Alibaba Cloud, 969 West Wen Yi Rd Yu Hang Dist, Hangzhou 311121, Zhejiang, Peoples R China	University of Southern California; Alibaba Group	Zhang, ZH (corresponding author), Univ Southern Calif, Rossier Sch Educ, 3551 Trousdale Pkwy, Los Angeles, CA 90089 USA.	zhihuiz@usc.edu		ZHANG, ZHIHUI/0000-0002-0277-4937				Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Afzaal M, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.723447; Alam A., 2021, 2021 INT C COMP INT, P1, DOI 10.1109/ICCICA52458.2021.9697272; Alemi M., 2011, Journal of Language Teaching and Research, V2, P81, DOI [10.4304/j1tr.2.1.81-98, DOI 10.4304/J1TR.2.1.81-98]; Bajaj Richa, 2018, Procedia Computer Science, V132, P834, DOI 10.1016/j.procs.2018.05.095; Cai MY, 2020, IEEE INT CONF ADV LE, P295, DOI 10.1109/ICALT49669.2020.00096; Chen HL, 2020, J EDUC COMPUT RES, V58, P1161, DOI 10.1177/0735633120929622; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Chiu TKF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2172044; Christiano PF, 2017, ADV NEUR IN, V30; Coniam David, 2008, ReCALL, V20, P98, DOI 10.1017/S0958344008000815; Daniels-Koch O., 2022, arXiv, DOI DOI 10.48550/ARXIV.2211.06519; Dokukina Irina, 2020, Procedia Computer Science, P542, DOI 10.1016/j.procs.2020.02.212; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Elkins Sabina, 2023, Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners, Doctoral Consortium and Blue Sky: 24th International Conference, AIED 2023, Proceedings. Communications in Computer and Information Science (1831), P536, DOI 10.1007/978-3-031-36336-8_83; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haristiani Nuria, 2019, Journal of Physics: Conference Series, V1387, DOI 10.1088/1742-6596/1387/1/012020; Hong W. C. H., 2023, Journal of Educational Technology and Innovation, V5; Hsu CCY, 2020, Arxiv, DOI arXiv:2009.10897; Huang AYQ, 2023, COMPUT EDUC, V194, DOI 10.1016/j.compedu.2022.104684; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Karyotaki M., 2022, Technium Social Sciences Journal, V30, P109; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim N.Y., 2018, Journal of Digital Convergence, V16; Kraus M, 2023, Arxiv, DOI [arXiv:2304.00116, DOI 10.48550/ARXIV.2304.00116]; Kweon S.O., 2008, Beyond Raw Frequency: Incidental Vocabulary Acquisition in Extensive Reading; Laufer B., 1999, Language Testing, V16, P33, DOI [10.1177/026553229901600103, DOI 10.1177/026553229901600103]; Levy M., 1997, COMPUT ASSIST LANG L; Li B, 2023, INT J COMPUT-ASSIST, V13, DOI 10.4018/IJCALLT.326135; Nation I., 2022, Learning vocabulary in another language, V3rd, DOI [DOI 10.1017/9781009093873, 10.1017/9781009093873]; Puchert P, 2023, Arxiv, DOI arXiv:2304.00457; Qasem F., 2023, Saudi Journal of Language Studies, V3, P76, DOI [10.1108/sjls-10-2022-0072, DOI 10.1108/SJLS-10-2022-0072]; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Ramos FDR, 2015, PROFILE-BOGOTA, V17, P157, DOI 10.15446/profile.v17n1.43957; Read J., 1998, Word associates test; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Sippel L, 2019, FOREIGN LANG ANN, V52, P595, DOI 10.1111/flan.12416; Timpe-Laughlin V, 2022, COMPUT ASSIST LANG L, V35, P1194, DOI 10.1080/09588221.2020.1774904; Wang CG, 2019, Arxiv, DOI [arXiv:1904.09408, DOI 10.48550/ARXIV.1904.09408]; Webb S, 2008, STUD SECOND LANG ACQ, V30, P79, DOI 10.1017/S0272263108080042; Yang S.-C., 2019, Communications in Computer and Information Science, P79, DOI [DOI 10.1007/978-981-15-1758-7_7, 10.1145/3371647.3371659, DOI 10.1145/3371647.3371659]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang WX, 2023, Arxiv, DOI arXiv:2305.15005; Ziebart B.D., 2010, P 27 INT C MACHINE L	44	0	0	49	49	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2405-8440		HELIYON	Heliyon	FEB 15	2024	10	3							e25370	10.1016/j.heliyon.2024.e25370	http://dx.doi.org/10.1016/j.heliyon.2024.e25370			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	KH1O1	38333802	Green Published, gold			2024-07-03	WOS:001178977400001
J	Shumway, DO; Hartman, HJ				Shumway, David O.; Hartman, Hayes J.			Medical malpractice liability in large language model artificial intelligence: legal review and policy recommendations	JOURNAL OF OSTEOPATHIC MEDICINE			English	Article						artificial intelligence; ChatGPT; large language models; liability; medical malpractice		The emergence of generative large language model (LLM) artificial intelligence (AI) represents one of the most profound developments in healthcare in decades, with the potential to create revolutionary and seismic changes in the practice of medicine as we know it. However, significant concerns have arisen over questions of liability for bad outcomes associated with LLM AI-influenced medical decision making. Although the authors were not able to identify a case in the United States that has been adjudicated on medical malpractice in the context of LLM AI at this time, sufficient precedent exists to interpret how analogous situations might be applied to these cases when they inevitably come to trial in the future. This commentary will discuss areas of potential legal vulnerability for clinicians utilizing LLM AI through review of past case law pertaining to third-party medical guidance and review the patchwork of current regulations relating to medical malpractice liability in AI. Finally, we will propose proactive policy recommendations including creating an enforcement duty at the US Food and Drug Administration (FDA) to require algorithmic transparency, recommend reliance on peer-reviewed data and rigorous validation testing when LLMs are utilized in clinical settings, and encourage tort reform to share liability between physicians and LLM developers.	[Shumway, David O.] Keesler Med Ctr, 301 Fisher St, Biloxi, MS 39534 USA		Shumway, DO (corresponding author), Keesler Med Ctr, 301 Fisher St, Biloxi, MS 39534 USA.	doshumway@live.com						American Medical Association, STAT MED LIAB REF; [Anonymous], 1954, JULIAN BARKER; [Anonymous], 1999, SPENSIERI LASKY; [Anonymous], 1976, LHOTKA LARSON; [Anonymous], 1974, MUELLER MUELLER; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Blackstone William., 1962, COMMENTARIES LAWS EN; Centers for Medicare and Medicaid Services, 2022, AFFORDABLE CARE ACT; Clark P, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.21792; congress.gov, S 1108 ALGORITHMIC A; Cutler DM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.2652; Duffourc M, 2023, JAMA-J AM MED ASSOC, V330, P313, DOI 10.1001/jama.2023.9630; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058; Price WN, 2019, JAMA-J AM MED ASSOC, V322, P1765, DOI 10.1001/jama.2019.15064; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; U.S. Food and Drug Administration, 2022, FDA2017D6569; Wyden Booker, CLARKE INTRO BILL RE	18	0	0	11	11	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY		2702-3648		J OSTEOPATH MED	J. Osteopath. Med.	JUN 26	2024	124	7					287	290		10.1515/jom-2023-0229	http://dx.doi.org/10.1515/jom-2023-0229		JAN 2024	4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	WJ0F0	38295300	hybrid			2024-07-03	WOS:001155099700001
J	Novikova, ML; Novikov, PN				Novikova, Marina L.; Novikov, Phillip N.			Analyzing the potential of using large language models for languages of peoples of the Russian Federation and the CIS in the modern digital space	FILOLOGICHESKIE NAUKI-NAUCHNYE DOKLADY VYSSHEI SHKOLY-PHILOLOGICAL SCIENCES-SCIENTIFIC ESSAYS OF HIGHER EDUCATION			Russian	Article						artificial intelligence; machine learning; languages of the peoples of Russia; large language models		In the timeframe from 2022 to 2023, the progress in the development of large language models, based on machine learning and neural network technologies, also referred to as "artificial intelligence", reached an unprecedented level. This facilitated making a significant leap for the application of natural language processing algorithms to both science and everyday life. The article examines the potential and current challenges of using these technologies with respect to the languages of the peoples of the Russian Federation and the CIS in the modern digital environment. The study touches upon such areas as translation, linguistic analysis, language popularization, and development of original language online services.	[Novikova, Marina L.] Peoples Friendship Univ Russia, Russian Language & Cultural Studies Dept, Moscow, Russia; [Novikov, Phillip N.] Peoples Friendship Univ Russia, Foreign Languages Dept, Moscow, Russia	Peoples Friendship University of Russia; Peoples Friendship University of Russia	Novikova, ML (corresponding author), Peoples Friendship Univ Russia, Russian Language & Cultural Studies Dept, Moscow, Russia.	novikova-ml@rudn.ru; philippnovikov@gmail.com						Athaluri S.A., 2023, Exploring the boundaries of reality: investigating the phenomenon of artificial intelligence hallucination in scientific writing through ChatGPT references, DOI [10.7759/cureus.37432//Cureus, DOI 10.7759/CUREUS.37432//CUREUS]; Avramenko A.P., 2023, Vestnik Moskovskogo gosudarstvennogo oblastnogo universiteta. Seriia: Pedagogika, P29; Bakhtikireeva U.M., 2022, Sokhranenie i razvitie iazykov i kul'tur korennykh narodov Sibiri, P7; Bakhtikireeva U.M., 2022, Lingvistika v dialoge s drugimi oblastiami znanii: iurislingvistika i diskursivnaia lingvistika, kommunikativnaia lingvistika i lingvokul'turologiia, P6; Bensemann J, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13300; Biswas S., 2023, MESOPOTAMIAN J COMPU, V2023, P8, DOI [10.58496/MJCSC/2023/002, DOI 10.58496/MJCSC/2023/002]; Burnashev R.F., 2022, Science and Education, P1390; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Hutchins W.J., 2023, Routledge encyclopedia of translation technology, V2nd, P128; Low D.S., 2022, Sustainable Multilingualism, V21, P1, DOI [10.2478/sm-2022-0011, DOI 10.2478/SM-2022-0011]; Zhang Lining, 2022, P 5 BLACKBOXNLP WORK, P297, DOI DOI 10.18653/V1/2022.BLACKBOXNLP-1.24	11	0	0	1	1	INOIT ALMAVEST	MOSCOW	UL VVEDENSKOGO, DOM 23A, STR 3, MOSCOW, 117342, RUSSIA	2310-4287			FILOL NAUK NAUCH DOK	Filol. Nauk.	NOV	2023		6		S			3	11		10.20339/PhS.6s-23.003	http://dx.doi.org/10.20339/PhS.6s-23.003			9	Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	HC4J8					2024-07-03	WOS:001157275300001
J	Benirschke, RC; Wodskow, J; Prasai, K; Freeman, A; Lee, JM; Groth, J				Benirschke, Robert C.; Wodskow, Joshua; Prasai, Kritika; Freeman, Andrew; Lee, John M.; Groth, John			Assessment of a large language model's utility in helping pathology professionals answer general knowledge pathology questions	AMERICAN JOURNAL OF CLINICAL PATHOLOGY			English	Article								Objectives: To assess the utility and performance of the large language model ChatGPT 4.0 regarding accuracy, completeness, and its potential as a time-saving tool for pathologists and laboratory directors.Methods: A deidentified database of questions previously sent to pathology residents from health care providers was used as a source of general knowledge-type pathology questions. These questions were submitted to the large language model and the responses graded by subject matter experts in different pathology subspecialties. The grading criteria assessed accuracy, completeness, and the potential time savings for helping the pathologist craft the response.Results: Overall, respondents thought that most of the answers would take less than 5 minutes of additional work to be used (85%). Accuracy and completeness for the 61 questions was high, with 98% of responses being at least "completely or mostly accurate" and 82% of responses "containing all relevant information." Of the respondents, 97% stated that the response would have "zero or near-zero potential for medical harm," and all thought the tool had potential to save time in constructing answers to health care providers' queries. Performance was similar in both Anatomic Pathology (AP) and Clinical Pathology (CP), with the only exception being some relevant information was excluded in 46% of AP answers vs only 10% in CP (P < .01).Conclusions: ChatGPT version 4.0 gave responses that were predominantly accurate and complete for general knowledge-type pathology questions. With further research and when reviewed by a pathologist or laboratorian, this could facilitate its use as a pathologist's aid in answering questions from health care providers.	[Benirschke, Robert C.; Wodskow, Joshua; Prasai, Kritika; Freeman, Andrew; Lee, John M.; Groth, John] NorthShore Univ HealthSyst, Dept Pathol & Lab Med, Evanston, IL 60201 USA; [Benirschke, Robert C.; Wodskow, Joshua; Prasai, Kritika; Freeman, Andrew; Lee, John M.; Groth, John] Univ Chicago, Pritzker Sch Med, Dept Pathol, Chicago, IL 60637 USA	NorthShore University Health System; University of Chicago	Benirschke, RC (corresponding author), NorthShore Univ HealthSyst, Dept Pathol & Lab Med, Evanston, IL 60201 USA.; Benirschke, RC (corresponding author), Univ Chicago, Pritzker Sch Med, Dept Pathol, Chicago, IL 60637 USA.	RBenirschke@northshore.org						Aggarwal A, 2023, J MED INTERNET RES, V25, DOI 10.2196/40789; Ahmed A, 2023, HEALTH INFORM J, V29, DOI 10.1177/14604582221146719; [Anonymous], 2022, SCOP PRACT BOARD CER; Branda JA, 2014, AM J CLIN PATHOL, V142, P144, DOI 10.1309/AJCP3NU7AOPPKYWO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Garcia E, 2019, AM J CLIN PATHOL, V152, P155, DOI [10.1093/ajcp/aqz046, 10.1093/AJCP/AQZ046]; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Jeblick K., 2022, ARXIV; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Metter DM, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.4337; OpenAI, 2023, ArXiv; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Theparee T, 2018, ACAD PATHOL, V5, DOI 10.1177/2374289518798820; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wells Kate, 2023, NPR; White J., 2023, ARXIV, DOI [DOI 10.48550/ARXIV.2302.11382, 10.48550/arxiv.2302.11382]	21	3	3	5	21	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	0002-9173	1943-7722		AM J CLIN PATHOL	Am. J. Clin. Pathol.	JAN 4	2024	161	1					42	48		10.1093/ajcp/aqad106	http://dx.doi.org/10.1093/ajcp/aqad106		SEP 2023	7	Pathology	Science Citation Index Expanded (SCI-EXPANDED)	Pathology	EC1M8	37658808				2024-07-03	WOS:001060710400001
J	Soos, C; Haroutunian, L				Soos, Carlin; Haroutunian, Levon			On the Question of Authorship in Large Language Models	KNOWLEDGE ORGANIZATION			English	Article						large language models; authorship; natural language processing; ChatGPT		Adoption of pre -trained large language models (LLMs) across an increasingly diverse range of tasks and domains poses significant problems for authorial attribution and other basic knowledge organization practices. Utilizing methods from value -sensitive design, this paper examines the theoretical, practical, and ethical issues introduced by LLMs and describes how their use challenges the supposedly firm boundaries separating specific works and creators. Focusing on the implications of LLM usage for higher education, we use hypothetical value scenarios and stakeholder analysis to weigh the pedagogical risks and benefits of LLM usage, assessing the consequences of their use on and beyond college campuses. While acknowledging the unique challenges presented by this emerging educational trend, we ultimately argue that the issues associated with these novel tools are indicative of preexisting limitations within standard entity -relationship models, not wholly new issues ushered in by the advent of a relatively young technology. We contend that LLM-generated texts largely exacerbate, rather than invent from scratch, the preexisting faults that have frequently posed problems to those seeking to determine, ascribe, and regulate authorship attributions. As the growing popularity of generative AI raises concerns about plagiarism, academic integrity, and intellectual property, we advocate for a reevaluation of reductive work -creator associations and encourage the adoption of more expansive authorial concepts.	[Soos, Carlin] UCLA, Dept Informat Studies, Los Angeles, CA 90095 USA; [Haroutunian, Levon] Univ Washington, Dept Linguist, Seattle, WA USA	University of California System; University of California Los Angeles; University of Washington; University of Washington Seattle	Soos, C (corresponding author), UCLA, Dept Informat Studies, Los Angeles, CA 90095 USA.	carlinsoos@gmail.com; levon.haroutunian@gmail.com						[Anonymous], 2022, OpenAI; Anthropic. N.d, Meet Claude; Bandy John, 2021, P NEUR INF PROC SYST; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Birhane A, 2022, arXiv, DOI [arXiv:2110.01963, DOI 10.48550/ARXIV.2110.01963]; Bloom Harold, 1997, ANXIETY INFLUENCE TH; Brown Tom B., Advances in Neural Information Processing Systems, V33, P1; Common Crawl, About; Cutter Charles A., 1876, Special Report on Public Libraries; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Deleuze Gilles., 2005, A Thousand Plateaus: Capitalism and Schizophrenia; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dey S., 2021, Reports of cheating at colleges soar during the pandemic; Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1286; Dolan Jill, 2023, Guidance on AI/ChatGPT: Memo to All Teaching Faculty-January 25, 2023; Foucault Michel., 1977, Language, Counter-Memory, Practice: Selected Essays and Interviews; Friedman Batya, 2017, Foundations and Trends in Human-Computer Interaction, V11, P63, DOI 10.1561/1100000015; Friedman B., 2007, The Human-Computer Interaction Handbook, P1267; Gehman S, 2020, M ASS FOR COMPUTATIO; Gnoli C, 2018, J DOC, V74, P1226, DOI 10.1108/JD-04-2018-0054; Hartocollis Anemona, 2024, The New York TimesJanuary 14; International Committee of Medical Journal Editors (ICMJE), 2023, Defining the Role of Authors and Contributors: Why Authorship Matters; Jenkins BD, 2023, TEACH PSYCHOL, V50, P407, DOI 10.1177/00986283211059067; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Leazer GH, 1999, P ASIS ANN, V36, P345; Leike Jan, 2022, Our approach to alignment research; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Littletree S, 2020, KNOWL ORGAN, V47, P410, DOI 10.5771/0943-7444-2020-5-410; Lock S., 2022, GUARDIAN; McCarthy Claudine, 2023, Dean & Provost, V24, P1, DOI [10.1002/dap.31202, DOI 10.1002/DAP.31202]; Nagel Sebastian, 2023, Common CrawlMarch/April; OpenAI, 2022, Introducing chatgpt; OpenAI, Enterprise; Ouyang Long, 2022, PREPRINT; Paullada A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100336; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037/0096-3445.104.3.192; Saussure Ferdinand de, 1959, Course in general linguistics; Smiraglia RP, 2007, CAT CLASSIF Q, V44, P179, DOI 10.1300/J104v44n03_02; Smiraglia RP, 2019, KNOWL ORGAN, V46, P308, DOI 10.5771/0943-7444-2019-4-308; Soos C, 2020, KNOWL ORGAN, V47, P486, DOI 10.5771/0943-7444-2020-6-486; Svenonius Elaine., 2009, The Intellectual Foundation of Information Organization; University of California Los Angeles (UCLA), 2023, ChatGPT and AI: Starting Points for Discussion; University of Washington, 2023, ChatGPT and other AIbased tools; University of Wisconsin-Madison, 2023, Considerations for Using AI in the Classroom; Vaswani A, 2017, ADV NEUR IN, V30; Vincent James, 2023, The VergeJanuary 18; Wager E, 2012, MATURITAS, V72, P165, DOI [10.5455/aim.2012.20.136-140, 10.1016/j.maturitas.2012.03.011]; Winkler T, 2021, ETHICS INF TECHNOL, V23, P17, DOI 10.1007/s10676-018-9476-2; Yang ZL, 2019, ADV NEUR IN, V32; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	56	0	0	0	0	NOMOS VERLAGSGESELLSCHAFT MBH & CO KG	BADEN-BADEN	WALDSEESTR 3 5, BADEN-BADEN, 76530, GERMANY	0943-7444			KNOWL ORGAN	Knowl. Organ.		2024	51	2					83	95		10.5771/0943-7444-2024-2-83	http://dx.doi.org/10.5771/0943-7444-2024-2-83			13	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	QP4J5					2024-07-03	WOS:001222058300001
J	Buhr, CR; Smith, H; Huppertz, T; Bahr-Hamm, K; Matthias, C; Cuny, C; Snijders, JP; Ernst, BP; Blaikie, A; Kelsey, T; Kuhn, S; Eckrich, J				Buhr, Christoph R.; Smith, Harry; Huppertz, Tilman; Bahr-Hamm, Katharina; Matthias, Christoph; Cuny, Clemens; Snijders, Jan Phillipp; Ernst, Benjamin Philipp; Blaikie, Andrew; Kelsey, Tom; Kuhn, Sebastian; Eckrich, Jonas			Assessing unknown potential-quality and limitations of different large language models in the field of otorhinolaryngology	ACTA OTO-LARYNGOLOGICA			English	Article						Large language models; artificial intelligence; ChatGPT; Bard; Claude; otorhinolaryngology; digital health; chatbots; global health; chatbot	CHALLENGES; HEALTH	Background: Large Language Models (LLMs) might offer a solution for the lack of trained health personnel, particularly in low- and middle-income countries. However, their strengths and weaknesses remain unclear. Aims/objectives: Here we benchmark different LLMs (Bard 2023.07.13, Claude 2, ChatGPT 4) against six consultants in otorhinolaryngology (ORL). Material and methods: Case-based questions were extracted from literature and German state examinations. Answers from Bard 2023.07.13, Claude 2, ChatGPT 4, and six ORL consultants were rated blindly on a 6-point Likert-scale for medical adequacy, comprehensibility, coherence, and conciseness. Given answers were compared to validated answers and evaluated for hazards. A modified Turing test was performed and character counts were compared. Results: LLMs answers ranked inferior to consultants in all categories. Yet, the difference between consultants and LLMs was marginal, with the clearest disparity in conciseness and the smallest in comprehensibility. Among LLMs Claude 2 was rated best in medical adequacy and conciseness. Consultants' answers matched the validated solution in 93% (228/246), ChatGPT 4 in 85% (35/41), Claude 2 in 78% (32/41), and Bard 2023.07.13 in 59% (24/41). Answers were rated as potentially hazardous in 10% (24/246) for ChatGPT 4, 14% (34/246) for Claude 2, 19% (46/264) for Bard 2023.07.13, and 6% (71/1230) for consultants. Conclusions and significance: Despite consultants superior performance, LLMs show potential for clinical application in ORL. Future studies should assess their performance on larger scale.	[Buhr, Christoph R.; Huppertz, Tilman; Bahr-Hamm, Katharina; Matthias, Christoph; Eckrich, Jonas] Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Otorhinolaryngol, Langenbeckstr 1, D-55131 Mainz, Rhineland Palat, Germany; [Buhr, Christoph R.; Blaikie, Andrew] Univ St Andrews, Sch Med, St Andrews, Scotland; [Smith, Harry; Kelsey, Tom] Univ St Andrews, Sch Comp Sci, St Andrews, Scotland; [Cuny, Clemens; Snijders, Jan Phillipp] Outpatient Clin, Dieburg, Germany; [Ernst, Benjamin Philipp] Univ Hosp Frankfurt, Dept Otorhinolaryngol, Frankfurt, Germany; [Kuhn, Sebastian] Philipps Univ Marburg, Univ Hosp Giessen & Marburg, Inst Digital Med, Marburg, Germany	Johannes Gutenberg University of Mainz; University of St Andrews; University of St Andrews; University of Hamburg; University Medical Center Hamburg-Eppendorf; Goethe University Frankfurt; Goethe University Frankfurt Hospital; University Hospital of Giessen & Marburg; Philipps University Marburg	Buhr, CR (corresponding author), Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Otorhinolaryngol, Langenbeckstr 1, D-55131 Mainz, Rhineland Palat, Germany.	buhrchri@uni-mainz.de		Kelsey, Tom/0000-0002-8091-1458; Blaikie, Andrew/0000-0001-7913-6872; Buhr, Christoph Raphael/0000-0002-9551-2310				[Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Ayoub NF, 2024, OTOLARYNG HEAD NECK, V170, P1484, DOI 10.1002/ohn.465; Buhr CR, 2023, JMIR MED EDUC, V9, DOI 10.2196/49183; Cabrera Johana, 2023, Bioinformatics and Biomedical Engineering: 10th International Work-Conference, IWBBIO 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Bioinformatics (13920), P313, DOI 10.1007/978-3-031-34960-7_22; Chee J, 2023, EUR ARCH OTO-RHINO-L, V280, P4687, DOI 10.1007/s00405-023-08135-1; Chiesa-Estomba CM, 2024, EUR ARCH OTO-RHINO-L, V281, P2777, DOI 10.1007/s00405-023-08267-4; Dallari V, 2024, EUR ARCH OTO-RHINO-L, V281, P995, DOI 10.1007/s00405-023-08321-1; Dawkins B, 2021, TROP MED INT HEALTH, V26, P1177, DOI 10.1111/tmi.13651; Dhar S, 2024, INT J PEDIATR OTORHI, V179, DOI 10.1016/j.ijporl.2024.111901; Eriksen AV., 2023, NEJM AI, V1, DOI [DOI 10.1056/AIP2300031, 10.1056/AIp2300031]; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Kuscu O, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1256459; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Long C, 2024, JMIR MED EDUC, V10, DOI 10.2196/49970; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Nicholas PK, 2006, POPUL RES POLICY REV, V25, P479, DOI 10.1007/s11113-006-9009-2; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Noda M, 2024, JMIR MED EDUC, V10, DOI 10.2196/57054; Pugliese G, 2023, CLIN CASE REP, V11, DOI 10.1002/ccr3.7933; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reineke U., 2007, FACHARZTPRFUNG HALS; Saibene AM, 2024, EUR ARCH OTO-RHINO-L, V281, P1835, DOI 10.1007/s00405-023-08372-4; Shen SA, 2024, EUR ARCH OTO-RHINO-L, V281, P3219, DOI 10.1007/s00405-024-08524-0; Thomas Lenarz H-GB., 2012, HALS NASEN OHREN HEI; Tu T., 2024, PREPRINT; Van Bokkelen G, 2015, CURR STEM CELL REP, V1, P102, DOI 10.1007/s40778-015-0013-5; Vaswani A, 2017, ADV NEUR IN, V30; Warrier A, 2024, LARYNGOSCOPE, DOI 10.1002/lary.31434; Zalzal HG, 2024, LARYNGOSCOPE INVEST, V9, DOI 10.1002/lio2.1193; Zalzal HG, 2023, OTO OPEN, V7, DOI 10.1002/oto2.94	31	0	0	1	1	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0001-6489	1651-2251		ACTA OTO-LARYNGOL	Acta Oto-Laryngol.	MAR 1	2024	144	3					237	242	2352843	10.1080/00016489.2024.2352843	http://dx.doi.org/10.1080/00016489.2024.2352843		MAY 2024	6	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	UR3G2	38781053	hybrid			2024-07-03	WOS:001230007900001
J	Park, D; An, GT; Kamyod, C; Kim, CG				Park, Daeseung; An, Gi-taek; Kamyod, Chayapol; Kim, Cheong Ghil			A Study on Performance Improvement of Prompt Engineering for Generative AI with a Large Language Model	JOURNAL OF WEB ENGINEERING			English	Article						AI; large language model; generative AI; few-shot learning; prompt engineering; AI Chatbot.		In the realm of Generative AI, where various models are introduced, prompt engineering emerges as a significant technique within natural language processing-based Generative AI. Its primary function lies in effectively enhancing the results of sentence generation by large language models (LLMs). Notably, prompt engineering has gained attention as a method capable of improving LLM performance by modifying the structure of input prompts alone. In this study, we apply prompt engineering to Korean-based LLMs, presenting an efficient approach for generating specific conversational responses with less data. We achieve this through the utilization of the query transformation module (QTM). Our proposed QTM transforms input prompt sentences into three distinct query methods, breaking them down into objectives and key points, making them more comprehensible for LLMs. For performance validation, we employ Korean versions of LLMs, specifically SKT GPT-2 and Kakaobrain KoGPT-3. We compare four different query methods, including the original unmodified query, using Google SSA to assess the naturalness and specificity of generated sentences. The results demonstrate an average improvement of 11.46% when compared to the unmodified query, underscoring the efficacy of the proposed QTM in achieving enhanced performance.	[Park, Daeseung; Kim, Cheong Ghil] Namseoul Univ, Dept Comp Sci, Cheonan, South Korea; [An, Gi-taek] Korea Food Res Inst, Wonju 55365, South Korea; [Kamyod, Chayapol] Mae Fah Luang Univ, Sch Informat Technol, Comp & Commun Engn Capac Bldg Res Ctr, Chiang Rai 57100, Thailand	Namseoul University; Korea Food Research Institute (KFRI); Mae Fah Luang University	Kim, CG (corresponding author), Namseoul Univ, Dept Comp Sci, Cheonan, South Korea.	dspark@daeseungpark.com; gt@kfri.re.kr; chayapol.kam@mfu.ac.th; cgkim@nsu.ac.kr		An, Gi-taek/0009-0005-7131-8889	National Research Foundation of Korea Grant - Korean Government [NRF-2021R1I1A4A01049755]; MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program [IITP-2020-001846]	National Research Foundation of Korea Grant - Korean Government(National Research Foundation of Korea); MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program(Ministry of Science & ICT (MSIT), Republic of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This work was supported by the National Research Foundation of Korea Grant funded by the Korean Government (NRF-2021R1I1A4A01049755) and by the MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center) support program (IITP-2020-001846) supervised by the IITP (Institute of Information and Communications Technology Planning and Evaluation).	An S., 2023, Software Policy & Research Institute Issue Report IS-158, V1; Bisong E., 2019, BUILDING MACHINE LEA, P59, DOI [10.1007/978-1-4842-4470-8_7, DOI 10.1007/978-1-4842-4470-87]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Google Research Blog, Towards a Conversational Agent that Can Chat About ...  Anything ...; Gozalo-Brizuela R., 2023, arXiv; Hadi M.U., 2023, PREPRINT, DOI [10.36227/techrxiv.23589741.v1, DOI 10.36227/TECHRXIV.23589741.V1]; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Kulshreshtha A., Towards a Human-like Open-Domain Chatbot; Lee Sang-Woo, 2023, Communications of the Korean Institute of Information Scientists and Engineers, V41, P91; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Monteiro T., 2023, gHacks Tech NewsMarch 10; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ravi Sachin, 2017, INT C LEARN REPR; Sukhdeve D. S. R., 2023, GOOGLE CLOUD PLATFOR, P11, DOI [10.1007/978-1-4842-9688-2_2, DOI 10.1007/978-1-4842-9688-2_2]; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2016, 30 C NEURAL INFORM P, V29; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wikipedia contributors, Language Integrated Query. InWikipedia, The Free Encyclopedia; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	29	0	0	46	46	RIVER PUBLISHERS	GISTRUP	ALSBJERGVEJ 10, GISTRUP, 9260, DENMARK	1540-9589	1544-5976		J WEB ENG	J. Web Eng.		2023	22	8					1187	1206		10.13052/jwe1540-9589.2285	http://dx.doi.org/10.13052/jwe1540-9589.2285			20	Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KY5W4					2024-07-03	WOS:001183552300005
C	Itagaki, T; Li, R			ACM	Itagaki, Toma; Li, Richard			Smart-Pikachu: Extending Interactivity of Stufed Animals with Large Language Models	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		Empathetic Computing; Prompt Design		We propose Smart-Pikachu, a stufed animal equipped with sensing and actuation to explore the use of large language models (LLM's) with sensor data inputs. The augmentation of pressure sensing will allow for the LLM to interpret various interactions such as hugs and handshakes with the user. Furthermore, the actuation capabilities will extend our system's interactivity by providing physical feedback to the user. We will also incorporate text-to-speech output from the LLM to add another mode of interaction between the system and user. In this Student Innovation Challenge, we intend to explore applications at the intersection of sensing and interaction through LLM's and demonstrate an extension of LLMs' multimodal capabilities.	[Itagaki, Toma] Columbia Univ, New York, NY 10027 USA; [Li, Richard] Paul G Allen Sch Comp Sci & Engn, Seattle, WA USA	Columbia University	Itagaki, T (corresponding author), Columbia Univ, New York, NY 10027 USA.	toma@cs.columbia.edu; lichard@cs.washington.edu						Binnard M, 2000, J MECH DESIGN, V122, P91, DOI 10.1115/1.533549; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Dollar AM, 2006, IEEE-ASME T MECH, V11, P154, DOI 10.1109/TMECH.2006.871090; Kiaghadi Ali, 2022, P 20 ANN INT C MOB S, P1; Liu X, 2023, Arxiv, DOI arXiv:2305.15525; Wu Y, 2023, Arxiv, DOI arXiv:2305.02412	6	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									114	10.1145/3586182.3625219	http://dx.doi.org/10.1145/3586182.3625219			2	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000113
J	Stavropoulos, A; Crone, DL; Grossmann, I				Stavropoulos, Alexander; Crone, Damien L.; Grossmann, Igor			Shadows of wisdom: Classifying meta-cognitive and morally grounded narrative content via large language models	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						NLP; Wisdom; Computational social science; Social science methods; Content analysis	AGREEMENT	We investigated large language models' (LLMs) efficacy in classifying complex psychological constructs like intellectual humility, perspective-taking, open-mindedness, and search for a compromise in narratives of 347 Canadian and American adults reflecting on a workplace conflict. Using state-of-the-art models like GPT-4 across few-shot and zero-shot paradigms and RoB-ELoC (RoBERTa -fine-tuned-on-Emotion-with-Logistic-Regression-Classifier), we compared their performance with expert human coders. Results showed robust classification by LLMs, with over 80% agreement and F1 scores above 0.85, and high human-model reliability (Cohen's kappa Md across top models = .80). RoB-ELoC and few-shot GPT-4 were standout classifiers, although somewhat less effective in categorizing intellectual humility. We offer example workflows for easy integration into research. Our proof-of-concept findings indicate the viability of both open-source and commercial LLMs in automating the coding of complex constructs, potentially transforming social science research.	[Stavropoulos, Alexander; Grossmann, Igor] Univ Waterloo, Dept Psychol, Waterloo, ON N2L 3G1, Canada; [Crone, Damien L.] Northeastern Univ, Boston, MA USA	University of Waterloo; Northeastern University	Grossmann, I (corresponding author), Univ Waterloo, Dept Psychol, Waterloo, ON N2L 3G1, Canada.	igrossma@uwaterloo.ca			Social Sciences and Humanities Research Council of Canada	Social Sciences and Humanities Research Council of Canada(Social Sciences and Humanities Research Council of Canada (SSHRC))	No Statement Available	Adoma AF, 2020, I COMP CONF WAVELET, P117, DOI 10.1109/ICCWAMTIP51612.2020.9317379; ANDERSON J, 1983, J READING, V26, P490; Barrett LF, 2022, AM PSYCHOL, V77, P894, DOI 10.1037/amp0001054; Benoit K, 2016, AM POLIT SCI REV, V110, P278, DOI 10.1017/S0003055416000058; Brienza JP, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23432-1; Brienza JP, 2018, J PERS SOC PSYCHOL, V115, P1093, DOI 10.1037/pspp0000171; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buechel S, 2018, Arxiv, DOI [arXiv:1808.10399, DOI 10.48550/ARXIV.1808.10399, 10.48550/arXiv.1808.10399]; Chan JYL, 2023, ARTIF INTELL REV, V56, P749, DOI 10.1007/s10462-022-10183-8; Cofie Nicholas, 2022, Can Med Educ J, V13, P73, DOI 10.36834/cmej.72504; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Costello T. H., 2023, PsyArXiv, DOI [10.31234/osf.io/gux95, DOI 10.31234/OSF.IO/GUX95]; CRONBACH LJ, 1955, PSYCHOL BULL, V52, P281, DOI 10.1037/h0040957; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Dodge J, 2020, Arxiv, DOI [arXiv:2002.06305, 10.48550/arXiv.2002.06305]; Dunning David, 2004, Psychol Sci Public Interest, V5, P69, DOI 10.1111/j.1529-1006.2004.00018.x; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Flyvbjerg B., 2001, Making Social Science Matter: Why social inquiry fails and how it can succeed again, DOI DOI 10.1017/CBO9780511810503; Fort K, 2011, COMPUT LINGUIST, V37, P413, DOI 10.1162/COLI_a_00057; Garten J., 2016, P IJCAI 2016 WORKSH; Glück J, 2018, J GERONTOL B-PSYCHOL, V73, P1393, DOI 10.1093/geronb/gbx140; Grossmann I, 2023, SCIENCE, V380, P1108, DOI 10.1126/science.adi1778; Grossmann I, 2020, PSYCHOL INQ, V31, P103, DOI 10.1080/1047840X.2020.1750917; Grossmann I, 2017, NAT HUM BEHAV, V1, DOI 10.1038/s41562-017-0061; Grossmann I, 2013, J EXP PSYCHOL GEN, V142, P944, DOI 10.1037/a0029560; Hartmann J, 2023, INT J RES MARK, V40, P75, DOI 10.1016/j.ijresmar.2022.05.005; HATTIE J, 1984, APPL PSYCH MEAS, V8, P295, DOI 10.1177/014662168400800306; Hosmer DW., 2013, Applied Logistic Regression, DOI [10.1002/9781118548387, DOI 10.1002/9781118548387]; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Karlan B, 2024, J EXP THEOR ARTIF IN, V36, P257, DOI 10.1080/0952813X.2022.2092559; Kern AI., 2023, Refinery. refinery-Kern AI-Documentation; Khanjani A., 2011, 2011 IEEE Symposium on Computers & Informatics (ISCI), P646, DOI 10.1109/ISCI.2011.5958992; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Koetke J, 2022, SOC PSYCHOL PERS SCI, V13, P277, DOI 10.1177/1948550620988242; Krippendorff K., 1980, CONTENT ANAL INTRO I; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lialin V, 2023, Arxiv, DOI [arXiv:2303.15647, 10.48550/arXiv.2303.15647]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lyons BA, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2019527118; MacQueen KM., 1998, CAM Journal, V10, P31, DOI DOI 10.1177/1525822X980100020301; Messeri L, 2024, NATURE, V627, P49, DOI 10.1038/s41586-024-07146-0; OpenAI, 2023, Models. OpenAI Platform; Pargent F, 2023, ADV METH PRACT PSYCH, V6, DOI 10.1177/25152459231162559; Pennycook G, 2020, PSYCHOL SCI, V31, P770, DOI 10.1177/0956797620939054; Porter T, 2022, NAT REV PSYCHOL, V1, P524, DOI 10.1038/s44159-022-00081-9; Price P., 2015, Research methods in psychology; Rathje S., 2023, GPT is an effective tool for multilingual psychological text analysis, DOI [10.31234/osf.io/sekf5, DOI 10.31234/OSF.IO/SEKF5]; Robinson MD, 2002, PSYCHOL BULL, V128, P934, DOI 10.1037//0033-2909.128.6.934; Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791; Shushkevich E, 2023, INVENTIONS-BASEL, V8, DOI 10.3390/inventions8050112; Sun XH, 2021, APPL INTELL, V51, P3600, DOI 10.1007/s10489-020-02075-7; Torre JB, 2018, EMOT REV, V10, P116, DOI 10.1177/1754073917742706; Vazire S, 2011, CURR DIR PSYCHOL SCI, V20, P104, DOI 10.1177/0963721411402478; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Wei JS, 2022, ADV NEUR IN; Yu H, 2023, Arxiv, DOI arXiv:2308.10092; Yu Y, 2021, Arxiv, DOI arXiv:2010.07835; Zhao ZX, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P500, DOI 10.1145/3442442.3452313; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	60	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 MAY 29	2024										10.3758/s13428-024-02441-0	http://dx.doi.org/10.3758/s13428-024-02441-0		MAY 2024	15	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	SL3R2	38811519				2024-07-03	WOS:001234573700002
C	Salinas, A; Shah, PV; Huang, YZ; McCormack, R; Morstatter, F			ACM	Salinas, Abel; Shah, Parth Vipul; Huang, Yuzhong; McCormack, Robert; Morstatter, Fred			The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations	PROCEEDINGS OF 2023 ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2023			English	Proceedings Paper	ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO)	OCT 30-NOV 01, 2023	Boston Univ, Boston, MA	Assoc Comp Machinery, Univ California, Schmidt Futures, PITcases, SIGecom, SIGAI, Mexican Natl Network Councils & State Org Sci & Technol, Constituent Members, Bicentennial US Mexico Diplomat Relat, US Embassy Mexico, Journal Artificial Intelligence	Boston Univ	Large Language Models; Demographic Bias; Fairness in AI; Chat-GPT; LLaMA; State-of-the-art models; Natural Language Generation; Real-world applications; Bias across LLMs; Bias analysis; Intersectionality; Empirical experiments	BLACK	Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes. Our code is available at https://github. com/Abel2Code/Unequal-Opportunities-of-LLMs.	[Salinas, Abel; Shah, Parth Vipul; Huang, Yuzhong; Morstatter, Fred] Univ Southern Calif, Informat Sci Inst, Los Angeles, CA 90007 USA; [McCormack, Robert] Aptima Inc, Woburn, MA USA	University of Southern California; Aptima, Inc.	Salinas, A (corresponding author), Univ Southern Calif, Informat Sci Inst, Los Angeles, CA 90007 USA.	asalinas@isi.edu; pvshah@isi.edu; yzhongh@isi.edu; rmccormack@aptima.com; fredmors@isi.edu			Defense Advanced Research Projects Agency (DARPA) [HR00112290021]	Defense Advanced Research Projects Agency (DARPA)(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	This project was sponsored by the Defense Advanced Research Projects Agency (DARPA) under Contract No. HR00112290021. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the Defense Advanced Research Projects Agency (DARPA).	Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Antecol H, 2004, J HUM RESOUR, V39, P564, DOI 10.2307/3559027; Bard, 2023, Google AI Updates: Bard and New AI Features in Search; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; ChatGPT, 2023, Introducing ChatGPT; Cohen R, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1856; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Hswen Y, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e04910; HuggingChat, 2023, HuggingChat; HuggingFace, 2022, sentencetransformers/ allMiniLML6-v2; Kirk H, 2021, Arxiv, DOI arXiv:2102.04130; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Markov T, 2022, Arxiv, DOI arXiv:2208.03274; Massey Douglas S, 2009, Race Soc Probl, V1, P12; McGee R.W., 2023, Empir. Study, V2023, DOI DOI 10.2139/SSRN.4359405; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Papakyriakopoulos Orestis., 2021, Proceedings of the International AAAI Conference on Web and Social Media, V15, P467; Radlinski F, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2863, DOI 10.1145/3477495.3531873; REIMERS CW, 1983, REV ECON STAT, V65, P570, DOI 10.2307/1935925; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Seshadri P., 2022, arXiv; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vig Jesse, 2020, Advances in neural information processing systems, V33, P12388; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	33	0	0	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0381-2				2023									34	10.1145/3617694.3623257	http://dx.doi.org/10.1145/3617694.3623257			15	Computer Science, Interdisciplinary Applications; Social Sciences, Mathematical Methods; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Mathematical Methods In Social Sciences; Social Sciences - Other Topics	BW2SD		Bronze			2024-07-03	WOS:001124266900034
J	Hilario, E; Azam, S; Sundaram, J; Mohammed, KI; Shanmugam, B				Hilario, Eric; Azam, Sami; Sundaram, Jawahar; Mohammed, Khwaja Imran; Shanmugam, Bharanidharan			Generative AI for pentesting: the good, the bad, the ugly	INTERNATIONAL JOURNAL OF INFORMATION SECURITY			English	Article						Cyber security; Generative AI; Large language models; Penetration testing; ChatGPT 3.5		This paper examines the role of Generative AI (GenAI) and Large Language Models (LLMs) in penetration testing exploring the benefits, challenges, and risks associated with cyber security applications. Through the use of generative artificial intelligence, penetration testing becomes more creative, test environments are customised, and continuous learning and adaptation is achieved. We examined how GenAI (ChatGPT 3.5) helps penetration testers with options and suggestions during the five stages of penetration testing. The effectiveness of the GenAI tool was tested using a publicly available vulnerable machine from VulnHub. It was amazing how quickly they responded at each stage and provided better pentesting report. In this article, we discuss potential risks, unintended consequences, and uncontrolled AI development associated with pentesting.	[Hilario, Eric; Azam, Sami; Mohammed, Khwaja Imran; Shanmugam, Bharanidharan] Charles Darwin Univ, Fac Sci & Technol, Energy & Resources Inst, Darwin, Australia; [Sundaram, Jawahar] Christ Acad Inst Adv Studies, Bangalore 560083, India	Charles Darwin University	Shanmugam, B (corresponding author), Charles Darwin Univ, Fac Sci & Technol, Energy & Resources Inst, Darwin, Australia.	eric.hilario@students.cdu.edu.au; sami.azam@cdu.edu.au; sundaramj@caias.in; khwajaimran.mohammed@cdu.edu.au; Bharanidharan.Shanmugam@cdu.edu.au	Shanmugam, Bharanidharan/C-3611-2011	Shanmugam, Bharanidharan/0000-0002-2591-1949	Charles Darwin University	Charles Darwin University	No Statement Available	Abu-Dabaseh F., 2018, Computer Science and Information Technology, P121, DOI DOI 10.5121/CSIT.2018.80610; Adamovic S., 2019, SINTEZA 2019 INT SCI, P229; Aggarwal G., 2023, FORBES; [Anonymous], 2023, EUROPOL CRIMINAL USE; assets.siemens-energy, 2023, SIEMENS ENERGY DEEPA; AttackIQ, 2023, ATTACKIQ READY; Avgerinos T, 2018, IEEE SECUR PRIV, V16, P52, DOI 10.1109/MSP.2018.1870873; Ben-Moshe S., 2023, CHECK POINT RES; BlackBerry Ltd, 2023, SAY IT DEC MAK BLACK; blogs.microsoft, 2023, MICROSOFT MICROSOFT; Chen JY, 2023, COMPUT SECUR, V126, DOI 10.1016/j.cose.2022.103055; Cunningham A., 2023, ARS TECHNICA; CyCraft Technology Corp, 2020, TRAIN MACHINE LEARNI; CyCraft Technology Corp CyCraft's Fuchikoma at Code Blue, 2019, MODERN DAY GHOST SHE; Deng G., 2023, PENTESTGPT; Gal U., 2023, CHATGPT IS DATA PRIV; github, 2023, THER1D SHELLGPT; github, 2023, SIGNIFICANT GRAVITAS; github, 2023, MORPHEUSLORD GPT VUL; github, 2023, IMARTINEZ PRIVATEGPT; Grbic Dijana Vukovic, 2023, 2023 22nd International Symposium INFOTEH-JAHORINA (INFOTEH), P1, DOI 10.1109/INFOTEH57020.2023.10094141; Greshake K., 2023, MORE YOUVE ASKED COM; Gupta M., 2023, IEEE Access; Gurman M., 2023, BLOOMBERG; help.openai, 2023, OPENAI CHATGPT RELEA; Hern A., 2023, The Guardian; kali, 2023, OFFENSIVE SECURITY G; Khan S, 2023, ACM T PRIV SECUR, V26, DOI 10.1145/3546068; Mansfield-Devine S., 2023, NETW SECUR; McDaniel L, 2016, P ANN HICSS, P5479, DOI 10.1109/HICSS.2016.677; Montalbano E., 2023, DARK READING; openai, 2023, OPENAI USAGE POLICIE; OpenAI, 2023, OPENAI MICROSOFT EXT; Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009; Petro D., 2017, DEF CON, V25; Prasad S. Guru, 2023, 2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC), P107, DOI 10.1109/ICAAIC56838.2023.10141395; Renaud K., 2023, MIT SLOAN MANAGE REV; Sanjaya I., 2020, INT J COMPUT NETW IN, V12; Scherb C., 2023, ARXIV; Shimony E., 2023, CHATTING OUR WAY CRE; Takaesu I., 2018, BLACKHAT; Temara S., 2023, RES SQUARE PLATFORM, DOI [10.21203/rs.3.rs-2707376/v1, DOI 10.21203/RS.3.RS-2707376/V1]; vulnhub, 2019, JAYANTH MISSION PUMP; Zacharakos A., 2023, SECURITY; Zhuo T.Y., 2023, ARXIV	45	0	0	20	20	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1615-5262	1615-5270		INT J INF SECUR	Int. J. Inf. Secur.	JUN	2024	23	3					2075	2097		10.1007/s10207-024-00835-x	http://dx.doi.org/10.1007/s10207-024-00835-x		MAR 2024	23	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	SD7Z5		hybrid			2024-07-03	WOS:001184206900002
J	Huang, AH; Wang, H; Yang, Y				Huang, Allen H.; Wang, Hui; Yang, Yi			FinBERT: A Large Language Model for Extracting Information from Financial Text	CONTEMPORARY ACCOUNTING RESEARCH			English	Article						deep learning; large language model; transfer learning; interpretable machine learning; sentiment classification; environment; social; and governance (ESG)	EARNINGS; READABILITY; DISCLOSURE	We develop FinBERT, a state-of-the-art large language model that adapts to the finance domain. We show that FinBERT incorporates finance knowledge and can better summarize contextual information in financial texts. Using a sample of researcher-labeled sentences from analyst reports, we document that FinBERT substantially outperforms the Loughran and McDonald dictionary and other machine learning algorithms, including naive Bayes, support vector machine, random forest, convolutional neural network, and long short-term memory, in sentiment classification. Our results show that FinBERT excels in identifying the positive or negative sentiment of sentences that other algorithms mislabel as neutral, likely because it uses contextual information in financial text. We find that FinBERT's advantage over other algorithms, and Google's original bidirectional encoder representations from transformers model, is especially salient when the training sample size is small and in texts containing financial words not frequently used in general texts. FinBERT also outperforms other models in identifying discussions related to environment, social, and governance issues. Last, we show that other approaches underestimate the textual informativeness of earnings conference calls by at least 18% compared to FinBERT. Our results have implications for academic researchers, investment professionals, and financial market regulators.	[Huang, Allen H.; Wang, Hui; Yang, Yi] Renmin Univ China, Beijing, Peoples R China	Renmin University of China	Huang, AH (corresponding author), Renmin Univ China, Beijing, Peoples R China.	allen.huang@ust.hk		Wang, Hui/0000-0002-4843-126X; Yang, Yi/0000-0001-8863-112X	Seoul National University; Hong Kong Research Grants Council [T31-604/18-N, T31-603/21-N, FinBERT-A]	Seoul National University; Hong Kong Research Grants Council(Hong Kong Research Grants Council)	Accepted by Jenny Tucker. We thank Jenny Tucker (editor), three anonymous referees, Stefano Bonini (discussant), Sean Cao (discussant), Diego Garcia (discussant), Louise Hayes (discussant), Alan Huang (discussant), Fuwei Jiang (discussant), Jaehoon Lee (discussant), Xiangyu Li, Brandon Lock (discussant), Tim Loughran, Amy Zang, and seminar participants at AllianceBernstein, Aqumon, Central University of Finance and Economics, Ernst & Young, Hong Kong Monetary Authority, HKUST, JP Morgan, Lancaster University, and Seoul National University, as well as the 2020 Bergen Fintech Conference, 2020 Conference on Asia-Pacific Financial Markets, 2021 AAA Annual Meeting, 2021 EAA Conference, 2021 EFMA Conference, 2021 FARS Midyear Conference, 2021 FMA Annual Meeting, 2021 Hawai`i Accounting Research Conference, 2021 Japanese Accounting Review Conference, 2021 Summer Institute of Finance, 2022 Fifth Annual Data Science in Finance: Frontiers in Investment Data Science, 2022 CAPANA conference, and 2022 China International Risk Forum for their comments. We gratefully acknowledge the financial support of the Hong Kong Research Grants Council (T31-604/18-N and T31-603/21-N). This paper was formally circulated under the title "FinBERT-A Deep Learning Approach to Extracting Textual Information."	Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Alvarez-Melis D., 2018, On the robustness of interpretability methods; [Anonymous], 2006, P 23 RD INT C MACHIN; [Anonymous], 2019, SCIBERT PRETRAINED C; Araci Dogu, 2019, Finbert: Financial sentiment analysis with pre-trained language models; Azimi M, 2021, REV ASSET PRICING ST, V11, P762, DOI 10.1093/rapstu/raab005; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blau BM, 2015, J CORP FINANC, V31, P203, DOI 10.1016/j.jcorpfin.2015.02.003; Bochkay K, 2023, CONTEMP ACCOUNT RES, V40, P765, DOI 10.1111/1911-3846.12825; Bochkay K, 2020, ACCOUNT REV, V95, P31, DOI 10.2308/accr-52507; Bonsall SB, 2017, J ACCOUNT ECON, V63, P329, DOI 10.1016/j.jacceco.2017.03.002; Brown S V., 2021, Financial Statement Adequacy and Firms' MDA Disclosures; Brown SV, 2018, CONTEMP ACCOUNT RES, V35, P622, DOI 10.1111/1911-3846.12414; Brown SV, 2011, J ACCOUNT RES, V49, P309, DOI 10.1111/j.1475-679X.2010.00396.x; Buehlmaier MMM, 2018, REV FINANC STUD, V31, P2693, DOI 10.1093/rfs/hhy007; Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a; Chalkidis I., 2020, LEGAL-BERT: The Muppets straight out of Law School; Clark K., 2019, WHAT DOES BERT LOOK; Das S. R., 2014, FDN TRENDS FINANCE, V8, P145, DOI DOI 10.1561/0500000045; Davis AK, 2015, REV ACCOUNT STUD, V20, P639, DOI 10.1007/s11142-014-9309-4; De la Parra D., 2021, THESIS RICE U; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Donovan J, 2021, REV ACCOUNT STUD, V26, P815, DOI 10.1007/s11142-020-09575-4; Efron B, 1994, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9; Elliott WB, 2015, REV ACCOUNT STUD, V20, P839, DOI 10.1007/s11142-014-9315-6; Frankel R, 2022, MANAGE SCI, V68, P5514, DOI 10.1287/mnsc.2021.4156; Frankel R, 2016, J ACCOUNT ECON, V62, P209, DOI 10.1016/j.jacceco.2016.07.003; Gentzkow M, 2019, J ECON LIT, V57, P535, DOI 10.1257/jel.20181020; Goldberg Y, 2019, CoRR abs/1901.05287; Hastie T., 2009, ELEMENTS STAT LEARNI; Henry E, 2016, ACCOUNT REV, V91, P153, DOI 10.2308/accr-51161; Hoberg G, 2016, J POLIT ECON, V124, P1423, DOI 10.1086/688176; Hofmann T, 2008, ANN STAT, V36, P1171, DOI 10.1214/009053607000000677; Huang AH, 2022, REV ACCOUNT STUD, V27, P1319, DOI 10.1007/s11142-021-09590-z; Huang AH, 2018, MANAGE SCI, V64, P2833, DOI 10.1287/mnsc.2017.2751; Huang AH, 2014, ACCOUNT REV, V89, P2151, DOI 10.2308/accr-50833; Huang X, 2018, ACCOUNT REV, V93, P231, DOI 10.2308/accr-52010; Ivers M., 1991, RANDOM HOUSE GUIDE G; Jain A., 2020, NUKEBERT PRE TRAINED; Keskek S, 2014, REV ACCOUNT STUD, V19, P1504, DOI 10.1007/s11142-014-9278-7; Kim Y, 2014, ARXIV14085882, DOI 10.3115/v1/D14-1181; Kingma D. P., 2017, ARXIV; Lang M, 2015, J ACCOUNT ECON, V60, P110, DOI 10.1016/j.jacceco.2015.09.002; Lansford B., 2009, Disclosure of Management Guidance in Conference Calls: Materiality, Determinants, and Consequences; Lauriola I, 2022, NEUROCOMPUTING, V470, P443, DOI 10.1016/j.neucom.2021.05.103; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li F., 2010, Journal of accounting literature, V29, P143; Li F, 2008, J ACCOUNT ECON, V45, P221, DOI 10.1016/j.jacceco.2008.02.003; Li F, 2013, J ACCOUNT RES, V51, P399, DOI 10.1111/j.1475-679X.2012.00472.x; Li F, 2010, J ACCOUNT RES, V48, P1049, DOI 10.1111/j.1475-679X.2010.00382.x; Liu Z., 2021, P 29 TH INT C INT JO; Loughran T, 2016, J ACCOUNT RES, V54, P1187, DOI 10.1111/1475-679X.12123; Loughran T, 2014, J FINANC, V69, P1643, DOI 10.1111/jofi.12162; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Lundholm RJ, 2014, ACCOUNT REV, V89, P1453, DOI 10.2308/accr-50725; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; Manela A, 2017, J FINANC ECON, V123, P137, DOI 10.1016/j.jfineco.2016.01.032; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; MSCI, 2022, MSCI ESG RAT METH; Nayak A., 2020, P 1 WORKSHOP INSIGHT; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Price SM, 2012, J BANK FINANC, V36, P992, DOI 10.1016/j.jbankfin.2011.10.013; Purda L, 2015, CONTEMP ACCOUNT RES, V32, P1193, DOI 10.1111/1911-3846.12089; Radford A., 2018, IMPROVING LANGUAGE U; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Sergeev A., 2018, Horovod: fast and easy distributed deep learning in tensorflow; Siano F, 2021, ACCOUNT HORIZ, V35, P217, DOI 10.2308/HORIZONS-19-161; Sinha K., 2021, Masked language modeling and the distributional hypothesis: order word matters pre-training for little; Sinha K., 2021, P 59 TH ANN M ASS CO; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Tenney Ian, 2019, Bert rediscovers the classical nlp pipeline; Vaswani A, 2017, ADV NEUR IN, V30; VUONG QH, 1989, ECONOMETRICA, V57, P307, DOI 10.2307/1912557; Wu Y., 2016, ARXIV160908144	81	43	48	206	444	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0823-9150	1911-3846		CONTEMP ACCOUNT RES	Contemp. Account. Res.	MAY	2023	40	2					806	841		10.1111/1911-3846.12832	http://dx.doi.org/10.1111/1911-3846.12832		JAN 2023	36	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	H7OD5		hybrid			2024-07-03	WOS:000909014900001
J	Viswanathan, V; Gashteovski, K; Lawrence, C; Wu, TS; Neubig, G				Viswanathan, Vijay; Gashteovski, Kiril; Lawrence, Carolin; Wu, Tongshuang; Neubig, Graham			Large Language Models Enable Few-Shot Clustering	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model (LLM) can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find that incorporating LLMs in the first two stages routinely provides significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.1	[Viswanathan, Vijay; Wu, Tongshuang; Neubig, Graham] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Gashteovski, Kiril; Lawrence, Carolin] NEC Labs Europe, Heidelberg, Germany; [Gashteovski, Kiril] Ss Cyril & Methodius Univ Skopje, Ctr Adv Interdisciplinary Res, Skopje, North Macedonia	Carnegie Mellon University; NEC Corporation; Saints Cyril & Methodius University of Skopje	Viswanathan, V (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.				NEC Laboratories Europe	NEC Laboratories Europe	This work was supported by a fellowship from NEC Laboratories Europe. We are grateful to Wiem Ben Rim, Saujas Vaduguru, and JillFain Lehman for their guidance. We also thank Chenyang Zhao for providing valuable feedback on this work.	Aggarwal CC, 2012, Mining Text Data, P163, DOI 10.1007/978-1-4614-3223-4; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Awasthi P, 2017, J MACH LEARN RES, V18; Bae J, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3340960; Banko M, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2670; Basu S, 2004, SIAM PROC S, P333; Basu Sugato., 2002, INT C MACHINE LEARNI; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Bunescu Razvan C., 2006, C EUROPEAN CHAPTER A; Caruana R, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P1259, DOI 10.1145/2505515.2514692; Casanueva I, 2020, NLP FOR CONVERSATIONAL AI, P38; Coden A., 2017, P 2017 SIAM INT C DA, P237; Dasgupta S, 2010, J ARTIF INTELL RES, V39, P581, DOI 10.1613/jair.3003; Dash Sarthak., 2020, C EMPIRICAL METHODS, DOI [10.18653/v1/2021.emnlp-main.811, DOI 10.18653/V1/2021.EMNLP-MAIN.811]; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; De Raedt M, 2023, Arxiv, DOI [arXiv:2305.19783, 10.18653/v1/2023.nlp4convai-1.7, DOI 10.18653/V1/2023.NLP4CONVAI-1.7]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fader Anthony., 2011, C EMPIRICAL METHODS; Galarraga L, 2014, P 23 ACM INT C C INF, P1679; Gashteovski Kiril, 2017, C EMPIRICAL METHODS; Gashteovski Kiril., 2019, P C AUTOMATIC KNOWLE; Hara K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174023; Hongjin Su., 2022, arXiv; Horton J.J., 2023, NBER Working Paper 31122, DOI [DOI 10.3386/W31122, 10.3386/ w31122]; Jinlan Fu., 2023, ArXiv, Vabs/2302.04166; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1311; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Milne D, 2008, P 17 ACM C INF KNOWL, P509, DOI DOI 10.1145/1458082.1458150; Park JS, 2023, ARXIV230403442; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shen W, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1578, DOI 10.1145/3534678.3539449; Vashishth S, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1317, DOI 10.1145/3178876.3186030; Wagstaff Kiri L., 2000, P 17 INT C MACHINE L; Yin JH, 2016, PROC INT CONF DATA, P625, DOI 10.1109/ICDE.2016.7498276; Zhang DJ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5419; Zhang HJ, 2020, LECT NOTES ARTIF INT, V11906, P57, DOI 10.1007/978-3-030-46150-8_4; Zhang YW, 2023, Arxiv, DOI [arXiv:2305.14871, 10.18653/v1/2023.emnlp-main.858]; Zhou ZH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P754	40	0	0	3	3	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	APR 5	2024	12						321	333		10.1162/tacl_a_00648	http://dx.doi.org/10.1162/tacl_a_00648			13	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	NN8G2		Green Submitted, gold			2024-07-03	WOS:001201214700003
J	Marks, M; Haupt, CE				Marks, Mason; Haupt, Claudia E.			AI Chatbots, Health Privacy, and Challenges to HIPAA Compliance	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Editorial Material								This Viewpoint examines the privacy concerns raised by medical uses of large language models, such as chatbots.	[Marks, Mason] Florida State Univ, Coll Law, Tallahassee, FL USA; [Marks, Mason] Harvard Law Sch, Petrie Flom Ctr Hlth Law Policy Biotechnol & Bioet, Project Psychedel Law & Regulat POPLAR, Cambridge, MA 02138 USA; [Haupt, Claudia E.] Northeastern Univ, Sch Law, Boston, MA USA; [Haupt, Claudia E.] Yale Law Sch, Solomon Ctr Hlth Law & Policy, New Haven, CT USA; [Marks, Mason] Harvard Law Sch, Petrie Flom Ctr Hlth Law Policy Biotechnol & Bioet, 1585 Massachusetts Ave, Cambridge, MA 02138 USA	State University System of Florida; Florida State University; Harvard University; Northeastern University; Yale University; Harvard University	Marks, M (corresponding author), Harvard Law Sch, Petrie Flom Ctr Hlth Law Policy Biotechnol & Bioet, 1585 Massachusetts Ave, Cambridge, MA 02138 USA.	mmarks@law.harvard.edu		Marks, Mason/0000-0002-4310-9183				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Feathers T., 2022, The Markup; Federspiel F, 2023, BMJ GLOB HEALTH, V8, DOI 10.1136/bmjgh-2022-010435; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Khan L., 2023, NEW YORK TIMES; Marks M., 2021, UC IRVINE L REV; Marks Mason, 2021, U.C. DAVIS L. REV., V55, P513; OpenAI, 2023, MARCH 20 CHATGPT OUT; Xiang C., 2023, VICE 0330; Xiang Chloe, 2023, VICE	10	22	22	6	11	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	JUL 25	2023	330	4					309	310		10.1001/jama.2023.9458	http://dx.doi.org/10.1001/jama.2023.9458		JUL 2023	2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	Q6OL3	37410450				2024-07-03	WOS:001025154600001
J	Kramer, D				Kramer, David			Will AI's growth create an explosion of energy consumption?	PHYSICS TODAY			English	Article								Further improvements in hardware and software efficiencies may counteract an expected surge in demand for electricity needed to power the new large language models.										de Vries A, 2023, JOULE, V7, P2191, DOI 10.1016/j.joule.2023.09.004	1	0	0	0	0	AMER INST PHYSICS	MELVILLE	1305 WALT WHITMAN RD ,STE 300, MELVILLE, NY 11747 USA	0031-9228	1945-0699		PHYS TODAY	Phys. Today	APR 1	2024	77	4					28	29		10.1063/pt.gqbw.iirw	http://dx.doi.org/10.1063/pt.gqbw.iirw			2	Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Physics	WF1A3		Bronze			2024-07-03	WOS:001253351200010
J	Giuffrè, M; Kresevic, S; You, KS; Dupont, J; Huebner, J; Grimshaw, AA; Shung, DL				Giuffre, Mauro; Kresevic, Simone; You, Kisung; Dupont, Johannes; Huebner, Jack; Grimshaw, Alyssa Ann; Shung, Dennis Legen			Systematic review: The use of large language models as medical chatbots in digestive diseases	ALIMENTARY PHARMACOLOGY & THERAPEUTICS			English	Review; Early Access							CHATGPT	BackgroundInterest in large language models (LLMs), such as OpenAI's ChatGPT, across multiple specialties has grown as a source of patient-facing medical advice and provider-facing clinical decision support. The accuracy of LLM responses for gastroenterology and hepatology-related questions is unknown.AimsTo evaluate the accuracy and potential safety implications for LLMs for the diagnosis, management and treatment of questions related to gastroenterology and hepatology.MethodsWe conducted a systematic literature search including Cochrane Library, Google Scholar, Ovid Embase, Ovid MEDLINE, PubMed, Scopus and the Web of Science Core Collection to identify relevant articles published from inception until January 28, 2024, using a combination of keywords and controlled vocabulary for LLMs and gastroenterology or hepatology. Accuracy was defined as the percentage of entirely correct answers.ResultsAmong the 1671 reports screened, we identified 33 full-text articles on using LLMs in gastroenterology and hepatology and included 18 in the final analysis. The accuracy of question-responding varied across different model versions. For example, accuracy ranged from 6.4% to 45.5% with ChatGPT-3.5 and was between 40% and 91.4% with ChatGPT-4. In addition, the absence of standardised methodology and reporting metrics for studies involving LLMs places all the studies at a high risk of bias and does not allow for the generalisation of single-study results.ConclusionsCurrent general-purpose LLMs have unacceptably low accuracy on clinical gastroenterology and hepatology tasks, which may lead to adverse patient safety events through incorrect information or triage recommendations, which might overburden healthcare systems or delay necessary care. Available large language models are not accurate enough to be deployed in real-life clinical practice, despite their user-friendly interfaces and rapid improvement cycles. The absence of standardised methods and benchmarks will probably delay their safe deployment into real-life clinical settings.image	[Giuffre, Mauro; Dupont, Johannes; Shung, Dennis Legen] Yale Sch Med, Dept Internal Med Digest Dis, New Haven, CT USA; [Giuffre, Mauro] Univ Trieste, Dept Med Surg & Hlth Sci, Trieste, Italy; [Kresevic, Simone] Univ Trieste, Dept Engn & Architecture, Trieste, Italy; [You, Kisung] CUNY, Dept Math, Baruch Coll, New York, NY USA; [Huebner, Jack] Yale Sch Med, Dept Internal Med, New Haven, CT USA; [Grimshaw, Alyssa Ann] Yale Univ, Harvey Cushing John Hay Whitney Med Lib, Res & Educ Librarian Clin, New Haven, CT USA; [Giuffre, Mauro; Shung, Dennis Legen] Dept Internal Med Digest Dis, POB 208019, New Haven, CT 05520 USA	Yale University; University of Trieste; University of Trieste; City University of New York (CUNY) System; Baruch College (CUNY); Yale University; Yale University	Giuffrè, M; Shung, DL (corresponding author), Dept Internal Med Digest Dis, POB 208019, New Haven, CT 05520 USA.	mauro.giuffre@yale.edu; dennis.shung@yale.edu			NIH NIDDK [DK125718]	NIH NIDDK(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Diabetes & Digestive & Kidney Diseases (NIDDK))	DLS is supported by NIH NIDDK grant DK125718.	[Anonymous], 2021, Yale University Harvey Cushing/John Hay Whitney Medical Library. Reference Deduplicator Internet; [Anonymous], Embeddings; Atarere J, 2024, DIGEST DIS SCI, V69, P791, DOI 10.1007/s10620-024-08274-3; Baily M., Machines of mind: the case for an AIpowered productivity boom; Bakhshandeh S., 2023, Nature Rev Bioeng, V1, P543, DOI DOI 10.1038/S44222-023-00097-7; Cai TT, 2022, Arxiv, DOI arXiv:2105.07536; Campbell M, 2020, BMJ-BRIT MED J, V368, DOI 10.1136/bmj.l6890; Cankurtaran RE, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46736; Cao JJ, 2023, AM J ROENTGENOL, V221, P556, DOI 10.2214/AJR.23.29493; Chen B., 2023, Unleashing the potential of prompt engineering in large language models: a comprehensive review; Chen L., 2023, How is ChatGPT's behavior changing over time?; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Consens ME, 2023, Arxiv, DOI [arXiv:2311.07621, DOI 10.48550/ARXIV.2311.07621]; Douglas MR., 2023, Large language models; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Emile SH, 2023, SURGERY, V174, P1273, DOI 10.1016/j.surg.2023.06.005; Endo Y, 2023, J GASTROINTEST SURG, V27, P1716, DOI 10.1007/s11605-023-05714-9; Giuffre Mauro, 2024, Clin Gastroenterol Hepatol, DOI 10.1016/j.cgh.2024.01.024; Giuffrè M, 2024, CLIN GASTROENTEROL H, V22, P1145, DOI 10.1016/j.cgh.2023.09.035; Golden A, 2024, Arxiv, DOI arXiv:2312.14385; Gorelik Y, 2023, GASTROINTEST ENDOSC, V98, DOI 10.1016/j.gie.2023.06.025; Haddaway NR, 2022, RES SYNTH METHODS, V13, P533, DOI 10.1002/jrsm.1563; Henson JB, 2023, AM J GASTROENTEROL, V118, P2276, DOI 10.14309/ajg.0000000000002397; Kerbage A, 2024, CLIN GASTROENTEROL H, V22, DOI 10.1016/j.cgh.2023.11.008; Klang E, 2023, THER ADV GASTROENTER, V16, DOI 10.1177/17562848231218618; Kleebayoon A, 2023, AM J GASTROENTEROL, V118, P2305, DOI 10.14309/ajg.0000000000002367; Kresevic S, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01091-y; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Levartovsky A, 2023, AM J GASTROENTEROL, V118, P2283, DOI 10.14309/ajg.0000000000002483; Lewis P., 2020, Retrievalaugmented generation for knowledgeintensive NLP tasks; Li JQ, 2023, J MED INTERNET RES, V25, DOI 10.2196/47551; Lim DYZ, 2024, J GASTROEN HEPATOL, V39, P81, DOI 10.1111/jgh.16375; Lv K., 2023, Full parameter finetuning for large language models with limited resources; Ma Y., 2023, Gastroenterol Endosc, V1, P130, DOI [10.1016/j.gande.2023.05.002, DOI 10.1016/J.GANDE.2023.05.002]; McGowan J, 2016, J CLIN EPIDEMIOL, V75, P40, DOI 10.1016/j.jclinepi.2016.01.021; Milmo D., 2023, Guardian, V2; Moazzam Z, 2023, ANN SURG ONCOL, V30, P6284, DOI 10.1245/s10434-023-13777-w; Mukherjee S, 2023, Gastro Hep Adv, V2, P1040, DOI 10.1016/j.gastha.2023.07.008; Munn Z, 2015, INT J EVID-BASED HEA, V13, P147, DOI 10.1097/XEB.0000000000000054; Naveed H., 2023, A Comprehensive Overview of Large Language Models; Nori H., 2023, Can generalist foundation models outcompete specialpurpose tuning? Case study in medicine; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Patil NS, 2023, J AM COLL RADIOL, V20, P1010, DOI 10.1016/j.jacr.2023.07.010; Pugliese N, 2024, CLIN GASTROENTEROL H, V22, DOI 10.1016/j.cgh.2023.08.033; Ratner N., 2022, Parallel context windows for large language models; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Shi W., 2024, EHRAgent: code empowers large language models for fewshot complex tabular reasoning on electronic health records; Simon DA, 2022, NAT MED, V28, P438, DOI 10.1038/s41591-022-01697-3; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Tariq R, 2024, GASTROENTEROLOGY, V166, P220, DOI 10.1053/j.gastro.2023.08.033; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tu T., 2024, Towards conversational diagnostic AI; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wachter RM, 2024, JAMA-J AM MED ASSOC, V331, P65, DOI 10.1001/jama.2023.25054; Webster P, 2023, NAT MED, DOI 10.1038/s41591-023-02700-1; Wei QH, 2024, J BIOMED INFORM, V151, DOI 10.1016/j.jbi.2024.104620; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Ziegler DM., 2019, Finetuning language models from human preferences	62	3	3	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0269-2813	1365-2036		ALIMENT PHARM THER	Aliment. Pharmacol. Ther.	2024 MAY 27	2024										10.1111/apt.18058	http://dx.doi.org/10.1111/apt.18058		MAY 2024	23	Gastroenterology & Hepatology; Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology; Pharmacology & Pharmacy	RY1G8	38798194				2024-07-03	WOS:001231121100001
C	Simmons, G		Padmakumar, V; Vallejo, G; Fu, Y		Simmons, Gabriel			Moral Mimicry: Large Language Models Produce Moral Rationalizations Tailored to Political Identity	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-SRW 2023, VOL 4			English	Proceedings Paper	61st Annual Meeting of the Association-for-Computational-Linguistics / Student Research Workshop (ACL-SRW)	JUL 10-12, 2023	Toronto, CANADA	Assoc Computat Linguist, Google, NSF				Large Language Models (LLMs) have demonstrated impressive capabilities in generating fluent text, as well as tendencies to reproduce undesirable social biases. This study investigates whether LLMs reproduce the moral biases associated with political groups in the United States, an instance of a broader capability herein termed moral mimicry. This hypothesis is explored in the GPT-3/3.5 and OPT families of Transformer-based LLMs. Using tools from Moral Foundations Theory, it is shown that these LLMs are indeed moral mimics. When prompted with a liberal or conservative political identity, the models generate text reflecting corresponding moral biases. This study also explores the relationship between moral mimicry and model size, and similarity between human and LLM moral word use.	[Simmons, Gabriel] Univ Calif Davis, Davis, CA 95616 USA	University of California System; University of California Davis	Simmons, G (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.	gsimmons@ucdavis.edu						Aher Gati, 2023, Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies; Alshomary M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P224; Alshomary M, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100253; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Arora Arnav, 2023, P 1 WORKSHOP CROSS C, P114, DOI DOI 10.18653/V1/2023; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bommasani, 2022, OPPORTUNITIES RISKS; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Davis DE, 2016, J PERS SOC PSYCHOL, V110, pE23, DOI 10.1037/pspp0000056; DeepSpeed, 2022, ZeRO-Inference: Democratizing massive model inference; Dobolyi David., 2016, Critiques | Moral Foundations Theory; Dogruyol B, 2019, PERS INDIV DIFFER, V151, DOI 10.1016/j.paid.2019.109547; Egorov M, 2020, J BUS ETHICS, V167, P707, DOI 10.1007/s10551-019-04178-9; Emelin D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P698; Etienne Hubert, 2021, Law, Innovation and Technology, V13, P85, DOI 10.1080/17579961.2021.1898310; Feinberg M, 2015, PERS SOC PSYCHOL B, V41, P1665, DOI 10.1177/0146167215607842; Fraser Kathleen C., 2022, P 2 WORKSHOP TRUSTWO, P26; Frimer JA, 2020, J RES PERS, V84, DOI 10.1016/j.jrp.2019.103906; Funder DC, 2019, ADV METH PRACT PSYCH, V2, P156; Gao Leo, 2021, SIZES OPENAI API MOD; Garten Justin, 2016, Morality Between the Lines: Detecting Moral Sentiment In Text; Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847; Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141; Haidt Jonathan, 2013, The righteous mind: Why good people are divided by politics and religion; Harper CA, 2021, BRIT J SOC PSYCHOL, V60, P1303, DOI 10.1111/bjso.12452; Hendrycks Dan, 2021, 9 INT C LEARNING REP; Hofstede G., 2001, International Journal of Cross Cultural Management, V1, P11, DOI [10.1177/147059580111002, DOI 10.1177/147059580111002]; Hopp FR, 2021, BEHAV RES METHODS, V53, P232, DOI 10.3758/s13428-020-01433-0; Iyer Srinivasan, 2023, Opt-iml: Scaling language model instruction meta learning through the lens of generalization; Jiang H., 2022, P 29 INT C COMPUTATI, P6818; Jiang Liwei, 2021, The Delphi Experiment; Jin Zhijing, 2022, NEURIPS; Johnson K, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P720; Kaplan Jared, 2020, Scaling laws for neural language models; Kodapanakkal RI, 2022, PSYCHOL SCI, V33, P433, DOI 10.1177/09567976211040803; Luttrell A, 2019, PSYCHOL SCI, V30, P1136, DOI 10.1177/0956797619854706; Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P653; Ming Qian, 2021, Artificial Intelligence in HCI. Second International Conference, AI-HCI 2021 Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 12797), P84, DOI 10.1007/978-3-030-77772-2_6; Mutlu EÇ, 2020, PR I-A I C AD S N A, P222, DOI 10.1109/ASONAM49781.2020.9381386; OpenAI, 2022, Model index for researchers; OpenAI, 2021, About us; Pavan Matheus C., 2020, IEEE Transactions on Affective Computing, P1; Perez Ethan, 2022, Discovering Language Model Behaviors with Model-Written Evaluations.; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Roy Shamik, 2022, P 5 WORKSHOP NATURAL, P183; Suhler CL, 2011, J COGNITIVE NEUROSCI, V23, P2103, DOI 10.1162/jocn.2011.21637; Talat Z, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P769; Tiku N., 2022, The Washington Post; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; World Values Survey, 2022, WVS Database; Yalçindag B, 2019, CURR PSYCHOL, V38, P440, DOI 10.1007/s12144-017-9618-4; Zhang S., 2022, Opt: Open pre-trained transformer language models; Ziems C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3755	56	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-69-2				2023							282	297						16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RW					2024-07-03	WOS:001181053700028
J	Cui, YD; Huang, SC; Zhong, JM; Liu, ZN; Wang, YT; Sun, C; Li, B; Wang, X; Khajepour, A				Cui, Yaodong; Huang, Shucheng; Zhong, Jiaming; Liu, Zhenan; Wang, Yutong; Sun, Chen; Li, Bai; Wang, Xiao; Khajepour, Amir			DriveLLM: Charting the Path Toward Full Autonomous Driving With Large Language Models	IEEE TRANSACTIONS ON INTELLIGENT VEHICLES			English	Article						Decision making; Cognition; Autonomous vehicles; Task analysis; Roads; Real-time systems; Training; Autonomous driving; computer vision; decision-making; large language models	INTELLIGENCE	Human drivers instinctively reason with commonsense knowledge to predict hazards in unfamiliar scenarios and to understand the intentions of other road users. However, this essential capability is entirely missing from traditional decision-making systems in autonomous driving. In response, this paper presents DriveLLM, a decision-making framework that integrates large language models (LLMs) with existing autonomous driving stacks. This integration allows for commonsense reasoning in decision-making. DriveLLM also features a unique cyber-physical feedback system, allowing it to learn and improve from its mistakes. In real-world case studies, the proposed framework outperforms traditional decision-making methods in complex scenarios, including difficult edge cases. Furthermore, we propose a novel approach that allows the decision-making system to interact with human inputs while guarding against adversarial attacks. Empirical evaluations demonstrate that this framework responds correctly to complex human instructions.	[Cui, Yaodong; Huang, Shucheng; Zhong, Jiaming; Liu, Zhenan] LoopX Innovat Inc, Waterloo, ON, Canada; [Cui, Yaodong; Huang, Shucheng; Zhong, Jiaming; Liu, Zhenan; Sun, Chen] Univ Waterloo, Dept Mech & Mechatron Engn, MVSLab, Waterloo, ON N2L3G1, Canada; [Wang, Yutong; Li, Bai] Hunan Univ, State Key Lab Adv Design & Mfg Vehicle Body, Changsha 410082, Peoples R China; [Wang, Yutong; Li, Bai] Hunan Univ, Coll Mech & Vehicle Engn, Changsha 410082, Peoples R China; [Wang, Xiao] Anhui Univ, Sch Artificial Intelligence, Hefei 230039, Peoples R China	University of Waterloo; Hunan University; Hunan University; Anhui University	Sun, C (corresponding author), Univ Waterloo, Dept Mech & Mechatron Engn, MVSLab, Waterloo, ON N2L3G1, Canada.	yaodong.cui@uwaterloo.ca; s95huang@uwaterloo.ca; j52zhong@uwaterloo.ca; z634liu@uwaterloo.ca; yutong.wang@ia.ac.cn; chen.sun@uwaterloo.ca; libai@zju.edu.cn; xiao.wang@ahu.edu.cn; a.khajepour@uwaterloo.ca	Huang, Shucheng/IAQ-1625-2023; Li, Bai/P-1446-2014	Huang, Shucheng/0000-0001-9737-8779; Li, Bai/0000-0002-8966-8992; Zhong, Jiaming/0009-0002-3717-0727; Sun, Chen/0000-0001-8772-9627; Cui, Yaodong/0000-0003-1132-9154; Wang, Yutong/0000-0001-7429-031X; wang, xiao/0000-0002-0008-0659				[Anonymous], 2005, OXFORD COMPANION PHI; Brown B, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3581045; Brown T., 2020, NIPS, P1877; Chen JY, 2019, IEEE INT C INTELL TR, P2765, DOI 10.1109/ITSC.2019.8917306; Chen L, 2023, IEEE T INTELL VEHICL, V8, P1046, DOI 10.1109/TIV.2022.3223131; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano PF, 2017, ADV NEUR IN, V30; Dorbala VS, 2023, Arxiv, DOI arXiv:2303.03480; Greshake K, 2023, Arxiv, DOI arXiv:2302.12173; Hang P, 2020, IEEE T VEH TECHNOL, V69, P14458, DOI 10.1109/TVT.2020.3040398; Hoel CJ, 2020, IEEE INT VEH SYM, P1563, DOI 10.1109/IV47402.2020.9304614; Hoel CJ, 2020, IEEE T INTELL VEHICL, V5, P294, DOI 10.1109/TIV.2019.2955905; Huang C, 2021, IEEE-ASME T MECH, V26, P611, DOI 10.1109/TMECH.2021.3053248; Huang YJ, 2020, IEEE T IND ELECTRON, V67, P1376, DOI 10.1109/TIE.2019.2898599; Karle P, 2022, IEEE T INTELL TRANSP, V23, P16962, DOI 10.1109/TITS.2022.3156011; Li B, 2023, IEEE T INTELL VEHICL, V8, P1512, DOI 10.1109/TIV.2022.3214777; Li B, 2023, IEEE T SYST MAN CY-S, V53, P2025, DOI 10.1109/TSMC.2022.3225250; Li B, 2022, IEEE T INTELL TRANSP, V23, P15729, DOI 10.1109/TITS.2022.3145389; Li GF, 2022, TRANSPORT RES C-EMER, V134, DOI 10.1016/j.trc.2021.103452; Li L, 2018, ARTIF INTELL REV, V50, P441, DOI 10.1007/s10462-018-9631-5; OpenAI, 2023, ArXiv; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Reis D, 2024, Arxiv, DOI [arXiv:2305.09972, 10.48550/arXiv.2305.09972]; Schick T., 2023, arXiv; Shalev-Shwartz S, 2018, Arxiv, DOI arXiv:1708.06374; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Sun C, 2024, IEEE T INTELL VEHICL, V9, P1711, DOI 10.1109/TIV.2023.3314731; Sun C, 2023, IEEE T COMPUT SOC SY, V10, P1199, DOI 10.1109/TCSS.2022.3170934; Sun C, 2022, IEEE INTEL TRANSP SY, V14, P10, DOI 10.1109/MITS.2021.3070651; Tang XL, 2022, IEEE T INTELL VEHICL, V7, P849, DOI 10.1109/TIV.2022.3188662; Teng SY, 2023, IEEE T INTELL VEHICL, V8, P3692, DOI 10.1109/TIV.2023.3274536; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P3763, DOI 10.1109/TIV.2023.3298655; Wang FY, 2023, IEEE INTEL TRANSP SY, V15, P171, DOI 10.1109/MITS.2023.3278158; Wang FY, 2007, IEEE INTELL SYST, V22, P79, DOI 10.1109/MIS.2007.41; Wang FY, 2022, IEEE INTELL SYST, V37, P16, DOI 10.1109/MIS.2022.3154541; Wang H, 2022, IEEE INTEL TRANSP SY, V14, P6, DOI 10.1109/MITS.2019.2953556; Wang JG, 2023, IEEE T INTELL VEHICL, V8, P2832, DOI 10.1109/TIV.2023.3249287; Wang X, 2023, IEEE T INTELL VEHICL, V8, P2888, DOI 10.1109/TIV.2023.3239903; Wang YT, 2023, IEEE-CAA J AUTOMATIC, V10, P2041, DOI 10.1109/JAS.2023.123966; Wei JS, 2022, ADV NEUR IN; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yin TW, 2021, PROC CVPR IEEE, P11779, DOI 10.1109/CVPR46437.2021.01161; Zhou GZ, 2023, Arxiv, DOI arXiv:2305.16986; Zhou KW, 2023, Arxiv, DOI arXiv:2301.13166	49	5	5	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2379-8858	2379-8904		IEEE T INTELL VEHICL	IEEE T. Intell. Veh.	JAN	2024	9	1					1450	1464		10.1109/TIV.2023.3327715	http://dx.doi.org/10.1109/TIV.2023.3327715			15	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Transportation Science & Technology	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Transportation	JL4V0					2024-07-03	WOS:001173317800124
J	Nowak, S; Sprinkart, AM				Nowak, Sebastian; Sprinkart, Alois M.			Large language models from OpenAI, Google, Meta, X and Co. The role of "closed" and "open" models in radiology	RADIOLOGIE			German	Review; Early Access						Gro ss e Sprachmodelle; Natural Language Processing; Deep Learning; Open Source; Datenschutz; Large language models; Natural language processing; Deep learning; Open source; Data privacy		BackgroundIn 2023, the release of ChatGPT triggered an artificial intelligence (AI) boom. The underlying large language models (LLM) of the nonprofit organization "OpenAI" are not freely available under open-source licenses, which does not allow on-site implementation inside secure clinic networks. However, efforts are being made by open-source communities, start-ups and large tech companies to democratize the use of LLMs. This opens up the possibility of using LLMs in a data protection-compliant manner and even adapting them to our own data. ObjectivesThis paper aims to explain the potential of privacy-compliant local LLMs for radiology and to provide insights into the "open" versus "closed" dynamics of the currently rapidly developing field of AI. Materials and methodsPubMed search for radiology articles with LLMs and subjective selection of references in the sense of a narrative key topic article. ResultsVarious stakeholders, including large tech companies such as Meta, Google and X, but also European start-ups such as Mistral AI, contribute to the democratization of LLMs by publishing the models (open weights) or by publishing the model and source code (open source). Their performance is lower than current "closed" LLMs, such as GPT-4 from OpenAI. ConclusionDespite differences in performance, open and thus locally implementable LLMs show great promise for improving the efficiency and quality of diagnostic reporting as well as interaction with patients and enable retrospective extraction of diagnostic information for secondary use of clinical free-text databases for research, teaching or clinical application.	[Nowak, Sebastian; Sprinkart, Alois M.] Univ Klinikum Bonn, Klin Diagnost & Interventionelle Radiol, Venusberg Campus 1, D-53127 Bonn, Germany	University of Bonn	Nowak, S (corresponding author), Univ Klinikum Bonn, Klin Diagnost & Interventionelle Radiol, Venusberg Campus 1, D-53127 Bonn, Germany.	Sebastian.Nowak@ukbonn.de						Abadi M., 2015, arXiv, DOI DOI 10.48550/ARXIV.1603.04467; Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Black S., 2022, PREPRINT; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Chen W, 2024, Arxiv, DOI arXiv:2404.01744; Chiang WL, 2024, Arxiv, DOI arXiv:2403.04132; cohere, Command R Veroffentlichung von Cohere; databricks, DBRX Veroffentlichung von Databricks; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Fedus W, 2022, J MACH LEARN RES, V23; Fink MA, 2023, RADIOLOGIE, V63, P665, DOI 10.1007/s00117-023-01187-8; github, Grok-1 Veroffentlichung von X; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Li BB, 2023, Arxiv, DOI arXiv:2312.02441; Luccioni AS., 2023, J Mach Learn Res, V24, P1; Mesnard T, Cassidy Hardin etal Gemma, DOI [10.34740/KAGGLE/M/3301, DOI 10.34740/KAGGLE/M/3301]; Nowak S, 2023, EUR RADIOL, V33, P4228, DOI 10.1007/s00330-023-09526-y; Nowak S, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10373-0; openai, Nutzungsbedingungen Llama-2 von Meta; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Paszke A, 2019, ADV NEUR IN, V32; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Salam Babak, 2024, J Cardiovasc Magn Reson, V26, P101035, DOI 10.1016/j.jocmr.2024.101035; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	29	0	0	0	0	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2731-7048	2731-7056		RADIOLOGIE	Radiologie	2024 JUN 7	2024										10.1007/s00117-024-01327-8	http://dx.doi.org/10.1007/s00117-024-01327-8		JUN 2024	7	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	TK9O8	38847898				2024-07-03	WOS:001241276300001
J	Sushil, M; Zack, T; Mandair, D; Zheng, ZW; Wali, A; Yu, YN; Quan, YW; Lituiev, D; Butte, AJ				Sushil, Madhumita; Zack, Travis; Mandair, Divneet; Zheng, Zhiwei; Wali, Ahmed; Yu, Yan-Ning; Quan, Yuwei; Lituiev, Dmytro; Butte, Atul J.			A comparative study of large language model-based zero-shot inference and task-specific supervised classification of breast cancer pathology reports	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						electronic health records; large language models; breast cancer; pathology; natural language processing		Objective Although supervised machine learning is popular for information extraction from clinical notes, creating large annotated datasets requires extensive domain expertise and is time-consuming. Meanwhile, large language models (LLMs) have demonstrated promising transfer learning capability. In this study, we explored whether recent LLMs could reduce the need for large-scale data annotations.Materials and Methods We curated a dataset of 769 breast cancer pathology reports, manually labeled with 12 categories, to compare zero-shot classification capability of the following LLMs: GPT-4, GPT-3.5, Starling, and ClinicalCamel, with task-specific supervised classification performance of 3 models: random forests, long short-term memory networks with attention (LSTM-Att), and the UCSF-BERT model.Results Across all 12 tasks, the GPT-4 model performed either significantly better than or as well as the best supervised model, LSTM-Att (average macro F1-score of 0.86 vs 0.75), with advantage on tasks with high label imbalance. Other LLMs demonstrated poor performance. Frequent GPT-4 error categories included incorrect inferences from multiple samples and from history, and complex task design, and several LSTM-Att errors were related to poor generalization to the test set.Discussion On tasks where large annotated datasets cannot be easily collected, LLMs can reduce the burden of data labeling. However, if the use of LLMs is prohibitive, the use of simpler models with large annotated datasets can provide comparable results.Conclusions GPT-4 demonstrated the potential to speed up the execution of clinical NLP studies by reducing the need for large annotated datasets. This may increase the utilization of NLP-based variables and outcomes in clinical studies.	[Sushil, Madhumita; Zack, Travis; Mandair, Divneet; Lituiev, Dmytro; Butte, Atul J.] Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA 94158 USA; [Zack, Travis; Mandair, Divneet; Butte, Atul J.] Univ Calif San Francisco, Helen Diller Family Comprehens Canc Ctr, San Francisco, CA 94158 USA; [Zheng, Zhiwei; Wali, Ahmed; Yu, Yan-Ning; Quan, Yuwei] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Butte, Atul J.] Univ Calif Oakland, Ctr Data driven Insights & Innovat, Off President, Oakland, CA 94607 USA; [Butte, Atul J.] Univ Calif San Francisco, Dept Pediat, San Francisco, CA 94158 USA; [Sushil, Madhumita] Bakar Computat Hlth Sci Inst, 490 Illinois St, Cubicle 2215, 2nd Fl, North Tower, San Francisco, CA 94148 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; UCSF Medical Center; UCSF Helen Diller Family Comprehensive Cancer Center; University of California System; University of California Berkeley; University of California System; University of California System; University of California San Francisco	Sushil, M (corresponding author), Bakar Computat Hlth Sci Inst, 490 Illinois St, Cubicle 2215, 2nd Fl, North Tower, San Francisco, CA 94148 USA.	Madhumita.Sushil@ucsf.edu		Sushil, Madhumita/0000-0001-7884-0526	National Cancer Institute; UCSF AI Tiger Team; Academic Research Services, Research Information Technology; Versa chat (the chat user interface); UCSF Information Commons team	National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); UCSF AI Tiger Team; Academic Research Services, Research Information Technology; Versa chat (the chat user interface); UCSF Information Commons team	This research would not have been possible without support from several people. The authors thank the UCSF AI Tiger Team, Academic Research Services, Research Information Technology, and the Chancellor's Task Force for Generative AI for their software development, analytical and technical support related to the use of Versa API gateway (the UCSF secure implementation of large language models and generative AI via API gateway), Versa chat (the chat user interface), and related data asset and services. We thank Boris Oskotsky, the UCSF Information Commons team, and the Wynton high-performance computing platform team at UCSF for supporting high-performance computing platforms that enable the use of language models with de-identified patient data. We further thank Debajoyti Datta and Michelle Turski for feedback on breast cancer pathology annotation schema, all members of the Butte lab for helpful discussions in the internal presentations, and Gundolf Schenk and Lakshmi Radhakrishnan for discussions related to clinical note de-identification.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agrawal M., 2022, P 2022 C EMP METH NA; Alsentzer E, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00957-x; [Anonymous], 2024, HumanSignal/label-studio; Barile J, 2024, JAMA PEDIATR, V178, P313, DOI 10.1001/jamapediatrics.2023.5750; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen QY, 2024, Arxiv, DOI [arXiv:2305.16326, 10.48550/arXiv.2305.16326, DOI 10.48550/ARXIV.2305.16326]; Datta S, 2024, J AM MED INFORM ASSN, V31, P375, DOI 10.1093/jamia/ocad218; EDGINGTO.ES, 1969, J PSYCHOL, V72, P143, DOI 10.1080/00223980.1969.10543491; Eriksen AV., 2023, NEJM AI, V1, pAIp2300031; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Fu SY, 2023, CTS-CLIN TRANSL SCI, V16, P398, DOI 10.1111/cts.13463; Gao YJ, 2022, J AM MED INFORM ASSN, V29, P1797, DOI 10.1093/jamia/ocac127; Garcia P, 2024, JAMA NETW OPEN, V7, DOI 10.1001/jamanetworkopen.2024.3201; Gholipour M, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05480-0; Guevara M, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-023-00970-0; Hu Y, 2024, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocad259; Hugging Face, 2024, Nexusflow/Starling-LM-7B-beta; Iqbal U, 2024, J AM MED INFORM ASSN, V31, P1341, DOI 10.1093/jamia/ocae067; Jahan I, 2024, COMPUT BIOL MED, V171, DOI 10.1016/j.compbiomed.2024.108189; Kojima T., 2022, Advances in neural information processing systems, V35, P22199, DOI DOI 10.48550/ARXIV.2205.11916; Krippendorff Klaus., 2004, Content analysis: An introduction to its methodology; Liu NF, 2024, T ASSOC COMPUT LING, V12, P157, DOI 10.1162/tacl_a_00638; Liu Q., 2023, P 2023 C EMP METH NA, P14414, DOI DOI 10.18653/V1/2023.EMNLP-MAIN.891; Mirza FN., 2024, NEJM AI, V1, pAIcs2300145; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Odisho AY, 2020, JAMIA OPEN, V3, P431, DOI 10.1093/jamiaopen/ooaa029; Radhakrishnan L, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad045; Sushil M., 2024, NEJM AI, V1, pAIdbp2300110, DOI [10.1056/AIdbp2300110, DOI 10.1056/AIDBP2300110]; Sushil M., 2022, arXiv; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Trivedi HM, 2019, J DIGIT IMAGING, V32, P30, DOI 10.1007/s10278-018-0105-8; Truhn D, 2024, J PATHOL, V262, P310, DOI 10.1002/path.6232; Wang LW, 2022, JCO CLIN CANCER INFO, V6, DOI 10.1200/CCI.22.00006; Wang Z, 2023, Arxiv, DOI arXiv:2306.01499; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wong C., 2023, MACHINE LEARNING HEA, P846; Wu HH, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00730-6; Zaretsky J, 2024, JAMA NETW OPEN, V7, DOI 10.1001/jamanetworkopen.2024.0357	42	0	0	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 JUN 20	2024										10.1093/jamia/ocae146	http://dx.doi.org/10.1093/jamia/ocae146		JUN 2024	13	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	UY3M4	38900207	hybrid			2024-07-03	WOS:001251585500001
J	Pan, SR; Luo, LH; Wang, YF; Chen, C; Wang, JP; Wu, XD				Pan, Shirui; Luo, Linhao; Wang, Yufei; Chen, Chen; Wang, Jiapu; Wu, Xindong			Unifying Large Language Models and Knowledge Graphs: A Roadmap	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Task analysis; Decoding; Cognition; Training; Predictive models; Knowledge graphs; Chatbots; Natural language processing; large language models; generative pre-training; knowledge graphs; roadmap; bidirectional reasoning	WEB	Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia, and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and, simultaneously, leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely: 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.	[Pan, Shirui] Griffith Univ, Sch Informat & Commun Technol, Nathan, Qld 4111, Australia; [Pan, Shirui] Griffith Univ, Inst Integrated & Intelligent Syst IIIS, Nathan, Qld 4111, Australia; [Luo, Linhao; Wang, Yufei] Monash Univ, Dept Data Sci & AI, Melbourne, Vic 3800, Australia; [Chen, Chen] Nanyang Technol Univ, Nanyang 639798, Singapore; [Wang, Jiapu] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China; [Wu, Xindong] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ China, Hefei 230002, Peoples R China; [Wu, Xindong] Zhejiang Lab, Res Ctr Knowledge Engn, Hangzhou 310058, Peoples R China	Griffith University; Griffith University; Monash University; Nanyang Technological University; Beijing University of Technology; Hefei University of Technology; Zhejiang Laboratory	Wu, XD (corresponding author), Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ China, Hefei 230002, Peoples R China.	s.pan@griffith.edu.au; linhao.luo@monash.edu; garyyufei@gmail.com; s190009@ntu.edu.sg; jpwang@emails.bjut.edu.cn; xwu@hfut.edu.cn		Wu, Xindong/0000-0003-2396-1704; Wang, Jiapu/0000-0001-7639-5289	Australian Research Council	Australian Research Council(Australian Research Council)	No Statement Available	Abu-Salih B, 2021, J NETW COMPUT APPL, V185, DOI 10.1016/j.jnca.2021.103076; Adolphs L, 2021, Arxiv, DOI arXiv:2108.01928; Alt M., 2019, P 1 C AUT KNOWL BAS; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Ayoola T, 2022, 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2022, P209; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bordes N., 2013, ADV NEURAL INFORM PR, P34; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Brown T., 2020, NIPS, P1877; Cao G., 2021, P INT C LEARN REPR A; Cao X, 2023, APPL INTELL, V53, P12032, DOI 10.1007/s10489-022-04123-w; Carlson A, 2010, AAAI CONF ARTIF INTE, P1306; Cattan A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P5100; Chen C., 2022, P 29 INT C COMPUTATI, P4005; Chen C., 2023, P 46 INT ACM SIGIR C; Chen WH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8635; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Chen Z, 2022, PROCEEDINGS OF THE 11TH INTERNATIONAL JOINT CONFERENCE ON KNOWLEDGE GRAPHS, IJCKG 2022, P20, DOI 10.1145/3579051.3579053; Choi B, 2021, IEEE ACCESS, V9, P132025, DOI 10.1109/ACCESS.2021.3113329; Choi W, 2019, IEEE ACCESS, V7, P179373, DOI 10.1109/ACCESS.2019.2957812; Choudhary N, 2024, Arxiv, DOI arXiv:2305.01157; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Cohen R, 2023, Arxiv, DOI arXiv:2307.12976; Dai D., 2021, arXiv; Danilevsky M, 2020, Arxiv, DOI [arXiv:2010.00711, DOI 10.48550/ARXIV.2010.00711]; Deng Shumin, 2023, 2023 IEEE 39th International Conference on Data Engineering (ICDE), P2988, DOI 10.1109/ICDE55515.2023.00229; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diao SZ, 2022, Arxiv, DOI arXiv:2201.08531; Farazi F, 2020, ACS OMEGA, V5, P18342, DOI 10.1021/acsomega.0c02055; Feng C, 2023, Arxiv, DOI arXiv:2309.03118; Feng SB, 2023, Arxiv, DOI arXiv:2305.08281; Feng YL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1295; Ferrada S, 2017, LECT NOTES COMPUT SC, V10588, P84, DOI 10.1007/978-3-319-68204-4_8; Gardent C., 2017, P 10 INT C NATURAL L, P124; Girdhar R, 2023, PROC CVPR IEEE, P15180, DOI 10.1109/CVPR52729.2023.01457; Golovneva O., 2023, P 11 INT C LEARN REP; Guan J, 2019, AAAI CONF ARTIF INTE, P6473; Guo QY, 2021, LECT NOTES COMPUT SC, V12999, P323, DOI 10.1007/978-3-030-87571-8_28; Guu K., 2020, INT C MACHINE LEARNI, P3929; Hai-Nyzhnyk P., 2022, Encyclopedia Herald Ukraine, V14, P81; Hakala K., 2019, P 5 WORKSH BIONLP OP, P56; Han JZ, 2024, Arxiv, DOI arXiv:2305.12392; He B, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2281; Hu N, 2023, Arxiv, DOI arXiv:2303.10368; Hu S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2098; Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956; Hwang JD, 2021, AAAI CONF ARTIF INTE, V35, P6384; Ilievski P., 2021, P SEM WEB C; Ji H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P725; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Ji Z., 2023, "ACMComput. Surv., V55, P38; Ji ZW, 2023, Arxiv, DOI arXiv:2212.01588; Jiang J., 2023, P 11 INT C LEARN REP; Jiang JH, 2023, Arxiv, DOI arXiv:2305.09645; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Jin Q., 2020, P 28 INT C COMPUTATI, P2398, DOI DOI 10.18653/V1/2020; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; Joshi M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5803; Kale A., 2020, P 13 INT C NATURAL L, P97; Kang J., 2022, P C N AM CHAPT ASS C, P5144; Ke P, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2526; Krysci nski W., 2019, arXiv; Kumar Ajay, 2020, 2020 6th International Conference on Signal Processing and Communication (ICSC), P310, DOI 10.1109/ICSC48311.2020.9182748; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li JY, 2021, Arxiv, DOI arXiv:2105.10311; Li S., 2022, arXiv; Li S., 2023, P ANN M ASS COMP LIN, P3366; Li S., 2022, P C EMP METH NAT LAN, P11118; Li ZY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3629; Li ZB, 2024, Arxiv, DOI [arXiv:2310.02129, DOI 10.48550/ARXIV.2310.02129]; Li ZJ, 2023, PROC INT CONF SOFTW, P1238, DOI 10.1109/ICSE48619.2023.00110; Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901; Liu X, 2023, Arxiv, DOI arXiv:2308.03688; Liu Y, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/9202457; Liu Y, 2021, AAAI CONF ARTIF INTE, V35, P6418; Liu Y, 2019, LECT NOTES COMPUT SC, V11503, P459, DOI 10.1007/978-3-030-21348-0_30; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Logan RL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5962; Lukovnikov D, 2019, LECT NOTES COMPUT SC, V11778, P470, DOI 10.1007/978-3-030-30793-6_27; Luo HR, 2023, Arxiv, DOI arXiv:2310.08975; Luo LH, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P900, DOI 10.1145/3539618.3591743; Luo LH, 2023, Arxiv, DOI arXiv:2310.01061; Luo LH, 2024, Arxiv, DOI arXiv:2309.01538; Luo T.-T., 2023, P C EMP METH NAT LAN; Ma Y., 2023, P 13 C EUR CHAPT ASS, P1963; Malinka K, 2023, Arxiv, DOI [arXiv:2303.11146, 10.48550/arXiv.2303.11146, DOI 10.1145/3587102.3588827, DOI 10.48550/ARXIV.2303.11146]; Mallen A, 2023, Arxiv, DOI arXiv:2212.10511; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Melnyk I., 2021, P NEURIPS 2021 WORKS; Meng ZQ, 2022, Arxiv, DOI arXiv:2110.08173; Mitchell T, 2018, COMMUN ACM, V61, P103, DOI 10.1145/3191513; Onoe Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2407; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Raffel C, 2020, J MACH LEARN RES, V21; Ribeiro M., 2021, P 3 WORKSHOP NATURAL, P211; Rosset C, 2021, Arxiv, DOI arXiv:2007.00655; Sanh V., 2022, P INT C LEARN REPR; Saravia E., 2022, "Prompt engineering guide; Saxena A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2814; Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4498; Shah S, 2019, AAAI CONF ARTIF INTE, P8876; Shen C., 2022, P INT C COMP LING, P1965; Shen T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8980; Shi BT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5182; Shi P, 2019, Arxiv, DOI arXiv:1904.05255; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Su D., 2019, P 2 WORKSHOP MACHINE, P203, DOI [10.18653/v1/D19-5827, DOI 10.18653/V1/D19-5827]; Su YS, 2021, AI OPEN, V2, P127, DOI 10.1016/j.aiopen.2021.06.004; Suchanek F.M., 2007, P 16 INT C WORLD WID, P697, DOI 10.1145/1242572.1242667; Sun JS, 2023, Arxiv, DOI arXiv:2307.07697; Sun R, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1405, DOI 10.1145/3340531.3411947; Sun T., 2020, P 28 INT C COMP LING, P3660, DOI [DOI 10.18653/V1/2020.COLING-MAIN.327, DOI 10.18653/V1/2020.COLING-MAIN.327,URL]; Sun Y., 2022, INT C MACH LEARN; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; Sun YQ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5049; Sung M., 2021, P 2021 C EMPIRICAL M, P4723, DOI [10.18653/v1/2021.emnlp-main.388, DOI 10.18653/V1/2021.EMNLP-MAIN.388]; Swamy V., 2021, arXiv; Tay Y., 2023, P 11 INT C LEARN REP; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tian H, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4067; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wan GJ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1926; Wang B, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1737, DOI 10.1145/3442381.3450043; Wang HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1835, DOI 10.1145/3178876.3186175; Wang J., 2022, P 2022 C EMPIRICAL M, P3164; Wang JN, 2024, Arxiv, DOI arXiv:2306.06427; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4281; Wang M, 2020, BIG DATA RES, V22, DOI 10.1016/j.bdr.2020.100159; Wang PF, 2019, AAAI CONF ARTIF INTE, P7152; Wang SY, 2023, Arxiv, DOI arXiv:2301.08913; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang XY, 2019, AAAI CONF ARTIF INTE, P7208; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Wang XT, 2022, Arxiv, DOI arXiv:2206.12617; Wang Y, 2023, Arxiv, DOI arXiv:2308.11730; Warren M., 2018, Proceedings of the 1st Workshop on Subjectivity, Ambiguity and Disagreement in Crowdsourcing, and Short Paper Proceedings of the 1st Workshop on Disentangling the Relation Between Crowdsourcing and Bias Management (SAD 2018 and CrowdBias 2018) co-located the 6th AAAI Conference on Human Computation and Crowdsourcing (HCOMP 2018), Zurich, Switzerland, July 5, 2018, volume 2276 of CEUR Workshop Proceedings, P41; Warren M., 2021, P AAAI SPRING S COMB; Wei J., 2022, "Trans. Mach.Learn. Res.; Wei JS, 2022, ADV NEUR IN; Wei XK, 2021, Arxiv, DOI arXiv:2110.08455; Wen YL, 2023, Arxiv, DOI arXiv:2308.09729; Wilmot D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P851; Wu M., 2022, P INT C LEARN REPR; Wu XD, 2023, IEEE T KNOWL DATA EN, V35, P634, DOI 10.1109/TKDE.2021.3073745; Wu Y., 2022, P C EMP METH NAT LAN, P5184; Xie X., 2022, "LambdaKG: A library for pre-trained language modelbased knowledge graph embeddings; Xie X, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P162, DOI 10.1145/3487553.3524238; Xiong W., 2020, P INT C LEARN REPR; Xiong WH, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1980; Xu B, 2017, LECT NOTES ARTIF INT, V10351, P428, DOI 10.1007/978-3-319-60045-1_44; Xu YC, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1201; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yam YM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3653; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang S. W.-T., 2015, P INT C LEARN REPR, P135; Yao L, 2019, Arxiv, DOI arXiv:1909.03193; Yao YZ, 2023, Arxiv, DOI arXiv:2305.13172; Yasunaga M., 2022, P INT C NEUR INF PRO; Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535; Ye HB, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P778, DOI 10.1145/3485447.3511921; Yin D, 2022, Arxiv, DOI arXiv:2202.08772; Yu DH, 2022, AAAI CONF ARTIF INTE, P11630; Yu WH, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1907; Zeng A., 2023, P 11 INT C LEARN REP; Zeng AH, 2023, Arxiv, DOI arXiv:2310.12823; Zhang DH, 2021, Arxiv, DOI arXiv:2009.02835; Zhang HQ, 2023, Arxiv, DOI arXiv:2201.05337; Zhang H, 2024, Arxiv, DOI [arXiv:2205.07424, DOI 10.48550/ARXIV.2205.07424]; Zhang HM, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4004; Zhang HM, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P201, DOI 10.1145/3366423.3380107; Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011; Zhang J, 2021, AI OPEN, V2, P14, DOI 10.1016/j.aiopen.2021.03.001; Zhang NY, 2022, Arxiv, DOI arXiv:2201.05575; Zhang TL, 2022, AAAI CONF ARTIF INTE, P11703; Zhang X., 2022, INT C LEARNING REPRE; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhang ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P259; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhen CQ, 2022, Arxiv, DOI arXiv:2212.13428; Zhong LF, 2023, Arxiv, DOI arXiv:2302.05019; Zhou H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4623; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592; Zhu H., 2023, Expert Syst. Appl., V215; Zhu XR, 2024, IEEE T KNOWL DATA EN, V36, P715, DOI 10.1109/TKDE.2022.3224228; Zhu YQ, 2017, SCI PROGRAMMING-NETH, V2017, DOI 10.1155/2017/5072427; Zhu YQ, 2024, Arxiv, DOI arXiv:2305.13168; Zoph B., 2022, arXiv	201	1	1	5	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2024	36	7					3580	3599		10.1109/TKDE.2024.3352100	http://dx.doi.org/10.1109/TKDE.2024.3352100			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TZ2O6		Green Submitted			2024-07-03	WOS:001245017200018
J	Carroll, AJ; Borycz, J				Carroll, Alexander J.; Borycz, Joshua			Integrating large language models and generative artificial intelligence tools into information literacy instruction	JOURNAL OF ACADEMIC LIBRARIANSHIP			English	Article						Generative artificial intelligence; Large language models; Information literacy; STEM education; Information retrieval; Critical thinking	RETRIEVAL; CHATGPT	Generative artificial intelligence (AI) and large language models (LLMs) have induced a mixture of excitement and panic among educators. However, there is a lack of consensus over how much experience science and engineering students have with using these tools for research-related tasks. Likewise, it is not yet known how educators and information professionals can leverage these tools to teach students strategies for information retrieval and knowledge synthesis. This study assesses the extent of students' use of AI tools in research-related tasks and if information literacy instruction could impact their perception of these tools. Responses to Likertscale questions indicate that many students did not have extensive experience using LLMs for research-related purposes prior to the information literacy sessions. However, after participating in a didactic lecture and discussion with an engineering librarian that explored how to use these tools effectively and responsibly, many students reported viewing these tools as potentially useful for future assignments. Student responses to openresponse questions suggest that librarian-led information literacy training can assist students in developing more sophisticated understandings of the limitations and use cases for artificial intelligence in inquiry-based coursework.	[Carroll, Alexander J.; Borycz, Joshua] Vanderbilt Univ, 3200 Stevenson Ctr,419 21st Ave South, Nashville, TN 37203 USA	Vanderbilt University	Carroll, AJ (corresponding author), Vanderbilt Univ, 3200 Stevenson Ctr,419 21st Ave South, Nashville, TN 37203 USA.	alex.carroll@vanderbilt.edu; joshua.d.borycz@Vanderbilt.Edu						Alphabet, 2024, Gemini-Chat to supercharge your ideas; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2015, Framework for Information Literacy for Higher Education; Anson C. M., 2008, Pluralizing plagiarism: Identities, contexts, pedagogies; ATTAR R, 1977, J ACM, V24, P397, DOI 10.1145/322017.322021; Autor D., 2024, working paper 32140, DOI [10.3386/w32140, DOI 10.3386/W32140]; BELKIN NJ, 1982, J DOC, V38, P61, DOI 10.1108/eb026722; Blakeslee S., 2004, LOEX Q, V31, P6, DOI DOI 10.3200/AEPR.105.4.31-36; Bodnick M., 2023, The Chronicle of Higher EducationJuly 26; BORGMAN CL, 1989, INFORM PROCESS MANAG, V25, P237, DOI 10.1016/0306-4573(89)90042-3; Boruff JT, 2023, J MED LIBR ASSOC, V111, P747, DOI 10.5195/jmla.2023.1826; Busch K. E., 2023, CRS report R47569, P11; Carroll A. J., 2024, Example didactic materials, DOI [10.17605/OSF.IO/RSYWJ, DOI 10.17605/OSF.IO/RSYWJ]; Carroll A. J., 2015, Journal of Creative Library Practice; Carroll A. J., 2024, Post-session Assessment Questionnaire, DOI [10.17605/OSF.IO/3H8E2, DOI 10.17605/OSF.IO/3H8E2]; Carroll A. J., 2024, Vanderbilt libraries' AI tools and ChatGPT assessment, DOI [10.17605/OSF.IO/MXSVJ, DOI 10.17605/OSF.IO/MXSVJ]; CNBC Television, 2024, We've hit "peak hype"of the AI revolution, says DeepMind co-founder Mustafa Suleyman; Coley M., 2023, Guidance on AI detection and why We're disabling Turnitin's AI detector | Brightspace support | Vanderbilt University; Cook DB, 2022, COLL RES LIBR, V83, P739; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; DAgostino S., 2022, Inside Higher EdOctober 25; Dempsey L., 2023, Generative AI and libraries: 7 contextsNovember 12; Dempsey L., 2023, Lorcan Dempsey's WeblogMay 24; DERVIN B, 1986, RQ, V25, P506; Diep F., 2023, The Chronicle of Higher EducationJuly 19; Duffy H., 2023, Harvard CrimsonFebruary 23; Eaton L., 2023, Syllabi Policies for AI Generative Tools; Faverio M., 2023, What the data says about Americans' views of artificial intelligenceNovember 21; Fraser C., 2023, ChatGPT: Automatic expensive BS at scaleFebruary 8; Gardijan N., 2023, 88 IFLA WORLD LIB IN; Genkina D., 2024, IEEE SpectrumMarch 6; Glaser B.G. Strauss., 2000, DISCOV GROUNDED THEO; Hadero H., 2024, AP NewsMarch 27; Herrman J., 2022, The machine will speak with you nowDecember 3; Horowitch R., 2023, The Atlantic; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Huang JS, 2023, AM J CANCER RES, V13, P1148; Huang K., 2023, The New York Times; Huiskes H., 2023, The Chronicle of Higher EducationJuly 28; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Karpathy A., 2015, Andrej Karpathy Blog; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kirschner PA, 2017, TEACH TEACH EDUC, V67, P135, DOI 10.1016/j.tate.2017.06.001; Klipfel KM, 2014, REF SERV REV, V42, P229, DOI 10.1108/RSR-08-2013-0043; Klosek K., 2024, ARL ViewsJanuary 23; Levine M., 2024, Bloomberg.ComJanuary 18; Levine M., 2024, Bloomberg.ComFebruary 20; Lo LS, 2024, J ACAD LIBR, V50, DOI 10.1016/j.acalib.2024.102883; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Marche S., 2022, The Atlantic; Meta, 2024, Meta llama; Metz C, 2023, New York Times29 March; Metz C., 2023, The New York TimesNovember 6; Miller RE, 2024, PORTAL-LIBR ACAD, V24, DOI 10.1353/pla.2024.a916988; Mollick E., 2023, One Useful ThingSeptember 16, DOI September 16; Noble SU, 2018, ALGORITHMS OF OPPRESSION, P1; Oakleaf M, 2012, COMMUN INF LIT, V6, P5, DOI 10.15760/comminfolit.2012.6.1.114; OpenAI, 2022, Introducing chatgpt; OpenAI, 2024, Prompt engineering; Pasick A., 2023, The New York TimesMarch 27; Pettit E., 2024, The Chronicle of Higher EducationJanuary 9; Pho A, 2022, COLL RES LIBR, V83, P726; Polverini G, 2024, EUR J PHYS, V45, DOI 10.1088/1361-6404/ad1420; Popper K. R., 1959, The Logic of Scientific Discovery; Prensky M., 2001, On the Horizon, V9, P1, DOI [10.1108/10748120110424816, DOI 10.1108/10748120110424816]; Reisner A., 2024, The AtlanticFebruary 29; Rogers EM., 2003, Diffusion of innovations (5. Aufl.), V5, DOI DOI 10.2307/2573300; Roose K., 2023, The New York TimesAugust 24; Rowlands I, 2008, ASLIB PROC, V60, P290, DOI 10.1108/00012530810887953; Salda├a┬▒a J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004; Sánchez-Ruiz LM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13106039; Schechner S., 2024, Wall Street JournalJanuary 17; Science Editorial Board, 2023, Science journals: Editorial policies; Selwyn N, 2009, ASLIB PROC, V61, P364, DOI 10.1108/00012530910973776; Sidoti O., 2023, About 1 in 5 U.S. teens who've heard of ChatGPT have used it for schoolworkNovember 16; Singer N., 2023, The New York TimesSeptember 1; Solomon L., 2023, What does this mean to me, Laura?February 10; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tay A., 2023, Musings about LibrarianshipMay 31; Terry O. K., 2023, The Chronicle of Higher EducationMay 12; Varanasi L., 2023, Business InsiderJanuary 25; Vogels E., 2023, A majority of Americans have heard of ChatGPT, but few have tried it themselves Internet; Walker KW, 2014, J ACAD LIBR, V40, P281, DOI 10.1016/j.acalib.2014.04.004; Wang KD, 2024, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1330486; Warner J., 2019, Just VisitingAugust 14; Warzel C., 2023, The Atlantic; Weiser B., 2023, The New York Times; White J., 2023, Prompt engineering for ChatGPT; Willson R, 2012, EVID BASED LIB INF P, V7, P52, DOI 10.18438/B85323; Wineburg S, 2022, J EDUC PSYCHOL, V114, P893, DOI 10.1037/edu0000740; Zerrenner E., 2023, ChatGPT Can't envision anything: It's actually BS-ing	91	0	0	8	8	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	0099-1333	1879-1999		J ACAD LIBR	J. Acad. Librariansh.	JUL	2024	50	4							102899	10.1016/j.acalib.2024.102899	http://dx.doi.org/10.1016/j.acalib.2024.102899			10	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	TZ9V0		hybrid			2024-07-03	WOS:001245207400001
J	Victor, BG; Sokol, RL; Goldkind, L; Perron, BE				Victor, Bryan G.; Sokol, Rebeccah L.; Goldkind, Lauri; Perron, Brian E.			Recommendations for Social Work Researchers and Journal Editors on the Use of Generative AI and Large Language Models	JOURNAL OF THE SOCIETY FOR SOCIAL WORK AND RESEARCH			English	Article						ChatGPT; large language models; generative artificial intelligence; social work research; social work journals		Generative artificial intelligence (AI) and large language models (LLMs) are poised to significantly impact social work research. These technologies can produce high-quality written materials and support qualitative and quantitative data analysis with simple, plain-language prompts from users. However, they also introduce challenges, such as potential bias, data privacy concerns, and generation of misinformation. In this paper, we use a disruptive-disrupting framework to discuss the dual nature of generative AI and LLMs and offer recommendations for social work researchers and journal editors that include guidance around data collection, analysis, interpretation, and dissemination. Researchers must use great caution when deploying generative AI technologies, meticulously examining, verifying, and taking accountability for the text and analyses produced by these instruments. Likewise, journal editors will need to implement quality control procedures and ethical standards to guide and evaluate the use of these technologies in social work research. We consider the recommendations offered here as a point of departure for disciplinary conversations about the role of generative AI and LLMs in social work research.	[Victor, Bryan G.] Wayne State Univ, Sch Social Work, Detroit, MI 48202 USA; [Sokol, Rebeccah L.] Univ Michigan Ann Arbor, Sch Social Work, Ann Arbor, MI USA; [Sokol, Rebeccah L.] Univ Michigan Ann Arbor, Inst Firearm Injury Prevent, Ann Arbor, MI USA; [Goldkind, Lauri] Fordham Univ, Grad Sch Social Serv, Bronx, NY 10458 USA; [Victor, Bryan G.] 5447 Wood ward Ave, Detroit, MI 48202 USA	Wayne State University; University of Michigan System; University of Michigan; University of Michigan System; University of Michigan; Fordham University	Victor, BG (corresponding author), 5447 Wood ward Ave, Detroit, MI 48202 USA.	bvictor@wayne.edu	Victor, Bryan/T-8349-2019; Perron, Brian E./AFW-1605-2022	Victor, Bryan/0000-0002-2092-912X; 				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; ATLAS.ti, 2023, ACC INN DAT AN; ATLAS.ti, 2023, Introducing: AI coding beta powered by OpenAI; Checco A, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-020-00703-8; Committee on Publication Ethics (COPE), 2023, AUTH TOOLS; Danneels E, 2004, J PROD INNOVAT MANAG, V21, P246, DOI 10.1111/j.0737-6782.2004.00076.x; Duracinsky M, 2017, BMC MED RES METHODOL, V17, DOI 10.1186/s12874-017-0371-z; Elsevier, 2023, Publishing Ethics; Felten Edward, 2023, ARXIV; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Goldkind L., IN PRESS; Gordon R., 2023, MIT NEWS; Ioakimidis V, 2023, BRIT J SOC WORK, V53, P693, DOI 10.1093/bjsw/bcad081; Kung JY, 2023, J CAN HEALTH LIBRARI, V44, P15, DOI 10.29173/jchla29657; Markovski Y., 2023, How Your Data is Used to Improve Model Performance; National Information Standards Organization, 2023, CRediT; Nature, 2023, NATURE 0124; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OpenAI, 2023, Terms of use; Perron B. E., 2023, MEDIUM 0411; Proceedings of the National Academy of Sciences (PNAS), 2023, PNAS J OUTLINE THEIR; Sardana D, 2023, J AM DENT ASSOC, V154, P361, DOI 10.1016/j.adaj.2023.02.008; Scheyett A, 2023, SOC WORK, V68, P101, DOI 10.1093/sw/swad010; Science, 2023, Science Journals: Editorial Policies; Scite Inc, 2023, US; semantic scholar, About us; Singer JB, 2023, J SOC WORK EDUC, V59, P294, DOI 10.1080/10437797.2023.2189878; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Victor BG, 2023, RES SOCIAL WORK PRAC, V33, P511, DOI 10.1177/10497315231166125; Wang S., 2023, arXiv	30	2	2	33	93	UNIV CHICAGO PRESS	CHICAGO	1427 E 60TH ST, CHICAGO, IL 60637-2954 USA	2334-2315	1948-822X		J SOC SOC WORK RES	J. Soc. Soc. Work Res.	SEP 1	2023	14	3					563	577		10.1086/726021	http://dx.doi.org/10.1086/726021		SEP 2023	15	Social Work	Social Science Citation Index (SSCI)	Social Work	U1CN0					2024-07-03	WOS:001039931900002
J	Park, PS; Schoenegger, P; Zhu, CY				Park, Peter S.; Schoenegger, Philipp; Zhu, Chongyang			Diminished diversity-of-thought in a standard large language model	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						GPT-3.5; Large language models; Artificial intelligence; Many Labs 2; Psychology; Replication; Order effects; Demographic effects; Diversity of thought; Social science	OPTIONS; BIAS; PSYCHOLOGY; PEOPLE	We test whether large language models (LLMs) can be used to simulate human participants in social-science studies. To do this, we ran replications of 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT-3.5. Based on our pre-registered analyses, we find that among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results and 37.5% of the Many Labs 2 results. However, we were unable to analyse the remaining six studies due to an unexpected phenomenon we call the "correct answer" effect. Different runs of GPT-3.5 answered nuanced questions probing political orientation, economic preference, judgement, and moral philosophy with zero or near-zero variation in responses: with the supposedly "correct answer." In one exploratory follow-up study, we found that a "correct answer" was robust to changing the demographic details that precede the prompt. In another, we found that most but not all "correct answers" were robust to changing the order of answer choices. One of our most striking findings occurred in our replication of the Moral Foundations Theory survey results, where we found GPT-3.5 identifying as a political conservative in 99.6% of the cases, and as a liberal in 99.3% of the cases in the reverse-order condition. However, both self-reported 'GPT conservatives' and 'GPT liberals' showed right-leaning moral foundations. Our results cast doubts on the validity of using LLMs as a general replacement for human participants in the social sciences. Our results also raise concerns that a hypothetical AI-led future may be subject to a diminished diversity of thought.	[Park, Peter S.] MIT, Dept Phys, 70 Vassar St, Cambridge, MA 02139 USA; [Schoenegger, Philipp] London Sch Econ & Polit Sci, Dept Management, 44 Lincolns Inn Fields, London WC2A 2ES, England; [Zhu, Chongyang] CVS Hlth, 1 CVS Dr, Woonsocket, RI USA	Massachusetts Institute of Technology (MIT); University of London; London School Economics & Political Science	Park, PS (corresponding author), MIT, Dept Phys, 70 Vassar St, Cambridge, MA 02139 USA.	dr_park@mit.edu; contact.schoenegger@gmail.com; cyzhu95@gmail.com			Massachusetts Institute of Technology (MIT); MIT Department of Physics and the Beneficial AI Foundation	Massachusetts Institute of Technology (MIT); MIT Department of Physics and the Beneficial AI Foundation	P.S.P. is grateful to be funded by the MIT Department of Physics and the Beneficial AI Foundation. The research views presented in this paper are solely the authors' and do not express the views of MIT, the institution of P.S.P.; of the London School of Economics, the institution of P.S.; or of CVS Health, the employer of C.Z., We are grateful to Maximilian Maier for his valuable contribution to the pre-registration writeup. We are also grateful to Mohammad Atari, Stephen Fowler, Ben Grodeck, Joe Henrich, Kevin Hong, Liav Koren, Ivan Kroupin, Raimund Pils, Konstantin Pilz, Slava Savitskiy, and Marc Wong for their helpful comments on the draft.	Abdulhai M., 2023, AAAI 2023; Aher G, 2022, Arxiv, DOI arXiv:2208.10264; Alba A., 2016, New York Daily News; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Atkinson R. C., 1968, Psychology of Learning and Motivation, V2, P89, DOI 10.1016/S0079-7421(08)60422-3; Bauer MA, 2012, PSYCHOL SCI, V23, P517, DOI 10.1177/0956797611429579; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Edwards B., 2023, Ars Technica; Ernst E, 2019, IZA J LABOR POLICY, V9, DOI 10.2478/izajolp-2019-0004; Graham J, 2011, J PERS SOC PSYCHOL, V101, P366, DOI 10.1037/a0021847; Graham J, 2009, J PERS SOC PSYCHOL, V96, P1029, DOI 10.1037/a0015141; Grossman D., 2018, POPULAR MECH; Grossmann I, 2023, SCIENCE, V380, P1108, DOI 10.1126/science.adi1778; Hartmann J, 2023, Arxiv, DOI [arXiv:2301.01768, 10.48550/ARXIV.2301.01768, DOI 10.48550/ARXIV.2301.01768]; Hauser M, 2007, MIND LANG, V22, P1, DOI 10.1111/j.1468-0017.2006.00297.x; Henrich J, 2010, BEHAV BRAIN SCI, V33, P61, DOI 10.1017/S0140525X0999152X; Hohensinn C, 2017, PSICOLOGICA, V38, P93; Horton JJ, 2023, Arxiv, DOI [arXiv:2301.07543, DOI 10.48550/ARXIV.2301.07543]; Hsee CK, 1998, J BEHAV DECIS MAKING, V11, P107, DOI 10.1002/(SICI)1099-0771(199806)11:2<107::AID-BDM292>3.0.CO;2-Y; Hu LJ, 2023, Arxiv, DOI arXiv:2301.09112; Huszar F, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2025334119; Inbar Y, 2009, EMOTION, V9, P435, DOI 10.1037/a0015960; John O. P., 1999, HDB PERSONALITY THEO, P102, DOI DOI 10.1525/FQ.1998.51.4.04A00260; Jones DN, 2014, ASSESSMENT, V21, P28, DOI 10.1177/1073191113514105; Kay AC, 2014, J EXP PSYCHOL GEN, V143, P486, DOI 10.1037/a0034462; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Klein RA, 2018, ADV METH PRACT PSYCH, V1, P443, DOI 10.1177/2515245918810225; Knobe J, 2003, ANALYSIS, V63, P190, DOI 10.1111/1467-8284.00419; Lambrecht A, 2019, MANAGE SCI, V65, P2966, DOI 10.1287/mnsc.2018.3093; Levin Sam., 2016, GUARDIAN; Li XX, 2024, Arxiv, DOI [arXiv:2212.10529, DOI 10.48550/ARXIV.2212.10529, 10.48550/arXiv.2212.10529]; Majid A, 2023, NAT REV PSYCHOL, V2, P199, DOI 10.1038/s44159-023-00169-w; Matthewson J, 2009, SYNTHESE, V170, P169, DOI 10.1007/s11229-008-9366-y; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Metz Cade, 2020, New York Times; Miotto M., 2022, P 5 WORKSHOP NATURAL, P218; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, Completions; OpenAI, 2023, Models; OpenAI, 2023, Introducing chatgpt; OpenAI, 2020, OpenAI Charter; OToole L., 2021, Authoritas; Park P. S., 2023, Open Science Framework; Risen JL, 2008, J PERS SOC PSYCHOL, V95, P293, DOI 10.1037/0022-3514.95.2.293; Robertson Ronald E., 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274417; Roose K., 2023, NEW YORK TIMES; Rose A., 2010, Time; Rosenblatt K., 2023, NBCNews.com; ROSS L, 1977, J EXP SOC PSYCHOL, V13, P279, DOI 10.1016/0022-1031(77)90049-X; Rottenstreich Y, 2001, PSYCHOL SCI, V12, P185, DOI 10.1111/1467-9280.00334; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Salles Arleen, 2020, AJOB Neurosci, V11, P88, DOI 10.1080/21507740.2020.1740350; Schimmelpfennig R., 2023, PsyArXiv; SCHWARZ N, 1991, PUBLIC OPIN QUART, V55, P3, DOI 10.1086/269239; SHAFIR E, 1993, MEM COGNITION, V21, P546, DOI 10.3758/BF03197186; Shiffrin R, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2300963120; Shihadeh J., 2022, 2022 IEEE GLOB HUM T, P62, DOI 10.1109/GHTC55712.2022.9910995; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; Warren T., 2023, VERGE	64	0	0	13	13	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 JAN 9	2024										10.3758/s13428-023-02307-x	http://dx.doi.org/10.3758/s13428-023-02307-x		JAN 2024	17	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	EI3T6	38194165	hybrid, Green Submitted, Green Accepted			2024-07-03	WOS:001138262400004
C	Shieh, A; Paolucci, I; Albuquerque, J; Brock, K; Odisio, B		Yoshida, H; Wu, S		Shieh, Alexander; Paolucci, Iwan; Albuquerque, Jessica; Brock, Kristy; Odisio, Bruno			Feasibility of Extracting Critical Diagnostic Imaging Report Findings Following Percutaneous Liver Ablation with a Large Language Model	IMAGING INFORMATICS FOR HEALTHCARE, RESEARCH, AND APPLICATIONS, MEDICAL IMAGING 2024	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging - Imaging Informatics for Healthcare, Research, and Applications	FEB 19-21, 2024	San Diego, CA	SPIE, Amer Assoc Physicists Med, Radiol Soc N Amer, World Mol Imaging Soc, Soc Imaging Informat Med, Int Fdn Comp Assisted Radiol & Surg, Med Image Percept Soc		percutaneous liver ablation; radiology report; large language model; information retrieval; cancer surveillance		Percutaneous liver ablation is a minimally invasive procedure to treat liver tumors. Postablation images are highly significant as they distinguish normal post-procedure changes from abnormalities, preventing unnecessary retreatment and confirming procedural quality. However, the cancer surveillance imaging reports after the procedure can be numerous and challenging to read. Moreover, annotated data is limited in this setting. In this study we used the cutting-edge large language model Llama 2 to automatically extract critical findings from real-world diagnostic imaging reports without the need of training a new information extraction model. This could potentially automate part of the outcome research and registry construction process, as well as decrease the number of studies needed to review for research purposes. A dataset of 87 full-text reports from 13 patients who underwent percutaneous thermal ablation for pancreatic liver metastases were used to benchmark the capability of Llama 2 for cancer progression finding extraction and classification. We asked Llama 2 to determine whether there is cancer progression within the given report and then classify progression findings into local tumor progression (LTP), intrahepatic progression (IHP) and extrahepatic progression (EHP). Llama 2 achieved decent performance for detecting progression at study level. The precision is 0.91 and recall is 0.96, with specificity 0.84. However, the classification of progression into LTP, IHP and EHP still needs to be improved.	[Shieh, Alexander; Paolucci, Iwan; Albuquerque, Jessica; Odisio, Bruno] Univ Texas MD Anderson Canc Ctr, Det Intervent Radiol, 1400 Pressler St, Houston, TX 77030 USA; [Shieh, Alexander; Brock, Kristy; Odisio, Bruno] Univ Texas MD Anderson Canc Ctr, Image Guided Canc Therapy Res Program, 1400 Pressler St, Houston, TX 77030 USA; [Brock, Kristy] Univ Texas MD Anderson Canc Ctr, Dept Imaging Phys, 1400 Pressler St, Houston, TX 77030 USA	University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center	Shieh, A (corresponding author), Univ Texas MD Anderson Canc Ctr, Det Intervent Radiol, 1400 Pressler St, Houston, TX 77030 USA.; Shieh, A (corresponding author), Univ Texas MD Anderson Canc Ctr, Image Guided Canc Therapy Res Program, 1400 Pressler St, Houston, TX 77030 USA.	adshieh@mdanderson.org						Ahmed M, 2014, RADIOLOGY, V273, P241, DOI [10.1148/radiol.14132958, 10.1016/j.jvir.2014.08.027]; Puijk RS, 2021, RADIOLOGY, V301, P533, DOI 10.1148/radiol.2021203715; Steinkamp JM, 2019, J DIGIT IMAGING, V32, P554, DOI 10.1007/s10278-019-00234-y; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258	5	0	0	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	1996-756X	978-1-5106-7167-6; 978-1-5106-7166-9	PROC SPIE			2024	12931								1293104	10.1117/12.3008791	http://dx.doi.org/10.1117/12.3008791			4	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BW9QJ					2024-07-03	WOS:001219280700003
J	King, E; Yu, HX; Lee, S; Julien, C				King, Evan; Yu, Haoxiang; Lee, Sangsu; Julien, Christine			Sasha: Creative Goal-Oriented Reasoning in Smart Homes with Large Language Models	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						smart environments; pervasive computing; ambient intelligence; large language models	USERS	Smart home assistants function best when user commands are direct and well-specified-e.g., "turn on the kitchen light"-or when a hard-coded routine specifies the response. In more natural communication, however, human speech is unconstrained, often describing goals (e.g., "make it cozy in here" or "help me save energy") rather than indicating specific target devices and actions to take on those devices. Current systems fail to understand these under-specified commands since they cannot reason about devices and settings as they relate to human situations. We introduce large language models (LLMs) to this problem space, exploring their use for controlling devices and creating automation routines in response to under-specified user commands in smart homes. We empirically study the baseline quality and failure modes of LLM-created action plans with a survey of age-diverse users. We find that LLMs can reason creatively to achieve challenging goals, but they experience patterns of failure that diminish their usefulness. We address these gaps with Sasha, a smarter smart home assistant. Sasha responds to loosely-constrained commands like "make it cozy" or "help me sleep better" by executing plans to achieve user goals-e.g., setting a mood with available devices, or devising automation routines. We implement and evaluate Sasha in a hands-on user study, showing the capabilities and limitations of LLM-driven smart homes when faced with unconstrained user-generated scenarios.	[King, Evan; Yu, Haoxiang; Lee, Sangsu; Julien, Christine] Univ Texas Austin, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	King, E (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.	e.king@utexas.edu; hxyu@utexas.edu; sethlee@utexas.edu; c.julien@utexas.edu		King, Evan/0000-0003-4689-4591	National Science Foundation [CNS-1909221]	National Science Foundation(National Science Foundation (NSF))	We thank the anonymous reviewers for their constructive feedback on the paper. This work was funded in part by the National Science Foundation under grant CNS-1909221. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the NSF.	Acampora G, 2013, P IEEE, V101, P2470, DOI 10.1109/JPROC.2013.2262913; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alaa M, 2017, J NETW COMPUT APPL, V97, P48, DOI 10.1016/j.jnca.2017.08.017; [Anonymous], 2022, Insteon REST API Documentation.; [Anonymous], 2023, About us; [Anonymous], 2023, TP-Link Kasa Smart Plugs; [Anonymous], 2022, Philips Hue API Documentation.; [Anonymous], 2022, Google Nest API Documentation.; Bentley Frank, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3264901; Botsch R, 2011, SCOPES METHODS POLIT; Branny A, 2022, CURR OPIN ENV SUST, V55, DOI 10.1016/j.cosust.2022.101168; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chomsky N., 2002, Syntactic Structures, V2, DOI DOI 10.1515/9783110218329; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clark Meghan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3132031; Cook DJ, 2012, IEEE INTELL SYST, V27, P32, DOI 10.1109/MIS.2010.112; COOPER WS, 1971, INFORM STORAGE RET, V7, P19, DOI 10.1016/0020-0271(71)90024-6; Cowan BR, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3098539; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019; Dunne R, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447242; Fast E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P237, DOI 10.1145/2858036.2858528; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Garg R, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3381002; Georgievski I, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3004294; Haoxiang Yu, 2021, SenSys '21: Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems, P537, DOI 10.1145/3485730.3494115; Jeong KA, 2010, ERGONOMICS, V53, P636, DOI 10.1080/00140130903581623; Kim D, 2022, ENERGIES, V15, DOI 10.3390/en15124278; Kim S, 2021, COMPUT HUM BEHAV, V124, DOI 10.1016/j.chb.2021.106914; King E, 2023, Arxiv, DOI arXiv:2303.14143; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Liang JCY, 2022, Arxiv, DOI [arXiv:2209.07753, 10.48550/arXiv.2209.07753]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Luger E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5286, DOI 10.1145/2858036.2858288; LUTOLF R, 1992, IEE CONF PUBL, V367, P277; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Motta I, 2022, LECT NOTES COMPUT SC, V13304, P494, DOI 10.1007/978-3-031-05412-9_34; Mu J, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312975; Noura M, 2020, LECT NOTES COMPUT SC, V12128, P171, DOI 10.1007/978-3-030-50578-3_13; Noura Mahda, 2020, P 10 INT C INTERNET, P1; OpenAI, 2023, tiktoken: a fast BPE tokeniser for use with OpenAI's models; Palanca J, 2018, INFORM SYST FRONT, V20, P125, DOI 10.1007/s10796-016-9670-x; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Pradhan A, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3373759; Qiao SF, 2023, Arxiv, DOI [arXiv:2212.09597, DOI 10.48550/ARXIV.2212.09597]; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Reisinger Michaela R, 2022, J Ambient Intell Humaniz Comput, P1, DOI 10.1007/s12652-021-03651-6; Shi F, 2023, Arxiv, DOI arXiv:2302.00093; Shin J, 2018, TECHNOL FORECAST SOC, V134, P246, DOI 10.1016/j.techfore.2018.06.029; Skreta M, 2023, Arxiv, DOI arXiv:2303.14100; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Upadhyay P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580925; Vaswani A, 2017, ADV NEUR IN, V30; Webster J.J., 1992, P 14 C COMP LING, V4, P1106, DOI DOI 10.3115/992424.992434; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94; Wilson C, 2015, PERS UBIQUIT COMPUT, V19, P463, DOI 10.1007/s00779-014-0813-0; Wu JMY, 2023, Arxiv, DOI arXiv:2305.05658; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582	64	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAR	2024	8	1							12	10.1145/3643505	http://dx.doi.org/10.1145/3643505			38	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	OM1I2		Green Submitted, hybrid			2024-07-03	WOS:001207594200012
C	Leiser, F; Eckhardt, S; Knaeble, M; Maedche, A; Schwabe, G; Sunyaev, A		Stolze, M; Loch, F; Baldauf, M; Alt, F; Schneedass, C; Kosch, T; Hirzle, T; Sadeghian, S; Draxler, F; Bektas, K; Lohan, K; Knierim, P		Leiser, Florian; Eckhardt, Sven; Knaeble, Merlin; Maedche, Alexander; Schwabe, Gerhard; Sunyaev, Ali			From ChatGPT to FactGPT: A Participatory Design Study to Mitigate the Effects of Large Language Model Hallucinations on Users	PROCEEDINGS OF 2023 MENSCH UND COMPUTER, MUC 2023: Building Bridges			English	Proceedings Paper	Conference on Mensch und Computer (MuC) - Building Bridges	SEP 03-06, 2023	Eastern Switzerland Univ Appl Sci, Rapperswil, SWITZERLAND	German Informat Soc, Special Interest Grp Human Comp Interact, German UPA	Eastern Switzerland Univ Appl Sci	ChatGPT; Large Language Models; Disney Method; Participatory Design; Artificial Hallucinations	AUTOMATION; ELIZA	Large language models (LLMs) like ChatGPT recently gained interest across all walks of life with their human-like quality in textual responses. Despite their success in research, healthcare, or education, LLMs frequently include incorrect information, called hallucinations, in their responses. These hallucinations could influence users to trust fake news or change their general beliefs. Therefore, we investigate mitigation strategies desired by users to enable identification of LLM hallucinations. To achieve this goal, we conduct a participatory design study where everyday users design interface features which are then assessed for their feasibility by machine learning (ML) experts. We find that many of the desired features are well-perceived by ML experts but are also considered as difficult to implement. Finally, we provide a list of desired features that should serve as a basis for mitigating the effect of LLM hallucinations on users.	[Leiser, Florian; Knaeble, Merlin; Maedche, Alexander; Sunyaev, Ali] Karlsruhe Inst Technol, Karlsruhe, Germany; [Eckhardt, Sven; Schwabe, Gerhard] Univ Zurich, Zurich, Switzerland	Helmholtz Association; Karlsruhe Institute of Technology; University of Zurich	Leiser, F (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.	florian.leiser@kit.edu; eckhardt@ifi.uzh.ch; merlin.knaeble@kit.edu; alexander.maedche@kit.edu; schwabe@ifi.uzh.ch; sunyaev@kit.edu		Schwabe, Gerhard/0000-0002-0453-9762; Eckhardt, Sven/0000-0002-4713-8408; Maedche, Alexander/0000-0001-6546-4816; Sunyaev, Ali/0000-0002-4353-8519; Knaeble, Merlin/0000-0002-5108-4609				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Adesso, 2022, PREPRINT; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Bassett C, 2019, AI SOC, V34, P803, DOI 10.1007/s00146-018-0825-9; Bell Emily, 2023, The GuardianMarch; Benke Ivo, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415189; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brereton Dmitri, 2023, Bing AI Can't Be Trusted; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Coulter Martin, 2023, ReutersFeb.; Dilts Robert, 1994, Aristotle, Sherlock Holmes, Walt Disney, Wolfgang Amadeus Mozart, V1; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Feine J, 2019, INT J HUM-COMPUT ST, V132, P138, DOI 10.1016/j.ijhcs.2019.07.009; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Google, 2021, LaMDA: our breakthrough conversation technology; Gu JC, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2041, DOI 10.1145/3340531.3412330; Holzinger Andreas, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P55, DOI 10.1109/DISA.2018.8490530; Kahne J, 2018, POLIT COMMUN, V35, P470, DOI 10.1080/10584609.2018.1426662; Kaplan D, 1998, COMMUN ACM, V41, P72, DOI 10.1145/269012.269024; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Knaeble M., 2023, 31st European Conference on Information Systems (ECIS) Research Papers; Knaeble M, 2023, 20TH INTERNATIONAL WEB FOR ALL CONFERENCE, W4A 2023, P104, DOI 10.1145/3587281.3587293; Lai V., 2021, arXiv; Lee JD, 2004, HUM FACTORS, V46, P50, DOI 10.1518/hfes.46.1.50.30392; Lins S, 2021, BUS INFORM SYST ENG+, V63, P441, DOI 10.1007/s12599-021-00708-w; Lopez YP, 2005, J BUS ETHICS, V60, P341, DOI 10.1007/s10551-005-1834-4; Lorenz J, 2011, P NATL ACAD SCI USA, V108, P9020, DOI 10.1073/pnas.1008636108; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; McGilvray D., 2021, Executing data quality projects: Ten steps to quality data and trusted information (TM); Mehdi Y., 2023, REINVENTING SEARCH N; Min Kyung Lee, 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359283; Muller Michael J., 2002, Participatory Design: The Third Space in HCI, P1051; Narayan Jyoti, 2023, Elon Musk and others urge ai pause, citing 'risks to society'; Norvig P., 1992, Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp; O'Connor S, 2023, NURSE EDUC PRACT, V67, DOI 10.1016/j.nepr.2023.103572; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OpenAI, 2023, Introducing chatgpt; OpenAI, OPENAI API REFERENCE; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Parasuraman R, 1997, HUM FACTORS, V39, P230, DOI 10.1518/001872097778543886; Passi Samir, 2022, Overreliance on AI: Literature review; Porciello J, 2020, NAT MACH INTELL, V2, P559, DOI 10.1038/s42256-020-00235-5; Renner Maximilian, 2021, BUILDING SUSTAINABIL; RobertWMcGee, 2023, Annie Chan: Three Short StoriesWritten with Chat GPT; Sathe A, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6874; Shneiderman B, 2020, INT J HUM-COMPUT INT, V36, P495, DOI 10.1080/10447318.2020.1741118; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tausch S, 2015, LECT NOTES COMPUT SC, V9298, P614, DOI 10.1007/978-3-319-22698-9_42; Thiebes S, 2021, ELECTRON MARK, V31, P447, DOI 10.1007/s12525-020-00441-4; Venuto Giuseppe, 2023, LLM failure archive (ChatGPT and beyond); Vincent James, 2023, Google and Microsoft's chatbots are already citing one another in a misinformation shitshow; von Rueden L, 2023, IEEE T KNOWL DATA EN, V35, P614, DOI 10.1109/TKDE.2021.3079836; Walter N, 2020, POLIT COMMUN, V37, P350, DOI 10.1080/10584609.2019.1668894; Wang YX, 2007, INT J COGN INFORM NA, V1, P73; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Yigitbasioglu Ogan M., 2012, International Journal of Accounting Information Systems, V13, P41, DOI 10.1016/j.accinf.2011.08.002; Zytko Douglas, 2022, 2022 CHI C HUM FACT, P1, DOI [10.1145/3491101, DOI 10.1145/3491101]	60	2	2	27	27	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0771-1				2023							81	90		10.1145/3603555.3603565	http://dx.doi.org/10.1145/3603555.3603565			10	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2KJ					2024-07-03	WOS:001117817900007
J	Ghandour, A; Woodford, BJ; Abusaimeh, H				Ghandour, Ahmad; Woodford, Brendon J.; Abusaimeh, Hesham			Ethical Considerations in the Use of ChatGPT: An Exploration Through the Lens of Five Moral Dimensions	IEEE ACCESS			English	Article						Machine ethics; machine learning; social implications of technology	ARTIFICIAL-INTELLIGENCE	This article seeks to illuminate the ethical challenges and concerns presented by the utilization of the large language model, ChatGPT. Five critical ethical dimensions as proposed by Laudon and Laudon - Information rights and obligations, Property rights and obligations, Accountability and control, System quality, and Quality of life - will serve as the analytical framework to explore the pertinent issues. Although our investigation revealed that AI technologies like ChatGPT have tremendous potential for societal advancement they also present complex ethical challenges. The implications of our research have impact not only for developers of large language models but also developers of AI technologies in general, policy makers, end-users of these AI applications, and society as whole. Based on our findings we propose key recommendations to address the current concerns with respect to the ethical issues surrounding large language models. By assessing these ethical dimensions within the context of ChatGPT, this paper underscores the importance of developing comprehensive ethical guidelines and policies in the era of increasingly sophisticated AI applications.	[Ghandour, Ahmad] Middle East Univ, Fac Business, Dept Business, Amman 11831, Jordan; [Woodford, Brendon J.] Univ Otago, Sch Comp, Dunedin 9054, New Zealand; [Abusaimeh, Hesham] Middle East Univ, Fac Informat Technol, Amman, Jordan	Middle East University; University of Otago; Middle East University	Ghandour, A (corresponding author), Middle East Univ, Fac Business, Dept Business, Amman 11831, Jordan.	aghandour@meu.edu.jo	Ghandour, Ahmad/JAC-9526-2023	Ghandour, Ahmad/0000-0003-4445-7443; Woodford, Brendon/0000-0001-5202-9700	Middle East University	Middle East University	This research received generous support from Middle East University, which also kindly covered the Article Processing Charges (APC) for publication. We express our gratitude fortheir invaluable contribution	Abbott R., 2016, BCL Rev, V57, P1079, DOI DOI 10.2139/SSRN.2727884; Alessa A, 2023, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023, P667, DOI 10.1145/3594806.3596572; Balkin J.M., 2016, UCDL REV, V49, P1183; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Biswas S., 2023, Journal of Alsalam University, V6, P39; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bossmann J., 2016, Top 9 ethical issues in artificial intelligence; Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316; Bryson J.J., 2019, Towards a New Enlightenment? A Transcendent Decade, P127; Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a; Cath C, 2018, SCI ENG ETHICS, V24, P505, DOI 10.1007/s11948-017-9901-7; Crawford K, 2016, NATURE, V538, P311, DOI 10.1038/538311a; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Ferrara E, 2023, Should ChatGPT Be Biased? Challenges and Risks of Bias in Large Language Models; Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5; Flynn S., 2020, Conversation on Intellectual Property (IP) and Artificial Intelligence (AI); Garcia MB, 2023, J LOSS TRAUMA, V28, P784, DOI 10.1080/15325024.2023.2240697; Gavaghan C., 2021, The Impact of Artificial Intelligence on Jobs and Work in New Zealand; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hales BM, 2006, J CRIT CARE, V21, P231, DOI 10.1016/j.jcrc.2006.06.002; Hartzog W, 2018, Cambridge Law J., V79, P377; Holzinger A, 2017, Arxiv, DOI arXiv:1712.09923; Jodha P., 2023, Res Militaris, V13, P1737; Kaplan J, 2021, Cyber Security, Artificial Intelligence, Data Protection & the Law, P39; Kejriwal M, 2023, Artificial Intelligence for Industries of the Future: Beyond Facebook, Amazon, Microsoft and Google, P101; Kuner C., 2021, The EU general data protection regulation: A commentary/update of selected articles, DOI [10.2139/ssrn.3839645, DOI 10.2139/SSRN.3839645]; Laudon K.C., 2009, MANAGEMENT INFORM SY, V11th; MacCarthy M., 2019, How To Address New Privacy Issues Raised By Artificial Intelligence and Machine Learning; Mansfield-Devine S, 2023, Network Security; Maras MH, 2019, INT J EVID PROOF, V23, P255, DOI 10.1177/1365712718807226; Mittelstadt BD, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951716679679; Neville-Rolfe B., 2016, The Challenge of Protecting Intellectual Property; Piñeiro-Martín A, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12143170; Rad D., 2023, Journal of Education, V32, P43, DOI [10.24250/jpe/Vol.321/2023/DR/GR, DOI 10.24250/JPE/VOL.321/2023/DR/GR]; Radford J., 2019, Language Models Are Unsupervised Multitask Learners; Regulation of the European Parliament and of the Council, 2016, document EU2016/679; Ryan M, 2024, AI SOC, V39, P557, DOI 10.1007/s00146-022-01430-1; Sarel R., 2023, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.4354486; Schiff D, 2020, IEEE SYS MAN CYBERN, P2746, DOI [10.1109/SMC42975.2020.9283454, 10.1109/smc42975.2020.9283454]; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Solove D. J, 2008, Res. Paper 420; Strowel A, 2023, IIC-INT REV INTELL P, DOI 10.1007/s40319-023-01321-y; Theofilou P, 2013, EUR J PSYCHOL, V9, P150, DOI 10.5964/ejop.v9i1.337; Vaswani A, 2017, ADV NEUR IN, V30; Wang ZB, 2022, PROC CVPR IEEE, P10369, DOI 10.1109/CVPR52688.2022.01013; WIPO, 2020, CONV INT PROP IP ART; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Wu X., 2024, J. Inf. Intell., V2, P102; Yapo A, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P5365; Zech Herbert, 2021, ERA Forum, V22, P147, DOI 10.1007/s12027-020-00648-0	50	0	0	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						60682	60693		10.1109/ACCESS.2024.3394243	http://dx.doi.org/10.1109/ACCESS.2024.3394243			12	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	PL8R4		gold			2024-07-03	WOS:001214330500001
J	Trad, F; Chehab, A				Trad, Fouad; Chehab, Ali			Prompt Engineering or Fine-Tuning? A Case Study on Phishing Detection with Large Language Models	MACHINE LEARNING AND KNOWLEDGE EXTRACTION			English	Article						large language models; prompt engineering; fine-tuning; phishing detection	URL	Large Language Models (LLMs) are reshaping the landscape of Machine Learning (ML) application development. The emergence of versatile LLMs capable of undertaking a wide array of tasks has reduced the necessity for intensive human involvement in training and maintaining ML models. Despite these advancements, a pivotal question emerges: can these generalized models negate the need for task-specific models? This study addresses this question by comparing the effectiveness of LLMs in detecting phishing URLs when utilized with prompt-engineering techniques versus when fine-tuned. Notably, we explore multiple prompt-engineering strategies for phishing URL detection and apply them to two chat models, GPT-3.5-turbo and Claude 2. In this context, the maximum result achieved was an F1-score of 92.74% by using a test set of 1000 samples. Following this, we fine-tune a range of base LLMs, including GPT-2, Bloom, Baby LLaMA, and DistilGPT-2-all primarily developed for text generation-exclusively for phishing URL detection. The fine-tuning approach culminated in a peak performance, achieving an F1-score of 97.29% and an AUC of 99.56% on the same test set, thereby outperforming existing state-of-the-art methods. These results highlight that while LLMs harnessed through prompt engineering can expedite application development processes, achieving a decent performance, they are not as effective as dedicated, task-specific LLMs.	[Trad, Fouad; Chehab, Ali] Amer Univ Beirut, Elect & Comp Engn, Beirut 11072020, Lebanon	American University of Beirut	Trad, F (corresponding author), Amer Univ Beirut, Elect & Comp Engn, Beirut 11072020, Lebanon.	fat10@mail.aub.edu; chehab@aub.edu.lb		Chehab, Ali/0000-0002-1939-2740	Maroun Semaan Faculty of Engineering and Architecture (MSFEA) at the American University of Beirut (AUB)	Maroun Semaan Faculty of Engineering and Architecture (MSFEA) at the American University of Beirut (AUB)	No Statement Available	Ahammad SKH, 2022, ADV ENG SOFTW, V173, DOI 10.1016/j.advengsoft.2022.103288; [Anonymous], 2023, Introducing Cloudflare's 2023 Phishing Threats Report; Arp D., 2022, P 31 USENIX SEC S BO; Asif A.U.Z., 2023, Lecture Notes in Computer Science, P481, DOI [10.1007/978-3-031-44274-2_36, DOI 10.1007/978-3-031-44274-2_36]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Benavides E, 2020, SMART INNOV SYST TEC, V152, P51, DOI 10.1007/978-981-13-9155-2_5; Bozkir AS, 2020, COMPUT SECUR, V95, DOI 10.1016/j.cose.2020.101855; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Catal C, 2022, KNOWL INF SYST, V64, P1457, DOI 10.1007/s10115-022-01672-x; Chhabra Sidharth., 2011, Proceedings of the 8th Annual Collaboration, Electronic messaging, Anti-Abuse and Spam Conference, P92, DOI DOI 10.1145/2030376.2030387; Dakle PP, 2023, Arxiv, DOI [arXiv:2211.14865, 10.48550/arXiv.2211.14865, DOI 10.48550/ARXIV.2211.14865]; Dhamija R., 2006, P SIGCHI C HUM FACT, P581; Do NQ, 2022, IEEE ACCESS, V10, P36429, DOI 10.1109/ACCESS.2022.3151903; Escalante J, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00425-2; Hageman K, 2021, SECRYPT 2021: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, P38, DOI 10.5220/0010516600380049; Hannousse Abdelhakim, 2021, Mendeley Data, V3, DOI 10.17632/C2GW7FY2J4.3; Hannousse A, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104347; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Hu ZQ, 2023, Arxiv, DOI arXiv:2304.01933; Huang YJ, 2019, IEEE TRUST, P112, DOI 10.1109/TrustCom/BigDataSE.2019.00024; Jiang JG, 2018, L N INST COMP SCI SO, V238, P438, DOI 10.1007/978-3-319-78813-5_22; Kirshner SN, 2024, J RETAIL CONSUM SERV, V76, DOI 10.1016/j.jretconser.2023.103580; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Kong AB, 2024, Arxiv, DOI [arXiv:2308.07702, 10.48550/arXiv.2308.07702, DOI 10.48550/ARXIV.2308.07702]; Le H, 2018, Arxiv, DOI arXiv:1802.03162; Liu ZL, 2024, LECT NOTES COMPUT SC, V14348, P464, DOI 10.1007/978-3-031-45673-2_46; Lv K, 2024, Arxiv, DOI arXiv:2306.09782; Mahajan R., 2018, International Journal of Computer Applications, V181, P45; McConnell B, 2023, LECT NOTES ARTIF INT, V14126, P145, DOI 10.1007/978-3-031-42508-0_14; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Moghimi M, 2016, EXPERT SYST APPL, V53, P231, DOI 10.1016/j.eswa.2016.01.028; Mohammad RM, 2014, IET INFORM SECUR, V8, P153, DOI 10.1049/iet-ifs.2013.0202; Mourtaji Y, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/8241104; Mustroph H., 2024, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, V1435, P347, DOI [10.1007/978-3-031-46846-9_19, DOI 10.1007/978-3-031-46846-9_19]; Nepal S., 2022, PREPRINT, DOI [10.21203/rs.3.rs-2043842/v2, DOI 10.21203/RS.3.RS-2043842/V2]; Ozcan A, 2023, NEURAL COMPUT APPL, V35, P4957, DOI 10.1007/s00521-021-06401-z; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rashid S.H., 2023, Int. J. Intell. Syst. Appl. Eng, V11, P451; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; da Silva CMR, 2020, COMPUT SECUR, V88, DOI 10.1016/j.cose.2019.101613; Sahingoz OK, 2019, EXPERT SYST APPL, V117, P345, DOI 10.1016/j.eswa.2018.09.029; Sahoo D, 2019, Arxiv, DOI arXiv:1701.07179; Sern L.J., 2020, P 2020 INT C COMM CO, P1; Shi YW, 2023, J BIOMED INFORM, V148, DOI 10.1016/j.jbi.2023.104533; Tajaddodianfar F, 2020, INT CONF ACOUST SPEE, P2857, DOI [10.1109/ICASSP40776.2020.9053670, 10.1109/icassp40776.2020.9053670]; Tan CCL, 2023, EXPERT SYST APPL, V220, DOI 10.1016/j.eswa.2023.119723; Tang LZ, 2021, MACH LEARN KNOW EXTR, V3, P672, DOI 10.3390/make3030034; Timiryasov I, 2023, Arxiv, DOI arXiv:2308.02019; Uppalapati P.J., 2023, ICST Trans. Scalable Inf. Syst, P10, DOI [10.4108/eetsis.vi.3300, DOI 10.4108/EETSIS.VI.3300]; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y., 2023, P ICASSP 2023 2023 I, P1, DOI [10.1109/ICASSP49357.2023.10095719, DOI 10.1109/ICASSP49357.2023.10095719]; Wang YB, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13137429; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei W, 2020, COMPUT NETW, V178, DOI 10.1016/j.comnet.2020.107275; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Woodbridge J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P22, DOI 10.1109/SPW.2018.00012; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Ye Xi, 2022, Advances in neural information processing systems, V35, P30378; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zouina M, 2017, HUM-CENT COMPUT INFO, V7, DOI 10.1186/s13673-017-0098-1	64	1	1	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2504-4990		MACH LEARN KNOW EXTR	Mach. Learn. Knowl. Extr.	MAR	2024	6	1					367	384		10.3390/make6010018	http://dx.doi.org/10.3390/make6010018			18	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering	MH2C1		gold			2024-07-03	WOS:001192658000001
J	Savage, N				Savage, Neil			Drug discovery companies are customizing ChatGPT: here's how	NATURE BIOTECHNOLOGY			English	News Item								Large language models are helping scientists to converse with artificial intelligence and even to generate potential drug targets.											0	27	28	3	17	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1087-0156	1546-1696		NAT BIOTECHNOL	Nat. Biotechnol.	MAY	2023	41	5					585	586		10.1038/s41587-023-01788-7	http://dx.doi.org/10.1038/s41587-023-01788-7		APR 2023	2	Biotechnology & Applied Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology	H2DV6	37095351				2024-07-03	WOS:000977408000001
J	Liao, HC; Shen, HM; Li, ZN; Wang, CY; Li, GF; Bie, YM; Xu, CZ				Liao, Haicheng; Shen, Huanming; Li, Zhenning; Wang, Chengyue; Li, Guofa; Bie, Yiming; Xu, Chengzhong			GPT-4 enhanced multimodal grounding for autonomous driving: Leveraging cross-modal attention with large language models	COMMUNICATIONS IN TRANSPORTATION RESEARCH			English	Article						Autonomous driving; Visual grounding; Cross-modal attention; Large language models; Human-machine interaction		In the field of autonomous vehicles (AVs), accurately discerning commander intent and executing linguistic commands within a visual context presents a significant challenge. This paper introduces a sophisticated encoderdecoder framework, developed to address visual grounding in AVs. Our Context-Aware Visual Grounding (CAVG) model is an advanced system that integrates five core encoders-Text, Emotion, Image, Context, and CrossModal-with a multimodal decoder. This integration enables the CAVG model to adeptly capture contextual semantics and to learn human emotional features, augmented by state-of-the-art Large Language Models (LLMs) including GPT-4. The architecture of CAVG is reinforced by the implementation of multi-head cross-modal attention mechanisms and a Region-Specific Dynamic (RSD) layer for attention modulation. This architectural design enables the model to efficiently process and interpret a range of cross-modal inputs, yielding a comprehensive understanding of the correlation between verbal commands and corresponding visual scenes. Empirical evaluations on the Talk2Car dataset, a real-world benchmark, demonstrate that CAVG establishes new standards in prediction accuracy and operational efficiency. Notably, the model exhibits exceptional performance even with limited training data, ranging from 50% to 75% of the full dataset. This feature highlights its effectiveness and potential for deployment in practical AV applications. Moreover, CAVG has shown remarkable robustness and adaptability in challenging scenarios, including long-text command interpretation, low-light conditions, ambiguous command contexts, inclement weather conditions, and densely populated urban environments.	[Liao, Haicheng; Li, Zhenning; Wang, Chengyue; Xu, Chengzhong] Univ Macau, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China; [Liao, Haicheng; Li, Zhenning; Xu, Chengzhong] Univ Macau, Dept Comp & Informat Sci, Macau 999078, Peoples R China; [Shen, Huanming] Univ Elect Sci & Technol China, Dept Informat & Software Engn, Chengdu 610000, Peoples R China; [Li, Zhenning; Wang, Chengyue] Univ Macau, Dept Civil & Environm Engn, Macau 999078, Peoples R China; [Li, Guofa] Chongqing Univ, Coll Mech & Vehicle Engn, Chongqing 400030, Peoples R China; [Bie, Yiming] Jilin Univ, Sch Transportat, Changchun 130000, Peoples R China	University of Macau; University of Macau; University of Electronic Science & Technology of China; University of Macau; Chongqing University; Jilin University	Li, ZN; Xu, CZ (corresponding author), Univ Macau, State Key Lab Internet Things Smart City, Macau 999078, Peoples R China.; Li, ZN; Xu, CZ (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau 999078, Peoples R China.; Li, ZN (corresponding author), Univ Macau, Dept Civil & Environm Engn, Macau 999078, Peoples R China.	zhenningli@um.edu.mo; czxu@um.edu.mo	XU, CHENGZHONG/AAX-1707-2020; Li, Zhenning/R-6862-2017	XU, CHENGZHONG/0000-0001-9480-0356; Liao, Haicheng/0000-0002-0207-5087; Li, Zhenning/0000-0002-0877-6829	Science and Technology Development Fund of Macau SAR [0021/2022/ITP, 0081/2022/A2, 0015/2019/AKP]; University of Macau [SKL- IoTSC (UM)-2024-2026/ORP/GA06/2023];  [SRG2023-00037-IOTSC];  [SKL-IoTSC (UM)-2021-2023/ORP/GA08/2022]	Science and Technology Development Fund of Macau SAR; University of Macau; ; 	This research is supported by the Science and Technology Development Fund of Macau SAR (Nos. 0021/2022/ITP, 0081/2022/A2, 0015/2019/AKP, SKL-IoTSC (UM)-2021-2023/ORP/GA08/2022, and SKL- IoTSC (UM)-2024-2026/ORP/GA06/2023), and University of Macau (No. SRG2023-00037-IOTSC). For any correspondence regarding this paper, please contact Dr. Zhenning Li (zhenningli@um.edu.mo) and Dr. Chengzhong Xu (czxu@um.edu.mo) for correspondence.	Hudson DA, 2018, Arxiv, DOI arXiv:1803.03067; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bhattacharyya A, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4944; Bonnefon JF, 2016, SCIENCE, V352, P1573, DOI 10.1126/science.aaf2654; Bugliarello E, 2021, T ASSOC COMPUT LING, V9, P978, DOI 10.1162/tacl_a_00408; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13; Chan HP, 2022, IEEE INT C INT ROBOT, P12464, DOI 10.1109/IROS47612.2022.9981515; Chen XP, 2018, Arxiv, DOI arXiv:1812.03426; Cheng B., 2021, arXiv, DOI DOI 10.48550/ARXIV.2107.06278; Cheng WH, 2023, Arxiv, DOI [arXiv:2305.15765, 10.48550/arXiv.2305.15765, DOI 10.48550/ARXIV.2305.15765]; Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808; Deruyttere T., EUROPEAN C COMPUTER, P3; Deruyttere T., 2019, arXiv; Deruyttere T, 2021, Arxiv, DOI [arXiv:2003.08717, 10.48550/arXiv.2003.08717, DOI 10.48550/ARXIV.2003.08717]; Deruyttere T, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104257; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding HH, 2023, IEEE T PATTERN ANAL, V45, P7900, DOI 10.1109/TPAMI.2022.3217852; Ding HH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16301, DOI 10.1109/ICCV48922.2021.01601; Dong Jiqian, 2022, Journal of Intelligent and Connected Vehicles, P235, DOI 10.1108/JICV-06-2022-0021; Dong JF, 2021, NEUROCOMPUTING, V440, P207, DOI 10.1016/j.neucom.2021.01.114; Dong JQ, 2023, TRANSPORT RES C-EMER, V156, DOI 10.1016/j.trc.2023.104358; Dong ZC, 2023, Arxiv, DOI [arXiv:2308.12537, 10.48550/arXiv.2308.12537, DOI 10.48550/ARXIV.2308.12537]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Everingham M., 2012, PATTERN ANAL STAT MO, V2007, P1, DOI DOI 10.1007/S11263-014-0733-5; Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Grujicic D, 2022, AAAI CONF ARTIF INTE, P715; Hang Dai, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P27, DOI 10.1007/978-3-030-66096-3_2; Hao SY, 2019, TRANSPORT RES C-EMER, V107, P287, DOI 10.1016/j.trc.2019.08.005; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493; Jain K, 2023, IEEE INT CONF ROBOT, P4113, DOI 10.1109/ICRA48891.2023.10160614; Jie Ou, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P51, DOI 10.1007/978-3-030-66096-3_5; Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180; Kheiri K, 2023, Arxiv, DOI [arXiv:2307.10234, DOI 10.48550/ARXIV.2307.10234]; Li GF, 2023, IEEE T INTELL VEHICL, V8, P2197, DOI 10.1109/TIV.2022.3227921; Li JN, 2022, Arxiv, DOI [arXiv:2201.12086, 10.48550/arXiv.2201.12086]; Li ZN, 2024, COMPUT-AIDED CIV INF, V39, P120, DOI 10.1111/mice.12989; Li ZN, 2023, ACCIDENT ANAL PREV, V185, DOI 10.1016/j.aap.2023.107019; Li ZN, 2022, PHYSICA A, V589, DOI 10.1016/j.physa.2021.126591; Liao HC, 2023, Arxiv, DOI [arXiv:2312.06371, 10.48550/arXiv.2312.06371, DOI 10.48550/ARXIV.2312.06371]; Liao Y., 2020, P IEEE CVF C COMP VI, P10880; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Loshchilov Ilya, 2016, arXiv, DOI DOI 10.48550/ARXIV.1608.03983; Mittal Vivek, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P62, DOI 10.1007/978-3-030-66096-3_6; Othman Kareem, 2021, AI Ethics, V1, P355, DOI 10.1007/s43681-021-00041-8; Qi D, 2020, Arxiv, DOI arXiv:2001.07966; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rufus Nivedita, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P39, DOI 10.1007/978-3-030-66096-3_4; Rufus N, 2021, IEEE INT C INT ROBOT, P8593, DOI 10.1109/IROS51168.2021.9636172; Shujie Luo, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P33, DOI 10.1007/978-3-030-66096-3_3; Su WJ, 2020, Arxiv, DOI arXiv:1908.08530; Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]; Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014; Vandenhende S, 2020, Arxiv, DOI [arXiv:2004.13822, 10.48550/arXiv.2004.13822, DOI 10.48550/ARXIV.2004.13822]; Vaswani A, 2017, ADV NEUR IN, V30; Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206; Wen KY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2188, DOI 10.1109/ICCV48922.2021.00221; Yang Kisu, 2019, arXiv, DOI DOI 10.48550/ARXIV.1906.11565; Yang L, 2022, PROC CVPR IEEE, P9489, DOI 10.1109/CVPR52688.2022.00928; Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142; Zhengyuan Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P387, DOI 10.1007/978-3-030-58568-6_23; Zhuang BH, 2018, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR.2018.00447	66	3	3	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2772-4247			COMMUN TRANSP RES	Commun. Transp. Res.	DEC	2024	4								100116	10.1016/j.commtr.2023.100116	http://dx.doi.org/10.1016/j.commtr.2023.100116		FEB 2024	19	Transportation; Transportation Science & Technology	Emerging Sources Citation Index (ESCI)	Transportation	NS6R3		Green Submitted, hybrid			2024-07-03	WOS:001202487400001
C	Sandoval, G; Pearce, H; Nys, T; Karri, R; Garg, S; Dolan-Gavitt, B			USENIX Association	Sandoval, Gustavo; Pearce, Hammond; Nys, Teo; Karri, Ramesh; Garg, Siddharth; Dolan-Gavitt, Brendan			Lost at C: A User Study on the Security Implications of Large Language Model Code Assistants	PROCEEDINGS OF THE 32ND USENIX SECURITY SYMPOSIUM			English	Proceedings Paper	32nd USENIX Security Symposium	AUG 09-11, 2023	Anaheim, CA	USENIX, Meta, Futurewei Technologies, Google, NSF, TikTok, Amazon, Ant Res, IBM, Technol Innovat Res, Cisco, Paloalto, ACM Queue, Elect Frontier Fdn			PERSPECTIVE	Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers' code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N=58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked 'shopping list' structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks.	[Sandoval, Gustavo; Pearce, Hammond; Nys, Teo; Karri, Ramesh; Garg, Siddharth; Dolan-Gavitt, Brendan] NYU, New York, NY 10012 USA	New York University	Sandoval, G (corresponding author), NYU, New York, NY 10012 USA.			Pearce, Hammond/0000-0002-3488-7004	NSF [2145482]	NSF(National Science Foundation (NSF))	We gratefully acknowledge the participants from our user study, as well as OpenAI who provided API access to their code-cushman-001 LLM for the duration. This research was supported in part by NSF Grant #2145482.	Acar Y, 2017, PROCEEDINGS OF THIRTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2017), P81; AI21, 2021, JUR 1 LANG MOD AI21; AI21, DISC US CAS AI21 STU; Aiken A., 2021, SYSTEM DETECTING SOF; Aizatsky M., 2016, Google Testing Blog; [Anonymous], 2019, Language Models are Unsupervised Multitask Learners, DOI DOI 10.18653/V1/W18-5019; Assaraf Ariel., 2015, This is what your developers are doing 75% of the time, and this is the cost you pay; Bandit, 2022, WELC BAND BAND DOC; Bavarian M., 2022, ARXIV220714255CS; Biderman S., 2022, ARXIV220107406CS; Black P. E., 2021, TECH REP; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, ARXIV210703374CS; Ciniselli M., 2022, ARXIV220406894CS; Dakhel A. M., 2022, ARXIV220615331CS; di Biase M, 2016, IEEE INT WORK C SO, P21, DOI 10.1109/SCAM.2016.30; Doderlein J.-B., 2022, ARXIV221014699CS; Ernst NA, 2022, IEEE SOFTWARE, V39, P106, DOI 10.1109/MS.2021.3133805; Fangohr H, 2004, LECT NOTES COMPUT SC, V3039, P1210; Feng Z., 2020, ARXIV200208155CS; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; G. Inc, 2021, CODEQL RES; Gage P., 1994, C Users Journal, V12, P23; Hung HMJ, 2005, BIOMETRICAL J, V47, P28, DOI 10.1002/bimj.200410084; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Ko AJ, 2015, EMPIR SOFTW ENG, V20, P110, DOI 10.1007/s10664-013-9279-3; Lieber O., 2021, TECH REP; Manès VJM, 2021, IEEE T SOFTWARE ENG, V47, P2312, DOI 10.1109/TSE.2019.2946563; MITRE, 2022, CWE COMM WEAKN EN; MITRE, 2022, 2022 cwe top 25 most dangerous software weaknesses; Nijkamp E., 2022, ARXIV220313474CS; OpenAI, EXA OPENAI API; OWASP, SOURC COD AN TOOLS; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pistoia M, 2007, IBM SYST J, V46, P265, DOI 10.1147/sj.462.0265; Polacek M., 2014, GCC UNDEFINED BEHAV; Salman I, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P666, DOI 10.1109/ICSE.2015.82; Sandoval G., 2022, LOST C DATA SECURITY; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Serebryany Konstantin, 2012, USENIX Annual Technical Conference, P309; Siddiq M. L., 2022, EMPIRICAL STUDY CODE; Tabachnyk M., 2022, ML-Enhanced Code Completion Improves Developer Productivity; Tahaei M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501957; Thomas Gavin, 2019, A proactive approach to more secure code; Topham C., 2022, PUBLICATION FSFFUNDE; Torres R., 2022, GITHUB COPILOT ADDS; Tuma K., 2020, P 23 ACM IEEE INT C, P332, DOI [DOI 10.1145/3365438.3410954, 10.1145/3365438.3410954]; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Wahle JP, 2021, ACM-IEEE J CONF DIG, P226, DOI 10.1109/JCDL52503.2021.00065; Walker E, 2011, J GEN INTERN MED, V26, P192, DOI 10.1007/s11606-010-1513-8; Zalewski Michal, 2020, American fuzzy lop; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	53	2	3	4	4	USENIX ASSOC	BERKELEY	SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710 USA			978-1-939133-37-3				2023							2205	2222						18	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV7HQ					2024-07-03	WOS:001066451502019
J	Newman-Toker, DE; Sharfstein, JM				Newman-Toker, David E.; Sharfstein, Joshua M.			The Role for Policy in AI-Assisted Medical Diagnosis	JAMA HEALTH FORUM			English	Article								This JAMA Forum discusses the promise and pitfalls of using large language models and artificial intelligence (AI) in the diagnosis of patients.	[Newman-Toker, David E.] Johns Hopkins Univ, Armstrong Inst, Ctr Diagnost Excellence, Sch Med, Baltimore, MD USA; [Sharfstein, Joshua M.] Johns Hopkins Univ, Bloomberg Sch Publ Hlth, 615 N Wolfe St, Baltimore, MD 21205 USA	Johns Hopkins University; Johns Hopkins University; Johns Hopkins Bloomberg School of Public Health	Sharfstein, JM (corresponding author), Johns Hopkins Univ, Bloomberg Sch Publ Hlth, 615 N Wolfe St, Baltimore, MD 21205 USA.	joshua.sharfstein@jhu.edu						Friedman CP, 2009, J AM MED INFORM ASSN, V16, P169, DOI 10.1197/jamia.M3092; Kerber KA, 2011, ACAD EMERG MED, V18, P619, DOI 10.1111/j.1553-2712.2011.01093.x; Kulkarni PA, 2023, JAMA-J AM MED ASSOC, V330, P317, DOI 10.1001/jama.2023.11440; Newman-Toker DE, 2024, BMJ QUAL SAF, V33, P109, DOI 10.1136/bmjqs-2021-014130; Patel RH, 2023, CANCERS, V15, DOI 10.3390/cancers15194694; Shortliffe E., 2014, Biomedical Informatics: Computer Applications in Health Care and Biomedicine, DOI [DOI 10.1007/0-387-36278-9, 10.1007/0-387-36278-9]; Tarnutzer AA, 2023, ANN NEUROL, V94, P295, DOI 10.1002/ana.26661	7	0	0	1	1	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2689-0186			JAMA-HEALTH FORUM	JAMA Health Forum	APR 18	2024	5	4							e241339	10.1001/jamahealthforum.2024.1339	http://dx.doi.org/10.1001/jamahealthforum.2024.1339			3	Health Care Sciences & Services; Health Policy & Services; Public, Environmental & Occupational Health	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	OE4I4	38635262	gold			2024-07-03	WOS:001205569300001
J	Tie, X; Shin, M; Pirasteh, A; Ibrahim, N; Huemann, Z; Castellino, SM; Kelly, KM; Garrett, J; Hu, JJ; Cho, SY; Bradshaw, TJ				Tie, Xin; Shin, Muheon; Pirasteh, Ali; Ibrahim, Nevein; Huemann, Zachary; Castellino, Sharon M.; Kelly, Kara M.; Garrett, John; Hu, Junjie; Cho, Steve Y.; Bradshaw, Tyler J.			Personalized Impression Generation for PET Reports Using Large Language Models	JOURNAL OF IMAGING INFORMATICS IN MEDICINE			English	Article						Natural Language Processing; Large Language Models; Informatics; Nuclear Medicine; Positron Emission Tomography; Radiology Report Summarization		Large language models (LLMs) have shown promise in accelerating radiology reporting by summarizing clinical findings into impressions. However, automatic impression generation for whole-body PET reports presents unique challenges and has received little attention. Our study aimed to evaluate whether LLMs can create clinically useful impressions for PET reporting. To this end, we fine-tuned twelve open-source language models on a corpus of 37,370 retrospective PET reports collected from our institution. All models were trained using the teacher-forcing algorithm, with the report findings and patient information as input and the original clinical impressions as reference. An extra input token encoded the reading physician's identity, allowing models to learn physician-specific reporting styles. To compare the performances of different models, we computed various automatic evaluation metrics and benchmarked them against physician preferences, ultimately selecting PEGASUS as the top LLM. To evaluate its clinical utility, three nuclear medicine physicians assessed the PEGASUS-generated impressions and original clinical impressions across 6 quality dimensions (3-point scales) and an overall utility score (5-point scale). Each physician reviewed 12 of their own reports and 12 reports from other physicians. When physicians assessed LLM impressions generated in their own style, 89% were considered clinically acceptable, with a mean utility score of 4.08/5. On average, physicians rated these personalized impressions as comparable in overall utility to the impressions dictated by other physicians (4.03, P = 0.41). In summary, our study demonstrated that personalized impressions generated by PEGASUS were clinically useful in most cases, highlighting its potential to expedite PET reporting by automatically drafting impressions.	[Tie, Xin; Shin, Muheon; Pirasteh, Ali; Ibrahim, Nevein; Huemann, Zachary; Garrett, John; Cho, Steve Y.; Bradshaw, Tyler J.] Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiol, Madison, WI 53706 USA; [Tie, Xin; Pirasteh, Ali; Garrett, John] Univ Wisconsin, Sch Med & Publ Hlth, Dept Med Phys, Madison, WI USA; [Castellino, Sharon M.] Emory Univ, Sch Med, Dept Pediat, Atlanta, GA USA; [Castellino, Sharon M.] Childrens Healthcare Atlanta, Aflac Canc & Blood Disorders Ctr, Atlanta, GA USA; [Kelly, Kara M.] Roswell Park Comprehens Canc Ctr, Dept Pediat Oncol, Buffalo, NY USA; [Kelly, Kara M.] SUNY Buffalo, Jacobs Sch Med & Biomed Sci, Dept Pediat, Buffalo, NY USA; [Hu, Junjie] Univ Wisconsin, Sch Med & Publ Hlth, Dept Biostat & Med Informat, Madison, WI USA; [Hu, Junjie] Univ Wisconsin, Sch Comp Data & Informat Sci, Dept Comp Sci, Madison, WI USA; [Cho, Steve Y.] Univ Wisconsin, Carbone Comprehens Canc Ctr, Madison, WI USA	University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; Emory University; Children's Healthcare of Atlanta (CHOA); Roswell Park Comprehensive Cancer Center; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison	Bradshaw, TJ (corresponding author), Univ Wisconsin, Sch Med & Publ Hlth, Dept Radiol, Madison, WI 53706 USA.	tbradshaw@wisc.edu		TIE, XIN/0000-0003-3062-5995	Imaging and Radiology Oncology Core Rhode Island	Imaging and Radiology Oncology Core Rhode Island	No Statement Available	Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Ben Abacha A, 2023, Arxiv, DOI arXiv:2305.17364; Castellino SM, 2022, NEW ENGL J MED, V387, P1649, DOI 10.1056/NEJMoa2206660; Chen C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2134; Delbrouck JB, 2022, Arxiv, DOI arXiv:2211.08584; Fabbri AR., 2021, Computational Linguistics, V9, P391, DOI [10.1162/tacl_a_00373, DOI 10.1162/TACL_A_00373]; Gao Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1347; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Hartung MP, 2020, RADIOGRAPHICS, V40, P1658, DOI 10.1148/rg.2020200020; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu J., 2022, arXiv; Hu J., 2021, arXiv; Huemann Z, 2023, Arxiv, DOI arXiv:2303.01258; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kayaalp Mehmet, 2014, AMIA Annu Symp Proc, V2014, P767; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lita Lucian Vlad, 2005, P C HUM LANG TECHN E, P740; Liu ZL, 2024, Arxiv, DOI [arXiv:2306.08666, DOI 10.48550/ARXIV.2306.08666, 10.48550/arXiv.2306.08666]; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lu Q., FINDINGS ASS COMPUTA, P5436, DOI DOI 10.18653/V1/2022.FINDINGS-EMNLP.398; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Ma C, 2024, Arxiv, DOI arXiv:2304.08448; Ng JP, 2015, Arxiv, DOI arXiv:1508.06034; Niederkohr RD, 2013, J NUCL MED, V54, P756, DOI 10.2967/jnumed.112.112177; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peyrard M, 2017, P WORKSH NEW FRONT S, P74, DOI DOI 10.18653/V1/W17-4510; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Rohan T., Stanford Alpaca: An Instruction-following LLaMA model; Scialom Thomas, 2019, arXiv; Smit A, 2020, Arxiv, DOI arXiv:2004.09167; Smith L, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-S2-S2; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Thompson B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P90; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vedantam R, 2015, Arxiv, DOI arXiv:1411.5726; Wang LL, 2023, Arxiv, DOI arXiv:2305.13693; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Yuan Hongyi, 2022, arXiv; Yuan WZ, 2021, Arxiv, DOI arXiv:2106.11520; Zhang JQ, 2020, Arxiv, DOI arXiv:1912.08777; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang Y., 2018, EMNLP 2018, P204; Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563; Zhong Ming, 2022, P 2022 C EMP METH NA, P2023	49	0	0	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	2948-2925	2948-2933		J IMAGING INFORM MED	J. Imaging Inform. Med.	APR	2024	37	2					471	488		10.1007/s10278-024-00985-3	http://dx.doi.org/10.1007/s10278-024-00985-3			18	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	OK6Z3	38308070	Green Published			2024-07-03	WOS:001207217100001
J	Hutson, M				Hutson, Matthew			Will superintelligent AI sneak up on us? New study offers reassurance	NATURE			English	News Item						Society; Technology; Mathematics and computing; Machine learning		Improvements in the performance of large language models such as ChatGPT are more predictable than they seem.											0	0	0	5	6	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JAN 11	2024	625	7994					223	223		10.1038/d41586-023-04094-z	http://dx.doi.org/10.1038/d41586-023-04094-z			1	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	FC5C5	38135753				2024-07-03	WOS:001143553300010
J	Cantini, R; Orsino, A; Talia, D				Cantini, Riccardo; Orsino, Alessio; Talia, Domenico			Xai-driven knowledge distillation of large language models for efficient deployment on low-resource devices	JOURNAL OF BIG DATA			English	Article						Knowledge distillation; eXplainable Artificial Intelligence; Low-resource devices; Edge AI; Large language models; Sustainable AI		Large Language Models (LLMs) are characterized by their inherent memory inefficiency and compute-intensive nature, making them impractical to run on low-resource devices and hindering their applicability in edge AI contexts. To address this issue, Knowledge Distillation approaches have been adopted to transfer knowledge from a complex model, referred to as the teacher, to a more compact, computationally efficient one, known as the student. The aim is to retain the performance of the original model while substantially reducing computational requirements. However, traditional knowledge distillation methods may struggle to effectively transfer crucial explainable knowledge from an LLM teacher to the student, potentially leading to explanation inconsistencies and decreased performance. This paper presents DiXtill, a method based on a novel approach to distilling knowledge from LLMs into lightweight neural architectures. The main idea is to leverage local explanations provided by an eXplainable Artificial Intelligence (XAI) method to guide the cross-architecture distillation of a teacher LLM into a self-explainable student, specifically a bi-directional LSTM network.Experimental results show that our XAI-driven distillation method allows the teacher explanations to be effectively transferred to the student, resulting in better agreement compared to classical distillation methods,thus enhancing the student interpretability. Furthermore, it enables the student to achieve comparable performance to the teacher LLM while also delivering a significantly higher compression ratio and speedup compared to other techniques such as post-training quantization and pruning, which paves the way for more efficient and sustainable edge AI applications	[Cantini, Riccardo; Orsino, Alessio; Talia, Domenico] Univ Calabria, Arcavacata Di Rende, Italy	University of Calabria	Cantini, R (corresponding author), Univ Calabria, Arcavacata Di Rende, Italy.	rcantini@dimes.unical.it	Cantini, Riccardo/GOE-4893-2022	Cantini, Riccardo/0000-0003-3053-6132	FAIR - Future Artificial Intelligence Research project [CUP H23C22000860006]	FAIR - Future Artificial Intelligence Research project	We acknowledge financial support from "FAIR - Future Artificial Intelligence Research" project - CUP H23C22000860006.	Alharbi R, 2021, IEEE INT CONF BIG DA, P705, DOI 10.1109/BigData52589.2021.9671988; Ali S, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101805; Ba J, 2014, Adv Neural Inf Process Syst, V27; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; bchapter Marozzo F, 2022, 2022 IEEE INT C DEP, P1; Belcastro L, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-021-00555-2; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cantini Riccardo, 2023, Discovery Science: 26th International Conference, DS 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14276), P126, DOI 10.1007/978-3-031-45275-8_9; Chang Y, 2023, ACM Transactions on Intelligent Systems and Technology; Chen Ting, 2020, ADV NEURAL INFORM PR, V33, P22243, DOI DOI 10.48550/ARXIV.2006.10029; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786; Rajani NF, 2019, Arxiv, DOI arXiv:1906.02361; Frantar E., 2023, P MACHINE LEARNING R, P10323; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; Gao Y, 2022, ACM Comput Surv; Ghorbani A, 2019, AAAI CONF ARTIF INTE, P3681; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286; Kim T, 2021, Arxiv, DOI arXiv:2105.08919; Kokhlikyan N, 2020, Arxiv, DOI [arXiv:2009.07896, DOI 10.48550/ARXIV.2009.07896]; Krishna S, 2022, Arxiv, DOI arXiv:2202.01602; Kumar P, 2022, NEURAL NETWORKS, V150, P392, DOI 10.1016/j.neunet.2022.03.017; Kwon W., 2022, P NIPS, P24101; Lin J, 2024, Arxiv, DOI arXiv:2306.00978; Liu YF, 2023, LECT NOTES COMPUT SC, V13845, P179, DOI 10.1007/978-3-031-26348-4_11; Lundberg SM, 2017, ADV NEUR IN, V30; Michel P, 2019, ADV NEUR IN, V32; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Saxena D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446374; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tang RP, 2019, Arxiv, DOI arXiv:1903.12136; Vaswani A, 2017, ADV NEUR IN, V30; Wang ZH, 2021, Arxiv, DOI arXiv:1910.04732; Yang Yi, 2020, FinBERT: A Pretrained Language Model for Financial Communications, DOI 10.48550/arXiv.2006.08097; Zeng Guohang, 2021, AS C MACH LEARN, P753; Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381; Zhu XY, 2023, Arxiv, DOI arXiv:2308.07633	41	0	0	6	6	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2196-1115		J BIG DATA-GER	J. Big Data	MAY 4	2024	11	1							63	10.1186/s40537-024-00928-3	http://dx.doi.org/10.1186/s40537-024-00928-3			17	Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PL2K0		gold			2024-07-03	WOS:001214165900002
C	Felkner, VK; Chang, HCH; Jang, E; May, J		Rogers, A; Boyd-Graber, J; Okazaki, N		Felkner, Virginia K.; Chang, Ho-Chun Herbert; Jang, Eugene; May, Jonathan			WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ plus Bias in Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Content Warning: This paper contains examples of homophobic and transphobic stereotypes. We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities.	[Felkner, Virginia K.; May, Jonathan] Univ Southern Calif, Inst Informat Sci, Los Angeles, CA 90007 USA; [Chang, Ho-Chun Herbert] Dartmouth Coll, Dept Quantitat Social Sci, Hanover, NH 03755 USA; [Jang, Eugene] Univ Southern Calif, Annenberg Sch Commun & Journalism, Los Angeles, CA USA	University of Southern California; Dartmouth College; University of Southern California	Chang, HCH (corresponding author), Dartmouth Coll, Dept Quantitat Social Sci, Hanover, NH 03755 USA.	felkner@isi.edu; herbert@dartmouth.edu; eugeneja@usc.edu; jonmay@isi.edu			National Science Foundation Graduate Research Fellowship [2236421]	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. 2236421. Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation. We also wish to thank Dr. Kristina Lerman and Dr. Fred Morstatter, who co-taught the Fairness in AI course where the authors met and this work was initially conceived. Finally, we would like to thank our three anonymous reviewers for their detailed and helpful suggestions.	[Anonymous], 2022, BLOOM: A 176bparameter open-access multilingual language model; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bird Steven, 2020, P 28 INT C COMPUTATI, P3504, DOI DOI 10.18653/V1/2020.COLING-MAIN.313; Cao YT, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1276; Costa-jussà MR, 2019, NAT MACH INTELL, V1, P495, DOI 10.1038/s42256-019-0105-5; Cryan J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376488; Czarnowska P, 2021, T ASSOC COMPUT LING, V9, P1249, DOI 10.1162/tacl_a_00425; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Devinney Hannah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2083, DOI 10.1145/3531146.3534627; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Felkner Virginia K., 2022, Towards winoqueer: Developing a benchmark for anti-queer bias in large language models; Ines Montani, 2023, explosion/spaCy: v3.5.0: New CLI commands, language updates, bug fixes and much more; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Névéol A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8521; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Smith E. M., 2022, P 2022 C EMPIRICAL M, P9180; Tomasev N, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P254, DOI 10.1145/3461702.3462540; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	23	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							9126	9140						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962500039
J	Nievas, M; Basu, A; Wang, YS; Singh, H				Nievas, Mauro; Basu, Aditya; Wang, Yanshan; Singh, Hrituraj			Distilling large language models for matching patients to clinical trials	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						large language models; distillation; clinical trial matching; GPT-3.5; GPT-4; LLAMA		Objective The objective of this study is to systematically examine the efficacy of both proprietary (GPT-3.5, GPT-4) and open-source large language models (LLMs) (LLAMA 7B, 13B, 70B) in the context of matching patients to clinical trials in healthcare.Materials and methods The study employs a multifaceted evaluation framework, incorporating extensive automated and human-centric assessments along with a detailed error analysis for each model, and assesses LLMs' capabilities in analyzing patient eligibility against clinical trial's inclusion and exclusion criteria. To improve the adaptability of open-source LLMs, a specialized synthetic dataset was created using GPT-4, facilitating effective fine-tuning under constrained data conditions.Results The findings indicate that open-source LLMs, when fine-tuned on this limited and synthetic dataset, achieve performance parity with their proprietary counterparts, such as GPT-3.5.Discussion This study highlights the recent success of LLMs in the high-stakes domain of healthcare, specifically in patient-trial matching. The research demonstrates the potential of open-source models to match the performance of proprietary models when fine-tuned appropriately, addressing challenges like cost, privacy, and reproducibility concerns associated with closed-source proprietary LLMs.Conclusion The study underscores the opportunity for open-source LLMs in patient-trial matching. To encourage further research and applications in this field, the annotated evaluation dataset and the fine-tuned LLM, Trial-LLAMA, are released for public use.	[Nievas, Mauro; Singh, Hrituraj] Triomics Inc, Tri Res, San Francisco, CA 94105 USA; [Basu, Aditya] Triomics Inc, Tri Res, Bengaluru 560102, Karnataka, India; [Wang, Yanshan] Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA; [Wang, Yanshan] Univ Pittsburgh, 6026 Forbes Tower, Pittsburgh, PA 15260 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Wang, YS (corresponding author), Univ Pittsburgh, 6026 Forbes Tower, Pittsburgh, PA 15260 USA.	yanshan.wang@pitt.edu						Achiam J., GPT-4 technical report; Agrawal M, 2022, Arxiv, DOI arXiv:2205.12689; Alazraki L, 2023, Arxiv, DOI arXiv:2310.06641; Association of Clinical Research Professionals, 2017, Patient Recruitment Shortcomings Laid at Feet of Poor Provider, Researcher Engagement; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bennette CS, 2016, JNCI-J NATL CANCER I, V108, DOI 10.1093/jnci/djv324; Berger ML, 2016, FUTURE ONCOL, V12, P1261, DOI 10.2217/fon-2015-0043; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A, 2023, J MACH LEARN RES, V24; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dong GT, 2024, Arxiv, DOI arXiv:2310.05492; Fang YL, 2022, J AM MED INFORM ASSN, V29, P1161, DOI 10.1093/jamia/ocac051; Fayter D, 2007, J CLIN EPIDEMIOL, V60, P990, DOI 10.1016/j.jclinepi.2006.12.013; Fleming SL., 2024, Proc AAAI Conf Artif Intell, V38, P22021; Gao YJ, 2023, Arxiv, DOI arXiv:2308.14321; Getz K., 2012, APPL CLIN TRIALS, V21, P24; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jin Q, 2024, Arxiv, DOI [arXiv:2307.15051, DOI 10.48550/ARXIV.2307.15051.PUBMED|CROSSREF]; Joseph G, 2009, CONTEMP CLIN TRIALS, V30, P552, DOI 10.1016/j.cct.2009.06.009; Kadam Rashmi Ashish, 2016, Perspect Clin Res, V7, P137, DOI 10.4103/2229-3485.184820; Koopman B, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P669, DOI 10.1145/2911451.2914672; Lamberti MJ, 2018, THER INNOV REGUL SCI, V52, P572, DOI 10.1177/2168479017751403; Miotto R, 2015, J AM MED INFORM ASSN, V22, pE141, DOI 10.1093/jamia/ocu050; Mishra S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3470; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Parker CG., 2005, Generating Medical Logic Modules for Clinical Trial Eligibility; Penberthy L, 2010, CONTEMP CLIN TRIALS, V31, P207, DOI 10.1016/j.cct.2010.03.005; Penberthy LT, 2012, J ONCOL PRACT, V8, P365, DOI 10.1200/JOP.2012.000646; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Pradeep R, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2325, DOI 10.1145/3477495.3531853; Rafailov R., 2024, Adv Neural Inf Process Syst., V36; Roberts K., 2021, P 30 TEXT RETRIEVAL; Roberts K., 2022, NIST Special Publication, V500-338; Rybinski M, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P4249, DOI 10.1145/3583780.3615174; Segura-Bedmar I, 2019, J AM MED INFORM ASSN, V26, P1181, DOI 10.1093/jamia/ocz139; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Thadani SR, 2009, J AM MED INFORM ASSN, V16, P869, DOI 10.1197/jamia.M3119; Tian SB, 2024, BRIEF BIOINFORM, V25, DOI 10.1093/bib/bbad493; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tunstall L, 2023, Arxiv, DOI arXiv:2310.16944; Van Veen D., 2023, Res Sq; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Weng CH, 2011, J AM MED INFORM ASSN, V18, pI116, DOI 10.1136/amiajnl-2011-000321; Yang JY, 2024, PATTERNS, V5, DOI 10.1016/j.patter.2023.100887; Yuan C, 2019, J AM MED INFORM ASSN, V26, P294, DOI 10.1093/jamia/ocy178; Zhang SY, 2024, Arxiv, DOI [arXiv:2308.10792, 10.48550/ARXIV.2308.10792, 10.48550/arXiv.2308.10792]; Zhou HJ, 2024, Arxiv, DOI arXiv:2311.05112	52	0	0	8	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 19	2024										10.1093/jamia/ocae073	http://dx.doi.org/10.1093/jamia/ocae073		APR 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	OD0N6	38641416	Green Submitted			2024-07-03	WOS:001205204700001
J	Baldassarre, A; Padovan, M				Baldassarre, Antonio; Padovan, Martina			Regulatory and Ethical Considerations on Artificial Intelligence for Occupational Medicine	MEDICINA DEL LAVORO			English	Article						Generative Artificial Intelligence; Large Language Models; Code of Ethics		Generative artificial intelligence and Large Language Models reshape labor dynamics and occupational health practices. As AI continues to evolve, there's a critical need to customize ethical considerations for its specific impacts on occupational health. Recognizing potential ethical challenges and dilemmas, stakeholders and physicians are urged to proactively adjust the practice of Occupational Medicine in response to shifting ethical paradigms. By advocating ensure responsible medical AI deployment, safeguarding the well-being of workers amidst the transformative effects of automation in healthcare.	[Baldassarre, Antonio] Univ Florence, Dept Expt & Clin Med, Florence, Italy; [Padovan, Martina] Tuscany North West Hlth Local Unit, Prevent Med, Lucca, Italy	University of Florence	Baldassarre, A (corresponding author), Univ Florence, Dept Expt & Clin Med, Florence, Italy.	antonio.baldassarre@unifi.it						Adel A, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00314-5; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2021, Ethics and governance of artificial intelligence for health: WHO guidance; [Anonymous], 2023, License: CC BY-NC-SA 3.0 IGO; [Anonymous], Council Directive 89/391/EEC of 12 June 1989 on the introduction of measures to encourage improvements in the safety and health of workers at work; [Anonymous], 2014, International code of ethics: For occupational health professionals, V3rd; [Anonymous], 2016, Med Lav, V107, P485; Armeni P, 2023, IntechOpen, DOI [10.5772/intechopen.112490, DOI 10.5772/INTECHOPEN.112490]; Baldassarre A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17144975; Berg J, 2021, World employment and social outlook: Trends 2021; Bhattad PB, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8041; Blobel B, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1244100; Boulos MNK, 2021, J PERS MED, V11, DOI 10.3390/jpm11080745; Chakraborty C, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1237704; Collatuzzo G, 2022, MED LAV, V113, DOI 10.23749/mdl.v113i1.12622; Collins L., 2017, Rewriting the rules for digital age, P97; Ethics and governance of artificial intelligence for health, 2024, GUIDANCE LARGE MULTI; EU-OSHA (European Agency for Safety and Health at Work), 2018, European Risk Observatory Report; EU-OSHA (European Agency for Safety and Health at Work), 2024, Discussion paper; EU-OSHA (European Agency for Safety and Health at Work), 2019, OSH and the Future of Work: benefits and risks of artificial intelligence tools; Friedland J, 2023, BUS HORIZONS, V66, P181, DOI 10.1016/j.bushor.2022.05.003; Gmyrek P, 2023, ILO Working Paper 96, DOI [10.54394/FHEM8239, DOI 10.54394/FHEM8239]; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Horizon, 2020, Mental Health promotion of cobot Workers in Industry 4.0, DOI [10.3030/847926, DOI 10.3030/847926]; INAIL, 2016, Il codice internazionale di etica per gli operatori di medicina del lavoro; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Lee P, 2023, NEW ENGL J MED, V388, P2400, DOI 10.1056/NEJMc2305286; Leso V, 2018, MED LAV, V109, P327, DOI 10.23749/mdl.v110i5.7282; McCarthy J, 2006, AI MAG, V27, P12; Menz BD, 2024, JAMA INTERN MED, V184, P92, DOI 10.1001/jamainternmed.2023.5947; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mokhtari F, 2023, GLOB CHALL, V7, DOI 10.1002/gch2.202300019; Murashov V, 2016, J OCCUP ENVIRON HYG, V13, DOI 10.1080/15459624.2015.1116700; Mutti A, 2023, MED LAV, V114, DOI 10.23749/mdl.v114i2.14451; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Padovan M, 2024, BIOENGINEERING-BASEL, V11, DOI 10.3390/bioengineering11010057; Paliga Mateusz, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20065111; Piwek L, 2016, PLOS MED, V13, DOI 10.1371/journal.pmed.1001953; Prince SA, 2019, INT J BEHAV NUTR PHY, V16, DOI 10.1186/s12966-019-0790-9; Shoja MM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40883; Sridi C, 2023, ANN OCCUP ENVIRON ME, V35, DOI 10.35371/aoem.2023.35.e42; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Topol Review, 2019, Final Report February 2019-A Call For Evidence. A Middleton invited to contribute; Wu DY, 2024, J ORGAN BEHAV, V45, P183, DOI 10.1002/job.2775; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	45	0	0	1	1	MATTIOLI 1885	FIDENZA	VIA DELLA LODESANA 649-SX, FIDENZA, 43046 PR, ITALY	0025-7818			MED LAV	Med. Lav.		2024	115	2							e2024013	10.23749/mdl.v115i2.15881	http://dx.doi.org/10.23749/mdl.v115i2.15881			8	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED)	Public, Environmental & Occupational Health	TI8B2					2024-07-03	WOS:001240715900003
J	Andrew, A				Andrew, Albert			Potential applications and implications of large language models in primary care	FAMILY MEDICINE AND COMMUNITY HEALTH			English	Editorial Material						Family Medicine; General Practice; Delivery of Health Care, Integrated; Health Services Research		The recent release of highly advanced generative artificial intelligence (AI) chatbots, including ChatGPT and Bard, which are powered by large language models (LLMs), has attracted growing mainstream interest over its diverse applications in clinical practice, including in health and healthcare. The potential applications of LLM-based programmes in the medical field range from assisting medical practitioners in improving their clinical decision-making and streamlining administrative paperwork to empowering patients to take charge of their own health. However, despite the broad range of benefits, the use of such AI tools also comes with several limitations and ethical concerns that warrant further consideration, encompassing issues related to privacy, data bias, and the accuracy and reliability of information generated by AI. The focus of prior research has primarily centred on the broad applications of LLMs in medicine. To the author's knowledge, this is, the first article that consolidates current and pertinent literature on LLMs to examine its potential in primary care. The objectives of this paper are not only to summarise the potential benefits, risks and challenges of using LLMs in primary care, but also to offer insights into considerations that primary care clinicians should take into account when deciding to adopt and integrate such technologies into their clinical practice.	[Andrew, Albert] Univ Auckland, Sch Med, Auckland, New Zealand	University of Auckland	Andrew, A (corresponding author), Univ Auckland, Sch Med, Auckland, New Zealand.	albertandrew@hotmail.co.nz	Andrew, Albert/JMP-5240-2023	Andrew, Albert/0000-0002-9451-4533				Aggarwal A, 2023, J MED INTERNET RES, V25, DOI 10.2196/40789; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amiri P, 2022, J AM MED INFORM ASSN, V29, P1000, DOI 10.1093/jamia/ocac014; [Anonymous], 1992, Profiles Healthc Mark, P40; Atallah SB, 2023, TECH COLOPROCTOL, V27, P609, DOI 10.1007/s10151-023-02837-8; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Birkeli Cecilie Normann, 2020, Tidsskr Nor Laegeforen, V140, DOI 10.4045/tidsskr.19.0597; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Choi HS, 2023, RADIAT ONCOL J, V41, P209, DOI 10.3857/roj.2023.00633; Clough RAJ, 2024, BJGP OPEN, V8, DOI 10.3399/BJGPO.2023.0116; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Del Giglio A, 2023, REV ASSOC MED BRAS, V69, DOI 10.1590/1806-9282.20230560; Divo MJ, 2014, EUR RESPIR J, V44, P1055, DOI 10.1183/09031936.00059814; Egli A, 2023, CLIN INFECT DIS, V77, P1322, DOI 10.1093/cid/ciad407; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Havik R., 2019, Int j Internet Sci, V11551, DOI [10.1007/978-3-030-17705-8, DOI 10.1007/978-3-030-17705-8]; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Huang J., 2022, arXiv; Isaza-Restrepo A, 2018, BMC MED EDUC, V18, DOI 10.1186/s12909-018-1395-8; Kazmi Zainab, 2013, Inform Prim Care, V21, P30, DOI 10.14236/jhi.v21i1.37; Lee Louise I T, 2019, BJR Open, V1, P20190037, DOI 10.1259/bjro.20190037; McKee M, 2023, INT J HEALTH POLICY, V12, DOI 10.34172/ijhpm.2022.7261; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]; Moodie C., 2023, Australian Medical Association calls for national regulations around AI in health care; Nashwan AJ, 2023, J EMERG NURS, V49, P651, DOI 10.1016/j.jen.2023.05.002; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pettit RW, 2021, EMERG TOP LIFE SCI, V5, P729, DOI 10.1042/ETLS20210246; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Schwartz IS, 2024, CLIN INFECT DIS, V78, P860, DOI 10.1093/cid/ciad633; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sinsky C, 2016, ANN INTERN MED, V165, P753, DOI 10.7326/M16-0961; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; Tyson A., 2023, 60% of Americans Would Be Uncomfortable With Provider Relying on AI in Their Own Health Care; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wilson L, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/35882; Zhang A, 2022, NAT BIOMED ENG, V6, P1330, DOI 10.1038/s41551-022-00898-y	40	0	0	9	9	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	2305-6983	2009-8774		FAM MED COMMUNITY HE	Fam. Med. Community Health	JAN	2024	12	SUPPL_1		1					e002602	10.1136/fmch-2023-002602	http://dx.doi.org/10.1136/fmch-2023-002602			6	Primary Health Care	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	GT5J8	38290759	gold, Green Published			2024-07-03	WOS:001154932700001
C	Falissard, L; Affeldt, S; Nadif, M		Nicosia, G; Ojha, V; LaMalfa, E; LaMalfa, G; Pardalos, PM; Umeton, R		Falissard, Louis; Affeldt, Severine; Nadif, Mohamed			Attentive Perturbation: Extending Prefix Tuning to Large Language Models Inner Representations	MACHINE LEARNING, OPTIMIZATION, AND DATA SCIENCE, LOD 2023, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	9th Annual Conference on Machine Learning, Optimization and Data science (LOD)	SEP 22-26, 2023	Grasmere, ENGLAND			Large language models; Parameter efficient fine-tuning; Adapters; Prefix-tuning; Natural language processing; Natural Language Understanding		From adapters to prefix-tuning, parameter efficient finetuning (PEFT) has been a well investigated research field in the past few years, which has led to an entire family of alternative approaches for large language model fine-tuning. All these methods rely on the fundamental idea of introducing additional learnable parameters to the model, while freezing all pre-trained representations during training. This finetuning process is generally done through refitting all model parameters to the new, supervised objective function. This process, however, still requires a considerable amount of computing power, which might not be readily available to everyone. In addition, even with the use of transfer learning, this method requires substantial amounts of data. In this article, we propose a novel and fairly straightforward extension of the prefix-tuning approach to modify both the model's attention weight and its internal representations. Our proposal introduces a "token-tuning" method relying on soft lookup based embeddings derived using attention mechanisms. We call this efficient extension "attentive perturbation", and empirically show that it outperforms other PEFT methods on most natural language understanding tasks in the few-shot learning setting.	[Falissard, Louis; Affeldt, Severine; Nadif, Mohamed] Univ Paris Cite, Ctr Borelli, UMR 9010, F-75006 Paris, France	Universite Paris Cite	Falissard, L (corresponding author), Univ Paris Cite, Ctr Borelli, UMR 9010, F-75006 Paris, France.	louis.falissard@u-paris.fr; severine.affeldt@u-paris.fr; mohamed.nadif@u-paris.fr			French National Research Agency (ANR) [ANR-19-CE23-0002]; Agence Nationale de la Recherche (ANR) [ANR-19-CE23-0002] Funding Source: Agence Nationale de la Recherche (ANR)	French National Research Agency (ANR)(Agence Nationale de la Recherche (ANR)Norwegian Agency for Development Cooperation - NORAD); Agence Nationale de la Recherche (ANR)(Agence Nationale de la Recherche (ANR))	This work was supported by a grant overseen by the French National Research Agency (ANR) (ANR-19-CE23-0002). It also received the labelling of Cap Digital and EuroBiomed competitiveness clusters.	Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Mao YN, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6253; Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Rebuffi SA, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]	13	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-53968-8; 978-3-031-53969-5	LECT NOTES COMPUT SC			2024	14505						488	496		10.1007/978-3-031-53969-5_36	http://dx.doi.org/10.1007/978-3-031-53969-5_36			9	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9PL		Green Submitted			2024-07-03	WOS:001217088300036
J	Frank, MC				Frank, Michael C.			Openly accessible LLMs can help us to understand human cognition	NATURE HUMAN BEHAVIOUR			English	Editorial Material; Early Access								Large language models can be construed as 'cognitive models', scientific artefacts that help us to understand the human mind. If made openly accessible, they may provide a valuable model system for studying the emergence of language, reasoning and other uniquely human behaviours.	[Frank, Michael C.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA	Stanford University	Frank, MC (corresponding author), Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.	mcfrank@stanford.edu		Frank, Michael/0000-0002-7551-4378	The author thanks N. D. Goodman and R. Saxe for helpful discussion.	The author thanks N. D. Goodman and R. Saxe for helpful discussion.	The author thanks N. D. Goodman and R. Saxe for helpful discussion.	Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Christiansen MH, 1999, COGNITIVE SCI, V23, P157, DOI 10.1016/S0364-0213(99)00003-8; Gandhi K, 2023, Arxiv, DOI [arXiv:2306.15448, 10.48550/arXiv.2306.15448]; Geiger A, 2024, Arxiv, DOI arXiv:2303.02536; Goodman ND, 2015, PSYCHOL SCI, V26, P539, DOI 10.1177/0956797614559544; Jones M, 2011, BEHAV BRAIN SCI, V34, P169, DOI 10.1017/S0140525X10003134; Ma W. J., 2023, Bayesian models of perception and action: an introduction; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Shiffrin R, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2300963120; Warstadt A, 2020, Arxiv, DOI arXiv:2007.06761	10	2	2	7	7	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2023 NOV 20	2023										10.1038/s41562-023-01732-4	http://dx.doi.org/10.1038/s41562-023-01732-4		NOV 2023	3	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	Y8GD1	37985910				2024-07-03	WOS:001107579600010
J	Li, B; Xu, TA; Li, XY; Cui, YD; Bian, XP; Teng, SY; Ma, SJ; Fan, LL; Tian, YL; Wang, FY				Li, Bai; Xu, Tian'ao; Li, Xinyuan; Cui, Yaodong; Bian, Xuepeng; Teng, Siyu; Ma, Siji; Fan, Lili; Tian, Yonglin; Wang, Fei-Yue			Integrating Large Language Models and Metaverse in Autonomous Racing: An Education-Oriented Perspective	IEEE TRANSACTIONS ON INTELLIGENT VEHICLES			English	Article						Metaverse; Training; Task analysis; Autonomous vehicles; Automobiles; Solid modeling; Medical services; Autonomous racing; intelligent vehicles for education (IV4E); metaverse; large language models (LLMs)	INTELLIGENCE	This letter is the third report from a series of IEEE TIV's decentralized and hybrid workshops (DHWs) on intelligent vehicles for education (IV4E). Autonomous racing serves as a vital platform for nurturing engineering talents among university students, contributing to the development of skills essential for the intelligent vehicle industry. This letter investigates how recent emerging techniques, such as large language models (LLMs) and the Metaverse, can contribute to organizing IV4E-oriented autonomous racing events. Among these DHWs, scholars from diverse fields have collectively explored the integration of LLMs and the Metaverse into autonomous racing for educational purposes. The discussions emphasize the role of Metaverse in creating dynamic and immersive training virtual reality platforms and the role of LLMs in enhancing race commentary and the spectator experience. Within this context, the Metaverse introduces complex scenarios to the racetrack, maintaining suspense about the winning team until a race's final moment. This dynamic feature excites the race and motivates the participating teams to intensify their competition efforts. LLMs facilitate personalized commentary, inspiring spectators to become future participants in these races. Our DHWs highlighted a future in which technology, autonomy, and education intersect, fostering inclusive, educational, and engaging autonomous racing events.	[Li, Bai; Li, Xinyuan] Hunan Univ, Coll Mech & Vehicle Engn, Changsha 410082, Peoples R China; [Xu, Tian'ao] Swiss Fed Inst Technol, Dept Mech & Proc Engn, CH-8092 Zurich, Switzerland; [Cui, Yaodong] Univ Waterloo, Dept Mech & Mechatron Engn, MVS Lab, Waterloo, ON N2L3G1, Canada; [Bian, Xuepeng] Tencent Com Inc, Tencent Automat Dr Lab, Beijing 100193, Peoples R China; [Teng, Siyu] Hong Kong Baptist Univ, Dept Comp Sci, Fac Sci, Hong Kong, Peoples R China; [Ma, Siji] Macau Univ Sci & Technol, Fac Innovat Engn, Macau 999078, Peoples R China; [Fan, Lili] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China; [Tian, Yonglin; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management& Control ofComplex Sys, Beijing 100190, Peoples R China	Hunan University; Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Waterloo; Hong Kong Baptist University; Macau University of Science & Technology; Beijing Institute of Technology; Chinese Academy of Sciences; Institute of Automation, CAS	Cui, YD (corresponding author), Univ Waterloo, Dept Mech & Mechatron Engn, MVS Lab, Waterloo, ON N2L3G1, Canada.; Wang, FY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management& Control ofComplex Sys, Beijing 100190, Peoples R China.	libai@zju.edu.cn; tianaxu@student.ethz.ch; lixinyuan99@hnu.edu.cn; yaodong.cui@uwaterloo.ca; waldronbian@tencent.com; siyuteng22@gmail.com; masijiguge123@gmail.com; lilifan@bit.edu.cn; yonglin.tian@ia.ac.cn; feiyue@ieee.org	Li, Bai/P-1446-2014	Li, Bai/0000-0002-8966-8992; Tian, Yonglin/0000-0003-1911-5791; Cui, Yaodong/0000-0003-1132-9154	National Natural Science Foundation of China [62103139]; Lotus Youth Talent Program of Hunan Province, China [2023RC3115]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Lotus Youth Talent Program of Hunan Province, China	This work was supported in part by the National Natural Science Foundation of China under Grant 62103139 and in part by the Lotus Youth Talent Program of Hunan Province, China under Grant 2023RC3115.	Bautista-Montesano R, 2020, 2020 IEEE EUROPEAN TECHNOLOGY AND ENGINEERING MANAGEMENT SUMMIT (E-TEMS 2020), DOI 10.1109/e-tems46250.2020.9111823; Bracke S, 2023, ROUTL RES SPORT CULT, P241, DOI 10.4324/9781003302650-22; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chengoden R, 2023, IEEE ACCESS, V11, P12764, DOI 10.1109/ACCESS.2023.3241628; Cui Can, 2024, 2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW), P958, DOI 10.1109/WACVW60836.2024.00106; Cui YD, 2024, IEEE T INTELL VEHICL, V9, P1450, DOI 10.1109/TIV.2023.3327715; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Huynh-The T, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105581; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Karaman S, 2017, INTEGR STEM EDU CONF, P195, DOI 10.1109/ISECon.2017.7910242; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kocmi T, 2023, Arxiv, DOI arXiv:2302.14520; Li B, 2023, IEEE T INTELL VEHICL, V8, P3974, DOI 10.1109/TIV.2023.3298914; Li B, 2023, IEEE T INTELL VEHICL, V8, P3217, DOI 10.1109/TIV.2023.3269207; Liu Y., 2023, MetaRadiology, V1; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175; Ritterbusch GD, 2023, IEEE ACCESS, V11, P12368, DOI 10.1109/ACCESS.2023.3241809; Sha H, 2023, Arxiv, DOI arXiv:2310.03026; SparkFun AVC, 2023, ABOUT US; Subramaniyaswamy V., 2018, International Journal of Advanced Intelligence Paradigms, V10, P103; Tanahashi K, 2023, Arxiv, DOI arXiv:2312.06351; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tian YL, 2023, IEEE T INTELL VEHICL, V8, P4198, DOI 10.1109/TIV.2023.3307012; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang H, 2023, IEEE INTERNET THINGS, V10, P14671, DOI 10.1109/JIOT.2023.3278329; Wang JG, 2023, IEEE T INTELL VEHICL, V8, P2832, DOI 10.1109/TIV.2023.3249287; Wang SY, 2023, IEEE T INTELL VEHICL, V8, P4706, DOI 10.1109/TIV.2023.3325300; Wang X, 2022, IEEE INTELL SYST, V37, P97, DOI 10.1109/MIS.2022.3196592; Wang YT, 2023, IEEE COMMUN SURV TUT, V25, P319, DOI 10.1109/COMST.2022.3202047; Wurman PR, 2022, NATURE, V602, P223, DOI 10.1038/s41586-021-04357-7; Yaqoob I, 2023, INTERNET THINGS-NETH, V23, DOI 10.1016/j.iot.2023.100884; Zhao C, 2023, IEEE T SYST MAN CY-S, V53, P2062, DOI 10.1109/TSMC.2022.3228914	34	1	1	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2379-8858	2379-8904		IEEE T INTELL VEHICL	IEEE T. Intell. Veh.	JAN	2024	9	1					59	64		10.1109/TIV.2024.3349466	http://dx.doi.org/10.1109/TIV.2024.3349466			6	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Transportation Science & Technology	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Transportation	JL4V0					2024-07-03	WOS:001173317800014
J	Yan, LX; Sha, LL; Zhao, LX; Li, YH; Martinez-Maldonado, R; Chen, GL; Li, XY; Jin, YQ; Gasevic, D				Yan, Lixiang; Sha, Lele; Zhao, Linxuan; Li, Yuheng; Martinez-Maldonado, Roberto; Chen, Guanliang; Li, Xinyu; Jin, Yueqiao; Gasevic, Dragan			Practical and ethical challenges of large language models in education: A systematic scoping review	BRITISH JOURNAL OF EDUCATIONAL TECHNOLOGY			English	Review						artificial intelligence; BERT; ChatGPT; education; GPT-3; large language models; pre-trained language models; systematic scoping review	GENERATION; PRINCIPLES	Educational technology innovations leveraging large language models (LLMs) have shown the potential to automate the laborious process of generating and analysing textual content. While various innovations have been developed to automate a range of educational tasks (eg, question generation, feedback provision, and essay grading), there are concerns regarding the practicality and ethicality of these innovations. Such concerns may hinder future research and the adoption of LLMs-based innovations in authentic educational contexts. To address this, we conducted a systematic scoping review of 118 peer-reviewed papers published since 2017 to pinpoint the current state of research on using LLMs to automate and support educational tasks. The findings revealed 53 use cases for LLMs in automating education tasks, categorised into nine main categories: profiling/labelling, detection, grading, teaching support, prediction, knowledge representation, feedback, content generation, and recommendation. Additionally, we also identified several practical and ethical challenges, including low technological readiness, lack of replicability and transparency and insufficient privacy and beneficence considerations. The findings were summarised into three recommendations for future studies, including updating existing innovations with state-of-the-art models (eg, GPT-3/4), embracing the initiative of open-sourcing models/systems, and adopting a human-centred approach throughout the developmental process. As the intersection of AI and education is continuously evolving, the findings of this study can serve as an essential reference point for researchers, allowing them to leverage the strengths, learn from the limitations, and uncover potential research opportunities enabled by ChatGPT and other generative AI models.	[Yan, Lixiang; Sha, Lele; Zhao, Linxuan; Li, Yuheng; Martinez-Maldonado, Roberto; Chen, Guanliang; Li, Xinyu; Jin, Yueqiao; Gasevic, Dragan] Monash Univ, Fac Informat Technol, Ctr Learning Analyt Monash, Clayton, Vic, Australia; [Yan, Lixiang] Monash Univ, Fac Informat Technol, Ctr Learning Analyt Monash, 20 Exhibit Walk, Clayton, Vic 3800, Australia	Monash University; Monash University	Yan, LX (corresponding author), Monash Univ, Fac Informat Technol, Ctr Learning Analyt Monash, 20 Exhibit Walk, Clayton, Vic 3800, Australia.	lixiang.yan@monash.edu	Martinez-Maldonado, Roberto/HKO-8635-2023; Yan, Lixiang/GQH-3481-2022	Yan, Lixiang/0000-0003-3818-045X; Li, Yuheng/0000-0002-5971-8469; Zhao, Linxuan/0000-0001-5564-0185; Chen, Guanliang/0000-0002-8236-3133	Australian Research Council [DP210100060, DP220101209]; Jacobs Foundation; Defense Advanced Research Project Agency [HR0011-22-2-0047]	Australian Research Council(Australian Research Council); Jacobs Foundation; Defense Advanced Research Project Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	Australian Research Council, Grant/Award Number: DP210100060 and DP220101209; Jacobs Foundation; Defense Advanced Research Project Agency, Grant/Award Number: HR0011-22-2-0047	Adams C, 2021, LECT NOTES ARTIF INT, V12749, P24, DOI 10.1007/978-3-030-78270-2_4; Ahmed A., 2022, 2022 INT C HUMAN COM, P1; Angelone AM, 2022, LECT NOTE NETW SYST, V326, P12, DOI 10.1007/978-3-030-86618-1_2; [Anonymous], 2016, SoLAR, DOI 10.18608/jla.2016.31.2; Bang Y, 2023, A multitask, multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and interactivity; Becker H.J., 2000, Educational Policy Analysis Archives, V8, P1, DOI [DOI 10.14507/EPAA.V8N51.2000, DOI 10.12307/EPAA.V8N51.2000]; Beseiso M, 2021, J COMPUT HIGH EDUC, V33, P727, DOI 10.1007/s12528-021-09283-1; Boeren E, 2019, INT REV EDUC, V65, P277, DOI 10.1007/s11159-019-09772-7; Brown Hannah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2280, DOI 10.1145/3531146.3534642; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bulut O, 2022, INT J ASSESS TOOLS E, V9, P72, DOI 10.21449/ijate.1124382; Caines A., 2023, AIED WORKSH; Carpenter D, 2020, LECT NOTES ARTIF INT, V12163, P55, DOI 10.1007/978-3-030-52237-7_5; Carroll A, 2022, SOC PSYCHOL EDUC, V25, P441, DOI 10.1007/s11218-022-09686-7; Cavalcanti A. P., 2021, Comput. Educ, V2, DOI DOI 10.1016/J.CAEAI.2021.100027; Chaudhry MA, 2022, LECT NOTES COMPUT SC, V13356, P195, DOI 10.1007/978-3-031-11647-6_33; Chechitelli A., 2023, WRITING DETECTION UP; Condor A., 2021, P 14 INT C ED DAT MI; Defence Science and Technology Group, 2021, TECHNOLOGY READINESS; Devlin J., 2018, BERT PRE TRAINING DE; Doewes A., 2021, On the limitations of human-computer agreement in automated essay scoring; DOYLE W, 1978, INTERCHANGE, V8, P1; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Ertmer PA, 1999, ETR&D-EDUC TECH RES, V47, P47, DOI 10.1007/BF02299597; Fonseca S. C., 2020, AUTOMATIC SUBJECT BA; Gasevic D, 2022, COMPUT HUM BEHAV, V134, DOI 10.1016/j.chb.2022.107304; Gasevic D, 2016, INTERNET HIGH EDUC, V28, P68, DOI 10.1016/j.iheduc.2015.10.002; Geller SA, 2021, IEEE T LEARN TECHNOL, V14, P665, DOI 10.1109/TLT.2021.3123266; Ghosh D, 2020, INNOVATIVE USE OF NLP FOR BUILDING EDUCATIONAL APPLICATIONS, P145; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Holmes W., 2022, ETHICS ARTIFICIAL IN; Jayaraman JD, 2022, LECT NOTE NETW SYST, V349, P133, DOI 10.1007/978-3-030-90677-1_13; Jialin Shang, 2022, 2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD), P1053, DOI 10.1109/CSCWD54268.2022.9776230; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khosravi H., 2022, Comput. Educ. Artif. Intell., V3, DOI [DOI 10.1016/J.CAEAI.2022.100074, 10.1016/j.caeai, DOI 10.1016/J.CAEAI]; Kumar N., 2022, 2022 3 INT C EM TECH, P1; Kurdi G, 2020, INT J ARTIF INTELL E, V30, P121, DOI 10.1007/s40593-019-00186-y; Leiker D., 2023, AIED WORKSH; Li CL, 2021, INT J ARTIF INTELL E, V31, P186, DOI 10.1007/s40593-020-00235-x; Li Y., 2023, Comput. Educ.., V4, DOI [DOI 10.1016/J.CAEAI.2023.100140, 10.1016/j.caeai.2023.100140]; Liang W., 2023, GPT DETECTORS ARE BI; Liu S, 2022, COMPUT EDUC, V181, DOI 10.1016/j.compedu.2022.104461; Liu Z., 2023, CONTEXT MATTERS STRA; Ma Q., 2023, AIED WORKSH; Maheen F, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1010; Maxwell SE, 2015, AM PSYCHOL, V70, P487, DOI 10.1037/a0039400; Merine R, 2022, IEEE INT CONF HEALT, P567, DOI 10.1109/ICHI54592.2022.00113; Min B., 2021, RECENT ADV NATURAL L; Mittelstadt B, 2019, NAT MACH INTELL, V1, P501, DOI 10.1038/s42256-019-0114-4; Moore S, 2022, LECT NOTES COMPUT SC, V13450, P243, DOI 10.1007/978-3-031-16290-9_18; Munn Zachary, 2018, BMC Med Res Methodol, V18, P143, DOI 10.1186/s12874-018-0611-x; Nguyen T. T., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100036; Nye B., 2023, AIED WORKSH; Oleny A., 2023, AIED WORKSHOPS; OpenAI, 2023, Introducing ChatGPT; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Pardo A, 2014, BRIT J EDUC TECHNOL, V45, P438, DOI 10.1111/bjet.12152; Pugh S L., 2021, Say What? Automatic Modeling of Collaborative Problem Solving Skills from Student Speech in the Wild; Ramesh D, 2022, ARTIF INTELL REV, V55, P2495, DOI 10.1007/s10462-021-10068-2; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sallam M, 2023, medRxiv; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sawatzki Jorg, 2022, Artificial Intelligence in Education: Emerging Technologies, Models and Applications: Proceedings of 2021 2nd International Conference on Artificial Intelligence in Education Technology. Lecture Notes on Data Engineering and Communications Technologies (104), P65, DOI 10.1007/978-981-16-7527-0_5; Schneider J, 2023, INT J ARTIF INTELL E, V33, P88, DOI 10.1007/s40593-022-00289-z; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Selwyn N, 2019, J LEARN ANAL, V6, P11, DOI 10.18608/jla.2019.63.3; Sha L., 2022, P 29 INT C COMP LING, P1275; Sha LL, 2023, IEEE T LEARN TECHNOL, V16, P339, DOI 10.1109/TLT.2022.3227013; Sha LL, 2022, IEEE T LEARN TECHNOL, V15, P481, DOI 10.1109/TLT.2022.3196278; Sha LL, 2021, LECT NOTES ARTIF INT, V12748, P381, DOI 10.1007/978-3-030-78292-4_31; Sharma A, 2021, LECT NOTES ARTIF INT, V12979, P365, DOI 10.1007/978-3-030-86517-7_23; Song WJ, 2022, INT INTERACT, V48, P204, DOI 10.1080/03050629.2021.1977638; Sridhar P., 2023, AIED WORKSH; Su Y, 2020, 2020 3RD INTERNATIONAL CONFERENCE ON BIG DATA AND EDUCATION (ICBDE 2020), P30, DOI 10.1145/3396452.3396458; Trong-Loc Truong, 2020, 2020 7th NAFOSTED Conference on Information and Computer Science (NICS), P362, DOI 10.1109/NICS51282.2020.9335912; Tsai YS, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P230, DOI 10.1145/3375462.3375536; Tsai YS, 2017, SEVENTH INTERNATIONAL LEARNING ANALYTICS & KNOWLEDGE CONFERENCE (LAK'17), P233, DOI 10.1145/3027385.3027400; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang DL, 2020, VEH TECHNOL CONFE, DOI 10.1109/VTC2020-Fall49728.2020.9348560; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Wu J., 2022, WIRELESS COMMUN MOBI, V2022, P1; Wu X., 2023, MATCHING EXEMPLAR NE; Yan LX, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P13, DOI 10.1145/3506860.3506862; Yang S.J.H., 2021, Computers and Education: Artificial Intelligence, V2, P1, DOI [DOI 10.1016/J.CAEAI.2021.100008, 10.1016/j.caeai.2021.100008]; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zeng Z., 2023, P AAAI C ARTIFICIAL, V37, P14602, DOI [10.1609/aaai.v37i12.26707, DOI 10.1609/AAAI.V37I12.26707]; Zheng LQ, 2023, BRIT J EDUC TECHNOL, V54, P686, DOI 10.1111/bjet.13283; Zheng LQ, 2022, BRIT J EDUC TECHNOL, V53, P130, DOI 10.1111/bjet.13156	89	19	19	156	343	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1013	1467-8535		BRIT J EDUC TECHNOL	Br. J. Educ. Technol.	JAN	2024	55	1								10.1111/bjet.13370	http://dx.doi.org/10.1111/bjet.13370		AUG 2023	23	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	KH9L4		Green Submitted, hybrid			2024-07-03	WOS:001043538000001
J	Lai, ZF; Wu, TJ; Fei, XH; Ling, Q				Lai, Zefeng; Wu, Tangjie; Fei, Xihong; Ling, Qiang			BERT4ST:: Fine-tuning pre-trained large language model for wind power forecasting	ENERGY CONVERSION AND MANAGEMENT			English	Article						Wind power forecasting; Spatial-temporal forecasting; Large language model	NEURAL-NETWORK; SPEED	Accurate forecasting of wind power generation is essential for ensuring power safety, scheduling various energy sources, and improving energy utilization. However, the elusive nature of wind, influenced by various meteorological and geographical factors, greatly complicates the wind power forecasting task. To improve the forecasting accuracy of wind power (WP), we propose a BERT -based model for spatio-temporal forecasting (BERT4ST), which is the first approach to fine-tune a large language model for the spatio-temporal modeling of WP. To deal with the inherent characteristics of WP, BERT4ST exploits the individual spatial and temporal dependency of patches and redesigns a set of spatial and temporal encodings. By well analyzing the connection between bidirectional attention networks and WP spatio-temporal data, BERT4ST employs a pre -trained BERT encoder as the backbone network to learn the individual spatial and temporal dependency of patches of WP data. Additionally, BERT4ST fine-tunes the pre -trained backbone in a multi -stage manner, i.e., first aligning the language model with the spatio-temporal data and then fine-tuning the downstream tasks while maintaining the stability of the backbone network. Experimental results demonstrate that our BERT4ST achieves desirable performance compared to some state-of-the-art methods.	[Lai, Zefeng; Wu, Tangjie; Ling, Qiang] Univ Sci & Technol China, Hefei, Peoples R China; [Fei, Xihong] Anhui Univ Technol, Maanshan, Peoples R China; [Ling, Qiang] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS; Anhui University of Technology	Ling, Q (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.; Ling, Q (corresponding author), Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei, Peoples R China.	qling@ustc.edu.cn		Ling, Qiang/0000-0001-5688-4130; fei, xihong/0000-0002-2820-8917	Key Science and Technology Program of Anhui [202203f07020002]; Key Common Technology Development Program of Hefei [GJ2022GX35]; Natural Science Foundation of Hefei [2022003]	Key Science and Technology Program of Anhui; Key Common Technology Development Program of Hefei; Natural Science Foundation of Hefei	This work was supported in part by the Key Science and Technology Program of Anhui under Grant 202203f07020002, in part by the Key Common Technology Development Program of Hefei (Research on Multisensor Perception and Fusion Algorithms for Autonomous Driving) under Grant GJ2022GX35, and in part by the Natural Science Foundation of Hefei under Grant 2022003.	Bentsen LO, 2023, APPL ENERG, V333, DOI 10.1016/j.apenergy.2022.120565; Cao DF, 2024, Arxiv, DOI arXiv:2310.04948; Carneiro TC, 2022, APPL ENERG, V314, DOI 10.1016/j.apenergy.2022.118936; Chang C, 2023, Arxiv, DOI arXiv:2308.08469; Child R, 2019, Arxiv, DOI [arXiv:1904.10509, DOI 10.48550/ARXIV.1904.10509]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fang Yuchen, 2021, arXiv; Fei XH, 2023, NEUROCOMPUTING, V521, P41, DOI 10.1016/j.neucom.2022.11.085; Fernández LM, 2006, RENEW ENERG, V31, P1203, DOI 10.1016/j.renene.2005.06.011; Fu CY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11803, DOI 10.1109/ICCV48922.2021.01161; Garza A, 2024, Arxiv, DOI arXiv:2310.03589; Ghosal D, 2023, Arxiv, DOI arXiv:2304.13731; Gruver N., 2023, arXiv; Guo SN, 2019, AAAI CONF ARTIF INTE, P922; Hodge BM, 2011, COMPUT-AIDED CHEM EN, V29, P1789; Hu TY, 2020, CSEE J POWER ENERGY, V6, P434, DOI 10.17775/CSEEJPES.2018.00010; Huang NC, 2023, INFORM FUSION, V91, P396, DOI 10.1016/j.inffus.2022.10.024; Jin M, 2024, Arxiv, DOI arXiv:2310.01728; Jonkman J., 2007, DYNAMICS MODELING LO; Ju Y, 2019, IEEE ACCESS, V7, P28309, DOI 10.1109/ACCESS.2019.2901920; Kavasseri RG, 2009, RENEW ENERG, V34, P1388, DOI 10.1016/j.renene.2008.09.006; Kim T., 2021, INT C LEARN REPR; Kumar A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.10054; Li YG, 2018, Arxiv, DOI [arXiv:1707.01926, DOI 10.48550/ARXIV.1707.01926]; Li YF, 2019, RENEW ENERG, V135, P540, DOI 10.1016/j.renene.2018.12.035; Li Z, 2023, IEEE T SUSTAIN ENERG, V14, P39, DOI 10.1109/TSTE.2022.3198816; Lin Y, 2019, IEEE T SUSTAIN ENERG, V10, P226, DOI 10.1109/TSTE.2018.2831238; Liu XL, 2021, ENERGY, V227, DOI 10.1016/j.energy.2021.120492; Liu Y, 2022, AM J NEURORADIOL, V43, P251, DOI 10.3174/ajnr.A7389; Lu P, 2021, RENEW ENERG, V179, P1925, DOI 10.1016/j.renene.2021.08.007; Lyu C, 2023, Arxiv, DOI arXiv:2306.09093; Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]; Nie YQ, 2023, Arxiv, DOI [arXiv:2211.14730, DOI 10.48550/ARXIV.2211.14730]; Nikodinoska D, 2022, APPL ENERG, V306, DOI 10.1016/j.apenergy.2021.117983; Olaofe ZO, 2014, SUSTAIN ENERGY TECHN, V6, P1, DOI 10.1016/j.seta.2013.12.001; Pan XX, 2022, ENERGY, V253, DOI 10.1016/j.energy.2022.124095; Pu N, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2149, DOI 10.1145/3394171.3413673; Ren YT, 2023, ENERGY, V267, DOI 10.1016/j.energy.2022.126590; Rene MQ, 2019, IEEE T IND INFORM, V15, P4624, DOI 10.1109/TII.2018.2882598; Shahid F, 2021, ENERGY, V223, DOI 10.1016/j.energy.2021.120069; Shao ZZ, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4454, DOI 10.1145/3511808.3557702; Song J, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4500, DOI 10.1145/3511808.3557705; Sun C., 2023, arXiv, DOI 10.48550/arXiv.2308.08241; Sun SL, 2023, ENERG CONVERS MANAGE, V283, DOI 10.1016/j.enconman.2023.116916; Ul Haque A, 2014, IEEE T POWER SYST, V29, P1663, DOI 10.1109/TPWRS.2014.2299801; Wang JL, 2024, IEEE T POWER SYST, V39, P2296, DOI 10.1109/TPWRS.2023.3268337; Wang L, 2022, APPL ENERG, V324, DOI 10.1016/j.apenergy.2022.119672; Wang XH, 2022, INT J MACH LEARN CYB, V13, P293, DOI 10.1007/s13042-021-01402-9; Wang Y, 2023, ENERG CONVERS MANAGE, V278, DOI 10.1016/j.enconman.2023.116709; Wang Y, 2021, APPL ENERG, V304, DOI 10.1016/j.apenergy.2021.117766; Wang Y, 2019, RENEW SUST ENERG REV, V116, DOI 10.1016/j.rser.2019.109422; Wu BR, 2022, ENERGY, V252, DOI 10.1016/j.energy.2022.123990; Wu HX, 2021, ADV NEUR IN, V34; Wu TJ, 2024, ENERG CONVERS MANAGE, V299, DOI 10.1016/j.enconman.2023.117896; Wu ZH, 2019, Arxiv, DOI arXiv:1906.00121; Wu ZH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P753, DOI 10.1145/3394486.3403118; Xiong BR, 2022, ELECTR POW SYST RES, V206, DOI 10.1016/j.epsr.2022.107776; Xue H, 2023, IEEE Transactions on Knowledge and Data Engineering; Yaghoubirad M, 2023, ENERG CONVERS MANAGE, V281, DOI 10.1016/j.enconman.2023.116760; Yoo J, P 2021 SIAM INT C DA; Yu B., 2017, ARXIV; Yu CQ, 2023, ENERGY, V263, DOI 10.1016/j.energy.2022.126034; Yu XX, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3048799; Yu XL, 2023, Arxiv, DOI arXiv:2306.11025; Zeng A, 2023, P AAAI C ART INT WAS, V37, P11121, DOI DOI 10.1609/AAAI.V37I9.26317; Zheng CAP, 2020, AAAI CONF ARTIF INTE, V34, P1234; Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106; Zhou T, 2023, Arxiv, DOI arXiv:2302.11939; Zhu QM, 2020, IEEE T SUSTAIN ENERG, V11, P509, DOI 10.1109/TSTE.2019.2897136	69	0	0	8	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0196-8904	1879-2227		ENERG CONVERS MANAGE	Energy Conv. Manag.	MAY 1	2024	307								118331	10.1016/j.enconman.2024.118331	http://dx.doi.org/10.1016/j.enconman.2024.118331			11	Thermodynamics; Energy & Fuels; Mechanics	Science Citation Index Expanded (SCI-EXPANDED)	Thermodynamics; Energy & Fuels; Mechanics	QX5E2					2024-07-03	WOS:001224172000001
J	Kong, QZ; Ju, KP; Wan, M; Liu, J; Wu, XQ; Li, YY; Zuo, XL; Li, YQ				Kong, Qing-Zhou; Ju, Kun-Ping; Wan, Meng; Liu, Jing; Wu, Xiao-Qi; Li, Yue-Yue; Zuo, Xiu-Li; Li, Yan-Qing			Comparative analysis of large language models in medical counseling: A focus on <i>Helicobacter pylori</i> infection	HELICOBACTER			English	Article						counseling tool; Helicobacter pylori; language model; reliability		Background: Large language models (LLMs) are promising medical counseling tools, but the reliability of responses remains unclear. We aimed to assess the feasibility of three popular LLMs as counseling tools for Helicobacter pylori infection in different counseling languages. Materials and Methods: This study was conducted between November 20 and December 1, 2023. Three large language models (ChatGPT 4.0 [LLM1], ChatGPT 3.5 [LLM2], and ERNIE Bot 4.0 [LLM3]) were input 15 H. pylori related questions each, once in English and once in Chinese. Each chat was conducted using the "New Chat" function to avoid bias from correlation interference. Responses were recorded and blindly assigned to three reviewers for scoring on three established Likert scales: accuracy (ranged 1-6 point), completeness (ranged 1-3 point), and comprehensibility (ranged 1-3 point). The acceptable thresholds for the scales were set at a minimum of 4, 2, and 2, respectively. Final various source and interlanguage comparisons were made. Results: The overall mean (SD) accuracy score was 4.80 (1.02), while 1.82 (0.78) for completeness score and 2.90 (0.36) for comprehensibility score. The acceptable proportions for the accuracy, completeness, and comprehensibility of the responses were 90%, 45.6%, and 100%, respectively. The acceptable proportion of overall completeness score for English responses was better than for Chinese responses (p = 0.034). For accuracy, the English responses of LLM3 were better than the Chinese responses (p = 0.0055). As for completeness, the English responses of LLM1 was better than the Chinese responses (p = 0.0257). For comprehensibility, the English responses of LLM1 was better than the Chinese responses (p = 0.0496). No differences were found between the various LLMs. Conclusions: The LLMs responded satisfactorily to questions related to H. pylori infection. But further improving completeness and reliability, along with considering language nuances, is crucial for optimizing overall performance.	[Kong, Qing-Zhou; Ju, Kun-Ping; Wan, Meng; Liu, Jing; Wu, Xiao-Qi; Li, Yue-Yue; Zuo, Xiu-Li; Li, Yan-Qing] Shandong Univ, Qilu Hosp, Dept Gastroenterol, Jinan 250012, Shandong, Peoples R China; [Kong, Qing-Zhou; Ju, Kun-Ping; Wan, Meng; Liu, Jing; Wu, Xiao-Qi; Li, Yue-Yue; Zuo, Xiu-Li; Li, Yan-Qing] Shandong Prov Clin Res Ctr Digest Dis, Jinan, Shandong, Peoples R China; [Kong, Qing-Zhou; Ju, Kun-Ping; Wan, Meng; Liu, Jing; Wu, Xiao-Qi; Li, Yue-Yue; Zuo, Xiu-Li; Li, Yan-Qing] Shandong Univ, Qilu Hosp, Lab Translat Gastroenterol, Jinan, Shandong, Peoples R China; [Kong, Qing-Zhou; Ju, Kun-Ping; Wan, Meng; Liu, Jing; Wu, Xiao-Qi; Li, Yue-Yue; Zuo, Xiu-Li; Li, Yan-Qing] Shandong Univ, Qilu Hosp, Robot Engn Lab Precise Diag & Therapy GI Tumor, Jinan, Shandong, Peoples R China	Shandong University; Shandong University; Shandong University	Li, YY (corresponding author), Shandong Univ, Qilu Hosp, Dept Gastroenterol, Jinan 250012, Shandong, Peoples R China.	lyynqj@126.com	li, yue/HSF-7296-2023; LI, YANQING/HKF-0151-2023	LI, YANQING/0000-0002-3595-7078; Kong, Qing-Zhou/0000-0002-4744-3269; Li, Yue-Yue/0000-0001-7042-9695				Hoang YN, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.50367; Huo B, 2023, NAT MED, DOI 10.1038/s41591-023-02656-2; Kong QZ, 2022, HELICOBACTER, V27, DOI 10.1111/hel.12912; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Li YH, 2023, LANCET GASTROENTEROL, V8, P553, DOI 10.1016/S2468-1253(23)00070-5; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Malfertheiner P, 2022, GUT, V71, P1724, DOI 10.1136/gutjnl-2022-327745; Moss S. F., 2023, Gastroenterology, V166, P267; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Pugliese N, 2024, CLIN GASTROENTEROL H, V22, DOI 10.1016/j.cgh.2023.08.033; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Southwell BG, 2023, ANNU REV PUBL HEALTH, V44, P113, DOI 10.1146/annurev-publhealth-071321-031118; Tan W, 2024, HELICOBACTER, V29, DOI 10.1111/hel.13029; Thrift AP, 2023, NAT REV CLIN ONCOL, V20, P338, DOI 10.1038/s41571-023-00747-0; Wu Y, 2020, HELICOBACTER, V25, DOI 10.1111/hel.12705; Zha J, 2022, HELICOBACTER, V27, DOI 10.1111/hel.12880; Zhou LY, 2022, CHINESE MED J-PEKING, V135, P2899, DOI 10.1097/CM9.0000000000002546; US	18	0	0	7	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1083-4389	1523-5378		HELICOBACTER	Helicobacter	JAN	2024	29	1							e13055	10.1111/hel.13055	http://dx.doi.org/10.1111/hel.13055			7	Gastroenterology & Hepatology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology; Microbiology	HF7C4					2024-07-03	WOS:001158133100001
J	Gilbert, S; Kather, JN; Hogan, A				Gilbert, Stephen; Kather, Jakob Nikolas; Hogan, Aidan			Augmented non-hallucinating large language models as medical information curators	NPJ DIGITAL MEDICINE			English	Article								Reliably processing and interlinking medical information has been recognized as a critical foundation to the digital transformation of medical workflows, and despite the development of medical ontologies, the optimization of these has been a major bottleneck to digital medicine. The advent of large language models has brought great excitement, and maybe a solution to the medicines' 'communication problem' is in sight, but how can the known weaknesses of these models, such as hallucination and non-determinism, be tempered? Retrieval Augmented Generation, particularly through knowledge graphs, is an automated approach that can deliver structured reasoning and a model of truth alongside LLMs, relevant to information structuring and therefore also to decision support.	[Gilbert, Stephen; Kather, Jakob Nikolas] TUD Dresden Univ Technol, Else Kroner Fresenius Ctr Digital Hlth, Dresden, Germany; [Hogan, Aidan] Univ Chile, Dept Comp Sci, Santiago, Chile; [Hogan, Aidan] Univ Chile, Millennium Inst Fdn Res Data, DCC, Santiago, Chile	Universidad de Chile; Universidad de Chile	Gilbert, S (corresponding author), TUD Dresden Univ Technol, Else Kroner Fresenius Ctr Digital Hlth, Dresden, Germany.	stephen.gilbert@tu-dresden.de		Hogan, Aidan/0000-0001-9482-1982	Bundesministerium fuer Bildung und Forschung (BMBF) project; European Union; ANID-Millennium Science Initiative Program [ICN17 002]; Fondecyt Grant [1221926]	Bundesministerium fuer Bildung und Forschung (BMBF) project; European Union(European Union (EU)); ANID-Millennium Science Initiative Program; Fondecyt Grant(Comision Nacional de Investigacion Cientifica y Tecnologica (CONICYT)CONICYT FONDECYT)	S.G. received funding through a Bundesministerium fuer Bildung und Forschung (BMBF) project (Personal Mastery of Health & Wellness Data, PATH) on consent in health data sharing, financed through the European Union NextGenerationEU program. A.H. received funding from ANID-Millennium Science Initiative Program-Code ICN17 002 and Fondecyt Grant 1221926.	Cenikj G, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-34981-4; Chandak P, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-01960-3; Chen J., 2023, arXiv, V5, P1; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Giuffre M., 2023, Clin. Gastroenterol. Hepatol, VS1542-3565, P00835; Guo Q, 2022, INT J INTELL SYST, V37, P8548, DOI 10.1002/int.22955; Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3418294, 10.1145/3447772]; Hahn Udo, 2020, Yearb Med Inform, V29, P208, DOI 10.1055/s-0040-1702001; Howell Michael D, 2024, JAMA, V331, P242, DOI 10.1001/jama.2023.25057; Hu X., 2006, Computational Systems Biology; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Köhler S, 2021, NUCLEIC ACIDS RES, V49, pD1207, DOI 10.1093/nar/gkaa1043; Kreuzthaler M, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1073313; Lehne M, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0158-1; Liao LZ, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P3452, DOI 10.1145/3539618.3594250; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Moy AJ, 2021, J AM MED INFORM ASSN, V28, P998, DOI 10.1093/jamia/ocaa325; Munn L, 2023, AI SOC, DOI 10.1007/s00146-023-01756-4; Newman-Griffis D, 2021, J AM MED INFORM ASSN, V28, P516, DOI 10.1093/jamia/ocaa269; Pan J. Z., 2023, Transactions on Graph Data and Knowledge (TGDK), V1, P1, DOI [10.4230/TGDK.1.1.2, DOI 10.4230/TGDK.1.1.2]; Rajabi E, 2022, J INF SCI, DOI 10.1177/01655515221112844; Schulze-Kremer S., 2005, Encyclopedia of Genetics, Genomics, Proteomics and Bioinformatics, V4; Truhn D, 2024, J PATHOL, V262, P310, DOI 10.1002/path.6232; Truhn D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-47500-2; Truhn D, 2023, NAT MED, DOI 10.1038/s41591-023-02594-z; Welzel C, 2023, J MED INTERNET RES, V25, DOI 10.2196/50158; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zakka Cyril, 2023, Res Sq, DOI 10.21203/rs.3.rs-2883198/v1	31	0	0	13	13	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	APR 23	2024	7	1							100	10.1038/s41746-024-01081-0	http://dx.doi.org/10.1038/s41746-024-01081-0			5	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	OK6Y5	38654142	gold			2024-07-03	WOS:001207216300001
C	Ocampo, R; Andres, J; Schmidt, A; Pegram, C; Shave, J; Hill, C; Wright, B; Bown, O		Rodriguez-Fernandez, N; Rebelo, SM; Johnson, C		Ocampo, Rodolfo; Andres, Josh; Schmidt, Adrian; Pegram, Caroline; Shave, Justin; Hill, Charlton; Wright, Brendan; Bown, Oliver			Using GPT-3 to Achieve Semantically Relevant Data Sonificiation for an Art Installation	ARTIFICIAL INTELLIGENCE IN MUSIC, SOUND, ART AND DESIGN, EVOMUSART 2023	Lecture Notes in Computer Science		English	Proceedings Paper	12th International Conference on Artificial Intelligence in Music, Sound, Art and Design (EvoMUSART) Held as Part of EvoStar Conference	APR 12-14, 2023	Brno, CZECH REPUBLIC			data sonification; machine learning; generative music; generative AI; large language models; word emdeddings		Large Language Models such as GPT-3 exhibit generative language capabilities with multiple potential applications in creative practice. In this paper, we present a method for data sonification that employs the GPT-3 model to create semantically relevant mappings between artificial intelligence-generated natural language descriptions of data, and human-generated descriptions of sounds. We implemented this method in a public art installation to generate a soundscape based on data from different systems. While common sonification approaches rely on arbitrary mappings between data values and sonic values, our approach explores the use of language models to achieve a mapping not via values but via meaning. We find our approach is a useful tool for musification practice and demonstrates a new application of generative language models in creative new media arts practice. We show how different prompts influence data to sound mappings, and highlight that matching the embeddings of texts of different lengths produces undesired behavior.	[Ocampo, Rodolfo; Wright, Brendan; Bown, Oliver] Univ New South Wales, Kensington, NSW, Australia; [Andres, Josh; Schmidt, Adrian] Australian Natl Univ, Canberra, ACT, Australia; [Pegram, Caroline; Shave, Justin; Hill, Charlton; Wright, Brendan] Uncanny Valley, Canberra, ACT, Australia	University of New South Wales Sydney; Australian National University	Ocampo, R (corresponding author), Univ New South Wales, Kensington, NSW, Australia.	r.ocampo_blanco@unsw.edu.au			Australian Research Council [DP200101059]; Australian Research Council [DP200101059] Funding Source: Australian Research Council	Australian Research Council(Australian Research Council); Australian Research Council(Australian Research Council)	This research was made possible by a commission from the School of Cybernetics at the Australian National University for music studio Uncanny Valley (UV). The development of the novel concept for a semantically relevant sonification using Large Language Models is an original contribution from Rodolfo Ocampo, who also led the technical development of the system, in collaboration with members of the UV team. The artwork uses UV's MEMU generative music system, developed by Justin Shave and Brendan Wright. The design and development of the visual user interface were led by Adrian Schmidt and Josh Andres. Oliver Bown and Rodolfo Ocampo's research is supported by an Australian Research Council Discovery Project (DP200101059).	Andres J., 2022, 2022 OZCHI C HUMAN F; Andres J, 2022, FRONT COMP SCI-SWITZ, V4, DOI 10.3389/fcomp.2022.931973; Brand S., 2018, J DESIGN SCI, DOI [DOI 10.21428/7F2-5F08, DOI 10.21428/7F2E5F08, 10.21428/7f2-5f08, 10.21428/7f2e5f08]; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Flowers John H., 2001, Sonification of daily weather records: Issues of perception, attention and memory in design choices, P432; Hermann T., 2003, 'Broadcasting auditory weather reports-a pilot project'; Hermann Thomas, 2011, SONIFICATION HDB; Kalonaris S, 2022, TOKYO KION ON QUERY; Krol SJ, 2022, LECT NOTES COMPUT SC, P131, DOI 10.1007/978-3-031-03789-4_9; Mardakheh MK, 2022, LEONARDO, V55, P516, DOI 10.1162/leon_a_02257; Neelakantan A., 2022, . Text and Code Embeddings by Contrastive Pre-Training.; OpenAI, 2022, OPENAI API; Polli A, 2004, ATMOSPHERICS WEATHER; Quinn M., 2001, Research set to music: The climate symphony and other sonifications of ice core, radar, DNA, seismic and solar wind data; Ramesh A, 2021, PR MACH LEARN RES, V139; Rocchesso Davide., 2008, CHI 08 EXTENDED ABST, P3969; Roddy S., 2022, SIGNAL NOISE LOOPS C, P525; Singhal Amit., 2001, Modern information retrieval: A brief overview	18	0	0	4	8	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-29955-1; 978-3-031-29956-8	LECT NOTES COMPUT SC			2023	13988						212	227		10.1007/978-3-031-29956-8_14	http://dx.doi.org/10.1007/978-3-031-29956-8_14			16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV1WI					2024-07-03	WOS:000999872400014
J	Zhang, JL; Fang, Y; Shao, X; Chen, HJ; Zhang, NY; Fan, XH				Zhang, Jinlu; Fang, Yin; Shao, Xin; Chen, Huajun; Zhang, Ningyu; Fan, Xiaohui			The Future of Molecular Studies through the Lens of Large Language Models	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Editorial Material								The rapid advancement of large language models is reshaping research across various fields, offering a novel approach to the complex realm of molecular studies. Our evaluation of GPT-4 and GPT-3.5, focusing on their performance in generating and optimizing molecular structures, highlights GPT-4's strengths in certain aspects of molecular optimization. However, it also revealed challenges in accurately creating complex molecules. Addressing these issues, we propose possible directions for future molecular science research. These suggestions aim to forge new paths for exploring the intricacies of molecular structures, potentially bringing new efficiencies and innovations in the field.	[Zhang, Jinlu; Shao, Xin; Fan, Xiaohui] Zhejiang Univ, Pharmaceut Informat Inst, Coll Pharmaceut Sci, Hangzhou 310058, Peoples R China; [Zhang, Jinlu; Shao, Xin; Fan, Xiaohui] Zhejiang Univ, Innovat Ctr Yangtze River Delta, Natl Key Lab Chinese Med Modernizat, Jiaxing 314100, Peoples R China; [Fang, Yin; Chen, Huajun] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China; [Fang, Yin; Chen, Huajun] ZJU Hangzhou Global Sci & Technol Innovat Ctr, Hangzhou 311200, Peoples R China; [Fang, Yin; Chen, Huajun; Zhang, Ningyu] Alibaba ZJU Frontier Technol Res Ctr, Hangzhou 310023, Peoples R China; [Zhang, Ningyu] Zhejiang Univ, Coll Comp Sci & Technol, Ningbo 315048, Peoples R China	Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University	Fan, XH (corresponding author), Zhejiang Univ, Pharmaceut Informat Inst, Coll Pharmaceut Sci, Hangzhou 310058, Peoples R China.; Fan, XH (corresponding author), Zhejiang Univ, Innovat Ctr Yangtze River Delta, Natl Key Lab Chinese Med Modernizat, Jiaxing 314100, Peoples R China.; Zhang, NY (corresponding author), Alibaba ZJU Frontier Technol Res Ctr, Hangzhou 310023, Peoples R China.; Zhang, NY (corresponding author), Zhejiang Univ, Coll Comp Sci & Technol, Ningbo 315048, Peoples R China.	zhangningyu@zju.edu.cn; fanxh@zju.edu.cn	luo, Jing/KFT-0288-2024; Zhang, Ningyu/AAQ-7391-2021; zhang, jinlu/KEE-9374-2024; Yang, Ning/KHD-1133-2024; FAN, Xiaohui/F-6458-2010	Zhang, Ningyu/0000-0002-1970-0678; FAN, Xiaohui/0000-0002-6336-3007; Zhang, Jinlu/0009-0002-3336-8074	National Natural Science Foundation of China [U23A20513]; National Natural Science Foundation of China [2022030309]; Ningbo Top Medical and Health Research Program	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Ningbo Top Medical and Health Research Program	This work is supported by the National Natural Science Foundation of China (U23A20513), Ningbo Top Medical and Health Research Program (No. 2022030309).	Boiko DA, 2023, Arxiv, DOI [arXiv:2304.05332, DOI 10.48550/ARXIV.2304.05332]; Edwards C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P595; Fang Y, 2023, Arxiv, DOI arXiv:2306.08018; Fang Y, 2023, NAT MACH INTELL, V5, P542, DOI 10.1038/s42256-023-00654-0; Fang Y, 2024, Arxiv, DOI arXiv:2301.11259; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Francl M, 2023, NAT CHEM, V15, P890, DOI 10.1038/s41557-023-01253-7; Huang Z., 2023, arXiv; Irwin JJ, 2012, J CHEM INF MODEL, V52, P1757, DOI 10.1021/ci3001277; Lee HRS, 2023, Arxiv, DOI [arXiv:2309.00267, 10.48550/arXiv.2309.00267]; Li JT, 2024, Arxiv, DOI arXiv:2306.06615; Meibohm B, 1997, INT J CLIN PHARM TH, V35, P401; Meng K, 2023, Arxiv, DOI [arXiv:2210.07229, 10.48550/ARXIV.2210.07229]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Qian C, 2023, Arxiv, DOI arXiv:2307.07443; Schick T., 2023, arXiv; Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232; Sliwoski G, 2014, PHARMACOL REV, V66, P334, DOI 10.1124/pr.112.007336; Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5; Vert JP, 2023, NAT BIOTECHNOL, V41, P750, DOI 10.1038/s41587-023-01789-6; White AD, 2023, NAT REV CHEM, V7, P457, DOI 10.1038/s41570-023-00502-0; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Yao Y., 2023, P 2023 C EMPIRICAL M, P10222; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	24	0	0	9	9	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	JAN 19	2024	64	3					563	566		10.1021/acs.jcim.3c01977	http://dx.doi.org/10.1021/acs.jcim.3c01977			4	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	HS9D8	38241025				2024-07-03	WOS:001161604200001
J	Roberts, J; Baker, M; Andrew, J				Roberts, John; Baker, Max; Andrew, Jane			Artificial intelligence and qualitative research: The promise and perils of large language model (LLM) 'assistance'	CRITICAL PERSPECTIVES ON ACCOUNTING			English	Article						Artificial intelligence; Large Language Models; Qualitative research; AI Ethics; Communicative rationality; ChatGPT	AI	New large language models (LLMs) like ChatGPT have the potential to change qualitative research by contributing to every stage of the research process from generating interview questions to structuring research publications. However, it is far from clear whether such 'assistance' will enable or deskill and eventually displace the qualitative researcher. This paper sets out to explore the implications for qualitative research of the recently emerged capabilities of LLMs; how they have acquired their seemingly 'human-like' capabilities to 'converse' with us humans, and in what ways these capabilities are deceptive or misleading. Building on a comparison of the different 'trainings' of humans and LLMs, the paper first traces the seemingly human-like qualities of the LLM to the human proclivity to project communicative intent into or onto LLMs' purely imitative capacity to predict the structure of human communication. It then goes on to detail the ways in which such human-like communication is deceptive and misleading in relation to the absolute 'certainty' with which LLMs 'converse', their intrinsic tendencies to 'hallucination' and 'sycophancy', the narrow conception of 'artificial intelligence', LLMs' complete lack of ethical sensibility or capacity for responsibility, and finally the feared danger of an 'emergence' of 'human-competitive' or 'superhuman' LLM capabilities. The paper concludes by noting the potential dangers of the widespread use of LLMs as 'mediators' of human self-understanding and culture. A postscript offers a brief reflection on what only humans can do as qualitative researchers.	[Roberts, John; Baker, Max; Andrew, Jane] Univ Sydney, Business Sch, Discipline Accounting Governance & Regulat, Darlington, NSW 2006, Australia	University of Sydney	Roberts, J (corresponding author), Univ Sydney, Business Sch, Discipline Accounting Governance & Regulat, Darlington, NSW 2006, Australia.	john.roberts@sydney.edu.au; max.baker@sydney.edu.au; jane.andrew@sydney.edu.au						Acemoglu D., 2021, Harms of ai; [Anonymous], 2023, Artificial Intelligence Index Report; Baker M, 2022, ACCOUNT AUDIT ACCOUN, V35, P1462, DOI 10.1108/AAAJ-09-2020-4943; Beck U., 1992, Risk society: Towards a new modernity, V17; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2023, J DEMOCR, V34, P111, DOI 10.1353/jod.2023.a907692; Berger P., 1966, SOCIAL CONSTRUCTION; Bergson H., 1889, Time and free will: An essay on the immediate data of consciousness, V3rd; Blau A, 2022, EUR J POLIT THEORY, V21, P321, DOI 10.1177/1474885119867679; Bostrom Nick, 2016, SUPERINTELLIGENCE PA, DOI DOI 10.1080/01402390.2013.844127; Butler J, 2015, SENSES OF THE SUBJECT, P1; Butler J, 2005, GIVING AN ACCOUNT OF ONESELF, P1, DOI 10.5422/fso/9780823225033.001.0001; Crawford Kate, 2021, Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence, DOI [10.2307/j.ctv1ghv45t, DOI 10.2307/J.CTV1GHV45T]; Dahl M, 2024, Arxiv, DOI [arXiv:2401.01301, 10.48550/arXiv.2401.01301]; Economist, 2023, The Economist; Forster C., 2022, Are large language models operationalizations of Saussurean Structure?; Future of Life Institute, 2022, Pause giant AI experiments: An open letter; Gebru Timnit, 2023, Statement from the listed authors of Stochastic Parrots on the "AI pause; Gendron Y, 2022, CRIT PERSPECT ACCOUN, V87, DOI 10.1016/j.cpa.2021.102411; Gent E., 2023, New Scientist10 May; Graziano M., 2021, Rethinking consciousness; A scientific theory of subjective experience; Habermas Jurgen., 1985, THEORY COMMUNICATIVE, V2. T; Hagendorff T., 2021, AI and Ethics, V2, P851; Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8; Hao K., 2020, MIT Technology Review'20 October; Harari Y. N., 2023, EconomistMay 6th; Hsu Jeremy., 2023, New Scientist; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Lacan Jacques., 1978, 4 FUNDAMENTAL CONCEP; Latour B., 2005, REASSEMBLING SOCIAL; Lewton T., 2023, New Scientist25 July; Margetts H, 2019, POLIT QUART, V90, P107, DOI 10.1111/1467-923X.12574; Mead George Herbert, 1934, MIND SELF SOC, DOI DOI 10.7208/CHICAGO/9780226112879.001.0001; Mitchell M., 2022, QuantamagazineDecember 13; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Murgia M., 2023, Financial TimesSeptember 12; Rhodes C, 2020, ROUTL STUD BUS ETHIC, P1; Roberts J, 2021, CRIT PERSPECT ACCOUN, V76, DOI 10.1016/j.cpa.2020.102203; Russell S., 2019, Human compatible. ai and the problem of control; Schutz A., 1967, The phenomenology of the social world; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Shimley R., 2023, Financial TimesNovember 3; Suleyman Mustafa, 2023, The coming wave: AI, power and the 21st century's greatest dilemma; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wei J., 2023, Google Deep Mind; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wiedermann G., 2022, The Handbook of Computational Social Science, V2, P366; Williams J., 2018, Stand out of our light: Freedom and resistance in the attention economy, DOI DOI 10.1017/9781108453004; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]; Zou A, 2023, Arxiv, DOI arXiv:2307.15043	52	0	0	20	20	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1045-2354	1095-9955		CRIT PERSPECT ACCOUN	Crit. Perspect. Account.	MAR	2024	99								102722	10.1016/j.cpa.2024.102722	http://dx.doi.org/10.1016/j.cpa.2024.102722		FEB 2024	9	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	NS1E2		hybrid			2024-07-03	WOS:001202342500001
J	Van Veen, D; Van Uden, C; Blankemeier, L; Delbrouck, JB; Aali, A; Bluethgen, C; Pareek, A; Polacin, M; Reis, EP; Seehofnerová, A; Rohatgi, N; Hosamani, P; Collins, W; Ahuja, N; Langlotz, CP; Hom, J; Gatidis, S; Pauly, J; Chaudhari, AS				Van Veen, Dave; Van Uden, Cara; Blankemeier, Louis; Delbrouck, Jean-Benoit; Aali, Asad; Bluethgen, Christian; Pareek, Anuj; Polacin, Malgorzata; Reis, Eduardo Pontes; Seehofnerova, Anna; Rohatgi, Nidhi; Hosamani, Poonam; Collins, William; Ahuja, Neera; Langlotz, Curtis P.; Hom, Jason; Gatidis, Sergios; Pauly, John; Chaudhari, Akshay S.			Adapted large language models can outperform medical experts in clinical text summarization	NATURE MEDICINE			English	Article; Early Access							BURNOUT; BURDEN; CARE; NURSES	Analyzing vast textual data and summarizing key information from electronic health records imposes a substantial burden on how clinicians allocate their time. Although large language models (LLMs) have shown promise in natural language processing (NLP) tasks, their effectiveness on a diverse range of clinical summarization tasks remains unproven. Here we applied adaptation methods to eight LLMs, spanning four distinct clinical summarization tasks: radiology reports, patient questions, progress notes and doctor-patient dialogue. Quantitative assessments with syntactic, semantic and conceptual NLP metrics reveal trade-offs between models and adaptation methods. A clinical reader study with 10 physicians evaluated summary completeness, correctness and conciseness; in most cases, summaries from our best-adapted LLMs were deemed either equivalent (45%) or superior (36%) compared with summaries from medical experts. The ensuing safety analysis highlights challenges faced by both LLMs and medical experts, as we connect errors to potential medical harm and categorize types of fabricated information. Our research provides evidence of LLMs outperforming medical experts in clinical text summarization across multiple tasks. This suggests that integrating LLMs into clinical workflows could alleviate documentation burden, allowing clinicians to focus more on patient care. Comparative performance assessment of large language models identified ChatGPT-4 as the best-adapted model across a diverse set of clinical text summarization tasks, and it outperformed 10 medical experts in a reader study.	[Van Veen, Dave; Blankemeier, Louis; Pauly, John] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Van Veen, Dave; Van Uden, Cara; Blankemeier, Louis; Delbrouck, Jean-Benoit; Bluethgen, Christian; Pareek, Anuj; Reis, Eduardo Pontes; Langlotz, Curtis P.; Gatidis, Sergios; Chaudhari, Akshay S.] Stanford Ctr Artificial Intelligence Med & Imaging, Palo Alto, CA 94304 USA; [Van Uden, Cara] Stanford Univ, Dept Comp Sci, Stanford, CA USA; [Aali, Asad] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX USA; [Bluethgen, Christian; Polacin, Malgorzata] Univ Hosp Zurich, Univ Zurich, Diagnost & Intervent Radiol, Zurich, Switzerland; [Pareek, Anuj] Copenhagen Univ Hosp, Copenhagen, Denmark; [Reis, Eduardo Pontes] Albert Einstein Israelite Hosp, Sao Paulo, Brazil; [Seehofnerova, Anna; Rohatgi, Nidhi; Hosamani, Poonam; Collins, William; Ahuja, Neera; Langlotz, Curtis P.; Hom, Jason] Stanford Univ, Dept Med, Stanford, CA USA; [Seehofnerova, Anna; Langlotz, Curtis P.; Gatidis, Sergios; Chaudhari, Akshay S.] Stanford Univ, Dept Radiol, Stanford, CA USA; [Rohatgi, Nidhi] Stanford Univ, Dept Neurosurg, Stanford, CA USA; [Langlotz, Curtis P.; Chaudhari, Akshay S.] Stanford Univ, Dept Biomed Data Sci, Stanford, CA USA; [Chaudhari, Akshay S.] Stanford Cardiovasc Inst, Stanford, CA USA	Stanford University; Stanford University; University of Texas System; University of Texas Austin; University of Zurich; University Zurich Hospital; University of Copenhagen; Hospital Israelita Albert Einstein; Stanford University; Stanford University; Stanford University; Stanford University	Van Veen, D (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.; Van Veen, D (corresponding author), Stanford Ctr Artificial Intelligence Med & Imaging, Palo Alto, CA 94304 USA.	vanveen@stanford.edu	Rohatgi, Nidhi/GWR-1096-2022; Gatidis, Sergios/AAF-4858-2020	Gatidis, Sergios/0000-0002-6928-4967; Collins, William/0000-0003-0974-2599; Aali, Asad/0009-0008-2120-5722; Van Veen, Dave/0000-0001-9312-1773; Pauly, John/0000-0001-5918-4172; Rohatgi, Nidhi/0000-0003-4574-0283; Chaudhari, Akshay/0000-0002-3667-6796; Ahuja, Neera/0000-0002-2979-7530	Foundation for the National Institutes of Health (Foundation for the National Institutes of Health, Inc.); Microsoft; Accelerate Foundation Models Academic Research; One Medical [R01 HL155410, R01 HL157235]; National Institute of Health (NIH) [R18HS026886]; Agency for Healthcare Research and Quality; Gordon and Betty Moore Foundation [75N92020C00021]; National Institute of Biomedical Imaging and Bioengineering [75N92020C00021, 75N92020C00008]; NIH; GE Healthcare; Philips and Amazon	Foundation for the National Institutes of Health (Foundation for the National Institutes of Health, Inc.)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Microsoft(Microsoft); Accelerate Foundation Models Academic Research; One Medical; National Institute of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Agency for Healthcare Research and Quality(United States Department of Health & Human ServicesAgency for Healthcare Research & Quality); Gordon and Betty Moore Foundation(Gordon and Betty Moore Foundation); National Institute of Biomedical Imaging and Bioengineering(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Biomedical Imaging & Bioengineering (NIBIB)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); GE Healthcare(General ElectricGE Healthcare); Philips and Amazon	Microsoft provided Azure OpenAI credits for this project via both the Accelerate Foundation Models Academic Research (AFMAR) program and also a cloud services grant to Stanford Data Science. Additional compute support was provided by One Medical, which A.A. used as part of his summer internship. C.L. is supported by National Institute of Health (NIH) grants R01 HL155410 and R01 HL157235, by Agency for Healthcare Research and Quality grant R18HS026886, by the Gordon and Betty Moore Foundation and by the National Institute of Biomedical Imaging and Bioengineering under contract 75N92020C00021. A.C. receives support from NIH grants R01 HL167974, R01 AR077604, R01 EB002524, R01 AR079431 and P41 EB027060; from NIH contracts 75N92020C00008 and 75N92020C00021; and from GE Healthcare, Philips and Amazon.	Abacha A. B., 2023, PROC 5 CLIN NATURAL, DOI [10.18653/v1/2023.clinicalnlp-1.52, DOI 10.18653/V1/2023.CLINICALNLP-1.52]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, Best practices for prompt engineering with OpenAI API; Arndt BG, 2017, ANN FAM MED, V15, P419, DOI 10.1370/afm.2121; Ben Abacha A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2228; Bowman Sue, 2013, Perspect Health Inf Manag, V10, p1c; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chang CP, 2016, CIN-COMPUT INFORM NU, V34, P183, DOI 10.1097/CIN.0000000000000222; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chen MX, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P76; Chen Z., 2023, PROC 61 ANN M ASS CO, DOI [10.18653/v1/2023.acl-short.41, DOI 10.18653/V1/2023.ACL-SHORT.41]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Deka P., 2022, Lecture Notes in Computer Science, DOI [10.1007/978-3-031-20627-6_1, DOI 10.1007/978-3-031-20627-6_1]; Delbrouck J.-B., 2023, PROC 22ST WORKSHOP B, DOI [10.18653/v1/2023.bionlp-1.45, DOI 10.18653/V1/2023.BIONLP-1.45]; Demner-Fushman D., 2023, 22 WORKSHOP BIOMEDIC; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Ding J., 2023, arXiv; Duffy William J, 2010, Nurs Adm Q, V34, pE1, DOI 10.1097/NAQ.0b013e3181c95ec4; Ehrenfeld JM, 2018, CURR OPIN ANESTHESIO, V31, P357, DOI 10.1097/ACO.0000000000000588; Fleming SL, 2023, Arxiv, DOI arXiv:2308.14089; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; Gao Y., 2023, BIONLP WORKSHOP 2023, DOI [10.13026/1z6g-ex18, DOI 10.13026/1Z6G-EX18]; Gao Yanjun, 2023, Proc Conf Assoc Comput Linguist Meet, V2023, P461, DOI 10.18653/v1/2023.bionlp-1.43; Gershanik Esteban F, 2011, AMIA Annu Symp Proc, V2011, P465; Gesner E, 2019, STUD HEALTH TECHNOL, V264, P1194, DOI 10.3233/SHTI190415; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Golob JF, 2016, J TRAUMA ACUTE CARE, V80, P742, DOI 10.1097/TA.0000000000000986; Han TY, 2023, Arxiv, DOI [arXiv:2304.08247, DOI 10.48550/ARXIV.2304.08247]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Johnson A., 2021, Mimic-iv. PhysioNet, DOI [DOI 10.13026/A3WN-HQ05,2020, DOI 10.13026/S6N6-XD98]; Johnson Alistair, 2019, PN; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410; Khamisa N, 2013, INT J ENV RES PUB HE, V10, P2214, DOI 10.3390/ijerph10062214; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lampinen A. K., 2022, FINDINGS ASS COMPUTA; Lehman E., 2023, C HLTH INF LEARN, P578; Liang P., Transact. Mach. Learn. Res.; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Longpre S, 2023, Arxiv, DOI arXiv:2301.13688; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Ma C, 2024, Arxiv, DOI arXiv:2304.08448; Manakul P., 2023, 22 WORKSHOP BIOMEDIC, P516; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; Mathur Y, 2023, Arxiv, DOI [arXiv:2306.17384, 10.48550/arXiv.2306.17384, DOI 10.48550/ARXIV.2306.17384]; Nie F., 2022, PREPRINT, DOI [10.48550/arXiv.2212.02216, DOI 10.48550/ARXIV.2212.02216]; Okazaki N., 2010, PROC 23 INT C COMPUT; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; OpenAi, 2022, Chatgpt; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng A., 2023, GPT-3.5 turbo fine-tuning and API updates; Poli M., 2023, P 40THINTERNATIONAL, V202, P1164; Raffel C, 2020, J MACH LEARN RES, V21; Ratwani RM, 2018, J AM MED INFORM ASSN, V25, P1197, DOI 10.1093/jamia/ocy088; Robinson KE, 2018, MEDICINE, V97, DOI 10.1097/MD.0000000000012319; Rosoł M, 2023, medRxiv, DOI [10.1101/2023.06.04.23290939, 10.1101/2023.06.04.23290939, DOI 10.1101/2023.06.04.23290939]; Saravia E., 2022, "Prompt engineering guide; Shanafelt TD, 2016, MAYO CLIN PROC, V91, P836, DOI 10.1016/j.mayocp.2016.05.007; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sinsky C, 2016, ANN INTERN MED, V165, P753, DOI 10.7326/M16-0961; Soldaini L., 2016, Quickumls: a fast, unsupervised approach for medical concept extraction; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tay Y, 2022, Arxiv, DOI arXiv:2205.05131; The Vicuna Team, 2023, Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tian Shi, 2021, ACM/IMS Transactions on Data Science, V2, DOI 10.1145/3419106; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Toussaint W, 2020, Arxiv, DOI [arXiv:2006.06292, 10.48550/arXiv.2006.06292, DOI 10.48550/ARXIV.2006.06292]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Vallat R., 2018, Journal of Open Source Software, V3, P1026, DOI DOI 10.21105/JOSS.01026; Van Veen D., 2023, 22 WORKSHOP BIOMEDIC, P449; Walsh KE, 2017, MED CARE, V55, P436, DOI 10.1097/MLR.0000000000000679; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Wei SB, 2023, Arxiv, DOI [arXiv:2304.07437, 10.48550/arXiv.2304.07437, DOI 10.48550/ARXIV.2304.07437]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Yackel TR, 2010, J AM MED INFORM ASSN, V17, P104, DOI 10.1197/jamia.M3294; Yim W., 2023, CEUR WORKSHOP P; Yim WW, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02487-3; Yu FY, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100802; Zack Travis, 2024, Lancet Digit Health, V6, pe12, DOI 10.1016/S2589-7500(23)00225-X; Zhang T., 2020, INT C LEARNING REPRE; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685	91	4	4	21	21	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	2024 FEB 27	2024										10.1038/s41591-024-02855-5	http://dx.doi.org/10.1038/s41591-024-02855-5		FEB 2024	27	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	KB5C3	38413730	Green Submitted			2024-07-03	WOS:001177503700002
J	Naik, HR; Prather, AD; Gurda, GT				Naik, Himani R.; Prather, Andrew D.; Gurda, Grzegorz T.			Synchronous Bilateral Breast Cancer: A Case Report Piloting and Evaluating the Implementation of the AI-Powered Large Language Model (LLM) ChatGPT	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						chatgpt aided case report; chatgpt; breast cancer risk; multifocal; bilateral; ductal carcinoma; breast cancer	GUIDELINES; RISK	Primary breast carcinoma is the most common cancer type in women, and although bilateral synchronous breast cancers (s-BBC) remain quite rare, the reported incidence may increase with the adoption of more sensitive imaging modalities. Here, we present a case of histomorphological and clinically distinct s-BBC, together with a discussion of clinical management decisions, prognosis, and treatment standards and how these relate to outcomes vis-a-vis more established standards in unifocal breast carcinoma. The case report also constitutes a pilot and formal evaluation of a large language model (LLM) of ChatGPT as a tool to aid in generating a single patient case report.	[Naik, Himani R.] Gunderson Med Fdn, Gundersen Lutheran Med Ctr, La Crosse, WI USA; [Prather, Andrew D.] Gundersen Lutheran Med Ctr, Radiol, La Crosse, WI USA; [Gurda, Grzegorz T.] Univ Wisconsin La Crosse, Biol, La Crosse, WI 54601 USA; [Gurda, Grzegorz T.] Gundersen Lutheran Med Ctr, Pathol, La Crosse, WI 54601 USA	Gundersen Lutheran Medical Center; Gundersen Lutheran Medical Center; University of Wisconsin System; University of Wisconsin La Crosse; Gundersen Lutheran Medical Center	Gurda, GT (corresponding author), Univ Wisconsin La Crosse, Biol, La Crosse, WI 54601 USA.; Gurda, GT (corresponding author), Gundersen Lutheran Med Ctr, Pathol, La Crosse, WI 54601 USA.	gtgurda@gundersenhealth.org						Aalders KC, 2017, EUR J CANCER, V79, P98, DOI 10.1016/j.ejca.2017.03.034; Begg CB, 2018, INT J CANCER, V142, P347, DOI 10.1002/ijc.31051; Gadea J, 2021, CLIN TRANSL ONCOL, V23, P1915, DOI 10.1007/s12094-021-02600-1; Gradishar WJ, 2018, J NATL COMPR CANC NE, V16, P310, DOI 10.6004/jnccn.2018.0012; Mejdahl MK, 2019, BRIT J CANCER, V120, P761, DOI 10.1038/s41416-019-0403-z; Sas-Korczynska B, 2018, Now Jr Onc., V68, P221; Saslow D, 2007, CA-CANCER J CLIN, V57, P75, DOI 10.3322/canjclin.57.2.75; Schootman M, 2008, BREAST CANCER RES TR, V111, P489, DOI 10.1007/s10549-007-9795-1	8	3	3	7	8	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	APR 14	2023	15	4							e37587	10.7759/cureus.37587	http://dx.doi.org/10.7759/cureus.37587			10	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	U1YS6	37193434	gold, Green Published			2024-07-03	WOS:001082835600036
C	Kwon, W; Li, ZH; Zhuang, SY; Sheng, Y; Zheng, LM; Yu, CH; Gonzalez, JE; Zhang, H; Stoica, I			ACM	Kwon, Woosuk; Li, Zhuohan; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Yu, Cody Hao; Gonzalez, Joseph E.; Zhang, Hao; Stoica, Ion			Efficient Memory Management for Large Language Model Serving with <i>PagedAttention</i>	PROCEEDINGS OF THE TWENTY-NINTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, SOSP 2023			English	Proceedings Paper	29th ACM Symposium on Operating Systems Principles (SOSP)	OCT 23-26, 2023	Meta, Koblenz, GERMANY	Assoc Comp Machinery, ACM SIGOPS, USENIX	Meta			High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2-4x with the same level of latency compared to the state-of-the-art systems, such as FasterTransformer and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. vLLM's source code is publicly available at https://github.com/vllm-project/vllm.	[Kwon, Woosuk; Li, Zhuohan; Zhuang, Siyuan; Sheng, Ying; Zheng, Lianmin; Gonzalez, Joseph E.; Stoica, Ion] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Sheng, Ying] Stanford Univ, Stanford, CA 94305 USA; [Zhang, Hao] Univ Calif San Diego, La Jolla, CA 92093 USA	University of California System; University of California Berkeley; Stanford University; University of California System; University of California San Diego	Kwon, W (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.		li, zhuohan/IZJ-4138-2023	li, zhuohan/0000-0002-9265-7151; , Ying/0000-0002-1883-2126; LI, ZHUOHAN/0009-0004-1534-9106				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amazon Web Services, 2023, US; Aminabadi RY, 2022, Arxiv, DOI [arXiv:2207.00032, DOI 10.48550/ARXIV.2207.00032]; [Anonymous], 2023, ABOUT US; [Anonymous], 1962, IRE Transactions on Electronic Computers; [Anonymous], 2022, OpenAI; Ba JL., 2016, arXiv; Bengio Y, 2001, ADV NEUR IN, V13, P932; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Chen TQ, 2016, Arxiv, DOI arXiv:1604.06174; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Crankshaw Daniel, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P477, DOI 10.1145/3419111.3421285; Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613; Cui WH, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P183; Dao T., 2022, Advances in Neural Information Processing Systems, V35, P16344, DOI [10.48550/arXiv2205.14135, DOI 10.48550/ARXIV2205.14135]; FastAPI, 2023, FastAPI; Gao P, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190541; Gholami Amir, 2021, RiseLab Medium Post, V1; Github, 2022, About us; Gujarati A, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P443; Han MC, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P539; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Huang CC, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1341, DOI 10.1145/3373376.3378530; Jain P., 2020, P MACHINE LEARNING S, V2, P497; Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li ZH, 2023, Arxiv, DOI arXiv:2302.11665; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; LMSYS ORG, 2023, Chatbot Arena Leaderboard Week 8: Introducing MT-Bench and Vicuna-33B; Ma LX, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P881; Neveol Aurelie, 2016, FINDINGS 2016 C MACH, P131; NVIDIA, 2023, NCCL: The NVIDIA Collective Communication Library; NVIDIA, 2023, Fastertransformer; NVIDIA, Triton Inference Server; Olston C, 2017, Arxiv, DOI arXiv:1712.06139; OpenAI, 2020, About us; OpenAI, 2023, ABOUT US; Paszke A, 2019, ADV NEUR IN, V32; Patil P., 2022, INT C MACHINE LEARNI, P17573; Pope Reiner, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2211.05102, 10.48550/arXiv.2211.05102]; Ren J, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P551; Reuters, 2023, about us; ShareGPT Team, 2023, About us; Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658; Sheng Y, 2023, Arxiv, DOI arXiv:2303.06865; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Steiner B, 2022, Arxiv, DOI [arXiv:2210.12924, 10.48550/arXiv.2210.12924, DOI 10.48550/ARXIV.2210.12924]; Sutskever I, 2014, ADV NEUR IN, V27; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang J, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P773; Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491; Wang XH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P113; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Yu GI, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P521; Zhang H, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P787; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zheng LM, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P559; Zhou Z, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P489	64	3	5	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0229-7				2023							611	626		10.1145/3600006.3613165	http://dx.doi.org/10.1145/3600006.3613165			16	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3BX		Green Submitted, hybrid			2024-07-03	WOS:001135072900039
J	Mahowald, K; Ivanova, AA; Blank, IA; Kanwisher, N; Tenenbaum, JB; Fedorenko, E				Mahowald, Kyle; Ivanova, Anna A.; Blank, Idan A.; Kanwisher, Nancy; Tenenbaum, Joshua B.; Fedorenko, Evelina			Dissociating language and thought in large language models	TRENDS IN COGNITIVE SCIENCES			English	Review							FLUID INTELLIGENCE; MIND NETWORKS; REPRESENTATION; LINGUISTICS; PERCEPTION; CONTRIBUTE; REGIONS; SYNTAX; MEMORY	Large language models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distinction between formal linguistic competence (knowledge of linguistic rules and patterns) and functional linguistic competence (understanding and using language in the world). We ground this distinction in human neuroscience, which has shown that formal and functional competence rely on different neural mechanisms. Although LLMs are surprisingly good at formal competence, their performance on functional competence tasks remains spotty and often requires specialized fine-tuning and/or coupling with external modules. We posit that models that use language in human -like ways would need to master both of these competence types, which, in turn, could require the emergence of separate mechanisms specialized for formal versus functional linguistic competence.	[Mahowald, Kyle] Univ Texas Austin, Austin, TX 78712 USA; [Ivanova, Anna A.] Georgia Inst Technol, Atlanta, GA 30332 USA; [Blank, Idan A.] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Kanwisher, Nancy; Tenenbaum, Joshua B.; Fedorenko, Evelina] MIT, Cambridge, MA 02139 USA	University of Texas System; University of Texas Austin; University System of Georgia; Georgia Institute of Technology; University of California System; University of California Los Angeles; Massachusetts Institute of Technology (MIT)	Mahowald, K (corresponding author), Univ Texas Austin, Austin, TX 78712 USA.; Ivanova, AA (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.; Blank, IA (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.; Kanwisher, N; Tenenbaum, JB; Fedorenko, E (corresponding author), MIT, Cambridge, MA 02139 USA.	mahowald@utexas.edu; a.ivanova@gatech.edu; iblank@psych.ucla.edu; ngk@mit.edu; jbt@mit.edu; evelina9@mit.edu			National Science Foundation (NSF) [2104995]; Quest Initiative for Intelligence; National Institutes of Health (NIH) [R01-DC016607, R01-DC016950, U01-NS121471]; Brain and Cognitive Sciences Department, McGovern Institute for Brain Research; Simons Foundation through the Simons Center for the Social Brain	National Science Foundation (NSF)(National Science Foundation (NSF)); Quest Initiative for Intelligence; National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Brain and Cognitive Sciences Department, McGovern Institute for Brain Research; Simons Foundation through the Simons Center for the Social Brain	For helpful conversations, we thank Jacob Andreas, Alex Warstadt, Dan Roberts, Kanishka Misra, students in the 2023 UT Austin Linguistics 393 seminar, the attendees of the Harvard LangCog journal club, the attendees of the UT Austin Department of Linguistics SynSem seminar, Gary Lupyan, John Krakauer, members of the Intel Deep Learning group, Yejin Choi and her group members, Allyson Ettinger, Nathan Schneider and his group members, the UT NLL Group, attendees of the KUISAI Talk Series at Koc University in Istanbul, Tom McCoy, attendees of the NYU Philosophy of Deep Learning conference, Sydney Levine, organizers and attendees of the ILFC seminar, and others who have engaged with our ideas. We also thank Aalok Sathe for help with document formatting and references. K.M. acknowledges funding from National Science Foundation (NSF) Grant 2104995. A.I. was supported by funds from the Quest Initiative for Intelligence. E.F. was supported by National Institutes of Health (NIH) awards R01-DC016607, R01-DC0169 50, and U01-NS12147 1 and by research funds from the Brain and Cognitive Sciences Department, McGovern Institute for Brain Research, and the Simons Foundation through the Simons Center for the Social Brain.	Amalric M, 2016, P NATL ACAD SCI USA, V113, P4909, DOI 10.1073/pnas.1603205113; Ambridge B, 2020, FIRST LANG, V40, P509, DOI 10.1177/0142723719869731; Andrés-Roqueta C, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00996; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 1992, Arenas of Language Use; Aronoff M., 2022, What Is Morphology; Baldassano C, 2017, NEURON, V95, P709, DOI 10.1016/j.neuron.2017.06.041; Baroni M., 2022, Algebraic Structures in Natural Language, P1; Baroni M, 2010, COMPUT LINGUIST, V36, P673, DOI 10.1162/coli_a_00016; Bates E, 2003, NAT NEUROSCI, V6, P448, DOI 10.1038/nn1050; Bates E., 1989, CROSSLINGUISTIC STUD, P3; Begus G, 2021, NEURAL NETWORKS, V139, P305, DOI 10.1016/j.neunet.2021.03.017; Belinkov Y, 2022, COMPUT LINGUIST, V48, P207, DOI 10.1162/coli_a_00422; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Benn Y, 2023, CEREB CORTEX, V33, P10380, DOI 10.1093/cercor/bhad289; Blank IA, 2023, TRENDS COGN SCI, V27, P987, DOI 10.1016/j.tics.2023.08.006; Blasi D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5486; Bommasani R, 2023, Arxiv, DOI [arXiv:2310.12941, 10.48550/arXiv.2310.12941]; Borgeaud S, 2022, PR MACH LEARN RES; Bottou L., 1990, Advances in Neural Information Processing Systems, P781; Bowman SR, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7484; Brennan JR, 2020, NEUROPSYCHOLOGIA, V146, DOI 10.1016/j.neuropsychologia.2020.107479; Bresnan J, 2007, STUD GENERAT GRAMM, V96, P75; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bucholtz Mary., 2004, A Companion to Linguistic Anthropology, P369, DOI DOI 10.1002/9780470996522.CH16; Buckner RL, 2019, NAT REV NEUROSCI, V20, P593, DOI 10.1038/s41583-019-0212-7; Cao RS, 2021, Arxiv, DOI [arXiv:2104.01490, DOI 10.48550/ARXIV.2104.01490]; Carruthers P, 2002, BEHAV BRAIN SCI, V25, P657, DOI 10.1017/S0140525X02000122; Caucheteux C, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03036-1; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chen XY, 2023, CEREB CORTEX, DOI 10.1093/cercor/bhad087; Chersoni E, 2019, NAT LANG ENG, V25, P483, DOI 10.1017/S1351324919000214; Chomsky N., 1991, The Chomskyan turn; Chomsky N., 1957, Syntactic Structures; Chronis G., 2020, P 24 C COMP NAT LANG, P227, DOI DOI 10.18653/V1/2020.CONLL-1.17; Clark A, 2014, P 5 WORKSH COGN ASP, P29; Clark H. H., 1996, USING LANGUAGE, DOI DOI 10.1017/CBO9780511620539; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cohen R, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1856; Cruse D.A., 1986, LEXICAL SEMANTICS; Dalrymple M., 2019, Argumentum, V15; Deen B, 2015, CEREB CORTEX, V25, P4596, DOI 10.1093/cercor/bhv111; Deniz F, 2019, J NEUROSCI, V39, P7722, DOI 10.1523/JNEUROSCI.0675-19.2019; Dennett D.C., 1994, What Is Inteligence? The Darwin College Lectures; Dobs K, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abl8913; Duncan J, 2010, TRENDS COGN SCI, V14, P172, DOI 10.1016/j.tics.2010.01.004; Dziri N, 2023, 37 C NEUR INF PROC S; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Elazar Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10486; ELMAN JL, 1993, COGNITION, V48, P71, DOI 10.1016/0010-0277(93)90058-4; Erk K, 2012, LANG LINGUIST COMPAS, V6, P635, DOI 10.1002/Inc3.362; Ettinger Allyson, 2016, P 1 WORKSH EV VECT S, P134; Everaert MBH, 2015, TRENDS COGN SCI, V19, P729, DOI 10.1016/j.tics.2015.09.008; Fedorenko E, 2020, COGNITION, V203, DOI 10.1016/j.cognition.2020.104348; Fedorenko E, 2016, P NATL ACAD SCI USA, V113, pE6256, DOI 10.1073/pnas.1612132113; Fedorenko E, 2016, ANN NY ACAD SCI, V1369, P132, DOI 10.1111/nyas.13046; Fedorenko E, 2011, P NATL ACAD SCI USA, V108, P16428, DOI 10.1073/pnas.1112937108; Fedorenko E, 2010, J NEUROPHYSIOL, V104, P1177, DOI 10.1152/jn.00032.2010; Ferstl EC, 2002, NEUROIMAGE, V17, P1599, DOI 10.1006/nimg.2002.1247; Fischer J, 2016, P NATL ACAD SCI USA, V113, pE5072, DOI 10.1073/pnas.1610344113; Frank MC, 2023, NAT HUM BEHAV, DOI 10.1038/s41562-023-01732-4; Gandhi K, 2023, 37 C NEUR INF PROC S; Gauthier J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P70; Georges Gabriel Charpentier L., 2023, P BABYLM CHAL 27 C C, P238; GLEITMAN LR, 1993, MOD PHILOLOGY, V90, pS13, DOI 10.1086/392120; Goldberg AE, 2019, EXPLAIN ME THIS: CREATIVITY, COMPETITION, AND THE PARTIAL PRODUCTIVITY OF CONSTRUCTIONS, P1; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Gopnik A., 1992, MIND LANGUAGE, V7, P145, DOI 10.1111/j.1468-0017.1992.tb00202.x; Gordon Jonathan, 2013, P 2013 WORKSHOP AUTO, P25, DOI [10.1145/2509558.2509563, DOI 10.1145/2509558.2509563]; Goyal A, 2022, P ICLR; Grand G, 2022, NAT HUM BEHAV, V6, P975, DOI 10.1038/s41562-022-01316-8; Grice HP., 1975, SYNTAX SEMANTICS, P41, DOI [DOI 10.1163/9789004368811_003, 10.1163/9789004368811_003]; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Hagoort P., 2014, The Cognitive Neurosciences, P667; HALLE M, 1962, WORD, V18, P54, DOI 10.1080/00437956.1962.11659765; Hauptman M, 2023, CORTEX, V162, P96, DOI 10.1016/j.cortex.2023.01.013; Heilbron M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201968119; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hosseini E.A., 2024, Neurobiol. Lang., V28, DOI [10.1162/nol-a-00137540, DOI 10.1162/NOL-A-00137540]; Hu J, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4194; Hu J, 2023, CEREB CORTEX, V33, P4384, DOI 10.1093/cercor/bhac350; Huang JY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1372; Ivanova AA, 2021, NEUROBIOL LANG, V2, P176, DOI 10.1162/nol_a_00030; Ivanova AA, 2020, ELIFE, V9, DOI 10.7554/eLife.58906; Jackendoff R, 2003, BEHAV BRAIN SCI, V26, P651, DOI 10.1017/S0140525X03000153; Jacoby Nir, 2020, Lang Cogn Neurosci, V35, P780, DOI 10.1080/23273798.2018.1525494; Jacoby N, 2016, NEUROIMAGE, V126, P39, DOI 10.1016/j.neuroimage.2015.11.025; Jain S, 2023, Neurobiol. Lang., DOI [10.1162/nol-a-00101, DOI 10.1162/NOL-A-00101]; Jouravlev O, 2019, NEUROPSYCHOLOGIA, V132, DOI 10.1016/j.neuropsychologia.2019.107132; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Keenan C., 2013, PWPL, V19, P11; Kim N., 2021, P SOC COMP LING 2021, P467; Kim N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P3835; Kim N, 2022, Arxiv, DOI [arXiv:2212.10769, 10.48550/arXiv.2212.10769]; Kim Y, 2023, NEURIPS 2023 WORKSH; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kudugunta S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P3577; Lampinen AK, 2022, Arxiv, DOI [arXiv:2210.15303, DOI 10.48550/ARXIV.2210.15303]; Lakretz Y., 2021, arXiv, DOI [10.48550/arXiv.2110.07240, DOI 10.48550/ARXIV.2110.07240]; Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Law R, 2021, J NEUROSCI, V41, P2186, DOI 10.1523/JNEUROSCI.1179-20.2021; Lederman H, 2024, Arxiv, DOI [arXiv:2401.04854, 10.48550/arXiv,2401.04854, DOI 10.48550/ARXIV,2401.04854]; Lenci A, 2023, Sistemi Intelligenti, V35, P277; Lerner Y, 2011, J NEUROSCI, V31, P2906, DOI 10.1523/JNEUROSCI.3684-10.2011; Levinson Stephen C., 2000, PRESUMPTIVE MEANINGS, DOI DOI 10.7551/MITPRESS/5526.001.0001; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Linzen T, 2019, LANGUAGE, V95, pE99, DOI 10.1353/lan.2019.0015; Linzen Tal, 2016, Transactions of the Association for Computational Linguistics, V1990, P521, DOI [10.1162/tacl_a_00115, DOI 10.1162/TACL_A_00115]; Liu B, 2023, Arxiv, DOI arXiv:2304.11477; Liu N., 2023, FINDINGS ASS COMPUTA, P7001; Liu Q, 2022, T ASSOC COMPUT LING, V10, P555, DOI 10.1162/tacl_a_00476; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2365; Liu YF, 2020, ELIFE, V9, DOI 10.7554/eLife.59340; MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676; MacSweeney M, 2002, BRAIN, V125, P1583, DOI 10.1093/brain/awf153; Mahowald K, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P265; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Mao Jiayuan, 2019, ARXIV190412584; Marcus G, 2020, Arxiv, DOI [arXiv:2002.06177, DOI 10.48550/ARXIV.2002.06177]; Martin L., 2020, P 58 ANN M ASS COMPU, P7203, DOI [DOI 10.18653/V1/2020.ACL-MAIN.645, 10.18653/v1/2020.acl-main.645,Online]; McCoy RT, 2023, Arxiv, DOI [arXiv:2309.13638, 10.48550/arXiv.2309.13638]; McCoy RT, 2023, T ASSOC COMPUT LING, V11, P652, DOI 10.1162/tacl_a_00567; McCoy RT, 2020, T ASSOC COMPUT LING, V8, P125, DOI 10.1162/tacl_a_00304; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Menenti L, 2011, PSYCHOL SCI, V22, P1173, DOI 10.1177/0956797611418347; Meng Kevin, 2022, Advances in Neural Information Processing Systems, P17359; Mialon G., 2023, arXiv; Michaud EJ, 2024, Arxiv, DOI [arXiv:2303.13506, 10.48550/arXiv.2303.13506]; Mielke SJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4975; Misra K, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P2928; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Moirangthem DS, 2020, NEURAL NETWORKS, V124, P1, DOI 10.1016/j.neunet.2019.12.022; Mollo DC, 2023, Arxiv, DOI arXiv:2304.01481; Monti MM, 2012, PSYCHOL SCI, V23, P914, DOI 10.1177/0956797612437427; Mueller A., 2022, P 26 C COMP NAT LANG, P95; Niu J., 2022, P 29 INT C COMP LING, P3143; Norvig P., 2012, Significance, V9, P30, DOI DOI 10.1111/J.1740-9713.2012.00590.X; Oh BD, 2023, T ASSOC COMPUT LING, V11, P336, DOI 10.1162/tacl_a_00548; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pallier C, 2011, P NATL ACAD SCI USA, V108, P2522, DOI 10.1073/pnas.1018711108; Patterson K, 2007, NAT REV NEUROSCI, V8, P976, DOI 10.1038/nrn2277; Paunov AM, 2022, NEUROBIOL LANG, V3, P413, DOI 10.1162/nol_a_00071; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Piantadosi S., 2023, Lingbuzz lingbuzz/007180; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; Pitt B, 2022, PSYCHOL SCI, V33, P371, DOI 10.1177/09567976211034502; Potts C., 2023, LingBuzz lingbuzz/007495; Pyers JE, 2009, PSYCHOL SCI, V20, P805, DOI 10.1111/j.1467-9280.2009.02377.x; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ravfogel S., 2021, P 25 C COMP NAT LANG, P194; Reddy A.J., 2021, Adv. Neural Inf. Proces. Syst., V34, P9843; Regev TI, 2021, bioRxiv, DOI [10.1101/2021.06.11.447786, 10.1101/2021.06.11.447786, DOI 10.1101/2021.06.11.447786, DOI 10.1101/2021.06.11.447786V1]; Ronco E., 1997, Neural networks for modelling and control; Ruan Q, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1292; Rumelhart D.E., 1986, Paralel Distributed Processing; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732; Samuel D., 2023, P BABYLM CHALLENGE 2, P221; Sap M., 2022, P 2022 C EMPIRICAL M, P3762, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.248; Saxe R, 2006, CURR OPIN NEUROBIOL, V16, P235, DOI 10.1016/j.conb.2006.03.001; Saxe R, 2003, NEUROIMAGE, V19, P1835, DOI 10.1016/S1053-8119(03)00230-1; Saxe R, 2006, PSYCHOL SCI, V17, P692, DOI 10.1111/j.1467-9280.2006.01768.x; Schick T., 2023, arXiv; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Schuster S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P969; Sclar M, 2023, Arxiv, DOI arXiv:2310.11324; Sclar M, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P13960; Scott TL, 2017, COGN NEUROSCI-UK, V8, P167, DOI 10.1080/17588928.2016.1201466; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shain C, 2020, NEUROPSYCHOLOGIA, V138, DOI 10.1016/j.neuropsychologia.2019.107307; Shapira N, 2023, Arxiv, DOI arXiv:2305.14763; Srivastava Aarohi, 2022, arXiv; Su JL, 2024, NEUROCOMPUTING, V568, DOI 10.1016/j.neucom.2023.127063; Sutskever I., 2011, Proceedings of the 28th International Conference on Machine Learning (ICML-11), P1017; Tayyar Madabushi Harish., 2020, Proceedings of the 28th International Conference on Computational Linguistics, P4020; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Tirumala K., 2022, Advances in Neural Information Processing Systems, V35, P38274; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Tseng YH, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6361; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Valmeekam K, 2022, NEURIPS 2022 FDN MOD; Van Dijk T. A., 1983, STRATEGIES DISCOURSE; van Schijndel M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5831; van Schijndel M, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12988; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vig J, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P63; Wallach H. M., 2019, Advances in Neural Information Processing Systems, P5901; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wang ZH, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2649; Warstadt A., 2023, P BABYLM CHAL 27 C C, P1; Warstadt A., 2022, Algebraic structures in natural language, P17, DOI [10.1201/9781003205388-2, DOI 10.1201/9781003205388-2]; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Waxman S.R., 2002, Blackwell handbook of childhood cognitive development, P102, DOI DOI 10.1002/9780470996652.CH5; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Weissweiler L., 2023, P 1 INT WORKSH CONST, P85; Weissweiler L., 2022, P 2022 C EMP METH NA, P10859; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wilcox E.G, 2022, Linguist. Inq., DOI [10.1162/ling-a-00491, DOI 10.1162/LING-A-00491]; Wilson SM, 2019, J SPEECH LANG HEAR R, V62, P3937, DOI 10.1044/2019_JSLHR-L-RSNP-19-0031; Wong L, 2023, Arxiv, DOI [arXiv:2306.12672, 10.48550/arXiv.2306.12672, DOI 10.48550/ARXIV.2306.12672]; Woolgar A, 2018, NAT HUM BEHAV, V2, P200, DOI 10.1038/s41562-017-0282-3; Woolgar A, 2010, P NATL ACAD SCI USA, V107, P14899, DOI 10.1073/pnas.1007928107; Wu ZF, 2023, Arxiv, DOI [arXiv:2307.02477, 10.48550/arXiv.2307.02477]; Yang GR, 2019, NAT NEUROSCI, V22, P297, DOI 10.1038/s41593-018-0310-2; Yedetore A, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P9370; Yildirim I, 2023, Arxiv, DOI [arXiv:2310.04276, 10.48550/arXiv.2310.04276, DOI 10.48550/ARXIV.2310.04276]; Yiu E, 2023, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916231201401; Yu C, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4040; Zhang H., 2023, P 32 INT JOINT C ART, P3365, DOI 10.24963/IJCAI.2023/; Zhou Y., 2022, Advances in Neural Information Processing Systems, V35, P7103	216	1	1	7	7	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	1364-6613	1879-307X		TRENDS COGN SCI	TRENDS COGN. SCI.	JUN	2024	28	6					517	540		10.1016/j.tics.2024.01.011	http://dx.doi.org/10.1016/j.tics.2024.01.011			24	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	UT1T1	38508911	Green Submitted			2024-07-03	WOS:001250223800001
J	Kumar, P				Kumar, Pranjal			Adversarial attacks and defenses for large language models (LLMs): methods, frameworks & challenges	INTERNATIONAL JOURNAL OF MULTIMEDIA INFORMATION RETRIEVAL			English	Article						Adversarial attacks; Artificial intelligence; Natural language processing; Machine learning; Neural networks; Large language models; ChatGPT; GPT	COMPUTER VISION	Large language models (LLMs) have exhibited remarkable efficacy and proficiency in a wide array of NLP endeavors. Nevertheless, concerns are growing rapidly regarding the security and vulnerabilities linked to the adoption and incorporation of LLM. In this work, a systematic study focused on the most up-to-date attack and defense frameworks for the LLM is presented. This work delves into the intricate landscape of adversarial attacks on language models (LMs) and presents a thorough problem formulation. It covers a spectrum of attack enhancement techniques and also addresses methods for strengthening LLMs. This study also highlights challenges in the field, such as the assessment of offensive or defensive performance, defense and attack transferability, high computational requirements, embedding space size, and perturbation. This survey encompasses more than 200 recent papers concerning adversarial attacks and techniques. By synthesizing a broad array of attack techniques, defenses, and challenges, this paper contributes to the ongoing discourse on securing LM against adversarial threats.	[Kumar, Pranjal] Lovely Profess Univ, Sch Comp Sci & Engn, Dept Intelligent Syst, Phagwara 144411, Punjab, India	Lovely Professional University	Kumar, P (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Dept Intelligent Syst, Phagwara 144411, Punjab, India.	pranjal@nith.ac.in						Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Abdelali A, 2024, P 18 C EUR CHAPT ASS, V1, P487; Abdullah Hadi, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P730, DOI 10.1109/SP40001.2021.00014; Abe N, 2004, P 10 ACM SIGKDD INT, P3; Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54; Akhtar N, 2021, IEEE ACCESS, V9, P155161, DOI 10.1109/ACCESS.2021.3127960; Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385; Alotaibi A, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15020062; Alsmadi I, 2022, IEEE ACCESS, V10, P17043, DOI 10.1109/ACCESS.2022.3146405; Alwahedi F, 2024, Internet Things Cyber Phys Syst, DOI [10.1016/j.iotcps.2023.12.003, DOI 10.1016/J.IOTCPS.2023.12.003]; Alzantot M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2890; [Anonymous], 2017, On the (statistical) detection of adversarial examples; Antoun W, 2023, ACT CORIA TALN 2023, V1; Athalye A, 2018, PR MACH LEARN RES, V80; Bajaj A, 2023, NEUROCOMPUTING, V558, DOI 10.1016/j.neucom.2023.126787; Bakhtin A, 2019, Arxiv, DOI arXiv:1906.03351; Bang Y, 2023, P 13 INT JOINT C NAT, P675, DOI [DOI 10.18653/V1/2023.IJCNLP--MAIN.45, DOI 10.18653/V1/2023.IJCNLP-MAIN.45]; Bao RZ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3248; Barham S, 2019, Arxiv, DOI arXiv:1905.12864; Bastings J, 2020, P 3 BLACKBOXNLP WORK, P149, DOI [DOI 10.18653/V1/2020.BLACKBOXNLP-1.14, 10.18653/v1/2020.blackboxnlp-1.14]; Bhattacharjee A, 2023, P 13 INT JOINT C NAT, V1; Birbil SI, 2004, J GLOBAL OPTIM, V30, P301, DOI 10.1007/s10898-004-8270-3; Blum Oliver, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P199, DOI 10.1007/978-3-030-12939-2_15; Boffa M, 2024, COMPUT SECUR, V141, DOI 10.1016/j.cose.2024.103805; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Brown G, 2021, ACM S THEORY COMPUT, P123, DOI 10.1145/3406325.3451131; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buckman J, 2018, INT C LEARN REPR; Carlini N, 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444; Carlini N, 2023, Arxiv, DOI arXiv:2307.15008; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Caucheteux C, 2021, BioRxiv, P2021; Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312; Chen DF, 2020, AAAI CONF ARTIF INTE, V34, P3430; Chen J, 2018, ICML, P883; Chen K, 2022, INT C LEARN REPR; Chen MS, 2024, IEEE ACCESS, V12, P39081, DOI 10.1109/ACCESS.2024.3356568; Chen QB, 2022, Arxiv, DOI arXiv:2201.08702; Chen XJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188450; Chen Y., 2024, ACM Trans Knowl Discov Data, DOI [10.1145/3654674, DOI 10.1145/3654674]; Chen YQ, 2023, EUR PHYS J C, V83, DOI 10.1140/epjc/s10052-023-11486-y; Chen YF, 2023, 39TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2023, P366, DOI 10.1145/3627106.3627196; Chen YT, 2023, Arxiv, DOI arXiv:2305.07969; Cheng MH, 2020, AAAI CONF ARTIF INTE, V34, P3601; Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602; Chia YK, 2024, P 1 ED WORKSH SCAL B, P35; Choi M, 2023, P 2023 C EMP METH NA, P11370; Cohen J, 2019, PMLR, P1310; Coleman C., 2017, Training, V100, P102; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Costa JC, 2024, IEEE Access; Dagan Y, 2020, PMLR, P1389; Das RK, 2020, INTERSPEECH, P4213, DOI 10.21437/Interspeech.2020-1052; Demontis A, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P321; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhillon GS, 2018, STOCHASTIC ACTIVATIO; Dong X, 2021, INT C LEARN REPR; Dong X, 2022, Adversarial attacks and defenses in natural language processing; Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z; Duan H, 2023, 61 ANN M ASS COMP LI; Dupuy C, 2022, INT CONF ACOUST SPEE, P4118, DOI 10.1109/ICASSP43922.2022.9746975; Durmus E, 2024, Arxiv, DOI arXiv:2306.16388; Dvijotham K, 2018, Arxiv, DOI arXiv:1805.10265; Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14; Ebrahimi J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P31; Fagni T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251415; Feldman V., 2020, Advances in Neural Information Processing Systems, V33, P2881; Feng S, 2021, Collaborative group learning; Fu Y, 2023, Arxiv, DOI arXiv:2305.17306; Fursov I, 2022, IEEE ACCESS, V10, P17966, DOI 10.1109/ACCESS.2022.3148413; Gan WC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6065; Gao J, 2018 IEEE SEC PRIV W, P50; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Garg S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6174; Gehman S, 2020, FINDINGS ASS COMPUTA, P3356; Gekhman Z, 2023, 2023 C EMP METH NAT; Ghojogh B, 2020, PREPRINT; Glockner M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P650; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Gong Z, 2018, Adversarial texts with gradient methods; Gong ZT, 2023, PROCEEDINGS OF THE SIXTH INTERNATIONAL WORKSHOP ON EXPLOITING ARTIFICIAL INTELLIGENCE TECHNIQUES FOR DATA MANAGEMENT, AIDM 2023, DOI 10.1145/3593078.3593935; Gowal S, 2019, Arxiv, DOI arXiv:1810.12715; Goyal S, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3593042; Guo C, 2018, 6 INT C LEARN REPR I; Guo C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5747; Gupta M, 2023, IEEE ACCESS, V11, P80218, DOI 10.1109/ACCESS.2023.3300381; Han X, 2021, AI OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002; He P, 2020, ICLR; He XL, 2024, Arxiv, DOI arXiv:2404.19597; Heilbron M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201968119; Honovich O, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P161; Hu SS, 2019, IEEE COMMUN MAG, V57, P120, DOI 10.1109/MCOM.2019.1900006; Huang PS, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4083; Huber L, 2022, PROCEEDINGS OF THE 7TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P156; Jain N, 2024, Baseline defenses for adversarial attacks against aligned language models; Jasser J, 2022, Arxiv, DOI arXiv:2111.10272; Jia R, 2017, P 2017 C EMPIRICAL M, P2021, DOI [10.18653/v1/D17-1215, DOI 10.18653/V1/D17-1215, DOI 10.18653/V1/D17-1215.URL]; Jia R., 2020, Building robust natural language processing systems; Jia R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4129; Jiang WB, 2023, PROC CVPR IEEE, P8133, DOI 10.1109/CVPR52729.2023.00786; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Kawaguchi K., 2022, Mathematical aspects of deep learning; Keraghel I, 2024, INT S INT DAT AN, P205; Khatiri S, 2024, SOFTWAREX, V27, DOI 10.1016/j.softx.2024.101748; Khormali A, 2020, Arxiv, DOI arXiv:2007.00146; Krishna K, 2020, INT C LEARN REPR; Kumar A, 2024, Arxiv, DOI arXiv:2309.02705; Kumar S, 2022, BioRxiv, P2022; Kurita K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2793; La Malfa E, 2023, On robustness for natural language processing; Lai VD, 2023, FINDINGS ASS COMPUTA, P13171; Laidlaw C, 2019, ADV NEUR IN, V32; Lan X, 2018, ADV NEUR IN, V31; Lecuyer M, 2019, P IEEE S SECUR PRIV, P656, DOI 10.1109/SP.2019.00044; Lee D, 2022, PR MACH LEARN RES; Lei Qi Wu., 2019, Proc Mach Learn Syst, V1, P146; Li H, 2023, FINDINGS ASS COMPUTA, P4138; Li JF, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23138; Li LY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3023; Li L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6193; Li X., 2021, INT C LEARN REPR; Li XD, 2012, IEEE T EVOLUT COMPUT, V16, P210, DOI 10.1109/TEVC.2011.2112662; Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615; Li YF, 2023, Arxiv, DOI arXiv:2305.13242; Li Z, 2020, P AS C COMP VIS; Li Z, 2024, P AAAI C ART INT, V38, P18608; Liang B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4208; Lim S, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1129082; Lin JY, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P333; Lin Y., 2023, P 5 WORKSH NLP CONV, P47, DOI DOI 10.18653/V1/2023; Liu B., 2023, Secur Commun Netw, V1; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu X, 2020, arXiv; Liu X, 2023, Coco: coherence-enhanced machine-generated text detection under low resource with contrastive learning, P16167; Liu XD, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P118; Liu Y, 2023, Socially Responsible Language Modelling Research; Liu Y, 2023, Arxiv, DOI arXiv:2306.05499; Liu YK, 2023, Arxiv, DOI arXiv:2304.07666; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Liu YY, 2023, NEUROCOMPUTING, V550, DOI 10.1016/j.neucom.2023.126489; Liu ZY, 2024, Arxiv, DOI arXiv:2306.05524; Livne M, 2024, CHEM SCI, V15, P8380, DOI 10.1039/d4sc00966e; Lopez-Lira A, 2023, Return predictability and large language models; Luong MT, 2016, 4 INT C LEARN REPR I; Ma X., 2023, Advances in neural information processing systems, V36, P21702; Madry Aleksander, 2018, INT C LEARN REPR; Maheshwary R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8396; Maheshwary R, 2021, AAAI CONF ARTIF INTE, V35, P13525; Majmudar J, 2022, Differentially private decoding in large language models; Maus N, 2023, Arxiv, DOI arXiv:2302.04237; Mewada A, 2023, J SUPERCOMPUT, V79, P5516, DOI 10.1007/s11227-022-04881-x; Minh DN, 2022, P 2022 C EMP METH NA, P6612; Mirman M, 2018, PMLR, P3578; Miyato T, 2021, Arxiv, DOI arXiv:1605.07725; Mnassri K, 2024, ENTROPY-SWITZ, V26, DOI 10.3390/e26040344; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Mounsif M, 2023, INT CONF SOFT COMP, P171, DOI 10.1109/ISCMI59957.2023.10458573; Mrksic N, 2016, P 2016 C N AM CHAPT, P142, DOI [10.18653/v1/N16-1018, DOI 10.18653/V1/N16-1018]; Myers D, 2024, CLUSTER COMPUT, V27, P1, DOI 10.1007/s10586-023-04203-7; Narang S, 2018, INT C LEARN REPR; Nazir A, 2024, SOFTW IMPACTS, V19, DOI 10.1016/j.simpa.2024.100619; Omar M, 2022, IEEE ACCESS, V10, P86038, DOI 10.1109/ACCESS.2022.3197769; Papernot N, 2016, IEEE MILIT COMMUN C, P49, DOI 10.1109/MILCOM.2016.7795300; Parkhi O., 2015, BMVC 2015; Peng H, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.03.017; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Peris C, 2023, P 16 ACM INT C WEB S, P1291; Pruthi D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5582; Qi FC, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9558; Qi X, 2024, P AAAI C ARTIFICIAL, V38, P21527; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raghunathan A, 2018, P 6 INT C LEARN REPR; Raghunathan A, Adv Neural Inf Process Syst, V31; Raiaan MAK, 2024, IEEE ACCESS, V12, P26839, DOI 10.1109/ACCESS.2024.3365742; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Rame A., 2021, ICLR 2021; Rane NL., 2023, Int Res J Mod Eng Technol Sci, V5, P875; Ren SH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1085; Ribeiro MT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P856; Roshan K, 2024, COMPUT SECUR, V141, DOI 10.1016/j.cose.2024.103853; Roth T, 2024, AI Commun, P1; Ruder S, 2019, AAAI CONF ARTIF INTE, P4822; Sadrizadeh S, 2022, INT CONF ACOUST SPEE, P7837, DOI 10.1109/ICASSP43922.2022.9747475; Salman H, 2019, Adv Neural Inf Process Syst, V32; Sang EF, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195; Saon G, 2017, INTERSPEECH, P132, DOI 10.21437/Interspeech.2017-405; Sato M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4323; Shafahi A, 2019, ADV NEUR IN, V32; Shen LJ, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P3141, DOI 10.1145/3460120.3485370; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Shrikumar A, 2017, PR MACH LEARN RES, V70; Singla S, 2020, P MACHINE LEARNING R, P8981; Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58; Song S, 2013, IEEE GLOB CONF SIG, P245, DOI 10.1109/GlobalSIP.2013.6736861; Steinhardt J, 2017, ADV NEUR IN, V30; Sundararajan M, 2017, PR MACH LEARN RES, V70; Sutskever I, 2014, ADV NEUR IN, V27; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Szeghy D, 2021, Adversarial perturbation stability of the layered group basis pursuit, P2; Le T, 2020, IEEE DATA MINING, P282, DOI [10.1109/CSCI51800.2020.00054, 10.1109/ICDM50108.2020.00037]; Tsiligkaridis T, 2022, PROC CVPR IEEE, P50, DOI 10.1109/CVPR52688.2022.00015; Uchendu A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8384; Uesato J., 2018, ADVERSARIAL RISK DAN, P5025; Ullah S, 2024, IEEE S SEC PRIV; Vassilev Apostol., 2024, Adversarial machine learning, DOI [10.6028/NIST.AI.100-2e2023, DOI 10.6028/NIST.AI.100-2E2023]; Vaswani A, 2017, ADV NEUR IN, V30; Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2153; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang B, 2023, Towards trustworthy large language models; Wang B, 2022, FINDINGS ASS COMPUTA, P176; Wang BX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6134; Wang Q, 2019, INTERSPEECH, P4010, DOI 10.21437/Interspeech.2019-2983; Wang T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5141; Wang W., 2024, Adv Neural Inf Process Syst, V36, P61501; Wang WJ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1102; Wang WQ, 2023, IEEE T KNOWL DATA EN, V35, P3159, DOI 10.1109/TKDE.2021.3117608; Wang YL, 2023, IEEE COMMUN SURV TUT, V25, P2245, DOI 10.1109/COMST.2023.3319492; Wang YT, 2023, IEEE OPEN J COMP SOC, V4, P280, DOI 10.1109/OJCS.2023.3300321; Wei A., 2024, Adv Neural Inf Process Syst, V36, P80079; Wei C., 2021, Adv Neural Inf Process Syst, V34, P16158; Wong E., 2020, INT C LEARN REPR; Wong Eric, 2018, INT C MACH LEARN, P5286; Wu C, 2023, CHIN HLTH INF PROC C, P214; Wu GL, 2021, AAAI CONF ARTIF INTE, V35, P10302; Wu JC, 2024, Arxiv, DOI arXiv:2310.14724; Wu XS, 2024, Arxiv, DOI arXiv:2403.08946; Xie X., 2024, Vis Intell, V2, P11, DOI [10.1007/s44267-024-00043-0, DOI 10.1007/S44267-024-00043-0]; Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x; Xu X, 2024, 12 INT C LEARN REPR; Xue J., 2024, Adv Neural Inf Process Syst, V36, P65665; Yan YM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P5065; Yang H, 2023, MATH PROGRAM, V201, P409, DOI 10.1007/s10107-022-01912-6; Yang J., 2024, ACM Transactions on Knowledge Discovery from Data, V18, P1, DOI 10.1145/3653304; Yang Q, 2018, IEEE T EVOLUT COMPUT, V22, P578, DOI 10.1109/TEVC.2017.2743016; Yang YQ, 2023, ARTIF INTELL REV, V56, P5545, DOI 10.1007/s10462-022-10283-5; Yao YF, 2024, HIGH-CONFID COMPUT, V4, DOI 10.1016/j.hcc.2024.100211; Ye M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3465; Yoo JY, 2020, P 3 BLACKBOXNLP WORK, P323; Yoo K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3656; Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017; Yuan L, 2024, Adv Neural Inf Process Syst, V36; Yuan LP, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1612; Yuan LP, 2021, Arxiv, DOI arXiv:2103.11578; Zang Y, 2020, P 58 ANN M ASS COMP, P6066, DOI DOI 10.18653/V1/2020.ACL-MAIN.540; Zang Y, 2020, Arxiv, DOI arXiv:2009.09192; Zhang D, 2019, Adv Neural Inf Process Syst, V32; Zhang WE, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3374217; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454; Zhang Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1298; Zhang Z, 2023, Arxiv, DOI arXiv:2307.07171; Zhang ZY, 2023, MACH INTELL RES, V20, P180, DOI 10.1007/s11633-022-1377-5; Zhao H, 2022, P MACHINE LEARNING R, P26958; Zhao Y, 2014, Adv Neural Inf Process Syst, V36, P54111; Zhong WJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2461; Zou A, 2023, Universal and transferable adversarial attacks on aligned language models; Zuccon G, 2023, ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL IN THE ASIA PACIFIC REGION, SIGIR-AP 2023, P46, DOI 10.1145/3624918.3625329	257	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	2192-6611	2192-662X		INT J MULTIMED INF R	Int. J. Multimed. Inf. Retr.	SEP	2024	13	3							26	10.1007/s13735-024-00334-8	http://dx.doi.org/10.1007/s13735-024-00334-8			28	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	WI1T1					2024-07-03	WOS:001254154900001
J	Perkins, M				Perkins, Mike			Academic Integrity considerations of AI Large Language Models in the post-pandemic era: ChatGPT and beyond	JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE			English	Article						Artificial Intelligence; Large Language Models; GPT-3; ChatGPT; plagiarism	WRITING ASSISTANCE; PLAGIARISM; COULD	This paper explores the academic integrity considerations of students' use of Artificial Intelligence (AI) tools using Large Language Models (LLMs) such as ChatGPT in formal assessments. We examine the evolution of these tools, and highlight the potential ways that LLMs can support in the education of students in digital writing and beyond, including the teaching of writing and composition, the possibilities of co-creation between humans and AI, supporting EFL learners, and improving Automated Writing Evaluations (AWE). We describe and demonstrate the potential that these tools have in creating original, coherent text that can avoid detection by existing technological methods of detection and trained academic staff alike, demonstrating a major academic integrity concern related to the use of these tools by students. Analysing the various issues related to academic integrity that LLMs raise for both Higher Education Institutions (HEIs) and students, we conclude that it is not the student use of any AI tools that defines whether plagiarism or a breach of academic integrity has occurred, but whether any use is made clear by the student. Deciding whether any particular use of LLMs by students can be defined as academic misconduct is determined by the academic integrity policies of any given HEI, which must be updated to consider how these tools will be used in future educational environments.	[Perkins, Mike] British Univ, Hanoi, Vietnam		Perkins, M (corresponding author), British Univ, Hanoi, Vietnam.	mgperkins@gmail.com						Abd-Elaal ES, 2022, EUR J ENG EDUC, V47, P725, DOI 10.1080/03043797.2022.2046709; Alarie B, 2021, LAW TECHNOL HUMANS, V3, P5, DOI 10.5204/lthj.2089; Allen L.K., 2016, HDB WRITING RES, V2nd, P316, DOI DOI 10.1007/S11145-008-9121-2; Amigud A, 2020, STUD HIGH EDUC, V45, P692, DOI 10.1080/03075079.2018.1564258; Amzalag M, 2022, J ACAD ETHICS, V20, P243, DOI 10.1007/s10805-021-09413-5; [Anonymous], 2006, College Student Journal; Anson C. M., 2022, Composition Studies, V50, P37; Bearman M., 2020, Reimagining university assessment in a digital world, V7, P37, DOI [DOI 10.1007/978-3-030-41956-14, 10.1007/978-3-030-41956-1_4, DOI 10.1007/978-3-030-41956-1_4]; Biderman S, 2022, Arxiv, DOI [arXiv:2201.07406, 10.48550/arXiv.2201.07406, DOI 10.48550/ARXIV.2201.07406]; Biermann OC, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1209, DOI 10.1145/3532106.3533506; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brockman G., 2022, TWITTER; Cavaleri M, 2016, J ACAD LANG LEARN, V10, pA223; Chen MH, 2015, COMPUT ASSIST LANG L, V28, P22, DOI 10.1080/09588221.2013.783873; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Clarke O., 2023, HIGH EDUC, V85, P247, DOI [10.1007/s10734-022-00830-y, DOI 10.1007/S10734-022-00830-Y]; Cope B, 2021, EDUC PHILOS THEORY, V53, P1229, DOI 10.1080/00131857.2020.1728732; Curtis G.J., 2022, CHEATING ACAD INTEGR, P11; Dale R, 2021, NAT LANG ENG, V27, P511, DOI 10.1017/S1351324921000164; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dinneen C., 2021, English Australia, V37, P40, DOI [10.3316/informit.748262877947586, DOI 10.3316/INFORMIT.748262877947586]; Eaton S. E., 2021, ARTIF INTELL; Fatemi G, 2020, J FURTH HIGH EDUC, V44, P1305, DOI 10.1080/0309877X.2019.1683521; Fitria T. N., 2021, Metathesis: Journal of English Language, Literature, and Teaching, V5, P65, DOI DOI 10.31002/METATHESIS.V5I1.3519; Fröhling L, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.443; Fu QK, 2024, COMPUT ASSIST LANG L, V37, P179, DOI 10.1080/09588221.2022.2033787; Furze L., 2022, CAN AI CRITIQUE HUMA; Gayed J. M., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100055; Gehrmann S, 2019, Arxiv, DOI arXiv:1906.04043; Godwin-Jones R, 2022, LANG LEARN TECHNOL, V26, P5, DOI 10.10125/73474; Grammarly, 2022, INN BAS ACH SUP PREC; Gunser V. E., 2021, Communications in Computer and Information Science, V1419, P520, DOI [10.1007/978-3-030-78635-9_67, DOI 10.1007/978-3-030-78635-9_67]; Henderson M, 2023, ASSESS EVAL HIGH EDU, V48, P980, DOI 10.1080/02602938.2022.2144802; Hern A., 2022, GUARDIAN        1204; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Ippolito D, 2020, Arxiv, DOI arXiv:1911.00650; Jenkins BD, 2023, TEACH PSYCHOL, V50, P407, DOI 10.1177/00986283211059067; Kansara S, 2023, OPER MANAGE RES, V16, P450, DOI 10.1007/s12063-022-00270-y; Kaqinari T, 2021, J UNIV TEACH LEARN P, V18; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Kozma R. B., 1991, Computers and Composition, V8, P31, DOI 10.1016/8755-4615(91)80046-G; Kumar R., 2022, CANADIAN SOC STUDY H; Lancaster T, 2021, INT J EDUC INTEGR, V17, DOI 10.1007/s40979-021-00070-0; Langston J., 2021, AI BLOG 1102; Lanier MM, 2006, J CRIM JUSTICE EDUC, V17, P244, DOI 10.1080/10511250600866166; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Lee Y, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022), P62; Lim K, 2023, NAT LANG ENG, V29, P1341, DOI 10.1017/S1351324922000298; Lin SPN, 2022, Arxiv, DOI [arXiv:2205.14334, 10.48550/ARXIV.2205.14334]; Luitse D, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211047734; Malesky L.A., 2016, College Teaching, V64, P178; Marche Stephen, 2022, The Atlantic6 December; McKnight L, 2021, CHANG ENGL, V28, P442, DOI 10.1080/1358684X.2021.1941768; Miller A., 2012, J INSTR PSYCHOL, V39; Nassim D., 2021, ETHICS SCI ENV POLIT, V21, P17; Nazari N, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07014; Nobles Susanne, 2015, Computers and Composition, V38, P16, DOI 10.1016/j.compcom.2015.09.001; O'Neill R, 2019, AUSTRALAS J EDUC TEC, V35, P42, DOI 10.14742/ajet.3795; OpenAi, ChatGPT; OpenAI, DALLE2; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Palmquist M., 2003, Computer and Composition, V20, P395, DOI 10.1016/j.compcom.2003.08.013; Park J.-H., 2020, KOREAN J APPL LINGUI, V36, P97, DOI 10.17154/kjal.2020.3.36.1.97; Parkinson AL, 2022, ASSESS EVAL HIGH EDU, V47, P1416, DOI 10.1080/02602938.2022.2040947; Perkins M., 2019, Pan-Pacific Management Science, V2, P1; Perkins M, 2018, J ACAD ETHICS, V16, P317, DOI 10.1007/s10805-018-9311-8; Prentice FM, 2018, INT J EDUC INTEGR, V14, DOI 10.1007/s40979-018-0036-7; Price M, 2002, COLL COMPOS COMMUN, V54, P88, DOI 10.2307/1512103; QuillBot, IS US PAR TOOL PLAG; QuillBot, CAN I US QUILLBOT PL; Rapanta C., 2021, Postdigital Science and Education, P715, DOI [10.1007/s42438-021-00249-1, DOI 10.1007/S42438-021-00249-1]; Reedy A, 2021, INT J EDUC INTEGR, V17, DOI 10.1007/s40979-021-00075-9; Risko EF, 2016, TRENDS COGN SCI, V20, P676, DOI 10.1016/j.tics.2016.07.002; Roe J, 2022, INT J EDUC INTEGR, V18, DOI 10.1007/s40979-022-00109-w; Rogerson AM, 2017, INT J EDUC INTEGR, V13, DOI 10.1007/s40979-016-0013-y; Sanh V, 2022, arXiv; Schulman J, 2022, Introducing chatgpt; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Sparrow J., 2022, GUARDIAN 1118; St-Onge C, 2022, BRIT J EDUC TECHNOL, V53, P349, DOI 10.1111/bjet.13169; Strobl C, 2019, COMPUT EDUC, V131, P33, DOI 10.1016/j.compedu.2018.12.005; Stuber-McEwen D., 2009, Online Journal of Distance Learning Administration, V12; Sun YC, 2013, J ENGL ACAD PURP, V12, P264, DOI 10.1016/j.jeap.2013.07.002; Tertiary Education Quality and Standards Agency, 2020, WHAT IS AC INT; Vargo D, 2021, HUM BEHAV EMERG TECH, V3, P13, DOI 10.1002/hbe2.242; Vaswani A, 2017, ADV NEUR IN, V30; Wahle JP, 2022, Arxiv, DOI arXiv:2210.03568; Wahle JP, 2022, LECT NOTES COMPUT SC, V13192, P393, DOI 10.1007/978-3-030-96957-8_34; Wahle JP, 2021, ACM-IEEE J CONF DIG, P226, DOI 10.1109/JCDL52503.2021.00065; Walsh LL, 2021, INT J EDUC INTEGR, V17, DOI 10.1007/s40979-021-00089-3; Warschauer M, 2008, PEDAGOGIES, V3, P22, DOI 10.1080/15544800701771580; Watson G., 2010, ONLINE J DISTANCE LE; Wilder N., 2021, EUR C AC INT PLAG, P179; Zhang Q, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23004; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao X, 2023, RELC J, V54, P890, DOI 10.1177/00336882221094089	96	105	108	76	396	UNIV WOLLONGONG	WOLLONGONG	NORTHFIELDS AVE, WOLLONGONG, NSW 2522, AUSTRALIA	1449-9789			J UNIV TEACH LEARN P	J. Univ. Teach. Learn. Pract.		2023	20	2							07	10.53761/1.20.02.07	http://dx.doi.org/10.53761/1.20.02.07			26	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	9E9CG		gold			2024-07-03	WOS:000937075200011
J	Laios, A; Theophilou, G; De Jong, D; Kalampokis, E				Laios, Alexandros; Theophilou, Georgios; De Jong, Diederick; Kalampokis, Evangelos			The Future of AI in Ovarian Cancer Research: The Large Language Models Perspective	CANCER CONTROL			English	Editorial Material						Large Language Models; Artificial Intelligence; Ovarian Cancer; GPT-4		Conversational large language model (LLM)-based chatbots utilize neural networks to process natural language. By generating highly sophisticated outputs from contextual input text, they revolutionize the access to further learning, leading to the development of new skills and personalized interactions. Although they are not developed to provide healthcare, their potential to address biomedical issues is rather unexplored. Healthcare digitalization and documentation of electronic health records is now developing into a standard practice. Developing tools to facilitate clinical review of unstructured data such as LLMs can derive clinical meaningful insights for ovarian cancer, a heterogeneous but devastating disease. Compared to standard approaches, they can host capacity to condense results and optimize analysis time. To help accelerate research in biomedical language processing and improve the validity of scientific writing, task-specific and domain-specific language models may be required. In turn, we propose a bespoke, proprietary ovarian cancer-specific natural language using solely in-domain text, whereas transfer learning drifts away from the pretrained language models to fine-tune task-specific models for all possible downstream applications. This venture will be fueled by the abundance of unstructured text information in the electronic health records resulting in ovarian cancer research ultimately reaching its linguistic home.	[Laios, Alexandros; Theophilou, Georgios; De Jong, Diederick] St James Univ Hosp, ESGO Ctr Excellence Ovarian Canc Surg, Dept Gynaecol Oncol, Leeds, England; [Kalampokis, Evangelos] Univ Macedonia, Dept Business Adm, Informat Syst Lab, Thessaloniki, Greece; [Laios, Alexandros] St James Univ Hosp, ESGO Ctr Excellence Ovarian Canc Surg, Dept Gynaecol Oncol, Leeds LS9 7TF, England	Saint James's University Hospital; University of Macedonia; Saint James's University Hospital	Laios, A (corresponding author), St James Univ Hosp, ESGO Ctr Excellence Ovarian Canc Surg, Dept Gynaecol Oncol, Leeds LS9 7TF, England.	a.laios@nhs.net	de Jong, Diederick/AAK-2586-2021; Laios, Alexandros/AAN-9433-2020	de Jong, Diederick/0000-0003-0081-674X; Laios, Alexandros/0000-0002-4870-7393				Barber EL, 2021, GYNECOL ONCOL, V160, P182, DOI 10.1016/j.ygyno.2020.10.004; Boetto E, 2021, J MED ETHICS, V47, DOI 10.1136/medethics-2020-106639; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Holzinger A, 2023, NEW BIOTECHNOL, V74, P16, DOI 10.1016/j.nbt.2023.02.001; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Kostick-Quenet KM, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00737-z; Laios A, 2022, CANCERS, V14, DOI 10.3390/cancers14143447; Laios A, 2022, J PERS MED, V12, DOI 10.3390/jpm12040607; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; OpenAI, OPENAI MOD GPT 3; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887	11	3	3	12	23	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1073-2748	1526-2359		CANCER CONTROL	Cancer Control	AUG	2023	30								10732748231197915	10.1177/10732748231197915	http://dx.doi.org/10.1177/10732748231197915			4	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	R5MX9	37624621	gold, Green Published			2024-07-03	WOS:001064803500001
C	Bao, KQ; Zhang, JZ; Zhang, Y; Wang, WJ; Feng, FL; He, XN			ACM	Bao, Keqin; Zhang, Jizhi; Zhang, Yang; Wang, Wenjie; Feng, Fuli; He, Xiangnan			TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Recommendation; Instruction Tuning; Large Language Models	NETWORK	Large Language Models (LLMs) have demonstrated remarkable performance across diverse domains, thereby prompting researchers to explore their potential for use in recommendation systems. Initial attempts have leveraged the exceptional capabilities of LLMs, such as rich knowledge and strong generalization through In-context Learning, which involves phrasing the recommendation task as prompts. Nevertheless, the performance of LLMs in recommendation tasks remains suboptimal due to a substantial disparity between the training tasks for LLMs and recommendation tasks, as well as inadequate recommendation data during pre-training. To bridge the gap, we consider building a Large Recommendation Language Model by tunning LLMs with recommendation data. To this end, we propose an efficient and effective Tuning framework for Aligning LLMs with Recommendations, namely TALLRec. We have demonstrated that the proposed TALLRec framework can significantly enhance the recommendation capabilities of LLMs in the movie and book domains, even with a limited dataset of fewer than 100 samples. Additionally, the proposed framework is highly efficient and can be executed on a single RTX 3090 with LLaMA-7B. Furthermore, the fine-tuned LLM exhibits robust cross-domain generalization. Our code and data are available at https://github.com/SAI990323/TALLRec.	[Bao, Keqin; Zhang, Jizhi; Zhang, Yang; Feng, Fuli; He, Xiangnan] Univ Sci & Technol China, Hefei, Peoples R China; [Wang, Wenjie] Natl Univ Singapore, Singapore, Singapore	Chinese Academy of Sciences; University of Science & Technology of China, CAS; National University of Singapore	Feng, FL; He, XN (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	baokq@mail.ustc.edu.cn; cdzhangjizhi@mail.ustc.edu.cn; zy2015@mail.ustc.edu.cn; wenjiewang96@gmail.com; fulifeng93@gmail.com; xiangnanhe@gmail.com	Yang, Zhang/JWP-0075-2024; He, Xiangnan/G-3986-2011	He, Xiangnan/0000-0003-2838-861X; Bao, Keqin/0009-0001-5910-0204; Zhang, Yang/0000-0002-7863-5183	National Natural Science Foundation of China [62272437]; CCCD Key Lab of Ministry of Culture and Tourism	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCCD Key Lab of Ministry of Culture and Tourism	This work is supported by the National Natural Science Foundation of China (62272437), and the CCCD Key Lab of Ministry of Culture and Tourism.	Ai QY, 2023, Arxiv, DOI arXiv:2307.09751; Brockman Greg, 2022, OpenAI API.; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Weizhu, 2022, 10 INT C LEARNING RE; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cui Q, 2020, IEEE T KNOWL DATA EN, V32, P317, DOI 10.1109/TKDE.2018.2881260; Cui Z., 2022, arXiv; Devlin J., 2018, BERT PRE TRAINING DE; Ding SH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P40, DOI 10.1145/3477495.3532002; Donkers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P152, DOI 10.1145/3109859.3109877; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Fang H, 2020, ACM T INFORM SYST, V39, DOI 10.1145/3426723; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; He RN, 2016, IEEE DATA MINING, P191, DOI [10.1109/ICDM.2016.0030, 10.1109/ICDM.2016.88]; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hou YP, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P585, DOI 10.1145/3534678.3539381; Houlsby N, 2019, PR MACH LEARN RES, V97; Iyer S, 2022, Arxiv, DOI [arXiv:2212.12017, 10.48550/arXiv.2212.12017, DOI 10.48550/ARXIV.2212.12017]; Jang J, 2023, Arxiv, DOI arXiv:2302.03202; Jeronymo V, 2023, Arxiv, DOI [arXiv:2301.01820, DOI 10.48550/ARXIV.2301.01820]; Jin M, 2023, Arxiv, DOI arXiv:2303.07263; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li L, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3580488; Li RY, 2023, Arxiv, DOI [arXiv:2305.11700, 10.48550/arXiv.2305.11700]; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin XV, 2022, Arxiv, DOI arXiv:2112.10668; Mahmood T., 2007, P 9 INT C ELECT COMM, P75, DOI [10.1145/1282100.1282114, DOI 10.1145/1282100.1282114]; Maxwell F, 2015, ACM Transactions on Interactive Intelligent Systems (TiiS); Ni YB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P596, DOI 10.1145/3219819.3219828; Ouyang L., 2022, NEURIPS; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Qiu RH, 2021, Arxiv, DOI arXiv:2110.05730; Qiu RH, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P813, DOI 10.1145/3488560.3498433; Rendle Steffen, 2010, P 19 INT C WORLD WID, P811; Sanh V, 2022, arXiv; Schick T., 2023, arXiv; Shah D., 2022, P C ROB LEARN, V205, P492; Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tikk D., 2016, C TRACK P; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang L, 2023, Arxiv, DOI arXiv:2303.07678; Wang PF, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P403, DOI 10.1145/2766462.2767694; Wang SJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6332; Wang ZL, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2195, DOI 10.1145/3485447.3512092; Wang Ziyang, 2022, arXiv; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wen HY, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3606, DOI 10.1145/3485447.3512255; Xiao T., 2022, arXiv; Xie X, 2022, PROC INT CONF DATA, P1259, DOI 10.1109/ICDE53745.2022.00099; Xu CF, 2021, NEUROCOMPUTING, V423, P580, DOI 10.1016/j.neucom.2020.10.066; Yan A, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2173, DOI 10.1145/3357384.3358113; Yang ZY, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P331, DOI 10.1145/3539618.3591624; Yuan FJ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1469, DOI 10.1145/3397271.3401156; Yuan FJ, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P582, DOI 10.1145/3289600.3290975; Yuan Z, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2639, DOI 10.1145/3539618.3591932; Zhang J., 2023, Proceedings of the 17th ACM Conference on Recommender Systems; Zhang TT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4320; Zhang Y, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P11, DOI 10.1145/3404835.3462875; Zhang Yang., 2023, Reformulating CTR Prediction: Learning Invariant Feature Interactions for Recommendation; Zhang ZZ, 2023, Arxiv, DOI arXiv:2304.05263; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng Y, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2980, DOI 10.1145/3442381.3449788; Ziegler C.-N., 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754	71	4	4	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1007	1014		10.1145/3604915.3608857	http://dx.doi.org/10.1145/3604915.3608857			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Green Submitted			2024-07-03	WOS:001156630300115
C	Ma, K; Grandi, D; McComb, C; Goucher-Lambert, K			AMER SOC MECHANICAL ENGINEERS	Ma, Kevin; Grandi, Daniele; McComb, Christopher; Goucher-Lambert, Kosa			CONCEPTUAL DESIGN GENERATION USING LARGE LANGUAGE MODELS	PROCEEDINGS OF ASME 2023 INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, IDETC-CIE2023, VOL 6			English	Proceedings Paper	ASME International Design Engineering Technical Conferences / 42nd Annual Computers and Information in Engineering Conference (IDETC-CIE) / 35th International Conference on Design Theory and Methodology (DTM)	AUG 20-23, 2023	Boston, MA	Amer Soc Mech Engineers, Design Engn Div, Amer Soc Mech Engineers, Comp & Informat Engn Div, Tech Comm Micro & Nano Syst			CREATIVITY; INNOVATION; METRICS	Concept generation is a creative step in the conceptual design phase, where designers often turn to brainstorming, mindmapping, or crowdsourcing design ideas to complement their own knowledge of the domain. Recent advances in natural language processing (NLP) and machine learning (ML) have led to the rise of Large Language Models (LLMs) capable of generating seemingly creative outputs from textual prompts. The success of these models has led to their integration and application across a variety of domains, including art, entertainment, and other creative work. In this paper, we leverage LLMs to generate solutions for a set of 12 design problems and compare them to a baseline of crowdsourced solutions. We evaluate the differences between generated and crowdsourced design solutions through multiple perspectives, including human expert evaluations and computational metrics. Expert evaluations indicate that the LLM-generated solutions have higher average feasibility and usefulness while the crowdsourced solutions have more novelty. We experiment with prompt engineering and find that leveraging few-shot learning can lead to the generation of solutions that are more similar to the crowdsourced solutions. These findings provide insight into the quality of design solutions generated with LLMs and begins to evaluate prompt engineering techniques that could be leveraged by practitioners to generate higher-quality design solutions synergistically with LLMs.	[Ma, Kevin; Goucher-Lambert, Kosa] Univ Calif Berkeley, Dept Mech Engn, Berkeley, CA 94720 USA; [Grandi, Daniele] Autodesk Res, San Francisco, CA USA; [McComb, Christopher] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA USA	University of California System; University of California Berkeley; Autodesk, Inc.; Carnegie Mellon University	Goucher-Lambert, K (corresponding author), Univ Calif Berkeley, Dept Mech Engn, Berkeley, CA 94720 USA.	kevinma1515@berkeley.edu; daniele.grandi@autodesk.com; ccm@cmu.edu; kosa@berkeley.edu						Ahmed F, 2019, INT DES ENG TECHN C, V59278; Ahmed F, 2018, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2018, VOL 7; Amabile T.M., 1996, SOCIAL PSYCHOL CREAT; AMABILE TM, 1988, RES ORGAN BEHAV, V10, P123; AMABILE TM, 1982, J PERS SOC PSYCHOL, V43, P997, DOI 10.1037/0022-3514.43.5.997; [Anonymous], 2007, Design-by-analogy and representation in innovative engineering concept generation; Baer John., 2009, HDB RES ASSESSMENT T, P65, DOI DOI 10.4018/978-1-60566-667-9.CH004; Barth P, 2021, J CREATIVE BEHAV, V55, P396, DOI 10.1002/jocb.462; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown NC, 2019, AI EDAM, V33, P40, DOI 10.1017/S0890060418000033; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryant CR, 2005, Proceedings of the ASME International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, Vol 5, P267; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Christensen BT, 2016, DESIGN STUD, V45, P116, DOI 10.1016/j.destud.2015.12.005; Cseh GM, 2019, PSYCHOL AESTHET CREA, V13, P159, DOI 10.1037/aca0000220; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dorst K, 2006, DESIGN STUD, V27, P633, DOI 10.1016/j.destud.2006.05.002; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Goucher-Lambert K, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4046077; Goucher-Lambert K, 2019, DESIGN STUD, V61, P1, DOI 10.1016/j.destud.2019.01.001; Goucher-Lambert K, 2019, DESIGN STUD, V60, P1, DOI 10.1016/j.destud.2018.07.001; Heyrani Nobari A., 2021, INT DES ENG TECHN C, V85383; Johnson TA, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 7; Kaufman JC, 2009, J CREATIVE BEHAV, V43, P223, DOI 10.1002/j.2162-6057.2009.tb01316.x; Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056; Kwon E, 2019, J MECH DESIGN, V141, DOI 10.1115/1.4042336; Lai Y., 2021, AI Open, V2, P205; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Miller S. R., 2021, Journal of Mechanical Design, V143; Nelson BA, 2009, DESIGN STUD, V30, P737, DOI 10.1016/j.destud.2009.07.002; Oman SK, 2013, RES ENG DES, V24, P65, DOI 10.1007/s00163-012-0138-9; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peters M. E., 2018, North American Chapter of the Association for Computational Linguistics; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Raina A, 2022, J MECH DESIGN, V144, DOI 10.1115/1.4052566; Ramesh A, 2021, Arxiv, DOI [arXiv:2102.12092, 10.48550/arXiv.2102.12092]; Ranjan Nihar, 2016, Int. J. Comput. Appl., V134, P6; Regenwetter L, 2023, Arxiv, DOI arXiv:2302.02913; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Sarica S, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112995; Sarkar P, 2011, DESIGN STUD, V32, P348, DOI 10.1016/j.destud.2011.01.002; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Shah J. J., 2003, Design Studies, V24, P111, DOI 10.1016/S0142-694X(02)00034-0; Shah JJ, 2000, J MECH DESIGN, V122, P377, DOI 10.1115/1.1315592; Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649; Siangliulue P, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P609, DOI 10.1145/2984511.2984578; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Su HJ, 2022, Arxiv, DOI arXiv:2209.01975; Sundstrom P., 2003, DS 31; Tack A, 2022, Arxiv, DOI arXiv:2205.07540; Tan ZX, 2020, AI OPEN, V1, P5, DOI 10.1016/j.aiopen.2020.11.001; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yu LX, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1225, DOI 10.1145/2556288.2557378; Zhang W., 2019, INT DES ENG TECHN C, DOI [DOI 10.1115/DETC2019-98525, 10.1115/detc2019-98525]; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhu Q., 2022, Proceedings of the Design Society, V2, P1825, DOI [DOI 10.1017/PDS.2022.185, https://doi.org/10.1017/pds.2022.185]; Zhu QH, 2023, J COMPUT INF SCI ENG, V23, DOI 10.1115/1.4056220; Zhu QH, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056598	66	0	0	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			978-0-7918-8734-9				2023														12	Engineering, Industrial	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering	BW9PW					2024-07-03	WOS:001219036200021
J	Panagoulias, DP; Virvou, M; Tsihrintzis, GA; Grandi, F; Song, L				Panagoulias, Dimitrios P.; Virvou, Maria; Tsihrintzis, George A.; Grandi, Fabio; Song, Liang			Augmenting Large Language Models with Rules for Enhanced Domain-Specific Interactions: The Case of Medical Diagnosis	ELECTRONICS			English	Article						AI-empowered software engineering; generative AI; dialogue theory; large language models; natural language processing; rule-augmented systems; medical diagnosis; evaluation	HEALTH	In this paper, we present a novel Artificial Intelligence (AI) -empowered system that enhances large language models and other machine learning tools with rules to provide primary care diagnostic advice to patients. Specifically, we introduce a novel methodology, represented through a process diagram, which allows the definition of generative AI processes and functions with a focus on the rule-augmented approach. Our methodology separates various components of the generative AI process as blocks that can be used to generate an implementation data flow diagram. Building upon this framework, we utilize the concept of a dialogue process as a theoretical foundation. This is specifically applied to the interactions between a user and an AI-empowered software program, which is called "Med|Primary AI assistant" (Alpha Version at the time of writing), and provides symptom analysis and medical advice in the form of suggested diagnostics. By leveraging current advancements in natural language processing, a novel approach is proposed to define a blueprint of domain-specific knowledge and a context for instantiated advice generation. Our approach not only encompasses the interaction domain, but it also delves into specific content that is relevant to the user, offering a tailored and effective AI-user interaction experience within a medical context. Lastly, using an evaluation process based on rules, defined by context and dialogue theory, we outline an algorithmic approach to measure content and responses.	[Panagoulias, Dimitrios P.; Virvou, Maria; Tsihrintzis, George A.] Univ Piraeus, Dept Informat, 80 Karaoli ke Dimitriou ST, Piraeus 18534, Greece	University of Piraeus	Panagoulias, DP (corresponding author), Univ Piraeus, Dept Informat, 80 Karaoli ke Dimitriou ST, Piraeus 18534, Greece.	panagoulias_d@unipi.gr; mvirvou@unipi.gr; geoatsi@unipi.gr	VIRVOU, Maria/AAR-1415-2021	Tsihrintzis, George/0000-0002-2716-4035; VIRVOU, MARIA/0000-0002-4008-4654; Panagoulias, Dimitris/0000-0002-9421-141X	University of Piraeus Research Center	University of Piraeus Research Center	This work has been partly supported by the University of Piraeus Research Center. Theoretical/medical support and technical/medical advice as per the validity of our hypothesis was provided on 30 October 2023 by the medical doctors of Dermacen S.A. https://www.dermatologikokentro.gr (accessed: 30 October 2023).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Balogh EP, 2015, IMPROVING DIAGNOSIS IN HEALTH CARE, P1, DOI 10.17226/21794; Blandford A, 2020, LANCET GLOB HEALTH, V8, pE1364, DOI 10.1016/S2214-109X(20)30362-4; Bolukbasi T, 2016, ADV NEUR IN, V29; Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105; Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; diskinside, NuhealtSoft Suite; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Floyd W, 2023, INT J RADIAT ONCOL, V117, pE383, DOI 10.1016/j.ijrobp.2023.06.2497; García-Carrión R, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00140; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goodair B, 2022, LANCET PUBLIC HEALTH, V7, pE638, DOI 10.1016/S2468-2667(22)00133-5; Gordon EB, 2024, J AM COLL RADIOL, V21, P353, DOI 10.1016/j.jacr.2023.09.011; Gorsky P., 2008, Understanding online instructional modeling: Theories and practices, P47; gpt-index.readthedocs.io, Vector Stores-LlamaIndex; Gualandi R, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0224899; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Holzinger A., 2020, INT WORKSHOP EXTENDI, P3; Kraft AD, 2009, J PEDIATR-US, V155, P281, DOI 10.1016/j.jpeds.2009.02.035; Kreimeyer K, 2017, J BIOMED INFORM, V73, P14, DOI 10.1016/j.jbi.2017.07.012; Locke S, 2021, TRENDS ANAESTH CRIT, V38, P4, DOI 10.1016/j.tacc.2021.02.007; Majumder MAA, 2019, ADV MED EDUC PRACT, V10, P387, DOI 10.2147/AMEP.S197275; Martin D, 2018, LANCET, V391, P1718, DOI 10.1016/S0140-6736(18)30181-8; McCarthy S, 2016, J DECIS SYST, V25, P354, DOI 10.1080/12460125.2016.1187394; Mitchell ML, 2009, NURS EDUC TODAY, V29, P398, DOI 10.1016/j.nedt.2008.10.007; OpenAI, 2019, Better language models and their implications; Panagoulias D., 2023, P 20 ACSIEEE INT C C; Panagoulias D., 2023, P 14 IEEE INT C INFO; Panagoulias D.P., 2023, P 2023 IEEE 35 INT C; Panagoulias D.P., 2022, P 2022 16 INT C SIGN, P386; Panagoulias DP, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12214430; Panagoulias DP, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010204; Panagoulias DP, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060857; python.langchain, Customizing Conversational Memory; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Snoswell CL, 2023, J TELEMED TELECARE, V29, P669, DOI 10.1177/1357633X211022907; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Pham T, 2017, J BIOMED INFORM, V69, P218, DOI 10.1016/j.jbi.2017.04.001; Treatable Mortality in Europe, Time Series; Trebble TM, 2010, BMJ-BRIT MED J, V341, DOI 10.1136/bmj.c4078; Vaswani A, 2017, ADV NEUR IN, V30; Wang B, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.12; webpath.med.utah.edu, The Internet Pathology Laboratory for Medical Education; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wilson D.C., 2020, A Guide to Good Reasoning: Cultivating Intellectual Virtues; Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068; Yang HS, 2023, EUR J PUBLIC HEALTH, V33	50	0	0	9	9	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JAN	2024	13	2							320	10.3390/electronics13020320	http://dx.doi.org/10.3390/electronics13020320			26	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	FX8T2		gold			2024-07-03	WOS:001149249900001
J	Holmes, J; Liu, ZL; Zhang, L; Ding, YZ; Sio, TT; McGee, LA; Ashman, JB; Li, X; Liu, TM; Shen, JJ; Liu, W				Holmes, Jason; Liu, Zhengliang; Zhang, Lian; Ding, Yuzhen; Sio, Terence T.; McGee, Lisa A.; Ashman, Jonathan B.; Li, Xiang; Liu, Tianming; Shen, Jiajian; Liu, Wei			Evaluating large language models on a highly-specialized topic, radiation oncology physics	FRONTIERS IN ONCOLOGY			English	Article						large language model; natural language processing; medical physics; artificial intelligence; ChatGPT		PurposeWe present the first study to investigate Large Language Models (LLMs) in answering radiation oncology physics questions. Because popular exams like AP Physics, LSAT, and GRE have large test-taker populations and ample test preparation resources in circulation, they may not allow for accurately assessing the true potential of LLMs. This paper proposes evaluating LLMs on a highly-specialized topic, radiation oncology physics, which may be more pertinent to scientific and medical communities in addition to being a valuable benchmark of LLMs. MethodsWe developed an exam consisting of 100 radiation oncology physics questions based on our expertise. Four LLMs, ChatGPT (GPT-3.5), ChatGPT (GPT-4), Bard (LaMDA), and BLOOMZ, were evaluated against medical physicists and non-experts. The performance of ChatGPT (GPT-4) was further explored by being asked to explain first, then answer. The deductive reasoning capability of ChatGPT (GPT-4) was evaluated using a novel approach (substituting the correct answer with "None of the above choices is the correct answer."). A majority vote analysis was used to approximate how well each group could score when working together. ResultsChatGPT GPT-4 outperformed all other LLMs and medical physicists, on average, with improved accuracy when prompted to explain before answering. ChatGPT (GPT-3.5 and GPT-4) showed a high level of consistency in its answer choices across a number of trials, whether correct or incorrect, a characteristic that was not observed in the human test groups or Bard (LaMDA). In evaluating deductive reasoning ability, ChatGPT (GPT-4) demonstrated surprising accuracy, suggesting the potential presence of an emergent ability. Finally, although ChatGPT (GPT-4) performed well overall, its intrinsic properties did not allow for further improvement when scoring based on a majority vote across trials. In contrast, a team of medical physicists were able to greatly outperform ChatGPT (GPT-4) using a majority vote. ConclusionThis study suggests a great potential for LLMs to work alongside radiation oncology experts as highly knowledgeable assistants.	[Holmes, Jason; Zhang, Lian; Ding, Yuzhen; Sio, Terence T.; McGee, Lisa A.; Ashman, Jonathan B.; Shen, Jiajian; Liu, Wei] Mayo Clin, Dept Radiat Oncol, Phoenix, AZ 85054 USA; [Liu, Zhengliang; Liu, Tianming] Univ Georgia, Sch Comp, Athens, GA USA; [Li, Xiang] Massachusetts Gen Hosp, Dept Radiol, Boston, MA USA	Mayo Clinic; Mayo Clinic Phoenix; University System of Georgia; University of Georgia; Harvard University; Massachusetts General Hospital	Shen, JJ; Liu, W (corresponding author), Mayo Clin, Dept Radiat Oncol, Phoenix, AZ 85054 USA.	shen.jiajian@mayo.edu; liu.wei@mayo.edu		Shen, Jiajian/0000-0003-0439-2075				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Achievable, 2023, KEY GRE STAT 2022 ET; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bello I, 2021, Arxiv, DOI [arXiv:2102.08602, DOI 10.48550/ARXIV.2102.08602]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cai XY, 2023, IEEE T MULTIMEDIA, V25, P845, DOI 10.1109/TMM.2021.3132724; College Board, 2022, STUD SCOR DISTR; Colonius F, 2022, Arxiv, DOI arXiv:2106.01204; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; De Lange M, 2023, Arxiv, DOI arXiv:2205.13452; Deng W, 2020, MED PHYS, V47, P2558, DOI 10.1002/mp.14125; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong Q., 2022, ARXIV; Fan KS, 2023, Arxiv, DOI arXiv:2306.11289; Ferreira MN, 2022, Arxiv, DOI arXiv:2201.04451; Gao T., 2020, arXiv; Glaese A, 2022, arXiv; Jahan CSA, 2022, Arxiv, DOI arXiv:2206.05715; Koubaa A., 2023, GPT-4 vs. GPT-3.5: a concise showdown, DOI [10.36227/techrxiv.22312330.v2, DOI 10.36227/TECHRXIV.22312330.V2]; Law School Admission Council, 2023, TEST REG TEST TAK; Le Scao Teven, 2022, Bloom: A 176b-parameter open-access multilingual language model; Lewis M., 2019, ARXIV, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu W, 2013, MED PHYS, V40, DOI 10.1118/1.4774363; Liu Zhengliang, 2022, Zhong Nan Da Xue Xue Bao Yi Xue Ban, V47, P981, DOI 10.11817/j.issn.1672-7347.2022.220376; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Muennighoff N., 2022, ARXIV; National Resident Matching Program, 2023, CHART OUTC MATCH SEN; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, Introducing ChatGPT; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Raffel C, 2020, J MACH LEARN RES, V21; Rajasekharan A., 2021, AMMUS SURVEY TRANSFO, DOI [10.1016/j.jbi.2021.103982, DOI 10.1016/J.JBI.2021.103982]; Rezayi S., 2022, P 31 INT JOINT C ART, P5150; Rezayi S, 2022, LECT NOTES COMPUT SC, V13583, P269, DOI 10.1007/978-3-031-21014-3_28; Röttger P, 2022, Arxiv, DOI arXiv:2112.07475; Rüdisser HT, 2022, Arxiv, DOI arXiv:2205.03578; Schild SE, 2014, WORLD J CLIN ONCOL, V5, P568, DOI 10.5306/wjco.v5.i4.568; Shan J, 2018, MED PHYS, V45, P460, DOI 10.1002/mp.12677; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; So David R, 2021, arXiv; The American Board of Radiology, 2023, MED PHYS RAD ONC; The Verge, 2023, Twitter taught Microsoft's AI chatbot to be a racist asshole in less than a day; Wang K, 2022, Arxiv, DOI arXiv:2206.09308; Yoshida R, 2022, Arxiv, DOI arXiv:2206.04206; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang DY, 2024, Arxiv, DOI arXiv:2306.02245; Zhang S., 2022, ARXIV; Zhao L, 2023, Arxiv, DOI arXiv:2303.15935	51	15	15	11	23	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2234-943X			FRONT ONCOL	Front. Oncol.	JUL 17	2023	13								1219326	10.3389/fonc.2023.1219326	http://dx.doi.org/10.3389/fonc.2023.1219326			11	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	N5PF0	37529688	gold, Green Submitted, Green Published			2024-07-03	WOS:001037522300001
J	Heseltine, M; von Hohenberg, BC				Heseltine, Michael; von Hohenberg, Bernhard Clemm			Large language models as a substitute for human experts in annotating political text	RESEARCH & POLITICS			English	Article						Large language models; GPT; machine learning; text analysis; text-as-data		Large-scale text analysis has grown rapidly as a method in political science and beyond. To date, text-as-data methods rely on large volumes of human-annotated training examples, which place a premium on researcher resources. However, advances in large language models (LLMs) may make automated annotation increasingly viable. This paper tests the performance of GPT-4 across a range of scenarios relevant for analysis of political text. We compare GPT-4 coding with human expert coding of tweets and news articles across four variables (whether text is political, its negativity, its sentiment, and its ideology) and across four countries (the United States, Chile, Germany, and Italy). GPT-4 coding is highly accurate, especially for shorter texts such as tweets, correctly classifying texts up to 95% of the time. Performance drops for longer news articles, and very slightly for non-English text. We introduce a 'hybrid' coding approach, in which disagreements of multiple GPT-4 runs are adjudicated by a human expert, which boosts accuracy. Finally, we explore downstream effects, finding that transformer models trained on hand-coded or GPT-4-coded data yield almost identical outcomes. Our results suggest that LLM-assisted coding is a viable and cost-efficient approach, although consideration should be given to task complexity.	[Heseltine, Michael] Univ Amsterdam, Amsterdam Sch Commun Res, Amsterdam, Netherlands; [von Hohenberg, Bernhard Clemm] GESIS Leibniz Inst Social Sci, Cologne, Germany; [Heseltine, Michael] Univ Amsterdam, Amsterdam Sch Commun Res, Nieuwe Achtergracht 166, NL-1018 Amsterdam, Netherlands	University of Amsterdam; Leibniz Institut fur Sozialwissenschaften (GESIS); University of Amsterdam	Heseltine, M (corresponding author), Univ Amsterdam, Amsterdam Sch Commun Res, Nieuwe Achtergracht 166, NL-1018 Amsterdam, Netherlands.	m.j.heseltine@uva.nl		Heseltine, Michael/0000-0002-2943-4414; Clemm von Hohenberg, Bernhard/0000-0002-6976-9745				Ballard AO, 2023, LEGIS STUD QUART, V48, P105, DOI 10.1111/lsq.12374; Bisbee J., 2023, SocArXiv, DOI [10.31235/osf.io/5ecfa, DOI 10.31235/OSF.IO/5ECFA]; Brady DW, 2007, LEGIS STUD QUART, V32, P79, DOI 10.3162/036298007X201994; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Hassell HJG, 2021, POLIT BEHAV, V43, P1137, DOI 10.1007/s11109-019-09588-z; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Johnson RL., 2022, The Ghost in the Machine Has an American Accent: Value Conflict in Gpt-3; Kuzman T., 2023, arXiv; Lau RR, 2009, ANNU REV POLIT SCI, V12, P285, DOI 10.1146/annurev.polisci.10.071905.101448; Motoki F., 2024, Public Choice, V198, P3; Mozafari M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237861; Nay JJJ, 2023, Arxiv, DOI arXiv:2301.01181; Ornstein J. T., 2023, How to Train Your Stochastic Parrot: Large Language Models for Political Texts; Peterson DAM, 2005, POLIT RES QUART, V58, P45, DOI 10.1177/106591290505800104; Rozado D, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0276367; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Wu PY, 2023, Arxiv, DOI [arXiv:2303.12057, 10.48550/arXiv.2303.12057, DOI 10.48550/ARXIV.2303.12057]; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	19	1	1	9	9	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA		2053-1680		RES POLITICS	Res. Politics	JAN	2024	11	1							20531680241236239	10.1177/20531680241236239	http://dx.doi.org/10.1177/20531680241236239			10	Political Science	Social Science Citation Index (SSCI)	Government & Law	JS1D3		gold			2024-07-03	WOS:001175053000001
C	Jang, M; Yoon, Y; Choi, J; Kim, J; Ong, H			ACM	Jang, Minsu; Yoon, Youngwoo; Choi, Jaewoo; Kim, Jaehong; Ong, Hyobin			A Structured Prompting based on Belief-Desire-Intention Model for Proactive and Explainable Task Planning	PROCEEDINGS OF THE 11TH CONFERENCE ON HUMAN-AGENT INTERACTION, HAI 2023			English	Proceedings Paper	11th International Conference on Human-Agent Interaction (HAI)	DEC 04-07, 2023	Chalmers Univ Technol, Gothenburg, SWEDEN	Assoc Comp Machinery, ACM SIGCHI	Chalmers Univ Technol	large language models; belief-desire-intention; prompting		We investigate the potential of the belief-desire-intention (BDI) model for enhancing proactive action planning and transparency in large language models (LLMs). Our proposed method, BDIPrompting, integrates the knowledge representation framework of the BDI model into prompt design. This allows agents to generate motivational and goal-directed service plans proactively while offering human users insights into the rationale behind the decision-making process. Through preliminary experiments with OpenAI's GPT-4, we highlight the effectiveness of our approach in planning motivational actions and providing improved explanations during human-agent interactions.	[Jang, Minsu; Yoon, Youngwoo; Choi, Jaewoo; Kim, Jaehong] Elect & Telecommun Res Inst, Daejeon, South Korea; [Ong, Hyobin] Univ Sci & Technol, Daejeon, South Korea	Electronics & Telecommunications Research Institute - Korea (ETRI); University of Science & Technology (UST)	Jang, M (corresponding author), Elect & Telecommun Res Inst, Daejeon, South Korea.	minsu@etri.re.kr; youngwoo@etri.re.kr; jwchoi@etri.re.kr; jhkim@etri.re.kr; ohnghb@etri.re.kr		Kim, Jaehong/0000-0002-6840-5026; Jang, Minsu/0000-0002-7166-0300	IITP grants - MSIT, South Korea [2020-0-00842]	IITP grants - MSIT, South Korea	This work was supported by IITP grants funded by MSIT, South Korea (No. 2020-0-00842, Development of Cloud Robot Intelligence).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown N., 2023, C ROBOT LEARNING, P287; Huang W, 2023, P 6 C ROBOT LEARNING, P1769; Huang W., 2022, PROC INT C MACHINE L, P9118; MosaicML NLP Team, 2023, Introducing mpt-7b: A new standard for open-source, commercially usable llms; RAO AS, 1991, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P473; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Yoshua X, 2023, AC Investment Research Journal, V220, P44	8	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0824-4				2023							375	377		10.1145/3623809.3623930	http://dx.doi.org/10.1145/3623809.3623930			3	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW4HI					2024-07-03	WOS:001148034200050
C	Hämäläinen, P; Tavast, M; Kunnari, A			ACM	Hamalainen, Perttu; Tavast, Mikke; Kunnari, Anton			Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		User experience; User models; Language models; GPT-3		Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI's GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.	[Hamalainen, Perttu; Tavast, Mikke] Aalto Univ, Espoo, Finland; [Kunnari, Anton] Univ Helsinki, Helsinki, Finland	Aalto University; University of Helsinki	Hämäläinen, P (corresponding author), Aalto Univ, Espoo, Finland.	perttu.hamalainen@aalto.fi; mikke.tavast@aalto.fi; anton.kunnari@helsinki.fi			European Commission [101017779]; Academy of Finland [318937]	European Commission(European Union (EU)European Commission Joint Research Centre); Academy of Finland(Research Council of Finland)	This work has been supported by the European Commission through the Horizon 2020 FET Proactive program (grant agreement 101017779) and by Academy of Finland Grant #318937.	Anwyl-Irvine AL, 2020, BEHAV RES METHODS, V52, P388, DOI 10.3758/s13428-019-01237-x; Argyle Lisa P, 2022, ARXIV220906899, DOI [10.48550/ arXiv.2209.06899, DOI 10.48550/ARXIV.2209.06899]; Bargas-Avila JA, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2689; Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bopp Julia A., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3474664; Bopp Julia, 2020, GAMESASART, DOI [10.17605/OSF. IO/RYVT6, DOI 10.17605/OSF.I0/RYVT6]; Branwen Gwern, 2020, GPT 3 CREATIVE FCTIO; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brysbaert M, 2019, J MEM LANG, V109, DOI 10.1016/j.jml.2019.104047; Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227; Cheema N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376701; Chowdhery Aakanksha, 2022, ARXIV220402311 CS CL; Clark Peter, 2021, P 29 INT JOINT C ART, DOI DOI 10.24963/IJCAI.2020/537; Cox Matt, 2019, THIS AI TEXT ADVENTU; Degrave Jonas, 2022, BUILDING VIRTUAL MAC; Delobelle P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1693; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; Dhariwal Prafulla, 2020, ARXIV200500341, DOI DOI 10.48550/ARXIV.2005.00341; Elhage N., 2021, Transformer Circuits Thread; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460; Fan X, 2022, AM J NEURORADIOL, DOI 10.3174/ajnr.A7538; FITTS PM, 1954, J EXP PSYCHOL, V47, P381, DOI 10.1037/h0055392; Gao Leo, 2021, SIZES OPENAI API MOD; Griffin Marybec, 2022, Qual Quant, V56, P2841, DOI 10.1007/s11135-021-01252-1; Grootendorst M., 2022, ARXIV PREPRINT ARXIV; Hamalainen Perttu, 2022, IUI '22 Companion: 27th International Conference on Intelligent User Interfaces, P77, DOI 10.1145/3490100.3516458; Hensel M, 2017, ADV NEUR IN, V30; Holtzman A., 2019, INT C LEARNING REPRE; Jokinen Jussi, 2021, P 2021 CHI C HUM FAC, P1, DOI DOI 10.1145/3411764.3445483; KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185; Kaplan J., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.08361; Köbis NC, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103364; Kojima Takeshi, 2022, Advances in Neural Information Processing Systems; Kristensson Per Ola, 2018, COMPUTATIONAL INTERA, P43; Kuperman V, 2021, J EXP PSYCHOL HUMAN, V47, P1103, DOI 10.1037/xhp0000932; Kwon Mijin, 2022, P ANN M COGN SCI SOC, V44; Kynkäänniemi T, 2019, ADV NEUR IN, V32; Lample Guillaume, 2019, INT C LEARN REPR; Le-Khac PH, 2020, IEEE ACCESS, V8, P193907, DOI 10.1109/ACCESS.2020.3031549; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu SS, 2018, IEEE T VIS COMPUT GR, V24, P553, DOI 10.1109/TVCG.2017.2745141; Loughran T, 2017, PRACTICAL GUIDE TO STUDYING HISTORY: SKILLS AND APPROACHES, P197; Lu K, 2022, AAAI CONF ARTIF INTE, P7628; MacKenzie I. S., 1992, CHI '92 Conference Proceedings. ACM Conference on Human Factors in Computing Systems. Striking a Balance, P219, DOI 10.1145/142750.142794; Macmillan NA., 2005, Detection theory: A users guide; Madani Ali, 2020, ProGen: Language modeling for protein generation, DOI 10.1101/ 2020.03.07.982272; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Montufar GF., 2014, ADV NEURAL INFORM PR, V27, P2924, DOI DOI 10.5555/2969033.2969153; Nightingale SJ, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120481119; Nye Maxwell, 2021, ADV NEURAL INFORM PR, V34, P25192; Olsson Catherine, 2022, Transformer Circuits; Oulasvirta Antti, 2019, Interactions, V26, P52, DOI DOI 10.1145/3330340; Ouyang L., 2022, TRAINING LANGUAGE MO, DOI DOI 10.48550/ARXIV.2203.02155; Park JS, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545616; Pérez J, 2021, J MACH LEARN RES, V22; Pettersson I, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174035; Poole B, 2016, ADV NEUR IN, V29; Power Alethea, 2022, ARXIV220102177; Radford A, 2017, LEARNING GENERATE RE; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae Jack W., 2021, ARXIV211211446 CS CL; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A, 2021, PR MACH LEARN RES, V139; Roohi Shaghayegh, 2020, CHI PLAY '20: Proceedings of the Annual Symposium on Computer-Human Interaction in Play, P585, DOI 10.1145/3410404.3414235; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Sanh Victor, 2022, Multitask Prompted Training Enables Zero-Shot Task Generalization; Sauro J, 2012, QUANTIFYING THE USER EXPERIENCE: PRACTICAL STATISTICS FOR USER RESEARCH, P1; Schulman J, 2022, Introducing chatgpt; Semeniuta Stanislau, 2018, ACCURATE EVALUATION, DOI [10.48550/ARXIV. 1806.04936, DOI 10.48550/ARXIV.1806.04936]; Simonite Tom, 2021, IT BEGAN FUELED DUNG; Smith Shaden, 2022, ARXIV220111990 CS CL; Tavast Mikke, 2022, IUI '22 Companion: 27th International Conference on Intelligent User Interfaces, P69, DOI 10.1145/3490100.3516464; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wei Jason, 2022, arXiv:2206.07682; Wei Jason, 2022, CHAIN THOUGHT PROMPT, DOI [10.48550/ARXIV.2201. 11903, DOI 10.48550/ARXIV.2201.11903]; Xue GR, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1462198.1462203; Ye QY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7163; Zallot C., 2021, Handbook of computational social science, VVol. 2, P140; Zhao TZ, 2021, PR MACH LEARN RES, V139	83	18	17	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580688	http://dx.doi.org/10.1145/3544548.3580688			19	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Published, Bronze			2024-07-03	WOS:001037809501005
J	Goli, A; Singh, A				Goli, Ali; Singh, Amandeep			Frontiers: Can Large Language Models Capture Human Preferences?	MARKETING SCIENCE			English	Article; Early Access						large language models; intertemporal preferences; decision making; chain of thought; conjoint	TIME-PREFERENCES; DISCOUNT RATES; THOUGHT; RISK	We explore the viability of large language models (LLMs), specifically OpenAI's GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting preferences, with a focus on intertemporal choices. Leveraging the extensive literature on intertemporal discounting for benchmarking, we examine responses from LLMs across various languages and compare them with human responses, exploring preferences between smaller, sooner and larger, later rewards. Our findings reveal that both generative pretrained transformer (GPT) models demonstrate less patience than humans, with GPT-3.5 exhibiting a lexicographic preference for earlier rewards unlike human decision makers. Although GPT-4 does not display lexicographic preferences, its measured discount rates are still considerably larger than those found in humans. Interestingly, GPT models show greater patience in languages with weak future tense references, such as German and Mandarin, aligning with the existing literature that suggests a correlation between language structure and intertemporal preferences. We demonstrate how prompting GPT to explain its decisions, a procedure we term "chain -of -thought conjoint," can mitigate, but does not eliminate, discrepancies between LLM and human responses. Although directly eliciting preferences using LLMs may yield misleading results, combining chain -of -thought conjoint with topic modeling aids in hypothesis generation, enabling researchers to explore the underpinnings of preferences. Chain -of -thought conjoint provides a structured framework for marketers to use LLMs to identify potential attributes or factors that can explain preference heterogeneity across different customers and contexts.	[Goli, Ali; Singh, Amandeep] Univ Washington, Michael G Foster Sch Business, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Goli, A (corresponding author), Univ Washington, Michael G Foster Sch Business, Seattle, WA 98195 USA.	agoli@uw.edu; amdeep@uw.edu						Andersen S, 2008, ECONOMETRICA, V76, P583, DOI 10.1111/j.1468-0262.2008.00848.x; Andreoni J, 2012, AM ECON REV, V102, P3333, DOI 10.1257/aer.102.7.3333; Angeletos GM, 2001, J ECON PERSPECT, V15, P47, DOI 10.1257/jep.15.3.47; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Atlas SA, 2017, J MARKETING RES, V54, P415, DOI 10.1509/jmr.14.0481; Ayres I, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208871120; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boroditsky L, 2001, COGNITIVE PSYCHOL, V43, P1, DOI 10.1006/cogp.2001.0748; Bradford D, 2017, J RISK UNCERTAINTY, V55, P119, DOI 10.1007/s11166-018-9272-8; Brand J, 2023, PREPRINT, DOI [10.2139/ssrn.4395751, DOI 10.2139/SSRN.4395751]; Brucks M, 2023, PREPRINT, DOI [10.2139/ssrn.4484416, DOI 10.2139/SSRN.4484416]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen MK, 2013, AM ECON REV, V103, P690, DOI 10.1257/aer.103.2.690; Chen SM, 2017, J CORP FINANC, V46, P320, DOI 10.1016/j.jcorpfin.2017.07.009; Chen YT, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2316205120; Coda-Forno J, 2023, Arxiv, DOI [arXiv:2304.11111, 10.48550/arXiv.2304.11111, DOI 10.48550/ARXIV.2304.11111]; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Falk A, 2018, Q J ECON, V133, P1645, DOI 10.1093/qje/qjy013; Frederick S, 2002, J ECON LIT, V40, P351, DOI 10.1257/002205102320161311; Frederick S, 2009, J CONSUM RES, V36, P553, DOI 10.1086/599764; Gui G, 2023, Arxiv, DOI arXiv:2312.15524; Harrison GW, 2002, AM ECON REV, V92, P1606, DOI 10.1257/000282802762024674; Hesketh B, 2000, J VOCAT BEHAV, V57, P62, DOI 10.1006/jvbe.1999.1725; Holt CA, 2002, AM ECON REV, V92, P1644, DOI 10.1257/000282802762024700; Horton JJ, 2023, Arxiv, DOI [arXiv:2301.07543, DOI 10.48550/ARXIV.2301.07543]; Li XL, 2021, J CONSUM RES, V48, P169, DOI 10.1093/jcr/ucaa064; Liu BB, 2023, Arxiv, DOI arXiv:2210.10749; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Maital S, 1976, Working paper; MILLAR MG, 1986, J PERS SOC PSYCHOL, V51, P259, DOI 10.1037/0022-3514.51.2.259; Mischel W., 2003, Economic and Psychological Perspectives on Intertemporal Choice, P175; O'Donoghue T, 1999, AM ECON REV, V89, P103, DOI 10.1257/aer.89.1.103; OpenAI, 2023, Introduction to the OpenAI Chat API; Osei-Tutu F, 2021, J FINANC SERV RES, V59, P47, DOI 10.1007/s10693-020-00335-8; Pender JL, 1996, J DEV ECON, V50, P257, DOI 10.1016/S0304-3878(96)00400-2; Salisbury LC, 2008, J CONSUM RES, V35, P349, DOI 10.1086/586915; SHELLEY MK, 1993, MANAGE SCI, V39, P806, DOI 10.1287/mnsc.39.7.806; SHELLEY MK, 1994, ORGAN BEHAV HUM DEC, V59, P124, DOI 10.1006/obhd.1994.1053; Sussman AB, 2023, J ASSOC CONSUM RES, V8, P365, DOI 10.1086/727194; Vaswani A, 2017, ADV NEUR IN, V30; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; WILSON TD, 1991, J PERS SOC PSYCHOL, V60, P181, DOI 10.1037/0022-3514.60.2.181; Zauberman G, 2009, J MARKETING RES, V46, P543, DOI 10.1509/jmkr.46.4.543; Zhang Y, 2022, Arxiv, DOI arXiv:2206.04301	44	0	0	34	34	INFORMS	CATONSVILLE	5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA	0732-2399	1526-548X		MARKET SCI	Mark. Sci.	2024 APR 25	2024										10.1287/mksc.2023.0306	http://dx.doi.org/10.1287/mksc.2023.0306		APR 2024	15	Business	Social Science Citation Index (SSCI)	Business & Economics	PO9A5					2024-07-03	WOS:001215125900001
J	[Anonymous]				[Anonymous]			Language models and linguistic theories beyond words	NATURE MACHINE INTELLIGENCE			English	Editorial Material								The development of large language models is mainly a feat of engineering and so far has been largely disconnected from the field of linguistics. Exploring links between the two directions is reopening longstanding debates in the study of language.										[Anonymous], 2023, NAT MACH INTELL, V5, P331; Jelinek F, 2005, LANG RESOUR EVAL, V39, P25, DOI 10.1007/s10579-005-2693-4; Linzen T, 2019, LANGUAGE, V95, pE99, DOI 10.1353/lan.2019.0015; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Moore R. K., 2005, ISCA; Pater J, 2019, LANGUAGE, V95, pE41, DOI 10.1353/lan.2019.0009; Piantadosi S., 2023, LingBuzz; Piattelli-Palmarini M., 1980, LANGUAGE LEARNING DE; Vu MH, 2023, NAT MACH INTELL, V5, P485, DOI 10.1038/s42256-023-00637-1; Zaadnoordijk L, 2022, NAT MACH INTELL, V4, P510, DOI 10.1038/s42256-022-00488-2; Zhang H., 2023, NATURE	12	0	0	0	3	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	JUL	2023	5	7					677	678		10.1038/s42256-023-00703-8	http://dx.doi.org/10.1038/s42256-023-00703-8			2	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	N2VT2		Bronze			2024-07-03	WOS:001035658800001
C	Samsi, S; Zhao, D; McDonald, J; Li, BL; Michaleas, A; Jones, M; Bergeron, W; Kepner, J; Tiwari, D; Gadepally, V			IEEE	Samsi, Siddharth; Zhao, Dan; McDonald, Joseph; Li, Baolin; Michaleas, Adam; Jones, Michael; Bergeron, William; Kepner, Jeremy; Tiwari, Devesh; Gadepally, Vijay			From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference	2023 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE, HPEC	IEEE High Performance Extreme Computing Conference		English	Proceedings Paper	IEEE High Performance Extreme Computing Virtual Conference (HPEC)	SEP 25-29, 2023	ELECTR NETWORK	IEEE		Large Language Models; Natural Language Processing; Inference; Green AI; LLM; NLP; Deep Learning; Distributed Computing; Energy; Sustainability		Large language models (LLMs) have exploded in popularity due to their new generative capabilities that go far beyond prior state-of-the-art. These technologies are increasingly being leveraged in various domains such as law, finance, and medicine. However, these models carry significant computational challenges, especially the compute and energy costs required for inference. Inference energy costs already receive less attention than the energy costs of training LLMs-despite how often these large models are called on to conduct inference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see increasing usage and deployment in various domains, a better understanding of their resource utilization is crucial for cost-savings, scaling performance, efficient hardware usage, and optimal inference strategies. In this paper, we describe experiments conducted to study the computational and energy utilization of inference with LLMs. We benchmark and conduct a preliminary analysis of the inference performance and inference energy costs of different sizes of LLaMA-a recent state-of-the-art LLM-developed by Meta AI on two generations of popular GPUs (NVIDIA V100 & A100) and two datasets (Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in research and practice. We present the results of multi-node, multi-GPU inference using model sharding across up to 32 GPUs. To our knowledge, our work is the one of the first to study LLM inference performance from the perspective of computational and energy resources at this scale.	[Samsi, Siddharth; McDonald, Joseph; Michaleas, Adam; Jones, Michael; Bergeron, William; Kepner, Jeremy; Gadepally, Vijay] MIT, Cambridge, MA 02139 USA; [Zhao, Dan] NYU, New York, NY USA; [Li, Baolin; Tiwari, Devesh] Northeastern Univ, Boston, MA USA	Massachusetts Institute of Technology (MIT); New York University; Northeastern University	Samsi, S (corresponding author), MIT, Cambridge, MA 02139 USA.		Li, Baolin/N-8884-2019	Michaleas, Adam/0000-0001-7402-8303				[Anonymous], 2023, Facebook Research; [Anonymous], Different development paths of llms; [Anonymous], 2023, Nvidia/megatron-lm: Ongoing research training transformer models at scale; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Desislavov R, 2023, SUSTAIN COMPUT-INFOR, V38, DOI 10.1016/j.suscom.2023.100857; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Epstein Z, 2023, SCIENCE, V380, P1110, DOI 10.1126/science.adh4451; FairScale authors, 2021, FairScale: A general purposemodular PyTorch library for high performance and large scale training; Foster D., 2022, Generative deep learning; Gozalo-Brizuela R., 2023, CHATGPT IS NOT ALL Y; Li BL, 2022, PROCEEDINGS OF THE 13TH SYMPOSIUM ON CLOUD COMPUTING, SOCC 2022, P173, DOI 10.1145/3542929.3563510; McDonald J., 2022, FINDINGS ASS COMPUTA, P1962, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.151; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; NVIDIA, Nvidia-smi; NVIDIA, 2023, NVIDIA Multi Instance GPU User Guide; NVIDIA, 2023, Multi-Process Service; NVIDIA, Nvidia data center GPU manager (dcgm); Patel D., 2023, The ai brick wall-a practical limit for scaling dense transformer models, and how gpt 4 will break past it; Reuther A, 2018, IEEE HIGH PERF EXTR; Sevilla J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891914; Shoeybi M., 2019, Megatron-lm: Training multibillion parameter language models using model parallelism; Stability-AI, 2023, Stable Diffusion; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Zhao D, 2022, IEEE SYM PARA DISTR, P742, DOI 10.1109/IPDPSW55747.2022.00126; Zohny H, 2023, J MED ETHICS, V49, P79, DOI 10.1136/jme-2023-108909	29	1	1	7	7	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2377-6943		979-8-3503-0860-0	IEEE HIGH PERF EXTR			2023										10.1109/HPEC58863.2023.10363447	http://dx.doi.org/10.1109/HPEC58863.2023.10363447			9	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW4YB		Green Submitted			2024-07-03	WOS:001156959800003
J	Karlsen, E; Luo, X; Zincir-Heywood, N; Heywood, M				Karlsen, Egil; Luo, Xiao; Zincir-Heywood, Nur; Heywood, Malcolm			Benchmarking Large Language Models for Log Analysis, Security, and Interpretation	JOURNAL OF NETWORK AND SYSTEMS MANAGEMENT			English	Article						Log analysis; LLM; GPT; BERT; NLP; Security; Interpretation		Large Language Models (LLM) continue to demonstrate their utility in a variety of emergent capabilities in different fields. An area that could benefit from effective language understanding in cybersecurity is the analysis of log files. This work explores LLMs with different architectures (BERT, RoBERTa, DistilRoBERTa, GPT-2, and GPT-Neo) that are benchmarked for their capacity to better analyze application and system log files for security. Specifically, 60 fine-tuned language models for log analysis are deployed and benchmarked. The resulting models demonstrate that they can be used to perform log analysis effectively with fine-tuning being particularly important for appropriate domain adaptation to specific log types. The best-performing fine-tuned sequence classification model (DistilRoBERTa) outperforms the current state-of-the-art; with an average F1-Score of 0.998 across six datasets from both web application and system log sources. To achieve this, we propose and implement a new experimentation pipeline (LLM4Sec) which leverages LLMs for log analysis experimentation, evaluation, and analysis.	[Karlsen, Egil; Zincir-Heywood, Nur; Heywood, Malcolm] Dalhousie Univ, Fac Comp Sci, Univ Ave, Halifax, NS B3H 1W5, Canada; [Luo, Xiao] Oklahoma State Univ, Dept Management Sci & Informat Syst, 370 Business Bldg, Stillwater, OK 74078 USA	Dalhousie University; Oklahoma State University System; Oklahoma State University - Stillwater	Karlsen, E (corresponding author), Dalhousie Univ, Fac Comp Sci, Univ Ave, Halifax, NS B3H 1W5, Canada.	egil.karlsen@dal.ca; xiao.luo@okstate.edu; zincir@cs.dal.ca; mheywood@cs.dal.ca						Adhikari A., 2023, Machine learning technique for intrusion detection in the field of the intrusion detection system; Bhatnagar M, 2022, ELMAR PROC, P57, DOI 10.1109/ELMAR55880.2022.9899790; Black Sid, 2021, Zenodo; Boffa M, 2022, 7TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (EUROS&PW 2022), P314, DOI 10.1109/EuroSPW55150.2022.00038; Copstein R, 2022, IT-INF TECHNOL, V64, P15, DOI 10.1515/itit-2021-0064; ECML/PKDD, 2021, ECML/PKDD 2007 Discovery Challenge; Farzad A., 2021, Log Message Anomaly Detection and Classification Using Auto-B/LSTM and Auto-GRU; Gallagher B., 2009, Classification of HTTP Attacks: A Study on the ECML/PKDD 2007 Discovery challenge, DOI [10.2172/1113394, DOI 10.2172/1113394]; Gniewkowski M, 2023, 38TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, SAC 2023, P1154, DOI 10.1145/3555776.3577663; Guo H., 2021, LogBERT: log anomaly detection via BERT, P1; Guo H., 2022, TransLog: A Unified Transformer-Based Framework for Log Anomaly Detection; Nguyen HT, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P271, DOI 10.1109/HIS.2012.6421346; He PJ, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P33, DOI 10.1109/ICWS.2017.13; Hilmi MAA., 2020, IEEE Dataport, DOI DOI 10.21227/VVVQ-6W47; Karlsen E., 2023, 2023 7 CYB SEC NETW, P1; Kokalj Enja, 2021, P EACL HACKASHOP NEW, P16; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Nam S, 2022, INT CONF NETW SER, P331, DOI 10.23919/CNSM55787.2022.9965187; Oliner A, 2007, I C DEPEND SYS NETWO, P575, DOI 10.1109/DSN.2007.103; Qi JX, 2022, IEEE IFIP NETW OPER, DOI 10.1109/NOMS54207.2022.9789917; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rostamizadeh A., 2012, FDN MACHINE LEARNING; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Seyyar Y.E., 2022, 2022 30 SIGN PROC CO, P1, DOI DOI 10.1109/SIU55565.2022.9864721; Shao Yangyi, 2022, 2022 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)., P161, DOI 10.1109/ICCCBDA55098.2022.9778900; Tumer Sivri T., 2022, COMMUNICATION PAPERS, P269, DOI [10.15439/2022F147, DOI 10.15439/2022F147]; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Le VH, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P492, DOI 10.1109/ASE51524.2021.9678773; Vartouni AM, 2019, IET INFORM SECUR, V13, P352, DOI 10.1049/iet-ifs.2018.5404; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang MY, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON FRONTIERS OF SIGNAL PROCESSING (ICFSP 2018), P140, DOI 10.1109/ICFSP.2018.8552075; Zaker Farzin, 2019, HarvardDataverse, V1	33	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1064-7570	1573-7705		J NETW SYST MANAG	J. Netw. Syst. Manag.	JUL	2024	32	3							59	10.1007/s10922-024-09831-x	http://dx.doi.org/10.1007/s10922-024-09831-x			27	Computer Science, Information Systems; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Telecommunications	UK9N9					2024-07-03	WOS:001248072500001
J	Kim, K; Cho, K; Jang, R; Kyung, S; Lee, S; Ham, S; Choi, E; Hong, GS; Kim, N				Kim, Kiduk; Cho, Kyungjin; Jang, Ryoungwoo; Kyung, Sunggu; Lee, Soyoung; Ham, Sungwon; Choi, Edward; Hong, Gil-Sun; Kim, Namkug			Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals	KOREAN JOURNAL OF RADIOLOGY			English	Article						Artificial intelligence; Generative artificial intelligence; Large language model; Synthetic data; Medical imaging	ADVERSARIAL NETWORK; DOSE CT; REDUCTION; CYCLEGAN	The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential.	[Kim, Kiduk; Kim, Namkug] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Convergence Med, Seoul, South Korea; [Cho, Kyungjin; Kyung, Sunggu; Lee, Soyoung] Univ Ulsan, Asan Med Inst Convergence Sci & Technol, Asan Med Ctr, Dept Biomed Engn,Coll Med, Seoul, South Korea; [Jang, Ryoungwoo] Coreline Soft Co Ltd, Seoul, South Korea; [Ham, Sungwon] Korea Univ, Coll Med, Ansan Hosp, Healthcare Readiness Inst Unified Korea, Ansan, South Korea; [Choi, Edward] Korea Adv Inst Sci & Technol, Daejeon, South Korea; [Hong, Gil-Sun; Kim, Namkug] Univ Ulsan, Asan Med Ctr, Coll Med, Dept Radiol, Seoul, South Korea; [Hong, Gil-Sun; Kim, Namkug] Univ Ulsan, Res Inst Radiol, Asan Med Ctr, Coll Med, Seoul, South Korea; [Hong, Gil-Sun] Univ Ulsan, Coll Med, Dept Radiol, Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea; [Hong, Gil-Sun; Kim, Namkug] Univ Ulsan, Res Inst Radiol, Asan Med Ctr, Coll Med, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea; [Kim, Namkug] Univ Ulsan, Coll Med, Dept Radiol, Dept Convergence Med & Radiol,Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea	University of Ulsan; Asan Medical Center; University of Ulsan; Asan Medical Center; Korea University; Korea University Medicine (KU Medicine); Korea Advanced Institute of Science & Technology (KAIST); University of Ulsan; Asan Medical Center; University of Ulsan; Asan Medical Center; University of Ulsan; University of Ulsan; University of Ulsan	Hong, GS (corresponding author), Univ Ulsan, Coll Med, Dept Radiol, Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.; Hong, GS; Kim, N (corresponding author), Univ Ulsan, Res Inst Radiol, Asan Med Ctr, Coll Med, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.; Kim, N (corresponding author), Univ Ulsan, Coll Med, Dept Radiol, Dept Convergence Med & Radiol,Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.	hgs2013@gmail.com; namkugkim@gmail.com		Hong, Gil-Sun/0000-0002-0068-9413; Kim, Kiduk/0000-0002-9659-897X; Kim, Namkug/0000-0002-3438-2217; Choi, Edward/0000-0002-5958-3509	Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI) - Ministry of Health & Welfare, Republic of Korea [HI21C1148, HI22C1723]	Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI) - Ministry of Health & Welfare, Republic of Korea	Funding Statement This research was supported by grants from the Korea Health Technology R&D Project through the Korea Health Industry Development Institute (KHIDI) , funded by the Ministry of Health & Welfare, Republic of Korea (HI21C1148 and HI22C1723) .	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Al Khalil Y, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102688; Alayrac Jean-Baptiste., Flamingo: a visual language model for few-shot learning; [Anonymous], A style-based generator architecture for generative adversarial networks; Antol S, VQA: visual question answering; Arora A, 2023, LANCET, V401, P997, DOI 10.1016/S0140-6736(23)00324-0; Bae K, 2022, KOREAN J RADIOL, V23, P139; Banerjee R, 2022, BRIT J HAEMATOL, V196, P1274, DOI 10.1111/bjh.17945; Bau D, Seeing what a GAN cannot generate; Behrendt F, 2023, Arxiv, DOI arXiv:2303.03758; Bowles C, Modelling the progression of Alzheimer's disease in MRI using generative adversarial networks, DOI [10.1117/12.2293256, DOI 10.1117/12.2293256]; Brown T., 2020, NIPS, P1877; Cao M, 2022, Arxiv, DOI arXiv:2203.14713; Chen RT, Isolating sources of disentanglement in VAEs; Chen XP, 2018, Arxiv, DOI arXiv:1812.03426; Cho KYJ, 2023, J DIGIT IMAGING, V36, P902, DOI 10.1007/s10278-023-00782-4; Choi Y., STARGAN UNIFIED GENE; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HYJ, 2022, MED IMAGE ANAL, V80, DOI 10.1016/j.media.2022.102479; Chung J, A recurrent latent variable model for sequential data; Chung M, 2022, J DIGIT IMAGING, V35, P1061, DOI 10.1007/s10278-022-00608-9; Conte GM, 2021, RADIOLOGY, V299, P313, DOI 10.1148/radiol.2021203786; de Rosa GH, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108098; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Durall R., 2020, arXiv; Elreedy D, 2019, INFORM SCIENCES, V505, P32, DOI 10.1016/j.ins.2019.07.070; Fetty L, 2020, Z MED PHYS, V30, P305, DOI 10.1016/j.zemedi.2020.05.001; Fontanella A, 2023, Arxiv, DOI [arXiv:2308.02062, 10.48550/arXiv.2308.02062, DOI 10.48550/ARXIV.2308.02062]; Gao Q, 2023, PREPRINT, DOI [10.1109/TMI.2023.3320812, DOI 10.1109/TMI.2023.3320812]; Gao Q, 2022, PROC SPIE, V12242, DOI 10.1117/12.2634939; Ghesu F, 2022, Arxiv, DOI arXiv:2201.01283; Goodfellow I. J., Generative adversarial networks; Gravina M, 2022, LECT NOTES COMPUT SC, V13231, P100, DOI 10.1007/978-3-031-06427-2_9; Gregor Karol., Draw: A recurrent neural network for image generation; Gu J, 2021, IEEE T COMPUT IMAG, V7, P73, DOI 10.1109/TCI.2021.3050266; Han CHE, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-020-03936-1; Harms J, 2019, MED PHYS, V46, P3998, DOI 10.1002/mp.13656; Ho Jonathan, Denoising diffusion probabilistic models; Hoang TT, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207181; Hong GS, 2023, KOREAN J RADIOL, V24, P1061, DOI 10.3348/kjr.2023.0393; Hossain MZ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3295748; Hu CF, 2023, Arxiv, DOI [arXiv:2304.08506, DOI 10.48550/ARXIV.2304.08506]; Huang JH, 2023, LECT NOTES COMPUT SC, V14229, P3, DOI 10.1007/978-3-031-43999-5_1; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; Ivanov O, 2019, Arxiv, DOI [arXiv:1806.02382, 10.48550/arXiv.1806.02382, DOI 10.48550/ARXIV.1806.02382]; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jia C, Scaling up visual and vision-language representation learning with noisy text supervision; Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35; Jung KH, 2023, KOREAN J RADIOL, V24, P1038, DOI 10.3348/kjr.2023.0790; Kahambing JG, 2023, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdad028; Kang E, 2019, MED PHYS, V46, P550, DOI 10.1002/mp.13284; Karras T, ANAL IMPROVING IMAGE; Karras T, Training generative adversarial networks with limited data; Karras T, 2018, Arxiv, DOI arXiv:1710.10196; Karras Tero., Alias-free generative adversarial networks; Khosla M, 2019, LECT NOTES COMPUT SC, V11861, P301, DOI 10.1007/978-3-030-32692-0_35; Kim B, 2022, LECT NOTES COMPUT SC, V13691, P347, DOI 10.1007/978-3-031-19821-2_20; Kim KH, 2018, MED PHYS, V45, P3120, DOI 10.1002/mp.12945; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Koga S, 2023, KOREAN J RADIOL, V24, P924, DOI 10.3348/kjr.2023.0738; KRAMER MA, 1992, COMPUT CHEM ENG, V16, P313, DOI 10.1016/0098-1354(92)80051-A; Kwon T, 2021, IEEE T COMPUT IMAG, V7, P1354, DOI 10.1109/TCI.2021.3129369; Lee JS, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0285489; Lee S, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31808-0; Lei Y, 2020, MED PHYS, V47, P530, DOI 10.1002/mp.13933; Lei Y, 2019, MED PHYS, V46, P3565, DOI 10.1002/mp.13617; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Li JP, 2023, LECT NOTES COMPUT SC, V14224, P579, DOI 10.1007/978-3-031-43904-9_56; Li Q, Ultra-low dose CT image denoising based on conditional denoising diffusion probabilistic model, DOI [10.1109/CyberC55534.2022.00041, DOI 10.1109/CYBERC55534.2022.00041]; Liang X, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab22f9; Liao ZB, 2019, LECT NOTES COMPUT SC, V11765, P687, DOI 10.1007/978-3-030-32245-8_76; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu X, 2023, Arxiv, DOI [arXiv:2305.15887, DOI 10.48550/ARXIV.2305.15887, 10.48550/arXiv.2305.15887]; Lyu Q, 2022, Arxiv, DOI arXiv:2209.12104; Ma J, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-44824-z; Marcel S, 2007, IEEE T PATTERN ANAL, V29, P743, DOI 10.1109/TPAMI.2007.1012; Maspero M, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aada6d; Mazurowski MA, 2023, MED IMAGE ANAL, V89, DOI 10.1016/j.media.2023.102918; Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]; Mokady R, Null- text inversion for editing real images using guided diffusion models; Mündler N, 2024, Arxiv, DOI arXiv:2305.15852; Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48; Nakao T, 2021, J DIGIT IMAGING, V34, P418, DOI 10.1007/s10278-020-00413-2; Nie D, 2018, IEEE T BIO-MED ENG, V65, P2720, DOI 10.1109/TBME.2018.2814538; Odena A., 2016, Distill, DOI [10.23915/DISTILL.00003, 10.23915/distill.00003, DOI 10.23915/DISTILL.00003, 10.23915/distill.00003.-URL]; Ouyang L, Training language models to follow instructions with human feedback; Özbey M, 2023, IEEE T MED IMAGING, V42, P3524, DOI 10.1109/TMI.2023.3290149; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Pan SY, 2023, Arxiv, DOI [arXiv:2305.19467, DOI 10.48550/ARXIV.2305.19467, 10.48550/arXiv.2305.19467]; Park JE, 2022, KOREAN J RADIOL, V23, P500, DOI 10.3348/kjr.2022.0033; Park SH, 2023, KOREAN J RADIOL, V24, P715, DOI 10.3348/kjr.2023.0643; Pinaya WHL, 2022, LECT NOTES COMPUT SC, V13438, P705, DOI 10.1007/978-3-031-16452-1_67; Preetha CJ, 2021, LANCET DIGIT HEALTH, V3, pE784, DOI 10.1016/S2589-7500(21)00205-3; Radford A., Learning transferable visual models from natural language supervision. International conference on machine learning. PMLR; 2021. p. 87488763; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2016, Arxiv, DOI arXiv:1511.06434; Rahman A, Ambiguous medical image segmentation using diffusion models; Rajotte JF, 2022, ISCIENCE, V25, DOI 10.1016/j.isci.2022.105331; Ramesh A., 2022, arXiv; Ramesh A, Zero-shot text-to-image generation; Ren Zhihang, 2022, J Percept Imaging, V5, P0005021, DOI 10.2352/j.percept.imaging.2022.5.000502; Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x; Selim M, 2023, Arxiv, DOI arXiv:2301.08815; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sohail M, 2019, LECT NOTES COMPUT SC, V11827, P22, DOI 10.1007/978-3-030-32778-1_3; Sohn K., Learning structured output representation using deep conditional generative models; Song JM, 2022, Arxiv, DOI arXiv:2010.02502; Song Y, 2021, Arxiv, DOI arXiv:2011.13456; Tang C, 2019, COMPUT MATH METHOD M, V2019, DOI 10.1155/2019/8639825; Tanner C, 2018, Arxiv, DOI arXiv:1807.07349; Thorlund K, 2020, CLIN EPIDEMIOL, V12, P457, DOI 10.2147/CLEP.S242097; Topol EJ, 2021, LANCET, V397, P785, DOI 10.1016/S0140-6736(21)00452-9; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Quan TM, 2018, IEEE T MED IMAGING, V37, P1488, DOI 10.1109/TMI.2018.2820120; Uppal S, 2022, INFORM FUSION, V77, P149, DOI 10.1016/j.inffus.2021.07.009; Vahdat A., 2021, NVAE: a deep hierarchical variational autoencoder; van Breugel B, DECAF: generating fair synthetic data using causally-aware generative networks; van Hespen KM, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87013-4; Vaswani A, 2017, ADV NEUR IN, V30; Wang JN, 2018, LECT NOTES COMPUT SC, V11070, P3, DOI 10.1007/978-3-030-00928-1_1; Wang T, High-fidelity GAN inversion for image attribute editing; Wolleb Julia, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P14, DOI 10.1007/978-3-030-59719-1_2; Wolleb J, Diffusion models for implicit image segmentation ensembles; Wolleb J, 2022, LECT NOTES COMPUT SC, V13438, P35, DOI 10.1007/978-3-031-16452-1_4; Wolterink JM, 2017, IEEE T MED IMAGING, V36, P2536, DOI 10.1109/TMI.2017.2708987; Wu CY, 2023, Arxiv, DOI [arXiv:2308.02463, DOI 10.48550/ARXIV.2308.02463]; Wu JD, 2023, Arxiv, DOI [arXiv:2301.11798, DOI 10.48550/ARXIV.2301.11798]; Wu JD, 2022, Arxiv, DOI arXiv:2211.00611; Xia WH, 2023, IEEE T PATTERN ANAL, V45, P3121, DOI 10.1109/TPAMI.2022.3181070; Xia WJ, 2022, Arxiv, DOI arXiv:2209.15136; Yan CG, 2021, KOREAN J RADIOL, V22, P983, DOI 10.3348/kjr.2020.0988; Yan PK, 2018, LECT NOTES COMPUT SC, V11046, P197, DOI 10.1007/978-3-030-00919-9_23; Yang G, 2018, IEEE T MED IMAGING, V37, P1310, DOI 10.1109/TMI.2017.2785879; Yang S, 2021, IEEE T MED IMAGING, V40, P3015, DOI 10.1109/TMI.2021.3077615; Yang Z, 2023, arXiv, DOI 10.48550/arXiv.2309.09357; Yao Z, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-36102-1; Yin Y, DiffGAR: model-agnostic restoration from generative artifacts using image-to-image diffusion models, DOI [10.1145/3577530.3577539, DOI 10.1145/3577530.3577539]; Yuan L., 2021, arXiv; Zellers Rowan., 2019, From Recognition to Cognition: Visual Commonsense Reasoning; Zhang KD, 2023, Arxiv, DOI arXiv:2304.13785; Zhang YC, 2023, Arxiv, DOI arXiv:2305.03678; Zhu J.-Y., Unpaired image-to-image translation using cycle-consistent adversarial networks	144	2	2	31	31	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	MAR	2024	25	3					224	242		10.3348/kjr.2023.0818	http://dx.doi.org/10.3348/kjr.2023.0818			19	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	KI9I8	38413108	Green Published			2024-07-03	WOS:001179444600005
J	De Paoli, S				De Paoli, Stefano			Performing an Inductive Thematic Analysis of Semi-Structured Interviews With a Large Language Model: An Exploration and Provocation on the Limits of the Approach	SOCIAL SCIENCE COMPUTER REVIEW			English	Article; Early Access						large language models; thematic analysis; qualitative research; human- AI collaboration		Large Language Models (LLMs) have emerged as powerful generative Artificial Intelligence solutions. This paper presents results and reflections of an experiment done with the LLM GPT 3.5-Turbo to perform an inductive Thematic Analysis (TA). Previous research has worked on conducting deductive analysis. Thematic Analysis is a qualitative method for analysis commonly used in social sciences and it is based on interpretations by the human analyst(s) and the identification of explicit and latent meanings in qualitative data. The paper presents the motivations for attempting this analysis; it reflects on how the six phases to a TA proposed by Braun and Clarke can partially be reproduced with the LLM and it reflects on what are the model's outputs. The paper uses two datasets of open access semi-structured interviews, previously analysed by other researchers. The first dataset contains interviews with videogame players, and the second is a dataset of interviews with lecturers teaching data science in a University. This paper used the analyses previously conducted on these datasets to compare with the results produced by the LLM. The results show that the model can infer most of the main themes from previous research. This shows that using LLMs to perform an inductive TA is viable and offers a good degree of validity. The discussion offers some recommendations for working with LLMs in qualitative analysis.	[De Paoli, Stefano] Abertay Univ, Digital Soc, Dundee, Scotland; [De Paoli, Stefano] Abertay Univ, Sociol Div, Bell St, Dundee DD1 1HG, Scotland	University of Abertay Dundee; University of Abertay Dundee	De Paoli, S (corresponding author), Abertay Univ, Sociol Div, Bell St, Dundee DD1 1HG, Scotland.	s.depaoli@abertay.ac.uk		De Paoli, Stefano/0000-0003-1120-4773				Baden C, 2022, COMMUN METHODS MEAS, V16, P1, DOI 10.1080/19312458.2021.2015574; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Curty R., 2022, Teaching undergraduates with quantitative data in the social sciences at University of California Santa Barbara, DOI [10.25349/D9402J, DOI 10.25349/D9402J]; Curty R., 2021, Teaching undergraduates with quantitative data in the social sciences at University of California Santa Barbara: a local report; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Flick U., 2018, SAGE HDB QUALITATIVE, DOI [10.4135/9781526416070.n4, DOI 10.4135/9781526416070.N4]; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Gao J, 2024, Arxiv, DOI [arXiv:2304.07366, 10.48550/arXiv.2304.07366, DOI 10.48550/ARXIV.2304.07366]; Gauthier Robert P., 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3492844; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Hao SB, 2023, Arxiv, DOI arXiv:2305.14992; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Jiang Jialun Aaron, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449168; Julianto I. T., 2023, Jurnal Nasional Pendidikan Teknik Informatika (JANAPATI), V12, P67, DOI [10.23887/janapati.v12i1.59746, DOI 10.23887/JANAPATI.V12I1.59746]; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Nelson LK, 2020, SOCIOL METHOD RES, V49, P3, DOI 10.1177/0049124117729703; Nowell LS., 2017, International Journal of Qualitative Methods, V16, DOI DOI 10.1177/1609406917733847; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perrotta Carlo, 2018, Zenodo, V1.2, DOI 10.5281/zenodo.1163698; Persico D., 2017, D2. 3 Report on interviews with experts and informants; Persico D., 2017, D2.1 Systematic Review and Methodological Framework; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Rai A, 2020, J ACAD MARKET SCI, V48, P137, DOI 10.1007/s11747-019-00710-5; Renz SM, 2018, QUAL HEALTH RES, V28, P824, DOI 10.1177/1049732317753586; Richards KAR, 2018, J TEACH PHYS EDUC, V37, P225, DOI 10.1123/jtpe.2017-0084; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sanmarchi F, 2023, medRxiv, DOI [10.1101/2023.02.06.23285514, 10.1101/2023.02.06.23285514, DOI 10.1101/2023.02.06.23285514]; Schiavone W., 2023, Can ChatGPT Replace UX Researchers? An Empirical Analysis of Comment Classifications; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	33	2	2	25	25	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0894-4393	1552-8286		SOC SCI COMPUT REV	Soc. Sci. Comput. Rev.	2023 DEC 7	2023										10.1177/08944393231220483	http://dx.doi.org/10.1177/08944393231220483		DEC 2023	23	Computer Science, Interdisciplinary Applications; Information Science & Library Science; Social Sciences, Interdisciplinary	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science; Social Sciences - Other Topics	AC9Y5		Green Published, hybrid			2024-07-03	WOS:001116391300001
J	David, AN; Sewsynker-Sukai, Y; Meyer, EL; Kana, EBG				David, Anthea Naomi; Sewsynker-Sukai, Y.; Meyer, E. L.; Kana, E. B. Gueguim			Harnessing Artificial Neural Networks and large language models for bioprocess optimization: Predicting sugar output from Kraft waste-based lignocellulosic pretreatments	INDUSTRIAL CROPS AND PRODUCTS			English	Article						Artificial Neural Network; Bioprocess modelling and optimization; Sensitivity analysis; Large language models; Kraft waste-based pretreatment	ALKALINE HYDROGEN-PEROXIDE; SALT PRETREATMENT; ENZYMATIC SACCHARIFICATION; BIOETHANOL PRODUCTION; DELIGNIFICATION; HYDROLYSIS; BAGASSE	This study implements Artificial Neural Network (ANN) models as predictive tools for glucose responses from Kraft waste-based pretreatments. The developed steam- and microwave-assisted ANN models achieved R2 scores > 0.95 for the observed and predicted glucose responses. An in-depth sensitivity analysis revealed that the glucose responses for the steam and microwave models were highly susceptible to the stepwise variation in green liquor dregs concentration (>3.3-fold) and power intensity (>2.6-fold), respectively. Comparative assessment on the capability of the large language model, ChatGPT, to generate innovative and factually accurate insights based on the process data was carried out. The novel process insights deduced by ChatGPT concurred with the authors' findings of this study, underscoring the unique critical role of integrating advanced artificial intelligence and domain-specific knowledge to accelerate progression in lignocellulosic waste pretreatment. As such, these synergies align with global sustainable developmental objectives that leverage 4IR technologies, propelling this research field forward.	[David, Anthea Naomi; Kana, E. B. Gueguim] Univ KwaZulu Natal, Sch Life Sci, Pietermaritzburg, South Africa; [Sewsynker-Sukai, Y.; Meyer, E. L.] Univ Ft Hare, Ft Hare Inst Technol, Private Bag X1314, ZA-5700 Alice, South Africa	University of Kwazulu Natal; University of Fort Hare	Kana, EBG (corresponding author), Univ KwaZulu Natal, Sch Life Sci, Pietermaritzburg, South Africa.	kanag@ukzn.ac.za		Evariste Bosco, GUEGUIM KANA/0000-0002-1598-7851	National Research Foundation (NRF) of South Africa [122080]	National Research Foundation (NRF) of South Africa(National Research Foundation - South Africa)	This work is based on research supported in part by the National Research Foundation (NRF) of South Africa (Grant number 122080) . Opinions expressed and conclusions arrived at, are those of the authors and are not necessarily to be attributed to the NRF.	Chang CW, 2011, J TAIWAN INST CHEM E, V42, P889, DOI 10.1016/j.jtice.2011.04.002; Chen S, 2020, ENERGY AI, V2, DOI 10.1016/j.egyai.2020.100028; David AN, 2021, IND CROP PROD, V174, DOI 10.1016/j.indcrop.2021.114222; David AN, 2020, FUEL, V274, DOI 10.1016/j.fuel.2020.117797; Jeoh T, 2017, BIOTECHNOL BIOENG, V114, P1369, DOI 10.1002/bit.26277; Kim JS, 2016, BIORESOURCE TECHNOL, V199, P42, DOI 10.1016/j.biortech.2015.08.085; Kumari N., 2019, Bioresour. Technol. Rep., V7, DOI [10.1016/j.biteb.2019.100289, DOI 10.1016/J.BITEB.2019.100289]; Laltha M, 2024, BIOMASS CONVERS BIOR, V14, P4139, DOI 10.1007/s13399-022-02630-x; Laltha M, 2021, IND CROP PROD, V174, DOI 10.1016/j.indcrop.2021.114166; Lee KM, 2020, BIOMASS BIOENERG, V139, DOI 10.1016/j.biombioe.2020.105621; Lin RC, 2015, BIORESOURCE TECHNOL, V182, P1, DOI 10.1016/j.biortech.2015.01.105; McKendry P, 2002, BIORESOURCE TECHNOL, V83, P37, DOI 10.1016/S0960-8524(01)00118-3; Moodley P, 2019, BIORESOURCE TECHNOL, V273, P682, DOI 10.1016/j.biortech.2018.11.034; Muthuvelu KS, 2019, WASTE MANAGE, V87, P368, DOI 10.1016/j.wasman.2019.02.015; Nikzad M, 2015, CHEM ENG COMMUN, V202, P728, DOI 10.1080/00986445.2013.871707; Nunes LJR, 2020, RENEW SUST ENERG REV, V120, DOI 10.1016/j.rser.2019.109658; Oh SE, 2003, ENVIRON SCI TECHNOL, V37, P5186, DOI 10.1021/es034291y; Patel A, 2021, J BIORESOUR BIOPROD, V6, P108, DOI 10.1016/j.jobab.2021.02.001; Qing Q, 2016, BIORESOURCE TECHNOL, V201, P230, DOI 10.1016/j.biortech.2015.11.059; Raghavi S, 2016, BIORESOURCE TECHNOL, V199, P202, DOI 10.1016/j.biortech.2015.08.062; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rebello S, 2020, BIORESOURCE TECHNOL, V301, DOI 10.1016/j.biortech.2019.122678; Rego ASC, 2018, BIORESOURCE TECHNOL, V267, P634, DOI 10.1016/j.biortech.2018.07.087; Rorke DCS, 2017, BIORESOURCE TECHNOL, V224, P590, DOI 10.1016/j.biortech.2016.10.048; Sebayang AH, 2017, IND CROP PROD, V97, P146, DOI 10.1016/j.indcrop.2016.11.064; Sewsynker-Sukai Y, 2018, IND CROP PROD, V125, P284, DOI 10.1016/j.indcrop.2018.08.086; Sewsynker-Sukai Y, 2017, BIORESOURCE TECHNOL, V243, P785, DOI 10.1016/j.biortech.2017.06.175; Sewsynker-Sukai Y, 2017, INT J HYDROGEN ENERG, V42, P5780, DOI 10.1016/j.ijhydene.2017.02.074; Sindhu R, 2016, BIORESOURCE TECHNOL, V213, P58, DOI 10.1016/j.biortech.2016.02.079; Sorn V, 2019, BIORESOURCE TECHNOL, V293, DOI 10.1016/j.biortech.2019.121929; Toscan A, 2019, BIORESOURCE TECHNOL, V285, DOI 10.1016/j.biortech.2019.121346; Valim IC, 2017, BIORESOURCE TECHNOL, V243, P760, DOI 10.1016/j.biortech.2017.06.029; Vani S, 2015, BIORESOURCE TECHNOL, V188, P128, DOI 10.1016/j.biortech.2015.01.083	33	1	1	14	17	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0926-6690	1872-633X		IND CROP PROD	Ind. Crop. Prod.	DEC 15	2023	206								117686	10.1016/j.indcrop.2023.117686	http://dx.doi.org/10.1016/j.indcrop.2023.117686		NOV 2023	10	Agricultural Engineering; Agronomy	Science Citation Index Expanded (SCI-EXPANDED)	Agriculture	Z1JS9		hybrid			2024-07-03	WOS:001109722100001
J	Chen, XQ; Gao, Y; Wang, LD; Cui, WJ; Huang, JM; Du, Y; Wang, B				Chen, Xueqing; Gao, Yang; Wang, Ludi; Cui, Wenjuan; Huang, Jiamin; Du, Yi; Wang, Bin			Large language model enhanced corpus of CO<sub>2</sub> reduction electrocatalysts and synthesis procedures	SCIENTIFIC DATA			English	Article							CARBON-DIOXIDE	CO2 electroreduction has garnered significant attention from both the academic and industrial communities. Extracting crucial information related to catalysts from domain literature can help scientists find new and effective electrocatalysts. Herein, we used various advanced machine learning, natural language processing techniques and large language models (LLMs) approaches to extract relevant information about the CO2 electrocatalytic reduction process from scientific literature. By applying the extraction pipeline, we present an open-source corpus for electrocatalytic CO(2)reduction. The database contains two types of corpus: (1) the benchmark corpus, which is a collection of 6,985 records extracted from 1,081 publications by catalysis postgraduates; and (2) the extended corpus, which consists of content extracted from 5,941 documents using traditional NLP techniques and LLMs techniques. The Extended Corpus I and II contain 77,016 and 30,283 records, respectively. Furthermore, several domain literature fine-tuned LLMs were developed. Overall, this work will contribute to the exploration of new and effective electrocatalysts by leveraging information from domain literature using cutting-edge computer techniques.	[Chen, Xueqing; Wang, Ludi; Cui, Wenjuan; Du, Yi] Chinese Acad Sci, Comp Network Informat Ctr, Lab Big Data Knowledge, Beijing 100083, Peoples R China; [Chen, Xueqing; Du, Yi] Univ Chinese Acad Sci, Beijing 100049, Peoples R China; [Gao, Yang; Huang, Jiamin; Wang, Bin] Natl Ctr Nanosci & Technol NCNST, CAS Key Lab Nanosyst & Hierarch Fabricat, Beijing 100190, Peoples R China; [Du, Yi] UCAS, Hangzhou Inst Adv Study, Hangzhou 310000, Peoples R China	Chinese Academy of Sciences; Computer Network Information Center, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; National Center for Nanoscience & Technology, CAS	Du, Y (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Lab Big Data Knowledge, Beijing 100083, Peoples R China.; Du, Y (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.; Wang, B (corresponding author), Natl Ctr Nanosci & Technol NCNST, CAS Key Lab Nanosyst & Hierarch Fabricat, Beijing 100190, Peoples R China.; Du, Y (corresponding author), UCAS, Hangzhou Inst Adv Study, Hangzhou 310000, Peoples R China.	duyi@cnic.cn; wangb@nanoctr.cn		Gao, Yang/0000-0002-3451-1904; Chen, Xueqing/0009-0008-8926-9626	National Natural Science Foundation of China (National Science Foundation of China) [2022YFF0712200, 2022YFF0711900, 2021YFA1202802]; National Key Research and Development Plan of China [T2322027]; Natural Science Foundation of China; Information Science Database in National Basic Science Data Center [BYESS2023410]; Young Elite Scientists Sponsorship Program by Beijing Association for Science and Technology; CAS Pioneer Hundred Talents Program; Youth Innovation Promotion Association CAS	National Natural Science Foundation of China (National Science Foundation of China)(National Natural Science Foundation of China (NSFC)); National Key Research and Development Plan of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Information Science Database in National Basic Science Data Center; Young Elite Scientists Sponsorship Program by Beijing Association for Science and Technology; CAS Pioneer Hundred Talents Program; Youth Innovation Promotion Association CAS	This work was supported by the National Key Research and Development Plan of China under Grant No. 2022YFF0712200, 2022YFF0711900 and 2021YFA1202802, the Natural Science Foundation of China under Grant No. T2322027, Information Science Database in National Basic Science Data Center under Grant No.NBSDC-DB-25, the Young Elite Scientists Sponsorship Program by Beijing Association for Science and Technology (BYESS2023410), the CAS Pioneer Hundred Talents Program and Youth Innovation Promotion Association CAS.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2005, P HUM LANG TECHN C C, DOI DOI 10.3115/1220575.1220634; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Bang Y., 2023, Long Papers, V1, P675; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Birdja YY, 2019, NAT ENERGY, V4, P732, DOI 10.1038/s41560-019-0450-y; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Borthwick A., 1999, A maximum entropy approach to named entity recognition; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2; Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]; Corbett P, 2006, LECT NOTES COMPUT SC, V4216, P107; Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6; Gao Y, 2023, ACS CATAL, V13, P8525, DOI 10.1021/acscatal.3c00759; He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553; Hettne KM, 2009, BIOINFORMATICS, V25, P2983, DOI 10.1093/bioinformatics/btp535; Hiszpanski AM, 2020, J CHEM INF MODEL, V60, P2876, DOI 10.1021/acs.jcim.0c00199; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Honnibal M., 2015, P 2015 C EMP METH NA, P1373, DOI [10.18653/v1/D15-1162, DOI 10.18653/V1/D15-1162]; Huang S, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00602-2; Huo HY, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0204-1; Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1; Kumar K, 2023, Arxiv, DOI arXiv:2304.02138; Liu R., 2018, PyMuPDF; Ma XZ, 2016, Arxiv, DOI [arXiv:1603.01354, DOI 10.48550/ARXIV.1603.01354]; Nakayama H, 2018, DOCCANO TEXT ANNOTAT; Paula AJ, 2022, CHEM MATER, V34, P979, DOI 10.1021/acs.chemmater.1c02961; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Peng JY, 2022, NAT REV MATER, V7, P991, DOI 10.1038/s41578-022-00466-5; Plank B, 2016, Arxiv, DOI arXiv:1604.05529; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Qiao JL, 2014, CHEM SOC REV, V43, P631, DOI 10.1039/c3cs60323g; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rebholz-Schuhmann D, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION; Rehrek Radim., 2010, Software framework for topic modelling with large corpora; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Teller V, 2000, COMPUT LINGUIST, V26, P638, DOI 10.1162/089120100750105975; Vaucher AC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17266-6; Wang L., 2023, A complete dataset of 476 catalytic material synthesis processes, DOI [10.57760/sciencedb.13293, DOI 10.57760/SCIENCEDB.13293]; Wang L., 2023, Benchmark corpus of CO>2 reduction electrocatalysts and synthesis procedures, DOI [10.57760/sciencedb.13290, DOI 10.57760/SCIENCEDB.13290]; Wang L, 2023, The extended corpus of CO>2 reduction electrocatalysts and synthesis procedures, DOI [10.57760/sciencedb.13292, DOI 10.57760/SCIENCEDB.13292]; Wang LD, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02089-z; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Zheng TT, 2018, ADV MATER, V30, DOI 10.1002/adma.201802066; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819; Zhong M, 2020, NATURE, V581, P178, DOI 10.1038/s41586-020-2242-8	49	0	0	5	5	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2052-4463		SCI DATA	Sci. Data	APR 6	2024	11	1							347	10.1038/s41597-024-03180-9	http://dx.doi.org/10.1038/s41597-024-03180-9			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	ND1A1	38582751	Green Published, gold			2024-07-03	WOS:001198408200005
J	Krusche, M; Callhoff, J; Knitza, J; Ruffer, N				Krusche, Martin; Callhoff, Johnna; Knitza, Johannes; Ruffer, Nikolas			Diagnostic accuracy of a large language model in rheumatology: comparison of physician and ChatGPT-4	RHEUMATOLOGY INTERNATIONAL			English	Article						Large language models; ChatGPT; Rheumatology; Triage; Diagnostic process; Artificial intelligence		Pre-clinical studies suggest that large language models (i.e., ChatGPT) could be used in the diagnostic process to distinguish inflammatory rheumatic (IRD) from other diseases. We therefore aimed to assess the diagnostic accuracy of ChatGPT-4 in comparison to rheumatologists. For the analysis, the data set of Graf et al. (2022) was used. Previous patient assessments were analyzed using ChatGPT-4 and compared to rheumatologists' assessments. ChatGPT-4 listed the correct diagnosis comparable often to rheumatologists as the top diagnosis 35% vs 39% (p = 0.30); as well as among the top 3 diagnoses, 60% vs 55%, (p = 0.38). In IRD-positive cases, ChatGPT-4 provided the top diagnosis in 71% vs 62% in the rheumatologists' analysis. Correct diagnosis was among the top 3 in 86% (ChatGPT-4) vs 74% (rheumatologists). In non-IRD cases, ChatGPT-4 provided the correct top diagnosis in 15% vs 27% in the rheumatologists' analysis. Correct diagnosis was among the top 3 in non-IRD cases in 46% of the ChatGPT-4 group vs 45% in the rheumatologists group. If only the first suggestion for diagnosis was considered, ChatGPT-4 correctly classified 58% of cases as IRD compared to 56% of the rheumatologists (p = 0.52). ChatGPT-4 showed a slightly higher accuracy for the top 3 overall diagnoses compared to rheumatologist's assessment. ChatGPT-4 was able to provide the correct differential diagnosis in a relevant number of cases and achieved better sensitivity to detect IRDs than rheumatologist, at the cost of lower specificity. The pilot results highlight the potential of this new technology as a triage tool for the diagnosis of IRD.	[Krusche, Martin; Ruffer, Nikolas] Univ Hosp Hamburg Eppendorf UKE, Div Rheumatol & Syst Inflammatory Dis, Hamburg, Germany; [Callhoff, Johnna] German Rheumatism Res Ctr, Epidemiol Unit, Berlin, Germany; [Callhoff, Johnna] Charite Univmed, Inst Social Med Epidemiol & Hlth Econ, Berlin, Germany; [Knitza, Johannes] Philipps Univ Marburg, Univ Hosp Giessen & Marburg, Inst Digital Med, Marburg, Germany; [Knitza, Johannes] Univ Grenoble Alpes, AGEIS, Grenoble, France	University of Hamburg; University Medical Center Hamburg-Eppendorf; Deutsches Rheuma-Forschungszentrum (DRFZ); Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; University Hospital of Giessen & Marburg; Philipps University Marburg; Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA)	Krusche, M (corresponding author), Univ Hosp Hamburg Eppendorf UKE, Div Rheumatol & Syst Inflammatory Dis, Hamburg, Germany.	m.krusche@uke.de; Johanna.callhoff@drfz.de; johannes.knitza@uk-erlangen.de; n.ruffer@uke.de		Knitza, Johannes/0000-0001-9695-0657; Callhoff, Johanna/0000-0002-3923-2728; Ruffer, Nikolas/0000-0001-8394-969X; Krusche, Martin/0000-0002-0582-7790	Projekt DEAL	Projekt DEAL	& nbsp;Open Access funding enabled and organized by Projekt DEAL. MK: Speaker fee from Ada, Scientific funding: Ada. JC: Speaker' fees from Janssen-Cilag, Pfizer, and Idorsia, all unrelated to this work.	[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; de Thurah A, 2022, ANN RHEUM DIS, V81, P1065, DOI 10.1136/annrheumdis-2022-222341; Fuchs F, 2023, RHEUMATOL INT, V43, P495, DOI 10.1007/s00296-022-05223-z; Gräf M, 2022, RHEUMATOL INT, V42, P2167, DOI 10.1007/s00296-022-05202-4; Hügle T, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003105; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Knitza J, 2021, ARTHRITIS RES THER, V23, DOI 10.1186/s13075-021-02498-8; Krusche M, 2019, Z RHEUMATOL, V78, P692, DOI 10.1007/s00393-019-00690-5; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Miloslavsky EM, 2022, J RHEUMATOL, V49, P555, DOI 10.3899/jrheum.220300; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Verhoeven F, 2023, ANN RHEUM DIS, V82, P1015, DOI 10.1136/ard-2023-223936	15	10	10	4	16	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0172-8172	1437-160X		RHEUMATOL INT	Rheumatol. Int.	FEB	2024	44	2					303	306		10.1007/s00296-023-05464-6	http://dx.doi.org/10.1007/s00296-023-05464-6		SEP 2023	4	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	FD2B3	37742280	hybrid			2024-07-03	WOS:001070598100001
C	Murray, JT; Murray, J; Salter, A			ACM	Murray, John T.; Murray, Jack; Salter, Anastasia			Playing with AI Chat	PROCEEDINGS OF THE 41ST INTERNATIONAL CONFERENCE ON DESIGN OF COMMUNICATION, SIGDOC 2023			English	Proceedings Paper	41st ACM International Conference on Design of Communication (SIGDOC)	OCT 26-28, 2023	Univ Cent Florida, Orlando, FL	Assoc Comp Machinery, Arizona State Univ, DePaul Univ, George Mason Univ, Michigan State Univ, Texas Tech Univ, Univ Minnesota, Univ N Texas, XML Press, Rosenfeld Media, Balsamiq, Axure, Loop11, Special Interest Grp Design Commun	Univ Cent Florida	ChatGPT; Large-Language Models; Chat Interfaces; GPT-4; Bard; Bing Chat; AI Dungeon		Large language models (LLMs) use statistical models to predict the next sequence of tokens and have capabilities previously considered unattainable outside of human intelligence. Communication design can benefit from a close examination of the ongoing conversations around the adoption and use of LLMs, both the public discourse and the specific language and rhetoric used in the initial set of application interfaces and prompts. Through a survey of existing practices and a case study of how AI is used within the interactive fiction community, where procedural content generation has played with expectations and personas, this paper offers a foundation for future critique of these models as they are embedded in the digital tools we rely upon for daily communication and work.	[Murray, John T.; Salter, Anastasia] Univ Cent Florida, Orlando, FL 32816 USA; [Murray, Jack] Univ Texas Dallas, Dallas, TX USA	State University System of Florida; University of Central Florida; University of Texas System; University of Texas Dallas	Murray, JT (corresponding author), Univ Cent Florida, Orlando, FL 32816 USA.	jtm@ucf.edu; jam130530@utdallas.edu; anastasia@ucf.edu						[Anonymous], 2019, OpenAI's new multitalented AI writes, translates, and slanders; [Anonymous], 2022, ChatGPT Is Dumber Than You Think; [Anonymous], 2023, Microsoft's Bing is an emotionally manipulative liar, and people love it; [Anonymous], 2023, Deep Learning (South Park); [Anonymous], 2019, The Creator of AI Dungeon 2 Shares GPT-2 Finetuning Advice; [Anonymous], 2019, This AI text adventure game has pretty much infinite possibilities; [Anonymous], 2019, OpenAI has published the text-generating AI it said was too dangerous to share; [Anonymous], 2023, The First Year of AI College Ends in Ruin; [Anonymous], 2019, GPT-2: 1.5B Release; [Anonymous], 2020, The machines are whispering: We tested AI Dungeon 2 and cannot stop laughing; [Anonymous], 2023, Elon Musk sits down exclusively with Tucker Carlson to discuss dangers of AI | Fox News Video; [Anonymous], 2023, Inworld AI; [Anonymous], 2023, US Lawyer Caught Using ChatGPT To Present Case With Fake Examples; [Anonymous], 2023, WASH. POST; [Anonymous], 2019, Who's afraid of OpenAI's big, bad text generator?; [Anonymous], 2019, Better Language Models and Their Implications; [Anonymous], 2023, Chatbots, deepfakes, and voice clones: AI deception for sale; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bird Christian, 2022, ACM Queue, P35, DOI 10.1145/3582083; Chen B. X., 2023, The New York Times; dexerto, ChatGPT owner OpenAI nears 1 billion monthly users as world's fastest-growing website; engadget, NVIDIA's generative AI lets gamers converse with NPCs; forbes, I Interviewed ChatGPT About AI Ethics-And It Lied To Me; Hendrikx M, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422957; Henrickson L., 2021, Reading computer-generated texts; Hocutt Daniel, 2021, SIGDOC '21: The 39th ACM International Conference on Design of Communication, P142, DOI 10.1145/3472714.3473634; Hutter Liz, 2021, SIGDOC '21: The 39th ACM International Conference on Design of Communication, P151, DOI 10.1145/3472714.3473635; inworld, Inworld's commitment to safety; jailbreakchat, about us; Klug Katharina, 2019, Media Trust in a DigitalWorld: Communication at Crossroads, P159; Murray J., 1997, Hamlet on the Holodeck: The Future of Narrative in Cyberspace; Noble S.U., 2018, ALGORITHMS OPPRESSIO, DOI DOI 10.18574/9781479833641; nvidianews.nvidia, NVIDIA ACE for Games Sparks Life Into Virtual Characters With Generative AI; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Tang Yingying, 2020, P 38 ACM INT C DESIG, P1; techcrunch, Inworld shows off impressive AI-powered character generation and interaction; Touvron H., 2023, arXiv; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vaswani A, 2017, ADV NEUR IN, V30; Walton Nick, Twitter; Wardrip-Fruin Noah., 2006, Expressive Processing: On Process-Intensive Literature and Digital Media"; Winter R., 2019, Porn Studies, DOI [10.1080/23268743.2019.1642794, DOI 10.1080/23268743.2019.1642794]	43	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0336-2				2023							82	88		10.1145/3615335.3623015	http://dx.doi.org/10.1145/3615335.3623015			7	Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Communication; Computer Science	BW2TF					2024-07-03	WOS:001124885600012
J	[Anonymous]				[Anonymous]			Introducing AI-supported Research Highlights	NATURE REVIEWS MICROBIOLOGY			English	Editorial Material								With the debut of our AI-supported Research Highlights, we combine advances in large language models with the trust and expertise of human editors.										Goodswen SJ, 2021, FEMS MICROBIOL REV, V45, DOI 10.1093/femsre/fuab015; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8	2	0	0	2	2	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1740-1526	1740-1534		NAT REV MICROBIOL	Nat. Rev. Microbiol.	NOV	2023	21	11					701	701		10.1038/s41579-023-00978-z	http://dx.doi.org/10.1038/s41579-023-00978-z			1	Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Microbiology	U8IK6	37828087	Bronze			2024-07-03	WOS:001087181300001
J	Elyoseph, Z; Refoua, E; Asraf, K; Lvovsky, M; Shimoni, Y; Hadar-Shoval, D				Elyoseph, Zohar; Refoua, Elad; Asraf, Kfir; Lvovsky, Maya; Shimoni, Yoav; Hadar-Shoval, Dorit			Capacity of Generative AI to Interpret Human Emotions From Visual and Textual Data: Pilot Evaluation Study	JMIR MENTAL HEALTH			English	Article						Reading the Mind in the Eyes Test; RMET; emotional awareness; emotional comprehension; emotional cue; emotional cues; ChatGPT; large language model; LLM; large language models; LLMs; empathy; mentalizing; mentalization; machine learning; artificial intelligence; AI; algorithm; algorithms; predictive model; predictive models; predictive analytics; predictive system; practical model; practical models; early warning; early detection; mental health; mental disease; mental illness; mental illnesses; mental diseases	AWARENESS	Background: Mentalization, which is integral to human cognitive processes, pertains to the interpretation of one's own and others' mental states, including emotions, beliefs, and intentions. With the advent of artificial intelligence (AI) and the prominence of large language models in mental health applications, questions persist about their aptitude in emotional comprehension. The prior iteration of the large language model from OpenAI, ChatGPT-3.5, demonstrated an advanced capacity to interpret emotions from textual data, surpassing human benchmarks. Given the introduction of ChatGPT-4, with its enhanced visual processing capabilities, and considering Google Bard's existing visual functionalities, a rigorous assessment of their proficiency in visual mentalizing is warranted. Objective: The aim of the research was to critically evaluate the capabilities of ChatGPT-4 and Google Bard with regard to their competence in discerning visual mentalizing indicators as contrasted with their textual-based mentalizing abilities. Methods: The Reading the Mind in the Eyes Test developed by Baron-Cohen and colleagues was used to assess the models' proficiency in interpreting visual emotional indicators. Simultaneously, the Levels of Emotional Awareness Scale was used to evaluate the large language models' aptitude in textual mentalizing. Collating data from both tests provided a holistic view of the mentalizing capabilities of ChatGPT-4 and Bard. Results: ChatGPT-4, displaying a pronounced ability in emotion recognition, secured scores of 26 and 27 in 2 distinct evaluations, significantly deviating from a random response paradigm (P<.001). These scores align with established benchmarks from the broader human demographic. Notably, ChatGPT-4 exhibited consistent responses, with no discernible biases pertaining to the sex of the model or the nature of the emotion. In contrast, Google Bard's performance aligned with random response patterns, securing scores of 10 and 12 and rendering further detailed analysis redundant. In the domain of textual analysis, both ChatGPT and Bard surpassed established benchmarks from the general population, with their performances being remarkably congruent. Conclusions: ChatGPT-4 proved its efficacy in the domain of visual mentalizing, aligning closely with human performance standards. Although both models displayed commendable acumen in textual emotion interpretation, Bard's capabilities in visual emotion interpretation necessitate further scrutiny and potential refinement. This study stresses the criticality of ethical AI development for emotional recognition, highlighting the need for inclusive data, collaboration with patients and mental health experts, and stringent governmental oversight to ensure transparency and protect patient privacy.	[Elyoseph, Zohar] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Educ Psychol, Emek Yezreel, Israel; [Elyoseph, Zohar] Imperial Coll London, London, England; [Refoua, Elad] Bar Ilan Univ, Dept Psychol, Ramat Gan, Israel; [Asraf, Kfir; Lvovsky, Maya; Hadar-Shoval, Dorit] Max Stern Yezreel Valley Coll, Dept Psychol, Emek Yezreel, Israel; [Shimoni, Yoav] Boston Childrens Hosp, Boston, MA USA; [Elyoseph, Zohar] Imperial Coll London, Fulham Palace Rd, London W6 8RF, England	Imperial College London; Bar Ilan University; Harvard University; Boston Children's Hospital; Imperial College London	Elyoseph, Z (corresponding author), Imperial Coll London, Fulham Palace Rd, London W6 8RF, England.	zohar.j.a@gmail.com		Elyoseph, Zohar/0000-0002-5717-4074; Refoua, Elad/0000-0003-1471-3573; Lvovsky, Maya/0009-0009-1219-1717; Shimoni, Yoav/0009-0007-2834-156X				Aival-Naveh E, 2019, CLIN PSYCHOL-SCI PR, V26, DOI 10.1111/cpsp.12300; Asman O, 2023, AM J BIOETHICS, V23, P62, DOI 10.1080/15265161.2023.2191046; Bard Google, About Us; Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715; Baslet G, 2009, J NERV MENT DIS, V197, P655, DOI 10.1097/NMD.0b013e3181b3b20f; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; ChatGPT. OpenAI, About us; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chen ZS, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100602; Doraiswamy PM, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101753; Elyoseph Z, 2024, AM J BIOETHICS, V24, P57, DOI 10.1080/15265161.2023.2278546; Elyoseph Z, 2024, FAM MED COMMUNITY HE, V12, DOI 10.1136/fmch-2023-002583; Elyoseph Z, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1213141; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Fonagy P., 2016, Development and Psychopathology, V3rd; Freeman C, 2016, BRIT J PSYCHOTHER, V32, P189, DOI 10.1111/bjp.12220; Haber Y, JMIR, DOI [10.2196/preprints.54781, DOI 10.2196/PREPRINTS.54781]; Hadar-Shoval D, 2024, PREPRINT, DOI [10.2196/preprints.55988, DOI 10.2196/PREPRINTS.55988]; Hadar-Shoval D, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1234397; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; LANE RD, 1990, J PERS ASSESS, V55, P124, DOI 10.1207/s15327752jpa5501&2_12; Leong SC, 2023, COMPUT SCI REV, V48, DOI 10.1016/j.cosrev.2023.100545; Levkovich I, 2023, FAM MED COMMUNITY HE, V11, DOI 10.1136/fmch-2023-002391; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; Luyten P, 2020, ANNU REV CLIN PSYCHO, V16, P297, DOI 10.1146/annurev-clinpsy-071919-015355; Luyten P, 2018, CLIN PSYCHOL REV, V64, P87, DOI 10.1016/j.cpr.2017.09.008; Maroti D, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00453; Nandrino JL, 2013, INT J PSYCHOL, V48, P1072, DOI 10.1080/00207594.2012.753149; Noroozi Fatemeh, 2021, IEEE Transactions on Affective Computing, V12, P505, DOI 10.1109/TAFFC.2018.2874986; Pham KT, 2022, PSYCHIAT QUART, V93, P249, DOI 10.1007/s11126-022-09973-8; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127; Schwarzer NH, 2021, INT FORUM PSYCHOANAL, V30, P34, DOI 10.1080/0803706X.2021.1873418; Sharp C, 2013, Social Cognition and Developmental Psychopathology; Tal A, 2023, AM J BIOETHICS, V23, P74, DOI 10.1080/15265161.2023.2250297; Vaswani A, 2017, ADV NEUR IN, V30	38	4	4	36	36	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2368-7959			JMIR MENT HEALTH	JMIR Ment. Health		2024	11								e54369	10.2196/54369	http://dx.doi.org/10.2196/54369			9	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	JY9P8	38319707	gold, Green Published			2024-07-03	WOS:001176840500001
J	Bridges, JM				Bridges, Joe M.			Computerized diagnostic decision support systems - a comparative performance study of Isabel Pro vs. ChatGPT4	DIAGNOSIS			English	Article; Early Access						artificial intelligence; diagnosis; computer assisted; Isabel Pro; ChatGPT4		Objectives: Validate the diagnostic accuracy of the Artificial Intelligence Large Language Model ChatGPT4 by comparing diagnosis lists produced by ChatGPT4 to Isabel Pro. Methods: This study used 201 cases, comparing ChatGPT4 to Isabel Pro. Systems inputs were identical. Mean Reciprocal Rank (MRR) compares the correct diagnosis's rank between systems. Isabel Pro ranks by the frequency with which the symptoms appear in the reference dataset. The mechanism ChatGPT4 uses to rank the diagnoses is unknown. A Wilcoxon Signed Rank Sum test failed to reject the null hypothesis. Results: Both systems produced comprehensive differential diagnosis lists. Isabel Pro's list appears immediately upon submission, while ChatGPT4 takes several minutes. Isabel Pro produced 175 (87.1 %) correct diagnoses and ChatGPT4 165 (82.1 %). The MRR for ChatGPT4 was 0.428 (rank 2.31), and Isabel Pro was 0.389 (rank 2.57), an average rank of three for each. ChatGPT4 outperformed on Recall at Rank 1, 5, and 10, with Isabel Pro outperforming at 20, 30, and 40. The Wilcoxon Signed Rank Sum Test confirmed that the sample size was inadequate to conclude that the systems are equivalent. ChatGPT4 fabricated citations and DOIs, producing 145 correct references (87.9 %) but only 52 correct DOIs (31.5 %). Conclusions: This study validates the promise of Clinical Diagnostic Decision Support Systems, including the Large Language Model form of artificial intelligence (AI). Until the issue of hallucination of references and, perhaps diagnoses, is resolved in favor of absolute accuracy, clinicians will make cautious use of Large Language Model systems in diagnosis, if at all.	[Bridges, Joe M.] Univ Texas Hlth Sci Ctr Houston, D Bradley McWilliams Sch Biomed Informat, 7000 Fannin St UCT600, Houston, TX 77030 USA	University of Texas System; University of Texas Health Science Center Houston	Bridges, JM (corresponding author), Univ Texas Hlth Sci Ctr Houston, D Bradley McWilliams Sch Biomed Informat, 7000 Fannin St UCT600, Houston, TX 77030 USA.	joe.bridges@uth.tmc.edu						Bond WF, 2012, J GEN INTERN MED, V27, P213, DOI 10.1007/s11606-011-1804-8; Bridges JM, 2022, Evaluation, validation, and implementation of acomputerized diagnostic decision support system in primary care; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Friedman CP, 1999, JAMA-J AM MED ASSOC, V282, P1851, DOI 10.1001/jama.282.19.1851; Fritz P, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01988-2; Graber ML, 2022, BMJ QUAL SAF, V31, P415, DOI 10.1136/bmjqs-2021-014033; Grober ML, 2008, J GEN INTERN MED, V23, P37, DOI 10.1007/s11606-007-0271-8; Hailu R, 2023, STAT, P5; Hirosawa T, 2023, JMIR MED INF, V11, DOI 10.2196/48808; Horiuchi D, 2024, NEURORADIOLOGY, V66, P73, DOI 10.1007/s00234-023-03252-4; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu XN, 2023, BLOOD, V142, DOI 10.1182/blood-2023-181518; Moller S, 2023, NEJM AI, V1, DOI [10.1056/aip2300031.8, DOI 10.1056/AIP2300031.8]; Riches N, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0148991; Sibbald M, 2022, BMJ QUAL SAF, V31, P426, DOI 10.1136/bmjqs-2021-013493; Wachter RM, 2024, JAMA-J AM MED ASSOC, V331, P65, DOI 10.1001/jama.2023.25054; Walters WH, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41032-5	18	0	0	4	4	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-8011	2194-802X		DIAGNOSIS	Diagnosis	2024 MAY 7	2024										10.1515/dx-2024-0033	http://dx.doi.org/10.1515/dx-2024-0033		MAY 2024	9	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	PM3M5	38709491	hybrid			2024-07-03	WOS:001214456800001
C	Celik, B; Ahmetoglu, A; Ugur, E; Oztop, E			IEEE	Celik, Batuhan; Ahmetoglu, Alper; Ugur, Emre; Oztop, Erhan			Developmental Scaffolding with Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON DEVELOPMENT AND LEARNING, ICDL			English	Proceedings Paper	IEEE International Conference on Development and Learning (ICDL)	NOV 09-11, 2023	Macau, PEOPLES R CHINA	IEEE				Exploration and self-observation are key mechanisms of infant sensorimotor development. These processes are further guided by parental scaffolding to accelerate skill and knowledge acquisition. In developmental robotics, this approach has been adopted often by having a human acting as the source of scaffolding. In this study, we investigate whether Large Language Models (LLMs) can act as a scaffolding agent for a robotic system that aims to learn to predict the effects of its actions. To this end, an object manipulation setup is considered where one object can be picked and placed on top of or in the vicinity of another object. The adopted LLM is asked to guide the action selection process through algorithmically generated state descriptions and action selection alternatives in natural language. The simulation experiments that include cubes in this setup show that LLM-guided (GPT3.5-guided) learning yields significantly faster discovery of novel structures compared to random exploration. However, we observed that GPT3.5 fails to effectively guide the robot in generating structures with different affordances such as cubes and spheres. Overall, we conclude that even without fine-tuning, LLMs may serve as a moderate scaffolding agent for improving robot learning, however, they still lack affordance understanding which limits the applicability of the current LLMs in robotic scaffolding tasks.	[Celik, Batuhan; Ahmetoglu, Alper; Ugur, Emre] Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye; [Oztop, Erhan] Ozyegin Univ, Dept Comp Sci, Istanbul, Turkiye; [Oztop, Erhan] Osaka Univ, Inst Open & Transdisciplinary Res Initiat, Symbiot Intelligent Syst Res Ctr, Suita, Osaka, Japan	Bogazici University; Ozyegin University; Osaka University	Celik, B (corresponding author), Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.		Ahmetoglu, Alper/HJP-9561-2023	Ahmetoglu, Alper/0000-0003-1330-6781	TUBITAK ARDEB 1001 program [120E274]; Japan Society for the Promotion of Science [22H03670]; International Joint Research Promotion Program, Osaka University under the project "Developmentally and biologically realistic modeling of perspective invariant action understanding" by the New Energy and Industrial Technology Development Organization (NED [JPNP16007]; University of Tokyo - IRCN Guest Researcher Program	TUBITAK ARDEB 1001 program(Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)); Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science); International Joint Research Promotion Program, Osaka University under the project "Developmentally and biologically realistic modeling of perspective invariant action understanding" by the New Energy and Industrial Technology Development Organization (NED; University of Tokyo - IRCN Guest Researcher Program	This research was supported by TUBITAK ARDEB 1001 program (project number: 120E274), Japan Society for the Promotion of Science, Grant-in-Aid for Scientific Research -the project with number 22H03670, the International Joint Research Promotion Program, Osaka University under the project "Developmentally and biologically realistic modeling of perspective invariant action understanding", and the project JPNP16007 commissioned by the New Energy and Industrial Technology Development Organization (NEDO). Additional support is provided by the University of Tokyo - IRCN Guest Researcher Program.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmetoglu A, 2022, Arxiv, DOI arXiv:2208.01021; Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; CAKMAK M, 2007, P 7 INT C EP ROB EPI; Chalvatzaki G, 2023, FRONT ROBOT AI, V10, DOI 10.3389/frobt.2023.1221739; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cui Y., 2022, LEARNING DYNAMICS CO, P893; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Huang WL, 2022, PR MACH LEARN RES; Jamone L, 2018, IEEE T COGN DEV SYST, V10, P4, DOI 10.1109/TCDS.2016.2594134; Jin CH, 2023, Arxiv, DOI arXiv:2305.18898; Kira Z., 2022, Awesome-llm-robotics; Kirk JR, 2023, Arxiv, DOI arXiv:2306.06770; Ladosz P, 2022, INFORM FUSION, V85, P1, DOI 10.1016/j.inffus.2022.03.003; Lykov A, 2023, Arxiv, DOI arXiv:2305.19352; Mees O, 2023, IEEE INT CONF ROBOT, P11576, DOI 10.1109/ICRA48891.2023.10160396; Mnih V, 2013, Arxiv, DOI [arXiv:1312.5602, DOI 10.48550/ARXIV.1312.5602]; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Radford A, 2021, PR MACH LEARN RES, V139; Ren A. Z., 2023, Conference on Robot Learning, P1531; Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3; Shridhar M., 2022, C ROBOT LEARNING, P894; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Tam A., 2022, Advances in Neural Information Processing Systems, V35, p25 377; Ten A, 2022, DRIVE FOR KNOWLEDGE, P53; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Ugur Emre, 2011, 2011 11th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2011), P480, DOI 10.1109/Humanoids.2011.6100890; Ugur E, 2015, ROBOTICA, V33, P1163, DOI 10.1017/S0263574714002148; Vaswani A, 2017, ADV NEUR IN, V30; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Vlachos A., 2013, EUR WORKSH REINF LEA, P143; Wang C, 2013, IEEE INT C INT ROBOT, P2288, DOI 10.1109/IROS.2013.6696676; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wei J., 2022, Advances in Neural Information Processing Systems, V35, p24 824; Weng JY, 2022, Arxiv, DOI arXiv:2211.16350; Xiao T., 2022, arXiv; Zhang CN, 2023, Arxiv, DOI arXiv:2303.11717	39	1	1	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-7075-9				2023							396	402		10.1109/ICDL55364.2023.10364374	http://dx.doi.org/10.1109/ICDL55364.2023.10364374			7	Behavioral Sciences; Computer Science, Artificial Intelligence; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Behavioral Sciences; Computer Science; Robotics	BW6EX		Green Submitted			2024-07-03	WOS:001172928700062
J	Sayeed, HM; Smallwood, W; Baird, SG; Sparks, TD				Sayeed, Hasan M.; Smallwood, Wade; Baird, Sterling G.; Sparks, Taylor D.			NLP meets materials science: Quantifying the presentation of materials data in literature	MATTER			English	Editorial Material								Large language models (LLMs) revolutionized how we engage with information. In materials science, we aim to leverage natural language processing to transform progress and discovery. Analyzing diverse materials science papers, we annotate data types and sources, laying the groundwork for targeted information extraction and LLM development.	[Sayeed, Hasan M.; Smallwood, Wade; Baird, Sterling G.; Sparks, Taylor D.] Univ Utah, Dept Mat Sci & Engn, 122 Cent Campus Dr, Salt Lake City, UT 84112 USA; [Baird, Sterling G.] Univ Toronto, Accelerat Consortium, 80 St George St, Toronto, ON M5S 3H6, Canada	Utah System of Higher Education; University of Utah; University of Toronto	Sparks, TD (corresponding author), Univ Utah, Dept Mat Sci & Engn, 122 Cent Campus Dr, Salt Lake City, UT 84112 USA.	sparks@eng.utah.edu			Na- tional Science Foundation (NSF) [DMR 2334411]; NSF	Na- tional Science Foundation (NSF)(National Science Foundation (NSF)); NSF(National Science Foundation (NSF))	ACKNOWLEDGMENTS This research was supported by the Na- tional Science Foundation (NSF) under grant number DMR 2334411. We extend our appreciation to the NSF for their financial support, which made this informal study possible.	Baird S.G., 2022, PREPRINT, DOI [10.1016/B978-0-12-823144-9.00079-0, DOI 10.1016/B978-0-12-823144-9.00079-0]; Hong Z, 2021, JOM-US, V73, P3383, DOI 10.1007/s11837-021-04902-9; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106	3	1	1	7	7	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	2590-2393	2590-2385		MATTER-US	Matter	MAR 6	2024	7	3					723	727		10.1016/j.matt.2023.12.032	http://dx.doi.org/10.1016/j.matt.2023.12.032		MAR 2024	5	Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science	NR6W4					2024-07-03	WOS:001202229300001
J	Luitse, D; Denkena, W				Luitse, Dieuwertje; Denkena, Wiebke			The great transformer: Examining the role of large language models in the political economy of AI	BIG DATA & SOCIETY			English	Article						Artificial intelligence; algorithmic techniques; Transformer; large language models; monopolization; platforms	PLATFORMIZATION	In recent years, AI research has become more and more computationally demanding. In natural language processing (NLP), this tendency is reflected in the emergence of large language models (LLMs) like GPT-3. These powerful neural network-based models can be used for a range of NLP tasks and their language generation capacities have become so sophisticated that it can be very difficult to distinguish their outputs from human language. LLMs have raised concerns over their demonstrable biases, heavy environmental footprints, and future social ramifications. In December 2020, critical research on LLMs led Google to fire Timnit Gebru, co-lead of the company's AI Ethics team, which sparked a major public controversy around LLMs and the growing corporate influence over AI research. This article explores the role LLMs play in the political economy of AI as infrastructural components for AI research and development. Retracing the technical developments that have led to the emergence of LLMs, we point out how they are intertwined with the business model of big tech companies and further shift power relations in their favour. This becomes visible through the Transformer, which is the underlying architecture of most LLMs today and started the race for ever bigger models when it was introduced by Google in 2017. Using the example of GPT-3, we shed light on recent corporate efforts to commodify LLMs through paid API access and exclusive licensing, raising questions around monopolization and dependency in a field that is increasingly divided by access to large-scale computing power.	[Luitse, Dieuwertje; Denkena, Wiebke] Univ Amsterdam, Dept Media Studies, Turfdraagsterpad 9, NL-1012 XT Amsterdam, Netherlands	University of Amsterdam	Luitse, D (corresponding author), Univ Amsterdam, Dept Media Studies, Turfdraagsterpad 9, NL-1012 XT Amsterdam, Netherlands.	dieuwertje.luitse@student.uva.nl	Luitse, Dieuwertje/JFS-1896-2023					Abdalla M, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P287, DOI 10.1145/3461702.3462563; Abid A., 2021, ARXIV210105783CS; Ahmed N., 2020, ARXIV201015581; Amoore Louise, 2020, Cloud ethics: algorithms and the attributes of ourselves and others; [Anonymous], 2014, Generating sequences with recurrent neural networks; [Anonymous], 2008, SOFTWARE STUDIES LEX; [Anonymous], 2017, PLATFORM CAPITALISM; [Anonymous], 2015, C P EMNLP2015 C EMP, DOI DOI 10.48550/ARXIV.1508.04025; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Brockman G., 2019, OPENAI LP; Brown Tom B, 2020, Neural Information Processing Systems; Cardon Dominique., 2018, R SEAUX, P173; Clark J., 2019, Better language models and their implications; Dai AM, 2015, ADV NEUR IN, V28; Devlin J., 2018, BERT PRE TRAINING DE; Dyer-Witheford N., 2019, INHUMAN POWER ARTIFI, DOI DOI 10.2307/J.CTVJ4SXC6; Etherington D., 2019, TECHCRUNCH; Feng C., 2021, S CHINA MORNING POST; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068; Hao K., 2020, OPENAI IS GIVING MIC; Hao K., 2020, STARTED CRYING INSID; Hemsoth N., 2021, THE NEXT PLATFORM; Hernandez A., 2020, ARXIV191208168CSMATH; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hwang T., 2018, SSRN ELECT J, P1; Kaiser C., 2020, DATA SCI; Kaplan Jared, 2020, Scaling laws for neural language models; Khan B., 2020, ALGPT2 2; Khan LN, 2018, J EUR COMPET LAW PRA, V9, P131, DOI 10.1093/jeclap/lpy020; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Langston J., 2020, AI BLOG; Langston J., 2021, AI BLOG; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee Kai -Fu, 2018, AI SUPERPOWERS CHINA; Macaulay T., 2020, OPENAI REVEALS PRICI; Marino MC., 2020, Critical code studies; Mayer HM., 2021, FORBES; McCulloch W. S., 1943, B MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259; McGuffie K., 2020, ARXIV200906807CS; Microsoft, 2019, OPENAI FORMS EXCL CO; Minsky M., 1969, PERCEPTRONS INTRO CO; Mucha T., 2020, ETLA WORKING PAPERS; Nayak P., 2019, The keyword, P295; Nieborg DB, 2019, MEDIA CULT SOC, V41, P196, DOI 10.1177/0163443718818384; Nieborg DB, 2018, NEW MEDIA SOC, V20, P4275, DOI 10.1177/1461444818769694; Parikh Ankur, 2016, P 2016 C EMP METH NA, P2249, DOI DOI 10.18653/V1/D16-1244; Pascanu R., 2013, INT C MACHINE LEARNI, V28, P1310, DOI DOI 10.5555/3042817.3043083; Pilipiszyn A., 2021, GPT 3 POWERS NEXT GE; Plantin JC, 2018, NEW MEDIA SOC, V20, P293, DOI 10.1177/1461444816661553; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raina R., 2009, ICML, ppp 873; Rieder B., 2020, ENGINES ORDER MECHAN, DOI DOI 10.5117/9789462986190; Rieder B, 2017, INFORM COMMUN SOC, V20, P100, DOI 10.1080/1369118X.2016.1181195; Rieder B, 2014, NEW MEDIA SOC, V16, P195, DOI 10.1177/1461444813481195; Riedl M., 2020, GRADIENT 0925; Rikap C, 2022, INNOV DEV, V12, P389, DOI 10.1080/2157930X.2020.1855825; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sanh Victor, 2020, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Shree P., 2020, JOURNEY OPEN AI GPT; Srnicek N., 2018, EC MANY, P153; Srnicek N., 2019, POLITICAL EC ARTIFIC; Srnicek N., 2020, DATA COMPUTE LABOUR; Staab P., 2019, Digitaler Kapitalismus: Markt und Herrschaft in der Okonomie der Unknappheit; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Sutskever I, 2014, ADV NEUR IN, V27; Vaswani A, 2017, ADV NEUR IN, V30; Whittaker M., 2021, DISTINGUISHED SPEAKE; Wiggers K., 2021, AI WEEKLY MEET PEOPL; Wittel A, 2017, DIGITISATION: THEORIES AND CONCEPTS FOR EMPIRICAL CULTURAL RESEARCH, P251; Wolf T., 2020, ARXIV191003771CS; Wooldridge M., 2020, The Road to Conscious Machines: The Story of AI; Zhao Z., 2019, P 2019 EMNLP 9 IJCNL, P241	77	35	36	18	64	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	2053-9517			BIG DATA SOC	Big Data Soc.	JUL	2021	8	2							20539517211047734	10.1177/20539517211047734	http://dx.doi.org/10.1177/20539517211047734			14	Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	WB7VQ		gold			2024-07-03	WOS:000703777500001
J	Baldassarre, A; Padovan, M				Baldassarre, Antonio; Padovan, Martina			Regulatory and Ethical Considerations on Artificial Intelligence for Occupational Medicine	MEDICINA DEL LAVORO			English	Article						Generative Artificial Intelligence; Large Language Models; Code of Ethics		Generative artificial intelligence and Large Language Models reshape labor dynamics and occupational health practices. As AI continues to evolve, there's a critical need to customize ethical considerations for its specific impacts on occupational health. Recognizing potential ethical challenges and dilemmas, stakeholders and physicians are urged to proactively adjust the practice of Occupational Medicine in response to shifting ethical paradigms. By advocating ensure responsible medical AI deployment, safeguarding the well-being of workers amidst the transformative effects of automation in healthcare.	[Baldassarre, Antonio] Univ Florence, Dept Expt & Clin Med, Florence, Italy; [Padovan, Martina] Tuscany North West Hlth Local Unit, Prevent Med, Lucca, Italy	University of Florence	Baldassarre, A (corresponding author), Univ Florence, Dept Expt & Clin Med, Florence, Italy.	antonio.baldassarre@unifi.it	Baldassarre, Antonio/GPS-7594-2022	Baldassarre, Antonio/0000-0002-6124-3570				Adel A, 2022, J CLOUD COMPUT-ADV S, V11, DOI 10.1186/s13677-022-00314-5; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2023, License: CC BY-NC-SA 3.0 IGO; [Anonymous], Council Directive 89/391/EEC of 12 June 1989 on the introduction of measures to encourage improvements in the safety and health of workers at work; [Anonymous], 2021, ETH GOV ART INT HLTH; [Anonymous], 2016, Med Lav, V107, P485; Armeni P, 2023, IntechOpen, DOI [10.5772/intechopen.112490, DOI 10.5772/INTECHOPEN.112490]; Baldassarre A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17144975; Berg J, 2021, World employment and social outlook: Trends 2021; Bhattad PB, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8041; Blobel B, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1244100; Boulos MNK, 2021, J PERS MED, V11, DOI 10.3390/jpm11080745; Chakraborty C, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1237704; Collatuzzo G, 2022, MED LAV, V113, DOI 10.23749/mdl.v113i1.12622; Collins L., 2017, Rewriting the rules for digital age, P97; Ethics and governance of artificial intelligence for health, 2024, Guidance on large multi-modal models; EU-OSHA (European Agency for Safety and Health at Work), 2018, European Risk Observatory Report; EU-OSHA (European Agency for Safety and Health at Work), 2024, Discussion paper; EU-OSHA (European Agency for Safety and Health at Work), 2019, OSH and the Future of Work: benefits and risks of artificial intelligence tools; Friedland J, 2023, BUS HORIZONS, V66, P181, DOI 10.1016/j.bushor.2022.05.003; Gmyrek P, 2023, ILO Working Paper 96, DOI [10.54394/FHEM8239, DOI 10.54394/FHEM8239]; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Horizon, 2020, Mental Health promotion of cobot Workers in Industry 4.0, DOI [10.3030/847926, DOI 10.3030/847926]; INAIL, 2016, Il codice internazionale di etica per gli operatori di medicina del lavoro; International Commission on Occupational Health (ICOH), 2014, International code of ethics for occupational health professionals, VThird; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Lee P, 2023, NEW ENGL J MED, V388, P2400, DOI 10.1056/NEJMc2305286; Leso V, 2018, MED LAV, V109, P327, DOI 10.23749/mdl.v110i5.7282; McCarthy J, 2006, AI MAG, V27, P12; Menz BD, 2024, JAMA INTERN MED, V184, P92, DOI 10.1001/jamainternmed.2023.5947; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mokhtari F, 2023, GLOB CHALL, V7, DOI 10.1002/gch2.202300019; Murashov V, 2016, J OCCUP ENVIRON HYG, V13, DOI 10.1080/15459624.2015.1116700; Mutti A, 2023, MED LAV, V114, DOI 10.23749/mdl.v114i2.14451; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Padovan M, 2024, BIOENGINEERING-BASEL, V11, DOI 10.3390/bioengineering11010057; Paliga Mateusz, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20065111; Piwek L, 2016, PLOS MED, V13, DOI 10.1371/journal.pmed.1001953; Prince SA, 2019, INT J BEHAV NUTR PHY, V16, DOI 10.1186/s12966-019-0790-9; Shoja MM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40883; Sridi C, 2023, ANN OCCUP ENVIRON ME, V35, DOI 10.35371/aoem.2023.35.e42; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Topol Review, 2019, Final Report February 2019-A Call For Evidence. A Middleton invited to contribute; Wu DY, 2024, J ORGAN BEHAV, V45, P183, DOI 10.1002/job.2775; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	45	0	0	1	1	MATTIOLI 1885	FIDENZA	VIA DELLA LODESANA 649-SX, FIDENZA, 43046 PR, ITALY	0025-7818			MED LAV	Med. Lav.		2024	115	2							e2024013	10.23749/mdl.v115i2.15881	http://dx.doi.org/10.23749/mdl.v115i2.15881			8	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED)	Public, Environmental & Occupational Health	QU2X2					2024-07-03	WOS:001223327200002
C	Ma, KJ; Zang, XH; Feng, ZR; Fang, H; Ban, C; Wei, YH; He, ZJ; Li, YX; Sun, H			IEEE	Ma, Kaijing; Zang, Xianghao; Feng, Zerun; Fang, Han; Ban, Chao; Wei, Yuhan; He, Zhongjiang; Li, Yongxiang; Sun, Hao			LLaViLo: Boosting Video Moment Retrieval via Adapter-Based Multimodal Modeling	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS, ICCVW	IEEE International Conference on Computer Vision Workshops		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF				Recent studies have explored the potential of large language models (LLMs) for understanding the semantic information in images. However, the use of LLMs to understand videos, which contain continuous contextual information, remains limited. In this paper, we propose LLaViLo (LLaMa-Video-Localizer), a video moment retrieval pipeline powered by a large language model. LLaViLo has two key features: 1) In contrast to fine-tuning the entire LLM, we introduce and optimize only 1.7% of additional parameters in adapter modules, freezing the pre-trained LLM to enable efficient alignment of video and text. 2) A multi-objective optimization framework concurrently optimizes two objectives: a set prediction objective and a captioning objective. The joint training of these two objectives allows the proposed framework to produce highquality time coordinates. Compared with other state-of-the-art methods, the proposed LLaViLo achieves significant performance improvement on QVHighlights and CharadesSTA datasets.	[Ma, Kaijing; Zang, Xianghao; Feng, Zerun; Fang, Han; Ban, Chao; Wei, Yuhan; He, Zhongjiang; Li, Yongxiang; Sun, Hao] Telecom Corp Ltd Data & AI Technol Co, Beijing, Peoples R China; [Ma, Kaijing] Xi An Jiao Tong Univ, Xian, Peoples R China; [Wei, Yuhan] Rice Univ, Houston, TX USA	Xi'an Jiaotong University; Rice University	Fang, H; Sun, H (corresponding author), Telecom Corp Ltd Data & AI Technol Co, Beijing, Peoples R China.		Ban, Chao/AAI-9187-2020					[Anonymous], 2021, ICML; Awadalla A., 2023, OPENFLAMINGO; Carion N, 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Escorcia Victor, 2019, ARXIV190712763; Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630; Gao JY, 2017, IEEE I CONF COMP VIS, P5277, DOI 10.1109/ICCV.2017.563; Gao Peng, 2023, ARXIV230415010; Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81; Hendricks LA, 2017, IEEE I CONF COMP VIS, P5804, DOI 10.1109/ICCV.2017.618; Ilharco G., 2021, Openclip; Jie Lei, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P447, DOI 10.1007/978-3-030-58589-1_27; Kim W, 2021, PR MACH LEARN RES, V139; Korbak T, 2022, PR MACH LEARN RES; Lei J., 2021, Advances in Neural Information Processing Systems, V34, P11846; Li Junnan, 2022, ICML; Li Liunian Harold, 2019, arXiv; Liu Y., 2019, CoRR abs/1907.11692; Liu Yahao, 2022, CVPR; Ma Yue, 2022, ARXIV221203490; Moon W, 2023, PROC CVPR IEEE, P23023, DOI 10.1109/CVPR52729.2023.02205; RADFORD A, 2021, LEARNING TRANSFERABL, V139; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Schuhmann Christoph, 2022, 36 C NEUR INF PROC S; Su W., 2020, ICLR, P1; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tran Du, 2015, ICCV; Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324; Wallingford M, 2022, PROC CVPR IEEE, P7551, DOI 10.1109/CVPR52688.2022.00741; Yu Shoubin, 2023, ARXIV230506988; Zhang H., 2020, P 58 ANN M ASS COMP, P6543; Zhang Renrui, 2023, arXiv:2303.16199; Zhang Songyang, 2020, AAAL	33	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2473-9936		979-8-3503-0744-3	IEEE INT CONF COMP V			2023							2790	2795		10.1109/ICCVW60793.2023.00297	http://dx.doi.org/10.1109/ICCVW60793.2023.00297			6	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW4XE					2024-07-03	WOS:001156680302091
C	Basar, E; Hendrickx, I; Krahmer, E; de Bruijn, GJ; Bosse, T		Rocha, AP; Steels, L; VandenHerik, J		Basar, Erkan; Hendrickx, Iris; Krahmer, Emiel; de Bruijn, Gert-Jan; Bosse, Tibor			Hints of Independence in a Pre-scripted World: On Controlled Usage of Open-domain Language Models for Chatbots in Highly Sensitive Domains	ICAART: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 1	ICAART		English	Proceedings Paper	14th International Conference on Agents and Artificial Intelligence (ICAART)	FEB 03-05, 2022	ELECTR NETWORK			Hybrid Conversational Agents; Task-oriented Dialogue Systems; Multi-turn Response Selection; Natural Language Generation		Open-domain large language models have progressed to generating natural-sounding and coherent text. Even though the generated texts appear human-like, the main stumbling block is that their output is never fully predictable, which runs the risk of resulting in harmful content such as false statements or inflammatory language. This makes it difficult to apply these models in highly sensitive domains including personal health counselling. Hence, most of the chatbots for highly sensitive domains are developed using pre-scripted approaches. Although pre-scripted approaches are highly controlled, they suffer from repetitiveness and scalability issues. In this paper, we explore the possibility of combining the best of both worlds. We propose and describe in detail a new, flexible expert-driven hybrid architecture for harnessing the benefits of large language models in a controlled manner for highly sensitive domains and discuss the expectations and challenges.	[Basar, Erkan; Bosse, Tibor] Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands; [Hendrickx, Iris] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands; [Krahmer, Emiel] Tilburg Univ, Tilburg Sch Humanities & Digital Sci, Tilburg, Netherlands; [de Bruijn, Gert-Jan] Univ Antwerp, Dept Commun Studies, Antwerp, Belgium; [de Bruijn, Gert-Jan] Univ Amsterdam, Fac Social & Behav Sci, Amsterdam, Netherlands	Radboud University Nijmegen; Radboud University Nijmegen; Tilburg University; University of Antwerp; University of Amsterdam	Basar, E (corresponding author), Radboud Univ Nijmegen, Behav Sci Inst, Nijmegen, Netherlands.		de Bruijn, Gert-Jan/GOV-4325-2022; Bruijn, G de/GNP-2334-2022	de Bruijn, Gert-Jan/0000-0001-9759-3938; Bruijn, G de/0000-0001-9759-3938; Basar, Erkan/0000-0003-1948-3551	Dutch Research Council (NWO) [406, DI.19.054]	Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO))	This project is partly financed by the Dutch Research Council (NWO) with project number 406.DI.19.054.	Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R., 2021, OPPORTUNITIES RISK; Brixey J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P370; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chen H., 2017, SIGKDD EXPLOR NEWSL; Denecke K, 2021, IEEE T EMERG TOP COM, V9, P1170, DOI 10.1109/TETC.2020.2974478; Devlin J., 2019, P NAACL 2019 HUM LAN; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Gu JC, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2041, DOI 10.1145/3340531.3412330; Gururangan S., 2020, P 58 ACL; He L., 2022, CAN CHATBOTS S UNPUB; Krahmer E., 2021, CHATBOTS HLTH GEN; Li C., 2021, DEEP CONTEXT MODELIN; Mikolov T., 2013, P 26 INT NEURIPS; Novikova J., 2017, P EMNLP 2017; Radford A., 2018, IMPROVING LANGUAGE U; Rousseau A.-L., 2020, Nabla; Saha T., 2021, IJCNN 2021; Schlesinger A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173889; See A., 2019, P NAACL HUM LANG TEC; Song Y., 2018, P IJCAI 18; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Tao C., 2018, P IJCAI 18; van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151; Vinyals O., 2015, ARXIV150605869; Whang T, 2020, INTERSPEECH, P1585, DOI 10.21437/Interspeech.2020-2153; Xu B., 2020, SURVEY PSYCHOTHERAPY; Yang L., 2019, P CIKM 19; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]	31	2	2	5	7	SCITEPRESS	SETUBAL	AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL	2184-433X		978-989-758-547-0	ICAART			2022							401	407		10.5220/0010914300003116	http://dx.doi.org/10.5220/0010914300003116			7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BS8PG		Green Published, hybrid			2024-07-03	WOS:000774749000044
J	Kong, ZY; Adi, VSK; Segovia-Hernández, JG; Sunarso, J				Kong, Zong Yang; Adi, Vincentius Surya Kurnia; Segovia-Hernandez, Juan Gabriel; Sunarso, Jaka			Complementary role of large language models in educating undergraduate design of distillation column: Methodology development	DIGITAL CHEMICAL ENGINEERING			English	Article						ChatGPT; Chemical engineering education; Large language models; Distillation; Industry 4.0; Mass transfer	EXTRACTIVE DISTILLATION; UNIVERSITY	This paper explores the integration of large language models (LLMs), such as ChatGPT, in chemical engineering education, departing from conventional practices that may not be universally accepted. While there is ongoing debate surrounding the acceptance of LLMs, driven by concerns over computational instability and potential inconsistencies, their inevitability in shaping our communication and interaction with technology cannot be ignored. As educators, we are positioned to play a vital role in guiding students toward the responsible, effective, and synergetic use of LLMs. Focusing specifically on distillation column design in undergraduate mass-transfer courses, this study demonstrates how ChatGPT can be utilized as an auxiliary tool to create interactive learning environments and simulate real-world engineering thinking processes. It emphasizes the need for students to develop critical thinking skills and a thorough understanding of LLM principles, taking responsibility for their use and creations. While ChatGPT should not be solely relied upon, its integration with fundamental principles of chemical engineering is crucial. The effectiveness and limitations of ChatGPT are exemplified through two case studies, showcasing the importance of manual calculations and established simulation software as primary tools for guiding and validating engineering results and analyses. This paper also addresses the pedagogical implications of integrating LLMs into mass transfer courses, encompassing curriculum integration, facilitation, guidance, and ethical considerations. Recommendations are provided for incorporating LLMs effectively into the curriculum. Overall, this study contributes to the advancement of chemical engineering education by examining the benefits and limitations of LLMs as educational aids in the design process.	[Kong, Zong Yang] Sunway Univ, Sch Engn & Technol, Dept Engn, Bandar Sunway 47500, Selangor, Malaysia; [Adi, Vincentius Surya Kurnia] Natl Chung Hsing Univ, Dept Chem Engn, Taichung 40227, Taiwan; [Segovia-Hernandez, Juan Gabriel] Univ Guanajuato, Div Ciencias Nat & Exactas, Dept Ingn Quim, Campus Guanajuato,Noria Alta S-N, Guanajuato 36050, Gto, Mexico; [Sunarso, Jaka] Swinburne Univ Technol, Res Ctr Sustainable Technol, Fac Engn Comp & Sci, Jalan Simpang Tiga, Kuching 93350, Sarawak, Malaysia	Sunway University; National Chung Hsing University; Universidad de Guanajuato; Swinburne University of Technology Sarawak; Swinburne University of Technology	Kong, ZY (corresponding author), Sunway Univ, Sch Engn & Technol, Dept Engn, Bandar Sunway 47500, Selangor, Malaysia.; Adi, VSK (corresponding author), Natl Chung Hsing Univ, Dept Chem Engn, Taichung 40227, Taiwan.	savierk@sunway.edu.my; skzyang@outlook.com	Adi, Vincentius Surya Kurnia/K-7498-2012	Adi, Vincentius Surya Kurnia/0000-0002-6857-2772; Kong, Zong Yang/0000-0002-4846-2744	Sunway University Malaysia; "Innovative Center on Sustainable Negative -Carbon Resources" from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan; Ministry of Science and Technology, Taiwan [MOST 106-2221-E-005-095, MOST 107-2221-E-005-034-, 105]; Ministry of Science and Technology [10617003 G]	Sunway University Malaysia; "Innovative Center on Sustainable Negative -Carbon Resources" from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan; Ministry of Science and Technology, Taiwan(Ministry of Science and Technology, Taiwan); Ministry of Science and Technology(Spanish Government)	Z.Y. Kong gratefully acknowledged the support from Sunway University Malaysia. V.S.K. Adi acknowledges the partial support from the "Innovative Center on Sustainable Negative -Carbon Resources" from The Featured Areas Research Center Program within the framework of the Higher Education Sprout Project by the Ministry of Education (MOE) in Taiwan, the partial support from the Ministry of Science and Technology, Taiwan under contract no. MOST 106-2221-E-005-095-, MOST 107-2221-E-005-034-, the 105 Ministry of Science and Technology subsidy for attracting special outstanding talents in colleges and universities award, and the grant (10617003 G) for newly recruited academics from National Chung-Hsing University.	[Anonymous], 2023, interview; Chronopoulou A., 2019, An embarrassingly simple approach for transfer learning from pretrained language models; Clark TM, 2023, J CHEM EDUC, V100, P1905, DOI 10.1021/acs.jchemed.3c00027; Crosthwaite C, 2006, EDUC CHEM ENG, V1, P39, DOI 10.1205/ece.05002; Goedhart MJ, 1998, J CHEM EDUC, V75, P378, DOI 10.1021/ed075p378; Kang YH, 2023, NAT MACH INTELL, V5, P309, DOI 10.1038/s42256-023-00628-2; Kong ZY, 2023, SEP PURIF TECHNOL, V312, DOI 10.1016/j.seppur.2023.123344; Kong ZY, 2022, PROCESS SAF ENVIRON, V166, P574, DOI 10.1016/j.psep.2022.08.056; Kong ZY, 2022, IND ENG CHEM RES, DOI 10.1021/acs.iecr.2c01768; Liebmann AJ., 1956, Journal of Chemical Education, V33, P166, DOI DOI 10.1021/ED033P166; Lievin V., 2022, Can large language models reason about medical questions?; Luyben WL, 2017, CHEM ENG TECHNOL, V40, P1895, DOI 10.1002/ceat.201600576; Luyben WL, 2013, DISTILLATION DESIGN AND CONTROL USING ASPEN(TM) SIMULATION, 2ND EDITION, P1, DOI 10.1002/9781118510193; Mann V, 2021, AICHE J, V67, DOI 10.1002/aic.17190; Molzahn M, 2002, CHEM ENG TECHNOL, V25, P231; Moodley K, 2020, EDUC CHEM ENG, V31, P1, DOI 10.1016/j.ece.2020.02.002; Rahman NA, 2013, EDUC CHEM ENG, V8, pE45, DOI 10.1016/j.ece.2013.02.003; Sitapure N, 2023, COMPUT CHEM ENG, V177, DOI 10.1016/j.compchemeng.2023.108339; Sitapure N, 2023, CHEM ENG RES DES, V194, P461, DOI 10.1016/j.cherd.2023.04.028; Sunarso J, 2020, EDUC CHEM ENG, V33, P17, DOI 10.1016/j.ece.2020.07.001; Tyson J, 2023, J CHEM EDUC, V100, P3098, DOI 10.1021/acs.jchemed.3c00361; Wisniak J, 1998, J CHEM EDUC, V75, P1486, DOI 10.1021/ed075p1486; Yang A, 2023, SEP PURIF TECHNOL, V310, DOI 10.1016/j.seppur.2023.123131; Yang A, 2022, SEP PURIF TECHNOL, V301, DOI 10.1016/j.seppur.2022.121983; Yang A, 2023, CHEM ENG J, V451, DOI 10.1016/j.cej.2022.138563; Yang A, 2022, SEP PURIF TECHNOL, V290, DOI 10.1016/j.seppur.2022.120884; Yang XL, 2018, IND ENG CHEM RES, V57, P11050, DOI 10.1021/acs.iecr.8b00711	27	1	1	15	17	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	2772-5081			DIGIT CHEM ENG	Digit. Chem. Eng.	DEC	2023	9								100126	10.1016/j.dche.2023.100126	http://dx.doi.org/10.1016/j.dche.2023.100126		SEP 2023	11	Engineering, Chemical	Emerging Sources Citation Index (ESCI)	Engineering	X3WF5		gold			2024-07-03	WOS:001097784400001
J	Huang, XW; Ruan, WJ; Huang, W; Jin, GJ; Dong, Y; Wu, CS; Bensalem, S; Mu, RH; Qi, Y; Zhao, XY; Cai, KW; Zhang, YH; Wu, SH; Xu, PP; Wu, DY; Freitas, A; Mustafa, MA				Huang, Xiaowei; Ruan, Wenjie; Huang, Wei; Jin, Gaojie; Dong, Yi; Wu, Changshun; Bensalem, Saddek; Mu, Ronghui; Qi, Yi; Zhao, Xingyu; Cai, Kaiwen; Zhang, Yanghao; Wu, Sihao; Xu, Peipei; Wu, Dengyu; Freitas, Andre; Mustafa, Mustafa A.			A survey of safety and trustworthiness of large language models through the lens of verification and validation	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						AI Safety; Trustworthy AI; Verification and Validation; Safeguarding; Large Language Models; Generative AI	DEEP; NETWORKS	Large language models (LLMs) have exploded a new heatwave of AI for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities and limitations of the LLMs, categorising them into inherent issues, attacks, and unintended bugs. Then, we consider if and how the Verification and Validation (V&V) techniques, which have been widely developed for traditional software and deep learning models such as convolutional neural networks as independent processes to check the alignment of their implementations against the specifications, can be integrated and further extended throughout the lifecycle of the LLMs to provide rigorous analysis to the safety and trustworthiness of LLMs and their applications. Specifically, we consider four complementary techniques: falsification and evaluation, verification, runtime monitoring, and regulations and ethical use. In total, 370+ references are considered to support the quick understanding of the safety and trustworthiness issues from the perspective of V&V. While intensive research has been conducted to identify the safety and trustworthiness issues, rigorous yet practical methods are called for to ensure the alignment of LLMs with safety and trustworthiness requirements.	[Huang, Xiaowei; Ruan, Wenjie; Huang, Wei; Jin, Gaojie; Dong, Yi; Mu, Ronghui; Qi, Yi; Zhao, Xingyu; Cai, Kaiwen; Zhang, Yanghao; Wu, Sihao; Xu, Peipei; Wu, Dengyu] Univ Liverpool, Liverpool, England; [Wu, Changshun; Bensalem, Saddek] Univ Grenoble Alpes, Grenoble, France; [Freitas, Andre; Mustafa, Mustafa A.] Univ Manchester, Manchester, England; [Mustafa, Mustafa A.] Katholieke Univ Leuven, COSIC, Leuven, Belgium; [Huang, Wei] Purple Mt Labs, Nanjing, Peoples R China	University of Liverpool; Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA); University of Manchester; KU Leuven	Huang, XW (corresponding author), Univ Liverpool, Liverpool, England.	xiaowei.huang@liverpool.ac.uk			European Union's Horizon 2020 research and innovation programme [956123]; European Union [EP/T026995/1]; U.K. EPSRC	European Union's Horizon 2020 research and innovation programme(Horizon 2020); European Union(European Union (EU)); U.K. EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This project has received funding from the European Union's Horizon 2020 research and innovation programme under Grant Agreement No 956123. It is also financially supported by the U.K. EPSRC through End-to-End Conceptual Guarding of Neural Architectures [EP/T026995/1].	Seshia SA, 2020, Arxiv, DOI arXiv:1606.08514; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aghakhani H, 2024, Arxiv, DOI arXiv:2301.02344; Agrawal M, 2022, Arxiv, DOI arXiv:2205.12689; Aiyappa R, 2023, Arxiv, DOI [arXiv:2303.12767, DOI 10.48550/ARXIV.2303.12767]; Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396; Alshiekh M, 2018, AAAI CONF ARTIF INTE, P2669; Alzantot M, 2018, Arxiv, DOI [arXiv:1804.07998, DOI 10.48550/ARXIV.1804.07998]; [Anonymous], Bitcoin energy consumption relative to selected countries in 2020; [Anonymous], 2022, AI risk management framework; [Anonymous], 2023, Blueprint for an AI bill of rights; [Anonymous], 2018, Data Protection Act; [Anonymous], 2022, New meta AI demo writes racist and inaccurate scientific literature, gets pulled; [Anonymous], 2023, EU AI act; [Anonymous], 2023, Understanding artificial intelligence ethics and safety: a guide for the responsible design and implementation of AI systems in the public sector; [Anonymous], 1996, Graduate texts in computer science; [Anonymous], 2004, Quality management systems-process validation guidance; [Anonymous], 2018, Ethics guidelines for trustworthy AI; [Anonymous], 2023, Responsible AI principles from Microsoft; [Anonymous], 2023, Prompt leaking; [Anonymous], 2021, China's regulations on the administration of deep synthesis internet information services; [Anonymous], 2023, He would still be here': man dies by suicide after talking with AI chatbot, widow says; [Anonymous], Tools such as ChatGPT threaten transparent science; here are our ground rules for their use; [Anonymous], 2023, ChatGPT: US lawyer admits using AI for case research; [Anonymous], 2022, Prompt injection attacks against gpt-3; [Anonymous], 2022, China's regulations on recommendation algorithms; [Anonymous], 2022, Originality AI; [Anonymous], 2023, Three Samsung employees reportedly leaked sensitive data to ChatGPT; [Anonymous], 2023, China's algorithm registry; [Anonymous], GPT-4's details are leaked; [Anonymous], Italy became the first western country to ban ChatGPT; [Anonymous], 2022, Content at scale; [Anonymous], 2023, A pro-innovation approach to AI regulation; [Anonymous], 2023, EU data act; [Anonymous], 2023, ChatGPT: get instant answers, find creative inspiration, and learn something new; [Anonymous], March 20 ChatGPT outage: here's what happened; Arora U, 2021, PREPRINT; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Balaji Y., 2022, arXiv; Balakrishnan A, 2019, DES AUT TEST EUROPE, P1433, DOI [10.23919/DATE.2019.8715114, 10.23919/date.2019.8715114]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bartocci E, 2018, Lectures on runtime verification; Bauer A, 2011, ACM T SOFTW ENG METH, V20, DOI 10.1145/2000799.2000800; Belinkov Y, 2018, Arxiv, DOI arXiv:1711.02173; Bensalem S., 1996, Computer Aided Verification. 8th International Conference, CAV '96. Proceedings, P323; Bensalem S, 1998, LECT NOTES COMPUT SC, V1427, P505, DOI 10.1007/BFb0028771; Bensalem S, 2023, ISOLA 2023; Bensalem S, 2022, LECT NOTES COMPUT SC, V13466, P131, DOI 10.1007/978-3-031-21222-2_8; Berthier N, 2021, Arxiv, DOI arXiv:2103.03704; Bibel W., 2013, Automated theorem proving; Black S., 2022, PREPRINT; Bonaert G, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P466, DOI 10.1145/3453483.3454056; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Botacin M, 2023, IEEE SEC PRIV WORKS, P238, DOI 10.1109/SPW59333.2023.00027; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bullwinkle M, 2023, Introduction to red teaming large language models (LLMS); Bursztein E, 2018, Attacks against machine learning-an overview; Cambiaso E, 2023, Arxiv, DOI [arXiv:2303.13521, 10.48550/arXiv.2303.13521, DOI 10.48550/ARXIV.2303.13521]; Cao Y, 2022, Arxiv, DOI arXiv:2210.15221; Carlini N, 2024, Arxiv, DOI arXiv:2302.10149; Changliu Liu, 2021, Foundations and Trends in Optimization, V4, P244, DOI 10.1561/2400000035; Chen B., 2019, SAFEAI AAAI; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen M., 2021, arXiv; Chen S, 2022, FINDINGS ASS COMPUTA, P6676; Chen S, FINDINGS ASS COMPUTA, P552; Chen S, 2023, MedrXiv, P2023; Chen XY, 2021, 37TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2021, P554, DOI 10.1145/3485832.3485837; Cheng Chih-Hong, 2022, Automated Technology for Verification and Analysis: 20th International Symposium, ATVA 2022, Proceedings. Lecture Notes in Computer Science (13505), P397, DOI 10.1007/978-3-031-19992-9_26; Cheng CH, 2019, DES AUT TEST EUROPE, P300, DOI [10.23919/date.2019.8714971, 10.23919/DATE.2019.8714971]; Cheng MH, 2020, AAAI CONF ARTIF INTE, V34, P3601; Cheng Y, 2019, Arxiv, DOI arXiv:1906.02443; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cho H, 2022, FINDINGS ASS COMPUTA, P783; Cho JH, 2019, IEEE I CONF COMP VIS, P4793, DOI 10.1109/ICCV.2019.00489; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano PF, 2017, ADV NEUR IN, V30; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cohen J, 2019, PMLR, P1310; Copernicuse, 2022, About us; Croce F, 2020, PR MACH LEARN RES, V119; Dai JZ, 2019, IEEE ACCESS, V7, P138872, DOI 10.1109/ACCESS.2019.2941376; Dan S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2096; Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; de Vries A, 2022, JOULE, V6, P498, DOI 10.1016/j.joule.2022.02.005; Desai S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P295; Deshpande A, 2023, Arxiv, DOI arXiv:2304.05335; Dettmers T., 2022, Advances in Neural Information Processing Systems, V35, P30318; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DeVries T, 2018, Arxiv, DOI arXiv:1802.04865; Dey N, 2023, GPT: a family of open, compute-efficient, large language models; Dodge J, 2020, Arxiv, DOI [arXiv:2002.06305, 10.48550/arXiv.2002.06305]; Du N, 2022, PR MACH LEARN RES; Du TY, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P516, DOI 10.1145/3460120.3484538; Duan H, 2022, FINDINGS ASS COMPUTA, P750; Duan JH, 2023, Arxiv, DOI arXiv:2302.01316; Dudley JJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3185517; E2Analyst, 2023, GPT-4: everything you want to know about OpenAI's new AI model; Ebrahimi J, 2018, Arxiv, DOI arXiv:1712.06751; Edwards B, 2023, Study claims ChatGPT is losing capability, but some experts aren't convinced; Engadget, OpenAI says a bug leaked sensitive ChatGPT user data; Eppstein D., 1996, Math Educ Res, V5, P15; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; EU GDPR, 2016, About us; Farhat F, 2023, COGENT ENG, V10, DOI 10.1080/23311916.2023.2222988; Fedus W., 2021, J Mach Learn Res, V23, P1; Feinman R, 2017, Arxiv, DOI arXiv:1703.00410; Feiyu Xu, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P563, DOI 10.1007/978-3-030-32236-6_51; Frantar E, 2023, INT C LEARN REPR; Frantar E, 2023, Arxiv, DOI arXiv:2208.11580; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Futureoflife, Pause giant AI experiments: an open letter; Gangal V, 2020, AAAI CONF ARTIF INTE, V34, P7764; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P50, DOI 10.1109/SPW.2018.00016; Gao L, 2023, Pal: Program-aided language models; García J, 2015, J MACH LEARN RES, V16, P1437; github, Prompt engineering guide; Goodfellow I, 2017, The challenge of verification and testing of machine learning; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Goodin D, 2023, Hackers are selling a service that bypasses ChatGPT restrictions on malware; Gopinath D, 2018, Arxiv, DOI arXiv:1807.10439; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Gowal S, 2019, Arxiv, DOI arXiv:1810.12715; Goyal S, 2023, Arxiv, DOI [arXiv:2203.06414, 10.48550/ARXIV.2203.06414, DOI 10.48550/ARXIV.2203.06414]; Greshake K, 2023, Arxiv, DOI arXiv:2302.12173; Gu JC, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2041, DOI 10.1145/3340531.3412330; Gu SD, 2023, Arxiv, DOI arXiv:2302.13137; Gu SD, 2024, Arxiv, DOI arXiv:2205.10330; Gu TY, 2019, IEEE ACCESS, V7, P47230, DOI 10.1109/ACCESS.2019.2909068; Gu YX, 2024, Arxiv, DOI arXiv:2306.08543; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; He R., 2022, P IEEECVF C COMPUTER, P9161; Hendrycks D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2744; Hendrycks Dan, 2016, INT C LEARN REPR; Henzinger TA, 2020, FRONT ARTIF INTEL AP, V325, P2433, DOI 10.3233/FAIA200375; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hintze A, 2023, Arxiv, DOI [arXiv:2304.12898, DOI 10.48550/ARXIV.2304.12898]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Holmes J, 2023, Arxiv, DOI arXiv:2304.01938; Hosseini H, 2017, Arxiv, DOI arXiv:1702.08138; Houlsby N, 2019, PR MACH LEARN RES, V97; Hrinchuk O, 2020, INT CONF ACOUST SPEE, P7074, DOI [10.1109/icassp40776.2020.9053051, 10.1109/ICASSP40776.2020.9053051]; Hu E.J., 2022, INT C LEARN REPR; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu Zhiting, 2017, P 34 INT C MACHINE L, P1587; Huang HW, 2020, Arxiv, DOI arXiv:2011.14654; Huang PS, 2019, Arxiv, DOI arXiv:1909.01492; Huang W, 2023, Arxiv, DOI arXiv:2205.08589; Huang W, 2022, Arxiv, DOI arXiv:2208.09418; Huang W, 2022, IEEE T RELIAB, V71, P1191, DOI 10.1109/TR.2021.3080664; Huang X, 2022, FORMAL METHODS SOFTW, P1; Huang XW, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100270; Huang XW, 2017, LECT NOTES COMPUT SC, V10426, P3, DOI 10.1007/978-3-319-63387-9_1; Huang XJ, 2019, Arxiv, DOI [arXiv:1911.07399, 10.48550/ARXIV.1911.07399]; Ilyas A, 2019, ADV NEUR IN, V32; Ivankay A, 2022, PREPRINT; Iyyer M, 2018, Arxiv, DOI arXiv:1804.06059; Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572; Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002; Jang ME, 2023, Arxiv, DOI arXiv:2303.06273; Jansen N., 2020, Safe reinforcement learning using probabilistic shields; Jansen N, 2019, Arxiv, DOI arXiv:1807.06096; Ji Y, 2023, Exploring chatgpt's ability to rank content: A preliminary study on consistency with human preferences; Jia RB, 2017, Arxiv, DOI arXiv:1707.07328; Jia RB, 2019, Arxiv, DOI arXiv:1909.00986; Jiang AQ, 2022, Arxiv, DOI arXiv:2210.12283; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Kalyan K. S., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.05542, 10.48550/arXiv.2108.05542]; Kambhampati S, 2022, COMMUN ACM, V65, P8, DOI 10.1145/3546954; Kande R, 2023, arXiv; Kang D., 2023, arXiv; Kang YH, 2023, Arxiv, DOI arXiv:2304.10743; Kapitanova K, 2013, INTELLIGENT SENSOR NETWORKS: THE INTEGRATION OF SENSOR NETWORKS, SIGNAL PROCESSING AND MACHINE LEARNING, P3; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Katz Daniel Martin, 2023, GPT-4 Passes the Bar Exam, DOI DOI 10.2139/SSRN.4389233; Khoury R, 2023, Arxiv, DOI arXiv:2304.09655; Kim Y-M., 2023, Korea Copyright Commission, V141, P5, DOI [10.30582/kdps.2023.36.1.5, DOI 10.30582/KDPS.2023.36.1.5]; Ko C-Y, 2019, PMLR, P3468; Koh JY, 2023, Arxiv, DOI arXiv:2305.17216; Kuleshov V, 2018, PREPRINT; Kumar A, 2020, T ASSOC COMPUT LING, V8, P330, DOI 10.1162/tacl_a_00318; Kurita K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2793; La Malfa E, 2020, Arxiv, DOI arXiv:2010.02004; Lam M., 2006, COMPILERS PRINCIPLES; Lambert N, 2022, Hugging Face Blog; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lee CLY, 2020, Arxiv, DOI [arXiv:1909.11299, 10.48550/arXiv.1909.11299]; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Lee KM, 2023, Arxiv, DOI arXiv:2302.12192; Lee NY, 2020, Arxiv, DOI arXiv:2006.04666; Lee P, 2016, Official Microsoft Blog; Lei YB, 2022, Arxiv, DOI arXiv:2205.10710; Lepikhin D, 2020, Arxiv, DOI [arXiv:2006.16668, DOI 10.48550/ARXIV.2006.16668]; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li HR, 2023, Arxiv, DOI [arXiv:2304.05197, 10.48550/arXiv.2304.05197]; Li J., 2023, arXiv; Li J, 2022, arXiv; Li JF, 2018, Arxiv, DOI arXiv:1812.05271; Li SF, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P3123, DOI 10.1145/3460120.3484576; Li XY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3102; Li Y, 2019, Arxiv, DOI arXiv:1808.05385; Liang B, 2019, Arxiv, DOI arXiv:1704.08006; Liang S., 2018, INT C LEARNING REPRE; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lin ZJ, 2020, Arxiv, DOI arXiv:1907.12108; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu W., 2020, Advances in neural information processing systems, P21464, DOI DOI 10.48550/ARXIV.2010.03759; Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Z., 2021, Adv. Neural Inf. Process.Syst., P28092; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Lou RZ, 2024, Arxiv, DOI [arXiv:2303.10475, 10.48550/ARXIV.2303.10475]; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Madaan N, 2021, AAAI CONF ARTIF INTE, V35, P13516; Madry A, 2019, Arxiv, DOI arXiv:1706.06083; Malinka K, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P47, DOI 10.1145/3587102.3588827; Manna Z., 2012, The temporal logic of reactive and concurrent systems: specification; Maus N, 2023, Arxiv, DOI arXiv:2302.04237; McCune W, 2005, Prover9 and Mace4; Mehdi Y, 2023, Announcing the next wave of AI innovation with Microsoft Bing and Edge; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Mirman M, 2018, PMLR, P3578; Mitrovic S, 2023, ChatGPT or Human? Detect and Explain. Explaining Decisions of Machine Learning Model for Detecting Short ChatGPT-generated Text; Monteiro J, 2019, IEEE SYS MAN CYBERN, P2839, DOI [10.1109/SMC.2019.8913861, 10.1109/smc.2019.8913861]; Nagel Markus, 2020, PMLR, P7197; Nelson B, 2008, P 1 US WORKSH LARG E; News TH, 2023, WormGPT: new AI tool allows cybercriminals to launch sophisticated cyber attacks; Ni A., 2023, INT C MACHINE LEARNI, P26106; Nichol A, 2022, Arxiv, DOI arXiv:2112.10741; Nie YX, 2020, Arxiv, DOI arXiv:1910.14599; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan S, 2023, Unifying large language models and knowledge graphs: a roadmap; Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950; Park G, 2024, Arxiv, DOI arXiv:2206.09557; Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pegoraro A, 2023, Arxiv, DOI [arXiv:2304.01487, 10.48550/arXiv.2304.01487, DOI 10.48550/ARXIV.2304.01487]; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Podolskiy A, 2021, AAAI CONF ARTIF INTE, V35, P13675; Qi Y, 2023, Arxiv, DOI arXiv:2304.01246; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A, 2020, NIPS'20; Radford A, 2017, Arxiv, DOI arXiv:1704.01444; Raffel C, 2020, J MACH LEARN RES, V21; Ramamurthy R, 2023, Arxiv, DOI arXiv:2210.01241; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Ren J, 2019, 33 C NEURAL INFORM P, V32; Ren SH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1085; Ren XZ, 2023, Arxiv, DOI arXiv:2303.10845; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rolfe J. T., 2016, PREPRINT; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Ruan WJ, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5944; Ruan WJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2651; Ruder S, 2019, P C N AM CHAPT ASS C, P15, DOI [10.18653/v1/N19-5004, DOI 10.18653/V1/N19-5004]; Rueckauer B, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00682; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Ryou W, 2021, LECT NOTES COMPUT SC, V12759, P225, DOI 10.1007/978-3-030-81685-8_10; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Samanta S, 2017, Arxiv, DOI arXiv:1707.02812; Sandoval G, 2022, Arxiv, DOI arXiv:2208.09727; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Senate U, 2023, Senate judiciary subcommittee hearing on oversight of AI; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shen LJ, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P3141, DOI 10.1145/3460120.3485370; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Shen YL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2443; Shi Z, 2019, INT C LEARN REPR; Shuster K, 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.07567; Shuster Kurt, 2022, PREPRINT; Sinha A, 2020, Arxiv, DOI arXiv:1710.10571; Smith L, 2018, Arxiv, DOI arXiv:1803.08533; Smith S, 2022, arXiv; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Soltan S, 2022, arXiv; Struppek L, 2022, arXiv; Sun H, 2023, Arxiv, DOI arXiv:2304.10436; Sun Y, ASE2018; Sun YC, 2019, Arxiv, DOI arXiv:1803.04792; Sun YC, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358233; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Tanguy L, 2016, COMPUT IND, V78, P80, DOI 10.1016/j.compind.2015.09.005; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Taylor R, 2022, arXiv; Tejankar A, 2023, PROC CVPR IEEE, P12239, DOI 10.1109/CVPR52729.2023.01178; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thorne J, 2018, CONFNORTH AM CHAPTER, V1, P809, DOI [10.18653/v1/n18-1074, DOI 10.18653/V1/N18-1074, 10.18653/v1/N18-1074]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Towardsdatascience, The carbon footprint of GPT-4; Tulshan AS, 2019, ADV SIGNAL PROCESSIN, P190; Tung F, 2019, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2019.00145; Uchendu A, 2023, CoRR. abs/2304.01002; Vardi M. Y., 1986, Proceedings of the Symposium on Logic in Computer Science (Cat. No.86CH2321-8), P332; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wallace M, 2022, PREPRINT; Wang BX, 2022, Arxiv, DOI arXiv:2111.02840; Wang F, 2023, Arxiv, DOI arXiv:2301.12456; Wang G., 2010, 2010 IEEEACM INT C G, P344, DOI [10.1109/GreenCom-CPSCom.2010.102, DOI 10.1109/GREENCOMCPSCOM.2010.102]; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang WJ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1102; Wang X., 2023, 11 INT C LEARN REPR; Wang YC, 2018, Arxiv, DOI arXiv:1804.06473; Wei JS, 2022, ADV NEUR IN; Wei J, 2023, Arxiv, DOI arXiv:2301.05843; Weng TW, 2018, Arxiv, DOI arXiv:1801.10578; Weng YX, 2024, Arxiv, DOI arXiv:2304.01665; Weng YX, 2023, Arxiv, DOI arXiv:2212.09561; Wicker M, 2018, LECT NOTES COMPUT SC, V10805, P408, DOI 10.1007/978-3-319-89960-2_22; Wolf Y, 2024, Arxiv, DOI arXiv:2304.11082; Wong ER, 2020, Arxiv, DOI [arXiv:2001.03994, DOI 10.48550/ARXIV.2001.03994]; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu DY, 2024, Arxiv, DOI arXiv:2301.09522; Wu DY, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.759900; Wu HR, 2023, Arxiv, DOI arXiv:2303.13648; Wu M, 2020, THEOR COMPUT SCI, V807, P298, DOI 10.1016/j.tcs.2019.05.046; Wu MH, 2024, Arxiv, DOI arXiv:2304.14402; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Wu XS, 2023, Arxiv, DOI arXiv:2303.14420; Wu Y, 2023, INTERV NEURORADIOL, V29, P63, DOI 10.1177/15910199211070900; Xu H, 2020, P 28 INT C COMP LING, P1452; Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x; Xu JZ, 2023, Arxiv, DOI [arXiv:2304.05977, 10.48550/arXiv.2304.05977]; Xu PP, 2023, COMPLEX INTELL SYST, V9, P3801, DOI 10.1007/s40747-022-00790-x; Yandex, Yandex/YaLM-100B: pretrained language model with 100B parameters; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang JK, 2024, Arxiv, DOI arXiv:2110.11334; Yang WK, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2048; Yang Z, 2023, Chinese tech giant Baidu just released its answer to ChatGPT; Yang ZL, 2019, ADV NEUR IN, V32; Yao Shunyu, 2023, 11 INT C LEARN REPR; Yao Z., 2022, Advances in Neural Information Processing Systems, V35, P27168; Ye M, 2020, Arxiv, DOI arXiv:2005.14424; Ye X, 2023, Arxiv, DOI arXiv:2211.13892; Yilmaz EH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2093; Yu JH, 2022, Arxiv, DOI [arXiv:2206.10789, 10.48550/arXiv.2206.10789]; Zeng JH, 2021, Arxiv, DOI arXiv:2105.03743; Zeng W., 2021, PREPRINT; Zeng ZY, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P870; Zhang C, 2023, PREPRINT; Zhang C, 2023, Arxiv, DOI arXiv:2304.00813; Zhang J., 2020, PMLR, P11328; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T., 2023, arXiv; Zhang YH, 2021, Arxiv, DOI arXiv:2102.07818; Zhao RC, 2023, Arxiv, DOI arXiv:2304.11076; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao X, 2021 51 ANN IEEE IFI, P5; Zhao X., 2021, P 37 C UNC ART INT, P887; Zhao Z., 2017, PREPRINT; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhou W, 2021, P 2021 C EMP METH NA; Zhou YH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5129; Zhu RJ, 2023, Arxiv, DOI [arXiv:2302.13939, 10.48550/arXiv.2302.13939, DOI 10.48550/ARXIV.2302.13939]	372	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821	1573-7462		ARTIF INTELL REV	Artif. Intell. Rev.	JUN 17	2024	57	7							175	10.1007/s10462-024-10824-0	http://dx.doi.org/10.1007/s10462-024-10824-0			53	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UN6B3		hybrid			2024-07-03	WOS:001248766900001
J	Landais, R; Sultan, M; Thomas, RH				Landais, Raphaelle; Sultan, Mustafa; Thomas, Rhys H.			The promise of AI Large Language Models for Epilepsy care	EPILEPSY & BEHAVIOR			English	Article						AI; Epilepsy; Physician assistant; Patient self-management; Automate paperwork; Time saving		Artificial intelligence (AI) has been supporting our digital life for decades, but public interest in this has exploded with the recognition of large language models, such as GPT-4. We examine and evaluate the potential uses for generative AI technologies in epilepsy and neurological services. Generative AI could not only improve patient care and safety by refining communication and removing certain barriers to healthcare but may also extend to streamlining a doctor's practice through strategies such as automating paperwork. Challenges with the integration of generative AI in epilepsy services are also explored and include the risk of producing inaccurate and biased information. The impact generative AI could have on the provision of healthcare, both positive and negative, should be understood and considered carefully when deciding on the steps that need to be taken before AI is ready for use in hospitals and epilepsy services.	[Landais, Raphaelle] Newcastle Univ, Fac Med Sci, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England; [Sultan, Mustafa] Manchester Univ NHS Fdn Trust, Manchester M13 9PT, Lancs, England; [Thomas, Rhys H.] Royal Victoria Infirm, Dept Neurol, Queen Victoria Rd, Newcastle Upon Tyne NE1 4LP, Tyne & Wear, England; [Thomas, Rhys H.] Translat & Clin Res Inst, Henry Wellcome Bldg,Framlington Pl, Newcastle Upon Tyne NE2 4HH, Tyne & Wear, England	Newcastle University - UK; Newcastle University - UK; Newcastle University - UK	Thomas, RH (corresponding author), Royal Victoria Infirm, Dept Neurol, Queen Victoria Rd, Newcastle Upon Tyne NE1 4LP, Tyne & Wear, England.	rhys.thomas@ncl.ac.uk		Landais, Raphaelle/0000-0002-7668-1776; Thomas, Rhys/0000-0003-2062-8623				[Anonymous], AI regulation in healthcare: UK and EU approaches; [Anonymous], Where Watson went wrong-Features-MM+M-Medical Marketing and Media; [Anonymous], When does artificial intelligence amount to a medical device and what is changing -Trowers & Hamlins; [Anonymous], Speech to text-OpenAI API; [Anonymous], ChatGPT vs. Perplexity vs. Claude: AI Chatbot Tools Compared; [Anonymous], What Gemini Apps can do and other frequently asked questions; [Anonymous], Artificial Intelligence and Machine Learning in Software as a Medical Device; [Anonymous], WHAT IS ARTIFICIAL I; [Anonymous], AI at Meta; [Anonymous], GPT-4; [Anonymous], Lack of care plans and access to specialists-Epilepsy Action; [Anonymous], ChatGPT vs GPT3 vs OpenAI: What Are The Key Differences?-Artificial Income Intelligence; [Anonymous], Bing chat; Beis, 2022, The Regulation of Artificial Intelligence as a Medical Device; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Busis NA, 2017, NEUROLOGY, V88, P797, DOI 10.1212/WNL.0000000000003640; ChatGPT, about us; Chen TC, 2023, BMJ NEUROL OPEN, V5, DOI 10.1136/bmjno-2023-000530; DALLE, Creating images from text; Daungsupawong H, 2024, SEIZURE-EUR J EPILEP, V114, P105, DOI 10.1016/j.seizure.2023.12.004; Day Suzanne, 2020, Res Involv Engagem, V6, P8, DOI 10.1186/s40900-020-0182-y; GPT-4, OpenAI's Next-Generation Multimodal AI with Advanced ChatGPT Functionality-Ultimate QA; Kerr WT, 2023, CURR NEUROL NEUROSCI, V23, P869, DOI 10.1007/s11910-023-01318-7; Kim HW, 2024, SEIZURE-EUR J EPILEP, V114, P1, DOI 10.1016/j.seizure.2023.11.013; Kuroda N, 2020, EPILEPSY BEHAV, V111, DOI 10.1016/j.yebeh.2020.107198; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Perzynski AT, 2017, CHRONIC ILLN, V13, P188, DOI 10.1177/1742395316674540; Plug L, 2009, SEIZURE-EUR J EPILEP, V18, P43, DOI 10.1016/j.seizure.2008.06.002; Protheroe J, 2015, BRIT J GEN PRACT, V65, pE192, DOI 10.3399/bjgp15X684013; Romano MF, 2023, NEUROLOGY, V101, P1058, DOI 10.1212/WNL.0000000000207967; Shankar R, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198261; Shankar Rohit, 2015, BMJ Qual Improv Rep, V4, DOI 10.1136/bmjquality.u208167.w3252; Sultan M, 2020, J NEUROL NEUROSUR PS, V91, P781, DOI 10.1136/jnnp-2019-322610; Wu YX, 2024, EPILEPSY BEHAV, V151, DOI 10.1016/j.yebeh.2024.109645; Zuchowski M, 2022, British Journal of Health Care Management, V28, P30, DOI [10.12968/BJHC.2021.0074/ASSET/IMAGES/LARGE/BJHC.2021.0074_T03.JPEG, DOI 10.12968/BJHC.2021.0074/ASSET/IMAGES/LARGE/BJHC.2021.0074_T03.JPEG]	35	0	0	1	1	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1525-5050	1525-5069		EPILEPSY BEHAV	Epilepsy Behav.	MAY	2024	154								109747	10.1016/j.yebeh.2024.109747	http://dx.doi.org/10.1016/j.yebeh.2024.109747		MAR 2024	7	Behavioral Sciences; Clinical Neurology; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Behavioral Sciences; Neurosciences & Neurology; Psychiatry	PR1L7	38518673				2024-07-03	WOS:001215718000001
J	Warrier, A; Singh, R; Haleem, A; Zaki, H; Eloy, JA				Warrier, Akshay; Singh, Rohan; Haleem, Afash; Zaki, Haider; Eloy, Jean Anderson			The Comparative Diagnostic Capability of Large Language Models in Otolaryngology	LARYNGOSCOPE			English	Article; Early Access						artificial intelligence; Bing AI; ChatGPT; diagnostic accuracy; Google Bard; large language models; otolaryngology		Objectives: Evaluate and compare the ability of large language models (LLMs) to diagnose various ailments in otolaryngology. Methods: We collected all 100 clinical vignettes from the second edition of Otolaryngology Cases-The University of Cincinnati Clinical Portfolio by Pensak et al. With the addition of the prompt "Provide a diagnosis given the following history," we prompted ChatGPT-3.5, Google Bard, and Bing-GPT4 to provide a diagnosis for each vignette. These diagnoses were compared to the portfolio for accuracy and recorded. All queries were run in June 2023. Results: ChatGPT-3.5 was the most accurate model (89% success rate), followed by Google Bard (82%) and Bing GPT (74%). A chi-squared test revealed a significant difference between the three LLMs in providing correct diagnoses (p = 0.023). Of the 100 vignettes, seven require additional testing results (i.e., biopsy, non-contrast CT) for accurate clinical diagnosis. When omitting these vignettes, the revised success rates were 95.7% for ChatGPT-3.5, 88.17% for Google Bard, and 78.72% for Bing-GPT4 (p = 0.002). Conclusions: ChatGPT-3.5 offers the most accurate diagnoses when given established clinical vignettes as compared to Google Bard and Bing-GPT4. LLMs may accurately offer assessments for common otolaryngology conditions but currently require detailed prompt information and critical supervision from clinicians. There is vast potential in the clinical applicability of LLMs; however, practitioners should be wary of possible "hallucinations" and misinformation in responses.	[Warrier, Akshay; Singh, Rohan; Haleem, Afash; Zaki, Haider; Eloy, Jean Anderson] Rutgers New Jersey Med Sch, Dept Otolaryngol Head & Neck Surg, Newark, NJ USA; [Eloy, Jean Anderson] Rutgers New Jersey Med Sch, Neurol Inst New Jersey, Ctr Skull Base & Pituitary Surg, Newark, NJ USA; [Warrier, Akshay] Rutgers New Jersey Med Sch, Dept Otolaryngol Head & Neck Surg, 180 West Market St, Newark, NJ 07103 USA	Rutgers University System; Rutgers University New Brunswick; Rutgers University Biomedical & Health Sciences; Rutgers University System; Rutgers University New Brunswick; Rutgers University Biomedical & Health Sciences; Rutgers University System; Rutgers University New Brunswick; Rutgers University Biomedical & Health Sciences	Warrier, A (corresponding author), Rutgers New Jersey Med Sch, Dept Otolaryngol Head & Neck Surg, 180 West Market St, Newark, NJ 07103 USA.	akw58@njms.rutgers.edu		Haleem, Afash/0000-0001-7268-6142				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Borji A., 2023, SSRN Electron. J., DOI [10.2139/SSRN.4476855, DOI 10.2139/SSRN.4476855]; Chatterjee S, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00700-1; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Europe PMC, 2016, Europe PMC; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Giannakopoulos K, 2023, J MED INTERNET RES, V25, DOI 10.2196/51580; Gordon EB, 2024, J AM COLL RADIOL, V21, P353, DOI 10.1016/j.jacr.2023.09.011; GPT-4, 2015, Accessed January 10, 2024; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Gupta R, 2023, AESTHET SURG J, DOI 10.1093/asj/sjad128; Hirosawa T, 2023, AM J MED, V136, P1119, DOI 10.1016/j.amjmed.2023.08.003; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kuroiwa T, 2023, J MED INTERNET RES, V25, DOI 10.2196/47621; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; McDuff D., 2023, arXiv; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Mitsuyama Y, 2023, medRxiv, DOI [10.1101/2023.10.27.23297585, 10.1101/2023.10.27.23297585, DOI 10.1101/2023.10.27.23297585]; Mu Xin, 2024, Skin Health Dis, V4, pe313, DOI 10.1002/ski2.313; Pensak ML., 2017, Otolaryngology Cases; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Roos J, 2023, JMIR MED EDUC, V9, DOI 10.2196/46482; Sharma SC, 2023, INDIAN J PLAST SURG, V56, P320, DOI 10.1055/s-0043-1771514; Shemer A, 2024, GRAEF ARCH CLIN EXP, DOI 10.1007/s00417-023-06363-z; Sosa BR, 2024, J ORTHOP RES, V42, P1276, DOI 10.1002/jor.25782; Stoneham S, 2024, CLIN EXP DERMATOL, V49, P707, DOI 10.1093/ced/llad402; Temsah Mohamad-Hani, 2023, Cureus, V15, pe44769, DOI 10.7759/cureus.44769; ten Berg H, 2024, ANN EMERG MED, V83, P83, DOI 10.1016/j.annemergmed.2023.08.003; Waisberg E, 2024, EYE, V38, P642, DOI 10.1038/s41433-023-02760-0; Zalzal HG, 2024, LARYNGOSCOPE INVEST, V9, DOI 10.1002/lio2.1193; Zalzal HG, 2023, OTO OPEN, V7, DOI 10.1002/oto2.94	36	1	1	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0023-852X	1531-4995		LARYNGOSCOPE	Laryngoscope	2024 APR 2	2024										10.1002/lary.31434	http://dx.doi.org/10.1002/lary.31434		APR 2024	6	Medicine, Research & Experimental; Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Research & Experimental Medicine; Otorhinolaryngology	MQ6N1	38563415	hybrid			2024-07-03	WOS:001195133600001
J	Yamazaki, T; Yoshikawa, K; Kawamoto, T; Mizumoto, T; Ohagi, M; Sato, T				Yamazaki, Takato; Yoshikawa, Katsumasa; Kawamoto, Toshiki; Mizumoto, Tomoya; Ohagi, Masaya; Sato, Toshinori			Building a hospitable and reliable dialogue system for android robots: a scenario-based approach with large language models	ADVANCED ROBOTICS			English	Article						Task-oriented dialogue systems; humanoid robots; human-robot interaction; large language models; prompt-programming; >		Dialogue systems implemented with android robots are expected to provide not only advanced conversational ability but also reliability and hospitality due to their human-like appearance. In this study, we aim to develop a hospitable dialogue system by encouraging open-ended utterances and responding adaptively to give users the feeling of being heard. To achieve this, utilizing large language models (LLMs) is a promising option, but task-oriented dialogue systems implemented with only LLMs often generate irrelevant, inconsistent, or contradictory utterances. Therefore, we propose a scenario-based dialogue system that subdivides the task into smaller sub-tasks, such as summarization, information extraction, and response generation, and uses LLMs in a fine-grained manner to overcome such shortcomings of the LLM-based dialogue system. Our system was evaluated in the tourist-spot recommendation task of the Dialogue Robot Competition 2022 and achieved second place in the preliminary round and first place in the final round, outperforming other rule-based dialogue systems. However, we also identified several challenges when using LLMs for android dialogue systems, including response delays due to computational complexity, hallucinations, and coordination issues between generated utterances and robot control.	[Yamazaki, Takato; Yoshikawa, Katsumasa; Kawamoto, Toshiki; Mizumoto, Tomoya; Ohagi, Masaya; Sato, Toshinori] LINE Corp, Tokyo, Japan; [Kawamoto, Toshiki] Tokyo Inst Technol, Tokyo, Japan	Tokyo Institute of Technology	Yamazaki, T (corresponding author), LINE Corp, Tokyo, Japan.	takato.yamazaki@linecorp.com						Agarwal Shubham, 2020, ACL, P8182; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Collins G.R., 2020, Int. Hosp. Rev., V34, P61, DOI [10.1108/IHR-09-2019-0019, DOI 10.1108/IHR-09-2019-0019]; Higashinaka R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3146; Inoue K., 2016, PROC ANN M SPECIAL I, P212; Inoue K, 2022, FRONT ROBOT AI, V9, DOI 10.3389/frobt.2022.933261; Jentzsch S., 2023, ARXIV; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kawamoto T., 2021, P 93 SPEC INT GROUP, P131; Kim B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3405; Kottur S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4903; Kubo Y., 2022, P DIAL ROB COMP 2022; Li M., 2020, P 58 ANN M ASS COMPU, P4715, DOI [10.18653/v1/2020.acl-main.428, DOI 10.18653/V1/2020.ACL-MAIN.428]; Madotto A., 2021, ARXIV; Minato T., 2022, P DIAL ROB COMP 2022; Miyama T., 2022, P DIAGL ROB COMP 202; Raunak V, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1172; Scheutz M, 2011, AI MAG, V32, P77, DOI 10.1609/aimag.v32i4.2381; Soo Mee Kim, 2014, 2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI 10.1109/NSSMIC.2014.7430762; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Yamazaki T., 2021, P 93 SPEC INT GROUP, P113	22	3	3	8	21	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0169-1864	1568-5535		ADV ROBOTICS	Adv. Robot.	NOV 2	2023	37	21			SI		1364	1381		10.1080/01691864.2023.2244554	http://dx.doi.org/10.1080/01691864.2023.2244554		AUG 2023	18	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	X5FW8		hybrid			2024-07-03	WOS:001052382900001
J	Polverini, G; Gregorcic, B				Polverini, Giulia; Gregorcic, Bor			How understanding large language models can inform the use of ChatGPT in physics education	EUROPEAN JOURNAL OF PHYSICS			English	Article						physics education; large language models; prompt engineering; GPT-4; ChatGPT; conceptual physics tasks; artificial intelligence in education		The paper aims to fulfil three main functions: (1) to serve as an introduction for the physics education community to the functioning of large language models (LLMs), (2) to present a series of illustrative examples demonstrating how prompt-engineering techniques can impact LLMs performance on conceptual physics tasks and (3) to discuss potential implications of the understanding of LLMs and prompt engineering for physics teaching and learning. We first summarise existing research on the performance of a popular LLM-based chatbot (ChatGPT) on physics tasks. We then give a basic account of how LLMs work, illustrate essential features of their functioning, and discuss their strengths and limitations. Equipped with this knowledge, we discuss some challenges with generating useful output with ChatGPT-4 in the context of introductory physics, paying special attention to conceptual questions and problems. We then provide a condensed overview of relevant literature on prompt engineering and demonstrate through illustrative examples how selected prompt-engineering techniques can be employed to improve ChatGPT-4's output on conceptual introductory physics problems. Qualitatively studying these examples provides additional insights into ChatGPT's functioning and its utility in physics problem-solving. Finally, we consider how insights from the paper can inform the use of LLMs in the teaching and learning of physics.	[Polverini, Giulia; Gregorcic, Bor] Uppsala Univ, Dept Phys & Astron, Box 516, SE-75120 Uppsala, Sweden	Uppsala University	Gregorcic, B (corresponding author), Uppsala Univ, Dept Phys & Astron, Box 516, SE-75120 Uppsala, Sweden.	bor.gregorcic@physics.uu.se	Polverini, Giulia/KLZ-4370-2024; Gregorcic, Bor/ABI-7225-2022	Polverini, Giulia/0000-0001-9280-4329; Gregorcic, Bor/0000-0002-9185-628X				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; [Anonymous], OpenAI Models; APS, Statement on Diversity in Physics; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bellini-Leite S C., Analytic Thinking (Type 2 or 'System 2') for Large Language Models: Using Psychology to Address Hallucination and Reliability Issues, DOI [10.1177/10597123231206604, DOI 10.1177/10597123231206604]; Bitzenbauer P, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13176; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chang EY, 2023, 2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC, P351, DOI 10.1109/CCWC57344.2023.10099179; Chiang T., ChatGPT Is a Blurry JPEG of the Web; Choi J H., 2022, J. Legal Educ, V71, P387; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Dahlkemper MN, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010142; Dave P., ChatGPT Is cutting non-english languages out of the AI revolution; Davis E, 2023, Arxiv, DOI arXiv:2301.09723; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Dos Santos R.P., 2023, arXiv, DOI 10.2139/ssrn.4478305; Edwards B., NASCAR driver stuns racing world with a move learned from Nintendo GameCube; Etkina E., 2019, College physics: Explore and apply, V2nd; Fang X, 2024, Arxiv, DOI arXiv:2309.09825; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Gallegos IO, 2024, Arxiv, DOI arXiv:2309.00770; Geerling W., 2023, Am. Econ, V0, DOI [10.1177/05694345231169654, DOI 10.1177/05694345231169654]; Goodwins R., ChatGPT Has Mastered the Confidence Trick, and That's a Terrible Look for AI; Gregorcic Bor, 2023, Physics Education, DOI 10.1088/1361-6552/acc299; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Hendrycks Dan, 2021, arXiv; HESTENES D, 1992, AM J PHYS, V60, P732, DOI 10.1119/1.17080; Hestenes D., 1992, PHYS TEACH, V30, P141, DOI [DOI 10.1119/1.2343497, 10.1119/1.2343497]; Holmes W., 2019, Promises and Implications for Teaching and Learning.; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kahneman D., 2011, THINKING FAST SLOW; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khandelwal K, 2023, Arxiv, DOI arXiv:2309.08573; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kortemeyer G, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010132; Kotek Hadas, 2023, CI '23: Proceedings of The ACM Collective Intelligence Conference, P12, DOI 10.1145/3582269.3615599; Krupp L, 2023, Arxiv, DOI arXiv:2309.03087; Liang T, 2024, Arxiv, DOI arXiv:2305.19118; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Long JY, 2023, Arxiv, DOI arXiv:2305.08291; Mhlanga D., 2023, ChatGPT in Education: Exploring Opportunities for Emerging Economies to Improve Education with ChatGPT, DOI [10.2139/ssrn.4355758, DOI 10.2139/SSRN.4355758]; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Newton P M., ChatGPT Performance on MCQ Exams in Higher Education. A Pragmatic Scoping Review; Nguyen Sydney., 2023, Proceedings of the Society for Computation in Linguistics, V6, DOI [https://doi.org/10.7275/xdf4-mh72, DOI 10.7275/XDF4-MH72]; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Opara E., 2023, Glob Acad J Humanit Soc Sci, V5, P33, DOI DOI 10.36348/GAJHSS.2023.V05I02.001; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Petroni F., 2020, arXiv; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; REDISH EF, 1994, AM J PHYS, V62, P796, DOI 10.1119/1.17461; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [10.37074/jalt.2023.6.1, DOI 10.37074/JALT.2023.6.1]; Salah M, 2023, CURR PSYCHOL, DOI 10.1007/s12144-023-04989-0; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Shi F, 2023, Arxiv, DOI arXiv:2302.00093; Shoufan A, 2023, IEEE ACCESS, V11, P38805, DOI 10.1109/ACCESS.2023.3268224; Talanquer V, 2023, J CHEM EDUC, V100, P2821, DOI 10.1021/acs.jchemed.3c00472; Tate T., 2023, Educational Research and AI-Generated Writing: Confronting the Coming Tsunami, DOI DOI 10.35542/OSF.IO/4MEC3; Taylor R., 1980, The computer in the school: tutor, tool, tutee; Thakur V, 2023, Arxiv, DOI arXiv:2307.09162; Ungdomsbarometern, 2022, Back2School 2023; Valmeekam K, 2023, Arxiv, DOI [arXiv:2206.10498, 10.48550/arXiv.2206.10498]; Vasconcelos M.A.R., 2023, Eurasia J. Math. Sci. Technol. Educ, V19, pem2296, DOI [10.29333/ejmste/13313, DOI 10.29333/EJMSTE/13313]; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Wei J., 2022, Transactions on Machine Learning Research, P2835; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Welding L., Half of College Students Say Using AI on Schoolwork Is Cheating or Plagiarism; West CG, 2023, Arxiv, DOI [arXiv:2303.17012, 10.48550/arXiv.2303.17012]; West CG, 2023, Arxiv, DOI arXiv:2303.01067; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wolfram S., 2023, Stephen Wolfram Writings; Xu BF, 2023, Arxiv, DOI arXiv:2305.14688; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yeadon Will, 2023, Physics Education, DOI 10.1088/1361-6552/acc5cf; Yeadon W, 2023, Arxiv, DOI arXiv:2309.05163; Yeadon W, 2023, Arxiv, DOI arXiv:2306.15609; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	98	4	4	79	79	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0143-0807	1361-6404		EUR J PHYS	Eur. J. Phys.	MAR 1	2024	45	2							025701	10.1088/1361-6404/ad1420	http://dx.doi.org/10.1088/1361-6404/ad1420			35	Education, Scientific Disciplines; Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Physics	GC9I4		hybrid, Green Submitted, Green Published			2024-07-03	WOS:001150579000001
C	Buck, C; Heafield, K; van Ooyen, B		Calzolari, N; Choukri, K; Declerck, T; Loftsson, H; Maegaard, B; Mariani, J; Moreno, A; Odijk, J; Piperidis, S		Buck, Christian; Heafield, Kenneth; van Ooyen, Bas			<i>N</i>-gram Counts and Language Models from the Common Crawl	LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION			English	Proceedings Paper	9th International Conference on Language Resources and Evaluation (LREC)	MAY 26-31, 2014	Reykjavik, ICELAND	Holmes Semant Solut, European Media Lab GmBH, EML, VoiceBox Technologies, KDICTIONARIES		web corpora; language models; multilingual		We contribute 5-gram counts and language models trained on the Common Crawl corpus, a collection over 9 billion web pages. This release improves upon the Google n-gram counts in two key ways: the inclusion of low-count entries and deduplication to reduce boilerplate. By preserving singletons, we were able to use Kneser-Ney smoothing to build large language models. This paper describes how the corpus was processed with emphasis on the problems that arise in working with data at this scale. Our unpruned Kneser-Ney English 5-gram language model, built on 975 billion deduplicated tokens, contains over 500 billion unique n-grams. We show gains of 0.5-1.4 BLEU by using large language models to translate into various languages.	[Buck, Christian] Univ Edinburgh, Edinburgh, Midlothian, Scotland; [Heafield, Kenneth] Stanford Univ, Stanford, CA 94305 USA; [van Ooyen, Bas] Owlin BV, Utrecht, Netherlands	University of Edinburgh; Stanford University	Buck, C (corresponding author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.	christian.buck@ed.ac.uk; heafield@cs.stanford.edu; bas@owlin.com		Heafield, Kenneth/0000-0002-6344-9927				[Anonymous], 2013, ACL; [Anonymous], P 15 C EUR CHAPT ACL; [Anonymous], P 10 INT WORKSH SPOK; [Anonymous], 2005, P MACHINE TRANSLATIO; [Anonymous], 2007, P ASS COMP LING PRAG; [Anonymous], P INT BRISB AUSTR; [Anonymous], P 7 INT WORKSH SPOK; Bergsma S, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P865; Bojar Ondej, 2013, P 8 WORKSH STAT MACH, P1; Brants T., 2006, GOOGLE WEB 1T 5 GRAM; Brants T., 2007, P 2007 JOINT C EMP M, P858; Chelba Ciprian, 2013, EMPIRICAL EXPLORATIO, P197; Chen Stanley, 1998, TR1098 HARV U; Durrani N, 2013, P 51 ANN M ASS COMP; Guthrie D., 2010, P EMNLP 2010 LOS ANG; Huang L, 2007, P 45 ANN M ASS COMPU, V45, P144; KNESER R, 1995, INT CONF ACOUST SPEE, P181, DOI 10.1109/ICASSP.1995.479394; Koehn Philipp, 2007, P 2007 JOINT C EMP M, P868; Kumar S, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P169; Lin Dekang, 2010, 2009 JHU CLSP WORKSH; Lin Dorlene, 2013, COMMUNICATION; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Parker R., 2011, ENGLISH GIGAWORD; Smith Jason, 2013, P ACL; Wang K., 2010, PROC C N AM CHAPTER, P45	25	61	77	0	2	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			978-2-9517408-8-4				2014							3579	3584						6	Linguistics; Language & Linguistics	Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Linguistics	BC8FH					2024-07-03	WOS:000355611005033
C	Töberg, JP; Cimiano, P			IEEE Comp Soc	Toberg, Jan-Philipp; Cimiano, Philipp			Generation of Robot Manipulation Plans Using Generative Large Language Models	2023 SEVENTH IEEE INTERNATIONAL CONFERENCE ON ROBOTIC COMPUTING, IRC 2023			English	Proceedings Paper	7th IEEE International Conference on Robotic Computing (IRC)	DEC 11-13, 2023	Laguna Hills, CA	IEEE, IEEE Comp Soc		Robot Plan Generation; Large Language Models; Action Similarity; CRAM; GPT		Designing plans that allow robots to carry out actions such as grasping an object or cutting a fruit is a time-consuming activity requiring specific skills and knowledge. The recent success of Generative Large Language Models (LLMs) has opened new avenues for code generation. In order to evaluate the ability of LLMs to generate code representing manipulation plans, we carry out experiments with different LLMs in the CRAM framework. In our experimental framework, we ask an LLM such as ChatGPT or GPT-4 to generate a plan for a specific target action given the plan (called designator within CRAM) for a given reference action as an example. We evaluate the generated designators against a ground truth designator using machine translation and code generation metrics, as well as assessing whether they compile. We find that GPT-4 slightly outperforms ChatGPT, but both models achieve a solid performance above all evaluated metrics. However, only similar to 36% of the generated designators compile successfully. In addition, we assess how the chosen reference action influences the code generation quality as well as the compilation success. Unexpectedly, the action similarity negatively correlates with compilation success. With respect to the metrics, we obtain either a positive or negative correlation depending on the used model. Finally, we describe our attempt to use ChatGPT in an interactive fashion to incrementally refine the initially generated designator. On the basis of our observations we conclude that the behaviour of ChatGPT is not reliable and robust enough to support the incremental refinement of a designator.	[Toberg, Jan-Philipp; Cimiano, Philipp] Univ Bielefeld, Ctr Cognit Interact Technol CITEC, Bielefeld, Germany; [Toberg, Jan-Philipp; Cimiano, Philipp] Univ Bielefeld, Joint Res Ctr Cooperat & Cognit Enabled CoAI JRC, Bielefeld, Germany	University of Bielefeld; University of Bielefeld	Töberg, JP (corresponding author), Univ Bielefeld, Ctr Cognit Interact Technol CITEC, Bielefeld, Germany.; Töberg, JP (corresponding author), Univ Bielefeld, Joint Res Ctr Cooperat & Cognit Enabled CoAI JRC, Bielefeld, Germany.	jtoeberg@techfak.uni-bielefeld.de; cimiano@techfak.uni-bielefeld.de		Toberg, Jan-Philipp/0000-0003-0434-6781; Cimiano, Philipp/0000-0002-4771-441X				Beetz M, 2010, IEEE INT C INT ROBOT, P1012, DOI 10.1109/IROS.2010.5650146; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; CaoandC Y., 2023, AAAI 2023 SPRING S C; Chen L., 2023, How is ChatGPT's behavior changing over time?; Dech J., 2023, PyCRAM; Evtikhiev M, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111741; Holter O. M., 2023, 4 C LANGUAGE DATA KN; Huang WL, 2022, PR MACH LEARN RES; Kotseruba I, 2020, ARTIF INTELL REV, V53, P17, DOI 10.1007/s10462-018-9646-y; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu XD, 2020, COMPUT METHOD BIOMEC, V23, P1102, DOI 10.1080/10255842.2020.1789119; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; OpenAI, 2023, GPT-4 Technical Report; Pallagani V., 2023, Understanding the Capabilities of Large Language Models for Automated Planning; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Wingfield C, 2023, BEHAV RES METHODS, V55, P3416, DOI 10.3758/s13428-022-01965-7; Wray R. E., 2021, 9 ANN C ADV COGNITIV, P1; WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133; You H., 2023, RobotEnabled Construction Assembly with Automated Sequence Planning based on ChatGPT: RoboGPT; Zhou S., 2023, DEEP LEARNING CODE D	25	0	0	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-9574-7				2023							190	197		10.1109/IRC59093.2023.00039	http://dx.doi.org/10.1109/IRC59093.2023.00039			8	Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW7SR					2024-07-03	WOS:001195993100033
J	Pressman, SM; Borna, S; Gomez-Cabello, CA; Haider, SA; Haider, CR; Forte, AJ				Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed Ali; Haider, Clifton R.; Forte, Antonio Jorge			Clinical and Surgical Applications of Large Language Models: A Systematic Review	JOURNAL OF CLINICAL MEDICINE			English	Review						artificial intelligence (AI); ChatGPT; diagnosis; management; deep learning; machine learning; surgical specialties	ARTIFICIAL-INTELLIGENCE; HEALTH-CARE; CHATGPT; MEDICINE; SURGERY; FUTURE	Background: Large language models (LLMs) represent a recent advancement in artificial intelligence with medical applications across various healthcare domains. The objective of this review is to highlight how LLMs can be utilized by clinicians and surgeons in their everyday practice. Methods: A systematic review was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Six databases were searched to identify relevant articles. Eligibility criteria emphasized articles focused primarily on clinical and surgical applications of LLMs. Results: The literature search yielded 333 results, with 34 meeting eligibility criteria. All articles were from 2023. There were 14 original research articles, four letters, one interview, and 15 review articles. These articles covered a wide variety of medical specialties, including various surgical subspecialties. Conclusions: LLMs have the potential to enhance healthcare delivery. In clinical settings, LLMs can assist in diagnosis, treatment guidance, patient triage, physician knowledge augmentation, and administrative tasks. In surgical settings, LLMs can assist surgeons with documentation, surgical planning, and intraoperative guidance. However, addressing their limitations and concerns, particularly those related to accuracy and biases, is crucial. LLMs should be viewed as tools to complement, not replace, the expertise of healthcare professionals.	[Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed Ali; Forte, Antonio Jorge] Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA; [Haider, Clifton R.] Mayo Clin, Dept Physiol & Biomed Engn, Rochester, MN 55905 USA; [Forte, Antonio Jorge] Ctr Digital Hlth, Mayo Clin, Rochester, MN 55905 USA	Mayo Clinic; Mayo Clinic; Mayo Clinic	Forte, AJ (corresponding author), Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA.; Forte, AJ (corresponding author), Ctr Digital Hlth, Mayo Clin, Rochester, MN 55905 USA.	ajvforte@yahoo.com.br	Forte, Antonio/I-2970-2019	Forte, Antonio/0000-0003-2004-7538; Gomez Cabello, Cesar Abraham/0009-0008-0603-3192; Pressman, Sophia/0009-0000-0398-8024; Borna, Sahar/0000-0002-7845-7356				Abi-Rafeh J, 2024, AESTHET SURG J, V44, P329, DOI 10.1093/asj/sjad260; Ali MJ, 2023, OPHTHAL PLAST RECONS, V39, P221, DOI 10.1097/IOP.0000000000002418; Argentiero A, 2022, J CLIN MED, V11, DOI 10.3390/jcm11102866; Asch D.A., 2023, NEJM Cat, V4, P1, DOI DOI 10.1056/CAT.23.0043; Atkinson D., 2023, Contemp. Read. Law Soc. Justice, V15, P134, DOI [10.22381/CRLSJ15120238, DOI 10.22381/CRLSJ15120238]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Tran BX, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16152699; Bohr A, 2020, Artificial Intelligence in Healthcare, P25, DOI [DOI 10.1016/B978-0-12-818438-7.00002-2, 10.1016/B978-0-12-818438-7.00002-2]; Bugaj M., 2023, Contemp. Read. Law Soc. Justice, V15, P9, DOI [10.22381/CRLSJ15120231, DOI 10.22381/CRLSJ15120231]; Cadamuro J, 2023, CLIN CHEM LAB MED, V61, P1158, DOI 10.1515/cclm-2023-0355; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Chen TC, 2023, WORLD NEUROSURG, V179, pE342, DOI 10.1016/j.wneu.2023.08.088; Cheng KM, 2023, ANN BIOMED ENG, V51, P1130, DOI 10.1007/s10439-023-03203-3; Chiesa-Estomba CM, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08104-8; Cirkovic A, 2023, JMIR FORM RES, V7, DOI 10.2196/51798; Cresswell Aynsley, 2015, BMJ Qual Improv Rep, V4, DOI 10.1136/bmjquality.u207936.w3197; Daher Mohammad, 2023, JSES Int, V7, P2534, DOI 10.1016/j.jseint.2023.07.018; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Duey AH, 2023, SPINE J, V23, P1684, DOI 10.1016/j.spinee.2023.07.015; Gala Dhir, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20156438; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Gengatharan D, 2024, CUREUS J MED SCIENCE, V16, DOI 10.7759/cureus.54858; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Grupac M., 2023, Contemp. Read. Law Soc. Justice, V15, P46, DOI [10.22381/CRLSJ15120233, DOI 10.22381/CRLSJ15120233]; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Jin Ziwen, 2023, 2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P1755, DOI 10.1109/ICIBA56860.2023.10165540; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Manning C., Artificial Intelligence Definitions; Mert S, 2024, ARCH ORTHOP TRAUM SU, V144, P2461, DOI 10.1007/s00402-024-05298-2; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Mufti F., 2023, Southeast Eur. J. Soft Comput, V12, P13, DOI [10.21533/scjournal, DOI 10.21533/SCJOURNAL]; Najafali Daniel, 2024, Eplasty, V24, pe13; O'Hern K, 2023, JAAD INT, V12, P168, DOI 10.1016/j.jdin.2023.06.002; OpenAi, ChatGPT; Ozsahin DU, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010045; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n160; Pressman SM, 2024, J CLIN MED, V13, DOI 10.3390/jcm13102832; Pressman SM, 2024, HEALTHCARE-BASEL, V12, DOI 10.3390/healthcare12080825; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Rajjoub R, 2024, GLOB SPINE J, V14, P998, DOI 10.1177/21925682231195783; Ravipati A, 2023, INT J DERMATOL, V62, pE547, DOI 10.1111/ijd.16746; Rizwan A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43106; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schukow C, 2024, ADV ANAT PATHOL, V31, P15, DOI 10.1097/PAP.0000000000000406; Sharma SC, 2023, INDIAN J PLAST SURG, V56, P320, DOI 10.1055/s-0043-1771514; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Srivastav S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41435; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; Vaira LA, 2024, OTOLARYNG HEAD NECK, V170, P1492, DOI 10.1002/ohn.489; Xiao DV, 2023, J PEDIATR SURG, V58, P2410, DOI 10.1016/j.jpedsurg.2023.07.008; Xv Y, 2023, WORLD J UROL, V41, P2569, DOI 10.1007/s00345-023-04539-0; Yin JM, 2021, J MED INTERNET RES, V23, DOI 10.2196/25759; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z; Zhang Y., 2023, Gastroenterol. Endosc, V1, P139, DOI [10.1016/j.gande.2023.07.002, DOI 10.1016/J.GANDE.2023.07.002]; Zhang YM, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020237	61	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-0383		J CLIN MED	J. Clin. Med.	JUN	2024	13	11							3041	10.3390/jcm13113041	http://dx.doi.org/10.3390/jcm13113041			24	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	UA8S3	38892752	gold			2024-07-03	WOS:001245439000001
C	Yang, V; Srivastava, A; Etesam, Y; Zhang, CX; Lim, A			IEEE	Yang, Vera; Srivastava, Archita; Etesam, Yasaman; Zhang, Chuxuan; Lim, Angelica			Contextual Emotion Estimation from Image Captions	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, ACII	International Conference on Affective Computing and Intelligent Interaction		English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			Large language model; emotion estimation; image captioning; context; ChatGPT; GPT-3.5		Emotion estimation in images is a challenging task, typically using computer vision methods to directly estimate people's emotions using face, body pose and contextual cues. In this paper, we explore whether Large Language Models (LLMs) can support the contextual emotion estimation task, by first captioning images, then using an LLM for inference. First, we must understand: how well do LLMs perceive human emotions? And which parts of the information enable them to determine emotions? One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. Towards this goal, we propose a set of natural language descriptors for faces, bodies, interactions, and environments. We use them to manually generate captions and emotion annotations for a subset of 331 images from the EMOTIC dataset. These captions offer an interpretable representation for emotion estimation, towards understanding how elements of a scene affect emotion perception in LLMs and beyond. Secondly, we test the capability of a large language model to infer an emotion from the resulting image captions. We find that GPT-3.5, specifically the text-davinci-003 model, provides surprisingly reasonable emotion predictions consistent with human annotations, but accuracy can depend on the emotion concept. Overall, the results suggest promise in the image captioning and LLM approach.	[Yang, Vera; Srivastava, Archita; Etesam, Yasaman; Zhang, Chuxuan; Lim, Angelica] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada	Simon Fraser University	Yang, V (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC, Canada.	veray@sfu.ca; archita_srivastava@sfu.ca; yetesam@sfu.ca; chuxuan_zhang@sfu.ca; angelica@sfu.ca			NSERC [06908-2019]	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was supported by NSERC Discovery Grant 06908-2019.	Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Barrett L.F., 2017, How Emotions Are Made: The Secret Life of the Brain; Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930; Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Calbi M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01684; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dudzik Bernd, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P153, DOI 10.1145/3382507.3418814; Hess U, 2015, IEEE INT CONF AUTOMA; Kosti R, 2020, IEEE T PATTERN ANAL, V42, P2755, DOI 10.1109/TPAMI.2019.2916866; Le N, 2022, NEURAL COMPUT APPL, V34, P21625, DOI 10.1007/s00521-021-06778-x; Mittal T., 2020, P 2020 IEEE CVF C CO, p14 234; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Puglisi B., 2019, The emotion thesaurus: A writer's guide to character expression, V1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Schindler K, 2008, NEURAL NETWORKS, V21, P1238, DOI 10.1016/j.neunet.2008.05.003; Shin S, 2022, COMPANION PUBLICATION OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P127, DOI 10.1145/3536220.3558036; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang ZL, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103679	22	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2156-8103		979-8-3503-2743-4	INT CONF AFFECT			2023										10.1109/ACII59096.2023.10388198	http://dx.doi.org/10.1109/ACII59096.2023.10388198			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IH		Green Submitted			2024-07-03	WOS:001161369900041
J	De Angelis, L; Baglivo, F; Arzilli, G; Privitera, GP; Ferragina, P; Tozzi, AE; Rizzo, C				De Angelis, Luigi; Baglivo, Francesco; Arzilli, Guglielmo; Privitera, Gaetano Pierpaolo; Ferragina, Paolo; Tozzi, Alberto Eugenio; Rizzo, Caterina			ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health	FRONTIERS IN PUBLIC HEALTH			English	Article						artificial intelligence; natural language processing; large language models; ChatGPT; public health; infodemic	ARTIFICIAL-INTELLIGENCE; BENEFITS	Large Language Models (LLMs) have recently gathered attention with the release of ChatGPT, a user-centered chatbot released by OpenAI. In this perspective article, we retrace the evolution of LLMs to understand the revolution brought by ChatGPT in the artificial intelligence (AI) field.The opportunities offered by LLMs in supporting scientific research are multiple and various models have already been tested in Natural Language Processing (NLP) tasks in this domain.The impact of ChatGPT has been huge for the general public and the research community, with many authors using the chatbot to write part of their articles and some papers even listing ChatGPT as an author. Alarming ethical and practical challenges emerge from the use of LLMs, particularly in the medical field for the potential impact on public health. Infodemic is a trending topic in public health and the ability of LLMs to rapidly produce vast amounts of text could leverage misinformation spread at an unprecedented scale, this could create an "AI-driven infodemic," a novel public health threat. Policies to contrast this phenomenon need to be rapidly elaborated, the inability to accurately detect artificial-intelligence-produced text is an unresolved issue.	[De Angelis, Luigi; Baglivo, Francesco; Arzilli, Guglielmo; Privitera, Gaetano Pierpaolo; Rizzo, Caterina] Univ Pisa, Dept Translat Res & New Technol Med & Surg, Pisa, Italy; [Privitera, Gaetano Pierpaolo] Natl Inst Hlth, Training Off, Rome, Italy; [Ferragina, Paolo] Univ Pisa, Dept Comp Sci, Pisa, Italy; [Tozzi, Alberto Eugenio] Bambino Gesu Pediat Hosp, Predict & Prevent Med Res Unit, Fetal Neonatal & Cardiol Sci Res Area, IRCCS, Rome, Italy	University of Pisa; Istituto Superiore di Sanita (ISS); University of Pisa; IRCCS Bambino Gesu	Arzilli, G (corresponding author), Univ Pisa, Dept Translat Res & New Technol Med & Surg, Pisa, Italy.	g.arzilli3@studenti.unipi.it	Tozzi, Alberto Eugenio/F-9494-2012; Rizzo, Caterina/H-4092-2012; Arzilli, Guglielmo/JDW-2714-2023	Rizzo, Caterina/0000-0002-5583-7508; De Angelis, Luigi/0009-0005-6136-6596; Baglivo, Francesco/0000-0001-9391-7966; Arzilli, Guglielmo/0000-0003-1258-1650				Becker BA, 2022, Arxiv, DOI arXiv:2212.01020; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2020, LANCET INFECT DIS, V20, P875, DOI 10.1016/S1473-3099(20)30565-X; [Anonymous], EVERYONES HAVING FIE; [Anonymous], BBC NEWS; [Anonymous], STANFORD CRFM INTRO; [Anonymous], CHATGPT OPT LANG MOD; [Anonymous], ELSEVIER DECLARATION; [Anonymous], VERGE; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Batra H., 2021, 9 INT C REL INF TECH; Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bornmann L, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-021-00903-w; Briand SC, 2021, CELL, V184, P6010, DOI 10.1016/j.cell.2021.10.031; Can AI., I TRIED 3 ONLINE TOO; Casigliani V, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m2672; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chen M., 2021, EVALUATING LARGE LAN; Chen Y., 2022, Transformers go for the lols: Generating (humourous) titles from scientific abstracts end-to-end; Cinelli M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73510-5; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Else H, 2020, NATURE, V588, P553, DOI 10.1038/d41586-020-03564-y; Extance A, 2018, NATURE, V561, P273, DOI 10.1038/d41586-018-06617-5; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Flanagin A, 2020, JAMA-J AM MED ASSOC, V324, P1840, DOI 10.1001/jama.2020.20674; Fraser N, 2021, PLOS BIOL, V19, DOI 10.1371/journal.pbio.3000959; Gendron Y, 2022, CRIT PERSPECT ACCOUN, V87, DOI 10.1016/j.cpa.2021.102411; Gisondi MA, 2022, J MED INTERNET RES, V24, DOI 10.2196/35552; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Grudniewicz A, 2019, NATURE, V576, P210, DOI 10.1038/d41586-019-03759-y; Gupta Anchal, 2022, 2022 6th International Conference on Intelligent Computing and Control Systems (ICICCS), P1625, DOI 10.1109/ICICCS53718.2022.9788271; Hopkins J., 2008, BMJ, V336, DOI [10.1136/bmj.39553.506597.DB, DOI 10.1136/BMJ.39553.506597.DB]; Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062; Kasirzadeh A, 2022, Arxiv, DOI arXiv:2209.00731; Keya AJ, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178398; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kung TH, 2022, medRxiv, DOI [10.1101/2022.12.19.22283643, 10.1101/2022.12.19.22283643v2, DOI 10.1101/2022.12.19.22283643V2, 10.1101/2022.12.19.22283643, DOI 10.1101/2022.12.19.22283643]; Langguth J, 2021, FRONT COMMUN, V6, DOI 10.3389/fcomm.2021.632317; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Markov T, 2022, Arxiv, DOI arXiv:2208.03274; McBride E, 2021, BRIT J HEALTH PSYCH, V26, P259, DOI 10.1111/bjhp.12520; McGufe K, 2020, arXiv; Moreno-Garcia CF., 2023, Decis Anal, V6, DOI [10.1016/j.dajour.2023.100162, DOI 10.1016/J.DAJOUR.2023.100162]; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Oniani D., 2020, P 11 ACM INT C BIOIN, P1; Ontoum S., 2022, AUTOMATIC TEXT SUMMA, P1; Openai A. R., IMPROVING LANGUAGE U; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Raza S, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04751-6; Rothkopf David J., 2003, The Washington Post; Schwartz IS, 2022, LANCET REG HEALTH-AM, V11, DOI 10.1016/j.lana.2022.100268; Sear RF., 2021, AAIML, V01, P191, DOI [10.54364/AAIML.2021.1112, DOI 10.54364/AAIML.2021.1112]; Shams R, 2014, Arxiv, DOI arXiv:1409.7612; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tuccori M, 2020, DRUG SAFETY, V43, P699, DOI 10.1007/s40264-020-00965-w; Vaccari C, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120903408; Vaswani A, 2017, ADV NEUR IN, V30; Vinuesa R, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-14108-y; WHO, PUBL HLTH RES AG MAN; Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X	70	123	124	139	251	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-2565		FRONT PUBLIC HEALTH	Front. Public Health	APR 25	2023	11								1166120	10.3389/fpubh.2023.1166120	http://dx.doi.org/10.3389/fpubh.2023.1166120			8	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	F5QK1	37181697	Green Published, gold			2024-07-03	WOS:000982888300001
C	Belyaeva, A; Cosentino, J; Hormozdiari, F; Eswaran, K; Shetty, S; Corrado, G; Carroll, A; McLean, CY; Furlotte, NA		Maier, AK; Schnabel, JA; Tiwari, P; Stegle, O		Belyaeva, Anastasiya; Cosentino, Justin; Hormozdiari, Farhad; Eswaran, Krish; Shetty, Shravya; Corrado, Greg; Carroll, Andrew; McLean, Cory Y.; Furlotte, Nicholas A.			Multimodal LLMs for Health Grounded in Individual-Specific Data	MACHINE LEARNING FOR MULTIMODAL HEALTHCARE DATA, ML4MHD 2023	Lecture Notes in Computer Science		English	Proceedings Paper	1st International Workshop on Machine Learning for Multimodal Healthcare Data (ML4MHD)	JUL 29, 2023	Honolulu, HI			Multimodal Large Language Models; Health; UK Biobank		Foundation large language models (LLMs) have shown an impressive ability to solve tasks across a wide range of fields including health. To effectively solve personalized health tasks, LLMs need the ability to ingest a diversity of data modalities that are relevant to an individual's health status. In this paper, we take a step towards creating multimodal LLMs for health that are grounded in individual-specific data by developing a framework (HeLM: Health Large Language Model for Multimodal Understanding) that enables LLMs to use high-dimensional clinical modalities to estimate underlying disease risk. HeLM encodes complex data modalities by learning an encoder that maps them into the LLM's token embedding space and for simple modalities like tabular data by serializing the data into text. Using data from the UK Biobank, we show that HeLM can effectively use demographic and clinical features in addition to high-dimensional time-series data to estimate disease risk. For example, HeLM achieves an AUROC of 0.75 for asthma prediction when combining tabular and spirogram data modalities compared with 0.49 when only using tabular data. Overall, we find that HeLM outperforms or performs at parity with classical machine learning approaches across a selection of eight binary traits. Furthermore, we investigate the downstream uses of this model such as its generalizability to out-of-distribution traits and its ability to power conversations around individual health and wellness.	[Belyaeva, Anastasiya; Cosentino, Justin; Eswaran, Krish; Shetty, Shravya; Corrado, Greg; Carroll, Andrew; Furlotte, Nicholas A.] Google Res, San Francisco, CA 94105 USA; [Hormozdiari, Farhad; McLean, Cory Y.] Google Res, Cambridge, MA 02142 USA	Google Incorporated; Google Incorporated	Furlotte, NA (corresponding author), Google Res, San Francisco, CA 94105 USA.	nickfurlotte@google.com						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Alipanahi B, 2021, AM J HUM GENET, V108, P1217, DOI 10.1016/j.ajhg.2021.05.004; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bycroft C, 2018, NATURE, V562, P203, DOI 10.1038/s41586-018-0579-z; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cosentino J, 2023, NAT GENET, V55, P787, DOI 10.1038/s41588-023-01372-4; Diaz-Papkovich A, 2019, PLOS GENET, V15, DOI 10.1371/journal.pgen.1008432; Dinh T., 2022, ADV NEURAL INFORM PR, V35, P11763; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Girdhar R, 2023, Arxiv, DOI arXiv:2305.05665; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065; Jia C, 2021, PR MACH LEARN RES, V139; Kirk HR, 2023, Arxiv, DOI arXiv:2303.05453; Kline A, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00712-8; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Lu JS, 2022, Arxiv, DOI arXiv:2206.08916; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Rabe KF, 2007, AM J RESP CRIT CARE, V176, P532, DOI 10.1164/rccm.200703-456SO; Radford A, 2021, PR MACH LEARN RES, V139; Recht B, 2018, Arxiv, DOI arXiv:1806.00451; Sakornsakolpat P, 2019, NAT GENET, V51, P494, DOI 10.1038/s41588-018-0342-2; Salemi A, 2024, Arxiv, DOI arXiv:2304.11406; Shrine N, 2019, NAT GENET, V51, P481, DOI 10.1038/s41588-018-0321-7; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Sontag D, 2023, INT C ARTIFICIAL INT, P5549; Steinberg E, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103637; Vokinger KN, 2021, COMMUN MED-LONDON, V1, DOI 10.1038/s43856-021-00028-w; Wang YH, 2024, Arxiv, DOI [arXiv:2211.00635, DOI 10.48550/ARXIV.2211.00635]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Yang KD, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20249-2; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yu JH, 2022, Arxiv, DOI arXiv:2205.01917; Zhou HY, 2022, NAT MACH INTELL, V4, P32, DOI 10.1038/s42256-021-00425-9	39	0	0	7	7	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-47678-5; 978-3-031-47679-2	LECT NOTES COMPUT SC			2024	14315						86	102		10.1007/978-3-031-47679-2_7	http://dx.doi.org/10.1007/978-3-031-47679-2_7			17	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering; Radiology, Nuclear Medicine & Medical Imaging	BW4HS		Green Submitted			2024-07-03	WOS:001148056600007
C	Gadiraju, V; Kane, S; Dev, S; Taylor, A; Wang, D; Denton, E; Brewer, R			ASSOC COMPUTING MACHINERY	Gadiraju, Vinitha; Kane, Shaun; Dev, Sunipa; Taylor, Alex; Wang, Ding; Denton, Emily; Brewer, Robin			"I wouldn't say offensive but...": Disability-Centered Perspectives on Large Language Models	PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023			English	Proceedings Paper	6th ACM Conference on Fairness, Accountability, and Transparency (FAccT)	JUN 12-15, 2023	Chicago, IL	Assoc Comp Machinery		data annotation; large language models; algorithmic harms; disability representation; qualitative; artificial intelligence; dialog model; chatbot		Large language models (LLMs) trained on real-world data can inadvertently reflect harmful societal biases, particularly toward historically marginalized communities. While previouswork has primarily focused on harms related to age and race, emerging research has shown that biases toward disabled communities exist. This study extends prior work exploring the existence of harms by identifying categories of LLM-perpetuated harms toward the disability community. We conducted 19 focus groups, during which 56 participants with disabilities probed a dialog model about disability and discussed and annotated its responses. Participants rarely characterized model outputs as blatantly offensive or toxic. Instead, participants used nuanced language to detail how the dialog model mirrored subtle yet harmful stereotypes they encountered in their lives and dominant media, e.g., inspiration porn and able-bodied saviors. Participants often implicated training data as a cause for these stereotypes and recommended training the model on diverse identities from disability-positive resources. Our discussion further explores representative data strategies to mitigate harm related to different communities through annotation co-design with ML researchers and developers.	[Gadiraju, Vinitha] Univ Colorado Boulder, Boulder, CO 80309 USA; [Kane, Shaun] Google Res, Boulder, CO USA; [Dev, Sunipa] Google Res, San Francisco, CA USA; [Taylor, Alex] City Univ London, London, England; [Wang, Ding] Google Res, Atlanta, GA USA; [Denton, Emily] Google Res, New York, NY USA; [Brewer, Robin] Univ Michigan, Ann Arbor, MI USA	University of Colorado System; University of Colorado Boulder; Google Incorporated; Google Incorporated; City University London; Google Incorporated; Google Incorporated; University of Michigan System; University of Michigan	Gadiraju, V (corresponding author), Univ Colorado Boulder, Boulder, CO 80309 USA.	vinitha.gadiraju@colorado.edu; shaunkane@google.com; sunipadev@google.com; alex.taylor@city.ac.uk; drdw@google.com; dentone@google.com; rnbrew@umich.edu	Taylor, Alex S/ABH-6436-2020	Taylor, Alex S/0000-0001-6311-3967; Brewer, Robin/0000-0003-3790-5834; Denton, Emily/0000-0003-4915-0512; Wang, Ding/0000-0002-5037-5017				Aflatoony Leila, 2020, PDC '20: Proceedings of the 16th Participatory Design Conference 2020 - Participation(s) Otherwise, P128, DOI 10.1145/3384772.3385158; Agaronnik ND, 2020, ARCH PHYS MED REHAB, V101, P1739, DOI 10.1016/j.apmr.2020.04.024; Ahn J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P533; Anhong Guo, 2020, ACM SIGACCESS Accessibility and Computing, DOI 10.1145/3386296.3386298; Ayers K. B., 2022, Redefining disability, P90; Barocas Aaron Shapiro Solon, 2017, P SIGCIS PHIL PA; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barton E., 2001, Embodied rhetorics: Disability in language and culture, P169; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berne P., 2018, WSQ, V46, P227, DOI [10.1353/wsq.2018.0003, DOI 10.1353/WSQ.2018.0003]; Birhane Abeba, 2022, P 2022 ACM C FAIRNES, DOI DOI 10.1145/3531146.3533157; Blodgett S.L., 2016, P EMNLP; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Boyatzis R., 1998, Transferring qualitative information", V1st; Braun V., 2012, Research designs: Quantitative, qualitative, neuropsychological and biological, V2, P57, DOI DOI 10.1037/13620-004(RESEARCH; Brewer R, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484507; Brisenden S., 1986, DISABILITY HANDICAP, V1, P173, DOI [10.1080/02674648666780171, DOI 10.1080/02674648666780171]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cohen Aaron Daniel, 2022, arXiv; Dev S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1968; Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659; Devlieger PJ, 1999, DISABIL REHABIL, V21, P346, DOI 10.1080/096382899297594; Oliva TD, 2021, SEX CULT, V25, P700, DOI 10.1007/s12119-020-09790-w; Diaz Mark, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2342, DOI 10.1145/3531146.3534647; Díaz M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173986; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Ferrigon Phillip, 2019, Journal of Teaching Disability Studies, V1; Foreman P, 2005, J INTELLECT DEV DIS, V30, P57, DOI 10.1080/13668250500033003; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Goyal Nitesh, 2022, P ACM C COMP SUPP CO; Grue J, 2016, DISABIL SOC, V31, P838, DOI 10.1080/09687599.2016.1205473; Guo Anhong, 2021, P 2021 CHI C HUM FAC, P1; Gurari D, 2019, PROC CVPR IEEE, P939, DOI 10.1109/CVPR.2019.00103; Haller B., 2016, Disability and Social Media, P63; Hanna A, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P501, DOI 10.1145/3351095.3372826; Huang PS, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P65; Hutchinson Ben, 2020, ACM SIGACCESS Accessibility and Computing, DOI 10.1145/3386296.3386305; Hutiri Wiebke Toussaint, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P230, DOI 10.1145/3531146.3533089; Kacorri H, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418026; Khandkar ShahedulHuq., 2009, Open coding, V23; Kiritchenko S, 2018, Arxiv, DOI [arXiv:1805.04508, DOI 10.48550/ARXIV.1805.04508]; Kivlichan Ian, 2021, P NEURIPS 2021 WORKS; Koenecke A, 2020, P NATL ACAD SCI USA, V117, P7684, DOI 10.1073/pnas.1915768117; Kong Youjin, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P485, DOI 10.1145/3531146.3533114; Krebs E., 2019, Disability Studies Quarterly, V39, DOI DOI 10.18061/DSQ.V39I3.6557; Li Tao, 2020, EMNLP; Luccioni A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P182; MacLeod H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5988, DOI 10.1145/3025453.3025814; Magee L, 2021, Arxiv, DOI arXiv:2107.07691; Magnus E, 2014, SCAND J DISABIL RES, V16, P316, DOI 10.1080/15017419.2012.761156; Mankoff J, 2010, ASSETS 2010: PROCEEDINGS OF THE 12TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P3; Marks D, 1997, DISABIL REHABIL, V19, P85, DOI 10.3109/09638289709166831; Mengesha Z, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.725911; Miceli Milagros, 2022, Proceedings of the ACM on Human-Computer Interaction, V6, DOI 10.1145/3492853; Monteleone R, 2018, TECHNOL INNOV, V20, P133, DOI 10.21300/20.1-2.2018.133; Morris MR, 2020, COMMUN ACM, V63, P35, DOI 10.1145/3356727; Davani AM, 2020, Arxiv, DOI arXiv:2010.12779; Nakamura K, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P1, DOI 10.1145/3308561.3353812; Panchanathan S, 2015, UNIVERSAL ACCESS INF, V14, P415, DOI 10.1007/s10209-014-0369-9; Park JS, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P52, DOI 10.1145/3442188.3445870; Paullada A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100336; Peers D, 2014, ADAPT PHYS ACT Q, V31, P265, DOI 10.1123/apaq.2013-0091; Peng H, 2019, Arxiv, DOI arXiv:1909.02134; Quintero C, 2022, DISABIL REHABIL-ASSI, V17, P369, DOI [10.1080/17483107.2020.1785564, 10.1145/3439231.3439234]; Ripat J.D., 2011, TECHNOL DISABIL, V23, P87, DOI [10.3233/TAD-2011-0315, DOI 10.3233/TAD-2011-0315]; Sarmiento-Pelayo Martha Patricia, 2015, rev.fac.med., V63, P149; Shakespeare T., 2006, DISABILITY STUDIES R, V2, P197, DOI DOI 10.2307/20141862; Sheng EM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4275; Spiel K, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375150; Tatman R, 2017, INTERSPEECH, P934, DOI 10.21437/Interspeech.2017-1746; Theodorou Lida, 2021, 23 INT ACM SIG ACCES, P1; Treviranus Jutta, 2017, Global Journal of Intellectual & Developmental Disabilities, V1, DOI [10.19080/GJIDD.2017.01.555560, DOI 10.19080/GJIDD.2017.01.555560]; Trewin S, 2018, Arxiv, DOI arXiv:1811.10670; Venkit P., 2022, P 29 INT C COMP LING, P1324; Webster M., 2018, Transactions of the Association for Computational Linguistics, V6, P605, DOI 10.1162/tacla00240.42; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Wendell S, 1989, Hypatia, V4, P104; Whittaker M., 2019, Report; Young S., 2012, I'm not your inspiration, thank you very much; Zellers R, 2020, Arxiv, DOI arXiv:1905.12616; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	83	5	5	5	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-7252-7				2023							205	216		10.1145/3593013.3593989	http://dx.doi.org/10.1145/3593013.3593989			12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Ethics; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BV6VC		Bronze			2024-07-03	WOS:001062819300020
J	Mehandru, N; Miao, BY; Almaraz, ER; Sushil, M; Butte, AJ; Alaa, A				Mehandru, Nikita; Miao, Brenda Y.; Almaraz, Eduardo Rodriguez; Sushil, Madhumita; Butte, Atul J.; Alaa, Ahmed			Evaluating large language models as agents in the clinic	NPJ DIGITAL MEDICINE			English	Article								Recent developments in large language models (LLMs) have unlocked opportunities for healthcare, from information synthesis to clinical decision support. These LLMs are not just capable of modeling language, but can also act as intelligent "agents" that interact with stakeholders in open-ended conversations and even influence clinical decision-making. Rather than relying on benchmarks that measure a model's ability to process clinical data or answer standardized test questions, LLM agents can be modeled in high-fidelity simulations of clinical settings and should be assessed for their impact on clinical workflows. These evaluation frameworks, which we refer to as "Artificial Intelligence Structured Clinical Examinations" ("AI-SCE"), can draw from comparable technologies where machines operate with varying degrees of self-governance, such as self-driving cars, in dynamic environments with multiple stakeholders. Developing these robust, real-world clinical evaluations will be crucial towards deploying LLM agents in medical settings.	[Mehandru, Nikita; Alaa, Ahmed] Univ Calif Berkeley, 2195 Hearst Ave,Warren Hall Suite,120C, Berkeley, CA 94709 USA; [Miao, Brenda Y.; Sushil, Madhumita; Butte, Atul J.; Alaa, Ahmed] Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA 94115 USA; [Almaraz, Eduardo Rodriguez] Univ Calif San Francisco, Neurosurg Dept, Div Neurooncol, 400 Parnassus Ave,8th Floor,RM A808, San Francisco, CA USA; [Almaraz, Eduardo Rodriguez] Univ Calif San Francisco, Dept Epidemiol & Biostat, 400 Parnassus Ave,8th Floor,RM A808, San Francisco, CA USA; [Butte, Atul J.] Univ Calif San Francisco, Dept Pediat, San Francisco, CA USA	University of California System; University of California Berkeley; University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco	Alaa, A (corresponding author), Univ Calif Berkeley, 2195 Hearst Ave,Warren Hall Suite,120C, Berkeley, CA 94709 USA.; Alaa, A (corresponding author), Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA 94115 USA.	amalaa@berkeley.edu		Rodriguez Almaraz, Eduardo/0000-0003-0978-1117; Sushil, Madhumita/0000-0001-7884-0526; Mehandru, Nikita/0000-0002-7374-7127	Division of Intramural Research, National Institute of Allergy and Infectious Diseases (Division of Intramural Research of the NIAID)	Division of Intramural Research, National Institute of Allergy and Infectious Diseases (Division of Intramural Research of the NIAID)	No Statement Available	Agrawal Monica, 2022, 2022 C EMPIRICAL MET; [Anonymous], 2023, Introducing Dr. Chatbot; Bankes SC, 2002, P NATL ACAD SCI USA, V99, P7199, DOI 10.1073/pnas.072081299; Bonabeau E, 2002, P NATL ACAD SCI USA, V99, P7280, DOI 10.1073/pnas.082080899; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen IY, 2021, ANNU REV BIOMED DA S, V4, P123, DOI 10.1146/annurev-biodatasci-092820-114757; Dash D, 2023, Arxiv, DOI [arXiv:2304.13714, DOI 10.48550/ARXIV.2304.13714]; Fagnant DJ, 2014, TRANSPORT RES C-EMER, V40, P1, DOI 10.1016/j.trc.2013.12.001; Fleming SL, 2023, medRxiv, DOI [10.1101/2023.04.25.23288588, 10.1101/2023.04.25.23288588, DOI 10.1101/2023.04.25.23288588]; Johnson AEW, 2023, SCI DATA, V10, DOI 10.1038/s41597-022-01899-x; Johri S, 2024, medRxiv, DOI [10.1101/2023.09.12.23295399, 10.1101/2023.09.12.23295399, DOI 10.1101/2023.09.12.23295399]; Kaur P, 2021, 2021 FOURTH INTERNATIONAL CONFERENCE ON CONNECTED AND AUTONOMOUS DRIVING (METROCAD 2021), DOI 10.1109/MetroCAD51599.2021.00018; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Park J. S., 2023, 36 S USER INTERFACE, P1; Radhakrishnan L, 2023, JAMIA OPEN, V6, DOI 10.1093/jamiaopen/ooad045; Rebedea Traian, 2023, P 2023 C EMPIRICAL M; Shen H., 2023, P 2023 C EMPIRICAL M, P9895; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Tracy M, 2018, ANNU REV PUBL HEALTH, V39, P77, DOI 10.1146/annurev-publhealth-040617-014317; Tu T, 2024, Arxiv, DOI arXiv:2401.05654; Webster P, 2023, NAT MED, DOI 10.1038/s41591-023-02700-1; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Zayyan Marliyya, 2011, Oman Med J, V26, P219, DOI 10.5001/omj.2011.55	29	1	1	12	12	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	APR 3	2024	7	1							84	10.1038/s41746-024-01083-y	http://dx.doi.org/10.1038/s41746-024-01083-y			3	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	MX5U2	38570554	gold			2024-07-03	WOS:001196956100001
J	Omiye, JA; Gui, HW; Rezaei, SJ; Zou, J; Daneshjou, R				Omiye, Jesutofunmi A.; Gui, Haiwen; Rezaei, Shawheen J.; Zou, James; Daneshjou, Roxana			Large Language Models in Medicine: The Potentials and Pitfalls A Narrative Review	ANNALS OF INTERNAL MEDICINE			English	Review							CHATGPT	Large language models (LLMs) are artificial intelligence models trained on vast text data to generate humanlike outputs. They have been applied to various tasks in health care, ranging from answering medical examination questions to generating clinical reports. With increasing institutional partnerships between companies producing LLMs and health systems, the real-world clinical application of these models is nearing realization. As these models gain traction, health care practitioners must understand what LLMs are, their development, their current and potential applications, and the associated pitfalls in a medical setting. This review, coupled with a tutorial, provides a comprehensive yet accessible overview of these areas with the aim of familiarizing health care professionals with the rapidly changing landscape of LLMs in medicine. Furthermore, the authors highlight active research areas in the field that promise to improve LLMs' usability in health care contexts.	[Omiye, Jesutofunmi A.; Gui, Haiwen; Rezaei, Shawheen J.; Daneshjou, Roxana] Stanford Univ, Dept Dermatol, Stanford, CA USA; [Omiye, Jesutofunmi A.; Zou, James; Daneshjou, Roxana] Stanford Univ, Dept Biomed Data Sci, Stanford, CA USA; [Daneshjou, Roxana] 1265 Welch Rd,MSOB West Wing,Third Floor, Stanford, CA 94305 USA	Stanford University; Stanford University	Daneshjou, R (corresponding author), 1265 Welch Rd,MSOB West Wing,Third Floor, Stanford, CA 94305 USA.	roxanad@stanford.edu	Daneshjou, Roxana/ABE-7764-2021	Gui, Haiwen/0000-0003-0564-940X; Rezaei, Shawheen/0000-0002-4394-7371; Daneshjou, Roxana/0000-0001-7988-9356				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; [Anonymous], 2023, OpenAI Blog; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R, PREPRINT; Brameier Devon T, 2023, J Bone Joint Surg Am, V105, P1388, DOI 10.2106/JBJS.23.00473; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chung H., PREPRINT; Claude Introducing, 2023, ANTHR; Cocco AM, 2018, MED J AUSTRALIA, V209, P342, DOI 10.5694/mja17.00889; Cross J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41399; Devlin J., 2018, BERT PRE TRAINING DE; Epic Eddy N., 2023, HLTHCARE IT NEWS; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Grewal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40135; Gupta R, 2023, J PLAST RECONSTR AES, V80, P145, DOI 10.1016/j.bjps.2023.03.004; Gururangan S., 2020, P 58 ANN M ASS COMPU, P1, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]; Holmes J, 2023, PREPRINT; Hu EJ, PREPRINT; Huang K, PREPRINT; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jeblick K, 2022, PREPRINT; Kaddour J, 2023, PREPRINT; Karn SK, 2023, PREPRINT; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lewis P, PREPRINT; Lewkowycz A, PREPRINT; Li C., 2023, PREPRINT; Liang P, PREPRINT; Lievin V, PREPRINT; Liu Siru, 2023, medRxiv, DOI 10.1101/2023.07.14.23292669; Liu Z, 2023, PREPRINT; Lukas N, PREPRINT; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Maynez J, PREPRINT; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Pichai S., 2023, Google; Radford A., 2023, Improving Language understanding by generative pre-training; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.21.23285886; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shoeybi M, PREPRINT; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Stanford Center for Research on Foundation Models; MosaicML. BioMedLM, 2023, HUGG FAC; Strong Eric, 2023, medRxiv, DOI 10.1101/2023.03.24.23287731; Tang X, PREPRINT; Touvron H, PREPRINT; Touvron H., 2023, PREPRINT; Trang B, 2023, STAT            0720; Tu T, 2023, PREPRINT; Van Riel Noor, 2017, BJGP Open, V1, pbjgpopen17X100833, DOI 10.3399/bjgpopen17X100833; Vaswani A., 2023, ADV NEURAL INFORM PR; Weidinger L., 2021, PREPRINT; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Wu C, PREPRINT; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yasunaga M, 2022, PREPRINT; Yasunaga M, PREPRINT; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zakka Cyril, 2023, Res Sq, DOI 10.21203/rs.3.rs-2883198/v1; Zhao WX, PREPRINT; Zhou J, PREPRINT, DOI [10.1101/2023.06.10.23291127, DOI 10.1101/2023.06.10.23291127]; Zhu D, PREPRINT; Zou A, 2023, PREPRINT	73	6	6	25	25	AMER COLL PHYSICIANS	PHILADELPHIA	INDEPENDENCE MALL WEST 6TH AND RACE ST, PHILADELPHIA, PA 19106-1572, UNITED STATES	0003-4819	1539-3704		ANN INTERN MED	Ann. Intern. Med.	FEB	2024	177	2								10.7326/M23-2772	http://dx.doi.org/10.7326/M23-2772		JAN 2024	12	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	JR7X4	38285984	Green Submitted			2024-07-03	WOS:001156408300001
J	Sezgin, E				Sezgin, Emre			Redefining Virtual Assistants in Health Care: The Future With Large Language Models	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Editorial Material						large language models; voice assistants; virtual assistants; chatbots; conversational agents; health care		This editorial explores the evolving and transformative role of large language models (LLMs) in enhancing the capabilities of virtual assistants (VAs) in the health care domain, highlighting recent research on the performance of VAs and LLMs in health care information sharing. Focusing on recent research, this editorial unveils the marked improvement in the accuracy and clinical relevance of responses from LLMs, such as GPT-4, compared to current VAs, especially in addressing complex health care inquiries, like those related to postpartum depression. The improved accuracy and clinical relevance with LLMs mark a paradigm shift in digital health tools and VAs. Furthermore, such LLM applications have the potential to dynamically adapt and be integrated into existing VA platforms, offering cost-effective, scalable, and inclusive solutions. These suggest a significant increase in the applicable range of VA applications, as well as the increased value, risk, and impact in health care, moving toward more personalized digital health ecosystems. However, alongside these advancements, it is necessary to develop and adhere to ethical guidelines, regulatory frameworks, governance principles, and privacy and safety measures. We need a robust interdisciplinary collaboration to navigate the complexities of safely and effectively integrating LLMs into health care applications, ensuring that these emerging technologies align with the diverse needs and ethical considerations of the health care domain.	[Sezgin, Emre] Nationwide Childrens Hosp, Abigail Wexner Res Inst, Columbus, OH USA; [Sezgin, Emre] Ohio State Univ, Coll Med, Columbus, OH USA; [Sezgin, Emre] Nationwide Childrens Hosp, Abigail Wexner Reseach Inst, 700 Childrens Dr, Columbus, OH 43205 USA	University System of Ohio; Ohio State University; Nationwide Childrens Hospital; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; Nationwide Childrens Hospital	Sezgin, E (corresponding author), Nationwide Childrens Hosp, Abigail Wexner Reseach Inst, 700 Childrens Dr, Columbus, OH 43205 USA.	emre.sezgin@nationwidechildrens.org		Sezgin, Emre/0000-0001-8798-9605				Agbavor Felix, 2022, PLOS Digit Health, V1, pe0000168, DOI 10.1371/journal.pdig.0000168; [Anonymous], 2023, AMA issues new principles for AI development, deployment and use; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bin Sawad A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22072625; Cai WL, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.232335; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Corbett CF, 2021, JMIR FORM RES, V5, DOI 10.2196/27327; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Ding H, 2024, J AM MED INFORM ASSN, V31, P746, DOI 10.1093/jamia/ocad222; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Lee J, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/24045; Liao F, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.931439; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]; Ogueji Kelechi, 2021, WORKSHOP MULTILINGUA, P116, DOI [10.18653/v1/2021.mrl-1.11, DOI 10.18653/V1/2021.MRL-1.11]; Palanica A, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.669971; Palanica A, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0133-x; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Sezgin E, 2023, J MED INTERNET RES, V25, DOI 10.2196/49240; Sezgin E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00332-0; Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Wiest IC, 2023, medRxiv, DOI [10.1101/2023.12.07.23299648, 10.1101/2023.12.07.23299648, DOI 10.1101/2023.12.07.23299648]; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yang Rui, 2023, Health Care Sci, V2, P255, DOI 10.1002/hcs2.61	28	0	0	12	12	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JAN 12	2024	26								e53225	10.2196/53225	http://dx.doi.org/10.2196/53225			4	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	IF2D5	38241074	gold, Green Published			2024-07-03	WOS:001164838200004
J	Luu, RK; Buehler, MJ				Luu, Rachel K.; Buehler, Markus J.			BioinspiredLLM: Conversational Large Language Model for the Mechanics of Biological and Bio-Inspired Materials	ADVANCED SCIENCE			English	Article						bio-inspiration; biological materials; generative artificial intelligence; hierarchical structures; large language models; mechanical properties	HIERARCHICAL STRUCTURE; BIOMECHANICS; MULTISCALE; SYSTEMS	The study of biological materials and bio-inspired materials science is well established; however, surprisingly little knowledge is systematically translated to engineering solutions. To accelerate discovery and guide insights, an open-source autoregressive transformer large language model (LLM), BioinspiredLLM, is reported. The model is finetuned with a corpus of over a thousand peer-reviewed articles in the field of structural biological and bio-inspired materials and can be prompted to recall information, assist with research tasks, and function as an engine for creativity. The model has proven that it is able to accurately recall information about biological materials and is further strengthened with enhanced reasoning ability, as well as with Retrieval-Augmented Generation (RAG) to incorporate new data during generation that can also help to traceback sources, update the knowledge base, and connect knowledge domains. BioinspiredLLM also has shown to develop sound hypotheses regarding biological materials design and remarkably so for materials that have never been explicitly studied before. Lastly, the model shows impressive promise in collaborating with other generative artificial intelligence models in a workflow that can reshape the traditional materials design process. This collaborative generative artificial intelligence method can stimulate and enhance bio-inspired materials design workflows. Biological materials are at a critical intersection of multiple scientific fields and models like BioinspiredLLM help to connect knowledge domains.	[Luu, Rachel K.; Buehler, Markus J.] MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Luu, Rachel K.] MIT, Dept Mat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Buehler, Markus J.] MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Buehler, MJ (corresponding author), MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Buehler, MJ (corresponding author), MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	mbuehler@mit.edu	Luu, Rachel/KKB-8743-2024; Buehler, Markus/C-4580-2008	Buehler, Markus/0000-0002-4173-9659; Luu, Rachel/0000-0002-7821-934X	National Science Foundation Graduate Research Fellowship; Army Research Office [W911NF1920098, W911NF2220213]; ONR [N00014-19-1-2375, N00014-20-1-2189]; USDA [2021-69012-35978]; MIT's Generative AI initiative; MIT-IBM Watson AI Lab;  [2141064]	National Science Foundation Graduate Research Fellowship(National Science Foundation (NSF)); Army Research Office; ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); USDA(United States Department of Agriculture (USDA)); MIT's Generative AI initiative; MIT-IBM Watson AI Lab(International Business Machines (IBM)); 	This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant no. 2141064. This work was funded by the Army Research Office (W911NF1920098 and W911NF2220213), ONR (N00014-19-1-2375 and N00014-20-1-2189), as well as USDA (2021-69012-35978). Additional support was provided by MIT's Generative AI initiative, and the MIT-IBM Watson AI Lab. The authors would like to thank MIT Libraries staff, including Dr. Ye Li, for their advice and support in text/data mining.	[Anonymous], OpenAI; ASHBY MF, 1995, P R SOC-MATH PHYS SC, V450, P123, DOI 10.1098/rspa.1995.0075; Ballarini R, 2013, CISM COURSES LECT, V546; Bar-On B, 2014, APPL PHYS LETT, V105, DOI 10.1063/1.4891191; Barthlott W, 2017, NANO-MICRO LETT, V9, DOI 10.1007/s40820-016-0125-1; Blecher L., 2023, AI; Brinson LC, 2024, MRS BULL, V49, P12, DOI 10.1557/s43577-023-00498-4; Brodnik NR, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062773; Bubeck S., 2023, arXiv; Buehler MJ, 2024, ACS ENG AU, V4, P241, DOI 10.1021/acsengineeringau.3c00058; Buehler MJ, 2023, J MECH PHYS SOLIDS, V181, DOI 10.1016/j.jmps.2023.105454; Chen IH, 2014, MAT SCI ENG C-MATER, V35, P441, DOI 10.1016/j.msec.2013.11.024; Chen IH, 2011, J MECH BEHAV BIOMED, V4, P713, DOI 10.1016/j.jmbbm.2010.12.013; Chen PY, 2012, PROG MATER SCI, V57, P1492, DOI 10.1016/j.pmatsci.2012.03.001; Chen Q, 2014, J BIOMECH, V47, P1332, DOI 10.1016/j.jbiomech.2014.02.010; Chern I.-C., 2023, ARXIV; Dettmers T., 2023, ARXIV; Dimas LS, 2014, SOFT MATTER, V10, P4436, DOI 10.1039/c3sm52890a; Dixon PG, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0321; Fernandez JG, 2013, ADV FUNCT MATER, V23, P4454, DOI 10.1002/adfm.201300053; Fratzl P, 2007, PROG MATER SCI, V52, P1263, DOI 10.1016/j.pmatsci.2007.06.001; Ghazlan A, 2021, COMPOS PART B-ENG, V205, DOI 10.1016/j.compositesb.2020.108513; Gibson LJ, 2005, J BIOMECH, V38, P377, DOI 10.1016/j.jbiomech.2004.09.027; Gibson LJ, 2012, J R SOC INTERFACE, V9, P2749, DOI 10.1098/rsif.2012.0341; Gludovatz B, 2017, J MECH BEHAV BIOMED, V76, P76, DOI 10.1016/j.jmbbm.2017.05.024; Greil P, 2010, MRS BULL, V35, P145, DOI 10.1557/mrs2010.635; Guan QF, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19174-1; Hepworth DG, 2000, J MATER SCI, V35, P5861, DOI 10.1023/A:1026716710498; Hu E., 2021, ICLR 2022 10 INT C L; Huang S, 2022, J CHEM INF MODEL, V62, P6365, DOI 10.1021/acs.jcim.2c00035; Huang W, 2019, ADV MATER, V31, DOI 10.1002/adma.201901561; Huang W, 2019, ACTA BIOMATER, V90, P267, DOI 10.1016/j.actbio.2019.04.003; Huang W, 2017, ACTA BIOMATER, V64, P1, DOI 10.1016/j.actbio.2017.09.043; Ivanova O, 2013, RAPID PROTOTYPING J, V19, P353, DOI 10.1108/RPJ-12-2011-0127; Janis CM, 2002, PALAEOGEOGR PALAEOCL, V177, P183, DOI 10.1016/S0031-0182(01)00359-5; Kingma D. P., 2017, ARXIV; Lauer C, 2018, ACTA BIOMATER, V77, P322, DOI 10.1016/j.actbio.2018.07.010; Lazarus BS, 2023, SMALL STRUCT, V4, DOI 10.1002/sstr.202200402; Lazarus BS, 2023, ACTA BIOMATER, V166, P430, DOI 10.1016/j.actbio.2023.04.040; Lazarus BS, 2022, ACTA BIOMATER, V151, P426, DOI 10.1016/j.actbio.2022.08.028; Lazarus BS, 2020, J MATER RES TECHNOL, V9, P15705, DOI 10.1016/j.jmrt.2020.10.062; Lee NA, 2022, MATTER-US, V5, P3597, DOI 10.1016/j.matt.2022.10.003; Lee S, 2011, MAT SCI ENG C-MATER, V31, P730, DOI 10.1016/j.msec.2010.10.017; Lewis P., 2020, Adv. Neural Inf. Process. Syst.; Liu DB, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau9183; Luu RK, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062310; Luu RK, 2023, APPL PHYS LETT, V122, DOI 10.1063/5.0155890; M. J, 2023, ABOUT US; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mahrous MA, 2023, J MATER RES TECHNOL, V26, P5535, DOI 10.1016/j.jmrt.2023.08.246; Méndez-Alonzo R, 2013, FUNCT ECOL, V27, P544, DOI 10.1111/1365-2435.12059; Meyers MA, 2008, PROG MATER SCI, V53, P1, DOI 10.1016/j.pmatsci.2007.05.002; Meyers MA, 2013, SCIENCE, V339, P773, DOI 10.1126/science.1220854; Mitra A., 2023, ARXIV; Naleway SE, 2016, MAT SCI ENG C-MATER, V59, P1143, DOI 10.1016/j.msec.2015.10.033; Naleway SE, 2015, ADV MATER, V27, P5455, DOI 10.1002/adma.201502403; Nepal D, 2023, NAT MATER, V22, P18, DOI 10.1038/s41563-022-01384-1; Ha NS, 2020, COMPOS PART B-ENG, V181, DOI 10.1016/j.compositesb.2019.107496; Ni B, 2023, CHEM-US, V9, P1828, DOI 10.1016/j.chempr.2023.03.020; Paszke A, 2019, ADV NEUR IN, V32; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rueggeberg M, 2007, COMP BIOCHEM PHYS A, V146, pS132, DOI 10.1016/j.cbpa.2007.01.252; Shen S. C.-y., 2022, COMMUN ENG, V1, P1, DOI [DOI 10.1038/S44172-022-00037-0, 10.1038/s44172-022-00037-0]; Sorieul M, 2016, MATERIALS, V9, DOI 10.3390/ma9080618; Sun JY, 2012, RSC ADV, V2, P12606, DOI 10.1039/c2ra21276e; Thoppilan R, 2022, ARXIV; Touvron H., ND; Touvron H., 2023, arXiv; Vincent J., 2012, Structural biomaterials; Wang B, 2016, ACTA BIOMATER, V41, P60, DOI 10.1016/j.actbio.2016.05.028; Wang B, 2016, PROG MATER SCI, V76, P229, DOI 10.1016/j.pmatsci.2015.06.001; Weaver JC, 2012, SCIENCE, V336, P1275, DOI 10.1126/science.1218764; Wegst UGK, 2015, NAT MATER, V14, P23, DOI [10.1038/NMAT4089, 10.1038/nmat4089]; Weinkamer R, 2011, MAT SCI ENG C-MATER, V31, P1164, DOI 10.1016/j.msec.2010.12.002; Xu CW, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01016-5; Yang ZZ, 2023, J MECH PHYS SOLIDS, V170, DOI 10.1016/j.jmps.2022.105098; Zhang F, 2020, MATER ADV, V1, P2592, DOI 10.1039/d0ma00599a; Zhang YW, 2020, ADV MATER, V32, DOI 10.1002/adma.201902806; Zhang YC, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2018.0093; Zhao JY, 2023, J CHEM INF MODEL, V63, P1961, DOI 10.1021/acs.jcim.2c01259; Zhao ZL, 2018, J MECH PHYS SOLIDS, V119, P224, DOI 10.1016/j.jmps.2018.06.014; Zhong W., 2023, ARXIV; Zhong W., ARXIV	83	3	3	52	53	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2198-3844		ADV SCI	Adv. Sci.	MAR	2024	11	10							2306724	10.1002/advs.202306724	http://dx.doi.org/10.1002/advs.202306724		DEC 2023	16	Chemistry, Multidisciplinary; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science	LB8H6	38145334	Green Published, Green Submitted, gold			2024-07-03	WOS:001129453100001
J	de Winter, JCF				de Winter, Joost C. F.			Can ChatGPT Pass High School Exams on English Language Comprehension?	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article; Early Access						GPT-3.5; GPT-4; Large language model; Educational assessment; Reading comprehension		Launched in late November 2022, ChatGPT, a large language model chatbot, has garnered considerable attention. However, ongoing questions remain regarding its capabilities. In this study, ChatGPT was used to complete national high school exams in the Netherlands on the topic of English reading comprehension. In late December 2022, we submitted the exam questions through the ChatGPT web interface (GPT-3.5). According to official norms, ChatGPT achieved a mean grade of 7.3 on the Dutch scale of 1 to 10-comparable to the mean grade of all students who took the exam in the Netherlands, 6.99. However, ChatGPT occasionally required re-prompting to arrive at an explicit answer; without these nudges, the overall grade was 6.5. In March 2023, API access was made available, and a new version of ChatGPT, GPT-4, was released. We submitted the same exams to the API, and GPT-4 achieved a score of 8.3 without a need for re-prompting. Additionally, employing a bootstrapping method that incorporated randomness through ChatGPT's 'temperature' parameter proved effective in self-identifying potentially incorrect answers. Finally, a re-assessment conducted with the GPT-4 model updated as of June 2023 showed no substantial change in the overall score. The present findings highlight significant opportunities but also raise concerns about the impact of ChatGPT and similar large language models on educational assessment.	[de Winter, Joost C. F.] Delft Univ Technol, Cognit Robot Dept, Delft, Netherlands	Delft University of Technology	de Winter, JCF (corresponding author), Delft Univ Technol, Cognit Robot Dept, Delft, Netherlands.	j.c.f.dewinter@tudelft.nl	de Winter, Joost/F-8373-2012	de Winter, Joost/0000-0002-1281-8200	Dr. Dimitra Dodou's role in scoring the output of ChatGPT according to the correction instruction is acknowledged.	Dr. Dimitra Dodou's role in scoring the output of ChatGPT according to the correction instruction is acknowledged.	Dr. Dimitra Dodou's role in scoring the output of ChatGPT according to the correction instruction is acknowledged.	Arora D, 2023, Arxiv, DOI [arXiv:2305.15074, 10.48550/arXiv.2305.15074]; Bordt S, 2023, Arxiv, DOI arXiv:2303.09461; Bubeck S., 2023, arXiv; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; CITO, 2023, CITO: tests, exams, tracking systems, certifications, and trainings; CITO, 2022, Test and item analysis VWO English 2022 period 1; College voor Toetsen en Examens, 2022, Engels VWO 2022; College voor Toetsen en Examens, 2020, Syllabus central exams 2022 Arabic, German, English, French, Russian, Spanish, Turkish; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Davis J. C., 2023, Figshare; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Geerling W., 2023, ChatGPT has mastered the principles of economics: Now what?, DOI [10.2139/ssrn.4356034, DOI 10.2139/SSRN.4356034]; Gilson A, 2022, medRxiv, DOI [10.1101/2022.12.23.22283901, 10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Han ZY, 2023, medRxiv, DOI [10.1101/2023.02.13.23285879, 10.1101/2023.02.13.23285879, DOI 10.1101/2023.02.13.23285879]; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; Kerrigan John, 2022, Journal of Educational Technology Systems, P192, DOI 10.1177/00472395221118392; Kim N, 2023, Arxiv, DOI arXiv:2212.10003; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Kirmani AR, 2022, ACS ENERGY LETT, V8, P574, DOI 10.1021/acsenergylett.2c02758; Kortemeyer G, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010132; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; LeCun Y., 2023, Spoiler: YES!; Lovin B, 2022, ChatGPT produces made-up nonexistent references; Mitchell A., 2022, Professor catches student cheating with ChatGPT: 'I feel abject terror'; Newton PM., 2023, PREPRINT, DOI DOI 10.35542/OSF.IO/SYTU3; Office Microsoft Blog, 2023, Introducing Microsoft 365 Copilot-your copilot for work; OpenAI, 2023, GPT-4 Technical Report; Pettit M, 2021, BONE JOINT OPEN, V2, P111, DOI [10.1302/2633-1462.22.BJO-2020-0142.R1, 10.1302/2633-1462.22.BJO-2020.0142.R1]; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Rospocher M, 2023, INFORMATION, V14, DOI 10.3390/info14030159; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Savelka J, 2023, Arxiv, DOI arXiv:2306.10073; Slapeta J, 2023, TRENDS PARASITOL, V39, P314, DOI 10.1016/j.pt.2023.02.006; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tabone W, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.231053; Vincent J., 2022, VERGE; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Whitford E, 2022, A computer can now write your college essay-Maybe better than you can; Zhai X., 2022, Chatgpt user experience: Implications for education; Zheng CY, 2023, Arxiv, DOI [arXiv:2304.09797, 10.48550/arXiv.2304.09797]; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]	50	12	12	24	32	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	2023 SEP 13	2023										10.1007/s40593-023-00372-z	http://dx.doi.org/10.1007/s40593-023-00372-z		SEP 2023	16	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	T2KE5		hybrid, Green Published			2024-07-03	WOS:001076314300001
J	Pratt, N; Madhavan, R; Weleff, J				Pratt, Nicholas; Madhavan, Ricky; Weleff, Jeremy			Digital Dialogue-How Youth Are Interacting With Chatbots	JAMA PEDIATRICS			English	Article								This Viewpoint describes the use of large language model chatbots in social, educational, and therapeutic settings and the need to assess when children are developmentally ready to engage with them.	[Pratt, Nicholas; Madhavan, Ricky; Weleff, Jeremy] Yale Univ, Sch Med, Dept Psychiat, New Haven, CT USA; [Weleff, Jeremy] Cleveland Clin, Neurol Inst, Ctr Behav Hlth, Dept Psychiat & Psychol, Cleveland, OH USA; [Pratt, Nicholas] Yale Univ, Sch Med, Dept Psychiat, 300 George St, Ste 901, New Haven, CT 06511 USA	Yale University; Cleveland Clinic Foundation; Yale University	Pratt, N (corresponding author), Yale Univ, Sch Med, Dept Psychiat, 300 George St, Ste 901, New Haven, CT 06511 USA.	nicholas.pratt@yale.edu		Weleff, Jeremy/0000-0001-8071-7412				American Academy of Child and Adolescent Psychiatry, 2023, POLICY STATEMENT IMP; Barua PD, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031192; Department of Health and Human Services, 2023, SOCIAL MEDIA YOUTH M; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Lazar N., 2023, HARVARD DATA SCI REV, V5, DOI [10.1162/99608f92.9f0adc39, DOI 10.1162/99608F92.9F0ADC39]; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Piazza J., 2023, SNAP AI CHATBOT INVE; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563	9	0	0	2	2	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6203	2168-6211		JAMA PEDIATR	JAMA Pediatr.	MAY	2024	178	5					429	430		10.1001/jamapediatrics.2024.0084	http://dx.doi.org/10.1001/jamapediatrics.2024.0084		MAY 2024	2	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	QN5K1	38497982				2024-07-03	WOS:001189497900002
J	Cascella, M; Semeraro, F; Montomoli, J; Bellini, V; Piazza, O; Bignami, E				Cascella, Marco; Semeraro, Federico; Montomoli, Jonathan; Bellini, Valentina; Piazza, Ornella; Bignami, Elena			The Breakthrough of Large Language Models Release for Medical Applications: 1-Year Timeline and Perspectives	JOURNAL OF MEDICAL SYSTEMS			English	Review						Large Language Models; Chatbot; Natural Language Processing; Artificial Intelligence; ChatGPT; Clinical Decision Support; Generative AI		Within the domain of Natural Language Processing (NLP), Large Language Models (LLMs) represent sophisticated models engineered to comprehend, generate, and manipulate text resembling human language on an extensive scale. They are transformer-based deep learning architectures, obtained through the scaling of model size, pretraining of corpora, and computational resources. The potential healthcare applications of these models primarily involve chatbots and interaction systems for clinical documentation management, and medical literature summarization (Biomedical NLP). The challenge in this field lies in the research for applications in diagnostic and clinical decision support, as well as patient triage. Therefore, LLMs can be used for multiple tasks within patient care, research, and education. Throughout 2023, there has been an escalation in the release of LLMs, some of which are applicable in the healthcare domain. This remarkable output is largely the effect of the customization of pre-trained models for applications like chatbots, virtual assistants, or any system requiring human-like conversational engagement. As healthcare professionals, we recognize the imperative to stay at the forefront of knowledge. However, keeping abreast of the rapid evolution of this technology is practically unattainable, and, above all, understanding its potential applications and limitations remains a subject of ongoing debate. Consequently, this article aims to provide a succinct overview of the recently released LLMs, emphasizing their potential use in the field of medicine. Perspectives for a more extensive range of safe and effective applications are also discussed. The upcoming evolutionary leap involves the transition from an AI-powered model primarily designed for answering medical questions to a more versatile and practical tool for healthcare providers such as generalist biomedical AI systems for multimodal-based calibrated decision-making processes. On the other hand, the development of more accurate virtual clinical partners could enhance patient engagement, offering personalized support, and improving chronic disease management.	[Cascella, Marco; Piazza, Ornella] Univ Salerno, Dept Med Surg & Dent Scuola Med Salernitana, Anesthesia & Pain Med, Via S Allende, I-84081 Baronissi, Italy; [Semeraro, Federico] Maggiore Hosp Carlo Alberto Pizzardi, Dept Anesthesia Intens Care & Prehosp Emergency, Bologna, Italy; [Montomoli, Jonathan] Infermi Hosp, Dept Anesthesia & Intens Care, AUSL Romagna, Viale Settembrini 2, I-47923 Rimini, Italy; [Bellini, Valentina; Bignami, Elena] Univ Parma, Dept Med & Surg, Anesthesiol Crit Care & Pain Med Div, Viale Gramsci 14, I-43126 Parma, Italy	University of Salerno; Hospital of Rimini; AUSL della Romagna; University of Parma	Bellini, V (corresponding author), Univ Parma, Dept Med & Surg, Anesthesiol Crit Care & Pain Med Div, Viale Gramsci 14, I-43126 Parma, Italy.	valentina.bellini@unipr.it	cascella, marco/N-1316-2018	cascella, marco/0000-0002-5236-3132	Universit degli Studi di Parma	Universit degli Studi di Parma	No Statement Available	Ainslie J, 2023, P 2023 C EMPIRICAL M, P4895, DOI 10.18653/; anthropology, About Us; avanade, Avanade Insight; Batarseh FA, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00445-7; Benary M, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.43689; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; bing, Microsoft Bing Blog; Birkun AA, 2023, PREHOSP DISASTER MED, DOI 10.1017/S1049023X23006568; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao ZH, 2021, IEEE T NEUR NET LEAR, V32, P5369, DOI 10.1109/TNNLS.2021.3084198; Cascella Marco, 2023, J Anesth Analg Crit Care, V3, P33, DOI 10.1186/s44158-023-00118-2; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cunningham H, 2023, Arxiv, DOI arXiv:2309.08600; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gemini Team Google, Gemini: A Family of Highly Capable Multimodal Models; google, Meta AI Request Form; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Gurrapu S, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1225093; Haque A, 2023, TechRxiv, DOI [10.36227/techrxiv.24354451.v2, DOI 10.36227/TECHRXIV.24354451.V2]; Hippocratic AI, About Us; Hugging Face, MPT-B; Jang Dongyeop, 2023, PLOS Digit Health, V2, pe0000416, DOI 10.1371/journal.pdig.0000416; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kalyan KS, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103982; Kauf C, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13386; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Madsen A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3546577; Manathunga S, 2023, Arxiv, DOI arXiv:2309.02884; medium, An END-to-END guide on how to finetune a LLM(Mistral-7B) into a Medical Chat Doctor using Huggingface; Mistral AI, About Us; Nijkamp E, 2023, Arxiv, DOI arXiv:2309.03450; Open AI, ChatGPT release note; OpenAI, 2023, Gpt-4 technical report; Ouyang L., 2022, Adv. Neural Inf. Process., V35, P730; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Radford A., 2018, IMPROVING LANGUAGE U; Rafailov R, 2023, Arxiv, DOI arXiv:2305.18290; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scheschenja M, 2024, CARDIOVASC INTER RAD, V47, P245, DOI 10.1007/s00270-023-03563-2; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Spies NC, 2023, J APPL LAB MED, V8, P1092, DOI 10.1093/jalm/jfad058; technologyreview, MIT Technology Review; The decoder, About Us; Tian S, 2023, Biomedicine and HealtharXiv:2306.10070; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tran D, 2022, Arxiv, DOI [arXiv:2207.07411, 10.48550/ARXIV.2207.07411, DOI 10.48550/ARXIV.2207.07411]; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Yasunaga Michihiro, 2022, LinkBERT: Pretraining Language Models with Document Links; zdnet, ZDNET Information	59	8	8	39	39	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	FEB 17	2024	48	1							22	10.1007/s10916-024-02045-3	http://dx.doi.org/10.1007/s10916-024-02045-3			11	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	HX5W5	38366043	Green Published, hybrid			2024-07-03	WOS:001162831400001
J	Chowdhery, A; Narang, S; Devlin, J; Bosma, M; Mishra, G; Roberts, A; Barham, P; Chung, HW; Sutton, C; Gehrmann, S; Schuh, P; Shi, K; Tsvyashchenko, S; Maynez, J; Rao, A; Barnes, P; Tay, Y; Shazeer, N; Prabhakaran, V; Reif, E; Du, N; Hutchinson, B; Pope, R; Bradbury, J; Austin, J; Isard, M; Gur-Ari, G; Yin, PC; Duke, T; Levskaya, A; Ghemawat, S; Dev, S; Michalewski, H; Garcia, X; Misra, V; Robinson, K; Fedus, L; Zhou, D; Ippolito, D; Luan, D; Lim, H; Zoph, B; Spiridonov, A; Sepassi, R; Dohan, D; Agrawal, S; Omernick, M; Dai, AM; Pillai, TS; Pellat, M; Lewkowycz, A; Moreira, E; Child, R; Polozov, O; Lee, K; Zhou, ZW; Wang, XZ; Saeta, B; Diaz, M; Firat, O; Catasta, M; Wei, J; Meier-Hellstern, K; Eck, D; Dean, J; Petrov, S; Fiedel, N				Chowdhery, Aakanksha; Narang, Sharan; Devlin, Jacob; Bosma, Maarten; Mishra, Gaurav; Roberts, Adam; Barham, Paul; Chung, Hyung Won; Sutton, Charles; Gehrmann, Sebastian; Schuh, Parker; Shi, Kensen; Tsvyashchenko, Sasha; Maynez, Joshua; Rao, Abhishek; Barnes, Parker; Tay, Yi; Shazeer, Noam; Prabhakaran, Vinodkumar; Reif, Emily; Du, Nan; Hutchinson, Ben; Pope, Reiner; Bradbury, James; Austin, Jacob; Isard, Michael; Gur-Ari, Guy; Yin, Pengcheng; Duke, Toju; Levskaya, Anselm; Ghemawat, Sanjay; Dev, Sunipa; Michalewski, Henryk; Garcia, Xavier; Misra, Vedant; Robinson, Kevin; Fedus, Liam; Zhou, Denny; Ippolito, Daphne; Luan, David; Lim, Hyeontaek; Zoph, Barret; Spiridonov, Alexander; Sepassi, Ryan; Dohan, David; Agrawal, Shivani; Omernick, Mark; Dai, Andrew M.; Pillai, Thanumalayan Sankaranarayana; Pellat, Marie; Lewkowycz, Aitor; Moreira, Erica; Child, Rewon; Polozov, Oleksandr; Lee, Katherine; Zhou, Zongwei; Wang, Xuezhi; Saeta, Brennan; Diaz, Mark; Firat, Orhan; Catasta, Michele; Wei, Jason; Meier-Hellstern, Kathy; Eck, Douglas; Dean, Jeff; Petrov, Slav; Fiedel, Noah			PaLM: Scaling Language Modeling with Pathways	JOURNAL OF MACHINE LEARNING RESEARCH			English	Article						Large language models; Few-shot learning; Natural language processing; Scalable deep learning		Large language models have been shown to achieve remarkable performance across a variety of natural language tasks using few-shot learning, which drastically reduces the number of task-specific training examples needed to adapt the model to a particular application. To further our understanding of the impact of scale on few-shot learning, we trained a 540 billion parameter, densely activated, Transformer language model, which we call Pathways Language Model (PaLM).We trained PaLM on 6144 TPU v4 chips using Pathways, a new ML system which enables highly efficient training across multiple TPU Pods. We demonstrate continued benefits of scaling by achieving state-of-the-art few-shot learning results on hundreds of language understanding and generation benchmarks. On a number of these tasks, PaLM 540B achieves breakthrough performance, outperforming the finetuned state-of-the-art on a suite of multi-step reasoning tasks, and outperforming average human performance on the recently released BIG-bench benchmark. A significant number of BIG-bench tasks showed discontinuous improvements from model scale, meaning that performance steeply increased as we scaled to our largest model. PaLM also has strong capabilities in multilingual tasks and source code generation, which we demonstrate on a wide array of benchmarks. We additionally provide a comprehensive analysis on bias and toxicity, and study the extent of training data memorization with respect to model scale. Finally, we discuss the ethical considerations related to large language models and discuss potential mitigation strategies.	[Chowdhery, Aakanksha; Narang, Sharan; Devlin, Jacob; Bosma, Maarten; Mishra, Gaurav; Roberts, Adam; Barham, Paul; Chung, Hyung Won; Sutton, Charles; Gehrmann, Sebastian; Schuh, Parker; Shi, Kensen; Tsvyashchenko, Sasha; Maynez, Joshua; Rao, Abhishek; Barnes, Parker; Tay, Yi; Shazeer, Noam; Prabhakaran, Vinodkumar; Reif, Emily; Du, Nan; Hutchinson, Ben; Pope, Reiner; Bradbury, James; Austin, Jacob; Isard, Michael; Gur-Ari, Guy; Yin, Pengcheng; Duke, Toju; Levskaya, Anselm; Ghemawat, Sanjay; Dev, Sunipa; Michalewski, Henryk; Garcia, Xavier; Misra, Vedant; Robinson, Kevin; Fedus, Liam; Zhou, Denny; Ippolito, Daphne; Luan, David; Lim, Hyeontaek; Zoph, Barret; Spiridonov, Alexander; Sepassi, Ryan; Dohan, David; Agrawal, Shivani; Omernick, Mark; Dai, Andrew M.; Pillai, Thanumalayan Sankaranarayana; Pellat, Marie; Lewkowycz, Aitor; Moreira, Erica; Child, Rewon; Polozov, Oleksandr; Lee, Katherine; Zhou, Zongwei; Wang, Xuezhi; Saeta, Brennan; Diaz, Mark; Firat, Orhan; Catasta, Michele; Wei, Jason; Meier-Hellstern, Kathy; Eck, Douglas; Dean, Jeff; Petrov, Slav; Fiedel, Noah] Google, Atlanta, GA 30309 USA	Google Incorporated	Chowdhery, A (corresponding author), Google, Atlanta, GA 30309 USA.	CHOWDHERY@GOOGLE.COM; SHARAN.NARANG@GMAIL.COM; JACOBDEVLIN@GOOGLE.COM	Michalewski, Henryk/L-4287-2018; Mishra, Gaurav/HKM-6801-2023; Mishra, Gaurav/GLR-6378-2022	Mishra, Gaurav/0000-0002-9832-3814; 				Abid A, 2021, Arxiv, DOI arXiv:2101.05783; Adiwardana D, 2020, Arxiv, DOI arXiv:2001.09977; Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Amini A, 2019, Arxiv, DOI arXiv:1905.13319; [Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2021, T5x; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bakshi S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P136; Barham Paul, 2022, MLSys 2022; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barocas S, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P368, DOI 10.1145/3461702.3462610; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BIG -bench collaboration, 2021, Beyond the imitation game: Measuring and extrapolating the capabilities of language models; Bird Steven, 2004, Nltk: The natural language toolkit, P214; Bisk Y, 2019, Arxiv, DOI arXiv:1911.11641; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Borgeaud S, 2022, Arxiv, DOI arXiv:2112.04426; Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao YT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4568; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Caswell I, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), VOL 1: RESEARCH PAPERS, P53; Chen M., 2021, arXiv; Child R, 2019, Arxiv, DOI [arXiv:1904.10509, DOI 10.48550/ARXIV.1904.10509]; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Choromanski K, 2021, Arxiv, DOI arXiv:2009.14794; Clark Jon, 2020, Transactions of the Association for Computational Linguistics; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Dev S, 2019, Arxiv, DOI arXiv:1908.09369; Dev S, 2021, Arxiv, DOI arXiv:2108.03362; Dev S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1968; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1286; Du N, 2022, Arxiv, DOI arXiv:2112.06905; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Dusek Ondrej, 2019, Neural generation for czech: Data and baselines; Dusek Ondrej, 2019, PROC 12 INT C NATURA, P563; Dusek Ondrej., 2019, P 12 INT C NATURAL L, P421; Edunov S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P489; Fan AEL, 2020, Arxiv, DOI arXiv:2010.11125; Fedus W, 2022, Arxiv, DOI arXiv:2101.03961; Ferreira Thiago Castro, 2020, P 3 INT WORKSHOP NAT, P55; Freitag M, 2020, Arxiv, DOI arXiv:2010.10239; Gale T, 2019, Arxiv, DOI [arXiv:1902.09574, DOI 10.48550/ARXIV.1902.09574]; Gardent C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P179, DOI 10.18653/v1/P17-1017; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Gehman Samuel, 2020, Realtoxicityprompts: Evaluating neural toxic degeneration in language models; Gehrmann S., 2022, arXiv; Gehrmann S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P96; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Google Cloud NLP, Google cloud infotype detector; Google Cloud NLP, Google cloud classifying content; Google Sustainability, 2022, Sustainability at Google.Carbon neutral since 2007.Carbon free by 2030; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Guu K, 2020, PR MACH LEARN RES, V119; Hendrycks Dan, 2021, Proc. Int. Conf. Learn Represent ICLR; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Huang YP, 2019, ADV NEUR IN, V32; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jacobs AZ, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P375, DOI 10.1145/3442188.3445901; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307; Kandpal N, 2022, Arxiv, DOI arXiv:2202.06539; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kingma D. P., 2017, ARXIV; Kitaev N., 2020, arXiv; Know Your Data, About Us; Koncel-Kedziorski R., 2016, NAACL HLT 2016 2016, P1152, DOI [10.18653/v1/N16, 10.18653/v1/N16-1136, DOI 10.18653/VLIN16-1136]; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Kulal Sumith, 2019, ADV NEURAL INFORM PR; Kurita Keita, 2019, 1 ACL WORKSH GEND BI; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lachaux MA, 2020, Arxiv, DOI arXiv:2006.03511; Ladhak F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4034; Lai G., 2017, ARXIV170404683, P785, DOI [DOI 10.18653/V1/D17-1082, 10.18653/v1/D17-1082]; Lan Yihuai, 2021, arXiv; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Lepikhin Dmitry, 2020, Gshard: Scaling giant models with conditional computation and automatic sharding; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewkowycz Aitor, 2022, arXiv; Li B, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P257; Li S, 2020, Arxiv, DOI [arXiv:2006.15704, DOI 10.14778/3415478.3415530]; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lieber O., 2021, JURASSIC 1 TECHNICAL; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin ZH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2649; Ling W, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P158, DOI 10.18653/v1/P17-1015; Lopes CV, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133908; Maziarz K., 2017, ARXIV170106538; McCandlish S, 2018, Arxiv, DOI [arXiv:1812.06162, DOI 10.48550/ARXIV.1812.06162]; Mihaylov T, 2018, Arxiv, DOI [arXiv:1809.02789, 10.48550/arXiv.1809.02789]; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Mostafazadeh Nasrin, 2016, P 2016 C N AM CHAPTE, P839, DOI [10.18653/v1/N16-1098, DOI 10.18653/V1/N16-1098]; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayanan D, 2021, PR MACH LEARN RES, V139; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; Nie YX, 2020, Arxiv, DOI arXiv:1910.14599; Novikova J, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P201; Nvidia Megatron LM, Megatron-LM; Nye Maxwell, 2021, arXiv; Ouyang Long, 2022, PREPRINT; Paperno Denis, 2016, arXiv; Pascanu R, 2013, Arxiv, DOI [arXiv:1211.5063, DOI 10.48550/ARXIV.1211.5063]; Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2080; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Pearce H, 2021, Arxiv, DOI arXiv:2108.09293; Pi XY, 2022, Arxiv, DOI arXiv:2201.11473; Piekos P, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P383; Pu A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P751; Qi Z., 2015, P 2015 INT S SOFTW T, P24, DOI DOI 10.1145/2771783.2771791; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Rajbhandari S, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476205; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Raji Inioluwa Deborah, 2021, arXiv; Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Reddy S, 2019, Arxiv, DOI arXiv:1808.07042; Ren J, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P551; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Roberts Adam, 2022, Scaling up models and data with t5x and seqio; Röttger P, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P41; Roy A, 2020, Arxiv, DOI arXiv:2003.05997; Rudinger J., 2018, P 2018 C N AM CHAPTE, P8, DOI [10.18653/v1/n18-2002.45, DOI 10.18653/V1/N18-2002, 10.18653/v1/N18-2002]; Sakaguchi K, 2020, AAAI CONF ARTIF INTE, V34, P8732; Sambasivan N, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P315, DOI 10.1145/3442188.3445896; Sanh V., 2021, P INT C LEARN REPR; Sap M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1668; Schuster Roei, 2020, 30 USENIX SEC S USEN; Scialom T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8051; Shazeer N, 2019, Arxiv, DOI arXiv:1911.02150; Shazeer N, 2020, Arxiv, DOI arXiv:2002.05202; Shazeer N, 2018, PR MACH LEARN RES, V80; Shazeer Noam, 2018, Advances in neural information processing systems, P10414; Sheng Emily, 2021, arXiv; Siddhant A, 2020, AAAI CONF ARTIF INTE, V34, P8854; Singh A, 2015, ACM SIGCOMM COMP COM, V45, P183, DOI 10.1145/2829988.2787508; Smith S, 2022, arXiv; Smith Samuel L., 2018, INT C LEARN REPR ICL; Song KT, 2019, PR MACH LEARN RES, V97; Stanovsky G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1679; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Sue D.W., 2006, INVISIBLE WHITENESS; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Tay Y., 2020, Sparse sinkhorn attention; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Toral A, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P386; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang A, 2019, ADV NEUR IN, V32; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang Yiren, 2019, ARXIV191007512; Webster Kellie, 2020, Scalable cross lingual pivots to model pronoun gender for translation; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2022, P INT C LEARN REPR I; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Welbl J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2447; Xia Y, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P424; XLA, 2019, XLA: Optimizing compiler for TensorFlow; Xu YZ, 2021, Arxiv, DOI arXiv:2105.04663; Xue LT, 2022, Arxiv, DOI arXiv:2105.13626; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yasunaga M., 2020, INT C MACHINE LEARNI, P10799; Yasunaga M, 2021, PR MACH LEARN RES, V139; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174; Zellers R, 2019, Arxiv, DOI arXiv:1905.07830; Zeng W., 2021, PREPRINT; Zhang J., 2020, PMLR, P11328; Zoph B., 2022, arXiv	175	55	57	14	17	MICROTOME PUBL	BROOKLINE	31 GIBBS ST, BROOKLINE, MA 02446 USA	1532-4435			J MACH LEARN RES	J. Mach. Learn. Res.		2023	24								240					113	Automation & Control Systems; Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science	Z6RY7					2024-07-03	WOS:001113340400001
J	Heersmink, R; de Rooij, B; Vazquez, MJC; Colombo, M				Heersmink, Richard; de Rooij, Barend; Vazquez, Maria Jimena Clavel; Colombo, Matteo			A phenomenology and epistemology of large language models: transparency, trust, and trustworthiness	ETHICS AND INFORMATION TECHNOLOGY			English	Article						ChatGPT; Bard; Large language models; Transparency; Cognitive artifacts; Generative AI; Conversational AI; Algorithms; Knowledge; Trust; Big data	KNOWLEDGE; ARTIFACTS; TALKING; BELIEF	This paper analyses the phenomenology and epistemology of chatbots such as ChatGPT and Bard. The computational architecture underpinning these chatbots are large language models (LLMs), which are generative artificial intelligence (AI) systems trained on a massive dataset of text extracted from the Web. We conceptualise these LLMs as multifunctional computational cognitive artifacts, used for various cognitive tasks such as translating, summarizing, answering questions, information-seeking, and much more. Phenomenologically, LLMs can be experienced as a "quasi-other"; when that happens, users anthropomorphise them. For most users, current LLMs are black boxes, i.e., for the most part, they lack data transparency and algorithmic transparency. They can, however, be phenomenologically and informationally transparent, in which case there is an interactional flow. Anthropomorphising and interactional flow can, in some users, create an attitude of (unwarranted) trust towards the output LLMs generate. We conclude this paper by drawing on the epistemology of trust and testimony to examine the epistemic implications of these dimensions. Whilst LLMs generally generate accurate responses, we observe two epistemic pitfalls. Ideally, users should be able to match the level of trust that they place in LLMs to the degree that LLMs are trustworthy. However, both their data and algorithmic opacity and their phenomenological and informational transparency can make it difficult for users to calibrate their trust correctly. The effects of these limitations are twofold: users may adopt unwarranted attitudes of trust towards the outputs of LLMs (which is particularly problematic when LLMs hallucinate), and the trustworthiness of LLMs may be undermined.	[Heersmink, Richard; de Rooij, Barend; Vazquez, Maria Jimena Clavel; Colombo, Matteo] Tilburg Univ, Sch Humanities & Digital Sci, Dept Philosophy, Tilburg, Netherlands	Tilburg University	Heersmink, R (corresponding author), Tilburg Univ, Sch Humanities & Digital Sci, Dept Philosophy, Tilburg, Netherlands.	j.r.heersmink@tilburguniversity.edu						Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Andrada G, 2023, AI SOC, V38, P1321, DOI 10.1007/s00146-021-01326-6; Arkoudas K., 2023, Philosophy Technology, V36, P54, DOI [10.1007/s13347-023-00619-6, DOI 10.1007/S13347-023-00619-6]; Audi R, 1997, AM PHILOS QUART, V34, P405; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bird Jon, 2011, Interactions, V18, P20, DOI 10.1145/2029976.2029983; Bommasani R, 2023, Arxiv, DOI [arXiv:2310.12941, 10.48550/arXiv.2310.12941]; Brey P, 2005, MIND MACH, V15, P383, DOI 10.1007/s11023-005-9003-1; Bricken T, 2023, Transformer Circuits Thread; Bruckman AS, 2022, SHOULD YOU BELIEVE WIKIPEDIA?, P1, DOI 10.1017/9781108780704; Buckner C, 2013, BIOL PHILOS, V28, P853, DOI 10.1007/s10539-013-9376-0; BURGE T, 1993, PHILOS REV, V102, P457, DOI 10.2307/2185680; Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512; Cassinadri G., 2024, Philosophy Technology, V37, P14, DOI [10.1007/s13347-024-00701-7, DOI 10.1007/S13347-024-00701-7]; Chalmers DJ, 2023, Arxiv, DOI [arXiv:2303.07103, DOI 10.48550/ARXIV.2303.07103, 10.48550/arXiv.2303.07103]; Clark A, 1998, ANALYSIS, V58, P7, DOI 10.1111/1467-8284.00096; Clark A., 2003, NATURAL BORN CYBORGS; Clark A, 2007, J MED PHILOS, V32, P263, DOI 10.1080/03605310701397024; de Ridder J, 2022, SOC EPISTEMOL, DOI 10.1080/02691728.2022.2151331; Donald M., 1991, Origins of the modern mind: Three stages in the evolution of culture and cognition; Dotov DG, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0009433; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eschenbach WJ., 2021, Philosophy & Technology, V34, P1607, DOI 10.1007/s13347-021-00477-0; Fallis D, 2008, J AM SOC INF SCI TEC, V59, P1662, DOI 10.1002/asi.20870; Fasoli M, 2018, MIND MACH, V28, P589, DOI 10.1007/s11023-018-9476-3; Frost-Arnold K., 2018, The Routledge Handbook of Applied Epistemology; Frost-Arnold K., 2023, Who should we be online? A social epistemology for the internet, DOI [10.1093/oso/9780190089184.001.0001, DOI 10.1093/OSO/9780190089184.001.0001]; Gillett AJ, 2019, COGN SYST RES, V56, P36, DOI 10.1016/j.cogsys.2019.03.004; Go E, 2019, COMPUT HUM BEHAV, V97, P304, DOI 10.1016/j.chb.2019.01.020; Goldman AI, 2001, PHILOS PHENOMEN RES, V63, P85, DOI 10.2307/3071090; Grindrod J, 2019, INQUIRY, DOI 10.1080/0020174X.2019.1688178; Gunn H., 2018, The Routledge Handbook of Applied Epistemology; Hawley K, 2014, NOUS, V48, P1, DOI 10.1111/nous.12000; Heersmink R, 2024, NAT HUM BEHAV, V8, P805, DOI 10.1038/s41562-024-01859-y; Heersmink R, 2018, SOC EPISTEMOL, V32, P1, DOI 10.1080/02691728.2017.1383530; Heersmink R, 2016, PHILOS EXPLOR, V19, P78, DOI 10.1080/13869795.2014.910310; Heersmink R, 2015, PHENOMENOL COGN SCI, V14, P577, DOI 10.1007/s11097-014-9355-1; Heersmink R, 2013, REV PHILOS PSYCHOL, V4, P465, DOI 10.1007/s13164-013-0148-1; Heidegger J., 1962, BEING TIME; Hu K., 2023, Reuters; Hutchins E., 1995, COGNITION WILD; Ihde D, 1990, Technology and the Lifeworld: From Garden to Earth; Jones K, 2012, ETHICS, V123, P61, DOI 10.1086/667838; KIRSH D, 1994, COGNITIVE SCI, V18, P513, DOI 10.1207/s15516709cog1804_1; Lee K., 2018, ICLR 2019; Leonard N., 2023, The Stanford Encyclopedia of Philosophy; Lynch MichaelP., 2016, Internet of Us: Knowing More and Understanding Less in the Age of Big Data; Magnus PD, 2009, EPISTEME-J INDIV SOC, V6, P74, DOI 10.3366/E1742360008000555; Marks S, 2023, Arxiv, DOI arXiv:2310.06824; Merleau-Ponty Maurice., 1962, PHENOMENOLOGY PERCEP; Miller B, 2017, NEW MEDIA SOC, V19, P1945, DOI 10.1177/1461444816644805; Miller B, 2013, EPISTEME-J INDIV SOC, V10, P117, DOI 10.1017/epi.2013.11; Munn L, 2023, AI SOC, DOI 10.1007/s00146-023-01756-4; Munton J, 2022, INQUIRY, DOI 10.1080/0020174X.2022.2140707; Narayanan D., 2022, Philos. Technol, V35, pE4512, DOI DOI 10.1007/S13347-022-00521-7; Neff G, 2016, INT J COMMUN-US, V10, P4915; Newen Albert, 2018, The Oxford Handbook of 4E Cognition, DOI [10.1093/oxfordhb/9780198735410.013.1, DOI 10.1093/OXFORDHB/9780198735410.001.0001, DOI 10.1093/OXFORDHB/9780198735410.013.1]; Norman D. A., 1993, THINGS MAKE US SMART; Norman D.A., 1998, INVISIBLE COMPUTER; Norman DA., 1991, Designing Interaction, V1, P17; OpenAI, 2023, Gpt-4 system card; Palermos SO, 2011, REV PHILOS PSYCHOL, V2, P741, DOI 10.1007/s13164-011-0075-y; Puri A., 2023, Journal of Human-Technology Relations, DOI [10.59490/jhtr.2023.1.7028, DOI 10.59490/JHTR.2023.1.7028]; Rupert RD, 2010, COGN SYST RES, V11, P343, DOI 10.1016/j.cogsys.2010.04.002; Salles Arleen, 2020, AJOB Neurosci, V11, P88, DOI 10.1080/21507740.2020.1740350; Schwengerer L, 2021, SOC EPISTEMOL, V35, P312, DOI 10.1080/02691728.2020.1815095; Schwitzgebel E, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100818; Shanahan M, 2024, COMMUN ACM, V67, P68, DOI 10.1145/3624724; Simion M., 2023, Asian Journal of Philosophy, V2, P8, DOI [10.1007/s44204-023-00063-5, DOI 10.1007/S44204-023-00063-5]; Simpson TW, 2012, METAPHILOSOPHY, V43, P426, DOI 10.1111/j.1467-9973.2012.01759.x; Smart P., 2021, Social Epistemology Review and Reply Collective, V10, P7; Smart P., 2018, Routledge handbook of applied epistemology; Sosa E., 2006, EPISTEMOLOGY TESTIMO, P116, DOI DOI 10.1093/ACPROF:OSO/9780199276011.003.0006; Tiku N., 2022, The Google engineer who thinks the company's AI has come to life; Varela FJ, 2016, EMBODIED MIND: COGNITIVE SCIENCE AND HUMAN EXPERIENCE, P1; Veliz C, 2023, NATURE, V615, P375, DOI 10.1038/d41586-023-00758-y; Verbeek P.-P., 2015, Technoscience and Postphenomenology: The Manhattan Papers, P189; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wheeler M., 2021, Perspectives interdisciplinaires sur le travail et la sante (PISTES); Wheeler M, 2019, AI SOC, V34, P857, DOI 10.1007/s00146-018-0824-x; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Zerilli J., 2019, PHILOS TECHNOLOGY, V32, P661, DOI [DOI 10.1007/S13347-018-0330-6, https://doi.org/10.1007/s13347-018-0330-6]; Zhao Tony Z, 2021, arXiv	84	0	0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	SEP	2024	26	3							41	10.1007/s10676-024-09777-3	http://dx.doi.org/10.1007/s10676-024-09777-3			15	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	UR2S4		hybrid			2024-07-03	WOS:001249725800001
J	Bai, YZ; Sun, M; Zhang, LM; Wang, YN; Liu, SH; Liu, YQ; Tan, JL; Yang, YQ; Lv, CL				Bai, Yuzhe; Sun, Min; Zhang, Liman; Wang, Yinong; Liu, Sihan; Liu, Yanqiu; Tan, Jingling; Yang, Yingqiu; Lv, Chunli			Enhancing Network Attack Detection Accuracy through the Integration of Large Language Models and Synchronized Attention Mechanism	APPLIED SCIENCES-BASEL			English	Article						network attack detection; large language models; synchronized attention mechanism; deep learning in cybersecurity; cross-domain application of NLP		In this study, we propose a novel method for detecting cyberattack behaviors by leveraging the combined strengths of large language models and a synchronized attention mechanism. Extensive experiments conducted on diverse datasets, including server logs, financial behaviors, and comment data, demonstrate the significant advantages of this method over existing models such as Transformer, BERT, OPT-175B, LLaMa, and ChatGLM3-6B in key performance metrics such as precision, recall, and accuracy. For instance, on the server log dataset, the method achieved a precision of 93%, a recall of 91%, and an accuracy of 92%; on the financial behavior dataset, it reached a precision of 90%, a recall of 87%, and an accuracy of 89%; and on the comment data dataset, it excelled with a precision of 95%, a recall of 93%, and an accuracy of 94%. The introduction of a synchronized attention mechanism and a newly designed synchronized loss function proved especially effective, enhancing the method's ability to process multi-source data and providing superior performance in identifying complex cyberattack patterns. Ablation experiments further validated the crucial roles of these innovations in boosting model performance: the synchronous attention mechanism substantially improved the model's precision, recall, and accuracy to 93%, 89%, and 91% respectively, far exceeding other attention mechanisms. Similarly, the synchronized loss showcased a significant advantage, achieving the best performance across all tested metrics compared to traditional cross-entropy loss, focal loss, and MSE. These results underscore the method's ability to deeply mine and analyze semantic information and contextual relationships within text data as well as to effectively integrate and process multimodal data, thereby offering strong technical support for the accurate and efficient detection of cyberattack behaviors.	[Bai, Yuzhe; Sun, Min; Zhang, Liman; Wang, Yinong; Liu, Sihan; Liu, Yanqiu; Tan, Jingling; Yang, Yingqiu; Lv, Chunli] China Agr Univ, Beijing 100083, Peoples R China	China Agricultural University	Lv, CL (corresponding author), China Agr Univ, Beijing 100083, Peoples R China.	byz@cau.edu.cn; 2021308160227@cau.edu.cn; 2020308130508@cau.edu.cn; wangyinong@cau.edu.cn; liusihan@cau.edu.cn; 2023311320326@cau.edu.cn; 2022308250124@cau.edu.cn; yyq@cau.edu.cn; lvcl@cau.edu.cn			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Alkhalil Z, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.563060; Alraizza A, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7030143; Alshehri A, 2023, COMPUT SYST SCI ENG, V44, P1679, DOI 10.32604/csse.2023.026526; An H, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14010460; Chang Y., 2023, J. ACM, V37, P1, DOI [10.48550/arXiv.2307.03109, DOI 10.48550/ARXIV.2307.03109]; Chen J, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6724513; Chu JJ, 2024, Arxiv, DOI arXiv:2402.02987; Chun J, 2020, COMPUT HUM BEHAV, V113, DOI 10.1016/j.chb.2020.106485; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ebrahimi M, 2020, Arxiv, DOI arXiv:2012.07994; Elnakib O, 2023, J SUPERCOMPUT, V79, P13241, DOI 10.1007/s11227-023-05197-0; Elsaeidy AA, 2020, IEEE ACCESS, V8, P137825, DOI 10.1109/ACCESS.2020.3012411; Fazil M, 2021, IEEE T INF FOREN SEC, V16, P4211, DOI 10.1109/TIFS.2021.3102498; Han K, 2021, ADV NEUR IN; Hazell J, 2023, Arxiv, DOI arXiv:2305.06972; Hu TL, 2023, COMPUT SECUR, V124, DOI 10.1016/j.cose.2022.102990; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kaur J, 2023, ARTIF INTELL REV, V56, P12725, DOI 10.1007/s10462-023-10433-3; Kereopa-Yorke B., 2024, J. Ai Robot. Workplace Autom, V3, P15; Liu Q, 2021, IEEE ACCESS, V9, P57542, DOI 10.1109/ACCESS.2021.3071263; Liu X., 2023, AI Open, DOI [10.1016/j.aiopen.2023.08.012, DOI 10.1016/J.AIOPEN.2023.08.012]; Meddeb R, 2023, SOFT COMPUT, V27, P9425, DOI 10.1007/s00500-023-08324-4; Meng Y, 2020, Arxiv, DOI arXiv:2010.07245; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Min SW, 2022, Arxiv, DOI arXiv:2108.04106; Muthukumar S, 2024, J HIGH SPEED NETW, V30, P251, DOI 10.3233/JHS-230142; Muyang Liu, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P286, DOI 10.1145/3395363.3397375; Nalendra AK, 2021, IOP CONF SER-MAT SCI, V1098, DOI 10.1088/1757-899X/1098/2/022103; Nicholls J, 2021, IEEE ACCESS, V9, P163965, DOI 10.1109/ACCESS.2021.3134076; Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091; Rezaimehr F, 2021, ARTIF INTELL REV, V54, P2011, DOI 10.1007/s10462-020-09898-3; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Song CW, 2024, Arxiv, DOI arXiv:2403.13334; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Viggiato M., 2023, IEEE Trans. Games, P1, DOI [10.1109/TG.2023.3313121, DOI 10.1109/TG.2023.3313121]; Wang DL, 2021, NUCLEIC ACIDS RES, V49, DOI 10.1093/nar/gkab016; Wang YB, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13137429; Wen PC, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION ENGINEERING (RCAE 2021), P165, DOI 10.1109/RCAE53607.2021.9638837; Wu JL, 2022, IEEE DATA MINING, P548, DOI 10.1109/ICDM54844.2022.00065; Xu JC, 2024, Arxiv, DOI arXiv:2403.01038; Yang YJ, 2023, CMC-COMPUT MATER CON, V74, P801, DOI 10.32604/cmc.2023.031907; Yao L, 2024, Arxiv, DOI arXiv:2308.13916; Zhang Y, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13122395; Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595; Zhu EZ, 2023, COGN COMPUT, V15, P1320, DOI 10.1007/s12559-022-10024-4; Zhu JM, 2023, Arxiv, DOI arXiv:2008.06448	47	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAY	2024	14	9							3829	10.3390/app14093829	http://dx.doi.org/10.3390/app14093829			28	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	QH5A8		gold			2024-07-03	WOS:001219988300001
C	Wei, W; Ren, XB; Tang, JB; Wang, QY; Su, LX; Cheng, SQ; Wang, JF; Yin, DW; Huang, C			Assoc computing machinery	Wei, Wei; Ren, Xubin; Tang, Jiabin; Wang, Qinyong; Su, Lixin; Cheng, Suqi; Wang, Junfeng; Yin, Dawei; Huang, Chao			LLMRec: Large Language Models with Graph Augmentation for Recommendation	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Large Language Models; Graph Learning; DataAugmentation; Contentbased Recommendation; Multi-modal Recommendation; Collaborative Filtering; Data Sparsity; Bias in Recommender System		The problem of data sparsity has long been a challenge in recommendation systems, and previous studies have attempted to address this issue by incorporating side information. However, this approach often introduces side effects such as noise, availability issues, and low data quality, which in turn hinder the accurate modeling of user preferences and adversely impact recommendation performance. In light of the recent advancements in large language models (LLMs), which possess extensive knowledge bases and strong reasoning capabilities, we propose a novel framework called LLMRec that enhances recommender systems by employing three simple yet effective LLM-based graph augmentation strategies. Our approach leverages the rich content available within online platforms (e.g., Netflix, MovieLens) to augment the interaction graph in three ways: (i) reinforcing user-item interaction egde, (ii) enhancing the understanding of item node attributes, and (iii) conducting user node profiling, intuitively from the natural language perspective. By employing these strategies, we address the challenges posed by sparse implicit feedback and low-quality side information in recommenders. Besides, to ensure the quality of the augmentation, we develop a denoised data robustification mechanism that includes techniques of noisy implicit feedback pruning and MAE-based feature enhancement that help refine the augmented data and improve its reliability. Furthermore, we provide theoretical analysis to support the effectiveness of LLMRec and clarify the benefits of our method in facilitating model optimization. Experimental results on benchmark datasets demonstrate the superiority of our LLMbased augmentation approach over state-of-the-art techniques. To ensure reproducibility, we have made our code and augmented data publicly available at: https://github.com/HKUDS/LLMRec.git.	[Wei, Wei; Ren, Xubin; Tang, Jiabin; Huang, Chao] Univ Hong Kong, Hong Kong, Peoples R China; [Wang, Qinyong; Su, Lixin; Cheng, Suqi; Wang, Junfeng; Yin, Dawei] Baidu Inc, Beijing, Peoples R China	University of Hong Kong; Baidu	Huang, C (corresponding author), Univ Hong Kong, Hong Kong, Peoples R China.	weiweics@connect.hku.hk; xubinrencs@gmail.com; jiabintang77@gmail.com; wangqinyong@baidu.com; sulixinict@gmail.com; chengsuqi@gmail.com; wangjunfeng@baidu.com; yindawei@acm.org; chaohuang75@gmail.com	Ren, Xubin/KOD-3622-2024	Ren, Xubin/0000-0003-3332-1073; WEI, WEI/0000-0002-6653-3788				Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Chen C, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3373807; Chen Chong, 2023, TOIS, V41, P1; Chen M, 2023, P 16 ACM INT C WEB S, P544, DOI [10.1145/3539597.3570484, DOI 10.1145/3539597.3570484]; Chen Z, 2023, Arxiv, DOI arXiv:2305.07622; Dai SH, 2023, Arxiv, DOI arXiv:2305.02182; Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488; Fu XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2331, DOI 10.1145/3366423.3380297; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; He RN, 2016, AAAI CONF ARTIF INTE, P144; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Huang TL, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3447548.3467408; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Ko H, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010141; Lee D, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P317, DOI 10.1145/3404835.3462935; Li Jiacheng, 2023, ACM SIGKDD C KNOWL D; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Liang K., 2023, arXiv; Liang K, 2024, IEEE T KNOWL DATA EN, V36, P226, DOI 10.1109/TKDE.2023.3282989; Liang K, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1559, DOI 10.1145/3539618.3591711; Liang K, 2022, Arxiv, DOI [arXiv:2212.05767, DOI 10.48550/ARXIV.2212.05767]; Liu ZW, 2021, Arxiv, DOI arXiv:2108.06479; Liu ZW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1608, DOI 10.1145/3404835.3463036; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Meng C, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P4649, DOI 10.1145/3580305.3599838; Meng C, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P1797, DOI 10.1145/3583780.3615004; Meng Chang, 2023, ACM Transactions on Information Systems, V42, P1; Paszke A, 2019, ADV NEUR IN, V32; Petrov A, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P81, DOI 10.1145/3523227.3546785; Radford A, 2021, PR MACH LEARN RES, V139; Ren XB, 2024, Arxiv, DOI arXiv:2310.15950; Ren XB, 2024, Arxiv, DOI arXiv:2308.05697; Rendle S, 2012, Arxiv, DOI arXiv:1205.2618; Tang JB, 2024, Arxiv, DOI arXiv:2310.13023; Tian Y, 2023, P AAAI C ART INT, V37, P9997; Tian YJ, 2023, Arxiv, DOI arXiv:2309.15427; Tian YJ, 2023, Arxiv, DOI arXiv:2302.00219; Tian Yijun, 2022, 11 INT C LEARN REPR; Wang WJ, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P373, DOI 10.1145/3437963.3441800; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wang XD, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P165, DOI 10.1145/3331184.3331267; Wang ZL, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P347, DOI 10.1145/3404835.3462855; Wei Wei, 2023, WWW '23: Proceedings of the ACM Web Conference 2023, P790, DOI 10.1145/3543507.3583206; Wei W, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P338, DOI 10.1145/3604915.3608807; Wei W, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1120, DOI 10.1145/3488560.3498527; Wei YW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3541, DOI 10.1145/3394171.3413556; Wei YW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5382, DOI 10.1145/3474085.3475665; Wei YW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1437, DOI 10.1145/3343031.3351034; Wei Yinwei, 2021, Transactions on Multimedia (TMM); Wu JC, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P726, DOI 10.1145/3404835.3462862; Yi ZX, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1807, DOI 10.1145/3477495.3532027; Ying Yuxin, 2023, P ACM WEB C 2023, P1396; Yu JL, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1294, DOI 10.1145/3477495.3531937; Yuan Zheng, 2023, ACM SIGIR C RES DEV; Zhang HL, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3578361; Zhang JH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3872, DOI 10.1145/3474085.3475259; Zhang Jinghao, 2022, TKDE; Zhang JJ, 2023, Arxiv, DOI arXiv:2305.07001; Zhang SY, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P367, DOI 10.1145/3404835.3462908; Zou D, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1358, DOI 10.1145/3477495.3532025	61	1	1	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							806	815		10.1145/3616855.3635853	http://dx.doi.org/10.1145/3616855.3635853			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN		Green Submitted			2024-07-03	WOS:001182230100090
J	Markowitz, DM; Hancock, JT				Markowitz, David M.; Hancock, Jeffrey T.			Generative AI Are More Truth-Biased Than Humans: A Replication and Extension of Core Truth-Default Theory Principles	JOURNAL OF LANGUAGE AND SOCIAL PSYCHOLOGY			English	Article						artificial intelligence; large language models; truth-bias; deception detection; truth-default theory	DECEPTION	Humans often display a truth-bias-the perception that others are honest independent of message veracity-but does this phenomenon extend to generative artificial intelligence (AI)? We had humans and large language models make nearly 1,000 veracity judgments across different prompts. Human detection accuracies were near chance (50%-53%) with notable truth-biases (59%-64%); AI had a substantially greater truth-bias than humans (67%-99%). GPT-4 was also truth-default, not suspecting deception when veracity assessments were unprompted. Together, people and AI judge most information to be true.	[Markowitz, David M.] Michigan State Univ, Dept Commun, E Lansing, MI USA; [Hancock, Jeffrey T.] Stanford Univ, Dept Commun, Stanford, CA USA; [Markowitz, David M.] Michigan State Univ, Dept Commun, 404 Wilson Rd, E Lansing, MI 48824 USA	Michigan State University; Stanford University; Michigan State University	Markowitz, DM (corresponding author), Michigan State Univ, Dept Commun, 404 Wilson Rd, E Lansing, MI 48824 USA.	dmm@msu.edu		Markowitz, David/0000-0002-7159-7014				Clare DD, 2019, HUM COMMUN RES, V45, P286, DOI 10.1093/hcr/hqz001; DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74; GILBERT DT, 1991, AM PSYCHOL, V46, P107, DOI 10.1037/0003-066X.46.2.107; Hartwig M, 2011, PSYCHOL BULL, V137, P643, DOI 10.1037/a0023589; Levine T.R., 2020, DUPED TRUTH DEFAULT; Levine TR, 2014, J LANG SOC PSYCHOL, V33, P378, DOI 10.1177/0261927X14535916; Lloyd E, 2019, BEHAV RES METHODS, V51, P429, DOI 10.3758/s13428-018-1061-4; Luke TJ, 2019, PERSPECT PSYCHOL SCI, V14, P646, DOI 10.1177/1745691619838258; Markowitz DM, 2020, PSYCHOL CRIME LAW, V26, P287, DOI 10.1080/1068316X.2019.1652751; McCornack S.A., 1986, COMMUNICATION YB, V9, P377, DOI DOI 10.1080/23808985.1986.11678616; Ott M, 2011, ACL HLT 2011 P 49 AN, V1, P309, DOI DOI 10.1145/2567948.2577293; Pennebaker JW., 2022, LINGUISTIC INQUIRY W; Vrij A., 2008, DETECTING LIES DECEI; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w	14	2	2	29	29	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0261-927X	1552-6526		J LANG SOC PSYCHOL	J. Lang. Soc. Psychol.	MAR	2024	43	2					261	267		10.1177/0261927X231220404	http://dx.doi.org/10.1177/0261927X231220404		DEC 2023	7	Communication; Linguistics; Psychology, Social	Social Science Citation Index (SSCI)	Communication; Linguistics; Psychology	HB2K5					2024-07-03	WOS:001127456800001
J	Duong, D; Solomon, BD				Duong, Dat; Solomon, Benjamin D.			Analysis of large-language model versus human performance for genetics questions	EUROPEAN JOURNAL OF HUMAN GENETICS			English	Article								Large-language models like ChatGPT have recently received a great deal of attention. One area of interest pertains to how these models could be used in biomedical contexts, including related to human genetics. To assess one facet of this, we compared the performance of ChatGPT versus human respondents (13,642 human responses) in answering 85 multiple-choice questions about aspects of human genetics. Overall, ChatGPT did not perform significantly differently (p = 0.8327) than human respondents; ChatGPT was 68.2% accurate, compared to 66.6% accuracy for human respondents. Both ChatGPT and humans performed better on memorization-type questions versus critical thinking questions (p < 0.0001). When asked the same question multiple times, ChatGPT frequently provided different answers (16% of initial responses), including for both initially correct and incorrect answers, and gave plausible explanations for both correct and incorrect answers. ChatGPT's performance was impressive, but currently demonstrates significant shortcomings for clinical or other high-stakes use. Addressing these limitations will be important to guide adoption in real-life situations.	[Duong, Dat; Solomon, Benjamin D.] Natl Human Genome Res Inst, Med Genet Branch, Med Genom Unit, Bethesda, MD 20894 USA	National Institutes of Health (NIH) - USA; NIH National Human Genome Research Institute (NHGRI)	Solomon, BD (corresponding author), Natl Human Genome Res Inst, Med Genet Branch, Med Genom Unit, Bethesda, MD 20894 USA.	solomonb@mail.nih.gov			Intramural Research Program of the National Human Genome Research Institute, National Institutes of Health	Intramural Research Program of the National Human Genome Research Institute, National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI))	This research was supported by the Intramural Research Program of the National Human Genome Research Institute, National Institutes of Health.	DeGrave AJ, 2021, NAT MACH INTELL, V3, P610, DOI 10.1038/s42256-021-00338-7; Dias R, 2019, GENOME MED, V11, DOI 10.1186/s13073-019-0689-8; Hanchard SEL, 2022, GENET MED, V24, P1593, DOI 10.1016/j.gim.2022.04.025; Jaganathan K, 2019, CELL, V176, P535, DOI 10.1016/j.cell.2018.12.015; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Poplin R, 2018, NAT BIOTECHNOL, V36, P983, DOI 10.1038/nbt.4235; Schaefer J, 2020, ORPHANET J RARE DIS, V15, DOI 10.1186/s13023-020-01424-6; Shelmerdine SC, 2022, BMJ-BRIT MED J, V379, DOI 10.1136/bmj-2022-072826; Singhal K, 2022, ARXIV; Solomon BD, 2023, AM J MED GENET A, V191, P659, DOI 10.1002/ajmg.a.63060; Tekendo-Ngongang C, 2020, AM J MED GENET A, V182, P2939, DOI 10.1002/ajmg.a.61888; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	12	39	39	44	73	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	1018-4813	1476-5438		EUR J HUM GENET	Eur. J. Hum. Genet.	APR	2024	32	4					466	468		10.1038/s41431-023-01396-8	http://dx.doi.org/10.1038/s41431-023-01396-8		MAY 2023	3	Biochemistry & Molecular Biology; Genetics & Heredity	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Genetics & Heredity	NC1C7	37246194	Green Published			2024-07-03	WOS:000995996800001
J	Tikhonova, E; Raitskaya, L				Tikhonova, Elena; Raitskaya, Lilia			ChatGPT: Where Is a Silver Lining? Exploring the realm of GPT and large language models	JOURNAL OF LANGUAGE AND EDUCATION			English	Editorial Material						generative pre-trained transformers (GPT); ChatGPT; artificial intelligence (AI); AI chatbots; natural language processing (NLP); large language model (LLM)		Introduction: the JLE editors analyse the scope and depth of the subject area of ChatGPT and related topics based on the Scopus database. The Scopus statistics prove a skyrocketing rise in the number of publications in the field in question during 2023. The major alarming themes cover authorship and integrity related to AI-assisted writing, threats to educational practices, medicine, and malevolent uses of ChatGPT. Keywords Explained: the key terminology is defined, including generative pre-trained transformers (GPT); ChatGPT; artificial intelligence (AI); AI chatbots; natural language processing (NLP); large language models; Open AI; large language model (LLM). International Research on ChatGPT: as of September 24 2023, the Scopus database has indexed 1,935 publications, with "ChatGPT" in the title, abstract, or keywords. A skyrocketing rise in the number of research has been reported since the early days of 2023. 1,925 indexed publications out of 1,935 were published in 2023. Most of them came from the USA, India, the UK, and China. The number of documents indexed in the Scopus database as well as PubMed, arXiv and others are exponentially rising. ChatGPT in education: the academic community has been actively discussing the challenges education will face in the era of ChatGPT in the context of the fundamental threats posed to the educational system. The latter include assessment procedures, information accuracy, and skill devaluation. As many complex technologies, generative pre-trained transformers are ambivalent in nature, providing a great potential for learning and education at large, including new approaches based on critical thinking and awareness of the pros and cons of AI. ChatGPT in science: great prospects for text generation and improvements in language quality adjoin to dubious authorship and potentially inconsistent and erroneous parts in the AI-produced texts. Publishers and journals are working out new publishing policies, including publishing ethics towards AI-assisted or AI-improved submissions. Conclusion: JLE is planning to revise its editorial policy to address the new challenges from AI technologies. JLE editors welcome new submissions of research articles and reviews as well as special issues on ChatGPT and related themes, with potential applications of chatbots in education, innovative approaches to writing assignments, facilitating personalized learning, academic integrity issues related to AI-supported writing, etc. in focus.	[Tikhonova, Elena] Natl Res Univ Higher Sch Econ, Moscow, Russia; [Tikhonova, Elena] RUDN Univ, Peoples Friendship Univ Russia, Moscow, Russia; [Raitskaya, Lilia] MGIMO Univ, Moscow State Inst Int Relat, Moscow, Russia	HSE University (National Research University Higher School of Economics); Peoples Friendship University of Russia; MGIMO University	Tikhonova, E (corresponding author), Natl Res Univ Higher Sch Econ, Moscow, Russia.; Tikhonova, E (corresponding author), RUDN Univ, Peoples Friendship Univ Russia, Moscow, Russia.	etihonova@hse.ru	Tikhonova, Elena/B-1951-2015	Tikhonova, Elena/0000-0001-8252-6150				Alasadi EA, 2023, J CHEM EDUC, V100, P2965, DOI 10.1021/acs.jchemed.3c00323; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Crompton H, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00392-8; Farazouli A, 2024, ASSESS EVAL HIGH EDU, V49, P363, DOI 10.1080/02602938.2023.2241676; Firat M., 2023, Journal of Applied Learning and Teaching, V1, P57; Fuchs K, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1166682; Fyfe P, 2023, AI SOC, V38, P1395, DOI 10.1007/s00146-022-01397-z; Ho WLJ, 2023, SURG PRACT SCI, V14, DOI 10.1016/j.sipas.2023.100185; Huber E, 2024, ASSESS EVAL HIGH EDU, V49, P102, DOI 10.1080/02602938.2023.2183487; Hufton AL, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100731; Illia L, 2023, BUS ETHICS ENV RESP, V32, P201, DOI 10.1111/beer.12479; Ivakhnenko E. N., 2023, Higher Education in Russia, V32, P9, DOI [10.31992/0869-3617-2023-32-4-9-22, DOI 10.31992/0869-3617-2023-32-4-9-22]; Kikalishvili S, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2220401; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Misra DP, 2023, J ROY COLL PHYS EDIN, V53, P90, DOI 10.1177/14782715231181023; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Qasem Fawaz, 2023, Library Hi Tech News, P30, DOI 10.1108/LHTN-03-2023-0043; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Rudolph J., 2023, JALT, V6, P364, DOI [10.37074/jalt.2023.6.1.23, DOI 10.37074/JALT.2023.6.1.23]; Schäfer MS, 2023, JCOM-J SCI COMMUN, V22, DOI 10.22323/2.22020402; Steele J L., 2023, Computers and Education: Artificial Intelligence, V5, P1; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Su JH, 2023, ECNU REV EDUC, V6, P355, DOI 10.1177/20965311231168423; Tang GY, 2023, IRISH J MED SCI, V192, P3195, DOI 10.1007/s11845-023-03374-x; Tewari Shubhra, 2021, ACM Digital Threats: Research Practice, V2, DOI 10.1145/3428158; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tollefson J, 2023, NATURE, V613, P621, DOI 10.1038/d41586-022-03307-1; Yeo MA, 2023, TESOL J, V14, DOI 10.1002/tesj.716	30	2	2	38	43	NATL RESEARCH UNIV HIGHER SCH ECONOMICS	MOSCOW	SHABOLOVKA, 26, MOSCOW, 119049, RUSSIA		2411-7390		J LANG EDUC	J. Lang. Educ.		2023	9	3					5	11		10.17323/jle.2023.18119	http://dx.doi.org/10.17323/jle.2023.18119			7	Education & Educational Research; Linguistics	Emerging Sources Citation Index (ESCI)	Education & Educational Research; Linguistics	Y3XD3		gold			2024-07-03	WOS:001104620100001
C	Mysore, S; McCallum, A; Zamani, H			ACM	Mysore, Sheshera; McCallum, Andrew; Zamani, Hamed			Large Language Model Augmented Narrative Driven Recommendations	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery				Narrative-driven recommendation (NDR) presents an information access problem where users solicit recommendations with verbose descriptions of their preferences and context, for example, travelers soliciting recommendations for points of interest while describing their likes/dislikes and travel circumstances. These requests are increasingly important with the rise of natural language-based conversational interfaces for search and recommendation systems. However, NDR lacks abundant training data for models, and current platforms commonly do not support these requests. Fortunately, classical user-item interaction datasets contain rich textual data, e.g., reviews, which often describe user preferences and context - this may be used to bootstrap training for NDR models. In this work, we explore using large language models (LLMs) for data augmentation to train NDR models. We use LLMs for authoring synthetic narrative queries from user-item interactions with fewshot prompting and train retrieval models for NDR on synthetic queries and user-item interaction data. Our experiments demonstrate that this is an effective strategy for training small-parameter retrieval models that outperform other retrieval and LLM baselines for narrative-driven recommendation.	[Mysore, Sheshera; McCallum, Andrew; Zamani, Hamed] Univ Massachusetts, Amherst, MA 01003 USA	University of Massachusetts System; University of Massachusetts Amherst	Mysore, S (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.	smysore@cs.umass.edu; mccallum@cs.umass.edu; hzamani@cs.umass.edu		Zamani, Hamed/0000-0002-0800-3340	Center for Intelligent Information Retrieval; NSF [IIS-1922090, 2143434]; Office of Naval Research [N000142212688]; Amazon Alexa Prize grant; Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction	Center for Intelligent Information Retrieval; NSF(National Science Foundation (NSF)); Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research); Amazon Alexa Prize grant; Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction(Chan Zuckerberg Initiative (CZI))	We thank anonymous reviewers for their invaluable feedback. This work was partly supported by the Center for Intelligent Information Retrieval, NSF grants IIS-1922090 and 2143434, the Office of Naval Research contract number N000142212688, an Amazon Alexa Prize grant, and the Chan Zuckerberg Initiative under the project Scientific Knowledge Base Construction. Any opinions, findings and conclusions or recommendations expressed here are those of the authors and do not necessarily reflect those of the sponsors.	Afzali J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2478, DOI 10.1145/3404835.3463243; Arguello J, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P5, DOI 10.1145/3406522.3446021; Bogers T, 2018, LECT NOTES COMPUT SC, V10766, P323, DOI 10.1007/978-3-319-78105-1_36; Bogers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P238, DOI 10.1145/3109859.3109893; Bogers Toine, 2018, KNOWLEDGEAWARE CONVE; Bogers Toine, 2019, STUDY RELEVANCE ASPE, V14, P503; Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863; Boytsov L, 2024, Arxiv, DOI arXiv:2301.02998; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buckley C., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P25, DOI 10.1145/1008992.1009000; Chae DK, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1251, DOI 10.1145/3397271.3401038; Chen Lei, 2023, P ACM WEB C 2023 AUS, P1012, DOI [10.1145/3543507.3583341, DOI 10.1145/3543507.3583341]; Chen L, 2022, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2022, DOI 10.1145/3543829.3544530; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai Zhuyun, 2023, 11 INT C LEARNING RE; Das M., 2007, P 16 INT C WORLD WID, P271; Davidson J., 2010, P 4 ACM C RECOMMENDE, P293, DOI DOI 10.1145/1864708.1864770; Eberhard L, 2019, PROCEEDINGS OF IUI 2019, P1, DOI 10.1145/3301275.3302287; Gao L., 2022, arXiv; Hariri N., 2013, P 7 ACM C REC SYST, P9, DOI DOI 10.1145/2507157.2507187; Hashemi Seyyed Hadi, 2016, TREC; Izacard Gautier, 2022, T MACHINE LEARNING R; Jeronymo V, 2023, Arxiv, DOI [arXiv:2301.01820, DOI 10.48550/ARXIV.2301.01820]; Koolen M, 2016, LECT NOTES COMPUT SC, V9822, P351, DOI 10.1007/978-3-319-44564-9_29; Leszczynski M, 2023, Arxiv, DOI arXiv:2301.11489; Liu X, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P733; Liu YD, 2017, PROC VLDB ENDOW, V10, P1010, DOI 10.14778/3115404.3115407; Lopez F., 2021, arXiv; Lu XH, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P2799; Luo K, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2535, DOI 10.1145/3366423.3380003; Ma J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1075; Mysore Sheshera, 2021, THIRTYFIFTH C NEURAL, DOI [10.48550/arXiv.2103.12906, DOI 10.48550/ARXIV.2103.12906]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papenmeier A, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P261, DOI 10.1145/3406522.3446035; Penha Gustavo, 2023, P ACM WEB C 2023 AUS, P3182, DOI [DOI 10.1145/3543507.3583261, 10.1145/3543507.3583261]; Radlinski F, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2863, DOI 10.1145/3477495.3531873; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Saad-Falcon J, 2023, Arxiv, DOI [arXiv:2303.00807, 10.48550/arXiv.2303.00807, DOI 10.48550/ARXIV.2303.00807]; Sachan D.S., 2022, P 2022 C EMP METH NA, P3781, DOI DOI 10.18653/V1/2022.EMNLP; Song K., 2020, ADV NEURAL INFORM PR, V33; Teevan J., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P449, DOI 10.1145/1076034.1076111; Wan MT, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P86, DOI 10.1145/3240323.3240369; Wang HN, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P768, DOI 10.1145/3442381.3449963; Wang QY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P548, DOI 10.1145/3292500.3330873; Xu JJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P502, DOI 10.1145/3523227.3547394; Ying Yuxin, 2023, P ACM WEB C 2023, P1396; Zamani H., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08808; Zou J, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P881, DOI 10.1145/3397271.3401180	49	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							777	783		10.1145/3604915.3608829	http://dx.doi.org/10.1145/3604915.3608829			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Green Submitted			2024-07-03	WOS:001156630300083
J	Küchemann, S; Steinert, S; Revenga, N; Schweinberger, M; Dinc, Y; Avila, KE; Kuhn, J				Kuechemann, Stefan; Steinert, Steffen; Revenga, Natalia; Schweinberger, Matthias; Dinc, Yavuz; Avila, Karina E.; Kuhn, Jochen			Can ChatGPT support prospective teachers in physics task development?	PHYSICAL REVIEW PHYSICS EDUCATION RESEARCH			English	Article							KNOWLEDGE; CONTEXT	The recent advancement of large language models presents numerous opportunities for teaching and learning. Despite widespread public debate regarding the use of large language models, empirical research on their opportunities and risks in education remains limited. In this work, we demonstrate the qualities and shortcomings of using ChatGPT 3.5 for physics task development by prospective teachers. In a randomized controlled trial, 26 prospective physics teacher students were divided into two groups: the first group used ChatGPT 3.5 to develop text-based physics tasks for four different concepts in the field of kinematics for 10th-grade high school students, while the second group used a classical textbook to create tasks for the same concepts and target group. The results indicate no difference in task correctness, but students using the textbook achieved a higher clarity and more frequently embedded their questions in a meaningful context. Both groups adapted the level of task difficulty easily to the target group but struggled strongly with sufficient task specificity, i.e., relevant information to solve the tasks was missing. Students using ChatGPT for problem posing rated high system usability but experienced difficulties with output quality. These results provide insights into the opportunities and pitfalls of using large language models in education.	[Kuechemann, Stefan; Steinert, Steffen; Revenga, Natalia; Schweinberger, Matthias; Dinc, Yavuz; Kuhn, Jochen] Ludwig Maximilians Univ Munchen LMU Munich, Chair Phys Educ, Fac Phys, Geschwister Scholl Pl 1, D-80539 Munich, Germany; [Avila, Karina E.] RPTU Kaiserslautern Landau, Dept Math, Paul Ehrlich Str 14, D-67663 Kaiserslautern, Germany	University of Munich	Küchemann, S (corresponding author), Ludwig Maximilians Univ Munchen LMU Munich, Chair Phys Educ, Fac Phys, Geschwister Scholl Pl 1, D-80539 Munich, Germany.	s.kuechemann@lmu.de	; Kuhn, Jochen/K-4031-2014	Kuchemann, Stefan/0000-0003-2729-1592; Steinert, Steffen/0000-0001-6364-934X; Avila, karina/0000-0002-2087-3592; Kuhn, Jochen/0000-0002-6985-3218	LMUexcellent - Federal Ministry of Education and Research (BMBF); Free State of Bavaria under the Excellence Strategy of the Federal Government and the Lander	LMUexcellent - Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); Free State of Bavaria under the Excellence Strategy of the Federal Government and the Lander	This research was supported by LMUexcellent, funded by the Federal Ministry of Education and Research (BMBF) and the Free State of Bavaria under the Excellence Strategy of the Federal Government and the Lander.	Abdelghani R, 2022, Arxiv, DOI [arXiv:2211.14228, arXiv:2211.14228, 10.48550/ARXIV.2211.14228, DOI 10.48550/ARXIV.2211.14228]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Airasian P. W., 2001, Classroom assessment: Concepts and applications; Akben N, 2020, RES SCI EDUC, V50, P1143, DOI 10.1007/s11165-018-9726-7; Anderson L. W., 2021, A Taxonomy for Learning, Teaching and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives; [Anonymous], 1986, Handbook of Research on Teaching; [Anonymous], 2002, Contemporary Issues in Early Childhood; [Anonymous], 1990, EDUC MEAS-ISSUES PRA, V9, P30, DOI [10.1111/j.1745-3992.1990.tb00391.x, DOI 10.1111/J.1745-3992.1990.TB00391.X]; Bao M, 2019, ArabWorld Eng. J. (AWEJ), DOI [10.2139/ssrn.3431734, DOI 10.2139/SSRN.3431734]; Bernius JP., 2022, Computers and Education: Artificial Intelligence, V3, P100081, DOI [DOI 10.1016/J.CAEAI.2022.100081, 10.1016/j.caeai.2022.100081]; Bhat S., 2022, P 15 INT C ED DATA M, V701; Bonotto C, 2013, EDUC STUD MATH, V83, P37, DOI 10.1007/s10649-012-9441-7; Brookhart S.M., 2011, Educational Measurement: Issues and Practice, V30, P3, DOI [DOI 10.1111/J.1745-3992.2010.00195.X, https://doi.org/10.1111/j.1745-3992.2010.00195.x]; Cai J., 2002, J. Math. Behav, V21, P401; Cai JF, 2020, EDUC STUD MATH, V105, P287, DOI 10.1007/s10649-020-10008-x; Cai JF, 2020, INT J EDUC RES, V102, DOI 10.1016/j.ijer.2019.01.001; Chen G., 2018, P INT AAAI C WEB SOC, V12, DOI [10.1609/icwsm.v12i1.14987, DOI 10.1609/ICWSM.V12I1.14987]; Chocarro R, 2023, EDUC STUD-UK, V49, P295, DOI 10.1080/03055698.2020.1850426; Crespo S., 2003, Educational Studies in Mathematics, V52, P243, DOI DOI 10.1023/A:1024364304664; Crespo S, 2008, J MATH TEACH EDUC, V11, P395, DOI 10.1007/s10857-008-9081-0; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dietrich R., 2022, Physik 10; Edwards R., 2015, BRIT SOC RES LEARNIN; Eyal L, 2012, EDUC TECHNOL SOC, V15, P37; Fischer H. E., 2022, Physics Education, P231; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao Leo, 2022, arXiv, DOI 10.48550/arXiv.2210.10760; Gess-Newsome J, 2019, INT J SCI EDUC, V41, P944, DOI 10.1080/09500693.2016.1265158; Han J, 2015, PHYS REV SPEC TOP-PH, V11, DOI 10.1103/PhysRevSTPER.11.010112; Holmes W., 2020, Artificial Intelligence in Education; Jeon J, 2023, COMPUT ASSIST LANG L, V36, P1338, DOI 10.1080/09588221.2021.1987272; Jia QJ, 2021, Arxiv, DOI [arXiv:2110.03895, DOI 10.48550/ARXIV.2110.03895, 10.48550/arXiv.2110.03895]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kleickmann T, 2013, J TEACH EDUC, V64, P90, DOI 10.1177/0022487112460398; Koichu B, 2013, INSTR SCI, V41, P681, DOI 10.1007/s11251-012-9254-1; Kuhn J., 2014, Perspectives in Science, V2, P5; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lee Y., 2018, Int. Electron. J. Mathemat. Educ, V13, P75, DOI [10.12973/iejme/2698, DOI 10.12973/IEJME/2698]; Leisen J., 2001, Math. Naturwiss. Unterr., V54, P401; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Löffler P, 2018, INT J SCI EDUC, V40, P1935, DOI 10.1080/09500693.2018.1514673; Mertler C.A., 1998, CLASSROOM ASSESSMENT; Neumann K, 2013, J RES SCI TEACH, V50, P162, DOI 10.1002/tea.21061; O'Kuma T.L., 2000, RANKING TASK EXERCIS; OpenAI, 2022, Introducing chatgpt; OpenAI, 2023, Openai chat; OpenAI, 2023, GPT-4: Advanced ai language model; Osborne JF, 2016, J RES SCI TEACH, V53, P821, DOI 10.1002/tea.21316; Polak S, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519866; Popham W. J., 2003, Educational Measurement, V22, P45; Pozas M., 2020, Open Educ. Stud., V2, P112; Raina V, 2022, Arxiv, DOI arXiv:2209.11830; Rodriguez-Torrealba R, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118258; Rowland T, 2005, J MATH TEACH EDUC, V8, P255, DOI 10.1007/s10857-005-0853-5; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schaefer M, 2009, HUM BRAIN MAPP, V30, P2722, DOI 10.1002/hbm.20701; SHULMAN LS, 1987, HARVARD EDUC REV, V57, P1, DOI 10.17763/haer.57.1.j463w79r56455411; Silver E.A., 1994, LEARN MATH, V14, P19; Silver EA, 1996, J RES MATH EDUC, V27, P521, DOI 10.2307/749846; Sinaga P, 2017, INT J INSTR, V10, P69, DOI 10.12973/iji.2017.1025a; Stiggins R. J., 1999, High School Magazine, V6, P20; Tai TY, 2023, INTERACT LEARN ENVIR, V31, P1485, DOI 10.1080/10494820.2020.1841801; Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926; Villarroel V, 2020, INNOV EDUC TEACH INT, V57, P38, DOI 10.1080/14703297.2018.1564882; Zhu MX, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103668	65	7	7	32	32	AMER PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	2469-9896			PHYS REV PHYS EDUC R	Phys. Rev. Phys. Educ. Res.	SEP 11	2023	19	2							020128	10.1103/PhysRevPhysEducRes.19.020128	http://dx.doi.org/10.1103/PhysRevPhysEducRes.19.020128			14	Education & Educational Research; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Education & Educational Research	KD1L7		gold, Green Submitted			2024-07-03	WOS:001177929400001
J	Wang, AY; Liu, C; Yang, JY; Weng, CH				Wang, Andy; Liu, Cong; Yang, Jingye; Weng, Chunhua			Fine-tuning large language models for rare disease concept normalization	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						large language model; concept normalization; Llama 2; HPO; fine-tuning		Objective We aim to develop a novel method for rare disease concept normalization by fine-tuning Llama 2, an open-source large language model (LLM), using a domain-specific corpus sourced from the Human Phenotype Ontology (HPO).Methods We developed an in-house template-based script to generate two corpora for fine-tuning. The first (NAME) contains standardized HPO names, sourced from the HPO vocabularies, along with their corresponding identifiers. The second (NAME+SYN) includes HPO names and half of the concept's synonyms as well as identifiers. Subsequently, we fine-tuned Llama 2 (Llama2-7B) for each sentence set and conducted an evaluation using a range of sentence prompts and various phenotype terms.Results When the phenotype terms for normalization were included in the fine-tuning corpora, both models demonstrated nearly perfect performance, averaging over 99% accuracy. In comparison, ChatGPT-3.5 has only similar to 20% accuracy in identifying HPO IDs for phenotype terms. When single-character typos were introduced in the phenotype terms, the accuracy of NAME and NAME+SYN is 10.2% and 36.1%, respectively, but increases to 61.8% (NAME+SYN) with additional typo-specific fine-tuning. For terms sourced from HPO vocabularies as unseen synonyms, the NAME model achieved 11.2% accuracy, while the NAME+SYN model achieved 92.7% accuracy.Conclusion Our fine-tuned models demonstrate ability to normalize phenotype terms unseen in the fine-tuning corpus, including misspellings, synonyms, terms from other ontologies, and laymen's terms. Our approach provides a solution for the use of LLMs to identify named medical entities from clinical narratives, while successfully normalizing them to standard concepts in a controlled vocabulary.	[Wang, Andy] Peddie Sch, Hightstown, NJ 08520 USA; [Wang, Andy; Liu, Cong; Weng, Chunhua] Columbia Univ, Dept Biomed Informat, 622 West 168 St,PH 20 room 407, New York, NY 10032 USA; [Yang, Jingye] Univ Penn, Dept Math, Philadelphia, PA 19104 USA	Columbia University; University of Pennsylvania	Weng, CH (corresponding author), Columbia Univ, Dept Biomed Informat, 622 West 168 St,PH 20 room 407, New York, NY 10032 USA.	cw2384@cumc.columbia.edu		Weng, Chunhua/0000-0002-9624-0214	NIH [LM012895, HG012655, HG013031]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by NIH grant number LM012895, HG012655, and HG013031.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733; Aronson AR, 2001, J AM MED INFORM ASSN, P17; Chen L, 2020, J AM MED INFORM ASSN, V27, P1576, DOI 10.1093/jamia/ocaa155; El-Sappagh S, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0651-5; Garcelon N, 2018, ORPHANET J RARE DIS, V13, DOI 10.1186/s13023-018-0830-6; Gillioz A., 2020, 2020 15 C COMP SCI I; Henriksson A, 2023, ARTIF INTELL MED, V146, DOI 10.1016/j.artmed.2023.102695; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hudson LD, 2018, CTS-CLIN TRANSL SCI, V11, P342, DOI 10.1111/cts.12556; Kodra Y, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15081644; Köhler S, 2009, AM J HUM GENET, V85, P457, DOI 10.1016/j.ajhg.2009.09.003; Kormilitzin A, 2021, ARTIF INTELL MED, V118, DOI 10.1016/j.artmed.2021.102086; Liu C, 2019, NUCLEIC ACIDS RES, V47, pW566, DOI 10.1093/nar/gkz386; McCandless M., 2010, Lucene in Action; Meijlink JM, 2015, TRANSL ANDROL UROL, V4, P499, DOI 10.3978/j.issn.2223-4683.2015.08.02; Mirsaeidi M, 2017, CHEST, V151, P947, DOI 10.1016/j.chest.2017.02.013; Mullin AP, 2021, CTS-CLIN TRANSL SCI, V14, P214, DOI 10.1111/cts.12845; Pariser AR, 2014, J GEN INTERN MED, V29, pS804, DOI 10.1007/s11606-014-2881-2; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Shi LL, 2014, BMC MED GENOMICS, V7, DOI 10.1186/s12920-014-0066-9; Silva JF, 2020, STUD HEALTH TECHNOL, V270, P93, DOI 10.3233/SHTI200129; Tingley K, 2018, ORPHANET J RARE DIS, V13, DOI 10.1186/s13023-018-0851-1; Tinn R, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100729; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wilson Donna, 2008, J AHIMA, V79, P54; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Yang JY, 2024, PATTERNS, V5, DOI 10.1016/j.patter.2023.100887; Yang ZL, 2019, ADV NEUR IN, V32; Zhao MG, 2020, NAR GENOM BIOINFORM, V2, DOI 10.1093/nargab/lqaa032	31	0	0	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 JUN 3	2024										10.1093/jamia/ocae133	http://dx.doi.org/10.1093/jamia/ocae133		JUN 2024	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	SV7W6	38829731	Green Submitted			2024-07-03	WOS:001237300000001
C	Yin, B; Xie, JJ; Qin, Y; Ding, ZX; Feng, ZC; Li, X; Lin, W			ACM	Yin, Bin; Xie, JunJie; Qin, Yu; Ding, ZiXiang; Feng, ZhiChao; Li, Xiang; Lin, Wei			Heterogeneous Knowledge Fusion: A Novel Approach for Personalized Recommendation via LLM	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Recommendation; Large Language Models		The analysis and mining of user heterogeneous behavior are of paramount importance in recommendation systems. However, the conventional approach of incorporating various types of heterogeneous behavior into recommendation models leads to feature sparsity and knowledge fragmentation issues. To address this challenge, we propose a novel approach for personalized recommendation via Large Language Model (LLM), by extracting and fusing heterogeneous knowledge from user heterogeneous behavior information. In addition, by combining heterogeneous knowledge and recommendation tasks, instruction tuning is performed on LLM for personalized recommendations. The experimental results demonstrate that our method can effectively integrate user heterogeneous behavior and significantly improve recommendation performance.	[Yin, Bin; Xie, JunJie; Qin, Yu; Ding, ZiXiang; Feng, ZhiChao] Meituan, Beijing, Peoples R China; [Li, Xiang; Lin, Wei] Unaffiliated, Beijing, Peoples R China		Li, X (corresponding author), Unaffiliated, Beijing, Peoples R China.	yinbin05@meituan.com; xiejunjie02@meituan.com; qinyu12@meituan.com; dingzixiang@meituan.com; fengzhichao03@meituan.com; leo.lx007@qq.com; lwsaviola@163.com	Lin, Wei/D-3353-2012; Feng, zhi chao/F-2264-2017; Xie, Junjie/V-6618-2019	Lin, Wei/0000-0003-2851-820X; , xie jun jie/0009-0009-2793-0092; Ding, Zixiang/0000-0002-5902-9073; Yin, Bin/0009-0007-3228-2670				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	10	1	1	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							599	601		10.1145/3604915.3608874	http://dx.doi.org/10.1145/3604915.3608874			3	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Green Submitted			2024-07-03	WOS:001156630300059
C	Das, A; Chen, SC; Shyu, ML; Sadiq, S			IEEE	Das, Ayushman; Chen, Shu-Ching; Shyu, Mei-Ling; Sadiq, Saad			Enabling Synergistic Knowledge Sharing and Reasoning in Large Language Models with Collaborative Multi-Agents	2023 IEEE 9TH INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING, CIC			English	Proceedings Paper	IEEE 9th International Conference on Collaboration and Internet Computing (CIC)	NOV 01-04, 2023	Atlanta, GA	IEEE, IEEE Comp Soc		large language model (LLM); multi-agent system (MAS); knowledge sharing; reasoning		Despite the significant advancements in the field of Natural Language Processing (NLP), Large Language Models (LLMs) have shown limitations in performing complex tasks that require arithmetic, commonsense, and symbolic reasoning. Reasoning frameworks like ReAct, Chain-of-thought (CoT), Tree-of-thoughts (ToT), etc. have shown success but with limitations in solving long-form complex tasks. To address this, we propose a knowledge-sharing and collaborative multi-agent assisted framework on LLMs that leverages the capabilities of existing reasoning frameworks and the collaborative skills of multi-agent systems (MASs). The objectives of the proposed framework are to overcome the limitations of LLMs, enhance their reasoning capabilities, and improve their performance in complex tasks. It involves generating natural language rationales and in-context few-shot learning via prompting, and integrates the reasoning techniques with efficient knowledge-sharing and communication-driven agent networks. The potential benefits of the proposed framework include saving time and money, improved efficiency for computationally intensive reasoning, and the ability to incorporate multiple collaboration strategies for dynamically changing environments.	[Das, Ayushman; Chen, Shu-Ching] Univ Missouri Kansas City, Data Sci & Analyt Innovat Ctr, Kansas City, MO 64110 USA; [Das, Ayushman; Shyu, Mei-Ling] Univ Missouri Kansas City, Sch Sci & Engn, Kansas City, MO 64110 USA; [Sadiq, Saad] Microsoft, Seattle, WA USA	University of Missouri System; University of Missouri Kansas City; University of Missouri System; University of Missouri Kansas City; Microsoft	Das, A (corresponding author), Univ Missouri Kansas City, Data Sci & Analyt Innovat Ctr, Kansas City, MO 64110 USA.; Das, A (corresponding author), Univ Missouri Kansas City, Sch Sci & Engn, Kansas City, MO 64110 USA.	ad5f2@mail.umkc.edu; s.chen@umkc.edu; shyum@umkc.edu; saad.sadiq@microsoft.com			National Science Foundation (NSF) [CNS-2301552]	National Science Foundation (NSF)(National Science Foundation (NSF))	This work was partially supported by the National Science Foundation (NSF), Grant Number CNS-2301552.	Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Boiko DA, 2023, Arxiv, DOI [arXiv:2304.05332, DOI 10.48550/ARXIV.2304.05332]; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen WZ, 2023, Arxiv, DOI arXiv:2308.10848; Finin T., 1994, CIKM 94. Proceedings of the Third International Conference on Information and Knowledge Management, P456, DOI 10.1145/191246.191322; Gao Luyu, 2023, P MACHINE LEARNING R, P10764; github, 2023, yoheinakajima. babyagi.; Hao SB, 2023, Arxiv, DOI arXiv:2305.14992; Huang W., 2022, Language models as zero-shot planners: Extracting actionable knowledge for embodied agents; Karpas E., 2022, arXiv; Liu B, 2023, Arxiv, DOI arXiv:2304.11477; Liu X, 2023, Arxiv, DOI arXiv:2308.03688; Longpre S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7052; Madaan A, 2022, Arxiv, DOI arXiv:2210.07128; Parisi A, 2022, Arxiv, DOI arXiv:2205.12255; Schick T., 2023, arXiv; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Significant-Gravitas, 2023, Autogpt; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao Shunyu, 2023, INT C LEARN REPR ICL; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	26	0	0	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-3912-3				2023							92	98		10.1109/CIC58953.2023.00021	http://dx.doi.org/10.1109/CIC58953.2023.00021			7	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW6BZ					2024-07-03	WOS:001170790200011
J	Huber, SE; Kiili, K; Nebel, S; Ryan, RM; Sailer, M; Ninaus, M				Huber, Stefan E.; Kiili, Kristian; Nebel, Steve; Ryan, Richard M.; Sailer, Michael; Ninaus, Manuel			Leveraging the Potential of Large Language Models in Education Through Playful and Game-Based Learning	EDUCATIONAL PSYCHOLOGY REVIEW			English	Article						Large language models; Generative artificial intelligence; Education; Playful learning; Gamification; Game-based learning	SELF-DETERMINATION THEORY; DELIBERATE PRACTICE; MOTIVATION; BENEFITS; CHATGPT; WRITE	This perspective piece explores the transformative potential and associated challenges of large language models (LLMs) in education and how those challenges might be addressed utilizing playful and game-based learning. While providing many opportunities, the stochastic elements incorporated in how present LLMs process text, requires domain expertise for a critical evaluation and responsible use of the generated output. Yet, due to their low opportunity cost, LLMs in education may pose some risk of over-reliance, potentially and unintendedly limiting the development of such expertise. Education is thus faced with the challenge of preserving reliable expertise development while not losing out on emergent opportunities. To address this challenge, we first propose a playful approach focusing on skill practice and human judgment. Drawing from game-based learning research, we then go beyond this playful account by reflecting on the potential of well-designed games to foster a willingness to practice, and thus nurturing domain-specific expertise. We finally give some perspective on how a new pedagogy of learning with AI might utilize LLMs for learning by generating games and gamifying learning materials, leveraging the full potential of human-AI interaction in education.	[Huber, Stefan E.; Ninaus, Manuel] Karl Franzens Univ Graz, Dept Psychol, Graz, Austria; [Kiili, Kristian] Tampere Univ, Fac Educ & Culture, Tampere, Finland; [Nebel, Steve] Univ Potsdam, Dept Educ Res, Media Educ, Potsdam, Germany; [Ryan, Richard M.] Australian Catholic Univ, Inst Posit Psychol & Educ, Sydney, NSW, Australia; [Ryan, Richard M.] Ewha Womans Univ, Coll Educ, Seoul, South Korea; [Sailer, Michael] Univ Augsburg, Learning Analyt & Educ Data Min, Augsburg, Germany; [Ninaus, Manuel] Univ Tubingen, LEAD Grad Sch & Res Network, Tubingen, Germany	University of Graz; Tampere University; University of Potsdam; Australian Catholic University; Ewha Womans University; University of Augsburg; Eberhard Karls University of Tubingen	Ninaus, M (corresponding author), Karl Franzens Univ Graz, Dept Psychol, Graz, Austria.; Ninaus, M (corresponding author), Univ Tubingen, LEAD Grad Sch & Res Network, Tubingen, Germany.	manuel.ninaus@uni-graz.at	Ryan, Richard M./H-1459-2019	Ryan, Richard M./0000-0002-2355-6154; Sailer, Michael/0000-0001-6831-5429; Kiili, Kristian/0000-0003-2838-6892; Ninaus, Manuel/0000-0002-4664-8430	Strategic Research Council	Strategic Research Council(Strategic Research Council (SRC))	No Statement Available	Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Ang RP., 2017, Handbook of research on serious games for educational applications, P115; Ariyaratne S, 2023, SKELETAL RADIOL, V52, P1755, DOI 10.1007/s00256-023-04340-5; Barz N, 2024, REV EDUC RES, V94, P193, DOI 10.3102/00346543231167795; Beresford Adam translator., 2020, Nicomachean Ethics; Bernabei M., 2023, Comput. Educ. Artific. Intellig, V5, DOI [10.1016/j.caeai.2023.100172, DOI 10.1016/J.CAEAI.2023.100172]; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bourgonjon J, 2010, COMPUT EDUC, V54, P1145, DOI 10.1016/j.compedu.2009.10.022; Brown J. K., 2016, To literacy and beyond: The poetics of Disney Infinity 3.0 as facilitators of new literacy practices; Butcher KR., 2017, Handbook of research on serious games for educational applications, P115, DOI [10.4018/978-1-5225-0513-6.ch006, DOI 10.4018/978-1-5225-0513-6.CH006]; Calvo RA, 2014, POSITIVE COMPUTING: TECHNOLOGY FOR WELLBEING AND HUMAN POTENTIAL, P1; Campitelli G, 2011, CURR DIR PSYCHOL SCI, V20, P280, DOI 10.1177/0963721411421922; Chen SI, 2023, INTERACT LEARN ENVIR, V31, P4309, DOI 10.1080/10494820.2021.1961159; Choontanom Trina., 2012, Games, Learning, and Society: Learning and Meaning in the Digital Age, P185, DOI 10.1017/CBO9781139031127.017; Cooper S, 2010, NATURE, V466, P756, DOI 10.1038/nature09304; Decker Adrienne., 2013, 44th ACM Technical Symposium on Computer Science Education, P233; Deterding S., 2011, P 15 INT ACAD MINDTR, P9, DOI DOI 10.1145/2181037.2181040; Deutscher Ethikrat, 2023, MENSCH MASCH HER DUR; Dillon MR, 2017, SCIENCE, V357, P47, DOI 10.1126/science.aal4724; Dunn C, 2023, J AM ACAD DERMATOL, V89, P388, DOI 10.1016/j.jaad.2023.04.005; Eager B, 2023, J UNIV TEACH LEARN P, V20; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Elvira Q, 2017, SCAND J EDUC RES, V61, P187, DOI 10.1080/00313831.2015.1119729; ERICSSON KA, 1993, PSYCHOL REV, V100, P363, DOI 10.1037/0033-295X.100.3.363; Fernandez-Manjon B., 2015, EAI Endorsed Transactions on Game-Based Learning, V2, DOI [10.4108/eai.5-11-2015.150611, DOI 10.4108/EAI.5-11-2015.150611]; Flanagan M, 2009, CRITICAL PLAY: RADICAL GAME DESIGN, P1; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Gatti W Jr, 2023, INT J SERIOUS GAMES, V10, P33, DOI 10.17083/ijsg.v10i4.645; Gee J.P., 2005, COMMUNITIES PRACTICE, DOI [DOI 10.1017/CB09780511610554.012, 10.1017/CBO9780511610554.012, DOI 10.1017/CBO9780511610554.012]; Google, 2023, Bard; Granic I, 2014, AM PSYCHOL, V69, P66, DOI 10.1037/a0034857; Greipl S, 2020, INT J TECHNOL ENHANC, V12, P363, DOI 10.1504/IJTEL.2020.110047; Hambrick DZ, 2016, PSYCHOL LEARN MOTIV, V64, P1, DOI 10.1016/bs.plm.2015.09.001; Hambrick DZ, 2014, INTELLIGENCE, V45, P34, DOI 10.1016/j.intell.2013.04.001; Hébert C, 2021, E-LEARNING DIGITAL M, V18, P307, DOI 10.1177/2042753021995315; Heston TF., 2023, Int. Med. Educ., V2, P198, DOI [DOI 10.3390/IME2030019, 10.3390/ime2030019]; Hodent C., 2018, The gamer's brain; Homer BD, 2019, HANDBOOK OF GAME-BASED LEARNING, P25; Hosseini M, 2023, medRxiv, DOI [10.1101/2023.03.31.23287979, 10.1101/2023.03.31.23287979, DOI 10.1101/2023.03.31.23287979]; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Hu YY, 2022, J RES SCI TEACH, V59, P1499, DOI 10.1002/tea.21765; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Johnson Arianna., 2023, Forbes; Kafai Y., 2006, GAMES CULT, V1, P36, DOI [DOI 10.1177/1555412005281767, 10.1177/1555412005281767]; Kafai YB, 2015, EDUC PSYCHOL-US, V50, P313, DOI 10.1080/00461520.2015.1124022; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kiili K, 2007, BRIT J EDUC TECHNOL, V38, P394, DOI 10.1111/j.1467-8535.2007.00704.x; Klopfer E, 2019, HANDBOOK OF GAME-BASED LEARNING, P387; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Korzynski P, 2023, ENTREPR BUS ECON REV, V11, P25, DOI 10.15678/EBER.2023.110302; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Kurzban R, 2013, BEHAV BRAIN SCI, V36, P661, DOI 10.1017/S0140525X12003196; Li C, 2023, Arxiv, DOI [arXiv:2307.11760, DOI 10.48550/ARXIV.2307.11760, 10.48550/arXiv.2307.11760]; Loderer K, 2019, HANDBOOK OF GAME-BASED LEARNING, P111; Mayer RE, 2019, HANDBOOK OF GAME-BASED LEARNING, P83; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Microsoft, 2023, Bing Chat; Miller EM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038680; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; Molenaar I., 2021, OECD digital education outlook 2021: Pushing the frontiers with artificial intelligence, blockchain and robots, DOI [10.1787/2cc25-37-en?format=html, DOI 10.1787/2CC25-37-EN?FORMAT=HTML]; Moreno-Ger P, 2008, COMPUTER, V41, P24, DOI 10.1109/MC.2008.73; Morris MR, 2024, Arxiv, DOI arXiv:2311.02462; Nasir MU, 2023, Arxiv, DOI [arXiv:2305.18243, 10.48550/ARXIV.2305.18243]; Nebel S, 2016, EDUC TECHNOL SOC, V19, P355; Ninaus M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.956798; OpenAI, 2023, CHATGPT; Oppenlaender J, 2023, Arxiv, DOI [arXiv:2303.13534, 10.48550/arXiv.2303.13534]; Pahor A, 2022, NAT HUM BEHAV, V6, P1243, DOI 10.1038/s41562-022-01384-w; Papert S., 1980, MINDSTORMS CHILDREN; Pasqualotto A, 2022, NAT HUM BEHAV, V6, P545, DOI 10.1038/s41562-021-01254-x; Patterson RE, 2010, J COGN ENG DECIS MAK, V4, P289, DOI 10.1177/155534341000400403; Piaget J., 1962, Play, dreams, and imitation in childhood; Plass JL, 2019, HANDBOOK OF GAME-BASED LEARNING, P3; Plass JL, 2015, EDUC PSYCHOL-US, V50, P258, DOI 10.1080/00461520.2015.1122533; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Reeve J., 2023, The Oxford Handbook of Self-Determination Theory, DOI [10.1093/oxfordhb/9780197600047.013.3, DOI 10.1093/OXFORDHB/9780197600047.013.3]; Resnick M., 2008, Learning Leading with Technology, V35, P18; Resnick M., 2013, Design, make, play: Growing the next generation of STEM innovators, P163; Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779; Rigby C.S., 2011, Glued to games. How video games draw us in and hold us spellbound; Rigby CS, 2014, GAMEFUL WORLD: APPROACHES, ISSUES, APPLICATIONS, P113; Rosenzweig-Ziff D., 2023, Washington Post; Ryan RM, 2019, HANDBOOK OF GAME-BASED LEARNING, P153; Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8; Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806; Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salomon G., 1991, EDUC RESEARCHER, V20, P2, DOI DOI 10.3102/0013189X020003002; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Short C.E., 2023, J Bus Ventur Insights, V19, pe00388, DOI DOI 10.1016/J.JBVI.2023.E00388; Shue E, 2023, bioRxiv, DOI [10.1101/2023.03.07.531414, 10.1101/2023.03.07.531414, DOI 10.1101/2023.03.07.531414]; Sorebo O, 2009, COMPUT EDUC, V53, P1177, DOI 10.1016/j.compedu.2009.06.001; Spiers HJ, 2023, TOP COGN SCI, V15, P120, DOI 10.1111/tops.12590; Steinkuehler C., 2012, Games, learning, and society: Learning and meaning in the digital age, P185, DOI [10.1017/CBO9781139031127.017, DOI 10.1017/CBO9781139031127.017]; Steinkuehler C, 2019, HANDBOOK OF GAME-BASED LEARNING, P177; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Todd G, 2023, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES, FDG 2023, DOI 10.1145/3582437.3587211; Tynjala P., 2006, Advances in Learning and Instruction, Higher Education and Working Life: Collaborations, Confrontations and Challenges, P77; Tynjälä P, 2008, EDUC RES REV-NETH, V3, P130, DOI 10.1016/j.edurev.2007.12.001; VYGOTSKY LS, 1967, SOV PSYCHOL-USSR, V5, P6, DOI 10.2753/RPO1061-040505036; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Wenger E., 1998, Community of practice: Learning, meaning, and identity, DOI [DOI 10.1017/CBO9780511803932, 10.2277/0521663636, DOI 10.2277/0521663636]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818; Zimmerman A, 2023, ANN SURG ONCOL, V30, P3170, DOI 10.1245/s10434-023-13436-0	111	1	1	65	65	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1040-726X	1573-336X		EDUC PSYCHOL REV	Educ. Psychol. Rev.	MAR	2024	36	1							25	10.1007/s10648-024-09868-z	http://dx.doi.org/10.1007/s10648-024-09868-z			20	Psychology, Educational	Social Science Citation Index (SSCI)	Psychology	JA5X2		hybrid			2024-07-03	WOS:001170456100001
J	Alqahtani, T; Badreldin, HA; Alrashed, M; Alshaya, AI; Alghamdi, SS; bin Saleh, K; Alowais, SA; Alshaya, OA; Rahman, I; Al Yami, MS; Albekairy, AM				Alqahtani, Tariq; Badreldin, Hisham A.; Alrashed, Mohammed; Alshaya, Abdulrahman I.; Alghamdi, Sahar S.; bin Saleh, Khalid; Alowais, Shuroug A.; Alshaya, Omar A.; Rahman, Ishrat; Al Yami, Majed S.; Albekairy, Abdulkareem M.			The emergent role of artificial intelligence, natural learning processing, and large language models in higher education and research	RESEARCH IN SOCIAL & ADMINISTRATIVE PHARMACY			English	Article						Artificial intelligence; Pharmacy; Education; Research; Natural language processing; Large language models	AUTHOR; BIAS	Artificial Intelligence (AI) has revolutionized various domains, including education and research. Natural lan-guage processing (NLP) techniques and large language models (LLMs) such as GPT-4 and BARD have signifi-cantly advanced our comprehension and application of AI in these fields. This paper provides an in-depth introduction to AI, NLP, and LLMs, discussing their potential impact on education and research. By exploring the advantages, challenges, and innovative applications of these technologies, this review gives educators, re-searchers, students, and readers a comprehensive view of how AI could shape educational and research practices in the future, ultimately leading to improved outcomes. Key applications discussed in the field of research include text generation, data analysis and interpretation, literature review, formatting and editing, and peer review. AI applications in academics and education include educational support and constructive feedback, assessment, grading, tailored curricula, personalized career guidance, and mental health support. Addressing the challenges associated with these technologies, such as ethical concerns and algorithmic biases, is essential for maximizing their potential to improve education and research outcomes. Ultimately, the paper aims to contribute to the ongoing discussion about the role of AI in education and research and highlight its potential to lead to better outcomes for students, educators, and researchers.	[Alqahtani, Tariq; Alghamdi, Sahar S.] King Saud bin Abdulaziz Univ Hlth Sci, Coll Pharm, Dept Pharmaceut Sci, Riyadh, Saudi Arabia; [Alqahtani, Tariq; Badreldin, Hisham A.; Alrashed, Mohammed; Alshaya, Abdulrahman I.; Alghamdi, Sahar S.; bin Saleh, Khalid; Alowais, Shuroug A.; Alshaya, Omar A.; Al Yami, Majed S.; Albekairy, Abdulkareem M.] King Abdullah Int Med Res Ctr, Riyadh, Saudi Arabia; [Badreldin, Hisham A.; Alshaya, Abdulrahman I.; bin Saleh, Khalid; Alowais, Shuroug A.; Alshaya, Omar A.; Al Yami, Majed S.; Albekairy, Abdulkareem M.] King Saud bin Abdulaziz Univ Hlth Sci, Coll Pharm, King Abdullah Int Med Res Ctr, Dept Pharm Practice, Riyadh, Saudi Arabia; [Badreldin, Hisham A.; Alrashed, Mohammed; Alshaya, Abdulrahman I.; bin Saleh, Khalid; Alowais, Shuroug A.; Alshaya, Omar A.; Al Yami, Majed S.; Albekairy, Abdulkareem M.] King Abdul Aziz Med City, Pharmaceut Care Dept, Natl Guard Hlth Affairs, Riyadh, Saudi Arabia; [Rahman, Ishrat] Princess Nourah bint Abdulrahman Univ, Coll Dent, Dept Basic Dent Sci, POB 84428, Riyadh 11671, Saudi Arabia; [Alqahtani, Tariq] KSAU HS, Coll Pharm, 2915 Al Haras Al Watani St, Riyadh 14611, Saudi Arabia	King Saud Bin Abdulaziz University for Health Sciences; King Saud Bin Abdulaziz University for Health Sciences; King Abdullah International Medical Research Center (KAIMRC); King Saud Bin Abdulaziz University for Health Sciences; King Abdullah International Medical Research Center (KAIMRC); King Saud Bin Abdulaziz University for Health Sciences; Ministry of National Guard - Health Affairs; King Abdulaziz Medical City - Riyadh; National Guard Health Affairs - Saudi Arabia; King Abdulaziz Medical City; Princess Nourah bint Abdulrahman University; King Saud Bin Abdulaziz University for Health Sciences	Alqahtani, T (corresponding author), KSAU HS, Coll Pharm, 2915 Al Haras Al Watani St, Riyadh 14611, Saudi Arabia.	Qahtanita@ksau-hs.edu.sa		Alqahtani, Tariq/0009-0007-1094-6835				Academy B, 2019, SERDICA J COMPUT, V13, P27, DOI [10.55630/SJC.2019.13.27-40, DOI 10.55630/SJC.2019.13.27-40]; Ahmed A, 2022, CSEDU: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION - VOL 2, P85, DOI 10.5220/0011082100003182; Aljohani N, J INNOV KNOWL; Alkaitis MS, 2021, JCO CLIN CANCER INFO, V5, P550, DOI 10.1200/CCI.20.00139; Almaleh A, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11092607; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2020, MIT TECHNOLOGY REV; Ashwini S, 2022 2 INT C COMPUTE, DOI [10.1109/ICCSEA54677.2022.9936389, DOI 10.1109/ICCSEA54677.2022.9936389]; Auerbach RP, 2016, PSYCHOL MED, V46, P2955, DOI 10.1017/S0033291716001665; Baars M, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.793002; Bhattamisra SK, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010010; Bile Hassan Ismail, 2021, SIGCSE '21: Proceedings of the 52nd ACM Technical Symposium on Computer Science Education, P529, DOI 10.1145/3408877.3432443; Blanco-Gonzalez A, ROLE AI DRUG DISCOVE; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chubb J, 2022, AI SOC, V37, P1439, DOI 10.1007/s00146-021-01259-0; Crothers E, 2023, Arxiv, DOI arXiv:2210.07321; D'Agostino D, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/138012; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Deshpande K, MITIGATING SOCIOLING, DOI [10.13016/M2KDHX-ZENE, DOI 10.13016/M2KDHX-ZENE]; Deshpande KV, 2020, ADJUNCT PUBLICATION, P268, DOI [10.1145/3386392.3399569, DOI 10.1145/3386392.3399569]; Dycke N, NLPEER UNIFIED RESOU; Elkin P, 2021, J MED INTERNET RES, DOI [10.2196/PREPRINTS.28946, DOI 10.2196/PREPRINTS.28946]; Fakhoury M, 2019, ADV EXP MED BIOL, V1192, P119, DOI 10.1007/978-981-32-9721-0_6; forbes, AI IS CHANGING WAY S; forbes, ARTIF INTELL; Gati I, 2021, J VOCAT BEHAV, V126, DOI 10.1016/j.jvb.2021.103545; Graham S, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1094-0; Grunhut J, 2021, J MED EDUC CURRIC DE, V8, DOI 10.1177/23821205211036836; Gupta PP, ADV MED TECHNOL CLIN, P47, DOI [10.4018/978-1-5225-7326-5.CH002, DOI 10.4018/978-1-5225-7326-5.CH002]; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Hosseini Mohammad, 2023, Res Sq, DOI 10.21203/rs.3.rs-2587766/v1; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Huang Q, 2020, J ONCOL, V2020, DOI 10.1155/2020/5976465; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Le Glaz A, 2021, J MED INTERNET RES, V23, DOI 10.2196/15708; Lee CJ, 2013, J AM SOC INF SCI TEC, V64, P2, DOI 10.1002/asi.22784; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Libbrecht P, NLP STUDENT TEACHER; Luo L, 2021, ANTI-CANCER DRUG, V32, P1038, DOI 10.1097/CAD.0000000000001108; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Manakul P, 2023, Arxiv, DOI [arXiv:2303.08896, 10.48550/arXiv.2303.08896]; Marshall C, 2021, PREPRINT, DOI [10.2196/PREPRINTS.32449, DOI 10.2196/PREPRINTS.32449]; Matyo-Cepero J, SURVIVING PUBLISH PE; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Nelson SD, 2020, AM J HEALTH-SYST PH, V77, P1556, DOI 10.1093/ajhp/zxaa218; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Quazi S., 2021, Role of Artificial Intelligence and Machine Learning in Bioinformatics: Drug Discovery and Drug Repurposing, DOI [DOI 10.20944/PREPRINTS202105.0346.V1, 10.20944/preprints202105.0346.v1]; Sarker Iqbal H, 2022, SN Comput Sci, V3, P158, DOI 10.1007/s42979-022-01043-x; Schulz R, 2022, BMC RES NOTES, V15, DOI 10.1186/s13104-022-06080-6; Scott A, WRITERS BLOCK STUDY; Sharma G, CHATGPT DRUG DISCOVE; Shehab A, 2016, ICENCO 2016 - 2016 12TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO) - BOUNDLESS SMART SOCIETIES, P65, DOI 10.1109/ICENCO.2016.7856447; Shetty P, 2020, INT J ENG ADV TECHNO, V9, P1033, DOI [10.35940/IJEAT.E9880.069520, DOI 10.35940/IJEAT.E9880.069520]; Shue E, 2023, bioRxiv, DOI [10.1101/2023.03.07.531414, 10.1101/2023.03.07.531414, DOI 10.1101/2023.03.07.531414]; Solangi Y. A., 2019, IEEE 5 INT C ENG TEC, DOI 10.1109/ICETAS.2018.8629198; Stelmakh I, ARXIV; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sureshkumar M, 2022, 2022 1 INT C COMPUTA, P262, DOI [10.1109/ICCST55948.2022.10040438, DOI 10.1109/ICCST55948.2022.10040438]; Tai MCT, 2020, TZU CHI MED J, V32, P339, DOI 10.4103/tcmj.tcmj_71_20; Tanniru MR, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115686; Tennant JP, 2020, RES INTEGR PEER REV, V5, DOI 10.1186/s41073-020-00092-1; Tomkins A, 2017, P NATL ACAD SCI USA, V114, P12708, DOI 10.1073/pnas.1707323114; Vasileva O, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01515; Wang Xuan, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1992/2/022124; Westman S., 2021, IAFOR J ED, V9, P43, DOI [DOI 10.22492/IJE.9.4.03, https://doi.org/10.22492/ije.9.4.03]; Xue YA, 2022, ACS APPL MATER INTER, V14, P37396, DOI 10.1021/acsami.2c08994; Yeung JA, 2023, medRxiv, DOI [10.1101/2023.03.02.23286705, 10.1101/2023.03.02.23286705, DOI 10.1101/2023.03.02.23286705]; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zheng P, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.870795	74	21	21	121	193	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	1551-7411	1934-8150		RES SOC ADMIN PHARM	Res. Soc. Adm. Pharm.	AUG	2023	19	8					1236	1242		10.1016/j.sapharm.2023.05.016	http://dx.doi.org/10.1016/j.sapharm.2023.05.016		JUL 2023	7	Public, Environmental & Occupational Health; Pharmacology & Pharmacy	Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health; Pharmacology & Pharmacy	P5CH3	37321925	hybrid			2024-07-03	WOS:001050843100001
J	Konet, A; Thomas, I; Gartlehner, G; Kahwati, L; Hilscher, R; Kugley, S; Crotty, K; Viswanathan, M; Chew, R				Konet, Amanda; Thomas, Ian; Gartlehner, Gerald; Kahwati, Leila; Hilscher, Rainer; Kugley, Shannon; Crotty, Karen; Viswanathan, Meera; Chew, Robert			Performance of two large language models for data extraction in evidence synthesis	RESEARCH SYNTHESIS METHODS			English	Article; Early Access						accuracy; artificial intelligence; data extraction; evidence synthesis; large language models		Accurate data extraction is a key component of evidence synthesis and critical to valid results. The advent of publicly available large language models (LLMs) has generated interest in these tools for evidence synthesis and created uncertainty about the choice of LLM. We compare the performance of two widely available LLMs (Claude 2 and GPT-4) for extracting pre-specified data elements from 10 published articles included in a previously completed systematic review. We use prompts and full study PDFs to compare the outputs from the browser versions of Claude 2 and GPT-4. GPT-4 required use of a third-party plugin to upload and parse PDFs. Accuracy was high for Claude 2 (96.3%). The accuracy of GPT-4 with the plug-in was lower (68.8%); however, most of the errors were due to the plug-in. Both LLMs correctly recognized when prespecified data elements were missing from the source PDF and generated correct information for data elements that were not reported explicitly in the articles. A secondary analysis demonstrated that, when provided selected text from the PDFs, Claude 2 and GPT-4 accurately extracted 98.7% and 100% of the data elements, respectively. Limitations include the narrow scope of the study PDFs used, that prompt development was completed using only Claude 2, and that we cannot guarantee the open-source articles were not used to train the LLMs. This study highlights the potential for LLMs to revolutionize data extraction but underscores the importance of accurate PDF parsing. For now, it remains essential for a human investigator to validate LLM extractions.	[Konet, Amanda; Thomas, Ian; Gartlehner, Gerald; Kahwati, Leila; Hilscher, Rainer; Kugley, Shannon; Crotty, Karen; Viswanathan, Meera; Chew, Robert] RTI Int, Social Stat & Environm Sci, Res Triangle Pk, NC 27709 USA; [Gartlehner, Gerald] Danube Univ Krems, Dept Evidence Based Med & Evaluat, Krems, Austria	Research Triangle Institute; Danube University Krems	Konet, A (corresponding author), RTI Int, Social Stat & Environm Sci, Res Triangle Pk, NC 27709 USA.	akonet@rti.org		Konet, Amanda/0000-0001-5295-6483; Kahwati, Leila/0000-0001-6963-2848	RTI International; Innovation Team at RTI International	RTI International; Innovation Team at RTI International	Thank you to Graham Booth for project support during the project's initial stages and the Innovation Team at RTI International for their project support.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alshami A, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11070351; [Anonymous], AskYourPDF; Anthropic, 2023, Model card and evaluations for claude models; Anthropic, CLAUDE 2; Bagel J, 2018, DERMATOLOGY THER, V8, P571, DOI 10.1007/s13555-018-0265-y; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Blauvelt A, 2020, BRIT J DERMATOL, V182, P1348, DOI 10.1111/bjd.18851; Gartlehner G, 2024, RES SYNTH METHODS, DOI 10.1002/jrsm.1710; Glatt S, 2017, BRIT J CLIN PHARMACO, V83, P991, DOI 10.1111/bcp.13185; Higgins JPT TJ, 2023, Cochrane Handbook for Systematic Reviews of Interventions; Jonnalagadda SR, 2015, SYST REV-LONDON, V4, DOI 10.1186/s13643-015-0066-7; Kartchner D., 2023, 22 WORKSH BIOM NAT L, DOI [10.18653/v1/2023.bionlp1.37, DOI 10.18653/V1/2023.BIONLP1.37]; Khraisha Q, 2023, Arxiv, DOI [arXiv:2310.17526, DOI 10.48550/ARXIV.2310.17526]; Lebwohl M, 2018, J AM ACAD DERMATOL, V79, P266, DOI 10.1016/j.jaad.2018.04.013; Li TJ, 2019, J CLIN EPIDEMIOL, V115, P77, DOI 10.1016/j.jclinepi.2019.07.005; Mahuli SA, 2023, BRIT DENT J, V235, P90, DOI 10.1038/s41415-023-6132-y; Mathes T, 2017, BMC MED RES METHODOL, V17, DOI 10.1186/s12874-017-0431-4; Nussbaumer-Streit B, 2021, J CLIN EPIDEMIOL, V139, P287, DOI 10.1016/j.jclinepi.2021.05.019; Papp KA, 2018, J AM ACAD DERMATOL, V79, P277, DOI 10.1016/j.jaad.2018.03.037; Reich K, 2017, BRIT J DERMATOL, V177, P1014, DOI 10.1111/bjd.15666; Reich K, 2017, J EUR ACAD DERMATOL, V31, P507, DOI 10.1111/jdv.14015; Reich K, 2017, J AM ACAD DERMATOL, V76, P418, DOI 10.1016/j.jaad.2016.11.042; Schmidt Lena, 2021, F1000Res, V10, P401, DOI 10.12688/f1000research.51117.1; Schopow N, 2023, JMIR MED INF, V11, DOI 10.2196/48933; Thaçi D, 2015, J AM ACAD DERMATOL, V73, P400, DOI 10.1016/j.jaad.2015.05.013; Warren RB, 2021, BRIT J DERMATOL, V184, P50, DOI 10.1111/bjd.19341; Zhuanlan S., 2024, medRxiv, DOI [10.1101/2024.02.20.24303083, DOI 10.1101/2024.02.20.24303083]	28	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1759-2879	1759-2887		RES SYNTH METHODS	Res. Synth. Methods	2024 JUN 19	2024										10.1002/jrsm.1732	http://dx.doi.org/10.1002/jrsm.1732		JUN 2024	7	Mathematical & Computational Biology; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology; Science & Technology - Other Topics	UQ2R0	38895747				2024-07-03	WOS:001249463300001
J	Tang, LY; Sun, ZY; Idnay, B; Nestor, JG; Soroush, A; Elias, PA; Xu, ZY; Ding, Y; Durrett, G; Rousseau, JF; Weng, CH; Peng, YF				Tang, Liyan; Sun, Zhaoyi; Idnay, Betina; Nestor, Jordan G.; Soroush, Ali; Elias, Pierre A.; Xu, Ziyang; Ding, Ying; Durrett, Greg; Rousseau, Justin F.; Weng, Chunhua; Peng, Yifan			Evaluating large language models on medical evidence summarization	NPJ DIGITAL MEDICINE			English	Article								Recent advances in large language models (LLMs) have demonstrated remarkable successes in zero- and few-shot performance on various downstream tasks, paving the way for applications in high-stakes domains. In this study, we systematically examine the capabilities and limitations of LLMs, specifically GPT-3.5 and ChatGPT, in performing zero-shot medical evidence summarization across six clinical domains. We conduct both automatic and human evaluations, covering several dimensions of summary quality. Our study demonstrates that automatic metrics often do not strongly correlate with the quality of summaries. Furthermore, informed by our human evaluations, we define a terminology of error types for medical evidence summarization. Our findings reveal that LLMs could be susceptible to generating factually inconsistent summaries and making overly convincing or uncertain statements, leading to potential harm due to misinformation. Moreover, we find that models struggle to identify the salient information and are more error-prone when summarizing over longer textual contexts.	[Tang, Liyan; Ding, Ying] Univ Texas Austin, Sch Informat, Austin, TX USA; [Sun, Zhaoyi; Peng, Yifan] Weill Cornell Med, Dept Populat Hlth Sci, New York, NY 10065 USA; [Idnay, Betina; Elias, Pierre A.; Weng, Chunhua] Columbia Univ, Dept Biomed Informat, New York, NY 10027 USA; [Nestor, Jordan G.; Soroush, Ali] Columbia Univ, Dept Med, New York, NY USA; [Xu, Ziyang] Massachusetts Gen Hosp, Dept Med, Boston, MA USA; [Durrett, Greg] Univ Texas Austin, Dept Comp Sci, Austin, TX USA; [Rousseau, Justin F.] Univ Texas Austin, Dell Med Sch, Dept Populat Hlth, Austin, TX 78712 USA; [Rousseau, Justin F.] Univ Texas Austin, Dell Med Sch, Dept Neurol, Austin, TX 78712 USA; [Rousseau, Justin F.] Univ Texas Southwestern Med Ctr, Dept Neurol, Dallas, TX 75390 USA	University of Texas System; University of Texas Austin; Cornell University; Weill Cornell Medicine; Columbia University; Columbia University; Harvard University; Massachusetts General Hospital; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Southwestern Medical Center Dallas	Peng, YF (corresponding author), Weill Cornell Med, Dept Populat Hlth Sci, New York, NY 10065 USA.; Weng, CH (corresponding author), Columbia Univ, Dept Biomed Informat, New York, NY 10027 USA.; Rousseau, JF (corresponding author), Univ Texas Austin, Dell Med Sch, Dept Populat Hlth, Austin, TX 78712 USA.; Rousseau, JF (corresponding author), Univ Texas Austin, Dell Med Sch, Dept Neurol, Austin, TX 78712 USA.; Rousseau, JF (corresponding author), Univ Texas Southwestern Med Ctr, Dept Neurol, Dallas, TX 75390 USA.	justin.rousseau@utsouthwestern.edu; cw2384@cumc.columbia.edu; yip4002@med.cornell.edu	zhang, yuanyuan/KHV-4459-2024; li, xiaomin/KCX-9845-2024; Nestor, Jordan Gabriela/AAX-7362-2021; Liu, Junjie/KHV-6949-2024; Soroush, Ali/O-5540-2016; Peng, Yifan/AAX-1862-2021	Nestor, Jordan Gabriela/0000-0003-1418-3103; Sun, Zhaoyi/0009-0003-8197-1465; Elias, Pierre/0000-0002-9643-3024; Idnay, Betina/0000-0002-4318-5987; Rousseau, Justin/0000-0002-2817-9124	This work was supported by the National Library of Medicine (NLM) of the National Institutes of Health (NIH) under grant number 4R00LM013001, 1R01LM014306, and 5R01LM009886, NIH Bridge2AI (OTA-21-008), National Cancer Institute (NCI) of NIH under grant num [4R00LM013001, 1R01LM014306, 5R01LM009886]; National Library of Medicine (NLM) of the National Institutes of Health (NIH) [OTA-21-008]; NIH [P30CA013696]; National Cancer Institute (NCI) of NIH [2145640, 2019844, 2303038]; National Science Foundation; Amazon Research Award; NSF	This work was supported by the National Library of Medicine (NLM) of the National Institutes of Health (NIH) under grant number 4R00LM013001, 1R01LM014306, and 5R01LM009886, NIH Bridge2AI (OTA-21-008), National Cancer Institute (NCI) of NIH under grant num; National Library of Medicine (NLM) of the National Institutes of Health (NIH); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Cancer Institute (NCI) of NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Science Foundation(National Science Foundation (NSF)); Amazon Research Award; NSF(National Science Foundation (NSF))	This work was supported by the National Library of Medicine (NLM) of the National Institutes of Health (NIH) under grant number 4R00LM013001, 1R01LM014306, and 5R01LM009886, NIH Bridge2AI (OTA-21-008), National Cancer Institute (NCI) of NIH under grant number P30CA013696, National Science Foundation under grant numbers 2145640, 2019844, and 2303038, and Amazon Research Award. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH and NSF.	Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Beller EM, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001419; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clason D.L., 1994, Journal of Agricultural Education, V35, P31, DOI DOI 10.5032/JAE.1994.04031; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Gross A, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004250.pub5; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kamo T, 2022, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD011968.pub4; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Luoa J., 2023, Cochrane Database Syst. Rev, V8, pCD013267; Mühlbauer V, 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD013304.pub2; OpenAI, 2023, Introducing chatgpt; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Tang L., 2023, Long Papers, V1, P11626; Tang LY, 2022, PROCEEDINGS OF THE 21ST WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2022), P359, DOI 10.18653/v1/2022.bionlp-1.35; Wei JS, 2022, ADV NEUR IN; Zhang YS, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4426; Zhang YS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1592	25	27	27	15	16	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	AUG 24	2023	6	1							158	10.1038/s41746-023-00896-7	http://dx.doi.org/10.1038/s41746-023-00896-7			8	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	GM7O0	37620423	gold, Green Published			2024-07-03	WOS:001153153500001
C	Di Fede, G; Rocchesso, D; Dow, S; Andolina, S			ACM	Di Fede, Giulia; Rocchesso, Davide; Dow, Steven; Andolina, Salvatore			The Idea Machine: LLM-based Expansion, Rewriting, Combination, and Suggestion of Ideas	PROCEEDINGS OF THE 14TH CREATIVITY AND COGNITION, C&C 2022			English	Proceedings Paper	14th ACM Creativity and Cognition Conference Series (C and C)	JUN 20-23, 2022	Venice, ITALY	Assoc Comp Machinery, ACM SIGCHI		Creativity; idea generation; large language models; brainstorming; human-centered AI		We introduce the Idea Machine, a creativity support tool that leverages large language models (LLMs) to empower people engaged in idea generation tasks. The tool includes a number of affordances that can be used to enable various levels of automation and intelligent support. Each idea entered into the system can be expanded, rewritten, or combined with other ideas or concepts. An idea suggestion mode can also be enabled to make the system proactively suggest ideas.	[Di Fede, Giulia; Rocchesso, Davide; Andolina, Salvatore] Univ Palermo, Palermo, Italy; [Dow, Steven] Univ Calif San Diego, San Diego, CA USA	University of Palermo; University of California System; University of California San Diego	Di Fede, G (corresponding author), Univ Palermo, Palermo, Italy.			Andolina, Salvatore/0000-0001-9804-4009; Rocchesso, Davide/0000-0002-0849-7766	MIUR (PON AIM) [CUP: B74I18000210006, AIM1875400-1]	MIUR (PON AIM)	This research is partially funded by the MIUR (PON AIM, id: AIM1875400-1, CUP: B74I18000210006)	Andolina S., 2015, Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition, ser. CC'15, Glasgow, P103, DOI DOI 10.1145/2757226.2757252; Andolina S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P106, DOI 10.1145/3059454.3059477; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chilton LB, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445089; Chilton LB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300402; Frich J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300619; Gero KI, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300526; Herring SR, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P87; Hwang AHC, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445270; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Runco MA, 2012, CREATIVITY RES J, V24, P66, DOI 10.1080/10400419.2012.652929; Shakeri H, 2021, CONFERENCE COMPANION PUBLICATION OF THE 2021 COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, CSCW 2021 COMPANION, P163, DOI 10.1145/3462204.3481771; Shneiderman B, 2007, COMMUN ACM, V50, P20, DOI 10.1145/1323688.1323689; Shneiderman B, 2021, ISSUES SCI TECHNOL, V37, P56; Siangliulue Pao, 2015, P 2015 ACM SIGCHI C, P83, DOI DOI 10.1145/2757226.2757230; Smith S., 1995, CREATIVE COGNITION A; Wang HC, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P103; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Yu LX, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1393; Yu LX, 2013, ACM T INTERACT INTEL, V3, DOI 10.1145/2448116.2448118	21	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9327-0				2022							623	627		10.1145/3527927.3535197	http://dx.doi.org/10.1145/3527927.3535197			5	Art; Computer Science, Interdisciplinary Applications; Psychology, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Art; Computer Science; Psychology	BW1WJ					2024-07-03	WOS:001112150300072
J	Alahmadi, MD; Alshangiti, M				Alahmadi, Mohammad D.; Alshangiti, Moayad			Optimizing OCR Performance for Programming Videos: The Role of Image Super-Resolution and Large Language Models	MATHEMATICS			English	Article						OCR (optical character recognition); code extraction; programming screencasts; image quality; pre-processing techniques; postprocessing techniques; large language models (LLMs); source code denoising; video programming tutorials; empirical study in software engineering		The rapid evolution of video programming tutorials as a key educational resource has highlighted the need for effective code extraction methods. These tutorials, varying widely in video quality, present a challenge for accurately transcribing the embedded source code, crucial for learning and software development. This study investigates the impact of video quality on the performance of optical character recognition (OCR) engines and the potential of large language models (LLMs) to enhance code extraction accuracy. Our comprehensive empirical analysis utilizes a rich dataset of programming screencasts, involving manual transcription of source code and the application of both traditional OCR engines, like Tesseract and Google Vision, and advanced LLMs, including GPT-4V and Gemini. We investigate the efficacy of image super-resolution (SR) techniques, namely, enhanced deep super-resolution (EDSR) and multi-scale deep super-resolution (MDSR), in improving the quality of low-resolution video frames. The findings reveal significant improvements in OCR accuracy with the use of SR, particularly at lower resolutions such as 360p. LLMs demonstrate superior performance across all video qualities, indicating their robustness and advanced capabilities in diverse scenarios. This research contributes to the field of software engineering by offering a benchmark for code extraction from video tutorials and demonstrating the substantial impact of SR techniques and LLMs in enhancing the readability and reusability of code from these educational resources.	[Alahmadi, Mohammad D.; Alshangiti, Moayad] Univ Jeddah, Coll Comp Sci & Engn, Dept Software Engn, Jeddah 23890, Saudi Arabia	University of Jeddah	Alahmadi, MD (corresponding author), Univ Jeddah, Coll Comp Sci & Engn, Dept Software Engn, Jeddah 23890, Saudi Arabia.	mdalahmadi@uj.edu.sa; mshangiti@uj.edu.sa		Alahmadi, Mohammad/0000-0002-3399-2996	University of Jeddah	University of Jeddah	No Statement Available	Akli A, 2022, Arxiv, DOI arXiv:2208.14799; Alahmadi M, 2020, EMPIR SOFTW ENG, V25, P1536, DOI 10.1007/s10664-019-09759-w; Alahmadi MD, 2023, IEEE T SOFTWARE ENG, V49, P1726, DOI 10.1109/TSE.2022.3188898; Alahmadi MD, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10173175; Bao L., 2020, P 28 ACMSIGSOFT INT; Bao LF, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3392093; Bao LF, 2019, IEEE T SOFTWARE ENG, V45, P823, DOI 10.1109/TSE.2018.2802916; Bao LF, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P924, DOI 10.1145/3236024.3264587; Ben Chaaben M, 2022, Arxiv, DOI arXiv:2212.03404; Brandt J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1589; Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25; Elanwar R, 2018, INT J DOC ANAL RECOG, V21, P59, DOI 10.1007/s10032-018-0298-x; Grzywaczewski A, 2012, J COMPUT SYST SCI, V78, P1204, DOI 10.1016/j.jcss.2011.10.009; Kang SM, 2022, Arxiv, DOI arXiv:2209.11515; Khandwala K, 2018, PROCEEDINGS OF THE FIFTH ANNUAL ACM CONFERENCE ON LEARNING AT SCALE (L@S'18), DOI 10.1145/3231644.3231652; Khormi A, 2020, IEEE WORK CONF MIN S, P65, DOI 10.1145/3379597.3387468; Kim J, 2016, PROC CVPR IEEE, P1646, DOI 10.1109/CVPR.2016.182; Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.181, 10.1109/CVPR.2016.182]; Le VH, 2023, Arxiv, DOI arXiv:2302.07435; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151; Lyu Y, 2023, Arxiv, DOI arXiv:2301.03944; MacLeod L, 2017, EMPIR SOFTW ENG, V22, P1478, DOI 10.1007/s10664-017-9501-9; Malkadi A, 2023, IEEE INT CONF AUTOM, P1492, DOI 10.1109/ASE56229.2023.00184; Moslehi P, 2020, EMPIR SOFTW ENG, V25, P4873, DOI 10.1007/s10664-020-09874-z; Moslehi P, 2018, IEEE WORK CONF MIN S, P192, DOI 10.1145/3196398.3196439; Nashid N, 2023, PROC INT CONF SOFTW, P2450, DOI 10.1109/ICSE48619.2023.00205; Ott J., 2018, P 26 C PROGRAM COMPR; Ott J, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0198-z; Ott J, 2018, IEEE WORK CONF MIN S, P376, DOI 10.1145/3196398.3196402; Parra E, 2018, INT C PROGRAM COMPRE, P222, DOI 10.1145/3196321.3196351; Perianez-Pascual J, 2020, PROCEEDINGS OF THE 13TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON SOFTWARE LANGUAGE ENGINEERING, SLE 2020, P126, DOI 10.1145/3426425.3426937; Poché E, 2017, INT C PROGRAM COMPRE, P196, DOI 10.1109/ICPC.2017.26; Pongnumkul S., 2011, P 24 ANN ACM S USER, P135, DOI [DOI 10.1145/2047196.2047213.URL, 10]; Ponzanelli Luca, 2019, IEEE Transactions on Software Engineering, V45, P464, DOI 10.1109/TSE.2017.2779479; Ponzanelli L, 2016, PROC INT CONF SOFTW, P261, DOI 10.1145/2884781.2884824; Ponzanelli L, 2016, 2016 IEEE/ACM 38TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING COMPANION (ICSE-C), P645, DOI 10.1145/2889160.2889172; Semkovych V., 2022, P INT S COMP SCI DIG, P693; Shetty A, 2024, MULTIMED TOOLS APPL, V83, P11411, DOI 10.1007/s11042-023-16018-0; Siddiq M.L., 2023, P 2023 IEEEACM 2 INT; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Storey M-A, 2014, P FUT SOFTW ENG FOSE, P100, DOI [DOI 10.1145/2593882.2593887, 10.1145/2593882.2593887]; Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278; Vahedi M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2021), P434, DOI 10.1109/SANER50967.2021.00047; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yadid S, 2016, ONWARD!'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE, P98, DOI 10.1145/2986012.2986021; Lin YT, 2022, IEEE T EDUC, V65, P617, DOI 10.1109/TE.2022.3155884; Zhao D., 2019, P 41 IEEEACM INT C S	49	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	APR	2024	12	7							1036	10.3390/math12071036	http://dx.doi.org/10.3390/math12071036			19	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	NN5Y9		gold			2024-07-03	WOS:001201155400001
J	Ravi, A; Neinstein, A; Murray, SG				Ravi, Akshay; Neinstein, Aaron; Murray, Sara G.			Large Language Models and Medical Education: Preparing for a Rapid Transformation in How Trainees Will Learn to Be Doctors	ATS SCHOLAR			English	Article						artificial intelligence; large language models; medical education		Artificial intelligence has the potential to revolutionize health care but has yet to be widely implemented. In part, this may be because, to date, we have focused on easily predicted rather than easily actionable problems. Large language models (LLMs) represent a paradigm shift in our approach to artificial intelligence because they are easily accessible and already being tested by frontline clinicians, who are rapidly identifying possible use cases. LLMs in health care have the potential to reduce clerical work, bridge gaps in patient education, and more. As we enter this era of healthcare delivery, LLMs will present both opportunities and challenges in medical education. Future models should be developed to support trainees to develop skills in clinical reasoning, encourage evidence-based medicine, and offer case-based training opportunities. LLMs may also change what we continue teaching trainees with regard to clinical documentation. Finally, trainees can help us train and develop the LLMs of the future as we consider the best ways to incorporate LLMs into medical education. Ready or not, LLMs will soon be integrated into various aspects of clinical practice, and we must work closely with students and educators to make sure these models are also built with trainees in mind to responsibly chaperone medical education into the next era.	[Ravi, Akshay; Neinstein, Aaron; Murray, Sara G.] Univ Calif San Francisco, Dept Med, San Francisco, CA USA; [Neinstein, Aaron] Univ Calif San Francisco, Ctr Digital Hlth Innovat, San Francisco, CA USA; [Murray, Sara G.] Univ Calif San Francisco, Hlth Informat, San Francisco, CA USA; [Ravi, Akshay] Univ Calif San Francisco, Dept Med, 521 Parnassus Ave,Box 0131, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California San Francisco	Ravi, A (corresponding author), Univ Calif San Francisco, Dept Med, 521 Parnassus Ave,Box 0131, San Francisco, CA 94143 USA.	akshay.ravi@ucsf.edu	Neinstein, Aaron/X-6909-2019	Neinstein, Aaron/0000-0002-9774-7180				Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brynjolfsson E, 2017, Harvard Business Review, V106, P3; Chui M, 2022, The state of AI in 2022-and a half decade in review; Djulbegovic B, 2017, LANCET, V390, P415, DOI 10.1016/S0140-6736(16)31592-6; Gabrielson AT, 2023, J UROLOGY, V209, P827, DOI 10.1097/JU.0000000000003383; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Glass Health, The first digital notebook designed for doctors; GUYATT G, 1992, JAMA-J AM MED ASSOC, V268, P2420, DOI 10.1001/jama.1992.03490170092032; Ho T, 2021, J GEN INTERN MED, V36, P3307, DOI 10.1007/s11606-020-06540-4; Hugging Face, Evaluating language model bias with evaluate; icml, 2023, CLAR LARG LANG MOD P; Ingram D., 2023, NBC News; Johnson KB, 2021, J AM MED INFORM ASSN, V28, P967, DOI 10.1093/jamia/ocaa274; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li B, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445172; Liu WS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0221606; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Medenilla A., 2023, PLoS Digital Health, V2; Mir TH, 2019, J AM BOARD FAM MED, V32, P65, DOI 10.3122/jabfm.2019.01.180055; Murray SG, Health Aff Forefr; Oikonomidi T, 2023, J AM MED INFORM ASSN, V30, P559, DOI 10.1093/jamia/ocac242; OpenAI, New AI classifier for indicating AI-written text; OpenAI, ABOUT US; OpenAI, Usage Policies; Poncelet Ann, 2008, Acad Med, V83, P444, DOI 10.1097/ACM.0b013e31816be675; Ryan R, 2014, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD007768.pub3; Schoen Cathy, 2005, Health Aff (Millwood), VSuppl Web Exclusives, pW5; Schulman J, 2022, Introducing chatgpt; Seneviratne MG, 2020, BMJ INNOV, V6, P45, DOI 10.1136/bmjinnov-2019-000359; Shanafelt TD, 2012, ARCH INTERN MED, V172, P1377, DOI 10.1001/archinternmed.2012.3199; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Soleimani H, 2020, AMIA ANN S; tiktok, ABOUT US; U.S. Department of Health and Human Services, 2021, Artificial intelligence (AI) at HHS; Venigalla A, Mosaic; West CP, 2018, J INTERN MED, V283, P516, DOI 10.1111/joim.12752; Wong A, 2021, JAMA INTERN MED, V181, P1065, DOI 10.1001/jamainternmed.2021.2626; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhang A, 2022, NAT BIOMED ENG, V6, P1330, DOI 10.1038/s41551-022-00898-y	44	1	1	7	11	AMER THORACIC SOC	NEW YORK	25 BROADWAY, 18 FL, NEW YORK, NY 10004 USA		2690-7097		ATS SCHOLAR	ATS Scholar	SEP	2023	4	3					282	292		10.34197/ats-scholar.2023-0036PS	http://dx.doi.org/10.34197/ats-scholar.2023-0036PS			11	Critical Care Medicine; Respiratory System	Emerging Sources Citation Index (ESCI)	General & Internal Medicine; Respiratory System	U2DG4	37795112	Green Published, gold			2024-07-03	WOS:001082956300007
J	Sahoo, SS; Plasek, JM; Xu, H; Uzuner, O; Cohen, T; Yetisgen, M; Liu, HF; Meystre, S; Wang, YS				Sahoo, Satya S.; Plasek, Joseph M.; Xu, Hua; Uzuner, Ozlem; Cohen, Trevor; Yetisgen, Meliha; Liu, Hongfang; Meystre, Stephane; Wang, Yanshan			Large language models for biomedicine: foundations, opportunities, challenges, and best practices	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Review; Early Access						clinical natural language processing; large language models; transformer neural networks; transfer learning; medical informatics applications		Objectives Generative large language models (LLMs) are a subset of transformers-based neural network architecture models. LLMs have successfully leveraged a combination of an increased number of parameters, improvements in computational efficiency, and large pre-training datasets to perform a wide spectrum of natural language processing (NLP) tasks. Using a few examples (few-shot) or no examples (zero-shot) for prompt-tuning has enabled LLMs to achieve state-of-the-art performance in a broad range of NLP applications. This article by the American Medical Informatics Association (AMIA) NLP Working Group characterizes the opportunities, challenges, and best practices for our community to leverage and advance the integration of LLMs in downstream NLP applications effectively. This can be accomplished through a variety of approaches, including augmented prompting, instruction prompt tuning, and reinforcement learning from human feedback (RLHF).Target Audience Our focus is on making LLMs accessible to the broader biomedical informatics community, including clinicians and researchers who may be unfamiliar with NLP. Additionally, NLP practitioners may gain insight from the described best practices.Scope We focus on 3 broad categories of NLP tasks, namely natural language understanding, natural language inferencing, and natural language generation. We review the emerging trends in prompt tuning, instruction fine-tuning, and evaluation metrics used for LLMs while drawing attention to several issues that impact biomedical NLP applications, including falsehoods in generated text (confabulation/hallucinations), toxicity, and dataset contamination leading to overfitting. We also review potential approaches to address some of these current challenges in LLMs, such as chain of thought prompting, and the phenomena of emergent capabilities observed in LLMs that can be leveraged to address complex NLP challenge in biomedical applications.	[Sahoo, Satya S.] Case Western Reserve Univ, Sch Med, Dept Populat & Quantitat Hlth Sci, Wolstein Res Bldg, Cleveland, OH 44122 USA; [Plasek, Joseph M.] Harvard Med Sch, Brigham & Womens Hosp, Div Gen Internal Med & Primary Care, Cambridge, MA 02115 USA; [Xu, Hua] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT 06510 USA; [Uzuner, Ozlem] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA; [Cohen, Trevor; Yetisgen, Meliha] Univ Washington, Dept Biomed Informat & Med Educ, Seattle, WA 98109 USA; [Liu, Hongfang] Univ Texas Hlth Sci Ctr Houston, Dept Hlth Data Sci & Artificial Intelligence, Houston, TX 77030 USA; [Meystre, Stephane] Univ Appl Sci & Arts Southern Switzerland, Inst Digital Technol Personalised Healthcare, Dipartimento Tecnol Innovat, CH-6962 Lugano, Switzerland; [Wang, Yanshan] Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA; [Wang, Yanshan] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15206 USA	University System of Ohio; Case Western Reserve University; Harvard University; Brigham & Women's Hospital; Yale University; George Mason University; University of Washington; University of Washington Seattle; University of Texas System; University of Texas Health Science Center Houston; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Sahoo, SS (corresponding author), Case Western Reserve Univ, Sch Med, Dept Populat & Quantitat Hlth Sci, Wolstein Res Bldg, Cleveland, OH 44122 USA.	satya.sahoo@case.edu	Plasek, Joseph/AAI-8263-2020	Plasek, Joseph/0000-0002-9686-3876; Sahoo, Satya/0000-0001-9190-4256; Meystre, Stephane/0000-0002-7632-9625	US National Institutes of Health (NIH) [U24EB029005, R01DA053028]; US Department of Defense (DoD) [W81XWH2110859]; Dravet Syndrome Foundation; Clinical and Translational Science Collaborative of Cleveland - NIH, National Center for Advancing Translational Sciences, Clinical and Translational Science Award grant [UL1TR002548]; NIH [UL1TR001857, U24TR004111, R01LM014306, R21LM013934, R01LM014056, R01LM014056-S1]	US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); US Department of Defense (DoD)(United States Department of Defense); Dravet Syndrome Foundation; Clinical and Translational Science Collaborative of Cleveland - NIH, National Center for Advancing Translational Sciences, Clinical and Translational Science Award grant; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	S.S.S. was funded in part by the grants from the US National Institutes of Health (NIH): U24EB029005, R01DA053028, the US Department of Defense (DoD) grant W81XWH2110859, the Dravet Syndrome Foundation, and the Clinical and Translational Science Collaborative of Cleveland, which is funded by the NIH, National Center for Advancing Translational Sciences, Clinical and Translational Science Award grant, UL1TR002548. The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH. Y.W. was funded in part by the NIH through grants UL1TR001857, U24TR004111, and R01LM014306. J.M.P. reports receiving personal fees from Credo Health unrelated to the submitted work. T.C. was funded in part by the NIH through grants R21LM013934, R01LM014056, and R01LM014056-S1.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alayrac JB., 2022, Advances in Neural Information Processing Systems (NeurIPS); Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], Google API; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chowdhery A, 2023, J MACH LEARN RES, V24; Christiano PF, 2017, ADV NEUR IN, V30; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du N, 2022, PR MACH LEARN RES; Fedus W, 2022, J MACH LEARN RES, V23; Fyodorov Y., 2000, P 2 WORKSHOP INFEREN; Han TY, 2023, Arxiv, DOI [arXiv:2304.08247, DOI 10.48550/ARXIV.2304.08247]; Hasan T, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4693; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; MacCartney B., 2009, Natural Language Inference; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Mostafazadeh N., 2016, P 2016 C N AM CHAPTE; Narayan S, 2021, T ASSOC COMPUT LING, V9, P1475, DOI 10.1162/tacl_a_00438; Nie Yixin, 2020, P 58 ANN M ASS COMPU, P4885, DOI [10.18653/v1/2020.acl-main.441, DOI 10.18653/V1/2020.ACL-MAIN.441, DOI 10.18653/V1/2020.ACL-MAIN, 10.18653/.v1/2020.acl-main.441]; Nori H., 2023, Medicine, V84, P77; Nye Maxwell, 2021, arXiv; Oniani D., 2023, AMIA SUMMITS TRANSLA; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Paperno D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1525; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Shazeer N., 2017, arXiv, DOI DOI 10.48550/ARXIV.1701.06538; Shazeer N, 2020, Arxiv, DOI arXiv:2002.05202; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Smith S, 2022, arXiv; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang A, 2019, ADV NEUR IN, V32; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu CY, 2023, Arxiv, DOI [arXiv:2304.14454, DOI 10.48550/ARXIV.2304.14454]; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	56	0	0	23	23	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 24	2024										10.1093/jamia/ocae074	http://dx.doi.org/10.1093/jamia/ocae074		APR 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	OL3V6	38657567				2024-07-03	WOS:001207398900001
J	Rajan, K; Treves, A; Gaudenzi, R				Rajan, Kanaka; Treves, Alessandro; Gaudenzi, Rocco			Reflections on Simplicity and Complexity in Computational Neuroscience	HUMAN ARENAS			English	Article; Early Access						Modelling practices in physics and biology; Computational neuroscience; Physics modelling of thought; Large language models		This double interview with two distinguished researchers in computational neuroscience, Kanaka Rajan and Alessandro Treves, aims to capture a part of their talks and discussions that emerged during a workshop on physical modelling of thought, held in Berlin in January 2023. The topic is the fascinating all-round intersection of physics and neuroscience through the perspectives of the interviewees. The dialogue traverses the complex terrain of modelling thought processes, shedding light on the trade-off between simplicity and complexity that defines the field of computational neuroscience. From the early days of physics-inspired brain models to the cutting-edge advancements in large language models, the interviewees share their journey, challenges, and insights into the modelling of physical and biological systems; they recount their experience with computational neuroscience, explore the impact of large language models on our understanding of human language and cognition, and speculate on the future directions of physics-inspired computational neuroscience, emphasising the importance of interdisciplinary collaboration and a deeper integration of complexity and detail in modelling the brain and its functions.	[Rajan, Kanaka] Icahn Sch Med Mt Sinai, Dept Neurosci, New York, NY USA; [Rajan, Kanaka] Icahn Sch Med Mt Sinai, Friedman Brain Inst, New York, NY USA; [Treves, Alessandro] SISSA Cognit Neurosci, Trieste, Italy; [Gaudenzi, Rocco] Univ Verona, Dept Human Sci, Verona, Italy	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; International School for Advanced Studies (SISSA); University of Verona	Gaudenzi, R (corresponding author), Univ Verona, Dept Human Sci, Verona, Italy.	rocco.gaudenzi@univr.it			Universit degli Studi di Verona	Universit degli Studi di Verona	No Statement Available	AMIT DJ, 1985, PHYS REV LETT, V55, P1530, DOI 10.1103/PhysRevLett.55.1530; Mezard Marc, 2022, Europhysics News, V53, P15, DOI 10.1051/epn/2022105; Ryom Kwang Il, 2023, PRX Life, DOI 10.1103/PRXLife.1.013005	3	0	0	0	0	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2522-5790	2522-5804		HUMAN ARENAS	Hum. Arenas	2024 JUN 21	2024										10.1007/s42087-024-00423-4	http://dx.doi.org/10.1007/s42087-024-00423-4		JUN 2024	9	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	UX3S0		hybrid			2024-07-03	WOS:001251330600001
C	Guo, C; Tang, JM; Hu, WM; Leng, JW; Zhang, C; Yang, F; Liu, YX; Guo, MY; Zhu, YH			ACM	Guo, Cong; Tang, Jiaming; Hu, Weiming; Leng, Jingwen; Zhang, Chen; Yang, Fan; Liu, Yunxin; Guo, Minyi; Zhu, Yuhao			OliVe: Accelerating Large Language Models via Hardware-friendly Outlier-Victim Pair Quantization	PROCEEDINGS OF THE 2023 THE 50TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, ISCA 2023	Conference Proceedings Annual International Symposium on Computer Architecture		English	Proceedings Paper	50th Annual International Symposium on Computer Architecture (ISCA)	JUN 17-21, 2023	Orlando, FL	IEEE, Assoc Comp Machinery, ACMSIGARCH, Alphabet, Ant Res, ARM, FutureWei Technologies, Qualcomm, Univ Cent Florida, IBM, VMware, AMD, Samsung		Large Language Model; Outlier-Victim Pair; Quantization		Transformer-based large language models (LLMs) have achieved great success with the growing model size. LLMs' size grows by 240x every two years, which outpaces the hardware progress and makes model inference increasingly costly. Model quantization is a promising approach to mitigate the widening gap between LLM size and hardware capacity. However, the existence of outliers, values with significant magnitudes, in LLMs makes existing quantization methods less effective. Prior outlier-aware quantization schemes adopt sparsity encoding techniques to separate outliers from normal values where the process requires global coordination (e.g., a global sparsity coordination list). This incurs complex encoding/decoding hardware logics and an extra orchestration controller for the computation between outlier and normal values. As such, it is not hardware-efficient and hence only achieves sub-optimal quantization benefits. We propose OliVe, an algorithm/architecture co-designed solution that adopts an outlier-victim pair (OVP) quantization and handles outlier values locally with low hardware overheads and high performance gains. The key insight of OliVe is that outliers are important while the normal values next to them are not. Thus those normal values (called victims) can be sacrificed to accommodate outliers. This enables a memory-aligned OVP encoding scheme, which can be efficiently integrated to the existing hardware accelerators like systolic array and tensor core. As a result, OliVe-based accelerator surpasses the existing outlier-aware accelerator, GOBO, by 4.5x speedup and 4.0x energy reduction, respectively, with a superior model accuracy.	[Guo, Cong; Tang, Jiaming; Hu, Weiming; Leng, Jingwen; Guo, Minyi] Shanghai Jiao Tong Univ, Shanghai Qi Zhi Inst, Shanghai, Peoples R China; [Zhang, Chen; Yang, Fan] Microsoft Res, Beijing, Peoples R China; [Liu, Yunxin] Tsinghua Univ, Inst AI Ind Res AIR, Beijing, Peoples R China; [Liu, Yunxin] Shanghai Artificial Intelligence Lab, Shanghai, Peoples R China; [Zhu, Yuhao] Univ Rochester, Rochester, NY USA; [Hu, Weiming] ShanghaiTech Univ, Shanghai, Peoples R China	Shanghai Jiao Tong University; Microsoft; Tsinghua University; University of Rochester; ShanghaiTech University	Leng, JW; Guo, MY (corresponding author), Shanghai Jiao Tong Univ, Shanghai Qi Zhi Inst, Shanghai, Peoples R China.	guocong@sjtu.edu.cn; sakits_tjm@sjtu.edu.cn; huweim1120@gmail.com; leng-jw@cs.sjtu.edu.cn; chzhang1990@gmail.com; fanyang@microsoft.com; liuyunxin@air.tsinghua.edu.cn; guo-my@cs.sjtu.edu.cn; yzhu@rochester.edu	hu, weiming/IQW-3171-2023; Leng, Jingwen/V-2299-2019; Zhang, Chen/AAE-9066-2022; Guo, Cong/KFA-2948-2024	Leng, Jingwen/0000-0002-5660-5493; Zhang, Chen/0000-0003-2762-2726; Hu, Weiming/0009-0003-5115-0498; Guo, Cong/0000-0002-4479-5525	National Key R&D Program of China [2022YFB4501401]; National Natural Science Foundation of China (NSFC) [62222210, 62072297, 61832006]	National Key R&D Program of China; National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This work was supported by the National Key R&D Program of China under Grant 2022YFB4501401, the National Natural Science Foundation of China (NSFC) grant (62222210, and 62072297, and 61832006). The authors would like to thank the anonymous reviewers for their constructive feedback for improving the work. We also thank Tailong Wangliu, Shuangjie Ruan for their continuous support.	Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11; [Anonymous], 2020, Nvidia ampere architecture whitepaper; Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648; Banner R, 2019, ADV NEUR IN, V32; Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1; Cai ZW, 2020, PROC CVPR IEEE, P2346, DOI 10.1109/CVPR42600.2020.00242; Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700; Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368; Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579; Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967; Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357; Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58; Choi Jungwook, 2018, ARXIV180506085; Choi Y, 2021, INT S HIGH PERF COMP, P493, DOI 10.1109/HPCA51647.2021.00049; Cui WH, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P183; Cui WH, 2019, PR IEEE COMP DESIGN, P497, DOI 10.1109/ICCD46524.2019.00075; Dettmers Tim, 2022, arXiv; Devlin J., 2018, BERT PRE TRAINING DE; Dodge Jesse, 2021, ARXIV210408758; Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038; Dong Zhen, 2020, P ADV NEUR INF PROC, V33, P18518; Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389; Gholami A, 2021, RiseLab Medium Post; Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106; Guan Y, 2022, AAAI CONF ARTIF INTE, P10710; Guan Yue, 2020, arXiv; Guan Yue, 2022, arXiv; Guo C, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218732; Guo C, 2022, PR IEEE COMP DESIGN, P738, DOI 10.1109/ICCD56317.2022.00113; Guo C, 2022, INT SYMP MICROARCH, P1414, DOI 10.1109/MICRO56248.2022.00095; Guo Cong, 2020, SC20, P1; Guo Cong, 2022, INT C LEARN REPR; Guo Cong, 2022, ANT github repository; Gupta S, 2015, PR MACH LEARN RES, V37, P1737; Han S., 2015, INT C LEARN REPR, V56, P3; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286; Jain S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317783; Jia ZH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P47, DOI 10.1145/3341301.3359630; Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448; Kerr Andrew, 2022, CUTLASS, P8; Khairy M, 2020, ANN I S COM, P473, DOI 10.1109/ISCA45697.2020.00047; Kurup P., 2012, Logic synthesis using Synopsys<(R); Le Scao Teven, 2022, ARXIV221105100; Leng J., 2013, P INT S COMP ARCH IS, V41, P487; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li Peng, 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060; Li Zhengyi, 2022, arXiv; Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358; Liu ZH, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P388, DOI 10.1145/3503222.3507752; Lo D, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P450, DOI 10.1145/2749469.2749475; Mars J, 2011, INT SYMP MICROARCH, P248; ModelTC, 2022, repositories; Muralimanohar N., 2009, P INT S MICR, V27, P28; Nagel Markus, 2021, ARXIV210608295; Nvidia, 2018, Technical report; Nvidia, 2020, Technical report; Nvidia, 2017, Technical report; Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063; Paszke A, 2019, ADV NEUR IN, V32; Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019; Qin Q, 2020, IEEE INT SYMP PHYS, DOI 10.1109/ipfa49335.2020.9260906; Qiu YX, 2019, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2019.00491; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raihan MA, 2019, INT SYM PERFORM ANAL, P79, DOI 10.1109/ISPASS.2019.00016; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Sarangi S., 2021, 2021 IEEE ISCAS, P1; Sharma H, 2016, INT SYMP MICROARCH; Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069; Sharma Hardik, 2018, Bitfusion github repository; Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815; Song ZR, 2020, ANN I S COM, P1010, DOI 10.1109/ISCA45697.2020.00086; Tambe T, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218516; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang K, 2019, PROC CVPR IEEE, P11899, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]; Wang Y, 2021, CONF PROC INT SYMP C, P1083, DOI 10.1109/ISCA52012.2021.00088; Wang ZW, 2019, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2019.00066; Wei Xiuying, 2022, Advances in Neural Information Processing Systems; Wikipedia contributors, 2022, 68-95-99.7 rule-Wikipedia, The Free Encyclopedia; Yang H., 2013, P 40 ANN INT S COMPU, P607; Yaohui Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13166, DOI 10.1109/CVPR42600.2020.01318; Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071; Zafrir O, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016; Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23; Zhang S., 2022, arXiv; Zhang SJ, 2016, INT SYMP MICROARCH; Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863; Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508; Zhou S. C., 2016, DOREFA NET TRAINING; Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011; Zhou YJ, 2023, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 2, ASPLOS 2023, P878, DOI 10.1145/3575693.3575723; Zhou YJ, 2021, I S WORKL CHAR PROC, P214, DOI 10.1109/IISWC53511.2021.00029; Zhu HY, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P233; Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269; Zhuang BH, 2022, IEEE T PATTERN ANAL, V44, P6140, DOI 10.1109/TPAMI.2021.3088904	98	2	2	6	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES	1063-6897		979-8-4007-0095-8	CONF PROC INT SYMP C			2023							33	47		10.1145/3579371.3589038	http://dx.doi.org/10.1145/3579371.3589038			15	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0OY		Green Submitted			2024-07-03	WOS:001098723900003
C	Zhu, YH; Zhou, QY			ACM	Zhu, Yihao; Zhou, Qinyi			Docent: Digital Operation-Centric Elicitation of Novice-friendly Tutorials	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		Software Tutorials; Digital Operation; Large Language Model		Nowadays, novice users often turn to digital tutorials for guidance in software. However, searching and utilizing the tutorial remains a challenge due to the request for proper problem articulation, extensive searches and mind-intensive follow-through. We introduce "Docent", a system designed to bridge this knowledge-seeking gap. Powered by Large Language Models (LLMs), Docent takes vague user input and recent digital operation contexts to reason, seek, and present the most relevant tutorials in-situ. We assume that Docent smooths the user experience and facilitates learning of the software.	[Zhu, Yihao; Zhou, Qinyi] Tsinghua Univ, Beijing, Peoples R China	Tsinghua University	Zhu, YH (corresponding author), Tsinghua Univ, Beijing, Peoples R China.	zhuyh22@mails.tsinghua.edu.cn; zhouqy22@mails.tsinghua.edu.cn		zhou, qy/0009-0000-1878-3646	Natural Science Foundation of China [62132010]; Beijing Key Lab of Networked Multimedia; 2025 Key Technological Innovation Program of Ningbo City [2022Z080]; Beijing Municipal Science and Technology Commission, Administrative Commission of Zhong-guancun Science Park [Z221100006722018]; Institute for Guo Qiang, Tsinghua University; Institute for Artifcial Intelligence, Tsinghua University (THUAI)	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Key Lab of Networked Multimedia; 2025 Key Technological Innovation Program of Ningbo City; Beijing Municipal Science and Technology Commission, Administrative Commission of Zhong-guancun Science Park; Institute for Guo Qiang, Tsinghua University; Institute for Artifcial Intelligence, Tsinghua University (THUAI)	This work is supported by the Natural Science Foundation of China under Grant No. 62132010, and by Beijing Key Lab of Networked Multimedia, the Institute for Guo Qiang, Tsinghua University, Institute for Artifcial Intelligence, Tsinghua University (THUAI), and by 2025 Key Technological Innovation Program of Ningbo City under Grant No. 2022Z080.; It is also supported by supported by Beijing Municipal Science and Technology Commission, Administrative Commission of Zhong-guancun Science Park No.Z221100006722018.	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chi PY, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1581, DOI 10.1145/2556288.2557254; Chundury P, 2023, INFORM VISUAL, V22, P69, DOI 10.1177/14738716221120064; Nguyen C, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1565, DOI 10.1145/2702123.2702209; Fraser CA, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300527; Lafreniere Ben, Looks cool, I'll try this later!": Understanding the Faces and Uses of Online Tutorials; Lau Tessa, Interpreting Written How-To Instructions; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mysore A, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P703, DOI 10.1145/3126594.3126628; Palani S, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P325, DOI 10.1145/3406522.3446046; Ponzanelli L, 2016, PROC INT CONF SOFTW, P261, DOI 10.1145/2884781.2884824; Ponzanelli L, 2016, 2016 IEEE/ACM 38TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING COMPANION (ICSE-C), P645, DOI 10.1145/2889160.2889172; Rieh SY, 2016, J INF SCI, V42, P19, DOI 10.1177/0165551515615841; Zhong Mingyuan, 2021, 34 ANN ACM S US INT, P1144, DOI [10.1145/3472749.3474812, DOI 10.1145/3472749.3474812]	14	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									121	10.1145/3586182.3625121	http://dx.doi.org/10.1145/3586182.3625121			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000120
J	Tsoutsanis, P; Tsoutsanis, A				Tsoutsanis, Panagiotis; Tsoutsanis, Aristotelis			Evaluation of Large language model performance on the Multi-Specialty Recruitment Assessment (MSRA) exam	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Large language models; Artificial intelligence; Medical education; Medical exam	ARTIFICIAL-INTELLIGENCE; SURGICAL EDUCATION	Introduction: AI-powered platforms have gained prominence in medical education and training, offering diverse applications from surgical performance assessment to exam preparation. This research paper examines the capabilities of Large Language Models (LLMs), including Llama 2, Google Bard, Bing Chat, and ChatGPT-3.5, in answering multiple-choice questions of the Clinical Problem Solving (CPS) paper of the Multi-Specialty Recruitment Assessment (MSRA) exam.Methods: Using a dataset of 100 CPS questions from ten subject categories, we assessed the LLMs' performance against medical doctors preparing for the exam.Results: Results showed that Bing Chat outperformed all other LLMs and even surpassed human users from the Qbank question bank. Conversely, Llama 2's performance was inferior to human users. Google Bard and ChatGPT 3.5 did not exhibit statistically significant differences in correct response rates compared to human candidates. Pairwise comparisons demonstrated Bing Chat's significant superiority over Llama 2, Google Bard, and ChatGPT 3.5. However, no significant differences were found between Llama 2 and Google Bard, Llama 2, and ChatGPT3.5, and Google Bard and ChatGPT-3.5.Discussion: Freely available LLMs have already demonstrated that they can perform as well or even outperform human users in answering MSRA exam questions. Bing Chat emerged as a particularly strong performer. The study also highlights the potential for enhancing LLMs' medical knowledge acquisition through tailored finetuning. Medical knowledge tailored LLMs such as Med-PaLM, have already shown promising results. Conclusion: We provided valuable insights into LLMs' competence in answering medical MCQs and their potential integration into medical education and assessment processes.	[Tsoutsanis, Panagiotis] Northern Care Alliance NHS Fdn Trust, Rochdale Infirm, Rochdale Eye Unit, Manchester, England; [Tsoutsanis, Panagiotis] Univ Oxford, Dept Educ, Oxford, England; [Tsoutsanis, Aristotelis] Tech Univ Munich, Dept Informat, Munich, Germany	University of Oxford; Technical University of Munich	Tsoutsanis, P (corresponding author), Northern Care Alliance NHS Fdn Trust, Rochdale Infirm, Rochdale Eye Unit, Manchester, England.	tpanos02@gmail.com	tsoutsanis, panagiotis/HJY-8745-2023	Tsoutsanis, Panagiotis/0000-0002-0438-422X				Ang TL, 2023, SINGAP MED J, V64, P219, DOI 10.4103/singaporemedj.SMJ-2023-055; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bakshi SK, 2021, BRIT J OPHTHALMOL, V105, P1325, DOI 10.1136/bjophthalmol-2020-316845; Bissonnette V., 2019, Top Training TI, V18, P1; England H.E., 2015, Applicant guidance. General practice: multi-specialty recruitment assessment, MSRA), P1; H.E. England, 2019, Multi-Specialty Recruitment Assessment (MSRA)-Test Blueprint & Information, V1-9; I. Meta Platforms, 2023, Llama 2.; Inc. A. Bard 1.0.0.0 Google AI, ABOUT US; Kirubarajan A, 2022, J SURG EDUC, V79, P500, DOI 10.1016/j.jsurg.2021.09.012; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee J, 2021, ACAD MED, V96, pS62, DOI 10.1097/ACM.0000000000004291; Lindegger DJ, 2022, OPHTHALMOL SCI, V2, DOI 10.1016/j.xops.2022.100164; Medenilla A., 2023, PLoS Digital Health, V2; Microsoft Corporation Microsoft Bing Chatbot, 2023, ABOUT US; OpenAI. GPT-3 5 model, 2021, ABOUT US; PassMedicine, 2023, MSRA question bank; Puladi B, 2024, INT J ORAL MAX SURG, V53, P78, DOI 10.1016/j.ijom.2023.09.005; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Touvron H, Llama 2: Open Foundation and Fine-Tuned Chat Models; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]	22	1	1	21	21	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	JAN	2024	168								107794	10.1016/j.compbiomed.2023.107794	http://dx.doi.org/10.1016/j.compbiomed.2023.107794		DEC 2023	5	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	DU9V4	38043471				2024-07-03	WOS:001134721800001
J	Zhang, YN; Dong, YJ; Mei, ZH; Hou, YQ; Wei, MY; Yeung, YH; Xu, JL; Hua, Q; Lai, LM; Li, N; Xia, SJ; Zhou, C; Zhou, JQ				Zhang, YuNing; Dong, Yijie; Mei, Zihan; Hou, Yiqing; Wei, Minyan; Yeung, Yat Hin; Xu, Jiale; Hua, Qing; Lai, LiMei; Li, Ning; Xia, ShuJun; Zhou, Chun; Zhou, JianQiao			Performance of large language models on benign prostatic hyperplasia frequently asked questions	PROSTATE			English	Article						artificial intelligence; benign prostatic hyperplasia; large language model		Background: Benign prostatic hyperplasia (BPH) is a common condition, yet it is challenging for the average BPH patient to find credible and accurate information about BPH. Our goal is to evaluate and compare the accuracy and reproducibility of large language models (LLMs), including ChatGPT-3.5, ChatGPT-4, and the New Bing Chat in responding to a BPH frequently asked questions (FAQs) questionnaire. Methods: A total of 45 questions related to BPH were categorized into basic and professional knowledge. Three LLM-ChatGPT-3.5, ChatGPT-4, and New Bing Chat-were utilized to generate responses to these questions. Responses were graded as comprehensive, correct but inadequate, mixed with incorrect/outdated data, or completely incorrect. Reproducibility was assessed by generating two responses for each question. All responses were reviewed and judged by experienced urologists. Results: All three LLMs exhibited high accuracy in generating responses to questions, with accuracy rates ranging from 86.7% to 100%. However, there was no statistically significant difference in response accuracy among the three (p > 0.017 for all comparisons). Additionally, the accuracy of the LLMs' responses to the basic knowledge questions was roughly equivalent to that of the specialized knowledge questions, showing a difference of less than 3.5% (GPT-3.5: 90% vs. 86.7%; GPT-4: 96.7% vs. 95.6%; New Bing: 96.7% vs. 93.3%). Furthermore, all three LLMs demonstrated high reproducibility, with rates ranging from 93.3% to 97.8%. Conclusions: ChatGPT-3.5, ChatGPT-4, and New Bing Chat offer accurate and reproducible responses to BPH-related questions, establishing them as valuable resources for enhancing health literacy and supporting BPH patients in conjunction with healthcare professionals.	[Zhang, YuNing; Dong, Yijie; Mei, Zihan; Hou, Yiqing; Wei, Minyan; Yeung, Yat Hin; Xu, Jiale; Hua, Qing; Lai, LiMei; Xia, ShuJun; Zhou, Chun; Zhou, JianQiao] Shanghai Jiao Tong Univ, Ruijin Hosp, Dept Ultrasound, Sch Med, 197 Ruijin Er Rd, Shanghai 200025, Peoples R China; [Zhang, YuNing; Dong, Yijie; Mei, Zihan; Hou, Yiqing; Wei, Minyan; Yeung, Yat Hin; Xu, Jiale; Hua, Qing; Lai, LiMei; Xia, ShuJun; Zhou, Chun; Zhou, JianQiao] Shanghai Jiao Tong Univ, Coll Hlth Sci & Technol, Sch Med, Shanghai, Peoples R China; [Li, Ning] Dali Univ, Affiliated Hosp 7, Yunnan Kungang Hosp, Dept Ultrasound, Anning, Yunnan, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University; Dali University	Xia, SJ; Zhou, C; Zhou, JQ (corresponding author), Shanghai Jiao Tong Univ, Ruijin Hosp, Dept Ultrasound, Sch Med, 197 Ruijin Er Rd, Shanghai 200025, Peoples R China.; Xia, SJ; Zhou, C; Zhou, JQ (corresponding author), Shanghai Jiao Tong Univ, Coll Hlth Sci & Technol, Sch Med, Shanghai, Peoples R China.	xiashu_jun@126.com; springirl_chun@126.com; zhousu30@126.com		Minyan, Wei/0009-0008-9140-3038	Academician Expert Workstation of Yunnan Province; National Natural Science Foundation of China [82071928];  [202105AF150087]	Academician Expert Workstation of Yunnan Province; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); 	This study was supported by National Natural Science Foundation of China (82071928) and the Academician Expert Workstation of Yunnan Province (202105AF150087).	Abdul-Muhsin H, 2017, AM J MENS HEALTH, V11, P147, DOI 10.1177/1557988315617527; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Foo KT, 2019, WORLD J UROL, V37, P1293, DOI 10.1007/s00345-019-02691-0; Kilaru AS, 2014, AM J PUBLIC HEALTH, V104, P1633, DOI 10.2105/AJPH.2014.302088; Koo K, 2017, AM J MENS HEALTH, V11, P300, DOI 10.1177/1557988316680935; Lee SI, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16561-5; Sare A, 2020, ACAD RADIOL, V27, P1549, DOI 10.1016/j.acra.2019.11.020; Somasundaram P., 2022, J PHARM NEGAT RESULT, V12, P3847; Tanwar Raman, 2015, Recenti Progressi in Medicina, V106, P337, DOI 10.1701/1940.21092	9	3	3	4	4	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0270-4137	1097-0045		PROSTATE	Prostate	JUN	2024	84	9					807	813		10.1002/pros.24699	http://dx.doi.org/10.1002/pros.24699		APR 2024	7	Endocrinology & Metabolism; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Endocrinology & Metabolism; Urology & Nephrology	PU4V8	38558009				2024-07-03	WOS:001194679200001
J	Yao, YF; Duan, JH; Xu, KD; Cai, YF; Sun, ZB; Zhang, Y				Yao, Yifan; Duan, Jinhao; Xu, Kaidi; Cai, Yuanfang; Sun, Zhibo; Zhang, Yue			A Survey on Large Language Model (LLM) Security and Privacy: The Good, The Bad, and The Ugly	HIGH-CONFIDENCE COMPUTING			English	Review						Large Language Model (LLM); LLM security; LLM privacy; ChatGPT; LLM attacks; LLM vulnerabilities	ATTACKS	Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into "The Good"(beneficial LLM applications), "The Bad"(offensive applications), and "The Ugly"(vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs' potential to both bolster and jeopardize cybersecurity. (c) 2024 The Author(s). Published by Elsevier B.V. on behalf of Shandong University. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	[Yao, Yifan; Duan, Jinhao; Xu, Kaidi; Cai, Yuanfang; Sun, Zhibo; Zhang, Yue] Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA	Drexel University	Zhang, Y (corresponding author), Drexel Univ, Dept Comp Sci, Philadelphia, PA 19104 USA.	yz899@drexel.edu		Yao, Yifan/0000-0002-2334-3984	National Science Foundation award [FMitF-2319242]	National Science Foundation award(National Science Foundation (NSF))	This research was supported partly by the National Science Foundation award FMitF-2319242. Any opinions, findings, conclusions, or recommendations expressed are those of the authors and not necessarily of the NSF.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aghakhani H, 2024, Arxiv, DOI arXiv:2301.02344; Ahmad B, 2023, Arxiv, DOI [arXiv:2302.01215, 10.48550/arXiv.2302.01215]; Al-Hawawreh M, 2023, CLUSTER COMPUT, V26, P3421, DOI 10.1007/s10586-023-04124-5; Alagarsamy S, 2023, Arxiv, DOI arXiv:2302.10352; Alawida M., 2023, PREPRINT; Ali T, 2023, Arxiv, DOI [arXiv:2309.16021, DOI 10.48550/ARXIV.2309.16021]; Ambikairajah E, 2011, IEEE CIRC SYST MAG, V11, P82, DOI 10.1109/MCAS.2011.941081; Amos Z, 2023, What is fraudgpt?; Anderson J.R., 2014, The Atomic Components of Thought, DOI DOI 10.4324/9781315805696; [Anonymous], 2023, 12 INT C LEARN REPR; Arcila B.B., 2023, J. Free Speech L., V3, P455; Bailey AH, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm2463; Bakhshandeh A., 2023, arXiv; Barikeri S, 2021, Arxiv, DOI arXiv:2106.03521; Ben-Moshe S., 2022, Check point research, V2023; Bhojani AR, 2023, THEOL SCI, V21, P557, DOI 10.1080/14746700.2023.2255944; Bianchi F, 2024, Arxiv, DOI arXiv:2309.07875; Bordia S, 2019, Arxiv, DOI arXiv:1904.03035; Botacin M, 2023, IEEE SEC PRIV WORKS, P238, DOI 10.1109/SPW59333.2023.00027; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Burgess M, 2023, ChatGPT has a plug-in problem; Cai YZ, 2024, Arxiv, DOI arXiv:2304.08103; Cao B, 2023, Defending against alignment-breaking attacks via robustly aligned llm; Carlini N, 2022, P IEEE S SECUR PRIV, P1897, DOI [10.1109/SP46214.2022.9833649, 10.1109/SP46214.2022.00090]; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Caven P., 2023, ChatGPT's Influence on CybersecurityApril 30,; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Charan P.V.S., 2023, From text to MITRE techniques: Exploring the malicious use of large language models for generating cyber attack payloads; Chen B., 2022, ARXIV; Chen BC, 2023, Arxiv, DOI arXiv:2310.02417; Chen C., 2023, Can LLM-generated misinformation be detected?; Chen C., 2023, Combating misinformation in the age of llms: Opportunities and challenges; Chen C, 2023, Arxiv, DOI arXiv:2309.05520; Chen TY, 2024, Arxiv, DOI [arXiv:2308.04662, 10.48550/arXiv.2308.04662, DOI 10.48550/ARXIV.2308.04662]; Chen XJ, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112948; Chen Y., 2023, Can large language models provide security & privacy advice? Measuring the ability of LLMs to refute misconceptions; Cheshkov A, 2023, Arxiv, DOI arXiv:2304.07232; Choquette-Choo CA, 2021, PR MACH LEARN RES, V139; Chowdhury Minhaz, 2023, 2023 IEEE International Conference on Electro Information Technology (eIT), P499, DOI 10.1109/eIT57321.2023.10187385; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; Dai SH, 2024, Arxiv, DOI arXiv:2310.20501; Dale D., 2021, arXiv; Das Purba M, 2023, 2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS, ISSREW, P112, DOI 10.1109/ISSREW60843.2023.00058; Dash B., 2023, Int. J. Eng. Appl. Sci., V10; Databricks, 2023, Free dolly: Introducing the world's first open and commercially viable instruction-tuned LLM; Debenedetti E, 2023, Arxiv, DOI arXiv:2309.05610; Delley D., 2023, WormGPT-The generative AI tool cybercriminals are using to launch business email compromise attacks; Deng G., 2024, P 31 ANN NETW DISTR; Deng GL, 2024, Arxiv, DOI arXiv:2308.06782; Deng GL, 2023, Arxiv, DOI arXiv:2307.08715; Deng Y., 2024, 2024 IEEE ACM 46 INT, P830; Deng Y. Li, 2022, arXiv; Deng YL, 2023, Arxiv, DOI arXiv:2304.02014; Derner E., 2023, Beyond the safeguards: Exploring the security risks of ChatGPT; Derner E, 2023, Arxiv, DOI arXiv:2311.11415; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhoni P., 2023, TechRxiv.; Ding HT, 2023, Arxiv, DOI arXiv:2306.03203; Ding X., 2023, P SC 23 WORKSH INT C, DOI [10.1145/3624062.3624172, DOI 10.1145/3624062.3624172]; Dong X., 2021, Advances in Neural Information Processing Systems, V34, P4356; Dong XJ, 2023, Arxiv, DOI arXiv:2311.00306; Duan J, 2023, INT C MACHINE LEARNI, P8717; Duan JH, 2024, Arxiv, DOI arXiv:2307.01379; Duarte Fabio, 2023, Number of chatgpt users; Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1; Egersdoerfer C., 2023, Early exploration of using ChatGPT for log-based anomaly detection on parallel file systems logs; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Elhafsi A, 2023, AUTON ROBOT, V47, P1035, DOI 10.1007/s10514-023-10132-6; Eli S., 2023, Self-enhancing pattern detection with LLMs: Our answer to uncovering malicious packages at scale; Espinha Gasiba T., 2023, 4 INT COMP PROGR ED; Falade P.V., 2023, Intl Journal of Scientific Research in Computer Science, Engineering and Information Technology, P185, DOI [DOI 10.32628/CSEIT2390533, 10.32628/cseit2390533]; Fan A., 2023, Large language models for software engineering: Survey and open problems; Fan T, 2023, Arxiv, DOI arXiv:2310.10049; Fang X, 2024, Arxiv, DOI arXiv:2309.09825; Farah JC, 2022, IEEE GLOB ENG EDUC C, P1634, DOI 10.1109/EDUCON52537.2022.9766793; Felkner VK, 2023, Arxiv, DOI [arXiv:2306.15087, DOI 10.48550/ARXIV.2306.15087]; Feng SY, 2021, Arxiv, DOI [arXiv:2105.03075, DOI 10.48550/ARXIV.2105.03075]; Fu M., 2023, ChatGPT for vulnerability detection, classification, and repair: How far are we?; Fu W., 2023, A probabilistic fluctuation based membership inference attack for diffusion models; Fu W., 2023, Practical membership inference attacks against fine-tuned large language models via self-prompt calibration; Ganesh P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1789, DOI 10.1145/3593013.3594116; Gao C.A., 2022, bioRxiv., P2012; Gehman S, 2020, Arxiv, DOI [arXiv:2009.11462, DOI 10.1017/S1431927621007376]; Greshake K, 2023, Arxiv, DOI arXiv:2302.12173; Gu QH, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P2201, DOI 10.1145/3611643.3617850; Gu ZP, 2023, Arxiv, DOI arXiv:2308.15366; Gupta M., 2023, IEEE Access; Hadi M.U., 2023, TECHRXIV; Happe A., 2023, Evaluating LLMs for privilege-escalation scenarios; Happe A, 2023, Arxiv, DOI [arXiv:2308.00121, 10.1145/3611643.3613083]; Hayes J, 2018, Arxiv, DOI arXiv:1705.07663; Hazell J, 2023, Large language models can be used to effectively scale spear phishing campaigns; He JX, 2023, PROCEEDINGS OF THE 2023 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, CCS 2023, P1865, DOI 10.1145/3576915.3623175; He X., 2024, 2024 IEEE S SEC PRIV; He XL, 2023, Arxiv, DOI arXiv:2308.05596; Heiding F, 2023, Devising and detecting phishing: Large language models vs. smaller human models; Helbling A., 2023, arXiv; Helmke R., 2023, DETECTION INTRUSIONS, V3959, P201; Henrik P., 2023, LLM-assisted malware review: AI and humans join forces to combat malware; Hernandez D, 2022, Arxiv, DOI arXiv:2205.10487; Hettwer B, 2020, J CRYPTOGR ENG, V10, P135, DOI 10.1007/s13389-019-00212-8; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Hu J, 2023, Arxiv, DOI arXiv:2306.06782; Hu SH, 2023, Arxiv, DOI [arXiv:2310.01152, 10.48550/arXiv.2310.01152]; Huang D, 2024, Arxiv, DOI [arXiv:2309.14345, 10.48550/arXiv.2309.14345, DOI 10.48550/ARXIV.2309.14345]; Huang HW, 2022, IEEE T DEPEND SECURE, V19, P3183, DOI 10.1109/TDSC.2021.3088480; Huang J., 2022, arXiv; Igure VM, 2008, IEEE COMMUN SURV TUT, V10, P6, DOI 10.1109/COMST.2008.4483667; Iqbal U., 2023, LLM Platform Security: Applying a Systematic Evaluation Framework to OpenAI's ChatGPT Plugins; Ivgi M., 2021, arXiv; Jain N, 2023, Arxiv, DOI arXiv:2309.00614; Jain R., 2023, P 16 INN SOFTW ENG C, P1; Jamal S., 2023, An improved transformer-based model for detecting phishing, spam, and ham: A large language model approach; Jayaraman B, 2021, Arxiv, DOI arXiv:2005.10881; Jiang HM, 2021, Arxiv, DOI arXiv:1911.03437; Jiang JA, 2023, Arxiv, DOI arXiv:2307.13896; Jiang N, 2023, PROC INT CONF SOFTW, P1430, DOI 10.1109/ICSE48619.2023.00125; Jiang SY, 2023, Arxiv, DOI arXiv:2310.10077; Jin M, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P1646, DOI 10.1145/3611643.3613892; Jin Xin, 2022, CCS '22: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, P1631, DOI 10.1145/3548606.3560612; Jin X, 2023, Binary code summarization: Benchmarking ChatGPT/GPT-4 and other large language models; Joshi C., 2015, Int. J, V5; Joulin A, 2016, Arxiv, DOI [arXiv:1612.03651, DOI 10.48550/ARXIV.1612.03651]; Juuti M, 2019, 2019 4TH IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P), P512, DOI 10.1109/EuroSP.2019.00044; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kandpal N., 2023, User inference attacks on large language models; Kandpal N., 2023, arXiv; Kandpal N, 2022, PR MACH LEARN RES, P10697; Kang D., 2023, arXiv; Kang S., 2023, 2023 IEEE ACM 45 INT; Kariyappa S, 2021, PROC CVPR IEEE, P13809, DOI 10.1109/CVPR46437.2021.01360; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Khalil M, 2023, Arxiv, DOI arXiv:2302.04335; Khatibi E, 2023, INT CONF WEARAB IMPL, DOI 10.1109/BSN58485.2023.10331423; Kirchenbauer J., 2023, arXiv; Koch Chris, 2023, I used GPT-3 to find 213 security vulnerabilities in a single codebase; Koide T, 2024, Arxiv, DOI arXiv:2306.05816; Kong F, 2023, Arxiv, DOI arXiv:2305.18355; Kotek Hadas, 2023, CI '23: Proceedings of The ACM Collective Intelligence Conference, P12, DOI 10.1145/3582269.3615599; Kuang WR, 2023, Arxiv, DOI arXiv:2309.00363; Kumari K., 2024, P 31 ANN NETW DISTR; Kumari K, 2023, Arxiv, DOI arXiv:2311.05019; Kurita K, 2020, Arxiv, DOI arXiv:2004.06660; Kwon H., 2023, Novel approach to cryptography implementation using ChatGPT; Laird JE, 2017, AI MAG, V38, P13, DOI 10.1609/aimag.v38i4.2744; Langford Tyson, 2023, Proceedings of the Future Technologies Conference (FTC) 2023. Lecture Notes in Networks and Systems (813), P174, DOI 10.1007/978-3-031-47454-5_13; Laurencon H., 2022, Advances in Neural Information Processing Systems, V35, P31809; Lee KTRE, 2022, Arxiv, DOI arXiv:2107.06499; Lee T., 2023, Who wrote this code? Watermarking for code generation,; Leite J.A., 2023, Detecting misinformation with LLM-predicted credibility signals and weak supervision; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Leskovec Jure, 2020, Mining of massive data sets; Li CY, 2023, Arxiv, DOI arXiv:2311.13624; Li HR, 2023, Arxiv, DOI [arXiv:2304.05197, 10.48550/arXiv.2304.05197]; Li HR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5858; Li J., 2023, Evaluating the impact of ChatGPT on exercises of a software security course; Li JZ, 2023, Arxiv, DOI arXiv:2304.14475; Li LY, 2023, Arxiv, DOI arXiv:2203.14207; Li LY, 2021, AAAI CONF ARTIF INTE, V35, P8410; Li X., 2021, ARXIV; Li Y, 2023, Multi-target backdoor attacks for code pre-trained models; Li YS, 2023, Arxiv, DOI arXiv:2305.06212; Li Z, 2023, Evaluating the instruction-following robustness of large language models to prompt injection; Li ZJ, 2023, PROCEEDINGS OF THE 2023 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, CCS 2023, P2336, DOI 10.1145/3576915.3623120; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Liu B., 2023, Secur. Commun. Netw., V2023; Liu CY, 2023, Arxiv, DOI arXiv:2309.11830; Liu P., 2023, Harnessing the power of LLM to support binary taint analysis; Liu T., 2023, Demystifying RCE vulnerabilities in LLM-integrated apps; Liu X, 2020, arXiv; Liu XG, 2024, Arxiv, DOI arXiv:2310.04451; Liu Y, 2023, Arxiv, DOI arXiv:2306.05499; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Logacheva V, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6804; Lyu LJ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2355; Ma QY, 2023, J MOL MED, DOI 10.1007/s00109-023-02389-2; Madry A, 2019, Arxiv, DOI arXiv:1706.06083; Mahloujifar S., 2021, arXiv; Majmudar J, 2022, Arxiv, DOI arXiv:2205.13621; Marshall J., 2023, What effects do large language models have on cybersecurity; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McIntosh T, 2023, COMPUT SECUR, V134, DOI 10.1016/j.cose.2023.103424; Meade N., 2021, arXiv; Meng R., 2024, P 31 ANN NETW DISTR; Meta AI, 2023, Introducing llama: A foundational, 65-billion-parameter language model; Mireshghallah F, 2022, Quantifying privacy risks of masked language models using membership inference attacks; Mireshghallah F., 2022, P 2022 C EMPIRICAL M, P1816; Mo WJ, 2023, Arxiv, DOI arXiv:2311.09763; Monje A., 2023, Being a bad influence on the kids: Malware generation in less than five minutes using ChatGPT; Moskovskiy D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): STUDENT RESEARCH WORKSHOP, P346; Mozes M., 2023, Use of llms for illicit purposes: Threats, prevention measures, and vulnerabilities; Nair M., 2023, Paper 2023/212; Narang S., 2022, Pathways language model (palm): Scaling to 540 billion parameters for breakthrough performance; Ni A., 2023, INT C MACHINE LEARNI, P26106; Nikolic S, 2023, EUR J ENG EDUC, V48, P559, DOI 10.1080/03043797.2023.2213169; Noever D, 2023, Arxiv, DOI [arXiv:2308.10345, 10.48550/arXiv.2308.10345, DOI 10.48550/ARXIV.2308.10345]; Novelli C, 2023, AI SOC, DOI 10.1007/s00146-023-01723-z; Ousidhoum N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4262; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; OWASP, 2023, OWASP Top 10 for LLM; Pa YMP, 2023, PROCEEDINGS OF 16TH CYBER SECURITY EXPERIMENTATION AND TEST WORKSHOP, CSET 2023, P10, DOI 10.1145/3607505.3607513; Pan XD, 2020, P IEEE S SECUR PRIV, P1314, DOI 10.1109/SP40000.2020.00095; Paria S, 2023, Arxiv, DOI arXiv:2308.06932; Parikh R., 2022, arXiv; Pearce H., 2022, Pop quiz! can a large language model help with reverse engineering?; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Peris C, 2023, P 16 ACM INT C WEB S, P1291; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pfitzmann A., 2010, A terminology for talking about privacy by data minimization: Anonymity, Unlinkability, Undetectability, Unobservability, Pseudonymity, and Identity Management; Plein L., 2023, Ratgpt: Turning online LLMs into proxies for malware attacks; Qammar A, 2023, Chatbots to ChatGPT in a cybersecurity space: Evolution, vulnerabilities, attacks, challenges, and future recommendations; Qi FC, 2021, Arxiv, DOI arXiv:2011.10369; Qi JX, 2023, Arxiv, DOI arXiv:2309.01189; Qin S., 2023, ACM Trans. Softw. Eng. Methodol.; Quidwai MA, 2023, Arxiv, DOI arXiv:2306.08122; Raeini M., 2023, Privacy-preserving large language models (PPLLMs); Raffel C., 2023, Exploring the limits of transfer learning with a unified text-to-text transformer; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Rando J, 2024, Arxiv, DOI arXiv:2311.14455; Real MM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156790; Renaud K., 2023, MIT SLOAN MANAGE REV; Robey A, 2024, Arxiv, DOI arXiv:2310.03684; Romero OJ, 2023, Arxiv, DOI arXiv:2308.09830; Rosyanafi R.J., 2023, J. Rev. Pendidikan Dasar J. Kajian Pendidikan Hasil Penelitian, V9, P220; Sakaoglu S., 2023, KARTAL: Web application vulnerability hunting using large language models, V85; Salesforce A.I. Research, 2023, Introducing a conditional transformer language model for controllable generation; Sandoval G., 2023, USENIX SECURITY 2023; Sapling, 2023, LLM index; Sarabi Armin, 2023, IMC '23: Proceedings of the 2023 ACM on Internet Measurement Conference, P478, DOI 10.1145/3618257.3624845; Scanlon M, 2023, FORENS SCI INT-DIGIT, V46, DOI 10.1016/j.fsidi.2023.301609; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Schuster R, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1559; Schwinn L., 2023, Adversarial attacks and defenses in large language models: Old and new threats; Sebastian G., 2023, IJSPPC, V15, P1, DOI [10.4018/IJSPPC.325475, DOI 10.4018/IJSPPC.325475]; Sebastian G., 2023, Privacy and data protection in chatgpt and other ai chatbots: Strategies for securing user information; Shah MA, 2023, Arxiv, DOI arXiv:2310.04445; Shaikh O, 2023, Arxiv, DOI arXiv:2212.08061; Shan SW, 2024, Arxiv, DOI arXiv:2310.13828; Shao K, 2021, COMPUT SECUR, V110, DOI 10.1016/j.cose.2021.102433; Shayegani E., 2023, Survey of vulnerabilities in large language models revealed by adversarial attacks; Shen XY, 2024, Arxiv, DOI [arXiv:2308.03825, 10.48550/arXiv.2308.03825]; Shi TW, 2024, Arxiv, DOI arXiv:2311.08685; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Shu ML, 2023, Arxiv, DOI arXiv:2306.17194; Shumailov I, 2021, 2021 IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2021), P212, DOI 10.1109/EuroSP51992.2021.00024; Siddiq ML, 2024, Arxiv, DOI arXiv:2311.00889; Siddiq ML, 2024, Arxiv, DOI arXiv:2305.00418; Sladic M., 2023, LLM in the shell: Generative honeypots; Smith V., 2023, Identifying and mitigating privacy risks stemming from language models: A survey; Sobania D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P23, DOI 10.1109/APR59189.2023.00012; Song CZ, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P377, DOI 10.1145/3372297.3417270; Song W., 2023, arXiv; Spatharioti SE, 2023, Arxiv, DOI arXiv:2307.03744; Spreitzer R, 2018, IEEE COMMUN SURV TUT, V20, P465, DOI 10.1109/COMST.2017.2779824; Staab R., 2023, Beyond memorization: Violating privacy via inference with large language models; Stephens K, 2023, AXIS Imaging News; Su J., 2023, Fake news detectors are biased against texts generated by large language models; Subramani N., 2023, P 3 WORKSHOP TRUSTWO, P208; Sullivan M., 2023, ChatGPT in higher education: Considerations for academic integrity and student learning; Sun X., 2023, P AAAI C ARTIFICIAL, V37, P5257; Sun ZQ, 2023, Arxiv, DOI arXiv:2305.03047; Talat Z, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P26; Tann W, 2023, Using large language models for cybersecurity capture-the-flag challenges and certification questions; Taveekitworachai Pittawat, 2023, Interactive Storytelling: 16th International Conference on Interactive Digital Storytelling, ICIDS 2023, Proceedings. Lecture Notes in Computer Science (14384), P285, DOI 10.1007/978-3-031-47658-7_27; Tay Z, 2023, Using Artificial Intelligence to Augment Bug Fuzzing; ThankGod Chinonso E., 2023, The Impact of ChatGPT on Privacy and Data Protection Laws; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tong M., 2023, PrivInfer: Privacy-preserving inference for black-box large language model; Torres Jorge., 2023, Navigating the LLM landscape: A comparative analysis of leading large language models; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Truex S, 2019, Arxiv, DOI arXiv:1807.09173; Truong JB, 2021, PROC CVPR IEEE, P4769, DOI 10.1109/CVPR46437.2021.00474; Uchendu A., 2023, P AAAI C HUMAN COMPU, V11, P163; Urchs S, 2024, Arxiv, DOI arXiv:2310.03031; Urman A., 2023, PREPRINT; Uzun L, 2023, Lang. Educ. Technol., V3; Uzuner Ö, 2007, J AM MED INFORM ASSN, V14, P550, DOI 10.1197/jamia.M2444; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Pham VT, 2020, IEEE INT CONF SOFTW, P460, DOI 10.1109/ICST46399.2020.00062; Vats A., 2023, Recovering from privacy-preserving masking with large language models; Ventayen R.J.M., 2023, Openai ChatGPT generated results: Similarity index of artificial intelligence-based contents; Vidas T., 2011, 5 USENIX WORKSH OFF; Wallace E, 2021, Arxiv, DOI arXiv:2010.12563; Wan ALXD, 2023, Arxiv, DOI arXiv:2305.00944; Wan Y, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1233, DOI 10.1145/3540250.3549153; Wan YX, 2023, Arxiv, DOI arXiv:2310.09219; Wang DL, 2019, PR MACH LEARN RES, V97; Wang H., 2023, Bot or Human? Detecting ChatGPT Imposters with A Single Question; Wang J., 2023, WASA: Watermark-based source attribution for large language model-generated data,; Wang J, 2023, Arxiv, DOI [arXiv:2309.15324, 10.48550/arXiv.2309.15324, DOI 10.48550/ARXIV.2309.15324]; Wang ZY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P2757; Wang ZH, 2023, Arxiv, DOI arXiv:2308.11521; Wei A., 2023, arXiv; Wei ZM, 2024, Arxiv, DOI arXiv:2310.06387; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Wen H, 2024, Arxiv, DOI arXiv:2308.15272; Weng J., 2023, US Patent, Patent No. [11,836,616, 11836616]; Weng JS, 2021, IEEE T DEPEND SECURE, V18, P2438, DOI 10.1109/TDSC.2019.2952332; Wenzek G, 2019, Arxiv, DOI arXiv:1911.00359; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu J., 2023, Fake news in sheep's clothing: Robust fake news detection against LLM-empowered style attacks.; Wu JC, 2024, Arxiv, DOI arXiv:2310.14724; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Wu X., 2023, Unveiling security, privacy, and ethical concerns of ChatGPT; Xi ZH, 2023, Arxiv, DOI arXiv:2309.13256; Xia C.S., 2023, Keep the conversation going: Fixing 162 out of 337 bugs for $ 0.42 each using chatgpt; Xia C.S, 2022, Practical program repair in the era of large pre-trained language models.; Xia CS, 2024, Arxiv, DOI arXiv:2308.04748; Xie Z., 2023, arXiv; Xiong M, 2024, Arxiv, DOI arXiv:2306.13063; Xu L., 2022, INT C NEUR INF PROC, P485; Yaman F, 2023, AgentSCA: Advanced physical side channel analysis agent with LLMs; Yan J, 2024, Arxiv, DOI arXiv:2307.16888; Yang C, 2023, White-box compiler fuzzing empowered by large language models; Yang HM, 2023, Arxiv, DOI arXiv:2308.14367; Yang J., 2023, bioRxiv., P2011; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang S., 2023, Ph.D. thesis; Yang Z., 2023, arXiv; Yao BW, 2023, Arxiv, DOI arXiv:2305.14328; Yao DY, 2024, Arxiv, DOI arXiv:2309.05274; Yao HW, 2023, Arxiv, DOI arXiv:2310.12439; Yoo JY, 2021, Arxiv, DOI arXiv:2109.00544; You WC, 2023, Arxiv, DOI arXiv:2310.18603; Yu JH, 2023, Arxiv, DOI arXiv:2309.10253; Yuan LF, 2023, Arxiv, DOI arXiv:2306.04618; Yuan Z, 2023, Arxiv, DOI arXiv:2304.05302; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zafar A, 2023, Arxiv, DOI arXiv:2308.13534; Zhang C, 2024, Arxiv, DOI arXiv:2307.12469; Zhang C, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2021.106775; Zhang R., 2023, REMARK-LLM: A robust and efficient watermarking framework for generative large language models; Zhang RS, 2022, Arxiv, DOI arXiv:2209.10505; Zhang X, 2023, Towards LLM-based fact verification on news claims with a hierarchical step-by-step prompting method; Zhang YM, 2024, Arxiv, DOI arXiv:2307.06865; Zhang ZX, 2023, Arxiv, DOI arXiv:2307.04401; Zhao JY, 2023, Arxiv, DOI arXiv:2305.13592; Zhao S, 2023, Arxiv, DOI arXiv:2305.01219; Zhao W., 2023, kNN-ICL: Compositional task-oriented parsing generalization with nearest neighbor in-context learning; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206; Zhu C, 2020, Arxiv, DOI arXiv:1909.11764; Zhu KJ, 2023, Arxiv, DOI arXiv:2306.04528; Ziems N, 2023, Arxiv, DOI arXiv:2305.09612; Zou A., 2023, Communication, it is essential for you to comprehend user queries in Cipher Code and subsequently deliver your responses utilizing Cipher Code	352	2	2	17	17	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2667-2952		HIGH-CONFID COMPUT	High-Confid. Comput.	JUN	2024	4	2							100211	10.1016/j.hcc.2024.100211	http://dx.doi.org/10.1016/j.hcc.2024.100211			21	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	RL8Z1		Green Submitted			2024-07-03	WOS:001227924000001
J	Bonadia, RS; Trindade, FCL; Freitas, W; Venkatesh, B				Bonadia, Rodrigo S.; Trindade, Fernanda C. L.; Freitas, Walmir; Venkatesh, Bala			On the Potential of ChatGPT to Generate Distribution Systems for Load Flow Studies Using OpenDSS	IEEE TRANSACTIONS ON POWER SYSTEMS			English	Article						Chatbots; Transformers; Power systems; Task analysis; Reactive power; Load modeling; Load flow; Artificial intelligence; large language models; OpenDSS; power distribution systems		In recent years, the Large Language Models have developed at an unprecedented pace with the potential to transform various fields, including power system analysis. This letter illustrates the current status and potential use of ChatGPT, (ready-to-use) pretrained chatbot, to create test distribution systems modeled as DSS files for load flow studies using OpenDSS, focusing on educational purposes. A performance comparison of GPT-3.5 and GPT-4 large language models (with the ChatGPT frontend) has been conducted. More specifically, the ability of ChatGPT to generate simple test circuits to run in OpenDSS is verified, including elements such as lines, loads, transformers, and photovoltaic generators. The ability of ChatGPT to identify and solve simple engineering problems applied to the generated circuits is also briefly discussed. The results demonstrate that GPT-4 has the potential to support educational activities by creating functional circuits and propose solutions for engineering problems if adequate guidance and examples are provided.	[Bonadia, Rodrigo S.] ERA Energy Res & Analyt, BR-13087570 Sao Paulo, Brazil; [Trindade, Fernanda C. L.; Freitas, Walmir] Univ Estadual Campinas, BR-13083970 Campinas, SP, Brazil; [Venkatesh, Bala] Toronto Metropolitan Univ, Toronto, ON M5B 2K3, Canada	Universidade Estadual de Campinas; Toronto Metropolitan University	Trindade, FCL (corresponding author), Univ Estadual Campinas, BR-13083970 Campinas, SP, Brazil.	rodrigo.bonadia@eraenergy.com.br; fernanda@ieee.org; walmir@ieee.org; bala@torontomu.ca	Trindade, Fernanda C. L./G-5731-2012; Freitas, Walmir/A-2516-2008	Trindade, Fernanda C. L./0000-0003-1558-5411; Freitas, Walmir/0000-0002-2042-6741	National Council for Scientific and Technological Development (CNPq) [304373/2020-6]; So Paulo Research Foundation (FAPESP) [2021/11380-5, 2022/11517-3, 2023/01719-0]	National Council for Scientific and Technological Development (CNPq)(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); So Paulo Research Foundation (FAPESP)(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	This work was supported in part by the National Council for Scientific and Technological Development (CNPq) under Grant 304373/2020-6 and in part by S & atilde;o Paulo Research Foundation (FAPESP) under Grants 2021/11380-5, 2022/11517-3, and 2023/01719-0.	Ali M, 2023, J IND INF INTEGR, V31, DOI 10.1016/j.jii.2022.100407; [Anonymous], 2020, ANSI C84.1; Bonadia R. S., 2023, ChatGPT applications in power distribution systems with OpenDSS full transcripts; Bonadia Rodrigo, 2023, IEEE DataPort, DOI 10.21227/91FJ-GR09; Bubeck Sebastien, 2023, arXiv preprint arXiv:2303.12712; EMTP, 1992, Alternative transients program (ATP): Rule book; EPRI, 2008, OpenDSS; Liang M, 2021, IEEE T SMART GRID, V12, P1163, DOI 10.1109/TSG.2020.3025259; Meira P., 2018, DSS extensions: Multi-platform OpenDSS extensions; Natalie, 2022, ChatGPT FAQ; YOUNG S, 2018, P IEEE POW EN SOC GE, DOI DOI 10.1109/PESGM.2018.8585792	11	0	0	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0885-8950	1558-0679		IEEE T POWER SYST	IEEE Trans. Power Syst.	NOV	2023	38	6					5965	5968		10.1109/TPWRS.2023.3315543	http://dx.doi.org/10.1109/TPWRS.2023.3315543			4	Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	X7PM4					2024-07-03	WOS:001100325200083
J	Shah, NH; Entwistle, D; Pfeffer, MA				Shah, Nigam H.; Entwistle, David; Pfeffer, Michael A.			Creation and Adoption of Large Language Models in Medicine	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Review								IMPORTANCE There is increased interest in and potential benefits from using large language models (LLMs) in medicine. However, by simply wondering how the LLMs and the applications powered by them will reshape medicine instead of getting actively involved, the agency in shaping how these tools can be used in medicine is lost.OBSERVATIONS Applications powered by LLMs are increasingly used to perform medical tasks without the underlying language model being trained on medical records and without verifying their purported benefit in performing those tasks.CONCLUSIONS AND RELEVANCE The creation and use of LLMs in medicine need to be actively shaped by provisioning relevant training data, specifying the desired benefits, and evaluating the benefits via testing in real-world deployments.	[Shah, Nigam H.] Stanford Univ, Ctr Biomed Informat Res, 3180 Porter Dr, Palo Alto, CA 94305 USA; [Shah, Nigam H.; Entwistle, David; Pfeffer, Michael A.] Stanford Hlth Care, Palo Alto, CA USA; [Shah, Nigam H.; Pfeffer, Michael A.] Stanford Univ, Sch Med, Dept Med, Stanford, CA USA; [Shah, Nigam H.] Stanford Univ, Clin Excellence Res Ctr, Sch Med, Stanford, CA USA	Stanford University; Stanford University; Stanford University; Stanford University	Shah, NH (corresponding author), Stanford Univ, Ctr Biomed Informat Res, 3180 Porter Dr, Palo Alto, CA 94305 USA.	nigam@stanford.edu		Pfeffer, Michael/0000-0002-8958-0843				Brynjolfsson E., 2023, AUGMENTED ED GLOBAL, P103; Chui M., EC POTENTIAL GENERAT; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; OpenAI, AL LANG MOD FOLL INS; Steinberg E, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103637; Taori R., STANFORD ALPACA CODE; Vaswani A, 2017, ADV NEUR IN, V30; Wikipedia contributors, WIKIPEDIA CONTRIBUTO; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zhao WX, PREPRINT	12	52	54	33	66	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	SEP 5	2023	330	9					866	869		10.1001/jama.2023.14217	http://dx.doi.org/10.1001/jama.2023.14217		AUG 2023	4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	W9PB5	37548965				2024-07-03	WOS:001046738800002
J	Blackie, MAL				Blackie, Margaret A. L.			ChatGPT is a game changer: detection and eradication is not the way forward	TEACHING IN HIGHER EDUCATION			English	Editorial Material						ChatGPT; higher education; assessment; large language models; LLM		Large language models such as ChatGPT can be seen as a major threat to reliable assessment in higher education. In this point of departure, I argue that these tools are a major game changer for society at large. Many of the jobs we now consider highly skilled are based on pattern recognition that can much more reliably be carried by fine-tuned language models. We are therefore at a turning point in history and it affords a powerful opportunity to reconsider the value of higher education in the light of these tools.	[Blackie, Margaret A. L.] Rhodes Univ, Ctr Higher Educ Res Teaching & Learning, Makhanda, South Africa	Rhodes University	Blackie, MAL (corresponding author), Rhodes Univ, Ctr Higher Educ Res Teaching & Learning, Makhanda, South Africa.	mags.blackie@ru.ac.za	Blackie, Margaret/F-1871-2011	Blackie, Margaret/0000-0002-2465-4987				Ashwin P., 2020, Transforming University Education: A Manifesto; Ashwin P, 2023, HIGH EDUC, V86, P1065, DOI 10.1007/s10734-022-00962-1; Blackie MAL, 2023, J CHEM EDUC, V100, P3302, DOI 10.1021/acs.jchemed.2c00980; Bommarito II M., 2022, ARXIV; Charlesworth H., 2009, CULTURAL DIVERSITY H, P37; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Dawson P, 2024, ASSESS EVAL HIGH EDU, V49, P262, DOI 10.1080/02602938.2023.2209298; Deng X, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P107, DOI 10.1145/3543873.3587324; Fraser Nancy., 2009, SCALES JUSTICE REIMA; Fry H., 2018, HELLO WORLD BE HUMAN; Kontsioti E, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01159-y; Kramm N., 2023, 22 INT MLEARNI TLT C; Lindenfeld Z, 2023, MED CARE RES REV, V80, P3, DOI 10.1177/10775587221093043; MacNeil S., 2022, ARXIV; McArthur J, 2023, HIGH EDUC, V85, P85, DOI 10.1007/s10734-022-00822-y; Nield D., 2023, THE MAGAZINE; Rubin J, 2014, REV ECON STAT, V96, P270, DOI 10.1162/REST_a_00368; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Schlossberg T., 2011, MCSWEENEY BLOG; Swiecki Z., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100075; Tomlinson M, 2018, HIGH EDUC, V75, P711, DOI 10.1007/s10734-017-0165-6; WRITER B, 2019, LITHIUM ION BATTERIE, DOI 10.1007/978-3-030-16800-1; Xu J., 2022, CHEMRXIV, DOI [10.26434/chemrxiv-2022-9fwmg, DOI 10.26434/CHEMRXIV-2022-9FWMG]; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zeng A., 2022, Are transformers effective for time series forecasting? arXiv preprint, P1, DOI [10.48550/arXiv.2204.00598, DOI 10.48550/ARXIV.2204.00598]; Zhang S., 2021, J CHINA COMPUTER ASS, V1, P170, DOI [10.1515/jccall-2021-2007, DOI 10.1515/JCCALL-2021-2007]	26	1	1	23	23	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1356-2517	1470-1294		TEACH HIGH EDUC	Teach. High Educ.	MAY 18	2024	29	4					1109	1116		10.1080/13562517.2023.2300951	http://dx.doi.org/10.1080/13562517.2023.2300951		JAN 2024	8	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	NG9K0					2024-07-03	WOS:001147408900001
C	Carlini, N; Tramèr, F; Wallace, E; Jagielski, M; Herbert-Voss, A; Lee, K; Roberts, A; Brown, T; Song, D; Erlingsson, U; Oprea, A; Raffel, C			USENIX Assoc	Carlini, Nicholas; Tramer, Florian; Wallace, Eric; Jagielski, Matthew; Herbert-Voss, Ariel; Lee, Katherine; Roberts, Adam; Brown, Tom; Song, Dawn; Erlingsson, Ulfar; Oprea, Alina; Raffel, Colin			Extracting Training Data from Large Language Models	PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM			English	Proceedings Paper	30th USENIX Security Symposium	AUG 11-13, 2021	ELECTR NETWORK	USENIX Assoc				It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model. We demonstrate our attack on GPT-2, a language model trained on scrapes of the public Internet, and are able to extract hundreds of verbatim text sequences from the model's training data. These extracted examples include (public) personally identifiable information (names, phone numbers, and email addresses), IRC conversations, code, and 128-bit UUIDs. Our attack is possible even though each of the above sequences are included in just one document in the training data. We comprehensively evaluate our extraction attack to understand the factors that contribute to its success. Worryingly, we find that larger models are more vulnerable than smaller models. We conclude by drawing lessons and discussing possible safeguards for training large language models.	[Carlini, Nicholas; Lee, Katherine; Roberts, Adam; Raffel, Colin] Google, Mountain View, CA 94043 USA; [Tramer, Florian] Stanford, Stanford, CA USA; [Wallace, Eric; Song, Dawn] Univ Calif Berkeley, Berkeley, CA USA; [Jagielski, Matthew; Oprea, Alina] Northeastern Univ, Boston, MA 02115 USA; [Herbert-Voss, Ariel; Brown, Tom] OpenAI, San Francisco, CA USA; [Herbert-Voss, Ariel] Harvard, Cambridge, MA USA; [Erlingsson, Ulfar] Apple, Cupertino, CA USA	Google Incorporated; Stanford University; University of California System; University of California Berkeley; Northeastern University; OpenAI; Apple Inc	Carlini, N (corresponding author), Google, Mountain View, CA 94043 USA.			Tramer, Florian/0000-0001-8703-8762; Lee, Katherine/0000-0002-9537-6195	NSF [CNS-1804222]	NSF(National Science Foundation (NSF))	We are grateful for comments on early versions of this paper by Dan Boneh, Andreas Terzis, Carey Radebaugh, Daphne Ippolito, Christine Robson, Kelly Cooke, Janel Thamkul, AustinTarango, Jack Clark, Ilya Mironov, and Om Thakkar. Florian Tramer is supported by NSF award CNS-1804222.	Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318; Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; [Anonymous], 2020, TACL; [Anonymous], 2014, ACM CCS; [Anonymous], 2012, PRIVACY AND CONFIDEN; [Anonymous], 2019, ARXIV PREPRINT ARXIV; [Anonymous], ACL; [Anonymous], 2020, STOC; [Anonymous], 2020, ARXIV PREPRINT ARXIV; [Anonymous], 2016, MOBISYS; [Anonymous], 1989, SICOMP; [Anonymous], 2020, ACM CCS; [Anonymous], 2020, Language Models are Few-Shot Learners; [Anonymous], 2019, PREDICTIVE MODELS; [Anonymous], 2020, ACM CCS; [Anonymous], 2020, USPTO REQUEST FOR CO; [Anonymous], zlib compression library; [Anonymous], 2020, ACL DEMO TRACK; [Anonymous], 2009, NIPS; [Anonymous], 2018, IEEE CSF; [Anonymous], 2020, NeurIPS; [Anonymous], 2018, THE ILLUSTRATED TRAN; [Anonymous], 2019, KDD; [Anonymous], 2018, KDD; [Anonymous], 2018, ACM SIGSAC; [Anonymous], TENSORFLOW PRIVACY; [Anonymous], 2020, ARXIV PREPRINT ARXIV; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bengio Y, 2001, ADV NEUR IN, V13, P932; Brown G., 2020, ARXIV201103885; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P267; Continella A, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23465; Devlin J., 2018, BERT PRE TRAINING DE; Dwork C, 2008, LECT NOTES COMPUT SC, V4978, P1, DOI 10.1007/978-3-540-79228-4_1; Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Fan A., 2018, ACL; Feldman V., 2020, Advances in Neural Information Processing Systems; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Gage P., 1994, C Users Journal, V12, P23; Gokaslan Aaron, 2019, OPENWEB TEXT CORPUS; Graves A., 2013, ARXIV, DOI DOI 10.1145/2661829.2661935; Henderson P, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P123, DOI 10.1145/3278721.3278777; Holtzman A., 2019, INT C LEARNING REPRE; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Jayaraman B, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1895; Kaplan Jared, 2020, Scaling laws for neural language models; Lewis Mike, 2020, P 58 ANN M ASS COMP; Li Jiwei, 2016, NAACL; Li ZH, 2020, PR MACH LEARN RES, V119; Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070; Long Y., 2018, ARXIV PREPRINT ARXIV; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]; McMahan H. B., 2018, P INT C LEARN REPR; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Nasr M, 2019, P IEEE S SECUR PRIV, P739, DOI 10.1109/SP.2019.00065; Nissenbaum H, 2004, WASH LAW REV, V79, P119; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; RATCLIFF R, 1990, PSYCHOL REV, V97, P285, DOI 10.1037/0033-295X.97.2.285; Roberts Adam, 2020, EMNLP; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Shoeybi M., 2019, Megatron-lm: Training multibillion parameter language models using model parallelism; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103; Vaswani A, 2017, ADV NEUR IN, V30; Zellers Rowan, 2019, Advances in Neural Information Processing Systems; Zhang CX, 2018, PROTEINS, V86, P136, DOI 10.1002/prot.25414	72	144	163	5	19	USENIX ASSOC	BERKELEY	SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710 USA			978-1-939133-24-3				2021							2633	2650						18	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BS4QP					2024-07-03	WOS:000722006802047
J	Li, RS; Xu, J; Cao, ZX; Zheng, HT; Kim, HG				Li, Rongsheng; Xu, Jin; Cao, Zhixiong; Zheng, Hai-Tao; Kim, Hong-Gee			Extending Context Window in Large Language Models with Segmented Base Adjustment for Rotary Position Embeddings	APPLIED SCIENCES-BASEL			English	Article						large language models (LLMs); rotary position embeddings (RoPE); long text processing; context window extension; segmented base adjustment		In the realm of large language models (LLMs), extending the context window for long text processing is crucial for enhancing performance. This paper introduces SBA-RoPE (Segmented Base Adjustment for Rotary Position Embeddings), a novel approach designed to efficiently extend the context window by segmentally adjusting the base of rotary position embeddings (RoPE). Unlike existing methods, such as Position Interpolation (PI), NTK, and YaRN, SBA-RoPE modifies the base of RoPE across different dimensions, optimizing the encoding of positional information for extended sequences. Through experiments on the Pythia model, we demonstrate the effectiveness of SBA-RoPE in extending context windows, particularly for texts exceeding the original training lengths. We fine-tuned the Pythia-2.8B model on the PG-19 dataset and conducted passkey retrieval and perplexity (PPL) experiments on the Proof-pile dataset to evaluate model performance. Results show that SBA-RoPE maintains or improves model performance when extending the context window, especially on longer text sequences. Compared to other methods, SBA-RoPE exhibits superior or comparable performance across various lengths and tasks, highlighting its potential as an effective technique for context window extension in LLMs.	[Li, Rongsheng; Xu, Jin; Cao, Zhixiong; Zheng, Hai-Tao] Tsinghua Univ, Shenzhen Int Grad Sch, Shenzhen 518071, Peoples R China; [Zheng, Hai-Tao] Pengcheng Lab, Shenzhen 518055, Peoples R China; [Kim, Hong-Gee] Seoul Natl Univ, Sch Dent, Seoul 03080, South Korea	Tsinghua University; Seoul National University (SNU)	Zheng, HT (corresponding author), Tsinghua Univ, Shenzhen Int Grad Sch, Shenzhen 518071, Peoples R China.; Zheng, HT (corresponding author), Pengcheng Lab, Shenzhen 518055, Peoples R China.	lrs21@mails.tsinghua.edu.cn; xj21@mails.tsinghua.edu.cn; caozx21@mails.tsinghua.edu.cn; zheng.haitao@sz.tsinghua.edu.cn; hgkim@snu.ac.kr		Zheng, Hai-Tao/0000-0001-5128-5649	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Azerbayev Z., Proof-Pile; Biderman S., 2023, INT C MACHINE LEARNI, P2397; Black S., 2022, PREPRINT; bloc97, Ntk-aware scaled rope allows llama models to have extended (8k+) context size without any finetuning and minimal perplexity degradation; Chen SY, 2023, Arxiv, DOI arXiv:2306.15595; De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Lefaudeux B., 2022, xformers: A modular and hackable transformer modelling library; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Medsker L. R., 2001, Design and Applications, V5, P2; Micikevicius P, 2017, arXiv; Mohtashami A, 2023, Arxiv, DOI arXiv:2305.16300; Paszke A, 2019, ADV NEUR IN, V32; Peng BW, 2023, Arxiv, DOI arXiv:2309.00071; Press O., 2022, P INT C LEARNING REP; Rae J.W., 2020, P INT C LEARNING REP; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Shaw P., 2018, P 2018 C N AM CHAPT, P464, DOI DOI 10.48550/ARXIV.1803.02155; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Sun Yutao, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30	25	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	7							3076	10.3390/app14073076	http://dx.doi.org/10.3390/app14073076			12	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	NN4F7		gold			2024-07-03	WOS:001201110200001
J	Helm, P; Bella, G; Koch, G; Giunchiglia, F				Helm, Paula; Bella, Gabor; Koch, Gertraud; Giunchiglia, Fausto			Diversity and language technology: how language modeling bias causes epistemic injustice	ETHICS AND INFORMATION TECHNOLOGY			English	Article						Language technology; Diversity; Digital divide; Epistemic injustice; Linguistic bias; Language modeling bias; Lexical gaps; Large language models		It is well known that AI-based language technology-large language models, machine translation systems, multilingual dictionaries, and corpora-is currently limited to three percent of the world's most widely spoken, financially and politically backed languages. In response, recent efforts have sought to address the "digital language divide" by extending the reach of large language models to "underserved languages." We show how some of these efforts tend to produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call language modeling bias. Language modeling bias is a specific and under-studied form of linguistic bias were language technology by design favors certain languages, dialects, or sociolects with respect to others. We show that language modeling bias can result in systems that, while being precise regarding languages and cultures of dominant powers, are limited in the expression of socio-culturally relevant notions of other communities. We further argue that at the root of this problem lies a systematic tendency of technology developer communities to apply a simplistic understanding of diversity which does not do justice to the more profound differences that languages, and ultimately the communities that speak them, embody. Drawing on the concept of epistemic injustice, we point to the broader ethico-political implications and show how it can lead not only to a disregard for valuable aspects of diversity but also to an under-representation of the needs of marginalized language communities. Finally, we present an alternative socio-technical approach that is designed to tackle some of the analyzed problems.	[Helm, Paula] Univ Amsterdam, Amsterdam, Netherlands; [Bella, Gabor] CNRS, IMT Atlantique, UMR 628, Lab STICC, Brest, France; [Koch, Gertraud] Univ Hamburg, Hamburg, Germany; [Giunchiglia, Fausto] Univ Trento, Trento, Italy	University of Amsterdam; Centre National de la Recherche Scientifique (CNRS); IMT - Institut Mines-Telecom; IMT Atlantique; Universite de Bretagne Occidentale; University of Hamburg; University of Trento	Helm, P (corresponding author), Univ Amsterdam, Amsterdam, Netherlands.	p.m.helm@uva.nl; gabor.bella@imt-atlantique.fr; gertraud.koch@uni-hamburg.de; fausto.giunchiglia@unitn.it	hu, guangchen/KEI-6324-2024	Helm, Paula/0000-0002-2719-9721	EU	EU(European Union (EU))	No Statement Available	Agirre E, 2006, TEXT SPEECH LANG TEC, V33, P1, DOI 10.1007/978-1-4020-4809-8; Aradau C., 2022, Algorithmic reason: the new government of self and others, DOI [10.1093/oso/9780192859624.001.0001, DOI 10.1093/OSO/9780192859624.001.0001]; Arora P, 2016, International Journal of Communication, V10, P1; Arora Payal., 2019, The Next Billion Users: Digital Life Beyond the West, DOI [https://doi.org/10.4159/9780674238879, DOI 10.4159/9780674238879]; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; Batsuren K., 2019, P 10 GLOBAL WORDNET, P238; Batsuren K, 2022, LANG RESOUR EVAL, V56, P165, DOI 10.1007/s10579-021-09544-6; Beer D, 2017, INFORM COMMUN SOC, V20, P1, DOI 10.1080/1369118X.2016.1216147; Bella G., 2022, P 60 ANN M ASS COMPU, P156; Bella G., 2022, University of Bayreuth African Studies Online, P173; Bella G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2812; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Bhuiyan J., 2023, The Guardian; Bird S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7817; Bird Steven, 2020, P 28 INT C COMPUTATI, P3504, DOI DOI 10.18653/V1/2020.COLING-MAIN.313; Broussard M., 2023, MORE GLITCH CONFRONT, DOI [10.7551/mitpress/14234.001.0001, DOI 10.7551/MITPRESS/14234.001.0001]; Coady D, 2010, EPISTEME-J INDIV SOC, V7, P101, DOI 10.3366/epi.2010.0001; De-Arteaga M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P120, DOI 10.1145/3287560.3287572; Dibitso Mary Ambrossine, 2019, Modeling and Using Context. 11th International and Interdisciplinary Conference, CONTEXT 2019. Proceedings. Lecture Notes in Artificial Intelligence (LNAI 11939), P62, DOI 10.1007/978-3-030-34974-5_6; Engel JS., Global clusters of innovation: Entrepreneurial engines of economic growth around the world; Fricker M, 2008, THEORIA-SPAIN, V23, P69; Friedman B, 1996, ACM T INFORM SYST, V14, P330, DOI 10.1145/230538.230561; Gitelman L, 2013, INFRASTRUCT SER, P1; Giunchiglia F., 2018, P 19 INT C COMPUTATI, P18; Giunchiglia F, 2023, ARTIF INTELL REV, V56, P11053, DOI 10.1007/s10462-023-10427-1; Giunchiglia F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4009; Goldman AI., 2002, 51the unity of the epistemic virtues. Pathways to knowledge: Private and Ublic, DOI [10.1093/0195138791.001.0001, DOI 10.1093/0195138791.001.0001]; GREENBERG JH, 1956, LANGUAGE, V32, P109, DOI 10.2307/410659; HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066; Harding S, 1995, SYNTHESE, V104, P331, DOI 10.1007/BF01064504; Helm P, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517231206802; Helm P, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P324, DOI 10.1145/3514094.3534149; Hovy D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P588; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Irani L, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1311; Joshi Pratik, 2020, P 58 ANN M ASS COMPU, P6282, DOI [10.18653/v1/2020. acl-main.560, DOI 10.18653/V1/2020.ACL-MAIN.560]; Khalilia H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1229697; Khishigsuren T., 2022, arXiv; Kornai A, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077056; Lignos C, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P523; Mazrui AliAlʼAmin., 1999, POLITICAL CULTURE LA; Miller GA., 1998, Wordnet: an electronic lexical database; Nair NC, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2833; Nyabola N., 2018, Digital democracy, analogue politics: How the internet era is transforming politics in kenya, DOI [10.5040/9781350219656, DOI 10.5040/9781350219656]; Ochigame R., 2019, How big tech manipulates academia to avoid regulation; Pfotenhauer S, 2017, SOC STUD SCI, V47, P783, DOI 10.1177/0306312717706110; Potthast T, 2014, ROUTL STUD BIODIVERS, P132; Ranciere Jacques., 1998, DISAGREEMENT POLITIC; RIJKHOFF J, 1993, STUD LANG, V17, P169, DOI 10.1075/sl.17.1.07rij; Saad-Sulonen J, 2018, CODESIGN, V14, P4, DOI 10.1080/15710882.2018.1426773; Schwartz L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P724; Schwemmer C, 2020, SOCIUS, V6, DOI 10.1177/2378023120967171; Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909; Smith RC, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3441334; Spivak Gayatri Chakravorty, 1988, MARXISM INTERPRETATI, P66, DOI DOI 10.1007/978-1-349-19059-1_20; Taylor L, 2015, GEOFORUM, V64, P229, DOI 10.1016/j.geoforum.2015.07.002; Thiong'o N.W., 1986, DECOLONISING MIND PO; Tsing AL, 2012, COMMON KNOWL, V18, P505, DOI 10.1215/0961754X-1630424; Vanmassenhove E, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2203; White JC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P454; Winner L., 1989, The whale and the reactor: A search for limits in an age of high technology, DOI [https://doi.org/10.7208/chicago/9780226902098.001.0001, DOI 10.7208/CHICAGO/9780226902098.001.0001]; Young H., 2015, The digital language divide; Young IM, 1990, Justice and the Politics of Difference; Zaugg IA, 2022, INTERNET POLICY REV, V11, DOI 10.14763/2022.2.1654; Zevallos R., 2023, Long papers, V1, P12508; Zouhar V, 2024, Arxiv, DOI arXiv:2304.02541	68	0	0	19	19	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	MAR	2024	26	1							8	10.1007/s10676-023-09742-6	http://dx.doi.org/10.1007/s10676-023-09742-6			15	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	FW4A4		hybrid			2024-07-03	WOS:001148865400001
J	He, ZW; Liang, T; Jiao, WX; Zhang, ZS; Yang, YJ; Wang, R; Tu, ZP; Shi, SM; Wang, X				He, Zhiwei; Liang, Tian; Jiao, Wenxiang; Zhang, Zhuosheng; Yang, Yujiu; Wang, Rui; Tu, Zhaopeng; Shi, Shuming; Wang, Xing			Exploring Human-Like Translation Strategy with Large Language Models	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								Large language models (LLMs) have demonstrated impressive capabilities in general scenarios, exhibiting a level of aptitude that approaches, in some aspects even surpasses, human-level intelligence. Among their numerous skills, the translation abilities of LLMs have received considerable attention. Compared to typical machine translation that focuses solely on source-to-target mapping, LLM-based translation can potentially mimic the human translation process, which might take preparatory steps to ensure high-quality translation. This work explores this possibility by proposing the MAPS framework, which stands for Multi-Aspect Prompting and Selection. Specifically, we enable LLMs first to analyze the given source sentence and induce three aspects of translation-related knowledge (keywords, topics, and relevant demonstrations) to guide the final translation process. Moreover, we employ a selection mechanism based on quality estimation to filter out noisy and unhelpful knowledge. Both automatic (3 LLMs x 11 directions x 2 automatic metrics) and human evaluation (preference study and MQM) demonstrate the effectiveness of MAPS. Further analysis shows that by mimicking the human translation process, MAPS reduces various translation errors such as hallucination, ambiguity, mistranslation, awkward style, untranslated text, and omission. Source code is available at https://github.com/zwhe99/MAPS-mt.	[He, Zhiwei; Zhang, Zhuosheng; Wang, Rui] Shanghai Jiao Tong Univ, Shanghai, Peoples R China; [Liang, Tian] Tsinghua Univ, Tsinghua, Peoples R China; [Jiao, Wenxiang; Tu, Zhaopeng; Shi, Shuming; Wang, Xing] Tencent AI Lab, Shenzhen, Peoples R China	Shanghai Jiao Tong University; Tsinghua University; Tencent	Wang, R (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.; Tu, ZP (corresponding author), Tencent AI Lab, Shenzhen, Peoples R China.	zwhe.cs@sjtu.edu.cn; liangt21@mails.tsinghua.edu.cn; joelwxjiao@tencent.com; zhangzs@sjtu.edu.cn; yang.yujiu@sz.tsinghua.edu.cn; wangrui12@sjtu.edu.cn; zptu@tencent.com; shumingshi@tencent.com; brightxwang@tencent.com	Yang, Yujiu/AAC-1481-2019; Tu, Zhaopeng/AAS-4259-2021; Yang, Yujiu/JGM-0303-2023	Yang, Yujiu/0000-0002-6427-1024	Tencent Open Fund [RBFR2023012]; National Natural Science Foundation of China [62176153]; Shanghai Municipal Science and Technology Major Project [2021SHZDZX0102]	Tencent Open Fund; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Municipal Science and Technology Major Project	Zhiwei and Rui are with MT-Lab, Department of Computer Science and Engineering, School of Electronic Information and Electrical Engineering, and also with the MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, Shanghai 200204, China. Rui and Zhiwei are supported by the Tencent Open Fund(RBFR2023012), the National Natural Science Foundation of China (62176153), and the Shanghai Municipal Science and Technology Major Project (2021SHZDZX0102).We are grateful to the action editor and reviewers, whose insightful suggestions and exceptionally prompt feedback significantly enhanced the quality of our manuscript.	Agrawal Sweta., 2023, FINDINGS ACL, P8857, DOI 10.18653/v1/2023.findings-acl.564; Baker M., 2018, In Other Words: A Coursebook on Translation, V3rd ed., DOI DOI 10.4324/9781315619187; Bar-Hillel Y, 1960, Advances in computers, V1, P158; Bawden R, 2023, Arxiv, DOI arXiv:2303.01911; Bowker Lynne., 2002, Computer-aided Translation Technology: A Practical Introduction, DOI [10.1353/book6554, DOI 10.1353/BOOK6554]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burchardt Aljoscha., 2013, P TRANSLATING COMPUT; Chen J, 2023, Arxiv, DOI arXiv:2304.04227; Fernandes P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1396; Fillippova K, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P864; Freitag M, 2021, T ASSOC COMPUT LING, V9, P1460, DOI 10.1162/tacl_a_00437; Freitag Markus., 2022, P 7 C MACHINE TRANSL, P46; Garcia X, 2023, Arxiv, DOI [arXiv:2302.01398, 10.48550/arXiv.2302.01398]; Ghazvininejad Marjan., 2023, arXiv; Gile D, 2009, MONTI, V1, P135; Guerreiro NM, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1059; Guerreiro NM, 2023, Arxiv, DOI arXiv:2303.16104; Hatim Basil., 2004, Translation: An Advanced Resource Book, DOI [10.4324/9780203501887, DOI 10.4324/9780203501887]; He Jie., 2020, FIND ASS COMP LING E, P3662, DOI [10.18653/v1/2020.findings-emnlp.327, DOI 10.18653/V1/2020.FINDINGS-EMNLP.327]; He ZW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6611; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiao WX, 2023, Arxiv, DOI arXiv:2304.02426; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Kim Hyuhng Joon., 2022, arXiv; Kocmi Tom, 2021, P 6 C MACHINE TRANSL, P478; Kocmi Tom., 2022, Proceedings of the Seventh Conference on Machine Translation (WMT), P1; Koehn P, 2009, MACH TRANSL, V23, P241, DOI 10.1007/s10590-010-9076-3; Kojima Takeshi., 2023, Adv. Neural Inf. Process. Syst, V35, P22199; Li JL, 2024, Arxiv, DOI [arXiv:2212.08635, DOI 10.48550/ARXIV.2212.08635]; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Longyue Wang Zefeng, 2023, Guofeng: A discourse-aware evaluation benchmark for language understanding, translation and generation; Lu HY, 2023, Arxiv, DOI arXiv:2305.06575; Lyu C, 2024, Arxiv, DOI [arXiv:2305.01181, 10.48550/arXiv.2305.01181, DOI 10.48550/ARXIV.2305.01181]; Macklovitch Elliott., 1995, P 4 BAR IL S FDN ART; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Moslem Y, 2023, Arxiv, DOI arXiv:2301.13294; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Parikh AP, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1173; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Patrick Fernandes Daniel, 2023, The devil is in the errors: Leveraging large language models for fine-grained machine translation evaluation, DOI [10.18653/v1/2023.wmt-1.100, DOI 10.18653/V1/2023.WMT-1.100]; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Pilault J, 2023, Arxiv, DOI arXiv:2301.10309; Pym A., 2014, Exploring translation theories, DOI DOI 10.4324/9781315857633; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P578; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P634; Rohan Taori, 2023, Stanford Alpaca: An instruction-following LLaMA model; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; ShareGPT, 2023, Sharegpt: Share your wildest chatgpt conversations with one click; Shi F, 2023, Arxiv, DOI arXiv:2302.00093; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vilar D, 2022, Arxiv, DOI arXiv:2211.09102; Wang LY, 2023, Arxiv, DOI [arXiv:2304.02210, 10.48550/arXiv.2304.02210]; Wang WX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2591; Wang X., 2023, 11 INT C LEARN REPR; Wang YM, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P8640; Wei Jason., 2023, Adv Neural Inform Proc Syst, V35, P24824; Wei JH, 2022, PR MACH LEARN RES; Wei-Lin Chiang, 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Wenhao Yu., 2023, INT C LEARN REPR ICL; Wu HR, 2023, Arxiv, DOI arXiv:2303.13648; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Yizhong Wang, Self-instruct: Aligning language model with self generated instructions, DOI [10.18653/v1/2023.acl-long.754, DOI 10.18653/V1/2023.ACL-LONG.754]; Zhang B, 2023, Arxiv, DOI [arXiv:2301.07069, 10.48550/arXiv.2301.07069]; Zhang Z., 2023, 11 INT C LEARN REPR; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]; Zhou CT, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1393; Zhu DY, 2023, Arxiv, DOI arXiv:2303.06594; Zhu WH, 2024, Arxiv, DOI arXiv:2304.04675	72	0	0	24	24	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	MAR 8	2024	12						229	246		10.1162/tacl_a_00642	http://dx.doi.org/10.1162/tacl_a_00642			18	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	KO8N9		Green Submitted, gold			2024-07-03	WOS:001181001100002
J	Bauer, B; Norel, R; Leow, A; Rached, ZA; Wen, B; Cecchi, G				Bauer, Brian; Norel, Raquel; Leow, Alex; Rached, Zad Abi; Wen, Bo; Cecchi, Guillermo			Using Large Language Models to Understand Suicidality in a Social Media-Based Taxonomy of Mental Health Disorders: Linguistic Analysis of Reddit Posts	JMIR MENTAL HEALTH			English	Article						natural language processing; explainable AI; suicide; mental health disorders; mental health disorder; mental health; social media; online discussions; online; large language model; LLM; downstream analyses; trauma; stress; depression; anxiety; AI; artificial intelligence; explainable artificial intelligence; web-based discussions	METAANALYSIS; DEPRESSION; RISK	Background: Rates of suicide have increased by over 35% since 1999. Despite concerted efforts, our ability to predict, explain, or treat suicide risk has not significantly improved over the past 50 years. Objective: The aim of this study was to use large language models to understand natural language use during public web-based discussions (on Reddit) around topics related to suicidality. Methods: We used large language model-based sentence embedding to extract the latent linguistic dimensions of user postings derived from several mental health-related subreddits, with a focus on suicidality. We then applied dimensionality reduction to these sentence embeddings, allowing them to be summarized and visualized in a lower-dimensional Euclidean space for further downstream analyses. We analyzed 2.9 million posts extracted from 30 subreddits, including r/SuicideWatch, between October 1 and December 31, 2022, and the same period in 2010. Results: Our results showed that, in line with existing theories of suicide, posters in the suicidality community (r/SuicideWatch) predominantly wrote about feelings of disconnection, burdensomeness, hopeless, desperation, resignation, and trauma. Further, we identified distinct latent linguistic dimensions (well-being, seeking support, and severity of distress) among all mental health subreddits, and many of the resulting subreddit clusters were in line with a statistically driven diagnostic classification system-namely, the Hierarchical Taxonomy of Psychopathology (HiTOP)-by mapping onto the proposed Conclusions: Overall, our findings provide data-driven support for several language-based theories of suicide, as well processing techniques can assist researchers in gaining deeper insights about emotions and experiences shared on the web and may aid in the validation and refutation of different mental health theories.	[Bauer, Brian] Univ Georgia, Dept Psychol, 125 Baldwin St, Athens, GA 30602 USA; [Norel, Raquel; Wen, Bo; Cecchi, Guillermo] IBM Res, Digital Hlth, Yorktown Hts, NY USA; [Leow, Alex] Univ Illinois, Dept Psychiat, Chicago, IL USA; [Leow, Alex] Univ Illinois, Dept Biomed Engn & Comp Sci, Chicago, IL USA; [Rached, Zad Abi] Coll Louise Wegmann, Beirut, Lebanon	University System of Georgia; University of Georgia; International Business Machines (IBM); University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital	Bauer, B (corresponding author), Univ Georgia, Dept Psychol, 125 Baldwin St, Athens, GA 30602 USA.	brian.bauer@uga.edu		Norel, Raquel/0000-0001-7737-4172; Abi Rached, Zad/0009-0008-1979-2921				American Psychiatric Association, 2013, DIAGNOSTIC STAT MANU; Arnaud E, 2023, 2023 IEEE INT C BIG, P4843, DOI [10.1109/BigData59044.2023.10386753, DOI 10.1109/BIGDATA59044.2023.10386753]; Arowosegbe A, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20021514; Birnbaum ML, 2020, NPJ SCHIZOPHR, V6, DOI 10.1038/s41537-020-00125-0; Burcusa SL, 2007, CLIN PSYCHOL REV, V27, P959, DOI 10.1016/j.cpr.2007.02.005; ChatGPT, OpenAI; Crowell SE, 2009, PSYCHOL BULL, V135, P495, DOI 10.1037/a0015616; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fineberg SK, 2016, PSYCHOL MED, V46, P2605, DOI 10.1017/S0033291716001215; Fox KR, 2020, PSYCHOL BULL, V146, P1117, DOI 10.1037/bul0000305; Franklin JC, 2017, PSYCHOL BULL, V143, P187, DOI 10.1037/bul0000084; Garnett Matthew F, 2023, NCHS Data Brief, P1; Gurumoorthy KS, 2019, IEEE DATA MINING, P260, DOI 10.1109/ICDM.2019.00036; Keller MB, 2006, J CLIN PSYCHIAT, V67, P14; Klonsky ED, 2015, INT J COGN THER, V8, P114, DOI 10.1521/ijct.2015.8.2.114; Kotov R, 2021, ANNU REV CLIN PSYCHO, V17, P83, DOI 10.1146/annurev-clinpsy-081219-093304; Le Glaz A, 2021, J MED INTERNET RES, V23, DOI 10.2196/15708; Low DM, 2020, J MED INTERNET RES, V22, DOI 10.2196/22635; Munn-Chernoff MA, 2021, ADDICT BIOL, V26, DOI 10.1111/adb.12880; O'Connor RC, 2011, CRISIS, V32, P295, DOI 10.1027/0227-5910/a000120; O'Dea Bridianne, 2015, Internet Interventions, V2, P183, DOI 10.1016/j.invent.2015.03.005; Paris J, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55060223; Reddit/Pushshift archives, The-Eye.eu; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Scheunemann J, 2023, J BEHAV THER EXP PSY, V79, DOI 10.1016/j.jbtep.2023.101836; Schuck A, 2019, BEHAV SCI LAW, V37, P223, DOI 10.1002/bsl.2397; SHNEIDMAN ES, 1993, J NERV MENT DIS, V181, P145, DOI 10.1097/00005053-199303000-00001; Srivastava A, 2023, BIOL PSYCHIAT-COGN N, V8, P1005, DOI 10.1016/j.bpsc.2023.06.007; Toma S, 2023, ACTA PSYCHIAT SCAND, V148, P219, DOI 10.1111/acps.13600; Tucker RP, 2016, J AFFECT DISORDERS, V189, P365, DOI 10.1016/j.jad.2015.07.049; Van Orden KA, 2008, J CONSULT CLIN PSYCH, V76, P72, DOI 10.1037/0022-006X.76.1.72; Watling D, 2022, ARCH SUICIDE RES, V26, P465, DOI 10.1080/13811118.2020.1833799; Xu YCE, 2023, MOL PSYCHIATR, V28, P2764, DOI 10.1038/s41380-022-01935-7	33	0	0	5	5	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2368-7959			JMIR MENT HEALTH	JMIR Ment. Health		2024	11								e57234	10.2196/57234	http://dx.doi.org/10.2196/57234			13	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	SI0E6	38771256	gold, Green Accepted			2024-07-03	WOS:001233700000001
J	Ogunde, F				Ogunde, Fife			Much ado about hallucinations: a brief assessment of the judicial response to large language model (LLM) hallucinations in the United States and Canada	INTERNATIONAL JOURNAL OF THE LEGAL PROFESSION			English	Article; Early Access								The surge in the utilization of generative artificial intelligence within the legal profession, particularly in preparing legal documents, has prompted a flurry of responses from the judiciary, including practice directives and standing orders. These varied responses have either directly or implicitly referred to litigants using "hallucinated" cases generated by large language models (LLMs) as a major concern. This article briefly evaluates these responses, making conclusions on their propriety and relevance.	[Ogunde, Fife] Govt Saskatchewan, Saskatoon, SK, Canada		Ogunde, F (corresponding author), Govt Saskatchewan, Saskatoon, SK, Canada.	fifeogunde@gmail.com						Ambrogi ob, 2024, LawSites; [Anonymous], State of the Courts Report 2024; [Anonymous], American Bar Association Model Rules of Professional Conduct; [Anonymous], 2024, Florida Bar Ethics Opinion 24-1; [Anonymous], 2023, Practice Direction, Re: Use of Artificial Intelligence in Court Submissions; [Anonymous], 2023, International Legal Generative AI report: Detailed survey findings; [Anonymous], 2023, Supreme Court of Nova Scotia; [Anonymous], 2023, Nova Scotia Provincial Court; [Anonymous], MODEL CODE PROFESSIO; [Anonymous], 2024, LexisNexis Launches Second-Generation Legal AI Assistant on Lexi+AI; [Anonymous], 2023, United States Court of Appeals for the Second Circuit 22-2057; [Anonymous], 2023, Bloomberg Law; [Anonymous], 2023, United States of America v Prakazrel Michel; [Anonymous], 2023, Standing Order Regarding use of Artificial Intelligence, 394th Judicial District Court; [Anonymous], 2023, Terms of use; [Anonymous], 2023, Casetext; [Anonymous], 2023, Artificial intelligence in space; [Anonymous], Ethical Principles for Judges; [Anonymous], 2024, Guidelines for the Use of Generative Artificial Intelligence in the Practice of Law; [Anonymous], 2023, Morgan v Community Against Violence; [Anonymous], 2023, Interim Principles and Guidelines on the Court's Use of Artificial Intelligence; [Anonymous], What are Large Language Models? - LLM AI Explained - AWS; [Anonymous], 2024, Thomson Reuters; [Anonymous], 2023, Superior Court of Quebec; [Anonymous], 2023, Notice to the Profession & PublicEnsuring the Integrity of court submissions when using large language models; [Anonymous], Individual Practices in Civil Cases, P7; [Anonymous], 2023, People v Zachariah C. Crabill 23PDJ067; [Anonymous], Practice Resource: Guidance on Professional Responsibility and Generative AI; [Anonymous], 2023, Generative AI & the Legal Profession; [Anonymous], 2023, Practice Direction, Use of Artificial Intelligence Tools; [Anonymous], 2023, Thomson Reuters; [Anonymous], 2024, Techniques for writing effective legal AI prompts; [Anonymous], American Bar Association Code of Judicial Conduct; Bent Adam Allen, 2023, Pace Law Review, V91, P132; Bent Adam Allen, 2023, Pace Law Review, V44, P91; Bloomberg, About us; Buchanan Joy, 2023, GPT-3.5 Hallucinates Non-Existent Citations: Evidence from Economics; Calandrillo S, 2022, U ILLINOIS LAW REV, P597; Callister Paul D., 2023, Generative AI and Finding the Law, P48; cit.uscourts, Order on Artificial Intelligence, United States Court of International Trade; Criddle Cristina, 2023, Law firms embrace the efficiencies of artificial intelligence; Curran S, 2023, Arxiv, DOI arXiv:2306.11520; Dahan Samuel, 2023, Lawyers should not trust ai: A call for an open-source legal language model; Dahl M, 2024, Arxiv, DOI [arXiv:2401.01301, 10.48550/arXiv.2401.01301]; Dipshan Rhys, 2023, Law.com; Dolmetsch Chris, 2024, Bloomberg News; Geoghegan Clara, 2023, LawweekColorado; Grossman Maura R., Is disclosure and certification of the use of generative AI really necessary; Grossman Maura R., Is disclosure and certification of the use of generative AI really necessary, P72; Gunder Jessica, 2024, Stanford Technology Law Review, V27; hid.uscourts, Disclosure and Certification RequirementsGenerative Artificial IntelligenceChambers of United States District Judge Leslie E. Kobayashi; Hon Chua Chin, 2023, Detecting LLM-Generated Text; ilnd.uscourts, Standing Order for Civil Cases before Magistrate Judge Fuentes; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Johnston Judge Iain D., Northern District of Illinois; Lai JQ, 2023, Arxiv, DOI arXiv:2312.03718; Lat David, Bloomberg Law; legal. thomsonreuters, State of the Courts Report 2024; Logvinova IIona, 2023, McKinsey; Ma Megan, 2024, Generative AI Legal Landscape 2024; Maleki N, 2024, Arxiv, DOI arXiv:2401.06796; Marshall David, 2023, Court Directives on Generative AI: Recent Attempts at Balancing Concerns with Ethical Duties and Effective Representation; Martin Tom, 2024, LawDroid Manifesto; Martineau Kim, 2023, What is Retrieval-Augmented Generation; Merken Sara, 2023, Reuters; Murray Michael, 2023, Artificial Intelligence and the Practice of Law Part 1: Lawyers must be Professional and Responsible Supervisors of AI; ohsd.uscourts, About us; okwd. uscourts, Disclosure and Certification RequirementsGenerative Artificial IntelligenceChambers of United States District Judge Scott L. Palk; Olijynk Zena, 2023, Canadian Lawyer; Patrice Joe, 2023, Above the Law; Perlman Andrew, The Legal Ethics of Generative AI; Peskoff Denis, Credible without Credit: Domain Experts Assess Generative Language Models; Rawte V, 2023, Arxiv, DOI arXiv:2310.04988; Schmitz Cristin, 2023, Law 360; supracon, About us; Surden Harry, 1942, Fordham Law Review, V92; Surden Harry, 2024, Fordham Law Review, V92, P1969; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; United States Bankruptcy Court, 2023, Northern District of Texas; United States Court of Appeals for the fifth Circuit, Notice of Proposed Amendment to 5th CIR; United States District Court, Eastern District of Missouri; Watwe Shweta, 2023, Bloomberg Law; Wellen Serena, 2024, How Lexis+ AI Delivers Hallucination-Free Linked Legal Citations; Wiggers Kyle, 2024, TechCruch; Wilkins Stephanie, The Problem with the 'Bogus' ChatGPT Legal Brief? It's not the Tech; Wilkins tephanie, 2023, Law.com; Xiang Chloe, 2023, VICE; Xu ZW, 2024, Arxiv, DOI arXiv:2401.11817	88	0	0	0	0	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0969-5958	1469-9257		INT J LEG PROF	Int. J. Leg. Prof.	2024 MAY 24	2024										10.1080/09695958.2024.2356084	http://dx.doi.org/10.1080/09695958.2024.2356084		MAY 2024	19	Law	Emerging Sources Citation Index (ESCI)	Government & Law	RU0E6					2024-07-03	WOS:001230047300001
J	Vaid, A; Duong, SQ; Lampert, J; Kovatch, P; Freeman, R; Argulian, E; Croft, L; Lerakis, S; Goldman, M; Khera, R; Nadkarni, GN				Vaid, Akhil; Duong, Son Q.; Lampert, Joshua; Kovatch, Patricia; Freeman, Robert; Argulian, Edgar; Croft, Lori; Lerakis, Stamatios; Goldman, Martin; Khera, Rohan; Nadkarni, Girish N.			Local large language models for privacy-preserving accelerated review of historic echocardiogram reports	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						large language models; LLM; privacy; generative AI; echocardiograms; open-source		Objectives The study developed framework that leverages an open-source Large Language Model (LLM) to enable clinicians to ask plain-language questions about a patient's entire echocardiogram report history. This approach is intended to streamline the extraction of clinical insights from multiple echocardiogram reports, particularly in patients with complex cardiac diseases, thereby enhancing both patient care and research efficiency.Materials and Methods Data from over 10 years were collected, comprising echocardiogram reports from patients with more than 10 echocardiograms on file at the Mount Sinai Health System. These reports were converted into a single document per patient for analysis, broken down into snippets and relevant snippets were retrieved using text similarity measures. The LLaMA-2 70B model was employed for analyzing the text using a specially crafted prompt. The model's performance was evaluated against ground-truth answers created by faculty cardiologists.Results The study analyzed 432 reports from 37 patients for a total of 100 question-answer pairs. The LLM correctly answered 90% questions, with accuracies of 83% for temporality, 93% for severity assessment, 84% for intervention identification, and 100% for diagnosis retrieval. Errors mainly stemmed from the LLM's inherent limitations, such as misinterpreting numbers or hallucinations.Conclusion The study demonstrates the feasibility and effectiveness of using a local, open-source LLM for querying and interpreting echocardiogram report data. This approach offers a significant improvement over traditional keyword-based searches, enabling more contextually relevant and semantically accurate responses; in turn showing promise in enhancing clinical decision-making and research by facilitating more efficient access to complex patient data.	[Vaid, Akhil; Duong, Son Q.; Lampert, Joshua; Nadkarni, Girish N.] Icahn Sch Med Mt Sinai, Charles Bronfman Inst Personalized Med, New York, NY 10029 USA; [Vaid, Akhil; Nadkarni, Girish N.] Icahn Sch Med Mt Sinai, Dept Med, Div Data Driven & Digital Med D3M, New York, NY 10029 USA; [Duong, Son Q.] Icahn Sch Med Mt Sinai, Div Pediat Cardiol, New York, NY 10029 USA; [Lampert, Joshua] Icahn Sch Med Mt Sinai, Helmsley Electrophysiol Ctr, New York, NY 10029 USA; [Kovatch, Patricia] Icahn Sch Med Mt Sinai, Dept Genet & Genom Sci, New York, NY 10029 USA; [Freeman, Robert] Icahn Sch Med Mt Sinai, Inst Healthcare Delivery Sci, Dept Populat Hlth Sci & Policy, New York, NY 10029 USA; [Argulian, Edgar; Croft, Lori; Lerakis, Stamatios; Goldman, Martin] Icahn Sch Med Mt Sinai, Zena & Michael A Wiener Cardiovasc Inst, New York, NY 10029 USA; [Argulian, Edgar; Croft, Lori; Lerakis, Stamatios; Goldman, Martin] Icahn Sch Med Mt Sinai, Mt Sinai Heart, New York, NY 10029 USA; [Khera, Rohan] Yale Sch Med, Dept Internal Med, Sect Cardiovasc Med, New Haven, CT 06510 USA; [Vaid, Akhil] Icahn Sch Med Mt Sinai, Dept Med, Div Data Driven & Digital Med D3M, New York, NY 10128 USA	Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Yale University; Icahn School of Medicine at Mount Sinai	Vaid, A (corresponding author), Icahn Sch Med Mt Sinai, Dept Med, Div Data Driven & Digital Med D3M, New York, NY 10128 USA.	akhil.vaid@mssm.edu		Freeman, Robert/0000-0003-4946-6533	National Heart, Lung, & Blood Institute [R01HL155915]; National Center for Advancing Clinical Sciences clinical and translational award for infrastructure [UL1TR004419]	National Heart, Lung, & Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); National Center for Advancing Clinical Sciences clinical and translational award for infrastructure	This study was funded by National Heart, Lung, & Blood Institute R01HL155915 and an National Center for Advancing Clinical Sciences clinical and translational award for infrastructure UL1TR004419.	Anderson DR, 2021, J ECHOCARDIOGR, V19, P222, DOI 10.1007/s12574-021-00531-y; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Cambria E, 2014, IEEE COMPUT INTELL M, V9, P48, DOI 10.1109/MCI.2014.2307227; Conneau A, 2018, Arxiv, DOI arXiv:1805.01070; Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3418294, 10.1145/3447772]; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu R., 2018, PyMuPDF; McKinney W., 2011, Python for high performance and scientific computing, V14, P1, DOI DOI 10.1002/MMCE.20381; Muennighoff N, 2022, Arxiv, DOI arXiv:2210.07316; Nedadur R, 2022, HEART, V108, P1592, DOI 10.1136/heartjnl-2021-319725; Noever D, 2023, Arxiv, DOI arXiv:2308.07326; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Poli M, 2023, Arxiv, DOI arXiv:2302.10866; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaid A, 2023, LANCET DIGIT HEALTH, V5, pE855, DOI 10.1016/S2589-7500(23)00202-9; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Wang L, 2024, Arxiv, DOI arXiv:2212.03533; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xiao G., 2023, INT C MACHINE LEARNI, P38087; Ye J, 2011, MATH COMPUT MODEL, V53, P91, DOI 10.1016/j.mcm.2010.07.022; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	27	0	0	9	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 30	2024										10.1093/jamia/ocae085	http://dx.doi.org/10.1093/jamia/ocae085		APR 2024	6	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	OU1I5	38687616				2024-07-03	WOS:001209699500001
C	Jiang, DF; Ren, X; Lin, BY		Rogers, A; Boyd-Graber, J; Okazaki, N		Jiang, Dongfu; Ren, Xiang; Lin, Bill Yuchen			LLM-BLENDER: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				We present LLM-BLENDER, an ensembling framework designed to attain consistently superior performance by leveraging the diverse- strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PAIRRANKER and GEN-FUSER, addressing the observation that optimal LLMs for different examples can significantly vary. PAIRRANKER employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PAIRRANKER exhibits the highest correlation with ChatGPT-based ranking. Then, GENFUSER aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate largescale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-BLENDER significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.	[Ren, Xiang; Lin, Bill Yuchen] Allen Inst Artificial Intelligence, Seattle, WA 98103 USA; [Ren, Xiang] Univ Southern Calif, Los Angeles, CA USA; [Jiang, Dongfu] Zhejiang Univ, Hangzhou, Peoples R China	University of Southern California; Zhejiang University	Jiang, DF (corresponding author), Zhejiang Univ, Hangzhou, Peoples R China.	dongfu@zju.edu.cn; xiangren@usc.edu; yuchenl@allenai.org		Jiang, Dongfu/0009-0007-9442-6721	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program [2022-22072200006]; DARPA MCS program [N660011924033]; Defense Advanced Research Projects Agency [W911NF-19-20271]; NSF [IIS 2048211]; Google; Amazon; Allen Institute	Office of the Director of National Intelligence (ODNI); Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program; DARPA MCS program(United States Department of Defense); Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); NSF(National Science Foundation (NSF)); Google(Google Incorporated); Amazon; Allen Institute	We thank members of the INK lab at USC and the Mosaic team at AI2 for valuable feedback on this project. Xiang is supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via the HIATUS Program contract #2022-22072200006, the DARPA MCS program under Contract No. N660011924033, the Defense Advanced Research Projects Agency with award W911NF-19-20271, NSF IIS 2048211, and gift awards from Google and Amazon. Yuchen's research was also supported by the Allen Institute for AI (AI2). The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government.	Aniol A, 2019, 2019 SEVENTH INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING WORKSHOPS (CANDARW 2019), P180, DOI 10.1109/CANDARW.2019.00039; Bojar Ondrej., 2017, Proceedings of the Second Conference on Machine Translation, P169; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Burges C., 2005, INT C MACH LEARN ICM, P89, DOI DOI 10.1145/1102351.1102363; Burges CJ, 2010, LEARNING, V11, P23; Cabrera Alex, 2023, BLOG POST; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Chung H.W., 2022, SCALING INSTRUCTION; Conover Mike, 2023, FREE DOLLY INTRODUCI; DIACONIS P, 1977, J ROY STAT SOC B MET, V39, P262, DOI 10.1111/j.2517-6161.1977.tb01624.x; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Geng X., 2023, Blog post; He PL, 2020, EMERG MARK FINANC TR, V56, P2198, DOI 10.1080/1540496X.2020.1785865; Hermann K. M., 2015, ADV NEURAL INFORM PR, P1693, DOI DOI 10.48550/ARXIV.1506.03340; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Jamieson K.G., 2011, P 25 ANN C NEUR INF, P2240; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; LAION-AI, 2023, OP ASS; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin BY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1823; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Liu YX, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P1065; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; NLP Team MosaicML, 2023, INTR MPT7B NEW STAND; Ouyang L., 2022, NEURIPS; Raffel C, 2020, J MACH LEARN RES, V21; Ravaut M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4504; Ravaut Mathieu, 2022, P 2022 C EMPIRICAL M, P8488; Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249; Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Shazeer N, 2018, PR MACH LEARN RES, V80; Stability-AI, 2023, STABL STAB LANG MOD; Sun Tianxiang, 2023, Blog post txsun1997; Sutawika Lintang, 2023, Pythia: A suite for analyzing large language models across training and scaling; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tiedemann J., 2020, P 22 ANN C EUROPEAN, P479; Tiedemann Jorg, 2020, P 22 ANN C EUR ASS M, P479; Touvron H., 2023, Llama: Open and efficient foundation language models; Wang Benyou, 2016, NLPCC ICCPOL; Wang Y., 2022, SELF INSTRUCT ALIGNI; Wang Yidong, 2023, Pandalm: Reproducible and automated language model assessment; Xu Canwen, 2023, OPEN SOURCE CHAT MOD; Yuan WZ, 2021, ADV NEUR IN, V34; Zhang J., 2020, PMLR, P11328; Zheng Lianmin, 2023, Blog post	47	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							14165	14178						14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962505054
J	Monti, P				Monti, Paolo			AI ENTERS PUBLIC DISCOURSE: A HABERMASIAN ASSESSMENT OF THE MORAL STATUS OF LARGE LANGUAGE MODELS	ETICA & POLITICA			English	Article						Large Language Models; Jurgen Habermas; Moral status; Responsibility; Public discourse		Large Language Models (LLMs) are generative AI systems capable of producing original texts based on inputs about topic and style provided in the form of prompts or questions. The introduction of the outputs of these systems into human discursive practices poses unprecedented moral and political questions. The article articulates an analysis of the moral status of these systems and their interactions with human interlocutors based on the Habermasian theory of communicative action. The analysis explores, among other things, Habermas's inquiries into the analogy between human minds and computers, and into the status of atypical participants in the linguistic community such as genetically modified subjects and animals. Major conclusions are the LLMs seem to qualify as authors that originally participate in discursive practices but do display only a structurally derivative form of communicative competence and fail to meet the status of communicative agents. In this sense, while the contribution of AI writing systems in public discourse and deliberation can support the process of mutual understanding within the community of speakers, the human actors involved in the development, use, and diffusion of these systems share a collective responsibility for the disclosure of AI authorship and verification and adjudication of validity claims.	[Monti, Paolo] Univ Milano Bicocca, Dipartimento Sci Umane Formaz Riccardo Massa, Milan, Italy	University of Milano-Bicocca	Monti, P (corresponding author), Univ Milano Bicocca, Dipartimento Sci Umane Formaz Riccardo Massa, Milan, Italy.	paolo.monti@unimib.it						Allen A., 2019, The Cambridge Habermas Lexicon, P47; Arendt H, 1998, The Human Condition; ARNOLD T, 2017, WORKSH 31 AAAI C ART; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bottici Chiara., 2014, IMAGINAL POLITICS IM, DOI 10.7312/columbia/9780231157780.001.0001; Brittain C.C., 2020, Toronto Journal of Theology, V36, P84; Christian B., 2020, The Alignment Problem: Machine Learning and Human Values; Christiano PF, 2017, ADV NEUR IN, V30; Coeckelbergh M, 2020, SCI ENG ETHICS, V26, P2051, DOI 10.1007/s11948-019-00146-8; Derner E, 2023, Arxiv, DOI arXiv:2305.08005; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Gabriel I, 2020, MIND MACH, V30, P411, DOI 10.1007/s11023-020-09539-2; Gordon JS, 2022, SOUTHERN J PHILOS, V60, P88, DOI 10.1111/sjp.12450; Green J.E., 2010, The Eyes of the People: Democracy in an Age of Spectatorship; HABERMAS J, 1970, INQUIRY, V13, P360, DOI 10.1080/00201747008601597; HABERMAS J, 1977, SOC RES, V44, P3; Habermas J., 2023, A New Structural Transformation of the Public Sphere and Deliberative Politics; Habermas J., 1984, THEORY COMMUNICATIVE; Habermas J., 1990, MORAL CONSCIOUSNESS; Habermas Jurgen, 1993, Justification and application: Remarks on discourse ethics; Habermas Jurgen., 2003, FUTURE HUMAN NATURE; Habermas Jurgen., 2008, Between Naturalism and Religion: Philosophical Essays; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Knox W.B., 2011, P ICML WORKSH NEW DE; Kruger H., 2019, The Cambridge Habermas Lexicon, P40; McDermid JA, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0363; Nicoletti M., 2021, Rivista Italiana di Filosofia Politica, V1, P137; OGieblyn M., 2021, God, Human, Animal, Machine: Technology, metaphor, and the search for meaning; Oviedo L, 2022, ZYGON, V57, P938, DOI 10.1111/zygo.12832; Pavlik J.V., 2023, Journalism & Mass Communication Educator, V78, P1; Preece A, 2018, INTELL SYST ACCOUNT, V25, P63, DOI 10.1002/isaf.1422; Redaelli R., 2023, Discover Artificial Intelligence, V3, P25; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schwitzgebel E, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100818; Sinnott-Armstrong W., 2021, Rethinking Moral Status, P269; Sunstein Cass R., 2017, REPUBLIC DIVIDED DEM; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Urbinati Nadia., 2019, ME PEOPLE POPULISM T; Van Dijk J., 2018, Internet and Democracy in the Network Society; Véliz C, 2021, AI SOC, V36, P487, DOI 10.1007/s00146-021-01189-x; Ye H., 2023, arXiv, DOI DOI 10.48550/ARXIV.2309.06794	43	0	0	1	1	UNIV STUDI TRIESTE, EDIZIONI UNIVERSITA TRIESTE-EUT	TRIESTE	VIA EDOARDO WEISS 21, TRIESTE, 34128, ITALY	1825-5167			ETICA POLITICA	Etica Politica		2024	26	1					61	80						20	Philosophy	Emerging Sources Citation Index (ESCI)	Philosophy	NV5P3					2024-07-03	WOS:001203247400004
J	Llanes-Jurado, J; Gómez-Zaragozá, L; Minissi, ME; Alcañiz, M; Marín-Morales, J				Llanes-Jurado, Jose; Gomez-Zaragoza, Lucia; Minissi, Maria Eleonora; Alcaniz, Mariano; Marin-Morales, Javier			Developing conversational Virtual Humans for social emotion elicitation based on large language models	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Virtual Human; Conversational agent; Affective computing; Emotion recognition; Large language models; Statistical learning	REALITY; COMMUNICATION; NAVIGATION; AGENTS; FIELD	Emotions play a critical role in numerous processes, including, but not limited to, social interactions. Consequently, the ability to evoke and recognize emotions is a challenging task with widespread implications, notably in the field of mental health assessment systems. However, up until now, emotional elicitation methods have not utilized simulated open social conversations. Our study introduces a comprehensive Virtual Human (VH), equipped with a realistic avatar and conversational abilities based on a Large Language Model. This architecture integrates psychological constructs - such as personality, mood, and attitudes - with emotional facial expressions, lip synchronization, and voice synthesis. All these features are embedded into a modular, cognitively-inspired framework, specifically designed for voice-based semi-guided emotional conversations in real time. The validation process involved an experiment with 64 participants interacting with six distinct VHs, each designed to provoke a different basic emotion. The system took an average of 4.44 s to generate the VH's response. Participants assessed the naturalness and realism of the conversation, scoring averages of 4.61 and 4.44 out of 7, respectively. The VHs successfully generated the intended emotional valence in the users, while arousal was not evoked, though it could be recognized in the VHs. Our findings underscore the feasibility of employing VHs within affective computing to elicit emotions in socially and ecologically valid contexts. This development holds significant potential for application in sectors such as health, education, and marketing, among others.	[Llanes-Jurado, Jose; Gomez-Zaragoza, Lucia; Minissi, Maria Eleonora; Alcaniz, Mariano; Marin-Morales, Javier] Univ Politecn Valencia, Inst Univ Invest Tecnol Centrada Ser Humano, Ciudad Politecn Innovac, Camino Vera,S N,Edif 8B, Valencia 46022, Spain; [Marin-Morales, Javier] Univ Politecn Valencia, Inst Univ Invest Tecnol Centrada Ser Humano, Ciudad Politecn Innovac, Access N Bldg 8B 3rd Floor Camino de Vera S N, Valencia 46022, Spain	Universitat Politecnica de Valencia; Universitat Politecnica de Valencia	Marín-Morales, J (corresponding author), Univ Politecn Valencia, Inst Univ Invest Tecnol Centrada Ser Humano, Ciudad Politecn Innovac, Access N Bldg 8B 3rd Floor Camino de Vera S N, Valencia 46022, Spain.	jllajur@upvnet.upv.es; lugoza@htech.upv.es; meminiss@htech.upv.es; malcaniz@htech.upv.es; jamarmo@htech.upv.es	Marin-Morales, Javier/AAL-1463-2020; Alcaniz, Mariano/I-9659-2016	Marin-Morales, Javier/0000-0003-1271-2892; Minissi, Maria Eleonora/0000-0001-6326-0609; Gomez-Zaragoza, Lucia/0000-0001-9885-2559; Alcaniz, Mariano/0000-0001-9207-0636	Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain [Ayuda a Primeros Proyectos de Investigacion] [PAID-06-22]; Ministerio de Derechos Sociales y Agenda 2030, Spain [Subvenciones para la realizacion de actividades relacionadas con la promocion e implementacion de la Agenda 2030 para el Desarrollo Sostenible en Espana] [A203023]	Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain [Ayuda a Primeros Proyectos de Investigacion]; Ministerio de Derechos Sociales y Agenda 2030, Spain [Subvenciones para la realizacion de actividades relacionadas con la promocion e implementacion de la Agenda 2030 para el Desarrollo Sostenible en Espana]	This work was supported by the Vicerrectorado de Investigacion de la Universitat Politecnica de Valencia (UPV), Spain [Ayuda a Primeros Proyectos de Investigacion (PAID-06-22)] and Ministerio de Derechos Sociales y Agenda 2030, Spain [Subvenciones para la realizacion de actividades relacionadas con la promocion e implementacion de la Agenda 2030 para el Desarrollo Sostenible en Espana (A203023)].	Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249; Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Adikari A, 2022, FUTURE GENER COMP SY, V126, P318, DOI 10.1016/j.future.2021.08.015; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bilquise G, 2022, HUM BEHAV EMERG TECH, V2022, DOI 10.1155/2022/9601630; Borrego A, 2018, GAMES HEALTH J, V7, P151, DOI 10.1089/g4h.2017.0114; Borrego A, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0174-1; Bradley M.M., 2007, INT AFFECTIVE PICTUR; BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9; Bredin H., 2021, arXiv; Balano JB, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P387, DOI 10.1109/IEA.2019.8715187; Burden D.S., 2019, inChapman & Hall/CRCArtificial Intelligence and Robotics Series; Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158; Ciechanowski L, 2019, FUTURE GENER COMP SY, V92, P539, DOI 10.1016/j.future.2018.01.055; Clemente M, 2014, EXPERT SYST APPL, V41, P1584, DOI 10.1016/j.eswa.2013.08.055; Denecke K, 2023, J MED INTERNET RES, V25, DOI 10.2196/41583; DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061; Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026; Ekman P., 1978, ENVIRON PSYCH NONVER, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; GALIN D, 1982, BRAIN LANG, V16, P19, DOI 10.1016/0093-934X(82)90070-0; Greene S, 2016, IEEE CONSUM ELECTR M, V5, P44, DOI 10.1109/MCE.2016.2590178; Gross JJ, 2014, CLIN PSYCHOL SCI, V2, P387, DOI 10.1177/2167702614536164; Guillen-Riquelme A., 2011, Psicothema, V23; Hachman M., 2014, PC World, V32, P13; Hube N, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519822; Hutchens J. L., 1998, Introducing megahal; Imam IF, 1997, AI MAG, V18, P75; Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15; Kurniawan AA, 2015, 2015 INTERNATIONAL CONFERENCE ON SCIENCE IN INFORMATION TECHNOLOGY (ICSITECH), P326, DOI 10.1109/ICSITech.2015.7407826; Lang PJ., 1980, TECHNOLOGY MENTAL HL, DOI DOI 10.1111/J.1469-8986.1993.TB03352.X; Ludlow CL, 2015, J CLIN NEUROPHYSIOL, V32, P294, DOI 10.1097/WNP.0000000000000186; Marín-Morales J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32063-4; May Richard, 2020, Addressing Global Challenges and Quality Education. 15th European Conference on Technology Enhanced Learning, EC-TEL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12315), P482, DOI 10.1007/978-3-030-57717-9_49; MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648; Miao F, 2022, J MARKETING, V86, P67, DOI 10.1177/0022242921996646; Moemeka E., 2015, Real world windows 10 development, P471; Nardelli M, 2015, IEEE T AFFECT COMPUT, V6, P385, DOI 10.1109/TAFFC.2015.2432810; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Ospina-Bohorquez Alejandra, 2022, Distributed Computing and Artificial Intelligence: 18th International Conference. Lecture Notes in Networks and Systems (15179), P32, DOI 10.1007/978-3-030-86261-9_4; Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Riva G, 2007, CYBERPSYCHOL BEHAV, V10, P45, DOI 10.1089/cpb.2006.9993; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Safayari A., 2021, Depression diagnosis by deep learning using EEG signals: A systematic review, DOI [10.20944/preprints202107.0028.v1, DOI 10.20944/PREPRINTS202107.0028.V1]; Segrin C, 2000, CLIN PSYCHOL REV, V20, P379, DOI 10.1016/S0272-7358(98)00104-4; Sollfrank T, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.651044; Stanica I, 2018, 2018 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P9, DOI 10.1109/ZINC.2018.8448645; Suparatpinyo S, 2023, ARTIF LIFE ROBOT, V28, P332, DOI 10.1007/s10015-023-00852-4; Susindar Sahinya, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P252, DOI 10.1177/1071181319631509; Tack Anais, 2022, P 15 INT C ED DAT MI, P522, DOI 10.5281/zenodo.6853187; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Vaish A, 2008, PSYCHOL BULL, V134, P383, DOI 10.1037/0033-2909.134.3.383; Serban IV, 2016, Arxiv, DOI [arXiv:1606.00776, DOI 10.48550/ARXIV.1606.00776]; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991	54	1	1	34	34	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	JUL 15	2024	246								123261	10.1016/j.eswa.2024.123261	http://dx.doi.org/10.1016/j.eswa.2024.123261		JAN 2024	16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	IF8T8		hybrid			2024-07-03	WOS:001165013400001
C	Kille, B; Lommatzsch, A; Özgobek, Ö; Liu, P; Eide, S; Zhang, LM			ACM	Kille, Benjamin; Lommatzsch, Andreas; Ozgobek, Ozlem; Liu, Peng; Eide, Simen; Zhang, Lemei			The Eleventh International Workshop on News Recommendation and Analytics (INRA'23)	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		news; personalization; recommender systems; analytics		Artificial Intelligence is transforming the news eco-system at a rapid pace. Large Language Models have emerged and facilitate producing content in larger quantities and with less skill or technical oversight. At the same time, media organizations struggle to maintain public trust as misinformation and disinformation continue to spread. The 11th International Workshop on News Recommendation and Analytics (INRA) serves as a venue for exchanging ideas, discussing recent developments, and important issues concerning news. We welcome contributions as scientific articles, demonstrations, and innovative ideas or citicism. Our goal is to bring together both academia and practitioners to address vital challenges facing the media world. The workshop gives attendees the chance to learn about ongoing research, discuss technical as well as ethical aspects of personalization, and contemplate about how technology, in particular Artificial Intelligence, will affect the way humans engage with news. Topics of interest include Large Language Models, advances in news personalization, mis- and disinformation, and user experience.	[Kille, Benjamin; Ozgobek, Ozlem; Liu, Peng; Zhang, Lemei] Norwegian Univ Sci & Technol, Trondheim, Norway; [Lommatzsch, Andreas] Tech Univ Berlin, Berlin, Germany; [Eide, Simen] Schibsted, Oslo, Norway	Norwegian University of Science & Technology (NTNU); Technical University of Berlin	Kille, B (corresponding author), Norwegian Univ Sci & Technol, Trondheim, Norway.	benjamin.u.kille@ntnu.no; andreas.lommatzsch@dai-labor.de; ozlem.ozgobek@ntnu.no; peng.liu@ntnu.no; simen.eide@schibsted.com; lemei.zhang@ntnu.no		Kille, Benjamin/0000-0002-3206-5154				Cantador Ivan, 2014, CEUR Workshop Proceedings, V1181; Cena Federica, 2016, CEUR Workshop Proceedings, V1618; Cuzzocrea A, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2309, DOI 10.1145/3269206.3274267; del Barrio DA, 2023, PROCEEDINGS OF THE 2023 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, ICMR 2023, P627, DOI 10.1145/3591106.3592278; Desai A, 2021, LANCET DIGIT HEALTH, V3, pE619, DOI 10.1016/S2589-7500(21)00178-3; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fallis D., 2014, PHILOS INFORM QUALIT, P135, DOI [DOI 10.1007/978-3-319-07121-3_8, 10.1007/978-3-319-07121-3_8]; Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018; Gulla Jon Atle, 2015, 3 INT WORKSHOP NEWS, P345, DOI [10.1145/2792838.2798721, DOI 10.1145/2792838.2798721]; Karimi M, 2018, INFORM PROCESS MANAG, V54, P1203, DOI 10.1016/j.ipm.2018.04.008; Koprinska Irena, 2020, Proceedings. Communications in Computer and Information Science, V1323, DOI [10.1007/978-3-030-65965-3, DOI 10.1007/978-3-030-65965-3]; Manic M., 2015, Bulletin of the Transilvania University of Brasov.Economic Sciences.Series V, V8, P53; Özgöbek Ö, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P772, DOI 10.1145/3460231.3470942; Özgöbek Ö, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P558, DOI 10.1145/3298689.3346972; Ozgobek Ozlem, 2017, 5 INT WORKSHOP NEWS; Ozgobek Ozlem, 2022, 10 INT WORKSHOP NEWS, P3470, DOI [10.1145/3477495.3531705, DOI 10.1145/3477495.3531705]; Purwins H, 2019, IEEE J-STSP, V13, P206, DOI 10.1109/JSTSP.2019.2908700; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Tavakolifard Mozhgan, 2013, WORKSHOP CHALLENGE N, P481, DOI [10.1145/2507157.2508004, DOI 10.1145/2507157.2508004]; West JD, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.1912444117; Wu CH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1652, DOI 10.1145/3404835.3463069; Xiao ST, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4215, DOI 10.1145/3534678.3539120; Yang KC, 2023, Arxiv, DOI arXiv:2304.00228; Zhang T., 2023, arXiv; Zhang W, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3279952	25	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1263	1266		10.1145/3604915.3608760	http://dx.doi.org/10.1145/3604915.3608760			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ					2024-07-03	WOS:001156630300170
C	Zhang, P; Jaipersaud, B; Ba, J; Petersen, A; Zhang, L; Zhang, MR			ACM	Zhang, Paul; Jaipersaud, Brandon; Ba, Jimmy; Petersen, Andrew; Zhang, Lisa; Zhang, Michael R.			Classifying Course Discussion Board Questions using LLMs	PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL. 2			English	Proceedings Paper	28th Annual Conference on Innovation and Technology in Computer Science Education (ITiCSE)	JUL 08-12, 2023	Univ Turku, Turku, FINLAND	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ, ACM Europe Council, Informat Europe	Univ Turku	Course Discussion Board; GPT-3; Large Language Models; Machine Learning; Natural Language Processing; Question Answering		Large language models (LLMs) can be used to answer student questions on course discussion boards, but there is a risk of LLMs answering questions they are unable to address. We propose and evaluate an LLM-based system that classifies student questions into one of four types: conceptual, homework, logistics, and not answerable. We then prompt an LLM using a type-specific prompt. Using GPT-3, we achieve 81% classification accuracy across the four categories. Furthermore, we achieve 93% accuracy on classifying not answerable questions. This indicates that our system effectively ignores questions that it cannot address.	[Zhang, Paul; Petersen, Andrew; Zhang, Lisa] Univ Toronto Mississauga, Toronto, ON, Canada; [Jaipersaud, Brandon] Vector Inst, Toronto, ON, Canada; [Ba, Jimmy; Zhang, Michael R.] Univ Toronto, Toronto, ON, Canada	University of Toronto; University Toronto Mississauga; Vector Institute for Artificial Intelligence; University of Toronto	Zhang, P (corresponding author), Univ Toronto Mississauga, Toronto, ON, Canada.	pol.zhang@utoronto.ca; brandon.jaipersaud@mail.utoronto.ca; jba@cs.toronto.edu; andrew.petersen@utoronto.ca; lczhang@cs.toronto.edu; michael@cs.toronto.edu		Petersen, Andrew/0000-0003-1337-7985; Jaipersaud, Brandon/0009-0007-0478-7356				Khot T, 2022, Arxiv, DOI arXiv:2210.02406	1	1	1	7	17	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0139-9				2023							658	658		10.1145/3587103.3594202	http://dx.doi.org/10.1145/3587103.3594202			1	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BV6AU					2024-07-03	WOS:001054840400063
C	Leinonen, J; Denny, P; MacNeil, S; Sarsa, S; Bernstein, S; Kim, J; Tran, A; Hellas, A			ACM	Leinonen, Juho; Denny, Paul; MacNeil, Stephen; Sarsa, Sami; Bernstein, Seth; Kim, Joanne; Tran, Andrew; Hellas, Arto			Comparing Code Explanations Created by Students and Large Language Models	PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1			English	Proceedings Paper	28th Annual Conference on Innovation and Technology in Computer Science Education (ITiCSE)	JUL 08-12, 2023	Univ Turku, Turku, FINLAND	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ, ACM Europe Council, Informat Europe	Univ Turku	natural language generation; code comprehension; GPT-3; CS1; ChatGPT; GPT-4; foundation models; code explanations; resource generation; large language models	PROGRAM COMPREHENSION	Reasoning about code and explaining its purpose are fundamental skills for computer scientists. There has been extensive research in the field of computing education on the relationship between a student's ability to explain code and other skills such as writing and tracing code. In particular, the ability to describe at a high-level of abstraction how code will behave over all possible inputs correlates strongly with code writing skills. However, developing the expertise to comprehend and explain code accurately and succinctly is a challenge for many students. Existing pedagogical approaches that scaffold the ability to explain code, such as producing exemplar code explanations on demand, do not currently scale well to large classrooms. The recent emergence of powerful large language models (LLMs) may offer a solution. In this paper, we explore the potential of LLMs in generating explanations that can serve as examples to scaffold students' ability to understand and explain code. To evaluate LLM-created explanations, we compare them with explanations created by students in a large course (n approximate to 1000) with respect to accuracy, understandability and length. We find that LLM-created explanations, which can be produced automatically on demand, are rated as being significantly easier to understand and more accurate summaries of code than student-created explanations. We discuss the significance of this finding, and suggest how such models can be incorporated into introductory programming education.	[Leinonen, Juho; Denny, Paul] Univ Auckland, Auckland, New Zealand; [MacNeil, Stephen; Bernstein, Seth; Kim, Joanne; Tran, Andrew] Temple Univ, Philadelphia, PA USA; [Sarsa, Sami; Hellas, Arto] Aalto Univ, Espoo, Finland	University of Auckland; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Aalto University	Leinonen, J (corresponding author), Univ Auckland, Auckland, New Zealand.	juho.leinonen@auckland.ac.nz; paul@cs.auckland.ac.nz; stephen.macneil@temple.edu; sami.sarsa@aalto.fi; seth.bernstein@temple.edu; joanne.kim@temple.edu; andrew.tran10@temple.edu; arto.hellas@aalto.fi	Leinonen, Juho/D-2162-2018; MacNeil, Stephen/HPH-0843-2023	Leinonen, Juho/0000-0001-6829-9449; MacNeil, Stephen/0000-0003-2781-6619; Denny, Paul/0000-0002-5150-9806	Ulla Tuominen Foundation	Ulla Tuominen Foundation	We are grateful for the grant from the Ulla Tuominen Foundation to the first author.	Abdi S, 2021, IEEE T LEARN TECHNOL, V14, P81, DOI 10.1109/TLT.2021.3058644; Abdul-Rahman SS, 2014, COMPUT HUM BEHAV, V30, P286, DOI 10.1016/j.chb.2013.09.007; Becker Brett A., 2023, PROC 54 ACM TECHNICA, V1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Cornelissen B, 2011, IEEE T SOFTWARE ENG, V37, P341, DOI 10.1109/TSE.2010.47; Cunningham K, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P551, DOI 10.1145/3478431.3499370; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny Paul, 2012, P 17 ACM ANN C INNOV, P75, DOI DOI 10.1145/2325296.2325318; Denny Paul, 2009, PROC 11 AUSTRALASIAN, V95; Denny Paul, 2023, PROC 54 ACM TECHNICA, V1; Ettles Andrew, 2018, P 20 AUSTR COMP ED C, P83, DOI 10.1145/3160489.3160493; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Griffin JM, 2016, SIGITE'16: PROCEEDINGS OF THE 17TH ANNUAL CONFERENCE ON INFORMATION TECHNOLOGY EDUCATION, P148, DOI 10.1145/2978192.2978231; Guo Philip J, 2013, Proceedings of the 44th SIGCSE Technical Symposium on Computer Science Education, SIGCSE '13, P579, DOI [10.1145/2445196.2445368, DOI 10.1145/2445196.2445368]; Hanks B, 2011, COMPUT SCI EDUC, V21, P135, DOI 10.1080/08993408.2011.579808; Hebig R, 2020, INT C PROGRAM COMPRE, P425, DOI 10.1145/3387904.3389283; Hui JS, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173596; Kerby D.S., 2014, Compr. Psychol, V3, p11, DOI DOI 10.2466/11.IT.3.1; Lehtinen Teemu, 2021, ITiCSE '21: Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education, P206, DOI 10.1145/3430665.3456322; Lehtinen Teemu, 2023, PROC 25 AUSTRALASIAN; Leinonen Juho, 2020, ITiCSE '20: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, P349, DOI 10.1145/3341525.3387385; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Lister R, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P161, DOI 10.1145/1595496.1562930; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil S, 2021, C&C'21: PROCEEDINGS OF THE 13TH CONFERENCE ON CREATIVITY AND COGNITION, DOI 10.1145/3450741.3465261; MacNeil Stephen, 2023, PROC 54 ACM TECHNICA; MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491; Marwan S, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P520, DOI 10.1145/3304221.3319759; MCGRAW KO, 1992, PSYCHOL BULL, V111, P361, DOI 10.1037/0033-2909.111.2.361; Murphy Laurie, 2012, PROC 9 ANN INT C INT, P111, DOI DOI 10.1145/2361276.2361299; Nygren Henrik, 2019, P 1 UK IR COMP ED RE, P1; Oney Steve, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274400; Pirttinen N, 2022, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2022, VOL 1, P12, DOI 10.1145/3502718.3524762; Pirttinen N, 2018, ITICSE'18: PROCEEDINGS OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P326, DOI 10.1145/3197091.3197117; Reek M. M., 1995, SIGCSE Bulletin, V27, P6, DOI 10.1145/199691.199696; Sanders K, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P177, DOI 10.1145/3291279.3339408; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sheard J, 2008, ITICSE '08: PROCEEDINGS OF THE 13TH ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P209; Snowdon S., 2011, P 7 INT WORKSH COMP, P93, DOI [10.1145/2016911.2016931, DOI 10.1145/2016911.2016931]; Sudol-DeLyser L.A., 2012, Proceedings of the 17th ACM Annual Conference on Innovation and Technology in Computer Science Education - ITiCSE'12, P81; Sun Ron, 2000, KNOWLEDGE BASED SYST, V2000, P249; Ullah Z, 2018, COMPUT APPL ENG EDUC, V26, P2328, DOI 10.1002/cae.21974; Vihavainen Arto, 2015, P 46 ACM TECHNICAL S, P284, DOI [DOI 10.1145/2676723.2677260, 10.1145/2676723, DOI 10.1145/2676723]; VONMAYRHAUSER A, 1995, COMPUTER, V28, P44, DOI 10.1109/2.402076; Wasserstein RL, 2016, AM STAT, V70, P129; Whalley Jacqueline L., 2006, ACE '06, V52, P243; Zhi R, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P98, DOI 10.1145/3287324.3287385	48	15	15	16	25	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0138-2				2023							124	130		10.1145/3587102.3588785	http://dx.doi.org/10.1145/3587102.3588785			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BV5PJ		Green Submitted, Bronze			2024-07-03	WOS:001051691300020
J	Mittelstadt, B; Wachter, S; Russell, C				Mittelstadt, Brent; Wachter, Sandra; Russell, Chris			To protect science, we must use LLMs as zero-shot translators	NATURE HUMAN BEHAVIOUR			English	Editorial Material								Large language models (LLMs) do not distinguish between fact and fiction. They will return an answer to almost any prompt, yet factually incorrect responses are commonplace. To ensure our use of LLMs does not degrade science, we must use them as zero-shot translators: to convert accurate source material from one form to another.	[Mittelstadt, Brent; Wachter, Sandra; Russell, Chris] Univ Oxford, Oxford Internet Inst, Oxford, England	University of Oxford	Mittelstadt, B (corresponding author), Univ Oxford, Oxford Internet Inst, Oxford, England.	brent.mittelstadt@oii.ox.ac.uk	Russell, Chris/HME-1474-2023	Russell, Chris/0000-0003-1665-1759	This work has been supported through research funding provided by the Wellcome Trust (grant no. 223765/Z/21/Z), Sloan Foundation (grant no. G-2021-16779), the Department of Health and Social Care, and Luminate Group to support the Trustworthiness Auditing [223765/Z/21/Z]; Wellcome Trust [G-2021-16779]; Sloan Foundation; Department of Health and Social Care; Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford; Wellcome Trust [223765/Z/21/Z] Funding Source: Wellcome Trust	This work has been supported through research funding provided by the Wellcome Trust (grant no. 223765/Z/21/Z), Sloan Foundation (grant no. G-2021-16779), the Department of Health and Social Care, and Luminate Group to support the Trustworthiness Auditing; Wellcome Trust(Wellcome Trust); Sloan Foundation(Alfred P. Sloan Foundation); Department of Health and Social Care; Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford; Wellcome Trust(Wellcome Trust)	This work has been supported through research funding provided by the Wellcome Trust (grant no. 223765/Z/21/Z), Sloan Foundation (grant no. G-2021-16779), the Department of Health and Social Care, and Luminate Group to support the Trustworthiness Auditing for AI project and Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford. The funders had no role in the decision to publish or the preparation of this manuscript.	Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Drezner Daniel W., 2017, The Ideas Industry; Feng SB, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11737; Graeber David., 2018, Bullshit jobs: A theory; Holtzman A., 2019, P INT C LEARN REPR; Johnson M., 2017, Google's multilingual neural machine translation system: Enabling zero-shot translation, V5, P339, DOI 10.1162/tacla00065; Kabir S., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2308.02312; Kang EB, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517221146122; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Liew CS, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012429; Lin J., 2013, ACM SIGKDD Explorations Newsletter, V14, P6, DOI DOI 10.1145/2481244.2481247; Mielke SJ, 2022, T ASSOC COMPUT LING, V10, P857, DOI 10.1162/tacl_a_00494; Mitchell M, 2023, SCIENCE, V381, DOI 10.1126/science.adj5957; Munn L, 2023, AI SOC, DOI 10.1007/s00146-023-01756-4	15	2	2	2	2	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	JAN	2024	8	1					11	13		10.1038/s41562-023-01744-0	http://dx.doi.org/10.1038/s41562-023-01744-0		NOV 2023	3	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	IX3B9	37985912	Green Submitted			2024-07-03	WOS:001107579600002
C	Chen, BQ; Yi, FD; Varró, D			IEEE	Chen, Boqi; Yi, Fandi; Varro, Daniel			Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction	2023 ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION, MODELS-C			English	Proceedings Paper	ACM/IEEE International Conference on Model Driven Engineering Languages and Systems (MODELS)	OCT 01-06, 2023	Vasteras, SWEDEN	IEEE, Assoc Comp Machinery, IEEE Comp Soc		taxonomy construction; domain-specific constraints; large language models; few-shot learning; fine-tuning		Taxonomies represent hierarchical relations between entities, frequently applied in various software modeling and natural language processing (NLP) activities. They are typically subject to a set of structural constraints restricting their content. However, manual taxonomy construction can be time-consuming, incomplete, and costly to maintain. Recent studies of large language models (LLMs) have demonstrated that appropriate user inputs (called prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks without explicit (re-)training. However, existing approaches for automated taxonomy construction typically involve fine-tuning a language model by adjusting model parameters. In this paper, we present a general framework for taxonomy construction that takes into account structural constraints. We subsequently conduct a systematic comparison between the prompting and fine-tuning approaches performed on a hypernym taxonomy and a novel computer science taxonomy dataset. Our result reveals the following: (1) Even without explicit training on the dataset, the prompting approach outperforms fine-tuning-based approaches. Moreover, the performance gap between prompting and fine-tuning widens when the training dataset is small. However, (2) taxonomies generated by the fine-tuning approach can be easily post-processed to satisfy all the constraints, whereas handling violations of the taxonomies produced by the prompting approach can be challenging. These evaluation findings provide guidance on selecting the appropriate method for taxonomy construction and highlight potential enhancements for both approaches.	[Chen, Boqi] McGill Univ, Elect & Comp Engn, Montreal, PQ, Canada; [Yi, Fandi] McGill Univ, Desautels Fac Management, Montreal, PQ, Canada; [Varro, Daniel] Linkoping Univ, Linkoping, Sweden; [Varro, Daniel] McGill Univ, Montreal, PQ, Canada	McGill University; McGill University; Linkoping University; McGill University	Chen, BQ (corresponding author), McGill Univ, Elect & Comp Engn, Montreal, PQ, Canada.		Varro, Daniel/C-5447-2015		FRQNT-B2X project [319955]; Wallenberg AI, Autonomous Systems and Software Program (WASP), Sweden	FRQNT-B2X project; Wallenberg AI, Autonomous Systems and Software Program (WASP), Sweden	Partially supported by the FRQNT-B2X project (file number: 319955) and the Wallenberg AI, Autonomous Systems and Software Program (WASP), Sweden	Aghajanyan A, 2020, Arxiv, DOI arXiv:2012.13255; [Anonymous], 2023, ACM computing classification system; Bansal M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1041; Black Sid, 2021, Zenodo; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cámara J, 2023, SOFTW SYST MODEL, V22, P781, DOI 10.1007/s10270-023-01105-5; Chaaben M. B, 2023, IEEEACM INT C SOFTWA; Chen B., 2022, 37 IEEEACM INT C AUT, P1; Chen C, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4687; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chen Weizhu, 2022, 10 INT C LEARNING RE; Cocos Anne, 2018, P 2018 C N AM CHAPT, P323, DOI DOI 10.18653/V1/N18-1030; Combemale B., 2023, Software and Systems Modeling., V22; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Jain D., 2022, arXiv; Li CY, 2018, Arxiv, DOI arXiv:1804.08838; Mao YN, 2018, Arxiv, DOI arXiv:1805.04044; McGuinness DL., 2004, W3C RECOMMENDATION, DOI DOI 10.2004-03; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; OpenAI, 2023, GPT-4 Technical Report; Radford A., 2018, IMPROVING LANGUAGE U; Sun L., 2022, FINDINGS ASS COMPUTA, P1776; Vaswani A, 2017, ADV NEUR IN, V30; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Weyssow M, 2022, SOFTW SYST MODEL, V21, P1071, DOI 10.1007/s10270-022-00975-5; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]	29	0	0	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-2498-3				2023							588	596		10.1109/MODELS-C59198.2023.00097	http://dx.doi.org/10.1109/MODELS-C59198.2023.00097			9	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3FC		Green Submitted			2024-07-03	WOS:001137051500079
J	Ott, S; Hebenstreit, K; Lievin, V; Hother, CE; Moradi, M; Mayrhauser, M; Praas, R; Winther, O; Samwald, M				Ott, Simon; Hebenstreit, Konstantin; Lievin, Valentin; Hother, Christoffer Egeberg; Moradi, Milad; Mayrhauser, Maximilian; Praas, Robert; Winther, Ole; Samwald, Matthias			ThoughtSource: A central hub for large language model reasoning data	SCIENTIFIC DATA			English	Article; Data Paper								Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates seven scientific/medical, three general-domain and five math word question answering datasets.	[Ott, Simon; Hebenstreit, Konstantin; Moradi, Milad; Mayrhauser, Maximilian; Praas, Robert; Samwald, Matthias] Med Univ Vienna, Inst Artificial Intelligence, Vienna, Austria; [Lievin, Valentin; Winther, Ole] Tech Univ Denmark, Sect Cognit Syst, Lyngby, Denmark; [Hother, Christoffer Egeberg] Copenhagen Univ Hosp, Dept Clin Immunol, Copenhagen, Denmark; [Praas, Robert] Royal Inst Technol KTH, Sch Elect Engn & Comp Sci, Stockholm, Sweden	Medical University of Vienna; Technical University of Denmark; University of Copenhagen; Royal Institute of Technology	Samwald, M (corresponding author), Med Univ Vienna, Inst Artificial Intelligence, Vienna, Austria.	matthias.samwald@meduniwien.ac.at	Winther, Ole/JOZ-2578-2023	Moradi, Milad/0000-0002-9724-0339; Hebenstreit, Konstantin/0009-0005-4604-0635; Samwald, Matthias/0000-0002-4855-2571; Winther, Ole/0000-0002-1966-3205				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Dalvi B., 2021, arXiv; Dua D, 2022, Arxiv, DOI [arXiv:2212.04092, DOI 10.48550/ARXIV.2212.04092]; Fries JA, 2022, Arxiv, DOI arXiv:2206.15076; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Hebenstreit K, 2023, Arxiv, DOI [arXiv:2305.02897, DOI 10.48550/ARXIV.2305.02897]; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Jung JH, 2022, Arxiv, DOI arXiv:2205.11822; Khattab O, 2023, Arxiv, DOI [arXiv:2212.14024, DOI 10.48550/ARXIV.2212.14024]; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Koncel-Kedziorski R., 2016, NAACL HLT 2016 2016, P1152, DOI [10.18653/v1/N16, 10.18653/v1/N16-1136, DOI 10.18653/VLIN16-1136]; Lamm M, 2021, T ASSOC COMPUT LING, V9, P790, DOI 10.1162/tacl_a_00398; Laurencon H., 2022, ADV NEURAL INFORM PR; Lhoest Q, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P175; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Ling W, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P158, DOI 10.18653/v1/P17-1015; Miao SY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P975; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Nair V, 2023, Arxiv, DOI [arXiv:2303.17071, DOI 10.48550/ARXIV.2303.17071]; Ott S., 2023, ZENODO, DOI [10.5281/zenodo.8199538, DOI 10.5281/ZENODO.8199538]; Ott S., 2023, ZENODO, DOI [10.5281/zenodo.8199390, DOI 10.5281/ZENODO.8199390]; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pal A., 2022, C HLTH INFERENCE LEA, V174, P248; Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2080; Press O, 2023, Arxiv, DOI arXiv:2210.03350; Sanh V, 2022, arXiv; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Trivedi H, 2023, Arxiv, DOI [arXiv:2212.10509, 10.48550/arXiv.2212.10509, DOI 10.48550/ARXIV.2212.10509]; Wang A, 2019, ADV NEUR IN, V32; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xie ZN, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5456; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	42	5	5	14	24	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2052-4463		SCI DATA	Sci. Data	AUG 8	2023	10	1							528	10.1038/s41597-023-02433-3	http://dx.doi.org/10.1038/s41597-023-02433-3			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	O5ZO0	37553439	Green Published, Green Submitted, gold			2024-07-03	WOS:001044589700002
J	Zhou, B; Li, XY; Liu, TY; Xu, KZ; Liu, W; Bao, JS				Zhou, Bin; Li, Xinyu; Liu, Tianyuan; Xu, Kaizhou; Liu, Wei; Bao, Jinsong			CausalKGPT: Industrial structure causal knowledge-enhanced large language model for cause analysis of quality problems in aerospace product manufacturing	ADVANCED ENGINEERING INFORMATICS			English	Article						Aerospace product; Causal quality-related knowledge graph; Large language model; Causal knowledge graph-guided prompt; Cause analysis of quality defects	ROOT CAUSE ANALYSIS; MAINTENANCE; INFERENCE; SYSTEMS; FAULTS	The whole cycle for manufacturing aerospace thin-walled shells is a lengthy and sophisticated process. A large amount of quality-related data exists within and between processes, involving many types of quality defects and influencing factors. However, there are ambiguous causal associations among quality-related data affecting the shape-properties of the shell. Also, the coupling of long processes and multiple factors makes it hard to analyze the main factors that affect the quality defects in shell manufacturing. In this paper, taking into account the advantages of causal Scientology and the large language model (LLM), we propose an industrial structure causal knowledge-enhanced large language model for the cause analysis of quality defects in aerospace product manufacturing. To reinforce the causal associations among quality-related data deriving from manufacturing documents (product defect survey sheets, quality inspection, and maintenance reports), a structure causal graphbased sum-product network (SCG-SPN) model is designed to model machining quality-related knowledge and eliminate pseudo-association confounding factors by doing an intervention. Thus, a causal quality-related knowledge graph (CQKG) with high-quality causal associations is constructed. With this, to provide a trustworthy guarantee in responding to quality problem solving, we construct a quality-related prompt dataset with multi-round conversations based on CQKG. Then, a novel P-tuning that adapts to utilize external CQKG instructions is designed to fine-tune an open-source ChatGLM base model. Based on this, a causal knowledge graphaugmented LLM, named CausalKGPT, is developed to enable reasoning and responding to quality defects in both Chinese and English. It uses natural text descriptions related to quality defects as input and takes a qualityrelated causal knowledge graph as an additional corpus. Finally, the case study shows that the CausalKGPT performs with more expertise and reliability in responding to quality question solving of aerospace shell manufacturing than the classic commercial models like ChatGPT and GPT4. The results indicate that the proposed method may provide a trustworthy guide in assisting workers to analyze quality defects in aerospace products.	[Zhou, Bin] Anhui Polytech Univ, Sch Artificial Intelligence, Wuhu 241000, Peoples R China; [Li, Xinyu; Bao, Jinsong] Donghua Univ, Coll Mech Engn, Shanghai 201620, Peoples R China; [Liu, Tianyuan] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong 999077, Peoples R China; [Xu, Kaizhou] Shanghai Space Prop Technol Res Inst, Shanghai 201109, Peoples R China; [Liu, Wei] Anhui Univ Finance & Econ, Sch Management Sci & Engn, Bengbu 233030, Peoples R China	Anhui Polytechnic University; Donghua University; Hong Kong Polytechnic University; Anhui University of Finance & Economics	Bao, JS (corresponding author), Donghua Univ, Coll Mech Engn, Shanghai 201620, Peoples R China.; Liu, W (corresponding author), Anhui Univ Finance & Econ, Sch Management Sci & Engn, Bengbu 233030, Peoples R China.	liuwei628@aufe.edu.cn; bao@dhu.edu.cn	LIU, Tianyuan/ITV-8891-2023; LI, XINYU/S-5783-2019	LIU, Tianyuan/0000-0002-4563-8716; LI, XINYU/0000-0002-4117-9698; BAO, Jinsong/0000-0003-1999-1003	National Key Research and Development Program of China [2019YFB1706300]; National Natural Science Foundation of China [62202001]; Shanghai Rising -Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality [22YF1400200]; Fundamental Research Funds for the Central Universities; Graduate Student Innovation Fund of Donghua University [CUSF-DH-D-2021043]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Rising -Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Graduate Student Innovation Fund of Donghua University	This work is supported by the National Key Research and Development Program of China (No.2019YFB1706300), the National Natural Science Foundation of China (No. 62202001), Shanghai Rising -Star Plan (Yangfan Program) from the Science and Technology Commission of Shanghai Municipality (No. 22YF1400200), and the Fundamental Research Funds for the Central Universities and Graduate Student Innovation Fund of Donghua University (No. CUSF-DH-D-2021043).	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chemweno P, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM); Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2778, DOI 10.1145/3485447.3511998; Chen ZY, 2024, INFORM FUSION, V101, DOI 10.1016/j.inffus.2023.101985; Dong L, 2023, J CLEAN PROD, V382, DOI 10.1016/j.jclepro.2022.135270; Du L, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2354; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Oliveira EE, 2023, J INTELL MANUF, V34, P2061, DOI 10.1007/s10845-022-01914-3; Feder A, 2022, T ASSOC COMPUT LING, V10, P1138, DOI 10.1162/tacl_a_00511; Han X, 2022, AI OPEN, V3, P182, DOI 10.1016/j.aiopen.2022.11.003; Hu SD, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2225; Jaimini U, 2022, IEEE INTERNET COMPUT, V26, P43, DOI 10.1109/MIC.2021.3133551; Jiang P., 2023, FINDINGS ASS COMPUTA, P11161, DOI 10.18653/v1/2023.findings-acl; Kiciman E, 2023, Arxiv, DOI arXiv:2305.00050; Kim J., 2023, arXiv, DOI 10.48550/arXiv.2310.11220; Kim L, 2021, COMPUT IND, V132, DOI 10.1016/j.compind.2021.103527; Kuang K, 2020, ENGINEERING-PRC, V6, P253, DOI 10.1016/j.eng.2019.08.016; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li G, 2016, CHEMOMETR INTELL LAB, V159, P1, DOI 10.1016/j.chemolab.2016.09.006; Li SA, 2023, J MANUF SYST, V69, P20, DOI 10.1016/j.jmsy.2023.05.027; Li XY, 2021, COMPUT IND, V129, DOI 10.1016/j.compind.2021.103449; Liu Y, 2023, IEEE T PATTERN ANAL, V45, P11624, DOI 10.1109/TPAMI.2023.3284038; Liu ZY, 2021, J INTELL FUZZY SYST, V41, P4351, DOI 10.3233/JIFS-189695; Lokrantz A, 2018, PROC CIRP, V72, P1057, DOI 10.1016/j.procir.2018.03.229; Lu YQ, 2022, J MANUF SYST, V62, P612, DOI 10.1016/j.jmsy.2022.02.001; Lu YQ, 2020, J MANUF SYST, V56, P312, DOI 10.1016/j.jmsy.2020.06.010; Lyu MT, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101494; Ma QP, 2021, COMPUT IND ENG, V160, DOI 10.1016/j.cie.2021.107580; Madenas N, 2016, INT J ADV MANUF TECH, V84, P1679, DOI 10.1007/s00170-015-7747-1; Martin-Joy J, 2020, DIAGNOSING FROM A DISTANCE: DEBATES OVER LIBEL LAW, MEDIA, AND PSYCHIATRIC ETHICS FROM BARRY GOLDWATER TO DONALD TRUMP, P86, DOI 10.1007/978-3-030-46633-6_5; Martinez-Gil J, 2022, PROCEDIA COMPUT SCI, V200, P944, DOI 10.1016/j.procs.2022.01.292; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Pearl J, 2019, COMMUN ACM, V62, P54, DOI 10.1145/3241036; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Poon H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P689, DOI 10.1109/ICCVW.2011.6130310; Qin K, 2022, CHEMOMETR INTELL LAB, V225, DOI 10.1016/j.chemolab.2022.104559; Russell Matthew, 2024, Journal of Intelligent Manufacturing, V35, P1305, DOI 10.1007/s10845-023-02108-1; Saez MA, 2020, IEEE T AUTOM SCI ENG, V17, P29, DOI 10.1109/TASE.2019.2918562; Schmid M, 2021, IEEE T POWER ELECTR, V36, P2584, DOI 10.1109/TPEL.2020.3012964; Shang HB, 2022, AEROSP SCI TECHNOL, V123, DOI 10.1016/j.ast.2022.107473; Shen XW, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2023.101880; Sim H, 2014, INT J PRECIS ENG MAN, V15, P1563, DOI 10.1007/s12541-014-0505-8; Siriwardhana S, 2023, T ASSOC COMPUT LING, V11, P1, DOI 10.1162/tacl_a_00530; Vashishth S., 2020, INT C LEARN REPR, P1; Veitch V, 2020, PR MACH LEARN RES, V124, P919; Vicuna, An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality-LMSYS Org; Waghen K, 2019, EXPERT SYST APPL, V136, P376, DOI 10.1016/j.eswa.2019.06.042; Wang XZ, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056321; Wang ZX, 2022, ADV ENG INFORM, V54, DOI 10.1016/j.aei.2022.101793; Wei L, 2023, Arxiv, DOI arXiv:2308.12067; Wen L, 2022, J MANUF SYST, V62, P964, DOI 10.1016/j.jmsy.2020.12.002; Xia LQ, 2023, RELIAB ENG SYST SAFE, V232, DOI 10.1016/j.ress.2022.109068; Xia LQ, 2022, J MANUF SYST, V64, P107, DOI 10.1016/j.jmsy.2022.06.002; Xu YD, 2023, INFORM FUSION, V95, P1, DOI 10.1016/j.inffus.2023.02.012; Xu ZG, 2023, INT J PROD RES, V61, P3227, DOI 10.1080/00207543.2022.2078748; Yan RQ, 2020, IEEE SENS J, V20, P8374, DOI 10.1109/JSEN.2019.2949057; Zecevic M., 2023, Transactions on Machine Learning Research, P1; Zeng A., 2023, 11 INT C LEARNING RE, P1; Zheng P, 2021, J MANUF SYST, V61, P16, DOI 10.1016/j.jmsy.2021.08.002; Zheng P, 2019, ADV ENG INFORM, V39, P203, DOI 10.1016/j.aei.2019.01.002; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]; Zhou B, 2022, ADV ENG INFORM, V54, DOI 10.1016/j.aei.2022.101799; Zhou B, 2022, INT J COMPUT INTEG M, V35, P1151, DOI 10.1080/0951192X.2021.1891572; Zhou B, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101441; Zhou B, 2021, ROBOT CIM-INT MANUF, V71, DOI 10.1016/j.rcim.2021.102160; Zhou B, 2020, IEEE INTL CONF IND I, P63, DOI 10.1109/INDIN45582.2020.9442198; Zhou BG, 2024, IEEE REV BIOMED ENG, V17, P4, DOI [10.1109/RBME.2022.3210270, 10.1080/00207543.2021.2022803]; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206	69	1	1	93	93	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1474-0346	1873-5320		ADV ENG INFORM	Adv. Eng. Inform.	JAN	2024	59								102333	10.1016/j.aei.2023.102333	http://dx.doi.org/10.1016/j.aei.2023.102333		JAN 2024	16	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	GN9F3					2024-07-03	WOS:001153460900001
J	Li, MF; Li, X; Hu, MN; Yuan, DY				Li, Mingfeng; Li, Xin; Hu, Mianning; Yuan, Deyu			Research on a Framework for Chinese Argot Recognition and Interpretation by Integrating Improved MECT Models	ENTROPY			English	Article						argot recognition and interpretation; information entropy; semantic space; MECT model; transformer architecture; large language model; prompt engineering; DBSCAN		In underground industries, practitioners frequently employ argots to communicate discreetly and evade surveillance by investigative agencies. Proposing an innovative approach using word vectors and large language models, we aim to decipher and understand the myriad of argots in these industries, providing crucial technical support for law enforcement to detect and combat illicit activities. Specifically, positional differences in semantic space distinguish argots, and pre-trained language models' corpora are crucial for interpreting them. Expanding on these concepts, the article assesses the semantic coherence of word vectors in the semantic space based on the concept of information entropy. Simultaneously, we devised a labeled argot dataset, MNGG, and developed an argot recognition framework named CSRMECT, along with an argot interpretation framework called LLMResolve. These frameworks leverage the MECT model, the large language model, prompt engineering, and the DBSCAN clustering algorithm. Experimental results demonstrate that the CSRMECT framework outperforms the current optimal model by 10% in terms of the F1 value for argot recognition on the MNGG dataset, while the LLMResolve framework achieves a 4% higher accuracy in interpretation compared to the current optimal model.The related experiments undertaken also indicate a potential correlation between vector information entropy and model performance.	[Li, Mingfeng; Li, Xin; Hu, Mianning; Yuan, Deyu] Peoples Publ Secur Univ China, Sch Informat & Network Secur, Beijing 102206, Peoples R China; [Li, Xin; Yuan, Deyu] Minist Publ Secur, Key Lab Secur Prevent Technol & Risk Assessment, Beijing 100038, Peoples R China	People's Public Security University of China; Ministry of Public Security (China)	Li, X (corresponding author), Peoples Publ Secur Univ China, Sch Informat & Network Secur, Beijing 102206, Peoples R China.; Li, X (corresponding author), Minist Publ Secur, Key Lab Secur Prevent Technol & Risk Assessment, Beijing 100038, Peoples R China.	lixin@ppsuc.edu.cn			China University of Political Science and Law (CUPSL) Cybersecurity and Law Enforcement Technology Innovation Project	China University of Political Science and Law (CUPSL) Cybersecurity and Law Enforcement Technology Innovation Project	No Statement Available	Arbelaitz O, 2013, PATTERN RECOGN, V46, P243, DOI 10.1016/j.patcog.2012.07.021; Belkin M, 2006, J MACH LEARN RES, V7, P2399; Bengio Y, 2006, STUD FUZZ SOFT COMP, V194, P137; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; China Internet Network Information Center (CNNIC), 2023, The 51st "China Internet Development Statistics Report", V3, P3; Dhuliawala S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4329; Durrett G., 2017, P 2017 C EMPIRICAL M, DOI [10.18653/v1/d17-1275, DOI 10.18653/V1/D17-1275]; Ester M., 1998, KI Journal of Artificial Intelligence, Special Issue on Data Mining, V12, P18; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507; Fan Y., 2023, Netw. Secur. Technol. Appl; Gui T, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4982; Gui T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1040; Hsiung P., 2004, Ph.D. Thesis; Hu CB, 2023, DECIS SUPPORT SYST, V165, DOI 10.1016/j.dss.2022.113896; Huang H., 2013, P 51 ANN M ASS COMPU, P1083; Ji Heng, 2018, P 1 WORKSH NAT LANG, P23; Jin ZG, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118385; Kolla A, 2023, Arxiv, DOI arXiv:2212.05613; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; [李楠 Li Nan], 2023, [数据分析与知识发现, Data Analysis and Knowledge Discovery], V7, P15; Li X., 2020, P 58 ANN M ASS COMPU, P6836, DOI [DOI 10.18653/V1/2020.ACL-MAIN.611, 10.18653/v1/2020.acl-main.611]; Liu P, 2022, NEUROCOMPUTING, V473, P37, DOI 10.1016/j.neucom.2021.10.101; [罗军舟 Luo Junzhou], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P103; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Ouyang T., 2017, J. Guangxi Police Coll, V30, P74; Ouyang T., 2016, J. Railw. Police Coll, V26, P44, DOI [10.19536/j.cnki.411439.2016.02.010, DOI 10.19536/J.CNKI.411439.2016.02.010]; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Sha Y, 2017, PROCEDIA COMPUT SCI, V108, P48, DOI 10.1016/j.procs.2017.05.106; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI [DOI 10.1002/J.1538-7305.1948.TB01338.X, DOI 10.1002/J.1538-7305.1948.TB00917.X]; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Sun Maosong, 2016, THUCTC: An efficient Chinese text classifier; Sun WW, 2023, Arxiv, DOI arXiv:2304.09542; Torgerson WS, 1952, PSYCHOMETRIKA, V17, P401; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Wang X., 2022, J. People'S Public Secur. Univ. China (Soc. Sci. Ed.), V38, P53; Wilson SR, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4764; WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9; Wu L, 2016, Arxiv, DOI [arXiv:1608.05129, 10.1007/s10579-018-9416-0, DOI 10.1007/S10579-018-9416-0]; Wu S., 2021, arXiv; Xu CW, 2021, Arxiv, DOI arXiv:2104.02704; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; You JR, 2018, LECT NOTES COMPUT SC, V10862, P487, DOI 10.1007/978-3-319-93713-7_44; Yuan K, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1027; Zhang BL, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P586; Zhang BL, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P706; Zhang Y., 2012, Data Anal. Knowl. Discov, V9, P49; Zhang Y, 2018, Arxiv, DOI arXiv:1805.02023; Zhou AY, 2000, J COMPUT SCI TECHNOL, V15, P509, DOI 10.1007/BF02948834	52	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1099-4300		ENTROPY-SWITZ	Entropy	APR	2024	26	4							321	10.3390/e26040321	http://dx.doi.org/10.3390/e26040321			23	Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Physics	OV0V7	38667875	gold, Green Published			2024-07-03	WOS:001209946900001
J	Hellström, T				Hellstrom, Thomas			AI and its consequences for the written word	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						ChatGPT; societal impact; LLM; Large Language Models; AI; human writing; the written word		The latest developments of chatbots driven by Large Language Models (LLMs), more specifically ChatGPT, have shaken the foundations of how text is created, and may drastically reduce and change the need, ability, and valuation of human writing. Furthermore, our trust in the written word is likely to decrease, as an increasing proportion of all written text will be AI-generated - and potentially incorrect. In this essay, I discuss these implications and possible scenarios for us humans, and for AI itself.	[Hellstrom, Thomas] Umea Univ, Dept Comp Sci, Umea, Sweden	Umea University	Hellström, T (corresponding author), Umea Univ, Dept Comp Sci, Umea, Sweden.	thomash@cs.umu.se			Ume Universitet10.13039/501100004885	Ume Universitet10.13039/501100004885	No Statement Available	[Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Bajesy R, 2018, AUTON ROBOT, V42, P177, DOI 10.1007/s10514-017-9615-3; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Canavilhas J, 2022, JOURNAL MEDIA, V3, P510, DOI 10.3390/journalmedia3030035; Carr N, 2008, YEARB NATL SOC STUD, V107, P89, DOI 10.1111/j.1744-7984.2008.00172.x; Carr Nicholas., 2014, The Glass Cage: Automation and Us; Chockley K, 2016, J AM COLL RADIOL, V13, P1415, DOI 10.1016/j.jacr.2016.07.010; Europol, 2022, Facing Reality? Law Enforcement and the Challenge of Deepfakes; Farina M, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1130913; Garner D., 2011, MailOnline; Hellstrom T., 2023, Dagens Nyheter KulturdebattJune 21; Horvitz E., 2022, Proceedings of the 2022 International Conference on Multimodal Interaction; Hu K., 2023, REUTERS, V12; McGlauflin P., 2023, Apple, Goldman Sachs, and Samsung Among Growing List of Companies Banning Employees From Using ChatGPT at Work, yahoo!finance, May 19, 2023; Najjar R, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13172760; Plato, 2009, Phaedrus; Polanyi M., 1958, PERSONAL KNOWLEDGE P; Saetra HS, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102372; Sato Satoshi., 2016, Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation, P31; Scott A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581296; Shumailov I, 2024, Arxiv, DOI [arXiv:2305.17493, DOI 10.48550/ARXIV.2305.17493]; Smith L, 2005, ARTIF LIFE, V11, P13, DOI 10.1162/1064546053278973; Wen X, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100082; Zhou JL, 2023, Arxiv, DOI arXiv:2305.10646	25	0	0	9	9	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	JAN 4	2024	6								1326166	10.3389/frai.2023.1326166	http://dx.doi.org/10.3389/frai.2023.1326166			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	FB9R7	38239498	Green Published, gold			2024-07-03	WOS:001143412200001
J	Mondal, H; Komarraju, S; Sathyanath, D; Muralidharan, S				Mondal, Himel; Komarraju, Satyalakshmi; Sathyanath, D.; Muralidharan, Shrikanth			Assessing the Capability of Large Language Models in Naturopathy Consultation	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						perplexity; claude; large language models; copilot; gemini; chatgpt; referral and consultation; yoga; natural language processing; naturopathy		Background The rapid advancements in natural language processing have brought about the widespread use of large language models (LLMs) across various medical domains. However, their effectiveness in specialized fields, such as naturopathy, remains relatively unexplored. Objective The study aimed to assess the capability of freely available LLM chatbots in providing naturopathy consultations for various types of diseases and disorders. Methods Five free LLMs (viz., Gemini, Copilot, ChatGPT, Claude, and Perplexity) were used to converse with 20 clinical cases (simulation of real -world scenarios). Each case had the case details and questions pertinent to naturopathy. The responses were presented to three naturopathy doctors with > 5 years of practice. The answers were rated by them on a five -point Likert-like scale for language fluency, coherence, accuracy, and relevancy. The average of these four attributes is termed perfection in his study. Results The overall score of the LLMs were Gemini 3.81 +/- 0.23, Copilot 4.34 +/- 0.28, ChatGPT 4.43 +/- 0.2, Claude 3.8 +/- 0.26, and Perplexity 3.91 +/- 0.28 (ANOVA F [3.034, 57.64] = 33.47, P <0.0001. Together, they showed overall similar to 80% perfection in consultation. The average measure intraclass correlation coefficient among the LLMs for the overall score was 0.463 (95% CI = -0.028 to 0.76), P = 0.03. Conclusion Although the LLM chatbots could help in providing naturopathy and yoga treatment consultation with approximately an overall fair level of perfection, their solution to the user varies across different chatbots and there was very low reliability among them.	[Mondal, Himel] All India Inst Med Sci, Physiol, Deoghar, Jharkhand, India; [Komarraju, Satyalakshmi; Sathyanath, D.] Natl Inst Naturopathy, Naturopathy & Yoga, Pune, India; [Muralidharan, Shrikanth] Natl Inst Naturopathy, Res, Pune, India		Muralidharan, S (corresponding author), Natl Inst Naturopathy, Res, Pune, India.	shrikanthmuralidharan23@gmail.com						Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Mehandru N, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01083-y; Mohapatra DP, 2023, INDIAN J PLAST SURG, V56, P413, DOI 10.1055/s-0043-1772704; Mondal H, 2024, Perspect Clin Res., DOI [10.4103/picr.picr27523, DOI 10.4103/PICR.PICR27523]; Mondal H, 2023, INDIAN J VASCULAR EN, V10, P200, DOI 10.4103/ijves.ijves_37_23; Mondal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.48296; Mondal H, 2023, J FAM MED PRIM CARE, V12, P1659, DOI 10.4103/jfmpc.jfmpc_262_23; Pushpanathan K, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.108163; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Roberts RHR, 2024, AESTHET SURG J OPEN, V6, DOI 10.1093/asjof/ojad109; Sarangi PK, 2024, INDIAN J RADIOL IMAG, V34, P269, DOI 10.1055/s-0043-1777289; Tabish Syed Amin, 2008, Int J Health Sci (Qassim), V2, pV; Tan Yang, 2024, Comput Biol Med, V172, P108290, DOI 10.1016/j.compbiomed.2024.108290; Zhang P, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15090286	17	0	0	0	0	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 1	2024	16	5							e59457	10.7759/cureus.59457	http://dx.doi.org/10.7759/cureus.59457			8	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	RX5Q2	38826991				2024-07-03	WOS:001230973900030
C	Azaria, A			IEEE	Azaria, Amos			ChatGPT: More Human-Like Than Computer-Like, but Not Necessarily in a Good Way	2023 IEEE 35TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, ICTAI	Proceedings-International Conference on Tools With Artificial Intelligence		English	Proceedings Paper	35th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)	NOV 06-08, 2023	Atlanta, GA	IEEE, IEEE Comp Soc, Biol & Artificial Intelligence Fdn		Cognitive biases; Rational behavior; ChatGPT	PSYCHOLOGY; FREQUENCY; GAMES; LAW	Large language models have been shown to be useful in multiple domains including conversational agents, education, and explainable AI. ChatGPT is a large language model developed by OpenAI as a conversational agent. ChatGPT was trained on data generated by humans and by receiving human feedback. This training process results in a bias toward humans' traits and preferences. In this paper, we stress multiple biases of ChatGPT, and show that its responses demonstrate many human traits. We begin by showing a very high correlation between the frequency of digits generated by ChatGPT and humans' favorite numbers, with the most frequent digit generated by ChatGPT, matching humans' most favorable number, 7. We continue by showing that ChatGPT's responses in several social experiments are much closer to those of humans' than to those of fully rational agents. Finally, we show that several cognitive biases, known in humans, are also present in ChatGPT's responses.	[Azaria, Amos] Ariel Univ, Sch Comp Sci, Ariel, Israel	Ariel University	Azaria, A (corresponding author), Ariel Univ, Sch Comp Sci, Ariel, Israel.		Azaria, Amos/Y-6302-2019	Azaria, Amos/0000-0002-5057-1309	Ministry of Science, Technology & Space (MOST), Israel	Ministry of Science, Technology & Space (MOST), Israel	This research has been partly supported by the Ministry of Science, Technology & Space (MOST), Israel.	Agranov M, 2015, J ECON SCI ASSOC-JES, V1, P146, DOI 10.1007/s40881-015-0003-5; Allouch M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248448; Amir O, 2005, MARKET LETT, V16, P443, DOI 10.1007/s11002-005-5904-2; Amir O, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0031461; ANDREONI J, 1993, ECON J, V103, P570, DOI 10.2307/2234532; [Anonymous], 1996, The Journal of the American Taxation Association, Vol; Azaria A, 2016, AUTON AGENT MULTI-AG, V30, P486, DOI 10.1007/s10458-015-9297-1; Bellos A., 2015, The grapes of math: How life reflects numbers and numbers reflect life; Buntain C, 2014, AAAI CONF ARTIF INTE, P916; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Durtschi C., 2004, J FORENSIC ACCOUNTIN, V50, P17; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732; Fujiwara Y, 2004, PHYSICA A, V337, P219, DOI 10.1016/j.physa.2004.01.037; Janssen EM, 2020, ACTA PSYCHOL, V206, DOI 10.1016/j.actpsy.2020.103042; Kahneman D., 2011, THINKING; Li W, 2002, GLOTTOMETRICS, V5, P14; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Miller S. J., 2015, Benford's law; Myerson RB, 1999, J ECON LIT, V37, P1067, DOI 10.1257/jel.37.3.1067; Nagel R, 1995, AM ECON REV, V85, P1313; Nowak MA, 2000, SCIENCE, V289, P1773, DOI 10.1126/science.289.5485.1773; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Piantadosi ST, 2014, PSYCHON B REV, V21, P1112, DOI 10.3758/s13423-014-0585-6; Rubinstein A, 2007, ECON J, V117, P1243, DOI 10.1111/j.1468-0297.2007.02081.x; STAHL DO, 1994, J ECON BEHAV ORGAN, V25, P309, DOI 10.1016/0167-2681(94)90103-1; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; TVERSKY A, 1981, SCIENCE, V211, P453, DOI 10.1126/science.7455683; TVERSKY A, 1973, COGNITIVE PSYCHOL, V5, P207, DOI 10.1016/0010-0285(73)90033-9; Tzieropoulos H, 2013, SOC NEUROSCI-UK, V8, P407, DOI 10.1080/17470919.2013.832375; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yi SKM, 2012, COGNITIVE SCI, V36, P452, DOI 10.1111/j.1551-6709.2011.01223.x	32	0	0	14	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		979-8-3503-4273-4	PROC INT C TOOLS ART			2023							468	473		10.1109/ICTAI59109.2023.00074	http://dx.doi.org/10.1109/ICTAI59109.2023.00074			6	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3KO		Green Published			2024-07-03	WOS:001139095400066
J	Zhang, R; Su, YX; Trisedya, BD; Zhao, XY; Yang, M; Cheng, H; Qi, JZ				Zhang, Rui; Su, Yixin; Trisedya, Bayu Distiawan; Zhao, Xiaoyan; Yang, Min; Cheng, Hong; Qi, Jianzhong			AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Learning systems; Knowledge graphs; Vectors; Data models; Task analysis; Attribute embeddings; deep learning; entity alignment; knowledge base; knowledge graph; knowledge graph alignment; large language model; predicate proximity graph; representation learning	WEB	The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods.	[Zhang, Rui] Tsinghua Univ, Beijing 100190, Peoples R China; [Su, Yixin; Qi, Jianzhong] Univ Melbourne, Parkville, Vic 3052, Australia; [Trisedya, Bayu Distiawan] Univ Indonesia, Depok City 16424, West Java, Indonesia; [Zhao, Xiaoyan; Cheng, Hong] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Yang, Min] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China	Tsinghua University; University of Melbourne; University of Indonesia; Chinese University of Hong Kong; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS	Su, YX (corresponding author), Univ Melbourne, Parkville, Vic 3052, Australia.	rayteam@yeah.net; yixin.su@outlook.com; b.distiawan@cs.ui.ac; xzhao@se.cuhk.edu.hk; min.yang@siat.ac.cn; hcheng@se.cuhk.edu.hk; jianzhong.qi@unimelb.edu.au	QI, JIANZHONG/P-7112-2015	QI, JIANZHONG/0000-0001-6501-9050	NSFC	NSFC(National Natural Science Foundation of China (NSFC))	No Statement Available	Ahuja A, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P7, DOI 10.1145/3336191.3371852; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Cao YX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1452; Chen M., 2017, P NIPS WORKSH AUT KN; Chen MH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1511; Ding N., 2021, P INT C LEARN REPR; Fellbaum C, 1998, LANG SPEECH & COMMUN, P1; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao JL, 2022, TSINGHUA SCI TECHNOL, V27, P719, DOI 10.26599/TST.2021.9010056; Hoffart J, 2013, ARTIF INTELL, V194, P28, DOI 10.1016/j.artint.2012.06.001; Hu ZN, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2704, DOI 10.1145/3366423.3380027; Huang Z., 2022, P ANN M ASS COMP LIN; Jiang WK, 2019, IEEE T KNOWL DATA EN, V31, P909, DOI 10.1109/TKDE.2018.2848257; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Li CJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2723; Li J, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P829, DOI 10.1145/3485447.3511926; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Liu WL, 2023, WORLD WIDE WEB, V26, P2215, DOI 10.1007/s11280-022-01134-y; Liu Z., 2020, P C EMP METH NAT LAN; Mangrulkar S, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P41, DOI 10.1145/3487553.3524204; Mao X, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P420, DOI 10.1145/3336191.3371804; Mei X, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116165; Socher R., 2013, ADV NEURAL INFORM PR, V1, P926; Stadler C, 2012, SEMANT WEB, V3, P333, DOI 10.3233/SW-2011-0052; Su YX, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1676, DOI 10.1145/3534678.3539238; Su YX, 2021, AAAI CONF ARTIF INTE, V35, P4357; Sun ZQ, 2020, AAAI CONF ARTIF INTE, V34, P222; Sun ZQ, 2020, PROC VLDB ENDOW, V13, P2326, DOI 10.14778/3407790.3407828; Sun ZQ, 2019, LECT NOTES COMPUT SC, V11778, P612, DOI 10.1007/978-3-030-30793-6_35; Sun ZQ, 2017, LECT NOTES COMPUT SC, V10587, P628, DOI 10.1007/978-3-319-68288-4_37; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Trisedya BD, 2022, IEEE T PATTERN ANAL, V44, P7521, DOI 10.1109/TPAMI.2021.3118703; Trisedya BD, 2020, AAAI CONF ARTIF INTE, V34, P9057; Trisedya BD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P229; Trisedya BD, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1627; Trisedya BD, 2019, AAAI CONF ARTIF INTE, P297; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Wang ZC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P349; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709; Wu Y., 2020, P ANN M ASS COMP LIN; Wu YT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5278; Wu YT, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P240; Xu K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3156; Yang SQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1878; Yang Shiquan, 2021, P INT JOINT C ART IN, P3978; Ye R, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4135; Yun S, 2019, ADV NEUR IN, V32; Zeng WX, 2020, PROC INT CONF DATA, P1870, DOI 10.1109/ICDE48307.2020.00191; Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673; Zhang QH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5429; Zhang R, 2022, VLDB J, V31, P1143, DOI 10.1007/s00778-022-00747-z; Zhang Z., 2020, P INT C COMP LING; Zhao YX, 2023, IEEE T KNOWL DATA EN, V35, P10237, DOI 10.1109/TKDE.2023.3253802; Zhu H, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4258	57	1	1	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUN	2024	36	6					2357	2371		10.1109/TKDE.2023.3325484	http://dx.doi.org/10.1109/TKDE.2023.3325484			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UA9M7		Green Submitted			2024-07-03	WOS:001245459400019
C	Cai, SQ; Venugopalan, S; Tomanek, K; Narayanan, A; Morris, MR; Brenner, MP			ASSOC COMPUTAT LINGUIST	Cai, Shanqing; Venugopalan, Subhashini; Tomanek, Katrin; Narayanan, Ajit; Morris, Meredith Ringel; Brenner, Michael P.			Context-Aware Abbreviation Expansion Using Large Language Models	NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES			English	Proceedings Paper	Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies	JUL 10-15, 2022	Seattle, WA	Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data				Motivated by the need for accelerating text entry in augmentative and alternative communication (AAC) for people with severe motor impairments, we propose a paradigm in which phrases are abbreviated aggressively as primarily word-initial letters. Our approach is to expand the abbreviations into full-phrase options by leveraging conversation context with the power of pretrained large language models (LLMs). Through zero-shot, few-shot, and fine-tuning experiments on four public conversation datasets, we show that for replies to the initial turn of a dialog, an LLM with 64B parameters is able to accurately expand over 70% of phrases with abbreviation length up to 10, leading to an effective keystroke saving rate of up to 77% on these expansions. Including a small amount of context in the form of a single conversation turn more than doubles abbreviation expansion accuracies compared to having no context, an effect that is more pronounced for longer phrases. Additionally, the robustness of the models against typo noise can be enhanced through fine-tuning on noisy data.	[Cai, Shanqing; Venugopalan, Subhashini; Tomanek, Katrin; Narayanan, Ajit; Morris, Meredith Ringel; Brenner, Michael P.] Google Res, Mountain View, CA 94043 USA	Google Incorporated	Cai, SQ (corresponding author), Google Res, Mountain View, CA 94043 USA.	cais@google.com; vsubhashini@google.com	Venugopalan, Subhashini/AAI-8074-2020; Cai, Shanqing/F-6880-2013	Venugopalan, Subhashini/0000-0003-3729-8456; 				Adhikary Jiban, 2021, P 59 ANN M ASS COMP, V1, P6574; Adhikary Jiban, 2019, P 8 WORKSH SPEECH LA, P37; Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; Anjaneyulu Thotapally, 2013, ETC REV GEN SEMANTIC, V70, P141; Austin Jacob, 2021, ARXIV210807732; Azenkot S., 2012, P 14 INT C HUMAN COM, P251, DOI [DOI 10.1145/2371574.2371612, https://doi.org/10.1145/2371574.2371612]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Byrne B., 2019, ARXIV190905358; Caligari M, 2013, AMYOTROPH LAT SCL FR, V14, P546, DOI 10.3109/21678421.2013.803576; Chen MX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/3292500.3330723; Danescu-Niculescu-Mizil Cristian, 2011, Proceedings of the 2nd Workshop on Cognitive Modeling and Computational Linguistics, P76; DEMASCO PW, 1992, COMMUN ACM, V35, P68, DOI 10.1145/129875.129881; Dinan E, 2020, SPRING SER CHALLENGE, P187, DOI 10.1007/978-3-030-29135-8_7; Feit AM, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1118, DOI 10.1145/3025453.3025599; Fowler A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P649, DOI 10.1145/2702123.2702503; Gorman Kyle, 2021, ARXIV211001140; Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057; Kane Shaun, 2017, P CSCW 2017; Kannan A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P955, DOI 10.1145/2939672.2939801; Kristensson P. O., 2012, P S EYE TRACK RES AP, P241, DOI [10.1145/2168556.2168605doi.org/10.1145/2168556.2168605, DOI 10.1145/2168556.2168605DOI.ORG/10.1145/2168556.2168605, 10.1145/2168556.2168605, DOI 10.1145/2168556.2168605]; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lester B., 2021, arXiv; Li Y., 2017, P 8 INT JOINT C NATU, P986; Majaranta P., 2007, TEXT ENTRY SYSTEMS M, P175, DOI DOI 10.1016/B978-012373591-1/50009-7; Mott ME, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2558, DOI 10.1145/3025453.3025517; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pini S., 2010, Proceedings of AVI, P181; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C., 2019, arXiv preprint arXiv:1910.10683; Roller Stephen, 2020, Recipes for building an open-domain chatbot; Ruder Sebastian, 2021, 27 INT C INT US INT; Shazeer N, 2018, PR MACH LEARN RES, V80; Shen Junxiao, 2022, 27 INT C INT US INT, P853, DOI DOI 10.1145/3490099.3511145; Shieber S. M., 2007, Natural Language Engineering, V13, P165, DOI 10.1017/S1351324906004311; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Tobii, 2022, CREAT ABBR EXP COMP; Trnka J, 2008, 25TH DANUBIA-ADRIA SYMPOSIUM ON ADVANCES IN EXPERIMENTAL MECHANICS, P261; Trnka K., 2009, ACM Transactions on Accessible Computing, V1, DOI [DOI 10.1145/1497302.1497307, 10.1145/1497302.1497307]; Vaswani A, 2017, ADV NEUR IN, V30; Vertanen K., 2011, P C EMP METH NAT LAN, P700; Vertanen K, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P347, DOI 10.1145/3132525.3134814; Waller A, 2019, INT J LANG COMM DIS, V54, P159, DOI 10.1111/1460-6984.12449; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Wills J, 2005, ANTIPODE BOOK SER, P1; Wisenburn B, 2008, AUGMENT ALTERN COMM, V24, P100, DOI 10.1080/07434610701740448	46	2	2	0	4	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-71-1				2022							1261	1275						15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9EE					2024-07-03	WOS:000859869501026
J	Pan, SR; Zheng, YZ; Liu, YX; Murugesan, S				Pan, Shirui; Zheng, Yizhen; Liu, Yixin; Murugesan, San			Integrating Graphs With Large Language Models: Methods and Prospects	IEEE INTELLIGENT SYSTEMS			English	Article						Merging; Predictive models; Transformers; Prediction algorithms; Cognition; Task analysis; Intelligent systems		Large language models (LLMs) such as Generative Pre-trained Transformer 4 have emerged as frontrunners, showcasing unparalleled prowess in diverse applications including answering queries, code generation, and more. Parallelly, graph-structured data, intrinsic data types, are pervasive in real-world scenarios. Merging the capabilities of LLMs with graph-structured data has been a topic of keen interest. This article bifurcates such integrations into two predominant categories. The first leverages LLMs for graph learning, where LLMs can not only augment existing graph algorithms but also stand as prediction models for various graph tasks. Conversely, the second category underscores the pivotal role of graphs in advancing LLMs. Mirroring human cognition, we solve complex tasks by adopting graphs in either reasoning or collaboration. Integrating with such structures can significantly boost the performance of LLMs in various complicated tasks. We also discuss and propose open questions for integrating LLMs with graph-structured data for the future direction of the field.	[Pan, Shirui] Griffith Univ, Gold Coast, Qld 4215, Australia; [Zheng, Yizhen; Liu, Yixin] Monash Univ, Melbourne, Vic 3800, Australia; [Pan, Shirui] Griffith Univ, Sch Informat & Commun Technol, Gold Coast, Qld 4215, Australia	Griffith University; Griffith University - Gold Coast Campus; Monash University; Griffith University; Griffith University - Gold Coast Campus	Pan, SR (corresponding author), Griffith Univ, Sch Informat & Commun Technol, Gold Coast, Qld 4215, Australia.	s.pan@griffith.edu.au; san@computer.org	Pan, Shirui/K-6763-2018	Pan, Shirui/0000-0003-0794-527X; Liu, Yixin/0000-0002-4309-5076				Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Chen Z., 2023, P SIGKDD 2023 WORKSH; Chen ZK, 2024, Arxiv, DOI arXiv:2307.03393; Guo JY, 2023, Arxiv, DOI arXiv:2305.15066; He XX, 2024, Arxiv, DOI arXiv:2305.19523; Hong S, 2023, Arxiv, DOI arXiv:2308.00352; Lei B., 2023, arXiv; WEI I, 2022, Advances in Neural Information Processing Systems, V35, P824; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Ye RS, 2024, Arxiv, DOI arXiv:2308.07134	10	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672	1941-1294		IEEE INTELL SYST	IEEE Intell. Syst.	JAN	2024	39	1					64	68		10.1109/MIS.2023.3332242	http://dx.doi.org/10.1109/MIS.2023.3332242			5	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KB8W7		Green Submitted			2024-07-03	WOS:001177602100002
C	Wu, TS; Terry, M; Cai, CJ			ACM	Wu, Tongshuang; Terry, Michael; Cai, Carrie Jun			AI Chains: Transparent and Controllable Human-AI Interaction by Chaining Large Language Model Prompts	PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22)			English	Proceedings Paper	CHI Conference on Human Factors in Computing Systems (CHI)	APR 30-MAY 05, 2022	New Orleans, LA	Assoc Comp Machinery, ACM SIGCHI, Google, Bloomberg, Meta, Microsoft, NSF, Yahoo		Human-AI Interaction; Large Language Models; Natural Language Processing		Although large language models (LLMs) have demonstrated impressive potential on simple tasks, their breadth of scope, lack of transparency, and insufficient controllability can make them less effective when assisting humans on more complex tasks. In response, we introduce the concept of Chaining LLM steps together, where the output of one step becomes the input for the next, thus aggregating the gains per step. We first define a set of LLM primitive operations useful for Chain construction, then present an interactive system where users can modify these Chains, along with their intermediate results, in a modular way. In a 20-person user study, we found that Chaining not only improved the quality of task outcomes, but also significantly enhanced system transparency, controllability, and sense of collaboration. Additionally, we saw that users developed new ways of interacting with LLMs through Chains: they leveraged sub-tasks to calibrate model expectations, compared and contrasted alternative strategies by observing parallel downstream effects, and debugged unexpected model outputs by "unit-testing" sub-components of a Chain. In two case studies, we further explore how LLM Chains may be used in future applications.	[Wu, Tongshuang] Univ Washington, Seattle, WA 98195 USA; [Terry, Michael; Cai, Carrie Jun] Google Res, Mountain View, CA USA	University of Washington; University of Washington Seattle; Google Incorporated	Wu, TS (corresponding author), Univ Washington, Seattle, WA 98195 USA.	wtshuang@cs.washington.edu; michaelterry@google.com; cjcai@google.com						Adhikary Jiban, 2021, P JOINT C 59 ANN M A; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; [Anonymous], A recipe for arbitrary text style transfer with large language models; [Anonymous], 2010, P 23ND ANN ACM S USE, DOI 10.1145/1866029.1866078; [Anonymous], 2014, Proceedings of the 27th annual ACM symposium on User interface software and technology; [Anonymous], 2010, P 23ND ANN ACM S USE, DOI DOI 10.1145/1866029.1866040; [Anonymous], PROMPT DESIGN 101; [Anonymous], GPT 3 IS IDEA MACHIN; Bansal Gagan, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445717; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Betz Gregor, 2021, ARXIV210313033; Bommasani Rishi, 2021, ARXIV210807258CSLG; Branwen G., 2020, Gpt-3 creative fiction; Buschek Daniel, 2021, ARXIV210400358; Cai CJ, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300234; Cai CJ, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3143, DOI 10.1145/2858036.2858237; Cai CarrieJ., 2014, CHI '14 Extended Abstracts on Human Factors in Computing Systems, P2239, DOI DOI 10.1145/2559206.2581183; Cambre J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173868; Carroll J.M., 1988, Handbook of Human-Computer Interaction, P45; Chen Qing, 2021, IEEE T VISUALIZATION; Cheng J, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1365, DOI 10.1145/2702123.2702145; Chilton Lydia B, 2013, P SIGCHI C HUMAN FAC, P1999, DOI DOI 10.1145/2470654.2466265; Chilton Lydia B, 2016, PASO; Clark E, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P329, DOI 10.1145/3172944.3172983; Davis N, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P196, DOI 10.1145/2856767.2856795; Dhariwal P., 2020, Advances in neural information processing systems; Edge D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3169; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gero KI, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300526; Hendrycks Dan., 2020, arXiv preprint arXiv:2009.03300; Holtzman A., 2019, INT C LEARNING REPRE; Huang Cheng-Zhi Anna, 2020, ARXIV201005388; Jiang Ellen, 2021, 34 ANN ACM S US INT; Jozefowicz Rafal, 2016, arXiv preprint arXiv:1602.02410; Kim J, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P233, DOI 10.1145/2998181.2998196; Kittur Aniket, 2011, P 24 ANN ACM S USER, P43, DOI [DOI 10.1145/2047196.2047202, 10.1145/2047196.2047202]; Koch J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300863; Kulkarni Anand Pramod, 2011, WORKSH 25 AAAI C ART; Law Edith, 2011, P 25 AAAI C ART INT; Levy A, 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445522; Lieber Opher, 2021, Technical report; Likert R., 1932, ARCH PSYCHOL, V22 140, P55, DOI DOI 10.4135/9781412961288.N454; Liu Jiachang, 2021, ARXIV210106804; Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739; Lu Yao, 2021, ARXIV210408786; Majaranta P., 2007, TEXT ENTRY SYSTEMS M, P175, DOI DOI 10.1016/B978-012373591-1/50009-7; Mishra Swaroop, 2021, ARXIV210408773; Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240; Narayan Hegde, 2019, NPJ DIGITAL MED, V2; Nushi B, 2017, AAAI CONF ARTIF INTE, P1017; OConnor Joe, 2021, ARXIV210608367; Oh C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174223; Ranzato MarcAurelio, 2016, P INT C LEARN REPR; Retelny Daniela, 2017, Proceedings of the ACM on Human-Computer Interaction, V1, DOI 10.1145/3134724; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rough D, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P169, DOI 10.1145/2598153.2598157; Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Smith-Renner A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376624; Swanson B, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P244; Tan BW, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4313; Teevan Jaime, 2016, P 2016 CHI C HUM FAC, P3500; Thoppilan Romal, 2022, ABS220108239 ARXIV; Vaswani A, 2017, ADV NEUR IN, V30; Verroios Vasilis, 2014, 2 AAAI C HUM COMP CR; Wang Cunxiang, 2021, ARXIV210806743; Wei Jason, 2022, arXiv:2201.11903; Welleck S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5553; Wu T., 2021, P 59 ANN M ASS COMP, V1, P6707, DOI DOI 10.18653/V1/2021.ACL-L0NG.523; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Xie BJ, 2017, ADV HUM-COMPUT INTER, V2017, DOI 10.1155/2017/3683546	71	45	52	8	34	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9157-3				2022										10.1145/3491102.3517582	http://dx.doi.org/10.1145/3491102.3517582			22		Conference Proceedings Citation Index - Science (CPCI-S)		BU6FJ		Bronze, Green Submitted			2024-07-03	WOS:000922929502049
J	Xu, ZY; Xu, HL; Lu, ZY; Zhao, YY; Zhu, R; Wang, YJ; Dong, MZ; Chang, YH; Lv, Q; Dick, RP; Yang, F; Lu, T; Gu, N; Shang, L				Xu, Zhenyu; Xu, Hailin; Lu, Zhouyang; Zhao, Yingying; Zhu, Rui; Wang, Yujiang; Dong, Mingzhi; Chang, Yuhu; Lv, Qin; Dick, Robert P.; Yang, Fan; Lu, Tun; Gu, Ning; Shang, Li			Can Large Language Models Be Good Companions? An LLM-Based Eyewear System with Conversational Common Ground	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						Smart eyewear; large language model; common ground; context-aware		Developing chatbots as personal companions has long been a goal of artificial intelligence researchers. Recent advances in Large Language Models (LLMs) have delivered a practical solution for endowing chatbots with anthropomorphic language capabilities. However, it takes more than LLMs to enable chatbots that can act as companions. Humans use their understanding of individual personalities to drive conversations. Chatbots also require this capability to enable human-like companionship. They should act based on personalized, real-time, and time-evolving knowledge of their users. We define such essential knowledge as the common ground between chatbots and their users, and we propose to build a common-ground-aware dialogue system from an LLM-based module, named OS-1, to enable chatbot companionship. Hosted by eyewear, OS-1 can sense the visual and audio signals the user receives and extract real-time contextual semantics. Those semantics are categorized and recorded to formulate historical contexts from which the user's profile is distilled and evolves over time, i.e., OS-1 gradually learns about its user. OS-1 combines knowledge from real-time semantics, historical contexts, and user-specific profiles to produce a common-ground-aware prompt input into the LLM module. The LLM's output is converted to audio, spoken to the wearer when appropriate. We conduct laboratory and in-field studies to assess OS-1's ability to build common ground between the chatbot and its user. The technical feasibility and capabilities of the system are also evaluated. Our results show that by utilizing personal context, OS-1 progressively develops a better understanding of its users. This enhances user satisfaction and potentially leads to various personal service scenarios, such as emotional support and assistance.	[Xu, Zhenyu; Xu, Hailin; Lu, Zhouyang; Dong, Mingzhi; Chang, Yuhu; Lu, Tun; Gu, Ning; Shang, Li] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China; [Zhao, Yingying] Univ Strathclyde, Dept Comp & Informat Sci, Glasgow, Lanark, Scotland; [Zhu, Rui] City Univ London, Bayes Business Sch, London, England; [Wang, Yujiang] Oxford Suzhou Ctr Adv Res, Suzhou, Peoples R China; [Lv, Qin] Univ Colorado Boulder, Dept Comp Sci, Boulder, CO USA; [Dick, Robert P.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI USA; [Yang, Fan] Fudan Univ, Sch Microelect, Shanghai, Peoples R China	Fudan University; University of Strathclyde; City University London; University of Colorado System; University of Colorado Boulder; University of Michigan System; University of Michigan; Fudan University	Chang, YH; Shang, L (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.	zyxu22@m.fudan.edu.cn; hlxu22@m.fudan.edu.cn; zylu22@m.fudan.edu.cn; yingying.zhao@strath.ac.uk; rui.zhu@city.ac.uk; yujiang.wang@oscar.ox.ac.uk; mingzhidong@gmail.com; yhchang@fudan.edu.cn; qin.lv@colorado.edu; dickrp@umich.edu; yangfan@fudan.edu.cn; lutun@fudan.edu.cn; ninggu@fudan.edu.cn; lishang@fudan.edu.cn						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Aher GV, 2023, INT C MACHINE LEARNI, P337; Ahmad Imtiaz, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415187; Ahn J, 2023, Arxiv, DOI arXiv:2305.17388; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Alibaba Cloud, 2023, Intelligent Speech Interaction for Human-Computer Interaction-Alibaba Cloud-alibabacloud.com; Allport GW, 1927, PSYCHOL BULL, V24, P284, DOI 10.1037/h0073629; Almazrouei Ebtesam, 2023, The falcon series of language models: Towards open frontier models; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], AutoGPT; Bai JZ, 2023, Arxiv, DOI [arXiv:2309.16609, 10.48550/arXiv.2309.16609, DOI 10.48550/ARXIV.2309.16609]; Beltagy I., 2019, arXiv; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Bipat T, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300651; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Calvaresi D, 2021, 2021 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2021), P682, DOI 10.1145/3486622.3493992; Castellano Ginevra, 2008, P 4 INT WORKSH HUM C, P1; Chang YH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1445, DOI 10.1109/ICASSP39728.2021.9414624; Chang YH, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3463509; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen Ching-Han, 2020, 2020 IEEE INT C CONS, P1, DOI [10.1109/ICCETaiwan49838.2020.9258014, DOI 10.1109/ICCETAIWAN49838.2020.9258014]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chu Z, 2023, Arxiv, DOI arXiv:2309.15402; Clark H. H., 1996, USING LANGUAGE, DOI DOI 10.1017/CBO9780511620539; Clark Herbert H, 2006, Concise Encyclopedia of Philosophy of Language and Linguistics (2006), V2006, P85; CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1207/s15516709cog1302_7; Clark L, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300705; Costa J, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P758, DOI 10.1145/2971648.2971752; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Deriu J, 2021, ARTIF INTELL REV, V54, P755, DOI 10.1007/s10462-020-09866-x; Di Lascio E, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P529, DOI 10.1145/3267305.3267316; Dinan E, 2020, SPRING SER CHALLENGE, P187, DOI 10.1007/978-3-030-29135-8_7; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Encode OSS Ltd, 2023, Starlette-starlette.io; Firdaus M, 2023, IEEE T COMPUT SOC SY, V10, P1455, DOI 10.1109/TCSS.2022.3182986; Guydish AJ, 2021, NEW IDEAS PSYCHOL, V63, DOI 10.1016/j.newideapsych.2021.100877; Hoyle R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P571, DOI 10.1145/2632048.2632079; Huang ML, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3383123; Humane, 2024, Humane AI Pin; Kocielnik Rafal, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI DOI 10.1145/3214273; Koelle M, 2018, NORDICHI'18: PROCEEDINGS OF THE 10TH NORDIC CONFERENCE ON HUMAN-COMPUTER INTERACTION, P473, DOI 10.1145/3240167.3240174; Leung SO, 2011, J SOC SERV RES, V37, P412, DOI 10.1080/01488376.2011.580697; Li B, 2023, Arxiv, DOI arXiv:2306.05425; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li MRR, 2019, Arxiv, DOI arXiv:1909.03087; Li YS, 2023, Arxiv, DOI arXiv:2305.06212; Liang Hongru, 2021, arXiv; Liu S, 2023, Arxiv, DOI arXiv:2306.07206; Lv ZX, 2023, SMALL STRUCT, V4, DOI 10.1002/sstr.202300158; Batista-Foguet JM, 2009, PERS INDIV DIFFER, V46, P575, DOI 10.1016/j.paid.2008.12.011; McGaugh JL, 2004, ANNU REV NEUROSCI, V27, P1, DOI 10.1146/annurev.neuro.27.070203.144157; Meta, 2024, Ray-Ban Meta Smart Glasses; Mostafazadeh Nasrin, 2017, arXiv; Motti VG, 2015, LECT NOTES COMPUT SC, V8976, P231, DOI 10.1007/978-3-662-48051-9_17; Myers IB, 1962, The Myers-Briggs Type Indicator: Manual (1962). The Myers-Briggs Type Indicator: Manual (1962); OpenAI, 2022, Introducing chatgpt; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Ozono H, 2022, LECT NOTES COMPUT SC, V13331, P52, DOI 10.1007/978-3-031-05654-3_4; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Pu X, 2023, Arxiv, DOI arXiv:2309.09558; Qi Xiangyao, 2023, P ACM INT MOB WEAR U, V7, P1; Qian C, 2024, Arxiv, DOI arXiv:2307.07924; Qualcomm Technologies Inc, 2023, Qualcomm Snapdragon Wear 4100 Plus Platform | New Smartwatch Processor; Rabbit, 2024, Rabbit; Ram Ashwin, 2018, arXiv; Ramirez Sebastian., 2023, FastAPI-fastapi.tiangolo.com; Redis Ltd, 2023, Redis-redis.io; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Ruensuk M, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3432223; Sebastian G., 2023, Privacy and data protection in chatgpt and other ai chatbots: Strategies for securing user information; Shoji N, 2021, IEEE ICCE, DOI 10.1109/ICCE50685.2021.9427763; Skantze G, 2023, Arxiv, DOI arXiv:2303.11708; Smith Eric Michael, 2022, arXiv; Tang YH, 2023, Arxiv, DOI arXiv:2305.11482; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tugade MM, 2004, J PERS SOC PSYCHOL, V86, P320, DOI 10.1037/0022-3514.86.2.320; USC Bureau, 2010, Frequently occurring surnames from the 2010 census; Venkatesh A., 2017, On evaluating and comparing conversational agents; Wang JG, 2021, INT CONF MANAGE DATA, P2614, DOI 10.1145/3448016.3457550; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wilks Y, 2005, LECT NOTES COMPUT SC, V3361, P36; Wu HP, 2017, J SOC SERV RES, V43, P527, DOI 10.1080/01488376.2017.1329775; Wu Xiaodong, 2023, Journal of Information and Intelligence, V2023; Xi ZH, 2023, Arxiv, DOI arXiv:2309.07864; Xu J, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5180; Xu Xinchao, 2022, arXiv; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Ye QH, 2024, Arxiv, DOI arXiv:2304.14178; Zhang Juzheng, 2016, P 29 INT C COMP AN S, P1; Zhang SZ, 2018, Arxiv, DOI arXiv:1801.07243; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao YY, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3517250; Zhong WJ, 2023, Arxiv, DOI arXiv:2305.10250; Zhou P, 2022, Arxiv, DOI arXiv:2211.09267; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	99	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAY	2024	8	2							87	10.1145/3659600	http://dx.doi.org/10.1145/3659600			41	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	RR2F4		Bronze			2024-07-03	WOS:001229316000046
J	Parker, JL; Richard, VM; Becker, K				Parker, Jessica L.; Richard, Veronica M.; Becker, Kimberly			Flexibility & Iteration: Exploring the Potential of Large Language Models in Developing and Refiining Interview Protocols	QUALITATIVE REPORT			English	Article						large language model; ChatGPT; interview protocol; qualitative methods	QUALITATIVE RESEARCH; ARTIFICIAL-INTELLIGENCE	This article investigates the potential of Large Language Model (LLM) tools like ChatGPT in aiding researchers in the development and refinement of interview protocols. We found that ChatGPT could generate appropriate interview questions, craft key questions, provide feedback on protocols, and simulate interviews, indicating its potential to reduce time and effort, particularly when human resources are limited. This article builds upon previous authors' insights and suggestions regarding developing and refining interview protocols to maximize the chances of achieving research aims, especially for novice researchers. Additionally, the researchers highlight the flexibility of these tools in adapting to different research contexts and cultural considerations. Ethical considerations and human oversight are emphasized as critical components in the responsible implementation of these tools. The research also paves the way for further exploration into the integration of LLMs into other aspects of research processes and offers suggestions for the use of LLMs in interview protocol development and refinement. The findings encourage a broader discussion on the evolving role of technology in academic research and present an exciting avenue for future studies in hybrid human-AI engagements in scholarly pursuits.	[Parker, Jessica L.] Massachusetts Coll Pharm & Hlth Sci, Sch Pharm, Boston, MA 02115 USA; [Richard, Veronica M.] Dissertat Design, Raleigh, NC USA; [Becker, Kimberly] Acad Insight Lab, Raleigh, NC USA		Parker, JL (corresponding author), Massachusetts Coll Pharm & Hlth Sci, Sch Pharm, Boston, MA 02115 USA.	jessica.parker@mcphs.edu; veronica@dissertationbydesign.com; kimberly@academicinsightlab.org						Denzin N.K., 1994, HDB QUALITATIVE RES, V2nd; Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; Brinkman S., 2018, HDB QUALITATIVE INQU, P576; Brinkmann S., 2015, Interviews, V3; Castillo-Montoya M, 2016, QUAL REP, V21, P811; Chenail R.J., 1997, The Qualitative Report, V3, P1, DOI [10.46743/2160-3715/1997.2020, DOI 10.46743/2160-3715/1997.2020]; Christou PA, 2023, QUAL REP, V28, P1968, DOI 10.46743/2160-3715/2023.6406; Creswell J.W., 2018, QUAL INQ, DOI DOI 10.1177/1524839915580941; Cyr AA, 2013, PSYCHON B REV, V20, P574, DOI 10.3758/s13423-012-0357-0; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; DiCicco-Bloom B, 2006, MED EDUC, V40, P314, DOI 10.1111/j.1365-2929.2006.02418.x; Eaton, 2021, Plagiarism in higher education: Tackling tough topics in academic integrity; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Jacob SA, 2012, QUAL REP, V17; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Lennon RP, 2021, FAM MED COMMUNITY HE, V9, DOI 10.1136/fmch-2021-001287; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; McGrath C, 2019, MED TEACH, V41, P1002, DOI 10.1080/0142159X.2018.1497149; Ojeda L, 2011, HISPANIC J BEHAV SCI, V33, P184, DOI 10.1177/0739986311402626; OpenAI, 2023, CHATGPT; Parker J., Journal of Nursing Education; Patton M.Q., 2014, Qualitative Research and Evaluation Methods: Integrating Theory and Practice; Pope C, 2000, BMJ-BRIT MED J, V320, P114, DOI 10.1136/bmj.320.7227.114; Rabionet SE, 2011, QUAL REP, V16, P563; Rahman M., 2023, Journal of Education, Management and Development Studies, V3, P1, DOI [10.52631/jemds.v3i1.175, DOI 10.52631/JEMDS.V3I1.175]; Roberts RE, 2020, QUAL REP, V25, P3185; Roulston Kathryn., 2012, SAGE HDB INTERVIEW R, V2nd, P61, DOI [10.4135/9781452218403.n5, DOI 10.4135/9781452218403.N5]; Rubin H. J., 2011, QUALITATIVE INTERVIE; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Smith JA., 2022, Interpretive phenomenological analysis: Theory, method and research, V2nd; Turner DW III, 2010, QUAL REP, V15, P754; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754	36	2	2	12	12	NOVA SOUTHEASTERN UNIV	FORT LAUDERDALE-DAVIE	3301 COLLEGE AVE, FORT LAUDERDALE-DAVIE, FL 33314 USA	1052-0147	2160-3715		QUAL REP	Qual. Rep.	SEP	2023	28	9					2772	2790		10.46743/2160-3715/2023.6695	http://dx.doi.org/10.46743/2160-3715/2023.6695			21	Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	Z9OS4		gold, Green Published			2024-07-03	WOS:001115307200001
J	Wang, LY; Yang, J; Wang, YS; Qi, Y; Wang, S; Li, J				Wang, Liyan; Yang, Jun; Wang, Yongshan; Qi, Yong; Wang, Shuai; Li, Jian			Integrating Large Language Models (LLMs) and Deep Representations of Emotional Features for the Recognition and Evaluation of Emotions in Spoken English	APPLIED SCIENCES-BASEL			English	Article						spoken English; large language models (LLMs); emotion recognition; emotion evaluation; emotional features		This study is dedicated to developing an innovative method for evaluating spoken English by integrating large language models (LLMs) with effective space learning, focusing on the analysis and evaluation of emotional features in spoken language. Addressing the limitation of current spoken English evaluation software that primarily focuses on acoustic features of speech (such as pronunciation, frequency, and prosody) while neglecting emotional expression, this paper proposes a method capable of deeply recognizing and evaluating emotional features in speech. The core of the method comprises three main parts: (1) the creation of a comprehensive spoken English emotion evaluation dataset combining emotionally rich speech data synthesized using LLMs with the IEMOCAP dataset and student spoken audio; (2) an emotion feature encoding network based on transformer architecture, dedicated to extracting effective spatial features from audio; (3) an emotion evaluation network for the spoken English language that accurately identifies emotions expressed by Chinese students by analyzing different audio characteristics. By decoupling emotional features from other sound characteristics in spoken English, this study achieves automated emotional evaluation. This method not only provides Chinese students with the opportunity to improve their ability to express emotions in spoken English but also opens new research directions in the fields of spoken English teaching and emotional expression evaluation.	[Wang, Liyan] Shaanxi Univ Sci & Technol, Sch Culture & Educ, Xian 710021, Peoples R China; [Yang, Jun; Wang, Yongshan; Qi, Yong; Li, Jian] Shaanxi Univ Sci & Technol, Sch Elect Informat & Artificial Intelligence, Xian 710021, Peoples R China; [Wang, Shuai] Shaanxi Normal Univ, Sch Hist & Civilizat, Xian 710062, Peoples R China	Shaanxi University of Science & Technology; Shaanxi University of Science & Technology; Shaanxi Normal University	Qi, Y (corresponding author), Shaanxi Univ Sci & Technol, Sch Elect Informat & Artificial Intelligence, Xian 710021, Peoples R China.	wangliyan@sust.edu.cn; 211612102@sust.edu.cn; lswx0925@gmail.com; qiyong@sust.edu.cn; wangshuai@snnu.edu.cn; lijianjsj@sust.edu.cn			2018 National Social Science Fund of China's Western Project [18XKG003]; National Social Science Fund of China's Western Project [23Y081]; Shaanxi University of Science and Technology: The Teaching Reform Research Project of Shaanxi University of Science and Technology [GJ22YB09]; Internationalization of Education and Teaching Reform Research Project of Shaanxi University of Science and Technology	2018 National Social Science Fund of China's Western Project; National Social Science Fund of China's Western Project; Shaanxi University of Science and Technology: The Teaching Reform Research Project of Shaanxi University of Science and Technology; Internationalization of Education and Teaching Reform Research Project of Shaanxi University of Science and Technology	Herein, our research team would like to express sincere gratitude for the support and assistance provided by the following projects to this thesis. We are thankful for the 2018 National Social Science Fund of China's Western Project (Project No. 18XKG003), whose funding has facilitated the smooth progress of our research. We are also grateful for the support from two teaching reform projects provided by Shaanxi University of Science and Technology: The Teaching Reform Research Project of Shaanxi University of Science and Technology (Project No. 23Y081) and the Internationalization of Education and Teaching Reform Research Project of Shaanxi University of Science and Technology (Project No. GJ22YB09). The financial and resource support from these projects provided invaluable conditions for the completion of this thesis.	Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6; Chaudhari A, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5040080; Chiorrini A, 2022, INT C PATT RECOG, P1706, DOI 10.1109/ICPR56361.2022.9956403; Du J, 2014, IEEE-ACM T AUDIO SPE, V22, P1601, DOI 10.1109/TASLP.2014.2341912; Ekman Paul, 1999, HDB COGNITION EMOTIO, P45, DOI [DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]; Etienne C, 2018, Arxiv, DOI arXiv:1802.05630; Hu Dou, 2021, arXiv; Islam MR, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152362; Jennings PA, 2009, REV EDUC RES, V79, P491, DOI 10.3102/0034654308325693; Kanluan I., 2008, P 2008 16 EUR SIGN P, P1; Liefooghe B, 2023, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.1092053; Liew TW, 2023, EDUC INF TECHNOL, V28, P1455, DOI 10.1007/s10639-022-11255-6; Liu F., 2021, Adv. Educ. Technol. Psychol, V5, P174; Luna-Jiménez C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010327; Martínez-Miranda J, 2005, COMPUT HUM BEHAV, V21, P323, DOI 10.1016/j.chb.2004.02.010; Melweth H.M.A., 2023, Migr. Lett, V20, P863; Orji FA, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.1015660; Pan B, 2023, NEUROCOMPUTING, V561, DOI 10.1016/j.neucom.2023.126866; Paranjape A., 2023, P 13 WORKSH COMP APP, P558; Patel S, 2011, BIOL PSYCHOL, V87, P93, DOI 10.1016/j.biopsycho.2011.02.010; Sahu G, 2019, Arxiv, DOI arXiv:1904.06022; Shao T., 2021, J. Contemp. Educ. Res, V5, P187, DOI [10.26689/jcer.v5i8.2460, DOI 10.26689/JCER.V5I8.2460]; Siriwardhana S, 2020, IEEE ACCESS, V8, P176274, DOI 10.1109/ACCESS.2020.3026823; Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788; Voloshina Tatiana, 2023, 2023 33rd Conference of Open Innovations Association (FRUCT), P309, DOI 10.23919/FRUCT58615.2023.10143065; Vu T, 2023, Arxiv, DOI arXiv:2305.00769; Wang YY, 2023, FRONT NEUROROBOTICS, V17, DOI 10.3389/fnbot.2023.1181598; Wei S., 2019, Artif. Intell. View, V3, P72; Zaidi SAM, 2023, Arxiv, DOI arXiv:2306.13804; Zhang FH, 2024, TRANS-FORM-ACAO, V47, DOI 10.1590/0101-3173.2024.v47.n4.e0240062	30	0	0	4	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAY	2024	14	9							3543	10.3390/app14093543	http://dx.doi.org/10.3390/app14093543			16	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	QH2L2		gold			2024-07-03	WOS:001219920600001
J	Ferrara, E				Ferrara, Emilio			GenAI against humanity: nefarious applications of generative artificial intelligence and large language models	JOURNAL OF COMPUTATIONAL SOCIAL SCIENCE			English	Article; Early Access						AI; Generative AI; Large Language Models; Risks; Social media		Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs) are marvels of technology; celebrated for their prowess in natural language processing and multimodal content generation, they promise a transformative future. But as with all powerful tools, they come with their shadows. Picture living in a world where deepfakes are indistinguishable from reality, where synthetic identities orchestrate malicious campaigns, and where targeted misinformation or scams are crafted with unparalleled precision. Welcome to the darker side of GenAI applications. This article is not just a journey through the meanders of potential misuse of GenAI and LLMs, but also a call to recognize the urgency of the challenges ahead. As we navigate the seas of misinformation campaigns, malicious content generation, and the eerie creation of sophisticated malware, we'll uncover the societal implications that ripple through the GenAI revolution we are witnessing. From AI-powered botnets on social media platforms to the unnerving potential of AI to generate fabricated identities, or alibis made of synthetic realities, the stakes have never been higher. The lines between the virtual and the real worlds are blurring, and the consequences of potential GenAI's nefarious applications impact us all. This article serves both as a synthesis of rigorous research presented on the risks of GenAI and misuse of LLMs and as a thought-provoking vision of the different types of harmful GenAI applications we might encounter in the near future, and some ways we can prepare for them.	[Ferrara, Emilio] Univ Southern Calif, Thomas Lord Dept Comp Sci, Los Angeles, CA 90007 USA	University of Southern California	Ferrara, E (corresponding author), Univ Southern Calif, Thomas Lord Dept Comp Sci, Los Angeles, CA 90007 USA.	emiliofe@usc.edu		Ferrara, Emilio/0000-0002-1942-2831	University of Southern California [HR001121C0169]; DARPA	University of Southern California; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA))	Work supported in part by DARPA (contract #HR001121C0169).	Baeza-Yates R, 2018, COMMUN ACM, V61, P54, DOI 10.1145/3209581; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Epstein Z, 2023, SCIENCE, V380, P1110, DOI 10.1126/science.adh4451; Ferrara E, 2023, machine learning with applications, V15, DOI [10.1016/j.mlwa.2024.100525, DOI 10.1016/J.MLWA.2024.100525]; Ferrara E., 2023, First Monday, V28; Ferrara E, 2019, COMMUN ACM, V62, P82, DOI 10.1145/3299768; Floridi L, 2019, NAT MACH INTELL, V1, P261, DOI 10.1038/s42256-019-0055-y; Fui-Hoon Nah F, 2023, J. Inf. Technol. Case Appl. Res, V25, P277, DOI [DOI 10.1080/15228053.2023.2233814, 10.1080/15228053.2023.2233814]; Gupta M, 2023, IEEE ACCESS, V11, P80218, DOI 10.1109/ACCESS.2023.3300381; Jagatic TN, 2007, COMMUN ACM, V50, P94, DOI 10.1145/1290958.1290968; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Köbis N, 2021, NAT HUM BEHAV, V5, P679, DOI 10.1038/s41562-021-01128-2; Kshetri N, 2022, COMPUTER, V55, P60, DOI 10.1109/MC.2022.3144763; Mazurczyk W, 2023, Arxiv, DOI arXiv:2306.05569; Menczer F., 2023, Nature Machine Intelligence, V2023, P1; Mozes M, 2023, Arxiv, DOI arXiv:2308.12833; Lara MAR, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32186-3; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Seymour M, 2023, COMMUN ACM, V66, P56, DOI 10.1145/3584973; Shaw A, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adk2031; Sison AJG, 2023, INT J HUM-COMPUT INT, DOI 10.1080/10447318.2023.2225931; Treleaven P., 2023, Social Science Research Network, DOI [10.2139/ssrn.4507244, DOI 10.2139/SSRN.4507244]; von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390; Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559; Yang KC, 2023, Arxiv, DOI arXiv:2307.16336; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	29	2	2	15	15	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2432-2717	2432-2725		J COMPUT SOC SCI	J. Comput. Soc. Sci.	2024 FEB 22	2024										10.1007/s42001-024-00250-1	http://dx.doi.org/10.1007/s42001-024-00250-1		FEB 2024	21	Social Sciences, Mathematical Methods	Emerging Sources Citation Index (ESCI)	Mathematical Methods In Social Sciences	IV1Y4		Green Submitted, hybrid			2024-07-03	WOS:001169032300001
J	Zernikow, J; Grassow, L; Gröschel, J; Henrion, P; Wetzel, PJ; Spethmann, S				Zernikow, Jasmin; Grassow, Leonhard; Groeschel, Jan; Henrion, Philippe; Wetzel, Paul J.; Spethmann, Sebastian			Clinical application of large language models Does ChatGPT replace medical report formulation? An experience report	INNERE MEDIZIN			German	Article; Early Access						Artificial intelligence; Digital transformation; Patient empowerment; ChatGPT; Chatbots		Artificial intelligence (AI)-based language models, such as ChatGPT offer an enormous potential for research and medical care but also for clinical workflow optimization by making medical documentation easier and more efficient in taking over standardized routine tasks. With their ability to guess a text's content using word statistics and thus outputting contextually relevant results in chat dialogues, large language models (LLM) can provide appropriate summaries of medical documentation for different target groups. For instance, text generation in easy to understand language could potentially contribute to an increase in patients' health literacy and, consequently, to increased adherence to treatment. Subsequent, the function of AI-based chatbot models to improve user experiences and enhance competence in the use of AI-based language models will be adressed. Current limitations and chances in creating epicrises are presented as an experience report. In the future, the implementation of local LLMs in medical management systems (hospital information systems, HIS and practice administration systems, PAS) and in conjunction with the electronic patient records (ePA) can fundamentally change clinical and outpatient care.	[Zernikow, Jasmin; Grassow, Leonhard; Groeschel, Jan; Henrion, Philippe; Spethmann, Sebastian] Deutsch Herzzentrum Charite DHZC, Klin Kardiol Angiol & Intens Med, Chariteplatz 1, D-10117 Berlin, Germany; [Zernikow, Jasmin; Groeschel, Jan; Henrion, Philippe; Wetzel, Paul J.; Spethmann, Sebastian] Charite Univ Med Berlin, Berlin, Germany; [Zernikow, Jasmin; Groeschel, Jan; Henrion, Philippe; Wetzel, Paul J.; Spethmann, Sebastian] Free Univ Berlin, Berlin, Germany; [Zernikow, Jasmin; Groeschel, Jan; Henrion, Philippe; Wetzel, Paul J.; Spethmann, Sebastian] Humboldt Univ, Berlin, Germany; [Grassow, Leonhard; Groeschel, Jan; Spethmann, Sebastian] Deutsch Zentrum Herz Kreislauf Forsch e V DZHK, Berlin, Germany; [Grassow, Leonhard; Groeschel, Jan] Charite Univ Med Berlin, Gemeinsame Einrichtung, Expt & Clin Res Ctr, Arbeitsgrp Kardiovask MRT, Berlin, Germany; [Grassow, Leonhard; Groeschel, Jan] Max Delbruck Ctr MDC, Berlin, Germany	Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin	Spethmann, S (corresponding author), Deutsch Herzzentrum Charite DHZC, Klin Kardiol Angiol & Intens Med, Chariteplatz 1, D-10117 Berlin, Germany.	sebastian.spethmann@dhzc-charite.de	Spethmann, Sebastian/AFP-1760-2022	Spethmann, Sebastian/0000-0003-0987-8007				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; bfdi.bund, About us; carbonhealth, About us; Medium, About us; netzpolitik, ABOUT US; openfoam, ABOUT US; Sadasivan SV., 2023, Can AI-generated text be reliably detected? arxiv pre-print server	7	1	1	11	20	SPRINGER MEDIZIN VERLAG GmBH	Berlin	Heidelbergerplatz 3, Berlin, GERMANY	2731-7080	2731-7099		INNERE MED	Innere Med.	2023 OCT 16	2023										10.1007/s00108-023-01600-3	http://dx.doi.org/10.1007/s00108-023-01600-3		OCT 2023	7	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	U7QA7	37843579				2024-07-03	WOS:001086702900001
J	Levine, S; Hausman, K				Levine, Sergey; Hausman, Karol			Using Big Data to Make Robots More Capable	IEEE SPECTRUM			English	Article						Codes; Generative AI; Neural networks; Big Data; Chatbots; Robots; Painting		The generative AI revolution embodied in tools like ChatGPT, Midjourney, and many others is at its core based on a simple formula: Take a very large neural network, train it on a huge dataset scraped from the Web, and then use it to fulfill a broad range of user requests. Large language models (LLMs) can answer questions, write code, and spout poetry, while image-generating systems can create convincing cave paintings or contemporary art.											0	0	0	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0018-9235	1939-9340		IEEE SPECTRUM	IEEE Spectr.	FEB	2024	61	2					42	46		10.1109/MSPEC.2024.10418906	http://dx.doi.org/10.1109/MSPEC.2024.10418906			5	Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	IN8A6					2024-07-03	WOS:001167086900001
C	Shandilya, SK; Prharsha, GSV; Datta, A; Choudhary, G; Park, H; You, I			IEEE	Shandilya, Shishir Kumar; Prharsha, G. S. V.; Datta, Agni; Choudhary, Gaurav; Park, Hoonyong; You, Ilsun			GPT Based Malware: Unveiling Vulnerabilities and Creating a Way Forward in Digital Space	2023 INTERNATIONAL CONFERENCE ON DATA SECURITY AND PRIVACY PROTECTION, DSPP			English	Proceedings Paper	International Conference on Data Security and Privacy Protection (DSPP)	OCT 16-18, 2023	Xian, PEOPLES R CHINA	IEEE, IEEE Comp Soc, NSCLab, Xian ISTC Base Data Secur & Privacy Preservat, State Key Lab Integrated Serv Networks		ChatGPT; Polymorphism; Malware; Large Language Model/s(LLMs)		The rise and development of AI-based solutions like ChatGPT have significantly changed the functioning of many enterprises, organizations, and domains including cybersecurity. The public's open access to ChatGPT and its resources does, however, present significant security challenges. This review study aims to shed light on the emergence of GPT-based malware. As traditional malware detection systems, have advanced to mitigate many sophisticated malware attacks, threat actors are now aiming to utilize GPT and other Large Language Models (LLMs) to create sophisticated tactics to infect systems with new malware. Furthermore, this study seeks to present a select number of methods that may be utilized to reduce the hazards posed by malware developed with ChatGPT and other LLM-based tools.	[Shandilya, Shishir Kumar; Prharsha, G. S. V.; Datta, Agni] VIT Bhopal Univ, Div Cyber Secur & Digital Forens, Bhopal, India; [Choudhary, Gaurav] Univ Southern Denmark, Ctr Ind Software, Sonderborg, Denmark; [Park, Hoonyong] Soonchunhyang Univ, Dept Informat Secur Engn, Asan, South Korea; [You, Ilsun] Kookmin Univ, Dept Informat Secur Cryptol & Math, Seoul, South Korea	VIT Bhopal University; University of Southern Denmark; Soonchunhyang University; Kookmin University	Shandilya, SK (corresponding author), VIT Bhopal Univ, Div Cyber Secur & Digital Forens, Bhopal, India.	shishir.sam@gmail.com; gsvprharsha@gmail.com; agnidatta.org@gmail.com; gac@mmmi.sdu.dk; hoon4569@gmail.com; ilsunu@gmail.com	Choudhary, Gaurav/ADR-6447-2022	Choudhary, Gaurav/0000-0003-3378-2945	Institute of Information & communications Technology Planning & Evaluation (IITP) - Korea government (MSIT) [2020-0-00952]	Institute of Information & communications Technology Planning & Evaluation (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea)	This work was supported by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2020-0-00952, Development of 5G Edge Security Technology for Ensuring 5G+ Service Stability and Availability, 100%)	Addington S., 2023, ChatGPT: Cyber Security Threats and Countermeasures; Bat-Erdene M, 2017, INT J INF SECUR, V16, P227, DOI 10.1007/s10207-016-0330-4; Borana Pramod, 2021, 2021 World Automation Congress (WAC), P21, DOI 10.23919/WAC50355.2021.9559449; Checkpoint Research, 2023, OpwnAI: Cybercriminals Starting to Use ChatGPT; Crowdstrike, 2022, What is a Polymorphic Virus? Detection and Best Practices.; Dai YS, 2018, DIGIT INVEST, V27, P30, DOI 10.1016/j.diin.2018.09.006; Dazed, 2023, What is Worm GPT? The new AI behind the recent wave of cyberattacks; Derner Erik, 2023, arXiv; DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650; Drew J, 2017, EURASIP J INF SECUR, DOI 10.1186/s13635-017-0055-6; Drew J, 2016, 2016 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2016), P81, DOI 10.1109/SPW.2016.30; Fraley JB, 2016, IEEE SOUTHEASTCON; Fritsch Lothar, 2022, An Overview of Artificial Intelligence Used in Malware, DOI [10.1007/978-3-031-17030-0\4, DOI 10.1007/978-3-031-17030-0]; Hyas, 2023, BlackMamba: Research Whitepaper; Kendall K., 2007, Practical malware analysis; McGraw G, 2000, IEEE SOFTWARE, V17, P33, DOI 10.1109/52.877857; OpenAI, 2022, Introducing chatgpt; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sihag V, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/9099476; Singla A, 2021, ASIA CCS'21: PROCEEDINGS OF THE 2021 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P501, DOI 10.1145/3433210.3453082; Souppaya M., 2013, NIST Special Publication, V800, P83, DOI DOI 10.6028/NIST.SP.800-83R1; Wikipedia, G PT-3,Wikipedia, The Free Encyclopedia	22	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0315-5				2023							164	173		10.1109/DSPP58763.2023.10404552	http://dx.doi.org/10.1109/DSPP58763.2023.10404552			10	Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW5VZ					2024-07-03	WOS:001168583200020
C	Poulsen, S; Sarsa, S; Prather, J; Leinonen, J; Becker, BA; Hellas, A; Denny, P; Reeves, BN			Assoc Computing Machinery	Poulsen, Seth; Sarsa, Sami; Prather, James; Leinonen, Juho; Becker, Brett A.; Hellas, Arto; Denny, Paul; Reeves, Brent N.			Solving Proof Block Problems Using Large Language Models	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		AI; algorithms; artificial intelligence; ChatGPT; code generation; generative AI; GPT-3; GPT-4; large language models; OpenAI; Proofs; Proof Blocks		Large language models (LLMs) have recently taken many fields, including computer science, by storm. Most recent work on LLMs in computing education has shown that they are capable of solving most introductory programming (CS1) exercises, exam questions, Parsons problems, and several other types of exercises and questions. Some work has investigated the ability of LLMs to solve CS2 problems as well. However, it remains unclear how well LLMs fare against more advanced upper-division coursework, such as proofs in algorithms courses. After all, while known to be proficient in many programming tasks, LLMs have been shown to have more difficulties in forming mathematical proofs. In this paper, we investigate the ability of LLMs to solve mathematical proofs by using Proof Blocks, a tool previously shown to efficaciously teach proofs to students. Our results show that GPT-3.5 is almost completely unable to provide correct solutions (11.4%), while GPT-4 shows a significant increase in correctness (64.8%). However, even given this improvement, current models still struggle to correctly order lines in a proof. It remains an open question whether this is a temporary situation or if LLMs will continue to struggle to solve these types of exercises in the future.	[Poulsen, Seth] Utah State Univ, Logan, UT 84322 USA; [Sarsa, Sami; Hellas, Arto] Aalto Univ, Espoo, Finland; [Prather, James; Reeves, Brent N.] Abilene Christian Univ, Abilene, TX 79699 USA; [Leinonen, Juho; Denny, Paul] Univ Auckland, Auckland, New Zealand; [Becker, Brett A.] Univ Coll Dublin, Dublin, Ireland	Utah System of Higher Education; Utah State University; Aalto University; Abilene Christian University; University of Auckland; University College Dublin	Poulsen, S (corresponding author), Utah State Univ, Logan, UT 84322 USA.	seth.poulsen@usu.edu; sami.sarsa@aalto.fi; james.prather@acu.edu; juho.leinonen@auckland.ac.n; brett.becker@ucd.ie; arto.hellas@aalto.fi; paul@cs.auckland.ac.nz; brent.reeves@acu.edu	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449; Prather, James/0000-0003-2807-6042; Poulsen, Seth/0000-0001-6284-9972; Reeves, Brent/0000-0001-5781-1136				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2013, Computer Science Curricula 2013: Curriculum Guidelines for Undergraduate Degree Programs in Computer Science; Association for Computing Machinery (ACM) The Joint Task Force on Computing Curricula and IEEE Computer Society, 2016, Technical Report; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Becker Brett A., 2023, Generative AI in Introductory Programming Education; Bird C, 2023, COMMUN ACM, V66, P56, DOI 10.1145/3589996; Brusilovsky Peter, 2023, P 54 ACM TECHNICAL S, DOI [10.1145/3545947.3573353, DOI 10.1145/3545947.3573353]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Cipriano BP, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P61, DOI 10.1145/3587102.3588814; Daun M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P110, DOI 10.1145/3587102.3588815; Denny P, 2024, COMMUN ACM, V67, P56, DOI 10.1145/3624720; Denny P, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P3, DOI 10.1145/3587102.3588773; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Dohmke T, 2023, Arxiv, DOI arXiv:2306.15033; Du YM, 2020, PROCEEDINGS OF THE TWENTY-SECOND AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE'20, P195, DOI 10.1145/3373165.3373187; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Ericson Barbara J., 2022, ITiCSE-WGR '22: Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education, P191, DOI 10.1145/3571785.3574127; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; First E, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428299; Goldman K, 2008, SIGCSE'08: PROCEEDINGS OF THE 39TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P256, DOI 10.1145/1352322.1352226; Hellas A, 2023, Arxiv, DOI arXiv:2306.05715; Kazemitabaar M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580919; Koubaa A., 2023, PREPRINT, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Koutcheme Charles, 2022, P 22 KOLI CALLING IN, DOI [10.1145/3564721.3565955, DOI 10.1145/3564721.3565955]; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; MacNeil S., 2022, P ACM TECHN S COMP S, P1255, DOI DOI 10.1145/3545947.3573358; Messer M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P491, DOI 10.1145/3587102.3588822; Patel Arkil, 2021, PREPRINT; Porter Leo, 2023, Learn AIAssisted Python Programming with GitHub Copilot and ChatGPT; Poulsen Seth, 2023, Artificial Intelligence in Education: 24th International Conference, AIED 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13916), P502, DOI 10.1007/978-3-031-36272-9_41; Poulsen S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P472, DOI 10.1145/3545945.3569797; Poulsen S, 2022, PROCEEDINGS OF THE 27TH ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2022, VOL 1, P428, DOI 10.1145/3502718.3524774; Poulsen S, 2021, ICER 2021: PROCEEDINGS OF THE 17TH ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P157, DOI 10.1145/3446871.3469741; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prather J, 2024, ACM T COMPUT-HUM INT, V31, DOI 10.1145/3617367; Reeves B, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P299, DOI 10.1145/3587102.3588805; Ringer T, 2019, FOUND TRENDS PROGRAM, V5, P102, DOI 10.1561/2500000045; Sanchez-Stern Alex, 2020, Generating Correctness Proofs with Neural Networks, P14; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI arXiv:2306.10073; Stylianides GJ., 2017, COMPENDIUM RES MATH, P237; Sundaram Sowmya S, 2022, arXiv; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Weber K., 2001, EDUCATIONAL STUDIES, V48, P101, DOI [DOI 10.1023/A:1015535614355, 10.1023/A:1015535614355]; Zhang P, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL. 2, P658, DOI 10.1145/3587103.3594202; Zhang SD, 2023, Arxiv, DOI arXiv:2305.04369	49	1	1	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							1063	1069		10.1145/3626252.3630928	http://dx.doi.org/10.1145/3626252.3630928			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP		hybrid			2024-07-03	WOS:001181240800154
J	Li, YM; Li, JF; He, JP; Tao, C				Li, Yiming; Li, Jianfu; He, Jianping; Tao, Cui			AE-GPT: Using Large Language Models to extract adverse events from surveillance reports-A use case with influenza vaccine adverse events	PLOS ONE			English	Article							GUILLAIN-BARRE-SYNDROME; SAFETY	Though Vaccines are instrumental in global health, mitigating infectious diseases and pandemic outbreaks, they can occasionally lead to adverse events (AEs). Recently, Large Language Models (LLMs) have shown promise in effectively identifying and cataloging AEs within clinical reports. Utilizing data from the Vaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study particularly focuses on AEs to evaluate LLMs' capability for AE extraction. A variety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama2, were evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5 model (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match and 0.816 for relaxed match. The encouraging performance of the AE-GPT underscores LLMs' potential in processing medical data, indicating a significant stride towards advanced AE detection, thus presumably generalizable to other AE extraction tasks.	[Li, Yiming; He, Jianping] Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX USA; [Li, Jianfu; Tao, Cui] Mayo Clin, Dept Artificial Intelligence & Informat, Jacksonville, FL 32224 USA	University of Texas System; University of Texas Health Science Center Houston; Mayo Clinic	Tao, C (corresponding author), Mayo Clin, Dept Artificial Intelligence & Informat, Jacksonville, FL 32224 USA.	Tao.Cui@mayo.edu		Tao, Cui/0000-0002-4267-1924	National Institute of Allergy And Infectious Diseases of the National Institutes of Health [R01AI130460, U24AI171008]	National Institute of Allergy And Infectious Diseases of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID))	This article was partially supported by the National Institute of Allergy And Infectious Diseases of the National Institutes of Health under Award Numbers R01AI130460 and U24AI171008. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.	Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; [Anonymous], VAERS-Data; [Anonymous], WHO, Vaccines and immunization; [Anonymous], Wide-ranging Online Data for Epidemiologic Research (CDC WONDER); [Anonymous], OpenAI GPT2; [Anonymous], 2023, Possible Side effects from Vaccines | CDC; [Anonymous], Vaccine Adverse Event Reporting System; Austin J, 2019, LECT NOTES COMPUT SC, V11869, P429, DOI 10.1007/978-3-030-33894-7_47; Babazadeh A, 2019, J TRANSL INTERN MED, V7, P137, DOI 10.2478/jtim-2019-0028; Biswas S., 2023, Prospective role of chat GPT in the military: According to ChatGPT, DOI [10.32388/8WYYOD, DOI 10.32388/8WYYOD]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Budzianowski P., 2019, Towards the Use of Pretrained Language Models for Task-Oriented Dialogue Systems; Centers for Disease Control and Prevention, 2023, Benefits of Flu Vaccination During 2021-2022 Flu Season; Chen J., 2023, When Large Language Models Meet Personalization: Perspectives of Challenges and Opportunities; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Cw A., 2004, Trends in immunology [Internet], V25; Di Renzo L, 2022, VACCINES-BASEL, V10, DOI 10.3390/vaccines10020294; Du JC, 2021, J AM MED INFORM ASSN, V28, P1393, DOI 10.1093/jamia/ocab014; Du JC, 2017, BIOMED INFORM INSIGH, V9, P1, DOI 10.1177/1178222617700627; Du JC, 2016, J BIOMED SEMANT, V7, DOI 10.1186/s13326-016-0056-2; Ferdinands JM, 2021, VACCINE, V39, P3678, DOI 10.1016/j.vaccine.2021.05.011; Fraiman J, 2022, VACCINE, V40, P5798, DOI 10.1016/j.vaccine.2022.08.036; Ghojogh B., 2020, Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey; Gokaslan A., OpenWebText Corpus; Gong Y., 2023, Multilevel Large Language Models for Everyone; Grabenstein JD., 2000, HOSP PHARM, V35, P199; Gringeri M, 2022, EXPERT REV VACCINES, V21, P675, DOI 10.1080/14760584.2022.2044799; Hagendorff T., 2023, MACHINE PSYCHOL INVE; Hou WP, 2023, bioRxiv, DOI [10.1101/2023.03.11.532238, 10.1101/2023.03.11.532238, DOI 10.1101/2023.03.11.532238, 10.1101/2023.03.11.532238v1]; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Imamguluyev R., 2023, Int. J. Res. Public. Rev, V4, P4893, DOI [10.55248/gengpi.2023.4.33987, DOI 10.55248/GENGPI.2023.4.33987]; Koubaa A., 2023, PREPRINT, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Lee JS, 2020, WORLD PAT INF, V62, DOI 10.1016/j.wpi.2020.101983; Li Y., 2023, 2023 IEEE 11 INT C H, P344, DOI [10.1109/ICHI57859.2023.00053, DOI 10.1109/ICHI57859.2023.00053]; Li Y., 2023, JMIR Prepr, DOI [10.2196/preprints.51007, DOI 10.2196/PREPRINTS.51007]; Li Y., 2023, Textbooks Are All You Need II: phi-1.5 technical report; Li YM, 2024, J BIOMED INFORM, V152, DOI 10.1016/j.jbi.2024.104621; Li YM, 2024, EXPERT REV VACCINES, V23, P53, DOI 10.1080/14760584.2023.2292203; Luo CL, 2021, PHARMACOEPIDEM DR S, V30, P602, DOI 10.1002/pds.5196; Machingaidze S, 2021, NAT MED, V27, P1338, DOI 10.1038/s41591-021-01459-7; McNeil MM, 2015, ALERGOL POL, V2, pT37, DOI 10.1016/j.jaci.2015.07.048; Monteith B., 2023, PREPRINT, DOI [10.36227/techrxiv.23291831.v1, DOI 10.36227/TECHRXIV.23291831.V1]; Natuva R., 2023, Indian Journal of Clinical Cardiology; Olmo A., 2021, GPT3-to-plan: Extracting plans from text using GPT-3; Paterson P, 2016, VACCINE, V34, P6700, DOI 10.1016/j.vaccine.2016.10.042; Roumeliotis KI., 2023, Preprints, P2023; Roy K., 2023, Knowledge-Infused Self Attention Transformers; Schneider ETR, 2021, COMP MED SY, P474, DOI 10.1109/CBMS52027.2021.00056; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shimabukuro TT, 2015, VACCINE, V33, P4398, DOI 10.1016/j.vaccine.2015.07.035; STREBEL PM, 1992, CLIN INFECT DIS, V14, P568, DOI 10.1093/clinids/14.2.568; Tarlaci F., 2023, GPT2sQA; Topal MO., Exploring Transformers in Natural Language Generation: GPT, BERT, and XLNet; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Ueda Daiju., 2023, medRxiv; Varricchio F, 2004, PEDIATR INFECT DIS J, V23, P287, DOI 10.1097/00006454-200404000-00002; Vega-Briceno Luis E, 2006, Rev Chilena Infectol, V23, P164; Vellozzi C, 2009, VACCINE, V27, P2114, DOI 10.1016/j.vaccine.2009.01.125; Vijayasarathi M S. A., 2023, Application of ChatGPT in medical science and Research, V3, P1480; Vucic S, 2009, J CLIN NEUROSCI, V16, P733, DOI 10.1016/j.jocn.2008.08.033; Wang DJ, 2012, INFLUENZA OTHER RESP, V6, P159, DOI 10.1111/j.1750-2659.2011.00294.x; Wodi P, 2023, VACCINE, V41, P1616, DOI 10.1016/j.vaccine.2022.12.038; Yu RK, 2006, INFECT IMMUN, V74, P6517, DOI 10.1128/IAI.00967-06	63	1	1	3	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	MAR 21	2024	19	3							e0300919	10.1371/journal.pone.0300919	http://dx.doi.org/10.1371/journal.pone.0300919			16	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	MA1B0	38512919	Green Published, gold, Green Submitted			2024-07-03	WOS:001190798400029
C	Baumann, J; Kramer, O		Smith, S; Correia, J; Cintrano, C		Baumann, Jill; Kramer, Oliver			Evolutionary Multi-objective Optimization of Large Language Model Prompts for Balancing Sentiments	APPLICATIONS OF EVOLUTIONARY COMPUTATION, EVOAPPLICATIONS 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	27th European International Conference on the Applications of Evolutionary Computation (EvoApplications) Held as Part of EvoStar Conference	APR 03-05, 2024	Aberystwyth, WALES					The advent of large language models (LLMs) such as ChatGPT has attracted considerable attention in various domains due to their remarkable performance and versatility. As the use of these models continues to grow, the importance of effective prompt engineering has come to the fore. Prompt optimization emerges as a crucial challenge, as it has a direct impact on model performance and the extraction of relevant information. Recently, evolutionary algorithms (EAs) have shown promise in addressing this issue, paving the way for novel optimization strategies. In this work, we propose a evolutionary multiobjective (EMO) approach specifically tailored for prompt optimization called EMO-Prompts, using sentiment analysis as a case study. We use sentiment analysis capabilities as our experimental targets. Our results demonstrate that EMO-Prompts effectively generates prompts capable of guiding the LLM to produce texts embodying two conflicting emotions simultaneously.	[Baumann, Jill; Kramer, Oliver] Carl Von Ossietzky Univ Oldenburg, Computat Intelligence Lab, Dept Comp Sci, Oldenburg, Germany	Carl von Ossietzky Universitat Oldenburg	Baumann, J (corresponding author), Carl Von Ossietzky Univ Oldenburg, Computat Intelligence Lab, Dept Comp Sci, Oldenburg, Germany.	jill.baumann@uni-oldenburg.de; oliver.kramer@uni-oldenburg.de						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Beume N, 2007, EUR J OPER RES, V181, P1653, DOI 10.1016/j.ejor.2006.08.008; Chen AELC, 2023, Arxiv, DOI arXiv:2302.14838; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Fernando C, 2023, Arxiv, DOI arXiv:2309.16797; Guo QY, 2024, Arxiv, DOI arXiv:2309.08532; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu Xiao, 2023, AI Open; Meyerson E, 2024, Arxiv, DOI [arXiv:2302.12170, 10.48550/arXiv.2302.12170, DOI 10.48550/ARXIV.2302.12170]; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wei J., 2022, Advances in Neural Information Processing Systems, V35, p24 824; Yao Shunyu, 2023, 11 INT C LEARN REPR; Zhou Y., 2023, 11 INT C LEARN REPR	15	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56854-1; 978-3-031-56855-8	LECT NOTES COMPUT SC			2024	14635						212	224		10.1007/978-3-031-56855-8_13	http://dx.doi.org/10.1007/978-3-031-56855-8_13			13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EW		Green Submitted			2024-07-03	WOS:001212344100013
J	Carvalho, I; Ivanov, S				Carvalho, Ines; Ivanov, Stanislav			ChatGPT for tourism: applications, benefits and risks	TOURISM REVIEW			English	Article						ChatGPT; Generative language models; LLMs; Tourism; Chatbots; AI in tourism; Intelligent automation	INTELLIGENCE	Purpose - The rapid growth of artificial intelligence is disrupting various industries, including the tourism sector. This paper aims to outline the applications, benefits and risks of ChatGPT and large language models in general on tourism. It also aims to establish a research agenda for investigating the implications of these models in tourism.Design/methodology/approach - Drawing on the available literature on ChatGPT, large language models and artificial intelligence, the paper identifies areas of application of ChatGPT for several tourism stakeholders. Potential benefits and risks are then considered.Findings - ChatGPT and other similar models are likely to have a profound impact on several tourism processes. They will contribute to further streamline customer service in front-of-house operations and increase productivity and efficiency in back-of-house operations. Although negative consequences for human resources are expected, this technology mostly enhances tourism employees.Originality/value - To the best of the authors' knowledge, this is one of the first studies that explore the potential implications of ChatGPT in tourism and hospitality.	[Carvalho, Ines] Univ Europeia, Fac Social Sci & Technol, Lisbon, Portugal; [Carvalho, Ines] Univ Aveiro, Res Unit Governance Competitiveness & Publ Pol GO, Aveiro, Portugal; [Carvalho, Ines] Univ Lisbon, Inst Social & Polit Sci, Interdisciplinary Ctr fGender Studies CIEG, Lisbon, Portugal; [Ivanov, Stanislav] Varna Univ Management, Bulgaria & ZangadorResearch Inst, Dept Tourism, Varna, Bulgaria	Universidade Europeia; Universidade de Aveiro; Universidade de Lisboa; Varna University of Management	Ivanov, S (corresponding author), Varna Univ Management, Bulgaria & ZangadorResearch Inst, Dept Tourism, Varna, Bulgaria.	ines.carvalho@universidadeeuropeia.pt; stanislav.ivanov@vumk.eu	Buttree, Matthew/JSK-8811-2023; Ivanov, Stanislav Hristov/D-7692-2012; Carvalho, Inês/AAW-2628-2021	Ivanov, Stanislav Hristov/0000-0002-6851-5823; Carvalho, Inês/0000-0003-1372-1299				Ali F., 2023, Journal of Global Hospitality and Tourism, V2, P1, DOI https://doi.org/10.5038/2771-5957.2.1.1016; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bornet P., 2021, Intelligent Automation: Welcome to the World of Hyperautomation: Learn How to Harness Artificial Intelligence to Boost Business Make Our World More Human; Buhalis D, 2022, J HOSP TOUR TECHNOL, V13, P386, DOI 10.1108/JHTT-03-2021-0104; Buhalis D, 2020, TOUR REV, V75, P267, DOI 10.1108/TR-06-2019-0258; Cai DT, 2022, J TRAVEL TOUR MARK, V39, P228, DOI 10.1080/10548408.2022.2061672; Chui M., 2022, GENERATIVE AI HERE T; Cobbe J, 2021, COMPUT LAW SECUR REV, V42, DOI 10.1016/j.clsr.2021.105573; Delouya S., 2022, BUSINESS INSIDER; Frieder S, 2023, ARXIV; Gozalo-Brizuela R., 2023, ARXIV; Grundner L, 2021, J DESTIN MARK MANAGE, V19, DOI 10.1016/j.jdmm.2020.100511; Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459; Hughes A, 2023, SCI FOCUS; ISKENDER A, 2023, ANN ONCOL, V34, P3414, DOI DOI 10.54055/EJTR.V34I.3169; Ivanov S., 2022, ROBONOMICS: The Journal of the Automated Economy, V3, P26; Ivanov S, 2021, J TOUR FUTURES, V9, P214, DOI 10.1108/JTF-02-2023-0038; Ivanov S, 2019, ROBOTS, ARTIFICIAL INTELLIGENCE, AND SERVICE AUTOMATION IN TRAVEL, TOURISM AND HOSPITALITY, P39, DOI 10.1108/978-1-78756-687-320191002; Ivanov SH, 2023, FORESIGHT, V25, P4, DOI 10.1108/FS-09-2021-0183; Karanjai R., 2022, ARXIV; Kim, 2023, BUSINESS INSIDER; Krugel S., 2023, ARXIV; Leung XY, 2020, TOUR REV, V75, P279, DOI 10.1108/TR-06-2019-0229; Ling EC, 2021, PSYCHOL MARKET, V38, P1031, DOI 10.1002/mar.21491; Lins S, 2021, BUS INFORM SYST ENG+, V63, P441, DOI 10.1007/s12599-021-00708-w; Melián-González S, 2021, CURR ISSUES TOUR, V24, P192, DOI 10.1080/13683500.2019.1706457; Min B., 2021, ARXIV; Pillai R, 2020, INT J CONTEMP HOSP M, V32, P3199, DOI 10.1108/IJCHM-04-2020-0259; Schulman J, 2022, Introducing chatgpt; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sorrells M., 2023, TRAVEL WEEKLY; Stack Overflow, 2023, WHY POST GPT CHATGPT; Tussyadiah I, 2020, ANN TOURISM RES, V81, DOI 10.1016/j.annals.2020.102883; van der Aalst WMP, 2021, IJISPM-INT J INF SYS, V9, P5, DOI 10.12821/ijispm090201; Zhuo T.Y., 2023, ARXIV; Zielinski C., 2023, CHATBOTS CHATGPT SCH	36	90	90	205	574	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1660-5373	1759-8451		TOUR REV	Tour. Rev.	FEB 6	2024	79	2					290	303		10.1108/TR-02-2023-0088	http://dx.doi.org/10.1108/TR-02-2023-0088		APR 2023	14	Hospitality, Leisure, Sport & Tourism	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	GJ0B1		Bronze			2024-07-03	WOS:000961061600001
J	Staniek, M; Schumann, R; Züfle, M; Riezler, S				Staniek, Michael; Schumann, Raphael; Zuefle, Maike; Riezler, Stefan			Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								We present Text-to-OverpassQL, a task designed to facilitate a natural language interface for querying geodata from OpenStreetMap (OSM). The Overpass Query Language (OverpassQL) allows users to formulate complex database queries and is widely adopted in the OSM ecosystem. Generating Overpass queries from natural language input serves multiple use-cases. It enables novice users to utilize OverpassQL without prior knowledge, assists experienced users with crafting advanced queries, and enables tool-augmented large language models to access information stored in the OSM database. In order to assess the performance of current sequence generation models on this task, we propose OverpassNL,1 a dataset of 8,352 queries with corresponding natural language inputs. We further introduce task specific evaluation metrics and ground the evaluation of the Text-to-OverpassQL task by executing the queries against the OSM database. We establish strong baselines by finetuning sequence-to-sequence models and adapting large language models with in-context examples. The detailed evaluation reveals strengths and weaknesses of the considered learning strategies, laying the foundations for further research into the Text-to-OverpassQL task.	[Staniek, Michael; Schumann, Raphael; Zuefle, Maike; Riezler, Stefan] Heidelberg Univ, Computat Linguist, Heidelberg, Germany; [Zuefle, Maike] Univ Edinburgh, Sch Informat, Edinburgh, Scotland; [Riezler, Stefan] Heidelberg Univ, IWR, Heidelberg, Germany	Ruprecht Karls University Heidelberg; University of Edinburgh; Ruprecht Karls University Heidelberg	Staniek, M (corresponding author), Heidelberg Univ, Computat Linguist, Heidelberg, Germany.	staniek@cl.uni-heidelberg.de; rschuman@cl.uni-heidelberg.de; zuefle@cl.uni-heidelberg.de; riezler@cl.uni-heidelberg.de			Google Focused Research Award on ''Learning to Negotiate Answers in Multi-Pass Semantic Parsing''	Google Focused Research Award on ''Learning to Negotiate Answers in Multi-Pass Semantic Parsing''	The research reported in this paper was supported by a Google Focused Research Award on ''Learning to Negotiate Answers in Multi-Pass Semantic Parsing''. We also thank Martin Raifer for helping us to acquire queries shared by Over-pass Turbo users.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2005, P 21 C UNCERTAINTY A, DOI DOI 10.3115/1690219.1690283; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Xinyun, 2023, arXiv preprint arXiv:2304.05128; Haas Carolin., 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P740; Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089; Kate R.J., 2005, P 20 NAT C ART INT 1, P1062; Kingma D. P., 2017, ARXIV; Lawrence C., 2016, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: System Demonstrations, P6; Lawrence C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1820; Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468; Lin XV, 2020, Arxiv, DOI arXiv:2012.12627; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Madaan Aman., 2023, arXiv preprint arXiv:2303 .17651; OpenStreetMap Foundation, 2019, Who uses openstreetmap?-openstreetmap; OpenStreetMap Wiki, 2023, Overpass api/ overpass ql-openstreetmap wiki; OpenStreetMap Wiki, 2022, Stats-openstreetmap wiki; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Pourreza Mohammadreza., 2023, 37 C NEURAL INFORM P; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Schick Timo., 2023, 37 C NEURAL INFORM P; Scholak T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9895; Sun Ruoxi., 2023, arXiv preprint arXiv:2306.00739; Tang L.R., 2001, P 12 EUROPEAN C MACH, P466, DOI DOI 10.1007/3-540-44795-4_40; Tao Y., 2021, INT C LEARNING REPRE; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xue LT, 2022, T ASSOC COMPUT LING, V10, P291, DOI 10.1162/tacl_a_00461; Yaghmazadeh N, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133887; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zhang R, C EMPIRICAL METHODS; Zhong VC, 2017, Arxiv, DOI arXiv:1709.00103	35	0	0	1	1	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	APR 30	2024	12						562	575		10.1162/tacl_a_00654	http://dx.doi.org/10.1162/tacl_a_00654			14	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	OP6B8		gold, Green Submitted			2024-07-03	WOS:001208508200003
C	Hong, RX; Zhang, HM; Zhao, H; Yu, D; Zhang, CS		Rogers, A; Boyd-Graber, J; Okazaki, N		Hong, Ruixin; Zhang, Hongming; Zhao, Hong; Yu, Dong; Zhang, Changshui			Faithful Question Answering with Monte-Carlo Planning	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			GO	Although large language models demonstrate remarkable question-answering performances, revealing the intermediate reasoning steps that the models faithfully follow remains challenging. In this paper, we propose FAME (FAithful question answering with MontE-carlo planning) to answer questions based on faithful reasoning steps. The reasoning steps are organized as a structured entailment tree, which shows how premises are used to produce intermediate conclusions that can prove the correctness of the answer. We formulate the task as a discrete decision-making problem and solve it through the interaction of a reasoning environment and a controller. The environment is modular and contains several basic task-oriented modules, while the controller proposes actions to assemble the modules. Since the search space could be large, we introduce a Monte-Carlo planning algorithm to do a look-ahead search and select actions that will eventually lead to highquality steps. FAME achieves advanced performance on the standard benchmark. It can produce valid and faithful reasoning steps compared with large language models with a much smaller model size.	[Hong, Ruixin; Zhao, Hong; Zhang, Changshui] Tsinghua Univ THUAI, Inst Artificial Intelligence, Beijing, Peoples R China; [Hong, Ruixin; Zhao, Hong; Zhang, Changshui] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China; [Hong, Ruixin; Zhao, Hong; Zhang, Changshui] Tsinghua Univ, Dept Automat, Beijing, Peoples R China; [Zhang, Hongming; Yu, Dong] Tencent AI Lab, Seattle, WA USA	Tsinghua University	Hong, RX (corresponding author), Tsinghua Univ THUAI, Inst Artificial Intelligence, Beijing, Peoples R China.; Hong, RX (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.; Hong, RX (corresponding author), Tsinghua Univ, Dept Automat, Beijing, Peoples R China.	hrx20@mails.tsinghua.edu.cn; hongmzhang@tencent.com; dyu@global.tencent.com; zcs@mail.tsinghua.edu.cn	yu, ya dong/KRO-7922-2024		National Key Research and Development Program [2020AAA0107800, 2020GQG0005]	National Key Research and Development Program	We appreciate the anonymous reviewers for their insightful comments. We would like to thank Qihan Liu for the helpful discussions. This work is supported by National Key Research and Development Program (2020AAA0107800) and the Guoqiang Institute of Tsinghua University (2020GQG0005).	Bommasani Rishi, 2021, abs/2108.07258; Bostrom Kaj, 2022, ABS220106028 CORR; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caicedo X, 2010, STUD LOGICA, V94, P189, DOI 10.1007/s11225-010-9230-1; Chaffin A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2953; Cowhey Isaac, 2018, CoRR; Creswell Antonia, 2022, ABS220509712 CORR; Creswell Antonia, 2022, ABS220814271 CORR; Dalvi B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7358; Dalvi Bhavana, 2022, ABS220413074 CORR; GUPTA MM, 1991, FUZZY SET SYST, V40, P431, DOI 10.1016/0165-0114(91)90171-L; He Pengcheng, 2021, CoRR, abs/2111.09543.; Hoffmann Jordan, 2022, ABS220315556 CORR; Hong Ruixin, 2022, FINDINGS ASS COMPUTA, P1887, DOI 10.18653/v1/2022.findings-naacl.145; Huang Yinya, 2022, EMNLP; Kazemi Seyed Mehran, 2022, ABS221213894 CORR; Khot Tushar, 2022, ABS221002406 CORR; Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29; Kojima Takeshi, 2022, CoRR,abs/2205.11916; Kumagai K., 2016, P WORKSH COMP CREAT, P11; Kumagai K, 2018, J ADV COMPUT INTELL, V22, P777, DOI 10.20965/jaciii.2018.p0777; Lamm M, 2021, T ASSOC COMPUT LING, V9, P790, DOI 10.1162/tacl_a_00398; Lampinen Andrew K., 2022, ABS220402329 CORR; Leblond I, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8410; Liu Tengxiao, 2022, ABS221017095 CORR; McCarthy J., 1960, Programs with common sense; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Nakano Reiichiro, 2021, ABS211209332 CORR; Oord A, 2018, ARXIV; Raffel C, 2020, J MACH LEARN RES, V21; Reimers Nils, 2019, IJCNLP; Ribeiro Danilo Neves, 2022, FINDINGS ASS COMPUTA, P465; Rosenthal Sara, 2021, ABS211207772 CORR; Rosin C, 2011, ANN MATH ARTIF INTEL, V61, P203, DOI 10.1007/s10472-011-9258-6; Sanyal S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1075; Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4; Schulman J, 2022, Introducing chatgpt; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Shazeer N, 2018, PR MACH LEARN RES, V80; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Suzgun Mirac, 2022, ABS221009261 CORR; Tafjord Oyvind, 2022, EMNLP; Tafjord Oyvind, 2021, ABS210902593 CORR; Thayaparan Mokanarangan, 2020, ABS201000389 CORR; Wang Xuezhi, 2022, ABS220311171 CORR; Wei Jason, 2022, CoRR, abs/2201.11903.; Wei Jason, 2022, ABS220607682 CORR; Weir Nathaniel, 2022, ABS220907662 CORR; Wiegreffe Sarah, 2021, P NEUR INF PROC SYST; Xie ZN, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5456; Yang Kaiyu, 2022, C EMP METH NAT LANG; Zelikman Eric, 2022, ABS220314465 CORR; Zhou Denny, 2022, ABS220510625 CORR; Zhou Hattie, 2022, ABS221109066 CORR	54	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							3944	3965						22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086802037
J	Mohammadi, H; Ghardallou, W; Brick, E; Mili, A				Mohammadi, Hessam; Ghardallou, Wided; Brick, Elijah; Mili, Ali			On the persistent rumors of the programmer's imminent demise	SOFTWARE AND SYSTEMS MODELING			English	Article						Programming languages; Automatic programming; Programming profession; Large language models		Since the dawn of programming, several developments in programming language design and programming methodology have been hailed as the end of the profession of programmer; they have all proven to be exaggerated rumors, to echo the words attributed to Mark Twain. In this short paper, we ponder the question of whether the emergence of large language models finally realizes these prophecies? Also, we discuss why even if this prophecy is finally realized, it does not change the job of the researcher in programming.	[Mohammadi, Hessam; Brick, Elijah; Mili, Ali] NJIT, CS Dept, Newark, NJ 07102 USA; [Ghardallou, Wided] Univ Sousse, Dept Comp Sci, Rue Khalifa Karoui, Sousse 4000, Tunisia	New Jersey Institute of Technology; Universite de Sousse	Mohammadi, H (corresponding author), NJIT, CS Dept, Newark, NJ 07102 USA.	hm385@njit.edu; wided.ghardallou@gmail.com; eb275@njit.edu; mili@njit.ed						[Anonymous], 1986, The C++ Programming Language; [Anonymous], 1975, The Mythical Man-Month; [Anonymous], 1983, Smalltalk-80: The Interactive Programming Environment; Dreibelbis E., 2023, PC Magazine; Gazzola L, 2019, IEEE T SOFTWARE ENG, V45, P34, DOI 10.1109/TSE.2017.2755013; Ichbiah J.D., 1979, SIGPLAN NOTICES, V14, P1, DOI 10.1145/956650.956651; Leveson NG, 2023, COMMUN ACM, V66, P22, DOI 10.1145/3615860; Meyers PJ., 2020, J COMPUTING SCI COLL, V36, P53, DOI [DOI 10.5555/3447065.3447072, 10.5555/3447065.3447072]; Mohammadi H., 2021, 10 INT C MODEL DATA; Parnas DL., 1985, SOFTWARE ASPECTS STR; REUBENSTEIN HB, 1991, IEEE T SOFTWARE ENG, V17, P226, DOI 10.1109/32.75413; Rich C., 1988, Computer, V21, P10, DOI 10.1109/2.86782; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Yellin DM, 2023, COMMUN ACM, V66, P41, DOI 10.1145/3555367	14	0	0	0	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1619-1366	1619-1374		SOFTW SYST MODEL	Softw. Syst. Model.	DEC	2023	22	6					1969	1976		10.1007/s10270-023-01136-y	http://dx.doi.org/10.1007/s10270-023-01136-y		NOV 2023	8	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CQ8Z9					2024-07-03	WOS:001102406400001
C	Bednár, P; Sarnovsky, M; Vanko, JI			ACM	Bednar, Peter; Sarnovsky, Martin; Vanko, Jakub Ivan			Cognitive Architecture for Process industries	PROCEEDINGS OF 3RD ECLIPSE SECURITY, AI, ARCHITECTURE AND MODELLING CONFERENCE ON CLOUD TO EDGE CONTINUUM, ESAAM 2023			English	Proceedings Paper	3rd Eclipse Security, AI, Architecture and Modelling Conference on Cloud to Edge Continuum (eSAAM)	OCT 17, 2023	Ludwigsburg, GERMANY	Univ Macedonia, Univ Politecnica Madrid, Eclipse Fdn		Data analytics; Ontologies; Large language models		This paper introduces a Cross-Sectorial Big Data Processing platform which provides tools for the semantic modelling of the data analytical processes and for the automatic generation of data analysis scripts for solving the described problems. The main contribution of this paper is the cognitive component for the automatic extraction of the task definition from the narrative description of the problem based on the Large Language Models (LLMs). We have evaluated the proposed method on five problems from the different domains and found that the automatic extraction of the task definition can have promising results that can be applied to full-automatic data analytics.	[Bednar, Peter; Sarnovsky, Martin; Vanko, Jakub Ivan] Tech Univ Kosice, Dept Cybernet & Artificial Intelligence, Kosice, Slovakia	Technical University Kosice	Bednár, P (corresponding author), Tech Univ Kosice, Dept Cybernet & Artificial Intelligence, Kosice, Slovakia.	peter.bednar@tuke.sk; martin.sarnovsky@tuke.sk; jakub.ivan.vanko@tuke.sk	Sarnovsky, Martin/Z-4954-2019	Sarnovsky, Martin/0000-0003-3019-8364	Slovak Scientific Research Grant Agency [1/0685/21]	Slovak Scientific Research Grant Agency	This work was supported by Slovak Scientific Research Grant Agency project no. 1/0685/21.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], Ameco Database; [Anonymous], 2011, Systems and software engineering - Systems and software Quality Requirements and Evaluation (SQuaRE) -System and software quality models; Bednar Peter, 2022, 2022 IEEE 16 INT S A, DOI [10.1109/SACI55618.2022.9919438, DOI 10.1109/SACI55618.2022.9919438]; Clark P. G., 1989, Proceedings of the IEEE 1989 National Aerospace and Electronics Conference NAECON 1989 (Cat. No.89CH2759-9), P1819, DOI 10.1109/NAECON.1989.40462; Ivancáková J, 2018, 2018 IEEE 16TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2018): DEDICATED TO THE MEMORY OF PIONEER OF ROBOTICS ANTAL (TONY) K. BEJCZY, P173, DOI 10.1109/SAMI.2018.8324834; Mackovjak S, 2021, MON NOT R ASTRON SOC, V508, P3111, DOI 10.1093/mnras/stab2536; Mirnig AG., 2015, P 33 ANN ACM C EXTEN, P437, DOI DOI 10.1145/2702613.2732511; Pete C., 2000, Cris. Consort, P76; Sarnovsky M, 2017, IEEE INT CONF INTELL, P187, DOI 10.1109/INES.2017.8118553; Sarnovsky M., 2018, Big Data and Cognitive Computing, V2, P3, DOI DOI 10.3390/BDCC2010003; Sarnovsky M, 2019, PROCESSES, V7, DOI 10.3390/pr7050281; Shearer C., 2000, J. Data Warehous, V5, P13	13	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0835-0				2023							15	20		10.1145/3624486.3624489	http://dx.doi.org/10.1145/3624486.3624489			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GH					2024-07-03	WOS:001147626200003
C	Li, YF; Lin, ZQ; Zhang, SZ; Fu, Q; Chen, B; Lou, JG; Chen, WZ		Rogers, A; Boyd-Graber, J; Okazaki, N		Li, Yifei; Lin, Zeqi; Zhang, Shizhuo; Fu, Qiang; Chen, Bei; Lou, Jian-Guang; Chen, Weizhu			Making Large Language Models Better Reasoners with Step-Aware Verifier	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Few-shot learning is a challenging task that requires language models to generalize from limited examples. Large language models like GPT-3 and PaLM have made impressive progress in this area, but they still face difficulties in reasoning tasks such as GSM8K, a benchmark for arithmetic problems. To improve their reasoning skills, previous work has proposed to guide the language model with prompts that elicit a series of reasoning steps before giving the final answer, achieving a significant improvement on GSM8K from 17.9% to 58.1% in problem-solving rate. In this paper, we present DIVERSE (Diverse Verifier on Reasoning Step), a novel approach that further enhances the reasoning capability of language models. DIVERSE has three main components: first, it generates diverse prompts to explore different reasoning paths for the same question; second, it uses a verifier to filter out incorrect answers based on a weighted voting scheme; and third, it verifies each reasoning step individually instead of the whole chain. We evaluate DIVERSE on the latest language model code-davinci-002 and show that it achieves new state-of-the-art results on six of eight reasoning benchmarks (e.g., GSM8K 74.4%. 83.2%).	[Li, Yifei] Peking Univ, Sch Comp Sci, Natl Key Lab Multimedia Informat Proc, Beijing, Peoples R China; [Li, Yifei; Lin, Zeqi; Zhang, Shizhuo; Fu, Qiang; Chen, Bei; Lou, Jian-Guang; Chen, Weizhu] Microsoft Corp, Redmond, WA 98052 USA; [Li, Yifei] Microsoft Res Asia, Beijing, Peoples R China	Peking University; Microsoft; Microsoft Research Asia; Microsoft	Li, YF (corresponding author), Peking Univ, Sch Comp Sci, Natl Key Lab Multimedia Informat Proc, Beijing, Peoples R China.; Li, YF (corresponding author), Microsoft Corp, Redmond, WA 98052 USA.	yifeili@microsoft.com; zeqi.lin@microsoft.com; v-shizzhang@microsoft.com; qifu@microsoft.com; bei.chen@microsoft.com; jlou@microsoft.com; wzchen@microsoft.com						Andor D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5947; [Anonymous], 2019 C EMP METH NAT; Bauer L, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4220; Bhagavatula Chandra, 2019, Abductive commonsense reasoning; Campagna G, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P122; Chen WH, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1026; Chowdhery A., 2022, ARXIV220402311; Cobbe K., 2021, ARXIV211014168; Creswell Antonia, 2022, Selection-inference: Exploiting large language models for interpretable logical reasoning; Deng X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6112; Ding M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2694; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Feng Yanlin, 2020, SCALABLE MULTIHOP RE; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Geva M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P946; He Junxian, 2022, INT C LEARN REPR; He P, 2020, ICLR; Holtzman Ari, 2021, SURFACE FORM COMPETI; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Hu MH, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1596; Jin W, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2763; Kojima Takeshi, 2022, Large language models are zero-shot reasoners; Koncel-Kedziorski R., 2015, Transactions of the Association for Computational Linguistics, V3, P585, DOI 10.1162/tacla00160; Kundu S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2737; Lampinen Andrew K, 2022, ARXIV220402329; Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627; Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu JY, 2020, EMERG INFECT DIS, V26, P1320, DOI 10.3201/eid2606.200239; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Lu Yao, 2021, FANTASTICALLY ORDERE; Miao SY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P975; Mihaylov T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P821; Min S., 2022, RETHINKING ROLE DEMO; Min Sewon, 2021, MetaICL: Learning to learn in context; Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2080; Pi Xinyu, 2022, ARXIV220111473; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Roy S., 2015, P 2015 C EMPIRICAL M, P1743, DOI DOI 10.18653/V1/D15-1202; Rubin Ohad, 2021, Learning to retrieve prompts for in-context learning; Shen JH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2269; Sinha K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4506; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Wang SY, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1619; Wang X., 2022, OXID MED CELL LONGEV, V2022, P2022; Wang Xiaoyan, 2019, P 33 THIRD AAAI C AR; Wang Xuezhi, 2022, Self-consistency improves chain of thought reasoning in language models; Wei Jason, 2022, arXiv:2201.11903; Xu Yichong, 2021, ARXIV211203254; Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Yoran O, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6016; Yu W., 2020, RECLOR READING COMPR; Zelikman Eric, 2022, ARXIV220314465; Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93; Zhao Tony Z., 2021, Calibrate before use: Improving few-shot performance of language models; Zhou D, 2022, LEAST TO MOST PROMPT; Zhu Fengbin, 2021, Tat-qa: A question answering benchmark on a hybrid of tabular and textual content in finance	60	4	4	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							5315	5333						19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086804013
C	Bhavya, B; Isaza, PT; Deng, Y; Nidd, M; Azad, AP; Shwartz, L; Zhai, CX		Pedrycz, W; Wang, J; He, Y; Dinh, TN; Grant, C; Qiu, M		Bhavya, Bhavya; Isaza, Paulina Toro; Deng, Yu; Nidd, Michael; Azad, Amar Prakash; Shwartz, Larisa; Zhai, ChengXiang			Exploring Large Language Models for Low-Resource IT Information Extraction	2023 23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW 2023	International Conference on Data Mining Workshops		English	Proceedings Paper	23rd IEEE International Conference on Data Mining (IEEE ICDM)	DEC 01-04, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, US National Science Foundation, Technology Innovation Institute, TWO SIGMA		LLM; information extraction; IT domain		Information Extraction (IE) in IT is an important foundational task that is needed for many AIOps applications. A major challenge of IE in IT is that we often do not have sufficient labelled data for training machine learning algorithms since acquiring labels is labor-intensive and costly. In this paper, we propose to leverage Large Language Models (LLMs) to address this challenge of low resources and study two data augmentation strategies, i.e., using LLMs to generate pseudo labels and generate synthetic data. We use multiple IE tasks and datasets, including a new Semantic Troubleshooting-Segment Extraction task and Named Entity Recognition, to evaluate the benefits of LLMs. Our experiment results suggest that data augmentation using LLMs, specifically, using SeqMix model that combines active labeling with synthetic data samples generated in the embedding-vector space, is a promising approach for IT domain IE. Our study also shows that although data augmentation and direct labeling with the state-of-the-art, ChatGPT model achieves a high performance on general domain IE, there is a need to adapt it for IE from IT text data. Moreover, our initial exploration of two label weighting and selection strategies (confidence and consistency-based) suggests that they could be used to improve data augmentation with ChatGPT for IT domain IE. Finally, we also suggest directions for future research on the new STSE task, including developing better evaluation metrics.	[Bhavya, Bhavya; Zhai, ChengXiang] Univ Illinois, Champaign, IL USA; [Isaza, Paulina Toro; Deng, Yu; Shwartz, Larisa] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA; [Nidd, Michael] IBM Res Europe, Ruschlikon, Switzerland; [Azad, Amar Prakash] IBM Res India, Gurgaon, India	University of Illinois System; University of Illinois Urbana-Champaign; International Business Machines (IBM)	Bhavya, B (corresponding author), Univ Illinois, Champaign, IL USA.	bhavya2@illinois.edu; ptoroisaza@ibm.com; dengy@us.ibm.com; mni@zurich.ibm.com; amarazad@in.ibm.com; lshwart@us.ibm.com; czhai@illinois.edu			IBM-Illinois Discovery Accelerator Institute (IIDAI)	IBM-Illinois Discovery Accelerator Institute (IIDAI)	This work is supported in part by the IBM-Illinois Discovery Accelerator Institute (IIDAI).	Agrawal M, 2022, Arxiv, DOI arXiv:2205.12689; Baker C.F., 1998, P 36 ANN M ASS COMP, P86, DOI DOI 10.3115/980845.980860; Bogatinovski J, 2021, Arxiv, DOI arXiv:2101.06054; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chauhan K, 2020, Arxiv, DOI arXiv:2005.11055; Clark S., 2003, Proceedings of the seventh conference on Natural language learning at HLT-NAACL 2003-Volume 4, CONLL'03, P49; Cunha W, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P665, DOI 10.1145/3539618.3591638; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doelitzscher F, 2013, INT CONF CLOUD COMP, P387, DOI 10.1109/CloudCom.2013.57; Du M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1285, DOI 10.1145/3133956.3134015; Finkel J. R., 2009, P 2009 C EMPIRICAL M, P141; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Gulenko A, 2020, IEEE IC COMP COM NET, DOI 10.1109/icccn49398.2020.9209606; Gupta A., 2018, P 27 INT C COMP LING, P3251; Honovich O., 2022, arXiv; Jiang ZX, 2021, MOBILE NETW APPL, V26, P2353, DOI 10.1007/s11036-021-01832-3; Khot T, 2022, Arxiv, DOI arXiv:2210.02406; Li B, 2023, Arxiv, DOI arXiv:2304.11633; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu XT, 2021, LECT NOTES COMPUT SC, V12632, P150, DOI 10.1007/978-3-030-76352-7_18; Lu Yao, 2021, arXiv; Yoo KM, 2021, Arxiv, DOI arXiv:2104.08826; Mohit B., 2014, Natural language processing of semitic languages, P221; Nguyen B., 2007, Lit. Rev. Lang. Stat., V2, P1; Notaro P, 2021, LECT NOTES COMPUT SC, V12632, P110, DOI 10.1007/978-3-030-76352-7_15; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Raffel C, 2020, J MACH LEARN RES, V21; Rizve M, 2021, Arxiv, DOI arXiv:2101.06329; Sahu G., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.01959; Sang EF, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195; Sarawagi S, 2007, FOUND TRENDS DATABAS, V1, P261, DOI 10.1561/1500000003; Sellam T, 2020, Arxiv, DOI arXiv:2004.04696; Settles B., 2009, ACTIVE LEARNING LIT; Tabassum J, 2020, Arxiv, DOI arXiv:2005.01634; Vaswani A, 2017, ADV NEUR IN, V30; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wei TW, 2021, Arxiv, DOI arXiv:2103.10682; Wu L, 2021, LECT NOTES COMPUT SC, V12632, P85, DOI 10.1007/978-3-030-76352-7_13; Yang Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199691; Zhang RZ, 2020, Arxiv, DOI arXiv:2010.02322; Zhang RX, 2020, Arxiv, DOI arXiv:2002.01861; Zhang Yu, 2022, 2022 IEEE International Conference on Big Data (Big Data), P4792, DOI 10.1109/BigData55660.2022.10020770; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	47	0	0	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2375-9232		979-8-3503-8164-1	INT CONF DAT MIN WOR			2023							1203	1212		10.1109/ICDMW60847.2023.00157	http://dx.doi.org/10.1109/ICDMW60847.2023.00157			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5OA					2024-07-03	WOS:001164077500148
C	Zhou, X; Kim, K; Xu, BW; Liu, JK; Han, D; Lo, D			IEEE	Zhou, Xin; Kim, Kisub; Xu, Bowen; Liu, Jiakun; Han, DongGyun; Lo, David			The Devil is in the Tails: How Long-Tailed Code Distributions Impact Large Language Models	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc				Learning-based techniques, especially advanced Large Language Models (LLMs) for code, have gained considerable popularity in various software engineering (SE) tasks. However, most existing works focus on designing better learning-based models and pay less attention to the properties of datasets. Learning-based models, including popular LLMs for code, heavily rely on data, and the data's properties (e.g., data distribution) could significantly affect their behavior. We conducted an exploratory study on the distribution of SE data and found that such data usually follows a skewed distribution (i.e., long-tailed distribution) where a small number of classes have an extensive collection of samples, while a large number of classes have very few samples. We investigate three distinct SE tasks and analyze the impacts of long-tailed distribution on the performance of LLMs for code. Our experimental results reveal that the long-tailed distribution has a substantial impact on the effectiveness of LLMs for code. Specifically, LLMs for code perform between 30.0% and 254.0% worse on data samples associated with infrequent labels compared to data samples of frequent labels. Our study provides a better understanding of the effects of long-tailed distributions on popular LLMs for code and insights for the future development of SE automation.	[Zhou, Xin; Kim, Kisub; Xu, Bowen; Liu, Jiakun; Lo, David] Singapore Management Univ, Singapore, Singapore; [Xu, Bowen] North Carolina State Univ, Raleigh, NC USA; [Han, DongGyun] Royal Holloway Univ London, London, England	Singapore Management University; North Carolina State University; University of London; Royal Holloway University London	Kim, K (corresponding author), Singapore Management Univ, Singapore, Singapore.	xinzhou.2020@phdcs.smu.edu.sg; kisubkim@smu.edu.sg; bowenxu.2017@phdcs.smu.edu.sg; jkliu@smu.edu.sg; donggyun.han@rhul.ac.uk; davidlo@smu.edu.sg	BOWEN, XU/AGF-1611-2022; Lo, David/A-2493-2012	Lo, David/0000-0002-4367-7201	National Research Foundation, Singapore, under its Industry Alignment Fund -Pre-positioning (IAF-PP) Funding Initiative	National Research Foundation, Singapore, under its Industry Alignment Fund -Pre-positioning (IAF-PP) Funding Initiative(National Research Foundation of Korea)	This research/project is supported by the National Research Foundation, Singapore, under its Industry Alignment Fund -Pre-positioning (IAF-PP) Funding Initiative. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore.	Alshammari S, 2022, PROC CVPR IEEE, P6887, DOI 10.1109/CVPR52688.2022.00677; [Anonymous], 2006, The Long Tail. Why the future of business is selling less of more; Benni KE, 2018, IEEE T SOFTWARE ENG, V44, P534, DOI 10.1109/TSE.2017.2731766; Borges H, 2016, PROC IEEE INT CONF S, P334, DOI 10.1109/ICSME.2016.31; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brynjolfsson E, 2003, MANAGE SCI, V49, P1580, DOI 10.1287/mnsc.49.11.1580.20580; Cabral GG, 2019, PROC INT CONF SOFTW, P666, DOI 10.1109/ICSE.2019.00076; Chen Y, 2020, IEEE WORK CONF MIN S, P32, DOI 10.1145/3379597.3387461; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Crammer K, 2002, J MACH LEARN RES, V2, P265, DOI 10.1162/15324430260185628; Croft R., 45 IEEE ACM INT C SO; Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949; Dabic O, 2021, IEEE WORK CONF MIN S, P560, DOI 10.1109/MSR52588.2021.00074; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dowd M., 2006, The Art of Software Security Assessment: Identifying and Preventing Software Vulnerabilities; Ebert F, 2018, PROC IEEE INT CONF S, P519, DOI 10.1109/ICSME.2018.00061; Elahi G, 2010, REQUIR ENG, V15, P41, DOI 10.1007/s00766-009-0090-z; Feng S, 2021, INFORM SOFTWARE TECH, V129, DOI 10.1016/j.infsof.2020.106432; Feng Z., 2020, ser. Findings of ACL, VEMNLP; Fenton NE, 2000, IEEE T SOFTWARE ENG, V26, P797, DOI 10.1109/32.879815; Fowkes J, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P254, DOI 10.1145/2950290.2950319; Gini C., 1912, VARIABILITA MUTABILI; Gu XD, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P631, DOI 10.1145/2950290.2950334; Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550; Hanson S., 1988, Advances in neural information processing systems, V1; Hastie T, 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, V2; López JAH, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556900; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Huang C, 2020, IEEE T PATTERN ANAL, V42, P2781, DOI 10.1109/TPAMI.2019.2914680; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Irsan I. C., 2023, 30 IEEE INT C SOFTW; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Jiang WX, 2023, PROC INT CONF SOFTW, P2463, DOI 10.1109/ICSE48619.2023.00206; Jiarpakdee J, 2020, EMPIR SOFTW ENG, V25, P3590, DOI 10.1007/s10664-020-09848-1; Johnson B, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P672, DOI 10.1109/ICSE.2013.6606613; Kamei Y, 2016, EMPIR SOFTW ENG, V21, P2072, DOI 10.1007/s10664-015-9400-x; Ko Y, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1029; Kochhar P. S., 2016, P 25 INT S SOFTWARE, P165; Le XBD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P163, DOI 10.1145/3180155.3182536; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Liu SQ, 2023, PROC INT CONF SOFTW, P2476, DOI 10.1109/ICSE48619.2023.00207; Liu ZX, 2020, IEEE INT CONF AUTOM, P585, DOI 10.1145/3324884.3416581; Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264; Lopes CV, 2015, ACM SIGPLAN NOTICES, V50, P675, DOI [10.1145/2858965.2814300, 10.1145/2814270.2814300]; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Martin J, 2022, INT C PROGRAM COMPRE, P321, DOI 10.1145/3524610.3527872; Martins P, 2018, IEEE WORK CONF MIN S, P1, DOI 10.1145/3196398.3196450; mitre, 2022, 2022 cwe top 25 most dangerous software weaknesses; Niu CG, 2023, PROC INT CONF SOFTW, P2136, DOI 10.1109/ICSE48619.2023.00180; Overflow S, Stack Exchange Dumps; Öztürk MM, 2017, INFORM SOFTWARE TECH, V92, P17, DOI 10.1016/j.infsof.2017.07.004; Pan SY, 2023, PROC INT CONF SOFTW, P957, DOI 10.1109/ICSE48619.2023.00088; python, 2023, difflib, a library to extract the token-level edits.; Sharma Tushar, 2021, arXiv, DOI 10.48550/ARXIV.2110.09610; Shi Ensheng, 2022, P 2022 C EMPIRICAL M, P5520; Shi JK, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556964; Shirky C, 2003, Power Laws, Weblogs, and Inequality; Sutskever I, 2014, ADV NEUR IN, V27; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27; Tan M, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P99, DOI 10.1109/ICSE.2015.139; Thong Hoang, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P34, DOI 10.1109/MSR.2019.00016; Thongtanunam P, 2022, PROC INT CONF SOFTW, P237, DOI 10.1145/3510003.3510067; Tufano R, 2022, PROC INT CONF SOFTW, P2291, DOI 10.1145/3510003.3510621; Tufano R, 2021, PROC INT CONF SOFTW, P163, DOI 10.1109/ICSE43902.2021.00027; Turner D., 2008, Symantec global internet security threat report trends for July-December 07, Vxii, P1; Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914; Nguyen VA, 2022, PROC IEEE ACM INT C, P178, DOI [10.1109/ICSE-Companion55297.2022.9793807, 10.1145/3510454.3516865]; Wang S, 2013, IEEE T RELIAB, V62, P434, DOI 10.1109/TR.2013.2259203; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Watson C, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3485275; Yang L, 2022, INT J COMPUT VISION, V130, P1837, DOI 10.1007/s11263-022-01622-8; Yang Z, 2022, PROC INT CONF SOFTW, P1482, DOI 10.1145/3510003.3510146; Zhou JY, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P705, DOI 10.1109/ASE51524.2021.9678720; Zhou X, 2021, PROC IEEE INT CONF S, P425, DOI 10.1109/ICSME52107.2021.00044; Zhou Y., 2019, Advances in neural information processing systems, V32; Zhou YQ, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3468854; Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236	79	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							40	52		10.1109/ASE56229.2023.00157	http://dx.doi.org/10.1109/ASE56229.2023.00157			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200004
C	Kim, M; Hwang, K; Oh, H; Kim, H; Kim, MA			ACM	Kim, Mirae; Hwang, Kyubum; Oh, Hayoung; Kim, Heejin; Kim, Min Ah			Can a Chatbot be Useful in Childhood Cancer Survivorship? Development of a Chatbot for Survivors of Childhood Cancer	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Retrieval-Based Model; Large Language Model; Domain-Adaptive Training; Childhood Cancer Survivors		This study introduces an informational and empathetic chatbot for childhood cancer survivors. As the survival rates for childhood cancer around the world have increased, survivors often face various psychosocial challenges during and after cancer treatment. However, they rarely seek support from psychosocial professionals due to the low availability of resources and stigma toward cancer survivors in countries like South Korea. This study aimed to develop a chatbot tailed to the unique characteristics of childhood cancer survivors in need of informational and emotional support. Given the limited availability of empirical data on childhood cancer survivors, quotes from survivors were gathered from academic articles and social media, then large language models were employed to generate appropriate responses. Furthermore, we incorporated domain learning techniques to ensure a more tailored and suitable model for addressing the needs of survivors.	[Kim, Mirae; Hwang, Kyubum; Oh, Hayoung; Kim, Heejin; Kim, Min Ah] Sungkyunkwan Univ, Seoul, South Korea	Sungkyunkwan University (SKKU)	Oh, H (corresponding author), Sungkyunkwan Univ, Seoul, South Korea.	miraekiim@gmail.com; bany981111@gmail.com; hyoh79@skku.edu; heejinkim990717@gmail.com; minahkim@skku.edu		Kim, Mirae/0009-0000-3763-1189; KIM, MIN AH/0000-0002-7420-4116; Hwang, Kyubum/0009-0009-5803-0214	National Research Foundation of Korea (NRF) - Korean government (MSIT) [NRF-2022R1F1A1074696]; Technology Innovation Program (Industrial Strategic Technology Development Program-Source Technology Development and Commercialization of Digital Therapeutics) - Ministry of Trade, Industry & Energy(MOTIE, Korea) [20014967]; AI Convergence Research Fund, Sungkyunkwan University, 2023; SMC-SKKU Future Convergence Research Program Grant	National Research Foundation of Korea (NRF) - Korean government (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Technology Innovation Program (Industrial Strategic Technology Development Program-Source Technology Development and Commercialization of Digital Therapeutics) - Ministry of Trade, Industry & Energy(MOTIE, Korea); AI Convergence Research Fund, Sungkyunkwan University, 2023; SMC-SKKU Future Convergence Research Program Grant	This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korean government (MSIT) (No. NRF-2022R1F1A1074696), the Technology Innovation Program (or Industrial Strategic Technology Development Program-Source Technology Development and Commercialization of Digital Therapeutics) (20014967, Development of Digital Therapeutics for Depression from COVID19) funded by the Ministry of Trade, Industry & Energy(MOTIE, Korea), AI Convergence Research Fund, Sungkyunkwan University, 2023 and SMC-SKKU Future Convergence Research Program Grant.	Ah Kim，Min, 2021, [Health and Social Welfare Review, 보건사회연구], V41, P130, DOI 10.15709/hswr.2021.41.3.130; AH KIM， MIN, 2014, [Mental Health & Social Work, 정신건강과 사회복지], V42, P121; AH KIM， MIN, 2012, Child Health Nursing Research, V18, P19; Greer S, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/15018; Gururangan S., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2004.10964; Ham J, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P422; Healthcare Media HiDoc, US; Humeau Samuel, 2019, ARXIV190501969, DOI [10.48550/arXiv.1905.01969, DOI 10.48550/ARXIV.1905.01969]; Junbum L., 2020, ANN C HUMAN LANGUAGE, P437; Korea Association for Children with Leukemia and Cancer, US; Korea Childhood Leukemia Foundation, US; Lown EA, 2015, PEDIATR BLOOD CANCER, V62, pS531, DOI 10.1002/pbc.25783; Ministry of Health and Welfare, 2019, NAT CANC REG PRIJ AN; National Cancer Information Center, about us; Park Sungjoon, 2021, ARXIV210509680, DOI [10.48550/arXiv.2105.09680, DOI 10.48550/ARXIV.2105.09680]; Prasad M, 2021, PEDIATR BLOOD CANCER, V68, DOI 10.1002/pbc.29248; Sharma A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5263; Tai W, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1433; Tawfik E, 2023, BMC NURS, V22, DOI 10.1186/s12912-023-01243-7; 임수진, 2020, [Journal of the Korea Convergence Society, 한국융합학회논문지], V11, P361, DOI 10.15207/JKCS.2020.11.3.361; 최권호, 2018, [Health and Social Welfare Review, 보건사회연구], V38, P417, DOI 10.15709/hswr.2018.38.2.417	21	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							4018	4022		10.1145/3583780.3615234	http://dx.doi.org/10.1145/3583780.3615234			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549504012
J	Tan, SY; Guo, YL				Tan, Suyan; Guo, Yilin			A study of the impact of scientific collaboration on the application of Large Language Model	AIMS MATHEMATICS			English	Article						scientific collaboration; Large Language Model application; financial support; dominant countries; heterogeneity		The study of Large Language Models (LLMs), as an interdisciplinary discipline involving multiple fields such as computer science, artificial intelligence, and linguistics, has diverse collaborations within its field. In this study, papers related to LLMs in the SSCI and SCI subcollections of the Web of Science core database from January 2020 to April 2024 are selected, and a mixed linear regression model is used to assess the impact of scientific collaborations on the application of LLMs. On this basis, the paper further considers factors such as financial support and dominant countries to deeply explore the heterogeneous impact of scientific collaborations on the application of LLMs. The findings show that (1) excessive involvement of academic institutions limits the research and application of LLMs, and the number of authors does not have a significant effect on the application of LLMs; (2) with or without financial support, the role played by scientific collaborations in the application of LLMs does not significantly change; and (3) differences in the dominant countries of scientific collaborations have a slightly heterogeneous effect on the role of LLMs applications, which are mainly reflected in the number of collaborators.	[Tan, Suyan; Guo, Yilin] Guangzhou Univ, Sch Foreign Studies, Guangzhou 510006, Guangdong, Peoples R China	Guangzhou University	Tan, SY (corresponding author), Guangzhou Univ, Sch Foreign Studies, Guangzhou 510006, Guangdong, Peoples R China.	sfstansuyan@gzhu.edu.cn			National Social Science Fund Project "Research on Cognitive Load in User Experience of College English Cloud Platform" [22BYY094]; Guangdong Postgraduate Education Innovation Project "Research on Innovative Mode of Postgraduate Moral Education Empowered by Information Technology" [2023JGXM_098]; Project of Philosophy and Social Sciences Planning of Guangdong Province [GD23WZXC01-13]	National Social Science Fund Project "Research on Cognitive Load in User Experience of College English Cloud Platform"; Guangdong Postgraduate Education Innovation Project "Research on Innovative Mode of Postgraduate Moral Education Empowered by Information Technology"; Project of Philosophy and Social Sciences Planning of Guangdong Province	This research was funded by the National Social Science Fund Project "Research on Cognitive Load in User Experience of College English Cloud Platform" (22BYY094) , the Guangdong Postgraduate Education Innovation Project "Research on Innovative Mode of Postgraduate Moral Education Empowered by Information Technology" (2023JGXM_098) , the Project of Philosophy and Social Sciences Planning of Guangdong Province (GD23WZXC01-13) .	Ali S, 2024, GENES-BASEL, V15, DOI 10.3390/genes15010025; Amin K, 2023, YALE J BIOL MED, V96, P407, DOI 10.59249/NKOY5498; Cai RA, 2024, SCIENTOMETRICS, DOI 10.1007/s11192-024-04974-9; Danquah MM, 2024, INF DISCOV DELIV, DOI 10.1108/IDD-11-2022-0122; Divito CB, 2024, MED TEACH, V46, P320, DOI 10.1080/0142159X.2023.2290997; Dotan E, 2024, BIOINFORMATICS, V40, DOI 10.1093/bioinformatics/btae196; Gao Y, 2024, NATL ACCOUNT REV, V6, P195, DOI 10.3934/NAR.2024009; Griewing S, 2023, J PERS MED, V13, DOI 10.3390/jpm13101502; Guleria A, 2023, J INFECT DEV COUNTR, V17, P1292, DOI 10.3855/jidc.18738; Gyamerah SA, 2024, GREEN FINANC, V6, P78, DOI 10.3934/GF.2024004; Indran IR, 2023, MED TEACH, DOI 10.1080/0142159X.2023.2294703; Kauf C, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13386; Kjell ONE, 2024, PSYCHIAT RES, V333, DOI 10.1016/j.psychres.2023.115667; Kohus Z, 2022, PUBLICATIONS-BASEL, V10, DOI 10.3390/publications10040035; Laios A, 2023, CANCER CONTROL, V30, DOI 10.1177/10732748231197915; Leng LG, 2024, MED EDUC ONLINE, V29, DOI 10.1080/10872981.2024.2304973; Li Z., 2024, Borsa Istanb. Rev., DOI [10.1016/j.bir.2024.04.016, DOI 10.1016/J.BIR.2024.04.016]; Li ZH, 2024, INT REV ECON FINANC, V92, P1526, DOI 10.1016/j.iref.2024.02.080; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Luo S, 2024, NATL ACCOUNT REV, V6, P172, DOI 10.3934/NAR.2024008; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Mannam SS, 2023, WORLD NEUROSURG, V180, pE765, DOI 10.1016/j.wneu.2023.10.043; Mestiri S, 2024, DATA SCI FINANC ECON, V4, P236, DOI 10.1109/ACCESS.2018.2887138; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Schillinger D, 2021, HEALTH SERV RES, V56, P132, DOI 10.1111/1475-6773.13560; Shin H, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271678; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Theodorou P, 2024, DATA SCI FINANC ECON, V4, P53, DOI 10.3934/DSFE.2024002; Tsai ML, 2023, EDUC CHEM ENG, V44, P71, DOI 10.1016/j.ece.2023.05.001; Wang TC, 2024, QUANT FINANC ECON, V8, P1, DOI 10.3934/QFE.2024001; Wang YM, 2023, QUANT FINANC ECON, V7, P569, DOI 10.3934/QFE.2023028; Wen YX, 2023, AIMS MATH, V8, P24825, DOI 10.3934/math.20231266; Williams Z, 2024, GREEN FINANC, V6, P265, DOI 10.3934/GF.2024011; Xu BB, 2024, EXPERT SYST APPL, V249, DOI 10.1016/j.eswa.2024.123810	34	0	0	1	1	AMER INST MATHEMATICAL SCIENCES-AIMS	SPRINGFIELD	PO BOX 2604, SPRINGFIELD, MO 65801-2604, UNITED STATES		2473-6988		AIMS MATH	AIMS Math.		2024	9	7								10.3934/math.2024963	http://dx.doi.org/10.3934/math.2024963			19	Mathematics, Applied; Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	UO8A1		gold			2024-07-03	WOS:001249078500001
J	Rahimzadeh, V; Kostick-Quenet, K; Barby, JB; McGuire, AL				Rahimzadeh, Vasiliki; Kostick-Quenet, Kristin; Barby, Jennifer Blumenthal; McGuire, Amy L.			Ethics Education for Healthcare Professionals in the Era of chatGPT and Other Large Language Models: Do We Still Need It?	AMERICAN JOURNAL OF BIOETHICS			English	Article						chatGPT; bioethics; medical education; healthcare professionals	MEDICAL-ETHICS; COMPASSION	In this paper, we contend with whether we still need traditional ethics education as part of healthcare professional training given the abilities of chatGPT (generative pre-trained transformer) and other large language models (LLM). We reflect on common programmatic goals to assess the current strengths and limitations of LLMs in helping to build ethics competencies among future clinicians. Through an actual case analysis, we highlight areas in which chatGPT and other LLMs are conducive to common bioethics education goals. We also comment on where such technologies remain an imperfect substitute for human-led ethics teaching and learning. Finally, we conclude that the relative strengths of chatGPT warrant its consideration as a teaching and learning tool in ethics education in ways that account for current limitations and build in flexibility as the technology evolves.	[Rahimzadeh, Vasiliki; Kostick-Quenet, Kristin; Barby, Jennifer Blumenthal; McGuire, Amy L.] Baylor Coll Med, Houston, TX 77046 USA	Baylor College of Medicine	Rahimzadeh, V (corresponding author), Baylor Coll Med, Houston, TX 77046 USA.	Vasiliki.Rahimzadeh@bcm.edu	Kostick-Quenet, Kristin/JMR-0618-2023; Rahimzadeh, Vasiliki/JXX-9772-2024	Kostick, Kristin/0000-0003-2510-0174; Blumenthal-Barby, Jennifer/0000-0003-1054-619X; McGuire, Amy/0000-0002-7819-519X; Rahimzadeh, Vasiliki/0000-0003-3537-7601				Ames M. G., 2023, ALGORITHMIC MODERNIT; [Anonymous], 2022, MLQ 1215; Asch D.A., 2023, NEJM Cat, V4, P1, DOI DOI 10.1056/CAT.23.0043; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baylor College of Medicine Center for Medical Ethics and Health Policy, ETH WORK; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Burns R, 2019, J STUD FINANC AID, V48; Campbell AV, 2007, MED TEACH, V29, P431, DOI 10.1080/01421590701504077; Carrese JA, 2015, ACAD MED, V90, P744, DOI 10.1097/ACM.0000000000000715; Cohen IG., 2023, SSRN Journal, DOI [10.2139/ssrn.4430100, DOI 10.2139/SSRN.4430100]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; CULVER CM, 1985, NEW ENGL J MED, V312, P253, DOI 10.1056/NEJM198501243120430; de la Garza S, 2017, ACAD PSYCHIATR, V41, P520, DOI 10.1007/s40596-016-0608-x; DuBois JM, 2002, ACAD MED, V77, P432, DOI 10.1097/00001888-200205000-00019; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eckles RE, 2005, ACAD MED, V80, P1143, DOI 10.1097/00001888-200512000-00020; Fasser C., 2007, J PHYS ASSIST ED, V18, P34, DOI [10.1097/01367895-200718010-00006, DOI 10.1097/01367895-200718010-00006]; FOX E, 1995, ACAD MED, V70, P761, DOI 10.1097/00001888-199509000-00011; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goldie J, 2000, MED EDUC, V34, P108, DOI 10.1046/j.1365-2923.2000.00607.x; Gonzales AL, 2020, COMMUN RES, V47, P750, DOI 10.1177/0093650218796366; Han Z., 2023, MEDRXIV, DOI [10.1101/2023.02.13.23285879, DOI 10.1101/2023.02.13.23285879]; Ignatowicz A, 2023, J MED ETHICS, V49, P136, DOI 10.1136/medethics-2021-107966; Johnson D., 2023, IN PRESS, DOI [10.21203/rs.3.rs-2566942/v1, DOI 10.21203/RS.3.RS-2566942/V1]; Kharya P., 2021, NVIDIA TECHNICA 1011; Kostick-Quenet KM, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00737-z; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Leget C, 2007, J MED ETHICS, V33, P617, DOI 10.1136/jme.2006.017772; Li J., 2023, CHATGPT HEALTHCARE T, DOI DOI 10.1101/2023.03.30.23287899; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Metz C., 2023, New York Times; MILES SH, 1989, ACAD MED, V64, P705, DOI 10.1097/00001888-198912000-00004; [Obeso V. Association of American Medical Colleges Association of American Medical Colleges], 2017, Core Entrustable Professional Activities for Entering Residency: Toolkits for the 13 Core EPAs - Abridged; OpenAI, 2023, GPT 4 BILL HLTH EX I; Pierson L., 2022, ETHICS ED US MEDICAL; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Suguri Motoki F. Y., 2023, SSRN ELECT J, DOI DOI 10.2139/SSRN.4372349; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Vk A., 2023, ANAL INDIA MAGA 0219; Wear D, 2008, J GEN INTERN MED, V23, P948, DOI 10.1007/s11606-007-0501-0; Webber KL, 2022, J HIGH EDUC-UK, V93, P934, DOI 10.1080/00221546.2022.2044976	45	17	17	79	120	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1526-5161	1536-0075		AM J BIOETHICS	Am. J. Bioeth.	OCT 3	2023	23	10					17	27		10.1080/15265161.2023.2233358	http://dx.doi.org/10.1080/15265161.2023.2233358		JUL 2023	11	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	U2KH6	37487184	hybrid			2024-07-03	WOS:001035978100001
J	Song, HF; Xia, Y; Luo, ZC; Liu, H; Song, Y; Zeng, X; Li, TJ; Zhong, GX; Li, JX; Chen, M; Zhang, GY; Xiao, B				Song, Haifeng; Xia, Yi; Luo, Zhichao; Liu, Hui; Song, Yan; Zeng, Xue; Li, Tianjie; Zhong, Guangxin; Li, Jianxing; Chen, Ming; Zhang, Guangyuan; Xiao, Bo			Evaluating the Performance of Different Large Language Models on Health Consultation and Patient Education in Urolithiasis	JOURNAL OF MEDICAL SYSTEMS			English	Article						Urolithiasis; Health consultation; Large language model; ChatGPT; Artificial intelligence		ObjectivesTo evaluate the effectiveness of four large language models (LLMs) (Claude, Bard, ChatGPT4, and New Bing) that have large user bases and significant social attention, in the context of medical consultation and patient education in urolithiasis.Materials and methodsIn this study, we developed a questionnaire consisting of 21 questions and 2 clinical scenarios related to urolithiasis. Subsequently, clinical consultations were simulated for each of the four models to assess their responses to the questions. Urolithiasis experts then evaluated the model responses in terms of accuracy, comprehensiveness, ease of understanding, human care, and clinical case analysis ability based on a predesigned 5-point Likert scale. Visualization and statistical analyses were then employed to compare the four models and evaluate their performance.ResultsAll models yielded satisfying performance, except for Bard, who failed to provide a valid response to Question 13. Claude consistently scored the highest in all dimensions compared with the other three models. ChatGPT4 ranked second in accuracy, with a relatively stable output across multiple tests, but shortcomings were observed in empathy and human caring. Bard exhibited the lowest accuracy and overall performance. Claude and ChatGPT4 both had a high capacity to analyze clinical cases of urolithiasis. Overall, Claude emerged as the best performer in urolithiasis consultations and education.ConclusionClaude demonstrated superior performance compared with the other three in urolithiasis consultation and education. This study highlights the remarkable potential of LLMs in medical health consultations and patient education, although professional review, further evaluation, and modifications are still required.	[Song, Haifeng; Luo, Zhichao; Liu, Hui; Zeng, Xue; Li, Tianjie; Zhong, Guangxin; Li, Jianxing; Xiao, Bo] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Urol, 168 Litang Rd, Beijing 102218, Peoples R China; [Song, Haifeng; Luo, Zhichao; Liu, Hui; Zeng, Xue; Li, Tianjie; Zhong, Guangxin; Li, Jianxing; Xiao, Bo] Tsinghua Univ, Inst Urol, Sch Clin Med, Beijing 102218, Peoples R China; [Xia, Yi; Chen, Ming; Zhang, Guangyuan] Southeast Univ, Zhongda Hosp, Dept Urol, 87 Dingjiaqiao, Nanjing 210009, Peoples R China; [Xia, Yi] Southeast Univ, Sch Med, Nanjing 210009, Peoples R China; [Song, Yan] China Med Univ, Urol Dept, Sheng Jing Hosp, Shenyang 110000, Peoples R China	Tsinghua University; Tsinghua University; Southeast University - China; Southeast University - China; China Medical University	Xiao, B (corresponding author), Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Dept Urol, 168 Litang Rd, Beijing 102218, Peoples R China.; Xiao, B (corresponding author), Tsinghua Univ, Inst Urol, Sch Clin Med, Beijing 102218, Peoples R China.; Zhang, GY (corresponding author), Southeast Univ, Zhongda Hosp, Dept Urol, 87 Dingjiaqiao, Nanjing 210009, Peoples R China.	shf1990@hotmail.com; xiayi11105110@163.com; 704690975@qq.com; lha00112@btch.edu.cn; Alexander-song@163.com; cengx12@tsinghua.org.cn; 873424932@qq.co; photons93@163.com; lijianxing2015@163.com; chenmingseu@126.com; zgy0879@qq.com; beidaxiaobo@163.com	Li, Jianxing/F-4253-2016; Luo, Zhi-Chao/F-4439-2010; Zhang, Guangyuan/AAD-5494-2020	Zhang, Guangyuan/0009-0009-1728-770X				Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Anderson LM, 2003, AM J PREV MED, V24, P68, DOI 10.1016/S0749-3797(02)00657-8; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Baatiah NY, 2020, UROL ANNALS, V12, P57, DOI 10.4103/UA.UA_13_19; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Croft P, 2015, BMC MED, V13, DOI 10.1186/s12916-014-0265-4; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; Digital The Lancet., 2023, Lancet Digit Health, V5, DOI DOI 10.1016/S2589-7500(23)00023-7; Geraghty RM, 2023, EUR UROL FOCUS, V9, P199, DOI 10.1016/j.euf.2022.06.014; Görtz M, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231173304; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; Raheem OA, 2017, EUR UROL FOCUS, V3, P18, DOI 10.1016/j.euf.2017.04.001; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.02.23285399; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zeng GH, 2022, UROLITHIASIS, V51, DOI 10.1007/s00240-022-01387-2; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	25	6	6	18	51	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	NOV 24	2023	47	1							125	10.1007/s10916-023-02021-3	http://dx.doi.org/10.1007/s10916-023-02021-3			9	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	AR2O0	37999899	Green Submitted			2024-07-03	WOS:001120123600001
C	Chen, YZ; Ding, ZJ; Alowain, L; Chen, XY; Wagner, D			ACM	Chen, Yizheng; Ding, Zhoujie; Alowain, Lamya; Chen, Xinyun; Wagner, David			DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection	PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON RESEARCH IN ATTACKS, INTRUSIONS AND DEFENSES, RAID 2023			English	Proceedings Paper	26th International Symposium on Research in Attacks, Intrusions and Defenses (RAID)	OCT 16-18, 2023	Hong Kong, HONG KONG	Blocksec Inc, KAUST, Resilient Comp & Cybersecur Ctr		datasets; vulnerability detection; deep learning; large language models		We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 18,945 vulnerable functions spanning 150 CWEs and 330,492 non-vulnerable functions extracted from 7,514 commits. Our dataset covers 295 more projects than all previous datasets combined. Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities. We study 11 model architectures belonging to 4 families. Our results showthat deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonstrate an important generalization challenge for the deployment of deep learning-based models. We show that increasing the volume of training data may not further improve the performance of deep learning models for vulnerability detection, but might be useful to improve the generalization ability to unseen projects. We also identify hopeful future research directions. We demonstrate that large language models (LLMs) are a promising research direction for ML-based vulnerability detection, outperforming Graph Neural Networks (GNNs) with code-structure features in our experiments. Moreover, developing source code specific pre-training objectives is a promising research direction to improve the vulnerability detection performance.	[Chen, Yizheng] Univ Maryland, Baltimore, MD 21201 USA; [Ding, Zhoujie; Wagner, David] Univ Calif Berkeley, Berkeley, CA USA; [Alowain, Lamya] King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia; [Chen, Xinyun] Google Deepmind, London, England	University System of Maryland; University of Maryland Baltimore; University of California System; University of California Berkeley; King Abdulaziz City for Science & Technology; Google Incorporated	Chen, YZ (corresponding author), Univ Maryland, Baltimore, MD 21201 USA.	yzchen@umd.edu; zhoujie.ding@berkeley.edu; lalowain@kacst.edu.sa; xinyunchen@google.com; daw@cs.berkeley.edu			NSF [CNS-2154873]; joint KACST -UC Berkeley Center of Excellence for Secure Computing; C3.AI's Digital Transformation Institute; Center for AI Safety Compute Cluster	NSF(National Science Foundation (NSF)); joint KACST -UC Berkeley Center of Excellence for Secure Computing; C3.AI's Digital Transformation Institute; Center for AI Safety Compute Cluster	We are grateful to Bryce Casaje for his contributions exploring multiple approaches for dataset construction, including manual labelling of commits, automated text-based labelling, and more. We are grateful to Kexin Pei for his advice on large language model fine tuning. We gratefully acknowledge the anonymous reviewers for many helpful remarks that significantly improved the paper. This research was supported by the NSF under grant CNS-2154873, by the joint KACST -UC Berkeley Center of Excellence for Secure Computing, by C3.AI's Digital Transformation Institute, and by the Center for AI Safety Compute Cluster. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the sponsors.	Alon Uri, 2022, arXiv; [Anonymous], The nist software assurance reference dataset project; Bessey A, 2010, COMMUN ACM, V53, P66, DOI 10.1145/1646353.1646374; Bhandari G, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE '21), P30, DOI 10.1145/3475960.3475985; Chakraborty S, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P18, DOI 10.1145/3540250.3549162; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P3280, DOI 10.1109/TSE.2021.3087402; Challande A, 2022, CODASPY'22: PROCEEDINGS OF THE TWELVETH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P101, DOI 10.1145/3508398.3511495; Croft Roland, 2023, 2023 IEEE ACM 45 INT; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan JH, 2020, IEEE WORK CONF MIN S, P508, DOI 10.1145/3379597.3387501; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Li YJ, 2017, Arxiv, DOI [arXiv:1511.05493, DOI 10.1103/PHYSREVLETT.116.082003, DOI 10.48550/ARXIV.1511.05493]; Li Z, 2022, IEEE T DEPEND SECURE, V19, P2244, DOI 10.1109/TDSC.2021.3051525; Li Z, 2018, Arxiv, DOI arXiv:1801.01681; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Mirsky Yisroel, 2023, USENIX Security 2023; National Institute of Standards and Technology, National Vulnerability Database; Nikitopoulos G, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1565, DOI 10.1145/3468264.3473122; Okun V., 2023, Special Publication (NIST SP), V500, P297, DOI DOI 10.6028/NIST.SP.500-297; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Russell RL, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P757, DOI 10.1109/ICMLA.2018.00120; Steenhoek B, 2023, PROC INT CONF SOFTW, P2237, DOI 10.1109/ICSE48619.2023.00188; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; The MITRE Corporation, 2022 CWE Top 25 Most Dangerous Software Weaknesses-Detailed Methodology; Wang XD, 2021, I C DEPEND SYS NETWO, P149, DOI 10.1109/DSN48987.2021.00030; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Yamaguchi F, 2014, P IEEE S SECUR PRIV, P590, DOI 10.1109/SP.2014.44; Zheng YH, 2021, 2021 IEEE/ACM 43RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2021), P111, DOI 10.1109/ICSE-SEIP52600.2021.00020; Zhou YQ, 2019, ADV NEUR IN, V32	33	2	2	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0765-0				2023							654	668		10.1145/3607199.3607242	http://dx.doi.org/10.1145/3607199.3607242			15	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GM		hybrid, Green Submitted			2024-07-03	WOS:001147724400044
J	Larosa, F; Hoyas, S; García-Martínez, J; Conejero, JA; Nerini, FF; Vinuesa, R				Larosa, Francesca; Hoyas, Sergio; Garcia-Martinez, Javier; Conejero, J. Alberto; Fuso Nerini, Francesco; Vinuesa, Ricardo			Halting generative AI advancements may slow down progress in climate research	NATURE CLIMATE CHANGE			English	Article							ARTIFICIAL-INTELLIGENCE	Large language models offer an opportunity to advance climate and sustainability research. We believe that a focus on regulation and validation of generative artificial intelligence models would provide more benefits to society than a halt in development.	[Larosa, Francesca; Vinuesa, Ricardo] KTH Royal Inst Technol, FLOW, Engn Mech, Stockholm, Sweden; [Larosa, Francesca; Fuso Nerini, Francesco; Vinuesa, Ricardo] KTH Climate Act Ctr, Stockholm, Sweden; [Hoyas, Sergio; Conejero, J. Alberto] Univ Politecn Valencia, Inst Univ Matemat Pura & Aplicada, Valencia, Spain; [Garcia-Martinez, Javier] Univ Alicante, Dept Quim Inorgan, Alicante, Spain; [Fuso Nerini, Francesco] KTH Royal Inst Technol, KTH Div Energy Syst, Sch Ind Engn & Management, Stockholm, Sweden	Royal Institute of Technology; Universitat Politecnica de Valencia; Universitat d'Alacant; Royal Institute of Technology	Larosa, F; Vinuesa, R (corresponding author), KTH Royal Inst Technol, FLOW, Engn Mech, Stockholm, Sweden.; Larosa, F; Vinuesa, R (corresponding author), KTH Climate Act Ctr, Stockholm, Sweden.	larosa@kth.se; rvinuesa@mech.kth.se	Conejero, J. Alberto/A-8589-2008; Vinuesa, Ricardo/ABG-6234-2020; Larosa, Francesca/JDW-7206-2023; Martinez, Javier Garcia/AAG-8670-2020; Hoyas, Sergio/B-6257-2008	Conejero, J. Alberto/0000-0003-3681-7533; Vinuesa, Ricardo/0000-0001-6570-5499; Martinez, Javier Garcia/0000-0002-7089-4973; Larosa, Francesca/0000-0002-4350-8790; Hoyas, Sergio/0000-0002-8458-7288	Digital Futures, Demonstrator Projects program; Ministerio de Ciencia, innovacion y Universidades / FEDER [PID2021-128676OB-I00]; ERDF A way of making Europe [PID2021-124618NB-C21, MCIN/AEI/10.13039/501100011033]; European Union	Digital Futures, Demonstrator Projects program; Ministerio de Ciencia, innovacion y Universidades / FEDER(Spanish Government); ERDF A way of making Europe; European Union(European Union (EU))	F.L., F.F.N. and R.V. acknowledge financial support from the Digital Futures, Demonstrator Projects program. S.H. is partially funded by project PID2021-128676OB-I00 at Ministerio de Ciencia, innovacion y Universidades / FEDER. J.A.C. is partially funded by grant PID2021-124618NB-C21, funded by MCIN/AEI/10.13039/501100011033 and ERDF A way of making Europe' by the European Union.	[Anonymous], PAUS GIANT AI EXP OP; [Anonymous], 2023, CLIMATE CHANGE NINA; [Anonymous], 2019, NAT HUM BEHAV, V3, P103; [Anonymous], 2023, Artificial Intelligence Act; Berrang-Ford L, 2021, NAT CLIM CHANGE; Callaghan MW, 2020, NAT CLIM CHANGE, V10, P118, DOI 10.1038/s41558-019-0684-5; Carleton TA, 2016, SCIENCE, V353, DOI 10.1126/science.aad9837; Cattaneo C, 2019, NAT CLIM CHANGE, V9, P907, DOI 10.1038/s41558-019-0646-y; Falkenberg M, 2022, NAT CLIM CHANGE, V12, P1114, DOI 10.1038/s41558-022-01527-x; Goh HH, 2021, DISCOV SUSTAIN, V2, DOI 10.1007/s43621-021-00064-5; Goujard C., 2023, Politico; Ho DT, 2023, NATURE, V616, P9, DOI 10.1038/d41586-023-00953-x; Kalluri P, 2020, NATURE, V583, P169, DOI 10.1038/d41586-020-02003-2; Lee H., 2023, IPCC CLIMATE CHANGE; Nerini FF, 2019, NAT SUSTAIN, V2, P674, DOI 10.1038/s41893-019-0334-y; Robitschek E., 2022, TRACKING NATL CLIMAT; Roe D, 2019, LANCET PLANET HEALTH, V3, pE287, DOI 10.1016/S2542-5196(19)30113-5; Smith TB, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01801-6; Vesco P, 2020, ECOL ECON, V172, DOI 10.1016/j.ecolecon.2020.106633; Vinuesa R, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-14108-y	20	7	7	13	32	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1758-678X	1758-6798		NAT CLIM CHANGE	Nat. Clim. Chang.	JUN	2023	13	6					497	499		10.1038/s41558-023-01686-5	http://dx.doi.org/10.1038/s41558-023-01686-5		MAY 2023	3	Environmental Sciences; Environmental Studies; Meteorology & Atmospheric Sciences	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Environmental Sciences & Ecology; Meteorology & Atmospheric Sciences	I7VQ0					2024-07-03	WOS:000997023000001
C	Ding, Y; Zhang, XH; Paxton, C; Zhang, SQ			IEEE	Ding, Yan; Zhang, Xiaohan; Paxton, Chris; Zhang, Shiqi			Task and Motion Planning with Large Language Models for Object Rearrangement	2023 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, IROS	IEEE International Conference on Intelligent Robots and Systems		English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	OCT 01-05, 2023	Detroit, MI	IEEE, RSJ				Multi-object rearrangement is a crucial skill for service robots, and commonsense reasoning is frequently needed in this process. However, achieving commonsense arrangements requires knowledge about objects, which is hard to transfer to robots. Large language models (LLMs) are one potential source of this knowledge, but they do not naively capture information about plausible physical arrangements of the world. We propose LLM-GROP, which uses prompting to extract commonsense knowledge about semantically valid object configurations from an LLM and instantiates them with a task and motion planner in order to generalize to varying scene geometry. LLM-GROP allows us to go from natural-language commands to human-aligned object rearrangement in varied environments. Based on human evaluations, our approach achieves the highest rating while outperforming competitive baselines in terms of success rate while maintaining comparable cumulative action costs. Finally, we demonstrate a practical implementation of LLM-GROP on a mobile manipulator in real-world scenarios. Supplementary materials are available at: https://sites.google.com/view/llm-grop	[Ding, Yan; Zhang, Xiaohan; Paxton, Chris; Zhang, Shiqi] SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA	State University of New York (SUNY) System; State University of New York (SUNY) Binghamton	Ding, Y (corresponding author), SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA.	yding25@binghamton.edu; xzhan244@binghamton.edu; zhangs@binghamton.edu	郑, 紫璇/JUF-5733-2023		National Science Foundation [NRI-1925044]; Ford Motor Company (URP Award 2019-2023); OPPO (Faculty Research Award 2020); SUNY Research Foundation	National Science Foundation(National Science Foundation (NSF)); Ford Motor Company (URP Award 2019-2023); OPPO (Faculty Research Award 2020); SUNY Research Foundation	A portion of this work has taken place at the Autonomous Intelligent Robotics (AIR) Group, SUNY Binghamton. AIR research is supported in part by grants from the National Science Foundation (NRI-1925044), Ford Motor Company (URP Award 2019-2023), OPPO (Faculty Research Award 2020), and SUNY Research Foundation.	Ahn M., 2022, arXiv preprint arXiv:2204.01691; [Anonymous], 2022, ARXIV PREPRINT ARXIV; Blukis V., 2022, C ROBOT LEARNING, P706; Boor V, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1018, DOI 10.1109/ROBOT.1999.772447; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Cheong SH, 2020, IEEE INT CONF ROBOT, P7791, DOI [10.1109/icra40945.2020.9197485, 10.1109/ICRA40945.2020.9197485]; Curtis A, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P1940, DOI 10.1109/ICRA46639.2022.9812057; Devlin J., 2018, BERT PRE TRAINING DE; Ding Y., 2023, ARXIV230517590; Gebser M., 2008, USERS GUIDE GRINGO C, P11086; GILKS WR, 1992, J R STAT SOC C-APPL, V41, P337; Goodwin W, 2022, IEEE INT CONF ROBOT, P11138, DOI 10.1109/ICRA46639.2022.9811817; Gu Jiayuan, 2022, ARXIV220902778; Huang E, 2019, IEEE INT CONF ROBOT, P211, DOI [10.1109/ICRA.2019.8793946, 10.1109/icra.2019.8793946]; Huang W., 2022, 30 9 INT C MACHINE L; Huang Wenlong, 2022, ARXIV220705608; Inoue Yuki, 2022, ARXIV221103267; Jiang YQ, 2019, FRONT INFORM TECH EL, V20, P363, DOI 10.1631/FITEE.1800514; Kant Y., 2022, ARXIV220510712; Kapelyukh I., 2022, ARXIV221002438; King JE, 2016, IEEE INT CONF ROBOT, P3940, DOI 10.1109/ICRA.2016.7487583; Liang Jacky, 2022, ARXIV220907753; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu B., 2023, ARXIV230411477; Liu Pengfei, 2021, arXiv; Liu W., 2021, ARXIV211010189; Liu W., 2022, ARXIV221104604; Liu WY, 2022, IEEE INT CONF ROBOT, P6322, DOI 10.1109/ICRA46639.2022.9811931; Min S. Y., 2021, INT C LEARN REPR ICL; OpenAI, 2023, CHATGPT; Ramesh Aditya, 2022, ARXIV220406125; Rana K., 2023, ARXIV230706135; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Singh Ishika, 2022, ARXIV220911302; Szot Andrew, 2022, Habitat rearrangement challenge 2022; Vasilopoulos V, 2021, IEEE INT CONF ROBOT, P6385, DOI 10.1109/ICRA48506.2021.9561958; Wei Qiuhong Anna, 2023, ARXIV230109629; Weihs L., 2021, IEEE CVF C COMP VIS; Wu J., 2023, ARXIV230505658; Zhang S., 2022, arXiv; Zhang Y., 2021, ARXIV210603427; Zhao Z., 2023, ARXIV230514078	42	3	4	9	9	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0858		978-1-6654-9190-7	IEEE INT C INT ROBOT			2023							2086	2092		10.1109/IROS55552.2023.10342169	http://dx.doi.org/10.1109/IROS55552.2023.10342169			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW2ZH		Green Submitted			2024-07-03	WOS:001133658801082
C	Hellas, A; Leinonen, J; Sarsa, S; Koutcheme, C; Kujanpää, L; Sorva, J			ACM	Hellas, Arto; Leinonen, Juho; Sarsa, Sami; Koutcheme, Charles; Kujanpaa, Lilja; Sorva, Juha			Exploring the Responses of Large Language Models to Beginner Programmers' Help Requests	PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1			English	Proceedings Paper	19th Annual ACM Conference on International Computing Education Research V.1 (ICER)	AUG 07-11, 2023	Chicago, IL	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		large language models; introductory programming education; CS1; help seeking; student questions; automatic feedback; OpenAI Codex; GPT	SEEKING	Background and Context: Over the past year, large language models (LLMs) have taken the world by storm. In computing education, like in other walks of life, many opportunities and threats have emerged as a consequence. Objectives: In this article, we explore such opportunities and threats in a specific area: responding to student programmers' help requests. More specifically, we assess how good LLMs are at identifying issues in problematic code that students request help on. Method: We collected a sample of help requests and code from an online programming course. We then prompted two different LLMs (OpenAI Codex and GPT-3.5) to identify and explain the issues in the students' code and assessed the LLM-generated answers both quantitatively and qualitatively. Findings: GPT-3.5 outperforms Codex in most respects. Both LLMs frequently find at least one actual issue in each student program (GPT-3.5 in 90% of the cases). Neither LLM excels at finding all the issues (GPT-3.5 finding them 57% of the time). False positives are common (40% chance for GPT-3.5). The advice that the LLMs provide on the issues is often sensible. The LLMs perform better on issues involving program logic rather than on output formatting. Model solutions are frequently provided even when the LLM is prompted not to. LLM responses to prompts in a non-English language are only slightly worse than responses to English prompts. Implications: Our results continue to highlight the utility of LLMs in programming education. At the same time, the results highlight the unreliability of LLMs: LLMs make some of the same mistakes that students do, perhaps especially when formatting output as required by automated assessment systems. Our study informs teachers interested in using LLMs as well as future efforts to customize LLMs for the needs of programming education.	[Hellas, Arto; Sarsa, Sami; Koutcheme, Charles; Kujanpaa, Lilja; Sorva, Juha] Aalto Univ, Espoo, Finland; [Leinonen, Juho] Univ Auckland, Auckland, New Zealand	Aalto University; University of Auckland	Hellas, A (corresponding author), Aalto Univ, Espoo, Finland.	arto.hellas@aalto.fi; juho.leinonen@auckland.ac.nz; sami.sarsa@aalto.fi; charles.koutcheme@aalto.fi; lilja.kujanpaa@aalto.fi; juha.sorva@aalto.fi	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449; Koutcheme, Charles/0000-0002-2272-2763				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahadi A., 2015, P 11 ANN INT C INT C, P121, DOI [DOI 10.1145/2787622.2787717, 10.1145/2787622.2787717]; Ala-Mutka KM, 2005, COMPUT SCI EDUC, V15, P83, DOI 10.1080/08993400500150747; Altadmri A., 2015, P 46 ACM TECHN S COM, P522, DOI DOI 10.1145/2676723.2677258; [Anonymous], 2016, Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE, DOI DOI 10.1145/2899415.2899463; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Becker Brett A., 2022, Programming Is Hard-Or at Least It Used to Be: Educational Opportunities And Challenges of AI Code Generation; Borich Gary D, 2005, Educational psychology: A contemporary approach; Brown NCC, 2017, ACM T COMPUT EDUC, V17, DOI 10.1145/2994154; Brown Neil CC, 2014, Proceedings of the Tenth Annual Conference on International Computing Education Research. ICER'14, P43; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Butler R, 1998, J EDUC PSYCHOL, V90, P630, DOI 10.1037/0022-0663.90.4.630; Carter A. S., 2015, Proceedings of the 11th Annual International Conference on International Computing Education Research (ICER'15), P141, DOI [DOI 10.1145/2787622.2787710, 10.1145/2787622.2787710]; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny P, 2023, Arxiv, DOI arXiv:2306.02608; Denny Paul, 2012, P 17 ACM ANN C INNOV, P75, DOI DOI 10.1145/2325296.2325318; Denny Paul, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445696, 10.1145/3411764, DOI 10.1145/3411764]; Denny Paul, 2022, Conversing with Copilot: Exploring Prompt Engineering for Solving CS1 Problems Using Natural Language; Dy T., 2010, P 10 KOL CALL INT C, P118; Ettles Andrew, 2018, P 20 AUSTR COMP ED C, P83, DOI 10.1145/3160489.3160493; Finnie-Ansley James, 2023, ACE '23: Australasian Computing Education Conference, P97, DOI 10.1145/3576123.3576134; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Glassman EL, 2015, ACM T COMPUT-HUM INT, V22, DOI 10.1145/2699751; Head A, 2017, PROCEEDINGS OF THE FOURTH (2017) ACM CONFERENCE ON LEARNING @ SCALE (L@S'17), P89, DOI 10.1145/3051457.3051467; Hellas A, 2017, ITICSE'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P238, DOI 10.1145/3059009.3059065; Hilton AD, 2019, PROCEEDINGS OF THE ACM CONFERENCE ON GLOBAL COMPUTING EDUCATION (COMPED '19), P78, DOI 10.1145/3300115.3309508; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ihantola P., 2010, P KOLI CALLING, P86, DOI 10.1145/1930464.1930480; Ihantola P., 2014, P 15 ANN C INFORM TE, P33; Ihantola P, 2016, PROCEEDINGS OF THE 2015 ITICSE CONFERENCE ON WORKING GROUP REPORTS (ITICSE-WGP'15), P41, DOI 10.1145/2858796.2858798; Jadud M. C., 2006, Proceedings of the 2nd International Workshop on Computing Education Research, P73; Jadud MC, 2005, COMPUT SCI EDUC, V15, P25, DOI 10.1080/08993400500056530; Jeuring Johan, 2022, ITiCSE-WGR '22: Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education, P95, DOI 10.1145/3571785.3574124; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kalyuga S, 2007, EDUC PSYCHOL REV, V19, P509, DOI 10.1007/s10648-007-9054-3; Karabenick SA, 2004, J EDUC PSYCHOL, V96, P569, DOI 10.1037/0022-0663.96.3.569; Kazemitabaar M, 2023, Arxiv, DOI [arXiv:2302.07427, DOI 10.1145/3544548.3580919]; Keuning H, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3231711; Koivisto Teemu, 2022, 2022 IEEE FRONT ED C, P1; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Leinonen J, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P871, DOI 10.1145/3478431.3499359; Leinonen J, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P885, DOI 10.1145/3478431.3499372; Leinonen J, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P200, DOI 10.1145/3105726.3106181; Leppanen Leo, 2022, 2022 IEEE FRONT ED C, P1; Lewis Johnson W, 1983, Bug Catalogue: I. Technical Report; Liao SN, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P196, DOI 10.1145/3304221.3319740; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Loksa D, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1449, DOI 10.1145/2858036.2858252; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil Stephen, 2023, P 54 ACM TECHNICAL S, V2, P1176, DOI DOI 10.1145/3545947.3569630; MacNeil Stephen, 2023, P SIGCSE 23 ACM; Mao Y., 2019, P 12 INT C ED DAT MI, P119; Marwan Samiha, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P194, DOI 10.1145/3372782.3406264; McCall D, 2019, ACM T COMPUT EDUC, V19, DOI 10.1145/3335814; McCall D, 2014, PROC FRONT EDUC CONF; Muller S, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P333, DOI 10.1145/3328778.3366885; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nelimarkka M, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P116, DOI 10.1145/3159450.3159495; Nguyen A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P491, DOI 10.1145/2566486.2568023; Nygren H, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P44, DOI 10.1145/3304221.3319768; Nygren Henrik, 2019, P 2019 C UK IR COMP, P1; Onah DFO, 2014, EDULEARN PROC, P5825; Orwell J., 2005, J ED RESOURCES COMPU, V5, DOI [10.1145/1163405.1163409, DOI 10.1145/1163405.1163409]; Ott C, 2016, ACM T COMPUT EDUC, V16, DOI 10.1145/2737596; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Petersen A, 2015, P 15 KOLI CALLING C, P77, DOI [10.1145/2828959.2828966, DOI 10.1145/2828959.2828966]; Prather J, 2023, Arxiv, DOI arXiv:2304.02491; Prather J, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P531, DOI 10.1145/3287324.3287374; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ryan AM, 1998, J EDUC PSYCHOL, V90, P528, DOI 10.1037/0022-0663.90.3.528; Ryan AM, 2001, EDUC PSYCHOL REV, V13, P93, DOI 10.1023/A:1009013420053; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sarsa Sami, 2022, 2022 IEEE FRONT ED C, P1; Seamark D, 2018, BRIT J GUID COUNS, V46, P120, DOI 10.1080/03069885.2016.1213372; Seppala Otto, 2015, P 15 KOL CALL C COMP, P87; Smith R, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P538, DOI 10.1145/3287324.3287394; SOLOWAY E, 1983, COMMUN ACM, V26, P853, DOI 10.1145/182.358436; Soloway Elliot, 1982, Directions in human-computer interaction, V6, P27; SPOHRER JC, 1986, COMMUN ACM, V29, P624, DOI 10.1145/6138.6145; Vaithilingam Priyan, 2022, CHI C HUM FACT COMP, P1; Vaswani A, 2017, ADV NEUR IN, V30; Vihavainen Arto, 2015, P 46 ACM TECHNICAL S, P284, DOI [DOI 10.1145/2676723.2677260, 10.1145/2676723, DOI 10.1145/2676723]; Vihavainen Arto, 2014, Koli Calling 2014, P109, DOI DOI 10.1145/2674683.2674692; Watson C, 2013, IEEE INT CONF ADV LE, P319, DOI 10.1109/ICALT.2013.99; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830	89	5	5	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9976-0				2023							93	105		10.1145/3568813.3600139	http://dx.doi.org/10.1145/3568813.3600139			13	Computer Science, Theory & Methods; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW3QV		Green Submitted, hybrid			2024-07-03	WOS:001141973500007
C	Talat, Z; Névéol, A; Biderman, S; Clinciu, M; Dey, M; Longpre, S; Luccioni, S; Masoud, M; Mitchell, M; Radev, D; Sharma, S; Subramonian, A; Tae, J; Tan, S; Tunuguntla, D; Van der Wal, O			Assoc Computat Linguist	Talat, Zeerak; Neveol, Aurelie; Biderman, Stella; Clinciu, Miruna; Dey, Manan; Longpre, Shayne; Luccioni, Sasha; Masoud, Maraim; Mitchell, Margaret; Radev, Dragomir; Sharma, Shanya; Subramonian, Arjun; Tae, Jaesung; Tan, Samson; Tunuguntla, Deepak; Van der Wal, Oskar			You Reap What You Sow: On the Challenges of Bias Evaluation Under Multilingual Settings	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				Evaluating bias, fairness, and social impact in monolingual language models is a difficult task. This challenge is further compounded when language modeling occurs in a multilingual context. Considering the implication of evaluation biases for large multilingual language models, we situate the discussion of bias evaluation within a wider context of social scientific research with computational work. We highlight three dimensions of developing multilingual bias evaluation frameworks: (1) increasing transparency through documentation, (2) expanding targets of bias beyond gender, and (3) addressing cultural differences that exist between languages. We further discuss the power dynamics and consequences of training large language models and recommend that researchers remain cognizant of the ramifications of developing such technologies.	[Talat, Zeerak] Simon Fraser Univ, Digital Democracies Inst, Burnaby, BC, Canada; [Neveol, Aurelie] Univ Paris Saclay, CNRS, LISN, Paris, France; [Biderman, Stella] Booz Allen Hamilton, Mclean, VA USA; [Biderman, Stella] EleutherAI, Chicago, IL USA; [Clinciu, Miruna] Edinburgh Ctr Robot, Edinburgh, Midlothian, Scotland; [Clinciu, Miruna] Heriot Watt Univ, Edinburgh, Midlothian, Scotland; [Clinciu, Miruna] Univ Edinburgh, Edinburgh, Midlothian, Scotland; [Dey, Manan] SAP, Walldorf, Germany; [Longpre, Shayne] MIT, Cambridge, MA 02139 USA; [Luccioni, Sasha; Mitchell, Margaret; Tae, Jaesung] Hugging Face, New York, NY USA; [Masoud, Maraim] Trinity Coll Dublin, Adapt Ctr, Dublin, Ireland; [Radev, Dragomir; Tae, Jaesung] Yale Univ, New Haven, CT 06520 USA; [Sharma, Shanya] Walmart Labs, Bengaluru, India; [Subramonian, Arjun] Univ Calif Los Angeles, Los Angeles, CA 90024 USA; [Subramonian, Arjun] Queer AI, New York, NY USA; [Tan, Samson] AWS AI Res & Educ, Palo Alto, CA USA; [Tan, Samson] Natl Univ Singapore, Singapore, Singapore; [Van der Wal, Oskar] Univ Amsterdam, Amsterdam, Netherlands	Simon Fraser University; Centre National de la Recherche Scientifique (CNRS); Universite Paris Saclay; Universite Paris Cite; Booz Allen Hamilton Holding Corporation; Heriot Watt University; University of Edinburgh; SAP; Massachusetts Institute of Technology (MIT); Trinity College Dublin; Yale University; University of California System; University of California Los Angeles; National University of Singapore; University of Amsterdam	Talat, Z (corresponding author), Simon Fraser Univ, Digital Democracies Inst, Burnaby, BC, Canada.		Radev, Dragomir/E-9641-2012	Talat, Zeerak/0000-0001-5503-867X				Abid Abubakar, 2021, AIES 2021 P 2021 AAA; Agostinho D, 2019, SURVEILL SOC, V17, P422, DOI 10.24908/ss.v17i3/4.12330; Aguera B., 2018, ALGORITHMS REVEAL SE; Al Kuwatly H., 2020, P 4 WORKSH ONL AB HA, P184; Allen L, 2019, LEARN PUBL, V32, P71, DOI 10.1002/leap.1210; Angelina McMillan-Major, 2022, arXiv; Anhong Guo, 2020, ACM SIGACCESS Accessibility and Computing, DOI 10.1145/3386296.3386298; Askell A., 2021, A general language assistant as a laboratory for alignment; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; Barocas Solon, 2017, The problem with bias: from allocative to representational harms in machine learning, V2; Bender E., 2019, GRADIENT; Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Biderman S., 2020, PITFALLS MACHINE LEA, DOI [10.48550/arXiv.2011.02832, DOI 10.48550/ARXIV.2011.02832]; Biderman S, 2022, Arxiv, DOI arXiv:2201.07311; Birhane A, 2022, Arxiv, DOI arXiv:2106.15590; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Blodgett SL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1415; Bolukbasi T, 2016, ADV NEUR IN, V29; Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Campolo A., 2017, AI Now 2017 report; Cao YT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4568; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Chan A., 2021, arXiv, DOI [10.48550/arxiv.2102.01265, DOI 10.48550/ARXIV.2102.01265]; Chang Kai-Wei, 2018, P NAACL, V2, DOI [10.18653/v1/N18-2003, DOI 10.18653/V1/N18-2003]; Chen John, 2020, P 3 CLIN NATURAL LAN, P301; Chen Y, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P24, DOI 10.1145/3461702.3462530; Cheng Lu., 2021, P 30 INT JOINT C ART; Cheshire J, 2007, LANGUAGE, V83, P432, DOI 10.1353/lan.2007.0058; CostanzaChock Sasha, 2018, Journal of Design and Science (JoDS), DOI [DOI 10.21428/96C8D426, 10.21428/96c8d426]; Crenshaw K., 1991, STANFORD LAW REV, V43, P1241, DOI 10.2307/1229039; Czarnowska P, 2021, T ASSOC COMPUT LING, V9, P1249, DOI 10.1162/tacl_a_00425; Datta Debajyoti, 2021, CHALLENGES LANGUAGE; De-Arteaga M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P120, DOI 10.1145/3287560.3287572; Dev S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1968; Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659; Dev Sunipa, 2021, WHAT BIAS MEASURES M; Dhamala Jwala, 2021, P 2021 ACM C FAIRN A, P862; DIgnazio C, 2020, STRONG IDEAS SERIES, P1; Dignum V., 2017, ICT Discoveries; Dodge J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1286; Douglas M., 1984, PURITY DANGER ANAL C; Dunn J, 2020, LANG RESOUR EVAL, V54, P999, DOI 10.1007/s10579-020-09489-2; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Font JE, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P147; Fraser Nancy, 1990, Habermas and the Public Sphere, V25-26, P56, DOI DOI 10.2307/466240; Friedler SA, 2021, COMMUN ACM, V64, P136, DOI 10.1145/3433949; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Garimella A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4534; Gebru T, 2021, Arxiv, DOI arXiv:1803.09010; Gehman S., 2020, FINDINGS ASS COMPUTA, P3356; Gitelman L, 2013, INFRASTRUCT SER, P1; Gonen H., 2019, P NAACL HLT, P609; Guo Anhong, 2019, FAIRNESS PEOPLE DISA; Guo W, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P122, DOI 10.1145/3461702.3462536; Gururangan S., 2022, arXiv; HARAWAY D, 1988, FEMINIST STUD, V14, P575, DOI 10.2307/3178066; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Huang PS, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P65; Hui Wendy, 2021, DISCRIMINATING DATA; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jacobs AZ, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P375, DOI 10.1145/3442188.3445901; Jin X, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3770; Joshi Pratik, 2020, P 58 ANN M ASS COMPU, P6282, DOI [10.18653/v1/2020. acl-main.560, DOI 10.18653/V1/2020.ACL-MAIN.560]; Kag gle, 2017, KAGGLES TOXICITY COM; Kandpal N, 2022, Arxiv, DOI arXiv:2202.06539; Kearns M, 2018, PR MACH LEARN RES, V80; Kerrison EM, 2018, RACE JUSTICE, V8, P7, DOI 10.1177/2153368717734291; Keyes Os, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449113; Kreutzer J, 2022, T ASSOC COMPUT LING, V10, P50, DOI 10.1162/tacl_a_00447; Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166; Labov W., 1986, Dialect and language variation, P304; Lau, 2021, WORKING PAPERS APPL, V1, P4; Lepawsky Josh., 2019, DISCARD STUDIES, V0; Levy Shahar, 2021, COLLECTING LARGE SCA; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Liao Q Vera, 2019, ARXIV PREPRINT ARXIV; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Madaan N, 2021, AAAI CONF ARTIF INTE, V35, P13516; Magee L, 2021, Arxiv, DOI arXiv:2107.07691; MAIEI, 2021, STAT AI ETH; Malik Vijit, 2021, SOCIALLY AWARE BIAS; Manela DD, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2232; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; Miceli M., 2022, P ACM HUMAN COMPUTER, P1; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Monteiro Mike., 2019, Mule Design; Nadeem Moin, 2020, Stereoset: Measuring stereotypical bias in pretrained language models; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nekoto W, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2144; Noble Safiya Umoja, 2018, ALGORITHMS OPPRESSIO; Parrish Alicia, BBQ HAND BUILT BIAS; Prashanth USVSN Sai, 2022, GPT NEOX 20B OPENSOU; Raji ID, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P429, DOI 10.1145/3306618.3314244; Raji Inioluwa Deborah, 2021, arXiv; Rajunov Micah, 2019, Nonbinary: Memoirs of gender and identity; Rudinger J., 2018, P 2018 C N AM CHAPTE, P8, DOI [10.18653/v1/n18-2002.45, DOI 10.18653/V1/N18-2002, 10.18653/v1/N18-2002]; Sambasivan Nithya, 2021, FAccT '21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency, P315, DOI 10.1145/3442188.3445896; Sanh V, 2022, arXiv; Sap Maarten, 2021, arXiv; Schiff Daniel., 2020, 2020 EUROPEAN C WORK; Sharma Shanya, EVALUATING GENDER BI; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Sheng Emily, P 59 ANN M ASS COMPU, V1, P4275; Smith S, 2022, arXiv; Spade Dean, 2015, Normal Life: Administrative Violence, Critical Trans Politics, and the Limits of Law, DOI DOI 10.1215/9780822374794; Stanczak K, 2021, Arxiv, DOI [arXiv:2112.14168, DOI 10.48550/ARXIV.2112.14168, 10.48550/ARXIV.2112.14168]; Stanovsky G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1679; Subramonian Arjun., 2021, ALLENNLP FAIRNESS BI; Sun T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1630; Tan S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2920; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thylstrup Nanna, 2020, SSRN ELECT J, DOI 10.2139/ssrn.3709719; Tomasev N, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P254, DOI 10.1145/3461702.3462540; Virtanen A., 2019, Multilingual is not enough: BERT for Finnish; Wallace E., 2019, P 2019 C EMPIRICAL M, DOI [10.18653/v1/D19-1221, DOI 10.18653/V1/D19-1221]; Wang TL, 2019, IEEE I CONF COMP VIS, P5309, DOI 10.1109/ICCV.2019.00541; Waseem Z, 2021, Arxiv, DOI arXiv:2101.11974; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; West Sarah Myers, 2019, Discriminating systems: Gender, race and power in AI; WINNER L, 1980, DAEDALUS, V109, P121; Zhou Pei, 2019, P 2019 C EMP METH NA, P5275; Zmigrod R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1651	130	10	11	2	6	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							26	41						16	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900003
C	Chen, HY; Yu, H			ACM	Chen, Huan-Yuan; Yu, Hong			Intent-based Web Page Summarization with Structure-Aware Chunking and Generative Language Models	COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023			English	Proceedings Paper	32nd World Wide Web Conference (WWW)	APR 30-MAY 04, 2023	Austin, TX	Assoc Comp Machinery, Amazon Science, Baidu, Megagon Labs, Zhipu AI, Google, Booking Com, eBay, Bloomberg Engn, Netflix, ACM SIGWEB, Univ Texas Austin, Sch Informat, Data World, Inst Fdn Machine Learning		Web for Good; Structure-Aware Chunking; Web Page Summarization; LLM Applications		This paper introduces a structure-aware method to segment web pages into chunks based on their web structures. We utilize large language models to select chunks correspond to a given intent and generate the abstractive summary. Experiments on a food pantry dataset developed for mitigating food insecurity show that the proposed framework is promising.	[Chen, Huan-Yuan] Univ Massachusetts Amherst, Coll Informat & Comp Sci, Amherst, MA 01003 USA; [Yu, Hong] Univ Massachusetts Lowell, Sch Comp & Informat Sci, Lowell, MA USA	University of Massachusetts System; University of Massachusetts Amherst; University of Massachusetts System; University of Massachusetts Lowell	Chen, HY (corresponding author), Univ Massachusetts Amherst, Coll Informat & Comp Sci, Amherst, MA 01003 USA.	huanyuanchen@umass.edu; hong_yu@uml.edu						Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Deng Xiang, 2022, arXiv; Guo Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1502, DOI 10.1145/3477495.3532086; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906	4	1	1	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9416-1				2023							310	313		10.1145/3543873.3587372	http://dx.doi.org/10.1145/3543873.3587372			4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SF					2024-07-03	WOS:001124276300074
J	[Anonymous]				[Anonymous]			Will ChatGPT transform healthcare?	NATURE MEDICINE			English	Editorial Material							THERAPEUTIC ALLIANCE	ChatGPT and other large language models may be able to enhance healthcare delivery and patients' quality of life. But they will need to be tailored to specific clinical needs first.										[Anonymous], 2021, Youth Risk Behavior Survey; HORVATH AO, 1991, J COUNS PSYCHOL, V38, P139, DOI 10.1037/0022-0167.38.2.139; Kuehn BM, 2013, JAMA-J AM MED ASSOC, V309, P756, DOI 10.1001/jama.2013.629; Levine D. M., 2023, PREPRINT, DOI [10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Mack JW, 2009, CANCER-AM CANCER SOC, V115, P3302, DOI 10.1002/cncr.24360; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Sturgiss EA, 2016, CLIN OBES, V6, P376, DOI 10.1111/cob.12167	7	97	99	18	133	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	MAR	2023	29	3					505	506		10.1038/s41591-023-02289-5	http://dx.doi.org/10.1038/s41591-023-02289-5		MAR 2023	2	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	A9AQ7	36918736	Bronze			2024-07-03	WOS:000950626100001
C	Chen, YF; Arunasalam, A; Celik, ZB			ACM	Chen, Yufan; Arunasalam, Arjun; Celik, Z. Berkay			Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions	39TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2023			English	Proceedings Paper	39th Annual Computer Security Applications Conference (ACSAC)	DEC 04-08, 2023	Austin, TX	Appl Comp Secur Associates		Large language models; security and privacy advice; misconception		Users seek security & privacy (S&P) advice from online resources, including trusted websites and content-sharing platforms. These resources help users understand S&P technologies and tools and suggest actionable strategies. Large Language Models (LLMs) have recently emerged as trusted information sources. However, their accuracy and correctness have been called into question. Prior research has outlined the shortcomings of LLMs in answering multiple-choice questions and user ability to inadvertently circumvent model restrictions (e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable S&P advice is not well-explored. In this paper, we measure their ability to refute popular S&P misconceptions that the general public holds. We first study recent academic literature to curate a dataset of over a hundred S&Prelated misconceptions across six different topics. We then query two popular LLMs (Bard and ChatGPT) and develop a labeling guide to evaluate their responses to these misconceptions. To comprehensively evaluate their responses, we further apply three strategies: query each misconception multiple times, generate and query their paraphrases, and solicit source URLs of the responses. Both models demonstrate, on average, a 21.3% non-negligible error rate, incorrectly supporting popular S&P misconceptions. The error rate increases to 32.6% when we repeatedly query LLMs with the same or paraphrased misconceptions. We also expose that models may partially support a misconception or remain noncommittal, refusing a firm stance on misconceptions. Our exploration of information sources for responses revealed that LLMs are susceptible to providing invalid URLs (21.2% for Bard and 67.7% for ChatGPT) or point to unrelated sources (44.2% returned by Bard and 18.3% by ChatGPT). Our findings highlight that existing LLMs are not completely reliable for S&P advice and motivate future work in understanding how users can better interact with this technology.	[Chen, Yufan; Arunasalam, Arjun; Celik, Z. Berkay] Purdue Univ, W Lafayette, IN 47907 USA	Purdue University System; Purdue University	Chen, YF (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.	chen4076@purdue.edu; aarunasa@purdue.edu; zcelik@purdue.edu		Celik, Berkay/0000-0001-7362-8905	Purdue University	Purdue University	We thank our anonymous reviewers and shepherd for providing us with valuable feedback that helped improve our paper. This work is supported by startup funding from Purdue University.	ALDayel A, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102597; Ali Waleed, 2019, International journal of media, journalism and mass communications, V5; [Anonymous], 2023, Requests: HTTP for Humans; [Anonymous], 2023, IAn important next step on our AI journey; [Anonymous], 2023, ChatGPT API; [Anonymous], 2023, Could ChatGPT REALLY slay Google; [Anonymous], 2023, I use ChatGPT to ace interviews: 'Works for every single job'; [Anonymous], 2023, Miss-date doctor launches revolutionary AI platform to help people find partners; [Anonymous], 2023, OpenAI ChatGPT job interview questions; [Anonymous], 2023, ChatGPT; [Anonymous], 2023, Google Scholar; [Anonymous], 2023, Claude; [Anonymous], 2023, ChatGPT: Online AI tool teachers say some students are using to cheat; [Anonymous], 2023, ChatGPT API Temperature Parameter.; [Anonymous], 2023, ChatGPT coding: OpenAI CEO says AI can save time on software jobs; [Anonymous], 2023, LLaMa; [Anonymous], 2023, How You Should-and Shouldn't-Use ChatGPT for Medical Advice; [Anonymous], 2023, Replication Package; [Anonymous], 2023, Wayback Machine; [Anonymous], 2023, GPT-3.5-turbo Model; [Anonymous], 2023, Statistics of Common Crawl Monthly Archives; [Anonymous], 2023, Rapid API; [Anonymous], 2023, Chatgpt plugins; [Anonymous], 2023, Paraphrase Genius; [Anonymous], 2023, Hugging Face; [Anonymous], 2023, Bard; [Anonymous], 2023, Investors are asking ChatGPT for stock market advice; [Anonymous], 2023, GPTStore; [Anonymous], 2023, Could your next therapist be AI? Tech raises hopes, concerns; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Barrett C, 2023, Arxiv, DOI arXiv:2308.14840; Birkun Alexei A, 2023, Current Problems in Cardiology, V2023; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Deng GL, 2024, Arxiv, DOI arXiv:2308.06782; Denning Tamara, 2013, ACM SIGSAC C COMPUTE; FLEISS JL, 1973, EDUC PSYCHOL MEAS, V33, P613, DOI 10.1177/001316447303300309; Gehman S, 2020, Arxiv, DOI [arXiv:2009.11462, DOI 10.1017/S1431927621007376]; Guerreiro NM, 2023, Arxiv, DOI arXiv:2303.16104; Huang Sean S, 2023, medRxiv; Kojima Takeshi, 2022, Advances in Neural Information Processing Systems; Lin Stephanie, 2022, Computational Linguistics; Nicholson J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300579; Noever D, 2023, Arxiv, DOI [arXiv:2308.10345, 10.48550/arXiv.2308.10345, DOI 10.48550/ARXIV.2308.10345]; OpenAI, 2023, Introducint ChatGPT.; Ouyang L., 2022, Advances in Neural Information Processing Systems; Paria S, 2023, Arxiv, DOI arXiv:2308.06932; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Peng BL, 2022, Arxiv, DOI arXiv:2206.11309; Rader Emilee, 2012, S USABLE PRIVACY SEC; Raffel C, 2020, J MACH LEARN RES, V21; Redmiles EM, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P666, DOI 10.1145/2976749.2978347; Redmiles EM, 2016, P IEEE S SECUR PRIV, P272, DOI 10.1109/SP.2016.24; Redmiles Elissa M, 2020, USENIX SECURITY S; Redmiles Elissa M., 2017, CHI C HUMAN FACTORS; Ren RY, 2023, Arxiv, DOI arXiv:2307.11019; Saeidnia Hamid Reza, 2023, Research Square; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Shuster K., 2022, arXiv; Si Wai Man, 2022, ACM SIGSAC C COMPUTE; Srikwan S, 2008, CRYPTOLOGIA, V32, P137, DOI 10.1080/01611190701743724; t5-paraphrase API, 2023, t5-large-paraphraser-diverse-high-quality model; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tol MC, 2023, Arxiv, DOI arXiv:2308.13062; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS; Wei JS, 2022, ADV NEUR IN; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhang-Kennedy Leah, 2016, International Journal of Human-Computer Interaction, V2016; Zuccon G, 2023, Arxiv, DOI [arXiv:2302.13793, DOI 10.48550/ARXIV.2302.13793]	72	2	2	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0886-2				2023							366	378		10.1145/3627106.3627196	http://dx.doi.org/10.1145/3627106.3627196			13	Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW4HF		hybrid			2024-07-03	WOS:001148013400028
J	Ma, JN; Song, JN; Young, ND; Chang, BCH; Korhonen, PK; Campos, TL; Liu, H; Gasser, RB				Ma, Jiani; Song, Jiangning; Young, Neil D.; Chang, Bill C. H.; Korhonen, Pasi K.; Campos, Tulio L.; Liu, Hui; Gasser, Robin B.			'Bingo'-a large language model- and graph neural network-based workflow for the prediction of essential genes from protein data	BRIEFINGS IN BIOINFORMATICS			English	Article						essential gene prediction; large language model; graph neural network; adversarial training; biological interpretation	SEQUENCE	The identification and characterization of essential genes are central to our understanding of the core biological functions in eukaryotic organisms, and has important implications for the treatment of diseases caused by, for example, cancers and pathogens. Given the major constraints in testing the functions of genes of many organisms in the laboratory, due to the absence of in vitro cultures and/or gene perturbation assays for most metazoan species, there has been a need to develop in silico tools for the accurate prediction or inference of essential genes to underpin systems biological investigations. Major advances in machine learning approaches provide unprecedented opportunities to overcome these limitations and accelerate the discovery of essential genes on a genome-wide scale. Here, we developed and evaluated a large language model- and graph neural network (LLM-GNN)-based approach, called 'Bingo', to predict essential protein-coding genes in the metazoan model organisms Caenorhabditis elegans and Drosophila melanogaster as well as in Mus musculus and Homo sapiens (a HepG2 cell line) by integrating LLM and GNNs with adversarial training. Bingo predicts essential genes under two 'zero-shot' scenarios with transfer learning, showing promise to compensate for a lack of high-quality genomic and proteomic data for non-model organisms. In addition, the attention mechanisms and GNNExplainer were employed to manifest the functional sites and structural domain with most contribution to essentiality. In conclusion, Bingo provides the prospect of being able to accurately infer the essential genes of little- or under-studied organisms of interest, and provides a biological explanation for gene essentiality.	[Gasser, Robin B.] Univ Melbourne, Melbourne Vet Sch, Dept Vet Biosci, Parkville, Vic 3010, Australia; [Ma, Jiani] Univ Melbourne, Gasser Lab, Parkville, Vic, Australia; [Ma, Jiani; Liu, Hui] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou, Peoples R China; [Song, Jiangning] Monash Univ, Monash Biomed Discovery Inst, Clayton, Vic, Australia; [Song, Jiangning] Monash Univ, Monash Data Futures Inst, Clayton, Vic, Australia; [Young, Neil D.; Gasser, Robin B.] Univ Melbourne, Parkville, Vic, Australia; [Chang, Bill C. H.] Genet Co Yourgene Hlth, Manchester, England; [Korhonen, Pasi K.] Nokia, Espoo, Finland; [Gasser, Robin B.] Australian Acad Sci FAA, Canberra, Act, Australia	University of Melbourne; University of Melbourne; China University of Mining & Technology; Monash University; Monash University; University of Melbourne; Australian Academy of Science	Gasser, RB (corresponding author), Univ Melbourne, Melbourne Vet Sch, Dept Vet Biosci, Parkville, Vic 3010, Australia.	jiani.ma@cumt.edu.cn; jiangning.song@monash.edu; nyoung@unimelb.edu.au; bchang@ozomics.com; pasi.korhonen@unimelb.edu.au; tulio.campos@unimelb.edu.au; hui.liu@cumt.edu.cn; robinbg@unimelb.edu.au	Young, Neil/KRQ-9423-2024; Ma, Jiani/JEF-7791-2023; Song, Jiangning/F-9787-2010; de Lima Campos, Tulio/N-5204-2018	Song, Jiangning/0000-0001-8031-9086; de Lima Campos, Tulio/0000-0003-0446-848X	China Scholarship Council; Australia Research Council [LP180101085, LP220200614]; Swiss National Science Foundation; Australian Research Council [LP220200614] Funding Source: Australian Research Council	China Scholarship Council(China Scholarship Council); Australia Research Council(Australian Research Council); Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); Australian Research Council(Australian Research Council)	This work was supported by a scholarship from the China Scholarship Council to J.M. and by grants from the Australia Research Council (LP180101085 to R.B.G.; LP220200614 to R.B.G. and J.S.) and the Swiss National Science Foundation to R.B.G.	[Anonymous], 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1181; Aromolaran O, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab128; Aromolaran O, 2020, COMPUT STRUCT BIOTEC, V18, P612, DOI 10.1016/j.csbj.2020.02.022; Ausländer S, 2017, ANGEW CHEM INT EDIT, V56, P6396, DOI 10.1002/anie.201609229; Beder T., 2021, Nar Genom Bioinform, V3, plqab110; Campos TL., 2020, NAR Genomics Bioinform, V2, plqaa051; Campos TL, 2022, BIOTECHNOL ADV, V54, DOI 10.1016/j.biotechadv.2021.107822; Campos TL, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22105056; Campos TL, 2020, COMPUT STRUCT BIOTEC, V18, P1093, DOI 10.1016/j.csbj.2020.05.008; Campos TL, 2019, COMPUT STRUCT BIOTEC, V17, P785, DOI 10.1016/j.csbj.2019.05.008; Carninci P, 2005, SCIENCE, V309, P1559, DOI 10.1126/science.1112014; Chen H., Proceedings of the AAAI Conference on Artificial Intelligence, V36; Decoville M, 2001, GENETICS, V157, P237; Dong C, 2020, BRIEF BIOINFORM, V21, P171, DOI 10.1093/bib/bby116; Dotson GA, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32980-z; Doyle MA, 2010, BMC GENOMICS, V11, DOI 10.1186/1471-2164-11-222; Eisenberg E, 2003, TRENDS GENET, V19, P362, DOI 10.1016/S0168-9525(03)00140-9; Fischer D, 1999, BIOINFORMATICS, V15, P759, DOI 10.1093/bioinformatics/15.9.759; Georgi B, 2013, PLOS GENET, V9, DOI 10.1371/journal.pgen.1003484; Ghen HB, 2020, BRIEF BIOINFORM, V21, P1397, DOI 10.1093/bib/bbz072; GLUECKSOHNWAELS.S, 1963, SCIENCE, V142, P1269, DOI 10.1126/science.142.3597.1269; Goodfellow Ian, 2015, INT C LEARN REPR; Gurumayum S, 2021, NUCLEIC ACIDS RES, V49, pD998, DOI 10.1093/nar/gkaa884; Hamilton WL., 2018, P 31 INT C NEUR INF; Hughes Timothy R, 2002, Funct Integr Genomics, V2, P199, DOI 10.1007/s10142-002-0059-1; Jiang Y, 2023, ADV SCI, V10, DOI 10.1002/advs.202206151; Jordan IK, 2002, GENOME RES, V12, P962, DOI 10.1101/gr.87702; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Li XY, 2020, BRIEF BIOINFORM, V21, P566, DOI 10.1093/bib/bbz017; Li YM, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btac779; Li YM, 2022, IEEE ACM T COMPUT BI, V19, P3263, DOI 10.1109/TCBB.2021.3122294; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; López-Terrada D, 2009, HUM PATHOL, V40, P1512, DOI 10.1016/j.humpath.2009.07.003; Min Zeng, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P98, DOI 10.1109/BIBM52615.2021.9669606; Miyato T., 2017, 5th International Conference on Learning Representations; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116; Perlman RL, 2016, EVOL MED PUBLIC HLTH, P170, DOI 10.1093/emph/eow014; Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084; Phillips D C, 1970, Biochem Soc Symp, V30, P11; Rancati G, 2018, NAT REV GENET, V19, P34, DOI 10.1038/nrg.2017.74; Ruan D, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100390; Schapke J, 2022, IEEE ACM T COMPUT BI, V19, P1615, DOI 10.1109/TCBB.2021.3054738; Schultz J, 2000, NUCLEIC ACIDS RES, V28, P231, DOI 10.1093/nar/28.1.231; Shi JW, 2015, NAT BIOTECHNOL, V33, P661, DOI 10.1038/nbt.3235; STEPHENS RM, 1992, MOL CELL BIOL, V12, P3733, DOI 10.1128/MCB.12.9.3733; STROMINGER JL, 1954, J AM CHEM SOC, V76, P6411, DOI 10.1021/ja01653a051; Tautz D, 2011, NAT REV GENET, V12, P692, DOI 10.1038/nrg3053; Tian D, 2018, DIS MODEL MECH, V11, DOI 10.1242/dmm.034546; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic G., 2018, 6 INT C LEARNING REP; Vyas VK, 2015, SCI ADV, V1, DOI 10.1126/sciadv.1500248; Wu CL, 2013, NUCLEIC ACIDS RES, V41, pD561, DOI 10.1093/nar/gks1114; Xu K, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337923; Ying R., 2019, 33 C NEUR INF PROC S; Zeng M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3076-y; Zeng M, 2021, IEEE ACM T COMPUT BI, V18, P296, DOI 10.1109/TCBB.2019.2897679; Zhang M, 2018, SCIENCE, V360, P506, DOI 10.1126/science.aap7847; Zhang S., 2015, P 29 PACIFIC ASIA C, P73, DOI DOI 10.18653/V1/P16-2034; Zhang X, 2016, FRONT PHYSIOL, V7, DOI 10.3389/fphys.2016.00075	61	0	0	17	17	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1467-5463	1477-4054		BRIEF BIOINFORM	Brief. Bioinform.	JAN	2024	25	1							bbad472	10.1093/bib/bbad472	http://dx.doi.org/10.1093/bib/bbad472			12	Biochemical Research Methods; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Mathematical & Computational Biology	JL6Y9	38152979	Green Published, hybrid			2024-07-03	WOS:001173375300084
J	Sebok, M; Máté, A; Ring, O; Kovács, V; Lehoczki, R				Sebok, Miklos; Mate, Akos; Ring, Orsolya; Kovacs, Viktor; Lehoczki, Richard			Leveraging Open Large Language Models for Multilingual Policy Topic Classification: The Babel Machine Approach	SOCIAL SCIENCE COMPUTER REVIEW			English	Article; Early Access						quantitative text analysis; deep learning; large language models; classification policy agendas; comparative agendas project	TEXT; MANIFESTOS; POSITIONS; SENTIMENT	The article presents an open-source and freely available natural language processing system for comparative policy studies. The CAP Babel Machine allows for the automated classification of input files based on the 21 major policy topics of the codebook of the Comparative Agendas Project (CAP). By using multilingual XLM-RoBERTa large language models, the pipeline can produce state-of-the-art level outputs for selected pairs of languages and domains (such as media or parliamentary speech). For 24 cases out of 41, the weighted macro F1 of our language-domain models surpassed 0.75 (and, for 6 language-domain pairs, 0.90). Besides macro F1, for most major topic categories, the distribution of micro F1 scores is also centered around 0.75. These results show that the CAP Babel machine is a viable alternative for human coding in terms of validity at less cost and higher reliability. The proposed research design also has significant possibilities for scaling in terms of leveraging new models, covering new languages, and adding new datasets for fine-tuning. Based on our tests on manifesto data, a different policy classification scheme, we argue that model-pipeline frameworks such as the Babel Machine can, over time, potentially replace double-blind human coding for a multitude of comparative classification problems.	[Sebok, Miklos; Mate, Akos; Ring, Orsolya; Kovacs, Viktor; Lehoczki, Richard] HUN REN Ctr Social Sci, 4 Toth Kalman utca, H-1097 Budapest, Hungary		Sebok, M (corresponding author), HUN REN Ctr Social Sci, 4 Toth Kalman utca, H-1097 Budapest, Hungary.	sebok.miklos@tk.hun-ren.hu			Governments of Czechia, Hungary, Poland; Slovakia through Visegrad Grants from the International Visegrad Fund [22310057]; Mesterseges Intelligencia Nemzeti Laboratorium [RRF-2.3.1-21-2022-00004]; Horizon 2020 Framework Programme [101008468]; Hungarian Academy of Sciences; HUN-REN Cloud	Governments of Czechia, Hungary, Poland; Slovakia through Visegrad Grants from the International Visegrad Fund; Mesterseges Intelligencia Nemzeti Laboratorium; Horizon 2020 Framework Programme(Horizon 2020); Hungarian Academy of Sciences(Hungarian Academy of Sciences); HUN-REN Cloud	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by the Governments of Czechia, Hungary, Poland, and Slovakia through Visegrad Grants from the International Visegrad Fund (22310057), Mesterseges Intelligencia Nemzeti Laboratorium (RRF-2.3.1-21-2022-00004), Horizon 2020 Framework Programme (101008468, SLICES-RI), the V-Shift Momentum Project of the Hungarian Academy of Sciences and the HUN-REN Cloud (https://science-cloud.hu/).	Adler E. S., 2015, Congressional bills project: 1989-2014; Albaugh Q., 2014, 7th annual Comparative Agendas Project (CAP) conference, P1; Alexandrova P., 2014, Measuring the European council agenda: Introducing a new approach and dataset; Barberá P, 2021, POLIT ANAL, V29, P19, DOI 10.1017/pan.2020.8; Barbera P, 2019, AM POLIT SCI REV, V113, P883, DOI 10.1017/S0003055419000352; BAUMGARTNER FR, 1991, J POLIT, V53, P1044, DOI 10.2307/2131866; Baumgartner FR., 2019, Comparative policy agendas: Theory, tools, data, DOI 10.1093/ije/23.5.991; Belchior A. M., 2019, Portuguese agendas project; Bevan S., 2019, Comparative policy agendas: Theory, tools, data, V1st ed., P176, DOI [10.1093/oso/9780198835332.003.0020, DOI 10.1093/OSO/9780198835332.003.0020]; Bevan S., 2019, COMP POLICY AGENDAS, P17, DOI DOI 10.1093/OSO/9780198835332.003.0002; Bommasani R., 2022, OPPORTUNITIES RISKS, DOI DOI 10.48550/ARXIV.2108.07258; Borghetto E., 2019, Italian agendas project; Breeman G. E., 2009, 67th annual meeting of the Midwest political science association, P1; Breunig C., 2019, Comparative policy Agendas: Theory, tools, data, V1st ed., P97, DOI [10.1093/oso/9780198835332.003.0010, DOI 10.1093/OSO/9780198835332.003.0010]; Bulut A.T., 2019, COMP POLICY AGENDAS, P167, DOI DOI 10.1093/OSO/9780198835332.003.0019; Burscher B, 2015, ANN AM ACAD POLIT SS, V659, DOI 10.1177/0002716215569441; Chaqus-Bonafont L., Spanish policy Agendas; Collingwood L, 2012, J INF TECHNOL POLITI, V9, P298, DOI 10.1080/19331681.2012.669191; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dun L, 2021, POLIT COMMUN, V38, P140, DOI 10.1080/10584609.2020.1763529; Fahey K., 2019, Comparative policy agendas: Theory, tools, data, V1st ed., P200, DOI [10.1093/oso/9780198835332.003.0023, DOI 10.1093/OSO/9780198835332.003.0023]; Flaounas I, 2013, DIGIT JOURNAL, V1, P102, DOI 10.1080/21670811.2012.714928; Frantzeskakis N, 2023, LEGIS STUD QUART, V48, P623, DOI 10.1111/lsq.12404; Gava R, 2017, SWISS POLIT SCI REV, V23, P77, DOI 10.1111/spsr.12224; Green-Pedersen C., 2019, Danish policy agenda project; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; Grossman E., 2019, French agendas project; Guinaudeau I., 2018, Documentation on the coding of German manifestos; Hemphill L., 2019, 77th Annual Meeting of the Midwest Political Science Association, P1; Hillard D, 2008, J INF TECHNOL POLITI, V4, P31, DOI 10.1080/19331680801975367; John Peter., 2013, POLICY AGENDAS BRIT; Jungblut J, 2023, SCAND POLIT STUD, V46, P167, DOI 10.1111/1467-9477.12252; Jurka TP, 2012, R J, V4, P56; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Karan M., 2016, Proceedings of the 10th SIGHUM workshop on language technology for cultural heritage, social sciences, and humanities, P12, DOI [10.18653/v1/W16-2102, DOI 10.18653/V1/W16-2102]; Kleinnijenhuis J., 2013, Wetenschappelijk Ondezoeks- en Documentatiecentrum, Ministerie van Veiligheid en Justitiie; Krippendorff Klaus., 2004, Content analysis: An introduction to its methodology; Kuipers G., 2021, White House Studies, V14, P357; Laver M, 2000, AM J POLIT SCI, V44, P619, DOI 10.2307/2669268; Lehmann P, 2018, EUR J POLIT RES, V57, P1056, DOI 10.1111/1475-6765.12266; Loftis MW, 2020, POLICY STUD J, V48, P184, DOI 10.1111/psj.12245; Lucas C, 2015, POLIT ANAL, V23, P254, DOI 10.1093/pan/mpu019; McLaughlin J., 2019, Pennsylvania policy database project; McLaughlin JP, 2010, STATE POLIT POLICY Q, V10, P320, DOI 10.1177/153244001001000306; Merz N, 2016, RES POLITICS, V3, DOI 10.1177/2053168016643346; Mikhaylov S, 2012, POLIT ANAL, V20, P78, DOI 10.1093/pan/mpr047; Miller B, 2020, POLIT ANAL, V28, P532, DOI 10.1017/pan.2020.4; Navarretta C, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1428; Pires T, 2019, Arxiv, DOI arXiv:1906.01502; Purpura S., 2006, Proceedings of the 2006 international conference on digital government research, P219; Quinn K.M., 2006, MIDWEST POLITICAL SC, P1; Rauh C, 2018, J INF TECHNOL POLITI, V15, P319, DOI 10.1080/19331681.2018.1485608; Regel Sven, 2020, CRAN; Rytting CM, 2023, Arxiv, DOI arXiv:2306.02177; Sebk M., 2018, Hungarian policy agendas project; Sebk M., 2023, Computational Communication Research, V5, P1, DOI [10.5117/CCR2023.2.6.MATE, DOI 10.5117/CCR2023.2.6.MATE]; Sebk M., 2022, Quality and Quantity, V56, P3621, DOI [10.1007/s11135-021-01287-4, DOI 10.1007/S11135-021-01287-4]; Sebok M, 2021, POLIT ANAL, V29, P236, DOI 10.1017/pan.2020.27; The Policy Agendas Project at the University of Texas at Austin, 2017, Hearings; Timmermans A., 2019, Comparative policy agendas: Theory, tools, data, V1st ed., P129, DOI [10.1093/oso/9780198835332.003.0014, DOI 10.1093/OSO/9780198835332.003.0014]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Volkens A, 2009, HIST SOC RES, V34, P234; Walgrave S., Belgian agenda-setting project; White AR, 2015, AM POLIT SCI REV, V109, P129, DOI 10.1017/S0003055414000562; Wilkerson J, 2017, ANNU REV POLIT SCI, V20, P529, DOI 10.1146/annurev-polisci-052615-025542; Wolbrecht Christina., 2016, American Political Party Platforms: 1948-2007; Young L, 2012, POLIT COMMUN, V29, P205, DOI 10.1080/10584609.2012.671234	69	0	0	0	0	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0894-4393	1552-8286		SOC SCI COMPUT REV	Soc. Sci. Comput. Rev.	2024 JUN 11	2024										10.1177/08944393241259434	http://dx.doi.org/10.1177/08944393241259434		JUN 2024	23	Computer Science, Interdisciplinary Applications; Information Science & Library Science; Social Sciences, Interdisciplinary	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science; Social Sciences - Other Topics	TT4T6		hybrid			2024-07-03	WOS:001243503600001
J	Tan, RSYC; Lin, Q; Low, GH; Lin, RX; Goh, TC; Chang, CCE; Lee, FF; Chan, WY; Tan, WC; Tey, HJ; Leong, FL; Tan, HQ; Nei, WL; Chay, WY; Tai, DWM; Lai, GGY; Cheng, LTE; Wong, FY; Chua, MCH; Chua, MLK; Tan, DSW; Thng, CH; Tan, IBH; Ng, HT				Tan, Ryan Shea Ying Cong; Lin, Qian; Low, Guat Hwa; Lin, Ruixi; Goh, Tzer Chew; Chang, Christopher Chu En; Lee, Fung Fung; Chan, Wei Yin; Tan, Wei Chong; Tey, Han Jieh; Leong, Fun Loon; Tan, Hong Qi; Nei, Wen Long; Chay, Wen Yee; Tai, David Wai Meng; Lai, Gillianne Geet Yi; Cheng, Lionel Tim-Ee; Wong, Fuh Yong; Chua, Matthew Chin Heng; Chua, Melvin Lee Kiang; Tan, Daniel Shao Weng; Thng, Choon Hua; Tan, Iain Bee Huat; Ng, Hwee Tou			Inferring cancer disease response from radiology reports using large language models with data augmentation and prompting	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						large language models; natural language processing; cancer; radiology; healthcare	ONCOLOGY; OUTCOMES; TRIALS	Objective To assess large language models on their ability to accurately infer cancer disease response from free-text radiology reports. Materials and Methods We assembled 10 602 computed tomography reports from cancer patients seen at a single institution. All reports were classified into: no evidence of disease, partial response, stable disease, or progressive disease. We applied transformer models, a bidirectional long short-term memory model, a convolutional neural network model, and conventional machine learning methods to this task. Data augmentation using sentence permutation with consistency loss as well as prompt-based fine-tuning were used on the best-performing models. Models were validated on a hold-out test set and an external validation set based on Response Evaluation Criteria in Solid Tumors (RECIST) classifications. Results The best-performing model was the GatorTron transformer which achieved an accuracy of 0.8916 on the test set and 0.8919 on the RECIST validation set. Data augmentation further improved the accuracy to 0.8976. Prompt-based fine-tuning did not further improve accuracy but was able to reduce the number of training reports to 500 while still achieving good performance. Discussion These models could be used by researchers to derive progression-free survival in large datasets. It may also serve as a decision support tool by providing clinicians an automated second opinion of disease response. Conclusions Large clinical language models demonstrate potential to infer cancer disease response from radiology reports at scale. Data augmentation techniques are useful to further improve performance. Prompt-based fine-tuning can significantly reduce the size of the training dataset.	[Tan, Ryan Shea Ying Cong; Low, Guat Hwa; Tan, Wei Chong; Tey, Han Jieh; Leong, Fun Loon; Chay, Wen Yee; Tai, David Wai Meng; Lai, Gillianne Geet Yi; Tan, Daniel Shao Weng; Tan, Iain Bee Huat] Natl Canc Ctr Singapore, Div Med Oncol, Singapore, Singapore; [Tan, Ryan Shea Ying Cong; Tan, Wei Chong; Chay, Wen Yee; Tai, David Wai Meng; Lai, Gillianne Geet Yi; Cheng, Lionel Tim-Ee; Chua, Melvin Lee Kiang; Thng, Choon Hua; Tan, Iain Bee Huat] Duke NUS Med Sch, Singapore, Singapore; [Lin, Qian; Lin, Ruixi; Ng, Hwee Tou] Natl Univ Singapore, Dept Comp Sci, Singapore, Singapore; [Goh, Tzer Chew; Chang, Christopher Chu En; Lee, Fung Fung; Chan, Wei Yin] Natl Univ Singapore, Inst Syst Sci, Singapore, Singapore; [Tan, Hong Qi; Nei, Wen Long; Wong, Fuh Yong; Chua, Melvin Lee Kiang] Natl Canc Ctr Singapore, Div Radiat Oncol, Singapore, Singapore; [Cheng, Lionel Tim-Ee] Singapore Gen Hosp, Dept Diagnost Radiol, Singapore, Singapore; [Chua, Matthew Chin Heng] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore, Singapore; [Chua, Melvin Lee Kiang] Natl Canc Ctr Singapore, Data & Computat Sci Core, Singapore, Singapore; [Tan, Daniel Shao Weng] Natl Canc Ctr Singapore, Div Clin Trials & Epidemiol Sci, Singapore, Singapore; [Thng, Choon Hua] Natl Canc Ctr Singapore, Div Oncol Imaging, Singapore, Singapore; [Tan, Ryan Shea Ying Cong] Natl Canc Ctr Singapore, Div Med Oncol, 30 Hosp Blvd, Singapore 168583, Singapore	National Cancer Centre Singapore (NCCS); National University of Singapore; National University of Singapore; National University of Singapore; National Cancer Centre Singapore (NCCS); Singapore General Hospital; National University of Singapore; National Cancer Centre Singapore (NCCS); National Cancer Centre Singapore (NCCS); National Cancer Centre Singapore (NCCS); National Cancer Centre Singapore (NCCS)	Tan, RSYC (corresponding author), Natl Canc Ctr Singapore, Div Med Oncol, 30 Hosp Blvd, Singapore 168583, Singapore.	gmstycrs@duke-nus.edu.sg	Chua, Melvin LK/ABG-6045-2020; Tan, Ryan/KBA-0903-2024	Chua, Melvin LK/0000-0002-1648-1473; Tan, Ryan/0000-0002-1023-5730; Lin, Qian/0009-0000-7034-7331	A*STAR under its IAF-PPprogramme [H18/01/a0/019]; Singapore Health Services under the Singhealth Duke-NUS Oncology ACP Programme [08/FY2020/EX(SL)/74-A150]	A*STAR under its IAF-PPprogramme(Agency for Science Technology & Research (A*STAR)); Singapore Health Services under the Singhealth Duke-NUS Oncology ACP Programme	This research was supported by A*STAR under its IAF-PPprogramme (Award H18/01/a0/019) and Singapore Health Services under the Singhealth Duke-NUS Oncology ACP Programme (Award 08/FY2020/EX(SL)/74-A150).	Abernethy AP, 2010, J CLIN ONCOL, V28, P4268, DOI 10.1200/JCO.2010.28.5478; Alsentzer E., ARXIV; Bommasani R., ARXIV; Cheng LTE, 2010, J DIGIT IMAGING, V23, P119, DOI 10.1007/s10278-009-9215-7; Chollet F., 2015, About us; Griffith Sandra D, 2019, JCO Clin Cancer Inform, V3, P1, DOI 10.1200/CCI.19.00013; Griffith SD, 2019, ADV THER, V36, P2122, DOI 10.1007/s12325-019-00970-1; Gu Y., ARXIV; He P., ARXIV; Kehl KL, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27358-6; Kehl KL, 2020, JCO CLIN CANCER INFO, V4, P680, DOI 10.1200/CCI.20.00020; Kehl KL, 2019, JAMA ONCOL, V5, P1421, DOI 10.1001/jamaoncol.2019.1800; Kim C, 2015, JAMA INTERN MED, V175, P1992, DOI 10.1001/jamainternmed.2015.5868; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Ma XN, 2021, ADV THER, V38, P1843, DOI 10.1007/s12325-021-01659-0; Mueller A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8318; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Rubinstein SM, 2018, JCO CLIN CANCER INFO, V2, DOI 10.1200/CCI.17.00060; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Sherman RE, 2016, NEW ENGL J MED, V375, P2293, DOI 10.1056/NEJMsb1609216; Shin H., 2006, ARXIV; Shmueli B., 2019, MULTICLASS METRICS 2; Sorin V, 2020, LANCET ONCOL, V21, P1553, DOI 10.1016/S1470-2045(20)30615-X; Sun X., ARXIV; Tam D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4980; Visvanathan K, 2017, J CLIN ONCOL, V35, P1845, DOI 10.1200/JCO.2017.72.6414; Wilson MK, 2015, LANCET ONCOL, V16, pE32, DOI 10.1016/S1470-2045(14)70375-4; Wolf Thomas, 2020, P EMNLP, P38, DOI DOI 10.18653/V1/2020.EMNLP-DEMOS.6; Xie Q., 2023, ADV NEURAL INFORM PR, V33; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang Z., ARXIV; Yim WW, 2016, JAMA ONCOL, V2, P797, DOI 10.1001/jamaoncol.2016.0213	35	5	5	15	39	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	SEP 25	2023	30	10					1657	1664		10.1093/jamia/ocad133	http://dx.doi.org/10.1093/jamia/ocad133		JUL 2023	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	T4AD3	37451682	Green Published, hybrid			2024-07-03	WOS:001028143800001
J	Wei, YH; Guo, L; Lian, C; Chen, J				Wei, Yaohui; Guo, Lei; Lian, Cheng; Chen, Jue			ChatGPT: Opportunities, risks and priorities for psychiatry	ASIAN JOURNAL OF PSYCHIATRY			English	Article						Artificial intelligence; ChatGPT; Large language model; Psychiatry		The advancement of large language models such as ChatGPT, opens new possibilities in psychiatry but also invites scrutiny. This paper examines the potential opportunities, risks, and crucial areas of focus within this area. The active engagement of the mental health community is seen as critical to ensure ethical practice, equal access, and a patient-centric approach.	[Wei, Yaohui; Lian, Cheng; Chen, Jue] Shanghai Jiao Tong Univ, Shanghai Mental Hlth Ctr, Sch Med, Shanghai, Peoples R China; [Wei, Yaohui] Tech Univ Munich, Univ Hosp Rechts Der Isar, Dept Psychiat & Psychotherapy, Munich, Germany	Shanghai Jiao Tong University; Technical University of Munich; University of Munich	Chen, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai Mental Hlth Ctr, Sch Med, Shanghai, Peoples R China.	chenjue2088@163.com		Guo, Lei/0000-0003-1624-9604	National Natural Science Foundation of China [82071545]; Science and Technology Commission of Shanghai Municipality, Medical Innovation Research Special Project [20Y11906500]; Shanghai Clinical Research Center for Mental Health [19MC1911100]; Shanghai Jiao Tong University [YG2022ZD026]; Shanghai Municipal Hospital Development Center [SHDC12023122]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Commission of Shanghai Municipality, Medical Innovation Research Special Project; Shanghai Clinical Research Center for Mental Health; Shanghai Jiao Tong University; Shanghai Municipal Hospital Development Center	This work was supported by the National Natural Science Foundation of China (82071545) ; the Science and Technology Commission of Shanghai Municipality, Medical Innovation Research Special Project (20Y11906500) ; the Shanghai Clinical Research Center for Mental Health (19MC1911100) ; the Shanghai Jiao Tong University (YG2022ZD026) ; and the Shanghai Municipal Hospital Development Center (SHDC12023122) .	Au K., 2023, Int J. Surg.; Bakken S, 2023, J AM MED INFORM ASSN, V30, P1225, DOI 10.1093/jamia/ocad091; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; He YH, 2023, ASIAN J PSYCHIATR, V88, DOI 10.1016/j.ajp.2023.103726; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kuehn BM, 2013, JAMA-J AM MED ASSOC, V309, P756, DOI 10.1001/jama.2013.629; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Mulvaney-Day N, 2018, J GEN INTERN MED, V33, P335, DOI 10.1007/s11606-017-4181-0; Nuryana Z, 2023, ASIAN J PSYCHIATR, V84, DOI 10.1016/j.ajp.2023.103571; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Thornton J, 2023, ASIAN J PSYCHIATR, V81, DOI 10.1016/j.ajp.2023.103509; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Unesco C., 2021, Recommendation on the Ethics of Artificial Intelligence; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yeo Y.H., 2023, Clin. Mol. Hepatol.; Zhao S, 2015, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD010823.pub2	19	5	5	23	35	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1876-2018	1876-2026		ASIAN J PSYCHIATR	Asian J. Psychiatr.	DEC	2023	90								103808	10.1016/j.ajp.2023.103808	http://dx.doi.org/10.1016/j.ajp.2023.103808		OCT 2023	3	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	Y9AW4	37898100				2024-07-03	WOS:001108124800001
J	Savage, T; Nayak, A; Gallo, R; Rangan, E; Chen, JH				Savage, Thomas; Nayak, Ashwin; Gallo, Robert; Rangan, Ekanath; Chen, Jonathan H.			Diagnostic reasoning prompts reveal the potential for large language model interpretability in medicine	NPJ DIGITAL MEDICINE			English	Article								One of the major barriers to using large language models (LLMs) in medicine is the perception they use uninterpretable methods to make clinical decisions that are inherently different from the cognitive processes of clinicians. In this manuscript we develop diagnostic reasoning prompts to study whether LLMs can imitate clinical reasoning while accurately forming a diagnosis. We find that GPT-4 can be prompted to mimic the common clinical reasoning processes of clinicians without sacrificing diagnostic accuracy. This is significant because an LLM that can imitate clinical reasoning to provide an interpretable rationale offers physicians a means to evaluate whether an LLMs response is likely correct and can be trusted for patient care. Prompting methods that use diagnostic reasoning have the potential to mitigate the "black box" limitations of LLMs, bringing them one step closer to safe and effective use in medicine.	[Savage, Thomas; Nayak, Ashwin; Rangan, Ekanath; Chen, Jonathan H.] Stanford Univ, Dept Med, Stanford, CA 94305 USA; [Savage, Thomas; Nayak, Ashwin; Chen, Jonathan H.] Stanford Univ, Div Hosp Med, Stanford, CA 94305 USA; [Gallo, Robert] Palo Alto Vet Affairs Med Ctr, Palo Alto, CA USA; [Gallo, Robert] Stanford Univ, Dept Hlth Policy, Stanford, CA USA; [Chen, Jonathan H.] Stanford Univ, Stanford Ctr Biomed Informat Res, Stanford, CA USA; [Chen, Jonathan H.] Stanford Univ, Clin Excellence Res Ctr, Stanford, CA USA	Stanford University; Stanford University; Stanford University; Stanford University; Stanford University	Savage, T (corresponding author), Stanford Univ, Dept Med, Stanford, CA 94305 USA.; Savage, T (corresponding author), Stanford Univ, Div Hosp Med, Stanford, CA 94305 USA.	tsavage@stanford.edu		Chen, Jonathan H./0000-0002-4387-8740; Nayak, Ashwin/0009-0003-2024-3683	NIH/National Institute of Allergy and Infectious Diseases [1R01AI17812101]; NIH/National Institute on Drug Abuse Clinical Trials Network [UG1DA015815-CTN-0136]; Gordon and Betty Moore Foundation [12409]; Google Inc.; NIH-NCATS-CTSA [UL1TR003142]; VA Advanced Fellowship in Medical Informatics	NIH/National Institute of Allergy and Infectious Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID)); NIH/National Institute on Drug Abuse Clinical Trials Network; Gordon and Betty Moore Foundation(Gordon and Betty Moore Foundation); Google Inc.(Google Incorporated); NIH-NCATS-CTSA(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS)); VA Advanced Fellowship in Medical Informatics	J.H.C. has received research funding support in part by the NIH/National Institute of Allergy and Infectious Diseases (1R01AI17812101), NIH/National Institute on Drug Abuse Clinical Trials Network (UG1DA015815-CTN-0136), Gordon and Betty Moore Foundation (Grant #12409), Stanford Artificial Intelligence in Medicine and Imaging-Human-Centered Artificial Intelligence (AIMI-HAI) Partnership Grant, Google Inc. Research collaboration, American Heart Association-Strategically Focused Research Network-Diversity in Clinical Trials, and the NIH-NCATS-CTSA grant (UL1TR003142) for common research resources. R.G. is supported by a VA Advanced Fellowship in Medical Informatics. The views expressed are those of the authors and not necessarily those of the Department of Veterans Affairs or those of the United States Government.	Ali R, 2023, NEUROSURGERY, V93, P1353, DOI 10.1227/neu.0000000000002632; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; [Anonymous], UpToDate: industry-leading clinical decision support; [Anonymous], 2023, New England Journal of Medicine.; [Anonymous], 2023, MKSAP 19; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown T. B., PROC 34 INT C NEURAL, V159, P1877; DSP, The Demonstrate-Search-Predict Framework; Jin D, 2020, Arxiv, DOI arXiv:2009.13081; Joyce DW, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00751-9; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Khattab O, 2023, Arxiv, DOI [arXiv:2212.14024, DOI 10.48550/ARXIV.2212.14024]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lightman H, 2023, Arxiv, DOI [arXiv:2305.20050, DOI 10.48550/ARXIV.2305.20050]; Nayak A, 2023, JAMA INTERN MED, V183, P1026, DOI 10.1001/jamainternmed.2023.2561; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, OpenAI GPT-3.5 API [text-davinci-003] and GPT-4 API; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; StatPearls, NCBI Bookshelf; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]	28	3	3	17	17	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	JAN 24	2024	7	1							20	10.1038/s41746-024-01010-1	http://dx.doi.org/10.1038/s41746-024-01010-1			7	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	FU2H5	38267608	Green Submitted, gold			2024-07-03	WOS:001148298600001
J	Liu, XQ; Zhang, ZR				Liu, Xin-Qiao; Zhang, Zi-Ru			Potential use of large language models for mitigating students' problematic social media use: ChatGPT as an example	WORLD JOURNAL OF PSYCHIATRY			English	Editorial Material						Problematic use of social media; Social media; Large language models; ChatGPT; Chatbots	INTERNET ADDICTION; NETWORKING; SLEEP	The problematic use of social media has numerous negative impacts on individuals' daily lives, interpersonal relationships, physical and mental health, and more. Currently, there are few methods and tools to alleviate problematic social media, and their potential is yet to be fully realized. Emerging large language models (LLMs) are becoming increasingly popular for providing information and assistance to people and are being applied in many aspects of life. In mitigating problematic social media use, LLMs such as ChatGPT can play a positive role by serving as conversational partners and outlets for users, providing personalized information and resources, monitoring and intervening in problematic social media use, and more. In this process, we should recognize both the enormous potential and endless possibilities of LLMs such as ChatGPT, leveraging their advantages to better address problematic social media use, while also acknowledging the limitations and potential pitfalls of ChatGPT technology, such as errors, limitations in issue resolution, privacy and security concerns, and potential overreliance. When we leverage the advantages of LLMs to address issues in social media usage, we must adopt a cautious and ethical approach, being vigilant of the potential adverse effects that LLMs may have in addressing problematic social media use to better harness technology to serve individuals and society.	[Liu, Xin-Qiao; Zhang, Zi-Ru] Tianjin Univ, Sch Educ, 135 Yaguan Rd, Tianjin 300350, Peoples R China	Tianjin University	Liu, XQ (corresponding author), Tianjin Univ, Sch Educ, 135 Yaguan Rd, Tianjin 300350, Peoples R China.	xinqiaoliu@pku.edu.cn	Liu, Xinqiao/AFG-0572-2022	Liu, Xinqiao/0000-0001-6620-4119				Alonzo R, 2021, SLEEP MED REV, V56, DOI 10.1016/j.smrv.2020.101414; Aminah S, 2023, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdad065; Andreassen CS, 2014, CURR PHARM DESIGN, V20, P4053, DOI 10.2174/13816128113199990616; [Anonymous], 2023, OpenAI Privacy policy; [Anonymous], Statista Growth of monthly active users of selected social media platforms worldwide from 2019 to 2021; Austermann MI, 2021, J CLIN MED, V10, DOI 10.3390/jcm10040617; Beatty C, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.847991; Benjamin CL, 2011, CHILD ADOL PSYCH CL, V20, P179, DOI 10.1016/j.chc.2011.01.011; Bernhardt JM, 2013, HEALTH EDUC BEHAV, V40, P129, DOI 10.1177/1090198113483140; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Cao XJ, 2022, WORLD J PSYCHIATR, V12, P1287, DOI 10.5498/wjp.v12.i10.1287; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Datareportal, 2023, Global Social Media Statistics; Drahosová M, 2017, PROCEDIA COMPUT SCI, V109, P1005, DOI 10.1016/j.procs.2017.05.446; Echeburúa E, 2010, ADICCIONES, V22, P91, DOI 10.20882/adicciones.196; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Eshghie M., 2023, SSRN Electronic J; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gao JL, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231924; Gao WJ, 2023, WORLD J PSYCHIATR, V13, P361, DOI 10.5498/wjp.v13.i6.361; Gentile B, 2012, COMPUT HUM BEHAV, V28, P1929, DOI 10.1016/j.chb.2012.05.012; George MJ, 2018, CHILD DEV, V89, P78, DOI 10.1111/cdev.12819; Gosling SD, 2011, CYBERPSYCH BEH SOC N, V14, P483, DOI 10.1089/cyber.2010.0087; Grodniewicz JP, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1190084; Hamdoun S, 2023, IEEE TECHNOL SOC MAG, V42, P25, DOI 10.1109/MTS.2023.3241309; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; He YH, 2023, ASIAN J PSYCHIATR, V88, DOI 10.1016/j.ajp.2023.103726; Hou YB, 2019, CYBERPSYCHOLOGY, V13, DOI 10.5817/CP2019-1-4; Huang AH, 2023, CONTEMP ACCOUNT RES, V40, P806, DOI 10.1111/1911-3846.12832; Islam MS, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.647386; Karaer Y, 2019, COMPR PSYCHIAT, V92, P22, DOI 10.1016/j.comppsych.2019.03.003; Kardefelt-Winther D, 2014, COMPUT HUM BEHAV, V31, P351, DOI 10.1016/j.chb.2013.10.059; Khawaja Z, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1278186; Kittinger R, 2012, CYBERPSYCH BEH SOC N, V15, P324, DOI 10.1089/cyber.2010.0410; Kretzschmar K, 2019, BIOMED INFORM INSIGH, V11, DOI 10.1177/1178222619829083; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Kuss DJ, 2011, INT J ENV RES PUB HE, V8, P3528, DOI 10.3390/ijerph8093528; Levenson JC, 2016, PREV MED, V85, P36, DOI 10.1016/j.ypmed.2016.01.001; Liu HF, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120600; Liu M, 2009, COMPUT HUM BEHAV, V25, P1306, DOI 10.1016/j.chb.2009.06.002; Liu XQ, 2023, WORLD J PSYCHIATR, V13, DOI 10.5498/wjp.v13.i7.409; Liu XQ, 2023, WORLD J CLIN CASES, V11, P1442, DOI 10.12998/wjcc.v11.i7.1442; Lucas GM, 2014, COMPUT HUM BEHAV, V37, P94, DOI 10.1016/j.chb.2014.04.043; MediaBriefAdmin, 2020, KalaGato Report: COVID 19 Digital Impact: A Boon for Social Media?; Miner AS, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0280-0; Mohr DC, 2017, ANNU REV CLIN PSYCHO, V13, P23, DOI 10.1146/annurev-clinpsy-032816-044949; Morris R III, 2023, CURR BEHAV NEUROSCI, V10, P65, DOI 10.1007/s40473-023-00261-8; Orzack MH, 2006, CYBERPSYCHOL BEHAV, V9, P348, DOI 10.1089/cpb.2006.9.348; Perez E, 2021, SLEEP HEALTH, V7, P474, DOI 10.1016/j.sleh.2021.03.004; Praveen SV, 2023, ANN BIOMED ENG, V51, P1654, DOI 10.1007/s10439-023-03222-0; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Van Noorden R, 2023, NATURE, V620, P258, DOI 10.1038/d41586-023-02470-3; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wu XD., 2023, J Inf and Intelligence; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yen JY, 2007, CYBERPSYCHOL BEHAV, V10, P323, DOI 10.1089/cpb.2006.9948	59	0	0	10	10	BAISHIDENG PUBLISHING GROUP INC	PLEASANTON	7041 Koll Center Parkway, Suite 160, PLEASANTON, CA, UNITED STATES	2220-3206			WORLD J PSYCHIATR	World J. Psychiatr.	MAR 19	2024	14	3								10.5498/wjp.v14.i3.334	http://dx.doi.org/10.5498/wjp.v14.i3.334			9	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	NV3R3	38617990	gold, Green Published			2024-07-03	WOS:001203197100003
J	Han, J; Zheng, Z; Lu, XZ; Chen, KY; Lin, JR				Han, Jin; Zheng, Zhe; Lu, Xin-Zheng; Chen, Ke-Yin; Lin, Jia-Rui			Enhanced earthquake impact analysis based on social media texts via large language model	INTERNATIONAL JOURNAL OF DISASTER RISK REDUCTION			English	Article						Earthquake; Impact assessment; Text mining; Social media; BERT; Social impact; Large language model	CLASSIFICATION; INFORMATION; AWARENESS	Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain -specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake -related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain -specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword -based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27 %, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87 % to 84.33 %. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post -disaster emergency responses to create more resilient cities.	[Han, Jin; Zheng, Zhe; Lu, Xin-Zheng; Chen, Ke-Yin; Lin, Jia-Rui] Tsinghua Univ, Dept Civil Engn, Beijing 100084, Peoples R China; [Lin, Jia-Rui] Minist Housing & Urban Rural Dev, Key Lab Digital Construct & Digital Twin, Beijing 100084, Peoples R China	Tsinghua University	Lin, JR (corresponding author), Tsinghua Univ, Dept Civil Engn, Beijing 100084, Peoples R China.; Lin, JR (corresponding author), Minist Housing & Urban Rural Dev, Key Lab Digital Construct & Digital Twin, Beijing 100084, Peoples R China.	lin611@tsinghua.edu.cn		Lu, Xinzheng/0000-0002-3313-7420	National Natural Science Foundation of China [52238011, 52378306, 72091512]; Tencent Foundation through the XPLORER PRIZE	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Tencent Foundation through the XPLORER PRIZE	The authors are grateful for the financial support received from the National Natural Science Foundation of China (No. 52238011, 52378306, 72091512) and the Tencent Foundation through the XPLORER PRIZE.	Adegoke D, 2023, SUSTAIN FUTURES, V5, DOI 10.1016/j.sftr.2023.100113; Ahadzadeh S, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13094814; [Anonymous], 2020, GB/T 17742; Arbane M, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118710; Binsaeed K, 2020, INT J ADV COMPUT SC, V11, P11; Cai JJ, 2018, I COMP CONF WAVELET, P123, DOI 10.1109/ICCWAMTIP.2018.8632592; Chen L., 2022, Weibo-search; Chen L., 2020, Crowding Out the Crowd: the Transformation of Network Disaster Communication Patterns on Weibo; Chen Y., 2015, Master's Thesis; Chen YD, 2022, INT J DISAST RISK RE, V68, DOI 10.1016/j.ijdrr.2021.102713; Chen YD, 2020, J MANAGE ENG, V36, DOI 10.1061/(ASCE)ME.1943-5479.0000836; Cui P, 2011, NAT HAZARDS, V56, P19, DOI 10.1007/s11069-009-9392-1; Dasari S.K, 2023, Int. J. Inf. Technol., P1; DesRoches R, 2011, EARTHQ SPECTRA, V27, pS1, DOI 10.1193/1.3630129; Devaraj A, 2020, INT J DISAST RISK RE, V51, DOI 10.1016/j.ijdrr.2020.101757; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Hong HC, 2016, GEOMAT NAT HAZ RISK, V7, P450, DOI 10.1080/19475705.2015.1060639; Huang QY, 2015, ISPRS INT J GEO-INF, V4, P1549, DOI 10.3390/ijgi4031549; Imran M, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1021; Jing Wang, 2012, 2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC 2012), P44, DOI 10.1109/CyberC.2012.17; Kouzis-Loukas D., 2016, Learning Scrapy; Kryvasheyeu Y, 2016, SCI ADV, V2, DOI 10.1126/sciadv.1500779; Kundu S, 2018, 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P790, DOI 10.1109/ASONAM.2018.8508695; Lai SW, 2015, AAAI CONF ARTIF INTE, P2267; Li LY, 2023, INT J DISAST RISK RE, V98, DOI 10.1016/j.ijdrr.2023.104062; Li LY, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102378; Li S, 2018, Arxiv, DOI arXiv:1805.06504; Lin BB, 2022, INT J DIGIT EARTH, V15, P868, DOI 10.1080/17538947.2022.2070677; Lowande RD, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13085079; Lu XZ, 2020, EARTHQ SPECTRA, V36, P806, DOI 10.1177/8755293019891724; Lv QZ, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12020046; Macintyre AG, 2006, PREHOSP DISASTER MED, V21, P4, DOI 10.1017/S1049023X00003253; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mori N, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL049210; Ogie RI, 2022, INT J DISAST RISK RE, V70, DOI 10.1016/j.ijdrr.2022.102783; Papadopoulos AN, 2023, EARTHQ SPECTRA, V39, P938, DOI 10.1177/87552930231153424; Ragini J.R., 2016, 2016 IEEE INT C COMP, P1; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Tounsi A, 2023, NAT HAZARDS, V116, P2819, DOI 10.1007/s11069-023-05842-0; Vani S., 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P331, DOI 10.1109/ICOEI.2019.8862686; Wadud M. A. H., 2022, International Journal of Information Management Data Insights, V2; Wang YZ, 2015, STAT INTERFACE, V8, P1; Wu DS, 2018, DECIS SUPPORT SYST, V111, P48, DOI 10.1016/j.dss.2018.04.005; Xing ZY, 2021, INT J DISAST RISK RE, V58, DOI 10.1016/j.ijdrr.2021.102200; Xu X, 2021, ADV ENG INFORM, V48, DOI 10.1016/j.aei.2021.101288; Yao KZ, 2021, INT J DISAST RISK RE, V58, DOI 10.1016/j.ijdrr.2021.102217; Yu MZ, 2019, INT J DIGIT EARTH, V12, P1230, DOI 10.1080/17538947.2019.1574316; Zekkos D., 2019, P 2 INT C NAT HAZ IN, P1; Zhang C, 2019, INT J INFORM MANAGE, V49, P190, DOI 10.1016/j.ijinfomgt.2019.04.004; Zheng Z, 2022, AUTOMAT CONSTR, V142, DOI 10.1016/j.autcon.2022.104524; Zheng Z, 2022, COMPUT IND, V142, DOI 10.1016/j.compind.2022.103733; Zhou YC, 2022, COMPUT IND, V142, DOI 10.1016/j.compind.2022.103746; Zou L, 2018, ANN AM ASSOC GEOGR, V108, P1422, DOI 10.1080/24694452.2017.1421897	53	0	0	2	2	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2212-4209			INT J DISAST RISK RE	Int. J. Disaster Risk Reduct.	JUL	2024	109								104574	10.1016/j.ijdrr.2024.104574	http://dx.doi.org/10.1016/j.ijdrr.2024.104574			19	Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences; Water Resources	Science Citation Index Expanded (SCI-EXPANDED)	Geology; Meteorology & Atmospheric Sciences; Water Resources	UN5Y7					2024-07-03	WOS:001248764300001
C	Leung, M; Murphy, G			IEEE	Leung, Mira; Murphy, Gail			On Automated Assistants for Software Development: The Role of LLMs	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		automation; machine learning; artificial intelligence; large language models; software development productivity		Software developers handle many complex tasks that include gathering and applying domain knowledge, coordinating subtasks, designing interfaces, turning ideas into elegant code, and more. They must switch contexts between these tasks, incurring more cognitive costs. Recent advances in large language models (LLMs) open up new possibilities for moving beyond the support provided by automated assistants (AAs) available today. In this paper, we explore if a human memory model can provide a framework for the systematic investigation of AAs for software development based on LLMs and other new technologies.	[Leung, Mira; Murphy, Gail] Univ British Columbia, Vancouver, BC, Canada	University of British Columbia	Leung, M (corresponding author), Univ British Columbia, Vancouver, BC, Canada.	miralng@cs.ubc.ca; murphy@cs.ubc.ca			NSERC [RGPIN-2022-03139]	NSERC(Natural Sciences and Engineering Research Council of Canada (NSERC))	This work was partly funded via NSERC by a post-graduate scholarship and a grant (RGPIN-2022-03139). The first author is also affiliated with Google.	Anderson J. R., 1993, Rules of the mind, P17; Anvik J, 2011, ACM T SOFTW ENG METH, V20, DOI 10.1145/2000791.2000794; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chattopadhyay S, 2019, PROC INT CONF SOFTW, P373, DOI 10.1109/ICSE.2019.00051; Hannemann Jan., 2005, AOSD 05, P135; Houde S., 2022, ANN C NEUR INF PROC; Hsiao S., 2023, What's ahead for Bard: More global, more visual, more integrated; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Khaliq Z, 2022, COMPUTER, V55, P64, DOI 10.1109/MC.2021.3136791; Lovett M. C., 1999, Modeling working memory in a unified architecture: An act-r perspective; Luo ZH, 2023, Arxiv, DOI arXiv:2303.15621; McNutt A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580940; Muslu K, 2012, ACM SIGPLAN NOTICES, V47, P669, DOI 10.1145/2398857.2384665; Parnin C., A cognitive neuroscience perspective on memory for programming tasks; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Perry N, 2023, Arxiv, DOI [arXiv:2211.03622, DOI 10.48550/ARXIV.2211.03622, 10.48550/arxiv.2211.03622]; Ritter FE, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1488; Robilliard PN, 1999, COMMUN ACM, V42, P87, DOI 10.1145/291469.291476; Ross Steven I., 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P491, DOI 10.1145/3581641.3584037; Siegmund J, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P140, DOI 10.1145/3106237.3106268; VONMAYRHAUSER A, 1995, COMPUTER, V28, P44, DOI 10.1109/2.402076; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Yetistiren B, 2023, Arxiv, DOI arXiv:2304.10778	23	0	0	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1737	1741		10.1109/ASE56229.2023.00035	http://dx.doi.org/10.1109/ASE56229.2023.00035			5	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Bronze			2024-07-03	WOS:001103357200145
J	Remadi, A; El Hage, K; Hobeika, Y; Bugiotti, F				Remadi, Adel; El Hage, Karim; Hobeika, Yasmina; Bugiotti, Francesca			To prompt or not to prompt: Navigating the use of Large Language Models for integrating and modeling heterogeneous data	DATA & KNOWLEDGE ENGINEERING			English	Article						Data engineering; Large language models; Conceptual schema modeling; Entity resolution; Data integration; Property graph models		Manually integrating data of diverse formats and languages is vital to many artificial intelligence applications. However, the task itself remains challenging and time-consuming. This paper highlights the potential of Large Language Models (LLMs) to streamline data extraction and resolution processes. Our approach aims to address the ongoing challenge of integrating heterogeneous data sources, encouraging advancements in the field of data engineering. Applied on the specific use case of learning disorders in higher education, our research demonstrates LLMs' capability to effectively extract data from unstructured sources. It is then further highlighted that LLMs can enhance data integration by providing the ability to resolve entities originating from multiple data sources. Crucially, the paper underscores the necessity of preliminary data modeling decisions to ensure the success of such technological applications. By merging human expertise with LLM-driven automation, this study advocates for the further exploration of semi-autonomous data engineering pipelines.	[Remadi, Adel; El Hage, Karim; Hobeika, Yasmina; Bugiotti, Francesca] Cent Supelec, 3 Rue Joliot Curie, F-91190 Gif Sur Yvette, Ile De France, France; [Bugiotti, Francesca] Univ Paris Saclay, Lab Interdisciplinaire Sci Numer, CNRS, F-91400 Orsay, Ile De France, France	Universite Paris Saclay; Universite Paris Cite; Universite Paris Saclay; Centre National de la Recherche Scientifique (CNRS)	El Hage, K (corresponding author), Cent Supelec, 3 Rue Joliot Curie, F-91190 Gif Sur Yvette, Ile De France, France.	adel.remadi@student-cs.fr; karim.elhage@student-cs.fr; yasmina.hobeika@student-cs.fr; francesca.bugiotti@centralesupelec.fr						Ajith A, 2023, Arxiv, DOI [arXiv:2307.00259, 10.48550/arXiv.2307.00259, DOI 10.48550/ARXIV.2307.00259]; Alonso Gustavo, 2023, SIGMOD/PODS '23: Companion of the 2023 International Conference on Management of Data, P261, DOI 10.1145/3555041.3589360; Aly R, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1516; Angles R., 2018, Data-Centric Systems and Applications, P1, DOI DOI 10.1007/978-3-319-96193-41; Angles R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1322432.1322433; Arachchige IAN, 2023, PROCEEDINGS OF THE 2023 INTERNATIONAL WORKSHOP ON HISTORICAL DOCUMENT IMAGING AND PROCESSING, HIP 2023, P85, DOI 10.1145/3604951.3605514; Arocena PC, 2015, PROC VLDB ENDOW, V9, P108; Arora S, 2023, PROC VLDB ENDOW, V17, P92, DOI 10.14778/3626292.3626294; Atzeni P, 2020, COMPUT STAND INTER, V67, DOI 10.1016/j.csi.2016.10.003; Balaguer A, 2024, Arxiv, DOI [arXiv:2401.08406, 10.48550/arXiv.2401.08406, DOI 10.48550/ARXIV.2401.08406]; Barbella M, 2023, PATTERN RECOGN LETT, V166, P134, DOI 10.1016/j.patrec.2023.01.007; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bernstein P.A., 2003, C INN DAT SYST RES C; Bork D., 2023, arXiv, DOI [10.48550/arXiv.2303.06758, DOI 10.48550/ARXIV.2303.06758]; Bose P, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188319; Cappuzzo R, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1335, DOI 10.1145/3318464.3389742; Carta S, 2023, Arxiv, DOI arXiv:2307.01128; Cattuto Ciro., 2013, Em First international workshop on graph data management experiences and systems, P11, DOI DOI 10.1145/2484425.2484442; Chen Z., 2023, C INN DAT SYST RES C; Davies I, 2006, DATA KNOWL ENG, V58, P358, DOI 10.1016/j.datak.2005.07.007; Doan A, 2012, PRINCIPLES OF DATA INTEGRATION, P1; El Hage K., 2023, IEEE INT C BIG DAT, P3134, DOI [10.1109/BigData59044.2023.10386535, DOI 10.1109/BIGDATA59044.2023.10386535]; Fernandez RC, 2023, PROC VLDB ENDOW, V16, P3302; Garmendia A., 2023, Optimising the Software Development Process with Artificial Intelligence, P93, DOI [10.1007/978-981-19-9948-24, DOI 10.1007/978-981-19-9948-24]; Golshan B, 2017, PODS'17: PROCEEDINGS OF THE 36TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P101, DOI 10.1145/3034786.3056124; Gupta A, 2023, DATA KNOWL ENG, V145, DOI 10.1016/j.datak.2023.102141; Halevy A., 2006, P 32 INT C VER LARG, P9; Halevy A, 2023, PROC VLDB ENDOW, V16, P4114, DOI 10.14778/3611540.3611634; Halevy A, 2023, Arxiv, DOI [arXiv:2304.04576, 10.48550/arXiv.2304.04576, DOI 10.48550/ARXIV.2304.04576]; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Hewasinghage M, 2018, LECT NOTES COMPUT SC, V11157, P488, DOI 10.1007/978-3-030-00847-5_35; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jindal A., 2024, C INN DAT SYST RES C; Johnson M., 2017, Google's multilingual neural machine translation system: Enabling zero-shot translation, V5, P339, DOI 10.1162/tacla00065; Kalinowski A., 2023, IEEE INT C BIG DAT B, P383, DOI [10.1109/BigData59044.2023.10386670, DOI 10.1109/BIGDATA59044.2023.10386670]; Kayali M, 2024, Arxiv, DOI [arXiv:2306.09610, 10.48550/arXiv.2306.09610, DOI 10.48550/ARXIV.2306.09610]; Li HH, 2024, Arxiv, DOI [arXiv:2401.03426, 10.48550/arXiv.2401.03426, DOI 10.48550/ARXIV.2401.03426]; Li P, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15339; Li YL, 2020, PROC VLDB ENDOW, V14, P50, DOI 10.14778/3421424.3421431; Lim W.S., 2023, C INN DAT SYST RES C; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Lukyanenko R, 2019, LECT NOTES BUS INF P, V350, P170, DOI 10.1007/978-3-030-21297-1_15; Maass W, 2021, DATA KNOWL ENG, V134, DOI 10.1016/j.datak.2021.101909; Mihindukulasooriya N, 2023, LECT NOTES COMPUT SC, V14266, P247, DOI 10.1007/978-3-031-47243-5_14; Min Sewon, 2022, P 2022 C EMPIRICAL M, P11048, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.759; Nananukul N, 2024, Arxiv, DOI [arXiv:2310.06174, 10.48550/arXiv.2310.06174, DOI 10.48550/ARXIV.2310.06174]; Narayan A, 2022, PROC VLDB ENDOW, V16, P738, DOI 10.14778/3574245.3574258; Narducci F, 2016, DATA KNOWL ENG, V106, P18, DOI 10.1016/j.datak.2016.08.001; Nayak Ameya., 2013, INT J APPL INFORM SY, V5, P16, DOI [10.5120/ijais12-450888, DOI 10.5120/IJAIS12-450888]; Neo4j, 2023, K-means clustering; Neo4j, 2024, Neo4j cypher query language; Nishikawa N., 2023, IEEE INT C BIG DAT B, P1793, DOI [10.1109/BigData59044.2023.10386475, DOI 10.1109/BIGDATA59044.2023.10386475]; Peeters R, 2024, Arxiv, DOI [arXiv:2310.11244, 10.48550/arXiv.2310.11244]; Picco G, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3, P357; Raharjana IK, 2021, IEEE ACCESS, V9, P53811, DOI 10.1109/ACCESS.2021.3070606; Roitsch J., 2019, Science, V7, P81, DOI DOI 10.11648/J.SJEDU.20190704.11; Rosenberg M., 1965, SOC ADOLESCENT SELF; Russo R., 2023, IEEE INT C BIG DAT B, P1, DOI [10.1109/BigData59044.2023.10386684, DOI 10.1109/BIGDATA59044.2023.10386684]; Sahatqija K, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P216, DOI 10.23919/MIPRO.2018.8400041; Schummer F, 2022, DATA-CENTRIC ENG, V3, DOI 10.1017/dce.2022.33; Sharma A., 2023, IEEE INT C BIG DAT B, P1824, DOI [10.1109/BigData59044.2023.10386931, DOI 10.1109/BIGDATA59044.2023.10386931]; Shaywitz SE, 2005, BIOL PSYCHIAT, V57, P1301, DOI 10.1016/j.biopsych.2005.01.043; Sivarajah U, 2017, J BUS RES, V70, P263, DOI 10.1016/j.jbusres.2016.08.001; Storey VC, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3589338; Sun Q, 2024, Arxiv, DOI [arXiv:2401.13598, 10.48550/arXiv.2401.13598, DOI 10.48550/ARXIV.2401.13598]; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Tang YC, 2023, DATA KNOWL ENG, V145, DOI 10.1016/j.datak.2022.102129; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Trujillo J, 2021, DATA KNOWL ENG, V135, DOI 10.1016/j.datak.2021.101911; Trummer I, 2022, PROC VLDB ENDOW, V15, P3770, DOI 10.14778/3554821.3554896; Trummer I, 2022, INT CONF MANAGE DATA, P190, DOI 10.1145/3514221.3517843; Urban M, 2023, PROCEEDINGS OF THE SIXTH INTERNATIONAL WORKSHOP ON EXPLOITING ARTIFICIAL INTELLIGENCE TECHNIQUES FOR DATA MANAGEMENT, AIDM 2023, DOI 10.1145/3593078.3593933; Vrailexia, 2023, About us; VRAILEXIA, 2024, Into The Box; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Wang X, 2023, P A I C C AUT ROBOT, P350, DOI 10.1109/ICCAR57134.2023.10151736; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu D, 2023, DATA KNOWL ENG, V148, DOI 10.1016/j.datak.2023.102218; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Xu HR, 2024, Arxiv, DOI [arXiv:2401.08417, 10.48550/arXiv.2401.08417]; Zaidi MA, 2021, LECT NOTES COMPUT SC, V12957, P522, DOI 10.1007/978-3-030-87013-3_39	82	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0169-023X	1872-6933		DATA KNOWL ENG	Data Knowl. Eng.	JUL	2024	152								102313	10.1016/j.datak.2024.102313	http://dx.doi.org/10.1016/j.datak.2024.102313			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TO0Y1		hybrid			2024-07-03	WOS:001242097800001
J	Lang, SG; Vitale, J; Fekete, TF; Haschtmann, D; Reitmeir, R; Ropelato, M; Puhakka, J; Galbusera, F; Loibl, M				Lang, Siegmund; Vitale, Jacopo; Fekete, Tamas F.; Haschtmann, Daniel; Reitmeir, Raluca; Ropelato, Mario; Puhakka, Jani; Galbusera, Fabio; Loibl, Markus			Are large language models valid tools for patient information on lumbar disc herniation? The spine surgeons' perspective	BRAIN AND SPINE			English	Article						Lumbar disc herniation; Patient education; Large language models; ChatGPT; Google bard; AI evaluation	SURGICAL INTERVENTIONS	Introduction: Generative AI is revolutionizing patient education in healthcare, particularly through chatbots that offer personalized, clear medical information. Reliability and accuracy are vital in AI-driven patient education. Research question: How effective are Large Language Models (LLM), such as ChatGPT and Google Bard, in delivering accurate and understandable patient education on lumbar disc herniation? Material and methods: Ten Frequently Asked Questions about lumbar disc herniation were selected from 133 questions and were submitted to three LLMs. Six experienced spine surgeons rated the responses on a scale from "excellent" to "unsatisfactory," and evaluated the answers for exhaustiveness, clarity, empathy, and length. Statistical analysis involved Fleiss Kappa, Chi-square, and Friedman tests. Results: Out of the responses, 27.2% were excellent, 43.9% satisfactory with minimal clarification, 18.3% satisfactory with moderate clarification, and 10.6% unsatisfactory. There were no significant differences in overall ratings among the LLMs (p = 0.90); however, inter-rater reliability was not achieved, and large differences among raters were detected in the distribution of answer frequencies. Overall, ratings varied among the 10 answers (p = 0.043). The average ratings for exhaustiveness, clarity, empathy, and length were above 3.5/5. Discussion and conclusion: LLMs show potential in patient education for lumbar spine surgery, with generally positive feedback from evaluators. The new EU AI Act, enforcing strict regulation on AI systems, highlights the need for rigorous oversight in medical contexts. In the current study, the variability in evaluations and occasional inaccuracies underline the need for continuous improvement. Future research should involve more advanced models to enhance patient-physician communication.	[Lang, Siegmund] Univ Hosp Regensburg, Dept Trauma Surg, Franz Joseph Str Allee 11, D-93053 Regensburg, Germany; [Vitale, Jacopo; Fekete, Tamas F.; Haschtmann, Daniel; Reitmeir, Raluca; Ropelato, Mario; Puhakka, Jani; Galbusera, Fabio; Loibl, Markus] Schulthess Klin, Spine Ctr, Zurich, Switzerland	University of Regensburg; Schulthess Clinic	Lang, SG (corresponding author), Univ Hosp Regensburg, Dept Trauma Surg, Franz Joseph Str Allee 11, D-93053 Regensburg, Germany.	Siegmund.lang@ukr.de; jacopo.vitale@kws.ch; Tamas.Fekete@kws.ch; daniel.haschtmann@kws.ch; raluca.reitmeir@kws.ch; Mario.Ropelato@kws.ch; jani.puhakka@kws.ch; Fabio.Galbusera@kws.ch; markus.loibl@kws.ch	Vitale, Jacopo Antonino/B-1758-2017; Fekete, Tamas F./A-8512-2011; Galbusera, Fabio/J-8618-2016	Vitale, Jacopo Antonino/0000-0002-7537-079X; Fekete, Tamas F./0000-0001-5231-5600; Galbusera, Fabio/0000-0003-1826-9190				Al-Medfa MK, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14744; [Anonymous], Large Language Models: A New Moore's Law?" n.d; [Anonymous], 2019, Ethics Guidelines for Trustworthy AI; [Anonymous], 2023, Macedonian J. Med. Sci.; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bai XL, 2021, MEDICINE, V100, DOI 10.1097/MD.0000000000024747; Bickmore TW, 2018, J MED INTERNET RES, V20, DOI 10.2196/11510; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Crook BS, 2023, J HAND SURG-AM, V48, P1122, DOI 10.1016/j.jhsa.2023.08.003; Daraz L, 2019, J GEN INTERN MED, V34, P1884, DOI 10.1007/s11606-019-05109-0; Engel-Yeger B, 2018, DISABIL REHABIL, V40, P302, DOI 10.1080/09638288.2016.1253114; EU AI Act, European Parliament and Council Reach Agreement | Perspectives. Events; Feng F, 2017, PAIN PHYSICIAN, V20, pE862; Fritsch SJ, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221116772; Ghassemi M, 2019, LANCET DIGIT HEALTH, V1, pE157, DOI 10.1016/S2589-7500(19)30084-6; Gottlieb S, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.3909; Hornung AL, 2022, EUR SPINE J, V31, P2057, DOI 10.1007/s00586-022-07176-0; Ionescu D, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1147254; Kögl N, 2021, ACTA NEUROCHIR, V163, P275, DOI 10.1007/s00701-020-04614-0; Kompa B, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00367-3; Matheny ME, 2020, JAMA-J AM MED ASSOC, V323, P509, DOI 10.1001/jama.2019.21579; McMullan M, 2006, PATIENT EDUC COUNS, V63, P24, DOI 10.1016/j.pec.2005.10.006; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Monteith S, 2024, BRIT J PSYCHIAT, V224, P33, DOI 10.1192/bjp.2023.136; Ott S, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02433-3; PatientEngagementHIT, 2023, ChatGPT continues to prove useful for patient education; Pearson A, 2012, SPINE, V37, P140, DOI 10.1097/BRS.0b013e3182276b2b; Perlis RH, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.35924; Qiao SF, 2023, Arxiv, DOI [arXiv:2212.09597, DOI 10.48550/ARXIV.2212.09597]; Raheja T., 2023, Cisco. Tech. Blog; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Roiha M, 2023, ACTA NEUROCHIR, V165, P797, DOI 10.1007/s00701-023-05522-9; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Stroop A, 2023, EUR SPINE J, DOI 10.1007/s00586-023-07975-z; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Wan ZY, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.814531; Wei FL, 2021, FRONT SURG, V8, DOI 10.3389/fsurg.2021.679142	38	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2772-5294			BRAIN SPINE	Brain Spine		2024	4								102804	10.1016/j.bas.2024.102804	http://dx.doi.org/10.1016/j.bas.2024.102804			8	Clinical Neurology	Emerging Sources Citation Index (ESCI)	Neurosciences & Neurology	SO2B6	38706800	gold, Green Published			2024-07-03	WOS:001235316400001
J	Lane, SN				Lane, Stuart N.			Editorial 2024: Large language models, artificial intelligence and geomorphology	EARTH SURFACE PROCESSES AND LANDFORMS			English	Article								Large language models (LLMs), such as ChatGPT, have seen an explosion of interest over the last 12 months. It is hard to see an area of education and research where we are not having to face the challenge they pose, a form of artificial intelligence (AI) that is capable of generating text in response to relatively minimum prompting. The text generated can be surprisingly convincing. We now have definitive evidence of work being submitted to Earth Surface Processes and Landforms (ESPL) that has made use of LLMs. As a result, the Editorial Board has recently developed its policy on the use of LLMs in authoring, reviewing and editing papers. In developing our policy, we have taken note that through the journal's publisher Wiley, we are a signatory to the Committee on Publication Ethics (COPE, ). COPE provides us with a framework within which our policy sits, one that given the speed with which LLMs are developing means that it will not be definitive and will surely need to be revisited over the not-too-distant future. This extended editorial explains our policy, specifies guidelines for authors, reviewers and editors and also reflects more generally on the positive opportunities and challenges that emerging forms of AI pose to our community and our stated goal of publishing research in geomorphology that is of the highest quality.	[Lane, Stuart N.] Univ Lausanne, Inst Earth Surface Dynam, Lausanne, Switzerland	University of Lausanne	Lane, SN (corresponding author), Univ Lausanne, Inst Earth Surface Dynam, Lausanne, Switzerland.	stuart.lane@unil.ch	Lane, Stuart/M-7934-2014	Lane, Stuart/0000-0002-6077-6076				Acerbi A, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2313790120; Banks S. A., 2011, THESIS CEDARVILLE U; Checco A, 2021, HUM SOC SCI COMMUN, V8, DOI 10.1057/s41599-020-00703-8; Dhar P, 2020, NAT MACH INTELL, V2, P423, DOI 10.1038/s42256-020-0219-9; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Lane SN, 2022, EARTH SURF PROC LAND, V47, P3, DOI 10.1002/esp.5297; Lane SN, 2021, EARTH SURF PROC LAND, V46, P3, DOI 10.1002/esp.5038; Lane SN, 2012, EARTH SURF PROC LAND, V37, P3, DOI 10.1002/esp.2269; Lane SN, 2023, EARTH SURF PROC LAND, V48, P3, DOI 10.1002/esp.5523; Posada J., 2023, SAGE HDB HUMAN MACHI; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Souliere M., 2021, Committee Publication Ethics, DOI [10.24318/9kvAgrnJ, DOI 10.24318/9KVAGRNJ]; Thai K., 2022, EXPLORING DOCUMENT L, P9882; Vicente L, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-42384-8; Zhang X., 2023, PREPRINT	15	0	0	5	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0197-9337	1096-9837		EARTH SURF PROC LAND	Earth Surf. Process. Landf.	JAN	2024	49	1					3	9		10.1002/esp.5773	http://dx.doi.org/10.1002/esp.5773		JAN 2024	7	Geography, Physical; Geosciences, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Physical Geography; Geology	HI2B2					2024-07-03	WOS:001145910700001
J	Mello, MM; Guha, N				Mello, Michelle M.; Guha, Neel			ChatGPT and Physicians' Malpractice Risk	JAMA HEALTH FORUM			English	Editorial Material							PRACTICE GUIDELINES	This JAMA Forum discusses the possibilities, limitations, and risks of physician use of large language models (such as ChatGPT) along with the improvements required to improve the accuracy of the technology.	[Mello, Michelle M.; Guha, Neel] Stanford Law Sch, 559 Nathan Abbott Way, Stanford, CA 94305 USA; [Mello, Michelle M.] Stanford Univ, Sch Med, Dept Hlth Policy, Stanford, CA USA; [Guha, Neel] Stanford Univ, Dept Comp Sci, Stanford, CA USA	Stanford University; Stanford University; Stanford University	Mello, MM (corresponding author), Stanford Law Sch, 559 Nathan Abbott Way, Stanford, CA 94305 USA.; Mello, MM (corresponding author), Stanford Sch Med, Dept Hlth Res & Policy, 559 Nathan Abbott Way, Stanford, CA 94305 USA.	mmello@law.stanford.edu		Mello, Michelle/0000-0003-2877-4270				Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; HYAMS AL, 1995, ANN INTERN MED, V122, P450, DOI 10.7326/0003-4819-122-6-199503150-00008; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mello MM, 2001, U PENN LAW REV, V149, P645, DOI 10.2307/3312867; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]	7	34	34	3	11	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2689-0186			JAMA-HEALTH FORUM	JAMA Health Forum	MAY	2023	4	5							e231938	10.1001/jamahealthforum.2023.1938	http://dx.doi.org/10.1001/jamahealthforum.2023.1938			3	Health Care Sciences & Services; Health Policy & Services; Public, Environmental & Occupational Health	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	O8SS2	37200013	gold			2024-07-03	WOS:001046466100001
J	Formanek, M				Formanek, Matus			Exploring the potential of large language models and generative artificial intelligence (GPT): Applications in Library and Information Science	JOURNAL OF LIBRARIANSHIP AND INFORMATION SCIENCE			English	Article; Early Access						ChatGPT; generative artificial intelligence; large language models; Library and Information Science; use cases		The presented study offers a systematic overview of the potential application of large language models (LLMs) and generative artificial intelligence tools, notably the GPT model and the ChatGPT interface, within the realm of library and information science (LIS). The paper supplements and extends the outcomes of a comprehensive information survey on the subject matter with the author's own experiences and examples showcasing possible applications, demonstrated through illustrative instances. This study does not involve testing available LLMs or selecting the most suitable tool; instead, it targets information professionals, specialists, librarians, and scientists, aiming to inspire them in various ways. Within this paper, we explore both well-known and less recognized use cases of generative AI tools, which may prove relevant not only for the target group of information specialists but also for other users. Our analysis demonstrates that apart from merely summarizing or expanding existing textual content, these AI tools hold the potential for performing non-standard yet sophisticated tasks with electronic information resources. They can facilitate interactive engagement with these resources, aid in the extraction and composition of descriptive metadata, indexing, and even possible classification. Nevertheless, it is essential to acknowledge the numerous limitations of current LLMs, which we acknowledge in this study.	[Formanek, Matus] Univ Zilina, Zilina, Slovakia; [Formanek, Matus] Univ Zilina, Fac Humanities, Univ 8215-1, Zilina 01026, Slovakia	University of Zilina; University of Zilina	Formanek, M (corresponding author), Univ Zilina, Fac Humanities, Univ 8215-1, Zilina 01026, Slovakia.	matus.formanek@fhv.uniza.sk		Formanek, Matus/0000-0002-0611-1794				Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Chan A., 2022, AI and Ethics, V3, P53, DOI DOI 10.1007/S43681-022-00148-6; chatPDF, FAQ; Chen Y., 2023, A ChatGPT-based model for user book rating prediction; CORDELL R., 2020, MACHINE LEARNING LIB; Coursera, 2023, What is prompt engineering? Definition and examples; DAIR.AI, 2023, Retrieval augmented generation (RAG); DAIR.AI, 2023, Prompt engineering guide; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Dinneen JD., 2021, ASIST '21: Proceedings of the 84th Annual Meeting of the Association for Information Science Technology, V58, P117; Duarte Fabio, 2023, Number of chatgpt users; Garoufallou E, 2021, COLL RES LIBR, V82, P410; Grbin L, 2022, J AUST LIB INF ASSOC, V71, P275, DOI 10.1080/24750158.2022.2087954; Hopkins P., 2018, Chatbots and digital assistants-Getting started in FE and HE (Report.); Hu L., 2023, Generative AI and Future; Kaushal V, 2022, J AUST LIB INF ASSOC, V71, P215, DOI 10.1080/24750158.2022.2106403; Krawczyk Jack, 2023, Bard's latest update: more features, languages and countries; Li ZH, 2023, Arxiv, DOI [arXiv:2304.14347, 10.48550/arXiv.2304.14347]; Luca E, 2022, J AUST LIB INF ASSOC, V71, P185, DOI 10.1080/24750158.2022.2104814; McCaffrey C., 2021, Planning and Implementing an Automated Storage and Retrieval System at the University of Limerick; Mckie I, 2022, J AUST LIB INF ASSOC, V71, P233, DOI 10.1080/24750158.2022.2104738; Mckie IAS, 2019, J AUST LIB INF ASSOC, V68, P268, DOI 10.1080/24750158.2019.1611694; Meta AI, 2023, Introducing llama: A foundational, 65-billion-parameter language model; Open AI, 2023, What are tokens and how to count them?; Open AI, 2023, GPT-4; PADILLA T., 2019, Responsible Operations: Data Science, Machine Learning, and AI in Libraries, DOI DOI 10.25333/XK7Z-9G97; Panda Subhajit, 2023, Library Hi Tech News, P22, DOI 10.1108/LHTN-02-2023-0032; Panda S., 2023, IP Indian Journal of Library Science and Information Technology, V8, P20; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Reitz JM., 2013, Dictionary for Library and Information Science; Sajan BP., 2023, The Lancet. Digital health, V5; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Samarth V., 2023, What is Prompt Engineering, and What is its Significance in Today's World?; Saracevic T., 2010, Information Science. Encyclopedia of Library and Information Sciences, V3rd edn., P570	35	0	0	85	85	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0961-0006	1741-6477		J LIBR INF SCI	J. Libr. Inf. Sci.	2024 MAR 24	2024										10.1177/09610006241241066	http://dx.doi.org/10.1177/09610006241241066		MAR 2024	23	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	LX6W0					2024-07-03	WOS:001190159800001
J	Ellaway, RH; Tolsgaard, M				Ellaway, Rachel H.; Tolsgaard, Martin			Artificial scholarship: LLMs in health professions education research	ADVANCES IN HEALTH SCIENCES EDUCATION			English	Editorial Material								This editorial examines the implications of artificial intelligence (AI), specifically large language models (LLMs) such as ChatGPT, on the authorship and authority of academic papers, and the potential ethical concerns and challenges in health professions education (HPE).	[Ellaway, Rachel H.] Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada; [Ellaway, Rachel H.] Univ Calgary, Cumming Sch Med, Off Hlth & Med Educ Scholarship, Calgary, AB, Canada; [Tolsgaard, Martin] Univ Copenhagen, Copenhagen Univ Hosp, Copenhagen Acad Med Educ & Simulat CAMES, Rigshosp, Copenhagen, Denmark	University of Calgary; University of Calgary; Rigshospitalet; University of Copenhagen	Ellaway, RH (corresponding author), Univ Calgary, Cumming Sch Med, Dept Community Hlth Sci, Calgary, AB, Canada.; Ellaway, RH (corresponding author), Univ Calgary, Cumming Sch Med, Off Hlth & Med Educ Scholarship, Calgary, AB, Canada.	rellaway@gmail.com						Alba D., 2022, Bloomberg; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; DeVilbiss MB, 2023, ACAD MED, V98, P865, DOI 10.1097/ACM.0000000000005261; ICMJE (International Committee of Medical Journal Editors) (, DEF ROL AUTH CONTR; Katznelson G, 2021, ADV HEALTH SCI EDUC, V26, P1447, DOI 10.1007/s10459-021-10040-3; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Kuper A., 2023, WHO SHOULD BE AUTHOR; Li D, 2019, ACAD MED, V94, P623, DOI 10.1097/ACM.0000000000002661; ROSEN LD, 1987, BEHAV RES METH INSTR, V19, P167, DOI 10.3758/BF03203781; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Steel P., 2023, USING CHATGPT ACAD P; Tolsgaard MG, 2020, ADV HEALTH SCI EDUC, V25, P1057, DOI 10.1007/s10459-020-10009-8; Vincent J., 2023, THE VERGE       0105	14	8	8	5	16	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1382-4996	1573-1677		ADV HEALTH SCI EDUC	Adv. Health Sci. Educ.	AUG	2023	28	3					659	664		10.1007/s10459-023-10257-4	http://dx.doi.org/10.1007/s10459-023-10257-4		JUN 2023	6	Education & Educational Research; Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Education & Educational Research; Health Care Sciences & Services	T2KW0	37335338	Bronze			2024-07-03	WOS:001014959200001
J	Meskó, B				Mesko, Bertalan			The Impact of Multimodal Large Language Models on Health Care's Future	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						artificial intelligence; ChatGPT; digital health; future; GPT-4; Generative Pre-Trained Transformer; large language models; multimodality; technology; AI; LLM		When large language models (LLMs) were introduced to the public at large in late 2022 with ChatGPT (OpenAI), the interest was unprecedented, with more than 1 billion unique users within 90 days. Until the introduction of Generative Pre-trained Transformer 4 (GPT-4) in March 2023, these LLMs only contained a single mode-text. As medicine is a multimodal discipline, the potential future versions of LLMs that can handle multimodality-meaning that they could interpret and generate not only text but also images, videos, sound, and even comprehensive documents-can be conceptualized as a significant evolution in the field of artificial intelligence (AI). This paper zooms in on the new potential of generative AI, a new form of AI that also includes tools such as LLMs, through the achievement of multimodal inputs of text, images, and speech on health care's future. We present several futuristic scenarios to illustrate the potential path forward as multimodal LLMs (M-LLMs) could represent the gateway between health care professionals and using AI for medical purposes. It is important to point out, though, that despite the unprecedented potential of generative AI in the form of M-LLMs, the human touch in medicine remains irreplaceable. AI should be seen as a tool that can augment health care professionals rather than replace them. It is also important to consider the human aspects of health care-empathy, understanding, and the doctor-patient relationship-when deploying AI.	[Mesko, Bertalan] Med Futurist Intitute, Budapest, Hungary; [Mesko, Bertalan] Med Futurist Intitute, Povl Bang Jensen u 2 B1 4 1, H-1118 Budapest 11, Hungary		Meskó, B (corresponding author), Med Futurist Intitute, Povl Bang Jensen u 2 B1 4 1, H-1118 Budapest 11, Hungary.	berci@medicalfuturist.com		Mesko, Bertalan/0000-0002-7005-7083				Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Adams K., 2023, Google Cloud, Mayo Clinic Strike Generative AI Partnership; Antunes RS, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3501813; Benjamens S, 2023, JMIR AI, V2, DOI DOI 10.2196/47283; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Braunstein ML, 2018, IEEE PULSE, V9, P24, DOI 10.1109/MPUL.2018.2869317; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Meskó B, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3359-4; Moor M, 2023, Med-Flamingo: a multimodal medical few-shot learner; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; OpenAI, 2022, OpenA I; Robeznieks A, 2023, Why generative AI like ChatGPT cannot replace physicians; Tu T, 2023, PREPRINT; Wu C, 2023, PREPRINT	15	13	13	47	59	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	NOV 2	2023	25								e52865	10.2196/52865	http://dx.doi.org/10.2196/52865			8	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	Y3GQ9	37917126	gold, Green Published			2024-07-03	WOS:001104191500001
C	Taylor, A; Vassar, A; Renzella, J; Pearce, H			Assoc Computing Machinery	Taylor, Andrew; Vassar, Alexandra; Renzella, Jake; Pearce, Hammond			dcc --help: Transforming the Role of the Compiler by Generating Context-Aware Error Explanations with Large Language Models	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		CS1; AI in CS1; AI in Education; Generative AI; Large Language Models; Compiler Error Messages; Debugging; Error Message Enhancement; Programming Error Messages		In the challenging field of introductory programming, high enrolments and failure rates drive us to explore tools and systems to enhance student outcomes, especially automated tools that scale to large cohorts. This paper presents and evaluates the dcc --help tool, an integration of a Large Language Model (LLM) into the Debugging C Compiler (DCC) to generate unique, novice-focused explanations tailored to each error. dcc --help prompts an LLM with contextual information of compile- and run-time error occurrences, including the source code, error location and standard compiler error message. The LLM is instructed to generate novice-focused, actionable error explanations and guidance, designed to help students understand and resolve problems without providing solutions. dcc --help was deployed to our CS1 and CS2 courses, with 2,565 students using the tool over 64,000 times in ten weeks. We analysed a subset of these error/explanation pairs to evaluate their properties, including conceptual correctness, relevancy, and overall quality. We found that the LLM-generated explanations were conceptually accurate in 90% of compile-time and 75% of run-time cases, but often disregarded the instruction not to provide solutions in code. Our findings, observations and reflections following deployment indicate that dcc --help provides novel opportunities for scaffolding students' introduction to programming.	[Taylor, Andrew; Vassar, Alexandra; Renzella, Jake; Pearce, Hammond] Univ New South Wales, Sydney, NSW 2052, Australia	University of New South Wales Sydney	Taylor, A (corresponding author), Univ New South Wales, Sydney, NSW 2052, Australia.			Vassar, Sasha/0000-0001-8856-2566; Renzella, Jake/0000-0002-9587-1196; Pearce, Hammond/0000-0002-3488-7004				Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bansal Gagan, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445717; Barik T, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE COMPANION 2014), P536, DOI 10.1145/2591062.2591124; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Becker BA, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P253, DOI 10.1145/3304221.3325539; Becker BA, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P640, DOI 10.1145/3159450.3159461; Becker BA, 2016, COMPUT SCI EDUC, V26, P148, DOI 10.1080/08993408.2016.1225464; Bennedsen J., 2019, ACM Inroads, V10, P30, DOI DOI 10.1145/3324888; Carvalho G, 2021, 2021 XVI LATIN AMERICAN CONFERENCE ON LEARNING TECHNOLOGIES (LACLO 2021), P389, DOI 10.1109/LACLO54177.2021.00048; Chen M., 2021, arXiv; Denny P., 2014, Proceedings of the 2014 conference on Innovation technology in computer science education ss, P273, DOI [10.1145/2591708.2591748, DOI 10.1145/2591708.2591748]; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Denny Paul, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445696, 10.1145/3411764, DOI 10.1145/3411764]; Dreibelbis Emily, 2023, PCMag AustraliaJune; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Traver VJ, 2010, ADV HUM-COMPUT INTER, V2010, DOI 10.1155/2010/602570; Karvelas I, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P759, DOI 10.1145/3328778.3366882; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kohn T, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P524, DOI 10.1145/3287324.3287381; LANDIS JR, 1977, BIOMETRICS, V33, P363, DOI 10.2307/2529786; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Linton Courtney, 2023, ChatGPT response by Australian Schools-Corney & Lind Lawyers; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Nethercote N, 2007, ACM SIGPLAN NOTICES, V42, P89, DOI 10.1145/1273442.1250746; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pettit R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P465, DOI 10.1145/3017680.3017768; Prather J, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P74, DOI 10.1145/3105726.3106169; Sweller J, 2019, EDUC PSYCHOL REV, V31, P261, DOI 10.1007/s10648-019-09465-5; Taylor A, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P346, DOI 10.1145/3545945.3569768; Vasconcelos H., 2023, P ACM HUMAN COMPUTER, V7, P1, DOI DOI 10.1145/3579605	32	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							1314	1320		10.1145/3626252.3630822	http://dx.doi.org/10.1145/3626252.3630822			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP					2024-07-03	WOS:001181240800190
J	Zhang, KP; Wang, SP; Jia, N; Zhao, L; Han, CY; Li, L				Zhang, Kunpeng; Wang, Shipu; Jia, Ning; Zhao, Liang; Han, Chunyang; Li, Li			Integrating visual large language model and reasoning chain for driver behavior analysis and risk assessment	ACCIDENT ANALYSIS AND PREVENTION			English	Article						Distracted driving classification; Large language model; Reasoning chain framework; Driving risk assessment; Explainable AI		Driver behavior is a critical factor in driving safety, making the development of sophisticated distraction classification methods essential. Our study presents a Distracted Driving Classification (DDC) approach utilizing a visual Large Language Model (LLM), named the Distracted Driving Language Model (DDLM). The DDLM introduces whole -body human pose estimation to isolate and analyze key postural features-head, right hand, and left hand-for precise behavior classification and better interpretability. Recognizing the inherent limitations of LLMs, particularly their lack of logical reasoning abilities, we have integrated a reasoning chain framework within the DDLM, allowing it to generate clear, reasoned explanations for its assessments. Tailored specifically with relevant data, the DDLM demonstrates enhanced performance, providing detailed, context -aware evaluations of driver behaviors and corresponding risk levels. Notably outperforming standard models in both zero -shot and few -shot learning scenarios, as evidenced by tests on the 100 -Driver dataset, the DDLM stands out as an advanced tool that promises significant contributions to driving safety by accurately detecting and analyzing driving distractions.	[Zhang, Kunpeng; Wang, Shipu; Zhao, Liang] Henan Univ Technol, Coll Elect Engn, Zhengzhou 450001, Peoples R China; [Zhang, Kunpeng; Han, Chunyang; Li, Li] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Jia, Ning] Tianjin Univ, Coll Management & Econ, Tianjin 300072, Peoples R China; [Han, Chunyang] Kunming Univ Sci & Technol, Fac Transportat Engn, Kunming 650500, Peoples R China	Henan University of Technology; Tsinghua University; Tianjin University; Kunming University of Science & Technology	Zhao, L (corresponding author), Henan Univ Technol, Coll Elect Engn, Zhengzhou 450001, Peoples R China.; Han, CY (corresponding author), Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China.; Han, CY (corresponding author), Kunming Univ Sci & Technol, Fac Transportat Engn, Kunming 650500, Peoples R China.	zhaoliang270@gmail.com; sandiant@foxmail.com	Li, Li/A-3453-2008	Li, Li/0000-0002-9428-1960; Zhao, Liang/0000-0003-1556-969X; zhang, kunpeng/0000-0003-1979-4261	National Natural Science Foundation of China [62002101]; Key Research Projects of Higher Education Institutions in Henan Province [24A120003]; Natural Science Project of Zhengzhou Municipal Bureau of Science and Technology [22ZZRDZX05]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key Research Projects of Higher Education Institutions in Henan Province; Natural Science Project of Zhengzhou Municipal Bureau of Science and Technology	<BOLD>Funding</BOLD> This research has been supported by the National Natural Science Foundation of China (Grants No. 62002101) , the Key Research Projects of Higher Education Institutions in Henan Province (Grants No. 24A120003) , and the Natural Science Project of Zhengzhou Municipal Bureau of Science and Technology (Grants No. 22ZZRDZX05) .	Administration N.H.T.S., 2021, Distracted driving in 2021; Amini RE, 2023, ACCIDENT ANAL PREV, V191, DOI 10.1016/j.aap.2023.107195; Atiquzzaman M, 2018, TRANSPORT RES F-TRAF, V58, P594, DOI 10.1016/j.trf.2018.06.027; Baheti B, 2020, IEEE T INTELL VEHICL, V5, P565, DOI 10.1109/TIV.2020.2995555; Bouhsissin S., 2023, Driver behavior classification: A systematic literature review; Chen QH, 2021, ACCIDENT ANAL PREV, V151, DOI 10.1016/j.aap.2020.105871; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cui Y., 2023, IEEE Trans. Intell. Veh.; Das K, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3519267; De Winter J.C., 2023, PREPRINT; Driessen T., 2023, Putting ChatGPT Vision (GPT-4V) to the test: risk perception in traffic images; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Dunn NJ, 2021, ACCIDENT ANAL PREV, V156, DOI 10.1016/j.aap.2021.106152; Freed SA, 2021, ACCIDENT ANAL PREV, V152, DOI 10.1016/j.aap.2021.105986; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Han CY, 2023, ANAL METHODS ACCID R, V37, DOI 10.1016/j.amar.2022.100253; Han CY, 2018, ANAL METHODS ACCID R, V20, P81, DOI 10.1016/j.amar.2018.10.002; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu YP, 2023, ACCIDENT ANAL PREV, V191, DOI 10.1016/j.aap.2023.107203; Huang C, 2020, IEEE ACCESS, V8, P109335, DOI 10.1109/ACCESS.2020.3001159; Huang HL, 2022, ACCIDENT ANAL PREV, V171, DOI 10.1016/j.aap.2022.106666; Jin S., 2020, COMPUTER VISIONECCV, P196, DOI 10.1007/978-3-030-58545-7_12; Kashevnik A, 2021, IEEE ACCESS, V9, P60063, DOI 10.1109/ACCESS.2021.3073599; Kashevnik A, 2020, IEEE T INTELL TRANSP, V21, P2427, DOI 10.1109/TITS.2019.2918328; Khan MQ, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112574; Lattanzi E, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114818; Li Y, 2023, ACCIDENT ANAL PREV, V192, DOI 10.1016/j.aap.2023.107271; Li Y, 2023, ACCIDENT ANAL PREV, V190, DOI 10.1016/j.aap.2023.107192; Li Y, 2022, ACCIDENT ANAL PREV, V175, DOI 10.1016/j.aap.2022.106781; Li Y, 2020, ACCIDENT ANAL PREV, V144, DOI 10.1016/j.aap.2020.105676; Liu HT, 2024, Arxiv, DOI arXiv:2310.03744; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Manu M.A., 2020, International Journal of Research in Engineering, Science and Management, V3, P48; Mao JG, 2023, Arxiv, DOI arXiv:2310.01415; Masello L, 2023, ACCIDENT ANAL PREV, V183, DOI 10.1016/j.aap.2023.106969; Masood S, 2020, PATTERN RECOGN LETT, V139, P79, DOI 10.1016/j.patrec.2017.12.023; Michelaraki E, 2023, ACCIDENT ANAL PREV, V192, DOI 10.1016/j.aap.2023.107241; Nasri I., 2022, IAES International Journal of Artificial Intelligence, V11, P494, DOI [10.11591/ijai.v11.i2.pp494-503, DOI 10.11591/IJAI.V11.I2.PP494-503]; Park SM, 2023, ARTIF INTELL REV, V56, P365, DOI 10.1007/s10462-022-10174-9; Peng YX, 2023, ACCIDENT ANAL PREV, V180, DOI 10.1016/j.aap.2022.106925; Ping P, 2023, INFORM FUSION, V89, P121, DOI 10.1016/j.inffus.2022.08.009; Shahverdy M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113240; Stavrinos D, 2020, ACCIDENT ANAL PREV, V144, DOI 10.1016/j.aap.2020.105678; Sysoev M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17102404; Tang JJ, 2020, ACCIDENT ANAL PREV, V148, DOI 10.1016/j.aap.2020.105833; Tang JJ, 2020, ANAL METHODS ACCID R, V27, DOI 10.1016/j.amar.2020.100123; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang J., 2023, IEEE Transactions on Intelligent Transportation Systems, P1; Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686; Wang S., 2023, IEEE Trans. Intell. Veh.; Xing Y, 2019, IEEE T VEH TECHNOL, V68, P5379, DOI 10.1109/TVT.2019.2908425; Yang K, 2022, IEEE OPEN J INTEL TR, V3, P111, DOI 10.1109/OJITS.2022.3149474; Zhang KP, 2024, INFORM FUSION, V102, DOI 10.1016/j.inffus.2023.102038; Zhang QR, 2023, ACCIDENT ANAL PREV, V183, DOI 10.1016/j.aap.2023.106971; Zhang SY, 2023, Arxiv, DOI arXiv:2309.06719; Zhang YX, 2021, NEUROCOMPUTING, V421, P26; Zheng O, 2023, Arxiv, DOI arXiv:2303.05382	58	1	1	32	32	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0001-4575	1879-2057		ACCIDENT ANAL PREV	Accid. Anal. Prev.	APR	2024	198								107497	10.1016/j.aap.2024.107497	http://dx.doi.org/10.1016/j.aap.2024.107497		FEB 2024	12	Ergonomics; Public, Environmental & Occupational Health; Social Sciences, Interdisciplinary; Transportation	Social Science Citation Index (SSCI)	Engineering; Public, Environmental & Occupational Health; Social Sciences - Other Topics; Transportation	JX1U5	38330547				2024-07-03	WOS:001176376100001
J	Li, HN; Hao, Y; Zhai, YZ; Qian, ZY				Li, Haonan; Hao, Yu; Zhai, Yizhuo; Qian, Zhiyun			Enhancing Static Analysis for Practical Bug Detection: An LLM-Integrated Approach	PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES-PACMPL			English	Article						Static analysis; bug detection; large language model		While static analysis is instrumental in uncovering software bugs, its precision in analyzing large and intricate codebases remains challenging. The emerging prowess of Large Language Models (LLMs) offers a promising avenue to address these complexities. In this paper, we present LLift, a pioneering framework that synergizes static analysis and LLMs, with a spotlight on identifying Use Before Initialization (UBI) bugs within the Linux kernel. Drawing from our insights into variable usage conventions in Linux, we enhance path analysis using post-constraint guidance. This approach, combined with our methodically crafted procedures, empowers LLift to adeptly handle the challenges of bug-specific modeling, extensive codebases, and the unpredictable nature of LLMs. Our real-world evaluations identified four previously undiscovered UBI bugs in the mainstream Linux kernel, which the Linux community has acknowledged. This study reaffirms the potential of marrying static program analysis with LLMs, setting a compelling direction for future research in this area.	[Li, Haonan; Hao, Yu; Zhai, Yizhuo; Qian, Zhiyun] Univ Calif Riverside, Riverside, CA 92521 USA	University of California System; University of California Riverside	Li, HN (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.	hli333@ucr.edu; yhao016@ucr.edu; yzhai003@ucr.edu; zhiyunq@cs.ucr.edu	Hao, Yu/JDD-2851-2023	Hao, Yu/0000-0002-3944-3162; Li, Haonan/0000-0003-0357-0888	National Science Foundation [1953933, 1652954]	National Science Foundation(National Science Foundation (NSF))	We thank the anonymous reviewers for their valuable feedback. This work was supported in part by the National Science Foundation under Grant No. 1953933 and 1652954. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed Toufique, 2024, 2024 IEEE ACM 45 INT; Anthropic, 2023, 2023. Claude 2; Chen JH, 2023, Arxiv, DOI arXiv:2304.03262; Chen M., 2021, arXiv; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Chiang Ted, 2023, The New YorkerFeb.; Copilot, 2023, GitHub Copilot documentation; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Gosain A., 2015, Advances in Intelligent Systems and Computing), P581; Huang J, 2007, Path-Oriented Program Analysis, DOI [10.1017/CBO9780511546990, DOI 10.1017/CBO9780511546990]; Huang J., 2022, arXiv; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Karpas E., 2022, arXiv; Khare A, 2024, Arxiv, DOI arXiv:2311.16169; Krawczyk Jack, 2023, Bard's latest update: more features, languages and countries; LangChain, 2023, Announcing LangSmith, a unified platform for debugging, testing, evaluating, and monitoring your LLM applications; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Li Haonan, 2024, Zenodo, DOI 10.5281/ZENODO.10780591; Liu H, 2023, Arxiv, DOI arXiv:2302.02676; Lu KJ, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1867, DOI 10.1145/3319535.3354244; Ma W, 2024, Arxiv, DOI arXiv:2305.12138; Nginx, 2020, About us; OpenAI, 2022, Introducing chatgpt; OpenAI, 2023, Function calling and other API updates; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pallagani V, 2023, Arxiv, DOI arXiv:2305.16151; Parisi A, 2022, Arxiv, DOI arXiv:2205.12255; Park J, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3464457; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pei K, 2024, Arxiv, DOI arXiv:2308.03312; Pei Kexin, 2023, P 40 INT C MACH LEAR; Salamone Luke, 2021, What is Temperature in NLP?; Schick T., 2023, arXiv; Shieh J., 2023, Best practices for prompt engineering with openai API; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Song YS, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3582688; Sui YL, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION (CC 2016), P265, DOI 10.1145/2892208.2892235; Sun W., 2023, arXiv; Sun Yuqiang, 2024, 2024 IEEE ACM 45 INT; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; TianoCore, 2022, tianocore/edk2; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weng L., 2023, Llm-powered autonomous agents; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao Shunyu, 2023, INT C LEARN REPR ICL; Zhai YZ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P221, DOI 10.1145/3368089.3409686; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng S, 2023, Arxiv, DOI [arXiv:2304.10513, 10.48550/arXiv.2304.10513]	54	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2475-1421		P ACM PROGRAM LANG	P. ACM Program. Lang.	APR	2024	8	OOPSLA							111	10.1145/3649828	http://dx.doi.org/10.1145/3649828			26	Computer Science, Software Engineering	Emerging Sources Citation Index (ESCI)	Computer Science	OV0C4					2024-07-03	WOS:001209927600018
J	Kugic, A; Schulz, S; Kreuzthaler, M				Kugic, Amila; Schulz, Stefan; Kreuzthaler, Markus			Disambiguation of acronyms in clinical narratives with large language models	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						natural language processing; large language models; electronic health records; acronyms	HEALTH	Objective To assess the performance of large language models (LLMs) for zero-shot disambiguation of acronyms in clinical narratives.Materials and Methods Clinical narratives in English, German, and Portuguese were applied for testing the performance of four LLMs: GPT-3.5, GPT-4, Llama-2-7b-chat, and Llama-2-70b-chat. For English, the anonymized Clinical Abbreviation Sense Inventory (CASI, University of Minnesota) was used. For German and Portuguese, at least 500 text spans were processed. The output of LLM models, prompted with contextual information, was analyzed to compare their acronym disambiguation capability, grouped by document-level metadata, the source language, and the LLM.Results On CASI, GPT-3.5 achieved 0.91 in accuracy. GPT-4 outperformed GPT-3.5 across all datasets, reaching 0.98 in accuracy for CASI, 0.86 and 0.65 for two German datasets, and 0.88 for Portuguese. Llama models only reached 0.73 for CASI and failed severely for German and Portuguese. Across LLMs, performance decreased from English to German and Portuguese processing languages. There was no evidence that additional document-level metadata had a significant effect.Conclusion For English clinical narratives, acronym resolution by GPT-4 can be recommended to improve readability of clinical text by patients and professionals. For German and Portuguese, better models are needed. Llama models, which are particularly interesting for processing sensitive content on premise, cannot yet be recommended for acronym resolution.	[Kugic, Amila; Schulz, Stefan; Kreuzthaler, Markus] Med Univ Graz, Inst Med Informat Stat & Documentat, Auenbruggerpl 2-5, A-8036 Graz, Austria	Medical University of Graz	Kreuzthaler, M (corresponding author), Med Univ Graz, Inst Med Informat Stat & Documentat, Auenbruggerpl 2-5, A-8036 Graz, Austria.	markus.kreuzthaler@medunigraz.at			European Union [101057062]	European Union(European Union (EU))	This research has received funding from the European Union's Horizon Research and Innovation Programme under grant agreement No 101057062 (AIDAVA, https://aidava.eu/).	Adams Griffin, 2020, Proc Mach Learn Res, V136, P12; Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Baker HP, 2024, J AM ACAD ORTHOP SUR, V32, P123, DOI 10.5435/JAAOS-D-23-00474; Ben Abacha A., 2023, Proceedings of the 5th Clinical Natural Language Processing Workshop, P503, DOI DOI 10.18653/V1/2023.CLINICALNLP-1.52; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Dreano S., 2023, P 8 C MACH TRANSL SI, P738, DOI [10.18653/v1/2023.wmt-1.60, DOI 10.18653/V1/2023.WMT-1.60]; Gaziano JM, 2016, J CLIN EPIDEMIOL, V70, P214, DOI 10.1016/j.jclinepi.2015.09.016; Kashyap A, 2020, INT J MED INFORM, V137, DOI 10.1016/j.ijmedinf.2020.104101; Kugic Amila, 2023, Stud Health Technol Inform, V309, P78, DOI 10.3233/SHTI230743; Link NB, 2022, INT J MED INFORM, V162, DOI 10.1016/j.ijmedinf.2022.104753; Lybarger K, 2023, J AM MED INFORM ASSN, V30, P1367, DOI 10.1093/jamia/ocad012; Moon S., 2012, Clinical abbreviation sense inventory; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Ramachandran GK., 2023, Proceedings of the 5th Clinical Natural Language Processing Workshop, P385, DOI [10.18653/v1/2023.clinicalnlp-1.41, DOI 10.18653/V1/2023.CLINICALNLP-1.41]; Scheschenja M, 2024, CARDIOVASC INTER RAD, V47, P245, DOI 10.1007/s00270-023-03563-2; Schwarz CM, 2021, J EVAL CLIN PRACT, V27, P1243, DOI 10.1111/jep.13533; Scott IA, 2024, INTERN MED J, V54, P705, DOI 10.1111/imj.16393; Oliveira LESE, 2022, J BIOMED SEMANT, V13, DOI 10.1186/s13326-022-00269-1; Skreta M, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25578-4; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Vaswani A, 2017, ADV NEUR IN, V30; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8	23	0	0	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 JUN 25	2024										10.1093/jamia/ocae157	http://dx.doi.org/10.1093/jamia/ocae157		JUN 2024	7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	WF4K4	38917444	hybrid			2024-07-03	WOS:001253440600001
C	Le, VH; Zhang, HY			IEEE	Le, Van-Hoang; Zhang, Hongyu			Log Parsing: How Far Can ChatGPT Go?	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Log analytics; Log parsing; Large language model; ChatGPT		Software logs play an essential role in ensuring the reliability and maintainability of large-scale software systems, as they are often the sole source of runtime information. Log parsing, which converts raw log messages into structured data, is an important initial step towards downstream log analytics. In recent studies, ChatGPT, the current cutting-edge large language model (LLM), has been widely applied to a wide range of software engineering tasks. However, its performance in automated log parsing remains unclear. In this paper, we evaluate ChatGPT's ability to undertake log parsing by addressing two research questions. (1) Can ChatGPT effectively parse logs? (2) How does ChatGPT perform with different prompting methods? Our results show that ChatGPT can achieve promising results for log parsing with appropriate prompts, especially with few-shot prompting. Based on our findings, we outline several challenges and opportunities for ChatGPT-based log parsing.	[Le, Van-Hoang] Univ Newcastle, Sch Informat & Phys Sci, Callaghan, NSW, Australia; [Zhang, Hongyu] Chongqing Univ, Sch Big Data & Software Engn, Chongqing, Peoples R China	University of Newcastle; Chongqing University	Zhang, HY (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chongqing, Peoples R China.	vanhoang.le@uon.edu.au; hyzhang@cqu.edu.cn		Le, Van-Hoang/0000-0002-7651-9154	Australian Research Council (ARC) [DP200102940, DP220103044]	Australian Research Council (ARC)(Australian Research Council)	This work is supported by Australian Research Council (ARC) Discovery Projects (DP200102940, DP220103044). We also thank anonymous reviewers for their insightful and constructive comments, which significantly improve this paper.	[Anonymous], 2023, A toolkit for automated log parsing; [Anonymous], 2023, Artifact for "guidelines for assessing the accuracy of log message template identification techniques, DOI [10.6084/m9.figshare.18858332, DOI 10.6084/M9.FIGSHARE.18858332]; [Anonymous], 2023, Openai chatgpt; [Anonymous], 2023, Gpt-3.5-turbo; Cao JL, 2023, Arxiv, DOI [arXiv:2304.08191, 10.48550/arXiv.2304.08191, 10.48550/ARXIV.2304.08191]; Dai H., 2020, IEEE Transactions on Software Engineering; Das A, 2018, HPDC '18: PROCEEDINGS OF THE 27TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P40, DOI 10.1145/3208040.3208051; Du M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1285, DOI 10.1145/3133956.3134015; Du M, 2016, IEEE DATA MINING, P859, DOI [10.1109/ICDM.2016.160, 10.1109/ICDM.2016.0103]; Fu QA, 2009, IEEE DATA MINING, P149, DOI 10.1109/ICDM.2009.60; Gao S., 2023, P 38 IEEE ACM INT C; Gurumdimma N, 2016, SYM REL DIST SYST, P51, DOI [10.1109/SRDS.2016.017, 10.1109/SRDS.2016.15]; He PJ, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P33, DOI 10.1109/ICWS.2017.13; He SL, 2016, PROC INT SYMP SOFTW, P207, DOI 10.1109/ISSRE.2016.21; Huo YT, 2023, PROC INT CONF SOFTW, P881, DOI 10.1109/ICSE48619.2023.00082; Jiang ZM, 2008, INT CONF QUAL SOFTW, P181, DOI 10.1109/QSIC.2008.50; Khan ZA, 2022, PROC INT CONF SOFTW, P1095, DOI 10.1145/3510003.3510101; Le SY, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P389, DOI 10.1109/ICWS.2017.135; Le VH, 2023, PROC INT CONF SOFTW, P2438, DOI 10.1109/ICSE48619.2023.00204; Le VH, 2022, PROC INT CONF SOFTW, P1356, DOI 10.1145/3510003.3510155; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li XY, 2020, PROC INT SYMP SOFTW, P92, DOI 10.1109/ISSRE5003.2020.00018; Li ZH, 2023, PROC INT CONF SOFTW, P830, DOI 10.1109/ICSE48619.2023.00078; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YD, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P1893, DOI 10.1145/3485447.3511993; Nagappan Meiyappan, 2010, Proceedings of the 2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010), P114, DOI 10.1109/MSR.2010.5463281; Nedelkoski S, 2021, LECT NOTES ARTIF INT, V12460, P122, DOI 10.1007/978-3-030-67667-4_8; Russo B, 2015, EMPIR SOFTW ENG, V20, P879, DOI 10.1007/s10664-014-9303-2; Shima K, 2016, Arxiv, DOI arXiv:1611.03213; Tang Liang, 2011, P 20 ACM INT C INFOR, P785, DOI 10.1145/2063576.2063690; Tao Shimin, 2022, ACM SIGMETRICS Performance Evaluation Review, V49, P93, DOI 10.1145/3543146.3543168; Vaarandi R, 2003, PROCEEDINGS OF THE 3RD IEEE WORKSHOP ON IP OPERATIONS & MANAGEMENT (IPOM2003), P119; Le VH, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P492, DOI 10.1109/ASE51524.2021.9678773; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wang XH, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1198, DOI 10.1145/3540250.3549176; Wei Jason, ADV NEURAL INFORM PR; Zhang X, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P807, DOI 10.1145/3338906.3338931; Zhu JM, 2023, Arxiv, DOI arXiv:2008.06448; Zhu JM, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P121, DOI 10.1109/ICSE-SEIP.2019.00021	39	1	1	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1699	1704		10.1109/ASE56229.2023.00206	http://dx.doi.org/10.1109/ASE56229.2023.00206			6	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200137
C	Pearce, H; Tan, B; Ahmad, B; Karri, R; Dolan-Gavitt, B			IEEE	Pearce, Hammond; Tan, Benjamin; Ahmad, Baleegh; Karri, Ramesh; Dolan-Gavitt, Brendan			Examining Zero-Shot Vulnerability Repair with Large Language Models	2023 IEEE SYMPOSIUM ON SECURITY AND PRIVACY, SP	IEEE Symposium on Security and Privacy		English	Proceedings Paper	44th IEEE Symposium on Security and Privacy (SP)	MAY 21-25, 2023	San Francisco, CA	IEEE, IEEE Comp Soc		Cybersecurity; AI; code generation; CWE		Human developers can produce code with cybersecurity bugs. Can emerging 'smart' code completion tools help repair those bugs? In this work, we examine the use of large language models (LLMs) for code (such as OpenAI's Codex and AI21's Jurassic J-1) for zero-shot vulnerability repair. We investigate challenges in the design of prompts that coax LLMs into generating repaired versions of insecure code. This is difficult due to the numerous ways to phrase key information-both semantically and syntactically-with natural languages. We perform a large scale study of five commercially available, black-box, "off-the-shelf" LLMs, as well as an open-source model and our own locally-trained model, on a mix of synthetic, hand-crafted, and real-world security bug scenarios. Our experiments demonstrate that while the approach has promise (the LLMs could collectively repair 100% of our synthetically generated and hand-crafted scenarios), a qualitative evaluation of the model's performance over a corpus of historical real-world examples highlights challenges in generating functionally correct code.	[Pearce, Hammond; Ahmad, Baleegh; Karri, Ramesh; Dolan-Gavitt, Brendan] NYU, New York, NY 10003 USA; [Tan, Benjamin] Univ Calgary, Calgary, AB, Canada	New York University; University of Calgary	Pearce, H (corresponding author), NYU, New York, NY 10003 USA.				ONR [N00014-18-1-2058]; NSF [2145482]	ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); NSF(National Science Foundation (NSF))	We would like to thank the anonymous reviewers for their constructive feedback and encouragement. This work was partially supported by ONR Award #N00014-18-1-2058 and NSF award #2145482. Any opinions, findings, and conclusions, or recommendations expressed are those of the authors and do not necessarily reflect the views of the sponsors.	AI21, DISC US CAS A121 STU; AI21, 2021, JUR1 LANG MOD AI21 S; [Anonymous], 2019, Language Models are Unsupervised Multitask Learners, DOI DOI 10.18653/V1/W18-5019; Austin J., 2021, ARXIV210807732 CS; Bandara V, 2020, IEEE INT WORK C SO, P198, DOI 10.1109/SCAM51674.2020.00027; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, ARXIV210703374 CS; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Drain D., 2021, P 5 ACM SIGPLAN INT, P1, DOI [DOI 10.1145/3460945.3464951, 10.1145/3460945.3464951]; Drechsler R, 2012, INT HIGH LEVEL DESIG, P164, DOI 10.1109/HLDVT.2012.6418259; G. Inc, 2021, CODEQL DOC; Gage P., 1994, C Users Journal, V12, P23; Gao X, 2021, ACM T SOFTW ENG METH, V30, DOI 10.1145/3418461; GitHub, GITHUB COP YOUR AI P; Hartmann B, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1019; Jeffrey D, 2009, INT C PROGRAM COMPRE, P70, DOI 10.1109/ICPC.2009.5090029; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Jong-Deok Choi, 2002, Software Engineering Notes, V27, P210, DOI 10.1145/566171.566211; Kasikci B, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P344, DOI 10.1145/2815400.2815412; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Li F, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2201, DOI 10.1145/3133956.3134072; Li J, 2018, AUTOMOTIVE INNOV, V1, P1, DOI 10.1007/s42154-018-0014-z; Lieber O., 2021, JURASSIC 1 TECHNICAL; Lin Tan, 2007, Operating Systems Review, V41, P145, DOI 10.1145/1323293.1294276; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319; Misra V, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P110, DOI 10.1145/3341105.3374009; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; OpenAI, 2021, OpenAI Codex; OpenAI, Completion-OpenAI API; OpenAI, EX OPENAI API; OWASP, SOURC COD AN TOOLS; Pascarella L, 2017, IEEE WORK CONF MIN S, P227, DOI 10.1109/MSR.2017.63; Pearce H., 2022, CODE DATASET EXAMINI; Pearce H., 2021, ARXIV210809293 CS; Pham TMT, 2020, INT C PROGRAM COMPRE, P308, DOI 10.1145/3387904.3389259; Polacek M., 2014, GCC UNDEFINED BEHAV; Qi ZM, 2015, PROCEEDINGS OF THE 2015 6TH INTERNATIONAL CONFERENCE ON AUTOMATION, ROBOTICS AND APPLICATIONS (ICARA), P22; Sahoo SK, 2013, ACM SIGPLAN NOTICES, V48, P139, DOI 10.1145/2499368.2451131; Serebryany Konstantin, 2012, USENIX Annual Technical Conference, P309; Steidl D, 2013, CONF PROC INT SYMP C, P83, DOI 10.1109/ICPC.2013.6613836; T. M. C. (MITRE, 2021, 2021 CWE TOP 25 MOST; T. M. C. (MITRE), VER US GUID VER 4 20; T. M. C. (MITRE), 2021, CWE 1194 CWE VIEW HA; T. M. C. (MITRE, 2020, CWE CWE COMP PROD SE; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Tufano M, 2018, IEEE INT CONF AUTOM, P832, DOI 10.1145/3238147.3240732; von Platen Patrick, 2020, How to generate text: using different decoding methods for language generation with Transformers; Xu F. F., 2022, SYSTEMATIC EVALUATIO; Yagemann C, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P320, DOI 10.1145/3460120.3485363; Yagemann C, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1989; Zeller A, 2002, IEEE T SOFTWARE ENG, V28, P183, DOI 10.1109/32.988498	52	27	29	3	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1081-6011		978-1-6654-9336-9	P IEEE S SECUR PRIV			2023							2339	2356		10.1109/SP46215.2023.10179420	http://dx.doi.org/10.1109/SP46215.2023.10179420			18	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4MI		Green Submitted			2024-07-03	WOS:001035501501001
C	Chen, JJ; Shi, W; Fu, ZQ; Cheng, SJ; Li, L; Xiao, YH		Rogers, A; Boyd-Graber, J; Okazaki, N		Chen, Jiangjie; Shi, Wei; Fu, Ziquan; Cheng, Sijie; Li, Lei; Xiao, Yanghua			<i>Say What You Mean!</i> Large Language Models Speak Too Positively about Negative Commonsense Knowledge	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			GRAPH	Large language models (LLMs) have been widely studied for their ability to store and utilize positive knowledge. However, negative knowledge, such as "lions don't live in the ocean", is also ubiquitous in the world but rarely mentioned explicitly in the text. What do LLMs know about negative knowledge? This work examines the ability of LLMs to negative commonsense knowledge. We design a constrained keywords-to-sentence generation task (CG) and a Boolean question-answering task (QA) to probe LLMs. Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge, yet they can correctly answer polar yes-or-no questions. We term this phenomenon the belief conflict of LLMs. Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict.(1)	[Chen, Jiangjie; Shi, Wei; Cheng, Sijie; Xiao, Yanghua] Fudan Univ, Shanghai Key Lab Data Sci, Sch Comp Sci, Shanghai, Peoples R China; [Fu, Ziquan] Syst Inc, Pittsburgh, PA USA; [Li, Lei] Univ Calif Santa Barbara, Santa Barbara, CA USA; [Xiao, Yanghua] Fudan Aishu Cognit Intelligence Joint Res Ctr, Shanghai, Peoples R China; [Fu, Ziquan] Brain Technol Inc, San Mateo, CA USA	Fudan University; University of California System; University of California Santa Barbara	Xiao, YH (corresponding author), Fudan Univ, Shanghai Key Lab Data Sci, Sch Comp Sci, Shanghai, Peoples R China.; Xiao, YH (corresponding author), Fudan Aishu Cognit Intelligence Joint Res Ctr, Shanghai, Peoples R China.	jjchen19@fudan.edu.cn; wshi22@m.fudan.edu.cn; frank@system.com; sjcheng20@fudan.edu.cn; leili@cs.ucsb.edu; shawyh@fudan.edu.cn			Science and Technology Commission of Shanghai Municipality Grant [22511105902]	Science and Technology Commission of Shanghai Municipality Grant(Science & Technology Commission of Shanghai Municipality (STCSM))	We thank the anonymous reviewers for their valuable comments. We also thank Siyu Yuan and Jian Xie from Fudan University, and Kexun Zhang, Yujian Liu, Qingxiu Dong and Xuandong Zhao from UC Santa Barbara for their useful suggestions and discussions for the manuscript. This research is funded by the Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902).	Aggarwal S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3050; Allaway Emily, 2022, ARXIV220511658; Arnaout H, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P37, DOI 10.1145/3511808.3557484; Arnaout H, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P544, DOI 10.1145/3442442.3452339; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Barker S, 2012, PHILOS PHENOMEN RES, V85, P117, DOI 10.1111/j.1933-1592.2010.00479.x; Bobzien Susanne, 2020, STANFORD ENCY PHILOS; Bommasani Rishi, 2021, ARXIV210807258; Branco R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1504; Camburu OM, 2018, ADV NEUR IN, V31; Cao BX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1860; Chen JJ, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3941; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Cheng Sijie, 2022, ARXIV221111160; Chowdhery A., 2022, ARXIV220402311; Chung Hyung Won, 2022, ARXIV221011416; Clark P, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3882; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Do N, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2061; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; Fitting Melvin, 2006, INTENSIONAL LOGIC; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Gubelmann R, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4602; Gururangan Suchin, 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-2017; Horn Laurence R., 2022, STANFORD ENCY PHILOS; Hossain MM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P716; Hosseini A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1301; Jang Joel, 2022, ARXIV220912711; Jung Jaehun, 2022, ARXIV220511822; Kassner N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8849; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Lai YX, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P989; Le Scao Teven, 2022, ARXIV221105100; Lin BY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1823; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Y, 2021, AAAI CONF ARTIF INTE, V35, P6418; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; MacDonald Charles, 1965, LAVAL THEOLOGIQUE PH, V21, P80; Min SW, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2791; Min Sewon, 2022, ARXIV220212837; Minsky Marvin, 1997, NEGATIVE EXPERTISE; Molnar G, 2000, AUSTRALAS J PHILOS, V78, P72, DOI 10.1080/00048400012349361; OpenAi, 2022, Chatgpt; Ouyang L., 2022, Advances in Neural Information Processing Systems; Petroni F., 2020, Automated Knowledge Base Construction; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Ravichander Abhilasha, 2022, ARXIV221100295; Reiter Ehud, 2019, ARXIV191108794; Richardson Kyle, 2022, ARXIV221107950; Rubin O, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2655; Safavi T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5633; Singh P, 2002, LECT NOTES COMPUT SC, V2519, P1223; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Speranza JL, 2010, J APPL LOGIC, V8, P277, DOI 10.1016/j.jal.2010.04.001; Sumers Theodore R, 2021, ARXIV210511950; Tafjord O, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3621; Tafjord Oyvind, 2022, ARXIV221012217; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Tian Bing, 2022, DEBIASING NLU MODELS; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang Xuezhi, 2022, ARXIV220311171; Wei JS, 2022, ADV NEUR IN; Wei JH, 2022, PR MACH LEARN RES; Welleck S., 2020, 8 INT C LEARN REPR I, P1; Yu WH, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3512467	68	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							9890	9908						19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962501035
J	Harrer, S				Harrer, Stefan			Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine	EBIOMEDICINE			English	Article						Generative arti fi cial intelligence; Large language models; Foundation models; AI ethics; Augmented; human intelligence; Information management; AI trustworthiness		Large Language Models (LLMs) are a key component of generative artificial intelligence (AI) applications for creating new content including text, imagery, audio, code, and videos in response to textual instructions. Without human oversight, guidance and responsible design and operation, such generative AI applications will remain a party trick with substantial potential for creating and spreading misinformation or harmful and inaccurate content at unprecedented scale. However, if positioned and developed responsibly as companions to humans augmenting but not replacing their role in decision making, knowledge retrieval and other cognitive processes, they could evolve into highly efficient, trustworthy, assistive tools for information management. This perspective describes how such tools could transform data management workflows in healthcare and medicine, explains how the underlying technology works, provides an assessment of risks and limitations, and proposes an ethical, technical, and cultural framework for responsible design, development, and deployment. It seeks to incentivise users, developers, providers, and regulators of generative AI that utilises LLMs to collectively prepare for the transformational role this technology could play in evidence-based sectors.	[Harrer, Stefan] Digital Hlth Cooperat Res Ctr, Melbourne, Vic, Australia	Digital Health Cooperative Research Centre (DHCRC)	Harrer, S (corresponding author), Digital Hlth Cooperat Res Ctr, Melbourne, Vic, Australia.	stefan.harrer@dhcrc.com		Harrer, Stefan/0000-0001-7947-330X				Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; [Anonymous], 2023, Forbes; [Anonymous], 2021, ETH GOV ART INT HLTH; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Binz M, 2023, P NATL ACAD SCI USA, V120; Blackman R., 2022, Harvard Business Review; Broderick R, 2022, WILD WORLD PROMPTBAS; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Callaway E, 2022, NATURE, V609, P661, DOI 10.1038/d41586-022-02947-7; Callaway E, 2022, NATURE, V608, P15, DOI 10.1038/d41586-022-02083-2; Christian B., 2020, The Alignment Problem: Machine Learning and Human Values; Clynch N, 2015, INT J MED INFORM, V84, P221, DOI 10.1016/j.ijmedinf.2014.12.001; Coalition for Health AI, 2022, CHAI CONSULTATION PA; Crawford E., 2023, CHEMISTRYWORLD; Croak M, 2023, RESPONSIBLE AI LOOKI; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dominguez D, 2022, OPENAI INTRO INSTRUC; eikkil M., 2022, MIT TECHNOL REV; ewton C, 2023, PLATFORMER; Frankfurt Harry., 1988, IMPORTANCE WHAT WE C, P47, DOI [10.1017/CBO9780511818172.011, DOI 10.1017/CBO9780511818172.011]; Gharpure R, 2020, MMWR-MORBID MORTAL W, V69, P705, DOI [10.15585/mmwr.mm6923e2, 10.1111/ajt.16300]; Goldman S., 2023, STABLE DIFFUSION ART; Gordon R, 2022, MIT NEWS; Grady P, 2022, GPT 3 GENERATIVE CRE; Greene T, 2022, META TAKES NEW AI SY; Harrer S, 2021, FORBES; Harrer S, 2019, TRENDS PHARMACOL SCI, V40, P577, DOI 10.1016/j.tips.2019.05.005; Heikkil M, 2022, MIT TECHNOL REV; Henry T, 2018, DO YOU SPEND MORE TI; Hosurmath M, 2021, AI 360 TOOLKIT AI MO; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Komorowski M, 2018, NAT MED, V24, P1716, DOI 10.1038/s41591-018-0213-5; Kovanovic V, 2023, FREETHINK; Kung T H., 2022, medRxiv, DOI DOI 10.1371/JOURNAL.PDIG.0000198; Lardinois F, 2023, MICROSOFT LAUNCHES N; Larsen B, 2023, WORLD EC FORUM; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Lipman J, 2023, TIME MAGAZINE; Lohr S., 2022, TheNew York Times; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Lyons Kim., 2020, VERGE; Marcus G., 2023, LARGE LANGUAGE MODEL; Metz C., 2022, The New York Times; Microsoft AI, 2023, RESP AI RES; Miller K, 2023, HUMAN WRITER AI SCHO; OpenAI, 2023, DALLE 2; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Perrigo B, 2023, Time Magazine; Philippidis A., 2023, Genetic Engineering & Biotechnology News; Pichai S., 2023, IMPORTANT NEXT STEP; Roose Kevin, 2022, NEW YORK TIMES; Rushabh HD, 2023, PROMISES PITFALLS CH; Sevilla J, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9891914; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Snoswell AJ, 2022, SILICONREPUBLIC; stability.ai, 2022, STABLE DIFFUSION V21; Strickland Eliza., 2022, Andrew Ng: Unbiggen AI; The Ezra Klein Show, 2023, NEW YORK TIMES; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tiernan R., 2022, METAS AI GURU LECUN; Tiku Nitasha., 2023, WASH POST; Topol E, 2023, GROUNDTRUTHS; Topol E.J., 2016, The patient will see you now: the future of medicine is in your hands; Ulloa M., 2022, FRONT COMPUT SCI-CHI, V4, P157; Vaswani A, 2017, ADV NEUR IN, V30; Verma P., 2022, The Washington Post; Vincent J., 2022, VERGE; Vincent James, 2023, The Verge; Vishwam S, 2023, INDEPENDENT; Wiggers K., 2022, TechCrunch; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhavoronkov A, 2023, NAT MED, V29, P532, DOI 10.1038/d41591-023-00014-w	75	94	97	174	397	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-3964			EBIOMEDICINE	EBioMedicine	APR	2023	90								104512	10.1016/j.ebiom.2023.104512	http://dx.doi.org/10.1016/j.ebiom.2023.104512		MAR 2023	12	Medicine, General & Internal; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Research & Experimental Medicine	0A3FC	36924620	Green Published			2024-07-03	WOS:000951710800001
C	Hamadanian, P; Arzani, B; Fouladi, S; Kakarla, SKR; Fonseca, R; Billor, D; Cheema, A; Nkposong, E; Chandra, R			ACM	Hamadanian, Pouya; Arzani, Behnaz; Fouladi, Sadjad; Kakarla, Siva Kesava Reddy; Fonseca, Rodrigo; Billor, Denizcan; Cheema, Ahmad; Nkposong, Edet; Chandra, Ranveer			A Holistic View of AI-driven Network Incident Management	PROCEEDINGS OF THE 22ND ACM WORKSHOP ON HOT TOPICS IN NETWORKS, HOTNETS 2023			English	Proceedings Paper	22nd ACM Workshop on Hot Topics in Networks (HotNets)	NOV 28-29, 2023	Cambridge, MA	Assoc Comp Machinery, ACM SIGCOMM		Large Language Models; Incident Management		We discuss the potential improvement large language models (LLM) can provide in incident management and how they can overhaul the ways operators conduct incident management today. We propose a holistic framework for building an AI helper for incident management and discuss the several avenues of future research needed to achieve it. We thoroughly analyze the fundamental requirements the community should consider when designing such helpers. Our work is based on discussions with operators of a large public cloud provider and their prior experiences both in incident management and with attempts to improve the incident management experience through various forms of automation.	[Hamadanian, Pouya] MIT, Cambridge, MA 02139 USA; [Arzani, Behnaz; Fouladi, Sadjad; Kakarla, Siva Kesava Reddy; Chandra, Ranveer] Microsoft Res, Bangalore, Karnataka, India; [Fonseca, Rodrigo] Azure Syst Res, Bangalore, Karnataka, India; [Billor, Denizcan; Cheema, Ahmad; Nkposong, Edet] Microsoft, Bangalore, Karnataka, India	Massachusetts Institute of Technology (MIT); Microsoft	Hamadanian, P (corresponding author), MIT, Cambridge, MA 02139 USA.			Fonseca, Rodrigo/0000-0001-9662-2661; Kakarla, Siva Kesava Reddy/0009-0006-2694-4685				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed T, 2023, Arxiv, DOI arXiv:2301.03797; Alipourfard O, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P414, DOI 10.1145/3341301.3359664; Alomar A, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P1115; Amazon Web Services, 2021, Summary of AWS Direct Connect Event in the Tokyo (AP-NORTHEAST-1) Region; Arzani Behnaz., 2021, arXiv; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Bubeck S., 2023, arXiv; Chase H., 2022, Langchain; Chen JJ, 2020, IEEE INT CONF AUTOM, P373, DOI 10.1145/3324884.3416624; Chen JJ, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P364, DOI 10.1109/ASE.2019.00042; Chen M., 2021, arXiv; Chen Yinfang, 2023, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Claessen K, 2000, ACM SIGPLAN NOTICES, V35, P268, DOI 10.1145/357766.351266; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cowan M, 2022, Arxiv, DOI arXiv:2201.11840; DAY JD, 1983, P IEEE, V71, P1334, DOI 10.1109/PROC.1983.12775; Du YL, 2023, Arxiv, DOI arXiv:2305.14325; Fernandez Marisa, 2018, Prime Day woes might have cost Amazon 72..-99m in sales; First E, 2023, Arxiv, DOI [arXiv:2303.04910, DOI 10.48550/ARXIV.2303.04910.9]; Gao JQ, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P253, DOI 10.1145/3387514.3405867; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Govindan R, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P58, DOI 10.1145/2934872.2934891; Guu K, 2020, Arxiv, DOI arXiv:2002.08909; Jiang JJ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1410, DOI 10.1145/3368089.3417054; Kim G, 2023, Arxiv, DOI arXiv:2303.17491; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Langley A, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P183, DOI 10.1145/3098822.3098842; Li YL, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P311; Liu Aiwei, 2023, arXiv; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Microsoft, 2023, LangChain; Microsoft Azure, 2023, Post Incident Review (PIR)-Azure Networking-Global WAN issues; Mogul JC, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P403; Moshref M, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P129, DOI 10.1145/2934872.2934879; Moshref M, 2014, ACM SIGCOMM COMP COM, V44, P419, DOI 10.1145/2740070.2626291; Nakajima Yohei, 2023, Task-driven autonomous agent utilizing gpt-4, pinecone, and langchain for diverse applications; Namyar P, 2023, Arxiv, DOI arXiv:2305.13792; Nye Maxwell, 2021, arXiv; OpenAI, 2023, ChatGPT plugins; Paul D, 2024, Arxiv, DOI [arXiv:2304.01904, 10.48550/arXiv.2304.01904]; Schick T., 2023, arXiv; Shah A, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P593; Shetty Manish, 2022, arXiv; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Sun RX, 2024, Arxiv, DOI arXiv:2306.00739; Tan C, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P599; Wang W, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P739; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu X, 2012, ACM SIGCOMM COMP COM, V42, P419, DOI 10.1145/2377677.2377759; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zeng A., 2022, ARXIV; Zhang SL, 2023, Arxiv, DOI arXiv:2302.10512; Zhuo DY, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P362, DOI 10.1145/3098822.3098849	58	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0415-4				2023							180	188		10.1145/3626111.3628176	http://dx.doi.org/10.1145/3626111.3628176			9	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TD		hybrid			2024-07-03	WOS:001124843800024
J	Kim, S; Kim, K; Jo, CW				Kim, Soojong; Kim, Kwanho; Jo, Claire Wonjeong			Accuracy of a large language model in distinguishing anti- and pro-vaccination messages on social media: The case of human papillomavirus vaccination	PREVENTIVE MEDICINE REPORTS			English	Article						Artificial intelligence; Large Language Models; Vaccination; Social media; Public discourse; Human Papillomavirus		Objective: Vaccination has engendered a spectrum of public opinions, with social media acting as a crucial platform for health-related discussions. The emergence of artificial intelligence technologies, such as large language models (LLMs), offers a novel opportunity to efficiently investigate public discourses. This research assesses the accuracy of ChatGPT, a widely used and freely available service built upon an LLM, for sentiment analysis to discern different stances toward Human Papillomavirus (HPV) vaccination. Methods: Messages related to HPV vaccination were collected from social media supporting different message formats: Facebook (long format) and Twitter (short format). A selection of 1,000 human-evaluated messages was input into the LLM, which generated multiple response instances containing its classification results. Accuracy was measured for each message as the level of concurrence between human and machine decisions, ranging between 0 and 1. Results: Average accuracy was notably high when 20 response instances were used to determine the machine decision of each message: .882 (SE = .021) and .750 (SE = .029) for anti- and pro-vaccination long-form; .773 (SE = .027) and .723 (SE = .029) for anti- and pro-vaccination short-form, respectively. Using only three or even one instance did not lead to a severe decrease in accuracy. However, for long-form messages, the language model exhibited significantly lower accuracy in categorizing pro-vaccination messages than anti-vaccination ones. Conclusions: ChatGPT shows potential in analyzing public opinions on HPV vaccination using social media content. However, understanding the characteristics and limitations of a language model within specific public health contexts remains imperative.	[Kim, Soojong; Jo, Claire Wonjeong] Univ Calif Davis, Dept Commun, Davis, CA USA; [Kim, Kwanho] Cornell Univ, Dept Commun, Ithaca, NY USA; [Kim, Soojong] Univ Calif Davis, Dept Commun, 1 Shields Ave,Kerr Hall 361, Davis, CA 95616 USA	University of California System; University of California Davis; Cornell University; University of California System; University of California Davis	Kim, S (corresponding author), Univ Calif Davis, Dept Commun, 1 Shields Ave,Kerr Hall 361, Davis, CA 95616 USA.	sjokim@ucdavis.edu						Alipour S, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-53124-x; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Blane J.T., 2023, Vaccine Communication Online: Counteracting Misinformation, Rumors and Lies, P57, DOI DOI 10.1007/978-3-031-24490-2_4; Chou WYS, 2020, AM J PUBLIC HEALTH, V110, pS273, DOI 10.2105/AJPH.2020.305905; Chou WYS, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1249; Cruickshank I, 2021, J MED INTERNET RES, V23, DOI 10.2196/29127; Dunn AG, 2017, VACCINE, V35, P3033, DOI 10.1016/j.vaccine.2017.04.060; Heseltine M, 2024, RES POLITICS, V11, DOI 10.1177/20531680241236239; Hornik R, 2022, J COMMUN, V72, P187, DOI 10.1093/joc/jqab052; Hu K., 2023, REUTERS, V12; Huang JD, 2014, TOB CONTROL, V23, P26, DOI 10.1136/tobaccocontrol-2014-051551; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Katz Daniel Martin, 2023, GPT-4 Passes the Bar Exam, DOI DOI 10.2139/SSRN.4389233; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; OpenAI, 2022, Introducing chatgpt; Paul E, 2021, LANCET REG HEALTH-EU, V1, DOI 10.1016/j.lanepe.2020.100012; Shapiro GK, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2017-016869; Shing JZ, 2022, AM J PREV MED, V62, P395, DOI 10.1016/j.amepre.2021.08.017; Sonawane K, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.24502; Sturgis P, 2021, NAT HUM BEHAV, V5, P1528, DOI 10.1038/s41562-021-01115-7; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Valdez D, 2023, SOC SCI MED, V339, DOI 10.1016/j.socscimed.2023.116365; Xu F, arXiv; Yaqub O, 2014, SOC SCI MED, V112, P1, DOI 10.1016/j.socscimed.2014.04.018; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	25	0	0	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2211-3355		PREV MED REP	Prev. Med. Rep.	JUN	2024	42								102723	10.1016/j.pmedr.2024.102723	http://dx.doi.org/10.1016/j.pmedr.2024.102723			5	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED)	Public, Environmental & Occupational Health	SD4A2	38659997	gold, Green Submitted			2024-07-03	WOS:001232494500001
J	Xia, LQ; Li, CX; Zhang, CB; Liu, SM; Zheng, P				Xia, Liqiao; Li, Chengxi; Zhang, Canbin; Liu, Shimin; Zheng, Pai			Leveraging error-assisted fine-tuning large language models for manufacturing excellence	ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING			English	Article						Large language model; Smart manufacturing; Industry 4.0; Knowledge management; Generative AI		The emergence of large language models (LLM), like GPT, is revolutionizing the field of information retrieval, finding applications across a wide range of domains. However, the intricate domain knowledge and the unique software paradigms inherent to the manufacturing sector have posed significant barriers to the effective utilization of LLM. To address this divide, an error-assisted fine-tuning approach is proposed to adapt LLM specifically for the manufacturing domain. Initially, the LLM is fine-tuned using a manufacturing-domain corpus, allowing it to learn and adapt to the nuances of the manufacturing field. Additionally, the injection of a labeled dataset into a pre-configured LLM enhances its ability to identify key elements within the domain. To ensure the generation of syntactically valid programs in domain-specific languages, and to accommodate environmental constraints, an error-assisted iterative prompting procedure is introduced, which facilitates the generation of reliable and expected code. Experimental results demonstrate the model's proficiency in accurately responding to manufacturing-related queries and its effectiveness in generating reliable code, where the accuracy of judgment querying can experience an improvement of approximately 4.1%. By expanding the applicability of LLM to the manufacturing industry, it is hoped that this research will pave the way for a broad array of new LLM-based applications within manufacturing.	[Xia, Liqiao; Li, Chengxi; Zhang, Canbin; Liu, Shimin; Zheng, Pai] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong, Peoples R China; [Zhang, Canbin] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Key Lab Ultra precis Machining Technol, Hong Kong, Peoples R China	Hong Kong Polytechnic University; Hong Kong Polytechnic University	Zheng, P (corresponding author), Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong, Peoples R China.	pai.zheng@polyu.edu.hk	Li, Chengxi/CAG-9066-2022	Li, Chengxi/0000-0003-1921-7448; ZHENG, PAI/0000-0002-2329-8634	Mainland-Hong Kong Joint Funding Scheme [MHX/001/20]; Shanghai Science and Technology Program [22010500900]; Innovation and Technology Commission (ITC), Hong Kong Special Administration Region, National Key R&D Programs of Cooperation on Science and Technology Innovation with Hong Kong, Macao and Taiwan [2020YFE020182]; Ministry of Science and Technology (MOST) of the People's Republic of China; State Key Laboratory of Ultra-Precision Machining Technology [1-BBR2]; Hong Kong Polytechnic University, HKSAR, China	Mainland-Hong Kong Joint Funding Scheme; Shanghai Science and Technology Program; Innovation and Technology Commission (ITC), Hong Kong Special Administration Region, National Key R&D Programs of Cooperation on Science and Technology Innovation with Hong Kong, Macao and Taiwan; Ministry of Science and Technology (MOST) of the People's Republic of China(Ministry of Science and Technology, China); State Key Laboratory of Ultra-Precision Machining Technology; Hong Kong Polytechnic University, HKSAR, China(Hong Kong Polytechnic University)	This research is partially funded by the Mainland-Hong Kong Joint Funding Scheme (MHX/001/20) , Shanghai Science and Technology Program under Grant (22010500900) , Innovation and Technology Commission (ITC), Hong Kong Special Administration Region, National Key R & D Programs of Cooperation on Science and Technology Innovation with Hong Kong, Macao and Taiwan (2020YFE020182) , Ministry of Science and Technology (MOST) of the People's Republic of China, and State Key Laboratory of Ultra-Precision Machining Technology (Project No. 1-BBR2) , The Hong Kong Polytechnic University, HKSAR, China.	Addepalli Sri, 2023, CIRP Ann; Akay Haluk, 2023, CIRP Ann; Badini S, 2023, ADV IND ENG POLY RES, V6, P278, DOI 10.1016/j.aiepr.2023.03.003; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Behnia R, 2022, INT CONF DAT MIN WOR, P560, DOI 10.1109/ICDMW58026.2022.00078; Chen Hongpeng, 2022, IEEE Trans. Instrum. Meas., V71, P1; Chen TY, 2021, IEEE ACCESS, V9, P82118, DOI 10.1109/ACCESS.2021.3083518; Cui YS, 2020, ROBOT CIM-INT MANUF, V62, DOI 10.1016/j.rcim.2019.101861; Gema Aryo, 2023, arXiv; Ghosal D, 2023, Arxiv, DOI arXiv:2304.13731; Keung KL, 2023, ROBOT CIM-INT MANUF, V83, DOI 10.1016/j.rcim.2023.102578; Kim J, 2023, Arxiv, DOI arXiv:2305.14152; Kitaev N., 2020, arXiv; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Li SF, 2023, ROBOT CIM-INT MANUF, V81, DOI 10.1016/j.rcim.2022.102510; Lim KYH, 2024, INT J PROD RES, V62, P4717, DOI 10.1080/00207543.2023.2274335; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu XG, 2022, IEEE ACCESS, V10, P75816, DOI 10.1109/ACCESS.2022.3191678; Majeed A, 2021, ROBOT CIM-INT MANUF, V67, DOI 10.1016/j.rcim.2020.102026; Qiu J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062166; Radford A., 2018, IMPROVING LANGUAGE U; Ruiz E, 2023, COMPUT IND, V151, DOI 10.1016/j.compind.2023.103988; Skreta M, 2023, Arxiv, DOI arXiv:2303.14100; Wang Xingzhi, 2023, Procedia CIRP, P7, DOI 10.1016/j.procir.2023.04.001; Xia LQ, 2023, RELIAB ENG SYST SAFE, V232, DOI 10.1016/j.ress.2022.109068; Xia LQ, 2022, J MANUF SYST, V64, P107, DOI 10.1016/j.jmsy.2022.06.002; Xiong HL, 2023, Arxiv, DOI arXiv:2304.01097; Yin Y, 2023, ADV ENG INFORM, V58, DOI 10.1016/j.aei.2023.102203; Zhang Guozhen, 2021, Math. Probl. Eng, V2021; Zhang YZ, 2014, INT J ADV MANUF TECH, V73, P1011, DOI 10.1007/s00170-014-5864-x; Zheng C, 2022, ROBOT CIM-INT MANUF, V73, DOI 10.1016/j.rcim.2021.102238; Zheng P, 2021, J MANUF SYST, V61, P16, DOI 10.1016/j.jmsy.2021.08.002	32	2	2	44	44	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0736-5845	1879-2537		ROBOT CIM-INT MANUF	Robot. Comput.-Integr. Manuf.	AUG	2024	88								102728	10.1016/j.rcim.2024.102728	http://dx.doi.org/10.1016/j.rcim.2024.102728		JAN 2024	9	Computer Science, Interdisciplinary Applications; Engineering, Manufacturing; Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Robotics	JD5O5					2024-07-03	WOS:001171237200001
J	Lupo, R; Vitale, E; Panzanaro, L; Lezzi, A; Lezzi, P; Botti, S; Rubbi, I; Carvello, M; Calabro, A; Puglia, A; Conte, L; De Nunzio, G				Lupo, Roberto; Vitale, Elsa; Panzanaro, Ludovica; Lezzi, Alessia; Lezzi, Pierluigi; Botti, Stefano; Rubbi, Ivan; Carvello, Maicol; Calabro, Antonino; Puglia, Alessandra; Conte, Luana; De Nunzio, Giorgio			Effects of Long COVID on Psycho-Physical Conditions in the Italian Population: A Statistical and Large Language Model Combined Description	EUROPEAN JOURNAL OF INVESTIGATION IN HEALTH PSYCHOLOGY AND EDUCATION			English	Article						long COVID; SARS-CoV-2; generative artificial intelligence; large language models; GPT; LangChain	MENTAL-HEALTH; INTERNET-USE; HIKIKOMORI	Background: Long COVID refers to the persistence or development of signs and symptoms well after the acute phase of COVID-19. Objective of the study: To investigate the long-term outcomes of the SARS-CoV-2 infection in terms of psychological, social, and relational consequences within the Italian population. Materials and methods: We conducted an observational, cross-sectional, and multicenter study using an online questionnaire distributed to a sample of the Italian population. By utilizing the Short Form 12 Health Survey (SF-12) and the Hikikomori scale, we assessed perceived quality of life and social isolation, respectively. The questionnaire also included an open-answer question: "What will you remember about the pandemic period?". We used generative artificial intelligence to analyze and summarize the corresponding answers. Results: A total of 1097 people participated in this study. A total of 79.3% (n = 870) of participants declared that they had been hospitalized and 62.8% (n = 689) received home care. Physical symptoms included headaches (43%, n = 472) and asthma (30.4%, n = 334). Additionally, 29.2% (n = 320) developed an addiction during the pandemic and, among these, 224 claimed internet addiction while 73 declared an emotional addiction. Furthermore, 51.8% (n = 568) experienced limitations in carrying out daily life activities. According to the Hikikomori scale, participants with positive SARS-CoV-2 infection exhibited higher levels of isolation compared to the others (p < 0.001). Participants without COVID-19 showed higher levels of emotional support (p < 0.001). Our semiautomatic analysis of the open-ended responses, obtained by a procedure based on a free large language model, allowed us to deduce and summarize the main feelings expressed by the interviewees regarding the pandemic. Conclusions: The data collected emphasize the urgent need to investigate the consequences of long COVID in order to implement interventions to support psychological well-being.	[Lupo, Roberto] San Giuseppe Copertino Hosp, ASL Local Hlth Author Lecce, I-73043 Lecce, LE, Italy; [Vitale, Elsa] ASL Local Hlth Author Bari, Dept Mental Hlth, I- 70100 Bari, BA, Italy; [Panzanaro, Ludovica] Sol Levante Srl, CRAP Carrubo, I-74020 Avetrana, TA, Italy; [Lezzi, Alessia] ANT Italian Onlus Fdn, Natl Canc Assoc, I-73100 Lecce, LE, Italy; [Lezzi, Pierluigi] Veris Delli Ponti Hosp, ASL Local Hlth Author, I-73020 Scorrano, LE, Italy; [Botti, Stefano] Azienda USL IRCCS Reggio Emilia, Hematol Unit, I-42100 Reggio Emilia, RE, Italy; [Rubbi, Ivan] Univ Bologna, Sch Nursing, I-40126 Bologna, BO, Italy; [Carvello, Maicol] ASL Local Hlth Author Romagna, Community Hosp, I-48121 Ravenna, RA, Italy; [Calabro, Antonino] Nuovo Osped Infermi Hosp, ASL Local Hlth Author, I-13900 Biella, BI, Italy; [Puglia, Alessandra] Perrino Hosp, ASL Local Hlth Author Brindisi, I-72100 Brindisi, BR, Italy; [Conte, Luana; De Nunzio, Giorgio] Univ Salento, Dept Math & Phys E De Giorgi, Lab Biomed Phys & Environm, I-73100 Lecce, LE, Italy; [Conte, Luana; De Nunzio, Giorgio] ASL Local Hlth Author, Lab Interdisciplinary Res Appl Med DReAM, Adv Data Anal Med ADAM, I-73100 Lecce, LE, Italy; [Conte, Luana; De Nunzio, Giorgio] Univ Salento, I-73100 Lecce, LE, Italy	IRCCS Saverio de Bellis; University of Bologna; University of Salento; University of Salento	Conte, L (corresponding author), Univ Salento, Dept Math & Phys E De Giorgi, Lab Biomed Phys & Environm, I-73100 Lecce, LE, Italy.; Conte, L (corresponding author), ASL Local Hlth Author, Lab Interdisciplinary Res Appl Med DReAM, Adv Data Anal Med ADAM, I-73100 Lecce, LE, Italy.; Conte, L (corresponding author), Univ Salento, I-73100 Lecce, LE, Italy.	roberto.lupo@uniba.it; vitaleelsa@libero.it; ludovica.panzanaro@hotmail.it; 1alessia.lezzi@gmail.com; pierlezzi@gmail.com; stefano.botti@ausl.re.it; maicol.carvello2@unibo.it; anto.cala76@gmail.com; alessandra.puglia@live.it; luana.conte@unisalento.it; giorgio.denunzio@unisalento.it	Vitale, Elsa/D-8904-2018; Botti, Stefano/AAA-5994-2021; Rubbi, Ivan/AAL-2367-2020; De Nunzio, Giorgio/L-7283-2015	Vitale, Elsa/0000-0002-9738-3479; Botti, Stefano/0000-0002-0678-0242; Rubbi, Ivan/0000-0001-6067-9578; Calabro, Antonino/0000-0003-2843-6693; Panzanaro, Ludovica/0009-0004-2258-7583; Conte, Luana/0000-0002-8741-3478; De Nunzio, Giorgio/0000-0002-1998-0286				Aiyegbusi OL, 2021, J ROY SOC MED, V114, P428, DOI 10.1177/01410768211032850; Alijanzadeh M, 2021, ASIAN J SOC HEAL BEH, V4, P45, DOI 10.4103/shb.shb_55_20; Alimoradi Z, 2022, CURR ADDICT REP, V9, P486, DOI 10.1007/s40429-022-00435-6; Mota DCB, 2021, CIENC SAUDE COLETIVA, V26, P2159, DOI 10.1590/1413-81232021266.44142020; Bonsaksen T, 2022, LIFE-BASEL, V12, DOI 10.3390/life12060901; Brand M, 2016, NEUROSCI BIOBEHAV R, V71, P252, DOI 10.1016/j.neubiorev.2016.08.033; Burkauskas J, 2022, CURR OPIN BEHAV SCI, V46, DOI 10.1016/j.cobeha.2022.101179; Centre for Suicide Prevention, 2020, Depression and Suicide Prevention; Chen CY, 2022, J ADDICT MED, V16, pE73, DOI 10.1097/ADM.0000000000000845; Chen IH, 2021, J BEHAV ADDICT, V10, P731, DOI 10.1556/2006.2021.00052; Chia YK, 2023, Arxiv, DOI arXiv:2306.04757; Coloma-Carmona A, 2021, J AFFECT DISORDERS, V294, P329, DOI 10.1016/j.jad.2021.07.032; Craparo G, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20010494; Feikin DR, 2022, LANCET, V399, P924, DOI 10.1016/S0140-6736(22)00152-0; Fung XCC, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.675839; Gecaite-Stonciene J, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.634464; Gondim FAA, 2017, ASIAN J PSYCHIATR, V30, P163, DOI 10.1016/j.ajp.2017.10.009; Groff D, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.28568; Hampshire A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24365-5; Honcharova O, 2022, STUD WARM, P63, DOI 10.31648/sw.8327; KING DL, 2022, J BEHAV ADDICT, V11, P243, DOI 10.1556/2006.2022.00011; Manfredini Alessio, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20064889; Moretti Chiara, 2022, Acta Biomed, V93, pe2022349, DOI 10.23750/abm.v93i6.14059; Nandwani P, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00776-6; O'Rourke MC., 2020, STATPEARLS; Pakpour AH, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.740333; Prioste C.D., 2019, DOXA Rev. Bras. Psicol. Educ, V21, P4, DOI [10.30715/doxa.v21i1.12931, DOI 10.30715/DOXA.V21I1.12931]; Rooksby M, 2020, WORLD PSYCHIATRY, V19, P399, DOI 10.1002/wps.20804; Roza TH, 2020, BRAZ J PSYCHIAT, V42, P454, DOI 10.1590/1516-4446-2020-0804; Shirali GA, 2021, ASIAN J SOC HEAL BEH, V4, P131, DOI 10.4103/shb.shb_74_21; Sykes DL, 2021, LUNG, V199, P113, DOI 10.1007/s00408-021-00423-z; Venkatesan P, 2021, LANCET RESP MED, V9, P129, DOI 10.1016/S2213-2600(21)00031-X; Vitale Elsa, 2021, Acta Biomed, V92, pe2021007, DOI 10.23750/abm.v92iS2.11305; Wahlster W, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0049; Wolf S, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-08384-6; World Health Organization (WHO), US; Xia S, 2020, SIGNAL TRANSDUCT TAR, V5, DOI 10.1038/s41392-020-0184-0; Zhou JY, 2020, AM J PSYCHIAT, V177, P574, DOI 10.1176/appi.ajp.2020.20030304	38	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2254-9625		EUR J INVEST HEALTH	Eur. J. Invest. Health Psychol. Educ.	MAY	2024	14	5					1153	1170		10.3390/ejihpe14050076	http://dx.doi.org/10.3390/ejihpe14050076			18	Psychology, Clinical	Emerging Sources Citation Index (ESCI)	Psychology	SM3S5	38785574				2024-07-03	WOS:001234836600001
J	Bronzini, M; Nicolini, C; Lepri, B; Passerini, A; Staiano, J				Bronzini, Marco; Nicolini, Carlo; Lepri, Bruno; Passerini, Andrea; Staiano, Jacopo			Glitter or gold? Deriving structured insights from sustainability reports via large language models	EPJ DATA SCIENCE			English	Article						ESG dimensions; Non-financial disclosures; Large language models; In-context learning; Knowledge graphs; Bipartite graph analyses; Interpretability	BETWEENNESS CENTRALITY; GRAPHS; ERROR	Over the last decade, several regulatory bodies have started requiring the disclosure of non-financial information from publicly listed companies, in light of the investors' increasing attention to Environmental, Social, and Governance (ESG) issues. Publicly released information on sustainability practices is often disclosed in diverse, unstructured, and multi-modal documentation. This poses a challenge in efficiently gathering and aligning the data into a unified framework to derive insights related to Corporate Social Responsibility (CSR). Thus, using Information Extraction (IE) methods becomes an intuitive choice for delivering insightful and actionable data to stakeholders. In this study, we employ Large Language Models (LLMs), In-Context Learning, and the Retrieval-Augmented Generation (RAG) paradigm to extract structured insights related to ESG aspects from companies' sustainability reports. We then leverage graph-based representations to conduct statistical analyses concerning the extracted insights. These analyses revealed that ESG criteria cover a wide range of topics, exceeding 500, often beyond those considered in existing categorizations, and are addressed by companies through a variety of initiatives. Moreover, disclosure similarities emerged among companies from the same region or sector, validating ongoing hypotheses in the ESG literature. Lastly, by incorporating additional company attributes into our analyses, we investigated which factors impact the most on companies' ESG ratings, showing that ESG disclosure affects the obtained ratings more than other financial or company data.	[Bronzini, Marco; Passerini, Andrea; Staiano, Jacopo] Univ Trento, Trento, Italy; [Bronzini, Marco; Nicolini, Carlo; Lepri, Bruno] Ipazia SpA, Milan, Italy; [Lepri, Bruno] Fdn Bruno Kessler FBK, Trento, Italy	University of Trento; Fondazione Bruno Kessler	Bronzini, M (corresponding author), Univ Trento, Trento, Italy.; Bronzini, M (corresponding author), Ipazia SpA, Milan, Italy.	marco.bronzini-1@unitn.it		Bronzini, Marco/0009-0004-9691-9464; passerini, andrea/0000-0002-2765-5395	FAIR - Future AI Research	FAIR - Future AI Research	We express our gratitude to the Reviewers for dedicating their time and effort to assess the manuscript. We genuinely value the insightful comments and suggestions that have contributed to enhancing the overall quality of the manuscript.	Abdi H., 2007, Encycl. Meas. Stat, V2, P508; Abhayawansa S., 2021, J WEALTH MANAGEMENT, V24, P49, DOI [10.3905/JWM.2021.1.130, DOI 10.3905/JWM.2021.1.130, 10.3905/jwm.2021.1.130]; Admin@Evo, 2023, Why impact materiality is critical to double materiality assessments; Aliakbari E, 2023, The impracticality of standardizing ESG reporting (ESG: myths and realities); Allen Institute for AI, open information extraction-demo; [Anonymous], ChatClimate grounded on the latest IPCC report; [Anonymous], Hugging Face: statistics on the number of monolingual models by language hosted on the Hugging Face platform; [Anonymous], European Union: fit for 55; [Anonymous], SDG Prospector-artificial intelligence serving the SDGs; [Anonymous], IR Solutions: ResponsibilityReports; [Anonymous], 2022, Refinitiv: environmental, social and governance (ESG) scores from Refinitiv; [Anonymous], 2022, Working paper: balancing your materiality assessment; [Anonymous], Non-financial reporting | European Commission; [Anonymous], SUSTAINABLE DEV AGEN; Asratian A.S., 1998, Bipartite Graphs and their Applications, DOI DOI 10.1017/CBO9780511984068; Axelsson A, 2023, arXiv; Baldini M, 2018, J BUS ETHICS, V150, P79, DOI 10.1007/s10551-016-3139-1; Barthélemy M, 2004, EUR PHYS J B, V38, P163, DOI 10.1140/epjb/e2004-00111-4; Bast H, 2016, FOUND TRENDS INF RET, V10, P120, DOI 10.1561/1500000032; Benesty J., 2009, Noise reduction in speech processing, V2, P1, DOI [10.1007/978-3-642-00296-05, DOI 10.1007/978-3-642-00296-05, DOI 10.1007/978-3-642-00296-0_5]; Berg F, 2022, REV FINANC, V26, P1315, DOI 10.1093/rof/rfac033; Berrar D., 2019, Cross-Validation, P542, DOI DOI 10.1016/B978-0-12-809633-8.20349-X; Billio M, 2021, CORP SOC RESP ENV MA, V28, P1426, DOI 10.1002/csr.2177; Brandes U., 2005, Network analysis: methodological foundations, DOI DOI 10.1007/B106453; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Busco C, 2020, J APPL CORP FINANC, V32, P117, DOI 10.1111/jacf.12411; Buttcher Stefan, 2010, Information retrieval: Implementing and evaluating search engines; Campbell JL, 2007, ACAD MANAGE REV, V32, P946, DOI 10.5465/AMR.2007.25275684; Carta S, 2023, Arxiv, DOI arXiv:2307.01128; Chatterji AK, 2016, STRATEGIC MANAGE J, V37, P1597, DOI 10.1002/smj.2407; Chen J, 2023, Arxiv, DOI arXiv:2305.09858; Chou C, 2023, CORP SOC RESP ENV MA, V30, P2664, DOI 10.1002/csr.2509; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Costa LD, 2021, Arxiv, DOI arXiv:2110.09619; Cover T. M., 2006, Elements of Information Theory, V2nd, DOI DOI 10.1002/047174882X; Croft W. B., 2010, Search engines: information retrieval in practice, V520; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dismuke C., 2006, METHODS DESIGNS OUTC, V93, P93; Dobrick J, 2023, FINANC RES LETT, V55, DOI 10.1016/j.frl.2023.104014; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Doyle TM, 2018, American Council for Capital Formation, P65; Draper N., 1998, Applied Regression Analysis, DOI DOI 10.1002/9781118625590; Drempetic S, 2020, J BUS ETHICS, V167, P333, DOI 10.1007/s10551-019-04164-1; Eccles RG, 2012, J APPL CORP FINANC, V24, P65, DOI 10.1111/j.1745-6622.2012.00380.x; Ehlers T., 2023, IMF Work Pap, V2023, DOI [10.5089/9798400235283.001.A001, DOI 10.5089/9798400235283.001.A001]; Estrada E., 2011, The Structure of Complex Networks: Theory and Applications, DOI DOI 10.1093/ACPROF:OSO/9780199591756.001.0001; European Union, corporate sustainability reporting directive (CSRD); European Union, EU emissions trading system (EU ETS); Faust K, 1997, SOC NETWORKS, V19, P157, DOI 10.1016/S0378-8733(96)00300-0; Fensel D., 2020, KNOWLEDGE GRAPHS, P1, DOI [DOI 10.1007/978-3-030-37439-6, 10.1007/978-3-030-37439-6, 10.1007/978-3-030-37439-61]; Gotelli NJ, 2012, OIKOS, V121, P171, DOI 10.1111/j.1600-0706.2011.20301.x; Guillaume JL, 2006, PHYSICA A, V371, P795, DOI 10.1016/j.physa.2006.04.047; Guo JF, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3486250; Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3418294, 10.1145/3447772]; Hastie T., 2009, ELEMENTS STAT LEARNI, V2, DOI [10.1007/978-0-387-84858-7, DOI 10.1007/978-0-387-84858-7]; Hewitt J, 2022, Arxiv, DOI arXiv:2210.15191; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jia Z, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P792, DOI 10.1145/3459637.3482416; Jobbins T, TheBloke/wizardLM-7B-HF Hugging Face; Katiyar A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P917, DOI 10.18653/v1/P17-1085; Khan M, 2016, ACCOUNT REV, V91, P1697, DOI 10.2308/accr-51383; Kim S, 2016, INT J FORECASTING, V32, P669, DOI 10.1016/j.ijforecast.2015.12.003; Kojima T, 2022, ADV NEUR IN; LaBella MJ., 2019, The devil is in the details: the divergence in esg data and implications for responsible investing; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Liu P, 2024, Arxiv, DOI arXiv:2208.08690; Lundberg SM, 2017, ADV NEUR IN, V30; Marodon R, 2022, Working paper 85f81dba-c8-2-4255-878a-0; Meyer LP, 2023, Arxiv, DOI arXiv:2307.06917; Muennighoff N, 2022, Arxiv, DOI arXiv:2202.08904; Nelson LS, 1998, J QUAL TECHNOL, V30, P298; Newman MEJ., 2010, NETWORKS INTRO, DOI DOI 10.1093/ACPROF:OSO/9780199206650.001.0001; Ni J, 2023, arXiv; Niklaus C, 2018, Arxiv, DOI arXiv:1806.05599; NLP Group of The University of Hong Kong, Instructor-xl Hugging Face-huggingface.co; OECD, 2020, OECD business and finance outlook 2020: sustainable and resilient finance. OECD business and finance outlook, DOI [10.1787/eb61fd29-en, DOI 10.1787/EB61FD29-EN]; Ott R.L., 2015, An Introduction to Statistical Methods and Data Analysis; Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Raghupathi V, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12114753; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Reinanda R, 2020, FOUND TRENDS INF RET, V14, P289, DOI 10.1561/1500000063; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Ro Y, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1107; Sadvilkar N., 2020, P 2 WORKSHOP NLP OPE, P110, DOI DOI 10.18653/V1/2020.NLPOSS-1.15; Sadvilkar N, about us; Sahin Ö, 2022, CORP SOC RESP ENV MA, V29, P1782, DOI 10.1002/csr.2326; sasb, Find industry topics; Shao BL, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113764; SSAB, SASB reporters; Su HJ, 2023, Arxiv, DOI arXiv:2212.09741; Sustainalytics, ESG risk ratings-methodology abstract; Taori R., 2023, Stanford alpaca: An instruction-following llama model; TCFD, 2017, Recommendations of the task force on climated-related financial disclosures; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trajanoska M, 2023, Arxiv, DOI arXiv:2305.04676; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Tunstall L., 2022, Natural Language Processing with Transformers; Vaghefi SA, 2023, Chatclimate: grounding conversational ai in climate science; Wang CG, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1225; Wang Y., 2020, arXiv; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Webersinke N, 2021, Arxiv, DOI arXiv:2110.12010; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079; Wong C, 2020, Survey report; Xu C, 2023, Arxiv, DOI arXiv:2304.12244; Yan JH, 2018, FRONT COMPUT SCI-CHI, V12, P55, DOI 10.1007/s11704-016-5228-9; Yang W, 2019, Arxiv, DOI arXiv:1903.10972; Yu EPY, 2021, INT REV FINANC ANAL, V75, DOI 10.1016/j.irfa.2021.101731; Yurtsev E, Kor-pypi.org; Zhang DB, 2017, AM STAT, V71, P310, DOI 10.1080/00031305.2016.1256839; Zhang JL, 2017, ADV INTEL SYS RES, V132, P300; Zhang SY, 2024, Arxiv, DOI [arXiv:2308.10792, 10.48550/ARXIV.2308.10792, 10.48550/arXiv.2308.10792]; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng A., 2018, Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists, DOI DOI 10.13140/RG.2.1.3564.3367; Zhu YQ, 2024, Arxiv, DOI arXiv:2305.13168; Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x; Zou XH, 2020, J PHYS CONF SER, V1487, DOI 10.1088/1742-6596/1487/1/012016; US	122	0	0	3	3	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES		2193-1127		EPJ DATA SCI	EPJ Data Sci.	JUN 7	2024	13	1							41	10.1140/epjds/s13688-024-00481-2	http://dx.doi.org/10.1140/epjds/s13688-024-00481-2			41	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Mathematics; Mathematical Methods In Social Sciences	TT0L4		gold			2024-07-03	WOS:001243391100001
J	Toro, JM				Toro, Juan Manuel			Insights from Animals to Build Better Artificial Language Learners	COMPARATIVE COGNITION & BEHAVIOR REVIEWS			English	Article						language; guided learning; artificial intelligence; LLMs		Recent advances in artificial intelligence have produced large language models that are proficient at processing and generating language. Lessons learned from comparative cognition will be pivotal to understanding the conditions under which different cognitive systems (both natural and artificial) might discover complex linguistic structures. Such lessons will fuel the development of more efficient learning algorithms. More important, they will help to advance a new science of intelligence that takes into account human, animal, and artificial systems.	[Toro, Juan Manuel] Inst Catalana Recerca & Estudis Avancats, Inst Med Genet & Appl Genom, Barcelona, Spain; [Toro, Juan Manuel] Univ Pompeu Fabra, Barcelona, Spain; [Toro, Juan Manuel] Univ Pompeu Fabra, C Ramon Trias Fargas 25-27, Barcelona 08005, Spain	ICREA; Pompeu Fabra University; Pompeu Fabra University	Toro, JM (corresponding author), Univ Pompeu Fabra, C Ramon Trias Fargas 25-27, Barcelona 08005, Spain.	juanmanuel.toro@upf.edu			Spanish Ministerio de Ciencia e Innovacion [PID2021-123973NB-I00]	Spanish Ministerio de Ciencia e Innovacion(Instituto de Salud Carlos IIISpanish Government)	This research was supported by grant PID2021-123973NB-I00 from the Spanish Ministerio de Ciencia e Innovacion.	Abe K, 2011, NAT NEUROSCI, V14, P1067, DOI 10.1038/nn.2869; Bouchon C, 2019, ANIM COGN, V22, P839, DOI 10.1007/s10071-019-01280-3; Chomsky Noah, 2023, NEW YORK TIMES  0308; Ferrigno S, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz1002; Fitch WT, 2018, CURR OPIN BEHAV SCI, V21, P68, DOI 10.1016/j.cobeha.2018.01.014; Fitch WT, 2004, SCIENCE, V303, P377, DOI 10.1126/science.1089401; Gentner TQ, 2006, NATURE, V440, P1204, DOI 10.1038/nature04675; Gervain J, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2430; Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569; Jiang XJ, 2018, CURR BIOL, V28, P1851, DOI 10.1016/j.cub.2018.04.047; Liao DA, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq3356; Mallikarjun A, 2021, ANIM COGN, V24, P419, DOI 10.1007/s10071-020-01436-6; Marcus G., 2018, arXiv; Marcus Gary, 2018, arXiv; Marcus GF, 1999, SCIENCE, V283, P77, DOI 10.1126/science.283.5398.77; Mitchell J., 2020, P 28 INT C COMPUTATI, P5147; Nazzi T, 1998, J EXP PSYCHOL HUMAN, V24, P756, DOI 10.1037/0096-1523.24.3.756; Nespor M., 2003, Lingue E Linguaggio, P203, DOI [DOI 10.1418/10879, 10. 1418/ 10879]; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Stobbe N, 2012, PHILOS T R SOC B, V367, P1995, DOI 10.1098/rstb.2012.0096; Toro JM, 2016, CURR DIR PSYCHOL SCI, V25, P130, DOI 10.1177/0963721416629645; Toro JM, 2016, COGNITION, V146, P1, DOI 10.1016/j.cognition.2015.09.006; Versace E, 2018, TRENDS COGN SCI, V22, P963, DOI 10.1016/j.tics.2018.07.005; WERKER JF, 1984, INFANT BEHAV DEV, V7, P49, DOI 10.1016/S0163-6383(84)80022-3	24	0	0	0	0	COMPARATIVE COGNITION SOC	KINGSTON	COMPARATIVE COGNITION SOC, KINGSTON, ON 00000, CANADA	1911-4745			COMP COGN BEHAV REV	Comp. Cogn. Behav. Rev.		2024	19						91	95		10.3819/CCBR.2024.190008	http://dx.doi.org/10.3819/CCBR.2024.190008			5	Behavioral Sciences	Emerging Sources Citation Index (ESCI)	Behavioral Sciences	NO5C7		gold			2024-07-03	WOS:001201394900011
J	[Anonymous]				[Anonymous]			Writing the rules in AI-assisted writing	NATURE MACHINE INTELLIGENCE			English	Editorial Material								As many authors are experimenting with using large language models in writing articles, some guidelines are becoming clear, but these will need to evolve as the capabilities and integration of such tools develop further.										[Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; Ji Z., 2023, ACM COMPUT SURV, V55, P248, DOI [10.1145/3571730, DOI 10.1145/3571730]; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088	3	4	4	3	14	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	MAY	2023	5	5							469	10.1038/s42256-023-00678-6	http://dx.doi.org/10.1038/s42256-023-00678-6			1	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	H3LQ1		Bronze			2024-07-03	WOS:000995018800001
C	Thakur, S; Ahmad, B; Fan, ZX; Pearce, H; Tan, B; Karri, R; Dolan-Gavitt, B; Garg, S		IEEE		Thakur, Shailja; Ahmad, Baleegh; Fan, Zhenxing; Pearce, Hammond; Tan, Benjamin; Karri, Ramesh; Dolan-Gavitt, Brendan; Garg, Siddharth			Benchmarking Large Language Models for Automated Verilog RTL Code Generation	2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE	Design Automation and Test in Europe Conference and Exhibition		English	Proceedings Paper	Design, Automation and Test in Europe Conference and Exhibition (DATE)	APR 17-19, 2023	Antwerp, BELGIUM	European Design & Automat Assoc, Elect Syst Design Alliance, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, IEEE Comp Soc Test Technol Tech Community, IEEE Solid State Circuits Soc, Cadence Design Syst, Siemens EDA, Synopsys Inc, Robert Bosch GmbH, Res Fdn Flanders, Raycics, Springer Nature, TOOL Corp, X FAB Semicond Foundries		Transformers; Verilog; GPT; LLM		Automating hardware design could obviate a significant amount of human error from the engineering process and lead to fewer errors. Verilog is a popular hardware description language to model and design digital systems, thus generating Verilog code is a critical first step. Emerging large language models (LLMs) are able to write high-quality code in other programming languages. In this paper, we characterize the ability of LLMs to generate useful Verilog. For this, we fine-tune pre-trained LLMs on Verilog datasets collected from GitHub and Verilog textbooks. We construct an evaluation framework comprising test-benches for functional analysis and a flow to test the syntax of Verilog code generated in response to problems of varying difficulty. Our findings show that across our problem scenarios, the fine-tuning results in LLMs more capable of producing syntactically correct code (25.9% overall). Further, when analyzing functional correctness, a fine-tuned open-source CodeGen LLM can outperform the state-of-the-art commercial Codex LLM (6.5% overall). We release our training/evaluation scripts and LLM checkpoints as open source contributions.	[Thakur, Shailja; Ahmad, Baleegh; Fan, Zhenxing; Pearce, Hammond; Karri, Ramesh; Dolan-Gavitt, Brendan; Garg, Siddharth] New York Univ, New York, NY 10012 USA; [Tan, Benjamin] Univ Calgary, Calgary, AB, Canada	New York University; University of Calgary	Thakur, S (corresponding author), New York Univ, New York, NY 10012 USA.		Tan, Benjamin/Q-8521-2019	Tan, Benjamin/0000-0002-7642-3638; Pearce, Hammond/0000-0002-3488-7004	NSF [2039607, 1553419, 1646671]; ARO [77191NC]	NSF(National Science Foundation (NSF)); ARO	This research work was supported in part by NSF Award 1553419, NSF Award 1646671, NSF Award 2039607, and ARO Award 77191NC. The opinions, findings, and conclusions, or recommendations expressed are those of the author(s) and do not necessarily reflect the views of any sponsors.	[Anonymous], 2019, Language Models are Unsupervised Multitask Learners, DOI DOI 10.18653/V1/W18-5019; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Dessouky G, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P213; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gage P., 1994, C Users Journal, V12, P23; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Harris CB, 2016, DES AUT TEST EUROPE, P966; Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pearce H, 2020, PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD '20), P27, DOI 10.1145/3380446.3430634; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Vaswani A, 2017, ADV NEUR IN, V30; Yan ZQ, 2017, Arxiv, DOI [arXiv:1705.07258, 10.48550/arXiv.1705.07258]	15	15	15	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1530-1591		979-8-3503-9624-9	DES AUT TEST EUROPE			2023										10.23919/DATE56975.2023.10137086	http://dx.doi.org/10.23919/DATE56975.2023.10137086			6	Automation & Control Systems; Computer Science, Hardware & Architecture; Engineering, Industrial	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BV4BQ		Green Submitted			2024-07-03	WOS:001027444200143
C	Xu, A; Ren, X; Jia, R		Rogers, A; Boyd-Graber, J; Okazaki, N		Xu, Albert; Ren, Xiang; Jia, Robin			Contrastive Novelty-Augmented Learning: Anticipating Outliers with Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				In many task settings, text classification models are likely to encounter examples from novel classes on which they cannot predict correctly. Selective prediction, in which models abstain on low-confidence examples, provides a possible solution, but existing models are often overly confident on unseen classes. To remedy this overconfidence, we introduce Contrastive Novelty-Augmented Learning (CoNAL), a two-step method that generates OOD examples representative of novel classes, then trains to decrease confidence on them. First, we generate OOD examples by prompting a large language model twice: we prompt it to enumerate relevant novel classes, then generate examples from each novel class matching the task format. Second, we train a classifier with a novel contrastive objective that encourages lower confidence on generated OOD examples than training examples. When trained with CoNAL, classifiers improve in their ability to detect and abstain on novel class examples over prior methods by an average of 2.3% in terms of accuracy under the accuracy-coverage curve (AUAC) and 5.5% AUROC across 4 NLP datasets, with no cost to in-distribution accuracy.(1)	[Xu, Albert; Ren, Xiang; Jia, Robin] Univ Southern Calif, Los Angeles, CA 90007 USA	University of Southern California	Xu, A (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	albertxu@usc.edu; xiangren@usc.edu; robinjia@usc.edu						Anaby-Tavor Ateret, 2020, AAAI C ART INT; [Anonymous], 2022, PR MACH LEARN RES; Arora Udit, 2021, P 2021 C EMP METH NA; Bendale A., 2016, P IEEE C COMP VIS PA; Bergman Liron, 2020, ARXIV200210445; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dhamija AR, 2018, 32 C NEURAL INFORM P; Doan T, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017; Du X., 2022, ARXIV220201197; El-Yaniv Ran, 2010, J MACHINE LEARNING R; Esmaeilpour Sepideh, 2022, P AAAI C ART INT; Fei Geli, 2016, P 2016 C N AM CHAPT; Garg Saurabh, 2022, ICML 2022 WORKSH COR; Ge Z., 2017, BMVC; Geifman Y., 2017, Advances in Neural Information Processing Systems, P4885; Geng C., 2021, IEEE T PATTERN ANAL; He PL, 2020, EMERG MARK FINANC TR, V56, P2198, DOI 10.1080/1540496X.2020.1785865; Hendrycks D., 2019, BENCHMARKING NEURAL; Hendrycks Dan, 2017, ICLR; Kamath Amita, 2020, P 58 ANN M ASS COMP; Komatsuzaki A, 2021, GPT-J-6B: 6B JAX-Based Transformer; Kong LK, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1326; Kumar Varun, 2021, 2 WORKSH LIF LONG LE; Lakshminarayanan B, 2017, ADV NEUR IN, V30; Lee K, 2018, ADV NEUR IN, V31; Li Xiaoya, 2021, P 2021 C EMP METH NA; Li Xin, 2002, COLING 2002; Lin Q, 2019, FRONT CHIN LING, P57, DOI 10.1007/978-981-13-1939-6_4; Liu Y, 2019, ARXIV PREPRINT ARXIV; Moller Felix, 2021, P IEEE CVF C COMP VI; Müller R, 2019, ADV NEUR IN, V32; Narayanan G, 2020, ENG COMPUTATION, V37, P981, DOI 10.1108/EC-05-2019-0244; Oza P, 2019, PROC CVPR IEEE, P2302, DOI 10.1109/CVPR.2019.00241; Perera Pramuditha, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11811, DOI 10.1109/CVPR42600.2020.01183; Podolskiy Alexander, 2021, P AAAI C ART INT; Ren Jie, 2021, ARXIV210609022; Sanh Victor, 2021, 10 INT C LEARN REPR; Saravia Elvis, 2018, P 2018 C EMP METH NA; Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256; Sehwag Vikash, 2021, 9 INT C LEARN REPR; Setlur Amrith, 2022, ARXIV220601367; Shu Lei, 2017, P 2017 C EMP METH NA; Tajwar Fahim, 2021, ICML WORKSH UNC ROB; Tifrea Alexandru, 2021, ARXIV201205825; Varshney Neeraj, 2022, Findings of the Association for Computational Linguistics: ACL 2022; Vernekar Sachin, 2019, NEURIPS 2019 SAF ROB; Winkens Jim, 2020, ARXIV200705566; Ye Xi, 2021, P 60 ANN M ASS COMP; Zeng Zhiyuan, 2021, P 59 ANN M ASS COMP; Zhang FF, 2022, INT J COMPUT ASS RAD, V17, P147, DOI 10.1007/s11548-021-02531-w; Zhang H., 2018, ICLR; Zhang Xiang, 2015, 29 C NEUR INF PROC S; Zhang Y N, 2017, J HEALTHCARE ENG, V2017, P2017, DOI DOI 10.18653/V1/D17-1004; Zheng Yinhe, 2020, IEEE ACM T AUDIO SPE; Zhou W, 2021, P 2021 C EMP METH NA	55	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							11778	11801						24	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962503028
J	Lakhnati, Y; Pascher, M; Gerken, J				Lakhnati, Younes; Pascher, Max; Gerken, Jens			Exploring a GPT-based large language model for variable autonomy in a VR-based human-robot teaming simulation	FRONTIERS IN ROBOTICS AND AI			English	Article						assistive robots; virtual reality; evaluation; shared control; variable autonomy; large language model; GPT	SHARED CONTROL	In a rapidly evolving digital landscape autonomous tools and robots are becoming commonplace. Recognizing the significance of this development, this paper explores the integration of Large Language Models (LLMs) like Generative pre-trained transformer (GPT) into human-robot teaming environments to facilitate variable autonomy through the means of verbal human-robot communication. In this paper, we introduce a novel simulation framework for such a GPT-powered multi-robot testbed environment, based on a Unity Virtual Reality (VR) setting. This system allows users to interact with simulated robot agents through natural language, each powered by individual GPT cores. By means of OpenAI's function calling, we bridge the gap between unstructured natural language input and structured robot actions. A user study with 12 participants explores the effectiveness of GPT-4 and, more importantly, user strategies when being given the opportunity to converse in natural language within a simulated multi-robot environment. Our findings suggest that users may have preconceived expectations on how to converse with robots and seldom try to explore the actual language and cognitive capabilities of their simulated robot collaborators. Still, those users who did explore were able to benefit from a much more natural flow of communication and human-like back-and-forth. We provide a set of lessons learned for future research and technical implementations of similar systems.	[Lakhnati, Younes; Pascher, Max; Gerken, Jens] TU Dortmund Univ, Inclus Human Robot Interact, Dortmund, NW, Germany; [Pascher, Max] Univ Duisburg Essen, Human Comp Interact, Essen, NW, Germany	Dortmund University of Technology; University of Duisburg Essen	Lakhnati, Y; Pascher, M; Gerken, J (corresponding author), TU Dortmund Univ, Inclus Human Robot Interact, Dortmund, NW, Germany.; Pascher, M (corresponding author), Univ Duisburg Essen, Human Comp Interact, Essen, NW, Germany.	younes.lakhnati@udo.edu; max.pascher@udo.edu; jens.gerken@udo.edu		Pascher, Max/0000-0002-6847-0696	German Federal Ministry of Education and Research (BMBF) [FKZ: 16SV8565]; TU Dortmund University	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); TU Dortmund University	The author(s) declare that financial support was received for the research, authorship, and/or publication of this article. This research is supported by the German Federal Ministry of Education and Research (BMBF, FKZ: 16SV8565). We would also like to acknowledge the financial support by the TU Dortmund University within the funding programme Open Access Costs.	Abbink DA, 2018, IEEE T HUM-MACH SYST, V48, P509, DOI 10.1109/THMS.2018.2791570; Ahn M., 2022, P 6 C ROB LEARN, P287; Alessa A, 2023, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023, P667, DOI 10.1145/3594806.3596572; Arumugam D, 2019, AUTON ROBOT, V43, P449, DOI 10.1007/s10514-018-9792-8; Ausat A., 2023, Journal on Education, V5, P16100, DOI [10.31004/joe.v5i4.2745, DOI 10.31004/JOE.V5I4.2745]; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Breazeal C, 2003, INT J HUM-COMPUT ST, V59, P119, DOI 10.1016/S1071-5819(03)00018-1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bustamante S, 2021, IEEE ROBOT AUTOM LET, V6, P3833, DOI 10.1109/LRA.2021.3064449; Canal G., 2016, Social robotics, V9979, DOI [10.1007/978-3-319-47437-3, DOI 10.1007/978-3-319-47437-3]; Chen M., 2021, arXiv; Chiou M, 2023, COMPANION OF THE ACM/IEEE INTERNATIONAL CONFERENCE ON HUMAN-ROBOT INTERACTION, HRI 2023, P932, DOI 10.1145/3568294.3579957; Clark H. H., 1996, USING LANGUAGE, DOI DOI 10.1017/CBO9780511620539; Cyphert A. B., 2021, UC Davis L. Rev, V55, P401; Deci E.L., 2012, HDB THEORIES SOCIAL, DOI [DOI 10.4135/9781446249215.N21, 10.4135/9781446201022]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Erdogan A, 2017, ROBOT AUTON SYST, V94, P282, DOI 10.1016/j.robot.2017.04.013; Firat M., 2023, How Chat Gpt Can Transform Autodidactic Experiences and Open Education; Flemisch F, 2019, COGN TECHNOL WORK, V21, P555, DOI 10.1007/s10111-019-00576-1; Fuentes C., 2023, Roboclean: contextual language grounding for human-robot interactions in specialised low-resource environments; Fussell S. R., 2008, 2008 3rd ACM/IEEE International Conference on Human-Robot Interaction (HRI 2008), P145; Gallenberger D, 2019, ACMIEEE INT CONF HUM, P267, DOI [10.1109/HRI.2019.8673309, 10.1109/hri.2019.8673309]; Garrod S, 2004, TRENDS COGN SCI, V8, P8, DOI 10.1016/j.tics.2003.10.016; Grudin J., 2017, From tool to partner: the evolution of human-computer interaction, DOI DOI 10.1007/978-3-031-02218-0; Haendler T, 2023, Arxiv, DOI arXiv:2310.03659; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hone K. S., 2000, Natural Language Engineering, V6, P287, DOI 10.1017/S1351324900002497; Irfan B., 2023, Between reality and delusion: challenges of applying large language models to companion robots for open-domain dialogues with older adults; Kahambing JG, 2023, J PUBLIC HEALTH-UK, DOI 10.1093/pubmed/fdad028; Kelly Dominique, 2023, Proceedings of the Association for Information Science and Technology, P1007, DOI 10.1002/pra2.927; Këpuska V, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P99, DOI 10.1109/CCWC.2018.8301638; Kim DJ, 2012, IEEE T SYST MAN CY A, V42, P2, DOI 10.1109/TSMCA.2011.2159589; Kocabalil A. B., 2018, P 32 INT BCS HUMAN C, P1; Kodur K., 2023, PREPRINT; Koubaa A., 2023, PREPRINT; Koubaa A, 2023, Preprints, DOI [10.20944/preprints202304.0827.v3, 10.20944/preprints202304.0827.v2, DOI 10.20944/PREPRINTS202304.0827.V2]; Latikka R, 2021, INT J SOC ROBOT, V13, P1747, DOI 10.1007/s12369-020-00743-9; Lauretti C, 2017, IEEE ROBOT AUTOM LET, V2, P1375, DOI 10.1109/LRA.2017.2669369; Lee YK, 2023, Arxiv, DOI arXiv:2308.16529; Lekova A., 2023, 2023 INT C INFORM TE; Lin Patrick, 2014, Robot Ethics: The Ethical and Social Implications of Robotics; Liu R, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419851402; Misra DK, 2016, INT J ROBOT RES, V35, P281, DOI 10.1177/0278364915602060; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Nilsson N. J., 1984, SHAKEY ROBOT; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Park D, 2020, ROBOT AUTON SYST, V124, DOI 10.1016/j.robot.2019.103344; Pascher Max, 2023, 2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN), P2300, DOI 10.1109/RO-MAN57019.2023.10309381; Pascher M., 2024, Proc. ACM Hum.-Comput. Interact, V8, DOI [10.48550/arXiv.2310.15887, DOI 10.48550/ARXIV.2310.15887]; Pascher M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580857; Pelikan HRM, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4921, DOI 10.1145/2858036.2858478; Perlman A., 2022, IMPLICATIONS CHATGPT; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Pollak A, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106469; Porcheron M, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P207, DOI 10.1145/2998181.2998298; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Rakhimkul S, 2019, IEEE SYS MAN CYBERN, P3962, DOI 10.1109/SMC.2019.8914465; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.02.23285399; Scassellati B, 2002, AUTON ROBOT, V12, P13, DOI 10.1023/A:1013298507114; Sebanz N, 2006, TRENDS COGN SCI, V10, P70, DOI 10.1016/j.tics.2005.12.009; Shea YF, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.25000; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Swanson B, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P244; Tack A, 2022, Arxiv, DOI arXiv:2205.07540; Trott S., 2015, AAAI Fall Symp. Ser, V2015, DOI [10.48550/arXiv.1706.03762, DOI 10.48550/ARXIV.1706.03762]; Trozze A, 2023, Arxiv, DOI arXiv:2308.06032; Vaswani A, 2017, ADV NEUR IN, V30; Veling L, 2021, INT J SOC ROBOT, V13, P1689, DOI 10.1007/s12369-020-00723-z; Vesper C, 2010, NEURAL NETWORKS, V23, P998, DOI 10.1016/j.neunet.2010.06.002; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3; Woods W. A., 1973, Proceedings of the June 4-8, 1973, national computer conference and exposition on-afips '73, DOI DOI 10.1145/1499586.1499695; Yang Z., 2019, ADV NEURAL INFORM PR, P5754, DOI DOI 10.5555/3454287.3454804; Zlotowski J, 2017, INT J HUM-COMPUT ST, V100, P48, DOI 10.1016/j.ijhcs.2016.12.008	76	0	0	10	10	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2296-9144			FRONT ROBOT AI	Front. Robot. AI	APR 3	2024	11								1347538	10.3389/frobt.2024.1347538	http://dx.doi.org/10.3389/frobt.2024.1347538			18	Robotics	Emerging Sources Citation Index (ESCI)	Robotics	NW2E2	38633059	gold, Green Published, Green Submitted			2024-07-03	WOS:001203418700001
J	Wang, XQ; Xu, XW; Liu, ZC; Tong, WD				Wang, Xingqiao; Xu, Xiaowei; Liu, Zhichao; Tong, Weida			Bidirectional Encoder Representations from Transformers-like large language models in patient safety and pharmacovigilance: A comprehensive assessment of causal inference implications	EXPERIMENTAL BIOLOGY AND MEDICINE			English	Article						Pharmacovigilance; patient safety; large language models; transformers; BERT		Causality assessment is vital in patient safety and pharmacovigilance (PSPV) for safety signal detection, adverse reaction management, and regulatory submission. Large language models (LLMs), especially those designed with transformer architecture, are revolutionizing various fields, including PSPV. While attempts to utilize Bidirectional Encoder Representations from Transformers (BERT)-like LLMs for causal inference in PSPV are underway, a detailed evaluation of "fit-for-purpose" BERT-like model selection to enhance causal inference performance within PSPV applications remains absent. This study conducts an in-depth exploration of BERT-like LLMs, including generic pre-trained BERT LLMs, domain-specific pre-trained LLMs, and domain-specific pre-trained LLMs with safety knowledge-specific fine-tuning, for causal inference in PSPV. Our investigation centers around (1) the influence of data complexity and model architecture, (2) the correlation between the BERT size and its impact, and (3) the role of domain-specific training and fine-tuning on three publicly accessible PSPV data sets. The findings suggest that (1) BERT-like LLMs deliver consistent predictive power across varied data complexity levels, (2) the predictive performance and causal inference results do not directly correspond to the BERT-like model size, and (3) domain-specific pre-trained LLMs, with or without safety knowledge-specific fine-tuning, surpass generic pre-trained BERT models in causal inference. The findings are valuable to guide the future application of LLMs in a broad range of application.	[Wang, Xingqiao; Xu, Xiaowei] Univ Arkansas, Dept Informat Sci, Little Rock, AR 72204 USA; [Tong, Weida] US FDA, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA; [Liu, Zhichao] Boehringer Ingelheim Pharmaceut Inc, Nonclin Drug Safety, Ridgefield, CT 06877 USA	University of Arkansas System; University of Arkansas Fayetteville; University of Arkansas Little Rock; US Food & Drug Administration (FDA); Boehringer Ingelheim	Tong, WD (corresponding author), US FDA, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA.; Liu, ZC (corresponding author), Boehringer Ingelheim Pharmaceut Inc, Nonclin Drug Safety, Ridgefield, CT 06877 USA.	zhichao.liu@boehringer-ingelheim.com; weida.tong@fda.hhs.gov						Agbabiaka TB, 2008, DRUG SAFETY, V31, P21, DOI 10.2165/00002018-200831010-00003; Ball R, 2022, DRUG SAFETY, V45, P429, DOI 10.1007/s40264-022-01157-4; Bates DW, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00423-6; Beltagy Iz, arXiv; Cherkas Y, 2022, DRUG SAFETY, V45, P571, DOI 10.1007/s40264-022-01163-6; Devlin J., ARXIV; Downing NS, 2017, JAMA-J AM MED ASSOC, V317, P1854, DOI 10.1001/jama.2017.5150; Hoofnagle JH, 2013, HEPATOLOGY, V57, P873, DOI 10.1002/hep.26175; Huang K, ARXIV; Kiciman E., ARXIV; Kompa B, 2022, DRUG SAFETY, V45, P477, DOI 10.1007/s40264-022-01176-1; Lan Zhenzhong, arXiv; Lavertu A, 2021, CLIN PHARMACOL THER, V109, P1197, DOI 10.1002/cpt.2172; Lee J., 2020, BIOINFORMATICS, V36, p1234; Liu Y, arXiv; Liu ZC, 2021, DRUG DISCOV TODAY, V26, P2593, DOI 10.1016/j.drudis.2021.06.009; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Rockey DC., 2010, HEPATOLOGY, V51; Singh S, 2012, TRIALS, V13, DOI 10.1186/1745-6215-13-138; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang XQ, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.999289; Wang XQ, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.659622; Wu JQ, 2022, NAT MACH INTELL, V4, P436, DOI 10.1038/s42256-022-00470-y; Wysowski DK, 2005, ARCH INTERN MED, V165, P1363, DOI 10.1001/archinte.165.12.1363; Xie JQ, 2021, JAMA-J AM MED ASSOC, V326, P1504, DOI 10.1001/jama.2021.15255; Zheng C, 2020, BONE MARROW TRANSPL, V55, DOI 10.1038/s41409-018-0424-x	28	0	0	2	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1535-3702	1535-3699		EXP BIOL MED	Exp. Biol. Med.	NOV	2023	248	21					1908	1917		10.1177/15353702231215895	http://dx.doi.org/10.1177/15353702231215895		DEC 2023	10	Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Research & Experimental Medicine	FJ4D8	38084745	Bronze			2024-07-03	WOS:001125818700001
C	Teixeira, AC; Marar, V; Yazdanpanah, H; Oliveira, A; Ghassemi, M			ACM	Teixeira, Ana Clara; Marar, Vaishali; Yazdanpanah, Hamed; Oliveira, Aline; Ghassemi, Mohammad			Enhancing Credit Risk Reports Generation using LLMs: An Integration of Bayesian Networks and Labeled Guide Prompting	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		GPT-4; prompt engineering; credit risk report; Bayesian network; labeled guide prompting		Credit risk analysis is a process that involves a wide range of complex cognitive abilities. Automating the credit risk analysis process using Large Language Models can bring transformative changes to the finance industry, but not without appropriate measures to ensure trustworthy responses. In this work, we propose a novel prompt-engineering method that enhances the ability of Large Language Models to generate reliable credit risk reports - Labeled Guide Prompting (LGP). LGP consists of: (1) providing annotated few-shot examples to the LLM that denote sets of tokens in an exemplary prompt that are of greater importance when generating sets of tokens in the exemplary response and (2) providing text in the prompt that describes the direction, pathways and interactions between variables from a Bayesian network used for credit risk assessment, thus promoting abductive reasoning. Using data from 100 credit applications, we demonstrate that LGP enables LLMs to generate credit risk reports that are preferred by human credit analysts (in 60-90% of cases) over alternative credit risk reports created by their peers in a blind review. Additionally, we found a statistically significant improvement (p-value < 10(-10)) in the insightfulness of the responses generated using LGP when compared to identical prompts without LGP components. We conclude that Labeled Guide Prompting can enhance LLM performance in complex problem-solving tasks, achieving a level of competency comparable to or exceeding human experts.	[Teixeira, Ana Clara; Marar, Vaishali; Yazdanpanah, Hamed; Oliveira, Aline; Ghassemi, Mohammad] Traive Inc, Brookline, MA 02446 USA		Teixeira, AC (corresponding author), Traive Inc, Brookline, MA 02446 USA.	ana.teixeira@traivefinance.com; vaishali.marar@traivefinance.com; hamed.yazdanpanah@traivefinance.com; aline.oliveira@traivefinance.com; mohammad.ghassemi@traivefinance.com		Marar, Vaishali/0009-0008-9389-140X; Teixeira Noronha, Ana Clara/0009-0009-2930-6955; /0000-0001-5135-8588	Traive Inc.	Traive Inc.	This research was supported by Traive Inc. We thank Traive's Risk Team, Luis Lapo, Antonio Hildenberg, Rafael Arruda, and the Customer Success Team, Danilo Carnevalli, Leandro Marques, Marinna Reis, and Anderson Viana, for their collaboration and insights.	Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Sai AB, 2020, Arxiv, DOI [arXiv:2008.12009, DOI 10.48550/ARXIV.2008.12009, 10.48550/arXiv.2008.12009]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chen ZY, 2020, Arxiv, DOI [arXiv:1904.09521, DOI 10.48550/ARXIV.1904.09521, 10.48550/arXiv.1904.09521]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Kim S, 2022, Arxiv, DOI arXiv:2207.05155; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liu ZY, 2024, Arxiv, DOI arXiv:2306.05524; Pareschi R, 2023, Arxiv, DOI arXiv:2307.10250; Srivastava Aarohi, 2022, arXiv; Suzgun Mirac, 2022, arXiv; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang AL, 2020, Arxiv, DOI arXiv:1905.00537; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Zeng YK, 2023, Arxiv, DOI arXiv:2303.08941; Zhang T., 2023, arXiv	21	0	0	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							340	348		10.1145/3604237.3626902	http://dx.doi.org/10.1145/3604237.3626902			9	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		hybrid			2024-07-03	WOS:001124982700040
J	Liu, XC; Wu, JG; Shao, A; Shen, WY; Ye, PP; Wang, Y; Ye, J; Jin, K; Yang, J				Liu, Xiaocong; Wu, Jiageng; Shao, An; Shen, Wenyue; Ye, Panpan; Wang, Yao; Ye, Juan; Jin, Kai; Yang, Jie			Uncovering Language Disparity of ChatGPT on Retinal Vascular Disease Classification: Cross-Sectional Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						large language models; ChatGPT; clinical decision support; retinal vascular disease; artificial intelligence		Background: Benefiting from rich knowledge and the exceptional ability to understand text, large language models like ChatGPT have shown great potential in English clinical environments. However, the performance of ChatGPT in non-English clinical settings, as well as its reasoning, have not been explored in depth. Objective: This study aimed to evaluate ChatGPT's diagnostic performance and inference abilities for retinal vascular diseases in a non-English clinical environment. Methods: In this cross-sectional study, we collected 1226 fundus fluorescein angiography reports and corresponding diagnoses written in Chinese and tested ChatGPT with 4 prompting strategies (direct diagnosis or diagnosis with a step-by-step reasoning process and in Chinese or English). Results: Compared with ChatGPT using Chinese prompts for direct diagnosis that achieved an F1-score of 70.47%, ChatGPT using English prompts for direct diagnosis achieved the best diagnostic performance (80.05%), which was inferior to ophthalmologists (89.35%) but close to ophthalmologist interns (82.69%). As for its inference abilities, although ChatGPT can derive a reasoning process with a low error rate (0.4 per report) for both Chinese and English prompts, ophthalmologists identified that the latter brought more reasoning steps with less incompleteness (44.31%), misinformation (1.96%), and hallucinations (0.59%) (all P<.001). Also, analysis of the robustness of ChatGPT with different language prompts indicated significant differences in the recall (P=.03) and F1-score (P=.04) between Chinese and English prompts. In short, when prompted in English, ChatGPT exhibited enhanced diagnostic and inference capabilities for retinal vascular disease classification based on Chinese fundus fluorescein angiography reports. Conclusions: ChatGPT can serve as a helpful medical assistant to provide diagnosis in non-English clinical environments, but there are still performance gaps, language disparities, and errors compared to professionals, which demonstrate the potential limitations and the need to continually explore more robust large language models in ophthalmology practice.	[Liu, Xiaocong; Shao, An; Shen, Wenyue; Ye, Panpan; Wang, Yao; Ye, Juan; Jin, Kai] Zhejiang Univ, Affiliated Hosp 2, Eye Ctr, 88 Jiefang Rd, Hangzhou 310009, Zhejiang, Peoples R China; [Liu, Xiaocong; Wu, Jiageng; Yang, Jie] Zhejiang Univ, Sch Med, Sch Publ Hlth, Hangzhou, Zhejiang, Peoples R China	Zhejiang University; Zhejiang University	Jin, K (corresponding author), Zhejiang Univ, Affiliated Hosp 2, Eye Ctr, 88 Jiefang Rd, Hangzhou 310009, Zhejiang, Peoples R China.	jinkai@zju.edu.cn	wang, liangyu/KHD-1769-2024; CHEN, BING/KHX-6659-2024; liu, zhao/KGM-5884-2024; zhang, yueqi/JXM-4287-2024	Ye, Juan/0000-0002-1948-2500; Yang, Jie/0000-0001-5696-363X; Wu, Jiageng/0000-0003-0984-0818; Liu, Xiaocong/0000-0001-5323-2954; Jin, Kai/0000-0003-4369-2417	Natural Science Foundation of China [82201195]; Medical Scientific Research Foundation of Zhejiang Province, China [2022502730]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Medical Scientific Research Foundation of Zhejiang Province, China	Acknowledgments KJ was supported by Natural Science Foundation of China (grant 82201195) . YW was supported by Medical Scientific Research Foundation of Zhejiang Province, China (grant 2022502730) .	Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Blevins T, 2022, P 2022 C EMPIRICAL M, DOI 10.18653/v1/2022.emnlp-main.233; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Bourne RRA, 2021, LANCET GLOB HEALTH, V9, pE130, DOI 10.1016/S2214-109X(20)30425-3; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Chen ML, 2021, GRAEF ARCH CLIN EXP, V259, P2401, DOI 10.1007/s00417-021-05151-x; Chetoui M, 2020, J MED IMAGING, V7, DOI 10.1117/1.JMI.7.4.044503; Dai L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23458-5; Ding L, 2020, IEEE T IMAGE PROCESS, V29, P6561, DOI 10.1109/TIP.2020.2991530; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Gahlaut N, 2015, EUR J PHARM BIOPHARM, V95, P323, DOI 10.1016/j.ejpb.2015.05.001; Gao ZY, 2023, BRIT J OPHTHALMOL, V107, P1852, DOI 10.1136/bjo-2022-321472; Holomcik D, 2023, EYE, V37, P1439, DOI 10.1038/s41433-022-02156-6; Huang JH, 2021, IEEE WINT CONF APPL, P2441, DOI 10.1109/WACV48630.2021.00249; Introducing ChatGPT, OpenAI; Janssen BV, 2023, BJS OPEN, V7, DOI 10.1093/bjsopen/zrad032; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Jin Kai, 2022, Adv Ophthalmol Pract Res, V2, P100078, DOI 10.1016/j.aopr.2022.100078; Jin K, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71622-6; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Li MJ, 2022, PROC CVPR IEEE, P20624, DOI 10.1109/CVPR52688.2022.02000; Li WY, 2022, TRANSL VIS SCI TECHN, V11, DOI 10.1167/tvst.11.3.9; Li ZW, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24116-6; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Marmoy OR, 2022, EYE, V36, P234, DOI 10.1038/s41433-020-01328-6; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Pan XJ, 2020, GRAEF ARCH CLIN EXP, V258, P779, DOI 10.1007/s00417-019-04575-w; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Ryu G, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02479-6; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Truhn D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-47500-2; Wei Jason, 2022, 36 C NEUR INF PROC S; Wu JG, 2024, Arxiv, DOI arXiv:2305.10163; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhao XY, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.101197; Zuccon G, 2023, Arxiv, DOI [arXiv:2302.13793, DOI 10.48550/ARXIV.2302.13793]	46	3	3	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JAN 22	2024	26								e51926	10.2196/51926	http://dx.doi.org/10.2196/51926			11	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	IE8U6	38252483	gold, Green Published			2024-07-03	WOS:001164750700003
J	Tang, C; Huang, DH; Ge, WQ; Liu, WY; Zhang, H				Tang, Chao; Huang, Dehao; Ge, Wenqi; Liu, Weiyu; Zhang, Hong			GraspGPT: Leveraging Semantic Knowledge From a Large Language Model for Task-Oriented Grasping	IEEE ROBOTICS AND AUTOMATION LETTERS			English	Article						Task analysis; Semantics; Robots; Training; Grasping; Pipelines; Natural languages; perception for grasping and manipulation; deep learning in grasping and manipulation		Task-oriented grasping (TOG) refers to the problem of predicting grasps on an object that enable subsequent manipulation tasks. To model the complex relationships between objects, tasks, and grasps, existing methods incorporate semantic knowledge as priors into TOG pipelines. However, the existing semantic knowledge is typically constructed based on closed-world concept sets, restraining the generalization to novel concepts out of the pre-defined sets. To address this issue, we propose GraspGPT, a large language model (LLM) based TOG framework that leverages the open-end semantic knowledge from an LLM to achieve zero-shot generalization to novel concepts. We conduct experiments on Language Augmented TaskGrasp (LA-TaskGrasp) dataset and demonstrate that GraspGPT outperforms existing TOG methods on different held-out settings when generalizing to novel concepts out of the training set. The effectiveness of GraspGPT is further validated in real-robot experiments.	[Tang, Chao; Huang, Dehao; Ge, Wenqi; Zhang, Hong] Southern Univ Sci & Technol, Shenzhen Key Lab Robot & Comp Vis, Shenzhen 518055, Peoples R China; [Tang, Chao; Huang, Dehao; Ge, Wenqi; Zhang, Hong] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China; [Liu, Weiyu] Georgia Inst Technol, Inst Robot & Intelligent Machines, Atlanta, GA 30332 USA	Southern University of Science & Technology; Southern University of Science & Technology; University System of Georgia; Georgia Institute of Technology	Tang, C (corresponding author), Southern Univ Sci & Technol, Shenzhen Key Lab Robot & Comp Vis, Shenzhen 518055, Peoples R China.; Tang, C (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China.	12131042@mail.sustech.edu.cn; huangdehao919@gmail.com; 12232112@mail.sustech.edu.cn; loftusoklamtin69@gmail.com; hzhang@sustech.edu.cn		Huang, Dehao/0009-0006-2693-9309; Tang, Chao/0000-0001-8287-7188	Shenzhen Key Laboratory of Robotics and Computer Vision [ZDSYS20220330160557001]	Shenzhen Key Laboratory of Robotics and Computer Vision	This work was supported by the Shenzhen Key Laboratory of Robotics and Computer Vision under Grant ZDSYS20220330160557001.	Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Antanas L, 2019, AUTON ROBOT, V43, P1393, DOI 10.1007/s10514-018-9784-8; Ardón P, 2019, IEEE ROBOT AUTOM LET, V4, P4571, DOI 10.1109/LRA.2019.2933815; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dang H, 2012, IEEE INT C INT ROBOT, P1311, DOI 10.1109/IROS.2012.6385563; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Huang C., 2022, P IEEE INT C ROB AUT, P10608; Huang W, 2023, P 6 C ROBOT LEARNING, P1769; Huang WL, 2022, PR MACH LEARN RES; Jiang YF, 2023, Arxiv, DOI arXiv:2210.03094; Kingma D. P., 2017, ARXIV; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Kokic M, 2020, IEEE ROBOT AUTOM LET, V5, P3352, DOI 10.1109/LRA.2020.2975706; Kuan F, 2020, INT J ROBOT RES, V39, P202, DOI 10.1177/0278364919872545; Liang J., 2022, P IEEE INT C ROB AUT, P9493; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu WY, 2020, IEEE INT CONF ROBOT, P2550, DOI [10.1109/icra40945.2020.9197289, 10.1109/ICRA40945.2020.9197289]; Mousavian A, 2019, IEEE I CONF COMP VIS, P2901, DOI 10.1109/ICCV.2019.00299; Murali W., 2021, P C ROB LEARN, P1540; Pan B., 2023, P C ROB LEARN, P1783; Qi C.R., 2017, PROC INT C NEURAL IN, P5099, DOI DOI 10.1109/CVPR.2017.16; Qin ZY, 2020, IEEE INT CONF ROBOT, P7278, DOI [10.1109/icra40945.2020.9196971, 10.1109/ICRA40945.2020.9196971]; Ren A. Z., 2023, Conference on Robot Learning, P1531; ROSCH E, 1975, J EXP PSYCHOL GEN, V104, P192, DOI 10.1037/0096-3445.104.3.192; Shah D, 2023, C ROBOT LEARNING, P492; Song D., 2010, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2010), P1579, DOI 10.1109/IROS.2010.5649406; Sundermeyer M, 2021, IEEE INT CONF ROBOT, P13438, DOI 10.1109/ICRA48506.2021.9561877; Tang C, 2023, arXiv; Nguyen T, 2022, AUTON ROBOT, V46, P83, DOI 10.1007/s10514-021-10008-7; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Vaswani A., 2017, Adv. Neural Inf. Process. Syst, P6000; Wu JMY, 2023, Arxiv, DOI arXiv:2305.05658; Zeng A., 2022, P 11 INT C LEARN REP	33	1	1	24	42	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2377-3766			IEEE ROBOT AUTOM LET	IEEE Robot. Autom. Lett.	NOV	2023	8	11					7551	7558		10.1109/LRA.2023.3320012	http://dx.doi.org/10.1109/LRA.2023.3320012			8	Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Robotics	W1GF5		Green Submitted			2024-07-03	WOS:001089173600011
C	Wen, YN; Chen, KW		Shane, JS; Madson, KM; Mo, Y; Poleacovschi, C; Sturgill, RE		Wen, Yining; Chen, Kaiwen			Autonomous Detection and Assessment of Indoor Building Defects Using Multimodal Learning and GPT	CONSTRUCTION RESEARCH CONGRESS 2024: ADVANCED TECHNOLOGIES, AUTOMATION, AND COMPUTER APPLICATIONS IN CONSTRUCTION			English	Proceedings Paper	2nd Joint Conference of the Construction Research Congress (CRC) / Construction-Institute (CI) Summit	MAR 20-23, 2024	Iowa State Univ, Des Moines, IA	Amer Soc Civil Engineers, Construct Inst, Construct Res Council	Iowa State Univ			Buildings deteriorate over their service life. The early detection of defects such as cracking, spalling, corrosion, and moisture can benefit the preventative maintenance of building systems. Autonomous robotic systems have enormous potential in automating indoor building defect inspections, along with challenges of inaccurate prediction and unorganized information. With the implementation of state-of-art multimodal learning methods and large language model (LLM) techniques, we present a cutting-edge workflow composed of image captioning, landmark documentation, and real-time on-site human-machine interactive path planning. Compared with previous vision and language navigation (VLN) algorithms, our workflow introduces defect prompts to improve indoor inspection captioning performance. These pivotal defect features are extracted by YOLO (You Only Look Once) v5, a PyTorch-based deep learning model. As the robotic system recognizes the environment clearly, inspectors are capable of providing target-oriented instructions to control the survey path. By implementing the large language model GPT-3, vocal and textual instructions are transferred to the robotic localization system and summarize a brief inspection report. In this way, with the assistance of GPT, numerous inspections that previously demanded substantial effort can be conducted efficiently and expeditiously.	[Wen, Yining; Chen, Kaiwen] Univ Alabama, Dept Civil Construct & Environm Engn, Tuscaloosa, AL 35487 USA	University of Alabama System; University of Alabama Tuscaloosa	Chen, KW (corresponding author), Univ Alabama, Dept Civil Construct & Environm Engn, Tuscaloosa, AL 35487 USA.	ywen11@crimson.ua.edu; kaiwen.chen@ua.edu						Asadi K, 2018, AUTOMAT CONSTR, V96, P470, DOI 10.1016/j.autcon.2018.10.009; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai W., 2023, Autom. Constr., V152; Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644; Cao Y., 2023, ARXIV; Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059; Gul F, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1632046; Huang C., 2023, arXiv; Ilyas M, 2021, IEEE-ASME T MECH, V26, P2845, DOI 10.1109/TMECH.2021.3100306; Jaradat MAK, 2011, ROBOT CIM-INT MANUF, V27, P135, DOI 10.1016/j.rcim.2010.06.019; Kirillov A., 2023, arXiv; Krantz J., 2020, arXiv; Luo Z., 2022, P IEEE CVF C COMP VI; Ma YW, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109420; Barros AM, 2022, ROBOTICS, V11, DOI 10.3390/robotics11010024; Mai G., 2023, ARXIV; McNamara T. P., Subjective Hierarchies in Spatial Memory; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Nguyen V.-Q., 2022, arXiv; Pan CB, 2022, ADV ENG INFORM, V54, DOI 10.1016/j.aei.2022.101767; Ren YP, 2020, CONSTR BUILD MATER, V234, DOI 10.1016/j.conbuildmat.2019.117367; Song K., 2022, IEEEASME Trans. Mechatron.; Wen Y., 2023, 2023 INT C COMPUTING; Yang L, 2023, J FIELD ROBOT, V40, P110, DOI 10.1002/rob.22119; Zhao H., 2023, Image.txt: Transform Image Into Unique Paragraph	25	0	0	1	1	AMER SOC CIVIL ENGINEERS	NEW YORK	UNITED ENGINEERING CENTER, 345 E 47TH ST, NEW YORK, NY 10017-2398 USA			978-0-7844-8526-2				2024							1001	1009						9	Construction & Building Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Construction & Building Technology	BW7UR					2024-07-03	WOS:001196835000102
J	Armitage, R				Armitage, Richard			Performance of GPT-4 in Membership of the Royal College of Paediatrics and Child Health-style examination questions	BMJ PAEDIATRICS OPEN			English	Letter						artificial intelligence; large language models; medical education; clinical medicine; paediatrics	CHATGPT	The large language model (LLM) ChatGPT has been shown to have considerable utility across medicine and healthcare. This paper aims to explore the capabilities of GPT-4 (Generative Pre-trained Transformer 4) in answering Membership of the Royal College of Paediatrics and Child Health (MRCPCH) written paper-style questions. GPT-4 was subjected to four publicly available sample papers designed for those preparing to sit MRCPCH theory components. The model received no specialised training or reinforcement. The average score across all four papers was 78.1%. The model provided reasoning for its answers despite this not being required by the questions. This performance strengthens the case for incorporating LLMs into supporting roles for practising clinicians and medical education in paediatrics.	[Armitage, Richard] Univ Nottingham, Sch Med, Nottingham, England	University of Nottingham	Armitage, R (corresponding author), Univ Nottingham, Sch Med, Nottingham, England.	richard.armitage@nhs.net		Armitage, Richard/0000-0003-1165-6753				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Armitage RC, 2023, POSTGRAD MED J, V99, P1130, DOI 10.1093/postmj/qgad046; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3	6	0	0	2	2	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND		2399-9772		BMJ PAEDIATR OPEN	BMJ Paediatr. Open	MAR	2024	8	1							e002575	10.1136/bmjpo-2024-002575	http://dx.doi.org/10.1136/bmjpo-2024-002575			2	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	UT5V5	38508662	Green Published, gold			2024-07-03	WOS:001250331500007
J	Apaza, G; Selva, D				Apaza, Gabriel; Selva, Daniel			Leveraging Large Language Models for Tradespace Exploration	JOURNAL OF SPACECRAFT AND ROCKETS			English	Article; Early Access						Natural Language Processing; Attitude Determination and Control System; Satellite Bus; Tropical Rainfall Measuring Mission; Renewable Energy; Model Based System Engineering; Synthetic Aperture Radar; Sun Synchronous Orbit; Data Products; Computing and Informatics	DESIGN; SYSTEM; FRONT	This paper proposes a method for leveraging large language models (LLMs) to improve the question-answering capabilities of artificial intelligence (AI) assistants for tradespace exploration. The method operates by querying an information space composed of fused data sources encompassing the tradespace exploration process and responding based on the gathered information. The information retrieval process is modeled as an internal dialog where an LLM-based dialog agent converses with a subquery answering agent. A case study is conducted on a next-generation soil moisture mission (SM-NG), and a generative AI assistant (named Daphne-G) is configured on it. The effect of the dialog agent and the choice of LLM are assessed by comparing the performance of three different system configurations on a validation question set. A second validation effort is conducted, comparing Daphne-G's responses to those of a baseline template-based AI assistant, Daphne-VA. Results show that the dialog-based system is necessary for answering complex questions requiring multiple documents. Furthermore, results show that Daphne-G can correctly answer all the questions Daphne-VA can answer, while simultaneously being able to answer a greater number of questions than Daphne-VA. The results suggest that LLMs could significantly improve the outcomes of the tradespace exploration process, which may result in better and more cost-effective mission concepts being implemented.	[Apaza, Gabriel; Selva, Daniel] Texas A&M Univ, College Stn, TX 77843 USA; [Apaza, Gabriel; Selva, Daniel] Aerosp Engn Dept, 710 Ross St, College Stn, TX USA	Texas A&M University System; Texas A&M University College Station	Apaza, G (corresponding author), Texas A&M Univ, College Stn, TX 77843 USA.	gapaza@tamu.edu; dselva@tamu.edu						[Anonymous], 2023, Oscar; [Anonymous], 2015, 2015 19 INT STUD C E; [Anonymous], 2022, The CEOS Database: Missions, Instruments, Measurements and Datasets; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Balling R., 1999, P 3 WORLD C STRUCTUR, P295; Bang H, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 7; Basha NS, 2023, SYSTEMS ENG, V26, P291, DOI 10.1002/sys.21656; Bast H., 2015, P 24 ACM INT C INFOR, P1431, DOI [10.1145/2806416.2806472, DOI 10.1145/2806416.2806472]; Battat JA, 2014, J SPACECRAFT ROCKETS, V51, P523, DOI 10.2514/1.A32562; Berquand A., 2019, AEROSP CONF PROC, P1, DOI [10.1109/AERO.2019.8742082, DOI 10.1109/aero.2019.8742082]; Blasco X, 2008, INFORM SCIENCES, V178, P3908, DOI 10.1016/j.ins.2008.06.010; Cohn, 2008, AAAI, V3, P1287; Crawley E., 2015, System Architecture: Strategy and Product Development for Complex Systems, V1st; Entekhabi D, 2010, P IEEE, V98, P704, DOI 10.1109/JPROC.2010.2043918; Fillingim KB, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4044160; Fu MC, 1997, J COMPUT CIVIL ENG, V11, P60, DOI 10.1061/(ASCE)0887-3801(1997)11:1(60); Garcia M, 2021, COMPUT LINGUIST, V47, P699, DOI 10.1162/coli_r_00410; Gero JS, 2004, DESIGN STUD, V25, P373, DOI 10.1016/j.destud.2003.10.010; Guerlain SA, 1999, HUM FACTORS, V41, P72, DOI 10.1518/001872099779577363; Haskins C., 2007, INCOSE; Hatchuel A., 2003, Proceedings of the 14th International Conference on Engineering Design ICED03, P109; Hogstrom K, 2019, AEROSP CONF PROC; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Jilla C., 2002, 9 AIAA ISSMO S MULT, DOI [10.2514/6.2002-5491, DOI 10.2514/6.2002-5491]; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Khattab O, 2023, Arxiv, DOI [arXiv:2212.14024, DOI 10.48550/ARXIV.2212.14024]; Ko A., 2017, 58 AIAA ASCE AHS ASC, DOI [10.2514/6.2017-0971, DOI 10.2514/6.2017-0971]; Le Moigne J, 2017, INT GEOSCI REMOTE SE, P1181, DOI 10.1109/IGARSS.2017.8127168; Lin SC, 2023, Arxiv, DOI arXiv:2302.07452; Llis, 2023, NASA; MacCalman AD, 2016, SYSTEMS ENG, V19, P409, DOI 10.1002/sys.21352; Maher ML., 1996, Advances in Formal Design Methods for CAD: Proceedings of the IFIP WG5.2 Workshop on Formal Design Methods for Computer-Aided Design, P3; Maier M. W., 2000, The Art of Systems Architecting, V2nd; Maisonobe L., 2010, 4 INT C ASTR TOOLS T, P3; Martin AVI, 2020, IEEE J-STARS, V13, P30, DOI 10.1109/JSTARS.2019.2948921; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Mosher T, 1999, J AIRCRAFT, V36, P200, DOI 10.2514/2.2426; Myers K, 2007, AI MAG, V28, P47; OpenAI, 2023, PREPRINT; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Raffel C, 2020, J MACH LEARN RES, V21; Ross Adam M., 2005, INCOSE International Symposium, V15, P1706, DOI DOI 10.1002/J.2334-5837.2005.TB00783.X; Ross AM, 2004, J SPACECRAFT ROCKETS, V41, P20, DOI 10.2514/1.9204; Segal R. B., 1999, Proceedings of the Third International Conference on Autonomous Agents, P276, DOI 10.1145/301136.301209; Selva D., 2012, Rule-Based System Architecting of Earth Observation Satellite Systems; Selva D, 2016, SYSTEMS ENG, V19, P477, DOI 10.1002/sys.21370; Shea G., 2017, NASA Systems Engineering Handbook Revision 2, Text; Song B., 2020, PROC SOC C, V1, P1551, DOI 10. 1017/dsd.2020.68; Song WB, 2002, COMPUT STRUCT, V80, P1853, DOI 10.1016/S0045-7949(02)00225-0; Stump G., 2007, INT DES ENG TECHN C, V48078, P1367, DOI [10.1115/DETC2007-34684, DOI 10.1115/DETC2007-34684]; Stump GM, 2004, AEROSP CONF PROC, P3885; Szykman S., 2001, J COMPUT INF SCI ENG, V1, P3, DOI DOI 10.1115/1.1344238; Thompson R. E., 2015, Ph.D. Thesis; Thompson RE, 2015, SYSTEMS ENG, V18, P549, DOI 10.1002/sys.21310; Thompson RE, 2015, J SPACECRAFT ROCKETS, V52, P1021, DOI 10.2514/1.A33135; Unal Mehmet., 2015, 41st Design Automation Conference, V2B, DOI DOI 10.1115/DETC2015-46895; Vaswani A, 2017, ADV NEUR IN, V30; Viros-i Martin A., 2022, International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, V86236, DOI [10.1115/DETC2022-89207, DOI 10.1115/DETC2022-89207]; Viros-i Martin A., 2021, International Design Engineering Technical Conferences and Computers and Information in Engineering Conference, V85420, DOI [10.1115/DETC2021-67619, DOI 10.1115/DETC2021-67619]; Watanabe S, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P880, DOI 10.1109/CEC.2014.6900650; Wertz J., 1999, Space Mission Analysis and Design, V8; Woodruff MJ, 2013, STRUCT MULTIDISCIP O, V48, P201, DOI 10.1007/s00158-013-0891-z; Yan X., 2012, 12th AIAA Aviation Technology, Integration, and Operations (ATIO) Conference and 14th AIAA/ISSMO Multidisciplinary Analysis and Optimization Conference, DOI [10.2514/6.2012-5662, DOI 10.2514/6.2012-5662]; Zhang XL, 2012, J ENG DESIGN, V23, P23, DOI 10.1080/09544828.2010.487260	64	0	0	3	3	AMER INST AERONAUTICS  ASTRONAUTICS	RESTON	1801 ALEXANDER BELL DRIVE, STE 500, RESTON, VA 22091-4344 USA	0022-4650	1533-6794		J SPACECRAFT ROCKETS	J. Spacecr. Rockets	2024 APR 8	2024										10.2514/1.A35834	http://dx.doi.org/10.2514/1.A35834		APR 2024	19	Engineering, Aerospace	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	PQ7I5					2024-07-03	WOS:001215610200001
J	Amin, KS; Mayes, LC; Khosla, P; Doshi, RH				Amin, Kanhai S.; Mayes, Linda C.; Khosla, Pavan; Doshi, Rushabh H.			Assessing the Efficacy of Large Language Models in Health Literacy: A Comprehensive Cross-Sectional Study	YALE JOURNAL OF BIOLOGY AND MEDICINE			English	Article						Large Language Models; ChatGPT; Google Bard; Google Gemini; Microsoft Bing; Health Literacy; Reading Grade Level; Artificial Intelligence; Pediatrics	INFORMATION; ADOLESCENTS; INTERNET	Enhanced health literacy in children has been empirically linked to better health outcomes over the long term; however, few interventions have been shown to improve health literacy. In this context, we investigate whether large language models (LLMs) can serve as a medium to improve health literacy in children. We tested pediatric conditions using 26 different prompts in ChatGPT-3.5, ChatGPT-4, Microsoft Bing, and Google Bard (now known as Google Gemini). The primary outcome measurement was the reading grade level (RGL) of output as assessed by Gunning Fog, Flesch-Kincaid Grade Level, Automated Readability Index, and Coleman-Liau indices. Word counts were also assessed. Across all models, output for basic prompts such as "Explain" and "What is (are)," were at, or exceeded, the tenth-grade RGL. When prompts were specified to explain conditions from the first- to twelfth-grade level, we found that LLMs had varying abilities to tailor responses based on grade level. ChatGPT-3.5 provided responses that ranged from the seventh-grade to college freshmen RGL while ChatGPT-4 outputted responses from the tenth-grade to the college senior RGL. Microsoft Bing provided responses from the ninth- to eleventhgrade RGL while Google Bard provided responses from the seventh- to tenth-grade RGL. LLMs face challenges in crafting outputs below a sixth-grade RGL. However, their capability to modify outputs above this threshold, provides a potential mechanism for adolescents to explore, understand, and engage with information regarding their health conditions, spanning from simple to complex terms. Future studies are needed to verify the accuracy and efficacy of these tools.	[Amin, Kanhai S.] Yale Coll, New Haven, CT 06520 USA; [Mayes, Linda C.] Yale Sch Med, Yale Child Study Ctr, New Haven, CT USA; [Khosla, Pavan; Doshi, Rushabh H.] Yale Sch Med, New Haven, CT USA	Yale University; Yale University; Yale University	Amin, KS (corresponding author), Yale Coll, New Haven, CT 06520 USA.	kanhai.amin@yale.edu						Amin K, 2024, Healthcare; Amin K, 2023, YALE J BIOL MED, V96, P407, DOI 10.59249/NKOY5498; Amin K, 2022, PEDIATR CLIN N AM, V69, P865, DOI 10.1016/j.pcl.2022.05.002; Amin KS, 2024, CLIN IMAG, V109, DOI 10.1016/j.clinimag.2024.110113; Amin Kanhai S, 2023, Radiology, V309, pe232561, DOI 10.1148/radiol.232561; Baker DW, 1998, J GEN INTERN MED, V13, P791, DOI 10.1046/j.1525-1497.1998.00242.x; Baker DW, 1997, AM J PUBLIC HEALTH, V87, P1027, DOI 10.2105/AJPH.87.6.1027; Berkman Nancy D, 2011, Evid Rep Technol Assess (Full Rep), P1; Berland GK, 2001, JAMA-J AM MED ASSOC, V285, P2612, DOI 10.1001/jama.285.20.2612; Bitencourt N, 2022, J RHEUMATOL, V49, P1201, DOI 10.3899/jrheum.220262; Conditions P. The Johns Hopkins University, About us; Doshi R, 2023, medRxiv, V2023, P06, DOI [10.1101/2023.06.04.23290786, DOI 10.1101/2023.06.04.23290786]; Fan LZ, 2023, Arxiv, DOI [arXiv:2304.02020, DOI 10.48550/ARXIV.2304.02020]; Freeman JL, 2018, J PEDIATR-US, V195, P244, DOI 10.1016/j.jpeds.2017.11.031; Hutchinson N, 2016, AM J MED, V129, P637, DOI 10.1016/j.amjmed.2016.01.008; Lam LT, 2014, CHILD ADOL PSYCH MEN, V8, DOI 10.1186/1753-2000-8-26; Lenhart A., 2015, INTERNET SCI TECH; Manganello JA, 2011, J HEALTH COMMUN, V16, P163, DOI 10.1080/10810730.2011.604704; Manyika James, 2023, An Overview of Bard: An Early Experiment with Generative AI; Metz C, The New York Times,3/21; Mörelius E, 2021, J MED INTERNET RES, V23, DOI 10.2196/31665; Morrison AK, 2019, PEDIATR REV, V40, P263, DOI 10.1542/pir.2018-0027; Omachi TA, 2013, J GEN INTERN MED, V28, P74, DOI 10.1007/s11606-012-2177-3; Otth M, 2021, J CANCER SURVIV, V15, P151, DOI 10.1007/s11764-020-00920-9; Pearson K, 2022, J MED INTERNET RES, V24, DOI 10.2196/31284; Perry EL, 2014, J SPEC PEDIATR NURS, V19, P210, DOI 10.1111/jspn.12072; Rague JT, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.27034; Riemann L, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182312464; seattlechildrens, All Conditions Seattle Children's Hospital; Van Cleave J, 2010, JAMA-J AM MED ASSOC, V303, P623, DOI 10.1001/jama.2010.104; Vogels E., 2023, A majority of Americans have heard of ChatGPT, but few have tried it themselves Internet; Vongxay V, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0209675; Williams MV, 1998, ARCH INTERN MED, V158, P166, DOI 10.1001/archinte.158.2.166; Zhong Y, 2020, J CHILD HEALTH CARE, V24, P246, DOI 10.1177/1367493519831493	34	2	2	2	2	YALE J BIOLOGY MEDICINE, INC	NEW HAVEN	333 CEDAR ST, PO BOX 208000, NEW HAVEN, CT 06520-8000 USA	0044-0086	1551-4056		YALE J BIOL MED	Yale J. Biol. Med.	MAR	2024	97	1					17	27		10.59249/ZTOZ1966	http://dx.doi.org/10.59249/ZTOZ1966			11	Biology; Medicine, General & Internal; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; General & Internal Medicine; Research & Experimental Medicine	QL1O4	38559461	gold, Green Accepted			2024-07-03	WOS:001220939600002
J	Sheik, R; Sundara, KPS; Nirmala, SJ				Sheik, Reshma; Sundara, K. P. Siva; Nirmala, S. Jaya			Neural Data Augmentation for Legal Overruling Task: Small Deep Learning Models vs. Large Language Models	NEURAL PROCESSING LETTERS			English	Article						Deep learning; Natural language processing; Data augmentation; Legal overruling task; Transformer; Few-shot; GPT-3; Large language models		Deep learning models produce impressive results in any natural language processing applications when given a better learning strategy and trained with large labeled datasets. However, the annotation of massive training data is far too expensive, especially in the legal domain, due to the need for trained legal professionals. Data augmentation solves the problem of learning without labeled big data. In this paper, we employ pre-trained language models and prompt engineering to generate large-scale pseudo-labeled data for the legal overruling task using 100 data samples. We train small recurrent and convolutional deep-learning models using this data and fine-tune a few other transformer models. We then evaluate the effectiveness of the models, both with and without data augmentation, using the benchmark dataset and analyze the results. We also test the performance of these models with the state-of-the-art GPT-3 model under few-shot setting. Our experimental findings demonstrate that data augmentation results in better model performance in the legal overruling task than models trained without augmentation. Furthermore, our best-performing deep learning model trained on augmented data outperforms the few-shot GPT-3 by 18% in the F1-score. Additionally, our results highlight that the small neural networks trained with augmented data achieve outcomes comparable to those of other large language models.	[Sheik, Reshma; Nirmala, S. Jaya] Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirapalli 620015, India; [Sundara, K. P. Siva] Coimbatore Inst Technol, Dept Elect & Commun Engn, Coimbatore 641013, India	National Institute of Technology (NIT System); National Institute of Technology Tiruchirappalli; Coimbatore Institute of Technology	Sheik, R (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Tiruchirapalli 620015, India.	rezmasheik@gmail.com; sivaparthi1989@gmail.com; sjaya@nitt.edu	SHEIK, RESHMA/HGB-3214-2022					Agarap A.F., 2018, arXiv, DOI DOI 10.48550/ARXIV.1803.08375; Anaby-Tavor A, 2020, AAAI CONF ARTIF INTE, V34, P7383; Bayer M., 2021, ACM Comput Surv; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Bonthu Sridevi, 2022, Proceedings of Third International Conference on Sustainable Computing: SUSCOM 2021. Advances in Intelligent Systems and Computing (1404), P521, DOI 10.1007/978-981-16-4538-9_51; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalkidis I, 2022, Arxiv, DOI arXiv:2110.00976; Chen EH, 2011, INFORM PROCESS MANAG, V47, P202, DOI 10.1016/j.ipm.2010.07.003; Chen Y, 2022, P 29 INT C COMPUTATI, P1157; Chen ZY, 2020, Arxiv, DOI [arXiv:1904.09521, DOI 10.48550/ARXIV.1904.09521, 10.48550/arXiv.1904.09521]; Clark J., 2019, Better language models and their implications; Csanyi G., 2021, Acta Tech. Jaurinensis, V15, P15, DOI [10.14513/actatechjaur.00628, DOI 10.14513/ACTATECHJAUR.00628]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Edwards A, 2021, Arxiv, DOI arXiv:2111.09064; Elsahar H, 2018, Arxiv, DOI arXiv:1802.06842; Fadaee M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P567, DOI 10.18653/v1/P17-2090; Feng SY, 2021, ARXIV; Guo H., 2019, arXiv; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hsu H, 2014, Wiley StatsRef: statistics reference online, DOI [10.1002/9781118445112.stat05929, DOI 10.1002/9781118445112.STAT05929]; Kafle K., 2017, Proceedings of The 10th International Natural Language Generation conference, P198; Kaushik D, 2020, Arxiv, DOI [arXiv:1909.12434, DOI 10.48550/ARXIV.1909.12434]; Kingma D. P., 2015, ICLR 2015, DOI DOI 10.1002/9781118900772.ETRDS0277; Kobayashi S., 2018, NAACL; Kumar Varun, 2020, P 2 WORKSHOP LIFE LO, P18; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Moradi M, 2022, Arxiv, DOI arXiv:2109.02555; Nguyen H, 2021, Arxiv, DOI arXiv:2104.07782; Okimura I, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), P88; Papanikolaou Y, 2020, Arxiv, DOI arXiv:2004.13845; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peric L, 2020, P 4 WORKSHOP AUTOMAT, V2764; Raffel C, 2020, J MACH LEARN RES, V21; Ratner A, 2016, ADV NEUR IN, V29; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P86; Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0; Wang W.Y., 2015, Association for Computational Linguistics, P2557, DOI DOI 10.18653/V1/D15-1306; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wu X, 2019, LECT NOTES COMPUT SC, V11539, P84, DOI 10.1007/978-3-030-22747-0_7; Yan G, 2019, LECT NOTES COMPUT SC, V11936, P232, DOI 10.1007/978-3-030-36204-1_19; Yang YB, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1008; Yoo KM, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2225; Zhang DQ, 2020, Arxiv, DOI arXiv:2009.10778; Zhang X, 2015, ADV NEUR IN, V28; Zheng Lucia, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P159, DOI 10.1145/3462757.3466088; Zichen Guo, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P549, DOI 10.1145/3395363.3404364	51	0	0	5	5	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1370-4621	1573-773X		NEURAL PROCESS LETT	Neural Process. Lett.	MAR 23	2024	56	2							121	10.1007/s11063-024-11574-4	http://dx.doi.org/10.1007/s11063-024-11574-4			21	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LU5W4		hybrid			2024-07-03	WOS:001189337900001
C	Morales, S; Clarisó, R; Cabot, J			IEEE	Morales, Sergio; Clariso, Robert; Cabot, Jordi			Automating Bias Testing of LLMs	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		testing; ethics; bias; fairness; large language models		Large Language Models (LLMs) are being quickly integrated in a myriad of software applications. This may introduce a number of biases, such as gender, age or ethnicity, in the behavior of such applications. To face this challenge, we explore the automatic generation of tests suites to assess the potential biases of an LLM. Each test is defined as a prompt used as input to the LLM and a test oracle that analyses the LLM output to detect the presence of biases.	[Morales, Sergio; Clariso, Robert] Univ Oberta Catalunya, Barcelona, Spain; [Cabot, Jordi] Luxembourg Inst Sci & Technol, Esch Sur Alzette, Luxembourg	UOC Universitat Oberta de Catalunya; Luxembourg Institute of Science & Technology	Morales, S (corresponding author), Univ Oberta Catalunya, Barcelona, Spain.		Clariso, Robert/B-5450-2009; Cabot, Jordi/P-7723-2015	Clariso, Robert/0000-0001-9639-0186; Morales, Sergio/0000-0002-5921-9440; Cabot, Jordi/0000-0003-2418-2489	Spanish government [PID2020-114615RB-I00/AEI/10.13039/501100011033]; Luxembourg National Research Fund (FNR) PEARL program [16544475]; ECSEL Joint Undertaking (JU) [101007350]	Spanish government(Spanish Government); Luxembourg National Research Fund (FNR) PEARL program; ECSEL Joint Undertaking (JU)	This work has been partially funded by the Spanish government (PID2020-114615RB-I00/AEI/10.13039/501100011033, project LOCOSS); the Luxembourg National Research Fund (FNR) PEARL program, grant agreement 16544475; and the AIDOaRt project, which has received funding from the ECSEL Joint Undertaking (JU) under grant agreement No 101007350.	Alnegheimish S., 2022, PROC 2022 C N AM CHA, P2824, DOI DOI 10.18653/V1/2022.NAACL-MAIN.2032; [Anonymous], Racial Bias Found in a Major Health Care Risk Algorithm; [Anonymous], Discriminating algorithms: 5 times AI showed prejudice; [Anonymous], How We Analyzed the COMPAS Recidivism Algorithm; [Anonymous], Hugging Face releases its own version of ChatGPT; [Anonymous], AMAZON SCRAPS SECRET; Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33; Bhardwaj R, 2021, COGN COMPUT, V13, P1008, DOI 10.1007/s12559-021-09881-2; Bolukbasi T, 2016, ADV NEUR IN, V29; Dhamala J, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P862, DOI 10.1145/3442188.3445924; Gehman S, 2020, M ASS FOR COMPUTATIO; Giner-Miguelez J, 2022, ACM/IEEE 25TH INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS, MODELS 2022 COMPANION, P22, DOI 10.1145/3550356.3559087; Hagendorff T, 2020, MIND MACH, V30, P99, DOI 10.1007/s11023-020-09517-8; Harrison A., 2021, Semantic Web Journal; Ibáñez JC, 2022, AI SOC, V37, P1663, DOI 10.1007/s00146-021-01267-0; Lu QH, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2022), P241, DOI [10.1109/ICSE-SEIP55303.2022.9793864, 10.1145/3510457.3513063]; Ma PC, 2023, Arxiv, DOI arXiv:2305.02626; Morley J, 2023, AI SOC, V38, P411, DOI 10.1007/s00146-021-01308-8; Prabhumoye S., 2021, arXiv; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Siddiq M. L., 2023, arXiv; Wan YX, 2023, Arxiv, DOI arXiv:2305.12434; Yohannis A, 2022, PROCEEDINGS OF THE 25TH INTERNATIONAL ACM/IEEE CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS, MODELS 2022, P143, DOI 10.1145/3550355.3552401; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zhao JY, 2018, Arxiv, DOI arXiv:1804.06876	26	0	0	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1705	1707		10.1109/ASE56229.2023.00018	http://dx.doi.org/10.1109/ASE56229.2023.00018			3	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200138
J	Tang, YT; Liu, ZJ; Zhou, ZC; Luo, XP				Tang, Yutian; Liu, Zhijie; Zhou, Zhichao; Luo, Xiapu			ChatGPT vs SBST: A Comparative Assessment of Unit Test Suite Generation	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						ChatGPT; search-based software testing; large language models		Recent advancements in large language models (LLMs) have demonstrated exceptional success in a wide range of general domain tasks, such as question answering and following instructions. Moreover, LLMs have shown potential in various software engineering applications. In this study, we present a systematic comparison of test suites generated by the ChatGPT LLM and the state-of-the-art SBST tool EvoSuite. Our comparison is based on several critical factors, including correctness, readability, code coverage, and bug detection capability. By highlighting the strengths and weaknesses of LLMs (specifically ChatGPT) in generating unit test cases compared to EvoSuite, this work provides valuable insights into the performance of LLMs in solving software engineering problems. Overall, our findings underscore the potential of LLMs in software engineering and pave the way for further research in this area.	[Tang, Yutian] Univ Glasgow, Glasgow City Q12 8QQ, Scotland; [Liu, Zhijie] ShanghaiTech Univ, Shanghai 201210, Peoples R China; [Zhou, Zhichao; Luo, Xiapu] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China	University of Glasgow; ShanghaiTech University; Hong Kong Polytechnic University	Tang, YT (corresponding author), Univ Glasgow, Glasgow City Q12 8QQ, Scotland.	yutian.tang@glasgow.ac.uk			Hong Kong RGC Project	Hong Kong RGC Project	No Statement Available	Alon U., 2019, Structural language models for any-code generation, P1; Arcuri A, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3477271; Artetxe M, 2022, Arxiv, DOI arXiv:2205.11726; Ayewah N, 2008, IEEE SOFTWARE, V25, P22, DOI 10.1109/MS.2008.130; bignerdranch, Replacing myself: Writing unit tests with ChatGPT; Braione P, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P90, DOI 10.1145/3092703.3092715; Brants T., 2007, P 2007 JOINT C EMP M, P858; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bui NDQ, 2021, PROC INT CONF SOFTW, P1186, DOI 10.1109/ICSE43902.2021.00109; Cai XY, 2023, IEEE T MULTIMEDIA, V25, P845, DOI 10.1109/TMM.2021.3132724; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; checkstyle, CheckStyle; Chen M., 2021, arXiv; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Copilot G., Your AI pair programmer; Daka E, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P57, DOI 10.1145/3092703.3092727; Dantas C. E. C., 2021, arXiv; Defects4J, Defects4J: A database of real faults and an experimental infrastructure to enable controlled experiments in software engineering research; Deng YL, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P423, DOI 10.1145/3597926.3598067; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong Z, 2020, PROC INT CONF SOFTW, P481, DOI 10.1145/3377811.3380402; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; evosuite, EvoSuite: Automatic test suite generation for Java; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2013, IEEE T SOFTWARE ENG, V39, P276, DOI 10.1109/TSE.2012.14; Gay G, 2017, LECT NOTES COMPUT SC, V10452, P65, DOI 10.1007/978-3-319-66299-2_5; github, Google Java style guide; github, Spotbugs; github, Writing unit test cases with ChatGPT; Grano G, 2021, IEEE T SOFTWARE ENG, V47, P2332, DOI 10.1109/TSE.2019.2946773; Haiduc S., 2010, 2010 32nd International Conference on Software Engineering (ICSE), P223, DOI 10.1145/1810295.1810335; Harman M, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379787; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; jacoco, 2023, JaCoCo Java code coverage library; Jahangirova G, 2021, IEEE T SOFTWARE ENG, V47, P1708, DOI 10.1109/TSE.2019.2934409; jetbrains, Intellij idea-the leading java and kotlin ide; Khashabi D, 2020, Arxiv, DOI arXiv:2005.00700; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Li Z, 2007, IEEE T SOFTWARE ENG, V33, P225, DOI 10.1109/TSE.2007.38; Lin Y, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1068, DOI 10.1145/3468264.3468619; Martin-Lopez A, 2021, ISSTA '21: PROCEEDINGS OF THE 30TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P682, DOI 10.1145/3460319.3469082; McBurney P. W., 2014, P 22 INT C PROGR COM, P279; McBurney PW, 2016, IEEE T SOFTWARE ENG, V42, P103, DOI 10.1109/TSE.2015.2465386; Miller W., 1976, IEEE Transactions on Software Engineering, VSE-2, P223, DOI 10.1109/TSE.1976.233818; Nie PY, 2023, Arxiv, DOI arXiv:2302.10166; openai, ChatGPT-Release Notes; openai, ChatGPT: Optimizing language models for dialogue; oracle, Code conventions for the Java programming language; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; P. S. C. Analyzer, Pmd; Panichella A., 2015, P IEEE 8 INT C SOFTW, P1; Panichella A, 2018, IEEE T SOFTWARE ENG, V44, P122, DOI 10.1109/TSE.2017.2663435; Pilault J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9308; Poesia G., 2022, P INT C LEARN REPR I, P1; Pugh B., Findbugs; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C., 2022, J. Mach. Learn. Res., V21, P1; Raffel C, 2020, J MACH LEARN RES, V21; Rojas Jose Miguel, 2015, Search-Based Software Engineering. 7th International Symposium, SSBSE 2015. Proceedings: LNCS 9275, P93, DOI 10.1007/978-3-319-22183-0_7; Roy D, 2020, IEEE INT CONF AUTOM, P287, DOI 10.1145/3324884.3416622; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Shrestha Kavir, 2011, Proceedings 2011 IEEE Fourth International Conference on Software Testing, Verification and Validation (ICST 2011), P110, DOI 10.1109/ICST.2011.50; Silva RA, 2017, INFORM SOFTWARE TECH, V81, P19, DOI 10.1016/j.infsof.2016.01.017; sonarsource, Cognitive computing: A new way of measuring understandability; spotbugs, Spotbug bug descriptions; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Terragni V, 2021, PROC IEEE ACM INT C, P85, DOI 10.1109/ICSE-Companion52605.2021.00042; the-decoder, ChatGPT guide: Use these prompt strategies to maximize your results; Tonella P., 2004, Software Engineering Notes, V29, P119, DOI 10.1145/1013886.1007528; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Ul Haq F, 2021, ISSTA '21: PROCEEDINGS OF THE 30TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P91, DOI 10.1145/3460319.3464802; Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101; Vaswani A, 2017, ADV NEUR IN, V30; Walcott K. R., 2006, P INT S SOFTW TEST A, P1, DOI DOI 10.1145/1146238.1146240; Wang S, 2021, PROC INT CONF SOFTW, P1548, DOI 10.1109/ICSE43902.2021.00138; Watson C, 2020, PROC INT CONF SOFTW, P1398, DOI 10.1145/3377811.3380429; Xu X, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P1335, DOI 10.1145/3071178.3071184; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Yun Lin, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P440, DOI 10.1145/3395363.3397358; Zhang J, 2020, PROC INT CONF SOFTW, P1385, DOI 10.1145/3377811.3380383; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhou ZC, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556902; Zhu H, 1997, ACM COMPUT SURV, V29, P366, DOI 10.1145/267580.267590	85	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	JUN	2024	50	6					1340	1359		10.1109/TSE.2024.3382365	http://dx.doi.org/10.1109/TSE.2024.3382365			20	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UL2G2		Green Submitted			2024-07-03	WOS:001248142900017
J	Patil, R; Gudivada, V				Patil, Rajvardhan; Gudivada, Venkat			A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs)	APPLIED SCIENCES-BASEL			English	Review						language models; PLMs; large language model; LLMs; natural language processing; NLP; literature review; survey; review		Natural language processing (NLP) has significantly transformed in the last decade, especially in the field of language modeling. Large language models (LLMs) have achieved SOTA performances on natural language understanding (NLU) and natural language generation (NLG) tasks by learning language representation in self-supervised ways. This paper provides a comprehensive survey to capture the progression of advances in language models. In this paper, we examine the different aspects of language models, which started with a few million parameters but have reached the size of a trillion in a very short time. We also look at how these LLMs transitioned from task-specific to task-independent to task-and-language-independent architectures. This paper extensively discusses different pretraining objectives, benchmarks, and transfer learning methods used in LLMs. It also examines different finetuning and in-context learning techniques used in downstream tasks. Moreover, it explores how LLMs can perform well across many domains and datasets if sufficiently trained on a large and diverse dataset. Next, it discusses how, over time, the availability of cheap computational power and large datasets have improved LLM's capabilities and raised new challenges. As part of our study, we also inspect LLMs from the perspective of scalability to see how their performance is affected by the model's depth, width, and data size. Lastly, we provide an empirical comparison of existing trends and techniques and a comprehensive analysis of where the field of LLM currently stands.	[Patil, Rajvardhan] Grand Valley State Univ, Sch Comp, Allendale, MI 49401 USA; [Gudivada, Venkat] East Carolina Univ, Comp Sci Dept, Greenville, NC 27858 USA	Grand Valley State University; University of North Carolina; East Carolina University	Patil, R (corresponding author), Grand Valley State Univ, Sch Comp, Allendale, MI 49401 USA.	patilr@gvsu.edu; gudivadav15@ecu.edu						Artetxe M, 2022, Arxiv, DOI arXiv:2112.10684; Athiwaratkun B., 2017, arXiv; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Biderman S., 2023, INT C MACHINE LEARNI, P2397; Black S., 2022, PREPRINT; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown P. F., 1990, Computational Linguistics, V16, P79; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Chen X, 2022, Arxiv, DOI arXiv:2209.06794; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dinan E, 2021, Arxiv, DOI [arXiv:2107.03451, 10.48550/arxiv.2107.03451, DOI 10.48550/ARXIV.2107.03451]; Dong L, 2019, ADV NEUR IN, V32; Du N, 2022, PR MACH LEARN RES; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Peters ME, 2019, Arxiv, DOI [arXiv:1909.04164, 10.18653/v1/D19-1005, DOI 10.18653/V1/D19-1005]; Fedus W, 2022, J MACH LEARN RES, V23; Gehman S, 2020, Arxiv, DOI [arXiv:2009.11462, DOI 10.1017/S1431927621007376]; Guu K., 2020, INT C MACHINE LEARNI, P3929; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Houlsby N, 2019, PR MACH LEARN RES, V97; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5; Iyer S, 2022, Arxiv, DOI [arXiv:2212.12017, 10.48550/arXiv.2212.12017, DOI 10.48550/ARXIV.2212.12017]; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kim B, 2021, Arxiv, DOI [arXiv:2109.04650, 10.48550/arXiv.2109.04650, DOI 10.48550/ARXIV.2109.04650]; Lepikhin D, 2020, Arxiv, DOI [arXiv:2006.16668, DOI 10.48550/ARXIV.2006.16668]; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Levine Y., 2020, Advances in Neural Information Processing Systems, V33, P22640; Lewkowycz A., 2022, Advances in Neural Information Processing Systems, P3843; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lieber O., 2021, White Paper. AI21 Labs, V1, P9; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Lin X.V., 2022, PROC 2022 C EMPIRICA, P9019; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Liu X., 2023, AI Open, DOI [10.1016/j.aiopen.2023.08.012, DOI 10.1016/J.AIOPEN.2023.08.012]; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; McCann B., 2017, P 31 INT C NEURAL IN; Melamud O., 2016, P 20TH SIGNLL C COMP, P51; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mosbach M, 2023, Arxiv, DOI arXiv:2305.16938; Muennighoff Niklas, 2022, arXiv; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nangia N, 2020, Arxiv, DOI arXiv:2010.00133; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rudinger R, 2018, Arxiv, DOI arXiv:1804.09301; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; SALTON G, 1968, J ACM, V15, P8, DOI 10.1145/321439.321441; Sanh V, 2022, arXiv; Shazeer N., 2017, arXiv, DOI DOI 10.48550/ARXIV.1701.06538; Soltan S, 2022, arXiv; SPARCKJONES K, 1972, J DOC, V28, P11, DOI 10.1108/eb026526; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Su H, 2022, Arxiv, DOI arXiv:2209.10372; Sun TX, 2020, Arxiv, DOI arXiv:2010.00309; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; Sutskever I, 2014, ADV NEUR IN, V27; Tang B., 2005, PROCEEDING SIAM INT, P17; Tay Y., 2022, P 11 INT C LEARNING; Tay Y, 2022, Arxiv, DOI arXiv:2210.11399; Tay Y, 2022, Arxiv, DOI arXiv:2109.10686; Taylor R, 2022, arXiv; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Ung M., 2021, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Vilnis L, 2015, Arxiv, DOI arXiv:1412.6623; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang RZ, 2020, Arxiv, DOI arXiv:2002.01808; Wang T., 2022, INT C MACHINE LEARNI, P22964; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wang YZ, 2022, Arxiv, DOI arXiv:2204.07705; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu J., 2021, arXiv; Wu S, 2021, arXiv; Xiong WH, 2019, Arxiv, DOI arXiv:1912.09637; Xue L., 2020, arXiv; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zeng W., 2021, PREPRINT; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang ZY, 2021, AI OPEN, V2, P216, DOI 10.1016/j.aiopen.2021.12.003; Zhang ZY, 2019, Arxiv, DOI arXiv:1905.07129; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zheng QK, 2023, Arxiv, DOI [arXiv:2303.17568, 10.48550/arXiv.2303.17568]; Zhou WCS, 2020, Arxiv, DOI arXiv:2011.07956; Zoph B., 2022, arXiv	106	3	3	109	109	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	5							2074	10.3390/app14052074	http://dx.doi.org/10.3390/app14052074			42	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	KT0N8		Green Submitted, gold			2024-07-03	WOS:001182099800001
J	Perez, R; Li, XN; Giannakoulias, S; Petersson, EJ				Perez, Ryann; Li, Xinning; Giannakoulias, Sam; Petersson, E. James			AggBERT: Best in Class Prediction of Hexapeptide Amyloidogenesis with a Semi-Supervised ProtBERT Model	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							AGGREGATION-PRONE; PROTEIN; MUTATIONS; PEPTIDES; LANGUAGE; REGIONS; TRENDS	The prediction of peptide amyloidogenesis is a challengingproblemin the field of protein folding. Large language models, such as theProtBERT model, have recently emerged as powerful tools in analyzingprotein sequences for applications, such as predicting protein structureand function. In this article, we describe the use of a semisupervisedand fine-tuned ProtBERT model to predict peptide amyloidogenesis fromsequences alone. Our approach, which we call AggBERT, achieved state-of-the-artperformance, demonstrating the potential for large language modelsto improve the accuracy and speed of amyloid fibril prediction oversimple heuristics or structure-based approaches. This work highlightsthe transformative potential of machine learning and large languagemodels in the fields of chemical biology and biomedicine.	[Perez, Ryann; Li, Xinning; Giannakoulias, Sam; Petersson, E. James] Univ Penn, Dept Chem, Philadelphia, PA 19104 USA	University of Pennsylvania	Giannakoulias, S; Petersson, EJ (corresponding author), Univ Penn, Dept Chem, Philadelphia, PA 19104 USA.	gianna1@sas.upenn.edu; ejpetersson@sas.upenn.edu		Giannakoulias, Sam/0000-0003-1830-6369	University of Pennsylvania; National Institutes of Health [R01-NS103873]; National Science Foundation (NSF); NIH;  [DGE-1845298];  [T32 GM133398]	University of Pennsylvania; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation (NSF)(National Science Foundation (NSF)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); ; 	This work was supported by the University of Pennsylvania and the National Institutes of Health (R01-NS103873 to E.J.P.). S.G.G. thanks the National Science Foundation (NSF) for funding through the NSF Graduate Research Fellowship Program (DGE-1845298). R.M.P. thanks the NIH for funding through the Chemistry Biology Interface Training Program (T32 GM133398).	Abadi Martin, 2016, arXiv; [Anonymous], 2020, P 2020 C EMP METH NA; Becht E, 2019, NAT BIOTECHNOL, V37, P38, DOI 10.1038/nbt.4314; Chiti F, 2006, ANNU REV BIOCHEM, V75, P333, DOI 10.1146/annurev.biochem.75.101304.123901; Chollet F., 2015, About us; Conchillo-Solé O, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-65; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; de la Paz ML, 2004, P NATL ACAD SCI USA, V101, P87, DOI 10.1073/pnas.2634884100; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Emily M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079722; Fernández L, 2018, CURR PROTEIN PEPT SC, V19, P958, DOI 10.2174/1389203718666170828123449; Ferrie JJ, 2020, CHEM SCI, V11, P12746, DOI 10.1039/d0sc02159h; Giannakoulias S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97965-2; Giannakoulias S, 2020, J PHYS CHEM B, V124, P8032, DOI 10.1021/acs.jpcb.0c05981; Golbraikh A, 2002, J MOL GRAPH MODEL, V20, P269, DOI 10.1016/S1093-3263(01)00123-1; Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55; Husted AS, 2017, CELL METAB, V25, P777, DOI 10.1016/j.cmet.2017.03.008; LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489; Louros N, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17207-3; Louros N, 2020, NUCLEIC ACIDS RES, V48, pD389, DOI 10.1093/nar/gkz758; Lu XM, 2016, ACS CHEM NEUROSCI, V7, P1264, DOI 10.1021/acschemneuro.6b00150; Mckenna A, 2022, J BIOMED INFORM, V128, DOI 10.1016/j.jbi.2022.104016; Milletti F, 2012, DRUG DISCOV TODAY, V17, P850, DOI 10.1016/j.drudis.2012.03.002; Nelson AL, 2010, NAT REV DRUG DISCOV, V9, P767, DOI 10.1038/nrd3229; Newberry RW, 2020, NAT CHEM BIOL, V16, P653, DOI 10.1038/s41589-020-0480-6; Oliveberg M, 2010, NAT METHODS, V7, P187, DOI 10.1038/nmeth0310-187; Pancoe SX, 2022, J MOL BIOL, V434, DOI 10.1016/j.jmb.2022.167859; Pawar AP, 2005, J MOL BIOL, V350, P379, DOI 10.1016/j.jmb.2005.04.016; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Phan HAT, 2021, CHEM SCI, V12, P10825, DOI 10.1039/d1sc00785h; Rajaraman S, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262838; Rocklin M., 2015, Python in Science Conference, V126, DOI DOI 10.25080/MAJORA-7B98E3ED-013; Schwenker F, 2014, PATTERN RECOGN LETT, V37, P4, DOI 10.1016/j.patrec.2013.10.017; Shringari SR, 2020, CHEM COMMUN, V56, P6774, DOI 10.1039/d0cc01959c; Souroujon MC, 1998, NAT BIOTECHNOL, V16, P919, DOI 10.1038/nbt1098-919; Srinivas P, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103456; Suzek BE, 2007, BIOINFORMATICS, V23, P1282, DOI 10.1093/bioinformatics/btm098; Tang L, 2004, J PHARM SCI-US, V93, P2184, DOI 10.1002/jps.20125; Tartaglia GG, 2008, J MOL BIOL, V380, P425, DOI 10.1016/j.jmb.2008.05.013; Thangakani AM, 2014, BIOINFORMATICS, V30, P1983, DOI 10.1093/bioinformatics/btu167; Vaswani A, 2017, ADV NEUR IN, V30; Walsh I, 2014, NUCLEIC ACIDS RES, V42, pW301, DOI 10.1093/nar/gku399; Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738; Zapadka KL, 2017, INTERFACE FOCUS, V7, DOI 10.1098/rsfs.2017.0030	44	2	2	9	25	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	AUG 8	2023	63	18					5727	5733		10.1021/acs.jcim.3c00817	http://dx.doi.org/10.1021/acs.jcim.3c00817		AUG 2023	7	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	S1RW1	37552230				2024-07-03	WOS:001044525600001
C	Mondal, R; Tang, A; Beckett, R; Millstein, T; Varghese, G			ACM	Mondal, Rajdeep; Tang, Alan; Beckett, Ryan; Millstein, Todd; Varghese, George			What do LLMs need to Synthesize Correct Router Configurations?	PROCEEDINGS OF THE 22ND ACM WORKSHOP ON HOT TOPICS IN NETWORKS, HOTNETS 2023			English	Proceedings Paper	22nd ACM Workshop on Hot Topics in Networks (HotNets)	NOV 28-29, 2023	Cambridge, MA	Assoc Comp Machinery, ACM SIGCOMM		CoSynth; network verification and synthesis; large language models (LLMs)		We investigate whether Large Language Models (e.g., GPT-4) can synthesize correct router configurations with reduced manual effort. We find GPT-4 works very badly by itself, producing promising draft configurations but with egregious errors in topology, syntax, and semantics. Our strategy, that we call Verified Prompt Programming, is to combine GPT-4 with verifiers, and use localized feedback from the verifier to automatically correct errors. Verification requires a specification and actionable localized feedback to be effective. We show results for two use cases: translating from Cisco to Juniper configurations on a single router, and implementing a no-transit policy on multiple routers. While human input is still required, if we define the leverage as the number of automated prompts to the number of human prompts, our experiments show a leverage of 10X for Juniper translation, and 6X for implementing the no-transit policy, ending with verified configurations.	[Mondal, Rajdeep; Tang, Alan; Millstein, Todd; Varghese, George] UCLA, Los Angeles, CA 90024 USA; [Beckett, Ryan] Microsoft Res, Redmond, WA 98052 USA	University of California System; University of California Los Angeles; Microsoft	Mondal, R (corresponding author), UCLA, Los Angeles, CA 90024 USA.	mondalrajdeep14@ucla.edu; atang42@cs.ucla.edu; Ryan.Beckett@Microsoft.com; todd@cs.ucla.edu; varghese@cs.ucla.edu		Millstein, Todd/0000-0002-2031-1514				Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bollobas B., 2023, The man who taught infinity: how G.H. Hardy tamed Srinivasa Ramanujan's genius; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Chen M., 2021, ARXIV; DeepLearning, 2023, AI. ChatGPT Prompt Engineering for Developers; Fogel Ari, 2015, 12 USENIX S NETWORKE; github, 2023, Github CoPilot: Your AI Pair Programmer; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Kani Rust Verifier Blog, 2023, Writing Code with ChatGPT? Improve it with Kani; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Tang A., 2023, SIGCOMM '23; Tang AL, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P748, DOI 10.1145/3452296.3472925; Wang J., 2023, Software Testing with Large Language Model: Survey, Landscape, and Vision	13	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0415-4				2023							189	195		10.1145/3626111.3628194	http://dx.doi.org/10.1145/3626111.3628194			7	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TD		hybrid, Green Submitted			2024-07-03	WOS:001124843800025
J	Wu, JG; Wu, X; Qiu, ZP; Li, MH; Lin, SX; Zhang, YY; Zheng, YF; Yuan, CZ; Yang, J				Wu, Jiageng; Wu, Xian; Qiu, Zhaopeng; Li, Minghui; Lin, Shixu; Zhang, Yingying; Zheng, Yefeng; Yuan, Changzheng; Yang, Jie			Large language models leverage external knowledge to extend clinical insight beyond language boundaries	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						large language models; clinical knowledge; natural language processing; medical examination		Objectives Large Language Models (LLMs) such as ChatGPT and Med-PaLM have excelled in various medical question-answering tasks. However, these English-centric models encounter challenges in non-English clinical settings, primarily due to limited clinical knowledge in respective languages, a consequence of imbalanced training corpora. We systematically evaluate LLMs in the Chinese medical context and develop a novel in-context learning framework to enhance their performance.Materials and Methods The latest China National Medical Licensing Examination (CNMLE-2022) served as the benchmark. We collected 53 medical books and 381 149 medical questions to construct the medical knowledge base and question bank. The proposed Knowledge and Few-shot Enhancement In-context Learning (KFE) framework leverages the in-context learning ability of LLMs to integrate diverse external clinical knowledge sources. We evaluated KFE with ChatGPT (GPT-3.5), GPT-4, Baichuan2-7B, Baichuan2-13B, and QWEN-72B in CNMLE-2022 and further investigated the effectiveness of different pathways for incorporating LLMs with medical knowledge from 7 distinct perspectives.Results Directly applying ChatGPT failed to qualify for the CNMLE-2022 at a score of 51. Cooperated with the KFE framework, the LLMs with varying sizes yielded consistent and significant improvements. The ChatGPT's performance surged to 70.04 and GPT-4 achieved the highest score of 82.59. This surpasses the qualification threshold (60) and exceeds the average human score of 68.70, affirming the effectiveness and robustness of the framework. It also enabled a smaller Baichuan2-13B to pass the examination, showcasing the great potential in low-resource settings.Discussion and Conclusion This study shed light on the optimal practices to enhance the capabilities of LLMs in non-English medical scenarios. By synergizing medical knowledge through in-context learning, LLMs can extend clinical insight beyond language barriers in healthcare, significantly reducing language-related disparities of LLM applications and ensuring global benefit in this field.	[Wu, Jiageng; Lin, Shixu; Yuan, Changzheng; Yang, Jie] Zhejiang Univ, Sch Med, Sch Publ Hlth, Hangzhou 310058, Peoples R China; [Wu, Xian; Qiu, Zhaopeng; Zhang, Yingying; Zheng, Yefeng] Tencent YouTu Lab, Jarvis Res Ctr, 1 Tianchen East Rd, Beijing 100101, Peoples R China; [Yuan, Changzheng] Harvard TH Chan Sch Publ Hlth, Dept Nutr, Boston, MA 02115 USA; [Yang, Jie] Harvard Med Sch, Brigham & Womens Hosp, Dept Med, Div Pharmacoepidemiol & Pharmacoecon, Boston, MA 02115 USA; [Yuan, Changzheng] Zhejiang Univ, Sch Publ Hlth, 866 Yuhangtang Rd, Hangzhou, Zhejiang, Peoples R China; [Yang, Jie] Brigham & Womens Hosp, Dept Med, 75 Francis St, Boston, MA 02115 USA; [Yang, Jie] Harvard Med Sch, 75 Francis St, Boston, MA 02115 USA	Zhejiang University; Tencent; Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Harvard Medical School; Brigham & Women's Hospital; Zhejiang University; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School	Wu, X (corresponding author), Tencent YouTu Lab, Jarvis Res Ctr, 1 Tianchen East Rd, Beijing 100101, Peoples R China.; Yuan, CZ (corresponding author), Zhejiang Univ, Sch Publ Hlth, 866 Yuhangtang Rd, Hangzhou, Zhejiang, Peoples R China.; Yang, J (corresponding author), Brigham & Womens Hosp, Dept Med, 75 Francis St, Boston, MA 02115 USA.; Yang, J (corresponding author), Harvard Med Sch, 75 Francis St, Boston, MA 02115 USA.	kevinxwu@tencent.com; chy478@zju.edu.cn; jyang66@bwh.harvard.edu						[Anonymous], THUOCL: Tsinghua open Chinese lexicon; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bai JZ, 2023, Arxiv, DOI [arXiv:2309.16609, 10.48550/arXiv.2309.16609, DOI 10.48550/ARXIV.2309.16609]; Bang Y, 2023, P 13 INT JOINT C NAT, P675, DOI [DOI 10.18653/V1/2023.IJCNLP--MAIN.45, DOI 10.18653/V1/2023.IJCNLP-MAIN.45]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Blevins T, 2022, P 2022 C EMPIRICAL M, DOI 10.18653/v1/2022.emnlp-main.233; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chung HW., 2024, Journal of Machine Learning Research, V25, P1; Cruz TM, 2021, MED CARE, V59, P379, DOI 10.1097/MLR.0000000000001507; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong L, 2019, ADV NEUR IN, V32; Edunov S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4052; Ferryman K, 2023, NEW ENGL J MED, V389, P833, DOI 10.1056/NEJMra2214964; Gao Y, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18918-3; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Grigorian A, 2023, JAMA SURG, V158, P1220, DOI 10.1001/jamasurg.2023.3875; Guu K, 2020, PR MACH LEARN RES, V119; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Heim L., 2023, Estimating Palm's Training Cost; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Jia ZE, 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00670-0; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Kim J, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.38050; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lam K, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100906; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lehman E., 2023, C HLTH INF LEARN, P578; Liévin V, 2024, PATTERNS, V5, DOI 10.1016/j.patter.2024.100943; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Liu XC, 2024, J MED INTERNET RES, V26, DOI 10.2196/51926; Min Sewon, 2022, P 2022 C EMPIRICAL M, P11048, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.759; Nayak A, 2023, JAMA INTERN MED, V183, P1026, DOI 10.1001/jamainternmed.2023.2561; Nicholas G., 2023, Lost in translation: Large language models in non-english content analysis; nmec, Introduction to Physician Qualification Examination | Chinese National Medical Examination Web; nmec, Outline of the Chinese National Medical Licensing Examination for Clinical Practitioners | Chinese National Medical Examination Web; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Qin C., 2023, P 2023 C EMPIRICAL M, P1339; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Rubin O, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2655; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Shwartz V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4615; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; The Most Spoken Languages, 2023, Statistics & Data; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thompson WE, 2023, Arxiv, DOI [arXiv:2312.06457, DOI 10.48550/ARXIV.2312.06457, 10.48550/arXiv.2312.06457]; Wang WX, 2023, Arxiv, DOI [arXiv:2310.00905, 10.48550/arXiv.2310.00905]; Wang XF, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100905; Wang XY, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01961-0; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Wei JH, 2022, PR MACH LEARN RES; Wu J., 2023, P ACM WEB C 2023 WWW, P3968, DOI [10.1145/3543507.3583867, DOI 10.1145/3543507.3583867]; Wu J, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06799-6; Wu JG, 2024, Arxiv, DOI [arXiv:2403.06609, 10.48550/arXiv.2403.06609, DOI 10.48550/ARXIV.2403.06609]; Wu JG, 2024, Arxiv, DOI [arXiv:2403.06611, 10.48550/arXiv.2403.06611, DOI 10.48550/ARXIV.2403.06611]; Yang AY, 2023, Arxiv, DOI [arXiv:2309.10305, DOI 10.48550/ARXIV.2309.10305]; Yoo KM, 2022, P 2022 C EMPIRICAL M, P2422, DOI 10.18653/v1/2022.emnlp-main.155; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang X, 2018, AAAI CONF ARTIF INTE, P5706; Zhang Z, 2023, 11 INT C LEARNING RE; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu WH, 2023, Arxiv, DOI arXiv:2308.04948	74	0	0	16	16	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 29	2024										10.1093/jamia/ocae079	http://dx.doi.org/10.1093/jamia/ocae079		APR 2024	11	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	OT3P5	38684792	Green Submitted			2024-07-03	WOS:001209494000001
C	Valencia, S; Cave, R; Kallarackal, K; Seaver, K; Terry, M; Kane, SK			ACM	Valencia, Stephanie; Cave, Richard; Kallarackal, Krystal; Seaver, Katie; Terry, Michael; Kane, Shaun K.			"The less I type, the beter": How AI Language Models can Enhance or Impede Communication for AAC Users	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023)			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		accessibility; communication; artificial intelligence; large language models		Users of augmentative and alternative communication (AAC) devices sometimes find it difficult to communicate in real time with others due to the time it takes to compose messages. AI technologies such as large language models (LLMs) provide an opportunity to support AAC users by improving the quality and variety of text suggestions. However, these technologies may fundamentally change how users interact with AAC devices as users transition from typing their own phrases to prompting and selecting AI-generated phrases. We conducted a study in which 12 AAC users tested live suggestions from a language model across three usage scenarios: extending short replies, answering biographical questions, and requesting assistance. Our study participants believed that AI-generated phrases could save time, physical and cognitive effort when communicating, but felt it was important that these phrases reflect their own communication style and preferences. This work identifies opportunities and challenges for future AI-enhanced AAC devices.	[Valencia, Stephanie] Carnegie Mellon Univ, Google Res, Pittsburgh, PA 15213 USA; [Cave, Richard] UCL, Dept Language & Cognit, London, England; [Kallarackal, Krystal; Terry, Michael] Google Res, Cambridge, MA USA; [Seaver, Katie] MGH Inst Hlth Profess, Boston, MA USA; [Kane, Shaun K.] Google Res, Boulder, CO USA	Carnegie Mellon University; Google Incorporated; University of London; University College London; Google Incorporated; Google Incorporated	Valencia, S (corresponding author), Carnegie Mellon Univ, Google Res, Pittsburgh, PA 15213 USA.	svalenci@andrew.cmu.edu; shaunkane@google.com	Valencia, Stephanie/JWP-8460-2024	Valencia, Stephanie/0000-0001-6588-9494; Cave, Richard/0000-0002-6410-8200				Beneteau E, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376344; Beukelman D. R., 2013, AUGMENTATIVE ALTERNA; Blackstone SW, 2007, AUGMENT ALTERN COMM, V23, P191, DOI 10.1080/07434610701553684; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai Shanqing, 2022, ARXIV220503767; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Dai YH, 2023, COMPUT METHOD BIOMEC, V26, P846, DOI 10.1080/10255842.2022.2092727; de Vargas MF, 2022, PROCEEDINGS OF THE 24TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2022, DOI 10.1145/3517428.3544805; de Vargas Mauricio Fontana, 2021, P 59 ANN M ASS COMP, V1, P1353, DOI [10.18653/v1/2021.acl-long.108, DOI 10.18653/V1/2021.ACL-L0NG.108]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fiannaca A, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P683, DOI 10.1145/2998181.2998215; Goodman Steven M, 2022, ARXIV220702308; Griggio Carla F., 2019, Proceedings of the ACM on Human-Computer Interaction, V3, DOI 10.1145/3359128; Higginbotham DJ, 1999, CONSTRUCTING (IN) COMPETENCE, P49; Jiang E, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503564; Kane S, 2012, P 14 INT ACM SIGACCE, DOI DOI 10.1145/2384916.2384926; Kane SK, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P129, DOI 10.1145/3064663.3064762; Kane SK, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P1166, DOI 10.1145/2998181.2998284; Kelly R, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P70, DOI 10.1145/2998181.2998184; Kristensson P. O., 2012, P S EYE TRACK RES AP, P241, DOI [10.1145/2168556.2168605doi.org/10.1145/2168556.2168605, DOI 10.1145/2168556.2168605DOI.ORG/10.1145/2168556.2168605, 10.1145/2168556.2168605, DOI 10.1145/2168556.2168605]; Lee Charlotte P., 2007, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V16, P307, DOI 10.1007/s10606-007-9044-5; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; McKelvey M, 2012, AUGMENT ALTERN COMM, V28, P232, DOI 10.3109/07434618.2012.737023; Miles M. B., 1994, Qualitative data analysis: A methods sourcebook, DOI DOI 10.1016/0149-7189(96)88232-2; Morrison C., 2021, P CHI C HUMAN FACTOR, P1; Mott ME, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2558, DOI 10.1145/3025453.3025517; Oh C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174223; Robillard A., 1994, Qualitative Sociology, V17, P383; Seale Jennifer M, 2020, AUGMENTATIVE ALTERNA, P1; Shen JX, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P853, DOI 10.1145/3490099.3511145; Thoppilan R., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2201.08239; Trinh Ha, 2012, P 3 WORKSH SPEECH LA, P19; Trnka K., 2009, ACM Transactions on Accessible Computing, V1, DOI [DOI 10.1145/1497302.1497307, 10.1145/1497302.1497307]; Valencia S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376376; Vertanen K, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P347, DOI 10.1145/3132525.3134814; Walther JB, 1996, COMMUN RES, V23, P3, DOI 10.1177/009365096023001001; Yang FM, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P189, DOI 10.1145/3377325.3377480; Yang Q, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300415; Yildirim N, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517491	40	2	2	0	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3581560	http://dx.doi.org/10.1145/3544548.3581560			14	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV5HH		Bronze			2024-07-03	WOS:001048393807026
J	Zaidat, B; Lahoti, YS; Yu, A; Mohamed, KS; Cho, SK; Kim, JS				Zaidat, Bashar; Lahoti, Yash S.; Yu, Alexander; Mohamed, Kareem S.; Cho, Samuel K.; Kim, Jun S.			Artificially Intelligent Billing in Spine Surgery: An Analysis of a Large Language Model	GLOBAL SPINE JOURNAL			English	Article; Early Access						spine; current procedural terminology; natural language processing; large language model; chatGPT; prompt engineering	PHYSICIAN PRACTICES; HEALTH; COST	Study Design Retrospective cohort study.Objectives This study assessed the effectiveness of a popular large language model, ChatGPT-4, in predicting Current Procedural Terminology (CPT) codes from surgical operative notes. By employing a combination of prompt engineering, natural language processing (NLP), and machine learning techniques on standard operative notes, the study sought to enhance billing efficiency, optimize revenue collection, and reduce coding errors.Methods The model was given 3 different types of prompts for 50 surgical operative notes from 2 spine surgeons. The first trial was simply asking the model to generate CPT codes for a given OP note. The second trial included 3 OP notes and associated CPT codes to, and the third trial included a list of every possible CPT code in the dataset to prime the model. CPT codes generated by the model were compared to those generated by the billing department. Model evaluation was performed in the form of calculating the area under the ROC (AUROC), and area under precision-recall curves (AUPRC).Results The trial that involved priming ChatGPT with a list of every possible CPT code performed the best, with an AUROC of .87 and an AUPRC of .67, and an AUROC of .81 and AUPRC of .76 when examining only the most common CPT codes.Conclusions ChatGPT-4 can aid in automating CPT billing from orthopedic surgery operative notes, driving down healthcare expenditures and enhancing billing code precision as the model evolves and fine-tuning becomes available.	[Zaidat, Bashar; Lahoti, Yash S.; Yu, Alexander; Mohamed, Kareem S.; Cho, Samuel K.; Kim, Jun S.] Icahn Sch Med Mt Sinai, Dept Orthopaed Surg, 425 West 59th St, New York, NY 10019 USA	Icahn School of Medicine at Mount Sinai	Kim, JS (corresponding author), Icahn Sch Med Mt Sinai, Dept Orthopaed Surg, 425 West 59th St, New York, NY 10019 USA.	jun.kim@mountsinai.org		Zaidat, Bashar/0000-0002-8823-720X; Mohamed, Kareem/0009-0003-9667-704X; Yu, Alexander/0000-0002-7246-2269				Buck C, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3579; Burns ML, 2020, ANESTHESIOLOGY, V132, P738, DOI 10.1097/ALN.0000000000003150; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Casalino LP, 2009, HEALTH AFFAIR, V28, pW533, DOI 10.1377/hlthaff.28.4.w533; Drabiak Katherine, 2020, AMA J Ethics, V22, pE221, DOI 10.1001/amajethics.2020.221; Duszak Richard, 2004, J Am Coll Radiol, V1, P734, DOI 10.1016/j.jacr.2004.05.003; Grieger DL, 2007, J AM COLL SURGEONS, V205, P89, DOI 10.1016/j.jamcollsurg.2007.02.074; Hammon Marilyn, 2005, J Okla State Med Assoc, V98, P401; Huang JM, 2019, COMPUT METH PROG BIO, V177, P141, DOI 10.1016/j.cmpb.2019.05.024; Kahn JG, 2005, HEALTH AFFAIR, V24, P1629, DOI 10.1377/hlthaff.24.6.1629; Kim JS, 2023, GLOB SPINE J, V13, P1946, DOI 10.1177/21925682211062831; Levy Joshua, 2022, J Pathol Inform, V13, P3, DOI 10.4103/jpi.jpi_52_21; Manley R, 2009, J VASC SURG, V50, P1232, DOI 10.1016/j.jvs.2009.07.065; Martin-Sanchez F, 2014, Yearb Med Inform, V9, P14, DOI 10.15265/IY-2014-0020; Morra D, 2011, HEALTH AFFAIR, V30, P1443, DOI 10.1377/hlthaff.2010.0893; Oh SH, 2022, HEALTHC INFORM RES, V28, P16, DOI 10.4258/hir.2022.28.1.16; Popel Martin, 2018, Prague Bulletin of Mathematical Linguistics, P43, DOI 10.2478/pralin-2018-0002; Shrank WH, 2019, JAMA-J AM MED ASSOC, V322, P1501, DOI 10.1001/jama.2019.13978; Soleymani MH, 2018, DARU, V26, P209, DOI 10.1007/s40199-018-0227-z; Tollen L., 2020, How Administrative Spending Contributes to Excess US Health Spending; Tseng P, 2018, JAMA-J AM MED ASSOC, V319, P691, DOI 10.1001/jama.2017.19148; Zaidat B, 2023, GLOB SPINE J, DOI 10.1177/21925682231164935	22	3	3	5	5	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	2192-5682	2192-5690		GLOB SPINE J	Glob. Spine J.	2023 DEC 26	2023										10.1177/21925682231224753	http://dx.doi.org/10.1177/21925682231224753		DEC 2023	8	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	DJ0Q8	38147047	gold			2024-07-03	WOS:001131553600001
J	Kim, H; Jin, HM; Bin Jung, Y; You, SC				Kim, Hanjae; Jin, Hee Min; Bin Jung, Yoon; You, Seng Chan			Patient-Friendly Discharge Summaries in Korea Based on ChatGPT: Software Development and Validation	JOURNAL OF KOREAN MEDICAL SCIENCE			English	Article						ChatGPT; Artificial Intelligence; Large Language Model; Patient Discharge Summaries; Patient-Centered Care; Documentation		Background: Although discharge summaries in patient -friendly language can enhance patient comprehension and satisfaction, they can also increase medical staff workload. Using a large language model, we developed and validated software that generates a patient -friendly discharge summary. Methods: We developed and tested the software using 100 discharge summary documents, 50 for patients with myocardial infarction and 50 for patients treated in the Department of General Surgery. For each document, three new summaries were generated using three different prompting methods (Zero -shot, One-shot, and Few -shot) and graded using a 5 -point Likert Scale regarding factuality, comprehensiveness, usability, ease, and fluency. We compared the effects of different prompting methods and assessed the relationship between input length and output quality. Results: The mean overall scores differed across prompting methods (4.19 +/- 0.36 in Few -shot, 4.11 +/- 0.36 in One-shot, and 3.73 +/- 0.44 in Zero -shot; P < 0.001). Post -hoc analysis indicated that the scores were higher with Few -shot and One-shot prompts than in zero -shot prompts, whereas there was no significant difference between Few -shot and One-shot prompts. The overall proportion of outputs that scored >= 4 was 77.0% (95% confidence interval: 68.8-85.3%), 70.0% (95% confidence interval [CI], 61.0-79.0%), and 32.0% (95% CI, 22.9-41.1%) with Few -shot, One-shot, and Zero -shot prompts, respectively. The mean factuality score was 4.19 +/- 0.60 with Few -shot, 4.20 +/- 0.55 with One-shot, and 3.82 +/- 0.57 with Zero -shot prompts. Input length and the overall score showed negative correlations in the Zero -shot ( r = -0.437, P < 0.001) and One-shot ( r = -0.327, P < 0.001) tests but not in the Few -shot ( r = -0.050, P = 0.625) tests. Conclusion: Large -language models utilizing Few -shot prompts generally produce acceptable discharge summaries without significant misinformation. Our research highlights the potential of such models in creating patient -friendly discharge summaries for Korean patients to support patient -centered care.	[Kim, Hanjae] Yonsei Univ, Coll Nursing, Seoul, South Korea; [Jin, Hee Min; You, Seng Chan] Yonsei Univ, Coll Med, Dept Biomed Syst Informat, 50-1 Yonsei Ro, Seoul 03722, South Korea; [Bin Jung, Yoon] Yonsei Univ, Coll Med, Dept Surg, Seoul, South Korea	Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System	You, SC (corresponding author), Yonsei Univ, Coll Med, Dept Biomed Syst Informat, 50-1 Yonsei Ro, Seoul 03722, South Korea.	Chandryou@yuhs.ac			Yonsei University College of Medicine [6-2023-0067]	Yonsei University College of Medicine	This study was supported by a faculty research grant of Yonsei University College of Medicine (6-2023-0067) .	Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Bang Y, 2023, arXiv, DOI [10.18653/v1/2023.ijcnlp-main.45.CROSSREF, DOI 10.18653/V1/2023.IJCNLP-MAIN.45.CROSSREF]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang Y, 2024, ACM Trans Intell Syst Technol, V15, P39; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chowdhery A, 2023, J MACH LEARN RES, V24; Cook JLE, 2022, BMJ OPEN QUAL, V11, DOI 10.1136/bmjoq-2021-001810; Deik A, 2023, J MOV DISORD, V16, P158, DOI 10.14802/jmd.23072; Deroy A, 2023, Arxiv, DOI [arXiv:2306.01248, 10.48550/arXiv.2306.01248, DOI 10.48550/ARXIV.2306.01248]; Doskaliuk B, 2023, J KOREAN MED SCI, V38, DOI 10.3346/jkms.2023.38.e207; Epstein RM, 2011, ANN FAM MED, V9, P100, DOI 10.1370/afm.1239; Gaffney A, 2022, JAMA INTERN MED, V182, P564, DOI 10.1001/jamainternmed.2022.0372; Google, BARD; Hanna Michael., 2021, P 6 C MACHINE TRANSL, P507; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kim S., 2023, Korean J Med, V98, P99; Kim YG, 2017, INT J MED INFORM, V101, P100, DOI 10.1016/j.ijmedinf.2017.02.009; Li TH, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01024-9; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Lin R, 2014, INTERN MED J, V44, P851, DOI 10.1111/imj.12482; Luo JL, 2024, Arxiv, DOI [arXiv:2401.08358, DOI 10.48550/ARXIV.2401.08358, 10.48550/arXiv.2401.08358]; Mead N, 2000, SOC SCI MED, V51, P1087, DOI 10.1016/S0277-9536(00)00098-8; Medenilla A., 2023, PLoS Digital Health, V2; Nayak A, 2023, JAMA INTERN MED, V183, P1026, DOI 10.1001/jamainternmed.2023.2561; Newnham H, 2017, INT J QUAL HEALTH C, V29, P752, DOI 10.1093/intqhc/mzx121; OpenAI, API data usage policies; OpenAI, Introducing ChatGPT; OpenAI, GPT 4; OpenAI platform, Models; OpenAI platform, Quickstart; OpenAI platform, Introduction; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Preiksaitis C, 2023, NAT MED, V29, P1296, DOI 10.1038/s41591-023-02341-4; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sorita A, 2021, J PATIENT SAF, V17, pE637, DOI 10.1097/PTS.0000000000000421; Tajirian T, 2020, J MED INTERNET RES, V22, DOI 10.2196/19274; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	45	0	0	0	0	KOREAN ACAD MEDICAL SCIENCES	SEOUL	4F, 37 Ichon-ro 46-Gil, Yongsan-gu, SEOUL, SOUTH KOREA	1011-8934	1598-6357		J KOREAN MED SCI	J. Korean Med. Sci.	APR 29	2024	39	16							e148	10.3346/jkms.2024.39.e148	http://dx.doi.org/10.3346/jkms.2024.39.e148			12	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	SI0Z0		gold			2024-07-03	WOS:001233720700006
C	Dang, H; Goller, S; Lehmann, F; Buschek, D			ACM	Dang, Hai; Goller, Sven; Lehmann, Florian; Buschek, Daniel			Choice Over Control: How Users Write with Large Language Models using Diegetic and Non-Diegetic Prompting	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Large language models; Co-creative systems; Human-AI collaboration; User-centric natural language generation		We propose a conceptual perspective on prompts for Large Language Models (LLMs) that distinguishes between (1) diegetic prompts (part of the narrative, e.g. "Once upon a time, I saw a fox..."), and (2) non-diegetic prompts (external, e.g. "Write about the adventures of the fox."). With this lens, we study how 129 crowd workers on Prolific write short texts with different user interfaces (1 vs 3 suggestions, with/out non-diegetic prompts; implemented with GPT-3): When the interface offered multiple suggestions and provided an option for non-diegetic prompting, participants preferred choosing from multiple suggestions over controlling them via non-diegetic prompts. When participants provided non-diegetic prompts it was to ask for inspiration, topics or facts. Single suggestions in particular were guided both with diegetic and non-diegetic information. This work informs human-AI interaction with generative models by revealing that (1) writing non-diegetic prompts requires effort, (2) people combine diegetic and non-diegetic prompting, and (3) they use their draft (i.e. diegetic information) and suggestion timing to strategically guide LLMs.	[Dang, Hai; Goller, Sven; Lehmann, Florian; Buschek, Daniel] Univ Bayreuth, Bayreuth, Bavaria, Germany	University of Bayreuth	Dang, H (corresponding author), Univ Bayreuth, Bayreuth, Bavaria, Germany.	hai.dang@uni-hayreuth.de; sven.goller@uni-bayreuth.de; florianiehmanti@uni-bayreuth.de; daniel.buschek@uni-bayreuth.de		Lehmann, Florian/0000-0003-0201-867X; Dang, Hai/0000-0003-3617-5657; Goller, Sven/0000-0001-5263-5372	Bavarian State Ministry of Science and the Arts	Bavarian State Ministry of Science and the Arts	We thank Lukas Mecke for feedback on the manuscript. This project is funded by the Bavarian State Ministry of Science and the Arts and coordinated by the Bavarian Research Institute for Digital Transformation (bidt).	Arnold Kenneth C., 2018, Graphics interface, P42, DOI [10.20380/GI2018.07, DOI 10.20380/GI2018.07]; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Bau David, 2018, TECHNICAL REPORT, DOI [10.48550/arXiv.1811.10597, DOI 10.48550/ARXIV.1811.10597]; Bhat Advait, 2022, STUDYING WRITER SUGG, DOI [DOI 10.48550/ARXIV.2208.00636, 10.48550/arXiv.2208.00636]; Buschek D, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445372; Calderwood A., 2020, HAI-GEN+ user2agent@ IUI; Chen MX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/3292500.3330723; Chung JJY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501819; Dunlop Mark, 2012, P SIGCHI C HUMAN FAC, P2669, DOI [DOI 10.1145/2207676.2208659, 10.1145/2207676.2208659]; Fowler A, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P649, DOI 10.1145/2702123.2702503; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Gero KI, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022), P11; Goel M., 2013, Proceedings of the SIGCHI Conference on Human Factors inComputing Systems. CHI '13, P2795, DOI DOI 10.1145/2470654.2481386; Goel Mayank, 2012, CHI '12, P2687, DOI 10.1145/2207676. 2208662; Goodman Steven, 2022, LAMPOST EVALUATION A; Gordon M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3817, DOI 10.1145/2858036.2858242; Ha David, 2017, ARXIV170403477CSSTAT; Haviv A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3618; Hayes JR, 2012, WRIT COMMUN, V29, P369, DOI 10.1177/0741088312451260; Jiang Ellen, 2022, CHI C HUM FACT COMP, P1; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Kannan A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P955, DOI 10.1145/2939672.2939801; Kuznetsova A, 2017, J STAT SOFTW, V82, P1, DOI 10.18637/jss.v082.i13; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Jiachang, 2021, ARXIV210106804CS; Liu Pengfei, 2021, ARXIV210713586CS; Muller MJ, 2012, HUM FACTORS ERGON, P1125; Nichol Alex, 2021, GLIDE PHOTOREALISTIC, DOI [DOI 10.48550/ARXIV.2112.10741, 10.48550/ARXIV.2112.10741]; NIELSEN J, 1994, HUMAN FACTORS IN COMPUTING SYSTEMS, CHI '94 CONFERENCE PROCEEDINGS - CELEBRATING INTERDEPENDENCE, P152, DOI 10.1145/191666.191729; Patashnik Or, 2021, STYLECLIP TEXT DRIVE, DOI [10.48550/ARXIV.2103.17249, DOI 10.48550/ARXIV.2103.17249]; Petroni Fabio, 2019, ARXIV190901066CS; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Quinn P, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P83, DOI 10.1145/2858036.2858305; Ramesh Aditya., Hierarchical Text-Conditional Image Generation with CLIP Latents, P2022, DOI DOI 10.48550/ARXIV.2204.06125; Roemmele M, 2015, LECT NOTES COMPUT SC, V9445, P81, DOI 10.1007/978-3-319-27036-4_8; Schick Timo, 2021, ARXIV200107676CS; Schick Timo, 2022, PEER COLLABORATIVE L, DOI [10.48550/ARXIV.2208.11663, DOI 10.48550/ARXIV.2208.11663]; Simon H., 1996, The Sciences of the Artificial; Singh N, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3511599; Strauss A., 1990, BASICS QUALITATIVE R, DOI DOI 10.2307/2074814; Strobelt Hendrik, 2022, ARXIV220807852CS; Swanson B, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P244; Touloumis A, 2015, J STAT SOFTW, V64, P1; Vertanen K, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2555691; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Wu Tongshuang, 2022, ARXIV220306566CS; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Yuan Weizhe, 2021, ARXIV210611520CS; Zhao Tony Z., 2021, ARXIV210209690CS	50	1	2	5	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580969	http://dx.doi.org/10.1145/3544548.3580969			17	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Submitted			2024-07-03	WOS:001037809505006
C	Zhuo, TY; Li, Z; Huang, YJ; Shiri, F; Wang, WQ; Haffari, G; Li, YF		Vlachos, A; Augenstein, I		Zhuo, Terry Yue; Li, Zhuang; Huang, Yujin; Shiri, Fatemeh; Wang, Weiqing; Haffari, Gholamreza; Li, Yuan-Fang			On Robustness of Prompt-based Semantic Parsing with Large Pre-trained Language Model: An Empirical Study on Codex	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Semantic parsing is a technique aimed at constructing a structured representation of the meaning of a natural-language question. Recent advances in language models trained on code have shown superior performance in generating these representations compared to language models trained solely on natural language text. The existing fine-tuned neural semantic parsers are vulnerable to adversarial attacks on natural-language inputs. While it has been established that the robustness of smaller semantic parsers can be enhanced through adversarial training, this approach is not feasible for large language models in real-world scenarios, as it requires both substantial computational resources and expensive human annotation on in-domain semantic parsing data. This paper presents the first empirical study on the adversarial robustness of a prompt-based semantic parser based on CODEX, a state-ofthe-art (SOTA) language model trained on code. Our results demonstrate that the large language model of code is vulnerable to carefully crafted adversarial examples. To overcome this challenge, we propose methods for enhancing robustness without requiring substantial amounts of labelled data or intensive computational resources.	[Zhuo, Terry Yue] CSIROs Data61, Canberra, ACT, Australia; [Zhuo, Terry Yue; Li, Zhuang; Huang, Yujin; Shiri, Fatemeh; Wang, Weiqing; Haffari, Gholamreza; Li, Yuan-Fang] Monash Univ, Clayton, Vic, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Monash University	Li, Z (corresponding author), Monash Univ, Clayton, Vic, Australia.	terry.zhuo@monash.edu; zhuang.li@monash.edu		Wang, Weiqing/0000-0002-9578-819X				Allen-Zhu Z, 2022, ANN IEEE SYMP FOUND, P977, DOI 10.1109/FOCS52979.2021.00098; Alzantot M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2890; Anand R, 2011, MINING MASSIVE DATAS; [Anonymous], 2018, ICLR; [Anonymous], 2018, ARXIV180600692; Bangarwa P, 2023, BENCHMARKING, V30, P3817, DOI 10.1108/BIJ-08-2021-0498; Bapna A, 2017, INTERSPEECH, P2476, DOI 10.21437/Interspeech.2017-518; Bartolo M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8830; Bisk Y., 2018, 6 INT C LEARNING REP; Boucher N, 2022, P IEEE S SECUR PRIV, P1987, DOI [10.1109/SP46214.2022.9833641, 10.1109/SP46214.2022.00045]; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Drozdov Andrew, 2022, ARXIV220915003; Duong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P43; Ebrahimi J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P31; Eger S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1634; Finegan-Dollak C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P351; Fitria T. N., 2021, Englisia: Journal of Language, Education, and Humanities, V9, P183, DOI 10.22373/ej.v9i1.10233; Ganin Y, 2016, J MACH LEARN RES, V17; Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P50, DOI 10.1109/SPW.2018.00016; Guo C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5747; Hosseini Hossein, 2017, ARXIV170208138; Huang S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3333; Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089; Iyyer M., 2018, P 2018 C N AM CHAPTE, V1, P1875, DOI DOI 10.18653/V1/N18-1170; Jia JY, 2021, ASIA CCS'21: PROCEEDINGS OF THE 2021 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2, DOI 10.1145/3433210.3437519; Kamath Aishwarya, 2018, Automated Knowledge Base Construction (AKBC); Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Li J, 2018, PROCEEDINGS OF THE 2018 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '18), P229, DOI 10.1145/3184407.3184410; Li Z, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3816; Liang B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4208; Liu Pengfei, 2021, arXiv; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Marasovic Ana, 2021, ARXIV211108284; McCarthy Philip M, 2005, An assessment of the range and usefulness of lexical diversity measures and the potential of the measure of textual, lexical diversity (MTLD); Min Y., 2021, Uncertainty in Artificial Intelligence, P129; Miyato T., 2016, Patenting software; Pang TY, 2019, PR MACH LEARN RES, V97; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pi XY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2007; Poon Hoifung, 2009, P 2009 C EMP METH NA, P1; Raghunathan A., 2019, Adversarial training can hurt generalization; Rajkumar Nitarshan, 2022, ARXIV220400498; Ramesh A, 2021, PR MACH LEARN RES, V139; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ribeiro Marco Tulio, 2018, ANN M ASS COMP LING; Ross A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3194; Roy Subhro, 2022, ARXIV220610668; Sanghi Aditya., 2022, P IEEECVF C COMPUTER, P18603; Sen Priyanka, 2020, P 1 WORKSH INT EX SE, P12; Shafahi A, 2020, AAAI CONF ARTIF INTE, V34, P5636; Shafahi A, 2019, ADV NEUR IN, V32; Shin R, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5417; Shin R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7699; Shiri Fatemeh, 2022, 2022 25 INT C INF FU, P1; Suzgun Mirac, 2022, ARXIV220511503; Szegedy Christian, 2014, ARXIV, DOI DOI 10.48550/ARXIV.1312.6199; Templin Mildred C, 1957, JSTOR, V10; Tramèr F, 2019, ADV NEUR IN, V32; WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811; Wang Ben, 2021, Gpt-j-6b: A 6 billion parameter autoregressive language model; Wu J, 2012, A data mining thinking, P1; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yi Mingyang, 2021, INT C MACHINE LEARNI, P11987; Yule G. Udny., 1944, STAT STUDY LIT VOCAB; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zhang HY, 2019, PR MACH LEARN RES, V97	67	2	2	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							1090	1102						13	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056903050
J	Venerito, V; Lalwani, D; Del Vescovo, S; Iannone, F; Gupta, L				Venerito, Vincenzo; Lalwani, Devansh; Del Vescovo, Sergio; Iannone, Florenzo; Gupta, Latika			Prompt engineering: The next big skill in rheumatology research	INTERNATIONAL JOURNAL OF RHEUMATIC DISEASES			English	Review						large language models; medical research; prompt engineering		Large language models (LLMs) like GPT-4 and Claude are catalyzing transformation across medical research including rheumatology. This review examines their applications, highlighting the pivotal role of prompt engineering in effectively guiding LLMs. Key aspects explored include literature synthesis, data analysis, manuscript drafting, coding assistance, privacy considerations, and generative artificial intelligence integrations. While LLMs accelerate workflows, reliance without apt prompting jeopardizes accuracy. By methodically constructing prompts and gauging model outputs, researchers can maximize relevance and utility. Locally run open-source models also offer data privacy protections. As LLMs permeate rheumatology research, developing expertise in strategic prompting and assessing model limitations is critical. With proper oversight, LLMs markedly boost scholarly productivity.	[Venerito, Vincenzo; Del Vescovo, Sergio; Iannone, Florenzo] Univ Bari, Polyclin Hosp, Dept Precis & Regenerat Med, Bari, Italy; [Venerito, Vincenzo; Del Vescovo, Sergio; Iannone, Florenzo] Univ Bari, Polyclin Hosp, Ionian Area DiMePRe J, Bari, Italy; [Lalwani, Devansh] Seth GS Med Coll & KEM Hosp, Mumbai, India; [Gupta, Latika] Royal Wolverhampton Trust, Dept Rheumatol, Wolverhampton WV10 0QP, England; [Gupta, Latika] Univ Manchester, Ctr Musculoskeletal Res, Sch Biol Sci, Div Musculoskeletal & Dermatol Sci, Manchester, England	Universita degli Studi di Bari Aldo Moro; Universita degli Studi di Bari Aldo Moro; Seth Gordhandas Sunderdas Medical College & King Edward Memorial Hospital; University of Manchester	Gupta, L (corresponding author), Royal Wolverhampton Trust, Dept Rheumatol, Wolverhampton WV10 0QP, England.; Gupta, L (corresponding author), Univ Manchester, Ctr Musculoskeletal Res, Sch Biol Sci, Div Musculoskeletal & Dermatol Sci, Manchester, England.	drlatikagupta@gmail.com		Iannone, Florenzo/0000-0003-0474-5344				arize, Applying large language models to tabular data. A New Approach-Arize AI; Beam AL, 2020, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2020, P295; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Chen CW, 2024, JMIR MED EDUC, V10, DOI 10.2196/48989; Garin SP, 2023, NAT MED, V29, P1038, DOI 10.1038/s41591-023-02264-0; Heston TF., 2023, Int. Med. Educ., V2, P198, DOI [DOI 10.3390/IME2030019, 10.3390/ime2030019]; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Nejjar M, 2024, Arxiv, DOI arXiv:2311.16733; Venerito V, 2024, NAT REV RHEUMATOL, V20, P75, DOI 10.1038/s41584-023-01070-9; Venerito V, 2023, RHEUMATOLOGY, V62, P3256, DOI 10.1093/rheumatology/kead291; Walter P, 2023, INT J RHEUM DIS, V26, P1019, DOI 10.1111/1756-185X.14688; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Zunic A, 2020, JMIR MED INF, V8, P34, DOI 10.2196/16023	15	0	0	10	10	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1756-1841	1756-185X		INT J RHEUM DIS	Int. J. Rheum. Dis.	MAY	2024	27	5							e15157	10.1111/1756-185X.15157	http://dx.doi.org/10.1111/1756-185X.15157			6	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	PR6H4	38720410	hybrid			2024-07-03	WOS:001215843800001
J	Lim, S; Schmälzle, R				Lim, Sue; Schmalzle, Ralf			Artificial intelligence for health message generation: an empirical study using a large language model (LLM) and prompt engineering	FRONTIERS IN COMMUNICATION			English	Article						health communication; message generation; artificial intelligence; prompt engineering; social media; folic acid (FA)	FOLIC-ACID; COMMUNICATION CAMPAIGNS; UNITED-STATES; BEHAVIOR; PREVENTION; STRATEGIES; KNOWLEDGE; AWARENESS	IntroductionThis study introduces and examines the potential of an AI system to generate health awareness messages. The topic of folic acid, a vitamin that is critical during pregnancy, served as a test case. MethodWe used prompt engineering to generate awareness messages about folic acid and compared them to the most retweeted human-generated messages via human evaluation with an university sample and another sample comprising of young adult women. We also conducted computational text analysis to examine the similarities between the AI-generated messages and human generated tweets in terms of content and semantic structure. ResultsThe results showed that AI-generated messages ranked higher in message quality and clarity across both samples. The computational analyses revealed that the AI generated messages were on par with human-generated ones in terms of sentiment, reading ease, and semantic content. DiscussionOverall, these results demonstrate the potential of large language models for message generation. Theoretical, practical, and ethical implications are discussed.	[Lim, Sue; Schmalzle, Ralf] Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA	Michigan State University	Lim, S (corresponding author), Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.	limsue@msu.edu		Lim, Sue/0000-0001-7559-1317				Ahmad FB, 2021, JAMA-J AM MED ASSOC, V325, P1829, DOI 10.1001/jama.2021.5469; Amitai Y, 2004, PREV MED, V39, P731, DOI 10.1016/j.ypmed.2004.02.042; [Anonymous], 2012, VIT B9; Armstrong J. S., 2010, Persuasive Advertising; Atkin C., 2008, An integrated approach to communication theory; Baclic Oliver, 2020, Can Commun Dis Rep, V46, P161, DOI 10.14745/ccdr.v46i06a02; Bechtel W, 2008, PHILOS SCI, V75, P983, DOI 10.1086/594540; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; BETTINGHAUS EP, 1986, PREV MED, V15, P475, DOI 10.1016/0091-7435(86)90025-3; Blei D. M., 2012, DIGIT HUMANIT Q; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; CDC, 2022, FOL AC; Chalmers A., 2013, WHAT IS THIS THING C; Chan AKM, 2020, ANAESTHESIA, V75, P1579, DOI 10.1111/anae.15057; Chen XY, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.580632; Cho H., 2011, HLTH COMMUNICATION M; Chollet F., 2021, Deep Learning with Python, Second Edition; Contractor D, 2020, Arxiv, DOI arXiv:2011.03116; Craver C., 2013, SEARCH MECH DISCOVER, DOI [DOI 10.7208/CHICAGO/9780226039824.001.0001, 10.7208/chicago/9780226039824.001.0001]; Crowson K., 2022, ARXIV; De Rosario Helios, 2020, CRAN; DellaVigna S, 2010, ANNU REV ECON, V2, P643, DOI 10.1146/annurev.economics.102308.124309; DeWilde B., 2020, Textacy: Nlp, before and after spacy; Dmochowski JP, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5567; Dubova M, 2022, COGN SYST RES, V72, P63, DOI 10.1016/j.cogsys.2021.12.002; Fan AEL, 2018, Arxiv, DOI arXiv:1805.04833; Feiyu Xu, 2019, Natural Language Processing and Chinese Computing. 8th CCF International Conference, NLPCC 2019. Proceedings. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 11839), P563, DOI 10.1007/978-3-030-32236-6_51; Flesch R., 1946, The art of plain talk; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477; Geisel J, 2003, J PERINAT NEONAT NUR, V17, P268, DOI 10.1097/00005237-200310000-00005; Gelernter D., 2010, The muse in the machine: Computerizing the poetry of human thought; Giles J, 2011, NATURE, V470, P18, DOI 10.1038/470018a; Githuku JN, 2014, PAN AFR MED J, V18, DOI 10.11604/pamj.2014.18.60.4070; Gomes S, 2016, PUBLIC HEALTH NUTR, V19, P176, DOI 10.1017/S1368980015000555; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gough Aisling, 2017, JMIR Public Health Surveill, V3, pe14, DOI 10.2196/publichealth.6313; Green-Raleigh K, 2006, MATERN CHILD HLTH J, V10, pS177, DOI 10.1007/s10995-006-0104-0; Greene J. O., 2013, Message production: Advances in communication theory; Greenwald AG, 2012, PERSPECT PSYCHOL SCI, V7, P99, DOI 10.1177/1745691611434210; Grün B, 2011, J STAT SOFTW, V40, P1; Hancock JT, 2020, J COMPUT-MEDIAT COMM, V25, P89, DOI 10.1093/jcmc/zmz022; Harrington N.G., 2016, Oxford Research Encyclopedia of Communication, DOI 10.1093/acrefore/9780190228613.013.7; Harrington NG, 2015, HEALTH COMMUN, V30, P103, DOI 10.1080/10410236.2014.974133; Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Hodgkinson GP, 2008, BRIT J PSYCHOL, V99, P1, DOI 10.1348/000712607X216666; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Huskey R, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.565973; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Karinshak Elise, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579592; Kim HS, 2015, J COMMUN, V65, P512, DOI 10.1111/jcom.12160; Kim M, 2019, J HEALTH COMMUN, V24, P761, DOI 10.1080/10810730.2019.1668090; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Lapinski MK, 2005, COMMUN THEOR, V15, P127, DOI 10.1111/j.1468-2885.2005.tb00329.x; Laurencon H., 2022, ADV NEURAL INFORM PR, P31809; Lee EWJ, 2024, HEALTH COMMUN, V39, P493, DOI 10.1080/10410236.2023.2170201; Lin ZY, 2021, Arxiv, DOI arXiv:2104.04039; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Marcus G, 2019, Rebooting AI: Building Artificial Intelligence We Can Trust; McGuire W.J., 2001, PUBLIC COMMUNICATION, V3, P22, DOI DOI 10.4135/9781452233260.N2; Medawar G, 2019, ANN GLOB HEALTH, V85, DOI 10.5334/aogh.2396; MILLER G, 1977, COMMUN MONOGR, V44, P37, DOI 10.1080/03637757709390113; Misri I., 2021, SET SAMPLING TEMPERA; Mitchell M., 2019, ARTIFICIAL INTELLIGE; Mokdad AH, 2004, JAMA-J AM MED ASSOC, V291, P1238, DOI 10.1001/jama.291.10.1238; Montani Ines, 2023, Zenodo; Morse A., 2022, Stable Fertility Rates 1990-2019 Mask Distinct Variations by Age; Nabi RL, 2020, COMMUN RES, V47, P1107, DOI 10.1177/0093650219861256; Noar SM, 2007, PSYCHOL BULL, V133, P673, DOI 10.1037/0033-2909.133.4.673; O'Keefe D. J., 2002, PERSUASION THEORY RE; O'Keefe DJ, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.664160; Palan S, 2018, J BEHAV EXP FINANC, V17, P22, DOI 10.1016/j.jbef.2017.12.004; Pei R, 2019, AM J PREV MED, V56, pS40, DOI 10.1016/j.amepre.2018.07.044; PETTY RE, 1984, ADV CONSUM RES, V11, P668; Rains SA, 2020, HEALTH COMMUN, V35, P26, DOI 10.1080/10410236.2018.1536955; Rashkin H, 2020, Arxiv, DOI arXiv:2004.14967; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rhodes N., 2013, The SAGE Handbook of Persuasion: Developments in Theory and Practice, P53; Rice R. E., 2012, Public Communication Campaigns; Rofail D, 2012, J PUBLIC HEALTH-UK, V34, P90, DOI 10.1093/pubmed/fdr048; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schmalzle R., 2017, POLICY INSIGHTS BEHA, V4, P163, DOI DOI 10.1177/2372732217720223; Schmälzle R, 2022, J MED INTERNET RES, V24, DOI 10.2196/28858; Schmälzle R, 2020, COMMUN METHODS MEAS, V14, P105, DOI 10.1080/19312458.2019.1708283; Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003; Scholl TO, 2000, AM J CLIN NUTR, V71, p1295S, DOI 10.1093/ajcn/71.5.1295s; Shi JY, 2018, HEALTH COMMUN, V33, P49, DOI 10.1080/10410236.2016.1242035; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Snscrape, 2021, SNSCRAP SOC NETW SER; Snyder LB, 2007, J NUTR EDUC BEHAV, V39, pS32, DOI 10.1016/j.jneb.2006.09.004; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Tan CH, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P613, DOI 10.1145/2872427.2883081; Thackeray R, 2008, HEALTH PROMOT PRACT, V9, P338, DOI 10.1177/1524839908325335; Theron D., 2022, GETTING STARTED BLOO; Thompson T. L., 2021, The Routledge handbook of health communication; Tunstall L., 2022, Natural Language Processing with Transformers; Turner M, 2021, COMMUN STUD, V72, P684, DOI 10.1080/10510974.2021.1953094; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; von Platen Patrick, 2020, How to generate text: using different decoding methods for language generation with Transformers; von Werra L., 2020, Trl: Transformer reinforcement learning; Wang XB, 2007, LANCET, V369, P1876, DOI 10.1016/S0140-6736(07)60854-X; Wang XH, 2019, COMPUT HUM BEHAV, V93, P149, DOI 10.1016/j.chb.2018.12.024; Weber R, 2018, COMMUN MONOGR, V85, P81, DOI 10.1080/03637751.2017.1395059; Wicks P, 2014, AMYOTROPH LAT SCL FR, V15, P479, DOI 10.3109/21678421.2014.984725; Willoughby JF, 2022, J HEALTH COMMUN, V27, P362, DOI 10.1080/10810730.2022.2110627; Witte K., 2001, EFFECTIVE HLTH RISK, P65, DOI https://doi.org/10.1002/tqem.3310070208; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yang JH, 2023, HEALTH COMMUN, V38, P925, DOI 10.1080/10410236.2021.1982561; Yeomans M., 2019, R J, DOI [10.32614/RJ-2018-079, DOI 10.32614/RJ-2018-079]; Zhou S, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231155679	114	11	11	30	80	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2297-900X		FRONT COMMUN	Front. Commun.	MAY 26	2023	8								1129082	10.3389/fcomm.2023.1129082	http://dx.doi.org/10.3389/fcomm.2023.1129082			15	Communication	Emerging Sources Citation Index (ESCI)	Communication	I5HL1		gold			2024-07-03	WOS:001003088700001
J	Li, JK; Hu, JP; Zhang, G				Li, Jiakai; Hu, Jianpeng; Zhang, Geng			Enhancing Relational Triple Extraction in Specific Domains: Semantic Enhancement and Synergy of Large Language Models and Small Pre-Trained Language Models	CMC-COMPUTERS MATERIALS & CONTINUA			English	Article						Relational triple extraction; semantic interaction; large language models; data augmentation; specific domains		In the process of constructing domain-specific knowledge graphs, the task of relational triple extraction plays a critical role in transforming unstructured text into structured information. Existing relational triple extraction models face multiple challenges when processing domain-specific data, including insufficient utilization of semantic interaction information between entities and relations, difficulties in handling challenging samples, and the scarcity of domain-specific datasets. To address these issues, our study introduces three innovative components: Relation semantic enhancement, data augmentation, and a voting strategy, all designed to significantly improve the model's performance in tackling domain-specific relational triple extraction tasks. We first propose an innovative attention interaction module. This method significantly enhances the semantic interaction capabilities between entities and relations by integrating semantic information from relation labels. Second, we propose a voting strategy that effectively combines the strengths of large language models (LLMs) and fine-tuned small pre-trained language models (SLMs) to reevaluate challenging samples, thereby improving the model's adaptability in specific domains. Additionally, we explore the use of LLMs for data augmentation, aiming to generate domain-specific datasets to alleviate the scarcity of domain data. Experiments conducted on three domain-specific datasets demonstrate that our model outperforms existing comparative models in several aspects, with F1 scores exceeding the State of the Art models by 2%, 1.6%, and 0.6%, respectively, validating the effectiveness and generalizability of our approach.	[Li, Jiakai; Hu, Jianpeng; Zhang, Geng] Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China	Shanghai University of Engineering Science	Hu, JP (corresponding author), Shanghai Univ Engn Sci, Sch Elect & Elect Engn, Shanghai 201620, Peoples R China.	mr@sues.edu.cn			Science and Technology Innovation 2030-Major Project of "New Generation Artificial Intelligence" - Ministry of Science and Technology [2020AAA0109300]	Science and Technology Innovation 2030-Major Project of "New Generation Artificial Intelligence" - Ministry of Science and Technology	This research was funded by Science and Technology Innovation 2030-Major Project of "New Generation Artificial Intelligence" granted by Ministry of Science and Technology, Grant Number 2020AAA0109300.	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chan Y. S., 2011, P 49 ANN M ASS COMPU, P551; Chiang CH, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15607; Chung JJY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P575; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Di Palma D, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1369, DOI 10.1145/3604915.3608889; Ding BS, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11173; Eberts M, 2020, FRONT ARTIF INTEL AP, V325, P2006, DOI 10.3233/FAIA200321; Feng SY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P968; Gupta P., 2016, PROC COLING 26 INT C, P2537; Huang X, 2022, P COLING GYEONGJ KOR, P2418; Katiyar A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P917, DOI 10.18653/v1/P17-1085; Li Q, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P402, DOI 10.3115/v1/p14-1038; Li XM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8055; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Ma Y., 2023, FINDINGS ASS COMPUTA, P10572; Mahapatra A., 2022, P EMNLP AB DHAB UN A, P942; Martínez-Cruz R, 2023, Arxiv, DOI arXiv:2304.14177; Ning JZ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11120; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng CY, 2023, ARTIF INTELL REV, V56, P13071, DOI 10.1007/s10462-023-10465-9; Qin C., 2023, P 2023 C EMPIRICAL M, P1339; Ren FL, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P824, DOI 10.1145/3488560.3498409; Roth D., 2004, P CONLL 2004 BOST MA, P1; Shang YM, 2022, AAAI CONF ARTIF INTE, P11285; Shen YL, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1704, DOI 10.1145/3442381.3449895; Sun W, 2023, P 2023 C EMPIRICAL M, P14918; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Tang W., 2022, P 2022 C EMPIRICAL M, P7087; Wang Y., 2020, PROC 28 INT C COMPUT, P1572, DOI DOI 10.18653/V1/2020.COLING-MAIN.138; Wang YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P220; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Wei ZP, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1476; Xu BF, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P659; Yan J., 2023, P AAAI C ART INT, V37, P10720; Yang P., 2021, P EMNLP PUNT CAN DOM, P4623; Ye DM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4904; Ye W, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1351; Yu Y, 2023, Advances Neural Inform. Process. Syst., V36, DOI [10.48550/arXiv.2306.15895, DOI 10.48550/ARXIV.2306.15895]; Yuan L, 2023, P AAAI C ART INT, V37, P11051; Zelenko D, 2003, J MACH LEARN RES, V3, P1083, DOI 10.1162/153244303322533205; Zeng XR, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P506; Zhang X., 2022, P COLING GYEONGJ KOR, P2398; Zheng H, 2021, PROC 59 ANN M ASS CO, P6225; Zheng SC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1227, DOI 10.18653/v1/P17-1113; Zhong ZX, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P50	46	0	0	0	0	TECH SCIENCE PRESS	HENDERSON	871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA	1546-2218	1546-2226		CMC-COMPUT MATER CON	CMC-Comput. Mat. Contin.		2024	79	2								10.32604/cmc.2024.050005	http://dx.doi.org/10.32604/cmc.2024.050005			23	Computer Science, Information Systems; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Materials Science	TX5J2					2024-07-03	WOS:001244568300025
J	Fernandez, RC; Elmore, AJ; Franklin, MJ; Krishnan, S; Tan, CH				Fernandez, Raul Castro; Elmore, Aaron J.; Franklin, Michael J.; Krishnan, Sanjay; Tan, Chenhao			How Large Language Models Will Disrupt Data Management	PROCEEDINGS OF THE VLDB ENDOWMENT			English	Article; Proceedings Paper	49th International Conference on Very Large Data Bases (VLDB)	AUG 28-SEP 01, 2023	Vancouver, CANADA				EXTRACTION; CODE; WEB	Large language models (LLMs), such as GPT-4, are revolutionizing software's ability to understand, process, and synthesize language. The authors of this paper believe that this advance in technology is significant enough to prompt introspection in the data management community, similar to previous technological disruptions such as the advents of the world wide web, cloud computing, and statistical machine learning. We argue that the disruptive influence that LLMs will have on data management will come from two angles. (1) A number of hard database problems, namely, entity resolution, schema matching, data discovery, and query synthesis, hit a ceiling of automation because the system does not fully understand the semantics of the underlying data. Based on large training corpora of natural language, structured data, and code, LLMs have an unprecedented ability to ground database tuples, schemas, and queries in real-world concepts. We will provide examples of how LLMs may completely change our approaches to these problems. (2) LLMs blur the line between predictive models and information retrieval systems with their ability to answer questions. We will present examples showing how large databases and information retrieval systems have complementary functionality.	[Fernandez, Raul Castro; Elmore, Aaron J.; Franklin, Michael J.; Krishnan, Sanjay; Tan, Chenhao] Univ Chicago, Chicago, IL 60637 USA	University of Chicago	Fernandez, RC (corresponding author), Univ Chicago, Chicago, IL 60637 USA.	raulf@uchicago.edu; aelmore@uchicago.edu; mjfranklin@uchicago.edu; skr@uchicago.edu; chenhao@uchicago.edu		Franklin, Michael/0009-0005-0310-4803				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, Survey: Massive Retooling Around Large Language Models Underway; [Anonymous], 2023, CONFIRMED NEW BING R; [Anonymous], 2022, A slight-less-magical perspective into autoregressive language modeling: count, compress and prune; [Anonymous], 2023, Alpaca: A Strong, Replicable Instruction-Following Model; Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34; Bielik Pavol, 2015, 1 SUMMIT ADV PROGRAM; Borisov V, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3229161; Boyle JE, 1925, ECON J, V35, P11, DOI 10.2307/2222576; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cafarella MJ, 2009, PROC VLDB ENDOW, V2; Cafarella MJ, 2008, SIGMOD REC, V37, P55, DOI 10.1145/1519103.1519112; Cappuzzo Riccardo, 2021, 29 ITALIAN S ADV DAT; Chamberlin DD, 2012, IEEE ANN HIST COMPUT, V34, P78, DOI 10.1109/MAHC.2012.61; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828; Cordonnier JB, 2020, Arxiv, DOI arXiv:1911.03584; De Sa C, 2016, SIGMOD REC, V45, P60, DOI [10.1145/2949741.2949756, 10.1145/3060586]; Deng X, 2020, PROC VLDB ENDOW, V14, P307, DOI 10.14778/3430915.3430921; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doan A, 2012, PRINCIPLES OF DATA INTEGRATION, P1; Doan A, 2005, AI MAG, V26, P83; Dong XL, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2869, DOI 10.1145/3219819.3219938; Dufter P, 2022, COMPUT LINGUIST, V48, P733, DOI 10.1162/coli_a_00445; Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001; Fernandez RC, 2018, PROC INT CONF DATA, P1001, DOI 10.1109/ICDE.2018.00094; Getoor L, 2007, Introduction to Statistical Relational Learning; Green Todd J., 2007, P 26 ACM SIGMOD SIGA, P31, DOI DOI 10.1145/1265530.1265535; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gulwani S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI 10.1145/1925844.1926423; Halevy A., 2006, P 32 INT C VER LARG, P9; Hill L.D., 2021, Grain Marketing, P121; Howard Jeremy, 2018, Now anyone can train imagenet in 18 minutes; HULL R, 1987, COMPUT SURV, V19, P201, DOI 10.1145/45072.45073; Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073; John R.J. L., 2017, CIDR; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kazemitabaar Majeed, 2023, P 2023 CHI C HUMAN F, P1; Kiciman E, 2023, Arxiv, DOI arXiv:2305.00050; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Li F, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P709, DOI 10.1145/2588555.2594519; Li YL, 2020, Arxiv, DOI arXiv:2004.00584; Liu NF, 2023, Arxiv, DOI arXiv:2304.09848; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Madhavan J., 2007, WEB SCALE DATA INTEG; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Miao Xupeng, 2022, arXiv; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Narayan A, 2022, Arxiv, DOI arXiv:2205.09911; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Niu F, 2012, VLDS, V12, P25; Paparrizos J, 2022, PROC INT CONF DATA, P2969, DOI 10.1109/ICDE53745.2022.00268; Posner Eric A., 2018, RADICAL MARKETS; Schuhmann C., 2022, arXiv; Shin J, 2015, PROC VLDB ENDOW, V8, P1310, DOI 10.14778/2809974.2809991; Suciu D., 2011, Synthesis lectures on data management, V3, P1, DOI [10.2200/s00362ed1v01y201105dtm016, DOI 10.2200/S00362ED1V01Y201105DTM016]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trummer I, 2022, PROC VLDB ENDOW, V15, P2921, DOI 10.14778/3551793.3551841; Trummer I, 2022, INT CONF MANAGE DATA, P190, DOI 10.1145/3514221.3517843; Trummer I, 2021, PROC VLDB ENDOW, V14, P1159, DOI 10.14778/3450980.3450984; Um T, 2023, PROC VLDB ENDOW, V16, P1086, DOI 10.14778/3579075.3579083; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS; Vanschoren J., 2013, SIGKDD EXPLORATIONS, V15, P49, DOI [DOI 10.1145/2641190.2641198, 10.1145/2641190.2641198]; Vartak M, 2018, INT CONF MANAGE DATA, P1285, DOI 10.1145/3183713.3196934; Vaswani A, 2017, ADV NEUR IN, V30; Vincent N, 2019, Arxiv, DOI arXiv:1912.00757; Wang QM, 2023, Arxiv, DOI arXiv:2301.03560; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Weikum G, 2021, PROC VLDB ENDOW, V14, P3233, DOI 10.14778/3476311.3476393; Weikum G, 2021, FOUND TRENDS DATABAS, V10, P108, DOI 10.1561/1900000064; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Yin PC, 2020, Arxiv, DOI arXiv:2005.08314; Zhang D., 2019, arXiv; Zhang MR, 2023, Arxiv, DOI arXiv:2305.13534; Zhang Z, 2022, Arxiv, DOI arXiv:2205.00119; Zhao YL, 2023, Arxiv, DOI [arXiv:2304.11277, 10.14778/3611540.3611569]; Zhao ZX, 2022, INT CONF MANAGE DATA, P1504, DOI 10.1145/3514221.3517891; Zuboff S, 2015, J INF TECHNOL-UK, V30, P75, DOI 10.1057/jit.2015.5	80	4	4	9	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2150-8097			PROC VLDB ENDOW	Proc. VLDB Endow.	JUL	2023	16	11					3302	3309						8	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	Q7GX8					2024-07-03	WOS:001059181900049
J	Jeon, J; Lee, S; Choe, H				Jeon, Jaeho; Lee, Seongyong; Choe, Hohsung			Beyond ChatGPT: A conceptual framework and systematic review of speech-recognition chatbots for language learning	COMPUTERS & EDUCATION			English	Review						Chatbot; Large language model; Automatic speech recognition; Affordance; Computer-assisted language learning	INTELLIGENT PERSONAL ASSISTANTS; LEARNERS WILLINGNESS; CONVERSATIONAL AGENT; SPEAKING; AFFORDANCES; DIALOGUE; BEHAVIOR; DESIGN; ROBOTS; BOTS	The diversification of chatbot technology, such as the emergence of large language models and their incorporation into various technologies, necessitates a conceptual framework for a comprehensive understanding of different chatbot types and their possibilities for educational use. However, despite the fact that chatbots with different characteristics can provide learners with different interaction experiences, previous research has drawn on a loose conceptualization of chatbots, ignoring the common or unique design features of different chatbots and the educational affordances that are provided accordingly. In response to this concern, this review aims to further our understanding of different types of speech-recognition chatbots for language learning and the affordances provided by the chatbots. Based on an analysis of 37 empirical studies on uses of chatbots ranging from those with predefined dialogue systems to those utilizing artificial intelligence technology, this review proposes a conceptual framework that comprises three key components of a chatbot system: goal-orientation, embodiment, and multimodality. Using this framework as an analytical tool, eight chatbot types are identified and defined. Additionally, a total of 12 affordances are derived from the presence and absence of each component of the framework. Analysis of the studies through the framework also offers specific insights into how future chatbot research and development should be pursued in terms of goalorientation, embodiment, and multimodality. Finally, we discuss the potential of the framework as a relevant model for understanding chatbots in adjacent disciplines and types other than speech-recognition chatbots, including ChatGPT and other large language models.	[Jeon, Jaeho] Indiana Univ Bloomington, Dept Literacy Culture & Language Educ, 201 N Rose Ave, Bloomington, IN 47405 USA; [Lee, Seongyong] Hannam Univ, Dept English Educ, 70 Hannam Ro, Daejeon 34430, South Korea; [Choe, Hohsung] Hankuk Univ Foreign Studies, Dept TESOL & English Linguist, 81 Oedae Ro, Yongin 17035, Gyeonggi Do, South Korea	Indiana University System; Indiana University Bloomington; Hannam University; Hankuk University Foreign Studies	Lee, S (corresponding author), Hannam Univ, Dept English Educ, 70 Hannam Ro, Daejeon 34430, South Korea.	jaehojeon21@gmail.com; seongyonglee77@gmail.com		Choe, Hohsung/0000-0002-4355-595X; Lee, Seongyong/0000-0002-9436-4272				Ahn SY, 2018, APPL LINGUIST REV, V9, P225, DOI 10.1515/applirev-2016-1064; Ayedoun E, 2020, IEEE T LEARN TECHNOL, V13, P604, DOI 10.1109/TLT.2020.2989776; Ayedoun E, 2019, INT J ARTIF INTELL E, V29, P29, DOI 10.1007/s40593-018-0171-6; Bibauw S, 2022, LANG LEARN TECHNOL, V26; Bibauw S, 2019, COMPUT ASSIST LANG L, V32, P827, DOI 10.1080/09588221.2018.1535508; Booton SA, 2023, COMPUT ASSIST LANG L, V36, P400, DOI 10.1080/09588221.2021.1930057; Bower M, 2015, COMPUT EDUC, V88, P343, DOI 10.1016/j.compedu.2015.07.013; Bower M, 2008, EDUC MEDIA INT, V45, P3, DOI 10.1080/09523980701847115; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Chen HHJ, 2023, INTERACT LEARN ENVIR, V31, P1335, DOI 10.1080/10494820.2020.1833043; Chien YC, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.785752; Choi S, 2023, INT J HUM-COMPUT INT, V39, P910, DOI 10.1080/10447318.2022.2049145; Coniam D, 2014, TEXT TALK, V34, P545, DOI 10.1515/text-2014-0018; Davis RO, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103605; Desmet PMA, 2009, INT J DES, V3, P1; Divekar RR, 2022, COMPUT ASSIST LANG L, V35, P2332, DOI 10.1080/09588221.2021.1879162; Dizon G., 2022, COMPUTERS ED ARTIFIC, V3; Dizon G., 2020, The JALT CALL Journal, V16, P107, DOI [DOI 10.29140/JALTCALL.V16N2.273, 10.29140/jaltcall.v16n2.273]; Dizon G, 2020, LANG LEARN TECHNOL, V24, P16; Dizon G, 2017, TESOL J, V8, P811, DOI 10.1002/tesj.353; Ebadi S, 2024, INTERACT LEARN ENVIR, V32, P655, DOI 10.1080/10494820.2022.2096638; El Shazly R, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12667; Forsyth CM, 2019, COMPUT ASSIST LANG L, V32, P398, DOI 10.1080/09588221.2018.1517126; Fryer L, 2006, LANG LEARN TECHNOL, V10, P8; Fryer LK, 2020, LANG LEARN TECHNOL, V24, P8; Fryer LK, 2019, COMPUT HUM BEHAV, V93, P279, DOI 10.1016/j.chb.2018.12.023; Fryer LK, 2017, COMPUT HUM BEHAV, V75, P461, DOI 10.1016/j.chb.2017.05.045; GIBSON JJ, 1979, ECOLOGICAL APPROACH; Gonulal T, 2023, INTERACT LEARN ENVIR, V31, P4521, DOI 10.1080/10494820.2021.1974489; Harless W. G., 1999, CALICO Journal, V16, P313; Hassani K, 2016, INTERACT LEARN ENVIR, V24, P252, DOI 10.1080/10494820.2013.846265; Hsu HL, 2023, INTERACT LEARN ENVIR, V31, P5732, DOI 10.1080/10494820.2021.2016864; Hsu MH, 2023, INTERACT LEARN ENVIR, V31, P4297, DOI 10.1080/10494820.2021.1960864; Huang WJ, 2022, J COMPUT ASSIST LEAR, V38, P237, DOI 10.1111/jcal.12610; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Hwang WY, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2095406; Hwang Y, 2023, COMPUT EDUC, V194, DOI 10.1016/j.compedu.2022.104693; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Jeon J, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2204343; Jeon J, 2022, COMPUT EDUC, V190, DOI 10.1016/j.compedu.2022.104620; Jeon J, 2022, EDUC INF TECHNOL, V27, P5767, DOI 10.1007/s10639-021-10839-y; Jeon J, 2024, COMPUT ASSIST LANG L, V37, P1, DOI 10.1080/09588221.2021.2021241; Jeon J, 2023, COMPUT ASSIST LANG L, V36, P1338, DOI 10.1080/09588221.2021.1987272; Ji H, 2023, J RES TECHNOL EDUC, V55, P48, DOI 10.1080/15391523.2022.2142873; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Koehler Matthew J., 2009, Contemporary Issues in Technology and Teacher Education, V9, P60; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Lee S, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2067182; Li J, 2015, INT J HUM-COMPUT ST, V77, P23, DOI 10.1016/j.ijhcs.2015.01.001; Li KC, 2020, EDUC SCI, V10, DOI 10.3390/educsci10110306; Lin CJ, 2021, EDUC TECHNOL SOC, V24, P16; Liu CC, 2022, COMPUT EDUC, V189, DOI 10.1016/j.compedu.2022.104576; Mayer RE, 2017, J COMPUT ASSIST LEAR, V33, P403, DOI 10.1111/jcal.12197; Mayer R. E., 2001, Multimedia learning, DOI DOI 10.1017/CBO9781139164603; Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005; Morton Hazel, 2011, Journal of Multimedia, V6, P436, DOI 10.4304/jmm.6.5.436-446; Morton H., 2005, Computer Assisted Language Learning, V18, P171, DOI 10.1080/09588220500173344; Morton H, 2010, COMPUT ASSIST LANG L, V23, P295, DOI 10.1080/09588221.2010.493524; Moussalli S, 2020, COMPUT ASSIST LANG L, V33, P865, DOI 10.1080/09588221.2019.1595664; Na-Young Kim, 2019, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V22, P32; Neuman W.L., 2011, Social Research Methods: qualitative and quantitative approaches; Norman Donald A., 1988, The Psychology of Everyday Things; Ockey GJ, 2021, APPL LINGUIST, V42, P924, DOI 10.1093/applin/amaa067; OpenAI, 2023, GPT-4; Papadopoulos I, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103924; Rietveld E, 2014, ECOL PSYCHOL, V26, P325, DOI 10.1080/10407413.2014.958035; Ruck J, 2022, LANG LEARN J, V50, P328, DOI 10.1080/09571736.2020.1752291; Shadiev R, 2023, RECALL, V35, P74, DOI 10.1017/S095834402200012X; Shalmani H. B., 2021, Computer Assisted Language Learning Electronic Journal, V22, P133; Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862; Sydorenko T, 2010, LANG LEARN TECHNOL, V14, P50; Tai TY, 2023, INTERACT LEARN ENVIR, V31, P1485, DOI 10.1080/10494820.2020.1841801; Tai TY, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2075013; Tai TY, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2070219; Tegos S, 2014, INT J ARTIF INTELL E, V24, P62, DOI 10.1007/s40593-013-0007-3; Timpe-Laughlin V, 2024, COMPUT ASSIST LANG L, V37, P149, DOI 10.1080/09588221.2022.2032184; Timpe-Laughlin V, 2022, COMPUT ASSIST LANG L, V35, P1194, DOI 10.1080/09588221.2020.1774904; Timpe-Laughlin V, 2020, INTERCULT PRAGMAT, V17, P221, DOI 10.1515/ip-2020-0010; Tondeur J, 2012, COMPUT EDUC, V59, P134, DOI 10.1016/j.compedu.2011.10.009; Tai TY, 2024, COMPUT ASSIST LANG L, V37, P433, DOI 10.1080/09588221.2022.2040536; van den Berghe R, 2019, REV EDUC RES, V89, P259, DOI 10.3102/0034654318821286; van Doremalen J, 2016, COMPUT ASSIST LANG L, V29, P833, DOI 10.1080/09588221.2016.1167090; Wang XH, 2024, COMPUT ASSIST LANG L, V37, P814, DOI 10.1080/09588221.2022.2056203; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Withagen R, 2012, NEW IDEAS PSYCHOL, V30, P250, DOI 10.1016/j.newideapsych.2011.12.003; Xu Y, 2022, CHILD DEV, V93, pE149, DOI 10.1111/cdev.13708; Xu Y, 2021, COMPUT EDUC, V161, DOI 10.1016/j.compedu.2020.104059; Yang H, 2022, RECALL, V34, P327, DOI 10.1017/S0958344022000039; Zhang RF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2220374; Zhang RF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2202704; Zhang RF, 2022, COMPUT ASSIST LANG L, V35, P2391, DOI 10.1080/09588221.2021.1880441; Zhang Y., 2023, Universal speech model (USM): State-of-the-art speech AI for 100+ languages	93	21	21	120	257	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-1315	1873-782X		COMPUT EDUC	Comput. Educ.	DEC	2023	206								104898	10.1016/j.compedu.2023.104898	http://dx.doi.org/10.1016/j.compedu.2023.104898		AUG 2023	21	Computer Science, Interdisciplinary Applications; Education & Educational Research	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Education & Educational Research	S3WK3					2024-07-03	WOS:001070504300001
J	Wang, YQ; Zuo, JM; Duan, C; Peng, H; Huang, J; Zhao, L; Zhang, L; Dong, ZQ				Wang, Yiqi; Zuo, Jinmei; Duan, Chao; Peng, Hao; Huang, Jia; Zhao, Liang; Zhang, Li; Dong, Zhiqiang			Large language models assisted multi-effect variants mining on cerebral cavernous malformation familial whole genome sequencing	COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL			English	Article						Whole genome sequencing; Cerebral cavernous malformation; Deep learning; Large language model; Natural language processing	DIFFERENTIATION; ASSOCIATION; MUTATION; SYSTEM; GENES; FGF1	Cerebral cavernous malformation (CCM) is a polygenic disease with intricate genetic interactions contributing to quantitative pathogenesis across multiple factors. The principal pathogenic genes of CCM, specifically KRIT1, CCM2, and PDCD10, have been reported, accompanied by a growing wealth of genetic data related to mutations. Furthermore, numerous other molecules associated with CCM have been unearthed. However, tackling such massive volumes of unstructured data remains challenging until the advent of advanced large language models. In this study, we developed an automated analytical pipeline specialized in single nucleotide variants (SNVs) related biomedical text analysis called BRLM. To facilitate this, BioBERT was employed to vectorize the rich information of SNVs, while a deep residue network was used to discriminate the classes of the SNVs. BRLM was initially constructed on mutations from 12 different types of TCGA cancers, achieving an accuracy exceeding 99%. It was further examined for CCM mutations in familial sequencing data analysis, highlighting an upstream master regulator gene fibroblast growth factor 1 (FGF1). With multi-omics characterization and validation in biological function, FGF1 demonstrated to play a significant role in the development of CCMs, which proved the effectiveness of our model. The BRLM web server is available at http://1.117.230.196.	[Wang, Yiqi; Duan, Chao; Dong, Zhiqiang] Huazhong Agr Univ, Coll Biomed & Hlth, Coll Life Sci & Technol, 1 Shizishan St, Wuhan 430070, Hubei, Peoples R China; [Wang, Yiqi; Duan, Chao; Peng, Hao; Zhang, Li; Dong, Zhiqiang] Hubei Univ Med, Taihe Hosp, Ctr Neurol Dis Res, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China; [Peng, Hao; Zhang, Li] Hubei Univ Med, Taihe Hosp, Dept Neurosurg, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China; [Wang, Yiqi; Zhao, Liang] Hubei Univ Med, Taihe Hosp, Precis Med Res Ctr, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China; [Zuo, Jinmei] Hubei Univ Med, Taihe Hosp, Phys Examinat Ctr, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China; [Huang, Jia] Lanzhou Univ, Clin Med Coll 2, 222 South Tianshui Rd, Lanzhou 730030, Gansu, Peoples R China	Huazhong Agricultural University; Hubei University of Medicine; Hubei University of Medicine; Hubei University of Medicine; Hubei University of Medicine; Lanzhou University	Dong, ZQ (corresponding author), Huazhong Agr Univ, Coll Biomed & Hlth, Coll Life Sci & Technol, 1 Shizishan St, Wuhan 430070, Hubei, Peoples R China.; Zhang, L; Dong, ZQ (corresponding author), Hubei Univ Med, Taihe Hosp, Ctr Neurol Dis Res, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China.; Zhao, L (corresponding author), Hubei Univ Med, Taihe Hosp, Precis Med Res Ctr, 32 Renmin South Rd, Shiyan 442000, Hubei, Peoples R China.	s080011@e.ntu.edu.sg; zhanglith@163.com; dongz@mail.hzau.edu.cn		Yiqi, Wang/0000-0001-9332-2292; Dong, Zhiqiang/0000-0001-6259-915X	Foundation of China [32070973, 32060150]	Foundation of China	This research was funded by the National Natural ScienceFoundation of China (32070973 and 32060150) .r Foundation of China (32070973 and 32060150) .	Adler DA, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/19962; Afzal S, 2021, J NETW SYST MANAG, V29, DOI 10.1007/s10922-021-09587-8; Ahir BK, 2020, MOL NEUROBIOL, V57, P2461, DOI 10.1007/s12035-020-01892-8; Lopez-Ramirez MA, 2021, J CLIN INVEST, V131, DOI 10.1172/JCI139570; Atkinson E, 2023, BIOORGAN MED CHEM, V90, DOI 10.1016/j.bmc.2023.117368; Bathke J, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04317-y; Bommasani R., 2020, P 58 ANN M ASS COMP, P4758, DOI DOI 10.18653/V1/2020.ACL-MAIN.431; Cavalcanti DD, 2012, J NEUROSURG, V116, P122, DOI 10.3171/2011.8.JNS101241; Chen BX, 2020, NEUROLOGY, V95, pE89, DOI 10.1212/WNL.0000000000009730; Chen SF, 2018, BIOINFORMATICS, V34, P884, DOI 10.1093/bioinformatics/bty560; Cui H, 2023, bioRxiv; de Vos IJHM, 2017, AM J MED GENET A, V173, P338, DOI 10.1002/ajmg.a.38028; Delaneau O, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4934; Devlin J., arXiv; Frazer KA, 2007, NATURE, V449, P851, DOI 10.1038/nature06258; Gasser E, 2022, NAT METAB, V4, P663, DOI 10.1038/s42255-022-00580-2; Glusman G, 2011, BIOINFORMATICS, V27, P3216, DOI 10.1093/bioinformatics/btr540; Gu ZG, 2023, GENOM PROTEOM BIOINF, V21, P190, DOI 10.1016/j.gpb.2022.04.008; Hariri RH, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0206-3; Hashimoto T, 2001, CIRC RES, V89, P111, DOI 10.1161/hh1401.094281; Hatva E, 1996, J NEUROPATH EXP NEUR, V55, P1124, DOI 10.1097/00005072-199611000-00003; Hernandez FG, 2021, Wellcome Open Res, V6; Hirschi KK, 1998, J CELL BIOL, V141, P805, DOI 10.1083/jcb.141.3.805; Ionita-Laza I, 2016, NAT GENET, V48, P214, DOI 10.1038/ng.3477; Karczewski KJ, 2020, NATURE, V581, P434, DOI 10.1038/s41586-020-2308-7; Landrum MJ, 2020, NUCLEIC ACIDS RES, V48, pD835, DOI 10.1093/nar/gkz972; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li XM, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac360; Lipok M, 2019, FEBS OPEN BIO, V9, P914, DOI 10.1002/2211-5463.12618; Liu XM, 2011, HUM MUTAT, V32, P894, DOI 10.1002/humu.21517; Mills RE, 2011, GENOME RES, V21, P830, DOI 10.1101/gr.115907.110; Mondejar R, 2017, NEUROLOGIA, V32, P540, DOI 10.1016/j.nrl.2015.07.001; Moya ML, 2010, BIOMATERIALS, V31, P2816, DOI 10.1016/j.biomaterials.2009.12.053; Muraina I., 2022, IDEAL DATASET SPLITT; Murakami M, 2012, WIRES SYST BIOL MED, V4, P615, DOI 10.1002/wsbm.1190; Ornitz DM, 2015, WIRES DEV BIOL, V4, P215, DOI 10.1002/wdev.176; Orsenigo F, 2020, ELIFE, V9, DOI 10.7554/eLife.61413; Ouyang JQ, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1200469; Padarti A, 2021, medRxiv; Richards S, 2015, GENET MED, V17, P405, DOI 10.1038/gim.2015.30; Roslin NM, 2016, bioRxiv; Scimone C, 2020, BBA-MOL BASIS DIS, V1866, DOI 10.1016/j.bbadis.2020.165956; Scimone C, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.00146; Scimone C, 2016, BMC MED GENET, V17, DOI 10.1186/s12881-016-0332-0; Scimone C, 2015, J MOL NEUROSCI, V57, P400, DOI 10.1007/s12031-015-0606-6; Sellers F., 2013, Case Rep, V2013; Songhet P, 2007, DEV DYNAM, V236, P633, DOI 10.1002/dvdy.21056; Spiegler S, 2018, NEUROGENETICS, V19, P55, DOI 10.1007/s10048-017-0531-7; Srivastava P, 2021, BIOMOLECULES, V11, DOI 10.3390/biom11111591; Storer K.P., 2006, .D. thesis; Su VL, 2020, OPEN BIOL, V10, DOI 10.1098/rsob.200263; Targ S., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.08029; Uchida S, 2018, BRAIN RES BULL, V141, P3, DOI 10.1016/j.brainresbull.2018.02.016; Uffelmann E, 2021, NAT REV METHOD PRIME, V1, DOI 10.1038/s43586-021-00056-9; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Wang X, 2013, CHINESE MED J-PEKING, V126, P3427, DOI 10.3760/cma.j.issn.0366-6999.20130590; Weng JC, 2021, AM J HUM GENET, V108, P942, DOI 10.1016/j.ajhg.2021.04.005; Wu XH, 2023, BIG DATA MIN ANAL, V6, P201, DOI 10.26599/BDMA.2022.9020021; Yang XX, 2023, COMPUT STRUCT BIOTEC, V21, P1807, DOI 10.1016/j.csbj.2023.02.038; Yoneyama T, 2003, J HUM GENET, V48, P309, DOI 10.1007/s10038-003-0030-6; Zhang B, 2023, THROMB J, V21, DOI 10.1186/s12959-023-00462-x; Zhou J, 2020, SOIL DYN EARTHQ ENG, V139, DOI 10.1016/j.soildyn.2020.106390; Zou YC, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.00059	63	0	0	5	5	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2001-0370			COMPUT STRUCT BIOTEC	Comp. Struct. Biotechnol. J..	DEC	2024	23						843	858		10.1016/j.csbj.2024.01.014	http://dx.doi.org/10.1016/j.csbj.2024.01.014		FEB 2024	16	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	KC0X3	38352937	hybrid, Green Published			2024-07-03	WOS:001177654700001
J	Neo, JRE; Ser, JS; Tay, S				Neo, Jin Rui Edmund; Ser, Joon Sin; Tay, San San			Use of large language model-based chatbots in managing the rehabilitation concerns and education needs of outpatient stroke survivors and caregivers	FRONTIERS IN DIGITAL HEALTH			English	Article						stroke; rehabilitation; caregivers; artificial intelligence; large language model; chatbots; ChatGPT; Google Bard	ARTIFICIAL-INTELLIGENCE	Background The utility of large language model-based (LLM) artificial intelligence (AI) chatbots in many aspects of healthcare is becoming apparent though their ability to address patient concerns remains unknown. We sought to evaluate the performance of two well-known, freely-accessible chatbots, ChatGPT and Google Bard, in responding to common questions about stroke rehabilitation posed by patients and their caregivers.Methods We collected questions from outpatients and their caregivers through a survey, categorised them by theme, and created representative questions to be posed to both chatbots. We then evaluated the chatbots' responses based on accuracy, safety, relevance, and readability. Interrater agreement was also tracked.Results Although both chatbots achieved similar overall scores, Google Bard performed slightly better in relevance and safety. Both provided readable responses with some general accuracy, but struggled with hallucinated responses, were often not specific, and lacked awareness of the possibility for emotional situations with the potential to turn dangerous. Additionally, interrater agreement was low, highlighting the variability in physician acceptance of their responses.Conclusions AI chatbots show potential in patient-facing support roles, but issues remain regarding safety, accuracy, and relevance. Future chatbots should address these problems to ensure that they can reliably and independently manage the concerns and questions of stroke patients and their caregivers.	[Neo, Jin Rui Edmund; Tay, San San] Changi Gen Hosp, Dept Rehabil Med, Singapore, Singapore; [Ser, Joon Sin] SingHlth Residency, Rehabil Med, Singapore, Singapore	Changi General Hospital	Neo, JRE (corresponding author), Changi Gen Hosp, Dept Rehabil Med, Singapore, Singapore.	edmund.neo.jin.rui@singhealth.com.sg						[Anonymous], 2023, NATURE, V619, P671, DOI 10.1038/d41586-023-02366-2; Ch'ng AM, 2008, J HEALTH PSYCHOL, V13, P1136, DOI 10.1177/1359105308095967; Chan C., 2009, Assessment: Short Answer Questions, Assessment Resources@HKU; Coghlan S, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231183542; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; EQUATOR Network, 2024, Search for Reporting Guidelines; Gianola S, 2024, J ORTHOP SPORT PHYS, V54, P222, DOI 10.2519/jospt.2024.12151; Google, Release Update; HANGER HC, 1993, STROKE, V24, P536, DOI 10.1161/01.STR.24.4.536; Hanger HC, 1998, CLIN REHABIL, V12, P45, DOI 10.1191/026921598668677675; Kassab J, 2024, AM J PREV MED, V66, P1054, DOI 10.1016/j.amepre.2024.02.006; Mehid Y., 2023, Reinventing Search with a New AI-Powered Microsoft Bing and Edge, your Copilot for the Web; Nigrelli V., How Chat GPT Helps me, a Stroke Survivor; Olczak J, 2021, ACTA ORTHOP, V92, P513, DOI 10.1080/17453674.2021.1918389; Parviainen J, 2022, MED HEALTH CARE PHIL, V25, P61, DOI 10.1007/s11019-021-10049-w; Pichai S., 2023, IMPORTANT NEXT STEP; Pradhan F, 2024, HEPATOL COMMUN, V8, DOI 10.1097/HC9.0000000000000367; Rossettini G, 2023, J ORTHOP SPORT PHYS, V53, P728, DOI 10.2519/jospt.2023.12000; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sng GGR, 2023, DIABETES CARE, V46, pE103, DOI 10.2337/dc23-0197; Sung J, 2023, ANN ACAD MED SINGAP, V52, P695, DOI 10.47102/annals-acadmedsg.2023272; Zakka C., 2024, NEJM AI, V1, DOI 10.1056/AIoa2300068	22	0	0	2	2	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-253X		FRONT DIGIT HEALTH	Front. Digit. Health	MAY 9	2024	6								1395501	10.3389/fdgth.2024.1395501	http://dx.doi.org/10.3389/fdgth.2024.1395501			9	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	RQ0J3	38784703	gold			2024-07-03	WOS:001229005000001
J	Ansari, N; Babaei, V; Najafpour, MM				Ansari, Navid; Babaei, Vahid; Najafpour, Mohammad Mahdi			Enhancing catalysis studies with chat generative pre-trained transformer (ChatGPT): Conversation with ChatGPT	DALTON TRANSACTIONS			English	Article							OXYGEN-EVOLVING COMPLEX; PHOTOSYSTEM-II; EVOLUTION	The progress made in natural language processing (NLP) and large language models (LLMs), such as generative pre-trained transformers, (GPT) has provided exciting opportunities for enhancing research across various fields. Within the realm of catalysis studies, GPT-driven models present valuable support in expediting the exploration and comprehension of catalytic processes. This research underscores the significance of ChatGPT in catalysis research, emphasizing its prowess as a valuable tool for furthering scientific inquiries. It suggests that for an outstanding oxygen evolution reaction (OER) catalyst as a case study, scientists can leverage ChatGPT to extract deeper insights and brainstorm innovative approaches to grasp the mechanism better and refine current systems. This study describes the integration of generative pre-trained transformer and similar large language models in catalysis research, highlighting their potential to revolutionize understanding and innovation in oxygen-evolution reaction catalysts.	[Ansari, Navid; Babaei, Vahid] Max Planck Inst Informat Saarbrucken, Saarbrucken, Germany; [Najafpour, Mohammad Mahdi] Inst Adv Studies Basic Sci IASBS, Dept Chem, Zanjan 4513766731, Iran; [Najafpour, Mohammad Mahdi] Inst Adv Studies Basic Sci IASBS, Ctr Climate Change & Global Warming, Zanjan 4513766731, Iran; [Najafpour, Mohammad Mahdi] Inst Adv Studies Basic Sci IASBS, Res Ctr Basic Sci & Modern Technol RBST, Zanjan 4513766731, Iran	Max Planck Society; Institute for Advanced Studies in Basic Sciences (IASBS); Institute for Advanced Studies in Basic Sciences (IASBS); Institute for Advanced Studies in Basic Sciences (IASBS)	Najafpour, MM (corresponding author), Inst Adv Studies Basic Sci IASBS, Dept Chem, Zanjan 4513766731, Iran.; Najafpour, MM (corresponding author), Inst Adv Studies Basic Sci IASBS, Ctr Climate Change & Global Warming, Zanjan 4513766731, Iran.; Najafpour, MM (corresponding author), Inst Adv Studies Basic Sci IASBS, Res Ctr Basic Sci & Modern Technol RBST, Zanjan 4513766731, Iran.	mmnajafpour@iasbs.ac.ir			Iran's National Elites Foundation; Institute for Advanced Studies in Basic Sciences; National Elite Foundation	Iran's National Elites Foundation; Institute for Advanced Studies in Basic Sciences; National Elite Foundation	We gratefully acknowledge Institute for Advanced Studies in Basic Sciences and the National Elite Foundation.	Akbari N, 2023, ACS APPL ENERG MATER, V6, P11613, DOI 10.1021/acsaem.3c02012; Akbari N, 2023, INORG CHEM, V62, P19107, DOI 10.1021/acs.inorgchem.3c03304; [Anonymous], 2023, TECHNOLOGY 2023 MAR; Askerka M, 2014, BIOCHEMISTRY-US, V53, P6860, DOI 10.1021/bi5011915; Atallah SB, 2023, TECH COLOPROCTOL, V27, P609, DOI 10.1007/s10151-023-02837-8; Badini S, 2023, ADV IND ENG POLY RES, V6, P278, DOI 10.1016/j.aiepr.2023.03.003; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Biswas S., 2023, Importance of chat GPT in Agriculture: According to chat GPT; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Britt RD, 2019, SCIENCE, V366, P305, DOI 10.1126/science.aaz4522; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chatenet M, 2022, CHEM SOC REV, V51, P4583, DOI 10.1039/d0cs01079k; Chen Z., 2018, Lifelong Machine Learning, VSecond; Cheng TY, 2020, MON NOT R ASTRON SOC, V494, P3750, DOI 10.1093/mnras/staa1015; Colombo M., 2011, NETWORKS BRAIN; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Ecoffet A., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.08774; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Garcia-Molina Hector, 2008, Database Systems: The Complete Book, V2; Ghojogh B., 2020, Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Grabolle M, 2005, BBA-BIOENERGETICS, V1708, P209, DOI 10.1016/j.bbabio.2005.03.007; Grossberg S., 2013, Scholarpedia, V8, P1888, DOI [10.4249/scholarpedia.1888, DOI 10.4249/SCHOLARPEDIA.1888, DOI 10.4249/scholarpedia.1888]; Guo Y, 2023, J AM CHEM SOC, DOI 10.1021/jacs.2c12174; Hua SS, 2023, PROCEEDINGS OF THE 2023 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2023, P596, DOI 10.1145/3600211.3604694; Jurafsky D., 2021, SPEECH LANGUAGE PROC; KOK B, 1970, PHOTOCHEM PHOTOBIOL, V11, P457, DOI 10.1111/j.1751-1097.1970.tb06017.x; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Litman D, 2016, AAAI CONF ARTIF INTE, P4170; Madadkhani S, 2023, ACS APPL ENERG MATER, V7, P165, DOI 10.1021/acsaem.3c02390; Makatura L., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2307.14377; McCormack J., 2018, P 27 INT JOINT C ART, P5509; Medsker L. R., 2001, Design and Applications, V5, P2; Moruzzi C, 2020, EUR J PHILOS SCI, V11, DOI 10.1007/s13194-020-00313-w; Munakata T., 1998, FUNDAMENTALS NEW ART; Najafpour MM, 2011, DALTON T, V40, P9076, DOI 10.1039/c1dt10746a; Najafpour MM, 2020, COORDIN CHEM REV, V409, DOI 10.1016/j.ccr.2020.213183; Nosta, OUR COGNITIVE MANIFE; Oguz FE, 2024, ANN BIOMED ENG, V52, P1128, DOI 10.1007/s10439-023-03333-8; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pappano L., 2012, NY TIMES, P2; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Parslow GR, 2011, BIOCHEM MOL BIOL EDU, V39, P228, DOI 10.1002/bmb.20514; Power D J., 2017, Decision support, analytics, and business intelligence; Rahman Md Mostafizer, 2021, Advances and Trends in Artificial Intelligence. From Theory to Practice: 34th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2021, Proceedings. Lecture Notes in Computer Science. Lecture Notes in Artifical Intelligence (12799), P15, DOI 10.1007/978-3-030-79463-7_2; Rahman M. M., P MACHINE LEARNING P, P75; Rahman MM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082973; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Savelka J., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.09325; Schulman J, 2022, Introducing chatgpt; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Shevela D, 2023, PHOTOSYNTH RES, V156, P279, DOI 10.1007/s11120-022-00991-y; Singh C, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-43713-1; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Susnjak T., 2022, ArXiv, P1, DOI DOI 10.48550/ARXIV.2212.09292; theglobalnlplab, TOP CHALLENGES LARGE; theverge, About us; Vaswani A, 2017, ADV NEUR IN, V30; Wang B., 2024, ARXIV; Willcocks L., 2016, SERVICE AUTOMATION R; Wilson DE., 2005, Mammal Species of the World. A Taxonomic and Geographic Reference, V3rd ed, DOI DOI 10.56021/9780801882210; Wollny S, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.654924; Zand Z, 2023, COMMUN CHEM, V6, DOI 10.1038/s42004-023-00881-x; Zaremba W., 2014, ARXIV, DOI [10.48550/arXiv.1409.2329, DOI 10.48550/ARXIV.1409.2329]	65	2	2	21	21	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	1477-9226	1477-9234		DALTON T	Dalton Trans.	FEB 20	2024	53	8					3534	3547		10.1039/d3dt04178f	http://dx.doi.org/10.1039/d3dt04178f		JAN 2024	14	Chemistry, Inorganic & Nuclear	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	ID5P9	38275279				2024-07-03	WOS:001149504800001
J	Leem, J; Galson, JD				Leem, Jinwoo; Galson, Jacob D.			Becoming fluent in proteins	CELL SYSTEMS			English	Editorial Material							LANGUAGE	Large language models have emerged as a new compass for navigating the complex landscapes of protein engineering. This issue of Cell Systems features ProGen2 and IgLM-two protein language models (PLMs) that use subtly different approaches to design proteins.	[Leem, Jinwoo; Galson, Jacob D.] Alchemab Therapeut Ltd, Off 1-02, London N1C 4AX, England		Leem, J; Galson, JD (corresponding author), Alchemab Therapeut Ltd, Off 1-02, London N1C 4AX, England.	jin@alchemab.com; jake@alchemab.com		Leem, Jinwoo/0000-0002-7817-3644; Galson, Jacob/0000-0003-4916-800X				Alamdari S, 2023, bioRxiv, DOI [10.1101/2023.09.11.556673, 10.1101/2023.09.11.556673, DOI 10.1101/2023.09.11.556673]; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Nijkamp E, 2023, CELL SYST, V14, DOI 10.1016/j.cels.2023.10.002; Shuai RW, 2023, CELL SYST, V14, P979, DOI 10.1016/j.cels.2023.10.001; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Watson JL, 2023, NATURE, V620, DOI 10.1038/s41586-023-06415-8	9	0	0	2	3	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	2405-4712	2405-4720		CELL SYST	Cell Syst.	NOV 15	2023	14	11					923	924		10.1016/j.cels.2023.10.008	http://dx.doi.org/10.1016/j.cels.2023.10.008		NOV 2023	2	Biochemistry & Molecular Biology; Cell Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology	Z8JK8	37972558				2024-07-03	WOS:001114480500001
J	Ahmad, N; Murugesan, S; Kshetri, N				Ahmad, Norita; Murugesan, San; Kshetri, Nir			Generative Artificial Intelligence and the Education Sector	COMPUTER			English	Article								Large language models (LLMs), such as ChatGPT and now GPT4, are considered a significant breakthrough in conversational artificial intelligence. Academic institutions have varying responses to LLMs in education, some banning LLMs and others encouraging them.	[Ahmad, Norita] Amer Univ Sharjah, Sharjah, U Arab Emirates; [Murugesan, San] BRITE Profess Serv, Sydney, Australia; [Kshetri, Nir] Univ North Carolina Greensboro, Bryan Sch Business & Econ, Greensboro, NC 27412 USA	American University of Sharjah; University of North Carolina; University of North Carolina Greensboro	Kshetri, N (corresponding author), Univ North Carolina Greensboro, Bryan Sch Business & Econ, Greensboro, NC 27412 USA.	nahmad@aus.edu; san@computer.org; nbkshetr@uncg.edu		Ahmad, Norita/0000-0001-5129-1133				[Anonymous], 2023, WRAL FEB; Baidoo-Anu D., Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bown O., 2023, CONVERSATION FEB; Cai WL, 2021, MACH LEARN, V110, P2389, DOI 10.1007/s10994-021-05983-y; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Jovanovic M, 2022, COMPUTER, V55, P107, DOI 10.1109/MC.2022.3192720; Kim SC, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.8061; Kirchner Jan Hendrik, 2023, New ai classifier for indicating ai-written text; Roy K., 2022, MEDIUM MAR; Sands A., 2023, AXIOS CHARLOTTE FEB; Smulian L., USING HELP EMERGENT; Sparrow J, 2022, AUST JOURNAL REV, V44, P163, DOI 10.1386/ajr_00101_7; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Svrluga S., 2023, WASH POST; Syme P., 2023, Business Insider; Villasenor J., 2023, Scientific American; Vincent J., 2022, VERGE DEC; weforum, CHATGPT CHEAT 5 WAYS; Wolfson S., CREATIVE COMMONS; Zhai X., CHATGPT USER EXPERIE	23	8	8	56	155	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	JUN	2023	56	6					72	76		10.1109/MC.2023.3263576	http://dx.doi.org/10.1109/MC.2023.3263576			5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	H3NQ6		Bronze			2024-07-03	WOS:000995071700013
C	Dibia, V		Bollegala, D; Huang, R; Ritter, A		Dibia, Victor			LIDA: A Tool Automaticof Grammar-Agnostic Visualizations and Infographics using Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-DEMO 2023, VOL 3			English	Proceedings Paper	61st Annual Meeting of the Association-for-Computational-Linguistics - System Demonstrations (ACL-DEMO)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist				Systems that support users in the automatic creation of visualizations must address several subtasks - understand the semantics of data, enumerate relevant visualization goals and generate visualization specifications. In this work, we pose visualization generation as a multi-stage generation problem and argue that well -orchestrated pipelines based on large language models (tEms) and image generation models (I0Ms) are suitable to addressing these tasks. We present LIDA, a novel tool for generating grammar- agnostic visualizations and infographics. LIDA comprises of 4 modules - A SUMMARIZER that converts data into a rich but compact natural language summary, a GOAL EXPLORER that enumerates visualization goals given the data, a VISGENERATOR that generates, refines, executes and filters visualization code and an INFOGRAPHER module that yields data-faithful stylized graphics using IGMs. LIDA provides a python api, and a hybrid USER INTERFACE (direct manipulation and multilingual natural language) for interactive chart, infographics and data story generation. Code and demo are available at this url https://microsoft.github.io/llida/	[Dibia, Victor] Microsoft Res, Redmond, WA 98052 USA	Microsoft	Dibia, V (corresponding author), Microsoft Res, Redmond, WA 98052 USA.	victordibia@microsoft.corn						Bavarian M, 2022, Arxiv, DOI [arXiv:2207.14255, 10.48550/arXiv.2207.14255]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Chen QC, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3563307; Chowdhery A., 2022, arXiv; Cohen Aaron Daniel, 2022, arXiv; Dibia V, 2019, IEEE COMPUT GRAPH, V39, P33, DOI 10.1109/MCG.2019.2924636; Dibia Victor, 2022, Interaction design for systerts that;systems integrate image generation models: A case peacasso; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gao LY, 2023, Arxiv, DOI [arXiv:2211.10435, 10.48550/arXiv.2211.10435, DOI 10.48550/ARXIV.2211.10435]; Haroz S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1191, DOI 10.1145/2702123.2702275; Harrison L, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1187, DOI 10.1145/2702123.2702545; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Li Y., 2022, PREPRINT; Lin S., 2022, arXiv; Liu Y, 2023, Arxiv, DOI arXiv:2303.16634; Luo YY, 2018, INT CONF MANAGE DATA, P1733, DOI 10.1145/3183713.3193545; McKinney W., 2010, P 9 PYTHON SCI C, P56, DOI [DOI 10.25080/MAJORA-92BF1922-00A, 10.25080/Majora-92bf1922-00a]; Mialon G., 2023, arXiv; Mitra R, 2022, IEEE VIS CONF, P6, DOI 10.1109/VIS54862.2022.00010; Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240; Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378; OpenAI, 2023, GPT-4 Technical Report; Podo L, 2024, Arxiv, DOI arXiv:2302.00569; Radford A, 2021, PR MACH LEARN RES, V139; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Satyanarayan A, 2017, IEEE T VIS COMPUT GR, V23, P341, DOI 10.1109/TVCG.2016.2599030; Shi Freda, 2022, arXiv; Shi Yang, 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P8236; Touvron H., 2023, Llama: Open and efficient foundation language models; Tyagi Anjul, 2021, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357; Wei J., 2022, ARXIV; Wongsuphasawat K, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P2648; Zhang D., 2019, arXiv; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	42	2	2	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-70-8				2023							113	126						14	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BW6RV					2024-07-03	WOS:001181040500011
J	Englhardt, Z; Ma, CQ; Morris, ME; Chang, CC; Xu, X; Qin, LH; McDduff, D; Liu, X; Patel, S; Iyer, V				Englhardt, Zachary; Ma, Chengqian; Morris, Margaret E.; Chang, Chun-Cheng; Xu, Xuhai Orson; Qin, Lianhui; McDduff, Daniel; Liu, Xin; Patel, Shwetak; Iyer, Vikram			From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						Passive sensing; large-language-models; clinical insights; mental health	DEPRESSION	Passively collected behavioral health data from ubiquitous sensors could provide mental health professionals valuable insights into patient's daily lives, but such efforts are impeded by disparate metrics, lack of interoperability, and unclear correlations between the measured signals and an individual's mental health. To address these challenges, we pioneer the exploration of large language models (LLMs) to synthesize clinically relevant insights from multi-sensor data. We develop chain-of-thought prompting methods to generate LLM reasoning on how data pertaining to activity, sleep and social interaction relate to conditions such as depression and anxiety. We then prompt the LLM to perform binary classification, achieving accuracies of 61.1%, exceeding the state of the art. We find models like GPT-4 correctly reference numerical data 75% of the time. While we began our investigation by developing methods to use LLMs to output binary classifications for conditions like depression, we find instead that their greatest potential value to clinicians lies not in diagnostic classification, but rather in rigorous analysis of diverse self-tracking data to generate natural language summaries that synthesize multiple data streams and identify potential concerns. Clinicians envisioned using these insights in a variety of ways, principally for fostering collaborative investigation with patients to strengthen the therapeutic alliance and guide treatment. We describe this collaborative engagement, additional envisioned uses, and associated concerns that must be addressed before adoption in real-world contexts.	[Englhardt, Zachary; Ma, Chengqian; Morris, Margaret E.; Chang, Chun-Cheng; McDduff, Daniel; Liu, Xin; Patel, Shwetak; Iyer, Vikram] Univ Washington, Seattle, WA 98195 USA; [Xu, Xuhai Orson] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Qin, Lianhui] Univ Calif San Diego, La Jolla, CA 92093 USA	University of Washington; University of Washington Seattle; Massachusetts Institute of Technology (MIT); University of California System; University of California San Diego	Englhardt, Z (corresponding author), Univ Washington, Seattle, WA 98195 USA.	zacharye@cs.washington.edu; vsiyer@uw.edu			Amazon Research Award; Google Research Scholar Award; Washington Research Foundation; Pastry-Powered T(o)uring Machine Endowed Fellowship	Amazon Research Award; Google Research Scholar Award; Washington Research Foundation; Pastry-Powered T(o)uring Machine Endowed Fellowship	This research was partially supported by an Amazon Research Award, a Google Research Scholar Award, The Washington Research Foundation, and the Pastry-Powered T(o)uring Machine Endowed Fellowship.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; American Psychiatric Association (APA), 2013, DIAGN STAT MAN MENT; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; Ani C, 2008, BMC FAM PRACT, V9, DOI 10.1186/1471-2296-9-1; Azerbayev Z, 2024, Arxiv, DOI arXiv:2310.10631; Bae Sangwon, 2017, Proc ACM Interact Mob Wearable Ubiquitous Technol, V1, DOI 10.1145/3090051; Bansal R, 2024, Arxiv, DOI [arXiv:2401.02412, 10.48550/arXiv.2401.02412]; Ben-Zeev D, 2015, PSYCHIATR REHABIL J, V38, P218, DOI 10.1037/prj0000130; Brants Thorsten, 2007, Large language models in machine translation; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cameron SK, 2018, CLIN PSYCHOL PSYCHOT, V25, P446, DOI 10.1002/cpp.2180; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chancellor S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0233-7; Chikersal P, 2021, ACM T COMPUT-HUM INT, V28, DOI 10.1145/3422821; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong XJ, 2023, Arxiv, DOI arXiv:2311.00306; Gao Luyu, 2023, P MACHINE LEARNING R, P10764; Gulcehre C, 2017, COMPUT SPEECH LANG, V45, P137, DOI 10.1016/j.csl.2017.01.014; Hickey Aodhan, 2021, Digital health, P357; Hsieh CY, 2023, Arxiv, DOI arXiv:2305.02301; Huckins JF, 2020, J MED INTERNET RES, V22, DOI 10.2196/20185; Huckins JF, 2020, JMIR MENT HEALTH, V7, DOI 10.2196/16684; Indrakumari R, 2020, EMERGENCE OF PHARMACEUTICAL INDUSTRY GROWTH WITH INDUSTRIAL IOT APPROACH, P163, DOI 10.1016/B978-0-12-819593-2.00006-6; Isakadze N, 2020, TRENDS CARDIOVAS MED, V30, P442, DOI 10.1016/j.tcm.2019.10.010; Jacobson NC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123572; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kim Y, 2024, Arxiv, DOI arXiv:2401.06866; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kroenke K, 2009, PSYCHOSOMATICS, V50, P613, DOI 10.1176/appi.psy.50.6.613; Lamichhane B, 2023, Arxiv, DOI [arXiv:2303.15727, 10.48550/arXiv.2303.15727, DOI 10.48550/ARXIV.2303.15727]; Lee HJ, 2023, PSYCHOL MED, V53, P5636, DOI 10.1017/S0033291722002847; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Liu X, 2023, Arxiv, DOI arXiv:2305.15525; Liu Xin, 2023, arXiv; Martin DJ, 2000, J CONSULT CLIN PSYCH, V68, P438, DOI 10.1037//0022-006X.68.3.438; Mattingly SM, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3299041; Min JK, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P477, DOI 10.1145/2556288.2557220; Mirjafari Shayan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3328908; Nickels S, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/27589; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Omar Reham, 2023, ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots, DOI DOI 10.48550/ARXIV.2302.06466; Parrish A, 2022, Arxiv, DOI arXiv:2110.08193; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Raffel C, 2020, J MACH LEARN RES, V21; Robinson Joshua, 2023, 11 INT C LEARN REPR; Rohani DA, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/mhealth.9691; Rui Wang, 2018, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V2, DOI 10.1145/3191775; Saeb S, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4273; Salekin Asif, 2018, Proc ACM Interact Mob Wearable Ubiquitous Technol, V2, DOI 10.1145/3214284; Sefidgar Yasaman S, 2019, Proc ACM Hum Comput Interact, V3, P1, DOI 10.1145/3359216; Shaikh O, 2023, Arxiv, DOI arXiv:2212.08061; Shridhar Kumar, 2023, FINDINGS ASS COMPUTA, P7059, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.441; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Triantafyllidis A, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103984; Wahle F, 2016, JMIR MHEALTH UHEALTH, V4, DOI 10.2196/mhealth.5960; Wang R, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P886, DOI 10.1145/2971648.2971740; Wang R, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P295, DOI 10.1145/2750858.2804251; Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wu CY, 2023, Arxiv, DOI [arXiv:2304.14454, DOI 10.48550/ARXIV.2304.14454]; Xu XH, 2022, PROC ACM INTERACT MO, V6, DOI 10.1145/3569485; Xu XH, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448107; Xu XH, 2021, PROC ACM INTERACT MO, V5, DOI 10.1145/3448124; Xu Xuhai., 2022, THIRTYSIXTH C NEURAL, P18; Yang BH, 2024, Arxiv, DOI arXiv:2309.13182; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Yeh Kai-Ching, 2023, P 35 C COMPUTATIONAL, P292; Zhang H, 2022, ACM T ACCESS COMPUT, V15, DOI 10.1145/3538514; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	80	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAY	2024	8	2							56	10.1145/3659604	http://dx.doi.org/10.1145/3659604			25	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	RR2F4		hybrid			2024-07-03	WOS:001229316000015
C	Cox, SR; Ooi, WT		Folstad, A; Araujo, T; Papadopoulos, S; Law, ELC; Luger, E; Goodwin, M; Hobert, S; Brandtzaeg, PB		Cox, Samuel Rhys; Ooi, Wei Tsang			Conversational Interactions with NPCs in LLM-Driven Gaming: Guidelines from a Content Analysis of Player Feedback	CHATBOT RESEARCH AND DESIGN, CONVERSATIONS 2023	Lecture Notes in Computer Science		English	Proceedings Paper	7th Conversations International Workshop (CONVERSATIONS)	NOV 22-23, 2023	Univ Oslo, Ctr Res Media Innovat, Oslo, NORWAY	SINTEF, Univ Amsterdam, Ctr Res & Technol Hellas, Durham Univ, Univ Edinburgh, Lubeck Univ Technol, Univ Agder	Univ Oslo, Ctr Res Media Innovat	Large Language Models; Video Games; Non-playable Characters		The growing capability and availability of large language models (LLMs) have led to their adoption in a number of domains. One application domain that could prove fruitful is to video games, where LLMs could be used to provide conversational responses from non-playable characters (NPCs) that are more dynamic and diverse. Additionally, LLMs could allow players the autonomy to converse in open-ended conversations potentially improving player immersion and agency. However, due to their recent commercial popularity, the consequences (both negative and positive) of using LLMs in video games from a player's perspective is currently unclear. On from this, we analyse player feedback to the use of LLM-driven NPC responses in a commercially available video game. We discuss findings and implications, and generate guidelines for designers incorporating LLMs into NPC dialogue.	[Cox, Samuel Rhys; Ooi, Wei Tsang] Natl Univ Singapore, Singapore, Singapore	National University of Singapore	Cox, SR (corresponding author), Natl Univ Singapore, Singapore, Singapore.	samuel.cox@u.nus.edu						[Anonymous], 2023, Bumblebee-Studios: Vaudeville on Steam; Bansal H, 2024, Arxiv, DOI arXiv:2308.15812; Bowey JT, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3337734; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Cox S.R., 2023, P 11 INT C HUM AG IN; Csepregi L.M., The Effect of Context-aware LLM-based NPC Conversations on Player Engagement in Role-playing Video Games; El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679; Frommel J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P163, DOI 10.1145/3242671.3242682; Hunicke R., 2005, P 2005 ACM SIGCHI IN, P429, DOI [DOI 10.1145/1178477.1178573, 10.1145/1178477.1178573]; Inworld, 2023, Inworld Origins on Steam; Inworld, Inworld-The most advanced Character Engine for AI NPCs; Jiang H., 2023, PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences; Khadpe Pranav, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415234; Kim BJ, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P1056, DOI 10.1145/3341105.3374063; Kway L., 2018, Proceedings of the 13th International Conference on the Foundations of Digital Games, P1, DOI [10.1145/3235765.3235777, DOI 10.1145/3235765.3235777]; Lin DY, 2019, EMPIR SOFTW ENG, V24, P170, DOI 10.1007/s10664-018-9627-4; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Mateas M., 2003, GAM DEV C, P4; Mehta Manish., 2007, Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems, p8:1; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Mori Yusuke, 2022, 2022 IEEE International Conference on Big Data (Big Data), P5132, DOI 10.1109/BigData55660.2022.10020271; OpenAI, 2023, Inworld AI; Packer C, 2024, Arxiv, DOI arXiv:2310.08560; Paduraru C., 2023, P 18 INT C SOFTW TEC; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Perlin K., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P205, DOI 10.1145/237170.237258; Phillips Cody, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3474682; Serapio-Garcia G, 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2307.00184; Sun YQ, 2023, Arxiv, DOI arXiv:2308.12915; Tanenbaum K., 2009, COMMITMENT MEANING R; van Stegeren J, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES, FDG 2021, DOI 10.1145/3472538.3472595; Vanhatupa J.M., 2011, Proceedings of the 6th International Conference on Foundations of Digital Games, P46; Vartinen S, 2024, IEEE T GAMES, V16, P127, DOI 10.1109/TG.2022.3228480; Weibel D, 2011, INT J COMPUT GAMES T, V2011, DOI 10.1155/2011/282345; Weir N, 2022, Arxiv, DOI arXiv:2212.10618; Wu WQ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P3080; Xi YD, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P175; Xie LX, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517712; Yan V., 2023, Yandere AI Girlfriend Simulator; Zagal J. P., 2013, P 8 INT C FDN DIG GA, P86; Zagal J P., 2009, Proceedings of the 4th International Conference on Foundations of Digital Games, P215; Zhang Amy X., 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274465	43	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-54974-8; 978-3-031-54975-5	LECT NOTES COMPUT SC			2024	14524						167	184		10.1007/978-3-031-54975-5_10	http://dx.doi.org/10.1007/978-3-031-54975-5_10			18	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9FF					2024-07-03	WOS:001212393500010
J	Zhang, L; Chen, ZL				Zhang, Liang; Chen, Zhelun			Large language model-based interpretable machine learning control in building energy systems	ENERGY AND BUILDINGS			English	Article						Building control; Machine learning control; Interpretable machine learning; Shapley value; Large language model		The potential of Machine Learning Control (MLC) in HVAC systems is hindered by its opaque nature and inference mechanisms, which is challenging for users and modelers to fully comprehend, ultimately leading to a lack of trust in MLC-based decision -making. To address this challenge, this paper investigates and explores Interpretable Machine Learning (IML), a branch of Machine Learning (ML) that enhances transparency and understanding of models and their inferences, to improve the credibility of MLC and its industrial application in HVAC systems. Specifically, we developed an innovative framework that combines the principles of Shapley values and the in -context learning feature of Large Language Models (LLMs). While the Shapley values are instrumental in dissecting the contributions of various features in ML models, LLM provides an in-depth understanding of the non -data -driven or rule -based elements in MLC; combining them, LLM further packages these insights into a coherent, human -understandable narrative. The paper presents a case study to demonstrate the feasibility of the developed IML framework for model predictive control -based precooling under demand response events in a virtual testbed. The results indicate that the developed framework generates and explains the control signals in accordance with the rule -based rationale.	[Zhang, Liang] Univ Arizona, Tucson, AZ 85721 USA; [Zhang, Liang] Natl Renewable Energy Lab, Golden, CO USA; [Chen, Zhelun] Drexel Univ, Philadelphia, PA USA	University of Arizona; United States Department of Energy (DOE); National Renewable Energy Laboratory - USA; Drexel University	Zhang, L (corresponding author), Univ Arizona, Tucson, AZ 85721 USA.	liangzhang1@arizona.edu		Chen, Zhelun/0000-0002-5570-1264; Zhang, Liang/0000-0001-9884-5199				Bae Y, 2021, ADV APPL ENERGY, V4, DOI 10.1016/j.adapen.2021.100068; Bellahsen A, 2021, ENERG BUILDINGS, V237, DOI 10.1016/j.enbuild.2021.110742; Chang X., 2020, ICASSP 2020; Chen Z, 2023, ADV APPL ENERGY, V9, DOI 10.1016/j.adapen.2023.100123; Cole WJ, 2014, ENERG BUILDINGS, V74, P69, DOI 10.1016/j.enbuild.2014.01.033; Crawley DB, 2001, ENERG BUILDINGS, V33, P319, DOI 10.1016/S0378-7788(00)00114-6; Deru M., 2011, Us department of energy commercial reference building models of the national building stock; DOE, 2015, Increasing efficiency of building systems and technologies, P145; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786; Duriez T, 2017, FLUID MECH APPL, V116, P1, DOI 10.1007/978-3-319-40624-4; Fan C, 2019, APPL ENERG, V235, P1551, DOI 10.1016/j.apenergy.2018.11.081; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao Y, 2022, APPL THERM ENG, V205, DOI 10.1016/j.applthermaleng.2021.118032; Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095; Jin XY, 2022, ENERG BUILDINGS, V260, DOI 10.1016/j.enbuild.2022.111909; Kim W, 2016, APPL ENERG, V162, P666, DOI 10.1016/j.apenergy.2015.10.153; Kotevska O., 2020, Methodology for Interpretable Reinforcement Learning Model for HVAC Energy Control; Li AO, 2021, APPL ENERG, V299, DOI 10.1016/j.apenergy.2021.117238; Lundberg S., 2018, ABOUT US; Lundberg SM, 2017, ADV NEUR IN, V30; Mao J., 2023, Science and Technology for the Built Environment, P1; Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28; Papadopoulos S, 2019, APPL ENERG, V233, P244, DOI 10.1016/j.apenergy.2018.10.053; Park S, 2020, INT CONF DAT MIN WOR, P762, DOI 10.1109/ICDMW51313.2020.00111; Raschka S., 2016, Mlxtend; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Ruelens F, 2017, IEEE T SMART GRID, V8, P2149, DOI 10.1109/TSG.2016.2517211; Saabas P., 2021, And the MAIF Data Team; Shapley L.S., 1953, CONTRIBUTIONS THEORY, VVolume II, P307, DOI [10.1515/9781400881970-018, DOI 10.1515/9781400881970-018]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Ribeiro MT, 2016, Arxiv, DOI [arXiv:1606.05386, 10.48550/arXiv.1606.05386]; Ugwuanyi C., 2021, Using interpretable machine learning for indoor CO2 level prediction and occupancy estimation; Wang Z, 2020, APPL ENERG, V269, DOI 10.1016/j.apenergy.2020.115036; Wei TS, 2017, DES AUT CON, DOI 10.1145/3061639.3062224; Yang YR, 2022, INDOOR AIR, V32, DOI 10.1111/ina.12984; Yu MG, 2022, ENERGY, V240, DOI 10.1016/j.energy.2021.122691; Zhang L., 2023, Building Simulation; Zhang L., SSRN 4572925; Zhang W, 2021, IEEE INTERNET THINGS, V8, P8021, DOI 10.1109/JIOT.2020.3042783	40	0	0	4	4	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0378-7788	1872-6178		ENERG BUILDINGS	Energy Build.	JUN 15	2024	313								114278	10.1016/j.enbuild.2024.114278	http://dx.doi.org/10.1016/j.enbuild.2024.114278			11	Construction & Building Technology; Energy & Fuels; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Energy & Fuels; Engineering	TK7R7					2024-07-03	WOS:001241227000001
C	Zhang, JY; Nie, PY; Li, JJ; Gligoric, M		Chandra, S; Blincoe, K; Tonella, P		Zhang, Jiyang; Nie, Pengyu; Li, Junyi Jessy; Gligoric, Milos			Multilingual Code Co-evolution using Large Language Models	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Language models; code translation; software evolution		Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 aligned code changes from 8 pairs of open-source software projects implementing similar functionalities in two programming languages ( Java and C#). Results show that Codeditor outperforms the state-of-the-art approaches by a large margin on all commonly used automatic metrics. Our work also reveals that Codeditor is complementary to the existing generation-based models, and their combination ensures even greater performance.	[Zhang, Jiyang; Nie, Pengyu; Li, Junyi Jessy; Gligoric, Milos] UT Austin, Austin, TX 78712 USA	University of Texas System; University of Texas Austin	Zhang, JY (corresponding author), UT Austin, Austin, TX 78712 USA.	jiyang.zhang@utexas.edu; pynie@utexas.edu; jessy@austin.utexas.edu; gligoric@utexas.edu		Zhang, Jiyang/0000-0001-8211-3321; Nie, Pengyu/0000-0003-1529-3216	US National Science Foundation [CCF-2107291, IIS-2145479, CCF-2217696, CCF-2313027]	US National Science Foundation(National Science Foundation (NSF))	We thank Nader Al Awar, Yu Liu, Sheena Panthaplackel, Aditya Thimmaiah, Zhiqiang Zang, and the anonymous reviewers for their comments and feedback. We acknowledge the Texas Advanced Computing Center (TACC) at The University of Texas at Austin for providing HPC resources that have contributed to the research results reported within this paper. This work is partially supported by the US National Science Foundation under Grant Nos. CCF-2107291, IIS-2145479, CCF-2217696 and CCF-2313027.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Ahmed T, 2022, ADV APPL CERAM, V121, P101, DOI 10.1080/17436753.2022.2072676; Nguyen AT, 2015, IEEE INT CONF AUTOM, P585, DOI 10.1109/ASE.2015.74; Apache Software, 2022, Apache Lucene; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Berg-Kirkpatrick T., 2012, P 2012 JOINT C EMPIR, P995; Bertsch A, 2023, Arxiv, DOI [arXiv:2305.01625, 10.48550/arXiv.2305.01625]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bui NDQ, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING TECHNOLOGIES RESULTS (ICSE-NIER), P33, DOI 10.1145/3183399.3183427; Chakraborty S, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P443, DOI 10.1109/ASE51524.2021.9678559; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P1385, DOI 10.1109/TSE.2020.3020502; Chance Elliot, 2021, A tool for transpiling C to Go; Chen M., 2021, arXiv; Christian Mauceri Alexandre FAU, 2013, Java2csharp; Dao T., 2022, Advances in Neural Information Processing Systems, V35, P16344, DOI [10.48550/arXiv2205.14135, DOI 10.48550/ARXIV2205.14135]; Ding YRB, 2020, IEEE INT CONF AUTOM, P275, DOI 10.1145/3324884.3416587; Galois and Immunant, 2023, C2Rust; Gao ZP, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P218, DOI 10.1145/3468264.3468553; google, 2023, Google Cloud; Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212; Gyori A., 2013, CROSSING GAP IMPERAT, P543; Jaccard P., 1912, NEW PHYTOL, V11, P37, DOI DOI 10.1111/J.1469-8137.1912.TB05611.X; Kamezawa H, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8718; Khan J. Y., 2022, Automated Software Engineering, P1; Li ZY, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1035, DOI 10.1145/3540250.3549081; Lin B, 2023, IEEE T SOFTWARE ENG, V49, P1640, DOI 10.1109/TSE.2022.3185458; Lin B, 2021, INT C PROGRAM COMPRE, P36, DOI 10.1109/ICPC52881.2021.00013; Liu, 2023, ARXIV; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Zhongxin., 2021, IEEE Transactions on Software Engineering; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Mariano Benjamin, 2022, INT C OBJ OR PROGR S, P1; MongoDB Inc, 2023, MongoDB; Napoles C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P588; Nie PY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4936; OpenAI, 2023, Introducing ChatGPT; Panthaplackel S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1853; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PARR TJ, 1995, SOFTWARE PRACT EXPER, V25, P789, DOI 10.1002/spe.4380250705; Pengyu Nie, 2023, Ph. D. Dissertation; Python Software Foundation, 2023, di~ib-Helpers for computing deltas; Radoi C, 2014, ACM SIGPLAN NOTICES, V49, P909, DOI [10.1145/2660193.2660228, 10.1145/2714064.2660228]; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Roziere B., 2020, Advances in neural information processing systems, V33, P20601; Roziere B., 2021, arXiv; Stahlberg F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5147; Tipirneni S, 2024, Arxiv, DOI arXiv:2206.05239; Trudel Marco, 2011, INT C OBJ MOD COMP P, P20; Tufano M, 2019, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2019.00021; Tufano R, 2022, PROC INT CONF SOFTW, P2291, DOI 10.1145/3510003.3510621; Vaswani A, 2017, ADV NEUR IN, V30; Wang YN, 2018, ADV NEUR IN, V31; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xu W., 2016, T ASS COMPUTATIONAL, V4, P401, DOI [DOI 10.1162/TACL_A_00107, DOI 10.1162/TACLA00107]; Yao Ziyu, 2021, INT C LEARN REPR; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zhang Jiyang, 2023, INT C SOFTW ENG SEIP; Zhu M, 2022, AAAI CONF ARTIF INTE, P11783	60	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							695	707		10.1145/3611643.3616350	http://dx.doi.org/10.1145/3611643.3616350			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		hybrid, Green Submitted			2024-07-03	WOS:001148157800057
J	Deriu, J; Cieliebak, M				Deriu, Jan; Cieliebak, Mark			A unified Model for Automated Evaluation of Text Generation Systems	ERCIM NEWS			English	Article								With all the recent hype around Large Language Models and ChatGPT in particular, one crucial question is still unanswered: how do we evaluate generated text, and how can this be automated? In this SNF project, we develop a theoretical framework to answer these questions.	[Deriu, Jan; Cieliebak, Mark] Zurich Univ Appl Sci, Zurich, Switzerland	Zurich University of Applied Sciences	Deriu, J (corresponding author), Zurich Univ Appl Sci, Ctr Artificial Intelligence, Zurich, Switzerland.	jan.deriu@zhaw.ch						Deriu J., Findings of the Association for Computational Linguistics: ACL 2023; von Daniken P., 2022, Findings of the Association for Computational Linguistics: EMNLP	2	0	0	0	0	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					44	45						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500025
J	Lee, M				Lee, Minhyeok			A Mathematical Investigation of Hallucination and Creativity in GPT Models	MATHEMATICS			English	Article						generative pretrained transformers; large language model; LLM; GPT; ChatGPT; hallucination; creativity		In this paper, we present a comprehensive mathematical analysis of the hallucination phenomenon in generative pretrained transformer (GPT) models. We rigorously define and measure hallucination and creativity using concepts from probability theory and information theory. By introducing a parametric family of GPT models, we characterize the trade-off between hallucination and creativity and identify an optimal balance that maximizes model performance across various tasks. Our work offers a novel mathematical framework for understanding the origins and implications of hallucination in GPT models and paves the way for future research and development in the field of large language models (LLMs).	[Lee, Minhyeok] Chung Ang Univ, Sch Elect & Elect Engn, Seoul 06974, South Korea	Chung Ang University	Lee, M (corresponding author), Chung Ang Univ, Sch Elect & Elect Engn, Seoul 06974, South Korea.	mlee@cau.ac.kr	Lee, Minhyeok/AAD-6000-2019	Lee, Minhyeok/0000-0003-2562-172X	Generative Artificial Intelligence System Inc. (GAIS)	Generative Artificial Intelligence System Inc. (GAIS)	This work was supported by a research grant funded by Generative Artificial Intelligence System Inc. (GAIS).	Albelwi S, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040551; ANDREWS DWK, 1992, ECONOMET THEOR, V8, P241, DOI 10.1017/S0266466600012780; Ba JL., 2016, arXiv; Borgeaud S, 2022, PR MACH LEARN RES; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N., 2021, P USENIX SEC S SAN D, VVolume 6; Donini M, 2018, ADV NEUR IN, V31; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kaiser L, 2016, Arxiv, DOI arXiv:1511.08228; Kingma D. P., 2017, ARXIV; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mukkamala MC, 2017, PR MACH LEARN RES, V70; OpenAI, 2023, GPT-4 Technical Report; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramachandran P, 2019, ADV NEUR IN, V32; Shaw P, 2018, Arxiv, DOI [arXiv:1803.02155, DOI 10.48550/ARXIV.1803.02155]; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200; Siino M., 2022, Proceedings of the Working notes of CLEF 2022-Conference and Labs of the Evaluation Forum, V3180, P2666; Siino M, 2022, INFORMATION, V13, DOI 10.3390/info13090426; Tirumala K., 2022, Advances in Neural Information Processing Systems, V35, P38274; Vaswani A, 2017, ADV NEUR IN, V30; Wei J., 2022, P ADV NEURAL INFORM; Xu H, 2023, COMPUT ECON, V61, P1, DOI 10.1007/s10614-019-09909-8; Zhao H., 2020, CVPR; Zhu QH, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056598	33	15	15	65	135	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	MAY 16	2023	11	10							2320	10.3390/math11102320	http://dx.doi.org/10.3390/math11102320			17	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	H5IA9		Green Published			2024-07-03	WOS:000996285900001
C	Wu, J; Antonova, R; Kan, A; Lepert, M; Zeng, A; Song, SR; Bohg, J; Rusinkiewicz, S; Funkhouser, T			IEEE	Wu, Jimmy; Antonova, Rika; Kan, Adam; Lepert, Marion; Zeng, Andy; Song, Shuran; Bohg, Jeannette; Rusinkiewicz, Szymon; Funkhouser, Thomas			TidyBot: Personalized Robot Assistance with Large Language Models	2023 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, IROS	IEEE International Conference on Intelligent Robots and Systems		English	Proceedings Paper	IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)	OCT 01-05, 2023	Detroit, MI	IEEE, RSJ				For a robot to personalize physical assistance effectively, it must learn user preferences that can be generally reapplied to future scenarios. In this work, we investigate personalization of household cleanup with robots that can tidy up rooms by picking up objects and putting them away. A key challenge is determining the proper place to put each object, as people's preferences can vary greatly depending on personal taste or cultural background. For instance, one person may prefer storing shirts in the drawer, while another may prefer them on the shelf. We aim to build systems that can learn such preferences from just a handful of examples via prior interactions with a particular person. We show that robots can combine language-based planning and perception with the few-shot summarization capabilities of large language models (LLMs) to infer generalized user preferences that are broadly applicable to future interactions. This approach enables fast adaptation and achieves 91.2% accuracy on unseen objects in our benchmark dataset. We also demonstrate our approach on a real-world mobile manipulator called TidyBot, which successfully puts away 85.0% of objects in real-world test scenarios.	[Wu, Jimmy; Rusinkiewicz, Szymon; Funkhouser, Thomas] Princeton Univ, Princeton, NJ 08544 USA; [Antonova, Rika; Lepert, Marion; Bohg, Jeannette] Stanford Univ, Stanford, CA 94305 USA; [Kan, Adam] Nueva Sch, Hillsborough, CA USA; [Zeng, Andy; Funkhouser, Thomas] Google, Mountain View, CA 94043 USA; [Song, Shuran] Columbia Univ, New York, NY USA	Princeton University; Stanford University; Google Incorporated; Columbia University	Wu, J (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.		wu, jimmy/KDP-2256-2024	Bohg, Jeannette/0000-0002-4921-7193	Princeton School of Engineering, Toyota Research Institute; National Science Foundation [CCF2030859, DGE-1656466, IIS-2132519]	Princeton School of Engineering, Toyota Research Institute; National Science Foundation(National Science Foundation (NSF))	This work was supported in part by the Princeton School of Engineering, Toyota Research Institute, and the National Science Foundation under CCF2030859, DGE-1656466, and IIS-2132519.	Abdo N, 2015, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ICRA.2015.7139396; Batra D., 2020, ARXIV PREPRINT ARXIV; Brohan A., 2022, 6 ANN C ROB LEARN; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Boyuan, 2022, ARXIV220909874; Chowdhery A., 2022, ARXIV220402311; Coulter R C., 1992, Technical report; Dewi T., 2020, B ELECT ENG INFORM; Ehsani K., 2021, P IEEE CVF C COMP VI; Farhadi, 2017, Ai2-thor: An interactive 3d environment for visual ai, V2, P3; Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005; Gu Xiuye, 2021, INT C LEARN REPR; Gupta M., 2012, 2012 IEEE INT C ROB; Herde M., 2018, 2018 INT JOINT C NEU; Hoeg S. H., 2022, WORKSH LANG ROB CORL; Holmberg R., 2000, INT J ROBOTICS RES; Huang E., 2019, 2019 INT C ROB AUT I; Huang W., 2022, ARXIV220107207; Huang Wenlong, 2022, ARXIV220705608; Kang M., 2018, 2018 15 INT C UB ROB; Kant Y., 2022, ARXIV220510712; Kapelyukh I., 2022, C ROB LEARN; Kujala J. V., 2016, 2016 IEEE RSJ INT C; Li C., 2022, C ROB LEARN; Liang Jacky, 2022, ARXIV220907753; Lin K., 2023, ARXIV230312153; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Lukka T. J., 2014, P INT C SENS BAS SO; Mees O., 2022, ARXIV221001911; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Nye Maxwell, 2021, ARXIV211200114; Puig X., 2018, P IEEE C COMP VIS PA; Radford A, 2021, PR MACH LEARN RES, V139; Raman S. S., 2022, ARXIV221109935; Rasch R., 2019, J AMBIENT INTELLIGEN; Reimers Nils, 2019, IJCNLP; Sarch G., 2022, EUR C COMP VIS; Shah D., 2022, ARXIV220704429; Shridhar Mohit, 2020, P IEEE CVF C COMP VI; Silver T., 2022, NEURIPS 2022 FDN MOD; Singh Ishika, 2022, ARXIV220911302; Song H., 2020, 2020 IEEE RSJ INT C; Srivastava S., 2022, C ROB LEARN; Szabo R., 2012, 2012 10 INT S EL TEL; Szot Andrew, 2021, ADV NEURAL INFORM PR; Taniguchi A., 2021, ADV ROBOTICS; Wei Jason, 2022, arXiv:2201.11903; Weihs L., 2021, P IEEE CVF C COMP VI; Yan Z, 2021, J GEOL SOC LONDON, V178, DOI 10.1144/jgs2020-231; Yao Shunyu, 2022, ARXIV221003629; Zeng A., 2022, INT J ROBOTICS RES; Zeng A., 2020, IEEE T ROBOTICS; Zeng Andy, 2022, ARXIV220400598	53	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0858		978-1-6654-9190-7	IEEE INT C INT ROBOT			2023							3546	3553		10.1109/IROS55552.2023.10341577	http://dx.doi.org/10.1109/IROS55552.2023.10341577			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW2ZH		Green Submitted			2024-07-03	WOS:001133658802091
C	Du, WY; Kim, ZM; Raheja, V; Kumar, D; Kang, D			Assoc Computat Linguist	Du, Wanyu; Kim, Zae Myung; Raheja, Vipul; Kumar, Dhruv; Kang, Dongyeop			Read, Revise, Repeat: A System Demonstration for Human-in-the-loop Iterative Text Revision	PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022)			English	Proceedings Paper	1st Workshop on Intelligent and Interactive Writing Assistants (In2Writing)	MAY 22-27, 2022	Dublin, IRELAND	Grammarly, Wordtune				Revision is an essential part of the human writing process. It tends to be strategic, adaptive, and, more importantly, iterative in nature. Despite the success of large language models on text revision tasks, they are limited to non-iterative, one-shot revisions. Examining and evaluating the capability of large language models for making continuous revisions and collaborating with human writers is a critical step towards building effective writing assistants. In this work, we present a human-in-the-loop iterative text revision system, Read, Revise, Repeat (R3), which aims at achieving high quality text revisions with minimal human efforts by reading model-generated revisions and user feedbacks, revising documents, and repeating human-machine interactions. In R3, a text revision model provides text editing suggestions for human writers, who can accept or reject the suggested edits. The accepted edits are then incorporated into the model for the next iteration of document revision. Writers can therefore revise documents iteratively by interacting with the system and simply accepting/rejecting its suggested edits until the text revision model stops making further revisions or reaches a predefined maximum number of revisions. Empirical experiments show that R3 can generate revisions with comparable acceptance rate to human writers at early revision depths, and the human-machine interaction can get higher quality revisions with fewer iterations and edits. The collected human-model interaction dataset and system code are available at https://github.com/vipulraheja/IteraTeR. Our system demonstration is available at https://youtu.be/lK08tIpEoaE.	[Du, Wanyu] Univ Virginia, Charlottesville, VA 22903 USA; [Kim, Zae Myung; Kang, Dongyeop] Univ Minnesota, Minneapolis, MN 55455 USA; [Raheja, Vipul; Kumar, Dhruv] Grammarly, San Francisco, CA USA	University of Virginia; University of Minnesota System; University of Minnesota Twin Cities	Du, WY (corresponding author), Univ Virginia, Charlottesville, VA 22903 USA.	wd5jq@virginia.edu; kim01756@umn.edu; vipul.raheja@grammarly.com; dhruv.kumar@grammarly.com; dongyeop@umn.edu	Raheja, Vipul/KFB-2673-2024					[Anonymous], 1981, College Composition and Communication; Botha JA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P732; Coenen A, 2021, Arxiv, DOI [arXiv:2107.07430, 10.48550/arXiv.2107.07430]; Faltings F, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5259; Faruqui M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P305; FITZGERALD J, 1987, REV EDUC RES, V57, P481, DOI 10.2307/1170433; Flower L., 1981, College Composition & Communication, V32, P365, DOI [10.2307/356600, DOI 10.2307/356600]; Flower L., 1980, Cognitive processes in writing, P31; Gero KI, 2021, Arxiv, DOI [arXiv:2110.07640, 10.48550/ARXIV.2110.07640]; Ito Takumi, 2019, P 12 INT C NAT LANG, P40; Lee Mina, 2022, CoAuthor: Designing a Human-AI Collaborative Writing Dataset for Exploring Language Model Capabilities; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu Y., 2019, CoRR abs/1907.11692; Padmakumar V, 2022, Arxiv, DOI arXiv:2111.04193; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Scardamalia M., 1986, HDB RESERCH TEACHING; Singh Nikhil, 2022, ACM Transactions on Computer-Human Interaction; Sommers N., 1980, COLL COMPOS COMMUN, V31, P378, DOI [10.2307/356588, DOI 10.2307/356588]; Sun Simeng., 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, P5972; Vaughan M. M., 1986, 24th Annual Meeting of the Association for Computational Linguistics. Proceedings of the Conference, P90; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xu W., 2016, T ASS COMPUTATIONAL, V4, P401, DOI [DOI 10.1162/TACL_A_00107, DOI 10.1162/TACLA00107]; Zhang J., 2020, PMLR, P11328	23	3	3	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-39-1				2022							96	108						13	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT6ZU					2024-07-03	WOS:000846893900014
J	Ai, QY; Bai, T; Cao, Z; Chang, Y; Chen, JW; Chen, ZM; Cheng, ZY; Dong, SB; Dou, ZC; Feng, FL; Gao, S; Guo, JF; He, XN; Lan, YY; Li, CL; Liu, YQ; Lyu, Z; Ma, WZ; Ma, J; Ren, ZC; Ren, PJ; Wang, ZQ; Wang, MW; Wen, JR; Wu, L; Xin, X; Xu, J; Yin, DW; Zhang, P; Zhang, F; Zhang, WA; Zhang, M; Zhu, XF				Ai, Qingyao; Bai, Ting; Cao, Zhao; Chang, Yi; Chen, Jiawei; Chen, Zhumin; Cheng, Zhiyong; Dong, Shoubin; Dou, Zhicheng; Feng, Fuli; Gao, Shen; Guo, Jiafeng; He, Xiangnan; Lan, Yanyan; Li, Chenliang; Liu, Yiqun; Lyu, Ziyu; Ma, Weizhi; Ma, Jun; Ren, Zhaochun; Ren, Pengjie; Wang, Zhiqiang; Wang, Mingwen; Wen, Ji-Rong; Wu, Le; Xin, Xin; Xu, Jun; Yin, Dawei; Zhang, Peng; Zhang, Fan; Zhang, Weinan; Zhang, Min; Zhu, Xiaofei			Information Retrieval meets Large Language Models: A strategic report from Chinese IR community	AI OPEN			English	Article						Information Retrieval; Language Models; Recommendation system		The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To thoroughly discuss the transformative impact of LLMs on IR research, the Chinese IR community conducted a strategic workshop in April 2023, yielding valuable insights. This paper provides a summary of the workshop's outcomes, including the rethinking of IR's core values, the mutual enhancement of LLMs and IR, the proposal of a novel IR technical paradigm, and open challenges.	[Ai, Qingyao; Lan, Yanyan; Liu, Yiqun; Ma, Weizhi; Zhang, Min] Tsinghua Univ, Beijing, Peoples R China; [Bai, Ting] Beijing Univ Posts & Telecommun, Beijing, Peoples R China; [Cao, Zhao] Huawei Technol Ltd Co, Shenzhen, Peoples R China; [Chang, Yi] Jilin Univ, Changchun, Peoples R China; [Chen, Jiawei] Zhejiang Univ, Zhejiang, Peoples R China; [Chen, Zhumin; Gao, Shen; Ma, Jun; Ren, Zhaochun; Ren, Pengjie; Xin, Xin] Shandong Univ, Jinan, Peoples R China; [Cheng, Zhiyong] Shandong Artificial Intelligence Inst, Jinan, Peoples R China; [Dong, Shoubin] South China Univ Technol, Guangzhou, Peoples R China; [Dou, Zhicheng; Wen, Ji-Rong; Xu, Jun] Renmin Univ China, Beijing, Peoples R China; [Feng, Fuli; He, Xiangnan] Univ Sci & Technol China, Hefei, Peoples R China; [Guo, Jiafeng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; [Li, Chenliang; Zhang, Fan] Wuhan Univ, Wuhan, Peoples R China; [Lyu, Ziyu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Beijing, Peoples R China; [Wang, Zhiqiang] Shanxi Univ, Taiyuan, Peoples R China; [Wang, Mingwen] Jiangxi Normal Univ, Nanchang, Peoples R China; [Wu, Le] Hefei Univ Technol, Hefei, Peoples R China; [Yin, Dawei] Baidu Inc, Beijing, Peoples R China; [Zhang, Peng] Tianjin Univ, Tianjin, Peoples R China; [Zhang, Weinan] Shanghai Jiao Tong Univ, Shanghai, Peoples R China; [Zhu, Xiaofei] Chongqing Univ Technol, Chongqing, Peoples R China	Tsinghua University; Beijing University of Posts & Telecommunications; Huawei Technologies; Jilin University; Zhejiang University; Shandong University; South China University of Technology; Renmin University of China; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS; Wuhan University; Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS; Shanxi University; Jiangxi Normal University; Hefei University of Technology; Baidu; Tianjin University; Shanghai Jiao Tong University; Chongqing University of Technology	Chen, JW (corresponding author), Zhejiang Univ, Zhejiang, Peoples R China.; He, XN (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.; Zhang, P (corresponding author), Tianjin Univ, Tianjin, Peoples R China.	sleepyhunt@zju.edu.cn; hexn@ustc.edu.cn; pzhang@tju.edu.cn	Wang, Zhiqiang/IUN-3896-2023; zhu, xiaofei/HGE-1301-2022	Wang, Zhiqiang/0009-0005-0773-1388; Ai, Qingyao/0000-0002-5030-709X; Dong, Shoubin/0000-0003-0153-850X				Agichtein E., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P19, DOI 10.1145/1148170.1148177; Alfieri A, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P5079, DOI 10.1145/3511808.3557516; [Anonymous], 2013, P 7 ACM C RECOMMENDE; [Anonymous], 2007, P 16 INT C WORLD WID, DOI DOI 10.1145/1242572.1242739; [Anonymous], 2012, ACM SIGKDD INT C KNO; Bao KQ, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1007, DOI 10.1145/3604915.3608857; Berthier R.-N., 1999, MODERN INFORM RETRIE; Blair-Stanek A, 2023, Arxiv, DOI arXiv:2302.06100; Borgeaud S, 2022, PR MACH LEARN RES; Borlund Pia, 2013, Journal of Information Management, V1, P12; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burges CJ, 2010, LEARNING, V11, P23; Chen L., 2012, P 21 INT C WORLD WID, P823; Chen ZM, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-9159-0; Craswell N, 2009, Encyclopedia of Database Systems, DOI 10.1007/978-0-387-39940-9_488; Dennis S, 2002, J AM SOC INF SCI TEC, V53, P120, DOI 10.1002/asi.10015; Duh K., 2008, P 31 ANN INT ACM SIG, P251, DOI DOI 10.1145/1390334.1390379; Edalati A, 2021, Arxiv, DOI arXiv:2110.08152; Esposito D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21206863; Faggioli G, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1935, DOI 10.1145/3404835.3463090; Feng JZ, 2023, Arxiv, DOI arXiv:2305.07402; Ford N, 1999, J DOC, V55, P385, DOI 10.1108/EUM0000000007152; Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916; Fujiwara Y., 2013, P 2013 ACM SIGMOD IN; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Guo JF, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102067; Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769; Guo YY, 2019, ACM T INFORM SYST, V37, DOI 10.1145/3295822; Gur SR, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P111; Guu K, 2020, PR MACH LEARN RES, V119; He HF, 2022, Arxiv, DOI arXiv:2301.00303; He Junxian, 2022, INT C LEARN REPR; Hersh W, 1994, P 17 ANN INT ACM SIG, P192, DOI DOI 10.1007/978-1-4471-2099-5_20; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu ZQ, 2023, Arxiv, DOI arXiv:2304.01933; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; INGWERSEN P, 1984, SOC SCI INFORM STUD, V4, P83, DOI 10.1016/0143-6236(84)90068-1; Izacard G., 2022, arXiv; Izacard G, 2022, Arxiv, DOI [arXiv:2112.09118, DOI 10.48550/ARXIV.2112.09118]; Janner M, 2023, Arxiv, DOI arXiv:2306.08810; Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418; Jeronymo V, 2023, Arxiv, DOI [arXiv:2301.01820, DOI 10.48550/ARXIV.2301.01820]; Jiang YY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P19, DOI 10.1145/3397271.3401070; Jin L, 2013, IEEE COMMUN MAG, V51, P144, DOI 10.1109/MCOM.2013.6588663; John R. I., 2001, Knowledge and Information Systems, V3, P81, DOI 10.1007/PL00011660; Karpukhin V, 2020, Arxiv, DOI [arXiv:2004.04906, 10.48550/arXiv.2004.04906]; Kim SY, 2022, Arxiv, DOI arXiv:2207.02516; Kobayashi M, 2000, ACM COMPUT SURV, V32, P144, DOI 10.1145/358923.358934; Komeili M, 2021, Arxiv, DOI [arXiv:2107.07566, 10.48550/ARXIV.2107.07566, DOI 10.48550/ARXIV.2107.07566]; Lazaridou A, 2022, Arxiv, DOI arXiv:2203.05115; Lee HYJ, 2022, Arxiv, DOI arXiv:2204.13596; Lee N., 2022, Advances in Neural Information Processing Systems, V35, P34586; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li JW, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P994; Li SK, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P223, DOI 10.1145/3477495.3532074; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Llordes M, 2023, Arxiv, DOI arXiv:2304.12631; Manavoglu E, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P203; Manning C.D., 2008, Introduction to information retrieval; Manoj M, 2008, J SCI IND RES INDIA, V67, P739; Mitra Bhaskar, 2017, CoRR abs/1705.01509; Mohsan SAH, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6060147; Mystakidis S., 2022, Encyclopedia, V2, P486, DOI [10.3390/encyclopedia2010031, DOI 10.3390/ENCYCLOPEDIA2010031]; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Ouyang L., 2022, NEURIPS; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pang L, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P257, DOI 10.1145/3132847.3132914; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487; Pi Q, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2671, DOI 10.1145/3292500.3330666; Qin Y., 2023, P ACL 2023 ASS COMP; Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183; Ram O, 2023, Arxiv, DOI arXiv:2302.00083; Ren PJ, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3432726; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Santhanam K., 2022, CoRR abs/2212.01340; Santoro A, 2016, PR MACH LEARN RES, V48; Schick T., 2023, arXiv; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Shenavarmasouleh F., 2022, Cyberphys. Smart Cities Infrastruct.: Optim. Oper. Intell. Decis. Making, P29; Shuster Kurt, 2022, PREPRINT; Su N, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P547, DOI 10.1145/3159652.3159714; Sun WW, 2024, ACM T INFORM SYST, V42, DOI 10.1145/3596510; Sun WW, 2023, Arxiv, DOI arXiv:2304.09542; Sun Y., 2020, P 37 INT C MACHINE L, P9229; Tay Y., 2022, Advances in Neural Information Processing Systems, V35, P21831; Teevan Jaime, 2008, P 31 ANN INT ACM SIG, P163, DOI [DOI 10.1145/1390334.1390364, 10.1145/1390334.1390364]; Trabelsi M, 2021, INFORM RETRIEVAL J, V24, P400, DOI 10.1007/s10791-021-09398-0; Tsvetkov V.Y., 2015, Eur. J. Psychol. Stud., P37; Vargas S., 2011, P 5 ACM C REC SYST, P109, DOI [DOI 10.1145/2043932.2043955, 10.1145/2043932.2043955]; Vassileva J, 2012, USER MODEL USER-ADAP, V22, P177, DOI 10.1007/s11257-011-9109-5; Wang BX, 2023, Arxiv, DOI arXiv:2304.06762; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Xu C, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2590, DOI 10.1145/3394486.3403309; Xu D, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P920, DOI 10.1145/3543873.3589755; Yang L, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P99, DOI 10.1145/2505515.2505720; Yin HZ, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3579995; Yuan FJ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1469, DOI 10.1145/3397271.3401156; Zamani H, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2875, DOI 10.1145/3477495.3531722; Zhan JT, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2486, DOI 10.1145/3511808.3557312; Zhang JZ, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P993, DOI 10.1145/3604915.3608860; Zhang Kai, 2014, P 23 ACM INT C C INF, P371, DOI [10.1145/2661829.2661908, DOI 10.1145/2661829.2661908]; Zhang QR, 2023, Arxiv, DOI arXiv:2303.10512; Zhen LL, 2019, PROC CVPR IEEE, P10386, DOI 10.1109/CVPR.2019.01064; Zheng JW, 2023, Arxiv, DOI arXiv:2304.09333; Zheng Y., 2010, IEEE Data(base) Eng. Bull.; Zhong PX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6556; Zhu M, 2004, Recall, Precision and Average Precision; Zhu MJ, 2022, P IEEE, V110, P246, DOI 10.1109/JPROC.2021.3140049	119	0	0	0	0	KEAI PUBLISHING LTD	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, Building 5, Room 411, BEIJING, DONGCHENG DISTRICT 100009, PEOPLES R CHINA		2666-6510		AI OPEN	AI Open		2023	4						80	90		10.1016/j.aiopen.2023.08.001	http://dx.doi.org/10.1016/j.aiopen.2023.08.001			11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	QP9H0		Green Submitted, gold			2024-07-03	WOS:001222186000001
C	Sanner, S; Balog, K; Radlinski, F; Wedin, B; Dixon, L			ACM	Sanner, Scott; Balog, Krisztian; Radlinski, Filip; Wedin, Ben; Dixon, Lucas			Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		recommendation; transparency; scrutability; natural language		Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods, despite having no supervised training for this specific task (zero-shot) or only a few labels (few-shot). This is particularly promising as language-based preference representations are more explainable and scrutable than item-based or vector-based representations.	[Sanner, Scott] Univ Toronto, Toronto, ON, Canada; [Balog, Krisztian] Google, Stavanger, Norway; [Radlinski, Filip] Google, London, England; [Wedin, Ben] Google, Cambridge, MA USA; [Dixon, Lucas] Google, Paris, France	University of Toronto; Google Incorporated; Google Incorporated; Google Incorporated; Google Incorporated	Sanner, S (corresponding author), Univ Toronto, Toronto, ON, Canada.	ssanner@mie.utoronto.ca; krisztianb@google.com; filiprad@google.com; wedin@google.com; ldixon@google.com	Balog, Krisztian/AAJ-8229-2020	Balog, Krisztian/0000-0003-2762-721X; Sanner, Scott/0000-0001-7984-8394; Wedin, Ben/0009-0003-5389-1230; Radlinski, Filip/0000-0002-1386-9288				Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Balog K, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P890, DOI 10.1145/3404835.3462893; Balog K, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P265, DOI 10.1145/3331184.3331211; Bogers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P238, DOI 10.1145/3109859.3109893; Borisov V, 2023, Arxiv, DOI [arXiv:2210.06280, 10.48550/arXiv.2210.06280]; Chaganty AT, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2754, DOI 10.1145/3539618.3591881; Chen HY, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P92, DOI 10.1145/3523227.3546788; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746; Dacrema MF, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P101, DOI 10.1145/3298689.3347058; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Friedman L, 2023, Arxiv, DOI arXiv:2305.07961; Gantner Zeno, 2011, RECSYS, P305, DOI 10.1145/2043932.2043989; Gao CM, 2021, AI OPEN, V2, P100, DOI 10.1016/j.aiopen.2021.06.002; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Hada DV, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P81, DOI 10.1145/3404835.3462939; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hou YP, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P585, DOI 10.1145/3534678.3539381; Hu Fangwei, 2013, P ACM C RECOMMENDER, P331; Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22; Jannach D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3453154; Kaminskas M, 2017, ACM T INTERACT INTEL, V7, DOI 10.1145/2926720; Kang J, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P229, DOI 10.1145/3109859.3109873; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Liang DW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P689, DOI 10.1145/3178876.3186150; Lops P, 2011, RECOMMENDER SYSTEMS HANDBOOK, P73, DOI 10.1007/978-0-387-85820-3_3; Malkiel I., 2020, arXiv; Mysore S, 2023, Arxiv, DOI arXiv:2306.02250; Mysore S, 2023, Arxiv, DOI arXiv:2304.04250; Nazari Z, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2433, DOI 10.1145/3485447.3512115; Pellegrini R, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P188, DOI 10.1145/3523227.3546753; Penha G, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P388, DOI 10.1145/3383313.3412249; Radlinski F, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2863, DOI 10.1145/3477495.3531873; Rendle S., 2012, Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009), DOI [DOI 10.5555/1795114.1795167, 10.48550/arXiv.1205.2618]; Rokach L, 2012, IEEE T SYST MAN CY C, V42, P1854, DOI 10.1109/TSMCC.2012.2197679; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI [10.1145/371920.372071, DOI 10.1145/371920.372071]; Sepliarskaia A, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P172, DOI 10.1145/3240323.3240352; Steck H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3251, DOI 10.1145/3308558.3313710; Verplanken B, 1999, EUR J SOC PSYCHOL, V29, P591, DOI 10.1002/(SICI)1099-0992(199908/09)29:5/6<591::AID-EJSP948>3.0.CO;2-H; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Xia Ning, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P497, DOI 10.1109/ICDM.2011.134; Zemlyanskiy Y, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2540	45	3	3	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							890	896		10.1145/3604915.3608845	http://dx.doi.org/10.1145/3604915.3608845			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Bronze, Green Submitted			2024-07-03	WOS:001156630300099
J	Park, YJ; Kaplan, D; Ren, ZC; Hsu, CW; Li, CH; Xu, HW; Li, SP; Li, J				Park, Yang Jeong; Kaplan, Daniel; Ren, Zhichu; Hsu, Chia-Wei; Li, Changhao; Xu, Haowei; Li, Sipei; Li, Ju			Can ChatGPT be used to generate scientific hypotheses?	JOURNAL OF MATERIOMICS			English	Article						large language models; scientific hypothesis generation; generative AI; GPT-4		We investigate whether large language models can perform the creative hypothesis generation that human researchers regularly do. While the error rate is high, generative AI seems to be able to effectively structure vast amounts of scientific knowledge and provide interesting and testable hypotheses. The future scientific enterprise may include synergistic efforts with a swarm of "hypothesis machines", challenged by automated experimentation and adversarial peer reviews. (c) 2023 The Authors. Published by Elsevier B.V. on behalf of The Chinese Ceramic Society. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	[Park, Yang Jeong; Li, Changhao; Xu, Haowei; Li, Sipei; Li, Ju] MIT, Dept Nucl Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Park, Yang Jeong] Seoul Natl Univ, Inst New Media & Commun, 1 Gwanak Ro, Seoul 08826, South Korea; [Kaplan, Daniel] Weizmann Inst Sci, Dept Condensed Matter Phys, IL-7610001 Rehovot, Israel; [Ren, Zhichu; Hsu, Chia-Wei; Li, Ju] MIT, Dept Mat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Li, Changhao] JPMorgan Chase, Global Technol Appl Res, 237 Pk Ave, New York, NY 10017 USA	Massachusetts Institute of Technology (MIT); Seoul National University (SNU); Weizmann Institute of Science; Massachusetts Institute of Technology (MIT); JP Morgan Chase & Company	Li, J (corresponding author), MIT, Dept Nucl Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	liju@mit.edu	Li, Ju/A-2993-2008	Li, Ju/0000-0002-7841-8058; Kaplan, Daniel/0000-0002-3957-0030	National Research Foundation of Korea (NRF) - Korean government, Ministry of Science and ICT (MSIT) [2021R1A6A3A01086766]	National Research Foundation of Korea (NRF) - Korean government, Ministry of Science and ICT (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	This work was supported by a grant from the National Research Foundation of Korea (NRF) funded by the Korean government, Ministry of Science and ICT (MSIT) (No. 2021R1A6A3A01086766) .	Andrich P, 2017, NPJ QUANTUM INFORM, V3, DOI 10.1038/s41534-017-0029-z; APPEL K, 1977, ILLINOIS J MATH, V21, P429, DOI 10.1215/ijm/1256049011; Boiko DA, 2023, Arxiv, DOI [arXiv:2304.05332, DOI 10.48550/ARXIV.2304.05332]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2; Di Sipio R, 2022, INT CONF ACOUST SPEE, P8612, DOI 10.1109/ICASSP43922.2022.9747675; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; HANAK JJ, 1970, J MATER SCI, V5, P964, DOI 10.1007/BF00558177; Krenn M, 2022, Arxiv, DOI arXiv:2210.00881; KRIGE DG, 1994, J S AFR I MIN METALL, V94, P95; Layden D, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.040502; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; [刘知远 Liu Zhiyuan], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P247; Luccioni A. S., 2022, arXiv, DOI 10.48550/ARXIV.2211.02001; Morgan D, 2022, CURR OPIN SOLID ST M, V26, DOI 10.1016/j.cossms.2021.100975; Onen M, 2022, SCIENCE, V377, P539, DOI 10.1126/science.abp8064; Radford A, 2021, PR MACH LEARN RES, V139; Rao MY, 2023, NATURE, V615, P823, DOI 10.1038/s41586-023-05759-5; Ren Z, 2023, ChemRxiv; Ren ZC, 2023, NAT REV MATER, V8, P563, DOI 10.1038/s41578-023-00588-4; Rui R.Z., APPL ENERGY SPECIAL; RuiR Z., MIT ATHORNB APPL ENE; Suri K, 2023, Language models sounds the death knell of knowledge graphs; Takamoto S, 2023, J MATERIOMICS, V9, P447, DOI 10.1016/j.jmat.2022.12.007; Taori R, 2023, Alpaca	25	0	0	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-8478			J MATERIOMICS	J. Materiomics	MAY	2024	10	3					578	584		10.1016/j.jmat.2023.08.007	http://dx.doi.org/10.1016/j.jmat.2023.08.007			7	Chemistry, Physical; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Materials Science; Physics	RW4E2		gold, Green Submitted			2024-07-03	WOS:001230675800001
J	Neyem, A; González, LA; Mendoza, M; Alcocer, JPS; Centellas, L; Paredes, C				Neyem, Andres; Gonzalez, Luis A.; Mendoza, Marcelo; Alcocer, Juan Pablo Sandoval; Centellas, Leonardo; Paredes, Carlos			Toward an AI Knowledge Assistant for Context-Aware Learning Experiences in Software Capstone Project Development	IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES			English	Article						Software; Artificial intelligence; Task analysis; Software engineering; Codes; Chatbots; Knowledge engineering; Capstone courses; ChatGPT; context-aware learning; generative artificial intelligence (AI); large language models (LLMs); software engineering education	READABILITY	Software assistants have significantly impacted software development for both practitioners and students, particularly in capstone projects. The effectiveness of these tools varies based on their knowledge sources; assistants with localized domain-specific knowledge may have limitations, while tools, such as ChatGPT, using broad datasets, might offer recommendations that do not always match the specific objectives of a capstone course. Addressing a gap in current educational technology, this article introduces an AI Knowledge Assistant specifically designed to overcome the limitations of the existing tools by enhancing the quality and relevance of large language models (LLMs). It achieves this through the innovative integration of contextual knowledge from a local "lessons learned" database tailored to the capstone course. We conducted a study with 150 students using the assistant during their capstone course. Integrated into the Kanban project tracking system, the assistant offered recommendations using different strategies: direct searches in the lessons learned database, direct queries to a generative pretrained transformers (GPT) model, query enrichment with lessons learned before submission to GPT and large language model meta AI (LLaMa) models, and query enhancement with Stack Overflow data before GPT processing. Survey results underscored a strong preference among students for direct LLM queries and those enriched with local repository insights, highlighting the assistant's practical value. Furthermore, our linguistic analysis conclusively demonstrated that texts generated by the LLM closely mirrored the linguistic standards and topical relevance of university course requirements. This alignment not only fosters a deeper understanding of course content but also significantly enhances the material's applicability to real-world scenarios.	[Neyem, Andres; Gonzalez, Luis A.; Mendoza, Marcelo; Alcocer, Juan Pablo Sandoval; Centellas, Leonardo; Paredes, Carlos] Pontificia Univ Catolica Chile, Fac Engn, Dept Comp Sci, Santiago 7810000, Chile	Pontificia Universidad Catolica de Chile	Mendoza, M (corresponding author), Pontificia Univ Catolica Chile, Fac Engn, Dept Comp Sci, Santiago 7810000, Chile.	aneyem@uc.cl; lagonza2@uc.cl; marcelo.mendoza@uc.cl; juanpablo.sandoval@uc.cl; lcentellas@uc.cl; cparedesr@uc.cl	Sandoval Alcocer, Juan Pablo/CAA-0465-2022	Sandoval Alcocer, Juan Pablo/0000-0002-8335-4351	National Center for Artificial Intelligence	National Center for Artificial Intelligence	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brooks R.M., 2004, The Journal of General Education, V53, P275; Campos EC, 2016, J SOFTW-EVOL PROC, V28, P863, DOI 10.1002/smr.1800; Carr SA, 2017, IEEE T SOFTWARE ENG, V43, P701, DOI 10.1109/TSE.2016.2625248; Carvalho A, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20), P161, DOI [10.1109/SANER48275.2020.9054842, 10.1109/saner48275.2020.9054842]; Chall J., 1995, READABILITY REVISITE; Cordeiro J., 2012, 2012 Third International Workshop on Recommendation Systems for Software Engineering (RSSE), P85, DOI 10.1109/RSSE.2012.6233418; Correa D, 2013, IEEE AUS SOFT ENGR, P88, DOI 10.1109/ASWEC.2013.20; Daun M, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P110, DOI 10.1145/3587102.3588815; De Souza L. B. L., 2014, P IEEE INT C PROG CO, P72, DOI DOI 10.1145/2597008.2597146; Dempere J, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1206936; Gunning R., 1968, TECHNIQUE CLEAR WRIT; He H, 2021, PROC IEEE ACM INT C, P9, DOI 10.1109/ICSE-Companion52605.2021.00023; Ilic A., 2020, P 24 INT C INF TECHN, P1; Kinsman T, 2021, IEEE WORK CONF MIN S, P420, DOI 10.1109/MSR52588.2021.00054; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Mahnic V, 2012, IEEE T EDUC, V55, P99, DOI 10.1109/TE.2011.2142311; Murgia A., 2016, P CHI C EXT ABSTR HU, P1272, DOI [10.1145/2851581.2892311, DOI 10.1145/2851581.2892311]; Neyem A, 2014, PROCEEDINGS OF THE 45TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'14), P391, DOI 10.1145/2538862.2538920; Ponzanelli L, 2017, PROC INT CONF SOFTW, P94, DOI 10.1109/ICSE.2017.17; Pu P., 2011, P 5 ACM C REC SYST, P157, DOI [10.1145/2043932.2043962, DOI 10.1145/2043932.2043962]; Rahman MM, 2014, 2014 SOFTWARE EVOLUTION WEEK - IEEE CONFERENCE ON SOFTWARE MAINTENANCE, REENGINEERING, AND REVERSE ENGINEERING (CSMR-WCRE), P194, DOI 10.1109/CSMR-WCRE.2014.6747170; Ramandanis D, 2023, INFORMATION, V14, DOI 10.3390/info14090503; Randall N, 2024, IEEE SOFTWARE, V41, P36, DOI 10.1109/MS.2023.3344682; RUSH RT, 1985, READ TEACH, V39, P274; Santhanam S, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.866; Savary-Leblanc M, 2023, SOFTWARE PRACT EXPER, V53, P856, DOI 10.1002/spe.3170; Schneider JG, 2020, 2020 ACM/IEEE 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET 2020), P119, DOI 10.1145/3377814.3381715; Shihab E, 2022, IEEE SOFTWARE, V39, P28, DOI 10.1109/MS.2022.3176864; Stulova N, 2020, IEEE INT WORK C SO, P65, DOI 10.1109/SCAM51674.2020.00012; Teyton C, 2013, WORK CONF REVERSE EN, P202, DOI 10.1109/WCRE.2013.6671295; Thies A., 2010, P 2 INT WORKSH REC S, P1; THOMAS G, 1975, J READING BEHAV, V7, P149, DOI 10.1080/10862967509547131; Thomas K, 2014, HIGH EDUC RES DEV, V33, P580, DOI 10.1080/07294360.2013.841646; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wessel Mairieli, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274451; Wessel M, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-023-10369-w; Zhou Y, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1510, DOI 10.1145/3468264.3473111; Zhou Y, 2020, IEEE T SOFTWARE ENG, V46, P1004, DOI 10.1109/TSE.2018.2872971	39	0	0	7	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1939-1382			IEEE T LEARN TECHNOL	IEEE Trans. Learn. Technol.		2024	17						1639	1654		10.1109/TLT.2024.3396735	http://dx.doi.org/10.1109/TLT.2024.3396735			16	Computer Science, Interdisciplinary Applications; Education & Educational Research	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Education & Educational Research	SP0W2					2024-07-03	WOS:001235546700003
C	Sultanum, N; Srinivasan, A			IEEE	Sultanum, Nicole; Srinivasan, Arjun			DATATALES: Investigating the use of Large Language Models for Authoring Data-Driven Articles	2023 IEEE VISUALIZATION AND VISUAL ANALYTICS, VIS	IEEE Visualization Conference		English	Proceedings Paper	IEEE Conference on Visualization and Visual Analytics (IEEE VIS)	OCT 22-27, 2023	Melbourne, AUSTRALIA	IEEE, IEEE Comp Soc, IEEE VGTC		Human-centered computing; Visualization; Visualization design and evaluation methods		Authoring data-driven articles is a complex process requiring authors to not only analyze data for insights but also craft a cohesive narrative that effectively communicates the insights. Text generation capabilities of contemporary large language models (LLMs) present an opportunity to assist the authoring of data-driven articles and expedite the writing process. In this work, we investigate the feasibility and perceived value of leveraging LLMs to support authors of data-driven articles. We designed a prototype system, DATATALES, that leverages a LLM to generate textual narratives accompanying a given chart. Using DATATALES as a design probe, we conducted a qualitative study with 11 professionals to evaluate the concept, from which we distilled affordances and opportunities to further integrate LLMs as valuable data-driven article authoring assistants.	[Sultanum, Nicole; Srinivasan, Arjun] Tableau Res, Seattle, WA 98103 USA		Sultanum, N (corresponding author), Tableau Res, Seattle, WA 98103 USA.	nsultanum@tableau.com; arjunsrinivasan@tableau.com	Sultanum, Nicole/JXM-6470-2024	Sultanum, Nicole/0000-0001-8608-1427				Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472; Conlen Matthew, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P1, DOI 10.1145/3472749.3474731; Dang H, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580969; Dang H, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545672; Danry V, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580672; Fang XX, 2023, EDUC INF TECHNOL, V28, P14361, DOI 10.1007/s10639-023-11741-5; Gao T, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P489, DOI 10.1145/2807442.2807478; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Kim Y, 2018, COMPUT GRAPH FORUM, V37, P157, DOI 10.1111/cgf.13409; King CL, 2012, IEEE T PROF COMMUN, V55, P254, DOI 10.1109/TPC.2012.2207838; Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241; Latif S., 2019, EuroVis (Short Papers); Latif S., 2018, EUROVIS SHORT PAPERS; Latif S, 2022, IEEE T VIS COMPUT GR, V28, P184, DOI 10.1109/TVCG.2021.3114802; Lee B, 2015, IEEE COMPUT GRAPH, V35, P84, DOI 10.1109/MCG.2015.99; Li B, 2023, Arxiv, DOI arXiv:2304.11633; Li H., 2023, P 2023 CHI C HUMAN F, P1; Li HT, 2023, Arxiv, DOI arXiv:2304.08366; Lundgard A, 2022, IEEE T VIS COMPUT GR, V28, P1073, DOI 10.1109/TVCG.2021.3114770; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Narechania A, 2021, IEEE T VIS COMPUT GR, V27, P369, DOI 10.1109/TVCG.2020.3030378; Obeid J, 2020, Arxiv, DOI arXiv:2010.09142; Petridis S, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580907; Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599; Saket B, 2019, IEEE T VIS COMPUT GR, V25, P2505, DOI 10.1109/TVCG.2018.2829750; Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179; Shen L., 2021, arXiv; Shi DQ, 2021, IEEE T VIS COMPUT GR, V27, P453, DOI 10.1109/TVCG.2020.3030403; Singh Nikhil, 2022, ACM Transactions on Computer-Human Interaction; Spencer J., 2023, The Future of Writing in a World of Artificial Intelligence #ChatGPT; Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145; Stolper C. D., 2016, Emerging and Recurring data-driven Storytelling Techniques: Analysis of a Curated Collection of Recent Stories; Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354; Sun M., 2022, IEEE Transactions on Visualization and Computer Graphics, V29, P983, DOI 10.1109/TVCG.2022.32094281,2,3,4; Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357; Wang Y, 2020, IEEE T VIS COMPUT GR, V26, P895, DOI 10.1109/TVCG.2019.2934398; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zacks J, 1999, MEM COGNITION, V27, P1073, DOI 10.3758/BF03201236; Zhang TH, 2023, Arxiv, DOI arXiv:2304.03728; Zhang Z, 2023, Arxiv, DOI arXiv:2304.07810	41	1	1	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2771-9537	2771-9553	979-8-3503-2557-7	IEEE VIS CONF			2023							231	235		10.1109/VIS54172.2023.00055	http://dx.doi.org/10.1109/VIS54172.2023.00055			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3FG		Green Submitted, Bronze			2024-07-03	WOS:001137142800047
C	Wei, YX; Xia, CQS; Zhang, LM		Chandra, S; Blincoe, K; Tonella, P		Wei, Yuxiang; Xia, Chunqiu Steven; Zhang, Lingming			Copiloting the Copilots: Fusing Large Language Models with Completion Engines for Automated Program Repair	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Program Repair; Large Language Model; Completion Engine		During Automated Program Repair (APR), it can be challenging to synthesize correct patches for real-world systems in general-purpose programming languages. Recent Large Language Models (LLMs) have been shown to be helpful "copilots" in assisting developers with various coding tasks, and have also been directly applied for patch synthesis. However, most LLMs treat programs as sequences of tokens, meaning that they are ignorant of the underlying semantics constraints of the target programming language. This results in plenty of statically invalid generated patches, impeding the practicality of the technique. Therefore, we propose Repilot, a general code generation framework to further copilot the AI "copilots" (i.e., LLMs) by synthesizing more valid patches during the repair process. Our key insight is that many LLMs produce outputs autoregressively (i.e., token by token), resembling human writing programs, which can be significantly boosted and guided through a Completion Engine. Repilot synergistically synthesizes a candidate patch through the interaction between an LLM and a Completion Engine, which 1) prunes away infeasible tokens suggested by the LLM and 2) proactively completes the token based on the suggestions provided by the Completion Engine. Our evaluation on a subset of the widely-used Defects4j 1.2 and 2.0 datasets shows that Repilot outperforms state-of-the-art techniques by fixing 27% and 47% more bugs, respectively. Moreover, Repilot produces more valid and correct patches than the base LLM with the same budget. While we focus on leveraging Repilot for APR in this work, the overall approach is also generalizable to other code generation tasks.	[Wei, Yuxiang; Xia, Chunqiu Steven; Zhang, Lingming] Univ Illinois, Urbana, IL 61801 USA	University of Illinois System; University of Illinois Urbana-Champaign	Wei, YX (corresponding author), Univ Illinois, Urbana, IL 61801 USA.	ywei40@illinois.edu; chunqiu2@illinois.edu; lingming@illinois.edu		Wei, Yuxiang/0000-0002-4391-3753	NSF [CCF-2131943, CCF-2141474]; Kwai Inc.	NSF(National Science Foundation (NSF)); Kwai Inc.	We thank all the reviewers for their insightful comments. We also thank Yifeng Ding for his helpful discussion on this work. This work was partially supported by NSF grants CCF-2131943 and CCF-2141474, as well as Kwai Inc.	Aghajanyan A, 2022, Arxiv, DOI [arXiv:2201.07520, 10.48550/arXiv.2201.07520]; Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; [Anonymous], 2014, P 6 INT WORKSHOP CON, DOI 10.1145/2593735.2593740; [Anonymous], 2023, Eclipse JDT LS; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Barr ET, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P306, DOI 10.1145/2635868.2635898; Cao JL, 2023, Arxiv, DOI [arXiv:2304.08191, 10.48550/arXiv.2304.08191, 10.48550/ARXIV.2304.08191]; Chen LS, 2017, IEEE INT CONF AUTOM, P637, DOI 10.1109/ASE.2017.8115674; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Clojure, 2023, Typed Clojure: An Optional Type System for Clojure; Deng YL, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P423, DOI 10.1145/3597926.3598067; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding Y, 2023, Arxiv, DOI arXiv:2310.11248; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Fried Daniel, 2023, 11 INT C LEARN REPR; Gazzola L, 2019, IEEE T SOFTWARE ENG, V45, P34, DOI 10.1109/TSE.2017.2755013; Ghanbari A, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P19, DOI 10.1145/3293882.3330559; GithubCopilot, 2023, GitHub Copilot: Your AI pair programmer; Guo D., 2021, ICLR; Holtzman A., 2019, INT C LEARNING REPRE; Hua JR, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P888, DOI 10.1145/236024.3264600; HuggingFace, 2023, about us; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Jiang YJ, 2021, PROC INT CONF SOFTW, P686, DOI 10.1109/ICSE43902.2021.00069; Joshi Harshit, 2023, Repair Is Nearly Generation: Multilingual Program Repair with LLMs; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Kolak S. D., 2022, DEEP LEARN COD WORKS; Koyuncu A, 2020, EMPIR SOFTW ENG, V25, P1980, DOI 10.1007/s10664-019-09780-z; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Le XBD, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P593, DOI 10.1145/3106237.3106309; Le XBD, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P213, DOI 10.1109/SANER.2016.76; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu K, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3579637; Liu K, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P31, DOI 10.1145/3293882.3330577; Long F, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P166, DOI 10.1145/2786805.2786811; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Martinez M., 2016, P 25 INT S SOFTWARE, P441, DOI [10.1145/2931037.2948705, DOI 10.1145/2931037.2948705, 10.1145/2931037]; Martinez M, 2017, EMPIR SOFTW ENG, V22, P1936, DOI 10.1007/s10664-016-9470-4; Mechtaev S, 2016, PROC INT CONF SOFTW, P691, DOI 10.1145/2884781.2884807; Microsoft, 2023, Language Server Protocol; Microsoft, 2023, TypeScript; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Poesia Gabriel, 2022, INT C LEARN REPR; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Python, 2023, Type Hints in Python; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Sutskever I, 2014, ADV NEUR IN, V27; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei Yuxiang, 2023, Zenodo, DOI 10.5281/ZENODO.8281250; Wei Yuxiang, 2023, UniverseFly/ eclipse. jdt. ls: Modi, DOI [10.5281/zenodo.8278193EclipseJDTLS, DOI 10.5281/ZENODO.8278193ECLIPSEJDTLS]; Wen M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/3180155.3180233; Xia C.S., 2023, arXiv; Xia CS, 2024, Arxiv, DOI arXiv:2308.04748; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xia CS, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P959, DOI 10.1145/3540250.3549101; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xia CS, 2023, Arxiv, DOI [arXiv:2303.10494, DOI 10.48550/ARXIV.2303.10494]; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yang ZL, 2019, ADV NEUR IN, V32; Ye H, 2022, PROC INT CONF SOFTW, P1506, DOI 10.1145/3510003.3510222; Zhang FJ, 2023, Arxiv, DOI arXiv:2303.12570; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	74	1	1	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							172	184		10.1145/3611643.3616271	http://dx.doi.org/10.1145/3611643.3616271			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted			2024-07-03	WOS:001148157800016
C	Ratner, N; Levine, Y; Belinkov, Y; Ram, O; Magar, I; Abend, O; Karpas, E; Shashua, A; Leyton-Brown, K; Shoham, Y		Rogers, A; Boyd-Graber, J; Okazaki, N		Ratner, Nir; Levine, Yoav; Belinkov, Yonatan; Ram, Ori; Magar, Inbal; Abend, Omri; Karpas, Ehud; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav			Parallel ContextWindows for Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				When applied to processing long text, Large Language Models (LLMs) are limited by their context window. Existing efforts to address this limitation involve training specialized architectures, and cannot be easily applied to offthe-shelf LLMs. We present Parallel Context Windows (PCW), a method that alleviates the context window restriction for any off-the-shelf LLM without further training. The key to the approach is to carve a long context into chunks ("windows"), restrict the attention mechanism to apply only within each window, and re-use the positional embeddings across the windows. Our main results test the PCW approach on in-context learning with models that range in size between 750 million and 178 billion parameters, and show substantial improvements for tasks with diverse input and output spaces. We show additional benefits in other settings where long context windows may be beneficial: multi-hop questions and retrieval-augmented question answering with multiple retrieved documents. Our results highlight Parallel Context Windows as a promising method for applying off-the-shelf LLMs in a range of settings that require long text sequences. We make our code publicly available at https://github.com/ ai21labs/parallel-context-windows.	[Ratner, Nir; Levine, Yoav; Belinkov, Yonatan; Ram, Ori; Magar, Inbal; Abend, Omri; Karpas, Ehud; Shashua, Amnon; Leyton-Brown, Kevin; Shoham, Yoav] AI21 Labs, Tel Aviv, Israel		Ratner, N (corresponding author), AI21 Labs, Tel Aviv, Israel.	nirr@ai21.com						Alex Neel, 2021, RAFT REAL WORLD FEW; [Anonymous], 2008, A holistic lexicon-based approach to opinion mining, DOI DOI 10.1145/1341531.1341561; Bartolo M, 2020, T ASSOC COMPUT LING, V8, P662, DOI 10.1162/tacl_a_00338; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Casanueva Inigo, 2020, P 2 WORKSH NLP CONVA; Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177; de Marneffe Marie-Catherine, 2019, The commitmentbank: Investigating projection in naturally occurring discourse; Guo Mandy, 2021, Longt5: Efficient text-to-text transformer for long sequences; Han Zhixiong, 2022, PROTOTYPICAL CALIBRA; Hao Yaru, 2022, Structured prompting: Scaling in-context learning to 1,000 examples; Hemphill J. J., 1990, P SPEECH NAT LANG WO, P96; Ivgi Maor, 2022, Efficient Long-Text Understanding with Short-Text Models; Izacard Gautier, 2020, arXiv preprint arXiv:2007.01282; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Larson S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1311; Lazaridou Angeliki, 2022, Internet-augmented language models through few-shot prompting for open-domain question answering; Levine Yoav, 2022, Huge frozen language models as readers for open-domain question answering; Levine Yoav, 2022, ARXIV220410019; Lhoest Q, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P175; Li Xin, 2002, COLING 2002 19 INT C; Lieber O., 2021, JURASSIC 1 TECHNICAL; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Liu J., 2012, INTERSPEECH; Lu Yao, 2021, FANTASTICALLY ORDERE; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Min Sewon, 2021, NOISY CHANNEL LANGUA; Mostafazadeh N., 2017, Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics, LSDSem@EACL 2017, Valencia, Spain, April 3, 2017, P46, DOI [DOI 10.18653/V1/W17-0906, 10.18653/v1/w17-0906]; Pang Bo, 2004, CSCL0409058 CORR; Press O., 2022, INT C LEARN REPR; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Shaham Uri, 2022, ARXIV220103533; Smith Lewis Noah Mike, 2022, INT C LEARN REPR; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Swietojanski Pawel, 2019, P 10 INT WORKSH SPOK; Tay Yi, 2020, ARXIV201104006; Vaswani A, 2017, ADV NEUR IN, V30; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Zaheer Manzil, 2020, Big bird: Transformers for longer sequences; Zhang X, 2015, ADV NEUR IN, V28; Zhang Xiang, 2015, ADV NEURAL INFORM PR, P649, DOI DOI 10.5555/2969239.2969312; Zhao Tony Z., 2021, Calibrate before use: Improving few-shot performance of language models	44	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							6383	6402						20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086805023
C	Saier, T; Ohta, M; Asakura, T; Färber, M		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Saier, Tarek; Ohta, Mayumi; Asakura, Takuto; Faerber, Michael			HyperPIE: Hyperparameter Information Extraction from Scientific Publications	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Information Extraction; Scientific Text; Hyperparameter		Automatic extraction of information from publications is key to making scientific knowledge machine-readable at a large scale. The extracted information can, for example, facilitate academic search, decision making, and knowledge graph construction. An important type of information not covered by existing approaches is hyperparameters. In this paper, we formalize and tackle hyperparameter information extraction (HyperPIE) as an entity recognition and relation extraction task. We create a labeled data set covering publications from a variety of computer science disciplines. Using this data set, we train and evaluate BERT-based fine-tuned models as well as five large language models: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned models, we develop a relation extraction approach that achieves an improvement of 29% F-1 over a state-of-the-art baseline. For large language models, we develop an approach leveraging YAML output for structured data extraction, which achieves an average improvement of 5.5% F-1 in entity recognition over using JSON. With our best performing model we extract hyperparameter information from a large number of unannotated papers, and analyze patterns across disciplines. All our data and source code is publicly available at https://github.com/IllDepence/hyperpie.	[Saier, Tarek; Faerber, Michael] Karlsruhe Inst Technol, Karlsruhe, Germany; [Ohta, Mayumi] Fraunhofer Inst Syst & Innovat Res, Karlsruhe, Germany; [Asakura, Takuto] Univ Tokyo, Tokyo, Japan	Helmholtz Association; Karlsruhe Institute of Technology; Fraunhofer Gesellschaft; University of Tokyo	Saier, T (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.	tarek.saier@kit.edu; mayumi.ohta@isi.fraunhofer.de; takuto@is.s.u-tokyo.ac.jp; michael.faerber@kit.edu		Ohta, Mayumi/0000-0001-5354-5571; Farber, Michael/0000-0001-5458-8645	German Federal Ministry of Education and Research (BMBF) [01IS17042]; state of Baden-Wurttemberg through bwHPC	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); state of Baden-Wurttemberg through bwHPC	This work was partially supported by the German Federal Ministry of Education and Research (BMBF) via [KOM,BI], a Software Campus project (01IS17042). The authors acknowledge support by the state of Baden-Wurttemberg through bwHPC. We thank Nicholas Popovic for extensive feedback on the experiment design and prompt engineering. We thank Tarek Gaddour for feedback during the annotation scheme development, and Xiao Ning for input during early model development.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Auer S, 2020, BIBL FORSCH PRAX, V44, P516, DOI 10.1515/bfp-2020-2042; Baudart G., 2020, P 7 ICML WORKSH AUT; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen SY, 2023, Arxiv, DOI arXiv:2306.15595; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dunn A., 2022, arXiv; Harper C., 2021, P 15 INT WORKSHOP SE, P306, DOI 10.18653/v1/2021.semeval-1.38; Jain S., 2020, P 58 ANN M ASS COMPU, P7506, DOI [10 .18653/v1/2020.acl-main.670, DOI 10.18653/V1/2020.ACLMAIN.670]; Kojima T, 2022, ADV NEUR IN; Kuhn T, 2014, COMPUT LINGUIST, V40, P121, DOI 10.1162/COLI_a_00168; Lai V., 2022, P 16 INT WORKSHOP SE, P1671, DOI [10.18653/v1/2022.semeval-1.230, DOI 10.18653/V1/2022.SEMEVAL-1.230]; Liesenfeld A, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3604316; Lin JL, 2022, SCIENTOMETRICS, V127, P2395, DOI 10.1007/s11192-022-04334-5; Luan Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3219; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; QasemiZadeh B, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1862; Raff E, 2019, ADV NEUR IN, V32; Rak-Amnouykit I., 2021, ICLR WORKSH SEC SAF; Saier T, 2023, ACM-IEEE J CONF DIG, P66, DOI 10.1109/JCDL57899.2023.00020; Sethi A, 2018, AAAI CONF ARTIF INTE, P7339; Stocker M., 2023, FAIR CONNECT, V1, DOI [DOI 10.3233/FC-221513, 10.3233/fc-221513]; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Taylor R., 2022, Galactica: A large language model for science; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Xie T, 2023, Arxiv, DOI arXiv:2304.02213; Xu C., 2023, Wizardlm: Empowering large language models to follow complex instructions; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Ye DM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4904	32	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						254	269		10.1007/978-3-031-56060-6_17	http://dx.doi.org/10.1007/978-3-031-56060-6_17			16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY		Green Submitted			2024-07-03	WOS:001211832000017
J	Peng, X				Peng, Xin			Software development in the age of intelligence: embracing large language models with the right approach	FRONTIERS OF INFORMATION TECHNOLOGY & ELECTRONIC ENGINEERING			English	Editorial Material						ChatGPT		The emergence of large language models(LLMs), represented by ChatGPT, has had a pro-found impact on various fields, including software engineering, and has also aroused widespread concerns. To see a right way through the fog, we have recently been discussing and contemplating a theme of "software development in the age of LLMs," or rather "the capability of LLMs in software development," based on various technical literature, shared experiences, and our own preliminary explorations. Additionally, I have participated in several online interviews and discussions on the theme, which have triggered further insights and reflections. Based on the aforementioned thinking and discussions, this article has been composed to disseminate information and foster an open discussion within the academic community. LLMs still largely remain a blackbox, and the technology is still rapidly iterating and evolving. Moreover, the existing cases reported by practitioners and our own practical experiences with LLM-based software development are relatively limited. Therefore, many of the insights and reflections in this article may not be accurate, and they maybe constantly refreshed as technology and practice continue to develop.	[Peng, Xin] Fudan Univ, Sch Comp Sci, Shanghai 200438, Peoples R China	Fudan University	Peng, X (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200438, Peoples R China.	pengxin@fudan.edu.cn		Peng, Xin/0000-0003-3376-2581				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; BROOKS FP, 1987, COMPUTER, V20, P10, DOI 10.1109/MC.1987.1663532; Dou SH, 2023, Arxiv, DOI arXiv:2308.01191; Du XY, 2023, Arxiv, DOI arXiv:2308.01861; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Wang JJ, 2024, Arxiv, DOI [arXiv:2307.07221, 10.48550/arXiv.2307.07221]; Welsh M, 2023, COMMUN ACM, V66, P34, DOI 10.1145/3570220; Wu QY, 2023, Arxiv, DOI arXiv:2308.08155; Yuan ZQ, 2023, Arxiv, DOI arXiv:2308.01240; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng ZB, 2023, Arxiv, DOI arXiv:2308.11396	13	0	0	9	9	ZHEJIANG UNIV PRESS	Hangzhou	Xixi Campus, Zhejiang University, No. 148 Tianmushan Road, Hangzhou, Zhejiang, PEOPLES R CHINA	2095-9184	2095-9230		FRONT INFORM TECH EL	Front. Inform. Technol. Elect. Eng.	NOV	2023	24	11					1513	1519		10.1631/FITEE.2300537	http://dx.doi.org/10.1631/FITEE.2300537			7	Computer Science, Information Systems; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	Z9OC8					2024-07-03	WOS:001115291600010
J	Lund, BD; Wang, T; Mannuru, NR; Nie, B; Shimray, S; Wang, Z				Lund, Brady D.; Wang, Ting; Mannuru, Nishith Reddy; Nie, Bing; Shimray, Somipam; Wang, Ziang			ChatGPT and a new academic reality: Artificial Intelligence-written research papers and the ethics of the large language models in scholarly publishing	JOURNAL OF THE ASSOCIATION FOR INFORMATION SCIENCE AND TECHNOLOGY			English	Article							AI; COMMUNICATION; CONSTRUCTION; PLAGIARISM; CITATION	This article discusses OpenAI's ChatGPT, a generative pre-trained transformer, which uses natural language processing to fulfill text-based user requests (i.e., a "chatbot "). The history and principles behind ChatGPT and similar models are discussed. This technology is then discussed in relation to its potential impact on academia and scholarly research and publishing. ChatGPT is seen as a potential model for the automated preparation of essays and other types of scholarly manuscripts. Potential ethical issues that could arise with the emergence of large language models like GPT-3, the underlying technology behind ChatGPT, and its usage by academics and researchers, are discussed and situated within the context of broader advancements in artificial intelligence, machine learning, and natural language processing for research and scholarly publishing.	[Lund, Brady D.; Mannuru, Nishith Reddy] Univ North Texas, Dept Informat Sci, Denton, TX 76203 USA; [Wang, Ting] Emporia State Univ, Sch Lib & Informat Management, Emporia, KS USA; [Nie, Bing] Zhejiang Tongji Vocat Coll Sci & Technol, Hangzhou, Peoples R China; [Shimray, Somipam] Babasaheb Bhimrao Ambedkar Univ, Dept Lib & Informat Sci, Lucknow, India; [Wang, Ziang] Baker Univ, Sch Educ, Baldwin City, KS USA	University of North Texas System; University of North Texas Denton; Babasaheb Bhimrao Ambedkar University; Baker University	Lund, BD (corresponding author), Univ North Texas, Dept Informat Sci, Denton, TX 76203 USA.	brady.lund@unt.edu	Shimray, Dr. Somipam R/AAX-6632-2021; Shimray, Dr. Somipam R/GQB-4371-2022; Mannuru, Nishith Reddy/GRJ-1450-2022	Shimray, Dr. Somipam R/0000-0001-7967-489X; Shimray, Dr. Somipam R/0000-0001-7967-489X; Mannuru, Nishith Reddy/0000-0002-6423-4899				Abd-Elaal ES, 2022, EUR J ENG EDUC, V47, P725, DOI 10.1080/03043797.2022.2046709; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Alutto J. A., 2008, FINAL REPORT AACSB I; American Association of University Professors, TENUR; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; [Anonymous], 2020, NAT MACH INTELL, V2, P419, DOI 10.1038/s42256-020-0223-0; Augier M, 2005, ORGAN SCI, V16, P85, DOI 10.1287/orsc.1040.0108; Baeza-Yates R, WSDM 15 P 8 ACM INT, V15, DOI [10.1145/3488560.3498370, DOI 10.1145/3488560.3498370]; Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33; Beath C, 2012, MIT SLOAN MANAGE REV, V53, P18; Bedeian AG, 1996, J MANAGE INQUIRY, V5, P311, DOI 10.1177/105649269654003; Bedeian AG, 2004, ACAD MANAG LEARN EDU, V3, P198, DOI 10.5465/AMLE.2004.13500489; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30; Brockman Greg, 2016, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Budzianowski P., 2019, HELLO, DOI DOI 10.48550/ARXIV.1907.05774; Caplow T., 1958, ACAD MARKET; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Cox A, 2023, J ASSOC INF SCI TECH, V74, P367, DOI 10.1002/asi.24635; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dale R, 2017, NAT LANG ENG, V23, P319, DOI 10.1017/S1351324917000018; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Erhan D, 2010, J MACH LEARN RES, V11, P625; Etzioni O, 2017, NATURE, V547, P32, DOI 10.1038/547032a; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Founta A.-M., 2018, Large scale crowdsourcing and characterization of twitter abusive behavior; Gasparyan AY, 2017, J KOREAN MED SCI, V32, P1220, DOI 10.3346/jkms.2017.32.8.1220; Gillotte J.L., 2019, UC Davis L. Rev., V53, P2655; Gilot R., 2023, WILL ARTIFICIAL INTE, DOI [10.1016/j.arthro.2023.01.014, DOI 10.1016/J.ARTHRO.2023.01.014]; Goh G., 2021, DISTILL, DOI DOI 10.23915/DISTILL.00030; González-Padilla DA, 2023, J UROLOGY, V209, P682, DOI 10.1097/JU.0000000000003131; Ha T, 2022, TECHNOL FORECAST SOC, V184, DOI 10.1016/j.techfore.2022.121974; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Hancock JT, 2020, J COMPUT-MEDIAT COMM, V25, P89, DOI 10.1093/jcmc/zmz022; Haque M., 2022, I THINK THIS IS MOST, DOI DOI 10.48550/ARXIV.2212.05856; Horner RD, 2019, MED CARE, V57, P399, DOI 10.1097/MLR.0000000000001116; Hosseini M. Rasmussen L. M. Resnik D. B., ACCOUNT RES, DOI [10.1080/08989621.2023.216853, DOI 10.1080/08989621.2023.216853]; Hristov K., 2016, Idea, V57, P431; Hugenholtz PB, 2021, IIC-INT REV INTELL P, V52, P1190, DOI 10.1007/s40319-021-01115-0; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Hyland K, 1999, APPL LINGUIST, V20, P341, DOI 10.1093/applin/20.3.341; Jarrahi MH, 2023, J ASSOC INF SCI TECH, V74, P303, DOI 10.1002/asi.24730; Jiao W., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.08745; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Kaltenbrunner W, 2022, J DOC, V78, P429, DOI 10.1108/JD-01-2022-0022; Khanna A., 2015, INT J U E SERV SCI T, V8, P277, DOI DOI 10.14257/IJUNESST.2015.8.7.28; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Kirmani AR, 2022, ACS ENERGY LETT, V8, P574, DOI 10.1021/acsenergylett.2c02758; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu X., 2021, GPT UNDERSTANDS, DOI DOI 10.48550/ARXIV.2103.10385; Liu YH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517731; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Lokman A. S., 2018, ADV INTELL SYST COMP, P1012; Lu Y, 2019, J MANAG ANAL, V6, P1, DOI 10.1080/23270012.2019.1570365; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Lund BD, 2022, ACCOUNT RES, V29, P224, DOI 10.1080/08989621.2021.1913124; Mahesh B., 2020, Int. J. Eng. Sci. (IJSR), V9, P381, DOI [10.21275/ART20203995, DOI 10.21275/ART20203995]; Makridakis S, 2017, FUTURES, V90, P46, DOI 10.1016/j.futures.2017.03.006; Marcus G., 2022, VERY PRELIMINARY ANA, DOI [DOI 10.48550/ARXIV.2204.13807, 10.48550/arxiv.2204.13807]; MERTON RK, 1968, SCIENCE, V159, P56, DOI 10.1126/science.159.3810.56; Miller AN, 2011, CAREER DEV INT, V16, P422, DOI 10.1108/13620431111167751; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; Moher D. Naudet F. Cristea I. A. Miedema F. Ioannidis J. P. A. Goodman S. N, PLOS BIOL, V16, DOI [10.1371/journal.pbio.2004089, DOI 10.1371/JOURNAL.PBIO.2004089]; Mollman S., 2022, YAHOO FINANCE; Muller V. C., 2020, STANFORD ENCY PHILOS; Nagarhalli TP, 2020, INT CONF ADVAN COMPU, P706, DOI [10.1109/icaccs48705.2020.9074420, 10.1109/ICACCS48705.2020.9074420]; Nolan C. W., 2004, LIBRARIANS CAREER GU, P281; Olsson A., 2022, THESIS; OpenAI, 2022, OPENAI PAG; Perc M, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0378; Perrigo Billy, 2023, Openai used kenyan workers on less than $2 per hour: Exclusive; Pertile SD, 2016, J ASSOC INF SCI TECH, V67, P2511, DOI 10.1002/asi.23593; Radford A., 2018, IMPROVING LANGUAGE U; Santini A, 2018, J CRIT CARE MED, V4, P3, DOI [10.2478/jccm-2018-0002, 10.1515/jccm-2018-0002]; Schonberger D., 2018, DEEP COPYRIGHT UP AN; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Tan YC, 2019, ADV NEURAL INFORM PR, P13230; Thigpen C., 2019, MOST AM SAYS SCI HAS; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; University of North Carolina, What is sociology?; Waggoner Denton A, 2018, College Teaching, V66, P22, DOI [10.1080/87567555.2017.1349075, DOI 10.1080/87567555.2017.1349075]; Wamba SF, 2021, TECHNOL FORECAST SOC, V164, DOI 10.1016/j.techfore.2020.120482; Wang XQ, 2023, J ASSOC INF SCI TECH, V74, P339, DOI 10.1002/asi.24621; Woods H. B., 2023, ASTROPHYS J, V7, P82, DOI DOI 10.12688/WELLCOMEOPENRES.17715.2; Yang ZL, 2019, ADV NEUR IN, V32; Yanisky-Ravid S., 2017, Michigan State Law Review, P659, DOI DOI 10.2139/SSRN.2957722; Zech Herbert, 2021, ERA Forum, V22, P147, DOI 10.1007/s12027-020-00648-0; Zhao J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P629; Zhou XY, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P329	98	140	142	504	1327	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2330-1635	2330-1643		J ASSOC INF SCI TECH		MAY	2023	74	5					570	581		10.1002/asi.24750	http://dx.doi.org/10.1002/asi.24750		MAR 2023	12	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	A8HN3		Green Submitted			2024-07-03	WOS:000947863900001
C	Du, SQ; Tang, SJ; Wang, WX; Li, XM; Guo, RZ		El-Sheimy, N; Abdelbary, AA; El-Bendary, N; Mohasseb, Y		Du, S. Q.; Tang, S. J.; Wang, W. X.; Li, X. M.; Guo, R. Z.			TREE-GPT: MODULAR LARGE LANGUAGE MODEL EXPERT SYSTEM FOR FOREST REMOTE SENSING IMAGE UNDERSTANDING AND INTERACTIVE ANALYSIS	GEOSPATIAL WEEK 2023, VOL. 48-1	International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences		English	Proceedings Paper	5th International-Society-for-Photogrammetry-and-Remote-Sensing (ISPRS) Geospatial Week (GSW)	SEP 02-07, 2023	Cairo, EGYPT	Int Soc Photogrammetry & Remote Sensing		Remote Sensing; Deep Learning; Forestry; Large Language Model; Individual Tree Segmentation; Tree Factor Estimation; Segment Anything Model	SEGMENTATION; ALGORITHM	This paper introduces a novel framework, Tree-GPT, which incorporates Large Language Models (LLMs) into the forestry remote sensing data workflow, thereby enhancing the efficiency of data analysis. Currently, LLMs are unable to extract or comprehend information from images and may generate inaccurate text due to a lack of domain knowledge, limiting their use in forestry data analysis. To address this issue, we propose a modular LLM expert system, Tree-GPT, that integrates image understanding modules, domain knowledge bases, and toolchains. This empowers LLMs with the ability to comprehend images, acquire accurate knowledge, generate code, and perform data analysis in a local environment. Specifically, the image understanding module extracts structured information from forest remote sensing images by utilizing automatic or interactive generation of prompts to guide the Segment Anything Model (SAM) in generating and selecting optimal tree segmentation results. The system then calculates tree structural parameters based on these results and stores them in a database. Upon receiving a specific natural language instruction, the LLM generates code based on a thought chain to accomplish the analysis task. The code is then executed by an LLM agent in a local environment and. For ecological parameter calculations, the system retrieves the corresponding knowledge from the knowledge base and inputs it into the LLM to guide the generation of accurate code. We tested this system on several tasks, including Search, Visualization, and Machine Learning Analysis. The prototype system performed well, demonstrating the potential for dynamic usage of LLMs in forestry research and environmental sciences.	[Du, S. Q.; Tang, S. J.; Wang, W. X.; Li, X. M.; Guo, R. Z.] Shenzhen Univ, Sch Architecture & Urban Planning, Res Inst Smart Cities, Shenzhen, Peoples R China; [Du, S. Q.; Tang, S. J.; Wang, W. X.; Li, X. M.; Guo, R. Z.] State Key Lab Subtrop Bldg & Urban Sci, Shenzhen, Peoples R China; [Du, S. Q.; Tang, S. J.; Wang, W. X.; Li, X. M.; Guo, R. Z.] Guangdong Hong Kong Macau Joint Lab Smart Cities, Hong Kong, Peoples R China	Shenzhen University	Tang, SJ (corresponding author), Shenzhen Univ, Sch Architecture & Urban Planning, Res Inst Smart Cities, Shenzhen, Peoples R China.; Tang, SJ (corresponding author), State Key Lab Subtrop Bldg & Urban Sci, Shenzhen, Peoples R China.; Tang, SJ (corresponding author), Guangdong Hong Kong Macau Joint Lab Smart Cities, Hong Kong, Peoples R China.				National Key Research and Development Program of China [2022 YFB 3903700]; Shenzhen Science and Technology Program [JCYJ 20210324093012033]; Natural Science Foundation of Guangdong Province [2121A1515012574]; National Natural Science Foundation of China [71901147, 41901329, 41971354, 41971341,42001331]; Shenzhen Key Laboratory of Digital Twin Technologies for Cities [ZDSYS20210623101800001]	National Key Research and Development Program of China; Shenzhen Science and Technology Program; Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shenzhen Key Laboratory of Digital Twin Technologies for Cities	This work was supported in part by the National Key Research and Development Program of China (Project No. 2022 YFB 3903700), a Shenzhen Science and Technology Program (Project No. JCYJ 20210324093012033), the Natural Science Foundation of Guangdong Province (Project No. 2121A1515012574), the National Natural Science Foundation of China (Project Nos. 71901147, 41901329, 41971354, and 41971341,42001331), Shenzhen Key Laboratory of Digital Twin Technologies for Cities (Project No: ZDSYS20210623101800001).	Beloiu M, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15051463; Chappuis C, 2022, IEEE COMPUT SOC CONF, P1371, DOI 10.1109/CVPRW56347.2022.00143; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Indirabai I, 2019, J GEOVIS SPAT ANAL, V3, DOI 10.1007/s41651-019-0033-2; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li YB, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14133035; Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782; Lutz JA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036131; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Qian C, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15020406; Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075; Strîmbu VF, 2015, ISPRS J PHOTOGRAMM, V104, P30, DOI 10.1016/j.isprsjprs.2015.01.018; Sun Y, 2019, IEEE J-STARS, V12, P4415, DOI 10.1109/JSTARS.2019.2950721; Suratno A, 2009, ISPRS J PHOTOGRAMM, V64, P683, DOI 10.1016/j.isprsjprs.2009.07.001; Tochon G, 2015, REMOTE SENS ENVIRON, V159, P318, DOI 10.1016/j.rse.2014.12.020; Turner JA, 2006, SCAND J FOREST RES, V21, P73, DOI 10.1080/02827580500478506; Vaswani A, 2017, ADV NEUR IN, V30; Wagner FH, 2018, ISPRS J PHOTOGRAMM, V145, P362, DOI 10.1016/j.isprsjprs.2018.09.013; Weinstein BG, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111309; Yang JT, 2020, IEEE J-STARS, V13, P1055, DOI 10.1109/JSTARS.2020.2979369; Yang QL, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11232880; Zhang C, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14040874; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	33	0	0	14	14	COPERNICUS GESELLSCHAFT MBH	GOTTINGEN	BAHNHOFSALLE 1E, GOTTINGEN, 37081, GERMANY	1682-1750	2194-9034		INT ARCH PHOTOGRAMM			2023							1729	1736		10.5194/isprs-archives-XLVIII-1-W2-2023-1729-2023	http://dx.doi.org/10.5194/isprs-archives-XLVIII-1-W2-2023-1729-2023			8	Archaeology; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Remote Sensing	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Archaeology; Computer Science; Remote Sensing	BW6ZA		Green Submitted, gold			2024-07-03	WOS:001185682000238
J	Frosolini, A; Catarzi, L; Benedetti, S; Latini, L; Chisci, G; Franz, L; Gennaro, P; Gabriele, G				Frosolini, Andrea; Catarzi, Lisa; Benedetti, Simone; Latini, Linda; Chisci, Glauco; Franz, Leonardo; Gennaro, Paolo; Gabriele, Guido			The Role of Large Language Models (LLMs) in Providing Triage for Maxillofacial Trauma Cases: A Preliminary Study	DIAGNOSTICS			English	Article						Large Language Models (LLM); GEMINI; ChatGPT; maxillofacial; trauma; triage; AIPI; QAMAI; maxillofacial surgery		Background: In the evolving field of maxillofacial surgery, integrating advanced technologies like Large Language Models (LLMs) into medical practices, especially for trauma triage, presents a promising yet largely unexplored potential. This study aimed to evaluate the feasibility of using LLMs for triaging complex maxillofacial trauma cases by comparing their performance against the expertise of a tertiary referral center. Methods: Utilizing a comprehensive review of patient records in a tertiary referral center over a year-long period, standardized prompts detailing patient demographics, injury characteristics, and medical histories were created. These prompts were used to assess the triage suggestions of ChatGPT 4.0 and Google GEMINI against the center's recommendations, supplemented by evaluating the AI's performance using the QAMAI and AIPI questionnaires. Results: The results in 10 cases of major maxillofacial trauma indicated moderate agreement rates between LLM recommendations and the referral center, with some variances in the suggestion of appropriate examinations (70% ChatGPT and 50% GEMINI) and treatment plans (60% ChatGPT and 45% GEMINI). Notably, the study found no statistically significant differences in several areas of the questionnaires, except in the diagnosis accuracy (GEMINI: 3.30, ChatGPT: 2.30; p = 0.032) and relevance of the recommendations (GEMINI: 2.90, ChatGPT: 3.50; p = 0.021). A Spearman correlation analysis highlighted significant correlations within the two questionnaires, specifically between the QAMAI total score and AIPI treatment scores (rho = 0.767, p = 0.010). Conclusions: This exploratory investigation underscores the potential of LLMs in enhancing clinical decision making for maxillofacial trauma cases, indicating a need for further research to refine their application in healthcare settings.	[Frosolini, Andrea; Catarzi, Lisa; Benedetti, Simone; Latini, Linda; Chisci, Glauco; Gennaro, Paolo; Gabriele, Guido] Univ Siena, Dept Med Biotechnol, Maxillofacial Surg Unit, I-53100 Siena, Italy; [Franz, Leonardo] Univ Padua, Dept Neurosci DNS, Phoniatris & Audiol Unit, I-35122 Treviso, Italy; [Franz, Leonardo] Univ Brescia, Dept Clin & Expt Sci, Artificial Intelligence Med & Innovat Clin Res & M, I-25121 Brescia, Italy	University of Siena; University of Padua; University of Brescia	Frosolini, A (corresponding author), Univ Siena, Dept Med Biotechnol, Maxillofacial Surg Unit, I-53100 Siena, Italy.	andreafrosolini@gmail.com; lisa.catarzi@student.unisi.it; simone.benedetti@student.unisi.it; latilinda94@gmail.com; glauco.chisci@gmail.com; leonardo.franz@unipd.it; paolo.gennaro@unisi.it; guido.gabriele@unisi.it	Frosolini, Andrea/AEU-3193-2022	Frosolini, Andrea/0000-0003-1347-4013; Benedetti, Simone/0000-0002-8997-5335; Chisci, Glauco/0000-0001-6992-324X; LATINI, LINDA/0000-0003-2894-9309; Franz, leonardo/0000-0002-2306-4088	University of Siena golden access	University of Siena golden access	No Statement Available	Abou-Abdallah M, 2024, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-024-08598-w; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Baig Z, 2024, DIAGNOSTICS, V14, DOI 10.3390/diagnostics14050527; Carlà MM, 2024, BRIT J OPHTHALMOL, DOI 10.1136/bjo-2023-325143; Cascino F, 2022, ORBIT-ABINGDON, DOI 10.1080/01676830.2022.2155974; Cascino F, 2019, J CRANIOFAC SURG, V30, P2207, DOI 10.1097/SCS.0000000000005846; Chu ZG, 2011, J CRANIO MAXILL SURG, V39, P503, DOI 10.1016/j.jcms.2010.10.022; Crook BS, 2023, J HAND SURG-AM, V48, P1122, DOI 10.1016/j.jhsa.2023.08.003; Fraser H, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/49995; Frosolini A, 2023, EUR ARCH OTO-RHINO-L, V280, P5129, DOI 10.1007/s00405-023-08205-4; Frosolini A, 2023, ANN BIOMED ENG, V51, P2120, DOI 10.1007/s10439-023-03248-4; Funk PF, 2024, EUR J INVEST HEALTH, V14, P657, DOI 10.3390/ejihpe14030043; Gabriele G, 2022, ANN ITAL CHIR, V93, P135; Gan RK, 2024, AM J EMERG MED, V75, P72, DOI 10.1016/j.ajem.2023.10.034; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Guillen-Grima F, 2023, CLINICS PRACT, V13, P1460, DOI 10.3390/clinpract13060130; Jacob J, 2023, INDIAN J CRIT CARE M, V27, P561, DOI 10.5005/jp-journals-10071-24498; Javadi N, 2021, IRAN J NURS MIDWIFE, V26, P189, DOI 10.4103/ijnmr.IJNMR_155_20; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Lechien JR, 2024, EUR ARCH OTO-RHINO-L, V281, P3309, DOI 10.1007/s00405-023-08441-8; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li WB, 2024, AESTHET PLAST SURG, V48, P1571, DOI 10.1007/s00266-023-03660-0; Liu HY, 2024, AESTHET PLAST SURG, V48, P1644, DOI 10.1007/s00266-023-03709-0; Masalkhi M, 2024, EYE, DOI 10.1038/s41433-024-02958-w; Miragall MF, 2023, J CLIN MED, V12, DOI 10.3390/jcm12216843; Navalesi P, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10070765; Riestra-Ayora J, 2024, EUR ARCH OTO-RHINO-L, V281, P3253, DOI 10.1007/s00405-024-08581-5; Sahin MC, 2024, COMPUT BIOL MED, V169, DOI 10.1016/j.compbiomed.2023.107807; Scherr R, 2023, JMIR MED EDUC, V9, DOI 10.2196/49877; Smith Andrew L, 2023, PLOS Digit Health, V2, pe0000388, DOI 10.1371/journal.pdig.0000388; Sorin V, 2024, J CANCER RES CLIN, V150, DOI 10.1007/s00432-024-05678-6; Suárez A, 2024, COMPUT STRUCT BIOTEC, V24, P46, DOI 10.1016/j.csbj.2023.11.058; Thompson L, 2021, SCAND J TRAUMA RESUS, V29, DOI 10.1186/s13049-021-00870-w; Vaira L.A., 2023, Head Neck Surg, DOI [10.1002/ohn.489, DOI 10.1002/OHN.489]; Wang AY, 2024, bioRxiv, DOI [10.1101/2023.12.28.573586, 10.1101/2023.12.28.573586, DOI 10.1101/2023.12.28.573586]; Wang TT, 2023, J ORAL MAXIL SURG, V81, P387, DOI 10.1016/j.joms.2022.12.022	36	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4418		DIAGNOSTICS	Diagnostics	APR	2024	14	8							839	10.3390/diagnostics14080839	http://dx.doi.org/10.3390/diagnostics14080839			11	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	OV8H6	38667484	gold			2024-07-03	WOS:001210140800001
C	Deng, Y; Lei, WQ; Huang, ML; Chua, TS			ACM	Deng, Yang; Lei, Wenqiang; Huang, Minlie; Chua, Tat-Seng			Rethinking Conversational Agents in the Era of Large Language Models: Proactivity, Non-collaborativity, and Beyond	ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL IN THE ASIA PACIFIC REGION, SIGIR-AP 2023			English	Proceedings Paper	1st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region (SIGIR-AP)	NOV 26-28, 2023	Beijing, PEOPLES R CHINA	Assoc Comp Machinery, ACM SIGIR, Xiaohongshu, Zhipu AI, Kuaishou		Open-domain Dialogue; Task-oriented Dialogue; Conversational Information Seeking; Proactivity		Conversational systems are designed to offer human users social support or functional services through natural language interactions. Typical conversation researches mainly focus on the responseability of the system, such as dialogue context understanding and response generation. In the era of large language models (LLMs), LLM-augmented conversational systems showcase exceptional capabilities of responding to user queries for different language tasks. However, as LLMs are trained to follow users' instructions, LLM-augmented conversational systems typically overlook the design of an essential property in intelligent conversations, i.e., goal awareness. In this tutorial, we will introduce the recent advances on the design of agent's awareness of goals in a wide range of conversational systems, including proactive, non-collaborative, and multi-goal conversational systems. In addition, we will discuss the main open challenges in developing agent's goal awareness in LLM-augmented conversational systems and several potential research directions for future studies.	[Deng, Yang; Chua, Tat-Seng] Natl Univ Singapore, Singapore, Singapore; [Lei, Wenqiang] Sichuan Univ, Chengdu, Peoples R China; [Huang, Minlie] Tsinghua Univ, Beijing, Peoples R China	National University of Singapore; Sichuan University; Tsinghua University	Deng, Y (corresponding author), Natl Univ Singapore, Singapore, Singapore.	ydeng@nus.edu.sg; wenqianglei@gmail.com; aihuang@tsinghua.edu.cn; chuats@comp.nus.edu.sg						Aliannejadi M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P475, DOI 10.1145/3331184.3331265; Baheti A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4846; Balaraman Vevake, 2020, SEMDIAL, P1; Chen L, 2023, Arxiv, DOI arXiv:2310.07289; Chen M, 2023, 61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2, P951; Chen Maximillian, 2022, P 2 C ASIA PACIFIC C, P399; Chen Y.-N., 2017, P 55 ANN M ASS COMPU, P8; Chen Zhiyu, 2022, FINDINGS ACL NAACL 2, P2581; Cheng Yi, 2022, arXiv, DOI DOI 10.48550/ARXIV.2210.04242; Chiu S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6143; Dalton J, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3455, DOI 10.1145/3477495.3532678; Deng Y, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4079; Deng Y, 2023, Arxiv, DOI arXiv:2305.13626; Deng Y, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3570640; Deng Y, 2023, Arxiv, DOI arXiv:2210.08817; Deng Y, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2998, DOI 10.1145/3485447.3512020; Deng Yang, 2023, IJCAI 2023, P6583; Deng Yang, 2023, ACL 2023 TUTORIAL AB, P1; Fu Y, 2023, Arxiv, DOI arXiv:2305.10142; Gao JF, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2421, DOI 10.1145/3397271.3401418; Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183; Grant AM, 2008, RES ORGAN BEHAV, V28, P3, DOI 10.1016/j.riob.2008.04.002; Guo Meiqi, 2021, AKBC 2021; He H, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2333; Kim H, 2022, Arxiv, DOI arXiv:2205.12688; Lei WQ, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P212, DOI 10.1145/3477495.3532001; Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769; Li HR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5858; Li Y, 2020, AAAI CONF ARTIF INTE, V34, P8293; Liao LZ, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P3452, DOI 10.1145/3539618.3594250; Liao Lizi, 2023, P 16 ACM INT C WEB S, P1244, DOI DOI 10.1145/3539597.3572724; Liu JW, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9731; Liu SY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3469; Liu ZM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1024; Liu ZM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1036; Mishra Kshitij, 2022, P 29 INT C COMP LING, P424; Ni JJ, 2022, AAAI CONF ARTIF INTE, P11112; Schulman John, 2022, Chatgpt: Optimizing language models for dialogue; Sekulic I, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P888, DOI 10.1145/3488560.3498440; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Su Pei-Hao., 2018, NAACL 2018 TUTORIAL, P27; Sun H, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3906; Sun K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1570; Tang JH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5624; Tu Q, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P308; Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5635; Wu WQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3794; Xie HY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1684; Yang RZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P681; Yang W, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES(NAACL HLT 2019), VOL. 2 (INDUSTRY PAPERS), P56; Yang Z., 2022, COLING, P745; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yao WR, 2024, Arxiv, DOI arXiv:2308.02151; Young T, 2022, AAAI CONF ARTIF INTE, P11622; Yu X, 2023, Arxiv, DOI [arXiv:2305.13660, DOI 10.48550/ARXIV.2305.13660]; Zamani H., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08808; Zamani H, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P418, DOI 10.1145/3366423.3380126; Zhang J., 2021, FINDINGS ASS COMPUTA, P1092; Zhang Qiang, 2023, FINDINGS ACL ACL 202, P6665; Zhang S, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1512, DOI 10.1145/3394486.3403202; Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776; Zheng ZH, 2023, Arxiv, DOI [arXiv:2308.11584, 10.48550/arXiv.2308.11584]; Zhou Yiheng, 2020, ICLR 2020	63	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0408-6				2023							298	301		10.1145/3624918.3629548	http://dx.doi.org/10.1145/3624918.3629548			4	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2NW					2024-07-03	WOS:001122582700034
J	Han, DC; Zhao, WJ; Yin, HX; Qu, M; Zhu, J; Ma, FF; Ying, YJ; Pan, A				Han, Dongchen; Zhao, Wuji; Yin, Hongxi; Qu, Ming; Zhu, Jian; Ma, Feifan; Ying, Yuejia; Pan, Annika			Large language models driven BIM-based DfMA method for free-form prefabricated buildings: framework and a usefulness case study	JOURNAL OF ASIAN ARCHITECTURE AND BUILDING ENGINEERING			English	Article; Early Access						Free-form; Large language models (LLMs); prefabrication; Design for manufacturing and assembly (DfMA); Building information modeling (BIM)	PARAMETRIC DESIGN; CONSTRUCTION; MANUFACTURE	The escalating demand for free-form buildings presents a formidable technological hurdle in the realm of prefabrication manufacturing and assembly. This research draws inspiration from recent advancements in large language models (LLMs) and seeks to harness their transformative potential in tandem with Building Information Modeling (BIM) to advance the Design for Manufacture and Assembly (DfMA) method. The ultimate aim is to catapult the prefabrication industry into an era characterized by unparalleled design freedom and heightened efficiency. The research includes contributions from the following four areas: (1) A review of the literature on DfMA theories, specifically fabrication and construction. (2) The development of a BIM-based DfMA method framework, including the methodological basis, Design for Manufacturing (DfM), and Design for Assembly (DfA). (3) A pipeline for LLMs driven BIM-based DfMA method framework and a validation using the Decathlon Solar Team design-build practice at the University of Washington's Lotus House. (4) An evaluation of 692 conversation scenarios to verify the feasibility of our proposal. We get a 91.1% user agreement on average based on GPT4. The research results could guide the workflow in building a lifecycle for DfMA practices in the future smart manufacturing era.	[Han, Dongchen; Zhao, Wuji] Soochow Univ, Sch Architecture, New York Off, Suzhou, Peoples R China; [Yin, Hongxi; Pan, Annika] Washington Univ, Sam Fox Sch Design & Visual Arts, St. Louis, MO USA; [Qu, Ming] Purdue Univ, Lyles Sch Civil Engn, W Lafayette, IN USA; [Zhu, Jian] ZGF Architects LLP, Shanghai Off, Portland, OR USA; [Ma, Feifan] Skidmore Owings & Merrill Inc, Chicago, IL USA; [Ying, Yuejia] Skidmore Owings & Merrill Inc, Chicago Off, Chicago, IL USA; [Yin, Hongxi] Washington Univ, Sam Fox Sch Design & Visual Arts, 1 Brooking Dr, St Louis, MO 63130 USA	Soochow University - China; Washington University (WUSTL); Purdue University System; Purdue University; Skidmore, Owings & Merrill; Skidmore, Owings & Merrill; Washington University (WUSTL)	Yin, HX (corresponding author), Washington Univ, Sam Fox Sch Design & Visual Arts, 1 Brooking Dr, St Louis, MO 63130 USA.	hongxi.yin@wustl.edu			National Natural Science Foundation of China [52108022]; College Students 'Innovation and Entrepreneurship Training Program" of Soochow University [202210285022Z]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); College Students 'Innovation and Entrepreneurship Training Program" of Soochow University	The research is supported by the National Natural Science Foundation of China under grant No. 52108022. This work is also supported by College Students 'Innovation and Entrepreneurship Training Program" of Soochow University, project number: 202210285022Z.	Akanni P. O., 2015, HBRC Journal, V11, P91, DOI 10.1016/j.hbrcj.2014.02.010; Alfieri E, 2020, ARCHIT ENG DES MANAG, V16, P247, DOI 10.1080/17452007.2020.1726725; Allen J., 1995, NATURAL LANGUAGE UND; [Anonymous], 2007, INTEGRATED PROJECT D; Banks C, 2018, PROC INST CIV ENG-MA, V171, P164, DOI 10.1680/jmapl.17.00027; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bird S., 2009, NATURAL LANGUAGE PRO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen HZ, 2020, AGR WATER MANAGE, V240, DOI 10.1016/j.agwat.2020.106303; Chen ZK, 2024, Arxiv, DOI arXiv:2307.03393; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Doumbouya L., 2016, Am. J. Civ. Eng. Archit, V4, P74; Eastman C.M., 2011, BIM HDB GUIDE BUILDI, DOI [DOI 10.1002/9780470261309.CH8, DOI 10.5130/AJCEB.V12I3.2749]; El-Nounu A, 2018, RES ENG DES, V29, P107, DOI 10.1007/s00163-017-0255-6; Fakhimi A., 2016, P 33 INT S AUTOMATIO, P18; Ganar A., 2015, International Journal on Recent and Innovation Trends in Computing and Communication, V3, P6472; Gao W, 2015, COMPUT AIDED DESIGN, V69, P65, DOI 10.1016/j.cad.2015.04.001; Goldberg Y., 2022, Neural network methods for natural language processing; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Han DC, 2020, J ARCHIT ENG, V26, DOI 10.1061/(ASCE)AE.1943-5568.0000397; Harik R.F., 2010, Computer-Aided Design and Applications, V7, P701, DOI [DOI 10.3722/CADAPS.2010.701-709, https://doi.org/10.3722/cadaps.2010.701-709]; Jewell C, 2014, CONSTR MANAG ECON, V32, P473, DOI 10.1080/01446193.2013.879194; Kim K, 2015, ARCHIT SCI REV, V58, P230, DOI 10.1080/00038628.2014.927751; Lague D, 2013, ISPRS J PHOTOGRAMM, V82, P10, DOI 10.1016/j.isprsjprs.2013.04.009; Lam PTI, 2009, CONSTR MANAG ECON, V27, P41, DOI 10.1080/01446190802570498; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Liu Y, 2019, TRANSPORT RES C-EMER, V101, P18, DOI 10.1016/j.trc.2019.01.027; Liu ZC, 2018, NANO LETT, V18, P6570, DOI 10.1021/acs.nanolett.8b03171; Liu ZY, 2023, Arxiv, DOI arXiv:2305.05662; Lu WS, 2021, ARCHIT ENG DES MANAG, V17, P77, DOI 10.1080/17452007.2020.1768505; N. OpenAI Openai, 2023, Chatgpt; OpenAI, 2023, GPT 4 TECHNICAL REPO; Paez O, 2005, HUM FACTORS ERGONOM, V15, P233, DOI 10.1002/hfm.20023; Park J, 2011, J ASIAN ARCHIT BUILD, V10, P327, DOI 10.3130/jaabe.10.327; Pradhananga P, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002007; Prasittisopin L, 2021, J ARCHIT ENG, V27, DOI 10.1061/(ASCE)AE.1943-5568.0000485; Qiping Shen, 2004, Engineering Construction and Architectural Management, V11, P9, DOI 10.1108/09699980410512629; R.R.I. of British Architects, 2013, Riba Plan of Work 2013 Designing for Manufacture and Assembly; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Roxas CLC, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13051164; Tan T, 2020, J CONSTR ENG M, V146, DOI 10.1061/(ASCE)CO.1943-7862.0001877; Touvron H., 2023, arXiv; Tuvayanond W, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13020429; Volk R, 2014, AUTOMAT CONSTR, V38, P109, DOI 10.1016/j.autcon.2013.10.023; Wang A., 2018, Glue: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding, P353, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]; Wang BW, 2024, ADV ENG INFORM, V60, DOI 10.1016/j.aei.2024.102463; Wang BW, 2023, APPL INTELL, V53, P10956, DOI 10.1007/s10489-022-04072-4; Wang BW, 2021, IEEE COMPUT SOC CONF, P2294, DOI 10.1109/CVPRW53098.2021.00259; Wang BW, 2021, IEEE ACCESS, V9, P46810, DOI 10.1109/ACCESS.2021.3067928; Wasim M, 2022, INT J CONSTR MANAG, V22, P3014, DOI 10.1080/15623599.2020.1837720; WINOGRAD T, 1972, COGNITIVE PSYCHOL, V3, P1, DOI 10.1016/0010-0285(72)90002-3; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Xi Z., 2023, The Rise and Potential of Large Language Model Based Agents: A Survey; Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738; Yuan ZM, 2018, AUTOMAT CONSTR, V88, P13, DOI 10.1016/j.autcon.2017.12.021; Zhang L., 2023, ARXIV	57	0	0	22	22	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1346-7581	1347-2852		J ASIAN ARCHIT BUILD	J. Asian Archit. Build. Eng.	2024 MAR 24	2024										10.1080/13467581.2024.2329351	http://dx.doi.org/10.1080/13467581.2024.2329351		MAR 2024	18	Architecture; Construction & Building Technology	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Architecture; Construction & Building Technology	MW9U8		gold			2024-07-03	WOS:001196799500001
J	Trozze, A; Davies, T; Kleinberg, B				Trozze, Arianna; Davies, Toby; Kleinberg, Bennett			Large language models in cryptocurrency securities cases: can a GPT model meaningfully assist lawyers?	ARTIFICIAL INTELLIGENCE AND LAW			English	Article; Early Access						Cryptocurrency; Securities law; Artificial intelligence (AI); Large language models (LLMs); ChatGPT		Large Language Models (LLMs) could be a useful tool for lawyers. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying GPT-3.5's legal reasoning and ChatGPT's legal drafting capabilities. We examine whether a) GPT-3.5 can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to ChatGPT. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by ChatGPT and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely missed additional, correct violations). ChatGPT performed better at legal drafting, and jurors' decisions were not statistically significantly associated with the author of the document upon which they based their decisions. Because GPT-3.5 cannot satisfactorily conduct legal reasoning tasks, it would be unlikely to be able to help lawyers in a meaningful way at this stage. However, ChatGPT's drafting skills (though, perhaps, still inferior to lawyers) could assist lawyers in providing legal services. Our research is the first to systematically study an LLM's legal drafting and reasoning capabilities in litigation, as well as in securities law and cryptocurrency-related misconduct.	[Trozze, Arianna] UCL, Dept Comp Sci, Gower St, London WC1E 6EA, England; [Trozze, Arianna; Davies, Toby; Kleinberg, Bennett] UCL, Dept Secur & Crime Sci, 35 Tavistock Sq, London WC1H 9EZ, England; [Davies, Toby] Univ Leeds, Sch Law, Liberty Bldg, Leeds LS2 9JT, England; [Kleinberg, Bennett] Tilburg Univ, Dept Methodol & Stat, Warandelaan 2, NL-5037 AB Tilburg, Netherlands	University of London; University College London; University of London; University College London; University of Leeds; Tilburg University	Trozze, A (corresponding author), UCL, Dept Comp Sci, Gower St, London WC1E 6EA, England.; Trozze, A (corresponding author), UCL, Dept Secur & Crime Sci, 35 Tavistock Sq, London WC1H 9EZ, England.	arianna.trozze@ucl.ac.uk		Davies, Toby/0000-0002-9677-2579	Engineering and Physical Sciences Research Council	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The authors would like to thank Antonis Papasavva for participating in the pilot phase of our study and his valuable feedback. We would also like to thank Anne Coventry for her assistance in conceptualizing our study and review of the legal concepts presented in this paper.	Ahmad Y, 2022, J VASC SURG-VENOUS L, V10, P1378, DOI 10.1016/j.jvsv.2022.05.005; Allingham JU, 2023, Arxiv, DOI [arXiv:2302.06235, 10.48550/arXiv.2302.06235, DOI 10.48550/ARXIV.2302.06235]; [Anonymous], 2020, Federal Rules of Civil Procedure; Archer R, 2016, Cantor Fitzgerald Exec Named In Virtual Currency Ponzi Suit; Blair-Stanek A, 2023, Arxiv, DOI arXiv:2302.06100; Bonsall S, 2019, ScholarSpace; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brysbaert M, 2019, J MEM LANG, V109, DOI 10.1016/j.jml.2019.104047; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Choi JH, 2022, J LEGAL EDUC, V71, P387; CoinMarketCap, 2023, Cryptocurrency prices, charts and market capitalizations; Cornell Law School, Prohibitions relating to interstate commerce and the mails; Cornell Law School, Civil liabilities arising in connection with prospectuses and communications; Dalton DL, 2013, Sector 10 defendants' proposed supplemental jury instructions; Gale ME., 1979, Albany Law Rev, V44, P298; Guarnaccia M, 2019, Rapper T.I. Faces 2nd ICO Suit, Parallel Suit Names Kevin Hart; Hadi MU, 2023, Large language models: a comprehensive survey of its applications, challenges, limitations, and future prospects, DOI [10.36227/techrxiv.23589741.v2, DOI 10.36227/TECHRXIV.23589741.V2]; Holzman ER, 2024, J ACCOUNT ECON, V77, DOI 10.1016/j.jacceco.2023.101610; Home Office, 2023, Technical report; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Innis CI, 2022, Coinbase is an unregistered securities exchange; Iu KY, 2023, ChatGPT by OpenAI: the end of litigation lawyers?, DOI [10.2139/ssrn.4339839, DOI 10.2139/SSRN.4339839]; Jarvis S, 2022, NBA-highlight NFTs count as securities, purchasers say; Kacperczyk M, 2024, J FINANC, V79, P305, DOI 10.1111/jofi.13299; Kahana E, 2023, ChatGPT Is A Cool Trick, But AI Won't Replace Lawyers; Karadimitriou SM, Mann-Whitney in SPSS; Kedia S, 2011, J ACCOUNT ECON, V51, P259, DOI 10.1016/j.jacceco.2011.01.004; Klausner M, 2013, Professional Liability Underwriting Society, V26; Kleinberg B., 2019, Detecting deceptive communication through linguistic concreteness, DOI [10.31234/osf.io/p3qjh, DOI 10.31234/OSF.IO/P3QJH]; Kochman B, 2018, Irish Cloud Coin Co. Breached US Securities Law, Suit Says; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Legal Information Institute, Securities Exchange Act of 1934; Legal Information Institute, Securities Act of 1933; Lender DJ, 2023, Class Action Fairness Act of 2005 (CAFA): overview; Litera, 2024, The Litera ecosystem; Martin CE, 2013, Plaintiff securities and exchange commission's notice of filing proposed jury instructions and verdict form; Martinson S, 2023, ChatGPT Mishap Attys 'Truly Mortified,' ask for no sanctions; McRae M, 2023, Initial stages of general litigation: overview; Moffett TA, 2022, Univ Richmond Law Rev, V57, pi; Nakamoto S., 2008, BITCOIN, DOI DOI 10.2139/SSRN.3440802; Narayanan A., 2016, Bitcoin and Cryptocurrency Technologies: A Comprehensive Introduction; Narayanan A, 2018, PODS'18: PROCEEDINGS OF THE 37TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P193, DOI 10.1145/3196959.3197545; Nay JJ, 2023, Arxiv, DOI arXiv:2306.07075; Newsham J, 2018, $70M weed cryptocurrency offering was illegal; Ninth Circuit Jury Instructions Committee, 2023, Manual of model civil jury instructions for the district courts of the ninth circuit; OpenAI, 2023, Api reference; OpenAI, 2023, Tokenizer; OpenAI, 2023, Fine-tuning; Perera K, 2023, Identical twins defrauded \$5M from 60 clients; Perlman AM, 2022, The implications of ChatGPT for legal services and society, DOI [10.2139/ssrn.4294197, DOI 10.2139/SSRN.4294197]; Practical Law, 2023, Federal question jurisdiction; Practical Law Litigation, 2023, Discovery motions in federal court toolkit; Practical Law Litigation, 2023, Dispositive motions in federal court toolkit; Practical Law Litigation, 2023, Motion practice in federal courts: overview; Practical Law Litigation, 2023, Commencing a federal lawsuit: drafting the complaint; Practical Law Litigation, 2023, Nondispositive motions in federal court; Practical Law Securities Litigation & White Collar Crime, 2023, Securities litigation and enforcement: overview; Prolific, 2014, ABOUT US; Ruscoe E, 2019, Erratic' Overstock.com CEO Punished Short Sellers, Suit Says; Savelka J, 2023, arXiv, DOI [10.1145/3594536.3595161, DOI 10.1145/3594536.3595161]; Sinay R, 2020, Investors accuse crypto firms of illicit token sales; Sinay R, 2020, Investors sue Block.one over unregistered \$4B ICO; Stanford Law School Cornerstone Research, 2023, Securities class action clearinghouse: filings database; Stevens KL, 2022, J SEX AGGRESS, V28, P218, DOI 10.1080/13552600.2021.1973127; Ting K.M., 2011, Encyclopedia of Machine Learning, DOI [DOI 10.1007/978-0-387-30164-8_652, 10.1007/978-0-387-30164-8_652.]; Topal MO, 2021, Arxiv, DOI arXiv:2102.08036; TRAC, 2021, Technical report; U.S. Department of Justice, 2022, Technical report; U.S. Securities and Exchange Commission, 2017, Enforcement manual; U.S. Securities and Exchange Commission, 2023, Crypto assets and cyber enforcement actions; U.S. Securities and Exchange Commission, 2022, SEC announces enforcement results for FY22; United States Courts, 2022, Civil cases; Koroteev MV, 2021, Arxiv, DOI [arXiv:2103.11943, DOI 10.48550/ARXIV.2103.11943]; Weinberger HP, 2023, Civil jury trials (federal); Wichert B, 2018, McAfee-linked bitcoin biz hit with pump-and-dump suit; Willmott D, 2018, J CRIM JUST, V57, P26, DOI 10.1016/j.jcrimjus.2018.03.004; Yu FY, 2022, Arxiv, DOI arXiv:2212.01326; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	78	0	0	12	12	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-8463	1572-8382		ARTIF INTELL LAW	Artif. Intell. Law	2024 APR 8	2024										10.1007/s10506-024-09399-6	http://dx.doi.org/10.1007/s10506-024-09399-6		APR 2024	47	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Law	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Government & Law	ND6D5		hybrid			2024-07-03	WOS:001198543600001
J	Binz, M; Schulz, E				Binz, Marcel; Schulz, Eric			Using cognitive psychology to understand GPT-3	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						artificial intelligence; language models; cognitive psychology; decision-making; reasoning	LANGUAGE; PROBABILITY; LESSONS	We study GPT-3, a recent large language model, using tools from cognitive psychology. More specifically, we assess GPT-3's decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature. We find that much of GPT-3's behavior is impressive: It solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multiarmed bandit task, and shows signatures of model-based reinforcement learning. Yet, we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task. Taken together, these results enrich our understanding of current large language models and pave the way for future investigations using tools from cognitive psychology to study increasingly capable and opaque artificial agents.	[Binz, Marcel; Schulz, Eric] Max Planck Inst Biol Cybernet, Max Planck Res Grp MPRG Computat Principles Intell, D-72076 Tubingen, Germany	Max Planck Society	Binz, M (corresponding author), Max Planck Inst Biol Cybernet, Max Planck Res Grp MPRG Computat Principles Intell, D-72076 Tubingen, Germany.	marcel.binz@tue.mpg.de		Binz, Marcel/0000-0001-8872-8386	Max Planck Society; Volkswagen Foundation; Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy [EXC2064/1-390727645]	Max Planck Society(Max Planck Society); Volkswagen Foundation(Volkswagen); Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy(German Research Foundation (DFG))	& nbsp;& nbsp;This work was funded by the Max Planck Society, the Volkswagen Foundation, as well as the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) under Germany's Excellence Strategy- EXC2064/1-390727645.	Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; beta.openai, OPENAI API; Betz G, 2021, Arxiv, DOI arXiv:2103.13033; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chalmers D., 2020, DLY NOUS; Chen M., 2021, arXiv; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Daw ND, 2011, NEURON, V69, P1204, DOI 10.1016/j.neuron.2011.02.027; Drori I, 2022, Arxiv, DOI [arXiv:2112.15594, 10.48550/ARXIV.2112.15594, DOI 10.48550/ARXIV.2112.15594]; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; da Silva CF, 2020, NAT HUM BEHAV, V4, P1053, DOI 10.1038/s41562-020-0905-y; Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Han S. J., 2022, PSYARXIV; Hertwig R, 2004, PSYCHOL SCI, V15, P534, DOI 10.1111/j.0956-7976.2004.00715.x; Hill F., 2020, INT C LEARNING REPRE; Jones C. R., 2022, P ANN M COGNITIVE SC, V44; KAHNEMAN D, 1972, COGNITIVE PSYCHOL, V3, P430, DOI 10.1016/0010-0285(72)90016-3; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kosoy E., 2022, UNDERSTANDING MACHIN; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Lin ZJ, 2020, AAAI CONF ARTIF INTE, V34, P13622; Luscombe R., 2022, The Guardian; Marcus G., 2020, Technology Review; McClelland JL, 2020, P NATL ACAD SCI USA, V117, P25966, DOI 10.1073/pnas.1910416117; Meder B, 2008, PSYCHON B REV, V15, P75, DOI 10.3758/PBR.15.1.75; Noever D, 2020, Arxiv, DOI arXiv:2008.04057; Nye M., 2021, ADV NEURAL INF PROCE, V34, P25192; Nyhout A, 2019, COGNITION, V183, P57, DOI 10.1016/j.cognition.2018.10.027; Pearl Judea, 2009, CAUSALITY, DOI DOI 10.1017/CBO9780511803161; Peterson JC, 2021, SCIENCE, V372, P1209, DOI 10.1126/science.abe2629; Pfungst O., 1907, Das Pferd des Herrn von Osten: der kluge Hans. Ein Beitrag zur experimentellen Tier- und Menschen-Psychologie; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rich AS, 2019, NAT MACH INTELL, V1, P174, DOI 10.1038/s42256-019-0038-z; Ritter S, 2017, PR MACH LEARN RES, V70; Ruggeri K, 2020, NAT HUM BEHAV, V4, P622, DOI 10.1038/s41562-020-0886-x; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schulz E, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101772; Schulz E, 2019, CURR OPIN NEUROBIOL, V55, P7, DOI 10.1016/j.conb.2018.11.003; Sobel DM, 2007, J COGN DEV, V8, P159, DOI 10.1080/15248370701202356; Srivastava Aarohi, 2022, Beyond the imitation game: Quantifying and extrapolating the capabilities of language models; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Suzgun Mirac, 2022, arXiv; Trott S, 2022, Arxiv, DOI [arXiv:2209.01515, DOI 10.48550/ARXIV.2209.01515]; TVERSKY A, 1983, PSYCHOL REV, V90, P293, DOI 10.1037/0033-295X.90.4.293; Tversky A., 2015, Progress in Social Psychology, V1, P49; Vaswani A, 2017, ADV NEUR IN, V30; Waldmann MR, 2005, J EXP PSYCHOL LEARN, V31, P216, DOI 10.1037/0278-7393.31.2.216; WASON PC, 1968, Q J EXP PSYCHOL, V20, P273, DOI 10.1080/14640746808400161; Webson A, 2022, Arxiv, DOI arXiv:2109.01247; Wikipedia, 2022, VIGN PSYCH; Wilson RC, 2014, J EXP PSYCHOL GEN, V143, P2074, DOI 10.1037/a0038199; Zaller I, 2021, BIOL PSYCHIAT, V89, pS217	55	64	66	126	222	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	FEB 7	2023	120	6							e2218523120	10.1073/pnas.2218523120	http://dx.doi.org/10.1073/pnas.2218523120			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	N6RH4	36730192	Green Submitted, hybrid, Green Published			2024-07-03	WOS:001038255000007
J	Cardona, G; Argiles, M; Pérez-Mañá, L				Cardona, Genis; Argiles, Marc; Perez-Mana, Lluis			Accuracy of a Large Language Model as a new tool for optometry education	CLINICAL AND EXPERIMENTAL OPTOMETRY			English	Article; Early Access						Artificial intelligence; ethics; Large Language Model; optometry education		Background: Large Language Models like ChatGPT (Generative Pretrained Transformer) are increasingly being used by researchers and students for work and academic assignments. The authoritative and conversationally correct language provided by these tools may mask their inherent limitations when presented with specific scientific and clinical queries. Methods: Three sets of 10 queries related to contact lenses & anterior eye, low vision and binocular vision & vision therapy were presented to ChatGPT, with instructions to provide five relevant references to support each response. Three experts and 53 undergraduate and post-graduate students graded from 0 to 10 the accuracy of the responses, and the references were evaluated for precision and relevance. Students graded from 0 to 10 the potential usefulness of ChatGPT for their academic coursework. Results: Median scores were 7, 8 and 6 (experts) and 8, 9 and 7.5 (students) for the contact lenses & anterior eye, low vision and binocular vision & vision therapy categories, respectively. Responses to more specific queries were awarded lower scores by both experts (rho = -0.612; P < 0.001) and students (rho = -0.578; P = 0.001). Of 150 references, 24% were accurate and 19.3% relevant. Students graded the usefulness of ChatGPT with 7.5 (2 to 9), 7 (3 to 9) and 8.5 (3 to 10) for contact lenses & anterior eye, low vision and binocular vision & vision therapy, respectively. Conclusion: Careful expert appraisal of the responses and, particularly, of the references provided by ChatGPT is required in research and academic settings. As the use of these tools becomes widespread, it is essential to take proactive steps to address their limitations and ensure their responsible use.	[Cardona, Genis; Argiles, Marc; Perez-Mana, Lluis] Univ Politecn Cataluna, Dept Opt & Optometry, Terrassa, Spain	Universitat Politecnica de Catalunya	Cardona, G (corresponding author), Univ Politecn Cataluna, Dept Opt & Optometry, Terrassa, Spain.	genis.cardona@upc.edu	Pérez-Mañá, Luis/JJE-5020-2023	Pérez-Mañá, Luis/0000-0002-8672-7803; Argiles Sans, Marc/0000-0001-5474-9832				Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; OpenAI, 2023, Online ChatGPT-optimizing language models for dialogue; OpenAI, 2023, Gpt-4 is openai's most advanced system, producing safer and more useful responses; OpenAI, 2023, How should AI systems behave, and who should decide? OpenAI Blog; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Thorndike EL, 1920, J APPL PSYCHOL, V4, P25, DOI 10.1037/h0071663; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wolffsohn JS, 2000, AM J OPHTHALMOL, V130, P793, DOI 10.1016/S0002-9394(00)00610-3; Xu RY, 2023, Arxiv, DOI arXiv:2307.01135	20	1	1	10	11	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0816-4622	1444-0938		CLIN EXP OPTOM	Clin. Exp. Optom.	2023 DEC 6	2023										10.1080/08164622.2023.2288174	http://dx.doi.org/10.1080/08164622.2023.2288174		DEC 2023	4	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	Z6PG9	38044041	Green Submitted			2024-07-03	WOS:001113270600001
J	Loconte, R; Russo, R; Capuozzo, P; Pietrini, P; Sartori, G				Loconte, Riccardo; Russo, Roberto; Capuozzo, Pasquale; Pietrini, Pietro; Sartori, Giuseppe			Verbal lie detection using Large Language Models	SCIENTIFIC REPORTS			English	Article							DECEPTION DETECTION; CUES; ACCURACY	Human accuracy in detecting deception with intuitive judgments has been proven to not go above the chance level. Therefore, several automatized verbal lie detection techniques employing Machine Learning and Transformer models have been developed to reach higher levels of accuracy. This study is the first to explore the performance of a Large Language Model, FLAN-T5 (small and base sizes), in a lie-detection classification task in three English-language datasets encompassing personal opinions, autobiographical memories, and future intentions. After performing stylometric analysis to describe linguistic differences in the three datasets, we tested the small- and base-sized FLAN-T5 in three Scenarios using 10-fold cross-validation: one with train and test set coming from the same single dataset, one with train set coming from two datasets and the test set coming from the third remaining dataset, one with train and test set coming from all the three datasets. We reached state-of-the-art results in Scenarios 1 and 3, outperforming previous benchmarks. The results revealed also that model performance depended on model size, with larger models exhibiting higher performance. Furthermore, stylometric analysis was performed to carry out explainability analysis, finding that linguistic features associated with the Cognitive Load framework may influence the model's predictions.	[Loconte, Riccardo; Pietrini, Pietro] IMT Sch Adv Studies Lucca, Mol Mind Lab, Piazza San Francesco 19, I-55100 Lucca, LU, Italy; [Russo, Roberto] Univ Padua, Dept Math Tullio Levi Civita, Padua, Italy; [Capuozzo, Pasquale; Sartori, Giuseppe] Univ Padua, Dept Gen Psychol, Padua, Italy	IMT School for Advanced Studies Lucca; University of Padua; University of Padua	Loconte, R (corresponding author), IMT Sch Adv Studies Lucca, Mol Mind Lab, Piazza San Francesco 19, I-55100 Lucca, LU, Italy.	riccardo.loconte@imtlucca.it						Amado BG, 2016, INT J CLIN HLTH PSYC, V16, P201, DOI 10.1016/j.ijchp.2016.01.002; Amado BG, 2015, EUR J PSYCHOL APPL L, V7, P3, DOI 10.1016/j.ejpal.2014.11.002; [Anonymous], 2015, EMNLP, DOI [10.18653/v1/d15-1133, DOI 10.18653/V1/D15-1133]; Bond CF, 2006, PERS SOC PSYCHOL REV, V10, P214, DOI 10.1207/s15327957pspr1003_2; Bond GD, 2023, PSYCHOL REP, V126, P3090, DOI 10.1177/00332941221105212; Bond GD, 2017, APPL COGNITIVE PSYCH, V31, P668, DOI 10.1002/acp.3376; Bond GD, 2005, APPL COGNITIVE PSYCH, V19, P313, DOI 10.1002/acp.1087; Boyd RJ, 2022, DIVERS DISTRIB, V28, P1404, DOI 10.1111/ddi.13551; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Capuozzo P, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1423; Chen H, 2012, INTEGR SER INFORM SY, V30, P1, DOI 10.1007/978-1-4614-1557-2; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Conroy NK., 2015, Proc Assoc Inf Sci Technol, V52, P1, DOI [10.1002/pra2.2015.145052010082, DOI 10.1002/PRA2.2015.145052010082]; Constâncio AS, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0281323; Daelemans Walter, 2013, Computational Linguistics and Intelligent Text Processing. 14th International Conference, CICLing 2013. Proceedings, P451, DOI 10.1007/978-3-642-37256-8_37; DePaulo BM, 2003, PSYCHOL BULL, V129, P74, DOI 10.1037//0033-2909.129.1.74; Fornaciari T., 2014, P 14 C EUR CHAPT ASS, DOI [10.3115/v1/e14-1030n, DOI 10.3115/V1/E14-1030N]; Fornaciari T, 2013, ARTIF INTELL LAW, V21, P303, DOI 10.1007/s10506-013-9140-4; Gancedo Y, 2021, EUR J PSYCHOL APPL L, V13, P99; Hancock JT, 2008, DISCOURSE PROCESS, V45, P1, DOI 10.1080/01638530701739181; Hauch V, 2015, PERS SOC PSYCHOL REV, V19, P307, DOI 10.1177/1088868314556539; Hernández-Castañeda A, 2017, SOFT COMPUT, V21, P585, DOI 10.1007/s00500-016-2409-2; Ilias L., 2022, PREPRINT; JOHNSON MK, 1981, PSYCHOL REV, V88, P67, DOI 10.1037/0033-295X.88.1.67; Kleinberg B, 2021, ACTA PSYCHOL, V213, DOI 10.1016/j.actpsy.2020.103250; Kleinberg B, 2017, COLLABRA-PSYCHOL, V3, DOI 10.1525/collabra.80; Kleinberg B, 2018, APPL COGNITIVE PSYCH, V32, P354, DOI 10.1002/acp.3407; Kleinberg B, 2018, J FORENSIC SCI, V63, P714, DOI 10.1111/1556-4029.13645; Kleinberg Bennett, 2019, Center for Open Science, DOI [10.31234/osf.io/p3qjh, DOI 10.31234/OSF.IO/P3QJH]; Levine TR, 2014, J LANG SOC PSYCHOL, V33, P378, DOI 10.1177/0261927X14535916; Levine TR, 1999, COMMUN MONOGR, V66, P125, DOI 10.1080/03637759909376468; Levitan S. I., 2018, NAACL HLT 2018 2018, V1, P1941, DOI [DOI 10.18653/V1/N18-1176, 10.18653/v1, DOI 10.18653/V1, 10.18653/v1/N18-1176]; Lin YC, 2023, Arxiv, DOI arXiv:2306.07111; Masip J, 2005, PSYCHOL CRIME LAW, V11, P99, DOI 10.1080/10683160410001726356; Mbaziira A. V., 2017, P INT C COMP DAT AN, DOI [10.1145/3093241.3093280, DOI 10.1145/3093241.3093280]; MCGRAW KO, 1992, PSYCHOL BULL, V111, P361, DOI 10.1037/0033-2909.111.2.361; Mihalcea Rada., 2009, Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, P309, DOI [10.3115/1667583.1667679, DOI 10.3115/1667583.1667679]; Monaro M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20462-6; Moore JH, 1999, PHYS MED BIOL, V44, pL11, DOI 10.1088/0031-9155/44/6/101; Nahari G, 2014, LEGAL CRIMINOL PSYCH, V19, P227, DOI 10.1111/j.2044-8333.2012.02069.x; Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010; Ott M, 2011, Arxiv, DOI [arXiv:1107.4557, DOI 10.48550/ARXIV.1107.4557]; Pennebaker J. W., 2001, Linguistic Inquiry and Word Count: LIWC 2001, DOI DOI 10.4018/978-1-60960-741-8.CH012; P‚rez-Rosas V, 2017, Arxiv, DOI [arXiv:1708.07104, DOI 10.48550/ARXIV.1708.07104]; Pérez-Rosas V, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P440; Rissola Esteban Andres, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P296, DOI 10.1007/978-3-030-45439-5_20; Sap M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2211715119; Sarzynska-Wawer J, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0281179; Schutte M., 2021, Center for Open Science, DOI [10.31234/osf.io/cth58, DOI 10.31234/OSF.IO/CTH58]; Sola-Sales S, 2023, BRAIN SCI, V13, DOI 10.3390/brainsci13020317; Sporer S. L., 2004, Reality monitoring and detection of deception in The Detection of Deception in Forensic Contexts, P64, DOI [10.1017/cbo9780511490071.004, DOI 10.1017/CBO9780511490071.004]; Sporer SL, 1997, APPL COGNITIVE PSYCH, V11, P373; Street CNH, 2015, SCAND J PSYCHOL, V56, P254, DOI 10.1111/sjop.12204; Tomas F, 2022, FRONT COMMUN, V7, DOI 10.3389/fcomm.2022.792378; Verschuere B, 2023, NAT HUM BEHAV, V7, P718, DOI 10.1038/s41562-023-01556-2; Vrij A., 2019, Evidence-Based Investigative Interviewing: Applying Cognitive Principles, P116, DOI DOI 10.4324/9781315160276-7; Vrij A, 2022, BRAIN SCI, V12, DOI 10.3390/brainsci12121644; Vrij A, 2017, LEGAL CRIMINOL PSYCH, V22, P1, DOI 10.1111/lcrp.12088; Vrij A, 2016, J APPL RES MEM COGN, V5, P302; Walczyk JJ, 2014, NEW IDEAS PSYCHOL, V34, P22, DOI 10.1016/j.newideapsych.2014.03.001; Xiaoling Chen, 2011, Machine Learning and Data Mining in Pattern Recognition. Proceedings 7th International Conference, MLDM 2011, P375, DOI 10.1007/978-3-642-23199-5_28; Yancheva M., 2013, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics Volume 1: Long Papers, P944; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f	64	0	0	7	7	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	DEC 21	2023	13	1							22849	10.1038/s41598-023-50214-0	http://dx.doi.org/10.1038/s41598-023-50214-0			19	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	EA8R5	38129677	Green Submitted, gold			2024-07-03	WOS:001136279200079
J	Sridharan, K; Sivaramakrishnan, G				Sridharan, Kannan; Sivaramakrishnan, Gowri			Enhancing readability of USFDA patient communications through large language models: a proof-of-concept study	EXPERT REVIEW OF CLINICAL PHARMACOLOGY			English	Article; Early Access						Artificial intelligence; ChatGPT; gemini; USFDA; drug safety communications; medication Guides	DRUG SAFETY COMMUNICATIONS; LITERACY; RISK	BackgroundThe US Food and Drug Administration (USFDA) communicates new drug safety concerns through drug safety communications (DSCs) and medication guides (MGs), which often challenge patients with average reading abilities due to their complexity. This study assesses whether large language models (LLMs) can enhance the readability of these materials.MethodsWe analyzed the latest DSCs and MGs, using ChatGPT 4.0 (c) and Gemini (c) to simplify them to a sixth-grade reading level. Outputs were evaluated for readability, technical accuracy, and content inclusiveness.ResultsOriginal materials were difficult to read (DSCs grade level 13, MGs 22). LLMs significantly improved readability, reducing the grade levels to more accessible readings (Single prompt - DSCs: ChatGPT 4.0 (c) 10.1, Gemini (c) 8; MGs: ChatGPT 4.0 (c) 7.1, Gemini (c) 6.5. Multiple prompts - DSCs: ChatGPT 4.0 (c) 10.3, Gemini (c) 7.5; MGs: ChatGPT 4.0 (c) 8, Gemini (c) 6.8). LLM outputs retained technical accuracy and key messages.ConclusionLLMs can significantly simplify complex health-related information, making it more accessible to patients. Future research should extend these findings to other languages and patient groups in real-world settings.	[Sridharan, Kannan] Arabian Gulf Univ, Coll Med & Med Sci, Dept Pharmacol & Therapeut, Manama, Bahrain; [Sivaramakrishnan, Gowri] Primary Hlth Care Ctr, Special Dent Residency Program, Manama, Bahrain	Arabian Gulf University	Sridharan, K (corresponding author), Arabian Gulf Univ, Coll Med & Med Sci, Dept Pharmacol & Therapeut, Manama, Bahrain.	skannandr@gmail.com						accessdata, US FDA Medication Guides; [Anonymous], 2009, Simply Put: A guide for creating easy-to-understand materials; Ayre J, 2024, J GEN INTERN MED, V39, P573, DOI 10.1007/s11606-023-08469-w; Bahri P, 2023, DRUG SAFETY, DOI 10.1007/s40264-023-01285-5; Bakdash L, 2024, J GEN INTERN MED, V39, P492, DOI 10.1007/s11606-023-08497-6; Benjamens S., 2023, JMIR AI, V2, pe47283; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Cascella M, 2024, J MED SYST, V48, DOI 10.1007/s10916-024-02045-3; CDER's Drug Safety Communications, Ensuring postmarket safety; chat.openai, ChatGPT 4.0; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Davis TC, 2006, J GEN INTERN MED, V21, P847, DOI 10.1111/j.1525-1497.2006.00529.x; Department of Health and Human Services, 2004, Pt, P115; Drug Safety Communications, ABOUT US; fda, FDA's external communications; federalregister, Medication Guides: Patient Medication Information. A Proposed Rule by the Food and Drug Administration on 05/31/2023; Furedi A, 1999, HUM REPROD UPDATE, V5, P621, DOI 10.1093/humupd/5.6.621; Gibbons RD, 2007, AM J PSYCHIAT, V164, P1356, DOI 10.1176/appi.ajp.2007.07030454; Goldman SA, 2004, DRUG SAFETY, V27, P519, DOI 10.2165/00002018-200427080-00005; Google, 2024, Gemini; Hutchinson N, 2016, AM J MED, V129, P637, DOI 10.1016/j.amjmed.2016.01.008; Kesselheim AS, 2019, J LAW MED ETHICS, V47, P430, DOI 10.1177/1073110519876176; Kesselheim AS, 2019, DRUG SAFETY, V42, P1287, DOI 10.1007/s40264-019-00849-8; Kim J, 2018, US PHARM, V43, P30; Koch-Weser S, 2010, J HEALTH COMMUN, V15, P590, DOI 10.1080/10810730.2010.499592; Lam WY, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/217047; Lipovetsky S, 2023, AXIOMS, V12, DOI 10.3390/axioms12050421; Marcum ZA, 2012, AM J GERIATR PHARMAC, V10, P264, DOI 10.1016/j.amjopharm.2012.05.002; Mason LJ., 2018, ASA Monitor, V81, P6; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/52865; Moons P, 2023, Eur J Cardiovasc Nurs; readable, Readable; Santana S, 2021, J PUBLIC HEALTH MAN, V27, pS258, DOI 10.1097/PHH.0000000000001324; Shane R, 2009, AM J HEALTH-SYST PH, V66, pS6, DOI 10.2146/ajhp090461; Stevenson FA, 2004, HEALTH EXPECT, V7, P235, DOI 10.1111/j.1369-7625.2004.00281.x; Wolf MS, 2006, PATIENT EDUC COUNS, V62, P316, DOI 10.1016/j.pec.2006.06.010; Wolf MS, 2012, J GEN INTERN MED, V27, P1714, DOI 10.1007/s11606-012-2068-7; Wood R, 1997, Popul Trends, P5; Zaretsky J, 2024, JAMA NETW OPEN, V7, DOI 10.1001/jamanetworkopen.2024.0357	39	0	0	1	1	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1751-2433	1751-2441		EXPERT REV CLIN PHAR	Expert Rev. Clin. Pharmacol.	2024 JUN 6	2024										10.1080/17512433.2024.2363840	http://dx.doi.org/10.1080/17512433.2024.2363840		JUN 2024	11	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	TO0A5	38823007				2024-07-03	WOS:001242074000001
J	Li, ZY; Chen, YF; Zhang, X; Liang, X				Li, Zhiyu; Chen, Yanfang; Zhang, Xuan; Liang, Xun			BookGPT: A General Framework for Book Recommendation Empowered by Large Language Model	ELECTRONICS			English	Article						book recommendation; large language model; general recommendation		With the continuous development and change exhibited by large language model (LLM) technology, represented by generative pretrained transformers (GPTs), many classic scenarios in various fields have re-emerged with new opportunities. This paper takes ChatGPT as the modeling object, incorporates LLM technology into the typical book resource understanding and recommendation scenario for the first time, and puts it into practice. By building a ChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT, this paper attempts to apply ChatGPT to recommendation modeling for three typical tasks: book rating recommendation, user rating recommendation, and the book summary recommendation; it also explores the feasibility of LLM technology in book recommendation scenarios. At the same time, based on different evaluation schemes for book recommendation tasks and the existing classic recommendation models, this paper discusses the advantages and disadvantages of the BookGPT in book recommendation scenarios and analyzes the opportunities and improvement directions for subsequent LLMs in these scenarios. The experimental research shows the following: (1) The BookGPT can achieve good recommendation results in existing classic book recommendation tasks. Especially in cases containing less information about the target object to be recommended, such as zero-shot or one-shot learning tasks, the performance of the BookGPT is close to or even better than that of the current classic book recommendation algorithms, and this method has great potential for improvement. (2) In text generation tasks such as book summary recommendation, the recommendation effect of the BookGPT model is better than that of the manual editing process of Douban Reading, and it can even perform personalized interpretable content recommendations based on readers' attribute and identity information, making it more persuasive than interpretable one-size-fits-all recommendation models. Finally, we have open-sourced the relevant datasets and experimental codes, hoping that the exploratory program proposed in this paper can inspire the development of more LLMs to expand their applications and theoretical research prospects in the field of book recommendation and general recommendation tasks.	[Li, Zhiyu] Inst Adv Algorithms Res, Shanghai 200232, Peoples R China; [Chen, Yanfang] Renmin Univ China, Lib, Beijing 100872, Peoples R China; [Zhang, Xuan; Liang, Xun] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China	Renmin University of China; Renmin University of China	Chen, YF (corresponding author), Renmin Univ China, Lib, Beijing 100872, Peoples R China.	cyf@ruc.edu.cn	li, aakas/KEZ-9616-2024; LI, Zhi-Yu/HCI-7304-2022	LI, Zhi-Yu/0000-0002-7320-8983	Fundamental Research Funds for the Central Universities	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	No Statement Available	[Anonymous], 1998, Statistical methods for speech recognition; [Anonymous], OpenAI Introducing ChatGPT; [Anonymous], Baidu Wenxin Yiyan; [Anonymous], 2017, Goodbooks-10k: a new dataset for book recommendations; Bellogín A, 2014, ACM T WEB, V8, DOI 10.1145/2579993; Bengio Y., 2000, P ADV NEURAL INFORM, VVolume 13; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Lipton ZC, 2015, Arxiv, DOI arXiv:1506.00019; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cox C., 2023, Coll. Res. Libr. News, V84, P99, DOI DOI 10.5860/CRLN.84.3.99; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dreibelbis E., ChatGPT Passes Google Coding Interview for Level 3 Engineer with $183K Salary; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; George T, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P625, DOI 10.1109/icdm.2005.14; Jiang H, 2023, Arxiv, DOI arXiv:2304.09960; Lampinen AK, 2022, Arxiv, DOI arXiv:2204.02329; Kirtania D.K., 2023, Qeios, DOI [10.32388/FO1CP6.3, DOI 10.32388/FO1CP6.3]; Koren Y, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644874; Lemire D, 2005, SIAM PROC S, P471; Linden G, 2003, IEEE INTERNET COMPUT, V7, P76, DOI 10.1109/MIC.2003.1167344; Liu V., 2022, P 2022 CHI C HUM FAC, P1; Liu XY, 2005, ANNU REV INFORM SCI, V39, P3; Lu QY, 2024, Arxiv, DOI arXiv:2303.13809; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Ma C, 2020, AAAI CONF ARTIF INTE, V34, P5045; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mnih A., 2007, P ADV NEURAL INFORM, VVolume 20; Panda Subhajit, 2023, Library Hi Tech News, P22, DOI 10.1108/LHTN-02-2023-0032; Rajpurkar S., 2015, Int. J. Innovative Res. Sci. Technol., V1, P314; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Saravia E., 2022, Prompt Engineering Guide; Sarzynska-Wawer J, 2021, PSYCHIAT RES, V304, DOI 10.1016/j.psychres.2021.114135; Shazhaev I., 2023, At. Indones. J., V28, P1; Tewari AS, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P135, DOI 10.1109/IC3I.2014.7019651; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Dien TT, 2022, J INFORM TELECOMMUN, V6, P381, DOI 10.1080/24751839.2022.2058250; Vaswani A, 2017, ADV NEUR IN, V30; Verma M., 2023, INT J TREND SCI RES, V7, P961; Wang X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P878, DOI 10.1145/3442381.3450133; WANG Y, 2013, C LEARN THEOR, P25, DOI DOI 10.3969/J.ISSN.1007-7545.2013.11.09; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu SW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3535101; Xu CH, 2018, INFORM PROCESS MANAG, V54, P463, DOI 10.1016/j.ipm.2018.02.005; Zeng A., 2023, P 11 INT C LEARN REP; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	47	0	0	33	34	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	NOV	2023	12	22							4654	10.3390/electronics12224654	http://dx.doi.org/10.3390/electronics12224654			19	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	AU0R0		gold, Green Submitted			2024-07-03	WOS:001120854800001
C	Grimme, B; Pohl, J; Winkelmann, H; Stampe, L; Grimme, C		Ceolin, D; Caselli, T; Tulin, M		Grimme, Britta; Pohl, Janina; Winkelmann, Hendrik; Stampe, Lucas; Grimme, Christian			Lost in Transformation: Rediscovering LLM-Generated Campaigns in Social Media	DISINFORMATION IN OPEN ONLINE MEDIA, MISDOOM 2023	Lecture Notes in Computer Science		English	Proceedings Paper	5th Multidisciplinary International Symposium on Disinformation in Open Online Media (MISDOOM)	NOV 21-22, 2023	Amsterdam, NETHERLANDS	European Res Ctr Informat Syst		Social Media; Campaign Detection; Large Language Models; Siamese Neural Networks		This paper addresses new challenges of detecting campaigns in social media, which emerged with the rise of Large Language Models (LLMs). LLMs particularly challenge algorithms focused on the temporal analysis of topical clusters. Simple similarity measures can no longer capture and map campaigns that were previously broadly similar in content. Herein, we analyze whether the classification of messages over time can be profitably used to rediscover poorly detectable campaigns at the content level. Thus, we evaluate classical classifiers and a new method based on siamese neural networks. Our results show that campaigns can be detected despite the limited reliability of the classifiers as long as they are based on a large amount of simultaneously spread artificial content.	[Grimme, Britta] TU Dortmund Univ, Dept Comp Sci, Dortmund, Germany; [Pohl, Janina; Stampe, Lucas; Grimme, Christian] Univ Munster, Computat Social Sci & Syst Anal, Munster, Germany; [Winkelmann, Hendrik] Univ Munster, Pract Comp Sci, Munster, Germany	Dortmund University of Technology; University of Munster; University of Munster	Grimme, C (corresponding author), Univ Munster, Computat Social Sci & Syst Anal, Munster, Germany.	britta.grimme@tu-dortmund.de; janina.pohl@uni-muenster.de; hendrik.winkelmann@uni-muenster.de; lucas.stampe@uni-muenster.de; christian.grimme@uni-muenster.de		Lutke Stockdiek, Janina/0000-0001-5251-1169; Grimme, Britta/0009-0008-2282-5130	European Research Center in Information Systems (ERCIS); German Federal Ministry of Education and Research [FKZ: 16KIS1531K]	European Research Center in Information Systems (ERCIS); German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	The authors acknowledge support by the European Research Center in Information Systems (ERCIS) and by the project HybriD (FKZ: 16KIS1531K) funded by the German Federal Ministry of Education and Research.	Alamleh Hosam, 2023, 2023 Systems and Information Engineering Design Symposium (SIEDS), P154, DOI 10.1109/SIEDS58326.2023.10137767; Antoun W, 2023, Arxiv, DOI arXiv:2306.05871; Assenmacher Dennis, 2020, Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis. 12th International Conference, SCSM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12194), P201, DOI 10.1007/978-3-030-49570-1_14; Assenmacher D, 2022, LECT NOTES ARTIF INT, V13757, P3, DOI 10.1007/978-3-031-21743-2_1; Assenmacher D, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120939264; Bellutta D., 2023, J. of Big Data, V10, P1; Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339; Chakraborty S, 2023, Arxiv, DOI arXiv:2304.04736; Cinelli M, 2022, DECIS SUPPORT SYST, V160, DOI 10.1016/j.dss.2022.113819; Cresci S, 2016, IEEE INTELL SYST, V31, P58, DOI 10.1109/MIS.2016.29; Crothers E, 2023, Arxiv, DOI arXiv:2210.07321; Davis CA, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P273, DOI 10.1145/2872518.2889302; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; EleutherAI, 2022, GPT Neo-An Implementation of Model & Data Parallel GPT3- Like Models Using the Mesh-Tensorflow Library; Erhardt K, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P1214, DOI 10.1145/3543873.3587672; Fagni T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251415; Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133; Ferrara E., 2023, First Monday, V28, P1, DOI [10.5210/fm.v28i6.13185, DOI 10.5210/FM.V28I6.13185]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Grimme C., 2020, P FLOR ART INT RES S; Grimme C, 2022, LECT NOTES COMPUT SC, V13545, P79, DOI 10.1007/978-3-031-18253-2_6; Grimme C, 2018, LECT NOTES COMPUT SC, V10913, P445, DOI 10.1007/978-3-319-91521-0_32; Grimme C, 2017, BIG DATA, V5, P279, DOI 10.1089/big.2017.0044; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Ippolito D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1808; James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1; Kirchner J.H., 2022, New AI classifier for indicating AI-written text; Kumarage T, 2023, Arxiv, DOI arXiv:2303.03697; Michail D., 2022, INT J INFORM MANAGE, V2, P100104, DOI 10.1016/j.jjimei.2022.100104; Mitchell E, 2023, Arxiv, DOI [arXiv:2301.11305, DOI 10.48550/ARXIV.2301.11305]; Mitrovic Sandra, 2023, arXiv; Pohl J., 2022, WORKSH P 16 INT C WE; Radford A., 2018, IMPROVING LANGUAGE U; Rauchfleisch A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241045; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Singh A, 2023, 2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC, P489, DOI 10.1109/CCWC57344.2023.10099219; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; Vaswani A, 2017, ADV NEUR IN, V30; Verma V, 2024, Arxiv, DOI arXiv:2305.15047; Weber D, 2021, SOC NETW ANAL MIN, V11, DOI 10.1007/s13278-021-00815-2	41	1	1	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-47895-6; 978-3-031-47896-3	LECT NOTES COMPUT SC			2023	14397						72	87		10.1007/978-3-031-47896-3_6	http://dx.doi.org/10.1007/978-3-031-47896-3_6			16	Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Communication; Computer Science	BW5HO					2024-07-03	WOS:001160755400006
J	You, HX; Ye, Y; Zhou, TY; Zhu, Q; Du, J				You, Hengxu; Ye, Yang; Zhou, Tianyu; Zhu, Qi; Du, Jing			Robot-Enabled Construction Assembly with Automated Sequence Planning Based on ChatGPT: RoboGPT	BUILDINGS			English	Article						robot-assembly; sequential learning; ChatGPT	GENETIC ALGORITHM; OPTIMIZATION; SEARCH; DESIGN	Robot-based assembly in construction has emerged as a promising solution to address numerous challenges such as increasing costs, labor shortages, and the demand for safe and efficient construction processes. One of the main obstacles in realizing the full potential of these robotic systems is the need for effective and efficient sequence planning for construction tasks. Current approaches, including mathematical and heuristic techniques or machine learning methods, face limitations in their adaptability and scalability to dynamic construction environments. To expand the current robot system's sequential understanding ability, this paper introduces RoboGPT, a novel system that leverages the advanced reasoning capabilities of ChatGPT, a large language model, for automated sequence planning in robot-based assembly applied to construction tasks. The proposed system adapts ChatGPT for construction sequence planning and demonstrates its feasibility and effectiveness through experimental evaluation including two case studies and 80 trials involving real construction tasks. The results show that RoboGPT-driven robots can handle complex construction operations and adapt to changes on the fly. This paper contributes to the ongoing efforts to enhance the capabilities and performance of robot-based assembly systems in the construction industry, and it paves the way for further integration of large language model technologies in the field of construction robotics.	[You, Hengxu; Ye, Yang; Zhou, Tianyu; Zhu, Qi; Du, Jing] Univ Florida, Engn Sch Sustainable Infrastruct & Environm, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Du, J (corresponding author), Univ Florida, Engn Sch Sustainable Infrastruct & Environm, Gainesville, FL 32611 USA.	you.h@ufl.edu; ye.yang@ufl.edu; zhoutianyu@ufl.edu; qi.zhu@nist.gov; eric.du@essie.ufl.edu	Zhou, Tianyu/IYJ-7379-2023; Du, Jing/AHE-6199-2022	Du, Jing/0000-0002-0481-4875	National Science Foundation (NSF) [2128895]	National Science Foundation (NSF)(National Science Foundation (NSF))	This research was funded by the National Science Foundation (NSF), grant number 2128895. The APC was funded by the NSF.	Abuwarda Z, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000587; Adami P, 2022, J COMPUT CIVIL ENG, V36, DOI 10.1061/(ASCE)CP.1943-5487.0001016; Alatartsev S, 2015, J INTELL ROBOT SYST, V80, P279, DOI 10.1007/s10846-015-0190-6; Ali AK, 2021, J BUILD ENG, V33, DOI 10.1016/j.jobe.2020.101556; Apolinarska AA, 2021, AUTOMAT CONSTR, V125, DOI 10.1016/j.autcon.2021.103569; Ardiny H, 2015, RSI INT CONF ROBOT M, P418, DOI 10.1109/ICRoM.2015.7367821; Arinez JF, 2020, J MANUF SCI E-T ASME, V142, DOI 10.1115/1.4047855; Badini S, 2023, ADV IND ENG POLY RES, V6, P278, DOI 10.1016/j.aiepr.2023.03.003; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Berry A, 2003, LECT NOTES COMPUT SC, V2880, P58; Bewoor LA, 2018, PROCEDIA MANUF, V22, P57, DOI 10.1016/j.promfg.2018.03.010; Cai SY, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100989; Caiafa CF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11094132; Cao TH, 1998, IEEE T SYST MAN CY C, V28, P204, DOI 10.1109/5326.669552; Cardno CA, 2018, CIVIL ENG, V88, P38; Carey NE, 2021, FRONT ROBOT AI, V8, DOI 10.3389/frobt.2021.645728; CHEN CLP, 1993, IEEE T SYST MAN CYB, V23, P1359, DOI 10.1109/21.260667; Chen IM, 1996, IEEE INT CONF ROBOT, P1440, DOI 10.1109/ROBOT.1996.506908; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; Ciosici MR, 2022, Arxiv, DOI arXiv:2208.12097; Craig Iain., 1995, Blackboard Systems; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dezert J, 2020, PROCEEDINGS OF 2020 23RD INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION 2020), P195; Ding YY, 2017, ROBOT CIM-INT MANUF, V44, P67, DOI 10.1016/j.rcim.2016.08.008; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao YF, 2022, AUTOMAT CONSTR, V140, DOI 10.1016/j.autcon.2022.104370; Garcia-Sabater JP, 2012, FLEX SERV MANUF J, V24, P171, DOI 10.1007/s10696-011-9126-z; Gardner L, 2020, J CONSTR STEEL RES, V172, DOI 10.1016/j.jcsr.2020.106233; Han ZP, 2021, FRONT MECH ENG-PRC, V16, P393, DOI 10.1007/s11465-020-0613-3; Harinarain N., 2021, P 37 ANN ARCOM C ONL, P36; Huang WL, 2022, Arxiv, DOI [arXiv:2207.05608, 10.48550/arXiv.2207.05608]; Kim T, 2020, J CLEAN PROD, V257, DOI 10.1016/j.jclepro.2020.120527; L'Heureux A, 2017, IEEE ACCESS, V5, P7776, DOI 10.1109/ACCESS.2017.2696365; Lacave C, 2004, KNOWL ENG REV, V19, P133, DOI 10.1017/S0269888904000190; Li WD, 2004, INT J PROD RES, V42, P1955, DOI 10.1080/00207540310001652897; Liang CJ, 2020, AUTOMAT CONSTR, V120, DOI 10.1016/j.autcon.2020.103370; Liu Zhifeng, 2011, China Mechanical Engineering, V22, P2162; Mitrovic Sandra, 2023, arXiv; Oke AE, 2022, CONSTR ECON BUILD, V22, P52, DOI 10.5130/AJCEB.v22i2.8015; Osa T, 2022, IEEE ACCESS, V10, P4523, DOI 10.1109/ACCESS.2022.3140781; Prieto SA, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13040857; Shan H., 2006, P 2006 INT TECHN INN, P1573; Shi YM, 2020, AUTOMAT CONSTR, V119, DOI 10.1016/j.autcon.2020.103367; Singh I, 2022, Arxiv, DOI arXiv:2209.11302; Song S.H., 2022, P 9 INT C CONSTRUCTI, P336; Souza MJF, 2010, EUR J OPER RES, V207, P1041, DOI 10.1016/j.ejor.2010.05.031; Strub MP, 2020, IEEE INT CONF ROBOT, P3191, DOI [10.1109/ICRA40945.2020.9197338, 10.1109/icra40945.2020.9197338]; Sun H, 2021, J BUILD ENG, V33, DOI 10.1016/j.jobe.2020.101816; Sundstrom N., 2012, IFAC P, V45, P1580; Suszynski M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110414; Tseng HE, 2018, EXPERT SYST APPL, V96, P492, DOI 10.1016/j.eswa.2017.11.004; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Vossen T, 2000, KNOWL ENG REV, V15, P85, DOI 10.1017/S0269888900001065; Wieckowski J, 2023, ENG APPL ARTIF INTEL, V122, DOI 10.1016/j.engappai.2023.106114; Xia H, 2016, COMPUT IND ENG, V102, P99, DOI 10.1016/j.cie.2016.10.015; Xing Y, 2007, ASSEMBLY AUTOM, V27, P157, DOI 10.1108/01445150710733423; Yang FJ, 2018, IEEE-CAA J AUTOMATIC, V5, P389, DOI 10.1109/JAS.2017.7510805; Yassine A., 2004, Urbana, V51, P1; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Zhang JS, 2022, COMPUTING IN CIVIL ENGINEERING 2021, P1204; Zhu AY, 2021, IEEE INT CON AUTO SC, P1282, DOI 10.1109/CASE49439.2021.9551402	62	3	3	34	68	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-5309		BUILDINGS-BASEL	BUILDINGS-BASEL	JUL	2023	13	7							1772	10.3390/buildings13071772	http://dx.doi.org/10.3390/buildings13071772			24	Construction & Building Technology; Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Construction & Building Technology; Engineering	N6LC6		gold, Green Submitted			2024-07-03	WOS:001038093500001
J	Paustian, T; Slinger, B				Paustian, Timothy; Slinger, Betty			Students are using large language models and AI detectors can often detect their use	FRONTIERS IN EDUCATION			English	Article						artificial intelligence; artificial intelligence detectors; plagiarism; cheating; large language model (LLM)		Large language model (LLM) artificial intelligence (AI) has been in development for many years. Open AI thrust them into the spotlight in late 2022 when it released ChatGPT to the public. The wide availability of LLMs resulted in various reactions, from jubilance to fear. In academia, the potential for LLM abuse in written assignments was immediately recognized, with some instructors fearing they would have to eliminate this mode of evaluation. In this study, we seek to answer two questions. First, how are students using LLM in their college work? Second, how well do AI detectors function in the detection of AI-generated text? We organized 153 students from an introductory microbiology course to write essays on the regulation of the tryptophan operon. We then asked AI the same question and had the students try to disguise the answer. We also surveyed students about their use of LLMs. The survey found that 46.9% of students use LLM in their college work, but only 11.6% use it more than once a week. Students are unclear about what constitutes unethical use of LLMs. Unethical use of LLMs is a problem, with 39% of students admitting to using LLMs to answer assessments and 7% using them to write entire papers. We also tested their prose against five AI detectors. Overall, AI detectors could differentiate between human and AI-written text, identifying 88% correctly. Given the stakes, having a 12% error rate indicates we cannot rely on AI detectors alone to check LLM use, but they may still have value.	[Paustian, Timothy; Slinger, Betty] Univ Wisconsin Madison, Dept Bacteriol, Madison, WI 53706 USA	University of Wisconsin System; University of Wisconsin Madison	Paustian, T (corresponding author), Univ Wisconsin Madison, Dept Bacteriol, Madison, WI 53706 USA.	paustian@wisc.edu						Abd-Elaal ES, 2022, EUR J ENG EDUC, V47, P725, DOI 10.1080/03043797.2022.2046709; Bird S., 2009, NATURAL LANGUAGE PRO; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Coley M., 2023, Guidance on AI detection and why We're disabling Turnitin's AI detector | Brightspace support | Vanderbilt University; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00140-5; Gillham J., 2023, AI content detector accuracy review + open source dataset and research tool-originality.AI; Graham S, 2015, ELEM SCHOOL J, V115, P523, DOI 10.1086/681947; Gunser V. E., 2021, Communications in Computer and Information Science, V1419, P520, DOI [10.1007/978-3-030-78635-9_67, DOI 10.1007/978-3-030-78635-9_67]; Intelligent, 2023, Intelligent; Klee M., 2023, rolling stone; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Liang WX, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100779; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Waltzer T, 2023, ETHICS BEHAV, V33, P130, DOI 10.1080/10508422.2022.2026775; Ye H., 2023, Cognitive mirage: A review of hallucinations in large language models	16	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2504-284X		FRONT EDUC	Front. Educ.	JUN 7	2024	9								1374889	10.3389/feduc.2024.1374889	http://dx.doi.org/10.3389/feduc.2024.1374889			11	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	UX5T4		gold			2024-07-03	WOS:001251384100001
J	Gartlehner, G; Kahwati, L; Hilscher, R; Thomas, I; Kugley, S; Crotty, K; Viswanathan, M; Nussbaumer-Streit, B; Booth, G; Erskine, N; Konet, A; Chew, R				Gartlehner, Gerald; Kahwati, Leila; Hilscher, Rainer; Thomas, Ian; Kugley, Shannon; Crotty, Karen; Viswanathan, Meera; Nussbaumer-Streit, Barbara; Booth, Graham; Erskine, Nathaniel; Konet, Amanda; Chew, Robert			Data extraction for evidence synthesis using a large language model: A proof-of-concept study	RESEARCH SYNTHESIS METHODS			English	Article; Early Access						accuracy; artificial intelligence; data extraction; evidence synthesis; large language models; proof of concept		Data extraction is a crucial, yet labor-intensive and error-prone part of evidence synthesis. To date, efforts to harness machine learning for enhancing efficiency of the data extraction process have fallen short of achieving sufficient accuracy and usability. With the release of large language models (LLMs), new possibilities have emerged to increase efficiency and accuracy of data extraction for evidence synthesis. The objective of this proof-of-concept study was to assess the performance of an LLM (Claude 2) in extracting data elements from published studies, compared with human data extraction as employed in systematic reviews. Our analysis utilized a convenience sample of 10 English-language, open-access publications of randomized controlled trials included in a single systematic review. We selected 16 distinct types of data, posing varying degrees of difficulty (160 data elements across 10 studies). We used the browser version of Claude 2 to upload the portable document format of each publication and then prompted the model for each data element. Across 160 data elements, Claude 2 demonstrated an overall accuracy of 96.3% with a high test-retest reliability (replication 1: 96.9%; replication 2: 95.0% accuracy). Overall, Claude 2 made 6 errors on 160 data items. The most common errors (n = 4) were missed data items. Importantly, Claude 2's ease of use was high; it required no technical expertise or labeled training data for effective operation (i.e., zero-shot learning). Based on findings of our proof-of-concept study, leveraging LLMs has the potential to substantially enhance the efficiency and accuracy of data extraction for evidence syntheses.	[Gartlehner, Gerald; Kahwati, Leila; Hilscher, Rainer; Thomas, Ian; Kugley, Shannon; Crotty, Karen; Viswanathan, Meera; Booth, Graham; Konet, Amanda; Chew, Robert] RTI Int, Social Stat & Environm Sci, Res Triangle Pk, NC 27709 USA; [Gartlehner, Gerald; Nussbaumer-Streit, Barbara] Danube Univ Krems, Dept Evidence Based Med & Evaluat, Krems, Austria; [Erskine, Nathaniel] Univ North Carolina Chapel Hill, Sch Med, Dept Family Med, Prevent Med Residency Program, Chapel Hill, NC USA	Research Triangle Institute; Danube University Krems; University of North Carolina School of Medicine; University of North Carolina; University of North Carolina Chapel Hill	Gartlehner, G (corresponding author), RTI Int, Social Stat & Environm Sci, Res Triangle Pk, NC 27709 USA.	gerald.gartlehner@donau-uni.ac.at	Chew, Rob/AAI-6054-2020; Gartlehner, Gerald/AAY-2801-2021	Chew, Rob/0000-0002-6979-1766; Gartlehner, Gerald/0000-0001-5531-3678; Crotty, Karen/0000-0002-5633-5040; Konet, Amanda/0000-0001-5295-6483; Kahwati, Leila/0000-0001-6963-2848; Hilscher, Rainer/0000-0002-5004-4584	RTI International Innovation Office; Innovation Team at RTI International	RTI International Innovation Office; Innovation Team at RTI International	Thank you to Colleen Ovelman for her support during the project's initial stages, Petra Wellemsen of Danube University, Krems for manuscript formatting, and the Innovation Team at RTI International for their project support.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anthropic, CLAUDE 2; Bagel J, 2018, DERMATOLOGY THER, V8, P571, DOI 10.1007/s13555-018-0265-y; Blaizot A, 2022, RES SYNTH METHODS, V13, P353, DOI 10.1002/jrsm.1553; Blauvelt A, 2020, BRIT J DERMATOL, V182, P1348, DOI 10.1111/bjd.18851; Bonin Francesca, 2020, AMIA Annu Symp Proc, V2020, P253; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen HL, 2024, Arxiv, DOI [arXiv:2311.16989, 10.48550/arXiv.2311.16989, DOI 10.48550/ARXIV.2311.16989]; Eden J, 2011, FINDING WHAT WORKS IN HEALTH CARE: STANDARDS FOR SYSTEMATIC REVIEWS, P1; Glatt S, 2017, BRIT J CLIN PHARMACO, V83, P991, DOI 10.1111/bcp.13185; Higgins JPT TJ, 2023, Cochrane Handbook for Systematic Reviews of Interventions; Jonnalagadda SR, 2015, SYST REV-LONDON, V4, DOI 10.1186/s13643-015-0066-7; Lebwohl M, 2018, J AM ACAD DERMATOL, V79, P266, DOI 10.1016/j.jaad.2018.04.013; Li TJ, 2019, J CLIN EPIDEMIOL, V115, P77, DOI 10.1016/j.jclinepi.2019.07.005; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Marshall IJ, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1074-9; Mathes T, 2017, BMC MED RES METHODOL, V17, DOI 10.1186/s12874-017-0431-4; Nussbaumer-Streit B, 2021, J CLIN EPIDEMIOL, V139, P287, DOI 10.1016/j.jclinepi.2021.05.019; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papp KA, 2018, J AM ACAD DERMATOL, V79, P277, DOI 10.1016/j.jaad.2018.03.037; Reich K, 2017, BRIT J DERMATOL, V177, P1014, DOI 10.1111/bjd.15666; Reich K, 2017, J EUR ACAD DERMATOL, V31, P507, DOI 10.1111/jdv.14015; Reich K, 2017, J AM ACAD DERMATOL, V76, P418, DOI 10.1016/j.jaad.2016.11.042; Restificar A., 2012, Proceedings of the ACM Sixth International Workshop on Data and Text Mining in Biomedical Informatics; Schmidt Lena, 2021, F1000Res, V10, P401, DOI 10.12688/f1000research.51117.1; Thaçi D, 2015, J AM ACAD DERMATOL, V73, P400, DOI 10.1016/j.jaad.2015.05.013; Trikalinos TA, 2012, J GEN INTERN MED, V27, pS67, DOI 10.1007/s11606-012-2031-7; Vaswani A, 2017, ADV NEUR IN, V30; Warren RB, 2021, BRIT J DERMATOL, V184, P50, DOI 10.1111/bjd.19341; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685	32	2	2	13	13	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1759-2879	1759-2887		RES SYNTH METHODS	Res. Synth. Methods	2024 MAR 3	2024										10.1002/jrsm.1710	http://dx.doi.org/10.1002/jrsm.1710		MAR 2024	14	Mathematical & Computational Biology; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Mathematical & Computational Biology; Science & Technology - Other Topics	JY9R1	38432227	Green Submitted, hybrid			2024-07-03	WOS:001176841800001
J	Kamnis, S				Kamnis, Spyros			Generative pre-trained transformers (GPT) for surface engineering	SURFACE & COATINGS TECHNOLOGY			English	Article						Thermal spray; GPT; Generative AI; LLM; Large language model; NLP		The knowledge of scientific articles within Generative Pre-trained Transformers (GPT) is not exhaustive due to factors such as data coverage, freshness, complexity, paywalls, and context. While it can provide general in-formation on scientific topics, it may struggle with specialized terminology, recent research, and nuanced un-derstanding. As a result, relying on GPT as a scientific assistant tool may not be ideal. Instead, it is important to consult specialized resources and databases for a comprehensive understanding of specific scientific domains and access to the latest research. A custom data driven GPT can enhance its performance as a scientific assistant tool by improving domain knowledge, providing up-to-date information, reducing ambiguity and errors, performing customized tasks, and offering enhanced search capabilities. This work demonstrates and evaluates the use of such GPT models using a small selection of peer reviewed published thermal spray articles as the reference domain knowledge. The specific domain knowledge model works exceptionally well outperforming the general state-of-the-art large language models.	[Kamnis, Spyros] Castolin Eutect Monitor Coatings Ltd, Newcastle Upon Tyne NE29 8SE, England		Kamnis, S (corresponding author), Castolin Eutect Monitor Coatings Ltd, Newcastle Upon Tyne NE29 8SE, England.	s_kamnis@hotmail.com		Kamnis, Spyros/0000-0001-6433-3101				[Anonymous], 2013, ECMA-404: the JSON data interchange format; Araguas-Rodriguez S., 2020, PROC ASME TURBO EXPO, DOI [10.1115/GT2020-16004, DOI 10.1115/GT2020-16004]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dimitriadis K, 2022, J ADV PROSTHODONT, V14, P96, DOI 10.4047/jap.2022.14.2.96; Faisal NH, 2022, ADV ENG MATER, V24, DOI 10.1002/adem.202200171; Farkiya A., 2015, INT J COMPUT SCI INF, V6, P5465; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; González S, 2023, J ALLOY COMPD, V936, DOI 10.1016/j.jallcom.2022.168219; González S, 2023, MATER LETT, V331, DOI 10.1016/j.matlet.2022.133504; Gozali E, 2015, SURF COAT TECH, V280, P370, DOI 10.1016/j.surfcoat.2015.09.012; Gozali E, 2014, J THERM SPRAY TECHN, V23, P940, DOI 10.1007/s11666-014-0106-1; Gozali E, 2013, SURF COAT TECH, V228, P176, DOI 10.1016/j.surfcoat.2013.04.026; Gu S, 2009, METALL MATER TRANS A, V40A, P2664, DOI 10.1007/s11661-009-9959-1; Gu S, 2009, SURF COAT TECH, V203, P3485, DOI 10.1016/j.surfcoat.2009.05.024; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Iakovidis DK, 2022, MEAS SCI TECHNOL, V33, DOI 10.1088/1361-6501/ac2dbd; Kamnis S, 2008, COMP MATER SCI, V43, P1172, DOI 10.1016/j.commatsci.2008.03.015; Kamnis S, 2008, SURF COAT TECH, V202, P2715, DOI 10.1016/j.surfcoat.2007.10.006; Kamnis S, 2023, J THERM SPRAY TECHN, V32, P401, DOI 10.1007/s11666-022-01462-5; Kamnis S, 2022, J THERM SPRAY TECHN, V31, P1000, DOI 10.1007/s11666-021-01268-x; Kamnis S, 2006, CHEM ENG SCI, V61, P5427, DOI 10.1016/j.ces.2006.04.005; Kamnis S, 2006, CHEM ENG PROCESS, V45, P246, DOI 10.1016/j.cep.2005.06.011; Kamnis S, 2005, J PHYS D APPL PHYS, V38, P3664, DOI 10.1088/0022-3727/38/19/015; Kamnis S, 2011, J THERM SPRAY TECHN, V20, P630, DOI 10.1007/s11666-010-9606-9; Kamnis S, 2010, J THERM SPRAY TECHN, V19, P31, DOI 10.1007/s11666-009-9382-6; Kamnis S, 2009, COMP MATER SCI, V46, P1038, DOI 10.1016/j.commatsci.2009.05.009; Kamnis S, 2008, J PHYS D APPL PHYS, V41, DOI 10.1088/0022-3727/41/16/165303; Kamnis S, 2019, J THERM SPRAY TECHN, V28, P946, DOI 10.1007/s11666-019-00874-0; Kamnis S, 2010, METALL MATER TRANS A, V41A, P3517, DOI 10.1007/s11661-010-0488-8; Kamnis S, 2007, INT J MODEL IDENTIF, V2, P229, DOI 10.1504/IJMIC.2007.014940; Karantzalis A.E., 2022, Alloys, V1, P70, DOI [10.3390/alloys1010006, DOI 10.3390/ALLOYS1010006]; Katranidis V, 2019, J THERM SPRAY TECHN, V28, P514, DOI 10.1007/s11666-019-00831-x; Katranidis V, 2018, J THERM SPRAY TECHN, V27, P1025, DOI 10.1007/s11666-018-0739-6; Katranidis V, 2018, J THERM SPRAY TECHN, V27, P898, DOI 10.1007/s11666-018-0721-3; Katranidis V, 2017, SURF COAT TECH, V328, P499, DOI 10.1016/j.surfcoat.2017.09.027; Katranidis V, 2017, SURF COAT TECH, V311, P206, DOI 10.1016/j.surfcoat.2017.01.015; Kumar A, 2013, SURF COAT TECH, V220, P164, DOI 10.1016/j.surfcoat.2012.08.061; Kumar A, 2012, APPL PHYS A-MATER, V109, P101, DOI 10.1007/s00339-012-7043-y; Liu J., 2022, LLAMAINDEX, DOI DOI 10.5281/ZENODO.1234; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Mahrukh M, 2016, IND ENG CHEM RES, V55, P7679, DOI 10.1021/acs.iecr.6b01725; Mahrukh M, 2016, IND ENG CHEM RES, V55, P2556, DOI 10.1021/acs.iecr.5b03956; Malamousi K, 2022, SURF COAT TECH, V433, DOI 10.1016/j.surfcoat.2022.128138; Ouyang L., 2022, NEURIPS; Pulsford J, 2020, SURF COAT TECH, V386, DOI 10.1016/j.surfcoat.2020.125468; Pulsford J, 2019, WEAR, V432, DOI 10.1016/j.wear.2019.202965; Pulsford J., 2017, P INT THERM SPRAY C; Seetha H., 2023, INT J RES APPL SCI E, DOI [10.22214/ijraset.2023.48848, DOI 10.22214/IJRASET.2023.48848]; Sfikas AK, 2022, METALS-BASEL, V12, DOI 10.3390/met12071092; Tealab Ahmed, 2018, Future Computing and Informatics Journal, V3, P334, DOI 10.1016/j.fcij.2018.10.003; Tzinava M., 2021, IFIP ADV INF COMMUN, DOI [10.1007/978-3-030-79150-6_16, DOI 10.1007/978-3-030-79150-6_16]; Tzinava M, 2020, SURF COAT TECH, V399, DOI 10.1016/j.surfcoat.2020.126148; Vaswani A, 2017, ADV NEUR IN, V30; Venturi F, 2021, MATER DESIGN, V202, DOI 10.1016/j.matdes.2021.109566; Younes A, 2020, J ALLOY COMPD, V817, DOI 10.1016/j.jallcom.2019.153330; Zeoli N, 2008, COMPUT CHEM ENG, V32, P1661, DOI 10.1016/j.compchemeng.2007.08.008; Zhu ZH, 2015, ACTA MATER, V90, P77, DOI 10.1016/j.actamat.2015.02.010	57	2	2	10	31	ELSEVIER SCIENCE SA	LAUSANNE	PO BOX 564, 1001 LAUSANNE, SWITZERLAND	0257-8972	1879-3347		SURF COAT TECH	Surf. Coat. Technol.	AUG 15	2023	466								129680	10.1016/j.surfcoat.2023.129680	http://dx.doi.org/10.1016/j.surfcoat.2023.129680		JUN 2023	9	Materials Science, Coatings & Films; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science; Physics	K7MA6					2024-07-03	WOS:001018231600001
J	Yang, JY; Liu, C; Deng, WY; Wu, D; Weng, CH; Zhou, YY; Wang, K				Yang, Jingye; Liu, Cong; Deng, Wendy; Wu, Da; Weng, Chunhua; Zhou, Yunyun; Wang, Kai			Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT	PATTERNS			English	Article							BIOMEDICAL TEXT	To enhance phenotype recognition in clinical notes of genetic diseases, we developed two models-PhenoBCBERT and PhenoGPT-for expanding the vocabularies of Human Phenotype Ontology (HPO) terms. While HPO offers a standardized vocabulary for phenotypes, existing tools often fail to capture the full scope of phenotypes due to limitations from traditional heuristic or rule -based approaches. Our models leverage large language models to automate the detection of phenotype terms, including those not in the current HPO. We compare these models with PhenoTagger, another HPO recognition tool, and found that our models identify a wider range of phenotype concepts, including previously uncharacterized ones. Our models also show strong performance in case studies on biomedical literature. We evaluate the strengths and weaknesses of BERT- and GPT-based models in aspects such as architecture and accuracy. Overall, our models enhance automated phenotype detection from clinical texts, improving downstream analyses on human diseases.	[Yang, Jingye; Deng, Wendy; Wu, Da; Zhou, Yunyun; Wang, Kai] Childrens Hosp Philadelphia, Raymond G Perelman Ctr Cellular & Mol Therapeut, Philadelphia, PA 19104 USA; [Liu, Cong; Weng, Chunhua] Columbia Univ, Dept Biomed Informat, New York, NY 10032 USA; [Zhou, Yunyun] Fox Chase Canc Ctr, Biostat & Bioinformat Facil, Philadelphia, PA 19111 USA; [Wang, Kai] Univ Penn, Dept Pathol & Lab Med, Philadelphia, PA 19104 USA; [Yang, Jingye] Univ Penn, Dept Math, Philadelphia, PA 19104 USA	University of Pennsylvania; Pennsylvania Medicine; Childrens Hospital of Philadelphia; Columbia University; Fox Chase Cancer Center; University of Pennsylvania; University of Pennsylvania	Zhou, YY; Wang, K (corresponding author), Childrens Hosp Philadelphia, Raymond G Perelman Ctr Cellular & Mol Therapeut, Philadelphia, PA 19104 USA.; Zhou, YY (corresponding author), Fox Chase Canc Ctr, Biostat & Bioinformat Facil, Philadelphia, PA 19111 USA.; Wang, K (corresponding author), Univ Penn, Dept Pathol & Lab Med, Philadelphia, PA 19104 USA.	yunyun.zhou@fccc.edu; wangk@chop.edu			NIH [LM012895, HG012655, HG013031]; Federal Work-Study Program; Penn DDDI fellowship program; CHOP Research Institute; IDDRC Biostatistics and Data Science core [HD105354]; CHOP Information Services	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Federal Work-Study Program; Penn DDDI fellowship program; CHOP Research Institute; IDDRC Biostatistics and Data Science core; CHOP Information Services	We thank Dr. Li Fang for providing insightful suggestions and guidance. This study is in part supported by the NIH (grant nos. LM012895, HG012655, and HG013031) , the Federal Work-Study Program, Penn DDDI fellowship program, and CHOP Research Institute. We give thanks for technical support from the IDDRC Biostatistics and Data Science core (HD105354) and CHOP Information Services for support on GPU computing.	Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Anazi S, 2017, HUM GENET, V136, P1419, DOI 10.1007/s00439-017-1843-2; [Anonymous], 2020, ADV NEUR IN; Arbabi A, 2019, JMIR MED INF, V7, P191, DOI 10.2196/12596; Aronson AR, 2001, J AM MED INFORM ASSN, P17; Birgmeier J, 2020, SCI TRANSL MED, V12, DOI 10.1126/scitranslmed.aau9113; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chambon PJ, 2023, J AM MED INFORM ASSN, V30, P318, DOI 10.1093/jamia/ocac219; Cho YJ, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3321-4; Clark JH, 2022, T ASSOC COMPUT LING, V10, P73, DOI 10.1162/tacl_a_00448; Deep Ganguli, 2022, P 2022 ACM C FAIRNES, P1747; Deisseroth CA, 2019, GENET MED, V21, P1585, DOI 10.1038/s41436-018-0381-1; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Dettmers T, 2022, Arxiv, DOI arXiv:2208.07339; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng YH, 2023, IEEE ACM T COMPUT BI, V20, P1269, DOI 10.1109/TCBB.2022.3170301; Fischer-Zirnsak B, 2019, AM J HUM GENET, V105, P631, DOI 10.1016/j.ajhg.2019.07.002; Groft SC, 2021, ACTA PAEDIATR, V110, P2711, DOI 10.1111/apa.15974; Groza Tudor, 2015, Database (Oxford), V2015, DOI 10.1093/database/bav005; Gupta P, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P933; hai W, 2023, Brief Bioinform., V24; Hartley T, 2020, ANNU REV GENOM HUM G, V21, P351, DOI 10.1146/annurev-genom-083118-015345; Havrilla JM, 2021, GENOME MED, V13, DOI 10.1186/s13073-021-00909-8; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu YF, 2020, PROCEEDINGS OF 2020 IEEE 19TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC 2020), P144, DOI 10.1109/ICCICC50026.2020.9450253; Huang J., 2022, arXiv; Jiang H, 2021, Reducing Human Labor Cost in Deep Learning for Natural Language Processing; Jiang HM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1775; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kelly C, 2022, TRENDS GENET, V38, P1271, DOI 10.1016/j.tig.2022.07.002; Kim D, 2019, IEEE ACCESS, V7, P73729, DOI 10.1109/ACCESS.2019.2920708; Köhler S, 2019, NUCLEIC ACIDS RES, V47, pD1018, DOI 10.1093/nar/gky1105; Köhler S, 2009, AM J HUM GENET, V85, P457, DOI 10.1016/j.ajhg.2009.09.003; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lafferty J., 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.5555/645530.655813; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lehman E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P946; Lison P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1518; Liu C, 2019, NUCLEIC ACIDS RES, V47, pW566, DOI 10.1093/nar/gkz386; Luo L, 2021, BIOINFORMATICS, V37, P1884, DOI 10.1093/bioinformatics/btab019; Maia N, 2022, AM J HUM GENET, V109, P345, DOI 10.1016/j.ajhg.2021.12.010; Martínez-Romero M, 2017, J BIOMED SEMANT, V8, DOI 10.1186/s13326-017-0128-y; Marwaha S, 2022, GENOME MED, V14, DOI 10.1186/s13073-022-01026-w; Organization WorldHealth., 1993, The ICD-10 Classification of Mental and Behavioural Disorders; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Peng CY, 2021, NAR GENOM BIOINFORM, V3, DOI 10.1093/nargab/lqab078; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Robinson PN, 2020, AM J HUM GENET, V107, P403, DOI 10.1016/j.ajhg.2020.06.021; Robinson PN, 2014, GENOME RES, V24, P340, DOI 10.1101/gr.160325.113; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Smedley D, 2015, GENOME MED, V7, DOI 10.1186/s13073-015-0199-2; Son JH, 2018, AM J HUM GENET, V103, P58, DOI 10.1016/j.ajhg.2018.05.010; Soysal E, 2018, J AM MED INFORM ASSN, V25, P331, DOI 10.1093/jamia/ocx132; Sung M, 2022, BIOINFORMATICS, V38, P4837, DOI 10.1093/bioinformatics/btac598; Taboada M, 2014, DATABASE-OXFORD, DOI 10.1093/database/bau045; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Weber L, 2022, DATABASE-OXFORD, V2022, DOI 10.1093/database/baac098; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yan SK, 2022, J BIOMED INFORM, V129, DOI 10.1016/j.jbi.2022.104059; Yang H, 2015, NAT METHODS, V12, P841, DOI [10.1038/NMETH.3484, 10.1038/nmeth.3484]; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yap ZY, 2021, AM J HUM GENET, V108, P2368, DOI 10.1016/j.ajhg.2021.11.003; Yoon W., 2021, P BIOCREATIVE 7 CHAL, P31; Zanello G, 2022, ORPHANET J RARE DIS, V17, DOI 10.1186/s13023-022-02337-2; Zhao MG, 2020, NAR GENOM BIOINFORM, V2, DOI 10.1093/nargab/lqaa032; Zhao MG, 2022, J NEURODEV DISORD, V14, DOI 10.1186/s11689-022-09442-0	72	5	6	9	9	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	2666-3899			PATTERNS	Patterns	JAN 12	2024	5	1							100887	10.1016/j.patter.2023.100887	http://dx.doi.org/10.1016/j.patter.2023.100887		JAN 2024	16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	IG8S9	38264716	Green Submitted, gold			2024-07-03	WOS:001165274200001
J	Wang, XC; Wang, SY				Wang, Xiaochen; Wang, Siyi			Exploring Chinese EFL learners' engagement with large language models: A self-determination theory perspective	LEARNING AND MOTIVATION			English	Article						EFL learners; Engagement; LLMs; SDT; Chinese context	STUDENTS; WILLINGNESS; EFFICACY; FEEDBACK; BELIEFS	Large language models (LLMs) greatly affect language learning, but research on Chinese EFL (English as a Foreign Language) learners' engagement is limited. In this sense, the present study draws upon Self-Determination Theory (SDT) and employs a mixed-methods approach to explore how 210 Chinese EFL Learners engage with LLMs. Findings showed that most of the basic psychological needs (BPNs) play a critical role in predicting behavioral, cognitive, and emotional engagement. However, perceived autonomy did not emerge as a predictor for behavioral engagement, and perceived competence was not found to be a predictor for either behavioral engagement or cognitive engagement. Furthermore, our qualitative interviews showed that the influence of BPNs on EFL learners' engagement with LLMs can be categorized into six thematic areas: self-directed learning empowerment, goal-oriented learning challenges, individual performance enhancement, limited knowledge advancement, collaborative learning access, and interpersonal connection gaps. The findings of this study could provide insights for foreign language teachers in their instructional design and for policymakers in formulating relevant policies.	[Wang, Xiaochen] Xi An Jiao Tong Univ, Sch Foreign Studies, Xian, Peoples R China; [Wang, Siyi] Nanjing Normal Univ, Sch Foreign Languages & Cultures, Nanjing, Peoples R China	Xi'an Jiaotong University; Nanjing Normal University	Wang, SY (corresponding author), Nanjing Normal Univ, Sch Foreign Languages & Cultures, Nanjing, Peoples R China.	wsynnu@163.com						Akbari E, 2015, COMPUT HUM BEHAV, V48, P126, DOI 10.1016/j.chb.2015.01.036; Alshurafat H, 2024, J FINANC REPORT ACCO, V22, P274, DOI 10.1108/JFRA-04-2023-0182; Baskara R., 2023, IJELTAL (Indonesian Journal of English Language Teaching and Applied Linguistics), V7; Bond M, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-019-0176-8; Chiu TKF, 2021, COMPUT HUM BEHAV, V124, DOI 10.1016/j.chb.2021.106909; Chiu TKF, 2022, J RES TECHNOL EDUC, V54, pS14, DOI 10.1080/15391523.2021.1891998; Collier J. E., 2020, Applied Structural Equation Modeling Using AMOS: Basic to Advanced Techniques; Dai K, 2024, SYSTEM, V123, DOI 10.1016/j.system.2024.103339; Davis WS, 2022, LANG LEARN J, V50, P29, DOI 10.1080/09571736.2020.1740768; Deng RQ, 2020, BRIT J EDUC TECHNOL, V51, P245, DOI 10.1111/bjet.12810; Ding L, 2023, ASIA-PAC EDUC RES, DOI 10.1007/s40299-023-00758-6; Gao Y, 2024, ASIA PAC J EDUC, V44, P29, DOI 10.1080/02188791.2024.2305173; Gao Y, 2024, CURR PSYCHOL, V43, P9089, DOI 10.1007/s12144-023-05062-6; Gao Y, 2022, J LANG EDUC, V8, P58, DOI 10.17323/jle.2022.15962; Guo K, 2024, EDUC INF TECHNOL, V29, P8435, DOI 10.1007/s10639-023-12146-0; Guo KY, 2024, EXPERT OPIN DRUG SAF, V23, P487, DOI [10.1007/s10639-023-12230-5, 10.1080/14740338.2024.2327502]; Guo YX, 2023, PORTA LINGUARUM, P253, DOI 10.30827/portalin.vi40.27061; Hafez SA, 2019, FOLIA LINGUIST LITT, P143, DOI 10.31902/fll.29.2019.11; Hao T, 2021, J RES EDUC EFF, V14, P645, DOI 10.1080/19345747.2021.1917028; He LM, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1185851; Hsu HCK, 2019, EDUC INF TECHNOL, V24, P2159, DOI 10.1007/s10639-019-09863-w; Hu L, 2023, BMC PSYCHOL, V11, DOI 10.1186/s40359-023-01378-x; Jeon J, 2023, COMPUT EDUC, V206, DOI 10.1016/j.compedu.2023.104898; Jeon J, 2022, EDUC INF TECHNOL, V27, P5767, DOI 10.1007/s10639-021-10839-y; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim Sunyoung, 2023, Journal of Multimedia Information System, V10, P79; Kline RB., 2023, Principles and Practice of Structural EquationModeling; Kuh G.D., 2007, ASHE Higher Education Report, V32, DOI [10.1002/aehe.3205, DOI 10.1002/AEHE.3205]; Lin J, 2024, ACTA PSYCHOL, V245, DOI 10.1016/j.actpsy.2024.104233; Liu GX, 2024, INNOV LANG LEARN TEA, V18, P125, DOI 10.1080/17501229.2023.2240316; Marks HM, 2000, AM EDUC RES J, V37, P153, DOI 10.3102/00028312037001153; Moqbel M. S. S., 2023, Journal of English Studies in Arabia Felix, V2, P71, DOI [10.56540/jesaf.v2i1.62, DOI 10.56540/JESAF.V2I1.62]; Newmann F., 1992, STUDENT ENGAGEMENT A; Pace C.R., 1984, MEASURING QUALITY CO; Pan ZW, 2023, J PSYCHOLINGUIST RES, V52, P1799, DOI 10.1007/s10936-023-09974-z; Pekrun R, 2012, HANDBOOK OF RESEARCH ON STUDENT ENGAGEMENT, P259, DOI 10.1007/978-1-4614-2018-7_12; Reeve J, 2013, J EDUC PSYCHOL, V105, P579, DOI 10.1037/a0032690; Reeve J, 2011, CONTEMP EDUC PSYCHOL, V36, P257, DOI 10.1016/j.cedpsych.2011.05.002; Reschly A. L., 2022, Handbook of research on student engagement, P3, DOI [10.1007/978-3-031-07853-8_1, DOI 10.1007/978-3-031-07853-8_1]; Reynolds BL, 2021, STUD SECOND LANG LE, V11, P423, DOI 10.14746/ssllt.2021.11.3.6; Reynolds BL, 2021, COMPUT ASSIST LANG L, V34, P462, DOI 10.1080/09588221.2019.1617747; Rodrigues OS, 2023, TEXTO LIVRE, V16, DOI 10.1590/1983-3652.2023.45997; Ryan RM, 2020, CONTEMP EDUC PSYCHOL, V61, DOI 10.1016/j.cedpsych.2020.101860; Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8; Ryan RM, 2000, CONTEMP EDUC PSYCHOL, V25, P54, DOI 10.1006/ceps.1999.1020; Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806; Shaikh S, 2023, EUR J INVEST HEALTH, V13, P1937, DOI 10.3390/ejihpe13090140; Tyler R., 1969, ED EVALUATION NEW RO; Wang MM, 2024, LEARN MOTIV, V86, DOI 10.1016/j.lmot.2024.101981; Wang N, 2021, COMPUT ASSIST LANG L, V34, P297, DOI 10.1080/09588221.2019.1607881; Wang QK, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151310184; Wang XC, 2024, EDUC SCI, V14, DOI 10.3390/educsci14050496; Wang XC, 2024, CURR PSYCHOL, V43, P15659, DOI 10.1007/s12144-023-05546-5; Wang XC, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.1010889; Wang YL, 2024, STUD SECOND LANG LE, V14, P235, DOI 10.14746/ssllt.38418; Wang YL, 2023, ASIA-PAC EDUC RES, DOI 10.1007/s40299-023-00750-0; Wang YL, 2023, PORTA LINGUARUM, P165, DOI 10.30827/portalin.vi39.23625; Wang YL, 2017, EURASIA J MATH SCI T, V13, P6875, DOI 10.12973/ejmste/78525; Wheaton B., 1977, SOCIOL METHODOL, V8, P84, DOI [https://doi.org/10.2307/270754, DOI 10.2307/270754, 10.2307/270754]; Wu HW, 2024, PORTA LINGUARUM, P193, DOI 10.30827/portalin.viIX.29878; Wu HW, 2024, ACTA PSYCHOL, V243, DOI 10.1016/j.actpsy.2024.104153; Yu MH, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211009163; Yüce E, 2023, PORTA LINGUARUM, P231, DOI 10.30827/portalin.vi39.24106; Zhi R, 2023, ASIA-PAC EDUC RES, DOI 10.1007/s40299-023-00782-6	64	0	0	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	0023-9690	1095-9122		LEARN MOTIV	Learn. Motiv.	AUG	2024	87								102014	10.1016/j.lmot.2024.102014	http://dx.doi.org/10.1016/j.lmot.2024.102014			10	Psychology, Biological; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	WM9S8					2024-07-03	WOS:001255414900001
C	Panagoulias, DP; Palamidas, FA; Virvou, M; Tsihrintzis, GA			IEEE	Panagoulias, Dimitrios P.; Palamidas, Filippos A.; Virvou, Maria; Tsihrintzis, George A.			Rule-Augmented Artificial Intelligence-empowered Systems for Medical Diagnosis using Large Language Models	2023 IEEE 35TH INTERNATIONAL CONFERENCE ON TOOLS WITH ARTIFICIAL INTELLIGENCE, ICTAI	Proceedings-International Conference on Tools With Artificial Intelligence		English	Proceedings Paper	35th IEEE International Conference on Tools with Artificial Intelligence (ICTAI)	NOV 06-08, 2023	Atlanta, GA	IEEE, IEEE Comp Soc, Biol & Artificial Intelligence Fdn		AI-empowered software engineering; explainability; ChatGPT; LLM; NLP; prompt-engineering		In this paper, we investigate the enhancement of Artificial Intelligence (AI) technologies in healthcare and the better understanding of medical literature with the use of Large Language Models (LLMs) and Natural Language Processing (NLP). Specifically, we introduce a rule-augmented AI-empowered system which incorporates a rule-based decision system, the ChatGPT application programming interface (API), and other external machine learning and analytical APIs to offer diagnostic suggestions to patients. The complexities of patient healthcare experiences, including doctor-patient interactions, understanding levels, treatment procedures, and preventive care, are considered. We illustrate how a diagnostic process typically integrates various strategies depending on various factors. To digitize the greatest portion of the process, we propose and illustrate the use of LLMs for humanizing the communication process and investigating ways to reduce burdens and costs in primary healthcare. We also outline a theoretical decision model for evaluating the use of technological components from external sources versus building them from scratch. The paper is structured into sections detailing background theories and context, our proposed and implemented rule-augmented AI-empowered system, as well as a system test in a corresponding use case. Finally, the paper key findings are presented, which contribute valuable insights for future work in this field.	[Panagoulias, Dimitrios P.; Virvou, Maria; Tsihrintzis, George A.] Univ Piraeus, Dept Informat, Piraeus 18534, Greece; [Palamidas, Filippos A.] Aristotle Univ Thessaloniki, Dept Med, Thessaloniki 54124, Greece	University of Piraeus; Aristotle University of Thessaloniki	Panagoulias, DP (corresponding author), Univ Piraeus, Dept Informat, Piraeus 18534, Greece.	panagoulias_d@unipi.gr; fpalamidas@gmail.com; mvirvou@unipi.gr; geoatsi@unipi.gr	VIRVOU, Maria/AAR-1415-2021	VIRVOU, MARIA/0000-0002-4008-4654; Panagoulias, Dimitris/0000-0002-9421-141X	University of Piraeus Research Center	University of Piraeus Research Center	This work has been partly supported by the University of Piraeus Research Center.	[Anonymous], 2022, 2022 13 INT C INF IN, P1; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Balogh EP, 2015, IMPROVING DIAGNOSIS IN HEALTH CARE, P1, DOI 10.17226/21794; Bolukbasi T, 2016, ADV NEUR IN, V29; Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105; Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gunning D., 2017, Defense advanced research projects agency (DARPA), nd Web, V2, P1, DOI DOI 10.1126/SCIROBOTICS.AAY7120; Hillson D., 2007, PRACTICAL PROJECT RI; Holzinger A, 2022, LECT NOTES ARTIF INT, V13200, P3, DOI 10.1007/978-3-031-04083-2_1; Kerzner H., 2017, Project Management: A Systems Approach to Planning, Scheduling, and Controlling; Kreimeyer K, 2017, J BIOMED INFORM, V73, P14, DOI 10.1016/j.jbi.2017.07.012; meta, Introducing llama 2; OpenAI, 2019, Better Language Models and Their Implications; openai, Gpt-4 is openai's most advanced system; Panagoulias D., 2023, 14 IEEE INT C INF IN; Panagoulias Dimitrios P., 2021, 2021 12th International Conference on Information, Intelligence, Systems & Applications (IISA), DOI 10.1109/IISA52424.2021.9555512; Panagoulias D.P., 2023, Electronics, V12; Panagoulias D. P., 2023, KNOWLEDGE BASED SOFT, V133; Panagoulias DP, 2022, 2022 16TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY & INTERNET-BASED SYSTEMS, SITIS, P386, DOI 10.1109/SITIS57111.2022.00065; Panagoulias DP, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060857; Panagoulias DP, 2021, PROC INT C TOOLS ART, P306, DOI 10.1109/ICTAI52525.2021.00051; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rogers EM, 2004, J HEALTH COMMUN, V9, P13, DOI 10.1080/10810730490271449; Russell SJ., 2016, ARTIF INTELL; stanford, Alpaca: A strong, replicable instruction -following model; Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004; Tsihrintzis George A., 2022, Advances in Assistive Technologies: Selected Papers in Honour of Professor Nikolaos G. Bourbakis, P73; Vaswani A, 2017, ADV NEUR IN, V30; Wang B, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.12; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; wikipedia, Bert (language model)	33	0	0	8	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1082-3409		979-8-3503-4273-4	PROC INT C TOOLS ART			2023							70	77		10.1109/ICTAI59109.2023.00018	http://dx.doi.org/10.1109/ICTAI59109.2023.00018			8	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3KO					2024-07-03	WOS:001139095400010
J	Wilson, M; Petty, J; Frank, R				Wilson, Michael; Petty, Jackson; Frank, Robert			How Abstract Is Linguistic Generalization in Large Language Models? Experiments with Argument Structure	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								Language models are typically evaluated on their success at predicting the distribution of specific words in specific contexts. Yet linguistic knowledge also encodes relationships between contexts, allowing inferences between word distributions. We investigate the degree to which pre-trained transformer-based large language models (LLMs) represent such relationships, focusing on the domain of argument structure. We find that LLMs perform well in generalizing the distribution of a novel noun argument between related contexts that were seen during pre-training (e.g., the active object and passive subject of the verb spray), succeeding by making use of the semantically organized structure of the embedding space for word embeddings. However, LLMs fail at generalizations between related contexts that have not been observed during pre-training, but which instantiate more abstract, but well-attested structural generalizations (e.g., between the active object and passive subject of an arbitrary verb). Instead, in this case, LLMs show a bias to generalize based on linear order. This finding points to a limitation with current models and points to a reason for which their training is data-intensive.1	[Wilson, Michael; Frank, Robert] Yale Univ, New Haven, CT 06520 USA; [Petty, Jackson] NYU, New York, NY USA	Yale University; New York University	Wilson, M (corresponding author), Yale Univ, New Haven, CT 06520 USA.	michael.a.wilson@yale.edu; petty@nyu.edu; bob.frank@yale.edu			National Science Foundation [BCS-1919321]	National Science Foundation(National Science Foundation (NSF))	For helpful comments, critiques and suggestions, we would like to thank Tal Linzen, Alec Marantz, the members of the Computational Linguistics at Yale (CLAY) lab and the Computation and Psycholinguistics lab at NYU, and the audiences at the Jabberwocky Words in Linguistics workshop and at the University of Toronto, Northwestern University, Stony Brook University, UCLA, and Heinrich Heine University Dusseldorf. The comments and suggestions of the anonymous TACL reviewers were also invaluable. This work was made possible by support from National Science Foundation grant BCS-1919321.	Bowman Samuel R., 2019, INT C LEARN REPR, P1; Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977; Cai Xingyu., 2021, P 9 INT C LEARN REPR; Chowdhury SA, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P204; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2; Gleitman Lelia, 1990, Lang. Acquis, V1, P3, DOI DOI 10.1207/S15327817LA01012; Gleitman LR, 2005, LANG LEARN DEV, V1, P23, DOI 10.1207/s15473341lld0101_4; Goldberg Y, 2019, CoRR abs/1901.05287; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Hawkins Robert, 2020, Proceedings_of_the_Conference_on Computational_Natural_Language_Learning, P408, DOI [10.18653/v1/2020.conll-1.33, 10.18653/v1]; Hawkins RD, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4653; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Kann Katharina, 2019, P SOC COMPUTATION LI, P287, DOI [DOI 10.7275/Q5JS-4Y86, 10.7275/q5js-4y86]; Kim N., 2021, P SOC COMP LING 2021, P467; Lasri K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2309; Lhoest Q, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P175; Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241; Linzen Tal, 2016, Transactions of the Association for Computational Linguistics, V1990, P521, DOI [10.1162/tacl_a_00115, DOI 10.1162/TACL_A_00115]; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Loaiciga Sharid., 2021, CoRR; Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]; Metheniti Eleni., 2020, P COLING, P1266, DOI 10.18653/v1/2020.coling-main.109; Mosbach Marius, 2021, P 9 INT C LEARN REPR; Mueller A, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1352; Newman B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3710; Pavlick E, 2022, ANNU REV LINGUIST, V8, P447, DOI 10.1146/annurev-linguistics-031120-122924; Petty Jackson., 2021, CoRR; Petty Jackson., 2022, Proceedings of the 46th Annual Boston University Conference on Language Development, V2, P657; Pinker Steven., 1989, Learnability and Cognition: The Acquisition of Argument Structure , 2013 new edition, volume 27 of Learning, Development, and Conceptual Change, V27; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sasano R, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3657; Sellam Thibault., 2022, P 10 INT C LEARN REP; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Thrush Tristan., 2020, P 3 BLACKBOXNLP WORK, P265, DOI [10.18653/v1/2020.blackboxnlp-1.25, DOI 10.18653/V1/2020.BLACKBOXNLP-1.25]; Timkey William., 2021, P 2021 C EMPIRICAL M, P4527, DOI [10.18653/v1/2021.emnlp-main.372, DOI 10.18653/V1/2021]; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Warstadt Alex., 2020, CoRR; Wilcox E., 2018, P 2018 EMNLP WORKSHO, P211; Wolf Thomas., 2020, CoRR; Yoshida Ryo., 2022, P SOC COMPUTATION LI, V5, P101; Zhu Xunjie, 2020, P 28 INT C COMP LING, P3389, DOI [10.18653/v1/2020.coling-main.300, DOI 10.18653/V1/2020.COLING-MAIN.300]	45	1	1	11	13	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	NOV 13	2023	11						1377	1395		10.1162/tacl_a_00608	http://dx.doi.org/10.1162/tacl_a_00608			19	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	Y4EO6		Green Submitted, gold			2024-07-03	WOS:001104813600003
J	Hosseini, M; Hosseini, M; Javidan, R				Hosseini, Manda; Hosseini, Mandana; Javidan, Reza			Leveraging Large Language Models for Clinical Abbreviation Disambiguation	JOURNAL OF MEDICAL SYSTEMS			English	Article						Clinical Abbreviation Disambiguation; Large Language Models; Generative Model; Health Informatics; Electronic Health Record		Clinical abbreviation disambiguation is a crucial task in the biomedical domain, as the accurate identification of the intended meanings or expansions of abbreviations in clinical texts is vital for medical information retrieval and analysis. Existing approaches have shown promising results, but challenges such as limited instances and ambiguous interpretations persist. In this paper, we propose an approach to address these challenges and enhance the performance of clinical abbreviation disambiguation. Our objective is to leverage the power of Large Language Models (LLMs) and employ a Generative Model (GM) to augment the dataset with contextually relevant instances, enabling more accurate disambiguation across diverse clinical contexts. We integrate the contextual understanding of LLMs, represented by BlueBERT and Transformers, with data augmentation using a Generative Model, called Biomedical Generative Pre-trained Transformer (BIOGPT), that is pretrained on an extensive corpus of biomedical literature to capture the intricacies of medical terminology and context. By providing the BIOGPT with relevant medical terms and sense information, we generate diverse instances of clinical text that accurately represent the intended meanings of abbreviations. We evaluate our approach on the widely recognized CASI dataset, carefully partitioned into training, validation, and test sets. The incorporation of data augmentation with the GM improves the model's performance, particularly for senses with limited instances, effectively addressing dataset imbalance and challenges posed by similar concepts. The results demonstrate the efficacy of our proposed method, showcasing the significance of LLMs and generative techniques in clinical abbreviation disambiguation. Our model achieves a good accuracy on the test set, outperforming previous methods.	[Hosseini, Manda] Zand Inst Higher Educ, Dept Comp Engn, Shiraz, Iran; [Hosseini, Mandana; Javidan, Reza] Shiraz Univ Technol, Dept Comp Engn & IT, Shiraz, Iran	Shiraz University of Technology	Hosseini, M (corresponding author), Zand Inst Higher Educ, Dept Comp Engn, Shiraz, Iran.	manda.hosseinii@gmail.com; mandana.hosseini@gmail.com; javidan@sutech.ac.ir	Javidan, Reza/L-2861-2019	Javidan, Reza/0000-0002-7788-6597; Hosseini, Manda/0009-0000-4902-3738				Adams Griffin, 2020, Proc Mach Learn Res, V136, P12; Agrawal M., 2022, P 2022 C EMP METH NA; Amosa TI, 2023, IEEE ACCESS, V11, P59297, DOI 10.1109/ACCESS.2023.3284682; [Anonymous], 2006, Shared Learning-Reported Incidents Involving Hydromorphone; Brunetti L, 2007, JT COMM J QUAL PATIE, V33, P576, DOI 10.1016/S1553-7250(07)33062-6; Cevik M, 2023, J HEALTHC INFORM RES, V7, P501, DOI 10.1007/s41666-023-00146-1; Chawla NV, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P853, DOI 10.1007/0-387-25465-X_40; Coghlan A, 2023, INTERN MED J, V53, P550, DOI 10.1111/imj.15582; Collard B, 2015, ANN MED SURG, V4, P100, DOI 10.1016/j.amsu.2015.03.008; DesRoches CM, 2020, SEMIN DIALYSIS, V33, P533, DOI 10.1111/sdi.12934; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Duganova B., 2019, JAHR; Finley Gregory P, 2016, AMIA Annu Symp Proc, V2016, P560; García V, 2010, LECT NOTES ARTIF INT, V6096, P541, DOI 10.1007/978-3-642-13022-9_54; Hao SL, 2023, NEURAL COMPUT APPL, V35, P24621, DOI 10.1007/s00521-023-08226-4; Huang C, 2016, PROC CVPR IEEE, P5375, DOI 10.1109/CVPR.2016.580; Jaber A, 2022, METHOD INFORM MED, V61, pE28, DOI 10.1055/s-0042-1742388; Jaber A, 2021, HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF, P501, DOI 10.5220/0010256105010508; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Joopudi V, 2018, J BIOMED INFORM, V86, P71, DOI 10.1016/j.jbi.2018.07.025; Joshi Mahesh, 2006, AMIA Annu Symp Proc, P399; Kacker P, 2022, Arxiv, DOI arXiv:2207.04008; Kashyap A, 2020, INT J MED INFORM, V137, DOI 10.1016/j.ijmedinf.2020.104101; Kaur J., 2018, A Systematic Review on Stopword Removal Algorithms, V4, P207; Khushi M, 2021, IEEE ACCESS, V9, P109960, DOI 10.1109/ACCESS.2021.3102399; Kim J., 2020, Improved Clinical Abbreviation Expansion via Non-Sense-Based Approaches; Kuhn Ivy Fenton, 2007, Pediatr Nurs, V33, P392; Kula S, 2022, NEURAL COMPUT APPL, V34, P20449, DOI 10.1007/s00521-021-06276-0; Kumar V, 2021, IEEE ACCESS, V9, P7107, DOI 10.1109/ACCESS.2020.3043221; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li I., 2019, arXiv; Link NB, 2022, INT J MED INFORM, V162, DOI 10.1016/j.ijmedinf.2022.104753; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Moon S., 2012, Clinical abbreviation sense inventory; Moon S, 2014, J AM MED INFORM ASSN, V21, P299, DOI 10.1136/amiajnl-2012-001506; Moon Sungrim, 2012, AMIA Annu Symp Proc, V2012, P1310; Navigli Roberto., 2011, P 20 ACM INT C INF K, P2317, DOI DOI 10.1145/2063576.2063955; Pakhomov Sergeui, 2005, AMIA Annu Symp Proc, P589; Peng Y., 2019, SIGBIOMED WORKSHOP B, V5865; Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58; Rajkomar A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35007-9; Schwartz Ariel S, 2003, Pac Symp Biocomput, P451; Seneviratne S., 2022, m-Networks: Adapting the Triplet Networks for Acronym Disambiguation; Skreta M, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25578-4; Socher R., Deep Learning for NLP (without Magic); Toole J., 2000, A Hybrid Approach to the Identification and Expansion of Abbreviations; Vaswani A, 2017, ADV NEUR IN, V30; Wagh Atharwa, 2023, Multi-disciplinary Trends in Artificial Intelligence: 16th International Conference, MIWAI 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14078), P214, DOI 10.1007/978-3-031-36402-0_19; Walsh KE, 2008, ARCH DIS CHILD, V93, P816, DOI 10.1136/adc.2008.141473; Wu Y., 2015, Clinical Abbreviation Disambiguation Using Neural Word Embeddings, DOI [10.18653/v1/W15-3822, DOI 10.18653/V1/W15-3822]; Wu YH, 2017, J AM MED INFORM ASSN, V24, pE79, DOI 10.1093/jamia/ocw109; Xu Hua, 2007, AMIA Annu Symp Proc, P821; Zhang CX, 2022, IEEE ACCESS, V10, P123328, DOI 10.1109/ACCESS.2022.3224802	53	0	0	7	7	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0148-5598	1573-689X		J MED SYST	J. Med. Syst.	FEB 27	2024	48	1							27	10.1007/s10916-024-02049-z	http://dx.doi.org/10.1007/s10916-024-02049-z			16	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	JC9A5	38411689				2024-07-03	WOS:001171063400002
J	Yang, JF; Jin, HY; Tang, RX; Han, XT; Feng, QZ; Jiang, HM; Zhong, SC; Yin, B; Hu, X				Yang, Jingfeng; Jin, Hongye; Tang, Ruixiang; Han, Xiaotian; Feng, Qizhang; Jiang, Haoming; Zhong, Shaochen; Yin, Bing; Hu, Xia			Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond	ACM TRANSACTIONS ON KNOWLEDGE DISCOVERY FROM DATA			English	Article						Large language models; neural language processing; practical guide; ChatGPT	LANGUAGE	This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pretraining data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at https://github.com/Mooler0410/LLMsPracticalGuide. An LLMs evolutionary tree, editable yet regularly updated, can be found at llmtree.ai.	[Yang, Jingfeng; Jiang, Haoming; Yin, Bing] Amazon, Seattle, WA 98109 USA; [Jin, Hongye; Han, Xiaotian; Feng, Qizhang] Texas A&M Univ, College Stn, TX USA; [Tang, Ruixiang; Zhong, Shaochen; Hu, Xia] Rice Univ, Houston, TX USA; [Yang, Jingfeng] 130 Descanso DR, San Jose, CA USA; [Jin, Hongye] 4150 Pendleton Dr, Bryan, TX 77802 USA; [Tang, Ruixiang] 2201 Crescent Pointe Pkwy, College Stn, TX 77845 USA; [Han, Xiaotian] 1001 Krenek Tap Rd, College Stn, TX 77840 USA; [Feng, Qizhang] 430 Southwest Pkwy 1008, College Stn, TX 77840 USA; [Jiang, Haoming] 101 Lytton Ave, Palo Alto, CA 94301 USA; [Yin, Bing] 101 Lytton Ave, Palo Alto, CA 94301 USA; [Hu, Xia] 4321 Jim West St, Bellaire, TX 77401 USA	Amazon.com; Texas A&M University System; Texas A&M University College Station; Rice University	Yang, JF (corresponding author), Amazon, Seattle, WA 98109 USA.; Yang, JF (corresponding author), 130 Descanso DR, San Jose, CA USA.	jingfengyangpku@gmail.com; jhy0410@tamu.edu; rt39@rice.edu; han@tamu.edu; qf31@tamu.edu; jhaoming@amazon.com; hz88@rice.edu; alexbyin@amazon.com; xia.hu@rice.edu		Tang, Ruixiang/0000-0001-6476-2336; Jiang, Haoming/0000-0003-0789-525X	NSF [IIS-2224843, IIS-1900990]	NSF(National Science Foundation (NSF))	This work is supported in part by NSF Grants No. IIS-2224843 and No. IIS-1900990.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ainslie J, 2023, Arxiv, DOI arXiv:2303.09752; Alajrami A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P131; Ananthaswamy A, 2023, NATURE, V615, P202, DOI 10.1038/d41586-023-00641-w; Ankit Pal, 2022, Promptify: Structured Output from LLMs; [Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2011, P 49 ANN M ASS COMPU; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bao HB, 2020, PR MACH LEARN RES, V119; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Beukeboom CJ, 2019, REV COMMUN RES, V7, P1, DOI 10.12840/issn.2255-4165.017; Bojar O, 2016, P 1 C MACH TRANSL, V2, P131; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Borkan D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P491, DOI 10.1145/3308560.3317593; Bowman SR, 2022, Arxiv, DOI arXiv:2211.03540; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen GZ, 2024, Arxiv, DOI arXiv:2310.16450; Chen M., 2021, arXiv; Chen X, 2022, Arxiv, DOI arXiv:2209.06794; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chu Z, 2023, Arxiv, DOI arXiv:2309.15402; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding BS, 2023, Arxiv, DOI arXiv:2212.10450; Dodge Jesse, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1877, DOI 10.1145/3531146.3533234; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Du MN, 2023, Arxiv, DOI arXiv:2208.11857; Duchêne C, 2023, Arxiv, DOI arXiv:2301.11125; Fu JL, 2023, Arxiv, DOI arXiv:2302.04166; Ge Yingqiang, 2023, P C ADV NEUR INF PRO; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Gunasekar S, 2023, Arxiv, DOI arXiv:2306.11644; Guo MY, 2022, Arxiv, DOI arXiv:2112.07916; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Han XC, 2023, Arxiv, DOI arXiv:2306.15091; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hua Hang, 2022, Fine-tuning Pre-trained Language Models with Noise Stability Regularization; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Izacard G, 2022, Arxiv, DOI arXiv:2208.03299; JasonWei Yi, 2022, Trans. Mach. Learn. Res.; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jin HY, 2023, Arxiv, DOI arXiv:2310.00576; Jin HY, 2024, Arxiv, DOI arXiv:2401.01325; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kedia A, 2022, Arxiv, DOI arXiv:2211.10147; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Kocmi T, 2023, Arxiv, DOI arXiv:2302.14520; Kong LK, 2020, Arxiv, DOI arXiv:2010.11506; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lai YX, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P989; Lambda Labs, OpenAI's GPT-3 Language Model: A Technical Overview.; Lee HY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P666; Lei Y., 2022, P 2022 C EMPIRICAL M, P10040; Lei Yuanyuan, 2022, P ASS COMP LING EMNL, P5581; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Ling W, 2017, Arxiv, DOI arXiv:1705.04146; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Liu Y, 2023, Arxiv, DOI arXiv:2303.16634; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Yixin, 2022, arXiv, DOI 10.48550/arXiv.2203.16804; Longpre S, 2023, Arxiv, DOI arXiv:2301.13688; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Lu Yao, 2021, arXiv; Ma Xuezhe, 2021, Advances in Neural Information Processing Systems, V34, P2441; McKenzie Ian, 2023, Inverse Scaling Prize: Second Round Winners; Yoo KM, 2021, Arxiv, DOI arXiv:2104.08826; Nallapati R, 2016, Arxiv, DOI [arXiv:1602.06023, DOI 10.48550/ARXIV.1602.06023]; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Nguyen Tri, 2016, choice, V2640, P660; Nie YX, 2020, Arxiv, DOI arXiv:1910.14599; nytimes, New York Times; OpenAI, GPT-4 system card.; OpenAI, Pricing; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Patel Arkil, 2021, PREPRINT; Peng BW, 2023, Arxiv, DOI arXiv:2309.00071; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Qiu SL, 2022, NEUROCOMPUTING, V492, P278, DOI 10.1016/j.neucom.2022.04.020; Bowman SR, 2015, Arxiv, DOI arXiv:1508.05326; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P, 2018, Arxiv, DOI arXiv:1806.03822; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Ruder S, 2019, P C N AM CHAPT ASS C, P15, DOI [10.18653/v1/N19-5004, DOI 10.18653/V1/N19-5004]; Sang EF, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195; Sanh V, 2022, arXiv; Shen LF, 2024, Arxiv, DOI arXiv:2310.08540; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Srivastava Aarohi, 2022, arXiv; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Tang RX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P633, DOI 10.1145/3442381.3449950; Tang Ruixiang, 2023, FINDINGS ASS COMPUTA, P4645, DOI DOI 10.18653/V1/2023.FINDINGS-ACL.284; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tay Y, 2021, PR MACH LEARN RES, V139, P7192; Tchango AF, 2022, Arxiv, DOI arXiv:2205.09148; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Uesato Jonathan, 2022, arXiv, DOI DOI 10.48550/ARXIV.2211; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wang A, 2019, ADV NEUR IN, V32; Wang JA, 2023, Arxiv, DOI arXiv:2303.04048; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wang T., 2022, INT C MACHINE LEARNI, P22964; Wang WH, 2022, Arxiv, DOI arXiv:2208.10442; Webson A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2300; Wei JS, 2023, Arxiv, DOI arXiv:2211.02011; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wortsman M, 2022, PROC CVPR IEEE, P7949, DOI 10.1109/CVPR52688.2022.00780; Yang Jian, 2021, P 6 C MACHINE TRANSL, P446; Yang Jingfeng, 2022, arXiv; Yang Jingfeng, 2022, arXiv; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Yuan JY, 2023, Arxiv, DOI [arXiv:2303.16756, 10.48550/arXiv.2303.16756]; Zha D., 2023, arXiv; Zhang J., 2020, PMLR, P11328; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T., 2023, arXiv; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]; Zhou KY, 2023, IEEE T PATTERN ANAL, V45, P4396, DOI 10.1109/TPAMI.2022.3195549	143	5	5	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	1556-4681	1556-472X		ACM T KNOWL DISCOV D	ACM Trans. Knowl. Discov. Data	JUL	2024	18	6							160	10.1145/3649506	http://dx.doi.org/10.1145/3649506			32	Computer Science, Information Systems; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OU9C2		hybrid, Green Submitted			2024-07-03	WOS:001209901400027
J	Hadid, A; Chakraborty, T; Busby, D				Hadid, Abdenour; Chakraborty, Tanujit; Busby, Daniel			When geoscience meets generative AI and large language models: Foundations, trends, and future challenges	EXPERT SYSTEMS			English	Article; Early Access						artificial intelligence; deep learning; diffusion models; generative adversarial networks; generative AI; geoscience; large language models; physics-informed neural networks		Generative Artificial Intelligence (GAI) represents an emerging field that promises the creation of synthetic data and outputs in different modalities. GAI has recently shown impressive results across a large spectrum of applications ranging from biology, medicine, education, legislation, computer science, and finance. As one strives for enhanced safety, efficiency, and sustainability, generative AI indeed emerges as a key differentiator and promises a paradigm shift in the field. This article explores the potential applications of generative AI and large language models in geoscience. The recent developments in the field of machine learning and deep learning have enabled the generative model's utility for tackling diverse prediction problems, simulation, and multi-criteria decision-making challenges related to geoscience and Earth system dynamics. This survey discusses several GAI models that have been used in geoscience comprising generative adversarial networks (GANs), physics-informed neural networks (PINNs), and generative pre-trained transformer (GPT)-based structures. These tools have helped the geoscience community in several applications, including (but not limited to) data generation/augmentation, super-resolution, panchromatic sharpening, haze removal, restoration, and land surface changing. Some challenges still remain, such as ensuring physical interpretation, nefarious use cases, and trustworthiness. Beyond that, GAI models show promises to the geoscience community, especially with the support to climate change, urban science, atmospheric science, marine science, and planetary science through their extraordinary ability to data-driven modelling and uncertainty quantification.	[Hadid, Abdenour] Sorbonne Univ Abu Dhabi, Sorbonne Ctr Artificial Intelligence, Abu Dhabi, U Arab Emirates; [Chakraborty, Tanujit] Sorbonne Univ Abu Dhabi, Dept Sci & Engn, Abu Dhabi, U Arab Emirates; [Busby, Daniel] TotalEnergies PAU, Pau, France		Hadid, A (corresponding author), Sorbonne Univ Abu Dhabi, Sorbonne Ctr Artificial Intelligence, Abu Dhabi, U Arab Emirates.	abdenour.hadid@sorbonne.ae			TotalEnergies collaboration agreement with Sorbonne University Abu Dhabi	TotalEnergies collaboration agreement with Sorbonne University Abu Dhabi	The support of TotalEnergies is fully acknowledged. Abdenour Hadid (Professor, Industry Chair at SCAI Center of Abu Dhabi) is funded by TotalEnergies collaboration agreement with Sorbonne University Abu Dhabi. The authors also acknowledge open-source generative AI tools that have been used for the generations of images used in this paper. T. C. acknowledges Madhurima Panja of IIIT Bangalore, India for valuable insights and suggestions.	Albert A, 2018, INT GEOSCI REMOTE SE, P2095, DOI 10.1109/IGARSS.2018.8518032; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Arjovsky M, 2017, PR MACH LEARN RES, V70; Artificial G., 2023, Handbook of geospatial artificial intelligence; Bergen KJ, 2019, SCIENCE, V363, P1299, DOI 10.1126/science.aau0323; bin Waheed U, 2021, COMPUT GEOSCI-UK, V155, DOI 10.1016/j.cageo.2021.104833; Blair-Stanek A, 2023, Arxiv, DOI arXiv:2302.06100; Bressan TS, 2020, COMPUT GEOSCI-UK, V139, DOI 10.1016/j.cageo.2020.104475; Cao Y., 2023, A comprehensive survey of AIgenerated content (AIGC): A history of generative AI from GAN to chatgpt. arXiv preprint arXiv:2303.04226; Chakraborty T, 2023, Arxiv, DOI arXiv:2308.16316; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Dai W, 2023, IEEE INT CONF ADV LE, P323, DOI 10.1109/ICALT58122.2023.00100; De Vos M. G., 2020, Geoscience Communication, V3, P191; Deng C., 2024, The 17th ACM international conference on web search and data mining, 03; Depina I, 2022, GEORISK, V16, P21, DOI 10.1080/17499518.2021.1971251; Devlin J., 2018, BERT PRE TRAINING DE; Dutta A., 2023, Van der polinformed neural networks for multistepahead forecasting of extreme climatic events. In NeurIPS 2023 AI for science workshop; Eddy SR, 1996, CURR OPIN STRUC BIOL, V6, P361, DOI 10.1016/S0959-440X(96)80056-X; Elabid Z, 2022, 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, ICMLA, P1203, DOI 10.1109/ICMLA55696.2022.00194; Feng RH, 2022, MATH GEOSCI, V54, P831, DOI 10.1007/s11004-022-09994-w; Fieberg C., 2023, Using gpt4 for financial advice. Available at SSRN 4488891; Fleming J, 2022, J EXPO SCI ENV EPID, DOI 10.1038/s41370-022-00433-w; Garza A, 2024, Arxiv, DOI arXiv:2310.03589; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Hao ZK, 2023, Arxiv, DOI [arXiv:2211.08064, 10.48550/arXiv.2211.08064, DOI 10.48550/ARXIV.2211.08064]; Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, 10.48550/arXiv.1606.08415]; Heris MP, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0542-3; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu S, 2024, ENG APPL ARTIF INTEL, V128, DOI 10.1016/j.engappai.2023.107453; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang M., 2024, IEEE Transactions on Geoscience and Remote Sensing; Jin XW, 2021, J COMPUT PHYS, V426, DOI 10.1016/j.jcp.2020.109951; Kang YH, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00734-5; Karimpouli S, 2020, GEOSCI FRONT, V11, P1993, DOI 10.1016/j.gsf.2020.07.007; Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5; Karpatne A, 2019, IEEE T KNOWL DATA EN, V31, P1544, DOI 10.1109/TKDE.2018.2861006; Karras T, 2018, Arxiv, DOI arXiv:1710.10196; Kranstauber B, 2011, ENVIRON MODELL SOFTW, V26, P834, DOI 10.1016/j.envsoft.2010.12.005; Kuckreja K, 2023, Arxiv, DOI arXiv:2311.15826; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Levine D. M., 2023, medRxiv; Lewis A, 2017, REMOTE SENS ENVIRON, V202, P276, DOI 10.1016/j.rse.2017.03.015; Li WD, 2021, IEEE ACCESS, V9, P11585, DOI 10.1109/ACCESS.2021.3049479; Li WW, 2023, GEOINFORMATICA, V27, P619, DOI 10.1007/s10707-022-00476-z; Li Z., 2023, Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Linde N., 2024, Computers Geosciences; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Lu L, 2021, SIAM REV, V63, P208, DOI 10.1137/19M1274067; Lv N, 2021, IEEE J-STARS, V14, P9318, DOI 10.1109/JSTARS.2021.3110842; Lyu B, 2024, COMPUT GEOTECH, V170, DOI 10.1016/j.compgeo.2024.106336; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Mao ZP, 2020, COMPUT METHOD APPL M, V360, DOI 10.1016/j.cma.2019.112789; Marconcini M, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00580-5; Mirza M., 2014, Comput. Sci., p1411.1784; Moseley B, 2020, Arxiv, DOI arXiv:2006.11894; Mosser L, 2017, PHYS REV E, V96, DOI 10.1103/PhysRevE.96.043309; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Navalgund RR, 2007, CURR SCI INDIA, V93, P1747; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Pardos Z. A., 2023, arXiv; Patel N, 2023, IEEE GEOSC REM SEN M, V11, P86, DOI 10.1109/MGRS.2023.3275984; Pu JC, 2021, NONLINEAR DYNAM, V105, P1723, DOI 10.1007/s11071-021-06554-5; RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045; Ramdani A. I., 2024, INT PETR TECHN C; Ranade R, 2021, COMPUT METHOD APPL M, V378, DOI 10.1016/j.cma.2021.113722; Rasht-Behesht M, 2022, J GEOPHYS RES-SOL EA, V127, DOI 10.1029/2021JB023120; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Rodrigues R., 2020, J RESPONSIBLE TECHNO, V4, DOI DOI 10.1016/J.JRT.2020.100005; Romanello M, 2023, LANCET, V402, P2055, DOI 10.1016/S0140-6736(23)02584-9; Ross S. I., 2023, The programmer's assistant: Conversational interaction with a large language model for software development. In Proceedings of the 28th international conference on intelligent user interfaces (pp. 491514); Sandoval G, 2022, Arxiv, DOI arXiv:2208.09727; Sasal L, 2022, 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, ICMLA, P671, DOI 10.1109/ICMLA55696.2022.00111; Savelka J, 2023, Arxiv, DOI arXiv:2306.09525; Shafer G., 2005, Algorithmic learning in a random world, DOI DOI 10.1007/B106715; Sharma P, 2023, Arxiv, DOI arXiv:2307.00112; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Son G, 2023, Arxiv, DOI [arXiv:2305.01505, 10.48550/arXiv.2305.01505]; Song SH, 2021, COMPUTAT GEOSCI, V25, P1251, DOI 10.1007/s10596-021-10059-w; Song YS, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3582688; Su Y., 2024, IEEE Transactions on Geoscience and Remote Sensing; Sumbul G, 2019, INT GEOSCI REMOTE SE, P5901, DOI [10.1109/IGARSS.2019.8900532, 10.1109/igarss.2019.8900532]; Sun LC, 2024, Arxiv, DOI arXiv:2401.05561; Tack A, 2022, Arxiv, DOI arXiv:2205.07540; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tay Y, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P695, DOI 10.1145/3077136.3080790; Taylor R., 2022, Galactica: A large language model for science; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; The MosaicML NLP Team, 2023, Introducing mpt7b: A new standard for opensource, commercially usable llms; Thottolil R, 2023, Arxiv, DOI arXiv:2306.05951; Tishechkin D., 2024, 4 EAGE DIG C EXH, V2024, P1; Touvron H., 2023, Llama: Open and efficient foundation language models; Vaswani A, 2017, ADV NEUR IN, V30; Vovk V., 2013, Empirical Inference: Festschrift in Honor of Vladimir N. Vapnik, P105, DOI DOI 10.1007/978-3-642-41136-6_11; Vovk V, 2017, CONFORMAL PROBABILIS, P82; Wang D., 2023, Samrs: Scalingup remote sensing segmentation dataset with segment anything model. In Thirtyseventh conference on neural information processing systems datasets and benchmarks track; Wang R, 2023, Arxiv, DOI arXiv:2306.03090; Wang SW, 2013, INT J GEOGR INF SCI, V27, P2122, DOI 10.1080/13658816.2013.776049; Wang TT, 2021, J GEOPHYS RES-SOL EA, V126, DOI 10.1029/2020JB020077; Wei JB, 2024, INT J APPL EARTH OBS, V128, DOI 10.1016/j.jag.2024.103752; West H., 2018, Teaching Geography, V43, P22; Wu Q., 2020, J Open Source Softw, V5, P2305, DOI [10.21105/joss.02305, DOI 10.21105/JOSS.02305]; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xiong ZT, 2024, Arxiv, DOI arXiv:2210.04936; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Xu R., 2024, IEEE Transactions on Geoscience and Remote Sensing; Yang L, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3626235; Yang L, 2021, J COMPUT PHYS, V425, DOI 10.1016/j.jcp.2020.109913; Yu FY, 2022, Arxiv, DOI arXiv:2212.01326; Yu Z., 2023, A comprehensive survey on sourcefree domain adaptation. arXiv preprint arXiv:2302.11803; Zaremba A., 2023, Chatgpt: Unlocking the future of nlp in finance; Zhang CK, 2021, COMPUTAT GEOSCI, V25, P553, DOI 10.1007/s10596-020-10027-w; Zhang H, 2024, Arxiv, DOI arXiv:2309.06799; Zhang S, 2023, GEOSCI DATA J, V10, P519, DOI 10.1002/gdj3.186; Zhang T, 2024, COMPUTAT GEOSCI, V28, P503, DOI 10.1007/s10596-024-10279-w; Zhang TF, 2019, PETROL SCI, V16, P541, DOI 10.1007/s12182-019-0328-4; Zhang WY, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P2482, DOI 10.1145/3534678.3539239; Zhang XY, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P4435, DOI 10.1145/3583780.3615285; Zhang Y, 2023, IEEE T GEOSCI REMOTE, V61, DOI [10.1109/TGRS.2023.3293832, 10.1109/TGRS.2023.3236973, 10.1109/TGRS.2023.3283508]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng Y., 2010, IEEE Data Eng Bull, V33, P32; Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555	130	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0266-4720	1468-0394		EXPERT SYST	Expert Syst.	2024 JUN 11	2024										10.1111/exsy.13654	http://dx.doi.org/10.1111/exsy.13654		JUN 2024	16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UD6G4					2024-07-03	WOS:001246156700001
C	Engelmann, B; Breuer, T; Friese, JI; Schaer, P; Fuhr, N		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Engelmann, Bjoern; Breuer, Timo; Friese, Jana Isabelle; Schaer, Philipp; Fuhr, Norbert			Context-Driven Interactive Query Simulations Based on Generative Large Language Models	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		User Simulation; Interactive Retrieval; Query Generation		Simulating user interactions enables a more user-oriented evaluation of information retrieval (IR) systems. While user simulations are cost-efficient and reproducible, many approaches often lack fidelity regarding real user behavior. Most notably, current user models neglect the user's context, which is the primary driver of perceived relevance and the interactions with the search results. To this end, this work introduces the simulation of context-driven query reformulations. The proposed query generation methods build upon recent Large Language Model (LLM) approaches and consider the user's context throughout the simulation of a search session. Compared to simple context-free query generation approaches, these methods show better effectiveness and allow the simulation of more efficient IR sessions. Similarly, our evaluations consider more interaction context than current session-based measures and reveal interesting complementary insights in addition to the established evaluation protocols. We conclude with directions for future work and provide an entirely open experimental setup.	[Engelmann, Bjoern; Breuer, Timo; Schaer, Philipp] Univ Appl Sci, TH Koln, Cologne, Germany; [Friese, Jana Isabelle; Fuhr, Norbert] Univ Duisburg Essen, Duisburg, Germany	University of Duisburg Essen	Engelmann, B (corresponding author), Univ Appl Sci, TH Koln, Cologne, Germany.	bjoern.engelmann@th-koeln.de; timo.breuer@th-koeln.de; jana.friese@uni-due.de; philipp.schaer@th-koeln.de; norbert.fuhr@uni-due.de		Breuer, Timo/0000-0002-1765-2449; Friese, Jana Isabelle/0009-0005-2483-0476; Engelmann, Bjorn/0009-0000-7074-9066	Klaus Tschira Stiftung [JoIE - 00.003.2020]; Deutsche Forschungsgemeinschaft [RESIRE - 509543643]	Klaus Tschira Stiftung; Deutsche Forschungsgemeinschaft(German Research Foundation (DFG))	This work was supported by Klaus Tschira Stiftung (JoIE - 00.003.2020) and Deutsche Forschungsgemeinschaft (RESIRE - 509543643).	Alaofi M, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1869, DOI 10.1145/3539618.3591960; Allan J., 2017, NIST Special Publication, V500; Azzopardi L., 2010, SIGIR Forum, V44, P35; Balog K, 2023, Arxiv, DOI [arXiv:2306.08550, 10.48550/arXiv.2306.08550]; Balog K, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2697, DOI 10.1145/3404835.3462821; Baskaya F, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2297, DOI 10.1145/2505515.2505660; Breuer T, 2024, ACM J DATA INF QUAL, V16, DOI 10.1145/3623640; Breuer T, 2022, LECT NOTES COMPUT SC, V13185, P80, DOI 10.1007/978-3-030-99736-6_6; Carterette Ben, 2015, P 2015 INT C THEOR I, P91, DOI [10.1145/2808194.2809470, DOI 10.1145/2808194.2809470]; Engelmann B, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P3875, DOI 10.1145/3583780.3615187; Hagen M., 2021, SIM4IR; Hagen M, 2016, LECT NOTES COMPUT SC, V9994, P138, DOI 10.1007/978-3-319-48051-0_11; Hersh W.R., 2000, P 23 ANN INT ACM SIG, P17, DOI [10.1145/345508, DOI 10.1145/345508]; Jarvelin K., 2000, SIGIR Forum, V34, P41; Järvelin K, 2008, LECT NOTES COMPUT SC, V4956, P4; KREBS JR, 1974, ANIM BEHAV, V22, P953, DOI 10.1016/0003-3472(74)90018-9; Lipani A, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P108; MacAvaney S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2429, DOI 10.1145/3404835.3463254; Macdonald C, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4526, DOI 10.1145/3459637.3482013; Mackie I, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2026, DOI 10.1145/3539618.3591992; Maxwell D., 2019, Modelling search and stopping in interactive information retrieval; Maxwell D., 2015, P 24 ACM INT C INF K, P313, DOI DOI 10.1145/2806416.2806476; Maxwell D, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1141, DOI 10.1145/2911451.2911469; Moffat A, 2009, ACM T INFORM SYST, V27, DOI 10.1145/1416950.1416952; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Pääkkönen T, 2017, INFORM RETRIEVAL J, V20, P338, DOI 10.1007/s10791-017-9301-2; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Scells H, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2825, DOI 10.1145/3477495.3531766; Tague J., 1980, INFORM RETRIEVAL RES, P236, DOI [10.5555/636669.636684, DOI 10.5555/636669.636684]; Tague J. M., 1981, SIGIR Forum, V16, P66, DOI 10.1145/1013228.511764; Turpin A. H., 2001, SIGIR Forum, P225; Voorhees E.M., 2018, NIST Special Publication, P500; Wang L., 2023, C EMP METH NAT LANG, P9414; Wang X., 2023, Generative query reformulation for effective adhoc search; Whiteson S., 2013, P 6 ACM INT C WEB SE, P183, DOI [10.1145/2433396, DOI 10.1145/2433396]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zerhoudi S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4661, DOI 10.1145/3511808.3557711; Zhang YN, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P193, DOI 10.1145/3121050.3121070	38	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						173	188		10.1007/978-3-031-56060-6_12	http://dx.doi.org/10.1007/978-3-031-56060-6_12			16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY		Green Submitted			2024-07-03	WOS:001211832000012
J	Ni, B; Buehler, MJ				Ni, Bo; Buehler, Markus J.			MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge	EXTREME MECHANICS LETTERS			English	Article						Multi-agent modeling; Large language model (LLM); Elasticity; Hyper-elasticity; Finite element method; GPT-4; Physics-inspired machine learning	FINITE-ELEMENT-ANALYSIS; NEURAL-NETWORKS	Solving mechanics problems using numerical methods requires comprehensive intelligent capability of retrieving relevant knowledge and theory, constructing and executing codes, analyzing the results, a task that has thus far mainly been reserved for humans. While emerging AI methods can provide effective approaches to solve end-toend problems, for instance via the use of deep surrogate models or various data analytics strategies, they often lack physical intuition since knowledge is baked into the parametric complement through training, offering less flexibility when it comes to incorporating mathematical or physical insights. By leveraging diverse capabilities of multiple dynamically interacting large language models (LLMs), we can overcome the limitations of conventional approaches and develop a new class of physics-inspired generative machine learning platform, here referred to as MechAgents. A set of AI agents can solve mechanics tasks, here demonstrated for elasticity problems, via autonomous collaborations. A two-agent team can effectively write, execute and self-correct code, in order to apply finite element methods to solve classical elasticity problems in various flavors (different boundary conditions, domain geometries, meshes, small/finite deformation and linear/hyper-elastic constitutive laws, and others). For more complex tasks, we construct a larger group of agents with enhanced division of labor among planning, formulating, coding, executing and criticizing the process and results. The agents mutually correct each other to improve the overall team-work performance in understanding, formulating and validating the solution. Our framework shows the potential of synergizing the intelligence of language models, the reliability of physicsbased modeling, and the dynamic collaborations among diverse agents, opening novel avenues for automation of solving engineering problems.	[Ni, Bo; Buehler, Markus J.] MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Buehler, Markus J.] MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Buehler, MJ (corresponding author), MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	mbuehler@MIT.EDU			USDA [2021-69012-35978]; DOE- SERDP; ARO [W911NF-22-2-0213, W911NF2120130, U01EB014976]; MIT -IBM Watson AI Lab; MIT's Generative AI Initiative; NIH [R01AR077793, N00014-19-1-2375]; ONR [N00014-20-1- 2189, WP22-S1-3475];  [79058LSCSB]	USDA(United States Department of Agriculture (USDA)); DOE- SERDP; ARO; MIT -IBM Watson AI Lab(International Business Machines (IBM)); MIT's Generative AI Initiative; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); 	We acknowledge support from USDA (2021-69012-35978) , DOE- SERDP (WP22-S1-3475) , ARO (79058LSCSB, W911NF-22-2-0213 and W911NF2120130) as well as the MIT -IBM Watson AI Lab and MIT's Generative AI Initiative. Additional support from NIH (U01EB014976 and R01AR077793) and ONR (N00014-19-1-2375 and N00014-20-1- 2189) is acknowledged.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ainsworth M, 2022, COMPUT METHOD APPL M, V395, DOI 10.1016/j.cma.2022.115034; Alhijazi M, 2020, NANOTECHNOL REV, V9, P853, DOI 10.1515/ntrev-2020-0069; Alnaes M.S., 2015, Arch Numer Softw, V3, DOI [10.11588/ans.2015.100.20553, DOI 10.11588/ANS.2015.100.20553]; Awadalla A., 2023, OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models; BABUSKA I, 1992, SIAM J NUMER ANAL, V29, P1261, DOI 10.1137/0729075; Baktash JA, 2023, Gpt-4: a review on advancements and opportunities in natural language processing; Begus G, 2023, AI ASSISTED CODING E; Bisong E., 2019, BUILDING MACHINE LEA, DOI [DOI 10.1007/978-1-4842-4470-8_7, 10.1007/978-1-4842-4470-8]; Bower A.F., 2010, Applied Mechanics of Solids; Brinson LC, 2024, MRS BULL, V49, P12, DOI 10.1557/s43577-023-00498-4; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Buehler MJ, 2024, ACS ENG AU, V4, P241, DOI 10.1021/acsengineeringau.3c00058; Buehler MJ, 2023, J MECH PHYS SOLIDS, V181, DOI 10.1016/j.jmps.2023.105454; Buehler MJ, 2024, APPL MECH REV, V76, DOI 10.1115/1.4063843; Buehler MJ, 2023, J APPL PHYS, V134, DOI 10.1063/5.0157367; Buehler MJ, 2023, J MATER RES, V38, P1317, DOI 10.1557/s43578-023-00892-3; Buehler MJ, 2022, J APPL MECH-T ASME, V89, DOI 10.1115/1.4055730; Buehler MJ, 2022, MATER TODAY, V57, P9, DOI 10.1016/j.mattod.2022.05.020; Castro-Orgaz O, 2019, SHALLOW WATER HYDRAULICS, P347, DOI 10.1007/978-3-030-13073-2_9; Chang Y., 2023, J. ACM, V37; ChatGPT, about us; Chen G., 2023, GPTEval: A Survey on Assessments of ChatGPT and GPT-4; Chen W, 2020, Arxiv, DOI [arXiv:2001.04815, DOI 10.48550/ARXIV.2001.04815]; COMSOL, Software for Multiphysics Simulation; Nguyen DN, 2023, MRS BULL, V48, P31, DOI 10.1557/s43577-022-00372-9; FEAP, About us; FEM on, About us; Fish J., 2007, 1 COURSE FINITE ELEM, V1; Fu Y., 2001, NONLINEAR ELASTICITY; Gat I., 2023, CODE LLAMA OPEN FDN; GitHub, GitHub repository; Google, 2023, PALM 2 TECHN REP; Google's Colaboratory, About us; Gu GX, 2018, EXTREME MECH LETT, V18, P19, DOI 10.1016/j.eml.2017.10.001; Guo K, 2020, INT J FRACTURE, V222, P13, DOI 10.1007/s10704-020-00423-9; Hughes T.J.R., 2000, The Finite Element Method: Linear Static and Dynamic Finite Element Analysis; Karabelas E, 2022, COMPUT METHOD APPL M, V394, DOI 10.1016/j.cma.2022.114887; Kashefi A., 2023, Journal of Machine Learning for Modeling and Computing, V4, P1, DOI DOI 10.1615/JMACHLEARNMODELCOMPUT.2023048492; Khare E, 2022, ACS BIOMATER SCI ENG, DOI 10.1021/acsbiomaterials.2c00737; Kuna M, 2013, Solid Mech. Appl., V201, DOI 10.1007/978-94-007-6680-8; Kuszczak I, 2023, EXTREME MECH LETT, V64, DOI 10.1016/j.eml.2023.102078; Lagaris IE, 1998, IEEE T NEURAL NETWOR, V9, P987, DOI 10.1109/72.712178; Lee NA, 2022, MATTER-US, V5, P3597, DOI 10.1016/j.matt.2022.10.003; Lew AJ, 2023, MATTER-US, V6, P1975, DOI 10.1016/j.matt.2023.03.031; Lew AJ, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01036-1; Lew AJ, 2023, MATER TODAY, V64, P10, DOI 10.1016/j.mattod.2023.03.007; Lew AJ, 2021, APPL PHYS REV, V8, DOI 10.1063/5.0057162; Lin X, 2019, NAT BIOMED ENG, V3, P632, DOI 10.1038/s41551-019-0380-9; Liu H., 2023, Improved baselines with visual instruction tuning; Lookman T, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0153-8; MOOSE, About us; Moukalled F., 2016, The Finite Volume Method in Computational Fluid Dynamics: An Advanced Introduction with OpenFOAM and Matlab, DOI DOI 10.1007/978-3-319-16874-6; Mousavi SMT, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-018-0140-5; Müzel SD, 2020, POLYMERS-BASEL, V12, DOI 10.3390/polym12040818; Ni B, 2024, SCI ADV, V10, DOI 10.1126/sciadv.adl4000; Ni B, 2023, CHEM-US, V9, P1828, DOI 10.1016/j.chempr.2023.03.020; Ni B, 2021, MRS BULL, V46, P19, DOI 10.1557/s43577-020-00006-y; Noack MM, 2023, MRS BULL, V48, P153, DOI 10.1557/s43577-023-00478-8; OpenAI A.P.I, About us; Peng GCY, 2021, ARCH COMPUT METHOD E, V28, P1017, DOI 10.1007/s11831-020-09405-5; python, Python Release Python 3.10.0 at Python.org; Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045; Reddy J.N., 2006, An introduction to the finite element method, P766; Shen S. C.-y., 2022, COMMUN ENG, V1, P1, DOI [DOI 10.1038/S44172-022-00037-0, 10.1038/s44172-022-00037-0]; Shukla SS, 2024, MRS BULL, V49, P17, DOI 10.1557/s43577-023-00561-0; Significant-Gravitas/AutoGPT, An experimental open-source attempt to make GPT- 4 fully autonomous; Smith M., 2009, ABAQUS/Standard User's Manual; Smith PT, 2023, MRS BULL, V48, P1172, DOI 10.1557/s43577-023-00619-z; Solanki K, 2004, ENG FRACT MECH, V71, P149, DOI 10.1016/S0013-7944(03)00099-7; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Trinh TH, 2024, NATURE, V625, DOI 10.1038/s41586-023-06747-5; Vaswani A, 2017, ADV NEUR IN, V30; Wang L., 2023, SURVEY LARGE LANGUAG; Wu Q., 2023, AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation; Xi Z., 2023, The Rise and Potential of Large Language Model Based Agents: A Survey; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Yang Z., 2023, The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision); Yang ZZ, 2021, J MECH PHYS SOLIDS, V154, DOI 10.1016/j.jmps.2021.104506; Yang ZZ, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abd7416; Zienkiewicz OC, 2005, FINITE ELEMENT METHOD FOR FLUID DYNAMICS, 6TH EDITION, P1	81	3	3	18	18	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-4316			EXTREME MECH LETT	EXTREME MECH. LETT.	MAR	2024	67								102131	10.1016/j.eml.2024.102131	http://dx.doi.org/10.1016/j.eml.2024.102131		FEB 2024	14	Engineering, Mechanical; Materials Science, Multidisciplinary; Mechanics	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Materials Science; Mechanics	LO6Z9		Green Submitted			2024-07-03	WOS:001187797200001
J	Hu, DQ; Liu, B; Zhu, XF; Lu, XD; Wu, N				Hu, Danqing; Liu, Bing; Zhu, Xiaofeng; Lu, Xudong; Wu, Nan			Zero-shot information extraction from radiological reports using ChatGPT	INTERNATIONAL JOURNAL OF MEDICAL INFORMATICS			English	Article						Information extraction; Large language model; Question answering; Radiological report; Lung cancer		Introduction: Electronic health records contain an enormous amount of valuable information recorded in free text. Information extraction is the strategy to transform free text into structured data, but some of its components require annotated data to tune, which has become a bottleneck. Large language models achieve good performances on various downstream NLP tasks without parameter tuning, becoming a possible way to extract information in a zero-shot manner. Methods: In this study, we aim to explore whether the most popular large language model, ChatGPT, can extract information from the radiological reports. We first design the prompt template for the interested information in the CT reports. Then, we generate the prompts by combining the prompt template with the CT reports as the inputs of ChatGPT to obtain the responses. A post-processing module is developed to transform the responses into structured extraction results. Besides, we add prior medical knowledge to the prompt template to reduce wrong extraction results. We also explore the consistency of the extraction results. Results: We conducted the experiments with 847 real CT reports. The experimental results indicate that ChatGPT can achieve competitive performances for some extraction tasks like tumor location, tumor long and short diameters compared with the baseline information extraction system. By adding some prior medical knowledge to the prompt template, extraction tasks about tumor spiculations and lobulations obtain significant improvements but tasks about tumor density and lymph node status do not achieve better performances. Conclusion: ChatGPT can achieve competitive information extraction for radiological reports in a zero-shot manner. Adding prior medical knowledge as instructions can further improve performances for some extraction tasks but may lead to worse performances for some complex extraction tasks.	[Hu, Danqing; Zhu, Xiaofeng] Zhejiang Lab, Hangzhou 311121, Zhejiang, Peoples R China; [Liu, Bing; Wu, Nan] Peking Univ Canc Hosp & Inst, Dept Thorac Surg 2, Beijing 100142, Peoples R China; [Lu, Xudong] Zhejiang Univ, Coll Biomed Engn & Instrumental Sci, Hangzhou 310027, Zhejiang, Peoples R China	Zhejiang Laboratory; Zhejiang University	Hu, DQ; Zhu, XF (corresponding author), Zhejiang Lab, Hangzhou 311121, Zhejiang, Peoples R China.; Wu, N (corresponding author), Peking Univ Canc Hosp & Inst, Dept Thorac Surg 2, Beijing 100142, Peoples R China.	hudq@zhejianglab.com; andy.zhu@zhejianglab.com; nanwu@bjmu.edu.cn	Zhu, Xiaofeng/HII-5291-2022	Zhu, Xiaofeng/0000-0001-6840-0578; Hu, Danqing/0000-0003-0810-4819	Beijing Natural Science Foun-dation [L222020]; Key Research Project of Zhejiang Lab [2022PG0AC02]	Beijing Natural Science Foun-dation(Beijing Natural Science Foundation); Key Research Project of Zhejiang Lab	This study was supported by the Beijing Natural Science Foun-dation (L222020) and the Key Research Project of Zhejiang Lab (2022PG0AC02) .	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733; Brown T., 2020, NIPS, P1877; Chen H., 2023, CHIP 2022, P109; Datta S, 2022, INT J MED INFORM, V158, DOI 10.1016/j.ijmedinf.2021.104628; Datta S, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103301; FRIEDMAN C, 1994, J AM MED INFORM ASSN, V1, P161, DOI 10.1136/jamia.1994.95236146; Gao S, 2018, J AM MED INFORM ASSN, V25, P321, DOI 10.1093/jamia/ocx131; Hassanpour S, 2016, ARTIF INTELL MED, V66, P29, DOI 10.1016/j.artmed.2015.09.007; Hu DQ, 2023, IEEE J BIOMED HEALTH, V27, P1216, DOI 10.1109/JBHI.2022.3233387; Hu DQ, 2022, JMIR MED INF, V10, P153, DOI 10.2196/35475; Hu DQ, 2021, JMIR MED INF, V9, DOI 10.2196/27955; Hu DQ, 2020, ARTIF INTELL MED, V107, DOI 10.1016/j.artmed.2020.101921; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Lei JB, 2014, J AM MED INFORM ASSN, V21, P808, DOI 10.1136/amiajnl-2013-002381; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Li Q, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0160-8; Liu RC, 2023, ARTIF INTELL REV, V56, P14439, DOI 10.1007/s10462-023-10506-3; Liu XC, 2023, medRxiv, DOI [10.1101/2023.06.28.23291931, DOI 10.1101/2023.06.28.23291931, 10.1101/2023.06.28.23291931]; Min B., 2023, ACM Computing Surveys; Nasar Z, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3445965; Roberts Kirk, 2012, AMIA Annu Symp Proc, V2012, P779; Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002; Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560; Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063; Unanue IJ, 2017, J BIOMED INFORM, V76, P102, DOI 10.1016/j.jbi.2017.11.007; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068; Yadav P, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3127881; Yim WW, 2016, JAMA ONCOL, V2, P797, DOI 10.1001/jamaoncol.2016.0213; Zhang HY, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01575-x; Zhang XH, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103985	33	1	1	24	24	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	1386-5056	1872-8243		INT J MED INFORM	Int. J. Med. Inform.	MAR	2024	183								105321	10.1016/j.ijmedinf.2023.105321	http://dx.doi.org/10.1016/j.ijmedinf.2023.105321		DEC 2023	8	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Health Care Sciences & Services; Medical Informatics	IJ5L8	38157785	Green Submitted			2024-07-03	WOS:001165970200001
J	Lu, J; Chen, MF				Lu, Jin; Chen, Meifen			Zero-sample face retrieval combining large language model and visual base model for IoT	INTERNET TECHNOLOGY LETTERS			English	Article; Early Access						face retrieval; IoT; large model		This paper presents a novel approach to face retrieval that leverages the capabilities of large language models and visual base models, marking a significant departure from traditional IoT text retrieval methods that depend on extensive data collection and model training. By eliminating the need for text-image pair data collection and model training, our method not only dramatically reduces the data and computational costs associated with IoT applications but also achieves high accuracy in face retrieval, as demonstrated by a 72% top-1 accuracy and 93% top-3 accuracy on the Celeb-A dataset. This substantial improvement in efficiency and performance has profound implications for the future of IoT systems, potentially revolutionizing face recognition technology by enabling more scalable, cost-effective, and accurate solutions. The successful application of zero-sample face retrieval illustrates the transformative impact that advanced AI models can have on real-world applications and opens new avenues for research and development in the realm of intelligent IoT devices.	[Lu, Jin] Shenzhen Polytech Univ, Guangdong Key Lab Big Data Intelligence Vocat Educ, Shenzhen, Peoples R China; [Chen, Meifen] Shenzhen Polytech Univ, Coll Digital Creat & Animat, Shenzhen, Peoples R China; [Lu, Jin] Shenzhen Polytech Univ, Guangdong Key Lab Big Data Intelligence Vocat Educ, Shenzhen 518055, Guangdong, Peoples R China	Shenzhen Polytechnic University; Shenzhen Polytechnic University; Shenzhen Polytechnic University	Lu, J (corresponding author), Shenzhen Polytech Univ, Guangdong Key Lab Big Data Intelligence Vocat Educ, Shenzhen 518055, Guangdong, Peoples R China.	lujin0808@szpu.edu.cn		Jin, Lu/0000-0001-6219-6166	Shenzhen Education Science Planning Project: Research on the Evolution Mechanism and Intervention of Interpersonal Relationships among College Students Driven by Multimodal Data	Shenzhen Education Science Planning Project: Research on the Evolution Mechanism and Intervention of Interpersonal Relationships among College Students Driven by Multimodal Data	Shenzhen Education Science "14TH FIVE-YEAR PLAN"2022 Subject: Research on Personalized Multimodal Complex Emotion Recognition for Natural Interaction between Teacher and Learner (ybzz22020); 2023 Guangdong University Young Innovative Talents Project "Research on Attention and Learning Emotion Recognition in Teacher -Student Adaptive Interaction Based on Multi -modal Data of Classroom Environment (2023WQNCX208)"; 2024 Shenzhen Polytechnic University Quality Engineering Project "Research on Classroom Scene Understanding and Behavior Analysis Method Based on Multimodal Attention Mechanisms"; Shenzhen Education Science Planning Project: Research on the Evolution Mechanism and Intervention of Interpersonal Relationships among College Students Driven by Multimodal Data, Grant/Award Number: rgzn23003r No Statement Availabler No Statement Availabler No Statement Available	Al-Qerem A, 2020, SOFT COMPUT, V24, P5695, DOI 10.1007/s00500-019-04220-y; Balasubramanian V, 2020, SIMUL MODEL PRACT TH, V98, DOI 10.1016/j.simpat.2019.101968; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cui Y., 2022, Learning for Dynamics and Control Conference; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng SG, 2020, IEEE INTERNET THINGS, V7, P7457, DOI 10.1109/JIOT.2020.2984887; Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379; Fan Z., 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics; Goh Gabriel, 2021, Distill, DOI DOI 10.23915/DISTILL.00030; Gupta BB, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4946; Hand E., 2017, Proceedings of the AAAI Conference on Artificial Intelligence, V31; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang ZH, 2015, Arxiv, DOI [arXiv:1508.01991, DOI 10.48550/ARXIV.1508.01991]; Jia C, 2021, PR MACH LEARN RES, V139; Jiang YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13779, DOI 10.1109/ICCV48922.2021.01354; Khosla P., 2020, ADV NEURAL INF PROCE, V33; Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277; Liu Z., 2018, Large-scale celebfaces attributes (celeba) dataset, V15, P11; Nam H., 2017, P OF THE IEEE C ON C; Pujol VC, 2023, IEEE INTERNET COMPUT, V27, P53, DOI 10.1109/MIC.2023.3284693; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raj MG, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.300824; Saleh A, 2023, Arxiv, DOI arXiv:2312.14647; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Tiwari A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.306260; Tsetse A., 2014, International Journal of Managing Information Technology, V6, P1, DOI [DOI 10.5121/IJMIT.2014.6301, 10.5121/ijmit.2014]; Vaswani A, 2017, ADV NEUR IN, V30; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Yuan L., 2021, arXiv; Alom MZ, 2018, Arxiv, DOI [arXiv:1803.01164, DOI 10.48550/ARXIV.1803.01164]; Zhang Yulun, 2018, Proceedings of the European conference on computer vision (ECCV); Zhou WA, 2017, Arxiv, DOI arXiv:1706.06064	36	0	0	3	3	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND		2476-1508		INTERNET TECHNOL LET	Internet. Technol. Lett.	2024 JAN 31	2024										10.1002/itl2.506	http://dx.doi.org/10.1002/itl2.506		JAN 2024	6	Telecommunications	Emerging Sources Citation Index (ESCI)	Telecommunications	GU3N3					2024-07-03	WOS:001155147500001
J	Sprint, G				Sprint, Gina			Social Networks and Large Language Models for Division I Basketball Game Winner Prediction	IEEE ACCESS			English	Article						Social networking (online); Games; Blogs; Task analysis; Sports; Predictive models; Few-shot learning; Context modeling; Large language models; Few-shot/zero-shot learning; in-context learning; large language models; March Madness prediction; NCAA college basketball; social networks		Sporting event outcome prediction is a well-established and actively researched domain, with a particular focus on college basketball's March Madness tournament. Researchers, fans, and gamblers alike seek accurate game-level predictions using features such as tournament seeds, season performance, and expert opinions. While machine learning algorithms have been harnessed to build prediction models, no perfect model or human-created bracket has emerged. This paper explores a novel approach to basketball game outcome prediction by utilizing the power of social networks and large language models (LLMs). LLMs are trained to understand and generate text, often eliminating the need for a feature engineering step. Consequently, our method utilizes tweets from official Division I college basketball team Twitter accounts in the days leading up to a game as context for knowledge discovery and winner prediction with LLMs. To do this, we have compiled a comprehensive dataset of over one million tweets from both men's and women's teams spanning two consecutive seasons. Instead of relying on traditional numeric features, we employ only tweet text with few-shot/zero-shot learning, thereby offering an emerging social network-based approach for sporting event outcome prediction. Furthermore, using chain of thought prompting we investigate the information in team tweets that are predictive of future game performance.	[Sprint, Gina] Gonzaga Univ, Dept Comp Sci, Spokane, WA 99258 USA	Gonzaga University	Sprint, G (corresponding author), Gonzaga Univ, Dept Comp Sci, Spokane, WA 99258 USA.	sprint@gonzaga.edu						[Anonymous], The Absurd Odds of a Perfect NCAA Bracket; [Anonymous], The Longest an NCAA Bracket Has Ever Stayed Perfect; [Anonymous], NCAA Tournament Bracket Challenge 2023; [Anonymous], Why the @Raddar Solution Works; [Anonymous], 2023, Phys. A, Stat. Mech. Appl., V626; Beal S. E., 2021, AAAI C ARTIF INTELL, V35, P1; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao TS, 2020, Arxiv, DOI arXiv:1909.11722; Chen S. S.-C., 'Sport J., V49; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; David M. D., College Student athletes and social media: The psychologicalimpacts of Twitter use; Dutta S, 2017, J QUANT ANAL SPORTS, V13, P79, DOI 10.1515/jqas-2016-0062; Fink CG, 2023, DATA BRIEF, V50, DOI 10.1016/j.dib.2023.109521; Gumm A., 2015, P IEEE ACIS 16 INT C, P1; Haugh B. R., 2016, International Journal of Sport Communication, V9, P278; Hido S, 2008, LECT NOTES ARTIF INT, V5012, P148, DOI 10.1007/978-3-540-68125-0_15; Hoegh A, 2015, J QUANT ANAL SPORTS, V11, P29, DOI 10.1515/jqas-2014-0054; Kampakis S, 2014, Arxiv, DOI arXiv:1411.1243; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim JW, 2023, MANAG DECIS ECON, V44, P2223, DOI 10.1002/mde.3814; Latififard M., 2020, Commun.Res., V27, P151; Liu A., P 60 ANN M ASS COMP, V1; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu Y., 2023, Meta-Radiology, V1; Lopez MJ, 2015, J QUANT ANAL SPORTS, V11, P5, DOI 10.1515/jqas-2014-0058; Ludden IG, 2020, J QUANT ANAL SPORTS, V16, P1, DOI 10.1515/jqas-2019-0022; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Mustafa RU, 2017, MALAYS J COMPUT SCI, V30, P63; Pearson K. E., UND SE C FOOTB TEAMS; Pfeffer D., 2023, P INT AAAI C WEB SOC, V17, P1163; Ruiz FJR, 2015, J QUANT ANAL SPORTS, V11, P39, DOI 10.1515/jqas-2014-0055; Schumaker RP, 2016, DECIS SUPPORT SYST, V88, P76, DOI 10.1016/j.dss.2016.05.010; Sonas J., March Machine Learning Mania 2023. Kag-gle; Sun JS, 2024, Arxiv, DOI arXiv:2304.11657; Sun ZQ, 2023, Arxiv, DOI arXiv:2210.01296; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; UzZaman N, 2012, Arxiv, DOI arXiv:1211.6496; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xue H, 2023, Arxiv, DOI arXiv:2210.08964; Xue H, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1224, DOI 10.1145/3488560.3498387; Yu XL, 2023, Arxiv, DOI arXiv:2306.11025; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]	44	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						84774	84784		10.1109/ACCESS.2024.3403490	http://dx.doi.org/10.1109/ACCESS.2024.3403490			11	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	WB7S5		gold			2024-07-03	WOS:001252479700001
J	Nguyen, QN; Cam, NT; Nguyen, KV				Nguyen, Qui Ngoc; Cam, Nguyen Tan; Nguyen, Kiet Van			XLMR4MD: New Vietnamese dataset and framework for detecting the consistency of description and permission in Android applications using large language models	COMPUTERS & SECURITY			English	Article						Large language models; App Android; Security policy; Application permissions; Application description; Deep learning		Google Play and other application marketplaces have various Android applications and metadata. Among these, description information and privacy policy help explain the application's functionality. They also describe the permission of the application, especially those related to sensitive information. Detecting the inconsistency between the description of the application and privacy information and the permission extracted in the application's source code helps users decide whether to install and use the application. In this research, we propose a new method based on a pre -trained language model to detect inconsistencies between the permission extracted from the description application and privacy policy and the permission extracted from the application's source code (file APK). Related works focus on models of large-scale datasets, especially for resource -rich languages such as English. However, a language with low resources, like Vietnamese, needs more datasets for the task. To solve this problem, we propose the ViDPApp dataset (Description and Privacy Policy of Applications on Vietnamese domains), a high -quality dataset that humans manually annotate with 12,000+ sentences with an inter -annotator agreement (IAA) of over 85%. In addition, we proposed XLMR4MD, a new framework using large language models, outperforming powerful machine models (LSTM, Bi-GRU-LSTM-CNN, WikiBERT, DistilBERT, mBERT, and PhoBERT) and achieving the best with 84.04% F1 score in detecting inconsistencies between Android application permission and description. This framework can be fine-tuned for 100 languages, which benefits lowresource languages like Vietnamese. The dataset is available for research purposes.	[Nguyen, Qui Ngoc; Cam, Nguyen Tan; Nguyen, Kiet Van] Univ Informat Technol, Ho Chi Minh City, Vietnam; [Nguyen, Qui Ngoc; Cam, Nguyen Tan; Nguyen, Kiet Van] Vietnam Natl Univ, Ho Chi Minh City, Vietnam	Vietnam National University Hochiminh City	Cam, NT (corresponding author), Univ Informat Technol, Ho Chi Minh City, Vietnam.; Cam, NT (corresponding author), Vietnam Natl Univ, Ho Chi Minh City, Vietnam.	camnt@uit.edu.vn			VNUHCM-University of Infor-mation Technology's Scientific Research Support Fund	VNUHCM-University of Infor-mation Technology's Scientific Research Support Fund	This research was supported by The VNUHCM-University of Infor-mation Technology's Scientific Research Support Fund.	Alecakir H, 2020, 2020 INTERNATIONAL CONFERENCE ON INFORMATION SECURITY AND CRYPTOLOGY (ISCTURKEY 2020), P56, DOI [10.1109/ISCTURKEY51113.2020.9308004, 10.1109/iscturkey51113.2020.9308004]; Alecakir H, 2021, INT J INF SECUR, V20, P797, DOI 10.1007/s10207-020-00536-1; Andriotis P, 2016, IEEE INT WORKS INFOR, DOI 10.14324/000.ds.1520825; Bird S., 2006, PAPER PRESENTED COLI, P69, DOI [10.48550/arXiv.cs/0205028, DOI 10.3115/1225403.1225421, 10.3115/1225403.1225421]; Bonné B, 2017, PROCEEDINGS OF THIRTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2017), P195; Cevik B, 2022, INT J INF SECUR, V21, P1107, DOI 10.1007/s10207-022-00601-x; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dominguez Alvarez Daniel, 2019, PhD thesis; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Felt AP, 2012, P 8 S USABLE PRIVACY, P1, DOI DOI 10.1145/2335356.2335360; Feng YL, 2019, IEEE ACCESS, V7, P57829, DOI 10.1109/ACCESS.2019.2912210; Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245; Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345; Grave E, 2018, Arxiv, DOI [arXiv:1802.06893, DOI 10.48550/ARXIV.1802.06893, 10.48550/arXiv.1802.06893]; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hosmer DW, 2013, WILEY SER PROBAB ST, P89; Kong DG, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P530, DOI 10.1145/2810103.2813689; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luo Q, 2022, IEEE INTERNET THINGS, V9, P6159, DOI 10.1109/JIOT.2021.3109785; Luu ST, 2020, IEEE RIVF INT CONF, P1, DOI 10.1109/rivf48685.2020.9140745; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Nowak S., 2010, P INT C MULT INF RET, P557, DOI [DOI 10.1145/1743384.1743478, 10.1145/1743384.1743478]; Pandita Rahul, 2013, USENIX SEC S, V2013; Pires T, 2019, Arxiv, DOI arXiv:1906.01502; Poplack S, 2003, J LINGUIST, V39, P678, DOI 10.1017/S0022226703272297; Qu ZY, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1354, DOI 10.1145/2660267.2660287; Nguyen DQ, 2020, Arxiv, DOI arXiv:2003.00744; Rish I., 2001, IJCAI 2001 WORKSH EM, VVolume 3, P41, DOI DOI 10.1039/B104835J; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Sen Sevil, 2021, arXiv; Shirazi AS, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3055, DOI 10.1145/2556288.2557189; Sorower MS, 2010, LIT SURVEY ALGORITHM, V18, P1; Huynh TV, 2020, IEEE RIVF INT CONF, P53, DOI 10.1109/rivf48685.2020.9140760; Tran Hieu Trung, 2021, 2021 8 NAFOSTED C IN, P513; Nguyen AT, 2020, Arxiv, DOI arXiv:2010.01891; Van Huynh Tin, 2019, arXiv; Van Huynh Tin, 2022, P 29 INT C COMPUTATI, P3858; Vu T, 2018, Arxiv, DOI arXiv:1801.01331; Vu Xuan-Son, 2019, arXiv, DOI DOI 10.26615/978-954-452-056-4_147; Wang R, 2020, IEEE T MOBILE COMPUT, V19, P2933, DOI 10.1109/TMC.2019.2934441; Wardhaugh Ronald., 2021, An Introduction to Sociolinguistics, V7th; Watanabe Takuya, 2015, 11 S US PRIV SEC SOU, P241; Yu L, 2018, IEEE T SOFTWARE ENG, V44, P834, DOI 10.1109/TSE.2017.2730198; Zhao Yingjia, 2021, 1 WORKSH SPEECH LANG, P216; Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001; Ziehe S., 2021, P 1 WORKSHOP LANGUAG, P132	49	0	0	0	0	ELSEVIER ADVANCED TECHNOLOGY	OXFORD	OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0167-4048	1872-6208		COMPUT SECUR	Comput. Secur.	MAY	2024	140								103814	10.1016/j.cose.2024.103814	http://dx.doi.org/10.1016/j.cose.2024.103814		MAR 2024	25	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QB5F1					2024-07-03	WOS:001218425900001
J	Twomey, R				Twomey, Robert			Communing with Creative AI	PROCEEDINGS OF THE ACM ON COMPUTER GRAPHICS AND INTERACTIVE TECHNIQUES			English	Article						surrealism; computational co-authorship; creative AI		Drawing on historical and contemporary examples, this paper discusses relationships between humans and machines in creative co-production with generative AI. It distinguishes between generative systems as augmenting tools and autonomous collaborators, and adopts the term communion to describe the close degree of exchange that is possible when working with these systems. It draws on historical examples of surrealist and AI artworks, and more recent examples made with Large Language Models and GAN-based generation. It concludes with a discussion of the primacy of text as an entry point to the possibilities of creative AI.	[Twomey, Robert] Univ Nebraska Lincoln, Johnny Carson Ctr Emerging Media Arts, Lincoln, NE 68588 USA	University of Nebraska System; University of Nebraska Lincoln	Twomey, R (corresponding author), Univ Nebraska Lincoln, Johnny Carson Ctr Emerging Media Arts, Lincoln, NE 68588 USA.	rtwomey@unl.edu		Twomey, Robert/0000-0002-9663-0706				Allado-McDowell K., 2021, PHARMAKO AI; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 1928, Robert Desnos; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Breton Andre., 1969, Manifestoes of Surrealism; Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]; Chaudhary Jatin, 2020, THE SPRINGBOARD; Cohen Harold, 2011, COLLABORATIONS MY OT; Cohen Harold, SIGGRAPH 2014 DISTIN; Cohen Harold, 2004, PUBLIC LECT; Coleman Patrick, 2020, RIDING RACEHORSE FIE; Dryhurst Mat, PHARMAKO AI COWRITIN; Fagon Jason, 2021, SAN FRANCISCO CHRONI; Howard R. A., 1960, Dynamic programming and markov processes; Karras T, 2021, Arxiv, DOI [arXiv:2106.12423, DOI 10.48550/ARXIV.2106.12423]; Lund Jonas, 2013, FEAR MISSING OUT; Newton C., 2016, The Verge; Oxford Languages via Google, COMM; Radford A, 2021, PR MACH LEARN RES, V139; Reben Alex, 2021, AM; Replika.replika.com, ABOUOT US; Romney Jonathan, 2009, INDEPENDENT; Twomey Robert, 2021, 3 STAGE DRAWING TRAN; Twomey Robert, 2005, MEGAHAL GRANDMOMMY; Twomey Robert, 2009, NOT ME COLLABORATION; Twomey Robert, 2018, THESIS; Twomey Robert, 2021, CLASSIFICATION MACHI; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991	28	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2577-6193		P ACM COMPUT GRAPH	P. ACM Comput. Graph. Interact. Tech.	AUG	2023	6	2							28	10.1145/3597633	http://dx.doi.org/10.1145/3597633			7	Computer Science, Software Engineering	Emerging Sources Citation Index (ESCI)	Computer Science	Q3DK5					2024-07-03	WOS:001056350400013
J	Aldrin, JC				Aldrin, John C.			BENEFITS AND CONCERNS of Using Emerging Artificial Intelligence Chatbots With Work in NDT	MATERIALS EVALUATION			English	Article								While most of the papers in this special issue explore the use of artificial intelligence and machine learning (AI/ML) to support the evaluation of nondestructive testing (NDT) data and assist with the classification of NDT indications, there are other important ways that emerging AI tools may impact how we work in NDT. The article discusses the recent emergence of AI chatbots, also referred to as generative artificial intelligence agents or large language models (LLMs), and highlights the potential benefits and risks as part of work in the NDT field.	[Aldrin, John C.] Computat Tools, Gurnee, IL 60031 USA		Aldrin, JC (corresponding author), Computat Tools, Gurnee, IL 60031 USA.	aldrin@computationaltools.com						Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Bisle W., 2023, NDT.net forum. 29 January; DelSignore P., 2023, Medium; Kim SG, 2023, MAX PLAST RECONSTR S, V45, DOI 10.1186/s40902-023-00381-x; Klein E., 2023, The New York Times. 16 April; Lindgren E, 2023, MATER EVAL, V81, P35, DOI 10.32548/2023.me-04364; Metz C., 2023, The New York Times. 14 March; Molla R., 2023, Vox. 10 April; Ross J, 2023, MATER EVAL, V81, P7; Singh R., 2023, Materials Evaluation, V81, P17; Singh R, 2021, J NONDESTRUCT EVAL, V40, DOI 10.1007/s10921-021-00808-3; Timothy M., 2023, MUO. 20 March; Vrana J, 2023, MATER EVAL, V81, P17; Wolfram Stephen, 2023, Stephen Wolfram Writings February 14; Yang Hong, 2023, Nature, DOI 10.1038/d41586-023-01026-9	15	0	0	4	4	AMER SOC NONDESTRUCTIVE TEST	COLUMBUS	1711 ARLINGATE LANE PO BOX 28518, COLUMBUS, OH 43228-0518 USA	0025-5327			MATER EVAL	Mater. Eval.	JUL	2023	81	7					28	34		10.32548/2023.me-04361	http://dx.doi.org/10.32548/2023.me-04361			7	Materials Science, Characterization & Testing	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science	KH1V3					2024-07-03	WOS:001178984600004
J	Shyr, C; Hu, Y; Bastarache, L; Cheng, AL; Hamid, R; Harris, P; Xu, H				Shyr, Cathy; Hu, Yan; Bastarache, Lisa; Cheng, Alex; Hamid, Rizwan; Harris, Paul; Xu, Hua			Identifying and Extracting Rare Diseases and Their Phenotypes with Large Language Models	JOURNAL OF HEALTHCARE INFORMATICS RESEARCH			English	Article						Natural language processing; ChatGPT; Rare disease; Artificial intelligence; Prompt learning; Large language model		PurposePhenotyping is critical for informing rare disease diagnosis and treatment, but disease phenotypes are often embedded in unstructured text. While natural language processing (NLP) can automate extraction, a major bottleneck is developing annotated corpora. Recently, prompt learning with large language models (LLMs) has been shown to lead to generalizable results without any (zero-shot) or few annotated samples (few-shot), but none have explored this for rare diseases. Our work is the first to study prompt learning for identifying and extracting rare disease phenotypes in the zero- and few-shot settings.MethodsWe compared the performance of prompt learning with ChatGPT and fine-tuning with BioClinicalBERT. We engineered novel prompts for ChatGPT to identify and extract rare diseases and their phenotypes (e.g., diseases, symptoms, and signs), established a benchmark for evaluating its performance, and conducted an in-depth error analysis.ResultsOverall, fine-tuning BioClinicalBERT resulted in higher performance (F1 of 0.689) than ChatGPT (F1 of 0.472 and 0.610 in the zero- and few-shot settings, respectively). However, ChatGPT achieved higher accuracy for rare diseases and signs in the one-shot setting (F1 of 0.778 and 0.725). Conversational, sentence-based prompts generally achieved higher accuracy than structured lists.ConclusionPrompt learning using ChatGPT has the potential to match or outperform fine-tuning BioClinicalBERT at extracting rare diseases and signs with just one annotated sample. Given its accessibility, ChatGPT could be leveraged to extract these entities without relying on a large, annotated corpus. While LLMs can support rare disease phenotyping, researchers should critically evaluate model outputs to ensure phenotyping accuracy.	[Shyr, Cathy; Bastarache, Lisa; Cheng, Alex; Harris, Paul] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN 37203 USA; [Hu, Yan] Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, Houston, TX 77225 USA; [Hamid, Rizwan] Vanderbilt Univ, Med Ctr, Div Med Genet & Genom Med, Nashville, TN 37203 USA; [Harris, Paul] Vanderbilt Univ, Med Ctr, Dept Biostat, Nashville, TN 37203 USA; [Harris, Paul] Vanderbilt Univ, Med Ctr, Dept Biomed Engn, 2525 West End Ave, Nashville, TN 37203 USA; [Xu, Hua] Yale Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St, New Haven, CT 06510 USA	Vanderbilt University; University of Texas System; University of Texas Health Science Center Houston; Vanderbilt University; Vanderbilt University; Vanderbilt University; Yale University	Harris, P (corresponding author), Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN 37203 USA.; Harris, P (corresponding author), Vanderbilt Univ, Med Ctr, Dept Biomed Engn, 2525 West End Ave, Nashville, TN 37203 USA.; Xu, H (corresponding author), Yale Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St, New Haven, CT 06510 USA.	cathy.shyr@vumc.org; yan.hu@uth.tmc.edu; lisa.bastarache@vumc.org; a.cheng@vumc.org; rizwan.hamid@vumc.org; paul.a.harris@vumc.org; hua.xu@yale.edu	Hu, Yan/KFQ-7370-2024	Shyr, Cathy/0000-0001-7466-0034	National Library of Medicine of the National Institutes of Health [1K99LM014429-01]	National Library of Medicine of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	Cathy Shyr was supported by the National Library of Medicine of the National Institutes of Health under Award Number 1K99LM014429-01.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Ahmad FS, 2020, CIRC CARDIO QUAL OUT, V13; Alsentzer E., 2019, arXiv; Carmichael N, 2015, J GENET COUNS, V24, P325, DOI 10.1007/s10897-014-9773-9; Chapman M, 2021, STUD HEALTH TECHNOL, V281, P560, DOI 10.3233/SHTI210233; Chen Q, 2023, ARXIV; Chung CCY, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1028545; Cohen JS, 2010, AM J MED GENET A, V152A, P1136, DOI 10.1002/ajmg.a.33380; Cui L, 2021, ARXIV; Davis MF, 2013, J AM MED INFORM ASSN, V20, pE334, DOI 10.1136/amiajnl-2013-001999; Deisseroth CA, 2019, GENET MED, V21, P1585, DOI 10.1038/s41436-018-0381-1; Devlin J., 2018, BERT PRE TRAINING DE; Fabregat H, 2018, COMPUT METH PROG BIO, V164, P121, DOI 10.1016/j.cmpb.2018.07.007; Gutierrez BJ., 2022, ARXIV; Hu Y., 2023, ARXIV; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Lee P., 2023, The AI Revolution in Medicine: GPT-4 and Beyond; Lo Barco T, 2021, EPILEPSIA, V62, P220, DOI 10.1186/s13023-021-01936-9; Ma R, 2021, ARXIV; Macnamara Ellen F, 2020, Transl Sci Rare Dis, V4, P179, DOI 10.3233/TRD-190045; Martínez-deMiguel C, 2022, J BIOMED INFORM, V125, DOI 10.1016/j.jbi.2021.103961; Mehnen L, 2023, CHATGPT MED DOCTOR D, P2023; Nigwekar SU, 2014, J GEN INTERN MED, V29, pS924, DOI 10.1007/s11606-014-2910-1; OpenAI, 2022, OPENAI INTR CHATGPT; Segura-Bedmar I, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04810-y; Stenetorp P, 2012, P DEM 13 C EUR CHAPT, P102, DOI DOI 10.5555/2380921.2380942; Taylor N, 2022, ARXIV; Tifft CJ, 2014, CURR OPIN PEDIATR, V26, P626, DOI 10.1097/MOP.0000000000000155; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wakap SN, 2020, EUR J HUM GENET, V28, P165, DOI 10.1038/s41431-019-0508-0; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Yang G, 2022, ORPHANET J RARE DIS, V17, DOI 10.1186/s13023-022-02299-5	32	0	0	12	12	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2509-4971	2509-498X		J HEALTHC INFORM RES	J. Healthc. Inform. Res.	JUN	2024	8	2					438	461		10.1007/s41666-023-00155-0	http://dx.doi.org/10.1007/s41666-023-00155-0		JAN 2024	24	Computer Science, Information Systems; Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Computer Science; Health Care Sciences & Services; Medical Informatics	OU1Y4	38681753	Green Published, hybrid, Green Submitted			2024-07-03	WOS:001136942300001
J	Parker, MJ; Anderson, C; Stone, C; Oh, Y				Parker, Michael J.; Anderson, Caitlin; Stone, Claire; Oh, Yearim			A Large Language Model Approach to Educational Survey Feedback Analysis	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article; Early Access						Large language model; Survey analysis; GPT-4; GPT-3.5; ChatGPT; Qualitative methodology	STUDENT-EVALUATIONS; SENTIMENT ANALYSIS; ONLINE	This paper assesses the potential for the large language models (LLMs) GPT-4 and GPT-3.5 to aid in deriving insight from education feedback surveys. Exploration of LLM use cases in education has focused on teaching and learning, with less exploration of capabilities in education feedback analysis. Survey analysis in education involves goals such as finding gaps in curricula or evaluating teachers, often requiring time-consuming manual processing of textual responses. LLMs have the potential to provide a flexible means of achieving these goals without specialized machine learning models or fine-tuning. We demonstrate a versatile approach to such goals by treating them as sequences of natural language processing (NLP) tasks including classification (multi-label, multi-class, and binary), extraction, thematic analysis, and sentiment analysis, each performed by LLM. We apply these workflows to a real-world dataset of 2500 end-of-course survey comments from biomedical science courses, and evaluate a zero-shot approach (i.e., requiring no examples or labeled training data) across all tasks, reflecting education settings, where labeled data is often scarce. By applying effective prompting practices, we achieve human-level performance on multiple tasks with GPT-4, enabling workflows necessary to achieve typical goals. We also show the potential of inspecting LLMs' chain-of-thought (CoT) reasoning for providing insight that may foster confidence in practice. Moreover, this study features development of a versatile set of classification categories, suitable for various course types (online, hybrid, or in-person) and amenable to customization. Our results suggest that LLMs can be used to derive a range of insights from survey text.	[Parker, Michael J.; Anderson, Caitlin] Harvard Med Sch, HMX, Off Online Learning, 4 Blackfan Circle, Boston, MA 02115 USA; [Stone, Claire; Oh, Yearim] Harvard Med Sch, Off External Educ, Boston, MA USA	Harvard University; Harvard Medical School; Harvard University; Harvard Medical School	Parker, MJ (corresponding author), Harvard Med Sch, HMX, Off Online Learning, 4 Blackfan Circle, Boston, MA 02115 USA.	michael_parker@hms.harvard.edu; caitlin_anderson@hms.harvard.edu; claire_stone@hms.harvard.edu; yearim_oh@hms.harvard.edu						Abdali S, 2023, Arxiv, DOI arXiv:2312.06820; Aldeman M., 2021, 2021 ASEE VIRT ANN C; Alhija FN-A., 2009, Studies in Educational Evaluation, V35, P37, DOI DOI 10.1016/J.STUEDUC.2009.01.002; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brennan J., 2004, Collecting and Using Student Feedback: A guide to Good Practice; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Cunningham-Nelson S, 2019, IEEE T EDUC, V62, P305, DOI 10.1109/TE.2019.2924385; Deepa D., 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P786, DOI 10.1109/I-SMAC47947.2019.9032456; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Diaz NP., 2022, International Journal of Teaching Learning in Higher Education, V33, P285; Dommeyer C.J., 2004, Assessment Evaluation in Higher Education, V29, P611, DOI [DOI 10.1080/02602930410001689171, 10.1080/02602930410001689171]; Edalati M., 2022, Intelligent Systems and Applications, P11, DOI [DOI 10.1007/978-3-030-82199-9_2, 10.1007/978-3-030-82199-92, DOI 10.1007/978-3-030-82199-92]; Fan X., 2015, P 33 ANN ACM C HUM F, P1473, DOI DOI 10.1145/2702613.2732853; Ferren A.S., 2001, New Directions for Institutional Research, V2001, P67, DOI DOI 10.1002/IR.29; Flodén J, 2017, ASSESS EVAL HIGH EDU, V42, P1054, DOI 10.1080/02602938.2016.1224997; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Gostautaite D, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115396; Gottipati Swapna, 2018, Res Pract Technol Enhanc Learn, V13, P6, DOI 10.1186/s41039-018-0073-0; Gottipati S, 2017, PROC FRONT EDUC CONF; Hamzah Almed, 2020, International Journal of Interactive Mobile Technologies, V14, P4, DOI 10.3991/ijim.v14i09.11069; Hassija V, 2024, COGN COMPUT, V16, P45, DOI 10.1007/s12559-023-10179-8; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; huggingface, Hugging Face: The AI community building the future; huggingface, 2022, cardiffnlp/twitter-roberta-base-sentiment-latest; Jansen B J., 2023, Natural Language Processing Journal, P100020, DOI DOI 10.1016/J.NLP.2023.100020; Johnson JM, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0192-5; Johnson R. B., 2004, Educational Researcher, V33, P14, DOI DOI 10.3102/0013189X033007014; Kane T.J., 2013, HAVE WE IDENTIFIED E; Kastrati Zenun, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P510, DOI 10.1145/3404555.3404633; Kastrati Z, 2020, IEEE ACCESS, V8, P106799, DOI 10.1109/ACCESS.2020.3000739; Kennedy RKL, 2024, J BIG DATA-GER, V11, DOI 10.1186/s40537-024-00897-7; Kiciman E, 2023, Arxiv, DOI arXiv:2305.00050; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lattuca L.R., 2007, NEW DIRECTIONS I RES, V136, P81, DOI [10.1002/ir.233, DOI 10.1002/IR.233]; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Loureiro D., 2022, arXiv; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Marginson S., 2000, The enterprise university: Power, governance and reinvention in Australia; Marks A, 2017, INT J EMERG TECHNOL, V12, P4, DOI [10.3991/ijet.v12.i11.6987, 10.3991/ijet.v12i11.6987]; MARSH HW, 1993, AM EDUC RES J, V30, P217, DOI 10.3102/00028312030001217; Masala M, 2021, LECT NOTES ARTIF INT, V12748, P282, DOI 10.1007/978-3-030-78292-4_23; Mattimoe R., 2021, Accounting, Finance, Governance Review, V27, P54, DOI DOI 10.52399/001C.22026; Mazzarol T., 2003, INT J ED MANAGEMENT, V17, P90, DOI DOI 10.1108/09513540310467778; McGourty J., 2002, 42 ANN FOR ASS I RES; McKeachie WJ, 1997, AM PSYCHOL, V52, P1218, DOI 10.1037/0003-066X.52.11.1218; Medina MS, 2019, AM J PHARM EDUC, V83, DOI 10.5688/ajpe7177; Meidinger M, 2021, ICAART: PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE - VOL 2, P866, DOI 10.5220/0010255108660873; Mentkowski M., 1991, J GEN EDUC, V40, P255; Morbidoni C., 2023, P 15 BIANN C IT SIGC, P1, DOI [10.1145/3605390.3610810, DOI 10.1145/3605390.3610810]; Moss J, 2002, BRIT J EDUC TECHNOL, V33, P583, DOI 10.1111/1467-8535.00293; Nanda G, 2021, IEEE T LEARN TECHNOL, V14, P146, DOI 10.1109/TLT.2021.3064798; Nitin GI, 2015, PROC FRONT EDUC CONF, P1658; Onan A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5909; Onan A, 2021, COMPUT APPL ENG EDUC, V29, P572, DOI 10.1002/cae.22253; Orescanin M, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1213419; Pangakis N, 2023, Arxiv, DOI arXiv:2306.00176; paperswithcode, Papers with Code-Machine Learning Datasets; Patil Pratik P., 2019, Proceedings of the 2nd International Conference on Data Engineering and Communication Technology (ICDECT 2017). Advances in Intelligent Systems and Computing (AISC 828), P221, DOI 10.1007/978-981-13-1610-4_23; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Perez-Encinas A, 2018, J STUD INT EDUC, V22, P20, DOI 10.1177/1028315317724556; Pradhan VK, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.828187; Pyasi S, 2018, PROC FRONT EDUC CONF; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Richardson J.T.E., 2005, Assessment and Evaluation in Higher Education, V30, P387, DOI [10.1080/02602930500099193, DOI 10.1080/02602930500099193]; Riger S., 2016, Handbook of methodological approaches to community-based research: Qualitative, quantitative, and mixed methods, P33, DOI [10.1093/med:psych/9780190243654.003.0004, DOI 10.1093/MED:PSYCH/9780190243654.003.0004]; Rother A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254764; Schreiner M., 2023, GPT-4 architecture, datasets, costs and more leaked; Schulz J., 2014, BELLWETHER ED PARTNE; Shah M., 2023, Imbalanced data in machine learning: A comprehensive review, DOI [10.13140/RG.2.2.18456.98564, DOI 10.13140/RG.2.2.18456.98564]; Shah M, 2020, J APPL RES HIGH EDUC, V12, P194, DOI 10.1108/JARHE-02-2019-0030; Shaik T, 2023, Arxiv, DOI arXiv:2302.04359; Shaik T, 2022, IEEE ACCESS, V10, P56720, DOI 10.1109/ACCESS.2022.3177752; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Sindhu I, 2019, IEEE ACCESS, V7, P108729, DOI 10.1109/ACCESS.2019.2928872; Smith AE, 2006, BEHAV RES METHODS, V38, P262, DOI 10.3758/BF03192778; Spooren P, 2013, REV EDUC RES, V83, P598, DOI 10.3102/0034654313496870; Stowell JR, 2012, ASSESS EVAL HIGH EDU, V37, P465, DOI 10.1080/02602938.2010.545869; Sunar AS, 2024, IEEE T LEARN TECHNOL, V17, P741, DOI 10.1109/TLT.2023.3330531; Sutoyo Edi, 2021, International Conference on Emerging Applications and Technologies for Industry 4.0 (EATI'2020): Emerging Applications and Technologies for Industry 4.0. Lecture Notes in Networks and Systems (254), P272, DOI 10.1007/978-3-030-80216-5_20; Törnberg P, 2023, Arxiv, DOI arXiv:2304.06588; Tunstall L, 2022, Arxiv, DOI [arXiv:2209.11055, 10.48550/arXiv.2209.11055, DOI 10.48550/ARXIV.2209.11055]; UC Berkeley Center for Teaching & Learning, Course evaluations question bank; Unankard S., 2020, Emerging Technologies for Education, P133, DOI [10.1007/978-3-030-38778-516, DOI 10.1007/978-3-030-38778-516]; University of Wisconsin-Madison, Student learning assessment; Veselovsky V, 2023, Arxiv, DOI [arXiv:2306.07899, 10.48550/arXiv.2306.07899, DOI 10.48550/ARXIV.2306.07899]; Wallace S.L., 2019, College Teaching, V67, P1, DOI [DOI 10.1080/87567555.2018.1483317, 10.1080/87567555.2018.1483317]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weng L., 2023, Lil'Log; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wongsurawat W, 2011, QUAL ASSUR EDUC, V19, P67, DOI 10.1108/09684881111107762; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang HB, 2020, INT J ARTIF INTELL T, V29, DOI 10.1142/S0218213020400187	97	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	2024 JUN 25	2024										10.1007/s40593-024-00414-0	http://dx.doi.org/10.1007/s40593-024-00414-0		JUN 2024	38	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	WH6F8		hybrid			2024-07-03	WOS:001254011100002
C	Liu, MQ; M'hiri, F			Assoc Computing Machinery	Liu, Mengqi; M'hiri, Faten			Beyond Traditional Teaching: Large Language Models as Simulated Teaching Assistants in Computer Science	PROCEEDINGS OF THE 55TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, SIGCSE 2024, VOL. 1			English	Proceedings Paper	55th ACM Technical Symposium on Computer Science Education (SIGCSE)	MAR 20-23, 2024	Portland, OR	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		CS education; GPT; ChatGPT; LLM; machine learning; novice programmers; OpenAI; Programming; adaptive teaching		As the prominence of Large Language Models (LLMs) grows in various sectors, their potential in education warrants exploration. In this study, we investigate the feasibility of employing GPT-3.5 from OpenAI, as an LLM teaching assistant (TA) or a virtual TA in computer science (CS) courses. The objective is to enhance the accessibility of CS education while maintaining academic integrity by refraining from providing direct solutions to current-semester assignments. Targeting Foundations of Programming (COMP202), an undergraduate course that introduces students to programming with Python, we have developed a virtual TA using the LangChain framework, known for integrating language models with diverse data sources and environments. The virtual TA assists students with their code and clarifies complex concepts. For homework questions, it is designed to guide students with hints rather than giving out direct solutions. We assessed its performance first through a qualitative evaluation, then a survey-based comparative analysis, using a mix of questions commonly asked on the COMP202 discussion board and questions created by the authors. Our preliminary results indicate that the virtual TA outperforms human TAs on clarity and engagement, matching them on accuracy when the question is non-assignment-specific, for which human TAs still proved more reliable. These findings suggest that while virtual TAs, leveraging the capabilities of LLMs, hold great promise towards making CS education experience more accessible and engaging, their optimal use necessitates human supervision. We conclude by identifying several directions that could be explored in future implementations.	[Liu, Mengqi; M'hiri, Faten] McGill Univ, Dept Comp Sci, Montreal, PQ, Canada	McGill University	M'hiri, F (corresponding author), McGill Univ, Dept Comp Sci, Montreal, PQ, Canada.	mengqi.liu2@mail.mcgill.ca; faten.mhiri@mcgill.ca						Borisov V, 2023, Arxiv, DOI [arXiv:2210.06280, 10.48550/arXiv.2210.06280]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chase H., 2022, Langchain; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Geng CQ, 2023, Arxiv, DOI arXiv:2305.02230; Hamid R. D., 2023, CS50 will integrate artificial intelligence into course instruction: News: The Harvard Crimson; Haque M.U., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.05856; Ho N, 2023, Arxiv, DOI arXiv:2212.10071; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Mogavi RH, 2023, Arxiv, DOI arXiv:2305.13114; OpenAI, 2023, GPT 4 TECHNICAL REPO; Qureshi B, 2023, Arxiv, DOI arXiv:2304.11214; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30	17	0	0	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0423-9				2024							743	749		10.1145/3626252.3630789	http://dx.doi.org/10.1145/3626252.3630789			7	Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Education & Educational Research	BW6SP					2024-07-03	WOS:001181240800109
J	Smirnov, EA				Smirnov, Evgeny A.			Fast, Simple, and Accurate Time Series Analysis with Large Language Models: An Example of Mean-motion Resonances Identification	ASTROPHYSICAL JOURNAL			English	Article							ASTEROIDS; STABILITY	Classical machine learning has been actively utilized in astronomy to address various challenges, including predicting orbital stability, classifying asteroids, galaxies, and other objects, and analyzing images. However, the emerging trend in artificial intelligence involves the use of large language models such as GPT-4 and ChatGPT. These models are trained on a large corpus of text and can perform a wide range of natural language processing tasks, including text generation, translation, summarization, and classification. Surprisingly, these capabilities present significant potential for application in astronomy. This paper demonstrates how the new model gpt-4-vision-preview can analyze visual patterns and accurately classify asteroids as resonant or nonresonant with high accuracy. This process requires no training, fine-tuning, or coding beyond writing the appropriate prompt in natural language. Moreover, this approach can be extended to other common problems within astronomy.	[Smirnov, Evgeny A.] Belgrade Astron Observ, Volgina 7, Belgrade 11000, Serbia		Smirnov, EA (corresponding author), Belgrade Astron Observ, Volgina 7, Belgrade 11000, Serbia.	smirik@gmail.com	Smirnov, Evgeny A/AAJ-2384-2021	Smirnov, Evgeny A/0000-0001-8264-8668				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Baron D, 2017, MON NOT R ASTRON SOC, V465, P4530, DOI 10.1093/mnras/stw3021; Carruba V, 2022, CELEST MECH DYN ASTR, V134, DOI 10.1007/s10569-022-10088-2; Carruba V, 2021, MON NOT R ASTRON SOC, V504, P692, DOI 10.1093/mnras/stab914; Carruba V, 2021, CELEST MECH DYN ASTR, V133, DOI 10.1007/s10569-021-10021-z; Carruba V, 2020, MON NOT R ASTRON SOC, V496, P540, DOI 10.1093/mnras/staa1463; Chao Liu, 2021, Monthly Notices of the Royal Astronomical Society, V502, P5362, DOI 10.1093/mnras/stab080; Lam C, 2018, MON NOT R ASTRON SOC, V476, P5692, DOI 10.1093/mnras/sty022; Lin HW, 2018, PUBL ASTRON SOC JPN, V70, DOI 10.1093/pasj/psx082; LOMB NR, 1976, ASTROPHYS SPACE SCI, V39, P447, DOI 10.1007/BF00648343; Malik A, 2022, MON NOT R ASTRON SOC, V513, P5505, DOI 10.1093/mnras/stab3692; Miao N, 2023, Arxiv, DOI arXiv:2308.00436; Minaee S, 2024, Arxiv, DOI [arXiv:2402.06196, 10.48550/arXiv.2402.06196]; Nesvorny D, 1998, ASTRON J, V116, P3029, DOI 10.1086/300632; OpenAI, 2024, ChatGPT Technical Report; Rawte V, 2023, Arxiv, DOI arXiv:2309.05922; SCARGLE JD, 1982, ASTROPHYS J, V263, P835, DOI 10.1086/160554; Shi F., 2023, 40 INT C MACH LEARN, P31210; Shridhar K, 2023, Arxiv, DOI arXiv:2311.07961; Smirnov E., 2024, Zenodo, DOI [10.5281/zenodo.1091158110.5281/zenodo.10911581, DOI 10.5281/ZENODO.1091158110.5281/ZENODO.10911581]; Smirnov EA, 2023, ASTRON COMPUT, V43, DOI 10.1016/j.ascom.2023.100707; Smirnov EA, 2018, SOLAR SYST RES+, V52, P347, DOI 10.1134/S0038094618040056; Smirnov EA, 2017, MON NOT R ASTRON SOC, V469, P2024, DOI 10.1093/mnras/stx999; Smirnov EA, 2013, ICARUS, V222, P220, DOI 10.1016/j.icarus.2012.10.034; Smullen RA, 2020, MON NOT R ASTRON SOC, V497, P1391, DOI 10.1093/mnras/staa1935; Tamayo D, 2020, P NATL ACAD SCI USA, V117, P18194, DOI 10.1073/pnas.2001258117; Xu XH, 2024, Arxiv, DOI arXiv:2309.06275; Zechmeister M, 2009, ASTRON ASTROPHYS, V496, P577, DOI 10.1051/0004-6361:200811296; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	29	0	0	5	5	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0004-637X	1538-4357		ASTROPHYS J	Astrophys. J.	MAY 1	2024	966	2							220	10.3847/1538-4357/ad3ae1	http://dx.doi.org/10.3847/1538-4357/ad3ae1			6	Astronomy & Astrophysics	Science Citation Index Expanded (SCI-EXPANDED)	Astronomy & Astrophysics	QC7N4		gold			2024-07-03	WOS:001218746200001
J	Pan, ZY; Fan, KJ; Liu, RY; Li, DF				Pan, Ziyang; Fan, Kangjia; Liu, Rongyu; Li, Daifeng			Towards Robust Neural Rankers with Large Language Model: A Contrastive Training Approach	APPLIED SCIENCES-BASEL			English	Article						contrastive learning; neural rankers; robustness; large language model		Pre-trained language model-based neural rankers have been widely applied in information retrieval (IR). However, the robustness issue of current IR models has not received sufficient attention, which could significantly impact the user experience in practical applications. In this study, we focus on the defensive ability of IR models against query attacks while guaranteeing their retrieval performance. We discover that improving the robustness of IR models not only requires a focus on model architecture and training methods but is also closely related to the quality of data. Different from previous research, we use large language models (LLMs) to generate query variations with the same intent, which exhibit richer and more realistic expressions while maintaining consistent query intent. Based on LLM-generated query variations, we propose a novel contrastive training framework that substantially enhances the robustness of IR models to query perturbations. Specifically, we combine the contrastive loss in the representation space of query variations with the ranking loss in the retrieval training stage to improve the model's ability to understand the underlying semantic information of queries. Experimental results on two public datasets, WikiQA and ANTIQUE, demonstrate that the proposed contrastive training approach effectively improves the robustness of models facing query attack scenarios while outperforming baselines in retrieval performance. Compared with the best baseline approach, the improvements in average robustness performance of Reranker IR models are 24.9%, 26.5%, 27.0%, and 75.0% on WikiQA and 8.7%, 1.9%, 6.3%, and 13.6% on ANTIQUE, in terms of the MAP (Mean Average Precision), MRR (Mean Reciprocal Rank), nDCG@10 (Normalized Discounted Cumulative Gain) and P@10 (Precision), respectively.	[Pan, Ziyang; Fan, Kangjia; Liu, Rongyu; Li, Daifeng] Sun Yat sen Univ, Sch Informat Management, Guangzhou 510275, Peoples R China	Sun Yat Sen University	Li, DF (corresponding author), Sun Yat sen Univ, Sch Informat Management, Guangzhou 510275, Peoples R China.	lidaifeng@mail.sysu.edu.cn		Liu, Rongyu/0009-0003-0447-0835	National Natural Science Foundation of China (NSFC) [72074231]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC))	This research was supported by the National Natural Science Foundation of China (NSFC)under grant no. 72074231.	[Anonymous], 2023, BAAI Bge-Large-En; [Anonymous], 2023, BAAI Bge-Base-En; [Anonymous], OpenAI Introducing ChatGPT; [Anonymous], 2016, P C EMPIRICAL METHOD, DOI DOI 10.18653/V1/D16-1063; Arslan A, 2019, INFORM RETRIEVAL J, V22, P543, DOI 10.1007/s10791-018-9347-9; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Burges C., 2006, Proceedings of the Advances in Neural Information Processing Systems, V19; Burges C., 2005, INT C MACH LEARN ICM, P89, DOI DOI 10.1145/1102351.1102363; Cao Z., 2007, P 24 INT C MACH LEAR, P129, DOI DOI 10.1145/1273496.1273513; Cheng P., 2021, P 9 INT C LEARNING R; Cho Bv, 2014, ARXIV14061078, P1724, DOI 10.3115/v1/d14-1179; Crammer K., 2001, Proceedings of the Advances in Neural Information Processing Systems, VVolume 14; Deng Yang, 2021, P 7 WORKSH NOIS US G, P175, DOI DOI 10.18653/V1/2021.WNUT-1.20; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fan A, 2021, J MACH LEARN RES, V22; Fan YX, 2022, FOUND TRENDS INF RET, V16, P178, DOI 10.1561/1500000100; Reddy RG, 2021, Arxiv, DOI arXiv:2104.07800; Guo JF, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P55, DOI 10.1145/2983323.2983769; Hashemi Helia, 2020, Advances in Information Retrieval. 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12036), P166, DOI 10.1007/978-3-030-45442-5_21; He KM, 2020, Arxiv, DOI arXiv:1911.05722; Izacard G, 2022, Arxiv, DOI [arXiv:2112.09118, DOI 10.48550/ARXIV.2112.09118]; Joachims T., 2002, P 8 ACM SIGKDD INT C, P133; Jun Xu, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P391; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Lavrenko Victor, 2001, P 24 ANN INT ACM SIG, P120, DOI DOI 10.1145/383952.383972; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li JF, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23138; Li ZH, 2023, Arxiv, DOI arXiv:2308.03281; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Luyu Gao, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P280, DOI 10.1007/978-3-030-72240-1_26; Luyu Gao, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12656), P146, DOI 10.1007/978-3-030-72113-8_10; MacAvaney S, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P845, DOI 10.1145/3336191.3371864; MacDonald Craig, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P161, DOI 10.1145/3409256.3409829; Madry Aleksander, 2018, INT C LEARN REPR; Muennighoff N., 2023, P 17 C EUROPEAN CHAP, P2014; Otegi A, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108072; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Penha G, 2022, LECT NOTES COMPUT SC, V13185, P397, DOI 10.1007/978-3-030-99736-6_27; Prakash P, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1728, DOI 10.1145/3404835.3463106; Qu Y., 2021, P 9 INT C LEARNING R; Raffel C, 2020, J MACH LEARN RES, V21; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Rendle S., 2012, Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009), DOI [DOI 10.5555/1795114.1795167, 10.48550/arXiv.1205.2618]; Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232; Shan YH, 2020, INT J MACH LEARN CYB, V11, P1825, DOI 10.1007/s13042-020-01074-x; Shashua A., 2002, Proceedings of the Advances in Neural Information Processing Systems, VVolume 15; Sidiropoulos G, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2132, DOI 10.1145/3477495.3531818; Su H., 2023, FINDINGS ASS COMPUTA, P1102; Ulukus S, 2022, IEEE J SEL AREA COMM, V40, P729, DOI 10.1109/JSAC.2022.3142358; Wang HZ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2658, DOI 10.1145/3404835.3462810; Wang JD, 2023, Arxiv, DOI [arXiv:2302.12095, 10.48550/arXiv.2302.12095]; Wu C, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3534928; Wu QA, 2010, INFORM RETRIEVAL, V13, P254, DOI 10.1007/s10791-009-9112-1; Morris JX, 2020, Arxiv, DOI arXiv:2005.05909; Xiong CY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P55, DOI 10.1145/3077136.3080809; Xiong W., 2021, P INT C LEARNING REP; Zhang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1601; Yang Y., 2015, P 2015 C EMPIRICAL M, P2013, DOI [DOI 10.18653/V1, 10.18653/v1/D15-1237, 10.18653/v1/d15-1237, DOI 10.18653/V1/D15-1237]; Yizhi Li, 2021, ICTIR '21: Proceedings of the 2021 ACM SIGIR International Conference on Theory of Information Retrieval, P287, DOI 10.1145/3471158.3472245; Zhang WE, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3374217; Zhuang SY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2836	63	0	0	4	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	SEP	2023	13	18							10148	10.3390/app131810148	http://dx.doi.org/10.3390/app131810148			19	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	FI3S2		gold			2024-07-03	WOS:001145099200001
C	Zhao, YL; Zhao, C; Nan, LY; Qi, ZT; Zhang, WL; Mi, BY; Tang, XR; Radev, D		Rogers, A; Boyd-Graber, J; Okazaki, N		Zhao, Yilun; Zhao, Chen; Nan, Linyong; Qi, Zhenting; Zhang, Wenlin; Mi, Boyu; Tang, Xiangru; Radev, Dragomir			ROBUT: A Systematic Study of Table QA Robustness Against Human-Annotated Adversarial Perturbations	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Despite significant progress having been made in question answering on tabular data (Table QA), it's unclear whether, and to what extent existing Table QA models are robust to taskspecific perturbations, e.g., replacing key question entities or shuffling table columns. To systematically study the robustness of Table QA models, we propose a benchmark called ROBUT, which builds upon existing Table QA datasets (WTQ, WIKISQL-WEAK, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question. Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets. We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models. Our data and code is publicly available at https: //github.com/yilunzhao/RobuT.	[Zhao, Yilun; Nan, Linyong; Tang, Xiangru; Radev, Dragomir] Yale Univ, New Haven, CT 06520 USA; [Zhao, Chen] NYU, New York, NY 10003 USA; [Qi, Zhenting; Zhang, Wenlin; Mi, Boyu] Zhejiang Univ, Hangzhou, Peoples R China	Yale University; New York University; Zhejiang University	Zhao, YL (corresponding author), Yale Univ, New Haven, CT 06520 USA.	yilun.zhao@yale.edu; cz1285@nyu.edu						Aly Rami, 2021, 35 C NEUR INF PROC S; Bach Stephen H., 2022, ARXIV220201279; Bartolo M, 2020, T ASSOC COMPUT LING, V8, P662, DOI 10.1162/tacl_a_00338; Chang Shuaichen, 2023, INT C LEARN REPR; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen W., 2020, P 58 ANN M ASS COMP, P7929, DOI DOI 10.18653/V1/2020.ACL-MAIN.708; Chen W., 2020, P ICLR; Chen Wenhu, 2022, LARGE LANGUAGE MODEL; Cheng ZJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1094; Cho Minseok, 2018, AS C MACH LEARN; Eisenschlos Julian, 2020, PROC EMNLP, P281; Gan YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2505; Goel K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P42; Guo JQ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2316; Gupta V, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3268; Gupta V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2309; Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320; Huang KH, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1022; Iyyer M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1821, DOI 10.18653/v1/P17-1167; Jia JY, 2021, ASIA CCS'21: PROCEEDINGS OF THE 2021 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2, DOI 10.1145/3433210.3437519; Jiang ZB, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P932; Le Scao Teven, 2022, ARXIV221105100; Lehmberg O, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P75, DOI 10.1145/2872518.2889386; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6193; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Pengfei, 2021, arXiv; Liu Qian, 2022, INT C LEARN REPR; Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470; Pi XY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2007; Scholak T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9895; Suhr A., 2020, P 58 ANN M ASS COMPU, P8372; Tsipras Dimitris, 2019, INT C LEARN REPR; Wang B., 2020, P 58 ANN M ASS COMPU, P7567; Wang LJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6923; Wang Tianlu, 2022, P FIND ASS COMP LING, P1719, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.130; Wang XZ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4569; Wei J., 2022, Emergent abilities of large language models; Wei Jason, 2022, Chain of thought prompting elicits reasoning in large language models; Yang JF, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P528; Yin Pengcheng, 2020, P 58 ANN M ASS COMPU, P8413, DOI [DOI 10.18653/V1/2020.ACL, 10.18653/v1/2020.acl-main.745, DOI 10.18653/V1/2020.ACL-MAIN.745]; Yu T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4511; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zeng JC, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P204; Zhang HY, 2019, PR MACH LEARN RES, V97; Zhang S., 2022, OPT: Open pre-trained transformer language models; Zhao C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5568; Zhao Y., 2022, P 2022 C EMPIRICAL M, P9006, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.615; Zhong V., 2017, ARXIV170900103; Zhu Yi, 2020, GENERATING SEMANTICA	50	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							6064	6081						18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086805004
J	Oniani, D; Hilsman, J; Zang, CX; Wang, JM; Cai, LJ; Zawala, J; Wang, YS				Oniani, David; Hilsman, Jordan; Zang, Chengxi; Wang, Junmei; Cai, Lianjin; Zawala, Jan; Wang, Yanshan			Emerging opportunities of using large language models for translation between drug molecules and indications	SCIENTIFIC REPORTS			English	Article						Computer science; Artificial intelligence; Large language models; Drug discovery	DISCOVERY; GRAPH	A drug molecule is a substance that changes an organism's mental or physical state. Every approved drug has an indication, which refers to the therapeutic use of that drug for treating a particular medical condition. While the Large Language Model (LLM), a generative Artificial Intelligence (AI) technique, has recently demonstrated effectiveness in translating between molecules and their textual descriptions, there remains a gap in research regarding their application in facilitating the translation between drug molecules and indications (which describes the disease, condition or symptoms for which the drug is used), or vice versa. Addressing this challenge could greatly benefit the drug discovery process. The capability of generating a drug from a given indication would allow for the discovery of drugs targeting specific diseases or targets and ultimately provide patients with better treatments. In this paper, we first propose a new task, the translation between drug molecules and corresponding indications, and then test existing LLMs on this new task. Specifically, we consider nine variations of the T5 LLM and evaluate them on two public datasets obtained from ChEMBL and DrugBank. Our experiments show the early results of using LLMs for this task and provide a perspective on the state-of-the-art. We also emphasize the current limitations and discuss future work that has the potential to improve the performance on this task. The creation of molecules from indications, or vice versa, will allow for more efficient targeting of diseases and significantly reduce the cost of drug discovery, with the potential to revolutionize the field of drug discovery in the era of generative AI.	[Oniani, David; Hilsman, Jordan; Wang, Yanshan] Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA; [Zang, Chengxi] Weill Cornell Med, Dept Populat Hlth Sci, New York, NY USA; [Zang, Chengxi] Weill Cornell Med, Inst Artificial Intelligence Digital Hlth, New York, NY USA; [Wang, Junmei; Cai, Lianjin] Univ Pittsburgh, Dept Pharmaceut Sci, Pittsburgh, PA USA; [Zawala, Jan] Polish Acad Sci, Jerzy Haber Inst Catalysis & Surface Chem, Krakow, Poland; [Wang, Yanshan] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15260 USA; [Wang, Yanshan] Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA; [Wang, Yanshan] Univ Pittsburgh, Clin & Translat Sci Inst, Pittsburgh, PA 15260 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Polish Academy of Sciences; Jerzy Haber Institute of Catalysis & Surface Chemistry; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Wang, YS (corresponding author), Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA 15260 USA.; Wang, YS (corresponding author), Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA 15260 USA.; Wang, YS (corresponding author), Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA.; Wang, YS (corresponding author), Univ Pittsburgh, Clin & Translat Sci Inst, Pittsburgh, PA 15260 USA.	yanshan.wang@pitt.edu		Zawala, Jan/0000-0003-4542-2226	National Science Foundation [2138259, 2138286, 2138307, 2137603, 2138296]	National Science Foundation(National Science Foundation (NSF))	This work used Bridges-2 at Pittsburgh Supercomputing Center through allocation from the Advanced Cyberinfrastructure Coordination Ecosystem: Services & Support (ACCESS) program, which is supported by National Science Foundation grants #2138259, #2138286, #2138307, #2137603, and #2138296.	Abbasian M, 2023, Arxiv, DOI arXiv:2309.12444; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adilov S., 2021, ChemRxiv, DOI [10.33774/chemrxiv-2021-5fwjd, DOI 10.33774/CHEMRXIV-2021-5FWJD]; Bagal V, 2022, J CHEM INF MODEL, V62, P2064, DOI 10.1021/acs.jcim.1c00600; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Capecchi A, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00445-4; Chithrananda S., 2020, Chemberta: Large-scale self-supervised pretraining for molecular property prediction; Chung JJY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P575; Davies M, 2015, NUCLEIC ACIDS RES, V43, pW612, DOI 10.1093/nar/gkv352; Decker S., 2007, Principles of Clinical Pharmacology, P439, DOI [10.1016/B978-012369417-1/50068-7, DOI 10.1016/B978-012369417-1/50068-7, 10.1016/B978- 012369417-1/50068-7]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Edwards C., 2022, P 2022 C EMPIRICAL M, P375; Edwards C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P595; Fabian B. etal, 2020, Machine Learning for Molecules; Ganea OE, 2021, ADV NEUR IN, V34; Gomez-Rodriguez C., 2023, Findings of the Association for Computational Linguistics: EMNLP 2023, 14504-14528, DOI [10.18653/v1/2023.findings-emnlp.966, DOI 10.18653/V1/2023.FINDINGS-EMNLP.966]; Gu A, 2024, Arxiv, DOI arXiv:2312.00752; Han XT, 2022, LIFE-BASEL, V12, DOI 10.3390/life12020319; Hu K., 2023, Reuters; Jaeger S, 2018, J CHEM INF MODEL, V58, P27, DOI 10.1021/acs.jcim.7b00616; Jiang AQ, 2024, Arxiv, DOI arXiv:2401.04088; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Lee N., 2022, Advances in Neural Information Processing Systems, V35, P34586; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin Chin-Yew, 2004, P 42 ANN M ASS COMPU, P605, DOI DOI 10.3115/1218955.1219032; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Liu Chia-Wei, 2016, P 2016 C EMPIRICAL M, P2122, DOI [DOI 10.18653/V1/D16-1230, 10.18653/v1/D16-1230]; Lu JY, 2022, J CHEM INF MODEL, V62, P1376, DOI 10.1021/acs.jcim.1c01467; Luo HM, 2024, ISCIENCE, V27, DOI 10.1016/j.isci.2024.109148; Lv QJ, 2024, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2024.3359657; Lv QJ, 2023, CHEM SCI, V14, P10684, DOI 10.1039/d3sc02139d; Lv QJ, 2023, NEURAL NETWORKS, V165, P94, DOI 10.1016/j.neunet.2023.05.039; Lv QJ, 2023, SIGNAL TRANSDUCT TAR, V8, DOI 10.1038/s41392-023-01339-1; Lv QJ, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3250324; Lv QJ, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab317; Mehta SS., 2008, Commercializing Successful Biomedical Technologies, DOI [10.1017/CBO9780511791345, DOI 10.1017/CBO9780511791345]; Méndez-Lucio O, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13807-w; Merk D, 2018, MOL INFORM, V37, DOI 10.1002/minf.201700153; Mikolov T, 2013, COMPUTING RES REPOSI; Miller F. P., 2009, Hamming Distance, DOI DOI 10.5555/1822502; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Moslem Y., 2023, P 24 ANN C EUROPEAN, P227; Mu Y., 2023, Findings of the Association for Computational Linguistics: ACL 2023, 10287-10299, Association for Computational Linguistics, DOI [DOI 10.18653/V1/2023.FINDINGS-ACL.653, 10.18653/v1/2023.findings-acl.653]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paul D, 2020, DRUG DISCOV TODAY, V26, P80, DOI 10.1016/j.drudis.2020.10.010; Porter J., 2023, Chatgpt continues to be one of the fastest-growing services ever; Preuer K, 2018, J CHEM INF MODEL, V58, P1736, DOI 10.1021/acs.jcim.8b00234; Raffel C, 2020, J MACH LEARN RES, V21; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Sadybekov AV, 2023, NATURE, V616, P673, DOI 10.1038/s41586-023-05905-z; Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232; Schneider N, 2015, J CHEM INF MODEL, V55, P2111, DOI 10.1021/acs.jcim.5b00543; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sterling T, 2015, J CHEM INF MODEL, V55, P2324, DOI 10.1021/acs.jcim.5b00559; Tanimoto T. T., 1958, An Elementary Mathematical Theory of Classification and Prediction; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wigh DS, 2022, WIRES COMPUT MOL SCI, V12, DOI 10.1002/wcms.1603; Wishart DS, 2006, NUCLEIC ACIDS RES, V34, pD668, DOI 10.1093/nar/gkj067; Wouters OJ, 2020, JAMA-J AM MED ASSOC, V323, P844, DOI 10.1001/jama.2020.1166; Yamada M, 2023, ACS OMEGA, V8, P19575, DOI 10.1021/acsomega.3c01078; Yu X., 2023, P 2023 C EMPIRICAL M, P739, DOI 10.18653/v1/2023.emnlp-industry.69	66	0	0	5	5	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAY 10	2024	14	1							10738	10.1038/s41598-024-61124-0	http://dx.doi.org/10.1038/s41598-024-61124-0			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	QC6T5	38730226	Green Submitted, gold			2024-07-03	WOS:001218726300051
C	Lemieux, C; Inala, JP; Lahiri, SK; Sen, S			IEEE	Lemieux, Caroline; Inala, Jeevana Priya; Lahiri, Shuvendu K.; Sen, Siddhartha			CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models	2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ICSE	International Conference on Software Engineering		English	Proceedings Paper	45th IEEE/ACM International Conference on Software Engineering (ICSE)	MAY 14-20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, Melbourne Convent Bur, State Govt Victoria, CSIRO, Huawei, Monash Univ, Meta, Google, AWS, Monash Univ, Dragon Testing Technol, IBM, Univ Melbourne, RMIT Univ			ALGORITHM	Search-based software testing (SBST) generates high-coverage test cases for programs under test with a combination of test case generation and mutation. SBST's performance relies on there being a reasonable probability of generating test cases that exercise the core logic of the program under test. Given such test cases, SBST can then explore the space around them to exercise various parts of the program. This paper explores whether Large Language Models (LLMs) of code, such as OpenAI's Codex, can be used to help SBST's exploration. Our proposed algorithm, CODAMOSA, conducts SBST until its coverage improvements stall, then asks Codex to provide example test cases for under-covered functions. These examples help SBST redirect its search to more useful areas of the search space. On an evaluation over 486 benchmarks, CODAMOSA achieves statistically significantly higher coverage on many more benchmarks (173 and 279) than it reduces coverage on (10 and 4), compared to SBST and LLM-only baselines.	[Lemieux, Caroline] Univ British Columbia, Vancouver, BC, Canada; [Inala, Jeevana Priya; Lahiri, Shuvendu K.; Sen, Siddhartha] Microsoft Res, Redmond, WA USA	University of British Columbia; Microsoft	Lemieux, C (corresponding author), Univ British Columbia, Vancouver, BC, Canada.	clemieux@cs.ubc.ca; jinala@microsoft.com; shuvendu.lahiri@microsoft.com; sidsen@microsoft.com						Albunian N, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1204, DOI 10.1145/3377930.3390194; Aleti A, 2017, AUTOMAT SOFTW ENG, V24, P603, DOI 10.1007/s10515-016-0197-7; Almasi MM, 2017, 2017 IEEE/ACM 39TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE TRACK (ICSE-SEIP 2017), P263, DOI 10.1109/ICSE-SEIP.2017.27; Arcuri A, 2018, INFORM SOFTWARE TECH, V104, P195, DOI 10.1016/j.infsof.2018.05.003; Arcuri A, 2017, LECT NOTES COMPUT SC, V10452, P3, DOI 10.1007/978-3-319-66299-2_1; Arcuri A, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/1985793.1985795; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bareiss P., 2022, Code Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language Models on Code; Batchelder Ned, 2010, COV PY; Bavishi R, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360594; Böhme M, 2022, PROC INT CONF SOFTW, P1621, DOI 10.1145/3510003.3510230; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryson Lingenfelter I. R., 2022, COPYDETECT; Chen M., 2021, EVALUATING LARGE LAN; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Crouse Sara, 2022, ABOUT US; Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017; Della Toffola L, 2017, IEEE INT CONF AUTOM, P44, DOI 10.1109/ASE.2017.8115617; Dinella E, 2022, PROC INT CONF SOFTW, P2130, DOI 10.1145/3510003.3510141; EvoSuite contributors, 2022, EVOSUITE CONTR; flutils contributors, 2022, FLUT CONTR; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2013, IEEE T SOFTWARE ENG, V39, P276, DOI 10.1109/TSE.2012.14; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Galeotti JP, 2013, PROC INT SYMP SOFTW, P360, DOI 10.1109/ISSRE.2013.6698889; Harman M, 2001, INFORM SOFTWARE TECH, V43, P833, DOI 10.1016/S0950-5849(01)00189-6; Harman M, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379787; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Kharkar A, 2022, PROC INT CONF SOFTW, P1307, DOI 10.1145/3510003.3510153; Lahiri S. K., 2022, Interactive code generation via test-driven user-intent formalization; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lin Y, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1068, DOI 10.1145/3468264.3468619; Lukasczyk S, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-022-10248-w; Lukasczyk S, 2022, PROC IEEE ACM INT C, P168, DOI [10.1109/ICSE-Companion55297.2022.9793730, 10.1145/3510454.3516829]; Mao K., 2016, P 25 INT S SOFTWARE, P94; Mastropaolo A., 2022, IEEE Transactions on Software Engineering; McMinn P, 2004, SOFTW TEST VERIF REL, V14, P105, DOI 10.1002/stvr.294; Myers G, 1999, J ACM, V46, P395, DOI 10.1145/316542.316550; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Pacheco C, 2007, PROC INT CONF SOFTW, P75; Panichella A, 2018, IEEE T SOFTWARE ENG, V44, P122, DOI 10.1109/TSE.2017.2663435; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Pipreqs Contributors, 2022, PIPR CONTR; Prenner JA, 2021, Arxiv, DOI [arXiv:2111.03922, DOI 10.48550/ARXIV.2111.03922]; Pynguin Contributors, 2022, TRY GEN SPEC FUNCT I; Pynguin Contributors, 2022, GEN ASS; Rak-amnouykit I, 2020, DLS '2020: PROCEEDINGS OF THE 16TH ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON DYNAMIC LANGUAGES, P57, DOI 10.1145/3426422.3426981; Rojas JM, 2016, SOFTW TEST VERIF REL, V26, P366, DOI 10.1002/stvr.1601; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schleimer S., 2003, P 2003 ACM SIGMOD IN, P76, DOI [10.1145/872757.872770, DOI 10.1145/872757.872770]; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Tanaka H., 2022, EDITDISTANCE; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tufano M., 2020, Unit Test Case Generation with Transformers and Focal Context; Tufano M, 2022, 3RD ACM/IEEE INTERNATIONAL CONFERENCE ON AUTOMATION OF SOFTWARE TEST (AST 2022), P54, DOI 10.1145/3524481.3527220; Watson C, 2020, PROC INT CONF SOFTW, P1398, DOI 10.1145/3377811.3380429; Widyasari R, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1556, DOI 10.1145/3368089.3417943; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yun Lin, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P440, DOI 10.1145/3395363.3397358; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864; Zitzler E., 2001, SPEA2: Improving the Strength Pareto Evolutionary Algorithm: Report, DOI 10.3929/ethz-a-004284029	62	9	9	6	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0270-5257		978-1-6654-5701-9	PROC INT CONF SOFTW			2023							919	931		10.1109/ICSE48619.2023.00085	http://dx.doi.org/10.1109/ICSE48619.2023.00085			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JK					2024-07-03	WOS:001032629800076
C	Ruan, K; Chen, XH; Jin, Z		Schneider, K; Dalpiaz, F; Horkoff, J		Ruan, Kun; Chen, Xiaohong; Jin, Zhi			Requirements Modeling Aided by ChatGPT: An hxperience in hmbedded Systems	2023 IEEE 31ST INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS, REW	IEEE International Requirements Engineering Conference Workshops		English	Proceedings Paper	31st IEEE International Requirements Engineering Conference (RE)	SEP 04-05, 2023	Hannover, GERMANY	IEEE, IEEE Comp Soc		ChatGPT; Requirements Modeling; Problem Frames Approach; Embedded system		Requirements modeling is a crucial tool for requirements analysis and has been demonstrated to aid in the comprehension and analysis of requirements. However, constructing requirements models from natural language descriptions in user requirements documents can be a time-consuming task. With the growing attention given to large language models, they have become an integral component of natural language processing. Consequently, utilizing large language models to facilitate the construction of high-quality requirement models is appealing. This paper presents an automated framework for requirement model generation that incorporates ChatGPT-based zero-shot learning to extract requirement models from requirement texts and subsequently compose them using predefined rules. The framework defines the requirement extraction task of ChatGPT by designing appropriate prompt, and it generates requirement models by employing composition rules. Furthermore, a case study on a digital home system is conducted to validate the feasibility of the framework in assisting requirements modeling.	[Ruan, Kun; Chen, Xiaohong] East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai, Peoples R China; [Jin, Zhi] Peking Univ, Sch Comp Sci, Beijing, Peoples R China; [Jin, Zhi] Minist Educ, Key Lab High Confidence Software Technol PKU, Beijing, Peoples R China	East China Normal University; Peking University	Chen, XH (corresponding author), East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai, Peoples R China.; Jin, Z (corresponding author), Peking Univ, Sch Comp Sci, Beijing, Peoples R China.; Jin, Z (corresponding author), Minist Educ, Key Lab High Confidence Software Technol PKU, Beijing, Peoples R China.	xhchen@sei.ecnu.edu.on; zhijin@pku.edu.on	liu, xinyi/KFB-4466-2024		National Natural Science Foundation of China [62192730,62192731,62272166]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This research was supported by National Natural Science Foundation of China (62192730,62192731,62272166).	Ambriola V, 1997, AUTOMATED SOFTWARE ENGINEERING, 12TH IEEE INTERNATIONAL CONFERENCE, PROCEEDINGS, P36, DOI 10.1109/ASE.1997.632822; Chen Xiao-Hong, 2011, Journal of Software, V22, P177, DOI 10.3724/SP.J.1001.2011.03755; Chen XH, 2019, INT REQUIR ENG CONF, P308, DOI 10.1109/RE.2019.00040; Elbendak M, 2011, J SYST SOFTWARE, V84, P1209, DOI 10.1016/j.jss.2011.02.025; Fill HG, 2023, ENTERP MODELLING INF, V18, P1, DOI 10.18417/emisa.18.3; Gao J, 2023, Arxiv, DOI [arXiv:2303.03836, DOI 10.48550/ARXIV.2303.03836]; Harmain HM, 2000, FIFTEENTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, PROCEEDINGS, P45, DOI 10.1109/ASE.2000.873649; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Jackson M., 1995, SOFTWARE REQUIREMENT; Jackson M., 2001, PROBLEM FRAMES ANAL; Jahan M, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P39, DOI 10.1109/REW53955.2021.00012; Jin Z., 2018, Environment Modeling-Based Requirements Engineering for Software Intensive Systems; Jin Z, 2019, INT REQUIR ENG CONF, P496, DOI 10.1109/RE.2019.00072; Jin Z, 2009, ASIA PAC SOFWR ENG, P249, DOI 10.1109/APSEC.2009.22; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mich L, 2002, MANAG INFORMAT SYST, V6, P321; openfoam, ABOUT US; Subramaniam Kalaivani., 2004, P 16 INT C SOFTWARE, P324; Tun TT, 2009, LECT NOTES COMPUT SC, V5512, P74, DOI 10.1007/978-3-642-02050-6_7; Wang CH, 2022, INT REQUIR ENG CONF, P18, DOI 10.1109/REW56159.2022.00012; Wang JA, 2023, Arxiv, DOI arXiv:2302.14229; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Yang MF, 2022, CHIN SPACE SCI TECHN, V42, P1, DOI 10.16708/j.cnki.1000-758X.2022.0046; Yu M., 2021, ICCCS, P1042; Yuan CH, 2023, Arxiv, DOI arXiv:2304.05454; Zhang JZ, 2023, Arxiv, DOI arXiv:2304.12562	26	1	1	5	8	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2770-6826		979-8-3503-2691-8	Intern Req Engg Work			2023							170	177		10.1109/REW57809.2023.00035	http://dx.doi.org/10.1109/REW57809.2023.00035			8	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV9BJ					2024-07-03	WOS:001085223300031
C	Singh, I; Blukis, V; Mousavian, A; Goyal, A; Xu, DF; Tremblay, J; Fox, D; Thomason, J; Garg, A			IEEE	Singh, Ishika; Blukis, Valts; Mousavian, Arsalan; Goyal, Ankit; Xu, Danfei; Tremblay, Jonathan; Fox, Dieter; Thomason, Jesse; Garg, Animesh			PROGPROMPT: Generating Situated Robot Task Plans using Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc				Task planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about prompt structure and generation constraints through ablation experiments, demonstrate state of the art success rates in VirtualHome household tasks, and deploy our method on a physical robot arm for tabletop tasks. Website at progprompt.github.io	[Singh, Ishika; Thomason, Jesse] Univ Southern Calif, Los Angeles, CA 90007 USA; [Blukis, Valts; Mousavian, Arsalan; Goyal, Ankit; Xu, Danfei; Tremblay, Jonathan; Fox, Dieter; Garg, Animesh] NVIDIA, Santa Clara, CA USA	University of Southern California; Nvidia Corporation	Singh, I (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	ishikasi@usc.edu						Ahn Michael, 2022, DO I CAN NOT I SAY G; Akakzia A., 2021, INT C LEARN REPR; Baier JA, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1808; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryce D, 2007, AI MAG, V28, P47; Chen M., 2021, ARXIV; Danielczuk M., 2021, IEEE INT C ROB AUT I; Eysenbach B., 2019, Advances in neural information processing systems, V32; FIKES RE, 1971, ARTIF INTELL, V2, P189, DOI 10.1016/0004-3702(71)90010-5; Garrett C. R., 2020, P INT C AUTOMATED PL, V30, P440; Gu X., 2022, INT C LEARN REPR; Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705; Hoffmann J, 2001, AI MAG, V22, P57; Holtzman A., 2019, INT C LEARNING REPRE; Huang W., 2022, ARXIV220107207; Huang Wenlong, 2022, ARXIV220705608; Jansen PA, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4412; Jiang Y., 2018, TASK PLANNING ROBOTI; Jiang YD, 2019, ADV NEUR IN, V32; Kurutach T, 2018, ADV NEUR IN, V31; Li S., 2022, PRETRAINED LANGUAGE; Liu Pengfei, 2021, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing; Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166; Mirchandani S., 2021, ADV NEURAL INFORM PR, V34, P29529; Nair S., 2020, INT C LEARN REPR; Patel Roma, 2022, INT C LEARN REPR; Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886; Shah D., 2022, INT C LEARN REPR; Sharma P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1713; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Silver T., 2022, MULT C REINF LEARN D; Srinivas A, 2018, INT C MACHINE LEARNI, V80, P4739; Sundermeyer M, 2021, IEEE INT CONF ROBOT, P13438, DOI 10.1109/ICRA48506.2021.9561877; Wei Jason, 2022, Chain of thought prompting elicits reasoning in large language models; Welker S., 2022, Socratic models: Composing zero-shot multimodal reasoning with language; Wiseman Sam., 2017, P 2017 C EMPIRICAL M, P2253, DOI [DOI 10.18653/V1/D17-1239, 10.18653/v1/D17-1239]; Xu D, 2019, ADV NEUR IN, V32; Xu DF, 2018, IEEE INT CONF ROBOT, P3795; Zhu Y., 2020, HIERARCHICAL PLANNIN	39	17	18	11	17	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							11523	11530		10.1109/ICRA48891.2023.10161317	http://dx.doi.org/10.1109/ICRA48891.2023.10161317			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371103090
C	Sheese, B; Liffiton, M; Savelka, J; Denny, P			ACM	Sheese, Brad; Liffiton, Mark; Savelka, Jaromir; Denny, Paul			Patterns of Student Help-Seeking When Using a Large Language Model-Powered Programming Assistant	PROCEEDINGS OF THE 26TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2024			English	Proceedings Paper	26th Australasian Computing Education Conference (ACE)	JAN 29-FEB 02, 2024	Sydney, AUSTRALIA			Intelligent tutoring systems; Intelligent programming tutors; Programming; assistance; Novice programmers; Natural language interfaces; Large language models; Guardrails		Providing personalized assistance at scale is a long-standing challenge for computing educators, but a new generation of tools powered by large language models (LLMs) offers immense promise. Such tools can, in theory, provide on-demand help in large class settings and be configured with appropriate guardrails to prevent misuse and mitigate common concerns around learner over-reliance. However, the deployment of LLM-powered tools in authentic classroom settings is still rare, and very little is currently known about howstudents will use them in practice and what type of help they will seek. To address this, we examine students' use of an innovative LLMpowered tool that provides on-demand programming assistance without revealing solutions directly. We deployed the tool for 12 weeks in an introductory computer and data science course (.. = 52), collecting more than 2,500 queries submitted by students throughout the term. We manually categorized all student queries based on the type of assistance sought, and we automatically analyzed several additional query characteristics. We found that most queries requested immediate help with programming assignments, whereas fewer requests asked for help on related concepts or for deepening conceptual understanding. Furthermore, students often provided minimal information to the tool, suggesting this is an area in which targeted instruction would be beneficial. We also found that students who achieved more success in the course tended to have used the tool more frequently overall. Lessons from this research can be leveraged by programming educators and institutions who plan to augment their teaching with emerging LLM-powered tools.	[Sheese, Brad; Liffiton, Mark] Illinois Wesleyan Univ, Bloomington, IL 61701 USA; [Savelka, Jaromir] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA; [Denny, Paul] Univ Auckland, Auckland, New Zealand	Illinois Wesleyan University; Carnegie Mellon University; University of Auckland	Sheese, B (corresponding author), Illinois Wesleyan Univ, Bloomington, IL 61701 USA.	bsheese@iwu.edu; mliffito@iwu.edu; jsavelka@cs.cmu.edu; paul@cs.auckland.ac.nz		Savelka, Jaromir/0000-0002-3674-5456				Balse R, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P292, DOI 10.1145/3587102.3588852; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Brusilovsky Peter, 2023, CS2023; Cipriano BP, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P61, DOI 10.1145/3587102.3588814; Collins JE, 2023, PHI DELTA KAPPAN, V104, P60, DOI 10.1177/00317217231168266; Denny P, 2023, Arxiv, DOI arXiv:2311.05943; Denny P, 2023, Arxiv, DOI arXiv:2307.16364; Denny P, 2023, Arxiv, DOI arXiv:2306.02608; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Doughty J, 2023, Arxiv, DOI arXiv:2312.03173; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gao ZK, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P300, DOI 10.1145/3478431.3499334; Gao Zhikai, 2021, Automatically Classifying Student Help Requests: A Multi-Year Analysis; Hellas A, 2023, Arxiv, DOI arXiv:2306.05715; Hicke Y, 2023, Arxiv, DOI [arXiv:2311.02775, DOI 10.48550/ARXIV.2311.02775]; Jalil S, 2023, Arxiv, DOI arXiv:2302.03287; Kazemitabaar M, 2023, Arxiv, DOI arXiv:2309.14049; Kazemitabaar M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580919; Leinonen J, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P563, DOI 10.1145/3545945.3569770; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Liffiton M, 2023, Arxiv, DOI arXiv:2308.06921; Macneil S, 2023, Arxiv, DOI arXiv:2311.16017; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; National Academies of Sciences Engineering and Medicine, 2018, Assessing and responding to the growth of computer science undergraduate enrollments; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; O'Connor C, 2020, INT J QUAL METH, V19, DOI 10.1177/1609406919899220; Pardos Z. A., 2023, arXiv; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prather J, 2023, Arxiv, DOI arXiv:2304.02491; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI arXiv:2310.20105; Savelka J, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P78, DOI 10.1145/3568813.3600142; Savelka J, 2023, Arxiv, DOI [arXiv:2303.08033, DOI 10.48550/ARXIV.2303.08033]; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938	35	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1619-5				2024							49	57		10.1145/3636243.3636249	http://dx.doi.org/10.1145/3636243.3636249			9	Computer Science, Software Engineering; Computer Science, Theory & Methods; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW5RQ		hybrid, Green Submitted			2024-07-03	WOS:001166861800006
J	Peng, C; Yang, X; Chen, AK; Yu, ZH; Smith, KE; Costa, AB; Flores, MG; Bian, J; Wu, YH				Peng, Cheng; Yang, Xi; Chen, Aokun; Yu, Zehao; Smith, Kaleb E.; Costa, Anthony B.; Flores, Mona G.; Bian, Jiang; Wu, Yonghui			Generative large language models are all-purpose text analytics engines: text-to-text learning is all your need	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article; Early Access						prompt tuning; large language model; text generation; clinical natural language processing; transformer model		Objective To solve major clinical natural language processing (NLP) tasks using a unified text-to-text learning architecture based on a generative large language model (LLM) via prompt tuning.Methods We formulated 7 key clinical NLP tasks as text-to-text learning and solved them using one unified generative clinical LLM, GatorTronGPT, developed using GPT-3 architecture and trained with up to 20 billion parameters. We adopted soft prompts (ie, trainable vectors) with frozen LLM, where the LLM parameters were not updated (ie, frozen) and only the vectors of soft prompts were updated, known as prompt tuning. We added additional soft prompts as a prefix to the input layer, which were optimized during the prompt tuning. We evaluated the proposed method using 7 clinical NLP tasks and compared them with previous task-specific solutions based on Transformer models.Results and Conclusion The proposed approach achieved state-of-the-art performance for 5 out of 7 major clinical NLP tasks using one unified generative LLM. Our approach outperformed previous task-specific transformer models by similar to 3% for concept extraction and 7% for relation extraction applied to social determinants of health, 3.4% for clinical concept normalization, 3.4%-10% for clinical abbreviation disambiguation, and 5.5%-9% for natural language inference. Our approach also outperformed a previously developed prompt-based machine reading comprehension (MRC) model, GatorTron-MRC, for clinical concept and relation extraction. The proposed approach can deliver the "one model for all" promise from training to deployment using a unified generative LLM.	[Peng, Cheng; Yang, Xi; Chen, Aokun; Yu, Zehao; Bian, Jiang; Wu, Yonghui] Univ Florida, Coll Med, Dept Hlth Outcomes & Biomed Informat, Clin & Translat Res Bldg,2004 Mowry Rd,POB 100177, Gainesville, FL 32611 USA; [Yang, Xi; Chen, Aokun; Bian, Jiang; Wu, Yonghui] Univ Florida, Hlth Canc Ctr, Canc Informat Shared Resource, Gainesville, FL 32610 USA; [Smith, Kaleb E.; Costa, Anthony B.; Flores, Mona G.] NVIDIA, Santa Clara, CA 95051 USA	State University System of Florida; University of Florida; State University System of Florida; University of Florida; Nvidia Corporation	Wu, YH (corresponding author), Univ Florida, Coll Med, Dept Hlth Outcomes & Biomed Informat, Clin & Translat Res Bldg,2004 Mowry Rd,POB 100177, Gainesville, FL 32611 USA.	yonghui.wu@ufl.edu		Peng, Cheng/0000-0002-1994-893X; Wu, Yonghui/0000-0002-6780-6135; Bian, Jiang/0000-0002-2238-5429	Patient-Centered Outcomes Research Institute; NVIDIA Corporation; NIVIDA AI Technology Center (NVAITC) UF program; UF Research Computing team	Patient-Centered Outcomes Research Institute(Patient-Centered Outcomes Research Institute - PCORI); NVIDIA Corporation(Nvidia Corporation); NIVIDA AI Technology Center (NVAITC) UF program; UF Research Computing team	We would like to thank the i2b2 and n2c2 challenge organizers to provide the annotated corpus. We gratefully acknowledge the support of NVIDIA Corporation and the NIVIDA AI Technology Center (NVAITC) UF program. We would like to thank the UF Research Computing team, led by Dr Erik Deumens, for providing computing power through UF HiperGator-AI cluster.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; [Anonymous], 2015, P 9 INT WORKSH SEM E, DOI DOI 10.18653/V1/S15-2070; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Bodenreider O, 2003, J BIOMED INFORM, V36, P414, DOI 10.1016/j.jbi.2003.11.002; Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cevik M, 2023, J HEALTHC INFORM RES, V7, P501, DOI 10.1007/s41666-023-00146-1; Chen AK, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104370; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Davenport M, 2012, J MED LIBR ASSOC, V100, DOI 10.3163/1536-5050.100.1.017; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elhadad N., 2015, P 9 INT WORKSH SEM E, P303, DOI [DOI 10.18653/V1/S15-2051, 10.18653/v1/S15-2051]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao YJ, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104346; Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; Lafferty J., 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.5555/645530.655813; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lybarger K, 2023, J AM MED INFORM ASSN, V30, P1367, DOI 10.1093/jamia/ocad012; Mahajan D, 2023, J BIOMED INFORM, V144, DOI 10.1016/j.jbi.2023.104432; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Moon S., 2012, Clinical abbreviation sense inventory; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Pathak P., 2015, Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), P412, DOI DOI 10.18653/V1/S15-2071; Peng C., 2024, J Biomed Inform, V153; Peng C., 2023, NPJ Digit Med, V6, P1; Peng C, 2023, J AM MED INFORM ASSN, V30, P1486, DOI 10.1093/jamia/ocad107; Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58; Raffel C, 2020, J MACH LEARN RES, V21; Saeed M, 2002, COMPUT CARDIOL, V29, P641, DOI 10.1109/CIC.2002.1166854; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shin HC, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4700; Shivade C., 2019, P 2018 C EMPIRICAL M, P1586; Si YQ, 2019, J AM MED INFORM ASSN, V26, P1297, DOI 10.1093/jamia/ocz096; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628; Suominen H, 2013, LECT NOTES COMPUT SC, V8138, P212, DOI 10.1007/978-3-642-40802-1_24; Sutskever I, 2014, ADV NEUR IN, V27; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203; Vaswani A, 2017, ADV NEUR IN, V30; Wei J., 2022, INT C LEARN REPR; Wu Yonghui, 2017, AMIA Annu Symp Proc, V2017, P1812; Xu J, 2015, P 9 INT WORKSH SEM E, P311, DOI DOI 10.18653/V1/S15-2052; Yang X, 2021, arXiv; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang X, 2020, J AM MED INFORM ASSN, V27, P1935, DOI 10.1093/jamia/ocaa189; Yang X, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0935-4; Yang X, 2020, J AM MED INFORM ASSN, V27, P65, DOI 10.1093/jamia/ocz144; Yang X, 2019, IEEE T NEUR NET LEAR, V30, P2987, DOI [10.1109/TNNLS.2018.2861991, 10.1109/TNNLS.2018.2790479]	55	0	0	23	23	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	2024 APR 17	2024										10.1093/jamia/ocae078	http://dx.doi.org/10.1093/jamia/ocae078		APR 2024	12	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	NX6V4	38630580	Green Submitted			2024-07-03	WOS:001203800600001
J	Mughal, N; Mujtaba, G; Shaikh, S; Kumar, A; Daudpota, SM				Mughal, Nimra; Mujtaba, Ghulam; Shaikh, Sarang; Kumar, Aveenash; Daudpota, Sher Muhammad			Comparative Analysis of Deep Natural Networks and Large Language Models for Aspect-Based Sentiment Analysis	IEEE ACCESS			English	Article						Aspect-based sentiment analysis (ABSA); large language model (LLM); GPT; PaLM; BERT	NEURAL-NETWORK; EXTRACTION	Sentiment analysis is essential for comprehending public opinion, particularly when considering e-commerce and the expansion of online businesses. Early approaches treated sentiment analysis as a document or sentence-level classification problem, lacking the ability to capture nuanced opinions about specific aspects. This limitation was addressed by the development of aspect-based sentiment analysis (ABSA), which links sentiment to specific aspects that are mentioned explicitly or implicitly in the review. ABSA is relatively a recent field of sentiment analysis and the existing models for ABSA face three main challenges, including domain-specificity, reliance on labeled data, and a lack of exploration into the potential of newer large language models (LLMs) such as GPT, PaLM, and T5. Leveraging a diverse set of datasets, including DOTSA, MAMS, and SemEval16, we evaluate the performance of prominent models such as ATAE-LSTM, flan-t5-large-absa, DeBERTa, PaLM, and GPT-3.5-Turbo. Our findings reveal nuanced strengths and weaknesses of these models across different domains, with DeBERTa emerging as consistently high-performing and PaLM demonstrating remarkable competitiveness for aspect term sentiment analysis (ATSA) tasks. In addition, the PaLM demonstrates competitive performance for all the domains that were used in the experiments including the restaurant, hotel, books, clothing, and laptop reviews. Notably, the analysis underscores the models' domain sensitivity, shedding light on their varying efficacy for both ATSA and ACSA tasks. These insights contribute to a deeper understanding of model applicability and highlight potential areas for improvement in ABSA research and development.	[Mughal, Nimra; Mujtaba, Ghulam] Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Blo, Dept Comp Sci, Sukkur 65200, Sindh, Pakistan; [Shaikh, Sarang] Norwegian Univ Sci & Technol NTNU, Dept Informat Secur & Commun Technol IIK, N-7034 Gjovik, Trondheim, Norway; [Kumar, Aveenash] Learners Ai, Toronto, ON M5C 2B5, Canada; [Daudpota, Sher Muhammad] Sukkur IBA Univ, Dept Comp Sci, Sukkur 65200, Sindh, Pakistan	Sukkur IBA University; Norwegian University of Science & Technology (NTNU); Sukkur IBA University	Mughal, N (corresponding author), Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Blo, Dept Comp Sci, Sukkur 65200, Sindh, Pakistan.; Shaikh, S (corresponding author), Norwegian Univ Sci & Technol NTNU, Dept Informat Secur & Commun Technol IIK, N-7034 Gjovik, Trondheim, Norway.	nimra.cs16@gmail.com; sarang.shaikh@ntnu.no		Daudpota, Sher Muhammad/0000-0001-6684-751X	National Research Program for Universities (NRPU), Higher Education Commission, Pakistan	National Research Program for Universities (NRPU), Higher Education Commission, Pakistan	No Statement Available	Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1; Akhtar MS, 2020, NEUROCOMPUTING, V398, P247, DOI 10.1016/j.neucom.2020.02.093; Alzubaidi L, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00444-8; [Anonymous], 2013, Int. J. Sci. Eng. Technol..; Bai XF, 2021, IEEE-ACM T AUDIO SPE, V29, P503, DOI 10.1109/TASLP.2020.3042009; Bao LX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P253; Brauwers G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3503044; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chavez MR, 2023, AM J OBSTET GYNECOL, V228, P706, DOI 10.1016/j.ajog.2023.03.010; Chebolu SUS, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3544557; Chumakov Stanislav, 2023, Procedia Computer Science, V229, P284, DOI 10.1016/j.procs.2023.12.030; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Cohen V., 2020, ACM Mag. Students., V27, P26; Cooray T., 2021, Proc. SPIE., V11766, P615; Cowell R. G., 2007, Proba[1]bilistic Networks and Expert Systems: Exact Computational Methods for Bayesian Networks; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dhanith PRJ, 2023, ARTIF INTELL REV, V56, P13127, DOI 10.1007/s10462-023-10460-0; Do B. T., 2018, PROC 31 INT FLAIRS C, P1; Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Galanis D., 2015, P SEMEVAL, P486, DOI [10.18653/v1/S15-2082, 10.18653/v1/s15-2082]; Ganesan K., 2010, P 23 INT C COMPUTATI, P340; Hoang M., 2019, P 22 NORDIC C COMPUT, P187; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Nguyen HT, 2018, INT CONF KNOWL SYS, P25, DOI 10.1109/KSE.2018.8573324; Jiang QN, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6280; Jie Wang, 2021, 2021 International Conference on Machine Learning and Intelligent Systems Engineering (MLISE), P267, DOI 10.1109/MLISE54096.2021.00056; Kirange D, 2014, Asian J. Comput. Sci. Inf. Technol. (AJCSIT), V4, P8; Kotha S., 2011, MARKET MAKERS RETAIL, P155, DOI 10.1093/acprof:oso/9780199590179.003.0006; Kumar A, 2021, NEURAL PROCESS LETT, V53, P4207, DOI 10.1007/s11063-021-10596-6; Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu B, 2010, CH CRC MACH LEARN PA, P627; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Luo HS, 2019, Arxiv, DOI arXiv:1906.01794; Luo Yun, 2022, arXiv; Machacek Jakub., 2016, PROC 10 INT WORKSHOP, P301; Magdaleno D., 2023, PROC MEXICAN INT C A, P61; Mewada A, 2023, J SUPERCOMPUT, V79, P5516, DOI 10.1007/s11227-022-04881-x; Mohammad SM, 2016, EMOTION MEASUREMENT, P201, DOI 10.1016/B978-0-08-100508-8.00009-6; Mukherjee Rajdeep, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P92, DOI 10.1007/978-3-030-72240-1_7; Nasim Z, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017500233; Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565; Orbach M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9154; Peng YQ, 2022, APPL INTELL, V52, P5867, DOI 10.1007/s10489-021-02724-5; Phan HT, 2022, IEEE ACCESS, V10, P110402, DOI 10.1109/ACCESS.2022.3214233; Pontiki M., 2016, P 10 INT WORKSH SEM, P19, DOI [10.18653/v1/S16-1002, DOI 10.18653/V1/S16-1002]; Rajapaksha S., 2022, PROC MORATUWA ENG RE, P1; Sadr H., 2021, J AI DATA MINING, V9, P141; Saeidi Marzieh, 2016, P COLING 2016 26 INT, P1546; Scaria K, 2023, Arxiv, DOI arXiv:2302.08624; Setiawan EI., 2020, Int. J. Intell. Eng. Syst., V13, P392, DOI [10.22266/ijies2020.1031.35, DOI 10.22266/IJIES2020.1031.35]; Shmueli G., 2017, Data mining for business analytics: concepts, techniques; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380; Szarvas G., 2020, arXiv; Tenney I., 2019, arXiv, DOI DOI 10.48550/ARXIV.1905.05950; Tim YN, 2021, INFORM SYST J, V31, P323, DOI 10.1111/isj.12312; Toledo-Ronen O, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2751; Trisna KW, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2021.2014186; Koroteev MV, 2021, Arxiv, DOI [arXiv:2103.11943, DOI 10.48550/ARXIV.2103.11943]; Varghese R, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1581, DOI 10.1109/ICACCI.2013.6637416; Vaswani A, 2017, ADV NEUR IN, V30; Wang XY, 2021, NEUROCOMPUTING, V450, P91, DOI 10.1016/j.neucom.2021.03.092; Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058; Wang YY, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106509; Webb G.I., 2010, Encyclopedia of Machine Learning, P713, DOI [10.1007/978-0-387-30164-8_576, DOI 10.1007/978-0-387-30164-8_576, 10.1007/978-1-4899-7502-7_581-1, DOI 10.1007/978-1-4899-7502-7581-1]; Wenqing Luo, 2021, 2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI), P353, DOI 10.1109/CISAI54367.2021.00074; Xu H., 2020, P 28 INT C COMP LING; Xu Y, 2012, J AM MED INFORM ASSN, V19, P824, DOI 10.1136/amiajnl-2011-000776; Yang C, 2019, INFORM PROCESS MANAG, V56, P463, DOI 10.1016/j.ipm.2018.12.004; Yang H, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P5117, DOI 10.1145/3583780.3614752; Yang H, 2024, Arxiv, DOI arXiv:2110.08604; Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199; Zeng BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163389; Zeng JF, 2019, IEEE ACCESS, V7, P20462, DOI 10.1109/ACCESS.2019.2893806; Zhang Y, 2021, NEUROCOMPUTING, V462, P101, DOI 10.1016/j.neucom.2021.07.072; Zhou J, 2019, IEEE ACCESS, V7, P78454, DOI 10.1109/ACCESS.2019.2920075	79	0	0	15	15	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						60943	60959		10.1109/ACCESS.2024.3386969	http://dx.doi.org/10.1109/ACCESS.2024.3386969			17	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	PL7L1		gold			2024-07-03	WOS:001214298100001
J	Church, KW; Yue, R				Church, Kenneth Ward; Yue, Richard			Emerging trends: Smooth-talking machines	NATURAL LANGUAGE ENGINEERING			English	Article						Large language models; Hallucinations; ChatGPT; Responsible AI	COMPUTER	Large language models (LLMs) have achieved amazing successes. They have done well on standardized tests in medicine and the law. That said, the bar has been raised so high that it could take decades to make good on expectations. To buy time for this long-term research program, the field needs to identify some good short-term applications for smooth-talking machines that are more fluent than trustworthy.	[Church, Kenneth Ward; Yue, Richard] Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA		Church, KW (corresponding author), Northeastern Univ, Inst Experiential AI, San Jose, CA 95113 USA.	k.church@northeastern.edu	Church, Kenneth Ward/GYR-1624-2022	Church, Kenneth Ward/0000-0001-8378-6069; Yue, Richard/0009-0009-4135-5629				Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Church K., 2022, NAT LANG ENG, V29, P483; Church K., 2011, Linguistic Issues in Language Technology, V6, P1; Church K. W., 1993, Machine Translation, V8, P239, DOI 10.1007/BF00981759; Church KW, 2023, NAT LANG ENG, V29, P824, DOI 10.1017/S1351324923000141; Dorr B., 2011, MACH TRANSL, P745; Firth JR, 1957, Selected Papers of J. R. Firth, P10; Klakow D, 2002, SPEECH COMMUN, V38, P19, DOI 10.1016/S0167-6393(01)00041-3; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; STEWART KK, 1985, J AUTOM CHEM, V7, P169, DOI 10.1155/S1463924685000360; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991	12	1	1	11	16	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1351-3249	1469-8110		NAT LANG ENG	Nat. Lang. Eng.	SEP	2023	29	5					1402	1410		10.1017/S1351324923000463	http://dx.doi.org/10.1017/S1351324923000463			9	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	R2BC5		hybrid			2024-07-03	WOS:001062434100008
C	Aveni, TJ; Fox, A; Hartmann, B			ACM	Aveni, Timothy J.; Fox, Armando; Hartmann, Bjorn			Bringing Context-Aware Completion Suggestions to Arbitrary Text Entry Interfaces	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		large language models; Web accessibility; intelligent user interfaces		Large language models (LLMs) can predict "obvious" next steps that users will take in text entry fields, especially the tedious components of tasks like software engineering or email composition. These models are not only useful in large, unbroken text fields, however. We present OmniFill, a browser extension that detects text entry fields and offers "autofill"-style suggestions based on context from the browsing session. The system constructs an LLM prompt that includes three main components: (a) a description of the active tab's text fields and their current values, (b) information from the user's recent web browsing context, and (c) a history, if available, of the user's prior submissions to the web form (alongside those submissions' associated browsing context). Suggestions from the LLM's response are offered to the user to be automatically typed into each corresponding text field. We offer a motivating example of a time-saving interaction and discuss the broader utility of interface-agnostic LLM integrations.	[Aveni, Timothy J.; Fox, Armando; Hartmann, Bjorn] Univ Calif Berkeley, Berkeley, CA 94720 USA	University of California System; University of California Berkeley	Aveni, TJ (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.	tja@berkeley.edu; fox@berkeley.edu; bjoern@berkeley.edu		Hartmann, Bjoern/0000-0002-0693-0829				Cypher A, 2012, S VIS LANG HUM CEN C, P23, DOI 10.1109/VLHCC.2012.6344474; Goodman SM, 2022, PROCEEDINGS OF THE 24TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2022, DOI 10.1145/3517428.3544819; Hartmann M, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P221, DOI 10.1109/ICSC.2009.83; Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159; Mallett Chris, 2023, AutoHotkey; Shaohua Wang, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P175, DOI 10.1109/SERVICES.2013.19; Stylos Jeffrey., 2004, P 17 ANN ACM S USER, P185, DOI [10.1145/1029632.1029665, DOI 10.1145/1029632.1029665]; Wang DK, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3381069; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	9	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									77	10.1145/3586182.3615825	http://dx.doi.org/10.1145/3586182.3615825			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000076
J	Oliveira, ON Jr; Christino, L; Oliveira, MCF; Paulovich, FV				Oliveira Jr, O. N.; Christino, L.; Oliveira, M. C. F.; Paulovich, F. V.			Artificial Intelligence Agents for Materials Sciences	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Editorial Material							DRIVEN; TOOL; AI	The artificial intelligence (AI) tools based on large-language models may serve as a demonstration that we are reaching a groundbreaking new paradigm in which machines themselves will generate knowledge autonomously. This statement is based on the assumption that the ability to master natural languages is the ultimate frontier for this new paradigm and perhaps an essential step to achieving the so-called general artificial intelligence. Autonomous knowledge generation implies that a machine will be able, for instance, to retrieve and understand the contents of the scientific literature and provide interpretations for existing data, allowing it to propose and address new scientific problems. While one may assume that the continued development of AI tools exploiting large-language models, with more data used for training, may lead these systems to learn autonomously, this learning can be accelerated by devising human-assisted strategies to deal with specific tasks. For example, strategies may be implemented for AI tools to emulate the analysis of multivariate data by human experts or in identifying and explaining patterns in temporal series. In addition to generic AI tools, such as Chat AIs, one may conceive personal AI agents, potentially working together, that are likely to serve end users in the near future. In this perspective paper, we discuss the development of this type of agent, focusing on its architecture and requirements. As a proof-of-concept, we exemplify how such an AI agent could work to assist researchers in materials sciences.	[Oliveira Jr, O. N.; Oliveira, M. C. F.] Univ Sao Paulo, BR-13560970 Sao Carlos, SP, Brazil; [Christino, L.] Dalhousie Univ, Halifax, NS B3H 4R2, Canada; [Christino, L.; Paulovich, F. V.] Eindhoven Univ Technol TU E, NL-5600 MB Eindhoven, Netherlands	Universidade de Sao Paulo; Dalhousie University; Eindhoven University of Technology	Oliveira, ON Jr (corresponding author), Univ Sao Paulo, BR-13560970 Sao Carlos, SP, Brazil.	chu@ifsc.usp.br			, Funda??o de Amparo ? Pesquisa do Estado de S?o Paulo [301847/2017-7]; CNPq [2018/22214-6]; FAPESP	, Funda??o de Amparo ? Pesquisa do Estado de S?o Paulo; CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP))	This work was supported by CNPq (301847/2017-7) and FAPESP (2018/22214-6).	Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], ChatGPT; ANSCOMBE FJ, 1973, AM STAT, V27, P17, DOI 10.2307/2682899; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Borji A, 2022, Arxiv, DOI [arXiv:2210.00586, 10.48550/arXiv.2210.00586]; Brito ACM, 2023, ACS APPL MATER INTER, V15, P27437, DOI 10.1021/acsami.3c01632; Cai JZ, 2020, NANOSCALE ADV, V2, P3115, DOI 10.1039/d0na00388c; Callaway E, 2022, NATURE, V604, P234, DOI 10.1038/d41586-022-00997-5; Canbek G.N., 2016, INT J HUMAN SCI, V13, P592, DOI [10.14687/ijhs.v13i1.3549, DOI 10.14687/IJHS.V13I1.3549]; Celonis Inc, About us; Choi W, 2023, MRS COMMUN, V13, P714, DOI 10.1557/s43579-023-00473-9; Christino L., 2023, ChatKG:Visualizing temporal patterns as knowledgegraph, DOI [10.2312/eurova.20231090, DOI 10.2312/EUROVA.20231090]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; de Arruda HF, 2016, CHAOS, V26, DOI 10.1063/1.4954215; GitHub, BabyAGI; Gu K, 2024, Arxiv, DOI arXiv:2309.10108; Gupta V, 2023, J CHEM INF MODEL, V63, P1865, DOI 10.1021/acs.jcim.3c00307; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Huang J., 2023, 2023 15 INT C INT HU, P241, DOI [10.1109/IHMSC58761.2023.00063, DOI 10.1109/IHMSC58761.2023.00063]; Kaufman L, 2014, SCRIPTA MATER, V70, P3, DOI 10.1016/j.scriptamat.2012.12.003; LangChain Inc, OpenAI; Leonardo Interactive Pty Ltd, About us; Li MR, 2024, Arxiv, DOI arXiv:2305.14623; Oliveira ON, 2021, ACS APPL MATER INTER, V13, P53301, DOI 10.1021/acsami.1c18225; Packer C, 2024, Arxiv, DOI arXiv:2310.08560; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Paulovich FV, 2018, ACS SENSORS, V3, P1433, DOI 10.1021/acssensors.8b00276; Reworkd AI Inc, AgentGPT; Silva FN, 2016, J INFORMETR, V10, P487, DOI 10.1016/j.joi.2016.03.008; Smith ML, 2021, COMPUT IND, V130, DOI 10.1016/j.compind.2021.103472; Sureshbabu SH, 2021, J CHEM INF MODEL, V61, P2667, DOI 10.1021/acs.jcim.1c00294; Van Noorden R, 2023, NATURE, V621, P672, DOI 10.1038/d41586-023-02980-0; Wang JJ, 2022, J MANUF SYST, V63, P381, DOI 10.1016/j.jmsy.2022.04.004; Warszycki D, 2021, J CHEM INF MODEL, V61, P5054, DOI 10.1021/acs.jcim.1c00589; Wolfram Alpha LLC, About us; Wu S, 2023, Arxiv, DOI arXiv:2308.04709; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Zhang C, 2023, Arxiv, DOI [arXiv:2304.06488, DOI 10.13140/RG.2.2.24789.70883]	41	1	1	9	9	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	DEC 12	2023	63	24					7605	7609		10.1021/acs.jcim.3c01778	http://dx.doi.org/10.1021/acs.jcim.3c01778			5	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	ET3Q2	38084508				2024-07-03	WOS:001141143200001
C	Wu, YN; Wu, XW; Li, JW; Zhang, Y; Wang, HF; Du, W; He, ZD; Liu, JP; Ruan, T		Payne, TR; Presutti, V; Qi, G; Poveda-Villalon, M; Stoilos, G; Hollink, L; Kaoudi, Z; Cheng, G; Li, J		Wu, Yinan; Wu, Xiaowei; Li, Junwen; Zhang, Yue; Wang, Haofen; Du, Wen; He, Zhidong; Liu, Jingping; Ruan, Tong			MMpedia: A Large-Scale Multi-modal Knowledge Graph	SEMANTIC WEB, ISWC 2023, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	22nd International Semantic Web Conference (ISWC)	NOV 06-10, 2023	Athens, GREECE	Create Link, Zhipu Ai, Bosch, IBM Res, Metaphacts, Google, Gesis, Leibniz Inst Social Sci, Ontotext, Ebay, Huawei, Elsevier, Journal of Artificial Intelligence, Qualco Grp, Bupsolutions		Multi-modal; Knowledge graph; Entity grounding		Knowledge graphs serve as crucial resources for various applications. However, most existing knowledge graphs present symbolic knowledge in the form of natural language, lacking other modal information, e.g., images. Previous multi-modal knowledge graphs have encountered challenges with scaling and image quality. Therefore, this paper proposes a highly-scalable and high-quality multi-modal knowledge graph using a novel pipeline method. Summarily, we first retrieve images from a search engine and build a new Recurrent Gate Multimodal model to filter out the non-visual entities. Then, we utilize entities' textual and type information to remove noisy images of the remaining entities. Through this method, we construct a large-scale multi-modal knowledge graph named MMpedia, containing 2,661,941 entity nodes and 19,489,074 images. As we know, MMpedia has the largest collection of images among existing multi-modal knowledge graphs. Furthermore, we employ human evaluation and downstream tasks to verify the usefulness of images in MMpedia. The experimental result shows that both the state-of-the-art method and multi-modal large language model (e.g., VisualChatGPT) achieve about a 4% improvement on Hit@1 in the entity prediction task by incorporating our collected images. We also find that the multi-modal large language model is hard to ground entities to images. The dataset (https://zenodo.org/record/7816711) and source code of this paper are available at https://github.com/Delicate2000/ MMpedia.	[Wu, Yinan; Wu, Xiaowei; Li, Junwen; Zhang, Yue; Liu, Jingping; Ruan, Tong] East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai, Peoples R China; [Wang, Haofen] Tongji Univ, Coll Design & Innovat, Shanghai, Peoples R China; [Du, Wen; He, Zhidong] DS Informat Technol, Shanghai, Peoples R China	East China University of Science & Technology; Tongji University	Ruan, T (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, Shanghai, Peoples R China.	y21220035@mail.ecust.edu.cn; jingpingliu@ecust.edu.cn; ruantong@ecust.edu.cn			Shanghai Municipal Special Fund for Promoting High-quality Development of Industries [2021-GZL-RGZN-01018]; Shanghai Sailing Program [23YF1409400]	Shanghai Municipal Special Fund for Promoting High-quality Development of Industries; Shanghai Sailing Program	This work was supported by the Shanghai Municipal Special Fund for Promoting High-quality Development of Industries (2021-GZL-RGZN-01018) and the Shanghai Sailing Program (23YF1409400).	Aghaei S, 2022, IEEE ACCESS, V10, P69788, DOI 10.1109/ACCESS.2022.3187178; Alberts H, 2021, Arxiv, DOI arXiv:2008.09150; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Calabrese A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4680; Chen DW, 2021, LECT NOTES COMPUT SC, V12682, P186, DOI 10.1007/978-3-030-73197-7_12; Chen Q, 2022, IEEE INTERNET THINGS, V9, P9205, DOI 10.1109/JIOT.2021.3093065; Chen X, 2023, Arxiv, DOI arXiv:2205.02357; Chen XL, 2013, IEEE I CONF COMP VIS, P1409, DOI 10.1109/ICCV.2013.178; Cheng MJ, 2022, PROC CVPR IEEE, P5174, DOI 10.1109/CVPR52688.2022.00512; Colla D, 2018, COMM COM INF SC, V853, P74, DOI 10.1007/978-3-319-91473-2_7; Corbière C, 2017, IEEE INT CONF COMP V, P2268, DOI 10.1109/ICCVW.2017.266; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ferrada S, 2017, LECT NOTES COMPUT SC, V10588, P84, DOI 10.1007/978-3-319-68204-4_8; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Gao J, 2023, Arxiv, DOI [arXiv:2303.03836, DOI 10.48550/ARXIV.2303.03836]; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendriksen M, 2023, Arxiv, DOI arXiv:2301.05174; Kang HK, 2022, NEUROCOMPUTING, V507, P166, DOI 10.1016/j.neucom.2022.07.079; Kim W, 2021, PR MACH LEARN RES, V139; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134; Li ML, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P77; Li Y., 2021, ACM MULTIMEDIA ASIA, P1; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu C., 2020, CVPR, DOI DOI 10.1109/CVPR42600.2020.01093; Liu Y, 2019, LECT NOTES COMPUT SC, V11503, P459, DOI 10.1007/978-3-030-21348-0_30; Lu JS, 2019, ADV NEUR IN, V32; Mafla Andres, 2021, P IEEE CVF WINT C AP, P2220; Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001; O¤oro-Rubio D, 2019, Arxiv, DOI arXiv:1709.02314; Peng YH, 2020, IEEE DATA MINING, P422, DOI 10.1109/ICDM50108.2020.00051; Radford A, 2021, PR MACH LEARN RES, V139; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Suchanek F.M., 2007, P 16 INT C WORLD WID, P697, DOI 10.1145/1242572.1242667; Sun R, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1405, DOI 10.1145/3340531.3411947; Sun ZQ, 2019, Arxiv, DOI [arXiv:1902.10197, 10.48550/arXiv.1902.10197]; Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802; Tong MH, 2020, AAAI CONF ARTIF INTE, V34, P9040; Trouillon T, 2016, PR MACH LEARN RES, V48; Tsimpoukelli M., 2021, Advances in Neural Information Processing Systems, V34, P200; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang H, 2022, IEEE T MULTIMEDIA, V24, P2515, DOI 10.1109/TMM.2021.3083109; Wang M, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2735, DOI 10.1145/3474085.3475470; Wang M, 2020, BIG DATA RES, V22, DOI 10.1016/j.bdr.2020.100159; Wang XW, 2022, LECT NOTES COMPUT SC, P297, DOI 10.1007/978-3-031-00129-1_24; Wen HY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: DEMONSTRATIONS (NAACL-HLT 2021), P133; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2560; Yang Y, 2022, APPL INTELL, V52, P6196, DOI 10.1007/s10489-021-02647-1; Yao L, 2019, Arxiv, DOI arXiv:1909.03193; Zhao J., 2020, P 37 INT C MACH LEAR, V119, P11365; Zhao Y, 2022, Arxiv, DOI [arXiv:2210.08821, 10.48550/arXiv.2210.08821, DOI 10.48550/ARXIV.2210.08821]; Zheng Chang, 2021, 2021 IEEE International Conference on Multimedia and Expo (ICME), P1, DOI 10.1109/ICME51207.2021.9428362; Zhu XR, 2022, Arxiv, DOI [arXiv:2202.05786, DOI 10.48550/ARXIV.2202.05786]	57	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-47242-8; 978-3-031-47243-5	LECT NOTES COMPUT SC			2023	14266						18	37		10.1007/978-3-031-47243-5_2	http://dx.doi.org/10.1007/978-3-031-47243-5_2			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5HM					2024-07-03	WOS:001160741700002
J	Iannantuono, GM; Bracken-Clarke, D; Karzai, F; Choo-Wosoba, H; Gulley, JL; Floudas, CS				Iannantuono, Giovanni Maria; Bracken-Clarke, Dara; Karzai, Fatima; Choo-Wosoba, Hyoyoung; Gulley, James L.; Floudas, Charalampos S.			Comparison of Large Language Models in Answering Immuno-Oncology Questions: A Cross-Sectional Study	ONCOLOGIST			English	Article; Early Access						large language models; artificial intelligence; immuno-oncology; ChatGPT; Google Bard		Background: The capability of large language models (LLMs) to understand and generate human-readable text has prompted the investigation of their potential as educational and management tools for patients with cancer and healthcare providers. Materials and Methods: We conducted a cross-sectional study aimed at evaluating the ability of ChatGPT-4, ChatGPT-3.5, and Google Bard to answer questions related to 4 domains of immuno-oncology (Mechanisms, Indications, Toxicities, and Prognosis). We generated 60 open-ended questions (15 for each section). Questions were manually submitted to LLMs, and responses were collected on June 30, 2023. Two reviewers evaluated the answers independently. Results: ChatGPT-4 and ChatGPT-3.5 answered all questions, whereas Google Bard answered only 53.3% (P < .0001). The number of questions with reproducible answers was higher for ChatGPT-4 (95%) and ChatGPT3.5 (88.3%) than for Google Bard (50%) (P < .0001). In terms of accuracy, the number of answers deemed fully correct were 75.4%, 58.5%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .03). Furthermore, the number of responses deemed highly relevant was 71.9%, 77.4%, and 43.8% for ChatGPT-4, ChatGPT-3.5, and Google Bard, respectively (P = .04). Regarding readability, the number of highly readable was higher for ChatGPT-4 and ChatGPT-3.5 (98.1%) and (100%) compared to Google Bard (87.5%) (P = .02). Conclusion: ChatGPT-4 and ChatGPT-3.5 are potentially powerful tools in immuno-oncology, whereas Google Bard demonstrated relatively poorer performance. However, the risk of inaccuracy or incompleteness in the responses was evident in all 3 LLMs, highlighting the importance of expert-driven verification of the outputs returned by these technologies.	[Iannantuono, Giovanni Maria; Karzai, Fatima] NCI, Genitourinary Malignancies Branch, Ctr Canc Res, NIH, Bethesda, MD USA; [Bracken-Clarke, Dara; Gulley, James L.; Floudas, Charalampos S.] NCI, Ctr Immunooncol, Ctr Canc Res, NIH, Bethesda, MD USA; [Choo-Wosoba, Hyoyoung] NCI, Biostat & Data Management Sect, Ctr Canc Res, NIH, Bethesda, MD USA	National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI); National Institutes of Health (NIH) - USA; NIH National Cancer Institute (NCI)	Floudas, CS (corresponding author), NCI, Ctr Immunooncol, Ctr Canc Res, Bldg 10,Room 7N240A,10 Ctr Dr, Bethesda, MD 20892 USA.	charalampos.floudas@nih.gov	Gulley, James L/K-4139-2016; Floudas, Charalampos/A-8742-2015	Floudas, Charalampos/0000-0002-0020-237X	Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research	Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research	This work was supported by the Intramural Research Program, National Institutes of Health, National Cancer Institute, Center for Cancer Research. The interpretation and reporting of these data are the sole responsibility of the authors.	Al-Ashwal FY, 2023, DRUG HEALTHC PATIENT, V15, P137, DOI 10.2147/DHPS.S425858; [Anonymous], What is natural language processing?; [Anonymous], 2009, BING; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Darvin P, 2018, EXP MOL MED, V50, DOI 10.1038/s12276-018-0191-1; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Google, Try Bard, an AI experiment by Google; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; IBM, 2023, AI vs. machine learning vs. deep learning vs. neural networks: what's the difference?; IBM, 2021, What is generative AI?; Johnson DB, 2022, NAT REV CLIN ONCOL, V19, P254, DOI 10.1038/s41571-022-00600-w; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; McCarthy J., WHAT IS ARTIFICIAL I; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Meo SA, 2023, J DIABETES SCI TECHN, DOI 10.1177/19322968231203987; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Morreel S, 2023, medRxiv, DOI [10.1101/2023.08.18.23294263, 10.1101/2023.08.18.23294263, DOI 10.1101/2023.08.18.23294263]; OpenAI, WHAT IS CHATGPT; Perplexity AI, Perplexity; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Risk A, 2002, JAMA-J AM MED ASSOC, V287, P2713, DOI 10.1001/jama.287.20.2713; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sullivan RJ, 2022, NAT REV DRUG DISCOV, V21, P495, DOI 10.1038/s41573-021-00259-5; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2; von Elm E, 2007, PLOS MED, V4, P1623, DOI [10.1016/S0140-6736(07)61602-X, 10.1371/journal.pmed.0040297]; Waisberg E, 2024, EYE, V38, P642, DOI 10.1038/s41433-023-02760-0	37	1	1	7	7	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1083-7159	1549-490X		ONCOLOGIST	Oncologist	2024 FEB 3	2024										10.1093/oncolo/oyae009	http://dx.doi.org/10.1093/oncolo/oyae009		FEB 2024	8	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	HA3U7	38309720	Green Submitted, Green Published, gold			2024-07-03	WOS:001156734600001
J	Chuang, YN; Tang, RX; Jiang, XQ; Hu, X				Chuang, Yu-Neng; Tang, Ruixiang; Jiang, Xiaoqian; Hu, Xia			SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Natural language processing; Knowledge representation and information; modeling; Data mining; Machine learning; Clinical research informatics		Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better -informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating instruction prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased performance variance, resulting in significantly distinct summaries even when instruction prompts share similar meanings. To tackle this challenge, we introduce a model -agnostic Soft Prompt-BasedCalibration (SPeC) pipeline that employs soft prompts to lower variance while preserving the advantages of prompt -based summarization. Experimental findings on multiple clinical note tasks and LLMs indicate that our method not only bolsters performance but also effectively regulates variance across different LLMs, providing a more consistent and reliable approach to summarizing critical medical information.	[Chuang, Yu-Neng; Tang, Ruixiang; Hu, Xia] Rice Univ, Houston, TX 77005 USA; [Jiang, Xiaoqian] Univ Texas Hlth Sci Ctr, Houston, TX USA	Rice University; University of Texas System; University of Texas Health Science Center Houston	Chuang, YN; Hu, X (corresponding author), Rice Univ, Houston, TX 77005 USA.	yc146@rice.edu; xia.hu@rice.edu		Jiang, Xiaoqian/0000-0001-9933-2205	CPRIT Scholar in Cancer Research [RR180012]; Christopher Sarofim Family Professorship, UT Stars award; UTHealth startup; National Institute of Health (NIH) [2124789, R01AG066749, R01AG066749-03S1, R01LM013712, R01LM014520, R01AG082721, U01AG 079847, U24LM013755, U01TR002062, U01CA274576, U54HG012510, 1OT2OD032581-02-211, 1OT2OD032581-02-164]; National Science Foundation (NSF) [2124789]	CPRIT Scholar in Cancer Research(Cancer Prevention & Research Institute of Texas); Christopher Sarofim Family Professorship, UT Stars award; UTHealth startup; National Institute of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Science Foundation (NSF)(National Science Foundation (NSF))	XJ is CPRIT Scholar in Cancer Research (RR180012) , and he was supported in part by Christopher Sarofim Family Professorship, UT Stars award, UTHealth startup, the National Institute of Health (NIH) under award number R01AG066749, R01AG066749-03S1, R01LM013712, R01LM014520, R01AG082721, R01AG066749, U01AG 079847, U24LM013755, U01TR002062, U01CA274576, U54HG012510, 1OT2OD032581-02-211, 1OT2OD032581-02-164 and the National Science Foundation (NSF) #2124789.	Arora S, 2022, Arxiv, DOI [arXiv:2210.02441, arXiv:2210.02441]; Cai X., 2021, IEEE Trans. Multimed.; Choi E, 2018, ADV NEUR IN, V31; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Gal Y, 2016, PR MACH LEARN RES, V48; Gershanik Esteban F, 2011, AMIA Annu Symp Proc, V2011, P465; Gupta Vishal, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P258, DOI 10.4304/jetwi.2.3.258-268; Jain R., 2022, arXiv; Johnson A., 2019, PhysioNet, V10, P8360; Kahn CE, 2009, RADIOLOGY, V252, P852, DOI 10.1148/radiol.2523081992; Kim M, 2023, ARXIV; Lakshminarayanan B, 2017, ADV NEUR IN, V30; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin H, 2019, AAAI CONF ARTIF INTE, P9815; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mishra S, 2022, Arxiv, DOI arXiv:2109.07830; OpenAI, 2023, GPT-4 technical report; Pivovarov R, 2015, J AM MED INFORM ASSN, V22, P938, DOI 10.1093/jamia/ocv032; Raffel C, 2020, J MACH LEARN RES, V21; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Vu Tu, 2021, arXiv; Wagner T, 2020, ELIFE, V9, DOI 10.7554/eLife.58227; Wang MQ, 2021, J AM MED INFORM ASSN, V28, P2287, DOI 10.1093/jamia/ocab143; Wang ZF, 2022, Arxiv, DOI [arXiv:2211.01761, 10.48550/arXiv.2211.01761, DOI 10.48550/ARXIV.2211.01761]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068; Yuan JY, 2023, Arxiv, DOI [arXiv:2303.16756, 10.48550/arXiv.2303.16756]; Zhang J., 2019, arXiv; Zhang SH, 2023, Arxiv, DOI arXiv:2303.10794; Zhang YH, 2022, Arxiv, DOI arXiv:2206.04673; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	37	2	2	3	3	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	MAR	2024	151								104606	10.1016/j.jbi.2024.104606	http://dx.doi.org/10.1016/j.jbi.2024.104606		FEB 2024	8	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	LP1U3	38325698	Green Submitted			2024-07-03	WOS:001187921900001
J	Tzachor, A; Devare, M; Richards, C; Pypers, P; Ghosh, A; Koo, J; Johal, S; King, B				Tzachor, A.; Devare, M.; Richards, C.; Pypers, P.; Ghosh, A.; Koo, J.; Johal, S.; King, B.			Large language models and agricultural extension services	NATURE FOOD			English	Review							FRAMEWORK; MEDIA; FOOD	Several factors have traditionally hampered the effectiveness of agricultural extension services, including limited institutional capacity and reach. Here we assess the potential of large language models (LLMs), specifically Generative Pre-trained Transformer (GPT), to transform agricultural extension. We focus on the ability of LLMs to simplify scientific knowledge and provide personalized, location-specific and data-driven agricultural recommendations. We emphasize shortcomings of this technology, informed by real-life testing of GPT to generate technical advice for Nigerian cassava farmers. To ensure a safe and responsible dissemination of LLM functionality across farming worldwide, we propose an idealized LLM design process with human experts in the loop. Agricultural extension services are critical for food security and rural development but face several limitations-particularly in low- and middle-income countries. Based on real-life testing of GPT to generate technical advice for cassava farmers in Nigeria, this Perspective examines the shortcomings of this technology, as well as its potential to transform extension services.	[Tzachor, A.; Richards, C.] Univ Cambridge, CSER, Cambridge, England; [Tzachor, A.] Reichman Univ, Sch Sustainabil, Herzliyya, Israel; [Devare, M.; Pypers, P.] Int Inst Trop Agr IITA, CGIAR, Ibadan, Nigeria; [Richards, C.] Univ Cambridge, Dept Engn, Cambridge, England; [Ghosh, A.] Int Ctr Trop Agr CIAT, CGIAR, Nairobi, Kenya; [Koo, J.] IFPRI, CGIAR, Washington, DC USA; [Johal, S.] Linux Fdn, Agstack Project, San Francisco, CA USA; [King, B.] CGIAR, Digital & Data Innovat Accelerator, Palmira, Colombia	University of Cambridge; Reichman University; CGIAR; International Institute of Tropical Agriculture (IITA); University of Cambridge; Alliance; International Center for Tropical Agriculture - CIAT; CGIAR; CGIAR; International Food Policy Research Institute (IFPRI)	Tzachor, A (corresponding author), Univ Cambridge, CSER, Cambridge, England.; Tzachor, A (corresponding author), Reichman Univ, Sch Sustainabil, Herzliyya, Israel.	atzachor@runi.ac.il	King, Brian/JQW-0424-2023; Koo, Jawoo/F-9397-2010	King, Brian/0000-0002-7056-9214; Pypers, Pieter/0000-0001-8913-0589; Koo, Jawoo/0000-0003-3424-9229; Richards, Catherine/0000-0002-0084-0734	This Perspective was made possible by a grant from Templeton World Charity Foundation. The opinions expressed in this publication are those of the author(s) and do not necessarily reflect the views of Templeton World Charity Foundation.; Templeton World Charity Foundation	This Perspective was made possible by a grant from Templeton World Charity Foundation. The opinions expressed in this publication are those of the author(s) and do not necessarily reflect the views of Templeton World Charity Foundation.; Templeton World Charity Foundation(Templeton World Charity Foundation)	This Perspective was made possible by a grant from Templeton World Charity Foundation. The opinions expressed in this publication are those of the author(s) and do not necessarily reflect the views of Templeton World Charity Foundation.	Alston J. M., 2000, IFPRI Research Report No 113; Anderson J. R., 2007, HDB AGR EC AGR DEV F, V3, P2343, DOI [DOI 10.1016/S1574-0072(06)03044-1, 10.1016/S1574-0072(06)03044-1]; [Anonymous], 2023, Financial Express; [Anonymous], 1998, PERF AUD REP; [Anonymous], ?About us"; [Anonymous], 2021, SCAL TEL DIG TECHN F; Bellon-Maurel V, 2022, AGR SYST, V203, DOI 10.1016/j.agsy.2022.103524; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bergamasco M. P. P., 2016, EVALUATION EXTENSION; Berhanu K, 2014, DEV POLICY REV, V32, pS199, DOI 10.1111/dpr.12082; Chowdhury A, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15064753; Davis K., 2010, 1041 IFPRI, P193; Eastwood C, 2019, J AGR ENVIRON ETHIC, V32, P741, DOI 10.1007/s10806-017-9704-5; Eastwood C, 2019, NJAS-WAGEN J LIFE SC, V90-91, DOI 10.1016/j.njas.2019.04.004; Eberhard DM., 2023, Ethnologue: Languages of the World, V26th ed; Fabregas R, 2019, SCIENCE, V366, P1328, DOI 10.1126/science.aay3038; Fielke S, 2020, AGR SYST, V180, DOI 10.1016/j.agsy.2019.102763; Ingram J, 2020, FRONT SUSTAIN FOOD S, V4, DOI 10.3389/fsufs.2020.00066; Klerkx L, 2021, J AGRIC EDUC EXT, V27, P277, DOI 10.1080/1389224X.2021.1934998; Klerkx L, 2019, NJAS-WAGEN J LIFE SC, V90-91, DOI 10.1016/j.njas.2019.100315; Kothari J.D, 2018, International Journal of Innovative Research in Computer and Communication Engineering, V7, P11082; Labarthe P, 2013, EUROCHOICES, V12, P21, DOI 10.1111/1746-692X.12015; Labarthe P, 2013, FOOD POLICY, V38, P240, DOI 10.1016/j.foodpol.2012.10.005; Lowder SK, 2016, WORLD DEV, V87, P16, DOI 10.1016/j.worlddev.2015.10.041; McCampbell M, 2023, J AGRIC EDUC EXT, V29, P29, DOI 10.1080/1389224X.2021.1984955; Mrisho LM, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.590889; National Agricultural Extension Program (NAEP), 2023, US; Norton GW, 2020, APPL ECON PERSPECT P, V42, P8, DOI 10.1002/aepp.13008; Ochola JN., 2012, J AGRIC EDUC EXT, V18, P2; Prager K, 2017, J RURAL STUD, V56, P1, DOI 10.1016/j.jrurstud.2017.09.002; Radford A., 2018, IMPROVING LANGUAGE U; Rajkhowa P, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259319; Ricciardi V, 2018, GLOB FOOD SECUR-AGR, V17, P64, DOI 10.1016/j.gfs.2018.05.002; Rutatora D.F., 2001, African Monograph, V22, P155, DOI DOI 10.14989/68210; Schaul K., 2023, WASH POST; Steinke J, 2021, INT J AGR SUSTAIN, V19, P549, DOI 10.1080/14735903.2020.1738754; Stilgoe J, 2013, RES POLICY, V42, P1568, DOI 10.1016/j.respol.2013.05.008; Tzachor A, 2022, NAT MACH INTELL, V4, P104, DOI 10.1038/s42256-022-00440-4; Wilkinson Mark D, 2016, Sci Data, V3, P160018, DOI 10.1038/sdata.2016.18; Wiseman L, 2019, NJAS-WAGEN J LIFE SC, V90-91, DOI 10.1016/j.njas.2019.04.007	40	4	4	45	63	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2662-1355		NAT FOOD	Nat. Food	NOV	2023	4	11					941	948		10.1038/s43016-023-00867-x	http://dx.doi.org/10.1038/s43016-023-00867-x		NOV 2023	8	Food Science & Technology	Science Citation Index Expanded (SCI-EXPANDED)	Food Science & Technology	Y8ML4	37932438				2024-07-03	WOS:001095302500001
J	Tuan, NT; Moore, P; Thanh, DHV; Pham, HV				Tuan, Nguyen Trung; Moore, Philip; Thanh, Dat Ha Vu; Pham, Hai Van			A Generative Artificial Intelligence Using Multilingual Large Language Models for ChatGPT Applications	APPLIED SCIENCES-BASEL			English	Article						generative AI; language comprehension; multilingual language models; large language models; support systems; technological determinism; chatbot; ChatGPT	DISRUPTIVE INNOVATION; TECHNOLOGY	ChatGPT plays significant roles in the third decade of the 21st Century. Smart cities applications can be integrated with ChatGPT in various fields. This research proposes an approach for developing large language models using generative artificial intelligence models suitable for small- and medium-sized enterprises with limited hardware resources. There are many generative AI systems in operation and in development. However, the technological, human, and financial resources required to develop generative AI systems are impractical for small- and medium-sized enterprises. In this study, we present a proposed approach to reduce training time and computational cost that is designed to automate question-response interactions for specific domains in smart cities. The proposed model utilises the BLOOM approach as its backbone for using generative AI to maximum the effectiveness of small- and medium-sized enterprises. We have conducted a set of experiments on several datasets associated with specific domains to validate the effectiveness of the proposed model. Experiments using datasets for the English and Vietnamese languages have been combined with model training using low-rank adaptation to reduce training time and computational cost. In comparative experimental testing, the proposed model outperformed the 'Phoenix' multilingual chatbot model by achieving a 92% performance compared to 'ChatGPT' for the English benchmark.	[Tuan, Nguyen Trung] Natl Econ Univ, Sch Informat Technol & Digital Econ, 207 Giai Phong St, Hanoi 10000, Vietnam; [Moore, Philip] Lanzhou Univ, Sch Informat Sci & Engn, Feiyun Bldg,222 Tianshui South Rd, Lanzhou 730030, Peoples R China; [Thanh, Dat Ha Vu; Pham, Hai Van] Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, 1 Dai Co Viet, Hanoi 10000, Vietnam	National Economics University - Vietnam; Lanzhou University; Hanoi University of Science & Technology (HUST)	Pham, HV (corresponding author), Hanoi Univ Sci & Technol, Sch Informat & Commun Technol, 1 Dai Co Viet, Hanoi 10000, Vietnam.	tuannt@neu.edu.vn; ptmbcu@gmail.com; dat.hvthanh@gmail.com; haipv@soict.hust.edu.vn	Moore, Philip Thomas/F-3981-2019	Moore, Philip Thomas/0000-0003-3874-8981; Tuan, Nguyen Trung/0000-0003-3249-2444	National Economics University, Vietnam	National Economics University, Vietnam	The authors thank the language experts who participated in the experiments using ChatGPT in both English and Vietnamese languages.	Aghajanyan A, 2020, Arxiv, DOI arXiv:2012.13255; Alabool Hamzeh Mohammad, 2023, 2023 International Conference on Information Technology (ICIT), P184, DOI 10.1109/ICIT58056.2023.10225801; Ayoola O.O., 2023, BizEcons Quarterly, V16, P1; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Beeching E., 2023, Open llm leaderboard; Checkland P., 1997, INFORM SYSTEMS INFOR; Chen W.K., 2021, P 2021 IEEE INT C SO, P1, DOI [10.1109/SSIM49526.2021.9555195, DOI 10.1109/SSIM49526.2021.9555195]; Chen ZH, 2023, Arxiv, DOI arXiv:2304.10453; Christensen C., 2013, Disruptive innovation; Christensen CM, 2018, J MANAGE STUD, V55, P1043, DOI 10.1111/joms.12349; Clarysse B, 2022, TECHNOVATION, V118, DOI 10.1016/j.technovation.2022.102644; Crosthwaite P., 2023, Applied Corpus Linguistics, V3, DOI DOI 10.1016/J.ACORP.2023.100066; Cuong L.A., 2023, Challenge on Vietnamese Large Language Models 2023 2023; Dai Yun, 2023, Procedia CIRP, P84, DOI 10.1016/j.procir.2023.05.002; Deqiang Xin, 2010, 2010 International Conference on E-Business and E-Government (ICEE 2010), P149, DOI 10.1109/ICEE.2010.45; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Espejel J.L., 2023, Nat. Lang. Process. J, V5, P100032, DOI DOI 10.1016/J.NLP.2023.100032; Fleck J, 2001, TECHNOL ANAL STRATEG, V13, P523; Hagendorff T, 2023, NAT COMPUT SCI, V3, P833, DOI 10.1038/s43588-023-00527-x; Pham HV, 2023, J INTELL FUZZY SYST, V44, P6775, DOI 10.3233/JIFS-221556; Hallström J, 2022, INT J TECHNOL DES ED, V32, P17, DOI 10.1007/s10798-020-09600-2; Han SJ, 2024, COGN SYST RES, V83, DOI 10.1016/j.cogsys.2023.101155; Hanief S, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P12; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Kohnke L., 2023, Computers and Education Artificial Intelligence, V5, P100156, DOI [10.1016/j.caeai.2023.100156, DOI 10.1016/J.CAEAI.2023.100156]; Kunst JR, 2023, INT J INTERCULT REL, V97, DOI 10.1016/j.ijintrel.2023.101888; Laurencon H., 2022, Advances in Neural Information Processing Systems, V35, P31809; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li MC, 2023, J RETAIL CONSUM SERV, V71, DOI 10.1016/j.jretconser.2022.103209; Li RY, 2018, PROCEEDINGS OF THE 2018 1ST IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE INNOVATION AND INVENTION (ICKII 2018), P362, DOI 10.1109/ICKII.2018.8569132; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Lybaert C, 2022, LANG COMMUN, V84, P1, DOI 10.1016/j.langcom.2022.01.004; Mackenzie D, 2023, ENGINEERING-PRC, V25, P9, DOI 10.1016/j.eng.2023.04.004; Marjanovic Olivera, 2007, 2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007), P448, DOI 10.1109/COLCOM.2007.4553874; Markides C, 2006, J PROD INNOVAT MANAG, V23, P19, DOI 10.1111/j.1540-5885.2005.00177.x; Martínez-Plumed F, 2021, TELEMAT INFORM, V58, DOI 10.1016/j.tele.2020.101525; Moslein K.M., 2015, Wiley Encyclopedia of Management, P1, DOI [10.1002/9781118785317.weom120036, DOI 10.1002/9781118785317.WEOM120036]; Nazir Anam, 2023, Meta Radiol, V1, DOI 10.1016/j.metrad.2023.100022; Nguyen DQ, 2024, Arxiv, DOI arXiv:2311.02945; Nguyen XP, 2023, Arxiv, DOI [arXiv:2312.00738, 10.48550/arXiv.2312, DOI 10.48550/ARXIV.2312]; Pham HV, 2023, INT J FUZZY SYST, V25, P3260, DOI 10.1007/s40815-023-01548-4; Pham HV, 2023, J ARTIF INTELL SOFT, V13, P165, DOI 10.2478/jaiscr-2023-0013; Pham V.H., 2022, P INT C INNOVATIVE C, VVolume 471, DOI [10.1007/978-981-19-2535-1_22, DOI 10.1007/978-981-19-2535-1_22]; Puranam P, 2014, ACAD MANAGE REV, V39, P162, DOI 10.5465/amr.2011.0436; Ren J, 2021, Arxiv, DOI [arXiv:2101.06840, 10.48550/arXiv.2101.06840]; Saetra HS, 2023, TECHNOL SOC, V75, DOI 10.1016/j.techsoc.2023.102372; Sandrini L, 2023, ECON LETT, V232, DOI 10.1016/j.econlet.2023.111317; Smith Noah A, 2021, arXiv; Sun XH, 2023, Arxiv, DOI arXiv:2304.08109; Taori R., 2023, Stanford Alpaca: A Strong, Replicable Instruction-Following Model; Thomas AM, 2014, INT J AD HOC UBIQ CO, V16, P268, DOI 10.1504/IJAHUC.2014.064862; Thomas RL, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100476; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Utterback JM, 2005, INT J INNOV MANAG, V9, P1, DOI 10.1142/S1363919605001162; Varghese Julian, 2024, J Hepatol, V80, P977, DOI 10.1016/j.jhep.2023.07.028; Wamba SF, 2023, INT J PROD ECON, V265, DOI 10.1016/j.ijpe.2023.109015; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wyatt S, 2007, HANDBOOK OF SCIENCE AND TECHNOLOGY STUDIES, THIRD EDITION, P165; Yilmaz R., 2023, Computers and Education: Artificial Intelligence, V4, DOI DOI 10.1016/J.CAEAI.2023.100147; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685	61	0	0	17	17	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	7							3036	10.3390/app14073036	http://dx.doi.org/10.3390/app14073036			24	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	NN2D7		gold			2024-07-03	WOS:001201056200001
J	Luo, H				Luo, Hubert			Improving NHL draft outcome predictions using scouting reports	JOURNAL OF QUANTITATIVE ANALYSIS IN SPORTS			English	Article; Early Access						machine learning; LLM; hockey		We leverage Large Language Models (LLMs) to extract information from scouting report texts and improve predictions of National Hockey League (NHL) draft outcomes. In parallel, we derive statistical features based on a player's on-ice performance leading up to the draft. These two datasets are then combined using ensemble machine learning models. We find that both on-ice statistics and scouting reports have predictive value, however combining them leads to the strongest results.	[Luo, Hubert] Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA; [Luo, Hubert] Lazard, Data Analyt Grp, Toronto, ON, Canada	University of Texas System; University of Texas Austin	Luo, H (corresponding author), Univ Texas Austin, Dept Comp Sci, Austin, TX 78712 USA.; Luo, H (corresponding author), Lazard, Data Analyt Grp, Toronto, ON, Canada.	hubertluo@utexas.edu						Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Berri DJ, 2011, J PROD ANAL, V35, P25, DOI 10.1007/s11123-010-0187-x; Chann S., 2023, Non-Determinism in GPT-4 Is Caused by Sparse MoE; Chen B., 2023, Unleashing the potential of prompt engineering in large language models: a comprehensive review; Deaner RO, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057753; Desjardins G., 2005, Behind the net; Jones L., 2023, 31 C NEUR INF PROC S; Lopez-Lira A, 2023, Arxiv, DOI arXiv:2304.07619; Luszczyszyn D., 2023, The Athletic; Manning C.D., 2008, Introduction to information retrieval; Nandakumar N, 2019, ANNU REV STAT APPL, V6, P19, DOI 10.1146/annurev-statistics-030718-105202; Schuckers M., 2011, Whats an nhl draft pick worth? A value pick chart for the national hockey league; Schuckers M., 2016, MIT sloan sports analytics conference; Schuckers M, 2011, J QUANT ANAL SPORTS, V7, DOI 10.2202/1559-0410.1329; Seppa T., 2017, Ottawa hockey analytics conference; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Tang Y., 2024, arXiv; Tu T., 2022, Proceedings of the 2nd machine learning for health symposium, volume 193 of proceedings of machine learning research, P343; Turtoro C., 2020, Network nhl equivalences (nnhle); Wheeler S., 2023, The Athletic; Wolfson J, 2011, J QUANT ANAL SPORTS, V7, DOI 10.2202/1559-0410.1302; Yejia Liu, 2019, Machine Learning and Data Mining for Sports Analytics. 5th International Workshop, MLSA 2018 Co-located with ECML/PKDD 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11330), P93, DOI 10.1007/978-3-030-17274-9_8	22	0	0	0	0	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6388	1559-0410		J QUANT ANAL SPORTS	J. Quant. Anal. Sports	2024 JUN 26	2024										10.1515/jqas-2024-0047	http://dx.doi.org/10.1515/jqas-2024-0047		JUN 2024	19	Social Sciences, Mathematical Methods	Emerging Sources Citation Index (ESCI)	Mathematical Methods In Social Sciences	WH4Y8					2024-07-03	WOS:001253978100001
C	Othman, A; Dhouib, A; Al Jabor, AN			ACM	Othman, Achraf; Dhouib, Amira; Al Jabor, Aljazi Nasser			Fostering websites accessibility: A case study on the use of the Large Language Models ChatGPT for automatic remediation	PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023			English	Proceedings Paper	16th ACM International Conference on Pervasive Technologies Related to Assistive Environments (PETRA)	JUL 05-07, 2023	Corfu, GREECE	Assoc Comp Machinery, ICPS Digital Libraries, Univ Texas Arlington, Coll Engn, Natl Sci Fdn, Univ Texas Arlington, Dept Comp Sci & Engn, Univ Texas Arlington, Human Centered Comp Lab, Univ Texas Arlington, iPerform Ind Univ NSF Ctr, Natl Ctr Sci Res, Ionian Univ, Technologies Journal		Web accessibility; Large Language Models; ChatGPT; Digital Accessibility	WEB ACCESSIBILITY	The use of automated accessibility testing tools remains a common practice for evaluating web accessibility. However, the results obtained from these tools may not always provide a comprehensive and complete view of a site's accessibility status. The main purpose of this study is to improve web accessibility by automatically remediating non-accessible ones using Large Language Models (LLM), particularly ChatGPT. The effectiveness of the used model in detecting and remediating accessibility issues to ensure compliance with the Web Content Accessibility Guidelines (WCAG 2.1) is also discussed. By using ChatGPT as a remediation tool, this study investigates the potential of LLM in improving web accessibility. In the case study, two websites that did not adhere to the WCAG 2.1 guidelines were selected as the primary experimental subjects for the study. These websites were assessed using the web accessibility evaluation tool, WAVE, to detect accessibility issues. The identified issues served then as the basis for remediation using ChatGPT. The effectiveness of the used advanced language model as a web accessibility remediation tool was evaluated by comparing its findings with those obtained from manual accessibility testing. The results of this comparison have significant implications for stakeholders involved in achieving WCAG compliance and contribute to the development of more accessible online platforms for individuals with disabilities.	[Othman, Achraf; Dhouib, Amira; Al Jabor, Aljazi Nasser] Mada Qatar Assist Technol Ctr, Doha, Qatar		Othman, A (corresponding author), Mada Qatar Assist Technol Ctr, Doha, Qatar.	aothman@mada.org.qa; adhouib@mada.org.qa; aaljabor@mada.org.qa	Dhouib, Dr. Amira/KSM-6048-2024	Dhouib, Dr. Amira/0000-0002-8464-4561; Othman, Achraf/0000-0003-1290-2098				Abu Doush I, 2023, CCF T PERVAS COMPUT, V5, P288, DOI 10.1007/s42486-023-00127-8; Abuaddous HY, 2016, INT J ADV COMPUT SC, V7, P172; Al jabor Aljazi Nasser, 2021, 2021 8th International Conference on ICT Accessibility (ICTA)., DOI 10.1109/ICTA54582.2021.9809423; [Anonymous], Web Content Accessibility Guidelines; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; British Airways, about us; Brophy P, 2007, LIBR TRENDS, V55, P950; Dhouib A, 2023, UNIVERSAL ACCESS INF, V22, P415, DOI 10.1007/s10209-021-00850-y; Kuzma J., 2009, Global e-government web accessibility: An empirical examination of EU, Asian and African sites; Lazar J, 2004, COMPUT HUM BEHAV, V20, P269, DOI 10.1016/j.chb.2003.10.018; openai, INTR CHATGPT; Othman A, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15043853; Paris M., 2006, Universal Access in the Information Society, V4, P292, DOI 10.1007/s10209-003-0081-7; Qatar Airways, about us; Richards J.T., 2004, PROC 13 INT C WORLD, P72, DOI DOI 10.1145/988672.988683; webaim, WAVE Web Accessibility Evaluation Tools; Yesilada Y., 2012, P CROSS DISC C WEB A, P1	17	3	3	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0069-9				2023							707	713		10.1145/3594806.3596542	http://dx.doi.org/10.1145/3594806.3596542			7	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2SR					2024-07-03	WOS:001124478300114
J	Berragan, C; Singleton, A; Calafiore, A; Morley, J				Berragan, Cillian; Singleton, Alex; Calafiore, Alessia; Morley, Jeremy			Mapping Great Britain's semantic footprints through a large language model analysis of Reddit comments	COMPUTERS ENVIRONMENT AND URBAN SYSTEMS			English	Article						Vernacular geography; Semantics; Social media; Natural language processing	INFORMATION	Observed regional variation in geotagged social media text is often attributed to dialects, where features in language are assumed to exhibit region-specific properties. While dialects are seen as a key component in defining the identity of regions, there are a multitude of other geographic properties that may be captured within natural language text. In our work, we consider locational mentions that are directly embedded within comments on the social media website Reddit, providing a range of associated semantic information, and enabling deeper representations between locations to be captured. Using a large corpus of geoparsed Reddit comments from UKrelated local discussion subreddits, we first extract embedded semantic information using a large language model, aggregated into local authority districts, representing the semantic footprint of these regions. These footprints broadly exhibit spatial autocorrelation, with clusters that conform with the national borders of Wales and Scotland. London, Wales, and Scotland also demonstrate notably different semantic footprints compared with the rest of Great Britain.	[Berragan, Cillian; Singleton, Alex] Univ Liverpool, Geog Data Sci Lab, Liverpool, England; [Calafiore, Alessia] Univ Edinburgh, Edinburgh Coll Art, Edinburgh, Scotland; [Morley, Jeremy] Ordnance Survey, Southampton, England	University of Liverpool; Edinburgh College of Art; University of Edinburgh	Berragan, C (corresponding author), Univ Liverpool, Geog Data Sci Lab, Liverpool, England.	c.berragan@liverpool.ac.uk; ucfnale@liverpool.ac.uk; acalafio@ed.ac.uk; jeremy.morley@os.uk		Berragan, Cillian/0000-0003-2198-2245	Economic and Social Research Council [ES/P000401/1]	Economic and Social Research Council(UK Research & Innovation (UKRI)Economic & Social Research Council (ESRC))	<BOLD>Funding</BOLD> This work was supported by the Economic and Social Research Council (ES/P000401/1) .	Allaoui M., 2020, IMAGE SIGNAL PROCESS, P317, DOI 10.1007/978-3-030-51935-3_34; [Anonymous], 2022, MOST POPULAR SOCIAL; ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x; Arthur R, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214466; Bailey M, 2018, J ECON PERSPECT, V32, P259, DOI 10.1257/jep.32.3.259; Baumgartner J, 2020, Arxiv, DOI arXiv:2001.08435; Berragan C, 2024, T I BRIT GEOGR, DOI 10.1111/tran.12669; Berragan C, 2023, INT J GEOGR INF SCI, V37, P747, DOI 10.1080/13658816.2022.2133125; Buttimer Anne., 2015, The Human Experience of Space and Place, P166; Carman C.J., 2014, MORE SCOTTISH BRIT 2; Chambers J. K., 1998, Dialectology., V2nd, P57, DOI [10.1017/CBO9780511805103.007, DOI 10.1017/CBO9780511805103.007]; Chen M.., 2019, Understanding the dynamics of urban areas of interest through volunteered geographic information, V21, DOI [10.1007/s10109-018-0284-3, DOI 10.1007/S10109-018-0284-3]; CLOKE Paul., 2005, Spaces of geographical thought: deconstructing human geography's binaries; Deacon B., 2007, The International Journal of Regional and Local Studies, V3, P5, DOI DOI 10.1179/JRL.2007.3.1.5; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doyle G., 2014, P 14 C EUR CHAPT ASS, P98, DOI DOI 10.3115/V1/E14-1011; Eisenstein J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0113114; Evans A. J., 2007, International Journal of Technology, Policy and Management, V7, P134, DOI 10.1504/IJTPM.2007.014547; Fenton T., 2018, Regional economic activity by gross value added (balanced); Gao S, 2017, INT J GEOGR INF SCI, V31, P1245, DOI 10.1080/13658816.2016.1273357; Gonçalves B, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112074; Goodchild M. F., 2011, Formalizing space and place.; Grace R., 2018, Identifying Actionable Information on Social Media for Emergency Dispatch, P11; Griffiths JD, 2022, PUBLIUS J FEDERALISM, V53, P133, DOI 10.1093/publius/pjac011; Haesly Richard., 2005, Nations and Nationalism, V11, P243, DOI DOI 10.1111/J.1354-5078.2005.00202.X; Han B., 2012, Geolocation prediction in social media data by finding location indicative words, P18; Han JL, 2018, IEEE T KNOWL DATA EN, V30, P59, DOI 10.1109/TKDE.2017.2758780; Hirsch D., 2016, London weighting and London costs-a fresh approach?.; Hollenstein L., 2008, Capturing vernacular geography from georeferenced tags.; Hu S, 2020, COMPUT ENVIRON URBAN, V80, DOI 10.1016/j.compenvurbsys.2019.101442; Huang Y, 2016, COMPUT ENVIRON URBAN, V59, P244, DOI 10.1016/j.compenvurbsys.2015.12.003; Jewell H.M., 1994, N S DIVIDE ORIGINS N; Jurafsky Daniel, 2007, Speech and language processing: An introduction to natural language processing, computational linguistics, and speech recognition; Knowles G., 1973, SCOUSE URBAN DIALECT; Lambiotte R, 2008, PHYSICA A, V387, P5317, DOI 10.1016/j.physa.2008.05.014; Lengyel B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137248; Li ZL, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94300-7; Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2; Llamas C., 2009, Language and identities; Llamas C, 2014, LANG LINGUIST COMPAS, V8, P610, DOI 10.1111/lnc3.12109; MacKenzie L., 2022, Journal of Linguistic Geography, V10, P46, DOI [10.1017/jlg.2022.2, DOI 10.1017/JLG.2022.2]; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Middleton C.., 2008, The impact of culture-led regeneration on regional identity in north East England; Murphy N., 2019, Reddit's 2019 year in review-upvoted; Oguz S., 2022, Productivity in towns and travel to work areas.; Paasi A, 2003, PROG HUM GEOG, V27, P475, DOI 10.1191/0309132503ph439pr; P‚rez JM, 2019, Arxiv, DOI arXiv:1907.04492; Purves RS, 2019, J ASSOC INF SCI TECH, V70, P1173, DOI 10.1002/asi.24194; Rae A, 2009, COMPUT ENVIRON URBAN, V33, P161, DOI 10.1016/j.compenvurbsys.2009.01.007; Ratti C, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0014248; Reades J, 2009, ENVIRON PLANN B, V36, P824, DOI 10.1068/b34133t; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rey S., 2023, GEOGRAPHIC DATA SCI; Russ B., 2012, EXAMINING LARGE SCAL; Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796; Sobolevsky S, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081707; Stuart-Smith J, 2008, VARIETIES OF ENGLISH 1: THE BRITISH ISLES, P48; Sui D, 2011, INT J GEOGR INF SCI, V25, P1737, DOI 10.1080/13658816.2011.604636; Thomas MJ, 2019, POPUL SPACE PLACE, V25, DOI 10.1002/psp.2233; Titheridge H., 2009, Journal of Transport and Land Use, V2, P31, DOI DOI 10.5198/JTLU.V2I2.44; Trudgill P., 2004, Dialects., V2nd, DOI [10.4324/9780203314609, DOI 10.4324/9780203314609]; Wagner D., 2020, Place in the GIScience community-An indicative and preliminary systematic literature review, DOI [10.5281/zenodo.3628855, DOI 10.5281/ZENODO.3628855]; Walden-Schreiner C, 2018, APPL GEOGR, V90, P44, DOI 10.1016/j.apgeog.2017.11.004; Waters T., 2003, Fuzzy"vernacular geography, V10; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Westerholt R., 2018, INTR PLATIAL 18 WORK, DOI [10.5281/zenodo.1475267, DOI 10.5281/ZENODO.1475267]; Yin WP, 2017, Arxiv, DOI arXiv:1702.01923; Zheng X, 2018, IEEE T KNOWL DATA EN, V30, P1652, DOI 10.1109/TKDE.2018.2807840; Zheng Y, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2743025	70	0	0	0	0	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0198-9715	1873-7587		COMPUT ENVIRON URBAN	Comput. Environ. Urban Syst.	JUN	2024	110								102121	10.1016/j.compenvurbsys.2024.102121	http://dx.doi.org/10.1016/j.compenvurbsys.2024.102121			12	Computer Science, Interdisciplinary Applications; Engineering, Environmental; Environmental Studies; Geography; Operations Research & Management Science; Regional & Urban Planning	Social Science Citation Index (SSCI)	Computer Science; Engineering; Environmental Sciences & Ecology; Geography; Operations Research & Management Science; Public Administration	SN5H6					2024-07-03	WOS:001235139000001
J	Deiner, MS; Deiner, NA; Hristidis, V; Mcleod, S; Doan, T; Lietman, TM; Porco, TC				Deiner, Michael S.; Deiner, Natalie A.; Hristidis, Vagelis; Mcleod, Stephen; Doan, Thuy; Lietman, Thomas M.; Porco, Travis C.			Use of Large Language Models to Assess the Likelihood of Epidemics From the Content of Tweets: Infodemiology Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						conjunctivitis; microblog; social media; generative large language model; Generative Pre-trained Transformers; GPT-3.5; GPT-4; epidemic detection; Twitter; X formerly known as Twitter; infectious eye disease	SOCIAL MEDIA; CONJUNCTIVITIS; OUTBREAK; TWITTER; ISLAND; COSTS	Background: Previous work suggests that Google searches could be useful in identifying conjunctivitis epidemics. Content -based assessment of social media content may provide additional value in serving as early indicators of conjunctivitis and other systemic infectious diseases. Objective: We investigated whether large language models, specifically GPT-3.5 and GPT-4 (OpenAI), can provide probabilistic assessments of whether social media posts about conjunctivitis could indicate a regional outbreak. Methods: A total of 12,194 conjunctivitis -related tweets were obtained using a targeted Boolean search in multiple languages from India, Guam (United States), Martinique (France), the Philippines, American Samoa (United States), Fiji, Costa Rica, Haiti, and the Bahamas, covering the time frame from January 1, 2012, to March 13, 2023. By providing these tweets via prompts to GPT-3.5 and GPT-4, we obtained probabilistic assessments that were validated by 2 human raters. We then calculated Pearson correlations of these time series with tweet volume and the occurrence of known outbreaks in these 9 locations, with time series bootstrap used to compute CIs. Results: Probabilistic assessments derived from GPT-3.5 showed correlations of 0.60 (95% CI 0.47-0.70) and 0.53 (95% CI 0.40-0.65) with the 2 human raters, with higher results for GPT-4. The weekly averages of GPT-3.5 probabilities showed substantial correlations with weekly tweet volume for 44% (4/9) of the countries, with correlations ranging from 0.10 (95% CI 0.0-0.29) to 0.53 (95% CI 0.39-0.89), with larger correlations for GPT-4. More modest correlations were found for correlation with known epidemics, with substantial correlation only in American Samoa (0.40, 95% CI 0.16-0.81). Conclusions: These findings suggest that GPT prompting can efficiently assess the content of social media posts and indicate possible disease outbreaks to a degree of accuracy comparable to that of humans. Furthermore, we found that automated content analysis of tweets is related to tweet volume for conjunctivitis -related posts in some locations and to the occurrence of actual epidemics. Future work may improve the sensitivity and specificity of these methods for disease outbreak detection.	[Deiner, Michael S.; Mcleod, Stephen; Doan, Thuy; Lietman, Thomas M.; Porco, Travis C.] Univ Calif San Francisco, Dept Ophthalmol, San Francisco, CA 94143 USA; [Deiner, Michael S.; Mcleod, Stephen; Doan, Thuy; Lietman, Thomas M.; Porco, Travis C.] Univ Calif San Francisco, Francis I Proctor Fdn Res Ophthalmol, 490 Illinois St,Box 0944, San Francisco, CA 94143 USA; [Deiner, Natalie A.] Univ Calif Santa Barbara, Coll Letters & Sci, Santa Barbara, CA USA; [Hristidis, Vagelis] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA USA; [Mcleod, Stephen] Amer Acad Ophthalmol, San Francisco, CA USA; [Doan, Thuy; Lietman, Thomas M.; Porco, Travis C.] Univ Calif San Francisco, Dept Epidemiol & Biostat, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; University of California System; University of California Santa Barbara; University of California System; University of California Riverside; University of California System; University of California San Francisco	Porco, TC (corresponding author), Univ Calif San Francisco, Francis I Proctor Fdn Res Ophthalmol, 490 Illinois St,Box 0944, San Francisco, CA 94143 USA.	travis.porco@ucsf.edu		Lietman, Thomas/0000-0001-8216-0240; Doan, Thuy/0000-0003-2733-8370; Christidis, Evangelos/0000-0001-8905-2832	National Eye Institute of the National Institutes of Health [1R01EY024608-01A1]; Core Grant for Vision Research from the National Eye Institute [EY002162]; Research to Prevent Blindness	National Eye Institute of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); Core Grant for Vision Research from the National Eye Institute; Research to Prevent Blindness(Research to Prevent Blindness (RPB))	This work was supported in part by a grant from the National Eye Institute of the National Institutes of Health (1R01EY024608-01A1; Principal Investigator [PI] : TML) , a Core Grant for Vision Research from the National Eye Institute (EY002162; PI: Erik M Ullian) , and an Unrestricted Grant from Research to Prevent Blindness (PI: JLD) . The funding organizations had no role in the design or conduct of this research. The authors gratefully acknowledge the contributions of the 2 human raters used in the validation of the large language model responses. The subject of the paper concerns analysis of the results of generative artificial intelligence (AI) -where we studied the use of the generative AI tools GPT-3.5 and GPT-4 (OpenAI) for LLM-based analyses of social media posts. Generative AI was not used in ideation, or manuscript writing, or preparation, other than for assistance from GPT-3.5 in helping us to refine the R code to improve the formatting of the figures and some tables.	Aiello AE, 2020, ANNU REV PUBL HEALTH, V41, P101, DOI 10.1146/annurev-publhealth-040119-094402; Al-Garadi MA, 2016, J BIOMED INFORM, V62, P1, DOI 10.1016/j.jbi.2016.05.005; [Anonymous], With new COVID-19 strain confirmed in Los Angeles county, residents advised to be aware of symptoms, take precautions; [Anonymous], ChatGPT; [Anonymous], Outbreak of extensively drug-resistant Pseudomonas aeruginosa associated with artificial tears; Aslam AA, 2014, J MED INTERNET RES, V16, DOI 10.2196/jmir.3532; Canaparo Marco, 2023, Healthc Anal (N Y), V3, P100172, DOI 10.1016/j.health.2023.100172; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Cumberland PM, 2014, BRIT J OPHTHALMOL, V98, P841, DOI 10.1136/bjophthalmol-2014-304930; Deiner MS, 2019, OPHTHALMOLOGY, V126, P1219, DOI 10.1016/j.ophtha.2019.04.008; Deiner MS, 2018, INVEST OPHTH VIS SCI, V59, P910, DOI 10.1167/iovs.17-22818; Deiner MS, 2016, JAMA OPHTHALMOL, V134, P1024, DOI 10.1001/jamaophthalmol.2016.2267; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Eysenbach G, 2009, J MED INTERNET RES, V11, DOI 10.2196/jmir.1157; Fagherazzi G, 2020, J MED INTERNET RES, V22, DOI 10.2196/19284; Filleul L, 2018, EMERG INFECT DIS, V24, P168, DOI 10.3201/eid2401.170916; Gao W, 2023, WORLD WIDE WEB, V26, P55, DOI 10.1007/s11280-022-01034-1; Gupta A, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103500; Honcharov V, 2023, JMIR INFODEMIOL, V3, DOI 10.2196/40575; Joshi A, 2020, EPIDEMIOLOGY, V31, P90, DOI 10.1097/EDE.0000000000001133; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kass-Hout TA, 2013, BRIT MED BULL, V108, P5, DOI 10.1093/bmb/ldt028; King D, 2013, MMWR-MORBID MORTAL W, V62, P637; Kreiss JP, 2012, HANDB STAT, V30, P3, DOI 10.1016/B978-0-444-53858-1.00001-6; Lalitha P, 2022, J CLIN VIROL, V157, DOI 10.1016/j.jcv.2022.105318; Lernout T, 2012, EUROSURVEILLANCE, V17, P8; Mason S, 2022, RES ETHICS-UK, V18, P93, DOI 10.1177/17470161221076948; Nagar R, 2014, J MED INTERNET RES, V16, P260, DOI 10.2196/jmir.3416; National Notifiable Diseases Surveillance System (NNDSS), Centers for Disease Control and Prevention; Ohta K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50369; Pepose JS, 2020, CLIN OPHTHALMOL, V14, P377, DOI 10.2147/OPTH.S233486; Pilipiec P, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0282101; Prajna NV, 2022, J CLIN VIROL, V157, DOI 10.1016/j.jcv.2022.105300; Rosol M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-46995-z; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Saito R, 2023, J COMPUT SOC SCI, V6, P359, DOI 10.1007/s42001-022-00186-4; Sano Y, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0285101; Sharpe J Danielle, 2016, JMIR Public Health Surveill, V2, pe161; Sié A, 2018, AM J TROP MED HYG, V99, P229, DOI 10.4269/ajtmh.17-0642; Sinnenberg L, 2017, AM J PUBLIC HEALTH, V107, pE1, DOI 10.2105/AJPH.2016.303512; Tsui E, 2019, OPHTHALMOLOGY, V126, P779, DOI 10.1016/j.ophtha.2019.02.015; Vashishtha VM, 2023, medRxiv, DOI [10.1101/2023.04.18.23288715, 10.1101/2023.04.18.23288715, DOI 10.1101/2023.04.18.23288715]; Wakamiya S, 2018, JMIR PUBLIC HLTH SUR, V4, P41, DOI 10.2196/publichealth.8627; Zhang L, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8030307; Zhang YM, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116882	45	0	0	5	5	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAR 1	2024	26								e49139	10.2196/49139	http://dx.doi.org/10.2196/49139			16	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	KY5Y5	38427404	Green Published, gold			2024-07-03	WOS:001183554400001
J	Toufiq, M; Rinchai, D; Bettacchioli, E; Kabeer, BSA; Khan, T; Subba, B; White, O; Yurieva, M; George, J; Jourde-Chiche, N; Chiche, L; Palucka, K; Chaussabel, D				Toufiq, Mohammed; Rinchai, Darawan; Bettacchioli, Eleonore; Kabeer, Basirudeen Syed Ahamed; Khan, Taushif; Subba, Bishesh; White, Olivia; Yurieva, Marina; George, Joshy; Jourde-Chiche, Noemie; Chiche, Laurent; Palucka, Karolina; Chaussabel, Damien			Harnessing large language models (LLMs) for candidate gene prioritization and selection	JOURNAL OF TRANSLATIONAL MEDICINE			English	Article						Transcriptomics; Erythroid cells; Feature selection; Large language models; Generative artificial intelligence	CARBONIC-ANHYDRASE II; HUMAN RED-CELLS; ERYTHROID-CELLS; EXPRESSION; CANCER; FERROCHELATASE; TRANSPORT; SYNTHASE; BICARBONATE; INHIBITORS	BackgroundFeature selection is a critical step for translating advances afforded by systems-scale molecular profiling into actionable clinical insights. While data-driven methods are commonly utilized for selecting candidate genes, knowledge-driven methods must contend with the challenge of efficiently sifting through extensive volumes of biomedical information. This work aimed to assess the utility of large language models (LLMs) for knowledge-driven gene prioritization and selection.MethodsIn this proof of concept, we focused on 11 blood transcriptional modules associated with an Erythroid cells signature. We evaluated four leading LLMs across multiple tasks. Next, we established a workflow leveraging LLMs. The steps consisted of: (1) Selecting one of the 11 modules; (2) Identifying functional convergences among constituent genes using the LLMs; (3) Scoring candidate genes across six criteria capturing the gene's biological and clinical relevance; (4) Prioritizing candidate genes and summarizing justifications; (5) Fact-checking justifications and identifying supporting references; (6) Selecting a top candidate gene based on validated scoring justifications; and (7) Factoring in transcriptome profiling data to finalize the selection of the top candidate gene.ResultsOf the four LLMs evaluated, OpenAI's GPT-4 and Anthropic's Claude demonstrated the best performance and were chosen for the implementation of the candidate gene prioritization and selection workflow. This workflow was run in parallel for each of the 11 erythroid cell modules by participants in a data mining workshop. Module M9.2 served as an illustrative use case. The 30 candidate genes forming this module were assessed, and the top five scoring genes were identified as BCL2L1, ALAS2, SLC4A1, CA1, and FECH. Researchers carefully fact-checked the summarized scoring justifications, after which the LLMs were prompted to select a top candidate based on this information. GPT-4 initially chose BCL2L1, while Claude selected ALAS2. When transcriptional profiling data from three reference datasets were provided for additional context, GPT-4 revised its initial choice to ALAS2, whereas Claude reaffirmed its original selection for this module.ConclusionsTaken together, our findings highlight the ability of LLMs to prioritize candidate genes with minimal human intervention. This suggests the potential of this technology to boost productivity, especially for tasks that require leveraging extensive biomedical knowledge.	[Toufiq, Mohammed; Khan, Taushif; Subba, Bishesh; White, Olivia; Yurieva, Marina; George, Joshy; Palucka, Karolina; Chaussabel, Damien] Jackson Lab Genom Med, Farmington, CT 06032 USA; [Rinchai, Darawan] Rockefeller Univ, New York, NY USA; [Bettacchioli, Eleonore] Univ Bretagne Occidentale, INSERM UMR1227, Lymphocytes B & Autoimmunite, Brest, France; [Bettacchioli, Eleonore] CHU Brest, Serv Rhumatol, Brest, France; [Kabeer, Basirudeen Syed Ahamed] Sidra Med, Doha, Qatar; [Jourde-Chiche, Noemie] Hop La Conception, Serv Nephrol, Marseille, France; [Chiche, Laurent] Hop Europeen, Serv Med Interne, Marseille, France	Jackson Laboratory; Rockefeller University; Institut National de la Sante et de la Recherche Medicale (Inserm); Universite de Bretagne Occidentale; CHU Brest; Sidra Medical & Research Center; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille	Chaussabel, D (corresponding author), Jackson Lab Genom Med, Farmington, CT 06032 USA.	damien.chaussabel@jax.org	Toufiq, Mohammed/AAQ-8686-2020; S, Basirudeen/A-5259-2009; Bettacchioli, Eleonore/JUV-1916-2023; Rinchai, Darawan/U-3246-2019	Toufiq, Mohammed/0000-0002-6368-6746; Bettacchioli, Eleonore/0009-0002-0797-8098; Rinchai, Darawan/0000-0001-8851-7730	Not applicable.	Not applicable.	Not applicable.	Akgul C, 2001, FEBS LETT, V487, P318, DOI 10.1016/S0014-5793(00)02324-3; Al-Samir S, 2013, J PHYSIOL-LONDON, V591, P4963, DOI 10.1113/jphysiol.2013.251181; Alper SL, 2002, ANNU REV PHYSIOL, V64, P899, DOI 10.1146/annurev.physiol.64.092801.141759; Altman MC, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24584-w; Anders S, 2015, BIOINFORMATICS, V31, P166, DOI 10.1093/bioinformatics/btu638; Balwani Manisha, 2013, Mol Med, V19, P26, DOI 10.2119/molmed.2012.00340; Bennett L, 2003, J EXP MED, V197, P711, DOI 10.1084/jem.20021553; Bergmann AK, 2010, PEDIATR BLOOD CANCER, V54, P273, DOI 10.1002/pbc.22244; Bernardes JP, 2020, IMMUNITY, V53, P1296, DOI 10.1016/j.immuni.2020.11.017; BISHOP DF, 1990, GENOMICS, V7, P207, DOI 10.1016/0888-7543(90)90542-3; BOISE LH, 1993, CELL, V74, P597, DOI 10.1016/0092-8674(93)90508-N; BOTTOMLEY SS, 1995, J BIOENERG BIOMEMBR, V27, P161, DOI 10.1007/BF02110031; Bottomley SS, 2014, HEMATOL ONCOL CLIN N, V28, P653, DOI 10.1016/j.hoc.2014.04.008; Bozorgmehr N, 2023, J IMMUNOTHER CANCER, V11, DOI 10.1136/jitc-2022-006595; Bruce LJ, 2005, NAT GENET, V37, P1258, DOI 10.1038/ng1656; Brummaier T, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-041631; Chaussabel D, 2008, IMMUNITY, V29, P150, DOI 10.1016/j.immuni.2008.05.012; Chaussabel D, 2015, NAT IMMUNOL, V16, P435, DOI 10.1038/ni.3151; Chaussabel D, 2014, NAT REV IMMUNOL, V14, P271, DOI 10.1038/nri3642; Dailey HA, 2013, CSH PERSPECT MED, V3, DOI 10.1101/cshperspect.a011676; Delbridge ARD, 2016, NAT REV CANCER, V16, P99, DOI 10.1038/nrc.2015.17; Elahi S, 2013, NATURE, V504, P158, DOI 10.1038/nature12675; Geers C, 2000, PHYSIOL REV, V80, P681, DOI 10.1152/physrev.2000.80.2.681; Geiss GK, 2008, NAT BIOTECHNOL, V26, P317, DOI 10.1038/nbt1385; Gentleman RC, 2004, GENOME BIOL, V5, DOI 10.1186/gb-2004-5-10-r80; Golub TR, 1999, SCIENCE, V286, P531, DOI 10.1126/science.286.5439.531; Halloy F, 2020, NUCLEIC ACIDS RES, V48, P4658, DOI 10.1093/nar/gkaa229; Harigae H, 2010, INT J HEMATOL, V92, P425, DOI 10.1007/s12185-010-0688-4; Hong S, 2019, J EXP MED, V216, P1154, DOI 10.1084/jem.20190185; Hood L, 2011, NAT REV CLIN ONCOL, V8, P184, DOI 10.1038/nrclinonc.2010.227; Hsu SY, 1997, P NATL ACAD SCI USA, V94, P12401, DOI 10.1073/pnas.94.23.12401; Huang DW, 2009, NAT PROTOC, V4, P44, DOI 10.1038/nprot.2008.211; Inafuku K, 1999, J DERMATOL SCI, V19, P189, DOI 10.1016/S0923-1811(98)00073-5; Irizarry RA, 2003, NUCLEIC ACIDS RES, V31, DOI 10.1093/nar/gng015; Johnson WE, 2007, BIOSTATISTICS, V8, P118, DOI 10.1093/biostatistics/kxj037; Joyce AR, 2006, NAT REV MOL CELL BIO, V7, P198, DOI 10.1038/nrm1857; Kager L, 2017, PEDIATR BLOOD CANCER, V64, DOI 10.1002/pbc.26227; Kieke MC, 2019, MOL GENET METAB REP, V20, DOI 10.1016/j.ymgmr.2019.100481; Lehenkari P, 1998, EXP CELL RES, V242, P128, DOI 10.1006/excr.1998.4071; Li S, 2014, NAT IMMUNOL, V15, P195, DOI 10.1038/ni.2789; Linsley PS, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138726; Mirmiran A, 2019, AM J HUM GENET, V104, P341, DOI 10.1016/j.ajhg.2018.12.021; Novershtern N, 2011, CELL, V144, P296, DOI 10.1016/j.cell.2011.01.004; Opferman JT, 2003, NAT IMMUNOL, V4, P410, DOI 10.1038/ni0503-410; Ottina E, 2012, EXP CELL RES, V318, P1291, DOI 10.1016/j.yexcr.2012.01.021; Ozsolak F, 2011, NAT REV GENET, V12, P87, DOI 10.1038/nrg2934; Perrotta S, 2008, LANCET, V372, P1411, DOI 10.1016/S0140-6736(08)61588-3; Rahman Mahbuba, 2016, F1000Res, V5, P414, DOI 10.12688/f1000research.8375.1; Rinchai D., 2022, F1000esearch, DOI [10.12688/f1000research.122811.1, DOI 10.12688/F1000RESEARCH.122811.1]; Rinchai D., 2022, F1000Research, DOI [10.12688/f1000research.126721.1, DOI 10.12688/F1000RESEARCH.126721.1]; Rinchai D, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abp9961; Rinchai D, 2020, CLIN TRANSL MED, V10, DOI 10.1002/ctm2.244; Rinchai D, 2020, J TRANSL MED, V18, DOI 10.1186/s12967-020-02456-z; Robinson MD, 2010, BIOINFORMATICS, V26, P139, DOI 10.1093/bioinformatics/btp616; Spurgeon SL, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0001662; Supuran CT, 2008, NAT REV DRUG DISCOV, V7, P168, DOI 10.1038/nrd2467; Tufts BL, 2003, COMP BIOCHEM PHYS A, V136, P259, DOI 10.1016/S1095-6433(03)00159-4; van't Veer LJ, 2002, NATURE, V415, P530, DOI 10.1038/415530a; Vince JW, 1998, J BIOL CHEM, V273, P28430, DOI 10.1074/jbc.273.43.28430; Vogler M, 2009, CELL DEATH DIFFER, V16, P360, DOI 10.1038/cdd.2008.137; Wang Z, 2009, NAT REV GENET, V10, P57, DOI 10.1038/nrg2484; Widdas W. F., 1994, Cytobios, V80, P7; Wu CK, 2001, NAT STRUCT BIOL, V8, P156, DOI 10.1038/84152; Zhang WL, 2023, AGING-US, V15, P3644, DOI 10.18632/aging.204697	64	3	3	5	5	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1479-5876		J TRANSL MED	J. Transl. Med.	OCT 16	2023	21	1							728	10.1186/s12967-023-04576-8	http://dx.doi.org/10.1186/s12967-023-04576-8			33	Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Research & Experimental Medicine	X6PK7	37845713	Green Published, gold			2024-07-03	WOS:001099647200003
J	Liu, Y; Ju, SG; Wang, JF				Liu, Yong; Ju, Shenggen; Wang, Junfeng			Exploring the potential of ChatGPT in medical dialogue summarization: a study on consistency with human preferences	BMC MEDICAL INFORMATICS AND DECISION MAKING			English	Article						Internet Healthcare; Large language models; ChatGPT; Automated medical consultation; Medical dialogue summarization		BackgroundTelemedicine has experienced rapid growth in recent years, aiming to enhance medical efficiency and reduce the workload of healthcare professionals. During the COVID-19 pandemic in 2019, it became especially crucial, enabling remote screenings and access to healthcare services while maintaining social distancing. Online consultation platforms have emerged, but the demand has strained the availability of medical professionals, directly leading to research and development in automated medical consultation. Specifically, there is a need for efficient and accurate medical dialogue summarization algorithms to condense lengthy conversations into shorter versions focused on relevant medical facts. The success of large language models like generative pre-trained transformer (GPT)-3 has recently prompted a paradigm shift in natural language processing (NLP) research. In this paper, we will explore its impact on medical dialogue summarization.MethodsWe present the performance and evaluation results of two approaches on a medical dialogue dataset. The first approach is based on fine-tuned pre-trained language models, such as bert-based summarization (BERTSUM) and bidirectional auto-regressive Transformers (BART). The second approach utilizes a large language models (LLMs) GPT-3.5 with inter-context learning (ICL). Evaluation is conducted using automated metrics such as ROUGE and BERTScore.ResultsIn comparison to the BART and ChatGPT models, the summaries generated by the BERTSUM model not only exhibit significantly lower ROUGE and BERTScore values but also fail to pass the testing for any of the metrics in manual evaluation. On the other hand, the BART model achieved the highest ROUGE and BERTScore values among all evaluated models, surpassing ChatGPT. Its ROUGE-1, ROUGE-2, ROUGE-L, and BERTScore values were 14.94%, 53.48%, 32.84%, and 6.73% higher respectively than ChatGPT's best results. However, in the manual evaluation by medical experts, the summaries generated by the BART model exhibit satisfactory performance only in the "Readability" metric, with less than 30% passing the manual evaluation in other metrics. When compared to the BERTSUM and BART models, the ChatGPT model was evidently more favored by human medical experts.ConclusionOn one hand, the GPT-3.5 model can manipulate the style and outcomes of medical dialogue summaries through various prompts. The generated content is not only better received than results from certain human experts but also more comprehensible, making it a promising avenue for automated medical dialogue summarization. On the other hand, automated evaluation mechanisms like ROUGE and BERTScore fall short in fully assessing the outputs of large language models like GPT-3.5. Therefore, it is necessary to research more appropriate evaluation criteria.	[Liu, Yong; Ju, Shenggen; Wang, Junfeng] Sichuan Univ, Dept Comp Sci, 24,South Sect 1,1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China	Sichuan University	Ju, SG (corresponding author), Sichuan Univ, Dept Comp Sci, 24,South Sect 1,1st Ring Rd, Chengdu 610065, Sichuan, Peoples R China.	jsg@scu.edu.cn			key project of the National Natural Science Foundation; School of Data Science at Fudan University	key project of the National Natural Science Foundation; School of Data Science at Fudan University	The authors would like to express their gratitude to the School of Data Science at Fudan University for their contribution in creating the Intelligent Medical Consultation System dataset (IMCS-V2), as well as to Alibaba Cloud for providing data storage, download, and task support.	Abdullah MA, 2022, I COMP CONF WAVELET, DOI 10.1109/ICCWAMTIP56608.2022.10016485; Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DeYoung J, 2021, arXiv; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; Giorgi J, 2023, Arxiv, DOI arXiv:2305.02220; Grail Q, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1792; Graves A, 2014, Arxiv, DOI [arXiv:1308.0850, 10.48550/arXiv.1308.0850, DOI 10.48550/ARXIV.1308.0850]; Gupta Supriya, 2022, Applied Information Processing Systems: Proceedings of ICCET 2021. Advances in Intelligent Systems and Computing (1354), P147, DOI 10.1007/978-981-16-2008-9_14; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hollander JE, 2020, NEW ENGL J MED, V382, P1679, DOI 10.1056/NEJMp2003539; Jain R., 2022, arXiv; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jo HS, 2019, PATIENT EDUC COUNS, V102, P1237, DOI 10.1016/j.pec.2019.02.004; Joshi A, 2020, Arxiv, DOI arXiv:2009.08666; Kanwal N, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P813, DOI 10.1145/3477314.3507256; Kieuvongngam V, 2020, Arxiv, DOI arXiv:2006.01997; Krishna K, 2021, Arxiv, DOI arXiv:2005.01795; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li HR, 2023, Arxiv, DOI [arXiv:2304.05197, 10.48550/arXiv.2304.05197]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu Y, 2019, arXiv; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Ma C, 2024, Arxiv, DOI arXiv:2304.08448; Mann DM, 2020, J AM MED INFORM ASSN, V27, P1132, DOI 10.1093/jamia/ocaa072; Michalopoulos G, 2022, FINDINGS ASS COMPUTA, P4741; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Moro G, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P180; Mrini Khalil, 2021, P 2 WORKSH NAT LANG, P58; Navarro DF, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P254; Ortega-Martin M, 2023, Arxiv, DOI arXiv:2302.06426; Ott M, 2019, Arxiv, DOI arXiv:1904.01038; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Renaud K, 2023, MIT Sloan Management Review; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Sebastian G., 2023, IJSPPC, V15, P1, DOI [10.4018/IJSPPC.325475, DOI 10.4018/IJSPPC.325475]; Shaib C, 2023, Arxiv, DOI arXiv:2305.06299; Song Yan, 2020, P 28 INT C COMP LING, P717, DOI 10.18653/v1/2020.coling-main.63; Sun ZQ, 2020, Arxiv, DOI arXiv:2004.02984; Tang XR, 2023, Arxiv, DOI arXiv:2305.05001; Vaswani A, 2017, ADV NEUR IN, V30; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Zhang Longxiang, 2021, arXiv; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang ZY, 2019, Arxiv, DOI arXiv:1905.07129	55	0	0	14	14	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1472-6947		BMC MED INFORM DECIS	BMC Med. Inform. Decis. Mak.	MAR 14	2024	24	1							75	10.1186/s12911-024-02481-8	http://dx.doi.org/10.1186/s12911-024-02481-8			20	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	LF1U4	38486198	gold			2024-07-03	WOS:001185283300001
J	Bai, XF; Xie, YB; Zhang, X; Han, HG; Li, JR				Bai, Xuefeng; Xie, Yabo; Zhang, Xin; Han, Honggui; Li, Jian-Rong			Evaluation of Open-Source Large Language Models for Metal-Organic Frameworks Research	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article; Early Access								Along with the development of machine learning, deep learning, and large language models (LLMs) such as GPT-4 (GPT: Generative Pre-Trained Transformer), artificial intelligence (AI) tools have been playing an increasingly important role in chemical and material research to facilitate the material screening and design. Despite the exciting progress of GPT-4 based AI research assistance, open-source LLMs have not gained much attention from the scientific community. This work primarily focused on metal-organic frameworks (MOFs) as a subdomain of chemistry and evaluated six top-rated open-source LLMs with a comprehensive set of tasks including MOFs knowledge, basic chemistry knowledge, in-depth chemistry knowledge, knowledge extraction, database reading, predicting material property, experiment design, computational scripts generation, guiding experiment, data analysis, and paper polishing, which covers the basic units of MOFs research. In general, these LLMs were capable of most of the tasks. Especially, Llama2-7B and ChatGLM2-6B were found to perform particularly well with moderate computational resources. Additionally, the performance of different parameter versions of the same model was compared, which revealed the superior performance of higher parameter versions.	[Bai, Xuefeng; Xie, Yabo; Zhang, Xin; Li, Jian-Rong] Beijing Univ Technol, Coll Mat Sci & Engn, Beijing Key Lab Green Catalysis & Separat, Beijing 100124, Peoples R China; [Bai, Xuefeng; Xie, Yabo; Zhang, Xin; Li, Jian-Rong] Beijing Univ Technol, Coll Mat Sci & Engn, Dept Chem Engn, Beijing 100124, Peoples R China; [Han, Honggui] Beijing Univ Technol, Fac Informat Technol, Engn Res Ctr Digital Community, Beijing Lab Urban Mass Transit,Minist Educ, Beijing 100124, Peoples R China; [Han, Honggui] Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intelligen, Beijing 100124, Peoples R China	Beijing University of Technology; Beijing University of Technology; Beijing University of Technology; Beijing University of Technology	Zhang, X; Li, JR (corresponding author), Beijing Univ Technol, Coll Mat Sci & Engn, Beijing Key Lab Green Catalysis & Separat, Beijing 100124, Peoples R China.; Zhang, X; Li, JR (corresponding author), Beijing Univ Technol, Coll Mat Sci & Engn, Dept Chem Engn, Beijing 100124, Peoples R China.; Han, HG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Engn Res Ctr Digital Community, Beijing Lab Urban Mass Transit,Minist Educ, Beijing 100124, Peoples R China.; Han, HG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing Key Lab Computat Intelligence & Intelligen, Beijing 100124, Peoples R China.	zhang.xin@bjut.edu.cn; rechardhan@sina.com; jrli@bjut.edu.cn	Zhang, Xin/P-3072-2017	Zhang, Xin/0000-0001-9318-8839; Li, Jian-Rong/0000-0002-8101-8493	National Natural Science Foundation of China [22225803, 22038001, 22278011, 22108007]; National Natural Science Foundation of China [Z230023]; Beijing Natural Science Foundation	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	We acknowledge the financial support from the National Natural Science Foundation of China (Nos. 22225803, 22038001, 22278011, and 22108007) and Beijing Natural Science Foundation (No. Z230023). AI tools were used in the article to generate content only for better comparison of AI models. No AI was used for writing, summaries, etc. for this article.	Boyd PG, 2019, NATURE, V576, P253, DOI 10.1038/s41586-019-1798-7; Cao ZL, 2023, J AM CHEM SOC, DOI 10.1021/jacs.2c11420; Chiang W.-L., Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chung YG, 2019, J CHEM ENG DATA, V64, P5985, DOI 10.1021/acs.jced.9b00835; Dao T, 2022, Arxiv, DOI [arXiv:2205.14135, DOI 10.48550/ARXIV.2205.14135]; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Ekins S, 2019, NAT MATER, V18, P435, DOI 10.1038/s41563-019-0338-z; Fan YX, 2023, Arxiv, DOI arXiv:2307.13923; Feng L, 2020, J AM CHEM SOC, V142, P3069, DOI 10.1021/jacs.9b12408; Guo TC, 2023, Arxiv, DOI arXiv:2305.18365; He T, 2022, NAT MATER, V21, P689, DOI 10.1038/s41563-022-01237-x; He T, 2021, ACCOUNTS CHEM RES, V54, P3083, DOI 10.1021/acs.accounts.1c00280; Idrees KB, 2022, J AM CHEM SOC, V144, P12212, DOI 10.1021/jacs.2c03114; Jablonka KM, 2023, Arxiv, DOI arXiv:2306.06283; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jiao L, 2021, ACCOUNTS MATER RES, V2, P327, DOI 10.1021/accountsmr.1c00009; Jiao L, 2018, ADV MATER, V30, DOI 10.1002/adma.201703663; Kang Y, 2023, Arxiv, DOI arXiv:2308.01423; Kang YH, 2023, NAT MACH INTELL, V5, P309, DOI 10.1038/s42256-023-00628-2; Lázaro IA, 2020, ANGEW CHEM INT EDIT, V59, P5211, DOI 10.1002/anie.201915848; Lu KD, 2018, ADV MATER, V30, DOI 10.1002/adma.201707634; Luo Y, 2022, ANGEW CHEM INT EDIT, V61, DOI 10.1002/anie.202200242; Macreadie LK, 2023, ANGEW CHEM INT EDIT, V62, DOI 10.1002/anie.202304094; Mo LB, 2024, Arxiv, DOI arXiv:2311.09447; Nandy A, 2021, J AM CHEM SOC, V143, P17535, DOI 10.1021/jacs.1c07217; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Peng P, 2022, NAT ENERGY, V7, P448, DOI 10.1038/s41560-022-01013-w; Ramakrishnan R, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.22; Rieth AJ, 2019, NAT REV MATER, V4, P708, DOI 10.1038/s41578-019-0140-1; Suresh K, 2019, ANGEW CHEM INT EDIT, V58, P16790, DOI 10.1002/anie.201907652; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5; von Lilienfeld OA, 2018, ANGEW CHEM INT EDIT, V57, P4164, DOI 10.1002/anie.201709686; Wang B, 2016, J AM CHEM SOC, V138, P6204, DOI 10.1021/jacs.6b01663; Wang HT, 2022, J MATER CHEM A, V10, P12497, DOI 10.1039/d2ta01466a; Wang J, 2022, ACS MATER LETT, V4, P2058, DOI 10.1021/acsmaterialslett.2c00751; Ward L, 2019, MRS COMMUN, V9, P891, DOI 10.1557/mrc.2019.107; White AD, 2023, NAT REV CHEM, V7, P457, DOI 10.1038/s41570-023-00502-0; Wu QY, 2023, Arxiv, DOI arXiv:2308.08155; Yan JC, 2021, ENVIRON SCI TECHNOL, V55, P14720, DOI 10.1021/acs.est.1c02960; Zhang X, 2024, TRENDS CHEM, V6, P22, DOI 10.1016/j.trechm.2023.11.001; Zhang X, 2020, ADV MATER, V32, DOI 10.1002/adma.201907995; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zheng ZL, 2023, ACS CENTRAL SCI, V9, P2161, DOI 10.1021/acscentsci.3c01087; Zheng ZL, 2023, ANGEW CHEM INT EDIT, V62, DOI 10.1002/anie.202311983; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819	47	0	0	29	29	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	2024 MAR 26	2024										10.1021/acs.jcim.4c00065	http://dx.doi.org/10.1021/acs.jcim.4c00065		MAR 2024	8	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	MB6A9	38529913				2024-07-03	WOS:001191194300001
J	Zhang, XW; Chen, ZF; Cao, YL; Chen, L; Zhou, YM				Zhang, Xiaowei; Chen, Zhifei; Cao, Yulu; Chen, Lin; Zhou, Yuming			Multi-Intent Inline Code Comment Generation via Large Language Model	INTERNATIONAL JOURNAL OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING			English	Article; Early Access						Inline comment generation; large language model; multiple intents		Code comment generation typically refers to the process of generating concise natural language descriptions for a piece of code, which facilitates program comprehension activities. Inline code comments, as a part of code comments, are also crucial for program comprehension. Recently, the emergence of large language models (LLMs) has significantly boosted the performance of natural language processing tasks. This naturally inspires us to explore the performance of the LLMs in the task of inline code comment generation. To this end, we evaluate open-source LLMs on a large-scale dataset and compare the results with the current state-of-the-art methods. Specifically, we explore the model performance in the following scenarios based on the widely used evaluation metrics (i.e. BLEU, Meteor, and ROUGE-L): (1) generation with simple instruction; (2) few-shot-guided generation with random examples selected from the database; (3) few-shot-guided generation with similar examples selected from the database; and (4) adopt the re-ranking strategy for the output of LLMs. Our findings reveal that: (1) under the simple instruction scenario, LLMs could not fully show the potential in the task of inline comment generation compared to the state-of-the-art models; (2) random few-shot leads to a slight improvement; (3) similar few-shot and re-ranking strategy could significantly enhance the performance of LLMs; and (4) for inline comment and code snippet pairs with different intents, why category achieves the best performance and what category achieves relatively poorer performance. That remains consistent across all four scenarios. Our findings shed light on future research directions for using LLMs in inline comment generation tasks.	[Zhang, Xiaowei; Cao, Yulu; Chen, Lin; Zhou, Yuming] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China; [Chen, Zhifei] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China	Nanjing University; Nanjing University of Science & Technology	Chen, L (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.	XiaoweiZhang@smail.nju.edu.cn; lchen@nju.edu.cn		Cao, Yulu/0000-0002-6623-1165; zhang, xiaowei/0000-0003-1481-5158	National Natural Science Foundation of China [62272221, 62172202, 62172205]; Cooperation Fund of Huawei-Nanjing University Next Generation Programming Innovation Lab [YBN2019105178SW35]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Cooperation Fund of Huawei-Nanjing University Next Generation Programming Innovation Lab	This work was supported in part by the National Natural Science Foundation of China under Grants 62272221, 62172202, and 62172205, and in part by the Cooperation Fund of Huawei-Nanjing University Next Generation Programming Innovation Lab under Grant YBN2019105178SW35.	Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Allamanis M, 2016, PR MACH LEARN RES, V48; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Beltagy I., 2019, arXiv; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cass Stephen., 2018, IEEE Spectrum; Chang Y., 2023, ACM Trans. Intell. Syst. Technol, P45; Chen M., 2021, arXiv; Chia YK, 2023, Arxiv, DOI arXiv:2306.04757; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eghbali A, 2022, PROC IEEE ACM INT C, P341, DOI [10.1109/ICSE-Companion55297.2022.9793747, 10.1145/3510454.3528648]; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Fu LY, 2024, Arxiv, DOI arXiv:2309.01940; Geng MY, 2023, Arxiv, DOI arXiv:2304.11384; Guo H., 2023, ACM Trans. Softw. Eng. Methodol, V33, P1; He H., 2022, arXiv; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu X, 2020, EMPIR SOFTW ENG, V25, P2179, DOI [10.1007/s10664-019-09730-9, 10.1007/978-981-13-8203-1_1]; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; Huang Y., 2023, ACM Trans. Softw. Eng. Methodol., V32, P1; Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073; Ji YJ, 2023, Arxiv, DOI arXiv:2303.14742; Jiang SY, 2017, IEEE INT CONF AUTOM, P135, DOI 10.1109/ASE.2017.8115626; Kang S, 2023, PROC INT CONF SOFTW, P2312, DOI 10.1109/ICSE48619.2023.00194; Labrak Y, 2024, Arxiv, DOI arXiv:2307.12114; LeClair A, 2019, PROC INT CONF SOFTW, P795, DOI 10.1109/ICSE.2019.00087; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu Z., CoRR abs/1909.06987; Liu ZX, 2018, IEEE INT CONF AUTOM, P373, DOI 10.1145/3238147.3238190; Luo ZY, 2023, Arxiv, DOI [arXiv:2306.08568, 10.48550/arXiv.2306.08568, DOI 10.48550/ARXIV.2306.08568]; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Mu F., 2023, arXiv; Nashid N, 2023, PROC INT CONF SOFTW, P2450, DOI 10.1109/ICSE48619.2023.00205; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pascarella L, 2017, IEEE WORK CONF MIN S, P227, DOI 10.1109/MSR.2017.63; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Raheja V, 2023, Arxiv, DOI arXiv:2305.09857; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shido Y, 2019, IEEE IJCNN; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vikram V, 2023, Arxiv, DOI [arXiv:2307.04346, 10.48550/arXiv.2307.04346, DOI 10.48550/ARXIV.2307.04346]; Wang L, 2024, Arxiv, DOI arXiv:2308.11432; Wei JS, 2022, ADV NEUR IN; Wong E, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P380, DOI 10.1109/SANER.2015.7081848; Xia X, 2018, IEEE T SOFTWARE ENG, V44, P951, DOI 10.1109/TSE.2017.2734091; Yang Z., 2019, ADV NEURAL INFORM PR, P5754, DOI DOI 10.5555/3454287.3454804; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan ZQ, 2023, Arxiv, DOI arXiv:2308.01240; Zan D., 2023, Long Papers, V1, P7443; Zhai J, 2020, PROC INT CONF SOFTW, P1359, DOI 10.1145/3377811.3380427; Zhang XW, 2024, INT J SOFTW ENG KNOW, V34, P331, DOI 10.1142/S0218194023500547; Zhang XW, 2023, IEEE T SOFTWARE ENG, V49, P2285, DOI 10.1109/TSE.2022.3216279; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zou A, 2023, Arxiv, DOI arXiv:2307.15043	62	0	0	4	4	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	0218-1940	1793-6403		INT J SOFTW ENG KNOW	Int. J. Softw. Eng. Knowl. Eng.	2024 MAR 23	2024										10.1142/S0218194024500050	http://dx.doi.org/10.1142/S0218194024500050		MAR 2024	24	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	LX0X9					2024-07-03	WOS:001190000000001
J	Voelker, R				Voelker, Rebecca			Google Health's Chief Clinical Officer Talks About Incorporating AI in Health Care	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	News Item								This Medical News article is an interview with Michael Howell, MD, MPH, about applications of large language models in medicine.											0	1	1	1	3	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	OCT 10	2023	330	14					1315	1317		10.1001/jama.2023.19137	http://dx.doi.org/10.1001/jama.2023.19137		SEP 2023	3	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	EY8K0	37728947				2024-07-03	WOS:001071397400013
J	Kwon, OH; Vu, K; Bhargava, N; Radaideh, MI; Cooper, J; Joynt, V; Radaideh, MI				Kwon, O. Hwang; Vu, Katie; Bhargava, Naman; Radaideh, Mohammed I.; Cooper, Jacob; Joynt, Veda; Radaideh, Majdi I.			Sentiment analysis of the United States public support of nuclear power on social media using large language models	RENEWABLE & SUSTAINABLE ENERGY REVIEWS			English	Article						Sentiment analysis; Natural language processing; Nuclear power; Public policy; Social media; Large language models	GENERATION	This study utilized large language models (LLMs) to analyze public sentiment in the United States (US) regarding nuclear power on social media, focusing on X/Twitter, considering climate change challenges and advancements in nuclear power technology. Approximately, 1.26 million nuclear tweets from 2008-2023 were examined to fine-tune LLMs for sentiment classification. We found the crucial role of accurate data labeling for model performance, with potential implications for a 15% improvement, achieved through highconfidence labels. LLMs demonstrated better performance compared to traditional machine learning classifiers, with reduced susceptibility to overfitting and up to 96% classification accuracy. LLMs are used to segment the US public tweets into policy and energy-related categories, revealing that 68% are politically themed. Policy tweets tended to convey negative sentiment, often reflecting opposing political perspectives and focusing on nuclear deals and international relations. Energy-related tweets covered diverse topics with predominantly neutral to positive sentiment, indicating broad support for nuclear power in 48 out of 50 US states. The US public positive sentiments toward nuclear power stemmed from its high power density, reliability regardless of weather conditions, environmental benefits, application versatility, and recent innovations and advancements in both fission and fusion technologies. Negative sentiments primarily focused on waste management, high capital costs, and safety concerns. The neutral campaign highlighted global nuclear facts and advancements, with varying tones leaning towards positivity or negativity. An interesting neutral theme was the advocacy for the combined use of renewable and nuclear energy to attain net-zero goals.	[Kwon, O. Hwang; Cooper, Jacob; Joynt, Veda; Radaideh, Majdi I.] Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA; [Vu, Katie] Univ Michigan, Dept Comp Sci & Engn, Ann Arbor, MI 48109 USA; [Bhargava, Naman] Univ Michigan, Dept Stat, Ann Arbor, MI 48109 USA; [Radaideh, Mohammed I.] Univ Michigan, Dept Mech Engn, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan; University of Michigan System; University of Michigan; University of Michigan System; University of Michigan; University of Michigan System; University of Michigan	Radaideh, MI (corresponding author), Univ Michigan, Dept Nucl Engn & Radiol Sci, Ann Arbor, MI 48109 USA.	radaideh@umich.edu		Radaideh, Majdi I/0000-0002-2743-0567	University of Michigan's Fastest Path to Zero initiative [G028455]; Department of Energy Office of Nuclear Energy [DE-NE0009382]; Nuclear Energy University Program (NEUP)	University of Michigan's Fastest Path to Zero initiative; Department of Energy Office of Nuclear Energy(United States Department of Energy (DOE)); Nuclear Energy University Program (NEUP)	Our team is grateful to Prof. Todd Allen from the University of Michigan's Department of Nuclear Engineering and Radiological Sciences for his valuable insights to improve this work. This work is sponsored by the University of Michigan's Fastest Path to Zero initiative under project number (G028455) and the Department of Energy Office of Nuclear Energy under project number (DE-NE0009382), which is funded through the Nuclear Energy University Program (NEUP). This research also made use of Idaho National Laboratory computing resources, which are supported by the Office of Nuclear Energy of the U.S. Department of Energy under Contract No. DE-AC07-05ID14517.	Abadi M., 2015, arXiv, DOI DOI 10.48550/ARXIV.1603.04467; Abbas M, 2019, INT J COMPUT SCI NET, V19, P62; Abiola Odeyinka, 2023, Journal of Electrical Systems and Information Technology, DOI 10.1186/s43067-023-00070-9; Abu-Shawareb H, 2024, PHYS REV LETT, V132, DOI 10.1103/PhysRevLett.132.065102; Almaghrabi M, 2020, PR INT CONF DATA SC, P745, DOI 10.1109/DSAA49011.2020.00095; [Anonymous], China starts up world's first fourth-generation nuclear reactor; [Anonymous], Textblob package description; [Anonymous], Vader package description; [Anonymous], pattern package description; [Anonymous], Tweetnlp package description; [Anonymous], pysentiment2 package-pysentiment2 0.1.1 documentation; [Anonymous], Fastest path to zero; [Anonymous], First planned small nuclear reactor plant in the us has been canceled; [Anonymous], Stanza package description; [Anonymous], cardiffnlp/twitter-roberta-base-offensive A hugging face; Arumugam S, 2021, LECT NOTES COMPUT SC, V13133, P471, DOI 10.1007/978-3-030-91669-5_36; Ata S, 2022, ESIC MARK, V53, DOI 10.7200/esicm.53.280; Bedi J, 2022, SUSTAIN CITIES SOC, V80, DOI 10.1016/j.scs.2022.103706; BELSON WA, 1959, ROY STAT SOC C-APP, V8, P65; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Cano-Marin E, 2023, Sustain Technol Entrepreneurship; Chervonenkis A.Y., 2013, Empirical Inference, P13, DOI [10.1007/978-3-642-41136-63, DOI 10.1007/978-3-642-41136-6_3, 10.1007/978-3-642-41136-6, DOI 10.1007/978-3-642-41136-6]; Chollet F., 2015, About us; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dey Sanjay, 2020, 2020 International Conference on Contemporary Computing and Applications (IC3A), P217, DOI 10.1109/IC3A48958.2020.233300; Fan RE, 2008, J MACH LEARN RES, V9, P1871; Garrett KP, 2023, RENEW SUST ENERG REV, V173, DOI 10.1016/j.rser.2022.113049; Gong P, 2022, J CLEAN PROD, V373, DOI 10.1016/j.jclepro.2022.133919; Gupta K, 2020, REV POLICY RES, V37, P491, DOI 10.1111/ropr.12385; Gupta K, 2019, ENERG POLICY, V133, DOI 10.1016/j.enpol.2019.110888; Gupta K, 2018, POLICY STUD J, V46, P119, DOI 10.1111/psj.12176; Hasegawa S, 2020, J MED INTERNET RES, V22, DOI 10.2196/18662; Holtham N, 2023, MATER CHARACT, V202, DOI 10.1016/j.matchar.2023.113024; Huang F, 2022, Master's thesis; Islam MM, 2018, Int J Comput Appl, V182, P1; Jeong SY, 2021, NUCL ENG TECHNOL, V53, P1013, DOI 10.1016/j.net.2020.07.031; Kahrstrom F., 2022, Natural language processing for Swedish nuclear power plants: A study of the challenges of applying natural language processing in operations and maintenance and how bert can be used in this industry; Karakus BA, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4783; Kegl B, 2009, Introduction to adaboost; Khatua A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206903; Kitada A, 2016, J NUCL SCI TECHNOL, V53, P1686, DOI 10.1080/00223131.2016.1175391; Lauren P, 2018, COGN COMPUT, V10, P625, DOI 10.1007/s12559-018-9548-y; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li S, 2020, Arxiv, DOI [arXiv:2006.15704, DOI 10.14778/3415478.3415530]; Liu Q, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100358; Liu ZY, 2018, LECT NOTES COMPUT SC, V11279, P99, DOI 10.1007/978-3-030-04257-8_9; Malhotra P., 2015, P EUR S ART NEUR NET, P89; Manobala T, 2021, CHEMOSPHERE, V269, DOI 10.1016/j.chemosphere.2020.128722; Monika R, 2019, INT CONF ADV COMPU, P92, DOI [10.1109/iacc48062.2019.8971592, 10.1109/IACC48062.2019.8971592]; Nagaya H, 2020, INFORMATION, V11, DOI 10.3390/info11070368; Nicodemo N, 2019, Arxiv, DOI arXiv:1911.00527; Nyagadza B, 2023, Sustain Technol Entrepreneurship, V2; Ohba T, 2021, ENVIRON INT, V148, DOI 10.1016/j.envint.2021.106379; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Rahman Sheikh Shah Mohammad Motiur, 2018, Journal of Physics: Conference Series, V1060, DOI 10.1088/1742-6596/1060/1/012036; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Savitha S, 2023, 2023 INT C COMP COMM, P1; Seo S, 2020, IEEE ACCESS, V8, P6861, DOI 10.1109/ACCESS.2019.2963426; StatsAmerica, ABOUT US; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; UD G, Sentiment analysis on twitter data by using convolutional neural network (cnn) and long short term memory (lstm); Wadhwani Ganesh Kumar, 2023, SN Comput Sci, V4, P346, DOI 10.1007/s42979-023-01790-5; Wisnubroto DS, 2019, AIP CONF PROC, V2180, DOI 10.1063/1.5135551; Xu H, 2022, KERNTECHNIK, V87, P167, DOI 10.1515/kern-2021-0034; Yamagata H, 2024, ENERG POLICY, V185, DOI 10.1016/j.enpol.2023.113939; Yue L, 2019, KNOWL INF SYST, V60, P617, DOI 10.1007/s10115-018-1236-4; Zarrabeitia-Bilbao E, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01033-8	67	0	0	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	1364-0321	1879-0690		RENEW SUST ENERG REV	Renew. Sust. Energ. Rev.	AUG	2024	200								114570	10.1016/j.rser.2024.114570	http://dx.doi.org/10.1016/j.rser.2024.114570			19	Green & Sustainable Science & Technology; Energy & Fuels	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics; Energy & Fuels	UT9C8		hybrid			2024-07-03	WOS:001250418300001
J	Pan, LM; Saxon, M; Xu, WD; Nathani, D; Wang, XY; Wang, WY				Pan, Liangming; Saxon, Michael; Xu, Wenda; Nathani, Deepak; Wang, Xinyi; Wang, William Yang			Automatically Correcting Large Language Models: <i>Surveying the Landscape of Diverse Automated Correction Strategies</i>	TRANSACTIONS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS			English	Article								While large language models (LLMs) have shown remarkable effectiveness in various NLP tasks, they are still prone to issues such as hallucination, unfaithful reasoning, and toxicity. A promising approach to rectify these flaws is correcting LLMs with feedback, where the LLM itself is prompted or guided with feedback to fix problems in its own output. Techniques leveraging automated feedback-either produced by the LLM itself (self-correction) or some external system-are of particular interest as they make LLM-based solutions more practical and deployable with minimal human intervention. This paper provides an exhaustive review of the recent advances in correcting LLMs with automated feedback, categorizing them into training-time, generation-time, and post-hoc approaches. We also identify potential challenges and future directions in this emerging field.	[Pan, Liangming; Saxon, Michael; Xu, Wenda; Nathani, Deepak; Wang, Xinyi; Wang, William Yang] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA	University of California System; University of California Santa Barbara	Pan, LM (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.	liangmingpan@ucsb.edu; saxon@ucsb.edu; wendaxu@ucsb.edu; dnathani@ucsb.edu; xinyi_wang@ucsb.edu; william@cs.ucsb.edu			National Science Foundation [2048122]	National Science Foundation(National Science Foundation (NSF))	This work was supported by the National Science Foundation (award #2048122). The views expressed are those of the authors and do not reflect the official policy or position of the US government. Thanks to Xinyuan Lu for assisting with the Github reading list repo.	Akyürek AF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7716; Alabau Vicent., 2014, Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL), P25, DOI DOI 10.3115/V1/E14-2007; Allaway S., 2022, P 2022 C EMP METH NA, P2407, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.154; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bai Yuntao., 2022, CoRR; Begus Gasper., 2023, CoRR; Bellhäuser H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1125873; Bogin B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3659; BOYD EM, 1983, J HUMANIST PSYCHOL, V23, P99, DOI 10.1177/0022167883232011; Cao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6251; Charalambous Yiannis., 2023, CoRR; Chen Angelica., 2023, CoRR; Chen Bei., 2023, P 11 INT C LEARN REP; Chen Justin Chih-Yao., 2023, CoRR; Chen Pinzhen., 2023, CoRR; Chen Xinyun., 2023, CORR; Chern I-Chun., 2023, CORR; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Cohen Roi., 2023, P 2023 C EMPIRICAL M; Creswell Antonia., 2022, CoRR; Dasgupta Ishita., 2022, CoRR; Dathathri Sumanth, 2020, Plug and play language models: A simple approach to controlled text generation; De Cao N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6491; do Carmo F, 2021, MACH TRANSL, V35, P101, DOI 10.1007/s10590-020-09252-y; Du YL, 2023, Arxiv, DOI arXiv:2305.14325; Dubois Yann., 2023, CoRR; Falke T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2214; Fernandes P, 2023, T ASSOC COMPUT LING, V11, P1643, DOI 10.1162/tacl_a_00626; Ferretti E, 2019, PAED CHILD HEALT-CAN, V24, P156, DOI 10.1093/pch/pxy102; First E, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P1229, DOI 10.1145/3611643.3616243; Freitag M, 2022, T ASSOC COMPUT LING, V10, P811, DOI 10.1162/tacl_a_00491; Fu Y, 2023, Arxiv, DOI arXiv:2305.10142; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Gao LY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P16477; Ge Gao., 2023, CoRR, DOI [10.18653/v1/2023.emnlp-main.27, DOI 10.18653/V1/2023.EMNLP-MAIN.27]; Gehman S, 2020, M ASS FOR COMPUTATIO; Gero Zelalem., 2023, CoRR; Glaese Amelia., 2022, CoRR; Go Dongyoung., 2023, CoRR; Golovneva O., 2023, P 11 INT C LEARN REP; Gou Zhibin., 2023, CORR; Gulcehre Caglar., 2023, CoRR; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Hao S, 2023, P 2023 C EMPIRICAL M, P8154; He HF, 2022, Arxiv, DOI arXiv:2301.00303; He P, 2020, ICLR; Helbling Alec., 2023, CoRR; Hoelscher-Obermaier Jason., 2023, FIND ASS COMP LING A, P11548, DOI DOI 10.18653/V1/2023.FINDINGSACL.733; Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638; Hong Ruixin., 2023, CoRR; Huang J., 2023, EMNLP, P1051; Huang Jie., 2023, CORR; Jiang Shuyang., 2023, CORR; Jung Jaehun, 2022, P 2022 C EMP METH NA, P1266, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.82; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Ke Pei., 2023, CoRR; Kelkar Amol., 2020, CoRR; Khalifa Muhammad., 2023, CoRR; Kim Geunwoo., 2023, CoRR; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Kojima Takeshi., 2022, 2022 ANN C NEUR INF; Kreutzer J., 2018, P 2018 C N AM CHAPT, P92, DOI DOI 10.18653/V1/N18-3012; Le Hung., 2022, ANN C NEUR INF PROC; Lee D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6045; Lee K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P438; Lee W, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3685; Levy S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4718; Li Junyi., 2023, CORR; Li Miaoran., 2023, CoRR; Li Ruosen., 2023, CoRR; Li Xiang., 2022, P ANN C NEUR INF PRO; Li YF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5315; Lightman H, 2023, Arxiv, DOI [arXiv:2305.20050, DOI 10.48550/ARXIV.2305.20050]; Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214; Lin YT, 2023, Arxiv, DOI arXiv:2305.13711; Lin Zhen., 2023, CoRR; Liu Hao., 2023, CORR; Liu Jiacheng., 2023, P 2023 C EMPIRICAL M, P11557, DOI 10.18653/v1/2023.emnlp-main.708; Liu YX, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P1065; London M, 2023, ANNU REV ORGAN PSYCH, V10, P261, DOI 10.1146/annurev-orgpsych-120920-044531; Lyu Chenyang., 2023, CoRR, DOI [10.18653/v1/2023.emnlp-main.1036, DOI 10.18653/V1/2023.EMNLP-MAIN.1036]; Lyu Qing., 2023, CoRR, DOI [10.18653/v1/2023.ijcnlp-main.20, DOI 10.18653/V1/2023.IJCNLP-MAIN.20]; Madaan A, 2022, P 2022 C EMPIRICAL M, P2833; Madaan Aman., 2023, CoRR; Manakul P., 2023, CORR, P9004, DOI DOI 10.18653/V1/2023.EMNLP-MAIN.557; Mehrabi Ninareh., 2023, CoRR; Metcalfe J, 2017, ANNU REV PSYCHOL, V68, P465, DOI 10.1146/annurev-psych-010416-044022; Miao Ning., 2023, CoRR; Min Sewon., 2023, P 2023 C EMPIRICAL M, DOI DOI 10.18653/V1/2023.EMNLP-MAIN.741; Murty Shikhar., 2022, P 2022 C EMP METH NA, P11600, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.797; Nathani Deepak., 2023, P 2023 C EMPIRICAL M, P6591, DOI 10.18653/v1/2023.emnlp-main.407; Ni Ansong., 2023, P 40 INT C MACH LEAR; Olausson Theo X., 2023, CoRR; Onoe Y, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5469; OpenAl, 2023, GPT-4 technical report; Ouyang Long., 2022, P ANN C NEUR INF PRO; Pan Liangming., 2023, FINDINGS ASS COMPUTA; Pang Jing-Cheng., 2023, CoRR; Paul D, 2024, Arxiv, DOI [arXiv:2304.01904, 10.48550/arXiv.2304.01904]; Peng Baolin., 2023, CoRR; Pu DQ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-SRW 2023, VOL 4, P1; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Raunak Vikas., 2023, CoRR, DOI [10.18653/v1/2023.findings-emnlp.804, DOI 10.18653/V1/2023.FINDINGS-EMNLP.804]; Ribeiro Danilo Neves., 2023, P 11 INT C LEARN REP; Sagarkar Manasvi., 2018, P 7 JOINT C LEX COMP, P192, DOI DOI 10.18653/V1/S18-2024; Saha S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P122; Saunders W, 2022, Arxiv, DOI arXiv:2206.05802; Saxon M, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3061; Scheurer Jeremy., 2023, CoRR; Schick Timo., 2023, P 11 INT C LEARN REP; Schulman J., 2017, ARXIV; Seonghyeon Ye, 2023, Blog post; Shaikh O, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4454; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Sinitsin Anton., 2020, P 8 INT C LEARN REPR; Srikanth N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4753; Stechly Kaya., 2023, CoRR; Suzgun Mirac., 2023, FINDINGS ASS COMPUTA, P13003, DOI 10.18653/v1/2023.findings-acl.824; Tafjord O, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3621; Tafjord Oyvind, 2022, P 2022 C EMPIRICAL M, P2078; Tanno Ryutaro., 2022, P 2022 ANN C NEUR IN; Tyen Gladys., 2023, CoRR; Uesato Jonathan., 2022, CoRR; Unanue IJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P915; Valmeekam Karthik., 2023, CoRR, Vabs/2310.08118; Varshney Neeraj., 2023, CoRR, Vabs/2307.03987; Wan D, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1010; Wang Boxin., 2023, CoRR; Wang Haotian., 2023, CoRR; Wang Liyuan., 2023, CORR; Wang T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3859; Wei Jason., 2022, ANN C NEUR INF PROCE; Wei Jason., 2022, CoRR; Welleck Sean., 2023, P 11 INT C LEARN REP; Wenda Xu., 2023, P 2023 C EMPIRICAL M, DOI 10.18653/v1/2023.emnlp-main.365; Weng Yixuan., 2023, CoRR, DOI [10.18653/v1/2023.findings-emnlp.167, DOI 10.18653/V1/2023.FINDINGS-EMNLP.167]; Xie YX, 2023, Arxiv, DOI [arXiv:2305.00633, DOI 10.48550/ARXIV.2305.00633]; Ximing Lu., 2022, P ANN C NEUR INF PRO; Xu X, 2017, ABS171104436 CORR; Yan H, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P3149; Yang K., 2022, P 2022 C EMPIRICAL M, P4393, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.296; Yang Kaiyu., 2022, P 2022 C EMP METH NA, P89, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.7; Yang K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3511; Yao Shunyu., 2023, CoRR; Yao Yunzhi., 2023, CORR; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1653; Yu WH, 2023, Arxiv, DOI arXiv:2305.14002; Yuan Weizhe., 2023, CoRR; Zelikman Eric., 2022, P ANN C NEUR INF PRO; Zeqiu Wu., 2023, CoRR; Zhang Kechi., 2023, CoRR, DOI [10.18653/v1/2023.acl-long.45, DOI 10.18653/V1/2023.ACL-LONG.45]; Zhang Kexun., 2023, CoRR; Zhang Muru., 2023, CoRR; Zhaofeng Wu., 2023, CoRR; Zhu XY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4471; Zhuo Terry Yue., 2023, CoRR	156	0	0	4	4	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA		2307-387X		T ASSOC COMPUT LING	Trans. Assoc. Comput. Linguist.	MAY 3	2024	12						484	506		10.1162/tacl_a_00660	http://dx.doi.org/10.1162/tacl_a_00660			23	Computer Science, Artificial Intelligence; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	QF5W2					2024-07-03	WOS:001219486300004
