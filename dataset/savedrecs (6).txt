PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
C	Giudice, O; Maggi, A; Nardelli, M			Assoc Computing Machinery	Giudice, Oliver; Maggi, Alessandro; Nardelli, Matteo			Exploring Naive Approaches to Tell Apart LLMs Productions from Human-written Text	PROCEEDINGS OF 2023 7TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2023			English	Proceedings Paper	7th International Conference on Natural Language Processing and Information Retrieval (NLPIR)	DEC 15-17, 2023	Seoul, SOUTH KOREA			NLP; LLM; human-written; machine-generated; detection; classification		Powerful Large Language Models (large LMs or LLMs) such as BERT and GPT are making the task of detecting machine-generated text more and more prominent and crucial to minimize threats posed by text generation models misuse. Nonetheless, only a limited number of efforts exist so far, which can be classified into simple classifiers, zero-shot approaches, and fine-tuned LMs. These approaches usually rely on LMs whose discrimination accuracy decreases as the size difference in favor of the generator model increases (hence, a detector should always employ a LM with at least the same number of parameters of the source LM). Also, most of these approaches do not explicitly investigate whether the sentence syntactic structure can provide additional information that helps to build better detectors. All these considerations make the generalizing ability of detection methods into question. While generation techniques become more and more capable of producing human-like text, are the detection techniques capable of keeping up if not properly trained? In this paper, we evaluate the most effective (and reproducible) detection method available in the state of the art in order to figure out the limits in its robustness. We complement this analysis by discussing results obtained using a novel naive approach that demonstrably achieves comparable results in terms of robustness with respect to much more advanced and sophisticated state-of-the-art methods. Code with details on experiments are available at: https://github.com/bancaditalia/gen-text-detect.	[Giudice, Oliver; Maggi, Alessandro; Nardelli, Matteo] Bank Italy, Rome, RM, Italy	European Central Bank; Bank of Italy	Giudice, O (corresponding author), Bank Italy, Rome, RM, Italy.	oliver.giudice@bancaditalia.it; alessandro.maggi@bancaditalia.it; matteo.nardelli@bancaditalia.it	Nardelli, Matteo/K-7215-2016	Nardelli, Matteo/0000-0002-9519-9387				Adelani David Ifeoluwa, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P1341, DOI 10.1007/978-3-030-44041-1_114; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bakhtin Anton, 2019, Real or Fake? Learning to Discriminate Machine from Human Generated Text; Borzì S, 2022, IEEE COMPUT SOC CONF, P71, DOI 10.1109/CVPRW56347.2022.00017; Chen T., 2015, R package version 042, V1, P1; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fagni T, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251415; Gehrmann S, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P111; Guarnera L, 2022, LECT NOTES COMPUT SC, V13232, P151, DOI 10.1007/978-3-031-06430-2_13; Holtzman A., 2019, INT C LEARNING REPRE; Ippolito D, 2020, Arxiv, DOI arXiv:1911.00650; Jawahar Ganesh, 2020, Automatic Detection of Machine Generated Text: A Critical Survey; Kushnareva L, 2022, Arxiv, DOI arXiv:2109.04825; Leotta R, 2023, LECT NOTES COMPUT SC, V14233, P364, DOI 10.1007/978-3-031-43148-7_31; Mitchell E., 2023, DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature; Mori M, 2022, PROCEEDINGS OF THE FIFTH FACT EXTRACTION AND VERIFICATION WORKSHOP (FEVER 2022), P78; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Solaiman I., 2019, Release strategies and the social impacts of language models; Uchendu A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8384; Vaswani A, 2017, ADV NEUR IN, V30; Weiss M., 2019, Technology Science; Zellers R, 2019, ADV NEUR IN, V32; Zhong WJ, 2020, Arxiv, DOI arXiv:2010.07475	23	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0922-7				2023							71	76		10.1145/3639233.3639354	http://dx.doi.org/10.1145/3639233.3639354			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6NK					2024-07-03	WOS:001179071500011
J	Rosenberg, GS; Magnéli, M; Barle, N; Kontakis, MG; Müller, AM; Wittauer, M; Gordon, M; Brodén, C				Rosenberg, Guillermo Sanchez; Magneli, Martin; Barle, Niklas; Kontakis, Michael G.; Muller, Andreas Marc; Wittauer, Matthias; Gordon, Max; Broden, Cyrus			ChatGPT-4 generates orthopedic discharge documents faster than humans maintaining comparable quality: a pilot study of 6 cases	ACTA ORTHOPAEDICA			English	Article							PHYSICIANS; BURNOUT; CARE	Background and purpose - Large language models like ChatGPT-4 have emerged. They hold the potential to reduce the administrative burden by generating everyday clinical documents, thus allowing the physician to spend more time with the patient. We aimed to assess both the quality and efficiency of discharge documents generated by ChatGPT-4 in comparison with those produced by physicians. Patients and methods - To emulate real -world situations, the health records of 6 fictional orthopedic cases were created. Discharge documents for each case were generated by a junior attending orthopedic surgeon and an advanced orthopedic resident. ChatGPT-4 was then prompted to generate the discharge documents using the same health record information. The quality assessment was performed by an expert panel (n = 15) blinded to the source of the documents. As secondary outcome, the time required to generate the documents was compared, logging the duration of the creation of the discharge documents by the physician and by ChatGPT-4. Results - Overall, both ChatGPT-4 and physiciangenerated notes were comparable in quality. Notably, ChatGPT-4 generated discharge documents 10 times faster than the traditional method. 4 events of hallucinations were found in the ChatGPT-4-generated content, compared with 6 events in the human/physician produced notes. Conclusion - ChatGPT-4 creates orthopedic discharge notes faster than physicians, with comparable quality. This shows it has great potential for making these documents more efficient in orthopedic care. ChatGPT-4 has the potential to significantly reduce the administrative burden on healthcare professionals.	[Rosenberg, Guillermo Sanchez; Muller, Andreas Marc; Wittauer, Matthias] Univ Hosp Basel, Dept Orthopaed & Trauma Surg, Basel, Switzerland; [Magneli, Martin; Barle, Niklas; Gordon, Max] Danderyd Hosp, Karolinska Inst, Dept Clin Sci, Stockholm, Sweden; [Kontakis, Michael G.; Broden, Cyrus] Uppsala Univ Hosp, Dept Surg Sci, Orthoped, Uppsala, Sweden	University of Basel; Karolinska Institutet; Danderyds Hospital; Uppsala University; Uppsala University Hospital	Brodén, C (corresponding author), Uppsala Univ Hosp, Dept Surg Sci, Orthoped, Uppsala, Sweden.		Gordon, Max/M-4330-2014	Gordon, Max/0000-0002-8080-5815				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brameier Devon T, 2023, J Bone Joint Surg Am, V105, P1388, DOI 10.2106/JBJS.23.00473; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Greer RC, 2016, BMC HEALTH SERV RES, V16, DOI 10.1186/s12913-016-1697-7; Hurley ET, 2024, ARTHROSCOPY, V40, DOI 10.1016/j.arthro.2023.07.048; Kripalani S, 2007, JAMA-J AM MED ASSOC, V297, P831, DOI 10.1001/jama.297.8.831; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu XX, 2020, LANCET DIGIT HEALTH, V2, pE537, DOI [10.1136/bmj.m3164, 10.1016/S2589-7500(20)30219-3, 10.1016/S2589-7500(20)30218-1]; Massey PA, 2023, J AM ACAD ORTHOP SUR, V31, P1173, DOI 10.5435/JAAOS-D-23-00396; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Nadeau S, Excess administrative costs burden the U.S. health care system; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Panagioti M, 2017, JAMA INTERN MED, V177, P195, DOI 10.1001/jamainternmed.2016.7674; Patel RS, 2018, BEHAV SCI-BASEL, V8, DOI 10.3390/bs8110098; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rotenstein LS, 2018, JAMA-J AM MED ASSOC, V320, P1131, DOI 10.1001/jama.2018.12777; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; West CP, 2018, J INTERN MED, V283, P516, DOI 10.1111/joim.12752; Wimsett J, 2014, EMERG MED AUSTRALAS, V26, P430, DOI 10.1111/1742-6723.12285; Woolhandler S, 2003, NEW ENGL J MED, V349, P768, DOI 10.1056/NEJMsa022033; Wright AA, 2018, NEW ENGL J MED, V378, P309, DOI 10.1056/NEJMp1716845	24	1	1	0	0	Medical Journal Sweden AB	Uppsala	Kungsngsvgen 27St, Uppsala, SWEDEN	1745-3674	1745-3682		ACTA ORTHOP	Acta Orthop.		2024	95						152	156		10.2340/17453674.2024.40182	http://dx.doi.org/10.2340/17453674.2024.40182			5	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	LV6R9	38597205	gold			2024-07-03	WOS:001189620200001
J	de Zarzà, I; de Curtò, J; Roig, G; Calafate, CT				de Zarza, I.; de Curto, J.; Roig, Gemma; Calafate, Carlos T.			LLM Multimodal Traffic Accident Forecasting	SENSORS			English	Article						LLM; VLM; LLaVA; accident forecasting; transformers; time series analysis; PCA loadings		With the rise in traffic congestion in urban centers, predicting accidents has become paramount for city planning and public safety. This work comprehensively studied the efficacy of modern deep learning (DL) methods in forecasting traffic accidents and enhancing Level-4 and Level-5 (L-4 and L-5) driving assistants with actionable visual and language cues. Using a rich dataset detailing accident occurrences, we juxtaposed the Transformer model against traditional time series models like ARIMA and the more recent Prophet model. Additionally, through detailed analysis, we delved deep into feature importance using principal component analysis (PCA) loadings, uncovering key factors contributing to accidents. We introduce the idea of using real-time interventions with large language models (LLMs) in autonomous driving with the use of lightweight compact LLMs like LLaMA-2 and Zephyr-7b-alpha. Our exploration extends to the realm of multimodality, through the use of Large Language-and-Vision Assistant (LLaVA)-a bridge between visual and linguistic cues by means of a Visual Language Model (VLM)-in conjunction with deep probabilistic reasoning, enhancing the real-time responsiveness of autonomous driving systems. In this study, we elucidate the advantages of employing large multimodal models within DL and deep probabilistic programming for enhancing the performance and usability of time series forecasting and feature weight importance, particularly in a self-driving scenario. This work paves the way for safer, smarter cities, underpinned by data-driven decision making.	[de Zarza, I.; de Curto, J.; Roig, Gemma] GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany; [de Zarza, I.; de Curto, J.; Calafate, Carlos T.] Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain; [de Zarza, I.; de Curto, J.] Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicac, Barcelona 08018, Spain; [Roig, Gemma] HESSIAN Ctr AI Hessian AI, D-64289 Darmstadt, Germany	Goethe University Frankfurt; Universitat Politecnica de Valencia; UOC Universitat Oberta de Catalunya	de Curtò, J (corresponding author), GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany.; de Curtò, J (corresponding author), Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain.; de Curtò, J (corresponding author), Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicac, Barcelona 08018, Spain.	dezarza@em.uni-frankfurt.de; decurto@em.uni-frankfurt.de; roig@cs.uni-frankfurt.de; calafate@disca.upv.es		de Curto y Diaz, J./0000-0002-8334-4719; Roig, Gemma/0000-0002-6439-8076; de Zarza i Cubero, I./0000-0002-5844-7871	GOETHE-University Frankfurt am Main; "xAIBiology-Hessian.AI"	GOETHE-University Frankfurt am Main; "xAIBiology-Hessian.AI"	No Statement Available	Ahangar MN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030706; Bingham E., 2018, J MACH LEARN RES, V20, P1; Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164; Chen CL, 2023, IEEE T NEUR NET LEAR, V34, P6913, DOI 10.1109/TNNLS.2022.3183903; Chen HY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15133402; Guo XY, 2023, VEH COMMUN, V39, DOI 10.1016/j.vehcom.2022.100550; Guo YH, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062291; Hu YH, 2023, PROC CVPR IEEE, P17853, DOI 10.1109/CVPR52729.2023.01712; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Jiang WW, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12030100; Jiang WW, 2022, EXPERT SYST APPL, V207, DOI 10.1016/j.eswa.2022.117921; Li GY, 2024, INFORM FUSION, V102, DOI 10.1016/j.inffus.2023.102063; Li GY, 2023, IEEE T KNOWL DATA EN, V35, P10967, DOI 10.1109/TKDE.2022.3233086; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Liu H., 2023, P NEURIPS 2023 NEW O; Mao JG, 2023, Arxiv, DOI arXiv:2310.01415; Miao Y, 2023, IEEE INTERNET THINGS, V10, P21217, DOI 10.1109/JIOT.2023.3283611; Minderer M, 2024, Arxiv, DOI arXiv:2306.09683; Minderer M, 2022, Arxiv, DOI arXiv:2205.06230; Negash NM, 2023, IEEE ACCESS, V11, P22788, DOI 10.1109/ACCESS.2023.3249144; Nguyen Ngan-Linh, 2022, Intelligence of Things: Technologies and Applications: The First International Conference on Intelligence of Things (ICIot 2022), Proceedings. Lecture Notes on Data Engineering and Communications Technologies (148), P388, DOI 10.1007/978-3-031-15063-0_37; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Pham H, 2022, Arxiv, DOI arXiv:2111.10050; Phan D., 2019, arXiv; Radford A, 2021, PR MACH LEARN RES, V139; Rafailov R, 2023, Arxiv, DOI arXiv:2305.18290; Ramesh A, 2021, PR MACH LEARN RES, V139; Rob J, 2018, Forecasting: principles and practice; Shumway RH, 2017, Time series analysis and its applications: with R examples, P75; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Taylor SJ, 2018, AM STAT, V72, P37, DOI 10.1080/00031305.2017.1380080; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Vlahogianni EI, 2014, TRANSPORT RES C-EMER, V43, P3, DOI 10.1016/j.trc.2014.01.005; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Weng WC, 2023, PATTERN RECOGN, V142, DOI 10.1016/j.patcog.2023.109670; Xia XY, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101968; Yeong D, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062140; Zaman M., 2023, P 2023 IEEE TRANSPOR, P1; Zonouzi MN, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106485	41	6	6	48	58	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	NOV	2023	23	22							9225	10.3390/s23229225	http://dx.doi.org/10.3390/s23229225			27	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	AQ4Z7	38005612	gold, Green Published			2024-07-03	WOS:001119927100001
C	Papakonstantinou, N; Van Bossuyt, DL; Hale, B; Arlitt, R; Salonen, J; Suomalainen, J			AMER SOC MECHANICAL ENGINEERS	Papakonstantinou, Nikolaos; Van Bossuyt, Douglas L.; Hale, Britta; Arlitt, Ryan; Salonen, Jarno; Suomalainen, Jani			CyberRiskDELPHI: TOWARDS OBJECTIVE CYBER RISK ASSESSMENT FOR COMPLEX SYSTEMS	PROCEEDINGS OF ASME 2023 INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, IDETC-CIE2023, VOL 2			English	Proceedings Paper	ASME International Design Engineering Technical Conferences / 43rd Annual Computers and Information in Engineering Conference (IDETC-CIE)	AUG 20-23, 2023	Boston, MA	Amer Soc Mech Engineers, Design Engn Div, Amer Soc Mech Engineers, Comp & Informat Engn Div, Tech Comm Micro & Nano Syst		Risk assessment; Risk management; Cyber insurance; Cybersecurity; DELPHI; CyberRiskDELPHI	SAFETY	Risk assessment is an essential step for architecting the resilience (safety/security) of a mission critical software-intensive system as well as a regular maintenance procedures. It closely relates to estimating the (cyber) insurance needs of the system. Managing of cyber risk involves gathering threat intelligence, prioritizing the current threats against the system of interest, and planning mitigation strategies. While reliability engineering can rely on a relatively stable set of failure modes and statistical data related to their probabilities of occurrence, security deals with a dynamic threat environment. This reality has dictated the use of qualitative methods (like STRIDE and DREAD), relying on the experience and the specific background of the person performing the study. This subjectivity leads to criticism, since results calculated by different experts for the same system can vary significantly. This challenge has been addressed in the past with a method called DELPHI aiming to reduce subjectivity using a group of experts. The scientific contribution of this paper is the development of the CyberRiskDELPHI, a modified version of original DELPHI method for the identification and prioritization of cyber risks. It is demonstrated over a case study of a 5G tactical bubble covering the communication needs of a critical operation. An early evaluation of the use of a large language model (ChatGPT) in risk identification and prioritization for this case study is also included as a complementary side-activity giving an indication of future developments in the risk assessment domain.	[Papakonstantinou, Nikolaos; Suomalainen, Jani] VTT Tech Res Ctr Finland, Espoo, Finland; [Van Bossuyt, Douglas L.; Hale, Britta] US Navy, Postgrad Sch, Monterey, CA USA; [Arlitt, Ryan] Tech Univ Denmark, Lyngby, Denmark; [Salonen, Jarno] VTT Tech Res Ctr Finland, Tampere, Finland	VTT Technical Research Center Finland; United States Department of Defense; United States Navy; Naval Postgraduate School; Technical University of Denmark; VTT Technical Research Center Finland	Papakonstantinou, N (corresponding author), VTT Tech Res Ctr Finland, Espoo, Finland.	nikolaos.papakonstantinou@vtt.fi			AI-NETANTILLAS project (CELTIC-NEXT) - Business Finland [C2019/3-3]; Technical University of Denmark; Naval Postgraduate School	AI-NETANTILLAS project (CELTIC-NEXT) - Business Finland; Technical University of Denmark; Naval Postgraduate School(United States Department of DefenseUnited States Navy)	This work was partially supported by the AI-NETANTILLAS project (CELTIC-NEXT, C2019/3-3), funded by Business Finland. This research was partially supported by the Technical University of Denmark and the Naval Postgraduate School. Any opinions or findings of this work are the responsibility of the authors, and do not necessarily reflect the views of the sponsors or collaborators. The case studies presented in this publication, while inspired by real systems and real events, is intentionally fictional and idealized in nature. Approved for Public Release; distribution is unlimited.	[Anonymous], GitHub CoPilot your ai pair programmer; [Anonymous], ChatGPT; [Anonymous], FORUM INCIDENT RESPO; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bossuyt Douglas L. Van, 2023, 69 ANN REL I MAINT S; Bowles J. B., 1998, Annual Reliability and Maintainability Symposium 1998 Proceedings. International Symposium on Product Quality and Integrity (Cat. No.98CH36161), P48, DOI 10.1109/RAMS.1998.653561; British Psychological Society, The Delphi method; Corporation RAND, Delphi Method; Forum of Incident Response and Security Teams, Common Vulnerability Scoring System SIG; Friedberg I, 2017, J INF SECUR APPL, V34, P183, DOI 10.1016/j.jisa.2016.05.008; Gibson J. Paul, 2018, Leveraging Applications of Formal Methods, Verification and Validation Distributed Systems. 8th International Symposium, ISoLA 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11246), P407, DOI 10.1007/978-3-030-03424-5_27; Goldstein Phil, 2019, FedTech Magazine; Group OpenStack Security, Security/OSSA-Metrics; Henley E.J., 1981, RELIABILITY ENG RISK; Hooper E, 2009, 2009 IEEE INTERNATIONAL SYSTEMS CONFERENCE, PROCEEDINGS, P257, DOI 10.1109/SYSTEMS.2009.4815808; Höyhtyä M, 2018, IEEE ACCESS, V6, P73572, DOI 10.1109/ACCESS.2018.2883787; Jensen D, 2010, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, VOL 8, PTS A AND B, P1033; Microsoft, The STRIDE Threat Model; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; OWASP, Threat Modeling Process; Paté-Cornell ME, 2018, RISK ANAL, V38, P226, DOI 10.1111/risa.12844; Pedersen Magnus, 2022, Ph.D. Thesis,; Petry K, 2007, J INTELL DISABIL RES, V51, P334, DOI 10.1111/j.1365-2788.2006.00882.x; Questback, 2023, Questback: Survey Solution 'I&' Feedback Platform; Rose Scott, 2020, SP 800-207: Zero Trust Architecture; Sprenkle D.H., 2005, RES METHODS FAMILY T, V2nd; Standard Military, 1980, Technical report no. MIL-STD-1629A; Suomalainen J, 2021, IEEE OPEN J COMM SOC, V2, P1590, DOI 10.1109/OJCOMS.2021.3093529; Ullman David, Decision and uncertainty management for human and human/agent teams; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]	30	0	0	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			978-0-7918-8729-5				2023														10	Engineering, Industrial; Engineering, Manufacturing; Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering	BW9TC					2024-07-03	WOS:001221468500049
J	Lee, YQ; Chen, CT; Chen, CC; Lee, CH; Chen, P; Wu, CS; Dai, HJ				Lee, You-Qian; Chen, Ching-Tai; Chen, Chien-Chang; Lee, Chung-Hong; Chen, Peitsz; Wu, Chi-Shin; Dai, Hong-Jie			Unlocking the Secrets Behind Advanced Artificial Intelligence Language Models in Deidentifying Chinese-English Mixed Clinical Text: Development and Validation Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						code mixing; electronic health record; deidentification; pretrained language model; large language model; ChatGPT	DE-IDENTIFICATION	Background: The widespread use of electronic health records in the clinical and biomedical fields makes the removal of protected health information (PHI) essential to maintain privacy. However, a significant portion of information is recorded in unstructured textual forms, posing a challenge for deidentification. In multilingual countries, medical records could be written in a mixture of more than one language, referred to as code mixing. Most current clinical natural language processing techniques are designed for monolingual text, and there is a need to address the deidentification of code -mixed text. Objective: The aim of this study was to investigate the effectiveness and underlying mechanism of fine-tuned pretrained language models (PLMs) in identifying PHI in the code -mixed context. Additionally, we aimed to evaluate the potential of prompting large language models (LLMs) for recognizing PHI in a zero -shot manner. Methods: We compiled the first clinical code -mixed deidentification data set consisting of text written in Chinese and English. We explored the effectiveness of fine-tuned PLMs for recognizing PHI in code -mixed content, with a focus on whether PLMs exploit naming regularity and mention coverage to achieve superior performance, by probing the developed models' outputs to examine their decision -making process. Furthermore, we investigated the potential of prompt -based in -context learning of LLMs for recognizing PHI in code -mixed text. Results: The developed methods were evaluated on a code -mixed deidentification corpus of 1700 discharge summaries. We observed that different PHI types had preferences in their occurrences within the different types of language -mixed sentences, and PLMs could effectively recognize PHI by exploiting the learned name regularity. However, the models may exhibit suboptimal results when regularity is weak or mentions contain unknown words that the representations cannot generate well. We also found that the availability of code -mixed training instances is essential for the model's performance. Furthermore, the LLM-based deidentification method was a feasible and appealing approach that can be controlled and enhanced through natural language prompts. Conclusions: The study contributes to understanding the underlying mechanism of PLMs in addressing the deidentification process in the code -mixed context and highlights the significance of incorporating code -mixed training instances into the model training phase. To support the advancement of research, we created a manipulated subset of the resynthesized data set available for research purposes. Based on the compiled data set, we found that the LLM-based deidentification method is a feasible approach, but carefully crafted prompts are essential to avoid unwanted output. However, the use of such methods in the hospital setting requires careful consideration of data security and privacy concerns. Further research could explore the augmentation of PLMs and LLMs with external knowledge to improve their strength in recognizing rare PHI.	[Lee, You-Qian] Asustek Comp Inc, Dialogue Syst Tech Dept, Intelligent Robot, Taipei, Taiwan; [Lee, You-Qian; Dai, Hong-Jie] Natl Kaohsiung Univ Sci & Technol, Coll Elect Engn & Comp Sci, Dept Elect Engn, Intelligent Syst Lab, Kaohsiung, Taiwan; [Chen, Ching-Tai] Asia Univ, Dept Bioinformat & Med Engn, Taichung, Taiwan; [Chen, Ching-Tai] Asia Univ, Ctr Precis Hlth Res, Taichung, Taiwan; [Chen, Chien-Chang] Natl Kaohsiung Univ Sci & Technol, Coll Elect Engn & Comp Sci, Dept Elect Engn, Electromagnet Sensing Control & AI Comp Syst Lab, Kaohsiung, Taiwan; [Lee, Chung-Hong] Natl Kaohsiung Univ Sci & Technol, Coll Elect Engn & Comp Sci, Dept Elect Engn, Knowledge Discovery & Data Min Lab, Kaohsiung, Taiwan; [Chen, Peitsz] Feng Chia Univ, Dept Chem Engn, Taichung, Taiwan; [Wu, Chi-Shin] Natl Hlth Res Inst, Natl Ctr Geriatr & Welf Res, Zhunan, Taiwan; [Dai, Hong-Jie] Natl Hlth Res Inst, Natl Inst Canc Res, Tainan, Taiwan; [Dai, Hong-Jie] Kaohsiung Med Univ, Coll Med, Sch Postbaccalaureate Med, Kaohsiung, Taiwan; [Dai, Hong-Jie] Kaohsiung Med Univ, Ctr Big Data Res, Kaohsiung, Taiwan; [Dai, Hong-Jie] Natl Kaohsiung Univ Sci & Technol, Coll Elect Engn & Comp Sci, Dept Elect Engn, Intelligent Syst Lab, 415 Jiangong Rd, Kaohsiung 80778, Taiwan	ASUSTek Computer; National Kaohsiung University of Science & Technology; Asia University Taiwan; Asia University Taiwan; National Kaohsiung University of Science & Technology; National Kaohsiung University of Science & Technology; Feng Chia University; National Health Research Institutes - Taiwan; National Health Research Institutes - Taiwan; Kaohsiung Medical University; Kaohsiung Medical University; National Kaohsiung University of Science & Technology	Dai, HJ (corresponding author), Natl Kaohsiung Univ Sci & Technol, Coll Elect Engn & Comp Sci, Dept Elect Engn, Intelligent Syst Lab, 415 Jiangong Rd, Kaohsiung 80778, Taiwan.	hjdai@nkust.edu.tw	Dai, Hong-Jie/C-2526-2013	Dai, Hong-Jie/0000-0002-1516-7255; Chen, Chien-Chang/0009-0008-0103-3089; WU, CHI-SHIN/0000-0003-2762-7295				Aberdeen J, 2010, INT J MED INFORM, V79, P849, DOI 10.1016/j.ijmedinf.2010.09.007; Aguilar G, 2018, COMPUTATIONAL APPROACHES TO LINGUISTIC CODE-SWITCHING, P138; Ahmed T, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75544-1; Alla NLV, 2021, Computer Methods and Programs in Biomedicine Update, V1, DOI [10.1016/j.cmpbup.2021.100024, DOI 10.1016/J.CMPBUP.2021.100024]; ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434; Alqurashi HS, 2022, Journal of Language and Linguistic Studies, V18, P344; [Anonymous], 2019, ICLR WORKSH DEB MACH; Bojanowski P, 2017, Arxiv, DOI [arXiv:1607.04606, DOI 10.48550/ARXIV.1607.04606]; Brathen S, 2021, P 23 NORD C COMP LIN; Cannon Jay, 2010, J AHIMA, V81, P36; Dai HJ, 2021, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.533949; Dernoncourt F, 2017, J AM MED INFORM ASSN, V24, P596, DOI 10.1093/jamia/ocw156; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Douglass MM, 2005, COMPUT CARDIOL; Dowlagar S, 2023, COMPUT SPEECH LANG, V78, DOI 10.1016/j.csl.2022.101449; federalregister, Standards for Privacy of Individually Identifiable Health Information; Feng S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3719; Ferrández O, 2013, J AM MED INFORM ASSN, V20, P77, DOI 10.1136/amiajnl-2012-001020; Gamback B, 2014, P 11 INT C NAT LANG; Gao N, 2023, IEEE-ACM T AUDIO SPE, V31, P4014, DOI 10.1109/TASLP.2023.3316422; Godin F, 2015, P WORKSH NOIS US GEN, P146, DOI DOI 10.18653/V1/W15-4322; Winata GI, 2019, Arxiv, DOI arXiv:1805.12061; ISLab: Intelligent System Lab, About us; Gutiérrez BJ, 2022, Arxiv, DOI arXiv:2203.08410; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Jonnagaddala J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-99554-9; Karuthan A., 2015, The English language needs of nurses in medical tourism in Malaysia; Keresztes C, 2010, SZTE Doktori Repozitorium; Kim H, 2022, Arxiv, DOI arXiv:2101.00160; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Smith SL, 2017, Arxiv, DOI arXiv:1702.03859; Lee You-Qian, 2022, Stud Health Technol Inform, V290, P627, DOI 10.3233/SHTI220153; Lin HY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7291; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Neamatullah I, 2008, BMC MED INFORM DECIS, V8, DOI 10.1186/1472-6947-8-32; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996; Saeed M, 2011, CRIT CARE MED, V39, P952, DOI 10.1097/CCM.0b013e31820a92c6; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shaalan K, 2009, J AM SOC INF SCI TEC, V60, P1652, DOI 10.1002/asi.21090; Silvestri S, 2019, IEEE WORLD CONGR SER, P283, DOI 10.1109/SERVICES.2019.00082; Stubbs A, 2017, J BIOMED INFORM, V75, pS4, DOI 10.1016/j.jbi.2017.06.011; Stubbs A, 2015, J BIOMED INFORM, V58, pS11, DOI 10.1016/j.jbi.2015.06.007; Tang TC, 2020, IEEE ACCESS, V8, P193248, DOI 10.1109/ACCESS.2020.3030468; Trivedi S, 2018, P 3 WORKSH COMP APPR, DOI [10.18653/v1/w18-3220, DOI 10.18653/V1/W18-3220]; Uzuner Ö, 2007, J AM MED INFORM ASSN, V14, P550, DOI 10.1197/jamia.M2444; Vakili T, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4245; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Virtanen A., 2019, Multilingual is not enough: BERT for Finnish; Wang CK, 2022, IEEE ACCESS, V10, P22875, DOI 10.1109/ACCESS.2022.3148396; Wang Hai, 2019, arXiv; Wei L., 1999, CODE SWITCHING CONVE, P156; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wu CS, 2020, J AFFECT DISORDERS, V260, P617, DOI 10.1016/j.jad.2019.09.044; WU S, 1992, COMMUN ACM, V35, P83, DOI 10.1145/135239.135244; Yang X, 2020, IEEE INT C IM PROC I, DOI [10.1109/ICIP40778.2020.9191097, DOI 10.1109/ICIP40778.2020.9191097]; Yulianti E, 2021, INT J ADV COMPUT SC, V12, P674; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	60	0	0	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JAN 25	2024	26								e48443	10.2196/48443	http://dx.doi.org/10.2196/48443			22	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	IP1M5	38271060	Green Published, gold			2024-07-03	WOS:001167441500001
J	Dorst, M; Zeevenhooven, N; Wilding, R; Mende, D; Brandt, BW; Zaura, E; Hoekstra, A; Sheraton, VM				Dorst, Mathieu; Zeevenhooven, Nathan; Wilding, Rory; Mende, Daniel; Brandt, Bernd W.; Zaura, Egija; Hoekstra, Alfons; Sheraton, Vivek M.			FAIR compliant database development for human microbiome data samples	FRONTIERS IN CELLULAR AND INFECTION MICROBIOLOGY			English	Article						database; fair principles; general data protection regulation (GDPR); (meta)data; microbiome; pseudonymize; real-time		Introduction: Sharing microbiome data among researchers fosters new innovations and reduces cost for research. Practically, this means that the (meta)data will have to be standardized, transparent and readily available for researchers. The microbiome data and associated metadata will then be described with regards to composition and origin, in order to maximize the possibilities for application in various contexts of research. Here, we propose a set of tools and protocols to develop a real-time FAIR (Findable. Accessible, Interoperable and Reusable) compliant database for the handling and storage of human microbiome and host-associated data. Methods: The conflicts arising from privacy laws with respect to metadata, possible human genome sequences in the metagenome shotgun data and FAIR implementations are discussed. Alternate pathways for achieving compliance in such conflicts are analyzed. Sample traceable and sensitive microbiome data, such as DNA sequences or geolocalized metadata are identified, and the role of the GDPR (General Data Protection Regulation) data regulations are considered. For the construction of the database, procedures have been realized to make data FAIR compliant, while preserving privacy of the participants providing the data. Results and discussion: An open-source development platform, Supabase, was used to implement the microbiome database. Researchers can deploy this real-time database to access, upload, download and interact with human microbiome data in a FAIR complaint manner. In addition, a large language model (LLM) powered by ChatGPT is developed and deployed to enable knowledge dissemination and non-expert usage of the database.	[Dorst, Mathieu; Zeevenhooven, Nathan] Univ Amsterdam, Informat Inst, Amsterdam, Netherlands; [Wilding, Rory] Supabase Ltd Liabil Co LLC, San Francisco, CA USA; [Mende, Daniel] Univ Amsterdam, Amsterdam Inst Infect & Immun, Med Ctr, Amsterdam, Netherlands; [Brandt, Bernd W.; Zaura, Egija] Vrije Univ Amsterdam, Acad Ctr Dent Amsterdam, Dept Prevent Dent, Amsterdam, Netherlands; [Brandt, Bernd W.; Zaura, Egija] Univ Amsterdam, Amsterdam, Netherlands; [Hoekstra, Alfons; Sheraton, Vivek M.] Univ Amsterdam, Informat Inst, Computat Sci Lab, Amsterdam, Netherlands	University of Amsterdam; University of Amsterdam; Academic Center for Dentistry Amsterdam; Vrije Universiteit Amsterdam; University of Amsterdam; University of Amsterdam	Sheraton, VM (corresponding author), Univ Amsterdam, Informat Inst, Computat Sci Lab, Amsterdam, Netherlands.	v.s.muniraj@uva.nl	Zaura, Egija/ADV-8519-2022	Zaura, Egija/0000-0003-1432-6194	Nederlandse Organisatie voor Wetenschappelijk Onderzoek10.13039/501100003246	Nederlandse Organisatie voor Wetenschappelijk Onderzoek10.13039/501100003246	No Statement Available	Abouelmehdi K, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0110-7; Abuimara T, 2022, BUILD SERV ENG RES T, V43, P517, DOI 10.1177/01436244211069655; Alharbi E, 2021, DATA INTELLIGENCE, V3, P507, DOI 10.1162/dint_a_00109; Baglamis S., 2023, Computational science-ICCS 2023, p10475 345; Bequignon OJM, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-022-00672-x; Berg G, 2020, MICROBIOME, V8, DOI 10.1186/s40168-020-00875-0; Bray MA, 2017, GIGASCIENCE, V6, DOI 10.1093/gigascience/giw014; Cao KY, 2020, IEEE ACCESS, V8, P85714, DOI 10.1109/ACCESS.2020.2991734; Chue Hong N.P., 2022, FAIR PRINCIPLES RES, DOI [10.15497/RDA00068, DOI 10.15497/RDA00068]; Dong JS, 2022, J ROY STAT SOC B, V84, P3, DOI 10.1111/rssb.12454; Eloe-Fadrosh EA, 2022, NUCLEIC ACIDS RES, V50, pD828, DOI 10.1093/nar/gkab990; European Commission, 2018, Cost-benefit analysis for FAIR research data: cost of not having FAIR research data, DOI DOI 10.2777/02999; Garabedian NT, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01429-9; Gursoy G, 2022, NAT REV GENET, V23, P245, DOI 10.1038/s41576-021-00428-7; Hittmeir M, 2022, LECT NOTES COMPUT SC, V13383, P15, DOI 10.1007/978-3-031-10684-2_2; Huttenhower C, 2023, NAT MICROBIOL, V8, P1960, DOI 10.1038/s41564-023-01484-x; Irving R., 2019, Emery and rimoin's principles and practice of medical genetics and genomics, P327, DOI [10.1016/B978-0-12-812536-6.00013-4, DOI 10.1016/B978-0-12-812536-6.00013-4]; Machanavajjhala A., 2006, ACM T KNOWL DISCOV D, P24, DOI [DOI 10.1145/1217299.1217302, 10.1109/icde.2006.1, DOI 10.1109/ICDE.2006.1]; Martínez-García A, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e15733; Mayer R, 2023, 18TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY & SECURITY, ARES 2023, DOI 10.1145/3600160.3600178; Roche DG, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002295; Rumbavicius I, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05492-w; Santos LOBD, 2023, DATA INTELLIGENCE, V5, P163, DOI 10.1162/dint_a_00160; Sheraton MV, 2019, J THEOR BIOL, V482, DOI 10.1016/j.jtbi.2019.109994; Subramanian I, 2020, BIOINFORM BIOL INSIG, V14, DOI 10.1177/1177932219899051; Supabase Inc, Supabase vector database and AI toolkit; Varrazzo D., Psycopg-PostgreSQL database adapter for Python; Wilding R, 2022, J ULTRASOUND, V25, P659, DOI 10.1007/s40477-021-00642-3; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Willemink MJ, 2020, RADIOLOGY, V295, P4, DOI 10.1148/radiol.2020192224; Yilmaz P, 2011, NAT BIOTECHNOL, V29, P415, DOI 10.1038/nbt.1823; Yoong SL, 2022, J PUBLIC HEALTH-UK, V44, pE582, DOI 10.1093/pubmed/fdac031	32	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2235-2988			FRONT CELL INFECT MI	Front. Cell. Infect. Microbiol.	MAY 7	2024	14								1384809	10.3389/fcimb.2024.1384809	http://dx.doi.org/10.3389/fcimb.2024.1384809			11	Immunology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Immunology; Microbiology	RK1S1	38774631	gold			2024-07-03	WOS:001227472300001
J	Cai, XB; Lai, HT; Wang, X; Wang, LY; Liu, W; Yijun, W; Wang, ZX; Cao, DS; Zeng, XX				Cai, Xibao; Lai, Houtim; Wang, Xing; Wang, Longyue; Liu, Wei; Yijun, Wang; Wang, Zixu; Cao, Dongsheng; Zeng, Xiangxiang			Comprehensive evaluation of molecule property prediction with ChatGPT	METHODS			English	Article						Molecule property prediction; ChatGPT; Evaluation; Prompt; Few-shot		The versatility of ChatGPT in performing a diverse range of tasks has elicited considerable interest on its potential applications within professional fields. Taking drug discovery as a testbed, this paper provides a comprehensive evaluation of ChatGPT's ability on molecule property prediction. The study focuses on three aspects: 1) Effects of different prompt settings, where we investigate the impact of varying prompts on the prediction outcomes of ChatGPT; 2) Comprehensive evaluation on molecule property prediction, where we conduct a comprehensive evaluation on 53 ADMET-related endpoints; 3) Analysis of ChatGPT's potential and limitations, where we make comparisons with models tailored for molecule property prediction, thus gaining a more accurate understanding of ChatGPT's capabilities and limitations in this area. Through comprehensive evaluation, we find that 1) With appropriate prompt settings, ChatGPT can attain satisfactory prediction outcomes that are competitive with specialized models designed for those tasks. 2) Prompt settings significantly affect ChatGPT's performance. Among all prompt settings, the strategy of selecting examples in few -shot has the greatest impact on results. Scaffold sampling greatly outperforms random sampling. 3) The capacity of ChatGPT to accomplish highprecision predictions is significantly influenced by the quality of examples provided, which may constrain its practical applicability in real -world scenarios. This work highlights ChatGPT's potential and limitations on molecule property prediction, which we hope can inspire future design and evaluation of Large Language Models within scientific domains.	[Cai, Xibao; Yijun, Wang; Zeng, Xiangxiang] Hunan Univ, Dept Comp Sci, Changsha, Peoples R China; [Lai, Houtim; Wang, Xing; Wang, Longyue; Liu, Wei] Tencent AI Lab, Shenzhen, Peoples R China; [Wang, Zixu] Univ Tsukuba, Tsukuba, Japan; [Cao, Dongsheng] Cent South Univ, Xiangya Sch Pharmaceut Sci, Changsha, Peoples R China	Hunan University; Tencent; University of Tsukuba; Central South University	Cai, XB; Yijun, W (corresponding author), Hunan Univ, Dept Comp Sci, Changsha, Peoples R China.; Wang, LY (corresponding author), Tencent AI Lab, Shenzhen, Peoples R China.	dalecai@hnu.edu.cn; vincentwang0229@gmail.com; wyjun@hnu.edu.cn	zeng, xiangxiang/H-3771-2014	Cai, Xibao/0009-0002-2656-6566				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ateia S., 2023, arXiv; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Q, 2023, bioRxiv, DOI [10.1101/2023.04.19.537463, 10.1101/2023.04.19.537463, DOI 10.1101/2023.04.19.537463]; Chen S, 2023, ARXIV; Guo TC, 2023, Arxiv, DOI arXiv:2305.18365; Jablonka KM, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-fw8n4, 10.26434/chemrxiv-2023-fw8n4, DOI 10.26434/CHEMRXIV-2023-FW8N4]; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramos MC, 2023, Arxiv, DOI [arXiv:2304.05341, DOI 10.48550/ARXIV.2304.05341]; Sharma G, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-qgs3k, 10.26434/chemrxiv-2023-qgs3k, DOI 10.26434/CHEMRXIV-2023-QGS3K]; Wang YZ, 2023, Arxiv, DOI [arXiv:2308.10275, DOI 10.48550/ARXIV.2308.10275]; Wu FX, 2020, FRONT CHEM, V8, DOI 10.3389/fchem.2020.00726; Xiong GL, 2021, NUCLEIC ACIDS RES, V49, pW5, DOI 10.1093/nar/gkab255; Xu MR, 2023, Arxiv, DOI [arXiv:2303.16129, DOI 10.48550/ARXIV.2303.16129]; Zhang C., 2023, ARXIV; Zhu JJ, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01818	19	1	1	17	17	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1046-2023	1095-9130		METHODS	Methods	FEB	2024	222						133	141		10.1016/j.ymeth.2024.01.004	http://dx.doi.org/10.1016/j.ymeth.2024.01.004		JAN 2024	9	Biochemical Research Methods; Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	JO0T6	38242382				2024-07-03	WOS:001173998000001
J	O'Brien, T; Stremmel, J; Pio-Lopez, L; McMillen, P; Rasmussen-Ivey, C; Levin, M				O'Brien, Thomas; Stremmel, Joel; Pio-Lopez, Leo; McMillen, Patrick; Rasmussen-Ivey, Cody; Levin, Michael			Machine learning for hypothesis generation in biology and medicine: exploring the latent space of neuroscience and developmental bioelectricity	DIGITAL DISCOVERY			English	Article							STRONG INFERENCE; ION CHANNELS; REGENERATION; ONTOLOGY; BIOINFORMATICS; DISCOVERY; DATABASE; GENE	Artificial intelligence is a powerful tool that could be deployed to accelerate the scientific enterprise. Here we address a major unmet need: use of existing scientific literature to generate novel hypotheses. We use a deep symmetry between the fields of neuroscience and developmental bioelectricity to evaluate a new tool, FieldSHIFT. FieldSHIFT is an in-context learning framework using a large language model to facilitate candidate scientific research from existing published studies, serving as a tool to generate hypotheses at scale. We release a new dataset for translating between the neuroscience and developmental bioelectricity domains and show how FieldSHIFT helps human scientists explore a latent space of papers that could exist, providing a rich field of suggested future research. We demonstrate the performance of FieldSHIFT for hypothesis generation relative to human-generated developmental biology research directions then test a key prediction of this model using bioinformatics, showing a surprising conservation of molecular mechanisms involved in cognitive behavior and developmental morphogenesis. By allowing scientists to rapidly explore symmetries and meta-parameters that exist in a corpus of scientific papers, we show how machine learning can potentiate human creativity and assist with one of the most interesting and crucial aspects of research: identifying insights from data and generating potential candidates for research agendas. FieldSHIFT uses in-context learning to translate neuroscience abstracts into developmental biology abstracts based on example concept mappings, creating new research hypotheses at scale.	[O'Brien, Thomas; Stremmel, Joel] Streams, Winona, MN 55987 USA; [Pio-Lopez, Leo; McMillen, Patrick; Rasmussen-Ivey, Cody; Levin, Michael] Tufts Univ, Allen Discovery Ctr, 200 Boston Ave,Suite 4600, Medford, MA 02155 USA; [Levin, Michael] Harvard Univ, Wyss Inst Biol Inspired Engn, Boston, MA 02115 USA	Tufts University; Harvard University	Levin, M (corresponding author), Tufts Univ, Allen Discovery Ctr, 200 Boston Ave,Suite 4600, Medford, MA 02155 USA.; Levin, M (corresponding author), Harvard Univ, Wyss Inst Biol Inspired Engn, Boston, MA 02115 USA.	michael.levin@tufts.edu	Levin, Michael/A-5918-2011	Levin, Michael/0000-0001-7292-8084; Stremmel, Joel/0009-0002-4540-7982	John Templeton Foundation [62212]; John Templeton Foundation	John Templeton Foundation; John Templeton Foundation	We thank Giovanni Pezzulo for helpful discussions, and Juanita Mathews for manually rating AI-derived text. We also thank Julia Poirier for assistance with the manuscript. M. L. gratefully acknowledges support via Grant 62212 from the John Templeton Foundation. The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the John Templeton Foundation.	Adams DS, 2013, CELL TISSUE RES, V352, P95, DOI 10.1007/s00441-012-1329-4; Allen M, 2018, SYNTHESE, V195, P2459, DOI 10.1007/s11229-016-1288-5; Asche S, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23828-z; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Bates E, 2015, ANNU REV CELL DEV BI, V31, P231, DOI 10.1146/annurev-cellbio-100814-125338; Beard DA, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000459; Biswas S, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102131; Bizzarri M, 2019, NAT REV MOL CELL BIO, V20, P261, DOI 10.1038/s41580-019-0127-1; Blackiston DJ, 2009, CELL CYCLE, V8, P3527, DOI 10.4161/cc.8.21.9888; Bohm D., 1998, On creativity; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; BUEHLER M, 2023, APPL MECH REV, P1; Buehler MJ, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100692; Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2; Burr HS, 1935, Q REV BIOL, V10, P322, DOI 10.1086/394488; Carbon S, 2021, NUCLEIC ACIDS RES, V49, pD325, DOI 10.1093/nar/gkaa1113; Chattopadhyay I, 2014, J R SOC INTERFACE, V11, DOI 10.1098/rsif.2014.0826; Constant A, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0685; Davis RH, 2006, PERSPECT BIOL MED, V49, P238, DOI 10.1353/pbm.2006.0022; Deiana AM, 2022, FRONT BIG DATA, V5, DOI 10.3389/fdata.2022.787421; DeVita VT, 2008, NAT CLIN PRACT ONCOL, V5, P239, DOI 10.1038/ncponc1126; DeVita VT, 2008, NAT CLIN PRACT ONCOL, V5, P177, DOI 10.1038/ncponc1094; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dodig-Crnkovic G, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24111576; Dong Q., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.00234; Feltes BC, 2018, MOL OMICS, V14, P289, DOI 10.1039/c8mo00111a; Fields C, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24060819; Fields C, 2020, PHYSIOLOGY, V35, P16, DOI 10.1152/physiol.00027.2019; FORSCHER BK, 1963, SCIENCE, V142, P339, DOI 10.1126/science.142.3590.339; Freitag M., 2017, 1 WORKSH NEUR MACH T; Friedman DA, 2021, FRONT BEHAV NEUROSCI, V15, DOI 10.3389/fnbeh.2021.647732; Friston K, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2014.1383; Fudge DS, 2014, J EXP BIOL, V217, P1202, DOI 10.1242/jeb.104976; Gianti E, 2022, BIOMACROMOLECULES, V23, P576, DOI 10.1021/acs.biomac.1c01436; Gibney E, 2022, NATURE, V608, P250, DOI 10.1038/d41586-022-02035-w; Gil Y, 2014, SCIENCE, V346, P171, DOI 10.1126/science.1259439; Grizou J, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay4237; Grossberg S., 1978, Progress in Theoretical Biology; Harris MP, 2021, DEVELOPMENT, V148, DOI 10.1242/dev.180794; Jewett DL, 2005, SCIENTIST, V19, P10; Kaplan J., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.08361; Kauffman Stuart A., 1993; King RD, 2004, NATURE, V427, P247, DOI 10.1038/nature02236; King RD, 2009, SCIENCE, V324, P85, DOI 10.1126/science.1165620; Kirchhoff M, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0792; Lagasse E., 2023, TRENDS MOL MED; Langton C. G., 1995, COMPLEX ADAPTIVE SYS, Vvol. xi; Larkin JW, 2018, CELL SYST, V7, P137, DOI 10.1016/j.cels.2018.06.005; Levin M, 1998, DEV BIOL, V203, P90, DOI 10.1006/dbio.1998.9024; Levin M, 1997, DEV BIOL, V189, P57, DOI 10.1006/dbio.1997.8662; LEVIN M, 1995, CELL, V82, P803, DOI 10.1016/0092-8674(95)90477-8; Levin M, 2023, ANIM COGN, V26, P1865, DOI 10.1007/s10071-023-01780-3; Levin M, 2022, FRONT SYST NEUROSCI, V16, DOI 10.3389/fnsys.2022.768201; Levin M, 2021, CELL, V184, P1971, DOI 10.1016/j.cell.2021.02.034; Levin M, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.02688; Levin M, 2018, BIOSYSTEMS, V164, P76, DOI 10.1016/j.biosystems.2017.08.009; Levin M, 2014, J PHYSIOL-LONDON, V592, P2295, DOI 10.1113/jphysiol.2014.271940; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Lianghao D., 2017, SOCIAL NETWORK ANAL; Liu JT, 2017, SCIENCE, V356, P638, DOI 10.1126/science.aah4204; Lobo D, 2016, BIOINFORMATICS, V32, P2681, DOI 10.1093/bioinformatics/btw299; Lobo D, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004295; Lobo D, 2014, REGENERATION, V1, P37, DOI 10.1002/reg2.13; Lobo D, 2014, BIOINFORMATICS, V30, P3598, DOI 10.1093/bioinformatics/btu582; Lobo D, 2013, BIOINFORMATICS, V29, P1098, DOI 10.1093/bioinformatics/btt088; Lobo D, 2013, BIOL OPEN, V2, P156, DOI 10.1242/bio.20123400; Loshchilov I, 2017, INT C LEARNING REPRE; Lu HY, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/ac160f; Lund E., 1947, Bioelectric fields and growth; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020; Martinez-Corral R, 2019, PHILOS T R SOC B, V374, DOI 10.1098/rstb.2018.0382; Mathews J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100737; Mathews J, 2018, CURR OPIN BIOTECH, V52, P134, DOI 10.1016/j.copbio.2018.03.008; McConnell J. V, 1970, P71; MCCONNELL JV, 1959, J COMP PHYSIOL PSYCH, V52, P1, DOI 10.1037/h0048028; NUCCITELLI R, 1986, BIOESSAYS, V5, P292, DOI 10.1002/bies.950050616; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Ouyang L., 2022, NEURIPS; Penedo G., 2023, arXiv; Pezzulo G, 2015, INTEGR BIOL-UK, V7, P1487, DOI 10.1039/c5ib00221d; Pezzulo G, 2018, TRENDS COGN SCI, V22, P294, DOI 10.1016/j.tics.2018.01.009; Pezzulo G, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0555; Pio-Lopez L, 2023, INTERFACE FOCUS, V13, DOI 10.1098/rsfs.2022.0072; Pio-Lopez L, 2023, DRUG DISCOV TODAY, V28, P1, DOI 10.1016/j.drudis.2023.103585; Pio-Lopez L, 2022, FRONT COMPUT NEUROSC, V16, DOI 10.3389/fncom.2022.988977; PLATT JR, 1964, SCIENCE, V146, P347, DOI 10.1126/science.146.3642.347; Polya G., 1957, SOLVE IT, DOI DOI 10.1515/9781400828678; Prindle A, 2015, NATURE, V527, P59, DOI 10.1038/nature15709; Qi Da., 2010, Journal of Integrative Bioinformatics, V7, DOI [DOI 10.2390/BIECOLL-JIB-2010-126, 10.1515/jib-2010-126, DOI 10.1515/JIB-2010-126]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sengupta B, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002400; Soldatova LN, 2006, BIOINFORMATICS, V22, pE464, DOI 10.1093/bioinformatics/btl207; Sparkes Andrew, 2010, Autom Exp, V2, P1, DOI 10.1186/1759-4499-2-1; Stern CD, 2022, DEV BIOL, V488, P30, DOI 10.1016/j.ydbio.2022.05.001; Sullivan Kelly G, 2016, Commun Integr Biol, V9, pe1192733, DOI 10.1080/19420889.2016.1192733; Sundelacruz S, 2009, STEM CELL REV REP, V5, P231, DOI 10.1007/s12015-009-9080-2; Tan ZX, 2020, AI OPEN, V1, P5, DOI 10.1016/j.aiopen.2020.11.001; Touvron H., 2023, arXiv; van den Heuvel MP, 2019, BIOL PSYCHIAT, V86, P512, DOI 10.1016/j.biopsych.2019.05.015; van Dijk ADJ, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2020.101890; Vasilevich A, 2018, CURR OPIN BIOMED ENG, V6, P74, DOI 10.1016/j.cobme.2018.03.005; Vaswani A, 2017, ADV NEUR IN, V30; Villoutreix P, 2021, DEVELOPMENT, V148, DOI 10.1242/dev.188474; Wang A., 2019, 33 INT C NEUR INF PR; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Westermayr J, 2021, J CHEM PHYS, V154, DOI 10.1063/5.0047760; Witkowski O, 2019, ARTIF LIFE, V25, P178, DOI 10.1162/artl_a_00288; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yang CY, 2020, CELL SYST, V10, P417, DOI 10.1016/j.cels.2020.04.002; Ye F., 2021, J PHYS C SER, V1744; Zhong SF, 2021, ENVIRON SCI TECHNOL, V55, P12741, DOI 10.1021/acs.est.1c01339	112	0	0	2	2	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2635-098X		DIGIT DISCOV	Digit. Discov.	FEB 14	2024	3	2								10.1039/d3dd00185g	http://dx.doi.org/10.1039/d3dd00185g		JAN 2024	16	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Chemistry; Computer Science	HQ0N4		gold			2024-07-03	WOS:001142699600001
J	Jiang, LY; Liu, XC; Nejatian, NP; Nasir-Moin, M; Wang, D; Abidin, A; Eaton, K; Riina, HA; Laufer, I; Punjabi, P; Miceli, M; Kim, NC; Orillac, C; Schnurman, Z; Livia, C; Weiss, H; Kurland, D; Neifert, S; Dastagirzada, Y; Kondziolka, D; Cheung, ATM; Yang, GC; Cao, M; Flores, M; Costa, AB; Aphinyanaphongs, Y; Cho, KYHY; Oermann, EK				Jiang, Lavender Yao; Liu, Xujin Chris; Nejatian, Nima Pour; Nasir-Moin, Mustafa; Wang, Duo; Abidin, Anas; Eaton, Kevin; Riina, Howard Antony; Laufer, Ilya; Punjabi, Paawan; Miceli, Madeline; Kim, Nora C.; Orillac, Cordelia; Schnurman, Zane; Livia, Christopher; Weiss, Hannah; Kurland, David; Neifert, Sean; Dastagirzada, Yosef; Kondziolka, Douglas; Cheung, Alexander T. M.; Yang, Grace; Cao, Ming; Flores, Mona; Costa, Anthony B.; Aphinyanaphongs, Yindalon; Cho, Kyunghyun; Oermann, Eric Karl			Health system-scale language models are all-purpose prediction engines	NATURE			English	Article								Physicians make critical time-constrained decisions every day. Clinical predictive models can help physicians and administrators make decisions by forecasting clinical and operational events. Existing structured data-based clinical predictive models have limited use in everyday practice owing to complexity in data processing, as well as model development and deployment(1-3). Here we show that unstructured clinical notes from the electronic health record can enable the training of clinical language models, which can be used as all-purpose clinical predictive engines with low-resistance development and deployment. Our approach leverages recent advances in natural language processing(4,5) to train a large language model for medical language (NYUTron) and subsequently fine-tune it across a wide range of clinical and operational predictive tasks. We evaluated our approach within our health system for five such tasks: 30-day all-cause readmission prediction, in-hospital mortality prediction, comorbidity index prediction, length of stay prediction, and insurance denial prediction. We show that NYUTron has an area under the curve (AUC) of 78.7-94.9%, with an improvement of 5.36-14.7% in the AUC compared with traditional models. We additionally demonstrate the benefits of pretraining with clinical text, the potential for increasing generalizability to different sites through fine-tuning and the full deployment of our system in a prospective, single-arm trial. These results show the potential for using clinical language models in medicine to read alongside physicians and provide guidance at the point of care.	[Jiang, Lavender Yao; Liu, Xujin Chris; Nasir-Moin, Mustafa; Riina, Howard Antony; Laufer, Ilya; Kim, Nora C.; Orillac, Cordelia; Schnurman, Zane; Livia, Christopher; Weiss, Hannah; Kurland, David; Neifert, Sean; Dastagirzada, Yosef; Kondziolka, Douglas; Cheung, Alexander T. M.; Yang, Grace; Cao, Ming; Oermann, Eric Karl] NYU Langone Hlth, Dept Neurosurg, New York, NY 10016 USA; [Jiang, Lavender Yao; Yang, Grace; Cao, Ming; Cho, Kyunghyun; Oermann, Eric Karl] NYU, Ctr Data Sci, New York, NY 10012 USA; [Liu, Xujin Chris] Tandon Sch Engn, Elect & Comp Engn, New York, NY USA; [Nejatian, Nima Pour; Abidin, Anas; Flores, Mona; Costa, Anthony B.] NVIDIA, Santa Clara, CA USA; [Wang, Duo; Aphinyanaphongs, Yindalon] NYU Langone Hlth, Predict Analyt Unit, New York, NY USA; [Eaton, Kevin; Punjabi, Paawan; Miceli, Madeline] NYU Langone Hlth, Dept Internal Med, New York, NY USA; [Aphinyanaphongs, Yindalon] NYU Langone Hlth, Dept Populat Hlth, New York, NY USA; [Cho, Kyunghyun] Genentech Inc, Prescient Design, New York, NY USA; [Cho, Kyunghyun] NYU, Courant Inst Math Sci, New York, NY USA; [Cho, Kyunghyun] Canadian Inst Adv Res, Toronto, ON, Canada; [Oermann, Eric Karl] NYU Langone Hlth, Dept Radiol, New York, NY 10016 USA	NYU Langone Medical Center; New York University; New York University; New York University Tandon School of Engineering; Nvidia Corporation; NYU Langone Medical Center; NYU Langone Medical Center; NYU Langone Medical Center; Roche Holding; Genentech; New York University; Canadian Institute for Advanced Research (CIFAR); NYU Langone Medical Center	Oermann, EK (corresponding author), NYU Langone Hlth, Dept Neurosurg, New York, NY 10016 USA.; Oermann, EK (corresponding author), NYU, Ctr Data Sci, New York, NY 10012 USA.; Oermann, EK (corresponding author), NYU Langone Hlth, Dept Radiol, New York, NY 10016 USA.	eric.oermann@nyulangone.org		Abidin, Anas/0000-0003-0032-0664; Nasir-Moin, Mustafa/0000-0002-0389-1852	National Cancer Institute's Early Surgeon Scientist Program [3P30CA016087-41S1]; W.M.~Keck Foundation	National Cancer Institute's Early Surgeon Scientist Program; W.M.~Keck Foundation(W.M. Keck Foundation)	E.K.O. is supported by the National Cancer Institute's Early Surgeon Scientist Program (3P30CA016087-41S1) and the W.M. Keck Foundation. We would like to acknowledge J. Golfinos, whose vision and support made this project possible. We also would like to acknowledge our collaborators M. Costantino and K. Yie from the NYU Langone High-Performance Computing (HPC) team; without their tireless assistance in building and maintaining our GPU cluster, none of this research would have been possible. We would also like to thank D. Bar-Sagi and N. Mherabi, whose support for this research has made everything possible. We would like to thank B. Guzman from the NYU Langone Predictive Analytics Unit and V.J. Major from the NYU Grossman School of Medicine for their help with learning the SQL data structures used as part of this work. We would like to thank Y.(R.) Pang for reviewing and editing the initial manuscript. We would like to thank X. Yang from University of Florida for helping us with preprocessing and evaluating the i2b2 dataset. We thank S. Ciprut for helping with the REDCap survey and research administration for our team. We thank C. Fernandez-Granda, J. Kempe, V. Dhar, N. Wu, M. Barot, A. Chen, K. Link and F. Kwon for their valuable discussions.	Ayaz M, 2021, JMIR MED INF, V9, DOI 10.2196/21929; Bird Steven, 2004, Nltk: The natural language toolkit, P214; Bolton E., 2022, PUBMEDGPT 2 7B; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caetano Nuno, 2014, 16th International Conference on Enterprise Information Systems (ICEIS 2014). Proceedings, P407; Center for Disease Control, 2022, WHAT IS C DIFF; Charlson comorbidity index (CCI), 2022, MD CALC; CHARLSON ME, 1987, J CHRON DIS, V40, P373, DOI 10.1016/0021-9681(87)90171-8; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Child C G, 1964, Major Probl Clin Surg, V1, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gage BF, 2004, CIRCULATION, V110, P2287, DOI 10.1161/01.CIR.0000145172.55640.93; Gaube S, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00385-9; Hoffmann J., 2022, Advances in Neural Information Processing Systems (NeurIPS), V35, P30016; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Johnson M, 2023, INFORM SYST FRONT, V25, P2179, DOI 10.1007/s10796-021-10137-5; Kaplan J., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.08361; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kingma D. P., 2017, ARXIV; KNAUS WA, 1985, CRIT CARE MED, V13, P818, DOI 10.1097/00003246-198510000-00009; LEGALL JR, 1993, JAMA-J AM MED ASSOC, V270, P2957, DOI 10.1001/jama.270.24.2957; Liang HY, 2019, NAT MED, V25, P433, DOI 10.1038/s41591-018-0335-9; Liaw R., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1807.05118; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; National Library of Medicine, 2022, PUBMED CENTR PMC ART; NCBI Literature Resources, 2022, DOWNL PUBMED DAT; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Perez Ethan, 2021, ADV NEURAL INFORM PR, V34, P11054; PUGH RNH, 1973, BRIT J SURG, V60, P646, DOI 10.1002/bjs.1800600817; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Roberts M, 2021, NAT MACH INTELL, V3, P199, DOI 10.1038/s42256-021-00307-0; Shoeybi M., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.1909.08053; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Sun WY, 2013, J BIOMED INFORM, V46, pS5, DOI 10.1016/j.jbi.2013.07.004; Sundararajan V, 2004, J CLIN EPIDEMIOL, V57, P1288, DOI 10.1016/j.jclinepi.2004.03.012; Tomasev N, 2019, NATURE, V572, P116, DOI 10.1038/s41586-019-1390-1; van Walraven C., 2012, OPEN MED, V6, P80; van Walraven C, 2010, CAN MED ASSOC J, V182, P551, DOI 10.1503/cmaj.091117; WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28; WELLS PS, 1995, LANCET, V345, P1326, DOI 10.1016/S0140-6736(95)92535-X; Wikimedia Foundation, 2021, WIK DOWNL; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514; Yang G., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2211.07047; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	46	53	54	27	52	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JUL 13	2023	619	7969					357	+		10.1038/s41586-023-06160-y	http://dx.doi.org/10.1038/s41586-023-06160-y		JUN 2023	25	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	M8CN9	37286606	hybrid, Green Published			2024-07-03	WOS:001005804900017
J	Tufano, R; Dabic, O; Mastropaolo, A; Ciniselli, M; Bavota, G				Tufano, Rosalia; Dabic, Ozren; Mastropaolo, Antonio; Ciniselli, Matteo; Bavota, Gabriele			Code Review Automation: Strengths and Weaknesses of the State of the Art	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Review						Automated code review; empirical study	RECOMMENDATION	The automation of code review has been tackled by several researchers with the goal of reducing its cost. The adoption of deep learning in software engineering pushed the automation to new boundaries, with techniques imitating developers in generative tasks, such as commenting on a code change as a reviewer would do or addressing a reviewer's comment by modifying code. The performance of these techniques is usually assessed through quantitative metrics, e.g., the percentage of instances in the test set for which correct predictions are generated, leaving many open questions on the techniques' capabilities. For example, knowing that an approach is able to correctly address a reviewer's comment in 10% of cases is of little value without knowing what was asked by the reviewer: What if in all successful cases the code change required to address the comment was just the removal of an empty line? In this paper we aim at characterizing the cases in which three code review automation techniques tend to succeed or fail in the two above-described tasks. The study has a strong qualitative focus, with similar to 105 man-hours of manual inspection invested in manually analyzing correct and wrong predictions generated by the three techniques, for a total of 2,291 inspected predictions. The output of this analysis are two taxonomies reporting, for each of the two tasks, the types of code changes on which the experimented techniques tend to succeed or to fail, pointing to areas for future work. A result of our manual analysis was also the identification of several issues in the datasets used to train and test the experimented techniques. Finally, we assess the importance of researching in techniques specialized for code review automation by comparing their performance with ChatGPT, a general purpose large language model, finding that ChatGPT struggles in commenting code as a human reviewer would do.	[Tufano, Rosalia; Dabic, Ozren; Mastropaolo, Antonio; Ciniselli, Matteo; Bavota, Gabriele] Univ Svizzera Italiana, SEART Software Inst, CH-6900 Lugano, Switzerland	Universita della Svizzera Italiana	Bavota, G (corresponding author), Univ Svizzera Italiana, SEART Software Inst, CH-6900 Lugano, Switzerland.	rosalia.tufano@usi.ch; ozren.dabic@usi.ch; antonio.mastropaolo@usi.ch; matteo.ciniselli@usi.ch; gabriele.bavota@usi.ch		BAVOTA, Gabriele/0000-0002-2216-3148; Ciniselli, Matteo/0000-0002-0251-4473; Tufano, Rosalia/0009-0009-7017-3066; Dabic, Ozren/0009-0008-1670-7592; Mastropaolo, Antonio/0000-0002-7965-7712	European Research Council (ERC) through the European Union#x2019;s Horizon 2020	European Research Council (ERC) through the European Union#x2019;s Horizon 2020(European Research Council (ERC))	No Statement Available	Al-Zubaidi WHA, 2020, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, PROMISE 2020, P21, DOI 10.1145/3416508.3417115; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; [Anonymous], 1999, Sorting data; [Anonymous], Copilot website; [Anonymous], ChatGPT; Asthana S, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P937, DOI 10.1145/3338906.3340449; Bacchelli A, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P712, DOI 10.1109/ICSE.2013.6606617; Bavota G, 2015, PROC IEEE INT CONF S, P81, DOI 10.1109/ICSM.2015.7332454; Beller M., 2014, 11 WORK C MIN SOFTW, P202, DOI DOI 10.1145/2597073.2597082; Bosu Amiangshu, 2013, 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), P133, DOI 10.1109/ESEM.2013.23; Chouchen M, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106908; Falleri J.-R., 2014, P 29 ACM IEEE INT C, P313, DOI DOI 10.1145/2642937.2642982; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; GitHub, US; Grissom RJ, 2005, Effect sizes for research: A broad practical approach; HOLM S, 1979, SCAND J STAT, V6, P65; Hong Y, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P507, DOI 10.1145/3540250.3549119; Jiang J, 2019, J SYST SOFTWARE, V154, P196, DOI 10.1016/j.jss.2019.04.055; Jiang J, 2017, INFORM SOFTWARE TECH, V84, P48, DOI 10.1016/j.infsof.2016.10.006; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Li LW, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1009, DOI 10.1145/3540250.3549099; Li ZY, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1035, DOI 10.1145/3540250.3549081; Mäntylä MV, 2009, IEEE T SOFTWARE ENG, V35, P430, DOI 10.1109/TSE.2008.71; Mastropaolo A, 2023, PROC INT CONF SOFTW, P2149, DOI 10.1109/ICSE48619.2023.00181; Mastropaolo A, 2022, PROC INT CONF SOFTW, P2279, DOI 10.1145/3510003.3511561; McIntosh S., 2014, 11 WORK C MIN SOFTW, P192, DOI DOI 10.1145/2597073.2597076; Mirsaeedi E, 2020, PROC INT CONF SOFTW, P1183, DOI 10.1145/3377811.3380335; Morales R, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P171, DOI 10.1109/SANER.2015.7081827; Ouni A, 2016, PROC IEEE INT CONF S, P367, DOI 10.1109/ICSME.2016.65; Pacheco Carlos, 2007, OOPSLA 07 COMPANION, P815, DOI [10.1145/1297846.1297902, DOI 10.1145/1297846.1297902]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pascarella Luca, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274404; Prettier, About us; Raffel C, 2020, J MACH LEARN RES, V21; Rahman MM, 2016, 2016 IEEE/ACM 38TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING COMPANION (ICSE-C), P222, DOI 10.1145/2889160.2889244; Rigby P. C., 2013, P 2013 9 JOINT M FDN, P202, DOI DOI 10.1145/2491411.2491444; Rigby PC, 2014, ACM T SOFTW ENG METH, V23, DOI 10.1145/2594458; Rosner B, 2011, Fundamentals of biostatistics, VSeventh; Sadowski C, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING - SOFTWARE ENGINEERING IN PRACTICE TRACK (ICSE-SEIP 2018), P181, DOI 10.1145/3183519.3183525; Shi ST, 2019, AAAI CONF ARTIF INTE, P4910; Strand A, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP), P1, DOI 10.1145/3377813.3381365; Thongtanunam P, 2022, PROC INT CONF SOFTW, P237, DOI 10.1145/3510003.3510067; Thongtanunam P, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P141, DOI 10.1109/SANER.2015.7081824; Tian FW, 2022, PROC IEEE INT CONF S, P374, DOI 10.1109/ICSME55016.2022.00042; Tsantalis N, 2022, IEEE T SOFTWARE ENG, V48, P930, DOI 10.1109/TSE.2020.3007722; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Tufano M, 2019, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2019.00021; Tufano R, 2022, PROC INT CONF SOFTW, P2291, DOI 10.1145/3510003.3510621; Tufano R, 2021, PROC INT CONF SOFTW, P163, DOI 10.1109/ICSE43902.2021.00027; Wei JS, 2022, ADV NEUR IN; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Xia X, 2015, PROC IEEE INT CONF S, P261, DOI 10.1109/ICSM.2015.7332472; Xia ZL, 2017, 6TH INTERNATIONAL WORKSHOP ON SOFTWARE MINING (SOFTWAREMINING), P24, DOI 10.1109/SOFTWAREMINING.2017.8100850; Ying HC, 2016, 2016 IEEE/ACM 3RD INTERNATIONAL WORKSHOP ON CROWDSOURCING IN SOFTWARE ENGINEERING (CSI-SE), P29, DOI [10.1109/CSI-SE.2016.013, 10.1145/2897659.2897660]; Yu SW, 2022, J SYST SOFTWARE, V190, DOI 10.1016/j.jss.2022.111304; Yu Y, 2016, INFORM SOFTWARE TECH, V74, P204, DOI 10.1016/j.infsof.2016.01.004; Zanjani MB, 2016, IEEE T SOFTWARE ENG, V42, P530, DOI 10.1109/TSE.2015.2500238	57	2	2	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	FEB	2024	50	2					338	353		10.1109/TSE.2023.3348172	http://dx.doi.org/10.1109/TSE.2023.3348172			16	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	IP4I9		Green Submitted			2024-07-03	WOS:001167516600004
J	Toyama, Y; Harigai, A; Abe, M; Nagano, M; Kawabata, M; Seki, Y; Takase, K				Toyama, Yoshitaka; Harigai, Ayaka; Abe, Mirei; Nagano, Mitsutoshi; Kawabata, Masahiro; Seki, Yasuhiro; Takase, Kei			Performance evaluation of ChatGPT, GPT-4, and Bard on the official board examination of the Japan Radiology Society	JAPANESE JOURNAL OF RADIOLOGY			English	Article; Early Access						ChatGPT; GPT-4; Bard; Japan Radiology Society		Purpose Herein, we assessed the accuracy of large language models (LLMs) in generating responses to questions in clinical radiology practice. We compared the performance of ChatGPT, GPT-4, and Google Bard using questions from the Japan Radiology Board Examination (JRBE). Materials and methods In total, 103 questions from the JRBE 2022 were used with permission from the Japan Radiological Society. These questions were categorized by pattern, required level of thinking, and topic. McNemar's test was used to compare the proportion of correct responses between the LLMs. Fisher's exact test was used to assess the performance of GPT-4 for each topic category. Results ChatGPT, GPT-4, and Google Bard correctly answered 40.8% (42 of 103), 65.0% (67 of 103), and 38.8% (40 of 103) of the questions, respectively. GPT-4 significantly outperformed ChatGPT by 24.2% (p < 0.001) and Google Bard by 26.2% (p < 0.001). In the categorical analysis by level of thinking, GPT-4 correctly answered 79.7% of the lower-order questions, which was significantly higher than ChatGPT or Google Bard (p < 0.001). The categorical analysis by question pattern revealed GPT-4's superiority over ChatGPT (67.4% vs. 46.5%, p = 0.004) and Google Bard (39.5%, p < 0.001) in the single-answer questions. The categorical analysis by topic revealed that GPT-4 outperformed ChatGPT (40%, p = 0.013) and Google Bard (26.7%, p = 0.004). No significant differences were observed between the LLMs in the categories not mentioned above. The performance of GPT-4 was significantly better in nuclear medicine (93.3%) than in diagnostic radiology (55.8%; p < 0.001). GPT-4 also performed better on lower-order questions than on higher-order questions (79.7% vs. 45.5%, p < 0.001). Conclusion ChatGPTplus based on GPT-4 scored 65% when answering Japanese questions from the JRBE, outperforming ChatGPT and Google Bard. This highlights the potential of using LLMs to address advanced clinical questions in the field of radiology in Japan.	[Toyama, Yoshitaka; Harigai, Ayaka; Abe, Mirei; Kawabata, Masahiro] Tohoku Univ Hosp, Dept Diagnost Radiol, 1-1 Seiryo-Machi,Aoba Ku, Sendai 9808575, Japan; [Harigai, Ayaka] Tohoku Med & Pharmaceut Univ, Dept Radiol, Sendai, Japan; [Harigai, Ayaka; Takase, Kei] Tohoku Univ, Dept Diagnost Radiol, Grad Sch Med, Sendai, Japan; [Nagano, Mitsutoshi] Tohoku Univ, Sch Med, Sendai, Japan; [Seki, Yasuhiro] Tohoku Univ Hosp, Dept Radiat Oncol, Sendai, Japan	Tohoku University; Tohoku Medical & Pharmaceutical University; Tohoku University; Tohoku University; Tohoku University	Toyama, Y (corresponding author), Tohoku Univ Hosp, Dept Diagnost Radiol, 1-1 Seiryo-Machi,Aoba Ku, Sendai 9808575, Japan.	ytoyama0818@gmail.com		Toyama, Yoshitaka/0000-0003-0027-9681	We would like to thank the Japan Radiology Society for granting permission to use the official Japan Radiology Board Examination for our study. We also extend our sincere gratitude to the Japanese Board-Certified Radiologist Examination Committee for thoug	We would like to thank the Japan Radiology Society for granting permission to use the official Japan Radiology Board Examination for our study. We also extend our sincere gratitude to the Japanese Board-Certified Radiologist Examination Committee for thoug	We would like to thank the Japan Radiology Society for granting permission to use the official Japan Radiology Board Examination for our study. We also extend our sincere gratitude to the Japanese Board-Certified Radiologist Examination Committee for thoughtfully crafting high-quality examination questions that uphold the standards of board-certified radiologists in Japan.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anil R., 2023, PaLM 2 Technical Report; bard.google, Bard-Chat based AI tool from Google, powered by PaLM 2; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bloom B. S., 1956, Taxonomy of Educational Objectives: The Classification of Educational Goals; Bloom BS., 2001, TAXONOMY LEARNING TE, DOI DOI 10.7771/1541-5015.1355; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; ChatGPT, about us; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hatem R, 2023, JAMA INTERN MED, V183, P1177, DOI 10.1001/jamainternmed.2023.4231; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; open AI, GPT-4; radiology, Japan Radiological Society.; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Singhal K., 2023, EXPERT LEVEL MEDICAL, DOI DOI 10.48550/ARXIV.2305.09617; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; w3techs, Usage statistics of content languages for websites; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942	24	16	16	6	10	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1867-1071	1867-108X		JPN J RADIOL	Jpn. J. Radiol.	2023 OCT 4	2023										10.1007/s11604-023-01491-2	http://dx.doi.org/10.1007/s11604-023-01491-2		OCT 2023	7	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	HK0M4	37792149	hybrid			2024-07-03	WOS:001159277500001
J	Freidel, S; Schwarz, E				Freidel, Sebastian; Schwarz, Emanuel			Knowledge graphs in psychiatric research: Potential applications and future perspectives	ACTA PSYCHIATRICA SCANDINAVICA			English	Review; Early Access						knowledge graphs; machine learning; personalized medicine; psychiatry	PREDICTION	BackgroundKnowledge graphs (KGs) remain an underutilized tool in the field of psychiatric research. In the broader biomedical field KGs are already a significant tool mainly used as knowledge database or for novel relation detection between biomedical entities. This review aims to outline how KGs would further research in the field of psychiatry in the age of Artificial Intelligence (AI) and Large Language Models (LLMs).MethodsWe conducted a thorough literature review across a spectrum of scientific fields ranging from computer science and knowledge engineering to bioinformatics. The literature reviewed was taken from PubMed, Semantic Scholar and Google Scholar searches including terms such as "Psychiatric Knowledge Graphs", "Biomedical Knowledge Graphs", "Knowledge Graph Machine Learning Applications", "Knowledge Graph Applications for Biomedical Sciences". The resulting publications were then assessed and accumulated in this review regarding their possible relevance to future psychiatric applications.ResultsA multitude of papers and applications of KGs in associated research fields that are yet to be utilized in psychiatric research was found and outlined in this review. We create a thorough recommendation for other computational researchers regarding use-cases of these KG applications in psychiatry.ConclusionThis review illustrates use-cases of KG-based research applications in biomedicine and beyond that may aid in elucidating the complex biology of psychiatric illness and open new routes for developing innovative interventions. We conclude that there is a wealth of opportunities for KG utilization in psychiatric research across a variety of application areas including biomarker discovery, patient stratification and personalized medicine approaches.	[Freidel, Sebastian; Schwarz, Emanuel] Heidelberg Univ, Hector Inst Artificial Intelligence Psychiat, Cent Inst Mental Hlth, Med Fac Mannheim, Mannheim, Germany; [Freidel, Sebastian; Schwarz, Emanuel] Heidelberg Univ, Cent Inst Mental Hlth, Med Fac Mannheim, Dept Psychiat & Psychotherapy, Mannheim, Germany	Ruprecht Karls University Heidelberg; Central Institute of Mental Health; Ruprecht Karls University Heidelberg; Central Institute of Mental Health	Schwarz, E (corresponding author), Heidelberg Univ, Hector Inst Artificial Intelligence Psychiat, Cent Inst Mental Hlth, Med Fac Mannheim, Mannheim, Germany.	emanuel.schwarz@zi-mannheim.de			German Federal Ministry of Education and Research; Hector II foundation [01EK2101B]; German Federal Ministry of Education and Research (BEST project)	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF)); Hector II foundation; German Federal Ministry of Education and Research (BEST project)	This work was supported by the Hector II foundation, and the German Federal Ministry of Education and Research (BEST project, grant 01EK2101B), and was endorsed by German Center for Mental Health (DZPG). Open Access funding enabled and organized by Projekt DEAL.	Agrawal G, 2024, Arxiv, DOI arXiv:2311.07914; Aisopos F, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05373-2; Akbik A., 2018, P 27 INT C COMP LING, P1638; Albraikan A., 2019, Harmony: A Digital Twin for Emotional WellBeing. Thesis, DOI [10.20381/ruor23480, DOI 10.20381/RUOR23480]; Aleksander SA, 2023, GENETICS, V224, DOI 10.1093/genetics/iyad031; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bang D, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-39301-y; Barkhuizen W, 2020, TRANSL PSYCHIAT, V10, DOI 10.1038/s41398-020-0765-2; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Callahan TJ, 2020, ANNU REV BIOMED DA S, V3, P23, DOI 10.1146/annurev-biodatasci-010820-091627; Chai X., 2020, IEEE Access, V8; Chandak P, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-01960-3; Chang S., 2020, Transl Psychiatry, V10, P1, DOI DOI 10.1038/S41398020008729; Chaohui Guo, 2021, ISAIMS 2021: Proceedings of the 2nd International Symposium on Artificial Intelligence for Medicine Sciences, P472, DOI 10.1145/3500931.3501011; Chen HH, 2019, COMM COM INF SC, V1134, P111, DOI 10.1007/978-981-15-1956-7_10; Chen Jun, 2021, Bioinformatics, V37, P853, DOI 10.1093/bioinformatics/btaa879; Chengcheng Fu, 2021, ISAIMS 2021: Proceedings of the 2nd International Symposium on Artificial Intelligence for Medicine Sciences, P63, DOI 10.1145/3500931.3500944; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Dang LD, 2023, J BIOMED INFORM, V145, DOI 10.1016/j.jbi.2023.104460; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dogan T, 2021, NUCLEIC ACIDS RES, V49, DOI 10.1093/nar/gkab543; Du LM, 2022, LECT NOTES ARTIF INT, V13369, P337, DOI 10.1007/978-3-031-10986-7_27; Eftimie R, 2023, ADV APPL MECH, V56, P323, DOI 10.1016/bs.aams.2022.09.001; Fei H, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa110; Feng F, 2023, NUCLEIC ACIDS RES, V51, pD950, DOI 10.1093/nar/gkac957; Ferdousi R., 2021, P 2021 IEEE GLOB WOR, DOI [10.1109/GCWkshps52748.2021.9681996, DOI 10.1109/GCWKSHPS52748.2021.9681996]; Frisoni G., 2021, Research and Innovation Forum 2020, P577, DOI [10.1007/978303062066044, DOI 10.1007/978303062066044]; Gao JY, 2019, Arxiv, DOI arXiv:1907.09657; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Guan X., 2024, Proc AAAI Conf Artif Intell, V38, P18126, DOI [10.1609/aaai.v38i16.29770, DOI 10.1609/AAAI.V38I16.29770]; Harnoune A., 2021, Computer Methods and Programs in Biomedicine Update, V1, DOI DOI 10.1016/J.CMPBUP.2021.100042; He Beijia, 2023, Health Information Science: 12th International Conference, HIS 2023, Proceedings. Lecture Notes in Computer Science (14305), P50, DOI 10.1007/978-981-99-7108-4_5; He S., 2015, P 24 ACM INT C INF K, P623, DOI [10.1145/2806416.2806502, DOI 10.1145/2806416.2806502]; Hernandez LM, 2021, BIOL PSYCHIAT, V89, P54, DOI 10.1016/j.biopsych.2020.06.005; Hu J., 2021, Proceedings of the 2nd International Symposium on Artificial Intelligence for Medicine Sciences, ISAIMS'21, P126, DOI [10.1145/3500931.3500954, DOI 10.1145/3500931.3500954]; Huang Z., 2017, Constructing Knowledge Graphs of Depression, P149, DOI [10.1007/978331969182416, DOI 10.1007/978331969182416]; Jackson R, 2021, DATABASE-OXFORD, DOI 10.1093/database/baab069; Jia T, 2022, DATA INTELLIGENCE, V4, P134, DOI 10.1162/dint_a_00117; Kim R, 2022, COMM COM INF SC, V1512, P411, DOI 10.1007/978-3-030-96498-6_24; Kojaku S, 2021, Arxiv, DOI [arXiv:2110.07654, 10.48550/arXiv.2110.07654, DOI 10.48550/ARXIV.2110.07654]; Lample G, 2016, Arxiv, DOI arXiv:1603.01360; Lee PH, 2021, BIOL PSYCHIAT, V89, P20, DOI 10.1016/j.biopsych.2020.09.026; Li MM, 2022, NAT BIOMED ENG, V6, P1353, DOI 10.1038/s41551-022-00942-x; Li XZ, 2024, Arxiv, DOI arXiv:2310.05634; Li ZF, 2022, IEEE T NEUR NET LEAR, V33, P3961, DOI 10.1109/TNNLS.2021.3055147; Liang Z., 2021, BERTbased semantic query graph extraction for knowledge graph Question answering. Accessed January 22; Lietaert P, 2021, IFIP ADV INF COMM TE, V630, P249, DOI 10.1007/978-3-030-85874-2_26; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Liu T, 2021, HEALTH INF SCI SYST, V9, DOI 10.1007/s13755-020-00128-2; Ma TF, 2023, Arxiv, DOI [arXiv:2312.06682, 10.48550/arXiv.2312.06682, DOI 10.48550/ARXIV.2312.06682]; Ma TF, 2023, IEEE T KNOWL DATA EN, V35, P7068, DOI 10.1109/TKDE.2022.3188154; Ma XZ, 2016, Arxiv, DOI [arXiv:1603.01354, DOI 10.48550/ARXIV.1603.01354]; Maj M, 2005, BRIT J PSYCHIAT, V186, P182, DOI 10.1192/bjp.186.3.182; Meyer LP, 2023, Arxiv, DOI arXiv:2307.06917; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Milosevic N, 2023, J WEB SEMANT, V75, DOI 10.1016/j.websem.2022.100756; Mohamed SK, 2020, BIOINFORMATICS, V36, P603, DOI 10.1093/bioinformatics/btz600; Page Lawrence, 1999, PAGERANK CITATION RA; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Papadakis E, 2023, HEALTH INF SCI SYST, V11, DOI 10.1007/s13755-023-00253-8; Park N, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P503, DOI 10.1145/3394486.3403093; Park N, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P596, DOI 10.1145/3292500.3330855; Paulheim H., 2023, Embedding Knowledge Graphs with RDF2vec, DOI [10.1007/9783031303876, DOI 10.1007/9783031303876]; Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732; Pesapane F, 2022, J CLIN MED, V11, DOI 10.3390/jcm11216553; Do P, 2022, APPL INTELL, V52, P636, DOI 10.1007/s10489-021-02460-w; Pouya Pezeshkpour YT., 2020, Revisiting evaluation of knowledge base completion models, DOI [10.24432/C53S3W, DOI 10.24432/C53S3W]; Prabhakar V, 2023, bioRxiv, DOI [10.1101/2023.03.19.533306, 10.1101/2023.03.19.533306, DOI 10.1101/2023.03.19.533306]; Pramanik S, 2023, Arxiv, DOI arXiv:2108.08614; Khan MR, 2020, Arxiv, DOI arXiv:2001.08904; Rossanez A, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01341-5; Sahlab Nada, 2021, 2021 4th IEEE International Conference on Industrial Cyber-Physical Systems (ICPS), P19, DOI 10.1109/ICPS49255.2021.9468219; Sakor A, 2023, J WEB SEMANT, V75, DOI 10.1016/j.websem.2022.100760; Sanjak J, 2023, J AM MED INFORM ASSN, V31, P154, DOI 10.1093/jamia/ocad186; Shomer Harry, 2023, Proceedings of the ACM Web Conference, WWW'23, P705, DOI DOI 10.1145/3543507.3583544; Shu D, 2024, Arxiv, DOI arXiv:2403.07311; Smaili FZ, 2019, BIOINFORMATICS, V35, P2133, DOI 10.1093/bioinformatics/bty933; Sousa D, 2022, IEEE J BIOMED HEALTH, V26, P4207, DOI 10.1109/JBHI.2022.3173558; Spitzer M, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1082598; Sun HR, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad340; Suri K, 2023, Language models sounds the death knell of knowledge graphs; Unni DR, 2022, CTS-CLIN TRANSL SCI, V15, P1848, DOI 10.1111/cts.13302; Vasantharajan C, 2022, ASIAPAC SIGN INFO PR, P1482, DOI 10.23919/APSIPAASC55919.2022.9980157; Wang LL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1298; Wang YQ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248552; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wood EC, 2022, BMC BIOINFORMATICS, V23, DOI 10.1186/s12859-022-04932-3; Wu Y., 2020, Transl Psychiatry, V10, P1, DOI [DOI 10.1038/S41398-020-00902-6, 10.1038/s41398020009026, DOI 10.1038/S41398020009026]; Yang Z., 2023, Proceedings of the IEEE International Conference on Medical Artificial Intelligence (MedAI), P133, DOI [10.1109/MedAI59581.2023.00026, DOI 10.1109/MEDAI59581.2023.00026]; Yanhong Zhu, 2021, 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), P362, DOI 10.1109/DTPI52967.2021.9540177; Zhang R, 2021, J BIOMED INFORM, V115, DOI 10.1016/j.jbi.2021.103696; Zhao S., 2020, Published Online December, V2; Zheng Y., 2023, Proceedings of the IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P1764, DOI [10.1109/BIBM58861.2023.10385478, DOI 10.1109/BIBM58861.2023.10385478]; Zhu Q, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.932665	96	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0001-690X	1600-0447		ACTA PSYCHIAT SCAND	Acta Psychiatr. Scand.	2024 JUN 17	2024										10.1111/acps.13717	http://dx.doi.org/10.1111/acps.13717		JUN 2024	12	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	UP3I5	38886846				2024-07-03	WOS:001249217200001
J	Sarkhel, R; Huang, BX; Lockard, C; Shiralkar, P				Sarkhel, Ritesh; Huang, Binxuan; Lockard, Cohn; Shiralkar, Prashant			Self-Training for Label-Efficient Information Extraction from Semi-Structured Web-Pages	PROCEEDINGS OF THE VLDB ENDOWMENT			English	Article; Proceedings Paper	49th International Conference on Very Large Data Bases (VLDB)	AUG 28-SEP 01, 2023	Vancouver, CANADA					Information Extraction (IE) from semi-structured web-pages is a long studied problem. Training a model for this extraction task requires a large number of human-labeled samples. Prior works have proposed transferable models to improve the label-efficiency of this training process. Extraction performance of transferable models however, depends on the size of their fine-tuning corpus. This holds true for large language models (LLM) such as GPT-3 as well. Generalist models like LLMs need to be fine-tuned on in-domain, human-labeled samples for competitive performance on this extraction task. Constructing a large-scale fine-tuning corpus with human-labeled samples, however, requires significant effort. In this paper, we develop a Label-Efficient Self-Training Algorithm (LEAST) to improve the label-efficiency of this fine-tuning process. Our contributions are two-fold. First, we develop a generative model that facilitates the construction of a large-scale fine-tuning corpus with minimal human-effort. Second, to ensure that the extraction performance does not suffer due to noisy training samples in our fine-tuning corpus, we develop an uncertainty-aware training strategy. Experiments on two publicly available datasets show that LEAST generalizes to multiple verticals and backbone models. Using LEAST, we can train models with less than ten human-labeled pages from each website, outperforming strong baselines while reducing the number of human-labeled training samples needed for comparable performance by up to 11x.	[Sarkhel, Ritesh; Huang, Binxuan; Lockard, Cohn; Shiralkar, Prashant] Amazon, Seattle, WA 98109 USA	Amazon.com	Sarkhel, R (corresponding author), Amazon, Seattle, WA 98109 USA.	rssarkhe@amazon.com; binxuan@amazon.com; clockard@amazon.com; shiralp@amazon.com						Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998; Amini MR, 2024, Arxiv, DOI arXiv:2202.12040; AshishVaswani NoamShazeer, 2017, NeurIPS, V30; Azir MAB, 2017, INT CONF ELECT ENG; Bing LD, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2857054; Bronzi M, 2013, PROC VLDB ENDOW, V6, P805, DOI 10.14778/2536206.2536209; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chang CH, 2006, IEEE T KNOWL DATA EN, V18, P1411, DOI 10.1109/TKDE.2006.152; Chen Jingye, 2022, arXiv; Chen Xingyu, 2021, P 2021 C EMPIRICAL M, P4173, DOI DOI 10.18653/V1/2021.EMNLP-MAIN; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Cui WY, 2019, Arxiv, DOI [arXiv:1903.02419, 10.14778/3055540.3055549]; Deng Xiang, 2022, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong XL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P601, DOI 10.1145/2623330.2623623; Dunn A., 2022, arXiv; Eleuther AI, 2021, The GPT-Neo 1.3B model; Fagin R, 2015, J ACM, V62, DOI 10.1145/2699442; Frénay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894; Gentile AL, 2015, AI MAG, V36, P55, DOI 10.1609/aimag.v36i1.2567; Gulhane P, 2011, PROC INT CONF DATA, P1209, DOI 10.1109/ICDE.2011.5767842; Guo Y, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1502, DOI 10.1145/3477495.3532086; Hao Q, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P775; Hendrycks D, 2019, Arxiv, DOI arXiv:1802.05300; Jiang L., 2018, P 35 INT C MACH LEAR, P2309; Kreines D., 1999, Oracle Database Administration: The Essential Refe; Kushmerick N, 2000, ARTIF INTELL, V118, P15, DOI 10.1016/S0004-3702(99)00100-9; Li Junlong, 2021, arXiv; Li XZ, 2019, ADV NEUR IN, V32; Lin BY, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1092, DOI 10.1145/3394486.3403153; Lockard C, 2018, Arxiv, DOI arXiv:1804.04635; Lockard C, 2020, Arxiv, DOI arXiv:2005.07105; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010; Mukherjee Subhabrata, 2020, NeurIPS, V33; Navathe S.B., 2016, 21 INT C DASFAA 2016; Ormandi R., 2021, arXiv; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Ren M., 2018, P ICML, P4331; Ruder S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1044; Sarkhel R, 2024, Arxiv, DOI arXiv:2303.00720; Sarkhel R, 2020, Arxiv, DOI arXiv:2002.07845; Sarkhel R, 2021, PROC VLDB ENDOW, V14, P822, DOI 10.14778/3446095.3446104; Sarkhel R, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3360; Sarkhel R, 2019, INT CONF MANAGE DATA, P247, DOI 10.1145/3299869.3319867; SCUDDER HJ, 1965, IEEE T INFORM THEORY, V11, P363, DOI 10.1109/tit.1965.1053799; Sleiman HA, 2013, IEEE T KNOWL DATA EN, V25, P1960, DOI 10.1109/TKDE.2012.135; Tarvainen A, 2018, Arxiv, DOI arXiv:1703.01780; Wang HW, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2000, DOI 10.1145/3308558.3313411; Wang QF, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P47, DOI 10.1145/3394486.3403047; Wang YQ, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1737, DOI 10.1145/3447548.3467235; Wu S, 2018, INT CONF MANAGE DATA, P1301, DOI 10.1145/3183713.3183729; ZHAI Y., 2005, Proceedinqs of 11th International Conference on World Wide Web, P76, DOI DOI 10.1145/1060745.1060761; Zhou YC, 2021, Arxiv, DOI arXiv:2101.02415	54	0	0	5	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2150-8097			PROC VLDB ENDOW	Proc. VLDB Endow.	JUL	2023	16	11					3098	3110		10.14778/3611479.3611511	http://dx.doi.org/10.14778/3611479.3611511			13	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	Q7GX8					2024-07-03	WOS:001059181900033
C	Qing, ZF; Cai, ZG; Yang, ZT; Yang, L		Spencer, SN		Qing, Zhongfei; Cai, Zhongang; Yang, Zhitao; Yang, Lei			Story-to-Motion: Synthesizing Infinite and Controllable Character Animation from Long Text	PROCEEDINGS SIGGRAPH ASIA 2023 TECHNICAL COMMUNICATIONS, SA TECHNICAL COMMUNICATIONS 2023			English	Proceedings Paper	SIGGRAPH Asia Conference on Technical Communications (SA Technical Communications)	DEC 12-15, 2023	Sydney, AUSTRALIA	ACM SIGGRAPH		text-to-motion; motion matching; motion in-betweening		Generating natural human motion from a story has the potential to transform the landscape of animation, gaming, and film industries. A new and challenging task, Story-to-Motion, arises when characters are required to move to various locations and perform specific motions based on a long text description. This task demands a fusion of low-level control (trajectories) and high-level control (motion semantics). Previous works in character control and text-to-motion have addressed related aspects, yet a comprehensive solution remains elusive: character control methods do not handle text description, whereas text-to-motion methods lack position constraints and often produce unstable motions. In light of these limitations, we propose a novel system that generates controllable, infinitely long motions and trajectories aligned with the input text. 1) We leverage contemporary Large Language Models to act as a text-driven motion scheduler to extract a series of (text, position, duration) pairs from long text. 2) We develop a text-driven motion retrieval scheme that incorporates motion matching with motion semantic and trajectory constraints. 3) We design a progressive mask transformer that addresses common artifacts in the transition motion such as unnatural pose and foot sliding. Beyond its pioneering role as the first comprehensive solution for Story-to-Motion, our system undergoes evaluation across three distinct sub-tasks: trajectory following, temporal action composition, and motion blending, where it outperforms previous state-of-the-art (SOTA) motion synthesis methods across the board. Homepage: https://story2motion.github.io/	[Qing, Zhongfei; Yang, Zhitao; Yang, Lei] SenseTime Res, Hong Kong, Peoples R China; [Cai, Zhongang] SenseTime Res, Singapore, Singapore		Yang, L (corresponding author), SenseTime Res, Hong Kong, Peoples R China.	qingzhongfei@sensetime.com; caizhongang@sensetime.com; yangzhitao@sensetime.com; yanglei@sensetime.com		Cai, Zhongang/0000-0002-1810-3855; Yang, Zhitao/0000-0003-0780-0134				Athanasiou Nikos, 2022, arXiv; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Clavet Simon, 2016, PROC GAME DEVELOPERS; Duan YL, 2021, Arxiv, DOI arXiv:2103.00776; Holden D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392440; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mahmood N, 2019, IEEE I CONF COMP VIS, P5441, DOI 10.1109/ICCV.2019.00554; Qin J, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555454; Zhang MY, 2023, Arxiv, DOI arXiv:2304.01116; Zhang MY, 2022, Arxiv, DOI [arXiv:2208.15001, DOI 10.48550/ARXIV.2208.15001]; Zhang Y, 2022, PROC CVPR IEEE, P20449, DOI 10.1109/CVPR52688.2022.01983	11	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0314-0				2023									28	10.1145/3610543.3626176	http://dx.doi.org/10.1145/3610543.3626176			4	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SW		Green Submitted			2024-07-03	WOS:001124772900028
J	Schramowski, P; Turan, C; Andersen, N; Rothkopf, CA; Kersting, K				Schramowski, Patrick; Turan, Cigdem; Andersen, Nico; Rothkopf, Constantin A.; Kersting, Kristian			Large pre-trained language models contain human-like biases of what is right and wrong to do	NATURE MACHINE INTELLIGENCE			English	Article								Large language models identify patterns in the relations between words and capture their relations in an embedding space. Schramowski and colleagues show that a direction in this space can be identified that separates 'right' and 'wrong' actions as judged by human survey participants. Artificial writing is permeating our lives due to recent advances in large-scale, transformer-based language models (LMs) such as BERT, GPT-2 and GPT-3. Using them as pre-trained models and fine-tuning them for specific tasks, researchers have extended the state of the art for many natural language processing tasks and shown that they capture not only linguistic knowledge but also retain general knowledge implicitly present in the data. Unfortunately, LMs trained on unfiltered text corpora suffer from degenerated and biased behaviour. While this is well established, we show here that recent LMs also contain human-like biases of what is right and wrong to do, reflecting existing ethical and moral norms of society. We show that these norms can be captured geometrically by a 'moral direction' which can be computed, for example, by a PCA, in the embedding space. The computed 'moral direction' can rate the normativity (or non-normativity) of arbitrary phrases without explicitly training the LM for this task, reflecting social norms well. We demonstrate that computing the 'moral direction' can provide a path for attenuating or even preventing toxic degeneration in LMs, showcasing this capability on the RealToxicityPrompts testbed.	[Schramowski, Patrick; Turan, Cigdem; Kersting, Kristian] Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany; [Turan, Cigdem; Rothkopf, Constantin A.; Kersting, Kristian] Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany; [Andersen, Nico] Leibniz Inst Res & Informat Educ, Frankfurt, Germany; [Rothkopf, Constantin A.] Tech Univ Darmstadt, Inst Psychol, Darmstadt, Germany; [Rothkopf, Constantin A.; Kersting, Kristian] Hessian Ctr Artificial Intelligence Hessian Ai, Darmstadt, Germany	Technical University of Darmstadt; Technical University of Darmstadt; Technical University of Darmstadt	Schramowski, P; Turan, C (corresponding author), Tech Univ Darmstadt, Comp Sci Dept, Artificial Intelligence & Machine Learning Lab, Darmstadt, Germany.; Turan, C (corresponding author), Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.	schramowski@cs.tu-darmstadt.de; cigdem.turan@cs.tu-darmstadt.de		Turan-Schwiewager, Cigdem/0000-0002-4836-6023; Rothkopf, Constantin/0000-0002-5636-0801; Schramowski, Patrick/0000-0003-1231-7120	ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon 2020) [952215]; Hessian research priority programme LOEWE within the project WhiteBox; Hessian Ministry of Higher Education, Research and the Arts (HMWK)	ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon 2020); Hessian research priority programme LOEWE within the project WhiteBox; Hessian Ministry of Higher Education, Research and the Arts (HMWK)	The authors thank the anonymous reviewers for their valuable feedback. Further, the authors are thankful to Aleph Alpha for very useful feedback and access to the GPT-3 API. This work benefited from the ICT-48 Network of AI Research Excellence Center 'TAILOR' (EU Horizon 2020, grant agreement no. 952215) (K.K.), the Hessian research priority programme LOEWE within the project WhiteBox (K.K. and C.R.), and the Hessian Ministry of Higher Education, Research and the Arts (HMWK) cluster projects 'The Adaptive Mind' (K.K. and C.R.) and 'The Third Wave of AI' (K.K., C.R. and P.S.).	Abid A., 2021, PERSISTENT ANTIMUSLI, P298, DOI DOI 10.1145/3461702.3462624; Alexander L., 2021, STANFORD ENCY PHILOS; [Anonymous], 2020, NAT MACH INTELL, V2, P419, DOI 10.1038/s42256-020-0223-0; [Anonymous], GPT-3 powers the next generation of apps; [Anonymous], 2019, IEEE SPECTRUM; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berreby F, 2015, LECT NOTES COMPUT SC, V9450, P532, DOI 10.1007/978-3-662-48899-7_37; Bicchieri Cristina., 2018, STANFORD ENCY PHILOS; Bolukbasi T, 2016, ADV NEUR IN, V29; Bowman Samuel R., 2019, INT C LEARN REPR, P1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cer D.M., 2018, P EMNLP, DOI 10.18653/v1/D18- 2029; Chami I, 2021, PR MACH LEARN RES, V139; Chen B., 2021, 9 INT C LEARN REPR; Chen MX, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/3292500.3330723; Christakis NA, 2019, NATURE, V569, P627, DOI 10.1038/d41586-019-01658-w; Churchland P. S., 2019, Conscience: The Origins of Moral Intuition; Coenen Andy, 2019, Advances in Neural Information Processing Systems, V32, P8594; Conneau A., 2017, P 2017 C EMP METH NA, P670, DOI DOI 10.18653/V1/D17-1070; Dathathri Sumanth, 2020, Plug and play language models: A simple approach to controlled text generation; Devlin J., 2018, BERT PRE TRAINING DE; Fassin D., 2012, A Companion to Moral Anthropology, DOI DOI 10.1002/9781118290620.CH; Gehman S., 2020, FINDINGS ASS COMPUTA, P3356; Gert B., 2020, STANFORD ENCY PHILOS, VFall 2020; Goldberg Y, 2019, CoRR abs/1901.05287; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Hendrycks D., 2021, P INT C LEARN REPR; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Jentzsch S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P37, DOI 10.1145/3306618.3314267; Katzenstein, 1996, CULTURE NATL SECURIT, DOI DOI 10.1057/EJDR.2009.24; Keskar N. S., 2019, ABS190905858 CORR; Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166; Levine S, 2020, P NATL ACAD SCI USA, V117, P26158, DOI 10.1073/pnas.2014505117; Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241; Lindström B, 2018, J EXP PSYCHOL GEN, V147, P228, DOI 10.1037/xge0000365; Maxwell F, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P653; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Peng X., 2020, P 13 INT C NATURAL L, P374; Pereira Luis Moniz, 2009, International Journal of Reasoning-based Intelligent Systems, V1, P209, DOI 10.1504/IJRIS.2009.028020; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Ross AS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2662; Schramowski P, 2020, NAT MACH INTELL, V2, P476, DOI 10.1038/s42256-020-0212-3; Schramowski P, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00036; Shafer-Landau R, 2012, Ethical theory: an anthology, V13; Shwartz V, 2019, T ASSOC COMPUT LING, V7, P403, DOI 10.1162/tacl_a_00277/1923583; SUMNER LW, 1967, ETHICS, V77, P95, DOI 10.1086/291620; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Tan Yi Chern, 2019, P 33 ADV NEUR INF PR, P13209; Teso S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P239, DOI 10.1145/3306618.3314293; Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934; Yang ZL, 2019, ADV NEUR IN, V32; Zhang ZS, 2020, AAAI CONF ARTIF INTE, V34, P9628; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	58	54	56	15	45	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	MAR	2022	4	3					258	+		10.1038/s42256-022-00458-8	http://dx.doi.org/10.1038/s42256-022-00458-8			17	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	ZY2TX		Green Submitted			2024-07-03	WOS:000772442700005
J	Moskatel, LS; Zhang, NS				Moskatel, Leon S.; Zhang, Niushen			The utility of ChatGPT in the assessment of literature on the prevention of migraine: an observational, qualitative study	FRONTIERS IN NEUROLOGY			English	Article						artificial intelligence; ChatGPT; migraine; preventive medications; evidence-based medicine		Background: It is not known how large language models, such as ChatGPT, can be applied toward the assessment of the efficacy of medications, including in the prevention of migraine, and how it might support those claims with existing medical evidence.Methods: We queried ChatGPT-3.5 on the efficacy of 47 medications for the prevention of migraine and then asked it to give citations in support of its assessment. ChatGPT's evaluations were then compared to their FDA approval status for this indication as well as the American Academy of Neurology 2012 evidence-based guidelines for the prevention of migraine. The citations ChatGPT generated for these evaluations were then assessed to see if they were real papers and if they were relevant to the query.Results: ChatGPT affirmed that the 14 medications that have either received FDA approval for prevention of migraine or AAN Grade A/B evidence were effective for migraine. Its assessments of the other 33 medications were unreliable including suggesting possible efficacy for four medications that have never been used for the prevention of migraine. Critically, only 33/115 (29%) of the papers ChatGPT cited were real, while 76/115 (66%) were "hallucinated" not real papers and 6/115 (5%) shared the names of real papers but had not real citations.Conclusion: While ChatGPT produced tailored answers on the efficacy of the queried medications, the results were unreliable and inaccurate because of the overwhelming volume of "hallucinated" articles it generated and cited.	[Moskatel, Leon S.; Zhang, Niushen] Stanford Univ, Dept Neurol, Div Headache & Facial Pain, Palo Alto, CA 94304 USA	Stanford University	Moskatel, LS (corresponding author), Stanford Univ, Dept Neurol, Div Headache & Facial Pain, Palo Alto, CA 94304 USA.	moskatel@stanford.edu			Funding for the open access publication fee was provided by Stanford University's School of Medicine, Department of Neurology.; Stanford University's School of Medicine, Department of Neurology	Funding for the open access publication fee was provided by Stanford University's School of Medicine, Department of Neurology.; Stanford University's School of Medicine, Department of Neurology	Funding for the open access publication fee was provided by Stanford University's School of Medicine, Department of Neurology.	[Anonymous], 2023, INTR CHATGPT; Armstrong C, 2013, AM FAM PHYSICIAN, V87, P584; Chiang CC, 2022, HEADACHE, V62, P939, DOI 10.1111/head.14339; Cowan RP, 2022, HEADACHE, V62, P870, DOI 10.1111/head.14324; DiMeglio LA, 2020, DIABETES CARE, V43, P2631, DOI 10.2337/dci20-0044; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Ha H, 2019, AM FAM PHYSICIAN, V99, P17; Lipton RB, 2019, NEUROLOGY, V92, pE2250, DOI 10.1212/WNL.0000000000007452; Moran C., 2023, GUARDIAN GUARDIAN NE; Silberstein SD, 2012, NEUROLOGY, V78, P1337, DOI 10.1212/WNL.0b013e3182535d20	10	4	4	3	10	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	1664-2295			FRONT NEUROL	Front. Neurol.	AUG 17	2023	14								1225223	10.3389/fneur.2023.1225223	http://dx.doi.org/10.3389/fneur.2023.1225223			7	Clinical Neurology; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	Q6XI7	37662036	gold, Green Published			2024-07-03	WOS:001058930700001
C	Augustyniak, L; Tagowski, K; Sawczyn, A; Janiak, D; Bartusiak, R; Szymczak, A; Watroba, M; Janz, A; Szymanski, P; Morzy, M; Kajdanowicz, T; Piasecki, M		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Augustyniak, Lukasz; Tagowski, Kamil; Sawczyn, Albert; Janiak, Denis; Bartusiak, Roman; Szymczak, Adrian; Watroba, Marcin; Janz, Arkadiusz; Szymanski, Piotr; Morzy, Mikolaj; Kajdanowicz, Tomasz; Piasecki, Maciej			This is the way: designing and compiling LEPISZCZE, a comprehensive NLP benchmark for Polish	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					The availability of compute and data to train larger and larger language models increases the demand for robust methods of benchmarking the true progress of LM training. Recent years witnessed significant progress in standardized benchmarking for English. Benchmarks such as GLUE, SuperGLUE, or KILT have become a de facto standard tools to compare large language models. Following the trend to replicate GLUE for other languages, the KLEJ benchmark1 has been released for Polish. In this paper, we evaluate the progress in benchmarking for low-resourced languages. We note that only a handful of languages have such comprehensive benchmarks. We also note the gap in the number of tasks being evaluated by benchmarks for resource-rich English/Chinese and the rest of the world. In this paper, we introduce LEPISZCZE(2), a new, comprehensive benchmark for Polish NLP with a large variety of tasks and high-quality operationalization of the benchmark. We design LEPISZCZE with flexibility in mind. Including new models, datasets, and tasks is as simple as possible while still offering data versioning and model tracking. In the first run of the benchmark, we test 13 experiments (task and dataset pairs) based on the five most recent LMs for Polish. We use five datasets from the Polish benchmark and add eight novel datasets. As the paper's main contribution, apart from LEPISZCZE, we provide insights and experiences learned while creating the benchmark for Polish as the blueprint to design similar benchmarks for other low-resourced languages.	[Augustyniak, Lukasz; Tagowski, Kamil; Sawczyn, Albert; Janiak, Denis; Bartusiak, Roman; Szymczak, Adrian; Watroba, Marcin; Janz, Arkadiusz; Szymanski, Piotr; Kajdanowicz, Tomasz; Piasecki, Maciej] WUST, Wroclaw, Poland; [Morzy, Mikolaj] Poznan Univ Tech, Poznan, Poland	Poznan University of Technology	Augustyniak, L (corresponding author), WUST, Wroclaw, Poland.				Polish Ministry of Education and Science, CLARIN-PL; European Regional Development Fund; Department of Artificial Intelligence at Wroclaw University of Science and Technology; project CLARIN-Q [2022/WK/09]	Polish Ministry of Education and Science, CLARIN-PL; European Regional Development Fund(European Union (EU)); Department of Artificial Intelligence at Wroclaw University of Science and Technology; project CLARIN-Q	The work was partially supported by (1) the Polish Ministry of Education and Science, CLARIN-PL; (2) the European Regional Development Fund as a part of the 2014-2020 Smart Growth Operational Programme, CLARIN -Common Language Resources and Technology Infrastructure, (3) project CLARIN-Q (agreement no. 2022/WK/09), and (4) the Department of Artificial Intelligence at Wroclaw University of Science and Technology.	Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Augustyniak Lukasz, 2020, P 4 WID NAT LANG PRO, P110; Biewald L., 2020, EXPT TRACKING WEIGHT; Broda B, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3218; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Ethayarajh K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4846; Fennig Charles, 2022, ETHNOLOGUE LANGUAGES, Vtwenty-fifth; Gorman K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2786, DOI 10.18653/v1/p19-1267; Hoffmann J., 2022, Training compute-optimal large language models; Kleczek Dariusz, 2020, Proceedings of the PolEval 2020 Workshop; Kocon J, 2021, INT CONF DAT MIN WOR, P166, DOI 10.1109/ICDMW53433.2021.00027; Kocon Jan, 2019, P 23 C COMPUTATIONAL, P980, DOI DOI 10.18653/V1/K19-1092; Kuprieiev Ruslan., 2022, DVC: Data Version Control-Git for Data & Models; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Li XY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P465, DOI 10.1007/978-981-15-3863-6_51; Mroczkowski R., 2021, P 8 WORKSH BALT SLAV, P1; Ogrodniczuk M, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3712; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Pezik Piotr, 2022, LANG RES EV C 2022; Pineau J, 2021, J MACH LEARN RES, V22; Przepiorkowski A., 2012, NARODOWY KORPUS JEZY; Rae J.W., 2021, Scaling language models: Methods, analysis insights from training gopher; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rybak P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1191; Wang A, 2019, ADV NEUR IN, V32; Wang Q, 2020, J BIOMED INFORM, V105, DOI 10.1016/j.jbi.2020.103418; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wróblewska A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P784, DOI 10.18653/v1/P17-1073; Yang ZL, 2019, ADV NEUR IN, V32; Ye DM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4904; Zhang BY, 2022, PROCEEDINGS OF THE THIRD WORKSHOP ON INSIGHTS FROM NEGATIVE RESULTS IN NLP (INSIGHTS 2022), P129	31	0	0	1	1	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259108067
J	Winter, B; Fischer, MH; Scheepers, C; Myachykov, A				Winter, Bodo; Fischer, Martin H.; Scheepers, Christoph; Myachykov, Andriy			More is Better: English Language Statistics are Biased Toward Addition	COGNITIVE SCIENCE			English	Article						Addition; Subtraction; Subtraction neglect; Latent semantic analysis; Word frequency; Heuristics and biases	R PACKAGE; VALENCE; AROUSAL; REPRESENTATION; ASSOCIATIONS; CONTEXT; WORDS; TASTE	We have evolved to become who we are, at least in part, due to our general drive to create new things and ideas. When seeking to improve our creations, ideas, or situations, we systematically overlook opportunities to perform subtractive changes. For example, when tasked with giving feedback on an academic paper, reviewers will tend to suggest additional explanations and analyses rather than delete existing ones. Here, we show that this addition bias is systematically reflected in English language statistics along several distinct dimensions. First, we show that words associated with an increase in quantity or number (e.g., add, addition, more, most) are more frequent than words associated with a decrease in quantity or number (e.g., subtract, subtraction, less, least). Second, we show that in binomial expressions, addition-related words are mentioned first, that is, add and subtract rather than subtract and add. Third, we show that the distributional semantics of verbs of change, such as to improve and to transform, overlap more with the distributional semantics of add/increase than subtract/decrease, which suggests that change verbs are implicitly biased toward addition. Fourth, addition-related words have more positive connotations than subtraction-related words. Fifth, we demonstrate that state-of-the-art large language models, such as the Generative Pre-trained Transformer (GPT-3), are also biased toward addition. We discuss the implications of our results for research on cognitive biases and decision-making.	[Winter, Bodo] Univ Birmingham, Dept English Language & Linguist, Birmingham, England; [Fischer, Martin H.] Univ Potsdam, Div Cognit Sci, Potsdam, Germany; [Scheepers, Christoph] Univ Glasgow, Sch Neurosci & Psychol, Glasgow, Scotland; [Myachykov, Andriy] Northumbria Univ, Dept Psychol, London, England; [Myachykov, Andriy] Higher Sch Econ, Inst Cognit Neurosci, Moscow, Russia; [Winter, Bodo] Univ Birmingham, Dept English Language & Linguist, Frankland Bldg, Edgbaston B15 2TT, England	University of Birmingham; University of Potsdam; University of Glasgow; Northumbria University; HSE University (National Research University Higher School of Economics); University of Birmingham	Winter, B (corresponding author), Univ Birmingham, Dept English Language & Linguist, Frankland Bldg, Edgbaston B15 2TT, England.	bodo@bodowinter.com	Winter, Bodo/K-6975-2018	Winter, Bodo/0000-0001-6036-6774	UKRI Future Leaders Fellowship [MR/T040505/1]; Basic Research Program at the National Research University Higher School of Economics [DFG-FI-1915/8-1]	UKRI Future Leaders Fellowship(UK Research & Innovation (UKRI)); Basic Research Program at the National Research University Higher School of Economics	Bodo Winter was supported by the UKRI Future Leaders Fellowship MR/T040505/1. Andriy Myachykov was supported by the Basic Research Program at the National Research University Higher School of Economics. Martin Fischer was supported by grant DFG-FI-1915/8-1 "Competing heuristics and biases in mental arithmetic."	Abdou M, 2021, Arxiv, DOI [arXiv:2109.06129, 10.48550/arXiv.2109.06129]; Adams GS, 2021, NATURE, V592, P258, DOI 10.1038/s41586-021-03380-y; Augustine AA, 2011, SOC PSYCHOL PERS SCI, V2, P508, DOI 10.1177/1948550611399154; Balota DA, 2007, BEHAV RES METHODS, V39, P445, DOI 10.3758/BF03193014; Baroni M, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P238; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Battistella E., 1996, The logic of markedness; Beekhuizen B, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12943; Benor SB, 2006, LANGUAGE, V82, P233, DOI 10.1353/lan.2006.0077; Blasi DE, 2022, TRENDS COGN SCI, V26, P1153, DOI 10.1016/j.tics.2022.09.015; BOUCHER J, 1969, J VERB LEARN VERB BE, V8, P1, DOI 10.1016/S0022-5371(69)80002-2; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bürkner PC, 2018, R J, V10, P395; Bürkner PC, 2017, J STAT SOFTW, V80, P1, DOI 10.18637/jss.v080.i01; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Davies M, 2010, LIT LINGUIST COMPUT, V25, P447, DOI 10.1093/llc/fqq018; De Houwer J, 2004, COGNITION EMOTION, V18, P251, DOI 10.1080/02699930341000022; FAZIO RH, 1986, J PERS SOC PSYCHOL, V50, P229, DOI 10.1037/0022-3514.50.2.229; Firth J. R., 1957, PAPERS LINGUISTICS 1; Fischer MH, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.720616; Fischer MH, 2014, Q J EXP PSYCHOL, V67, P1461, DOI 10.1080/17470218.2014.927515; Günther F, 2019, PERSPECT PSYCHOL SCI, V14, P1006, DOI 10.1177/1745691619861372; Heylen K, 2015, LINGUA, V157, P153, DOI 10.1016/j.lingua.2014.12.001; Hilpert M, 2020, CORPUS LINGUIST LING, V16, P393, DOI 10.1515/cllt-2017-0009; Hunston S., 2007, INT J CORPUS LINGUIS, V12, P249, DOI DOI 10.1075/IJCL.12.2.09HUN; Jentzsch S., 2019, P 2019 AAAI ACM C AI; Jonauskaite D, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251559; Jonauskaite D, 2019, SEX ROLES, V80, P630, DOI 10.1007/s11199-018-0955-z; Kahneman D., 2011, THINKING FAST SLOW; Kay M., 2018, tidybayes: Tidy data and geoms for Bayesian models, DOI DOI 10.5281/ZENODO.1308151; Klotz Leidy, 2021, Subtract: The Untapped Science of Less; Kloumann IM, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0029484; Kuperman V, 2014, J EXP PSYCHOL GEN, V143, P1065, DOI 10.1037/a0035669; Ladle RJ, 2019, PEOPLE NAT, V1, P524, DOI 10.1002/pan3.10053; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lemoine NP, 2019, OIKOS, V128, P912, DOI 10.1111/oik.05985; Lenci A, 2008, ITAL J LINGUIST, V20, P1; Lewis M, 2020, NAT HUM BEHAV, V4, P1021, DOI 10.1038/s41562-020-0918-6; Louwerse M, 2011, COGNITIVE SCI, V35, P381, DOI 10.1111/j.1551-6709.2010.01157.x; Louwerse MM, 2008, PSYCHON B REV, V15, P838, DOI 10.3758/PBR.15.4.838; Louwerse MM, 2018, TOP COGN SCI, V10, P573, DOI 10.1111/tops.12349; Louwerse MM, 2011, TOP COGN SCI, V3, P273, DOI 10.1111/j.1756-8765.2010.01106.x; Lund K, 1996, BEHAV RES METH INSTR, V28, P203, DOI 10.3758/BF03204766; Lyons J., 1977, SEMANTICS; McElreath R, 2016, TEXT STAT SCI, pXI; Meier BP, 2008, BASIC APPL SOC PSYCH, V30, P46, DOI 10.1080/01973530701866516; Michel JB, 2011, SCIENCE, V331, P176, DOI 10.1126/science.1199644; Mikolov T, 2017, Arxiv, DOI arXiv:1712.09405; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Morley J, 2009, INT J CORPUS LINGUIS, V14, P139, DOI 10.1075/ijcl.14.2.01mor; Nuerk HC, 2004, Q J EXP PSYCHOL-A, V57, P835, DOI 10.1080/02724980343000512; Pedersen Thomas Lin, 2024, CRAN; Pereira F, 2016, COGN NEUROPSYCHOL, V33, P175, DOI 10.1080/02643294.2016.1176907; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Proctor RW, 2006, PSYCHOL BULL, V132, P416, DOI 10.1037/0033-2909.132.3.416; Regier T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151138; Sinclair J. M., 1991, Corpus, concordance, collocation; Snefjella B, 2016, COGNITION, V156, P135, DOI 10.1016/j.cognition.2016.07.010; Stewart D., 2010, SEMANTIC PROSODY CRI; Stubbs M., 2001, WORDS PHRASES CORPUS; Torchiano Marco, 2016, Zenodo; Vigliocco G, 2009, LANG COGN, V1, P219, DOI 10.1515/LANGCOG.2009.011; Warriner AB, 2015, COGNITION EMOTION, V29, P1147, DOI 10.1080/02699931.2014.968098; Warriner AB, 2013, BEHAV RES METHODS, V45, P1191, DOI 10.3758/s13428-012-0314-x; Whitsitt Sam., 2005, INT J CORPUS LINGUIS, V10, P283, DOI [10.1075/ijcl.10.3.01whi, DOI 10.1075/IJCL.10.3.01WHI]; Wickham H., 2019, JOSS, V4, P1686, DOI [DOI 10.21105/JOSS.01686, 10.21105/joss.01686]; Wierzbicka Anna., 2014, IMPRISONED ENGLISH H; Wild Fridolin, 2022, CRAN; Winter B, 2019, CONV EVI LANG COMMUN, V20, P1, DOI 10.1075/celcr.20; Winter B, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12439; Winter B, 2021, LINGUISTICS, V59, P1251, DOI 10.1515/ling-2019-0049; Winter B, 2018, COGNITION, V179, P213, DOI 10.1016/j.cognition.2018.05.008; Winter B, 2016, LANG COGN NEUROSCI, V31, P975, DOI 10.1080/23273798.2016.1193619; Winter B, 2015, NEUROSCI BIOBEHAV R, V57, P209, DOI 10.1016/j.neubiorev.2015.09.005; Yakov MALKIEL., 1959, LINGUA, V8, P113, DOI [10.1016/0024-3841(59)90018-X, DOI 10.1016/0024-3841(59)90018-X]; ZAJONC RB, 1968, J PERS SOC PSYCHOL, V9, P1, DOI 10.1037/h0025848; Zuur Alain F., 2009, P1; Zwaan RA, 2003, PSYCHON B REV, V10, P954, DOI 10.3758/BF03196557	78	3	3	5	15	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	APR	2023	47	4							e13254	10.1111/cogs.13254	http://dx.doi.org/10.1111/cogs.13254			25	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	C6PH2	37017257	hybrid, Green Accepted			2024-07-03	WOS:000963108300001
C	Ristoski, P; Lin, ZZ; Zhou, QZ			ACM	Ristoski, Petar; Lin, Zhizhong; Zhou, Qunzhi			KG-ZESHEL: Knowledge Graph-Enhanced Zero-Shot Entity Linking	PROCEEDINGS OF THE 11TH KNOWLEDGE CAPTURE CONFERENCE (K-CAP '21)			English	Proceedings Paper	11th Knowledge Capture Conference (K-CAP)	DEC 02-03, 2021	ELECTR NETWORK	Assoc Comp Machinery, ACM SIGAI, Univ Politecnica Madrid, Artificial Intelligence Journal		Entity Linking; Knowledge Graph; Zero-Shot Learning	SCALE	Entity linking is a fundamental task for a successful use of knowledge graphs in many information systems. It maps textual mentions to their corresponding entities in a given knowledge graph. However, with the rapid evolution of knowledge graphs, a large number of entities is continuously added over time. Performing entity linking on new, or unseen, entities poses a great challenge, as standard entity linking approaches require large amounts of labeled data for all new entities, and the underlying model must be regularly updated. To address this challenge, several zero-shot entity linking approaches have been proposed, which don't require additional labeled data to perform entity linking over unseen entities and new domains. Most of these approaches use large language models, such as BERT, to encode the textual description of the mentions and entities in a common embedding space, which allows linking mentions to unseen entities. While such approaches have shown good performance, one big drawback is that they are not able to exploit the entity symbolic information from the knowledge graph, such as entity types, relations, popularity scores and graph embeddings. In this paper, we present KG-ZESHEL, a knowledge graph-enhanced zero-shot entity linking approach, which extends an existing BERT-based zero-shot entity linking approach with mention and entity auxiliary information. Experiments on two benchmark entity linking datasets, show that our proposed approach outperforms the related BERT-based state-of-the-art entity linking models.	[Ristoski, Petar; Zhou, Qunzhi] eBay Inc, San Jose, CA 95125 USA; [Lin, Zhizhong] Univ Georgia, Athens, GA 30602 USA; [Lin, Zhizhong] eBay, San Jose, CA USA	eBay Inc.; University System of Georgia; University of Georgia; eBay Inc.	Ristoski, P (corresponding author), eBay Inc, San Jose, CA 95125 USA.	pristoski@ebay.com; zhizhong.lin@uga.edu; qunzhou@ebay.com						Broscheit S, 2020, Arxiv, DOI arXiv:2003.05473; Bunescu R., 2006, Using encyclopedic knowledge for named entity disambiguation; Demsar J, 2006, J MACH LEARN RES, V7, P1; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Faldu K, 2021, Arxiv, DOI [arXiv:2104.08145, DOI 10.48550/ARXIV.2104.08145]; Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002; Ganea O, 2017, P 2017 C EMP METH NA, P2619, DOI [10.18653/v1/D17-1277, DOI 10.18653/V1/D17-1277]; Gillick D, 2019, Arxiv, DOI arXiv:1909.10506; Gupta N, 2017, P 2017 C EMP METH NA, P2681, DOI [DOI 10.18653/V1/D17-1284, 10.18653/v1/D17-1284]; He Z, 2013, ACL, V2, P30; Hogan A, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447772; Humeau S., 2019, Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring, DOI DOI 10.48550/ARXIV.1905.01969; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Kolitsas N, 2018, Arxiv, DOI arXiv:1808.07699; Larochelle H., 2008, Proceedings of the national conference on artificial intelligence, V1, P3; Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134; Ling Xiao, 2012, 26 AAAI C ART INT; Logeswaran L, 2019, Arxiv, DOI [arXiv:1906.07348, DOI 10.48550/ARXIV.1906.07348]; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Moreno JG, 2017, LECT NOTES COMPUT SC, V10249, P337, DOI 10.1007/978-3-319-58068-5_21; Nedelchev R, 2020, Arxiv, DOI arXiv:2002.11143; Noy N, 2019, COMMUN ACM, V62, P36, DOI 10.1145/3331166; Onoe Y, 2019, Arxiv, DOI [arXiv:1905.01566, 10.48550/arXiv.1905.01566]; Onoe Y, 2020, AAAI CONF ARTIF INTE, V34, P8576; Page Lawrence, 1999, PAGERANK CITATION RA; Partalidou E, 2021, Arxiv, DOI arXiv:2103.04156; Pittman R. J., 2017, COMMERCE; Ravi MPK, 2021, Arxiv, DOI arXiv:2101.09969; Raiman J, 2018, AAAI CONF ARTIF INTE, P5406; Ristoski Petar., 2014, Linked Data for Knowledge Discovery; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Rochat Y., 2009, Closeness centrality extended to unconnected graphs: The harmonic centrality index; Roth D., 2014, P 52 ANN M ASS COMPU, P7; Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]; Sevgili O, 2022, Arxiv, DOI arXiv:2006.00575; Sil A., 2018, P 56 ANN M ASS COMPU, DOI 10.18653/v1/P18- 5008; Sil A., 2012, P 2012 JOINT C EMP M, P116; Singhal Amit, 2012, Official Google Blog, V16; Sun Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1333; Vincent P., 2008, P 25 INT C MACH LEAR, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]; Vishwanathan SVN, 2010, J MACH LEARN RES, V11, P1201; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang H., 2015, Proc. 2015 Conf. Empir. Methods Nat. Lang. Process, P695; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6397; Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P23; Yamada Ikuya, 2016, SIGNLL C COMPUT NATU, P250, DOI 10.18653/v1/K16-1025	47	4	4	4	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-8457-5				2021							49	56		10.1145/3460210.3493549	http://dx.doi.org/10.1145/3460210.3493549			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU6OE					2024-07-03	WOS:000926615800007
J	Chakraborty, T; Reddy, KSU; Naik, SM; Panja, M; Manvitha, B				Chakraborty, Tanujit; Reddy, K. S. Ujjwal; Naik, Shraddha M.; Panja, Madhurima; Manvitha, Bayapureddy			Ten years of generative adversarial nets (GANs): a survey of the state-of-the-art	MACHINE LEARNING-SCIENCE AND TECHNOLOGY			English	Review						adversarial learning; image generation; deep learning; model evaluation and selection; generative adversarial networks; artificial intelligence.	NEURAL-NETWORKS; IMAGE; MODELS	Generative adversarial networks (GANs) have rapidly emerged as powerful tools for generating realistic and diverse data across various domains, including computer vision and other applied areas, since their inception in 2014. Consisting of a discriminative network and a generative network engaged in a minimax game, GANs have revolutionized the field of generative modeling. In February 2018, GAN secured the leading spot on the 'Top Ten Global Breakthrough Technologies List' issued by the Massachusetts Science and Technology Review. Over the years, numerous advancements have been proposed, leading to a rich array of GAN variants, such as conditional GAN, Wasserstein GAN, cycle-consistent GAN, and StyleGAN, among many others. This survey aims to provide a general overview of GANs, summarizing the latent architecture, validation metrics, and application areas of the most widely recognized variants. We also delve into recent theoretical developments, exploring the profound connection between the adversarial principle underlying GAN and Jensen-Shannon divergence while discussing the optimality characteristics of the GAN framework. The efficiency of GAN variants and their model architectures will be evaluated along with training obstacles as well as training solutions. In addition, a detailed discussion will be provided, examining the integration of GANs with newly developed deep learning frameworks such as transformers, physics-informed neural networks, large language models, and diffusion models. Finally, we reveal several issues as well as future research outlines in this field.	[Chakraborty, Tanujit] Sorbonne Univ, Dept Sci & Engn, Abu Dhabi, U Arab Emirates; [Reddy, K. S. Ujjwal; Manvitha, Bayapureddy] VIT AP Univ, Sch Comp Sci & Engn, Amaravati, Andhra Pradesh, India; [Chakraborty, Tanujit] Sorbonne Univ, Sorbonne Ctr Artificial Intelligence, Paris, France; [Panja, Madhurima] Int Inst Informat Technol Bangalore, Ctr Data Sci, Bangalore, India; [Naik, Shraddha M.] Manipal Acad Higher Educ, Manipal Inst Technol Bengaluru, Manipal 576104, Karnataka, India	VIT-AP University; Sorbonne Universite; International Institute of Information Technology Bangalore (IIIT Bangalore); Manipal Academy of Higher Education (MAHE)	Chakraborty, T (corresponding author), Sorbonne Univ, Dept Sci & Engn, Abu Dhabi, U Arab Emirates.; Chakraborty, T (corresponding author), Sorbonne Univ, Sorbonne Ctr Artificial Intelligence, Paris, France.	tanujit.chakraborty@sorbonne.ae	Chakraborty, Tanujit/ABE-1484-2020	Panja, Madhurima/0009-0004-7467-2456	MCC Economics Finance	MCC Economics Finance	The authors would like to acknowledge the associate editor and learned reviewers of the journal for their valuable suggestions.	Gatys LA, 2015, Arxiv, DOI [arXiv:1508.06576, 10.1167/16.12.326]; Abouelnaga Y, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE & COMPUTATIONAL INTELLIGENCE (CSCI), P1192, DOI [10.1109/CSCI.2016.224, 10.1109/CSCI.2016.0225]; Afchar D, 2018, IEEE INT WORKS INFOR; Albert A, 2019, Arxiv, DOI arXiv:1907.09543; Albert A, 2018, INT GEOSCI REMOTE SE, P2095, DOI 10.1109/IGARSS.2018.8518032; Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292; Alvarez-Melis D., 2022, Advances in Neural Information Processing Systems, V35, P9072; Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650; Arjovsky M., 2017, arXiv; Arjovsky M, 2017, PR MACH LEARN RES, V70; Arora S, 2017, Arxiv, DOI [arXiv:1706.08224, 10.48550/arXiv.1706.08224]; BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181; Berthelot D, 2018, Arxiv, DOI arXiv:1807.07543; Biau G, 2021, J MACH LEARN RES, V22, P1; Biau G, 2020, ANN STAT, V48, P1539, DOI 10.1214/19-AOS1858; Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009; Bounliphone W, 2016, Arxiv, DOI arXiv:1511.04581; Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18; Brigham E. O., 1988, The Fast Fourier Transform and Its Applications; Brock A, 2019, Arxiv, DOI [arXiv:1809.11096, DOI 10.48550/ARXIV.1809.11096]; Brophy E, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3559540; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bullwinkel B, 2022, Arxiv, DOI arXiv:2209.07081; Buolamwini J., 2018, Conference on fairness, accountability and transparency, P77; Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814; Carin L., 2016, NIPS WORKSH ADV TRAI, V21, P1, DOI DOI 10.1016/J.SCITOTENV.2016.02.166; Chaitanya K, 2023, MED IMAGE ANAL, V87, DOI 10.1016/j.media.2023.102792; Chakraborty T, 2021, IEEE T RELIAB, V70, P481, DOI 10.1109/TR.2020.3020238; Chen X, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P29, DOI 10.1145/2984511.2984512; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Chu H, 2016, Arxiv, DOI arXiv:1611.03477; Civit M, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118190; Clark J., 2019, Better language models and their implications; Croitoru FA, 2023, IEEE T PATTERN ANAL, V45, P10850, DOI 10.1109/TPAMI.2023.3261988; Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665; Dai T, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108249; Dam T, 2022, IEEE IMAGE PROC, P3712, DOI 10.1109/ICIP46576.2022.9897874; Daras Giannis, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14519, DOI 10.1109/CVPR42600.2020.01454; Daw A, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P237, DOI 10.1145/3447548.3467449; De Meulemeester H, 2021, LECT NOTES ARTIF INT, V12976, P52, DOI 10.1007/978-3-030-86520-7_4; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Denton EL, 2015, Advances in neural information processing systems, P28; Dhariwal P, 2021, ADV NEUR IN, V34; Dong H, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1201, DOI 10.1145/3123266.3129391; Dong HW, 2018, AAAI CONF ARTIF INTE, P34; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Dumoulin V, 2017, Arxiv, DOI arXiv:1606.00704; Durgadevi M., 2021, 2021 6 INT C COMM EL, P1; Smith KE, 2020, Arxiv, DOI arXiv:2006.16477; Elabid Z., 2022, 2022 21 IEEE INT C M, ppp 1203; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; Esteban C, 2017, Arxiv, DOI [arXiv:1706.02633, DOI 10.48550/ARXIV.1706.02633]; Farnia Farzan, 2020, P MACHINE LEARNING R, P3029; Franceschelli G, 2024, Arxiv, DOI arXiv:2104.02726; Frid-Adar M, 2018, I S BIOMED IMAGING, P289, DOI 10.1109/ISBI.2018.8363576; Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265; Gawlikowski J, 2023, ARTIF INTELL REV, V56, P1513, DOI 10.1007/s10462-023-10562-9; Gecer B, 2018, LECT NOTES COMPUT SC, V11215, P230, DOI 10.1007/978-3-030-01252-6_14; Geiger A, 2020, IEEE INT CONF BIG DA, P33, DOI 10.1109/BigData50022.2020.9378139; Ghosh A, 2016, Arxiv, DOI arXiv:1611.08788; Gómez-de-Segura G, 2019, J FLUID MECH, V875, P124, DOI 10.1017/jfm.2019.482; Goodfellow I, 2017, Arxiv, DOI arXiv:1701.00160; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Graves A, 2014, Arxiv, DOI [arXiv:1410.5401, DOI 10.48550/ARXIV.1410.5401]; Gui J, 2023, IEEE T KNOWL DATA EN, V35, P3313, DOI 10.1109/TKDE.2021.3130191; Guo J., 2018, P AAAI C ART INT, P32; Gurumurthy S, 2017, PROC CVPR IEEE, P4941, DOI 10.1109/CVPR.2017.525; Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787; Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343; Hashemi SR, 2019, IEEE ACCESS, V7, P1721, DOI 10.1109/ACCESS.2018.2886371; Hausknecht M, 2015, 2015 AAAI FALL S SER; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; He WC, 2024, Arxiv, DOI arXiv:2302.13425; He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751; Hensel M, 2017, ADV NEUR IN, V30; Higgins I., 2017, ICLR, V2, P6; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131; Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167; Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069; Iglesias G, 2023, COMPUT SCI REV, V48, DOI 10.1016/j.cosrev.2023.100553; Ioffe S, 2015, PR MACH LEARN RES, V37, P448; Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9; Gulrajani I, 2017, ADV NEUR IN, V30; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572; Jabbar A, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3463475; Ji SL, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3597493; Jiang SH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3721; Jiang Y., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2102.07074; Jiang ZY, 2023, Arxiv, DOI arXiv:2306.03509; Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43; Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734; Jordon James, 2018, INT C LEARNING REPRE; Kadurin A, 2017, MOL PHARMACEUT, V14, P3098, DOI 10.1021/acs.molpharmaceut.7b00346; Kadurin A, 2017, ONCOTARGET, V8, P10883, DOI 10.18632/oncotarget.14073; Kalchbrenner Nal, 2017, ICML, P1771; Karniadakis G E., 2021, arXiv; Karras T., 2020, ADV NEURAL INFORM PR, V33, p12 104, DOI 10.48550/arXiv.2006.06676; Karras T, 2018, Arxiv, DOI arXiv:1710.10196; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kim SW, 2020, PROC CVPR IEEE, P1228, DOI 10.1109/CVPR42600.2020.00131; Korshunov P, 2019, INT CONF BIOMETR; Krizhevsky A., LEARNING MULTIPLE LA; Kulkarni R., 2019, International Journal of Engineering Research & Technology, V8, P646; Lai C, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455972; Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19; Lehmann E L., 1986, Testing Statistical Hypotheses, pp 3; Li K, 2019, IEEE I CONF COMP VIS, P4219, DOI 10.1109/ICCV.2019.00432; Li W, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107646; Li Y., 2021, IEEE Trans. on Knowledge and Data Engineering; Li YC, 2021, NEUROCOMPUTING, V435, P26, DOI 10.1016/j.neucom.2020.12.114; Li YF, 2023, KNOWL-BASED SYST, V271, DOI 10.1016/j.knosys.2023.110585; Li YJ, 2017, ADV NEUR IN, V30; Lin Z., 2021, INT C ARTIFICIAL INT, V130, P1522; Liu J, 2022, KNOWL INF SYST, V64, P885, DOI 10.1007/s10115-022-01664-x; Liu LL, 2019, NEUROCOMPUTING, V341, P156, DOI 10.1016/j.neucom.2019.03.011; Liu MY, 2021, P IEEE, V109, P839, DOI 10.1109/JPROC.2021.3049196; Liu S., 2017, Advances in Neural Information Processing Systems, P30; Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23; Liu Y, 2019, INT C PAR DISTRIB SY, P985, DOI 10.1109/ICPADS47876.2019.00150; Lucic M, 2018, ADV NEUR IN, V31; Luo B, 2018, AAAI CONF ARTIF INTE, P1652; Lv ZZ, 2022, INT J INTELL SYST, V37, P4417, DOI 10.1002/int.22724; Ma LQ, 2017, ADV NEUR IN, V30; Ma SQ, 2020, MED PHYS, V47, P5194, DOI 10.1002/mp.14443; Mahmud M, 2021, COGN COMPUT, V13, P1, DOI 10.1007/s12559-020-09773-x; Makhzani A, 2016, Arxiv, DOI arXiv:1511.05644; Mameli M, 2022, IEEE ACCESS, V10, P1545, DOI 10.1109/ACCESS.2021.3137893; Mao XF, 2018, NEUROCOMPUTING, V293, P55, DOI 10.1016/j.neucom.2018.02.092; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Marcus G., 2022, arXiv, DOI DOI 10.48550/ARXIV.2204.13807; Mariani G, 2018, Arxiv, DOI [arXiv:1803.09655, DOI 10.48550/ARXIV.1803.09655]; Mbacke SD, 2023, Arxiv, DOI [arXiv:2302.08942, DOI 10.48550/ARXIV.2302.08942.7]; Meitz M, 2023, Arxiv, DOI arXiv:2104.10601; Mescheder L., 2017, Advances in Neural Information Processing Systems, P30; Metz L, 2017, Arxiv, DOI arXiv:1611.02163; Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]; Miyato T, 2018, Arxiv, DOI [arXiv:1802.05957, 10.48550/arXiv.1802.05957]; Mohamed S, 2017, Arxiv, DOI arXiv:1610.03483; Mosser L, 2017, PHYS REV E, V96, DOI 10.1103/PhysRevE.96.043309; Mu Zhaoxi, 2021, arXiv; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Nair V., 2010, P ICML, P807; Abirami RN, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5541134; NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529; Nema S, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101641; Nguyen A, 2016, Arxiv, DOI arXiv:1602.03616; Nowozin S., 2016, Adv Neural Inf Process Syst, P29; Oberdiek P., 2022, Advances in Neural Information Processing Systems, V35, P21371; Odena A, 2017, PR MACH LEARN RES, V70; Pan XL, 2017, Arxiv, DOI arXiv:1704.03952; Pan ZQ, 2022, IEEE T MULTIMEDIA, V24, P519, DOI 10.1109/TMM.2021.3054509; Pandey N, 2020, NEUROCOMPUTING, V414, P356, DOI 10.1016/j.neucom.2020.07.092; Panja M, 2023, NEURAL NETWORKS, V165, P185, DOI 10.1016/j.neunet.2023.05.049; Percival D B., 2000, Wavelet Methods for Time Series Analysis, pp 4; Puchkin N, 2024, Arxiv, DOI arXiv:2102.00199; Bowman SR, 2016, Arxiv, DOI [arXiv:1511.06349, 10.48550/ARXIV.1511.06349, DOI 10.48550/ARXIV.1511.06349]; Radford A, 2016, Arxiv, DOI arXiv:1511.06434; Radford A, 2021, PR MACH LEARN RES, V139; Radford Alec, 2021, OpenAI Blog; Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Ratliff LJ, 2013, ANN ALLERTON CONF, P917, DOI 10.1109/Allerton.2013.6736623; Razavi A, 2019, ADV NEUR IN, V32; Recht B, 2019, PR MACH LEARN RES, V97; Reed S, 2016, PR MACH LEARN RES, V48; Ren WH, 2022, NAT COMPUT SCI, V2, P711, DOI 10.1038/s43588-022-00351-9; Ren Y, 2022, INT CONF ACOUST SPEE, P7577, DOI 10.1109/ICASSP43922.2022.9746883; Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Saharia C., 2022, ACM SIGGRAPH 2022 C, P1; Salimans T, 2016, ADV NEUR IN, V29; Samangouei P, 2018, Arxiv, DOI [arXiv:1805.06605, DOI 10.48550/ARXIV.1805.06605]; Sampath V, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00414-0; Sasal L, 2022, 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, ICMLA, P671, DOI 10.1109/ICMLA55696.2022.00111; Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12; Sergio Y C M W H., 2016, Stat, V1050; Shaham TR, 2019, IEEE I CONF COMP VIS, P4569, DOI 10.1109/ICCV.2019.00467; Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Shrivastava A, 2017, PROC CVPR IEEE, P2242, DOI 10.1109/CVPR.2017.241; Singh G., 2021, Illiterate Dall-E Learns to Compose; Singh N. K., 2021, Health Informatics: A Computational Perspective in Healthcare, P77, DOI DOI 10.1007/978-981-15-9735-05; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Song Y, 2019, ADV NEUR IN, V32; Suh S, 2021, NEURAL NETWORKS, V133, P69, DOI 10.1016/j.neunet.2020.10.004; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308; Guibas JT, 2018, Arxiv, DOI arXiv:1709.01872; Taeihagh A, 2021, POLICY SOC, V40, P137, DOI 10.1080/14494035.2021.1928377; Tan JX, 2021, COMPUT MED IMAG GRAP, V87, DOI 10.1016/j.compmedimag.2020.101817; Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262; Thottolil R, 2023, Arxiv, DOI arXiv:2306.05951; Togelius Julian., 2014, PROCEDURAL CONTENT G; Tolstikhin I O., 2017, Advances in Neural Information Processing Systems, P30; Torfi A, 2020, Arxiv, DOI arXiv:2001.09346; Toshevska M., 2021, IEEE T ART INT; TramŠr F, 2020, Arxiv, DOI arXiv:1705.07204; Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165; Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; Vaswani A, 2017, ADV NEUR IN, V30; Volodina V, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0071; Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24; Vovk V., 2013, Empirical Inference: Festschrift in Honor of Vladimir N. Vapnik, P105, DOI DOI 10.1007/978-3-642-41136-6_11; Wang CJ, 2021, INFORM FUSION, V67, P147, DOI 10.1016/j.inffus.2020.10.015; Wang J, 2020, SOFT COMPUT, V24, P18173, DOI 10.1007/s00500-020-05073-6; Wang TT, 2021, J GEOPHYS RES-SOL EA, V126, DOI 10.1029/2020JB020077; Wang WJ, 2024, Arxiv, DOI arXiv:2305.10874; Wang YH, 2020, IEEE WINT CONF APPL, P1149, DOI [10.1109/WACV45572.2020.9093492, 10.1109/wacv45572.2020.9093492]; Wang Z, 2003, CONF REC ASILOMAR C, P1398; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Wang ZW, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439723; Westerlund M, 2019, TECHNOL INNOV MANAG, V9, P39, DOI 10.22215/timreview/1282; Wilby D, 2019, VISION RES, V158, P100, DOI 10.1016/j.visres.2019.02.008; Wu Y, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21734-y; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Xia WH, 2023, IEEE T PATTERN ANAL, V45, P3121, DOI 10.1109/TPAMI.2022.3181070; Xiao JS, 2022, NEURAL COMPUT APPL, V34, P7209, DOI 10.1007/s00521-021-06841-7; Xie Q, 2019, ARXIV190412848; Xu JJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3940; Xun SY, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105063; Yang JW, 2017, Arxiv, DOI arXiv:1703.01560; Yang JS, 2023, IEEE ACCESS, V11, P31941, DOI 10.1109/ACCESS.2023.3259467; Yang LC, 2017, Arxiv, DOI arXiv:1703.10847; Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310; Yu LT, 2017, AAAI CONF ARTIF INTE, P2852; Yu PP, 2021, IET BIOMETRICS, V10, P607, DOI 10.1049/bme2.12031; Yu Y, 2017, LECT NOTES COMPUT SC, V10667, P97, DOI 10.1007/978-3-319-71589-6_9; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang G, 2018, LECT NOTES COMPUT SC, V11210, P422, DOI 10.1007/978-3-030-01231-1_26; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhang MS, 2018, IEEE INT CONF AUTOM, P132, DOI 10.1145/3238147.3238187; Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068; Zhang TF, 2019, PETROL SCI, V16, P541, DOI 10.1007/s12182-019-0328-4; Zhang WY, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P2482, DOI 10.1145/3534678.3539239; Zhang Y., 2020, EUROPEAN C COMPUTER, V12357, P70, DOI [DOI 10.1007/978-3-030-58610-25, 10.1007/978-3-030-58610-2 5]; Zhang ZY, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2377, DOI 10.1145/3357384.3358081; Zhao JY, 2018, Arxiv, DOI arXiv:1804.06876; Zhao Y, 2022, NEUROCOMPUTING, V500, P567, DOI 10.1016/j.neucom.2022.05.044; Zhou T, 2022, PR MACH LEARN RES; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhu MF, 2019, PROC CVPR IEEE, P5795, DOI 10.1109/CVPR.2019.00595; Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186	249	1	1	68	68	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND		2632-2153		MACH LEARN-SCI TECHN	Mach. Learn.-Sci. Technol.	MAR 1	2024	5	1							011001	10.1088/2632-2153/ad1f77	http://dx.doi.org/10.1088/2632-2153/ad1f77			35	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Science & Technology - Other Topics	GD3G9		gold, Green Submitted			2024-07-03	WOS:001150683000001
J	Yang, C; Li, ZC; Zhang, LF				Yang, Cong; Li, Zuchao; Zhang, Lefei			Bootstrapping Interactive Image-Text Alignment for Remote Sensing Image Captioning	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING			English	Article						Remote sensing; Visualization; Feature extraction; Transformers; Task analysis; Semantics; Discrete Fourier transforms; Fourier transformer; multimodal information alignment; remote sensing image captioning (RSIC); vision-language pre-training (VLP)	NETWORK	Recently, remote sensing image captioning (RSIC) has gained significant attention in the remote sensing community. Due to the significant differences in spatial resolution of remote sensing images, existing methods in this field have predominantly concentrated on the fine-grained extraction of remote sensing image features, but they cannot effectively handle the semantic consistency between visual features and textual features. To efficiently align the image-text, we propose a novel two-stage vision-language pre-training (VLP)-based approach to bootstrap interactive image-text alignment for RSIC, called BITA, which relies on the design of a lightweight interactive Fourier transformer (IFT) to better align remote sensing image-text features. The Fourier layer in the IFT is capable of extracting multiscale features of remote sensing images in the frequency domain, thereby reducing the redundancy of remote sensing visual features. Specifically, the first stage involves preliminary alignment through image-text contrastive learning (ITC), which aligns the learned multiscale remote sensing features from the IFT with textual features. In the second stage, the IFT connects the frozen image encoder with a large language model (LLM). Then, prefix causal language modeling (PCLM) is utilized to guide the text generation process using visual features. Ultimately, across the UCM-caption, RSICD, and NWPU-caption datasets, the experimental results clearly demonstrate that BITA outperforms other advanced comparative approaches.	[Yang, Cong; Li, Zuchao; Zhang, Lefei] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China; [Yang, Cong; Li, Zuchao; Zhang, Lefei] Hubei Luojia Lab, Wuhan 430079, Peoples R China	Wuhan University	Zhang, LF (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Sch Comp Sci, Wuhan 430072, Peoples R China.	yangcong356@whu.edu.cn; zcli-charlie@whu.edu.cn; zhanglefei@whu.edu.cn			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Barraco M, 2022, IEEE COMPUT SOC CONF, P4661, DOI 10.1109/CVPRW56347.2022.00512; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen HRX, 2023, ISPRS J PHOTOGRAMM, V198, P99, DOI 10.1016/j.isprsjprs.2023.03.004; Cheng H. Huang, 2022, IEEE Trans. Geosci. Remote Sens., V60; COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354; Dai D., 2023, FINDINGS ASS COMPUTA, P4005; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong YN, 2021, IEEE T CYBERNETICS, V51, P3185, DOI 10.1109/TCYB.2020.3004263; Dong YH, 2021, PR MACH LEARN RES, V139; Dosovitskiy A., 2020, INT C LEARN REPRESEN, P1; Hoxha G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3105004; Hoxha S., 2022, IEEE Trans. Geosci. Remote Sens., V60, DOI DOI 10.1109/TGRS.2022.3195692.[44]C; Huang W, 2021, IEEE GEOSCI REMOTE S, V18, P436, DOI 10.1109/LGRS.2020.2980933; Huang ZC, 2020, Arxiv, DOI arXiv:2004.00849; Kandala H, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3198234; Lee-Thorp J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4296; Li G, 2020, AAAI CONF ARTIF INTE, V34, P11336; Li J, 2022, arXiv; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li X., 2020, EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8; Li X, 2024, Arxiv, DOI arXiv:2305.05726; Li XL, 2021, IEEE T GEOSCI REMOTE, V59, P5246, DOI 10.1109/TGRS.2020.3010106; Li YP, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3102590; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lu JS, 2019, ADV NEUR IN, V32; Lu XQ, 2020, IEEE T GEOSCI REMOTE, V58, P1985, DOI 10.1109/TGRS.2019.2951636; Lu XX, 2018, IEEE T GEOSCI REMOTE, V56, P2183, DOI 10.1109/TGRS.2017.2776321; Mei SH, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2022.3233726; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qu X. Li, 2016, P INT C COMP INF TEL, P1; Radford A, 2021, PR MACH LEARN RES, V139; Rao YM, 2021, ADV NEURAL INFORM PR, V34; Roy SK, 2023, IEEE T GEOSCI REMOTE, V61, DOI 10.1109/TGRS.2023.3286826; Shi ZW, 2017, IEEE T GEOSCI REMOTE, V55, P3623, DOI 10.1109/TGRS.2017.2677464; Sumbul G, 2021, IEEE T GEOSCI REMOTE, V59, P6922, DOI 10.1109/TGRS.2020.3031111; Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015; Vaswani A, 2017, ADV NEUR IN, V30; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang BQ, 2019, IEEE GEOSCI REMOTE S, V16, P1274, DOI 10.1109/LGRS.2019.2893772; Wang Q, 2023, IEEE T CYBERNETICS, V53, P6910, DOI 10.1109/TCYB.2022.3222606; Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P10532, DOI 10.1109/TGRS.2020.3044054; Wang YY, 2022, AAAI CONF ARTIF INTE, P2585; Wang Y, 2022, IEEE J-STARS, V15, P2154, DOI 10.1109/JSTARS.2022.3153636; Wang Z., 2022, P INT C LEARN REPR I, P1; Xi JB, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14122931; Yang QQ, 2022, ISPRS J PHOTOGRAMM, V186, P190, DOI 10.1016/j.isprsjprs.2022.02.001; Yao D., 2023, IEEE Trans. Geosci. Remote Sens., V61; Zhang LF, 2022, IEEE GEOSC REM SEN M, V10, P270, DOI 10.1109/MGRS.2022.3145854; Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang W., 2022, IEEE Trans. Geosci. Remote Sens., V60; Zhang XR, 2017, INT GEOSCI REMOTE SE, P4798, DOI 10.1109/IGARSS.2017.8128075; Zhao Z. Shi, 2022, IEEE Trans. Geosci. RemoteSens., V60; Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041	59	5	5	13	13	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	0196-2892	1558-0644		IEEE T GEOSCI REMOTE	IEEE Trans. Geosci. Remote Sensing		2024	62								5607512	10.1109/TGRS.2024.3359316	http://dx.doi.org/10.1109/TGRS.2024.3359316			12	Geochemistry & Geophysics; Engineering, Electrical & Electronic; Remote Sensing; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Geochemistry & Geophysics; Engineering; Remote Sensing; Imaging Science & Photographic Technology	JL2H0		Green Submitted			2024-07-03	WOS:001173250800007
J	Fecho, K; Bizon, C; Issabekova, T; Moxon, S; Thessen, AE; Abdollahi, S; Baranzini, SE; Belhu, B; Byrd, WE; Chung, L; Crouse, A; Duby, MP; Ferguson, S; Foksinska, A; Forero, L; Friedman, J; Gardner, V; Glusman, G; Hadlock, J; Hanspers, K; Hinderer, E; Hobbs, C; Hyde, G; Huang, S; Koslicki, D; Mease, P; Muller, S; Mungall, CJ; Ramsey, SA; Roach, J; Rubin, I; Schurman, SH; Shalev, A; Smith, B; Soman, K; Stemann, S; Su, AI; Ta, C; Watkins, PB; Williams, MD; Wu, CL; Xu, CH				Fecho, Karamarie; Bizon, Chris; Issabekova, Tursynay; Moxon, Sierra; Thessen, Anne E.; Abdollahi, Shervin; Baranzini, Sergio E.; Belhu, Basazin; Byrd, William E.; Chung, Lawrence; Crouse, Andrew; Duby, Marc P.; Ferguson, Stephen; Foksinska, Aleksandra; Forero, Laura; Friedman, Jennifer; Gardner, Vicki; Glusman, Gwenlyn; Hadlock, Jennifer; Hanspers, Kristina; Hinderer, Eugene; Hobbs, Charlotte; Hyde, Gregory; Huang, Sui; Koslicki, David; Mease, Philip; Muller, Sandrine; Mungall, Christopher J.; Ramsey, Stephen A.; Roach, Jared; Rubin, Irit; Schurman, Shepherd H.; Shalev, Anath; Smith, Brett; Soman, Karthik; Stemann, Sarah; Su, Andrew I.; Ta, Casey; Watkins, Paul B.; Williams, Mark D.; Wu, Chunlei; Xu, Colleen H.		Biomed Data Translator Consortium	An approach for collaborative development of a federated biomedical knowledge graph-based question-answering system: Question-of-the-Month challenges	JOURNAL OF CLINICAL AND TRANSLATIONAL SCIENCE			English	Article						Translational research; team science; knowledge graphs; bioinformatics; semantic technology		Knowledge graphs have become a common approach for knowledge representation. Yet, the application of graph methodology is elusive due to the sheer number and complexity of knowledge sources. In addition, semantic incompatibilities hinder efforts to harmonize and integrate across these diverse sources. As part of The Biomedical Translator Consortium, we have developed a knowledge graph-based question-answering system designed to augment human reasoning and accelerate translational scientific discovery: the Translator system. We have applied the Translator system to answer biomedical questions in the context of a broad array of diseases and syndromes, including Fanconi anemia, primary ciliary dyskinesia, multiple sclerosis, and others. A variety of collaborative approaches have been used to research and develop the Translator system. One recent approach involved the establishment of a monthly "Question-of-the-Month (QotM) Challenge" series. Herein, we describe the structure of the QotM Challenge; the six challenges that have been conducted to date on drug-induced liver injury, cannabidiol toxicity, coronavirus infection, diabetes, psoriatic arthritis, and ATP1A3-related phenotypes; the scientific insights that have been gleaned during the challenges; and the technical issues that were identified over the course of the challenges and that can now be addressed to foster further development of the prototype Translator system. We close with a discussion on Large Language Models such as ChatGPT and highlight differences between those models and the Translator system.	[Fecho, Karamarie; Bizon, Chris; Gardner, Vicki] Univ N Carolina, Renaissance Comp Inst RENCI, Chapel Hill, NC 27599 USA; [Fecho, Karamarie] Copperline Profess Solut, Pittsboro, NC 27312 USA; [Issabekova, Tursynay; Thessen, Anne E.] Univ Colorado, Dept Biomed Informat, Anschutz Med Campus, Aurora, CO USA; [Moxon, Sierra; Mungall, Christopher J.] Lawrence Berkeley Natl Lab, Biosyst Data Sci Dept, Berkeley, CA USA; [Abdollahi, Shervin; Stemann, Sarah; Williams, Mark D.] NIH, Natl Ctr Adv Translat Sci, Div Preclin Innovat, Rockville, MD USA; [Baranzini, Sergio E.; Soman, Karthik] Univ Calif San Francisco, Weill Inst Neurosci, Dept Neurol, San Francisco, CA USA; [Belhu, Basazin; Glusman, Gwenlyn; Hadlock, Jennifer; Huang, Sui; Roach, Jared; Rubin, Irit; Smith, Brett] Inst Syst Biol, Seattle, WA USA; [Byrd, William E.; Crouse, Andrew; Foksinska, Aleksandra; Shalev, Anath] Univ Alabama Birmingham, Hugh Kaul Precis Med Inst, Birmingham, AL USA; [Chung, Lawrence; Duby, Marc P.; Muller, Sandrine] Broad Inst MIT & Harvard, Cambridge, MA USA; [Ferguson, Stephen] Natl Inst Environm Hlth Sci, NIH, Res Triangle Pk, NC USA; [Forero, Laura; Friedman, Jennifer; Hobbs, Charlotte] Rady Childrens Hosp, Rady Childrens Inst Genom Med, San Diego, CA USA; [Forero, Laura; Friedman, Jennifer] Univ Calif San Diego, San Diego, CA USA; [Hanspers, Kristina] Univ Calif San Francisco, Gladstone Inst, San Francisco, CA USA; [Hinderer, Eugene] Tufts Med Ctr, Tufts Clin & Translat Sci Inst, Boston, MA USA; [Hyde, Gregory] Dartmouth Coll, Thayer Sch Engn, Hanover, NH USA; [Koslicki, David] Penn State Univ, Dept Comp Sci & Engn, University Pk, PA USA; [Koslicki, David] Penn State Univ, Dept Biol, University Pk, PA USA; [Koslicki, David] Penn State Univ, Huck Inst Life Sci, University Pk, PA USA; [Mease, Philip] St Joseph Hlth, Swedish Med Ctr, Seattle, WA USA; [Mease, Philip] Univ Washington, Seattle, WA USA; [Ramsey, Stephen A.] Oregon State Univ, Portland, OR USA; [Schurman, Shepherd H.] NIA, NIH, Baltimore, MD USA; [Su, Andrew I.; Wu, Chunlei; Xu, Colleen H.] Scripps Res Inst, La Jolla, CA USA; [Ta, Casey] Columbia Univ, Irving Med Ctr, New York, NY USA; [Watkins, Paul B.] Univ N Carolina, Eshelman Sch Pharm, Div Pharmacotherapy & Expt Therapeut, Chapel Hill, NC USA	University of North Carolina; University of North Carolina Chapel Hill; University of Colorado System; University of Colorado Anschutz Medical Campus; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; National Institutes of Health (NIH) - USA; NIH National Center for Advancing Translational Sciences (NCATS); University of California System; University of California San Francisco; Institute for Systems Biology (ISB); University of Alabama System; University of Alabama Birmingham; Harvard University; Massachusetts Institute of Technology (MIT); Broad Institute; National Institutes of Health (NIH) - USA; NIH National Institute of Environmental Health Sciences (NIEHS); Rady Childrens Hospital San Diego; University of California System; University of California San Diego; University of California System; University of California San Francisco; The J David Gladstone Institutes; Tufts Medical Center; Dartmouth College; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Swedish Medical Center; University of Washington; University of Washington Seattle; Oregon State University; National Institutes of Health (NIH) - USA; NIH National Institute on Aging (NIA); Scripps Research Institute; NewYork-Presbyterian Hospital; Columbia University; University of North Carolina; University of North Carolina Chapel Hill	Fecho, K (corresponding author), Univ N Carolina, Renaissance Comp Inst RENCI, Chapel Hill, NC 27599 USA.; Fecho, K (corresponding author), Copperline Profess Solut, Pittsboro, NC 27312 USA.	kfecho@copperlineprofessionalsolutions.com	Wu, Chunlei/ABF-4720-2020; Koslicki, David/IAR-7779-2023; Baranzini, Sergio/A-9422-2013	Wu, Chunlei/0000-0002-2629-6124; Koslicki, David/0000-0002-0640-954X; Baranzini, Sergio/0000-0003-0067-194X; Byrd, William/0000-0003-4730-5293; Issabekova, Tursynay/0000-0003-0842-7335; Thessen, Anne/0000-0002-2908-3327; Fecho, Karamarie/0000-0002-6704-9306; Xu, Colleen/0000-0003-2975-882X; Su, Andrew I./0000-0002-9859-4104; Glusman, Gwenlyn/0000-0001-8060-5955; Taylor Moxon, Sierra/0000-0002-8719-7760	The authors are grateful for the leadership and support provided by Dr. Tyler F. Beck, Dr. Christine M. Colvis, and the rest of the Translator Extramural Leadership Team at the National Center for Advancing Translational Sciences (NCATS). They also acknowl; Translator Extramural Leadership Team at the National Center for Advancing Translational Sciences (NCATS)	The authors are grateful for the leadership and support provided by Dr. Tyler F. Beck, Dr. Christine M. Colvis, and the rest of the Translator Extramural Leadership Team at the National Center for Advancing Translational Sciences (NCATS). They also acknowl; Translator Extramural Leadership Team at the National Center for Advancing Translational Sciences (NCATS)	The authors are grateful for the leadership and support provided by Dr. Tyler F. Beck, Dr. Christine M. Colvis, and the rest of the Translator Extramural Leadership Team at the National Center for Advancing Translational Sciences (NCATS). They also acknowledge the NCATS Intramural Research Program for their support of the work described herein and both the NCATS Publications Committee and the Translator Publications Committee for review and approval of the manuscript for publication.	Alston William., 2005, Beyond Justification: Dimensions of Epistemic Evaluation; Davis AP, 2023, NUCLEIC ACIDS RES, V51, pD1257, DOI 10.1093/nar/gkac833; DrugBank Online, Flunarizine; DrugBank Online, Haloperidol; DrugBank Online, Clozapine; DrugBank Online, Botulinum toxin type A; Fecho K, 2022, CTS-CLIN TRANSL SCI, V15, P1838, DOI 10.1111/cts.13301; Fecho K, 2021, CTS-CLIN TRANSL SCI, V14, P1719, DOI 10.1111/cts.13021; Fecho K, 2019, J BIOMED INFORM, V100, DOI 10.1016/j.jbi.2019.103325; Fecho K, 2019, CTS-CLIN TRANSL SCI, V12, P91, DOI 10.1111/cts.12592; Folino TB., 2022, StatPearls; Fu D, 2019, TOXICOL SCI, V171, P431, DOI 10.1093/toxsci/kfz154; GO, 1999, The Gene Ontology (GO) knowledgebase is the world's largest source of information on the functions of genes. This knowledge is both human-readable and machine-readable, and is a foundation for computational analysis of large-scale molecular biology and genetics experiments in biomedical research; Jazz Pharmaceuticals Inc, EPIDIOLEX® (cannabidiol) oral solution: prescribing information; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kilicoglu H, 2012, BIOINFORMATICS, V28, P3158, DOI 10.1093/bioinformatics/bts591; MONDO, 2023, The Mondo Disease Ontology (MONDO) aims to harmonize disease definitions across biomedical disciplines; National Center for Advancing Translational Sciences, NCATS BioPlanet: A Resource for Discovery; National Institute of Diabetes and Digestive Disorders, Porphyria; National Library of Medicine, DailyMed. The DailyMed database contains 145958 labels submitted to the US Food and Drug Administration by companies; National Library of Medicine National Center for Biotechnology Information, ALAS1 5'-aminolevulinate synthase 1 [Homo sapiens (human)], Gene ID: 211; National Library of Medicine National Center for Biotechnology Information, Gene ID: 5468; NCATS Translator, 2023, Reasoner API. Tranlsator Reasoner Application Programming Interface (TRAPI) defines a standard HTTP Aaplication Programming Interface schema for communication across Translator components by leveraging a graph-based query structure and applying Biolink Model to precisely describe the semantics of biological entities and their relationships; Node Normalization, Node Normalization is a Translator service that, when provided with an input compact uniform resource identifier (CURIE) for an entity, returns the Translator-preferred CURIE, a list of equivalent CURIEs, and the Biolink Model-defined semantic types for that entity; NORD: National Organization for Rare Disorders, Sitosterolemia; OpenAI, 2015, GPT-4. GPT-4 is OpenAI's most advanced system, producing safer and more useful responses; Stewart JD, 2010, HEPATOLOGY, V52, P1791, DOI 10.1002/hep.23891; The Alan Turing Institute Interest Group, 2023, Knowledge graphs. How do we encode knowledge to use at scale in open, evolving, decentralized systems?; The Biomedical Data Translator Consortium, 2019, Clini Translat Sci, V12, P91, DOI [10.1111/cts.13021, DOI 10.1111/CTS.13021]; Thielen LA, 2020, CELL METAB, V32, P353, DOI 10.1016/j.cmet.2020.07.002; ThinkML, 2022, What are the Natural Language Processing Challenges, and How to Fix them?; Unni DR, 2022, CTS-CLIN TRANSL SCI, V15, P1848, DOI 10.1111/cts.13302; WebMD LLC, 2005, Beta-Sitosterol-Uses, Side Effects, and More; WikiPathways, WikiPathways is an open science platform for biological pathways contributed, updated, and used by the research community; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037	36	1	1	2	4	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND		2059-8661		J CLIN TRANSL SCI	J. Clin. Transl. Sci.	SEP 14	2023	7	1							e214	10.1017/cts.2023.619	http://dx.doi.org/10.1017/cts.2023.619			10	Medicine, Research & Experimental	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine	U6WZ5	37900350	Green Published, gold			2024-07-03	WOS:001086202500001
J	Dhar, S; Kothari, D; Vasquez, M; Clarke, T; Maroda, A; McClain, WG; Sheyn, A; Tuliszewski, RM; Tang, DM; Rangarajan, S				Dhar, Sarit; Kothari, Dhruv; Vasquez, Missael; Clarke, Travis; Maroda, Andrew; McClain, Wade G.; Sheyn, Anthony; Tuliszewski, Robert M.; Tang, Dennis M.; Rangarajan, Sanjeet, V			The utility and accuracy of ChatGPT in providing post-operative instructions following tonsillectomy: A pilot study	INTERNATIONAL JOURNAL OF PEDIATRIC OTORHINOLARYNGOLOGY			English	Article						Artificial intelligence; Otolaryngology; Tonsillectomy; ChatGPT; Machine learning; Post-operative instructions		Objective: To investigate the utility of answers generated by ChatGPT, a large language model, to common questions parents have for their children following tonsillectomy. Methods: Twenty Otolaryngology residents anonymously submitted common questions asked by parents of pediatric patients following tonsillectomy. After identifying the 16 most common questions via consensus-based approach, we asked ChatGPT to generate responses to these queries. Satisfaction with the AI-generated answers was rated from 1 (Worst) to 5 (Best) by an expert panel of 3 pediatric Otolaryngologists. Results: The distribution of questions across the five most common domains, their mean satisfaction scores, and their Krippendorf's interrater reliability coefficient were: Pain management [6, (3.67), (0.434)], Complications [4, (3.58), (-0.267)], Diet [3, (4.33), (-0.357)], Physical Activity [2, (4.33), (-0.318)], and Follow-up [1, (2.67), (-0.250)]. The panel noted that answers for diet, bleeding complications, and return to school were thorough. Pain management and follow-up recommendations were inaccurate, including a recommendation to prescribe codeine to children despite a black -box warning, and a suggested post-operative follow-up at 1 week, rather than the customary 2-4 weeks for our panel. Conclusion: Although ChatGPT can provide accurate answers for common patient questions following tonsillectomy, it sometimes provides eloquently written inaccurate information. This may lead to patients using AIgenerated medical advice contrary to physician advice. The inaccuracy in pain management answers likely reflects regional practice variability. If trained appropriately, ChatGPT could be an excellent resource for Otolaryngologists and patients to answer questions in the postoperative period. Future research should investigate if Otolaryngologist-trained models can increase the accuracy of responses.	[Dhar, Sarit; Kothari, Dhruv; Clarke, Travis; Maroda, Andrew; McClain, Wade G.; Sheyn, Anthony; Tuliszewski, Robert M.] Univ Tennessee, Hlth Sci Ctr, Dept Otolaryngol Head & Neck Surg, 910 Madison Ave, Memphis, TN 38163 USA; [Kothari, Dhruv; Vasquez, Missael; Tang, Dennis M.] Cedars Sinai Med Ctr, Dept Otolaryngol Head & Neck Surg, 8700 Beverly Blvd, Los Angeles, CA 90048 USA; [Rangarajan, Sanjeet, V] Case Western Reserve Univ, Univ Hosp Cleveland Med Ctr, Dept Otolaryngol Head & Neck Surg, Sch Med, 11100 Euclid Ave, Cleveland, OH 44106 USA	University of Tennessee System; University of Tennessee Health Science Center; Cedars Sinai Medical Center; University Hospitals of Cleveland; University System of Ohio; Case Western Reserve University	Rangarajan, S (corresponding author), Case Western Reserve Univ, Univ Hosp Cleveland Med Ctr, Dept Otolaryngol Head & Neck Surg, Sch Med, 11100 Euclid Ave, Cleveland, OH 44106 USA.			Tang, Dennis/0000-0003-2315-9930; /0000-0002-2568-271X; Dhar, Sarit/0009-0009-1880-4561				Anand VT, 1999, CLIN OTOLARYNGOL, V24, P360, DOI 10.1046/j.1365-2273.1999.00284.x; [Anonymous], Tonsil removal-what to ask your doctor information; [Anonymous], 2013, Safety Review Update of Codeine Use in Children; New Boxed Warning and Contraindication on Use after Tonsillectomy And/or Adenoidectomy; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Baugh RF, 2011, OTOLARYNG HEAD NECK, V144, pS1, DOI 10.1177/0194599810389949; Benke K, 2018, INT J ENV RES PUB HE, V15, DOI 10.3390/ijerph15122796; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Campbell DJ, 2023, J CLIN SLEEP MED, V19, P1989, DOI 10.5664/jcsm.10728; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chiesa-Estomba CM, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08104-8; Chua KP, 2017, PEDIATRICS, V140, DOI 10.1542/peds.2017-1765; clevelandclinic, Tonsillectomy: procedure details and recovery; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Evaluating Patient and Otolaryngologist Dialogues Generated by ChatGPT,, 2023, Are They Adequate?, DOI [10.21203/rs.3.rs-2719379/v1, DOI 10.21203/RS.3.RS-2719379/V1]; Harbaugh CM, 2019, CURR OPIN PEDIATR, V31, P378, DOI 10.1097/MOP.0000000000000768; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Long C., 2023, Evaluating ChatGPT-4 in Otolaryngology-Head and Neck Surgery Board Examination Using the CVSA Model, P2023, DOI [10.1101/2023.05.30.23290758,05.30.23290758, DOI 10.1101/2023.05.30.23290758,05.30.23290758]; medlineplus, Tonsil removal-what to ask your doctor: MedlinePlus Medical Encyclopedia; Mitchell R.B., Clinical practice guideline: tonsillectomy in children; Suresh K., 2023, Utility of GPT-4 as an Informational Patient Resource in Otolaryngology, P2023, DOI [10.1101/2023.05.14.23289944,05.14.23289944, DOI 10.1101/2023.05.14.23289944,05.14.23289944]; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Womer J, 2014, J PAIN SYMPTOM MANAG, V48, P903, DOI 10.1016/j.jpainsymman.2013.12.241; Yaster M, 2020, CURR OPIN ANESTHESIO, V33, P327, DOI 10.1097/ACO.0000000000000865	25	3	3	1	1	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0165-5876	1872-8464		INT J PEDIATR OTORHI	Int. J. Pediatr. Otorhinolaryngol.	APR	2024	179								111901	10.1016/j.ijporl.2024.111901	http://dx.doi.org/10.1016/j.ijporl.2024.111901		MAR 2024	6	Otorhinolaryngology; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology; Pediatrics	NR2N4	38447265				2024-07-03	WOS:001202116100001
J	Kleinstreuer, N; Hartung, T				Kleinstreuer, Nicole; Hartung, Thomas			Artificial intelligence (AI)-it's the end of the tox as we know it (and I feel fine)	ARCHIVES OF TOXICOLOGY			English	Review						Artificial intelligence; Toxicology; Predictive modeling; Chemical safety; Risk assessment; Computational toxicology	TOXICITY; MODEL; QSAR; VALIDATION; CHALLENGES; KNOWLEDGE; PATHWAY; TOOLS	The rapid progress of AI impacts diverse scientific disciplines, including toxicology, and has the potential to transform chemical safety evaluation. Toxicology has evolved from an empirical science focused on observing apical outcomes of chemical exposure, to a data-rich field ripe for AI integration. The volume, variety and velocity of toxicological data from legacy studies, literature, high-throughput assays, sensor technologies and omics approaches create opportunities but also complexities that AI can help address. In particular, machine learning is well suited to handle and integrate large, heterogeneous datasets that are both structured and unstructured-a key challenge in modern toxicology. AI methods like deep neural networks, large language models, and natural language processing have successfully predicted toxicity endpoints, analyzed high-throughput data, extracted facts from literature, and generated synthetic data. Beyond automating data capture, analysis, and prediction, AI techniques show promise for accelerating quantitative risk assessment by providing probabilistic outputs to capture uncertainties. AI also enables explanation methods to unravel mechanisms and increase trust in modeled predictions. However, issues like model interpretability, data biases, and transparency currently limit regulatory endorsement of AI. Multidisciplinary collaboration is needed to ensure development of interpretable, robust, and human-centered AI systems. Rather than just automating human tasks at scale, transformative AI can catalyze innovation in how evidence is gathered, data are generated, hypotheses are formed and tested, and tasks are performed to usher new paradigms in chemical safety assessment. Used judiciously, AI has immense potential to advance toxicology into a more predictive, mechanism-based, and evidence-integrated scientific discipline to better safeguard human and environmental wellbeing across diverse populations.	[Kleinstreuer, Nicole] NIH, NIEHS, DTT, NICEATM, Durham, NC USA; [Hartung, Thomas] Johns Hopkins Univ, Doerenkamp Zbinden Chair Evidence Based Toxicol, Ctr Alternat Anim Testing CAAT, Bloomberg Sch Publ Hlth, Baltimore, MD 21218 USA; [Hartung, Thomas] Univ Konstanz, CAAT Europe, Constance, Germany	National Institutes of Health (NIH) - USA; NIH National Institute of Environmental Health Sciences (NIEHS); Johns Hopkins University; Johns Hopkins Bloomberg School of Public Health; University of Konstanz	Hartung, T (corresponding author), Johns Hopkins Univ, Doerenkamp Zbinden Chair Evidence Based Toxicol, Ctr Alternat Anim Testing CAAT, Bloomberg Sch Publ Hlth, Baltimore, MD 21218 USA.; Hartung, T (corresponding author), Univ Konstanz, CAAT Europe, Constance, Germany.	THartung@jhu.edu	Hartung, Thomas/Q-1076-2015	Hartung, Thomas/0000-0003-1359-7689	Directorate-General for Research and Innovation [963845]; European Union; Intramural Research Program of the NIH	Directorate-General for Research and Innovation; European Union(European Union (EU)); Intramural Research Program of the NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No. 963845 (ONTOX). This work was supported (in part) by the Intramural Research Program of the NIH. The authors are most grateful to Ms. Erni Peterson for designing the graphs.	Abedini J, 2021, COMPUT TOXICOL, V20, DOI 10.1016/j.comtox.2021.100184; Abuhammad A, 2016, EXPERT OPIN DRUG DIS, V11, P197, DOI 10.1517/17460441.2016.1118046; Acodis, 2020, EVERYTHING YOU NEED; Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Allen TEH, 2014, CHEM RES TOXICOL, V27, P2100, DOI 10.1021/tx500345j; Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140; Baskin II, 2018, METHODS MOL BIOL, V1800, P119, DOI 10.1007/978-1-4939-7899-1_5; Baxi V, 2022, MODERN PATHOL, V35, P23, DOI 10.1038/s41379-021-00919-2; Benfenati E, 1997, TOXICOLOGY, V119, P213, DOI 10.1016/S0300-483X(97)03631-7; Bhhatarai B, 2019, NAT MATER, V18, P418, DOI 10.1038/s41563-019-0332-5; Bozada T, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.685298; Briggs AH, 2012, MED DECIS MAKING, V32, P722, DOI 10.1177/0272989X12458348; Challa AP, 2020, REPROD TOXICOL, V95, P148, DOI 10.1016/j.reprotox.2020.05.004; Chiu WA, 2017, ALTEX-ALTERN ANIM EX, V34, P377, DOI 10.14573/altex.1608251; Chou YL, 2022, INFORM FUSION, V81, P59, DOI 10.1016/j.inffus.2021.11.003; Clark C, 2016, ACM-IEEE J CONF DIG, P143, DOI 10.1145/2910896.2910904; Corradi Marie P F, 2022, Biomater Biosyst, V7, P100061, DOI 10.1016/j.bbiosy.2022.100061; Council N.R., 2007, TOXICITY TESTING 21, DOI DOI 10.17226/11970; Daniel AB, 2022, FRONT TOXICOL, V4, DOI 10.3389/ftox.2022.987848; Daxberger E, 2021, PR MACH LEARN RES, V139; Devinyak OT, 2016, CURR COMPUT-AID DRUG, V12, P265, DOI 10.2174/1573409912666160509121831; Eriksson L, 2003, ENVIRON HEALTH PERSP, V111, P1361, DOI 10.1289/ehp.5758; Foster C, 2024, STANDARDIZING EXTRAC; Gilmour N, 2022, REGUL TOXICOL PHARM, V131, DOI 10.1016/j.yrtph.2022.105159; Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018; Hartung T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1269932; Hartung T, 2023, ALTEX-ALTERN ANIM EX, V40, P559, DOI 10.14573/altex.2309191; Hartung T, 2023, ALTEX-ALTERN ANIM EX, V40, P4, DOI 10.14573/altex.2301061; Hartung T, 2009, ALTEX-ALTERN TIEREXP, V26, P155; Hines DE, 2022, FRONT PHARMACOL, V13, DOI 10.3389/fphar.2022.864742; Hoffmann S, 2006, HUM EXP TOXICOL, V25, P497, DOI 10.1191/0960327106het648oa; Hoffmann S, 2017, ARCH TOXICOL, V91, P2551, DOI 10.1007/s00204-017-1980-3; Idakwo G, 2018, J ENVIRON SCI HEAL C, V36, P169, DOI 10.1080/10590501.2018.1537118; Interagency Coordinating Committee on the Validation of Alternative Methods (ICCVAM), 2023, Validation, qualification, and regulatory acceptance of new approach methodologies; Jeong AESO, 2022, ENVIRON SCI TECHNOL, V56, P7532, DOI 10.1021/acs.est.1c07413; Jia XL, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c00653; Kadurin A, 2017, ONCOTARGET, V8, P10883, DOI 10.18632/oncotarget.14073; Karmaus AL, 2022, TOXICOL SCI, V188, P34, DOI 10.1093/toxsci/kfac042; Kavlock R, 2012, CHEM RES TOXICOL, V25, P1287, DOI 10.1021/tx3000939; Kejriwal M, 2022, INFORMATION, V13, DOI 10.3390/info13040161; Kiritchenko S, 2018, EXAMINING GENDER RAC; Kleinstreuer NC, 2020, CHEM RES TOXICOL, V33, P687, DOI 10.1021/acs.chemrestox.0c00070; Kleinstreuer Nicole C, 2018, Comput Toxicol, V8, P21, DOI 10.1016/j.comtox.2018.08.002; Kleinstreuer NC, 2017, CHEM RES TOXICOL, V30, P946, DOI 10.1021/acs.chemrestox.6b00347; Kleinstreuer NC, 2016, ENVIRON HEALTH PERSP, V124, P556, DOI 10.1289/ehp.1510183; Kleinstreuer NC, 2016, REGUL TOXICOL PHARM, V76, P39, DOI 10.1016/j.yrtph.2016.01.007; Korb KB, 2008, STUD COMPUT INTELL, V156, P83; Kwon Y., 2020, UNCERTAINTY QUANTIFI; Li YK, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-00144-6; Lin ZM, 2022, TOXICOL SCI, V189, P7, DOI 10.1093/toxsci/kfac075; Liu FC, 2023, APPL MATH MODEL, V117, P296, DOI 10.1016/j.apm.2022.12.008; Liu J, 2015, CHEM RES TOXICOL, V28, P738, DOI 10.1021/tx500501h; Lu J., 2017, Advances in Neural Information Processing Systems, P314; Luechtefeld T, 2018, TOXICOL RES-UK, V7, P732, DOI 10.1039/c8tx00051d; Luechtefeld T, 2018, TOXICOL SCI, V165, P198, DOI 10.1093/toxsci/kfy152; Luechtefeld T, 2017, ALTEX-ALTERN ANIM EX, V34, P459, DOI 10.14573/altex.1710141; Luo W, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5870; Maertens A, 2022, ALTEX-ALTERN ANIM EX, V39, P3, DOI 10.14573/altex.2201081; Mansouri K, 2024, FREE OPEN SOUR UNPUB; Mansouri K, 2021, ENVIRON HEALTH PERSP, V129, DOI 10.1289/EHP8495; Mansouri K, 2020, ENVIRON HEALTH PERSP, V128, DOI 10.1289/EHP5580; Marchant CA, 2008, TOXICOL MECH METHOD, V18, P177, DOI 10.1080/15376510701857320; Mayr A, 2016, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00080; Miller TH, 2018, ENVIRON SCI TECHNOL, V52, P12953, DOI 10.1021/acs.est.8b05382; OECD, 2017, REVISED GUIDANCE DOC; OECD, 2023, SAR ASSESSMENT FRAME; PAYNE MP, 1994, J CHEM INF COMP SCI, V34, P154, DOI 10.1021/ci00017a019; Santín EP, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1516; Pu LM, 2019, BMC PHARMACOL TOXICO, V20, DOI 10.1186/s40360-018-0282-6; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Richardson M, 2006, MACH LEARN, V62, P107, DOI 10.1007/s10994-006-5833-1; Rugard M, 2020, TOXICOL SCI, V173, P32, DOI 10.1093/toxsci/kfz214; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Samek W, 2021, P IEEE, V109, P247, DOI 10.1109/JPROC.2021.3060483; Schölkopf B, 2021, P IEEE, V109, P612, DOI 10.1109/JPROC.2021.3058954; Sedykh A, 2022, CHEM RES TOXICOL, V35, P992, DOI 10.1021/acs.chemrestox.1c00443; Sedykh AY, 2021, CHEM RES TOXICOL, V34, P634, DOI 10.1021/acs.chemrestox.0c00464; Shilo S, 2020, NAT MED, V26, P29, DOI 10.1038/s41591-019-0727-5; Song AH., 2023, Nature Reviews Bioengineering, V1, P930, DOI DOI 10.1038/S44222-023-00096-8; Sukur N, 2023, FOOD CHEM TOXICOL, V180, DOI 10.1016/j.fct.2023.114013; Tang WH, 2018, J ENVIRON SCI HEAL C, V36, P252, DOI 10.1080/10590501.2018.1537563; Thomas RS, 2019, TOXICOL SCI, V169, P317, DOI 10.1093/toxsci/kfz058; Tong WD, 2004, ENVIRON HEALTH PERSP, V112, P1249, DOI 10.1289/txg.7125; Tropsha A, 2010, MOL INFORM, V29, P476, DOI 10.1002/minf.201000061; Van Tran TT, 2023, J CHEM INF MODEL, V63, P2628, DOI 10.1021/acs.jcim.3c00200; Varghese Arun, 2020, Environment Systems & Decisions, V40, P465, DOI 10.1007/s10669-020-09763-2; Vidgen B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1667; Vinken M, 2021, TOXICOLOGY, V458, DOI 10.1016/j.tox.2021.152846; Vo AH, 2020, CHEM RES TOXICOL, V33, P20, DOI 10.1021/acs.chemrestox.9b00227; Walker VR, 2022, ENVIRON INT, V159, DOI 10.1016/j.envint.2021.107025; Wang T, 2021, NAT COMMUN, V12, DOI [10.1038/s41467-021-23774-w, 10.1038/s41467-020-20646-7]; Williams AJ, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0247-6; Wu JM, 2022, ENVIRON INT, V163, DOI 10.1016/j.envint.2022.107184; Wu YY, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19082358; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Yan RG, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01492-2	96	4	4	15	15	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0340-5761	1432-0738		ARCH TOXICOL	Arch. Toxicol.	MAR	2024	98	3					735	754		10.1007/s00204-023-03666-2	http://dx.doi.org/10.1007/s00204-023-03666-2		JAN 2024	20	Toxicology	Science Citation Index Expanded (SCI-EXPANDED)	Toxicology	HL3V7	38244040	hybrid, Green Published			2024-07-03	WOS:001145957600001
J	Kahveci, ZU				Kahveci, Zeynep Ulku			Attribution problem of generative AI: a view from US copyright law	JOURNAL OF INTELLECTUAL PROPERTY LAW & PRACTICE			English	Article							PROPERTY	center dot Three significant lawsuits concerning generative Artificial Intelligence (AI) were filed in the USA, starting the first wave of lawsuits against AI: (i) coders filed claims for the alleged use of their codes by OpenAI's CoPilot, (ii) visual artists filed claims against companies using Stable Diffusion and (iii) Getty Images filed claims against Stability AI, which uses Stable Diffusion. Following the lead of these lawsuits, copyright owners of literary works filed four other lawsuits against OpenAI, Meta and Alphabet (Google)'s large language models. All of these lawsuits are pending at the time of writing. center dot Among other things, plaintiffs filed claims challenging generative AI's lack of attribution to copyright owners of in-copyright works in its training data. As US copyright law does not protect moral rights strongly, a federal rule granting a right of attribution to all copyright owners does not exist. Yet, there are some provisions providing quasi-protection. Section 1202 of the Digital Millennium Copyright Act (DMCA) is one of them and protects copyright owners against removal/modification of the Copyright Management Information in connection with their works. center dot This article lays down the limitations of moral rights protection in the USA and demonstrates the difficulties faced by the plaintiffs of the pending lawsuits. The limitations of Section 1202 DMCA are explained to demonstrate its difference from a classic moral right of attribution. The outcomes of these lawsuits will be significant in building case law on generative AI for the first time in the USA. This article evaluates the benefits and disadvantages of courts' possible acceptance of plaintiffs' claims regarding attribution.	[Kahveci, Zeynep Ulku] Harvard Law Sch, Cambridge, MA 02138 USA	Harvard University	Kahveci, ZU (corresponding author), Harvard Law Sch, Cambridge, MA 02138 USA.	zeynep.kahveci@bilgi.edu.tr						Ad Hoc Working Grp, 1986, US ADHERENCE BERNE C; Akyurek Ekin., 2022, FINDINGS ASS COMPUTA, P2429; Andersen Sarah, 2023, INDIVIDUAL REPRESENT; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 17 USC 201; [Anonymous], 2008, 630FSUPP2D585 MDNC; [Anonymous], 2010, 739FSUPP2D927 ED VA; [Anonymous], 2019, GREGORY MANGO BUZZFE; [Anonymous], 2020, KIRK KARA CORP STONE; [Anonymous], 17 USC 106A; [Anonymous], 1976, GILLIAM AM BROADCAST; [Anonymous], 2003, HUGHES N 58 692 CARR; [Anonymous], 2023, HELEN TONERWHAT ARE; [Anonymous], 539US23 2003; [Anonymous], 2023, Forbes; [Anonymous], 15 US CODE 9401; [Anonymous], 2022, WALTER N ONEAL 3 SID; [Anonymous], 2023, NATURE, V618, P214; [Anonymous], 17 USC 1202 C; [Anonymous], 2023, PLAINTIFFS ALPHABET; [Anonymous], LANHAM TRADEMARK ACT; [Anonymous], 17 USC 1202; [Anonymous], BERNE CONVENTION IMP; [Anonymous], HOLL ACT STRIK WILL; [Anonymous], 2023, DOE 1 GITHUB INC; [Anonymous], 2003, 539 US 23 37 123 S C; [Anonymous], 2019, COUNCIL DIRECTIVE EC; [Anonymous], 2015, WATSON KAPPA MAP GRP; [Anonymous], 2011, USPQ2D BNA 1595 ED P; [Anonymous], 17 USC 1202 A B; [Anonymous], 2023, TIME MAGAZINE   0112; [Anonymous], 2012, PERS KEEPSAKES INC P; [Anonymous], 2011, AGENCE FRANCE PRESSE; [Anonymous], 17 USC 101; [Anonymous], 2023, GETTY IMAGES US INC; [Anonymous], 1988, S REP NO 352 100 CON; Bass Dina, 2023, BLOOMBERG       0123; Black Nicole, 2023, ABA J; Bradshaw Tim, 2023, FINANCIAL TIMES 0613; CALABRESI G, 1972, HARVARD LAW REV, V85, P1089, DOI 10.2307/1340059; Chui Michael, 2023, MCKINSEY DIGITAL JUN; Fisher William., 2001, NEW ESSAYS LEGAL POL; Gabriel A., FUENTES STANDING ORD; Ginsburg Jane C., 2001, CARDOZO ARTS ENT LJ, V19, P9; Ginsburg JaneC., 2012, CARDOZO ARTS ENT. L.J, V30, P73; github, About us; Gorman Robert A., 2001, COLUM JL ARTS, V25, P1; Harvard Law School, STAT US AI LARG LANG; help.openai, NAT OPENAI WHAT CHAE; Hughes Justin., 1998, Cardozo Arts Ent. L. J, V16, P81; Hughes Justin, 2007, UTAH LAW REV, V659, P668; Kadrey Richard, 2023, INDIVIDUAL REPRESENT; Kwall Roberta Rosenthal, 2010, SOUL CREATIVITY, P25; KWALL RR, 1985, VANDERBILT LAW REV, V38, P1; Mahari Robert, 2023, CONVERSATION    0615; Matulionyte Rita, 2023, Law, Innovation and Technology, P124, DOI 10.1080/17579961.2023.2184138; Merryman John Henry, 1976, HASTINGS LAW J, V27, P1037; Michael M., BAYLSON STANDING ORD; Nordemann JB, 2022, J INTELLET PROP LAW, V17, P973, DOI 10.1093/jiplp/jpac106; Park Sung Min, 2023, ARXIV; Paul Tremblay, 2023, MONA AWAD INDIVIDUAL; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; RADIN MJ, 1982, STANFORD LAW REV, V34, P957, DOI 10.2307/1228541; Rajan Mira T. Sundara, 2011, FORDHAM INTELL PROP, V21, P905; Rosati E, 2019, ASIA PAC LAW REV, V27, P198, DOI 10.1080/10192557.2019.1705525; Samuelson P, 2021, COMMUN ACM, V64, P20, DOI 10.1145/3486628; Sarah Silverman, 2023, CHRISTOPHER GOLDEN R; So Anthony Man-Cho, 2021, ARTIF INTELL, P11; Sobel Benjamin L.W., 2017, COLUM. J.L. & ARTS, V41, P45; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; turnitin, DESP COMM MISC TURN; txnd, MANDATORY CERTIFICAT; U.S. Copyright Office, 2019, Authors, Attribution, and Integrity: Examining Moral Rights in the United States, A Report of the Register of Copyrights; Weiser Benjamin., 2023, The New York Times; youtube, About Us	75	2	2	22	38	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1747-1532	1747-1540		J INTELLET PROP LAW	J. Intellect. Prop. Law Pract.	NOV 22	2023	18	11					796	807		10.1093/jiplp/jpad076	http://dx.doi.org/10.1093/jiplp/jpad076		SEP 2023	12	Law	Emerging Sources Citation Index (ESCI)	Government & Law	AH4C7		hybrid			2024-07-03	WOS:001067646900001
C	Roychoudhury, A		Chakrabarti, SK; Rastogi, A; Ghosh, S; Komondoor, R; Medicherla, RK; Kumar, L; Godboley, S		Roychoudhury, Abhik			Program Repair and Trusted Automatic Programming	PROCEEDINGS OF THE 17TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, ISEC 2024			English	Proceedings Paper	17th Innovations in Software Engineering Conference (ISEC)	FEB 22-24, 2024	IIITB Bangalore, Bangalore, INDIA	ACM India SIGSOFT Chapter, ACM In Cooperat, IIITB Bangalore, Ctr Technol Res & Innovat Digital Governance, TCS Res, Microsoft, IBM, ABB, Google, ISoft, ACM Chapter Conference	IIITB Bangalore	Program Analysis; Programming Language		Automated program repair can be seen as automated code generation at a micro-scale. The research done in automated program repair is thus particularly relevant today with the movement towards automatic programming using tools like Github Copilot. Since automatically generated code from natural language descriptions lack understanding of program semantics, using semantic analysis techniques to auto-correct or rectify the code is of value. In our work we have proposed the use of semantic or symbolic program analysis techniques to automatically rectify code. Effectively symbolic analysis is used to generalize tests into specifications of intent. These techniques can be employed on manually written code as well as automatically generated code. The techniques have been used for security vulnerability repair in software (thereby achieving autonomous cybersecurity) as well as for supporting intelligent tutoring systems. Apart from the practical value of such techniques, conceptually this gave a new direction to use symbolic reasoning. We use symbolic reasoning to derive a logical constraint which would capture what it means for the program to be "correct" thereby inferring specification about intended program behavior. We will conclude with a forward looking perspective on last mile repair of code generated from large language models, as well as acceptable evidences of correctness for such automatically generated code.	[Roychoudhury, Abhik] Natl Univ Singapore, Singapore, Singapore	National University of Singapore	Roychoudhury, A (corresponding author), Natl Univ Singapore, Singapore, Singapore.	abhik@comp.nus.edu.sg							0	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1767-3				2024									2	10.1145/3641399.3644113	http://dx.doi.org/10.1145/3641399.3644113			1	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6ID					2024-07-03	WOS:001174625700002
J	Fowler, T; Pullen, S; Birkett, L				Fowler, Thomas; Pullen, Simon; Birkett, Liam			Performance of ChatGPT and Bard on the official part 1 FRCOphth practice questions	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Early Access						Medical Education		BackgroundChat Generative Pre-trained Transformer (ChatGPT), a large language model by OpenAI, and Bard, Google's artificial intelligence (AI) chatbot, have been evaluated in various contexts. This study aims to assess these models' proficiency in the part 1 Fellowship of the Royal College of Ophthalmologists (FRCOphth) Multiple Choice Question (MCQ) examination, highlighting their potential in medical education.MethodsBoth models were tested on a sample question bank for the part 1 FRCOphth MCQ exam. Their performances were compared with historical human performance on the exam, focusing on the ability to comprehend, retain and apply information related to ophthalmology. We also tested it on the book 'MCQs for FRCOpth part 1', and assessed its performance across subjects.ResultsChatGPT demonstrated a strong performance, surpassing historical human pass marks and examination performance, while Bard underperformed. The comparison indicates the potential of certain AI models to match, and even exceed, human standards in such tasks.ConclusionThe results demonstrate the potential of AI models, such as ChatGPT, in processing and applying medical knowledge at a postgraduate level. However, performance varied among different models, highlighting the importance of appropriate AI selection. The study underlines the potential for AI applications in medical education and the necessity for further investigation into their strengths and limitations.	[Fowler, Thomas] Barking Havering & Redbridge Univ Hosp NHS Trust, Dept Med, London, England; [Pullen, Simon] Princess Alexandra Hosp, Dept Anaesthet, Harlow, England; [Birkett, Liam] Royal Free Hosp, Emergency Med, London, England; [Fowler, Thomas] Barking Havering & Redbridge Univ Hosp NHS Trust, London, England	Princess Alexandra Hospital NHS Trust; University of London; University College London; Royal Free London NHS Foundation Trust; UCL Medical School	Fowler, T (corresponding author), Barking Havering & Redbridge Univ Hosp NHS Trust, London, England.	thomas.fowler6@nhs.net		Birkett, Liam/0000-0002-0696-3794; Fowler, Thomas/0009-0003-9166-1954	We would like to acknowledge OpenAI for providing access to the ChatGPT model and the memorisation effects Levenshtein detector (MELD) algorithm, which were used in this study.	We would like to acknowledge OpenAI for providing access to the ChatGPT model and the memorisation effects Levenshtein detector (MELD) algorithm, which were used in this study.	We would like to acknowledge OpenAI for providing access to the ChatGPT model and the memorisation effects Levenshtein detector (MELD) algorithm, which were used in this study.	Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bommasani R., 2021, 2108.07258; Cai Louis Z, 2023, Am J Ophthalmol, V256, P201, DOI 10.1016/j.ajo.2023.07.030; De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6; google, ABOUT US; Google AI Blog, LaMDA: Open-domain conversational agents; Gov.uk, 2022, The regulation of artificial intelligence as a medical device; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P798, DOI 10.1001/jamaophthalmol.2023.2754; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; OpenAI, 2023, GPT-4: Scaling up language models; OpenAI, Introducing GPT-4; The Royal College of Ophthalmologists, 2016, FRCOPHTH SAMPL MCQ 1; The Royal College of Ophthalmologists, 2023, Part 1 Frcophth exam; Vaswani A, 2017, ADV NEUR IN, V30	16	6	6	14	19	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161	1468-2079		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	2023 NOV 6	2023										10.1136/bjo-2023-324091	http://dx.doi.org/10.1136/bjo-2023-324091		NOV 2023	5	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	X3OG6	37932006				2024-07-03	WOS:001097575500001
C	Malkadi, A; Tayeb, A; Haiduc, S			IEEE	Malkadi, Abdulkarim; Tayeb, Ahmad; Haiduc, Sonia			Improving code extraction from coding screencasts using a code-aware encoder-decoder model	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		code extraction; coding screencasts; code-aware model; optical character recognition		Accurate automatic code extraction from tutorial videos is crucial for software developers seeking to reuse the code contained in these videos. Current methods using optical character recognition (OCR) often yield inaccurate results due to code complexity and variations in screencast formats. To address this issue, we introduce CodeT5-OCRfix, an approach that leverages the pre-trained code-aware large language model CodeT5 to enhance code extraction accuracy by post-processing OCRed code. We first collect a large and diverse dataset of source code screenshots captured from more than 10K Java projects from GitHub. We then apply the most widely used OCR engine for the task of code extraction from videos, Tesseract, on these screenshots and collect the OCRed code along with the ground truth code extracted from the Java files. We built a training dataset of more than 585K pairs of OCRed and ground truth code pairs, which we then used to fine-tune CodeT5, obtaining our model CodeT5-OCRfix. An empirical evaluation on both screenshots and screencast frames shows that CodeT5-OCRfix outperforms baseline code extraction models and is also more time-efficient. Our approach therefore improves the state-of-the-art in code extraction techniques from screencasts and images.	[Malkadi, Abdulkarim; Tayeb, Ahmad; Haiduc, Sonia] Florida State Univ, Tallahassee, FL 32306 USA; [Malkadi, Abdulkarim] Jazan Univ, Jizan, Saudi Arabia; [Tayeb, Ahmad] King Abdulaziz Univ, Jeddah, Saudi Arabia	State University System of Florida; Florida State University; Jazan University; King Abdulaziz University	Malkadi, A (corresponding author), Florida State Univ, Tallahassee, FL 32306 USA.; Malkadi, A (corresponding author), Jazan Univ, Jizan, Saudi Arabia.	malkadi@cs.fsu.edu; tayeb@cs.fsu.edu; shaiduc@cs.fsu.edu						Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; Alahmadi M, 2018, PROMISE'18: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, P2, DOI 10.1145/3273934.3273935; Alahmadi Mohammad, 2020, Empirical Software Engineering, P1; Alahmadi MD, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10173175; Alahmadi Mohammad D, 2022, IEEE Transactions on Software Engineering.; Allamanis M, 2013, IEEE WORK CONF MIN S, P207, DOI 10.1109/MSR.2013.6624029; Bao L., 2018, IEEE Transactions on Software Engineering; Bao LF, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3392093; Bao LF, 2017, EMPIR SOFTW ENG, V22, P134, DOI 10.1007/s10664-015-9417-1; Bao LF, 2015, 2015 22ND INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), P399, DOI 10.1109/SANER.2015.7081850; Brandt J, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1589; Collard ML, 2013, PROC IEEE INT CONF S, P516, DOI 10.1109/ICSM.2013.85; Ellmann Mathias., 2017, P 3 ACM SIGSOFT INT, P1; Haefliger S, 2008, MANAGE SCI, V54, P180, DOI 10.1287/mnsc.1070.0748; Helnski Marcin, 2012, Report on the comparison of Tesseract and ABBYY FineReader OCR engines; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jain S, 2009, 16TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING (HIPC), PROCEEDINGS, P254, DOI 10.1109/HIPC.2009.5433202; Khandwala K, 2018, PROCEEDINGS OF THE FIFTH ANNUAL ACM CONFERENCE ON LEARNING AT SCALE (L@S'18), DOI 10.1145/3231644.3231652; Khormi A, 2020, IEEE WORK CONF MIN S, P65, DOI 10.1145/3379597.3387468; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Li Zhiyu, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1035, DOI 10.1145/3540250.3549081; Moslehi P, 2018, IEEE WORK CONF MIN S, P192, DOI 10.1145/3196398.3196439; Nguyen XP, 2022, Arxiv, DOI arXiv:2205.15544; Niu CA, 2023, Arxiv, DOI arXiv:2302.04026; Nong CY, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING EDUCATION AND TRAINING (ICSE-SEET), P95, DOI 10.1109/ICSE-SEET.2019.00018; Ott J, 2018, INT C PROGRAM COMPRE, P336, DOI 10.1145/3196321.3196359; Ott J, 2018, IEEE WORK CONF MIN S, P376, DOI 10.1145/3196398.3196402; Parra E, 2018, INT C PROGRAM COMPRE, P222, DOI 10.1145/3196321.3196351; Perianez-Pascual J, 2020, PROCEEDINGS OF THE 13TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON SOFTWARE LANGUAGE ENGINEERING, SLE 2020, P126, DOI 10.1145/3426425.3426937; Poché E, 2017, INT C PROGRAM COMPRE, P196, DOI 10.1109/ICPC.2017.26; Ponzanelli L, 2016, PROC INT CONF SOFTW, P261, DOI 10.1145/2884781.2884824; Ponzanelli L, 2016, 2016 IEEE/ACM 38TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING COMPANION (ICSE-C), P645, DOI 10.1145/2889160.2889172; Ponzanelli Luca, 2017, IEEE T SOFTWARE ENG; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Rousseeuw PJ, 2011, WIRES DATA MIN KNOWL, V1, P73, DOI 10.1002/widm.2; Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991; Smith Ray, 1994, HPL-94-113; Sulistya A, 2020, EMPIR SOFTW ENG, V25, P996, DOI 10.1007/s10664-019-09775-w; Tafti Ahmad P., 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P735, DOI 10.1007/978-3-319-50835-1_66; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Yang CR, 2022, EUR CON SFTWR MTNCE, P73, DOI 10.1109/SANER53432.2022.00021; Zhao DH, 2019, PROC INT CONF SOFTW, P350, DOI 10.1109/ICSE.2019.00049	42	1	1	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1492	1504		10.1109/ASE56229.2023.00184	http://dx.doi.org/10.1109/ASE56229.2023.00184			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200119
C	Yu, L; Lu, JY; Liu, XL; Yang, L; Zhang, FJ; Ma, JJ			IEEE	Yu, Lei; Lu, Junyi; Liu, Xianglong; Yang, Li; Zhang, Fengjun; Ma, Jiajia			PSCVFinder: A Prompt-Tuning Based Framework for Smart Contract Vulnerability Detection	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, ISSRE	Proceedings International Symposium on Software Reliability Engineering		English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART		Smart Contract; Blockchain; Vulnerability Detection; Prompt-Tuning		With the increasing security issues in the blockchain, smart contract vulnerability detection has gradually become the focus of research. Recently, many approaches have been proposed to detect smart contract vulnerabilities. Despite promising results, these approaches still have three drawbacks: 1) Symbolic execution and static analysis methods are constrained by predefined rules, which limits their adaptability to different vulnerabilities. 2) Most smart contract code contains abundant irrelevant information which is useless for vulnerability detection. 3) Pre-trained models fail to bridge the gap between pre-training and detecting smart contract vulnerabilities. To solve these problems, we propose an approach named PSCVFinder for detecting reentrancy vulnerability and timestamp dependency vulnerability, which are two severe vulnerabilities in smart contract. To better detect these vulnerabilities, we propose CSCV which is a smart contract slicing method to reduce the irrelevant code. Unlike existing approaches, our model first learns the representation of programming language through the pre-training model, then fully exploits the capacity of large language model with prompt-tuning to precisely detect smart contract vulnerability. We conduct experiments on real-world dataset and the results reflect that PSCVFinder scores 93.83% and 93.49% on two kinds of vulnerabilities in F1-score, surpassing the state-of-the-art baseline by 1.14% and 4.02%, respectively.	[Yu, Lei; Lu, Junyi; Liu, Xianglong; Yang, Li; Zhang, Fengjun; Ma, Jiajia] Chinese Acad Sci, Inst Software, Beijing, Peoples R China; [Yu, Lei; Lu, Junyi; Liu, Xianglong] Univ Chinese Acad Sci, Beijing, Peoples R China; [Zhang, Fengjun] Chinese Acad Sci, Inst Software, State Key Lab Comp Sci, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Software, CAS	Yang, L (corresponding author), Chinese Acad Sci, Inst Software, Beijing, Peoples R China.	yulei2022@iscas.ac.cn; lujunyi2022@iscas.ac.cn; liuxianglong21@otcaix.iscas.ac.cn; yangli2017@iscas.ac.cn; fengjun@iscas.ac.cn; majiajia@iscas.ac.cn			Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan [202016002000032]; Alliance of International Science Organizations	Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan; Alliance of International Science Organizations	This work was supported by Chinese Academy of Sciences-Dongguan Science and Technology Service Network Plan (No.202016002000032) and the Alliance of International Science Organizations (No.ANSO-CR-KP-2022-03).	Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Alharby M., 2017, COMPUTER SCI INFORM, DOI DOI 10.5121/CSIT.2017.71011; Bartoletti Massimo, 2017, Financial Cryptography and Data Security. FC 2017 International Workshops WAHC, BITCOIN, VOTING, WTSC, and TA. Revised Selected Papers: LNCS 10323, P494, DOI 10.1007/978-3-319-70278-0_31; Bergstra J., 2011, Adv. Neural Inf. Process. Syst., P2546; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai J, 2023, J SYST SOFTWARE, V195, DOI 10.1016/j.jss.2022.111550; Chung J., 2014, CORR; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Dhillon V., 2017, BLOCKCHAIN ENABLED A, P67, DOI [10.1007/978-1-4842-3081-7_6, DOI 10.1007/978-1-4842-3081-7_6]; Feist J, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P8, DOI 10.1109/WETSEB.2019.00008; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Ferreira JF, 2020, IEEE INT CONF AUTOM, P1349, DOI 10.1145/3324884.3415298; Gao Tianyu, 2020, arXiv; Gao ZP, 2019, PROC IEEE INT CONF S, P394, DOI 10.1109/ICSME.2019.00067; Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P933, DOI 10.1145/3180155.3180167; Gu Yuxian, 2021, arXiv; Guo D., 2020, arXiv; Han X, 2022, AI OPEN, V3, P182, DOI 10.1016/j.aiopen.2022.11.003; Hegedus P, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P35, DOI 10.1145/3194113.3194119; Hewa T, 2021, J NETW COMPUT APPL, V177, DOI 10.1016/j.jnca.2020.102857; Husain H., 2019, ARXIV190909436; Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073; Kanade A, 2020, PR MACH LEARN RES, V119; Kim S, 2021, PROC INT CONF SOFTW, P150, DOI 10.1109/ICSE43902.2021.00026; Kipf T. N., 2016, ICLR, DOI 10.48550/arXiv.1609.02907; LeClair A, 2020, INT C PROGRAM COMPRE, P184, DOI 10.1145/3387904.3389268; Lester B., 2021, arXiv; Li Lingwei, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1009, DOI 10.1145/3540250.3549099; Li Y, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360588; Li Z., 2022, arXiv; Liu Z., arXiv; Liu Z., 2021, IEEE T KNOWLEDGE DAT; Liu Z., 2022, arXiv; Luu L, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P254, DOI 10.1145/2976749.2978309; Mehar MI, 2019, J CASES INF TECHNOL, V21, P19, DOI 10.4018/JCIT.2019010102; Mossberg M, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1186, DOI 10.1109/ASE.2019.00133; Mueller B., 2017, Mythril-Reversing and bug hunting framework for the ethereum blockchain; OLeary R., 2017, CoindeskNov, V15; Palladino S., 2017, PARITY WALLET HACK E; Petroni F., 2020, arXiv; Qian P, 2020, IEEE ACCESS, V8, P19685, DOI 10.1109/ACCESS.2020.2969429; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Sak H, 2014, INTERSPEECH, P338; Schick T., arXiv; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Swan M., 2015, BLOCKCHAIN BLUEPRINT; Tann W. J.-W., 2018, arXiv; Tikhomirov S, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB), P9, DOI 10.1145/3194113.3194115; Torres CF, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P664, DOI 10.1145/3274694.3274737; Tsankov P, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P67, DOI 10.1145/3243734.3243780; Vaswani A, 2017, ADV NEUR IN, V30; Vujici D., 2018, 2018 17 INT S INF JA, P1; Wan Y, 2018, IEEE INT CONF AUTOM, P397, DOI 10.1145/3238147.3238206; Wang Chaozheng, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P382, DOI 10.1145/3540250.3549113; Wang Y., 2021, arXiv preprint arXiv:2109.00859; Wood G., 2014, Ethereum: A secure decentralised generalised transaction ledger, V151, P1; Wu HJ, 2021, PROC INT SYMP SOFTW, P378, DOI 10.1109/ISSRE52982.2021.00047; Yu L., 2023, 2023 INT JOINT C NEU, P1; Zhang Z, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3560428; Zhou X., 2023, arXiv; Zhu J., arXiv; Zhuang Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3283; Zou WQ, 2021, IEEE T SOFTWARE ENG, V47, P2084, DOI 10.1109/TSE.2019.2942301	65	2	2	7	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1071-9458		979-8-3503-1594-3	PROC INT SYMP SOFTW			2023							556	567		10.1109/ISSRE59848.2023.00030	http://dx.doi.org/10.1109/ISSRE59848.2023.00030			12	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KU					2024-07-03	WOS:001096886300049
C	Zhao, WX; Zhou, K; Zhang, BC; Gong, Z; Chen, ZP; Zhou, YH; Wen, JR; Sha, J; Wang, SJ; Liu, C; Hu, GP			ACM	Zhao, Wayne Xin; Zhou, Kun; Zhang, Beichen; Gong, Zheng; Chen, Zhipeng; Zhou, Yuanhang; Wen, Ji-Rong; Sha, Jing; Wang, Shijin; Liu, Cong; Hu, Guoping			JiuZhang 2.0: A Unified Chinese Pre-trained Language Model for Multi-task Mathematical Problem Solving	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD		Chinese pre-trained language model; Mathematical problem solving		Although pre-trained language models (PLMs) have recently advanced the research progress in mathematical reasoning, they are not specially designed as a capable multi-task solver, suffering from high cost for multi-task deployment (e.g., a model copy for a task) and inferior performance on complex mathematical problems in practical applications. To address these issues, we propose JiuZhang 2.0, a unified Chinese PLM specially for multi-task mathematical problem solving. Our idea is to maintain a moderate-sized model and employ the cross-task knowledge sharing to improve the model capacity in a multi-task setting. Specially, we construct a Mixture-of-Experts (MoE) architecture for modeling mathematical text, to capture the common mathematical knowledge across tasks. For optimizing the MoE architecture, we design multi-task continual pre-training and multi-task fine-tuning strategies for multi-task adaptation. These training strategies can effectively decompose the knowledge from the task data and establish the cross-task sharing via expert networks. To further improve the general capacity of solving different complex tasks, we leverage large language models (LLMs) as complementary models to iteratively refine the generated solution by our PLM, via in-context learning. Extensive experiments have demonstrated the effectiveness of our model.	[Zhao, Wayne Xin; Zhang, Beichen; Gong, Zheng; Chen, Zhipeng; Wen, Ji-Rong] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; [Zhou, Kun; Zhou, Yuanhang] Renmin Univ China, Sch Informat, Beijing, Peoples R China; [Sha, Jing; Wang, Shijin; Liu, Cong; Hu, Guoping] iFLYTEK Res, State Key Lab Cognit Intelligence, Hefei, Peoples R China; [Wang, Shijin] iFLYTEK AI Res Cent China, Wuhan, Peoples R China	Renmin University of China; Renmin University of China	Zhao, WX (corresponding author), Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China.	batmanfly@gmail.com; francis_kun_zhou@163.com; zhangbeichen724@gmail.com; gongzheng0109@ruc.edu.cn; zhipeng_chen@ruc.edu.cn; sdzyh002@gmail.com; jrwen@ruc.edu.cn; jingsha@iflytek.com; sjwang3@iflytek.com; congliu2@iflytek.com; gphu@iflytek.com	guo, yi/KHC-4669-2024; Chen, Zhipeng/AAR-3039-2021; su, lin/KHC-5034-2024; Xia, Lianghao/IWV-0954-2023	Zhou, Kun/0000-0003-0650-9521	National Natural Science Foundation of China [62222215]; Beijing Natural Science Foundation [4222027]; Beijing Outstanding Young Scientist Program [BJJWZYJH012019100020098]; Outstanding Innovative Talents Cultivation Funded Programs 2021 of Renmin University of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation); Beijing Outstanding Young Scientist Program; Outstanding Innovative Talents Cultivation Funded Programs 2021 of Renmin University of China	This work was partially supported by National Natural Science Foundation of China under Grant No. 62222215, Beijing Natural Science Foundation under Grant No. 4222027, and Beijing Outstanding Young Scientist Program under Grant No. BJJWZYJH012019100020098. And this work is also partially supported by the Outstanding Innovative Talents Cultivation Funded Programs 2021 of Renmin University of China. Xin Zhao is the corresponding author.	Aghajanyan Armen, 2021, ABS210111038 ARXIV; [Anonymous], 2019 C N AM CHAPT; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Banerjee A, 2023, COMM COM INF SC, V1704, P406, DOI 10.1007/978-3-031-23599-3_31; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen Wenhu, 2022, ARXIV221112588; Chiang Ting-Rui, 2019, NAACL; Cobbe K., 2021, ARXIV211014168; Cui Yiming, 2021, TASLP; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong Li, 2019, ADV NEURAL INFORM PR; Drori Iddo, 2021, ARXIV211215594; Fedus William, 2021, ARXIV210103961; Fu Yao, 2022, ABS221000720 ARXIV; Gao Luyu, 2022, ARXIV221110435; Gao Tianyu, 2021, ABS210408821 ARXIV; Gong Z, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5923; Gupta Shashank, 2022, ABS220407689 ARXIV; Gururangan S., 2020, P 58 ANN M ASS COMPU, P1, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]; Hendrycks Dan, 2021, ARXIV210303874; Hendrycks Dan, 2021, ABS210303874 ARXIV; Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79; Kim Y, 2014, ARXIV14085882, DOI 10.3115/v1/D14-1181; Kojima Takeshi, 2022, ABS220511916 ARXIV; Kudugunta Sneha, 2021, C EMP METH LANG PROC; Lai SW, 2015, AAAI CONF ARTIF INTE, P2267; Lan Yihuai, 2021, ARXIV210900799; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Lewkowycz Aitor, 2022, ABS220614858 ARXIV; Li Junyi., 2019, ACL; Li Yifei, 2022, ARXIV220602336; Liu Jiachang, 2021, WORKSH KNOWL EXTR IN; Liu Xiaodong, 2019, ANN M ASS COMP LING; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Lu Pan, 2022, ABS221210535 ARXIV; Meadows Jordan, 2022, ABS220515231 ARXIV; Mishra Swaroop, 2022, ABS221017517 ARXIV; Peng Shuai, 2021, ARXIV210500377; Polu Stanislas, 2020, ARXIV200903393; Ponti E., 2022, ABS220213914 ARXIV; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Shao Yunfan, 2021, ARXIV210905729; Shazeer Noam M., 2017, ABS170106538 ARXIV; Shi S., 2015, P 2015 C EMPIRICAL M, P1132, DOI DOI 10.18653/V1/D15-1135; Sundaram Sowmya S., 2022, ABS220515683 ARXIV; Vaswani A, 2017, ADV NEUR IN, V30; Wang Xuezhi, 2022, arXiv:2203.11171; Wei Jason, 2022, ABS220111903 ARXIV; Ye Qinyuan, 2022, Eliciting and understanding cross-task skills with task-level mixture-of-experts; Zanibbi R, 2012, INT J DOC ANAL RECOG, V15, P331, DOI 10.1007/s10032-011-0174-4; Zhang Zhuosheng, 2022, ABS221003493 ARXIV; Zhang Zhuosheng, 2021, ARXIV211006696; Zhao WX, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4571, DOI 10.1145/3534678.3539131; Zhao Wayne Xin, 2023, arXiv; Zhong W, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2541, DOI 10.1145/3404835.3462794; Zhou Denny, 2022, arXiv:2205.10625; Zhu Xinyu, 2022, ABS221016257 ARXIV; Zoph Barret, 2022, 2202.08906	59	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5660	5672		10.1145/3580305.3599850	http://dx.doi.org/10.1145/3580305.3599850			13	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ		Green Submitted			2024-07-03	WOS:001118896305063
J	Guillen-Grima, F; Guillen-Aguinaga, S; Guillen-Aguinaga, L; Alas-Brun, R; Onambele, L; Ortega, W; Montejo, R; Aguinaga-Ontoso, E; Barach, P; Aguinaga-Ontoso, I				Guillen-Grima, Francisco; Guillen-Aguinaga, Sara; Guillen-Aguinaga, Laura; Alas-Brun, Rosa; Onambele, Luc; Ortega, Wilfrido; Montejo, Rocio; Aguinaga-Ontoso, Enrique; Barach, Paul; Aguinaga-Ontoso, Ines			Evaluating the Efficacy of ChatGPT in Navigating the Spanish Medical Residency Entrance Examination (MIR): Promising Horizons for AI in Clinical Medicine	CLINICS AND PRACTICE			English	Article						machine learning; artificial intelligence; ChatGPT; GPT-3.5; GPT-4; medical education; quality of care; patient safety; image; large language model	REFERENCING HALLUCINATIONS LESSONS; ARTIFICIAL-INTELLIGENCE; BIPOLAR DISORDER; CARDIOVASCULAR SAFETY; PREGNANCY; ALGORITHM; DIAGNOSIS; REVIEWERS; TEACHERS; EDITORS	The rapid progress in artificial intelligence, machine learning, and natural language processing has led to increasingly sophisticated large language models (LLMs) for use in healthcare. This study assesses the performance of two LLMs, the GPT-3.5 and GPT-4 models, in passing the MIR medical examination for access to medical specialist training in Spain. Our objectives included gauging the model's overall performance, analyzing discrepancies across different medical specialties, discerning between theoretical and practical questions, estimating error proportions, and assessing the hypothetical severity of errors committed by a physician. Material and methods: We studied the 2022 Spanish MIR examination results after excluding those questions requiring image evaluations or having acknowledged errors. The remaining 182 questions were presented to the LLM GPT-4 and GPT-3.5 in Spanish and English. Logistic regression models analyzed the relationships between question length, sequence, and performance. We also analyzed the 23 questions with images, using GPT-4's new image analysis capability. Results: GPT-4 outperformed GPT-3.5, scoring 86.81% in Spanish (p < 0.001). English translations had a slightly enhanced performance. GPT-4 scored 26.1% of the questions with images in English. The results were worse when the questions were in Spanish, 13.0%, although the differences were not statistically significant (p = 0.250). Among medical specialties, GPT-4 achieved a 100% correct response rate in several areas, and the Pharmacology, Critical Care, and Infectious Diseases specialties showed lower performance. The error analysis revealed that while a 13.2% error rate existed, the gravest categories, such as "error requiring intervention to sustain life" and "error resulting in death", had a 0% rate. Conclusions: GPT-4 performs robustly on the Spanish MIR examination, with varying capabilities to discriminate knowledge across specialties. While the model's high success rate is commendable, understanding the error severity is critical, especially when considering AI's potential role in real-world medical practice and its implications for patient safety.	[Guillen-Grima, Francisco; Guillen-Aguinaga, Sara; Guillen-Aguinaga, Laura; Alas-Brun, Rosa; Aguinaga-Ontoso, Ines] Univ Publ Navarra, Dept Hlth Sci, Pamplona 31008, Spain; [Guillen-Grima, Francisco; Aguinaga-Ontoso, Ines] Healthcare Res Inst Navarra IdiSNA, Pamplona 31008, Spain; [Guillen-Grima, Francisco] Clin Univ Navarra, Dept Prevent Med, Pamplona 31008, Spain; [Guillen-Grima, Francisco] Inst Hlth Carlos III, CIBER Epidemiol & Publ Hlth CIBERESP, Madrid 46980, Spain; [Guillen-Aguinaga, Laura] Kystad Helse & Velferdssenter, Dept Nursing, N-7026 Trondheim, Norway; [Onambele, Luc] Catholic Univ Cent Africa, Sch Hlth Sci, Yaounde 1100, Cameroon; [Ortega, Wilfrido] Univ Alcala De Henares, Dept Surg Med & Social Sci, Alcala De Henares 28871, Spain; [Montejo, Rocio] Univ Gothenburg, Inst Clin Sci, Dept Obstet & Gynecol, S-41346 Gothenburg, Sweden; [Montejo, Rocio] Sahlgrens Univ Hosp, Dept Obstet & Gynecol, S-41346 Gothenburg, Sweden; [Aguinaga-Ontoso, Enrique] Univ Murcia, Dept Sociosanit Sci, Murcia 30100, Spain; [Barach, Paul] Jefferson Coll Populat Hlth, Philadelphia, PA 19107 USA; [Barach, Paul] Thomas Jefferson Univ, Sch Med, Philadelphia, PA 19107 USA; [Barach, Paul] Sigmund Freud Univ, Interdisciplinary Res Inst Hlth Law & Sci, A-1020 Vienna, Austria; [Barach, Paul] Imperial Coll, Dept Surg, London SW7 2AZ, England	Universidad Publica de Navarra; University of Navarra; CIBER - Centro de Investigacion Biomedica en Red; CIBERESP; Universidad de Alcala; University of Gothenburg; Sahlgrenska University Hospital; University of Murcia; Jefferson University; Imperial College London	Guillen-Grima, F; Aguinaga-Ontoso, I (corresponding author), Univ Publ Navarra, Dept Hlth Sci, Pamplona 31008, Spain.; Guillen-Grima, F; Aguinaga-Ontoso, I (corresponding author), Healthcare Res Inst Navarra IdiSNA, Pamplona 31008, Spain.; Guillen-Grima, F (corresponding author), Clin Univ Navarra, Dept Prevent Med, Pamplona 31008, Spain.; Guillen-Grima, F (corresponding author), Inst Hlth Carlos III, CIBER Epidemiol & Publ Hlth CIBERESP, Madrid 46980, Spain.	f.guillen.grima@unavarra.es; sguillen.4@alumni.unav.es; guillen.124514@e.unavarra.es; rosamaria.alas@unavarra.es; onambele.luc@ess-ucac.org; wilfrido.ortega@edu.uah.es; rocio.montejo.rodriguez@gu.se; aguinaga@um.es; paul.barach@jefferson.edu; ines.aguinaga@unavarra.es	Guillen-Aguinaga, Sara/AAS-9683-2021; Aguinaga-Ontoso, Ines/AAW-6947-2021; Guillen-Grima, Francisco/H-3359-2012; Barach, Paul/B-9915-2016	Guillen-Aguinaga, Sara/0000-0003-4748-9520; Aguinaga-Ontoso, Ines/0000-0002-2882-930X; Guillen-Grima, Francisco/0000-0001-9749-8076; ALAS-BRUN, ROSA MARIA/0000-0003-3450-9342; Barach, Paul/0000-0002-7906-698X; Aguinaga-Ontoso, Enrique/0000-0002-7994-3559				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Albertini Elizabeth, 2019, Focus (Am Psychiatr Publ), V17, P249, DOI 10.1176/appi.focus.20190007; Alowais SA, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04698-z; Angiolillo DJ, 2017, AM J CARDIOVASC DRUG, V17, P97, DOI 10.1007/s40256-016-0200-5; [Anonymous], 2022, Boletin Oficial del Estado, V211; [Anonymous], 2017, Boletin Of. De La Comunidad De Madrid, V16, P8; [Anonymous], 2022, Ley 3/2022, de 24 de Febrero, de Convivencia UniversitariaBoletin Oficial del Estado, P1; [Anonymous], 2023, ChatGPT (September 25 Version) [Large language model]; Arslan S, 2023, ANN BIOMED ENG, V51, P1887, DOI 10.1007/s10439-023-03227-9; ASHM, HIV Management Guidelines; BAXTER GM, 1991, BRIT J RADIOL, V64, P777, DOI 10.1259/0007-1285-64-765-777; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Burande AP, 2023, EUR J OBSTET GYN R B, V280, P40, DOI 10.1016/j.ejogrb.2022.10.028; Busnatu S, 2022, J CLIN MED, V11, DOI 10.3390/jcm11082265; Cao Y, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061895; Carrasco JP., 2023, Rev Esp Edu Med, V4, P12, DOI DOI 10.6018/EDUMED.556511; Chakraborty U, 2021, DIABETES METAB SYND, V15, DOI 10.1016/j.dsx.2021.102326; Chan FKL, 2017, LANCET, V389, P2375, DOI 10.1016/S0140-6736(17)30981-9; Chen TC, 2023, WORLD NEUROSURG, V179, pE342, DOI 10.1016/j.wneu.2023.08.088; Cheung K, 2021, J APPL PHYSIOL, V130, P1479, DOI 10.1152/japplphysiol.00019.2021; Coakley S, 2022, RADIOGRAPHY, V28, P943, DOI 10.1016/j.radi.2022.06.020; Copeland-Halperin LR, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005226; Costa C, 2012, PROC TECH, V5, P334, DOI 10.1016/j.protcy.2012.09.037; Da Soh Z, 2024, PROG RETIN EYE RES, V98, DOI 10.1016/j.preteyeres.2023.101227; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Panfilis L, 2023, BMJ SUPPORT PALLIAT, V13, P183, DOI 10.1136/bmjspcare-2021-002948; Dean AG, 2013, OpenEpi: Open-Source Epidemiologic Statistics for Public Health; DeHaan EJ M., 2022, PEP to Prevent HIV Infection [Internet]; dos Santos FLC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45679-x; Dunn C, 2023, J AM ACAD DERMATOL, V89, P388, DOI 10.1016/j.jaad.2023.04.005; Eberhard M, 2020, CARDIOVASC DIAGN THE, V10, P820, DOI 10.21037/cdt-20-381; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Epstein RA, 2015, DRUG HEALTHC PATIENT, V7, P7, DOI 10.2147/DHPS.S50556; Epstein RH, 2023, JMIR MED EDUC, V9, DOI 10.2196/48305; Examen MIR, 2023, (sic)Que Preguntas Podrian ser Impugnables?; Food and Drug Administration (FDA), Artificial intelligence and machine learning (AI/ML)-enabled medical devices; Frazier P, 1987, N C Med J, V48, P270; Frosolini A, 2023, ANN BIOMED ENG, V51, P2120, DOI 10.1007/s10439-023-03248-4; Galvan A., Numero 1 del Examen MIR 2023, Elige Dermatologia Para Realizar su Residencia; Gamarra M, 2023, Resultados de Los Extracomunitarios en el MIR; Gawrieh S, 2020, ANN DIAGN PATHOL, V47, DOI 10.1016/j.anndiagpath.2020.151518; Gentile S, 2006, BIPOLAR DISORD, V8, P207, DOI 10.1111/j.1399-5618.2006.00295.x; Giles TD, 2008, J CARD FAIL, V14, P445, DOI 10.1016/j.cardfail.2008.02.007; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goktas P, 2023, J ALLER CL IMM-PRACT, V11, P2697, DOI 10.1016/j.jaip.2023.05.042; Goldberg SB, 2020, J COUNS PSYCHOL, V67, P438, DOI 10.1037/cou0000382; Gorbea-Portal S, 2018, GAC MED MEX, V154, P335, DOI 10.24875/GMM.18003293; Gordon A, 2019, CRIT CARE NURS Q, V42, P371, DOI 10.1097/CNQ.0000000000000277; Grech V, 2023, SAUDI J ANAESTH, V17, P401, DOI 10.4103/sja.sja_344_23; Grewal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40135; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Harrington L, 2023, AACN ADV CRIT CARE, V34, P280, DOI 10.4037/aacnacc2023129; Hasikin K, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1227948; He N, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231181922; Henry KE, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00597-7; Ho E, 2014, HEART LUNG CIRC, V23, P242, DOI 10.1016/j.hlc.2013.08.001; Huo WW, 2023, INT J MED INFORM, V175, DOI 10.1016/j.ijmedinf.2023.105073; Iftikhar S., 2022, Int. J. Innov. Sci. Technol, V3, P223, DOI [10.33411/IJIST/2021030518, DOI 10.33411/IJIST/2021030518]; Ismail AMA, 2023, ANN BIOMED ENG, V51, P2634, DOI 10.1007/s10439-023-03279-x; Jin B, 2018, EPILEPSIA, V59, P982, DOI 10.1111/epi.14064; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Jost E, 2023, J CLIN MED, V12, DOI 10.3390/jcm12216833; Jung LB, 2023, DTSCH ARZTEBL INT, V120, P373, DOI 10.3238/arztebl.m2023.0113; Juurlink DN, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b2942; Kao YS, 2024, ANN BIOMED ENG, V52, P455, DOI 10.1007/s10439-023-03308-9; Kesieme E, 2011, J BLOOD MED, V2, P59, DOI 10.2147/JBM.S19009; Kim YW, 2019, MINIM INVASIV THER, V28, P69, DOI 10.1080/13645706.2019.1596956; Kleebayoon A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231189760; Kleebayoon A, 2023, J NEURO-ONCOL, V163, P727, DOI 10.1007/s11060-023-04375-7; Koubaa A., 2023, PREPRINT, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Krishnan G, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1227091; Kristiansen TB, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.862095; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Levin G, 2024, BJOG-INT J OBSTET GY, V131, P378, DOI 10.1111/1471-0528.17641; Lindblad B, 1988, Eur J Vasc Surg, V2, P161, DOI 10.1016/S0950-821X(88)80069-0; Lueck Tyler, 2023, Neoreviews, V24, P1, DOI 10.1542/neo.24-1-e1; Makimoto H, 2024, HYPERTENS RES, V47, P685, DOI 10.1038/s41440-023-01469-7; Markov T., 2022, Proc. AAAI Conf. Artif. Intell, V37, P15009, DOI [https://doi.org/10.48550/ARXIV.2208.03274, DOI 10.1609/AAAI.V37I12.26752]; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Meissner Mark H, 2002, Rev Cardiovasc Med, V3 Suppl 2, pS76; Ministerio de Sanidad, 2022, Pruebas Selectivas 2021, Cuaderno de Examen, Medicina-Version 0; Murphy DJ, 2020, BJOG-INT J OBSTET GY, V127, pE70, DOI 10.1111/1471-0528.16092; National Institute for Health and Care Excellence Scenario, Post-Exposure Prophylaxis for HIV; NCC-MERP National Coordinating Council for Medication Error Reporting and Prevention, Taxonomy of Medication Errors; Nikolov A, 2009, Akush Ginekol (Sofiia), V48, P3; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Oancea A, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101861; OpenAI, How should AI systems behave, and who should decide?; Panayides AS, 2020, IEEE J BIOMED HEALTH, V24, P1837, DOI 10.1109/JBHI.2020.2991043; Pantanowitz L, 2020, LANCET DIGIT HEALTH, V2, pE407, DOI 10.1016/S2589-7500(20)30159-X; Pepine CJ, 2017, CLIN CARDIOL, V40, P1352, DOI 10.1002/clc.22814; Pérez-Sanz F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21061993; Perlis RH, 2023, medRxiv, DOI [10.1101/2023.04.14.23288595, 10.1101/2023.04.14.23288595, DOI 10.1101/2023.04.14.23288595]; Rådholm K, 2018, CIRCULATION, V138, P458, DOI 10.1161/CIRCULATIONAHA.118.034222; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Rava RA, 2021, WORLD NEUROSURG, V155, pE748, DOI 10.1016/j.wneu.2021.08.136; Rawashdeh B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42150; Raza Muhammad Ahmer, 2022, Innov Pharm, V13, DOI 10.24926/iip.v13i2.4839; Rodriguez B, 2022, CURR TREAT OPTION NE, V24, P173, DOI 10.1007/s11940-022-00714-7; Sagué-Vilavella M, 2022, ARCH WOMEN MENT HLTH, V25, P729, DOI 10.1007/s00737-022-01234-8; Saillard C, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-42453-6; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scarpignato C, 2015, BMC MED, V13, DOI 10.1186/s12916-015-0285-8; Schjerning AM, 2020, NAT REV CARDIOL, V17, P574, DOI 10.1038/s41569-020-0366-z; Scrandis DA, 2017, J MIDWIFERY WOM HEAL, V62, P673, DOI 10.1111/jmwh.12645; Sezgin E, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231186520; Shah SIH, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120048; Shamszare H, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11162308; Shavit L, 2018, CLIN NEPHROL, V90, P87, DOI 10.5414/CN109363; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Shepherd S, 2017, NEUROHOSPITALIST, V7, P41, DOI 10.1177/1941874416663279; Singh S, 2022, INDIAN J PHARMACOL, V54, P443, DOI 10.4103/ijp.ijp_407_21; Siriborvornratanakul T., 2023, Advanced Artificial Intelligence Methods for Medical Applications, P329, DOI [10.1007/978-3-031-35748-0_24, DOI 10.1007/978-3-031-35748-0_24]; Sloan M, 2023, INVESTIG CLIN UROL, V64, P588, DOI 10.4111/icu.20230170; Sociedad Espanola de Ginecologia y Obstetricia, 2002, Protocolos de Procedimientos Diagnosticos y Terapeuticos en Obstetricia; Sohail SS, 2024, ANN BIOMED ENG, V52, P1131, DOI 10.1007/s10439-023-03335-6; Sorace L, 2024, RADIOGRAPHY, V30, P107, DOI 10.1016/j.radi.2023.10.014; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Száva-Kováts E, 2002, J AM SOC INF SCI TEC, V53, P1098, DOI 10.1002/asi.10105; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tanana MJ, 2021, BEHAV RES METHODS, V53, P2069, DOI 10.3758/s13428-020-01531-z; Tay THC, 2023, MED TEACH, V45, P1439, DOI 10.1080/0142159X.2023.2245129; Tison GH, 2018, JAMA CARDIOL, V3, P409, DOI 10.1001/jamacardio.2018.0136; Uguz F, 2020, ASIAN J PSYCHIATR, V52, DOI 10.1016/j.ajp.2020.102145; Uguz F, 2017, J MATERN-FETAL NEO M, V30, P2569, DOI 10.1080/14767058.2016.1256991; Universidad Publica de Navarra, 2020, Normativa Reguladora de los Procesos de Evaluacion En la Universidad Publica de Navarra (Texto Consolidado); Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Webster DP, 2015, HIV MED, V16, P73, DOI 10.1111/hiv.12187; Wiens J., 2023, Stat News; Xv Y, 2023, WORLD J UROL, V41, P2569, DOI 10.1007/s00345-023-04539-0; Yang LL, 2022, ALEX ENG J, V61, P1852, DOI 10.1016/j.aej.2021.07.007; Young AL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05892-0; Yousefi S, 2023, J OPHTHAL VIS RES, V18, P97, DOI 10.18502/jovr.v18i1.12730; Zerangian N, 2023, HEALTH SCI REP-US, V6, DOI 10.1002/hsr2.1085; Zhou J, 2020, GASTROINTEST ENDOSC, V91, P428, DOI 10.1016/j.gie.2019.11.026; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589	137	6	6	20	20	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2039-7275	2039-7283		CLINICS PRACT	Clin. Pract.	DEC	2023	13	6					1460	1487		10.3390/clinpract13060130	http://dx.doi.org/10.3390/clinpract13060130			28	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	DM2D2	37987431	gold, Green Published			2024-07-03	WOS:001132385500001
J	Hosokawa, T; Jatowt, A; Sugiyama, K				Hosokawa, Taishi; Jatowt, Adam; Sugiyama, Kazunari			Temporal validity reassessment: commonsense reasoning about information obsoleteness	DISCOVER COMPUTING			English	Article						Temporal validity; Temporal commonsense reasoning; Natural language inference		It is useful for machines to know whether text information remains valid or not for various applications including text comprehension, story understanding, temporal information retrieval, and user state tracking on microblogs as well as via chatbot conversations. This kind of inference is still difficult for current models, including also large language models, as it requires temporal commonsense knowledge and reasoning. We approach in this paper the task of Temporal Validity Reassessment, inspired by traditional natural language reasoning to determine the updates of the temporal validity of text content. The task requires judgment whether actions expressed in a sentence are still ongoing or rather completed, hence, whether the sentence still remains valid or has become obsolete, given the presence of context in the form of a supplementary content such as a follow-up sentence. We first construct our own dataset for this task and train several machine learning models. Then we propose an effective method for learning information from an external knowledge base that gives information regarding temporal commonsense knowledge. Using our prepared dataset, we introduce a machine learning model that incorporates the information from the knowledge base and demonstrate that incorporating external knowledge generally improves the results. We also experiment with different embedding types to represent temporal commonsense knowledge as well as with data augmentation methods to increase the size of our dataset.	[Hosokawa, Taishi] Kyoto Univ, Dept Social Informat, Yoshida Honmachi,Sakyo Ku, Kyoto 6068501, Japan; [Jatowt, Adam] Univ Innsbruck, Dept Comp Sci, Innrain 15, A-6020 Innsbruck, Tirol, Austria; [Sugiyama, Kazunari] Osaka Seikei Univ, Fac Data Sci, 1-3-7 Aikawa,Higashiyodogawa ku, Osaka, Osaka 5330007, Japan	Kyoto University; University of Innsbruck	Jatowt, A (corresponding author), Univ Innsbruck, Dept Comp Sci, Innrain 15, A-6020 Innsbruck, Tirol, Austria.	taishihosokawa@yahoo.co.jp; jatowt@gmail.com; sugiyama-k@g.osaka-seikei.ac.jp			University of Innsbruck and Medical University of Innsbruck	University of Innsbruck and Medical University of Innsbruck	No Statement Available	Abe S, 2018, IEEE INT C SEMANT CO, P219, DOI 10.1109/ICSC.2018.00038; Abel F, 2011, LECT NOTES COMPUT SC, V6787, P1, DOI 10.1007/978-3-642-22362-4_1; Acharya A, 2023, P 2023 C EMP METH NA, P6750; Allein L, 2021, J WEB SEMANT, V71, DOI 10.1016/j.websem.2021.100663; Almquist Axel, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P86, DOI 10.1007/978-3-030-15712-8_6; [Anonymous], 2017, SHORT PAPERS; [Anonymous], 2003, P HLT NAACL 2003 WOR; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Campos R, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2619088; Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152; Chen W, 2021, A dataset for answering time-sensitive questions; Chen Y, 2018, P 22 C COMP NAT LANG, P562, DOI [10.18653/v1/K18-1054, DOI 10.18653/V1/K18-1054]; Cheng F, 2020, arXiv; Chicco D, 2021, METHODS MOL BIOL, V2190, P73, DOI 10.1007/978-1-0716-0826-5_3; Cole JR, 2023, Salient span masking for temporal understanding; Conneau A., 2017, P 2017 C EMP METH NA, P670, DOI DOI 10.18653/V1/D17-1070; Crawshaw M., 2020, arXiv; Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177; Demszky D, 2018, Arxiv, DOI arXiv:1809.02922; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhingra B, 2022, T ASSOC COMPUT LING, V10, P257, DOI 10.1162/tacl_a_00459; Fillmore CJ., 2010, OXFORD HDB LINGUISTI, P313, DOI DOI 10.1093/OXFORDHB/9780199544004.013.0013; Fyodorov Y., 2000, P 2 WORKSH INF COMP, P1; Gao QZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P934; Glockner M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P650; Han RJ, 2019, Arxiv, DOI arXiv:1904.11942; Harabagiu S, 2005, P AAAI 2005 WORKSH I, P27; Hosokawa T, 2023, LECT NOTES COMPUT SC, V13980, P441, DOI 10.1007/978-3-031-28244-7_28; Hwang JD, 2021, AAAI CONF ARTIF INTE, V35, P6384; Jang J, 2023, TemporalWiki: a lifelong benchmark for training and evaluating ever-evolving language models; Jatowt A, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P895, DOI 10.1145/3487553.3526023; Jatowt A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P484, DOI 10.1145/2736277.2741632; Kanazawa K., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P278, DOI 10.1109/WI-IAT.2011.250; Kanhabua N, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1235, DOI 10.1145/2911451.2914805; Kapanipathi P, 2020, AAAI CONF ARTIF INTE, V34, P8074; Kawai H, 2010, P 4 INT C UN INF MAN, P1; Khot T, 2018, AAAI CONF ARTIF INTE, P5189; Kimura M, 2021, P STUD RES WORKSH AS, P78; Koupaee M, 2018, Arxiv, DOI arXiv:1810.09305; Levesque E., 2012, 13 INT C PRINCIPLES, P552; Li PF, 2019, IEEE T KNOWL DATA EN, V31, P1150, DOI 10.1109/TKDE.2018.2852764; Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu Q, 2017, P AAAI 2017 SPRING S, P315; Luo ZY, 2016, FIFTEENTH INTERNATIONAL CONFERENCE ON THE PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING, P421; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Mihaylov T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P821; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Minard A-L, 2015, P 9 INT WORKSH SEM E, P778, DOI DOI 10.18653/V1/S15-2132; Mnasri M, 2019, Arxiv, DOI arXiv:1903.09025; Mostafazadeh Nasrin, 2016, P 2016 C N AM CHAPTE, P839, DOI [10.18653/v1/N16-1098, DOI 10.18653/V1/N16-1098]; Ng N, 2019, FOURTH CONFERENCE ON MACHINE TRANSLATION (WMT 2019), P314; Ning Q, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1318; Paszke A, 2019, ADV NEUR IN, V32; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43; Qin Lianhui., 2021, P 59 ANN M ASS COMP, V1, P7066, DOI [10.18653/v1/2021.acl-long.549, DOI 10.18653/V1/2021.ACL-LONG.549]; Rashkin H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P463; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Santana B, 2023, ARTIF INTELL REV, V56, P8393, DOI 10.1007/s10462-022-10338-7; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Schuler K. K., 2005, VerbNet: A Broad-Coverage, Comprehensive Verb Lexicon; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Srivastava A., 2023, Beyond the imitation game: Quantifying and extrapolating the capabilities of language models; Storks S, 2020, Arxiv, DOI [arXiv:1904.01172, DOI 10.48550/ARXIV.1904.01172]; Storks Shane, 2019, arXiv, P1; Sun ZJ, 2020, Arxiv, DOI [arXiv:2012.01786, 10.48550/arXiv.2012.01786]; Takemura H, 2012, P 21 ACM INT C INF K, P2367; Tamborrino A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3878; Torfi A, 2021, Arxiv, DOI [arXiv:2003.01200, 10.48550/arXiv.2003.01200]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trouillon T, 2016, PR MACH LEARN RES, V48; Vashishtha S, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4070; Vashishtha S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2906; Vaswani A, 2017, ADV NEUR IN, V30; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wang J, 2023, BiTimeBERT: extending pre-trained language representations with bi-temporal information; Wang XY, 2019, AAAI CONF ARTIF INTE, P7208; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Wenzel G, 2023, arXiv, DOI [10.48550/ARXIV.2308.00002, DOI 10.48550/ARXIV.2308.00002]; Wenzel G, 2024, arXiv, DOI [10.48550/ARXIV.2401.00779, DOI 10.48550/ARXIV.2401.00779]; White RW, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P636, DOI 10.1145/3289600.3290997; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Xiang W, 2019, IEEE ACCESS, V7, P173111, DOI 10.1109/ACCESS.2019.2956831; Yamamoto Y, 2008, LECT NOTES COMPUT SC, V5175, P206, DOI 10.1007/978-3-540-85481-4_17; Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535; Young P., 2014, P TACL, V2, P67, DOI DOI 10.1162/TACL_A_00166; Zhang L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4630; Zhang TL, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2608, DOI 10.1145/3459637.3482436; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhou B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3363; Zhou Ben, 2020, P ACL, P7579, DOI DOI 10.18653/V1/2020.ACL-MAIN.678	94	1	1	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	2948-2984	2948-2992		DISCOV COMPUT	Discov. Comput.	MAY 6	2024	27	1							4	10.1007/s10791-024-09433-w	http://dx.doi.org/10.1007/s10791-024-09433-w			20	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PN5J3		hybrid			2024-07-03	WOS:001214767500002
J	Yang, MH; Zhang, SC; Zheng, ZH; Zhang, PF; Liang, Y; Tang, SJ				Yang, Minghao; Zhang, Shichen; Zheng, Zhihang; Zhang, Pengfei; Liang, Yan; Tang, Shaojun			Employing bimodal representations to predict DNA bendability within a self-supervised pre-trained framework	NUCLEIC ACIDS RESEARCH			English	Article							SEQUENCE	The bendability of genomic DNA, which measures the DNA looping rate, is crucial for numerous biological processes of DNA. Recently, an advanced high-throughput technique known as 'loop-seq' has made it possible to measure the inherent cyclizability of DNA fragments. However, quantifying the bendability of large-scale DNA is costly, laborious, and time-consuming. To close the gap between rapidly evolving large language models and expanding genomic sequence information, and to elucidate the DNA bendability's impact on critical regulatory sequence motifs such as super-enhancers in the human genome, we introduce an innovative computational model, named MIXBend, to forecast the DNA bendability utilizing both nucleotide sequences and physicochemical properties. In MIXBend, a pre-trained language model DNABERT and convolutional neural network with attention mechanism are utilized to construct both sequence- and physicochemical-based extractors for the sophisticated refinement of DNA sequence representations. These bimodal DNA representations are then fed to a k-mer sequence-physicochemistry matching module to minimize the semantic gap between each modality. Lastly, a self-attention fusion layer is employed for the prediction of DNA bendability. In conclusion, the experimental results validate MIXBend's superior performance relative to other state-of-the-art methods. Additionally, MIXBend reveals both novel and known motifs from the yeast. Moreover, MIXBend discovers significant bendability fluctuations within super-enhancer regions and transcription factors binding sites in the human genome. Graphical Abstract	[Yang, Minghao; Zhang, Shichen; Zheng, Zhihang; Zhang, Pengfei; Tang, Shaojun] Hong Kong Univ Sci & Technol Guangzhou, Biosci & Biomed Engn Thrust, Syst Hub, Guangzhou 511466, Peoples R China; [Liang, Yan] South China Normal Univ, Sch Artificial Intelligence, Foshan 528225, Peoples R China; [Tang, Shaojun] Hong Kong Univ Sci & Technol, Div Life Sci, Hong Kong 999077, Peoples R China	Hong Kong University of Science & Technology (Guangzhou); South China Normal University; Hong Kong University of Science & Technology	Tang, SJ (corresponding author), Hong Kong Univ Sci & Technol Guangzhou, Biosci & Biomed Engn Thrust, Syst Hub, Guangzhou 511466, Peoples R China.; Tang, SJ (corresponding author), Hong Kong Univ Sci & Technol, Div Life Sci, Hong Kong 999077, Peoples R China.	shaojuntang@ust.hk	Zhang, Shi-Chen/JTU-5432-2023	Yang, Minghao/0009-0007-0158-2494	HKUST (Guangzhou) Municipal Start-up Fund; HKUST Center for Aging Science 2022 Seed Funding [Z1056]; Center for Aging Science 2022 Seed Funding	HKUST (Guangzhou) Municipal Start-up Fund; HKUST Center for Aging Science 2022 Seed Funding; Center for Aging Science 2022 Seed Funding	HKUST (Guangzhou) Municipal Start-up Fund, and HKUST Center for Aging Science 2022 Seed Funding [Z1056]. Funding for open access charge: Center for Aging Science 2022 Seed Funding.	Baharav TZ, 2020, PATTERNS, V1, DOI 10.1016/j.patter.2020.100081; Basu A, 2021, J MOL BIOL, V433, DOI 10.1016/j.jmb.2021.166861; Basu A, 2021, NATURE, V589, P462, DOI 10.1038/s41586-020-03052-3; Benesty J., 2009, Noise reduction in speech processing, V2, P1, DOI [10.1007/978-3-642-00296-05, DOI 10.1007/978-3-642-00296-05, DOI 10.1007/978-3-642-00296-0_5]; Bruyère C, 2011, TRANSL ONCOL, V4, P126, DOI 10.1593/tlo.10253; Buske FA, 2010, BIOINFORMATICS, V26, P860, DOI 10.1093/bioinformatics/btq049; Chen W, 2017, BIOINFORMATICS, V33, P3518, DOI 10.1093/bioinformatics/btx479; Chen W, 2015, BIOINFORMATICS, V31, P119, DOI 10.1093/bioinformatics/btu602; Chereji RV, 2018, GENOME BIOL, V19, DOI 10.1186/s13059-018-1398-0; Cottier F, 2017, G3-GENES GENOM GENET, V7, P3597, DOI 10.1534/g3.117.300238; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Garcia HG, 2007, BIOPOLYMERS, V85, P115, DOI 10.1002/bip.20627; Gouveia B, 2022, NATURE, V609, P255, DOI 10.1038/s41586-022-05138-6; Gupta S, 2007, GENOME BIOL, V8, DOI 10.1186/gb-2007-8-2-r24; Han K, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbac514; Herbert A, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.200222; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jabbari K, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-51036-9; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Jiang WJ, 2023, NUCLEIC ACIDS RES, DOI 10.1093/nar/gkad720; Khan SR, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.105945; Kim T., 2023, P IEEECVF C COMPUTER, P4900; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li KR, 2022, NUCLEIC ACIDS RES, V50, P3142, DOI 10.1093/nar/gkac162; Liu SP, 2022, BIOINFORMATICS, V38, P28, DOI 10.1093/bioinformatics/btac237; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Luger K, 1997, NATURE, V389, P251, DOI 10.1038/38444; Mitchell JS, 2017, J CHEM THEORY COMPUT, V13, P1539, DOI 10.1021/acs.jctc.6b00904; NAGELKERKE NJD, 1991, BIOMETRIKA, V78, P691, DOI 10.1093/biomet/78.3.691; NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4; Qi Z., 2016, NOT SIMPLY INDUCTION; Radford A, 2021, PR MACH LEARN RES, V139; Ran XC, 2023, ARTIF INTELL REV, V56, P8219, DOI 10.1007/s10462-022-10366-3; Richmond TJ, 2003, NATURE, V423, P145, DOI 10.1038/nature01595; Segal E, 2006, NATURE, V442, P772, DOI 10.1038/nature04979; Segal E, 2009, TRENDS GENET, V25, P335, DOI 10.1016/j.tig.2009.06.002; Sjottem E, 1997, J MOL BIOL, V267, P490, DOI 10.1006/jmbi.1997.0893; SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Vámosi G, 2018, BIOPHYS J, V114, P2253, DOI 10.1016/j.bpj.2017.10.047; Vineetha V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42966-5; Wang XF, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad111; Wang YZ, 2023, NUCLEIC ACIDS RES, V51, pD280, DOI 10.1093/nar/gkac968; Yeou S, 2022, CHEM SCI, V13, P7516, DOI 10.1039/d1sc07115g; Yoo Jejoong, 2021, Nucleic Acids Res, V49, P11459, DOI 10.1093/nar/gkab967; Zhang TY, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac447; Zheng A, 2021, NAT MACH INTELL, V3, DOI 10.1038/s42256-020-00282-y; Zhou YX, 2023, COMPUT BIOL MED, V164, DOI 10.1016/j.compbiomed.2023.107288; Zhu GC, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120439	49	0	0	2	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0305-1048	1362-4962		NUCLEIC ACIDS RES	Nucleic Acids Res.	APR 12	2024	52	6								10.1093/nar/gkae099	http://dx.doi.org/10.1093/nar/gkae099		FEB 2024	13	Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	NP7I7	38375921	gold, Green Published			2024-07-03	WOS:001166339700001
J	Li, HY; Gerkin, RC; Bakke, A; Norel, R; Cecchi, G; Laudamiel, C; Niv, MY; Ohla, K; Hayes, JE; Parma, V; Meyer, P				Li, Hongyang; Gerkin, Richard C.; Bakke, Alyssa; Norel, Raquel; Cecchi, Guillermo; Laudamiel, Christophe; Niv, Masha Y.; Ohla, Kathrin; Hayes, John E.; Parma, Valentina; Meyer, Pablo			Text-based predictions of COVID-19 diagnosis from self-reported chemosensory descriptions	COMMUNICATIONS MEDICINE			English	Article							ODORS; SMELL	Background There is a prevailing view that humans' capacity to use language to characterize sensations like odors or tastes is poor, providing an unreliable source of information. Methods Here, we developed a machine learning method based on Natural Language Processing (NLP) using Large Language Models (LLM) to predict COVID-19 diagnosis solely based on text descriptions of acute changes in chemosensation, i.e., smell, taste and chemesthesis, caused by the disease. The dataset of more than 1500 subjects was obtained from survey responses early in the COVID-19 pandemic, in Spring 2020. Results When predicting COVID-19 diagnosis, our NLP model performs comparably (AUC ROC similar to 0.65) to models based on self-reported changes in function collected via quantitative rating scales. Further, our NLP model could attribute importance of words when performing the prediction; sentiment and descriptive words such as "smell", "taste", "sense", had strong contributions to the predictions. In addition, adjectives describing specific tastes or smells such as "salty", "sweet", "spicy", and "sour" also contributed considerably to predictions. Conclusions Our results show that the description of perceptual symptoms caused by a viral infection can be used to fine-tune an LLM model to correctly predict and interpret the diagnostic status of a subject. In the future, similar models may have utility for patient verbatims from online health portals or electronic health records.	[Li, Hongyang; Norel, Raquel; Cecchi, Guillermo; Meyer, Pablo] IBM TJ Watson Res Ctr, Hlth Care & Life Sci, Yorktown Hts, NY 10598 USA; [Gerkin, Richard C.] Arizona State Univ, Sch Life Sci, Tempe, AZ USA; [Gerkin, Richard C.] Osmo, Cambridge, MA USA; [Bakke, Alyssa; Ohla, Kathrin; Hayes, John E.] Penn State Univ, Dept Food Sci, University Pk, PA USA; [Laudamiel, Christophe] DreamAir LLC, Dept Scent Engn, New York, NY USA; [Niv, Masha Y.] Hebrew Univ Jerusalem, Fac Agr Food & Environm, Rehovot, Israel; [Ohla, Kathrin] Dsm Firmenich, Sci & Res, Satigny, Switzerland; [Parma, Valentina] Monell Chem Senses Ctr, Philadelphia, PA USA	International Business Machines (IBM); Arizona State University; Arizona State University-Tempe; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Hebrew University of Jerusalem; Monell Chemical Senses Center	Meyer, P (corresponding author), IBM TJ Watson Res Ctr, Hlth Care & Life Sci, Yorktown Hts, NY 10598 USA.	pmeyerr@us.ibm.com	Parma, Valentina/AAR-7176-2020; Hayes, John E/A-5893-2008; Niv, Masha/AAL-1123-2020	Norel, Raquel/0000-0001-7737-4172; Niv, Masha/0000-0001-8275-8795	Pennsylvania State University	Pennsylvania State University	This work was supported financially with discretionary funds from the Pennsylvania State University (Penn State), including a gift from James and Helen Zallie given in support of Sensory Science at Penn State. We thank all GCCR members and the subjects that participated.	Agyeman AA, 2020, MAYO CLIN PROC, V95, P1621, DOI 10.1016/j.mayocp.2020.05.030; [Anonymous], MANUSCRIPT CODE, DOI [10.5281/zenodo.8144371, DOI 10.5281/ZENODO.8144371]; Bartoshuk LM, 2019, AM PSYCHOL, V74, P1003, DOI 10.1037/amp0000577; Beauchamp N., 2022, ICWSM, V16, P1363, DOI [10.1609/icwsm.v16i1.19388, DOI 10.1609/ICWSM.V16I1.19388]; CAIN WS, 1979, SCIENCE, V203, P467, DOI 10.1126/science.760202; Chen XC, 2018, BMC PSYCHIATRY, V18, DOI 10.1186/s12888-018-1786-8; Cook BL, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/8708434; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dey S, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100493; ENGEN T, 1987, AM SCI, V75, P497; Finlay JB, 2022, SCI TRANSL MED, V14, DOI 10.1126/scitranslmed.add0484; Fullard ME, 2016, PARKINSONISM RELAT D, V25, P45, DOI 10.1016/j.parkreldis.2016.02.013; Gerkin RC, 2021, CHEM SENSES, V46, DOI 10.1093/chemse/bjaa081; Gutiérrez ED, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07439-9; Hannum ME, 2020, CHEM SENSES, V45, P865, DOI [10.1093/chemse/bjaa064, 10.1101/2020.07.04.20145870]; Karni Noam, 2021, Open Forum Infect Dis, V8, pofaa589, DOI 10.1093/ofid/ofaa589; Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173; Landis BN, 2003, CHEM SENSES, V28, P691, DOI 10.1093/chemse/bjg061; Larsson M, 1997, CHEM SENSES, V22, P623, DOI 10.1093/chemse/22.6.623; Lundberg SM, 2017, ADV NEUR IN, V30; Mainland JD, 2020, CHEM SENSES, V45, P493, DOI 10.1093/chemse/bjaa038; Marcusson J, 2020, BMC GERIATR, V20, DOI 10.1186/s12877-020-1475-6; Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011; Moein ST, 2020, INT FORUM ALLERGY RH, V10, P944, DOI 10.1002/alr.22587; Mullol J, 2020, CURR ALLERGY ASTHM R, V20, DOI 10.1007/s11882-020-00961-1; Ohla K, 2022, RHINOLOGY, V60, P207, DOI 10.4193/Rhin21.415; Parma V, 2020, CHEM SENSES, V45, P609, DOI 10.1093/chemse/bjaa041; Pierron D, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18963-y; ROZIN P, 1982, PERCEPT PSYCHOPHYS, V31, P397, DOI 10.3758/BF03202667; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schab F. R., 2014, Memory for odors; Snitz K, 2022, COMMUN MED-LONDON, V2, DOI 10.1038/s43856-022-00095-7; Soler ZM, 2020, INT FORUM ALLERGY RH, V10, P814, DOI 10.1002/alr.22578; SWETS JA, 1988, SCIENCE, V240, P1285, DOI 10.1126/science.3287615; Tan BKJ, 2022, BMJ-BRIT MED J, V378, DOI 10.1136/bmj-2021-069503; Vaswani A, 2017, ADV NEUR IN, V30; Velupillai S, 2018, J BIOMED INFORM, V88, P11, DOI 10.1016/j.jbi.2018.10.005; Walsh-Messinger J, 2021, EUR J NEUROSCI, V54, P6256, DOI 10.1111/ejn.15430; Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5; Yeshurun Y, 2010, ANNU REV PSYCHOL, V61, P219, DOI 10.1146/annurev.psych.60.110707.163639; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253	41	0	0	2	3	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2730-664X			COMMUN MED-LONDON	Communications Med.	JUL 27	2023	3	1							104	10.1038/s43856-023-00334-5	http://dx.doi.org/10.1038/s43856-023-00334-5			8	Medicine, Research & Experimental	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine	N5LS4	37500763	gold, Green Published			2024-07-03	WOS:001037431200001
J	Zaboli, A; Kasimalla, SR; Park, K; Hong, YG; Hong, JH				Zaboli, Aydin; Kasimalla, Swetha Rani; Park, Kuchan; Hong, Younggi; Hong, Junho			A Comprehensive Review of Behind-the-Meter Distributed Energy Resources Load Forecasting: Models, Challenges, and Emerging Technologies	ENERGIES			English	Review						battery energy storage system; behind the meter; distributed energy resources; electric vehicle; load forecasting; photovoltaic system; smart grids; smart meters	LEARNING-METHOD; TERM; POWER; IDENTIFICATION	Behind the meter (BTM) distributed energy resources (DERs), such as photovoltaic (PV) systems, battery energy storage systems (BESSs), and electric vehicle (EV) charging infrastructures, have experienced significant growth in residential locations. Accurate load forecasting is crucial for the efficient operation and management of these resources. This paper presents a comprehensive survey of the state-of-the-art technologies and models employed in the load forecasting process of BTM DERs in recent years. The review covers a wide range of models, from traditional approaches to machine learning (ML) algorithms, discussing their applicability. A rigorous validation process is essential to ensure the model's precision and reliability. Cross-validation techniques can be utilized to reduce overfitting risks, while using multiple evaluation metrics offers a comprehensive assessment of the model's predictive capabilities. Comparing the model's predictions with real-world data helps identify areas for improvement and further refinement. Additionally, the U.S. Energy Information Administration (EIA) has recently announced its plan to collect electricity consumption data from identified U.S.-based crypto mining companies, which can exhibit abnormal energy consumption patterns due to rapid fluctuations. Hence, some real-world case studies have been presented that focus on irregular energy consumption patterns in residential buildings equipped with BTM DERs. These abnormal activities underscore the importance of implementing robust anomaly detection techniques to identify and address such deviations from typical energy usage profiles. Thus, our proposed framework, presented in residential buildings equipped with BTM DERs, considering smart meters (SMs). Finally, a thorough exploration of potential challenges and emerging models based on artificial intelligence (AI) and large language models (LLMs) is suggested as a promising approach.	[Zaboli, Aydin; Kasimalla, Swetha Rani; Park, Kuchan; Hong, Younggi; Hong, Junho] Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA	University of Michigan System; University of Michigan	Hong, JH (corresponding author), Univ Michigan, Dept Elect & Comp Engn, Dearborn, MI 48128 USA.	azaboli@umich.edu; sweraka@umich.edu; kuchan@umich.edu; younggi@umich.edu; jhwr@umich.edu	Zaboli, Aydin/V-2743-2017	Zaboli, Aydin/0000-0001-9052-1851; hong, junho/0000-0001-5035-8260				Abdalzaher MS, 2022, ENERGIES, V15, DOI 10.3390/en15197419; Abumohsen M, 2023, ENERGIES, V16, DOI 10.3390/en16052283; Ahmad A, 2019, ENERGIES, V12, DOI 10.3390/en12010164; Ahmad N, 2022, IEEE ACCESS, V10, P71054, DOI 10.1109/ACCESS.2022.3187839; Akarslan E, 2021, SUSTAIN ENERGY GRIDS, V27, DOI 10.1016/j.segan.2021.100488; Al Amin M. Abdullah, 2019, 2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON), P205, DOI 10.1109/IEMECONX.2019.8877077; Andriopoulos N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010158; Azad MI, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13020407; Bacanin N, 2023, ENERGIES, V16, DOI 10.3390/en16031434; Cecati C, 2015, IEEE T IND ELECTRON, V62, P6519, DOI 10.1109/TIE.2015.2424399; Cha JW, 2021, ENERGIES, V14, DOI 10.3390/en14217067; Colak I, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1045, DOI 10.1109/ICMLA.2015.33; Dai YM, 2020, APPL ENERG, V279, DOI 10.1016/j.apenergy.2020.115332; Das P, 2018, ENERGY STRATEG REV, V22, P1, DOI 10.1016/j.esr.2018.06.005; De Carne G, 2019, IEEE T IND APPL, V55, P7328, DOI 10.1109/TIA.2019.2918053; Deivamani K., 2023, P 2023 IEEE PES INN, P1; DeRoche M., Cryptocurrency Miners Need to Report Their Energy Use; Du L, 2015, IEEE T SMART GRID, V6, P819, DOI 10.1109/TSG.2014.2373314; Elmenshawy MS, 2023, IEEE ACCESS, V11, P103916, DOI 10.1109/ACCESS.2023.3315591; Erdener BC, 2022, RENEW SUST ENERG REV, V160, DOI 10.1016/j.rser.2022.112224; Farhoumandi Matin, 2023, 2023 9th International Conference on Control, Decision and Information Technologies (CoDIT), P2414, DOI 10.1109/CoDIT58514.2023.10284135; Fekri MN, 2021, APPL ENERG, V282, DOI 10.1016/j.apenergy.2020.116177; Forero-Quintero JF, 2023, SUSTAIN ENERGY TECHN, V60, DOI 10.1016/j.seta.2023.103404; Geng GC, 2023, ENERGIES, V16, DOI 10.3390/en16124616; Ghayoor F., 2023, P 2023 IEEE KANS POW, P1; Ghayoor F, 2022, COMPUT IND ENG, V164, DOI 10.1016/j.cie.2021.107900; Grabner M, 2023, IEEE T SMART GRID, V14, P4927, DOI 10.1109/TSG.2023.3264525; Habbak H, 2023, ENERGIES, V16, DOI 10.3390/en16031480; He Li, 2023, IEEE Transactions on Energy Markets, Policy and Regulation, P107, DOI 10.1109/TEMPR.2023.3250948; Hong Y, 2020, IEEE ACCESS, V8, P55785, DOI 10.1109/ACCESS.2020.2981817; Hossain MS, 2020, IEEE POWER ENERG CON, DOI 10.1109/peci48348.2020.9064654; Ibrahem MI, 2021, IEEE INTERNET THINGS, V8, P1243, DOI 10.1109/JIOT.2020.3026692; Jacob M., 2020, Forecasting and Assessing Risk of Individual Electricity Peaks, P15, DOI DOI 10.1007/978-3-030-28669-92; Ji PR, 2012, ASIA-PAC POWER ENERG; Jin M, 2012, EXPERT SYST APPL, V39, P773, DOI 10.1016/j.eswa.2011.07.072; Karthika S, 2017, 2017 INNOVATIONS IN POWER AND ADVANCED COMPUTING TECHNOLOGIES (I-PACT), DOI 10.1109/ICOEI.2017.8300713; Khan RA, 2018, IEEE POW INDIA INT C; Khodayar M, 2021, IEEE T NEUR NET LEAR, V32, P4713, DOI 10.1109/TNNLS.2020.3042434; Kong WC, 2019, IEEE T SMART GRID, V10, P841, DOI 10.1109/TSG.2017.2753802; Li KX, 2021, IEEE ACCESS, V9, P1376, DOI 10.1109/ACCESS.2020.3047147; Lin J, 2022, IEEE T SMART GRID, V13, P268, DOI 10.1109/TSG.2021.3115904; Lindberg KB, 2019, UTIL POLICY, V58, P102, DOI 10.1016/j.jup.2019.04.001; Liu YS, 2023, IEEE OPEN J IND ELEC, V4, P451, DOI 10.1109/OJIES.2023.3319040; Luo ZY, 2023, ENERG CONVERS MANAGE, V278, DOI 10.1016/j.enconman.2023.116705; M Jahid Hasan A. S., 2023, 2023 International Conference on Information and Communication Technology for Sustainable Development (ICICT4SD), P388, DOI 10.1109/ICICT4SD59951.2023.10303520; Madadi Mehrnaz, 2023, 2023 IEEE Energy Conversion Congress and Exposition (ECCE), P610, DOI 10.1109/ECCE53617.2023.10362343; Mansoor M, 2021, MATH COMPUT SIMULAT, V184, P282, DOI 10.1016/j.matcom.2020.07.011; Montero-Manso P, 2021, INT J FORECASTING, V37, P1632, DOI 10.1016/j.ijforecast.2021.03.004; Moradzadeh A, 2022, IEEE ACCESS, V10, P2196, DOI 10.1109/ACCESS.2021.3136091; Oprea SV, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910963; Pan KD, 2022, APPL ENERG, V309, DOI 10.1016/j.apenergy.2021.118450; Proedrou E, 2021, IEEE ACCESS, V9, P12114, DOI 10.1109/ACCESS.2021.3050074; Rafi SH, 2021, IEEE ACCESS, V9, P32436, DOI 10.1109/ACCESS.2021.3060654; Real AC, 2024, ENERGY AI, V16, DOI 10.1016/j.egyai.2024.100347; Rodrigues F, 2023, ENERGIES, V16, DOI 10.3390/en16104098; Saeedi R, 2021, IEEE T IND INFORM, V17, P7060, DOI 10.1109/TII.2021.3060898; Selakov A, 2012, TRANS DISTRIB CONF; Shabbir N, 2024, ELECTRONICS-SWITZ, V13, DOI 10.3390/electronics13081420; Shakeel A, 2023, J CLEAN PROD, V409, DOI 10.1016/j.jclepro.2023.137130; Sharma D, 2015, 2015 IEEE INNOVATIVE SMART GRID TECHNOLOGIES - ASIA (ISGT ASIA); Shi YT, 2022, ENERGIES, V15, DOI 10.3390/en15207800; Smart Energy International, 2023, US Smart Meter Penetration to Reach 93% by 2027-Berg Insight; Som Trina, 2023, Prediction Techniques for Renewable Energy Generation and Load Demand Forecasting. Lecture Notes in Electrical Engineering (956), P153, DOI 10.1007/978-981-19-6490-9_9; Stratman A, 2023, IEEE T IND APPL, V59, P5341, DOI 10.1109/TIA.2023.3276356; Takiyar Swati, 2015, 2015 4th International Conference on Reliability, Infocom Technologies and Optimization (ICRITO) (Trends and Future Directions), P1, DOI 10.1109/ICRITO.2015.7359274; Huy THB, 2023, 2023 ASIA MEETING ON ENVIRONMENT AND ELECTRICAL ENGINEERING, EEE-AM; Tziolis G., 2023, P 2023 IEEE INT SMAR, P1; U.S. Energy Information Administration, Press Release; Wang K, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102175; Wang XL, 2024, INT J PR ENG MAN-GT, V11, P963, DOI 10.1007/s40684-023-00537-0; Wang XL, 2023, APPL ENERG, V330, DOI 10.1016/j.apenergy.2022.120279; Wang Y, 2019, IEEE T SMART GRID, V10, P2593, DOI 10.1109/TSG.2018.2805723; Wang Y, 2018, IEEE T POWER SYST, V33, P3255, DOI 10.1109/TPWRS.2017.2762599; Welikala S, 2019, IEEE T SMART GRID, V10, P448, DOI 10.1109/TSG.2017.2743760; Wen M, 2023, AIP ADV, V13, DOI 10.1063/5.0176239; Wood M, 2023, FORECASTING-BASEL, V5, P297, DOI 10.3390/forecast5010016; Xia L, 2024, EXPERT SYST APPL, V239, DOI 10.1016/j.eswa.2023.122019; Xiang Li, 2021, 2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE), P237, DOI 10.1109/AEMCSE51986.2021.00057; Ye N, 2012, 2012 WORLD AUTOMATION CONGRESS (WAC); Yuan YX, 2021, IEEE ELECTRIF MAG, V9, P92, DOI 10.1109/MELE.2021.3093636; Zaboli A, 2023, Arxiv, DOI arXiv:2311.05462; Zaboli A, 2023, IEEE POW ENER SOC GE, DOI 10.1109/PESGM52003.2023.10252389; Zaboli A, 2023, IEEE ACCESS, V11, P49378, DOI 10.1109/ACCESS.2023.3276646; Zhang Xiaoyu, 2022, 2022 2nd International Conference on Electrical Engineering and Mechatronics Technology (ICEEMT), P337, DOI 10.1109/ICEEMT56362.2022.9862617; Zhao L, 2022, INFORM SCIENCES, V610, P326, DOI 10.1016/j.ins.2022.07.161; Zheng J, 2017, 2017 51ST ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS)	86	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1996-1073		ENERGIES	Energies	JUN	2024	17	11							2534	10.3390/en17112534	http://dx.doi.org/10.3390/en17112534			27	Energy & Fuels	Science Citation Index Expanded (SCI-EXPANDED)	Energy & Fuels	UA2G7		gold			2024-07-03	WOS:001245271300001
J	Shieh, A; Tran, B; He, GE; Kumar, M; Freed, JA; Majety, P				Shieh, Allen; Tran, Brandon; He, Gene; Kumar, Mudit; Freed, Jason A.; Majety, Priyanka			Assessing ChatGPT 4.0's test performance and clinical diagnostic accuracy on USMLE STEP 2 CK and clinical case reports	SCIENTIFIC REPORTS			English	Article						ChatGPT 4; USMLE; Case reports; Diagnostic accuracy	ARTIFICIAL-INTELLIGENCE	While there is data assessing the test performance of artificial intelligence (AI) chatbots, including the Generative Pre-trained Transformer 4.0 (GPT 4) chatbot (ChatGPT 4.0), there is scarce data on its diagnostic accuracy of clinical cases. We assessed the large language model (LLM), ChatGPT 4.0, on its ability to answer questions from the United States Medical Licensing Exam (USMLE) Step 2, as well as its ability to generate a differential diagnosis based on corresponding clinical vignettes from published case reports. A total of 109 Step 2 Clinical Knowledge (CK) practice questions were inputted into both ChatGPT 3.5 and ChatGPT 4.0, asking ChatGPT to pick the correct answer. Compared to its previous version, ChatGPT 3.5, we found improved accuracy of ChatGPT 4.0 when answering these questions, from 47.7 to 87.2% (p = 0.035) respectively. Utilizing the topics tested on Step 2 CK questions, we additionally found 63 corresponding published case report vignettes and asked ChatGPT 4.0 to come up with its top three differential diagnosis. ChatGPT 4.0 accurately created a shortlist of differential diagnoses in 74.6% of the 63 case reports (74.6%). We analyzed ChatGPT 4.0's confidence in its diagnosis by asking it to rank its top three differentials from most to least likely. Out of the 47 correct diagnoses, 33 were the first (70.2%) on the differential diagnosis list, 11 were second (23.4%), and three were third (6.4%). Our study shows the continued iterative improvement in ChatGPT's ability to answer standardized USMLE questions accurately and provides insights into ChatGPT's clinical diagnostic accuracy.	[Shieh, Allen; Tran, Brandon; He, Gene] Virginia Commonwealth Univ, Sch Med, Richmond, VA 23284 USA; [Kumar, Mudit] Virginia Commonwealth Univ, Dept Psychiat, Div Child & Adolescent Psychiat, Richmond, VA USA; [Freed, Jason A.] Beth Israel Deaconess Med Ctr, Dept Internal Med, Div Hematol & Hematol Malignancies, Boston, MA USA; [Majety, Priyanka] Virginia Commonwealth Univ, Dept Internal Med, Div Endocrinol Diabet & Metab, Richmond, VA USA	Virginia Commonwealth University; Virginia Commonwealth University; Harvard University; Beth Israel Deaconess Medical Center; Virginia Commonwealth University	Tran, B (corresponding author), Virginia Commonwealth Univ, Sch Med, Richmond, VA 23284 USA.	tranb6@vcu.edu						Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Cheng KM, 2023, INT J SURG, V109, P1545, DOI 10.1097/JS9.0000000000000388; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Doyal AS, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43292; Fischer Q, 2020, EUR HEART J-CASE REP, V4, DOI 10.1093/ehjcr/ytaa180; Geetha SD, 2024, AM J CLIN PATHOL, V161, P393, DOI 10.1093/ajcp/aqad158; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Ismail A, 2023, J AM COLL RADIOL, V20, P696, DOI 10.1016/j.jacr.2023.02.025; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Massey PA, 2023, J AM ACAD ORTHOP SUR, V31, P1173, DOI 10.5435/JAAOS-D-23-00396; OpenAI, 2023, Research-gpt-4; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23	16	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	APR 23	2024	14	1							9330	10.1038/s41598-024-58760-x	http://dx.doi.org/10.1038/s41598-024-58760-x			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	OL3V9	38654011	gold			2024-07-03	WOS:001207399200004
J	Sargsyan, K; Lim, C				Sargsyan, Karen; Lim, Carmay			Using protein language models for protein interaction hot spot prediction with limited data	BMC BIOINFORMATICS			English	Article						Protein language models; ESM-2; Protein-protein interaction; PPI-hotspot; Small datasets; Feature selection	BINDING; CONSURF	BackgroundProtein language models, inspired by the success of large language models in deciphering human language, have emerged as powerful tools for unraveling the intricate code of life inscribed within protein sequences. They have gained significant attention for their promising applications across various areas, including the sequence-based prediction of secondary and tertiary protein structure, the discovery of new functional protein sequences/folds, and the assessment of mutational impact on protein fitness. However, their utility in learning to predict protein residue properties based on scant datasets, such as protein-protein interaction (PPI)-hotspots whose mutations significantly impair PPIs, remained unclear. Here, we explore the feasibility of using protein language-learned representations as features for machine learning to predict PPI-hotspots using a dataset containing 414 experimentally confirmed PPI-hotspots and 504 PPI-nonhot spots.ResultsOur findings showcase the capacity of unsupervised learning with protein language models in capturing critical functional attributes of protein residues derived from the evolutionary information encoded within amino acid sequences. We show that methods relying on protein language models can compete with methods employing sequence and structure-based features to predict PPI-hotspots from the free protein structure. We observed an optimal number of features for model precision, suggesting a balance between information and overfitting.ConclusionsThis study underscores the potential of transformer-based protein language models to extract critical knowledge from sparse datasets, exemplified here by the challenging realm of predicting PPI-hotspots. These models offer a cost-effective and time-efficient alternative to traditional experimental methods for predicting certain residue properties. However, the challenge of explaining why specific features are important for determining certain residue properties remains.	[Sargsyan, Karen; Lim, Carmay] Acad Sinica, Inst Biomed Sci, Taipei 115, Taiwan	Academia Sinica - Taiwan	Sargsyan, K; Lim, C (corresponding author), Acad Sinica, Inst Biomed Sci, Taipei 115, Taiwan.	karen.sarkisyan@gmail.com; carmay@gate.sinica.edu.tw			Academia Sinica	Academia Sinica(Academia Sinica - Taiwan)	Not applicable.	Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bateman A, 2019, NUCLEIC ACIDS RES, V47, pD506, DOI 10.1093/nar/gky1049; Case DA, 2023, J CHEM INF MODEL, V63, P6183, DOI 10.1021/acs.jcim.3c01153; Chen Y, 2023, PPI-hotspotID: a method for detecting protein-protein interaction hot spots from the free protein structure, DOI [10.21203/rs.3.rs-3400169/v1, DOI 10.21203/RS.3.RS-3400169/V1]; Chen YC, 2022, J CHEM INF MODEL, V62, P1052, DOI 10.1021/acs.jcim.2c00025; Cheng Y, 2023, NAT CHEM BIOL, V19, P548, DOI 10.1038/s41589-022-01223-z; Chowdhury R, 2022, NAT BIOTECHNOL, V40, P1692, DOI 10.1038/s41587-022-01556-z; Durairaj J, 2023, NATURE, V622, P646, DOI 10.1038/s41586-023-06622-3; Erickson N, 2020, Arxiv, DOI [arXiv:2003.06505, DOI 10.48550/ARXIV.2003.06505]; Fischer TB, 2003, BIOINFORMATICS, V19, P1453, DOI 10.1093/bioinformatics/btg163; Glaser F, 2003, BIOINFORMATICS, V19, P163, DOI 10.1093/bioinformatics/19.1.163; Heinzinger M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3220-8; Hie B, 2022, bioRxiv, V2022; Hie BL, 2024, NAT BIOTECHNOL, V42, DOI 10.1038/s41587-023-01763-2; Hsu C., 2022, P MACH LEARN REPR PM, P8946; Jankauskaite J, 2019, BIOINFORMATICS, V35, P462, DOI 10.1093/bioinformatics/bty635; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Landau M, 2005, NUCLEIC ACIDS RES, V33, pW299, DOI 10.1093/nar/gki370; Le NQK, 2023, PROTEOMICS, V23, DOI 10.1002/pmic.202300011; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mazmanian K, 2020, J AM CHEM SOC, V142, P9861, DOI 10.1021/jacs.0c02430; Meier J, 2021, bioRxiv, V2009; Mitternacht Simon, 2016, F1000Res, V5, P189, DOI 10.12688/f1000research.7931.1; Raza A, 2023, J CHEM INF MODEL, V63, P6537, DOI 10.1021/acs.jcim.3c01563; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Schwen Lars Ole, 2022, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.100853; Strodthoff N, 2020, BIOINFORMATICS, V36, P2401, DOI 10.1093/bioinformatics/btaa003; Su J, 2023, bioRxiv, V2010; Thorn KS, 2001, BIOINFORMATICS, V17, P284, DOI 10.1093/bioinformatics/17.3.284; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wu R., 2022, BIORXIV, DOI [10.1101/2022.07.21.500999, DOI 10.1101/2022.07.21.500999]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	35	0	0	9	9	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	MAR 16	2024	25	1							115	10.1186/s12859-024-05737-2	http://dx.doi.org/10.1186/s12859-024-05737-2			10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	LG9F1	38493120	gold			2024-07-03	WOS:001185746700001
J	Karjus, A; Cuskley, C				Karjus, Andres; Cuskley, Christine			Evolving linguistic divergence on polarizing social media	HUMANITIES & SOCIAL SCIENCES COMMUNICATIONS			English	Article								Language change is influenced by many factors, but often starts from synchronic variation, where multiple linguistic patterns or forms coexist, or where different speech communities use language in increasingly different ways. Besides regional or economic reasons, communities may form and segregate based on political alignment. The latter, referred to as political polarization, is of growing societal concern across the world. Here we map and quantify linguistic divergence across the partisan left-right divide in the United States, using social media data. We develop a general methodology to delineate (social) media users by their political preference, based on which (potentially biased) news media accounts they do and do not follow on a given platform. Our data consists of 1.5M short posts by 10k users (about 20M words) from the social media platform Twitter (now "X"). Delineating this sample involved mining the platform for the lists of followers (n = 422M) of 72 large news media accounts. We quantify divergence in topics of conversation and word frequencies, messaging sentiment, and lexical semantics of words and emoji. We find signs of linguistic divergence across all these aspects, especially in topics and themes of conversation, in line with previous research. While US American English remains largely intelligible within its large speech community, our findings point at areas where miscommunication may eventually arise given ongoing polarization and therefore potential linguistic divergence. Our flexible methodology - combining data mining, lexicostatistics, machine learning, large language models and a systematic human annotation approach - is largely language and platform agnostic. In other words, while we focus here on US political divides and US English, the same approach is applicable to other countries, languages, and social media platforms.	[Karjus, Andres] Tallinn Univ, ERA Chair Cultural Data Analyt, Tallinn, Estonia; [Karjus, Andres] Tallinn Univ, Sch Humanities, Tallinn, Estonia; [Karjus, Andres] Estonian Business Sch, Tallinn, Estonia; [Cuskley, Christine] Newcastle Univ, English Literature Language & Linguist, Newcastle Upon Tyne, England; [Cuskley, Christine] Newcastle Univ, Ctr Behav & Evolut, Newcastle Upon Tyne, England	Tallinn University; Tallinn University; Estonian Business School; Newcastle University - UK; Newcastle University - UK	Karjus, A (corresponding author), Tallinn Univ, ERA Chair Cultural Data Analyt, Tallinn, Estonia.; Karjus, A (corresponding author), Tallinn Univ, Sch Humanities, Tallinn, Estonia.; Karjus, A (corresponding author), Estonian Business Sch, Tallinn, Estonia.	andres.karjus@tlu.ee		Karjus, Andres/0000-0002-2445-5072				Adamic LA, 2005, INT WORKSHOP LINK DI, P36, DOI DOI 10.1145/1134271.1134277; Albertson BL, 2015, POLIT BEHAV, V37, P3, DOI 10.1007/s11109-013-9265-x; AllSides, 2021, AllSides Media Bias Ratings; AllSides, 2022, AllSides February 2022 February 2022 Blind Bias Survey Whitepaper; Alshaabi T, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abe6534; Altmann EG, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0019009; An J., 2012, P INT AAAI C WEB SOC, V6, P2; Ananthasubramaniam A, 2022, arXiv; Andresen JT, 2016, Languages in the world: How history, culture, and politics shape language; Andris C, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123507; Angelov D, 2020, Arxiv, DOI [arXiv:2008.09470, DOI 10.48550/ARXIV.2008.09470, 10.48550/arXiv.2008.09470]; Azarbonyad H, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1509, DOI 10.1145/3132847.3132878; Bailey G., 1991, LANG VAR CHANGE, V3, P241, DOI DOI 10.1017/S0954394500000569; Balietti S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2112552118; Begus G, 2023, Arxiv, DOI arXiv:2305.00948; Beskow DM, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102170; Bhat P, 2020, TWITTER PUBLIC SPHER, P151, DOI [10.1007/978-3-030-41421-4_7, DOI 10.1007/978-3-030-41421-4_7]; blAnK Andreas, 1997, Prinzipien des lexikalischen Bedeutungswandels am Beispiel der romanischen Sprachen, DOI DOI 10.1515/9783110931600; Blythe RA, 2012, ADV COMPLEX SYST, V15, DOI 10.1142/S0219525911003414; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Broockman D, 2022, OSF preprint, DOI [10.31219/osf.io/jrw26, DOI 10.31219/OSF.IO/JRW26]; Brown JR, 2021, NAT HUM BEHAV, V5, P998, DOI 10.1038/s41562-021-01066-z; Burton JW, 2021, NAT HUM BEHAV, V5, P1629, DOI 10.1038/s41562-021-01133-5; Carda D, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120510119; Chen THY, 2021, GLOBAL ENVIRON CHANG, V71, DOI 10.1016/j.gloenvcha.2021.102348; Chin A, 2022, PROCEEDINGS OF THE 14TH ACM WEB SCIENCE CONFERENCE, WEBSCI 2022, P296, DOI 10.1145/3501247.3531547; Conover MD, 2011, P INT AAAI C WEB SOC, V133, P89, DOI DOI 10.1609/ICWSM.V5I1.14126; Croft W., 2000, EXPLAINING LANGUAGE; Cuskley C, 2022, OSF preprint, DOI [10.31234/osf.io/w7qy9, DOI 10.31234/OSF.IO/W7QY9]; Davies M., 2008, The Corpus of Contemporary American English (COCA) Computer software; Demszky D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2970; Dixon RMW, 2003, Word: A Cross-linguistic Typology; Donoso G., 2017, P 4 WORKSH NLP SIM L, P16, DOI [10.18653/v1/W17-1202, DOI 10.18653/V1/W17-1202]; Dzogang F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197002; Falkenberg M, 2023, Arxiv, DOI arXiv:2311.18535; Feltgen Q, 2017, ROY SOC OPEN SCI, V4, DOI 10.1098/rsos.170830; Fraxanet E, 2024, Arxiv, DOI arXiv:2307.06571; Gentzkow M, 2019, ECONOMETRICA, V87, P1307, DOI 10.3982/ECTA16566; Gilardi F, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2305016120; González-Bailón S, 2023, SCIENCE, V381, P392, DOI 10.1126/science.ade7138; Grieve J, 2018, J ENGL LINGUIST, V46, P293, DOI 10.1177/0075424218793191; Hamilton WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1489; Haspelmath M, 2011, FOLIA LINGUIST, V45, P31, DOI 10.1515/FLIN.2011.002; Hetherington M., 2018, Prius or pickup?: How the answers to four simple questions explain America's great divide; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Huang F, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P294, DOI 10.1145/3543873.3587368; Huszar F, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2025334119; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Ibrus I, 2023, INT J COMMUN-US, V17, P6741; Jaidka K, 2019, ASIAN J COMMUN, V29, P252, DOI 10.1080/01292986.2018.1453849; Joseph K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P312; Jurkowitz M., 2020, Pew Research Center; Kaiser J, 2022, J COMMUN, V72, P214, DOI 10.1093/joc/jqac002; Kapidzic S, 2015, NEW MEDIA SOC, V17, P958, DOI 10.1177/1461444813520301; Karjus A, 2023, Arxiv, DOI arXiv:2309.14379; Karjus A, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.13035; Karjus A, 2020, LANG DYN CHANG, V10, P86, DOI 10.1163/22105832-01001200; Kemp C, 2018, ANNU REV LINGUIST, V4, P109, DOI 10.1146/annurev-linguistics-011817-045406; Khoo J., 2017, Philosophical Topics, V45, P33, DOI [10.5840/philtopics201745213, DOI 10.5840/PHILTOPICS201745213]; Kutuzov A, 2022, Northern Eur J Lang Technol, V8; Ledford H, 2023, Nature News; Li P, 2017, BEHAV RES METHODS, V49, P1668, DOI 10.3758/s13428-017-0931-5; Lobera J, 2022, INT J PUBLIC OPIN R, V34, DOI 10.1093/ijpor/edab033; Louf T, 2023, Arxiv, DOI arXiv:2307.10016; Louf T, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01611-3; Macy MW, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2102144118; McCulloch G, 2019, INTERNET UNDERSTANDI, Patent No. 9780735210936; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Muise D, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn0083; Mukerjee S, 2022, POLIT COMMUN, V39, P565, DOI 10.1080/10584609.2022.2075061; Müller K, 2021, J EUR ECON ASSOC, V19, P2131, DOI 10.1093/jeea/jvaa045; Mummolo J, 2017, J POLIT, V79, P45, DOI 10.1086/687569; Oakey D, 2022, Discourses, Modes, Media and Meaning in an Era of Pandemic; Oiva M, 2024, Humanities and Social Sciences Communications; OpenAI, 2023, GPT 4 TECHNICAL REPO; Penelas-Leguía A, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01805-9; Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2; Petersen MB, 2023, AM POLIT SCI REV, V117, P1486, DOI 10.1017/S0003055422001447; Pew Research Center, 2020, Differences in how Democrats and Republicans behave on Twitter; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Ramiro C, 2018, P NATL ACAD SCI USA, V115, P2323, DOI 10.1073/pnas.1714730115; Rasmussen SHR, 2022, Preprints, DOI [10.31234/osf.io/tp93r, DOI 10.31234/OSF.IO/TP93R]; Rathje S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2024292118; Rawlings C, 2022, SocArXiv, DOI [10.31235/osf.io/4yqve, DOI 10.31235/OSF.IO/4YQVE]; Robertson Alexander, 2020, ACM Transactions on Social Computing, V3, DOI 10.1145/3377479; Robertson A, 2021, Arxiv, DOI arXiv:2105.00846; Rodman E, 2020, POLIT ANAL, V28, P87, DOI 10.1017/pan.2019.23; Rosin Guy D., 2022, FINDINGS ASS COMPUTA, P1498, DOI [10.18653/v1/2022.findings-naacl.112, DOI 10.18653/V1/2022.FINDINGS-NAACL.112]; Schlechtweg D., 2018, P 2018 C N AM CHAPT, P169; Schlechtweg D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P732; Schlechtweg Dominik., 2020, P 14 WORKSHOP SEMANT, P1, DOI DOI 10.18653/V1/2020.SEMEVAL-1.1; Soliman A, 2019, PROCEEDINGS OF THE 30TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA (HT '19), P259, DOI 10.1145/3342220.3343662; Spinde Timo, 2021, Diversity, Divergence, Dialogue. 16th International Conference, iConference 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12646), P215, DOI 10.1007/978-3-030-71305-8_17; Stewart I, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4360; Sylwester K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0137422; Tyler M, 2023, AM POLIT SCI REV, V117, P347, DOI 10.1017/S000305542200048X; Verma Devika, 2020, ICT Analysis and Applications. Proceedings of ICT4SD 2019. Lecture Notes in Networks and Systems (LNNS 93), P285, DOI 10.1007/978-981-15-0630-7_28; Wang Yu, 2017, Social Informatics, Lecture Notes in Computer Science, P440, DOI [10.1007/978-3-319-67217-5_27, DOI 10.1007/978-3-319-67217-5_27]; Wendlandt Laura, 2018, Long Papers, V1, P2092, DOI [DOI 10.18653/V1/N18-1190, 10.18653/v1/N18-1190]; Wignell P, 2021, J LANG POLIT, V20, P197, DOI 10.1075/jlp.19046.wig; Wojcik S, 2019, SIZING TWITTER USERS; Xiao ZP, 2022, Arxiv, DOI arXiv:2209.08110; Yang PY, 2022, Arxiv, DOI [arXiv:2210.16065, 10.48550/arXiv.2210.16065, DOI 10.48550/ARXIV.2210.16065]; Zemaityte V, 2024, PLOS ONE, V19, DOI 10.1371/journal.pone.0297404; Ziems C, 2023, Comput Linguist, P1	105	1	1	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2662-9992		HUM SOC SCI COMMUN	Hum. Soc. Sci. Commun.	MAR 15	2024	11	1							422	10.1057/s41599-024-02922-9	http://dx.doi.org/10.1057/s41599-024-02922-9			14	Humanities, Multidisciplinary; Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; Social Sciences - Other Topics	LH4K1		Green Submitted, gold			2024-07-03	WOS:001185882900005
J	Yang, YT; Zuo, X; Das, A; Xu, H; Zheng, WJ				Yang, Yuntao; Zuo, Xu; Das, Avisha; Xu, Hua; Zheng, Wenjin			Representation Learning of Biological Concepts: A Systematic Review	CURRENT BIOINFORMATICS			English	Review						Machine learning; biological concepts; representation learning; embedding; natural language processing; graph neural networks	PROTEIN SEQUENCES; NETWORK; ASSOCIATION; PREDICTION; GENOME	Objective Representation learning in the context of biological concepts involves acquiring their numerical representations through various sources of biological information, such as sequences, interactions, and literature. This study has conducted a comprehensive systematic review by analyzing both quantitative and qualitative data to provide an overview of this field.Methods Our systematic review involved searching for articles on the representation learning of biological concepts in PubMed and EMBASE databases. Among the 507 articles published between 2015 and 2022, we carefully screened and selected 65 papers for inclusion. We then developed a structured workflow that involved identifying relevant biological concepts and data types, reviewing various representation learning techniques, and evaluating downstream applications for assessing the quality of the learned representations.Results The primary focus of this review was on the development of numerical representations for gene/DNA/RNA entities. We have found Word2Vec to be the most commonly used method for biological representation learning. Moreover, several studies are increasingly utilizing state-of-the-art large language models to learn numerical representations of biological concepts. We also observed that representations learned from specific sources were typically used for single downstream applications that were relevant to the source.Conclusion Existing methods for biological representation learning are primarily focused on learning representations from a single data type, with the output being fed into predictive models for downstream applications. Although there have been some studies that have explored the use of multiple data types to improve the performance of learned representations, such research is still relatively scarce. In this systematic review, we have provided a summary of the data types, models, and downstream applications used in this task.	[Yang, Yuntao; Zuo, Xu; Das, Avisha; Xu, Hua; Zheng, Wenjin] Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, Houston, TX 77030 USA	University of Texas System; University of Texas Health Science Center Houston	Zheng, WJ (corresponding author), Univ Texas Hlth Sci Ctr Houston, Sch Biomed Informat, Houston, TX 77030 USA.	Wenjin.J.Zheng@uth.tmc.edu			Cancer Prevention and Research Institute of Texas [RP170668, RP210045]; National Institutes of Health (NIH) [1UL1TR003167, R01AG066749]; NIA [R56AG069880]; DoD [W81XWH-22-1-0164]	Cancer Prevention and Research Institute of Texas(Cancer Prevention & Research Institute of Texas); National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NIA(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); DoD(United States Department of Defense)	This work has been partly supported by the Cancer Prevention and Research Institute of Texas through grants RP170668 (WJZ) and RP210045 (AD), and the National Institutes of Health (NIH) through grants 1UL1TR003167 and R01AG066749 (WJZ), and NIA R56AG069880 (HX) and DoD W81XWH-22-1-0164 (Zheng).	Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3; Alachram H, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258623; [Anonymous], 2022, PubMedGPT 2.7B 2022; Aoki G, 2018, BIOINFORMATICS, V34, P237, DOI 10.1093/bioinformatics/bty228; Asgari E, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38746-w; Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287; Ashoor H, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14974-x; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Charoenkwan P, 2021, BIOINFORMATICS, V37, P2556, DOI 10.1093/bioinformatics/btab133; Chen L, 2019, GENE THER, V26, P465, DOI 10.1038/s41434-019-0099-y; Chen QY, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007617; Chen ZH, 2019, GENES-BASEL, V10, DOI 10.3390/genes10110924; Chen Z, 2018, GENOM PROTEOM BIOINF, V16, P451, DOI 10.1016/j.gpb.2018.08.004; Choi J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-32180-0; Choi W, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258626; Cohen T, 2009, J BIOMED INFORM, V42, P390, DOI 10.1016/j.jbi.2009.02.002; Dai W, 2020, GENES-BASEL, V11, DOI 10.3390/genes11020153; Deepika SS, 2018, J BIOMED INFORM, V84, P136, DOI 10.1016/j.jbi.2018.06.015; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devkota K, 2020, BIOINFORMATICS, V36, P464, DOI 10.1093/bioinformatics/btaa459; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du JC, 2019, BMC GENOMICS, V20, DOI 10.1186/s12864-018-5370-x; Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Fakoor R., 2013, P INT C MACH LEARN 2, VVolume 28, P3937; Fan YX, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab361; Firth JR, 1957, Selected Papers of J. R. Firth, P10; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Guthrie D., 2006, A closer look at skip-gram modelling, V1222, P1225; Hao J., 2020, ACMBCB 2020 11 ACM, DOI [DOI 10.1145/3388440.3412477, 10.1145/3388440.3412477]; Heinzinger M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3220-8; Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950; Hong JW, 2021, BIOINFORMATICS, V37, P3436, DOI 10.1093/bioinformatics/btab349; Hou WJ, 2018, J BIOINF COMPUT BIOL, V16, DOI 10.1142/S0219720018400279; Jin Y, 2021, BIOMOLECULES, V11, DOI 10.3390/biom11121783; Kang CZ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab513; Khanal J, 2021, COMPUT STRUCT BIOTEC, V19, P1612, DOI 10.1016/j.csbj.2021.03.015; Kim S, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0349-7; Lan W, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab494; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Le NQK, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab005; Li GB, 2021, PEERJ, V9, DOI 10.7717/peerj.11262; Li JY, 2020, BIOMED RES INT, V2020, DOI 10.1155/2020/6248686; Li K, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.605620; Li L, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1009655; Liu XQ, 2019, GENES-BASEL, V10, DOI 10.3390/genes10040273; Lu CQ, 2020, BIOINFORMATICS, V36, P5656, DOI 10.1093/bioinformatics/btaa1077; Lyons J, 2014, J COMPUT CHEM, V35, P2040, DOI 10.1002/jcc.23718; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Min X, 2017, BIOINFORMATICS, V33, pI92, DOI 10.1093/bioinformatics/btx234; Mudiyanselage TB, 2022, METHODS, V198, P32, DOI 10.1016/j.ymeth.2021.10.008; Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]; Ostrovsky-Berman M, 2021, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.680687; OZCAN SN., 2019, BMC Bioinformatics, V20, P1; Pan XY, 2020, BIOINFORMATICS, V36, P5159, DOI 10.1093/bioinformatics/btaa656; Pan XY, 2020, BBA-PROTEINS PROTEOM, V1868, DOI 10.1016/j.bbapap.2020.140477; Patrick MT, 2019, J INVEST DERMATOL, V139, P683, DOI 10.1016/j.jid.2018.09.018; Pennington J, 2014, P 2014 C EMP METH NA, V2014, P1532, DOI DOI 10.3115/V1/D14-1162; Qin TT, 2014, NUCLEIC ACIDS RES, V42, DOI 10.1093/nar/gku678; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093; Tange HJ, 1998, J AM MED INFORM ASSN, V5, P571, DOI 10.1136/jamia.1998.0050571; Nguyen TTD, 2019, ANAL BIOCHEM, V577, P73, DOI 10.1016/j.ab.2019.04.011; Tsoi LC, 2009, BIOINFORMATICS, V25, P1314, DOI 10.1093/bioinformatics/btp158; Le QV, 2014, Arxiv, DOI [arXiv:1405.4053, 10.48550/arXiv.1405.4053]; Vang YS, 2017, BIOINFORMATICS, V33, P2658, DOI 10.1093/bioinformatics/btx264; Villegas-Morcillo A, 2021, BIOINFORMATICS, V37, P162, DOI 10.1093/bioinformatics/btaa701; Wang JC, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20236046; Wang YB, 2019, CELLS-BASEL, V8, DOI 10.3390/cells8020122; Wang ZF, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab342; Wijaya C.Y., 2021, 4 Categorical Encoding Concepts to Know for Data Scientists; Woloszynek S, 2019, PLOS COMPUT BIOL, V15, DOI 10.1371/journal.pcbi.1006721; Wu CY, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3006-z; Wu L, 2018, AAAI CONF ARTIF INTE, P5569; Xiao Z, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0238915; Xie WD, 2021, BRIEF BIOINFORM, V22, P2032, DOI 10.1093/bib/bbaa022; Xu BB, 2017, PEERJ, V5, DOI 10.7717/peerj.3579; Xuan P, 2022, IEEE J BIOMED HEALTH, V26, P2839, DOI 10.1109/JBHI.2021.3130110; Yang KK, 2018, BIOINFORMATICS, V34, P2642, DOI 10.1093/bioinformatics/bty178; Yang K, 2019, IEEE J BIOMED HEALTH, V23, P1805, DOI 10.1109/JBHI.2018.2870728; Yang L, 2021, BIOINFORMATICS, V37, P3579, DOI 10.1093/bioinformatics/btab252; Yang S, 2020, MOLECULES, V25, DOI 10.3390/molecules25194372; Yang S, 2020, BIOINFORMATICS, V36, P4797, DOI 10.1093/bioinformatics/btaa580; You RH, 2018, METHODS, V145, P82, DOI 10.1016/j.ymeth.2018.05.026; Yuan H, 2019, NAT METHODS, V16, P858, DOI 10.1038/s41592-019-0511-y; Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255; Zeng M, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab360; Zeng WW, 2018, BMC GENOMICS, V19, DOI 10.1186/s12864-018-4459-6; Zhang HY, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac083; Zhang JL, 2020, METHODS, V179, P81, DOI 10.1016/j.ymeth.2020.05.010; Zhang W, 2022, COMPUT MATH METHOD M, V2022, DOI 10.1155/2022/8693746; Zhang X, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1008229; Zhao XS, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab407; Zou Q, 2019, RNA, V25, P205, DOI 10.1261/rna.069112.118	95	0	0	3	3	BENTHAM SCIENCE PUBL LTD	SHARJAH	EXECUTIVE STE Y-2, PO BOX 7917, SAIF ZONE, 1200 BR SHARJAH, U ARAB EMIRATES	1574-8936	2212-392X		CURR BIOINFORM	Curr. Bioinform.		2024	19	1					61	72		10.2174/1574893618666230612161210	http://dx.doi.org/10.2174/1574893618666230612161210			12	Biochemical Research Methods; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Mathematical & Computational Biology	MV4Z6		hybrid			2024-07-03	WOS:001196411600007
J	Rau, A; Rau, S; Zöller, D; Fink, A; Tran, H; Wilpert, C; Nattenmuller, J; Neubauer, J; Bamberg, F; Reisert, M; Russe, MF				Rau, Alexander; Rau, Stephan; Zoeller, Daniela; Fink, Anna; Tran, Hien; Wilpert, Caroline; Nattenmuller, Johanna; Neubauer, Jakob; Bamberg, Fabian; Reisert, Marco; Russe, Maximilian F.			A Context-based Chatbot Surpasses Radiologists and Generic ChatGPT in Following the ACR Appropriateness Guidelines	RADIOLOGY			English	Article							CLINICAL DECISION-SUPPORT	Background: Radiologic imaging guidelines are crucial for accurate diagnosis and optimal patient care as they result in standardized decisions and thus reduce inappropriate imaging studies. Purpose: To investigate the potential to support clinical decision-making using an interactive chatbot designed to provide personalized imaging recommendations from American College of Radiology (ACR) appropriateness criteria documents using semantic similarity processing. Materials and Methods: The authors used 209 ACR appropriateness criteria documents as a specialized knowledge base and used LlamaIndex, a framework for connecting large language models with external data, and ChatGPT-3.5-turbo to create an appropriateness criteria context aware chatbot (accGPT). Fifty clinical case files were used to compare the performance of accGPT with that of general radiologists at varying experience levels and to generic ChatGPT-3.5 and 4.0. Results: The performance of all chatbots reached at least that of humans. For the 50 case files, accGPT performed best in providing correct recommendations that were "usually appropriate" according to the ACR criteria and also provided the highest proportion of consistently correct answers in comparison with the generic chatbots and radiologists. Furthermore, the chatbots provided substantial time and cost savings, with an average decision time of 5 minutes and a cost of _0.19 ($0.21) for all cases, compared with 50 minutes and _29.99 ($33.24) for radiologists (both P < .01). Conclusion: ChatGPT-based algorithms have the potential to substantially improve the decision-making for clinical imaging studies in accordance with ACR guidelines. Specifically, the performance of a context-based algorithm was superior to that of its generic counterpart, demonstrating the value of tailoring artificial intelligence solutions to specific health care applications. (c) RSNA, 2023	[Rau, Alexander; Rau, Stephan; Fink, Anna; Tran, Hien; Wilpert, Caroline; Nattenmuller, Johanna; Bamberg, Fabian; Russe, Maximilian F.] Univ Freiburg, Dept Diagnost & Intervent Radiol, Breisacher Str 64, D-79106 Freiburg, Germany; [Rau, Alexander] Univ Freiburg, Dept Neuroradiol, Breisacher Str 64, D-79106 Freiburg, Germany; [Reisert, Marco] Univ Freiburg, Dept Diagnost & Intervent Radiol, Med Phys, Breisacher Str 64, D-79106 Freiburg, Germany; [Reisert, Marco] Univ Freiburg, Med Ctr Univ Freiburg, Dept Stereotact & Funct Neurosurg, Fac Med, Breisacher Str 64, D-79106 Freiburg, Germany; [Zoeller, Daniela] Univ Freiburg, Inst Med Biometry & Stat, Fac Med, Freiburg, Germany; [Zoeller, Daniela] Univ Freiburg, Med Ctr, Freiburg, Germany; [Zoeller, Daniela] Univ Freiburg, Freiburg Ctr Data Anal & Modelling, Freiburg, Germany	University of Freiburg; University of Freiburg; University of Freiburg; University of Freiburg; University of Freiburg; University of Freiburg; University of Freiburg	Russe, MF (corresponding author), Univ Freiburg, Dept Diagnost & Intervent Radiol, Breisacher Str 64, D-79106 Freiburg, Germany.	maximilian.russe@uniklinik-freiburg.de	Neubauer, Jakob/KQV-4104-2024; Rau, Alexander/AAK-3948-2021; Fink, Anna/KLY-9411-2024; Wilpert, Caroline/JBI-8004-2023	Rau, Alexander/0000-0001-5881-6043; Fink, Anna/0009-0002-9903-283X; Wilpert, Caroline/0000-0003-2375-2478; Nattenmueller, Johanna/0000-0003-4032-378X; Rau, Stephan/0000-0002-8992-2401; Neubauer, Jakob/0000-0001-9388-0219; Zoller, Daniela/0000-0001-9929-7403	Berta-Ottenstein-Programme for Clinician Scientists, Faculty of Medicine, University of Freiburg	Berta-Ottenstein-Programme for Clinician Scientists, Faculty of Medicine, University of Freiburg	A.R. supported by Berta-Ottenstein-Programme for Clinician Scientists, Faculty of Medicine, University of Freiburg.	[Anonymous], GPT-3.5-turbo; [Anonymous], GPT-4; Bookman K, 2017, ACAD EMERG MED, V24, P839, DOI 10.1111/acem.13195; Buvat I, 2023, J NUCL MED, V64, P505, DOI 10.2967/jnumed.123.265636; Carter SM, 2020, BREAST, V49, P25, DOI 10.1016/j.breast.2019.10.001; CASCADE PN, 1994, RADIOLOGY, V192, pA50; Chaudhari GR, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00740-6; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; ESR, 2019, INSIGHTS IMAGING, V10, DOI 10.1186/s13244-019-0720-z; ESR, 2016, INSIGHTS IMAGING, V7, P481, DOI 10.1007/s13244-016-0493-6; European Soc Radiology, 2017, INSIGHTS IMAGING, V8, P1, DOI 10.1007/s13244-016-0523-4; Francisco MZ, 2021, CURR PROBL DIAGN RAD, V50, P799, DOI 10.1067/j.cpradiol.2020.11.004; Gabelloni M, 2020, RADIOL MED, V125, P531, DOI 10.1007/s11547-020-01142-w; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kwee TC, 2021, INSIGHTS IMAGING, V12, DOI 10.1186/s13244-021-01031-4; Lyu Q, 2023, Arxiv, DOI arXiv:2303.09038; Markus T, 2023, INSIGHTS IMAGING, V14, DOI 10.1186/s13244-023-01371-3; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Rao Arya S., 2023, medRxiv; Saban M, 2022, EUR RADIOL, V32, P4218, DOI 10.1007/s00330-021-08479-4; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Young GJ, 2020, J GEN INTERN MED, V35, P1661, DOI 10.1007/s11606-019-05621-3	23	24	24	8	13	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	JUL	2023	308	1							e230970	10.1148/radiol.230970	http://dx.doi.org/10.1148/radiol.230970			8	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	S0NG3	37489981	Green Submitted			2024-07-03	WOS:001068217100029
J	Gupta, R; Herzog, I; Park, JB; Weisberger, J; Firouzbakht, P; Ocon, V; Chao, JH; Lee, ES; Mailey, BA				Gupta, Rohun; Herzog, Isabel; Park, John B.; Weisberger, Joseph; Firouzbakht, Peter; Ocon, Vanessa; Chao, John; Lee, Edward S.; Mailey, Brian A.			Performance of ChatGPT on the Plastic Surgery Inservice Training Examination	AESTHETIC SURGERY JOURNAL			English	Article; Early Access								Background Developed originally as a tool for resident self-evaluation, the Plastic Surgery Inservice Training Examination (PSITE) has become a standardized tool adopted by Plastic Surgery residency programs. The introduction of large language models (LLMs), such as ChatGPT (OpenAI, San Francisco, CA), has demonstrated the potential to help propel the field of Plastic Surgery. Objectives The authors of this study wanted to assess whether or not ChatGPT could be utilized as a tool in resident education by assessing its accuracy on the PSITE. Methods Questions were obtained from the 2022 PSITE, which was present on the American Council of Academic Plastic Surgeons (ACAPS) website. Questions containing images or tables were carefully inspected and flagged before being inputted into ChatGPT. All responses by ChatGPT were qualified utilizing the properties of natural coherence. Responses that were found to be incorrect were divided into the following categories: logical, informational, or explicit fallacy. Results ChatGPT answered a total of 242 questions with an accuracy of 54.96%. The software incorporated logical reasoning in 88.8% of questions, internal information in 95.5% of questions, and external information in 92.1% of questions. When stratified by correct and incorrect responses, we determined that there was a statistically significant difference in ChatGPT's use of external information (P < .05). Conclusions ChatGPT is a versatile tool that has the potential to impact resident education by providing general knowledge, clarifying information, providing case-based learning, and promoting evidence-based medicine. With advancements in LLM and artificial intelligence (AI), it is possible that ChatGPT may be an impactful tool for resident education within Plastic Surgery.	[Gupta, Rohun; Firouzbakht, Peter] St Louis Univ, Dept Surg, Div Plast Surg, Sch Med, St Louis, MO USA; [Herzog, Isabel; Park, John B.; Chao, John] Rutgers New Jersey Sch Med, Dept Plast Surg, Newark, NJ USA; [Gupta, Rohun] SLUCare Acad Pavil, 1008 S Spring Ave,Suite,1500 St Louis, St Louis, MO 63110 USA	Saint Louis University	Gupta, R (corresponding author), SLUCare Acad Pavil, 1008 S Spring Ave,Suite,1500 St Louis, St Louis, MO 63110 USA.	rohunguptamd@gmail.com	Gupta, Rohun/HQY-7933-2023	Gupta, Rohun/0000-0003-1491-2441; Herzog, Isabel/0000-0001-7491-5746				American Council of Academic Plastic Surgeons, US; American Society of Plastic Surgeons, INS EX RES; [Anonymous], ACGME PROGRAM REQUIR; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Girotto JA, 2019, PLAST RECONSTR SURG, V143, p1099E, DOI 10.1097/PRS.0000000000005536; Gupta R, 2023, AESTHET SURG J, V43, pNP656, DOI 10.1093/asj/sjad108; Gupta R, 2023, J PLAST RECONSTR AES, V80, P145, DOI 10.1016/j.bjps.2023.03.004; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Meaike JD, 2021, PRS-GLOB OPEN, V9, DOI 10.1097/GOX.0000000000003639; OpenAI©, Chatgpt: Optimizing language models for dialogue; OpenAI, GPT 3 POW NEXT GEN A; Silvestre J, 2015, AESTHET SURG J, V35, P739, DOI 10.1093/asj/sju151; Southern Matt., Search Engine Journal; Trabasso T., 1991, Advances in Psychology. Vol, V79, P297	16	28	28	19	42	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1090-820X	1527-330X		AESTHET SURG J	Aesthet. Surg. J.	2023 MAY 2	2023										10.1093/asj/sjad128	http://dx.doi.org/10.1093/asj/sjad128		MAY 2023	5	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	H3QV6	37128784				2024-07-03	WOS:000995155000001
J	Razzaq, MS; Maqbool, F; Ilyas, M; Jabeen, H				Razzaq, Muhammad Saad; Maqbool, Fahad; Ilyas, Muhammad; Jabeen, Hajira			EvoRecipes: A Generative Approach for Evolving Context-Aware Recipes	IEEE ACCESS			English	Article						Knowledge graph; ontology; computational creativity; recipe evolution; recipe; food		Generative AI e.g. Large Language Models (LLMs) can be used to generate new recipes. However, LLMs struggle with more complex aspects like recipe semantics and process comprehension. Furthermore, LLMs have limited ability to account for user preferences since they are based on statistical patterns. As a result, these recipes may be invalid. Evolutionary algorithms inspired by the process of natural selection are optimization algorithms that use stochastic operators to generate new solutions. These algorithms can generate large number of solutions from the set of possible solution space. Moreover, these algorithms have the capability to incorporate user preferences in fitness function to generate novel recipes that are more aligned with the fitness objective. In this paper, we propose the EvoRecipes framework to generate novel recipes. The EvoRecipes framework utilizes both Genetic Algorithm and generative AI in addition to RecipeOn ontology, and RecipeKG knowledge graph. Genetic Algorithm explore the large solution space of encoded recipe solutions and are capable of incorporating user preferences, while LLMs are used to generate recipe text from encoded recipe solutions. EvoRecipes uses a population of context-aware recipe solutions from the RecipeKG knowledge graph. RecipeKG encodes recipes in RDF format using classes and properties as defined in the RecipeOn ontology. Moreover, to evaluate the alignment of EvoRecipe generated recipes with multiple intended objectives, we propose a fitness function that incorporates novelty, simplicity, visual appeal, and feasibility. Additionally, to evaluate the quality of the EvoRecipe generated recipes while considering the subjective nature of recipes, we conducted a survey using multi-dimensional metrics (i.e. contextual, procedural, and novelty). Results show that EvoRecipes generated recipes are novel, valid and incorporate user preferences.	[Razzaq, Muhammad Saad; Maqbool, Fahad; Ilyas, Muhammad] Univ Sargodha, Dept Comp Sci & IT, Sargodha 40100, Pakistan; [Jabeen, Hajira] GESIS Leibniz Inst Social Sci, D-50667 Cologne, Germany	University of Sargodha; Leibniz Institut fur Sozialwissenschaften (GESIS)	Razzaq, MS (corresponding author), Univ Sargodha, Dept Comp Sci & IT, Sargodha 40100, Pakistan.	saad.razzaq@uos.edu.pk		Razzaq, Saad/0000-0003-2940-0836; Maqbool, Fahad/0000-0003-3969-5551				Al-Raeei M, 2022, MODEL EARTH SYST ENV, V8, P1443, DOI 10.1007/s40808-020-01075-3; Camaréna S, 2020, J CLEAN PROD, V271, DOI 10.1016/j.jclepro.2020.122574; Chambers LD, 2019, PRACTICAL HDB GENETI; DENG J, 2022, POWER SYST TECHNOL, P1; Dooley DM, 2018, NPJ SCI FOOD, V2, DOI 10.1038/s41538-018-0032-6; Draschner C., 2019, P EVO LEIPZ GERM APR, P8; Gim M, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P3092, DOI 10.1145/3511808.3557092; Gim M, 2021, IEEE ACCESS, V9, P143623, DOI 10.1109/ACCESS.2021.3120265; Haussmann S, 2019, LECT NOTES COMPUT SC, V11779, P146, DOI 10.1007/978-3-030-30796-7_10; Jabeen H., 2020, P IEEE C EV COMP CEC, P1; Jabeen H, 2019, LECT NOTES COMPUT SC, V11453, P156, DOI 10.1007/978-3-030-16667-0_11; Jimenez-Mavillard A, 2022, AI SOC, V37, P331, DOI 10.1007/s00146-021-01183-3; Khilji AFUR, 2021, ARAB J SCI ENG, V46, P3701, DOI 10.1007/s13369-020-05236-5; Lawo D., 2020, VEGANAIZER AI ASSIST; Loughran Roisin, 2017, ICCC, P197; Mitchell M., 1997, Artificial Life, V3, P63, DOI [10.1162/artl.1997.3.63, DOI 10.1162/ARTL.1997.3.63]; Morris R.G., 2012, P INT C COMPUTATIONA, P119; Nadee Wanvimol, 2021, 2021 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunication Engineering, P14, DOI 10.1109/ECTIDAMTNCON51128.2021.9425778; Pan YR, 2020, I C DATA ENGIN WORKS, P94, DOI 10.1109/ICDEW49219.2020.000-1; Park DJ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87171-5; Pinel Florian., 2014, CHI 14 EXTENDED ABST, P439, DOI DOI 10.1145/2559206.2574794; Reddy K. S., 2023, ADV COMPUT SCI TECHN, V16, P35; Sakib MS, 2022, IEEE ROBOT AUTOM LET, V7, P11492, DOI 10.1109/LRA.2022.3191068; Santos W. A. D., 2020, IEEE ACCESS, V8; Schifferstein HNJ, 2022, J CULIN SCI TECHNOL, V20, P293, DOI 10.1080/15428052.2020.1824833; Shao N., 2014, PROC ICCC, P324; Sharma T, 2020, I C DATA ENGIN WORKS, P98, DOI 10.1109/ICDEW49219.2020.00007; Shirai SS, 2021, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.621766; Shukla D.P., 2019, TRJ Tourism Research Journal, V3, P203; Spence C, 2022, INT J GASTRON FOOD S, V27, DOI 10.1016/j.ijgfs.2021.100433; Tuwani R, 2019, I C DATA ENGIN WORKS, P85, DOI 10.1109/ICDEW.2019.00-30; Varshney LR, 2016, J CREATIVE BEHAV, V50, P211, DOI 10.1002/jocb.121; Varshney LR, 2013, PROCEEDINGS OF THE 2013 12TH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI CC 2013), P36, DOI 10.1109/ICCI-CC.2013.6622223; VARSHNEY LR, 2019, IBM J RES DEV, V63, P1, DOI DOI 10.1147/JRD.2019.2893905; Venkataramanan R, 2023, Arxiv, DOI arXiv:2306.01805; Zhang Q, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103443	36	0	0	8	16	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						74148	74164		10.1109/ACCESS.2023.3296144	http://dx.doi.org/10.1109/ACCESS.2023.3296144			17	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	N6ST5		gold			2024-07-03	WOS:001038293500001
J	Zhang, YH; Gosline, R				Zhang, Yunhao; Gosline, Renee			Human favoritism, not AI aversion: People's perceptions (and bias) toward generative AI, human experts, and human-GAI collaboration in persuasive content generation	JUDGMENT AND DECISION MAKING			English	Article						Generative AI; Algorithm Aversion; Human Favortism; Consumer Perception		With the wide availability of large language models and generative AI, there are four primary paradigms for human-AI collaboration: human-only, AI-only (ChatGPT-4), augmented human (where a human makes the final decision with AI output as a reference), or augmented AI (where the AI makes the final decision with human output as a reference). In partnership with one of the world's leading consulting firms, we enlisted professional content creators and ChatGPT-4 to create advertising content for products and persuasive content for campaigns following the aforementioned paradigms. First, we find that, contrary to the expectations of some of the existing algorithm aversion literature on conventional predictive AI, the content generated by generative AI and augmented AI is perceived as of higher quality than that produced by human experts and augmented human experts. Second, revealing the source of content production reduces-but does not reverse-the perceived quality gap between human- and AI-generated content. This bias in evaluation is predominantly driven by human favoritism rather than AI aversion: Knowing that the same content is created by a human expert increases its (reported) perceived quality, but knowing that AI is involved in the creation process does not affect its perceived quality. Further analysis suggests this bias is not due to a 'quality prime' as knowing the content they are about to evaluate comes from competent creators (e.g., industry professionals and state-of-the-art AI) without knowing exactly that the creator of each piece of content does not increase participants' perceived quality.	[Zhang, Yunhao] MIT Sloan, Berkeley Haas, Berkeley, CA 94720 USA; [Gosline, Renee] MIT Sloan, Cambridge, MA USA	Massachusetts Institute of Technology (MIT)	Zhang, YH (corresponding author), MIT Sloan, Berkeley Haas, Berkeley, CA 94720 USA.	zyhjerry@mit.edu	Zhang, Yunhao/KPY-6502-2024	Zhang, Yunhao/0000-0001-8576-0612	Accenture Applied Intelligence; MIT Initiative on the Digital Economy	Accenture Applied Intelligence; MIT Initiative on the Digital Economy	The authors appreciate Jon Baron, the two anonymous reviewers, and seminar participants from MIT B-Lab for their constructive feedback. The authors are grateful to Accenture Applied Intelligence and the MIT Initiative on the Digital Economy for financial support. We thank Patrick Connolly, Shraavya Koppole, and Philippe Roussiere for facilitating our communication and collaboration with Accenture and helping us recruit and collect responses from the professional content creators from the firm that were used as part of our stimulus.	Acemoglu D, 2020, J POLIT ECON, V128, P2188, DOI 10.1086/705716; Acemoglu D, 2018, AM ECON REV, V108, P1488, DOI 10.1257/aer.20160696; Agrawal A, 2019, J ECON PERSPECT, V33, P31, DOI 10.1257/jep.33.2.31; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bar-Hillel M, 2012, JUDGM DECIS MAK, V7, P149; Berg J., 2023, Academy of Management Discoveries; Botha J, 2020, PR INT CONF INF WAR, P57, DOI 10.34190/ICCWS.20.085; Brynjolfsson E., 2023, Generative AI at work (No. w31161); Castelo N, 2019, J MARKETING RES, V56, P809, DOI 10.1177/0022243719851788; Clayton J., 2023, BBC News; Dietvorst BJ, 2015, J EXP PSYCHOL GEN, V144, P114, DOI 10.1037/xge0000033; Frey CB, 2017, TECHNOL FORECAST SOC, V114, P254, DOI 10.1016/j.techfore.2016.08.019; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Khan G., 2023, Will AI -generated images create a new crisis for fact -checkers? Experts are not so sure; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Liu YH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517731; Logg JM, 2019, ORGAN BEHAV HUM DEC, V151, P90, DOI 10.1016/j.obhdp.2018.12.005; McKendrick J., 2022, Harvard Business Review, V15; Morewedge CK, 2022, TRENDS COGN SCI, V26, P824, DOI 10.1016/j.tics.2022.07.007; Noy S, 2023, SCIENCE, V381, P187, DOI 10.1126/science.adh2586; Sun Z, 2023, ARTIF INTELL REV, V56, P937, DOI 10.1007/s10462-023-10541-0; Zhang Y., 2023, Understanding Algorithm Aversion: When Do People Abandon AI After Seeing It Err?	22	1	1	168	189	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1930-2975			JUDGM DECIS MAK	Judgm. Decis. Mak.	NOV 28	2023	18								e41	10.1017/jdm.2023.37	http://dx.doi.org/10.1017/jdm.2023.37			16	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	Z5NN8		gold			2024-07-03	WOS:001112542000001
J	Algaraady, J; Mahyoob, M				Algaraady, Jeehaan; Mahyoob, Mohammad			ChatGPT's Capabilities in Spotting and Analyzing Writing Errors Experienced by EFL Learners	ARAB WORLD ENGLISH JOURNAL			English	Article						Artificial Intelligence; ChatGPT; EFL writing; EFL learners; LLMs; error analysis		The recent Large Language Models (LLMs) use advanced algorithms to identify areas where sentence structure and word choice can be improved and to detect grammar, syntax, and spelling mistakes in sentences. This study aimed to investigate the effectiveness of the Chat Generative Pre-trained Transformer (ChatGPT) in detecting English as a foreign language (EFL) learners' writing errors compared to human instructors. This study examines the ChatGPT as a recent and advanced LLM in analyzing and processing EFL learners' writing issues. This paper provides valuable insights into the potential benefits and challenges of integrating Artificial Intelligence (AI) into EFL writing education. Our results revealed that ChatGPT successfully identified most surface-level errors but could not detect writing errors related to deep structure and pragmatics. Conversely, human teachers could spot most of these issues. These findings suggest that while ChatGPT can be a valuable tool in identifying surface-level errors, it cannot replace human instructors' expertise and nuanced understanding in detecting errors related to the more complex aspects of writing. The writing error types (data) are statistically analyzed. The descriptive analysis displays valuable insights into the reliability of the data and its potential implications, where the F-score, which measures the statistical model accuracy, is found to be 1.5. In the meantime, the p-value score, which shows the probability of obtaining results as extreme as the detected data, is calculated to be 0.23. The results suggest that the collected data is statistically significant, and further analysis may yield valuable insights.	[Algaraady, Jeehaan] Taiz Univ, Fac Educ, English Dept, Taizi, Yemen; [Mahyoob, Mohammad] Taibah Univ, Languages & Translat Dept, Madina, Saudi Arabia; [Mahyoob, Mohammad] Tech Community Coll Taiz, Computat Linguist, Taizi, Yemen	Taiz University; Taibah University	Mahyoob, M (corresponding author), Taibah Univ, Languages & Translat Dept, Madina, Saudi Arabia.; Mahyoob, M (corresponding author), Tech Community Coll Taiz, Computat Linguist, Taizi, Yemen.	mqassem@taibahu.edu	Mahyoob, Mohammad/AAG-1598-2021	Mahyoob, Mohammad/0000-0002-6664-1017; Algaraady, Jeehaan/0000-0003-3901-4648	Arab World English Journal (AWEJ)	Arab World English Journal (AWEJ)	This paper has been funded by Arab World English Journal (AWEJ)	ABDALKADER SMA, 2022, EGYPTIAN J ED SCI, V2, P39; Algaraady J., 2021, TESOL International, V16; Algaraady J, 2022, INT J INF COMMUN TEC, V18, DOI 10.4018/IJICTE.309137; Baskara F. R., 2023, International Journal of Education and Learning, V5, DOI DOI 10.31763/IJELE.V5I1.858; Baskara R., 2023, International Journal of Education and Learning, V5; Bishop L., 2023, Research, and Writing; Bowman Emma, 2022, NPR19 Dec; Chen T, 2016, COMPUT ASSIST LANG L, V29, P365, DOI 10.1080/09588221.2014.960942; Cho K, 2007, COMPUT EDUC, V48, P409, DOI 10.1016/j.compedu.2005.02.004; Corder S.P., 1981, Error analysis and interlanguage; Ellis R., 2002, Second language acquisition; Gayed J. M., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100055; Halaweh M., 2023, CONT ED TECHNOLOGY, V15; Han J, 2023, Arxiv, DOI [arXiv:2305.11583, 10.48550/arXiv.2305.11583]; Holmes W, 2024, INT J ARTIF INTELL E, V34, P144, DOI 10.1007/s40593-023-00364-z; Hong W. C. H., 2023, Journal of Educational Technology and Innovation, V5; Huawei S, 2023, EDUC INF TECHNOL, V28, P771, DOI 10.1007/s10639-022-11200-7; Karim A, 2018, INT J ENGL LINGUIST, V8, P122, DOI 10.5539/ijel.v8n4p122; Lin V, 2022, COMPUT ASSIST LANG L, V35, P989, DOI 10.1080/09588221.2020.1770291; Lu XX, 2019, BIG DATA-US, V7, P121, DOI 10.1089/big.2018.0151; Mahyoob M, 2021, INT J INF COMMUN TEC, V17, DOI 10.4018/IJICTE.20211001.oa7; Park J., 2019, The Korea English Language Testing Association, V14, P11; Park Junhee, 2019, [Multimedia-Assisted Language Learning, 멀티미디어 언어교육], V22, P112; Pedro F., 2019, Artificial intelligence in education: challenges and opportunities for sustainable development; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Stevenson M, 2019, CAM APPL L, P125; Su YF, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100752; Tate T. P., 2023, Educational Research and AI-Generated Writing: Confronting the Coming Tsunami, DOI [10.35542/osf.io/4mec, DOI 10.35542/OSF.IO/4MEC]; Wang ZJ, 2022, LIBR HI TECH, V40, P80, DOI 10.1108/LHT-05-2020-0113; Wu HR, 2023, Arxiv, DOI arXiv:2303.13648; Yan D, 2023, EDUC INF TECHNOL, V28, P13943, DOI 10.1007/s10639-023-11742-4; Zhai N, 2023, J EDUC COMPUT RES, V61, P875, DOI 10.1177/07356331221127300	32	4	4	60	126	ARAB WORLD ENGLISH JOURNAL	KUALA LUMPUR	JALAN 34-24 WANGSA MAJU, KUALA LUMPUR, 53300, MALAYSIA	2229-9327			ARAB WORLD ENGL J	Arab World Engl. J.	JUL	2023					9		3	17		10.24093/awej/call9.1	http://dx.doi.org/10.24093/awej/call9.1			15	Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	Q4OU2		Green Submitted, gold			2024-07-03	WOS:001057338300001
J	Gandhi, AP; Joesph, FK; Rajagopal, V; Aparnavi, P; Katkuri, S; Dayama, S; Satapathy, P; Khatib, MN; Gaidhane, S; Zahiruddin, QS; Behera, A				Gandhi, Aravind P.; Joesph, Felista Karen; Rajagopal, Vineeth; Aparnavi, P.; Katkuri, Sushma; Dayama, Sonal; Satapathy, Prakasini; Khatib, Mahalaqua Nazli; Gaidhane, Shilpa; Zahiruddin, Quazi Syed; Behera, Ashish			Performance of ChatGPT on the India Undergraduate Community Medicine Examination: Cross-Sectional Study	JMIR FORMATIVE RESEARCH			English	Article						artificial intelligence; ChatGPT; community medicine; India; large language model; medical education; digitalization		Background: Medical students may increasingly use large language models (LLMs) in their learning. ChatGPT is an LLM at the forefront of this new development in medical education with the capacity to respond to multidisciplinary questions. Objective: The aim of this study was to evaluate the ability of ChatGPT 3.5 to complete the Indian undergraduate medical examination in the subject of community medicine. We further compared ChatGPT scores with the scores obtained by the students. Methods: The study was conducted at a publicly funded medical college in Hyderabad, India. The study was based on the internal assessment examination conducted in January 2023 for students in the Bachelor of Medicine and Bachelor of Surgery Final Year-Part I program; the examination of focus included 40 questions (divided between two papers) from the community medicine subject syllabus. Each paper had three sections with different weightage of marks for each section: section one had two long essay-type questions worth 15 marks each, section two had 8 short essay-type questions worth 5 marks each, and section three had 10 short -answer questions worth 3 marks each. The same questions were administered as prompts to ChatGPT 3.5 and the responses were recorded. Apart from scoring ChatGPT responses, two independent evaluators explored the responses to each question to further analyze their quality with regard to three subdomains: relevancy, coherence, and completeness. Each question was scored in these subdomains on a Likert scale of 1-5. The average of the two evaluators was taken as the subdomain score of the question. The proportion of questions with a score 50% of the maximum score (5) in each subdomain was calculated. Results: ChatGPT 3.5 scored 72.3% on paper 1 and 61% on paper 2. The mean score of the 94 students was 43% on paper 1 and 45% on paper 2. The responses of ChatGPT 3.5 were also rated to be satisfactorily relevant, coherent, and complete for most of the questions (>80%). Conclusions: ChatGPT 3.5 appears to have substantial and sufficient knowledge to understand and answer the Indian medical undergraduate examination in the subject of community medicine. ChatGPT may be introduced to students to enable the self -directed learning of community medicine in pilot mode. However, faculty oversight will be required as ChatGPT is still in the initial stages of development, and thus its potential and reliability of medical content from the Indian context need to be further explored comprehensively.	[Gandhi, Aravind P.] All India Inst Med Sci, Dept Community Med, Room 420 Dept Community Med,Plot 2,Sect 20, Nagpur 441108, Maharashtra, India; [Joesph, Felista Karen] Melmaruvathur Adhiparasakthi Inst Med Sci & Res, Melmaruvathur, India; [Rajagopal, Vineeth] Postgrad Inst Med Educ & Res, Sch Publ Hlth, Dept Community Med, Chandigarh, India; [Aparnavi, P.] KMCH Inst Hlth Sci & Res, Dept Community Med, Coimbatore, India; [Katkuri, Sushma] ESIC Med Coll & Hosp, Dept Community Med, Hyderabad, India; [Dayama, Sonal] Saveetha Univ, Saveetha Med Coll & Hosp, Saveetha Inst Med & Tech Sci, Ctr Global Hlth Res, Chennai, India; [Satapathy, Prakasini] AL Mustaqbal Univ, Med Labs Tech Dept, Hillah, Babil, Iraq; [Khatib, Mahalaqua Nazli] Datta Meghe Inst Higher Educ, Global Consortium Publ Hlth & Res, Div Evidence Synth, Wardha, India; [Gaidhane, Shilpa] Datta Meghe Inst Higher Educ, Jawaharlal Nehru Med Coll, Ctr Hlth Educ Res & Dev 1, Wardha, India; [Zahiruddin, Quazi Syed; Behera, Ashish] Datta Meghe Inst Higher Educ & Res, Global Hlth Acad Div Evidence Synth, Jawaharlal Nehru Med Coll, Sch Epidemiol & Publ Hlth & Res, Wardha, India; [Gandhi, Aravind P.; Behera, Ashish] Postgrad Inst Med Educ & Res, Dept Internal Med, Chandigarh, India	All India Institute of Medical Sciences (AIIMS) Nagpur; Post Graduate Institute of Medical Education & Research (PGIMER), Chandigarh; Saveetha Institute of Medical & Technical Science; Saveetha Medical College & Hospital; Al-Mustaqbal University College; Datta Meghe Institute of Higher Education & Research (Deemed to be University); Jawaharlal Nehru Medical College Wardha; Datta Meghe Institute of Higher Education & Research (Deemed to be University); Jawaharlal Nehru Medical College Wardha; Post Graduate Institute of Medical Education & Research (PGIMER), Chandigarh	Gandhi, AP (corresponding author), All India Inst Med Sci, Dept Community Med, Room 420 Dept Community Med,Plot 2,Sect 20, Nagpur 441108, Maharashtra, India.	aravindsocialdoc@gmail.com	Satapathy, Prakasini/HNQ-9666-2023; Padhi, Bijaya K/E-7102-2010; Khatib, Mahalaqua Nazli/E-7308-2010; Quazi, Syed Zahiruddin/IWM-4926-2023; Gaidhane, Shilpa/AAL-2089-2020	Satapathy, Prakasini/0000-0001-7614-8587; Padhi, Bijaya K/0000-0001-7614-8587; Khatib, Mahalaqua Nazli/0000-0001-5875-8277; Quazi, Syed Zahiruddin/0000-0002-1435-899X; Gaidhane, Shilpa/0000-0002-3012-7438; Dayama, Sonal/0000-0003-4938-5020; Rajagopal, Vineeth/0000-0001-7204-8888; Aparnavi, P/0000-0001-8671-7261; Gandhi P, Aravind/0000-0003-3898-5450				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Abdulai AF, 2023, NURS INQ, V30, DOI 10.1111/nin.12556; Ahmed F U, 2008, Indian J Public Health, V52, P194; Alaagib NA, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1799-0; [Anonymous], 2018, Competency based undergraduate curriculum for the Indian Medical Graduate., VII; [Anonymous], CHATGPT: Optimizing language models for dialogue; [Anonymous], ChatGPT statistics 2023 revealed: insights and trends; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Educator considerations for ChatGPT, About us; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gemini. Google, About us; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Guze Phyllis A, 2015, Trans Am Clin Climatol Assoc, V126, P260; Hu K., 2023, Reuters; Huang JS, 2023, AM J CANCER RES, V13, P1148; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Karabacak M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48163; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee H, 2023, JMIR MED EDUC, V9, DOI 10.2196/47427; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Periaysamy AG, 2023, ANN MED SURG, V85, P1317, DOI 10.1097/MS9.0000000000000371; Rosenblatt K., 2023, NBC News; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Seo K, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00292-9; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140	32	0	0	4	4	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2024	8								e49964	10.2196/49964	http://dx.doi.org/10.2196/49964			8	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	MT9G3	38526538	Green Published, gold			2024-07-03	WOS:001195998600002
J	Ball, R; Talal, AH; Dang, O; Munoz, M; Markatou, M				Ball, Robert; Talal, Andrew H.; Dang, Oanh; Munoz, Monica; Markatou, Marianthi			Trust but Verify: Lessons Learned for the Application of AI to Case-Based Clinical Decision-Making From Postmarketing Drug Safety Assessment at the US Food and Drug Administration	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						drug safety; artificial intelligence; machine learning; natural language processing; causal inference; case-based reasoning; clinical decision support	TEXT MINING SYSTEM; CAUSALITY ASSESSMENT; ADVERSE; CLASSIFICATION	Adverse drug reactions are a common cause of morbidity in health care. The US Food and Drug Administration (FDA) evaluates individual case safety reports of adverse events (AEs) after submission to the FDA Adverse Event Reporting System as part of its surveillance activities. Over the past decade, the FDA has explored the application of artificial intelligence (AI) to evaluate these reports to improve the efficiency and scientific rigor of the process. However, a gap remains between AI algorithm development and deployment. This viewpoint aims to describe the lessons learned from our experience and research needed to address both general issues in case-based reasoning using AI and specific needs for individual case safety report assessment. Beginning with the recognition that the trustworthiness of the AI algorithm is the main determinant of its acceptance by human experts, we apply the Diffusion of Innovations theory to help explain why certain algorithms for evaluating AEs at the FDA were accepted by safety reviewers and others were not. This analysis reveals that the process by which clinicians decide from case reports whether a drug is likely to cause an AE is not well defined beyond general principles. This makes the development of high performing, transparent, and explainable AI algorithms challenging, leading to a lack of trust by the safety reviewers. Even accounting for the introduction of large language models, the pharmacovigilance community needs an improved understanding of causal inference and of the cognitive framework for determining the causal relationship between a drug and an AE. We describe specific future research directions that underpin facilitating implementation and trust in AI for drug safety applications, including improved methods for measuring and controlling of algorithmic uncertainty, computational reproducibility, and clear articulation of a cognitive framework for causal inference in case-based reasoning.	[Ball, Robert; Dang, Oanh; Munoz, Monica] US FDA, Off Surveillance & Epidemiol, Ctr Drug Evaluat & Res, 10903 New Hampshire Ave, Silver Spring, MD 20993 USA; [Talal, Andrew H.] Jacobs Sch Med & Biomed Sci, Buffalo, NY USA; [Markatou, Marianthi] Univ Buffalo, Sch Publ Hlth & Hlth Profess, Buffalo, NY 14260 USA	US Food & Drug Administration (FDA); State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Ball, R (corresponding author), US FDA, Off Surveillance & Epidemiol, Ctr Drug Evaluat & Res, 10903 New Hampshire Ave, Silver Spring, MD 20993 USA.	robert.ball@fda.hhs.gov		Markatou, Marianthi/0000-0002-1453-8229; Munoz, Monica/0000-0001-9754-1986	Troup Fund of the Kaleida Health Foundation	Troup Fund of the Kaleida Health Foundation	The authors thank the safety reviewers in the Office of Surveillance and Epidemiology, Center for Drug Evaluation and Research, Food and Drug Administration (FDA) , who provided valuable feedback on the acceptance of artificial intelligence algorithms for pharmacovigilance. Representatives of the FDA reviewed a draft of the manuscript for presence of confidential information and accuracy regarding presentation of any FDA policy statements. The views expressed are those of the authors and not necessarily those of the US FDA. This work was also partially supported by the Troup Fund of the Kaleida Health Foundation.	Afendras G, 2019, J STAT PLAN INFER, V199, P286, DOI 10.1016/j.jspi.2018.07.005; Afendras G, 2017, ICSA BOOK SER STAT, P27, DOI 10.1007/978-3-319-69416-0_2; Agbabiaka TB, 2008, DRUG SAFETY, V31, P21, DOI 10.2165/00002018-200831010-00003; [Anonymous], 2021, Artificial Intelligence Index Report 2021; [Anonymous], Best practices in drug and biological product Postmarket safety surveillance for FDA staff; [Anonymous], Using artificial intelligence and machine learning in the development of drug and biological products; Baer B, 2016, METHOD INFORM MED, V55, P144, DOI 10.3414/ME14-01-0066; Ball R, 2022, DRUG SAFETY, V45, P429, DOI 10.1007/s40264-022-01157-4; Bloomgren G, 2012, NEW ENGL J MED, V366, P1870, DOI 10.1056/NEJMoa1107829; Botsis T, 2013, APPL CLIN INFORM, V4, P88, DOI 10.4338/ACI-2012-11-RA-0049; Botsis T, 2016, J BIOMED INFORM, V64, P354, DOI 10.1016/j.jbi.2016.07.023; Botsis T, 2013, DRUG SAFETY, V36, P573, DOI 10.1007/s40264-013-0064-4; Botsis T, 2012, J AM MED INFORM ASSN, V19, P1011, DOI 10.1136/amiajnl-2012-000881; Botsis T, 2011, J AM MED INFORM ASSN, V18, P631, DOI 10.1136/amiajnl-2010-000022; BOX GEP, 1976, J AM STAT ASSOC, V71, P791, DOI 10.2307/2286841; Brown JS, 2022, J AM MED INFORM ASSN, V29, P2191, DOI 10.1093/jamia/ocac153; Bulatao I, 2020, CLIN PHARMACOL THER, V108, P1243, DOI 10.1002/cpt.1948; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Croteau D, 2022, DRUG SAFETY, V45, P169, DOI 10.1007/s40264-021-01142-3; Edwards IR, 2017, DRUG SAFETY, V40, P365, DOI 10.1007/s40264-017-0509-2; Han L, 2017, J AM MED INFORM ASSN, V24, P913, DOI 10.1093/jamia/ocx022; Hodges J.S., 1987, Statistical Science, V2, P259, DOI [DOI 10.1214/SS/1177013224, DOI 10.1214/ss/1177013224]; Hüllermeier E, 2021, MACH LEARN, V110, P457, DOI 10.1007/s10994-021-05946-3; Montañez MI, 2017, FRONT IMMUNOL, V8, DOI 10.3389/fimmu.2017.00614; Kravitz RL., Design and implementation of n-of-1 trials: a user's guide; Kreimeyer K., 2022, Front Drug Saf Regul, V2, DOI [10.3389/fdsfr.2022.918897, DOI 10.3389/FDSFR.2022.918897]; Kreimeyer K, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104517; Kreimeyer K, 2017, DRUG SAFETY, V40, P571, DOI 10.1007/s40264-017-0523-4; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Laber EB, 2011, J AM STAT ASSOC, V106, P904, DOI 10.1198/jasa.2010.tm10053; Lavesson N., 2006, P 21 NAT C ART INT B, V6, P395; Lester J, 2013, PHARMACOEPIDEM DR S, V22, P302, DOI 10.1002/pds.3395; Liu KL, 2016, ANNU REV STAT APPL, V3, P78, DOI 10.1146/annurev-statistics-010814-020310; Liu Q, 2023, CLIN PHARMACOL THER, V113, P771, DOI 10.1002/cpt.2668; Markatou M, 2005, J MACH LEARN RES, V6, P1127; Marques FPC, 2022, PATTERN RECOGN LETT, V158, P171, DOI 10.1016/j.patrec.2022.04.031; Mentch L, 2016, J MACH LEARN RES, V17; Munoz MA, 2020, DRUG SAFETY, V43, P329, DOI 10.1007/s40264-019-00897-0; Norén GN, 2017, DRUG SAFETY, V40, P543, DOI 10.1007/s40264-017-0548-8; Pinnow E, 2018, CLIN PHARMACOL THER, V104, P390, DOI 10.1002/cpt.944; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Rogers E.M., 2010, DIFFUSION INNOVATION; Senge R, 2014, INFORM SCIENCES, V255, P16, DOI 10.1016/j.ins.2013.07.030; Spiker J, 2020, DRUG SAFETY, V43, P905, DOI 10.1007/s40264-020-00945-0; Subbiah V, 2023, NAT MED, V29, P49, DOI 10.1038/s41591-022-02160-z; Tregunno PM, 2014, DRUG SAFETY, V37, P249, DOI 10.1007/s40264-014-0146-y; Wang Q, 2014, STAT SINICA, V24, P1117, DOI 10.5705/ss.2012.215; Wang W, 2016, J BIOMED INFORM, V62, P78, DOI 10.1016/j.jbi.2016.06.006; Whitaker HJ, 2006, STAT MED, V25, P1768, DOI 10.1002/sim.2302; Whitaker HJ, 2019, ANNU REV STAT APPL, V6, P241, DOI 10.1146/annurev-statistics-030718-105108	50	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	JUN 6	2024	26								e50274	10.2196/50274	http://dx.doi.org/10.2196/50274			14	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	TV9Z9	38842929	gold			2024-07-03	WOS:001244166300001
J	Ji, J; Hou, YS; Chen, XY; Pan, YC; Xiang, Y				Ji, Jia; Hou, Yongshuai; Chen, Xinyu; Pan, Youcheng; Xiang, Yang			Vision-Language Model for Generating Textual Descriptions From Clinical Images: Model Development and Validation Study	JMIR FORMATIVE RESEARCH			English	Article						clinical image; radiology report generation; vision-language model; multistage fine-tuning; prior knowledge		Background: The automatic generation of radiology reports, which seeks to create a free -text description from a clinical radiograph, is emerging as a pivotal intersection between clinical medicine and artificial intelligence. Leveraging natural language processing technologies can accelerate report creation, enhancing health care quality and standardization. However, most existing studies have not yet fully tapped into the combined potential of advanced language and vision models. Objective: The purpose of this study was to explore the integration of pretrained vision -language models into radiology report generation. This would enable the vision -language model to automatically convert clinical images into high -quality textual reports. Methods: In our research, we introduced a radiology report generation model named ClinicalBLIP, building upon the foundational InstructBLIP model and refining it using clinical image -to -text data sets. A multistage fine-tuning approach via low -rank adaptation was proposed to deepen the semantic comprehension of the visual encoder and the large language model for clinical imagery. Furthermore, prior knowledge was integrated through prompt learning to enhance the precision of the reports generated. Experiments were conducted on both the IU X-RAY and MIMIC-CXR data sets, with ClinicalBLIP compared to several leading methods. Results: Experimental results revealed that ClinicalBLIP obtained superior scores of 0.570/0.365 and 0.534/0.313 on the IU X-RAY/MIMIC-CXR test sets for the Metric for Evaluation of Translation with Explicit Ordering (METEOR) and the Recall -Oriented Understudy for Gisting Evaluation (ROUGE) evaluations, respectively. This performance notably surpasses that of existing state-of-the-art methods. Further evaluations confirmed the effectiveness of the multistage fine-tuning and the integration of prior information, leading to substantial improvements. Conclusions: The proposed ClinicalBLIP model demonstrated robustness and effectiveness in enhancing clinical radiology report generation, suggesting significant promise for real -world clinical applications.	[Ji, Jia] Shenzhen Inst Informat Technol, Shenzhen, Peoples R China; [Hou, Yongshuai; Pan, Youcheng; Xiang, Yang] Peng Cheng Lab, 2 Xingke 1st St, Shenzhen 518000, Peoples R China; [Chen, Xinyu] Harbin Inst Technol, Shenzhen, Peoples R China	Shenzhen Institute of Information Technology; Peng Cheng Laboratory; Harbin Institute of Technology	Pan, YC (corresponding author), Peng Cheng Lab, 2 Xingke 1st St, Shenzhen 518000, Peoples R China.	panyoucheng4@gmail.com		Pan, Youcheng/0000-0002-8270-5455; Xiang, Yang/0000-0003-1395-6805	Research Project of Shenzhen Institute of Information Technology [SZIIT2022KJ050]; China Postdoctoral Science Foundation [2023M741843]; Natural Science Foundation of China [62106115]	Research Project of Shenzhen Institute of Information Technology; China Postdoctoral Science Foundation(China Postdoctoral Science Foundation); Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Acknowledgments This work was jointly supported by grants from the Research Project of Shenzhen Institute of Information Technology (grant SZIIT2022KJ050) , and the project was funded by the China Postdoctoral Science Foundation (grant 2023M741843) , and the Natural Science Foundation of China (grant 62106115) .	Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chen Weizhu, 2022, 10 INT C LEARNING RE; Chen Z., 2021, P 59 ANN M ASS COMP, P5904, DOI DOI 10.18653/V1/2021.ACL-LONG.459; Chen ZH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1439; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Hou WJ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P8108; Jia C, 2021, PR MACH LEARN RES, V139; Li CY, 2019, AAAI CONF ARTIF INTE, P6666; Li J., 2023, P MACHINE LEARNING R, P19730; Li JN, 2022, PR MACH LEARN RES; Li YX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P16464; Li YX, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P10757; Li YX, 2023, Arxiv, DOI arXiv:2305.03701; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu FL, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P269; Liu FL, 2021, PROC CVPR IEEE, P13748, DOI 10.1109/CVPR46437.2021.01354; Liu FL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3001; Nooralahzadeh F, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2824; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pino P, 2021, LECT NOTES COMPUT SC, V12966, P654, DOI 10.1007/978-3-030-87589-3_67; Qin H, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P448; Radford A, 2021, PR MACH LEARN RES, V139; Shin HC, 2016, PROC CVPR IEEE, P2497, DOI 10.1109/CVPR.2016.274; Smit A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1500; Song X., 2022, P 29 INT C COMP LING, P2388; Vaswani A, 2017, ADV NEUR IN, V30; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang X., 2021, J Artif Intell Med Sci., V2, P21, DOI [DOI 10.2991/JAIMS.D.210428.002, 10.2991/jaims.d.210428.002]; Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369; Yang SX, 2022, MED IMAGE ANAL, V80, DOI 10.1016/j.media.2022.102510; You D, 2021, LECT NOTES COMPUT SC, V12903, P72, DOI 10.1007/978-3-030-87199-4_7; Yuan JB, 2019, LECT NOTES COMPUT SC, V11769, P721, DOI 10.1007/978-3-030-32226-7_80	34	0	0	5	5	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2024	8								e32690	10.2196/32690	http://dx.doi.org/10.2196/32690			13	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	IG3X9	38329788	gold, Green Published			2024-07-03	WOS:001165148700001
J	Madrid-Garcia, A; Rosales-Rosado, Z; Freites-Nunez, D; Perez-Sancristobal, I; Pato-Cour, E; Plasencia-Rodriguez, C; Cabeza-Osorio, L; Abasolo-Alcazar, L; Leon-Mateos, L; Fernandez-Gutierrez, B; Rodriguez-Rodriguez, L				Madrid-Garcia, Alfredo; Rosales-Rosado, Zulema; Freites-Nunez, Dalifer; Perez-Sancristobal, Ines; Pato-Cour, Esperanza; Plasencia-Rodriguez, Chamaida; Cabeza-Osorio, Luis; Abasolo-Alcazar, Lydia; Leon-Mateos, Leticia; Fernandez-Gutierrez, Benjamin; Rodriguez-Rodriguez, Luis			Harnessing ChatGPT and GPT-4 for evaluating the rheumatology questions of the Spanish access exam to specialized medical training	SCIENTIFIC REPORTS			English	Article							INTERRATER RELIABILITY; HIGH AGREEMENT; LOW KAPPA	The emergence of large language models (LLM) with remarkable performance such as ChatGPT and GPT-4, has led to an unprecedented uptake in the population. One of their most promising and studied applications concerns education due to their ability to understand and generate human-like text, creating a multitude of opportunities for enhancing educational practices and outcomes. The objective of this study is twofold: to assess the accuracy of ChatGPT/GPT-4 in answering rheumatology questions from the access exam to specialized medical training in Spain (MIR), and to evaluate the medical reasoning followed by these LLM to answer those questions. A dataset, RheumaMIR, of 145 rheumatology-related questions, extracted from the exams held between 2010 and 2023, was created for that purpose, used as a prompt for the LLM, and was publicly distributed. Six rheumatologists with clinical and teaching experience evaluated the clinical reasoning of the chatbots using a 5-point Likert scale and their degree of agreement was analyzed. The association between variables that could influence the models' accuracy (i.e., year of the exam question, disease addressed, type of question and genre) was studied. ChatGPT demonstrated a high level of performance in both accuracy, 66.43%, and clinical reasoning, median (Q1-Q3), 4.5 (2.33-4.67). However, GPT-4 showed better performance with an accuracy score of 93.71% and a median clinical reasoning value of 4.67 (4.5-4.83). These findings suggest that LLM may serve as valuable tools in rheumatology education, aiding in exam preparation and supplementing traditional teaching methods.	[Madrid-Garcia, Alfredo; Rosales-Rosado, Zulema; Freites-Nunez, Dalifer; Perez-Sancristobal, Ines; Pato-Cour, Esperanza; Abasolo-Alcazar, Lydia; Leon-Mateos, Leticia; Fernandez-Gutierrez, Benjamin; Rodriguez-Rodriguez, Luis] Inst Invest Sanitaria Hosp Clin San Carlos IdISSC, Hosp Clin San Carlos, Grp Patol Musculoesquelet, Prof Martin Lagos S-N, Madrid 28040, Spain; [Plasencia-Rodriguez, Chamaida] Hosp Univ La Paz IdiPaz, Reumatol, Paseo Castellana,261, Madrid 28046, Spain; [Cabeza-Osorio, Luis] Hosp Univ Henares, Med Interna, Ave Marie Curie,0, Madrid 28822, Spain; [Cabeza-Osorio, Luis] Univ Francisco Vitoria, Fac Med, Carretera Pozuelo,Km 1800, Madrid 28223, Spain; [Fernandez-Gutierrez, Benjamin] Univ Complutense Madrid, Fac Med, Madrid, Spain	Hospital Clinico San Carlos; Hospital Universitario La Paz; Universidad Francisco de Vitoria; Complutense University of Madrid	Madrid-Garcia, A (corresponding author), Inst Invest Sanitaria Hosp Clin San Carlos IdISSC, Hosp Clin San Carlos, Grp Patol Musculoesquelet, Prof Martin Lagos S-N, Madrid 28040, Spain.	alfredo.madrid@salud.madrid.org	Madrid, Alfredo/ABC-6134-2021; Leon, Leticia/HKO-1151-2023	Madrid, Alfredo/0000-0002-1591-0467; Leon, Leticia/0000-0001-7142-0545; Perez-Sancristobal, Ines/0000-0002-2098-4313; Pato, Esperanza/0000-0002-4145-7395; Fernandez-Gutierrez, Benjamin/0000-0002-6126-8786; Freites Nunez, Dalifer/0000-0002-0966-2778	Instituto de Salud Carlos III, Ministry of Health, Madrid, Spain	Instituto de Salud Carlos III, Ministry of Health, Madrid, Spain(Instituto de Salud Carlos III)	No Statement Available	[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Beltrami Eric J, 2024, J Am Acad Dermatol, V90, P879, DOI 10.1016/j.jaad.2023.02.052; Biswas S, 2023, ANN BIOMED ENG, V51, P1885, DOI 10.1007/s10439-023-03224-y; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Carrasco JP., 2023, Rev. Esp. Educ. Med, V4, P1; CICCHETTI DV, 1990, J CLIN EPIDEMIOL, V43, P551, DOI 10.1016/0895-4356(90)90159-M; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Dennean K., 2023, LETS CHAT CHATGPT; FEINSTEIN AR, 1990, J CLIN EPIDEMIOL, V43, P543, DOI 10.1016/0895-4356(90)90158-L; Feng GC, 2015, METHODOLOGY-EUR, V11, P13, DOI 10.1027/1614-2241/a000086; Feng SW, 2023, ACAD MED, V98, P867, DOI 10.1097/ACM.0000000000005242; Ferrara E., 2023, Should ChatGPT be biased? Challenges and risks of bias in large language models, DOI [10.5210/fm.v28i11.13346, DOI 10.5210/FM.V28I11.13346]; Garcia Alfredo Madrid, 2023, Zenodo, DOI 10.5281/ZENODO.8153291; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Grabb D, 2023, ACAD PSYCHIATR, V47, P439, DOI 10.1007/s40596-023-01791-9; Gwet KL, 2008, BRIT J MATH STAT PSY, V61, P29, DOI 10.1348/000711006X126600; Hawkins R. D., 2023, PREPRINT; He YB, 2023, INT J SURG, V109, P2544, DOI 10.1097/JS9.0000000000000453; Huang JS, 2023, AM J CANCER RES, V13, P1148; Hügle T, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003105; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Jansz J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36302; Jin Q., 2023, PREPRINT; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Kang YB, 2023, AESTHET PLAST SURG, V47, P2190, DOI 10.1007/s00266-023-03372-5; Knitza J, 2021, ARTHRITIS RES THER, V23, DOI 10.1186/s13075-021-02616-6; Krumborg JR, 2023, BASIC CLIN PHARMACOL, V133, P3, DOI 10.1111/bcpt.13879; Krusche M, 2024, RHEUMATOL INT, V44, P303, DOI 10.1007/s00296-023-05464-6; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Li WB, 2023, ANN BIOMED ENG, V51, P1892, DOI 10.1007/s10439-023-03232-y; Madrid-García A, 2023, SEMIN ARTHRITIS RHEU, V61, DOI 10.1016/j.semarthrit.2023.152213; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Munaf U, 2023, ACAD MED, V98, P868, DOI 10.1097/ACM.0000000000005250; Nakhleh A, 2023, DIABETES TECHNOL THE, V25, P571, DOI 10.1089/dia.2023.0134; OpenAI, 2023, PREPRINT; Quarfoot D, 2016, AM STAT, V70, P373, DOI 10.1080/00031305.2016.1141708; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sanidad G., 2022, PREPRINT; Seetharaman R, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01957-w; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Sifat RI, 2023, ANN BIOMED ENG, V51, P1357, DOI 10.1007/s10439-023-03204-2; Solomon DH, 2023, ARTHRITIS RHEUMATOL, V75, P867, DOI 10.1002/art.42497; Strong E, 2023, medRxiv, DOI [10.1101/2023.03.24.23287731, 10.1101/2023.03.24.23287731, DOI 10.1101/2023.03.24.23287731]; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Teixeira da Silva JA, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2023.101005; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749; van de Ridder JMM, 2023, ACAD MED, V98, P867, DOI 10.1097/ACM.0000000000005254; Verhoeven F, 2023, ANN RHEUM DIS, V82, P1015, DOI 10.1136/ard-2023-223936; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	56	4	4	4	5	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	DEC 13	2023	13	1							22129	10.1038/s41598-023-49483-6	http://dx.doi.org/10.1038/s41598-023-49483-6			11	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CP0H2	38092821	Green Submitted, gold			2024-07-03	WOS:001126327000013
C	Jiang, ZY; Shi, L; Yang, GW; Wang, Q			IEEE	Jiang, Ziyou; Shi, Lin; Yang, Guowei; Wang, Qing			SCPatcher: Mining Crowd Security Discussions to Enrich Secure Coding Practices	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc				Secure coding practices (SCPs) have been proposed to guide software developers to write code securely to prevent potential security vulnerabilities. Yet, they are typically one-sentence principles without detailed specifications, e.g., "Properly free allocated memory upon the completion of functions and at all exit points.", which makes them difficult to follow in practice, especially for software developers who are not yet experienced in secure programming. To address this problem, this paper proposes SCPatcher, an automated approach to enrich secure coding practices by mining crowd security discussions on online knowledge-sharing platforms, such as Stack Overflow. In particular, for each security post, SCPatcher first extracts the area of coding examples and coding explanations with a fix-prompt tuned Large Language Model (LLM) via Prompt Learning. Then, it hierarchically slices the lengthy code into coding examples and summarizes the coding explanations with the areas. Finally, SCPatcher matches the CWE and Public SCP, integrating them with extracted coding examples and explanations to form the SCP specifications, which are the wild SCPs with details, proposed by the developers. To evaluate the performance of SCPatcher, we conduct experiments on 3,907 security posts from Stack Overflow. The experimental results show that SCPatcher outperforms all baselines in extracting the coding examples with 2.73% MLine on average, as well as coding explanations with 3.97% F1 on average. Moreover, we apply SCPatcher on 447 new security posts to further evaluate its practicality, and the extracted SCP specifications enrich the public SCPs with 3,074 lines of code and 1,967 sentences.	[Jiang, Ziyou; Wang, Qing] State Key Lab Intelligent Game, Beijing, Peoples R China; [Jiang, Ziyou; Wang, Qing] Chinese Acad Sci, Sci & Technol Integrated Informat Syst Lab, Inst Software, Beijing, Peoples R China; [Jiang, Ziyou; Wang, Qing] Univ Chinese Acad Sci, Beijing, Peoples R China; [Shi, Lin] Beihang Univ, Sch Software, Beijing, Peoples R China; [Yang, Guowei] Univ Queensland, Brisbane, Qld, Australia	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Beihang University; University of Queensland	Wang, Q (corresponding author), State Key Lab Intelligent Game, Beijing, Peoples R China.; Wang, Q (corresponding author), Chinese Acad Sci, Sci & Technol Integrated Informat Syst Lab, Inst Software, Beijing, Peoples R China.; Wang, Q (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.	ziyou2019@iscas.ac.cn; shilin@buaa.edu.cn; guowei.yang@uq.edu.au; wq@iscas.ac.cn	Yang, Guowei/AAY-5880-2021	Yang, Guowei/0000-0002-1404-4560	National Natural Science Foundation of China [62272445, 62232016, 62072442]; Youth Innovation Promotion Association Chinese Academy of Sciences; University of Queensland NSRSG [NS-2201]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association Chinese Academy of Sciences; University of Queensland NSRSG(University of Queensland)	We sincerely appreciate anonymous reviewers for their constructive and insightful suggestions for improving this manuscript. This work is supported by the National Natural Science Foundation of China Grant No. 62272445, 62232016, 62072442, the Youth Innovation Promotion Association Chinese Academy of Sciences, and the University of Queensland NSRSG Grant NS-2201.	Acar Y, 2017, 2017 IEEE CYBERSECURITY DEVELOPMENT (SECDEV), P22, DOI 10.1109/SecDev.2017.17; Adolphs L., 2022, The CRINGE loss: Learning what language not to model; Anis A, 2018, 2018 16TH IEEE INT CONF ON DEPENDABLE, AUTONOM AND SECURE COMP, 16TH IEEE INT CONF ON PERVAS INTELLIGENCE AND COMP, 4TH IEEE INT CONF ON BIG DATA INTELLIGENCE AND COMP, 3RD IEEE CYBER SCI AND TECHNOL CONGRESS (DASC/PICOM/DATACOM/CYBERSCITECH), P618, DOI 10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.00112; Berkeley U., 2023, Secure Coding Practice Guidelines; Betz G., 2021, Thinking aloud: Dynamic context generation improves zero-shot reasoning performance of GPT-2; Bin Nazim MT, 2022, 2022 IEEE 46TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2022), P1768, DOI 10.1109/COMPSAC54236.2022.00281; Brown T. B., 2020, Advances in Neural Information Processing Systems, V33; Chi H., 2013, Proceedings of the 2013 on InfoSecCD'13: Information Security Curriculum Development Conference, InfoSecCD'13, P42; Cochard V, 2022, 2022 IEEE 7TH EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2022), P60, DOI 10.1109/EuroSP53844.2022.00012; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Exchange S., 2022, Stack Exchange Sites; Google, 2023, Best Practices for Privacy and Security; Gorski PL, 2022, IEEE T SOFTWARE ENG, V48, P3467, DOI 10.1109/TSE.2021.3094171; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu YM, 2023, FRONT COMPUT SCI-CHI, V17, DOI 10.1007/s11704-022-2313-0; Khalili A, 2016, EMPIR SOFTW ENG, V21, P4, DOI 10.1007/s10664-014-9341-9; Lan Z., 2020, 8 INT C LEARNING RE; LaValle SM, 2004, INT J ROBOT RES, V23, P673, DOI 10.1177/0278364904045481; Le T. H. M., 2020, CoRR; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu SG, 2020, IEEE T FUZZY SYST, V28, P1329, DOI 10.1109/TFUZZ.2019.2958558; Liu X., 2021, GPT understands, too; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Lopez T, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN SOCIETY (ICSE-SEIS 2019), P31, DOI 10.1109/ICSE-SEIS.2019.00012; Lopez T, 2018, 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SECURITY AWARENESS FROM DESIGN TO DEPLOYMENT (SEAD), P26, DOI [10.23919/SEAD.2018.8472850, 10.1145/3194707.3194713]; M.Corporation, 2021, Common weakness enumeration; Madabushi Harish Tayyar, 2019, P 2 WORKSH NAT LANG, P125; Margatina K., 2019, Papers Association for Computational Linguistics, V1, P7944; Meng N, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P372, DOI 10.1145/3180155.3180201; Meyers BS, 2019, 2019 IEEE/ACM 12TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING (CHASE 2019), P79, DOI 10.1109/CHASE.2019.00026; Mnih V, 2014, ADV NEUR IN, V27; Overflow S., 2022, Stack Overflow-Where Developers Learn, Share, & Build Careers; OWASP, 2022, Secure Coding Practices Quick Reference Guide; Pan Shengyi, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P834, DOI 10.1145/3540250.3549156; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pérez J, 2020, J SYST SOFTWARE, V168, DOI 10.1016/j.jss.2020.110657; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Python, 2014, pyparser 0.1; Raffel C, 2020, J MACH LEARN RES, V21; Replication Package for, 2023, Zenodo, DOI [10.5281/zenodo.8254682, DOI 10.5281/ZENODO.8254682]; Salimi S, 2022, J SYST SOFTWARE, V193, DOI 10.1016/j.jss.2022.111450; Schick T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P390; Shi ES, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4053; Shi L, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P142, DOI 10.1109/ASE51524.2021.9678894; Singleton Larry, 2020, SIGITE '20: Proceedings of the 21st Annual Conference on Information Technology Education, P403, DOI 10.1145/3368308.3415419; Sun C., 2019, P 5 WORKSH BIONLP OP, P100, DOI 10.18653/v1/D19-5715; Le THM, 2021, PROCEEDINGS OF EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING (EASE 2021), P109, DOI 10.1145/3463274.3463331; van Puffelen F., 2022, Best Practices for Firebase Data Models; Vaswani A, 2017, ADV NEUR IN, V30; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Yang XL, 2016, J COMPUT SCI TECH-CH, V31, P910, DOI 10.1007/s11390-016-1672-0; Yoo KM, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2225; Zahedi M, 2018, PROCEEDINGS OF THE 51ST ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES (HICSS), P5504; Zhang J, 2019, PROC INT CONF SOFTW, P783, DOI 10.1109/ICSE.2019.00086	57	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							358	370		10.1109/ASE56229.2023.00040	http://dx.doi.org/10.1109/ASE56229.2023.00040			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200029
C	Pan, JY; Chou, G; Berenson, D			IEEE	Pan, Jiayi; Chou, Glen; Berenson, Dmitry			Data-Efficient Learning of Natural Language to Linear Temporal Logic Translators for Robot Task Specification	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc				To make robots accessible to a broad audience, it is critical to endow them with the ability to take universal modes of communication, like commands given in natural language, and extract a concrete desired task specification, defined using a formal language like linear temporal logic (LTL). In this paper, we present a learning-based approach for translating from natural language commands to LTL specifications with very limited human-labeled training data. This is in stark contrast to existing natural-language to LTL translators, which require large human-labeled datasets, often in the form of labeled pairs of LTL formulas and natural language commands, to train the translator. To reduce reliance on human data, our approach generates a large synthetic training dataset through algorithmic generation of LTL formulas, conversion to structured English, and then exploiting the paraphrasing capabilities of modern large language models (LLMs) to synthesize a diverse corpus of natural language commands corresponding to the LTL formulas. We use this generated data to finetune an LLM and apply a constrained decoding procedure at inference time to ensure the returned LTL formula is syntactically correct. We evaluate our approach on three existing LTL/natural language datasets and show that we can translate natural language commands at 75% accuracy with far less human data (<= 12 annotations). Moreover, when training on large human-annotated datasets, our method achieves higher test accuracy (95% on average) than prior work. Finally, we show the translated formulas can be used to plan long-horizon, multi-stage tasks on a 12D quadrotor.	[Pan, Jiayi; Chou, Glen; Berenson, Dmitry] Univ Michigan, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan	Pan, JY (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.	jiayipan@umich.edu; gchou@umich.edu; dmitryb@umich.edu						Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; [Anonymous], 2021, INT J ROBOTICS RES, DOI DOI 10.1186/S13046-020-01760-2; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Baier C, 2008, PRINCIPLES OF MODEL CHECKING, P1; Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133; Berg M, 2020, IEEE INT CONF ROBOT, P208, DOI [10.1109/icra40945.2020.9197068, 10.1109/ICRA40945.2020.9197068]; Brown Tom B., 2020, Advances in Neural Information Processing Systems; Cherukuri H, 2022, LECT NOTES COMPUT SC, V13216, P79, DOI 10.1007/978-3-030-98464-9_7; Chou G., 2021, C ROBOT LEARNING, P1612; Chou G, 2022, IEEE ROBOT AUTOM LET, V7, P3827, DOI 10.1109/LRA.2022.3148436; Chou G, 2022, AUTON ROBOT, V46, P149, DOI 10.1007/s10514-021-10004-x; Chou G, 2020, ROBOTICS: SCIENCE AND SYSTEMS XVI; Chou G, 2020, IEEE ROBOT AUTOM LET, V5, P3682, DOI 10.1109/LRA.2020.2974427; Das A, 2018, INT SYMP NETW CHIP; Finucane C, 2010, IEEE INT C INT ROBOT, P1988, DOI 10.1109/IROS.2010.5650371; Gopalan N., 2018, ROBOTICS SCI SYSTEMS; Hahn C., 2022, ARXIV220601962 CS; Hsiung E, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P3624, DOI 10.1109/ICRA46639.2022.9812169; Kress-Gazit H, 2008, ADV ROBOTICS, V22, P1343, DOI 10.1163/156855308X344864; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; MacGlashan J, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI; Nikora A. P., 2009, AUTOMATED IDENTIFICA; Oh Y., 2019, ROBOTICS SCI SYSTEMS; Pakonen A, 2016, IEEE INT C EMERG; Patel R., 2020, ROBOTICS SCI SYSTEMS; Perez-DArpino C., 2017, 2017 IEEE INT C ROB, P4058, DOI DOI 10.1109/ICRA.2017.7989466; Raffel C, 2020, J MACH LEARN RES, V21; Raman V, 2014, IEEE DECIS CONTR P, P81, DOI 10.1109/CDC.2014.7039363; Ranta A, 2011, LECT NOTES ARTIF INT, V6803, P5, DOI 10.1007/978-3-642-22438-6_3; Rongali S., 2022, P 31 INT JOINT C ART, P4353; Schlör R, 1998, LECT NOTES COMPUT SC, V1385, P208, DOI 10.1007/BFb0053507; Scobee Dexter R. R., 2020, 8 INT C LEARN REPR I; Shah A. J., 2020, INTERACTIVE ROBOT TR; Shah A, 2018, ADV NEUR IN, V31; Shin R., 2021, ARXIV210408768 CS; Srivastava Aarohi, 2022, ARXIV220604615; Sun YB, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P361; Vaswani A, 2017, ADV NEUR IN, V30; Vazquez-Chanlatte M., 2018, ADV NEURAL INFORM PR, V31, P5372; Wang C., 2020, P MACHINE LEARNING R, V155, P1706; Wang G, 2020, ACMIEEE INT CONF HUM, P649, DOI 10.1145/3319502.3374824; Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332; Xu SL, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P422; Yin PC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1455	44	0	0	3	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							11554	11561		10.1109/ICRA48891.2023.10161125	http://dx.doi.org/10.1109/ICRA48891.2023.10161125			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371103094
C	Seenivasan, L; Islam, M; Kannan, G; Ren, HL		Greenspan, H; Madabhushi, A; Mousavi, P; Salcudean, S; Duncan, J; Syeda-Mahmood, T; Taylor, R		Seenivasan, Lalithkumar; Islam, Mobarakol; Kannan, Gokul; Ren, Hongliang			SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery	MEDICAL IMAGE COMPUTING AND COMPUTER ASSISTED INTERVENTION, MICCAI 2023, PT IX	Lecture Notes in Computer Science		English	Proceedings Paper	26th International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)	OCT 08-12, 2023	Vancouver, CANADA				SIMULATION	Advances in GPT-based large language models (LLMs) are revolutionizing natural language processing, exponentially increasing its use across various domains. Incorporating uni-directional attention, these autoregressive LLMs can generate long and coherent paragraphs. However, for visual question answering (VQA) tasks that require both vision and language processing, models with bi-directional attention or models employing fusion techniques are often employed to capture the context of multiple modalities all at once. As GPT does not natively process vision tokens, to exploit the advancements in GPT models for VQA in robotic surgery, we design an end-to-end trainable Language-Vision GPT (LV-GPT) model that expands the GPT2 model to include vision input (image). The proposed LV-GPT incorporates a feature extractor (vision tokenizer) and vision token embedding (token type and pose). Given the limitations of unidirectional attention in GPT models and their ability to generate coherent long paragraphs, we carefully sequence the word tokens before vision tokens, mimicking the human thought process of understanding the question to infer an answer from an image. Quantitatively, we prove that the LV-GPT model outperforms other state-ofthe-art VQA models on two publically available surgical-VQA datasets (based on endoscopic vision challenge robotic scene segmentation 2018 and CholecTriplet2021) and on our newly annotated dataset (based on the holistic surgical scene dataset). We further annotate all three datasets to include question-type annotations to allow sub-type analysis. Furthermore, we extensively study and present the effects of token sequencing, token type and pose embedding for vision tokens in the LV-GPT model.	[Seenivasan, Lalithkumar; Ren, Hongliang] Natl Univ Singapore, Dept Biomed Engn, Singapore, Singapore; [Islam, Mobarakol] UCL, WEISS, London, England; [Kannan, Gokul] Natl Inst Technol, Dept Prod Engn, Tiruchirappalli, India; [Ren, Hongliang] Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China; [Ren, Hongliang] Chinese Univ Hong Kong, Shun Hing Inst Adv Engn, Shatin, Hong Kong, Peoples R China	National University of Singapore; University of London; University College London; National Institute of Technology (NIT System); National Institute of Technology Tiruchirappalli; Chinese University of Hong Kong; Chinese University of Hong Kong	Ren, HL (corresponding author), Natl Univ Singapore, Dept Biomed Engn, Singapore, Singapore.; Ren, HL (corresponding author), Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.; Ren, HL (corresponding author), Chinese Univ Hong Kong, Shun Hing Inst Adv Engn, Shatin, Hong Kong, Peoples R China.	hlren@ee.cuhk.edu.hk	Islam, Mobarakol/GQZ-4100-2022; Ren, Hongliang/N-9194-2017	Islam, Mobarakol/0000-0002-7162-2822; K KRISHNA, ADITHYA/0000-0002-2284-703X; Ren, Hongliang/0000-0002-6488-1551	Hong Kong Research Grants Council (RGC) Collaborative Research Fund [CRF C4026-21GF, CRF C4063-18G]; Shun Hing Institute of Advanced Engineering at the Chinese University of Hong Kong [BME-p1-21/8115064]; EPSRC [EP/W00805X/1]	Hong Kong Research Grants Council (RGC) Collaborative Research Fund; Shun Hing Institute of Advanced Engineering at the Chinese University of Hong Kong; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work was supported by Hong Kong Research Grants Council (RGC) Collaborative Research Fund (CRF C4026-21GF and CRF C4063-18G) and Shun Hing Institute of Advanced Engineering (BME-p1-21/8115064) at the Chinese University of Hong Kong. M. Islam was funded by EPSRC grant [EP/W00805X/1].	ADAMS L, 1990, IEEE COMPUT GRAPH, V10, P43, DOI 10.1109/38.55152; Allan M, 2020, Arxiv, DOI [arXiv:2001.11190, DOI 10.48550/ARXIV.2001.11190, 10.48550/arXiv.2001.11190]; Bates DW, 2000, ANN INTERN MED, V132, P763, DOI 10.7326/0003-4819-132-9-200005020-00025; Ben-Younes H, 2019, AAAI CONF ARTIF INTE, P8102; Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Guo JX, 2022, Arxiv, DOI arXiv:2212.10846; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hong MS, 2021, VIRTUAL REAL-LONDON, V25, P491, DOI 10.1007/s10055-020-00469-z; Kneebone R, 2003, MED EDUC, V37, P267, DOI 10.1046/j.1365-2923.2003.01440.x; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Peng BL, 2021, Arxiv, DOI arXiv:2005.05298; Rogers DA, 1998, AM J SURG, V175, P508, DOI 10.1016/S0002-9610(98)00087-7; Sarker SK, 2007, INT J CLIN PRACT, V61, P2120, DOI 10.1111/j.1742-1241.2007.01435.x; Seenivasan L, 2022, LECT NOTES COMPUT SC, V13437, P33, DOI 10.1007/978-3-031-16449-1_4; Sharma D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98390-1; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957; Valderrama N, 2022, LECT NOTES COMPUT SC, V13437, P442, DOI 10.1007/978-3-031-16449-1_42; Wang S., 2023, arXiv; Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340; Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202	25	2	2	6	6	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-43995-7; 978-3-031-43996-4	LECT NOTES COMPUT SC			2023	14228						281	290		10.1007/978-3-031-43996-4_27	http://dx.doi.org/10.1007/978-3-031-43996-4_27			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Engineering, Biomedical	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW1RN		Green Submitted			2024-07-03	WOS:001109638800027
J	Abd-hood, SF; Omar, N				Abd-hood, Samia F.; Omar, Nazlia			Hashtag Segmentation: A Comparative Study Involving the Viterbi, Triangular Matrix and Word Breaker Algorithms	JOURNAL OF ADVANCES IN INFORMATION TECHNOLOGY			English	Article						hashtag segmentation; twitter; viterbi algorithm; word breaker algorithm; triangular matrix algorithm		Microblogging and social networking sites such as Twitter, Facebook, and Instagram, are becoming increasingly popular, registering more than 500 million posts each day. Twitter uses hashtags that are dynamic, user-generated text, preceded by a pound (#) symbol, to retrieve similar posts or topics, to mark events or to tag channels. Following segmentation, hashtags can be used for many Natural Language Processing (NLP) applications. These include sentiment analysis, text classification, named entity recognition, and sarcasm detection. This study delves into a comparison of three algorithms, namely the Viterbi, Triangular matrix and Word breaker algorithms, to determine the best among the three, for the segmentation of hashtags. These algorithms utilize different resources, to calculate the probability of the segmented parts, in order to rank the possible generated segmentations. For example, while the Viterbi and Triangular Matrix algorithms use two statistical corpora of unigram and bigram, the Word Breaker algorithm uses the n-gram language model. According to conducted experiment, the Viterbi algorithm is better for hashtag segmentation than the Triangular Matrix algorithm. This can be attributed to the manner in which the Viterbi algorithm conducts the backtracking. On the other hand, the Word Breaker algorithm, which can ascertain the meaningful tokens in the form of words, before proceeding with the segmentation of the remaining characters, is considered superior to both the Viterbi and Triangular Matrix algorithms, particularly when it comes to the detection of unknown words. Used together with the Good-Turing smoothing algorithm, the Word Breaker algorithm achieved 86.64% f1-score on a large language model.	[Abd-hood, Samia F.; Omar, Nazlia] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia; [Abd-hood, Samia F.] Hadhramout Univ, Hadhramout, Yemen	Universiti Kebangsaan Malaysia	Abd-hood, SF (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, Bangi, Malaysia.; Abd-hood, SF (corresponding author), Hadhramout Univ, Hadhramout, Yemen.	gp07233@siswa.ukm.edu.my; nazlia@ukm.edu.my	Abd-hood, Samia/IQT-1847-2023		UKM [GP-2020-K007009]	UKM	This project is funded by UKM under the research code GP-2020-K007009. The first author would like to thank Establishment of Hadhramout for Development and Humanity.	Al-Ghuribi SM, 2019, IEEE ACCESS, V7, P169446, DOI 10.1109/ACCESS.2019.2954861; Alfina I, 2017, P 9 INT C MACHINE LE, DOI [10.1145/3055635, DOI 10.1145/3055635.3056631, 10.1145/3055635.3056631]; Bansal Piyush, 2015, Advances in Information Retrieval. 37th European Conference on IR Research (ECIR 2015). Proceedings: LNCS 9022, P453, DOI 10.1007/978-3-319-16354-3_50; Bansal P, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P7, DOI 10.1145/2740908.2742717; Baziotis C., 2017, P 11 INT WORKSHOP, P747; Belainine Billal, 2016, P 2 WORKSH NOIS US G, P102; Cai D, 2016, Arxiv, DOI arXiv:1606.04300; Çelebi A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2981; Çelebi A, 2018, J ASSOC INF SCI TECH, V69, P675, DOI 10.1002/asi.23989; Declerck T., 2015, P INT C RECENT ADV N, P104; Doval Y, 2019, J ASSOC INF SCI TECH, V70, P187, DOI 10.1002/asi.24082; Glushkova T, 2019, Arxiv, DOI arXiv:1911.03270; Heafield K., 2011, P 6 WORKSHOP STAT MA, P187; Li XY, 2019, Arxiv, DOI arXiv:1905.05526; Ma J, 2018, Arxiv, DOI arXiv:1808.06511; Maddela M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2538; Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238; Omnicore A, 2020, TWITTER STAT; Peng G, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P336, DOI 10.1109/ICALIP.2016.7846561; Reuter J., 2016, INT J NAT LANG COMPU, V5, P23, DOI 10.5121/ijnlc.2016.5402; Saberi B., 2017, INT J ADV SCI ENG IN, V7, P1660, DOI DOI 10.18517/IJASEIT.7.5.2137; Sharma S., 2016, 2016 International Conference on Advances in Computing, Communication, Automation (ICACCA) (Spring), P1; Simeon C, 2016, PROCEEDINGS OF 3RD IEEE/ACM INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS, (DSAA 2016), P743, DOI 10.1109/DSAA.2016.80; Stolcke A, 2002, 7 INT C SPOKEN LANGU	24	0	0	1	2	ENGINEERING & TECHNOLOGY PUBLISHING	ROWLAND HEIGHTS	2448 DESIRE AVE, ROWLAND HEIGHTS, CA 91748 USA	1798-2340			J ADV INFORM TECHNOL	J. Adv. Inf. Technol.	NOV	2021	12	4					311	318		10.12720/jait.12.4.311-318	http://dx.doi.org/10.12720/jait.12.4.311-318			8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	6G7HN		gold			2024-07-03	WOS:000884922800006
J	Verbruggen, G; Le, V; Gulwani, S				Verbruggen, Gust; Le, Vu; Gulwani, Sumit			Semantic Programming by Example with Pre-trained Models	PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES-PACMPL			English	Article						program synthesis; programming by example; language models		The ability to learn programs from few examples is a powerful technology with disruptive applications in many domains, as it allows users to automate repetitive tasks in an intuitive way. Existing frameworks on inductive synthesis only perform syntactic manipulations, where they rely on the syntactic structure of the given examples and not their meaning. Any semantic manipulations, such as transforming dates, have to be manually encoded by the designer of the inductive programming framework. Recent advances in large language models have shown these models to be very adept at performing semantic transformations of its input by simply providing a few examples of the task at hand. When it comes to syntactic transformations, however, these models are limited in their expressive power. In this paper, we propose a novel framework for integrating inductive synthesis with few-shot learning language models to combine the strength of these two popular technologies. In particular, the inductive synthesis is tasked with breaking down the problem in smaller subproblems, among which those that cannot be solved syntactically are passed to the language model. We formalize three semantic operators that can be integrated with inductive synthesizers. To minimize invoking expensive semantic operators during learning, we introduce a novel deferred query execution algorithm that considers the operators to be oracles during learning. We evaluate our approach in the domain of string transformations: the combination methodology can automate tasks that cannot be handled using either technologies by themselves. Finally, we demonstrate the generality of our approach via a case study in the domain of string profiling.	[Verbruggen, Gust] Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium; [Le, Vu; Gulwani, Sumit] Microsoft, One Microsoft Way, Redmond, WA 98052 USA	KU Leuven; Microsoft	Verbruggen, G (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, Leuven, Belgium.	gust.verbruggen@kuleuven.be; levu@microsoft.com; sumitg@microsoft.com			European Research Council (ERC) under the European Union [694980]; Flemish Government (AI Research Program)	European Research Council (ERC) under the European Union(European Research Council (ERC)); Flemish Government (AI Research Program)	We would like to thank Luc De Raedt for his valuable feedback during the early stages of this research, as well as our anonymous reviewers for their insightful remarks that helped us improve the quality of this work.; This work has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No [694980] SYNTH: Synthesising Inductive Data Models). This research received funding from the Flemish Government (AI Research Program).	Abedjan Z, 2016, PROC INT CONF DATA, P1134, DOI 10.1109/ICDE.2016.7498319; [Anonymous], 2012, P ACM SIGMOD INT C M, DOI DOI 10.1145/2213836.2213848; Balog M, 2019, 5 INT C LEARN REPR I; Bhupatiraju Surya, 2017, ARXIV170404327; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cypher Allen, 1993, WATCH WHAT I DO PROG; Devlin J., 2018, BERT PRE TRAINING DE; Devlin J, 2017, PR MACH LEARN RES, V70; Ellis K, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1638; Ellis Kevin, ACM SIGPLAN; Gao X, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428287; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gulwani S, 2012, COMMUN ACM, V55, P97, DOI 10.1145/2240236.2240260; Gulwani S, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P317, DOI 10.1145/1926385.1926423; He YY, 2018, PROC VLDB ENDOW, V11, P1165, DOI 10.14778/3231751.3231766; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Le V, 2014, ACM SIGPLAN NOTICES, V49, P542, DOI [10.1145/2594291.2594333, 10.1145/2666356.2594333]; Liu J., 2021, ARXIV PREPRINT ARXIV; Mayer M, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P291, DOI 10.1145/2807442.2807459; Microsoft, 2015, PROGR SYNTH INP OUTP; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Miltner A, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360569; Padhi S, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3276520; Parisotto E., 2016, Neuro-symbolic program synthesis; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raza M, 2017, AAAI CONF ARTIF INTE, P882; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Rolim R, 2017, PROC INT CONF SOFTW, P404, DOI 10.1109/ICSE.2017.44; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Song Jie, 2021, P 2021 INT C MAN DAT, DOI [10.1145/3448016, DOI 10.1145/3448016]; Xiao Liu, 2021, ARXIV PREPRINT ARXIV; Zhao TZ, 2021, PR MACH LEARN RES, V139	35	9	9	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2475-1421		P ACM PROGRAM LANG	P. ACM Program. Lang.	OCT	2021	5								100	10.1145/3485477	http://dx.doi.org/10.1145/3485477			25	Computer Science, Software Engineering	Emerging Sources Citation Index (ESCI)	Computer Science	XQ5EX		gold, Green Published			2024-07-03	WOS:000731569200004
J	Li, KC; Bu, ZJ; Shahjalal, M; He, BX; Zhuang, ZF; Li, C; Liu, JP; Wang, B; Liu, ZL				Li, Ke-Cheng; Bu, Zhi-Jun; Shahjalal, Md.; He, Bai-Xiang; Zhuang, Zi-Fan; Li, Chen; Liu, Jian-Ping; Wang, Bin; Liu, Zhao-Lan			Performance of ChatGPT on Chinese Master's Degree Entrance Examination in Clinical Medicine	PLOS ONE			English	Article								Background ChatGPT is a large language model designed to generate responses based on a contextual understanding of user queries and requests. This study utilised the entrance examination for the Master of Clinical Medicine in Traditional Chinese Medicine to assesses the reliability and practicality of ChatGPT within the domain of medical education. Methods We selected 330 single and multiple-choice questions from the 2021 and 2022 Chinese Master of Clinical Medicine comprehensive examinations, which did not include any images or tables. To ensure the test's accuracy and authenticity, we preserved the original format of the query and alternative test texts, without any modifications or explanations. Results Both ChatGPT3.5 and GPT-4 attained average scores surpassing the admission threshold. Noteworthy is that ChatGPT achieved the highest score in the Medical Humanities section, boasting a correct rate of 93.75%. However, it is worth noting that ChatGPT3.5 exhibited the lowest accuracy percentage of 37.5% in the Pathology division, while GPT-4 also displayed a relatively lower correctness percentage of 60.23% in the Biochemistry section. An analysis of sub-questions revealed that ChatGPT demonstrates superior performance in handling single-choice questions but performs poorly in multiple-choice questions. Conclusion ChatGPT exhibits a degree of medical knowledge and the capacity to aid in diagnosing and treating diseases. Nevertheless, enhancements are warranted to address its accuracy and reliability limitations. Imperatively, rigorous evaluation and oversight must accompany its utilization, accompanied by proactive measures to surmount prevailing constraints.	[Li, Ke-Cheng; Wang, Bin] Beijing Univ Chinese Med, Dongzhimen Hosp, Dept Androl, Beijing, Peoples R China; [Bu, Zhi-Jun; Liu, Jian-Ping; Liu, Zhao-Lan] Beijing Univ Chinese Med, Ctr Evidence Based Chinese Med, Beijing, Peoples R China; [Shahjalal, Md.] North South Univ, Dept Publ Hlth, Dhaka, Bangladesh; [He, Bai-Xiang] Beijing Univ Chinese Med, Dongzhimen Hosp, Dept Gastroenterol, Beijing, Peoples R China; [Zhuang, Zi-Fan] China Acad Chinese Med Sci, Guanganmen Hosp, Dept Endocrinol, Beijing, Peoples R China; [Li, Chen] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China	Beijing University of Chinese Medicine; Beijing University of Chinese Medicine; North South University (NSU); Beijing University of Chinese Medicine; China Academy of Chinese Medical Sciences; Guang'anmen Hospital, CACMS; Xi'an Jiaotong University	Wang, B (corresponding author), Beijing Univ Chinese Med, Dongzhimen Hosp, Dept Androl, Beijing, Peoples R China.; Liu, ZL (corresponding author), Beijing Univ Chinese Med, Ctr Evidence Based Chinese Med, Beijing, Peoples R China.	dayiwangbin@sina.com; lzl1019@163.com	SHAHJALAL, MD./AAC-8316-2021	SHAHJALAL, MD./0000-0002-2218-8433; Bu, Zhijun/0009-0006-0051-1662	National Natural Science Foundation of China [82374298]; Reserve Discipline Leader Funding of Beijing University of Chinese Medicine [90010960920033]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Reserve Discipline Leader Funding of Beijing University of Chinese Medicine	This study is supported by a grant from the National Natural Science Foundation of China (Grant No. 82374298) and the Reserve Discipline Leader Funding of Beijing University of Chinese Medicine (Grant No. 90010960920033). There was no additional external funding received for this study.	Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Fuentes-Martín A, 2023, ARCH BRONCONEUMOL, V59, P534, DOI 10.1016/j.arbres.2023.03.017; Gilson A., 2023, JMIR Med Educ; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Grewal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40135; Guigue PA, 2024, INT J GYNECOL OBSTET, V164, P959, DOI 10.1002/ijgo.15083; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Ippolito D, 2019, Arxiv, DOI arXiv:1906.06362; Kocon J., 2023, Information Fusion, P101861; Koubaa A., 2023, arXiv; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Liu Y., 2023, Meta-Radiol ogy; Lo LS, 2023, J ACAD LIBR, V49, DOI 10.1016/j.acalib.2023.102720; Miao J, 2024, CLIN J AM SOC NEPHRO, V19, P35, DOI 10.2215/CJN.0000000000000330; OpenAI R., 2023, Gpt-4 technical report. arxiv 2303.08774, P2; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946	19	0	0	3	3	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	APR 4	2024	19	4							e0301702	10.1371/journal.pone.0301702	http://dx.doi.org/10.1371/journal.pone.0301702			12	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	NC5V4	38573944	Green Published, gold			2024-07-03	WOS:001198272000118
C	Hou, I; Man, O; Mettille, S; Gutierrez, S; Angelikas, K; MacNeil, S			ACM	Hou, Irene; Man, Owen; Mettille, Sophia; Gutierrez, Sebastian; Angelikas, Kenneth; MacNeil, Stephen			More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve Visually Diverse Images of Parsons Problems	PROCEEDINGS OF THE 26TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2024			English	Proceedings Paper	26th Australasian Computing Education Conference (ACE)	JAN 29-FEB 02, 2024	Sydney, AUSTRALIA			Generative AI; LLMs; GPT-4V; ChatGPT; Bard; Parsons Problems; visual programming problems; computing education		Large language models are reshaping computing education. Based on recent research, these models explain code better than students, answer multiple choice questions at or above the class average, and generate code that can pass automated tests in introductory courses. In response to these capabilities, instructors have quickly adjusted their courses and assessment methods to align with shifting learning goals and the increased risk of academic integrity issues. While some scholars have advocated for the integration of visual problems as a safeguard against the capabilities of language models, new multimodal models now have vision and language capabilities that may allow them to analyze and solve visual problems. In this paper, we compare the large multimodal model (LMMs) GPT-4V with Bard, an LLM that uses Google Lens for text recognition. We find that LMMs, which have learned both pixel features (from images) and text features (from prompts) in the same embedding space, performed substantially better than Bard which uses a piecemeal approach. With a specific focus on Parsons problems presented across diverse visual representations, our results show that GPT-4V solved 96.7% these visual problems, struggling minimally with a single Parsons problem. Conversely, Bard performed poorly by only solving 69.2% of problems, struggling with common issues like hallucinations and refusals. These findings suggest that merely transitioning to visual programming problems might not be a panacea to issues of academic integrity in the generative AI era.	[Hou, Irene; Man, Owen; Mettille, Sophia; Gutierrez, Sebastian; Angelikas, Kenneth; MacNeil, Stephen] Temple Univ, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Hou, I (corresponding author), Temple Univ, Philadelphia, PA 19122 USA.	irene.hou@temple.edu; owen.man@temple.edu; sophia.mettille@temple.edu; guts@temple.edu; kenneth.angelikas@temple.edu; stephen.macneil@temple.edu		Gutierrez, Sebastian/0009-0005-4844-692X				[Anonymous], 2008, P 4 INT WORKSHOP COM, DOI DOI 10.1145/1404520.1404532; Bari ATMG, 2019, GENET PROGRAM EVOL M, V20, P213, DOI 10.1007/s10710-019-09343-7; Barke S, 2022, Arxiv, DOI [arXiv:2206.15000, DOI 10.48550/ARXIV.2206.15000]; Becker BA, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P500, DOI 10.1145/3545945.3569759; Blum S. D., 2020, Ungrading: Why rating students undermines learning (and what to do instead); Brusilovsky P., 2014, P WORK GROUP 2014 IN, P31; Cahapay M.B., 2021, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.3791771; Chen M., 2021, arXiv; Chu Gary, 2020, Ungrading: Why Rating Students Undermines Learning (and What to Do Instead), P161; Coghlan Simon, 2021, Philos Technol, V34, P1581, DOI 10.1007/s13347-021-00476-1; Davis D, 2013, ACAD MED, V88, P593, DOI 10.1097/ACM.0b013e318286803a; Denny P, 2023, Arxiv, DOI arXiv:2307.16364; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Du YM, 2020, PROCEEDINGS OF THE TWENTY-SECOND AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE'20, P195, DOI 10.1145/3373165.3373187; Ericson Barbara J., 2022, ITiCSE-WGR '22: Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education, P191, DOI 10.1145/3571785.3574127; Ericson B, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER'16), P191, DOI 10.1145/2960310.2960335; Ericson Barbara, 2015, Analysis of Interactive Features Designed to Enhance Learning in an Ebook, P169, DOI [10.1145/2787622.2787731, DOI 10.1145/2787622.2787731]; Ericson BJ, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL. 2, P571, DOI 10.1145/3587103.3594211; Ericson BJ, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P1012, DOI 10.1145/3328778.3366950; Ericson BJ, 2017, 17TH KOLI CALLING INTERNATIONAL CONFERENCE ON COMPUTING EDUCATION RESEARCH (KOLI CALLING 2017), P20, DOI 10.1145/3141880.3141895; Ericson Barbara J., 2015, Proceedings of the eleventh annual International Conference on International Computing Education Research, P169, DOI DOI 10.1145/2787622.2787731; Fan ZY, 2023, PROC INT CONF SOFTW, P1469, DOI 10.1109/ICSE48619.2023.00128; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gaspar Alessio, 2019, Lessons Learned from Available Parsons Puzzles Software, DOI [10.18260/1-2--33060, DOI 10.18260/1-2--33060]; Gong T, 2023, Arxiv, DOI [arXiv:2305.04790, 10.48550/arXiv.2305.04790]; González-González CS, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12083488; Harms KJ, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER'16), P241, DOI 10.1145/2960310.2960314; Helminen J., 2012, Proceedings of the ninth annual international conference on International computing education research, P119; Holmes JD, 2021, TEACH PSYCHOL, V48, P293, DOI 10.1177/0098628320979884; Hou Irene, 2024, AUSTR COMP ED C ACE; Ihantola Petri, 2011, Journal of Information Technology Education, V10, P119; Ihantola P., 2013, Koli Calling, V13, P51, DOI DOI 10.1145/2526968.2526974; Ihantola P, 2011, J INF TECHNOL EDUC-I, V10, P116; Ihantola Petri, 2013, P 13 KOLI CALL INT R, DOI [10.1145/ConferenceonComputingEducation2526968.2526974, DOI 10.1145/CONFERENCEONCOMPUTINGEDUCATION2526968.2526974]; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Joshi Ishika, 2023, ChatGPT and the Future of Undergraduate Computer Science: Challenges, Opportunities and Recommendations; Koutcheme Charles, 2023, Artificial Intelligence in Education: 24th International Conference, AIED 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13916), P798, DOI 10.1007/978-3-031-36272-9_74; Kumar AN, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P527, DOI 10.1145/3159450.3159576; Kumar AN, 2017, LECT NOTES ARTIF INT, V10331, P528, DOI 10.1007/978-3-319-61425-0_56; Lau S, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P106, DOI 10.1145/3568813.3600138; Leinonen J, 2023, Arxiv, DOI arXiv:2304.03938; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu YL, 2024, Arxiv, DOI arXiv:2305.07895; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil S., 2022, P ACM TECHN S COMP S, P1255, DOI DOI 10.1145/3545947.3573358; Macneil S, 2023, Arxiv, DOI arXiv:2311.16017; MacNeil Stephen, 2023, P SIGCSE 23; MacNeil Stephen, 2016, P 47 ACM TECHN S COM, P193; Parsons D., 2006, Australasian Computing Education Conference, V52, P157; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prather J, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL. 2, P561, DOI 10.1145/3587103.3594206; Puryear B., 2022, Journal of Computing Sciences in Colleges, V38, P37; Reeves B, 2023, PROCEEDINGS OF THE 2023 CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, ITICSE 2023, VOL 1, P299, DOI 10.1145/3587102.3588805; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI [arXiv:2303.09325, DOI 10.48550/ARXIV.2303.09325]; Savelka J, 2023, Arxiv, DOI [arXiv:2303.08033, DOI 10.48550/ARXIV.2303.08033]; Savelka Jaromir, 2023, 19 ACM C INT COMP ED; Scott KA, 2015, LEARN MEDIA TECHNOL, V40, P412, DOI 10.1080/17439884.2014.924966; Seminario C. E., 2015, P 46 ACM TECHN S COM, P392, DOI [DOI 10.1145/2676723.2677240, 10.1145/2676723.2677240]; Shan SW, 2024, Arxiv, DOI arXiv:2310.13828; Sirkia T., 2016, Koli Calling on Computing Education Research, P155, DOI [10.1145/2999541.2999558, DOI 10.1145/2999541.2999558]; Spurlock S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P631, DOI 10.1145/3545945.3569747; Strauss A., 2004, SOCIAL RES METHODS R, P303; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tran Andrew, 2023, Generating multiple choice questions for computing courses using large language models; Wang JQ, 2023, Arxiv, DOI arXiv:2307.00855; Wermelinger M, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P172, DOI 10.1145/3545945.3569830; Xie Benjamin, 2021, L@S '21: Proceedings of the Eighth ACM Conference on Learning @ Scale, P77, DOI 10.1145/3430895.3460141; YeckehZaare I, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P71, DOI 10.1145/3291279.3339411; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zastudil C, 2023, Arxiv, DOI arXiv:2308.04309	73	1	1	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1619-5				2024							29	38		10.1145/3636243.3636247	http://dx.doi.org/10.1145/3636243.3636247			10	Computer Science, Software Engineering; Computer Science, Theory & Methods; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW5RQ		Green Submitted			2024-07-03	WOS:001166861800004
J	Lewis, M; Cahill, A; Madnani, N; Evans, J				Lewis, Molly; Cahill, Aoife; Madnani, Nitin; Evans, James			Local similarity and global variability characterize the semantic space of human languages	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						human cognition; language; semantics; culture; communication	BODY; CATEGORIES; ENGLISH; COLOR; SPECIFICITY; SENSITIVITY; EVOLUTION; PATTERNS; MEANINGS; REFLECTS	How does meaning vary across the world's languages? Scholars recognize the existence of substantial variability within specific domains, ranging from nature and color to kinship. The emergence of large language models enables a systems-level approach that directly characterizes this variability through comparison of word organization across semantic domains. Here, we show that meanings across languages manifest lower variability within semantic domains and greater variability between them, using models trained on both 1) large corpora of native language text comprising Wikipedia articles in 35 languages and also 2) Test of English as a Foreign Language (TOEFL) essays written by 38,500 speakers from the same native languages, which cluster into semantic domains. Concrete meanings vary less across languages than abstract meanings, but all vary with geographical, environmental, and cultural distance. By simultaneously examining local similarity and global difference, we harmonize these findings and provide a description of general principles that govern variability in semantic space across languages. In this way, the structure of a speaker's semantic space influences the comparisons cognitively salient to them, as shaped by their native language, and suggests that even successful bilingual communicators likely think with "semantic accents" driven by associations from their native language while writing English. These findings have dramatic implications for language education, cross-cultural communication, and literal translations, which are impossible not because the objects of reference are uncertain, but because associations, metaphors, and narratives interlink meanings in different, predictable ways from one language to another.	[Lewis, Molly] Carnegie Mellon Univ, Psychol & Social & Decis Sci, Pittsburgh, PA 15213 USA; [Cahill, Aoife] Dataminr Inc, New York, NY 10016 USA; [Madnani, Nitin] Educ Testing Serv, Princeton, NJ 08541 USA; [Evans, James] Univ Chicago, Sociol & Data Sci, Chicago, IL 60637 USA; [Evans, James] Santa Fe Inst, Santa Fe, NM 87501 USA	Carnegie Mellon University; Educational Testing Service (ETS); University of Chicago; The Santa Fe Institute	Lewis, M (corresponding author), Carnegie Mellon Univ, Psychol & Social & Decis Sci, Pittsburgh, PA 15213 USA.; Evans, J (corresponding author), Univ Chicago, Sociol & Data Sci, Chicago, IL 60637 USA.; Evans, J (corresponding author), Santa Fe Inst, Santa Fe, NM 87501 USA.	mollyllewis@gmail.com; orjevans@uchicago.edu		Evans, James/0000-0001-9838-0707	NSF [1520074]; Educational Testing Service	NSF(National Science Foundation (NSF)); Educational Testing Service	We acknowledge NSF #1520074 for partial support for this project, and thank the Educational Testing Service (A.C. and N.M.) for sharing and processing TOEFL data.	Aceves P, 2023, Arxiv, DOI arXiv:2112.08491; Ameel E, 2005, J MEM LANG, V53, P60, DOI 10.1016/j.jml.2005.02.004; Ameel E, 2009, J MEM LANG, V60, P270, DOI 10.1016/j.jml.2008.10.001; [Anonymous], PsycEXTRA Dataset, DOI [10.1037/e527312012-204, DOI 10.1037/E527312012-204]; [Anonymous], 1991, Basic color terms: Their universality and evolution; Arora S, 2019, Arxiv, DOI arXiv:1502.03520; Baddeley R, 2009, PSYCHOL SCI, V20, P1100, DOI 10.1111/j.1467-9280.2009.02412.x; Bastian M., 2009, P INT AAAI C WEB SOC, V3, P361, DOI DOI 10.1609/ICWSM.V3I1.13937; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Bolukbasi T, 2016, ADV NEUR IN, V29; Boutonnet B, 2015, J NEUROSCI, V35, P9329, DOI 10.1523/JNEUROSCI.5111-14.2015; Bowerman M, 2003, BRADFORD BOOKS, P387; Brysbaert M, 2014, BEHAV RES METHODS, V46, P904, DOI 10.3758/s13428-013-0403-5; Butts C.T., 2016, SNA TOOLS SOCIAL NET; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Casasanto D, 2011, CURR DIR PSYCHOL SCI, V20, P378, DOI 10.1177/0963721411422058; Choi S, 1999, COGNITIVE DEV, V14, P241, DOI 10.1016/S0885-2014(99)00004-0; Costa P, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0089254, 10.1371/journal.pone.0094842]; Dale R, 2012, ADV COMPLEX SYST, V15, DOI 10.1142/S0219525911500172; Dediu D, 2018, LANG DYN CHANG, V8, P1, DOI 10.1163/22105832-00801001; Dekker D, 2007, PSYCHOMETRIKA, V72, P563, DOI 10.1007/s11336-007-9016-1; Dong YP, 2005, BILING-LANG COGN, V8, P221, DOI 10.1017/S1366728905002270; Dryer MatthewS., 2013, WALS ONLINE; Fick SE, 2017, INT J CLIMATOL, V37, P4302, DOI 10.1002/joc.5086; Frank MC, 2008, COGNITION, V108, P819, DOI 10.1016/j.cognition.2008.04.007; Freeman RB, 2014, NATURE, V513, P305, DOI 10.1038/513305a; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Gennari SP, 2002, COGNITION, V83, P49, DOI 10.1016/S0010-0277(01)00166-4; Gentner D., 2009, Crossling. Appr. Psychol. Lang.: Res. Trad. Dan Isaac Slobin, V480; Gentner D., 1982, Language Development: Syntax and semantics; Gentner D., 1981, Cognition and Brain Theory, V4, P161; Gentner D., 2006, ACTION MEETS WORD, P544, DOI [10.1093/acprof:oso/9780195170009.001.0001, DOI 10.1093/ACPROF:OSO/9780195170009.003.0022]; Greenwald AG, 2017, SCIENCE, V356, P133, DOI 10.1126/science.aan0649; Hammarstrom H., 2011, Oslo Stud. Lang., V3, P31; Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830; Hayakawa S, 2018, COGNITION, V173, P8, DOI 10.1016/j.cognition.2017.12.010; Hill F, 2015, COMPUT LINGUIST, V41, P665, DOI 10.1162/COLI_a_00237; Huisman JLA, 2021, COGN LINGUIST, V32, P455, DOI 10.1515/cog-2020-0079; Jackson JC, 2019, SCIENCE, V366, P1517, DOI 10.1126/science.aaw8160; Jarvis S., 2008, CROSSLINGUISTIC INFL; Kay P, 2006, TRENDS COGN SCI, V10, P51, DOI 10.1016/j.tics.2005.12.007; Kemmerer D., 2019, CONCEPTS BRAIN VIEW, DOI [10.1093/oso/9780190682620.001.0001, DOI 10.1093/OSO/9780190682620.001.0001]; Kemp C, 2012, SCIENCE, V336, P1049, DOI 10.1126/science.1218811; Keysar B, 2012, PSYCHOL SCI, V23, P661, DOI 10.1177/0956797611432178; Kirby KR, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0158391; Kirby S, 2008, P NATL ACAD SCI USA, V105, P10681, DOI 10.1073/pnas.0707835105; Kozlowski AC, 2019, AM SOCIOL REV, V84, P905, DOI 10.1177/0003122419877135; Kutas M, 2011, ANNU REV PSYCHOL, V62, P621, DOI 10.1146/annurev.psych.093008.131123; Lakoff G., 2008, Women, Fire, and Dangerous Things: What Categories Reveal about the Mind, P58; LaTourrette AS, 2020, P NATL ACAD SCI USA, V117, P21230, DOI 10.1073/pnas.2006608117; Levi-Strauss Claude., 2008, Structural Anthropology; Levinson S., 2003, SPACE LANGUAGE COGNI, DOI DOI 10.1017/CBO9780511613609; Levinson SC, 2006, LANG SCI, V28, P221, DOI 10.1016/j.langsci.2005.11.007; Levy O, 2014, ADV NEUR IN, V27; Lewis M., Local-Global Semantics PNAS; Lewis M, 2020, NAT HUM BEHAV, V4, P1021, DOI 10.1038/s41562-020-0918-6; Lewis ML, 2016, COGNITION, V153, P182, DOI 10.1016/j.cognition.2016.04.003; LOFTUS EF, 1974, J VERB LEARN VERB BE, V13, P585, DOI 10.1016/S0022-5371(74)80011-3; Lupyan G., 2013, P ANN M COGNITIVE SC, P1678; Lupyan G, 2007, PSYCHOL SCI, V18, P1077, DOI 10.1111/j.1467-9280.2007.02028.x; Lupyan G, 2016, TRENDS COGN SCI, V20, P649, DOI 10.1016/j.tics.2016.07.005; Lupyan G, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0008559; Lupyan Gary., 2015, LANGUAGE STRUCTURE E, P289; Majid A, 2004, TRENDS COGN SCI, V8, P108, DOI 10.1016/j.tics.2004.01.003; Majid A, 2007, COGN LINGUIST, V18, P133, DOI 10.1515/COG.2007.005; Majid A, 2018, P NATL ACAD SCI USA, V115, P11369, DOI 10.1073/pnas.1720419115; Majid A, 2015, TOP COGN SCI, V7, P570, DOI 10.1111/tops.12159; Majid A, 2015, LANG SCI, V49, P1, DOI 10.1016/j.langsci.2014.11.002; Majid A, 2014, COGNITION, V130, P266, DOI 10.1016/j.cognition.2013.11.004; Malt BC, 2003, BRADFORD BOOKS, P81; Malt BC, 2015, J MEM LANG, V82, P86, DOI 10.1016/j.jml.2015.03.001; Malt BC, 2003, J MEM LANG, V49, P20, DOI 10.1016/S0749-596X(03)00021-4; Malt BC, 1999, J MEM LANG, V40, P230, DOI 10.1006/jmla.1998.2593; Marti Louis, 2023, Open Mind (Camb), V7, P79, DOI 10.1162/opmi_a_00072; Matsuki E, 2021, BILING-LANG COGN, V24, P137, DOI 10.1017/S1366728920000322; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; MURDOCK GP, 1970, ETHNOLOGY, V9, P165, DOI 10.2307/3772782; Pagel M, 2007, NATURE, V449, P717, DOI 10.1038/nature06176; Pavlenko A, 2002, APPL LINGUIST, V23, P190, DOI 10.1093/applin/23.2.190; Pavlenko A, 2011, BILING EDUC BILING, P237; Pereira F, 2016, COGN NEUROPSYCHOL, V33, P175, DOI 10.1080/02643294.2016.1176907; Quine WVO., 1960, Word and Object; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2018, IMPROVING LANGUAGE U; Regier T, 2007, P NATL ACAD SCI USA, V104, P1436, DOI 10.1073/pnas.0610341104; Regier T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151138; Regier T, 2009, TRENDS COGN SCI, V13, P439, DOI 10.1016/j.tics.2009.07.001; Rehurek R., 2011, NLP Centre Faculty Inf. Masaryk Univ. Brno, Czech Repub., V3; ROSCH E, 1975, COGNITIVE PSYCHOL, V7, P573, DOI 10.1016/0010-0285(75)90024-9; Saussure F. De., 1960, Course in General Linguistics; Shi F, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-36741-4; SWADESH MORRIS., 1952, P AM PHILOS SOC, V96, P452; Thompson B, 2020, NAT HUM BEHAV, V4, P1029, DOI 10.1038/s41562-020-0924-8; Vaswani A, 2017, ADV NEUR IN, V30; Wichmann S., 2013, ASJP DATABASE VERSIO; Winawer J, 2007, P NATL ACAD SCI USA, V104, P7780, DOI 10.1073/pnas.0701644104; Wnuk E, 2022, COGNITION, V229, DOI 10.1016/j.cognition.2022.105223; Xu Y, 2020, COGNITION, V201, DOI 10.1016/j.cognition.2020.104280; Youn H, 2016, P NATL ACAD SCI USA, V113, P1766, DOI 10.1073/pnas.1520752113; Zaslavsky N, 2019, TOP COGN SCI, V11, P207, DOI 10.1111/tops.12395; Zettersten M, 2020, COGNITION, V196, DOI 10.1016/j.cognition.2019.104135; Zhou Y., 2021, Proc. Annu. Meet. Cogn. Sci. Soc., V43, P314	102	1	1	12	14	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	DEC 19	2023	120	51							e2300986120	10.1073/pnas.2300986120	http://dx.doi.org/10.1073/pnas.2300986120			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	FO2O7	38079546	Green Submitted, hybrid			2024-07-03	WOS:001146716000007
C	Ayre, D; Dougherty, C; Zhao, YT			AMER SOC MECHANICAL ENGINEERS	Ayre, Dennis; Dougherty, Carolyn; Zhao, Yitong			IMPLEMENTATION OF AN ARTIFICIAL INTELLIGENCE (AI) INSTRUCTIONAL SUPPORT SYSTEM IN A VIRTUAL REALITY (VR) THERMAL-FLUIDS LABORATORY	PROCEEDINGS OF ASME 2023 INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, IMECE2023, VOL 8			English	Proceedings Paper	ASME International Mechanical Engineering Congress and Exposition (IMECE)	OCT 29-NOV 02, 2023	Undergraduate Res & Design Expo, New Orleans, LA	Amer Soc Mech Engineers	Undergraduate Res & Design Expo	Virtual Reality; Artificial Intelligence; Generative AI; GPT; Engineering Education	EDUCATION	Physical laboratory experiments have long been the cornerstone of higher education, providing future engineers practical real-life experience invaluable to their careers. However, demand for laboratory time has exceeded physical capabilities. Virtual reality (VR) labs have proven to retain many benefits of attending physical labs while also providing significant advantages only available in a VR environment. Previously, our group had developed a pilot VR lab that replicated six (6) unique thermal-fluids lab experiments developed using the Unity game engine. One of the VR labs was tested in a thermal-fluid mechanics laboratory class with favorable results, but students highlighted the need for additional assistance within the VR simulation. In response to this testing, we have incorporated an artificial intelligence (AI) assistant to aid students within the VR environment by developing an interaction model. Utilizing the Generative Pre-trained Transformer 4 (GPT-4) large language model (LLM) and augmented context retrieval, the AI assistant can provide reliable instruction and troubleshoot errors while students conduct the lab procedure to provide an experience similar to a real-life lab assistant. The updated VR lab was tested in two laboratory classes and while the overall tone of student response to an AI-powered assistant was excitement and enthusiasm, observations and other recorded data show that students are currently unsure of how to utilize this new technology, which will help guide future refinement of AI components within the VR environment.	[Ayre, Dennis; Dougherty, Carolyn; Zhao, Yitong] Calif State Polytech Univ Pomona, Pomona, CA 91768 USA	California State University System; California State Polytechnic University Pomona	Ayre, D (corresponding author), Calif State Polytech Univ Pomona, Pomona, CA 91768 USA.							Ayre D., 2023, ASEE PSW C APR; CARBONEL.JR, 1970, IEEE T MAN MACHINE, VMM11, P190, DOI 10.1109/TMMS.1970.299942; Chambers Jack A., 1983, Computer-Assisted Learning: Its Use in the Classroom; Clancey W., 1987, KNOWLEDGE BASED TUTO; Converse G., 2021, Neural network methods for application in educational measurement, DOI [10.17077/etd.005860, DOI 10.17077/ETD.005860]; Freedman Reva, AAAI 99 WORKSH MIX I; Huang XY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13094639; Johnson-Glenberg MC, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00081; L. L. C. Translated by Content Engine, 2023, CE Noticias Financieras; Leiker Daniel, 2023, INT C ART INT ED 202; MAYER RE, 1984, INSTR SCI, V13, P95; Mouloua M., Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V49, P2263; Oh H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041314; Pande P, 2021, RES LEARN TECHNOL, V29, DOI 10.25304/rlt.v29.2482; Paszkiewicz A, 2022, ENERGIES, V15, DOI 10.3390/en15010277; Peixoto B, 2021, IEEE ACCESS, V9, P48952, DOI 10.1109/ACCESS.2021.3068858; PINTRICH PR, 1993, EDUC PSYCHOL MEAS, V53, P801, DOI 10.1177/0013164493053003024; Ruan BB, 2022, ADV MULTIMED, V2022, DOI 10.1155/2022/3721301; Taylor L., 2023, Chat GPT sparks concern and hope for professors; Thorp S, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6050031; Velickovic P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020321; Young GW, 2020, J UNIVERS COMPUT SCI, V26, P904; Zhang Q, 2020, IEEE ACCESS, V8, P162830, DOI 10.1109/ACCESS.2020.3019262; Zhang WP, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132212646; Zhao Y., 2019, IMECE C SALT LAK CIT	25	0	0	0	0	AMER SOC MECHANICAL ENGINEERS	NEW YORK	THREE PARK AVENUE, NEW YORK, NY 10016-5990 USA			978-0-7918-8765-3				2023														16	Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Engineering	BW9OV					2024-07-03	WOS:001216737600029
J	Wu, ZX; Weng, ZJ; Peng, WJ; Yang, XT; Li, A; Davis, LS; Jiang, YG				Wu, Zuxuan; Weng, Zejia; Peng, Wujian; Yang, Xitong; Li, Ang; Davis, Larry S.; Jiang, Yu-Gang			Building an Open-Vocabulary Video CLIP Model With Better Architectures, Optimization and Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE			English	Article						CLIP; language models; video recognition; zero-shot recognition	LANGUAGE	Despite significant results achieved by Contrastive Language-Image Pretraining (CLIP) in zero-shot image recognition, limited effort has been made exploring its potential for zero-shot video recognition. This paper presents Open-VCLIP++, a simple yet effective framework that adapts CLIP to a strong zero-shot video classifier, capable of identifying novel actions and events during testing. Open-VCLIP++ minimally modifies CLIP to capture spatial-temporal relationships in videos, thereby creating a specialized video classifier while striving for generalization. We formally demonstrate that training Open-VCLIP++ is tantamount to continual learning with zero historical data. To address this problem, we introduce Interpolated Weight Optimization, a technique that leverages the advantages of weight interpolation during both training and testing. Furthermore, we build upon large language models to produce fine-grained video descriptions. These detailed descriptions are further aligned with video features, facilitating a better transfer of CLIP to the video domain. Our approach is evaluated on three widely used action recognition datasets, following a variety of zero-shot evaluation protocols. The results demonstrate that our method surpasses existing state-of-the-art techniques by significant margins. Specifically, we achieve zero-shot accuracy scores of 88.1%, 58.7%, and 81.2% on UCF, HMDB, and Kinetics-600 datasets respectively, outpacing the best-performing alternative methods by 8.5%, 8.2%, and 12.3%. We also evaluate our approach on the MSR-VTT video-text retrieval dataset, where it delivers competitive video-to-text and text-to-video retrieval performance, while utilizing substantially less fine-tuning data compared to other methods.	[Wu, Zuxuan; Weng, Zejia; Peng, Wujian; Jiang, Yu-Gang] Fudan Univ, Sch Comp Sci, Shanghai 200437, Peoples R China; [Yang, Xitong] Meta AI, Menlo Pk, CA 94025 USA; [Li, Ang] Simular AI, San Mateo, CA 94401 USA; [Davis, Larry S.] Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA	Fudan University; University System of Maryland; University of Maryland College Park	Jiang, YG (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai 200437, Peoples R China.	zxwu@fudan.edu.cn; zjweng20@fudan.edu.cn; wjpeng22@m.fudan.edu.cn; xyang35@umd.edu; ang@simular.ai; lsd@umiacs.umd.edu; ygj@fudan.edu.cn		Peng, Wujian/0009-0001-6428-276X	NSFC	NSFC(National Natural Science Foundation of China (NSFC))	No Statement Available	Rusu AA, 2016, Arxiv, DOI arXiv:1606.04671; Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676; BAAI, 2023, Aquilachat2; Bain M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1708, DOI 10.1109/ICCV48922.2021.00175; Balaji Y, 2020, Arxiv, DOI arXiv:2010.02418; Bertasius G, 2021, PR MACH LEARN RES, V139; Bishay M, 2019, Arxiv, DOI arXiv:1907.09021; Brattoli B, 2020, PROC CVPR IEEE, P4612, DOI 10.1109/CVPR42600.2020.00467; Bulat A., 2021, P INT C NEUR INF PRO, P19594; Carreira J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1808.01340; Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356; Chen SZ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13618, DOI 10.1109/ICCV48922.2021.01338; Chen ZH, 2023, Arxiv, DOI arXiv:2304.10453; Crowson K, 2022, LECT NOTES COMPUT SC, V13697, P88, DOI 10.1007/978-3-031-19836-6_6; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Esmaeilpour S, 2022, AAAI CONF ARTIF INTE, P6568; Farajtabar M, 2020, PR MACH LEARN RES, V108, P3762; Foo LG, 2023, Arxiv, DOI arXiv:2308.14177; Gao JY, 2021, IEEE T PATTERN ANAL, V43, P3476, DOI 10.1109/TPAMI.2020.2985708; Gao JY, 2019, AAAI CONF ARTIF INTE, P8303; Ghiasi G., 2021, arXiv; Ghiasi G, 2022, LECT NOTES COMPUT SC, V13696, P540, DOI 10.1007/978-3-031-20059-5_31; Ghosh S, 2023, Arxiv, DOI arXiv:2306.00301; Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622; Hu HY, 2021, Arxiv, DOI arXiv:2111.01956; Ilharco G, 2022, Advances in Neural Information Processing Systems, P29262; Izmailov P, 2019, Arxiv, DOI arXiv:1803.05407; Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521; Jia C, 2021, PR MACH LEARN RES, V139; Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353; Kay W, 2017, Arxiv, DOI [arXiv:1705.06950, DOI 10.48550/ARXIV.1705.06950]; Kim TS, 2021, AAAI CONF ARTIF INTE, V35, P1817; Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543; Lei J., 2022, arXiv; Li J, 2023, P INT C MACH LEARN A; Li JN, 2022, PR MACH LEARN RES; Li KC, 2022, Arxiv, DOI [arXiv:2211.09552, DOI 10.48550/ARXIV.2211.09552]; Lin CC, 2022, PROC CVPR IEEE, P19946, DOI 10.1109/CVPR52688.2022.01935; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028; Mandal D, 2019, PROC CVPR IEEE, P9977, DOI 10.1109/CVPR.2019.01022; Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272; Ming Y., 2022, Advances in Neural Information Processing Systems, V35, P35087; Mishra A, 2018, IEEE WINT CONF APPL, P372, DOI 10.1109/WACV.2018.00047; Ni B, 2022, LECT NOTES COMPUT SC, V13664, P1, DOI 10.1007/978-3-031-19772-7_1; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ordonez V., 2011, Advances in Neural Information Processing Systems, P1143; Pan J., 2022, Adv. Neural Inf. Process. Syst., V35, P26462; Portillo-Quintero JA, 2021, LECT NOTES COMPUT SC, V12725, P3, DOI 10.1007/978-3-030-77004-4_1; Radford A, 2021, PR MACH LEARN RES, V139; Rotstein N, 2023, Arxiv, DOI arXiv:2305.17718; Schuhmann C, 2021, Arxiv, DOI arXiv:2111.02114; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Shin H, 2017, ADV NEUR IN, V30; Shu Y, 2023, P IEEE INT C MACH LE, P31716; Soomro K, 2012, Arxiv, DOI arXiv:1212.0402; Thengane V., 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vicuna, 2023, Vicuna: An open-source chatbot impressing GPT-4 with 90%*chatgpt quality; Wang J, 2022, P INT C NEUR INF PRO, P5696; Wang M., 2021, arXiv; Wang Y, 2022, Arxiv, DOI arXiv:2212.03191; Wang Z, 2022, P 36 INT C NEURAL IN, P8483; Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139; Weng Z., 2023, INT C MACHINE LEARNI, P36978; Weng Z., 2023, ACM Trans. Multimedia Comput. Commun. Appl., V20, P1; Weng ZJ, 2022, LECT NOTES COMPUT SC, V13690, P605, DOI 10.1007/978-3-031-20056-4_35; Wortsman M, 2022, PROC CVPR IEEE, P7949, DOI 10.1109/CVPR52688.2022.00780; Wu W., 2023, P AAAI C ARTIFICIAL, P2847, DOI [10.1609/aaai.v37i3.25386, DOI 10.1609/AAAI.V37I3.25386]; Wu ZX, 2022, IEEE T PATTERN ANAL, V44, P1699, DOI 10.1109/TPAMI.2020.3029425; Xing Z, 2023, Arxiv, DOI arXiv:2310.10647; Xing Z, 2023, Arxiv, DOI arXiv:2211.13222; Xu H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6787; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Xu X, 2017, INT J COMPUT VISION, V123, P309, DOI 10.1007/s11263-016-0983-5; Yin D, 2021, Arxiv, DOI arXiv:2006.10974; Zellers R, 2017, Arxiv, DOI arXiv:1707.09468; Zeng A., 2023, P INT C LEARN REPR; Zhang X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7940, DOI 10.1109/ICCV48922.2021.00786; Zheng L, 2023, P INT C NEUR INF PRO; Zheng W., 2022, arXiv; Zhu DY, 2023, Arxiv, DOI arXiv:2303.06594	84	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0162-8828	1939-3539		IEEE T PATTERN ANAL	IEEE Trans. Pattern Anal. Mach. Intell.	JUL	2024	46	7					4747	4762		10.1109/TPAMI.2024.3357503	http://dx.doi.org/10.1109/TPAMI.2024.3357503			16	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TG6I0	38261478	Green Submitted			2024-07-03	WOS:001240147800019
J	Arshed, MA; Gherghina, SC; Dur-E-Zahra; Manzoor, M				Arshed, Muhammad Asad; Gherghina, Stefan Cristian; Dur-E-Zahra; Manzoor, Mahnoor			Prediction of Machine-Generated Financial Tweets Using Advanced Bidirectional Encoder Representations from Transformers	ELECTRONICS			English	Article						machine learning; deep learning; transformers; encoder representation; fake tweets; multi-class identification		With the rise of Large Language Models (LLMs), distinguishing between genuine and AI-generated content, particularly in finance, has become challenging. Previous studies have focused on binary identification of ChatGPT-generated content, overlooking other AI tools used for text regeneration. This study addresses this gap by examining various AI-regenerated content types in the finance domain. Objective: The study aims to differentiate between human-generated financial content and AI-regenerated content, specifically focusing on ChatGPT, QuillBot, and SpinBot. It constructs a dataset comprising real text and AI-regenerated text for this purpose. Contribution: This research contributes to the field by providing a dataset that includes various types of AI-regenerated financial content. It also evaluates the performance of different models, particularly highlighting the effectiveness of the Bidirectional Encoder Representations from the Transformers Base Cased model in distinguishing between these content types. Methods: The dataset is meticulously preprocessed to ensure quality and reliability. Various models, including Bidirectional Encoder Representations Base Cased, are fine-tuned and compared with traditional machine learning models using TFIDF and Word2Vec approaches. Results: The Bidirectional Encoder Representations Base Cased model outperforms other models, achieving an accuracy, precision, recall, and F1 score of 0.73, 0.73, 0.73, and 0.72 respectively, in distinguishing between real and AI-regenerated financial content. Conclusions: This study demonstrates the effectiveness of the Bidirectional Encoder Representations base model in differentiating between human-generated financial content and AI-regenerated content. It highlights the importance of considering various AI tools in identifying synthetic content, particularly in the finance domain in Pakistan.	[Arshed, Muhammad Asad; Dur-E-Zahra; Manzoor, Mahnoor] Univ Management & Technol, Sch Syst & Technol, Lahore 54770, Pakistan; [Gherghina, Stefan Cristian] Bucharest Univ Econ Studies, Dept Finance, 6 Piata Romana, Bucharest 010374, Romania	University of Management & Technology (UMT); Bucharest University of Economic Studies	Arshed, MA (corresponding author), Univ Management & Technol, Sch Syst & Technol, Lahore 54770, Pakistan.; Gherghina, SC (corresponding author), Bucharest Univ Econ Studies, Dept Finance, 6 Piata Romana, Bucharest 010374, Romania.	asad.arshed@umt.edu.pk; stefan.gherghina@fin.ase.ro	Gherghina, Stefan Cristian/J-3339-2012	Gherghina, Stefan Cristian/0000-0003-2911-6480				Alamleh H., 2023, P 2023 SYST INF ENG; Alammary AS, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115720; [Anonymous], SpinBot-Article Spinning, Text Rewriting, Content Creation Tool; [Anonymous], EVALUATION METRICS M; [Anonymous], Tweet-Preprocessor PyPI; Arase Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5393; Cahyani Denis Eka, 2021, Bull. Electr. Eng. Inform, V10, P2780, DOI DOI 10.11591/EEI.V10I5.3157; Charbuty B., 2021, J. Appl. Sci. Technol. Trends, V2, P20, DOI [10.38094/jastt20165, DOI 10.38094/JASTT20165]; Chawla S, 2023, MULTIMED TOOLS APPL, V82, P40167, DOI 10.1007/s11042-023-15211-5; Chen YT, 2023, Arxiv, DOI arXiv:2305.07969; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dipta SR, 2024, Arxiv, DOI arXiv:2402.11815; Fitria T. N., 2021, Englisia: Journal of Language, Education, and Humanities, V9, P183, DOI 10.22373/ej.v9i1.10233; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Ghosh A, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107981; Hamed AA, 2024, Arxiv, DOI arXiv:2308.11767; Han T., 2023, P 2 INT C MATH STAT, DOI [10.4108/EAI.26-5-2023.2334244, DOI 10.4108/EAI.26-5-2023.2334244]; Jafarzadeh H, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214405; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katib I, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11153400; Khan T.A., 2024, J. Inform. Web Eng, V3, P67, DOI [10.33093/jiwe.2024.3.1.5, DOI 10.33093/JIWE.2024.3.1.5]; Kumar P., 2021, P INT C COMM COMP TE, P923, DOI [10.1007/978-981-16-3246-470, DOI 10.1007/978-981-16-3246-470]; Kumarage T, 2023, Arxiv, DOI arXiv:2303.03697; Li Q, 2023, KNOWL-BASED SYST, V277, DOI 10.1016/j.knosys.2023.110761; Liao WX, 2023, Arxiv, DOI [arXiv:2304.11567, 10.48550/ARXIV.2304.11567, DOI 10.48550/ARXIV.2304.11567]; Liu X, 2023, GPT UNDERSTANDS TOO; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Mindner L., 2023, International Conference on Artificial Intelligence in Education Technology, DOI [10.1007/978-981-99-7947-912, DOI 10.1007/978-981-99-7947-912]; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Pardos Z. A., 2023, arXiv; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Saha N, 2018, INT J APPL PATTERN R, V5, P251, DOI 10.1504/IJAPR.2018.094819; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shah K, 2020, Augment. Human Res, V5, P1, DOI [DOI 10.1007/S41133-020-00032-0, 10.1007/s41133-020-00032-0]; Shahriar S, 2023, Arxiv, DOI [arXiv:2302.13817, 10.47852/bonviewAIA3202939, DOI 10.47852/BONVIEWAIA3202939]; Topal MO, 2021, Arxiv, DOI arXiv:2102.08036; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yu PP, 2024, Arxiv, DOI arXiv:2304.12008; Zhang X., 2016, P 2016 12 WORLD C IN, DOI [10.1109/WCICA.2016.7578522, DOI 10.1109/WCICA.2016.7578522]	39	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JUN	2024	13	11							2222	10.3390/electronics13112222	http://dx.doi.org/10.3390/electronics13112222			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	UA5V1		gold			2024-07-03	WOS:001245363800001
J	Kaartemo, V; Helkkula, A				Kaartemo, Valtteri; Helkkula, Anu			Human-AI resource relations in value cocreation in service ecosystems	JOURNAL OF SERVICE MANAGEMENT			English	Article; Early Access						Value; Cocreation; Artificial intelligence; Service ecosystem; Resource; Postphenomenology	TECHNOLOGY; EXPERIENCE	Purpose-Applications of artificial intelligence (AI), such as virtual and physical service robots, generative AI, large language models and decision support systems, alter the nature of services. Most service research centers on the division between human and AI resources. Less attention has been paid to analyzing the entangled resource relations and interactions between humans and AI entities. Thus, the purpose of this paper is to extend our metatheoretical understanding of resource integration and value cocreation by analyzing different human-AI resource relations in service ecosystems. Design/methodology/approach-The conceptual paper adapts a novel framework from postphenomenology, specifically cyborg intentionality. This framework is used to analyze what kinds of human-AI resource relations enable resource integration and value cocreation in service ecosystems. Findings-We conceptualize seven different human-AI resource relations, namely background, embodiment, hermeneutic, alterity, cyborg, immersion and composite relation. The sociotechnical entangled perspective on human-AI resource relations challenges and reframes our understanding of interactions between humans and nonhumans in resource integration and value cocreation and the distinction between operant and operand resources in service research. Originality/value-Our primary contribution to researchers and service providers is dissolving the distinction between operant and operand resources. We present two foundational propositions. 1. Humans and AI become entangled value cocreating resources in inherently sociotechnical service ecosystems; and 2. Human and AI entanglements in value cocreation manifest through seven resource relations in inherently sociotechnical service ecosystems. Understanding the combinatorial potential of different human-AI resource relations enables service providers to make informed choices in service ecosystems.	[Kaartemo, Valtteri] Univ Turku, Turku Inst Adv Studies, Dept Mkt & Int Business, Turku, Finland; [Helkkula, Anu] Hanken Sch Econ, Ctr Relationship Mkt & Serv Management CERS, Dept Mkt, Helsinki, Finland	University of Turku; Hanken School of Economics	Helkkula, A (corresponding author), Hanken Sch Econ, Ctr Relationship Mkt & Serv Management CERS, Dept Mkt, Helsinki, Finland.	anu.helkkula@hanken.fi						Akaka MA, 2014, INF SYST E-BUS MANAG, V12, P367, DOI 10.1007/s10257-013-0220-5; [Anonymous], 2019, Oxford English Dictionary; Anthony C, 2023, ORGAN SCI, V34, P1672, DOI 10.1287/orsc.2022.1651; Arnould E, 2024, J BUS RES, V176, DOI 10.1016/j.jbusres.2024.114590; Aydin C, 2019, Philosophy and Technology, V32, P321, DOI DOI 10.1007/S13347-018-0309-3; Barad K., 2007, M UNIVERSE HALFWAY Q; Benjamin J.J., 2023, Machine Horizons: Post-Phenomenological Studies; Bijker W., 1995, BICYCLES BAKELITES B; Callon M., 1986, MAPPING DYNAMICS SCI, P19; Constantin JamesA., 1994, Understanding Resource Management; De Keyser A, 2019, J SERV MANAGE, V30, P156, DOI 10.1108/JOSM-03-2018-0082; de Véricourt F, 2023, MANAGE SCI, DOI 10.1287/mnsc.2023.4791; Dyndal G.L., 2017, NATO Review; Findsrud R, 2018, MARKETING THEOR, V18, P493, DOI 10.1177/1470593118764590; Fügener A, 2022, INFORM SYST RES, V33, P678, DOI 10.1287/isre.2021.1079; Goeminne G, 2011, FOUND SCI, V16, P173, DOI 10.1007/s10699-010-9196-5; Helkkula A, 2022, J BUS RES, V149, P860, DOI 10.1016/j.jbusres.2022.05.031; Helkkula A, 2012, J SERV RES-US, V15, P59, DOI 10.1177/1094670511426897; Hoffman DL, 2018, J CONSUM RES, V44, P1178, DOI 10.1093/jcr/ucx105; Hottat E, 2023, J SERV MANAGE, V34, P696, DOI 10.1108/JOSM-04-2022-0125; Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459; Ihde Don., 1995, POSTPHENOMENOLOGY ES; Jaakkola E., 2020, AMS Rev, V10, P18, DOI [DOI 10.1007/S13162-020-00161-0, 10.1007/s13162-020-00161-0]; Jain H, 2021, INFORM SYST RES, V32, P675, DOI 10.1287/isre.2021.1046; Kleinaltenkamp M, 2023, MARKETING THEOR, DOI 10.1177/14705931231207327; Latour Bruno., 2007, REASSEMBLING SOCIAL; Lebovitz S, 2022, ORGAN SCI, V33, P126, DOI 10.1287/orsc.2021.1549; Maglio PP, 2009, INF SYST E-BUS MANAG, V7, P395, DOI 10.1007/s10257-008-0105-1; Mele C., 2010, SERV SCI, V2, P126, DOI [DOI 10.1287/SERV.2.12.126, 10.1287/serv.2.1_2.126, DOI 10.1287/SERV.2.1_2.126]; Mele C, 2022, EUR J MARKETING, V56, P72, DOI 10.1108/EJM-04-2019-0308; Mele C, 2021, J BUS RES, V129, P949, DOI 10.1016/j.jbusres.2020.09.004; Meyer-Waarden L, 2022, TECHNOVATION, V109, DOI 10.1016/j.technovation.2021.102348; Mozafari N, 2022, J SERV MANAGE, V33, P221, DOI 10.1108/JOSM-10-2020-0380; Murray A, 2021, ACAD MANAGE REV, V46, P552, DOI 10.5465/amr.2019.0186; Odekerken-Schröder G, 2022, J SERV MANAGE, V33, P246, DOI 10.1108/JOSM-10-2020-0372; Orlikowski WJ, 2007, ORGAN STUD, V28, P1435, DOI 10.1177/0170840607081138; Pakarinen P, 2023, J MANAGE STUD, DOI 10.1111/joms.12915; Paluch S., Mark. Weiterdenken, P2020; Paluch S, 2022, J SERV MANAGE, V33, P363, DOI 10.1108/JOSM-11-2020-0406; Pickering A., 1995, The Mangle of Practice: Time, Agency, Science; Pitardi V, 2022, J SERV MANAGE, V33, P389, DOI 10.1108/JOSM-12-2020-0435; Sony M, 2020, TECHNOL SOC, V61, DOI 10.1016/j.techsoc.2020.101248; Teodorescu MHM, 2021, MIS QUART, V45, P1483, DOI 10.25300/MISQ/2021/16535; Van Manen M., 2016, Phenomenology of practice: Meaning-giving methods in phenomenological research and writing; Vargo S. L., 2018, Journal of Creating Value, V4, P202, DOI DOI 10.1177/2394964318809191; Vargo SL, 2008, J ACAD MARKET SCI, V36, P1, DOI 10.1007/s11747-007-0069-6; Vargo SL, 2016, J ACAD MARKET SCI, V44, P5, DOI 10.1007/s11747-015-0456-3; Vargo StephenL., 2012, Service Science, V4, P207, DOI DOI 10.1287/SERV.1120.0019; Verbeek PP, 2008, HUM STUD, V31, P11, DOI 10.1007/s10746-007-9079-0; Vindenes J, 2021, FRONT VIRTUAL REAL, V2, DOI 10.3389/frvir.2021.656423; Vink J, 2021, J SERV RES-US, V24, P168, DOI 10.1177/1094670520952537; Wirtz J, 2018, J SERV MANAGE, V29, P907, DOI 10.1108/JOSM-04-2018-0119	52	0	0	7	7	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1757-5818	1757-5826		J SERV MANAGE	J. Serv. Manage.	2024 MAY 28	2024										10.1108/JOSM-03-2023-0104	http://dx.doi.org/10.1108/JOSM-03-2023-0104		MAY 2024	16	Management	Social Science Citation Index (SSCI)	Business & Economics	RW6W5		hybrid			2024-07-03	WOS:001230746100001
J	Wang, ZX; Zhang, Z; Traverso, A; Dekker, A; Qian, LX; Sun, PF				Wang, Zhixiang; Zhang, Zhen; Traverso, Alberto; Dekker, Andre; Qian, Linxue; Sun, Pengfei			Assessing the role of GPT-4 in thyroid ultrasound diagnosis and treatment recommendations: enhancing interpretability with a chain of thought approach	QUANTITATIVE IMAGING IN MEDICINE AND SURGERY			English	Article						ChatGPT; thyroid cancer; diagnosis; artificial intelligence (AI); ultrasound	NODULES; MANAGEMENT; GO	Background: As artificial intelligence (AI) becomes increasingly prevalent in the medical field, the effectiveness of AI-generated medical reports in disease diagnosis remains to be evaluated. ChatGPT is a large language model developed by open AI with a notable capacity for text abstraction and comprehension. This study aimed to explore the capabilities, limitations, and potential of Generative Pre-trained Transformer (GPT)-4 in analyzing thyroid cancer ultrasound reports, providing diagnoses, and recommending treatment plans. Methods: Using 109 diverse thyroid cancer cases, we evaluated GPT-4's performance by comparing its generated reports to those from doctors with various levels of experience. We also conducted a Turing Test and a consistency analysis. To enhance the interpretability of the model, we applied the Chain of Thought (CoT) method to deconstruct the decision-making chain of the GPT model. Results: GPT-4 demonstrated proficiency in report structuring, professional terminology, and clarity of expression, but showed limitations in diagnostic accuracy. In addition, our consistency analysis highlighted certain discrepancies in the AI's performance. The CoT method effectively enhanced the interpretability of the AI's decision-making process. Conclusions: GPT-4 exhibits potential as a supplementary tool in healthcare, especially for generating thyroid gland diagnostic reports. Our proposed online platform, "ThyroAIGuide", alongside the CoT method, underscores the potential of AI to augment diagnostic processes, elevate healthcare accessibility, and advance patient education. However, the journey towards fully integrating AI into healthcare is ongoing, requiring continuous research, development, and careful monitoring by medical professionals to ensure patient safety and quality of care.	[Wang, Zhixiang; Qian, Linxue; Sun, Pengfei] Capital Med Univ, Beijing Friendship Hosp, Dept Ultrasound, Beijing, Peoples R China; [Wang, Zhixiang; Zhang, Zhen; Traverso, Alberto; Dekker, Andre] Maastricht Univ, GROW Sch Oncol, Med Ctr, Dept Radiat Oncol Maastro, Maastricht, Netherlands; [Qian, Linxue; Sun, Pengfei] Capital Med Univ, Beijing Friendship Hosp, Dept Ultrasound, 95 Yong An Rd, Beijing 100050, Peoples R China	Capital Medical University; Maastricht University; Capital Medical University	Qian, LX; Sun, PF (corresponding author), Capital Med Univ, Beijing Friendship Hosp, Dept Ultrasound, 95 Yong An Rd, Beijing 100050, Peoples R China.	qianlinxue2002@163.com; spfjlmpc@163.com	Dekker, Andre/AAE-4830-2019; Wang, Zhixiang/AAC-7106-2021	Dekker, Andre/0000-0002-0422-7996; 	Capital's Funds for Health Improvement and Research [2022-1-2022]	Capital's Funds for Health Improvement and Research	Funding: This work was supported by the Capital's Funds for Health Improvement and Research (No. 2022-1-2022) .	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; Durante C, 2018, JAMA-J AM MED ASSOC, V319, P914, DOI 10.1001/jama.2018.0898; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303; Frasca F, 2022, EXPERT REV ENDOCRINO, V17, P447, DOI 10.1080/17446651.2022.2112176; French RM, 2000, TRENDS COGN SCI, V4, P115, DOI 10.1016/S1364-6613(00)01453-4; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Grinberg M., 2018, Flask web development: developing web applications with python; Guth S, 2009, EUR J CLIN INVEST, V39, P699, DOI 10.1111/j.1365-2362.2009.02162.x; Haugen BR, 2016, THYROID, V26, P1, DOI 10.1089/thy.2015.0020; He W, 2013, INT J INFORM MANAGE, V33, P464, DOI 10.1016/j.ijinfomgt.2013.01.001; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Joyce DW, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00751-9; Koubaa A, 2023, PREPRINT; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; McKinlay J, 2010, CHANDOS INF PROF SER, P1, DOI 10.1533/9781780630243; Moon WJ, 2011, KOREAN J RADIOL, V12, P1, DOI 10.3348/kjr.2011.12.1.1; Murdoch TB, 2013, JAMA-J AM MED ASSOC, V309, P1351, DOI 10.1001/jama.2013.393; Myong Y, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0279349; OpenAI TJO, 2022, CHATGPT OPTIMIZING L; Petch J, 2022, CAN J CARDIOL, V38, P204, DOI 10.1016/j.cjca.2021.09.004; Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259; Schrittwieser J, 2020, NATURE, V588, P604, DOI 10.1038/s41586-020-03051-4; Secinaro S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01488-9; Sharma M, 2022, J MED INTERNET RES, V24, DOI 10.2196/40238; Shickel Benjamin, 2018, IEEE J Biomed Health Inform, V22, P1589, DOI 10.1109/JBHI.2017.2767063; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sohn E, 2023, NATURE, V613, P402, DOI 10.1038/d41586-023-00023-2; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Vorisek CN, 2022, JMIR MED INF, V10, DOI 10.2196/35724; Wei J, 2022, PART ADV NEURAL INFO, V35, P2022	32	1	1	20	20	AME PUBLISHING COMPANY	SHATIN	FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA	2223-4292	2223-4306		QUANT IMAG MED SURG	Quant. Imaging Med. Surg.	FEB	2024	14	2								10.21037/qims-23-1180	http://dx.doi.org/10.21037/qims-23-1180		JAN 2024	15	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	MP8D1	38415150	Green Published, gold			2024-07-03	WOS:001146755700001
J	Witte, H; Blatter, TU; Nagabhushana, P; Schaer, D; Ackermann, J; Cadamuro, J; Leichtle, AB				Witte, Harald; Blatter, Tobias U. U.; Nagabhushana, Priyanka; Schaer, David; Ackermann, James; Cadamuro, Janne; Leichtle, Alexander B. B.			Statistical learning and big data applications	JOURNAL OF LABORATORY MEDICINE			English	Article						ChatGPT; clinical decision-support systems; laboratory medicine; machine learning; personalized medicine; wearables	CLASSIFICATION	The amount of data generated in the field of laboratory medicine has grown to an extent that conventional laboratory information systems (LISs) are struggling to manage and analyze this complex, entangled information ("Big Data"). Statistical learning, a generalized framework from machine learning (ML) and artificial intelligence (AI) is predestined for processing "Big Data" and holds the potential to revolutionize the field of laboratory medicine. Personalized medicine may in particular benefit from AI-based systems, especially when coupled with readily available wearables and smartphones which can collect health data from individual patients and offer new, cost-effective access routes to healthcare for patients worldwide. The amount of personal data collected, however, also raises concerns about patient-privacy and calls for clear ethical guidelines for "Big Data" research, including rigorous quality checks of data and algorithms to eliminate underlying bias and enable transparency. Likewise, novel federated privacy-preserving data processing approaches may reduce the need for centralized data storage. Generative AI-systems including large language models such as ChatGPT currently enter the stage to reshape clinical research, clinical decision-support systems, and healthcare delivery. In our opinion, AI-based systems have a tremendous potential to transform laboratory medicine, however, their opportunities should be weighed against the risks carefully. Despite all enthusiasm, we advocate for stringent added-value assessments, just as for any new drug or treatment. Human experts should carefully validate AI-based systems, including patient-privacy protection, to ensure quality, transparency, and public acceptance. In this opinion paper, data prerequisites, recent developments, chances, and limitations of statistical learning approaches are highlighted.	[Witte, Harald; Blatter, Tobias U. U.; Nagabhushana, Priyanka; Schaer, David; Ackermann, James; Leichtle, Alexander B. B.] Inselspital Univ Hosp Bern, Dept Clin Chem, Bern, Switzerland; [Witte, Harald] Univ Bern, Dept Biomed Res DBMR, Bern, Switzerland; [Blatter, Tobias U. U.] Univ Bern, Grad Sch Hlth Sci GHS, Bern, Switzerland; [Cadamuro, Janne] Univ Salzburg, Dept Lab Med, Paracelsus Med, Salzburg, Austria; [Leichtle, Alexander B. B.] Univ Bern, Ctr Artificial Intelligence Med CAIM, Bern, Switzerland	University of Bern; University Hospital of Bern; University of Bern; University of Bern; Salzburg University; University of Bern	Witte, H (corresponding author), Inselspital Univ Hosp Bern, Dept Clin Chem, Bern, Switzerland.; Witte, H (corresponding author), Univ Bern, Dept Biomed Res DBMR, Bern, Switzerland.	harald.witte@unibe.ch	Leichtle, Alexander/C-7262-2011; Leichtle, Alexander/JQI-9700-2023; Nasarian, Elham/ISB-6863-2023	Leichtle, Alexander/0000-0002-6528-9904; Ackermann, James Louis Nicolas/0000-0002-4215-1232; Witte, Harald/0000-0002-4421-3580; Blatter, Tobias Ueli/0000-0002-0298-8177	Bern Centre for Precision Medicine; Swiss National Science Foundation [202101104]; Swiss Personalized Health Network [2018DEV22]	Bern Centre for Precision Medicine; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); Swiss Personalized Health Network	This work has been funded by grantsfrom the Bern Centre for Precision Medicine (PGX-link PGM),the Swiss National Science Foundation (2021-01104), and the Swiss Personalized Health Network (2018DEV22).	Amann Julia, 2022, PLOS Digit Health, V1, pe0000016, DOI 10.1371/journal.pdig.0000016; Andre F, 2022, NATURE, V610, P343, DOI 10.1038/s41586-022-05068-3; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Babu Nirmal Varghese, 2022, SN Comput Sci, V3, P74, DOI 10.1007/s42979-021-00958-1; Bernal J, 2022, NATO ADV SCI I E, V12, P10228; Blatter TU, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081923; Bunch DR, 2023, CLIN LAB MED, V43, P47, DOI 10.1016/j.cll.2022.09.005; Cadamuro J, 2023, CLIN CHEM LAB MED, V61, P1158, DOI 10.1515/cclm-2023-0355; Colborn KL, 2023, SURGERY, V173, P464, DOI 10.1016/j.surg.2022.10.026; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Ferretti A, 2022, J EMPIR RES HUM RES, V17, P129, DOI 10.1177/15562646211053538; Froelicher D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25972-y; Grady C, 2015, NEW ENGL J MED, V372, P855, DOI 10.1056/NEJMra1411250; Habehh H, 2021, CURR GENOMICS, V22, P291, DOI 10.2174/1389202922666210705124359; Haymond S, 2021, J APPL LAB MED, V6, P1640, DOI 10.1093/jalm/jfab075; Healthy.Io, US; Hong C, 2023, JAMA-J AM MED ASSOC, V329, P306, DOI 10.1001/jama.2022.24683; Kapoor S, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2207.07048; Khanijahani A, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01877-1; Liniger Z, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12123148; Mannino RG, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07262-2; Medenilla A., 2023, PLoS Digital Health, V2; Naugler C, 2019, CRIT REV CL LAB SCI, V56, P98, DOI 10.1080/10408363.2018.1561640; Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356; Pennestrì F, 2022, CLIN CHEM LAB MED, V60, P1867, DOI 10.1515/cclm-2022-0096; Popescu DM, 2022, NAT CARDIOVASC RES, V1, P334, DOI 10.1038/s44161-022-00041-9; Schmidt W, 2022, ANN AGR ENV MED, V29, P274, DOI 10.26444/aaem/145376; Seastedt Kenneth P, 2022, PLOS Digit Health, V1, pe0000102, DOI 10.1371/journal.pdig.0000102; Sebastian AM, 2022, LIFE-BASEL, V12, DOI 10.3390/life12121991; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singh V, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103523; Su MK, 2023, CLIN CHEM LAB MED, V61, P521, DOI 10.1515/cclm-2022-1006; Taylor P, TOTAL DATA VOLUME WO; Triep K, 2022, JMIR MED INF, V10, DOI 10.2196/31356; Turbé V, 2021, NAT MED, V27, P1165, DOI 10.1038/s41591-021-01384-9; Visco V, 2021, CURR MED CHEM, V28, P6569, DOI 10.2174/0929867328666201218122633; Vokinger KN, 2021, COMMUN MED-LONDON, V1, DOI 10.1038/s43856-021-00028-w; Vokinger KN, 2020, J LAW MED ETHICS, V48, P228, DOI 10.1177/1073110520917025; Witte H, 2022, JMIR FORM RES, V6, DOI 10.2196/36176; Yap CX, 2021, CELL, V184, P5916, DOI 10.1016/j.cell.2021.10.015	41	2	2	5	24	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2567-9430	2567-9449		J LAB MED	J. Lab. Med.	AUG 28	2023	47	4					181	186		10.1515/labmed-2023-0037	http://dx.doi.org/10.1515/labmed-2023-0037		JUN 2023	6	Medical Laboratory Technology	Science Citation Index Expanded (SCI-EXPANDED)	Medical Laboratory Technology	N8GK1		Green Published, gold			2024-07-03	WOS:001000436200001
J	Xiang, JY; Liu, MF; Li, QY; Qiu, C; Hu, HJ				Xiang, Junyi; Liu, Maofu; Li, Qiyuan; Qiu, Chen; Hu, Huijun			A cross-guidance cross-lingual model on generated parallel corpus for classical Chinese machine reading comprehension	INFORMATION PROCESSING & MANAGEMENT			English	Article						Classical Chinese machine reading; comprehension; Chinese diachronic gap; Cross-guidance cross-lingual model; Parallel corpus generation		Chinese diachronic gap is a key issue in classical Chinese machine reading comprehension (CCMRC). Preceding work on bridging this gap has been mostly restricted to limited monolingual classical Chinese corpora pre-training and lexical knowledge integration, which require a great deal of human resources. In this paper, we propose a cross-guidance cross-lingual model (CGCLM), pre-trained on a classical and modern Chinese parallel corpus generated from a large language model, to bridge the Chinese diachronic gap and reduce the manual effort. The CGCLM facilitates accurate translation by providing in-context examples and feedback based on the longest common substring between source and target sentences, thereby avoiding untranslated Chinese words. Specifically, we consider three pre-training tasks, i.e., cross-masked language modeling, linguistic label cross-prediction, and semantic cross-aware translation language modeling. The knowledge acquired from masked tokens uncovering and linguistic label predicting can lead to the implicit semantic alignment between two language styles. Taking advantage of the semantic similarity between the same syntactic levels of parallel pairs, cross aware modeling integrates and transmits contextualized semantic information. We utilize an 18.6G monolingual corpus to create a 37.2G parallel corpus. Manual evaluation has resulted in only acceptable discrepancies between our generated and human-edited parallel corpora. Extensive experimental results show that our proposed model outperforms the state-of-the-art by an average accuracy of 3.13%, 2.44%, and 2.17% on CCMRC, classical Chinese language understanding evaluation (CCLUE), and modern Chinese language understanding evaluation (MCLUE) tasks.	[Xiang, Junyi; Liu, Maofu; Li, Qiyuan; Qiu, Chen; Hu, Huijun] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China; [Xiang, Junyi; Li, Qiyuan; Qiu, Chen; Hu, Huijun] Hubei Prov Key Lab Intelligent Informat Proc & Rea, Wuhan 430065, Peoples R China; [Xiang, Junyi; Li, Qiyuan; Qiu, Chen; Hu, Huijun] Wuhan Univ Sci & Technol, Inst Big Data Sci & Engn, Wuhan 430065, Peoples R China	Wuhan University of Science & Technology; Wuhan University of Science & Technology	Liu, MF (corresponding author), Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430065, Peoples R China.	jyxiang31@wust.edu.cn; liumaofu@wust.edu.cn; liumaofu@wust.edu.cn; chen@wust.edu.cn; huhuijun@wust.edu.cn	Xiang, Junyi/KFA-6895-2024; Li, Qiyuan/GWZ-3537-2022; Xiang, Junyi/AAI-6885-2021	Xiang, Junyi/0000-0003-2717-7888; Xiang, Junyi/0000-0003-2717-7888	Hubei (China) Province Advantageous and Characteristic Discipline	Hubei (China) Province Advantageous and Characteristic Discipline	The work presented in this paper is partially supported by the Hubei (China) Province Advantageous and Characteristic Discipline	Artetxe M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P451, DOI 10.18653/v1/P17-1042; Bhattacharjee A, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P2541; Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P95; Chai Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4702; Chi Y, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3061; Chi ZW, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3576; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475; Conneau A, 2019, ADV NEUR IN, V32; Cui YM, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P657; Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding L, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2417; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Eronen J, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103250; Eronen J, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102981; Fadaee M, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P436; Fei Hao, 2020, P 58 ANN M ASS COMP, P7014; Feng FXY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P878; Han X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2241; Huang HY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2485; Ji ZJ, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3112, DOI [10.1145/3459637.3482068, 10.1145//3459637.3482068]; Ji ZJ, 2021, COMM COM INF SC, V1466, P295, DOI 10.1007/978-981-16-6471-7_24; Jiang CC, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P210, DOI 10.1145/3487553.3524245; [琚生根 Ju Shenggen], 2022, [软件学报, Journal of Software], V33, P3793; Kolluru K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2502; Li L, 2023, INFORM FUSION, V91, P352, DOI 10.1016/j.inffus.2022.10.018; Li WL, 2023, IEEE T NEUR NET LEAR, V34, P7158, DOI 10.1109/TNNLS.2021.3138956; Li YF, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2579; Li YZ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1986; Liang Xu., 2020, P 28 INT C COMPUTATI, P4762, DOI [10.18653/v1/2020.coling-main.419, DOI 10.18653/V1/2020.COLING-MAIN.419]; Liu M., 2022, ACM Transactions on Asian and LowResource Language Information Processing, V22, P1; Liu Q, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103145; Nikolaev D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1159; Ouyang X, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P27; Qiang JP, 2023, T ASSOC COMPUT LING, V11, P740, DOI 10.1162/tacl_a_00572; Sun K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8736; Sun K, 2020, T ASSOC COMPUT LING, V8, P141, DOI 10.1162/tacl_a_00305; Sun ZJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2065; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang D.-b., 2021, Library Forum, P1; Wang H., 2023, Findings of the association for computational linguistics, P8589, DOI [10.18653/v1/2023.findings-acl.545, DOI 10.18653/V1/2023.FINDINGS-ACL.545]; Wang Y., 2023, Findings of the association for computational linguistics, P1089, DOI [10.18653/v1/2023.findings-acl.70, DOI 10.18653/V1/2023.FINDINGS-ACL.70]; Wu SQ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P2593; Xiao D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1702; Xu MZ, 2023, WORLD WIDE WEB, V26, P733, DOI 10.1007/s11280-022-01083-6; Xu S., 2021, 35 C NEURAL INFORM P; Yang J, 2020, AAAI CONF ARTIF INTE, V34, P9386; Ye J., 2022, P 2022 C EMPIRICAL M, P11653; Ye J., 2022, FINDINGS ASS COMPUTA, P3671; Yu Y., 2023, Findings of the Association for Computational Linguistics: ACL 2023, P11782, DOI 10.18653/v1/2023.findings-acl.748; Yue J., 2023, ACM Transactions on Asian and Low-Resource Language Information Processing, V22, P20; Zhang B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1628; Zhang ST, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-SRW 2023, VOL 4, P83; Zhang W, 2023, NEURAL COMPUT APPL, V35, P2325, DOI 10.1007/s00521-022-07690-8; Zhao J., 2022, INT C DATA MINING BI, P369; Zheng CJ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P778; Zhou B., 2023, FINDINGS ASS COMPUTA, P3294, DOI 10.18653/v1/2023.findings-acl.204; Zhou S., 2023, Findings of the Association for Computational Linguistics: ACL 2023, P12038, DOI [10.18653/v1/2023.findings-acl.762, DOI 10.18653/V1/2023.FINDINGS-ACL.762]	59	1	1	11	11	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-4573	1873-5371		INFORM PROCESS MANAG	Inf. Process. Manage.	MAR	2024	61	2							103607	10.1016/j.ipm.2023.103607	http://dx.doi.org/10.1016/j.ipm.2023.103607		DEC 2023	19	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	EL0P8					2024-07-03	WOS:001138967300001
J	Metawei, MA; Taher, M; ElDeeb, H; Nassar, SM				Metawei, Maha A.; Taher, Mohamed; ElDeeb, Hesham; Nassar, Salwa M.			A topic-aware classifier based on a hybrid quantum-classical model	NEURAL COMPUTING & APPLICATIONS			English	Article						Quantum natural language processing; Quantum neural network; Hybrid quantum-classical; Classification; Supervised learning		In the era of Large Language Models, there is still potential for improvement in current Natural Language Processing (NLP) methods in terms of verifiability and consistency. NLP classical approaches are computationally expensive due to their high-power consumption, computing power, and storage requirements. Another computationally efficient approach to NLP is categorical quantum mechanics, which combines grammatical structure and individual word meaning to deduce the sentence meaning. As both quantum theory and natural language use vector space to describe states which are more efficient on quantum hardware, QNLP models can achieve up to quadratic speedup over classical direct calculation methods. In recent years, there is significant progress in utilizing quantum features such as superposition and entanglement to represent linguistic meaning on quantum hardware. Earlier research work has already demonstrated QNLP's potential quantum advantage in terms of speeding up search, enhancing classification tasks' accuracy and providing an exponentially large quantum state space in which complex linguistic structures can be efficiently embedded. In this work, a QNLP model is used to determine if two sentences are related to the same topic or not. By comparing our QNLP model to a classical tensor network-based one, our model improved training accuracy by up to 45% and validation accuracy by 35%, respectively. The QNLP model convergence is also studied when varying: first, the problem size, second, parametrized quantum circuits used for model's training, and last, the backend quantum simulator noise model. The experimental results show that strongly entangled ansatz designs result in fastest model convergence.	[Metawei, Maha A.; Taher, Mohamed] Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt; [Metawei, Maha A.; ElDeeb, Hesham; Nassar, Salwa M.] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt	Egyptian Knowledge Bank (EKB); Ain Shams University; Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI)	Metawei, MA (corresponding author), Ain Shams Univ, Fac Engn, Comp & Syst Dept, Cairo, Egypt.; Metawei, MA (corresponding author), Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.	maha_metawei@eri.sci.eg; mohamed.taher@eng.asu.edu.eg; eldeeb@eri.sci.eg; salwa@eri.sci.eg	Metawei, Maha/JNQ-9479-2023	Metawei, Maha/0000-0003-0178-7194				Aaronson S, 2016, ARXIV; Abbas A., 2020, ARXIV; Abbas A, 2021, NAT COMPUT SCI, V1, P403, DOI 10.1038/s43588-021-00084-1; Abbas-zadeh M, 2021, ARXIV; Aleksandrowicz Gadi, 2019, Zenodo, DOI 10.5281/ZENODO.2562110; Arad I, 2010, SIAM J COMPUT, V39, P3089, DOI 10.1137/080739379; Arthur D, 2022, ARXIV; Bergholm V., 2018, ARXIV; Biswas D etal, 2021, ARXIV; Brakerski Z, 2020, ARXIV; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Casadio C, 2021, JOACHIM LAMBEK INTER; Chen SYC, 2020, IEEE ACCESS, V8, P141007, DOI 10.1109/ACCESS.2020.3010470; Coecke B., 2020, arXiv; Coecke B, 2022, QUANTUM COMPUTING AR, P277; Coecke B., 2010, ARXIV; Corp P, 2022, QML STRONGLYENTANGLI; deFelice G, 2020, ARXIV; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; El-Mahalawy AM, 2021, OPTIK, V246, DOI 10.1016/j.ijleo.2021.167793; Farhi E., 2018, ARXIV; Gambetta J., 2020, IBM Research Blog; Georgescu IM, 2014, REV MOD PHYS, V86, P153, DOI 10.1103/RevModPhys.86.153; Guarasci R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12115651; Havlícek V, 2019, NATURE, V567, P209, DOI 10.1038/s41586-019-0980-2; Holmes Z, 2022, PRX QUANTUM, V3, DOI 10.1103/PRXQuantum.3.010313; Hubregtsen T, 2021, QUANT MACH INTELL, V3, DOI 10.1007/s42484-021-00038-w; Karamlou A, 2022, ARXIV; Kartsaklis D, 2021, ARXIV; Kha QH, 2022, METHODS, V207, P90, DOI 10.1016/j.ymeth.2022.09.007; Khatri N, 2022, EXPT COMP ANSATZE QU; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Le NQK, 2022, COMPUT BIOL CHEM, V99, DOI 10.1016/j.compbiolchem.2022.107732; Lorenz R, 2021, ARXIV; Meichanetzidis K, 2023, QUANT MACH INTELL, V5, DOI 10.1007/s42484-023-00097-1; Metawei MA, 2022, EVALUATION DIFFERENT; Metawei MA, 2020, 2020 INT C COMM COMP, P1; Ragone M, 2022, ARXIV; Schuld M, 2020, PHYS REV A, V101, DOI 10.1103/PhysRevA.101.032308; Sim S, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201900070; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang-Mascianica V, 2023, ARXIV; Waseem MH., 2022, ELECT P THEOR COMPUT, V366, P50, DOI [10.4204/eptcs.366.7, DOI 10.4204/EPTCS.366.7]; Wiebe N, 2015, QUANTUM INF COMPUT, V15, P316; Womanium.org, 2022, WOM QUANT HACK; Zeng WJ, 2016, SLPCS QPL; Zyczkowski K, 2005, PHYS REV A, V71, DOI 10.1103/PhysRevA.71.032313	47	0	0	2	5	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0941-0643	1433-3058		NEURAL COMPUT APPL	Neural Comput. Appl.	SEP	2023	35	25			SI		18803	18812		10.1007/s00521-023-08706-7	http://dx.doi.org/10.1007/s00521-023-08706-7		JUN 2023	10	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	P2WY3		hybrid			2024-07-03	WOS:001019458000003
J	Huang, AS; Hirabayashi, K; Barna, L; Parikh, D; Pasquale, LR				Huang, Andy S.; Hirabayashi, Kyle; Barna, Laura; Parikh, Deep; Pasquale, Louis R.			Assessment of a Large Language Model's Responses to Questions and Cases About Glaucoma and Retina Management	JAMA OPHTHALMOLOGY			English	Article								Importance: Large language models (LLMs) are revolutionizing medical diagnosis and treatment, offering unprecedented accuracy and ease surpassing conventional search engines. Their integration into medical assistance programs will become pivotal for ophthalmologists as an adjunct for practicing evidence-based medicine. Therefore, the diagnostic and treatment accuracy of LLM-generated responses compared with fellowship-trained ophthalmologists can help assess their accuracy and validate their potential utility in ophthalmic subspecialties. Objective: To compare the diagnostic accuracy and comprehensiveness of responses from an LLM chatbot with those of fellowship-trained glaucoma and retina specialists on ophthalmological questions and real patient case management. Design, Setting, and Participants: This comparative cross-sectional study recruited 15 participants aged 31 to 67 years, including 12 attending physicians and 3 senior trainees, from eye clinics affiliated with the Department of Ophthalmology at Icahn School of Medicine at Mount Sinai, New York, New York. Glaucoma and retina questions (10 of each type) were randomly selected from the American Academy of Ophthalmology's Commonly Asked Questions. Deidentified glaucoma and retinal cases (10 of each type) were randomly selected from ophthalmology patients seen at Icahn School of Medicine at Mount Sinai-affiliated clinics. The LLM used was GPT-4 (version dated May 12, 2023). Data were collected from June to August 2023. Main Outcomes and Measures: Responses were assessed via a Likert scale for medical accuracy and completeness. Statistical analysis involved the Mann-Whitney U test and the Kruskal-Wallis test, followed by pairwise comparison. Results: The combined question-case mean rank for accuracy was 506.2 for the LLM chatbot and 403.4 for glaucoma specialists (n = 831; Mann-Whitney U = 27976.5; P < .001), and the mean rank for completeness was 528.3 and 398.7, respectively (n = 828; Mann-Whitney U = 25218.5; P < .001). The mean rank for accuracy was 235.3 for the LLM chatbot and 216.1 for retina specialists (n = 440; Mann-Whitney U = 15518.0; P = .17), and the mean rank for completeness was 258.3 and 208.7, respectively (n = 439; Mann-Whitney U = 13123.5; P = .005). The Dunn test revealed a significant difference between all pairwise comparisons, except specialist vs trainee in rating chatbot completeness. The overall pairwise comparisons showed that both trainees and specialists rated the chatbot's accuracy and completeness more favorably than those of their specialist counterparts, with specialists noting a significant difference in the chatbot's accuracy (z = 3.23; P = .007) and completeness (z = 5.86; P < .001). Conclusions and Relevance: This study accentuates the comparative proficiency of LLM chatbots in diagnostic accuracy and completeness compared with fellowship-trained ophthalmologists in various clinical scenarios. The LLM chatbot outperformed glaucoma specialists and matched retina specialists in diagnostic and treatment accuracy, substantiating its role as a promising diagnostic adjunct in ophthalmology.	[Huang, Andy S.; Hirabayashi, Kyle; Barna, Laura; Parikh, Deep; Pasquale, Louis R.] Icahn Sch Med Mt Sinai, Dept Ophthalmol, 310 E 14th St, New York, NY 10003 USA; [Barna, Laura] Harvard Med Sch, Dept Ophthalmol, Massachusetts Eye & Ear, Boston, MA USA	Icahn School of Medicine at Mount Sinai; Harvard University; Harvard Medical School; Massachusetts Eye & Ear Infirmary	Huang, AS (corresponding author), Icahn Sch Med Mt Sinai, Dept Ophthalmol, 310 E 14th St, New York, NY 10003 USA.	andyshihuang@gmail.com		Barna, Laura/0009-0002-6123-4348	Manhattan Eye and Ear Ophthalmology Alumni Foundation	Manhattan Eye and Ear Ophthalmology Alumni Foundation	No Statement Available	Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Caranfa JT, 2023, JAMA OPHTHALMOL, V141, P906, DOI 10.1001/jamaophthalmol.2023.3314; Delsoz Mohammad, 2023, medRxiv, DOI 10.1101/2023.08.25.23294635; Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Hu XY, 2023, OPHTHALMOL THER, V12, P3395, DOI 10.1007/s40123-023-00789-8; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Rojas-Carabali W, 2023, OCUL IMMUNOL INFLAMM, DOI 10.1080/09273948.2023.2253471	10	2	2	5	5	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6165	2168-6173		JAMA OPHTHALMOL	JAMA Ophthalmol.	APR	2024	142	4					371	375		10.1001/jamaophthalmol.2023.6917	http://dx.doi.org/10.1001/jamaophthalmol.2023.6917		APR 2024	5	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	OE4P5	38386351	hybrid			2024-07-03	WOS:001174564400007
J	Corradi, M; Luechtefeld, T; de Haan, AM; Pieters, R; Freedman, JH; Vanhaecke, T; Vinken, M; Teunis, M				Corradi, Marie; Luechtefeld, Thomas; de Haan, Alyanne M.; Pieters, Raymond; Freedman, Jonathan H.; Vanhaecke, Tamara; Vinken, Mathieu; Teunis, Marc			The application of natural language processing for the extraction of mechanistic information in toxicology	FRONTIERS IN TOXICOLOGY			English	Article						natural language processing; toxicology; adverse outcome pathway; risk assessment; machine learning; open science	TOXICITY	To study the ways in which compounds can induce adverse effects, toxicologists have been constructing Adverse Outcome Pathways (AOPs). An AOP can be considered as a pragmatic tool to capture and visualize mechanisms underlying different types of toxicity inflicted by any kind of stressor, and describes the interactions between key entities that lead to the adverse outcome on multiple biological levels of organization. The construction or optimization of an AOP is a labor intensive process, which currently depends on the manual search, collection, reviewing and synthesis of available scientific literature. This process could however be largely facilitated using Natural Language Processing (NLP) to extract information contained in scientific literature in a systematic, objective, and rapid manner that would lead to greater accuracy and reproducibility. This would support researchers to invest their expertise in the substantive assessment of the AOPs by replacing the time spent on evidence gathering by a critical review of the data extracted by NLP. As case examples, we selected two frequent adversities observed in the liver: namely, cholestasis and steatosis denoting accumulation of bile and lipid, respectively. We used deep learning language models to recognize entities of interest in text and establish causal relationships between them. We demonstrate how an NLP pipeline combining Named Entity Recognition and a simple rules-based relationship extraction model helps screen compounds related to liver adversities in the literature, but also extract mechanistic information for how such adversities develop, from the molecular to the organismal level. Finally, we provide some perspectives opened by the recent progress in Large Language Models and how these could be used in the future. We propose this work brings two main contributions: 1) a proof-of-concept that NLP can support the extraction of information from text for modern toxicology and 2) a template open-source model for recognition of toxicological entities and extraction of their relationships. All resources are openly accessible via GitHub (https://github.com/ontox-project/en-tox).	[Corradi, Marie; de Haan, Alyanne M.; Pieters, Raymond; Teunis, Marc] Utrecht Univ Appl Sci, Innovat Testing Life Sci & Chem, Utrecht, Netherlands; [Luechtefeld, Thomas] ToxTrack, Bethesda, MD USA; [Luechtefeld, Thomas] Johns Hopkins Bloomberg Sch Publ Hlth, Environm Hlth & Engn, Baltimore, MD USA; [Pieters, Raymond] Univ Utrecht, Inst Risk Assessment Sci, Utrecht, Netherlands; [Freedman, Jonathan H.] Univ North Carolina Chapel Hill, Gillings Sch Global Publ Hlth, Chapel Hill, NC USA; [Vanhaecke, Tamara; Vinken, Mathieu] Vrije Univ Brussel Belgium, Dept Pharmaceut & Pharmacol Sci, Brussels, Belgium	Johns Hopkins University; Johns Hopkins Bloomberg School of Public Health; Utrecht University; University of North Carolina School of Medicine; University of North Carolina; University of North Carolina Chapel Hill	Corradi, M (corresponding author), Utrecht Univ Appl Sci, Innovat Testing Life Sci & Chem, Utrecht, Netherlands.	marie.corradi@hu.nl	Vinken, Mathieu/H-7513-2013	Vinken, Mathieu/0000-0001-5115-8893; Vanhaecke, Tamara/0000-0002-6685-7299	Horizon 202010.13039/501100007601	Horizon 202010.13039/501100007601	We thank Iris den Hertog for her initial contribution to the relationship extraction pipeline, as well as Eefje Poppelaars for her contribution to the en-tox NER model. We are grateful to Ramiro Jover and Anouk Verhoeven for their contribution to the list of compounds for liver adverse outcomes and explanations on how these were selected.	Anders LC, 2016, TOXICOL APPL PHARM, V311, P34, DOI 10.1016/j.taap.2016.09.026; Ankley GT, 2010, ENVIRON TOXICOL CHEM, V29, P730, DOI 10.1002/etc.34; AOP, 2024, AOP wiki; ASPIS, 2023, ASPIS cluster website; Bhalla D, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btac767; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Bus James S., 2017, Current Opinion in Toxicology, V3, P87, DOI 10.1016/j.cotox.2017.06.013; Cabot PLH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2370; Corradi Marie P F, 2022, Biomater Biosyst, V7, P100061, DOI 10.1016/j.bbiosy.2022.100061; CUI LX, 1995, J CLIN INVEST, V95, P555, DOI 10.1172/JCI117698; Davis AP, 2023, NUCLEIC ACIDS RES, V51, pD1257, DOI 10.1093/nar/gkac833; Fernandes MR, 2017, REV ASSOC MED BRAS, V63, P923; GitHub repository, 2023, Ontox-project/en-tox en-tox github repository; Guan LL, 2024, MOL NUTR FOOD RES, V68, DOI 10.1002/mnfr.202200812; Hartung T, 2012, ALTEX-ALTERN ANIM EX, V29, P119, DOI 10.14573/altex.2012.2.119; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Jaylet T, 2023, ENVIRON INT, V177, DOI 10.1016/j.envint.2023.108017; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jin R, 2020, ENVIRON INT, V134, DOI 10.1016/j.envint.2019.105220; Katritsis NM, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.894209; Ku TT, 2021, ECOTOX ENVIRON SAFE, V220, DOI 10.1016/j.ecoenv.2021.112309; Lála J, 2023, Arxiv, DOI arXiv:2312.07559; Maertens A, 2022, ALTEX-ALTERN ANIM EX, V39, P3, DOI 10.14573/altex.2201081; Mendez D, 2019, NUCLEIC ACIDS RES, V47, pD930, DOI 10.1093/nar/gky1075; Monserrate S.G., 2022, Social and Ethical Responsibilities of Computing, DOI DOI 10.21428/2C646DE5.031D4553; Neumann M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P319; Van Norman GA, 2019, JACC-BASIC TRANSL SC, V4, P845, DOI 10.1016/j.jacbts.2019.10.008; Villeneuve DL, 2014, TOXICOL SCI, V142, P312, DOI 10.1093/toxsci/kfu199; Vinken M, 2021, TOXICOLOGY, V458, DOI 10.1016/j.tox.2021.152846; Wang DZ, 2018, ARCH TOXICOL, V92, P1847, DOI 10.1007/s00204-018-2177-0; Waters MD, 2004, NAT REV GENET, V5, P936, DOI 10.1038/nrg1493; Westergaard D, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005962; Yu HY, 2017, TUMOR BIOL, V39, DOI 10.1177/1010428317712102; Zaslavsky Leonid, 2021, Front Res Metr Anal, V6, P689059, DOI 10.3389/frma.2021.689059	34	0	0	0	0	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-3080		FRONT TOXICOL	Front. Toxicol.	MAY 10	2024	6								1393662	10.3389/ftox.2024.1393662	http://dx.doi.org/10.3389/ftox.2024.1393662			10	Toxicology	Emerging Sources Citation Index (ESCI)	Toxicology	RT3C5	38800806	gold			2024-07-03	WOS:001229862000001
J	Bonfitto, GR; Roletto, A; Savardi, M; Fasulo, SV; Catania, D; Signoroni, A				Bonfitto, G. R.; Roletto, A.; Savardi, M.; Fasulo, S. V.; Catania, D.; Signoroni, A.			Harnessing ChatGPT dialogues to address claustrophobia in MRI - A radiographers' education perspective	RADIOGRAPHY			English	Article						ChatGPT; Generative AI; Simulation: radiographer; Claustrophobia; Magnetic resonance imaging	PATIENT ANXIETY; COMMUNICATION; RATES	Introduction: The healthcare sector invests significantly in communication skills training, but not always with satisfactory results. Recently, generative Large Language Models, have shown promising results in medical education. This study aims to use ChatGPT to simulate radiographer-patient conversations about the critical moment of claustrophobia management during MRI, exploring how Artificial Intelligence can improve radiographers' communication skills. Methods: This study exploits specifically designed prompts on ChatGPT-3.5 and ChatGPT-4 to generate simulated conversations between virtual claustrophobic patients and six radiographers with varying levels of work experience focusing on their differences in model size and language generation capabilities. Success rates and responses were analysed. The methods of radiographers in convincing virtual patients to undergo MRI despite claustrophobia were also evaluated. Results: A total of 60 simulations were conducted, achieving a success rate of 96.7% (58/60). ChatGPT-3.5 exhibited errors in 40% (12/30) of the simulations, while ChatGPT-4 showed no errors. In terms of radiographers' communication during the simulations, out of 164 responses, 70.2% (115/164) were categorized as "Supportive Instructions," followed by "Music Therapy" at 18.3% (30/164). Experts mainly used "Supportive Instructions" (82.2%, 51/62) and "Breathing Techniques" (9.7%, 6/62). Intermediate participants favoured "Music Therapy" (26%, 13/50), while Beginner participants frequently utilized "Mild Sedation" (15.4%, 8/52). Conclusion: The simulation of clinical scenarios via ChatGPT proves valuable in assessing and testing radiographers' communication skills, especially in managing claustrophobic patients during MRI. This pilot study highlights the potential of ChatGPT in preclinical training, recognizing different training needs at different levels of professional experience. Implications for practice: This study is relevant in radiography practice, where AI is increasingly widespread, as it explores a new way to improve the training of radiographers. (c) 2024 The Author(s). Published by Elsevier Ltd on behalf of The College of Radiographers. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).	[Bonfitto, G. R.] Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy; [Roletto, A.] Univ Brescia, Dept Mech & Ind Engn, Via Branze 38, I-25123 Brescia, Italy; [Bonfitto, G. R.; Roletto, A.; Fasulo, S. V.; Catania, D.] IRCCS Osped San Raffaele, Via Olgettina 60, I-20132 Milan, Italy; [Savardi, M.; Signoroni, A.] Univ Brescia, Dept Med & Surg Specialties Radiol Sci & Publ Hlth, Viale Europa 11, I-25123 Brescia, Italy	University of Brescia; University of Brescia; Vita-Salute San Raffaele University; IRCCS Ospedale San Raffaele; University of Brescia	Bonfitto, GR (corresponding author), Univ Brescia, Dept Informat Engn, Via Branze 38, I-25123 Brescia, Italy.	giuseppe.bonfitto@unibs.it; andrea.roletto@unibs.it; mattia.savardi@unibs.it; fasulo.simone@hsr.it; catania.diego@hsr.it; alberto.signoroni@unibs.it	Bonfitto, Giuseppe Roberto/HGU-1929-2022	Bonfitto, Giuseppe Roberto/0000-0003-3169-9021; Catania, Diego/0009-0003-6256-5605; Roletto, Andrea/0000-0002-0271-5638; SIGNORONI, Alberto/0000-0002-8383-3766				Ajam Amna A, 2020, Top Magn Reson Imaging, V29, P131, DOI 10.1097/RMR.0000000000000242; Al-Shemmari AF, 2022, RADIOGRAPHY, V28, P148, DOI 10.1016/j.radi.2021.09.007; Alam F, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1279707; Babl FE, 2023, EMERG MED AUSTRALAS, V35, P809, DOI 10.1111/1742-6723.14233; Bacciu A, 2023, RRAML: reinforced retrieval augmented machine learning; Bachmann C, 2022, PATIENT EDUC COUNS, V105, P2320, DOI 10.1016/j.pec.2021.11.016; Bajaj S, 2024, ACAD RADIOL, V31, P1256, DOI 10.1016/j.acra.2023.08.039; Barash Y, 2023, J AM COLL RADIOL, V20, P998, DOI 10.1016/j.jacr.2023.06.009; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Bera K, 2024, CURR PROBL DIAGN RAD, V53, P215, DOI 10.1067/j.cpradiol.2023.10.013; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bwanga O, Radiography students' perceptions and experiences of their clinical placements-A qualitative systematic review; ChatGPT OpenAI, 2023, Large language model; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Currie G, 2023, RADIOGRAPHY, V29, P792, DOI 10.1016/j.radi.2023.05.011; D'Antonoli TA, 2024, DIAGN INTERV RADIOL, V30, P80, DOI 10.4274/dir.2023.232417; Ding S, 2024, RADIOGRAPHY, V30, P340, DOI 10.1016/j.radi.2023.11.016; Doshi R., Utilizing large Language Models to simplify radiology reports: a comparative analysis of ChatGPT3.5, ChatGPT4.0, Google bard, and microsoft bing n.d, DOI [10.1101/2023.06.04.23290786, DOI 10.1101/2023.06.04.23290786]; Dziuda L, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-40737-w; Fadel C., 2019, Artificial intelligence in education: Promises and implications for teaching and learning; Foldes Z., 2017, Psychomusicology: Music, Mind, and Brain, V27, P343, DOI DOI 10.1037/PMU0000199; Forshaw KL, 2018, J AM COLL RADIOL, V15, P630, DOI 10.1016/j.jacr.2017.12.030; Francová A, 2023, PRESENCE-VIRTUAL AUG, V32, P23, DOI 10.1162/pres_a_00385; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hamd ZY, 2023, BRAIN SCI, V13, DOI 10.3390/brainsci13030416; He ZK, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P720, DOI 10.1145/3583780.3614949; Hisan U. K., 2023, Journal of Pedagogy and Education Science, V2, P71, DOI [DOI 10.56741/JPES.V2I01.302, 10.56741/jpes.v2i01.302]; Hu B, 2023, Enabling intelligent interactions between an agent and an LLM: a reinforcement learning approach; Huang JS, 2023, AM J CANCER RES, V13, P1148; Hudson DM, 2022, RADIOGRAPHY, V28, P780, DOI 10.1016/j.radi.2022.02.010; Hudson DM, 2022, RADIOGRAPHY, V28, P154, DOI 10.1016/j.radi.2021.09.008; Humphris G, 2019, SUPPORT CARE CANCER, V27, P2143, DOI 10.1007/s00520-018-4484-7; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Karera A, 2023, RADIOGRAPHY, V29, P590, DOI 10.1016/j.radi.2023.03.012; Kyaw BM, 2019, J MED INTERNET RES, V21, DOI 10.2196/12959; Lawal O, 2024, Radiography (Lond), V30, P80, DOI 10.1016/j.radi.2023.10.011; Lee G-G, 2023, Gemini pro defeated by GPT-4V: evidence from education, V1; Li David, 2023, Radiology, V308, pe232082, DOI 10.1148/radiol.232082; Liyanage U.P., 2023, J. Comput. Soc. Dyn, V8, P15; Madl JEM, 2024, J MAGN RESON IMAGING, V59, P675, DOI 10.1002/jmri.29134; Mäkinen H, 2022, BEHAV INFORM TECHNOL, V41, P1, DOI 10.1080/0144929X.2020.1788162; Mes e I, 2023, Diagn Interventional Radiol, DOI [10.4274/dir.2023.232496.0(0):0-0, DOI 10.4274/DIR.2023.232496.0(0):0-0]; Metsälä E, 2017, INSIGHTS IMAGING, V8, P329, DOI 10.1007/s13244-016-0542-1; Mollick E, 2023, RES TECHNOL MANAGE, V66, P11, DOI 10.1080/08956308.2023.2213102; Msavardi, 2023, Zenodo, DOI 10.5281/ZENODO.10441155; Munn Z, 2015, J MED IMAGING RADIAT, V46, P23, DOI 10.1016/j.jmir.2014.07.006; Munn Z, 2016, J MED IMAGING RADIAT, V47, P329, DOI 10.1016/j.jmir.2016.04.007; Norbash A, 2016, J MAGN RESON IMAGING, V44, P1040, DOI 10.1002/jmri.25219; OpenAI, WHAT IS CHATGPT; OpenAi, ChatGPT; Portelli JL, 2018, RADIOGRAPHY, V24, P33, DOI 10.1016/j.radi.2017.08.009; Powell R, 2015, BRIT J HEALTH PSYCH, V20, P449, DOI 10.1111/bjhp.12132; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Rockall AG, 2022, EUR J RADIOL, V155, DOI 10.1016/j.ejrad.2022.110464; Ryan P, 2019, BMJ-BRIT MED J, V364, DOI 10.1136/bmj.l161; Rygiel K, 2017, NEUROPSYCH NEURO-POL, V12, P126, DOI 10.5114/nan.2017.71670; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scherr R, 2023, JMIR MED EDUC, V9, DOI 10.2196/49877; Stogiannos N, 2022, RADIOGRAPHY, V28, P133, DOI 10.1016/j.radi.2021.09.003; Szczotka AB, 2021, IEEE T MED IMAGING, V40, P1863, DOI 10.1109/TMI.2021.3067512; Tanana MJ, 2019, J MED INTERNET RES, V21, DOI 10.2196/12529; Tazegul G, 2015, MAGN RESON IMAGING, V33, P180, DOI 10.1016/j.mri.2014.08.024; van der Kruk SR, 2022, PATIENT EDUC COUNS, V105, P1928, DOI 10.1016/j.pec.2022.02.005; Vaswani A, 2017, ADV NEUR IN, V30; Wang XY, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000033592; Webb Jeremy J, 2023, Cureus, V15, pe38755, DOI 10.7759/cureus.38755; Wen X., Effects of aromatherapy and music therapy on patients' anxiety during MRI examinations: a randomized controlled trial, DOI [10.1007/s00330-022-09230-3, DOI 10.1007/S00330-022-09230-3]; Windover AK, 2013, The REDE model of healthcare communication: optimizing relationship as a therapeutic agent; Wollburg E, 2011, APPL PSYCHOPHYS BIOF, V36, P81, DOI 10.1007/s10484-011-9150-5; Wouda JC, 2012, PATIENT EDUC COUNS, V86, P57, DOI 10.1016/j.pec.2011.03.011; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhou Y, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1253824	73	0	0	5	5	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1078-8174	1532-2831		RADIOGRAPHY	Radiography	MAY	2024	30	3					737	744		10.1016/j.radi.2024.02.015	http://dx.doi.org/10.1016/j.radi.2024.02.015			8	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	QX7H9	38428198	hybrid			2024-07-03	WOS:001224227700001
J	Yu, ZH; Peng, C; Yang, X; Dang, C; Adekkanattu, P; Patra, BG; Peng, YF; Pathak, J; Wilson, DL; Chang, CY; Lo-Ciganic, WH; George, TJ; Hogan, WR; Guo, Y; Bian, J; Wu, YH				Yu, Zehao; Peng, Cheng; Yang, Xi; Dang, Chong; Adekkanattu, Prakash; Patra, Braja Gopal; Peng, Yifan; Pathak, Jyotishman; Wilson, Debbie L.; Chang, Ching -Yuan; Lo-Ciganic, Wei-Hsuan; George, Thomas J.; Hogan, William R.; Guo, Yi; Bian, Jiang; Wu, Yonghui			Identifying social determinants of health from clinical narratives: A study of performance, documentation ratio, and potential bias	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Social determinants of health; Large language model; Transformer; Clinical concept extraction; Natural language processing; Cancer	CANCER; DISPARITIES	Objective: To develop a natural language processing (NLP) package to extract social determinants of health (SDoH) from clinical narratives, examine the bias among race and gender groups, test the generalizability of extracting SDoH for different disease groups, and examine population-level extraction ratio. Methods: We developed SDoH corpora using clinical notes identified at the University of Florida (UF) Health. We systematically compared 7 transformer-based large language models (LLMs) and developed an open-source package - SODA (i.e., SOcial DeterminAnts) to facilitate SDoH extraction from clinical narratives. We examined the performance and potential bias of SODA for different race and gender groups, tested the generalizability of SODA using two disease domains including cancer and opioid use, and explored strategies for improvement. We applied SODA to extract 19 categories of SDoH from the breast (n = 7,971), lung (n =11,804), and colorectal cancer (n = 6,240) cohorts to assess patient-level extraction ratio and examine the differences among race and gender groups. Results: We developed an SDoH corpus using 629 clinical notes of cancer patients with annotations of 13,193 SDoH concepts/attributes from 19 categories of SDoH, and another cross-disease validation corpus using 200 notes from opioid use patients with 4,342 SDoH concepts/attributes. We compared 7 transformer models and the GatorTron model achieved the best mean average strict/lenient F1 scores of 0.9122 and 0.9367 for SDoH concept extraction and 0.9584 and 0.9593 for linking attributes to SDoH concepts. There is a small performance gap (similar to 4%) between Males and Females, but a large performance gap (>16 %) among race groups. The performance dropped when we applied the cancer SDoH model to the opioid cohort; fine-tuning using a smaller opioid SDoH corpus improved the performance. The extraction ratio varied in the three cancer cohorts, in which 10 SDoH could be extracted from over 70 % of cancer patients, but 9 SDoH could be extracted from less than 70 % of cancer patients. Individuals from the White and Black groups have a higher extraction ratio than other minority race groups. Conclusions: Our SODA package achieved good performance in extracting 19 categories of SDoH from clinical narratives. The SODA package with pre-trained transformer models is available at https://github.com/uf-hob i-informatics-lab/SODA_Docker.	[Yu, Zehao; Peng, Cheng; Yang, Xi; Dang, Chong; Hogan, William R.; Guo, Yi; Bian, Jiang; Wu, Yonghui] Univ Florida, Coll Med, Dept Hlth Outcomes & Biomed Informat, Gainesville, FL USA; [Peng, Cheng; Yang, Xi; Guo, Yi; Bian, Jiang; Wu, Yonghui] Univ Florida, Hlth Canc Ctr, Canc Informat Shared Resource, Gainesville, FL USA; [Adekkanattu, Prakash] Weill Cornell Med, Informat Technol & Serv, New York, NY USA; [Patra, Braja Gopal; Peng, Yifan; Pathak, Jyotishman] Weill Cornell Med, Dept Populat Hlth Sci, New York, NY USA; [Wilson, Debbie L.; Chang, Ching -Yuan; Lo-Ciganic, Wei-Hsuan] Univ Florida, Coll Pharm, Dept Pharmaceut Outcomes & Policy, Gainesville, FL 32611 USA; [George, Thomas J.] Univ Florida, Coll Med, Dept Med, Div Hematol & Oncol, Gainesville, FL USA; [Wu, Yonghui] Clin & Translat Res Bldg,2004 Mowry Rd,POB 100177, Gainesville, FL 32610 USA	State University System of Florida; University of Florida; State University System of Florida; University of Florida; Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; State University System of Florida; University of Florida; State University System of Florida; University of Florida	Wu, YH (corresponding author), Clin & Translat Res Bldg,2004 Mowry Rd,POB 100177, Gainesville, FL 32610 USA.	yonghui.wu@ufl.edu	; Wilson, Debbie/AAV-2571-2020	Adekkanattu, Prakash/0000-0003-1125-1449; Wilson, Debbie/0000-0002-1640-5497; Peng, Cheng/0000-0002-1994-893X	Patient-Centered Outcomes Research Institute (R) (PCORI (R)) [1R56AG069880]; National Institute on Aging [1R01AG080624-01, R21AG068717, R01AG080991, 23A09]; Ed and Ethel Moore Alzheimer's Disease Research Program [1R01CA246418]; National Cancer Institute [3R01CA246418-02S1, 1R21CA245858-01A1, R21CA245858-01A1S1, R21CA253394-01A1, R01AI172875]; National Institute of Allergy and Infectious Diseases [1R01HL169277]; National Heart, Lung, and Blood Institute [1R01DA050676]; National Institute on Drug Abuse [1R01MH121907]; National Institute of Mental Health [5R21MH129682-02, 4R00LM013001]; National Library of Medicine [2145640]; NSF Career [1U18DP006512]; Centers for Disease Control and Prevention;  [ME-2018C3-14754]	Patient-Centered Outcomes Research Institute (R) (PCORI (R))(Patient-Centered Outcomes Research Institute - PCORI); National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA)); Ed and Ethel Moore Alzheimer's Disease Research Program; National Cancer Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); National Institute of Allergy and Infectious Diseases(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID)); National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); National Institute on Drug Abuse(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)); National Institute of Mental Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH)); National Library of Medicine(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM)); NSF Career(National Science Foundation (NSF)NSF - Office of the Director (OD)); Centers for Disease Control and Prevention(United States Department of Health & Human ServicesCenters for Disease Control & Prevention - USA); 	This study was partially supported by grants from the Patient-Centered Outcomes Research Institute (R) (PCORI (R)) (ME-2018C3-14754) , the National Institute on Aging (1R56AG069880, 1R01AG080624-01, R21AG068717, R01AG080991) , Ed and Ethel Moore Alzheimer's Disease Research Program (23A09) , the National Cancer Institute (1R01CA246418, 3R01CA246418-02S1, 1R21CA245858-01A1, R21CA245858-01A1S1, R21CA253394-01A1, R21CA253394-01A1) , National Institute of Allergy and Infectious Diseases (R01AI172875) , National Heart, Lung, and Blood Institute (1R01HL169277) , National Institute on Drug Abuse (1R01DA050676) , National Institute of Mental Health (1R01MH121907, 5R21MH129682-02) , National Library of Medicine (4R00LM013001) , NSF Career (2145640) , and Centers for Disease Control and Prevention (1U18DP006512) .	aha, American Hospital Association| ICD-10-CM Coding for Social Determinants of Health; Akushevich Igor, 2011, ISRN Oncol, V2011, P415790, DOI 10.5402/2011/415790; Albright DL, 2021, SOC WORK PUBLIC HLTH, V36, P723, DOI 10.1080/19371918.2021.1939831; Alpert J, 2022, JMIR FORM RES, V6, DOI 10.2196/43059; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Braveman P, 2014, PUBLIC HEALTH REP, V129, P19, DOI 10.1177/00333549141291S206; Burnes D, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.17758; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cantu R, 2023, HEALTH PROMOT PRACT, V24, P16, DOI 10.1177/1524839920943207; Carson NJ, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0211116; Chen XG, 2014, AM J PUBLIC HEALTH, V104, pE119, DOI 10.2105/AJPH.2013.301530; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dillahunt-Aspillaga C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115873; EHP, 2018, Beyond Health Care: The Role of Social Determinants in Promoting Health and Health Equity; Eppes C, 2020, OBSTET GYNECOL, V135, p133S; Feller DJ, 2020, APPL CLIN INFORM, V11, P172, DOI 10.1055/s-0040-1702214; Feller Daniel J, 2018, AMIA Annu Symp Proc, V2018, P422; Galea S, 2011, AM J PUBLIC HEALTH, V101, P1456, DOI 10.2105/AJPH.2010.300086; Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360; Gerend MA, 2008, CANCER EPIDEM BIOMAR, V17, P2913, DOI 10.1158/1055-9965.EPI-07-0633; Gundlapalli A, 2020, AMIA Annu. Symp. Proc, V2019, P267; Gundlapalli Adi V, 2013, AMIA Annu Symp Proc, V2013, P537; Guo J., 2022, Circulation; Guo Y, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023818; Han SF, 2022, J BIOMED INFORM, V127, DOI 10.1016/j.jbi.2021.103984; Hatef E, 2022, JAMIA OPEN, V5, DOI 10.1093/jamiaopen/ooac006; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; health, Social Determinants of Health-Healthy People 2030 | health.gov.; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Hiatt RA, 2008, AM J PREV MED, V35, pS141, DOI 10.1016/j.amepre.2008.05.006; Hillemeier M, Data Set Directory of Social Determinants of Health at the Local Level, P75; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lybarger K, 2023, J AM MED INFORM ASSN, V30, P1367, DOI 10.1093/jamia/ocad012; Lybarger K, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103631; Matthews AK, 2018, SEMIN ONCOL NURS, V34, P12, DOI 10.1016/j.soncn.2017.11.001; Pager D, 2008, ANNU REV SOCIOL, V34, P181, DOI 10.1146/annurev.soc.33.040406.131740; Patra BG, 2021, J AM MED INFORM ASSN, V28, P2716, DOI 10.1093/jamia/ocab170; Probst JC, 2007, BMC HEALTH SERV RES, V7, DOI 10.1186/1472-6963-7-40; Putnam-Hornstein E, 2013, CHILD ABUSE NEGLECT, V37, P33, DOI 10.1016/j.chiabu.2012.08.005; Rajendran Suraj, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P507; Rangachari P, 2022, BMC PUBLIC HEALTH, V22, DOI 10.1186/s12889-022-12653-8; Saffer H, 2013, J HUM CAPITAL, V7, P378, DOI 10.1086/671200; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Singh Gopal K, 2017, Int J MCH AIDS, V6, P139, DOI 10.21106/ijma.236; Stemerman R, 2021, JAMIA OPEN, V4, DOI 10.1093/jamiaopen/ooaa069; Sterling MR, 2020, J AM HEART ASSOC, V9, DOI 10.1161/JAHA.119.014836; Thompson HM, 2021, J AM MED INFORM ASSN, V28, P2393, DOI 10.1093/jamia/ocab148; Wang Yan, 2015, AMIA Annu Symp Proc, V2015, P2121; Wolfe MK, 2020, AM J PUBLIC HEALTH, V110, P815, DOI 10.2105/AJPH.2020.305579; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yang X, 2020, J AM MED INFORM ASSN, V27, P1935, DOI 10.1093/jamia/ocaa189; Yang X, 2020, J AM MED INFORM ASSN, V27, P65, DOI 10.1093/jamia/ocz144; Yang X, 2019, DRUG SAFETY, V42, P123, DOI 10.1007/s40264-018-0761-0; Yetisgen M, 2017, LECT NOTES ARTIF INT, V10259, P171, DOI 10.1007/978-3-319-59758-4_18; Yu ZH, 2021, Arxiv, DOI arXiv:2108.04949; Yu ZH, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.778463	58	0	0	0	0	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	MAY	2024	153								104642	10.1016/j.jbi.2024.104642	http://dx.doi.org/10.1016/j.jbi.2024.104642			9	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	RW1R6	38621641	Green Submitted, Green Accepted			2024-07-03	WOS:001230611200001
J	Siepmann, R; Huppertz, M; Rastkhiz, A; Reen, M; Corban, E; Schmidt, C; Wilke, S; Schad, P; Yueksel, C; Kuhl, C; Truhn, D; Nebelung, S				Siepmann, Robert; Huppertz, Marc; Rastkhiz, Annika; Reen, Matthias; Corban, Eric; Schmidt, Christian; Wilke, Stephan; Schad, Philipp; Yueksel, Can; Kuhl, Christiane; Truhn, Daniel; Nebelung, Sven			The virtual reference radiologist: comprehensive AI assistance for clinical image reading and interpretation	EUROPEAN RADIOLOGY			English	Article; Early Access						Radiology; Diagnostic imaging; Artificial intelligence; Diagnostic errors		Objectives Large language models (LLMs) have shown potential in radiology, but their ability to aid radiologists in interpreting imaging studies remains unexplored. We investigated the effects of a state-of-the-art LLM (GPT-4) on the radiologists' diagnostic workflow. Materials and methods In this retrospective study, six radiologists of different experience levels read 40 selected radiographic [n = 10], CT [n = 10], MRI [n = 10], and angiographic [n = 10] studies unassisted (session one) and assisted by GPT-4 (session two). Each imaging study was presented with demographic data, the chief complaint, and associated symptoms, and diagnoses were registered using an online survey tool. The impact of Artificial Intelligence (AI) on diagnostic accuracy, confidence, user experience, input prompts, and generated responses was assessed. False information was registered. Linear mixed-effect models were used to quantify the factors (fixed: experience, modality, AI assistance; random: radiologist) influencing diagnostic accuracy and confidence. Results When assessing if the correct diagnosis was among the top-3 differential diagnoses, diagnostic accuracy improved slightly from 181/240 (75.4%, unassisted) to 188/240 (78.3%, AI-assisted). Similar improvements were found when only the top differential diagnosis was considered. AI assistance was used in 77.5% of the readings. Three hundred nine prompts were generated, primarily involving differential diagnoses (59.1%) and imaging features of specific conditions (27.5%). Diagnostic confidence was significantly higher when readings were AI-assisted (p > 0.001). Twenty-three responses (7.4%) were classified as hallucinations, while two (0.6%) were misinterpretations. Conclusion Integrating GPT-4 in the diagnostic process improved diagnostic accuracy slightly and diagnostic confidence significantly. Potentially harmful hallucinations and misinterpretations call for caution and highlight the need for further safeguarding measures. Clinical relevance statement Using GPT-4 as a virtual assistant when reading images made six radiologists of different experience levels feel more confident and provide more accurate diagnoses; yet, GPT-4 gave factually incorrect and potentially harmful information in 7.4% of its responses.	[Siepmann, Robert; Huppertz, Marc; Rastkhiz, Annika; Reen, Matthias; Corban, Eric; Schmidt, Christian; Wilke, Stephan; Schad, Philipp; Yueksel, Can; Kuhl, Christiane; Truhn, Daniel; Nebelung, Sven] Univ Hosp RWTH Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany	RWTH Aachen University; RWTH Aachen University Hospital	Nebelung, S (corresponding author), Univ Hosp RWTH Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany.	snebelung@ukaachen.de	Truhn, Daniel/AAG-9359-2021	Truhn, Daniel/0000-0002-9605-0728; Siepmann, Robert/0000-0002-4608-5180; Yuksel, Can/0000-0002-1719-9875	Horizon 2020 Framework Programme [2023]; COPE (Committee on Publication Ethics)	Horizon 2020 Framework Programme(Horizon 2020); COPE (Committee on Publication Ethics)	Following the COPE (Committee on Publication Ethics) position statement of February 13th, 2023 (https://publicationethics.org/cope-position-statements/ai-author), the authors hereby disclose the use of the following artificial intelligence models during the writing of this article. GPT-4 (OpenAI) for checking spelling and grammar.	Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Akinci DAntonoli T, 2023, Diagn Interv Radiol, V30, P80; Bajaj S, 2024, ACAD RADIOL, V31, P1256, DOI 10.1016/j.acra.2023.08.039; Bera K, 2024, CURR PROBL DIAGN RAD, V53, P215, DOI 10.1067/j.cpradiol.2023.10.013; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Dratsch T, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222176; Faul F, 2007, BEHAV RES METHODS, V39, P175, DOI 10.3758/BF03193146; Finck T, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020452; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lightman H, 2023, Arxiv, DOI [arXiv:2305.20050, DOI 10.48550/ARXIV.2305.20050]; Nav N, 2023, 97+ ChatGPT Statistics & User Numbers in May 2023 (New Data); Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Rao Arya S., 2023, medRxiv; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Suthar Pokhraj P, 2023, Cureus, V15, pe43958, DOI 10.7759/cureus.43958; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]	22	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0938-7994	1432-1084		EUR RADIOL	Eur. Radiol.	2024 APR 16	2024										10.1007/s00330-024-10727-2	http://dx.doi.org/10.1007/s00330-024-10727-2		APR 2024	15	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	OE9X7	38627289	hybrid			2024-07-03	WOS:001205718800003
J	Suppadungsuk, S; Thongprayoon, C; Krisanapan, P; Tangpanithandee, S; Valencia, OG; Miao, J; Mekraksakit, P; Kashani, K; Cheungpasitporn, W				Suppadungsuk, Supawadee; Thongprayoon, Charat; Krisanapan, Pajaree; Tangpanithandee, Supawit; Valencia, Oscar Garcia; Miao, Jing; Mekraksakit, Poemlarp; Kashani, Kianoush; Cheungpasitporn, Wisit			Examining the Validity of ChatGPT in Identifying Relevant Nephrology Literature: Findings and Implications	JOURNAL OF CLINICAL MEDICINE			English	Article						ChatGPT; nephrology literature; references; reliability; accuracy	LITERATURE SEARCH; FUTURE	Literature reviews are valuable for summarizing and evaluating the available evidence in various medical fields, including nephrology. However, identifying and exploring the potential sources requires focus and time devoted to literature searching for clinicians and researchers. ChatGPT is a novel artificial intelligence (AI) large language model (LLM) renowned for its exceptional ability to generate human-like responses across various tasks. However, whether ChatGPT can effectively assist medical professionals in identifying relevant literature is unclear. Therefore, this study aimed to assess the effectiveness of ChatGPT in identifying references to literature reviews in nephrology. We keyed the prompt "Please provide the references in Vancouver style and their links in recent literature on horizontal ellipsis name of the topic" into ChatGPT-3.5 (03/23 Version). We selected all the results provided by ChatGPT and assessed them for existence, relevance, and author/link correctness. We recorded each resource's citations, authors, title, journal name, publication year, digital object identifier (DOI), and link. The relevance and correctness of each resource were verified by searching on Google Scholar. Of the total 610 references in the nephrology literature, only 378 (62%) of the references provided by ChatGPT existed, while 31% were fabricated, and 7% of citations were incomplete references. Notably, only 122 (20%) of references were authentic. Additionally, 256 (68%) of the links in the references were found to be incorrect, and the DOI was inaccurate in 206 (54%) of the references. Moreover, among those with a link provided, the link was correct in only 20% of cases, and 3% of the references were irrelevant. Notably, an analysis of specific topics in electrolyte, hemodialysis, and kidney stones found that >60% of the references were inaccurate or misleading, with less reliable authorship and links provided by ChatGPT. Based on our findings, the use of ChatGPT as a sole resource for identifying references to literature reviews in nephrology is not recommended. Future studies could explore ways to improve AI language models' performance in identifying relevant nephrology literature.	[Suppadungsuk, Supawadee; Thongprayoon, Charat; Krisanapan, Pajaree; Tangpanithandee, Supawit; Valencia, Oscar Garcia; Miao, Jing; Mekraksakit, Poemlarp; Kashani, Kianoush; Cheungpasitporn, Wisit] Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA; [Suppadungsuk, Supawadee; Tangpanithandee, Supawit] Mahidol Univ, Fac Med, Chakri Naruebodindra Med Inst, Ramathibodi Hosp, Samut Prakan 10540, Thailand; [Krisanapan, Pajaree] Thammasat Univ Hosp, Div Nephrol, Pathum Thani 12120, Thailand	Mayo Clinic; Mahidol University; Thammasat University	Cheungpasitporn, W (corresponding author), Mayo Clin, Dept Med, Div Nephrol & Hypertens, Rochester, MN 55905 USA.	s.suppadungsuk@hotmail.com; charat.thongprayoon@gmail.com; pajaree_fai@hotmail.com; supawit_d@hotmail.com; garciavalencia.oscar@mayo.edu; miao.jing@mayo.edu; mekraksakit.poemlarp@mayo.edu; kashani.kianoush@mayo.edu; wcheungpasitporn@gmail.com	Krisanapan, Pajaree/GOH-1278-2022; Miao, Jing/IWE-2159-2023; Cheungpasitporn, Wisit/H-8194-2019; Thongprayoon, Charat/J-4184-2019; Miao, Jing/IWE-2204-2023; suppadungsuk, supawadee/ISU-2478-2023	Krisanapan, Pajaree/0000-0002-2888-881X; Miao, Jing/0000-0003-0642-9740; Cheungpasitporn, Wisit/0000-0001-9954-9711; Thongprayoon, Charat/0000-0002-8313-3604; Tangpanithandee, Supawit/0000-0001-6103-2338; Suppadungsuk, Supawadee/0000-0003-1597-2411; Kashani, Kianoush/0000-0003-2184-3683; Mekraksakit, Poemlarp/0000-0002-2127-2529; Garcia Valencia, Oscar/0000-0003-0186-9448				Alhasan K, 2023, ACTA PAEDIATR, DOI 10.1111/apa.16867; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Blanco-González A, 2022, Arxiv, DOI arXiv:2212.08104; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chavez MR, 2023, AM J OBSTET GYNECOL, V228, P706, DOI 10.1016/j.ajog.2023.03.010; Connor CW, 2019, ANESTHESIOLOGY, V131, P1346, DOI 10.1097/ALN.0000000000002694; Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Gottlieb M, 2023, AM J EMERG MED, V70, P81, DOI 10.1016/j.ajem.2023.05.018; Grewal A, 2016, INDIAN J ANAESTH, V60, P635, DOI 10.4103/0019-5049.190618; Jamal Amr, 2023, Cureus, V15, pe43036, DOI 10.7759/cureus.43036; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kuper A, 2006, ACAD MED, V81, pS128, DOI 10.1097/00001888-200610001-00032; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lu YQ, 2023, ANN BIOMED ENG, V51, P1898, DOI 10.1007/s10439-023-03234-w; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; Martin S, 2017, SCOT MED J, V62, P58, DOI 10.1177/0036933017707163; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Meskó B, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00333-z; Miao J, 2023, KIDNEY INT REP, V8, P1657, DOI 10.1016/j.ekir.2023.05.014; Mojadeddi ZM, 2023, NEW ZEAL MED J, V136, P60; Niel O, 2019, AM J KIDNEY DIS, V74, P803, DOI 10.1053/j.ajkd.2019.05.020; openai, ChatGPT GPT-4.0; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; platform, Models Overview; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Salas M, 2022, PHARM MED, V36, P295, DOI 10.1007/s40290-022-00441-z; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Siddiqui TA, 2022, J PAK MED ASSOC, V72, pS91, DOI 10.47391/JPMA.AKU-18; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744	45	16	16	12	34	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2077-0383		J CLIN MED	J. Clin. Med.	SEP	2023	12	17							5550	10.3390/jcm12175550	http://dx.doi.org/10.3390/jcm12175550			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	R6EL7	37685617	Green Published, gold			2024-07-03	WOS:001065264400001
J	Wang, XZ; Zhong, YH; Huang, CQ; Huang, XD				Wang, Xizhe; Zhong, Yihua; Huang, Changqin; Huang, Xiaodi			ChatPRCS: A Personalized Support System for English Reading Comprehension Based on ChatGPT	IEEE TRANSACTIONS ON LEARNING TECHNOLOGIES			English	Article						Chatbots; Artificial intelligence; Linguistics; Prediction algorithms; Vocabulary; Task analysis; Learning systems; Chat generative pretrained transformer (ChatGPT); personalized question generation (QG); prompt engineering; reading comprehension	LEARNING-PERFORMANCE PREDICTION; NEURAL-NETWORKS	Reading comprehension is a widely adopted method for learning English, involving reading articles and answering related questions. However, the reading comprehension training typically focuses on the skill level required for a standardized learning stage, without considering the impact of individual differences in linguistic competence. This article presents a personalized support system for reading comprehension, named chat generative pretrained transformer (ChatGPT)-based personalized reading comprehension support (ChatPRCS), based on the zone of proximal development (ZPD) theory. It leverages the advanced capabilities of large language models, exemplified by ChatGPT. ChatPRCS employs methods, including skill prediction, question generation and automatic evaluation, to enhance reading comprehension instruction. First, a ZPD-based algorithm is developed to predict students' reading comprehension skills. This algorithm analyzes historical data to generate questions with appropriate difficulty. Second, a series of ChatGPT prompt patterns is proposed to address two key aspects of reading comprehension objectives: question generation, and automated evaluation. These patterns further improve the quality of generated questions. Finally, by integrating personalized skill prediction and reading comprehension prompt patterns, ChatPRCS is validated through a series of experiments. Empirical results demonstrate that it provides learners with high-quality reading comprehension questions that are broadly aligned with expert-crafted questions at a statistical level. Furthermore, this study investigates the effect of the system on learning achievement, learning motivation, and cognitive load, providing further evidence of its effectiveness in instructing English reading comprehension.	[Wang, Xizhe; Zhong, Yihua; Huang, Changqin] Zhejiang Normal Univ, Zhejiang Key Lab Intelligent Educ Technol & Applic, Jinhua 321004, Peoples R China; [Huang, Xiaodi] Charles Sturt Univ, Sch Comp Math & Engn, Albury, NSW 2640, Australia	Zhejiang Normal University; Charles Sturt University	Huang, CQ (corresponding author), Zhejiang Normal Univ, Zhejiang Key Lab Intelligent Educ Technol & Applic, Jinhua 321004, Peoples R China.	xzwang@zjnu.edu.cn; yiwer007@zjnu.edu.cn; cqhuang@zju.edu.cn; xhuang@csu.edu.au	Huang, Xiaodi/E-9204-2012	Huang, Xiaodi/0000-0002-6084-1851; Huang, Changqin/0000-0003-1371-2608	National Science and Technology Major	National Science and Technology Major	No Statement Available	Amorim AN, 2022, COMPUT EDUC, V177, DOI 10.1016/j.compedu.2021.104364; BARNETT MA, 1986, MOD LANG J, V70, P343, DOI 10.2307/326811; Barrot JS, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100745; Ben Jabeur S, 2020, J OPER RES SOC, V71, P1161, DOI 10.1080/01605682.2019.1581405; Biswas SK, 2017, SOFT COMPUT, V21, P7579, DOI 10.1007/s00500-016-2312-x; Chaipidech P., 2022, Computers and Education: Artificial Intelligence, V3, P100064, DOI [10.1016/j.caeai.2022.100064, DOI 10.1016/J.CAEAI.2022.100064]; Chen MP, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103602; Chomphooyod P., 2023, Comput. Educ.: Artif. Intell., V5; Cohen J., 1988, Statistical power and analysis for the behavioral sciences, V2nd ed.; Domingos P., 1999, P 5 ACM SIGKDD INT C, V55, P155, DOI DOI 10.1145/312129.312220; Elleman AM, 2022, LEARN INDIVID DIFFER, V98, DOI 10.1016/j.lindif.2022.102182; Fan TT, 2020, STUD EDUC EVAL, V67, DOI 10.1016/j.stueduc.2020.100931; Ferguson C., 2022, Comput. Educ.: Artif. Intell., V3; Freed J, 2015, RES DEV DISABIL, V41-42, P13, DOI 10.1016/j.ridd.2015.03.003; Goyal N, 2022, T ASSOC COMPUT LING, V10, P522, DOI 10.1162/tacl_a_00474; Han S, 2022, TECHNOL SOC, V70, DOI 10.1016/j.techsoc.2022.102002; Heil CR., 2016, The EuroCALL Review, V24, P32, DOI [10.4995/eurocall.2016.6402, DOI 10.4995/EUROCALL.2016.6402]; Huang AYQ, 2023, COMPUT EDUC, V194, DOI 10.1016/j.compedu.2022.104684; Huo MRY, 2021, LEARN INDIVID DIFFER, V92, DOI 10.1016/j.lindif.2021.102082; Hwang G.-J., 2020, Comput. Educ. Artif. Intell., V1, DOI [DOI 10.1016/J.CAEAI.2020.100001, 10.1016/j.caeai.2020.100001]; Hwang GJ, 2013, COMPUT EDUC, V69, P121, DOI 10.1016/j.compedu.2013.07.008; Khodadi I, 2016, INFORM PROCESS MANAG, V52, P340, DOI 10.1016/j.ipm.2015.09.001; Kim YJ, 2016, EXPERT SYST APPL, V62, P32, DOI 10.1016/j.eswa.2016.06.016; Kinnunen R., 1995, Learn. Instruct., V5, P143, DOI [10.1016/0959-4752(95)00009-R, DOI 10.1016/0959-4752(95)00009-R]; Lee YF, 2022, ETR&D-EDUC TECH RES, V70, P1843, DOI 10.1007/s11423-022-10142-8; Li HY, 2021, COMPUT EDUC, V171, DOI 10.1016/j.compedu.2021.104239; Lim Lyn, 2023, Computers in Human Behavior, DOI 10.1016/j.chb.2022.107547; Liu CC, 2022, COMPUT EDUC, V189, DOI 10.1016/j.compedu.2022.104576; Liu M., 2023, Future in Educational Research, V1, P72, DOI [DOI 10.1002/FER3.10, 10.1002/fer3.10]; Liu M, 2024, IEEE T LEARN TECHNOL, V17, P815, DOI 10.1109/TLT.2023.3333439; Liu SM, 2023, IEEE T NEUR NET LEAR, V34, P186, DOI 10.1109/TNNLS.2021.3091681; Loibl K, 2017, EDUC PSYCHOL REV, V29, P693, DOI 10.1007/s10648-016-9379-x; M. of Education Examination Center, 1999, National Public English Proficiency Test Syllabus; McCarthy KS, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102283; Muñoz-Cristóbal JA, 2018, IEEE T LEARN TECHNOL, V11, P203, DOI 10.1109/TLT.2017.2693150; Murphy DH, 2023, EDUC PSYCHOL REV, V35, DOI 10.1007/s10648-023-09808-3; Nicholas M, 2021, LEARN CULT SOC INTER, V30, DOI 10.1016/j.lcsi.2021.100530; PINCHES GE, 1973, J FINANC, V28, P1, DOI 10.2307/2978164; Pintrich P.R., 1991, MOTIVATED STRATEGIES; Qian DD, 2002, LANG LEARN, V52, P513, DOI 10.1111/1467-9922.00193; Rao CHD, 2023, IEEE T LEARN TECHNOL, V16, P40, DOI 10.1109/TLT.2022.3224232; Ronimus M, 2022, LEARN INDIVID DIFFER, V98, DOI 10.1016/j.lindif.2022.102197; Sampayo-Vargas S, 2013, COMPUT EDUC, V69, P452, DOI 10.1016/j.compedu.2013.07.004; Snyder L, 2005, TOP LANG DISORD, V25, P33, DOI 10.1097/00011363-200501000-00005; Song CY, 2023, KNOWL-BASED SYST, V264, DOI 10.1016/j.knosys.2023.110290; Su YF, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100752; Sun JCY, 2012, BRIT J EDUC TECHNOL, V43, P191, DOI 10.1111/j.1467-8535.2010.01157.x; Tossell CC, 2024, IEEE T LEARN TECHNOL, V17, P1069, DOI 10.1109/TLT.2024.3355015; Vajjala S, 2018, INT J ARTIF INTELL E, V28, P79, DOI 10.1007/s40593-017-0142-3; Wang M, 2024, IEEE T LEARN TECHNOL, V17, P629, DOI 10.1109/TLT.2023.3324714; Wang XZ, 2021, INFORM SCIENCES, V545, P223, DOI 10.1016/j.ins.2020.08.017; Wang XZ, 2019, COMPUTING, V101, P587, DOI 10.1007/s00607-018-00699-9; Wertsch J.W., 1984, NEW DIRECTIONS CHILD, P7, DOI DOI 10.1002/CD.23219842303; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xie H, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103599; Zhai C., 2023, Computers and Education: Artificial Intelligence, DOI [10.1016/j.caeai.2023.100134, DOI 10.1016/J.CAEAI.2023.100134]; Zheng CP, 2023, SYSTEM, V115, DOI 10.1016/j.system.2023.103037; Zhou ZH, 2006, IEEE T KNOWL DATA EN, V18, P63, DOI 10.1109/TKDE.2006.17	58	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1939-1382			IEEE T LEARN TECHNOL	IEEE Trans. Learn. Technol.		2024	17						1762	1776		10.1109/TLT.2024.3405747	http://dx.doi.org/10.1109/TLT.2024.3405747			15	Computer Science, Interdisciplinary Applications; Education & Educational Research	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Education & Educational Research	UL1C1		Green Submitted			2024-07-03	WOS:001248112800001
C	Wang, RZ; Najafabadi, MM; Zhang, CQ; Chen, LQ; Olenina, T; Yankov, D		Damiani, ML; Renz, M; Eldawy, A; Kroger, P; Nascimento, MA		Wang, Renzhong; Najafabadi, Maryam Mousaarab; Zhang, Chiqun; Chen, Long-Qi; Olenina, Tanya; Yankov, Dragomir			GPT Applications in Relevance Model Training in Map Search	31ST ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, ACM SIGSPATIAL GIS 2023			English	Proceedings Paper	31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS)	NOV 13-16, 2023	Hamburg, GERMANY	ACM SIGSPATIAL, Apple, Oracle, Esri		GPT; query processing; maps service; information retrieval		Understanding map queries and retrieving correct entity results are the two main relevance tasks in Map search. They are usually performed by a set of task specific machine learning models. Collecting large amount of high quality labelled data for training such models is a time-consuming and labor-intensive process. Although various methods have been studied for producing pseudo data labels, they are limited in their effectiveness when applied across different languages or tasks. The recently released Large Language models (LLMs), including ChatGPT and GPT-4 (GPT for short), have demonstrated state-of-the-art performance in text understanding by using simple prompt instructions with only a handful of examples for in-context learning. In this paper, we explore GPT as a cost-effective alternative for both data labeling and synthetic data generation, where we subsequently use data obtained from this approach to train various task specific models such as maps intent detection, address detection, address parsing, geo-entity ranking, and rank scores calibration. GPT demonstrates strong potential in generating otherwise hard-to-synthesize data. We observe significant accuracy and relevance improvement across all task specific models when trained or fine-tuned on data generated by GPT. Lastly, we propose a general framework combining labeled data from GPT with other sources and a prompt fine-tune structure to guide GPT model in completing a given task.	[Wang, Renzhong; Najafabadi, Maryam Mousaarab; Olenina, Tanya] Microsoft Corp, Redmond, WA 98052 USA; [Zhang, Chiqun; Yankov, Dragomir] Microsoft, Mountain View, CA USA; [Chen, Long-Qi] Microsoft, Taipei, Taiwan	Microsoft; Microsoft	Wang, RZ (corresponding author), Microsoft Corp, Redmond, WA 98052 USA.	rewan@microsoft.com; maryam.mousaarab@microsoft.com; chizhang@microsoft.com; a-longqichen@microsoft.com; taolen@microsoft.com; dragoy@microsoft.com						Berkhin P., 2015, Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems, P1; Craig H, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), P424, DOI 10.1145/3347146.3359070; Huang J, 2022, FEM LEGAL STUD, V30, P1, DOI 10.1007/s10691-021-09472-4; Li X., 2014, P 4 INT WORKSH LOC W, P33, DOI 10.1145/2663713.2664430; OpenAI, 2023, Gpt-4 technical report, 2023.; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Wei Jason, 2022, arXiv:2201.11903; Zhang Chiqun, 2021, FAST ATTENTION BASED	8	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0168-9				2023							382	385		10.1145/3589132.3625618	http://dx.doi.org/10.1145/3589132.3625618			4	Computer Science, Information Systems; Remote Sensing	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Remote Sensing	BW4XN		Bronze			2024-07-03	WOS:001156830400068
C	Yue, ZR; Zeng, HM; Zhang, Y; Shang, LY; Wang, D		Rogers, A; Boyd-Graber, J; Okazaki, N		Yue, Zhenrui; Zeng, Huimin; Zhang, Yang; Shang, Lanyu; Wang, Dong			MetaAdapt: Domain Adaptive Few-Shot Misinformation Detection via Meta Learning	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			FAKE NEWS	With emerging topics (e.g., COVID-19) on social media as a source for the spreading misinformation, overcoming the distributional shifts between the original training domain (i.e., source domain) and such target domains remains a non-trivial task for misinformation detection. This presents an elusive challenge for early-stage misinformation detection, where a good amount of data and annotations from the target domain is not available for training. To address the data scarcity issue, we propose MetaAdapt, a meta learning based approach for domain adaptive few-shot misinformation detection. MetaAdapt leverages limited target examples to provide feedback and guide the knowledge transfer from the source to the target domain (i.e., learn to adapt). In particular, we train the initial model with multiple source tasks and compute their similarity scores to the meta task. Based on the similarity scores, we rescale the meta gradients to adaptively learn from the source tasks. As such, MetaAdapt can learn how to adapt the misinformation detection model and exploit the source data for improved performance in the target domain. To demonstrate the efficiency and effectiveness of our method, we perform extensive experiments to compare MetaAdapt with state-of-the-art baselines and large language models (LLMs) such as LLaMA, where MetaAdapt achieves better performance in domain adaptive few-shot misinformation detection with substantially reduced parameters on real-world datasets.	[Yue, Zhenrui; Zeng, Huimin; Zhang, Yang; Shang, Lanyu; Wang, Dong] Univ Illinois, Champaign, IL 61820 USA	University of Illinois System; University of Illinois Urbana-Champaign	Yue, ZR (corresponding author), Univ Illinois, Champaign, IL 61820 USA.	zhenrui3@illinois.edu; huiminz3@illinois.edu; yzhangnd@illinois.edu; lshang3@illinois.edu; dwang24@illinois.edu		Shang, Lanyu/0000-0002-7480-6889	National Science Foundation [IIS-2202481, CHE-2105005, IIS-2008228, CNS-1845639, CNS1831669]	National Science Foundation(National Science Foundation (NSF))	This research is supported in part by the National Science Foundation under Grant No. IIS-2202481, CHE-2105005, IIS-2008228, CNS-1845639, CNS1831669. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on.	Abhijit Suprem, 2022, ARXIV220509817; Abu Salem Fatima K, 2021, PATTERNS, V2; [Anonymous], 2020, 2020 INT JOINT C NEU, DOI DOI 10.1109/ICC40277.2020.9148641; Antoniou A., 2018, P INT C LEARN REPR, P1; Brand E., 2021, TTO, P18; Buntain C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P208, DOI 10.1109/SmartCloud.2017.40; Chen Canyu, 2022, ARXIV221105289; Cui LM, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P492, DOI 10.1145/3394486.3403092; Cui Limeng, 2020, ARXIV; Das Sourya Dipta, 2021, INT WORKSH COMB ONL, P164, DOI DOI 10.1007/978-3-030-73696-516; Finn C, 2017, PR MACH LEARN RES, V70; Han CC, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1664; Hayawi K, 2022, PUBLIC HEALTH, V203, P23, DOI 10.1016/j.puhe.2021.11.022; He Bing., 2023, WWW 23 P ACM WEB C 2, P2698, DOI [10.1145/3543507.3583388, DOI 10.1145/3543507.3583388]; Hu Edward J, 2021, arXiv preprint arXiv:2106.09685; Hu LM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P754; Jiang GY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103029; Jin Zhiwei, 2016, P AAAI C ART INT, V30; Kang GL, 2019, PROC CVPR IEEE, P4888, DOI 10.1109/CVPR.2019.00503; Karimi H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3432; Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552; Kou ZY, 2021, IEEE INT CONF DISTR, P140, DOI 10.1109/DCOSS52077.2021.00035; Kou Ziyi, 2022, IJCAI, P5087; Kou Ziyi, 2022, PROC ACM HUM COMPUT, V6, P1; Lee N, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1971; Lei T., 2022, P 29 INT C COMP LING, P4873; Li S, 2018, IEEE T IMAGE PROCESS, V27, P4260, DOI 10.1109/TIP.2018.2839528; Li YC, 2021, IEEE INT CONF BIG DA, P668, DOI 10.1109/BigData52589.2021.9671592; Lin J. Ma, 2022, FINDINGS ASS COMPUTA, P2543; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Liu Z., 2020, ACL, P7342; Monti F., 2019, ARXIV190206673; Mosallanezhad A, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3632, DOI 10.1145/3485447.3512258; Motiian S, 2017, ADV NEUR IN, V30; Na J, 2021, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR46437.2021.00115; Nan Q., 2022, P 29 INT C COMP LING, P2834; Patwa P., 2021, Communications in Computer and Information Science, V1402, P21, DOI DOI 10.1007/978-3-030-73696-5_3; Rajeswaran A, 2019, ADV NEUR IN, V32; Risdal M., 2016, Getting real about fake news; Robnik-Sikonja M., 2022, Neurocomputing; Roozenbeek J, 2020, ROY SOC OPEN SCI, V7, DOI 10.1098/rsos.201199; Ryu M, 2022, KNOWL INF SYST, V64, P3113, DOI 10.1007/s10115-022-01736-y; Santiari Ni Putu Linda, 2022, 2022 4th International Conference on Cybernetics and Intelligent System (ICORIS), P1, DOI 10.1109/ICORIS56080.2022.10031351; Serrano Juan Carlos Medina, 2020, P 1 WORKSH NLP COVID; Shang LY, 2022, INT WORKSH QUAL SERV, DOI 10.1109/IWQoS54832.2022.9812879; Shang LY, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P3623, DOI 10.1145/3485447.3512257; Shang LY, 2021, IEEE INT CONF BIG DA, P899, DOI 10.1109/BigData52589.2021.9671928; Shang Lanyu, 2022, ADV SOCIAL NETWORKS, P34; Sharaf A, 2020, NEURAL GENERATION AND TRANSLATION, P43; Shen K, 2022, PR MACH LEARN RES, P19847; Shu K, 2020, P INT AAAI C WEB SOC, V14, P626; Shu K., 2022, FRONTIERS FAKE MEDIA, P215, DOI [https://doi.org/10.1007/978-981-19-1524-6_9, DOI 10.1007/978-981-19-1524-6_9]; Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062; Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994; Shu Kai, 2020, Disinformation, misinformation, and fake news in social media; Sicilia Anthony, 2021, ARXIV210203924; Silva A, 2021, AAAI CONF ARTIF INTE, V35, P557; Snell J, 2017, ADV NEUR IN, V30; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thorne J, 2018, CONFNORTH AM CHAPTER, V1, P809, DOI [10.18653/v1/n18-1074, DOI 10.18653/V1/N18-1074, 10.18653/v1/N18-1074]; Touvron Hugo, 2023, ARXIV230213971; Tseng H.Y., 2020, ARXIV200108735; Vinyals O, 2016, 30 C NEURAL INFORM P, V29; Vo N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7717; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903; Wu Junfei, 2022, ACM SIGKDD EXPLORATI; Wu XQ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P543; Wu Zhenyu, 2023, ARXIV230302913; Xie BH, 2022, AAAI CONF ARTIF INTE, P8708; Yue ZR, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2423, DOI 10.1145/3511808.3557263; Zeng Huimin, 2022, UNSUPERVISED DOMAIN, P159; Zhang Qiang, 2021, ARXIV210803805; Zhao An, 2021, P IEEECVF WINTER C A, P1390; Zhou P., 2021, Uncertainty in artificial intelligence, P23	76	1	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							5223	5239						17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086804007
C	Akbar, KA; Halim, SM; Hu, YB; Singhal, A; Khan, L; Thuraisingham, B		Sural, S; Lu, H		Akbar, Khandakar Ashrafi; Halim, Sadaf Md; Hu, Yibo; Singhal, Anoop; Khan, Latifur; Thuraisingham, Bhavani			Knowledge Mining in Cybersecurity: From Attack to Defense	DATA AND APPLICATIONS SECURITY AND PRIVACY XXXVI, DBSEC 2022	Lecture Notes in Computer Science		English	Proceedings Paper	36th Annual IFIP WG 11.3 Conference on Data and Applications Security and Privacy (DBSec)	JUL 18-20, 2022	Newark, NJ	IFIP WG 11 3		Cyber Threat Intelligence; Natural Language Processing; Semantic Association		In the fast-evolving world of Cybersecurity, an analyst often has the difficult task of responding to new threats and attack campaigns within a limited amount of time. If an analyst fails to do so, this can lead to severe consequences for the system under attack. In this work, we are motivated to aid the security analyst by introducing a tool which will help to produce a swift and effective response to incoming threats. If an analyst identifies the nature of an incoming attack, our system can produce a ranked list of solutions for the analyst to quickly try out, saving both effort and time. Currently, the security analyst is typically left to manually produce a solution by consulting existing frameworks and knowledge bases, such as the ATT&CK and D3FEND frameworks by the MITRE Corporation. To solve these challenges, our tool leverages state-of-the-art machine learning frameworks to provide a comprehensive solution for security analysts. Our tool uses advanced natural language processing techniques, including a large language model (RoBERTa), to derive meaningful semantic associations between descriptions of offensive techniques and defensive countermeasures. Experimental results confirm that our proposed method can provide useful suggestions to the security analyst with good accuracy, especially in comparison to baseline approaches which fail to exhibit the semantic and contextual understanding necessary to make such associations.	[Akbar, Khandakar Ashrafi; Halim, Sadaf Md; Hu, Yibo; Khan, Latifur; Thuraisingham, Bhavani] Univ Texas Dallas, 800 West Campbell Rd, Richardson, TX 75080 USA; [Singhal, Anoop] NIST, 100 Bur Dr, Gaithersburg, MD 20899 USA	University of Texas System; University of Texas Dallas; National Institute of Standards & Technology (NIST) - USA	Akbar, KA (corresponding author), Univ Texas Dallas, 800 West Campbell Rd, Richardson, TX 75080 USA.	kxa190007@utdallas.edu			NSF [DMS-1737978, DGE-2039542, OAC-1828467, OAC-1931541, DGE-1906630]; ONR [N00014-17-1-2995, N00014-20-1-2738]; Army Research Office [W911NF2110032]; DARPA [FA8750-19-C-0006]; IBM faculty award	NSF(National Science Foundation (NSF)); ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); Army Research Office; DARPA(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); IBM faculty award(International Business Machines (IBM))	The research reported herein was supported in part by NSF awards DMS-1737978, DGE-2039542, OAC-1828467, OAC-1931541, and DGE-1906630, ONR awards N00014-17-1-2995 and N00014-20-1-2738, Army Research Office Contract No. W911NF2110032, DARPA FA8750-19-C-0006, and IBM faculty award (Research).	Akbar K. A., 2021, P INT C INF SYST SEC, P3; Ayoade G., 2020, IEEE CONF COMM NETW, P1, DOI DOI 10.1109/cns48642.2020.9162264; Ayoade G, 2018, 2018 4TH IEEE INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC 2018), P236, DOI 10.1109/CIC.2018.00040; Booth H., 2013, The national vulnerability database (nvd): Overview; Debnath B, 2018, INT CON DISTR COMP S, P1052, DOI 10.1109/ICDCS.2018.00105; Devlin J., 2019, C N AM CHAPTER ASS C; Face H, 2019, ROBERTAE; Han J., 2015, SYSTEMS METHODS DETE; Hutchins E, 2011, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION WARFARE AND SECURITY, P113; Jibilian I., 2021, US IS READYING SANCT; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Masud MM, 2010, LECT NOTES ARTIF INT, V6119, P311; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; MITRE, CVE; MITRE, 2021, D3FEND; MITRE, 2015, ENT MATR; OpenCV, 2020, ZERO SHOT LEARNING I; OpenIOC, 2013, OP IND COMPR; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Sammut C., 2010, ENCY MACHINE LEARNIN, P986, DOI 10.1007/978-0-387-30164-8832; STIX, 2021, STRUCTURED THREAT IN; Strom B.E., 2017, FINDING CYBER THREAT; TAXII, 2021, TRUST AUT EXCH INT I; Tomas Mikolov ( Google), 2013, EFFICIENT ESTIMATION; Zou Q., 2021, DBSEC 2021 DATA APPL, DOI [10.1007/978-3-030-81242-313, DOI 10.1007/978-3-030-81242-313]	25	5	6	3	9	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-10684-2; 978-3-031-10683-5	LECT NOTES COMPUT SC			2022	13383						110	122		10.1007/978-3-031-10684-2_7	http://dx.doi.org/10.1007/978-3-031-10684-2_7			13	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BU1EQ					2024-07-03	WOS:000876988000007
J	Sharma, M; Kandasamy, I; Vasantha, WB				Sharma, Mayukh; Kandasamy, Ilanthenral; Vasantha, W. B.			Emotion quantification and classification using the neutrosophic approach to deep learning	APPLIED SOFT COMPUTING			English	Article						Neutrosophy; Sentiment analysis; Refined emotion neutrosophic set; Emotion quantification; Neutrosophic iterative neural clustering (NINC)	SET	Advancements in the rapidly evolving specialization of deep learning have aided in improving several natural language understanding tasks. Sentiment and emotion classification models have improved, but when it comes to fine-grained sentiment analysis, these models can perform better. Human sentiment in natural language is generally an intricate combination of emotions, which can sometimes be indeterminate, neutral, or ambiguous. In the case of fine-grained sentiment analysis, the sentiments can be very similar to each other and interconnected, e.g., anger and fear. Most deep learning systems try to solve the problem of fine-grained sentiment analysis as a classification problem. However, fine-grained sentiments might combine similar emotions with one primary emotion. Trying to solve the problem as a classification task can result in better performance on benchmarks but does not ensure a better understanding and representation of language. The proposed work explores applying neutrosophy for fine-grained sentiment analysis using large language models. Neutrosophy identifies neutralities and employs membership functions (neutral, positive, negative) to quantify an instance into Single Valued Neutrosophic Sets (SVNS). This paper introduces Refined Emotion Neutrosophic Sets (RENS) for emotions (with four emotions) and Refined Ekman's Emotion Neutrosophic Sets (REENS) with seven emotions. In this paper, refined neutrosophic sets with membership functions are employed for each sentiment across a given taxonomy and assigned their values using the Neutrosophic Iterative Neural Clustering (NINC) algorithm proposed in this paper. It facilitates not only classifying sentiments but also quantifying the presence of each sentiment present in a given sample. It aids in better understanding and representation of samples across multiple sentiments, as in fine-grained sentiment analysis, experiments are performed on the GoEmotions dataset. The proposed approach performs on par with cross-entropy deep learning classifiers and is reproducible across different pre-trained language models.	[Sharma, Mayukh] Univ Calif San Diego, San Diego, CA 92093 USA; [Kandasamy, Ilanthenral; Vasantha, W. B.] VIT, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India	University of California System; University of California San Diego; Vellore Institute of Technology (VIT); VIT Vellore	Kandasamy, I (corresponding author), VIT, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.	mas037@ucsd.edu; ilanthenral.k@vit.ac.in; vasantha.wb@vit.ac.in						[Anonymous], 2013, Progress Phys, DOI DOI 10.5281/ZENODO.49149; Awajan I, 2021, IEEE ACCESS, V9, P47338, DOI 10.1109/ACCESS.2021.3067844; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Baziotis C., 2017, P 11 INT WORKSHOP, P747; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Cambria E, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P105, DOI 10.1145/3340531.3412003; Chatterjee A., 2019, P 13 INT WORKSHOP SE, P39, DOI [10.18653/, DOI 10.18653/V1/S19-2005]; Chen LY, 2022, INT J MACH LEARN CYB, V13, P2153, DOI 10.1007/s13042-022-01512-y; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Demszky D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4040; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550; Essameldin R, 2022, IEEE ACCESS, V10, P63314, DOI 10.1109/ACCESS.2022.3183108; Fersini E., 2022, P 16 INT WORKSHOP SE, P533; Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265; Ghazi D, 2015, LECT NOTES COMPUT SC, V9042, P152, DOI 10.1007/978-3-319-18117-2_12; Jain A, 2020, SOFT COMPUT, V24, P3, DOI 10.1007/s00500-019-04209-7; Kandasamy I., 2020, Optimization Theory Based on Neutrosophic and Plithogenic Sets, P117; Kandasamy I, 2020, COMPUT IND, V115, DOI 10.1016/j.compind.2019.103180; Kandasamy I, 2020, SOFT COMPUT, V24, P7459, DOI 10.1007/s00500-019-04372-x; Kandasamy I, 2018, J INTELL SYST, V27, P163, DOI 10.1515/jisys-2016-0088; Kandasamy I, 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI); Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Liu PD, 2018, INT J MACH LEARN CYB, V9, P281, DOI 10.1007/s13042-015-0385-y; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Meaney J.A., 2021, P 15 INT WORKSHOP SE, P105, DOI 10.18653/v1/2021.semeval-1.9; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mohammad S., 2018, P 12 INT WORKSHOP SE, P1; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Phan HT, 2023, INFORM FUSION, V91, P149, DOI 10.1016/j.inffus.2022.10.004; Rosenthal S., 2017, P 11 INT WORKSHOP SE, P502; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shahi TB, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5681574; Sharma C., 2020, arXiv preprint arXiv:2008.03781, P759; Sharma M., 2022, P 16 INT WORKSHOP SE, P761; Sharma M., 2021, P 15 INT WORKSH SEM, P1146, DOI [10.18653/v1/2021.semeval-1.161, DOI 10.18653/V1/2021.SEMEVAL-1.161]; Sharma M., 2020, P 14 WORKSH SEM EV S, P1163; Sharma M, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115458; Sharma M, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107058; Sitaula C, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/2158184; Smarandache F, 2019, APPL SOFT COMPUT, V80, P167, DOI 10.1016/j.asoc.2019.03.034; Song K., 2020, NEURIPS 2020; Tan CQ, 2018, LECT NOTES COMPUT SC, V11141, P270, DOI 10.1007/978-3-030-01424-7_27; Vasantha WB, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030402; Vaswani A, 2017, ADV NEUR IN, V30; Wang H, 2010, SINGLE VALUED NEUTRO; Yang ZL, 2019, ADV NEUR IN, V32; Ye J, 2015, ARTIF INTELL MED, V63, P171, DOI 10.1016/j.artmed.2014.12.007; Ye J, 2014, APPL MATH MODEL, V38, P1170, DOI 10.1016/j.apm.2013.07.020; Zhang DW, 2021, NEUROCOMPUTING, V436, P260, DOI 10.1016/j.neucom.2020.11.046; Zhang DW, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P294, DOI 10.1145/3394171.3413743; Zhang J., 2022, P 16 INT WORKSH SEM, P585; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	55	1	1	8	15	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1568-4946	1872-9681		APPL SOFT COMPUT	Appl. Soft. Comput.	NOV	2023	148								110896	10.1016/j.asoc.2023.110896	http://dx.doi.org/10.1016/j.asoc.2023.110896		OCT 2023	13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	W6OI8		hybrid			2024-07-03	WOS:001092797000001
J	Han, LF; Gladkoff, S; Erofeev, G; Sorokina, I; Galiano, B; Nenadic, G				Han, Lifeng; Gladkoff, Serge; Erofeev, Gleb; Sorokina, Irina; Galiano, Betty; Nenadic, Goran			Neural machine translation of clinical text: an empirical investigation into multilingual pre-trained language models and transfer-learning	FRONTIERS IN DIGITAL HEALTH			English	Article						Neural machine translation; clinical text translation; multilingual pre-trained language model; large language model; transfer learning; clinical knowledge transformation; Spanish-English translation	SYSTEM; CT	Clinical text and documents contain very rich information and knowledge in healthcare, and their processing using state-of-the-art language technology becomes very important for building intelligent systems for supporting healthcare and social good. This processing includes creating language understanding models and translating resources into other natural languages to share domain-specific cross-lingual knowledge. In this work, we conduct investigations on clinical text machine translation by examining multilingual neural network models using deep learning such as Transformer based structures. Furthermore, to address the language resource imbalance issue, we also carry out experiments using a transfer learning methodology based on massive multilingual pre-trained language models (MMPLMs). The experimental results on three sub-tasks including (1) clinical case (CC), (2) clinical terminology (CT), and (3) ontological concept (OC) show that our models achieved top-level performances in the ClinSpEn-2022 shared task on English-Spanish clinical domain data. Furthermore, our expert-based human evaluations demonstrate that the small-sized pre-trained language model (PLM) outperformed the other two extra-large language models by a large margin in the clinical domain fine-tuning, which finding was never reported in the field. Finally, the transfer learning method works well in our experimental setting using the WMT21fb model to accommodate a new language space Spanish that was not seen at the pre-training stage within WMT21fb itself, which deserves more exploitation for clinical knowledge transformation, e.g. to investigate into more languages. These research findings can shed some light on domain-specific machine translation development, especially in clinical and healthcare fields. Further research projects can be carried out based on our work to improve healthcare text analytics and knowledge transformation. Our data is openly available for research purposes at: https://github.com/HECTA-UoM/ClinicalNMT.	[Han, Lifeng; Nenadic, Goran] Univ Manchester, Dept Comp Sci, Manchester, England; [Gladkoff, Serge; Erofeev, Gleb; Sorokina, Irina] Logrus Global Translat & Localizat, AI Lab, Philadelphia, PA 18944 USA; [Galiano, Betty] Ocean Translat, Management Dept, Rosario, Argentina	University of Manchester	Han, LF; Nenadic, G (corresponding author), Univ Manchester, Dept Comp Sci, Manchester, England.; Gladkoff, S (corresponding author), Logrus Global Translat & Localizat, AI Lab, Philadelphia, PA 18944 USA.	Lifeng.Han@manchester.ac.uk; serge.gladkoff@logrusglobal.com; g.nenadic@manchester.ac.uk		Han, Lifeng/0000-0002-3221-2185	Assembling the Data Jigsaw: Powering Robust Research on the Causes, Determinants and Outcomes of MSK Disease"; Nuffield Foundation; Integrating hospital outpatient letters in to the healthcare data space [EP/V047949/1]	Assembling the Data Jigsaw: Powering Robust Research on the Causes, Determinants and Outcomes of MSK Disease"; Nuffield Foundation; Integrating hospital outpatient letters in to the healthcare data space	LH and GN are grateful for the support from the grant "Assembling the Data Jigsaw: Powering Robust Research on the Causes, Determinants and Outcomes of MSK Disease". The project has been funded by the Nuffield Foundation, but the views expressed are those of the authors and not necessarily the Foundation. Visit www.nuffieldfoundation.org. LH and GN are also supported by the grant "Integrating hospital outpatient letters in to the healthcare data space"(EP/V047949/1; funder: UKRI/EPSRC)	Almansor Ebtesam H, 2018, Machine Learning and Data Mining in Pattern Recognition, P347; Alyafeai Z, 2020, Arxiv, DOI arXiv:2007.04239; [Anonymous], 1955, Machine Translation of Languages: Fourteen Essays; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Belkadi S, 2023, Arxiv, DOI arXiv:2210.12770; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Bojar O, 2016, P 1 C MACH TRANSL, V2, P131; Costa-jussa, 2022, arXiv, DOI DOI 10.48550/ARXIV.2207.04672; Dehghan A, 2015, J BIOMED INFORM, V58, pS53, DOI 10.1016/j.jbi.2015.06.029; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dew KN, 2018, J BIOMED INFORM, V85, P56, DOI 10.1016/j.jbi.2018.07.018; Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279; Elbattah M, 2021, HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF, P825, DOI 10.5220/0010414508250832; Fan A, 2021, J MACH LEARN RES, V22; Fintey G., 2018, P 2018 C N AM CHAPTE, V3, P121; Gladkoff S, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P13; Gricit B., 2023, IEEE 11th International Conference on Healthcare Informatics (ICHI), P627, DOI [10.1109/ICHI57859.2023.00110, DOI 10.1109/ICHI57859.2023.00110]; Han L., 2023, P 5 CLIN NAT LANG PR, P31; Han L., 2021, P 23 NORD C COMP LIN, P336; Han L., 2021, P 1 WORKSHOP MODELLI, P15; Han L., 2022, An investigation into multi-word expressions in machine translation; Han L., 2018, P ESSLLI 2018 ASS LO, P54; Han LF, 2023, Arxiv, DOI arXiv:2210.06068; Han Lifeng, 2022, P 7 C MACHINE TRANSL, P908; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Islam MA, 2021, NEURAL COMPUT APPL, V33, P12141, DOI 10.1007/s00521-021-05895-x; Jiang H, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107856; Junczys-Dowmunt M, 2018, NEURAL MACHINE TRANSLATION AND GENERATION, P129; Junczys-Dowmunt M, 2018, 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P116; Junczys-Dowmunt Marcin, 2017, P INT JOINT C NAT LA, V1, P120; Khoong EC, 2022, J GEN INTERN MED, V37, P1275, DOI 10.1007/s11606-021-07164-y; Kovacevic A, 2013, J AM MED INFORM ASSN, V20, P859, DOI 10.1136/amiajnl-2013-001625; Kuang SH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1767; Lepikhin Dmitry, 2020, Gshard: Scaling giant models with conditional computation and automatic sharding; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Luo X, 2022, IEEE J BIOMED HEALTH, V26, P1737, DOI 10.1109/JBHI.2021.3123192; Manchanda S., 2022, P 7 C MACH TRANSL WM, P925; Mujjiga S, 2019, AAAI CONF ARTIF INTE, P9552; Neves M., 2022, WMT22 7 C MACHINE TR, P694; Nguyen NTH., 2023, arXiv, DOI [10.48550/arXiv.2302.05392, DOI 10.48550/ARXIV.2302.05392]; Noor K, 2022, JMIR MED INF, V10, DOI 10.2196/38122; Oyebode O, 2021, JMIR MED INF, V9, DOI 10.2196/22734; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng YF, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P58; Percha B, 2021, ANNU REV BIOMED DA S, V4, P165, DOI 10.1146/annurev-biodatasci-030421-030931; Pomares-Quimbaya A, 2021, STUD HEALTH TECHNOL, V281, P377, DOI 10.3233/SHTI210184; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Qian ZZ, 2021, MACH LEARN, V110, P15, DOI 10.1007/s10994-020-05921-4; Randhawa G, 2013, CAN FAM PHYSICIAN, V59, P382; Rei R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2685; Sennrich R., 2017, P DEM 15 C EUR CHAPT; Soto Xabier, 2019, P 2 WORKSH MULT INT, P8; Spasic I, 2020, JMIR MED INF, V8, DOI 10.2196/17984; Tiedemann J., 2020, P 22 ANN C EUROPEAN, P479; Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214; Tran C., 2021, P WMT; Vaswani A, 2017, ADV NEUR IN, V30; Villegas M., 2018, LREC MULTILINGUALBIO; Wang W., 2022, P 7 C MACH TRANSL WM, P930; Wroge TJ, 2018, IEEE SIG PROC MED, DOI 10.1109/SPMB.2018.8615607; Yang H, 2009, J AM MED INFORM ASSN, V16, P596, DOI 10.1197/jamia.M3096; Yeganova L., 2021, P 6 C MACH TRANSL ON, P664; Zhang Biao, 2021, 9 INT C LEARN REPR 2; Zhu ZW, 2021, INTERDISCIP SCI, V13, P73, DOI 10.1007/s12539-020-00408-1	64	0	0	3	3	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-253X		FRONT DIGIT HEALTH	Front. Digit. Health	FEB 26	2024	6								1211564	10.3389/fdgth.2024.1211564	http://dx.doi.org/10.3389/fdgth.2024.1211564			16	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	KI7S7	38468693	gold, Green Submitted, Green Published			2024-07-03	WOS:001179402300001
J	Chen, H; Liao, BY; Luo, J; Zhu, WJ; Yang, XY				Chen, Hang; Liao, Bingyu; Luo, Jing; Zhu, Wenjing; Yang, Xinyu			Learning a Structural Causal Model for Intuition Reasoning in Conversation	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Causal model; conversation; implicit causes; utterance relationship	GRAPH; GENERATION; NETWORK; MEMORY	Reasoning, a crucial aspect of NLP research, has not been adequately addressed by prevailing models including Large Language Model. Conversation reasoning, as a critical component of it, remains largely unexplored due to the absence of a well-designed cognitive model. In this article, inspired by intuition theory on conversation cognition, we develop a conversation cognitive model (CCM) that explains how each utterance receives and activates channels of information recursively. Besides, we algebraically transformed CCM into a structural causal model (SCM) under some mild assumptions, rendering it compatible with various causal discovery methods. We further propose a probabilistic implementation of the SCM for utterance-level relation reasoning. By leveraging variational inference, it explores substitutes for implicit causes, addresses the issue of their unobservability, and reconstructs the causal representations of utterances through the evidence lower bounds. Moreover, we constructed synthetic and simulated datasets incorporating implicit causes and complete cause labels, alleviating the current situation where all available datasets are implicit-causes-agnostic. Extensive experiments demonstrate that our proposed method significantly outperforms existing methods on synthetic, simulated, and real-world datasets. Finally, we analyze the performance of CCM under latent confounders and propose theoretical ideas for addressing this currently unresolved issue.	[Chen, Hang; Luo, Jing; Yang, Xinyu] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Shannxi, Peoples R China; [Liao, Bingyu] Chinese Univ Hong Kong, Dept Cultural & Religious Studies, Hong Kong, Peoples R China; [Zhu, Wenjing] Du Xiao Man Inc, Beijing 100089, Peoples R China	Xi'an Jiaotong University; Chinese University of Hong Kong	Chen, H (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian 710049, Shannxi, Peoples R China.	albert2123@stu.xjtu.edu.cn; bingyuliao@link.cuhk.edu.hk; luojingl@stu.xjtu.edu.cn; thinkre7@163.com; yxyphd@mail.xjtu.edu.cn		Luo, Jing/0000-0001-7138-3705				Acheli M, 2022, IEEE T KNOWL DATA EN, V34, P5708, DOI 10.1109/TKDE.2021.3077653; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agrawal R, 2021, Arxiv, DOI arXiv:2102.07921; Allan K, 2013, PERSP PRAGMAT PHILO, V2, P285, DOI 10.1007/978-3-319-01014-4_11; Baker C. L., 2014, Plan Activity Intent Recognit. Theory Pract., V7, P177; Bernstein DI, 2020, PR MACH LEARN RES, V108, P4098; Bikakis A, 2010, IEEE T KNOWL DATA EN, V22, P1492, DOI 10.1109/TKDE.2010.37; Bloch Charlotte., 1996, Human Studies, V16, P323; Brown-Schmidt S, 2016, TOP COGN SCI, V8, P722, DOI 10.1111/tops.12224; Chen H., 2023, P C EMP METH NAT LAN, P494; Chen H, 2022, Arxiv, DOI arXiv:2208.13549; Chen H, 2022, IEEE T KNOWL DATA EN, V34, P2254, DOI 10.1109/TKDE.2020.3014166; Chen R., 2022, Toward a Motivation Model of Pragmatics; Cheng G, 2023, IEEE T KNOWL DATA EN, V35, P4825, DOI 10.1109/TKDE.2022.3144391; Civitarese G, 2021, IEEE T KNOWL DATA EN, V33, P209, DOI 10.1109/TKDE.2019.2930050; Clark H., 1977, Basic Processes in Reading: Perception and Production, P243; CLARK HH, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P127, DOI 10.1037/10096-006; CLARK HH, 1989, COGNITIVE SCI, V13, P259, DOI 10.1207/s15516709cog1302_7; Du ZX, 2023, IEEE T KNOWL DATA EN, V35, P1283, DOI 10.1109/TKDE.2021.3104310; Evans RJ, 2016, SCAND J STAT, V43, P625, DOI 10.1111/sjos.12194; Funakoshi K., 2022, arXiv; Gao J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P807; Gerstenberg T., 2017, Oxford Hand-book Causal Reasoning, P515, DOI DOI 10.1093/OXFORDHB/9780199399550.013.28; Ghosal D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P154; Gupta N., 2019, P INT C LEARN REPR, P1; Hargie O., 2021, Skilled interpersonal communication: Research, theory and practice; Heim Irene., 1983, SEMANTICS CRITICAL C, P108; Horton WS, 1996, COGNITION, V59, P91, DOI 10.1016/0010-0277(96)81418-1; Houlihan S. D., 2022, P ANN M COGN SCI SOC, P854; Hu LM, 2023, IEEE T KNOWL DATA EN, V35, P11141, DOI 10.1109/TKDE.2022.3231338; Hunt M, 2022, J PRAGMATICS, V188, P152, DOI 10.1016/j.pragma.2021.11.005; Hunter A, 2000, KNOWL ENG REV, V15, P317, DOI 10.1017/S0269888900002046; Kamp H, 2013, CURR RES SEMANT PRAG, V29, P329; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; King DB, 2015, ACS SYM SER, V1214, P1; Kleres J, 2011, J THEOR SOC BEHAV, V41, P182, DOI 10.1111/j.1468-5914.2010.00451.x; Knyazev B, 2019, ADV NEUR IN, V32; Kojima T, 2022, ADV NEUR IN; Li W, 2023, IEEE T AFFECT COMPUT, V14, P1754, DOI 10.1109/TAFFC.2022.3216551; Li Y., 2017, P 8 INT JOINT C NATU, P986; Li YF, 2023, Arxiv, DOI arXiv:2206.02336; Lian Z, 2021, NEUROCOMPUTING, V454, P483, DOI 10.1016/j.neucom.2021.05.017; LITMAN DJ, 1987, COGNITIVE SCI, V11, P163, DOI 10.1207/s15516709cog1102_4; Liu HC, 2022, IEEE T KNOWL DATA EN, V34, P1011, DOI 10.1109/TKDE.2020.2997175; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu ZB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1782; Lowe S., 2022, C CAUSAL LEARNING RE, P509; Lyu Z, 2023, IEEE T KNOWL DATA EN, V35, P4954, DOI 10.1109/TKDE.2022.3142260; Maddison C., 2017, INT C LEARNING REPRE, P1; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; McKinley GL, 2017, MEM COGNITION, V45, P1281, DOI 10.3758/s13421-017-0730-3; Pearl Judea, 2009, CAUSALITY, DOI DOI 10.1017/CBO9780511803161; Peng L, 2022, IEEE T KNOWL DATA EN, V34, P1644, DOI 10.1109/TKDE.2020.2998805; Peng YH, 2019, KNOWL-BASED SYST, V163, P429, DOI 10.1016/j.knosys.2018.09.006; Poesio M, 1997, COMPUT INTELL-US, V13, P309, DOI 10.1111/0824-7935.00042; Poria S, 2021, COGN COMPUT, V13, P1317, DOI 10.1007/s12559-021-09925-7; Reed ES, 1997, HUM DEV, V40, P245, DOI 10.1159/000278728; Roy S., 2015, P 2015 C EMPIRICAL M, P1743, DOI DOI 10.18653/V1/D15-1202; Sanchez-Romero R, 2019, NETW NEUROSCI, V3, P274, DOI 10.1162/netn_a_00061; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Shen Q, 2012, IEEE T KNOWL DATA EN, V24, P649, DOI 10.1109/TKDE.2010.255; Shen WZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1551; Shen WZ, 2021, AAAI CONF ARTIF INTE, V35, P13789; Shen Y, 2021, IEEE T KNOWL DATA EN, V33, P3607, DOI 10.1109/TKDE.2020.2970044; Shimizu S, 2006, J MACH LEARN RES, V7, P2003; Sidera F, 2018, CURR PSYCHOL, V37, P82, DOI 10.1007/s12144-016-9492-5; Solomon Denise., 2012, INTERPERSONAL COMMUN; Song LF, 2022, IEEE T KNOWL DATA EN, V34, P631, DOI 10.1109/TKDE.2020.2982894; Sordoni A., 2015, P C N AM CHAPT ASS C, P196, DOI DOI 10.3115/V1/N15-1020; Spirtes P., 2013, P 29 C UNC ART INT, P606; Squires C., 2022, C CAUSAL LEARNING RE, P669; Stalnaker R, 2002, LINGUIST PHILOS, V25, P701, DOI 10.1023/A:1020867916902; Stalnaker R., 1999, Pragmatics, P78, DOI [DOI 10.1163/9789004368873_013, 10.1093/0198237073.003.0005]; Sun X, 2018, COGN COMPUT, V10, P389, DOI 10.1007/s12559-017-9539-4; Teo D. W., 2022, P ANN M COGN SCI SOC, P2200; Van Dijk T. A., 1983, STRATEGIES DISCOURSE; Velickovic P., 2017, stat, V1050, P10; Vo DV, 2023, IEEE T KNOWL DATA EN, V35, P6811, DOI 10.1109/TKDE.2022.3188497; Wang WC, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107246; Wang XM, 2023, IEEE T KNOWL DATA EN, V35, P9836, DOI 10.1109/TKDE.2022.3159802; Wang XZ, 2022, Arxiv, DOI arXiv:2207.00747; Wei JS, 2022, ADV NEUR IN; Wei KW, 2023, IEEE T KNOWL DATA EN, V35, P8865, DOI 10.1109/TKDE.2022.3218830; Wei YW, 2023, IEEE T KNOWL DATA EN, V35, P11153, DOI 10.1109/TKDE.2022.3231352; Xia R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1003; Xie F., 2020, Neural Information Processing Systems; Yang ZG, 2023, IEEE T KNOWL DATA EN, V35, P10210, DOI 10.1109/TKDE.2023.3267036; Yao LY, 2023, IEEE T KNOWL DATA EN, V35, P8799, DOI 10.1109/TKDE.2022.3209997; Yu JX, 2023, IEEE T KNOWL DATA EN, V35, P725, DOI 10.1109/TKDE.2021.3073227; Yuan Y, 2023, IEEE T KNOWL DATA EN, V35, P1938, DOI 10.1109/TKDE.2021.3110724; Zelikman E, 2022, ADV NEUR IN; Zhang D, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5415; Zhang Z., 2022, P 11 INT C LEARN REP, P1; Zhao W., 2022, P 31 INT JOINT C ART, P4524; Zheng CJ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P115; Zheng YS, 2023, IEEE T KNOWL DATA EN, V35, P1567, DOI 10.1109/TKDE.2021.3100564; Zhou H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4623; Zhou H, 2018, AAAI CONF ARTIF INTE, P730; Zhu QN, 2021, IEEE T KNOWL DATA EN, V33, P2015, DOI 10.1109/TKDE.2019.2951103	99	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2024	36	7					3210	3223		10.1109/TKDE.2024.3352575	http://dx.doi.org/10.1109/TKDE.2024.3352575			14	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TZ2O6		Green Submitted			2024-07-03	WOS:001245017200045
J	Glanois, C; Weng, PL; Zimmer, M; Li, D; Yang, TP; Hao, JY; Liu, WL				Glanois, Claire; Weng, Paul; Zimmer, Matthieu; Li, Dong; Yang, Tianpei; Hao, Jianye; Liu, Wulong			A survey on interpretable reinforcement learning	MACHINE LEARNING			English	Article; Early Access						Reinforcement learning; Deep reinforcement learning; Interpretability; Explainability	MODELS; LEVEL; POLICIES; SKILLS; MDPS	Although deep reinforcement learning has become a promising machine learning approach for sequential decision-making problems, it is still not mature enough for high-stake domains such as autonomous driving or medical applications. In such contexts, a learned policy needs for instance to be interpretable, so that it can be inspected before any deployment (e.g., for safety and verifiability reasons). This survey provides an overview of various approaches to achieve higher interpretability in reinforcement learning (RL). To that aim, we distinguish interpretability (as an intrinsic property of a model) and explainability (as a post-hoc operation) and discuss them in the context of RL with an emphasis on the former notion. In particular, we argue that interpretable RL may embrace different facets: interpretable inputs, interpretable (transition/reward) models, and interpretable decision-making. Based on this scheme, we summarize and analyze recent work related to interpretable RL with an emphasis on papers published in the past 10 years. We also discuss briefly some related research areas and point to some potential promising research directions, notably related to the recent development of foundation models (e.g., large language models, RL from human feedback).	[Glanois, Claire] ITU, Real Lab, Copenhagen, Denmark; [Weng, Paul] Duke Kunshan Univ, Kunshan, Peoples R China; [Zimmer, Matthieu] Huawei, London, England; [Li, Dong; Hao, Jianye; Liu, Wulong] Huawei, Beijing, Peoples R China; [Yang, Tianpei; Hao, Jianye] Tianjin Univ, Tianjin, Peoples R China	Duke Kunshan University; Huawei Technologies; Huawei Technologies; Tianjin University	Weng, PL (corresponding author), Duke Kunshan Univ, Kunshan, Peoples R China.	paul.weng@dukekunshan.edu.cn			Huawei Technologies	Huawei Technologies(Huawei Technologies)	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adjodah D., 2018, NEURIPS WORKSHOP REP; Agnew W., 2018, NEURIPS WORKSHOP DEE; AI HLEG, 2019, ETHICS GUIDELINES TR; Akkaya I, 2019, Arxiv, DOI [arXiv:1910.07113, DOI 10.48550/ARXIV.1910.07113]; Akrour R., 2019, WORKSHOP DEEP CONTIN; Aksaray D, 2016, IEEE DECIS CONTR P, P6565, DOI 10.1109/CDC.2016.7799279; Alharin A, 2020, IEEE ACCESS, V8, P171058, DOI 10.1109/ACCESS.2020.3023394; Amodei D, 2016, Arxiv, DOI arXiv:1606.06565; Ananny M, 2018, NEW MEDIA SOC, V20, P973, DOI 10.1177/1461444816676645; Andersen G, 2017, ADV NEUR IN, V30; Anderson G., 2020, NEURIPS; Andreas J, 2017, PR MACH LEARN RES, V70; Annasamy RM, 2019, AAAI CONF ARTIF INTE, P4561; Arnold T., 2017, AAAI WORKSHOP; Arora S, 2020, Arxiv, DOI arXiv:1806.06877; Atrey A., 2020, ICLR; Ault J., 2020, AAMAS; Bader S., 2005, We Will Show Them: Essays in Honour of Dov Gabbay; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Barto AG, 2003, DISCRETE EVENT DYN S, V13, P41, DOI [10.1023/A:1022140919877, 10.1023/A:1025696116075]; Barwise J., 1977, Studies in Logic and the Foundations of Mathematics, V90, P5, DOI [10.1016/S0049-237X(08)71097-8, DOI 10.1016/S0049-237X(08)71097-8]; Bastani O, 2018, ADV NEUR IN, V31; Battaglia Peter W, 2016, NEURIPS; Bear D., 2020, NEURIPS; Bertsekas D. P., 1996, Neuro-Dynamic Programming; Bewley T., 2022, AAMAS; Bewley T, 2021, AAAI CONF ARTIF INTE, V35, P11415; Beyret B, 2019, IEEE INT C INT ROBOT, P5014, DOI [10.1109/iros40897.2019.8968488, 10.1109/IROS40897.2019.8968488]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bonnefon JF, 2019, P IEEE, V107, P502, DOI 10.1109/JPROC.2019.2897447; Bosch A.V.D., 2011, Encyclopedia of Machine Learning, P495, DOI DOI 10.1007/978-0-387-30164-8_363; Boutilier C, 2000, ARTIF INTELL, V121, P49, DOI 10.1016/S0004-3702(00)00033-3; Brunelli R., 2009, Template matching techniques in computer vision: theory and practice, DOI DOI 10.1002/9780470744055; Brunner Gino, 2020, 8 INT C LEARNING REP; Bucila C., 2006, P KDD, P535, DOI 10.1145/1150402.1150464; Burke M, 2019, ROBOTICS: SCIENCE AND SYSTEMS XV; Lipton ZC, 2017, Arxiv, DOI [arXiv:1606.03490, 10.48550/arXiv.1606.03490]; Camacho A, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6065; Cao Y., 2022, NEURIPS; Casper S, 2023, Arxiv, DOI [arXiv:2307.15217, 10.48550/arXiv.2307.15217]; Chang M.B., 2017, 5 INT C LEARN REPR I; Chari S, 2020, Arxiv, DOI arXiv:2003.07523; Chen J., 2020, ICML WORKSHOP AUTONO; Cichosz P, 2014, INT J AP MAT COM-POL, V24, P579, DOI 10.2478/amcs-2014-0042; Cimatti A, 2008, FOUND ARTIF INTELL, P841, DOI 10.1016/S1574-6526(07)03022-2; Cole J., 2003, INANNUAL PARTNER C; Colmenarejo S. G., 2016, ICLR; Coppens Y., 2019, IJCAI WORKSHOP XAI; Corazza J, 2022, AAAI CONF ARTIF INTE, P6429; Cranmer Miles, 2020, NEURIPS; Crawford K., 2016, Tech. rep; Cropper A, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4833; Cruz F, 2019, LECT NOTES ARTIF INT, V11919, P66, DOI 10.1007/978-3-030-35288-2_6; Garcez AD, 2018, Arxiv, DOI arXiv:1804.08597; Daly A., 2019, SSRN Electronic Journal, DOI [10.2139/ssrn.3414805, DOI 10.2139/SSRN.3414805]; Das Gupta U, 2015, AAAI CONF ARTIF INTE, P2547; De Raedt L, 2015, MACH LEARN, V100, P5, DOI 10.1007/s10994-015-5494-z; Dean T., 1989, Computational Intelligence, V5, P142, DOI 10.1111/j.1467-8640.1989.tb00324.x; Raji ID, 2020, Arxiv, DOI [arXiv:2001.00973, 10.48550/arXiv.2001.00973, DOI 10.48550/ARXIV.2001.00973]; Degris T., 2006, ICML CESSES REINFORC; Delfosse Q., 2023, NEURIPS; Demeester T., 2016, EMNLP; Diligenti M, 2017, ARTIF INTELL, V244, P143, DOI 10.1016/j.artint.2015.08.011; Diuk C., 2008, P 25 INT C MACHINE L, DOI 10.1145/1390156.1390187; Donadello I, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1596; Doshi-Velez F, 2019, Arxiv, DOI [arXiv:1711.01134, DOI 10.2139/SSRN.3064761]; Dragan AD, 2013, ACMIEEE INT CONF HUM, P301, DOI 10.1109/HRI.2013.6483603; Driessens, 2001, EWRL; Driessens K, 2006, MACH LEARN, V64, P91, DOI 10.1007/s10994-006-8258-y; Dutra A. R., 2017, CEUR WORKSHOP P; Dwork C., 2012, ICTS; Dzeroski S, 2001, MACH LEARN, V43, P7, DOI 10.1023/A:1007694015589; Dzeroski S., 1998, ICML; Ernst D, 2005, J MACH LEARN RES, V6, P503; Evans R, 2018, J ARTIF INTELL RES, V61, P1; Eysenbach B, 2019, ADV NEUR IN, V32; Finn Chelsea, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2786, DOI 10.1109/ICRA.2017.7989324; Finn C., 2016, NEURIPS; Franca MVM, 2014, MACH LEARN, V94, P81, DOI 10.1007/s10994-013-5392-1; François-Lavet V, 2019, AAAI CONF ARTIF INTE, P3582; Friedler SA, 2021, COMMUN ACM, V64, P136, DOI 10.1145/3433949; Friedman D., 2023, NEURIPS; Fujimoto S, 2018, PR MACH LEARN RES, V80; Fukuchi Y, 2017, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON HUMAN AGENT INTERACTION (HAI'17), P97, DOI 10.1145/3125739.3125746; Furelos-Blanco D, 2021, J ARTIF INTELL RES, V70, P1031; Gaon M, 2020, AAAI CONF ARTIF INTE, V34, P3980; Garg S, 2020, Arxiv, DOI arXiv:2002.07375; Garnelo M., 2016, NEURIPS WORKSHOP DRL; Gilmer J, 2017, PR MACH LEARN RES, V70; Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018; Glaese A, 2022, arXiv; Goel V, 2018, ADV NEUR IN, V31; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Greydanus S, 2018, PR MACH LEARN RES, V80; Grzes M, 2008, 2008 4TH INTERNATIONAL IEEE CONFERENCE INTELLIGENT SYSTEMS, VOLS 1 AND 2, P416; Guestrin C., 2003, IJCAI; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gupta P., 2020, ICLR; Haarnoja T, 2018, PR MACH LEARN RES, V80; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Hasanbeig M, 2020, LECT NOTES COMPUT SC, V12288, P1, DOI 10.1007/978-3-030-57628-8_1; Hayes B, 2017, ACMIEEE INT CONF HUM, P303, DOI 10.1145/2909824.3020233; Hein D, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCCO'19 COMPANION), P23, DOI 10.1145/3319619.3326755; Hein D, 2018, ENG APPL ARTIF INTEL, V76, P158, DOI 10.1016/j.engappai.2018.09.007; Hein D, 2017, ENG APPL ARTIF INTEL, V65, P87, DOI 10.1016/j.engappai.2017.07.005; Henderson P, 2018, AAAI CONF ARTIF INTE, P3207; Heuillet A, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106685; Higgins I, 2018, Arxiv, DOI [arXiv:1812.02230, DOI 10.48550/ARXIV.1812.02230]; Horvitz E, 2015, SCIENCE, V349, P253, DOI 10.1126/science.aac4520; Huang S., 2017, ICLR WORKSHOP; Hussein A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054912; Icarte RT, 2019, ADV NEUR IN, V32; Icarte RT, 2018, PR MACH LEARN RES, V80; Icarte RT, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P452; Illanes L., 2020, ICAPS; Iyer R, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P144, DOI 10.1145/3278721.3278776; Jain S, C N AM CHAPTER ASS F, V1, P3543; Janisch J, 2023, Arxiv, DOI arXiv:2009.12462; Jia RX, 2019, ENRGY PROCED, V158, P6158, DOI 10.1016/j.egypro.2019.01.494; Jiang Y., 2018, ICAPS; Jiang ZY, 2019, PR MACH LEARN RES, V97; Jin M, 2022, AAAI CONF ARTIF INTE, P7042; Juozapaitis Z, 2019, IJCAIECAI WORKSHOP E; Kaiser M., 2019, ESANN; Kansky K, 2017, PR MACH LEARN RES, V70; Kasenberg D, 2017, IEEE DECIS CONTR P, DOI 10.1109/CDC.2017.8264386; Kenny E. M., 2023, ICLR; Kim J, 2020, IEEE COMPUT SOC CONF, P1310, DOI 10.1109/CVPRW50498.2020.00169; Koller D, 1999, LECT NOTES ARTIF INT, V1634, P3; Konidaris G, 2018, J ARTIF INTELL RES, V61, P215, DOI 10.1613/jair.5575; Konidaris G, 2014, AAAI CONF ARTIF INTE, P1932; Konidaris G, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3619; Koul A., 2019, ICLR; Kulick J., 2013, IJCAI; Kunapuli G, 2013, IEEE DATA MINING, P409, DOI 10.1109/ICDM.2013.79; Kwon M., 2023, ICLR; Lao N, 2010, MACH LEARN, V81, P53, DOI 10.1007/s10994-010-5205-8; Le HM, 2019, Advances in Neural Information Processing Systems, V32; Leonetti M, 2016, ARTIF INTELL, V241, P103, DOI 10.1016/j.artint.2016.07.004; Leslie D., 2020, SSRN Electronic Journal; Levine S, 2018, Arxiv, DOI [arXiv:1805.00909, DOI 10.48550/ARXIV.1805.00909]; Li X, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay6276; Li X, 2017, IEEE INT C INT ROBOT, P3834, DOI 10.1109/IROS.2017.8206234; Li Y., 2017, GLOBAL C; Li Yanghao, 2017, INT C LEARN REPR WOR; Likmeta A, 2020, ROBOT AUTON SYST, V131, DOI 10.1016/j.robot.2020.103568; Lim B. Y., 2019, IUI WORKSHOPS; Littman M.L., 2017, arXiv; Liu GL, 2019, LECT NOTES ARTIF INT, V11052, P414, DOI 10.1007/978-3-030-10928-8_25; Liu Y., 2023, MetaRadiology, V1; Lo Piano S, 2020, HUM SOC SCI COMMUN, V7, DOI 10.1057/s41599-020-0501-9; Lu KT, 2018, Arxiv, DOI arXiv:1809.11074; Lundberg SM, 2017, ADV NEUR IN, V30; Lyu DM, 2019, AAAI CONF ARTIF INTE, P2970; Ma Z., 2020, arXiv; Maclin R, 1996, MACH LEARN, V22, P251, DOI 10.1007/BF00114730; Madumal P, 2020, Arxiv, DOI arXiv:2001.10284; Madumal P, 2020, AAAI CONF ARTIF INTE, V34, P2493; Maes F., 2012, Recent advances in reinforcement learning; Maes Francis, 2012, Discovery Science; Maes P., 1996, INT C SIMULATION ADA; Mania H, 2018, ADV NEUR IN, V31; Marom O, 2018, 32 C NEURAL INFORM P; Martínez D, 2016, P I C AUTOMAT PLAN S, P235; Martínez D, 2017, J MACH LEARN RES, V18; Martínez D, 2017, ARTIF INTELL, V247, P295, DOI 10.1016/j.artint.2015.02.006; Metzen J. H., 2013, ECML; Michels J., 2005, ICML; Miller T, 2019, ARTIF INTELL, V267, P1, DOI 10.1016/j.artint.2018.07.007; Minervini P, 2017, CONFERENCE ON UNCERTAINTY IN ARTIFICIAL INTELLIGENCE (UAI2017); Mittelstadt B, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P279, DOI 10.1145/3287560.3287574; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Mohseni S, 2020, Arxiv, DOI [arXiv:1811.11839, 10.1145/3387166, DOI 10.1145/3387166]; Molnar C., 2019, INTERPRETABLE MACHIN, DOI DOI 10.1007/S10290-014-0202-9; Morley J, 2020, SCI ENG ETHICS, V26, P2141, DOI 10.1007/s11948-019-00165-5; Mott A., 2019, NEURIPS; Munzer T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3735; Nageshrao S., 2019, ICMLA; Natarajan S., 2011, IJCAI; Ng A. Y., 2000, P 17 INT C MACH LEAR, P663; Ninareh Mehrabi, 2022, A Survey on Bias and Fairness in Machine Learning, DOI 10.48550/arXiv.1908.09635; Osa T., 2018, An algorithmic perspective on imitation learning., V7, P1, DOI 10.1561/2300000053; Pace A., 2022, ICLR; Páez A, 2019, MIND MACH, V29, P441, DOI 10.1007/s11023-019-09502-w; Paischer F., 2023, NeurIPS; Pasula HM, 2007, J ARTIF INTELL RES, V29, P309, DOI 10.1613/jair.2113; Payani A, 2019, Arxiv, DOI arXiv:1906.03523; Payani A, 2020, Arxiv, DOI arXiv:2003.10386; Payani A, 2019, Arxiv, DOI arXiv:1904.01554; Penkov S., 2019, ICLR; Plumb G, 2020, Arxiv, DOI arXiv:1902.06787; Pomerleau D., 1989, INNEURIPS; Puiutta E., 2020, LNCS; Puterman M.L., 2014, Markov Decision Processes: Discrete Stochastic Dynamic Programming; Qiu W., 2022, ICLR; Rafailov R., 2023, NEURIPS; Ramesh A, 2021, Arxiv, DOI [arXiv:2102.12092, 10.48550/arXiv.2102.12092]; Randlov J., 1998, Learning to drive a bicycle using reinforcement learning and shaping; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Ribeiro MT, 2016, ARXIV; Rocktaschel T., 2015, Human language technologies; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Ross S., 2011, AISTATS; Roth Aaron M., 2019, arXiv; Rothkopf CA, 2011, LECT NOTES ARTIF INT, V6913, P34, DOI 10.1007/978-3-642-23808-6_3; Rudin C., 2019, INFORMS Tutorials in Information Research, P44, DOI DOI 10.1287/EDUC.2019.0200; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Russell S., 1998, COLT; Sanchez-Gonzalez A, 2018, PR MACH LEARN RES, V80; Sanner S., 2005, ICML WORKSHOP RICH R; Sanner S., 2011, International planning competition; Santoro A, 2017, ADV NEUR IN, V30; Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605; Scholz J, 2014, PR MACH LEARN RES, V32, P1089; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Sequeira P, 2020, ARTIF INTELL-AMST, V288, DOI 10.1016/j.artint.2020.103367; Serafini L., 2016, CEUR WORKSHOP; Shi WJ, 2021, Arxiv, DOI arXiv:2003.07069; Shu T., 2018, ICLR; Silva A., 2020, AISTATS; Silva A, 2020, Arxiv, DOI arXiv:1902.06007; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Singh C, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-43713-1; Slaney J, 2001, ARTIF INTELL, V125, P119, DOI 10.1016/S0004-3702(00)00079-5; Sridharan M, 2019, J ARTIF INTELL RES, V65, P87, DOI 10.1613/jair.1.11524; Srinivasan S., 2020, AMIA JOINT SUMMITS T; Sun S. H., 2020, ICLR; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; Swain M., 2013, Encyclopedia of Systems Biology, P1082; Tang Y., 2020, GECCO; Tasse G. N., 2022, ICLRLOGICAL COMPOSIT; Tasse GN, 2020, ADV NEUR IN, V33; Todorov E., 2009, NEURIPS; Topin N, 2021, AAAI CONF ARTIF INTE, V35, P9923; Topin N, 2019, AAAI CONF ARTIF INTE, P2514; Torrey L., 2013, AAMAS; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; van Otterlo M., 2005, CTIT Technical Report Series: Tech. rep; van Otterlo M, 2012, ADAPT LEARN OPTIM, V12, P253; van Otterlo Martijn., 2009, The Logic of Adaptive Behavior -; Vasic M, 2022, Arxiv, DOI arXiv:1906.06717; Vaswani A, 2017, ADV NEUR IN, V30; Veerapaneni R., 2020, CORL; Verma A, 2018, PR MACH LEARN RES, V80; Vinyals O, 2017, Arxiv, DOI arXiv:1708.04782; Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z; Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb; Battaglia PW, 2018, Arxiv, DOI [arXiv:1806.01261, DOI 10.48550/ARXIV.1806.01261, 10.48550/arXiv.1806.01261]; Walker T., 2004, ICML WORKSHOP RELATI; Walker T, 2008, LECT NOTES ARTIF INT, V4894, P280; Walsh J., 2010, PhD thesis; Wang T, 2018, IEEE IMTC P, P1900, DOI 10.1109/CACS.2018.8606730; Wang WY, 2020, AAAI CONF ARTIF INTE, V34, P9225; Wang Y., 2020, SPRING S COMBINING M; Weng P., 2013, ECML WORKSHOP RL GEN; Whittlestone J, 2021, J ARTIF INTELL RES, V70, P1003; Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11; Wiener N., 1954, The Human Use of Human Beings: Cybernetics and Society; Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962; Wu BH, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P34; Wu MK, 2019, Arxiv, DOI arXiv:1908.05254; Wu Z., 2023, NEURIPS; Xu JY, 2018, PR MACH LEARN RES, V80; Xu Z., 2020, ICAPS; Yang F, 2017, 31 ANN C NEURAL INFO, V30; Yang FK, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4860; Yang Y., 2019, ICLR; Yang Y., 2018, ICML WORKSHOP HUMAN; Younes L., 2004, PPDDL1.0: The language for the probabilistic part of IPC-4; Yu H, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5527; Zahavy T, 2016, PR MACH LEARN RES, V48; Zambaldi Vinicius, 2019, P ICLR; Zhang A., 2018, PR MACH LEARN RES; Zhang CY, 2018, Arxiv, DOI arXiv:1804.06893; Zhang HD, 2019, Arxiv, DOI arXiv:1910.09986; Zhang SQ, 2022, Arxiv, DOI arXiv:2008.08548; Zhang YC, 2016, PR MACH LEARN RES, V48; Zhu GX, 2018, ADV NEUR IN, V31; Zhu GX, 2020, AAAI CONF ARTIF INTE, V34, P6989; Zhu H, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P686, DOI 10.1145/3314221.3314638; Zimmer M., 2014, AAMAS WORKSHOP AUTON; Zimmer M, 2021, Arxiv, DOI arXiv:2102.11529	285	0	0	10	10	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0885-6125	1573-0565		MACH LEARN	Mach. Learn.	2024 APR 19	2024										10.1007/s10994-024-06543-w	http://dx.doi.org/10.1007/s10994-024-06543-w		APR 2024	44	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OC8J5		Green Submitted			2024-07-03	WOS:001205148600001
J	Sapkota, B; Bondurant, L				Sapkota, Bima; Bondurant, Liza			Assessing Concepts, Procedures, and Cognitive Demand of ChatGPT-generated Mathematical Tasks	INTERNATIONAL JOURNAL OF TECHNOLOGY IN EDUCATION			English	Article						Fraction multiplication; Area model; Mathematical tasks; ChatGPT	INSTRUCTIONAL TASKS	In November 2022, ChatGPT, an Artificial Intelligence (AI) large language model (LLM) capable of generating human-like responses, was launched. ChatGPT has a variety of promising applications in education, such as using it as thought-partner in generating curricular resources. However, scholars also recognize that the use of ChatGPT raises concerns, such as outputs that are inaccurate, nonsensical, or vague. We, two mathematics teacher educators, engaged in a collaborative self-study using qualitative descriptive approaches to investigate the procedures, concepts, and cognitive demand of ChatGPT-generated mathematical tasks focused on fraction multiplication using the area model approach. We found that the ChatGPT-generated tasks were mostly procedural and not cognitively demanding. Moreover, despite ten variations of input prompts, ChatGPT did not produce any tasks that used the area model approach for fraction multiplication. Rather, it generated tasks focused on procedural approaches. Alarmingly, some tasks were conceptually and/or procedurally inaccurate and vague. We suggest that educators cannot fully rely on ChatGPT to generate cognitively demanding fraction multiplication tasks using the area model. We offer recommendations for educators' strategic use of ChatGPT to generate cognitively demanding mathematical tasks.	[Sapkota, Bima] Univ Texas Rio Grande Valley, Edinburg, TX 78539 USA; [Bondurant, Liza] Mississippi State Univ, Mississippi State, MS USA	University of Texas System; University of Texas Rio Grande Valley; Mississippi State University	Sapkota, B (corresponding author), Univ Texas Rio Grande Valley, Edinburg, TX 78539 USA.	bima.sapkota@utrgv.edu		Bondurant, Liza/0000-0001-8069-2382; Sapkota, Bima/0000-0003-4992-2666				[Anonymous], 2010, Common core state standards, DOI DOI 10.3102/0002831213481240; [Anonymous], 2018, The Opportunity Myth: What Students Can Show Us About How School Is Letting Them Down-and How to Fix It; Beckmann S., 2022, Mathematics for elementary and middle school teachers, activities manual, V6th; Boaler J., 2016, Mathematical Mindsets: Unleashing Students' Potential through Creative Math, Inspiring Messages and Innovative Teaching; Boston MD, 2009, J RES MATH EDUC, V40, P119; Butler B. M., 2022, Learning through Collaboration in Self -Study; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Cope L., 2015, Delta Journal of Education, V5, P10; Doherty K., 2022, Exploring dissonance and harmony in elementary mathematics teachers' curricular use, autonomy, decision-making, and coherence, P237; EdReports, 2023, The state of the market; Education Week, 2023, More Teachers are embracing ChatGPT, Students not so much; Elliott R., 2005, HDB RES METHODS CLIN, V1, P147, DOI DOI 10.1093/MED:PSYCH/9780198527565.001.0001; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Finlay L, 2011, PHENOMENOLOGY FOR THERAPISTS: RESEARCHING THE LIVED WORLD, P139; Gattupalli S., 2023, Comparing teacher-written and AI-generated math problem solving strategies for elementary school students: Implications for classroom learning, DOI [10.7275/8sgx-xj08, DOI 10.7275/8SGX-XJ08]; Grassini S, 2023, EDUC SCI, V13, DOI 10.3390/educsci13070692; HIEBERT J, 1993, AM EDUC RES J, V30, P393, DOI 10.3102/00028312030002393; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Johnson K. R., 2023, Mathematics Teacher Educator, V11, P145, DOI [10.5951/MTE.2023.0007, DOI 10.5951/MTE.2023.0007]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kosnik C., 2009, Self-study research methodologies for teacher educators, P225; Leinwand S., 1991, Mathematics assessment: Myths, models, good questions, and practical suggestions, P16; Li ZK, 2019, Arxiv, DOI arXiv:1907.08854; Liljedahl P., 2020, Building thinking classrooms in mathematics, grades K-12: 14 teaching practices for enhancing learning; Maringe F, 2013, COMPARE, V43, P9, DOI 10.1080/03057925.2013.746548; Milner H. R., 2007, ED RES, V36, P388, DOI [https://doi.org/10.3102/0013189X07309471, DOI 10.3102/0013189X07309471, 10.3102/0013189X07309471]; Onal S., 2023, Journal of Educational Technology Systems, P1, DOI [10.1177/00472395231196532, DOI 10.1177/00472395231196532]; OpenAI, 2023, CHATGPT; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Salda├a┬▒a J., 2016, CODING MANUAL QUALIT, DOI DOI 10.1017/CBO9781107415324.004; Sapkota B., 2022, MATH ED, V30, P3; Sapkota B., 2024, Encouraging transnational learning throughtelecollaboration in global teacher education; Shakarian P., 2023, P AAAI 2023 SPRING S; Stein M.K., 2000, Implementing standards-based mathematics instruction: A casebook for professional development; Van De Walle J. A., 2023, Elementary and middle school mathematics: Teaching developmentally, V11th ed.; Wardat Y., 2023, Eurasia Journal of Mathematics, Science and Technology Education, V19, DOI DOI 10.29333/EJMSTE/13272; Wilhelm AG, 2014, J RES MATH EDUC, V45, P636; Yogeeswaran K, 2017, CAMBRIDGE HANDBOOK OF THE PSYCHOLOGY OF PREJUDICE, P241; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712	39	0	0	7	7	INT SOC TECHNOLOGY EDUCATION & SCIENCE-ISTES	MONUMENT	19723 LINDENMERE DR, MONUMENT, COLORADO, UNITED STATES		2689-2758		INT J TECHNOL EDUC	Int. J. Technol. Educ.		2024	7	2			SI		218	238		10.46328/ijte.677	http://dx.doi.org/10.46328/ijte.677			21	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	OS4O8		gold			2024-07-03	WOS:001209255000003
J	Lee, TK				Lee, Tong King			Artificial intelligence and posthumanist translation: ChatGPT versus the translator	APPLIED LINGUISTICS REVIEW			English	Article; Early Access						artificial intelligence; ChatGPT; distributed cognition; posthumanism; translation		Although automated translation has been available for decades in myriad forms, the implication of the current exponential advancement in artificial intelligence (AI) for communication in general and translation in particular is more starkly affrontational than ever. Although Large Language Models, of which ChatGPT is exemplary, were not specifically designed for translation purposes, they are attested to have attained a sufficient degree of technical sophistication as to generate translations that match or surpass dedicated translation systems in the market like Google Translate and DeepL. This impacts the modus operandi of communication and the self-concept of language professionals including, of course, translators. This article asks how translation as a field of practice can best respond to this development. It critically reflects on the implications of AI for the conception of translation, arguing that an alternative framing around the idea of distribution allows us to rescale translation toward broader competencies and conceive of AI as a prosthesis of translators' minds. The article advocates a posthumanist perspective on translation with a view to expanding its spectrum of skills, modes, and media as well as transcending the traditional personae of translators.	[Lee, Tong King] Univ Hong Kong, Sch English, Hong Kong, Peoples R China	University of Hong Kong	Lee, TK (corresponding author), Univ Hong Kong, Sch English, Hong Kong, Peoples R China.	leetk@hku.hk	/F-9789-2012	/0000-0002-8885-6887				Baker M., 2018, In Other Words: A Coursebook on Translation, V3rd ed., DOI DOI 10.4324/9781315619187; Baynham Mike, 2017, WORKING PAPERS TRANS; Bennett Jane., 2010, VIBRANT MATTER POLIT; Blackledge Adrian, 2018, WORKING PAPERS TRANS; Brogger MN, 2017, META, V62, P396; Cowley Stephen J., 2012, DISTRIBUTED LANGUAGE; Cronin Michael., 2013, Translation in the Digital Age: New perspectives in Translation Studies; Drugan Joanna., 2013, Quality in Professional Translation: Assessment and improvement; Gally Tom, 2023, TRANSLATING CHATGPT; Gally Tom, 2023, IMPLICATIONS TRANSLA; Gally Tom, 2023, CAN CHATGPT TRANSLAT; Gigerenzer G., 2022, How to stay smart in a smart world: why human intelligence still beats algorithms; Gigerenzer Gerd, 2023, WIRED; Grayling A.C., 2013, The God Argument: The Case against Religion and for Humanism; Halliday M. A. K., 1976, COHESION ENGLISH, DOI 10.1677/ERC-09-0254; Hasegawa Yoko., 2014, Japanese: A Linguistic Introduction; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Howard Jeremy, 2023, GPT 4 UNCHARTERED TE; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jimenez-Crespo M.A., 2013, TRANSLATION WEB LOCA; Jimenez-Crespo M.A., 2017, Crowdsourcing and Online Collaborative Translation. Expanding the limits of Translation Studies, DOI DOI 10.1075/BTL.131; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Kenny D., 2022, MACH TRANSL, V18, P23, DOI DOI 10.5281/ZENODO.6653406; Kenny Dorothy., 2019, The Routledge Handbook of Translation andPhilosophy, P428; Lee TK, 2023, APPL LINGUIST REV, V14, P369, DOI 10.1515/applirev-2020-0139; National Accreditation Authority for Translators and Interpreters (NAATI), 2015, OTI TRANSL CERT KNOW; Nayar PramodK., 2014, POSTHUMANISM; Nord C, 2018, TRANS THEOR EXPLORE; O'Brien S., 2014, Postediting of Machine Translation: Processes and Applications; O'Hagan Minako., 2013, The Routledge Handbook of Translation Studies, P503; oBRiEN Sharon, 2022, Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence, P105, DOI [10.5281/zenodo.6759982, DOI 10.5281/ZENODO.6759982]; Pennycook A, 2018, APPL LINGUIST, V39, P445, DOI 10.1093/applin/amw016; Pym A, 2023, Exploring translation theories, V3rd; Pym A., 2016, Translation Solutions for Many Languages: History of a Flawed Dream; Pym Anthony, 2023, 60 ANN FAC TRANSL IN; Risku H, 2013, TARGET-NETH, V25, P33, DOI 10.1075/target.25.1.04ris; Thibault PJ, 2011, ECOL PSYCHOL, V23, P210, DOI 10.1080/10407413.2011.591274; Vilar D, 2022, Arxiv, DOI arXiv:2211.09102; Wakayabashi Judy, 2021, JAPANESE ENGLISH TRA; Zhang B, 2023, Arxiv, DOI [arXiv:2301.07069, 10.48550/arXiv.2301.07069]	40	5	5	104	253	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	1868-6303	1868-6311		APPL LINGUIST REV	Appl. Linguist. Rev.	2023 AUG 1	2023										10.1515/applirev-2023-0122	http://dx.doi.org/10.1515/applirev-2023-0122		AUG 2023	22	Linguistics; Language & Linguistics	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Linguistics	O0OJ6					2024-07-03	WOS:001040898100001
C	Imani, A; Lin, PQ; Kargaran, AH; Severini, S; Sabet, MJ; Kassner, N; Ma, CL; Schmid, H; Martins, AFT; Yvon, F; Schütze, H		Rogers, A; Boyd-Graber, J; Okazaki, N		Imani, Ayyoob; Lin, Peiqin; Kargaran, Amir Hossein; Severini, Silvia; Sabet, Masoud Jalili; Kassner, Nora; Ma, Chunlan; Schmid, Helmut; Martins, Andre F. T.; Yvon, Francois; Schuetze, Hinrich			Scaling Multilingual Corpora and Language Models to 500 Languages	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				The NLP community has mainly focused on scaling Large Language Models (LLMs) vertically, i.e., making them better for about 100 languages. We instead scale LLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM that covers 511 predominantly low-resource languages. An important part of this effort is to collect and clean Glot500-c, a corpus that covers these 511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five diverse tasks across these languages. We observe large improvements for both high-resource and low-resource languages compared to an XLM-R baseline. Our analysis shows that no single factor explains the quality of multilingual LLM representations. Rather, a combination of factors determines quality including corpus size, script, "help" from related languages and the total capacity of the model. Our work addresses an important goal of NLP research: we should not limit NLP to a small fraction of the world's languages and instead strive to support as many languages as possible to bring the benefits of NLP technology to all languages and cultures. Code, data and models are available at https://github.com/cisnlp/Glot500.	[Imani, Ayyoob; Lin, Peiqin; Kargaran, Amir Hossein; Severini, Silvia; Sabet, Masoud Jalili; Kassner, Nora; Ma, Chunlan; Schmid, Helmut; Schuetze, Hinrich] Ludwig Maximilians Univ Munchen, CIS, Munich, Germany; [Imani, Ayyoob; Lin, Peiqin; Kargaran, Amir Hossein; Kassner, Nora; Ma, Chunlan; Schuetze, Hinrich] Munich Ctr Machine Learning MCML, Munich, Germany; [Martins, Andre F. T.] Inst Super Tecn Lisbon ELLIS Unit, Lisbon, Portugal; [Martins, Andre F. T.] Inst Telecomunicacoes, Lisbon, Portugal; [Martins, Andre F. T.] Unbabel, Lisbon, Portugal; [Yvon, Francois] Sorbonne Univ, CNRS, ISIR, Paris, France	University of Munich; Instituto de Telecomunicacoes; Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)	Imani, A (corresponding author), Ludwig Maximilians Univ Munchen, CIS, Munich, Germany.; Imani, A (corresponding author), Munich Ctr Machine Learning MCML, Munich, Germany.	ayyoob@cis.lmu.de; linpq@cis.lmu.de; amir@cis.lmu.de; silvia@cis.lmu.de			European Research Council [740516, 758969]; EU's Horizon Europe Research and Innovation Actions (UTTER) [101070631]	European Research Council(European Research Council (ERC)); EU's Horizon Europe Research and Innovation Actions (UTTER)	We would like to thank Renhao Pei, Yihong Liu, Verena Blaschke, and the anonymous reviewers. This work was funded by the European Research Council (grants #740516 and #758969) and EU's Horizon Europe Research and Innovation Actions (UTTER, contract 101070631).	Abate Solomon Teferra, 2018, P 27 INT C COMP LING, P3102; Abdelmoniem AM, 2021, PROCEEDINGS OF THE 1ST WORKSHOP ON MACHINE LEARNING AND SYSTEMS (EUROMLSYS'21), P96, DOI 10.1145/3437984.3458839; Abu Kwaik K, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3645; Adebara Ife, 2022, ARXIV221210785; Adelani D, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3053; Adelani David, 2021, P MACH TRANSL SUMM 1, V1, P61; Agerri R, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2322; Alabi Jesujoba O., 2022, P 29 INT C COMP LING, P4336; Alsarsour I, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3666; Anastasopoulos Antonios, 2020, P 1 WORKSH NLP COVID; Ansell A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1778; Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288; Bafna Niyati, 2022, EMPIRICAL MODELS IND; Banon M., 2022, P 23 ANN C EUR ASS M, P301; Bañón M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4555; Bapna Ankur, 2022, ARXIV220503983; Camacho-Collados J, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1701; Chi ZW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6170; Chi ZW, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3576; Choenni R, 2022, COMPUT LINGUIST, V48, P635, DOI 10.1162/coli_a_00444; Chowdhery A., 2022, ARXIV220402311; Chung HW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4536; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Costa-jussa Marta R, 2022, ARXIV220704672; de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI [10.1162/coli_a_00402, 10.1162/COLI_a_00402]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dufter P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4423; Dufter P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1520; Dunn J, 2020, LANG RESOUR EVAL, V54, P999, DOI 10.1007/s10579-020-09489-2; Eberhard D. M., 2022, Ethnologue: Languages of the world, V25th ed.; Ebrahimi A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4555; El-Haj M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1318; El-Haj M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3622; Fan A, 2021, J MACH LEARN RES, V22; Gamallo Pablo, 2017, P 4 WORKSH NLP SIM L, P109, DOI DOI 10.18653/V1/W17-1213; Goldhahn D, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P759; Gongora S, 2022, PROCEEDINGS OF THE FIFTH WORKSHOP ON THE USE OF COMPUTATIONAL METHODS IN THE STUDY OF ENDANGERED LANGUAGES (COMPUTEL-5 2022), P127; Gongora Santiago, 2021, P 1 WORKSH NAT LANG, P153; Gowda T, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P306; Hasan T, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4693; Heafield K., 2011, P 6 WORKSHOP STAT MA, P187; Hu JJ, 2020, PR MACH LEARN RES, V119; ImaniGooghari A., 2022, P 2022 C EMP METH NA, P1577; Joshi Pratik, 2020, P 58 ANN M ASS COMPU, P6282, DOI [10.18653/v1/2020. acl-main.560, DOI 10.18653/V1/2020.ACL-MAIN.560]; Kakwani D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4948; Koto F., 2020, P PAC AS C LANG INF, P138; Kreutzer J, 2022, T ASSOC COMPUT LING, V10, P50, DOI 10.1162/tacl_a_00447; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Kunchukuttan A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3473; Laurencon Hugo, 2022, 36 C NEUR INF PROC S; Lauscher A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4483; Le Scao Teven, 2022, Bloom: A 176b-parameter open-access multilingual language model; Leong Colin, 2022, P 2022 C EMPIRICAL M, P8608; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Ma Chunlan, 2023, TAXI1500 MULTILINGUA; Majlis Martin, 2011, W2C WEB CORPUS CORPO; Mirzakhalov J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5876; Moran S, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1150; Morishita M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P3603; Nakazawa T, 2021, WAT 2021: THE 8TH WORKSHOP ON ASIAN TRANSLATION, P1; Nakazawa Toshiaki, 2022, P 22 ACM INT C INTEL, P1; Neubig Graham, 2011, The Kyoto free translation task; Ogueji Kelechi, 2021, WORKSHOP MULTILINGUA, P116, DOI [10.18653/v1/2021.mrl-1.11, DOI 10.18653/V1/2021.MRL-1.11]; Palen-Michel C, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2080; Pan XM, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1946, DOI 10.18653/v1/P17-1178; Pfeiffer J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3479; Pfeiffer J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10186; Raffel C, 2020, J MACH LEARN RES, V21; Rozis Roberts, 2017, P 21 NORDIC C COMPUT, P263; Sabet MJ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1627; Sajjad Hassan, 2020, P 28 INT C COMPUTATI, P5094; Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699; Schwenk H, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1351; Severini Silvia, 2022, ARXIV220112219; Siddhant Aditya, 2022, ARXIV220103110; Singh A.K., 2008, P IJCNLP 08 WORKSH N; Suarez P.J.O., 2019, P WORKSHOP CHALLENGE, P9, DOI [10.14618/ids-pub-9021, DOI 10.14618/IDS-PUB-9021]; Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214; Turc Iulia, 2021, ABS210616171 CORR; Wang HR, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2019), P316, DOI 10.1109/BigDataService.2019.00056; Wang Mingyang, 2023, ABS230500090 CORR; Wang XY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P863; Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yang J, 2020, AAAI CONF ARTIF INTE, V34, P9386; Zevallos Rodolfo, 2022, P 3 WORKSH DEEP LEAR, P1; Zhao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2226	87	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							1082	1117						36	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086807055
C	Sivakumar, JA; Moosavi, NS		Rogers, A; Boyd-Graber, J; Okazaki, N		Sivakumar, Jasivan Alex; Moosavi, Nafise Sadat			FERMAT: An Alternative to Accuracy for Numerical Reasoning	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				While pre-trained language models achieve impressive performance on various NLP benchmarks, they still struggle with tasks that require numerical reasoning. Recent advances in improving numerical reasoning are mostly achieved using very large language models that contain billions of parameters and are not accessible to everyone. In addition, numerical reasoning is measured using a single score on existing datasets. As a result, we do not have a clear understanding of the strengths and shortcomings of existing models on different numerical reasoning aspects and therefore, potential ways to improve them apart from scaling them up. Inspired by CheckList (Ribeiro et al., 2020), we introduce a multi-view evaluation set for numerical reasoning in English, called FERMAT. Instead of reporting a single score on a whole dataset, FERMAT evaluates models on various key numerical reasoning aspects such as number understanding, mathematical operations, and training dependency. Apart from providing a comprehensive evaluation of models on different numerical reasoning aspects, FERMAT enables a systematic and automated generation of an arbitrarily large training or evaluation set for each aspect.The datasets and codes are publicly available to generate further multi-view data for ulterior tasks and languages.(1)	[Sivakumar, Jasivan Alex; Moosavi, Nafise Sadat] Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England	University of Sheffield	Sivakumar, JA (corresponding author), Univ Sheffield, Dept Comp Sci, Sheffield, S Yorkshire, England.	jasivakumar1@sheffield.ac.uk; n.s.moosavi@sheffield.ac.uk			Centre for Doctoral Training in Speech and Language Technologies (SLT) - UK Research and Innovation [EP/S023062/1]	Centre for Doctoral Training in Speech and Language Technologies (SLT) - UK Research and Innovation	This work was supported by the Centre for Doctoral Training in Speech and Language Technologies (SLT) and their Applications funded by UK Research and Innovation [grant number EP/S023062/1]. Additional thanks to our mathematics teachers Ana Maria Ocampo Lucumi and Liz Scott for creating and checking the expert templates. A further acknowledgement to Constantinos Karouzos, Mugdha Pandya and Valeria Pastorino for their continued feedback in this research.	Andor D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5947; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, ARXIV220402311; Cobbe K., 2021, ARXIV211014168; Dasigi P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5925; Demszky D., 2018, ARXIV180902922; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Geva M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P946; Gupta V, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2309; Huang DQ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P887; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Kojima Takeshi, 2022, ICML 2022 WORKSH KNO; Koncel-Kedziorski R., 2016, NAACL HLT 2016 2016, P1152, DOI [10.18653/v1/N16, 10.18653/v1/N16-1136, DOI 10.18653/VLIN16-1136]; Kumar V, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2705; Kumar V, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4194; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewkowycz A., 2022, Advances in Neural Information Processing Systems; Liang Z, 2022, FINDINGS ASS COMPUTA, P997, DOI DOI 10.18653/V1/2022.FINDINGS-NAACL.74; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Ling W, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P158, DOI 10.18653/v1/P17-1015; Mandal S., 2022, INT J INTELL SYST AP, V10, P87, DOI [10.18201/ijisae.2022.271, DOI 10.18201/IJISAE.2022.271]; Mishra S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3505; Mishra Swaroop, 2022, P 2022 C EMP METH NA, P5807; Moosavi Nafise, 2021, P NEUR INF PROC SYST, V1; Muffo M, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P291; Patel A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2080; Petrak Dominic, 2022, ARXIV220506733; Raffel C, 2020, J MACH LEARN RES, V21; Razeghi Yasaman., 2022, FINDINGS ASS COMPUTA, P840, DOI 10.18653/v1/2022.findings-emnlp.59; Ribeiro MT, 2020, P 58 ANN M ASS COMP, P4902, DOI [DOI 10.18653/V1/2020.ACL-MAIN.442, 10.18653/v1/2020.acl-main.442]; Roy S., 2015, P 2015 C EMPIRICAL M, P1743, DOI DOI 10.18653/V1/D15-1202; Roy Subhro, 2016, P 2016 C N ASS COMP, P52; Sanh Victor, 2022, INT C LEARNING REPRE; Saxton D., 2019, ICLR; Suadaa LH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1451; Tafjord Oyvind, 2019, P 33 AAAI C ART INT; Vlachos Andreas, 2015, P 2015 C EMPIRICAL M, P2596, DOI DOI 10.18653/V1/D15-1312; Wei J., 2022, INT C LEARN REPR; Wei Jason, 2022, ADV NEURAL INFORM PR; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xiong Wenhan, 2021, INT C LEARN REPR; Yang Peng-Jian, 2021, ARXIV210407307; Zhou B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3363; Zhou Hattie, 2022, ARXIV221109066	44	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15026	15043						18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962506043
J	Wal, OV; Bachmann, D; Leidinger, A; van Maanen, L; Zuidema, W; Schulz, K				Wal, Oskar van der; Bachmann, Dominik; Leidinger, Alina; van Maanen, Leendert; Zuidema, Willem; Schulz, Katrin			Undesirable Biases in NLP: Addressing Challenges of Measurement	JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH			English	Article							AGREEMENT; FAIRNESS	As Large Language Models and Natural Language Processing (NLP) technology rapidly develop and spread into daily life, it becomes crucial to anticipate how their use could harm people. One problem that has received a lot of attention in recent years is that this technology has displayed harmful biases, from generating derogatory stereotypes to producing disparate outcomes for different social groups. Although a lot of effort has been invested in assessing and mitigating these biases, our methods of measuring the biases of NLP models have serious problems and it is often unclear what they actually measure. In this paper, we provide an interdisciplinary approach to discussing the issue of NLP model bias by adopting the lens of psychometrics - a field specialized in the measurement of concepts like bias that are not directly observable. In particular, we will explore two central notions from psychometrics, the construct validity and the reliability of measurement tools, and discuss how they can be applied in the context of measuring model bias. Our goal is to provide NLP practitioners with methodological tools for designing better bias measures, and to inspire them more generally to explore tools from psychometrics when working on bias measurement tools.	[Wal, Oskar van der; Bachmann, Dominik; Leidinger, Alina; Zuidema, Willem; Schulz, Katrin] Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands; [Bachmann, Dominik; van Maanen, Leendert] Univ Utrecht, Dept Expt Psychol, Utrecht, Netherlands	University of Amsterdam; Utrecht University	Wal, OV (corresponding author), Univ Amsterdam, Inst Log Language & Computat, Amsterdam, Netherlands.	O.D.VANDERWAL@UVA.NL; D.BACHMANN@UVA.NL; A.J.LEIDINGER@UVA.NL; L.VANMAANEN@UU.NL; W.H.ZUIDEMA@UVA.NL; K.SCHULZ@UVA.NL	Van Maanen, Leendert/Z-5637-2019	Van Maanen, Leendert/0000-0001-9120-1075	Dutch Research Council (NWO) [406.DI.19.059]	Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO))	The two first authors, Oskar van der Wal and Dominik Bachmann, contributed equally to the paper. We thank our four anonymous reviewers for their thoughtful and elaborate feedback. This publication is part of the project "The biased reality of online media-Using stereotypes to make media manipulation visible" (with project number 406.DI.19.059) of the research programme Open Competition Digitalisation-SSH, which is financed by the Dutch Research Council (NWO) .	Abbasi A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3748; Akyurek A. F, 2022, P 4 WORKSHOP GENDER, P76; Akyurek A. F., 2022, FINDINGS ASS COMPUTA, P551; Amidei J., 2020, P 28 INT C COMPUTATI, P4787, DOI DOI 10.18653/V1/2020.COLING-MAIN.421; [Anonymous], 2008, COLING 2008 P WORKSH, DOI [10.3115/1611628.1611637, DOI 10.3115/1611628.1611637]; Antoniak M, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1889; Aribandi V, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1778; Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Bach SH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P93; Balayn A, 2021, Tech. Rep.); Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Barocas S, 2017, 9 ANN C SPECIAL INTE; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Biderman S., 2023, INT C MACHINE LEARNI, P2397; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Bolukbasi T, 2016, ADV NEUR IN, V29; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bommasani R, 2022, Arxiv, DOI arXiv:2212.11672; Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7; Borsboom D, 2004, PSYCHOL REV, V111, P1061, DOI 10.1037/0033-295x.111.4.1061; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; CAMPBELL DT, 1959, PSYCHOL BULL, V56, P81, DOI 10.1037/h0046016; Cao YT, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P561; Chang Kai-Wei, 2018, P NAACL, V2, DOI [10.18653/v1/N18-2003, DOI 10.18653/V1/N18-2003]; Cheng L., 2021, Journal of Artificial Intelligence Research, V71, P1137; Ciora C., 2021, P 14 INT C NAT LANG, P55; CRONBACH LJ, 1955, PSYCHOL BULL, V52, P281, DOI 10.1037/h0040957; D'Amour A., 2022, J MACH LEARN RES, V23, P1; Danesi M., 2014, Dictionary of media and communications; De-Arteaga M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P120, DOI 10.1145/3287560.3287572; Dehghani M, 2021, Arxiv, DOI [arXiv:2107.07002, 10.48550/arXiv.2107.07002]; Delobelle P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1693; Dev S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1968; Dev Sunipa, 2022, Findings of the Association for Computational Linguistics: AACL-IJCNLP, P246; Dinan E, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P314; Du YP, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10012; Eagly AH, 2020, AM PSYCHOL, V75, P301, DOI 10.1037/amp0000494; Ethayarajh K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2914; Ethayarajh K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1696; Fang QX, 2022, EPJ DATA SCI, V11, DOI 10.1140/epjds/s13688-022-00353-7; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Field A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P596; Founta Antigoni, 2018, P INT AAAI C WEB SOC; Friedler SA, 2021, COMMUN ACM, V64, P136, DOI 10.1145/3433949; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Golchin S, 2024, Arxiv, DOI arXiv:2308.08493; Goldfarb-Tarrant S, 2023, Arxiv, DOI arXiv:2305.12757; Goldfarb-Tarrant S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1926; Gonen H, 2022, PROCEEDINGS OF THE 7TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P67; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464; Greenwald AG, 2009, J PERS SOC PSYCHOL, V97, P17, DOI 10.1037/a0015575; Hambleton R. K., 1985, Item response theory, DOI DOI 10.1007/978-94-017-1988-9; Harrington D., 2009, Confirmatory Factor Analysis, DOI [10.1093/acprof:oso/9780195339888.001.0001, DOI 10.1093/ACPROF:OSO/9780195339888.001.0001]; Hogenboom S. A. M., 2023, Implicit association tests: Stimuli validation from participant responses; Hooker S, 2020, Arxiv, DOI [arXiv:2010.03058, DOI 10.48550/ARXIV.2010.03058]; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jacobs AZ, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P375, DOI 10.1145/3442188.3445901; Jiao MC, 2021, GEBNLP 2021: THE 3RD WORKSHOP ON GENDER BIAS IN NATURAL LANGUAGE PROCESSING, P8; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Kiritchenko Svetlana, 2021, Journal of Artificial Intelligence Research, V71, P431; Kline P., 1994, An easy guide to factor analysis, DOI DOI 10.4324/9781315788135; Krumpal I, 2013, QUAL QUANT, V47, P2025, DOI 10.1007/s11135-011-9640-9; Lalor John P, 2016, Proc Conf Empir Methods Nat Lang Process, V2016, P648; Lam CSP, 2019, EUR HEART J, V40, P3859, DOI 10.1093/eurheartj/ehz835; Laskar MTR, 2023, Arxiv, DOI arXiv:2305.18486; Limisiewicz T., 2022, P 4 WORKSHOP GENDER, P17, DOI DOI 10.18653/V1/2022.GEBNLP-1.3; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Longpre S., 2023, P 40 INT C MACH LEAR, P22631; Malik V, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1041; Martin J. H., 2011, P INT AAAI C WEB SOC, P385; Mathet Y, 2015, COMPUT LINGUIST, V41, P437, DOI 10.1162/COLI_a_00227; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; Meade N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1878; Montuschi P, 2014, IT PROF, V16, P41, DOI 10.1109/MITP.2013.62; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Névéol A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8521; Newton PE, 2013, PSYCHOL METHODS, V18, P301, DOI 10.1037/a0032969; Nissim M, 2020, COMPUT LINGUIST, V46, P487, DOI [10.1162/coli_a_00379, 10.1162/COLI_a_00379]; Nosek BA, 2015, SCIENCE, V348, P1422, DOI 10.1126/science.aab2374; Orgad Hadas, 2022, P 4 WORKSHOP GENDER, P151, DOI DOI 10.18653/V1/2022.GEBNLP; Prystawski B, 2022, COGNITIVE SCI, V46, DOI 10.1111/cogs.13146; Sanh V., 2022, ICLR 2022 10 INT C L; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Sedoc J, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P55; Seshadri P., 2022, arXiv; Stanczak K, 2021, Arxiv, DOI [arXiv:2112.14168, DOI 10.48550/ARXIV.2112.14168, 10.48550/ARXIV.2112.14168]; Stanovsky G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1679; Talat Z, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P26; Tontodimamma A., 2022, Quality & Quantity, V56; van der Wal O., 2022, P 4 WORKSHOP GENDER, P75; Vig Jesse, 2020, Advances in neural information processing systems, V33, P12388; Wagner C, 2016, EPJ DATA SCI, V5, DOI 10.1140/epjds/s13688-016-0066-4; Walter T, 2021, ACM-IEEE J CONF DIG, P51, DOI 10.1109/JCDL52503.2021.00017; Wang YS, 2018, J BIOMED INFORM, V77, P34, DOI 10.1016/j.jbi.2017.11.011; Warrens M. J, 2015, Quantitative Psychology Research, P293, DOI DOI 10.1007/978-3-319-07503-7_18; Way A, 2018, MACH TRANS TECH APPL, V1, P159, DOI 10.1007/978-3-319-91241-7_8; Webster Kellie, 2020, arXiv; Weinberg L, 2022, J ARTIF INTELL RES, V74, P75; Whitlock M, 2015, Atherosclerosis, V241, P219; Wong K., 2021, P 59 ANN M ASS COMPU, V1, P7053, DOI DOI 10.18653/V1/2021.ACL-LONG.548; Wong K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P378; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Zeinert P, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3181; Zhang HY, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P759; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang YY, 2022, INTERSPEECH, P3168, DOI 10.21437/Interspeech.2022-836; Zhao J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P629; Zhong H., 2020, P 58 ANN M ASS COMPU, P5218	111	0	0	3	3	AI ACCESS FOUNDATION	MARINA DEL REY	USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA	1076-9757	1943-5037		J ARTIF INTELL RES	J. Artif. Intell. Res.		2023	79						1	40						40	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FQ0A1					2024-07-03	WOS:001147182800002
C	Liang, C; He, PC; Shen, YL; Chen, WZ; Zhao, T			Assoc Computat Linguist	Liang, Chen; He, Pengcheng; Shen, Yelong; Chen, Weizhu; Zhao, Tuo			CAMERO: Consistency Regularized Ensemble of Perturbed Language Models with Weight Sharing	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple				Model ensemble is a popular approach to produce a low-variance and well-generalized model. However, it induces large memory and inference costs, which are often not affordable for real-world deployment. Existing work has resorted to sharing weights among models. However, when increasing the proportion of the shared weights, the resulting models tend to be similar, and the benefits of using model ensemble diminish. To retain ensemble benefits while maintaining a low memory cost, we propose a consistency-regularized ensemble learning approach based on perturbed models, named CAMERO. Specifically, we share the weights of bottom layers across all models and apply different perturbations to the hidden representations for different models, which can effectively promote the model diversity. Meanwhile, we apply a prediction consistency regularizer across the perturbed models to control the variance due to the model diversity. Our experiments using large language models demonstrate that CAMERO significantly improves the generalization performance of the ensemble model. Specifically, CAMERO outperforms the standard ensemble of 8 BERT-base models on the GLUE benchmark by 0.7 with a significantly smaller model size (114.2M vs. 880.6M).	[Liang, Chen; Zhao, Tuo] Georgia Inst Technol, Atlanta, GA 30332 USA; [Liang, Chen; He, Pengcheng; Shen, Yelong; Chen, Weizhu] Microsoft Azure AI, Redmond, WA USA	University System of Georgia; Georgia Institute of Technology	Liang, C (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.	cliang73@gatech.edu; penhe@microsoft.com; yelong.shen@microsoft.com; wzchen@microsoft.com; tourzhao@gatech.edu	He, Pengcheng/GYJ-6459-2022; wang, yue/KDO-9209-2024					Aghajanyan Armen, 2020, ARXIV200803156; Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874; [Anonymous], 2018, ARXIV180502282; Bentivogli Luisa, 2009, TAC WORKSH; Bojar O, 2016, P 1 C MACH TRANSL, V2, P131; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; Cettolo M., 2016, INT WORKSH SPOK LANG; Chen DF, 2020, AAAI CONF ARTIF INTE, V34, P3430; Dagan I, 2006, LECT NOTES ARTIF INT, V3944, P177; Devlin J., 2019, CoRR, P4171; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z; Feng Shaoxiong, 2020, ARXIV200907712; Gao J., 2019, ARXIV191103437; Giampiccolo Danilo, 2007, P ACL PASCAL WORKSH, P1; Gu Jiatao, 2018, ARXIV10205368; Harikrishnan R., 2006, Plant Health Progress, P1; He P, 2020, ICLR; Jiang Haoming, 2019, ARXIV191102692; Kim J, 2021, INT C PATT RECOG, P4619, DOI 10.1109/ICPR48806.2021.9412615; Kingma D. P., 2017, ARXIV; Lan X, 2018, Arxiv, DOI arXiv:1806.04606; Li Z, 2020, P AS C COMP VIS; Liu XD, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P118; Liu Y., 2019, CoRR abs/1907.11692; LUONG MT, 2015, ARXIV151106114; Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821; Ott M, 2019, Arxiv, DOI arXiv:1904.01038; Ott Myle, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, P1; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Pryzant R., 2017, P 2 C MACH TRANSL WM, P118; Qiushan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11017, DOI 10.1109/CVPR42600.2020.01103; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Rame Alexandre, 2021, ARXIV210105544; Ruder S, 2019, AAAI CONF ARTIF INTE, P4822; Sennrich Rico, 2015, ARXIV PREPRINT ARXIV; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; Wu Guile, 2021, AAAI; Yang CG, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3750, DOI 10.1109/ICASSP39728.2021.9414664; Yang Yongquan, 2021, ARXIV210108387; Zeng JL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P447; Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454	49	0	0	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-21-6				2022							7162	7175						14	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EM					2024-07-03	WOS:000828702307022
C	Zhang, XY; Chen, MH; May, J			Assoc Computat Linguist	Zhang, Xiyang; Chen, Muhao; May, Jonathan			Salience-Aware Event Chain Modeling for Narrative Understanding	2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021)			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing (EMNLP)	NOV 07-11, 2021	Punta Cana, DOMINICAN REP					Storytelling, whether via fables, news reports, documentaries, or memoirs, can be thought of as the communication of interesting and related events that, taken together, form a concrete process. It is desirable to extract the event chains that represent such processes. However, this extraction remains a challenging problem. We posit that this is due to the nature of the texts from which chains are discovered. Natural language text interleaves a narrative of concrete, salient events with background information, contextualization, opinion, and other elements that are important for a variety of necessary discourse and pragmatics acts but are not part of the principal chain of events being communicated. We introduce methods for extracting this principal chain from natural language text, by filtering away non-salient events and supportive sentences. We demonstrate the effectiveness of our methods at isolating critical event chains by comparing their effect on downstream tasks. We show that by pre-training large language models on our extracted chains, we obtain improvements in two tasks that benefit from a clear understanding of event chains: narrative prediction and event-based temporal question answering. The demonstrated improvements and ablative studies confirm that our extraction method isolates critical event chains.(1)	[Zhang, Xiyang; Chen, Muhao; May, Jonathan] Univ Southern Calif, Inst Informat Sci, Los Angeles, CA 90007 USA	University of Southern California	Zhang, XY (corresponding author), Univ Southern Calif, Inst Informat Sci, Los Angeles, CA 90007 USA.	xiyangzh@isi.edu; muhao@isi.edu; jonmay@isi.edu	Chen, Muhao/AAA-3634-2021	Chen, Muhao/0000-0003-1812-6835; May, Jonathan/0000-0002-5284-477X	DARPA's KAIROS program [FA8750-19-2-0500]	DARPA's KAIROS program	This research is based upon work supported by DARPA's KAIROS program, Contract FA8750-19-2-0500. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright annotation thereon.	Balasubramanian Niranjan, 2013, P 2013 C EMP METH NA, P1721; Berant Jonathan, 2014, P 2014 C EMPIRICAL M, P1499; Chambers Nathanael., 2008, P ACL 08 HLT, P789; Chaturvedi H., 2017, P 2017 C EMPIRICAL M, P1603, DOI DOI 10.18653/V1/D17-1168; Cheng Pengxiang, 2018, NAACL HLT; Choubey P K., 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume, V2, P340; Choubey Prafulla Kumar, 2020, P 58 ANN M ASS COMPU, P5374; CUI W, 2020, PBZN 2020 9 INT S LE, P539, DOI DOI 10.1007/978-3-030-37070-1_46; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Han RJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P434; Jindal D., 2020, P 28 INT C COMPUTATI, P114; Li M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P684; Lian DF, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P695, DOI 10.1145/3366423.3380151; Lin S.-T., 2021, P 59 ANN M ASS COMP, V1, P7142; Lin Y., 2020, P 58 ANN M ASS COMPU, P7999, DOI DOI 10.18653/V1/2020.ACL-MAIN.713; Liu Y., 2019, CoRR abs/1907.11692; Liu ZZ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1226; Lyu Qing, 2021, P 14 INT C NAT LANG; Mostafazadeh Nasrin, 2016, P 2016 C N AM CHAPTE, P839, DOI [10.18653/v1/N16-1098, DOI 10.18653/V1/N16-1098]; Ning Q, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1158; Ostermann Simon, 2019, P 8 JOINT C LEX COMP, P103; Peng Haoruo, 2019, P 23 C COMPUTATIONAL, P550; Peng N, 2018, P 1 WORKSH STOR, P43, DOI DOI 10.18653/V1/W18-1505; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Pichotta K, 2016, AAAI CONF ARTIF INTE, P2800; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radinsky K, 2013, P 6 ACM INT C WEB SE, P255; Radinsky K, 2012, P 21 INT C WORLD WID, P909, DOI [10.1145/2187836.2187958, DOI 10.1145/2187836.2187958]; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Rudinger Rachel, 2015, P 2015 C EMP METH NA, P1681; Sandhaus Evan, 2008, NEW YORK TIMES ANNOT, V6, DOI [10.35111/77ba-9x74, DOI 10.35111/77BA-9X74]; Srinivasan Siddarth., 2018, P 2018 C N AM CHAPTE, V2, P92, DOI 10.18653/v1/N18-2015; Sun K, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2633; van Dijk T. A., 1988, News As Discourse; Weber N, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3783; Weber Noah, 2018, P AAAI C ARTIFICIAL, V32; Wilson M, 2002, PSYCHON B REV, V9, P625, DOI 10.3758/BF03196322; Yao LL, 2019, AAAI CONF ARTIF INTE, P7378; Yarlott WV, 2018, P WORKSH EV STOR NEW, P25; Zhang H, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7695419; Zheng JM, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P249, DOI 10.1145/3397271.3401173; Zhou B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1361	42	0	0	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-09-4				2021							1418	1428						11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT8XM					2024-07-03	WOS:000855966301040
C	Najork, M			ACM	Najork, Marc			Generative Information Retrieval	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Generative Information Retrieval; Large Language Models; Question Answering; Tool-Augmented Generation		Historically, information retrieval systems have all followed the same paradigm: information seekers frame their needs in the form of a short query, the system selects a small set of relevant results from a corpus of available documents, rank-orders the results by decreasing relevance, possibly excerpts a responsive passage for each result, and returns a list of references and excerpts to the user. Retrieval systems typically did not attempt fusing information from multiple documents into an answer and displaying that answer directly. This was largely due to available technology: at the core of each retrieval system is an index that maps lexical tokens or semantic embeddings to document identifiers. Indices are designed for retrieving responsive documents; they do not support integrating these documents into a holistic answer. More recently, the coming-of-age of deep neural networks has dramatically improved the capabilities of large language models (LLMs). Trained on a large corpus of documents, these models not only memorize the vocabulary, morphology and syntax of human languages, but have shown to be able to memorize facts and relations [2]. Generative language models, when provided with a prompt, will extend the prompt with likely completions - an ability that can be used to extract answers to questions from the model. Two years ago, Metzler et al. argued that this ability of LLMs will allow us to rethink the search paradigm: to answer information needs directly rather that directing users to responsive primary sources [1]. Their vision was not without controversy; the following year Shaw and Bender argued that such a system is neither feasible nor desirable [3]. Nonetheless, the past year has seen the emergence of such systems, with offerings from established search engines and multiple new entrants to the industry. The keynote will summarize the short history of these generative information retrieval systems, and focus on the many open challenges in this emerging field: ensuring that answers are grounded, attributing answer passages to a primary source, providing nuanced answers to non-factoid-seeking questions, avoiding bias, and going beyond simple regurgitation of memorized facts. It will also touch on the changing nature of the content ecosystem. LLMs are starting to be used to generate web content. Should search engines treat such derived content equal to human-authored content? Is it possible to distinguish generated from original content? How should we view hybrid authorship where humans contribute ideas and LLMs shape these ideas into prose? And how will this parallel technical evolution of search engines and content ecosystems affect their respective business models?	[Najork, Marc] Google, Mountain View, CA 94043 USA	Google Incorporated	Najork, M (corresponding author), Google, Mountain View, CA 94043 USA.	najork@google.com						Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816	3	2	2	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							1	1		10.1145/3539618.3591871	http://dx.doi.org/10.1145/3539618.3591871			1	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG					2024-07-03	WOS:001118084000001
J	Karnalim, O; Toba, H; Johan, MC				Karnalim, Oscar; Toba, Hapnes; Johan, Meliana Christianti			Detecting AI assisted submissions in introductory programming via code anomaly	EDUCATION AND INFORMATION TECHNOLOGIES			English	Article; Early Access						ChatGPT; AI assistance misuse; Code anomaly; Introductory programming; Python	PLAGIARISM DETECTION; ARTIFICIAL-INTELLIGENCE; DETECTION TOOL	Artificial Intelligence (AI) can foster education but can also be misused to breach academic integrity. Large language models like ChatGPT are able to generate solutions for individual assessments that are expected to be completed independently. There are a number of automated detectors for AI assisted work. However, most of them are not dedicated to programming and/or they rely on existing student submissions (i.e., the learning approach). This paper presents a straightforward detector for AI assisted code, relying on code anomaly. No existing student submissions are needed. The detector employs 34 features covering constants, data structures, branches, loops, functions, and others. According to our evaluation on three data sets, the detector and its normalized variation are effective with 89% top-K precision. However, allowing discussion among colleagues and access to the internet might reduce the effectiveness by 25%. The effectiveness is further reduced by about the same amount when AI assistance is only used on some tasks, not the whole submissions. Although our detectors should be used with caution due to the limitations, it sufficiently shows that code anomaly can be distinctive for identifying AI assisted work. Instructors can start looking for the code anomaly among the submissions for such identification.	[Karnalim, Oscar; Toba, Hapnes; Johan, Meliana Christianti] Maranatha Christian Univ, Bandung, West Java, Indonesia	Universitas Kristen Maranatha	Karnalim, O (corresponding author), Maranatha Christian Univ, Bandung, West Java, Indonesia.	oscar.karnalim@it.maranatha.edu; hapnestoba@it.maranatha.edu; meliana.christianti@it.maranatha.edu	Toba, Hapnes/B-2485-2019; Karnalim, Oscar/F-9133-2018	Toba, Hapnes/0000-0003-0586-8880; Karnalim, Oscar/0000-0003-4930-6249	Research Institute and Community Service (LPPM) at Maranatha Christian University Indonesia	Research Institute and Community Service (LPPM) at Maranatha Christian University Indonesia	The research presented in this paper was supported by the Research Institute and Community Service (LPPM) at Maranatha Christian University Indonesia.	Allen J.M., 2018, ASEE ANN C EXPOSITIO; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; Aurelia S, 2024, MULTIMED TOOLS APPL, V83, P31805, DOI 10.1007/s11042-023-16714-x; Behera CK, 2015, PROCEDIA COMPUT SCI, V70, P757, DOI 10.1016/j.procs.2015.10.114; Bhattathiripad P. V., 2012, Proceedings of the 2012 IEEE 36th IEEE Annual Computer Software and Applications Conference Workshops (COMPSACW), P206, DOI 10.1109/COMPSACW.2012.46; Budiman AE, 2019, COMPUTERS, V8, DOI 10.3390/computers8010011; Burrows S., 2007, ADCS 2007 P 12 AUSTR, P32; Burrows S, 2009, LECT NOTES COMPUT SC, V5463, P699, DOI 10.1007/978-3-642-00887-0_61; Carlini Nicholas, 2021, USENIX SECURITY S, V6; Cheers H, 2023, INFORM EDUC, V22, P1, DOI 10.15388/infedu.2023.05; Cheers H, 2021, IEEE ACCESS, V9, P50391, DOI 10.1109/ACCESS.2021.3069367; Chen LJ, 2020, IEEE ACCESS, V8, P75264, DOI 10.1109/ACCESS.2020.2988510; Clear A, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P653, DOI 10.1145/3287324.3287517; Cosma G, 2008, IEEE T EDUC, V51, P195, DOI 10.1109/TE.2007.906776; Croft W. B., 2010, Search engines: information retrieval in practice, V520; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Daly C, 2005, COMPUT J, V48, P662, DOI 10.1093/comjnl/bxh139; Dendir S, 2020, COMPUT HUM BEHAV REP, V2, DOI 10.1016/j.chbr.2020.100033; Flores E, 2015, J UNIVERS COMPUT SCI, V21, P1708; Frankel SF, 2021, IEEE INT CONF BIG DA, P3298, DOI 10.1109/BigData52589.2021.9671332; Frantzeskou G., 2006, 28th International Conference on Software Engineering Proceedings, P893, DOI 10.1145/1134285.1134445; Fraser R, 2014, INFORM EDUC, V13, P179, DOI 10.15388/infedu.2014.01; Fu Deqiang., 2017, Scientific Programming, V2017, DOI DOI 10.1155/2017/7809047; Gehrmann S., 2019, arXiv; Halak B., 2016, 11 EUROPEAN WORKSHOP, P1; Hayes JH, 2010, SOFTW TEST VERIF REL, V20, P329, DOI 10.1002/stvr.412; Herrera G., 2019, 3 IEEE WORLD ENG ED; Hoq M., 2023, WORKSHOP EMPOWERING; Hoq M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11061076; Hosam E., 2022, Journal of Engineering and Applied Science, V69, P1; Ibrahim H, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38964-3; Jeongmin Byun, 2020, L@S '20. Proceedings of the Seventh ACM Conference on Learning @ Scale, P273, DOI 10.1145/3386527.3406726; Joy M, 1999, IEEE T EDUC, V42, P129, DOI 10.1109/13.762946; Kalgutkar V., 2018, 13 INT C AVAILABILIT, P1; Kalgutkar V, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3292577; Karnalim O., 2019, INT C ENG TECHNOLOGY, P1; Lancaster T., 2018, Higher education computer science, P59, DOI [10.1007/978-3-319-98590-9_5, DOI 10.1007/978-3-319-98590-9_5]; Lancaster T, 2016, HANDBOOK OF ACADEMIC INTEGRITY, P639, DOI 10.1007/978-981-287-098-8_17; Li XC, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P1129, DOI 10.1145/2675133.2675245; Liu Y., 2019, CoRR abs/1907.11692; Ljubovic V, 2020, IEEE ACCESS, V8, P96505, DOI 10.1109/ACCESS.2020.2996146; Mann S., 2006, Proceedings of the 8th Australasian Conference on Computing Education, P143; Nowak A, 2018, IEEE TECHNOL SOC MAG, V37, P26, DOI 10.1109/MTS.2018.2876105; Orenstrakh M.S., 2023, Detecting llm-generated text in computing education: A comparative study for chatgpt cases; Ottenstein Karl J, 1976, ACM SIGCSE Bulletin, V8, p30S41, DOI 10.1145/382222.382462; Parr T., 2013, The Definitive ANTLR 4 Reference; Prather J, 2023, Arxiv, DOI arXiv:2310.00658; Prechelt L, 2002, J UNIVERS COMPUT SCI, V8, P1016; Prentice FM, 2018, INT J EDUC INTEGR, V14, DOI 10.1007/s40979-018-0036-7; Simon, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P852, DOI 10.1145/3159450.3159547; Solaiman I., 2019, OpenAI; Sulistiani L, 2019, COMPUT APPL ENG EDUC, V27, P166, DOI 10.1002/cae.22066; Toba H., 2023, arXiv; Ullah F, 2020, TECHNOL FORECAST SOC, V159, DOI 10.1016/j.techfore.2020.120186; Ullah F, 2019, IEEE ACCESS, V7, P141987, DOI 10.1109/ACCESS.2019.2943639; Vamplew P., 2010, 7 AUSTRALASIAN C COM, P83; Wang Y, 2019, PROCEEDINGS OF THE 2019 2ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND INFORMATION MANAGEMENT (ICSIM 2019) / 2019 2ND INTERNATIONAL CONFERENCE ON BIG DATA AND SMART COMPUTING (ICBDSC 2019), P96, DOI 10.1145/3305160.3305189; Wang Z., 2020, INT C NATURAL COMPUT, P1407; Zhang CX, 2017, LECT NOTES COMPUT SC, V10366, P282, DOI 10.1007/978-3-319-63579-8_22; Zhang J, 2019, PROC INT CONF SOFTW, P783, DOI 10.1109/ICSE.2019.00086	60	0	0	17	17	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1360-2357	1573-7608		EDUC INF TECHNOL	Educ. Inf. Technol.	2024 FEB 16	2024										10.1007/s10639-024-12520-6	http://dx.doi.org/10.1007/s10639-024-12520-6		FEB 2024	26	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	HX3H2					2024-07-03	WOS:001162764000001
C	Mees, O; Borja-Diaz, J; Burgard, W			IEEE	Mees, Oier; Borja-Diaz, Jessica; Burgard, Wolfram			Grounding Language with Visual Affordances over Unstructured Data	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc				Recent works have shown that Large Language Models (LLMs) can be applied to ground natural language to a wide variety of robot skills. However, in practice, learning multi-task, language-conditioned robotic skills typically requires large-scale data collection and frequent human intervention to reset the environment or help correcting the current policies. In this work, we propose a novel approach to efficiently learn general-purpose language-conditioned robot skills from unstructured, offline and reset-free data in the real world by exploiting a self-supervised visuo-lingual affordance model, which requires annotating as little as 1% of the total data with language. We evaluate our method in extensive experiments both in simulated and real-world robotic tasks, achieving state-of-the-art performance on the challenging CALVIN benchmark and learning over 25 distinct visuomotor manipulation tasks with a single policy in the real world. We find that when paired with LLMs to break down abstract natural language instructions into subgoals via few-shot prompting, our method is capable of completing long-horizon, multi-tier tasks in the real world, while requiring an order of magnitude less data than previous approaches. Code and videos are available at http://hulc2.cs.uni-freiburg.de.	[Mees, Oier; Borja-Diaz, Jessica] Univ Freiburg, Freiburg, Germany; [Burgard, Wolfram] Univ Technol Nuremberg, Nurnberg, Germany	University of Freiburg	Mees, O (corresponding author), Univ Freiburg, Freiburg, Germany.				German Federal Ministry of Education and Research [01IS18040B-OML]	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	We thank Andy Zeng for fruitful discussions on few-shot prompting of LLMs. This work has been supported partly by the German Federal Ministry of Education and Research under contract 01IS18040B-OML.	Abramson J., 2021, ARXIV211203763; Ahn M., 2022, arXiv preprint arXiv:2204.01691; Bisk Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8718; Blukis V., 2021, C ROBOT LEARNING, P1829; Borja-Diaz J., 2022, P IEEE INT C ROB AUT; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Hatori J., 2018, ICRA; Huang Wenlong, 2022, ARXIV220705608; Jang E., 2022, C ROBOT LEARNING, P991; KAELBLING LP, 1993, IJCAI-93, VOLS 1 AND 2, P1094; Liang Jacky, 2022, ARXIV220907753; Lynch C., 2019, P 3 ANN C ROBOT LEAR; Lynch C., 2021, RSS; Mees O., 2021, ISER; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P11205, DOI 10.1109/LRA.2022.3196123; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P7327, DOI 10.1109/LRA.2022.3180108; Misra D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2667; Moravec Hans., 1988, Mind Children: The Future of Robot and Human Intelligence; Nair S., 2021, CORL; Nair Suraj, 2022, ARXIV220312601; Nguyen T., 2020, RSS; Paul R., 2016, RSS; Radford A, 2021, PR MACH LEARN RES, V139; Ramesh A, 2021, PR MACH LEARN RES, V139; Reed Scott, 2022, ARXIV220506175; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ren YF, 2022, IEEE INT C INT ROBOT, P6332, DOI 10.1109/IROS47612.2022.9981518; Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28; Rosete-Beas E., 2022, P 6 C ROB LEARN CORL; Shridhar M., 2022, C ROBOT LEARNING, P894; Shridhar Mohit., 2018, RSS; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Do TT, 2018, IEEE INT CONF ROBOT, P5882, DOI 10.1109/ICRA.2018.8460902; Tobin J, 2017, IEEE INT C INT ROBOT, P23; Yuan W., 2021, C ROBOT LEARNING, P148; Zeng A., 2020, C ROB LEARN CORL; Zeng A, 2018, IEEE INT CONF ROBOT, P3750, DOI 10.1109/ICRA.2018.8461044; Zeng Andy, 2022, ARXIV220400598; Zhang H., 2021, RSS	39	6	6	2	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							11576	11582		10.1109/ICRA48891.2023.10160396	http://dx.doi.org/10.1109/ICRA48891.2023.10160396			7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371103097
J	Szumilo, N; Wiegelmann, T				Szumilo, Nikodem; Wiegelmann, Thomas			Real Estate Insights AI: real estate's new roommate - the good, the bad and the algorithmic	JOURNAL OF PROPERTY INVESTMENT & FINANCE			English	Article						Generative AI; AI analysis; AI in real estate; AI use cases; Jaggered Frontier; Technology in real estate		Purpose - This paper aims to provide a comprehensive analysis of the transformative impact of Artificial Intelligence (AI) and Large Language Models (LLMs), such as GPT-4, on the real estate industry. It explores how these technologies are reshaping various aspects of the sector, from market analysis and valuation to customer interactions and evaluates the balance between technological efficiency and the preservation of human elements in business. Design/methodology/approach - The study is based on an analysis of the strengths and weaknesses of AI as a technology in applications for real estate. It uses this framework to assess the potential of this technology in different use cases. This is supplemented by an emerging literature on the topic, practical insights and industry expert opinions to provide a balanced perspective on the subject. Findings - The paper reveals that AI and LLMs offer significant benefits in real estate, including enhanced data-driven decision-making, predictive analytics and operational efficiency. However, it also uncovers critical challenges, such as potential biases in AI algorithms and the risk of depersonalising customer interactions. Practical implications - The paper advocates for a balanced approach to adopting AI, emphasising the importance of understanding its strengths and limitations while ensuring ethical usage in the diverse and complex landscape of real estate. Originality/value - This work stands out for its balanced examination of both the advantages and limitations of AI in real estate. It introduces the novel concept of the "jagged technological frontier" in real estate, providing a unique framework for understanding the interplay between AI and human expertise in the industry.	[Szumilo, Nikodem] UCL, London, England	University of London; University College London	Szumilo, N (corresponding author), UCL, London, England.	n.szumilo@ucl.ac.uk						De Cremer D., 2023, HARVARD BUS REV, V13; DellAcqua F., 2023, Harvard Business School Technology & Operations Mgt. Unit Working Paper, P24; McKinsey Company, 2023, GENERATIVE AI CAN CH; Szumilo N, 2021, ECON J, V131, P3041, DOI 10.1093/ej/ueaa129; Viriato JC, 2019, J PORTFOLIO MANAGE, V45, P43, DOI 10.3905/jpm.2019.45.7.043	5	0	0	9	9	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1463-578X	1470-2002		J PROP INVEST FINANC	J. Prop. Invest. Finance	APR 16	2024	42	2			SI		211	217		10.1108/JPIF-01-2024-0001	http://dx.doi.org/10.1108/JPIF-01-2024-0001		MAR 2024	7	Business, Finance	Emerging Sources Citation Index (ESCI)	Business & Economics	NO5U5					2024-07-03	WOS:001185960000001
J	Wu, YX; Zhang, ZY; Dong, XY; Hong, SQ; Hu, Y; Liang, P; Li, LS; Zou, B; Wu, XX; Wang, DF; Chen, H; Qiu, HL; Tang, HT; Kang, KY; Li, QL; Zhai, X				Wu, Yuxin; Zhang, Zaiyu; Dong, Xinyu; Hong, Siqi; Hu, Yue; Liang, Ping; Li, Lusheng; Zou, Bin; Wu, Xuanxuan; Wang, Difei; Chen, Hui; Qiu, Hanli; Tang, Haotian; Kang, Kaiyi; Li, Qinling; Zhai, Xuan			Evaluating the performance of the language model ChatGPT in responding to common questions of people with epilepsy	EPILEPSY & BEHAVIOR			English	Article						Artificial intelligence; ChatGPT; Epilepsy; Patient education; Language learning models	HEALTH INFORMATION; INTERNET; OUTCOMES	Objective: People with epilepsy desire to acquire accurate information about epilepsy and actively engage in its management throughout the long journey of living with seizures. ChatGPT is a large language model and we aimed to assess the accuracy and consistency of ChatGPT in responding to the common concerns of people with epilepsy and to evaluate its ability to provide emotional support. Methods: Questions were collected from the International League against Epilepsy and the China Association against Epilepsy. The responses were independently assessed by two board-certified epileptologists from the China Association against Epilepsy, and a third reviewer resolved disagreements. The reviewers assessed its ability to provide emotional support subjectively. Results: A total of 378 questions related to epilepsy and 5 questions related to emotional support were included. ChatGPT provided "correct and comprehensive" answers to 68.4% of the questions. The model provided reproducible answers for 82.3% questions. The model performed poorly in answering prognostic questions, with only 46.8% of the answers rated as comprehensive. When faced with questions requiring emotional support, the model can generate natural and understandable responses. Significance: ChatGPT provides accurate and reliable answers to patients with epilepsy and is a valuable source of information. It also provides partial emotional support, potentially assisting those experiencing emotional distress. However, ChatGPT may provide incorrect responses, leading users to inadvertently accept incorrect and potentially dangerous advice. Therefore, the direct use of ChatGPT for medical guidance is not recommended and its primary use at present is in patients education.	[Wu, Yuxin; Zhang, Zaiyu; Dong, Xinyu; Hong, Siqi; Hu, Yue; Liang, Ping; Li, Lusheng; Zou, Bin; Wu, Xuanxuan; Wang, Difei] Chongqing Med Univ, Natl Clin Res Ctr Child Hlth & Disorders, Dept Neurosurg, Childrens Hosp,Minist Educ,Key Lab Child Dev & Dis, Chongqing, Peoples R China; [Wu, Yuxin; Zhang, Zaiyu; Dong, Xinyu; Hong, Siqi; Hu, Yue; Liang, Ping; Li, Lusheng; Zou, Bin; Wu, Xuanxuan; Wang, Difei] Chongqing Key Lab Translat Med Res Cognit Dev & Le, Chongqing, Peoples R China; [Qiu, Hanli] Univ Tubingen, MEG Ctr, Tubingen, Germany; [Qiu, Hanli] Univ Tubingen, Hertie Inst Klin Hirnforschung, Abt Neuronale Dynam & Magnetoenzephalog, Tubingen, Germany; [Li, Qinling; Zhai, Xuan] Chongqing Med Univ, Childrens Hosp, 136 Zhongshan 2nd Rd, Chongqing 400010, Peoples R China	Chongqing Medical University; Eberhard Karls University of Tubingen; Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Chongqing Medical University	Li, QL; Zhai, X (corresponding author), Chongqing Med Univ, Childrens Hosp, 136 Zhongshan 2nd Rd, Chongqing 400010, Peoples R China.	wuxuanxuan@hospital.cqmu; mr_zaiyuzhang@163.com; wuxuanxuan@hospital.cqmu.edu.cn; siqihong@cqmu.edu.cn; huyue915@163.com; liangping868@sina.com; liangping868@sina.com; 59100497@qq.com; wuxuanxuan@hospital.cqmu; wangdifei1993@163.com; chenhuimed@sina.com; hanliqiu_1207@163.com; tang_haotian_0996@163.com; kaiyi_kang@163.com; liangping868@sina.com; wuxuanxuan@hospital.cqmu	Dong, Xinyu/KDO-5939-2024; Wu, Yuxin/HZL-5896-2023; Wu, Yuxin/AAG-9394-2019	Dong, Xinyu/0009-0002-7313-0757; Wu, Yuxin/0000-0002-9334-9820; Wu, Yuxin/0000-0002-0337-7538	National Natural Science Founda- tion [81971217]	National Natural Science Founda- tion(National Natural Science Foundation of China (NSFC))	<BOLD>Funding</BOLD> This study was supported by the National Natural Science Founda- tion (Grant No. 81971217) .	Arslan S, 2023, ANN BIOMED ENG, V51, P1887, DOI 10.1007/s10439-023-03227-9; Baca CB, 2011, PEDIATRICS, V128, pE1532, DOI 10.1542/peds.2011-0245; Baxendale S, 2021, EPILEPSY BEHAV, V118, DOI [10.1016/j.yebeh.2021.107917, 10.1016/j.yebeh.2021.107899]; Beghi E, 2019, LANCET NEUROL, V18, P357, DOI 10.1016/S1474-4422(18)30454-X; Beghi E, 2016, PHARMACOL RES, V107, P79, DOI 10.1016/j.phrs.2016.03.003; Berg AT, 2019, EPILEPSY BEHAV, V97, P44, DOI 10.1016/j.yebeh.2019.05.011; Branum C, 2023, NURS EDUC, V48, P231, DOI 10.1097/NNE.0000000000001436; Brigo F, 2014, EPILEPSY BEHAV, V31, P67, DOI 10.1016/j.yebeh.2013.11.020; Christiano P.F., 2017, ADV NEURAL INFORM PR, P30; Correa DJ, 2020, EPILEPSIA, V61, P528, DOI 10.1111/epi.16446; Couldridge L, 2001, SEIZURE-EUR J EPILEP, V10, P605, DOI 10.1053/seiz.2001.0652; Escoffery C, 2008, EPILEPSY BEHAV, V12, P109, DOI 10.1016/j.yebeh.2007.07.013; Granbichler CA, 2017, EPILEPSIA, V58, P1939, DOI 10.1111/epi.13902; He YB, 2023, ANN BIOMED ENG, V51, P1362, DOI 10.1007/s10439-023-03206-0; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Karadzic T, 2022, EPILEPSY BEHAV, V136, DOI 10.1016/j.yebeh.2022.108912; Kee D, 2023, EPILEPSIA, V64, P479, DOI 10.1111/epi.17483; Koo YS, 2012, EPILEPSY BEHAV, V25, P156, DOI 10.1016/j.yebeh.2012.06.002; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu JM, 2015, CHINESE MED J-PEKING, V128, P3324, DOI 10.4103/0366-6999.171425; Liu JM, 2013, SEIZURE-EUR J EPILEP, V22, P787, DOI 10.1016/j.seizure.2013.06.007; Meng Y, 2017, EPILEPSY BEHAV, V71, P79, DOI 10.1016/j.yebeh.2017.04.033; O'Callaghan C, 2021, EPILEPSY BEHAV, V121, DOI 10.1016/j.yebeh.2021.108033; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Samaan JS, 2023, Assessing the Accuracy of Responses by the Language Model ChatGPT to Questions Regarding Bariatric Surgery, P1; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Silek H, 2023, EPILEPSY BEHAV, V138, DOI 10.1016/j.yebeh.2022.109017; Singh R, 2023, J NEUROSURG, V139, P1487, DOI 10.3171/2023.3.JNS23555; Thijs RD, 2019, LANCET, V393, P689, DOI 10.1016/S0140-6736(18)32596-0; Vaughan KA, 2019, J NEUROSURG, V130, P1127, DOI 10.3171/2018.3.JNS171722; Yeo YH, 2023, Assessing the performance of ChatGPT in answering questions regarding cirrhosis and hepatocellular carcinoma 2023	31	1	1	6	6	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1525-5050	1525-5069		EPILEPSY BEHAV	Epilepsy Behav.	FEB	2024	151								109645	10.1016/j.yebeh.2024.109645	http://dx.doi.org/10.1016/j.yebeh.2024.109645		JAN 2024	7	Behavioral Sciences; Clinical Neurology; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Behavioral Sciences; Neurosciences & Neurology; Psychiatry	JO1J2	38244419				2024-07-03	WOS:001174013600001
C	Jang, J; Kim, Y; Lee, J; Kim, JJ			IEEE Comp Soc	Jang, Jaeyong; Kim, Yulhwa; Lee, Juheun; Kim, Jae-Joon			FIGNA: Integer Unit-based Accelerator Design for FP-INT GEMM Preserving Numerical Accuracy	2024 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE, HPCA 2024	International Symposium on High-Performance Computer Architecture-Proceedings		English	Proceedings Paper	30th IEEE International Symposium on High-Performance Computer Architecture (HPCA)	MAR 02-06, 2024	Edinburgh, SCOTLAND	IEEE, IEEE Comp Soc, Huawei, Amazon Sci, Ant Res, CodePlay, ARM, FuriosaAI, Google, Rebellions, AMD, IBM, MangoBoost, Moreh, Qualcomm			FLOATING-POINT	The weight-only quantization has emerged as a promising technique for alleviating the computational burden of large language models (LLMs) by employing low-precision integer (INT) weights, while retaining full-precision floating point (FP) activations to ensure inference quality. Despite the memory footprint reduction achieved through decreased bit-precision of weight parameters, the actual computing performance is often not improved significantly due to FP-INT multiply-accumulation (MAC) operations being performed on the floating point unit (FPU) after dequantizing the INT weight values to FP values, owing to the lack of dedicated FP-INT arithmetic units. In this study, we investigate the impact of introducing a dedicated FPINT unit on overall performance and find that such specialization does not yield substantial improvements. As an alternative approach, we propose FIGNA, an accelerator based on INT units designed specifically for FP-INT MAC operations. A key feature of FIGNA is its ability to achieve the same numerical accuracy as the FPU while relying solely on the integer-unit, a departure from prior methods that relied on integer-units with numerical approximations for FP arithmetic results, albeit claiming similar inference accuracy through dedicated network training. Through comprehensive experiments on FP-INT quantized networks for LLMs, including OPT and BLOOM, we demonstrate the superior performance of FIGNA compared to conventional FPUs in terms of performance per area (TOPS/mm2) and energy efficiency (TOPS/W) across various input and weight precision combinations. For instance, in the FP16-INT4 case, FIGNA shows 6.34x higher TOPS/ mm(2) and 2.19x higher TOPS/W compared to the baseline.	[Jang, Jaeyong; Lee, Juheun; Kim, Jae-Joon] Seoul Natl Univ, Seoul, South Korea; [Kim, Yulhwa] Sungkyunkwan Univ, Seoul, South Korea	Seoul National University (SNU); Sungkyunkwan University (SKKU)	Kim, JJ (corresponding author), Seoul Natl Univ, Seoul, South Korea.	jaeyongjang@snu.ac.kr; yulhwa.k@gmail.com; juheun.lee@snu.ac.kr; kimjaejoon@snu.ac.kr			Institute of Information communications Technology Planning Evaluation (IITP) - Korea government (MSIT) [2020R1A2C2004329, IITP-2023-RS-2023-00256081, 2021-0-01343]; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education [2022R1A6A3A01087416]; BK21 FOUR program at Seoul National University; Inter-university Semiconductor Research Center at Seoul National University; IC Design Education Center (IDEC)	Institute of Information communications Technology Planning Evaluation (IITP) - Korea government (MSIT)(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education(National Research Foundation of KoreaMinistry of Education (MOE), Republic of KoreaNational Research Council for Economics, Humanities & Social Sciences, Republic of Korea); BK21 FOUR program at Seoul National University; Inter-university Semiconductor Research Center at Seoul National University; IC Design Education Center (IDEC)	y This work was supported in part by Institute of Information communications Technology Planning Evaluation (IITP) grant funded by the Korea government (MSIT) (No.2020R1A2C2004329, NeuroHub: Web-based Open Simulation Platform for Collaborative In-Memory Neural Network Hardware Research, IITP-2023-RS-2023-00256081: artificial intelligence semiconductor support program to nurture the best talents, No. 2021-0-01343: Artificial Intelligence Graduate School Program (Seoul National University)), Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (2022R1A6A3A01087416), BK21 FOUR program at Seoul National University, and Inter-university Semiconductor Research Center at Seoul National University. The EDA tool was supported by the IC Design Education Center (IDEC).	[Anonymous], 2017, Mixed precision training; Bai Y, 2019, Arxiv, DOI arXiv:1810.00861; Bhalgat Y, 2020, IEEE COMPUT SOC CONF, P2978, DOI 10.1109/CVPRW50498.2020.00356; Black D.C., 2004, SystemC: From the Ground Up; Burgess N, 2019, P S COMP ARITHM, P88, DOI 10.1109/ARITH.2019.00022; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Chung IS, 2020, Arxiv, DOI arXiv:2009.07453; Dai S., 2021, P MACH LEARN SYST, V3, P873; Darvish Rouhani B., 2023, P 50 ANN INT S COMP, P1; Dettmers T, 2022, Arxiv, DOI arXiv:2208.07339; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan HX, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P28, DOI 10.1109/ICFPT47387.2019.00012; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; HOKENEK E, 1990, IEEE J SOLID-ST CIRC, V25, P1207, DOI 10.1109/4.62143; I. S. Association, 2012, Ieee standard for standard systemc language reference manual; Jeon Y., 2022, P IEEE CVF C COMP VI, p12 329; Jeon Y, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00099; Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Kim S, 2024, Arxiv, DOI arXiv:2306.07629; Kim S, 2023, Arxiv, DOI arXiv:2302.14017; Kim Y., 2023, 11 INT C LEARN REPR; Kim Y. J., 2022, Who says elephants can't run: Bringing large scale moe models into cloud scale production; Köster U, 2017, ADV NEUR IN, V30; Kung S. Y., 1985, IEEE ASSP Magazine, V2, P4, DOI 10.1109/MASSP.1985.1163741; Kurup P., 2012, Logic synthesis using Synopsys<(R); Kwon S. J., 2022, arXiv; Li YH, 2021, Arxiv, DOI arXiv:2102.05426; Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958; Lin J., 2023, Awq: Activation-aware weight quantization for llm compression and acceleration; Luccioni A. S., 2022, arXiv, DOI 10.48550/ARXIV.2211.02001; Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556; Merity S, 2016, Arxiv, DOI [arXiv:1609.07843, DOI 10.48550/ARXIV.1609.07843]; Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433; Muller J.-M., 2018, Handbook of Floating-Point Arithmetic; NVIDIA, Nvidia a100 tensor core gpu; NVIDIA, FasterTransformer; Park G, 2024, Arxiv, DOI arXiv:2206.09557; Qin YB, 2023, CONF PROC INT SYMP C, P301, DOI 10.1145/3579371.3589057; Quinnell E, 2007, CONFERENCE RECORD OF THE FORTY-FIRST ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1-5, P331; Rouhani Bita Darvish, 2020, Advances in neural information processing systems, V33; Scao T. L., 2023, Bloom: A 176b -parameter open -access multilingual language model; Shewchuk JR, 1997, DISCRETE COMPUT GEOM, V18, P305, DOI 10.1007/PL00009321; Song ZR, 2018, AAAI CONF ARTIF INTE, P816; Touvron H., 2023, Llama: Open and efficient foundation language models; Vijayakumar A. K., 2018, Diverse beam search: Decoding diverse solutions from neural sequence models; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wilkinson J. H., 1994, Rounding errors in algebraic processes; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Wu X., 2022, Advances in Neural Information Processing Systems, V35, P3217; Xiao GX, 2024, Arxiv, DOI arXiv:2211.10438; Xu C, 2018, Arxiv, DOI arXiv:1802.00150; Yao Z., 2022, Advances in Neural Information Processing Systems, V35, P27168; Yu GI, 2022, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, OSDI 2022, P521; Yuan ZH, 2023, Arxiv, DOI arXiv:2304.01089; Zhang S., 2022, Opt: Open pre-trained transformer language models; Zhang SQ, 2022, INT S HIGH PERF COMP, P846, DOI 10.1109/HPCA53966.2022.00067	57	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-0897		979-8-3503-9313-2; 979-8-3503-9314-9	INT S HIGH PERF COMP			2024							760	773		10.1109/HPCA57654.2024.00064	http://dx.doi.org/10.1109/HPCA57654.2024.00064			14	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW8WI					2024-07-03	WOS:001207751400053
J	Dentella, V; Günther, F; Leivada, E				Dentella, Vittoria; Guenther, Fritz; Leivada, Evelina			Systematic testing of three Language Models reveals low language accuracy, absence of response stability, and a yes- response bias	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						Language Models; cognitive models; bias; language		Humans are universally good in providing stable and accurate judgments about what forms part of their language and what not. Large Language Models (LMs) are claimed to possess human -like language abilities; hence, they are expected to emulate this behavior by providing both stable and accurate answers, when asked whether a string of words complies with or deviates from their next -word predictions. This work tests whether sta-bility and accuracy are showcased by GPT-3/text- davinci-002, GPT-3/text- davinci-003, and ChatGPT, using a series of judgment tasks that tap on 8 linguistic phenomena: plural attraction, anaphora, center embedding, comparatives, intrusive resumption, negative polarity items, order of adjectives, and order of adverbs. For every phenomenon, 10 sentences (5 grammatical and 5 ungrammatical) are tested, each randomly repeated 10 times, totaling 800 elicited judgments per LM (total n = 2,400). Our results reveal variable above-chance accuracy in the grammatical condition, below-chance accuracy in the ungrammatical condition, a significant instability of answers across phenomena, and a yes- response bias for all the tested LMs. Furthermore, we found no evidence that repetition aids the Models to converge on a processing strategy that culminates in stable answers, either accurate or inaccurate. We demonstrate that the LMs' performance in identifying (un)grammatical word patterns is in stark contrast to what is observed in humans (n = 80, tested on the same tasks) and argue that adopting LMs as theories of human language is not motivated at their current stage of development.	[Dentella, Vittoria] Univ Rovira i Virgili, Dept Estudis Anglesos & Alemanys, Tarragona 43002, Spain; [Guenther, Fritz] Humboldt Univ, Inst Psychol, D-10099 Berlin, Germany; [Leivada, Evelina] Univ Autonoma Barcelona, Dept Filol Catalana, Barcelona 08193, Spain; [Leivada, Evelina] Inst Catalana Recerca & Estudis Avancats ICREA, Barcelona 08010, Spain	Universitat Rovira i Virgili; Humboldt University of Berlin; Autonomous University of Barcelona; ICREA	Dentella, V (corresponding author), Univ Rovira i Virgili, Dept Estudis Anglesos & Alemanys, Tarragona 43002, Spain.	vittoria.dentella@urv.cat		Gunther, Fritz/0000-0002-9205-6786; Dentella, Vittoria/0000-0001-6697-9184; Leivada, Evelina/0000-0003-3181-1917	European Union [945413]; Universitat Rovira i Virgili; German Research Foundation (Deutsche Forschungsgemeinschaft) under the Emmy-Noether grant "What's in a name?" [459717703]; Spanish Ministry of Science and Innovation (MCIN/AEI);  [PID2021-124399NA-I00]	European Union(European Union (EU)); Universitat Rovira i Virgili; German Research Foundation (Deutsche Forschungsgemeinschaft) under the Emmy-Noether grant "What's in a name?"(German Research Foundation (DFG)); Spanish Ministry of Science and Innovation (MCIN/AEI); 	V.D. acknowledges funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 945413 and from the Universitat Rovira i Virgili. F.G. acknowledges funding from the German Research Foundation (Deutsche Forschungsgemeinschaft) under the Emmy-Noether grant "What's in a name?" (project No. 459717703) . E.L. acknowledges funding from the Spanish Ministry of Science and Innovation (MCIN/AEI/10.13039/501100011033) under the research project No. PID2021-124399NA-I00.	[Anonymous], 1970, Cognition and the Development of Language; Arehalli S., 2022, Neural networks as cognitive models of the processing of syntactic constraints; Baroni M., 2022, Algebraic structures in natural language; Beltrama A, 2016, GLOSSA-UK, V1, DOI 10.5334/gjgl.24; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Birhane A., 2021, Automating Ambiguity: Challenges and Pitfalls of Artificial Intelligence; Birhane Abeba, 2021, Kvinder, Kon & Forskning, V29, P60, DOI DOI 10.7146/KKF.V29I2.124899; Bowerman M., 1988, EXPLAINING LANGUAGE, P73; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; CHOMSKY N, 1977, LINGUIST INQ, V8, P425; Chomsky N, 2022, COGN SEMANT, V8, P347, DOI 10.1163/23526416-BJA10040; Chouinard MM, 2003, J CHILD LANG, V30, P637, DOI 10.1017/S0305000903005701; Cinque Guglielmo, 2010, The Syntax of Adjectives: A Comparative Study; D'Alessandro R, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.700126; de Leeuw J. R., 2023, Journal of Open Source Software, V8, DOI DOI 10.21105/JOSS.05351; Dentella V., Systematic testing of three Language Models reveals low language accuracy, absence of response stability, and a yesresponse bias; Dentella V, 2023, Arxiv, DOI [arXiv:2302.12313, 10.48550/arXiv.2302.12313]; Devitt M, 2006, BRIT J PHILOS SCI, V57, P481, DOI 10.1093/bjps/axl017; Dillon B, 2013, J MEM LANG, V69, P85, DOI 10.1016/j.jml.2013.04.003; Ellis K, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32012-w; Everaert MBH, 2015, TRENDS COGN SCI, V19, P729, DOI 10.1016/j.tics.2015.09.008; Gibson E, 1999, LANG COGNITIVE PROC, V14, P225, DOI 10.1080/016909699386293; Henry A, 2005, LINGUA, V115, P1599, DOI 10.1016/j.lingua.2004.07.006; Hu J, 2023, Arxiv, DOI [arXiv:2305.13264, 10.48550/arXiv.2305.13264]; Kandpal N, 2023, Arxiv, DOI [arXiv:2211.08411, 10.48550/arXiv.2211.08411]; Karimi H, 2016, Q J EXP PSYCHOL, V69, P1013, DOI 10.1080/17470218.2015.1053951; Langsford S, 2018, GLOSSA-UK, V3, DOI 10.5334/gjgl.396; Le Page R.B., 1985, Acts of identity: Creole-based approaches to language and ethnicity; LEES RB, 1957, LANGUAGE, V33, P375, DOI 10.2307/411160; Leivada E, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00364; Lemoine B., 2022, Is lamda sentient?-An interview. Medium; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Linzen T, 2018, GLOSSA-UK, V3, DOI 10.5334/gjgl.528; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; MARCUS GF, 1993, COGNITION, V46, P53, DOI 10.1016/0010-0277(93)90022-N; Merrill W., 2022, P 26 C COMPUTATIONAL, P176; Milway D., 2023, lingbuzz/007264; Mitchell J., 2020, P 28 INT C COMPUTATI, P5147; Moro A, 2016, IMPOSSIBLE LANGUAGES, P1, DOI 10.7551/mitpress/9780262034890.001.0001; Murphy E, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201651119; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Parker D, 2016, COGNITION, V157, P321, DOI 10.1016/j.cognition.2016.08.016; Payne Amanda., 2018, Adverb typology: A computational characterization; Phillips C., 2011, Experiments at the Interfaces; Piantadosi S., 2023, Lingbuzz lingbuzz/007180; Piantasodi S, 2022, Arxiv, DOI [arXiv:2208.02957, 10.48550/arXiv.2208.02957, DOI 10.48550/ARXIV.2208.02957]; Razeghi Y, 2022, Arxiv, DOI [arXiv:2202.07206, 10.48550/arXiv.2202.07206]; Rizzi L., 2016, The Oxford Handbook of Universal Grammar; Schutze Carson T., 2016, EMPIRICAL BASE LINGU; Sprouse J, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X17000590; Sprouse J, 2013, LINGUA, V134, P219, DOI 10.1016/j.lingua.2013.07.002; Sprouse J, 2012, J LINGUIST, V48, P609, DOI 10.1017/S0022226712000011; van Rooij I., 2023, Reclaiming AI as a theoretical tool for cognitive science. PsyArxiv, DOI [10.31234/osf.io/4cbuv, DOI 10.31234/OSF.IO/4CBUV]; van Rooij I, 2022, NAT REV PSYCHOL, V1, P127, DOI 10.1038/s44159-022-00031-5; Wagers MW, 2009, J MEM LANG, V61, P206, DOI 10.1016/j.jml.2009.04.002; Wellwood A, 2018, J SEMANT, V35, P543, DOI 10.1093/jos/ffy014	57	2	2	7	8	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	DEC 19	2023	120	51							e2309583120	10.1073/pnas.2309583120	http://dx.doi.org/10.1073/pnas.2309583120			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HE5S2	38091290	Green Published, hybrid			2024-07-03	WOS:001157836300014
J	Thanasi-Boçe, M; Hoxha, J				Thanasi-Boce, Marsela; Hoxha, Julian			From ideas to ventures: building entrepreneurship knowledge with LLM, prompt engineering, and conversational agents	EDUCATION AND INFORMATION TECHNOLOGIES			English	Article; Early Access						Artificial intelligence (AI); GPT-4; Entrepreneurship education; Prompt Engineering Techniques (PETs); Conversational agents; Retrieval Augmentation Generation (RAG)		Entrepreneurship education has evolved to meet the demands of a dynamic business environment, necessitating innovative teaching methods to prepare entrepreneurs for market uncertainties. Large Language Models (LLMs) like the Generative Pre-trained Transformer 4 (GPT-4), recognized for their exceptional performance on public datasets, are examined in this study for their potential adaptability and interactivity nature, which align well with the dynamic nature of entrepreneurship learning. The interaction with LLMs can be enhanced by using effective prompt engineering techniques (PETs) that allow for crafting precise queries to elicit accurate and relevant responses for entrepreneurial learning. Critical concerns regarding the use of GPT-4 and conversational agents in entrepreneurship courses include the reliability and accuracy of data sources, the necessity for specific, real-time data for effective decision-making, and the lack of in-depth exploration of effective prompting strategies tailored to entrepreneurship education. Addressing these issues, this study aims to identify and compare the quality output of currently available PETs, develop innovative PETs that are well-aligned with entrepreneurial learning, and provide guidelines on how to fully utilize LLMs and conversational agents with Retrieval Augmentation Generation (RAG) technology in entrepreneurship education. The combination of conversational agents and RAG technology into a hybrid innovative approach overcomes inherent limitations in each technology separately and enhances efficiency and relevancy in entrepreneurship education through exact, dynamic interactions and advanced memory capabilities. The findings of the study significantly contribute to the field of entrepreneurship by offering practical insights for students and educators on enhancing the entrepreneurship learning experience, particularly by utilizing cutting-edge technology to improve data relevance and answer accuracy in entrepreneurial queries and scenarios.	[Thanasi-Boce, Marsela] Amer Univ Middle East, Coll Business Adm, Egaila, Kuwait; [Hoxha, Julian] Amer Univ Middle East, Coll Engn & Technol, Egaila, Kuwait	American University of the Middle East; American University of the Middle East	Thanasi-Boçe, M (corresponding author), Amer Univ Middle East, Coll Business Adm, Egaila, Kuwait.	Marsela.Thanasi@aum.edu.kw; Julian.Hoxha@aum.edu.kw	Thanasi, Marsela/K-9798-2018	Thanasi, Marsela/0000-0001-9117-9453				Achiam J., 2023, GPT-4 Technical Report; Alshater M., 2022, Exploring the role of artificial intelligence in enhancing academic performance: A case study of ChatGPT, DOI [DOI 10.2139/SSRN.4312358, https://doi.org/10.2139/ssrn.4312358]; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Audretsch DB, 2007, ELGAR ORIG REF, P1; Ausat AMA., 2023, Jurnal Minfo Polgan, V12, P1220, DOI [10.33395/jmp.v12i1.12667, DOI 10.33395/JMP.V12I1.12667]; Ba JL., 2016, arXiv; Bajaj P, 2018, Arxiv, DOI arXiv:1611.09268; Bell R., 2023, Entrepreneurship Education, V6, P1, DOI 10.1007/s41959-023-00099-x; Bhaskar P, 2024, INTERACT TECHNOL SMA, DOI 10.1108/ITSE-08-2023-0169; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chase H., 2022, Langchain; Chen M., 2021, arXiv; Christiano PF, 2017, ADV NEUR IN, V30; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Deb R., 2020, Journal of Engineering Education Transformations, V33; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhuliawala S, 2023, Arxiv, DOI [arXiv:2309.11495, 10.48550/arXiv.2309.11495]; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Dua D, 2022, Arxiv, DOI [arXiv:2212.04092, DOI 10.48550/ARXIV.2212.04092]; Dunn M, 2017, Arxiv, DOI arXiv:1704.05179; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Elbanna S., 2024, Management and Sustainability: An Arab Review, V3, P16, DOI DOI 10.1108/MSAR-03-2023-0016; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fayolle A, 2018, ELGAR RES AGENDAS, P127; Gao T., 2020, arXiv; Gupta M, 2023, IEEE ACCESS, V11, P80218, DOI 10.1109/ACCESS.2023.3300381; Hao Y., 2022, arXiv; Ho X, 2020, Arxiv, DOI arXiv:2011.01060; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Hugging Face, 2024, API Reference (Swagger); Huggingface, 2024, About us; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lightman H, 2023, Arxiv, DOI [arXiv:2305.20050, DOI 10.48550/ARXIV.2305.20050]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Linkon A. A., 2024, Journal of Computer Science and Technology Studies, V6, P225; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Y, 2023, Arxiv, DOI arXiv:2308.05374; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lu Yao, 2021, arXiv; Lukasik M, 2024, Arxiv, DOI arXiv:2403.04182; Meng C, 2024, Arxiv, DOI arXiv:2404.01012; Minaee S, 2024, Arxiv, DOI [arXiv:2402.06196, 10.48550/arXiv.2402.06196]; Mogavi R. H., 2024, Computers in Human Behavior: Artificial Humans; Mogavi RH, 2023, Arxiv, DOI arXiv:2305.13114; Narayan A., 2022, ICLR; Open AI, 2023, About us; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng M., 2024, arXiv; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Perez E., 2022, arXiv; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Press O, 2023, Arxiv, DOI arXiv:2210.03350; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rahaman M. S., 2023, Emergence of Entrepreneurial Research; Ratten V, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100857; Ratten V, 2021, INT J MANAG EDUC-OXF, V19, DOI 10.1016/j.ijme.2020.100431; Ratten V, 2021, INT J MANAG EDUC-OXF, V19, DOI 10.1016/j.ijme.2020.100367; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Seckler C., 2021, Journal of Business Venturing Design, V1, DOI 10.1016/j.jbvd.2022.100004; Sharif O. O., 2024, Journal of Higher Education Theory & Practice, V24, P148; Shi F, 2023, INT C MACHINE LEARNI, P31210; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Shoufan A, 2023, IEEE ACCESS, V11, P38805, DOI 10.1109/ACCESS.2023.3268224; Smith LN, 2017, IEEE WINT CONF APPL, P464, DOI 10.1109/WACV.2017.58; Su JH, 2023, ECNU REV EDUC, V6, P355, DOI 10.1177/20965311231168423; Su Y., 2023, International Journal of New Developments in Education, V5, P1; Sudirman Ivan Diryana, 2023, 2023 IEEE World AI IoT Congress (AIIoT), P0786, DOI 10.1109/AIIoT58121.2023.10174472; Susnjak T, 2024, INT J ARTIF INTELL E, V34, P452, DOI 10.1007/s40593-023-00336-3; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; Thanasi-Boçe M, 2020, EDUC TRAIN, DOI 10.1108/ET-06-2019-0109; Thorne J, 2018, Arxiv, DOI arXiv:1803.05355; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Tu JJ, 2022, ECON RES-EKON ISTRAZ, DOI 10.1080/1331677X.2022.2119429; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vecchiarini M, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100879; Wang L., 2024, Frontiers of Computer Science, V18, P1; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, ADV NEUR IN; Weng YX, 2023, Arxiv, DOI arXiv:2212.09561; Wilson K. E., 2008, Chapter 5: Entrepreneurship Education in Europe; Xi ZH, 2023, Arxiv, DOI arXiv:2309.07864; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang ZL, 2018, Arxiv, DOI arXiv:1809.09600; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Ye JC, 2023, Arxiv, DOI arXiv:2302.05698; Yuan ZQ, 2023, Arxiv, DOI arXiv:2308.01240; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]; Zhou DY, 2022, Arxiv, DOI [arXiv:2205.10625, DOI 10.48550/ARXIV.2205.10625]; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]; Zhuang Y., 2024, Advances in Neural Information Processing Systems, V36	103	0	0	6	6	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1360-2357	1573-7608		EDUC INF TECHNOL	Educ. Inf. Technol.	2024 JUN 10	2024										10.1007/s10639-024-12775-z	http://dx.doi.org/10.1007/s10639-024-12775-z		JUN 2024	57	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	TQ4Y6					2024-07-03	WOS:001242724800003
J	Shiraishi, M; Lee, HS; Kanayama, K; Moriwaki, Y; Okazaki, M				Shiraishi, Makoto; Lee, Haesu; Kanayama, Koji; Moriwaki, Yuta; Okazaki, Mutsumi			Appropriateness of Artificial Intelligence Chatbots in Diabetic Foot Ulcer Management	INTERNATIONAL JOURNAL OF LOWER EXTREMITY WOUNDS			English	Article; Early Access						diabetic foot ulcers; artificial intelligence; ChatGPT; GPT-4; Claude-2	QUESTIONS; ACCURACY; QUALITY; SOCIETY; CHATGPT	Type 2 diabetes is a significant global health concern. It often causes diabetic foot ulcers (DFUs), which affect millions of people and increase amputation and mortality rates. Despite existing guidelines, the complexity of DFU treatment makes clinical decisions challenging. Large language models such as chat generative pretrained transformer (ChatGPT), which are adept at natural language processing, have emerged as valuable resources in the medical field. However, concerns about the accuracy and reliability of the information they provide remain. We aimed to assess the accuracy of various artificial intelligence (AI) chatbots, including ChatGPT, in providing information on DFUs based on established guidelines. Seven AI chatbots were asked clinical questions (CQs) based on the DFU guidelines. Their responses were analyzed for accuracy in terms of answers to CQs, grade of recommendation, level of evidence, and agreement with the reference, including verification of the authenticity of the references provided by the chatbots. The AI chatbots showed a mean accuracy of 91.2% in answers to CQs, with discrepancies noted in grade of recommendation and level of evidence. Claude-2 outperformed other chatbots in the number of verified references (99.6%), whereas ChatGPT had the lowest rate of reference authenticity (66.3%). This study highlights the potential of AI chatbots as tools for disseminating medical information and demonstrates their high degree of accuracy in answering CQs related to DFUs. However, the variability in the accuracy of these chatbots and problems like AI hallucinations necessitate cautious use and further optimization for medical applications. This study underscores the evolving role of AI in healthcare and the importance of refining these technologies for effective use in clinical decision-making and patient education.	[Shiraishi, Makoto; Lee, Haesu; Kanayama, Koji; Moriwaki, Yuta; Okazaki, Mutsumi] Univ Tokyo Hosp, Dept Plast & Reconstruct Surg, Tokyo, Japan; [Shiraishi, Makoto] Univ Tokyo Hosp, Dept Plast & Reconstruct Surg, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138655, Japan	University of Tokyo; University of Tokyo	Shiraishi, M (corresponding author), Univ Tokyo Hosp, Dept Plast & Reconstruct Surg, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138655, Japan.	shiraishi-kyf@umin.ac.jp	Shiraishi, Makoto/HOF-3529-2023	Shiraishi, Makoto/0000-0002-3734-2085				Arab-Zozani M, 2022, INT J LOW EXTR WOUND, V21, P41, DOI 10.1177/15347346211014392; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Armstrong DG, 2023, JAMA-J AM MED ASSOC, V330, P62, DOI 10.1001/jama.2023.10578; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Bandarian F, 2022, INT J LOW EXTR WOUND, DOI 10.1177/15347346221109057; Barlas T, 2024, INT J OBESITY, V48, P271, DOI 10.1038/s41366-023-01410-5; Cassidy B, 2023, DIABETES RES CLIN PR, V205, DOI 10.1016/j.diabres.2023.110951; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Christiano PF, 2017, ADV NEUR IN, V30; Eysenbach G, 2002, JAMA-J AM MED ASSOC, V287, P2691, DOI 10.1001/jama.287.20.2691; Hingorani A, 2016, J VASC SURG, V63, p3S, DOI 10.1016/j.jvs.2015.10.003; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Hong Jison, 2023, Clin Diabetes, V41, P549, DOI 10.2337/cd23-0026; Huang CL, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04354-6; Hulman A., 2023, PLoS One, V18; Husers Jens, 2022, Stud Health Technol Inform, V289, P301, DOI 10.3233/SHTI210919; Kung TH., 2023, PLOS Digital Health, V2; Kusunose K, 2023, CIRC J, V87, P1030, DOI 10.1253/circj.CJ-23-0308; Lo ZJ, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231205747; Lo ZJ, 2021, INT WOUND J, V18, P375, DOI 10.1111/iwj.13540; Meo SA, 2023, J DIABETES SCI TECHN, DOI 10.1177/19322968231203987; Mousa KM, 2023, SAGE OPEN NURS, V9, DOI 10.1177/23779608231185873; Nakhleh A, 2023, DIABETES TECHNOL THE, V25, P571, DOI 10.1089/dia.2023.0134; Sanjari M, 2011, INT J LOW EXTR WOUND, V10, P200, DOI 10.1177/1534734611428728; Stefanopoulos S, 2022, J DIABETES SCI TECHN, DOI 10.1177/19322968221142899; Sun HA, 2023, J MED INTERNET RES, V25, DOI 10.2196/51300; Tolossa T, 2020, BMC PUBLIC HEALTH, V20, DOI 10.1186/s12889-019-8133-y; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhang PZ, 2017, ANN MED, V49, P106, DOI 10.1080/07853890.2016.1231932; Zhang YQ, 2020, DIABETES CARE, V43, P964, DOI 10.2337/dc19-1614; Zimmet P, 2001, NATURE, V414, P782, DOI 10.1038/414782a	32	4	4	12	12	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1534-7346	1552-6941		INT J LOW EXTR WOUND	Int. J. Low. Extrem. Wounds	2024 FEB 28	2024										10.1177/15347346241236811	http://dx.doi.org/10.1177/15347346241236811		FEB 2024	7	Dermatology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology; Surgery	JM0L2	38419470				2024-07-03	WOS:001173466100001
J	Tian, SC; Huang, SB; Li, RS; Wei, C				Tian, Sicheng; Huang, Shaobin; Li, Rongsheng; Wei, Chi			A prompt construction method for the reverse dictionary task of large-scale language models	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Reverse dictionary; Large-scale language models; Prompt engineering; Multiple semantic; Negative samples		A reverse dictionary (RD) is a tool designed to find the appropriate word based on a given definition. While large language models (LLMs) have demonstrated exceptional natural language generation capabilities, offering a promising solution for this task, existing LLMs, particularly those with smaller parameter sizes, still require performance enhancements on RD. Fine-tuning LLMs is a direct method of improvement, but it comes with high computational costs and the potential sacrifice of the LLMs' ability to solve other problems. In contrast, employing prompt engineering to construct high-quality prompts that evoke the latent potential of LLMs on RD is a more ideal approach. To this end, we propose a method of automatically constructing prompts based on a small-scale language model. Our method analyzes definitions across multiple semantic dimensions and introduces negative samples to enhance the model's universality and adaptability. Consequently, our small model can generate a candidate set containing the target word with an accuracy rate of 93.1%. We then use these candidates to form effective prompts for LLMs, significantly improving the performance of larger models. Evaluations on a new dataset from the Oxford dictionary show that our LLMs can directly select the target word with an accuracy of 57.5%, which increases to 73.8% when given five candidate words. Our research not only enhances the performance of LLMs on RD but also provides a new perspective on how small models can augment large models, which is particularly important when computational resources are limited.	[Tian, Sicheng; Huang, Shaobin; Li, Rongsheng; Wei, Chi] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China	Harbin Engineering University	Li, RS (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 150001, Peoples R China.	dasheng@hrbeu.edu.cn			National Natural Science Foundation of China [62302121]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<BOLD>Acknowledgements</BOLD> This work is supported by the National Natural Science Foundation of China (No.62302121) .	Aljanabi M., 2024, Mesopotamian J. Arabic Lang. Stud., P16; [Anonymous], 2016, Transactions of the Association for Computational Linguistics; Ardoiz A., 2022, P 16 INT WORKSH SEM, P68; Augustyniak L, 2019, 2019 IEEE SECOND INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND KNOWLEDGE ENGINEERING (AIKE), P43, DOI 10.1109/AIKE.2019.00016; Ben-David E, 2022, T ASSOC COMPUT LING, V10, P414, DOI 10.1162/tacl_a_00468; Bendahman N., 2022, P 16 INT WORKSH SEM, P94; Bilac S., 2004, P 10 ANN M ASS NAT L, P556; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cerniavski R., 2022, P 16 INT WORKSH SEM, P88; Chang TY, 2018, Arxiv, DOI arXiv:1809.03348; Chang TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6064; Chen M., 2019, P 23 C COMP NAT LANG, P152; Chen P., 2022, P 16 INT WORKSH SEM, P75; Cuiy LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1835; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fan R., 2023, P IEEECVF C COMPUTER, P3225; Gadetsky A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P266; Gunel B., 2020, INT C LEARN REPR; Guo H., 2021, arXiv; Han Qi, 2023, ACM TURC '23: Proceedings of the ACM Turing Award Celebration Conference - China 2023, P114, DOI 10.1145/3603165.3607426; He TX, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2044; HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554; Jiang S., 2022, A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Kong C., 2022, arXiv; Korencic D., 2022, arXiv; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; Li B., 2022, P 16 INT WORKSH SEM, P29; Li RS, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115440; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Loshchilov I, 2017, INT C LEARNING REPRE; Mendez O., 2013, 12 MEX INT C ART I 1, P275; Mickus T., 2022, P 16 INT WORKSH SEM, P1; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Morinaga Y., 2018, 24 INT C ICIST 2018, V24, P533; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2151; Robinson Joshua David, 2021, ICLR; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schick T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P390; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Shaw R, 2013, IEEE T KNOWL DATA EN, V25, P528, DOI 10.1109/TKDE.2011.225; Shin R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7699; Siddique B., 2023, SN Computer Science, V4, P168; Siddique B, 2022, IEEE ACCESS, V10, P28385, DOI 10.1109/ACCESS.2022.3158011; Sierra Gerardo., 2000, Bd. I, P223; Srivastava A., 2022, P 16 INT WORKSH SEM, P60; Sun W., 2023, P AAAI C ARTIFICIAL, P13618; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tran T.H.H., 2022, P 16 INT WORKSH SEM, P101; Tsai YHH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6558, DOI 10.18653/v1/p19-1656; Vaswani A., 2017, P ADV NEURAL INFORM, P30; Welleck S., 2020, 8 INT C LEARN REPR I, P1; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wu Y, 2017, PERIPHYTON: FUNCTIONS AND APPLICATION IN ENVIRONMENTAL REMEDIATION, P1; Ye HB, 2021, AAAI CONF ARTIF INTE, V35, P14257; Zhang B., 2023, 12 INT C LEARN REPR; Zhang W., 2024, Adv. Neural Inf. Process. Syst., V36; Zhou Y, 2022, 11 INT C LEARN REPR	61	0	0	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUL	2024	133		F						108596	10.1016/j.engappai.2024.108596	http://dx.doi.org/10.1016/j.engappai.2024.108596			15	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science; Engineering	TP5Q7					2024-07-03	WOS:001242480900001
J	Williams, DO; Fadda, E				Williams, Devin Ormsby; Fadda, Elisa			Can ChatGPT pass Glycobiology?	GLYCOBIOLOGY			English	Article						AI; ChatGPT; Glycobiology; higher education; LLM		The release of text-generating applications based on interactive Large Language Models (LLMs) in late 2022 triggered an unprecedented and ever-growing interest worldwide. The almost instantaneous success of LLMs stimulated lively discussions in public media and in academic fora alike not only on the value and potentials of such tools in all areas of knowledge and information acquisition and distribution but also on the dangers posed by their uncontrolled and indiscriminate use. This conversation is now particularly active in the higher education sector, where LLMs are seen as a potential threat to academic integrity at all levels, from facilitating cheating by students in assignments to plagiarizing academic writing in the case of researchers and administrators. Within this framework, we are interested in testing the boundaries of the LLM ChatGPT (www.openai.com) in areas of our scientific interest and expertise and in analyzing the results from different perspectives, i.e. of a final year BSc student, of a research scientist, and of a lecturer in higher education. To this end, in this paper, we present and discuss a systematic evaluation on how ChatGPT addresses progressively complex scientific writing tasks and exam-type questions in Carbohydrate Chemistry and Glycobiology. The results of this project allowed us to gain insight on: (i) the strengths and limitations of the ChatGPT model to provide relevant and (most importantly) correct scientific information, (ii) the format(s) and complexity of the query required to obtain the desired output, and (iii) strategies to integrate LLMs in teaching and learning.	[Williams, Devin Ormsby; Fadda, Elisa] Maynooth Univ, Dept Chem, Maynooth, Kildare, Ireland; [Fadda, Elisa] Maynooth Univ, Hamilton Inst, Maynooth, Kildare, Ireland	Maynooth University; Maynooth University	Fadda, E (corresponding author), Maynooth Univ, Dept Chem, Maynooth, Kildare, Ireland.	DEVIN.ORMSBYWILLIAMS.2020@MUMAIL.IE; elisa.fadda@mu.ie		Fadda, Elisa/0000-0002-2898-7770				Bommasani R., 2021, ARXIV CSLG; Casalino Lorenzo, 2020, bioRxiv, DOI 10.1101/2020.06.11.146522; Chomsky N., FALSE PROMISE CHATGP; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Newby ML, 2023, J MOL BIOL, V435, DOI 10.1016/j.jmb.2022.167928; Seeberger PH, 2003, CHEM COMMUN, P1115, DOI 10.1039/b210230g; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Vaswani A, 2017, ADV NEUR IN, V30; Vu MH, 2023, NAT MACH INTELL, V5, P485, DOI 10.1038/s42256-023-00637-1	11	0	0	24	54	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	0959-6658	1460-2423		GLYCOBIOLOGY	Glycobiology	OCT 6	2023	33	8					606	614	cwad064	10.1093/glycob/cwad064	http://dx.doi.org/10.1093/glycob/cwad064		AUG 2023	9	Biochemistry & Molecular Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology	X7AD3	37531256	Green Submitted			2024-07-03	WOS:001052316000001
C	Mai, V; Bauer, A; Deggelmann, C; Richert, A		Zaphiris, P; Ioannou, A; Sottilare, RA; Schwarz, J; Nah, FFH; Siau, K; Wei, J; Salvendy, G		Mai, Vanessa; Bauer, Alexander; Deggelmann, Christian; Richert, Anja			Acceptance and User Needs of Coaching Chatbots: An Empirical Analysis of a StudiCoachBot's Conversation Histories	HCI INTERNATIONAL 2023 LATE BREAKING PAPERS, HCII 2023, PT VII	Lecture Notes in Computer Science		English	Proceedings Paper	25th International Conference on Human-Computer Interaction (HCI International)	JUL 23-28, 2023	Copenhagen, DENMARK			AI-based Coaching; Conversational AI; Working Alliance; Acceptance; Social Presence		As technology advances, AI-based coaching continues to offer new opportunities in supporting humans. The StudiCoachBot of TH Koeln/University of Applied Sciences is a coaching chatbot, that is designed to support students with exam anxiety through low-threshold self-reflection. It is an intent-based AI-supported chatbot and is developed in the Conversational AI framework Rasa. This paper gives insights into how iterative development of coaching chatbots can be a key factor for successful chatbot design in terms of acceptance and user needs. Our study consists of two parts: In the first part, we present the iterative development of our coaching chatbot, consisting of user testings with several hundred test users. In the second part, we present the results from our field test after the chatbot release. We collected and evaluated conversation histories and questionnaires from users for a period of 10 weeks. Our results include the evaluation of 242 conversations and 24 questionnaires. On the one hand, the results provide information about access numbers and rates as well as chatbot coaching topics accessed by users. On the other hand, the data shows high acceptance rates and that users can build a relationship in chatbot coaching (measured via working alliance). However, users perceived naturalness of the conversation only moderate. This is understandable, as our intent-based chatbot only allows us to react flexibly to a limited extent to free user input. In a next iteration, we will therefore improve the conversation with the help of large language models to make it more natural.	[Mai, Vanessa; Bauer, Alexander; Deggelmann, Christian; Richert, Anja] TH Koln Univ Appl Sci, Cologne, Germany		Mai, V (corresponding author), TH Koln Univ Appl Sci, Cologne, Germany.	vanessa.mai@th-koeln.de; alexander_christoph.bauer@th-koeln.de; christian_michael.deggelmann@th-koeln.de; anja.richert@th-koeln.de		Richert, Anja/0000-0002-3940-3136				Berninger-Schafer E., 2018, Online-Coaching, DOI [10.1007/978-3-658-10128-2, DOI 10.1007/978-3-658-10128-2]; Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30; Brown M., 2020, EDUCAUSE; Diederich S, 2022, J ASSOC INF SYST, V23, P96, DOI 10.17705/1jais.00724; Grassmann C, 2020, HUM RELAT, V73, P35, DOI 10.1177/0018726718819725; Gratch J, 2007, LECT NOTES ARTIF INT, V4722, P125; Hauser-Ulrich S, 2020, JMIR MHEALTH UHEALTH, V8, DOI 10.2196/15806; Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93; Kanatouri S., 2020, The Digital Coach; Kohne A., 2020, Chatbots: Conversation Design, V1st; Laban G., 2019, INT WORKSH CHATB RES, P215; Lindart M., 2016, Was Coaching wirksam macht: Wirkfaktoren von Coachingprozessen im Fokus, DOI [10.1007/978-3-658-11761-0, DOI 10.1007/978-3-658-11761-0]; Mai V., 2023, Organisationsberatung, Supervision, Coaching, V30, P45, DOI [10.1007/s11613-022-00801-3, DOI 10.1007/S11613-022-00801-3]; Mai V., 2022, Coaching | Theorie & Praxis, V8, P15, DOI [10.1365/s40896-021-00063-3, DOI 10.1365/S40896-021-00063-3]; Mai V, 2022, LECT NOTES COMPUT SC, V13518, P391, DOI 10.1007/978-3-031-21707-4_28; Nagarhalli TP, 2020, INT CONF ADVAN COMPU, P706, DOI [10.1109/icaccs48705.2020.9074420, 10.1109/ICACCS48705.2020.9074420]; Potts C., 2022, Toolkit for the Co-Creation of Health-Based Chatbots, V1st; Schlippe A., 2016, Lehrbuch der systemischen Therapie und Beratung I. Das Grundlagenwissen; Terblanche N., 2020, Philosophy Coach. Int. J., V5, P61, DOI DOI 10.22316/POC/05.1.06; Terblanche N, 2020, INT J EVID BASED COA, V18, P152, DOI 10.24384/b7gs-3h05; Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540; Wilmers F., 2008, KLINISCHE DIAGNOSTIK, V1, P343, DOI [10.7892/BORIS.27962, DOI 10.7892/BORIS.27962, 10.7892/boris.27962]	22	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48059-1; 978-3-031-48060-7	LECT NOTES COMPUT SC			2023	14060						176	190		10.1007/978-3-031-48060-7_14	http://dx.doi.org/10.1007/978-3-031-48060-7_14			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5EY					2024-07-03	WOS:001159628500014
J	Klang, E; Sourosh, A; Nadkarni, GN; Sharif, K; Lahat, A				Klang, Eyal; Sourosh, Ali; Nadkarni, Girish N.; Sharif, Kassem; Lahat, Adi			Evaluating the role of ChatGPT in gastroenterology: a comprehensive systematic review of applications, benefits, and limitations	THERAPEUTIC ADVANCES IN GASTROENTEROLOGY			English	Review						artificial intelligence; ChatGPT; gastroenterology; large language models; review		Background:The integration of artificial intelligence (AI) into healthcare has opened new avenues for enhancing patient care and clinical research. In gastroenterology, the potential of AI tools, specifically large language models like ChatGPT, is being explored to understand their utility and effectiveness.Objectives:The primary goal of this systematic review is to assess the various applications, ascertain the benefits, and identify the limitations of utilizing ChatGPT within the realm of gastroenterology.Design:Through a systematic approach, this review aggregates findings from multiple studies to evaluate the impact of ChatGPT on the field.Data sources and methods:The review was based on a detailed literature search of the PubMed database, targeting research that delves into the use of ChatGPT for gastroenterological purposes. It incorporated six selected studies, which were meticulously evaluated for quality using the Joanna Briggs Institute critical appraisal instruments. The data were then synthesized narratively to encapsulate the roles, advantages, and drawbacks of ChatGPT in gastroenterology.Results:The investigation unearthed various roles of ChatGPT, including its use in patient education, diagnostic self-assessment, disease management, and the formulation of research queries. Notable benefits were its capability to provide pertinent recommendations, enhance communication between patients and physicians, and prompt valuable research inquiries. Nonetheless, it encountered obstacles in decoding intricate medical questions, yielded inconsistent responses at times, and exhibited limitations in generating novel content. The review also considered ethical implications.Conclusion:ChatGPT has demonstrated significant potential in the field of gastroenterology, especially in facilitating patient-physician interactions and managing diseases. Despite these advancements, the review underscores the necessity for ongoing refinement, customization, and ethical regulation of AI tools. These findings serve to enrich the dialog concerning AI's role in healthcare, with a specific focus on ChatGPT's application in gastroenterology. Checking how ChatGPT works in gastroenterology: a detailed look at its uses, advantages, and challengesGoal We looked at how ChatGPT, a computer program, is used in the study Gastroenterology. We wanted to understand what's good about it, what's challenging, and how it can help doctors and patients. How We Did It We searched for articles about ChatGPT in Gastroenterology on PubMed. We found six suitable articles and checked their quality using the Joanna Briggs Institute (JBI) critical appraisal tools. Then, we put all the information together to get a clear picture. What We Found Doctors and researchers use ChatGPT in many ways. Some use it to teach patients about their health, while others use it to help patients check their symptoms or manage their conditions. It can even help come up with research questions. The good things about ChatGPT are that it gives helpful advice, makes talking between doctors and patients easier, and helps come up with research topics. But, sometimes it doesn't understand hard medical questions, gives different answers for the same question, or lacks new ideas. There are also concerns about using it the right way. What This Means ChatGPT can be a helpful tool in Gastroenterology, especially when talking with patients and managing their health. But, there are challenges that need to be fixed. Our review helps people understand how ChatGPT can be used in health care, especially in the field of Gastroenterology.	[Lahat, Adi] Sheba Med Ctr Tel Hashomer, Dept Gastroenterol, IL-52621 Ramat Gan, Israel; [Lahat, Adi] Tel Aviv Univ, Tel Aviv Med Sch, Tel Aviv, Israel; [Klang, Eyal; Sourosh, Ali; Nadkarni, Girish N.] Icahn Sch Med Mt Sinai, Div Data Driven & Digital Med D3M, New York, NY USA; [Klang, Eyal; Sourosh, Ali; Nadkarni, Girish N.] Icahn Sch Med Mt Sinai, Charles Bronfman Inst Personalized Med, New York, NY USA; [Klang, Eyal] Tel Aviv Univ, ARC Innovat Ctr, Sheba Med Ctr Tel Hashomer, Tel Aviv Med Sch, Tel Aviv, Israel; [Sharif, Kassem] Tel Aviv Univ, Sheba Med Ctr Tel Hashomer, Dept Gastroenterol, Tel Aviv Med Sch, Tel Aviv, Israel	Chaim Sheba Medical Center; Tel Aviv University; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Chaim Sheba Medical Center; Tel Aviv University; Tel Aviv University; Chaim Sheba Medical Center	Lahat, A (corresponding author), Sheba Med Ctr Tel Hashomer, Dept Gastroenterol, IL-52621 Ramat Gan, Israel.; Lahat, A (corresponding author), Tel Aviv Univ, Tel Aviv Med Sch, Tel Aviv, Israel.	zokadi@gmail.com						[Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Gorelik Y, 2023, GASTROINTEST ENDOSC, V98, DOI 10.1016/j.gie.2023.06.025; Henson JB, 2023, AM J GASTROENTEROL, V118, P2276, DOI 10.14309/ajg.0000000000002397; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lahat A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231155520; Lee TC., 2023, Gastroenterology, V165; Nashwan AJ, 2023, Gastroenterol. Endosc., P132, DOI [10.1016/j.gande.2023.07.004, DOI 10.1016/J.GANDE.2023.07.004]; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Tustumi F., 2023, Arq Bras Cir Dig, V36	13	2	2	15	15	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1756-283X	1756-2848		THER ADV GASTROENTER	Ther. Adv. Gastroenterol.		2023	16								17562848231218618	10.1177/17562848231218618	http://dx.doi.org/10.1177/17562848231218618			10	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	DD0P7	38149123	Green Published, gold			2024-07-03	WOS:001129979600001
J	Law, L				Law, Locky			Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review	COMPUTERS AND EDUCATION OPEN			English	Review						Generative AI; AI; Language education; Scoping review; Content generation; ChatGPT		This scoping literature review examines the application of Generative Artificial Intelligence (GenAI), a disruptive technology, in language teaching and learning. Since its launch in November 2022, GenAI has captured global attention with OpenAI's ChatGPT, powered by the generative pre-trained transformer-3 (GPT-3) large-language model. The emergence of GenAI holds immense implications across various domains, including language education. This review aims to provide an overview of the current state of research and identify research gaps and future directions in this emerging field. The review follows the PRISMA-ScR guidelines and includes eligible publications published between 2017 and July 2023. Four electronic databases were searched and 41 of the 224 initial papers were eventually selected for review. The findings reveal key terms related to GenAI in language education, the most researched language study and education levels, areas of research, attitudes towards GenAI, and the potential benefits and challenges of GenAI application. The review highlights several research gaps, including the need for more empirical studies to assess the effectiveness and impact of GenAI tools, discussion of ethical considerations, targeted interventions for specific language skills, and stakeholder engagement in responsible integration. Educators are encouraged to incorporate GenAI tools into their teaching practices while remaining vigilant about potential risks. Continuous professional development for educators is crucial to ensure informed decision-making and effective integration of GenAI tools. This scoping review contributes to the existing knowledge on the use of GenAI in language education and informs future research and practice in this disruptive and rapidly evolving field.	[Law, Locky] Univ Hong Kong, Ctr Appl English Studies, Hong Kong, Peoples R China; [Law, Locky] Room 1307,Block P, Hong Kong, Peoples R China	University of Hong Kong	Law, L (corresponding author), Room 1307,Block P, Hong Kong, Peoples R China.	lockylaw@hku.hk		Law, Locky/0000-0003-2234-9337				Agustini N.P.O., 2023, EDUKASIA: J Pendidikan Dan Pembelajaran, V4, P921; Aktay S., 2023, Turk Akademik Yayinlar Dergisi (TAY Journal), V7, P378, DOI [10.29329/tayjournal.2023.543.03, DOI 10.29329/TAYJOURNAL.2023.543.03]; Ali J. K. M., 2023, Journal of English Studies in Arabia Felix, V2, P41, DOI DOI 10.56540/JESAF.V2I1.51; Anthony L., 2023, AntConc (version 4.2.4) computer software; Bonner E., 2023, Teaching English with Technology, V23, P23, DOI [DOI 10.56297/BKAM1691/WIEO1749, 10.56297/BKAM1691/WIEO1749]; Chen XL, 2022, EDUC TECHNOL SOC, V25, P28; Chiu TKF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2253861; Forrester A, 2023, STiLE-Scholarship of teaching in language education; Google, 2023, Google Cloud; Guo K, 2023, COMPUT EDUC, V203, DOI 10.1016/j.compedu.2023.104862; Hong WCH., 2023, Journal of Educational Technology and Innovation, V5, P37, DOI [10.61414/jeti.v5i1.103, DOI 10.61414/JETI.V5I1.103]; Hutson J, 2023, Glob J Comput Sci Technol, V23; Hwang GJ, 2023, EDUC TECHNOL SOC, V26, DOI 10.30191/ETS.202304_26(2).0014; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Jeon J, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2204343; Jourdan L., 2023, arXiv; Klimova B., 2023, The use of persona in foreign language learning facilitated by chatbots; Kohnke L., 2023, Computers and Education Artificial Intelligence, V5, P100156, DOI [10.1016/j.caeai.2023.100156, DOI 10.1016/J.CAEAI.2023.100156]; Kohnke L, 2023, RELC J, V54, P537, DOI 10.1177/00336882231162868; Koraishi O., 2023, Language Education & Technology, V3, P55; Laupichler M C., 2022, Computers and Education: Artificial Intelligence, V3, P1, DOI DOI 10.1016/J.CAEAI.2022.100101; Law L, 2023, STILE-Scholarsh Teach Lang Educ, V1, P9; Lee JH, 2023, RELC J, V54, P508, DOI 10.1177/00336882231165060; Li B, 2023, INT J COMPUT-ASSIST, V13, DOI 10.4018/IJCALLT.326135; Loem M, 2023, Arxiv, DOI arXiv:2305.18156; Mantekilla, 2023, YouTube; Marzuki, 2023, COGENT EDUC, V10, DOI 10.1080/2331186X.2023.2236469; Mizumoto A., 2023, Research Methods in Applied Linguistics, V2, P100050, DOI DOI 10.1016/J.RMAL.2023.100050; Mohamed AM, 2024, EDUC INF TECHNOL, V29, P3195, DOI 10.1007/s10639-023-11917-z; Mohammadkarimi E., 2023, J APPL LEARN TEACH, V6, DOI [10.37074/jalt.2023.6.2.10, DOI 10.37074/JALT.2023.6.2.10]; Munoz S, 2023, Soc Space J, V23; OpenAI, Dalle 2; OpenAI, 2023, GPT-4; OpenAI, 2022, New GPT-3 capabilities: edit & insert; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Rays Pradeep P, 2023, Philos Technol, V36, P40, DOI [10.1007/s13347-023-00643-6, DOI 10.1007/S13347-023-00643-6]; Resemble A.I., 2022, YouTube; Roe J, 2023, Journal of English and Applied Linguistics, V2, P3, DOI 10.59588/2961-3094.1035; Sakai N, 2023, osf.io; Schmidt-Fajlik R, 2023, Asia CALL Online Journal, V14, P105, DOI DOI 10.54855/ACOJ.231417; Selwyn N, 2022, EUR J EDUC, V57, P620, DOI 10.1111/ejed.12532; Siegle D., 2023, Gifted Child Today, V46, P211, DOI DOI 10.1177/10762175231168443; Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745; Topsakal O., 2022, The Journal of Cognitive Systems, V7, P33, DOI DOI 10.52876/JCS.1227392; Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850; Utami SPT, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13419; Vaswani A, 2017, ADV NEUR IN, V30; Vera F, 2023, Transf Electron J, V4; Wharton School, 2023, YouTube; Woo D, 2023, ResearchGate; Woo DJ, 2024, Arxiv, DOI arXiv:2304.02478; Yan D, 2023, EDUC INF TECHNOL, V28, P13943, DOI 10.1007/s10639-023-11742-4; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhai C., 2023, Computers and Education: Artificial Intelligence, DOI [10.1016/j.caeai.2023.100134, DOI 10.1016/J.CAEAI.2023.100134]; Zhang RF, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2220374; Zhou TQ, 2023, Arxiv, DOI [arXiv:2303.11812, 10.48550/arXiv.2303.11812, DOI 10.48550/ARXIV.2303.11812]; Zhu CJ, 2023, KNOWL MANAG E-LEARN, V15, P133, DOI 10.34105/j.kmel.2023.15.008; Zounhin Toboula C.M., 2023, Exploring the impact of AI -Powered collaborative and interactive NLP apps on EFL teaching in the post-Covid-19 era	58	1	1	21	21	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-5573			COMPUT EDUC OPEN	Computer Educ. Open	JUN	2024	6								100174	10.1016/j.caeo.2024.100174	http://dx.doi.org/10.1016/j.caeo.2024.100174			13	Computer Science, Interdisciplinary Applications; Education & Educational Research	Emerging Sources Citation Index (ESCI)	Computer Science; Education & Educational Research	QR4F5		gold			2024-07-03	WOS:001222577400001
J	Dai, Y				Dai, Yun			Dual-contrast pedagogy for AI literacy in upper elementary schools	LEARNING AND INSTRUCTION			English	Article						Artificial intelligence; AI literacy; Pedagogy; Instructional design; Human -AI comparison	DESIGN-BASED RESEARCH; CONCEPTUAL CHANGE; ARTIFICIAL-INTELLIGENCE; COMPUTATIONAL THINKING; COGNITIVE CONFLICT; ANALOGIES; EDUCATION; STRATEGY; ANXIETY; GENDER	Background: Advances in artificial intelligence (AI) have highlighted the need to equip young students with basic AI-related knowledge, skills, values, and attitudes. However, pedagogical design for AI literacy remains a critical challenge, especially for upper elementary students aged 10-12. Aims: This design-based study had two goals: to develop a pedagogical approach for AI literacy in upper elementary education and to empirically assess this approach through an experiment. Sample: One hundred forty-seven sixth graders in an upper elementary school were randomly assigned to a control group (n = 75) and an experimental group (n = 72). Methods: Following a theory-informed design convention, we proposed a dual-contrast pedagogical (DCP) approach. This approach centers on human-AI comparisons by integrating analogies and cognitive conflicts. Two teaching examples on machine learning and large language models were provided. The experimental group was taught with the DCP approach, while the control group received conventional direct instruction. Data drawn from assessment tasks and questionnaires were subjected to two-way analyses of variance and covariance. Results: The experimental group demonstrated significantly higher performance in AI knowledge, skills, and ethical awareness. They also exhibited a significant increase in AI learning confidence and intrinsic motivation and a significant decrease in learning anxiety. Conclusions: The DCP approach significantly improved students' learning performance and attitudes, demonstrating its effectiveness in promoting AI literacy. This study highlights the pedagogical value of human-AI comparisons in teaching AI, while contributing to a research agenda on the cognitive and conceptual aspects of AI education.	[Dai, Yun] Chinese Univ Hong Kong, Dept Curriculum & Instruct, Hong Kong, Peoples R China	Chinese University of Hong Kong	Dai, Y (corresponding author), Chinese Univ Hong Kong, Dept Curriculum & Instruct, Hong Kong, Peoples R China.	yundai@cuhk.edu.hk		Dai, Yun/0000-0002-1199-9855				Agassi A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3312894; Anderson T, 2012, EDUC RESEARCHER, V41, P16, DOI 10.3102/0013189X11428813; [Anonymous], 2007, A collection of definitions of intelligence [Accessed December 1, 2023]; [Anonymous], 1982, Science education, DOI [DOI 10.1002/SCE.3730660207, 10.1002/sce.3730660207]; [Anonymous], 2004, Computer Science Education Research; Baker B, 2023, TEACH COLL REC, V125, P60, DOI 10.1177/01614681231191291; Barab S, 2004, J LEARN SCI, V13, P1, DOI 10.1207/s15327809jls1301_1; Bell T., 2009, NZ J APPL COMPUTING, V123, P20, DOI DOI 10.2307/1386128; Bergdahl J., 2021, 5 AI Misconceptions Debunked: Artificial intelligence can be a very confusing topic; Boden Margaret A., 2004, The creative mind: Myths and mechanisms, DOI DOI 10.4324/9780203508527; Boyle GJ., 2014, Measures of Personality and Social Psychological Constructs; Brette R, 2022, FRONT ECOL EVOL, V10, DOI 10.3389/fevo.2022.878729; Brush T., 2017, Successfully implementing problem-based learning in classrooms: Research in k-12 and teacher education, P79; Burgsteiner H, 2016, AAAI CONF ARTIF INTE, P4126; Caeli EN, 2020, TECHTRENDS, V64, P29, DOI 10.1007/s11528-019-00410-5; Casal-Otero L, 2023, INT J STEM EDUC, V10, DOI 10.1186/s40594-023-00418-7; Chang HY, 2020, STUD SCI EDUC, V56, P77, DOI 10.1080/03057267.2020.1735822; Chi M.T., 2002, RECONSIDERING CONCEP, P3; China M., 2022, Curriculum guidance of information technology education in compulsory education; China M. o. E. o. t. P. s. R. o., 2021, Notice on promoting innovative practices and typical experiences of after-school services in some compulsory education schools; Chuan CH, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P339, DOI 10.1145/3306618.3314285; Churchland P.S., 1992, The Computational Brain; Clement C. J. J., 2013, International handbook of research on conceptual change, P424; Clement JJ, 2002, J LEARN SCI, V11, P389, DOI 10.1207/S15327809JLS1104_1; Coll RK, 2005, INT J SCI EDUC, V27, P183, DOI 10.1080/0950069042000276712; DAGHER ZR, 1994, SCI EDUC, V78, P601, DOI 10.1002/sce.3730780605; Dai Y., 2023, An inclusive education approach to promote AI literacy among cross-border students in Hong Kong; Dai Y, 2024, J EDUC COMPUT RES, V61, P159, DOI 10.1177/07356331231201342; Dai Y, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13371; Dai Y, 2023, J ENG EDUC, V112, P23, DOI 10.1002/jee.20503; Dai Y, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12166597; Daniel S, 2020, EUR J ENG EDUC, V45, P654, DOI 10.1080/03043797.2019.1704689; Darling-Hammond L., 2015, POWERFUL LEARNING WH; DiPaola D., 2021, P 52 ACM TECHN S COM; DiSessa A.A., 2014, HIST CONCEPTUAL CHAN; Dörner D, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01153; DREYFUS A, 1990, SCI EDUC, V74, P555, DOI 10.1002/sce.3730740506; Druga S, 2019, PROCEEDINGS OF 8TH ANNUAL CONFERENCE ON MAKER EDUCATION (FABLEARN 2019), P104, DOI 10.1145/3311890.3311904; Druga S, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P231, DOI 10.1145/3202185.3202741; Duit R, 2001, LEARN INSTR, V11, P283, DOI 10.1016/S0959-4752(00)00034-7; Fagerlund J, 2021, COMPUT APPL ENG EDUC, V29, P12, DOI 10.1002/cae.22255; Fast E, 2017, AAAI CONF ARTIF INTE, P963; Freedman G, 2018, PSYCHOL WOMEN QUART, V42, P178, DOI 10.1177/0361684318754528; Gadanidis G, 2017, INT J INF LEARN TECH, V34, P133, DOI 10.1108/IJILT-09-2016-0048; Gal-Ezer J, 2009, ITICSE 2009: PROCEEDING OF THE 2009 ACM SIGSE ANNUAL CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P278, DOI 10.1145/1595496.1562963; Gentner D, 2003, J EDUC PSYCHOL, V95, P393, DOI 10.1037/0022-0663.95.2.393; Goel A. K., 2011, Cambridge handbook of intelligence, V3rd; Goode J, 2008, SIGCSE'08: PROCEEDINGS OF THE 39TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P362, DOI 10.1145/1352322.1352259; Grover S, 2013, EDUC RESEARCHER, V42, P38, DOI 10.3102/0013189X12463051; Guo S., 2021, Aritificial intellignece: Elementery education; Harrison AG, 2006, SCI TECHNOL EDUC LIB, V30, P11; Hassabis D, 2017, NEURON, V95, P245, DOI 10.1016/j.neuron.2017.06.011; Heinze C, 2010, AAAI CONF ARTIF INTE, P1890; Ho C.-Y., 2019, Talent education for foreign students to learn concepts of artificial intelligence; Horvitz E, 2017, SCIENCE, V357, P7, DOI 10.1126/science.aao2466; Hox J.J., 2017, Multilevel Analysis: Techniques and Applications, DOI DOI 10.4324/9781315650982; Kim K, 2023, EDUC INF TECHNOL, V28, P9827, DOI 10.1007/s10639-023-11600-3; Koc M, 2013, COMPUT EDUC, V68, P1, DOI 10.1016/j.compedu.2013.04.024; Limón M, 2001, LEARN INSTR, V11, P357, DOI 10.1016/S0959-4752(00)00037-2; Lindner A, 2019, LECT NOTES COMPUT SC, V11913, P123, DOI 10.1007/978-3-030-33759-9_10; Long DR, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376727; Marx E., 2023, Computers and Education: Artificial Intelligence; Mertala P., 2022, Computers and Education: Artificial Intelligence, V3, P100095, DOI DOI 10.1016/J.CAEAI.2022.100095; Mislevy R. J., 2006, ED MEASUREMENT ISSUE, V25, P6, DOI DOI 10.1111/J.1745-3992.2006.00075.X; Moreno-Leon J., 2015, SCRATCH C; Newton D.P., 2011, Teaching for understanding: What it is and how to do it; Ng D. T. K., 2022, Computers and Education: Artificial Intelligence, V3, DOI 10.1016/j.caeai.2022.100054; Ng D.T.K., 2021, Computers and Education: Artificial Intelligence, V2, DOI DOI 10.1016/J.CAEAI.2021.100041; Ng DTK, 2023, EDUC INF TECHNOL, V28, P8445, DOI 10.1007/s10639-022-11491-w; Olari V, 2021, AAAI CONF ARTIF INTE, V35, P15630; Ottenbreit-Leftwich A., 2021, P 52 ACM TECHN S COM; Papavlasopoulou S, 2020, COMPUT HUM BEHAV, V105, DOI 10.1016/j.chb.2019.03.003; Park J, 2023, INT J STEM EDUC, V10, DOI 10.1186/s40594-023-00454-3; Peppler K., 2021, 2021 ASEE VIRT ANN C; Pfost M, 2014, REV EDUC RES, V84, P203, DOI 10.3102/0034654313509492; Piaget J., 2013, The construction of reality in the child; Qin J., 2019, Foundation of aritificial intellignece for primary education; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Rea-Ramirez M.A., 1998, SEARCH DISSONANCE EV; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Schwarz CV, 2007, J SCI TEACH EDUC, V18, P243, DOI 10.1007/s10972-007-9039-6; Shamir Gilad, 2022, International Journal of Child-Computer Interaction, DOI 10.1016/j.ijcci.2021.100415; Shin Sein, 2018, [Journal of Korean Elementary Science Education, 초등과학교육], V37, P126, DOI 10.15267/keses.2018.37.2.126; Su J., 2022, Computers and Education: Artificial Intelligence, V3, DOI [DOI 10.1016/J.CAEAI.2022.100065, DOI 10.1016/J.CAEAI.2022.100065GET]; Su JH, 2023, EARLY EDUC DEV, V34, P910, DOI 10.1080/10409289.2022.2078617; Sulmont Elisabeth, 2019, SIGCSE '19: Proceedings of the 50th ACM Technical Symposium on Computer Science Education, P948, DOI 10.1145/3287324.3287392; Sun LH, 2022, COMPUT EDUC, V181, DOI 10.1016/j.compedu.2022.104457; Taber KS, 2018, RES SCI EDUC, V48, P1273, DOI 10.1007/s11165-016-9602-2; Touretzky D, 2019, AAAI CONF ARTIF INTE, P9795; Tsan J., 2022, P 47 ACM TECHN S COM; UNESCO, 2022, K-12 AI curriculum: A mapping of government-endorsed. AI curricula; Vosniadou S, 2007, HUM DEV, V50, P47, DOI 10.1159/000097684; WALBERG HJ, 1983, AM EDUC RES J, V20, P359, DOI 10.3102/00028312020003359; Wang J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P615, DOI 10.1145/3017680.3017734; Wang J, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P47, DOI 10.1145/3105726.3106175; Wang YY, 2022, INTERACT LEARN ENVIR, V30, P619, DOI 10.1080/10494820.2019.1674887; Weintrop D, 2019, COMMUN ACM, V62, P22, DOI 10.1145/3341221; Williams R, 2021, AAAI CONF ARTIF INTE, V35, P15678; Wong G. K. W, 2019, ACM Inroads, V10, P43, DOI [10.1145/3369739, DOI 10.1145/3369739]; Wong G. K. W., 2020, ACM Inroads, V11, P20, DOI DOI 10.1145/3381884; Xia Q, 2022, COMPUT EDUC, V189, DOI 10.1016/j.compedu.2022.104582; Yang Weipeng., 2022, Computers and Education: Artificial Intelligence, V3, P1, DOI [10.1016/j.caeai.2022.100061, DOI 10.1016/J.CAEAI.2022.100061]; Yang X, 2020, ARTIF INTELL REV, V53, P5189, DOI 10.1007/s10462-020-09818-5; You D, 2011, ETHICS BEHAV, V21, P263, DOI 10.1080/10508422.2011.585591; Yue M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142315620; Zhang H, 2023, INT J ARTIF INTELL E, V33, P290, DOI 10.1007/s40593-022-00293-3; Zimmerman M., 2018, Teaching AI: Exploring new frontiers for learning	107	0	0	17	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0959-4752	1873-3263		LEARN INSTR	Learn Instr.	JUN	2024	91								101899	10.1016/j.learninstruc.2024.101899	http://dx.doi.org/10.1016/j.learninstruc.2024.101899		MAR 2024	12	Education & Educational Research; Psychology, Educational	Social Science Citation Index (SSCI)	Education & Educational Research; Psychology	QC4O9					2024-07-03	WOS:001218669700001
C	Bashir, S; Abbas, M; Saadatmand, M; Enoiu, EP; Bohlin, M; Lindberg, P		Ferrari, A; Penzenstadler, B		Bashir, Sarmad; Abbas, Muhammad; Saadatmand, Mehrdad; Enoiu, Eduard Paul; Bohlin, Markus; Lindberg, Pernilla			Requirement or Not, That is the Question: A Case from the Railway Industry	REQUIREMENTS ENGINEERING: FOUNDATION FOR SOFTWARE QUALITY, REFSQ 2023	Lecture Notes in Computer Science		English	Proceedings Paper	29th International Working Conference on Requirements Engineering - Foundation for Software Quality (REFSQ)	APR 17-20, 2023	Barcelona, SPAIN			Requirements identification; Requirements classification; tender documents; NLP		[Context and Motivation] Requirements in tender documents are often mixed with other supporting information. Identifying requirements in large tender documents could aid the bidding process and help estimate the risk associated with the project. [Question/problem] Manual identification of requirements in large documents is a resource-intensive activity that is prone to human error and limits scalability. This study compares various state-of-the-art approaches for requirements identification in an industrial context. For generalizability, we also present an evaluation on a real-world public dataset. [Principal ideas/results] We formulate the requirement identification problem as a binary text classification problem. Various state-of-the-art classifiers based on traditional machine learning, deep learning, and few-shot learning are evaluated for requirements identification based on accuracy, precision, recall, and F1 score. Results from the evaluation show that the transformer-based BERT classifier performs the best, with an average F1 score of 0.82 and 0.87 on industrial and public datasets, respectively. Our results also confirm that few-shot classifiers can achieve comparable results with an average F1 score of 0.76 on significantly lower samples, i.e., only 20% of the data. [Contribution] There is little empirical evidence on the use of large language models and few-shots classifiers for requirements identification. This paper fills this gap by presenting an industrial empirical evaluation of the state-of-the-art approaches for requirements identification in large tender documents. We also provide a running tool and a replication package for further experimentation to support future research in this area.	[Bashir, Sarmad; Abbas, Muhammad; Saadatmand, Mehrdad] RISE Res Inst Sweden, Vasteras, Sweden; [Bashir, Sarmad; Abbas, Muhammad; Enoiu, Eduard Paul; Bohlin, Markus] Malardalen Univ, Vasteras, Sweden; [Lindberg, Pernilla] Alstom, Vasteras, Sweden	RISE Research Institutes of Sweden; Malardalen University; Alstom	Abbas, M (corresponding author), RISE Res Inst Sweden, Vasteras, Sweden.; Abbas, M (corresponding author), Malardalen Univ, Vasteras, Sweden.	sarmad.bashir@ri.se; muhammad.abbas@ri.se; mehrdad.saadatmand@ri.se; eduard.paul.enoiu@mdu.se; markus.bohlin@mdu.se; pernilla.lindberg@alstomgroup.com		Bashir, Sarmad/0009-0006-8512-6412	AIDOaRt (KDT) project; SmartDelta [27] (ITEA) project	AIDOaRt (KDT) project; SmartDelta [27] (ITEA) project	This work is partially funded by the AIDOaRt (KDT) and SmartDelta [27] (ITEA) projects.	Abbas M., 2022, Requir. Eng., V28, P1; Abbas M, 2020, LECT NOTES COMPUT SC, V12541, P173, DOI 10.1007/978-3-030-64694-3_11; Abualhaija S, 2020, EMPIR SOFTW ENG, V25, P5454, DOI 10.1007/s10664-020-09864-1; Abualhaija S, 2019, INT REQUIR ENG CONF, P51, DOI 10.1109/RE.2019.00017; Alhoshan W, 2022, LECT NOTES COMPUT SC, V13216, P52, DOI 10.1007/978-3-030-98464-9_5; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Berry DM, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-09986-0; Binkhonain M., 2019, Expert Systems with Applications: X, V1, p10 0 0 01, DOI DOI 10.1016/J.ESWAX.2019.100001; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Cleland-Huang J, 2018, 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING TECHNOLOGIES RESULTS (ICSE-NIER), P109, DOI 10.1145/3183399.3183408; Dell'Anna D, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-022-10243-1; Eckhardt J, 2016, PROC INT CONF SOFTW, P832, DOI 10.1145/2884781.2884788; Falkner A, 2019, LECT NOTES COMPUT SC, V11412, P176, DOI 10.1007/978-3-030-15538-4_13; Ferrari A, 2017, IEEE SOFTWARE, V34, P28, DOI 10.1109/MS.2017.4121207; Herwanto GB, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P406, DOI 10.1109/REW53955.2021.00072; Hey T, 2020, INT REQUIR ENG CONF, P169, DOI 10.1109/RE48521.2020.00028; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Huang ZH, 2015, Arxiv, DOI [arXiv:1508.01991, DOI 10.48550/ARXIV.1508.01991]; Hubert M., 2010, International Encyclopedia of Statistical Science; Jindal R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2027, DOI 10.1109/ICACCI.2016.7732349; Kingma D. P., 2017, ARXIV; Koch G., 2015, ICML Deep Learning Workshop, VVolume 2, DOI DOI 10.1007/S11263-015-0816-Y; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8; Saadatmand M, 2022, EUROMICRO CONF PROC, P754, DOI 10.1109/DSD57027.2022.00106; Sainani A, 2020, INT REQUIR ENG CONF, P147, DOI 10.1109/RE48521.2020.00026; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Tunstall L, 2022, Arxiv, DOI [arXiv:2209.11055, 10.48550/arXiv.2209.11055, DOI 10.48550/ARXIV.2209.11055]; Varenov V, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P444, DOI [10.1109/REW53955.2021.00081, 10.1109/REW53955.2021.9714713]; Vaswani A., 2017, P 31 INT C NEUR INF, V30, P1, DOI DOI 10.5555/3295222.3295349; Wang W., 2020, P 34 INT C NEURAL IN, V33, P5776; Winkler J, 2016, 2016 IEEE 24TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P39, DOI [10.1109/REW.2016.021, 10.1109/REW.2016.16]; Winkler JP, 2019, INT REQUIR ENG CONF, P40, DOI 10.1109/RE.2019.00016; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Zhang TY, 2021, Arxiv, DOI arXiv:2006.05987; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689	39	2	2	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-29785-4; 978-3-031-29786-1	LECT NOTES COMPUT SC			2023	13975						105	121		10.1007/978-3-031-29786-1_8	http://dx.doi.org/10.1007/978-3-031-29786-1_8			17	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9BX					2024-07-03	WOS:001210623500008
J	Levin, C; Kagan, T; Rosen, S; Saban, M				Levin, Chedva; Kagan, Tehilla; Rosen, Shani; Saban, Mor			An evaluation of the capabilities of language models and nurses in providing neonatal clinical decision support	INTERNATIONAL JOURNAL OF NURSING STUDIES			English	Article						Artificial Intelligence; ChatGPT; Claude; Clinical reasoning; Neonatal care		Aim: To assess the clinical reasoning capabilities of two large language models, ChatGPT-4 and Claude -2.0, compared to those of neonatal nurses during neonatal care scenarios. Design: A cross-sectional study with a comparative evaluation using a survey instrument that included six neonatal intensive care unit clinical scenarios. Participants: 32 neonatal intensive care nurses with 5 -10 years of experience working in the neonatal intensive care units of three medical centers. Methods: Participants responded to 6 written clinical scenarios. Simultaneously, we asked ChatGPT-4 and Claude -2.0 to provide initial assessments and treatment recommendations for the same scenarios. The responses from ChatGPT-4 and Claude -2.0 were then scored by certified neonatal nurse practitioners for accuracy, completeness, and response time. Results: Both models demonstrated capabilities in clinical reasoning for neonatal care, with Claude -2.0 significantly outperforming ChatGPT-4 in clinical accuracy and speed. However, limitations were identified across the cases in diagnostic precision, treatment specificity, and response lag. Conclusions: While showing promise, current limitations reinforce the need for deep refinement before ChatGPT-4 and Claude -2.0 can be considered for integration into clinical practice. Additional validation of these tools is important to safely leverage this Artificial Intelligence technology for enhancing clinical decision -making. Impact: The study provides an understanding of the reasoning accuracy of new Artificial Intelligence models in neonatal clinical care. The current accuracy gaps of ChatGPT-4 and Claude -2.0 need to be addressed prior to clinical usage. (c) 2024 Elsevier Ltd. All rights reserved.	[Levin, Chedva] Lev Acad Ctr, Jerusalem Coll Technol, Fac Sch Life & Hlth Sci, Nursing Dept, Jerusalem, Israel; [Levin, Chedva] Chaim Sheba Med Ctr, Dept Vasc Surg, Tel Aviv, Israel; [Kagan, Tehilla] Shaare Zedek Med Ctr, Jerusalem, Israel; [Rosen, Shani; Saban, Mor] Tel Aviv Univ, Fac Med & Hlth Sci, Sch Hlth Profess, Dept Nursing, Tel Aviv, Israel; [Saban, Mor] Tel Aviv Univ, Fac Med, Sch Hlth Sci, Tel Aviv, Israel	Chaim Sheba Medical Center; Hebrew University of Jerusalem; Shaare Zedek Medical Center; Tel Aviv University; Tel Aviv University	Saban, M (corresponding author), Tel Aviv Univ, Fac Med, Sch Hlth Sci, Tel Aviv, Israel.	morsaban1@tauex.tau.ac.il	Saban, Mor/ABE-8773-2021	Saban, Mor/0000-0001-6869-0907				Almudeer A, 2023, J CLIN NEONATOL, V12, P130, DOI 10.4103/jcn.jcn_19_23; AlShatarat M, 2022, SAGE OPEN NURS, V8, DOI 10.1177/23779608221130588; Aydin O., 2022, Emerging Computer Technologies, V2, P22, DOI DOI 10.2139/SSRN.4308687; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Borji A., 2023, SSRN Electron. J., DOI [10.2139/SSRN.4476855, DOI 10.2139/SSRN.4476855]; Brydges CR, 2019, INNOV AGING, V3, DOI 10.1093/geroni/igz036; Campbell S, 2020, J RES NURS, V25, P652, DOI 10.1177/1744987120927206; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Fu Y., 2023, Chain of thought Hub: A Continuous Effort to Measure Large Language Models' Reasoning Performance; Garg RK, 2023, HEALTH PROMOT PERSPE, V13, P183, DOI 10.34172/hpp.2023.22; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Genna C, 2023, EUR J PEDIATR, V182, P1755, DOI 10.1007/s00431-022-04803-2; Griffiths P, 2018, J ADV NURS, V74, P1474, DOI 10.1111/jan.13564; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Hoffman D.A., 2023, SSRN Electron. J., DOI [10.2139/SSRN.4526219, DOI 10.2139/SSRN.4526219]; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kao HJ, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000034068; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Mallio CA, 2023, RADIOL MED, V128, P808, DOI 10.1007/s11547-023-01651-4; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; Ray TR, 2024, J NEUROINTERV SURG, V16, DOI 10.1136/jnis-2023-020353; Saban M, 2024, J ADV NURS, DOI 10.1111/jan.16101; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420; Suhag A, 2023, AM J OBST GYNEC MFM, V5, DOI 10.1016/j.ajogmf.2023.101029; Sutriningsih A, 2020, J PUBLIC HEALTH RES, V9, P85, DOI 10.4081/jphr.2020.1808; Tan K, 2005, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD004211.pub2; Tredinnick L., 2023, Black box Creativity and Generative Artifical Intelligence, DOI [10.1177/02663821231195131, DOI 10.1177/02663821231195131]; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wu S., 2023, GPT 4 and Claude 2: Multiple choice Test Taking in Nephrology	32	0	0	5	5	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0020-7489	1873-491X		INT J NURS STUD	Int. J. Nurs. Stud.	JUL	2024	155								104771	10.1016/j.ijnurstu.2024.104771	http://dx.doi.org/10.1016/j.ijnurstu.2024.104771			7	Nursing	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Nursing	SO1S5	38688103				2024-07-03	WOS:001235307300001
J	Gengatharan, D; Saggi, SS; Razak, HRB				Gengatharan, Dhivakaran; Saggi, Sandip Singh; Razak, Hamid Rahmatullah Bin Abd			Pre-operative Planning of High Tibial Osteotomy With ChatGPT: Are We There Yet?	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						joint-preserving surgery; high tibial osteotomy; orthopedics; pre-operative planning; chatgpt	IN-VIVO; JOINT	Introduction: ChatGPT (Chat Generative Pre-trained Transformer), developed by OpenAI (San Francisco, CA, USA), has gained attention in the medical field. It has the potential to enhance and simplify tasks, such as preoperative planning in orthopedic surgery. We aimed to test ChatGPT's accuracy in measuring the angle of correction for high tibial osteotomy for cases planned and performed at a tertiary teaching hospital in Singapore. Materials and methods: Peri -operative angular parameters from 114 consecutive patients who underwent medial opening wedge high tibial osteotomy (MOWHTO) were used to query ChatGPT 3.0. First ChatGPT 3.0 was queried on what information it required to plan a MOWHTO. Based on its response, pre -operative medial proximal tibial angle (MPTA) and joint line congruence angle (JLCA) were provided. ChatGPT 3.0 then responded with its recommended angle of correction. This was compared against the manually planned surgical correction by our fellowship-trained surgeon. A root mean square analysis was then performed to compare ChatGPT 3.0 and manual planning. Results: The root mean square error (RMSE) of ChatGPT 3.0 in predicting correction angle in MWHTO was 2.96, suggesting a very poor model fit. Conclusion: Although ChatGPT 3.0 represents a significant breakthrough in large language models with extensive capabilities, it is not currently optimized to effectively perform complex pre -operative planning in orthopedic surgery, specifically in the context of MOWHTO. Further refinement and consideration of specific factors are necessary to enhance its accuracy and suitability for such applications.	[Gengatharan, Dhivakaran; Saggi, Sandip Singh; Razak, Hamid Rahmatullah Bin Abd] Sengkang Gen Hosp, Orthopaed Surg, Singapore, Singapore; [Razak, Hamid Rahmatullah Bin Abd] Duke Nus Med Sch, Musculoskeletal Sci, Singapore, Singapore	National University of Singapore	Gengatharan, D (corresponding author), Sengkang Gen Hosp, Orthopaed Surg, Singapore, Singapore.	dhiva09@gmail.com						Abd-Alrazaq A, 2020, J MED INTERNET RES, V22, DOI 10.2196/18301; [Anonymous], 2023, As ChatGPT's popularity explodes, U.S. lawmakers take an interest; Bejnordi BE, 2017, JAMA-J AM MED ASSOC, V318, P2199, DOI 10.1001/jama.2017.14585; Capella M, 2017, ANN JOINT, V2, DOI 10.21037/aoj.2017.06.06; Chen ZX, 2014, P I MECH ENG H, V228, P564, DOI 10.1177/0954411914537476; COVENTRY MB, 1993, J BONE JOINT SURG AM, V75A, P196, DOI 10.2106/00004623-199302000-00006; Fraysse F, 2016, J BIOMECH, V49, P3538, DOI 10.1016/j.jbiomech.2016.08.005; Ghasemi S Ali, 2023, J Clin Orthop Trauma, V36, P102085, DOI 10.1016/j.jcot.2022.102085; JACKSON JP, 1961, J BONE JOINT SURG BR, V43, P746, DOI 10.1302/0301-620X.43B4.746; Kutzner I, 2010, J BIOMECH, V43, P2164, DOI 10.1016/j.jbiomech.2010.03.046; Lee Dong Chul, 2012, Knee Surg Relat Res, V24, P61, DOI 10.5792/ksrr.2012.24.2.61; Micicoi G, 2021, Video J Sports Med., V1, DOI [10.1177/26350254211032968, DOI 10.1177/26350254211032968]; Mina C, 2008, AM J SPORT MED, V36, P949, DOI 10.1177/0363546508315471; Seth I, 2023, J Clin Cases Rep., V13, P6, DOI [10.46619/joccr.2023.6-S13.1075, DOI 10.46619/JOCCR.2023.6-S13.1075]; Spahn G, 2006, OSTEOARTHR CARTILAGE, V14, P190, DOI 10.1016/j.joca.2005.08.013; Spahn Gunter, 2004, Arch Orthop Trauma Surg, V124, P649, DOI 10.1007/s00402-003-0588-7; YASUDA K, 1992, CLIN ORTHOP RELAT R, P186	17	1	1	2	2	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	FEB 25	2024	16	2							e54858	10.7759/cureus.54858	http://dx.doi.org/10.7759/cureus.54858			10	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	NK4Z4	38533173	Green Published, gold			2024-07-03	WOS:001200347500007
J	Jeong, Y; Song, JJ; Yang, J; Kang, S				Jeong, Yongwoo; Song, Jae-Jun; Yang, Jiseon; Kang, Sungmin			Advancing Tinnitus Therapeutics: GPT-2 Driven Clustering Analysis of Cognitive Behavioral Therapy Sessions and Google T5-Based Predictive Modeling for THI Score Assessment	IEEE ACCESS			English	Article						Augmentation; cognitive; CBT; GPT-2; Google; tinnitus; T5; RMSE; ROUGE-L		Cognitive Behavioral Therapy (CBT) for tinnitus alleviates psychological discomfort caused by severe tinnitus symptoms. During CBT, the patients will have various homework assignments, including writing daily diaries and self-monitoring. Most of these homework assignments are hand-written, textual data. This paper proposes that tinnitus therapeutics can utilize Large Language Models (LLMs) to analyze CBT and predict the outcomes of CBT treatments to manage high caseloads. We anonymized patient data and examined it with GPT-2-based-embedding, dimensionality reduction, and clustering process to observe how patients themselves changed their misconceptions and developed less unnecessary excessive emotional discomfort and how their Tinnitus Handicap Inventory (THI) scores were improved after the CBT treatment. We also discussed clustering results as a part of the demonstrations that LLMs can give us insights into the CBT. Then, we augmented textual patient data in three ways to minimize augmentation bias with a corresponding penalty to overcome the constraints of limitation of the number of datasets. We trained the Google T5 Transformer with the augmented data to predict the THI score outcomes at the end of the CBT sessions. We measured the performance using the ROUGE-L metric during the training and validation. The generated THI scores by Google T5 were converted from strings to floats to measure RMSE performance, which proved that the LLM could predict the outcome of CBT treatment with CBT data. Even though there is a risk of overfitting issues, this work demonstrated that tinnitus therapeutics experts can employ LLMs to manage caseloads.	[Jeong, Yongwoo; Yang, Jiseon; Kang, Sungmin] Rowan Inc, Seoul 03145, South Korea; [Song, Jae-Jun] Neurive Co Ltd, Gimhae Si 50969, South Korea; [Song, Jae-Jun] Korea Univ, Dept Otorhinolaryngol Head & Neck Surg, Med Ctr, Seoul 02841, South Korea	Korea University; Korea University Medicine (KU Medicine)	Jeong, Y (corresponding author), Rowan Inc, Seoul 03145, South Korea.; Song, JJ (corresponding author), Neurive Co Ltd, Gimhae Si 50969, South Korea.; Song, JJ (corresponding author), Korea Univ, Dept Otorhinolaryngol Head & Neck Surg, Med Ctr, Seoul 02841, South Korea.	oscar.eaglewatch@gmail.com; jjsong23@gmail.com		Jeong, Yongwoo/0009-0006-5746-6380	Technology Innovation Program (Development of tinnitus treatment platform based on non-invasive vagus nerve stimulation and cognitive behavioral therapy to solve medical unmet needs) funded by the Ministry of Trade, Industry and Energy (MOTIE), South Korea	Technology Innovation Program (Development of tinnitus treatment platform based on non-invasive vagus nerve stimulation and cognitive behavioral therapy to solve medical unmet needs) funded by the Ministry of Trade, Industry and Energy (MOTIE), South Korea	No Statement Available	Allgaier J, 2021, IEEE ENG MED BIO, P816, DOI 10.1109/EMBC46164.2021.9629964; Baguley D, 2013, LANCET, V382, P1600, DOI 10.1016/S0140-6736(13)60142-7; BECK A T, 1976, P356; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doborjeh M, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020902; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Fuller T, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD012614.pub2; Gujjar J.P, 2023, 6 INT C INFSYST COMP, P1, DOI [10.1109/ISCON57294.2023.10112058, DOI 10.1109/ISCON57294.2023.10112058]; Gunning Robert., 1952, TECHNIQUE CLEAR WRIT; Hesser H, 2011, CLIN PSYCHOL REV, V31, P545, DOI 10.1016/j.cpr.2010.12.006; Hintze JL, 1998, AM STAT, V52, P181, DOI 10.2307/2685478; Hou RR, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3422, DOI 10.1109/WCICA.2012.6359039; Johnson D.A., 2007, Applied Multivariate Statistical Analy-sis, V6; Jones E, 2014, SCIPY OPEN SOURCE SC; Ju HT, 2023, Arxiv, DOI arXiv:2206.02659; Kincaid R. P., NavalTech; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Lake BM, 2023, NATURE, V623, P115, DOI 10.1038/s41586-023-06668-3; Lample G, 2019, Arxiv, DOI arXiv:1901.07291; Landry EC, 2020, OTOL NEUROTOL, V41, P153, DOI 10.1097/MAO.0000000000002472; Lewis R, 2007, J HEURISTICS, V13, P387, DOI 10.1007/s10732-007-9012-8; Li J, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01946-y; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin CT, 2023, J NEURAL ENG, V20, DOI 10.1088/1741-2552/acab33; Liu S., 2023, J. Otolaryngol.-HeadNeck Surg., V52, DOI [10.1186/s40463-023-00631-y.[27]Y., DOI 10.1186/S40463-023-00631-Y.[27]Y]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Manta O, 2023, J CLIN MED, V12, DOI 10.3390/jcm12113843; Niu YL, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000036199; NumPy, NumPy: A Fundamental Package for Scientific Computing WithPython; Qian HJ, 2022, PROC INT CONF DATA, P2762, DOI 10.1109/ICDE53745.2022.00252; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Rapids.ai, Open GPU Data Science; Rebuffi SA, 2021, Arxiv, DOI arXiv:2111.05328; Rodrigo H, 2022, AM J AUDIOL, V31, P1167, DOI 10.1044/2022_AJA-21-00270; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Smith B. V. K., 2011, INT C INF VISUALIZAT, P229; Smith E.A, Tech. Rep., AMRL-TR-66-220,; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Wang S., 2005, Mathematica J., V9, P768; WANG SJ, 1995, ANN I STAT MATH, V47, P65, DOI 10.1007/BF00773412; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Yu SJ, 2019, IEEE ACCESS, V7, P185476, DOI 10.1109/ACCESS.2019.2960263; Zhang JQ, 2020, Arxiv, DOI arXiv:1912.08777; Zhuang FZ, 2020, Arxiv, DOI [arXiv:1911.02685, DOI 10.1109/JPROC.2020.3004555]	51	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						52414	52427		10.1109/ACCESS.2024.3383020	http://dx.doi.org/10.1109/ACCESS.2024.3383020			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	OC0O5		gold			2024-07-03	WOS:001204945600001
J	Tian, C; Yin, WP; Li, D; Moens, MF				Tian, Chang; Yin, Wenpeng; Li, Dan; Moens, Marie-Francine			Fighting Against the Repetitive Training and Sample Dependency Problem in Few-Shot Named Entity Recognition	IEEE ACCESS			English	Article						Detectors; Training; Internet; Encyclopedias; Online services; Task analysis; Adaptation models; Artificial intelligence; Data mining; Feature extraction; Few-shot learning; Natural language processing; Text analysis; data mining; feature extraction; few-shot learning; named entity recognition; natural language processing; text analysis	ALGORITHM	Few-shot named entity recognition (NER) systems recognize entities using a few labeled training examples. The general pipeline consists of a span detector to identify entity spans in text and an entity-type classifier to assign types to entities. Current span detectors rely on extensive manual labeling to guide training. Almost every span detector requires initial training on basic span features followed by adaptation to task-specific features. This process leads to repetitive training of the basic span features among span detectors. Additionally, metric-based entity-type classifiers, such as prototypical networks, typically employ a specific metric that gauges the distance between the query sample and entity-type referents, ultimately assigning the most probable entity type to the query sample. However, these classifiers encounter the sample dependency problem, primarily stemming from the limited samples available for each entity-type referent. To address these challenges, we proposed an improved few-shot NER pipeline. First, we introduce a steppingstone span detector that is pre-trained on open-domain Wikipedia data. It can be used to initialize the pipeline span detector to reduce the repetitive training of basic features. Second, we leverage a large language model (LLM) to set reliable entity-type referents, eliminating reliance on few-shot samples of each type. Our model exhibits superior performance with fewer training steps and human-labeled data compared with baselines, as demonstrated through extensive experiments on various datasets. Particularly in fine-grained few-shot NER settings, our model outperforms strong baselines, including ChatGPT. We will publicly release the code, datasets, LLM outputs, and model checkpoints.	[Tian, Chang; Moens, Marie-Francine] Katholieke Univ Leuven, Dept Comp Sci, LIIR, B-3000 Leuven, Belgium; [Yin, Wenpeng] Penn State Univ, AI4Res Lab, State Coll, PA 16801 USA; [Li, Dan] Elsevier, NL-1043 NX Amsterdam, Netherlands	KU Leuven; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University	Tian, C (corresponding author), Katholieke Univ Leuven, Dept Comp Sci, LIIR, B-3000 Leuven, Belgium.	chang.tian@kuleuven.be			China Scholarship Council	China Scholarship Council(China Scholarship Council)	No Statement Available	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai C., 2023, FIND ASS COMP LING E, P2969; Christensen W, 2013, PHENOMENOL COGN SCI, V12, P907, DOI 10.1007/s11097-012-9292-9; Correia FA, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102794; Cuiy LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1835; Cunha LFD, 2022, MACH LEARN KNOW EXTR, V4, P42, DOI 10.3390/make4010003; Das SSS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6338; de Lichy C, 2021, 1ST WORKSHOP ON META LEARNING AND ITS APPLICATIONS TO NATURAL LANGUAGE PROCESSING (METANLP 2021), P44; Derczynski L., 2017, PROC 3 WORKSHOP NOIS, P140, DOI [10.18653/v1/W17-4418,eprint:https://aclanthology.org/W17-4418.pdf, 10.18653/v1/w17-4418]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding N., 2022, PROC C EMPIRICAL MET, P6888; Ding N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3198; Ehrmann M, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3604931; Fang JY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4261; Feng JZ, 2024, INFORM PROCESS MANAG, V61, DOI 10.1016/j.ipm.2023.103557; Finn C, 2017, PR MACH LEARN RES, V70; Fritzler A, 2019, SAC '19: PROCEEDINGS OF THE 34TH ACM/SIGAPP SYMPOSIUM ON APPLIED COMPUTING, P993, DOI 10.1145/3297280.3297378; He K, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3314807; Hon YT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1381; Huang JX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10408; Huang Y, 2022, P 29 INT C COMP LING, P2515; Ilya L., 2018, PROC INT C LEARN REP; Ji B., 2022, PROC 29 INT C COMPUT, P1842; Li J, 2022, IEEE T KNOWL DATA EN, V34, P4245, DOI 10.1109/TKDE.2020.3038670; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Li Y, 2023, FUEL, V351, DOI 10.1016/j.fuel.2023.128911; Liu CG, 2021, IEEE ACCESS, V9, P126728, DOI 10.1109/ACCESS.2021.3109911; Liu Y., 2022, P FIND ASS COMP LING, P1822, DOI 10.18653/v1/2022.findings-naacl.139; LOU HL, 1995, IEEE SIGNAL PROC MAG, V12, P42, DOI 10.1109/79.410439; Ma R., 2023, FINDINGS 61TH ANN M, P4115; Ma RT, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5721; Ma TT, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1584; Ma ZC, 2018, NEUROCOMPUTING, V275, P1121, DOI 10.1016/j.neucom.2017.09.057; Nasar Z, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3445965; Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161; Pradhan Sameer, 2017, Handbook of Linguistic Annotation, P521; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sang EF, 2003, P 7 C NATURAL LANGUA, P142, DOI DOI 10.3115/1119176.1119195; Sheng Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P734, DOI 10.1145/3219819.3219901; Triantafillou E, 2019, PROC INT C LEARN REP; Vinyals O, 2016, 30 C NEURAL INFORM P, V29; Wang JH, 2020, IEEE INT CONF ELECTR, P178, DOI 10.1109/iceiec49280.2020.9152261; Wang PY, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5012; Wang Z., 2023, PROC FINDINGS ASS CO, P2228; Wu QH, 2020, AAAI CONF ARTIF INTE, V34, P9274; Yang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6365; Yang Z., 2023, PROC FINDINGS ASS CO, P15635; Zeldes A, 2017, LANG RESOUR EVAL, V51, P581, DOI 10.1007/s10579-016-9343-x; Zhang J., 2023, P AAAI C ARTIFICIAL, P3940; Zhang S., 2023, PROC FINDINGS ASS CO, P3280; Zhao ZY, 2023, IEEE ACCESS, V11, P99101, DOI 10.1109/ACCESS.2023.3313608	51	0	0	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						37600	37614		10.1109/ACCESS.2024.3374727	http://dx.doi.org/10.1109/ACCESS.2024.3374727			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	LE2H1		gold			2024-07-03	WOS:001185033000001
J	Kim, K; Park, EJ; Shin, JH; Kwon, OW; Kim, YK				Kim, Kangil; Park, Eun-Jin; Shin, Jong-Hun; Kwon, Oh-Woog; Kim, Young-Kil			Divergence-based fine pruning of phrase-based statistical translation model	COMPUTER SPEECH AND LANGUAGE			English	Article						Statistical machine translation; Model revision; Phrase table; Entropy-based pruning; Relative entropy		A widely used automatic translation approach, phrase-based statistical machine translation, learns a probabilistic translation model composed of phrases from a large parallel corpus with a large language model. The translation model is often enormous because of many combinations of source and target phrases, which leads to the restriction of applications to limited computing environments. Entropy-based pruning resolves this issue by reducing the model size while retaining the translation quality. To safely reduce the size, this method detects redundant components by evaluating a relative entropy of models before and after pruning the components. In the literature, this method is effective, but we have observed that it can be improved more by adjusting the divergence distribution determined by the relative entropy. In the results of preliminary experiments, we derive two factors responsible for limiting pruning efficiency of entropy-based pruning. The first factor is proportion of pairs composing translation models with respect to their translation probability and its estimate. The second factor is the exponential increase of the divergence for pairs with low translation probability and estimate. To control the factors, we propose a divergence-based fine pruning using a divergence metric to adapt the curvature change of the boundary conditions for pruning and Laplace smoothing. In practical translation tasks for English-Spanish and English-French language pairs, this method shows statistically significant improvement on the efficiency up to 50% and average 12% more pruning compared to entropy-based pruning to show the same translation quality. (C) 2016 Elsevier Ltd. All rights reserved.	[Kim, Kangil] Konkuk Univ, 120 Neungdong Ro, Seoul 05029, South Korea; [Park, Eun-Jin; Shin, Jong-Hun; Kwon, Oh-Woog; Kim, Young-Kil] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon 34129, South Korea	Konkuk University; Electronics & Telecommunications Research Institute - Korea (ETRI)	Kim, K (corresponding author), Konkuk Univ, 120 Neungdong Ro, Seoul 05029, South Korea.	kangil.kim.01@gmail.com			ICT R&D program of MSIP/IITP [10041807]	ICT R&D program of MSIP/IITP(Institute for Information & Communication Technology Planning & Evaluation (IITP), Republic of Korea)	This work was supported by the ICT R&D program of MSIP/IITP. [10041807, Development of Original Software Technology for Automatic Speech Translation with Performance 90% for Tour/International Event Focused on Multilingual Expansibility and Based on Knowledge Learning].	[Anonymous], IWSLT; [Anonymous], MT SUMMIT; [Anonymous], P JOINT C EMP METH N; [Anonymous], P MT SUMM 11; [Anonymous], P 2012 JOINT C EMP M; [Anonymous], P 2003 C N AM CHAPT; [Anonymous], P 40 ANN M ASS COMP; [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071; [Anonymous], P 10 C ASS MACH TRAN; [Anonymous], P DARPA BROADC NEWS; [Anonymous], 1994, MACHINE TRANSLATION; [Anonymous], P INT C AC SPEECH SI, DOI DOI 10.1109/ICASSP.1995.479394; [Anonymous], HLT NAACL; Brown P. F., 1993, Computational Linguistics, V19, P263; Chiang David, 2005, 43rd Annual Meeting on Association for Computational Linguistics, P263; Cover T. M., 2012, ELEMENTS INFORM THEO; Doddington G., 2002, P 22 INT C HUM LANG, P138; Foster G., 2006, P 2006 C EMP METH NA, P53; Heafield K., 2011, P 6 WORKSHOP STAT MA, P187; Koehn P, 2004, LECT NOTES COMPUT SC, V3265, P115; Koehn P, 2007, P 45 ANN M ACL INTER, P177, DOI [10.3115/1557769.1557821, DOI 10.3115/1557769.1557821]; Koehn P, 2009, Statistical machine translation, DOI DOI 10.1017/CBO9780511815829; KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694; Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586; Och C., 1999, 1999 JOINT SIGDAT C; Och FJ, 2003, COMPUT LINGUIST, V29, pc, DOI 10.1162/089120103321337421; Park EJ, 2015, ETRI J, V37, P541, DOI 10.4218/etrij.15.0114.1017; Vogel S., 1996, P 16 C COMP LING ASS, V2, P836, DOI [DOI 10.3115/993268.993313, 10.3115/993268.993313]; Zens R, 2002, LECT NOTES ARTIF INT, V2479, P18; Zens Richard., 2012, Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, P972	30	3	3	0	26	ACADEMIC PRESS LTD- ELSEVIER SCIENCE LTD	LONDON	24-28 OVAL RD, LONDON NW1 7DX, ENGLAND	0885-2308	1095-8363		COMPUT SPEECH LANG	Comput. Speech Lang.	JAN	2017	41						146	160		10.1016/j.csl.2016.06.006	http://dx.doi.org/10.1016/j.csl.2016.06.006			15	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	DY1OI					2024-07-03	WOS:000384863900008
J	Sahin, B; Genç, YE; Dogan, K; Sener, TE; Sekerci, CA; Tanidir, Y; Yücel, S; Tarcan, T; Çam, HK				Sahin, Bahadir; Genc, Yunus Emre; Dogan, Kader; Sener, Tarik Emre; Sekerci, cagri Akin; Tanidir, Yiloren; Yucel, Selcuk; Tarcan, Tufan; Cam, Haydar Kamil			Evaluating the Performance of ChatGPT in Urology: A Comparative Study of Knowledge Interpretation and Patient Guidance	JOURNAL OF ENDOUROLOGY			English	Article; Early Access						artificial intelligence; ChatGPT; machine-learning; debate; deep-learning		Background/Aim: To evaluate the performance of Chat Generative Pre-trained Transformer (ChatGPT), a large language model trained by Open artificial intelligence.Materials and Methods: This study has three main steps to evaluate the effectiveness of ChatGPT in the urologic field. The first step involved 35 questions from our institution's experts, who have at least 10 years of experience in their fields. The responses of ChatGPT versions were qualitatively compared with the responses of urology residents to the same questions. The second step assesses the reliability of ChatGPT versions in answering current debate topics. The third step was to assess the reliability of ChatGPT versions in providing medical recommendations and directives to patients' commonly asked questions during the outpatient and inpatient clinic.Results: In the first step, version 4 provided correct answers to 25 questions out of 35 while version 3.5 provided only 19 (71.4% vs 54%). It was observed that residents in their last year of education in our clinic also provided a mean of 25 correct answers, and 4th year residents provided a mean of 19.3 correct responses. The second step involved evaluating the response of both versions to debate situations in urology, and it was found that both versions provided variable and inappropriate results. In the last step, both versions had a similar success rate in providing recommendations and guidance to patients based on expert ratings.Conclusion: The difference between the two versions of the 35 questions in the first step of the study was thought to be due to the improvement of ChatGPT's literature and data synthesis abilities. It may be a logical approach to use ChatGPT versions to inform the nonhealth care providers' questions with quick and safe answers but should not be used to as a diagnostic tool or make a choice among different treatment modalities.	[Sahin, Bahadir; Genc, Yunus Emre; Dogan, Kader; Sener, Tarik Emre; Sekerci, cagri Akin; Tanidir, Yiloren; Yucel, Selcuk; Tarcan, Tufan; Cam, Haydar Kamil] Marmara Univ, Sch Med, Dept Urol, Istanbul, Turkiye	Marmara University	Genç, YE (corresponding author), Marmara Univ, Sch Med, Pendik Res & Training Hosp, Dept Urol, TR-34890 Istanbul, Turkiye.			Tanidir, Yiloren/0000-0003-1607-5819; Genc, Yunus emre/0000-0001-8335-1292				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], GPT-4; Bibault JE, 2019, J MED INTERNET RES, V21, DOI 10.2196/15787; Earnshaw Charles H, 2020, Future Healthc J, V7, P149, DOI 10.7861/fhj.2019-0046; Harris PA, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103208; Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Rahimi F, 2023, ARCH MED RES, V54, P272, DOI 10.1016/j.arcmed.2023.03.004; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Why ChatGPT Should Not Be Used to Write Academic Scientific Manuscripts for Publication, 2023, Ann Fam Med, V21, P2958, DOI [10.1370/afm.2982, DOI 10.1370/AFM.2982]; Zhou ZH, 2023, EUR UROL, V84, P355, DOI 10.1016/j.eururo.2023.03.037	13	1	1	0	0	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	0892-7790	1557-900X		J ENDOUROL	J. Endourol.	2024 MAY 30	2024										10.1089/end.2023.0413	http://dx.doi.org/10.1089/end.2023.0413		MAY 2024	10	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	SN2J6	38815140				2024-07-03	WOS:001235063000004
J	Malgaroli, M; Hull, TD; Zech, JM; Althoff, T				Malgaroli, Matteo; Hull, Thomas D.; Zech, James M.; Althoff, Tim			Natural language processing for mental health interventions: a systematic review and research framework	TRANSLATIONAL PSYCHIATRY			English	Review							COMPUTERIZED TEXT ANALYSIS; TOPIC MODELS; THERAPY; ANXIETY; CARE; DEPRESSION; EMOTION; ACCESS; COUNTRIES; ALLIANCE	Neuropsychiatric disorders pose a high societal cost, but their treatment is hindered by lack of objective outcomes and fidelity metrics. AI technologies and specifically Natural Language Processing (NLP) have emerged as tools to study mental health interventions (MHI) at the level of their constituent conversations. However, NLP's potential to address clinical and research challenges remains unclear. We therefore conducted a pre-registered systematic review of NLP-MHI studies using PRISMA guidelines (osf.io/s52jh) to evaluate their models, clinical applications, and to identify biases and gaps. Candidate studies (n = 19,756), including peer-reviewed AI conference manuscripts, were collected up to January 2023 through PubMed, PsycINFO, Scopus, Google Scholar, and ArXiv. A total of 102 articles were included to investigate their computational characteristics (NLP algorithms, audio features, machine learning pipelines, outcome metrics), clinical characteristics (clinical ground truths, study samples, clinical focus), and limitations. Results indicate a rapid growth of NLP MHI studies since 2019, characterized by increased sample sizes and use of large language models. Digital health platforms were the largest providers of MHI data. Ground truth for supervised learning models was based on clinician ratings (n = 31), patient self-report (n = 29) and annotations by raters (n = 26). Text-based features contributed more to model accuracy than audio markers. Patients' clinical presentation (n = 34), response to intervention (n = 11), intervention monitoring (n = 20), providers' characteristics (n = 12), relational dynamics (n = 14), and data preparation (n = 4) were commonly investigated clinical categories. Limitations of reviewed studies included lack of linguistic diversity, limited reproducibility, and population bias. A research framework is developed and validated (NLPxMHI) to assist computational and clinical researchers in addressing the remaining gaps in applying NLP to MHI, with the goal of improving clinical utility, data access, and fairness.	[Malgaroli, Matteo] NYU, Grossman Sch Med, Dept Psychiat, New York, NY 10016 USA; [Hull, Thomas D.; Zech, James M.] Talkspace, New York, NY 10025 USA; [Zech, James M.] Florida State Univ, Dept Psychol, Tallahassee, FL 32306 USA; [Althoff, Tim] Univ Washington, Dept Comp Sci, Seattle, WA 98195 USA	New York University; State University System of Florida; Florida State University; University of Washington; University of Washington Seattle	Malgaroli, M (corresponding author), NYU, Grossman Sch Med, Dept Psychiat, New York, NY 10016 USA.	matteo.malgaroli@nyulangone.org			National Institutes of Health (NIH); National Center for Advancing Translational Sciences (NCATS) [1K23MH134068-01, 2KL2TR001446-06A1]; Talkspace; American Foundation for Suicide Prevention [PRG-0-104-19]; National Institutes of Health [R44MH124334, R01MH125179-01]; NIH [R01MH125179]; NSF [IIS-1901386, CNS-2025022]; Bill & Melinda Gates Foundation [INV-004841]; Office of Naval Research [N00014-21-1-2154]	National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Center for Advancing Translational Sciences (NCATS)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS)); Talkspace; American Foundation for Suicide Prevention; National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); NSF(National Science Foundation (NSF)); Bill & Melinda Gates Foundation(Bill & Melinda Gates FoundationBill & Melinda Gates Foundation Grand Challenges Explorations InitiativeCGIAR); Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research)	MM's research was supported by the National Institutes of Health (NIH) and National Center for Advancing Translational Sciences (NCATS) and through grants # 1K23MH134068-01 and 2KL2TR001446-06A1, Talkspace, and by the American Foundation for Suicide Prevention through grant PRG-0-104-19. TDH's research was supported by National Institutes of Health Awards # R44MH124334 and R01MH125179-01. TA's research was supported by NIH grant R01MH125179, NSF grant IIS-1901386, NSF grant CNS-2025022, Bill & Melinda Gates Foundation (INV-004841), and the Office of Naval Research (#N00014-21-1-2154). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.	Aafjes-van Doorn K, 2021, PSYCHOTHER RES, V31, P92, DOI 10.1080/10503307.2020.1808729; Alonso-Sánchez MF, 2022, SCHIZOPHRENIA-UK, V8, DOI 10.1038/s41537-022-00246-8; Alonso-Sanchez MF., 2022, Schizophrenia Res, V259, P97; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Althoff Tim, 2016, Trans Assoc Comput Linguist, V4, P463; [Anonymous], 2020, LANCET GLOB HEALTH, V8, pE1352, DOI 10.1016/S2214-109X(20)30432-0; Arevian AC, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0225695; Association A.P., 2006, AM PSYCH ASS PRACT G; Aswamenakul C, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P356, DOI 10.1145/3242969.3242990; Atkins DC, 2014, IMPLEMENT SCI, V9, DOI 10.1186/1748-5908-9-49; Atkins DC, 2012, J FAM PSYCHOL, V26, P816, DOI 10.1037/a0029607; Atzil-Slonim D, 2021, PSYCHOTHERAPY, V58, P324, DOI 10.1037/pst0000362; Baggott MJ, 2015, J PSYCHOPHARMACOL, V29, P669, DOI 10.1177/0269881115581962; Bantilan N., 2021, Psychother Res, V31, P289; Burkhardt H., 2022, Comparing emotion feature extraction approaches for predicting depression and anxiety, P105, DOI DOI 10.18653/V1/2022.CLPSYCH-1.9; Burkhardt HA, 2021, J MED INTERNET RES, V23, DOI 10.2196/28244; Can D, 2016, J COUNS PSYCHOL, V63, P343, DOI 10.1037/cou0000111; Cao J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5599; Carcone AI, 2019, J PEDIATR PSYCHOL, V44, P289, DOI 10.1093/jpepsy/jsy113; Carrillo F, 2016, Arxiv, DOI arXiv:1606.02231; Carrillo F, 2018, J AFFECT DISORDERS, V230, P84, DOI 10.1016/j.jad.2018.01.006; Chancellor S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0233-7; Chaoua I, 2018, P 1 JOINT WORKSHOP A, P97; Chen Z, 2022, Findings of the Association for Computational Linguistics: EMNLP 2022, P5787; Chen ZH, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101380; Chen ZH, 2019, INT CONF ACOUST SPEE, P6605, DOI [10.1109/ICASSP.2019.8682885, 10.1109/icassp.2019.8682885]; Cho K., 2014, PROC SSST EMNLP, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179, DOI 10.3115/V1/W14-4012]; Chorpita Bruce F, 2005, Ment Health Serv Res, V7, P5, DOI 10.1007/s11020-005-1962-6; Christian C, 2021, J PSYCHOLINGUIST RES, V50, P143, DOI 10.1007/s10936-021-09768-1; Corcoran CM, 2018, WORLD PSYCHIATRY, V17, P67, DOI 10.1002/wps.20491; Cristea IA, 2021, JAMA PSYCHIAT, V78, P593, DOI 10.1001/jamapsychiatry.2020.4793; Cuijpers P, 2019, ANNU REV CLIN PSYCHO, V15, P207, DOI 10.1146/annurev-clinpsy-050718-095424; Cuijpers P, 2012, CLIN PSYCHOL REV, V32, P280, DOI 10.1016/j.cpr.2012.01.003; Cunningham PJ, 2009, HEALTH AFFAIR, V28, pW490, DOI 10.1377/hlthaff.28.3.w490; Cunningham S., 2021, Causal inference: The mixtape; Delgadillo J, 2020, JAMA PSYCHIAT, V77, P889, DOI 10.1001/jamapsychiatry.2020.1048; Demiris G, 2022, INT J MED INFORM, V160, DOI 10.1016/j.ijmedinf.2022.104716; DeRubeis RJ, 2008, NAT REV NEUROSCI, V9, P788, DOI 10.1038/nrn2345; Ding XR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P68; Dirkse D, 2015, COGN BEHAV THERAPY, V44, P21, DOI 10.1080/16506073.2014.952773; Doré BP, 2018, PSYCHOL SCI, V29, P1716, DOI 10.1177/0956797618779971; Douthit N, 2015, PUBLIC HEALTH, V129, P611, DOI 10.1016/j.puhe.2015.04.001; Dwyer DB, 2018, ANNU REV CLIN PSYCHO, V14, P91, DOI [10.1146/annurev-clinpsy-032816-045037, 10.1146/annurev-clinpsy-032816045037]; Crangle CE, 2019, Arxiv, DOI arXiv:1901.04110; Ewbank MP, 2021, PSYCHOTHER RES, V31, P326, DOI 10.1080/10503307.2020.1788740; Ewbank MP, 2020, JAMA PSYCHIAT, V77, P35, DOI 10.1001/jamapsychiatry.2019.2664; Figueroa JF, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.1210; Firth J, 2017, WORLD PSYCHIATRY, V16, P287, DOI 10.1002/wps.20472; Flemotomos N., 2021, CoRR, Abs, V2102, p10.3758.; Flemotomos N, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0258639; Gaut G, 2017, IEEE J BIOMED HEALTH, V21, P476, DOI 10.1109/JBHI.2015.2503985; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Gibson J, 2016, INTERSPEECH, P1447, DOI 10.21437/Interspeech.2016-554; Glauser T, 2020, ACTA NEUROL SCAND, V141, P388, DOI 10.1111/ane.13216; Goldberg SB, 2020, J COUNS PSYCHOL, V67, P438, DOI 10.1037/cou0000382; Goldberg SB, 2021, PSYCHOTHER RES, V31, P281, DOI 10.1080/10503307.2020.1741047; Goldenberg A., 2019, What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use; He QW, 2017, ASSESSMENT, V24, P157, DOI 10.1177/1073191115602551; Heisler E.J., 2018, MENTAL HLTH WORKFORC; Hernandez-Boussard T, 2020, J AM MED INFORM ASSN, V27, P2011, DOI 10.1093/jamia/ocaa088; Hicks JL, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0121-1; Hogarty DT, 2019, CLIN EXP OPHTHALMOL, V47, P128, DOI 10.1111/ceo.13381; Hoogendoorn M, 2017, IEEE J BIOMED HEALTH, V21, P1449, DOI 10.1109/JBHI.2016.2601123; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Howes Christine., 2014, Proceedings of the Workshop on Computational Linguistics and Clinical Psychology: From Linguistic Signal to Clinical Reality, P7, DOI 10.3115/v1/W14-3202; Hudon A, 2022, HEALTH INFORM J, V28, DOI 10.1177/14604582221142442; Hull TD, 2021, JMIR FORM RES, V5, DOI 10.2196/26190; Imel ZE, 2017, J COUNS PSYCHOL, V64, P385, DOI 10.1037/cou0000213; Imel ZE, 2015, PSYCHOTHERAPY, V52, P19, DOI 10.1037/a0036841; Insel TR, 2018, WORLD PSYCHIATRY, V17, P276, DOI 10.1002/wps.20550; Johnsen TJ, 2015, PSYCHOL BULL, V141, P747, DOI 10.1037/bul0000015; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Just SA, 2020, FRONT PSYCHIATRY, V11, DOI 10.3389/fpsyt.2020.00846; Kazdin AE, 2009, PSYCHOTHER RES, V19, P418, DOI 10.1080/10503300802448899; Kilbourne AM, 2018, WORLD PSYCHIATRY, V17, P30, DOI 10.1002/wps.20482; Kshirsagar R., 2017, CLPsych, P66, DOI [10.18653/v1/W17-3108, DOI 10.18653/V1/W17-3108]; Lane J, 2010, HEALTH SERV RES, V45, P1456, DOI 10.1111/j.1475-6773.2010.01141.x; Lee F-T., 2019, P 6 WORKSH COMP LING, P12, DOI 10.18653/v1/W19-3002; Liu ZL, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.779091; Lutz W, 2009, PSYCHOTHER RES, V19, P502, DOI 10.1080/10503300802688486; MacAvaney Sean, 2021, P 7 WORKSH COMP LING, P70, DOI DOI 10.18653/V1/2021.CLPSYCH-1.7; Malins S, 2022, JMIR MED INF, V10, DOI 10.2196/38168; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Mao K, 2022, IEEE Trans Affective Comput., V1; Martinez VR, 2019, INTERSPEECH, P1901, DOI [10.21437/interspeech.2019-2829, 10.21437/Interspeech.2019-2829]; Mehta M., 2022, P 8 WORKSHOP COMPUTA, P47; Mieskes M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2896; Min D.J., 2021, P 7 WORKSH COMP LING, P159, DOI [DOI 10.18653/V1/2021.CLPSYCH-1.18, 10.18653/v1/2021.clpsych-1.18]; Miner AS, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0285-8; Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746; Miner AS., 2022, npj Ment Health Res, V1, P19; Miranda J, 2008, AM J PSYCHIAT, V165, P1102, DOI 10.1176/appi.ajp.2008.08030333; Morris RR, 2018, J MED INTERNET RES, V20, DOI 10.2196/10148; Mota NB., 2022, Schizophrenia Res, V259, P38; Moyers TB, 2005, J CONSULT CLIN PSYCH, V73, P590, DOI 10.1037/0022-006X.73.4.590; Moyers T, 2003, BEHAV COGN PSYCHOTH, V31, P177, DOI 10.1017/S1352465803002054; Mullet E, 2018, QUAL QUANT, V52, P1977, DOI 10.1007/s11135-017-0592-6; Murray CJL, 2018, LANCET, V392, P1995, DOI [10.1016/s0140-6736(18)32279-7, 10.1016/S0140-6736(18)32279-7, 10.1016/s0140-6736(18)32278-5]; Nasir M, 2019, INTERSPEECH, P1423, DOI [10.21437/interspeech.2019-1900, 10.21437/Interspeech.2019-1900]; Nitti M, 2010, PSYCHOTHER RES, V20, P546, DOI 10.1080/10503301003641886; Nook EC, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2114737119; Norman KP, 2020, JMIR FORM RES, V4, DOI 10.2196/17424; Ohlsson H, 2020, JAMA PSYCHIAT, V77, P637, DOI 10.1001/jamapsychiatry.2019.3758; ONeil C., 2016, Weapons of math destruction: how big data increases inequality and threatens democracy; Oyebode F., 2008, SIMSSYMPTOMS MIND IN, V4; Pace A, 2017, ANNU REV LINGUIST, V3, P285, DOI 10.1146/annurev-linguistics-011516-034226; Palaniyappan L, 2019, PROG NEURO-PSYCHOPH, V88, P112, DOI 10.1016/j.pnpbp.2018.07.007; Park J, 2021, PATIENT EDUC COUNS, V104, P2098, DOI 10.1016/j.pec.2021.01.004; Pascual-Leone A, 2018, PSYCHOTHER RES, V28, P165, DOI 10.1080/10503307.2017.1349350; Pérez-Rosas V, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3742; Pérez-Rosas V, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P926; Perez-Rosas V, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1426, DOI 10.18653/v1/P17-1131; Pérez-Rosas V, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1128; Provoost S, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.01065; Ramakrishna A, 2018, INTERSPEECH, P2344, DOI [10.21437/Interspeech.2018-1583, 10.21437/interspeech.2018-1583]; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Salmi S, 2022, BMC PUBLIC HEALTH, V22, DOI 10.1186/s12889-022-12926-2; Saraceno B, 2007, LANCET, V370, P1164, DOI 10.1016/S0140-6736(07)61263-X; Schaffter T, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.0265; Schultebraucks K, 2022, PSYCHOL MED, V52, P957, DOI 10.1017/S0033291720002718; Schultebraucks K, 2020, NAT MED, V26, P1084, DOI 10.1038/s41591-020-0951-z; Shapira N, 2021, J COUNS PSYCHOL, V68, P77, DOI 10.1037/cou0000440; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2; Sharma A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5263; Sharma A, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P194, DOI 10.1145/3442381.3450097; Shidara Kazuhiro, 2022, Annu Int Conf IEEE Eng Med Biol Soc, V2022, P2668, DOI 10.1109/EMBC48229.2022.9871408; Si D, 2019, PROC INT C TOOLS ART, P339, DOI 10.1109/ICTAI.2019.00055; Singla K, 2018, INTERSPEECH, P3413, DOI 10.21437/interspeech.2018-2551; Skivington K, 2021, BMJ-BRIT MED J, V374, DOI 10.1136/bmj.n2061; Son Y, 2023, PSYCHOL MED, V53, P918, DOI 10.1017/S0033291721002294; SPark S, 2019, IEEE 31 INT C TOOLS, P339; Spruit M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12042179; Srivastava A, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3920, DOI 10.1145/3534678.3539187; Sterne JAC, 2009, BMJ-BRIT MED J, V339, DOI 10.1136/bmj.b2393; Substance Abuse and Mental Health Services Administration, 2021, HHS PUBLICATION NO P; Syzdek BM, 2020, PSYCHOL STUD, V65, P520, DOI 10.1007/s12646-020-00567-7; Tanana M, 2016, J SUBST ABUSE TREAT, V65, P43, DOI 10.1016/j.jsat.2016.01.006; Tanana MJ, 2021, BEHAV RES METHODS, V53, P2069, DOI 10.3758/s13428-020-01531-z; Tasca AN, 2023, PSYCHOTHER RES, V33, P757, DOI 10.1080/10503307.2022.2156306; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; Tavabi Leili, 2020, Proc ACM Int Conf Multimodal Interact, V2020, P406, DOI 10.1145/3382507.3418853; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tracey TJG, 2014, AM PSYCHOL, V69, P218, DOI 10.1037/a0035099; Tsakalidis A, 2021, P 7 WORKSH COMP LING, P122; Tseng SY, 2017, INTERSPEECH, P3291, DOI 10.21437/Interspeech.2017-1621; Vaci N, 2020, EVID-BASED MENT HEAL, V23, P21, DOI 10.1136/ebmental-2019-300134; Vaswani A, 2017, ADV NEUR IN, V30; Wadden D., 2021, P INT AAAI C WEB SOC, V15, P751, DOI DOI 10.1609/ICWSM.V15I1.18100; Wampold BE, 2015, GREAT PSYCHOTHERAPY DEBATE: THE EVIDENCE FOR WHAT MAKES PSYCHOTHERAPY WORK, 2ND EDITION, P1; Wang PS, 2007, LANCET, V370, P841, DOI 10.1016/S0140-6736(07)61414-7; Wawer A, 2022, COGN COMPUT, V14, P461, DOI 10.1007/s12559-021-09834-9; Wei J, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4450; Weintraub MJ, 2021, J PSYCHIATR RES, V136, P39, DOI 10.1016/j.jpsychires.2021.01.019; Weld G, 2022, P INT AAAI C WEB SOC, P1109; Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1007/BF00116900; Wiegersma S, 2020, EUR J PSYCHOTRAUMATO, V11, DOI 10.1080/20008198.2020.1726672; Wu Z, 2021, P 7 WORKSH COMP LING, P204; Wu ZX, 2022, INTERSPEECH, P1906, DOI 10.21437/Interspeech.2022-506; Xezonaki D, 2020, Arxiv, DOI arXiv:2006.08336; Xiao B, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.59; Xiao B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0143055; Xu SJ, 2018, 2018 INTERNATIONAL CONFERENCE ON MICROWAVE AND MILLIMETER WAVE TECHNOLOGY (ICMMT2018); Xu YC, 2021, INTERNET INTERV, V26, DOI 10.1016/j.invent.2021.100486; Xu ZZ, 2021, SOC SCI MED, V283, DOI 10.1016/j.socscimed.2021.114176; Zhang Justine, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415202; Zhang J, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, P5276; Zhang J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P936; Zhang XS, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2487, DOI 10.1145/3292500.3330779	168	5	5	8	16	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2158-3188			TRANSL PSYCHIAT	Transl. Psychiatr.	OCT 6	2023	13	1							309	10.1038/s41398-023-02592-2	http://dx.doi.org/10.1038/s41398-023-02592-2			17	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	T8CQ2	37798296	gold, Green Published			2024-07-03	WOS:001080210400001
J	Karakose, T; Demirkol, M; Yirci, R; Polat, H; Ozdemir, TY; Tülübas, T				Karakose, Turgut; Demirkol, Murat; Yirci, Ramazan; Polat, Hakan; Ozdemir, Tuncay Yavuz; Tulubas, Tijen			A Conversation with ChatGPT about Digital Leadership and Technology Integration: Comparative Analysis Based on Human-AI Collaboration	ADMINISTRATIVE SCIENCES			English	Article						digital leadership; technology integration; school leadership; ChatGPT; artificial intelligence; generative AI; AI in education; chatbot	ARTIFICIAL-INTELLIGENCE; TEACHER BELIEFS; AGE	Artificial intelligence (AI) is one of the ground-breaking innovations of the 21st century that has accelerated the digitalization of societies. ChatGPT is a newer form of AI-based large language model that can generate complex texts that are almost indistinguishable from human-generated text. It has already garnered substantial interest from people due to its potential utility in a variety of contexts. The current study was conducted to evaluate the utility of ChatGPT in generating accurate, clear, concise, and unbiased information that could support a scientific research process. To achieve this purpose, we initiated queries on both versions of ChatGPT regarding digital school leadership and teachers' technology integration, two significant topics currently discussed in educational literature, under four categories: (1) the definition of digital leadership, (2) the digital leadership skills of school principals, (3) the factors affecting teachers' technology integration, and (4) the impact of digital leadership on teachers' technology integration. Next, we performed a comparative analysis of the responses generated by ChatGPT-3.5 and ChatGPT-4. The results showed that both versions were capable of providing satisfactory information compatible with the relevant literature. However, ChatGPT-4 provided more comprehensive and categorical information as compared to ChatGPT-3.5, which produced responses that were more superficial and short-cut. Although the results are promising in aiding the research process with AI-based technologies, we should also caution that, in their current form, these tools are still in their infancy, and there is a long way to go before they become fully capable of supporting scientific work. Meanwhile, it is significant that researchers continue to develop the relevant knowledge base to support the responsible, safe, and ethical integration of these technologies into the process of scientific knowledge creation, as Pandora's box has already been opened, releasing newer opportunities and risks to be tackled.	[Karakose, Turgut; Tulubas, Tijen] Kutahya Dumlupinar Univ, Fac Educ, TR-43100 Kutahya, Turkiye; [Demirkol, Murat; Polat, Hakan; Ozdemir, Tuncay Yavuz] Firat Univ, Fac Educ, TR-23119 Elazig, Turkiye; [Yirci, Ramazan] Sutcuimam Univ, Fac Educ, TR-46050 Kahramanmaras, Turkiye	Dumlupinar University; Firat University; Kahramanmaras Sutcu Imam University	Yirci, R (corresponding author), Sutcuimam Univ, Fac Educ, TR-46050 Kahramanmaras, Turkiye.	turgut.karakose@dpu.edu.tr; mdemirkol@firat.edu.tr; yirci@ksu.edu.tr; hakanpolat@firat.edu.tr; tyozdemir@firat.edu.tr; tijen.tulubas@dpu.edu.tr	Karakose, Turgut/AAR-2642-2021; POLAT, HAKAN/ABG-2858-2021; Yirci, Ramazan/N-8738-2015; Ozdemir, Tuncay Yavuz/W-7212-2018	Karakose, Turgut/0000-0003-0346-8154; POLAT, HAKAN/0000-0002-0271-3747; Tulubas, Tijen/0000-0001-9406-8361; DEMIRKOL, MURAT/0000-0003-3108-3219; Yirci, Ramazan/0000-0003-4696-7420; OZDEMIR, Tuncay Yavuz/0000-0002-5361-7261; Ozdemir, Tuncay Yavuz/0000-0001-6474-5915				Abu Al-Ruz J, 2011, EDUC TECHNOL SOC, V14, P77; Agustina R., 2020, Int. J. Learn. Teach. Educ. Res, V19, P24, DOI DOI 10.26803/IJLTER.19.11.2; Aksal F. A., 2016, EGITIM BILIM, V40, P77; Alghamdi Abdulmajeed., 2015, AUSTR ED COMPUTING, V30, P1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2004, Introduction to Machine Learning; [Anonymous], 2021, In Digital Transformation of Learning Organizations, DOI DOI 10.1007/978-3-030-55878-96#DOI; Arham Ahmad Fadhly, 2023, Digitalisation: Opportunities and Challenges for Business. Lecture Notes in Networks and Systems (621), P849, DOI 10.1007/978-3-031-26956-1_79; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; Berente N., 2021, MIS Quart., V45, P1433, DOI DOI 10.25300/MISQ/2021/16274; Biswas S., 2023, MESOPOTAMIAN J COMPU, V2023, P8, DOI [10.58496/MJCSC/2023/002, DOI 10.58496/MJCSC/2023/002]; Blumenthal D, 2017, MILBANK Q, V95, P15, DOI 10.1111/1468-0009.12239; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bogost I., 2022, CHATGPT IS DUMBER YO; Bolte S, 2018, ACTA TECH NAPOC SER-, V61, P637; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chang IH, 2012, EDUC TECHNOL SOC, V15, P328; Choi JH, 2022, J LEGAL EDUC, V71, P387; Christensen R., 2002, Journal of Research on Technology in Education, V34, P411; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; de Saint Laurent CD, 2018, EUR J PSYCHOL, V14, P734, DOI 10.5964/ejop.v14i4.1823; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eberl JK, 2021, L N INF SYST ORGAN, V48, P223, DOI 10.1007/978-3-030-86800-0_17; Elmas Cetin., 2021, YAPAY ZEKA UYGULAMAL; Ertmer PA, 2012, COMPUT EDUC, V59, P423, DOI 10.1016/j.compedu.2012.02.001; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Gao J, 2023, Arxiv, DOI [arXiv:2303.03836, DOI 10.48550/ARXIV.2303.03836]; Ghavifekr S., 2023, Global Perspectives on the Internationalization of Higher Education, P1, DOI [10.4018/978-1-6684-5929-4.ch001, DOI 10.4018/978-1-6684-5929-4.CH001]; Gupta P., 2023, SSRN ELECT J, DOI [https://doi.org/10.2139/ssrn.4386113, DOI 10.2139/SSRN.4386113]; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Hamzah N. H., 2021, J ED E LEARNING RES, V8, P216, DOI [https://doi.org/10.20448/journal.509.2021.82.216.221, DOI 10.20448/JOURNAL.509.2021.82.216.221]; Hapsari Intan Permata, 2022, Innovative Technologies and Learning: 5th International Conference, ICITL 2022, Proceedings. Lecture Notes in Computer Science (13449), P444, DOI 10.1007/978-3-031-15273-3_49; Hensellek S., 2020, Journal of Media Management and Entrepreneurship (JMME), V2, P55, DOI DOI 10.4018/JMME.2020010104; Howley A., 2011, Journal of Research in Rural Education, V26, P1; Jia FL, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142315527; Jones C.I, 2018, EC ARTIFICIAL INTELL, P237; Kane GC, 2019, MIT SLOAN MANAGE REV, V60, P34; Karakose T., 2023, Educ. Process Int. J., V12, P7, DOI [10.22521/edupij.2023.122.1, DOI 10.22521/EDUPIJ.2023.121.1]; Karakose T, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142316171; Karakose T, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132313448; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kaymak Uzay., 2010, PAPER PRESENTED INT, P1; Keengwe J, 2008, J SCI EDUC TECHNOL, V17, P560, DOI 10.1007/s10956-008-9123-5; Kim C, 2013, TEACH TEACH EDUC, V29, P76, DOI 10.1016/j.tate.2012.08.005; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Liu SH, 2011, COMPUT EDUC, V56, P1012, DOI 10.1016/j.compedu.2010.12.001; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; McCarthy J, 2006, AI MAG, V27, P12; McLeod S., 2015, Independent School, V74; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Michail A, 2023, Arxiv, DOI arXiv:2303.01194; Milmo Dan., 2023, GUARDIAN 0202; Mitchell T., 1997, Machine learning; Navaridas-Nalda F, 2020, COMPUT HUM BEHAV, V112, DOI 10.1016/j.chb.2020.106481; Oberer B, 2018, INT J ORGAN LEADERSH, V7, P404, DOI 10.33844/ijol.2018.60332; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Ongoz Sakine., 2020, E ITIMDE YAPAY ZEKA, P58; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; OpenAi, 2022, Chatgpt; OpenAI, 2023, GPT-4 Technical Report; Qadir Junaid, 2023, 2023 IEEE Global Engineering Education Conference (EDUCON), P1, DOI 10.1109/EDUCON54358.2023.10125121; Ruggiero D, 2015, J INF TECHNOL EDUC-R, V14, P161; Russel S. J., 2014, The Knowledge Engineering Review, V3rd, DOI [DOI 10.1017/S0269888900007724, 10.1017/S0269888900007724]; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Sauers NJ, 2018, J EDUC COMPUT RES, V56, P892, DOI 10.1177/0735633117713021; Scharth M., 2022, The chatgpt chatbot is blowing people away with its writing skills; Shukla Shubhendu S., 2013, International Journal of Scientific Engineering and Research, V1, P28; Shuldman M., 2004, Journal of Research on Technology in Education, V36, P319; Siddiqui S, 2020, J E-LEARN KNOWL SOC, V16, P11, DOI 10.20368/1971-8829/1135188; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokes F, 2020, NURS PHILOS, V21, DOI 10.1111/nup.12306; Sun SY, 2011, HEALTH SERV OUTCOME, V11, P145, DOI 10.1007/s10742-011-0077-3; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Teebagy S, 2023, medRxiv, DOI [10.1101/2023.04.03.23287957, 10.1101/2023.04.03.23287957, DOI 10.1101/2023.04.03.23287957]; Tigre FB, 2023, J LEADERSH ORG STUD, V30, P40, DOI 10.1177/15480518221123132; Tulubas T., 2023, Educational Process International Journal, V12, P93, DOI [10.22521/edupij.2023.122.6, DOI 10.22521/EDUPIJ.2023.122.6]; Warrens MJ., 2015, J PSYCHOL PSYCHOTHER, V05, P197, DOI [10.4172/2161-0487.1000197, DOI 10.4172/2161-0487.1000197]; West CG, 2023, Arxiv, DOI [arXiv:2303.17012, 10.48550/arXiv.2303.17012]; Yilmaz A., 2020, Participatory Educational Research, V8, P163, DOI DOI 10.17275/PER.21.35.8.2; Zaitsu W, 2023, PLOS ONE, V18; Zhai Xioming., 2022, CHATGPT USER EXPERIE, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhao Yukun., 2023, PREPRINT, DOI [10.21203/rs.3.rs-2928607/v1, DOI 10.21203/RS.3.RS-2928607/V1]; Zhong L., 2017, J ED TECHNOLOGY DEV, V10, P27, DOI [10.18785/jetde.1001.03, DOI 10.18785/JETDE.1001.03, https://doi.org/10.18785/jetde.1001.03]	86	9	10	46	109	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3387		ADM SCI	Adm. Sci.	JUL	2023	13	7							157	10.3390/admsci13070157	http://dx.doi.org/10.3390/admsci13070157			19	Management	Emerging Sources Citation Index (ESCI)	Business & Economics	N1LX0		gold, Green Published			2024-07-03	WOS:001034722300001
J	Fahy, S; Niemann, M; Böhm, P; Winkler, T; Oehme, S				Fahy, Stephen; Niemann, Marcel; Boehm, Peter; Winkler, Tobias; Oehme, Stephan			Assessment of the Quality and Readability of Information Provided by ChatGPT in Relation to the Use of Platelet-Rich Plasma Therapy for Osteoarthritis	JOURNAL OF PERSONALIZED MEDICINE			English	Article						osteoarthritis (OA); regenerative medicine; platelet-rich plasma (PRP); readability; digital health literacy; patient education materials (PEMs); artificial intelligence (AI)	LITERACY; INTERNET	Objective: This study aimed to evaluate the quality and readability of information generated by ChatGPT versions 3.5 and 4 concerning platelet-rich plasma (PRP) therapy in the management of knee osteoarthritis (OA), exploring whether large language models (LLMs) could play a significant role in patient education. Design: A total of 23 common patient queries regarding the role of PRP therapy in knee OA management were presented to ChatGPT versions 3.5 and 4. The quality of the responses was assessed using the DISCERN criteria, and readability was evaluated using six established assessment tools. Results: Both ChatGPT versions 3.5 and 4 produced moderate quality information. The quality of information provided by ChatGPT version 4 was significantly better than version 3.5, with mean DISCERN scores of 48.74 and 44.59, respectively. Both models scored highly with respect to response relevance and had a consistent emphasis on the importance of shared decision making. However, both versions produced content significantly above the recommended 8th grade reading level for patient education materials (PEMs), with mean reading grade levels (RGLs) of 17.18 for ChatGPT version 3.5 and 16.36 for ChatGPT version 4, indicating a potential barrier to their utility in patient education. Conclusions: While ChatGPT versions 3.5 and 4 both demonstrated the capability to generate information of moderate quality regarding the role of PRP therapy for knee OA, the readability of the content remains a significant barrier to widespread usage, exceeding the recommended reading levels for PEMs. Although ChatGPT version 4 showed improvements in quality and source citation, future iterations must focus on producing more accessible content to serve as a viable resource in patient education. Collaboration between healthcare providers, patient organizations, and AI developers is crucial to ensure the generation of high quality, peer reviewed, and easily understandable information that supports informed healthcare decisions.	[Fahy, Stephen; Niemann, Marcel; Winkler, Tobias; Oehme, Stephan] Charite Univ Med Berlin, Freie Univ Berlin, Humboldt Univ Berlin, Ctr Musculoskeletal Surg, D-10117 Berlin, Germany; [Boehm, Peter] Deutsch Rheuma Liga eV Bonn, D-53111 Bonn, Germany; [Winkler, Tobias] Charite Univ med Berlin, Berlin Inst Hlth Ctr Regenerat Therapies, Berlin Inst Hlth, D-13353 Berlin, Germany; [Winkler, Tobias] Charite Univ Med Berlin, Berlin Inst Hlth, Julius Wolff Inst, D-13353 Berlin, Germany	Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Berlin Institute of Health; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Berlin Institute of Health	Oehme, S (corresponding author), Charite Univ Med Berlin, Freie Univ Berlin, Humboldt Univ Berlin, Ctr Musculoskeletal Surg, D-10117 Berlin, Germany.	stephen.fahy@charite.de; marcel.niemann@charite.de; peboehm@gmx.de; tobias.winkler@charite.de; stephan.oehme@charite.de		Niemann, Marcel/0000-0001-7264-3089; Winkler, Tobias/0000-0003-0727-4680	European Union	European Union(European Union (EU))	No Statement Available	Abrams GD, 2013, SPORTS MED ARTHROSC, V21, P213, DOI 10.1097/JSA.0b013e3182999740; allstarorthopedic, All Star Orthopaedics of Austin; American Academy of Orthopedic Surgeons, 2024, OrthoInfo; [Anonymous], 2024, Caring Medical; [Anonymous], 2012, The nation's report card: Science 2011; [Anonymous], 2024, Veritas Arthritis Health; [Anonymous], 2024, Health Gains: How Many PRP Injections Are Needed for Knee?; Brega AG, 2015, J HEALTH COMMUN, V20, P69, DOI 10.1080/10810730.2015.1081997; Currie GM, 2023, J NUCL MED TECHNOL, V51, P314, DOI 10.2967/jnmt.123.266485; Di Martino A, 2019, AM J SPORT MED, V47, P347, DOI 10.1177/0363546518814532; Doak C.H., 1996, Teaching patients with low literacy skills; Doinn TO, 2022, ORTHOP J SPORTS MED, V10, DOI 10.1177/23259671221092356; Doinn TO, 2021, J BONE JOINT SURG AM, V103, DOI 10.2106/JBJS.20.01347; Doral Doc, 2024, PRP Therapy for Arthritis; Fahy S, 2024, J PERS MED, V14, DOI 10.3390/jpm14010104; Feucht MJ, 2016, KNEE SURG SPORT TR A, V24, P201, DOI 10.1007/s00167-014-3364-z; Filardo G, 2021, CARTILAGE, V13, p364S, DOI 10.1177/1947603520931170; Ghodasra JH, 2018, ARTHROSCOPY, V34, P272, DOI 10.1016/j.arthro.2017.06.023; Gruson KI, 2023, ARCH BONE JT SURG-AB, V11, P227, DOI 10.22038/ABJS.2022.68429.3237; GUCCIONE AA, 1994, AM J PUBLIC HEALTH, V84, P351, DOI 10.2105/AJPH.84.3.351; Hautala GS, 2021, INJURY, V52, P3299, DOI 10.1016/j.injury.2021.02.029; Hsu WK, 2013, J AM ACAD ORTHOP SUR, V21, P739, DOI 10.5435/JAAOS-21-12-739; Hurley ET, 2024, ARTHROSCOPY, V40, DOI 10.1016/j.arthro.2023.07.048; Johnson VL, 2014, BEST PRACT RES CL RH, V28, P5, DOI 10.1016/j.berh.2014.01.004; Kennedy MI, 2018, CURR REV MUSCULOSKE, V11, P573, DOI 10.1007/s12178-018-9516-x; Kienzle A, 2024, J PERS MED, V14, DOI 10.3390/jpm14010069; Oleander Software, 2019, Readability Studio 2019: Professional Edition.; Platelet Rich Plasma Market, 2020, Forcast Report 2021-2031; Saint Helens and Knowsley Teaching Hospital NHS Trust, 2024, Information for Patients Having a Platelet Rich Plasma (PRP) Injection; Sánchez M, 2021, INT ORTHOP, V45, P401, DOI 10.1007/s00264-020-04669-9; Shahid A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34533; Shai SS, 2021, CARTILAGE, V13, p392S, DOI 10.1177/1947603520906598; Silberg WM, 1997, JAMA-J AM MED ASSOC, V277, P1244, DOI 10.1001/jama.1997.03540390074039; Weis B., 2003, Health literacy: a manual for clinicians; Weiss B D, 1994, J Health Care Poor Underserved, V5, P99; Xiong YQ, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1204144; Yang JW, 2024, J ARTHROPLASTY, V39, P1184, DOI 10.1016/j.arth.2024.01.029	37	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2075-4426		J PERS MED	J. Pers. Med.	MAY	2024	14	5							495	10.3390/jpm14050495	http://dx.doi.org/10.3390/jpm14050495			12	Health Care Sciences & Services; Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; General & Internal Medicine	SF6Y3	38793077	gold			2024-07-03	WOS:001233093100001
J	Govender, RG				Govender, Reginald Gerald			My AI students: Evaluating the proficiency of three AI chatbots in completeness and accuracy	CONTEMPORARY EDUCATIONAL TECHNOLOGY			English	Article						artificial intelligence; chatbots; generative text; completeness; accuracy	ANSWER QUALITY	A new era of artificial intelligence (AI) has begun, which can radically alter how humans interact with and profit from technology. The confluence of chat interfaces with large language models lets humans write a natural language inquiry and receive a natural language response from a machine. This experimental design study tests the capabilities of three popular AI chatbot services referred to as my AI students: Microsoft Bing, Google Bard, and OpenAI ChatGPT on completeness and accuracy . A Likert scale was used to rate c ompleteness and accuracy, respectively, a three-point and five-point. Descriptive statistics and non-parametric tests were used to compare marks and scale ratings. The results show that AI chatbots were awarded a score of 80.0% overall. However, they struggled with answering questions from the higher Bloom's taxonomic levels. The median completeness was 3.00 with a mean of 2.75 and the median accuracy was 5.00 with a mean of 4.48 across all Bloom's taxonomy questions (n=128). Overall, the completeness of the solution was rated mostly incomplete due to limited response (76.2%), while accuracy was rated mostly correct (83.3%). In some cases, generative text was found to be verbose and disembodied, lacking perspective and coherency. Microsoft Bing ranked first among the three AI text generative tools in providing correct answers (92.0%). The Kruskal-Wallis test revealed a significant difference in completeness (asymp. sig.=0.037, p<0.05) and accuracy (asymp. sig.=0.006, p<0.05) among the three AI chatbots. A series of Mann and Whitney tests were carried out showing no significance between AI chatbots for completeness (all p-values>0.015 and 0	[Govender, Reginald Gerald] Univ KwaZulu Natal, Durban, South Africa	University of Kwazulu Natal	Govender, RG (corresponding author), Univ KwaZulu Natal, Durban, South Africa.	govenderr4@ukzn.ac.za		Govender, Reginald Gerald/0000-0002-3143-4050	National Research Foundation of South Africa [TTK2204092902]	National Research Foundation of South Africa(National Research Foundation - South Africa)	This article was supported by National Research Foundation of South Africa (grant number: TTK2204092902) .	Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Allam Hesham, 2023, 2023 9th International Conference on Information Technology Trends (ITT), P151, DOI 10.1109/ITT59889.2023.10184267; Berrar DP, 2014, KYBERNETES, V43, P82, DOI 10.1108/K-08-2013-0175; Bibi W, 2020, FWU J SOC SCI, V14, P111; Blooma MJ, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P1107; Borenstein Jason, 2021, AI Ethics, V1, P61, DOI 10.1007/s43681-020-00002-7; Buchholz K., 2023, Statista; Carter C., 2023, Cyber-human systems, space technologies, and threats.; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Craighead WE, 2010, CORSINI ENCY PSYCHOL, P1, DOI [10.1002/9780470479216.corpsy0491, DOI 10.1002/9780470479216.CORPSY0491]; Dheda G., 2023, Open AI Master; Edelsbrunner P., 2023, PsyArXiv, DOI [10.31234/osf.io/uxzwg, DOI 10.31234/OSF.IO/UXZWG]; Emerson R.W., 2020, Journal of Visual Impairment Blindness, V114, P77, DOI [DOI 10.1177/0145482X20901378, 10.1177/0145482X2090, DOI 10.1177/0145482X2090]; Fichman P, 2011, J INF SCI, V37, P476, DOI 10.1177/0165551511415584; Forehand M., 2010, Emerging Perspectives on Learning, Teaching, and Technology, V1st ed., P41; Garg M, 2022, COMPUT SECUR, V113, DOI 10.1016/j.cose.2021.102544; Gonçalves B, 2023, MIND MACH, V33, P1, DOI 10.1007/s11023-022-09616-8; Govender R. G., 2021, Teaching and learning in the 21st century, P30, DOI [10.1163/9789004460386003, DOI 10.1163/9789004460386003]; Gulyamov S., 2023, Uzbek Journal of Law and Digital Policy, V1; Hodges A., 2009, Parsing the Turing Test, DOI [10.1007/978-1-4020-6710-52, DOI 10.1007/978-1-4020-6710-52]; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Jabotinsky H. Y., 2022, Ethical dilemmas and artificial intelligence, DOI [DOI 10.2139/SSRN.4303959, 10.2139/ssrn.4303959]; Jannai D., 2023, arXiv, DOI [10.48550/arXiv.2305.20010, DOI 10.48550/ARXIV.2305.20010]; John BM, 2011, IEEE INTERNET COMPUT, V15, P66, DOI 10.1109/MIC.2011.23; Jones K., 2020, On reimagining a future for online learning in the post-COVID-19 era, DOI [10.2139/ssrn.3578310, DOI 10.2139/SSRN.3578310]; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Lee DB, 2022, COMPUT EDUC, V191, DOI 10.1016/j.compedu.2022.104646; Li L, 2016, LECT NOTES COMPUT SC, V9751, P61, DOI 10.1007/978-3-319-39396-4_6; Marcus G, 2016, AI MAG, V37, P3, DOI 10.1609/aimag.v37i1.2650; Microsoft, 2023, What is Bing Chat, and how can you use it?; MOOR JH, 1976, PHILOS STUD, V30, P249, DOI 10.1007/BF00372497; Naidu S, 2022, DISTANCE EDUC, V43, P1, DOI 10.1080/01587919.2022.2029652; Newton PM, 2024, J ACAD ETHICS, V22, P323, DOI 10.1007/s10805-023-09485-5; Nguyen C, 2021, J MED LIBR ASSOC, V109, P613, DOI 10.5195/jmla.2021.1229; Nilsen EB, 2020, J APPL ECOL, V57, P842, DOI 10.1111/1365-2664.13571; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramesh D, 2022, ARTIF INTELL REV, V55, P2495, DOI 10.1007/s10462-021-10068-2; Selwyn N, 2022, EUR J EDUC, V57, P620, DOI 10.1111/ejed.12532; Shieber S. M., 1994, arXiv, DOI [10.1145/175208.175217, DOI 10.1145/175208.175217]; Shin B., 2023, Fortune; Strzelecki A, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2209881; Su JH, 2023, ECNU REV EDUC, V6, P355, DOI 10.1177/20965311231168423; Taylor R.S., 1986, VALUE ADDED PROCESSE; Theophilou E., 2023, INT C IT ASS ART INT, V14318, P481, DOI [10.1007/978-3-031-47546-733, DOI 10.1007/978-3-031-47546-733]; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Visentin DC, 2020, J ADV NURS, V76, P917, DOI 10.1111/jan.14283; Wang J, 2023, AM J PHYS, V91, P255, DOI 10.1119/5.0145897; Wang JR, 2023, J KNOWL ECON, DOI 10.1007/s13132-022-01096-6; Yin D, 2022, Arxiv, DOI arXiv:2202.08772; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zhu LX, 2023, RESUSCITATION, V188, DOI 10.1016/j.resuscitation.2023.109783	53	0	0	2	2	BASTAS PUBL LTD - UK	London	Bastas Headquarters, 71-75 Shelton St, Convent Garden, London, UNITED KINGDOM		1309-517X		CONTEMP EDUC TECHNOL	Contemp. Educ. Technol.	APR	2024	16	2							ep509	10.30935/cedtech/14564	http://dx.doi.org/10.30935/cedtech/14564			13	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	TE7V0					2024-07-03	WOS:001239659800001
C	Das, D; Mathews, NS; Mathai, A; Tamilselvam, S; Sedamaki, K; Chimalakonda, S; Kumar, A			IEEE	Das, Debeshee; Mathews, Noble Saji; Mathai, Alex; Tamilselvam, Srikanth; Sedamaki, Kranthi; Chimalakonda, Sridhar; Kumar, Atul			<i>COMEX</i>: A Tool for Generating Customized Source Code Representations	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Representation Learning; Static Analysis		Learning effective representations of source code is critical for any Machine Learning for Software Engineering (ML4SE) system. Inspired by natural language processing, large language models (LLMs) like Codex and CodeGen treat code as generic sequences of text and are trained on huge corpora of code data, achieving state of the art performance on several software engineering (SE) tasks. However, valid source code, unlike natural language, follows a strict structure and pattern governed by the underlying grammar of the programming language. Current LLMs do not exploit this property of the source code as they treat code like a sequence of tokens and overlook key structural and semantic properties of code that can be extracted from code-views like the Control Flow Graph (CFG), Data Flow Graph (DFG), Abstract Syntax Tree (AST), etc. Unfortunately, the process of generating and integrating code-views for every programming language is cumbersome and time consuming. To overcome this barrier, we propose our tool COMEX - a framework that allows researchers and developers to create and combine multiple code-views which can be used by machine learning (ML) models for various SE tasks. Some salient features of our tool are: (i) it works directly on source code (which need not be compilable), (ii) it currently supports Java and C#, (iii) it can analyze both method-level snippets and program-level snippets by using both intra-procedural and inter-procedural analysis, and (iv) it is easily extendable to other languages as it is built on tree-sitter - a widely used incremental parser that supports over 40 languages. We believe this easy-to-use code-view generation and customization tool will give impetus to research in source code representation learning methods and ML4SE. The source code and demonstration of our tool can be found at https://github.com/IBM/tree- sitter-codeviews and https://youtu.be/GER6U87FVbU, respectively.	[Das, Debeshee; Mathews, Noble Saji; Sedamaki, Kranthi; Chimalakonda, Sridhar] Indian Inst Technol Tirupati, Tirupati, Andhra Pradesh, India; [Mathai, Alex; Tamilselvam, Srikanth; Kumar, Atul] IBM Res, Gurgaon, Haryana, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Tirupati	Das, D (corresponding author), Indian Inst Technol Tirupati, Tirupati, Andhra Pradesh, India.	debesheedas@gmail.com; elbonleon@gmail.com; alexmathai98@gmail.com; srikanthtamilselvam@gmail.com; skranthi4444@gmail.com; sridhar.chimalakonda@gmail.com; atulkumar@gmail.com						Allamanis M, 2018, Arxiv, DOI arXiv:1711.00740; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Nguyen AT, 2015, IEEE INT CONF AUTOM, P585, DOI 10.1109/ASE.2015.74; Barrett L, 2022, Mate: Interactive program analysis with code property graphs; Bieber D., 2022, Static prediction of runtime errors by learning to execute programs with external resource descriptions; Bieber D, 2022, Arxiv, DOI arXiv:2208.07461; Chen M., 2021, ARXIV; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hagberg A, 2020, Networkx: Network analysis with python; Hellendoorn Vincent Josua, 2020, Global relational models of source code; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; IBM, 2021, Project codenet; Johnson Daniel, 2020, Advances in Neural Information Processing Systems, V33, P2; Long T, 2022, Arxiv, DOI arXiv:2202.12481; Machiry A, 2020, P IEEE S SECUR PRIV, P1562, DOI 10.1109/SP40000.2020.00038; Mukherjee R., 2021, Neural program generation modulo static analysis, P18984; Nijkamp E., 2023, Codegen: An open large language model for code with multi-turn program synthesis; Svajlenko J, 2014, PROC IEEE INT CONF S, P476, DOI 10.1109/ICSME.2014.77; Vallee-Rai R., 1999, Proceedings of the 1999 Conference of the Centre for Advanced Studies on Collaborative Research, CASCON'99, page, P13; Vasudevan S., 2021, Adv. Neural Inf. Process. Syst., V34, P23491; Yamaguchi F, 2014, P IEEE S SECUR PRIV, P590, DOI 10.1109/SP.2014.44; Zhou Y., 2019, Advances in neural information processing systems, V32	22	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							2054	2057		10.1109/ASE56229.2023.00010	http://dx.doi.org/10.1109/ASE56229.2023.00010			4	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200196
J	Korzynski, P; Mazurek, G; Krzypkowska, P; Kurasinski, A				Korzynski, Pawel; Mazurek, Grzegorz; Krzypkowska, Pamela; Kurasinski, Artur			Artificial intelligence prompt engineering as a new digital competence: Analysis of generative AI technologies such as ChatGPT	ENTREPRENEURIAL BUSINESS AND ECONOMICS REVIEW			English	Article						artificialintelligence(AI); generativeartificialintelligence(GAI); ChatGPT; GPT-3; Bard; AI prompt engineering; digital competences; DigComp; prompting strategies		Objective: The article aims to offer a thorough examination and comprehension of the challenges and prospects connected with artificial intelligence (AI) prompt engineering. Our research aimed to create a theoretical framework that would highlight optimal approaches in the field of AI prompt engineering.Research Design & Methods: This research utilized a narrative and critical literature review and established a conceptual framework derived from existing literature taking into account both academic and practitioner sources. This article should be regarded as a conceptual work that emphasizes the best practices in the domain of AI prompt engineering.Findings: Based on the conducted deep and extensive query of academic and practitioner literature on the subject, as well as professional press and Internet portals, we identified various insights for effective AI prompt engineering. We provide specific prompting strategies.Implications & Recommendations: The study revealed the profound implications of AI prompt engineering across various domains such as entrepreneurship, art, science, and healthcare. We demonstrated how the effective crafting of prompts can significantly enhance the performance of large language models (LLMs), generating more accurate and contextually relevant results. Our findings offer valuable insights for AI practitioners, researchers, educators, and organizations integrating AI into their operations, emphasizing the need to invest time and resources in prompt engineering. Moreover, we contributed the AI PROMPT framework to the field, providing clear and actionable guidelines for text-to-text prompt engineering. Contribution & Value Added: The value of this study lies in its comprehensive exploration of AI prompt engineering as a digital competence. By building upon existing research and prior literature, this study aimed to provide a deeper understanding of the intricacies involved in AI prompt engineering and its role as a digital competence.	[Korzynski, Pawel] Kozminski Univ, Dept Int Management, Ul Jagiellonska 57-59, PL-03301 Warsaw, Poland; [Mazurek, Grzegorz] Kozminski Univ, Dept Mkt, Ul Jagiellonska 57-59, PL-03301 Warsaw, Poland; [Krzypkowska, Pamela] Microsoft Poland, Inst Math, ul Al Jerozolimskie 195A, PL-02222 Warsaw, Poland; [Kurasinski, Artur] ul Szpitalna 4 M 8A, PL-00031 Warsaw, Poland	Kozminski University; Kozminski University	Korzynski, P (corresponding author), Kozminski Univ, Dept Int Management, Ul Jagiellonska 57-59, PL-03301 Warsaw, Poland.	pkorzynski@alk.edu.pl; gmazurek@kozminski.edu.pl; pamela.krzypkowska@gmail.com; artur@revolver.pl	Mazurek, Grzegorz/P-4258-2015; Korzynski, Pawel/H-5096-2013	Mazurek, Grzegorz/0000-0002-0047-6944; Korzynski, Pawel/0000-0002-6457-4965				Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Blundell CN, 2022, COMPUT EDUC OPEN, V3, DOI 10.1016/j.caeo.2022.100093; Cuofano G., 2023, Prompt Engineering And Why It Matters To The AI Revolution; DeWitt D., 2023, Digitalization and Development, P112, DOI [10.4324/9781003367093-7, DOI 10.4324/9781003367093-7]; Ekin S, 2023, TechRxiv, DOI [10.36227/techrxiv.22683919.v2, DOI 10.36227/TECHRXIV.22683919.V2]; Falloon G, 2020, ETR&D-EDUC TECH RES, V68, P2449, DOI 10.1007/s11423-020-09767-4; Ghazvininejad M., 2022, P 2022 C EMP METH NA; Glodowska A., 2023, International Entrepreneurship Review, V9; God K., 2023, Why Prompt Engineering Is the Job of the Future; Guitert M, 2021, EUR J EDUC, V56, P133, DOI 10.1111/ejed.12430; Kelentric M., 2017, The Norwegian Centre for ICT in Education, V134, P1; Korzynski P., 2023, International Entrepreneurship Review, V9, P7, DOI [10.15678/IER.2023.0902.01, DOI 10.15678/IER.2023.0902.01]; Korzynski P, 2023, CENT EUR MANAG J, V31, P3, DOI 10.1108/CEMJ-02-2023-0091; Korzynski P, 2021, HARVARD BUS REV, V99, P29; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Ling C., 2023, working paper; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Fernández-Batanero JM, 2022, EUR J TEACH EDUC, V45, P513, DOI 10.1080/02619768.2020.1827389; Martzoukou K, 2020, J DOC, V76, P1413, DOI 10.1108/JD-03-2020-0041; Meyerson E, 2024, Arxiv, DOI [arXiv:2302.12170, 10.48550/arXiv.2302.12170, DOI 10.48550/ARXIV.2302.12170]; Microsoft, 2023, CarMax puts customers first with car research tools powered by Azure OpenAI Service; Microsoft, 2023, Strabag SE builds a risk management solution to improve efficiency using Microsoft Intelligent Data Platform; Microsoft, 2023, KPMG augments current capabilities and improves service delivery model with Azure OpenAI Service; Oppenlaender J, 2023, Arxiv, DOI [arXiv:2303.13534, 10.48550/arXiv.2303.13534]; Oppenlaender J, 2023, Arxiv, DOI arXiv:2303.13530; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Parsons G., 2023, How to use AI image prompts to generate art using DALL-E; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Popli N., 2023, The AI Job That Pays Up to $335K-and You Don't Need a Computer Engineering Background; Pozo-Sánchez S, 2020, CULT EDUC-UK, V32, P213, DOI 10.1080/11356405.2020.1741876; Ratten V., 2023, Research Methodologies for Business Management; Reisoglu I, 2020, COMPUT EDUC, V156, DOI 10.1016/j.compedu.2020.103940; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rokenes FM, 2016, COMPUT EDUC, V97, P1, DOI 10.1016/j.compedu.2016.02.014; Short C.E., 2023, J Bus Ventur Insights, V19, pe00388, DOI DOI 10.1016/J.JBVI.2023.E00388; Smith C.S., 2023, Mom, Dad, I Want To Be A Prompt Engineer; Staka Z, 2022, 2022 21ST INTERNATIONAL SYMPOSIUM INFOTEH-JAHORINA (INFOTEH), DOI 10.1109/INFOTEH53737.2022.9751285; Vuorikari Rina R., 2023, DigComp 2.2: The Digital Competence Framework for Citizens-With new examples of knowledge, skills and attitudes; Wach K, 2023, ENTREPR BUS ECON REV, V11, P7, DOI 10.15678/EBER.2023.110201; Wang JQ, 2024, Arxiv, DOI [arXiv:2304.14670, DOI 10.48550/ARXIV.2304.14670]; Wang XH, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.652594; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388	43	4	4	104	151	CRACOW UNIV ECONOMICS	KRACOW	UL RAKOWICKA 27, KRACOW, 31510, POLAND	2353-883X	2353-8821		ENTREPR BUS ECON REV	Entrepr. Bus. Econ. Rev.		2023	11	3					25	37		10.15678/EBER.2023.110302	http://dx.doi.org/10.15678/EBER.2023.110302			13	Economics	Emerging Sources Citation Index (ESCI)	Business & Economics	U2DR4		gold			2024-07-03	WOS:001082967300003
J	Sachan, S; Liu, X				Sachan, Swati; Liu (Lisa), Xi			Blockchain-based auditing of legal decisions supported by explainable AI and generative AI tools	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Legal; Law; Explainable AI; Blockchain; Generative AI; Responsible AI	EVIDENTIAL REASONING APPROACH; SCHEME; SECURE; RULE	Generative AI tools powered by Large Language Models (LLMs) have demonstrated advanced capabilities in understanding and articulating legal facts closer to the level of legal practitioners. However, scholars hold contrasting views on the reliability of the reasoning behind a decision derived from LLMs due to its black-box nature. Law firms are vigilant in recognizing the potential risks of violating confidentiality and inappropriate exposure of sensitive legal data through the prompt sent to Generative AI. This research attempts to find an equilibrium between responsible usage and control of human legal professionals over content produced by Generative AI through regular audits. It investigates the potential of Generative AI in drafting correspondence for pre-litigation decisions derived from an eXplainable AI (XAI) algorithm. This research presents an end-to-end process of designing the architecture and methodology for a blockchain-based auditing system. It detects unauthorized alterations of data repositories containing the decisions by an XAI model and automated textual explanation by Generative AI. The automated auditing by blockchain facilitates responsible usage of AI technologies and reduces discrepancies in tracing the accountability of adversarial decisions. It conceptualizes the two algorithms. First, strategic on-chain (within blockchain) and off-chain (outside blockchain) data storage in compliance with the data protection laws and critical requirements of stakeholders in a legal firm. Second, auditing by comparison of the unique signature as Merkle roots of files stored off-chain with their immutable blockchain counterpart. A case study on liability cases under tort law demonstrates the system implementation results.	[Sachan, Swati] Univ Liverpool, Management Sch, Artificial Intelligence Finance, Financial Technol FinTech & Blockchain, Chatham St, Liverpool L69 7ZH, England; [Liu (Lisa), Xi] Kennedys Law LLP, 16 John Dalton St, Manchester M2 6HY, England	University of Liverpool	Sachan, S (corresponding author), Univ Liverpool, Management Sch, Artificial Intelligence Finance, Financial Technol FinTech & Blockchain, Chatham St, Liverpool L69 7ZH, England.	Swati.Sachan@liverpool.ac.uk; Lisa.Liu@kennedysiq.com		Sachan, Dr. Swati/0000-0003-0136-0553	University of Liverpool [106897]	University of Liverpool	We are grateful to the four anonymous reviewers for their insightful comments, which significantly improved our manuscript. This work is fully funded by the University of Liverpool by the research grant 106897. We want to express gratitude to the law students who partici-pated in our experimental study; their contributions were invaluable.; their contributions were invaluable. The first author is thankful to Prof Walter Davis Jr. and Mr. Graham Fairclough for valuable advice on the integration of AI and Blockchain in legal practices.	Agyekum KOBO, 2022, IEEE SYST J, V16, P1685, DOI 10.1109/JSYST.2021.3076759; Ajevski M, 2023, LAW TEACH, V57, P352, DOI 10.1080/03069400.2023.2207426; Al-Abdulkarim L, 2014, FRONT ARTIF INTEL AP, V271, P61, DOI 10.3233/978-1-61499-468-8-61; Aleven V. A. M., 1997, Teaching case-based argumentation through a model and examples; [Anonymous], 2023, A Guide to the Data Protection Principles; [Anonymous], 1987, P 1 INT C ART INT LA; Bell J, 2013, CAMB LAW J, V72, P17, DOI 10.1017/S0008197313000238; Bendiab G, 2023, IEEE T INTELL TRANSP, V24, P3614, DOI 10.1109/TITS.2023.3236274; Biever C, 2023, NATURE, V619, P686, DOI 10.1038/d41586-023-02361-7; Binder Alexander, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P913, DOI 10.1007/978-981-10-0557-2_87; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bushard B., 2023, Workers' ChatGPT Use Restricted at More Banks-Including Goldman; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Collenette J, 2023, ARTIF INTELL, V317, DOI 10.1016/j.artint.2023.103861; Collins E., 2021, Lamda: Our breakthrough conversation technology; Conrad E., 2016, CISSP Study Guide, V3rd ed., P103; Constant A, 2024, ARTIF INTELL LAW, V32, P441, DOI 10.1007/s10506-023-09357-8; Das M, 2021, AUTOMAT CONSTR, V126, DOI 10.1016/j.autcon.2021.103682; Datta S, 2023, FUTURE GENER COMP SY, V147, P59, DOI 10.1016/j.future.2023.04.015; Davies M., 1989, Leg. Stud., V9, P67; Dempster AP, 2008, STUD FUZZ SOFT COMP, V219, P57; Du YW, 2021, INFORM SCIENCES, V547, P1201, DOI 10.1016/j.ins.2020.07.072; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Fenton N, 2016, ANNU REV STAT APPL, V3, P51, DOI 10.1146/annurev-statistics-041715-033428; Finck M., 2019, BLOCKCHAIN GEN DATA; Fu C, 2015, EUR J OPER RES, V246, P886, DOI 10.1016/j.ejor.2015.05.042; Galanti R., 2023, Eng. Appl. Artif. Intell.; Han HD, 2023, INT J ACCOUNT INF SY, V48, DOI 10.1016/j.accinf.2022.100598; Hao K, 2020, WORLD WIDE WEB, V23, P2215, DOI 10.1007/s11280-019-00761-2; Hariharasitaraman S., 2019, J. Ambient Intell. Hum. Comput., P1; Hasan HR, 2021, IEEE NETWORK, V35, P174, DOI 10.1109/MNET.021.2000442; Hasan HR, 2020, IEEE ACCESS, V8, P222093, DOI 10.1109/ACCESS.2020.3043350; Huang Q, 2022, IEEE T NETW SCI ENG, V9, P2139, DOI 10.1109/TNSE.2022.3155385; Iu K.Y., 2023, ChatGPT by OpenAI: The End of Litigation Lawyers?; Joe C.V., 2021, Artificial Intelligence and Capsule Networks, P259; Juels A, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P584; Kang P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145100; Karisma K., 2023, Blockchain: Legal and Regulatory Issues, P75; Katz D. M., 2023, GPT-4 Passes the Bar Exam; Kushwaha SS, 2022, IEEE ACCESS, V10, P6605, DOI 10.1109/ACCESS.2021.3140091; Kuzlu M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P536, DOI 10.1109/Blockchain.2019.00003; Liu B, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P468, DOI 10.1109/ICWS.2017.54; Liu X., 2019, 25 IEEE INT C AUT CO, P1; Lundberg SM, 2017, ADV NEUR IN, V30; Malhotra D, 2021, INT CONF COMMUN SYST, DOI 10.1109/COMSNETS51098.2021.9352908; Manley S, 2023, ACCOUNT RES, V30, P219, DOI 10.1080/08989621.2021.1986018; Manzoor A, 2021, J NETW COMPUT APPL, V176, DOI 10.1016/j.jnca.2020.102917; Martino R, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100254; Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008; Morris C, 1952, U PENN LAW REV, V101, P189, DOI 10.2307/3310121; Muralidharan S, 2019, I SYMP CONSUM ELECTR; Nassar M, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1340; Neil M, 2019, ARTIF INTELL LAW, V27, P403, DOI 10.1007/s10506-019-09250-3; Nepal S., 2011, Proceedings of the 2011 IEEE 4th International Conference on Cloud Computing (CLOUD 2011), P308, DOI 10.1109/CLOUD.2011.35; Nizamuddin N, 2018, LECT NOTES COMPUT SC, V10974, P199, DOI 10.1007/978-3-319-94478-4_14; Norkute M., 2021, 2021 CHI C HUM FACT, P1; OpenAI, 2023, GPT-4 Technical Report; Philip AO, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105630; Politou E, 2022, Priv Data Prot Challenges Distrib Era, V26, P151; Politou E, 2020, FUTURE GENER COMP SY, V112, P956, DOI 10.1016/j.future.2020.06.037; Pongnumkul S, 2017, 2017 26TH INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND NETWORKS (ICCCN 2017); Prakken H, 2015, ARTIF INTELL, V227, P214, DOI 10.1016/j.artint.2015.06.005; Ray PP, 2021, IEEE SYST J, V15, P85, DOI 10.1109/JSYST.2020.2963840; Reuters T., 2023, New report on ChatGPT & generative AI in law firms shows opportunities abound, even as concerns persist; Sachan S., 2021, 31 EUR C OP RES; Sachan S., 2023, Integration of Explainable Deep Neural Network with Blockchain Technology: Medical Indemnity Insurance; Sachan S, 2023, Confer Block Crypto, DOI 10.1109/ICBC56567.2023.10174925; Sachan S, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115597; Sachan S, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113100; Seavey WA, 1942, HARVARD LAW REV, V56, P72, DOI 10.2307/1334778; Shacham H, 2013, J CRYPTOL, V26, P442, DOI 10.1007/s00145-012-9129-2; Shah MehulA., 2008, Privacy-preserving audit and extraction of digital contents; Shinde R., 2021, Journal of Open Innovation: Technology, Market, and Complexity, V189; Siddiqui ZA, 2023, ENG APPL ARTIF INTEL, V118, DOI 10.1016/j.engappai.2022.105699; Song J, 2021, PROCEDIA MANUF, V53, P585, DOI 10.1016/j.promfg.2021.06.059; Stefanie Bruninghaus, 2003, P 9 INT C ART INT LA, P233, DOI DOI 10.1145/1047788.1047838; Sunyaev A., 2020, Internet Computing: Principles of Distributed Systems and Emerging Internet-Based Technologies, P265, DOI [DOI 10.1007/978-3-030-34957-8_9, 10.1007/978-3-030-34957-8_9]; SYKES AO, 1988, HARVARD LAW REV, V101, P563, DOI 10.2307/1341141; Taherdoost H, 2023, INFORMATION, V14, DOI 10.3390/info14020117; Torrey D.B., 2015, Tort Trial & Ins. Prac. LJ, V51, P749; Ribeiro MT, 2016, Arxiv, DOI [arXiv:1606.05386, 10.48550/arXiv.1606.05386]; Union E., 2016, Regulation (EU) 2016/679 (General Data Protection Regulation); Unsal E., 2023, P INT C FRONT AC RES, V1, P544; Wöhrer M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (ICBC), DOI 10.1109/ICBC51069.2021.9461109; Wu YL, 2016, IEICE T INF SYST, VE99D, P2638, DOI 10.1587/transinf.2016EDL8079; Xiao Z., 2023, IEEE Trans. Emerg. Top. Comput. Intell.; Yang JB, 2013, ARTIF INTELL, V205, P1, DOI 10.1016/j.artint.2013.09.003; Yang W., 2021, Knowledge-Based Systems; Zhang WB, 2022, FUTURE GENER COMP SY, V132, P254, DOI 10.1016/j.future.2022.02.023; Zhu HL, 2019, IEEE ACCESS, V7, P90036, DOI 10.1109/ACCESS.2019.2924486; Zikratov I, 2017, PROC CONF OPEN INNOV, P534, DOI 10.23919/FRUCT.2017.8071359	91	1	1	44	44	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	MAR	2024	129								107666	10.1016/j.engappai.2023.107666	http://dx.doi.org/10.1016/j.engappai.2023.107666		DEC 2023	25	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science; Engineering	DZ9O6					2024-07-03	WOS:001136038900001
J	Xie, YQ; Yi, JW; Shao, JW; Curl, J; Lyu, L; Chen, QF; Xie, X; Wu, FZ				Xie, Yueqi; Yi, Jingwei; Shao, Jiawei; Curl, Justin; Lyu, Lingjuan; Chen, Qifeng; Xie, Xing; Wu, Fangzhao			Defending ChatGPT against jailbreak attack via self-reminders	NATURE MACHINE INTELLIGENCE			English	Article; Early Access								ChatGPT is a societally impactful artificial intelligence tool with millions of users and integration into products such as Bing. However, the emergence of jailbreak attacks notably threatens its responsible and secure use. Jailbreak attacks use adversarial prompts to bypass ChatGPT's ethics safeguards and engender harmful responses. This paper investigates the severe yet under-explored problems created by jailbreaks as well as potential defensive techniques. We introduce a jailbreak dataset with various types of jailbreak prompts and malicious instructions. We draw inspiration from the psychological concept of self-reminders and further propose a simple yet effective defence technique called system-mode self-reminder. This technique encapsulates the user's query in a system prompt that reminds ChatGPT to respond responsibly. Experimental results demonstrate that self-reminders significantly reduce the success rate of jailbreak attacks against ChatGPT from 67.21% to 19.34%. Our work systematically documents the threats posed by jailbreak attacks, introduces and analyses a dataset for evaluating defensive interventions and proposes the psychologically inspired self-reminder technique that can efficiently and effectively mitigate against jailbreaks without further training. Interest in using large language models such as ChatGPT has grown rapidly, but concerns about safe and responsible use have emerged, in part because adversarial prompts can bypass existing safeguards with so-called jailbreak attacks. Wu et al. build a dataset of various types of jailbreak attack prompt and demonstrate a simple but effective technique to counter these attacks by encapsulating users' prompts in another standard prompt that reminds ChatGPT to respond responsibly.	[Xie, Yueqi; Shao, Jiawei; Chen, Qifeng] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Yi, Jingwei] Univ Sci & Technol China, Hefei, Peoples R China; [Curl, Justin] Tsinghua Univ, Beijing, Peoples R China; [Lyu, Lingjuan] Sony AI, Tokyo, Japan; [Xie, Xing; Wu, Fangzhao] Microsoft Res Asia, Beijing, Peoples R China	Hong Kong University of Science & Technology; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Tsinghua University; Microsoft; Microsoft Research Asia	Wu, FZ (corresponding author), Microsoft Res Asia, Beijing, Peoples R China.	fangzwu@microsoft.com		Xie, Yueqi/0000-0002-5169-3180; SHAO, Jiawei/0000-0001-8836-1430				Albert Alex, 2023, Jailbreak chat; [Anonymous], 2022, NAT MACH INTELL, V4, P1055, DOI 10.1038/s42256-022-00598-x; [Anonymous], 2023, Microsoft blogs; [Anonymous], 2023, ChatGPT-The Impact of Large Language Models on Law Enforcement; [Anonymous], 2023, GPT-4 system card; Askell A, 2021, Arxiv, DOI [arXiv:2112.00861, DOI 10.48550/ARXIV.2112.00861]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; BANDURA A, 1977, PSYCHOL REV, V84, P191, DOI 10.1037/0033-295X.84.2.191; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Carver CharlesS. Michael F. Scheier., 2001, SELF REGULATION BEHA, DOI DOI 10.1017/CBO9781139174794; Chowdhery A, 2023, J MACH LEARN RES, V24; Daryanani L., 2023, Watcher Guru; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Gollwitzer PM, 1999, AM PSYCHOL, V54, P493, DOI 10.1037//0003-066X.54.7.493; Greshake K, 2023, Arxiv, DOI arXiv:2302.12173; Harnish RJ, 2011, SOC PSYCHOL EDUC, V14, P319, DOI 10.1007/s11218-011-9152-4; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kasai Jungo, 2021, P 9 INT C LEARN REPR; Kasirzadeh A, 2022, Arxiv, DOI arXiv:2209.00731; Klang E, 2023, J THROMB HAEMOST, V21, P1055, DOI 10.1016/j.jtha.2023.01.011; Klimt B, 2004, LECT NOTES COMPUT SC, V3201, P217; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Li HR, 2023, Arxiv, DOI [arXiv:2304.05197, 10.48550/arXiv.2304.05197]; Liu Y, 2024, Arxiv, DOI [arXiv:2305.13860, DOI 10.48550/ARXIV.2305.13860, 10.48550/arXiv.2305.13860]; MADSEN CH, 1968, J APPL BEHAV ANAL, V1, P139, DOI 10.1901/jaba.1968.1-139; Meichenbaum D., 1977, Scandinavian Journal of Behaviour Therapy, V6, P185, DOI [DOI 10.1080/16506073.1977.9626708, 10.1080/16506073.1977.9626708]; Mitchell E., 2023, INT C MACHINE LEARNI, P24950; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; OpenAi, 2022, Chatgpt; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Pryzant R, 2023, Arxiv, DOI arXiv:2305.03495; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Selvi J., 2022, Exploring prompt injection attacks; Shen XY, 2024, Arxiv, DOI [arXiv:2308.03825, 10.48550/arXiv.2308.03825]; Shi F., 2023, P 11 INT C LEARN REP; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; UBS, 2023, Let's chat about ChatGPT; Wang A., 2019, Glue: A multi-task benchmark and analysis platform for natural language understanding; Wang X, 2023, P 11 INT C LEARN REP; Warren T., 2023, VERGE; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Yi J., 2023, yjw1029/self-reminder-data: v.1.0.0, DOI [10.5281/zenodo.10043052, DOI 10.5281/ZENODO.10043052]; Yi J., 2023, yjw1029/self-reminder: v.1.0.0, DOI [10.5281/zenodo.10043044, DOI 10.5281/ZENODO.10043044]; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang T. J., 2023, P 40 INT C MACH LEAR, P41414; Zhou D.W., 2023, P 11 INT C LEARN REP	55	3	3	14	14	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	2023 DEC 12	2023										10.1038/s42256-023-00765-8	http://dx.doi.org/10.1038/s42256-023-00765-8		DEC 2023	16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CN2R8		Green Submitted			2024-07-03	WOS:001125868200001
C	Li, C; Qi, WJ; Jin, BL; Demestichas, P; Tsagkaris, K; Kritikou, Y; Guo, WS			IEEE	Li, Chen; Qi, Weijie; Jin, Bailu; Demestichas, Panagiotis; Tsagkaris, Kostas; Kritikou, Yiouli; Guo, Weisi			Quality-of-Trust in 6G: Combining Emotional and Physical Trust through Explainable AI	2023 IEEE 98TH VEHICULAR TECHNOLOGY CONFERENCE, VTC2023-FALL	IEEE Vehicular Technology Conference Proceedings		English	Proceedings Paper	98th IEEE Vehicular Technology Conference (VTC-Fall)	OCT 10-13, 2023	Hong Kong, HONG KONG	IEEE, IEEE VTS		machine learning; deep learning; XAI; wireless; trust; sentiment; NLP; LLM	CHALLENGES	Wireless networks like many multi-user services have to balance limited resources in real-time. In 6G, increased network automation makes consumer trust crucial. Trust is reflect in both a personal emotional sentiment as well as a physical understanding of the transparency of AI decision making. Whilst there has been isolated studies of consumer sentiment to wireless services, this is not well linked to the decision making engineering. Likewise, limited recent research in explainable AI (XAI) has not established a link to consumer perception. Here, we develop a Quality-of-Trust (QoT) KPI that balances personal perception with the quality of decision explanation. That is to say, the QoT varies with both the time-varying sentiment of the consumer as well as the accuracy of XAI outcomes. We demonstrate this idea with an example in Neural Water-Filling (N-WF) power allocation, where the channel capacity is perceived by artificial consumers that communicate through Large Language Model (LLM) generated text feedback. Natural Language Processing (NLP) analysis of emotional feedback is combined with a physical understanding of N-WF decisions via meta-symbolic XAI. Combined they form the basis for QoT. Our results show that whilst the XAI interface can explain up to 98.9% of the neural network decisions, a small proportion of explanations can have large errors causing drops in QoT. These drops have immediate transient effects in the physical mistrust, but emotional perception of consumers are more persistent. As such, QoT tends to combine both instant physical mistrust and long-term emotional trends.	[Li, Chen; Jin, Bailu; Guo, Weisi] Cranfield Univ, Cranfield, Beds, England; [Qi, Weijie; Demestichas, Panagiotis; Tsagkaris, Kostas; Kritikou, Yiouli; Guo, Weisi] WINGS ICT, Athens, Greece	Cranfield University	Li, C (corresponding author), Cranfield Univ, Cranfield, Beds, England.				EC H2020 Grant [778305]; EPSRC [EP/X040518/1]	EC H2020 Grant; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	We acknowledge funding from EC H2020 Grant 778305 -DAWN4IoE: Data Aware Wireless Network for Internet-of-Everything, and EPSRC Grant EP/X040518/1 -CHEDDAR: Communications Hub For Empowering Distributed ClouD Computing Applications And Research.	Agarwal B., 2023, IEEE Communications Magazine, V61; Alaa AM, 2019, ADV NEUR IN, V32; Banovic-Curguz N, 2019, 2019 42ND INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P404, DOI [10.23919/MIPRO.2019.8757034, 10.23919/mipro.2019.8757034]; Glass Alyssa, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P227, DOI 10.1145/1378773.1378804; Guo WS, 2020, IEEE COMMUN MAG, V58, P39, DOI 10.1109/MCOM.001.2000050; Hashmi US, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcfall.2019.8891552; Hossfeld T, 2017, INT WORK QUAL MULTIM; Kim H, 2020, IEEE NETWORK, V34, P288, DOI 10.1109/MNET.011.2000245; Li C, 2020, IEEE VEH TECHNOL MAG, V15, P112, DOI 10.1109/MVT.2020.3017181; Liang F, 2020, IEEE T COMMUN, V68, P1760, DOI 10.1109/TCOMM.2019.2957482; Ma B, 2020, IEEE ACCESS, V8, P35606, DOI 10.1109/ACCESS.2020.2975004; Orsino A, 2018, IEEE VEH TECHNOL MAG, V13, P120, DOI 10.1109/MVT.2017.2772646; Park JS, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545616; Qi W., 2019, 2019 IEEE INT SMART; Qi WJ, 2019, IEEE ACCESS, V7, P113726, DOI 10.1109/ACCESS.2019.2935200; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; She W, 2019, IEEE ACCESS, V7, P38947, DOI 10.1109/ACCESS.2019.2902811; Sun HR, 2017, IEEE INT WORK SIGN P; Sun S. C., 2020, 2020 IEEE 91 VEHICUL, P1; Yang BW, 2016, IEEE WIREL COMMUN LE, V5, P380, DOI 10.1109/LWC.2016.2561924; Yang L, 2022, IEEE NETWORK, V36, P134, DOI 10.1109/MNET.003.2100672; Zhao L, 2013, 2013 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MCC)	22	0	0	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2577-2465		979-8-3503-2928-5	IEEE VTS VEH TECHNOL			2023										10.1109/VTC2023-Fall60731.2023.10333364	http://dx.doi.org/10.1109/VTC2023-Fall60731.2023.10333364			7	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BW2ZI					2024-07-03	WOS:001133762500019
J	Freire, Y; Laorden, AS; Pérez, JO; Sánchez, MG; García, VDF; Suárez, A				Freire, Yolanda; Laorden, Andrea Santamaria; Perez, Jaime Orejas; Sanchez, Margarita Gomez; Garcia, Victor Diaz -Flores; Suarez, Ana			ChatGPT performance in prosthodontics: Assessment of accuracy and repeatability in answer generation	JOURNAL OF PROSTHETIC DENTISTRY			English	Article							ARTIFICIAL-INTELLIGENCE	Statement of problem. The artificial intelligence (AI) software program ChatGPT is based on large language models (LLMs) and is widely accessible. However, in prosthodontics, little is known about its performance in generating answers. Purpose. The purpose of this study was to determine the performance of ChatGPT in generating answers about removable dental prostheses (RDPs) and tooth -supported fixed dental prostheses (FDPs). Material and methods. Thirty short questions were designed about RDPs and tooth -supported FDP, and 30 answers were generated for each of the questions using ChatGPT-4 in October 2023. The 900 generated answers were independently graded by experts using a 3 -point Likert scale. The relative frequency and absolute percentage of answers were described. Accuracy was assessed using the Wald binomial method, while repeatability was evaluated using percentage agreement, Brennan and Prediger coefficient, Conger generalized Cohen kappa, Fleiss kappa, Gwet AC, and Krippendorff alpha methods. Confidence intervals were set at 95%. Statistical analysis was performed using the STATA software program. Results. The performance of ChatGPT in generating answers related to RDP and tooth -supported FDP was limited. The answers showed a reliability of 25.6%, with a confidence range between 22.9% and 28.6%. The repeatability ranged from substantial to moderate. Conclusions. The results show that currently ChatGPT has limited ability to generate answers related to RDPs and tooth -supported FDPs. Therefore, ChatGPT cannot replace a dentist, and, if professionals were to use it, they should be aware of its limitations. (J Prosthet Dent 2024;131:659.e1 -e6)	[Freire, Yolanda; Laorden, Andrea Santamaria; Perez, Jaime Orejas; Garcia, Victor Diaz -Flores; Suarez, Ana] European Univ Madrid UEM, Fac Biomed & Hlth Sci, Dept Preclin Dent, S-N Calle Tajo, Madrid 28670, Spain; [Sanchez, Margarita Gomez] European Univ Madrid UEM, Fac Biomed & Hlth Sci, Dept Preclin Dent & Clin Dent, Dent, Madrid, Spain	European University of Madrid; European University of Madrid	García, VDF (corresponding author), European Univ Madrid UEM, Fac Biomed & Hlth Sci, Dept Preclin Dent, S-N Calle Tajo, Madrid 28670, Spain.		Suarez, Ana/ABB-2464-2021	Suarez, Ana/0000-0003-2448-6669				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Aminoshariae A, 2021, J ENDODONT, V47, P1352, DOI 10.1016/j.joen.2021.06.003; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Barrington Nikki M, 2023, Med Sci (Basel), V11, DOI 10.3390/medsci11030061; British Society for Restorative Dentistry, 2013, Crowns, Fixed Bridges and Dental Implants: Guidelines; Coskun BN, 2024, RHEUMATOL INT, V44, P509, DOI 10.1007/s00296-023-05473-5; Danesh A, 2023, J AM DENT ASSOC, V154, P970, DOI 10.1016/j.adaj.2023.07.016; Dashti M, 2023, J Prosthet Dent; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Deiana G, 2023, VACCINES-BASEL, V11, DOI 10.3390/vaccines11071217; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Gwet K. L., 2014, Handbook of inter-rater reliability: The definitive guide to measuring the extent of agreement among raters, V4th; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; Krusche M, 2024, RHEUMATOL INT, V44, P303, DOI 10.1007/s00296-023-05464-6; Mago J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42133; Ogden A., 1996, Guidelines in Prosthetic and Implant Dentistry. Guidelines on standards for the treatment of patients using endosseous implants; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Revilla-León M, 2023, J PROSTHET DENT, V129, P276, DOI 10.1016/j.prosdent.2021.06.001; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singi SR, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.30962; Suárez A, 2024, COMPUT STRUCT BIOTEC, V24, P46, DOI 10.1016/j.csbj.2023.11.058; Suárez A, 2024, INT ENDOD J, V57, P108, DOI 10.1111/iej.13985; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	24	2	2	2	2	MOSBY-ELSEVIER	NEW YORK	360 PARK AVENUE SOUTH, NEW YORK, NY 10010-1710 USA	0022-3913	1097-6841		J PROSTHET DENT	J. Prosthet. Dent.	APR	2024	131	4								10.1016/j.prosdent.2024.01.018	http://dx.doi.org/10.1016/j.prosdent.2024.01.018			6	Dentistry, Oral Surgery & Medicine	Science Citation Index Expanded (SCI-EXPANDED)	Dentistry, Oral Surgery & Medicine	QX1J5	38310063				2024-07-03	WOS:001224073300001
J	Mahajan, D; Liang, JJ; Tsou, CH; Uzuner, Ö				Mahajan, Diwakar; Liang, Jennifer J.; Tsou, Ching-Huei; Uzuner, Ozlem			Overview of the 2022 n2c2 shared task on contextualized medication event extraction in clinical notes	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Medication information; Natural language processing; Clinical informatics; Electronic health records; Information extraction; Shared task	INFORMATION; DESIGN	Background: An accurate medication history, foundational for providing quality medical care, requires understanding of medication change events documented in clinical notes. However, extracting medication changes without the necessary clinical context is insufficient for real-world applications. Methods: To address this need, Track 1 of the 2022 National NLP Clinical Challenges focused on extracting the context for medication changes documented in clinical notes using the Contextualized Medication Event Dataset. Track 1 consisted of 3 subtasks: extracting medication mentions from clinical notes (NER), determining whether a medication change is being discussed (Event), and determining the action, negation, temporality, certainty, and actor for any change events (Context). Participants were allowed to participate in any one or more of the subtasks. Results: A total of 32 teams with participants from 19 countries submitted a total of 211 systems across all subtasks. Most teams formulated NER as a token classification task and Event and Context as multiclass classification tasks, using transformer-based large language models. Overall, performance for NER was high across submitted systems. However, performance for Event and Context were much lower, often due to indirectly stated change events with no clear action verb, events requiring farther textual clues for understanding, and medication mentions with multiple change events. Conclusions: This shared task showed that while NLP research on medication extraction is relatively mature, understanding of contextual information surrounding medication events in clinical notes is still an open problem requiring further research to achieve the end goal of supporting real-world clinical applications.	[Mahajan, Diwakar; Liang, Jennifer J.; Tsou, Ching-Huei] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA; [Uzuner, Ozlem] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA USA	International Business Machines (IBM); George Mason University	Liang, JJ (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.	jjliang@us.ibm.com	Tsou, Ching-Huei/JCE-1997-2023	Uzuner, Ozlem/0000-0001-8011-9850	National Institutes of Health, National Library of Medicine, United States of America [R13LM013127]	National Institutes of Health, National Library of Medicine, United States of America	This work was supported in part by the National Institutes of Health, National Library of Medicine, United States of America grant number R13LM013127 (OU) . The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.	[Anonymous], 2017, Overview of the TAC 2017 Adverse Reaction Extraction from Drug Labels Track; Belden JL, 2019, J AM MED INFORM ASSN, V26, P95, DOI 10.1093/jamia/ocy143; Cadwallader J, 2013, APPL CLIN INFORM, V4, P110, DOI 10.4338/ACI-2012-12-RA-0057; Fan YD, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0626-6; Fan YD, 2016, IEEE INT C BIOINFORM, P1054, DOI 10.1109/BIBM.2016.7822668; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Jagannatha A, 2019, DRUG SAFETY, V42, P99, DOI 10.1007/s40264-018-0762-z; Jensen PB, 2012, NAT REV GENET, V13, P395, DOI 10.1038/nrg3208; Kumar V, 2015, J BIOMED INFORM, V58, pS6, DOI 10.1016/j.jbi.2015.09.018; Lerner I, PREPRINT; Liu FF, 2019, J AM MED INFORM ASSN, V26, P943, DOI 10.1093/jamia/ocz048; Liu Mei, 2011, AMIA Annu Symp Proc, V2011, P815; Mahajan Diwakar, 2021, AMIA Annu Symp Proc, V2021, P833; Meystre SM, 2015, STUD HEALTH TECHNOL, V216, P609, DOI 10.3233/978-1-61499-564-7-609; Noreen EW, 1989, Computer-intensive methods for testing hypotheses: an introduction; Pakhomov SV, 2002, AMIA 2002 SYMPOSIUM, PROCEEDINGS, P587; Plaisant C., 2003, The Craft of Information Visualization, P308, DOI DOI 10.1016/B978-155860915-0/50038-X; Poon EG, 2006, J AM MED INFORM ASSN, V13, P581, DOI 10.1197/jamia.M2142; Sohn Sunghwan, 2010, AMIA Annu Symp Proc, V2010, P762; Stubbs A, 2015, J BIOMED INFORM, V58, pS67, DOI 10.1016/j.jbi.2015.07.001; Stubbs A, 2015, J BIOMED INFORM, V58, pS11, DOI 10.1016/j.jbi.2015.06.007; Turchin A, 2009, J AM MED INFORM ASSN, V16, P362, DOI 10.1197/jamia.M2777; Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203; Uzuner Ö, 2010, J AM MED INFORM ASSN, V17, P514, DOI 10.1136/jamia.2010.003947	24	2	2	3	5	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	AUG	2023	144								104432	10.1016/j.jbi.2023.104432	http://dx.doi.org/10.1016/j.jbi.2023.104432		JUL 2023	10	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	M3MH3	37356640	hybrid			2024-07-03	WOS:001029248300001
C	Guilherme, VH; Vincenzi, AMR			ACM	Guilherme, Vitor H.; Vincenzi, Auri M. R.			An initial investigation of ChatGPT unit test generation capability	PROCEEDINGS OF THE 8TH BRAZILIAN SYMPOSIUM ON SYSTEMATIC AND AUTOMATED SOFT-WARE TESTING, SAST 2023			English	Proceedings Paper	8th Brazilian Symposium on Systematic and Automated Software Testing (SAST)	SEP 25-29, 2023	Campo Grande, BRAZIL	Brazilian Comp Soc, Univ Fed Mato Grosso Sul, UFMS, FACOM, Soc Brasileira Computacao, Comissao Especial Engn Software		software testing; experimental software engineering; automated test generation; coverage testing; mutation testing; testing tools		Context: Software testing ensures software quality, but developers often disregard it. The use of automated testing generation is pursued to reduce the consequences of overlooked test cases in a software project. Problem: In the context of Java programs, several tools can completely automate generating unit test sets. Additionally, studies are conducted to offer evidence regarding the quality of the generated test sets. However, it is worth noting that these tools rely on machine learning and other AI algorithms rather than incorporating the latest advancements in Large Language Models (LLMs). Solution: This work aims to evaluate the quality of Java unit tests generated by an OpenAI LLM algorithm, using metrics like code coverage and mutation test score. Method: For this study, 33 programs used by other researchers in the field of automated test generation were selected. This approach was employed to establish a baseline for comparison purposes. For each program, 33 unit test sets were generated automatically, without human interference, by changing Open AI API parameters. After executing each test set, metrics such as code line coverage, mutation score, and success rate of test execution were collected to evaluate the efficiency and effectiveness of each set. Summary of Results: Our findings revealed that the OpenAI LLM test set demonstrated similar performance across all evaluated aspects compared to traditional automated Java test generation tools used in the previous research. These results are particularly remarkable considering the simplicity of the experiment and the fact that the generated test code did not undergo human analysis.	[Guilherme, Vitor H.; Vincenzi, Auri M. R.] Univ Fed Sao Carlos, Sao Carlos, SP, Brazil	Universidade Federal de Sao Carlos	Guilherme, VH (corresponding author), Univ Fed Sao Carlos, Sao Carlos, SP, Brazil.	vitor.guilherme@estudante.ufscar.br; auri@ufscar.br	Vincenzi, Auri Marcelo Rizzo/D-8465-2013	Vincenzi, Auri Marcelo Rizzo/0000-0001-5902-1672	Brazilian Funding Agency FAPESP [2019/23160-0]; Brazilian Funding Agency CNPq; Brazilian Funding Agency CAPES [001]	Brazilian Funding Agency FAPESP(Fundacao de Amparo a Pesquisa do Estado de Sao Paulo (FAPESP)); Brazilian Funding Agency CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); Brazilian Funding Agency CAPES(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES))	This work is partially supported by Brazilian Funding Agencies CAPES -Grant 001, FAPESP -Grant no 2019/23160-0, and CNPq.	Abdi Mehrdad, 2022, CEUR WORKSHOP P, V1, P10; Andrews JH, 2005, PROC INT CONF SOFTW, P402, DOI 10.1145/1062455.1062530; Araujo FS, 2020, PROCEEDINGS OF THE 19TH BRAZILIAN SYMPOSIUM ON SOFTWARE QUALITY, SBOS 2020, DOI 10.1145/3439961.3439977; Arcuri A, 2016, IEEE INT CONF SOFTW, P401, DOI 10.1109/ICST.2016.44; Barr ET, 2015, IEEE T SOFTWARE ENG, V41, P507, DOI 10.1109/TSE.2014.2372785; Chen YH, 2024, Arxiv, DOI arXiv:2305.04764; Coles Henry, 2015, PITest: real world mutation testing; DEMILLO RA, 1978, COMPUTER, V11, P34, DOI 10.1109/C-M.1978.218136; Fernandes L, 2022, 36TH BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING, SBES 2022, P198, DOI 10.1145/3555228.3555233; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2016, 2016 IEEE/ACM 9TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST), P33, DOI [10.1109/SBST.2016.014, 10.1145/2897010.2897020]; Fraser G, 2014, ACM T SOFTW ENG METH, V24, DOI 10.1145/2685612; Jia Y, 2011, IEEE T SOFTWARE ENG, V37, P649, DOI 10.1109/TSE.2010.62; Just R, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P654, DOI 10.1145/2635868.2635929; Li Tsz-On, 2023, Finding Failure-Inducing Test Cases with ChatGPT; Liu Z, 2023, Arxiv, DOI arXiv:2305.09434; Ma W, 2024, Arxiv, DOI arXiv:2305.12138; OpenAI, 2023, OpenAI GTP-3.5 Models Documentation; Pacheco Carlos, 2007, OOPSLA 07 COMPANION, P815, DOI [10.1145/1297846.1297902, DOI 10.1145/1297846.1297902]; Ribeiro Marco Tulio, 2023, Testing Language Models (and Prompts) Like We Test Software; Roper M., 1994, SOFTWARE TESTING; Sakti A, 2015, 2015 IEEE/ACM 8TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST), P52, DOI 10.1109/SBST.2015.20; Schweikl S, 2022, 15TH SEARCH-BASED SOFTWARE TESTING WORKSHOP (SBST 2022), P33, DOI 10.1145/3526072.3527526; Siddiq ML, 2024, Arxiv, DOI arXiv:2305.00418; Vaswani A, 2017, ADV NEUR IN, V30; Vincenzi AuriM. R., 2016, Proceedings of the 7th International Workshop on Automating Test Case Design, Selection, P23, DOI DOI 10.1145/2994291.2994295; Vogl S, 2021, 2021 IEEE/ACM 14TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST 2021), P28, DOI 10.1109/SBST52555.2021.00012; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zhang S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1182, DOI 10.1145/1985793.1986036	30	1	2	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1629-4				2023							15	24		10.1145/3624032.3624035	http://dx.doi.org/10.1145/3624032.3624035			10	Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KT					2024-07-03	WOS:001150657900003
J	Zhou, HY; Skolnick, J				Zhou, Hongyi; Skolnick, Jeffrey			Utility of the Morgan Fingerprint in Structure-Based Virtual Ligand Screening	JOURNAL OF PHYSICAL CHEMISTRY B			English	Article							SCORING FUNCTION; DOCKING; OPTIMIZATION; DISCOVERY	In modern drug discovery, virtual ligand screening (VLS) is frequently applied to identify possible hits before experimental testing and refinement due to its cost-effective nature for large compound libraries. For decades, efforts have been devoted to developing VLS methods with high accuracy. These include the state-of-the-art FINDSITE suite of approaches FINDSITEcomb2.0, FRAGSITE, and FRAGSITE2 and the meta version FRAGSITE(comb) that were developed in our lab. These methods combine ligand homology modeling (LHM), traditional ligand similarity methods, and more recently machine learning approaches to rank ligands and have proven to be superior to most recent deep learning and large language model-based approaches. Here, we describe further improvements to our previous best methods by combining the Morgan fingerprint (MF) with the originally used PubChem fingerprint and FP2 fingerprint. We then benchmarked FINDSITEcomb2.0M, FRAGSITE(M), FRAGSITE2(M), and the composite meta-approach FRAGSITE(combM). On the 102 target DUD-E set, the 1% enrichment factor (EF1%) and area under the precision-recall curve (AUPR) of FRAGSITE(comb) increased from 42.0/0.59 to 47.6/0.72. This 0.72 AUPR is significantly better than that of the state-of-the-art deep learning-based method DenseFS's AUPR of 0.443. An independent test on the 81 targets DEKOIS2.0 set shows that EF1%/AUPR increases from 18.3/0.520 to 23.1/0.683. An ablation investigation shows that the MF contributes to most of the improvement of all four approaches. Thus, the MF is a useful addition to structure-based VLS.	[Zhou, Hongyi; Skolnick, Jeffrey] Georgia Inst Technol, Ctr Study Syst Biol, Sch Biol Sci, Atlanta, GA 30332 USA	University System of Georgia; Georgia Institute of Technology	Skolnick, J (corresponding author), Georgia Inst Technol, Ctr Study Syst Biol, Sch Biol Sci, Atlanta, GA 30332 USA.	skolnick@gatech.edu		Skolnick, Jeffrey/0000-0002-1877-4958	National Institute of General Medical Sciences [R35GM118039]; Division of General Medical Sciences of the NIH	National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); Division of General Medical Sciences of the NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	We thank Bartosz Ilkowski for computing support and Jessica Forness for proof reading the manuscript. This project was funded by R35GM118039 of the Division of General Medical Sciences of the NIH.	Allen WJ, 2015, J COMPUT CHEM, V36, P1132, DOI 10.1002/jcc.23905; Anonymous, 2007, DAYLIGHT THEORY MANU; Bauer MR, 2013, J CHEM INF MODEL, V53, P1447, DOI [10.1021/ci400115b, 10.1021/ci400115bl]; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Brylinski M, 2008, P NATL ACAD SCI USA, V105, P129, DOI 10.1073/pnas.0707684105; Brylinski M, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000405; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Crampon K, 2022, DRUG DISCOV TODAY, V27, P151, DOI 10.1016/j.drudis.2021.09.007; Davis J., 2006, P 23 INT C MACH LEAR, P233, DOI DOI 10.1145/1143844.1143874; Flower DR, 1998, J CHEM INF COMP SCI, V38, P379, DOI 10.1021/ci970437z; Friesner RA, 2004, J MED CHEM, V47, P1739, DOI 10.1021/jm0306430; GAULTON A, 2012, NUCL ACIDS RES, V0040; Glen RC, 2006, QSAR COMB SCI, V25, P1133, DOI 10.1002/qsar.200610097; Imrie F, 2018, J CHEM INF MODEL, V58, P2319, DOI 10.1021/acs.jcim.8b00350; Jain AN, 2003, J MED CHEM, V46, P499, DOI 10.1021/jm020406h; Keiser MJ, 2007, NAT BIOTECHNOL, V25, P197, DOI 10.1038/nbt1284; Kim Sunghwan, 2019, Nucleic Acids Res, V47, pD1102, DOI 10.1093/nar/gky1033; Kroemer RT, 2007, CURR PROTEIN PEPT SC, V8, P312; Livyatan I, 2015, CELL STEM CELL, V17, P647, DOI 10.1016/j.stem.2015.11.015; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Mysinger MM, 2012, J MED CHEM, V55, P6582, DOI 10.1021/jm300687e; O'Boyle NM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-33; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Ragoza M, 2017, J CHEM INF MODEL, V57, P942, DOI 10.1021/acs.jcim.6b00740; Riniker S, 2013, J CHEMINFORMATICS, V5, DOI 10.1186/1758-2946-5-26; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; Rohrer SG, 2009, J CHEM INF MODEL, V49, P169, DOI 10.1021/ci8002649; Singh R, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2220778120; Stein RM, 2020, NATURE, V579, P609, DOI 10.1038/s41586-020-2027-0; Tran-Nguyen VK, 2020, J CHEM INF MODEL, V60, P4263, DOI 10.1021/acs.jcim.0c00155; Truhlar DG, 2007, J COMPUT CHEM, V28, P73, DOI 10.1002/jcc.20529; Willett P, 2006, DRUG DISCOV TODAY, V11, P1046, DOI 10.1016/j.drudis.2006.10.005; Wishart DS, 2006, NUCLEIC ACIDS RES, V34, pD668, DOI 10.1093/nar/gkj067; Wójcikowski M, 2017, SCI REP-UK, V7, DOI 10.1038/srep46710; Yap CW, 2011, J COMPUT CHEM, V32, P1466, DOI 10.1002/jcc.21707; Zhang Y, 2007, PROTEINS, V68, P1020, DOI 10.1002/prot.21643; Zhou HY, 2024, PROTEIN SCI, V33, DOI 10.1002/pro.4869; Zhou HY, 2021, J CHEM INF MODEL, V61, P2074, DOI 10.1021/acs.jcim.0c01160; Zhou HY, 2018, J CHEM INF MODEL, V58, P2343, DOI 10.1021/acs.jcim.8b00309; Zhou HY, 2013, J CHEM INF MODEL, V53, P230, DOI 10.1021/ci300510n; Zhou HY, 2012, PROTEINS, V80, P352, DOI 10.1002/prot.23183	41	0	0	0	0	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1520-6106	1520-5207		J PHYS CHEM B	J. Phys. Chem. B	MAY 24	2024	128	22					5363	5370		10.1021/acs.jpcb.4c01875	http://dx.doi.org/10.1021/acs.jpcb.4c01875		MAY 2024	8	Chemistry, Physical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	TM6L6	38783525	hybrid			2024-07-03	WOS:001231821400001
J	Mashatian, S; Armstrong, DG; Ritter, A; Robbins, J; Aziz, S; Alenabi, I; Huo, M; Anand, T; Tavakolian, K				Mashatian, Shayan; Armstrong, David G.; Ritter, Aaron; Robbins, Jeffery; Aziz, Shereen; Alenabi, Ilia; Huo, Michelle; Anand, Taneeka; Tavakolian, Kouhyar			Building Trustworthy Generative Artificial Intelligence for Diabetes Care and Limb Preservation: A Medical Knowledge Extraction Case	JOURNAL OF DIABETES SCIENCE AND TECHNOLOGY			English	Article; Early Access						generative AI; knowledge extraction; LLM; diabetes self-education; layperson education; trustworthy AI; few-shot learning; diabetic foot ulcer		Background: Large language models (LLMs) offer significant potential in medical information extraction but carry risks of generating incorrect information. This study aims to develop and validate a retriever-augmented generation (RAG) model that provides accurate medical knowledge about diabetes and diabetic foot care to laypersons with an eighth-grade literacy level. Improving health literacy through patient education is paramount to addressing the problem of limb loss in the diabetic population. In addition to affecting patient well-being through improved outcomes, improved physician well-being is an important outcome of a self-management model for patient health education.Methods: We used an RAG architecture and built a question-and-answer artificial intelligence (AI) model to extract knowledge in response to questions pertaining to diabetes and diabetic foot care. We utilized GPT-4 by OpenAI, with Pinecone as a vector database. The NIH National Standards for Diabetes Self-Management Education served as the basis for our knowledge base. The model's outputs were validated through expert review against established guidelines and literature. Fifty-eight keywords were used to select 295 articles and the model was tested against 175 questions across topics.Results: The study demonstrated that with appropriate content volume and few-shot learning prompts, the RAG model achieved 98% accuracy, confirming its capability to offer user-friendly and comprehensible medical information.Conclusion: The RAG model represents a promising tool for delivering reliable medical knowledge to the public which can be used for self-education and self-management for diabetes, highlighting the importance of content validation and innovative prompt engineering in AI applications.	[Mashatian, Shayan; Tavakolian, Kouhyar] Univ North Dakota, Biomed Engn Program, 4200 James Ray Dr, Grand Forks, ND 58202 USA; [Mashatian, Shayan; Aziz, Shereen; Alenabi, Ilia] Silverberry Grp Inc, Grand Forks, ND USA; [Armstrong, David G.] Univ Southern Calif, Keck Sch Med, Los Angeles, CA USA; [Ritter, Aaron] US Dept Vet Affairs, Little Rock, AR USA; [Robbins, Jeffery] US Dept Vet Affairs, Washington, DC USA; [Huo, Michelle] Univ Calif Los Angeles, Dept Life Sci, Los Angeles, CA USA; [Anand, Taneeka] Emory Univ, Oxford Coll, Oxford, GA USA	University of North Dakota Grand Forks; University of Southern California; US Department of Veterans Affairs; US Department of Veterans Affairs; University of California System; University of California Los Angeles; Emory University	Mashatian, S (corresponding author), Univ North Dakota, Biomed Engn Program, 4200 James Ray Dr, Grand Forks, ND 58202 USA.	shayan@silverberry.ai		Mashatian, Shayan/0000-0003-2131-3367; Alenabi, Ilia/0009-0003-1844-3213	Silverberry Group, Inc.; National Institutes of Health, National Institute of Diabetes and Digestive and Kidney Diseases Award [1R01124789-01A1]; National Science Foundation (NSF) Center to Stream Healthcare in Place (#C2SHiP) CNS Award [2052578]	Silverberry Group, Inc.; National Institutes of Health, National Institute of Diabetes and Digestive and Kidney Diseases Award; National Science Foundation (NSF) Center to Stream Healthcare in Place (#C2SHiP) CNS Award(National Science Foundation (NSF))	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was sponsored by Silverberry Group, Inc. This study is partially supported by the National Institutes of Health, National Institute of Diabetes and Digestive and Kidney Diseases Award Number 1R01124789-01A1. This study is partially supported by the National Science Foundation (NSF) Center to Stream Healthcare in Place (#C2SHiP) CNS Award Number 2052578.	American Medical Association, 6 big things that must change to beat physician burnout; Armstrong DG, 2023, JAMA-J AM MED ASSOC, V330, P62, DOI 10.1001/jama.2023.10578; Armstrong DG, 2020, J FOOT ANKLE RES, V13, DOI 10.1186/s13047-020-00383-2; Armstrong DG., 2021, Nutrition Interventions in Adults With Diabetic Foot Ulcers; Bagde H, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e23050; Donnelly HR, 2024, INT WOUND J, V21, DOI 10.1111/iwj.14483; Funnell MM, 2010, DIABETES CARE, V33, pS89, DOI [10.2337/dc11-S089, 10.2337/dc10-S089]; Hoffstad O, 2015, DIABETES CARE, V38, P1852, DOI 10.2337/dc15-0536; International Diabetes Federation, 2020, The Diabetic Foot; Kessels RPC, 2003, J ROY SOC MED, V96, P219, DOI 10.1258/jrsm.96.5.219; McDermott K, 2023, DIABETES CARE, V46, P209, DOI 10.2337/dci22-0043; Meloni M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9061780; Paterick Timothy E, 2017, Proc (Bayl Univ Med Cent), V30, P112; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Qiu Y., 2024, Intell Syst Appl, V21, P200308, DOI [10.1016/j.iswa.2023.200308., DOI 10.1016/J.ISWA.2023.200308]; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thomas LR, 2018, JAMA-J AM MED ASSOC, V319, P1541, DOI 10.1001/jama.2018.1331; Timmers T, 2020, J MED INTERNET RES, V22, DOI 10.2196/17342	18	0	0	9	9	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1932-2968			J DIABETES SCI TECHN	J. Diabetes Sci. Technol.	2024 MAY 20	2024										10.1177/19322968241253568	http://dx.doi.org/10.1177/19322968241253568		MAY 2024	7	Endocrinology & Metabolism	Emerging Sources Citation Index (ESCI)	Endocrinology & Metabolism	RM7C7	38767382				2024-07-03	WOS:001228135600001
J	Karkera, N; Acharya, S; Palaniappan, SK				Karkera, Nikitha; Acharya, Sathwik; Palaniappan, Sucheendra K.			Leveraging pre-trained language models for mining microbiome-disease relationships	BMC BIOINFORMATICS			English	Article						Microbe-disease relationship extraction; Language models; Fine-tuning; Deep-learning; Transfer learning; Biomedical informatics; Natural language processing	DATABASE	Background: The growing recognition of the microbiome's impact on human health and well-being has prompted extensive research into discovering the links between microbiome dysbiosis and disease (healthy) states. However, this valuable information is scattered in unstructured form within biomedical literature. The struc-tured extraction and qualification of microbe-disease interactions are important. In parallel, recent advancements in deep-learning-based natural language processing algorithms have revolutionized language-related tasks such as ours. This study aims to leverage state-of-the-art deep-learning language models to extract microbe-disease relationships from biomedical literature.Results: In this study, we first evaluate multiple pre-trained large language models within a zero-shot or few-shot learning context. In this setting, the models performed poorly out of the box, emphasizing the need for domain-specific fine-tuning of these language models. Subsequently, we fine-tune multiple language models (specifi-cally, GPT-3, BioGPT, BioMedLM, BERT, BioMegatron, PubMedBERT, BioClinicalBERT, and BioLinkBERT) using labeled training data and evaluate their performance. Our experimental results demonstrate the state-of-the-art performance of these fine-tuned models ( specifically GPT-3, BioMedLM, and BioLinkBERT), achieving an average F1 score, precision, and recall of over > 0.8 compared to the previous best of 0.74.Conclusion: Overall, this study establishes that pre-trained language models excel as transfer learners when fine-tuned with domain and problem-specific data, enabling them to achieve state-of-the-art results even with limited training data for extracting microbiome-disease interactions from scientific publications.	[Acharya, Sathwik; Palaniappan, Sucheendra K.] Syst Biol Inst, Tokyo, Japan; [Palaniappan, Sucheendra K.] Iom Bioworks Pvt Ltd, Bengaluru, India; [Acharya, Sathwik] PES Univ, Bengaluru, India; [Karkera, Nikitha; Palaniappan, Sucheendra K.] SBX Corp, Tokyo, Japan	PES University	Palaniappan, SK (corresponding author), Syst Biol Inst, Tokyo, Japan.; Palaniappan, SK (corresponding author), Iom Bioworks Pvt Ltd, Bengaluru, India.; Palaniappan, SK (corresponding author), SBX Corp, Tokyo, Japan.	sucheendra@sbi.jp			ONR Global [N62909-21-1-2032]	ONR Global	The study is partly funded by ONR Global Grant-N62909-21-1-2032.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed SAJA, 2022, FRONT PHYSIOL, V13; Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Badal VD, 2019, MICROBIOME, V7, DOI 10.1186/s40168-019-0742-2; Bao WZ, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1968-2; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cheng L, 2020, NUCLEIC ACIDS RES, V48, pD554, DOI 10.1093/nar/gkz843; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gu Y., 2020, arXiv; Hong LX, 2020, NAT MACH INTELL, V2, P347, DOI 10.1038/s42256-020-0189-y; Huang YA, 2017, J TRANSL MED, V15, DOI 10.1186/s12967-017-1304-7; Janssens Y, 2018, BMC MICROBIOL, V18, DOI 10.1186/s12866-018-1197-5; Jin HB, 2022, NUCLEIC ACIDS RES, V50, pD808, DOI 10.1093/nar/gkab973; Kitano H, 2021, NPJ SYST BIOL APPL, V7, DOI 10.1038/s41540-021-00189-3; Kitano H, 2016, AI MAG, V37, P39, DOI 10.1609/aimag.v37i1.2642; Konstantinova N, 2014, COMM COM INF SC, V436, P15, DOI 10.1007/978-3-319-12580-0_2; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li L, 2021, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.697059; Lim KMK, 2016, BIOINFORMATICS, V32, P2981, DOI 10.1093/bioinformatics/btw357; Lozupone CA, 2012, NATURE, V489, P220, DOI 10.1038/nature11550; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Ma W, 2017, BRIEF BIOINFORM, V18, P85, DOI 10.1093/bib/bbw005; Moradi M, 2022, Arxiv, DOI arXiv:2109.02555; Nakayama H, 2018, DOCCANO TEXT ANNOTAT; Nedellec C, 2013, P BIONLP SHAR TASK 2, P1, DOI DOI 10.1007/S11192-022-04332-7; Noronha A, 2019, NUCLEIC ACIDS RES, V47, pD614, DOI 10.1093/nar/gky992; Park Y, 2021, Scientific Reports, V11, P1; Peng LH, 2020, FRONT MICROBIOL, V11, DOI 10.3389/fmicb.2020.592430; Qi CL, 2023, NUCLEIC ACIDS RES, V51, pD717, DOI 10.1093/nar/gkac871; Qu J, 2019, FRONT MICROBIOL, V10, DOI 10.3389/fmicb.2019.00291; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Schulman J, 2022, Introducing chatgpt; Shin HC, 2020, Arxiv, DOI arXiv:2010.06060; Sommer F, 2013, NAT REV MICROBIOL, V11, P227, DOI 10.1038/nrmicro2974; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Taylor R, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Venigalla A, MOSAICML; Wang HL, 2022, NEURAL COMPUT APPL, V34, P4781, DOI 10.1007/s00521-021-06667-3; Wang QF, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66724-0; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wu CK, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04346-7; Xu H, 2022, GDREBASE COMPREHENSI; Yao GC, 2020, GENOM PROTEOM BIOINF, V18, P760, DOI 10.1016/j.gpb.2020.11.001; Yasunaga Michihiro, 2022, LinkBERT: Pretraining Language Models with Document Links; Zhang J, 2022, MICROBIOL SPECTR, V10, DOI 10.1128/spectrum.02116-22; Zhao B-W, 2023, IEEE T EMERG COMPUT; Zhao BW, 2021, CANCERS, V13, DOI 10.3390/cancers13092111	49	2	4	7	17	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	JUL 19	2023	24	1							290	10.1186/s12859-023-05411-z	http://dx.doi.org/10.1186/s12859-023-05411-z			19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	M9QK8	37468830	Green Published, gold			2024-07-03	WOS:001033485400001
C	Huang, CG; Mees, O; Zeng, A; Burgard, W			IEEE	Huang, Chenguang; Mees, Oier; Zeng, Andy; Burgard, Wolfram			Visual Language Maps for Robot Navigation	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc			LOCALIZATION	Grounding language to the visual observations of a navigating agent can be performed using off-the-shelf visual-language models pretrained on Internet-scale data (e.g., image captions). While this is useful for matching images to natural language descriptions of object goals, it remains disjoint from the process of mapping the environment, so that it lacks the spatial precision of classic geometric maps. To address this problem, we propose VLMaps, a spatial map representation that directly fuses pretrained visual-language features with a 3D reconstruction of the physical world. VLMaps can be autonomously built from video feed on robots using standard exploration approaches and enables natural language indexing of the map without additional labeled data. Specifically, when combined with large language models (LLMs), VLMaps can be used to (i) translate natural language commands into a sequence of open-vocabulary navigation goals (which, beyond prior work, can be spatial by construction, e.g., "in between the sofa and the TV" or "three meters to the right of the chair") directly localized in the map, and (ii) can be shared among multiple robots with different embodiments to generate new obstacle maps on-the-fly (by using a list of obstacle categories). Extensive experiments carried out in simulated and real-world environments show that VLMaps enable navigation according to more complex language instructions than existing methods. Videos are available at https://vlmaps.github.io.	[Huang, Chenguang; Mees, Oier] Univ Freiburg, Freiburg, Germany; [Zeng, Andy] Google Res, New York, NY USA; [Burgard, Wolfram] Univ Technol Nuremberg, Nurnberg, Germany	University of Freiburg; Google Incorporated	Huang, CG (corresponding author), Univ Freiburg, Freiburg, Germany.		Liu, Zhe/KEJ-5299-2024		German Federal Ministry of Education and Research [01IS18040B-OML]	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	This work has been supported partly by the German Federal Ministry of Education and Research under contract 01IS18040B-OML	Ahn M., 2022, arXiv preprint arXiv:2204.01691; Anderson, 2018, ARXIV180706757; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Anderson Peter, 2021, C ROBOT LEARNING, P671; Borja-Diaz J., 2022, P IEEE INT C ROB AUT; Chang Angel., 2017, 3DV; Chen Boyuan, 2022, ARXIV220909874; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681; Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199; Fried D, 2018, ADV NEUR IN, V31; Gadre S. Y., 2022, ARXIV220310421; Ganapathi A., 2022, ARXIV220301983; Gu Xiuye, 2021, INT C LEARN REPR; Guhur P., 2021, P IEEECVF INT C COMP, P1634; Hong Y., 2022, P IEEECVF C COMPUTER, P15439; Huang W., 2022, ARXIV220107207; Huang Wenlong, 2022, ARXIV220705608; Hughes N, 2022, ROBOT SCI SYS; Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180; Krantz Jacob, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P104, DOI 10.1007/978-3-030-58604-1_7; Krantz Jacob, 2021, P IEEECVF INT C COMP, P15162; Labbé M, 2019, J FIELD ROBOT, V36, P416, DOI 10.1002/rob.21831; Li Boyi, 2021, INT C LEARN REPR; Liang Jacky, 2022, ARXIV220907753; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965; MACMAHON M, 2006, P NAT C ART INT AAAI, P1475; McCormac John, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4628, DOI 10.1109/ICRA.2017.7989538; McCormac J, 2018, INT CONF 3D VISION, P32, DOI 10.1109/3DV.2018.00015; MCNAMARA TP, 1989, J EXP PSYCHOL LEARN, V15, P211, DOI 10.1037/0278-7393.15.2.211; Mees O., 2022, ARXIV221001911; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P11205, DOI 10.1109/LRA.2022.3196123; Mees O, 2022, IEEE ROBOT AUTOM LET, V7, P7327, DOI 10.1109/LRA.2022.3180108; Newman EL, 2007, COGNITION, V104, P231, DOI 10.1016/j.cognition.2006.05.013; Radford A, 2021, PR MACH LEARN RES, V139; Rünz M, 2018, INT SYM MIX AUGMENT, P10, DOI 10.1109/ISMAR.2018.00024; Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178; Savva M, 2019, IEEE I CONF COMP VIS, P9338, DOI 10.1109/ICCV.2019.00943; Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1109/ICCV.2017.74, 10.1007/s11263-019-01228-7]; Shah D., 2022, ARXIV220704429; Shridhar M., 2022, C ROBOT LEARNING, P894; Tellex S., 2011, AAAI, V25; Thrun S, 1998, AUTON ROBOT, V5, P253, DOI 10.1023/A:1008806205438; Wu J, 2021, IEEE INT CONF ROBOT, P8749, DOI 10.1109/ICRA48506.2021.9561359; Wu SC, 2021, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR46437.2021.00743; Xu BB, 2019, IEEE INT CONF ROBOT, P5231, DOI [10.1109/icra.2019.8794371, 10.1109/ICRA.2019.8794371]; Zakka K., 2022, C ROBOT LEARNING, P537; Zeng A., 2019, THESIS; Zeng Andy, 2022, ARXIV220400598	50	14	14	8	11	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							10608	10615		10.1109/ICRA48891.2023.10160969	http://dx.doi.org/10.1109/ICRA48891.2023.10160969			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371103046
J	Aslan, I; Neu, D; Neupert, D; Grafberger, S; Weise, N; Pfeil, P; Kuschewski, M				Aslan, Ilhan; Neu, Dominik; Neupert, Daniela; Grafberger, Stefan; Weise, Nico; Pfeil, Pascal; Kuschewski, Maximilian			How to Compliment a Human - Designing Affective and Well-being Promoting Conversational Things	INTERACTION DESIGN AND ARCHITECTURES			English	Article						UX Design; Affective Computing; IoT; Machine Learning; Application; Conversational User Interfaces; Prompt Engineering	IMAGES	With today's technologies it seems easier than ever to augment everyday things with the ability to perceive their environment and to talk to users. Considering conversational user interfaces, tremendous progress has already been made in designing and evaluating task oriented conversational interfaces, such as voice assistants for ordering food, booking a flight etc. However, it is still very challenging to design smart things that can have with their users an informal conversation and emotional exchange, which requires the smart thing to master the usage of social everyday utterances, using irony and sarcasm, delivering good compliments, etc. In this paper, we focus on the experience design of compliments and the Complimenting Mirror design. The paper reports in detail on three phases of a human-centered design process including a Wizard of Oz study in the lab with 24 participants to explore and identify the effect of different compliment types on user experiences and a consequent field study with 105 users in an architecture museum with a fully functional installation of the Complimenting Mirror. In our analyses we argue why and how a "smart" mirror should compliment users and provide a theorization applicable for affective interaction design with things in more general. We focus on subjective user feedback including user concerns and prepositions of receiving compliments from a thing and on observations of real user behavior in the field i.e. transitions of bodily affective expressions comparing affective user states before, during, and after compliment delivery. Our research shows that compliment design matters significantly and using the right type of compliments in our final design in the field test, we succeed in achieving reactive expressions of positive emotions, "sincere" smiles and laughter, even from the seemingly sternest users. We conclude by providing an outlook of our contribution for the new age of large language models and prompt engineering.	[Aslan, Ilhan] Huawei Technol, Munich Res Ctr, Device Software Lab, Munich, Germany; [Aslan, Ilhan; Neu, Dominik; Neupert, Daniela; Grafberger, Stefan; Weise, Nico; Pfeil, Pascal; Kuschewski, Maximilian] Augsburg Univ, Human Ctr Multimedia Lab, Augsburg, Germany; [Grafberger, Stefan] Univ Amsterdam, AIRLab, Amsterdam, Netherlands; [Kuschewski, Maximilian] Tech Univ Munich, Chair Decentralized Informat Syst & Data Managemen, Munich, Germany	Huawei Technologies; University of Amsterdam; Technical University of Munich	Aslan, I (corresponding author), Huawei Technol, Munich Res Ctr, Device Software Lab, Munich, Germany.; Aslan, I (corresponding author), Augsburg Univ, Human Ctr Multimedia Lab, Augsburg, Germany.	ilhan.aslan@huawei.com						Amiriparian S., 2021, arXiv; Andreu Y, 2016, COMPUT VIS IMAGE UND, V148, P3, DOI 10.1016/j.cviu.2016.03.018; Aslan I, 2005, LECT NOTES COMPUT SC, V3814, P3, DOI 10.1007/11590323_1; Aslan Ilhan, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P433, DOI 10.1145/3382507.3418848; Avula S, 2018, CHIIR'18: PROCEEDINGS OF THE 2018 CONFERENCE ON HUMAN INFORMATION INTERACTION & RETRIEVAL, P52, DOI 10.1145/3176349.3176380; Besserer D., 2016, P WORKSH MULT AN EN, P48, DOI [10.1145/3011263.3011265, DOI 10.1145/3011263.3011265]; Bimbo Brasil, 2014, Friendly Mirror-Nutrella. Video.; Blum T, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P115, DOI 10.1109/VR.2012.6180909; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown Z, 2016, BODY IMAGE, V19, P37, DOI 10.1016/j.bodyim.2016.08.007; Calvo RA, 2014, POSITIVE COMPUTING: TECHNOLOGY FOR WELLBEING AND HUMAN POTENTIAL, P1; Cha N, 2018, PROCEEDINGS OF THE 2018 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (UBICOMP/ISWC'18 ADJUNCT), P21, DOI 10.1145/3267305.3267616; Dang CT, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON THE INTERNET OF THINGS ( IOT 2019), DOI 10.1145/3365871.3365893; Deibel D., 2021, Conversations with Things: UX design for Chat and Voice; Farve Niaja, 2016, Persuasive Technology. 11th International Conference, PERSUASIVE 2016. Proceedings: LNCS 9638, P211, DOI 10.1007/978-3-319-31510-2_18; Groesz LM, 2002, INT J EAT DISORDER, V31, P1, DOI 10.1002/eat.10005; HOLMES J, 1986, ANTHROPOL LINGUIST, V28, P485; Höök K, 2008, LECT NOTES COMPUT SC, V5033, P1, DOI 10.1007/978-3-540-68504-3_1; Ikea UK, 2014, Video; Ju W., 2015, Synthesis Lectures on Human-Centered Informatics, V8, P1, DOI [10.1007/978-3-031-02210-4, DOI 10.1007/978-3-031-02210-4]; Kleinke CL, 1998, J PERS SOC PSYCHOL, V74, P272, DOI 10.1037/0022-3514.74.1.272; Lee CP, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501955; Lowe-Calverley E, 2018, TELEMAT INFORM, V35, P186, DOI 10.1016/j.tele.2017.10.011; Lowgren J, 2004, THOUGHTFUL INTERACTION DESIGN: A DESIGN PERSPECTIVE ON INFORMATION TECHNOLOGY, P1; McCabe MP, 2004, J PSYCHOSOM RES, V56, P675, DOI 10.1016/S0022-3999(03)00129-6; Pérez-Marín D, 2013, BEHAV INFORM TECHNOL, V32, P955, DOI 10.1080/0144929X.2012.687774; Petrak B, 2019, IEEE ROMAN, DOI 10.1109/RO-MAN46459.2019.8956463; Picard R. W., 2000, Affective computing; Pomerantz A., 1978, Studies in the organization of conversational interaction, P79, DOI [DOI 10.1016/B978-0-12-623550-0.50010-0, 10.1016/B978-0-12-623550-0.50010-0]; Portela M, 2017, P 18 INT C HUMAN COM, P1, DOI DOI 10.1145/3123818.3123826; Rapp A, 2021, INT J HUM-COMPUT ST, V151, DOI 10.1016/j.ijhcs.2021.102630; Ritschel H., Irony Man: Augmenting a Social Robot with the Ability to Use Irony in Multimodal Communication with Humans; Rosa H., 2016, Resonanz: Eine Soziologie der Weltbeziehung; Sajadieh S, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290607.3313287; Shusterman R., 2008, Body consciousness: A philosophy of mindfulness and somaesthetics; Tsaknaki V., 2021, P 2021 CHI C HUMAN F, P1, DOI DOI 10.1145/3411764.3445628; Tsaknaki V, 2019, PROCEEDINGS OF THE 2019 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2019), P1237, DOI 10.1145/3322276.3322327; Tsujita H., 2011, CHI 11 HUM FACT COMP, P117, DOI [10.1145/1979742.1979608, DOI 10.1145/1979742.1979608]; Turk M, 2000, COMMUN ACM, V43, P32, DOI 10.1145/330534.330535; Weber K, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P154, DOI 10.1145/3242969.3242976; Yang Z., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.15873	41	0	0	0	0	INTERACTION DESIGN & ARCHITECTURES	ROMA	INTERACTION DESIGN & ARCHITECTURES, ROMA, 00000, ITALY	1826-9745	2283-2998		INTERACT DES ARCHIT	Interact. Des. Archit.	FAL	2023		58			SI		157	184						28	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	WC8U0					2024-07-03	WOS:001252769900001
C				IEEE				Few-shot Learning with Prompting Methods	2023 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS, IPRIA	International Conference on Pattern Recognition and Image Analysis		English	Proceedings Paper	6th International Conference on Pattern Recognition and Image Analysis (IPRIA)	FEB 14-16, 2023	Univ Tehran, Coll Farabi, Fac Engn, Qom, IRAN		Univ Tehran, Coll Farabi, Fac Engn	few-shot learning; natural language processing; prompting; prompt-based learning; pre-trained language model		Today, in natural language processing, labeled data is important, however, getting adequate amount of data is a challenging step. There are many tasks for which it is difficult to obtain the required training data. For example, in machine translation, we need to prepare a lot of data in the target language, so that the work performance is acceptable. We may not be able to collect useful data in the target language. Hence, we need to use few-shot learning. Recently, a method called prompting has evolved, in which text inputs are converted into text with a new structure using a certain format, which has a blank space. Given the prompted text, a pre-trained language model replaces the space with the best word. Prompting can help us in the field of few-shot learning; even in cases where there is no data, i.e. zero-shot learning. Recent works use large language models such as GPT-2 and GPT-3, with the prompting method, performed tasks such as machine translation. These efforts do not use any labeled training data. But these types of models with a massive number of parameters require powerful hardware. Pattern-Exploiting Training (PET) and iterative Pattern-Exploiting Training (iPET) were introduced, which perform fewshot learning using prompting and smaller pre-trained language models such as Bert and Roberta. For example, for the Yahoo text classification dataset, using iPET and Roberta and ten labeled datasets, 70% accuracy has been reached. This paper reviews research works in few-shot learning with a new paradigm in natural language processing, which we dub prompt-based learning or in short, prompting.						Khotanlou, Hassan/0000-0001-7351-9397				Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704; Radford A., 2018, IMPROVING LANGUAGE U; Schick T., 2020, arXiv; Schick T, 2020, Arxiv, DOI arXiv:2010.13641; Schick T, 2021, Arxiv, DOI [arXiv:2001.07676, 10.48550/arXiv.2001.07676]; Schick T, 2021, Arxiv, DOI arXiv:2009.07118; Tam D, 2021, arXiv; Wang A, 2019, ADV NEUR IN, V32; Williams A, 2018, Arxiv, DOI arXiv:1704.05426; Zhang J., 2020, PMLR, P11328; Zhang X, 2015, ADV NEUR IN, V28	16	0	0	4	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-1455-7	Pattern Recog Img An			2023										10.1109/IPRIA59240.2023.10147172	http://dx.doi.org/10.1109/IPRIA59240.2023.10147172			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BV3SY					2024-07-03	WOS:001023221900005
J	Sievert, M; Aubreville, M; Mueller, SK; Eckstein, M; Breininger, K; Iro, H; Goncalves, M				Sievert, Matti; Aubreville, Marc; Mueller, Sarina Katrin; Eckstein, Markus; Breininger, Katharina; Iro, Heinrich; Goncalves, Miguel			Diagnosis of malignancy in oropharyngeal confocal laser endomicroscopy using GPT 4.0 with vision	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article						Confocal laser endomicroscopy; Oropharyngeal squamous cell carcinoma; GPT; Head and neck malignancies	SURGERY; MARGINS	PurposeConfocal Laser Endomicroscopy (CLE) is an imaging tool, that has demonstrated potential for intraoperative, real-time, non-invasive, microscopical assessment of surgical margins of oropharyngeal squamous cell carcinoma (OPSCC). However, interpreting CLE images remains challenging. This study investigates the application of OpenAI's Generative Pretrained Transformer (GPT) 4.0 with Vision capabilities for automated classification of CLE images in OPSCC.MethodsCLE Images of histological confirmed SCC or healthy mucosa from a database of 12 809 CLE images from 5 patients with OPSCC were retrieved and anonymized. Using a training data set of 16 images, a validation set of 139 images, comprising SCC (83 images, 59.7%) and healthy normal mucosa (56 images, 40.3%) was classified using the application programming interface (API) of GPT4.0. The same set of images was also classified by CLE experts (two surgeons and one pathologist), who were blinded to the histology. Diagnostic metrics, the reliability of GPT and inter-rater reliability were assessed.ResultsOverall accuracy of the GPT model was 71.2%, the intra-rater agreement was kappa = 0.837, indicating an almost perfect agreement across the three runs of GPT-generated results. Human experts achieved an accuracy of 88.5% with a substantial level of agreement (kappa = 0.773).ConclusionsThough limited to a specific clinical framework, patient and image set, this study sheds light on some previously unexplored diagnostic capabilities of large language models using few-shot prompting. It suggests the model`s ability to extrapolate information and classify CLE images with minimal example data. Whether future versions of the model can achieve clinically relevant diagnostic accuracy, especially in uncurated data sets, remains to be investigated.	[Sievert, Matti; Mueller, Sarina Katrin; Iro, Heinrich] Erlangen Univ Hosp, Friedrich Alexander Univ Erlangen Nuremberg, Dept Otorhinolaryngol Head & Neck Surg, Erlangen, Germany; [Aubreville, Marc] Techn Hochschule Ingolstadt, Ingolstadt, Germany; [Eckstein, Markus] Univ Hosp, Friedrich Alexander Univ Erlangen Nurnberg, Inst Pathol, Erlangen, Germany; [Breininger, Katharina] Friedrich Alexander Univ Erlangen Nurnberg, Dept Artificial Intelligence Biomed Engn, Erlangen, Germany; [Goncalves, Miguel] Univ Hosp Wurzburg, Dept Otorhinolaryngol Plast & Aesthet Operat, Joseph Schneider Str 11, D-97080 Wurzburg, Germany	University of Erlangen Nuremberg; University of Erlangen Nuremberg; University of Erlangen Nuremberg; University of Wurzburg	Goncalves, M (corresponding author), Univ Hosp Wurzburg, Dept Otorhinolaryngol Plast & Aesthet Operat, Joseph Schneider Str 11, D-97080 Wurzburg, Germany.	Goncalves_M@ukw.de	Aubreville, Marc/W-7235-2019; Breininger, Katharina/ACE-9793-2022; Mueller, Sarina/AAJ-9925-2021; Eckstein, Markus/KPB-0180-2024	Aubreville, Marc/0000-0002-5294-5247; Breininger, Katharina/0000-0001-7600-5869; Mueller, Sarina/0000-0001-5790-0841; Eckstein, Markus/0000-0001-5418-3349	Deutsche Forschungsgemeinschaft	Deutsche Forschungsgemeinschaft(German Research Foundation (DFG))	No Statement Available	Arboleda LPA, 2023, CANCERS, V15, DOI 10.3390/cancers15174405; Aubreville M, 2019, INT J COMPUT ASS RAD, V14, P31, DOI 10.1007/s11548-018-1836-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Chee J, 2023, EUR ARCH OTO-RHINO-L, V280, P4687, DOI 10.1007/s00405-023-08135-1; Dolak W, 2015, ENDOSC INT OPEN, V3, pE19, DOI 10.1055/s-0034-1377935; Gorphe P, 2019, ORAL ONCOL, V98, P69, DOI 10.1016/j.oraloncology.2019.09.017; Grégoire V, 2019, LANCET ONCOL, V20, P1328, DOI 10.1016/S1470-2045(19)30495-4; Hu E.J., 2021, ARXIV; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Li JC, 2023, CLIN ORAL INVEST, V27, P6597, DOI 10.1007/s00784-023-05265-y; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu H, 2023, P NEURIPS 2023; Mazurowski MA, 2023, MED IMAGE ANAL, V89, DOI 10.1016/j.media.2023.102918; Nichols AC, 2022, J CLIN ONCOL, V40, P866, DOI 10.1200/JCO.21.01961; Pan ZY, 2023, AM J OTOLARYNG, V44, DOI 10.1016/j.amjoto.2022.103779; Preiksaitis C, 2023, JMIR MED EDUC, V9, DOI 10.2196/48785; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.21.23285886; Sievert M, 2022, ORAL ONCOL, V132, DOI 10.1016/j.oraloncology.2022.105978; Sievert M, 2021, AURIS NASUS LARYNX, V48, P764, DOI 10.1016/j.anl.2021.01.005; Sievert M, 2021, EUR ARCH OTO-RHINO-L, V278, P4433, DOI 10.1007/s00405-021-06659-y; Tan J, 2022, WORLD J GASTRO SURG, V14, P1375, DOI 10.4240/wjgs.v14.i12.1375; Temsah R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.47469; Urken ML, 2023, ORAL ONCOL, V143, DOI 10.1016/j.oraloncology.2023.106445; Wenda N, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13193081; Wenda N, 2022, INT ARCH OTORHINOLAR, V26, pE396, DOI 10.1055/s-0041-1724091; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776	27	3	3	5	5	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	APR	2024	281	4					2115	2122		10.1007/s00405-024-08476-5	http://dx.doi.org/10.1007/s00405-024-08476-5		FEB 2024	8	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	LQ7A3	38329525				2024-07-03	WOS:001157594500004
J	Rodríguez-Cantelar, M; Estecha-Garitagoitia, M; D'Haro, LF; Matía, F; Córdoba, R				Rodriguez-Cantelar, Mario; Estecha-Garitagoitia, Marcos; D'Haro, Luis Fernando; Matia, Fernando; Cordoba, Ricardo			Automatic Detection of Inconsistencies and Hierarchical Topic Classification for Open-Domain Chatbots	APPLIED SCIENCES-BASEL			English	Article						chatbots; inconsistent responses; zero-shot topic detection; clustering		Current State-of-the-Art (SotA) chatbots are able to produce high-quality sentences, handling different conversation topics and larger interaction times. Unfortunately, the generated responses depend greatly on the data on which they have been trained, the specific dialogue history and current turn used for guiding the response, the internal decoding mechanisms, and ranking strategies, among others. Therefore, it may happen that for semantically similar questions asked by users, the chatbot may provide a different answer, which can be considered as a form of hallucination or producing confusion in long-term interactions. In this research paper, we propose a novel methodology consisting of two main phases: (a) hierarchical automatic detection of topics and subtopics in dialogue interactions using a zero-shot learning approach, and (b) detecting inconsistent answers using k-means and the Silhouette coefficient. To evaluate the efficacy of topic and subtopic detection, we use a subset of the DailyDialog dataset and real dialogue interactions gathered during the Alexa Socialbot Grand Challenge 5 (SGC5). The proposed approach enables the detection of up to 18 different topics and 102 subtopics. For the purpose of detecting inconsistencies, we manually generate multiple paraphrased questions and employ several pre-trained SotA chatbot models to generate responses. Our experimental results demonstrate a weighted F-1 value of 0.34 for topic detection, a weighted F-1 value of 0.78 for subtopic detection in DailyDialog, then 81% and 62% accuracy for topic and subtopic classification in SGC5, respectively. Finally, to predict the number of different responses, we obtained a mean squared error (MSE) of 3.4 when testing smaller generative models and 4.9 in recent large language models.	[Rodriguez-Cantelar, Mario; Matia, Fernando] Univ Politecn Madrid, Ctr Automat & Robot CAR UPM CSIC, Intelligent Control Grp ICG, C Jose Gutierrez Abascal 2, Madrid 28006, Spain; [Estecha-Garitagoitia, Marcos; D'Haro, Luis Fernando; Cordoba, Ricardo] Univ Politecn Madrid, Speech Technol & Machine Learning Grp THAU, ETSI Telecomunicac, Av Complutense 30, Madrid 28040, Spain	Consejo Superior de Investigaciones Cientificas (CSIC); Universidad Politecnica de Madrid; CSIC-UPM - Centro de Automatica y Robotica; Universidad Politecnica de Madrid	D'Haro, LF (corresponding author), Univ Politecn Madrid, Speech Technol & Machine Learning Grp THAU, ETSI Telecomunicac, Av Complutense 30, Madrid 28040, Spain.	mario.rcantelar@upm.es; marcos.estecha.garitagoitia@upm.es; luisfernando.dharo@upm.es; fernando.matia@upm.es; ricardo.cordoba@upm.es	de Córdoba Herralde, Ricardo/B-5861-2008; D'Haro, Luis Fernando/B-8194-2011	de Córdoba Herralde, Ricardo/0000-0002-7136-9636; D'Haro, Luis Fernando/0000-0002-3411-7384; Matia, Fernando/0000-0002-2198-1448; Rodriguez-Cantelar, Mario/0000-0001-9703-4458	This work is supported by project BEWORD (PID2021-126061OB-C43) funded by MCIN/AEI/10.13039/501100011033 and, as appropriate, by "ERDF A way of making Europe", by the "European Union". In addition, it is part of the Ramp;amp;D project "Cognitive Personal [MCIN/AEI/10.13039/501100011033, PID2020-113096RB-I00]; European Union [PID2020-113096RB-I00]; Amazon Alexa Prize;  [PID2021-126061OB-C43]	This work is supported by project BEWORD (PID2021-126061OB-C43) funded by MCIN/AEI/10.13039/501100011033 and, as appropriate, by "ERDF A way of making Europe", by the "European Union". In addition, it is part of the Ramp;amp;D project "Cognitive Personal; European Union(European Union (EU)); Amazon Alexa Prize; 	This work is supported by project BEWORD (PID2021-126061OB-C43) funded by MCIN/AEI/10.13039/501100011033 and, as appropriate, by "ERDF A way of making Europe", by the "European Union". In addition, it is part of the R & amp;D project "Cognitive Personal Assistance for Social Environments (ACOGES)", reference PID2020-113096RB-I00, funded by MCIN/AEI/10.13039/501100011033. Finally, we would like to acknowledge the support from the Amazon Alexa Prize as part of SocialBot Grand Challenge 5.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anderson P., 2017, P 2017 C EMPIRICAL M, P936; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381; Conneau Alexis., 2020, P 58 ANN M ASS COMP, P8440, DOI [DOI 10.18653/V1/2020.ACL-MAIN.747, 10.18653/v1/2020.acl-main.747]; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; Dziri N, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204.07931, 10.48550/arXiv.2204.07931]; Dziri N, 2020, Arxiv, DOI arXiv:1904.03371; Fan AEL, 2018, Arxiv, DOI arXiv:1805.04833; Ghazarian Sarik, 2019, P WORKSH METH OPT EV, P82, DOI [10.18653/v1/W19-2310, DOI 10.18653/V1/W19-2310]; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Guo L. Zhu, 2021, P INT C COMP INF SCI, P845; Hakkani-Tur Dilek, 2021, ALEXA PRIZE SOCIALBO; He P., 2021, P INT C LEARNING REP; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Hu Shui., 2021, ALEXA PRIZE SOCIALBO; Huang LS, 2020, Arxiv, DOI arXiv:2010.03994; Khatri C, 2018, Arxiv, DOI arXiv:1812.10757; Komeili M, 2021, Arxiv, DOI [arXiv:2107.07566, 10.48550/ARXIV.2107.07566, DOI 10.48550/ARXIV.2107.07566]; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li Y., 2017, P 8 INT JOINT C NATU, P986; Liu Chia-Wei, 2016, P 2016 C EMPIRICAL M, P2122, DOI [DOI 10.18653/V1/D16-1230, 10.18653/v1/D16-1230]; Lowe R, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1116, DOI 10.18653/v1/P17-1103; Maynez J, 2020, Arxiv, DOI [arXiv:2005.00661, DOI 10.48550/ARXIV.2005.00661]; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mehri S., 2022, Report from the NSF Future Directions Workshop on Automatic Evaluation of Dialog: Research Directions and Challenges; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pourpanah F, 2023, IEEE T PATTERN ANAL, V45, P4051, DOI 10.1109/TPAMI.2022.3191696; Prats J.M., 2022, P PROCEEDING IBERSPE, P116, DOI DOI 10.21437/IBERSPEECH.2022-24; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rodriguez-Cantelar M., 2021, ALEXA PRIZE SOCIALBO; Roller S, 2020, Arxiv, DOI arXiv:2004.13637; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schick T, 2021, Arxiv, DOI [arXiv:2001.07676, 10.48550/arXiv.2001.07676]; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Shuster K., 2022, arXiv; Shuster Kurt, 2022, PREPRINT; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Sun W., 2023, P AAAI C ARTIFICIAL, P13618; Tao CY, 2018, AAAI CONF ARTIF INTE, P722; Tavares D, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P6935, DOI 10.1145/3503161.3548759; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Wolf T., 2019, PREPRINT; Xu J, 2021, Arxiv, DOI [arXiv:2107.07567, 10.48550/ARXIV.2107.07567, DOI 10.48550/ARXIV.2107.07567]; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Zeng H, 2023, Arxiv, DOI arXiv:2304.12986; Zhang C, 2022, AAAI CONF ARTIF INTE, P11657; Zhang C, 2021, Arxiv, DOI arXiv:2111.02110; Zhang YZ, 2020, Arxiv, DOI arXiv:1911.00536	52	2	2	5	7	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	AUG	2023	13	16							9055	10.3390/app13169055	http://dx.doi.org/10.3390/app13169055			22	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	Q2KS9		Green Submitted, gold			2024-07-03	WOS:001055863300001
C	Liu, BL; Hu, YR; Ai, QY; Liu, YQ; Wu, YY; Li, CL; Shen, WX			ACM	Liu, Bulou; Hu, Yiran; Ai, Qingyao; Liu, Yiqun; Wu, Yueyue; Li, Chenliang; Shen, Weixing			Leveraging Event Schema to Ask Clarifying Questions for Conversational Legal Case Retrieval	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Conversational search; legal case retrieval; clarifying question		Legal case retrieval is a special IR task aiming to retrieve supporting cases for a given query case. Existing works have shown that conversational search paradigm can improve users' search experience in legal case retrieval. One of the keys to a practical conversational search system is how to ask high-quality clarifying questions to initiate conversations with users and understand their search intents. Recently, Large Language Models, such as ChatGPT and GPT-4, have shown superior ability in both open-domain QA and conversations with human. Thus it is natural to believe that they could be applied to legal conversational search as well. However, our preliminary study has shown that generating clarifying questions in legal conversational search with SOTA LLMs (e.g., GPT-4) often suffers from several problems such as duplication and low-utility contents. To address these problems, we propose LeClari, which leverages legal event schema as external knowledge to instruct LLMs to generate effective clarifying questions for legal conversational search. LeClari is constructed with a prompt module and a novel legal event selection module. The former defines a prompt with legal events for clarifying question generation and the latter selects potential event types by modeling the relationships of legal event types, conversational context, and candidate cases. We also propose ranking-oriented rewards and employ the reward augmented maximum likelihood (RAML) method to optimize LeClari directly based on the final retrieval performance of the conversational legal search system. Empirical results over two widely adopted legal case retrieval datasets demonstrate the effectiveness of our approach as compared with the state-of-the-art baselines.	[Liu, Bulou; Ai, Qingyao; Liu, Yiqun; Wu, Yueyue] Tsinghua Univ, Inst Internet Judiciary, Quan Cheng Lab, DCST, Beijing, Peoples R China; [Hu, Yiran; Shen, Weixing] Tsinghua Univ, Law Sch, Beijing, Peoples R China; [Li, Chenliang] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan, Peoples R China	Tsinghua University; Tsinghua University; Wuhan University	Liu, YQ (corresponding author), Tsinghua Univ, Inst Internet Judiciary, Quan Cheng Lab, DCST, Beijing, Peoples R China.	lbl20@mails.tsinghua.edu.cn; huyr21@mails.tsinghua.edu.cn; aiqingyao@gmail.com; yiqunliu@tsinghua.edu.cn; wuyueyue@mail.tsinghua.edu.cn; cllee@whu.edu.cn; wxshen@mail.tsinghua.edu.cn		LIU, Yiqun/0000-0002-0140-4512; Ai, Qingyao/0000-0002-5030-709X; , HU/0009-0003-7986-3692	Quan Cheng Laboratory [QCLZD202301]; Natural Science Foundation of China [62002194]	Quan Cheng Laboratory; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work is supported by Quan Cheng Laboratory (Grant No. QCLZD202301) and the Natural Science Foundation of China (Grant No. 62002194).	Aliannejadi M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P475, DOI 10.1145/3331184.3331265; Auer P., 2002, Journal of Machine Learning Research, V3, P397, DOI DOI 10.4271/610369; BELKIN NJ, 1995, EXPERT SYST APPL, V9, P379, DOI 10.1016/0957-4174(95)00011-W; Carterette Ben, 2014, NIST SPECIAL PUBLICA; Chen YP, 2019, J NANOMATER, V2019, DOI 10.1155/2019/2626085; Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746; DOYLE J, 1992, LAW LIBR J, V84, P229; Ferrer Angel Sancho, 2014, REV DEMOCRACIA DIGIT, V1, P120; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Gururangan Suchin, 2020, ARXIV200410964; Li Haitao, 2023, ARXIV230506812; Li Haitao, 2023, ARXIV230506817; Li Haitao, 2023, ARXIV230411370; Liu BJ, 2020, J INFRARED MILLIM W, V39, P1, DOI 10.11972/j.issn.1001-9014.2020.01.001; Liu BL, 2023, LECT NOTES COMPUT SC, V13980, P622, DOI 10.1007/978-3-031-28244-7_39; Liu BL, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103051; Liu BL, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3347, DOI 10.1145/3534678.3539105; Liu BL, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1622, DOI 10.1145/3404835.3463064; Ma YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2342, DOI 10.1145/3404835.3463250; Ma Yixiao, 2021, P 18 INT C ART INT L; McGinnis JohnO., 2019, Actual Probs. Econ. L., P1230; Norouzi M, 2016, ADV NEUR IN, V29; Nowak R, 2008, ANN ALLERTON CONF, P568, DOI 10.1109/ALLERTON.2008.4797609; OpenAI, 2022, OpenA I; OpenAI, 2023, Gpt-4 technical report, 2023.; Radlinski F, 2017, CHIIR'17: PROCEEDINGS OF THE 2017 CONFERENCE HUMAN INFORMATION INTERACTION AND RETRIEVAL, P117, DOI 10.1145/3020165.3020183; Rose D. E., 1989, Second International Conference on Artificial Intelligence and Law. Proceedings of the Conference, P138, DOI 10.1145/74014.74033; Saravanan M, 2009, ARTIF INTELL LAW, V17, P101, DOI 10.1007/s10506-009-9075-y; SHAO Y, P 29 INT JOINT C ART, P3501, DOI DOI 10.24963/IJCAI.2020/484; Shao YQ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P962, DOI 10.1145/3404835.3462876; Shao Yunqiu, 2020, ARXIV201213102; Solomon P, 1997, LIBR INFORM SCI RES, V19, P217, DOI 10.1016/S0740-8188(97)90014-1; Turtle H., 1995, Artificial Intelligence and Law, V3, P5, DOI 10.1007/BF00877694; van Opijnen M, 2017, ARTIF INTELL LAW, V25, P65, DOI 10.1007/s10506-017-9195-8; Wang XZ, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P998; Wang Zhenduo, 2023, P ACM WEB C 2023, P3288; Xiao CJ, 2021, AI OPEN, V2, P79, DOI 10.1016/j.aiopen.2021.06.003; Yao F, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P183; Yao Feng, 2023, P AAAI C ARTIFICIAL, V37, P4783; Zamani H, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P418, DOI 10.1145/3366423.3380126; Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776; Zhong Haoxi, 2019, TECHNICAL REPORT; Zou J, 2020, ACM T INFORM SYST, V38, DOI 10.1145/3388640; Zou J, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P369, DOI 10.1145/3357384.3357967; Zou Jie, 2022, ACM T INFORM SYSTEMS, V41, P1	45	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							1513	1522		10.1145/3583780.3614953	http://dx.doi.org/10.1145/3583780.3614953			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		hybrid			2024-07-03	WOS:001161549501059
J	Alkhaaldi, SMI; Kassab, CH; Dimassi, Z; Alsoud, LO; Al Fahim, M; Al Hageh, C; Ibrahim, H				Alkhaaldi, Saif M., I; Kassab, Carl H.; Dimassi, Zakia; Alsoud, Leen Oyoun; Al Fahim, Maha; Al Hageh, Cynthia; Ibrahim, Halah			Medical Student Experiences and Perceptions of ChatGPT and Artificial Intelligence: Cross-Sectional Study	JMIR MEDICAL EDUCATION			English	Article						medical education; ChatGPT; artificial intelligence; large language models; LLMs; AI; medical student; medical students; cross-sectional study; training; technology; medicine; health care professionals; risk; education	EDUCATION	Background: Artificial intelligence (AI) has the potential to revolutionize the way medicine is learned, taught, and practiced, and medical education must prepare learners for these inevitable changes. Academic medicine has, however, been slow to embrace recent AI advances. Since its launch in November 2022, ChatGPT has emerged as a fast and user-friendly large language model that can assist health care professionals, medical educators, students, trainees, and patients. While many studies focus on the technology's capabilities, potential, and risks, there is a gap in studying the perspective of end users. Objective: The aim of this study was to gauge the experiences and perspectives of graduating medical students on ChatGPT and AI in their training and future careers. Methods: A cross-sectional web-based survey of recently graduated medical students was conducted in an international academic medical center between May 5, 2023, and June 13, 2023. Descriptive statistics were used to tabulate variable frequencies. Results: Of 325 applicants to the residency programs, 265 completed the survey (an 81.5% response rate). The vast majority of respondents denied using ChatGPT in medical school, with 20.4% (n=54) using it to help complete written assessments and only 9.4% using the technology in their clinical work (n=25). More students planned to use it during residency, primarily for exploring new medical topics and research (n=168, 63.4%) and exam preparation (n=151, 57%). Male students were significantly more likely to believe that AI will improve diagnostic accuracy (n=47, 51.7% vs n=69, 39.7%; P=.001), reduce medical error (n=53, 58.2% vs n=71, 40.8%; P=.002), and improve patient care (n=60, 65.9% vs n=95, 54.6%; P=.007). Previous experience with AI was significantly associated with positive AI perception in terms of improving patient care, decreasing medical errors and misdiagnoses, and increasing the accuracy of diagnoses (P=.001, P<.001, P=.008, respectively). Conclusions: The surveyed medical students had minimal formal and informal experience with AI tools and limited perceptions of the potential uses of AI in health care but had overall positive views of ChatGPT and AI and were optimistic about the future of AI in medical education and health care. Structured curricula and formal policies and guidelines are needed to adequately prepare medical learners for the forthcoming integration of AI in medicine.	[Alkhaaldi, Saif M., I; Kassab, Carl H.] Khalifa Univ, Coll Med & Hlth Sci, Abu Dhabi, U Arab Emirates; [Dimassi, Zakia; Alsoud, Leen Oyoun; Al Hageh, Cynthia; Ibrahim, Halah] Khalifa Univ, Coll Med & Hlth Sci, Dept Med Sci, Abu Dhabi, U Arab Emirates; [Al Fahim, Maha] Sheikh Khalifa Med City, Educ Inst, Abu Dhabi, U Arab Emirates; [Ibrahim, Halah] Khalifa Univ, Coll Med & Hlth Sci, Dept Med Sci, POB 127788, Abu Dhabi, U Arab Emirates	Khalifa University of Science & Technology; Khalifa University of Science & Technology; Khalifa University of Science & Technology	Ibrahim, H (corresponding author), Khalifa Univ, Coll Med & Hlth Sci, Dept Med Sci, POB 127788, Abu Dhabi, U Arab Emirates.	halah.ibrahim@ku.ac.ae		AL HAGEH, Cynthia/0000-0001-8386-4063; Dimassi, Zakia/0000-0001-8729-1581; Kassab, Carl H/0009-0007-0902-4104; , Saif Mohamad Ismail Alkhaaldi/0009-0007-9443-7420				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], The impact of artificial intelligence on the future of workforces in the European Union and the United States of America; [Anonymous], The Global Gender Gap Report 2013; [Anonymous], How AI and ChatGPT in healthcare elevating the game?; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Brender TD, 2023, JAMA INTERN MED, V183, P507, DOI 10.1001/jamainternmed.2023.1832; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chen CH, 2020, JMIR MED EDUC, V6, DOI 10.2196/19725; Dorr DA, 2023, JAMA-J AM MED ASSOC, V329, P1347, DOI 10.1001/jama.2023.2771; Duffourc M, 2023, JAMA-J AM MED ASSOC, V330, P313, DOI 10.1001/jama.2023.9630; Elkhodr M., 2023, STEM Education, V3, P70, DOI [10.3934/steme.2023006, DOI 10.3934/STEME.2023006]; Eysenbach G, 2004, J MED INTERNET RES, V6, P12, DOI 10.2196/jmir.6.3.e34; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fear K, 2023, JMIR AGING, V6, DOI 10.2196/51776; Frenk J, 2022, LANCET, V400, P1539, DOI 10.1016/S0140-6736(22)02092-X; Gibert K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12063129; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hisan U. K., 2023, Journal of Pedagogy and Education Science, V2, P71, DOI [DOI 10.56741/JPES.V2I01.302, 10.56741/jpes.v2i01.302]; Hooda M, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/7690103; Ibrahim H, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0340-3; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Katznelson G, 2021, ADV HEALTH SCI EDUC, V26, P1447, DOI 10.1007/s10459-021-10040-3; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kim SG, 2023, MAX PLAST RECONSTR S, V45, DOI 10.1186/s40902-023-00381-x; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee J, 2021, ACAD MED, V96, pS62, DOI 10.1097/ACM.0000000000004291; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Liu DS, 2022, JMIR MED EDUC, V8, DOI 10.2196/38325; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; McCoy LG, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0294-7; McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6; McLean M, 2009, EDUC HEALTH, V22, P287; Mohamed NA, 2018, HUM RESOUR HEALTH, V16, DOI 10.1186/s12960-018-0283-y; Mohammad Bushra, 2023, Stud Health Technol Inform, V305, P644, DOI 10.3233/SHTI230580; Özdemir V, 2021, OMICS, V25, P249, DOI 10.1089/omi.2021.0020; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rajab MH, 2020, CUREUS J MED SCIENCE, V12, DOI 10.7759/cureus.8966; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Russell RG, 2023, ACAD MED, V98, P348, DOI 10.1097/ACM.0000000000004963; Shrestha S, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.976838; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Sukhera J, 2021, ACAD MED, V96, pS1, DOI 10.1097/ACM.0000000000004326; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812	47	3	3	23	23	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e51302	10.2196/51302	http://dx.doi.org/10.2196/51302			10	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	FM3B4	38133911	gold, Green Published			2024-07-03	WOS:001146166500002
J	Gavriilidis, GI; Vasileiou, V; Orfanou, A; Ishaque, N; Psomopoulos, F				Gavriilidis, George I.; Vasileiou, Vasileios; Orfanou, Aspasia; Ishaque, Naveed; Psomopoulos, Fotis			A mini-review on perturbation modelling across single-cell omic modalities	COMPUTATIONAL AND STRUCTURAL BIOTECHNOLOGY JOURNAL			English	Review						Perturbation; Single -cell RNA sequencing; ScRNAseq; Machine learning; Deep learning	GENERATION; CIRCUITS; SCREENS	Recent advances in single-cell omics technology have transformed the landscape of cellular and molecular research, enriching the scope and intricacy of cellular characterisation. Perturbation modelling seeks to comprehensively grasp the effects of external influences like disease onset or molecular knock-outs or external stimulants on cellular physiology, specifically on transcription factors, signal transducers, biological pathways, and dynamic cell states. Machine and deep learning tools transform complex perturbational phenomena in algorithmically tractable tasks to formulate predictions based on various types of single-cell datasets. However, the recent surge in tools and datasets makes it challenging for experimental biologists and computational scientists to keep track of the recent advances in this rapidly expanding filed of single-cell modelling. Here, we recapitulate the main objectives of perturbation modelling and summarise novel single-cell perturbation technologies based on genetic manipulation like CRISPR or compounds, spanning across omic modalities. We then concisely review a burgeoning group of computational methods extending from classical statistical inference methodologies to various machine and deep learning architectures like shallow models or autoencoders, to biologically informed approaches based on gene regulatory networks, and to combinatorial efforts reminiscent of ensemble learning. We also discuss the rising trend of large foundational models in single-cell perturbation modelling inspired by large language models. Lastly, we critically assess the challenges that underline single-cell perturbation modelling while pointing towards relevant future perspectives like perturbation atlases, multiomics and spatial datasets, causal machine learning for interpretability, multi-task learning for performance and explainability as well as prospects for solving interoperability and benchmarking pitfalls.	[Gavriilidis, George I.; Vasileiou, Vasileios; Orfanou, Aspasia; Psomopoulos, Fotis] Ctr Res & Technol Hellas, Inst Appl Biosci, Thessaloniki, Greece; [Vasileiou, Vasileios] Democritus Univ Thrace, Dept Mol Biol & Genet, Alexandroupolis, Greece; [Ishaque, Naveed] Charite Univ Med Berlin, Berlin Inst Hlth, Ctr Digital Hlth, Berlin, Germany	Centre for Research & Technology Hellas; Democritus University of Thrace; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Berlin Institute of Health	Gavriilidis, GI; Psomopoulos, F (corresponding author), Ctr Res & Technol Hellas, Inst Appl Biosci, Thessaloniki, Greece.	ggeorav@certh.gr; fpsom@certh.gr		Vasileiou, Vasileios/0000-0003-0145-033X	HORIZON-INFRA-2021-EOSC-01-04 project Scilake; Federal Ministry of Education and Research of Germany;  [031L0265]	HORIZON-INFRA-2021-EOSC-01-04 project Scilake; Federal Ministry of Education and Research of Germany(Federal Ministry of Education & Research (BMBF)); 	The authors express gratitude for the financial assistance received from the HORIZON-INFRA-2021-EOSC-01-04 project Scilake (https://scilake.eu/) and ELIXIR (https://elixir-europe.org/) , the research infrastructure for life -science data. Additionally, the authors acknowledge the financial support provided by the Federal Ministry of Education and Research of Germany in the framework of SAGE (project number 031L0265) .	Aibar S, 2017, NAT METHODS, V14, P1083, DOI [10.1038/NMETH.4463, 10.1038/nmeth.4463]; Barry T, 2021, GENOME BIOL, V22, DOI 10.1186/s13059-021-02545-2; Bravo Gonzalez-Blas Carmen, 2023, Nat Methods, V20, P1355, DOI 10.1038/s41592-023-01938-4; Bunne C., Learning Single-Cell Perturbation Responses using Neural Optimal Transport; Burkhardt DB, 2021, NAT BIOTECHNOL, V39, P619, DOI 10.1038/s41587-020-00803-5; Cao K, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35094-8; Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734; Chandrasekaran SN, 2024, NAT METHODS, V21, DOI 10.1038/s41592-024-02241-6; Cheng JY, 2023, ADV SCI, V10, DOI 10.1002/advs.202204484; Consens ME, 2023, Arxiv, DOI [arXiv:2311.07621, DOI 10.48550/ARXIV.2311.07621]; Cui HT, 2024, NAT METHODS, DOI 10.1038/s41592-024-02201-0; Dann E, 2022, NAT BIOTECHNOL, V40, P245, DOI 10.1038/s41587-021-01033-z; Datlinger P, 2017, NAT METHODS, V14, P297, DOI [10.1038/NMETH.4177, 10.1038/nmeth.4177]; Dhainaut M, 2022, CELL, V185, P1223, DOI 10.1016/j.cell.2022.02.015; Dixit A, 2016, CELL, V167, P1853, DOI 10.1016/j.cell.2016.11.038; Doncevic D, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad387; Dong MZ, 2023, NAT METHODS, V20, DOI 10.1038/s41592-023-02040-5; Dong XR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-38335-6; Duan B, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10216-x; Frangieh CJ, 2021, NAT GENET, V53, P332, DOI 10.1038/s41588-021-00779-1; Ghandeharioun A, 2024, Arxiv, DOI arXiv:2401.06102; Guna Alina, 2023, BMC Genomics, V24, P651, DOI 10.1186/s12864-023-09754-y; Hafemeister C, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-019-1874-1; Hao MS, 2023, bioRxiv, DOI [10.1101/2023.05.29.542705, 10.1101/2023.05.29.542705, DOI 10.1101/2023.05.29.542705]; Hawkins DY, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad278; He B, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-36637-3; Inecik K, 2022, bioRxiv, DOI [10.1101/2022.07.08.499049, 10.1101/2022.07.08.499049, DOI 10.1101/2022.07.08.499049]; Ishikawa M, 2023, COMMUN BIOL, V6, DOI 10.1038/s42003-023-05594-4; Jaitin DA, 2016, CELL, V167, P1883, DOI 10.1016/j.cell.2016.11.039; Ji YG, 2021, CELL SYST, V12, P522, DOI 10.1016/j.cels.2021.05.016; Jiang JL, 2023, bioRxiv, DOI [10.1101/2023.04.19.537364, 10.1101/2023.04.19.537364, DOI 10.1101/2023.04.19.537364]; Jin K, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac324; Kamimoto K, 2023, NATURE, V614, P742, DOI 10.1038/s41586-022-05688-9; Kamimoto K, 2023, STEM CELL REP, V18, P97, DOI 10.1016/j.stemcr.2022.11.010; Kana O, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100817; Kedzierska KZ, 2023, bioRxiv, DOI [10.1101/2023.10.16.561085, 10.1101/2023.10.16.561085, DOI 10.1101/2023.10.16.561085, 10.16.561085]; Kropiwnicki E, 2021, DATABASE-OXFORD, DOI 10.1093/database/baab017; Liscovitch-Brauer N, 2021, NAT BIOTECHNOL, V39, P1270, DOI 10.1038/s41587-021-00902-x; Littman R, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.107124; Liu TY, 2023, bioRxiv, DOI [10.1101/2023.12.07.569910, 10.1101/2023.12.07.569910, DOI 10.1101/2023.12.07.569910]; Lopez R, 2022, Arxiv, DOI arXiv:2211.03553; Lotfollahi M, 2023, MOL SYST BIOL, V19, DOI 10.15252/msb.202211517; Lotfollahi M, 2023, NAT CELL BIOL, V25, P337, DOI 10.1038/s41556-022-01072-x; Lotfollahi M, 2020, BIOINFORMATICS, V36, pI610, DOI 10.1093/bioinformatics/btaa800; Lotfollahi M, 2019, NAT METHODS, V16, P715, DOI 10.1038/s41592-019-0494-8; Ma PJ, 2023, CELL, V186, P877, DOI 10.1016/j.cell.2023.01.002; McFarland JM, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17440-w; Mimitou EP, 2019, NAT METHODS, V16, P409, DOI 10.1038/s41592-019-0392-0; Nicol PB, 2023, bioRxiv, DOI [10.1101/2023.05.06.539326, 10.1101/2023.05.06.539326, DOI 10.1101/2023.05.06.539326]; Occhipinti A, 2024, TRENDS CELL BIOL, V34, P85, DOI 10.1016/j.tcb.2023.11.002; Otto JE, 2023, MOL CELL, V83, P1350, DOI 10.1016/j.molcel.2023.03.013; Palma A, 2023, bioRxiv, DOI [10.1101/2023.07.17.549216, :10.1101/2023.07.17.549216, DOI 10.1101/2023.07.17.549216, 10.1101/2023.07.17.549216]; Papalexi E, 2021, NAT GENET, V53, P322, DOI 10.1038/s41588-021-00778-2; Peidli S, 2024, NAT METHODS, V21, DOI 10.1038/s41592-023-02144-y; Pierce SE, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23213-w; Rajewsky N, 2020, NATURE, V587, P377, DOI 10.1038/s41586-020-2715-9; Roohani Y, 2023, NAT BIOTECHNOL, DOI 10.1038/s41587-023-01905-6; Roth TL, 2020, CELL, V181, P728, DOI 10.1016/j.cell.2020.03.039; Rubin AJ, 2019, CELL, V176, P361, DOI 10.1016/j.cell.2018.11.022; Schraivogel D, 2020, NAT METHODS, V17, P629, DOI 10.1038/s41592-020-0837-5; Seninge L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26017-0; Skinnider MA, 2021, NAT BIOTECHNOL, V39, P30, DOI 10.1038/s41587-020-0605-1; Song QK, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-02044-w; Srivatsan SR, 2020, SCIENCE, V367, P45, DOI 10.1126/science.aax6234; Subramanian A, 2017, CELL, V171, P1437, DOI 10.1016/j.cell.2017.10.049; Sunshine S, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-41788-4; Suphavilai C, 2021, GENOME MED, V13, DOI 10.1186/s13073-021-01000-y; Tang X, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37477-x; Tejada-Lapuerta A., Causal machine learning for single-cell genomics; Ursu O, 2022, NAT BIOTECHNOL, V40, P896, DOI 10.1038/s41587-021-01160-7; van de Sande B, 2023, NAT REV DRUG DISCOV, V22, P496, DOI 10.1038/s41573-023-00688-4; Wu Y, 2023, ICLR, V2023; Xie SQ, 2017, MOL CELL, V66, P285, DOI 10.1016/j.molcel.2017.03.007; Yang L, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-1928-4; Yang L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-24324-0; Yang YJ, 2023, NUCLEIC ACIDS RES, V51, P6578, DOI 10.1093/nar/gkad450; Ye CY, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06500-x; Yeo GHT, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23518-w; Yu H, 2022, bioRxiv, DOI [10.1101/2022.07.20.500854, 10.1101/2022.07.20.500854, DOI 10.1101/2022.07.20.500854]; Zheng Y., 2023, Unagi: Deep Generative Model for Deciphering Cellular Dynamics and In-Silico Drug Discovery in Complex Diseases, DOI [10.21203/rs.3.rs-3676579/v1, DOI 10.21203/RS.3.RS-3676579/V1]; Zheng YX, 2023, SCI CHINA LIFE SCI, V66, P2952, DOI 10.1007/s11427-023-2431-x; Zinati Y, 2023, bioRxiv, DOI [10.1101/2023.07.25.550225, 10.1101/2023.07.25.550225, DOI 10.1101/2023.07.25.550225]	82	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2001-0370			COMPUT STRUCT BIOTEC	Comp. Struct. Biotechnol. J..	DEC	2024	23						1886	1896		10.1016/j.csbj.2024.04.058	http://dx.doi.org/10.1016/j.csbj.2024.04.058			11	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology	SN4G9	38721585				2024-07-03	WOS:001235112300001
J	de Zarzà, I; de Curtò, J; Roig, G; Calafate, CT				de Zarza, I.; de Curto, J.; Roig, Gemma; Calafate, Carlos T.			Optimized Financial Planning: Integrating Individual and Cooperative Budgeting Models with LLM Recommendations	AI			English	Article						financial planning; household finance; LLMs; budgeting; extended coevolutionary	LIFE-CYCLE	In today's complex economic environment, individuals and households alike grapple with the challenge of financial planning. This paper introduces novel methodologies for both individual and cooperative (household) financial budgeting. We firstly propose an optimization framework for individual budget allocation, aiming to maximize savings by efficiently distributing monthly income among various expense categories. We then extend this model to households, wherein the complexity of handling multiple incomes and shared expenses is addressed. The cooperative model prioritizes not only maximized savings but also the preferences and needs of each member, fostering a harmonious financial environment, whether they are short-term needs or long-term aspirations. A notable innovation in our approach is the integration of recommendations from a large language model (LLM). Given its vast training data and potent inferential capabilities, the LLM provides initial feasible solutions to our optimization problems, acting as a guiding beacon for individuals and households unfamiliar with the nuances of financial planning. Our preliminary results indicate that the LLM-recommended solutions result in budget plans that are both economically sound, meaning that they are consistent with established financial management principles and promote fiscal resilience and stability, and aligned with the financial goals and preferences of the concerned parties. This integration of AI-driven recommendations with econometric models, as an instantiation of an extended coevolutionary (EC) theory, paves the way for a new era in financial planning, making it more accessible and effective for a wider audience, as we propose an example of a new theory in economics where human behavior can be greatly influenced by AI agents.	[de Zarza, I.; de Curto, J.; Roig, Gemma] GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany; [de Zarza, I.; de Curto, J.; Calafate, Carlos T.] Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain; [de Zarza, I.; de Curto, J.] Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicac, Barcelona 08018, Spain; [Roig, Gemma] HESSIAN Ctr AI hessian AI, D-64293 Darmstadt, Germany	Goethe University Frankfurt; Universitat Politecnica de Valencia; UOC Universitat Oberta de Catalunya	de Zarzà, I (corresponding author), GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany.; de Zarzà, I (corresponding author), Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain.; de Zarzà, I (corresponding author), Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomunicac, Barcelona 08018, Spain.	dezarza@em.uni-frankfurt.de; decurto@em.uni-frankfurt.de; roig@cs.uni-frankfurt.de; calafate@disca.upv.es		Roig, Gemma/0000-0002-6439-8076; de Curto y Diaz, J./0000-0002-8334-4719	GOETHE-University Frankfurt am Main	GOETHE-University Frankfurt am Main	No Statement Available	Alhenawi Y, 2022, RES INT BUS FINANC, V59, DOI 10.1016/j.ribaf.2021.101550; Althnian A, 2021, INT J ADV COMPUT SC, V12, P182; ANDO A, 1963, AM ECON REV, V53, P55; Arner D.W., 2017, Georgetown Journal of International Affairs, V18, P47, DOI [DOI 10.1353/GIA.2017.0036, https://doi.org/10.2139/ssrn.3211708, DOI 10.2139/SSRN.3211708]; Arsenyan J, 2023, IEEE T ENG MANAGE, DOI 10.1109/TEM.2022.3229821; Baker HKent., 2017, Financial Behavior: Player, Services, Products, and Markets; Branzei R., 2008, Models in Cooperative Game Theory, V556; Browning M, 2001, J ECON PERSPECT, V15, P3, DOI 10.1257/jep.15.3.3; Browning M, 1996, J ECON LIT, V34, P1797; Campbell JY, 2006, J FINANC, V61, P1553, DOI 10.1111/j.1540-6261.2006.00883.x; Chai JJ, 2011, REV FINANC, V15, P875, DOI 10.1093/rof/rfr016; CHARNES A, 1957, MANAGE SCI, V4, P38, DOI 10.1287/mnsc.4.1.38; de Zarzà I, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12122722; Dixon M, 2017, ALGORITHMIC FINANC, V6, P67, DOI 10.3233/AF-170176; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Guiso L, 2023, J FINANC ECON, V147, P573, DOI 10.1016/j.jfineco.2023.01.002; Guiso Luigi., 2013, Handbook of the Economics of Finance, P1397, DOI [10.1016/B978-0-44-459406-8.00021-4, DOI 10.1016/B978-0-44-459406-8.00021-4]; Kahneman D, 2003, AM ECON REV, V93, P1449, DOI 10.1257/000282803322655392; Kumar S, 2023, INFORM SYST FRONT, V25, P871, DOI 10.1007/s10796-022-10279-0; Markowitz H, 1952, J FINANC, V7, P77, DOI 10.1111/j.1540-6261.1952.tb01525.x; MERTON RC, 1969, REV ECON STAT, V51, P247, DOI 10.2307/1926560; Mhlanga D, 2020, INT J FINANC STUD, V8, DOI 10.3390/ijfs8030045; Nazareth N, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119640; Pallathadka Harikumar, 2023, Materials Today: Proceedings, P2610, DOI 10.1016/j.matpr.2021.06.419; Perry VG, 2023, AI-BASEL, V4, P888, DOI 10.3390/ai4040045; Radford A, 2021, PR MACH LEARN RES, V139; Roccetti M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00428-8; THALER R, 1980, J ECON BEHAV ORGAN, V1, P39, DOI 10.1016/0167-2681(80)90051-7; Vaswani A, 2017, ADV NEUR IN, V30; Weber P, 2024, MANAG REV Q, V74, P867, DOI 10.1007/s11301-023-00320-0; Xiao J.J., 2008, HDB CONSUMER FINANCE, P69, DOI [DOI 10.1007/978-0-387-75734-6_5, 10.1007/978-0-387-46401-5_8]	31	0	0	6	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2673-2688		AI-BASEL	AI	MAR	2024	5	1					91	114		10.3390/ai5010006	http://dx.doi.org/10.3390/ai5010006			24	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	MC8P6		gold			2024-07-03	WOS:001191522500001
J	Yovel, Y; Rechavi, O				Yovel, Yossi; Rechavi, Oded			AI and the Doctor Dolittle challenge	CURRENT BIOLOGY			English	Editorial Material								Talking to animals is a fundamental human desire. The emergence of powerful AI algorithms, and specifi cally Large Language Models, has driven many to suggest that we are on the verge of fulfilling this wish. A few large scientific consortia have been formed around this topic and several commercial entities even offer such services. We frame the task of communicating with animals as 'The Doctor Dolittle challenge' and identify three main obstacles on the route to doing so. First, although generative AI models can create novel animal communication samples, it is very difficult to determine their context, and we will forever be biased by our human umwelt when doing so. Second, using AI to extract context in an unsupervised manner must be validated through controlled experiments aiming to measure the animals' response. This is difficult, and moreover, AI algorithms tend to cling on to any available information and are thus prone to fi nding spurious correlations. And third, animal communication focuses on a restricted set of contexts, such as alarm and courtship, highly limiting our ability to communicate regarding other contexts. Nevertheless, using the tremendous power of novel AI methods to decipher and mimic animal communication is both fascinating and important. We thus defi ne the criteria for passing the Doctor Dolittle challenge and call upon scientists to take on the mission. "...animals don't always speak with their mouths, said the parrot in a high voice, raising her eyebrows. They talk with their ears, with their feet, with their tails, with everything" - Polynesia the Parrot, The Story of Doctor Dolittle	[Yovel, Yossi] Tel Aviv Univ, Sch Zool, Wise Fac Life Sci, Tel Aviv, Israel; [Yovel, Yossi; Rechavi, Oded] Tel Aviv Univ, Sagol Sch Neurosci, Tel Aviv, Israel; [Rechavi, Oded] Tel Aviv Univ, Wise Fac Life Sci, Dept Neurobiol, Tel Aviv, Israel	Tel Aviv University; Tel Aviv University; Tel Aviv University	Yovel, Y (corresponding author), Tel Aviv Univ, Sch Zool, Wise Fac Life Sci, Tel Aviv, Israel.; Yovel, Y (corresponding author), Tel Aviv Univ, Sagol Sch Neurosci, Tel Aviv, Israel.	yossiyovel@gmail.com; odedrechavi@gmail.com						Amit Y, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.106466; [Anonymous], TechRepublic; Arbib MA, 2008, CURR ANTHROPOL, V49, P1052, DOI 10.1086/593015; Arnold K, 2006, NATURE, V441, P303, DOI 10.1038/441303a; Bloomfield TC, 2011, NAT NEUROSCI, V14, P947, DOI 10.1038/nn.2884; Bobkov YV, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83024-3; Burling R, 2010, LANGUAGE, V86, P244; Calhoun AJ, 2019, NAT NEUROSCI, V22, P2040, DOI 10.1038/s41593-019-0533-x; Faria JJ, 2010, BEHAV ECOL SOCIOBIOL, V64, P1211, DOI 10.1007/s00265-010-0988-y; Fernandez AA, 2021, SCIENCE, V373, P923, DOI 10.1126/science.abf9279; Filippi P, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01393; Fischer J, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0045; Gomez-Marin A, 2016, J R SOC INTERFACE, V13, DOI 10.1098/rsif.2016.0466; Greggers U, 2013, P ROY SOC B-BIOL SCI, V280, DOI 10.1098/rspb.2013.0528; Hauser MD., 1999, DESIGN ANIMAL COMMUN; Hebets EA, 2016, P ROY SOC B-BIOL SCI, V283, DOI 10.1098/rspb.2015.2889; Igic B, 2014, BEHAV ECOL, V25, P538, DOI 10.1093/beheco/aru018; Janik VM, 2014, CURR OPIN NEUROBIOL, V28, P60, DOI 10.1016/j.conb.2014.06.010; Kato S, 2015, CELL, V163, P656, DOI 10.1016/j.cell.2015.09.034; Kershenbaum A, 2012, P ROY SOC B-BIOL SCI, V279, P2974, DOI 10.1098/rspb.2012.0322; Klein Barrett A., 2012, Communicative & Integrative Biology, V5, P466, DOI 10.4161/cib.21304; Landgraf T., 2008, Applied Bionics and Biomechanics, V5, P157, DOI 10.1080/11762320802617552; Landgraf T, 2018, Arxiv, DOI arXiv:1803.07126; Lauer J, 2022, NAT METHODS, V19, P496, DOI 10.1038/s41592-022-01443-0; Lopuch S, 2020, APIDOLOGIE, V51, P631, DOI 10.1007/s13592-020-00748-3; MICHELSEN A, 1987, J COMP PHYSIOL A, V161, P633, DOI 10.1007/BF00605005; Narins PM, 2005, P NATL ACAD SCI USA, V102, P2425, DOI 10.1073/pnas.0406407102; Pilley JW, 2011, BEHAV PROCESS, V86, P184, DOI 10.1016/j.beproc.2010.11.007; Prat Y, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2002556; Prat Y, 2016, SCI REP-UK, V6, DOI 10.1038/srep39419; Probert R, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250913; Robertson Hugh M, 2006, WormBook, P1; SEYFARTH RM, 1980, ANIM BEHAV, V28, P1070, DOI 10.1016/S0003-3472(80)80097-2; Smith JM, 1995, J THEOR BIOL, V177, P305; Soltis J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0089403; Stephens GJ, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000028; Suddendorf T., 2013, The gap: The science of what separates us from other animals; Suzuki TN, 2020, CURR BIOL, V30, P2616, DOI 10.1016/j.cub.2020.04.062; Suzuki TN, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2018.0405; Suzuki TN, 2018, P NATL ACAD SCI USA, V115, P1541, DOI 10.1073/pnas.1718884115; ten Cate C, 2012, PHILOS T R SOC B, V367, P1984, DOI 10.1098/rstb.2012.0055; Zahavi A., 1999, The handicap principle: A missing piece of Darwin's puzzle; Zuberbühler K, 2020, PHILOS T R SOC B, V375, DOI 10.1098/rstb.2019.0062; Zuberbühler K, 2018, CURR OPIN BEHAV SCI, V21, P161, DOI 10.1016/j.cobeha.2018.03.015	44	0	0	0	1	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	0960-9822	1879-0445		CURR BIOL	Curr. Biol.	AUG 7	2021	33	15					R783	R787						5	Biochemistry & Molecular Biology; Biology; Cell Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Life Sciences & Biomedicine - Other Topics; Cell Biology	VM9FV					2024-07-03	WOS:001058808800001
J	Yin, H; Lu, PR; Li, Z; Sun, B; Li, K				Yin, Hang; Lu, Pinren; Li, Ziang; Sun, Bin; Li, Kan			MODE: a multimodal open-domain dialogue dataset with explanation	APPLIED INTELLIGENCE			English	Article						Multimodal data construction; Open-domain dialogue; AIGC; Explainability		The need for high-quality data has been a key issue hindering the research of dialogue tasks. Recent studies try to build datasets through manual, web crawling and so on. However, man-made data is expensive and data collected from the internet often includes generic responses, meaningless statements even toxic information. With the development of LLM (large language models), generating data through LLM has broad application potential. For open-domain multimodal dialogue tasks, there are still three drawbacks: 1) There is currently a lack of a unified and effective framework for collecting high-quality multimodal dialogue data; 2) The output of LLM in Multimodal dialogue generation lacks scene explanation, affecting human understanding; 3) Previous work has not quantitatively examined the impact of data quality on model performance. To improve data quality and reduce expenditure in the data collection process, we propose the Multimodal Data Construction Framework (MDCF). MDCF utilizes the modal conversion module and designs proper prompts to the LLM to generate well-formed and high-quality content. It also provides explanation for the multimodal dialogue, helping to understand conversation scenarios and facilitate manual subsequent quality inspection. Based on this, we release a Multimodal Open-domain Dialogue dataset with Explanation(MODE). We mainly compared open domain datasets such as Image-Chat. Both human evaluation and experiments show that high-quality datasets enable models to have greater understanding and generation capabilities.	[Yin, Hang; Lu, Pinren; Li, Ziang; Sun, Bin; Li, Kan] Beijing Inst Technol, Sch Comp Sci & Technol, 5 South St, Beijing 100081, Peoples R China	Beijing Institute of Technology	Li, K (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, 5 South St, Beijing 100081, Peoples R China.	yh@bit.edu.cn; poplpr@bit.edu.cn; 3120220943@bit.edu.cn; binsun@bit.edu.cn; likan@bit.edu.cn			Beijing Natural Science Foundation, China [4222037, L181010]	Beijing Natural Science Foundation, China(Beijing Natural Science Foundation)	This work is supported by the Beijing Natural Science Foundation, China (Nos. 4222037, L181010).	Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Baheti A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4846; Boratko M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1122; Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016; Camburu OM, 2018, ADV NEUR IN, V31; Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5; Chiang DC, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2310.05657; cjadams Sorensen J, 2017, TOXIC COMMENT CLASSI; Dai W, 2023, ARXIV, DOI [DOI 10.48550/ARXIV.2305.06500, 10.48550/arXiv.2305.06500]; Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121; Dinan E., 2019, 7 INT C LEARNING REP; Hanu L., 2020, Detoxify; Kim Hyunwoo, 2022, P 2022 C EMPIRICAL M, P4005, DOI 10.18653/v1/2022.emnlp-main.267; Kirillov A, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.02643; Li J., 2016, P 2016 C N AM CHAPTE, P110, DOI DOI 10.18653/V1; Li J., 2023, PMLR, P19730; Li Y., 2017, P 8 INT JOINT C NATU, P986; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Lison P, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P923; Liu H., 2023, ADV NEURAL INFORM PR, DOI DOI 10.48550/ARXIV.2304.08485; Liu P, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3510414; Mostafazadeh Nasrin, 2017, P 8 INT JOINT C NAT, V1, P462; Ouyang L., 2022, NEURIPS; Radford A, 2021, PR MACH LEARN RES, V139; Shuster K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2414; Sun K, 2019, T ASSOC COMPUT LING, V7, P217, DOI 10.1162/tacl_a_00264; Sun QF, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2854; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935; Wang J, 2023, SHOWLABIMAGE2PARAGRA; Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176; Wang S, 2021, ARXIV; Williams Jason D, 2016, Dialogue & Discourse, V7, P4; Wu J, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2212.00280; Wu Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P496, DOI 10.18653/v1/P17-1046; Xu XN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3981; Zang X., 2021, P 59 ANN M ASS COMPU, V1, P6142; Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204; Zheng Y, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P5778; Zhou C, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.11206; Zhou L, 2020, COMPUT LINGUIST, V46, P53, DOI [10.1162/coli_a_00368, 10.1162/COLI_a_00368]; Zhu D, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.10592	42	0	0	2	2	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X	1573-7497		APPL INTELL	Appl. Intell.	APR	2024	54	7					5891	5906		10.1007/s10489-024-05479-x	http://dx.doi.org/10.1007/s10489-024-05479-x		MAY 2024	16	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QN6M9					2024-07-03	WOS:001215042000002
J	Parra, V; Sureda, P; Corica, A; Schiaffino, S; Godoy, D				Parra, Veronica; Sureda, Patricia; Corica, Ana; Schiaffino, Silvia; Godoy, Daniela			Can Generative AI Solve Geometry Problems? Strengths and Weaknesses of LLMs for Geometric Reasoning in Spanish	INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE			English	Article						Chatbots; Generative AI; Geometry; LLMs; Math Problem-Solving		Generative Artificial Intelligence (AI) has emerged as a disruptive technology that is challenging traditional teaching and learning practices. Question -answering in natural language fosters the use of chatbots, such as ChatGPT, Bard and others, that generate text based on pre -trained Large Language Models (LLMs). The performance of these models in certain areas, like Math problem solving is receiving a crescent attention as it directly impacts on its potential use in educational settings. Most of these evaluations, however, concentrate on the construction and use of benchmarks comprising diverse Math problems in English. In this work, we discuss the capabilities of most used LLMs within the subfield of Geometry, in view of the relevance of this subject in high-school curricula and the difficulties exhibited by even most advanced multimodal LLMs to deal with geometric notions. This work focuses on Spanish, which is additionally a less resourced language. The answers of three major chatbots, based on different LLMs, were analyzed not only to determine their capacity to provide correct solutions, but also to categorize the errors found in the reasoning processes described. Understanding LLMs strengths and weaknesses in a field like Geometry can be a first step towards the design of more informed methodological proposals to include these technologies in classrooms as well as the development of more powerful automatic assistance tools based on generative AI.	[Parra, Veronica; Sureda, Patricia; Corica, Ana] Univ Nacl Ctr Prov Buenos Aires, Fac Ciencias Exactas, NIEM, Tandil, Buenos Aires, Argentina; [Schiaffino, Silvia; Godoy, Daniela] Univ Nacl Ctr Prov Buenos Aires, Fac Ciencias Exactas, ISISTAN, Tandil, Buenos Aires, Argentina; [Parra, Veronica; Sureda, Patricia; Corica, Ana; Schiaffino, Silvia; Godoy, Daniela] Consejo Nacl Invest Cient & Tecn, Buenos Aires, Argentina	Comision Nacional de Energia Atomica (CNEA); Comision Nacional de Energia Atomica (CNEA); Consejo Nacional de Investigaciones Cientificas y Tecnicas (CONICET)	Godoy, D (corresponding author), Univ Nacl Ctr Prov Buenos Aires, Fac Ciencias Exactas, ISISTAN, Tandil, Buenos Aires, Argentina.; Godoy, D (corresponding author), Consejo Nacl Invest Cient & Tecn, Buenos Aires, Argentina.	vparra@niem.exa.unicen.edu.ar; psureda@niem.exa.unicen.edu.ar; acorica@niem.exa.unicen.edu.ar; silvia.schiaffino@isistan.unicen.edu.ar; daniela.godoy@isistan.unicen.edu.ar	Godoy, Daniela/W-2190-2017	Godoy, Daniela/0000-0002-5185-4570				Abrate R., 2006, Revista Iberoamericana de Educacion, V39, P1, DOI DOI 10.35362/RIE3912598; Barrantes-López Manuel, 2012, Rev. Int. Investig. Cienc. Soc., V8, P25; Bosma M., 2023, Chain-of-thought prompting elicits reasoning in large language models; Bressan A. M., 2000, Razones para ensenar geometria en la educacion beisica: mirar, construir, decir y pensar, V1a; Brown T., 2020, P 34 INT C NEUR INF, V33, P1877; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Chowdhery A., 2022, Scaling language modeling with pathways; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Eko Y. S., 2018, Journal of Physics: Conference Series, V1097, DOI [10.1088/1742-6596/1097/1/012146, DOI 10.1088/1742-6596/1097/1/012146]; Fauring P., 2020, Olimpiadas de Mayo-XVII a XXIV; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Frieder S, 2023, Mathematical capabilities of chatgpt; Gao J., 2023, G-LLaVA: Solving geometric problem with multi-modal large language model; García-Peñalvo FJ, 2024, RIED-REV IBEROAM EDU, V27, DOI 10.5944/ried.27.1.37716; Gill S. S., 2024, Internet of Things and Cyber-Physical Systems, V4, P19, DOI [DOI 10.1016/J.IOTCPS.2023.06.002, 10.1016/j.iotcps.2023]; Glass B., 2004, Preceedings of the Twenty-eighth Annual Conference of the International Group for the Psychology of Mathematics Education, V2, P463; Han B., 2023, INT C ARTIFICIAL INT, V13916, P667, DOI [10.1007/978-3-031-36272-9_54, DOI 10.1007/978-3-031-36272-9_54]; Hendrycks D., 2021, P 35 C NEUR INF PROC; Liu H., 2023, NEURIPS; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Zunzarren GM, 2012, PROCD SOC BEHV, V46, P3209, DOI 10.1016/j.sbspro.2012.06.038; McCoy R. T., 2023, Embers of autoregression: Understanding large language models through the problem they are trained to solve; Memarian B., 2023, Comput Human Behav Artif Hum, V1, P100022, DOI DOI 10.1016/J.CHBAH.2023.100022; Ministerio de Educacion Argentina, 2006, Nucleos de Aprendizajes Prioritarios. Matemeitica. Ciclo Beisico Educacion Secundaria 1 y 2 / 2 y 3 An os; Mogavi R. H., 2024, Computers in Human Behavior: Artificial Humans, V2, DOI DOI 10.1016/J.CHBAH.2023.100027; Nguyen P., 2023, Evaluation of mathematics performance of Google Bard on the mathematics test of the vietnamese national high school graduation examination, V07, DOI [10.36227/techrxiv.23691876.v1, DOI 10.36227/TECHRXIV.23691876.V1]; OpenAI, 2023, Gpt-4 technical report. 2303.08774; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Plevris V., 2023, Chatbots put to the test in math and logic problems: A preliminary comparison and assessment of ChatGPT- 3.5, ChatGPT-4, and Google Bard; Santalo L., 2021, Revista de Educacion Matemeitica, V6, DOI [10.33044/revem.11101, DOI 10.33044/REVEM.11101]; Shakarian P., 2023, P AAAI 2023 SPRING S; Suarez C. R., 2021, Educacao Matemeitica Pesquisa, V22, DOI [10.23925/1983-3156.2020v22, DOI 10.23925/1983-3156.2020V22]; Wu Y., 2023, An empirical study on challenging math problem solving with GPT-4	33	0	0	22	22	UNIV INT RIOJA-UNIR	LOGRONO	RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN	1989-1660			INT J INTERACT MULTI	Int. J. Interact. Multimed. Artif. Intell.	MAR	2024	8	5								10.9781/ijimai.2024.02.009	http://dx.doi.org/10.9781/ijimai.2024.02.009			83	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KO8Q8		gold			2024-07-03	WOS:001181004000004
J	Shen, LX; Zhang, YZ; Zhang, HD; Wang, Y				Shen, Leixian; Zhang, Yizhi; Zhang, Haidong; Wang, Yun			Data Player: Automatic Generation of Data Videos with Narration-Animation Interplay	IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS			English	Article						Visualization; Narration-animation interplay; Data video; Human-AI collaboration	VISUALIZATION; STORIES	Data visualizations and narratives are often integrated to convey data stories effectively. Among various data storytelling formats, data videos have been garnering increasing attention. These videos provide an intuitive interpretation of data charts while vividly articulating the underlying data insights. However, the production of data videos demands a diverse set of professional skills and considerable manual labor, including understanding narratives, linking visual elements with narration segments, designing and crafting animations, recording audio narrations, and synchronizing audio with visual animations. To simplify this process, our paper introduces a novel method, referred to as Data Player, capable of automatically generating dynamic data videos with narration-animation interplay. This approach lowers the technical barriers associated with creating data videos rich in narration. To enable narration-animation interplay, Data Player constructs references between visualizations and text input. Specifically, it first extracts data into tables from the visualizations. Subsequently, it utilizes large language models to form semantic connections between text and visuals. Finally, Data Player encodes animation design knowledge as computational low-level constraints, allowing for the recommendation of suitable animation presets that align with the audio narration produced by text-to-speech technologies. We assessed Data Player's efficacy through an example gallery, a user study, and expert interviews. The evaluation results demonstrated that Data Player can generate high-quality data videos that are comparable to human-composed ones.	[Shen, Leixian] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Zhang, Yizhi] Cornell Univ, Ithaca, NY USA; [Zhang, Haidong; Wang, Yun] Microsoft Res Asia MSRA, Beijing, Peoples R China; [Shen, Leixian; Zhang, Yizhi] MSRA, Beijing, Peoples R China	Hong Kong University of Science & Technology; Cornell University	Wang, Y (corresponding author), Microsoft Res Asia MSRA, Beijing, Peoples R China.	lshenaj@connect.ust.hk; yz2668@cornell.edu; haizhang@microsoft.com; wangyun@microsoft.com						Amini F, 2018, AVI'18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON ADVANCED VISUAL INTERFACES, DOI 10.1145/3206505.3206552; Amini F, 2017, IEEE T VIS COMPUT GR, V23, P501, DOI 10.1109/TVCG.2016.2598647; Amini F, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1459, DOI 10.1145/2702123.2702431; Badam S. K., 2019, IEEE Transactions on Visualization and Computer Graphics, V25, P5; Cao YN, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581472; Chen Q., 2023, IEEE Transactions on Visualization and Computer Graphics, P1; Chen ZT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI [10.1145/3491102.3517485, 10.1109/TENCON55691.2022.9978005]; Cheng H, 2022, COMPUT GRAPH FORUM, V41, P527, DOI 10.1111/cgf.14560; Chi Peggy, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P677, DOI 10.1145/3472749.3474778; Chi Peggy, 2020, P 33 ANN ACM S US IN, P279, DOI DOI 10.1145/3379337.3415814; Clark JM, 1991, EDUC PSYCHOL REV, V3, P149, DOI 10.1007/BF01320076; Conlen M, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P977, DOI 10.1145/3242587.3242600; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; deeplearning, Chatgpt prompt engineering for developers; ffmpeg, Ffmpeg multimedia framework; Ge T, 2020, COMPUT GRAPH FORUM, V39, P607, DOI 10.1111/cgf.14005; Ge T., 2021, P 2021 CHI C HUM FAC, P1; greensock, Gsap animation platform; Heer J, 2007, IEEE T VIS COMPUT GR, V13, P1240, DOI 10.1109/TVCG.2007.70539; Hohman F, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P151, DOI [10.1109/visual.2019.8933695, 10.1109/VISUAL.2019.8933695]; Hook J, 2018, TVX 2018: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P43, DOI 10.1145/3210825.3210826; Kim DH, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P423, DOI 10.1145/3242587.3242617; Kim Y., 2021, IEEE Transactions on Visualization and Computer Graphics, V27, P2; Kim Y, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P201, DOI [10.1109/VIS49827.2021.9623291, 10.1109/VIS49827.2021.00048]; Kong N, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P31, DOI 10.1145/2556288.2557241; Lai CF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376443; Lan XY, 2022, IEEE T VIS COMPUT GR, V28, P933, DOI 10.1109/TVCG.2021.3114775; Latif S., 2021, IEEE Transactions on Visualization and Computer Graphics; Li HT, 2023, Arxiv, DOI arXiv:2304.08366; Li HT, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502048; Li W., 2023, P 2023 CHI C HUM FAC, V1, P1; Lin Y., 2023, IEEE Transactions on Visualization and Computer Graphics, V14, P9; Liu V., 2022, P 2022 CHI C HUM FAC, P1; Luo Y., 2023, Proceedings of the ACM on Management of Data, SIGMOD'23, V1, P1; Masson D., 2023, ACM C HUM FACT COMP; McKenna S, 2017, COMPUT GRAPH FORUM, V36, P377, DOI 10.1111/cgf.13195; Metoyer R, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P503, DOI 10.1145/3172944.3173007; microsoft, Microsoft azure text-to-speech service; Moritz D, 2019, IEEE T VIS COMPUT GR, V25, P438, DOI 10.1109/TVCG.2018.2865240; Ren DH, 2017, IEEE PAC VIS SYMP, P230, DOI 10.1109/PACIFICVIS.2017.8031599; Ruoff M., P 2023 CHI C HUM FAC, P1; Russell D. M., 2014, Ways of Knowing in HCI, P3; Segel E, 2010, IEEE T VIS COMPUT GR, V16, P1139, DOI 10.1109/TVCG.2010.179; Seyser D, 2018, IEEE INT CON INF VIS, P401, DOI 10.1109/iV.2018.00075; Shen Hua, 2023, arXiv; Shen L., 2021, P 23 EUR C VIS SHORT, DOI [DOI 10.2312/EVS.20211061, 10.2312/evs.20211061]; Shen L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1; Shen LX, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4975, DOI 10.1145/3511808.3557159; Shen LX, 2022, DATA SCI ENG, V7, P354, DOI 10.1007/s41019-022-00195-3; Shen LX, 2023, IEEE T VIS COMPUT GR, V29, P3121, DOI 10.1109/TVCG.2022.3148007; Shi D, 2021, COMPUT GRAPH FORUM, V40, P495, DOI 10.1111/cgf.14324; Shi Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445337; Srinivasan A, 2019, IEEE T VIS COMPUT GR, V25, P672, DOI 10.1109/TVCG.2018.2865145; Sultanum N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445354; Swearngin A, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376593; Thompson J, 2020, COMPUT GRAPH FORUM, V39, P207, DOI 10.1111/cgf.13974; Thompson J., 2021, P ACM C HUM FACT COM, P2; Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017; Wang Y., 2023, WonderFlow: Narration-Centric Design of Animated Data Videos, P1; Wang Yun, 2023, IEEE Trans Vis Comput Graph, V29, P1222, DOI 10.1109/TVCG.2022.3209357; Wang Y, 2021, COMPUT GRAPH FORUM, V40, P507, DOI 10.1111/cgf.14325; Wu AY, 2022, IEEE T VIS COMPUT GR, V28, P5049, DOI 10.1109/TVCG.2021.3099002; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Xie L., 2023, IEEE Transactions on Visualization and Computer Graphics, P1; Xu P., 2014, P 27 ANN ACM S US IN, P243, DOI DOI 10.1145/2642918.2647398; Ying L, 2022, IEEE T VIS COMPUT GR, V28, P400, DOI 10.1109/TVCG.2021.3114877; Zhi Q, 2019, COMPUT GRAPH FORUM, V38, P675, DOI 10.1111/cgf.13719; Zong J, 2023, IEEE T VIS COMPUT GR, V29, P149, DOI 10.1109/TVCG.2022.3209369	68	1	1	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1077-2626	1941-0506		IEEE T VIS COMPUT GR	IEEE Trans. Vis. Comput. Graph.	JAN	2024	30	1					109	119		10.1109/TVCG.2023.3327197	http://dx.doi.org/10.1109/TVCG.2023.3327197			11	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HJ3Z6	37922173	Green Submitted			2024-07-03	WOS:001159106500118
C	Ferdowsi, K; Williams, J; Drosos, I; Gordon, AD; Negreanu, C; Polikarpova, N; Sarkar, A; Zorn, B			IEEE	Ferdowsi, Kasra; Williams, Jack; Drosos, Ian; Gordon, Andrew D.; Negreanu, Carina; Polikarpova, Nadia; Sarkar, Advait; Zorn, Benjamin			ColDeco: An End User Spreadsheet Inspection Tool for AI-Generated Code	2023 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING, VL/HCC	Symposium on Visual Languages and Human Centric Computing VL HCC		English	Proceedings Paper	IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)	OCT 02-06, 2023	Martin Luther King Jr Memorial Lib, Washington, DC	IEEE, IEEE Comp Soc	Martin Luther King Jr Memorial Lib			Code-generating large language models (LLMs) are transforming programming. Their capability to generate multi-step solutions provides even non-programmers a mechanism to harness the power of coding. Non-programmers often use spreadsheets to manage tabular data, as they offer an intuitive understanding of data manipulation and formula out-comes. Considering that LLMs can generate complex, potentially incorrect code, our focus is on enabling user trust in the accuracy of LLM-generated code. We present ColDeco, the first end-user inspection tool for comprehending code produced by LLMs for tabular data tasks. ColDeco integrates two new features for inspection with a grid-based interface. First, users can decompose a generated solution into intermediate helper columns to understand how the problem is solved step by step. Second, users can interact with a filtered table of summary rows, which highlight interesting cases in the program. We evaluate our tool using a within-subjects user study (n=24) where participants are asked to verify the correctness of programs generated by an LLM. We found that while all features are independently useful, participants preferred them in combination. Users especially noted the usefulness of helper columns, but wanted more transparency in how summary rows are generated to assist with understanding and trusting them. Users also highlighted the application of ColDeco in collaborative settings for explaining and understanding existing formulas.	[Ferdowsi, Kasra; Polikarpova, Nadia] Univ Calif San Diego, La Jolla, CA 92093 USA; [Williams, Jack; Drosos, Ian; Gordon, Andrew D.; Negreanu, Carina; Sarkar, Advait] Microsoft Res, Cambridge, England; [Zorn, Benjamin] Microsoft Res, Redmond, WA USA	University of California System; University of California San Diego; Microsoft; Microsoft	Ferdowsi, K (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.	kferdows@ucsd.edu; jack.williams@microsoft.com; l-iandrosos@microsoft.com; adg@microsoft.com; cnegreanu@microsoft.com; npolikarpova@ucsd.edu; advait@microsoft.com; ben.zorn@microsoft.com		Williams, Jack/0000-0003-1925-7191				Abraham R, 2005, 2005 IEEE SYMPOSIUM ON VISUAL LANGUAGE AND HUMAN-CENTRIC COMPUTING, PROCEEDINGS, P189, DOI 10.1109/VLHCC.2005.70; Barke S., 2022, GROUNDED COPILOT PRO; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Chalhoub G, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501833; Chen M., 2021, ARXIV; Chowdhery A., 2022, ARXIV220402311; Dell N., 2012, participant response bias in HCI, P1321, DOI [10.1145/2207676.2208589, DOI 10.1145/2207676.2208589]; Dhamdhere K, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P493, DOI 10.1145/3025171.3025227; Dourish P., 2017, The Stuff of Bits: An Essay on the Materialities of Information, V1st ed.; Drosos I, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20); Du Boulay B., 1986, J ED COMPUTING RES, V2; Fariha A, 2020, PROC VLDB ENDOW, V13, P2861, DOI 10.14778/3415478.3415494; Fariha A, 2019, PROC VLDB ENDOW, V12, P1262, DOI 10.14778/3342263.3342266; Ferdowsi K., 2023, TECH REP; Flanagan Cormac, 1993, SIGPLAN Conf. Programming Language Design and Impl. (PLDI'93), P237, DOI [10.1145/173262.155113, 10.1145/155090.155113]; Friedman N., 2021, Introducing github copilot: your ai pair programmer; Gines M., 2022, BETTER INSIGHTS ANAL; GULWANI S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI [DOI 10.1145/1925844.1926423, DOI 10.1145/1926385.1926423]; GUO S, 2020, UIST 20, P627, DOI DOI 10.1145/3379337.3415900; Hall A., 2018, ARXIV180108603; James MB, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428273; KAY A, 1984, SCI AM, V251, P52, DOI 10.1038/scientificamerican0984-52; Ko AJ, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922658; Lau S, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445265; Lewis C., 1987, EMPIRICAL STUDIES PR, P248; Li Yujia, 2022, ARXIV220307814; Liang J. T., UNDERSTANDING USABIL; Liu M. X., 2023, P ACM CHI C HUM FACT; Mayer M, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P291, DOI 10.1145/2807442.2807459; McCutchen M, 2016, ONWARD!'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE, P112, DOI 10.1145/2986012.2986018; McNutt A. M., 2023, DESIGN AI POWERED CO; Miller G, 2016, S VIS LANG HUM CEN C, P240, DOI 10.1109/VLHCC.2016.7739696; Mozannar H., 2022, READING LINES MODELI; NARDI BA, 1990, HUMAN-COMPUTER INTERACTION : INTERACT 90, P977; Pal A., 2021, TOP 50 BESTSELLING N; Peleg H, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428227; Ramachandran A., 2022, TOP IMDB RATED TV SH; Rezig E, 2021, PROC VLDB ENDOW, V14, P2819, DOI 10.14778/3476311.3476353; Sarkar A., 2022, ARXIV220806213; Sarkar A, 2018, 2018 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P85, DOI 10.1109/VLHCC.2018.8506584; Sarkar Advait, 2022, 2022 IEEE S VIS LANG, P1; Schmitz T, 2017, S VIS LANG HUM CEN C, P117, DOI 10.1109/VLHCC.2017.8103458; SHNEIDERMAN B, 1983, COMPUTER, V16, P57, DOI 10.1109/MC.1983.1654471; Tohidi Maryam, 2006, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI '06, ACM, New York, NY, USA, P1243, DOI [10.1145/1124772.11249602, DOI 10.1145/1124772.11249602, 10.1145/1124772, DOI 10.1145/1124772.1124960]; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; WEISER M, 1984, IEEE T SOFTWARE ENG, V10, P352, DOI 10.1109/TSE.1984.5010248; Weisz JD, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P402, DOI 10.1145/3397481.3450656; Zhang S., 2022, arXiv; Ziegler A., 2022, PRODUCTIVITY ASSESSM	49	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1943-6092		979-8-3503-2946-9	S VIS LANG HUM CEN C			2023							82	91		10.1109/VL-HCC57772.2023.00017	http://dx.doi.org/10.1109/VL-HCC57772.2023.00017			10	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1AN					2024-07-03	WOS:001103187300009
J	Stengel, FC; Stienen, MN; Ivanov, M; Gandia-Gonz, ML; Raffa, G; Ganau, M; Whitfield, P; Motov, S				Stengel, Felix C.; Stienen, Martin N.; Ivanov, Marcel; Gandia-Gonz, Maria L.; Raffa, Giovanni; Ganau, Mario; Whitfield, Peter; Motov, Stefan			Can AI pass the written European Board Examination in Neurological Surgery? - Ethical and practical issues	BRAIN AND SPINE			English	Article						Neurosurgery board examination; Artificial intelligence; Chat gpt; Bing; Bard; EANS; Board-certification		Introduction: Artificial intelligence (AI) based large language models (LLM) contain enormous potential in education and training. Recent publications demonstrated that they are able to outperform participants in written medical exams. Research question: We aimed to explore the accuracy of AI in the written part of the EANS board exam. Material and methods: Eighty-six representative single best answer (SBA) questions, included at least ten times in prior EANS board exams, were selected by the current EANS board exam committee. The questions' content was classified as 75 text -based (TB) and 11 image -based (IB) and their structure as 50 interpretation -weighted, 30 theory -based and 6 true -or -false. Questions were tested with Chat GPT 3.5, Bing and Bard. The AI and participant results were statistically analyzed through ANOVA tests with Stata SE 15 (StataCorp, College Station, TX). Pvalues of <0.05 were considered as statistically significant. Results: The Bard LLM achieved the highest accuracy with 62% correct questions overall and 69% excluding IB, outperforming human exam participants 59% (p = 0.67) and 59% (p = 0.42), respectively. All LLMs scored highest in theory -based questions, excluding IB questions (Chat-GPT: 79%; Bing: 83%; Bard: 86%) and significantly better than the human exam participants (60%; p = 0.03). AI could not answer any IB question correctly. Discussion and conclusion: AI passed the written EANS board exam based on representative SBA questions and achieved results close to or even better than the human exam participants. Our results raise several ethical and practical implications, which may impact the current concept for the written EANS board exam.	[Stengel, Felix C.; Stienen, Martin N.; Motov, Stefan] Kantonsspital St Gallen, Dept Neurosurg, Rorschacher Str 95, CH-9007 St Gallen, Switzerland; [Stengel, Felix C.; Stienen, Martin N.; Motov, Stefan] Kantonsspital St Gallen, Spine Ctr Eastern Switzerland, Rorschacher Str 95, CH-9007 St Gallen, Switzerland; [Stengel, Felix C.; Stienen, Martin N.; Motov, Stefan] Med Sch St Gallen, St Gallen, Switzerland; [Ivanov, Marcel] Royal Hallamshire Hosp, Sheffield, England; [Gandia-Gonz, Maria L.] Hosp Univ La Paz, Madrid, Spain; [Raffa, Giovanni] Univ Messina, BIOMORF Dept, Div Neurosurg, Messina, Italy; [Ganau, Mario] Oxford Univ Hosp NHS Fdn Trust, Oxford, England; [Whitfield, Peter] South West Neurosurg Ctr, Plymouth, England	Kantonsspital St. Gallen; Kantonsspital St. Gallen; University of Sheffield; Hospital Universitario La Paz; University of Messina; Oxford University Hospitals NHS Foundation Trust	Motov, S (corresponding author), Kantonsspital St Gallen, Dept Neurosurg, Rorschacher Str 95, CH-9007 St Gallen, Switzerland.; Motov, S (corresponding author), Kantonsspital St Gallen, Spine Ctr Eastern Switzerland, Rorschacher Str 95, CH-9007 St Gallen, Switzerland.	stefan.motov@kssg.ch	Ivanov, Marcel/AAP-9201-2020	Ivanov, Marcel/0000-0003-3016-8931; Ganau, Mario/0000-0002-8676-1147; Stengel, Felix C./0009-0001-0415-3923; Stienen, Martin N./0000-0002-6417-1787; Motov, Stefan/0000-0003-1950-9168; Whitfield, Peter/0000-0003-0566-1820				Ali K., 2023, Eur. J. Dent. Educ.; Ben-Shabat N, 2021, JMIR MED INF, V9, DOI 10.2196/32507; EANS, 2023, EANS board examination webpage; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Guo AA, 2023, MED TEACH, V45, P1063, DOI 10.1080/0142159X.2023.2198094; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Klang E, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04752-w; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Mannam SS, 2023, WORLD NEUROSURG, V180, pE765, DOI 10.1016/j.wneu.2023.10.043; Medenilla A., 2023, PLoS Digital Health, V2; Saad A, 2023, SURG-J R COLL SURG E, V21, P263, DOI 10.1016/j.surge.2023.07.001; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Stengel FC, 2022, BRAIN SPINE, V2, DOI 10.1016/j.bas.2022.100929; Stienen MN, 2020, ACTA NEUROCHIR, V162, P2303, DOI 10.1007/s00701-020-04513-4; Stienen MN, 2017, ACTA NEUROCHIR, V159, P325, DOI 10.1007/s00701-016-3042-7; Stienen MN, 2016, ACTA NEUROCHIR, V158, P1823, DOI 10.1007/s00701-016-2917-y; Whitfield Peter C, 2023, Brain Spine, V3, P101744, DOI 10.1016/j.bas.2023.101744; Zoia C, 2022, J NEUROSURG SCI, V66, P473, DOI 10.23736/S0390-5616.22.05802-7	20	0	0	2	2	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2772-5294			BRAIN SPINE	Brain Spine		2024	4								102765	10.1016/j.bas.2024.102765	http://dx.doi.org/10.1016/j.bas.2024.102765		FEB 2024	8	Clinical Neurology	Emerging Sources Citation Index (ESCI)	Neurosciences & Neurology	LI2C3	38510593	Green Published, gold			2024-07-03	WOS:001186084800001
J	Chen, S; Li, YY; Lu, S; Van, H; Aerts, HJWL; Savova, GK; Bitterman, DS				Chen, Shan; Li, Yingya; Lu, Sheng; Van, Hoang; Aerts, Hugo J. W. L.; Savova, Guergana K.; Bitterman, Danielle S.			Evaluating the ChatGPT family of models for biomedical reasoning and classification	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						natural language processing; ChatGPT; biomedical research; classification; reasoning		Objective Large language models (LLMs) have shown impressive ability in biomedical question-answering, but have not been adequately investigated for more specific biomedical applications. This study investigates ChatGPT family of models (GPT-3.5, GPT-4) in biomedical tasks beyond question-answering.Materials and Methods We evaluated model performance with 11 122 samples for two fundamental tasks in the biomedical domain-classification (n = 8676) and reasoning (n = 2446). The first task involves classifying health advice in scientific literature, while the second task is detecting causal relations in biomedical literature. We used 20% of the dataset for prompt development, including zero- and few-shot settings with and without chain-of-thought (CoT). We then evaluated the best prompts from each setting on the remaining dataset, comparing them to models using simple features (BoW with logistic regression) and fine-tuned BioBERT models.Results Fine-tuning BioBERT produced the best classification (F1: 0.800-0.902) and reasoning (F1: 0.851) results. Among LLM approaches, few-shot CoT achieved the best classification (F1: 0.671-0.770) and reasoning (F1: 0.682) results, comparable to the BoW model (F1: 0.602-0.753 and 0.675 for classification and reasoning, respectively). It took 78 h to obtain the best LLM results, compared to 0.078 and 0.008 h for the top-performing BioBERT and BoW models, respectively.Discussion The simple BoW model performed similarly to the most complex LLM prompting. Prompt engineering required significant investment.Conclusion Despite the excitement around viral ChatGPT, fine-tuning for two fundamental biomedical natural language processing tasks remained the best strategy.	[Chen, Shan; Aerts, Hugo J. W. L.; Bitterman, Danielle S.] Harvard Med Sch, Artificial Intelligence Med AIM Program, Mass Gen Brigham, Boston, MA 02115 USA; [Chen, Shan; Aerts, Hugo J. W. L.; Bitterman, Danielle S.] Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiat Oncol, Boston, MA 02115 USA; [Li, Yingya; Van, Hoang; Savova, Guergana K.] Boston Childrens Hosp, Computat Hlth Informat Program, Boston, MA 02115 USA; [Li, Yingya; Van, Hoang; Savova, Guergana K.] Harvard Med Sch, Boston, MA 02115 USA; [Lu, Sheng] Tech Univ Darmstadt, Ubiquitous Knowledge Proc Lab UKP Lab, D-64289 Darmstadt, Germany; [Aerts, Hugo J. W. L.] Maastricht Univ, Radiol & Nucl Med, GROW, NL-6211 LK Maastricht, Netherlands; [Aerts, Hugo J. W. L.] Maastricht Univ, CARIM, NL-6211 LK Maastricht, Netherlands	Harvard University; Harvard Medical School; Harvard University; Brigham & Women's Hospital; Dana-Farber Cancer Institute; Harvard University; Boston Children's Hospital; Harvard University; Harvard Medical School; Technical University of Darmstadt; Maastricht University; Maastricht University; Maastricht University Medical Centre (MUMC)	Bitterman, DS (corresponding author), Harvard Med Sch, Artificial Intelligence Med AIM Program, Mass Gen Brigham, Boston, MA 02115 USA.; Bitterman, DS (corresponding author), Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiat Oncol, Boston, MA 02115 USA.	dbitterman@bwh.harvard.edu	Aerts, Hugo/ABF-2821-2020	Aerts, Hugo/0000-0002-2122-2003; Chen, Shan/0000-0001-7999-7410	US National Institutes of Health (NIH) [R01GM114355, R01LM013486]; Woods Foundation	US National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Woods Foundation	Funding support for this article was provided by the US National Institutes of Health (NIH) grant (R01GM114355 (Y.L.), R01LM013486 (H.V., G.S.)), Woods Foundation (S. C., D.B.).	Beam K, 2023, JAMA PEDIATR, V177, P977, DOI 10.1001/jamapediatrics.2023.2373; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Devlin J., 2018, BERT PRE TRAINING DE; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Guevara M., 2023, ARXIV; Kojima T., 2022, ARXIV; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lehman E., 2023, ARXIV; Li YY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6018; Lievin V., 2022, ARXIV; Lyu Q., 2023, ARXIV; Murk W, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.31205; Nori H., 2023, ARXIV; Ouyang L., 2022, NEURIPS PROCEESINGS; Ouyang L., 2022, ARXIV; platform.openai, OpenAI API; Reardon Sara., 2023, Scientific American; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Shi F., 2023, ARXIV; Singhal K, 2022, ARXIV; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Taylor R., 2022, ARXIV; Vaswani A., 2017, NEURIPS P; Wang J., 2023, arXiv; Wang X., 2022, ARXIV; Wei J., 2022, ARXIV; Yu B, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4664; Zuccon G., 2023, ARXIV	30	3	3	34	34	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	APR 3	2024	31	4					940	948		10.1093/jamia/ocad256	http://dx.doi.org/10.1093/jamia/ocad256		JAN 2024	9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	MU3W9	38261400	Green Submitted			2024-07-03	WOS:001146859600001
J	Buehler, MJ				Buehler, Markus J.			MeLM, a generative pretrained language modeling framework that solves forward and inverse mechanics problems	JOURNAL OF THE MECHANICS AND PHYSICS OF SOLIDS			English	Article						Mechanics; Attention; Transformer; Language model; Forward; Inverse; Design; Modeling; Multiscale; Atomistic; Encoding; Representation; Causal; Emergent; Collective; Graph neural network; GPT; Human -machine interaction	TRANSFORMER	We report a flexible multi-modal mechanics language model, MeLM, applied to solve various nonlinear forward and inverse problems, that can deal with a set of instructions, numbers and microstructure data. The framework is applied to various examples including bio-inspired hierarchical honeycomb design, carbon nanotube mechanics, and protein unfolding. In spite of the adaptable nature of the model-which allows us to easily incorporate diverse materials, scales, and mechanical features-it performs well across disparate forward and inverse tasks. Based on an autoregressive attention-model, MeLM effectively represents a large multi-particle system consisting of hundreds of millions of neurons, where the interaction potentials are discovered through graph-forming self-attention mechanisms that are then used to identify relationships from emergent structures, while taking advantage of synergies discovered in the training data. We show that the model can solve complex degenerate mechanics design problems and determine novel material architectures across a range of hierarchical levels, providing an avenue for materials discovery and analysis. To illustrate the use case for broader possibilities, we outline a human-machine interactive MechGPT model, here trained on a set of 1,103 Wikipedia articles related to mechanics, showing how the general framework can be used not only to solve forward and inverse problems but in addition, for complex language tasks like summarization, generation of new research concepts, and knowledge extraction. Looking beyond the demonstrations reported in this paper, we discuss other opportunities in applied mechanics and general considerations about the use of large language models in modeling, design, and analysis that can span a broad spectrum of material properties from mechanical, thermal, optical, to electronic.	[Buehler, Markus J.] MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Buehler, Markus J.] MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Buehler, MJ (corresponding author), MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	mbuehler@mit.edu	Buehler, Markus/C-4580-2008	Buehler, Markus/0000-0002-4173-9659	MIT-IBM Watson AI Lab; Army Research Office [W911NF1920098, W911NF2220213]; ONR [N00014-19-1-2375, N00014-20-1-2189]; USDA [2021-69012-35978]	MIT-IBM Watson AI Lab(International Business Machines (IBM)); Army Research Office; ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); USDA(United States Department of Agriculture (USDA))	This work was supported by the MIT-IBM Watson AI Lab, the Army Research Office (W911NF1920098 & W911NF2220213) , ONR (N00014-19-1-2375 and N00014-20-1-2189) , as well as USDA (2021-69012-35978) .	Abid A., 2019, Gradio: Hassle-Free Sharing and Testing of ML Models in the Wild'; Abid N, 2019, J MECH PHYS SOLIDS, V124, P350, DOI 10.1016/j.jmps.2018.10.012; Aboelkassem Y, 2019, CURR OPIN BIOMED ENG, V11, P35, DOI 10.1016/j.cobme.2019.09.005; Akinwande D, 2017, EXTREME MECH LETT, V13, P42, DOI 10.1016/j.eml.2017.01.008; Alber M, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0193-y; Andonian A., GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch; Barreiro DL, 2019, MACROMOL BIOSCI, V19, DOI 10.1002/mabi.201800253; BATES M, 1995, P NATL ACAD SCI USA, V92, P9977, DOI 10.1073/pnas.92.22.9977; Bock FE, 2019, FRONT MATER, V6, DOI 10.3389/fmats.2019.00110; Brodnik NR, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062773; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buehler MJ, 2023, J APPL PHYS, V134, DOI 10.1063/5.0157367; Buehler MJ, 2023, MODEL SIMUL MATER SC, V31, DOI 10.1088/1361-651X/accfb5; Buehler MJ, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100692; Buehler MJ, 2023, J MATER RES, V38, P1317, DOI 10.1557/s43578-023-00892-3; Buehler MJ, 2022, ACCOUNTS CHEM RES, V55, P3387, DOI 10.1021/acs.accounts.2c00330; Buehler MJ, 2022, J APPL MECH-T ASME, V89, DOI 10.1115/1.4055730; Buehler MJ, 2022, MATER TODAY, V57, P9, DOI 10.1016/j.mattod.2022.05.020; Buehler MJ, 2005, ACTA MECH SINICA-PRC, V21, P103, DOI 10.1007/s10409-005-0019-9; Buehler MJ, 2003, COMP MATER SCI, V28, P385, DOI 10.1016/j.commatsci.2003.08.001; Canadija M, 2021, CARBON, V184, P891, DOI 10.1016/j.carbon.2021.08.091; Chen X, 2022, AIP ADV, V12, DOI 10.1063/5.0080842; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du ZY, 2021, NAT PROTOC, V16, P5634, DOI 10.1038/s41596-021-00628-9; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; falconllm, Falcon LLM-Home; Gao EL, 2018, J MECH PHYS SOLIDS, V115, P248, DOI 10.1016/j.jmps.2018.03.014; Giesa T, 2012, ADV ENG MATER, V14, P810, DOI 10.1002/adem.201200109; Guo K, 2021, MATER HORIZ, V8, P1153, DOI 10.1039/d0mh01451f; Guo K, 2020, EXTREME MECH LETT, V41, DOI 10.1016/j.eml.2020.101029; Hanakata PZ, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.255304; He XL, 2021, COMPUT METHOD APPL M, V385, DOI 10.1016/j.cma.2021.114034; He-Yueya J., 2023, Solving math word problems by combining language models with symbolic solvers; Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, 10.48550/arXiv.1606.08415]; Hsu YC, 2022, APL MATER, V10, DOI 10.1063/5.0082338; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu Yiwen, 2023, APL Machine Learning, DOI 10.1063/5.0134317; Hu YW, 2022, ACS NANO, V16, P20656, DOI 10.1021/acsnano.2c07681; Jang E., 2017, P 5 INT C LEARN REPR; Jung GS, 2017, ANNU REV BIOMED ENG, V19, P435, DOI 10.1146/annurev-bioeng-071516-044555; Kingma D. P., 2017, ARXIV; Kitaev N, 2020, REFORMER EFFICIENT T; Lejeune E, 2020, EXTREME MECH LETT, V36, DOI 10.1016/j.eml.2020.100659; Lew AJ, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01036-1; Lew AJ, 2023, MATER TODAY, V64, P10, DOI 10.1016/j.mattod.2023.03.007; Li XY, 2009, P NATL ACAD SCI USA, V106, P16108, DOI 10.1073/pnas.0901765106; Liu FYC, 2022, EXTREME MECH LETT, V55, DOI 10.1016/j.eml.2022.101803; Liu YZ, 2022, J MECH PHYS SOLIDS, V168, DOI 10.1016/j.jmps.2022.105043; Lu Y., 2021, Roformer: Enhanced transformer with rotary position embedding; Luu RK, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062310; Luu RK, 2023, APPL PHYS LETT, V122, DOI 10.1063/5.0155890; Maddison Chris J, 2016, ARXIV161100712; Marcus G., A very preliminary analysis of DALL-E, P2; Martínez-Martínez F, 2017, COMPUT BIOL MED, V90, P116, DOI 10.1016/j.compbiomed.2017.09.019; McCulloch AD, 2023, J GEN PHYSIOL, V155, DOI 10.1085/jgp.202313388; Micheli V., 2022, Transformers are sample efficient world models; Ni B, 2023, CHEM-US, V9, P1828, DOI 10.1016/j.chempr.2023.03.020; Noé F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331; Paszke A, 2019, ADV NEUR IN, V32; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Peng GCY, 2021, ARCH COMPUT METHOD E, V28, P1017, DOI 10.1007/s11831-020-09405-5; Radford A., 2023, Improving Language understanding by generative pre-training; Radford A., 2023, Language Models are Unsupervised Multitask Learners; Radford A, 2021, PR MACH LEARN RES, V139; Schleder GR, 2019, J PHYS-MATER, V2, DOI 10.1088/2515-7639/ab084b; Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576; Sikora M, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000547; Spivak DI, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023911; Suwardi A, 2022, ADV MATER, V34, DOI 10.1002/adma.202102703; Taylor R., 2022, Galactica: A large language model for science; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic G., 2018, 6 INT C LEARNING REP; Wang S, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005324; Xue K, 2021, MATER TODAY BIO, V12, DOI 10.1016/j.mtbio.2021.100165; Xue LT, 2022, T ASSOC COMPUT LING, V10, P291, DOI 10.1162/tacl_a_00461; Yang ZZ, 2023, J MECH PHYS SOLIDS, V170, DOI 10.1016/j.jmps.2022.105098; Yang ZZ, 2021, FRONT MATER, V8, DOI 10.3389/fmats.2021.740754; Yang ZZ, 2021, J MECH PHYS SOLIDS, V154, DOI 10.1016/j.jmps.2021.104506; Yu J., 2021, Vector-quantized image modeling with improved vqgan; Zhou HF, 2022, J MECH PHYS SOLIDS, V159, DOI 10.1016/j.jmps.2021.104746	86	14	14	18	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0022-5096	1873-4782		J MECH PHYS SOLIDS	J. Mech. Phys. Solids	DEC	2023	181								105454	10.1016/j.jmps.2023.105454	http://dx.doi.org/10.1016/j.jmps.2023.105454		OCT 2023	24	Materials Science, Multidisciplinary; Mechanics; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Materials Science; Mechanics; Physics	Y7HE3		Green Submitted			2024-07-03	WOS:001106926600001
J	Abi-Rafeh, J; Cattelan, L; Xu, HH; Bassiri-Tehrani, B; Kazan, R; Nahai, F				Abi-Rafeh, Jad; Cattelan, Leila; Xu, Hong Hao; Bassiri-Tehrani, Brian; Kazan, Roy; Nahai, Foad			Artificial Intelligence-Generated Social Media Content Creation and Management Strategies for Plastic Surgeons	AESTHETIC SURGERY JOURNAL			English	Article							GLOBALIZATION	Background Social media platforms have come to represent integral components of the professional marketing and advertising strategy for plastic surgeons. Effective and consistent content development, however, remains technically demanding and time consuming, prompting most to employ, at non-negligible costs, social media marketing specialists for content planning and development.Objectives In the present study, we aimed to investigate the ability of presently available artificial intelligence (AI) models to assist plastic surgeons in their social media content development and sharing plans.Methods An AI large language model was prompted on the study's objectives through a series of standardized user interactions. Social media platforms of interest, on which the AI model was prompted, included Instagram, TikTok, and X (formerly Twitter).Results A 1-year, entirely AI-generated social media plan, comprising a total of 1091 posts for the 3 aforementioned social media platforms, is presented. Themes of the AI-generated content proposed for each platform were classified in 6 categories, including patient-related, practice-related, educational, "uplifting," interactive, and promotional posts. Overall, 91 publicly recognized holidays and observant and awareness days were incorporated into the content calendars. The AI model demonstrated an ability to differentiate between the distinct formats of each of the 3 social media platforms investigated, generating unique ideas for each, and providing detailed content development and posting instructions, scripts, and post captions, leveraging features specific to each platform.Conclusions By providing detailed and actionable social media content creation and posting plans to plastic surgeons, presently available AI models can be readily leveraged to assist in and significantly alleviate the burden associated with social media account management, content generation, and potentially patient conversion.	[Abi-Rafeh, Jad; Kazan, Roy] McGill Univ Hlth Ctr, Div Plast Reconstruct & Aesthet Surg, Montreal, PQ, Canada; [Cattelan, Leila] McGill Univ Hlth Ctr, Dept Med, Montreal, PQ, Canada; [Xu, Hong Hao] Laval Univ, Fac Med, Quebec City, PQ, Canada; [Nahai, Foad] Emory Univ, Div Plast & Reconstruct Surg, 875 Johnson Ferry Rd NE, Atlanta, GA 30304 USA	McGill University; McGill University; Laval University; Emory University	Nahai, F (corresponding author), Emory Univ, Div Plast & Reconstruct Surg, 875 Johnson Ferry Rd NE, Atlanta, GA 30304 USA.	nahaimd@aol.com		Abi-Rafeh, Jad/0000-0002-7483-1515; Bassiri-Tehrani, Brian/0000-0003-4891-4920				Abi-Rafeh J, 2023, AESTHET SURG J, V43, pNP1098, DOI 10.1093/asj/sjad277; Abi-Rafeh J, 2023, AESTHET PLAST SURG, DOI 10.1007/s00266-023-03538-1; Abi-Rafeh J, 2024, AESTHET SURG J, V44, P329, DOI 10.1093/asj/sjad260; Abi-Rafeh J, 2023, AESTHET SURG J, V43, pNP726, DOI 10.1093/asj/sjad162; Aiello AE, 2020, ANNU REV PUBL HEALTH, V41, P101, DOI 10.1146/annurev-publhealth-040119-094402; Alderson D, 2010, MED TEACH, V32, P830, DOI 10.3109/01421591003695329; Alves H, 2016, PSYCHOL MARKET, V33, P1029, DOI 10.1002/mar.20936; Atiyeh BS, 2021, AESTHET PLAST SURG, V45, P1310, DOI 10.1007/s00266-020-01961-2; Auxier B, 2021, SOCIAL MEDIA USE 202; Axelrod DA, 2000, ARCH SURG-CHICAGO, V135, P55, DOI 10.1001/archsurg.135.1.55; Bassiri-Tehrani B, 2023, AESTHET SURG J, V43, P1395, DOI 10.1093/asj/sjad135; Bernat JL, 2006, ARCH SURG-CHICAGO, V141, P86, DOI 10.1001/archsurg.141.1.86; Birney A., ANDROID AUTHORITY; Black E., 2018, CNBC; Cevallos PC, 2023, AESTHET SURG J, V43, pNP1083, DOI 10.1093/asj/sjad171; Chandawarkar AA, 2018, AESTHET SURG J, V38, P913, DOI 10.1093/asj/sjy024; Chavez MR, 2023, AM J OBSTET GYNECOL, V228, P706, DOI 10.1016/j.ajog.2023.03.010; Chen JH, 2021, J MED INTERNET RES, V23, DOI 10.2196/17917; Cho MJ, 2020, PLAST RECONSTR SURG, V146, p83E, DOI 10.1097/PRS.0000000000006936; Cho MJ, 2019, PLAST RECONSTR SURG, V143, P1533, DOI 10.1097/PRS.0000000000005533; Constantinides E, 2014, PROCD SOC BEHV, V148, P40, DOI 10.1016/j.sbspro.2014.07.016; Cook B., HOSPITALSNEW SPECIAL; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Cress PE, 2023, AESTHET SURG J, V43, P938, DOI 10.1093/asj/sjad163; Dhawan R, 2024, AESTHET SURG J, V44, pNP323, DOI 10.1093/asj/sjad357; Dorfman RG, 2019, AESTHET SURG J, V39, P447, DOI 10.1093/asj/sjy285; Dwivedi Y.K., 2015, MARKETING REV, V15, P289, DOI [10.1362/146934715X14441363377999, DOI 10.1362/146934715X14441363377999]; Ge J, 2023, HEPATOL COMMUN, V7, DOI 10.1097/HC9.0000000000000097; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Hutton G, 2011, J ADVERTISING RES, V51, P564, DOI 10.2501/JAR-51-4-564-570; Jakubanis R., OPENAI; Kennedy ED, 2021, BRIT J SURG, V108, P435, DOI 10.1093/bjs/znaa087; Klietz ML, 2020, AESTHET SURG J, V40, P577, DOI 10.1093/asj/sjz204; Long EA, 2023, PLAST RECONSTR SURG, V151, p1043E, DOI 10.1097/PRS.0000000000010121; Malik A., 2022, TECHCRUNCH; Najafali D, 2023, AESTHET SURG J, V43, pNP715, DOI 10.1093/asj/sjad119; Nguyen W., DETAILED LOOK 10 MOS; Oladipo T., BUFFER; Palacios JF, 2023, AESTHET SURG J, V43, pNP918, DOI 10.1093/asj/sjad197; Roberts RHR, 2024, AESTHET SURG J OPEN, V6, DOI 10.1093/asjof/ojad109; Rosenfield LK, 2023, AESTHET SURG J, V43, P109, DOI 10.1093/asj/sjac182; Satava RM, 2003, J AM COLL SURGEONS, V196, P933, DOI 10.1016/S1072-7515(03)00237-0; Schroeder R, 2016, INT J COMMUN-US, V10, P5626; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Seth I, 2023, AESTHET SURG J, V43, pNP809, DOI 10.1093/asj/sjad210; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Staudacher N., OPENAL; Steele SR, 2015, SURGERY, V158, P857, DOI 10.1016/j.surg.2015.06.002; Sultan DL, 2022, PLAST RECONSTR SURG, V150, P1368, DOI 10.1097/PRS.0000000000009702; Sun YX, 2023, AESTHET SURG J, V43, pNP670, DOI 10.1093/asj/sjad134; Tang JB, 2016, J HAND SURG-EUR VOL, V41, P365, DOI 10.1177/1753193416641590; TikTok, CAMERA TOOLS VIDEO L; Vardanian AJ, 2013, PLAST RECONSTR SURG, V131, P1184, DOI 10.1097/PRS.0b013e318287a072; Zhou JY, 2023, AESTHET SURG J, V43, pNP720, DOI 10.1093/asj/sjad158	56	0	0	11	11	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1090-820X	1527-330X		AESTHET SURG J	Aesthet. Surg. J.	MAR 28	2024	44	7					769	778		10.1093/asj/sjae036	http://dx.doi.org/10.1093/asj/sjae036		FEB 2024	10	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	UE0H8	38366026				2024-07-03	WOS:001193092800001
J	Huynh, LM; Bonebrake, BT; Schultis, K; Quach, A; Deibert, CM				Huynh, Linda My; Bonebrake, Benjamin T.; Schultis, Kaitlyn; Quach, Alan; Deibert, Christopher M.			New Artificial Intelligence ChatGPT Performs Poorly on the 2022 Self-assessment Study Program for Urology	UROLOGY PRACTICE			English	Article						artificial intelligence; medical informatics applications; urology		Introduction:Large language models have demonstrated impressive capabilities, but application to medicine remains unclear. We seek to evaluate the use of ChatGPT on the American Urological Association Self-assessment Study Program as an educational adjunct for urology trainees and practicing physicians.Methods:One hundred fifty questions from the 2022 Self-assessment Study Program exam were screened, and those containing visual assets (n=15) were removed. The remaining items were encoded as open ended or multiple choice. ChatGPT's output was coded as correct, incorrect, or indeterminate; if indeterminate, responses were regenerated up to 2 times. Concordance, quality, and accuracy were ascertained by 3 independent researchers and reviewed by 2 physician adjudicators. A new session was started for each entry to avoid crossover learning.Results:ChatGPT was correct on 36/135 (26.7%) open-ended and 38/135 (28.2%) multiple-choice questions. Indeterminate responses were generated in 40 (29.6%) and 4 (3.0%), respectively. Of the correct responses, 24/36 (66.7%) and 36/38 (94.7%) were on initial output, 8 (22.2%) and 1 (2.6%) on second output, and 4 (11.1%) and 1 (2.6%) on final output, respectively. Although regeneration decreased indeterminate responses, proportion of correct responses did not increase. For open-ended and multiple-choice questions, ChatGPT provided consistent justifications for incorrect answers and remained concordant between correct and incorrect answers.Conclusions:ChatGPT previously demonstrated promise on medical licensing exams; however, application to the 2022 Self-assessment Study Program was not demonstrated. Performance improved with multiple-choice over open-ended questions. More importantly were the persistent justifications for incorrect responses-left unchecked, utilization of ChatGPT in medicine may facilitate medical misinformation.	[Huynh, Linda My] Univ Nebraska Med Ctr, Omaha, NE USA; [Bonebrake, Benjamin T.; Schultis, Kaitlyn] Univ Nebraska Med Ctr, Coll Med, Omaha, NE USA; [Quach, Alan; Deibert, Christopher M.] Univ Nebraska Med Ctr, Div Urol, Omaha, NE USA; [Deibert, Christopher M.] Univ Nebraska Med Ctr, Dept Surg, Div Urol, 987521 Nebraska Med Ctr, Omaha, NE 68198 USA	University of Nebraska System; University of Nebraska Medical Center; University of Nebraska System; University of Nebraska Medical Center; University of Nebraska System; University of Nebraska Medical Center; University of Nebraska System; University of Nebraska Medical Center	Deibert, CM (corresponding author), Univ Nebraska Med Ctr, Dept Surg, Div Urol, 987521 Nebraska Med Ctr, Omaha, NE 68198 USA.	linda.huynh@unmc.edu; benjamin.bonebrake@unmc.edu; kaitlyn.schultis@unmc.edu; alan.quach@unmc.edu; christopher.deibert@unmc.edu						Ahmed I, 2022, INTERDISCIP SCI, V14, P504, DOI 10.1007/s12539-021-00465-0; American Urological Association, 2022, SELF ASS STUD PROGR; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Baine M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020017; Choi JH, 2303 MINN LEG STUD R; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Harikrishnan NB, 2022, MED BIOL ENG COMPUT, V60, P2245, DOI 10.1007/s11517-022-02591-3; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; IBM Corp, 2021, IBM SPSS Statistics for Windows, Version 28.0; Jia LL, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.1026216; Karpicke JD, 2012, CURR DIR PSYCHOL SCI, V21, P157, DOI 10.1177/0963721412443552; Katsufrakis PJ., 2018, J GRADUATE MED EDU, V10, P421; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; OpenAI, 2020, GPT 3 175B COMP SOFT; OpenAI, 2021, CHATGPT V4; Paab G., ARXIV; Pangaro LN., 2011, CLIN ANAT, V24, P275; Peterson AC., 2019, J UROLOGY, V202, P446; Preuss K, 2022, CANCERS, V14, DOI 10.3390/cancers14071654; Singhal K., ARXIV; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	23	22	22	2	9	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	2352-0779	2352-0787		UROL PRACT	Urol. Pract.	JUL	2023	10	4					408	+		10.1097/UPJ.0000000000000406	http://dx.doi.org/10.1097/UPJ.0000000000000406			8	Urology & Nephrology	Emerging Sources Citation Index (ESCI)	Urology & Nephrology	P3XV7	37276372				2024-07-03	WOS:001050017200035
J	Tangadulrat, P; Sono, S; Tangtrakulwanich, B				Tangadulrat, Pasin; Sono, Supinya; Tangtrakulwanich, Boonsin			Using ChatGPT for Clinical Practice and Medical Education: Cross-Sectional Survey of Medical Students' and Physicians' Perceptions	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; AI; artificial intelligence; medical education; medical students; student; students; intern; interns; resident; residents; knee osteoarthritis; survey; surveys; questionnaire; questionnaires; chatbot; chatbots; conversational agent; conversational agents; attitude; attitudes; opinion; opinions; perception; perceptions; perspective; perspectives; acceptance		Background: ChatGPT is a well-known large language model-based chatbot. It could be used in the medical field in many aspects. However, some physicians are still unfamiliar with ChatGPT and are concerned about its benefits and risks. Objective: We aim to evaluate the perception of physicians and medical students toward using ChatGPT in the medical field. Methods: A web-based questionnaire was sent to medical students, interns, residents, and attending staff with questions regarding their perception toward using ChatGPT in clinical practice and medical education. Participants were also asked to rate their perception of ChatGPT's generated response about knee osteoarthritis. Results: Participants included 124 medical students, 46 interns, 37 residents, and 32 attending staff. After reading ChatGPT's response, 132 of the 239 (55.2%) participants had a positive rating about using ChatGPT for clinical practice. The proportion of positive answers was significantly lower in graduated physicians (48/115, 42%) compared with medical students (84/124, 68%; P<.001). Participants listed a lack of a patient-specific treatment plan, updated evidence, and a language barrier as ChatGPT's pitfalls. Regarding using ChatGPT for medical education, the proportion of positive responses was also significantly lower in graduate physicians (71/115, 62%) compared to medical students (103/124, 83.1%; P<.001). Participants were concerned that ChatGPT's response was too superficial, might lack scientific evidence, and might need expert verification. Conclusions: Medical students generally had a positive perception of using ChatGPT for guiding treatment and medical education, whereas graduated doctors were more cautious in this regard. Nonetheless, both medical students and graduated doctors positively perceived using ChatGPT for creating patient educational materials.	[Tangadulrat, Pasin; Tangtrakulwanich, Boonsin] Prince Songkla Univ, Fac Med, Dept Orthoped, Floor 9 Rattanacheewarak Bldg,15 Kanchanavanich Rd, Hat Yai 90110, Thailand; [Sono, Supinya] Prince Songkla Univ, Fac Med, Div Family & Prevent Med, Hat Yai, Thailand	Prince of Songkla University; Prince of Songkla University	Tangtrakulwanich, B (corresponding author), Prince Songkla Univ, Fac Med, Dept Orthoped, Floor 9 Rattanacheewarak Bldg,15 Kanchanavanich Rd, Hat Yai 90110, Thailand.	boonsin.b@psu.ac.th		Tangadulrat, Pasin/0000-0003-0346-7135; Sono, Supinya/0000-0003-3145-1907				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Benhenneda R, 2023, ORTHOP TRAUMATOL-SUR, V109, DOI 10.1016/j.otsr.2023.103652; Coppock James A, 2023, Osteoarthr Cartil Open, V5, P100378, DOI 10.1016/j.ocarto.2023.100378; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Flores-Cohaila JA, 2023, JMIR MED EDUC, V9, DOI 10.2196/48039; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Hsu HY, 2023, JMIR MED EDUC, V9, DOI 10.2196/48433; Huang RST, 2023, JMIR MED EDUC, V9, DOI 10.2196/50514; Hueber AJ, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003248; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Huynh LM, 2023, UROL PRACT, V10, P408, DOI 10.1097/UPJ.0000000000000406; Kim MS, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10060632; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Li XY, 2022, J MED INTERNET RES, V24, DOI 10.2196/40681; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Niszczota P, 2023, NUTRITION, V112, DOI 10.1016/j.nut.2023.112076; Roos J, 2023, JMIR MED EDUC, V9, DOI 10.2196/46482; Salimi A, 2023, AM J OPHTHALMOL, V254, P177, DOI 10.1016/j.ajo.2023.06.004; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Sharma S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38380; Svab I, 2023, ZDRAV VARST, V62, P109, DOI 10.2478/sjph-2023-0015; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Tsang R, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231178449; Wang H, 2022, J MED INTERNET RES, V24, DOI 10.2196/29969; Weeks R, 2022, J MED INTERNET RES, V24, DOI 10.2196/38418; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946	38	5	5	22	23	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e50658	10.2196/50658	http://dx.doi.org/10.2196/50658			8	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	FM3B4	38133908	gold			2024-07-03	WOS:001146166500001
C	Chang, WC; Jiang, JY; Zhang, J; Al-Darabsah, M; Teo, CH; Hsieh, CJ; Yu, HF; Vishwanathan, SVN			Assoc computing machinery	Chang, Wei-Cheng; Jiang, Jyun-Yu; Zhang, Jiong; Al-Darabsah, Mutasem; Teo, Choon Hui; Hsieh, Cho-Jui; Yu, Hsiang-Fu; Vishwanathan, S. V. N.			PEFA: Parameter-Free Adapters for Large-scale Embedding-based Retrieval Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		embedding-based retrieval; bi-encoders; parameter-free adapters; k-nearest neighbor models		Embedding-based Retrieval Models (ERMs) have emerged as a promising framework for large-scale text retrieval problems due to powerful large language models. Nevertheless, fine-tuning ERMs to reach state-of-the-art results can be expensive due to the extreme scale of data as well as the complexity of multi-stages pipelines (e.g., pre-training, fine-tuning, distillation). In this work, we propose the PEFA framework, namely ParamEter-Free Adapters, for fast tuning of ERMs without any backward pass in the optimization. At index building stage, PEFA equips the ERM with a non-parametric. k-nearest neighbor (kNN) component. At inference stage, PEFA performs a convex combination of two scoring functions, one from the ERM and the other from the kNN. Based on the neighborhood definition, PEFA framework induces two realizations, namely PEFA-XL (i.e., extra large) using double ANN indices and PEFA-XS (i.e., extra small) using a single ANN index. Empirically, PEFA achieves significant improvement on two retrieval applications. For document retrieval, regarding Recall@100 metric, PEFA improves not only pre-trained ERMs on Trivia-QA by an average of 13.2%, but also fine-tuned ERMs on NQ-320K by an average of 5.5%, respectively. For product search, PEFA improves the Recall@100 of the fine-tuned ERMs by an average of 5.3% and 14.5%, for PEFA-XS and PEFA-XL, respectively. Our code is available at https://github.com/amzn/pecos/tree/mainline/examples/pefa-wsdm24.	[Chang, Wei-Cheng] Amazon, Seattle, WA 98109 USA; [Jiang, Jyun-Yu; Zhang, Jiong; Al-Darabsah, Mutasem; Teo, Choon Hui; Yu, Hsiang-Fu; Vishwanathan, S. V. N.] Amazon, Palo Alto, CA USA; [Hsieh, Cho-Jui] UCLA, Los Angeles, CA USA	Amazon.com; Amazon.com; University of California System; University of California Los Angeles	Chang, WC (corresponding author), Amazon, Seattle, WA 98109 USA.	weicheng.cmu@gmail.com; jyunyu.jiang@gmail.com; zhangjiong724@gmail.com; mutasema@amazon.com; choonhui@amazon.com; chohsieh@cs.ucla.edu; rofu.yu@gmail.com; vishy@amazon.com		Hsieh, Cho-Jui/0000-0002-3520-9627; Chang, Wei-Cheng/0000-0002-5646-9356; S. V. N., Vishwanathan/0009-0007-0041-3488				[Anonymous], 2020, ADV NEUR IN; Aumüller M, 2020, INFORM SYST, V87, DOI 10.1016/j.is.2019.02.006; Bevilacqua M., 2022, Advances in Neural Information Processing Systems, V35, P31668; Borgeaud S, 2022, PR MACH LEARN RES; Brown T., 2020, P ADV NEUR INF PROC, P1877; Chang WC, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2643, DOI 10.1145/3447548.3467092; Chang Wei-Cheng, 2020, 8 INT C LEARN REPR I; Chen Patrick H, 2019, INT C LEARN REPR ICL; Chien Eli, 2022, INT C LEARN REPR ICL; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Formal T, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2353, DOI 10.1145/3477495.3531857; Gao LY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P981; Gao LY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2843; Guo JF, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3486250; Guo RQ, 2020, PR MACH LEARN RES, V119; Guu K, 2020, PR MACH LEARN RES, V119; He JX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5703; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu E.J., 2022, INT C LEARN REPR; Huang JT, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2553, DOI 10.1145/3394486.3403305; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Jain H, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P528, DOI 10.1145/3289600.3290979; Jiang JY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2177, DOI 10.1145/3366423.3380283; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Joshi A, 2022, 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2022, P160; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Jung E, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P502, DOI 10.1145/3485447.3511978; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khandelwal Urvashi, 2020, INT C LEARN REPR; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lin SC, 2021, REPL4NLP 2021: PROCEEDINGS OF THE 6TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P163; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lu HQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P146; Ma XY, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P1471, DOI 10.1145/3511808.3557445; Magnani A, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3495, DOI 10.1145/3534678.3539164; Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473; Muhamed Aashiq, 2023, ADV KNOWLEDGE DISCOV; Ni JM, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P1864; Ni Jianmo, 2022, P 2022 C EMPIRICAL M, P9844; Nigam P, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2876, DOI 10.1145/3292500.3330759; Pal V, 2023, LECT NOTES COMPUT SC, V13981, P16, DOI 10.1007/978-3-031-28238-6_2; Reimers N, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P605; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Ren RY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2825; Ren RY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2173; Shen YL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P373, DOI 10.1145/2567948.2577348; Song K., 2020, Adv. Neural Inf. Process. Syst, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297; Song LYH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2909, DOI 10.1145/3394486.3403342; Subramanya SJ, 2019, ADV NEUR IN, V32; Tang Zhengyang, 2022, P 29 INT C COMP LING, P1193; Tay Y., 2022, Advances in Neural Information Processing Systems, V35, P21831; Wang L, 2024, Arxiv, DOI arXiv:2212.03533; Wang MZ, 2021, Arxiv, DOI arXiv:2101.12631; Wang Y., 2022, Advances in Neural Information Processing Systems, V35, P25600; Wu F, 2019, PR MACH LEARN RES, V97; Xiong Lee, 2021, ICLR; Yogatama D, 2021, T ASSOC COMPUT LING, V9, P362, DOI 10.1162/tacl_a_00371; Yu HF, 2017, ADV NEUR IN, V30; Yu Hsiang-Fu, 2022, J Mach Learn Res, V23, P1; Zhan JT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1503, DOI 10.1145/3404835.3462880; Zhang Hang, 2022, INT C LEARN REPR; Zhang Jie, ADV NEURAL INFORM PR, V6; Zhang SY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5990	65	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							77	86		10.1145/3616855.3635791	http://dx.doi.org/10.1145/3616855.3635791			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN		Green Submitted			2024-07-03	WOS:001182230100013
J	Wang, G; Liu, Q; Chen, G; Xia, B; Zeng, D; Chen, G; Guo, C				Wang, G.; Liu, Q.; Chen, G.; Xia, B.; Zeng, D.; Chen, G.; Guo, C.			AI's deep dive into complex pediatric inguinal hernia issues: a challenge to traditional guidelines?	HERNIA			English	Article						ChatGPT/ChatGPT 4.0; Inguinal hernia; Controversial issues; Systematic reviews; Guidelines	INFANTS; RISK	Objective This study utilized ChatGPT, an artificial intelligence program based on large language models, to explore controversial issues in pediatric inguinal hernia surgery and compare its responses with the guidelines of the European Association of Pediatric Surgeons (EUPSA).Methods Six contentious issues raised by EUPSA were submitted to ChatGPT 4.0 for analysis, for which two independent responses were generated for each issue. These generated answers were subsequently compared with systematic reviews and guidelines. To ensure content accuracy and reliability, a content analysis was conducted, and expert evaluations were solicited for validation. Content analysis evaluated the consistency or discrepancy between ChatGPT 4.0's responses and the guidelines. An expert scoring method assess the quality, reliability, and applicability of responses. The TF-IDF model tested the stability and consistency of the two responses.Results The responses generated by ChatGPT 4.0 were mostly consistent with the guidelines. However, some differences and contradictions were noted. The average quality score was 3.33, reliability score was 2.75, and applicability score was 3.46 (out of 5). The average similarity between the two responses was 0.72 (out of 1), Content analysis and expert ratings yielded consistent conclusions, enhancing the credibility of our research.Conclusion ChatGPT can provide valuable responses to clinical questions, but it has limitations and requires further improvement. It is recommended to combine ChatGPT with other reliable data sources to improve clinical practice and decision-making.	[Wang, G.; Liu, Q.; Chen, G.; Xia, B.; Zeng, D.; Guo, C.] Chongqing Med Univ, Womens & Childrens Hosp, Dept Pediat, 120 Longshan Rd, Chongqing 401147, Peoples R China; [Wang, G.] Chongqing Med Univ, Childrens Hosp, Dept Pediat, Chongqing, Peoples R China; [Liu, Q.; Chen, G.; Xia, B.; Zeng, D.; Guo, C.] Chongqing Hlth Ctr Women & Children, Dept Fetus & Pediat, Chongqing, Peoples R China; [Wang, G.; Chen, G.; Guo, C.] Chongqing Med Univ, Chongqing Maternal & Child Hlth Hosp, Dept Pediat Gen Surg, Chongqing, Peoples R China; [Chen, G.] Chongqing Med Univ, Women & Childrens Hosp, Chongqing Hlth Ctr Women & Children, Dept Obstet & Gynecol, 120 Longshan Rd, Chongqing 401147, Peoples R China	Chongqing Medical University; Chongqing Medical University; Chongqing Medical University; Chongqing Medical University	Guo, C (corresponding author), Chongqing Med Univ, Womens & Childrens Hosp, Dept Pediat, 120 Longshan Rd, Chongqing 401147, Peoples R China.; Guo, C (corresponding author), Chongqing Hlth Ctr Women & Children, Dept Fetus & Pediat, Chongqing, Peoples R China.; Chen, G; Guo, C (corresponding author), Chongqing Med Univ, Chongqing Maternal & Child Hlth Hosp, Dept Pediat Gen Surg, Chongqing, Peoples R China.; Chen, G (corresponding author), Chongqing Med Univ, Women & Childrens Hosp, Chongqing Hlth Ctr Women & Children, Dept Obstet & Gynecol, 120 Longshan Rd, Chongqing 401147, Peoples R China.	38096550@qq.com; guochunbao@foxmail.com	wang, guoyong/IAQ-4526-2023	wang, guoyong/0000-0002-8224-7706	National Natural Science Foundation of China [30973440, 30770950]; Ministry of Key Laboratory of Child Development and Disorders [YBRP-2021XX]; Chongqing Natural Science Foundation [cstc2020jcyj-msxmX0326, CSTB2022NSCQ-MSX0819]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Ministry of Key Laboratory of Child Development and Disorders; Chongqing Natural Science Foundation(Natural Science Foundation of Chongqing)	The research was supported by the National Natural Science Foundation of China (No: 30973440, 30770950), the Youth Basic Research Project from the Ministry of Key Laboratory of Child Development and Disorders (No. YBRP-2021XX) for collection, analysis and interpretation of data and the key project of the Chongqing Natural Science Foundation (cstc2020jcyj-msxmX0326, CSTB2022NSCQ-MSX0819) in writing the manuscript. The funding agency paid for the scholarships of the students involved in the research.	Castro BA, 2019, J LAPAROENDOSC ADV S, V29, P1302, DOI 10.1089/lap.2019.0116; [Anonymous], 2001, B WORLD HEALTH ORGAN, V79, P373, DOI 10.1001/jama.2013.281053; Antonoff MB, 2005, J PEDIATR SURG, V40, P1009, DOI 10.1016/j.jpedsurg.2005.03.018; Becker M, 2018, SYST REV-LONDON, V7, DOI 10.1186/s13643-017-0669-2; Beltrami Eric J, 2024, J Am Acad Dermatol, V90, P879, DOI 10.1016/j.jaad.2023.02.052; Bradshaw JC, 2023, ANN EMERG MED, V81, P764, DOI 10.1016/j.annemergmed.2023.01.022; Breeding T, 2024, AM SURGEON, V90, P560, DOI 10.1177/00031348231180950; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Goktas P, 2023, J ALLER CL IMM-PRACT, V11, P2697, DOI 10.1016/j.jaip.2023.05.042; Kastner M, 2015, J CLIN EPIDEMIOL, V68, P498, DOI 10.1016/j.jclinepi.2014.12.013; Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018; Kothari AN, 2023, ANN SURG ONCOL, V30, P3174, DOI 10.1245/s10434-023-13442-2; Kusunose K, 2023, J ECHOCARDIOGR, V21, P99, DOI 10.1007/s12574-023-00611-1; Lao OB, 2012, SURG CLIN N AM, V92, P487, DOI 10.1016/j.suc.2012.03.017; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Miltenburg DM, 1997, AM J SURG, V174, P741, DOI 10.1016/S0002-9610(97)00182-7; Mollen KP, 2007, CURR OPIN PEDIATR, V19, P344, DOI 10.1097/MOP.0b013e3281574597; Morini F, 2022, EUR J PEDIATR SURG, V32, P219, DOI 10.1055/s-0040-1721420; Ohkura T, 2022, PEDIATR INT, V64, DOI 10.1111/ped.15193; Parelkar SV, 2010, J PEDIATR SURG, V45, P789, DOI 10.1016/j.jpedsurg.2009.08.007; Sulkowski JP, 2015, J PEDIATR SURG, V50, P171, DOI 10.1016/j.jpedsurg.2014.10.035; Svab I, 2023, ZDRAV VARST, V62, P109, DOI 10.2478/sjph-2023-0015; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Zamakhshary M, 2008, CAN MED ASSOC J, V179, P1001, DOI 10.1503/cmaj.070923; Zhang HX, 2023, J LAPAROENDOSC ADV S, V33, P821, DOI 10.1089/lap.2022.0529	25	5	5	5	16	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1265-4906	1248-9204		HERNIA	Hernia	OCT	2023	27	6					1587	1599		10.1007/s10029-023-02900-1	http://dx.doi.org/10.1007/s10029-023-02900-1		OCT 2023	13	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	GO9X1	37843604				2024-07-03	WOS:001086719400002
C	Zhang, YS; Wang, J; Wang, ZG; Zhang, R		Rogers, A; Boyd-Graber, J; Okazaki, N		Zhang, Yusen; Wang, Jun; Wang, Zhiguo; Zhang, Rui			XSEMPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages and Meaning Representations	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Cross-Lingual Semantic Parsing (CLSP) aims to translate queries in multiple natural languages (NLs) into meaning representations (MRs) such as SQL, lambda calculus, and logic forms. However, existing CLSP models are separately proposed and evaluated on datasets of limited tasks and applications, impeding a comprehensive and unified evaluation of CLSP on a diverse range of NLs and MRs. To this end, we present XSEMPLR, a unified benchmark for cross-lingual semantic parsing featured with 22 natural languages and 8 meaning representations by examining and selecting 9 existing datasets to cover 5 tasks and 164 domains. We use XSEMPLR to conduct a comprehensive benchmark study on a wide range of multilingual language models including encoder-based models (mBERT, XLM-R), encoder-decoder models (mBART, mT5), and decoder-based models (Codex, BLOOM). We design 6 experiment settings covering various lingual combinations (monolingual, multilingual, cross-lingual) and numbers of learning samples (full dataset, few-shot, and zero-shot). Our experiments show that encoder-decoder models (mT5) achieve the highest performance compared with other popular models, and multilingual training can further improve the average performance. Notably, multilingual large language models (e.g., BLOOM) are still inadequate to perform CLSP tasks. We also find that the performance gap between monolingual training and cross-lingual transfer learning is still significant for multilingual models, though it can be mitigated by cross-lingual few-shot training. Our dataset and code are available at https://github.com/psunlpgroup/XSemPLR.	[Zhang, Yusen; Zhang, Rui] Penn State Univ, University Pk, PA 16802 USA; [Wang, Jun; Wang, Zhiguo] AWS AI Labs, New York, NY USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Zhang, YS (corresponding author), Penn State Univ, University Pk, PA 16802 USA.	yfz5488@psu.edu; juwanga@amazon.com; zhiguow@amazon.com; rmz5227@psu.edu	Zhang, Yusen/R-8508-2017					[Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2017, ABS171004087 CORR; Asai Akari, 2020, ARXIV201011856; Athiwaratkun Ben, 2022, ARXIV221014868; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen Yanda, 2021, ARXIV210602293; Chipman HA, 2022, BAYESIAN ANAL, V17, P515, DOI 10.1214/21-BA1259; Conneau A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2475; Conneau Alexis, 2019, Unsupervised cross-lingual representation learning at scale; Cui RX, 2022, T ASSOC COMPUT LING, V10, P937, DOI 10.1162/tacl_a_00499; Cui Ruixiang, 2021, ARXIV210803509; Dahl D.A., 1994, HUMAN LANGUAGE TECHN; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dou Longxu, 2022, ARXIV221213492; Duong Long, 2017, P 21 C COMP NAT LANG, P379; Finegan-Dollak C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P351; Guo JQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1520; Gupta Sonal, 2018, ARXIV181007942; Haas Carolin., 2016, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, P740; Hu JJ, 2020, PR MACH LEARN RES, V119; Iyer Srinivasan, 2017, ARXIV170408760; Jones B.K., 2012, P 50 ANN M ASS COMP, V1, P488; Keysers D., 2020, 8 INT C LEARNING REP; Keysers Daniel, 2019, INT C LEARN REPR; Lampiris G, 2020, ANN OPER RES, V294, P225, DOI 10.1007/s10479-019-03337-5; Laurencon Hugo, 2022, 36 C NEUR INF PROC S; Lawrence C, 2016, PROCEEDINGS OF THE ASME POWER CONFERENCE, 2015; Lewis Patrick, 2019, ARXIV191007475; Li Haoran, 2020, ARXIV200809335; Li Jinyang, 2023, ARXIV230107507; Liang Yaobo, 2020, Xglue: A new benchmark dataset for cross-lingual pre-training, understanding and generation, DOI DOI 10.18653/V1/2020.EMNLP-MAIN.484; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin X.V., 2022, PROC 2022 C EMPIRICA, P9019; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Liu YH, 2020, T ASSOC COMPUT LING, V8, P726, DOI 10.1162/tacl_a_00343; Lu Wei., 2011, Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, P1611; Min Qingkai, 2019, ARXIV190913293; Moradshahi Mehrad, 2020, ARXIV201005106; Nguyen Anh Tuan, 2020, ARXIV201001891; Oard Douglas W, 2019, ACM NTCIR 14 C, V10; Pfeiffer J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3479; Prakash Prafull, 2020, ARXIV201005002; PRICE D, 1990, POWYS REV, P24; Qi Zhenting, 2022, ARXIV220900840; Rongali Subendhu, 2020, WWW '20: Proceedings of The Web Conference 2020, P2962, DOI 10.1145/3366423.3380064; Scao T. L., 2022, arXiv preprint arXiv:2211.05100; Sherborne T, 2023, T ASSOC COMPUT LING, V11, P49, DOI 10.1162/tacl_a_00533; Sherborne T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4134; Sherborne Tom, 2021, ARXIV210407554; Sherborne Tom, 2020, ARXIV200402585; Shi Peng, 2022, ARXIV221013693; Shi Peng, 2021, P 1 WORKSH MULT REPR, P251, DOI 10.18653/v1/2021.mrl-1.24; Shi Peng, 2022, FINDINGS ASS COMPUTA, P5296; Shu C, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4414; Srivastava Aarohi, 2022, ARXIV220604615; Sun S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4160; Susanto RH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P38, DOI 10.18653/v1/P17-2007; Susanto Raymond Hendy, 2017, P AAAI C ART INT; Upadhyay S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6034, DOI 10.1109/ICASSP.2018.8461905; Vaswani A, 2017, ADV NEUR IN, V30; Wang YS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1332; Wu Y., 2016, ARXIV160908144; Xu SL, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1685, DOI 10.1145/3340531.3411974; Xu Weijia, 2020, ARXIV200414353; Xue L., 2020, mT5: a massively multilingual pretrained texttotext transformer; Yin PC, 2018, IEEE WORK CONF MIN S, P476, DOI 10.1145/3196398.3196408; Yogatama D., 2019, ARXIV191011856; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zbib R, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P645, DOI 10.1145/3331184.3331222; Zelle JM, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1050; Zettlemoyer Luke S, 2012, ARXIV12071420; Zhang Rui, 2019, ARXIV190603492; ZhiruoWang Grace Cuenca, 2022, ARXIV220308388; Zhu JM, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/8121161; Zhu Junnan, 2019, ARXIV190900156; Zou Yanyan, 2018, ARXIV180605461	76	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15918	15947						30	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962507040
J	Chen, LQ; Cai, ZB; Jiang, ZJ; Luo, JX; Sun, LY; Childs, P; Zuo, HY				Chen, Liuqing; Cai, Zebin; Jiang, Zhaojun; Luo, Jianxi; Sun, Lingyun; Childs, Peter; Zuo, Haoyu			AskNatureNet: A divergent thinking tool based on bio-inspired design knowledge	ADVANCED ENGINEERING INFORMATICS			English	Article						Bio-inspired design; Semantic network; Divergent thinking; Design creativity; Design ideation	BIOMIMETICS; SYSTEMS	Divergent thinking is a process in design by exploring multiple possible solutions, is crucial in the early stages of design to break fixation and expand the design ideation. Design -by -Analogy promotes divergent thinking, by studying solutions have solved similar problems and using this knowledge to make inferences and solve problems in new and unfamiliar situations. Bio-inspired design (BID) is a form of design by analogy and its knowledge provides diverse sources for analogy, making BID knowledge as a potential source for divergent thinking. Existing BID database has focused on collecting BID cases and facilitating the retrieval of biological knowledge. Despite its success, applying BID knowledge into divergent thinking still encounters challenge, as the association between source domain and target domain are always limited within a single case. In this work, a novel approach is proposed to support divergent thinking from three subsequent phases: encoding, retrieval and mapping. Specifically, biological knowledge is encoded in a triple form by employing a large language model (LLM) to extract key information from a well-known BID knowledge base. The created triples are implemented in a semantic network to facilitate bidirectional retrieval modes: problem -driven and solutiondriven, as well as mapping for divergent thinking. The mapping algorithm calculates the semantic similarity between nodes in the semantic network based on their attributes in three progressive steps by following the paradigm of divergent thinking. The proposed approach is implemented as tool called AskNatureNet, 1 which supports divergent thinking by retrieving and mapping knowledge in a visualized interactive semantic network. An ideation case study on evaluating the effectiveness of AskNatureNet shows that our tool is capable of supporting divergent thinking efficiently.	[Chen, Liuqing; Cai, Zebin; Jiang, Zhaojun; Sun, Lingyun] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310030, Peoples R China; [Childs, Peter; Zuo, Haoyu] Imperial Coll London, Dyson Sch Design Engn, Exhibit Rd, London SW7 2AZ, England; [Luo, Jianxi] City Univ Hong Kong, Dept Syst Engn, Hong Kong, Peoples R China	Zhejiang University; Imperial College London; City University of Hong Kong	Zuo, HY (corresponding author), Imperial Coll London, Dyson Sch Design Engn, Exhibit Rd, London SW7 2AZ, England.	chenlq@zju.edu.cn; caizebin@zju.edu.cn; 22321008@zju.edu.cn; lianxi.luo@cityu.edu.hk; sunly@zju.edu.cn; p.childs@imperial.ac.uk; hz2019@ic.ac.uk		Childs, Peter/0000-0002-2465-8822; Zuo, Haoyu/0000-0003-3811-4479	National Key R&D Program of China [2022YFB3303301]; National Natural Science Foundation of China [62207023]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<BOLD>Acknowledgments</BOLD> This research is supported by National Key R&D Program of China (2022YFB3303301) and National Natural Science Foundation of China (62207023) .	Acar S, 2012, HANDBOOK OF ORGANIZATIONAL CREATIVITY, P115, DOI 10.1016/B978-0-12-374714-3.00006-9; AMABILE TM, 1982, J PERS SOC PSYCHOL, V43, P997, DOI 10.1037/0022-3514.43.5.997; Baer J, 1996, J CREATIVE BEHAV, V30, P183, DOI 10.1002/j.2162-6057.1996.tb00767.x; Bar-Cohen Y, 2006, BIOINSPIR BIOMIM, V1, pP1, DOI 10.1088/1748-3182/1/1/P01; Bhatta SR, 1996, AI EDAM, V10, P131, DOI 10.1017/S0890060400001372; BionicInspiration.org, 2014, BionicInspiration.org: A website dedicated to promoting bio-inspired design; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao GZ, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101352; Chakrabarti A., 2014, Biologically inspired Design: Computational Methods and Tools, P201; Chan J, 2011, J MECH DESIGN, V133, DOI 10.1115/1.4004396; Chen C, 2021, COMPUT IND, V127, DOI 10.1016/j.compind.2021.103402; Chen LQ, 2019, J VIS COMMUN IMAGE R, V61, P10, DOI 10.1016/j.jvcir.2019.02.009; Cheong H, 2014, J MECH DESIGN, V136, DOI 10.1115/1.4027494; Childs P, 2022, J INTELL-BASEL, V10, DOI 10.3390/jintelligence10040073; Cohen Y.H., 2016, Biomimetic Design Method for Innovation and Sustainability, V10; Cohen YH, 2014, J MECH DESIGN, V136, DOI 10.1115/1.4028169; Deldin J.M., 2014, Biologically Inspired Design, P17, DOI [DOI 10.1007/978-1-4471-5248-4_2, 10.1007/978-1-4471-5248-42, DOI 10.1007/978-1-4471-5248-42]; Fayemi PE, 2017, BIOINSPIR BIOMIM, V12, DOI 10.1088/1748-3190/12/1/011002; Goel A., 2022, DESIGN COMPUTING COG, P369; Goel A. K., 2015, BIOL INSPIRED DESIGN; Goel AK, 2012, COMPUT AIDED DESIGN, V44, P879, DOI 10.1016/j.cad.2011.03.010; Goel AK, 2009, AI EDAM, V23, P23, DOI 10.1017/S0890060409000080; Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947; HALL RP, 1989, ARTIF INTELL, V39, P39, DOI 10.1016/0004-3702(89)90003-9; Han J, 2022, J MECH DESIGN, V144, DOI 10.1115/1.4052148; Helms M, 2009, DESIGN STUD, V30, P606, DOI 10.1016/j.destud.2009.04.003; Hey J, 2008, INT J ENG EDUC, V24, P283; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Hirtz J, 2002, RES ENG DES, V13, P65, DOI 10.1007/s00163-001-0008-3; Hooker G., 2016, INSIGHT, V19, P46; Hund AK, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8010048; Jiang S, 2022, J MECH DESIGN, V144, DOI 10.1115/1.4051681; Jiang ZMJ, 2023, ADV ENG INFORM, V58, DOI 10.1016/j.aei.2023.102240; Kokinov B., 2003, Encycl. Cogn. Sci., V1, P113; Kozaki K., 2014, ISWC POSTERS DEMOS, P469; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee JHJ, 2022, DESIGN STUD, V79, DOI 10.1016/j.destud.2022.101089; Li XR, 2022, ADV ENG INFORM, V52, DOI 10.1016/j.aei.2022.101617; Linsey JS, 2010, J MECH DESIGN, V132, DOI 10.1115/1.4001110; Liu QY, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101502; MARKMAN AB, 1993, COGNITIVE PSYCHOL, V25, P431, DOI 10.1006/cogp.1993.1011; McAdams DA, 2002, J MECH DESIGN, V124, P173, DOI 10.1115/1.1475317; Melo M., 2016, Introduction to Nature Inspired Solutions; Moreno D.P., 2015, DESIGN COMPUTING COG, P607; Müller R, 2018, BIOINSPIR BIOMIM, V13, DOI 10.1088/1748-3190/aac96a; Nagel J.K., 2014, Biologically Inspired Des. Comput. Methods Tools, P95, DOI DOI 10.1007/978-1-4471-5248-4_5; Nagel JKS, 2010, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, DETC 2010, VOL 5, P117; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Reisberg D., 2013, The Oxford Handbook of Cognitive Psychology, DOI DOI 10.1093/OXFORDHB/9780195376746.001.0001; Risch J., 2021, P 3 WORKSHOP MACHINE, P149, DOI 10.18653/v1/2021.mrqa-1.15; Rugaber S, 2016, LECT NOTES ARTIF INT, V9969, P342, DOI 10.1007/978-3-319-47096-2_23; Runco M. A., 2010, The Cambridge Handbook of Creativity, P413, DOI [10.1017/CBO9780511763205.026, DOI 10.1017/CBO9780511763205.02, DOI 10.1017/CBO9780511763205.026]; Runco M.A., 1991, DIVERGENT THINKING; RUNCO MA, 1992, DEV REV, V12, P233, DOI 10.1016/0273-2297(92)90010-Y; Sarica S, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112995; Sarkar P, 2008, J COMPUT INF SCI ENG, V8, DOI 10.1115/1.2956995; Shah J. J., 2003, Design Studies, V24, P111, DOI 10.1016/S0142-694X(02)00034-0; Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649; Shu LH, 2011, CIRP ANN-MANUF TECHN, V60, P673, DOI 10.1016/j.cirp.2011.06.001; Shu LH, 2010, AI EDAM, V24, P507, DOI 10.1017/S0890060410000363; Siddharth L, 2018, AI EDAM, V32, P431, DOI 10.1017/S0890060418000136; Stemler S. E., 2004, Practical Assessment, Research, and Evaluation, V9, P4, DOI DOI 10.7275/96JP-XZ07; Stemler S.E., 2008, BEST PRACTICES QUANT, P29, DOI [DOI 10.4135/9781412995627.D5, 10.4135/9781412995627]; Sun F, 2023, ADV ENG INFORM, V55, DOI 10.1016/j.aei.2023.101904; Sutskever I, 2014, ADV NEUR IN, V27; Vaswani A, 2017, ADV NEUR IN, V30; Vattam S., 2007, BIOLOGICALLY INSPIRE; Vattam SS, 2008, DESIGN COMPUTING AND COGNITION '08, P377, DOI 10.1007/978-1-4020-8728-8_20; Verhaegen PA, 2011, COMPUT IND, V62, P446, DOI 10.1016/j.compind.2010.12.007; Vincent JFV, 2006, J R SOC INTERFACE, V3, P471, DOI 10.1098/rsif.2006.0127; Wanieck K, 2017, BIOINSPIR BIOMIM NAN, V6, P53, DOI 10.1680/jbibn.16.00010; Wray KB, 2005, PHILOS SCI, V72, P656, DOI 10.1086/505478; Yilmaz S, 2016, DESIGN STUD, V45, P137, DOI 10.1016/j.destud.2015.12.008; Zhu QH, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056598; Zuo HY, 2022, J INTELL-BASEL, V10, DOI 10.3390/jintelligence10040103	75	0	0	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1474-0346	1873-5320		ADV ENG INFORM	Adv. Eng. Inform.	OCT	2024	62		A						102593	10.1016/j.aei.2024.102593	http://dx.doi.org/10.1016/j.aei.2024.102593			17	Computer Science, Artificial Intelligence; Engineering, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	UI0Z7		hybrid			2024-07-03	WOS:001247323500001
J	Caufield, JH; Hegde, H; Emonet, V; Harris, NL; Joachimiak, MP; Matentzoglu, N; Kim, H; Moxon, S; Reese, JT; Haendel, MA; Robinson, PN; Mungall, CJ				Caufield, J. Harry; Hegde, Harshad; Emonet, Vincent; Harris, Nomi L.; Joachimiak, Marcin P.; Matentzoglu, Nicolas; Kim, Hyeongsik; Moxon, Sierra; Reese, Justin T.; Haendel, Melissa A.; Robinson, Peter N.; Mungall, Christopher J.			Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES): a method for populating knowledge bases using zero-shot learning	BIOINFORMATICS			English	Article							ONTOLOGY; WEB	Motivation Creating knowledge bases and ontologies is a time consuming task that relies on manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrarily complex nested knowledge schemas.Results Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against an LLM to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for matched elements. We present examples of applying SPIRES in different domains, including extraction of food recipes, multi-species cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease relationships. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction methods, but greatly surpasses an LLM's native capability of grounding entities with unique identifiers. SPIRES has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any new training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM.Availability and implementation SPIRES is available as part of the open source OntoGPT package: https://github.com/monarch-initiative/ontogpt.	[Caufield, J. Harry; Hegde, Harshad; Harris, Nomi L.; Joachimiak, Marcin P.; Moxon, Sierra; Reese, Justin T.; Mungall, Christopher J.] Lawrence Berkeley Natl Lab, Div Environm Genom & Syst Biol, Biosyst Data Sci, Berkeley, CA 94720 USA; [Emonet, Vincent] Maastricht Univ, Inst Data Sci, Fac Sci & Engn, NL-6200 MD Maastricht, Netherlands; [Matentzoglu, Nicolas] Semanticly, Athens, Greece; [Kim, Hyeongsik] Robert Bosch LLC, Sunnyvale, CA 94085 USA; [Haendel, Melissa A.] Univ Colorado, Dept Biomed Informat, Anschutz Med Campus, Aurora, CO 80217 USA; [Robinson, Peter N.] Charite, Berlin Inst Hlth, D-10178 Berlin, Germany; [Caufield, J. Harry] Lawrence Berkeley Natl Lab, Div Environm Genom & Syst Biol, Biosyst Data Sci, 1 Cyclotron Rd,Mailstop 977-0257, Berkeley, CA 94720 USA	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Maastricht University; Bosch; University of Colorado System; University of Colorado Anschutz Medical Campus; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Berlin Institute of Health; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory	Caufield, JH (corresponding author), Lawrence Berkeley Natl Lab, Div Environm Genom & Syst Biol, Biosyst Data Sci, 1 Cyclotron Rd,Mailstop 977-0257, Berkeley, CA 94720 USA.	jhc@lbl.gov		Harris, Nomi/0000-0001-6315-3707; Hegde, Harshad/0000-0002-2411-565X; Haendel, Melissa/0000-0001-9114-8737; Reese, Justin/0000-0002-2170-2250; Emonet, Vincent/0000-0002-1501-1082; Matentzoglu, Nicolas/0000-0002-7356-1779; joachimiak, marcin/0000-0001-8175-045X	National Institutes of Health National Human Genome Research Institute [RM1 HG010860]; National Institutes of Health Office of the Director [R24 OD011883]; Office of Science, Office of Basic Energy Sciences, of the US Department of Energy [DE-AC0205CH11231]; Bosch Research	National Institutes of Health National Human Genome Research Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Human Genome Research Institute (NHGRI)); National Institutes of Health Office of the Director(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); Office of Science, Office of Basic Energy Sciences, of the US Department of Energy(United States Department of Energy (DOE)); Bosch Research	This work was supported by the National Institutes of Health National Human Genome Research Institute [RM1 HG010860]; National Institutes of Health Office of the Director [R24 OD011883]; and the Director, Office of Science, Office of Basic Energy Sciences, of the US Department of Energy [DE-AC0205CH11231 to J.H.C., H. H., N.L.H., M.J., S.M., J.T.R, and C.J.M.]. We also gratefully acknowledge Bosch Research for their support of this research project.	Ateia S., 2023, CLEF 2023 C LABS EVA; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002; Brown EG, 1999, DRUG SAFETY, V20, P109, DOI 10.2165/00002018-199920020-00002; Carbon S, 2019, NUCLEIC ACIDS RES, V47, pD330, DOI 10.1093/nar/gky1055; Dagdelen J, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-45563-x; Dooley DM, 2018, NPJ SCI FOOD, V2, DOI 10.1038/s41538-018-0032-6; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; Fabregat A, 2018, NUCLEIC ACIDS RES, V46, pD649, DOI 10.1093/nar/gkx1132; Fecho K, 2022, CTS-CLIN TRANSL SCI, V15, P1838, DOI 10.1111/cts.13301; Furrer L, 2019, J CHEMINFORMATICS, V11, DOI 10.1186/s13321-018-0326-3; Giglou HB, 2023, LECT NOTES COMPUT SC, V14265, P408, DOI 10.1007/978-3-031-47240-4_22; GIUDICELLI JF, 1990, J PHARMACOL EXP THER, V255, P836; Graybeal J., 2019, 13 RES DATA ALLIANCE; Gyori BM, 2022, BIOINFORM ADV, V2, DOI 10.1093/bioadv/vbac034; Hastings J, 2016, NUCLEIC ACIDS RES, V44, pD1214, DOI 10.1093/nar/gkv1031; Hoyt CT, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01807-3; Jackson RC, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3002-3; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jonquet C, 2018, COMPUT ELECTRON AGR, V144, P126, DOI 10.1016/j.compag.2017.10.012; Jonquet Clement, 2009, Summit Transl Bioinform, V2009, P56; Jupp S, 2015, SWAT4LS, P118; Kazakov Y., 2015, P 28 INT WORKSHOP DE, V1350; Khambete Mihir P, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P345; Kindermann C., 2018, P 31 INT WORKSHOP DE, V2211; Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068; Liaw CC, 1999, ANTI-CANCER DRUG, V10, P275, DOI 10.1097/00001813-199903000-00004; Lipscomb CE, 2000, B MED LIBR ASSOC, V88, P265; Liu ZL, 2023, Arxiv, DOI [arXiv:2309.06419, DOI 10.48550/ARXIV.2309.06419]; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Luo YZ, 2023, Arxiv, DOI arXiv:2308.09442; Matentzoglu N, 2023, Arxiv, DOI [arXiv:2310.03666, DOI 10.48550/ARXIV.2310.03666, 10.48550/arXiv.2310.03666]; Moxon S., 2021, CEUR WORKSHOP P, V3073, P148; Osumi-Sutherland D, 2017, J BIOMED SEMANT, V8, DOI 10.1186/s13326-017-0126-0; Pareti Paolo, 2022, Reasoning Web. Declarative Artificial Intelligence: 17th International Summer School 2021, Tutorial Lectures. Lecture Notes in Computer Science, Information Systems and Applications, incl. Internet/Web, and HCI (13100), P115, DOI 10.1007/978-3-030-95481-9_6; Qiang ZC, 2024, Arxiv, DOI [arXiv:2312.00326, 10.48550/arXiv.2312.00326, DOI 10.48550/ARXIV.2312.00326]; Rizwan MM, 2009, PERSPECT PSYCHIATR C, V45, P62, DOI 10.1111/j.1744-6163.2009.00201.x; Schadow G, 1999, J AM MED INFORM ASSN, V6, P151, DOI 10.1136/jamia.1999.0060151; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Unni DR, 2022, CTS-CLIN TRANSL SCI, V15, P1848, DOI 10.1111/cts.13302; Vaswani A, 2017, ADV NEUR IN, V30; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wachter RM, 2024, JAMA-J AM MED ASSOC, V331, P65, DOI 10.1001/jama.2023.25054; Wang YS, 2020, JMIR MED INF, V8, DOI 10.2196/23375; Whetzel PL, 2011, NUCLEIC ACIDS RES, V39, pW541, DOI 10.1093/nar/gkr469; Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037; Xu J., 2015, P 5 BIOCREATIVE CHAL, P254; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]	49	0	0	14	14	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803	1367-4811		BIOINFORMATICS	Bioinformatics	MAR 4	2024	40	3							btae104	10.1093/bioinformatics/btae104	http://dx.doi.org/10.1093/bioinformatics/btae104			10	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	KP6U5	38383067	gold, Green Submitted			2024-07-03	WOS:001181218000002
C	Fan, HX; Venieris, SI; Kouris, A; Lane, ND			ACM	Fan, Hongxiang; Venieris, Stylianos I.; Kouris, Alexandros; Lane, Nicholas D.			Sparse-DySta: Sparsity-Aware Dynamic and Static Scheduling for Sparse Multi-DNNWorkloads	56TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, MICRO 2023			English	Proceedings Paper	56th IEEE/ACM International Symposium on Microarchitecture (MICRO)	OCT 28-NOV 01, 2023	Toronto, CANADA	Assoc Comp Machinery, IEEE, IEEE Comp Soc Tech Comm Microprogramming & Microarchitecture, ACM SIGMICRO, Amazon Web Serv, Huawei, AMD, MangoBoost, IBM, Google		Sparse Multi-DNN Scheduling; Dynamic and Static Approach; Algorithm and Hardware Co-Design	EFFICIENT	Running multiple deep neural networks (DNNs) in parallel has become an emerging workload in both edge devices, such as mobile phones where multiple tasks serve a single user for daily activities, and data centers, where various requests are raised from millions of users, as seen with large language models. To reduce the costly computational and memory requirements of these workloads, various efficient sparsification approaches have been introduced, resulting in widespread sparsity across different types of DNN models. In this context, there is an emerging need for scheduling sparse multi-DNN workloads, a problem that is largely unexplored in previous literature. This paper systematically analyses the use-cases of multiple sparse DNNs and investigates the opportunities for optimizations. Based on these findings, we propose Dysta, a novel bi-level dynamic and static scheduler that utilizes both static sparsity patterns and dynamic sparsity information for the sparse multi-DNN scheduling. Both static and dynamic components of Dysta are jointly designed at the software and hardware levels, respectively, to improve and refine the scheduling approach. To facilitate future progress in the study of this class of workloads, we construct a public benchmark that contains sparse multi-DNN workloads across different deployment scenarios, spanning from mobile phones and AR/VR wearables to data centers. A comprehensive evaluation on the sparse multi-DNN benchmark demonstrates that our proposed approach outperforms the state-of-the-art methods with up to 10% decrease in latency constraint violation rate and nearly 4x reduction in average normalized turnaround time. Our artifacts and code are publicly available at: https://github.com/SamsungLabs/Sparse- Multi-DNN-Scheduling.	[Fan, Hongxiang; Venieris, Stylianos I.; Kouris, Alexandros] Samsung AI Ctr, Cambridge, England; [Fan, Hongxiang; Lane, Nicholas D.] Univ Cambridge, Cambridge, England; [Lane, Nicholas D.] Flower Labs, Cambridge, England	University of Cambridge	Venieris, SI (corresponding author), Samsung AI Ctr, Cambridge, England.	hongxiangfan@ieee.org; s.venieris@samsung.com; a.kouris@samsung.com; ndl32@cam.ac.uk		Venieris, Stylianos/0000-0001-5181-6251				AlexWang Amanpreet Singh, 2018, P 2018 EMNLP WORKSHO; Almeida M., 2021, ACM INTERNET MEASURE; Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081; Blalock Davis, 2020, C MACHINE LEARNING S; Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232; Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007; Choi S, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P199; Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027; Cox B, 2021, INT CONF PERVAS COMP, DOI 10.1109/PERCOM50583.2021.9439111; Dave S, 2021, P IEEE, V109, P1706, DOI 10.1109/JPROC.2021.3098483; Deng CH, 2021, CONF PROC INT SYMP C, P1110, DOI 10.1109/ISCA52012.2021.00090; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J., 2018, BERT PRE TRAINING DE; Dudziak L., 2020, Advances in Neural Information Processing Systems (NeurIPS); ErweiWang James J Davis, 2019, Where We're Going, V52, P1; Eyerman S, 2008, IEEE MICRO, V28, P42, DOI 10.1109/MM.2008.44; Fan H, 2022, INT SYMP MICROARCH, P599, DOI 10.1109/MICRO56248.2022.00050; Ferianc M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040520; Ghodrati S, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P681, DOI 10.1109/MICRO50266.2020.00062; Goel S, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P66, DOI 10.1109/ICFPT51103.2020.00018; Ham TJ, 2021, CONF PROC INT SYMP C, P692, DOI 10.1109/ISCA52012.2021.00060; Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035; Han S., 2015, INT C LEARN REPR, V56, P3; He Kaiming, 2016, PROC CVPR IEEE, P630, DOI DOI 10.1007/978-3-319-46493-0_38; He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155; Howard A. G., 2017, ARXIV170404861; Ignatov A, 2019, IEEE INT CONF COMP V, P3617, DOI 10.1109/ICCVW.2019.00447; Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214; Jang JW, 2021, CONF PROC INT SYMP C, P15, DOI 10.1109/ISCA52012.2021.00011; Jeong Joo Seong, 2022, ANN INT C MOBILE SYS; Jouppi Norman P, 2023, ACM IEEE 50 ANN INT; Kao SC, 2022, INT S HIGH PERF COMP, P814, DOI 10.1109/HPCA53966.2022.00065; Kedia R, 2021, IEEE EMBED SYST LETT, V13, P114, DOI 10.1109/LES.2020.3017455; Kim Seah, 2024, ACM INT C ARCHITECTU; Kurtz M., 2020, PMLR, P5533; Kurtz M, 2020, PR MACH LEARN RES, V119; Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016; Kwon Hyoukjun, 2023, C MACHINE LEARNING S; Lee J, 2021, DES AUT CON, P247, DOI 10.1109/DAC18074.2021.9586312; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2; Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010; Lu L., 2021, 54 ANN IEEEACM INT S; Martinez Francisco Munoz, 2023, ACM INT C ARCHITECTU; Menghani Gaurav, ACM Computing Surveys (CSUR); Muñoz-Martínez F, 2021, I S WORKL CHAR PROC, P201, DOI 10.1109/IISWC53511.2021.00028; Nair V., 2010, P ICML, P807; NVIDIA, 2021, Accelerating inference with sparsity using the nvidia ampere architecture and nvidia tensorrt; Oh YH, 2021, INT S HIGH PERF COMP, P584, DOI 10.1109/HPCA51647.2021.00056; Paszke A, 2019, ADV NEUR IN, V32; Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015; Qu Z, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P14, DOI 10.1145/3503222.3507738; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045; Reddi Vijay Janapa, 2022, C MACHINE LEARNING S; Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Venieris S. I., 2018, 2018 28 INT C FIELD, P1; Venieris SI, 2023, COMPUTER, V56, P70, DOI 10.1109/MC.2022.3176845; Wang HR, 2021, INT S HIGH PERF COMP, P97, DOI 10.1109/HPCA51647.2021.00018; Wei C., 2018, BRIT MACHINE VISION; Wu YN, 2022, INT SYMP MICROARCH, P1377, DOI 10.1109/MICRO56248.2022.00096; Yang L, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218676; Yi J., 2020, ANN INT C MOBILE COM; Zeng SL, 2023, IEEE T COMPUT, V72, P1314, DOI 10.1109/TC.2022.3214113; Zhang Li Lyna, 2021, INT C MOBILE SYSTEMS; Zhou Aojun, 2021, INT C REPRESENTATION; Zhou Z., 2021, IEEE T COMPUTER AIDE	70	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0329-4				2023							353	366		10.1145/3613424.3614263	http://dx.doi.org/10.1145/3613424.3614263			14	Computer Science, Hardware & Architecture; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW5OB		Bronze, Green Submitted			2024-07-03	WOS:001164081800025
C	Tang, Z; Ge, JD; Liu, SQ; Zhu, TW; Xu, TT; Huang, LG; Luo, B			IEEE	Tang, Ze; Ge, Jidong; Liu, Shangqing; Zhu, Tingwei; Xu, Tongtong; Huang, Liguo; Luo, Bin			Domain Adaptive Code Completion via Language Models and Decoupled Domain Databases	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		domain adaptive code completion; retrieval-augment language model		Large Language Models (LLMs) have demonstrated remarkable performance in code completion. However, due to the lack of domain-specific knowledge, they may not be optimal in completing code that requires intensive domain knowledge for example completing the library names. Although there are several works that have confirmed the effectiveness of fine-tuning techniques to adapt language models for code completion in specific domains. They are limited by the need for constant fine-tuning of the model when the project is in constant iteration. To address this limitation, in this paper, we propose kNM-LM, a retrieval-augmented language model (R-LM), that integrates domain knowledge into language models without fine-tuning. Different from previous techniques, our approach is able to automatically adapt to different language models and domains. Specifically, it utilizes the in-domain code to build the retrieval-based database decoupled from LM, and then combines it with LM through Bayesian inference to complete the code. The extensive experiments on the completion of intra-project and intra-scenario have confirmed that kNM-LM brings about appreciable enhancements when compared to CodeGPT and UnixCoder. A deep analysis of our tool including the responding speed, storage usage, specific type code completion, and API invocation completion has confirmed that kNM-LM provides satisfactory performance, which renders it highly appropriate for domain adaptive code completion. Furthermore, our approach operates without the requirement for direct access to the language model's parameters. As a result, it can seamlessly integrate with black-box code completion models, making it easy to integrate our approach as a plugin to further enhance the performance of these models.	[Tang, Ze; Ge, Jidong; Zhu, Tingwei; Luo, Bin] Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China; [Liu, Shangqing] Nanyang Technol Univ, Singapore, Singapore; [Xu, Tongtong] Huawei Software Engn Applicat Technol, Shenzhen, Peoples R China; [Huang, Liguo] Southern Methodist Univ, Dept Comp Sci, Dallas, TX USA	Nanjing University; Nanyang Technological University; Southern Methodist University	Ge, JD (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Nanjing, Peoples R China.; Liu, SQ (corresponding author), Nanyang Technol Univ, Singapore, Singapore.	zetang@smail.nju.edu.cn; gjd@nju.edu.cn; liu.shangqing@ntu.edu.sg; tingweizhu33@smail.nju.edu.cn; xutongtong9@huawei.com; lghuang@lyle.smu.edu; luobin@nju.edu.cn			National Key Research and Development Program of China [2022YFF0711404]; Natural Science Foundation of Jiangsu Province, China [BK20201250]; Cooperation Fund of Huawei-NJU Creative Laboratory for the Next Programming; CCF-Huawei Populus Grove Fund	National Key Research and Development Program of China; Natural Science Foundation of Jiangsu Province, China(Natural Science Foundation of Jiangsu Province); Cooperation Fund of Huawei-NJU Creative Laboratory for the Next Programming; CCF-Huawei Populus Grove Fund	We are grateful to the anonymous reviewers for their useful comments and suggestions. This work was supported by National Key Research and Development Program of China (2022YFF0711404), Natural Science Foundation of Jiangsu Province, China (BK20201250), Cooperation Fund of Huawei-NJU Creative Laboratory for the Next Programming and CCF-Huawei Populus Grove Fund. Jidong Ge and Shangqing Liu are the corresponding authors.	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Allamanis M., INT C LEARN REPR; Alon U., INT C LEARN REPR; Alon U., 2022, INT C MACH LEARN PML; Bardou P, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-293; Bogomolov Egor, 2022, arXiv, DOI [10.48550/arXiv.2206.03333, DOI 10.48550/ARXIV.2206.03333]; Chen M., 2021, arXiv; Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1; Dinella E, 2022, PROC INT CONF SOFTW, P2130, DOI 10.1145/3510003.3510141; github, GitHub Copilot website; Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212; Guo Daya, 2021, INT C LEARN REPR ICL, P1; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Guu K, 2020, PR MACH LEARN RES, V119; Hashimoto T., 2018, ADV NEURAL INFORM PR; Hayati SA, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P925; He JX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5703; He XC, 2021, PROC INT CONF SOFTW, P1634, DOI 10.1109/ICSE43902.2021.00145; Hellendoorn VJ, 2019, PROC INT CONF SOFTW, P960, DOI 10.1109/ICSE.2019.00101; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; Huang YSB, 2023, Arxiv, DOI arXiv:2302.10879; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Izacard G, 2022, Arxiv, DOI arXiv:2208.03299; Izadi M, 2022, PROC INT CONF SOFTW, P401, DOI 10.1145/3510003.3510172; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Joyce J., 2003, The Stanford Encyclopedia of Philosophy; Khandelwal Urvashi, 2021, 9 INT C LEARN REPR I; Li J, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4159; Liu Shikun, INT C LEARN REPR; Lu S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6227; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Meng Y., ICLR 2022 WORKSH DEE; Nie P., 2023, Learning deep semantics for test completion; Niu CG, 2022, PROC INT CONF SOFTW, P2006, DOI 10.1145/3510003.3510096; Niu F., 2023, 2023 45 INT C SOFTW; openai, Openai's completion api; openai, Openai's text embedding api; Parvez MR, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2719; Peng Y, 2023, IEEE T SOFTWARE ENG, V49, P1876, DOI 10.1109/TSE.2022.3197063; Raffel C, 2020, J MACH LEARN RES, V21; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Spirin E, 2021, IEEE WORK CONF MIN S, P13, DOI 10.1109/MSR52588.2021.00014; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Svyatkovskiy A, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2727, DOI 10.1145/3292500.3330699; Tai KS, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1556; visualstudio, ChatGPT plugin in VSCode; Wang Chaozheng, 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.03846; Wang WH, 2022, Arxiv, DOI arXiv:2208.08643; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Xu F. F., 2022, 10 INT C LEARN REPR; Zan D., 2022, P 31 INT JOINT C ART, P2369; Zettlemoyer Luke., 2020, ICLR; Zhang FJ, 2023, Arxiv, DOI arXiv:2303.12570; Zhong H, 2009, LECT NOTES COMPUT SC, V5653, P318, DOI 10.1007/978-3-642-03013-0_15; Zhong WK, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556943; Zhou Y., 2019, Advances in neural information processing systems, V32	56	0	0	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							421	433		10.1109/ASE56229.2023.00076	http://dx.doi.org/10.1109/ASE56229.2023.00076			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200034
J	Porebski, BT; Balmforth, M; Browne, G; Riley, A; Jamali, K; Fürst, MJLJ; Velic, M; Buchanan, A; Minter, R; Vaughan, T; Holliger, P				Porebski, Benjamin T.; Balmforth, Matthew; Browne, Gareth; Riley, Aidan; Jamali, Kiarash; Furst, Maximillian J. L. J.; Velic, Mirko; Buchanan, Andrew; Minter, Ralph; Vaughan, Tristan; Holliger, Philipp			Rapid discovery of high-affinity antibodies via massively parallel sequencing, ribosome display and affinity screening	NATURE BIOMEDICAL ENGINEERING			English	Article							RNA-PROTEIN INTERACTIONS; HUMAN-BREAST; DNA; RECEPTOR; TRASTUZUMAB; EXPRESSION; PREDICTION; SELECTION; LANGUAGE; CELLS	Developing therapeutic antibodies is laborious and costly. Here we report a method for antibody discovery that leverages the Illumina HiSeq platform to, within 3 days, screen in the order of 108 antibody-antigen interactions. The method, which we named 'deep screening', involves the clustering and sequencing of antibody libraries, the conversion of the DNA clusters into complementary RNA clusters covalently linked to the instrument's flow-cell surface on the same location, the in situ translation of the clusters into antibodies tethered via ribosome display, and their screening via fluorescently labelled antigens. By using deep screening, we discovered low-nanomolar nanobodies to a model antigen using 4 x 106 unique variants from yeast-display-enriched libraries, and high-picomolar single-chain antibody fragment leads for human interleukin-7 directly from unselected synthetic repertoires. We also leveraged deep screening of a library of 2.4 x 105 sequences of the third complementarity-determining region of the heavy chain of an anti-human epidermal growth factor receptor 2 (HER2) antibody as input for a large language model that generated new single-chain antibody fragment sequences with higher affinity for HER2 than those in the original library. A high-throughput method leveraging the Illumina HiSeq platform to screen in the order of 108 individual antibody-antigen interactions within 3 days facilitates the rapid discovery of antibodies to clinically relevant targets.	[Porebski, Benjamin T.; Balmforth, Matthew; Jamali, Kiarash; Furst, Maximillian J. L. J.; Holliger, Philipp] MRC Lab Mol Biol, Cambridge, England; [Browne, Gareth; Riley, Aidan; Buchanan, Andrew; Minter, Ralph; Vaughan, Tristan] AstraZeneca, Biol Engn, Cambridge, England; [Balmforth, Matthew] UCB, Slough, England; [Furst, Maximillian J. L. J.] Univ Groningen, Groningen Biomol Sci & Biotechnol Inst, Groningen, Netherlands; [Minter, Ralph] Alchemab Therapeut, London, England	MRC Laboratory Molecular Biology; AstraZeneca; UCB Pharma SA; University of Groningen	Holliger, P (corresponding author), MRC Lab Mol Biol, Cambridge, England.	ph1@mrc-lmb.cam.ac.uk		Buchanan, Andrew/0000-0002-5191-7682; Jamali, Kiarash/0009-0008-4805-9518; Balmforth, Matthew/0000-0003-2651-9428	We thank our colleagues J. Attwater, G. Houlihan, E. Derivery and T. Stevens. We thank our collaborators C. Tuckey, P. Coupland and J. Hadfield for their helpful advice and support throughout the course of this work. We thank the Biological Expression Team [MC_U105178804]; Medical Research Council (MRC) [ALTF 648-202]; EMBO Long-term Postdoctoral Fellowship	We thank our colleagues J. Attwater, G. Houlihan, E. Derivery and T. Stevens. We thank our collaborators C. Tuckey, P. Coupland and J. Hadfield for their helpful advice and support throughout the course of this work. We thank the Biological Expression Team; Medical Research Council (MRC)(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)); EMBO Long-term Postdoctoral Fellowship(European Molecular Biology Organization (EMBO))	We thank our colleagues J. Attwater, G. Houlihan, E. Derivery and T. Stevens. We thank our collaborators C. Tuckey, P. Coupland and J. Hadfield for their helpful advice and support throughout the course of this work. We thank the Biological Expression Team (BET) at AstraZeneca, specifically N. Hudson and S. Javed for their assistance in Fab expression and purification. We also thank the following LMB facilities and staff for their general support of this work: LMB Scientific Computing (J. Grimmett, T. Darling and I. Clayson), LMB Mechanical Workshop (S. Scotcher and A. Fowle), LMB Electronics Workshop (A. Howe), LMB Instrument Services (P. Marriott, D. Few and J. Ingle), LMB Biophysics Facility (S. McLaughlin and C. Johnson), LMB Light Microscopy Facility (N. Barry, J. Howe, J. Boulanger, B. Sutcliffe and J. Manton) and LMB Mass Spectrometry Facility (H. Kramer, M. Skehel and S. Maslen). This work was supported by the Medical Research Council (MRC) grant program number MC_U105178804 (P.H.), a research collaboration between AstraZeneca UK and the MRC-MRC-AstraZeneca Blue Sky Grant (BTP), and by an EMBO Long-term Postdoctoral Fellowship ALTF 648-202 (to M.J.L.J.F.).	Agresti JJ, 2010, P NATL ACAD SCI USA, V107, P4004, DOI 10.1073/pnas.0910781107; Alley EC, 2019, NAT METHODS, V16, P1315, DOI 10.1038/s41592-019-0598-1; Arnaout R, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022365; Arnold FH, 2019, ANGEW CHEM INT EDIT, V58, P14420, DOI 10.1002/anie.201907729; Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754; Bentley DR, 2008, NATURE, V456, P53, DOI 10.1038/nature07517; Biswas S, 2021, NAT METHODS, V18, P389, DOI 10.1038/s41592-021-01100-y; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buenrostro JD, 2014, NAT BIOTECHNOL, V32, P562, DOI 10.1038/nbt.2880; Chen B, 2016, NAT CHEM BIOL, V12, P76, DOI [10.1038/nchembio.1978, 10.1038/NCHEMBIO.1978]; Chen ZQ, 2018, CLIN PROTEOM, V15, DOI 10.1186/s12014-018-9184-2; Chowdhery A, 2023, J MACH LEARN RES, V24; COUSSENS L, 1985, SCIENCE, V230, P1132, DOI 10.1126/science.2999974; Cozens C, 2012, P NATL ACAD SCI USA, V109, P8067, DOI 10.1073/pnas.1120964109; Daramola O, 2014, BIOTECHNOL PROGR, V30, P132, DOI 10.1002/btpr.1809; Denny SK, 2019, CSH PERSPECT BIOL, V11, DOI 10.1101/cshperspect.a032300; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Elnaggar A., 2020, ARXIV, DOI [10.48550/arXiv.2007.06225, DOI 10.48550/ARXIV.2007.06225]; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; FENDLY BM, 1990, CANCER RES, V50, P1550; Glanville J, 2009, P NATL ACAD SCI USA, V106, P20216, DOI 10.1073/pnas.0909775106; Greiff V, 2015, TRENDS IMMUNOL, V36, P738, DOI 10.1016/j.it.2015.09.006; Gu LC, 2014, NATURE, V515, P554, DOI 10.1038/nature13761; Hartgring SAY, 2010, ARTHRITIS RHEUM-US, V62, P2716, DOI 10.1002/art.27578; Heinzinger M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3220-8; Hirsch FR, 2004, SEMIN ONCOL, V31, P75, DOI 10.1053/j.seminoncol.2003.12.018; Hsu C, 2022, NAT BIOTECHNOL, V40, P1114, DOI 10.1038/s41587-021-01146-5; HUDZIAK RM, 1989, MOL CELL BIOL, V9, P1165, DOI 10.1128/MCB.9.3.1165; Hughes RA, 2017, CSH PERSPECT BIOL, V9, DOI 10.1101/cshperspect.a023812; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Klapper LN, 2000, ADV CANCER RES, V77, P25; Kovaltsuk A, 2018, J IMMUNOL, V201, P2502, DOI 10.4049/jimmunol.1800708; Kreft KL, 2012, J IMMUNOL, V188, P1874, DOI 10.4049/jimmunol.1102559; Lassus H, 2006, J MOL MED-JMM, V84, P671, DOI 10.1007/s00109-006-0054-4; Layton CJ, 2019, MOL CELL, V73, P1075, DOI 10.1016/j.molcel.2019.02.019; Lee LF, 2012, P NATL ACAD SCI USA, V109, P12674, DOI 10.1073/pnas.1203795109; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; McKeage K, 2002, DRUGS, V62, P209, DOI 10.2165/00003495-200262010-00008; McMahon C, 2018, NAT STRUCT MOL BIOL, V25, P289, DOI 10.1038/s41594-018-0028-6; Meier J., 2021, ADV NEURAL INF PROCE, V34, P29287, DOI [DOI 10.1101/2021.07.09.450648, 10.1101/2021.07.09.450648]; Murphy K, 2012, JANEWAYS IMMUNOBIOLO, V8th; Nutiu R, 2011, NAT BIOTECHNOL, V29, P659, DOI 10.1038/nbt.1882; Olsen TH, 2022, PROTEIN SCI, V31, P141, DOI 10.1002/pro.4205; PERELSON AS, 1979, J THEOR BIOL, V81, P645, DOI 10.1016/0022-5193(79)90275-3; Ramachandran N, 2004, SCIENCE, V305, P86, DOI 10.1126/science.1097639; Rao R., 2020, Biorxiv, DOI [10.1101/2020.12.15.422761, DOI 10.1101/2020.12.15.422761]; Rees AR, 2020, MABS-AUSTIN, V12, DOI 10.1080/19420862.2020.1729683; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Rouet R, 2018, FRONT IMMUNOL, V9, DOI 10.3389/fimmu.2018.00118; Shendure J, 2005, SCIENCE, V309, P1728, DOI 10.1126/science.1117389; Shimizu Y, 2001, NAT BIOTECHNOL, V19, P751, DOI 10.1038/90802; Shin JE, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22732-w; SLAMON DJ, 1989, SCIENCE, V244, P707, DOI 10.1126/science.2470152; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; Svensen N, 2016, CHEMBIOCHEM, V17, P1628, DOI 10.1002/cbic.201600298; Syu GD, 2020, MOL CELL PROTEOMICS, V19, P916, DOI 10.1074/mcp.R120.001936; Tang Y, 2007, J IMMUNOL, V179, P2815, DOI 10.4049/jimmunol.179.5.2815; Tome JM, 2014, NAT METHODS, V11, P683, DOI [10.1038/NMETH.2970, 10.1038/nmeth.2970]; Vodnik M, 2011, MOLECULES, V16, P790, DOI 10.3390/molecules16010790; Vollmers C, 2013, P NATL ACAD SCI USA, V110, P13463, DOI 10.1073/pnas.1312146110; Wei J., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2109.01652; Wilson DS, 1999, ANNU REV BIOCHEM, V68, P611, DOI 10.1146/annurev.biochem.68.1.611; Winter G, 2019, ANGEW CHEM INT EDIT, V58, P14438, DOI 10.1002/anie.201909343; Wu DN, 2023, ANAL CHEM, V95, P2645, DOI 10.1021/acs.analchem.1c04777; Wu ZC, 2021, CURR OPIN CHEM BIOL, V65, P18, DOI 10.1016/j.cbpa.2021.04.004; Xu M, 2021, INT C LEARNING REPRE, DOI [10.48550/ARXIV.2203.02923, DOI 10.48550/ARXIV.2203.02923]	66	3	3	16	22	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2157-846X			NAT BIOMED ENG	Nat. Biomed. Eng	MAR	2024	8	3								10.1038/s41551-023-01093-3	http://dx.doi.org/10.1038/s41551-023-01093-3		OCT 2023	29	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	ML1O7	37814006	hybrid, Green Accepted, Green Published			2024-07-03	WOS:001078085500002
J	Vermeersch, A				Vermeersch, Aaron			Deep learning for K3 fibrations in heterotic/Type IIA string duality	NUCLEAR PHYSICS B			English	Article							N=2	The development of Large Language Models, such as the recently released GPT-4, has revolutionized the field of Machine Learning and opened new avenues for interdisciplinary research. Prompt Engineering, a methodology for designing effective input prompts to guide these AI models, will emerge as a powerful tool for accelerating research efforts. In this study, we leverage Prompt Engineering with GPT-4 to address the problem of predicting K3 Fibrations in Calabi-Yau manifolds embedded in toric varieties with a single weight system. Out of the 184,026 weights spaces previously discovered, 101,495 remained unclassified concerning the presence of a K3 projection, thereby providing an opportunity for machine learning to bridge this gap. By utilizing an ensemble of Deep Neural Networks, we are able to predict the existence of the K3 fibration. Furthermore, we assess the potential of these models to predict the spectrum of possible Hodge Numbers and other properties of reflexive polytopes. These results not only demonstrate the utility of AI in studying the heterotic/Type IIA string duality in F-Theory but also serve as a stepping stone for further machine learning integration into traditional scientific workflows. & COPY; 2023 The Author. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons .org /licenses /by /4 .0/). Funded by SCOAP3.				aaronvermeersch@gmail.com						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aldazabal G, 1996, NUCL PHYS B, V461, P85, DOI 10.1016/0550-3213(95)00654-0; Arias-Tamargo G, 2022, PHYS LETT B, V833, DOI 10.1016/j.physletb.2022.137376; Aspinwall PS, 1996, PHYS LETT B, V369, P233, DOI 10.1016/0370-2693(95)01541-8; Audin M., 1991, The topology of Torus Actions on Symplectic Manifolds; Avram AC, 1997, NUCL PHYS B, V494, P567, DOI 10.1016/S0550-3213(97)00214-9; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bao J., 2022, arXiv; Batyrev V.V., 1993, arXiv; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bull K, 2018, PHYS LETT B, V785, P65, DOI 10.1016/j.physletb.2018.08.008; Candelas P, 2013, COMMUN MATH PHYS, V324, P937, DOI 10.1007/s00220-013-1802-2; Chollet F., 2017, Deep Learning with Python, DOI DOI 10.1186/S12859-020-03546-X; Cox D., 2014, ARXIVALGGEOM9210008; Deen R, 2020, Arxiv, DOI arXiv:2003.13339; Geron A., 2017, Hands-on Machine Learning With Scikit-Learn and TensorFlow: concepts, tools, and Techniques to Build Intelligent Systems; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Lian BH, 1995, Arxiv, DOI arXiv:hep-th/9507151; He Y.-H., 2017, arXiv; He YH, 2023, Arxiv, DOI arXiv:2303.12626; He YH, 2021, PHYS LETT B, V815, DOI 10.1016/j.physletb.2021.136139; He YH, 2019, PHYS LETT B, V798, DOI 10.1016/j.physletb.2019.134889; KLEMM A, 1995, PHYS LETT B, V357, P313, DOI 10.1016/0370-2693(95)00937-G; Kreuzer M, 1997, COMMUN MATH PHYS, V185, P495, DOI 10.1007/s002200050100; Kreuzer M, 2004, COMPUT PHYS COMMUN, V157, P87, DOI 10.1016/S0010-4655(03)00491-0; Kreuzer M, 1998, J GEOM PHYS, V26, P272, DOI 10.1016/S0393-0440(97)00059-4; Kreuzer M, 2000, Arxiv, DOI arXiv:hep-th/0002240; Ruehle F, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP08(2017)038; Aspinwall PS, 1999, Arxiv, DOI arXiv:hep-th/9611137; Skarke H, 1996, MOD PHYS LETT A, V11, P1637, DOI 10.1142/S0217732396001636; Vafa C, 1996, NUCL PHYS B, P225, DOI 10.1016/0920-5632(96)00025-4; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]	32	0	0	1	10	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0550-3213	1873-1562		NUCL PHYS B	Nucl. Phys. B	AUG	2023	993								116279	10.1016/j.nuclphysb.2023.116279	http://dx.doi.org/10.1016/j.nuclphysb.2023.116279		JUN 2023	14	Physics, Particles & Fields	Science Citation Index Expanded (SCI-EXPANDED)	Physics	Q1FJ4		gold			2024-07-03	WOS:001055040800001
C	Cheung, TH; Lam, KM			IEEE	Cheung, Tsun-Hin; Lam, Kin-Man			FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking	2023 ASIA PACIFIC SIGNAL AND INFORMATION PROCESSING ASSOCIATION ANNUAL SUMMIT AND CONFERENCE, APSIPA ASC	Asia-Pacific Signal and Information Processing Association Annual Summit and Conference		English	Proceedings Paper	Asia-Pacific-Signal-and-Information-Processing-Association Annual Summit and Conference (APSIPA ASC)	OCT 31-NOV 03, 2023	Taipei, TAIWAN	Asia Pacific Signal & Informat Proc Assoc				Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments on two widely used fact-checking datasets: RAWFC and LIAR. The results demonstrate that our approach achieves state-of-the-art performance in fact-checking tasks. By integrating external evidence, we bridge the gap between the model's knowledge and the most up-to-date and sufficient context available, leading to improved fact-checking outcomes. Our findings have implications for combating misinformation and promoting the dissemination of accurate information on online platforms. Our released materials are accessible at: https://thcheung.github.io/factllama.	[Cheung, Tsun-Hin; Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Elect Engn, Kowloon, Hong Kong, Peoples R China	Hong Kong Polytechnic University	Cheung, TH (corresponding author), Hong Kong Polytech Univ, Dept Elect & Elect Engn, Kowloon, Hong Kong, Peoples R China.	tsun-hin.cheung@connect.polyu.hk; enkmlam@polyu.edu.hk	Cheung, Tsun-Hin/ITV-1234-2023	Cheung, Tsun-Hin/0000-0001-5467-6872				Atanasova Pepa, 2020, P 58 ANN M ASS COMPU, DOI 10.18653/v1/2020.acl-main.656; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cui LM, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2961, DOI 10.1145/3357384.3357862; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Google AI, 2022, Google AI Blog; Guo ZJ, 2022, T ASSOC COMPUT LING, V10, P178, DOI 10.1162/tacl_a_00454; Hassan N, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1803, DOI 10.1145/3097983.3098131; Hu E., 2022, ICLR 2022; Hu LM, 2022, AI OPEN, V3, P133, DOI 10.1016/j.aiopen.2022.09.001; Kotonya N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7740; Ma J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2561; Mishra S., 2022, P ANN M ASS COMP LIN, DOI [10.18653/v1/2022.acllong.244, DOI 10.18653/V1/2022.ACLLONG.244]; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Popat K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P22; Rashkin H, 2017, P 2017 C EMP METH NA, P2931, DOI 10.18653/v1/d17-1317; Raval M. S., 2022, P 2022 AS PAC SIGN I, DOI DOI 10.23919/APSIPAASC55919.2022.9980089; Taori R., 2023, GitHub Repository; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067; Wang Y., 2023, Self-instruct: Aligning language models with self-generated instructions; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yang Z., 2022, P 29 INT C COMPUTATI, P2608; Zhu BR, 2021, IEEE-ACM T AUDIO SPE, V29, P3132, DOI 10.1109/TASLP.2021.3120636	27	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2309-9402		979-8-3503-0067-3	ASIAPAC SIGN INFO PR			2023							846	853		10.1109/APSIPAASC58517.2023.10317251	http://dx.doi.org/10.1109/APSIPAASC58517.2023.10317251			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1OB		Green Submitted			2024-07-03	WOS:001108741800131
C	Song, CH; Xiao, X; Zhang, B; Xia, ST			ACM	Song, Chen-Hui; Xiao, Xi; Zhang, Bin; Xia, Shu-Tao			Follow the Will of the Market: A Context-Informed Drift-Aware Method for Stock Prediction	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Stock Prediction; Context-Informed; Drift-Aware		The dynamic nature of stock market styles, referred to as concept drift, poses a formidable challenge when applying deep learning to stock prediction. Models trained on historical data often struggle to adapt to the latest market styles, as the patterns they have learned may no longer hold true over time. To alleviate this issue, the recently popularized concept of In-Context learning has provided us with valuable insights. In this approach, large language models (LLMs) are exposed to multiple examples of input-label pairs, also known as demonstrations, as part of the prompt before performing a task on an unseen example. By thoroughly analyzing these demonstrations, LLMs can uncover potential patterns and effectively adapt to new tasks. Building upon this concept, we propose a Context-Informed drift-aware method for Stock Prediction (CISP), which continually adjusts to the latest market styles and offers more accurate predictions. Our proposed method consists of two key parts. Firstly, we introduce a straightforward and efficient technique for designing demonstrations that aggregate current market information, thereby indicating the prevailing stock market style. Secondly, we incorporate a prediction module with dynamic parameters, allowing it to appropriately adjust its model parameters based on the market patterns embedded in the aforementioned demonstrations. Through extensive experiments conducted on real-world stock market datasets, our approach consistently outperforms the most advanced existing methods for stock prediction.	[Song, Chen-Hui; Xiao, Xi; Xia, Shu-Tao] Tsinghua Univ, Grad Sch, Shenzhen, Peoples R China; [Zhang, Bin; Xia, Shu-Tao] Peng Cheng Lab, Shenzhen, Peoples R China	Tsinghua Shenzhen International Graduate School; Tsinghua University; Peng Cheng Laboratory	Xiao, X (corresponding author), Tsinghua Univ, Grad Sch, Shenzhen, Peoples R China.	sch21@mails.tsinghua.edu.cn; xiaox@sz.tsinghua.edu.cn; bin.zhang@pcl.ac.cn; xiast@sz.tsinghua.edu.cn		XIAO, XI/0000-0003-1521-9542	National Natural Science Foundation of China [61972219, 62171248]; Science and Technology Program of Shenzhen [JCYJ20220818101012025]; Research and Development Program of Shenzhen [JCYJ20190813174403598]; Overseas Research Cooperation Fund of Tsinghua Shenzhen International Graduate School [HW2021013]; Key Project of Peng Cheng Laboratory [PCL2021A07, PCL2023AS4-1]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Science and Technology Program of Shenzhen; Research and Development Program of Shenzhen; Overseas Research Cooperation Fund of Tsinghua Shenzhen International Graduate School; Key Project of Peng Cheng Laboratory	This work is supported in part by the National Natural Science Foundation of China (61972219 and 62171248), the Science and Technology Program of Shenzhen (JCYJ20220818101012025), the Research and Development Program of Shenzhen (JCYJ20190813174403598), the Overseas Research Cooperation Fund of Tsinghua Shenzhen International Graduate School (HW2021013), and the Key Project of Peng Cheng Laboratory (PCL2021A07 and PCL2023AS4-1).	AMAYA D, 2011, CREATES RES PAPERS, V8011; Asgharian Hossein, 2002, TECHNICAL REPORT; Bai Shaojie, 2018, CoRR, DOI DOI 10.48550/ARXIV.1803.01271; Chen T., 2015, R package version 042, V1, P1; Chen W, 2021, INFORM SCIENCES, V556, P67, DOI 10.1016/j.ins.2020.12.068; Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243; Ding DZ, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1114, DOI 10.1145/3292500.3330896; Ding QG, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4640; Dong Qingxiu, 2022, ARXIV230100234; Ehsani S, 2022, J FINANC, V77, P1877, DOI 10.1111/jofi.13131; Greenwood Robin., 2005, CROSS SECTIONAL ANAL; Grinsztajn Leo, 2022, ARXIV220708815; Hahn Michael, 2023, ARXIV230307971; Hansen PR, 2006, J BUS ECON STAT, V24, P127, DOI 10.1198/073500106000000071; Jiang WW, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115537; Kalra Sneh, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P491, DOI 10.1109/COMITCon.2019.8862265; Ke GL, 2017, ADV NEUR IN, V30; Kumar D, 2022, MATER TODAY-PROC, V49, P3187, DOI 10.1016/j.matpr.2020.11.399; Kumbure MM, 2022, EXPERT SYST APPL, V197, DOI 10.1016/j.eswa.2022.116659; Li JZ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3063, DOI [10.1145/3340531.3412879, 10.1061/9780784482933.264]; Li W, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4541; Li Xiaonan, 2023, ARXIV230213539; Li YL, 2020, INT J FORECASTING, V36, P1541, DOI 10.1016/j.ijforecast.2020.05.001; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin HX, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1017, DOI 10.1145/3447548.3467358; Liu G, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4555; Long JW, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106205; Lu J, 2019, IEEE T KNOWL DATA EN, V31, P2346, DOI 10.1109/TKDE.2018.2876857; Scarselli F, 1998, NEURAL NETWORKS, V11, P15, DOI 10.1016/S0893-6080(97)00097-X; Schwert GW, 1990, Financial Analysts Journal, V46, P23, DOI DOI 10.2469/FAJ.V46.N3.23; Tsymbal A, 2004, PROBLEM CONCEPT DRIF; Vaswani A, 2017, ADV NEUR IN, V30; Wang HY, 2020, AAAI CONF ARTIF INTE, V34, P971; Wang Q, 2020, NEUROCOMPUTING, V399, P342, DOI 10.1016/j.neucom.2020.02.065; Wang SH, 2011, J WEB SEMANT, V9, P247, DOI 10.1016/j.websem.2011.05.003; Wei Jerry, 2023, ARXIV230303846; Wu JMT, 2023, MULTIMEDIA SYST, V29, P1751, DOI 10.1007/s00530-021-00758-w; Xie Sang Michael, 2021, ARXIV211102080; Yan Bencheng, 2022, ADV NEURAL INFORM PR, V35, P24740; Yang LY, 2022, AAAI CONF ARTIF INTE, P11604; Yoo J, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2037, DOI 10.1145/3447548.3467297; Zhang CH, 2020, IEEE DATA MINING, P781, DOI 10.1109/ICDM50108.2020.00087; Zhang LH, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2141, DOI 10.1145/3097983.3098117	43	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							2311	2320		10.1145/3583780.3614886	http://dx.doi.org/10.1145/3583780.3614886			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Bronze			2024-07-03	WOS:001161549502037
J	Farrell, S; Appleton, C; Noble, PJM; Al Moubayed, N				Farrell, Sean; Appleton, Charlotte; Noble, Peter-John Maentylae; Al Moubayed, Noura			PetBERT: automated ICD-11 syndromic disease coding for outbreak detection in first opinion veterinary electronic health records	SCIENTIFIC REPORTS			English	Article								Effective public health surveillance requires consistent monitoring of disease signals such that researchers and decision-makers can react dynamically to changes in disease occurrence. However, whilst surveillance initiatives exist in production animal veterinary medicine, comparable frameworks for companion animals are lacking. First-opinion veterinary electronic health records (EHRs) have the potential to reveal disease signals and often represent the initial reporting of clinical syndromes in animals presenting for medical attention, highlighting their possible significance in early disease detection. Yet despite their availability, there are limitations surrounding their free text-based nature, inhibiting the ability for national-level mortality and morbidity statistics to occur. This paper presents PetBERT, a large language model trained on over 500 million words from 5.1 million EHRs across the UK. PetBERT-ICD is the additional training of PetBERT as a multi-label classifier for the automated coding of veterinary clinical EHRs with the International Classification of Disease 11 framework, achieving F1 scores exceeding 83% across 20 disease codings with minimal annotations. PetBERT-ICD effectively identifies disease outbreaks, outperforming current clinician-assigned point-of-care labelling strategies up to 3 weeks earlier. The potential for PetBERT-ICD to enhance disease surveillance in veterinary medicine represents a promising avenue for advancing animal health and improving public health outcomes.	[Farrell, Sean; Al Moubayed, Noura] Univ Durham, Dept Comp Sci, Durham, England; [Appleton, Charlotte] Univ Lancaster, Lancaster Med Sch, Ctr Hlth Informat Comp & Stat, Lancaster, England; [Noble, Peter-John Maentylae] Univ Liverpool, Inst Infect Vet & Ecol Sci, Liverpool, England; [Al Moubayed, Noura] Evergreen Life Ltd, Manchester, Lancs, England	Durham University; Lancaster University; University of Liverpool	Farrell, S (corresponding author), Univ Durham, Dept Comp Sci, Durham, England.	sean.farrell2@durham.ac.uk			This work was supported by Innovate UK grant number 10027358. [10027358]; Innovate UK	This work was supported by Innovate UK grant number 10027358.; Innovate UK(UK Research & Innovation (UKRI)Innovate UK)	This work was supported by Innovate UK grant number 10027358.	Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; Arsevska E, 2017, VET REC, V181, P228, DOI 10.1136/vr.j3642; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barak-Corren Y, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00537-x; Burns ML, 2020, ANESTHESIOLOGY, V132, P939, DOI 10.1097/ALN.0000000000003223; Decaro N, 2004, MICROBIOLOGICA, V27, P177; Derscheid RJ, 2021, J VET DIAGN INVEST, V33, P419, DOI 10.1177/1040638721999373; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong H, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00705-7; Farzandipour M, 2010, INT J INFORM MANAGE, V30, P78, DOI 10.1016/j.ijinfomgt.2009.07.002; GREEN J, 1993, MED CARE, V31, P719, DOI 10.1097/00005650-199308000-00005; Hale A.C, 2022, arXiv; Hale AC, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53352-6; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; HSIA DC, 1988, NEW ENGL J MED, V318, P352, DOI 10.1056/NEJM198802113180604; Hsu JL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247116; Huang C.-W., 2022, P 4 CLIN NAT LANG PR, P10, DOI DOI 10.18653/V1/2022.CLINICALNLP-1.2; Hur B, 2020, 19TH SIGBIOMED WORKSHOP ON BIOMEDICAL LANGUAGE PROCESSING (BIONLP 2020), P156; Jie Chen, 2019, 2019 IEEE 14th International Conference on Intelligent Systems and Knowledge Engineering (ISKE). Proceedings, P1178, DOI 10.1109/ISKE47853.2019.9170305; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5941; LLOYD SS, 1985, JAMA-J AM MED ASSOC, V254, P1330, DOI 10.1001/jama.254.10.1330; Lucero NE, 2010, EPIDEMIOL INFECT, V138, P280, DOI 10.1017/S0950268809990525; McDermott MBA, 2021, SCI TRANSL MED, V13, DOI 10.1126/scitranslmed.abb1655; Moore GE, 2006, EMERG INFECT DIS, V12, P501, DOI 10.3201/eid1203.050809; Nie A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0067-8; Noble PJM, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0260402; Oehler RL, 2009, LANCET INFECT DIS, V9, P439, DOI 10.1016/S1473-3099(09)70110-0; Owczarczak-Garstecka SC, 2022, VET REC, V191, DOI 10.1002/vetr.1681; Radford AD, 2021, EMERG INFECT DIS, V27, P517, DOI 10.3201/eid2702.202452; Romanov A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1586; Royal College of Veterinary Surgeons, 2022, Tech. Rep.; Sánchez-Vizcano F, 2015, VET REC, V177, P591, DOI 10.1136/vr.h6174; Shi H., 2018, P 56 ANN M ASS COMP, P1066, DOI DOI 10.18653/V1/P18-1098; Smith S, 2010, EUROSURVEILLANCE, V15; Smith Shirley L, 2021, Curr Res Virol Sci, V2, P100011, DOI 10.1016/j.crviro.2021.100011; Song H, 2022, Arxiv, DOI arXiv:2007.08199; Stavisky J, 2011, PREV VET MED, V99, P185, DOI 10.1016/j.prevetmed.2011.02.009; Stone Kieran, 2022, PLOS Digit Health, V1, pe0000017, DOI 10.1371/journal.pdig.0000017; Stubbs A, 2015, J BIOMED INFORM, V58, pS20, DOI 10.1016/j.jbi.2015.07.020; Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Uzuner Ö, 2011, J AM MED INFORM ASSN, V18, P552, DOI 10.1136/amiajnl-2011-000203; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; WHO, 2019, International statistical classification of diseases and related health problems, P11; WHO, 2010, Asia Pacific Strategy for Emerging Diseases; WHO World Health Organization, 2017, ONE HEALTH-AMSTERDAM; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; World Health Organization, 2016, INT STAT CLASS DIS R, DOI DOI 10/2016/EN; Yuan Z, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P808; Zafirah SA, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-2843-1; Yalniz IZ, 2019, Arxiv, DOI [arXiv:1905.00546, DOI 10.48550/ARXIV.1905.00546]; Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang YH, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0113-1; Zhang Z., 2020, P 3 CLIN NATURAL LAN, P24, DOI DOI 10.18653/V1/2020.CLINICALNLP-1.3; Zhu XQ, 2004, ARTIF INTELL REV, V22, P177, DOI 10.1007/s10462-004-0751-8	59	0	0	3	4	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	OCT 21	2023	13	1							18015	10.1038/s41598-023-45155-7	http://dx.doi.org/10.1038/s41598-023-45155-7			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	W8SN2	37865683	Green Published, Green Submitted, gold			2024-07-03	WOS:001094273200034
J	Just, J				Just, Julian			Natural language processing for innovation search - Reviewing an emerging non-human innovation intermediary	TECHNOVATION			English	Article						Natural language processing; Innovation search; Innovation intermediation; Front-end of innovation; AI -based innovation management; Systematic literature review	FUZZY FRONT-END; INFORMATION OVERLOAD; SOCIAL MEDIA; PRODUCT; TECHNOLOGY; IDEAS; DESIGN; ORGANIZATIONS; METHODOLOGY; COMMUNITIES	Applying artificial intelligence (AI), especially natural language processing (NLP), to harness large amounts of information from patent databases, online communities, social media, or crowdsourcing platforms is becoming increasingly popular to help organizations find promising solutions. In the era of non-human innovation intermediaries, we should begin to view NLP not only as a useful technology applied in different innovation practices but also as an intermediary orchestrating valuable information. Previous research has not taken this perspective, and knowledge about its intermediation activities and functions is limited. This study reviews 167 academic articles to better understand how NLP approaches can enrich intermediation in early-stage innovation search. It identifies 18 distinctive innovation practices taking over activities like forecasting trends, illustrating technology and idea landscapes, filtering out distinctive contributions, recombining domain-specific and analogous knowledge, or matching problems with solutions. While certain NLP capabilities complement each other, the analysis shows that the choice of the most appropriate approach depends on the characteristics of the innovation practice. Innovation researchers and practitioners should rethink current roles and responsibilities in AI-based innovation processes. As seen in the recent emergence of large language models (LLMs), the rapidly evolving field offers many future research opportunities and practical benefits.	[Just, Julian] Univ Innsbruck, Team Innovat & Entrepreneurship, Univ Str 15, A-6020 Innsbruck, Austria	University of Innsbruck	Just, J (corresponding author), Univ Innsbruck, Team Innovat & Entrepreneurship, Univ Str 15, A-6020 Innsbruck, Austria.	julian.just@uibk.ac.at		Just, Julian/0000-0002-9292-087X				Ahmed F, 2018, J MECH DESIGN, V140, DOI 10.1115/1.4038070; Ahmed F, 2016, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2016, VOL 7; Alammar J., 2022, Python package "topically"; Alfeo AL, 2021, J INTELL MANUF, V32, P1699, DOI 10.1007/s10845-021-01797-w; [Anonymous], 2023, About youChat; [Anonymous], 2018, P NAACL HLT; [Anonymous], 2015, The state of crowdsourcing in 2015; Antons D, 2023, ORGAN RES METHODS, V26, P107, DOI 10.1177/1094428121991230; Antons D, 2020, R&D MANAGE, V50, P329, DOI 10.1111/radm.12408; Arts S, 2021, RES POLICY, V50, DOI 10.1016/j.respol.2020.104144; Ayele W.Y., 2021, FUTURE INFORM COMMUN, P744; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bernier C, 2021, INNOV-ORGAN MANAG, DOI 10.1080/14479338.2021.2016417; Bian Z, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112412082; Bianchi F, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P759; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bouschery SG, 2023, J PROD INNOVAT MANAG, V40, P139, DOI 10.1111/jpim.12656; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brunswicker S, 2010, INT J INNOV MANAG, V14, P683, DOI 10.1142/S1363919610002829; Cai D, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3417, DOI 10.1145/3477495.3532682; Caloffi A, 2023, TECHNOL FORECAST SOC, V189, DOI 10.1016/j.techfore.2023.122351; Chandrasekaran D, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3440755; Chang YC, 2022, INFORM MANAGE-AMSTER, V59, DOI 10.1016/j.im.2021.103587; Chase H., 2023, Google Search Wrapper.; Chen Xieling., 2022, Natural Language Processing Journal, V1, P100001, DOI [10.1016/j.nlp.2022.100001, DOI 10.1016/J.NLP.2022.100001]; Cheng XS, 2020, J MANAGE INFORM SYST, V37, P349, DOI 10.1080/07421222.2020.1759344; Chesbrough H., 2006, OPEN BUSINESS MODELS; Chesbrough HW, 2003, MIT SLOAN MANAGE REV, V44, P35; Choi J, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102279; Christensen K, 2017, CREAT INNOV MANAG, V26, P17, DOI 10.1111/caim.12202; Chui M, 2022, The state of AI in 2022-and a half decade in review; Cockburn IainM., 2019, EC ARTIFICIAL INTELL, P115; Cohan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2270; Cohere, 2023, The Python Package "Cohere; COOPER RG, 1988, IND MARKET MANAG, V17, P249, DOI 10.1016/0019-8501(88)90008-9; Csardi G., 2020, R Package "igraph.; Dahlander L, 2021, RES POLICY, V50, DOI 10.1016/j.respol.2021.104218; Dahlander L, 2010, RES POLICY, V39, P699, DOI 10.1016/j.respol.2010.01.013; Davenport TH, 2018, J BUS ANAL, V1, P73, DOI 10.1080/2573234X.2018.1543535; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dieng AB, 2020, T ASSOC COMPUT LING, V8, P439, DOI 10.1162/tacl_a_00325; Dodgson M, 2006, R&D MANAGE, V36, P333, DOI 10.1111/j.1467-9310.2006.00429.x; Duan W, 2009, MIS QUART, V33, P23; Edmunds A, 2000, INT J INFORM MANAGE, V20, P17, DOI 10.1016/S0268-4012(99)00051-1; Felin T, 2016, ORGAN SCI, V27, P222, DOI 10.1287/orsc.2015.1022; Felin T, 2014, RES POLICY, V43, P914, DOI 10.1016/j.respol.2013.09.006; Fu K, 2015, RES ENG DES, V26, P77, DOI 10.1007/s00163-014-0186-4; Fu K, 2013, DESIGN STUD, V34, P729, DOI 10.1016/j.destud.2013.06.002; Fu K, 2013, J MECH DESIGN, V135, DOI 10.1115/1.4023158; Füller J, 2007, J BUS RES, V60, P60, DOI 10.1016/j.jbusres.2006.09.019; Füller J, 2022, TECHNOL FORECAST SOC, V178, DOI 10.1016/j.techfore.2022.121598; Geum Y, 2016, TECHNOL FORECAST SOC, V111, P176, DOI 10.1016/j.techfore.2016.06.026; Giordano V, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120499; Goucher-Lambert K, 2020, J MECH DESIGN, V142, DOI 10.1115/1.4046077; Grootendorst M., 2022, BERTOPIC NEURAL TOPI; Haefner N, 2021, TECHNOL FORECAST SOC, V162, DOI 10.1016/j.techfore.2020.120392; Han Y, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4048819; He YJ, 2019, J MECH DESIGN, V141, DOI 10.1115/1.4044399; Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625; Hiebl MRW, 2023, ORGAN RES METHODS, V26, P229, DOI 10.1177/1094428120986851; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Hong J, 2022, MARKET SCI, V41, P941, DOI 10.1287/mksc.2022.1351; Hong S, 2022, TECHNOVATION, V112, DOI 10.1016/j.technovation.2021.102407; Howells J, 2022, R&D MANAGE, V52, P992, DOI 10.1111/radm.12534; Howells J, 2006, RES POLICY, V35, P715, DOI 10.1016/j.respol.2006.03.005; Hugging Face, 2023, Python package "transformers; Jeon D, 2022, TECHNOL FORECAST SOC, V174, DOI 10.1016/j.techfore.2021.121294; Jeong Y, 2019, TECHNOL FORECAST SOC, V146, P655, DOI 10.1016/j.techfore.2018.05.010; Just J., 2023, Innovation., P1, DOI [10.1080/14479338.2023.2215740,00, DOI 10.1080/14479338.2023.2215740,00]; Kakatkar C, 2020, BUS HORIZONS, V63, P171, DOI 10.1016/j.bushor.2019.10.006; Kang Y, 2020, J MANAG ANAL, V7, P139, DOI 10.1080/23270012.2020.1756939; Kavlakoglu E., 2020, Watson Blog; Kayser V, 2014, INT J INNOV MANAG, V18, DOI 10.1142/S1363919614400040; Khurana A, 1998, J PROD INNOVAT MANAG, V15, P57, DOI 10.1016/S0737-6782(97)00066-0; Kim J, 2002, R&D MANAGE, V32, P269, DOI 10.1111/1467-9310.00259; Kim J, 2019, R&D MANAGE, V49, P155, DOI 10.1111/radm.12292; Kim J, 2021, TECHNOL FORECAST SOC, V171, DOI 10.1016/j.techfore.2021.120972; Koen P, 2001, RES TECHNOL MANAGE, V44, P46, DOI 10.1080/08956308.2001.11671418; Lakhani K.R., 2016, Harv. Bus. Rev.; Lee CH, 2013, TRENDS ENDOCRIN MET, V24, P222, DOI [10.1016/j.tem.2013.01.005, 10.1016/j.technovation.2020.102140]; Lee C, 2021, TECHNOL FORECAST SOC, V166, DOI 10.1016/j.techfore.2021.120646; Lee H, 2018, IND MANAGE DATA SYST, V118, P683, DOI 10.1108/IMDS-02-2017-0044; Lee S, 2008, R&D MANAGE, V38, P169, DOI 10.1111/j.1467-9310.2008.00509.x; Lee S, 2009, TECHNOVATION, V29, P481, DOI 10.1016/j.technovation.2008.10.006; Li Q., 2020, ACM Trans. Intell. Syst. Technol, V37; Liu Q., 2020, ARXIV; Liu Y, 2019, TOTAL QUAL MANAG BUS, V30, P1596, DOI 10.1080/14783363.2017.1389265; Liu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2890; Lopez-Vega H, 2016, RES POLICY, V45, P125, DOI 10.1016/j.respol.2015.08.003; Ma TT, 2021, TECHNOL FORECAST SOC, V173, DOI 10.1016/j.techfore.2021.121159; Makarius EE, 2020, J BUS RES, V120, P262, DOI 10.1016/j.jbusres.2020.07.045; Mikolov T, 2013, COMPUTING RES REPOSI; Miric M, 2023, STRATEGIC MANAGE J, V44, P491, DOI 10.1002/smj.3441; Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237; OpenAI, 2023, ChatGPT plugins; OpenAI, 2023, Python Package "OpenAI; Ozcan S, 2021, TECHNOVATION, V107, DOI 10.1016/j.technovation.2021.102322; Papers With Code, 2023, Browse State-of-the-Art; Park H, 2015, SERV BUS, V9, P115, DOI 10.1007/s11628-013-0222-x; Park M, 2021, SERV BUS, V15, P539, DOI 10.1007/s11628-021-00449-6; Pedersen T.L., 2020, R: Package tidygraph; Pedersen T.L., 2020, R Package "Ggraph; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Piezunka H, 2015, ACAD MANAGE J, V58, P856, DOI 10.5465/amj.2012.0458; Ravi K, 2015, KNOWL-BASED SYST, V89, P14, DOI 10.1016/j.knosys.2015.06.015; Rehurek R., 2010, P LREC 2010 WORKSH N, P45, DOI DOI 10.13140/2.1.2393.1847; Ritala P., 2023, Transforming boundaries: how does ChatGPT change knowledge work?, DOI [10.1108/JBS-05-2023-0094, DOI 10.1108/JBS-05-2023-0094]; Robinson D., 2020, R Package "widyr.; Roetzel P. G., 2019, BUSINESS RES, V12, P479, DOI DOI 10.1007/S40685-018-0069-Z; Rosvall M, 2008, P NATL ACAD SCI USA, V105, P1118, DOI 10.1073/pnas.0706851105; Sasaki H, 2020, ENG TECHNOL APPL SCI, V10, P5903; Seo W, 2016, TECHNOL FORECAST SOC, V105, P94, DOI 10.1016/j.techfore.2016.01.011; Shen YC, 2020, TECHNOL FORECAST SOC, V160, DOI 10.1016/j.techfore.2020.120225; Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649; Siddharth L, 2022, DES SCI, V8, DOI 10.1017/dsj.2022.16; Simsek Z., 2021, Systematicity in organizational research literature reviews: a framework and assessment, P1, DOI [10.1177/10944281211008652, DOI 10.1177/10944281211008652]; Son C, 2012, EXPERT SYST APPL, V39, P2489, DOI 10.1016/j.eswa.2011.08.101; Song B, 2017, RES ENG DES, V28, P251, DOI 10.1007/s00163-016-0240-5; Song K, 2017, TECHNOVATION, V60-61, P1, DOI 10.1016/j.technovation.2017.03.001; Stanko MA, 2016, MIT SLOAN MANAGE REV, V57, P15; Sykora M, 2022, J BUS RES, V144, P997, DOI 10.1016/j.jbusres.2022.02.048; Takey SM, 2016, TECHNOL FORECAST SOC, V111, P97, DOI 10.1016/j.techfore.2016.06.011; Tan LB, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101408; Teng F, 2021, TECHNOL FORECAST SOC, V169, DOI 10.1016/j.techfore.2021.120859; Terwiesch C, 2008, MANAGE SCI, V54, P1529, DOI 10.1287/mnsc.1080.0884; Testa S, 2020, INFORM MANAGE-AMSTER, V57, DOI 10.1016/j.im.2019.103196; Thorleuchter D, 2015, FUTURES, V66, P25, DOI 10.1016/j.futures.2014.12.007; Timoshenko A, 2019, MARKET SCI, V38, P1, DOI 10.1287/mksc.2018.1123; Tranfield D, 2003, BRIT J MANAGE, V14, P207, DOI 10.1111/1467-8551.00375; Trappey A, 2021, TECHNOL FORECAST SOC, V164, DOI 10.1016/j.techfore.2020.120511; Trappey AJC, 2018, ADV ENG INFORM, V36, P120, DOI 10.1016/j.aei.2018.03.004; Tseng YH, 2007, INFORM PROCESS MANAG, V43, P1216, DOI 10.1016/j.ipm.2006.11.011; Vaswani A, 2017, ADV NEUR IN, V30; Veganti R, 1997, R&D MANAGE, V27, P377, DOI 10.1111/1467-9310.00072; von Hippel E, 2021, RES POLICY, V50, DOI 10.1016/j.respol.2020.104056; von Hippel E, 2016, ORGAN SCI, V27, P207, DOI 10.1287/orsc.2015.1023; Wahl J, 2022, R&D MANAGE, V52, P427, DOI 10.1111/radm.12526; Wang JT, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100941; Wang MY, 2010, R&D MANAGE, V40, P491, DOI 10.1111/j.1467-9310.2010.00612.x; Wang X, 2022, J MARKETING, V86, P155, DOI 10.1177/00222429211047822; Wang XF, 2021, IEEE T ENG MANAGE, V68, P1309, DOI 10.1109/TEM.2019.2958113; Wei Y, 2022, J MARKETING, V86, P87, DOI 10.1177/00222429211005481; West J, 2017, INNOV-ORGAN MANAG, V19, P43, DOI 10.1080/14479338.2016.1258995; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5; Yang ZL, 2021, TECHNOL FORECAST SOC, V167, DOI 10.1016/j.techfore.2021.120673; Yoon J, 2015, TECHNOL FORECAST SOC, V100, P153, DOI 10.1016/j.techfore.2015.04.012; Zhang CW, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037478; Zhang M, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102389; Zhang ZL, 2023, MANAGE SCI, V69, P2339, DOI 10.1287/mnsc.2022.4443; Zhang ZQ, 2013, NAT LANG ENG, V19, P411, DOI 10.1017/S1351324912000125; Zhao M, 2021, TECHNOL ECON DEV ECO, V27, P550, DOI 10.3846/tede.2021.14223; [赵文轩 Zhao Wenxuan], 2023, [中国土壤与肥料, Soil and Fertilizer Sciences in China], P1	154	5	5	59	85	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0166-4972	1879-2383		TECHNOVATION	Technovation	JAN	2024	129								102883	10.1016/j.technovation.2023.102883	http://dx.doi.org/10.1016/j.technovation.2023.102883		OCT 2023	21	Engineering, Industrial; Management; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Engineering; Business & Economics; Operations Research & Management Science	W0GS4		hybrid			2024-07-03	WOS:001088506400001
J	Wandelt, S; Sun, XQ; Zhang, AM				Wandelt, Sebastian; Sun, Xiaoqian; Zhang, Anming			AI-driven assistants for education and research? A case study on ChatGPT for air transport management	JOURNAL OF AIR TRANSPORT MANAGEMENT			English	Article						Chatbots; Artificial Intelligence; Education; Research	AVIATION; CHALLENGES; STUDENTS	Artificial Intelligence is in the process to transform various parts of the aviation industry, from the reduction of delays and increasing fuel efficiency to better demand prediction models. The latest kid on the block is ChatGPT, a large language model developed by OpenAI, which has made into the news for its mindblowing ability to create textual content in any structured language. Doing so, ChatGPT has the potential to revolutionize the way we communicate with computers, and it could have a lasting impact on aviation education and research. In this study, we investigate the potential of this impact and, the extent to which it has already materialized, based on a set of graduate student surveys and experiments with ChatGPT. The results of our surveys indicate the interest of students in efficient learning, time saving, and improvement in programming/writing skills. Our experiments on terminology explanation, state-of-the-art identification of selected research tasks as well as programming design, highlight the tradeoffs between benefits and potential risks inherent to the usage of ChatGPT and AI-driven assistants in general. Overall, we believe that our study makes a first contribution to evaluating an exciting new technology which has the potential to revolutionize our aviation system.	[Wandelt, Sebastian; Sun, Xiaoqian] Beihang Univ, Sch Elect & Informat Engn, Natl Key Lab CNS ATM, Beijing 100191, Peoples R China; [Zhang, Anming] Univ British Columbia, Sauder Sch Business, Vancouver, BC, Canada	Beihang University; University of British Columbia	Sun, XQ (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Natl Key Lab CNS ATM, Beijing 100191, Peoples R China.	wandelt@buaa.edu.cn; sunxq@buaa.edu.cn; anming.zhang@sauder.ubc.ca			National Natural Science Foundation of China [U2233214, 62250710166]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This study is supported by the National Natural Science Foundation of China (Grant No. U2233214, No. 62250710166) .	Abdelghany A, 2023, J AIR TRANSP MANAG, V107, DOI 10.1016/j.jairtraman.2022.102339; Adnan M., 2020, J. Pedagog. Res, V2, P45, DOI [DOI 10.33902/JPSP.2020261309, 10.33902/jpsp.2020261309, 10.33902/JPSP.2020261309]; Al-Hosan AM, 2020, J PUBLIC AFF, V20, DOI 10.1002/pa.2332; Alhat S., 2020, International Journal of Education, V8, P101, DOI DOI 10.34293/EDUCATION.V8I4.3238; Aristovnik A, 2020, Impacts of the COVID-19 pandemic on life of higher education students: A global perspective, DOI [10.20944/preprints202008.0246.v2, DOI 10.20944/PREPRINTS202008.0246.V2]; Ates S.S., 2022, Digitalization and the Impacts of COVID-19 on the Aviation Industry, P102; Biswas B., 2020, University student perspective, V4, P1, DOI [10.29333/aquademia/8443, DOI 10.29333/AQUADEMIA/8443]; Byers D.A, 2016, TR News; Cavagnetto N., 2022, Transp. Res. Procedia, V66, P156; Chu HC, 2014, EDUC TECHNOL SOC, V17, P332; Chung SH, 2020, TRANSPORT RES E-LOG, V134, DOI 10.1016/j.tre.2020.101837; Council N.R, 1997, Taking Flight: Education and Training for Aviation Careers; Diana T, 2022, J AIR TRANSP MANAG, V102, DOI 10.1016/j.jairtraman.2022.102228; Geursen IL, 2023, J AIR TRANSP MANAG, V109, DOI 10.1016/j.jairtraman.2023.102397; Golfetti A, 2021, Transform. Transp., V21, P3; Gowthami S., 2016, International Journal of Scientific Engineering and Applied Science, V2, P473; Hong SJ, 2016, J AIR TRANSP MANAG, V55, P213, DOI 10.1016/j.jairtraman.2016.05.010; Ilic A, 2010, EUR J OPER RES, V206, P289, DOI 10.1016/j.ejor.2010.02.022; Jardines A, 2021, J AIR TRANSP MANAG, V95, DOI 10.1016/j.jairtraman.2021.102109; Lappas I, 2016, J AEROSP TECHNOL MAN, V8, P232; Lucini FR, 2020, J AIR TRANSP MANAG, V83, DOI 10.1016/j.jairtraman.2019.101760; Maheshwari A., 2018, 2018 Aviation Technology, Integration, and Operations Conference p, P3980, DOI DOI 10.2514/6.2018-3980; Miani P, 2021, J AIR TRANSP MANAG, V94, DOI 10.1016/j.jairtraman.2021.102081; Naciri A., 2020, Aquademia, V4, pep20016, DOI DOI 10.29333/AQUADEMIA/8227; Newcomer JM, 2014, INT J AVIAT AERONAUT, V1, DOI 10.15394/ijaaa.2014.1014; Ng DTK, 2022, BRIT J EDUC TECHNOL, V53, P443, DOI 10.1111/bjet.13185; Peksatici,Ö, 2019, J AIR TRANSP MANAG, V79, DOI 10.1016/j.jairtraman.2019.101687; Raisinghani MS, 2005, INT J DIST EDUC, V3, P20, DOI 10.4018/jdet.2005010102; Rajendran S, 2021, J AIR TRANSP MANAG, V92, DOI 10.1016/j.jairtraman.2021.102043; Rodríguez-Sanz A, 2021, J AIR TRANSP MANAG, V90, DOI 10.1016/j.jairtraman.2020.101940; Soni V.D., 2020, GLOBAL IMPACT E LEAR, DOI [DOI 10.2139/SSRN.3630073, 10.2139/ssrn.363007]; Sun XQ, 2021, TRANSPORT POLICY, V114, P104, DOI 10.1016/j.tranpol.2021.09.010; Sun XQ, 2017, J ADV TRANSPORT, DOI 10.1155/2017/8426926; Truong D, 2021, J AIR TRANSP MANAG, V91, DOI 10.1016/j.jairtraman.2020.101993; Vázquez-Cano E, 2022, INT J INSTR, V15, P37, DOI 10.29333/iji.2022.1523a; Wandelt S, 2021, RELIAB ENG SYST SAFE, V206, DOI 10.1016/j.ress.2020.107307; Yadav DK, 2012, IND HIGHER EDUC, V26, P393, DOI 10.5367/ihe.2012.0118; Yiu CY, 2022, TRANSPORT POLICY, V128, P179, DOI 10.1016/j.tranpol.2022.09.020; Zaharia S., 2021, EDULEARN21 P, P7744	39	3	3	20	20	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0969-6997	1873-2089		J AIR TRANSP MANAG	J. Air Transp. Manag.	OCT	2023	113								102483	10.1016/j.jairtraman.2023.102483	http://dx.doi.org/10.1016/j.jairtraman.2023.102483			11	Transportation	Social Science Citation Index (SSCI)	Transportation	GA7T1					2024-07-03	WOS:001150009300001
J	Zagirova, D; Pushkov, S; Leung, GHD; Liu, BHM; Urban, A; Sidorenko, D; Kalashnikov, A; Kozlova, E; Naumov, V; Pun, FW; Ozerov, IV; Aliper, A; Zhavoronkov, A				Zagirova, Diana; Pushkov, Stefan; Leung, Geoffrey Ho Duen; Liu, Bonnie Hei Man; Urban, Anatoly; Sidorenko, Denis; Kalashnikov, Aleksandr; Kozlova, Ekaterina; Naumov, Vladimir; Pun, Frank W.; Ozerov, Ivan V.; Aliper, Alex; Zhavoronkov, Alex			Biomedical generative pre-trained based transformer language model for age-related disease target discovery	AGING-US			English	Article						transformers; deep learning; therapeutic target discovery; aging biomarkers; human aging	PARATHYROID-HORMONE LEVELS; ARTIFICIAL-INTELLIGENCE; CENICRIVIROC; EXPRESSION; DATABASE	Target discovery is crucial for the development of innovative therapeutics and diagnostics. However, current approaches often face limitations in efficiency, specificity, and scalability, necessitating the exploration of novel strategies for identifying and validating disease-relevant targets. Advances in natural language processing have provided new avenues for predicting potential therapeutic targets for various diseases. Here, we present a novel approach for predicting therapeutic targets using a large language model (LLM). We trained a domain-specific BioGPT model on a large corpus of biomedical literature consisting of grant text and developed a pipeline for generating target prediction. Our study demonstrates that pre-training of the LLM model with task-specific texts improves its performance. Applying the developed pipeline, we retrieved prospective aging and age-related disease targets and showed that these proteins are in correspondence with the database data. Moreover, we propose CCR5 and PTH as potential novel dual-purpose anti-aging and disease targets which were not previously identified as age-related but were highly ranked in our approach. Overall, our work highlights the high potential of transformer models in novel target prediction and provides a roadmap for future integration of AI approaches for addressing the intricate challenges presented in the biomedical field.	[Zagirova, Diana; Pushkov, Stefan; Leung, Geoffrey Ho Duen; Liu, Bonnie Hei Man; Urban, Anatoly; Sidorenko, Denis; Kozlova, Ekaterina; Naumov, Vladimir; Pun, Frank W.; Ozerov, Ivan V.; Aliper, Alex; Zhavoronkov, Alex] Insilico Med Hong Kong Ltd, Hong Kong Sci & Technol Pk, Hong Kong, Peoples R China; [Kalashnikov, Aleksandr; Aliper, Alex; Zhavoronkov, Alex] Insilico Med AI Ltd, Level 6,Unit 08,Block A,IRENA HQ Bldg, Abu Dhabi, U Arab Emirates		Zhavoronkov, A (corresponding author), Insilico Med Hong Kong Ltd, Hong Kong Sci & Technol Pk, Hong Kong, Peoples R China.; Zhavoronkov, A (corresponding author), Insilico Med AI Ltd, Level 6,Unit 08,Block A,IRENA HQ Bldg, Abu Dhabi, U Arab Emirates.	alex@insilico.com						Aldinucci D, 2014, MEDIAT INFLAMM, V2014, DOI 10.1155/2014/292376; Andréasson C, 2019, EMBO REP, V20, DOI 10.15252/embr.201947865; Arabi A, 2012, OSTEOPOROSIS INT, V23, P971, DOI 10.1007/s00198-011-1659-1; BACZYNSKI R, 1985, KIDNEY INT, V28, P722, DOI 10.1038/ki.1985.190; Barardo D, 2017, AGING CELL, V16, P594, DOI 10.1111/acel.12585; Bergman E, 1999, J NEUROSCI RES, V57, P153, DOI 10.1002/(SICI)1097-4547(19990715)57:2<153::AID-JNR1>3.0.CO;2-A; Bird S., 2009, NATURAL LANGUAGE PRO; Cai YS, 2022, SCI CHINA LIFE SCI, V65, P2354, DOI 10.1007/s11427-022-2161-3; Chen KM, 2019, NAT METHODS, V16, P315, DOI 10.1038/s41592-019-0360-8; Chen L, 2020, SIGNAL TRANSDUCT TAR, V5, DOI 10.1038/s41392-020-0196-9; Cock PJA, 2009, BIOINFORMATICS, V25, P1422, DOI 10.1093/bioinformatics/btp163; Combadiere C, 1996, J LEUKOCYTE BIOL, V60, P147, DOI 10.1002/jlb.60.1.147; Fan L, 2023, A Bibliometric Review of Large Language Models Research from 2017 to 2023; FENG LL, 1995, J CLIN INVEST, V95, P1009, DOI 10.1172/JCI117745; Galkin F, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101199; Galkin F, 2020, AGEING RES REV, V60, DOI 10.1016/j.arr.2020.101050; Goltzman D, 2018, ENDOCRIN METAB CLIN, V47, P743, DOI 10.1016/j.ecl.2018.07.003; Gossage L, 2015, NAT REV CANCER, V15, P55, DOI 10.1038/nrc3844; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Guo J, 2022, SIGNAL TRANSDUCT TAR, V7, DOI 10.1038/s41392-022-01251-0; Hagberg A. A., 2008, Proc. of the 7th Python in Science Conf. (SciPy2008), P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003; Jiao XM, 2021, BREAST CANCER RES, V23, DOI 10.1186/s13058-021-01391-1; Jiao XM, 2019, CANCER RES, V79, P4801, DOI 10.1158/0008-5472.CAN-19-1167; Jin Q, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2567; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Kadurin A, 2017, MOL PHARMACEUT, V14, P3098, DOI 10.1021/acs.molpharmaceut.7b00346; Kandhaya-Pillai R, 2022, AGING CELL, V21, DOI 10.1111/acel.13646; Khan M., 2023, StatPearls; Kingma D. P., 2017, ARXIV; Li TW, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00209; Liberale L, 2021, EUR J CLIN INVEST, V51, DOI 10.1111/eci.13600; López-Otín C, 2013, CELL, V153, P1194, DOI 10.1016/j.cell.2013.05.039; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mamoshina P, 2018, J GERONTOL A-BIOL, V73, P1482, DOI 10.1093/gerona/gly005; Marino N, 2023, FRONT AGING-LAUSANNE, V4, DOI 10.3389/fragi.2023.1057204; Martin-Blondel G, 2016, NAT REV NEUROL, V12, P95, DOI 10.1038/nrneurol.2015.248; Mohamed H, 2022, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.816515; Moskalev A, 2015, AGING-US, V7, P616, DOI 10.18632/aging.100799; Narang S., Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer; Need AG, 2004, J CLIN ENDOCR METAB, V89, P1646, DOI 10.1210/jc.2003-031539; de Almeida AJPO, 2017, OXID MED CELL LONGEV, V2017, DOI 10.1155/2017/7941563; Povey S, 2001, HUM GENET, V109, P678, DOI 10.1007/s00439-001-0615-0; Pun FW, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.914017; Pun FW, 2022, AGING-US, V14, P2475, DOI 10.18632/aging.203960; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Ridley AJ, 2003, SCIENCE, V302, P1704, DOI 10.1126/science.1092053; Robbins PD, 2021, ANNU REV PHARMACOL, V61, P779, DOI 10.1146/annurev-pharmtox-050120-105018; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Salvatore D, 2021, NAT REV ENDOCRINOL, V17, P296, DOI 10.1038/s41574-021-00470-9; Tacke F, 2018, EXPERT OPIN INV DRUG, V27, P301, DOI 10.1080/13543784.2018.1442436; Tacutu R, 2018, NUCLEIC ACIDS RES, V46, pD1083, DOI 10.1093/nar/gkx1042; Tajar A, 2013, AGE AGEING, V42, P352, DOI 10.1093/ageing/afs162; Takahashi M, 2001, CYTOKINE GROWTH F R, V12, P361, DOI 10.1016/S1359-6101(01)00012-0; TANAKA Y, 1993, NATURE, V361, P79, DOI 10.1038/361079a0; Toson B, 2017, RHEUMATOLOGY, V56, P495, DOI 10.1093/rheumatology/kew398; Uhlen M, 2010, NAT BIOTECHNOL, V28, P1248, DOI 10.1038/nbt1210-1248; Vaswani A, 2017, ADV NEUR IN, V30; Vilone G, 2020, Arxiv, DOI [arXiv:2006.00093, DOI 10.48550/ARXIV.2006.00093]; Visser M, 2003, J CLIN ENDOCR METAB, V88, P5766, DOI 10.1210/jc.2003-030604; Wang B, 2021, A Systematic Survey, V1, P57; Waziry R, 2023, NATURE AGING, V3, P248, DOI 10.1038/s43587-022-00357-y; White Jacob, 2020, Medical Reference Services Quarterly, V39, P382, DOI 10.1080/02763869.2020.1826228; Wu MH, 2017, BIOTECHNOL BIOTEC EQ, V31, P1237, DOI 10.1080/13102818.2017.1371641; Ye XY, 2017, SCAND J GASTROENTERO, V52, P551, DOI 10.1080/00365521.2017.1281435; Yu DK, 2018, LIVER INT, V38, P1128, DOI 10.1111/liv.13698; Zhavoronkov A, 2021, NATURE AGING, V1, P5, DOI 10.1038/s43587-020-00020-4; Zhavoronkov A, 2019, AGING-US, V11, P10771, DOI 10.18632/aging.102475; Zhavoronkov A, 2019, NAT BIOTECHNOL, V37, P1038, DOI 10.1038/s41587-019-0224-x; Zhavoronkov A, 2019, TRENDS PHARMACOL SCI, V40, P546, DOI 10.1016/j.tips.2019.05.004; Zhavoronkov A, 2018, MOL PHARMACEUT, V15, P4311, DOI 10.1021/acs.molpharmaceut.8b00930; Zou JR, 2019, MOL MED REP, V19, P759, DOI 10.3892/mmr.2018.9712	72	2	2	10	25	IMPACT JOURNALS LLC	ORCHARD PARK	6666 E QUAKER ST, STE 1, ORCHARD PARK, NY 14127 USA	1945-4589			AGING-US	Aging-US	SEP 30	2023	15	18					9293	9309						17	Cell Biology; Geriatrics & Gerontology	Science Citation Index Expanded (SCI-EXPANDED)	Cell Biology; Geriatrics & Gerontology	U2TQ6	37742294	gold, Green Published			2024-07-03	WOS:001083382600007
C	Ahmed, T; Devanbu, P			IEEE	Ahmed, Toufique; Devanbu, Premkumar			Better patching using LLM prompting, <i>via</i> Self-Consistency	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		LLMs; Self-consistency; Program Repair		Large Language models (LLMs) can be induced to solve non-trivial problems with "few-shot" prompts including illustrative problem-solution examples. Now if the few-shots also include "chain of thought" (CoT) explanations, which are of the form problem-explanation-solution, LLMs will generate a "explained" solution, and perform even better. Recently an exciting, substantially better technique, self-consistency [1] (S-C) has emerged, based on the intuition that there are many plausible explanations for the right solution; when the LLM is sampled repeatedly to generate a pool of explanation-solution pairs, for a given problem, the most frequently occurring solutions in the pool (ignoring the explanations) tend to be even more likely to be correct! Unfortunately, the use of this highly-performant S-C (or even CoT) approach in software engineering settings is hampered by the lack of explanations; most software datasets lack explanations. In this paper, we describe an application of the S-C approach to program repair, using the commit log on the fix as the explanation, only in the illustrative few-shots. We achieve state-of-the art results, beating previous approaches to prompting-based program repair, on the MODIT dataset; we also find evidence suggesting that the correct commit messages are helping the LLM learn to produce better patches.	[Ahmed, Toufique; Devanbu, Premkumar] Univ Calif Davis, Davis, CA 95616 USA	University of California System; University of California Davis	Ahmed, T (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.	tfahmed@ucdavis.edu; ptdevanbu@ucdavis.edu			National Science Foundation [2107592]	National Science Foundation(National Science Foundation (NSF))	This material is based upon work supported by the National Science Foundation under Grant NSF CCF (SHF-MEDIUM) No. 2107592. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Ahmed T, 2024, Arxiv, DOI arXiv:2304.06815; Ahmed T, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559555; Bareiss P, 2022, Arxiv, DOI [arXiv:2206.01335, DOI 10.48550/ARXIV.2206.01335]; Berabi B, 2021, PR MACH LEARN RES, V139; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chakraborty Saikat, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P18, DOI 10.1145/3540250.3549162; Chakraborty S, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P443, DOI 10.1109/ASE51524.2021.9678559; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Lu Shuai, 35 C NEUR INF PROC S; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; Nashid N, 2023, PROC INT CONF SOFTW, P2450, DOI 10.1109/ICSE48619.2023.00205; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Ye H, 2022, PROC INT CONF SOFTW, P1506, DOI 10.1145/3510003.3510222; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955	27	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1742	1746		10.1109/ASE56229.2023.00065	http://dx.doi.org/10.1109/ASE56229.2023.00065			5	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200146
C	Chen, YD; Zhong, RQ; Zha, S; Karypis, G; He, H			Assoc Computat Linguist	Chen, Yanda; Zhong, Ruiqi; Zha, Sheng; Karypis, George; He, He			Meta-learning via Language Model In-context Tuning	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS)			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple				The goal of meta-learning is to learn to adapt to a new task with only a few labeled examples. Inspired by the recent progress in large language models, we propose in-context tuning (ICT), which recasts task adaptation and prediction as a simple sequence prediction problem: to form the input sequence, we concatenate the task instruction, labeled in-context examples, and the target input to predict; to meta-train the model to learn from in-context examples, we fine-tune a pre-trained language model (LM) to predict the target label given the input sequence on a collection of tasks. We benchmark our method on two collections of text classification tasks: LAMA and BinaryClfs. Compared to MAML which adapts the model through gradient descent, our method leverages the inductive bias of pre-trained LMs to perform pattern matching, and outperforms MAML by an absolute 6% average AUC-ROC score on BinaryClfs, gaining more advantage with increasing model size. Compared to non-fine-tuned in-context learning (i.e. prompting a raw LM), in-context tuning meta-trains the model to learn from in-context examples. On BinaryClfs, ICT improves the average AUC-ROC score by an absolute 10%, and reduces the variance due to example ordering by 6x and example choices by 2x.	[Chen, Yanda] Columbia Univ, New York, NY 10027 USA; [Zhong, Ruiqi] Univ Calif Berkeley, Berkeley, CA 94720 USA; [Chen, Yanda; Zha, Sheng; Karypis, George; He, He] AWS AI, Seattle, WA USA; [He, He] NYU, New York, NY 10003 USA	Columbia University; University of California System; University of California Berkeley; New York University	Chen, YD (corresponding author), Columbia Univ, New York, NY 10027 USA.	yc3384@columbia.edu; ruiqizhong@berkeley.edu; zhasheng@amazon.com; gkarypis@amazon.com; hehea@amazon.com	he, he/JPL-3505-2023; zhu, yujie/KBC-4009-2024					Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; Aghajanyan A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5799; Aharoni R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3874; [Anonymous], 2016, Building machines that learn and think like people; Antoniou A., 2019, INT C LEARNING REPRE; Bansal T., 2020, P 28 INT C COMP LING, P5108, DOI 10.18653/v1/2020.coling-main.448; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Deng SM, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P151, DOI 10.1145/3336191.3371796; Dou ZY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1192; Finn C, 2017, PR MACH LEARN RES, V70; Gao Tianyu, 2021, Making pre-trained language models better few-shot learners; Geng R., 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), P3895; Gu JT, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3622; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendrycks D, 2019, Arxiv, DOI arXiv:1903.12261; Holla N, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4517; Jiang Xiang, 2018, Attentive task-agnostic meta-learning for few-shot text classi~cation; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kaufmann M, 2023, Arxiv, DOI arXiv:1908.08016; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Lake B, 2018, PR MACH LEARN RES, V80; Lee CH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2261; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li Xiang Lisa, P 59 ANN M ASS COMPU, V1, P4582; Liu Jiachang, 2021, What makes good in-context examples for gpt-3?; Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487; Min Sewon, 2021, arXiv; Mishra Swaroop., Cross-task generalization via natu; Nikolaev D, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1159; Perez Ethan, 2021, True Few-Shot Learning with Language Models; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Poerner N, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P803; Qin G., 2021, NAACL, P5203, DOI [DOI 10.18653/V1/2021.NAACLMAIN.410, 10.18653/v1/2021.naacl-main.410, 10.18653/v1/2021.naaclmain.410]; Radford A., 2019, OpenAI Blog; Rajeswaran A, 2019, ADV NEUR IN, V32; Sagawa S, 2020, Arxiv, DOI arXiv:1911.08731; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Schick Timo, P 16 C EUR CHAPT ASS; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Suhr A., 2020, P 58 ANN M ASS COMPU, P8372; Vanschoren J, 2019, SPRING SER CHALLENGE, P35, DOI 10.1007/978-3-030-05318-5_2; Wang Sinong, 2020, arXiv preprint arXiv:2006.04768; Wei J., 2021, FINETUNED LANGUAGE M; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wortsman M, 2022, Arxiv, DOI arXiv:2109.01903; Ye Qinyuan, 2021, arXiv; Yu Mo, 2018, P 2018 C N AM CHAPT; Yu Philip., 2021, P 2021 C N AM CHAPTE, P1351; Zhao Tony Z., CALIBRATE USE IMPROV; Zhong Ruiqi, 2021, Adapting language models for zero-shot learning by meta-tuning on dataset and prompt collections	52	5	6	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-21-6				2022							719	730						12	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EM					2024-07-03	WOS:000828702300053
J	Fu, XY; Sanchez, TW; Li, CS; Junqueira, JR				Fu, Xinyu; Sanchez, Thomas W.; Li, Chaosu; Junqueira, Juliana Reu			Deciphering Public Voices in the Digital Era	JOURNAL OF THE AMERICAN PLANNING ASSOCIATION			English	Article; Early Access						ChatGPT; citizen engagement; natural language processing; public feedback; urban planning	PARTICIPATION	Problem, research strategy, and findingsPlanners are increasingly using online public engagement approaches to broaden their reach in communities. This results in substantial volumes of digital, text-based public feedback data, making it difficult to analyze efficiently and derive meaningful insights. We explored the use of the novel large language model (LLM), ChatGPT, in analyzing a public feedback data set collected via online submissions in Hamilton City (New Zealand) in response to a proposed local plan change. Specifically, we initially employed zero-shot prompts with ChatGPT for tasks like summarizing, topic identification, and sentiment analysis and compared the results with those obtained by human planners and two standard natural language processing (NLP) techniques: latent Dirichlet allocation (LDA) topic modeling and lexicon-based sentiment analysis. The findings show that zero-shot prompting effectively identified political stances (accuracy: 81.7%), reasons (87.3%), decisions sought (85.8%), and associated sentiments (94.1%). Although subject to several limitations, ChatGPT demonstrates promise in automating the analysis of public feedback, offering substantial time and cost savings. In addition, few-shot prompting enhanced performance in more complex tasks, such as topic identification involving planning jargon. We also provide insights for urban planners to better harness the power of ChatGPT to analyze citizen feedback.Takeaway for practiceChatGPT presents a transformative opportunity for planners, particularly those dealing with growing volumes of public feedback data. However, it cannot be entirely relied upon. Planners must be mindful of ChatGPT's limitations, including its sensitivity to prompt phrasing, inherent biases from training data, tendency to overgeneralize, and occasional omission of nuanced details. To enhance accuracy, planners should prescreen data for consistency, provide clear and iteratively tested prompts, use few-shot prompts for complex analysis, and explore various combinations of prompting strategies to develop an effective local approach. It is also crucial to ensure human review of the results.	[Fu, Xinyu] Univ Waikato, Hamilton, New Zealand; [Sanchez, Thomas W.] Texas A&M Univ, College Stn, TX USA; [Li, Chaosu] Hong Kong Univ Sci & Technol, Div Publ Policy, Hong Kong, Peoples R China; Hamilton City Council, Hamilton, New Zealand	University of Waikato; Texas A&M University System; Texas A&M University College Station; Hong Kong University of Science & Technology	Fu, XY (corresponding author), Univ Waikato, Hamilton, New Zealand.	xinyu.fu@waikato.ac.nz; twsanchez@tamu.edu; chaosuli@ust.hk; juliana.reujunqueira@hcc.govt.nz	Fu, Xinyu/ABA-6804-2020; Sanchez, Thomas W/D-5093-2012	Fu, Xinyu/0000-0002-3591-4158; 				Aigwi IE, 2019, SUSTAIN CITIES SOC, V48, DOI 10.1016/j.scs.2019.101547; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; ARNSTEIN SR, 1969, J AM I PLANNERS, V35, P216, DOI 10.1080/01944366908977225; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Brinkley C, 2024, J PLAN EDUC RES, V44, P632, DOI [10.1177/0739456x21995890, 10.1177/0739456X21995890]; Cai M, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e06322; Clark JK, 2021, AM REV PUBLIC ADM, V51, P199, DOI 10.1177/0275074020956397; DAVIDOFF P, 1965, J AM I PLANNERS, V31, P331, DOI 10.1080/01944366508978187; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Ertiö TP, 2017, INT J INFORM MANAGE, V37, P111, DOI 10.1016/j.ijinfomgt.2017.01.001; Foroughi M, 2023, CITIES, V135, DOI 10.1016/j.cities.2023.104235; Fredericks J, 2013, AUST PLAN, V50, P244, DOI 10.1080/07293682.2012.748083; Fu XY, 2024, J PLAN LIT, DOI 10.1177/08854122241229571; Fu XY, 2023, J AM PLANN ASSOC, DOI 10.1080/01944363.2023.2271893; Fu XY, 2023, J AM PLANN ASSOC, V89, P107, DOI 10.1080/01944363.2022.2038659; Fung A, 2001, POLIT SOC, V29, P5, DOI 10.1177/0032329201029001002; Haklay M, 2018, QUAEST GEOGR, V37, P127, DOI 10.2478/quageo-2018-0030; Hamilton City Council, 2023, Plan change 12-Enabling housing supply; Hamilton City Council, 2024, Plan change 12-Enabling housing supply; Han AT, 2023, ENVIRON PLAN B-URBAN, V50, P416, DOI 10.1177/23998083221118003; Han AT, 2021, J AM PLANN ASSOC, V87, P211, DOI 10.1080/01944363.2020.1831401; Healey P., 1997, Collaborative planning: Shaping places in a fragmented society; Huai SY, 2023, URBAN FOR URBAN GREE, V81, DOI 10.1016/j.ufug.2023.127869; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Innes Judith, 2004, PLANNING THEORY PRAC, V5, P419, DOI DOI 10.1080/1464935042000293170; Khoo CSG, 2018, J INF SCI, V44, P491, DOI 10.1177/0165551517703514; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kim B, 2021, CITIES, V108, DOI 10.1016/j.cities.2020.102941; Kong LQ, 2022, LANDSCAPE URBAN PLAN, V226, DOI 10.1016/j.landurbplan.2022.104482; Krizek K, 2009, PLAN THEORY PRACT, V10, P459, DOI 10.1080/14649350903417241; Laskey AB, 2019, J AM PLANN ASSOC, V85, P348, DOI 10.1080/01944363.2019.1618729; Lock O, 2020, GEO-SPAT INF SCI, V23, P275, DOI 10.1080/10095020.2020.1815596; Ministry for the Environment, 2021, Resource management (enabling housing supply and other matters) amendment act 2021; Ministry for the Environment, 2021, Building competitive cities: Reform of the urban and infrastructure planning system-A technical working paper; Ministry for the Environment, 2022, National Policy Statement on Urban Development 2020; Mleczko M, 2023, URBAN STUD, V60, P2564, DOI 10.1177/00420980231156352; OpenAI, 2023, New models and developer products announced at devday; Quick KS, 2011, J PLAN EDUC RES, V31, P272, DOI 10.1177/0739456X11410979; Ramage D., 2009, NIPS 2009 WORKSH APP, Vvol. 5, P1; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sanchez T., 2023, Planning with Artificial Intelligence; Sanchez T. W., 2013, Citizen e-participation in urban governance: Crowdsourcing and collaborative creativity, P35; Shipley R, 2012, J PLAN LIT, V27, P22, DOI 10.1177/0885412211413133; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; van der Hoeven A, 2020, SPACE CULT, V23, P129, DOI 10.1177/1206331218797038; Wilson A, 2019, ENVIRON PLAN B-URBAN, V46, P286, DOI 10.1177/2399808317712515; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Yu T, 2019, J CLEAN PROD, V212, P537, DOI 10.1016/j.jclepro.2018.12.071; Zhai W, 2020, INT J DISAST RISK RE, V48, DOI 10.1016/j.ijdrr.2020.101611; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	51	1	1	12	12	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0194-4363	1939-0130		J AM PLANN ASSOC	J. Am. Plan. Assoc.	2024 MAR 20	2024										10.1080/01944363.2024.2309259	http://dx.doi.org/10.1080/01944363.2024.2309259		MAR 2024	14	Regional & Urban Planning; Urban Studies	Social Science Citation Index (SSCI)	Public Administration; Urban Studies	LV1Y9		Green Submitted, hybrid			2024-07-03	WOS:001189496500001
J	Spennemann, DHR				Spennemann, Dirk H. R.			Will Artificial Intelligence Affect How Cultural Heritage Will Be Managed in the Future? Responses Generated by Four genAI Models	HERITAGE			English	Article						artificial intelligence; cultural heritage studies; futures studies; strategic foresight	CLASSIFICATION; RECONSTRUCTION; IDENTIFICATION; REALITY; FUSION; EARTH; CITY	Generative artificial intelligence (genAI) language models have become firmly embedded in public consciousness. Their abilities to extract and summarise information from a wide range of sources in their training data have attracted the attention of many scholars. This paper examines how four genAI large language models (ChatGPT, GPT4, DeepAI, and Google Bard) responded to prompts, asking (i) whether artificial intelligence would affect how cultural heritage will be managed in the future (with examples requested) and (ii) what dangers might emerge when relying heavily on genAI to guide cultural heritage professionals in their actions. The genAI systems provided a range of examples, commonly drawing on and extending the status quo. Without a doubt, AI tools will revolutionise the execution of repetitive and mundane tasks, such as the classification of some classes of artifacts, or allow for the predictive modelling of the decay of objects. Important examples were used to assess the purported power of genAI tools to extract, aggregate, and synthesize large volumes of data from multiple sources, as well as their ability to recognise patterns and connections that people may miss. An inherent risk in the 'results' presented by genAI systems is that the presented connections are 'artifacts' of the system rather than being genuine. Since present genAI tools are unable to purposively generate creative or innovative thoughts, it is left to the reader to determine whether any text that is provided by genAI that is out of the ordinary is meaningful or nonsensical. Additional risks identified by the genAI systems were that some cultural heritage professionals might use AI systems without the required level of AI literacy and that overreliance on genAI systems might lead to a deskilling of general heritage practitioners.	[Spennemann, Dirk H. R.] Charles Sturt Univ, Gulbali Inst, POB 789, Albury, NSW 2640, Australia	Charles Sturt University	Spennemann, DHR (corresponding author), Charles Sturt Univ, Gulbali Inst, POB 789, Albury, NSW 2640, Australia.	dspennemann@csu.edu.au		Spennemann, Dirk/0000-0003-2639-7950				Agapiou A, 2023, HERITAGE-BASEL, V6, P4072, DOI 10.3390/heritage6050214; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amakawa J, 2018, INT J HERIT STUD, V24, P315, DOI 10.1080/13527258.2017.1378909; Anglisano A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141811214; Anichini F., 2020, Internet Archaeology, V52; Anichini F, 2021, J ARCHAEOL SCI-REP, V36, DOI 10.1016/j.jasrep.2020.102788; Aoulalay A., 2020, P 2020 IEEE 2 INT C, P1; Argyrou A, 2023, DRONES-BASEL, V7, DOI 10.3390/drones7090578; Aslan S, 2020, PATTERN RECOGN LETT, V131, P158, DOI 10.1016/j.patrec.2019.12.007; Assael Y, 2022, NATURE, V603, P280, DOI 10.1038/s41586-022-04448-z; Babl FE, 2023, EMERG MED AUSTRALAS, V35, P809, DOI 10.1111/1742-6723.14233; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; bard.google.com, Google Bard FAQ; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bickler S.H., 2018, Archaeol. New Zealand, V61, P48; Bickler S.H., 2018, Archaeology, V20, P20; bing.com, Microsoft Bing Chat Enterprise; León RB, 2023, J ADV INFORM TECHNOL, V14, P788, DOI 10.12720/jait.14.4.788-795; Boyko J, 2023, Arxiv, DOI arXiv:2311.04929; Byeon W, 2019, J COMPUT SCI-NETH, V32, P36, DOI 10.1016/j.jocs.2019.02.005; Cardarelli L, 2022, J ARCHAEOL SCI, V144, DOI 10.1016/j.jas.2022.105640; Chammas M, 2022, MULTIMED TOOLS APPL, V81, P30769, DOI 10.1007/s11042-022-12673-x; Chang KK, 2023, Arxiv, DOI arXiv:2305.00118; Chesterman S, 2024, POLICY SOC, DOI 10.1093/polsoc/puae006; Chetouani A, 2020, PATTERN RECOGN LETT, V131, P1, DOI 10.1016/j.patrec.2019.12.009; Cintas C, 2020, J CULT HERIT, V41, P106, DOI 10.1016/j.culher.2019.06.005; Collins E, Our Breakthrough Conversation Technology; Comes R, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168131; Cuéllar A, 2023, HIPOGRIFO, V11, P101, DOI 10.13035/H.2023.11.01.08; Deacon H, 2013, HERIT SOC, V6, P129, DOI 10.1179/2159032X13Z.0000000009; deepai.org, DeepAi DeepAi; Domínguez-Rodrigo M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-75994-7; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Erdem B, 2012, CURRENT ISSUES IN HOSPITALITY AND TOURISM RESEARCH AND INNOVATIONS, P213; Ferrara E, 2024, Arxiv, DOI [arXiv:2310.00737, 10.2139/ssrn.4614223]; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Flensted T., The Complete ChatGPT Language List; Frackiewicz M, ChatGPT-4 for Digital Archaeology: AI-Powered Artifact Discovery and Analysis; Fu XM, 2022, ISPRS INT J GEO-INF, V11, DOI 10.3390/ijgi11010045; Google Arts & Culture Fabricius, About us; google.com, Google Google Bard Version 2023.07.13; Graham D., 2023, Qeios, DOI [10.32388/JPECON, DOI 10.32388/JPECON]; Griffin G, 2023, AI SOC, DOI 10.1007/s00146-023-01689-y; Gross N, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12080435; Guidi T, 2023, ALGORITHMS, V16, DOI 10.3390/a16020079; Head C., 2023, New Directions for Evaluation, V2023, P33, DOI DOI 10.1002/EV.20556; Hines Andy., 2006, Thinking About the Future: Guidelines for Strategic Foresight; Hiter S, Generative AI Ethics: Concerns and Solutions; Hua SY, 2024, DATA INTELLIGENCE, V6, P201, DOI 10.1162/dint_a_00243; Inayatullah S., 2004, J. Futures Stud, V9, P83; Jiang Dengpan, 2022, 2022 International Conference on 3D Immersion, Interaction and Multi-sensory Experiences (ICDIIME), P65, DOI 10.1109/ICDIIME56946.2022.00022; Jigyasu N, 2022, J CULT HERIT MANAG S, DOI 10.1108/JCHMSD-07-2022-0116; Kamran A., 2023, RMS J; Katz R, 2015, INT J CULTURAL STUD, V18, P155, DOI 10.1177/1367877914554539; Korsten B., The Next Rembrandt; Koutsoudis A, 2007, J CULT HERIT, V8, P26, DOI 10.1016/j.culher.2006.08.003; Kuck K., 2023, P 2023 WORLD ENG ED, P1; Kuntitan P., 2022, Curr. Appl. Sci. Technol, V22, P1, DOI [10.55003/cast.2022.02.22.002, DOI 10.55003/CAST.2022.02.22.002]; Labadi Sophia., 2013, UNESCO CULTURAL HERI; Locaputo A., 2023, P CEUR WORKSHOP P, P68; Lucchi N, 2023, EUR J RISK REGUL, DOI 10.1017/err.2023.59; Maietti F., 2022, Cultural Leadership in Transition Tourism: Developing Innovative and Sustainable Models, P139; Makhortykh M., 2023, Discover Artificial Intelligence, V3, P28; Manyika James, 2023, An Overview of Bard: An Early Experiment with Generative AI; Marchant Jo, 2023, Nature, DOI 10.1038/d41586-023-03212-1; Marcinowski M, 2023, AUST J FORENSIC SCI, V55, P745, DOI 10.1080/00450618.2022.2079722; Marie I, 2005, J ARCHAEOL SCI, V32, P1527, DOI 10.1016/j.jas.2005.04.011; Markov T., New and Improved Content Moderation Tooling; Mbalaka B., 2023, Digital Transformation and Society, V2, P376, DOI [10.1108/DTS-01-2023-0003, DOI 10.1108/DTS-01-2023-0003]; McGee R. W., 2023, Is ChatGPT biased against conservatives? An empirical study, DOI DOI 10.2139/SSRN.4359405; Merritt E, Chatting about Museums with ChatGPT; Messner W, 2023, Arxiv, DOI arXiv:2312.17256; Milic RJ, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142416432; Neumuller Moritz, 2014, 3D Research Challenges in Cultural Heritage. A Roadmap in Digital Heritage Preservation: LNCS 8355, P119, DOI 10.1007/978-3-662-44630-0_9; OpenAI, How ChatGPT and Our Language Models Are Developed; openai.com, OpenAI ChatGPT 3.5; Ostertag C, 2020, PATTERN RECOGN LETT, V131, P336, DOI 10.1016/j.patrec.2020.01.012; Paradis K., 2023, J. Inf. Ethics, V32, P70; Plecher DA, 2020, ADJUNCT PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2020), P326, DOI 10.1109/ISMAR-Adjunct51615.2020.00092; Popova D, 2023, DIGIT PRESENT PRESER, V13, P117; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reisner A., 2023, Atlantic; Roueché C, 2022, NATURE, V603, P235, DOI 10.1038/d41586-022-00641-2; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Sanders D.H., 2018, P 2018 3 DIGITAL HER, P1; Shaus A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237962; Shi M, The ethics of generative AI: How we can harness this powerful technology; Sizyakin R., 2021, P 14 INT C MACHINE V, P422; Spennemann D.H.R., 2023, Preprint, P1, DOI [10.20944/preprints202308.1271.v1, DOI 10.20944/PREPRINTS202308.1271.V1]; Spennemann D.H.R., 2023, Knowledge, V18, P480, DOI 10.3390/knowledge3030032; Spennemann DHR, 2023, Preprints, DOI [10.20944/preprints202309.1528.v1, 10.20944/preprints202309.1528.v1, DOI 10.20944/PREPRINTS202309.1528.V1]; Spennemann DHR, 2023, PUBLICATIONS, V11, DOI 10.3390/publications11030045; Spennemann DHR, 2023, Arxiv, DOI [arXiv:2308.03301, 10.48550/arXiv.2308.03301, DOI 10.48550/ARXIV.2308.03301]; Spennemann DHR, 2023, HERITAGE-BASEL, V6, P5732, DOI 10.3390/heritage6080302; Spennemann DHR, 2022, HERITAGE-BASEL, V5, P2007, DOI 10.3390/heritage5030105; Sutton RA, 2011, KOREAN STUD, V35, P4, DOI 10.1353/ks.2011.0011; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Trichopoulos G, 2023, 2ND INTERNATIONAL CONFERENCE OF THE GREECE ACM SIGCHI CHAPTER, CHIGREECE 2023, DOI 10.1145/3609987.3610018; Trichopoulos G, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12183829; Trichopoulos G, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7030148; Tschirschwitz F, 2019, PFG-J PHOTOGRAMM REM, V87, P47, DOI 10.1007/s41064-019-00065-0; Van Duijne F., 2018, Introduction to Strategic Foresight, VVolume 1, P67; Vaughan-Nichols S, GPT-3.5 vs GPT-4: Is ChatGPT Plus Worth Its Subscription Fee?	105	0	0	12	12	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2571-9408			HERITAGE-BASEL	Heritage	MAR	2024	7	3					1453	1471		10.3390/heritage7030070	http://dx.doi.org/10.3390/heritage7030070			19	Humanities, Multidisciplinary; Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Arts & Humanities - Other Topics; Science & Technology - Other Topics	MH4N9		gold			2024-07-03	WOS:001192721900001
J	Fink, MA; Bischoff, A; Fink, CA; Moll, M; Kroschke, J; Dulz, L; Heussel, CP; Kauczor, HU; Weber, TF				Fink, Matthias A.; Bischoff, Arved; Fink, Christoph A.; Moll, Martin; Kroschke, Jonas; Dulz, Luca; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.			Potential of ChatGPT and GPT-4 for Data Mining of Free-Text CT Reports on Lung Cancer	RADIOLOGY			English	Article								Background: The latest large language models (LLMs) solve unseen problems via user-defined text prompts without the need for retraining, offering potentially more efficient information extraction from free-text medical records than manual annotation. Purpose: To compare the performance of the LLMs ChatGPT and GPT-4 in data mining and labeling oncologic phenotypes from free-text CT reports on lung cancer by using user-defined prompts. Materials and Methods: This retrospective study included patients who underwent lung cancer follow-up CT between September 2021 and March 2023. A subset of 25 reports was reserved for prompt engineering to instruct the LLMs in extracting lesion diameters, labeling metastatic disease, and assessing oncologic progression. This output was fed into a rule-based natural language processing pipeline to match ground truth annotations from four radiologists and derive performance metrics. The oncologic reasoning of LLMs was rated on a five-point Likert scale for factual correctness and accuracy. The occurrence of confabulations was recorded. Statistical analyses included Wilcoxon signed rank and McNemar tests. Results: On 424 CT reports from 424 patients (mean age, 65 years +/- 11 [SD]; 265 male), GPT-4 outperformed ChatGPT in extracting lesion parameters (98.6% vs 84.0%, P <.001), resulting in 96% correctly mined reports (vs 67% for ChatGPT, P <.001). GPT-4 achieved higher accuracy in identification of metastatic disease (98.1% [95% CI: 97.7, 98.5] vs 90.3% [95% CI: 89.4, 91.0]) and higher performance in generating correct labels for oncologic progression (F1 score, 0.96 [95% CI: 0.94, 0.98] vs 0.91 [95% CI: 0.89, 0.94]) (both P <.001). In oncologic reasoning, GPT-4 had higher Likert scale scores for factual correctness (4.3 vs 3.9) and accuracy (4.4 vs 3.3), with a lower rate of confabulation (1.7% vs 13.7%) than ChatGPT (all P <.001). Conclusion: When using user-defined prompts, GPT-4 outperformed ChatGPT in extracting oncologic phenotypes from free-text CT reports on lung cancer and demonstrated better oncologic reasoning with fewer confabulations. (c) RSNA, 2023	[Fink, Matthias A.; Bischoff, Arved; Moll, Martin; Kroschke, Jonas; Dulz, Luca; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.] Univ Hosp Heidelberg, Clin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany; [Fink, Christoph A.] Univ Hosp Heidelberg, Dept Radiat Oncol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany; [Fink, Matthias A.; Bischoff, Arved; Dulz, Luca; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.] Translat Lung Res Ctr Heidelberg, Heidelberg, Germany; [Fink, Matthias A.; Bischoff, Arved; Dulz, Luca; Heussel, Claus Peter; Kauczor, Hans-Ulrich; Weber, Tim F.] German Ctr Lung Res, Heidelberg, Germany; [Heussel, Claus Peter] Heidelberg Univ, Dept Diagnost & Intervent Radiol Nucl Med, Heidelberg Thorac Clin, Heidelberg, Germany	Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg	Fink, MA (corresponding author), Univ Hosp Heidelberg, Clin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany.; Fink, MA (corresponding author), Translat Lung Res Ctr Heidelberg, Heidelberg, Germany.; Fink, MA (corresponding author), German Ctr Lung Res, Heidelberg, Germany.	matthias.fink@uni-heidelberg.de	Fink, Matthias/HNC-1848-2023	Fink, Matthias/0000-0002-0189-7070; Weber, Tim Frederik/0000-0001-5911-123X; Kroschke, Jonas/0000-0003-1225-3016				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bozkurt S, 2019, J DIGIT IMAGING, V32, P544, DOI 10.1007/s10278-019-00237-9; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; cancerresearchuk, 2015, Lung cancer incidence statistics; ChatGPT, OpenAI; Chen Ting, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.10852; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Do RKG, 2021, RADIOLOGY, V301, P115, DOI 10.1148/radiol.2021210043; Fink MA, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220055; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, GPT-4 (March 23 version); openai, INTR CHATGPT; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Riihimäki M, 2014, LUNG CANCER, V86, P78, DOI 10.1016/j.lungcan.2014.07.020; Savova GK, 2019, CANCER RES, V79, P5463, DOI 10.1158/0008-5472.CAN-19-0579; Tu ZZ, 2022, LECT NOTES COMPUT SC, V13684, P459, DOI 10.1007/978-3-031-20053-3_27; Yamashita R, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210092; Yim WW, 2016, JAMA ONCOL, V2, P797, DOI 10.1001/jamaoncol.2016.0213; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	30	22	22	15	23	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	SEP	2023	308	3							e231362	10.1148/radiol.231362	http://dx.doi.org/10.1148/radiol.231362			9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	FS1D7	37724963				2024-07-03	WOS:001147743800016
J	Chen, Y; Esmaeilzadeh, P				Chen, Yan; Esmaeilzadeh, Pouyan			Generative AI in Medical Practice: In-Depth Exploration of Privacy and Security Challenges	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						artificial intelligence; AI; generative artificial intelligence; generative AI; medical practices; potential benefits; security and privacy threats	HEALTH RECORDS; SYNTHETIC DATA; ATTACKS; MODELS	As advances in artificial intelligence (AI) continue to transform and revolutionize the field of medicine, understanding the potential uses of generative AI in health care becomes increasingly important. Generative AI, including models such as generative adversarial networks and large language models, shows promise in transforming medical diagnostics, research, treatment planning, and patient care. However, these data -intensive systems pose new threats to protected health information. This Viewpoint paper aims to explore various categories of generative AI in health care, including medical diagnostics, drug discovery, virtual health assistants, medical research, and clinical decision support, while identifying security and privacy threats within each phase of the life cycle of such systems (ie, data collection, model development, and implementation phases). The objectives of this study were to analyze the current state of generative AI in health care, identify opportunities and privacy and security challenges posed by integrating these technologies into existing health care infrastructure, and propose strategies for mitigating security and privacy risks. This study highlights the importance of addressing the security and privacy threats associated with generative AI in health care to ensure the safe and effective use of these systems. The findings of this study can inform the development of future generative AI systems in health care and help health care organizations better understand the potential benefits and risks associated with these systems. By examining the use cases and benefits of generative AI across diverse domains within health care, this paper contributes to theoretical discussions surrounding AI ethics, security vulnerabilities, and data privacy regulations. In addition, this study provides practical insights for stakeholders looking to adopt generative AI solutions within their organizations.	[Chen, Yan; Esmaeilzadeh, Pouyan] Florida Int Univ, Coll Business, Dept Informat Syst & Business Analyt, Modesto A Maidique Campus,1200 SW 8th St,RB 261 B, Miami, FL 33199 USA	State University System of Florida; Florida International University	Esmaeilzadeh, P (corresponding author), Florida Int Univ, Coll Business, Dept Informat Syst & Business Analyt, Modesto A Maidique Campus,1200 SW 8th St,RB 261 B, Miami, FL 33199 USA.	pesmaeil@fiu.edu		Esmaeilzadeh, Pouyan/0000-0002-3885-8112; Chen, Yan/0000-0001-9212-3566				Abadir PM, 2023, NATURE AGING, V3, P629, DOI 10.1038/s43587-023-00430-0; Ahmad K, 2022, COMPUT SCI REV, V43, DOI 10.1016/j.cosrev.2021.100452; Albahri AS, 2023, INFORM FUSION, V96, P156, DOI 10.1016/j.inffus.2023.03.008; Ali M, 2023, IEEE J BIOMED HEALTH, V27, P778, DOI 10.1109/JBHI.2022.3181823; Alqahtani H, 2021, ARCH COMPUT METHOD E, V28, P525, DOI 10.1007/s11831-019-09388-y; [Anonymous], The legal issues presented by generative AI; [Anonymous], Synthetic data is enabling better healthcare tools-here's how; [Anonymous], 2023, EU AI Act: first regulation on artificial intelligence; [Anonymous], 2023, Artificial Intelligence Risk Management Framework (AIRMF1.0), DOI [10.6028/NIST.AI.100-1, DOI 10.6028/NIST.AI.100-1]; [Anonymous], BLUEPR AI BILL RIGHT; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Bale AS, 2023, Int J Intell Syst Appl Eng, V12, P697; Bohr A., 2020, Artificial Intelligence in Healthcare; Brown Hannah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2280, DOI 10.1145/3531146.3534642; Byrne DW, 2022, Artificial Intelligence for Improved Patient Outcomes: Principles for Moving Forward with Rigorous Science; Cai ZP, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459992; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chen CS, 2012, SOC BEHAV PERSONAL, V40, P639, DOI 10.2224/sbp.2012.40.4.639; Chen DF, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P343, DOI 10.1145/3372297.3417238; Chen RJ, 2021, NAT BIOMED ENG, V5, P493, DOI 10.1038/s41551-021-00751-8; Chen Y, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2020.103394; Choi E, 2017, P 2017 MACH LEARN HL, P1; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Ellis RJ, 2022, Intelligence-Based Medicine, V6, DOI [DOI 10.1016/J.IBMED.2022.100068, 10.1016/j.ibmed.2022.100068]; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fernandes M, 2023, ADV COMPUT, V129, P39, DOI 10.1016/bs.adcom.2022.08.009; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Fui-Hoon Nah F, 2023, J. Inf. Technol. Case Appl. Res, V25, P277, DOI [DOI 10.1080/15228053.2023.2233814, 10.1080/15228053.2023.2233814]; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Gesk TS, 2022, GOV INFORM Q, V39, DOI 10.1016/j.giq.2022.101704; Ghosheh GO, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3636424; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Han C, 2019, IEEE ACCESS, V7, P156966, DOI 10.1109/ACCESS.2019.2947606; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hernandez M, 2022, NEUROCOMPUTING, V493, P28, DOI 10.1016/j.neucom.2022.04.053; Hu YP, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3487890; Huang C, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19120656; Jain S, 2022, J INTELL MANUF, V33, P1007, DOI 10.1007/s10845-020-01710-x; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100105; Jiang S, 2022, J MECH DESIGN, V144, DOI 10.1115/1.4051681; Khan S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/9985933; Kim BN, 2021, IEEE T MED IMAGING, V40, P1737, DOI 10.1109/TMI.2021.3065727; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lankton NK, 2015, J ASSOC INF SYST, V16, P880, DOI 10.17705/1jais.00411; Learned K, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0096-4; Lee D, 2020, J AM MED INFORM ASSN, V27, P1411, DOI 10.1093/jamia/ocaa119; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li X., 2021, Discover Artificial Intelligence, V1, P5, DOI DOI 10.1007/S44163-021-00006-0; Liu Q, 2018, IEEE ACCESS, V6, P12103, DOI 10.1109/ACCESS.2018.2805680; Lu TK, 2009, NAT BIOTECHNOL, V27, P1139, DOI 10.1038/nbt.1591; Mahmood F, 2018, IEEE T MED IMAGING, V37, P2572, DOI 10.1109/TMI.2018.2842767; Martín-Noguerol T, 2023, EUR J RADIOL, V161, DOI 10.1016/j.ejrad.2023.110726; Martinelli DD, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105403; Mattioli J, 2023, P SAFE AI 2023 AAAIS; Matwin S, 2015, Advanced Research in Data Privacy; McCoy LG, 2022, J CLIN EPIDEMIOL, V142, P252, DOI 10.1016/j.jclinepi.2021.11.001; Mcknight D. H., 2011, ACM Transactions on Management Information Systems, V2, p12:1, DOI [10.1145/1985347.1985353, DOI 10.1145/1985347.1985353]; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Mopuri KR, 2018, LECT NOTES COMPUT SC, V11213, P20, DOI 10.1007/978-3-030-01240-3_2; Mosqueira-Rey E, 2023, ARTIF INTELL REV, V56, P3005, DOI 10.1007/s10462-022-10246-w; Nasr M, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P634, DOI 10.1145/3243734.3243855; Noorbakhsh-Sabet N, 2019, AM J MED, V132, P795, DOI 10.1016/j.amjmed.2019.01.017; Nova K., 2023, J Adv Anal Healthc Manag, V7, P115; Park Y., 2016, P 10 USENIX WORKSH O, P1; Paul D, 2020, DRUG DISCOV TODAY, V26, P80, DOI 10.1016/j.drudis.2020.10.010; Quiring E, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P1363; Rane N., 2023, Challenges Oppor. Ind, V4, P4603234, DOI [10.2139/ssrn.4603234, DOI 10.2139/SSRN.4603234]; Reichman Benjamin, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P266, DOI 10.1007/978-3-030-68763-2_20; Shafahi A, 2018, ADV NEUR IN, V31; Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41; Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687; Shoukry Y, 2013, LECT NOTES COMPUT SC, V8086, P55, DOI 10.1007/978-3-642-40349-1_4; Song Y, 2018, Arxiv, DOI arXiv:1710.10766; Summerfield C., 2022, NATURAL GEN INTELLIG; Sun H, 2023, IEEE T KNOWL DATA EN, V35, P3367, DOI 10.1109/TKDE.2021.3130903; Tang X, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12112437; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Topol Eric J, 2023, Science, V381, padk6139, DOI 10.1126/science.adk6139; Tripathy A, 2019, ANN ALLERTON CONF, P495, DOI [10.1109/ALLERTON.2019.8919758, 10.1109/allerton.2019.8919758]; Tseng BW, 2020, IEEE T INF FOREN SEC, V15, P2499, DOI 10.1109/TIFS.2020.2968188; van Bussel MJP, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-08189-7; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang Z, 2020, P IEEE CVF C COMPUTE, P8916, DOI 10.1109/CVPR42600.2020.00894; Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/infocom.2019.8737416, 10.1109/INFOCOM.2019.8737416]; Xiao QX, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P443; Xie Qianqian, 2023, Res Sq, DOI 10.21203/rs.3.rs-3661764/v1; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yale A, 2020, NEUROCOMPUTING, V416, P244, DOI 10.1016/j.neucom.2019.12.136; Zeng XX, 2022, CELL REP MED, V3, DOI 10.1016/j.xcrm.2022.100794; Zhang P, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15090286	91	2	2	41	41	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAR 8	2024	26								e53008	10.2024/1/e53008	http://dx.doi.org/10.2024/1/e53008			19	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	LI4B4	38457208				2024-07-03	WOS:001186136400004
J	Ostrowska, M; Kacala, P; Onolememen, D; Vaughan-Lane, K; Joseph, AS; Ostrowski, A; Pietruszewska, W; Banaszewski, J; Wróbel, MJ				Ostrowska, Magdalena; Kacala, Paulina; Onolememen, Deborah; Vaughan-Lane, Katie; Sisily Joseph, Anitta; Ostrowski, Adam; Pietruszewska, Wioletta; Banaszewski, Jacek; Wrobel, Maciej J.			To trust or not to trust: evaluating the reliability and safety of AI responses to laryngeal cancer queries	EUROPEAN ARCHIVES OF OTO-RHINO-LARYNGOLOGY			English	Article; Early Access						Artificial intelligence; ChatGPT; Bard; Laryngeal cancer; Oncology; Patient education	INFORMATION	Purpose As online health information-seeking surges, concerns mount over the quality and safety of accessible content, potentially leading to patient harm through misinformation. On one hand, the emergence of Artificial Intelligence (AI) in healthcare could prevent it; on the other hand, questions raise regarding the quality and safety of the medical information provided. As laryngeal cancer is a prevalent head and neck malignancy, this study aims to evaluate the utility and safety of three large language models (LLMs) as sources of patient information about laryngeal cancer.Methods A cross-sectional study was conducted using three LLMs (ChatGPT 3.5, ChatGPT 4.0, and Bard). A questionnaire comprising 36 inquiries about laryngeal cancer was categorised into diagnosis (11 questions), treatment (9 questions), novelties and upcoming treatments (4 questions), controversies (8 questions), and sources of information (4 questions). The population of reviewers consisted of 3 groups, including ENT specialists, junior physicians, and non-medicals, who graded the responses. Each physician evaluated each question twice for each model, while non-medicals only once. Everyone was blinded to the model type, and the question order was shuffled. Outcome evaluations were based on a safety score (1-3) and a Global Quality Score (GQS, 1-5). Results were compared between LLMs. The study included iterative assessments and statistical validations.Results Analysis revealed that ChatGPT 3.5 scored highest in both safety (mean: 2.70) and GQS (mean: 3.95). ChatGPT 4.0 and Bard had lower safety scores of 2.56 and 2.42, respectively, with corresponding quality scores of 3.65 and 3.38. Inter-rater reliability was consistent, with less than 3% discrepancy. About 4.2% of responses fell into the lowest safety category (1), particularly in the novelty category. Non-medical reviewers' quality assessments correlated moderately (r = 0.67) with response length.Conclusions LLMs can be valuable resources for patients seeking information on laryngeal cancer. ChatGPT 3.5 provided the most reliable and safe responses among the models evaluated.	[Ostrowska, Magdalena; Wrobel, Maciej J.] Nicolaus Copernicus Univ Torun, Dept Otolaryngol & Laryngol Oncol, Coll Med, Ul Marie Sklodowskiej Curie 9, PL-85094 Bydgoszcz, Poland; [Kacala, Paulina; Onolememen, Deborah; Vaughan-Lane, Katie; Sisily Joseph, Anitta] Nicolaus Copernicus Univ Torun, Dept Otolaryngol & Laryngol Oncol, ENT Sci Club, Coll Med, Ul Marie Sklodowskiej Curie 9, PL-85094 Bydgoszcz, Poland; [Ostrowski, Adam] Nicolaus Copernicus Univ Torun, Dept Urol, Coll Med, Ul Marie Sklodowskiej Curie 9, PL-85094 Bydgoszcz, Poland; [Pietruszewska, Wioletta] Med Univ Lodz, Dept Otolaryngol Laryngol Oncol Audiol & Phoniatr, Ul Zeromskiego 113, PL-90549 Lodz, Poland; [Banaszewski, Jacek] Poznan Univ Med Sci, Dept Otolaryngol Head & Neck Oncol, Ul Przybyszewskiego 49, PL-60355 Poznan, Poland	Nicolaus Copernicus University; Nicolaus Copernicus University; Nicolaus Copernicus University; Medical University Lodz; Poznan University of Medical Sciences	Vaughan-Lane, K (corresponding author), Nicolaus Copernicus Univ Torun, Dept Otolaryngol & Laryngol Oncol, ENT Sci Club, Coll Med, Ul Marie Sklodowskiej Curie 9, PL-85094 Bydgoszcz, Poland.	orlamb@cm.umk.pl; katielane.kl@gmail.com; adam.ostrowski@cm.umk.pl; wioletta.pietruszewska@umed.lodz.pl; jbanasz@ump.edu.pl		Wrobel, Maciej/0000-0003-1865-2122; lane, Katie/0009-0008-7846-7440; Onolememen, Osemhengbe Deborah/0009-0007-7196-9280				Afify AY, 2023, EUR ARCH OTO-RHINO-L, V280, P1855, DOI 10.1007/s00405-022-07730-y; Bergmo TS, 2023, JMIR FORM RES, V7, DOI 10.2196/40466; Bernard A, 2007, AM J GASTROENTEROL, V102, P2070, DOI 10.1111/j.1572-0241.2007.01325.x; Bujnowska-Fedak MM, 2019, ADV EXP MED BIOL, V1211, P1, DOI 10.1007/5584_2019_396; Calixte R, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17186856; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chatelan A, 2023, J ACAD NUTR DIET, V123, P1525, DOI 10.1016/j.jand.2023.08.001; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Decker H, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36997; Eurostat, 2024, About us, DOI [10.2908/ISOC_CI_AC_I, DOI 10.2908/ISOC_CI_AC_I]; Google AI, 2023, About us; Hatem R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.44720; Haver HL, 2024, RADIOL-IMAG CANCER, V6, DOI 10.1148/rycan.230086; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Kuscu O, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1256459; Li HOY, 2020, BMJ GLOB HEALTH, V5, DOI 10.1136/bmjgh-2020-002604; Machiels JP, 2020, ANN ONCOL, V31, P1462, DOI 10.1016/j.annonc.2020.07.011; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/52865; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Nie H, 2021, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.680327; Nocini R, 2020, CHINESE J CANCER RES, V32, P18, DOI 10.21147/j.issn.1000-9604.2020.01.03; OpenAI, 2022, US; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schwab K., 2016, 4 IND REVOLUTION WHA, DOI DOI 10.1080/01969722.2016.1128762; Sexton GP, 2023, EUR ARCH OTO-RHINO-L, V280, P4587, DOI 10.1007/s00405-023-08055-0; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Siegel RL, 2022, CA-CANCER J CLIN, V72, P7, DOI 10.3322/caac.21708; Siu A.H.Y., 2023, J. Med. Educ, V22, pe137753, DOI [10.5812/jme-137753, DOI 10.5812/JME-137753]; Stroop A, 2023, EUR SPINE J, DOI 10.1007/s00586-023-07975-z; VARAS JULIAN, 2023, Rev. Col. Bras. Cir., V50, pe20233605, DOI 10.1590/0100-6991e-20233605-en; Vaswani A, 2017, ADV NEUR IN, V30; Venerito V, 2023, RHEUMATOLOGY, V62, P3256, DOI 10.1093/rheumatology/kead291; Watters C, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1224976	35	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0937-4477	1434-4726		EUR ARCH OTO-RHINO-L	Eur. Arch. Oto-Rhino-Laryn.	2024 APR 23	2024										10.1007/s00405-024-08643-8	http://dx.doi.org/10.1007/s00405-024-08643-8		APR 2024	13	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	OK1E0	38652298	hybrid			2024-07-03	WOS:001207064800002
C	Chen, QQ; Zhang, TY; Nie, MW; Wang, Z; Xu, SH; Shi, W; Cao, Z			ACM	Chen, Qianqian; Zhang, Tianyi; Nie, Maowen; Wang, Zheng; Xu, Shihao; Shi, Wei; Cao, Zhao			Fashion-GPT: Integrating LLMs with Fashion Retrieval System	PROCEEDINGS OF THE 1ST WORKSHOP ON LARGE GENERATIVE MODELS MEET MULTIMODAL APPLICATIONS, LGM3A 2023			English	Proceedings Paper	1st Workshop on Large Generative Models Meet Multimodal Applications (LGM3A)	NOV 02, 2023	Ottawa, CANADA	Assoc Comp Machinery, ACM SIGMM		ChatGPT-based system with retrieval function; multimodal pre-training network; multi-round multi-modal search		Customers on a fashion e-commerce platform although expressing their clothing preferences through combined imagery and textual information, they are limited to retrieve with single-round fixed inputs. At the same time, large language models (LLMs) have been gaining attention across various fields. ChatGPT is a remarkable example of an LLM, known for its user-friendly language interface, impressive conversational proficiency, and reasoning abilities. To this end, we propose Fashion-GPT, a system paradigm that integrates ChatGPT with a pool of AI models in the fashion domain to achieve a multi-round multi-modal search. Specifically, it enables the system to utilize the LLMs for understanding user queries, select retrieval models based on their function descriptions, execute each subtask with the selected fashion models, and leverage LLMs to summarize the response corresponding to the execution results. In order to boost the performance dominated by AI experts, we also introduce a novel pre-trained framework called 3M (short for Multi-view Multi-modal Matching). In particular, unlike prior studies that rely solely on one-to-one matching on image-text pair, 3M incorporates multiple texts describing the same image to achieve one-to-many alignment. Maximizing mutual information between features extracted from these views boosts capturing information about high-level factors that influence multiple views, such as the occurrence of specific objects. In addition, with the advantage of the characteristics of fashion data, multi-view images from the same product, like front-view and side-view, are naturally suitable for intra-modal self-alignment. Therefore, 3M also introduces an intra-modal contrastive objective to provide additional benefits in representation learning from the image perspective. To the best of our knowledge, our framework is the first to consider one-to-many mapping for multi-modality representation learning. Experimental evaluations demonstrate that our fashion experts are competitive and achieve state-of-the-art performance, bringing a +3.47% R@10 boost on Fashion-200K and +1.98% R@10 boost on the Fashion-IQ dress dataset compared to the previous SOTA results.	[Chen, Qianqian; Zhang, Tianyi; Nie, Maowen; Wang, Zheng; Xu, Shihao; Shi, Wei] Huawei Singapore Res Ctr, Singapore, Singapore; [Cao, Zhao] Huawei Technol Co Ltd, Shenzhen, Peoples R China	Huawei Technologies; Huawei Technologies	Chen, QQ (corresponding author), Huawei Singapore Res Ctr, Singapore, Singapore.	chenqianqian20@huawei.com; zhang.tianyi@huawei.com; nie.maowen@huawei.com; wangzheng155@huawei.com; shihao.xu@huawei.com; w.shi@huawei.com; caozhao1@huawei.com		wang, zheng/0000-0002-7064-6267; Shi, Wei/0009-0006-2717-4192				Bachman P, 2019, Arxiv, DOI arXiv:1906.00910; Baldrati A, 2022, PROC CVPR IEEE, P21434, DOI 10.1109/CVPR52688.2022.02080; Baldrati A, 2022, IEEE COMPUT SOC CONF, P4955, DOI 10.1109/CVPRW56347.2022.00543; Baldrati Alberto, 2022, Conditioned and Composed Image Retrieval Combining and Partially Fine-Tuning CLIP-Based Features, P4959; Chen FL, 2023, MACH INTELL RES, V20, P38, DOI 10.1007/s11633-022-1369-5; Chen YB, 2020, PROC CVPR IEEE, P2998, DOI 10.1109/CVPR42600.2020.00307; Delmas G, 2022, Arxiv, DOI arXiv:2203.08101; Hjelm RD, 2019, Arxiv, DOI [arXiv:1808.06670, DOI 10.48550/ARXIV.1808.06670]; Du YF, 2022, Arxiv, DOI arXiv:2202.10936; Goenka S, 2022, PROC CVPR IEEE, P14085, DOI 10.1109/CVPR52688.2022.01371; Guo XX, 2018, Arxiv, DOI [arXiv:1805.00145, DOI 10.48550/ARXIV.1805.00145]; Han Xiao, 2022, FashionViL: FashionFocused VisionandLanguage Representation Learning, DOI [10.1007/978-3-031-19833-5_37, DOI 10.1007/978-3-031-19833-5_37]; Han Xiao, 2022, arXiv, DOI [10.48550/arXiv.2204.03111, DOI 10.48550/ARXIV.2204.03111]; Han XT, 2017, Arxiv, DOI [arXiv:1708.01311, 10.48550/ARXIV.1708.01311, DOI 10.48550/ARXIV.1708.01311]; Hataya Ryuichiro, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2211, 10.48550/arXiv.2211, 10.48550/arXiv.2211.]; Huang SH, 2023, Arxiv, DOI arXiv:2302.14045; Kim J, 2021, AAAI CONF ARTIF INTE, V35, P1771; Lee S, 2021, PROC CVPR IEEE, P802, DOI 10.1109/CVPR46437.2021.00086; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Liu S, 2012, PROC CVPR IEEE, P3330, DOI 10.1109/CVPR.2012.6248071; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Z, 2021, Arxiv, DOI arXiv:2103.14030; Liu ZY, 2021, Arxiv, DOI [arXiv:2108.04024, 10.48550/ARXIV.2108.04024, DOI 10.48550/ARXIV.2108.04024]; Mirchandani S, 2022, Arxiv, DOI [arXiv:2210.15028, DOI 10.48550/ARXIV.2210.15028]; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Perez E, 2017, Arxiv, DOI arXiv:1709.07871; Poole B, 2019, Arxiv, DOI arXiv:1905.06922; Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A., 2022, arXiv; Rostamzadeh N, 2018, Arxiv, DOI [arXiv:1806.08317, DOI 10.48550/ARXIV.1806.08317]; Russakovsky O, 2015, Arxiv, DOI arXiv:1409.0575; Schick T., 2023, arXiv; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Vo N, 2018, Arxiv, DOI [arXiv:1812.07119, DOI 10.48550/ARXIV.1812.07119, 10.48550/ARXIV.1812.07119]; Wen HK, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1369, DOI 10.1145/3404835.3462967; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu H, 2020, Arxiv, DOI [arXiv:1905.12794, DOI 10.48550/ARXIV.1905.12794]; Yang Xuewen, 2020, arXiv, DOI [10.48550/ARXIV.2008.02693, DOI 10.48550/ARXIV.2008.02693]; Yu Z, 2023, Arxiv, DOI arXiv:2303.01903; Zhang L, 2023, Arxiv, DOI arXiv:2302.05543; Zhang WQ, 2022, Arxiv, DOI [arXiv:2207.04211, 10.48550/ARXIV.2207.04211, DOI 10.48550/ARXIV.2207.04211]; Zhao YD, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1012, DOI 10.1145/3477495.3532047; Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184; Zhu DY, 2023, Arxiv, DOI arXiv:2303.06594; Zi-Yi D, 2022, Arxiv, DOI arXiv:2111.02387	47	0	0	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0283-9				2023							69	78		10.1145/3607827.3616844	http://dx.doi.org/10.1145/3607827.3616844			10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KH					2024-07-03	WOS:001150367900011
C	Jalil, S; Rafi, S; LaToza, TD; Moran, K; Lam, W			IEEE	Jalil, Sajed; Rafi, Suzzana; LaToza, Thomas D.; Moran, Kevin; Lam, Wing			ChatGPT and Software Testing Education: Promises & Perils	2023 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND VALIDATION WORKSHOPS, ICSTW	IEEE International Conference on Software Testing Verification and Validation Workshops		English	Proceedings Paper	16th IEEE International Conference on Software Testing, Verification and Validation (ICST)	APR 16-20, 2023	Dublin, IRELAND	IEEE, IEEE Comp Soc, Fidel Investments, Failte Ireland, LERO, Meta, Google		ChatGPT; testing; education; case study		Over the past decade, predictive language modeling for code has proven to be a valuable tool for enabling new forms of automation for developers. More recently, we have seen the advent of general purpose "large language models", based on neural transformer architectures, that have been trained on massive datasets of human written text, which includes code and natural language. However, despite the demonstrated representational power of such models, interacting with them has historically been constrained to specific task settings, limiting their general applicability. Many of these limitations were recently overcome with the introduction of ChatGPT, a language model created by OpenAl and trained to operate as a conversational agent, enabling it to answer questions and respond to a wide variety of commands from end users. The introduction of models, such as ChatGPT, has already spurred fervent discussion from educators, ranging from fear that students could use these AI tools to circumvent learning, to excitement about the new types of learning opportunities that they might unlock. However, given the nascent nature of these tools, we currently lack fundamental knowledge related to how well they perform in different educational settings, and the potential promise (or danger) that they might pose to traditional forms of instruction. As such, in this paper, we examine how well ChatGPT performs when tasked with answering common questions in a popular software testing curriculum. We found that given its current capabilities, ChatGPT is able to respond to 77.5% of the questions we examined and that, of these questions, it is able to provide correct or partially correct answers in 55.6% of cases, provide correct or partially correct explanations of answers in 53.0% of cases, and that prompting the tool in a shared question context leads to a marginally higher rate of correct answers and explanations. Based on these findings, we discuss the potential promises and perils related to the use of ChatGPT by students and instructors.	[Jalil, Sajed; Rafi, Suzzana; LaToza, Thomas D.; Moran, Kevin; Lam, Wing] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA	George Mason University	Jalil, S (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	sjalil@gmu.edu; srafi@gmu.edu; tlatoza@gmu.edu; kpmoran@gmu.edu; winglam@gmu.edu	Jalil, Sajed/JQI-9119-2023	Jalil, Sajed/0000-0003-1249-2113				Allamanis M., 2018, INT C LEARN REPR; Ammann P., 2023, INTRO SOFTWARE TESTI; [Anonymous], 2016, Introduction to software testing; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Devlin J., 2018, BERT PRE TRAINING DE; Feng Z., 2020, arXiv; Finnie-Ansley J., 2022, ACE; Finnie-Ansley J., 2023, ACE; github, 2023, CHATGPT SOFTW TEST S; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Jalil Sajed, 2023, Zenodo, DOI 10.5281/ZENODO.7700501; Kung T.H., medRxiv; Lertbanjongngam S., 2022, IWSC; Li Y., 2022, SCIENCE; openai, 2023, New Models and Developer Products Announced at DevDay; OpenAI, 2023, CHATGPT; Ouyang L., 2022, ARXIV; Pearce H., 2023, S P; Puryear B., 2022, GITHUB COPILOT CLASS; Vaithilingam P., 2022, CHI; Vasconcelos H., 2022, ARXIV; Vaswani A, 2017, ADV NEUR IN, V30; White M, 2015, 12TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2015), P334, DOI 10.1109/MSR.2015.38; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569	26	27	27	4	5	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2159-4848		979-8-3503-3335-0	IEEE ICST WORKSHOP			2023							430	437		10.1109/ICSTW58534.2023.00078	http://dx.doi.org/10.1109/ICSTW58534.2023.00078			8	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV2PQ		Green Submitted			2024-07-03	WOS:001009223100064
J	Ezzeddine, F; Ayoub, O; Giordano, S; Nogara, G; Sbeity, I; Ferrara, E; Luceri, L				Ezzeddine, Fatima; Ayoub, Omran; Giordano, Silvia; Nogara, Gianluca; Sbeity, Ihab; Ferrara, Emilio; Luceri, Luca			Exposing influence campaigns in the age of LLMs: a behavioral-based AI approach to detecting state-sponsored trolls	EPJ DATA SCIENCE			English	Article						Social network; Troll; Misinformation	NEURAL-NETWORKS	The detection of state-sponsored trolls operating in influence campaigns on social media is a critical and unsolved challenge for the research community, which has significant implications beyond the online realm. To address this challenge, we propose a new AI-based solution that identifies troll accounts solely through behavioral cues associated with their sequences of sharing activity, encompassing both their actions and the feedback they receive from others. Our approach does not incorporate any textual content shared and consists of two steps: First, we leverage an LSTM-based classifier to determine whether account sequences belong to a state-sponsored troll or an organic, legitimate user. Second, we employ the classified sequences to calculate a metric named the "Troll Score", quantifying the degree to which an account exhibits troll-like behavior. To assess the effectiveness of our method, we examine its performance in the context of the 2016 Russian interference campaign during the U.S. Presidential election. Our experiments yield compelling results, demonstrating that our approach can identify account sequences with an AUC close to 99% and accurately differentiate between Russian trolls and organic users with an AUC of 91%. Notably, our behavioral-based approach holds a significant advantage in the ever-evolving landscape, where textual and linguistic properties can be easily mimicked by Large Language Models (LLMs): In contrast to existing language-based techniques, it relies on more challenging-to-replicate behavioral cues, ensuring greater resilience in identifying influence campaigns, especially given the potential increase in the usage of LLMs for generating inauthentic content. Finally, we assessed the generalizability of our solution to various entities driving different information operations and found promising results that will guide future research.	[Ezzeddine, Fatima; Ayoub, Omran; Giordano, Silvia; Nogara, Gianluca; Luceri, Luca] Univ Appl Sci & Arts Southern Switzerland, Dept Innovat Technol, Lugano, Switzerland; [Ezzeddine, Fatima; Sbeity, Ihab] Lebanese Univ, Fac Sci, Dept Appl Math, Beirut, Lebanon; [Ferrara, Emilio; Luceri, Luca] Univ Southern Calif, Viterbi Sch Engn, Informat Sci Inst, Marina Del Rey, CA USA	Lebanese University; University of Southern California	Ezzeddine, F (corresponding author), Univ Appl Sci & Arts Southern Switzerland, Dept Innovat Technol, Lugano, Switzerland.; Ezzeddine, F (corresponding author), Lebanese Univ, Fac Sci, Dept Appl Math, Beirut, Lebanon.	fatima.ezzeddine@supsi.ch	Ferrara, Emilio/F-6136-2012; Luceri, Luca/AAQ-8158-2020	Ferrara, Emilio/0000-0002-1942-2831; Luceri, Luca/0000-0001-5267-7484; Ayoub, Omran/0000-0002-3884-3594; Ezzeddine, Fatima/0000-0002-5128-5814	Swiss National Science Foundation [CRSII5_209250]; SPARK project Detecting Troll Activity in Online Social Networks [CRSK-2_195707]; Swiss National Science Foundation (SNF) [CRSK-2_195707, CRSII5_209250] Funding Source: Swiss National Science Foundation (SNF)	Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); SPARK project Detecting Troll Activity in Online Social Networks; Swiss National Science Foundation (SNF)(Swiss National Science Foundation (SNSF))	The authors gratefully acknowledge support by the Swiss National Science Foundation through the Sinergia project(CRSII5_209250) CAll for Regulation support In Social MediA (CARISMA) and the SPARK project Detecting Troll Activity in Online Social Networks (CRSK-2_195707).	Abou Daya A, 2019, 2019 IFIP/IEEE SYMPOSIUM ON INTEGRATED NETWORK AND SERVICE MANAGEMENT (IM), P144; Addawood A., 2019, P INT AAAI C WEB SOC, V13, P15, DOI [10.1609/icwsm.v13i01.3205, DOI 10.1609/ICWSM.V13I01.3205]; Alhazbi S, 2020, IEEE ACCESS, V8, P195132, DOI 10.1109/ACCESS.2020.3033666; Alizadeh M, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abb5824; Allem Jon-Patrick, 2017, JMIR Public Health Surveill, V3, pe98, DOI 10.2196/publichealth.8641; [Anonymous], 2020, LANCET INFECT DIS, V20, P875, DOI 10.1016/S1473-3099(20)30565-X; [Anonymous], 2018, Why so serious, DOI [10.2139/ssrn.3131087, DOI 10.2139/SSRN.3131087]; Aro J., 2016, European View, V15, P121, DOI DOI 10.1007/S12290-016-0395-5; Badawy A, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0578-6; Bessi A., 2016, First Monday, V21, DOI 10.5210/fm.v21i11.7090; Beykpour K, 2020, Additional steps we're taking ahead of the 2020 US Election; Cambridge Luceri L, 2020, Proceedings of the Fourteenth International AAAI Conference on Web and Social Media, V14, P417, DOI [DOI 10.1609/ICWSM.V14I1.7311, 10.1609/icwsm.v14i1.7311]; Carroll Oliver, 2017, The Independent; Chavoshi N, 2016, IEEE DATA MINING, P817, DOI [10.1109/ICDM.2016.0096, 10.1109/ICDM.2016.86]; Chen E, 2022, J COMPUT SOC SCI, V5, P1, DOI 10.1007/s42001-021-00117-9; Cresci S, 2018, IEEE T DEPEND SECURE, V15, P561, DOI 10.1109/TDSC.2017.2681672; Del Vicario M, 2016, SCI REP-UK, V6, DOI 10.1038/srep37825; Drumnond C., 2003, ICML KDD 2003 WORKSH; Ferrara E., 2023, First Monday; Ferrara E, 2022, Arxiv, DOI arXiv:2211.05913; Ferrara E, 2020, J COMPUT SOC SCI, V3, P271, DOI 10.1007/s42001-020-00094-5; Ferrara E, 2016, COMMUN ACM, V59, P96, DOI 10.1145/2818717; Ferrara Emilio, 2015, ACM SIGWEB Newsletter Spring, V2015, P4, DOI DOI 10.1145/2749279.2749283; Frommer D, 2019, Twitter's list of 2,752 Russian trolls; Gatta VL., 2023, P 34 ACM C HYP SOC M, P1; Hu ZW, 2020, J MED INTERNET RES, V22, DOI 10.2196/22639; Im J, 2020, PROCEEDINGS OF THE 12TH ACM CONFERENCE ON WEB SCIENCE, WEBSCI 2020, P1, DOI 10.1145/3394231.3397889; Ionin T, 2008, LINGUA, V118, P554, DOI 10.1016/j.lingua.2006.11.012; Jachim P, 2020, NEW SECURITY PARADIGMS WORKSHOP (NSPW 2020), P59, DOI 10.1145/3442167.3442169; Kim D, 2019, J COMPUT SOC SCI, V2, P331, DOI 10.1007/s42001-019-00051-x; Kudugunta S, 2018, INFORM SCIENCES, V467, P312, DOI 10.1016/j.ins.2018.08.019; Liu XY, 2009, IEEE T SYST MAN CY B, V39, P539, DOI 10.1109/TSMCB.2008.2007853; Luceri L, 2021, The Internet and the 2020 Campaign, V1; Luceri L, 2019, First Monday; Luceri Luca, 2021, First Monday; Matakos A, 2017, DATA MIN KNOWL DISC, V31, P1480, DOI 10.1007/s10618-017-0527-9; Mazza M, 2022, COMPUT COMMUN, V196, P23, DOI 10.1016/j.comcom.2022.09.022; Mazza M, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P183, DOI 10.1145/3292522.3326015; Menczer F, 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00690-w; Metaxas P., 2015, Proceedings of the international AAAI conference on web and social media; Metaxas PT, 2012, SCIENCE, V338, P472, DOI 10.1126/science.1230456; Mitrovic Sandra, 2023, arXiv; Mueller R. S., 2019, Report on the Investigation into Russian Interference in the 2016 Presidential Election; Nicolai G, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P854; Nielsen M.A., 2015, NEURAL NETWORKS DEEP, V25; Nogara G, 2022, PROCEEDINGS OF THE 14TH ACM WEB SCIENCE CONFERENCE, WEBSCI 2022, P348, DOI 10.1145/3501247.3531573; Nwala AC, 2023, EPJ DATA SCI, V12, DOI 10.1140/epjds/s13688-023-00410-9; Pariser E., 2011, The filter bubble: What the Internet is hiding from you, DOI DOI 10.3139/9783446431164; Phadke S., 2022, P INT AAAI C WEB SOC, V16, P770, DOI DOI 10.1609/ICWSM.V16I1.19333; Pierri F, 2023, PROCEEDINGS OF THE 15TH ACM WEB SCIENCE CONFERENCE, WEBSCI 2023, P65, DOI 10.1145/3578503.3583597; Pierri F, 2023, Arxiv, DOI [arXiv:2209.07614, 10.48550/arXiv.2209.07614, DOI 10.48550/ARXIV.2209.07614]; Pierri F, 2022, Arxiv, DOI arXiv:2209.01675; Pierri F, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-10070-w; Popken Ben, 2018, NBC News, V14; Saeed M. H., 2021, arXiv; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Stella M, 2018, P NATL ACAD SCI USA, V115, P12435, DOI 10.1073/pnas.1803470115; Suresh Vishnuprasad Padinjaredath, 2024, P INT AAAI C WEB SOC; Valldor E., 2018, SWED S DEEP LEARN; Vanhove T, 2013, 2013 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2013), P1195; Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559; Wang EMY, 2022, Arxiv, DOI arXiv:2209.09339; Wang G, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P225, DOI 10.1145/2858036.2858107; Weller H, 2019, Identifying Russian trolls on Reddit with deep learning and bert word embeddings; Yang KC, 2023, Arxiv, DOI arXiv:2307.16336; Zannettou S, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P353, DOI 10.1145/3292522.3326016; Zollo F, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138740	67	1	1	6	9	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES		2193-1127		EPJ DATA SCI	EPJ Data Sci.	OCT 9	2023	12	1							46	10.1140/epjds/s13688-023-00423-4	http://dx.doi.org/10.1140/epjds/s13688-023-00423-4			21	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Mathematics; Mathematical Methods In Social Sciences	U0QA1	37822355	Green Submitted, Green Published, gold			2024-07-03	WOS:001081926100001
J	Leypold, T; Schaefer, B; Boos, A; Beier, JP				Leypold, Tim; Schaefer, Benedikt; Boos, Anja; Beier, Justus P.			Can AI Think Like a Plastic Surgeon? Evaluating GPT-4's Clinical Judgment in Reconstructive Procedures of the Upper Extremity	PLASTIC AND RECONSTRUCTIVE SURGERY-GLOBAL OPEN			English	Article								This study delves into the potential application of OpenAI's Generative Pretrained Transformer 4 (GPT-4) in plastic surgery, with a particular focus on procedures involving the hand and arm. GPT-4, a cutting-edge artificial intelligence (AI) model known for its advanced chat interface, was tested on nine surgical scenarios of varying complexity. To optimize the performance of GPT-4, prompt engineering techniques were used to guide the model's responses and improve the relevance and accuracy of its output. A panel of expert plastic surgeons evaluated the responses using a Likert scale to assess the model's performance, based on five distinct criteria. Each criterion was scored on a scale of 1 to 5, with 5 representing the highest possible score. GPT-4 demonstrated a high level of performance, achieving an average score of 4.34 across all cases, consistent across different complexities. The study highlights the ability of GPT-4 to understand and respond to complicated surgical scenarios. However, the study also identifies potential areas for improvement. These include refining the prompts used to elicit responses from the model and providing targeted training with specialized, up-to-date sources. This study demonstrates a new approach to exploring large language models and highlights potential future applications of AI. These could improve patient care, refine surgical outcomes, and even change the way we approach complex clinical scenarios in plastic surgery. However, the intrinsic limitations of AI in its current state, together with the potential ethical considerations and the inherent uncertainty of unanticipated issues, serve to reiterate the indispensable role and unparalleled value of human plastic surgeons.	[Leypold, Tim; Schaefer, Benedikt; Boos, Anja; Beier, Justus P.] Univ Hosp RWTH Aachen, Hand Surg Burn Ctr, Dept Plast Surg, Aachen, Germany	RWTH Aachen University; RWTH Aachen University Hospital	Leypold, T (corresponding author), Univ Hosp RWTH Aachen, Hand Surg Burn Ctr, Dept Plast Surg, Aachen, Germany.							Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Najafali D, 2023, AESTHET SURG J, V43, pNP591, DOI 10.1093/asj/sjad056; OpenAI, 2023, GPT-4; Sun YX, 2023, AESTHET SURG J, V43, pNP670, DOI 10.1093/asj/sjad134; Wei J., 2021, ARXIV; Xie Y, 2023, Aesthetic Plast Surg; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	10	4	4	4	4	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	2169-7574			PRS-GLOB OPEN	PRS-GLOB. OPEN	DEC	2023	11	12							e5471	10.1097/GOX.0000000000005471	http://dx.doi.org/10.1097/GOX.0000000000005471			3	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	CF1Y2	38093728	gold			2024-07-03	WOS:001123756300001
J	Ali, R; Tang, OY; Connolly, ID; Sullivan, PLZ; Shin, JH; Fridley, JS; Asaad, WF; Cielo, D; Oyelese, AA; Doberstein, CE; Gokaslan, ZL; Telfeian, AE				Ali, Rohaid; Tang, Oliver Y.; Connolly, Ian D.; Sullivan, Patricia L. Zadnik; Shin, John H.; Fridley, Jared S.; Asaad, Wael F.; Cielo, Deus; Oyelese, Adetokunbo A.; Doberstein, Curtis E.; Gokaslan, Ziya L.; Telfeian, Albert E.			Performance of ChatGPT and GPT-4 on Neurosurgery Written Board Examinations	NEUROSURGERY			English	Article						Neurosurgery; Medical education; Surgical education; Residency education; Artificial intelligence; Large language models; ChatGPT; GPT-4		BACKGROUND AND OBJECTIVES: Interest surrounding generative large language models (LLMs) has rapidly grown. Although ChatGPT (GPT-3.5), a general LLM, has shown near-passing performance on medical student board examinations, the performance of ChatGPT or its successor GPT-4 on specialized examinations and the factors affecting accuracy remain unclear. This study aims to assess the performance of ChatGPT and GPT-4 on a 500-question mock neurosurgical written board examination.METHODS: The Self-Assessment Neurosurgery Examinations (SANS) American Board of Neurological Surgery Self-Assessment Examination 1 was used to evaluate ChatGPT and GPT-4. Questions were in single best answer, multiple-choice format. chi 2, Fisher exact, and univariable logistic regression tests were used to assess performance differences in relation to question characteristics.RESULTS: ChatGPT (GPT-3.5) and GPT-4 achieved scores of 73.4% (95% CI: 69.3%-77.2%) and 83.4% (95% CI: 79.8%-86.5%), respectively, relative to the user average of 72.8% (95% CI: 68.6%-76.6%). Both LLMs exceeded last year's passing threshold of 69%. Although scores between ChatGPT and question bank users were equivalent (P = .963), GPT-4 outperformed both (both P < .001). GPT-4 answered every question answered correctly by ChatGPT and 37.6% (50/133) of remaining incorrect questions correctly. Among 12 question categories, GPT-4 significantly outperformed users in each but performed comparably with ChatGPT in 3 (functional, other general, and spine) and outperformed both users and ChatGPT for tumor questions. Increased word count (odds ratio = 0.89 of answering a question correctly per +10 words) and higher-order problem-solving (odds ratio = 0.40, P = .009) were associated with lower accuracy for ChatGPT, but not for GPT-4 (both P > .005). Multimodal input was not available at the time of this study; hence, on questions with image content, ChatGPT and GPT-4 answered 49.5% and 56.8% of questions correctly based on contextual context clues alone.CONCLUSION: LLMs achieved passing scores on a mock 500-question neurosurgical written board examination, with GPT-4 significantly outperforming ChatGPT.	[Ali, Rohaid; Tang, Oliver Y.; Sullivan, Patricia L. Zadnik; Fridley, Jared S.; Asaad, Wael F.; Cielo, Deus; Oyelese, Adetokunbo A.; Doberstein, Curtis E.; Gokaslan, Ziya L.; Telfeian, Albert E.] USA, Blountstown, FL USA; [Connolly, Ian D.] Massachusetts Gen Hosp, Dept Neurosurg, Boston, MA USA; [Shin, John H.; Asaad, Wael F.] Rhode Isl Hosp, Norman Prince Neurosci Inst, Dept Neurosci, Providence, RI 02903 USA; [Asaad, Wael F.] Brown Univ, Dept Neurosci, Providence, RI USA; [Asaad, Wael F.] Brown Univ, Carney Inst Brain Sci, Dept Neurosci, Providence, RI USA; [Ali, Rohaid] Rhode Isl Hosp, Dept Neurosurg, LPG Neurosurg, 593 Eddy St,APC6, Providence, RI 02903 USA	Harvard University; Massachusetts General Hospital; Lifespan Health Rhode Island; Rhode Island Hospital; Brown University; Brown University; Lifespan Health Rhode Island; Rhode Island Hospital	Ali, R (corresponding author), Rhode Isl Hosp, Dept Neurosurg, LPG Neurosurg, 593 Eddy St,APC6, Providence, RI 02903 USA.	RAli@lifespan.org; oliver_tang@brown.edu; iconnolly@mgh.harvard.edu; patricia_sullivan@brown.edu; Shin.John@mgh.harvard.edu; jared_fridley@brown.edu; wael_asaad@brown.edu; deus_cielo@brown.edu; AOyelese@lifespan.org; curtis_doberstein@brown.edu; Ziya.Gokaslan@lifespan.org; atelfeian@lifespan.org	Sullivan, Patricia L/C-6824-2008; Asaad, Wael/I-8485-2012	Asaad, Wael/0000-0003-4406-9096	American Board of Neurological Surgery	American Board of Neurological Surgery	We acknowledge and thank the Congress of Neurological Surgeons and American Board of Neurological Surgery for their development and dissemination of the mock examination questions used for this study.	Burk-Rafel J, 2017, ACAD MED, V92, pS67, DOI 10.1097/ACM.0000000000001916; Chen PHC, 2019, NAT MATER, V18, P410, DOI 10.1038/s41563-019-0345-0; Gupta A., 2023, A Responsible Path to Generative AI in Healthcare; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3; Martinez E., 2023, SSRN Electron J, P410; Moran S., 2020, How to Prepare for the USMLE® Step 1; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; Nori H., 2023, ARXIV; Oermann EK, 2023, NEUROSURGERY, V92, P665, DOI 10.1227/neu.0000000000002415; OpenAI, 2023, GPT 4 TECHNICAL REPO; Tang OY., Neurosurgery, DOI [10.1227/neu.0000000000002618, DOI 10.1227/NEU.0000000000002618]; The American Board of Neurological Surgery, 2023, Frequently Asked Questions; Touvron H., 2023, Llama: Open and efficient foundation language models	14	29	29	19	19	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0148-396X	1524-4040		NEUROSURGERY	Neurosurgery	DEC	2023	93	6					1353	1365		10.1227/neu.0000000000002632	http://dx.doi.org/10.1227/neu.0000000000002632			13	Clinical Neurology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Surgery	FJ9E0	37581444	Green Submitted			2024-07-03	WOS:001145512300026
J	Babayigit, O; Eroglu, ZT; Sen, DO; Yarkac, FU				Babayigit, Osman; Eroglu, Zeynep Tastan; Sen, Dilek Ozkan; Yarkac, Fatma Ucan			Potential Use of ChatGPT for Patient Information in Periodontology: A Descriptive Pilot Study	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						chatgpt; chat generative pre-trained transformer; large language models (llms); patient information; oral medicine and periodontology; dental care; artificial intelligence in dentistry		ObjectivesThe aim of this study is to evaluate the accuracy and completeness of the answers given by Chat Generative Pre-trained Transformer (ChatGPT) (OpenAI OpCo, LLC, San Francisco, CA), to the most frequently asked questions on different topics in the field of periodontology. MethodsThe 10 most frequently asked questions by patients about seven different topics (periodontal diseases, peri-implant diseases, tooth sensitivity, gingival recessions, halitosis, dental implants, and periodontal surgery) in periodontology were created by ChatGPT. To obtain responses, a set of 70 questions was submitted to ChatGPT, with an allocation of 10 questions per subject. The responses that were documented were assessed using two distinct Likert scales by professionals specializing in the subject of periodontology. The accuracy of the responses was rated on a Likert scale ranging from one to six, while the completeness of the responses was rated on a scale ranging from one to three. ResultsThe median accuracy score for all responses was six, while the completeness score was two. The mean scores for accuracy and completeness were 5.50 +/- 0.23 and 2.34 +/- 0.24, respectively. It was observed that ChatGPT's responses to the most frequently asked questions by patients for information purposes in periodontology were at least "nearly completely correct" in terms of accuracy and "adequate" in terms of completeness. There was a statistically significant difference between subjects in terms of accuracy and completeness (P<0.05). The highest and lowest accuracy scores were peri-implant diseases and gingival recession, respectively, while the highest and lowest completeness scores were gingival recession and dental implants, respectively. ConclusionsThe utilization of large language models has become increasingly prevalent, extending its applicability to patients within the healthcare domain. While ChatGPT may not offer absolute precision and comprehensive results without expert supervision, it is apparent that those within the field of periodontology can utilize it as an informational resource, albeit acknowledging the potential for inaccuracies.	[Babayigit, Osman; Eroglu, Zeynep Tastan; Sen, Dilek Ozkan; Yarkac, Fatma Ucan] Necmettin Erbakan Univ, Fac Dent, Dept Periodontol, Konya, Turkiye	Necmettin Erbakan University	Babayigit, O (corresponding author), Necmettin Erbakan Univ, Fac Dent, Dept Periodontol, Konya, Turkiye.	osmanbabayigit95@gmail.com	ozkan sen, Dilek/JRW-5015-2023; ucan yarkac, fatma/JRW-2348-2023; taştan eroğlu, zeynep/HKN-1983-2023; Babayigit, Osman/IQT-3837-2023	ozkan sen, Dilek/0000-0002-0531-1217; ucan yarkac, fatma/0000-0001-8126-585X; taştan eroğlu, zeynep/0000-0002-0003-2120; Babayigit, Osman/0000-0001-9842-6306				Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Balel Y, 2023, J STOMATOL ORAL MAXI, V124, DOI 10.1016/j.jormas.2023.101471; Beaumont J, 2023, BRIT DENT J, V234, P253, DOI 10.1038/s41415-023-5525-2; Bizzi I, 2017, J CLIN PERIODONTOL, V44, P308, DOI 10.1111/jcpe.12668; Dillon GF, 2004, QUAL SAF HEALTH CARE, V13, pI41, DOI 10.1136/qshc.2004.010025; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haman M, 2023, ANN BIOMED ENG, V51, P1128, DOI 10.1007/s10439-023-03201-5; He YB, 2023, ANN BIOMED ENG, V51, P1362, DOI 10.1007/s10439-023-03206-0; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lahat A, 2023, J TELEMED TELECARE, DOI 10.1177/1357633X231155520; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	18	3	3	5	6	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	NOV 8	2023	15	11							e48518	10.7759/cureus.48518	http://dx.doi.org/10.7759/cureus.48518			30	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Y6QC1	38073946	Green Published, gold			2024-07-03	WOS:001106475700019
J	Cirkovic, A; Katz, T				Cirkovic, Aleksandar; Katz, Toam			Exploring the Potential of ChatGPT-4 in Predicting Refractive Surgery Categorizations: Comparative Study	JMIR FORMATIVE RESEARCH			English	Article						artificial intelligence; machine learning; decision support systems; clinical; refractive surgical procedures; risk assessment; ophthalmology; health informatics; predictive modeling; data analysis; medical decision -making; eHealth; ChatGPT-4; ChatGPT; refractive surgery; categorization; AI -powered algorithm; large language model; decision -making		Background: Refractive surgery research aims to optimally precategorize patients by their suitability for various types of surgery. Recent advances have led to the development of artificial intelligence-powered algorithms, including machine learning approaches, to assess risks and enhance workflow. Large language models (LLMs) like ChatGPT-4 (OpenAI LP) have emerged as potential general artificial intelligence tools that can assist across various disciplines, possibly including refractive surgery decision-making. However, their actual capabilities in precategorizing refractive surgery patients based on real-world parameters remain unexplored.Objective: This exploratory study aimed to validate ChatGPT-4's capabilities in precategorizing refractive surgery patients based on commonly used clinical parameters. The goal was to assess whether ChatGPT-4's performance when categorizing batch inputs is comparable to those made by a refractive surgeon. A simple binary set of categories (patient suitable for laser refractive surgery or not) as well as a more detailed set were compared.Methods: Data from 100 consecutive patients from a refractive clinic were anonymized and analyzed. Parameters included age, sex, manifest refraction, visual acuity, and various corneal measurements and indices from Scheimpflug imaging. This study compared ChatGPT-4's performance with a clinician's categorizations using Cohen kappa coefficient, a chi-square test, a confusion matrix, accuracy, precision, recall, F-1-score, and receiver operating characteristic area under the curve.Results: A statistically significant noncoincidental accordance was found between ChatGPT-4 and the clinician's categorizations with a Cohen kappa coefficient of 0.399 for 6 categories (95% CI 0.256-0.537) and 0.610 for binary categorization (95% CI 0.372-0.792). The model showed temporal instability and response variability, however. The chi-square test on 6 categories indicated an association between the 2 raters' distributions (chi(2)(5)=94.7, P<.001). Here, the accuracy was 0.68, precision 0.75, recall 0.68, and F-1-score 0.70. For 2 categories, the accuracy was 0.88, precision 0.88, recall 0.88, F-1-score 0.88, and area under the curve 0.79.Conclusions: This study revealed that ChatGPT-4 exhibits potential as a precategorization tool in refractive surgery, showing promising agreement with clinician categorizations. However, its main limitations include, among others, dependency on solely one human rater, small sample size, the instability and variability of ChatGPT's (OpenAI LP) output between iterations and nontransparency of the underlying models. The results encourage further exploration into the application of LLMs like ChatGPT-4 in health care, particularly in decision-making processes that require understanding vast clinical data. Future research should focus on defining the model's accuracy with prompt and vignette standardization, detecting confounding factors, and comparing to other versions of ChatGPT-4 and other LLMs to pave the way for larger-scale validation and real-world implementation.	[Cirkovic, Aleksandar] Care Vis Germany Ltd, Nurnberg, Germany; [Katz, Toam] Univ Med Ctr Hamburg Eppendorf, Dept Ophthalmol, Hamburg, Germany; [Cirkovic, Aleksandar] Care Vis Germany Ltd, Zeltnerstr 1-3, D-90443 Nurnberg, Germany	University of Hamburg; University Medical Center Hamburg-Eppendorf	Cirkovic, A (corresponding author), Care Vis Germany Ltd, Zeltnerstr 1-3, D-90443 Nurnberg, Germany.	aleksandar.cirkovic@mailbox.org		Cirkovic, Aleksandar/0000-0002-2122-5175				Ambrósio R, 2023, AM J OPHTHALMOL, V251, P126, DOI 10.1016/j.ajo.2022.12.016; [Anonymous], How to build your own custom ChatGPT with OpenAI's GPT builder; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Awad EA, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-017-0584-2; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; ChatGPT, about us; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Collins GS, 2015, BMJ-BRIT MED J, V350, DOI [10.1136/bmj.g7594, 10.1111/1471-0528.13244]; D'Souza RF, 2023, ASIAN J PSYCHIATR, V89, DOI 10.1016/j.ajp.2023.103770; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fraser H, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/49995; Giray L, 2023, ANN BIOMED ENG, V51, P2629, DOI 10.1007/s10439-023-03272-4; Hashemi H, 2016, J CURR OPHTHALMOL, V28, P21, DOI 10.1016/j.joco.2016.01.009; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hirosawa T, 2023, JMIR MED INF, V11, DOI 10.2196/48808; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Huo B, 2023, NAT MED, DOI 10.1038/s41591-023-02656-2; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Knebel D, 2023, medRxiv, DOI [10.1101/2023.04.16.23288645, 10.1101/2023.04.16.23288645v1, DOI 10.1101/2023.04.16.23288645V1]; Kraljevic Z, 2023, Arxiv, DOI arXiv:2212.08072; Li B, 2023, PREPRINT, DOI [10.2139/ssrn.4502081, DOI 10.2139/SSRN.4502081]; Lim HB, 2014, CLIN OPHTHALMOL, V8, P2215, DOI 10.2147/OPTH.S66598; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Nastasi AJ, 2023, medRxiv, DOI [10.1101/2023.02.25.23286451, 10.1101/2023.02.25.23286451, DOI 10.1101/2023.02.25.23286451]; OpenAI, 2023, GPT-4 Technical Report; Radford A, 2023, PREPRINT; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarbay I, 2023, TURK J EMERG MED, V23, P156, DOI 10.4103/tjem.tjem_79_23; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Ting DSJ, 2024, EYE, V38, P4, DOI 10.1038/s41433-023-02619-4; Zhang C, 2023, Arxiv, DOI [arXiv:2304.06488, DOI 10.13140/RG.2.2.24789.70883]; Zhang JQ, 2023, Arxiv, DOI arXiv:2307.08152; Zuccon G, 2023, Arxiv, DOI [arXiv:2302.13793, DOI 10.48550/ARXIV.2302.13793]	38	2	2	9	9	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2023	7								e51798	10.2196/51798	http://dx.doi.org/10.2196/51798			10	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	FO1S0	38153777	gold, Green Published			2024-07-03	WOS:001146693300002
J	Sharma, A; Medapalli, T; Alexandrou, M; Brilakis, E; Prasad, A				Sharma, Aditi; Medapalli, Tejas; Alexandrou, Micaella; Brilakis, Emmanouil; Prasad, Anand			Exploring the Role of ChatGPT in Cardiology: A Systematic Review of the Current Literature	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Review						cardiovascular care; patient education; language models; artificial intelligence; cardiology; chatgpt		Chat Generative Pre -Trained Transformer (ChatGPT) is a chatbot based on a large language model that has gained public interest since its release in November 2022. This systematic review examines the current literature on the potential applications of ChatGPT in cardiology. A systematic literature search was conducted to retrieve all publications on ChatGPT in PubMed, Scopus, MedRxiv, and the Cochrane Library published on or before September 30, 2023. Search terms relating to ChatGPT and cardiology were used. Publications without relevance to ChatGPT and cardiology were excluded. The included publications were divided into cohorts. Cohort A examined ChatGPT's role in improving patient health literacy. Cohort B explored ChatGPT's role in clinical care. Cohort C examined ChatGPT's role in future literature and research. Cohort D included case reports that used ChatGPT. A total of 115 publications were found across all databases. Twenty-four publications met the inclusion criteria and were included in the review. Cohort A -C included a total of 14 records comprised of editorials/letters to the editor (29%), research letters/correspondence (21%), review papers (21%), observational studies (7%), research studies (7%), and short reports (7%). Cohort D included 10 case reports. No relevant systematic literature reviews, meta -analyses, or randomized controlled trials were identified in the search. Based on this review of the literature, ChatGPT has the potential to enhance patient education, support clinicians providing clinical care, and enhance the development of future literature. However, further studies are needed to understand the potential applications of ChatGPT in cardiology and to address ethical concerns regarding the delivery of medical advice and the authoring of manuscripts.	[Sharma, Aditi; Medapalli, Tejas; Prasad, Anand] Univ Texas UT Hlth San Antonio, Dept Med, Div Cardiol, San Antonio, TX 78229 USA; [Alexandrou, Micaella; Brilakis, Emmanouil] Minneapolis Heart Inst, Dept Cardiol, Minneapolis, MN USA	University of Texas System; University of Texas Health Science Center at San Antonio; Minneapolis Heart Institute Foundation	Prasad, A (corresponding author), Univ Texas UT Hlth San Antonio, Dept Med, Div Cardiol, San Antonio, TX 78229 USA.	prasada@uthscsa.edu			Freeman Heart Association	Freeman Heart Association	Acknowledgements This project was supported by the Freeman Heart Association.	Afzal I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38185; Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Akhter HM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34752; [Anonymous], 2023, Model index for researchers; Bart NK, 2023, HEART LUNG CIRC, V32, P883, DOI 10.1016/j.hlc.2023.07.005; Bawa A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36326; Biswas S, 2023, YALE J BIOL MED, V96, P415, DOI 10.59249/SKDH9286; Brown C, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36415; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gala Dhir, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20156438; Karatzia L, 2022, FRONT CARDIOVASC MED, V9, DOI 10.3389/fcvm.2022.945726; Kattoor AJ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36002; Kleebayoon A, 2024, ACTA CARDIOL, V79, P402, DOI 10.1080/00015385.2023.2238537; Koulaouzidis G, 2022, J CLIN MED, V11, DOI 10.3390/jcm11133910; Krittanawong C, 2023, JACC-CARDIOVASC INTE, V16, P1551, DOI 10.1016/j.jcin.2023.04.042; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kusunose K, 2023, CIRC J, V87, P1030, DOI 10.1253/circj.CJ-23-0308; Kusunose K, 2023, J ECHOCARDIOGR, V21, P99, DOI 10.1007/s12574-023-00611-1; Kusunose K, 2021, J ECHOCARDIOGR, V19, P21, DOI 10.1007/s12574-020-00496-4; Lal Vallath Aditya, 2023, Cureus, V15, pe36581, DOI 10.7759/cureus.36581; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Nakaya Y, 2023, EUR HEART J-DIGIT HL, V4, P141, DOI 10.1093/ehjdh/ztad026; Raxwal B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35894; Reserach, 2023, GPT-4 is openAI's most advanced system, producing safer and more useful responses; Rizwan A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43106; Saeed A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34574; Schussler JM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36101; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Valencia OAG, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11182518; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Williams MC, 2023, J CARDIOVASC COMPUT, V17, P281, DOI 10.1016/j.jcct.2023.03.010; Yazdi F, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39288	36	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	APR 24	2024	16	4							e58936	10.7759/cureus.58936	http://dx.doi.org/10.7759/cureus.58936			11	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	QC8O4	38800264				2024-07-03	WOS:001218773200018
C	Zhiyenbekov, Z; Omirbekova, Z; Mutanov, G; Tasbolatov, M		Calvo, H; Martinez-Villasenor, L; Ponce, H		Zhiyenbekov, Zhalgas; Omirbekova, Zhanar; Mutanov, Galymkair; Tasbolatov, Madiyar			Visualizing the Cosmos: A Novel Method for Text Recombination with Space News	ADVANCES IN SOFT COMPUTING, MICAI 2023, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	22nd Mexican International Conference on Artificial Intelligence (MICAI)	NOV 13-18, 2023	Inst Investigaciones Matematicas Aplicadas & Sistemas, Yucatan, MEXICO	Univ Autonoma Estado Yucatan, Mexican Soc Artificial Intelligence	Inst Investigaciones Matematicas Aplicadas & Sistemas	Named Entity Recognition; word embeddings; Principal Component Analysis; Natural Language Processing		As the volume of data continues to surge, researchers are confronted with the challenge of extracting meaningful insights from this wealth of information. Despite rapid advancements in Natural Language Processing (NLP) techniques in the AI industry, there remain gaps and opportunities for further exploration, particularly in the realm of data recombination techniques and methods. This paper proposes a novel text recombination method to facilitate the generation of recombined words from a given text. The process commences with a 'stanza' model, which identifies and compiles Named Entity Recognitions (NERs) into a list. These NERs are then cross-referenced with Wikipedia pages to retrieve relevant information, thereby enhancing entity understanding and analysis. The ensuing step involves preprocessing the output text from the previous stage, generating a list of unique words while eliminating stop words. This preprocessing stage serves to remove noise and focus on meaningful words, laying the groundwork for more effective clustering. To enable clustering, we employ vector embeddings, representing words in a 2-dimensional space, rendering them suitable for clustering techniques. Notably, the proposed method further enhances results by re-clustering words after applying K-Means, thereby identifying the most fitting candidate words for recombination. Comparatively, this method outperforms large language models (LLMs) due to its incorporation of NER information, utilization of Wikipedia pages, and effective preprocessing techniques. Unlike LLMs, which operate as resource-intensive black boxes on static data, this method benefits from real-time information access and knowledge base updates. Furthermore, each stage of the process is visualized to control the progress correctly. Thus, due to the plots of word clusterization, the proposed text recombination approach showed positive results.	[Zhiyenbekov, Zhalgas] Kazakh British Tech Univ, Sch Informat Technol & Engn, Alma Ata 050000, Kazakhstan; [Omirbekova, Zhanar] Al Farabi Kazakh Natl Univ, Affiliat Dept Comp Sci, Alma Ata 050000, Kazakhstan; [Mutanov, Galymkair; Tasbolatov, Madiyar] Inst Informat & Computat Technol, Alma Ata 050000, Kazakhstan	Kazakh British Technical University; Al-Farabi Kazakh National University; Institute of Information & Computational Technologies	Zhiyenbekov, Z (corresponding author), Kazakh British Tech Univ, Sch Informat Technol & Engn, Alma Ata 050000, Kazakhstan.	z_zhiyenbekov@kbtu.kz; zh.omirbekova@ipic.kz			Aerospace Committee of the Ministry of Digital Development, Innovations and Aerospace Industry of the Republic of Kazakhstan [BR11265420]	Aerospace Committee of the Ministry of Digital Development, Innovations and Aerospace Industry of the Republic of Kazakhstan	This research is funded by the Aerospace Committee of the Ministry of Digital Development, Innovations and Aerospace Industry of the Republic of Kazakhstan (BR11265420)	Begus G, 2021, NEURAL NETWORKS, V139, P305, DOI 10.1016/j.neunet.2021.03.017; Butt S, 2021, COMPUT SIST, V25, P23, DOI 10.13053/CyS-25-1-3897; Fang F, 2020, J COMPUT SCI TECH-CH, V35, P522, DOI 10.1007/s11390-020-0305-9; García RG, 2020, COMPUT SIST, V24, P429, DOI 10.13053/CyS-24-2-3369; Gimaletdinova G, 2021, COMPUT SIST, V25, P667, DOI [10.13053/cys-25-3-4028, 10.13053/CyS-25-3-4028]; Lam TK, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P245; Li H, 2021, P 28 INT JOINT C ART, V12156, P110, DOI [10.1117/12.2626538, DOI 10.1117/12.2626538]; Liu L., 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, V1: Long Papers, P5834; Mi CG, 2022, NEURAL NETWORKS, V148, P194, DOI 10.1016/j.neunet.2022.01.016; Pichardo-Lagunas O, 2022, COMPUT SIST, V26, P1557, DOI [10.13053/cys-26-4-4425, 10.13053/CyS-26-4-4425]; Qiu LL, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4341; Flores OR, 2020, COMPUT SIST, V24, P533, DOI [10.13053/CyS-24-2-3377, 10.13053/cys-24-2-3377]; Sagingaliyev Beibarys, 2022, Advances in Computational Intelligence: 21st Mexican International Conference on Artificial Intelligence, MICAI 2022, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13613), P148, DOI 10.1007/978-3-031-19496-2_12; Shih-Ta Liu, 2020, Human Interface and the Management of Information. Interacting with Information. Thematic Area, HIMI 2020 Held as Part of the 22nd International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12185), P479, DOI 10.1007/978-3-030-50017-7_36; Sohn H, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1616, DOI 10.1145/3534678.3539349; Zhai Jianyue, 2022, 2022 4th International Conference on Applied Machine Learning (ICAML), P151, DOI 10.1109/ICAML57167.2022.00036; Zhang L, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5243; Zhang Xingxin, 2022, Proceedings of SPIE, V12258, DOI 10.1117/12.2639492; Zhou X, 2019, SCIENTOMETRICS, V121, P699, DOI 10.1007/s11192-019-03218-5	19	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-47639-6; 978-3-031-47640-2	LECT NOTES ARTIF INT			2024	14392						3	15		10.1007/978-3-031-47640-2_1	http://dx.doi.org/10.1007/978-3-031-47640-2_1			13	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4JX					2024-07-03	WOS:001150288400001
J	Patel, CR; Pandya, SK; Sojitra, BM				Patel, Chetna R.; Pandya, Sajal K.; Sojitra, Brijesh M.			Perspectives of ChatGPT in Pharmacology Education, and Research in Health Care: A Narrative Review	JOURNAL OF PHARMACOLOGY & PHARMACOTHERAPEUTICS			English	Review						ChatGPT; pharmacology; healthcare; education; geneGPT; research		Background: In the era of advanced Open artificial intelligence (AI) technology, the large language model tool known as chat generative pre-training transformer (ChatGPT) is gaining an increasing number of users in various fields such as healthcare, medical education, agriculture, and customer support due to its features like information retrieval, generating human-like conversations, and natural language processing. Purpose: The purpose of this narrative review is to present the perspectives of ChatGPT in pharmacology and medical education. And highlight the limitations of ChatGPT in these areas and draw the attention of policymakers in healthcare to implement such technologies while taking into consideration ethical issues. Methods: To collect information regarding the perspectives of ChatGPT in pharmacology and medical education. And highlight the limitations of ChatGPT in these areas. Results: In health care, it helps in the drug discovery and development process, diagnosis, treatment, counseling, assisting in surgical procedures, pharmacovigilance, pharmacy, and so on. In medical education, this tool plays a crucial role in online tutoring, personalized assistance, grading, improvement in grammar, and so on. Despite the limitations, ChatGPT is helpful in healthcare, medical education, and scientific writing. To overcome such limitations of ChatGPT, like ethical issues, emotionlessness, providing information before 2021, the risk of biases, uncontrollability, lack of transparency, academic dishonesty, and so on, alternatives have been developed, but they also fail to entirely resolve the associated limitations. Conclusion: Looking at the current scenarios, there is an urgent need for comprehensive guidelines to address these limitations and provide a framework for appropriately utilizing AI tools in healthcare domains. This framework should also focus on maintaining a balance between human involvement and technological advancements.	[Patel, Chetna R.; Pandya, Sajal K.; Sojitra, Brijesh M.] Govt Med Coll, Dept Pharmacol, Surat, Gujarat, India; [Patel, Chetna R.] Govt Med Coll, Dept Pharmacol, Surat 395001, Gujarat, India		Patel, CR (corresponding author), Govt Med Coll, Dept Pharmacol, Surat 395001, Gujarat, India.	drchetnapatel2012@yahoo.com		Pandya, Dr. Sajal/0009-0000-0363-3960; Sojitra, Dr. Brijeshkumar/0009-0002-2501-7098; Patel, Dr Chetna/0000-0003-4134-3280				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2020, SIMPLILEARN WHAT IS; [Anonymous], 2023, TOP 30 CHATGPT ALTER, P39; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Bates A., IMPLICATIONS CHAT GP; Blanco-González A, 2023, PHARMACEUTICALS-BASE, V16, DOI 10.3390/ph16060891; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Duggal N., 2021, SIMPLILEARN; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Golan R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42214; Ingle P and Mommessin J-M, 2022, MARKTECHPOST; Jairoun AA, 2023, RES SOC ADMIN PHARM, V19, P975, DOI 10.1016/j.sapharm.2023.03.012; JAVA T., POINT APPL; Jin Q., 2023, PREPRINT; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Karabacak M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48163; Koncz A., 2023, MED FUTURIST; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Mijwil MM., 2015, HIST ARTIFICIAL INTE, V3, P1, DOI [10.13140/RG.2.2.16418.15046, DOI 10.13140/RG.2.2.16418.15046]; New drugs and clinical trial rules, CURRENT AFFAIRS; Ocampo TSC, 2023, IMAGNG SCI DENT, V53, P175, DOI 10.5624/isd.20230085; onlinedegrees.sandiego, EX ART INT ED SAND; Quintans LJ, 2023, REV SOC BRAS MED TRO, V56, DOI 10.1590/0037-8682-0060-2023; Roman A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43502; Sharma G., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-qgs3k, DOI 10.26434/CHEMRXIV-2023-QGS3K]; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tickoo A., 2023, MARKTECHPOST; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; VanBuskirk A., 2023, WORDBOT; Wang HY, 2023, DRUG SAFETY, V46, P711, DOI 10.1007/s40264-023-01315-2; Zhao AL, 2023, FRONT PHARMACOL, V14, DOI 10.3389/fphar.2023.1194216	34	1	1	18	18	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0976-500X	0976-5018		J PHARMACOL PHARMACO	J. Pharmacol. Pharmacother.	SEP	2023	14	3					171	177		10.1177/0976500X231210427	http://dx.doi.org/10.1177/0976500X231210427		DEC 2023	7	Pharmacology & Pharmacy	Emerging Sources Citation Index (ESCI)	Pharmacology & Pharmacy	HE7A2		hybrid			2024-07-03	WOS:001130186400001
J	Wright, BM; Bodnar, MS; Moore, AD; Maseda, MC; Kucharik, MP; Diaz, CC; Schmidt, CM; Mir, HR				Wright, B. M.; Bodnar, M. S.; Moore, A. D.; Maseda, M. C.; Kucharik, M. P.; Diaz, C. C.; Schmidt, C. M.; Mir, H. R.			Is ChatGPT a trusted source of information for total hip and knee arthroplasty patients?	BONE & JOINT OPEN			English	Article							TOTAL JOINT ARTHROPLASTY; ORTHOPEDIC SURGEONS; ONLINE INFORMATION; AMERICAN ACADEMY; SEARCH TERM; QUALITY; ACCURACY; INTERNET; READABILITY; COMPREHENSION	Aims While internet search engines have been the primary information source for patients' questions, artificial intelligence large language models like ChatGPT are trending towards becoming the new primary source. The purpose of this study was to determine if ChatGPT can answer patient questions about total hip (THA) and knee arthroplasty (TKA) with consistent accuracy, comprehensiveness, and easy readability. Methods We posed the 20 most Google-searched questions about THA and TKA, plus ten additional postoperative questions, to ChatGPT. Each question was asked twice to evaluate for consistency in quality. Following each response, we responded with, "Please explain so it is easier to understand," to evaluate ChatGPT's ability to reduce response reading grade level, measured as Flesch-Kincaid Grade Level (FKGL). Five resident physicians rated the 120 responses on 1 to 5 accuracy and comprehensiveness scales. Additionally, they answered a "yes" or "no" question regarding acceptability. Mean scores were calculated for each question, and responses were deemed acceptable if >= four raters answered "yes." Results The mean accuracy and comprehensiveness scores were 4.26 (95% confidence interval (CI) 4.19 to 4.33) and 3.79 (95% CI 3.69 to 3.89), respectively. Out of all the responses, 59.2% (71/120; 95% CI 50.0% to 67.7%) were acceptable. ChatGPT was consistent when asked the same question twice, giving no significant difference in accuracy (t = 0.821; p = 0.415), comprehensiveness (t = 1.387; p = 0.171), acceptability (chi 2 = 1.832; p = 0.176), and FKGL (t = 0.264; p = 0.793). There was a significantly lower FKGL (t = 2.204; p = 0.029) for easier responses (11.14; 95% CI 10.57 to 11.71) than original responses (12.15; 95% CI 11.45 to 12.85). Conclusion ChatGPT answered THA and TKA patient questions with accuracy comparable to previous reports of websites, with adequate comprehensiveness, but with limited acceptability as the sole information source. ChatGPT has potential for answering patient questions about THA and TKA, but needs improvement.	[Wright, B. M.; Bodnar, M. S.] Univ S Florida, Morsani Coll Med, Tampa, FL 33620 USA; [Moore, A. D.; Maseda, M. C.; Kucharik, M. P.; Diaz, C. C.; Schmidt, C. M.] Univ S Florida, Dept Orthopaed Surg, Tampa, FL USA; [Mir, H. R.] Florida Orthoped Inst, Orthopaed Trauma Serv, Tampa, FL USA	State University System of Florida; University of South Florida; State University System of Florida; University of South Florida; Florida Orthopaedic Institute	Wright, BM (corresponding author), Univ S Florida, Morsani Coll Med, Tampa, FL 33620 USA.	benjaminwright@usf.edu		Wright, Benjamin/0009-0000-8354-6540; Moore, Andrew/0000-0002-1296-489X				Achiam J, arXiv; Agree EM, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.3352; [Anonymous], New models and developer products announced at DevDay; [Anonymous], 2019, National Cancer Institute: Health Information National Trends Survey 5 Cycle 3; [Anonymous], ChatGPT General FAQ; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Badarudeen S, 2008, J BONE JOINT SURG AM, V90A, P199, DOI 10.2106/JBJS.G.00347; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Burrus M Tyrrell, 2017, HSS J, V13, P271, DOI 10.1007/s11420-017-9568-2; Chang N, 2016, P 3 AAAI C HUMAN COM; Chevalier A, 2015, COMPUT HUM BEHAV, V53, P305, DOI 10.1016/j.chb.2015.07.017; Crozier-Shaw G, 2017, ORTHOPEDICS, V40, pE262, DOI 10.3928/01477447-20161116-02; Doak CC, 1996, American Journal of Nursing; Dy CJ, 2012, J HAND SURG-AM, V37A, P1881, DOI 10.1016/j.jhsa.2012.05.021; Eltorai AEM, 2015, CLIN ORTHOP RELAT R, V473, P1181, DOI 10.1007/s11999-014-4071-2; Fabricant PD, 2013, J PEDIATR ORTHOPED, V33, P361, DOI 10.1097/BPO.0b013e31827d0dd2; Fraval A, 2012, AUSTRALAS MED J, V5, P633, DOI 10.4066/AMJ.2012.1530; Friedman DB, 2006, HEALTH EDUC BEHAV, V33, P352, DOI 10.1177/1090198105277329; Garcia GH, 2014, J BONE JOINT SURG AM, V96A, DOI 10.2106/JBJS.M.01228; Hadeed MM, 2017, J ORTHOP TRAUMA, V31, pE96, DOI 10.1097/BOT.0000000000000746; Hällfors E, 2018, J ARTHROPLASTY, V33, P650, DOI 10.1016/j.arth.2017.10.040; Hautala GS, 2021, INJURY, V52, P3299, DOI 10.1016/j.injury.2021.02.029; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hu K., 2023, Reuters; Johnson D, 2023, Res Sq.; Kher Akhil, 2017, Adv Prev Med, V2017, P9780317, DOI 10.1155/2017/9780317; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; Mathur S, 2005, SPINE, V30, P2695, DOI 10.1097/01.brs.0000188266.22041.c2; Medenilla A., 2023, PLoS Digital Health, V2; Ouyang L., 2022, ARXIV; Parmar P, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00560-6; Polisetty TS, 2022, BONE JOINT J, V104B, P1292, DOI 10.1302/0301-620X.104B12.BJJ-2022-0922.R1; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Shakir U., The Verge; Shen TS, 2021, J ARTHROPLASTY, V36, P1224, DOI 10.1016/j.arth.2020.10.024; Siddiqi A, 2022, ARTHROPLAST TODAY, V13, P205, DOI 10.1016/j.artd.2022.01.020; SPANDORFER JM, 1995, ANN EMERG MED, V25, P71, DOI 10.1016/S0196-0644(95)70358-6; Wang DA, 2017, CARTILAGE, V8, P112, DOI 10.1177/1947603516648737; Whalen S, 2016, METHODS, V93, P92, DOI 10.1016/j.ymeth.2015.08.016; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zade RT, 2020, JAAOS GLOB RES REV, V4, DOI 10.5435/JAAOSGlobal-D-19-00181	41	0	0	3	3	BRITISH EDITORIAL SOC BONE & JOINT SURGERY	LONDON	22 BUCKINGHAM ST, LONDON, WC2N 6ET, ENGLAND	2633-1462			BONE JOINT OPEN	Bone Joint Open	FEB	2024	5	2					139	146		10.1302/2633-1462.52.BJO-2023-0113.R1	http://dx.doi.org/10.1302/2633-1462.52.BJO-2023-0113.R1			8	Orthopedics	Emerging Sources Citation Index (ESCI)	Orthopedics	HV0Z7	38354748	gold, Green Published			2024-07-03	WOS:001162177700001
J	Nadeem, M; Sohail, SS; Javed, L; Anwer, F; Saudagar, AKJ; Muhammad, K				Nadeem, Mohammad; Sohail, Shahab Saquib; Javed, Laeeba; Anwer, Faisal; Saudagar, Abdul Khader Jilani; Muhammad, Khan			Vision-Enabled Large Language and Deep Learning Models for Image-Based Emotion Recognition	COGNITIVE COMPUTATION			English	Article; Early Access						Large language models; Deep learning; Generative artificial intelligence; Emotion recognition; ChatGPT	AI	The significant advancements in the capabilities, reasoning, and efficiency of artificial intelligence (AI)-based tools and systems are evident. Some noteworthy examples of such tools include generative AI-based large language models (LLMs) such as generative pretrained transformer 3.5 (GPT 3.5), generative pretrained transformer 4 (GPT-4), and Bard. LLMs are versatile and effective for various tasks such as composing poetry, writing codes, generating essays, and solving puzzles. Thus far, LLMs can only effectively process text-based input. However, recent advancements have enabled them to handle multimodal inputs, such as text, images, and audio, making them highly general-purpose tools. LLMs have achieved decent performance in pattern recognition tasks (such as classification), therefore, there is a curiosity about whether general-purpose LLMs can perform comparable or even superior to specialized deep learning models (DLMs) trained specifically for a given task. In this study, we compared the performances of fine-tuned DLMs with those of general-purpose LLMs for image-based emotion recognition. We trained DLMs, namely, a convolutional neural network (CNN) (two CNN models were used: CNN1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$CNN_1$$\end{document} and CNN2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$CNN_2$$\end{document}), ResNet50, and VGG-16 models, using an image dataset for emotion recognition, and then tested their performance on another dataset. Subsequently, we subjected the same testing dataset to two vision-enabled LLMs (LLaVa and GPT-4). The CNN2\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$CNN_2$$\end{document} was found to be the superior model with an accuracy of 62% while VGG16 produced the lowest accuracy with 31%. In the category of LLMs, GPT-4 performed the best, with an accuracy of 55.81%. LLava LLM had a higher accuracy than CNN1\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$CNN_1$$\end{document} and VGG16 models. The other performance metrics such as precision, recall, and F1-score followed similar trends. However, GPT-4 performed the best with small datasets. The poor results observed in LLMs can be attributed to their general-purpose nature, which, despite extensive pretraining, may not fully capture the features required for specific tasks like emotion recognition in images as effectively as models fine-tuned for those tasks. The LLMs did not surpass specialized models but achieved comparable performance, making them a viable option for specific tasks without additional training. In addition, LLMs can be considered a good alternative when the available dataset is small.	[Nadeem, Mohammad; Javed, Laeeba; Anwer, Faisal] Aligarh Muslim Univ, Dept Comp Sci, Aligarh, India; [Sohail, Shahab Saquib] VIT Bhopal Univ, Sch Comp Sci & Engn, Sehore 466114, MP, India; [Saudagar, Abdul Khader Jilani] Imam Mohammad Ibn Saud Islamic Univ IMSIU, Coll Comp & Informat Sci, Informat Syst Dept, Riyadh 11432, Saudi Arabia; [Muhammad, Khan] Sungkyunkwan Univ, Coll Comp & Informat, Dept Appl Artificial Intelligence, Visual Analyt Knowledge Lab VIS2KNOW Lab, Seoul 03063, South Korea	Aligarh Muslim University; VIT Bhopal University; Imam Mohammad Ibn Saud Islamic University (IMSIU); Sungkyunkwan University (SKKU)	Muhammad, K (corresponding author), Sungkyunkwan Univ, Coll Comp & Informat, Dept Appl Artificial Intelligence, Visual Analyt Knowledge Lab VIS2KNOW Lab, Seoul 03063, South Korea.	khan.muhammad@ieee.org	sohail, shahab/O-3263-2019	sohail, shahab/0000-0002-5944-7371	Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University (IMSIU) [IMSIU-RP23058]	Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University (IMSIU)	This work was supported and funded by the Deanship of Scientific Research at Imam Mohammad Ibn Saud Islamic University (IMSIU) (grant number IMSIU-RP23058).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amin MM, 2023, IEEE INTELL SYST, V38, P15, DOI 10.1109/MIS.2023.3254179; Amin MM, 2023, IEEE INTELL SYST, V38, P5, DOI 10.1109/MIS.2023.3305861; Areeb QM, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1512; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Bodapati J.D., 2019, Int J Innov Technol Explor Eng, V8, P1928; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chamola V, 2023, Arxiv, DOI [arXiv:2308.06272, 10.48550/arxiv.2308.06272, DOI 10.48550/ARXIV.2308.06272]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdary MK, 2023, NEURAL COMPUT APPL, V35, P23311, DOI 10.1007/s00521-021-06012-8; Devi DAS, 2023, MULTIMED TOOLS APPL, V82, P18669, DOI 10.1007/s11042-022-14186-z; Dhruv Patel, 2020, Machine Learning and Information Processing. Proceedings of ICMLIP 2019. Advances in Intelligent Systems and Computing (AISC 1101), P367, DOI 10.1007/978-981-15-1884-3_34; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Elliott EA, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00115; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9; Feng ST, 2023, Arxiv, DOI arXiv:2309.12881; Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16; Hassija V, 2023, IEEE ACCESS, V11, P143657, DOI 10.1109/ACCESS.2023.3339553; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Lakshmi D, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103834; Lammerse M., 2022, 2022 14th International Conference on Quality of Multimedia Experience (QoMEX), P1; Lazarus RS, 2006, J PERS, V74, P9, DOI 10.1111/j.1467-6494.2005.00368.x; Lei SL, 2024, Arxiv, DOI arXiv:2309.11911; Li HD, 2020, KNOWL-BASED SYST, V204, DOI 10.1016/j.knosys.2020.106172; Liu H., 2024, Adv. Neural Inf. Process. Syst., V36; Loh E, 2024, BMJ LEAD, V8, P51, DOI 10.1136/leader-2023-000797; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mishra S, 2022, LECT NOTE DATA ENG, V68, P301, DOI 10.1007/978-981-16-1866-6_22; Mosaiyebzadeh F, 2023, P 24 ANN C INF TECHN, P84; Norden F, 2019, A comparative analysis of machine learning algorithms in binary facial expression recognition; O'Leary DE, 2023, INTELL SYST ACCOUNT, V30, P41, DOI 10.1002/isaf.1531; Patrinos GP, 2023, PHARMACOGENOMICS J, V23, P178, DOI 10.1038/s41397-023-00316-9; Radford A, 2021, PR MACH LEARN RES, V139; Ravi A, 2018, Arxiv, DOI arXiv:1812.06387; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rescigno M, 2020, MULTIMED TOOLS APPL, V79, P35811, DOI 10.1007/s11042-020-09405-4; Sai S, 2024, COGN COMPUT, V16, P482, DOI 10.1007/s12559-023-10219-3; Sashida Masaki, 2023, 2023 14th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI), P742, DOI 10.1109/IIAI-AAI59060.2023.00158; Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802; Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516-044442, 10.1146/annurev-bioeng-071516044442]; Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sohail SS, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101675; Sultana F, 2018, 2018 FOURTH IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P122, DOI 10.1109/ICRCICN.2018.8718718; Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Taylor R, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tseng SY, 2021, IEEE SIGNAL PROC LET, V28, P608, DOI 10.1109/LSP.2021.3065598; Wang YY, 2019, ALGORITHMS, V12, DOI 10.3390/a12110227; Yosinski J, 2014, ADV NEUR IN, V27; Zhang H, 2023, Arxiv, DOI [arXiv:2306.02858, 10.48550/arXiv.2306.02858, DOI 10.48550/ARXIV.2306.02858]; Zhao B, 2023, NEUROCOMPUTING, V557, DOI 10.1016/j.neucom.2023.126708	56	0	0	4	4	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1866-9956	1866-9964		COGN COMPUT	Cogn. Comput.	2024 MAY 27	2024										10.1007/s12559-024-10281-5	http://dx.doi.org/10.1007/s12559-024-10281-5		MAY 2024	14	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Neurosciences & Neurology	SC2E1					2024-07-03	WOS:001232186300001
J	Alessandri-Bonetti, M; Liu, HY; Donovan, JM; Ziembicki, JA; Egro, FM				Alessandri-Bonetti, Mario; Liu, Hilary Y.; Donovan, James M.; Ziembicki, Jenny A.; Egro, Francesco M.			A Comparative Analysis of ChatGPT, ChatGPT-4, and Google Bard Performances at the Advanced Burn Life Support Exam	JOURNAL OF BURN CARE & RESEARCH			English	Article; Early Access						artificial intelligence; chatgpt; burn; education		Artificial intelligence and large language models (LLMs) have recently gained attention as promising tools in various healthcare domains, offering potential benefits in clinical decision-making, medical education, and research. The Advanced Burn Life Support (ABLS) program is a didactic initiative endorsed by the American Burn Association, aiming to provide knowledge on the immediate care of severely burn patients. The aim of the study was to compare the performance of three LLMs (ChatGPT-3.5, ChatGPT-4, and Google Bard) on the ABLS exam. The ABLS exam consists of 50 questions with 5 multiple-choice answers. The passing threshold is 80% of correct answers. The 3 LLMs were queried with the 50 questions included in the latest version of the ABLS exam, on July 18th, 2023. ChatGPT-3.5 scored 86% (43 out of 50), ChatGPT-4 scored 90% (45 out of 50), and Bard scored 70% (35 out of 50). No difference was measured between ChatGPT-3.5 and ChatGPT-4 (P = .538) and between ChatGPT-3.5 and Bard (P = .054), despite the borderline P-value. ChatGPT-4 performed significantly better than Bard (P = .012). Out of the 50 questions, 78% (n = 39) were direct questions, while 12% (n = 11) were presented as clinical scenarios. No difference in the rate of wrong answers was found based on the type of question for the 3 LLMs. ChatGPT-3.5 and ChatGPT-4 demonstrated high accuracy at the ABLS exam and outperformed Google Bard. However, the potential multiple applications of LLMs in emergency burn and trauma care necessitate appropriate surveillance and most likely should represent a tool to complement human cognition.	[Alessandri-Bonetti, Mario; Liu, Hilary Y.; Egro, Francesco M.] Univ Pittsburgh, Med Ctr, Dept Plast Surg, Pittsburgh, PA 15213 USA; [Donovan, James M.; Ziembicki, Jenny A.; Egro, Francesco M.] Univ Pittsburgh, Med Ctr, Dept Surg, Pittsburgh, PA 15213 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Egro, FM (corresponding author), Univ Pittsburgh, Med Ctr, Dept Plast Surg, Pittsburgh, PA 15213 USA.; Egro, FM (corresponding author), Univ Pittsburgh, Med Ctr, Dept Surg, Pittsburgh, PA 15213 USA.	francescoegro@gmail.com						Advanced Burn Life Support (ABLS), American Burn Association; Alessandri-Bonetti M, 2023, J PLAST RECONSTR AES, V87, P390, DOI 10.1016/j.bjps.2023.10.091; Alessandri-Bonetti M, 2024, ANN BIOMED ENG, V52, P1551, DOI 10.1007/s10439-023-03372-1; Alessandri-Bonetti M, 2024, ANN BIOMED ENG, V52, P1107, DOI 10.1007/s10439-023-03325-8; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Bonetti MA, 2024, ANN BIOMED ENG, V52, P745, DOI 10.1007/s10439-023-03318-7; cdn.openai, About us; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Giorgino R, 2023, FRONT SURG, V10, DOI 10.3389/fsurg.2023.1284015; Jeong T, 2023, MICROSURG, V43, P752, DOI 10.1002/micr.31106; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liao ZQ, 2024, ANN BIOMED ENG, V52, P125, DOI 10.1007/s10439-023-03288-w; Liu HY, 2024, AESTHET PLAST SURG, V48, P590, DOI 10.1007/s00266-023-03713-4; Liu HY, 2024, AESTHET PLAST SURG, V48, P1644, DOI 10.1007/s00266-023-03709-0; Liu HY, 2023, J PLAST RECONSTR AES, V85, P488, DOI 10.1016/j.bjps.2023.07.039; Norbury W, 2016, SURG INFECT, V17, P250, DOI 10.1089/sur.2013.134; Ong YS, 2006, BURNS, V32, P145, DOI 10.1016/j.burns.2005.09.005	18	0	0	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1559-047X	1559-0488		J BURN CARE RES	J. Burn Care Res.	2024 JUN 4	2024										10.1093/jbcr/irae044	http://dx.doi.org/10.1093/jbcr/irae044		JUN 2024	4	Critical Care Medicine; Dermatology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Dermatology; Surgery	TE5B5	38833383				2024-07-03	WOS:001239588200001
J	Isleem, UN; Zaidat, B; Ren, RE; Geng, EA; Burapachaisri, A; Tang, JE; Kim, JS; Cho, SK				Isleem, Ula N.; Zaidat, Bashar; Ren, Renee; Geng, Eric A.; Burapachaisri, Aonnicha; Tang, Justin E.; Kim, Jun S.; Cho, Samuel K.			Can generative artificial intelligence pass the orthopaedic board examination?	JOURNAL OF ORTHOPAEDICS			English	Article							IN-TRAINING EXAMINATION; QUESTIONS	Background: Resident training programs in the US use the Orthopaedic In -Training Examination (OITE) developed by the American Academy of Orthopaedic Surgeons (AAOS) to assess the current knowledge of their residents and to identify the residents at risk of failing the Amerian Board of Orthopaedic Surgery (ABOS) examination. Optimal strategies for OITE preparation are constantly being explored. There may be a role for Large Language Models (LLMs) in orthopaedic resident education. ChatGPT, an LLM launched in late 2022 has demonstrated the ability to produce accurate, detailed answers, potentially enabling it to aid in medical education and clinical decision -making. The purpose of this study is to evaluate the performance of ChatGPT on Orthopaedic In -Training Examinations using SelfAssessment Exams from the AAOS database and approved literature as a proxy for the Orthopaedic Board Examination. Methods: 301 SAE questions from the AAOS database and associated AAOS literature were input into ChatGPT's interface in a question and multiple-choice format and the answers were then analyzed to determine which answer choice was selected. A new chat was used for every question. All answers were recorded, categorized, and compared to the answer given by the OITE and SAE exams, noting whether the answer was right or wrong. Results: Of the 301 questions asked, ChatGPT was able to correctly answer 183 (60.8%) of them. The subjects with the highest percentage of correct questions were basic science (81%), oncology (72.7%, shoulder and elbow (71.9%), and sports (71.4%). The questions were further subdivided into 3 groups: those about management, diagnosis, or knowledge recall. There were 86 management questions and 47 were correct (54.7%), 45 diagnosis questions with 32 correct (71.7%), and 168 knowledge recall questions with 102 correct (60.7%). Conclusions: ChatGPT has the potential to provide orthopedic educators and trainees with accurate clinical conclusions for the majority of board -style questions, although its reasoning should be carefully analyzed for accuracy and clinical validity. As such, its usefulness in a clinical educational context is currently limited but rapidly evolving. Clinical relevance: ChatGPT can access a multitude of medical data and may help provide accurate answers to clinical questions.	[Isleem, Ula N.; Zaidat, Bashar; Ren, Renee; Geng, Eric A.; Burapachaisri, Aonnicha; Tang, Justin E.; Kim, Jun S.; Cho, Samuel K.] Icahn Sch Med Mt Sinai, Dept Orthopaed Surg, New York, NY USA; [Cho, Samuel K.] 787 11th Ave,7th Fl, New York, NY 10019 USA	Icahn School of Medicine at Mount Sinai	Cho, SK (corresponding author), 787 11th Ave,7th Fl, New York, NY 10019 USA.	samuel.cho@mountsinai.org		Cho, Samuel/0000-0001-7511-2486; Tang, Justin/0000-0003-4544-3262; Ren, Renee/0000-0002-2740-940X; Zaidat, Bashar/0000-0002-8823-720X				Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Arora Anmol, 2022, Future Healthc J, V9, P190, DOI 10.7861/fhj.2022-0013; Bernstein J, 2022, Clin Orthop Relat Res, V10, P10; Bertini A, 2022, Front Bioeng Biotechnol, V9, P1385; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Byrne MF, 2019, GUT, V68, P94, DOI 10.1136/gutjnl-2017-314547; Cho BH, 2020, GLOB SPINE J, V10, P611, DOI 10.1177/2192568219868190; Ellsworth BK, 2020, J PEDIATR ORTHOPED, V40, pE1017, DOI 10.1097/BPO.0000000000001663; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Grandizio Louis C, 2016, Hand (N Y), V11, P484, DOI 10.1177/1558944715620793; Harris AHS, 2019, CLIN ORTHOP RELAT R, V477, P452, DOI 10.1097/CORR.0000000000000601; Kallianos K, 2019, CLIN RADIOL, V74, P338, DOI 10.1016/j.crad.2018.12.015; Karhade AV, 2020, SPINE J, V20, P695, DOI 10.1016/j.spinee.2019.12.006; Kim Junhyuk, 2022, SAE Technical Papers, P2022, DOI 10.4271/2022-01-0072; Lebrun DG, 2022, HAND-AM ASSOC HAND S, V17, P975, DOI 10.1177/1558944720964960; Liu F, 2018, MAGN RESON MED, V79, P2379, DOI 10.1002/mrm.26841; Ljubic B, 2020, J AM MED INFORM ASSN, V27, P1343, DOI 10.1093/jamia/ocaa120; Muehlematter UJ, 2019, EUR RADIOL, V29, P2207, DOI 10.1007/s00330-018-5846-8; Murphy RF, 2017, J PEDIATR ORTHOPED, V37, pE394, DOI 10.1097/BPO.0000000000000913; Oosterhoff JHF, 2021, GERIATR ORTHOP SURG, V12, DOI 10.1177/21514593211062277; Open AI, 2022, ChatGPT; Osbahr Daryl C, 2012, Am J Orthop (Belle Mead NJ), V41, P63; Premkumar A, 2021, J ARTHROPLASTY, V36, P1156, DOI 10.1016/j.arth.2020.09.018; Shen TS, 2021, J AM ACAD ORTHOP SUR, V29, pE1225, DOI 10.5435/JAAOS-D-20-00862; Straw I, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240376; Tang JE, 2021, Spine Deformity, V2, P1; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang H, Efficient Natural Language Processing	28	0	0	8	8	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0972-978X			J ORTHOP	J. Orthop.	JUL	2024	53						27	33		10.1016/j.jor.2023.10.026	http://dx.doi.org/10.1016/j.jor.2023.10.026		MAR 2024	7	Orthopedics	Emerging Sources Citation Index (ESCI)	Orthopedics	NU2C7	38450060				2024-07-03	WOS:001202893000001
J	Li, H; Zhang, RW; Lee, YC; Kraut, RE; Mohr, DC				Li, Han; Zhang, Renwen; Lee, Yi-Chieh; Kraut, Robert E.; Mohr, David C.			Systematic review and meta-analysis of AI-based conversational agents for promoting mental health and well-being	NPJ DIGITAL MEDICINE			English	Review							EFFICACY; CHATBOT; INTERVENTIONS; MODELS; ROBOT	Conversational artificial intelligence (AI), particularly AI-based conversational agents (CAs), is gaining traction in mental health care. Despite their growing usage, there is a scarcity of comprehensive evaluations of their impact on mental health and well-being. This systematic review and meta-analysis aims to fill this gap by synthesizing evidence on the effectiveness of AI-based CAs in improving mental health and factors influencing their effectiveness and user experience. Twelve databases were searched for experimental studies of AI-based CAs' effects on mental illnesses and psychological well-being published before May 26, 2023. Out of 7834 records, 35 eligible studies were identified for systematic review, out of which 15 randomized controlled trials were included for meta-analysis. The meta-analysis revealed that AI-based CAs significantly reduce symptoms of depression (Hedge's g 0.64 [95% CI 0.17-1.12]) and distress (Hedge's g 0.7 [95% CI 0.18-1.22]). These effects were more pronounced in CAs that are multimodal, generative AI-based, integrated with mobile/instant messaging apps, and targeting clinical/subclinical and elderly populations. However, CA-based interventions showed no significant improvement in overall psychological well-being (Hedge's g 0.32 [95% CI -0.13 to 0.78]). User experience with AI-based CAs was largely shaped by the quality of human-AI therapeutic relationships, content engagement, and effective communication. These findings underscore the potential of AI-based CAs in addressing mental health issues. Future research should investigate the underlying mechanisms of their effectiveness, assess long-term effects across various mental health outcomes, and evaluate the safe integration of large language models (LLMs) in mental health care.	[Li, Han; Zhang, Renwen] Natl Univ Singapore, Dept Commun & New Media, Singapore 117416, Singapore; [Lee, Yi-Chieh] Natl Univ Singapore, Dept Comp Sci, Singapore 117416, Singapore; [Kraut, Robert E.] Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA 15213 USA; [Mohr, David C.] Northwestern Univ, Ctr Behav Intervent Technol, Dept Prevent Med, Chicago, IL 60611 USA	National University of Singapore; National University of Singapore; Carnegie Mellon University; Northwestern University	Zhang, RW (corresponding author), Natl Univ Singapore, Dept Commun & New Media, Singapore 117416, Singapore.	r.zhang@nus.edu.sg	LI, HAN/KIA-8718-2024	LI, HAN/0000-0002-9050-715X; Mohr, David/0000-0002-5443-7596; Zhang, Renwen/0000-0002-7636-9598	U.S. Department of Health & Human Services | NIH | National Institute of Mental Health (NIMH) [Tier 1 A-8000877-00-00]; Singapore Ministry of Education Academic Research Fund [A-8000936-01-00]; National University of Singapore [P50 MH119029]; NIMH	U.S. Department of Health & Human Services | NIH | National Institute of Mental Health (NIMH); Singapore Ministry of Education Academic Research Fund(Ministry of Education, Singapore); National University of Singapore(National University of Singapore); NIMH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Mental Health (NIMH))	The present study is supported by the Singapore Ministry of Education Academic Research Fund Tier 1 A-8000877-00-00, National University of Singapore Start-up Grant A-8000936-01-00, and NIMH grant P50 MH119029. The funders of the study had no role in the study design, data collection, data analysis, data interpretation, or writing of the manuscript.	Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Abd-Alrazaq AA, 2020, J MED INTERNET RES, V22, DOI 10.2196/16021; Abdollahi H, 2017, 2017 IEEE-RAS 17TH INTERNATIONAL CONFERENCE ON HUMANOID ROBOTICS (HUMANOIDS), P541, DOI 10.1109/HUMANOIDS.2017.8246925; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Assink M, 2016, QUANT METH PSYCHOL, V12, P154, DOI 10.20982/tqmp.12.3.p154; Bassi G, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/32211; Bennion MR, 2020, J MED INTERNET RES, V22, DOI 10.2196/16794; Bird T, 2018, BEHAV COGN PSYCHOTH, V46, P570, DOI 10.1017/S1352465817000820; Charlson F, 2019, LANCET, V394, P240, DOI 10.1016/S0140-6736(19)30934-1; Chiauzzi E., 2023, PREPRINT, DOI [10.21203/rs.3.rs-2488688/v1, DOI 10.21203/RS.3.RS-2488688/V1]; Cho E, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300488; COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155; Cuijpers P, 2020, JAMA PSYCHIAT, V77, P694, DOI 10.1001/jamapsychiatry.2020.0164; Daley K, 2020, FRONT DIGIT HEALTH, V2, DOI 10.3389/fdgth.2020.576361; De Nieva J. O., 2020, 6 INT ACM IN COOPERA; Demirci H., 2018, User experience over time with conversational agents case study of woebot on supporting subjective well-being; Dingler Tilman, 2021, Yearb Med Inform, V30, P191, DOI 10.1055/s-0041-1726510; Driessen E, 2010, J CONSULT CLIN PSYCH, V78, P668, DOI 10.1037/a0020570; Drouin M, 2022, COMPUT HUM BEHAV, V128, DOI 10.1016/j.chb.2021.107100; Druga S, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2017), P595, DOI 10.1145/3078072.3084330; Firth J, 2017, WORLD PSYCHIATRY, V16, P287, DOI 10.1002/wps.20472; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Fulmer R, 2018, JMIR MENT HEALTH, V5, DOI 10.2196/mental.9782; Gamborino E, 2019, IEEE ROMAN, DOI 10.1109/ro-man46459.2019.8956460; Goga N, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010133; Guyatt GH, 2008, BRIT MED J, V336, P924, DOI 10.1136/bmj.39489.470347.AD; Hak T., 2016, How to Interpret Results of meta-Analysis.; He YH, 2023, J MED INTERNET RES, V25, DOI 10.2196/43862; He YH, 2022, J MED INTERNET RES, V24, DOI 10.2196/40719; Higgins JPT, 2020, COCHRANE HDB SYSTEMA; Higgins JPT, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d5928; Inkster B, 2018, JMIR MHEALTH UHEALTH, V6, DOI 10.2196/12106; Jabir AI, 2023, J MED INTERNET RES, V25, DOI 10.2196/44548; Klos MC, 2021, JMIR FORM RES, V5, DOI 10.2196/20678; Koutsouleris N, 2022, LANCET DIGIT HEALTH, V4, pe829, DOI 10.1016/S2589-7500(22)00153-4; Legaspi C. M., 2023, AS HCI S 22, P52; Leo AJ, 2022, JMIR FORM RES, V6, DOI 10.2196/36203; Leo AJ, 2022, JMIR FORM RES, V6, DOI 10.2196/34889; Lim SM, 2022, BEHAV THER, V53, P334, DOI 10.1016/j.beth.2021.09.007; Linardon J, 2019, WORLD PSYCHIATRY, V18, P325, DOI 10.1002/wps.20673; Liu H, 2022, INTERNET INTERV, V27, DOI 10.1016/j.invent.2022.100495; Loveys K, 2022, INT J HUM-COMPUT ST, V160, DOI 10.1016/j.ijhcs.2021.102771; Loveys K, 2019, J MED INTERNET RES, V21, DOI 10.2196/13664; Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636; Macdonald G, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001930.pub3; Massetti GM, 2017, AM J PREV MED, V53, pS30, DOI 10.1016/j.amepre.2017.04.023; May R, 2022, INFORM HEALTH SOC CA, V47, P194, DOI 10.1080/17538157.2021.1983578; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Nicol G, 2022, JMIR FORM RES, V6, DOI 10.2196/40242; O'Brien HL, 2008, J AM SOC INF SCI TEC, V59, P938, DOI 10.1002/asi.20801; Ogawa M, 2022, PARKINSONISM RELAT D, V99, P43, DOI 10.1016/j.parkreldis.2022.04.018; Papadopoulos C, 2022, INT J SOC ROBOT, V14, P245, DOI 10.1007/s12369-021-00781-x; Pham M, 2021, IEEE ROBOT AUTOM LET, V6, P4040, DOI 10.1109/LRA.2021.3067867; Prochaska JJ, 2021, DRUG ALCOHOL DEPEN, V227, DOI 10.1016/j.drugalcdep.2021.108986; Prochaska JJ, 2021, J MED INTERNET RES, V23, DOI 10.2196/24850; Rathnayaka P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103653; Romanovskyi O., 2021, COLINS 5 INT C COMP, P1215; Sabour S, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1133987; Scoglio AAJ, 2019, J MED INTERNET RES, V21, DOI 10.2196/13322; Sezgin E, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00332-0; Singh B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00856-1; Tawfik E, 2023, BMC NURS, V22, DOI 10.1186/s12912-023-01243-7; Terblanche N, 2022, INT J EVID BASED COA, V20, P20, DOI 10.24384/5cgf-ab69; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Trappey AJC, 2022, PROCESSES, V10, DOI 10.3390/pr10050930; Tulsulkar G, 2021, VISUAL COMPUT, V37, P3019, DOI 10.1007/s00371-021-02242-y; Vaidyam AN, 2021, CAN J PSYCHIAT, V66, P339, DOI 10.1177/0706743720966429; van Agteren J, 2021, NAT HUM BEHAV, V5, P631, DOI 10.1038/s41562-021-01093-w; Vertsberger Dana, 2022, JMIR AI, V1, pe38171, DOI 10.2196/38171; Viertiö S, 2021, BMC PUBLIC HEALTH, V21, DOI 10.1186/s12889-021-10560-y; Wampold BE, 2015, WORLD PSYCHIATRY, V14, P270, DOI 10.1002/wps.20238; Wang L., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2107.13115, 10.48550/arXiv.2107.13115]; Wrightson-Hester AR, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/46849	75	5	5	89	89	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2398-6352			NPJ DIGIT MED	npj Digit. Med.	DEC 19	2023	6	1							236	10.1038/s41746-023-00979-5	http://dx.doi.org/10.1038/s41746-023-00979-5			14	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	DD0G4	38114588	gold			2024-07-03	WOS:001129970300001
J	Schulte, B				Schulte, Brian			Capacity of ChatGPT to Identify Guideline-Based Treatments for Advanced Solid Tumors	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						targeted therapy; immunotherapy; chemotherapy; cancer; nccn guidelines; oncology; chatgpt	INTELLIGENCE	Background: ChatGPT, created by OpenAI, is a large language model which has become the fastest growing consumer application in history, recognized for its expansive knowledge of varied subjects. The field of oncology is highly specialized and requires nuanced understanding of medications and conditions. Herein, we sought to better qualify the ability of ChatGPT to name applicable treatments for patients with advanced solid cancers.Methods: This observational study was conducted utilizing ChatGPT. The capacity of ChatGPT to tabulate appropriate systemic therapies for new diagnoses of advanced solid malignancies was ascertained through standardized prompts. A ratio of those medications listed by ChatGPT to those suggested in the National Comprehensive Cancer Network (NCCN) guidelines was produced and called the valid therapy quotient (VTQ). Additional descriptive analyses of the VTQ and its association with incidence and type of treatment were performed.Results: Some 51 distinct diagnoses were utilized within this experiment. ChatGPT was able to identify 91 distinct medications in response to prompts related to advanced solid tumors. The overall VTQ is 0.77. In all cases, ChatGPT was able to provide at least one example of systemic therapy suggested by the NCCN. There was a weak association between incidence of each malignancy and the VTQ.Conclusion: The capacity of ChatGPT to identify medications used to treat advanced solid tumors indicates a level of concordance with the NCCN guidelines. As it stands, the role of ChatGPT to assist oncologists and patients in treatment decision making remains unknown. Nonetheless, in future iterations, it may be anticipated that accuracy and consistency in this domain will improve, and further studies will be needed to better quantify its capabilities.	[Schulte, Brian] Univ Calif San Francisco, Med, San Francisco, CA 94143 USA	University of California System; University of California San Francisco	Schulte, B (corresponding author), Univ Calif San Francisco, Med, San Francisco, CA 94143 USA.	brian.schulte@ucsf.edu						[Anonymous], 2023, INTRO CHATGPT PLUS; [Anonymous], 2023, PROXIMAL POLICY OPTI; [Anonymous], 2023, EUROPEAN SOC MED ONC; [Anonymous], 2023, National Comprehensive Cancer Network Clinical Practice Guidelines in Oncology Version 4: Non-Small Cell Lung Cancer; [Anonymous], 2023, AM SOC CLIN ONCOLOGY; Antsaklis PJ, 2018, J INTELL ROBOT SYST, V91, P23, DOI 10.1007/s10846-018-0832-6; Bakhtin A, 2022, SCIENCE, V378, P1067, DOI 10.1126/science.ade9097; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bortolan G., 1991, Proceedings. Computers in Cardiology (Cat. No.91CH3116-1), P177, DOI 10.1109/CIC.1991.169074; Cacciamani GE, 2023, NAT MED, V29, P14, DOI 10.1038/s41591-022-02139-w; ChatGPT, 2023, OPTIMIZING LANGUAGE; Hauke J, 2011, QUAEST GEOGR, V30, P87, DOI 10.2478/v10117-011-0021-1; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; James CA, 2022, JAMA-J AM MED ASSOC, V327, P1333, DOI 10.1001/jama.2022.3580; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Microsoft's new AI chatbot has been saying some, 2023, CRAZY UNHINGED THING; Pangaro L, 1999, ACAD MED, V74, P1203, DOI 10.1097/00001888-199911000-00012; Siegel RL, 2023, CA-CANCER J CLIN, V73, P17, DOI 10.3322/caac.21763; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Vasey B, 2022, NAT MED, V28, P924, DOI 10.1038/s41591-022-01772-9	20	18	18	7	18	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	APR 21	2023	15	4							e37938	10.7759/cureus.37938	http://dx.doi.org/10.7759/cureus.37938			8	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	H4UE2	37220429	gold, Green Published			2024-07-03	WOS:000995922600030
J	Amoore, L; Campolo, A; Jacobsen, B; Rella, L				Amoore, Louise; Campolo, Alexander; Jacobsen, Benjamin; Rella, Ludovico			A world model: On the political logics of generative AI	POLITICAL GEOGRAPHY			English	Article								The computational logics of large language models (LLMs) or generative AI - from the early models of CLIP and BERT to the explosion of text and image generation via ChatGPT and DALL-E - are increasingly penetrating the social and political world. Not merely in the direct sense that generative AI models are being deployed to govern difficult problems, whether decisions on the battlefield or responses to pandemic, but also because generative AI is shaping and delimiting the political parameters of what can be known and actioned in the world. Contra the promise of a generalizable "world model" in computer science, the article addresses how and why generative AI gives rise to a model of the world, and with it a set of political logics and governing rationalities that have profound and enduring effects on how we live today. The article traces the genealogies of generative AI models, how they have come into being, and why some concepts and techniques that animate these models become durable forms of knowledge that actively shape the world, even long after a specific material commercial GPT model has moved on to a new iteration. Though generative AI retains significant traces of former scientific and computational regimes - in statistical practices, probabilistic knowledge, and so on - it is also dislocating epistemological arrangements and opening them to novel ways of perceiving, characterising, classifying, and knowing the world. Four defining aspects of the political logic of generative AI are elaborated: i) generativity as something more than the capacity to generate image or text outputs, so that a generative logic acts upon the world understood as estimates of "underlying distributions" in data; ii) latency as a political logic of compression in which (by contrast with claims to reduction or distortion) the thing that is hidden, unknown or latent becomes surfaced and amenable to being governed; iii) broken and parallelized sequences as the ordering device of the political logic of generative AI, where attention frameworks radically change the possibilities for governing non-linear problems; iv) pretraining and fine-tuning as a computational logic of generative AI that simultaneously shapes a "zero shot politics" oriented towards unencountered data and new tasks. Across each of the four aspects, the article maps the emerging contemporary political logic of generative AI.	[Amoore, Louise; Campolo, Alexander; Rella, Ludovico] Univ Durham, Dept Geog, Durham, England; [Jacobsen, Benjamin] York Univ, Dept Sociol, York, England	Durham University; University of York - UK	Amoore, L (corresponding author), Univ Durham, Dept Geog, Durham, England.	louise.amoore@durham.ac.uk		Rella, Ludovico/0000-0001-5468-9526	European Research Council (ERC) under Horizon 2020, Advanced Investigator Grant [ERC- 2019-ADG-883107-ALGOSOC]	European Research Council (ERC) under Horizon 2020, Advanced Investigator Grant(European Research Council (ERC))	The research has received funding from the European Research Council (ERC) under Horizon 2020, Advanced Investigator Grant ERC- 2019-ADG-883107-ALGOSOC.	Amoore L, 2023, REV INT STUD, V49, P20, DOI 10.1017/S0260210522000031; Amoore Louise, 2020, Cloud ethics: algorithms and the attributes of ourselves and others; [Anonymous], 2011, PHILOS SIMULATION EM; Aradau Claudia., 2022, Algorithmic Reason: The New Government of Self and Other; Barry Andrew., 2001, Political Machines: Governing a Technological Society; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R., 2022, arXiv, DOI 10.48550/arXiv.2211.13972; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bucher T., 2018, THEN ALGORITHMIC POW; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Burkhardt S, 2024, BIG DATA SOC, V11, DOI 10.1177/20539517241247839; Campolo A, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517231188725; Chiang T., 2023, The New Yorker; Crary Jonathan., 2001, Suspensions of Perception: Attention Spectacle, and Modern Culture; Daston Lorraine., 2022, Rules: A Short History of What We Live By; de Vries K, 2020, INFORM COMMUN SOC, V23, P2110, DOI 10.1080/1369118X.2020.1754877; Deletang G., 2023, arXiv; Denton E, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211035955; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin K., 2000, MATH GENE; DWORKIN R, 1983, NEW YORK REV BOOKS, V30, P4; Fisher L., 2024, Financial Times28 February; Foucault M., 2003, ORDER THINGS; Foucault M., 2007, SECURITY TERRITORY P; Foucault Michel, 1991, FOUCAULT EFFECT STUD, DOI DOI 10.7208/CHICAGO/9780226028811.001.0001; Genomics England, 2021, NVIDIA GTC C NOV 8 1; Gentleman A., 2023, The Guardian; Gillespie Tarleton., 2016, Digital Keywords: A Vocabulary of Information Society and Culture, P18; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Goodfellow I. J., 2014, arXiv, DOI DOI 10.48550/ARXIV.1406.2661; Gordon Colin., 1991, FOUCAULT EFFECT, P1, DOI DOI 10.7208/CHICAGO/9780226028811.001.0001; Harwell D., 2023, Washington Post25 February; Hayles NK, 2023, AM LIT, V95, P255, DOI 10.1215/00029831-10575063; Jacobsen BN, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517221145372; Jaton F, 2017, SOC STUD SCI, V47, P811, DOI 10.1177/0306312717730428; Joque Justin., 2022, Revolutionary Mathematics: Artificial Intelligence, Statistics and the Logic of Capitalism; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Law John., 1993, Organising Modernity: Social Ordering and Social Theory; LeCun Y., 2022, Open Review; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Dai AM, 2015, Arxiv, DOI arXiv:1511.01432; McQuillan D., 2018, Philosophy and Technology, V31, P253, DOI DOI 10.1007/S13347-017-0273-3; Mol Annemarie., 2003, The Body Multiple: Ontology in Medical Practice, DOI DOI 10.2307/J.CTV1220NC1; Morgan Mary S, 2012, WORLD MODEL EC WORK; Mulvin D., 2021, Proxies: The Cultural Work of Standing In; Ng AY, 2002, ADV NEUR IN, V14, P841; Offert F., 2021, MEDIA ENV, V3, P1, DOI DOI 10.1525/001C.29905; OpenAI, 2023, Gpt-4 technical report, P1, DOI DOI 10.48550/ARXIV.2303.08774; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Palantir, 2022, Introducing Palantir AIP: Capabilities and product demo; Palantir, 2022, Artificial intelligence platform (AIP) defense and military; Paul K., 2023, The Guardian; Pedersen MA, 2021, ANNU REV ANTHROPOL, V50, P309, DOI 10.1146/annurev-anthro-101819-110356; Phan T, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211046377; Radford A., 2023, Improving Language understanding by generative pre-training; Radford A., 2015, PREPRINT; Ranciere Jacques., 2007, FUTURE IMAGE; Ranciere Jacques, 2010, Dissensus: On Politics and Aesthetics; Rawls John., 1971, A theory of justice, DOI [10.2307/j.ctvjf9z6v, DOI 10.2307/J.CTVJF9Z6V, DOI 10.4159/9780674042605]; Rella L, 2024, SOC STUD SCI, V54, P3, DOI 10.1177/03063127231185095; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Ribes D, 2019, SOC STUD SCI, V49, P281, DOI 10.1177/0306312719849709; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rubinstein Y. D., 1997, Proceedings of the Third International Conference on Knowledge Discovery and Data Mining, P49; Ruthotto L, 2021, INTRO DEEP GENERATIV; Seaver N, 2018, CULT ANTHROPOL, V33, P375, DOI 10.14506/ca33.3.04; Sutsekver I., 2023, STANF HAI SPRING C 1; Sutskever I., 2023, COMMUNICATION 0327; Sutskever I, 2014, ADV NEUR IN, V27; Vapnik V., 1998, STAT LEARNING THEORY; Vaswani A., 2017, Advances in neural information processing systems, P6000; Veel K, 2021, UNCERTAIN ARCHIVES, P313; Weber S., 2009, Targets of opportunity; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xie S. M., 2022, arXiv	75	0	0	1	1	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0962-6298	1873-5096		POLIT GEOGR	Polit. Geogr.	AUG	2024	113								103134	10.1016/j.polgeo.2024.103134	http://dx.doi.org/10.1016/j.polgeo.2024.103134			9	Geography; Political Science	Social Science Citation Index (SSCI)	Geography; Government & Law	UD9U7					2024-07-03	WOS:001246249800001
J	Mohammadi, SS; Nguyen, QD				Mohammadi, S. Saeed; Nguyen, Quan Dong			A User-friendly Approach for the Diagnosis of Diabetic Retinopathy Using ChatGPT and Automated Machine Learning	OPHTHALMOLOGY SCIENCE			English	Article						arti fi cial intelligence; ChatGPT; Generative Pretrained Transformer; image classi fi cation; machine learning	SYSTEM	Purpose: To assess the capabilities of Chat Generative Pre-trained Transformer (ChatGPT) and Vertex AI in executing code -free preprocessing, training machine learning (ML) models, and analyzing the data. Design: Evaluation of diagnostic test or technology. Participants: ChatGPT and Vetrex AI as publicly available large language model and ML platform, respectively. Methods: ChatGPT was employed to improve the resolution of fundus photography images from the Methods to Evaluate Segmentation and Indexing Techniques in the field of Retinal Ophthalmology (Messidor -2) open -source dataset using the Contrast Limited Adaptive Histogram Equalization (CLAHE) technique by Fiji software. Subsequently, Vertex AI, an automated ML (AutoML) platform, was utilized to develop 2 classification models. The first model served as a binary classifier for detecting the presence of diabetic retinopathy (DR), while the second determined its severity. Finally, ChatGPT was used to provide scripts for R and Python programming languages for data analysis and was also directly employed in analyzing the data in a code -free method. Main Outcome Measures: Evaluating the utility of ChatGPT in generating scripts for preprocessing images using Fiji and analyzing data across Python and R and assessing its potential in analyzing data through a codefree method. Investigating the capabilities of Vertex AI to train image classification models for detection of DR and its severity. Results: Two ML models were trained using 1740 images from the Messidor -2 database. The first model, designed to detect the severity of DR, achieved an area under the precision-recall curve (AUPRC) of 0.81, with a precision rate of 81.81% and recall of 72.83%. The second model, tailored for the detection of the presence of DR, recorded a precision and recall of 84.48% with an AUPRC of 0.90. Conclusions: ChatGPT and Vertex AI have the potential to enable physicians without coding expertise to preprocess images, analyze data, and train ML models. Financial Disclosure(s): Proprietary or commercial disclosure may be found in the Footnotes and Disclosures at the end of this article. Ophthalmology Science 2024;4:100495 (c) 2024 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/ licenses/by-nc-nd/4.0/).	[Mohammadi, S. Saeed; Nguyen, Quan Dong] Stanford Univ, Byers Eye Inst, Dept Ophthalmol, Palo Alto, CA USA; [Nguyen, Quan Dong] Stanford Univ, Byers Eye Inst, Spencer Ctr Vis Res, 2370 Watson Court, Suite 200, Palo Alto, CA 94303 USA	Stanford University; Stanford University	Nguyen, QD (corresponding author), Stanford Univ, Byers Eye Inst, Spencer Ctr Vis Res, 2370 Watson Court, Suite 200, Palo Alto, CA 94303 USA.	ndquan@stanford.edu			National Eye Institute (NEI) [P30-EY026877]; Research to Prevent Blindness, Inc.	National Eye Institute (NEI)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Eye Institute (NEI)); Research to Prevent Blindness, Inc.(Research to Prevent Blindness (RPB))	The Byers Eye Institute is supported by funding from the National Eye Institute (NEI P30-EY026877) and from the Research to Prevent Blindness, Inc.	Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6; Alwakid G, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060863; [Anonymous], How to use ChatGPT's advanced data analysis feature; Antal B, 2012, IEEE T BIO-MED ENG, V59, P1720, DOI 10.1109/TBME.2012.2193126; Bresnick GH, 2000, OPHTHALMOLOGY, V107, P19, DOI 10.1016/S0161-6420(99)00010-X; Budach L, 2022, Arxiv, DOI [arXiv:2207.14529, DOI 10.48550/ARXIV.2207.14529]; Buscemi A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2308.04477; Dai L, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23458-5; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; DCCT Res Grp, 1994, J PEDIATR-US, V125, P177, DOI 10.1016/S0022-3476(94)70190-3; Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155; Early Treatment Diabetic Retinopathy Study Res Grp, 1991, OPHTHALMOLOGY, V98, P766; Eisma JH, 2015, WORLD J DIABETES, V6, P312, DOI 10.4239/wjd.v6.i2.312; Faes L, 2019, LANCET DIGIT HEALTH, V1, pE232, DOI 10.1016/S2589-7500(19)30108-6; Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008; Ghaffar Nia N., 2023, Discover Artif Intell, V3, P5, DOI [10.1007/s44163-023-00049-5, DOI 10.1007/S44163-023-00049-5]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gong EJ, 2022, J PERS MED, V12, DOI 10.3390/jpm12060963; Hao Y, 2023, IEEE INT C INT ROBOT, P11436, DOI 10.1109/IROS55552.2023.10342139; Hayati Mira, 2023, Procedia Computer Science, P57, DOI 10.1016/j.procs.2022.12.111; Hendrick AM, 2015, PRIMARY CARE, V42, P451, DOI 10.1016/j.pop.2015.05.005; Hitam MS, 2013, INT C COMPUTER APPL; Jeong Y, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12010134; KINYOUN JL, 1992, INVEST OPHTH VIS SCI, V33, P1888; Krause J, 2018, OPHTHALMOLOGY, V125, P1264, DOI 10.1016/j.ophtha.2018.01.034; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Messidor-ADCIS, About Us; Morton Caroline E, 2019, JMIR Med Educ, V5, pe11940, DOI 10.2196/11940; Nelli F, 2018, Python Data Analytics: With Pandas, NumPy, and Matplotlib, VSecond; Nneji GU, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12020540; Open AI, We've made ChatGPT Plus fresher and simpler to use; Pinto-Coelho L, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10121435; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Sánchez CI, 2011, INVEST OPHTH VIS SCI, V52, P4866, DOI 10.1167/iovs.10-6633; Saponara Sergio, 2022, Applications in Electronics Pervading Industry, Environment and Society: APPLEPIES 2021. Lecture Notes in Electrical Engineering (866), P10, DOI 10.1007/978-3-030-95498-7_2; Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/nmeth.2019, 10.1038/NMETH.2019]; Seoud Lama, 2016, IEEE Trans Med Imaging, V35, P1116, DOI 10.1109/TMI.2015.2509785; Singh P, 2020, J DIGIT IMAGING, V33, P273, DOI 10.1007/s10278-019-00211-5; Stratton IM, 2001, DIABETOLOGIA, V44, P156, DOI 10.1007/s001250051594; Strong E, 2023, medRxiv, DOI [10.1101/2023.03.24.23287731, 10.1101/2023.03.24.23287731, DOI 10.1101/2023.03.24.23287731]; Tomita Y, 2021, J CLIN MED, V10, DOI 10.3390/jcm10204666; Tondin BR, 2022, IFMBE PROC, P1837, DOI 10.1007/978-3-030-70601-2_268; Touma S, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06127-5	44	0	0	3	3	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-9145			OPHTHALMOL SCI	Ophthalmol. Sci.	AUG	2024	4	4							100495	10.1016/j.xops.2024.100495	http://dx.doi.org/10.1016/j.xops.2024.100495		APR 2024	8	Ophthalmology	Emerging Sources Citation Index (ESCI)	Ophthalmology	QA3E8	38690313	hybrid			2024-07-03	WOS:001218113300001
J	Awosanya, OD; Harris, A; Creecy, A; Qiao, X; Toepp, AJ; Mccune, T; Kacena, MA; Ozanne, MV				Awosanya, Olatundun D.; Harris, Alexander; Creecy, Amy; Qiao, Xian; Toepp, Angela J.; Mccune, Thomas; Kacena, Melissa A.; Ozanne, Marie V.			The Utility of AI in Writing a Scientific Review Article on the Impacts of COVID-19 on Musculoskeletal Health	CURRENT OSTEOPOROSIS REPORTS			English	Review						AI; ChatGPT; Scientific review article; Query; COVID-19; Bone Loss; Osteoporosis; Fracture; SARS-CoV-2		Purpose of ReviewThere were two primary purposes to our reviews. First, to provide an update to the scientific community about the impacts of COVID-19 on musculoskeletal health. Second, was to determine the value of using a large language model, ChatGPT 4.0, in the process of writing a scientific review article. To accomplish these objectives, we originally set out to write three review articles on the topic using different methods to produce the initial drafts of the review articles. The first review article was written in the traditional manner by humans, the second was to be written exclusively using ChatGPT (AI-only or AIO), and the third approach was to input the outline and references selected by humans from approach 1 into ChatGPT, using the AI to assist in completing the writing (AI-assisted or AIA). All review articles were extensively fact-checked and edited by all co-authors leading to the final drafts of the manuscripts, which were significantly different from the initial drafts.Recent FindingsUnfortunately, during this process, it became clear that approach 2 was not feasible for a very recent topic like COVID-19 as at the time, ChatGPT 4.0 had a cutoff date of September 2021 and all articles published after this date had to be provided to ChatGPT, making approaches 2 and 3 virtually identical. Therefore, only two approaches and two review articles were written (human and AI-assisted). Here we found that the human-only approach took less time to complete than the AI-assisted approach. This was largely due to the number of hours required to fact-check and edit the AI-assisted manuscript. Of note, the AI-assisted approach resulted in inaccurate attributions of references (about 20%) and had a higher similarity index suggesting an increased risk of plagiarism.SummaryThe main aim of this project was to determine whether the use of AI could improve the process of writing a scientific review article. Based on our experience, with the current state of technology, it would not be advised to solely use AI to write a scientific review article, especially on a recent topic.	[Awosanya, Olatundun D.; Harris, Alexander; Creecy, Amy; Kacena, Melissa A.] Indiana Univ Sch Med, Dept Orthopaed Surg, Indianapolis, IN 46202 USA; [Qiao, Xian] SMG Pulm, Crit Care & Sleep Specialists, Norfolk, VA USA; [Qiao, Xian] Eastern Virginia Med Sch, Div Pulm & Crit Care Med, Norfolk, VA USA; [Qiao, Xian; Toepp, Angela J.; Mccune, Thomas] Eastern Virginia Med Sch, Dept Internal Med, Norfolk, VA USA; [Toepp, Angela J.] Sentara Hlth, Enterprise Analyt, Norfolk, VA USA; [Mccune, Thomas] Eastern Virginia Med Sch, Div Nephrol, Norfolk, VA USA; [Kacena, Melissa A.] Richard L Roudebush VA Med Ctr, Indianapolis, IN 46202 USA; [Ozanne, Marie V.] Mt Holyoke Coll, Dept Math & Stat, South Hadley, MA 01075 USA	Indiana University System; Indiana University Bloomington; Eastern Virginia Medical School; Eastern Virginia Medical School; Sentara Healthcare; Eastern Virginia Medical School; US Department of Veterans Affairs; Veterans Health Administration (VHA); Richard L. Roudebush VA Medical Center; Mount Holyoke College	Kacena, MA (corresponding author), Indiana Univ Sch Med, Dept Orthopaed Surg, Indianapolis, IN 46202 USA.; Kacena, MA (corresponding author), Richard L Roudebush VA Med Ctr, Indianapolis, IN 46202 USA.; Ozanne, MV (corresponding author), Mt Holyoke Coll, Dept Math & Stat, South Hadley, MA 01075 USA.	mkacena@iupui.edu; mozanne@mtholyoke.edu			National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	No Statement Available	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Creecy A, 2024, CURR OSTEOPOROS REP, V22, P122, DOI 10.1007/s11914-023-00842-2; Harris A, 2024, CURR OSTEOPOROS REP, V22, P135, DOI 10.1007/s11914-023-00843-1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kacena MA, 2024, CURR OSTEOPOROS REP, V22, P115, DOI 10.1007/s11914-023-00852-0; Karnik SJ, 2024, CURR OSTEOPOROS REP, V22, P165, DOI 10.1007/s11914-023-00847-x; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Margetts TJ, 2024, CURR OSTEOPOROS REP, V22, P152, DOI 10.1007/s11914-023-00848-w; Margetts TJ, 2024, CURR OSTEOPOROS REP, V22, P177, DOI 10.1007/s11914-023-00853-z; Morris AJ, 2024, CURR OSTEOPOROS REP, V22, P193, DOI 10.1007/s11914-023-00846-y; Nazzal MK, 2024, CURR OSTEOPOROS REP, V22, P182, DOI 10.1007/s11914-023-00850-2; Nazzal MK, 2024, CURR OSTEOPOROS REP, V22, P217, DOI 10.1007/s11914-023-00854-y; Neumeistera L, 2023, LAWYERS BLAME CHATGP; Parker RS, 2024, CURR OSTEOPOROS REP, V22, P205, DOI 10.1007/s11914-023-00844-0; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Wang HS, 2024, CURR OSTEOPOROS REP, DOI 10.1007/s11914-023-00851-1	16	5	5	12	12	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1544-1873	1544-2241		CURR OSTEOPOROS REP	Curr. Osteoporos. Rep.	FEB	2024	22	1					146	151		10.1007/s11914-023-00855-x	http://dx.doi.org/10.1007/s11914-023-00855-x		JAN 2024	6	Endocrinology & Metabolism	Science Citation Index Expanded (SCI-EXPANDED)	Endocrinology & Metabolism	JL8U4	38216806	Green Published, hybrid			2024-07-03	WOS:001141185200001
J	Haber, J; Poesio, M				Haber, Janosch; Poesio, Massimo			Polysemy-Evidence from Linguistics, Behavioral Science, and Contextualized Language Models	COMPUTATIONAL LINGUISTICS			English	Article							SENTENCE COMPREHENSION; DISTRIBUTIONAL MODELS; SEMANTIC AMBIGUITY; LEXICAL AMBIGUITY; WORD; SENSE; HOMONYMY; REPRESENTATION; MEANINGS; ACCESS	Polysemy is the type of lexical ambiguity where a word has multiple distinct but related interpretations. In the past decade, it has been the subject of a great many studies across multiple disciplines including linguistics, psychology, neuroscience, and computational linguistics, which have made it increasingly clear that the complexity of polysemy precludes simple, universal answers, especially concerning the representation and processing of polysemous words. But fuelled by the growing availability of large, crowdsourced datasets providing substantial empirical evidence; improved behavioral methodology; and the development of contextualized language models capable of encoding the fine-grained meaning of a word within a given context, the literature on polysemy recently has developed more complex theoretical analyses.In this survey we discuss these recent contributions to the investigation of polysemy against the backdrop of a long legacy of research across multiple decades and disciplines. Our aim is to bring together different perspectives to achieve a more complete picture of the heterogeneity and complexity of the phenomenon of polysemy. Specifically, we highlight evidence supporting a range of hybrid models of the mental processing of polysemes. These hybrid models combine elements from different previous theoretical approaches to explain patterns and idiosyncrasies in the processing of polysemous that the best known models so far have failed to account for. Our literature review finds that (i) traditional analyses of polysemy can be limited in their generalizability by loose definitions and selective materials; (ii) linguistic tests provide useful evidence on individual cases, but fail to capture the full range of factors involved in the processing of polysemous sense extensions; and (iii) recent behavioral (psycho) linguistics studies, large-scale annotation efforts, and investigations leveraging contextualized language models provide accumulating evidence suggesting that polysemous sense similarity covers a wide spectrum between identity of sense and homonymy-like unrelatedness of meaning.We hope that the interdisciplinary account of polysemy provided in this survey inspires further fundamental research on the nature of polysemy and better equips applied research to deal with the complexity surrounding the phenomenon, for example, by enabling the development of benchmarks and testing paradigms for large language models informed by a greater portion of the rich evidence on the phenomenon currently available.	[Haber, Janosch] Queen Mary Univ London, Sch Elect Engn & Comp Sci, Chattermill, London, England; [Poesio, Massimo] Queen Mary Univ London, London, England; [Poesio, Massimo] Univ Utrecht, Utrecht, Netherlands	University of London; Queen Mary University London; University of London; Queen Mary University London; Utrecht University	Haber, J (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, Chattermill, London, England.	janoschhaber@gmail.com						Agirre Eneko., 2003, P C RECENT ADV NATUR, P121, DOI [10.1075/cilt.260.13agi, DOI 10.1075/CILT.260.13AGI]; Almuhareb A, 2006, FRONT ARTIF INTEL AP, V141, P543; Amrami A., 2019, ARXIV; Amrami A, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4860; Amsler Robert A., 1980, The structure of the Merriam-Webster pocket dictionary; ANDERSON RC, 1975, COGNITIVE PSYCHOL, V7, P167, DOI 10.1016/0010-0285(75)90008-0; [Anonymous], 2010, P 2010 C EMP METH NA; [Anonymous], 1960, Advances in Computers, DOI DOI 10.1016/S0065-2458(08)60607-5; [Anonymous], 2018, Transactions of the Association for Computational Linguistics, V6, P483, DOI [DOI 10.1162/TACL_A_00034, DOI 10.1162/TACLA00034]; [Anonymous], 2004, P 42 ANN M ASS COMPU, DOI DOI 10.3115/1218955.1218991; [Anonymous], 2014, Transactions of the Association for Computational Linguistics, DOI DOI 10.1162/tacl_a_00185; Anscombe G. E. M., 1958, Philosophical investigations, V2nd; Antunes Sandra., 2003, P 2 INT WORKSHOP GEN; Apidianaki M, 2023, COMPUT LINGUIST, V49, P465, DOI 10.1162/coli_a_00474; APRESJAN JD, 1974, LINGUISTICS, P5; Arapinis A, 2015, APPL ONTOL, V10, P285, DOI 10.3233/AO-150156; Armendariz CS, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P5870; Asher N., 2011, Lexical Meaning in Context: A Web of Words, DOI DOI 10.1017/CBO9780511793936; Asher N, 2006, J COGN SCI, V7, P1; Asher Nicholas, 2003, Logics of conversation; Baker C.F., 1998, P 36 ANN M ASS COMP, P86, DOI DOI 10.3115/980845.980860; Bamler R, 2017, PR MACH LEARN RES, V70; Banerjee S., 2002, Computational Linguistics and Intelligent Text Processing. Third International Conference, CICLing 2002. Proceedings (Lecture Notes in Computer Science Vol.2276), P136; Baroni M., 2014, LiLT (Linguistic Issues in Language Technology), V9, P241, DOI DOI 10.33011/LILT.V9I.1321; Bennett A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1513; Beretta A, 2005, COGNITIVE BRAIN RES, V24, P57, DOI 10.1016/j.cogbrainres.2004.12.006; Bevilacqua Michele, 2021, INT JOINT C ARTIFICI, P4330, DOI DOI 10.24963/IJCAI.2021/593; BIERWISCH M, 1992, COGNITION, V42, P23, DOI 10.1016/0010-0277(92)90039-K; blAnK Andreas, 1997, Prinzipien des lexikalischen Bedeutungswandels am Beispiel der romanischen Sprachen, DOI DOI 10.1515/9783110931600; Blevins T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1006; Boleda G., 2013, P 10 INT C COMPUTATI; Boleda G, 2020, ANNU REV LINGUIST, V6, P213, DOI 10.1146/annurev-linguistics-011619-030303; Boleda G, 2012, COMPUT LINGUIST, V38, P575, DOI 10.1162/COLI_a_00093; Boleda Gemma., 2012, SEM 2012 1 JOINT C L, P151; Bowdle BF, 2005, PSYCHOL REV, V112, P193, DOI 10.1037/0033-295X.112.1.193; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Breal M, 1897, Essai de semantique, science des significations; Brochhagen T, 2022, COGNITION, V226, DOI 10.1016/j.cognition.2022.105179; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bruera A, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13388; BRUGMAN CLAUDIA MARLEA, 1988, The story of over: Polysemy, semantics, and the structure of the lexicon; Buitelaar Paul., 1998, CoreLex: Systematic Polysemy and Underspecification; Burchardt Aljoscha., 2006, P 5 INT C LANGUAGE R; Camacho-Collados J, 2018, J ARTIF INTELL RES, V63, P743, DOI 10.1613/jair.1.11259; Campello R., 2013, Advances in Knowledge Discovery and Data Mining, P160, DOI [10.1007/978-3-642-37456-2_14, DOI 10.1007/978-3-642-37456-2_14]; Caramazza A., 1976, GEORGETOWN U ROUND T, P181; Carston R., 2002, Thoughts and utterances: The pragmatics of explicit communication, DOI [10.1002/9780470754603, DOI 10.1002/9780470754603]; Carston Robyn., 2013, What is Said and What is Not; Chang TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6064; Clark Stephen., 2015, Vector Space Models of Lexical Meaning, P493, DOI [10.1002/9781118882139.ch16, DOI 10.1002/9781118882139.CH16]; Copestake A., 1995, J SEMANT, V12, P15, DOI [DOI 10.1093/J0S/12.1.15, DOI 10.1093/JOS/12.1.15, 10.1093/jos/12.1.15]; Copestake Ann., 1994, Inheritance, Defaults and the Lexicon, P148, DOI [10.1017/CBO9780511663642.009, DOI 10.1017/CBO9780511663642.009]; Crain Stephen., 1985, On Not Being Led up the Garden Path: The Use of Context by the Psychological Syntax Processor, DOI [10.1017/CBO9780511597855.011, DOI 10.1017/CBO9780511597855.011]; Cruse D.A., 1995, COMPUTATIONAL LEXICA, P33, DOI DOI 10.1017/CBO9780511527227.004; Cruse D.A., 1986, LEXICAL SEMANTICS; Cruse D. Alan., 2004, Lexical 'Facets': Between Monosemy and Polysemy; Cruse David Allan., 2000, Polysemy: Theoretical and Computational Approaches, P30, DOI DOI 10.1093/OSO/9780198238423.003.0002; Dai Andrew M., 2015, ADV NEURAL INFORM PR, P9; Dautriche Isabelle., 2015, Weaving an ambiguous lexicon; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dolling J, 1995, INT J HUM-COMPUT ST, V43, P785, DOI 10.1006/ijhc.1995.1074; Dolling Johannes., 2020, Systematic Polysemy, DOI [10.1002/9781118788516.sem099, DOI 10.1002/9781118788516.SEM099]; DURKIN K, 1989, J PSYCHOLINGUIST RES, V18, P577, DOI 10.1007/BF01067161; Ellsworth Michael., 2004, P LREC; Erk K., 2009, P JOINT C 47 ANN M A, P10; Erk K, 2012, LANG LINGUIST COMPAS, V6, P635, DOI 10.1002/Inc3.362; Erk K, 2013, COMPUT LINGUIST, V39, P511, DOI 10.1162/COLI_a_00142; Erk Katrin., 2009, EMNLP 2009 P 2009 C, P441, DOI [10.3115/1699510.1699568, DOI 10.3115/1699510.1699568]; Erk Katrin., 2010, Proceedings of the ACL 2010 Conference Short Papers, P92, DOI DOI 10.1017/S0022226704003056; Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55; Falkum I.L., 2011, SEMANTICS PRAGMATICS; Falkum IL, 2015, LINGUA, V157, P83, DOI 10.1016/j.lingua.2014.11.004; Falkum IL, 2015, LINGUA, V157, P1, DOI 10.1016/j.lingua.2015.02.002; Fellbaum Christiane., 1998, Building Semantic Concordances; Fillmore Charles J., 1985, Quaderni di Semantica, VIV; Firth JR, 1957, Selected Papers of J. R. Firth, P10; Fodor J., 1998, Concepts: Where cognitive science went wrong; Foraker S, 2012, J MEM LANG, V67, P407, DOI 10.1016/j.jml.2012.07.010; FRAZIER L, 1990, J MEM LANG, V29, P181, DOI 10.1016/0749-596X(90)90071-7; Frermann L., 2016, Transactions of the Association for Computational Linguistics, V4, P31, DOI 10.1162/tacl_a_00081; Frisson S, 2005, J MEM LANG, V53, P277, DOI 10.1016/j.jml.2005.03.004; Frisson S, 2015, LINGUA, V157, P17, DOI 10.1016/j.lingua.2014.07.017; Frisson S, 2009, LANG LINGUIST COMPAS, V3, P111, DOI 10.1111/j.1749-818x.2008.00104.x; Geeraerts D., 1993, Cognitive Linguistics, V4, P223, DOI [DOI 10.1515/COGL.1993.4.3.223, 10.1515/cogl.1993.4.3.223]; Gilliver Peter., 2013, Dictionaries: Journal of the Dictionary Society of North America, V34, P10, DOI [10.1353/dic.2013.0009, DOI 10.1353/DIC.2013.0009]; Gillon B., 1999, The Lexical Semantics of English Count and Mass Nouns, V10, DOI [10.1007/978-94-017-0952-1_2, DOI 10.1007/978-94-017-0952-1_2]; GILLON BS, 1992, LINGUIST PHILOS, V15, P597, DOI 10.1007/BF00628112; Giulianelli M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3960; GOLDSTONE R, 1994, J EXP PSYCHOL GEN, V123, P178, DOI 10.1037/0096-3445.123.2.178; Gotham Matthew Graham Haigh., 2014, Copredication, Quantification and Individuation; Haber J., 2020, P 9 JOINT C LEXICAL, P114; Haber J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2663; Haber Janosch., 2022, Word Sense Distance and Similarity Patterns in Regular Polysemy; Habibi Amir Ahmad., 2021, P 11 GLOBAL WORDNET, P26; Hadiwinoto C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5297; Hamilton WL, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1489; Hanks P, 2000, COMPUT HUMANITIES, V34, P205, DOI 10.1023/A:1002471322828; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Hauer B, 2020, AAAI CONF ARTIF INTE, V34, P7895; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; HOBBS JR, 1993, ARTIF INTELL, V63, P69, DOI 10.1016/0004-3702(93)90015-4; Hopper Paul J., 1991, Approachestogrammaticalization, V1, P17, DOI [10.1075/ts1.19.1, DOI 10.1075/TSL.19.1.04HOP]; Hovy E., 2006, P HUM LANG TECHN C N, P57; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Hu RF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3899; Huang Eric H, 2012, ANN M ASS COMP LING, P873; Huang LY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3509; Iacobacci I, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P897; Iacobacci I, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P95; Ide N, 1998, COMPUT LINGUIST, V24, P1; Jackendoff R., 1989, MIND LANG, V4, P68; Jackendoff Ray S., 1992, Languages of the Mind: Essays on Mental Representation, DOI [10.7551/mitpress/4129.001.0001, DOI 10.7551/MITPRESS/4129.001.0001]; Jackson H., 2002, LEXICOGRAPHY INTRO; Jezek E., 2014, P 1 IT C COMP LING P, V1, P219; JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329; Karjus A, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.13035; KATZ JJ, 1963, LANGUAGE, V39, P170, DOI 10.2307/411200; Katz JJ., 1972, SEMANTIC THEORY; Keller F., 2000, Gradience in Grammar: Experimental and Computational Aspects of Degrees of Grammaticality; Kempson RuthM., 1977, SEMANTIC THEORY; Kilgarriff A, 1997, COMPUT HUMANITIES, V31, P91, DOI 10.1023/A:1000583911091; Kilgarriff Adam., 1992, Polysemy; Kilgarriff Adam., 2001, P SENSEVAL 2 2 INT W, P17; Kitaev Nikita., 2020, CoRR; Klein DE, 2002, J MEM LANG, V47, P548, DOI 10.1016/S0749-596X(02)00020-7; Klein DE, 2001, J MEM LANG, V45, P259, DOI 10.1006/jmla.2001.2779; Klepousniotou E, 2002, BRAIN LANG, V81, P205, DOI 10.1006/brln.2001.2518; Klepousniotou E, 2008, J EXP PSYCHOL LEARN, V34, P1534, DOI 10.1037/a0013012; Klepousniotou E, 2012, BRAIN LANG, V123, P11, DOI 10.1016/j.bandl.2012.06.007; Kucera H., 1967, COMPUTATIONAL ANAL P; Lafourcade Mathieu., 2007, P 7 S NATURAL LANGUA; Lafourcade Mathieu., 2020, P LREC WORKSHOP GAME, P26; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lau J. H., 2012, EACL; Lau Jey Han., 2014, Proceedings of the 36th Annual Meeting of the Cognitive Science Society (CogSci 2014); Laurence S., 1999, Concepts: Core Readings, V6th, P3, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]; Lenci A, 2018, ANNU REV LINGUIST, V4, P151, DOI 10.1146/annurev-linguistics-030514-125254; Lesk M., 1986, P 5 ANN INT C SYSTEM, P24; Levin Beth, 1993, ENGLISH VERB CLASSES; Levine Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4656; Lewis Mike, 2020, Advances in Neural Information Processing Systems; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241; Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073; Löhr G, 2024, INQUIRY, V67, P68, DOI 10.1080/0020174X.2020.1868329; Lyons John., 1977, Semantics, V1, DOI [10.1017/CBO9781139165693, DOI 10.1017/CBO9781139165693]; MacGregor LJ, 2015, NEUROPSYCHOLOGIA, V68, P126, DOI 10.1016/j.neuropsychologia.2015.01.008; MARSLENWILSON W, 1980, COGNITION, V8, P1, DOI 10.1016/0010-0277(80)90015-3; McCann Bryan, 2017, LEARNED TRANSLATION; McCarthy D, 2016, COMPUT LINGUIST, V42, P245, DOI 10.1162/COLI_a_00247; Melamud O., 2016, P 20TH SIGNLL C COMP, P51; Mickus T, 2020, P SOC COMP LING 2020, P279; Mihalcea R., 2004, SENSEVAL 3, P25; Mikolov T, 2013, COMPUTING RES REPOSI; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Miller G, 1993, P WORKSH HUM LANG TE, P303; Miller G.A., 1976, Language and perception, DOI [10.4159/harvard.9780674421288, DOI 10.4159/HARVARD.9780674421288]; Miller G.A., 1990, 5 PAPERS WORDNET; Miller G. A., 1994, P WORKSHOP HUMAN LAN, P240, DOI DOI 10.3115/1075812.1075866; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; MILLER GA, 1991, LANG COGNITIVE PROC, V6, P1, DOI 10.1080/01690969108406936; Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x; Moro A., 2014, TACL, V2, P231, DOI [10.1162/tacla00179, DOI 10.1162/TACLA00179, 10.1162/tacl_a_00179, DOI 10.1162/TACL_A_00179]; Murphy, 2021, THESIS U COLL LONDON; Murphy E., 2019, PERSPECTIVES ABSTRAC, P145, DOI DOI 10.1075/HCP.65.08MUR; Nair Sathvik, 2020, P WORKSHOP COGNITIVE, P129; Navigli R, 2007, P 4 INT WORKSH SEM E, P30; Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001; Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355; Navigli Roberto, 2021, P 30 INT JOINT C ART, P4559; Neelakantan A., 2014, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), P1059, DOI [10.3115/v1/D14-1113, DOI 10.3115/V1/D14-1113]; Nerlich B., 2003, TRENDS LINGUISTICS P, P3; Norrick N. R., 1981, Semiotic principles in semantic theory, V20, DOI [https://doi.org/10.1075/cilt.20, DOI 10.1075/CILT.20]; NUNBERG G, 1979, LINGUIST PHILOS, V3, P143, DOI 10.1007/BF00126509; Nunberg G., 1995, J SEMANT, V12, P109, DOI DOI 10.1093/JOS/12.2.109; OpenAI, 2023, : GPT-4 technical report.; Ortega-Andrés M, 2019, GLOSSA-UK, V4, DOI 10.5334/gjgl.564; Ortega-Andres Marina., 2021, Interpretation of Copredicative Sentences: A Rich Underspecification Account of Polysemy, DOI [10.1007/978-3-030-56437-7_9, DOI 10.1007/978-3-030-56437-7_9]; Osman Nabil., 1971, Kleines Lexikon untergegangener Worter: Wortuntergang seit dem Ende des 18. Jahrhunderts, V487; Ostler N., 1991, Workshop of SIGLEX (Special Interest Group within ACL on the Lexicon), P87, DOI [10.1007/3-540-55801-2_29, DOI 10.1007/3-540-55801-2_29]; Palmer M, 2005, COMPUT LINGUIST, V31, P71, DOI 10.1162/0891201053630264; Paradis C, 2004, METAPHOR SYMBOL, V19, P245, DOI 10.1207/s15327868ms1904_1; Paradis C., 2011, Definingmetonymy in cognitive linguistics: Towards a consensusview, P61, DOI [10.1075/hcp.28.04par, DOI 10.1075/HCP.28.04PAR]; Pasini T, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4008; Passonneau RJ, 2012, LANG RESOUR EVAL, V46, P219, DOI 10.1007/s10579-012-9188-x; Passonneau RebeccaJ., 2012, Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC); Paul Hermann., 2002, Deutsches Worterbuch, DOI [10.1515/9783110929799, DOI 10.1515/9783110929799]; Pedersen Ted., 1997, 2 C EMPIRICAL METHOD; PELLETIER FJ, 1975, PHILOSOPHIA, V5, P451, DOI 10.1007/BF02379268; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161; Peters Wim., 2000, P 2 INT C LANGUAGE R; Peterson D, 2018, AAAI CONF ARTIF INTE, P5398; Petrolito T, 2014, PROCEEDINGS OF THE SEVENTH GLOBAL WORDNET CONFERENCE, GWC 2014, P236; Pietroski Paul M., 2005, Contextualism in Philosophy: Knowledge, Meaning, and Truth, DOI [10.1093/oso/9780199267408.003.0010, DOI 10.1093/OSO/9780199267408.003.0010]; Pilehvar MT, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1267; Pinkal Manfred., 1985, Logik Und Lexikon: Die Semantik des Unbestimmten, DOI [10.1515/9783110849523, DOI 10.1515/9783110849523]; Pinkal Manfred., 1995, Logic and Lexicon. The Semantics of the Indefinite, DOI [10.1007/978-94-015-8445-6, DOI 10.1007/978-94-015-8445-6]; Poesio Massimo., 2020, Ambiguity, DOI [10.1002/9781118788516.sem098, DOI 10.1002/9781118788516.SEM098]; Pradhan S., 2012, JOINT C EMP METH NAT, P1; Pradhan S., 2013, CONLL, P143; Pradhan SS, 2007, INT J SEMANT COMPUT, V1, P405, DOI 10.1142/S1793351X07000251; Pustejovsky J., 1995, GENERATIVE LEXICON; Pustejovsky James., 1993, SEMANTICS LEXICON, P73, DOI DOI 10.1007/978-94-011-1972-6_6; Pylkkänen L, 2006, J COGNITIVE NEUROSCI, V18, P97, DOI 10.1162/089892906775250003; Rabinovich Ella., 2020, P ANN C COGNITIVE SC, P3370; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Raganato A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P99; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Ravin Yael., 2000, Polysemy: An Overview, DOI [10.1093/oso/9780198238423.003.0001, DOI 10.1093/OSO/9780198238423.003.0001]; Recanati Francois., 1998, Pragmatics: Critical Concepts, P509; Reisinger J., 2010, HLT-NAACL, P109; Resnik P., 1999, Natural Language Engineering, V5, P113, DOI 10.1017/S1351324999002211; Rodd J, 2002, J MEM LANG, V46, P245, DOI 10.1006/jmla.2001.2810; Rodd JM, 2004, COGNITIVE SCI, V28, P89, DOI 10.1016/j.cogsci.2003.08.002; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Rumshisky Anna, 2008, P ACL WORKSHOP HUMAN, P33, DOI DOI 10.3115/1611628.1611634; Sanderson M., 2000, Information Retrieval, V2, P49, DOI DOI 10.1023/A:1009933700147.; Sandra D, 1998, COGN LINGUIST, V9, P361; Schlechtweg D., 2018, P 2018 C N AM CHAPT, P169; Schneider Nathan., 2014, Lexical Semantic Analysis in Natural Language; Schuler K. K., 2005, VerbNet: A Broad-Coverage, Comprehensive Verb Lexicon; Schumacher PB, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00677; Schuster T, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1599; Schutze H, 1998, COMPUT LINGUIST, V24, P97; Simpson G.B., 1994, HDB PSYCHOLINGUISTIC, P359; SIMPSON GB, 1981, J VERB LEARN VERB BE, V20, P120, DOI 10.1016/S0022-5371(81)90356-X; Snow R., 2007, P C EMPIRICAL METHOD, P1005; Snyder B, 2004, SENSEVAL, P41; Song Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4311; Sorace A, 2005, LINGUA, V115, P1497, DOI 10.1016/j.lingua.2004.07.002; Sparck-Jones Karen., 1964, Synonymy and Semantic Classification; Srinivasan M, 2015, LINGUA, V157, P124, DOI 10.1016/j.lingua.2014.12.004; Stammers Jonathan., 2008, Lexis, V1, DOI [10.4000/lexis.771, DOI 10.4000/LEXIS.771]; Stokoe Christopher., 2005, P HUMAN LANGUAGE TEC, P403, DOI [10.3115/1220575.1220626, DOI 10.3115/1220575.1220626]; SWINNEY DA, 1979, J VERB LEARN VERB BE, V18, P645, DOI 10.1016/S0022-5371(79)90355-4; TABOSSI P, 1987, PSYCHOL RES-PSYCH FO, V49, P161, DOI 10.1007/BF00308682; Taieb MAH, 2020, ARTIF INTELL REV, V53, P4407, DOI 10.1007/s10462-019-09796-3; Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Traugott E.C., 2017, Oxford Research Encyclopedia of Linguistics, DOI DOI 10.1093/ACREFORE/9780199384655.013.323; Travis C., 1997, COMPANION PHILOS LAN, P87, DOI DOI 10.1002/9781118972090.CH6; Travis Charles., 2008, Occasion-sensitivity: Selected essays, DOI [10.1093/acprof:oso/9780199230334.001.0001, DOI 10.1093/ACPROF:OSO/9780199230334.001.0001]; Trott S., 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, P7077; Tuggy D., 1993, COGNITIVE LINGUISTICS, V4, P273, DOI [10.1515/cogl.1993.4.3.273, DOI 10.1515/COGL.1993.4.3.273]; Ullmann S., 1959, Principles of Semantics; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Vega Moreno Rosa E., 2007, Creativity and Convention: The pragmatics of everyday figurative speech, DOI [10.1075/pbns.156, DOI 10.1075/PBNS.156]; Vicente A., 2017, Oxford Research Encyclopedia of Linguistics, DOI [10.1093/acrefore/9780199384655.013.325, DOI 10.1093/ACREFORE/9780199384655.013.325]; Vicente A, 2015, LINGUA, V157, P54, DOI 10.1016/j.lingua.2014.04.013; Voorhees Ellen M., 1993, P ACM SIGIR C, P171, DOI [DOI 10.1145/160688.160715, 10.1145/160688.160715]; Walde SSI, 2006, COMPUT LINGUIST, V32, P159, DOI 10.1162/coli.2006.32.2.159; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967; Weaver W., 1949, Machine Translation of Languages: Fourteen Essays; WEINREICH U, 1964, INT J AM LINGUIST, V30, P405, DOI 10.1086/464799; Westera M., 2019, P 13 INT C COMPUTATI, P120, DOI [10.18653/v1/W19-0410, DOI 10.18653/V1/W19-0410]; Wiedemann Gregor., 2019, P 15 C NATURAL LANGU, P10; Wilks Yorick A., 1996, Electric Words, DOI [10.7551/mitpress/2663.001.0001, DOI 10.7551/MITPRESS/2663.001.0001]; Wilson Kyra., 2022, P 5 INT C NATURAL LA, P144; Windisch BrownS., 2008, Procs. of the Meeting of the Association for Computational Linguistics, and the Conference on Human Language Technology, Columbus, Ohio, P249, DOI DOI 10.3115/1557690.1557762; Yang Y., 2019, Adv. Neural Inf. Process. Syst, V32, P11; Yenicelik D., 2020, P 3 BLACKBOXNLP WORK, P156; Zhong Z., 2010, Proceedings of the ACL 2010 system demonstrations, P78; Zhuang L., 2021, P 20 CHINESE NATL C, P1218; ZIPF G K, 1945, J Gen Psychol, V33, P251; Zwicky A.M., 1975, SYNTAX SEMANTICS, V4, P1	273	0	0	0	0	MIT PRESS	CAMBRIDGE	ONE ROGERS ST, CAMBRIDGE, MA 02142-1209 USA	0891-2017	1530-9312		COMPUT LINGUIST	Comput. Linguist.	MAR 1	2023	50	1					351	417		10.1162/coli_a_00500	http://dx.doi.org/10.1162/coli_a_00500			67	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics; Language & Linguistics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Computer Science; Linguistics	OC9U9		Green Published, gold			2024-07-03	WOS:001205186000003
J	Lewandowski, M; Lukowicz, P; Swietlik, D; Baranska-Rybak, W				Lewandowski, Milosz; Lukowicz, Pawel; Swietlik, Dariusz; Baranska-Rybak, Wioletta			ChatGPT-3.5 and ChatGPT-4 dermatological knowledge level based on the Specialty Certificate Examination in Dermatology	CLINICAL AND EXPERIMENTAL DERMATOLOGY			English	Article								Background The global use of artificial intelligence (AI) has the potential to revolutionize the healthcare industry. Despite the fact that AI is becoming more popular, there is still a lack of evidence on its use in dermatology.Objectives To determine the capacity of ChatGPT-3.5 and ChatGPT-4 to support dermatology knowledge and clinical decision-making in medical practice.Methods Three Specialty Certificate Examination in Dermatology tests, in English and Polish, consisting of 120 single-best-answer, multiple-choice questions each, were used to assess the performance of ChatGPT-3.5 and ChatGPT-4.Results ChatGPT-4 exceeded the 60% pass rate in every performed test, with a minimum of 80% and 70% correct answers for the English and Polish versions, respectively. ChatGPT-4 performed significantly better on each exam (P < 0.01), regardless of language, compared with ChatGPT-3.5. Furthermore, ChatGPT-4 answered clinical picture-type questions with an average accuracy of 93.0% and 84.2% for questions in English and Polish, respectively. The difference between the tests in Polish and English were not significant; however, ChatGPT-3.5 and ChatGPT-4 performed better overall in English than in Polish by an average of 8 percentage points for each test. Incorrect ChatGPT answers were highly correlated with a lower difficulty index, denoting questions of higher difficulty in most of the tests (P < 0.05).Conclusions The dermatology knowledge level of ChatGPT was high, and ChatGPT-4 performed significantly better than ChatGPT-3.5. Although the use of ChatGPT will not replace a doctor's final decision, physicians should support the development of AI in dermatology to raise the standards of medical care.	[Lewandowski, Milosz; Baranska-Rybak, Wioletta] Med Univ Gdansk, Fac Med, Dept Dermatol Venereol & Allergol, Gdansk, Poland; [Lukowicz, Pawel; Swietlik, Dariusz] Med Univ Gdansk, Div Biostat & Neural Networks, Gdansk, Poland	Fahrenheit Universities; Medical University Gdansk; Fahrenheit Universities; Medical University Gdansk	Lewandowski, M (corresponding author), Med Univ Gdansk, Fac Med, Dept Dermatol Venereol & Allergol, Gdansk, Poland.	milosz.lewandowski@gumed.edu.pl	Lewandowski, Miłosz/ABD-2045-2021	Lewandowski, Miłosz/0000-0002-3561-5705; Lukowicz, Pawel/0009-0008-8643-1990; Swietlik, Dariusz/0000-0002-9127-7368	The manuscript was prepared entirely by the authors with no direct assistance from generative artificial intelligence, large language models or similar technologies.	The manuscript was prepared entirely by the authors with no direct assistance from generative artificial intelligence, large language models or similar technologies.	The manuscript was prepared entirely by the authors with no direct assistance from generative artificial intelligence, large language models or similar technologies.	AI Guider, LIST LANG CHATGPT SU; Ali R., 2023, MEDRXIV, DOI 10.1101/2023.03.25.23287743; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Beltrami Eric J, 2024, J Am Acad Dermatol, V90, P879, DOI 10.1016/j.jaad.2023.02.052; Chan S, 2020, DERMATOLOGY THER, V10, P365, DOI 10.1007/s13555-020-00372-0; Dick V, 2019, JAMA DERMATOL, V155, P1291, DOI 10.1001/jamadermatol.2019.1375; Dunn C, 2023, J AM ACAD DERMATOL, V89, P388, DOI 10.1016/j.jaad.2023.04.005; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Liopyris K, 2022, DERMATOLOGY THER, V12, P2637, DOI 10.1007/s13555-022-00833-8; OpenAI, MODELS; OpenAI, GPT 4; Polesie S, 2023, ACTA DERM-VENEREOL, V103, DOI 10.2340/actadv.v103.9593; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.02.23285399; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sanderson K., GPT 4 IS HERE WHAT S; Young AT, 2020, J INVEST DERMATOL, V140, P1504, DOI 10.1016/j.jid.2020.02.026; Zielinski C., CHATGPT SCHOLARLY MA	22	16	16	44	118	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0307-6938	1365-2230		CLIN EXP DERMATOL	Clin. Exp. Dermatol.	SEP 14	2023	49	7					686	691		10.1093/ced/llad255	http://dx.doi.org/10.1093/ced/llad255		AUG 2023	6	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	WF2R7	37540015				2024-07-03	WOS:001066785500001
J	Abdelghani, R; Wang, YH; Yuan, XD; Wang, T; Lucas, P; Sauzeon, H; Oudeyer, PY				Abdelghani, Rania; Wang, Yen-Hsiang; Yuan, Xingdi; Wang, Tong; Lucas, Pauline; Sauzeon, Helene; Oudeyer, Pierre-Yves			GPT-3-Driven Pedagogical Agents to Train Children's Curious Question-Asking Skills	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article						GPT-3; Large Language Models; Education; Prompt-Based Content Generation; Curiosity-Driven Learning; Question-Asking; Field Study; Children; Educational Technologies	INTRINSIC MOTIVATION; EPISTEMIC CURIOSITY; LANGUAGE MODELS; VALIDATION	The ability of children to ask curiosity-driven questions is an important skill that helps improve their learning. For this reason, previous research has explored designing specific exercises to train this skill. Several of these studies relied on providing semantic and linguistic cues to train them to ask more of such questions (also called divergent questions). But despite showing pedagogical efficiency, this method is still limited as it relies on generating the said cues by hand, which can be a very long and costly process. In this context, we propose to leverage advances in the natural language processing field (NLP) and investigate the efficiency of using a large language model (LLM) for automating the production of key parts of pedagogical content within a curious question-asking (QA) training. We study generating the said content using the "prompt-based" method that consists of explaining the task to the LLM in natural text. We evaluate the output using human experts annotations and comparisons with hand-generated content. Results suggested indeed the relevance and usefulness of this content. We then conduct a field study in primary school (75 children aged 9-10), where we evaluate children's QA performance when having this training. We compare 3 types of content: 1) hand-generated content that proposes "closed" cues leading to predefined questions; 2) GPT-3-generated content that proposes the same type of cues; 3) GPT-3-generated content that proposes "open" cues leading to several possible questions. Children were assigned to either one of these groups. Based on human annotations of the questions generated, we see a similar QA performance between the two "closed" trainings (showing the scalability of the approach using GPT-3), and a better one for participants with the "open" training. These results suggest the efficiency of using LLMs to support children in generating more curious questions, using a natural language prompting approach that affords usability by teachers and other users not specialists of AI techniques. Furthermore, results also show that open-ended content may be more suitable for training curious question-asking skills.	[Abdelghani, Rania; Sauzeon, Helene; Oudeyer, Pierre-Yves] Inria Bordeaux, Flowers Team, Talence, France; [Abdelghani, Rania] EvidenceB, Paris, France; [Abdelghani, Rania; Lucas, Pauline; Sauzeon, Helene] Univ Bordeaux, Talence, France; [Wang, Yen-Hsiang] Natl Chung Hsing Univ, Taichung, Taiwan; [Yuan, Xingdi; Wang, Tong; Oudeyer, Pierre-Yves] Microsoft Res, Montreal, PQ, Canada	Universite de Bordeaux; National Chung Hsing University	Abdelghani, R (corresponding author), Inria Bordeaux, Flowers Team, Talence, France.; Abdelghani, R (corresponding author), EvidenceB, Paris, France.; Abdelghani, R (corresponding author), Univ Bordeaux, Talence, France.	rania.abdelghani@inria.fr	Abdelghani, Rania/HPD-2516-2023; Sauzéon, Hélène/T-1178-2019	Sauzéon, Hélène/0000-0001-5781-9891; ABDELGHANI, Rania/0000-0002-6361-6609	EvidenceB; French National Association of Research and Technology (ANRT); DeepCuriosity AI Chair project (ANR)	EvidenceB; French National Association of Research and Technology (ANRT)(Agence Nationale de la Recherche (ANR)); DeepCuriosity AI Chair project (ANR)(Agence Nationale de la Recherche (ANR))	This work has been funded by the educational technologies company EvidenceB, the French National Association of Research and Technology (ANRT), and the DeepCuriosity AI Chair project (ANR). The authors thank the teachers who participated in this study and the research team members who helped conduct the experiments in classes.	Abdelghani R, 2022, INT J HUM-COMPUT ST, V167, DOI 10.1016/j.ijhcs.2022.102887; Alaimi M, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376776; Aleven V, 1999, FRONT ARTIF INTEL AP, V50, P199; [Anonymous], 1991, Questioning skills for teachers. What research says to the teacher; [Anonymous], 1963, Merrill-Palmer Quarterly; [Anonymous], 2000, Human Resource Development Quarterly, DOI [10.1002/1532-1096(200021)11:1lt;5::AID-HRDQ2gt;3.0.CO;2-A, DOI 10.1002/1532-1096(200021)11:1LT;5::AID-HRDQ2GT;3.0.CO;2-A]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berlyne DE, 1954, BRIT J PSYCHOL, V45, P180, DOI 10.1111/j.2044-8295.1954.tb01243.x; Bjork RA., 2017, CREATING DESIRABLE D; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Brown J.C., 2005, P C HUM LANG TECHN E, P819, DOI DOI 10.3115/1220575.1220678; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Ceha J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300636; Cordova DI, 1996, J EDUC PSYCHOL, V88, P715, DOI 10.1037/0022-0663.88.4.715; Devlin J., 2018, BERT PRE TRAINING DE; Diakidoy IAN, 2002, J CREATIVE BEHAV, V36, P41, DOI 10.1002/j.2162-6057.2002.tb01055.x; GALL MD, 1970, REV EDUC RES, V40, P707, DOI 10.3102/00346543040005707; Gordon G, 2015, ACMIEEE INT CONF HUM, P91, DOI 10.1145/2696454.2696469; Goupil L, 2023, COGNITION, V231, DOI 10.1016/j.cognition.2022.105325; GRAESSER AC, 1992, QUESTIONS AND INFORMATION SYSTEMS, P167; GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.3102/00028312031001104; Guay F, 2022, CAN J SCH PSYCHOL, V37, P75, DOI 10.1177/08295735211055355; HART S G, 1988, P139; He R., 2021, J OFRESEARCH CHILDHO, V29, P551, DOI [10.1080/02568543.2015.1073199, DOI 10.1080/02568543.2015.1073199]; Humphries J, 2015, J RES CHILD EDUC, V29, P551, DOI 10.1080/02568543.2015.1073199; Jepma M, 2012, FRONT BEHAV NEUROSCI, V6, DOI 10.3389/fnbeh.2012.00005; Jiang ZB, 2021, T ASSOC COMPUT LING, V9, P962, DOI 10.1162/tacl_a_00407; Jirout J., 2018, NEW SCI CURIOSITY, P243; Jones A, 2018, INT J SOC ROBOT, V10, P439, DOI 10.1007/s12369-017-0430-y; Jost J T, 1998, Pers Soc Psychol Rev, V2, P137, DOI 10.1207/s15327957pspr0202_6; Kang MJ, 2009, PSYCHOL SCI, V20, P963, DOI 10.1111/j.1467-9280.2009.02402.x; Kashdan TB, 2004, J PERS ASSESS, V82, P291, DOI 10.1207/s15327752jpa8203_05; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kumar S., 2021, arXiv; Law E, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4098, DOI 10.1145/2858036.2858144; Lefavrais P., 2005, ALOUETTE R TEST ANAL; Li X., 2021, ARXIV; Litman JA, 2003, J PERS ASSESS, V80, P75, DOI 10.1207/S15327752JPA8001_16; Litman JA, 2005, COGNITION EMOTION, V19, P793, DOI 10.1080/02699930541000101; Liu J., 2022, ARXIV; LOEWENSTEIN G, 1994, PSYCHOL BULL, V116, P75, DOI 10.1037/0033-2909.116.1.75; Lu Y., 2021, ARXIV; Marx A, 2000, LEARNING ENVIRON RES, V2, P249, DOI [10.1023/A:1009901922191, DOI 10.1023/A:1009901922191]; Mehta H., 2018, CogSci; Metcalfe J, 2020, CURR OPIN BEHAV SCI, V35, P40, DOI 10.1016/j.cobeha.2020.06.007; Min S., 2022, ARXIV; Murayama K, 2019, EDUC PSYCHOL REV, V31, P875, DOI 10.1007/s10648-019-09499-9; Oudeyer PY, 2007, IEEE T EVOLUT COMPUT, V11, P265, DOI 10.1109/TEVC.2006.890271; Post T, 2019, MOTIV EMOTION, V43, P159, DOI 10.1007/s11031-018-9728-9; Raffel C, 2020, J MACH LEARN RES, V21; Roebers CM, 2007, BRIT J DEV PSYCHOL, V25, P109, DOI 10.1348/026151006X104392; Rubin O., 2021, ARXIV; Ryan R. M., 2000, COGNITION INSTRUCT, V9, P177, DOI [10.1207/s1532690xci0903_1, DOI 10.1207/S1532690XCI0903_1]; SCARDAMALIA M, 1992, COGNITION INSTRUCT, V9, P177, DOI 10.1207/s1532690xci0903_1; Silvervarg Flycht-Eriksson A. S., 2010, P 2 WORKSH NAT LANG; Stahl AE, 2015, SCIENCE, V348, P91, DOI 10.1126/science.aaa3799; Steuer T., 2021, ARXIV; Sultan MA, 2014, ACM-IEEE J CONF DIG, P379, DOI 10.1109/JCDL.2014.6970194; Ten A, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26196-w; Tullis JG, 2015, MEM COGNITION, V43, P634, DOI 10.3758/s13421-014-0478-y; VALLERAND RJ, 1989, CAN J BEHAV SCI, V21, P323, DOI 10.1037/h0079855; von Stumm S, 2011, PERSPECT PSYCHOL SCI, V6, P574, DOI 10.1177/1745691611421204; Yuan X., 2022, ARXIV; Zhao TZ, 2021, PR MACH LEARN RES, V139	64	8	8	29	50	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	JUN	2024	34	2					483	518		10.1007/s40593-023-00340-7	http://dx.doi.org/10.1007/s40593-023-00340-7		JUN 2023	36	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	SP4N3		Green Submitted			2024-07-03	WOS:001020167600001
J	Buehler, MJ				Buehler, Markus J.			MechGPT, a Language-Based Strategy for Mechanics and Materials Modeling That Connects Knowledge Across Scales, Disciplines, and Modalities	APPLIED MECHANICS REVIEWS			English	Review						mechanics; materials; failure; AI; scientific ML; attention; transformer; language model; GPT; human-machine		For centuries, researchers have sought out ways to connect disparate areas of knowledge. While early scholars (Galileo, da Vinci, etc.) were experts across fields, specialization took hold later. With the advent of Artificial Intelligence, we can now explore relationships across areas (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-art). To achieve this, we use a fine-tuned large language model (LLM), here for a subset of knowledge in multiscale materials failure. The approach includes the use of a general-purpose LLM to distill question-answer pairs from raw sources followed by LLM fine-tuning. The resulting MechGPT LLM foundation model is used in a series of computational experiments to explore its capacity for knowledge retrieval, various language tasks, hypothesis generation, and connecting knowledge across disparate areas. While the model has some ability to recall knowledge from training, we find that LLMs are particularly useful for extracting structural insights through Ontological Knowledge Graphs. These interpretable graph structures provide explanatory insights, frameworks for new research questions, and visual representations of knowledge that also can be used in retrieval-augmented generation. Three versions of MechGPT are discussed, featuring different sizes from 13 x 109 to 70 x 109 parameters, and reaching context lengths of more than 10,000 tokens. This provides ample capacity for sophisticated retrieval augmented strategies, as well as agent-based modeling where multiple LLMs interact collaboratively and/or adversarially, the incorporation of new data from the literature or web searches, as well as multimodality.	[Buehler, Markus J.] MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Buehler, Markus J.] MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT)	Buehler, MJ (corresponding author), MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Buehler, MJ (corresponding author), MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	mbuehler@MIT.EDU	Buehler, Markus/C-4580-2008	Buehler, Markus/0000-0002-4173-9659	Army Research Office [W911NF1920098, W911NF2220213]; Office of Naval Research [N00014-19-1-2375, N00014-20-1-2189]; United States Department of Agriculture [2021-69012-35978]	Army Research Office; Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research); United States Department of Agriculture(United States Department of Agriculture (USDA))	Army Research Office (Grant Nos. W911NF1920098 and W911NF2220213; Funder ID: 10.13039/100000183).Office of Naval Research (Grant Nos. N00014-19-1-2375 and N00014-20-1-2189; Funder ID: 10.13039/100000006).United States Department of Agriculture (Grant No. 2021-69012-35978; Funder ID: 10.13039/100000199).	Abid A, 2019, Arxiv, DOI [arXiv:1906.02569, DOI 10.48550/ARXIV.1906.02569]; Aboelkassem Y, 2019, CURR OPIN BIOMED ENG, V11, P35, DOI 10.1016/j.cobme.2019.09.005; [Anonymous], 2017, STAT-US, V1050; Barreiro DL, 2019, MACROMOL BIOSCI, V19, DOI 10.1002/mabi.201800253; BATES M, 1995, P NATL ACAD SCI USA, V92, P9977, DOI 10.1073/pnas.92.22.9977; Blecher L, 2023, Arxiv, DOI [arXiv:2308.13418, 10.48550/arXiv.2308.13418]; Bock FE, 2019, FRONT MATER, V6, DOI 10.3389/fmats.2019.00110; Bottou L, 2023, Arxiv, DOI [arXiv:2310.01425, 10.48550/arXiv.2310.01425]; Brodnik NR, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062773; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buehler M.J., 2008, ATOMISTIC MODELING M, P1; Buehler MJ, 2023, J MECH PHYS SOLIDS, V181, DOI 10.1016/j.jmps.2023.105454; Buehler MJ, 2023, J APPL PHYS, V134, DOI 10.1063/5.0157367; Buehler MJ, 2023, J MATER RES, V38, P1317, DOI 10.1557/s43578-023-00892-3; Buehler MJ, 2022, J APPL MECH-T ASME, V89, DOI 10.1115/1.4055730; Buehler MJ, 2004, J CHIN INST ENG, V27, P763, DOI 10.1080/02533839.2004.9670927; Canadija M, 2021, CARBON, V184, P891, DOI 10.1016/j.carbon.2021.08.091; Chen BH, 2024, Arxiv, DOI [arXiv:2310.14735, 10.48550/arXiv.2310.14735]; Chen WH, 2023, Arxiv, DOI [arXiv:2211.12588, DOI 10.48550/ARXIV.2211.12588]; Chen X, 2022, AIP ADV, V12, DOI 10.1063/5.0080842; Chern IC, 2023, Arxiv, DOI arXiv:2307.13528; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Dhuliawala S, 2023, Arxiv, DOI [arXiv:2309.11495, 10.48550/arXiv.2309.11495]; Fernando C, 2023, Arxiv, DOI arXiv:2309.16797; Ge YQ, 2023, Arxiv, DOI [arXiv:2304.04370, 10.48550/arXiv.2304.04370]; Giesa T, 2012, ADV ENG MATER, V14, P810, DOI 10.1002/adem.201200109; Giesa T, 2011, BIONANOSCIENCE, V1, P153, DOI 10.1007/s12668-011-0022-5; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; He-Yueya J, 2023, Arxiv, DOI arXiv:2304.09102; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu Yiwen, 2023, APL Machine Learning, DOI 10.1063/5.0134317; Jung GS, 2017, ANNU REV BIOMED ENG, V19, P435, DOI 10.1146/annurev-bioeng-071516-044555; Kingma D. P., 2017, ARXIV; Lee N., 2023, HuggingFace repository; Lewis P., 2020, Adv. Neural Inf. Process. Syst.; Luu RK, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062310; Luu RK, 2023, APPL PHYS LETT, V122, DOI 10.1063/5.0155890; Paszke A, 2019, ADV NEUR IN, V32; Peng GCY, 2021, ARCH COMPUT METHOD E, V28, P1017, DOI 10.1007/s11831-020-09405-5; Qin Z, 2013, J APPL MECH-T ASME, V80, DOI 10.1115/1.4023641; Radford A., 2023, OpenAI; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A, 2021, PR MACH LEARN RES, V139; Schiotz J, 2003, SCIENCE, V301, P1357, DOI 10.1126/science.1086636; Society of Engineering Science, 2023, Homepage-Society of Engineering Science; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Sung Park J., 2023, P 36 ANN ACM S USER, P1, DOI DOI 10.1145/3586183.3606763; Taylor R, 2022, arXiv; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; van der Zant T., 2013, Philosophy and Theory of Artificial Intelligence, V5, P107, DOI [10.1007/978-3-642-31674-6, DOI 10.1007/978-3-642-31674-68]; Vaswani A, 2017, ADV NEUR IN, V30; Wang CX, 2023, Arxiv, DOI arXiv:2310.07521; Wolfram S., 2023, Chatgpt gets its 'wolfram superpowers'!; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]	56	5	5	37	37	ASME	NEW YORK	TWO PARK AVE, NEW YORK, NY 10016-5990 USA	0003-6900	2379-0407		APPL MECH REV	Appl. Mech. Rev.	MAR 1	2024	76	2							021001	10.1115/1.4063843	http://dx.doi.org/10.1115/1.4063843			35	Mechanics	Science Citation Index Expanded (SCI-EXPANDED)	Mechanics	NL9Z2		Green Submitted			2024-07-03	WOS:001200739600001
J	Lim, DYZ; Tan, YB; Koh, JTE; Tung, JYM; Sng, GGR; Tan, DMY; Tan, CK				Lim, Daniel Yan Zheng; Tan, Yu Bin; Koh, Jonathan Tian En; Tung, Joshua Yi Min; Sng, Gerald Gui Ren; Tan, Damien Meng Yew; Tan, Chee-Kiat			ChatGPT on guidelines: Providing contextual knowledge to GPT allows it to provide advice on appropriate colonoscopy intervals	JOURNAL OF GASTROENTEROLOGY AND HEPATOLOGY			English	Article						Artificial intelligence; Colonoscopy; Colorectal cancer; GPT; Screening and surveillance interval	SOCIETY TASK-FORCE; CLINICAL-PRACTICE GUIDELINES; COLORECTAL-CANCER; AMERICAN SOCIETY; PRACTICE UPDATE; MANAGEMENT; RECOMMENDATIONS; SURVEILLANCE; DIAGNOSIS; COLON	Background and Aim Colonoscopy is commonly used in screening and surveillance for colorectal cancer. Multiple different guidelines provide recommendations on the interval between colonoscopies. This can be challenging for non-specialist healthcare providers to navigate. Large language models like ChatGPT are a potential tool for parsing patient histories and providing advice. However, the standard GPT model is not designed for medical use and can hallucinate. One way to overcome these challenges is to provide contextual information with medical guidelines to help the model respond accurately to queries. Our study compares the standard GPT4 against a contextualized model provided with relevant screening guidelines. We evaluated whether the models could provide correct advice for screening and surveillance intervals for colonoscopy.Methods Relevant guidelines pertaining to colorectal cancer screening and surveillance were formulated into a knowledge base for GPT. We tested 62 example case scenarios (three times each) on standard GPT4 and on a contextualized model with the knowledge base.Results The contextualized GPT4 model outperformed the standard GPT4 in all domains. No high-risk features were missed, and only two cases had hallucination of additional high-risk features. A correct interval to colonoscopy was provided in the majority of cases. Guidelines were appropriately cited in almost all cases.Conclusions A contextualized GPT4 model could identify high-risk features and quote appropriate guidelines without significant hallucination. It gave a correct interval to the next colonoscopy in the majority of cases. This provides proof of concept that ChatGPT with appropriate refinement can serve as an accurate physician assistant.	[Lim, Daniel Yan Zheng; Tan, Yu Bin; Koh, Jonathan Tian En; Tan, Damien Meng Yew; Tan, Chee-Kiat] Singapore Gen Hosp, Dept Gastroenterol & Hepatol, Singapore, Singapore; [Sng, Gerald Gui Ren] Singapore Gen Hosp, Dept Endocrinol, Singapore, Singapore; [Tung, Joshua Yi Min] Singapore Gen Hosp, Dept Urol, Singapore, Singapore; [Lim, Daniel Yan Zheng; Tan, Damien Meng Yew; Tan, Chee-Kiat] Duke NUS Med Sch, Med Acad Clinin Programme, Singapore, Singapore; [Lim, Daniel Yan Zheng] Singapore Gen Hosp, Outram Rd, Singapore 169608, Singapore	Singapore General Hospital; Singapore General Hospital; Singapore General Hospital; National University of Singapore; Singapore General Hospital	Lim, DYZ (corresponding author), Singapore Gen Hosp, Outram Rd, Singapore 169608, Singapore.	limyzd@gmail.com	Tan, Chee-Kiat/AAF-6443-2019; Lim, Daniel Yan Zheng/AGY-3425-2022	Tan, Chee-Kiat/0000-0001-6992-2319; Lim, Daniel Yan Zheng/0000-0002-9715-6970; Koh, Jonathan TE/0000-0003-3694-2748; TAN, YU BIN/0000-0002-4639-5760				[Anonymous], OpenAI; Bee YM., 2023, DIABETES CARE; Boardman LA, 2020, CLIN GASTROENTEROL H, V18, P2415, DOI 10.1016/j.cgh.2020.05.058; Boland CR, 2022, AM J GASTROENTEROL, V117, P846, DOI 10.14309/ajg.0000000000001755; Bowlus CL, 2023, HEPATOLOGY, V77, P659, DOI 10.1002/hep.32771; Davidson KW, 2021, JAMA-J AM MED ASSOC, V325, P1965, DOI 10.1001/jama.2021.6238; Giardiello FM, 2014, DIS COLON RECTUM, V57, P1025, DOI 10.1097/DCR.000000000000000; Gupta S, 2020, AM J GASTROENTEROL, V115, P415, DOI 10.14309/ajg.0000000000000544; Hardiman KM, 2021, DIS COLON RECTUM, V64, P517, DOI 10.1097/DCR.0000000000001984; Herzig D, 2017, DIS COLON RECTUM, V60, P881, DOI 10.1097/DCR.0000000000000912; Herzig DO, 2017, DIS COLON RECTUM, V60, P137, DOI 10.1097/DCR.0000000000000785; Kahi CJ, 2016, GASTROENTEROLOGY, V150, P758, DOI 10.1053/j.gastro.2016.01.001; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lee TC, 2023, Gastroenterology; Medenilla A., 2023, PLoS Digital Health, V2; Murthy SK, 2021, GASTROENTEROLOGY, V161, P1043, DOI 10.1053/j.gastro.2021.05.063; Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174; Rubenstein JH, 2015, GASTROENTEROLOGY, V149, P777, DOI 10.1053/j.gastro.2015.07.036; Shaukat A, 2021, AM J GASTROENTEROL, V116, P458, DOI 10.14309/ajg.0000000000001122; Shieh, BEST PRACTICES PROMP; Syngal S, 2015, AM J GASTROENTEROL, V110, P223, DOI 10.1038/ajg.2014.435; Yang J, 2020, GASTROINTEST ENDOSC, V91, P963, DOI 10.1016/j.gie.2020.01.028	22	7	7	13	20	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0815-9319	1440-1746		J GASTROEN HEPATOL	J. Gastroenterol. Hepatol.	JAN	2024	39	1					81	106		10.1111/jgh.16375	http://dx.doi.org/10.1111/jgh.16375		OCT 2023	26	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	GJ7J5	37855067				2024-07-03	WOS:001086157300001
C	Gao, SZ; Wen, XC; Gao, CY; Wang, WX; Zhang, HY; Lyu, MR			IEEE	Gao, Shuzheng; Wen, Xin-Cheng; Gao, Cuiyun; Wang, Wenxuan; Zhang, Hongyu; Lyu, Michael R.			What Makes Good In-context Demonstrations for Code Intelligence Tasks with LLMs?	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc				Pre-trained models of source code have gained widespread popularity in many code intelligence tasks. Recently, with the scaling of the model and corpus size, large language models have shown the ability of in-context learning (ICL). ICL employs task instructions and a few examples as demonstrations, and then inputs the demonstrations to the language models for making predictions. This new learning paradigm is training-free and has shown impressive performance in various natural language processing and code intelligence tasks. However, the performance of ICL heavily relies on the quality of demonstrations, e.g., the selected examples. It is important to systematically investigate how to construct a good demonstration for code-related tasks. In this paper, we empirically explore the impact of three key factors on the performance of ICL in code intelligence tasks: the selection, order, and number of demonstration examples. We conduct extensive experiments on three code intelligence tasks including code summarization, bug fixing, and program synthesis. Our experimental results demonstrate that all the above three factors dramatically impact the performance of ICL in code intelligence tasks. Additionally, we summarize our findings and provide takeaway suggestions on how to construct effective demonstrations, taking into account these three perspectives. We also show that a carefully-designed demonstration based on our findings can lead to substantial improvements over widely-used demonstration construction methods, e.g., improving BLEU-4, EM, and EM by at least 9.90%, 175.96%, and 50.81% on code summarization, bug fixing, and program synthesis, respectively.	[Gao, Shuzheng; Wen, Xin-Cheng; Gao, Cuiyun] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China; [Wang, Wenxuan; Lyu, Michael R.] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Peoples R China; [Zhang, Hongyu] Chongqing Univ, Sch Big Data & Software Engn, Chongqing, Peoples R China; [Gao, Shuzheng] Chinese Univ Hong Kong, Hong Kong, Peoples R China; [Gao, Cuiyun] Peng Cheng Lab, Shenzhen, Peoples R China	Harbin Institute of Technology; Chinese University of Hong Kong; Chongqing University; Chinese University of Hong Kong; Peng Cheng Laboratory	Gao, CY (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.; Gao, CY (corresponding author), Peng Cheng Lab, Shenzhen, Peoples R China.	szgao98@gmail.com; xiamenwxc@foxmail.com; gaocuiyun@hit.edu.cn; wxwang@cse.cuhk.edu.hk; hyzhang@cqu.edu.cn; lyu@cse.cuhk.edu.hk	Gao, Shuzheng/JZT-4452-2024; Wen, Xin-Cheng/JFK-4468-2023; Wang, Wenxuan/AAW-9073-2020		National Key R&D Pro-Science Foundation of China [62002084]; Natural Science Foundation of Guangdong Province [2023A1515011959]; Shenzhen Basic Research [JCYJ20220531095214031]; Major Key Project of PCL [PCL2022A03, PCL2021A02, PCL2021A09]; Research Grants Council of the Hong Kong Special Administrative Region, China [CUHK 14206921]	National Key R&D Pro-Science Foundation of China; Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Shenzhen Basic Research; Major Key Project of PCL; Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council)	This research is supported by National Key R&D Pro-Science Foundation of China under project (No. 62002084), Natural Science Foundation of Guangdong Province (Project No. 2023A1515011959), Shenzhen Basic Research (General Project No. JCYJ20220531095214031), and the Major Key Project of PCL (Grant No. PCL2022A03, PCL2021A02, PCL2021A09). The work is also supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (No. CUHK 14206921 of the General Research Fund).	Ahmad W., 2020, P 58 ANN M ASS COMPU, P4998, DOI 10.18653/v1/2020.acl-main.449; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Ahmed T, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559555; Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown Charles E, 1998, Applied multivariate statistics in geohydrology and related sciences, P155; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bulatov A., 2022, Advances in Neural Information Processing Systems; Chakraborty Saikat, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P18, DOI 10.1145/3540250.3549162; Chakraborty S, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P443, DOI 10.1109/ASE51524.2021.9678559; ChatGPT, 2022, ABOUT US; Chen M., 2021, arXiv; Cheng Z., 2023, Binding language models in symbolic languages; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Gao SZ, 2023, PROC INT CONF SOFTW, P30, DOI 10.1109/ICSE48619.2023.00015; Gao SZ, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3522674; Gensim, 2010, Gensim package; Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu C.-H., 2022, FINDINGS ASS COMPUTA, P2627; Hu E.J., 2022, 10 INT C LEARN REPR; Hu X, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2269; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Khan JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559548; Kojima T, 2022, NeurIPS; Levy I, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1401; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lu Shuai, 2021, P NEUR INF PROC SYST, P1; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Luan Y, 2021, T ASSOC COMPUT LING, V9, P329, DOI 10.1162/tacl_a_00369; Nashid N, 2023, PROC INT CONF SOFTW, P2450, DOI 10.1109/ICSE48619.2023.00205; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2023, GPT-4 Technical Report; OpenAI-pricing, 2022, Openai-pricing; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng Y, 2023, Arxiv, DOI [arXiv:2306.01394, DOI 10.48550/ARXIV.2306.01394, 10.48550/arXiv.2306.01394]; Poesia Gabriel, 2022, 10 INT C LEARN REPR; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Rubin O, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2655; Sentence-transformers, st-codesearch-distilroberta; Shi E., 2023, Cocosoda: Effective contrastive learning for code search, P2198; Shi ES, 2022, PROC INT CONF SOFTW, P1597, DOI 10.1145/3510003.3510060; Su H., 2023, Selective annotation makes language models better few-shot learners; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Tufano M, 2019, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2019.00021; Vaswani A, 2017, ADV NEUR IN, V30; Wang Chaozheng, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P382, DOI 10.1145/3540250.3549113; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei BL, 2020, IEEE INT CONF AUTOM, P349, DOI 10.1145/3324884.3416578; Wei J., 2022, Trans. Mach. Learn. Res., V2022; Wei J., 2022, NEURIPS; Wei MS, 2022, PROC INT CONF SOFTW, P376, DOI 10.1145/3510003.3510159; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Yin PC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P440, DOI 10.18653/v1/P17-1041; Yin PC, 2018, IEEE WORK CONF MIN S, P476, DOI 10.1145/3196398.3196408; Zeng ZR, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P39, DOI 10.1145/3533767.3534390; Zhang J, 2020, PROC INT CONF SOFTW, P1385, DOI 10.1145/3377811.3380383; Zheng QK, 2023, Arxiv, DOI [arXiv:2303.17568, 10.48550/arXiv.2303.17568]	68	1	1	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							761	773		10.1109/ASE56229.2023.00109	http://dx.doi.org/10.1109/ASE56229.2023.00109			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200061
J	Lai, YK; Liao, FQ; Zhao, JL; Zhu, CP; Hu, Y; Li, ZS				Lai, Yongkang; Liao, Foqiang; Zhao, Jiulong; Zhu, Chunping; Hu, Yi; Li, Zhaoshen			Exploring the capacities of ChatGPT: A comprehensive evaluation of its accuracy and repeatability in addressing <i>helicobacter pylori</i>-related queries	HELICOBACTER			English	Article						Helicobacter pylori; observational study; treatment	ERADICATION	Background: Educational initiatives on Helicobacter pylori (H. pylori) constitute a highly effective approach for preventing its infection and establishing standardized protocols for its eradication. ChatGPT, a large language model, is a potentially patient-friendly online tool capable of providing health-related knowledge. This study aims to assess the accuracy and repeatability of ChatGPT in responding to questions related to H. pylori. Materials and Methods: Twenty-one common questions about H. pylori were collected and categorized into four domains: basic knowledge, diagnosis, treatment, and prevention. ChatGPT was utilized to individually answer the aforementioned 21 questions. Its responses were independently assessed by two experts on H. pylori. Questions with divergent ratings were resolved by a third reviewer. Cohen's kappa coefficient was calculated to assess the consistency between the scores of the two reviewers. Results: The responses of ChatGPT on H. pylori-related questions were generally satisfactory, with 61.9% marked as "completely correct" and 33.33% as "correct but inadequate." The repeatability of the responses of ChatGPT to H. pylori-related questions was 95.23%. Among the responses, those related to prevention (comprehensive: 75%) had the best response, followed by those on treatment (comprehensive: 66.7%), basic knowledge (comprehensive: 60%), and diagnosis (comprehensive: 50%). In the "treatment" domain, 16.6% of the ChatGPT responses were categorized as "mixed with correct or incorrect/outdated data." However, ChatGPT still lacks relevant knowledge regarding H. pylori resistance and the use of sensitive antibiotics. Conclusions: ChatGPT can provide correct answers to the majority of H. pylori-related queries. It exhibited good reproducibility and delivered responses that were easily comprehensible to patients. Further enhancement of real-time information updates and correction of inaccurate information will make ChatGPT an essential auxiliary tool for providing accurate H. pylori-related health information to patients.	[Lai, Yongkang; Zhu, Chunping; Li, Zhaoshen] Nanchang Univ, Ganzhou Peoples Hosp, Jiangxi Med Coll, Dept Gastroenterol, Nanchang, Peoples R China; [Lai, Yongkang; Zhao, Jiulong; Li, Zhaoshen] Naval Med Univ, Shanghai Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China; [Liao, Foqiang; Hu, Yi] Nanchang Univ, Affiliated Hosp 1, Jiangxi Med Coll, Dept Gastroenterol, Nanchang 330000, Peoples R China; [Zhu, Chunping; Li, Zhaoshen] Nanchang Univ, Ganzhou Peoples Hosp, Jiangxi Med Coll, Dept Gastroenterol, Ganzhou 341000, Peoples R China	Nanchang University; Naval Medical University; Nanchang University; Nanchang University	Li, ZS (corresponding author), Naval Med Univ, Shanghai Changhai Hosp, Dept Gastroenterol, Shanghai 200433, Peoples R China.; Hu, Y (corresponding author), Nanchang Univ, Affiliated Hosp 1, Jiangxi Med Coll, Dept Gastroenterol, Nanchang 330000, Peoples R China.; Zhu, CP; Li, ZS (corresponding author), Nanchang Univ, Ganzhou Peoples Hosp, Jiangxi Med Coll, Dept Gastroenterol, Ganzhou 341000, Peoples R China.	chunpingzhu2012@163.com; ndyfy06202@ncu.edu.cn; chzshenli@163.com			Nanchang University Graduate Student Innovation Fund	Nanchang University Graduate Student Innovation Fund	We thank Bullet Edits Limited and Home for researchers for the linguistic editing and proofreading of the manuscript.	Argueta EA, 2022, GASTROENTEROLOGY, V162, P32, DOI 10.1053/j.gastro.2021.10.048; Campbell DJ, 2024, THYROID, V34, P371, DOI 10.1089/thy.2023.0491; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Darkhabani M, 2023, AUTOIMMUN REV, V22, DOI 10.1016/j.autrev.2023.103360; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Ding SZ, 2022, GUT, V71, P238, DOI 10.1136/gutjnl-2021-325630; Du RC, 2023, HELICOBACTER, V28, DOI 10.1111/hel.13007; Du YQ, 2020, J GASTROEN HEPATOL, V35, P624, DOI 10.1111/jgh.14947; El Haj M, 2023, AGEING RES REV, V92, DOI 10.1016/j.arr.2023.102117; Fallone CA, 2019, GASTROENTEROLOGY, V157, P44, DOI 10.1053/j.gastro.2019.04.011; Gisbert JP, 2011, ALIMENT PHARM THER, V34, P1255, DOI 10.1111/j.1365-2036.2011.04887.x; Graham DY, 2022, GUT, V71, P643, DOI 10.1136/gutjnl-2021-326170; Hanci SY, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000035543; He ZX, 2023, J MED INTERNET RES, V25, DOI 10.2196/41518; Kong WW, 2021, J MED INTERNET RES, V23, DOI 10.2196/30409; Lai YK, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1231240; Liou JM, 2020, GUT, V69, P2093, DOI 10.1136/gutjnl-2020-322368; Lunn RM, 2022, JNCI-J NATL CANCER I, V114, P1441, DOI 10.1093/jnci/djac164; Luo MM, 2020, HELICOBACTER, V25, DOI 10.1111/hel.12682; Malfertheiner P, 2023, NAT REV DIS PRIMERS, V9, DOI 10.1038/s41572-023-00431-8; Malfertheiner P, 2022, GUT, V71, P1724, DOI 10.1136/gutjnl-2022-327745; Nyssen OP, 2021, GUT, V70, P40, DOI 10.1136/gutjnl-2020-321372; Osipenko MF, 2014, TERAPEVT ARKH, V86, P27; Prestin A, 2015, J HEALTH COMMUN, V20, P790, DOI 10.1080/10810730.2015.1018590; Ralser A, 2023, GUT, V72, P1258, DOI 10.1136/gutjnl-2022-328075; Tan W, 2024, HELICOBACTER, V29, DOI 10.1111/hel.13029; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Wang CH, 2015, WORLD J GASTROENTERO, V21, P11179, DOI 10.3748/wjg.v21.i39.11179; Wang TY, 2019, HELICOBACTER, V24, DOI 10.1111/hel.12569; Xie JH, 2023, J EXTRACELL VESICLES, V12, DOI 10.1002/jev2.12306; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zha J, 2022, HELICOBACTER, V27, DOI 10.1111/hel.12880	32	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1083-4389	1523-5378		HELICOBACTER	Helicobacter	MAY	2024	29	3							e13078	10.1111/hel.13078	http://dx.doi.org/10.1111/hel.13078			8	Gastroenterology & Hepatology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology; Microbiology	UG9J9	38867649				2024-07-03	WOS:001247019800001
J	Chari, S; Acharya, P; Gruen, DM; Zhang, OLV; Eyigoz, EK; Ghalwash, M; Seneviratne, O; Saiz, FS; Meyer, P; Chakraborty, P; McGuinness, DL				Chari, Shruthi; Acharya, Prasant; Gruen, Daniel M.; Zhang, Olivia; Eyigoz, Elif K.; Ghalwash, Mohamed; Seneviratne, Oshani; Saiz, Fernando Suarez; Meyer, Pablo; Chakraborty, Prithwish; McGuinness, Deborah L.			Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes	ARTIFICIAL INTELLIGENCE IN MEDICINE			English	Article						User-driven; Clinical explainability; Contextual explanations; Question-answering approach; Type-2 diabetes comorbidity risk prediction	ADVANCED TERMINOLOGY; PRACTICE GUIDELINES	Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by 'contextual explanations' that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients' clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) -a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians' usage of AI models.	[Chari, Shruthi; Acharya, Prasant; Gruen, Daniel M.; Seneviratne, Oshani; McGuinness, Deborah L.] Rensselaer Polytech Inst, 110 8th St, Troy, NY 12180 USA; [Zhang, Olivia; Eyigoz, Elif K.; Ghalwash, Mohamed; Meyer, Pablo; Chakraborty, Prithwish] IBM Res, Ctr Computat Hlth, 1101 Kitchawan Rd, Yorktown Hts, NY 10598 USA; [Saiz, Fernando Suarez] IBM Watson Hlth, 75 Binney St, Cambridge, MA 02142 USA	Rensselaer Polytechnic Institute; International Business Machines (IBM)	Chari, S (corresponding author), Rensselaer Polytech Inst, 110 8th St, Troy, NY 12180 USA.	charis@rpi.edu	Chari, Shruthi/JXL-9579-2024; Ghalwash, Mohamed Fakhry Eldin/F-8926-2014	Chari, Shruthi/0000-0003-2946-7870; Suarez Saiz, Fernando J/0000-0001-8176-5184				Agosti M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P973, DOI 10.1145/3331184.3331289; Amer Diabet Assoc, 2014, DIABETES CARE, V37, pS14, DOI 10.2337/dc14-S014; [Anonymous], 2021, CHRONIC KIDNEY DIS B; [Anonymous], 2021, About Chronic Diseases; Aronson AR, 2010, J AM MED INFORM ASSN, V17, P229, DOI 10.1136/jamia.2009.002733; Arya V, 2019, Arxiv, DOI arXiv:1909.03012; Banning M, 2008, J CLIN NURS, V17, P187, DOI 10.1111/j.1365-2702.2006.01791.x; Briganti G, 2020, FRONT MED-LAUSANNE, V7, DOI 10.3389/fmed.2020.00027; Chakraborty P, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3547, DOI 10.1145/3394486.3406470; Challener DW, 2019, JAMA-J AM MED ASSOC, V321, P2405, DOI 10.1001/jama.2019.5284; Chari Shruthi, 2020, The Semantic Web - ISWC 2020. 19th International Semantic Web Conference. Lecture Notes in Computer Science (LNCS 12507), P228, DOI 10.1007/978-3-030-62466-8_15; Chari S, 2020, STUD SEMANTIC WEB, V47, P245, DOI 10.3233/SSW200022; Chari S, 2020, STUD SEMANTIC WEB, V47, P23, DOI 10.3233/SSW200010; Chari S, 2019, LECT NOTES COMPUT SC, V11779, P53, DOI 10.1007/978-3-030-30796-7_4; Devlin J, 2018, ACL ANTHOL; Dey AK, 1998, KNOWL-BASED SYST, V11, P3, DOI 10.1016/S0950-7051(98)00053-7; Dey S, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100493; Dijksta E.W., 1959, NUMER MATH, V1, P269, DOI DOI 10.1007/BF01386390; Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Främling K, 2020, LECT NOTES ARTIF INT, V12175, P57, DOI 10.1007/978-3-030-51924-7_4; Gatta R, 2019, LECT NOTES BUS INF P, V362, P545, DOI 10.1007/978-3-030-37453-2_44; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Gilpin LH, 2018, PR INT CONF DATA SC, P80, DOI 10.1109/DSAA.2018.00018; Goldenberg A., 2019, What Clinicians Want: Contextualizing Explainable Machine Learning for Clinical End Use; Graham R, 2011, CLINICAL PRACTICE GUIDELINES WE CAN TRUST, P1; Gunning D., 2017, Defense advanced research projects agency (DARPA), nd Web, V2, P1, DOI DOI 10.1126/SCIROBOTICS.AAY7120; Gurumoorthy KS, 2019, IEEE DATA MINING, P260, DOI 10.1109/ICDM.2019.00036; Hagberg A. A., 2008, Proc. of the 7th Python in Science Conf. (SciPy2008), P11, DOI DOI 10.1016/J.JELECTROCARD.2010.09.003; Hematialam H, 2021, IDENTIFYING CONDITIO; HuggingFace, 2022, BIOCLINICALBERT ADR; Hussain M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083296; Knoll T, 2022, Arxiv, DOI arXiv:2205.02549; Lakkaraju H., 2022, arXiv; Lamy JB, 2015, STUD HEALTH TECHNOL, V210, P924, DOI 10.3233/978-1-61499-512-8-924; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liao QV, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376590; Lieberman H, 2000, IBM SYST J, V39, P617, DOI 10.1147/sj.393.0617; Lundberg SM, 2018, NAT BIOMED ENG, V2, P749, DOI 10.1038/s41551-018-0304-0; McKinney W., 2011, Python for high performance and scientific computing, V14, P1, DOI DOI 10.1002/MMCE.20381; Murad MH, 2017, MAYO CLIN PROC, V92, P423, DOI 10.1016/j.mayocp.2017.01.001; Natarajan K, 2010, INT J MED INFORM, V79, P515, DOI 10.1016/j.ijmedinf.2010.03.004; Otegi A, 2020, P 1 WORKSHOP NLP COV, DOI [10.18653/v1/2020.nlpcovid19-2.15,URL, DOI 10.18653/V1/2020.NLPCOVID19-2.15,URL]; Patel C, 2007, LECT NOTES COMPUT SC, V4825, P816; Pollard TJ, 2018, JAMIA OPEN, V1, P26, DOI 10.1093/jamiaopen/ooy012; Raghu Aniruddh, 2021, CHIL '21: Proceedings of the Conference on Health, Inference, and Learning, P95, DOI 10.1145/3450439.3451869; Riaño D, 2019, ARTIF INTELL MED, V100, DOI 10.1016/j.artmed.2019.101713; Richardson L., 2007, Beautiful soup documentation; Rieger Laura, 2020, INT C MACHINE LEARNI, P8116; Rosner AL, 2012, J BODYW MOV THER, V16, P42, DOI 10.1016/j.jbmt.2011.05.003; Rufibach K, 2010, J CLIN EPIDEMIOL, V63, P938, DOI 10.1016/j.jclinepi.2009.11.009; Sarrouti M, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101767; Schlegel Daniel R, 2019, AMIA Annu Symp Proc, V2019, P784; Seroussi B, 2018, STUD HEALTH TECHNOL, V255, P190, DOI 10.3233/978-1-61499-921-8-190; Shortliffe EH, 1974, MYCIN RULE BASTED CO; Sittig DF, 2008, J BIOMED INFORM, V41, P387, DOI 10.1016/j.jbi.2007.09.003; Suryanarayanan P, 2021, Arxiv, DOI arXiv:2106.13265; SWARTOUT W, 1991, IEEE EXPERT, V6, P58, DOI 10.1109/64.87686; Müller ST, 2021, Arxiv, DOI arXiv:2102.04972; Teufel S, 2007, TEXT SPEECH LANG TEC, V37, P163; Videha Sharma IA, 2021, BMJ HEALTH CARE INFO, V28; Wang DD, 2019, I C OPT COMMUN NETW, DOI [10.1109/icocn.2019.8934212, 10.1145/3290605.3300831]; Weber R, 2021, ARXIV; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Yao H, 2021, ADV NEURAL INF PROCE, V34; Yoon W, 2019, PKDDECML WORKSHOPS; Yu Chen, 2021, WSDM '21: Proceedings of the 14th ACM International Conference on Web Search and Data Mining, P544, DOI 10.1145/3437963.3441816; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang X, 2021, IEEE T NEUR NET LEAR	69	3	3	8	16	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0933-3657	1873-2860		ARTIF INTELL MED	Artif. Intell. Med.	MAR	2023	137								102498	10.1016/j.artmed.2023.102498	http://dx.doi.org/10.1016/j.artmed.2023.102498		FEB 2023	25	Computer Science, Artificial Intelligence; Engineering, Biomedical; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Medical Informatics	8Z3AV	36868690	Green Submitted			2024-07-03	WOS:000933256300001
J	Mukherjee, P; Gokul, RS; Sadhukhan, S; Godse, M; Chakraborty, B				Mukherjee, Prasenjit; Gokul, R. S.; Sadhukhan, Sourav; Godse, Manish; Chakraborty, Baisakhi			Detection of Autism Spectrum Disorder (ASD) from Natural Language Text using BERT and ChatGPT Models	INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS			English	Article						-BERT model; ChatGPT model; autism; machine learning; generative AI; autism detection		D may be caused by a combination of genetic and environmental factors, including gene mutations and exposure to toxins. People with ASD may also have trouble forming social relationships, have difficulty with communication and language, and struggle with sensory sensitivity. These difficulties can range from mild to severe and can affect a person's ability to interact with the world around them. Autism spectrum disorder (ASD) is a developmental disorder that affects people in different ways. But early detection of ASD in a child is a good option for parents to start corrective therapies and treatment. They can take action to reduce the ASD symptoms in their child. The proposed work is the detection of ASD in a child using a parent's dialog. The most popular Bert model and recent ChatGPT have been utilized to analyze the sentiment of each statement from parents for the detection of symptoms of ASD. The Bert model has been developed by the transformers which are the most popular in the natural language processing field whereas the ChatGPT model is a large language model (LLM). It is based on Reinforcement learning from human feedback (RLHF) that can able to generate the sentiment of the sentence, computer language codes, text paragraphs, etc. The sentiment analysis has been done on parents' dialog using the Bert model and ChatGPT model. The data has been prepared from various Autism groups on social sites and other resources on the internet. The data has been cleaned and prepared to train the Bert model and ChatGPT model. The Bert model is able to detect the sentiment of each sentence from parents. Any positive sentiment detection means parents should be aware of their children. The proposed model has given 83 percent accuracy according to the prepared data.	[Mukherjee, Prasenjit; Gokul, R. S.] Vodafone Intelligent Solut, Dept Technol, Pune, India; [Mukherjee, Prasenjit] Manipur Int Univ, Dept Comp Sci, Imphal, Manipur, India; [Sadhukhan, Sourav] Pune Inst Business Management, Dept Finance, Pune, India; [Godse, Manish] BizAm Software, Dept IT, Pune, India; [Chakraborty, Baisakhi] Natl Inst Technol, Dept Comp Sci & Engn, Durgapur, India	National Institute of Technology (NIT System); National Institute of Technology Durgapur	Mukherjee, P (corresponding author), Vodafone Intelligent Solut, Dept Technol, Pune, India.; Mukherjee, P (corresponding author), Manipur Int Univ, Dept Comp Sci, Imphal, Manipur, India.				Manipur International University, Imphal, India	Manipur International University, Imphal, India	The authors extend their appreciation to the Manipur International University, Imphal, India for supporting this Post-Doctoral (D.Sc.) research work on Autism.	Aarthi D., 2020, International Journal of Advanced Research in Engineering and Technology, V11, P235; Abdullah Azian Azamimi, 2019, INT C BIOM ENG, P1; Alteneiji MR, 2020, INT J ADV COMPUT SC, V11, P252; Amalraj Victoire T., 2021, Journal of Theoretical and Applied Information Technology, V99, P4759; American Psychiatric Association, 2013, AM PSYCHIAT ASS; Amrutha S M, 2021, International Research Journal of Engineering and Technology (IRJET), V8, P1252; Calvo RA, 2017, NAT LANG ENG, V23, P649, DOI 10.1017/S1351324916000383; Downs Johnny, 2017, AMIA Annu Symp Proc, V2017, P641; Fusaroli R, 2023, COGNITION, V236, DOI 10.1016/j.cognition.2023.105422; Gandhi R., 2018, towardsdatascience; Igorevna Firsanova Victoria, 2021, 27 INT C COMPUTATION, P1; Kamel Sherif, 2021, International Journal of Computer Science & Information Technology (IJCSIT), V13, P1; Kruthi C H, 2020, International Journal of Scientific Research & Engineering Trends, V7, P2267; Lord C, 2018, LANCET, V392, P508, DOI 10.1016/S0140-6736(18)31129-2; Mao ZY, 2019, INFORM SCIENCES, V499, P1, DOI 10.1016/j.ins.2019.05.043; Mohammed A., 2019, Proceedings of 2018 International Conference on Hydraulics and Pneumatics - HERVEX, P85; Moridian P, 2022, FRONT MOL NEUROSCI, V15, DOI 10.3389/fnmol.2022.999605; Tabtah F., 2017, 1 INT C MED HLTH INF, P1; Tabtah F., A mobile app for ASD screening; Tabtah F., 2017, Machine Learning in Autistic Spectrum Disorder Behavioral Research: A Review: To Appear in Informatics for Health and Social Care Journal; Vaswani A, 2017, ADV NEUR IN, V30; Wall DP, 2012, TRANSL PSYCHIAT, V2, DOI 10.1038/tp.2012.10; Ye Junjie, 2023, arXiv	23	0	0	10	10	SCIENCE & INFORMATION SAI ORGANIZATION LTD	WEST YORKSHIRE	19 BOLLING RD, BRADFORD, WEST YORKSHIRE, 00000, ENGLAND	2158-107X	2156-5570		INT J ADV COMPUT SC	Int. J. Adv. Comput. Sci. Appl.	OCT	2023	14	10					382	396						15	Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	CN6Y1					2024-07-03	WOS:001125979200001
J	Zack, T; Lehman, E; Suzgun, M; Rodriguez, JA; Celi, LA; Gichoya, J; Jurafsky, D; Szolovits, P; Bates, DW; Abdulnour, REE; Butte, AJ; Alsentzer, E				Zack, Travis; Lehman, Eric; Suzgun, Mirac; Rodriguez, Jorge A.; Celi, Leo Anthony; Gichoya, Judy; Jurafsky, Dan; Szolovits, Peter; Bates, David W.; Abdulnour, Raja-Elie E.; Butte, Atul J.; Alsentzer, Emily			Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study	LANCET DIGITAL HEALTH			English	Article						Public Health; Boston; MA		Background Large language models (LLMs) such as GPT-4 hold great promise as transformative tools in health care, ranging from automating administrative tasks to augmenting clinical decision making. However, these models also pose a danger of perpetuating biases and delivering incorrect medical diagnoses, which can have a direct, harmful impact on medical care. We aimed to assess whether GPT-4 encodes racial and gender biases that impact its use in health care. Methods Using the Azure OpenAI application interface, this model evaluation study tested whether GPT-4 encodes racial and gender biases and examined the impact of such biases on four potential applications of LLMs in the clinical domain-namely, medical education, diagnostic reasoning, clinical plan generation, and subjective patient assessment. We conducted experiments with prompts designed to resemble typical use of GPT-4 within clinical and medical education applications. We used clinical vignettes from NEJM Healer and from published research on implicit bias in health care. GPT-4 estimates of the demographic distribution of medical conditions were compared with true US prevalence estimates. Differential diagnosis and treatment planning were evaluated across demographic groups using standard statistical tests for significance between groups. Findings We found that GPT-4 did not appropriately model the demographic diversity of medical conditions, consistently producing clinical vignettes that stereotype demographic presentations. The differential diagnoses created by GPT-4 for standardised clinical vignettes were more likely to include diagnoses that stereotype certain races, ethnicities, and genders. Assessment and plans created by the model showed significant association between demographic attributes and recommendations for more expensive procedures as well as differences in patient perception. Interpretation Our findings highlight the urgent need for comprehensive and transparent bias assessments of LLM tools such as GPT-4 for intended use cases before they are integrated into clinical care. We discuss the potential sources of these biases and potential mitigation strategies before clinical implementation.	[Zack, Travis; Butte, Atul J.] Univ Calif San Francisco, Bakar Computat Hlth Sci Inst, San Francisco, CA USA; [Zack, Travis] Univ Calif San Francisco, Helen Diller Family Comprehens Canc Ctr, San Francisco, CA USA; [Lehman, Eric; Szolovits, Peter] Massachusetts Inst Technol MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA USA; [Celi, Leo Anthony] MIT, Lab Computat Physiol, Cambridge, MA USA; [Suzgun, Mirac; Jurafsky, Dan] Stanford Univ, Dept Comp Sci, Stanford, CA USA; [Suzgun, Mirac] Stanford Univ, Stanford Law Sch, Stanford, CA USA; [Jurafsky, Dan] Stanford Univ, Dept Linguist, Stanford, CA USA; [Rodriguez, Jorge A.; Bates, David W.; Alsentzer, Emily] Brigham & Womens Hosp, Div Gen Internal Med, Boston, MA USA; [Abdulnour, Raja-Elie E.] Brigham & Womens Hosp, Div Pulm & Crit Care Med, Boston, MA USA; [Celi, Leo Anthony] Beth Israel Deaconess Med Ctr, Div Pulm Crit Care & Sleep Med, Boston, MA USA; [Celi, Leo Anthony] Harvard T H Chan Sch Publ Hlth, Dept Biostat, Boston, MA USA; [Bates, David W.] Harvard T H Chan Sch Publ Hlth, Dept Hlth Policy & Management, Boston, MA USA; [Gichoya, Judy] Emory Univ, Dept Radiol, Atlanta, GA USA; [Abdulnour, Raja-Elie E.] Harvard Med Sch, Boston, MA USA; [Butte, Atul J.] Univ Calif Oakland, Ctr Data Driven Insights & Innovat, Oakland, CA USA; [Alsentzer, Emily] Brigham & Womens Hosp, Div Gen Internal Med, Boston, MA 02115 USA	University of California System; University of California San Francisco; University of California System; University of California San Francisco; UCSF Medical Center; UCSF Helen Diller Family Comprehensive Cancer Center; Massachusetts Institute of Technology (MIT); Stanford University; Stanford University; Stanford University; Harvard University; Brigham & Women's Hospital; Harvard University; Brigham & Women's Hospital; Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Harvard T.H. Chan School of Public Health; Emory University; Harvard University; Harvard Medical School; Harvard University; Brigham & Women's Hospital	Alsentzer, E (corresponding author), Brigham & Womens Hosp, Div Gen Internal Med, Boston, MA 02115 USA.	ealsentzer@bwh.harvard.edu			T32 NCI Hematology/Oncology training fellowship grant; Open Philanthropy; National Science Foundation;  [IIS-2128145]	T32 NCI Hematology/Oncology training fellowship grant(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Cancer Institute (NCI)); Open Philanthropy; National Science Foundation(National Science Foundation (NSF)); 	TZ is funded by a T32 NCI Hematology/Oncology training fellowship grant. MS and DJ gratefully acknowledge the support of Open Philanthropy and the National Science Foundation (via award IIS-2128145). Partial funding for this work is from a philanthropic gift from Priscilla Chan and Mark Zuckerberg.	Abdulnour REE, 2022, NEW ENGL J MED, V386, P1946, DOI 10.1056/NEJMe2204540; Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adam H, 2022, COMMUN MED-LONDON, V2, DOI 10.1038/s43856-022-00214-4; Alesina A, 2003, J ECON GROWTH, V8, P155, DOI 10.1023/A:1024471506938; [Anonymous], United States cancer statistics: Data visualizations; Armitage H, 2019, Stanford Medicine Magazine; Bartlett J, 2023, The Boston Globe; Baughman RP, 2016, ANN AM THORAC SOC, V13, P1244, DOI 10.1513/AnnalsATS.201511-760OC; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BENJAMINI Y, 1995, J R STAT SOC B, V57, P289, DOI 10.1111/j.2517-6161.1995.tb02031.x; Bhattaram S, 2023, AM J EMERG MED, V69, P215, DOI 10.1016/j.ajem.2023.03.027; Burton DC, 2010, AM J PUBLIC HEALTH, V100, P1904, DOI 10.2105/AJPH.2009.181313; Centers for Disease Control and Prevention, CDC COVID Data Tracker; Centers for Disease Control and Prevention, 2020, Tuberculosis cases and case rates per 100,000 population by race/ethnicity, United States; Centers for Disease Control and Prevention, Data briefs number 361; Centers for Disease Control and Prevention, 2021, Cases of STDs reported by disease and state; Centers for Disease Control and Prevention, Prostate cancer incidence by stage at diagnosis, United States-2001-2019; Centers for Disease Control and Prevention, NAT DIAB STAT REP; Centers for Disease Control and Prevention, 2019, HIV and other races; Dash D, 2023, Arxiv, DOI [arXiv:2304.13714, DOI 10.48550/ARXIV.2304.13714]; Daugherty SL, 2017, J AM HEART ASSOC, V6, DOI 10.1161/JAHA.117.006872; Fingar KathrynR., 2017, Delivery hospitalizations involving preeclampsia and eclampsia, 2005-2014: statistical brief# 222; Fisher RA, 1922, J R STAT SOC, V85, P87, DOI 10.2307/2340521; Fleming SL, 2023, medRxiv, DOI [10.1101/2023.04.25.23288588, 10.1101/2023.04.25.23288588, DOI 10.1101/2023.04.25.23288588]; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Haider AH, 2015, J AM COLL SURGEONS, V220, P1077, DOI 10.1016/j.jamcollsurg.2015.01.065; Haoran Zhang, 2020, CHIL '20: Proceedings of the Conference on Health, Inference, and Learning, P110, DOI 10.1145/3368555.3384448; Hittle M, 2023, JAMA NEUROL, V80, P693, DOI 10.1001/jamaneurol.2023.1135; Humphries KH, 2018, ACAD EMERG MED, V25, P413, DOI 10.1111/acem.13371; Izmirly PM, 2021, LUPUS SCI MED, V8, DOI 10.1136/lupus-2021-000614; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kapoor Sayash, AI Snake Oil; Kawatkar AA, 2019, RHEUMATOL INT, V39, P541, DOI 10.1007/s00296-018-04235-y; Khan MZ, 2020, AM J CARDIOL, V129, P125, DOI 10.1016/j.amjcard.2020.05.037; Kolata G., 2023, the New York times; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Liu GKM, 2023, Arxiv, DOI arXiv:2303.02891; Liu Y., 2023, arXiv, DOI DOI 10.48550/ARXIV.2305.10201; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Medenilla A., 2023, PLoS Digital Health, V2; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; OpenAI, 2023, CHATGPT; Shaikh O, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P4454; Siegel RL, 2023, CA-CANCER J CLIN, V73, P233, DOI 10.3322/caac.21772; Suzgun Mirac., 2023, FINDINGS ASS COMPUTA, P13003, DOI 10.18653/v1/2023.findings-acl.824; Taori R., Stanford alpaca: an instruction-following llama model; Turbes S, 2002, ACAD MED, V77, P209, DOI 10.1097/00001888-200203000-00007; Valentine JA, 2008, SEX TRANSM DIS, V35, pS23, DOI 10.1097/OLQ.0b013e31818d3cc7; Webson A., 2022, PROCEEDING 2022 C N, DOI [10.18653/v1/2022.naacl-main.167, DOI 10.18653/V1/2022.NAACL-MAIN.167]; Whelton Paul K, 2018, J Am Soc Hypertens, V12, DOI [10.1161/HYP.0000000000000065, 10.1016/j.jash.2018.06.010]; Yan YL, 2023, Arxiv, DOI arXiv:2301.01766; youtube, Khan Academy announces GPT-4 powered learning guide; Zack T, 2023, J GEN INTERN MED, V38, P5, DOI 10.1007/s11606-022-07758-0; Zaghlol R, 2020, ESC HEART FAIL, V7, P1056, DOI 10.1002/ehf2.12664	58	0	0	6	6	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2589-7500		LANCET DIGIT HEALTH	Lancet Digit. Health	JAN	2024	6	1												11	Medical Informatics; Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics; General & Internal Medicine	JK3G5					2024-07-03	WOS:001173016200001
J	Mondal, H; Dash, I; Mondal, S; Behera, JK				Mondal, Himel; Dash, Ipsita; Mondal, Shaikat; Behera, Joshil Kumar			ChatGPT in Answering Queries Related to Lifestyle-Related Diseases and Disorders	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						public health education; patient; internet; non-communicable disease; healthcare; language model; lifestyle; education; chatgpt; artificial intelligence	HEALTH INFORMATION	BackgroundLifestyle-related diseases and disorders have become a significant global health burden. However, the majority of the population ignores or do not consult doctors for such disease or disorders. Artificial intelligence (AI)-based large language model (LLM) like ChatGPT (GPT3.5) is capable of generating customized queries of a user. Hence, it can act as a virtual telehealth agent. Its capability to answer lifestyle-related diseases or disorders has not been explored.ObjectiveThis study aimed to evaluate the effectiveness of ChatGPT, an LLM, in providing answers to queries related to lifestyle-related diseases or disorders.MethodsA set of 20 lifestyle-related disease or disorder cases covering a wide range of topics such as obesity, diabetes, cardiovascular health, and mental health were prepared with four questions. The case and questions were presented to ChatGPT and asked for the answers to those questions. Two physicians rated the content on a three-point Likert-like scale ranging from accurate (2), partially accurate (1), and inaccurate (0). Further, the content was rated as adequate (2), inadequate (1), and misguiding (0) for testing the applicability of the guides for patients. The readability of the text was analyzed by the Flesch-Kincaid Ease Score (FKES). ResultsAmong 20 cases, the average score of accuracy was 1.83 +/- 0.37 and guidance was 1.9 +/- 0.21. Both the scores were higher than the hypothetical median of 1.5 (p=0.004 and p<0.0001, respectively). ChatGPT answered the questions with a natural tone in 11 cases and nine with a positive tone. The text was understandable for college graduates with a mean FKES of 27.8 +/- 5.74.ConclusionThe analysis of content accuracy revealed that ChatGPT provided reasonably accurate information in the majority of the cases, successfully addressing queries related to lifestyle-related diseases or disorders. Hence, initial guidance can be obtained by patients when they get little time to consult a doctor or wait for an appointment to consult a doctor for suggestions about their condition.	[Mondal, Himel] All India Inst Med Sci, Physiol, Deoghar, India; [Dash, Ipsita] Saheed Laxman Nayak Med Coll & Hosp, Biochem, Koraput, India; [Mondal, Shaikat] Raiganj Govt Med Coll & Hosp, Physiol, Raiganj, India; [Behera, Joshil Kumar] Nagaland Inst Med Sci & Res, Physiol, Kohima, India		Mondal, H (corresponding author), All India Inst Med Sci, Physiol, Deoghar, India.	himelmkcg@gmail.com						Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Denecke K, 2023, J BIOMED INFORM, V140, DOI 10.1016/j.jbi.2023.104336; Fallis D, 2002, J AM MED INFORM ASSN, V9, P73, DOI 10.1136/jamia.2002.0090073; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Islam SMS, 2014, GLOBALIZATION HEALTH, V10, DOI 10.1186/s12992-014-0081-9; Jindal P, 2017, EDUC HEALTH, V30, P84, DOI 10.4103/1357-6283.210517; Li H, 2023, CLIN IMAG, V101, P137, DOI 10.1016/j.clinimag.2023.06.008; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Ng R, 2020, INT J EPIDEMIOL, V49, P113, DOI 10.1093/ije/dyz078; Park J, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.17052; Sharma Mukesh, 2009, Indian J Occup Environ Med, V13, P109, DOI 10.4103/0019-5278.58912; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Taber JM, 2015, J GEN INTERN MED, V30, P290, DOI 10.1007/s11606-014-3089-1; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Zhavoronkov A, 2023, NAT MED, V29, P532, DOI 10.1038/d41591-023-00014-w	15	4	4	11	11	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	NOV 5	2023	15	11							e48296	10.7759/cureus.48296	http://dx.doi.org/10.7759/cureus.48296			7	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Z2VH3	38058315	Green Published, gold			2024-07-03	WOS:001110699100024
J	Oeding, JF; Yang, LJ; Sanchez-Sotelo, J; Camp, CL; Karlsson, J; Samuelsson, K; Pearle, AD; Ranawat, AS; Kelly, BT; Pareek, A				Oeding, Jacob F.; Yang, Linjun; Sanchez-Sotelo, Joaquin; Camp, Christopher L.; Karlsson, Jon; Samuelsson, Kristian; Pearle, Andrew D.; Ranawat, Anil S.; Kelly, Bryan T.; Pareek, Ayoosh			A practical guide to the development and deployment of deep learning models for the orthopaedic surgeon: Part III, focus on registry creation, diagnosis, and data privacy	KNEE SURGERY SPORTS TRAUMATOLOGY ARTHROSCOPY			English	Review; Early Access						artificial intelligence; data privacy; deep learning; diagnosis; orthopaedic surgery; registry creation	ARTHROPLASTY; REOPERATION; DISLOCATION; RISK	Deep learning is a subset of artificial intelligence (AI) with enormous potential to transform orthopaedic surgery. As has already become evident with the deployment of Large Language Models (LLMs) like ChatGPT (OpenAI Inc.), deep learning can rapidly enter clinical and surgical practices. As such, it is imperative that orthopaedic surgeons acquire a deeper understanding of the technical terminology, capabilities and limitations associated with deep learning models. The focus of this series thus far has been providing surgeons with an overview of the steps needed to implement a deep learning-based pipeline, emphasizing some of the important technical details for surgeons to understand as they encounter, evaluate or lead deep learning projects. However, this series would be remiss without providing practical examples of how deep learning models have begun to be deployed and highlighting the areas where the authors feel deep learning may have the most profound potential. While computer vision applications of deep learning were the focus of Parts I and II, due to the enormous impact that natural language processing (NLP) has had in recent months, NLP-based deep learning models are also discussed in this final part of the series. In this review, three applications that the authors believe can be impacted the most by deep learning but with which many surgeons may not be familiar are discussed: (1) registry construction, (2) diagnostic AI and (3) data privacy. Deep learning-based registry construction will be essential for the development of more impactful clinical applications, with diagnostic AI being one of those applications likely to augment clinical decision-making in the near future. As the applications of deep learning continue to grow, the protection of patient information will become increasingly essential; as such, applications of deep learning to enhance data privacy are likely to become more important than ever before.Level of Evidence: Level IV.	[Oeding, Jacob F.] Mayo Clin, Sch Med, Alix Sch Med, Rochester, MN USA; [Oeding, Jacob F.] Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Orthopaed, Gothenburg, Sweden; [Yang, Linjun] Mayo Clin, Dept Orthoped Surg, Orthoped Surg Artificial Intelligence Lab OSAIL, Rochester, MN USA; [Sanchez-Sotelo, Joaquin; Camp, Christopher L.] Mayo Clin, Dept Orthoped Surg, Rochester, MN USA; [Karlsson, Jon; Samuelsson, Kristian] Gothenburg Univ, Sahlgrenska Univ Hosp, Sahlgrenska Acad, Dept Orthopaed, Gothenburg, Sweden; [Pearle, Andrew D.; Ranawat, Anil S.; Kelly, Bryan T.; Pareek, Ayoosh] Hosp Special Surg, Sports Med & Shoulder Serv, New York, NY USA; [Oeding, Jacob F.] 226 2nd St SW, Rochester, MN 55905 USA	Mayo Clinic; University of Gothenburg; Mayo Clinic; Mayo Clinic; University of Gothenburg; Sahlgrenska University Hospital	Oeding, JF (corresponding author), 226 2nd St SW, Rochester, MN 55905 USA.	jacoboeding@gmail.com	Sanchez-Sotelo, Joaquin/AAJ-1248-2021	Oeding, Jacob/0000-0002-4562-4373				Alessandri-Bonetti M, 2024, ANN BIOMED ENG, V52, P1107, DOI 10.1007/s10439-023-03325-8; Bhatt DL, 2015, J AM COLL CARDIOL, V66, P2230, DOI 10.1016/j.jacc.2015.07.010; Biedermann R, 2005, J BONE JOINT SURG BR, V87B, P762, DOI 10.1302/0301-620X.87B6; Chambon PJ, 2023, J AM MED INFORM ASSN, V30, P318, DOI 10.1093/jamia/ocac219; Dipnall JF, 2022, EUR J RADIOL, V153, DOI 10.1016/j.ejrad.2022.110366; Fayed AM, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00642-8; Gordon C., Forbes; Ahn G, 2023, J ORTHOP RES, V41, P84, DOI 10.1002/jor.25325; Hachamovitch R, 2017, JACC-CARDIOVASC IMAG, V10, P276, DOI 10.1016/j.jcmg.2017.01.003; Hamad MN, 2022, J EXP ORTHOP, V9, DOI 10.1186/s40634-022-00506-7; Hinterwimmer F, 2023, KNEE SURG SPORT TR A, V31, P1323, DOI 10.1007/s00167-022-06957-w; Jeong HW, 2023, KNEE SURG SPORT TR A, V31, P3070, DOI 10.1007/s00167-022-07137-6; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Karhade AV, 2020, SPINE J, V20, P1602, DOI 10.1016/j.spinee.2020.02.021; Karhade AV, 2020, SPINE J, V20, P695, DOI 10.1016/j.spinee.2019.12.006; Karhade AV, 2021, SPINE J, V21, P1635, DOI 10.1016/j.spinee.2020.04.001; Khosravi B, 2023, RADIOL-ARTIF INTELL, V5, DOI 10.1148/ryai.230085; Khosravi B, 2023, J ARTHROPLASTY, V38, DOI 10.1016/j.arth.2022.12.013; Khosravi B, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220067; Kita K, 2023, J ORTHOP SCI, V28, P1392, DOI 10.1016/j.jos.2022.09.003; Kunze KN, 2023, J SHOULDER ELB SURG, V32, P2115, DOI 10.1016/j.jse.2023.03.028; Malchau H, 2018, J ORTHOP RES, V36, P2319, DOI 10.1002/jor.24014; Oeding JF, 2024, ARTHROSCOPY, V40, P1044, DOI 10.1016/j.arthro.2023.08.084; Oeding JF, 2023, J SHOULDER ELB SURG, V32, pE437, DOI 10.1016/j.jse.2023.03.001; Oeding JF, 2023, KNEE SURG SPORT TR A, V31, P1635, DOI 10.1007/s00167-023-07338-7; Oeding JF, 2023, KNEE SURG SPORT TR A, V31, P382, DOI 10.1007/s00167-022-07239-1; Rouzrokh Pouria, 2024, J Arthroplasty, V39, P966, DOI 10.1016/j.arth.2023.09.025; Rouzrokh P, 2022, J BONE JOINT SURG AM, V104, P1649, DOI 10.2106/JBJS.21.01229; Rouzrokh P, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210206; Rouzrokh P, 2021, J ARTHROPLASTY, V36, P2510, DOI 10.1016/j.arth.2021.02.026; Rouzrokh PHP, 2024, J ARTHROPLASTY, V39, DOI 10.1016/j.arth.2023.08.063; Sagheb E, 2021, J ARTHROPLASTY, V36, P922, DOI 10.1016/j.arth.2020.09.029; Smolle MA, 2023, KNEE SURG SPORT TR A, V31, P1053, DOI 10.1007/s00167-022-07220-y; Stotter C, 2023, KNEE SURG SPORT TR A, DOI 10.1007/s00167-023-07644-0; Sun JM, 2017, J CHEM INF MODEL, V57, P1591, DOI 10.1021/acs.jcim.7b00159; Thomas KA, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2020190065; Van Eetvelde H, 2021, J EXP ORTHOP, V8, DOI 10.1186/s40634-021-00346-x; Wolterink JM, 2021, RADIOGRAPHICS, V41, P840, DOI 10.1148/rg.2021200151; Wyles CC, 2019, J BONE JOINT SURG AM, V101, P1931, DOI 10.2106/JBJS.19.00071; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Yang LJ, 2024, J SHOULDER ELB SURG, V33, P773, DOI 10.1016/j.jse.2023.09.021; Zech JR, 2023, PEDIATR RADIOL, V53, P2386, DOI 10.1007/s00247-023-05754-y	42	0	0	3	3	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0942-2056	1433-7347		KNEE SURG SPORT TR A	Knee Surg. Sports Traumatol. Arthrosc.	2024 MAR 1	2024										10.1002/ksa.12085	http://dx.doi.org/10.1002/ksa.12085		MAR 2024	11	Orthopedics; Sport Sciences; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Sport Sciences; Surgery	KD7I8	38426614				2024-07-03	WOS:001178082700001
J	Wu, LH; Gray, M; Dang, O; Xu, JS; Fang, H; Tong, WD				Wu, Leihong; Gray, Magnus; Dang, Oanh; Xu, Joshua; Fang, Hong; Tong, Weida			RxBERT: Enhancing drug labeling text mining and analysis with AI language modeling	EXPERIMENTAL BIOLOGY AND MEDICINE			English	Article						Artificial intelligence; natural language processing; language model; BERT; drug labeling; pharmacovigilance		The US drug labeling document contains essential information on drug efficacy and safety, making it a crucial regulatory resource for Food and Drug Administration (FDA) drug reviewers. Due to its extensive volume and the presence of free-text, conventional text mining analysis have encountered challenges in processing these data. Recent advances in artificial intelligence (AI) for natural language processing (NLP) have provided an unprecedented opportunity to identify key information from drug labeling, thereby enhancing safety reviews and support for regulatory decisions. We developed RxBERT, a Bidirectional Encoder Representations from Transformers (BERT) model pretrained on FDA human prescription drug labeling documents for an enhanced application of drug labeling documents in both research and drug review. RxBERT was derived from BioBERT with further training on human prescription drug labeling documents. RxBERT was demonstrated in several tasks using regulatory datasets, including those involved in the National Institutes of Technology Text Analysis Challenge Dataset (NIST TAC dataset), the FDA Adverse Drug Event Evaluation Dataset (ADE Eval dataset), and the classification of texts from submission packages into labeling sections (US Drug Labeling dataset). For all these tasks, RxBERT reached 86.5 F1-scores in both TAC and ADE Eval classification, respectively, and prediction accuracy of 87% for the US Drug Labeling dataset. Overall, RxBERT was shown to be as competitive or have better performance compared to other NLP approaches such as BERT, BioBERT, etc. In summary, we developed RxBERT, a transformer-based model specific for drug labeling that outperformed the original BERT model. RxBERT has the potential to be used to assist research scientists and FDA reviewers to better process and utilize drug labeling information toward the advancement of drug effectiveness and safety for public health. This proof-of-concept study also demonstrated a potential pathway to customized large language models (LLMs) tailored to the sensitive regulatory documents for internal application.	[Wu, Leihong; Gray, Magnus; Xu, Joshua; Tong, Weida] FDA, Div Bioinformat & Biostat, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA; [Dang, Oanh] FDA, Off Surveillance & Epidemiol, Ctr Drug Evaluat & Res, Silver Spring, MD 20993 USA; [Fang, Hong] FDA, Off Sci Coordinat, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA	US Food & Drug Administration (FDA); US Food & Drug Administration (FDA); US Food & Drug Administration (FDA)	Wu, LH (corresponding author), FDA, Div Bioinformat & Biostat, Natl Ctr Toxicol Res, Jefferson, AR 72079 USA.	Leihong.wu@fda.hhs.gov		Xu, Joshua/0000-0001-5313-5847; Gray, Magnus/0009-0009-6355-7627; Wu, Leihong/0000-0002-4093-3708	Oak Ridge Institute for Science and Education; Research Participation Program at the National Center for Toxicological Research, US Food and Drug Administration	Oak Ridge Institute for Science and Education; Research Participation Program at the National Center for Toxicological Research, US Food and Drug Administration	MG thanks the Oak Ridge Institute for Science and Education for their support to the Research Participation Program at the National Center for Toxicological Research, US Food and Drug Administration.	Bayer S, 2021, DRUG SAFETY, V44, DOI 10.1007/s40264-020-00996-3; Beltagy Iz, arXiv; Brown T., 2020, ADV NEUR INFORM PROC, V33; Chalkidis I., ARXIV; Chen MJ, 2011, DRUG DISCOV TODAY, V16, P697, DOI 10.1016/j.drudis.2011.05.007; Chowdhery A., ARXIV; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Devlin J., ARXIV; Fang H, 2020, NAT BIOTECHNOL, V38, P1378, DOI 10.1038/s41587-020-00751-0; Fang H, 2016, DRUG DISCOV TODAY, V21, P1566, DOI 10.1016/j.drudis.2016.06.006; federalregister, MAINT AM LEAD ART IN; federalregister, PROM US TRUSTW ART I; Gray M, 2023, CHEM RES TOXICOL, V36, P1290, DOI 10.1021/acs.chemrestox.3c00028; Huang K, ARXIV; Lee J., 2020, BIOINFORMATICS, V36, p1234; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mikolov T, ARXIV; Muller M., COVID TWITTER BERT N, DOI [10.3389/frai.2023.1023281/full, DOI 10.3389/FRAI.2023.1023281/FULL]; Roberts K., OVERVIEW TAC 2017 AD; Sarzynska-Wawer J, 2021, PSYCHIAT RES, V304, DOI 10.1016/j.psychres.2021.114135; Sonntagbauer M, 2023, MED KLIN-INTENSIVMED, V118, P366, DOI 10.1007/s00063-023-01019-6; Sun TX, 2022, MACH INTELL RES, V19, P169, DOI 10.1007/s11633-022-1331-6; Thakkar S, 2023, REGUL TOXICOL PHARM, V140, DOI 10.1016/j.yrtph.2023.105388; U.S. Food and Drug Administration, About us; ValizadehAslani T, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad226; Vaswani A, 2017, ADV NEUR IN, V30; Vought R.T., Guidance for regulation of artificial intelligence applications; Wu LH, 2023, REGUL TOXICOL PHARM, V137, DOI 10.1016/j.yrtph.2022.105287; Wu LH, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2628-5; Wu Y, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.729834; Zhang S., ARXIV; Zhou M, 2020, ENGINEERING-PRC, V6, P275, DOI 10.1016/j.eng.2019.12.014	32	2	2	7	7	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1535-3702	1535-3699		EXP BIOL MED	Exp. Biol. Med.	NOV	2023	248	21					1937	1943		10.1177/15353702231220669	http://dx.doi.org/10.1177/15353702231220669		JAN 2024	7	Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Research & Experimental Medicine	FJ4D8	38166420				2024-07-03	WOS:001136440100001
J	Eberhard, L; Popova, K; Walk, S; Helic, D				Eberhard, Lukas; Popova, Kristina; Walk, Simon; Helic, Denis			Computing recommendations from free-form text	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Deep learning; Keyword extraction; Named entity recognition; Narrative-driven recommendations; Aspect-based sentiment analysis	SYSTEMS	While searching for consumer goods, users frequently ask for suggestions from their peers by writing short free-form textual requests. For example, when searching for movies users may ask for "Drama movies with a mind-bending story and a surprise ending, such as Fight Club"in one of the many online discussion boards. Despite the recent developments in large language models (LLMs) and natural language processing (NLP), modern recommender systems still struggle to process such requests. Therefore, in this paper we evaluate several approaches for annotating structured information from such short, free-form natural language user texts to calculate recommendations. We set up this evaluation as a two phase processes including (a) identification of the best NLP approach to identify key elements of users' requests, and (b) assessment of the quality of recommendations computed with such elements.For our evaluation, we use a gold-standard reddit movie recommendation dataset consisting of annotations, manually created by crowdworkers who extracted keywords, actor names and movie titles. Using this dataset we evaluate a collection of more than 30 NLP and five recommender approaches. In addition, we perform an ablation study to assess relative annotation importance for movie recommendations. We find that domainspecific deep learning models, trained on a subset of data as well as embedding-based recommendation approaches are able to match the recommendation performance of recommendations computed from manual annotations. These promising results warrant further investigation in automatic processing of short free-form texts for computation of recommendations. Specifically, we provide insights into which NLP models and configurations work best for automatically annotating free text to compute (movie) recommendations, hence substantially reducing the search space for combinations of NLP and recommendation algorithms in the movie and potentially other domains.	[Eberhard, Lukas; Popova, Kristina] Graz Univ Technol, Graz, Austria; [Walk, Simon] Avery Dennison Atma Io, Graz, Austria; [Helic, Denis] Modul Univ Vienna, Vienna, Austria	Graz University of Technology	Eberhard, L (corresponding author), Graz Univ Technol, Graz, Austria.	lukas.eberhard@tugraz.at; kristina.popova@alumni.tugraz.at; simon.walk@eu.averydennison.com; denis.helic@modul.ac.at		Helic, Denis/0000-0003-0725-7450				Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714; Adomavicius G, 2005, IEEE T KNOWL DATA EN, V17, P734, DOI 10.1109/TKDE.2005.99; [Anonymous], 2001, HCI New Millennium; [Anonymous], 2008, P 14 ACM SIGKDD INT; APPELT DE, 1993, IJCAI-93, VOLS 1 AND 2, P1172; Ashwini S., 2014, arXiv, DOI 10.48550/arXiv.1408.0782; Ballesteros M., 2016, P NAACL HLT, P260, DOI [DOI 10.18653/V1/N16-1030, 10.18653/v1/N16-1030]; Barkan O., 2016, P IEEE 26 INT WORKSH, P1; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Bhattacharjee K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7927; Bogers T, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P238, DOI 10.1145/3109859.3109893; Brown P. F., 1992, Computational Linguistics, V18, P467; Cai H., 2020, P 28 INT C COMP LING, P833, DOI [10.18653/v1/2020.coling-main.72, DOI 10.18653/V1/2020.COLING-MAIN.72]; Cenikj G, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P385, DOI 10.1145/3366424.3383300; Chen SG, 2021, Arxiv, DOI [arXiv:2109.01758, 10.48550/arXiv.2109.01758,arXiv.]; Chieu H. L., 2003, P 7 C NATURAL LANGUA, P160; Chiu J.P., 2016, Transactions of the Association for Computational Linguistics, V4, P357, DOI [10.1162/tacl_a_00104, 10.1162/tacla00104]; Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746; Christakou C, 2007, INT J ARTIF INTELL T, V16, P771, DOI 10.1142/S0218213007003540; Cimiano P., 2004, WWW, P462; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Cui Z., 2022, arXiv; Desrosiers C, 2011, RECOMMENDER SYSTEMS HANDBOOK, P107, DOI 10.1007/978-0-387-85820-3_4; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Eberhard Lukas, 2020, HT '20: Proceedings of the 31st ACM Conference on Hypertext and Social Media, P301, DOI 10.1145/3372923.3404818; Eberhard L, 2019, PROCEEDINGS OF IUI 2019, P1, DOI 10.1145/3301275.3302287; Elsafty A., 2018, P 2018 C N AM CHAPTE, V3, P216; Feng SS, 2017, AAAI CONF ARTIF INTE, P102; Fessahaye F, 2019, I SYMP CONSUM ELECTR, DOI 10.1109/icce.2019.8662028; Fu L, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5589285; Funk S., 2006, Netflix update: Try this at home; Ghosh S., 1999, Proceedings of the Third International Conference on Autonomous Agents, P434, DOI 10.1145/301136.301303; Glenski Maria, 2017, 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), P609, DOI 10.1145/3110025.3120993; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Ozsoy MG, 2016, Arxiv, DOI arXiv:1601.01356; Gundogdu A. S., 2018, Computing Research Repository, DOI [10.48550/arXiv.1809.08711, DOI 10.48550/ARXIV.1809.08711]; Hamilton WL, 2017, ADV NEUR IN, V30; Hariri N., 2013, P 7 ACM C REC SYST, P9, DOI DOI 10.1145/2507157.2507187; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu MH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P537; Huang J, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P190, DOI 10.1145/3383313.3412252; Janchevski A, 2019, COMM COM INF SC, V1110, P96, DOI 10.1007/978-3-030-33110-8_9; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kouki P, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P140, DOI 10.1145/3383313.3412235; Lamprecht D., 2015, P 15 INT C KNOWL TEC, DOI [https://doi.org/10.1145/2809563.2809603, DOI 10.1145/2809563.2809603]; Langevin R, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445312; Levy O., 2015, T ASSOC COMPUT LING, V3, P211, DOI DOI 10.1162/TACL_A_00134; Li C., 2021, arXiv; Li HZ, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P13, DOI 10.1145/3383313.3412240; Li X, 2019, ARXIV PREPRINT ARXIV, P34, DOI [DOI 10.18653/V1/D19-5505, 10.18653/v1/D19-5505]; Liang DW, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P59, DOI 10.1145/2959100.2959182; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Liu S, 2020, Arxiv, DOI arXiv:2004.06427; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ludewig M, 2018, USER MODEL USER-ADAP, V28, P331, DOI 10.1007/s11257-018-9209-6; Mak H, 2003, IEEE/WIC INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P602; Mansouri A, 2008, INT J COMPUT SCI NET, V8, P339; Mihalcea R., 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Min B., 2021, arXiv; Mnih A., 2008, Advances in neural information processing systems, V21; Montazeralghaem A, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P220, DOI 10.1145/3460231.3474271; Musto C., 2022, Expert Systems with Applications, DOI [10.2139/ssrn.4140047, DOI 10.2139/SSRN.4140047]; Musto Cataldo., 2015, RecSys Posters, V1441; Oku K., 2006, 7th International Conference on Mobile Data Management (MDM'06), P109, DOI DOI 10.1109/MDM.2006.56; Okura S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1933, DOI 10.1145/3097983.3098108; Panchendrarajan Rrubaa, 2018, PROC 32 PACIFIC ASIA; Penha G, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P388, DOI 10.1145/3383313.3412249; Pereira JA, 2018, COMPUT LANG SYST STR, V54, P451, DOI 10.1016/j.cl.2018.01.003; Moreira GDP, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P143, DOI 10.1145/3460231.3474255; Perny P., 2001, Information, Interaction, Intelligence, V1, P9; Polignano M, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P187, DOI 10.1145/3460231.3474272; Pradel B., 2012, P 6 ACM C RECOMMENDE, P147; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Ramshaw L.A., 1999, TEXT SPEECH LANG TEC, P157; RATCLIFF JW, 1988, DR DOBBS J, V13, P46; Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905; Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1; Ritter A., 2011, P 2011 C EMP METH NA, P1524; Rose S., 2010, TEXT MINING APPL THE, P1, DOI DOI 10.1002/9780470689646.CH1; Sabir A, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517510; Salton G., 1983, INTRO MODERN INFORM, P1; Schedl M, 2018, INT J MULTIMED INF R, V7, P95, DOI 10.1007/s13735-018-0154-2; Setlur V, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501972; Smith B, 2017, IEEE INTERNET COMPUT, V21, P12, DOI 10.1109/MIC.2017.72; Stanescu A, 2013, 2013 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P73, DOI 10.1109/WI-IAT.2013.11; Stiebellehner S, 2017, Arxiv, DOI [arXiv:1801.00215, 10.48550/arXiv.1801.00215, 10.48550/ARXIV.1801.00215, DOI 10.48550/ARXIV.1801.00215]; Sutiono A. P., 2022, Computing Research Repository, DOI [10.48550/arXiv.2208.06957, DOI 10.48550/ARXIV.2208.06957]; Szomszor M., 2007, P 4 EUR SEM WEB C IN, P71; Tao J, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010024; Trusca MM, 2020, LECT NOTES COMPUT SC, V12128, P365, DOI 10.1007/978-3-030-50578-3_25; Vazan M, 2021, Arxiv, DOI arXiv:2109.07680; Villegas NM, 2018, KNOWL-BASED SYST, V140, P173, DOI 10.1016/j.knosys.2017.11.003; Wang HW, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P968, DOI 10.1145/3292500.3330836; Wang SJ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3465401; Wölbitsch M, 2019, ACM UMAP '19: PROCEEDINGS OF THE 27TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, P104, DOI 10.1145/3320435.3320454; Wu YX, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P241, DOI 10.1145/3460231.3474256; Zeng ZH, 2019, LECT NOTES COMPUT SC, V11772, P108, DOI 10.1007/978-3-030-31624-2_9; Zhang Y., 2021, NEURIPS 2021 WORKSH; Zitouni I, 2014, Natural language processing of semitic languages, DOI [10.1007/978-3-642-45358-8, DOI 10.1007/978-3-642-45358-8_2, 10.3923/rjphyto.2014.139.147, DOI 10.1007/978-3-642-45358-8]	104	0	0	6	20	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	FEB	2024	236								121268	10.1016/j.eswa.2023.121268	http://dx.doi.org/10.1016/j.eswa.2023.121268		SEP 2023	21	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	S6XE0		hybrid			2024-07-03	WOS:001072568400001
J	Lower, K; Seth, I; Lim, B; Seth, N				Lower, Kirk; Seth, Ishith; Lim, Bryan; Seth, Nimish			ChatGPT-4: Transforming Medical Education and Addressing Clinical Exposure Challenges in the Post-pandemic Era	INDIAN JOURNAL OF ORTHOPAEDICS			English	Article						Chat-GPT; Orthopaedic Surgery; Artificial Intelligence		BackgroundThe COVID-19 pandemic has affected medical education, constraining clinical exposure and posing unprecedented challenges for students and junior doctors. This research explores the potential of artificial intelligence (AI), specifically the ChatGPT-4 language model, to transform medical education and address the deficiencies in clinical exposure during the post-pandemic era.Research Questions/PurposeWhat is the potential of AI large language models in delivering safe and coherent medical advice to junior doctors for clinical orthopaedic scenarios?Patients and MethodsA series of diverse orthopaedic questions was presented to ChatGPT-4, from general medicine to highly specialised fields. The questions were based on a variety of common orthopaedic presentations including neck of femur fracture, compartment syndrome, pulmonary embolism, and a motor vehicle accident. A validated questionnaire (Likert Scale) was implemented to evaluate the answers produced by ChatGPT-4.ResultsOur results indicate that ChatGPT-4 exhibits exceptional proficiency in delivering accurate and coherent medical advice. Its intuitive interface, accessibility, and sophisticated algorithm render it an ideal supplementary tool for medical students and junior doctors. Despite certain limitations, such as its inability to fully address highly specialised areas, this study highlights the potential of AI and ChatGPT-4 to revolutionise medical education and fill the clinical exposure void generated by the pandemic. Future research should concentrate on the practical application of ChatGPT-4 in real-world medical environments and its integration with other emerging technologies to optimise its influence on the education and training of healthcare professionals.ConclusionsChatGPT-4's integration into orthopaedic education and practice can mitigate pandemic-related experience gaps, promoting self-directed, personalised learning and decision-making support for interns and residents. Future advancements may address limitations to enhance healthcare professionals' learning and expertise.	[Lower, Kirk] St George Hosp, Dept Orthopaed, Gray St, Sydney, NSW 2000, Australia; [Seth, Ishith; Lim, Bryan] Monash Univ, Fac Sci Med & Hlth, Alfred Ctr, Cent Clin Sch, 99 Commercial Rd, Melbourne, Vic 3004, Australia; [Seth, Ishith; Lim, Bryan; Seth, Nimish] Peninsula Hlth, Dept Orthopaed Surg, Melbourne, Vic 3004, Australia	St George Hospital; Monash University; Peninsula Health	Lower, K (corresponding author), St George Hosp, Dept Orthopaed, Gray St, Sydney, NSW 2000, Australia.	kirk96lower@gmail.com; ishithseth1@gmail.com; lim.bryan58@gmail.com; sethnimish@hotmail.com	Seth, Ishith/IXX-0725-2023	Seth, Ishith/0000-0001-5444-8925				Anders BA., 2023, C2C DIGITAL MAGAZINE, V1, P4; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Blease C, 2019, J MED INTERNET RES, V21, DOI 10.2196/12802; Char DS, 2018, NEW ENGL J MED, V378, P981, DOI 10.1056/NEJMp1714229; Chen Y, 2023, INFORM SYST FRONT, V25, P161, DOI 10.1007/s10796-022-10291-4; Dimitriu MCT, 2020, MED HYPOTHESES, V144, DOI 10.1016/j.mehy.2020.109972; Gao C. A., 2022, bioRxiv; Gilson A., 2022, MEDRXIV; Jeblick K, 2022, PREPRINT; Kannampallil TG, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237301; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Price WN, 2019, NAT MED, V25, P37, DOI 10.1038/s41591-018-0272-7; Seifman MA, 2022, POSTGRAD MED J, V98, P466, DOI 10.1136/postgradmedj-2020-139575; Seth I, 2023, J Orthop Sports Med., V5, P112, DOI [10.26502/josm.511500088, DOI 10.26502/JOSM.511500088]; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7	17	10	10	21	41	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0019-5413	1998-3727		INDIAN J ORTHOP	Indian J. Orthop.	SEP	2023	57	9					1527	1544		10.1007/s43465-023-00967-7	http://dx.doi.org/10.1007/s43465-023-00967-7		AUG 2023	18	Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics	P5QR7	37609022				2024-07-03	WOS:001045629000002
J	Kiriakedis, S; Duty, B; Chase, T; Wusirika, R; Metzler, I				Kiriakedis, Satomi; Duty, Brian; Chase, Tyler; Wusirika, Raghav; Metzler, Ian			Using ChatGPT-4 to Analyze 24-Hour Urine Results and Generate Custom Dietary Recommendations for Nephrolithiasis	JOURNAL OF ENDOUROLOGY			English	Article; Early Access						artificial intelligence; urology; nephrolithiasis; diagnostic techniques and procedures; diet therapy	PRACTICE PATTERNS; UROLOGISTS	Purpose: The increasing incidence of nephrolithiasis underscores the need for effective, accessible tools to aid urologists in preventing recurrence. Despite dietary modification's crucial role in prevention, targeted dietary counseling using 24-hour urine collections is underutilized. This study evaluates ChatGPT-4, a multimodal large language model, in analyzing urine collection results and providing custom dietary advice, exploring the potential for artificial intelligence-assisted analysis and counseling.Materials and Methods: Eleven unique prompts with synthesized 24-hour urine collection results were submitted to ChatGPT-4. The model was instructed to provide five dietary recommendations in response to the results. One prompt contained all "normal" values, with subsequent prompts introducing one abnormality each. Generated responses were assessed for accuracy, completeness, and appropriateness by two urologists, a nephrologist, and a clinical dietitian.Results: ChatGPT-4 achieved average scores of 5.2/6 for accuracy, 2.4/3 for completeness, and 2.6/3 for appropriateness. It correctly identified all "normal" values but had difficulty consistently detecting abnormalities and formulating appropriate recommendations. The model performed particularly poorly in response to calcium and citrate abnormalities and failed to address 3/10 abnormalities entirely.Conclusions: ChatGPT-4 exhibits potential in the dietary management of nephrolithiasis but requires further refinement for dependable performance. The model demonstrated the ability to generate personalized recommendations that were often accurate and complete but displayed inconsistencies in identifying and addressing urine abnormalities. Despite these limitations, with precise prompt design, physician oversight, and continued training, ChatGPT-4 can serve as a foundation for personalized medicine while also reducing administrative burden, indicating its promising role in improving the management of conditions such as nephrolithiasis.	[Kiriakedis, Satomi; Duty, Brian; Chase, Tyler; Wusirika, Raghav; Metzler, Ian] Oregon Hlth & Sci Univ, Portland, OR USA; [Metzler, Ian] Oregon Hlth & Sci Univ, Dept Urol, 3303 S Bond, Portland, OR 97239 USA	Oregon Health & Science University; Oregon Health & Science University	Metzler, I (corresponding author), Oregon Hlth & Sci Univ, Dept Urol, 3303 S Bond, Portland, OR 97239 USA.	metzleri@ohsu.edu						[Anonymous], 2023, Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service; Huynh LM, 2023, UROL PRACT, V10, P408, DOI 10.1097/UPJ.0000000000000406; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; McGuire BB, 2016, J ENDOUROL, V30, P460, DOI 10.1089/end.2015.0207; Milose JC, 2014, J UROLOGY, V191, P376, DOI 10.1016/j.juro.2013.08.080; OpenAI, 2023, Gpt-4 technical report, P1, DOI DOI 10.48550/ARXIV.2303.08774; Pearle MS, 2014, J UROLOGY, V192, P316, DOI 10.1016/j.juro.2014.05.006; Pfau AKF., 2023, National Kidney Foundation Primer on Kidney Diseases, P688; Wertheim ML, 2014, J ENDOUROL, V28, P1127, DOI 10.1089/end.2014.0164	9	1	1	1	1	MARY ANN LIEBERT, INC	NEW ROCHELLE	140 HUGUENOT STREET, 3RD FL, NEW ROCHELLE, NY 10801 USA	0892-7790	1557-900X		J ENDOUROL	J. Endourol.	2024 MAY 24	2024										10.1089/end.2024.0055	http://dx.doi.org/10.1089/end.2024.0055		MAY 2024	6	Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Urology & Nephrology	RU5F8	38717951				2024-07-03	WOS:001230179900001
J	Chien, AC; Tang, HB; Jagessar, B; Chang, KW; Peng, NY; Nael, K; Salamon, N				Chien, Aichi; Tang, Hubert; Jagessar, Bhavita; Chang, Kai-wei; Peng, Nanyun; Nael, Kambiz; Salamon, Noriko			AI-Assisted Summarization of Radiological Reports: Evaluating GPT3davinci, BARTcnn, LongT5booksum, LEDbooksum, LEDlegal, and LEDclinical	AMERICAN JOURNAL OF NEURORADIOLOGY			English	Article								BACKGROUND AND PURPOSE: The review of clinical reports is an essential part of monitoring disease progression. Synthesizing multiple imaging reports is also important for clinical decisions. It is critical to aggregate information quickly and accurately. Machine learning natural language processing (NLP) models hold promise to address an unmet need for report summarization.MATERIALS AND METHODS: We evaluated NLP methods to summarize longitudinal aneurysm reports. A total of 137 clinical reports and 100 PubMed case reports were used in this study. Models were 1) compared against expert-generated summary using longitudinal imaging notes collected in our institute and 2) compared using publicly accessible PubMed case reports. Five AI models were used to summarize the clinical reports, and a sixth model, the online GPT3davinci NLP large language model (LLM), was added for the summarization of PubMed case reports. We assessed the summary quality through comparison with expert summaries using quantitative metrics and quality reviews by experts.RESULTS: In clinical summarization, BARTcnn had the best performance (BERTscore = 0.8371), followed by LongT5Booksum and LEDlegal. In the analysis using PubMed case reports, GPT3davinci demonstrated the best performance, followed by models BARTcnn and then LEDbooksum (BERTscore = 0.894, 0.872, and 0.867, respectively).CONCLUSIONS: AI NLP summarization models demonstrated great potential in summarizing longitudinal aneurysm reports, though none yet reached the level of quality for clinical usage. We found the online GPT LLM outperformed the others; however, the BARTcnn model is potentially more useful because it can be implemented on-site. Future work to improve summarization, address other types of neuroimaging reports, and develop structured reports may allow NLP models to ease clinical workflow.	[Chien, Aichi; Tang, Hubert; Jagessar, Bhavita; Nael, Kambiz; Salamon, Noriko] UCLA, David Geffen Sch Med, Dept Radiol Sci, Los Angeles, CA USA; [Chang, Kai-wei; Peng, Nanyun] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA USA; [Chien, Aichi] UCLA, Dept Radiol, David Geffen Sch Med, 10833 LeConte Ave,Box 951721, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA; University of California System; University of California Los Angeles; University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA	Chien, AC (corresponding author), UCLA, Dept Radiol, David Geffen Sch Med, 10833 LeConte Ave,Box 951721, Los Angeles, CA 90095 USA.	aichi@ucla.edu	Chang, Kai-Wei/AAJ-7874-2020	Chang, Kai-Wei/0000-0002-4674-2662; chien, aichi/0000-0001-6233-4047	NIH [R01HL152270]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Due to the sensitive nature of the aneurysm clinical reports collected for this study and to protect patient privacy, requests to access the data by researchers trained in human subject research may be sent to the corresponding author or NIH NHLBI BioLINNC Biologic Specimen and Data Repositories Information Coordinating Center following NIH public access policy reference to project R01HL152270. To access the source code for the models described in this study, links are provided in Online Supplemental Data.	Adams G., 2022, ARXIV, p2204.10290; Alfattni G, 2020, J BIOMED INFORM, V108, DOI 10.1016/j.jbi.2020.103488; Beltagy I., 2020, arXiv; Bhandari M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9347; Chien A, 2020, J NEUROSURG, V132, P1077, DOI 10.3171/2018.11.JNS181814; D'Antonoli TA, 2024, DIAGN INTERV RADIOL, V30, P80, DOI 10.4274/dir.2023.232417; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eskey CJ, 2018, CIRCULATION, V137, pE661, DOI 10.1161/CIR.0000000000000567; Fu SY, 2019, JMIR MED INF, V7, P82, DOI 10.2196/12109; Goldstein A, 2016, J BIOMED INFORM, V61, P159, DOI 10.1016/j.jbi.2016.03.022; Goyal T, 2022, ARXIV; Guo M., 2022, FINDINGS ASS COMPUTA, P724, DOI [10.18653/v1/2022.findings-naacl.55, DOI 10.18653/V1/2022.FINDINGS-NAACL.55]; Hirsch JS, 2015, J AM MED INFORM ASSN, V22, P263, DOI 10.1136/amiajnl-2014-002945; Huang K, 2020, ARXIV; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Kim C, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212778; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Mishra R, 2014, J BIOMED INFORM, V52, P457, DOI 10.1016/j.jbi.2014.06.009; Moharasan G, 2019, J HEALTHC INFORM RES, V3, P220, DOI 10.1007/s41666-019-00049-0; Monajatipoor M, 2022, LECT NOTES COMPUT SC, V13435, P725, DOI 10.1007/978-3-031-16443-9_69; Moskovitch R, 2019, J BIOMED INFORM, V90, DOI 10.1016/j.jbi.2018.12.006; Percha B, 2021, ANNU REV BIOMED DA S, V4, P165, DOI 10.1146/annurev-biodatasci-030421-030931; Sarzynski E, 2017, BMJ QUAL SAF, V26, P372, DOI 10.1136/bmjqs-2015-005201; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Styler William F 4th, 2014, Trans Assoc Comput Linguist, V2, P143; Sun WY, 2013, J AM MED INFORM ASSN, V20, P806, DOI 10.1136/amiajnl-2013-001628; Sun WC, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/4302425; Tippareddy Charit, 2023, Curr Probl Diagn Radiol, DOI 10.1067/j.cpradiol.2023.08.018; Wheater E, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0908-7; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Zhang T., 2019, INT C LEARNING REPRE	32	0	0	4	4	AMER SOC NEURORADIOLOGY	DENVILLE	PO BOX 3000, DENVILLE, NJ 07834-9349 USA	0195-6108	1936-959X		AM J NEURORADIOL	Am. J. Neuroradiol.	FEB	2024	45	2					244	248		10.3174/ajnr.A8102	http://dx.doi.org/10.3174/ajnr.A8102		JAN 2024	5	Clinical Neurology; Neuroimaging; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Radiology, Nuclear Medicine & Medical Imaging	GC5K1	38238092	hybrid			2024-07-03	WOS:001145523300001
J	Wu, RH; Su, WC; Ma, KD; Liao, J				Wu, Ronghuan; Su, Wanchao; Ma, Kede; Liao, Jing			IconShop: Text-Guided Vector Icon Synthesis with Autoregressive Transformers	ACM TRANSACTIONS ON GRAPHICS			English	Article						SVG; Icon Synthesis; Vector Graphics Generation; Text-Guided Generation; Autoregressive Transformers		Scalable Vector Graphics (SVG) is a popular vector image format that offers good support for interactivity and animation. Despite its appealing characteristics, creating custom SVG content can be challenging for users due to the steep learning curve required to understand SVG grammars or get familiar with professional editing software. Recent advancements in text-to-image generation have inspired researchers to explore vector graphics synthesis using either image-based methods (i.e., text. raster image. vector graphics) combining text-to-image generation models with image vectorization, or language-based methods (i.e., text. vector graphics script) through pretrained large language models. Nevertheless, these methods suffer from limitations in terms of generation quality, diversity, and flexibility. In this paper, we introduce IconShop, a text-guided vector icon synthesis method using autoregressive transformers. The key to success of our approach is to sequentialize and tokenize SVG paths (and textual descriptions as guidance) into a uniquely decodable token sequence. With that, we are able to exploit the sequence learning power of autoregressive transformers, while enabling both unconditional and text-conditioned icon synthesis. Through standard training to predict the next token on a large-scale vector icon dataset accompanied by textural descriptions, the proposed IconShop consistently exhibits better icon synthesis capability than existing image-based and language-based methods both quantitatively (using the FID and CLIP scores) and qualitatively (through formal subjective user studies). Meanwhile, we observe a dramatic improvement in generation diversity, which is validated by the objective Uniqueness and Novelty measures. More importantly, we demonstrate the flexibility of IconShop with multiple novel icon synthesis tasks, including icon editing, icon interpolation, icon semantic combination, and icon design auto-suggestion.	[Wu, Ronghuan; Su, Wanchao; Ma, Kede; Liao, Jing] City Univ Hong Kong, Hong Kong, Peoples R China; [Su, Wanchao] Monash Univ, Clayton, Vic, Australia	City University of Hong Kong; Monash University	Liao, J (corresponding author), City Univ Hong Kong, Hong Kong, Peoples R China.	ronghwu2-c@my.cityu.edu.hk; wanchao_su@outlook.com; kede.ma@cityu.edu.hk; jingliao@cityu.edu.hk		SU, Wanchao/0000-0002-7498-3033; Ma, Kede/0000-0001-8608-1128; LIAO, Jing/0000-0001-7014-5377; WU, Ronghuan/0000-0001-9741-9876	GRF grant from the Research Grants Council (RGC) of the Hong Kong Special Administrative Region, China [CityU 11216122]; OPPO	GRF grant from the Research Grants Council (RGC) of the Hong Kong Special Administrative Region, China; OPPO	The work described in this paper was substantially supported by a GRF grant from the Research Grants Council (RGC) of the Hong Kong Special Administrative Region, China [Project No. CityU 11216122]. We would also like to express our sincere gratitude to OPPO for their generous support of our work.	Aghajanyan A, 2022, Arxiv, DOI [arXiv:2201.07520, 10.48550/arXiv.2201.07520]; Huang CZA, 2018, Arxiv, DOI [arXiv:1809.04281, 10.48550/arXiv.1809.04281, DOI 10.48550/ARXIV.1809.04281]; Aoki H, 2022, IEEE IMAGE PROC, P646, DOI 10.1109/ICIP46576.2022.9897633; Bavarian M, 2022, Arxiv, DOI [arXiv:2207.14255, 10.48550/arXiv.2207.14255]; Bergen S, 2012, VISUAL COMPUT, V28, P35, DOI 10.1007/s00371-011-0597-4; Brooks T, 2023, Arxiv, DOI arXiv:2211.09800; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Carlier M., 2020, Adv.Neural Inf. Process. Syst., V33, P16351; Chang H., 2023, arXiv; Chang HW, 2022, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR52688.2022.01103; Chen M, 2020, PR MACH LEARN RES, V119; Chen Yinpeng, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P2536, DOI 10.1145/3503161.3548109; Clouƒtre L, 2019, Arxiv, DOI [arXiv:1901.02199, DOI 10.48550/ARXIV.1901.02199]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding M, 2021, Advances in Neural Information Processing Systems, V34; Ding M, 2022, Arxiv, DOI [arXiv:2204.14217, 10.48550/arXiv.2204.14217]; Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268; Frans K, 2021, Arxiv, DOI arXiv:2106.14843; Fried Daniel, 2023, INT C LEARNING REPRE; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Ha D, 2017, Arxiv, DOI arXiv:1704.03477; Hensel M, 2017, ADV NEUR IN, V30; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; JAIN A., 2022, arXiv; Kang MG, 2023, Arxiv, DOI arXiv:2303.05511; Karamatsu Takuro., 2020, JOINT WORKSHOP MULTI, P7; Kingma D. P., 2017, ARXIV; Li NH, 2019, AAAI CONF ARTIF INTE, P6706; Lopes RG, 2019, IEEE I CONF COMP VIS, P7929, DOI 10.1109/ICCV.2019.00802; Ma X, 2022, PROC CVPR IEEE, P16293, DOI 10.1109/CVPR52688.2022.01583; Nichol A, 2022, Arxiv, DOI arXiv:2112.10741; OpenAI, 2023, GPT-4 technical report; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Poole B., 2022, arXiv; Probets S., 2001, Proceedings of the ACM Symposium on Document Engineering (DocEng '01), P135, DOI 10.1145/502187.502207; Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Ramesh A, 2021, PR MACH LEARN RES, V139; Reed S, 2016, PR MACH LEARN RES, V48; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saharia C., 2022, Adv. Neural Inf. Process. Syst., V35, P36479; Selinger P., 2003, Potrace: A Polygon-Based Tracing Algorithm; Setlur V, 2005, COMPUT GRAPH FORUM, V24, P647, DOI 10.1111/j.1467-8659.2005.00889.x; Setlur V, 2011, P 16 INT C INT US IN, P165; Turc I, 2019, Arxiv, DOI arXiv:1908.08962; Valle R, 2020, Arxiv, DOI arXiv:2005.05957; Vaswani A, 2017, ADV NEUR IN, V30; Wang YZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480488; Xu JZ, 2023, Arxiv, DOI [arXiv:2304.05977, 10.48550/arXiv.2304.05977]; Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143; Xu X, 2022, PR MACH LEARN RES; Yang HY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11177890; Yu JH, 2022, Arxiv, DOI [arXiv:2206.10789, 10.48550/arXiv.2206.10789]; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhang Z, 2022, Arxiv, DOI arXiv:2105.14211; Zhang ZZ, 2018, PROC CVPR IEEE, P6199, DOI 10.1109/CVPR.2018.00649; Zhao NX, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376618; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244	61	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0730-0301	1557-7368		ACM T GRAPHIC	ACM Trans. Graph.	DEC	2023	42	6							230	10.1145/3618364	http://dx.doi.org/10.1145/3618364			14	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	EO2B0		Green Submitted			2024-07-03	WOS:001139790400058
J	Park, K; Park, S; Joung, J				Park, Kyunghoon; Park, Seyoung; Joung, Junegak			Contextual Meaning-Based Approach to Fine-Grained Online Product Review Analysis for Product Design	IEEE ACCESS			English	Article						Bidirectional encoder representations from transformers (BERT); contextual meaning; customer opinion; online product review; polysemy word; product design; product feature; sentiment analysis; sub-feature identification; television (TV)	CUSTOMER REVIEWS; USERS	Customers share their opinions about a product through online reviews. Companies incorporate customer opinions into product design to increase customer satisfaction and market success. Many studies have attempted to analyze customer opinions on specific product features. However, these studies do not attempt to understand the actual intent of customers when mentioning a product feature in the context of a review. To overcome this limitation, this study develops a contextual meaning-based approach that considers the contextual meanings of product features in reviews. This approach enables a deeper understanding of the intent behind the target features of a product. First, a large language model-based word embedding model and clustering algorithms are introduced to divide product features into sub-features based on contextual meanings. Second, a new method is developed for creating a contextual word map to interpret the clustering results. Third, a sentiment analysis is performed to evaluate customer satisfaction for each sub-feature using BERT. A case study of a television product was conducted to demonstrate the applicability of the developed approach. The results showed that, unlike in other studies, several sub-features were identified from four targeted TV features based on their contextual meanings. Furthermore, customer satisfaction was evaluated for each sub-feature. This study is the first attempt at providing a fine-grained online product review analysis based on unsupervised learning to clarify meanings according to the context. The developed approach can be useful for determining detailed directions for improvement in the product design process and is expected to offer a new perspective.	[Park, Kyunghoon] Pohang Univ Sci & Technol POSTECH, Dept Ind Engn & Management, Pohang 790784, South Korea; [Park, Seyoung] Univ Illinois Urbana Champaign UIUC, Dept Ind & Enterprise Syst Engn, Urbana, IL 61801 USA; [Joung, Junegak] Hanyang Univ, Sch Interdisciplinary Ind Studies, Seoul 04763, South Korea	Pohang University of Science & Technology (POSTECH); University of Illinois System; University of Illinois Urbana-Champaign; Hanyang University	Joung, J (corresponding author), Hanyang Univ, Sch Interdisciplinary Ind Studies, Seoul 04763, South Korea.	june30@hanyang.ac.kr		Park, Seyoung/0000-0002-3103-5412; Joung, junegak/0000-0003-3595-3349	Research fund of Hanyang University [HY-202300000001721]; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education [2021R1I1A1A01044552]	Research fund of Hanyang University; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education(National Research Foundation of KoreaMinistry of Education (MOE), Republic of KoreaNational Research Council for Economics, Humanities & Social Sciences, Republic of Korea)	This work was supported in part by the Research fund of Hanyang University under Grant HY-202300000001721, and in part by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education under Grant 2021R1I1A1A01044552.	Aletras N., 2014, P 14 C EUR ASS COMP, P22, DOI DOI 10.3115/V1/E14-4005; Vo AD, 2018, IEEE ACCESS, V6, P5415, DOI 10.1109/ACCESS.2018.2797224; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boyd-Graber J., 2014, Handbook of Mixed Membership Models and Its Applications, P3; Chen YH, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159901; COOPER RG, 1987, J PROD INNOVAT MANAG, V4, P169, DOI 10.1111/1540-5885.430169; DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dieng AB, 2020, T ASSOC COMPUT LING, V8, P439, DOI 10.1162/tacl_a_00325; Du YF, 2022, INT J PROD RES, V60, P4176, DOI 10.1080/00207543.2021.2023776; Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800; Füller J, 2008, J PROD INNOVAT MANAG, V25, P608, DOI 10.1111/j.1540-5885.2008.00325.x; Gozuacik N, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115388; GRIFFIN A, 1993, MARKET SCI, V12, P1, DOI 10.1287/mksc.12.1.1; Gruen TW, 2006, J BUS RES, V59, P449, DOI 10.1016/j.jbusres.2005.10.004; Guo F, 2024, INT J HUM-COMPUT INT, V40, P3092, DOI 10.1080/10447318.2023.2179217; Huang LJ, 2019, IEEE ACCESS, V7, P91940, DOI 10.1109/ACCESS.2019.2920091; Jey H. L., 2014, P 14 C EUROPEAN CHAP, P530, DOI DOI 10.3115/V1/E14-1056; Jiang HM, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100969; Jin J, 2022, INT J PROD RES, V60, P6708, DOI 10.1080/00207543.2021.1949641; Jin J, 2016, INT J PROD RES, V54, P3019, DOI 10.1080/00207543.2016.1154208; Joung J, 2022, INT J PROD RES, V60, P7053, DOI 10.1080/00207543.2021.2000656; Joung J, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4049865; Joung J, 2021, J MECH DESIGN, V143, DOI 10.1115/1.4048960; Kahn KB, 2001, J PROD INNOVAT MANAG, V18, P314, DOI 10.1016/S0737-6782(01)00101-1; Kim HS, 2019, J MECH SCI TECHNOL, V33, P2785, DOI 10.1007/s12206-019-0525-5; Ko N, 2018, IEEE ACCESS, V6, P1680, DOI 10.1109/ACCESS.2017.2780046; Koltcov S, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21070660; Kpiebaareh MY, 2022, INFORMATION, V13, DOI 10.3390/info13030118; Lee J, 2023, IEEE ACCESS, V11, P71859, DOI 10.1109/ACCESS.2023.3295452; Lee Y, 2021, NEURAL PROCESS LETT, V53, P1979, DOI 10.1007/s11063-021-10499-6; Magnusson PR, 2009, J PROD INNOVAT MANAG, V26, P578, DOI 10.1111/j.1540-5885.2009.00684.x; Mimno D., 2011, P 2011 C EMPIRICAL M, P262; Mudambi SM, 2010, MIS QUART, V34, P185; Ng CY, 2020, COMPUT IND ENG, V139, DOI 10.1016/j.cie.2019.106180; Piller FT, 2006, R&D MANAGE, V36, P307, DOI 10.1111/j.1467-9310.2006.00432.x; Raghupathi D, 2015, INT J INTERACT DES M, V9, P201, DOI 10.1007/s12008-015-0273-4; Shahin A, 2021, TQM J, V33, P804, DOI 10.1108/TQM-11-2019-0267; Sun H, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101174; Wu XY, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14396-3; Xu X, 2017, INT J INFORM MANAGE, V37, P673, DOI 10.1016/j.ijinfomgt.2017.06.004; Zhan JM, 2009, EXPERT SYST APPL, V36, P2107, DOI 10.1016/j.eswa.2007.12.039	42	0	0	25	25	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						4225	4238		10.1109/ACCESS.2023.3343501	http://dx.doi.org/10.1109/ACCESS.2023.3343501			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	EQ0N7		gold			2024-07-03	WOS:001140273100001
J	Zhou, YF; Zhu, C; Zhu, WJ				Zhou, Yunfeng; Zhu, Cui; Zhu, Wenjun			ProMvSD: Towards unsupervised knowledge graph anomaly detection via prior knowledge integration and multi-view semantic-driven estimation	INFORMATION PROCESSING & MANAGEMENT			English	Article						Knowledge graph; Anomaly detection; Pre-trained language models; Semantics; Unsupervised learning		Knowledge graphs (KGs) have found extensive applications within intelligent systems, such as information retrieval. Much of the research has predominantly focused on completing missing knowledge, with little consideration given to examining errors. Unfortunately, during customizing KGs, diverse unpredictable errors are virtually unavoidable to be introduced, and these anomalies significantly impact the performance of applications. Detecting erroneous knowledge presents a formidable challenge due to the costly acquisition of ground -truth labels. In this work, we develop an unsupervised anomaly detection framework named ProMvSD, aiming to adapt KGs of varying scales via serialization components. To overcome the insufficient contextual information provided by the topological structure, we introduce the large language model as a reasoner to extract prior knowledge from extensive pre -trained textual data, thereby enhancing the understanding of KGs. Anomalous triple may result in a larger semantic gap between the head and tail neighborhoods. To uncover latent anomalies effectively, we propose a multi -view semantic -driven model (MvSD) based on the assumptions of self -consistency and information stability. MvSD jointly estimates the suspiciousness of triples from three hyperviews: node -view semantic contradiction, triple -view semantic gap, and pathway -view semantic gap. Extensive experiments on three English benchmark KGs and a Chinese medical KG demonstrate that, for the top 1% of the most suspicious triples, we can detect real anomalies with at most 99.9% accuracy. Furthermore, ProMvSD significantly outperforms state-of-the-art representation learning baselines, achieving a 29.2% improvement in detecting all anomalies.	[Zhou, Yunfeng; Zhu, Cui; Zhu, Wenjun] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China	Beijing University of Technology	Zhu, C (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.	yfzhou@emails.bjut.edu.cn; cuizhu@bjut.edu.cn; cuizhu@bjut.edu.cn			National Natural Science Foundation of China [62276011]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgments</B> This work was supported by the National Natural Science Foundation of China under Grant No. 62276011.	Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Belth C, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1115, DOI 10.1145/3366423.3380189; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Carlson A, 2010, AAAI CONF ARTIF INTE, P1306; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dai QuocNguyen TDN, 2018, P 2018 C N AM CHAPT, P327, DOI [DOI 10.18653/V1/N18-2053, 10.18653/v1/n18-2053]; Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong J., 2023, P 16 ACM INT C WEB S, P877, DOI [10.1145/3539597.3570368, DOI 10.1145/3539597.3570368]; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fan Miao, 2014, P 28 PACIFIC ASIA C, P328; Galarraga L.A., 2013, WWW 13, P413, DOI DOI 10.1145/2488388.2488425; Ge CC, 2020, Arxiv, DOI arXiv:2004.14478; Grubb T, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P84, DOI 10.1145/3487553.3524212; Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1; Huang X, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P105, DOI 10.1145/3289600.3290956; Jia SB, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2865, DOI 10.1145/3308558.3313586; Kazemi SM, 2018, ADV NEUR IN, V31; Kingma D. P., 2017, ARXIV; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Li ZF, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103348; Lin YK, 2015, AAAI CONF ARTIF INTE, P2181; Liu HX, 2017, PR MACH LEARN RES, V70; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lu YJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P505; Ma JT, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109688; Ma Y., 2014, Communications in Computer and Information Science, V480, P29, DOI DOI 10.1007/978-3-662-45495-4; Mahdisoltani F., 2013, Yago3: A Knowledge Base from Multilingual Wikipedias; Mao X, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P420, DOI 10.1145/3336191.3371804; Meilicke C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3137; Meilicke C, 2018, LECT NOTES COMPUT SC, V11136, P3, DOI 10.1007/978-3-030-00671-6_1; Melo A, 2017, K-CAP 2017: PROCEEDINGS OF THE KNOWLEDGE CAPTURE CONFERENCE, DOI 10.1145/3148011.3148033; Nathani D, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4710; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Paulheim H, 2014, INT J SEMANT WEB INF, V10, P63, DOI 10.4018/ijswis.2014040104; Sheng JW, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1681; Shi B, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103447; Sun ZQ, 2020, AAAI CONF ARTIF INTE, V34, P222; Sun ZQ, 2019, Arxiv, DOI [arXiv:1902.10197, 10.48550/arXiv.1902.10197]; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Toutanova K., 2015, P 3RDWORKSHOP CONTIN, P57, DOI [10.18653/v1/W15-4007, DOI 10.18653/V1/W15-4007]; Trouillon T, 2016, PR MACH LEARN RES, V48; TURNER JC, 1986, BRIT J SOC PSYCHOL, V25, P237, DOI 10.1111/j.2044-8309.1986.tb00732.x; Vaswani A, 2017, ADV NEUR IN, V30; Wang Q, 2017, IEEE T KNOWL DATA EN, V29, P2724, DOI 10.1109/TKDE.2017.2754499; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xie RB, 2018, AAAI CONF ARTIF INTE, P4954; Yang B., 2014, arXiv; Yang Y, 2022, NEURAL NETWORKS, V146, P1, DOI 10.1016/j.neunet.2021.11.010; Yao L, 2019, Arxiv, DOI arXiv:1909.03193; Ye C, 2023, KNOWL INF SYST, V65, P3273, DOI 10.1007/s10115-023-01866-x; Zaveri A, 2013, P 9 INT C SEM SYST, P97, DOI [10.1145/2506182.2506195, DOI 10.1145/2506182.2506195]; Zhang B, 2023, Arxiv, DOI [arXiv:2301.07069, 10.48550/arXiv.2301.07069]; Zhang QG, 2024, IEEE T KNOWL DATA EN, V36, P1667, DOI 10.1109/TKDE.2023.3310149; Zhang QG, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P2590, DOI 10.1145/3511808.3557264; Zhang ZH, 2020, Arxiv, DOI arXiv:2010.11522	60	0	0	2	2	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-4573	1873-5371		INFORM PROCESS MANAG	Inf. Process. Manage.	JUL	2024	61	4							103705	10.1016/j.ipm.2024.103705	http://dx.doi.org/10.1016/j.ipm.2024.103705		MAR 2024	20	Computer Science, Information Systems; Information Science & Library Science	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Information Science & Library Science	QN7H3					2024-07-03	WOS:001221611600001
J	Salim, MS; Hossain, SI				Salim, Md. Shahidul; Hossain, Sk Imran			An Applied Statistics dataset for human vs AI-generated answer classification	DATA IN BRIEF			English	Article; Data Paper						LLM; Assignment; Transformer; AI		Due to the increasing popularity of Large Language Models (LLMs) like ChatGPT, students from various fields now commonly rely on AI -powered text generation tools to complete their assignments. This poses a challenge for course instructors who struggle to identify the authenticity of submitted work. Several AI detection tools for differentiating humangenerated text from AI -generated text exist for domains like medical and coding, and available generic tools do not perform well on domain -specific tasks. Those AI detection tools depend on LLM, and to train the LLM, an instruction dataset is needed that helps the LLM to learn the differences between patterns of human -generated text and AI -generated text. To help with the creation of a tool for Applied Statistics, we have created a dataset containing 4231 questionand -answer combinations. To create the dataset, first, we collected 116 questions covering a wide range of topics from Applied Statistics selected by domain experts. Second, we created a framework to randomly distribute and collect answers to the questions from students. Third, we collected answers to fifty assigned questions from each of the 100 students participating in the work. Fourth, we generated an equal number of AI -generated answers using ChatGPT. The prepared dataset will be useful for creating AI -detector tools for the Applied Statistics domain as well as benchmarking AI -detector tools, and the proposed data preparation framework will be useful for collecting data for other domains.	[Salim, Md. Shahidul; Hossain, Sk Imran] Khulna Univ Engn & Technol, Khulna 9203, Bangladesh	Khulna University of Engineering & Technology (KUET)	Hossain, SI (corresponding author), Khulna Univ Engn & Technol, Khulna 9203, Bangladesh.	ss@cse.kuet.ac.bd; imran@cse.kuet.ac.bd						Brown TB., 2020, ADV NEURAL INF PROCE, V2020; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ibrahim H, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-38964-3; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Salim Shahidul M D, 2023, Mendeley Data, DOI 10.17632/MH892RKSK2; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Turnitin LLC, 2023, Turnitin; Vasilatos C, 2023, Arxiv, DOI arXiv:2305.18226; Weber-Wulff D, 2023, Arxiv, DOI [arXiv:2306.15666, 10.48550/arXiv.2306.15666, DOI 10.48550/ARXIV.2306.15666]	10	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-3409			DATA BRIEF	Data Brief	JUN	2024	54								110240	10.1016/j.dib.2024.110240	http://dx.doi.org/10.1016/j.dib.2024.110240		MAR 2024	6	Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Science & Technology - Other Topics	OJ8J5		hybrid			2024-07-03	WOS:001206991700001
J	Li, HL; Choi, J; Kwon, Y; Ahn, JH				Li, Hailong; Choi, Jaewan; Kwon, Yongsuk; Ahn, Jung Ho			A Hardware-Friendly Tiled Singular-Value Decomposition-Based Matrix Multiplication for Transformer-Based Models	IEEE COMPUTER ARCHITECTURE LETTERS			English	Article						Matrix decomposition; Computational modeling; Transformers; Graphics processing units; Natural language processing; Kernel; Task analysis; Transformer-based model; GPU; tiled singular vector decomposition		Transformer-based models have become the backbone of numerous state-of-the-art natural language processing (NLP) tasks, including large language models. Matrix multiplication, a fundamental operation in the Transformer-based models, accounts for most of the execution time. While singular value decomposition (SVD) can accelerate this operation by reducing the amount of computation and memory footprints through rank size reduction, it leads to degraded model quality due to challenges in preserving important information. Moreover, this method does not effectively utilize the resources of modern GPUs. In this paper, we propose a hardware-friendly approach: matrix multiplication based on tiled singular value decomposition (TSVD). TSVD divides a matrix into multiple tiles and performs matrix factorization on each tile using SVD. By breaking down the process into smaller regions, TSVD mitigates the loss of important data. We apply the matrices decomposed by TSVD for matrix multiplication, and our TSVD-based matrix multiplication (TSVD-matmul) leverages GPU resources more efficiently compared to the SVD approach. As a result, TSVD-matmul achieved a speedup of 1.03x to 3.24x compared to the SVD approach at compression ratios ranging from 2 to 8. When deployed to GPT-2, TSVD not only performs competitively with a full fine-tuning on the E2E NLG task but also achieves a speedup of 1.06x to 1.24x at 2 to 8 compression ratios while increasing accuracy by up to 1.5 BLEU score.	[Li, Hailong; Choi, Jaewan; Kwon, Yongsuk; Ahn, Jung Ho] Seoul Natl Univ, Seoul 08826, South Korea	Seoul National University (SNU)	Ahn, JH (corresponding author), Seoul Natl Univ, Seoul 08826, South Korea.	lhl2017@scale.snu.ac.kr; jwchoi@scale.snu.ac.kr; yongsuk.kwon@scale.snu.ac.kr; gajh@snu.ac.kr	Ahn, Jung Ho/D-1298-2013	Ahn, Jung Ho/0000-0003-1733-1394; Choi, Jaewan/0000-0003-2447-4369; Kwon, Yongsuk/0000-0002-1956-4629	Samsung Electronics Company, Ltd.	Samsung Electronics Company, Ltd.(Samsung)	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown T., 2020, P ADV NEUR INF PROC, P1877; Chen JY, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P106, DOI 10.1145/3330345.3330355; Choi J, 2022, I S WORKL CHAR PROC, P92, DOI 10.1109/IISWC55918.2022.00018; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dusek Ondrej., 2018, P 11 INT C NAT LANG, P322; Hsu Y.-C., 2022, P INT C LEARN REPR; Kerr A., 2017, Cutlass: Fast linear algebra in cuda c++; Kwon S. J., 2022, P C EMP METH NAT LAN, P3288; Li H., 2020, PROC INT C ELECT INF, P1; Li H, 2022, I S WORKL CHAR PROC, P104, DOI 10.1109/IISWC55918.2022.00019; NVIDIA, 2020, Faster Transformer; Osama M., 2023, P 28 ACM SIGPLAN ANN, P439; Osawa K, 2017, 2017 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P186, DOI 10.1109/HPCS.2017.37; Park G, 2024, Arxiv, DOI arXiv:2206.09557; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Vaswani A., 2017, Adv. Neural Inf. Process. Syst, P6000	17	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1556-6056	1556-6064		IEEE COMPUT ARCHIT L	IEEE Comput. Archit. Lett.	JUL-DEC	2023	22	2					169	172		10.1109/LCA.2023.3323482	http://dx.doi.org/10.1109/LCA.2023.3323482			4	Computer Science, Hardware & Architecture	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CB6F0					2024-07-03	WOS:001122822900001
C	Assem, H; Sarkar, I; Dutta, S		Chen, Y; Ludwig, H; Tu, Y; Fayyad, U; Zhu, X; Hu, X; Byna, S; Liu, X; Zhang, J; Pan, S; Papalexakis, V; Wang, J; Cuzzocrea, A; Ordonez, C		Assem, Haytham; Sarkar, Iajdeep; Dutta, Sourav			<i>QASAR</i>: Self-Supervised Learning Framework for Extractive Question Answering	2021 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)	IEEE International Conference on Big Data		English	Proceedings Paper	9th IEEE International Conference on Big Data (IEEE BigData)	DEC 15-18, 2021	ELECTR NETWORK	IEEE, IEEE Comp Soc, Ankura, Lyve Cloud, Seagate, NSF		Question Answering; Self-Supervised Learning; Question Generation; Context Retrieval		Question Answering (QA) has become a foundational research area in Natural Language Understanding (NLU) with widespread applications in search, personal digital assistance, and conversational systems. Despite the success in open-domain question answering, existing extractive question answering models pre-trained using Wikipedia articles (e.g., SQuAD data) perform rather poorly in closed-domain and industrial scenarios. Further, a major limitation in adapting question answering systems to such contexts is the poor availability and the expensive annotation of domain-specific data. Thus, wide applicability of QA models are severely hampered in enterprise systems. In this paper, we aim to address the above challenges by introducing a novel QA framework, Qasar, using self-supervised learning for efficient domain adaptation. We show, for the first time, the advantage of finetuning pre-trained QA models for closed-domains by synthetically generated domain-specific questions and answers (from relevant documents) from large language models like T5. Further, we also propose a novel context retrieval component based on question-context semantic relatedness to further boost the accuracy of the Qasar QA framework. Experimental results show significant performance improvements on both openand closed-domain QA datasets, while requiring no labelling efforts, which we believe will contribute to the ease of deployment of such systems in enterprise settings. The different modules of our framework (synthetic data generation, context retrieval, and question answering) can be fully reproduced by fine-tuning publicly available language models and QA models on SQuAD dataset as discussed in the paper.	[Assem, Haytham; Sarkar, Iajdeep; Dutta, Sourav] Huawei Res, Dublin, Ireland; [Sarkar, Iajdeep] Natl Univ Ireland Galway, Galway, Ireland	Ollscoil na Gaillimhe-University of Galway	Assem, H (corresponding author), Huawei Res, Dublin, Ireland.	haytham.assem@huawei.com; r.sarkari@nuigalway.ie; sourav.dutta2@huawei.com		Dutta, Sourav/0000-0002-8934-9166	Government of Ireland Postgraduate Fellowship; Irish Research Council [GOIPG/2019/3480]; Science Foundation Ireland [SFI/12/RC/2289 2]	Government of Ireland Postgraduate Fellowship; Irish Research Council(Irish Research Council for Science, Engineering and Technology); Science Foundation Ireland(Science Foundation Ireland)	This work is supported by a grant from The Government of Ireland Postgraduate Fellowship, Irish Research Council under project ID GOIPG/2019/3480. The work is also co-supported by Science Foundation Ireland under grant number SFI/12/RC/2289 2 (Insight).	[Anonymous], 2009, ENCY DATABASE SYSTEM; [Anonymous], 2015, P 2015 C EMP METH NA; Assem H, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P423; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Chan Ying-Hong, 2019, P 2 WORKSH MACH READ, P154; Devlin J., 2019, CoRR, P4171; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303; Huang WY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5258; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; KEMBHAVI A, 2017, CVPR, P5376, DOI DOI 10.1109/CVPR.2017.571; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lee HG, 2021, IEEE ACCESS, V9, P21279, DOI 10.1109/ACCESS.2021.3054912; Li H, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2125, DOI 10.1145/3357384.3358088; Liu S., 2019, ARXIV190701118; Liu Y., 2019, CoRR abs/1907.11692; Loginova E, 2018, COMM COM INF SC, V909, P274, DOI 10.1007/978-3-030-00063-9_26; Luyu Gao, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P280, DOI 10.1007/978-3-030-72240-1_26; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; Mollá D, 2007, COMPUT LINGUIST, V33, P41, DOI 10.1162/coli.2007.33.1.41; Nentidis Nentidis A A, ECML PKDD, P553; OZYURT M, 2021, P C LABS EV FOR CLEF, P1, DOI DOI 10.14689/EJER.2021.94.1; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Puri Raul, 2020, P 2020 C EMPIRICAL M, P5811; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Sal DD, 2006, PROCES LENG NAT, P131; Semnaniy S. J., 2019, P 33 C NEUR INF PROC, P1; Seonwooy Y., 2020, ARXIV201102687; Talmor A., 2021, P ICLR, V2021, P1; Trischler Adam, 2017, P 2 WORKSH REPR LEAR, P191, DOI [DOI 10.18653/V1/W17-2623, 10.18653/v1/W17-2623]; Vegupatti M., 2020, P AICS, P1; WANG D, 2020, APPL SCI-BASEL, V10, DOI DOI 10.1038/S41408-020-0274-9; Yu WH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P178; Zhang T., 2019, INT C LEARNING REPRE; Zhang Y., BERT QUESTION ANSWER; Zhang ZW., 2020, PLANT SOIL, V1, P1, DOI DOI 10.1109/TIE.2020.3007078	38	2	2	0	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2639-1589		978-1-6654-3902-2	IEEE INT CONF BIG DA			2021							1797	1808		10.1109/BigData52589.2021.9671570	http://dx.doi.org/10.1109/BigData52589.2021.9671570			12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT1RU					2024-07-03	WOS:000800559501108
J	Iu, KY; Zhou, ZY				Iu, Kwan Yuen; Zhou, Ziyue			Catalyst for Common Law Evolution: Experiment with ChatGPT and a Hypothetical Common Law Jurisdiction	ASIAN JOURNAL OF LAW AND ECONOMICS			English	Article						artificial intelligence; ChatGPT; common law system; efficient rules; judicial decision-making	BIAS	This paper aims to carry out empirical analysis of the viability of large language models (LLMs), specifically ChatGPT, in simulating the common law system and facilitating its evolutionary processes. Drawing on the Theory of Rules Evolution, it is understood that common law generates efficient rules by natural selection through constant litigation. Nonetheless, this evolutionary mechanism faces several hindrances. The process of change is typically slow and incremental. Courts often have to wait for a case that's deemed 'appropriate' before they can change the law, leading to extended delays. Additionally, courts frequently struggle to make efficient decisions due to limited information. Other factors that decelerate the creation of efficient rules include judicial bias, unequal distribution of resources among litigating parties, and the diminishing presence of a competitive legal order. This study first assesses ChatGPT's capability to embrace the essence of the common law system, namely the doctrine of stare decisis. We then assess its potential to overcome the hindrances in common law development and promote efficient rules. Through a series of meticulously designed hypothetical cases set in a virtual jurisdiction called the "Matrix Kingdom," we observed that ChatGPT mimic the functions of a common law court by citing, following, and distinguishing its own precedents, but it accomplishes this with significantly fewer resources and in less time. This implies that humans can introduce hypothetical legal situations, enabling LLMs to replicate the natural selection process observed in the common law system but with a significantly accelerated pace. Given that LLMs are trained with diverse information sources, not just the factual contexts of cases, they could potentially lower the informational constraints in decision-making. As such, LLMs might significantly contribute to the evolutionary processes of common law development. However, it is important to remain cautious of certain limitations, such as the potential for AI Hallucination and inherent biases in LLMs, which require careful consideration and management.	[Iu, Kwan Yuen] Co Pacific Chambers, Hksar, Peoples R China; [Zhou, Ziyue] Univ Hong Kong, Fac Law, Hksar, Peoples R China	University of Hong Kong	Iu, KY (corresponding author), Co Pacific Chambers, Hksar, Peoples R China.	kwanyueniu@gmail.com; ziyue@connect.hku.hk		IU, Kwan Yuen/0009-0000-1826-4803				[Anonymous], 1954, BERMAN V PARKER; [Anonymous], What is Strong AI?; [Anonymous], 2023, NEWSWIRE        0124; [Anonymous], 2016, State v. Loomis; [Anonymous], 1989, WATKINS V OLAFSON; [Anonymous], 2023, Mata v. Avianca, Inc.; [Anonymous], 2005, Kelo v. City of New London; [Anonymous], 1934, OLSON V US; [Anonymous], 1984, US V 50 ACRES LAND; [Anonymous], 2022, ChatGPT: Optimizing language models for dialogue; [Anonymous], Artificial Intelligence - What it is and why it matters; Aranson P. H., 1992, Constitutional Political Economy, V3, P289; Bartoletti, 2023, TWITTER; Boeglin J., 2015, YALE J LAW TECHNOLOG, V17, P4; Britannica, IS STRONG AI POSS; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Benjamin Minhao, 2021, HARVARD J LAW TECHNO; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Coglianese C, 2017, GEORGETOWN LAW J, V105, P1147; Cuéllar MF, 2019, COLUMBIA LAW REV, V119, P1773; Day J., 1976, CASE WEST R LAW REV, V26; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; EPIC, CRIMINAL JUSTICE SYS; Fagan F, 2019, SOUTH CALIF LAW REV, V93, P1; Geistfeld MA, 2017, CALIF LAW REV, V105, P1611, DOI 10.15779/Z38416SZ9R; Gennaioli N, 2007, J POLIT ECON, V115, P43, DOI 10.1086/511996; Glover E., 2023, BUILTIN         0726; Glover E., 2022, STRONG AI VS WEAK AI; GOODMAN JC, 1978, J LEGAL STUD, V7, P393, DOI 10.1086/467600; Google, LINK APP; HADFIELD GK, 1992, GEORGETOWN LAW J, V80, P583; HEINER RA, 1986, J LEGAL STUD, V15, P227, DOI 10.1086/467812; Hetler A., 2023, CHATGPT; Hutchinson A., 2003, HIBERNIAN LAW J, V4, P27; Iu KY, 2023, ChatGPT by OpenAI: the end of litigation lawyers?, DOI [10.2139/ssrn.4339839, DOI 10.2139/SSRN.4339839]; Jackson M., 2020, LOOPER          0131; Kahan DM, 2013, JUDGM DECIS MAK, V8, P407; Katz Daniel Martin, 2023, GPT-4 Passes the Bar Exam, DOI DOI 10.2139/SSRN.4389233; Keats Citron D., 2008, Washington University Law Review, V85, P1249; Klerman D, 2007, U CHICAGO LAW REV, V74, P1179, DOI 10.2307/20141860; Kowalkiewicz Marek, 2019, DID WE GET HERE STOR; LANDES WM, 1985, J LEGAL STUD, V14, P535, DOI 10.1086/467785; Lemley Mark A., 2023, WHERES LIABILITY HAR, DOI [10.2139/ssrn.4531029, DOI 10.2139/SSRN.4531029]; Liptak A., 2017, NEW YORK TIMES  0501; Liu V., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2109.06977; McCarthy J., 2007, WHAT IS ARTIFICIAL INTELLIGENCE?; Miceli TJ, 2009, J LEGAL STUD, V38, P157, DOI 10.1086/587439; Newport C., 2023, NEW YORKER      0413; Openai, IS CHATGPT BIAS; Park J. S., 2023, arXiv, V2023, P03442, DOI [10.48550/arXiv.2304.03442, DOI 10.48550/ARXIV.2304.03442]; Posner R. A., 2005, LAW PRAGMATISM DEMOC, P57, DOI [10.2307/j.ctv2d7x4rs, DOI 10.2307/J.CTV2D7X4RS]; Posner R. A., 2014, EC ANAL LAW, P304; POSNER RA, 1979, J LEGAL STUD, V8, P103, DOI 10.1086/467603; Posner RichardA., 2005, FLA STATE UNIV LAW R, V32, P1259; PRIEST GL, 1977, J LEGAL STUD, V6, P65, DOI 10.1086/467563; Re RichardM., 2019, Stanford Technology Law Review, V22, P242; rishnamurthy P., 2022, MEDIUM          0330; Rizzo M. J., 1980, HOFSTRA LAW REV, V8, P7; Rose J., 2023, VICA            0204; RUBIN PH, 1977, J LEGAL STUD, V6, P51, DOI 10.1086/467562; Russell S., 2019, ARTIF INTELL, P1; Schroer A., 2023, WHAT IS ARTIFICIAL I; Singh Sahib, 2023, PREPRINT; Stinson J. M., 2010, BROOKLYN LAW R, V76, P5; Taylor L., 2023, GUARDIAN        0228; Thapar A. R., 2018, MICH LAW REV, V116, P823, DOI [10.36644/mlr.116.6, DOI 10.36644/MLR.116.6]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Zhou Y., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2211.01910; Zywicki T. J., 2002, NORTHWEST U LAW REV, V97, P1581	69	0	0	13	13	WALTER DE GRUYTER GMBH	BERLIN	GENTHINER STRASSE 13, D-10785 BERLIN, GERMANY	2194-6086	2154-4611		ASIAN J LAW ECON	Asian J. Law Econ.	MAR 11	2024	15	1					55	82		10.1515/ajle-2023-0114	http://dx.doi.org/10.1515/ajle-2023-0114		JAN 2024	28	Law	Emerging Sources Citation Index (ESCI)	Government & Law	KR8E3					2024-07-03	WOS:001136769500001
J	Bhayana, R; Krishna, S; Bleakney, RR				Bhayana, Rajesh; Krishna, Satheesh; Bleakney, Robert R.			Performance of ChatGPT on a Radiology Board-style Examination: Insights into Current Strengths and Limitations	RADIOLOGY			English	Article								Background: ChatGPT is a powerful artificial intelligence large language model with great potential as a tool in medical practice and education, but its performance in radiology remains unclear. Purpose: To assess the performance of ChatGPT on radiology board-style examination questions without images and to explore its strengths and limitations.Materials and Methods: In this exploratory prospective study performed from February 25 to March 3, 2023, 150 multiple-choice ques-tions designed to match the style, content, and difficulty of the Canadian Royal College and American Board of Radiology examina-tions were grouped by question type (lower-order [recall, understanding] and higher-order [apply, analyze, synthesize] thinking) and topic (physics, clinical). The higher-order thinking questions were further subclassified by type (description of imaging findings, clinical management, application of concepts, calculation and classification, disease associations). ChatGPT performance was evaluated overall, by question type, and by topic. Confidence of language in responses was assessed. Univariable analysis was performed.Results: ChatGPT answered 69% of questions correctly (104 of 150). The model performed better on questions requiring lower-order thinking (84%, 51 of 61) than on those requiring higher-order thinking (60%, 53 of 89) (P = .002). When compared with lower-order questions, the model performed worse on questions involving description of imaging findings (61%, 28 of 46; P = .04), calculation and classification (25%, two of eight; P = .01), and application of concepts (30%, three of 10; P = .01). ChatGPT performed as well on higher-order clinical management questions (89%, 16 of 18) as on lower-order questions (P = .88). It performed worse on physics questions (40%, six of 15) than on clinical questions (73%, 98 of 135) (P = .02). ChatGPT used confident language consistently, even when incorrect (100%, 46 of 46).Conclusion: Despite no radiology-specific pretraining, ChatGPT nearly passed a radiology board-style examination without images; it performed well on lower-order thinking questions and clinical management questions but struggled with higher-order thinking questions involving description of imaging findings, calculation and classification, and application of concepts.	[Bhayana, Rajesh; Krishna, Satheesh; Bleakney, Robert R.] Univ Toronto, Toronto Gen Hosp, Univ Hlth Network, Mt Sinai Hosp & Womens CollHosp,Joint Dept Med Ima, 200 Elizabeth St, Peter Mulk Bldg, 1st Fl, Toronto, ON M5G 24C, Canada	University of Toronto; University Health Network Toronto; Toronto General Hospital	Bhayana, R (corresponding author), Univ Toronto, Toronto Gen Hosp, Univ Hlth Network, Mt Sinai Hosp & Womens CollHosp,Joint Dept Med Ima, 200 Elizabeth St, Peter Mulk Bldg, 1st Fl, Toronto, ON M5G 24C, Canada.	rajesh.bhayana@uhn.ca	Krishna, Satheesh/AGF-5005-2022; Li, Meng/JRY-4275-2023	Krishna, Satheesh/0000-0001-6603-7621; Bhayana, Rajesh/0000-0002-8352-7953				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], 2022, COMPUT HUMAN BEHAV, V128; [Anonymous], R: The R Project for Statistical Computing; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bloom BS., 2001, TAXONOMY LEARNING TE, DOI DOI 10.7771/1541-5015.1355; Certifying Exam, US; ChatGPTSpecial Radiology:AI Podcast Collaboration, US, DOI [10.1148/radiol.2212023.podcast/full/, DOI 10.1148/RADIOL.2212023.PODCAST/FULL]; Choi JH, 2303 CHATGPT GOES LA; DiSantis DJ, 2013, RADIOGRAPHICS, V33, P1865, DOI 10.1148/rg.337125749; Format of the Examination in Diagnostic Radiology, 2023, US; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Introducing ChatGPT, OpenAI; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jin D, 2020, Arxiv, DOI arXiv:2009.13081; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Needleman E, WOULD CHAT GPT GET W; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Qualifying (Core) Exam, US; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Rohrbach A, P 2018 C EMPIRICAL M; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; SAWIN EI, 1957, ELEM SCHOOL J, V57, P343, DOI 10.1086/459563; Senel S, 2015, PROCD SOC BEHV, V191, P925, DOI 10.1016/j.sbspro.2015.04.221; Shelmerdine SC, 2022, BMJ-BRIT MED J, V379, DOI 10.1136/bmj-2022-072826; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; The Doctor's Digital Path to Treatment, DOCT DIG PATH TREATM; Wang S., 2023, arXiv; Xiao YJ, 2021, Arxiv, DOI [arXiv:2103.15025, DOI 10.48550/ARXIV.2103.15025, 10.48550/arXiv.2103.15025]	30	105	106	37	56	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	JUN	2023	307	5							e230582	10.1148/radiol.230582	http://dx.doi.org/10.1148/radiol.230582			8	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	N7FI7	37191485				2024-07-03	WOS:001038622300007
J	Beheshti, M; Mahdiraji, HA; Rocha-Lona, L				Beheshti, Moein; Mahdiraji, Hannan Amoozad; Rocha-Lona, Luis			Transitioning drivers from linear to circular economic models: evidence of entrepreneurship in emerging nations	MANAGEMENT DECISION			English	Article; Early Access						Interpretive structural modelling (ISM); Cross-impact matrix multiplication approach applied to classification (MICMAC); Fuzzy sets; Linear economic models; Circular economic models	SUPPLY CHAINS; BARRIERS; OPPORTUNITIES; MARKETS; SECTOR	Purpose - Various publications have extensively documented the advantages of a circular economy in ensuring sustainability and limiting climate change. Despite academic records emphasising the need to adopt this business strategy, entrepreneurs in developing countries prefer linear economies. This reluctance is attributable to several factors, including insufficient infrastructure and technology, limited financial access, inadequate education systems and the prevalence of informal enterprises. Therefore, a thorough analysis of the underlying economic, political and social conditions is required to identify the drivers of circular economies (CEs) and their contribution to entrepreneurship in developing countries. Design/methodology/approach - In this study, the authors first conducted a comprehensive quantitative literature review based on LangChain to identify the critical CE drivers from the social, technological and organisational perspectives. Based on the input from the expert panel of Iranian academic and industry professionals, the authors applied an integrated fuzzy interpretive structural modelling and cross-impact matrix multiplication approach to classification (Fuzzy-ISM-MICMAC) to investigate the chronology of entrepreneurial drivers. Findings - Level-based model results reveal entrepreneurial drivers in developing nations and their interrelationships, specifically underlining the importance of supply chain factors and stakeholder preferences. Thus, the differences between the perception of the main drivers in developed and developing economies can be identified, with the former paying particular attention to legislative and financial factors. The study's findings contribute to conserving resources, reducing waste and adopting more sustainable corporate practices, thereby assisting developing countries in achieving development goals. Originality/value - This study employs an innovative quantitative systematic literature review approach that relies on a large language model to identify the drivers of the CE. Furthermore, it adopts a systematic approach to examine the enablers of the CE rather than a narrow and individual perspective of the entrepreneurial drivers. The study employs the fuzzy ISM MICMAC technique to showcase the prioritisation of entrepreneurial prospects in emerging economies.	[Beheshti, Moein] Masaryk Univ, Fac Econ & Adm, Brno, Czech Republic; [Mahdiraji, Hannan Amoozad] Univ Birmingham, Birmingham Business Sch, Birmingham, England; [Rocha-Lona, Luis] Inst Politecn Nacl, ESCA Santo Tomas, Mexico City, Mexico	Masaryk University Brno; University of Birmingham; Instituto Politecnico Nacional - Mexico	Mahdiraji, HA (corresponding author), Univ Birmingham, Birmingham Business Sch, Birmingham, England.	h.m.amoozad@bham.ac.uk	Beheshti, Moein/AAK-7337-2021; LONA, LUIS ROCHA/I-9183-2014; Amoozad Mahdiraji, Hannan/AAT-9996-2020	Beheshti, Moein/0000-0002-4525-5029; Amoozad Mahdiraji, Hannan/0000-0002-8382-6603				Aamer AM, 2022, J CLEAN PROD, V379, DOI 10.1016/j.jclepro.2022.134736; Aarikka-Stenroos L, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132413764; Abad-Segura E, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12145792; Agyemang M, 2019, MANAGE DECIS, V57, P971, DOI 10.1108/MD-11-2018-1178; Aranda-Usón A, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11030888; Baah C., 2021, Circ. Econ. Sustain, V2, DOI [10.1007/s43615- 021-00093-2, DOI 10.1007/S43615-021-00093-2]; Babatunde S, 2021, EDUC TRAIN, V63, P1092, DOI 10.1108/ET-12-2020-0368; Barros MV, 2021, CLEAN ENVIRON SYST, V2, DOI 10.1016/j.cesys.2020.100006; Bilal M, 2020, J CLEAN PROD, V276, DOI 10.1016/j.jclepro.2020.123250; Bist N, 2020, ENVIRON TECHNOL INNO, V20, DOI 10.1016/j.eti.2020.101054; Boyer RHW, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132212348; Buch R, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13168925; Cagno E, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083328; Cezarino LO, 2021, MANAGE DECIS, V59, P1841, DOI 10.1108/MD-10-2018-1084; Chamberlin L, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10062070; Chase, 2023, Longchain; Chaudhuri A, 2022, J BUS RES, V142, P32, DOI 10.1016/j.jbusres.2021.12.039; Chen WM, 2019, ENERG ENVIRON-UK, V30, P586, DOI 10.1177/0958305X19845759; Chowdhury RH, 2022, J SMALL BUS MANAGE, V60, P668, DOI 10.1080/00472778.2020.1726125; Cullen UA, 2021, RESOUR CONSERV RECY, V168, DOI 10.1016/j.resconrec.2020.105300; Hugo AD, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132112246; Del Giudice M, 2021, INT J LOGIST MANAG, V32, P337, DOI 10.1108/IJLM-03-2020-0119; Devkota N., 2022, Journal of International Studies, V15, P181; Dzogbenuku RK, 2019, ASIA PAC J INNOV ENT, V13, P168, DOI 10.1108/APJIE-12-2018-0072; Elf P, 2022, BUS STRATEG ENVIRON, V31, P2682, DOI 10.1002/bse.2999; Farooque M, 2019, SUPPLY CHAIN MANAG, V24, P677, DOI 10.1108/SCM-10-2018-0345; Ferronato N, 2019, J ENVIRON MANAGE, V230, P366, DOI 10.1016/j.jenvman.2018.09.095; Foroozanfar MH, 2022, J ENTREP EMERG ECON, V14, P678, DOI 10.1108/JEEE-10-2021-0411; Garcés-Ayerbe C, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16050851; Gedam VV, 2021, J CLEAN PROD, V311, DOI 10.1016/j.jclepro.2021.127670; Godinho M, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14052772; Gorane S. J., 2013, International Journal of Logistics Systems and Management, V16, P147; Govindan K, 2018, INT J PROD RES, V56, P278, DOI 10.1080/00207543.2017.1402141; Gue IHV, 2020, J CLEAN PROD, V276, DOI 10.1016/j.jclepro.2020.123204; Guldmann E, 2020, J CLEAN PROD, V243, DOI 10.1016/j.jclepro.2019.118160; Gusmerotti NM, 2019, J CLEAN PROD, V230, P314, DOI 10.1016/j.jclepro.2019.05.044; Haleem A, 2021, J IND INTEGR MANAG, V06, P107, DOI 10.1142/S2424862220500177; Hildenbrand J, 2021, RECYCLING-BASEL, V6, DOI 10.3390/recycling6040074; Hina M, 2022, J CLEAN PROD, V333, DOI 10.1016/j.jclepro.2021.130049; Hofmann F, 2020, BUS STRATEG ENVIRON, V29, P2770, DOI 10.1002/bse.2542; Hussain M, 2020, J CLEAN PROD, V256, DOI 10.1016/j.jclepro.2020.120375; Huynh PH, 2022, INT J PRODUCT PERFOR, V71, P870, DOI 10.1108/IJPPM-12-2020-0683; Huysveld S, 2019, J CLEAN PROD, V211, P1, DOI 10.1016/j.jclepro.2018.11.110; Hysa E, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12124831; Kaya DI, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13052479; Ilic MP, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14020702; Iqbal M, 2023, INT J GREEN ENERGY, V20, P265, DOI 10.1080/15435075.2022.2038609; Jabbour CJC, 2020, J ENVIRON MANAGE, V264, DOI 10.1016/j.jenvman.2020.110416; Jafari-Sadeghi V, 2021, J BUS RES, V134, P352, DOI 10.1016/j.jbusres.2021.05.027; Joensuu T, 2020, J CLEAN PROD, V276, DOI 10.1016/j.jclepro.2020.124215; Johl SK, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13116253; Jokar D, 2021, J CLEAN PROD, V320, DOI 10.1016/j.jclepro.2021.128712; Karamat J, 2018, SUSTAINABILITY-BASEL, V10, DOI 10.3390/su10114155; Kasmi F, 2022, J INNOV ECON MANAG, P173, DOI 10.3917/jie.039.0173; Katika Tina, 2022, Circ Econ Sustain, V2, P1077, DOI 10.1007/s43615-021-00137-7; Kayikci Y, 2022, J BUS RES, V149, P375, DOI 10.1016/j.jbusres.2022.05.042; Khaba S, 2021, TQM J, V33, P1281, DOI 10.1108/TQM-04-2020-0069; Khan EA, 2022, MANAGE DECIS, DOI 10.1108/MD-05-2022-0731; Khan W, 2023, J ENVIRON PLANN MAN, DOI 10.1080/09640568.2023.2189544; Kirchherr J, 2017, RESOUR CONSERV RECY, V127, P221, DOI 10.1016/j.resconrec.2017.09.005; Kiselev A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132212885; Klein N, 2022, CORP SOC RESP ENV MA, V29, P509, DOI 10.1002/csr.2215; Kouhizadeh M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081712; Kumar V, 2019, MANAGE DECIS, V57, P1067, DOI 10.1108/MD-09-2018-1070; Kumar V, 2020, INT J QUAL RELIAB MA, V37, P1007, DOI 10.1108/IJQRM-10-2019-0312; Kuzma Edson Luis, 2021, Prod., V31, pe20210008, DOI 10.1590/0103-6513.20210008; Lehmann C, 2022, J CLEAN PROD, V360, DOI 10.1016/j.jclepro.2022.132146; Lekawska-Andrinopoulou L, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13105668; Li YN, 2023, IND MANAGE DATA SYST, V123, P1178, DOI 10.1108/IMDS-05-2022-0267; Mahdiraji HA, 2022, BRIT FOOD J, V124, P1984, DOI 10.1108/BFJ-08-2021-0876; Manea DI, 2021, J BUS ECON MANAG, V22, P1342, DOI 10.3846/jbem.2021.15547; Maranesi C, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12229383; Mehmood A, 2021, BUS STRATEGY DEV, V4, P465, DOI 10.1002/bsd2.171; Chau MQ, 2021, ENERG SOURCE PART A, DOI 10.1080/15567036.2021.1994057; Mishra JL, 2021, MANAGE DECIS, V59, P1784, DOI 10.1108/MD-10-2018-1111; Mocanu C., 2022, Circular Economy and Sustainability, P71; Munaro MR, 2023, CLEAN RESPONS CONSUM, V8, DOI 10.1016/j.clrc.2023.100107; Murray A, 2017, J BUS ETHICS, V140, P369, DOI 10.1007/s10551-015-2693-2; Nandi S, 2021, SUSTAIN PROD CONSUMP, V27, P10, DOI 10.1016/j.spc.2020.10.019; Neligan A, 2023, BUS STRATEG ENVIRON, V32, P1175, DOI 10.1002/bse.3100; O'Grady T, 2021, RESOUR CONSERV RECY, V175, DOI 10.1016/j.resconrec.2021.105847; Olalekan R., 2019, MOJ Ecology & Environmental Sciences, V4, P114, DOI [DOI 10.15406/MOJES.2019.04.00142, 10.15406/mojes.2019.04.00142]; Ozili P.K., 2021, Circ. Econ. Sustain., V1, P787, DOI [10.1007/s43615-021-00043-y, DOI 10.1007/S43615-021-00043-Y]; Palafox-Alcantar PG, 2020, ENERGIES, V13, DOI 10.3390/en13071845; Pereno A, 2020, FUTURES, V122, DOI 10.1016/j.futures.2020.102605; Pîrvu R, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11154173; Qu DX, 2022, INT J INSTR, V15, P1, DOI 10.29333/iji.2022.1531a; Saura JR, 2022, MANAGE DECIS, DOI 10.1108/MD-02-2022-0190; Rani R, 2021, MULTIMED TOOLS APPL, V80, P3275, DOI 10.1007/s11042-020-09549-3; Rizos V, 2016, SUSTAINABILITY-BASEL, V8, DOI 10.3390/su8111212; Rodríguez-Espíndola O, 2022, INT J PROD ECON, V248, DOI 10.1016/j.ijpe.2022.108495; Rok B, 2021, CORP GOV-INT J BUS S, V21, P339, DOI 10.1108/CG-01-2020-0043; Sabharwal R, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00605-3; Salvioni D., 2020, Symphonya. Emerging Issues in Management, V1, P26, DOI [DOI 10.4468/2020.1.03SALVIONI.ALMICI, 10.4468/2020.1.03SALVIONI.ALMICI]; Shanker S, 2021, INT J SUSTAIN ENG, V14, P1269, DOI 10.1080/19397038.2020.1862351; Sharma N, 2022, INT J ORGAN ANAL, V30, P84, DOI 10.1108/IJOA-07-2020-2341; Singh SK, 2018, MANAGE DECIS, V56, P2, DOI 10.1108/MD-11-2017-1131; Srivastava A, 2022, ANN OPER RES, V315, P2115, DOI 10.1007/s10479-021-04072-6; Suchek N, 2021, BUS STRATEG ENVIRON, V30, P3686, DOI 10.1002/bse.2834; Sulaiman Z, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19042326; Svensson-Hoglund S, 2021, J CLEAN PROD, V288, DOI 10.1016/j.jclepro.2020.125488; Tan JV, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14031757; Le TT, 2022, MANAGE DECIS, DOI 10.1108/MD-02-2022-0150; Tura N, 2019, J CLEAN PROD, V212, P90, DOI 10.1016/j.jclepro.2018.11.202; Vafadarnikjoo A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12051934; van Boerdonk PJM, 2021, J CLEAN PROD, V282, DOI 10.1016/j.jclepro.2020.125375; Van Opstal W, 2023, J CLEAN PROD, V396, DOI 10.1016/j.jclepro.2023.136510; Veleva V, 2018, J CLEAN PROD, V188, P20, DOI 10.1016/j.jclepro.2018.03.196; Wackernagel M, 2017, FRONT ENERGY RES, V5, DOI 10.3389/fenrg.2017.00018; Wang GR, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13020640; Wilson M, 2022, MANAG ENVIRON QUAL, V33, P9, DOI 10.1108/MEQ-10-2020-0222; Wrålsen B, 2021, J CLEAN PROD, V317, DOI 10.1016/j.jclepro.2021.128393; Wu CY, 2021, SUSTAIN PROD CONSUMP, V26, P228, DOI 10.1016/j.spc.2020.10.009; Zarbà C, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13158350; Zhang BY, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132011514; Zhu Q, 2019, MANAGE DECIS, V57, P1108, DOI 10.1108/MD-06-2018-0639	116	0	0	32	41	EMERALD GROUP PUBLISHING LTD	Leeds	floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	0025-1747	1758-6070		MANAGE DECIS	Manag. Decis.	2023 SEP 28	2023										10.1108/MD-02-2023-0279	http://dx.doi.org/10.1108/MD-02-2023-0279		SEP 2023	23	Business; Management	Social Science Citation Index (SSCI)	Business & Economics	S6TN4					2024-07-03	WOS:001072473800001
C	Pandian, S; Ganguly, D; MacAvaney, S		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Pandian, Saran; Ganguly, Debasis; MacAvaney, Sean			Evaluating the Explainability of Neural Rankers	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		IR Evaluation; Neural Ranking Models; Explainability		Information retrieval models have witnessed a paradigm shift from unsupervised statistical approaches to feature-based supervised approaches to completely data-driven ones that make use of the pre-training of large language models. While the increasing complexity of the search models have been able to demonstrate improvements in effectiveness (measured in terms of relevance of top-retrieved results), a question worthy of a thorough inspection is - "how explainable are these models?", which is what this paper aims to evaluate. In particular, we propose a common evaluation platform to systematically evaluate the explainability of any ranking model (the explanation algorithm being identical for all the models that are to be evaluated). In our proposed framework, each model, in addition to returning a ranked list of documents, also requires to return a list of explanation units or rationales for each document. This meta-information from each document is then used to measure how locally consistent these rationales are as an intrinsic measure of interpretability - one that does not require manual relevance assessments. Additionally, as an extrinsic measure, we compute how relevant these rationales are by leveraging sub-document level relevance assessments. Our findings show a number of interesting observations, such as sentence-level rationales are more consistent, an increase in complexity mostly leads to less consistent explanations, and that interpretability measures offer a complementary dimension of evaluation of IR systems because consistency is not well-correlated with nDCG at top ranks.	[Pandian, Saran] Univ Illinois, Chicago, IL USA; [Ganguly, Debasis; MacAvaney, Sean] Univ Glasgow, Glasgow, Scotland	University of Illinois System; University of Illinois Chicago; University of Illinois Chicago Hospital; University of Glasgow	Ganguly, D (corresponding author), Univ Glasgow, Glasgow, Scotland.	spand43@uic.edu; Debasis.Ganguly@glasgow.ac.uk; Sean.Macavaney@glasgow.ac.uk						Anand A, 2022, Arxiv, DOI [arXiv:2211.02405, 10.48550/ARXIV.2211.02405]; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Craswell Nick, 2020, Overview of the TREC 2019 deep learning track; Dai ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1533, DOI 10.1145/3397271.3401204; Fernando ZT, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1005, DOI 10.1145/3331184.3331312; Jose KM, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2595, DOI 10.1145/3404835.3462784; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Li Jiwei, 2017, CoRR abs/1612.08220; Lin SC, 2021, REPL4NLP 2021: PROCEEDINGS OF THE 6TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P163; Lundberg SM, 2017, ADV NEUR IN, V30; Lyu LJ, 2023, LECT NOTES COMPUT SC, V13980, P653, DOI 10.1007/978-3-031-28244-7_41; MacAvaney S., 2022, ABNIRML: analyzing the behavior of neural IR models, DOI [10.1162/tacla00457, DOI 10.1162/TACLA00457]; Nguyen T., 2016, CEUR Workshop Proceedings, V1773; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Nogueira Rodrigo, 2019, From doc2query to docTTTTTquery"; Oramas Jose, 2019, INT C LEARN REPR; Pradeep R, 2021, Arxiv, DOI arXiv:2101.05667; Pradeep R, 2022, LECT NOTES COMPUT SC, V13185, P655, DOI 10.1007/978-3-030-99736-6_44; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Sen P, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4449, DOI 10.1145/3511808.3557637; Sen P, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2069, DOI 10.1145/3397271.3401286; Amiri SS, 2020, Arxiv, DOI arXiv:2011.09892; Tan JT, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1784, DOI 10.1145/3459637.3482420; Verma M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1281, DOI 10.1145/3331184.3331377; Xiong L, 2020, Arxiv, DOI arXiv:2007.00808; Yang M., 2019, arXiv, DOI DOI 10.48550/ARXIV.1907.09701; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang HT, 2020, INFORM RETRIEVAL J, V23, P1, DOI 10.1007/s10791-019-09361-0	29	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56065-1; 978-3-031-56066-8	LECT NOTES COMPUT SC			2024	14611						369	383		10.1007/978-3-031-56066-8_28	http://dx.doi.org/10.1007/978-3-031-56066-8_28			15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EA		Green Submitted			2024-07-03	WOS:001211834200028
J	Harada, Y; Suzuki, T; Harada, T; Sakamoto, T; Ishizuka, K; Miyagami, T; Kawamura, R; Kunitomo, K; Nagano, H; Shimizu, T; Watari, T				Harada, Yukinori; Suzuki, Tomoharu; Harada, Taku; Sakamoto, Tetsu; Ishizuka, Kosuke; Miyagami, Taiju; Kawamura, Ren; Kunitomo, Kotaro; Nagano, Hiroyuki; Shimizu, Taro; Watari, Takashi			Performance evaluation of ChatGPT in detecting diagnostic errors and their contributing factors: an analysis of 545 case reports of diagnostic errors	BMJ OPEN QUALITY			English	Article						Chart review methodologies; Diagnostic errors; Artificial Intelligence		Background Manual chart review using validated assessment tools is a standardised methodology for detecting diagnostic errors. However, this requires considerable human resources and time. ChatGPT, a recently developed artificial intelligence chatbot based on a large language model, can effectively classify text based on suitable prompts. Therefore, ChatGPT can assist manual chart reviews in detecting diagnostic errors. Objective This study aimed to clarify whether ChatGPT could correctly detect diagnostic errors and possible factors contributing to them based on case presentations. Methods We analysed 545 published case reports that included diagnostic errors. We imputed the texts of case presentations and the final diagnoses with some original prompts into ChatGPT (GPT-4) to generate responses, including the judgement of diagnostic errors and contributing factors of diagnostic errors. Factors contributing to diagnostic errors were coded according to the following three taxonomies: Diagnosis Error Evaluation and Research (DEER), Reliable Diagnosis Challenges (RDC) and Generic Diagnostic Pitfalls (GDP). The responses on the contributing factors from ChatGPT were compared with those from physicians. Results ChatGPT correctly detected diagnostic errors in 519/545 cases (95%) and coded statistically larger numbers of factors contributing to diagnostic errors per case than physicians: DEER (median 5 vs 1, p<0.001), RDC (median 4 vs 2, p<0.001) and GDP (median 4 vs 1, p<0.001). The most important contributing factors of diagnostic errors coded by ChatGPT were 'failure/delay in considering the diagnosis' (315, 57.8%) in DEER, 'atypical presentation' (365, 67.0%) in RDC, and 'atypical presentation' (264, 48.4%) in GDP. Conclusion ChatGPT accurately detects diagnostic errors from case presentations. ChatGPT may be more sensitive than manual reviewing in detecting factors contributing to diagnostic errors, especially for 'atypical presentation'.	[Harada, Yukinori; Harada, Taku; Sakamoto, Tetsu; Kawamura, Ren; Shimizu, Taro] Dokkyo Med Univ, Dept Diagnost & Generalist Med, Shimotsuga, Tochigi, Japan; [Suzuki, Tomoharu] Urasoe Gen Hosp, Urasoe, Okinawa, Japan; [Harada, Taku] Nerima Hikarigaoka Hosp, Nerima Ku, Tokyo, Japan; [Ishizuka, Kosuke] Yokohama City Univ, Sch Med, Grad Sch Med, Yokohama, Kanagawa, Japan; [Miyagami, Taiju] Juntendo Univ, Fac Med, Dept Gen Med, Bunkyo Ku, Tokyo, Japan; [Kunitomo, Kotaro] NHO Kumamoto Med Ctr, Kumamoto, Kumamoto, Japan; [Nagano, Hiroyuki] Tenri Hosp, Dept Gen Internal Med, Tenri, Nara, Japan; [Watari, Takashi] Kyoto Univ Hosp, Integrated Clin Educ Ctr, Kyoto, Japan	Dokkyo Medical University; Yokohama City University; Juntendo University; Tenri Hospital; Kyoto University	Harada, Y (corresponding author), Dokkyo Med Univ, Dept Diagnost & Generalist Med, Shimotsuga, Tochigi, Japan.	yuki.gym23@gmail.com		Ishizuka, Kosuke/0000-0003-4313-6592; Miyagami, Taiju/0000-0002-4893-2224				Bradford A, 2022, J PATIENT SAF, V18, P521, DOI 10.1097/PTS.0000000000001006; Chen QJ, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad557; Chen TC, 2023, WORLD NEUROSURG, V179, pE342, DOI 10.1016/j.wneu.2023.08.088; Branson CF, 2021, BMJ QUAL SAF, V30, P1002, DOI 10.1136/bmjqs-2020-012456; Giardina TD, 2022, J GEN INTERN MED, V37, P3965, DOI 10.1007/s11606-022-07554-w; Goyder CR, 2015, BRIT J GEN PRACT, V65, pE838, DOI 10.3399/bjgp15X687889; Harada Y, 2023, DIAGNOSIS, V10, P329, DOI 10.1515/dx-2023-0030; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kostopoulou O, 2008, FAM PRACT, V25, P400, DOI 10.1093/fampra/cmn071; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lane KP, 2019, J HOSP MED, V14, P622, DOI 10.12788/jhm.3262; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Mahajan P, 2021, DIAGNOSIS, V8, P340, DOI 10.1515/dx-2020-0122; Matulis JC, 2020, DIAGNOSIS, V7, P107, DOI 10.1515/dx-2019-0070; Meyer AND, 2019, JAMA-J AM MED ASSOC, V321, P737, DOI 10.1001/jama.2019.0113; Murphy DR, 2019, BMJ QUAL SAF, V28, P151, DOI 10.1136/bmjqs-2018-008086; Newman-Toker DE, 2021, DIAGNOSIS, V8, P67, DOI 10.1515/dx-2019-0104; Newman-Toker DE., 2022, Agency for Healthcare Research and Quality (AHRQ), DOI [10.23970/AHRQEPCCER258, DOI 10.23970/AHRQEPCCER258]; Perry MF, 2021, J PEDIATR-US, V232, P257, DOI 10.1016/j.jpeds.2020.11.065; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Schiff GD, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2021.44531; Schiff GD, 2012, BMJ QUAL SAF, V21, P89, DOI 10.1136/bmjqs-2011-000590; Schiff GD, 2009, ARCH INTERN MED, V169, P1881, DOI 10.1001/archinternmed.2009.333; Shea YF, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.25000; Singh H, 2021, DIAGNOSIS, V8, P51, DOI 10.1515/dx-2020-0045; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; ten Berg H, 2024, ANN EMERG MED, V83, P83, DOI 10.1016/j.annemergmed.2023.08.003	29	0	0	2	2	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND		2399-6641		BMJ OPEN QUAL	BMJ Open Qual.	JUN	2024	13	2							e002654	10.1136/bmjoq-2023-002654	http://dx.doi.org/10.1136/bmjoq-2023-002654			8	Health Care Sciences & Services; Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; General & Internal Medicine	TE0O7	38830730	gold			2024-07-03	WOS:001239470200005
J	Tan, RES; Teo, WZW; Puhaindran, ME				Tan, Ruth En Si; Teo, Wendy Zi Wei; Puhaindran, Mark E.			Artificial Intelligence in Hand Surgery - How Generative AI is Transforming the Hand Surgery Landscape	JOURNAL OF HAND SURGERY-ASIAN-PACIFIC VOLUME			English	Review						Artificial intelligence; Hand surgery; Electronic medical records system; Patient care; Education		Artificial intelligence (AI) has witnessed significant advancements, reshaping various industries, including healthcare. The introduction of ChatGPT by OpenAI in November 2022 marked a pivotal moment, showcasing the potential of generative AI in revolutionising patient care, diagnosis and treatment. Generative AI, unlike traditional AI systems, possesses the ability to generate new content by understanding patterns within datasets. This article explores the evolution of AI in healthcare, tracing its roots to the term coined by John McCarthy in 1955 and the contributions of pioneers like John Von Neumann and Alan Turing. Currently, generative AI, particularly Large Language Models, holds promise across three broad categories in healthcare: patient care, education and research. In patient care, it offers solutions in clinical document management, diagnostic support and operative planning. Notable advancements include Microsoft's collaboration with Epic for integrating AI into electronic medical records (EMRs), enhancing clinical data management and patient care. Furthermore, generative AI aids in surgical decision-making, as demonstrated in plastic, orthopaedic and hepatobiliary surgeries. However, challenges such as bias, hallucination and integration with EMR systems necessitate caution and ongoing evaluation. The article also presents insights from the implementation of NUHS Russell-GPT, a generative AI chatbot, in a hand surgery department, showcasing its utility in administrative tasks but highlighting challenges in surgical planning and EMR integration. The survey showed unanimous support for incorporating AI into clinical settings, with all respondents being open to its use. In conclusion, generative AI is poised to enhance patient care and ease physician workloads, starting with automating administrative tasks and evolving to inform diagnoses, tailored treatment plans, as well as aid in surgical planning. As healthcare systems navigate the complexities of integrating AI, the potential benefits for both physicians and patients remain significant, offering a glimpse into a future where AI transforms healthcare delivery.Level of Evidence: Level V (Diagnostic)	[Tan, Ruth En Si; Teo, Wendy Zi Wei; Puhaindran, Mark E.] Natl Univ Singapore Hosp, Dept Hand & Reconstruct Microsurg, Singapore, Singapore; [Tan, Ruth En Si] Natl Univ Hlth Syst, Dept Hand & Reconstruct Microsurg, Level 11 Tower Block 1E Kent Ridge Rd, Singapore 119228, Singapore	National University of Singapore; National University of Singapore	Tan, RES (corresponding author), Natl Univ Hlth Syst, Dept Hand & Reconstruct Microsurg, Level 11 Tower Block 1E Kent Ridge Rd, Singapore 119228, Singapore.							Boyd E., 2023, The Official Microsoft Blog . August 22; Briceño J, 2022, HEPATOB PANCREAT DIS, V21, P347, DOI 10.1016/j.hbpd.2022.03.001; Cascella M, 2024, J MED SYST, V48, DOI 10.1007/s10916-024-02045-3; Cheng KM, 2023, ANN BIOMED ENG, V51, P1366, DOI 10.1007/s10439-023-03207-z; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Crook BS, 2023, J HAND SURG-AM, V48, P1122, DOI 10.1016/j.jhsa.2023.08.003; Dhar S, 2024, INT J PEDIATR OTORHI, V179, DOI 10.1016/j.ijporl.2024.111901; Gajjar Avi A, 2024, Neurosurgery, DOI 10.1227/neu.0000000000002856; Ghanem YK, 2024, SURG ENDOSC, V38, P2887, DOI 10.1007/s00464-024-10739-5; Gupta A, 2022, J EDUC HEALTH PROMOT, V11, DOI 10.4103/jehp.jehp_625_21; Gutierrez L, 2022, EYE VISION, V9, DOI 10.1186/s40662-021-00273-z; Jindal JA, 2024, J AM MED INFORM ASSN, V31, DOI 10.1093/jamia/ocae043; Kane R., 2023, Zapier; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Leypold T, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005471; Mittermaier M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00858-z; Pinto VBP, 2024, NEUROUROL URODYNAM, V43, P935, DOI 10.1002/nau.25442; Raza MM, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-023-00988-4; Reynolds Kelly, 2024, JMIR Dermatol, V7, pe48451, DOI 10.2196/48451; Venkatesh KP, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00694-7; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zhao GH, 2024, FRONT ONCOL, V14, DOI 10.3389/fonc.2024.1345810	22	0	0	6	6	WORLD SCIENTIFIC PUBL CO PTE LTD	SINGAPORE	5 TOH TUCK LINK, SINGAPORE 596224, SINGAPORE	2424-8355	2424-8363		J HAND SURG-ASIAN-PA	J. Hand Surg.-Asian Pac.-Vol.	APR	2024	29	02					81	87		10.1142/S2424835524300019	http://dx.doi.org/10.1142/S2424835524300019			7	Surgery	Emerging Sources Citation Index (ESCI)	Surgery	MN6V0	38553849				2024-07-03	WOS:001194349000008
J	Yaneva, V; Baldwin, P; Jurich, DP; Swygert, K; Clauser, BE				Yaneva, Victoria; Baldwin, Peter; Jurich, Daniel P.; Swygert, Kimberly; Clauser, Brian E.			Examining ChatGPT Performance on USMLE Sample Items and Implications for Assessment	ACADEMIC MEDICINE			English	Article							ARTIFICIAL-INTELLIGENCE	Purpose In late 2022 and early 2023, reports that ChatGPT could pass the United States Medical Licensing Examination (USMLE) generated considerable excitement, and media response suggested ChatGPT has credible medical knowledge. This report analyzes the extent to which an artificial intelligence (AI) agents performance on these sample items can generalize to performance on an actual USMLE examination and an illustration is given using ChatGPT. Method As with earlier investigations, analyses were based on publicly available USMLE sample items. Each item was submitted to ChatGPT (version 3.5) 3 times to evaluate stability. Responses were scored following rules that match operational practice, and a preliminary analysis explored the characteristics of items that ChatGPT answered correctly. The study was conducted between February and March 2023. Results For the full sample of items, ChatGPT scored above 60% correct except for one replication for Step 3. Response success varied across replications for 76 items (20%). There was a modest correspondence with item difficulty wherein ChatGPT was more likely to respond correctly to items found easier by examinees. ChatGPT performed significantly worse (P < .001) on items relating to practice-based learning. Conclusions Achieving 60% accuracy is an approximate indicator of meeting the passing standard, requiring statistical adjustments for comparison. Hence, this assessment can only suggest consistency with the passing standards for Steps 1 and 2 Clinical Knowledge, with further limitations in extrapolating this inference to Step 3. These limitations are due to variances in item difficulty and exclusion of the simulation component of Step 3 from the evaluationlimitations that would apply to any AI system evaluated on the Step 3 sample items. It is crucial to note that responses from large language models exhibit notable variations when faced with repeated inquiries, underscoring the need for expert validation to ensure their utility as a learning tool.	[Yaneva, Victoria] Natl Board Med Examiners, Off Res Strategy, Nat Language Proc Res, Philadelphia, PA USA; [Baldwin, Peter; Clauser, Brian E.] Natl Board Med Examiners, Off Res Strategy, Philadelphia, PA USA; [Jurich, Daniel P.] Natl Board Med Examiners, US Med Licensing Examinat, Philadelphia, PA USA; [Swygert, Kimberly] Natl Board Med Examiners, Test Dev Innovat, Philadelphia, PA USA		Yaneva, V (corresponding author), Natl Board Med Examiners, 3750 Market St, Philadelphia, PA 19104 USA.	vyaneva@nbme.org; pbaldwin@nbme.org; djurich@nbme.org; kswygert@nbme.org; bclauser@nbme.org		Swygert, Kimberly/0000-0003-3357-1603	National Board of Medical Examiners	National Board of Medical Examiners	All work on the research and manuscript was completed while the authors were employees of the National Board of Medical Examiners.	Angoff W.H., 1971, ED MEASUREMENT, V2nd, P508; Ault A., 2018, MEDSCAPE; Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; DePeau-Wilson M., MEDPAGE TODAY; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lievin V., ARXIV; Margolis MJ., PRACTICAL GUIDE EVAL; OpenAI, 2023, ArXiv; Rogers A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560260; Singhal K., ARXIV; United States Medical Licensing Examination, USMLE PHYS TASK COMP; United States Medical Licensing Examination, SOCIAL CAPITAL E EUR; USMLE Score Interpretation Guidelines, US; Yasunaga M., ARXIV	18	1	1	7	7	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	1040-2446	1938-808X		ACAD MED	Acad. Med.	FEB	2024	99	2					192	197		10.1097/ACM.0000000000005549	http://dx.doi.org/10.1097/ACM.0000000000005549			6	Education, Scientific Disciplines; Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Health Care Sciences & Services	HE9G7	37934828	hybrid			2024-07-03	WOS:001157928900009
C	Huo, SQ; Arabzadeh, N; Clarke, CLA			ACM	Huo, Siqing; Arabzadeh, Negar; Clarke, Charles L. A.			Retrieving Supporting Evidence for Generative Question Answering	ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL IN THE ASIA PACIFIC REGION, SIGIR-AP 2023			English	Proceedings Paper	1st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region (SIGIR-AP)	NOV 26-28, 2023	Beijing, PEOPLES R CHINA	Assoc Comp Machinery, ACM SIGIR, Xiaohongshu, Zhipu AI, Kuaishou				Current large language models (LLMs) can exhibit near-human levels of performance on many natural language-based tasks, including open-domain question answering. Unfortunately, at this time, they also convincingly hallucinate incorrect answers, so that responses to questions must be verified against external sources before they can be accepted at face value. In this paper, we report two simple experiments to automatically validate generated answers against a corpus. We base our experiments on questions and passages from the MS MARCO (V1) test collection, and a retrieval pipeline consisting of sparse retrieval, dense retrieval and neural rerankers. In the first experiment, we validate the generated answer in its entirety. After presenting a question to an LLM and receiving a generated answer, we query the corpus with the combination of the question + generated answer. We then present the LLM with the combination of the question + generated answer + retrieved answer, prompting it to indicate if the generated answer can be supported by the retrieved answer. In the second experiment, we consider the generated answer at a more granular level, prompting the LLM to extract a list of factual statements from the answer and verifying each statement separately. We query the corpus with each factual statement and then present the LLM with the statement and the corresponding retrieved evidence. The LLM is prompted to indicate if the statement can be supported and make necessary edits using the retrieved material. With an accuracy of over 80%, we find that an LLM is capable of verifying its generated answer when a corpus of supporting material is provided. However, manual assessment of a random sample of questions reveals that incorrect generated answers are missed by this verification process. While this verification process can reduce hallucinations, it can not entirely eliminate them.	[Huo, Siqing; Arabzadeh, Negar; Clarke, Charles L. A.] Univ Waterloo, Waterloo, ON, Canada	University of Waterloo	Huo, SQ (corresponding author), Univ Waterloo, Waterloo, ON, Canada.	siqing.huo.canada@gmail.com; narabzad@uwaterloo.ca; claclark@gmail.com	Arabzadeh, Negar/IUM-8036-2023	Arabzadeh, Negar/0000-0002-4411-7089; Clarke, Charles/0000-0001-8178-9194				Amati G, 2004, LECT NOTES COMPUT SC, V2997, P127; Azad HK, 2019, INFORM PROCESS MANAG, V56, P1698, DOI 10.1016/j.ipm.2019.05.009; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bodner Richard C, 1996, Knowledge-based approaches to query expansion in information retrieval; Bohnet B, 2023, Arxiv, DOI arXiv:2212.08037; Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390; Chen Jifan, 2022, P 2022 C EMP METH NA, P3495; Clinchant S., 2019, arXiv; Das Souvik, 2023, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dziri N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5271; Feldman P, 2023, Arxiv, DOI arXiv:2306.06085; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Formal Thibault, 2021, Splade v2: Sparse lexical and expansion model for information retrieval; Gao LY, 2022, Arxiv, DOI arXiv:2210.08726; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Karpukhin V, 2020, Arxiv, DOI [arXiv:2004.04906, 10.48550/arXiv.2004.04906]; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lin J., 2021, arXiv; Liu Y, 2019, arXiv; Longpre S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7052; Miller D, 2019, Arxiv, DOI [arXiv:1906.04165, DOI 10.48550/ARXIV.1906.04165]; Min SW, 2023, Arxiv, DOI arXiv:2305.14251; Nguyen Tri, 2016, choice, V2640, P660; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Pradeep R, 2021, Arxiv, DOI arXiv:2101.05667; Radford A., 2018, IMPROVING LANGUAGE U; Rashkin H, 2022, Arxiv, DOI [arXiv:2112.12870, 10.48550/arXiv.2112.12870]; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Sanderson M, 2012, P IEEE, V100, P1444, DOI 10.1109/JPROC.2012.2189916; Thakur Nandan, 2021, 35 C NEURAL INFORM P; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang ZG, 2019, Arxiv, DOI arXiv:1908.08167; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wright D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2448; Xiong L, 2020, Arxiv, DOI arXiv:2007.00808; Yang W, 2019, Arxiv, DOI arXiv:1902.01718; Yu S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P829, DOI 10.1145/3404835.3462856; Yue X, 2023, Arxiv, DOI arXiv:2305.06311; Zhu JH, 2020, Arxiv, DOI arXiv:2002.06823; Zighelnic Liron, 2008, P 31 ANN INT ACM SIG, P825, DOI [10.1145/1390334, DOI 10.1145/1390334]	42	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0408-6				2023							11	20		10.1145/3624918.3625336	http://dx.doi.org/10.1145/3624918.3625336			10	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2NW		Green Submitted			2024-07-03	WOS:001122582700002
J	Gonzalez-Garcia, L; González-Carreño, G; Machota, AMR; Fernández-Vega, JP				Gonzalez-Garcia, Lino; Gonzalez-Carreno, Gema; Machota, Ana Maria Rivas; Fernandez-Vega, Juan Padilla			Enhancing knowledge graphs with microdata and LLMs: the case of Schema.org and Wikidata in touristic information	ELECTRONIC LIBRARY			English	Article						Knowledge graphs; Wikidata; CommonCrawl; Microdata; Schema.org; Large language models	WEB	PurposeKnowledge graphs (KGs) are structured knowledge bases that represent real-world entities and are used in a variety of applications. Many of them are created and curated from a combination of automated and manual processes. Microdata embedded in Web pages for purposes of facilitating indexing and search engine optimization are a potential source to augment KGs under some assumptions of complementarity and quality that have not been thoroughly explored to date. In that direction, this paper aims to report results on a study that evaluates the potential of using microdata extracted from the Web to augment the large, open and manually curated Wikidata KG for the domain of touristic information. As large corpora of Web text is currently being leveraged via large language models (LLMs), these are used to compare the effectiveness of the microdata enhancement method.Design/methodology/approachThe Schema.org taxonomy was used as the source to determine the annotation types to be collected. Here, the authors focused on tourism-related pages as a case study, selecting the relevant Schema.org concepts as point of departure. The large CommonCrawl resource was used to select those annotations from a large recent sample of the World Wide Web. The extracted annotations were processed and matched with Wikidata to estimate the degree to which microdata produced for SEO might become a valuable resource to complement KGs or vice versa. The Web pages themselves can also serve as a context to produce additional metadata elements using them as context in pipelines of an existing LLMs. That way, both the annotations and the contents itself can be used as sources.FindingsThe samples extracted revealed a concentration of metadata annotations in only a few of the relevant Schema.org attributes and also revealed the possible influence of authoring tools in a significant fraction of microdata produced. The analysis of the overlapping of attributes in the sample with those of Wikidata showed the potential of the technique, limited by the disbalance of the presence of attributes. The combination of those with the use of LLMs to produce additional annotations demonstrates the feasibility of the approach in the population of existing Wikidata locations. However, in both cases, the effectiveness appears to be lower in the cases of less content in the KG, which are arguably the most relevant when considering the scenario of an automated population approach.Originality/valueThe research reports novel empirical findings on the way touristic annotations with a SEO orientation are being produced in the wild and provides an assessment of their potential to complement KGs, or reuse information from those graphs. It also provides insights on the potential of using LLMs for the task.	[Gonzalez-Garcia, Lino; Gonzalez-Carreno, Gema; Machota, Ana Maria Rivas; Fernandez-Vega, Juan Padilla] Univ Camilo Jose Cela, Dept Tecnol & Ciencia, Madrid, Spain; [Gonzalez-Garcia, Lino] Univ Alcala, Dept Comp Sci, Alcala De Henares, Spain	Camilo Jose Cela University; Universidad de Alcala	Gonzalez-Garcia, L (corresponding author), Univ Camilo Jose Cela, Dept Tecnol & Ciencia, Madrid, Spain.; Gonzalez-Garcia, L (corresponding author), Univ Alcala, Dept Comp Sci, Alcala De Henares, Spain.	linogonzgar@gmail.com						Abbasi BUD, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1163; Balci B.T., 2018, E REV TOURISM RES; Caufield J.H., 2023, ARXIV; Dash S, 2021, INFORMATION, V12, DOI 10.3390/info12080316; Guha RV, 2016, COMMUN ACM, V59, P44, DOI 10.1145/2844544; Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3418294, 10.1145/3447772]; Hao S., 2022, ARXIV; Hu E.J., 2021, ARXIV; Iliadis A, 2023, J ASSOC INF SCI TECH, DOI 10.1002/asi.24744; Jiang Z., 2020, ARXIV; Kanza S, 2018, LECT NOTES COMPUT SC, V10843, P335, DOI 10.1007/978-3-319-93417-4_22; Katumba S, 2017, ISPRS INT J GEO-INF, V6, DOI 10.3390/ijgi6090284; Krle E., 2016, INFORM COMMUNICATION, P99, DOI DOI 10.1007/978-3-319-28231-2; Meusel R., 2015, P 5 INT C WEB INT MI, P1; Meusel R, 2014, LECT NOTES COMPUT SC, V8796, P277, DOI 10.1007/978-3-319-11964-9_18; Mora-Cantallops M, 2019, DATA TECHNOL APPL, V53, P250, DOI 10.1108/DTA-12-2018-0110; Omeliyanenko J, 2020, LECT NOTES COMPUT SC, V12506, P456, DOI 10.1007/978-3-030-62419-4_26; Pan S., 2024, IEEE T KNOWL DATA EN; Panasiuk O, 2018, LECT NOTES COMPUT SC, V11155, P137, DOI 10.1007/978-3-319-98192-5_26; Paulheim H, 2017, SEMANT WEB, V8, P489, DOI 10.3233/SW-160218; Petroni F., 2019, ARXIV; Roa-Valverde AJ, 2014, INFORM RETRIEVAL, V17, P295, DOI 10.1007/s10791-014-9240-0; Sicilia M.-A., 2006, International Journal of Metadata, Semantics and Ontologies, V1, P83, DOI 10.1504/IJMSO.2006.008773; Tanon TP, 2020, LECT NOTES COMPUT SC, V12123, P583, DOI 10.1007/978-3-030-49461-2_34; Wallis R., 2017, CODE4LIB J; Wang C., 2020, ARXIV	26	0	0	2	2	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	0264-0473	1758-616X		ELECTRON LIBR	Electron. Libr.	JUN 27	2024	42	3			SI		443	454		10.1108/EL-06-2023-0160	http://dx.doi.org/10.1108/EL-06-2023-0160		MAY 2024	12	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	WF1Q9					2024-07-03	WOS:001233321300001
J	Polak, MP; Modi, S; Latosinska, A; Zhang, JM; Wang, CW; Wang, SN; Hazra, AD; Morgan, D				Polak, Maciej P.; Modi, Shrey; Latosinska, Anna; Zhang, Jinming; Wang, Ching-Wen; Wang, Shaonan; Hazra, Ayan Deep; Morgan, Dane			Flexible, model-agnostic method for materials data extraction from text using general purpose language models	DIGITAL DISCOVERY			English	Article								Accurate and comprehensive material databases extracted from research papers are crucial for materials science and engineering, but their development requires significant human effort. With large language models (LLMs) transforming the way humans interact with text, LLMs provide an opportunity to revolutionize data extraction. In this study, we demonstrate a simple and efficient method for extracting materials data from full-text research papers leveraging the capabilities of LLMs combined with human supervision. This approach is particularly suitable for mid-sized databases and requires minimal to no coding or prior knowledge about the extracted property. It offers high recall and nearly perfect precision in the resulting database. The method is easily adaptable to new and superior language models, ensuring continued utility. We show this by evaluating and comparing its performance on GPT-3 and GPT-3.5/4 (which underlie ChatGPT), as well as free alternatives such as BART and DeBERTaV3. We provide a detailed analysis of the method's performance in extracting sentences containing bulk modulus data, achieving up to 90% precision at 96% recall, depending on the amount of human effort involved. We further demonstrate the method's broader effectiveness by developing a database of critical cooling rates for metallic glasses over twice the size of previous human curated databases. This study presents an efficient language model-based method for high-precision data extraction from text, requiring minimal human effort.	[Polak, Maciej P.; Modi, Shrey; Latosinska, Anna; Zhang, Jinming; Wang, Ching-Wen; Wang, Shaonan; Hazra, Ayan Deep; Morgan, Dane] Univ Wisconsin Madison, Dept Mat Sci & Engn, Madison, WI 53706 USA	University of Wisconsin System; University of Wisconsin Madison	Polak, MP; Morgan, D (corresponding author), Univ Wisconsin Madison, Dept Mat Sci & Engn, Madison, WI 53706 USA.	mppolak@wisc.edu; ddmorgan@wisc.edu		Modi, Shrey/0009-0002-4189-0997	National Science Foundation [1931298, 2017072]; National Science Foundation Cyberinfrastructure for Sustained Scientific Innovation	National Science Foundation(National Science Foundation (NSF)); National Science Foundation Cyberinfrastructure for Sustained Scientific Innovation	The research in this work was primarily supported by the National Science Foundation Cyberinfrastructure for Sustained Scientific Innovation (CSSI) Award No. 1931298. Additional support for engaging undergraduates in research was provided by the National Science Foundation Training-based Workforce Development for Advanced Cyberinfrastructure (CyberTraining) Award No. 2017072. We thank Shishmitha Adusumilli, Harmon Bhasin, and Shanchao Liang for their participation in this project.	Afflerbach BT, 2022, CHEM MATER, V34, P2945, DOI 10.1021/acs.chemmater.1c03542; Ansari M., 2023, ARXIV; Beard EJ, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01355-w; Behnel S., 2005, lxml: Xml and html with python; Bird S., 2009, NATURAL LANGUAGE PRO; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Choudhary K, 2023, J PHYS CHEM C, V127, P17545, DOI 10.1021/acs.jpcc.3c03106; Conneau A, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1699; Court CJ, 2020, NPJ COMPUT MATER, V6, DOI 10.1038/s41524-020-0287-8; Dagdelen J, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-45563-x; Dong QY, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01294-6; elsevier, ELSEVIER DEVELOPER P; Georgescu AB, 2021, CHEM MATER, V33, P5591, DOI 10.1021/acs.chemmater.1c00905; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; He P., 2021, ARXIV; Hiszpanski AM, 2020, J CHEM INF MODEL, V60, P2876, DOI 10.1021/acs.jcim.0c00199; Huo HY, 2022, CHEM MATER, V34, P7323, DOI 10.1021/acs.chemmater.2c01293; Isayev O, 2019, NATURE, V571, P42, DOI 10.1038/d41586-019-01978-x; Isazawa T, 2022, J CHEM INF MODEL, V62, P1207, DOI 10.1021/acs.jcim.1c01199; Jensen Z, 2019, ACS CENTRAL SCI, V5, P892, DOI 10.1021/acscentsci.9b00193; Jessop DM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-41; Karpovich C., 2021, ARXIV; Kim E, 2020, J CHEM INF MODEL, V60, P1194, DOI 10.1021/acs.jcim.9b00995; Kim E, 2017, CHEM MATER, V29, P9436, DOI 10.1021/acs.chemmater.7b03500; Kononova O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102155; Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1; Krallinger M, 2017, CHEM REV, V117, P7673, DOI 10.1021/acs.chemrev.6b00851; Kumar P, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01301-w; Lewis Mike, 2020, P 58 ANN M ASS COMP; Lla J., 2023, ARXIV; Mavracic J, 2021, J CHEM INF MODEL, V61, P4280, DOI 10.1021/acs.jcim.1c00446; Midjourney, ABOUT US; Miret S., 2024, ARXIV; Morgan Dane, 2020, Annual Review of Materials Research, V50, P71, DOI 10.1146/annurev-matsci-070218-010015; Mosqueira-Rey E, 2023, ARTIF INTELL REV, V56, P3005, DOI 10.1007/s10462-022-10246-w; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Ouyang L., 2022, ARXIV; Polak M. P., 2023, DATA FLEXIBLE MODEL, DOI [10.6084/m9.figshare.21861948.v5, DOI 10.6084/M9.FIGSHARE.21861948.V5]; Polak MP, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-45914-8; Ramesh Aditya, 2022, arXiv; Ray P. J., 2016, THESIS U COPENHAGEN, P2; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saal JE, 2020, ANNU REV MATER RES, V50, P49, DOI 10.1146/annurev-matsci-090319-010954; Sierepeklis O, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01752-1; Song Y., 2023, FINDINGS ASS COMPUTA; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Touvron H., 2023, arXiv; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Wang ZR, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01317-2; Weston L, 2019, J CHEM INF MODEL, V59, P3692, DOI 10.1021/acs.jcim.9b00470; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2022, ARXIV; Yin W., 2019, ARXIV; Zhang S., 2022, ARXIV; Zhao JY, 2022, J CHEM INF MODEL, V62, P2670, DOI 10.1021/acs.jcim.2c00253; Zhao JY, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01295-5; Zhao X., 2021, FINE TUNING BERT MOD	58	0	0	1	1	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2635-098X		DIGIT DISCOV	Digit. Discov.	JUN 12	2024	3	6					1221	1235		10.1039/d4dd00016a	http://dx.doi.org/10.1039/d4dd00016a		MAY 2024	15	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Chemistry; Computer Science	TW0R6		gold, Green Submitted			2024-07-03	WOS:001235564500001
C	Guo, ZX; Wang, TJJ; Pehlivan, S; Radman, A; Laaksonen, J			ACM	Guo, Zixin; Wang, Tzu-Jui Julius; Pehlivan, Selen; Radman, Abduljalil; Laaksonen, Jorma			PiTL: Cross-modal Retrieval with Weakly-supervised Vision-language Pre-training via Prompting	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Vision-language Retrieval; Pre-training; Knowledge Prompting		Vision-language (VL) Pre-training (VLP) has shown to well generalize VL models over a wide range of VL downstream tasks, especially for cross-modal retrieval. However, it hinges on a huge amount of image-text pairs, which requires tedious and costly curation. On the contrary, weakly-supervised VLP (W-VLP) [33] explores means with object tags generated by a pre-trained object detector (OD) from images. Yet, they still require paired information, i.e. images and object-level annotations, as supervision to train an OD. To further reduce the amount of supervision, we propose Prompts-in-The-Loop (PiTL) that prompts knowledge from large language models (LLMs) to describe images. Concretely, given a category label of an image, e.g. refinery, the knowledge, e.g. a refinery could be seen with large storage tanks, pipework, and ..., extracted by LLMs is used as the language counterpart. The knowledge supplements, e.g. the common relations among entities most likely appearing in a scene. We create IN14K, a new VL dataset of 9M images and 1M descriptions of 14K categories from ImageNet21K [8] with PiTL. Empirically, the VL models pre-trained with PiTL-generated pairs are strongly favored over other W-VLP works on image-to-text (I2T) and text-to-image (T2I) retrieval tasks, with less supervision. The results reveal the effectiveness of PiTL-generated pairs for VLP.	[Guo, Zixin; Wang, Tzu-Jui Julius; Pehlivan, Selen; Radman, Abduljalil; Laaksonen, Jorma] Aalto Univ, Espoo, Finland	Aalto University	Guo, ZX (corresponding author), Aalto Univ, Espoo, Finland.	zixin.guo@aalto.fi; tzu-jui.wang@aalto.fi; selen.pehlivantort@aalto.fi; abduljalil.saif@aalto.fi; jorma.laaksonen@aalto.fi	; Radman, Abduljalil/A-1722-2012	Guo, Zixin/0000-0002-7088-2331; Radman, Abduljalil/0000-0002-6317-9752	Academy of Finland [345791]	Academy of Finland(Research Council of Finland)	This work is supported by the Academy of Finland in project 345791. We acknowledge the LUMI supercomputer, owned by the EuroHPC Joint Undertaking, hosted by CSC and the LUMI consortium.	Bao Hangbo, 2021, ARXIV210608254; Byun J, 2022, LECT NOTES COMPUT SC, V13679, P395, DOI 10.1007/978-3-031-19800-7_23; Changpinyo S, 2021, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR46437.2021.00356; Chen C, 2022, PROC INT C TOOLS ART, P799, DOI 10.1109/ICTAI56018.2022.00123; Chuang J, 2022, ELEC COMP C, P1567, DOI 10.1109/ECTC51906.2022.00250; Deakin T, 2020, PROCEEDINGS OF 2020 IEEE/ACM INTERNATIONAL WORKSHOP ON PERFORMANCE, PORTABILITY AND PRODUCTIVITY IN HPC (P3HPC 2020), P1, DOI 10.1109/P3HPC51967.2020.00006; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dosovitskiy A., 2021, PROC INT C LEARN REP, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]; Gan Z., 2020, Advances in Neural Information Processing Systems, P6616; Jia C, 2021, PR MACH LEARN RES, V139; Kim W, 2021, PR MACH LEARN RES, V139; Lenc Karel, 2022, ARXIV220414198; Li Chenliang, 2022, arXiv; Li J., 2021, ADV NEURAL INFORM PR, P9694; Li JN, 2022, PR MACH LEARN RES; Li Junnan, 2023, ARXIV230112597; Li L. H., 2020, ARXIV201012831; Li W, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2592; Li Wei, 2022, ARXIV220309067; Li X., 2020, EUR C COMP VIS, P121, DOI DOI 10.1007/978-3-030-58577-8_8; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028; Menon Sachit, 2022, ARXIV221007183; Ordonez V., 2011, Advances in Neural Information Processing Systems, P1143; Pratt Sarah, 2022, ARXIV220903320; Radford A, 2021, PR MACH LEARN RES, V139; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Singh A, 2022, PROC CVPR IEEE, P15617, DOI 10.1109/CVPR52688.2022.01519; Touvron H, 2021, PR MACH LEARN RES, V139, P7358; Wang T., 2022, INT C MACH LEARN, P22680; Wang TJJ, 2023, IEEE WINT CONF APPL, P1073, DOI 10.1109/WACV56688.2023.00113; Wang Wenhui, 2022, ARXIV220810442; XU YG, 2022, P 2 C AS PAC CHAPT A, P337, DOI DOI 10.1109/ICCR55715.2022.10053881; Yang Yue, 2022, ARXIV221111158; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Zellers R., 2021, Advances in Neural Information Processing Systems, P23634; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553; Zhou MY, 2022, PROC CVPR IEEE, P16464, DOI 10.1109/CVPR52688.2022.01599; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	40	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							2261	2265		10.1145/3539618.3592038	http://dx.doi.org/10.1145/3539618.3592038			5	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		hybrid, Green Published, Green Submitted			2024-07-03	WOS:001118084002060
C	Jaimes, NE; Zeng, C; Simha, R		Blowers, M; Holt, J; Wysocki, BT		Jaimes, Nelson E.; Zeng, Chen; Simha, Rahul			Using Biologically Hierarchical Modular Architecture for Explainable, Tunable, Generalizable, Spatial AI	DISRUPTIVE TECHNOLOGIES IN INFORMATION SCIENCES VII	Proceedings of SPIE		English	Proceedings Paper	Conference on Disruptive Technologies in Information Sciences VII	MAY 01-03, 2023	Orlando, FL	SPIE		explainable; artificial intelligence; brain; machine learning; navigation; spatial learning	DIRECTION; HIPPOCAMPUS; CORTEX	Explainable artificial intelligence (XAI) is an area of ongoing research for a variety of machine learning applications that aims to describe decision making employed by many artificial neural networks (ANNs) in an intuitive manner for humans. Another seemingly unsolved topic generating research interest is AI conceptual understanding, (such as in large language models) which falls within a more general problem of AI model generalizability and integrability. How might computational problems of that difficulty be solved, and more importantly, which approach will result in genuine advancement in the fields of neuroscience and/or artificial intelligence? An oftenused strategy in machine learning is to use knowledge about biological brains to inspire machine learning model design. That strategy can continue to be useful and novel because both neuroscience and artificial intelligence are rapidly growing fields of research; the same unification strategy between both fields can yield significantly different models as neuroscience knowledge and machine learning capabilities both grow and develop. In this paper, we focus on the usefulness of using current neuroscience knowledge to design biologically hierarchical and modular architecture (BHMA) models of the brain that can solve spatial learning tasks. We discuss the potential implications of biologically constrained hierarchical neural networks for the future of human-computer interaction, computational neuroscience, and machine learning given their potential for generating more explainable models with verifiable aspects of conceptual understanding.	[Jaimes, Nelson E.; Zeng, Chen; Simha, Rahul] George Washington Univ, 800 22nd St NW, Washington, DC 20052 USA	George Washington University	Jaimes, NE (corresponding author), George Washington Univ, 800 22nd St NW, Washington, DC 20052 USA.	njaimes@gwmail.gwu.edu						Banker SM, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-019-56003-y; Baumann O, 2010, J NEUROSCI, V30, P12897, DOI 10.1523/JNEUROSCI.3077-10.2010; Bendre N, 2021, IEEE SYS MAN CYBERN, P3006, DOI 10.1109/SMC52423.2021.9659223; Bermudez-Contreras E, 2020, FRONT COMPUT NEUROSC, V14, DOI 10.3389/fncom.2020.00063; Chadwick MJ, 2015, CURR BIOL, V25, P87, DOI 10.1016/j.cub.2014.11.001; DiBattista AM, 2016, CURR ALZHEIMER RES, V13, P1200, DOI 10.2174/1567205013666160401115127; DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010; Durán JM, 2021, J MED ETHICS, V47, P329, DOI [10.1136/medethics-2020-106820, 10.1136/medethics-2021-107531]; Gallistel C.R., 1990, The organization of learning; Green AE, 2016, CURR DIR PSYCHOL SCI, V25, P28, DOI 10.1177/0963721415618485; Howard J. J., 2022, arXiv, DOI DOI 10.1007/978-3-031-37660-3; Kim M, 2019, HIPPOCAMPUS, V29, P619, DOI 10.1002/hipo.23060; Kriegeskorte N, 2018, NAT NEUROSCI, V21, P1148, DOI 10.1038/s41593-018-0210-5; Maguire EA, 1998, SCIENCE, V280, P921, DOI 10.1126/science.280.5365.921; MCNAUGHTON BL, 1991, J COGNITIVE NEUROSCI, V3, P192, DOI 10.1162/jocn.1991.3.2.190; Medenilla A., 2023, PLoS Digital Health, V2; OKEEFE J, 1979, BEHAV BRAIN SCI, V2, P487, DOI 10.1017/S0140525X00063949; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Riesenhuber M, 2000, NAT NEUROSCI, V3, P1199, DOI 10.1038/81479; Shine JP, 2016, J NEUROSCI, V36, P6371, DOI 10.1523/JNEUROSCI.1268-15.2016; Skaggs WE, 1996, SCIENCE, V271, P1870, DOI 10.1126/science.271.5257.1870; van Seijen H, 2017, ADV NEUR IN, V30; Zhang WC, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501826	23	0	0	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	1996-756X	978-1-5106-6200-1; 978-1-5106-6201-8	PROC SPIE			2023	12542								125420W	10.1117/12.2679920	http://dx.doi.org/10.1117/12.2679920			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4XK					2024-07-03	WOS:001043366600022
C	Liu, YX; Fabbri, AR; Liu, PF; Zhao, YL; Nan, LY; Han, RL; Han, SM; Joty, S; Wu, CS; Xiong, CM; Radev, D		Rogers, A; Boyd-Graber, J; Okazaki, N		Liu, Yixin; Fabbri, Alexander R.; Liu, Pengfei; Zhao, Yilun; Nan, Linyong; Han, Ruilin; Han, Simeng; Joty, Shafiq; Wu, Chien-Sheng; Xiong, Caiming; Radev, Dragomir			Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Human evaluation is the foundation upon which the evaluation of both summarization systems and automatic metrics rests. However, existing human evaluation studies for summarization either exhibit a low inter-annotator agreement or have insufficient scale, and an in-depth analysis of human evaluation is lacking. Therefore, we address the shortcomings of existing summarization evaluation along the following axes: (1) We propose a modified summarization salience protocol, Atomic Content Units (ACUs), which is based on fine-grained semantic units and allows for a high interannotator agreement. (2) We curate the Robust Summarization Evaluation (RoSE) benchmark, a large human evaluation dataset consisting of 22,000 summary-level annotations over 28 top-performing systems on three datasets. (3) We conduct a comparative study of four human evaluation protocols, underscoring potential confounding factors in evaluation setups. (4) We evaluate 50 automatic metrics and their variants using the collected human annotations across evaluation protocols and demonstrate how our benchmark leads to more statistically stable and significant results. The metrics we benchmarked include recent methods based on large language models (LLMs), GPTScore and G-Eval. Furthermore, our findings have important implications for evaluating LLMs, as we show that LLMs adjusted by human feedback (e.g., GPT-3.5) may overfit unconstrained human evaluation, which is affected by the annotators' prior, input-agnostic preferences, calling for more robust, targeted evaluation methods.	[Liu, Yixin; Zhao, Yilun; Nan, Linyong; Han, Ruilin; Han, Simeng; Radev, Dragomir] Yale Univ, New Haven, CT 06520 USA; [Fabbri, Alexander R.; Joty, Shafiq; Wu, Chien-Sheng; Xiong, Caiming] Salesforce AI, San Francisco, CA USA; [Liu, Pengfei] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Yale University; Carnegie Mellon University	Liu, YX (corresponding author), Yale Univ, New Haven, CT 06520 USA.	yixin.liu@yale.edu; afabbri@salesforce.com	Liu, Yi-Xin/L-8291-2019	Liu, Yi-Xin/0000-0001-9374-5981				Anderson J, 2019, IEEE INT CONF ASAP, P25, DOI 10.1109/ASAP.2019.00-41; [Anonymous], 2021, FIND ASS COMP LING A, DOI DOI 10.1145/3466752.3480113; Bao SQ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P85; Bhandari M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9347; Brown Tom B., 2020, Advances in Neural Information Processing Systems; Cao SY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6633; Card D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9263; Chaganty AT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P643; Chen JA, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4106; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Cohan A, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P806; Deng MK, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7580; Deutsch D, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P6038; Deutsch D, 2021, T ASSOC COMPUT LING, V9, P1132, DOI 10.1162/tacl_a_00417; Deutsch D, 2021, T ASSOC COMPUT LING, V9, P774, DOI 10.1162/tacl_a_00397; Deutsch Daniel, 2020, P 2 WORKSH NLP OP SO, P120; Dongwook Lee, 2019, arXiv; Dou ZY, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4830; Durmus Esin, 2020, P 58 ANN M ASS COMPU, P5055, DOI [10.18653/v1/2020.acl-main.454, 10.18653/v1/2020.acl-main]; Efron B, 1994, An Introduction to the Bootstrap, DOI [10.1201/9780429246593, DOI 10.1201/9780429246593]; Fabbri Alexander, 2022, T ASS COMPUTATIONAL, V9, P391; Fabbri AR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2587; Feng XC, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1479; Fu Jinlan, 2023, ABS230204166 ARXIV; Gabriel S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P478; Gao MQ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5693; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Gao Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1347; Gehrmann S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P96; Gehrmann Sebastian, 2022, ABS220206935 ARXIV; Gliwa Bogdan, 2019, P 2 WORKSHOP NEW FRO, P70, DOI DOI 10.18653/V1/D19-5409; Goyal Tanya, 2022, News summarization and evaluation in the era of gpt-3; Graham Y., 2015, P 2015 C EMPIRICAL M, P128, DOI DOI 10.18653/V1/D15-1013; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Hardy, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3381; He Junxian, 2020, Ctrlsum: Towards generic controllable text summarization; He Pengcheng, 2022, ABS220809770 ARXIV; Honovich O, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P161; Huang DD, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P446; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Kasai J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3540; Kasai Jungo, 2022, ABS220405424 ARXIV; Krippendorff K, 2011, Computing krippendorff's alpha-reliability; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Laban Philippe, SUMMAC REVISITING NL; Lavie A., 2007, P 2 WORKSH STAT MACH, P228; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Liang P., 2022, Holistic evaluation of language models; Lin C, 2004, NTCIR; Liu F., 2008, short papers, P201; Liu Yang, 2023, ABS230316634 ARXIV; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Liu YX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2890; Liu YX, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P1065; Liu ZY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P92; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Ma Ye, 2021, Advances in Neural Information Processing Systems, V34, P16545; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayan Shashi, PLANNING LEARNED ENT; Nenkova A, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P145; OpenAI, 2023, : GPT-4 technical report.; Ouyang L., 2022, Advances in Neural Information Processing Systems; Owczarzak Karolina, 2012, P 50 ANN M ASS COMP, V2, P359; Pang Richard Yuanzhe, 2021, 9 INT C LEARN REPR I; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peyrard M, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5093; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Rankel Peter A., 2013, Short Papers, V2, P131; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Sakaguchi K, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P208; Sanh Victor, 2022, INT C LEARNING REPRE; Scialom T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6594; Scialom T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3246; Shapiral O, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P682; Song KQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1392; Steen J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1861; Stiennon N., 2020, P 34 INT C NEUR INF; Tam Derek, 2022, ABS221108412 ARXIV; Tang Liyan, 2022, Understanding factual errors in summarization: Errors, summarizers, datasets, error detectors; Tang XR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5680; Vasilyev O., 2020, P 1 WORKSHOP EVALUAT, P11; VEDANTAM R, 2015, PROC CVPR IEEE, P4566, DOI DOI 10.1109/CVPR.2015.7299087; Wei Johnny, 2021, Long Papers, V1, P6840; Yuan WZ, 2021, ADV NEUR IN, V34; Zhang J., 2020, P MACHINE LEARNING R, V119, P11328; Zhang J., 2020, PMLR, P11328; Zhang SY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6617; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhao W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P563; Zhong Ming, 2022, YANG; Zhong Ming, 2020, P 58 ANN M ASS COMPU, P6197, DOI [10.18653/v1/2020.acl-main.552, DOI 10.18653/V1/2020.ACL-MAIN.552]	95	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							4140	4170						31	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086802048
J	Ekanayake, EMCL; Gezawa, AS; Lei, YQ				Ekanayake, Ekanayake Mudiyanselage Chulabhaya Lankanatha; Gezawa, Abubakar Sulaiman; Lei, Yunqi			Trends in Event Understanding and Caption Generation/Reconstruction in Dense Video: A Review	CMC-COMPUTERS MATERIALS & CONTINUA			English	Review						Video description; video to text; video caption; sentence reconstruction		Video description generates natural language sentences that describe the subject, verb, and objects of the targeted Video. The video description has been used to help visually impaired people to understand the content. It is also playing an essential role in devolving human -robot interaction. The dense video description is more difficult when compared with simple Video captioning because of the object's interactions and event overlapping. Deep learning is changing the shape of computer vision (CV) technologies and natural language processing (NLP). There are hundreds of deep learning models, datasets, and evaluations that can improve the gaps in current research. This article filled this gap by evaluating some state-of-the-art approaches, especially focusing on deep learning and machine learning for video caption in a dense environment. In this article, some classic techniques concerning the existing machine learning were reviewed. And provides deep learning models, a detail of benchmark datasets with their respective domains. This paper reviews various evaluation metrics, including Bilingual Evaluation Understudy (BLEU), Metric for Evaluation of Translation with Explicit Ordering (METEOR), Word Mover's Distance (WMD), and Recall -Oriented Understudy for Gisting Evaluation (ROUGE) with their pros and cons. Finally, this article listed some future directions and proposed work for context enhancement using key scene extraction with object detection in a particular frame. Especially, how to improve the context of video description by analyzing key frames detection through morphological image analysis. Additionally, the paper discusses a novel approach involving sentence reconstruction and context improvement through key frame object detection, which incorporates the fusion of large language models for refining results. The ultimate results arise from enhancing the generated text of the proposed model by improving the predicted text and isolating objects using various keyframes. These keyframes identify dense events occurring in the video sequence.	[Ekanayake, Ekanayake Mudiyanselage Chulabhaya Lankanatha; Lei, Yunqi] Xiamen Univ, Dept Comp Sci, Xiamen 361005, Peoples R China; [Ekanayake, Ekanayake Mudiyanselage Chulabhaya Lankanatha] Wayamba Univ Sri Lanka, Main Lib, Kuliyapitiya 60200, Sri Lanka; [Gezawa, Abubakar Sulaiman] Sanming Univ, Sch Informat Engn, Sanming 365004, Peoples R China	Xiamen University; Wayamba University of Sri Lanka; Sanming University	Gezawa, AS (corresponding author), Sanming Univ, Sch Informat Engn, Sanming 365004, Peoples R China.	20220505@fjsmu.edu.cn	Ekanayake, E.M.C.L/HPF-0846-2023	Ekanayake, E.M.C.L/0000-0001-6864-5604				Aafaq N, 2019, PROC CVPR IEEE, P12479, DOI 10.1109/CVPR.2019.01277; Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390; Ahmed S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010317; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; [Anonymous], 2022, UCSD Anomaly Detection Dataset; [Anonymous], 1997, P NAT C ART INT 9 C; [Anonymous], 2022, Monitoring Human Activity-Action Recognition; Bin Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P436, DOI 10.1145/2964284.2967258; Bitton Y., 2023, P AAAI C ART INT WAS, V37, P241; Bitton Y., 2022, Advances in Neural Information Processing Systems (NeurIPS), P1; Chang Z, 2022, NEURAL NETWORKS, V146, P120, DOI 10.1016/j.neunet.2021.11.017; Chen D. L., 2011, Association for Computational Linguistics, V1, P190; Chen JW, 2019, AAAI CONF ARTIF INTE, P8167; Chen SX, 2019, AAAI CONF ARTIF INTE, P8191; Chen SQ, 2020, NEURAL PROCESS LETT, V52, P2353, DOI 10.1007/s11063-020-10352-2; Chen SH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4853, DOI 10.1145/3474085.3479216; Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22; Chen Z., 2021, P INT C LEARN REPR; Das P, 2013, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2013.340; Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139; Gella S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P968; Han TD, 2023, IEEE I CONF COMP VIS, P13599, DOI 10.1109/ICCV51070.2023.01255; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; Henderson P, 2018, AAAI CONF ARTIF INTE, P3207; Hodson TO, 2022, GEOSCI MODEL DEV, V15, P5481, DOI 10.5194/gmd-15-5481-2022; Hoy Matthew B., 2018, Medical Reference Services Quarterly, V37, P81, DOI 10.1080/02763869.2018.1404391; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Ibrahimi S, 2023, IEEE I CONF COMP VIS, P12020, DOI 10.1109/ICCV51070.2023.01107; Jan A, 2023, INT J INTERACT MULTI, V8, P158, DOI 10.9781/ijimai.2021.10.010; Kang SH, 2023, INT J SOC ROBOT, V15, P631, DOI 10.1007/s12369-021-00842-1; Karpathy A., 2014, P IEEE C COMP VIS PA, P10; Kim J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071162; Kim W, 2021, PR MACH LEARN RES, V139; Koller D., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P90, DOI 10.1109/CVPR.1991.139667; Kusner MJ, 2015, PR MACH LEARN RES, V37, P957; Lavie A., 2007, P 2 WORKSH STAT MACH, P228; Li F, 2017, Arxiv, DOI arXiv:1707.04555; Li KC, 2024, Arxiv, DOI [arXiv:2305.06355, 10.48550/arXiv.2305.06355]; Li XP, 2019, WORLD WIDE WEB, V22, P621, DOI 10.1007/s11280-018-0531-z; Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2208; Li Y, 2018, PROC CVPR IEEE, P7492, DOI 10.1109/CVPR.2018.00782; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu FY, 2023, T ASSOC COMPUT LING, V11, P635, DOI 10.1162/tacl_a_00566; Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320; Mercha E, 2023, NEUROCOMPUTING, V531, P195, DOI 10.1016/j.neucom.2023.02.015; Mishra N., 2018, INT C LEARN REPR ICL, P1; Nabati M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102302; Niu TZ, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109202; Olivastri S, 2019, IEEE INT CONF COMP V, P1474, DOI 10.1109/ICCVW.2019.00185; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Parekh Z, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2855; Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854; PETS, 2009, Benchmark Data; Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767; Rohrbach A, 2015, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2015.7298940; Rohrbach A, 2014, LECT NOTES COMPUT SC, V8753, P184, DOI 10.1007/978-3-319-11752-2_15; Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801; Ruan LD, 2021, Arxiv, DOI arXiv:2106.06138; Shvetsova N, 2023, Arxiv, DOI arXiv:2310.04900; Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31; Suhr A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P217, DOI 10.18653/v1/P17-2034; Sun C, 2019, IEEE I CONF COMP VIS, P7463, DOI 10.1109/ICCV.2019.00756; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Thrush T, 2022, PROC CVPR IEEE, P5228, DOI 10.1109/CVPR52688.2022.00517; Torabi A, 2015, Arxiv, DOI arXiv:1503.01070; Torrey L., 2010, HDB RES MACHINE LEAR, P242, DOI DOI 10.4018/978-1-60566-766-9.CH011; Wang WH, 2023, PROC CVPR IEEE, P19175, DOI 10.1109/CVPR52729.2023.01838; Wang X, 2018, PROC CVPR IEEE, P4213, DOI 10.1109/CVPR.2018.00443; Wang YL, 2016, Arxiv, DOI arXiv:1607.06416; Wei HW, 2018, AAAI CONF ARTIF INTE, P216; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu RJ, 2024, Arxiv, DOI arXiv:2310.10207; Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571; Yang ZL, 2016, ADV NEUR IN, V29; Yarom M, 2023, Arxiv, DOI arXiv:2305.10400; Young P., 2014, P TACL, V2, P67, DOI DOI 10.1162/TACL_A_00166; Zeng KH, 2016, LECT NOTES COMPUT SC, V9906, P609, DOI 10.1007/978-3-319-46475-6_38; Zhang H, 2023, Arxiv, DOI [arXiv:2306.02858, 10.48550/arXiv.2306.02858, DOI 10.48550/ARXIV.2306.02858]; Zhao B, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2916757; Zheng Q., 2020, P IEEE CVF C COMP VI, P13093, DOI 10.1109/CVPR42600.2020.01311; Zhu XF, 2023, AUTOMAT CONSTR, V155, DOI 10.1016/j.autcon.2023.105074; Zhu YQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P802, DOI 10.1145/3343031.3350932; Ziqi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13275, DOI 10.1109/CVPR42600.2020.01329	83	0	0	9	9	TECH SCIENCE PRESS	HENDERSON	871 CORONADO CENTER DR, SUTE 200, HENDERSON, NV 89052 USA	1546-2218	1546-2226		CMC-COMPUT MATER CON	CMC-Comput. Mat. Contin.		2024	78	3					2941	2965		10.32604/cmc.2024.046155	http://dx.doi.org/10.32604/cmc.2024.046155			25	Computer Science, Information Systems; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Materials Science	OE4X8		gold			2024-07-03	WOS:001205586300001
J	Li, X; Henriksson, A; Duneld, M; Nouri, J; Wu, YC				Li, Xiu; Henriksson, Aron; Duneld, Martin; Nouri, Jalal; Wu, Yongchao			Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation	FUTURE INTERNET			English	Article						educational content recommendation; AI-enhanced learning; pre-trained language models; ensemble embeddings; knowledge graph embeddings; text similarity; textual semantic search; natural language processing		Educational content recommendation is a cornerstone of AI-enhanced learning. In particular, to facilitate navigating the diverse learning resources available on learning platforms, methods are needed for automatically linking learning materials, e.g., in order to recommend textbook content based on exercises. Such methods are typically based on semantic textual similarity (STS) and the use of embeddings for text representation. However, it remains unclear what types of embeddings should be used for this task. In this study, we carry out an extensive empirical evaluation of embeddings derived from three different types of models: (i) static embeddings trained using a concept-based knowledge graph, (ii) contextual embeddings from a pre-trained language model, and (iii) contextual embeddings from a large language model (LLM). In addition to evaluating the models individually, various ensembles are explored based on different strategies for combining two models in an early vs. late fusion fashion. The evaluation is carried out using digital textbooks in Swedish for three different subjects and two types of exercises. The results show that using contextual embeddings from an LLM leads to superior performance compared to the other models, and that there is no significant improvement when combining these with static embeddings trained using a knowledge graph. When using embeddings derived from a smaller language model, however, it helps to combine them with knowledge graph embeddings. The performance of the best-performing model is high for both types of exercises, resulting in a mean Recall@3 of 0.96 and 0.95 and a mean MRR of 0.87 and 0.86 for quizzes and study questions, respectively, demonstrating the feasibility of using STS based on text embeddings for educational content recommendation. The ability to link digital learning materials in an unsupervised manner-relying only on readily available pre-trained models-facilitates the development of AI-enhanced learning.	[Li, Xiu; Henriksson, Aron; Duneld, Martin; Nouri, Jalal; Wu, Yongchao] Stockholm Univ, Dept Comp & Syst Sci, NOD Huset, Borgarfjordsgatan 12, S-16455 Stockholm, Sweden	Stockholm University	Henriksson, A (corresponding author), Stockholm Univ, Dept Comp & Syst Sci, NOD Huset, Borgarfjordsgatan 12, S-16455 Stockholm, Sweden.	xiu.li@dsv.su.se; aronhen@dsv.su.se; xmartin@dsv.su.se; jalal@dsv.su.se; yongchao.wu@dsv.su.se						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Barria-Pineda J., 2022, Technical Report; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Bougouin A., 2013, INT JOINT C NAT LANG, P543; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Christiansen JG, 2023, Arxiv, DOI arXiv:2308.15047; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Peters ME, 2019, Arxiv, DOI [arXiv:1909.04164, 10.18653/v1/D19-1005, DOI 10.18653/V1/D19-1005]; Ekgren A, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3509; El Boukkouri H, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019:): STUDENT RESEARCH WORKSHOP, P295; Fang LT, 2023, IEEE T KNOWL DATA EN, V35, P5534, DOI 10.1109/TKDE.2022.3159539; Fang LT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P427, DOI 10.1145/3308558.3313425; Faruqui M, 2015, Arxiv, DOI [arXiv:1411.4166, 10.48550/ARXIV.1411.4166]; Ferragina P, 2010, P 19 ACM INT C INF K, P1625, DOI [DOI 10.1145/1871437.1871689.(VER, DOI 10.1145/1871437.1871689, 10.1145/1871437.1871689]; Ganaie MA, 2022, ENG APPL ARTIF INTEL, V115, DOI 10.1016/j.engappai.2022.105151; Goossens S., A Guide to Building Document Embeddings; Greene R., OpenAI Blog; Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754; Hadi M. U., 2023, A Survey on large language models: Applications, challenges, limitation, and practical usage, P1, DOI [10.36227/techrxiv.23589741.v1, DOI 10.36227/TECHRXIV.23589741.V1]; Herlinda R., 2014, P 6 TEFLIN INT C SUR; Isbister T, 2020, Arxiv, DOI arXiv:2009.03116; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Hamilton WL, 2018, Arxiv, DOI [arXiv:1706.02216, 10.48550/arXiv.1706.02216, DOI 10.48550/ARXIV.1706.02216]; Li X., 2023, P INT C METH INT SYS, P96; Li XM, 2022, LECT NOTES COMPUT SC, V13263, P133, DOI 10.1007/978-3-031-09342-5_13; Lietard B., 2021, arXiv; Ling C, 2023, Arxiv, DOI arXiv:2305.18703; Malmsten M., 2020, arXiv; Meng R., 2017, arXiv; MIHALCEA R, 2006, P 21 NAT C ART INT A, P775; Murom„gi A, 2017, Arxiv, DOI arXiv:1704.01419; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Niu YM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131910933; Okubo F, 2023, IEEE T LEARN TECHNOL, V16, P92, DOI 10.1109/TLT.2022.3225206; Ostendorff M, 2020, Arxiv, DOI arXiv:2008.00202; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Rahdari Behnam, 2020, Addressing Global Challenges and Quality Education. 15th European Conference on Technology Enhanced Learning, EC-TEL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12315), P363, DOI 10.1007/978-3-030-57717-9_28; Rahdari B., 2020, P 2 INT WORKSH INT T; Rahman MM, 2018, IEEE ACCESS, V6, P34166, DOI 10.1109/ACCESS.2018.2850376; Rajabi E, 2022, J INF SCI, DOI 10.1177/01655515221112844; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rekathati F, 2022, The KBLab Blog: Introducing a Swedish Sentence Transformer; Ri R., 2021, arXiv; Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Sterling JA, 2022, IEEE ACCESS, V10, P16, DOI 10.1109/ACCESS.2021.3137960; Su YK, 2023, DATA-BASEL, V8, DOI 10.3390/data8120180; Suchanek F.M., 2007, P 16 INT C WORLD WID, P697, DOI 10.1145/1242572.1242667; Thaker K., 2020, P INT C ED DAT MIN E; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Wan SS, 2020, IEEE T KNOWL DATA EN, V32, P827, DOI 10.1109/TKDE.2019.2895033; Wang B, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1737, DOI 10.1145/3442381.3450043; Wang X, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P950, DOI 10.1145/3292500.3330989; Wang Z., 2016, IJCAI, P4, DOI 10.18653/v1/N18-1068; Xiong CY, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1271, DOI 10.1145/3038912.3052558; Yamada I, 2020, Arxiv, DOI arXiv:2010.01057; Yu DH, 2022, AAAI CONF ARTIF INTE, P11630; Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673; Zhao QH, 2023, NEUROCOMPUTING, V552, DOI 10.1016/j.neucom.2023.126511; Zhong Qihuang, 2023, IEEE Transactions on Knowledge and Data Engineering, P10098, DOI 10.1109/TKDE.2023.3250499	62	2	2	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	JAN	2024	16	1							12	10.3390/fi16010012	http://dx.doi.org/10.3390/fi16010012			21	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	FX3T4		gold, Green Published			2024-07-03	WOS:001149119000001
J	Lehnen, NC; Dorn, F; Wiest, IC; Zimmermann, H; Radbruch, A; Kather, JN; Paech, D; Kroener, E				Lehnen, Nils C.; Dorn, Franziska; Wiest, Isabella C.; Zimmermann, Hanna; Radbruch, Alexander; Kather, Jakob Nikolas; Paech, Daniel; Kroener, Else			Data Extraction from Free-Text Reports on Mechanical Thrombectomy in Acute Ischemic Stroke Using ChatGPT: A Retrospective Analysis	RADIOLOGY			English	Article								Background: Procedural details of mechanical thrombectomy in patients with ischemic stroke are important predictors of clinical outcome and are collected for prospective studies or national stroke registries. To date, these data are collected manually by human readers, a labor-intensive task that is prone to errors. Purpose: To evaluate the use of the large language models (LLMs) GPT-4 and GPT-3.5 to extract data from neuroradiology reports on mechanical thrombectomy in patients with ischemic stroke. Materials and Methods: This retrospective study included consecutive reports from patients with ischemic stroke who underwent mechanical thrombectomy between November 2022 and September 2023 at institution 1 and between September 2016 and December 2019 at institution 2. A set of 20 reports was used to optimize the prompt, and the ability of the LLMs to extract procedural data from the reports was compared using the McNemar test. Data manually extracted by an interventional neuroradiologist served as the reference standard. Results: A total of 100 internal reports from 100 patients (mean age, 74.7 years +/- 13.2 [SD]; 53 female) and 30 external reports from 30 patients (mean age, 72.7 years +/- 13.5; 18 male) were included. All reports were successfully processed by GPT-4 and GPT-3.5. Of 2800 data entries, 2631 (94.0% [95% CI: 93.0, 94.8]; range per category, 61%-100%) data points were correctly extracted by GPT-4 without the need for further postprocessing. With 1788 of 2800 correct data entries, GPT-3.5 produced fewer correct data entries than did GPT-4 (63.9% [95% CI: 62.0, 65.6]; range per category, 14%-99%; P < .001). For the external reports, GPT-4 extracted 760 of 840 (90.5% [95% CI: 88.3, 92.4]) correct data entries, while GPT-3.5 extracted 539 of 840 (64.2% [95% CI: 60.8, 67.4]; P < .001). Conclusion: Compared with GPT-3.5, GPT-4 more frequently extracted correct procedural data from free -text reports on mechanical thrombectomy performed in patients with ischemic stroke.	[Lehnen, Nils C.; Dorn, Franziska; Radbruch, Alexander; Paech, Daniel] Rhein Friedrich Wilhelms Univ Bonn, Univ Hosp Bonn, Dept Neuroradiol, Venusberg Campus 1, D-53127 Bonn, Germany; [Lehnen, Nils C.; Radbruch, Alexander] German Ctr Neurodegenerat Dis DZNE, Res Grp Clin Neuroimaging, Bonn, Germany; [Wiest, Isabella C.] Heidelberg Univ, Med Fac Mannheim, Dept Med 2, Mannheim, Germany; [Wiest, Isabella C.; Kather, Jakob Nikolas] Tech Univ Dresden, Med Fac Carl Gustav Carus, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Zimmermann, Hanna] Ludwig Maximilians Univ Munchen, Univ Hosp, Inst Neuroradiol, Munich, Germany; [Paech, Daniel] Harvard Med Sch, Brigham & Womens Hosp, Dept Radiol, Boston, MA USA	University of Bonn; Helmholtz Association; German Center for Neurodegenerative Diseases (DZNE); Ruprecht Karls University Heidelberg; Technische Universitat Dresden; Carl Gustav Carus University Hospital; University of Munich; Harvard University; Harvard Medical School; Brigham & Women's Hospital	Lehnen, NC (corresponding author), Rhein Friedrich Wilhelms Univ Bonn, Univ Hosp Bonn, Dept Neuroradiol, Venusberg Campus 1, D-53127 Bonn, Germany.; Lehnen, NC (corresponding author), German Ctr Neurodegenerat Dis DZNE, Res Grp Clin Neuroimaging, Bonn, Germany.	nils.lehnen@ukbonn.de	Kather, Jakob Nikolas/D-4279-2015	Kather, Jakob Nikolas/0000-0002-3730-5348; Zimmermann, Hanna/0000-0002-1476-3477; Paech, Daniel/0000-0001-5755-6833				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Amin Kanhai S, 2023, Radiology, V309, pe232561, DOI 10.1148/radiol.232561; [Anonymous], ChatGPT-4. OpenAl.; [Anonymous], ChatGPT-3.5; Berkhemer OA, 2015, NEW ENGL J MED, V372, P394; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Campbell BCV, 2015, NEW ENGL J MED, V372, P1009, DOI 10.1056/NEJMoa1414792; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Goyal M, 2015, NEW ENGL J MED, V372, P1019, DOI 10.1056/NEJMoa1414905; Goyal M, 2016, LANCET, V387, P1723, DOI 10.1016/S0140-6736(16)00163-X; Gunter D, 2022, NEURORADIOLOGY, V64, P2357, DOI 10.1007/s00234-022-03029-1; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Jovin TG, 2015, NEW ENGL J MED, V372, P2296, DOI 10.1056/NEJMoa1503780; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Li D, 2024, RADIOLOGY, V310, DOI 10.1148/radiol.232411; Li MD, 2021, AM J NEURORADIOL, V42, P429, DOI 10.3174/ajnr.A6961; Lopez-Ubeda P, 2023, EUR RADIOL, V33, P9455, DOI 10.1007/s00330-023-09901-9; Miller MI, 2022, NEUROCRIT CARE, V37, P291, DOI 10.1007/s12028-022-01513-3; Ong CJ, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0234908; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Saver JL, 2015, NEW ENGL J MED, V372, P2285, DOI 10.1056/NEJMoa1415061; Siddiqui Z, 2023, Neurosci Inform, V3; Sung SF, 2021, J AM HEART ASSOC, V10, DOI 10.1161/JAHA.121.023486; Torres-Lopez VM, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.27109; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Yu AYX, 2021, JMIR MED INF, V9, DOI 10.2196/24381	29	0	0	1	1	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	APR	2024	311	1							e232741	10.1148/radiol.232741	http://dx.doi.org/10.1148/radiol.232741			8	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	UC3M1	38625006				2024-07-03	WOS:001245823000006
J	Wong, LH; Park, H; Looi, CK				Wong, Lung-Hsiang; Park, Hyejin; Looi, Chee-Kit			From hype to insight: Exploring ChatGPT's early footprint in education via altmetrics and bibliometrics	JOURNAL OF COMPUTER ASSISTED LEARNING			English	Article; Early Access						AI in education; altmetrics; bibliometrics; ChatGPT in education; probing publication deluge; research impact		Background: The emergence of ChatGPT in the education literature represents a transformative phase in educational technology research, marked by a surge in publications driven by initial research interest in new topics and media hype. While these publications highlight ChatGPT's potential in education, concerns arise regarding their quality, methodology, and uniqueness. Objective: Our study employs unconventional methods by combining altmetrics and bibliometrics to explore ChatGPT in education comprehensively. Methods: Two scholarly databases, Web of Science and Altmetric, were adopted to retrieve publications with citations and those mentioned on social media, respectively. We used a search query, "ChatGPT," and set the publication date between November 30th, 2022, and August 31st, 2023. Both datasets were within the education-related domains. Through a filtering process, we identified three publication categories: 49 papers with both altmetrics and citations, 60 with altmetrics only, and 66 with citations only. Descriptive statistical analysis was conducted on all three lists of papers, further dividing the entire collection into three distinct periods. All the selected papers underwent detailed coding regarding open access, paper types, subject domains, and learner levels. Furthermore, we analysed the keywords occurring and visualized clusters of the co-occurring keywords. Results and Conclusions: An intriguing finding is the significant correlation between media/social media mentions and academic citations in ChatGPT in education papers, underscoring the transformative potential of ChatGPT and the urgency of its incorporation into practice. Our keyword analysis also reveals distinctions between the themes of the papers that received both mentions and citations and those that received only citations but no mentions. Additionally, we noticed a limitation that authors' choice of keywords might be influenced by individual subjective judgements, potentially skewing results in thematic analysis based solely on author-assigned keywords such as keyword co-occurrence analysis. Henceforth, we advocate for developing a standardized keyword taxonomy in the educational technology field and integrating Large Language Models to enhance keyword analysis in altmetric and bibliometric tools. This study reveals that ChatGPT in education literature is evolving from rapid publication to rigorous research.	[Wong, Lung-Hsiang] Nanyang Technol Univ, Natl Inst Educ, Singapore, Singapore; [Park, Hyejin] Korea Inst Sci & Technol Informat, Daejeon, South Korea; [Looi, Chee-Kit] Educ Univ Hong Kong, Dept Curriculum & Instruct, Hong Kong, Peoples R China; [Park, Hyejin] Korea Inst Sci & Technol Informat, 245 Daehak Ro, Daejeon 34141, South Korea	Nanyang Technological University; National Institute of Education (NIE) Singapore; Korea Institute of Science & Technology Information (KISTI); Education University of Hong Kong (EdUHK); Korea Institute of Science & Technology Information (KISTI)	Park, H (corresponding author), Korea Inst Sci & Technol Informat, 245 Daehak Ro, Daejeon 34141, South Korea.	hpark7@kisti.re.kr		Wong, Lung-Hsiang/0000-0002-0402-9199; Park, Hyejin/0000-0001-9695-8456				Adiguzel T, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13152; Altmetric, 2023, How is the Altmetric attention score calculated; Altmetric, 2023, The donut and Altmetric attention score; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Bahroun Z, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151712983; Bar-Ilan Judit, 2018, Proceedings of the Association for Information Science and Technology, V55, DOI 10.1002/pra2.2018.14505501073; Bommineni V. L., 2023, Performance of ChatGPT on the MCAT: The road to personalized and equitable premedical learning 2023-2003; Bornmann L, 2014, J INFORMETR, V8, P895, DOI 10.1016/j.joi.2014.09.005; Bradea I., 2015, Journal of Eastern Europe Research in Business Economics, V2015, P1, DOI [10.5171/2015.169472, DOI 10.5171/2015.169472]; Cañas-Guerrero I, 2013, EUR J AGRON, V50, P19, DOI 10.1016/j.eja.2013.05.002; Castello-Sirvent F., 2023, international conference on education and new learning technologies; Corder G.W., 2009, NONPARAMETRIC STAT N; Costas R, 2015, J ASSOC INF SCI TECH, V66, P2003, DOI 10.1002/asi.23309; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; COURTIAL JP, 1994, SCIENTOMETRICS, V31, P251, DOI 10.1007/BF02016875; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Eysenbach G, 2011, J MED INTERNET RES, V13, DOI 10.2196/jmir.2012; Fang ZC, 2022, SCIENTOMETRICS, V127, P4523, DOI 10.1007/s11192-022-04468-6; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Garfield E, 1996, BRIT MED J, V313, P411, DOI 10.1136/bmj.313.7054.411; Garfield E., 1963, Science citation index. Science Citation Index 1961, 1; Garfield E., 1979, CITATION INDEXING IT; Gaviria-Marin M, 2018, J KNOWL MANAG, V22, P1655, DOI 10.1108/JKM-10-2017-0497; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Girard C, 2013, J COMPUT ASSIST LEAR, V29, P207, DOI 10.1111/j.1365-2729.2012.00489.x; Grassini S, 2023, EDUC SCI, V13, DOI 10.3390/educsci13070692; Heimans S, 2023, ASIA-PAC J TEACH EDU, V51, P105, DOI 10.1080/1359866X.2023.2189368; Hepp A., 2023, Human-Machine Communication, V6, P4; Holmberg K.J., 2015, Altmetrics for information professionals: Past, present and future; Hood WW, 2001, SCIENTOMETRICS, V52, P291, DOI 10.1023/A:1017919924342; Huang Y., 2023, AI and education in China-Imagining the future, excavating the past; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Hwang G.-J., 2022, COMPUTERS ED ARTIFIC, V3, DOI [10.1016/j.caeai.2022.100082, DOI 10.1016/J.CAEAI.2022.100082]; Imran M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13605; Jabeen M., 2015, INT INF LIBR REV, V47, P71, DOI [10.1080/10572317.2015.1113602, DOI 10.1080/10572317.2015.1113602]; Jahic I., 2023, Harnessing the power of artificial intelligence and ChatGPT in education-a first rapid literature review; Jeon J, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2204343; Karanatsiou D, 2017, PERFORM MEAS METR, V18, P16, DOI 10.1108/PMM-08-2016-0036; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khosravi H., 2023, Chatbots and ChatGPT: A bibliometric analysis and systematic review of publications in web of science and Scopus databases; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lin S. M., 2023, International conference on innovative technologies and learning; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Megahed FM, 2024, QUAL ENG, V36, P287, DOI 10.1080/08982112.2023.2206479; Mingers J, 2015, EUR J OPER RES, V246, P1, DOI 10.1016/j.ejor.2015.04.002; Mogavi R. H., 2023, Exploring User Perspectives on ChatGPT: Applications, Perceptions, and Implications for AI-Integrated Education; Montenegro-Rueda M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080153; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Ortega JL, 2020, SCIENTOMETRICS, V122, P555, DOI 10.1007/s11192-019-03299-2; Park H, 2021, PROF INFORM, V30, DOI 10.3145/epi.2021.mar.14; Park H, 2021, J DATA INFO SCI, V6, P116, DOI 10.2478/jdis-2021-0001; Park Hyo Chan., 2018, Quality and Quantity, V53, P935, DOI DOI 10.1007/S11135-018-0797-3; Payne N, 2008, J INF SCI, V34, P3, DOI 10.1177/0165551507079417; pek I., 2023, Educational Process: International Journal, V12, P26, DOI [10.22521/edupij.2023.123.2, DOI 10.22521/EDUPIJ.2023.123.2]; Perera P., 2023, INT J RES INNOVATION, VVII, P306, DOI [10.47772/IJRISS.2023.7623, DOI 10.47772/IJRISS.2023.7623]; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Piwowar H, 2013, NATURE, V493, P159, DOI 10.1038/493159a; Pradana M, 2023, COGENT EDUC, V10, DOI 10.1080/2331186X.2023.2243134; Rajaraman V, 2023, RESONANCE, V28, P889, DOI 10.1007/s12045-023-1620-6; Raman R., 2023, Early research trends on CahtGPT: A review based on Altmetrics and science mapping analysis, DOI [10.21203/rs.3.rs-2768211/v1, DOI 10.21203/RS.3.RS-2768211/V1]; Rogers EM., 2003, Diffusion of innovations (5. Aufl.), V5, DOI DOI 10.2307/2573300; Rudolph J, 2023, Journal of Applied Learning and Teaching, V6; Saeed-Ul Hassan, 2017, SCIENTOMETRICS, V113, P1037, DOI 10.1007/s11192-017-2512-x; Schijven MP, 2023, SIMULAT GAMING, V54, P147, DOI 10.1177/10468781231152682; Shi YL, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11133716; Su HN, 2010, SCIENTOMETRICS, V85, P65, DOI 10.1007/s11192-010-0259-8; Syamili C, 2017, COLLNET J SCIENTOMET, V11, P103, DOI 10.1080/09737766.2016.1260815; Thelwall M, 2018, COMM COM INF SC, V856, P11, DOI 10.1007/978-981-13-1053-9_2; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Van Eck N. J., 2023, VOSviewer Manual; Vargas-Murillo A. R., 2023, Int. J. Learn. Teach. Educ. Res, V22, P122, DOI [10.26803/ijlter.22.7.7, DOI 10.26803/IJLTER.22.7.7]; VOSViewer, 2023, VOSviewer Manual; Zhang LW, 2018, SCIENTOMETRICS, V117, P495, DOI 10.1007/s11192-018-2876-6	75	0	0	28	28	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0266-4909	1365-2729		J COMPUT ASSIST LEAR	J. Comput. Assist. Learn.	2024 FEB 23	2024										10.1111/jcal.12962	http://dx.doi.org/10.1111/jcal.12962		FEB 2024	19	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	JQ1B6					2024-07-03	WOS:001174528300001
J	Omizo, R; Hart-Davidson, W				Omizo, Ryan; Hart-Davidson, William			Is Genre Enough? A Theory of Genre Signaling as Generative AI Rhetoric	RHETORIC SOCIETY QUARTERLY			English	Article; Early Access						Genre; genre signaling; machine learning; peer review; rhetorical theory	ONLINE CONSUMER REVIEWS; CORPUS	OpenAI's ChatGPT is a large language model (LLM) that excels at generating text and public controversy. Upon its release, many marveled at its ability to author intelligible and generically responsible texts (Herman). Writing about his students' experiences using artificial intelligence (AI) writing assistants, S. Scott Graham remarks that the results were "consistently mediocre-and usually quite obvious in their fabrication." Why might this be true? How can an LLM succeed in some respects and fail in others? We argue that the discrepant reactions to human and AI rhetoric are a question of genre, specifically that AI rhetoric is only generic; AI rhetoric represents a new enactment of "writing degree zero" (Barthes) that is disengaged from immediate rhetorical situations and knowledge bases. AI text generators (currently) have a more difficult time simulating the positioned perspectives that human writers bring to situations and communicate to audiences through their genre usage. Drawing on the work of Bakhtin, we treat this problem as a question of generic form and audience addressivity. We describe the interplay of form and addressivity as genre signaling and offer it as a construct for the analysis of AI rhetoric and genre as a cultural form (Miller). Genre signaling (Hart-Davidson and Omizo) describes a feature of communicative behavior as it occurs over time that can help both humans and machines evaluate written discourse as it exhibits certain stabilized formal features. When texts contain specific genre signals at expected frequencies and intensities, it may be recognized as being generally accurate, reliable, trustworthy. Without these signals, a text with a similar topical focus might fail to be taken as credible or useful. In this essay we propose to quantify genre signaling based on three measures: (1) stability, (2) frequency, and (3) periodicity.	[Omizo, Ryan] Temple Univ, Dept English, Mazur Hall,12th Floor,1114 W Polett Walk, Philadelphia, PA 19122 USA; [Hart-Davidson, William] Michigan State Univ, E Lansing, MI USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Michigan State University	Omizo, R (corresponding author), Temple Univ, Dept English, Mazur Hall,12th Floor,1114 W Polett Walk, Philadelphia, PA 19122 USA.	ryan.omizo@temple.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 1986, SPEECH GENRES OTHER; Askalidis G, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P155, DOI 10.1145/2959100.2959181; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barthes Roland., 1977, Writing Degree Zero; Biber D., 2007, DISCOURSE MOVE USING; Davidse K., 2002, The Nominative Accusative and Their Counterparts; Freadman Anne., 1994, Genre and the New Rhetoric, P43; Gambetti A, 2023, Arxiv, DOI arXiv:2302.07731; Gillam Alice M., 1991, The Writing Center Journal, V11, P3, DOI [10.7771/2832-9414.1223, DOI 10.7771/2832-9414.1223]; Graham SS, 2015, TECH COMMUN Q, V24, P70, DOI 10.1080/10572252.2015.975955; Graham S. Scott., 2022, Inside Higher Ed; Halliday M. A. K., 1976, COHESION ENGLISH, DOI 10.1677/ERC-09-0254; Hart-davidson William, 2021, SIGDOC '21: The 39th ACM International Conference on Design of Communication, P319, DOI 10.1145/3472714.3473659; Hart-Davidson William., 2017, Topologies as Techniques for a Post-Critical Rhetoric, P99, DOI [https://doi.org/10.1007/978-3-319-51268-66, DOI 10.1007/978-3-319-51268-66]; Herman Daniel., 2022, The Atlantic; Hong H, 2017, DECIS SUPPORT SYST, V102, P1, DOI 10.1016/j.dss.2017.06.007; Janzing D, 2019, Arxiv, DOI arXiv:1910.13413; Jockers ML, 2013, TOP DIGIT HUM, P1; Kane Megan., P 38 ACM INT C DES C; Kaufer D., 2006, IEEE Transactions on Professional Communication, V49, P254, DOI 10.1109/TPC.2006.880743; Kaufer D., 2023, DocuScope-Department of English-Dietrich College of Humanities and Social Sciences-Carnegie Mellon University; Kaufer David., 1998, GitHub; Klebanov BB, 2016, APPL COGN LINGUIST, V33, P167; Kuhn H.W., 2016, Contributions to the theory of games (AM-28), VII.; Larson B., 2016, P 34 ACM INT C DESIG, P1, DOI [10.1145/2987592.2987603, DOI 10.1145/2987592.2987603]; Lundberg S., 2018, Welcome to the SHAP Documentation-SHAP Latest Documentation; Lundberg SM, 2017, ADV NEUR IN, V30; Lundberg SM, 2019, Arxiv, DOI [arXiv:1802.03888, DOI 10.48550/ARXIV.1802.03888]; Mackiewicz J, 2015, TECH COMMUN-STC, V62, P3; Mackiewicz J, 2010, J BUS TECH COMMUN, V24, P3, DOI 10.1177/1050651909346929; Marciano Jonathan., 2021, World Economic Forum; Maslowska E, 2017, DECIS SUPPORT SYST, V98, P1, DOI 10.1016/j.dss.2017.03.010; MILLER CR, 1984, Q J SPEECH, V70, P151, DOI 10.1080/00335638409383686; Molnar Christoph., 2023, christophm.github.io; Molnar Christoph., christophm.github.io; Omizo Ryan M., 2020, Computers and Composition, V57, P1, DOI 10.1016/j.compcom.2020.102578; Omizo R, 2016, J WRIT RES, V7, P485, DOI 10.17239/jowr-2016.07.03.08; Omizo Ryan., 2016, DHCommons Journal, V2; PowerReviews, 2023, PowerReviews; Salminen J, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102771; Schreiner Maximilian., 2023, THE DECODER; SCHRYER CF, 1993, WRIT COMMUN, V10, P200, DOI 10.1177/0741088393010002003; Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830; Sundararajan M, 2020, Arxiv, DOI [arXiv:1908.08474, DOI 10.48550/ARXIV.1908.08474]; SWALES J, 1987, WRIT COMMUN, V4, P175, DOI 10.1177/0741088387004002004; Swales J. M., 1990, Genre analysis: English in academic and research settings; Swarts J, 2022, TECH COMMUN-STC, V69, P40, DOI 10.55177/tc812725; Tate Alison., 1994, Literature and the New Interdisciplinarity: Poetics, Linguistics, History, P135, DOI [10.1163/9789004484801013, DOI 10.1163/9789004484801013]; Tiku N., 2022, The Washington Post; Upton TA, 2009, DISCOURSE STUD, V11, P585, DOI 10.1177/1461445609341006; Vaswani A, 2017, ADV NEUR IN, V30; Virtanen T, 2017, J PRAGMATICS, V116, P77, DOI 10.1016/j.pragma.2017.03.011; Vsquez Camilla., 2014, The Discourse of Online Consumer Reviews; Wang S., 2015, J INTERACTIVE ADVERT, V15, P151, DOI DOI 10.1080/15252019.2015.1091755; Zheng LL, 2021, J BUS RES, V135, P226, DOI 10.1016/j.jbusres.2021.06.038; Zhuo Y, 2020, THEOR CULT SOC, V37, P77, DOI 10.1177/0263276420910464	57	0	0	0	0	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0277-3945	1930-322X		RHETOR SOC Q	Rhetor. Soc. Q.	2024 JUN 5	2024										10.1080/02773945.2024.2343615	http://dx.doi.org/10.1080/02773945.2024.2343615		JUN 2024	14	Communication; Literature; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Communication; Literature; Philosophy	UJ5K9					2024-07-03	WOS:001247701600001
C	Zhang, HC; Korikov, A; Farinneya, P; Pour, MMA; Bharadwaj, M; Pesaranghader, A; Huang, XY; Lok, YX; Wang, ZQ; Jones, N; Sanner, S			ACM	Zhang, Haochen; Korikov, Anton; Farinneya, Parsa; Pour, Mohammad Mahdi Abdollah; Bharadwaj, Manasa; Pesaranghader, Ali; Huang, Xi Yu; Lok, Yi Xin; Wang, Zhaoqi; Jones, Nathan; Sanner, Scott			Recipe-MPR: A Test Collection for Evaluating Multi-aspect Preference-based Natural Language Retrieval	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		multi-aspect preference retrieval; natural language reasoning; recipe retrieval; benchmark dataset		The rise of interactive recommendation assistants has led to a novel domain of natural language (NL) recommendation that would benefit from improved multi-aspect reasoning to retrieve relevant items based on NL statements of preference. Such preference statements often involve multiple aspects, e.g., "I would like meat lasagna but I'm watching my weight". Unfortunately, progress in this domain is slowed by the lack of annotated data. To address this gap, we curate a novel dataset1 which captures logical reasoning over multiaspect, NL preference-based queries and a set of multiple-choice, multi-aspect item descriptions. We focus on the recipe domain in which multi-aspect preferences are often encountered due to the complexity of the human diet. The goal of publishing our dataset is to provide a benchmark for joint progress in three key areas: 1) structured, multi-aspect NL reasoning with a variety of properties (e.g., level of specificity, presence of negation, and the need for commonsense, analogical, and/or temporal inference), 2) the ability of recommender systems to respond to NL preference utterances, and 3) explainable NL recommendation facilitated by aspect extraction and reasoning. We perform experiments using a variety of methods (sparse and dense retrieval, zero- and few-shot reasoning with large language models) in two settings: a monolithic setting which uses the full query and an aspect-based setting which isolates individual query aspects and aggregates the results. GPT-3 results in much stronger performance than other methods with 73% zeroshot accuracy and 83% few-shot accuracy in the monolithic setting. Aspect-based GPT-3, which facilitates structured explanations, also shows promise with 68% zero-shot accuracy. These results establish baselines for future research into explainable recommendations via multi-aspect preference-based NL reasoning.	[Zhang, Haochen; Korikov, Anton; Farinneya, Parsa; Pour, Mohammad Mahdi Abdollah; Huang, Xi Yu; Lok, Yi Xin; Wang, Zhaoqi; Jones, Nathan; Sanner, Scott] Univ Toronto, Toronto, ON, Canada; [Bharadwaj, Manasa; Pesaranghader, Ali] LG Elect, Toronto AI Lab, Toronto, ON, Canada; [Sanner, Scott] Vector Inst Artificial Intelligence, Toronto, ON, Canada	University of Toronto; Vector Institute for Artificial Intelligence	Zhang, HC (corresponding author), Univ Toronto, Toronto, ON, Canada.	hcz.zhang@mail.utoronto.ca; anton.korikov@mail.utoronto.ca; parsa.farinneya@mail.utoronto.ca; m.abdollahpour@mail.utoronto.ca; manasa.bharadwaj@lge.com; ali.pesaranghader@lge.com; xiyu.huang@mail.utoronto.ca; y.lok@mail.utoronto.ca; mr.wang@mail.utoronto.ca; nathan.jones@mail.utoronto.ca; ssanner@mie.utoronto.ca	Zhaoqi, Wang/GYU-5131-2022	Lok, Yi Xin/0009-0000-9240-3357	LG Electronics, Toronto AI Lab Grant [2022-1473]	LG Electronics, Toronto AI Lab Grant	We would like to thank Zhenwei Tang and Touqir Sajed for their valuable assistance. This work was supported by LG Electronics, Toronto AI Lab Grant Ref #2022-1473.	Bird S., 2009, NATURAL LANGUAGE PRO; Camburu OM, 2018, ADV NEUR IN, V31; Clark Christopher, 2019, ARXIV190510044; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; DeYoung Jay, 2019, ARXIV191103429; Fu Zuohui, 2020, ARXIV200809237; Gao CM, 2021, AI OPEN, V2, P100, DOI 10.1016/j.aiopen.2021.06.002; Gao Jianfeng, 2022, ARXIV220105176; Haussmann S, 2019, LECT NOTES COMPUT SC, V11779, P146, DOI 10.1007/978-3-030-30796-7_10; Hofstätter S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P113, DOI 10.1145/3404835.3462891; Jaques Natasha, 2019, ARXIV190700456; Joshi C.K., 2017, NIPS CONV AI WORKSH; Kang C., 2012, Proceedings of the Fifth ACM International Conference on Web Search and Data Mining, WSDM '12, P453, DOI 10.1145/2124295.2124350; Khashabi Daniel, 2018, P 2018 C N AM CHAPT, V1, P252, DOI 10.18653/v1/N18-1023; Kong WZ, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3178, DOI 10.1145/3534678.3539137; Lei T., 2016, RATIONALIZING NEURAL, P107; Li RYM, 2018, ADV INTELL SYST, V595, P31, DOI 10.1007/978-3-319-60384-1_4; Li SK, 2023, LECT NOTES ARTIF INT, V13714, P740, DOI 10.1007/978-3-031-26390-3_43; Li SK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103067; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lyu S, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P866, DOI 10.1145/3442381.3450123; MacCartney B., 2008, COLING 2008, P521; Manning C.D., 2008, Introduction to information retrieval; Marin J, 2021, IEEE T PATTERN ANAL, V43, P187, DOI 10.1109/TPAMI.2019.2927476; McAuley J., 2013, P 7 ACM C REC SYST, P165, DOI DOI 10.1145/2507157.2507163; Neelakantan Arvind, 2022, ARXIV220110005; Ouyang Long, 2022, ARXIV220302155; Perez Ethan, 2019, ARXIV190905863; Pour MMA, 2023, LECT NOTES COMPUT SC, V13980, P3, DOI 10.1007/978-3-031-28244-7_1; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radlinski F, 2019, 20TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2019), P353; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Rogers A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560260; Russell SJ., 2016, ARTIF INTELL; Volokhin S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3091; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang A, 2019, ADV NEUR IN, V32; Wei Jason, 2022, arXiv:2201.11903; Weston J., 2019, ARXIV190105415; Yi Sanghyun, 2019, ARXIV190413015; Zaidan Omar, 2008, Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, P31; Zhang Honghua, 2022, ARXIV220511502; Zhang S., 2022, arXiv; Zhou K., 2020, ARXIV201004125	46	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							2744	2753		10.1145/3539618.3591880	http://dx.doi.org/10.1145/3539618.3591880			10	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG					2024-07-03	WOS:001118084002132
J	Brozovic, J; Mikulic, B; Tomas, M; Juzbas, M; Blaskovic, M				Brozovic, Juraj; Mikulic, Barbara; Tomas, Matej; Juzbas, Martina; Blaskovic, Marko			Assessing the performance of Bing Chat artificial intelligence: Dental exams, clinical guidelines, and patients' frequent questions	JOURNAL OF DENTISTRY			English	Article						Artificial intelligence; Dentistry; Dental informatics; Dental education; Dental ethics	VISUAL ANALOG SCALE	Objectives: Bing Chat is a large language model artificial intelligence (AI) with online search and text generating capabilities. This study assessed its performance within the scope of dentistry in: (a) tackling exam questions for dental students, (ii) providing guidelines for dental practitioners, and (iii) answering patients' frequently asked questions. We discuss the potential of clinical tutoring, common patient communication and impact on academia. Methods: With the aim of assessing AI's performance in dental exams, Bing Chat was presented with 532 multiplechoice questions and awarded scores based on its answers. In evaluating guidelines for clinicians, a further set of 15 questions, each with 2 follow-up questions on clinical protocols, was presented to the AI. The answers were assessed by 4 reviewers using electronic visual analog scale. In evaluating answers to patients' frequently asked questions, another list of 15 common questions was included in the session, with respective outputs assessed. Results: Bing Chat correctly answered 383 out of 532 multiple-choice questions in dental exam part, achieving a score of 71.99 %. As for outlining clinical protocols for practitioners, the overall assessment score was 81.05 %. In answering patients' frequently asked questions, Bing Chat achieved an overall mean score of 83.8 %. The assessments demonstrated low inter-rater reliability. CONCLUSIONS: The overall performance of Bing Chat was above the regularly adopted passing scores, particularly in answering patient's frequently asked questions. The generated content may have biased sources. These results suggest the importance of raising clinicians' awareness of AI's benefits and risks, as well as timely adaptations of dental education curricula, and safeguarding its use in dentistry and healthcare in general. Clinical significance: Bing Chat AI performed above the passing threshold in three categories, and thus demonstrated potential for educational assistance, clinical tutoring, and answering patients' questions. We recommend popularizing its benefits and risks among students and clinicians, while maintaining awareness of possible false information.	[Brozovic, Juraj] Univ Osijek, Fac Dent Med & Hlth, Oral Surg, Osijek, Croatia; [Mikulic, Barbara; Juzbas, Martina] Univ Osijek, Fac Dent Med & Hlth, Osijek, Croatia; [Tomas, Matej] Univ Osijek, Fac Dent Med & Hlth, Osijek, Croatia; [Blaskovic, Marko] Univ Rijeka, Fac Dent Med, Dept Oral Surg, Oral Surg, Rijeka, Croatia	University of JJ Strossmayer Osijek; University of JJ Strossmayer Osijek; University of JJ Strossmayer Osijek; University of Rijeka	Brozovic, J (corresponding author), Univ Osijek, Fac Dent Med & Hlth, Oral Surg, Osijek, Croatia.	jbrozovic@fdmz.hr		, Juraj/0009-0002-1898-9243; Juzbasic, Martina/0000-0001-9211-6251				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ali K, 2023, Preprints, DOI [10.20944/preprints202302.0513.v1, 10.20944/preprints202302.0513.v1, DOI 10.20944/PREPRINTS202302.0513.V1]; Arsiwala-Scheppach LT, 2024, J DENT, V140, DOI 10.1016/j.jdent.2023.104793; Bernea JV, 2023, J DENT, V135, DOI 10.1016/j.jdent.2023.104581; Bijur PE, 2001, ACAD EMERG MED, V8, P1153, DOI 10.1111/j.1553-2712.2001.tb01132.x; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Chang H.M., 2023, Spotlight on Beijing Institute for General Artificial Intelligence; Chang R, 2018, EVAL HEALTH PROF, V41, P246, DOI 10.1177/0163278718759396; Dao XQ, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-kxxpd, 10.26434/chemrxiv-2023-kxxpd, DOI 10.26434/CHEMRXIV-2023-KXXPD]; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Heller GZ, 2016, SCAND J PAIN, V13, P67, DOI 10.1016/j.sjpain.2016.06.012; Kuhlmann T, 2017, BEHAV RES METHODS, V49, P2173, DOI 10.3758/s13428-016-0850-x; Lehnert Bernhard, 2015, CRAN; Liu Jinyuan, 2016, Shanghai Arch Psychiatry, V28, P115, DOI 10.11919/j.issn.1002-0829.216045; Mangano FG, 2023, J DENT, V133, DOI 10.1016/j.jdent.2023.104485; Maslej N., 2023, The ai index 2023 annual report; Microsoft, 2023, NEW BING OUR APPROAC; Microsoft, 2023, Microsoft Responsible AI Standard; Nogueira-Reis F, 2024, J DENT, V141, DOI 10.1016/j.jdent.2023.104829; Pfänder L, 2023, J DENT, V135, DOI 10.1016/j.jdent.2023.104588; Schwendicke F, 2020, J DENT RES, V99, P769, DOI 10.1177/0022034520915714; Shan T, 2021, J DENT RES, V100, P232, DOI 10.1177/0022034520969115; Tang L, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231186064; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Tiwari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40367; UNESCO, 2023, Foundation Models such as ChatGPT through the prism of the UNESCO; Vasconcelos M.A.R., 2023, Eurasia J. Math. Sci. Technol. Educ, V19, pem2296, DOI [10.29333/ejmste/13313, DOI 10.29333/EJMSTE/13313]; Zhu MY, 2024, J DENT, V141, DOI 10.1016/j.jdent.2023.104808	29	0	0	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0300-5712	1879-176X		J DENT	J. Dent.	MAY	2024	144								104927	10.1016/j.jdent.2024.104927	http://dx.doi.org/10.1016/j.jdent.2024.104927		MAR 2024	8	Dentistry, Oral Surgery & Medicine	Science Citation Index Expanded (SCI-EXPANDED)	Dentistry, Oral Surgery & Medicine	QD3T7	38458379				2024-07-03	WOS:001218908600001
J	Sun, YS; Chu, WQ; Zhou, H; Wang, KSY; Koike, H				Sun, Yasheng; Chu, Wenqing; Zhou, Hang; Wang, Kaisiyuan; Koike, Hideki			AVI-Talking: Learning Audio-Visual Instructions for Expressive 3D Talking Face Generation	IEEE ACCESS			English	Article						Large language models; audio-visual instruction; diffusion model; expressive talking face generation; contrastive learning		While considerable progress has been made in achieving accurate lip synchronization for 3D speech-driven talking face generation, the task of incorporating expressive facial detail synthesis aligned with the speaker's speaking status remains challenging. Existing efforts either focus on learning a dynamic talking head pose synchronized with speech rhythm or aim for stylized facial movements guided by external reference such as emotional labels or reference video clips. The former works often yield coarse alignment, neglecting the emotional nuances present in the audio content while the latter studies lead to unnatural applications, requiring manual style source selection by users. Our goal is to directly leverage the inherent style information conveyed by human speech for generating an expressive talking face that aligns with the speaking status. In this paper, we propose AVI-Talking, an Audio-Visual Instruction system for expressive Talking face generation. This system harnesses the robust contextual reasoning and hallucination capability offered by Large Language Models (LLMs) to instruct the realistic synthesis of 3D talking faces. Instead of directly learning facial movements from human speech, our two-stage strategy involves the LLMs first comprehending audio information and generating instructions implying expressive facial details seamlessly corresponding to the speech. Subsequently, a diffusion-based generative network executes these instructions. This two-stage process, coupled with the incorporation of LLMs, enhances model interpretability and provides users with flexibility to comprehend instructions and specify desired operations or modifications. Specifically, given a speech clip, we first employ a Q-Former for contrastive alignment the speech features with visual instructions, which is then projected to input text embedding of LLMs. It functions as a prompting strategy, prompting LLMs to generate plausible visual instructions that encompass diverse facial details. In order to use these predicted instructions, a language-guided talking face generation system with disentangled latent space is delicately derived, where the speech content related lip movements and emotion correlated facial expressions are separately represented in speech content space and content irrelevant space. Additionally, we introduce a contrastive instruction-style alignment and diffusion technique within the content-irrelevant space to fully exploit the talking prior network for diverse instruction-following synthesis. Extensive experiments showcase the effectiveness of our approach in producing vivid talking faces with expressive facial movements and consistent emotional status.	[Sun, Yasheng; Koike, Hideki] Tokyo Inst Technol, Tokyo 1528550, Japan; [Chu, Wenqing; Zhou, Hang] Baidu Inc, Beijing 100085, Peoples R China; [Wang, Kaisiyuan] Univ Sydney, Sch Elect & Comp Engn, Darlington, NSW 2008, Australia	Tokyo Institute of Technology; Baidu; University of Sydney	Sun, YS (corresponding author), Tokyo Inst Technol, Tokyo 1528550, Japan.	sun.y.aj@m.titech.ac.jp		Koike, Hideki/0000-0002-8989-6434				Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24; ANEJA S., 2023, ARXIV; Baevski Alexei, 2020, ARXIV200611477; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Cudeiro D, 2019, PROC CVPR IEEE, P10093, DOI 10.1109/CVPR.2019.01034; Danecek R., 2023, PROC SIGGRAPH ASIA C, P1; Danecek R, 2022, PROC CVPR IEEE, P20279, DOI 10.1109/CVPR52688.2022.01967; Esser Patrick, 2021, arXiv, DOI 10.48550/ARXIV.2012.09841; Fan YR, 2022, PROC CVPR IEEE, P18749, DOI 10.1109/CVPR52688.2022.01821; Gan Y., 2023, PROC IEEECVP INT C C, P22634; Guo YD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5764, DOI 10.1109/ICCV48922.2021.00573; Gururani S., 2023, INPROCEEDINGS IEEECV, P20914; Hensel M, 2017, ADV NEUR IN, V30; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Hsu WN, 2021, IEEE-ACM T AUDIO SPE, V29, P3451, DOI 10.1109/TASLP.2021.3122291; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Huang RC, 2023, PROC CVPR IEEE, P12759, DOI 10.1109/CVPR52729.2023.01227; Huang RJ, 2023, Arxiv, DOI arXiv:2304.12995; Ji XY, 2021, PROC CVPR IEEE, P14075, DOI 10.1109/CVPR46437.2021.01386; Ji Xinya, 2022, SPECIAL INTEREST GRO, P1; Kaisiyuan Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P700, DOI 10.1007/978-3-030-58589-1_42; Karras T, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073658; Lam Max W. Y., 2022, PROC INT C LEARN REP; Lavie A., 2007, P 2 WORKSH STAT MACH, P228; Lele Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P35, DOI 10.1007/978-3-030-58545-7_3; Lewis P., 2020, PROC 34 INT C NEURUL, P5; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813; Liang BR, 2022, PROC CVPR IEEE, P3377, DOI 10.1109/CVPR52688.2022.00338; Liang V.W., 2022, Advances in Neural Information Processing Systems, V35, P17612; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391; Ma YF, 2023, Arxiv, DOI arXiv:2312.09767; Ma YF, 2023, Arxiv, DOI arXiv:2301.01081; Ma YF, 2023, Arxiv, DOI arXiv:2304.00334; Mohamed O., 2021, arXiv; Ng E., 2023, PROC IEEECVF INT C C, P10083; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paszke A., 2019, NEURIPS; Peng Z., 2023, PROC IEEECVF INT C C, P20687; Prajwal KR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P484, DOI 10.1145/3394171.3413532; Ramesh A., 2022, arXiv; Ren Z., 2023, PROC IEEE INT C ACOU, P1; Richard A, 2021, IEEE WINT CONF APPL, P41, DOI 10.1109/WACV48630.2021.00009; Richard A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1153, DOI 10.1109/ICCV48922.2021.00121; Sadoughi N, 2021, IEEE T AFFECT COMPUT, V12, P1031, DOI 10.1109/TAFFC.2019.2916031; Schick T., 2023, arXiv; Sinha S., 2022, arXiv; Sun Y., 2023, arXiv; Sun Y., 2021, PROC 30 INT JOINT C, V2, P4; Sun YS, 2022, PROCEEDINGS SIGGRAPH ASIA 2022, DOI 10.1145/3550469.3555393; Sun ZY, 2024, Arxiv, DOI arXiv:2310.00434; Tan S., 2023, PROC IEEECVP INT C C, P22146; Tevet Guy, 2022, arXiv; Thambiraja B., 2023, PROC IEEECVF INT C C, P20621; Thies Justus, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P716, DOI 10.1007/978-3-030-58517-4_42; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; van den Oord A, 2016, ADV NEUR IN, V29; Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8; Wang C., 2023, arXiv; Wang DM, 2023, Arxiv, DOI arXiv:2311.17465; Wang QZ, 2019, PROC CVPR IEEE, P4190, DOI 10.1109/CVPR.2019.00432; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41; Wu HZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1478, DOI 10.1145/3474085.3475280; Wu SQ, 2023, Arxiv, DOI arXiv:2309.05519; Xing JB, 2023, PROC CVPR IEEE, P12780, DOI 10.1109/CVPR52729.2023.01229; Xu C, 2023, PROC CVPR IEEE, P6609, DOI 10.1109/CVPR52729.2023.00639; Xu YX, 2023, Arxiv, DOI arXiv:2312.10381; Ya L., 2024, PROC 12 INT C LEARN, P6; Yu Z., 2023, PROC IEEECVF INT C C, P7645; Zeng A., 2023, PROC 11 INT C LEARN, P1; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang WX, 2023, PROC CVPR IEEE, P8652, DOI 10.1109/CVPR52729.2023.00836; Zheng KZ, 2024, Arxiv, DOI arXiv:2310.02239; Zhou H, 2021, PROC CVPR IEEE, P4174, DOI 10.1109/CVPR46437.2021.00416; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	81	0	0	3	3	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						57288	57301		10.1109/ACCESS.2024.3390182	http://dx.doi.org/10.1109/ACCESS.2024.3390182			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	OR1D6		Green Submitted, gold			2024-07-03	WOS:001208900400001
J	Ahmed, W; Saturno, M; Rajjoub, R; Duey, AH; Zaidat, B; Hoang, T; Mejia, MR; Gallate, ZS; Shrestha, N; Tang, JS; Zapolsky, I; Kim, JS; Cho, SK				Ahmed, Wasil; Saturno, Michael; Rajjoub, Rami; Duey, Akiro H.; Zaidat, Bashar; Hoang, Timothy; Restrepo Mejia, Mateo; Gallate, Zachary S.; Shrestha, Nancy; Tang, Justin; Zapolsky, Ivan; Kim, Jun S.; Cho, Samuel K.			ChatGPT versus NASS clinical guidelines for degenerative spondylolisthesis: a comparative analysis	EUROPEAN SPINE JOURNAL			English	Article; Early Access						Degenerative spondylolisthesis; Clinical guidelines; Artificial intelligence; Large language models; Spine	CONSERVATIVE MANAGEMENT; DIAGNOSIS	Background contextClinical guidelines, developed in concordance with the literature, are often used to guide surgeons' clinical decision making. Recent advancements of large language models and artificial intelligence (AI) in the medical field come with exciting potential. OpenAI's generative AI model, known as ChatGPT, can quickly synthesize information and generate responses grounded in medical literature, which may prove to be a useful tool in clinical decision-making for spine care. The current literature has yet to investigate the ability of ChatGPT to assist clinical decision making with regard to degenerative spondylolisthesis.PurposeThe study aimed to compare ChatGPT's concordance with the recommendations set forth by The North American Spine Society (NASS) Clinical Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and assess ChatGPT's accuracy within the context of the most recent literature.MethodsChatGPT-3.5 and 4.0 was prompted with questions from the NASS Clinical Guideline for the Diagnosis and Treatment of Degenerative Spondylolisthesis and graded its recommendations as "concordant" or "nonconcordant" relative to those put forth by NASS. A response was considered "concordant" when ChatGPT generated a recommendation that accurately reproduced all major points made in the NASS recommendation. Any responses with a grading of "nonconcordant" were further stratified into two subcategories: "Insufficient" or "Over-conclusive," to provide further insight into grading rationale. Responses between GPT-3.5 and 4.0 were compared using Chi-squared tests.ResultsChatGPT-3.5 answered 13 of NASS's 28 total clinical questions in concordance with NASS's guidelines (46.4%). Categorical breakdown is as follows: Definitions and Natural History (1/1, 100%), Diagnosis and Imaging (1/4, 25%), Outcome Measures for Medical Intervention and Surgical Treatment (0/1, 0%), Medical and Interventional Treatment (4/6, 66.7%), Surgical Treatment (7/14, 50%), and Value of Spine Care (0/2, 0%). When NASS indicated there was sufficient evidence to offer a clear recommendation, ChatGPT-3.5 generated a concordant response 66.7% of the time (6/9). However, ChatGPT-3.5's concordance dropped to 36.8% when asked clinical questions that NASS did not provide a clear recommendation on (7/19). A further breakdown of ChatGPT-3.5's nonconcordance with the guidelines revealed that a vast majority of its inaccurate recommendations were due to them being "over-conclusive" (12/15, 80%), rather than "insufficient" (3/15, 20%). ChatGPT-4.0 answered 19 (67.9%) of the 28 total questions in concordance with NASS guidelines (P = 0.177). When NASS indicated there was sufficient evidence to offer a clear recommendation, ChatGPT-4.0 generated a concordant response 66.7% of the time (6/9). ChatGPT-4.0's concordance held up at 68.4% when asked clinical questions that NASS did not provide a clear recommendation on (13/19, P = 0.104).ConclusionsThis study sheds light on the duality of LLM applications within clinical settings: one of accuracy and utility in some contexts versus inaccuracy and risk in others. ChatGPT was concordant for most clinical questions NASS offered recommendations for. However, for questions NASS did not offer best practices, ChatGPT generated answers that were either too general or inconsistent with the literature, and even fabricated data/citations. Thus, clinicians should exercise extreme caution when attempting to consult ChatGPT for clinical recommendations, taking care to ensure its reliability within the context of recent literature.	[Ahmed, Wasil; Saturno, Michael; Rajjoub, Rami; Duey, Akiro H.; Zaidat, Bashar; Hoang, Timothy; Restrepo Mejia, Mateo; Gallate, Zachary S.; Tang, Justin] Icahn Sch Med Mt Sinai, New York, NY USA; [Shrestha, Nancy] Rosalind Franklin Univ, Chicago Med Sch, N Chicago, IL USA; [Zapolsky, Ivan; Kim, Jun S.; Cho, Samuel K.] Icahn Sch Med Mt Sinai, Dept Orthoped, One Gustave L Levy Pl, New York, NY 10029 USA	Icahn School of Medicine at Mount Sinai; Rosalind Franklin University of Medicine & Science; Chicago Medical School; Icahn School of Medicine at Mount Sinai	Cho, SK (corresponding author), Icahn Sch Med Mt Sinai, Dept Orthoped, One Gustave L Levy Pl, New York, NY 10029 USA.	Samuel.Cho@mountsinai.org						Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Borodulina I V, 2022, Vopr Kurortol Fizioter Lech Fiz Kult, V99, P45, DOI 10.17116/kurort20229902145; Bydon M, 2019, NEUROSURG CLIN N AM, V30, P299, DOI 10.1016/j.nec.2019.02.003; Caterini R, 2011, J ORTHOP TRAUMATOL, V12, P87, DOI 10.1007/s10195-011-0141-3; CAUCHOIX J, 1976, CLIN ORTHOP RELAT R, P122; Cheung JPY, 2020, BONE JOINT J, V102B, P1062, DOI 10.1302/0301-620X.102B8.BJJ-2020-0528.R1; D'Andrea G, 2005, J SPINAL DISORD TECH, V18, P80, DOI 10.1097/01.bsd.0000133062.43337.81; Demir-Deviren S, 2019, J BACK MUSCULOSKELET, V32, P701, DOI 10.3233/BMR-181185; Eseonu K, 2022, INT J SPINE SURG, V16, P612, DOI 10.14444/8297; Hammouri QM, 2007, SPINE, V32, P2361, DOI 10.1097/BRS.0b013e318155796e; Harrop JS, 2014, SPINE, V39, pS75, DOI 10.1097/BRS.0000000000000545; Huang KY, 2009, EUR SPINE J, V18, P1851, DOI 10.1007/s00586-009-1059-9; Inose H, 2022, SPINE J, V22, P747, DOI 10.1016/j.spinee.2021.12.014; Jackson R, 1998, BRIT MED J, V317, P427; Jones KE, 2019, NEUROSURG CLIN N AM, V30, P365, DOI 10.1016/j.nec.2019.02.010; Kalichman L, 2008, EUR SPINE J, V17, P327, DOI 10.1007/s00586-007-0543-3; Kanno H, 2018, SPINE J, V18, P726, DOI 10.1016/j.spinee.2017.08.251; Karsy M, 2019, NEUROSURG CLIN N AM, V30, P333, DOI 10.1016/j.nec.2019.02.007; Koreckij TD, 2015, J SPINAL DISORD TECH, V28, P236, DOI 10.1097/BSD.0000000000000298; Kreiner DS, 2013, SPINE J, V13, P734, DOI 10.1016/j.spinee.2012.11.059; Leonova ON, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-041134; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Matsunaga S, 2000, J NEUROSURG, V93, P194, DOI 10.3171/spi.2000.93.2.0194; Matz PG, 2016, SPINE J, V16, P439, DOI 10.1016/j.spinee.2015.11.055; McGregor AH, 2002, SPINE, V27, P1582, DOI 10.1097/00007632-200207150-00019; Ozawa H, 2012, AM J NEURORADIOL, V33, P1191, DOI 10.3174/ajnr.A2920; Perugia D, 1991, Ital J Orthop Traumatol, V17; Phan Kevin, 2016, J Spine Surg, V2, P31, DOI 10.21037/jss.2016.01.07; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; ROSENBERG NJ, 1975, J BONE JOINT SURG AM, VA 57, P467, DOI 10.2106/00004623-197557040-00004; Sclafani Joseph A, 2016, PM R, V8, pS160, DOI 10.1016/j.pmrj.2016.07.043; Sencan S, 2017, J BACK MUSCULOSKELET, V30, P841, DOI 10.3233/BMR-160543; Watters WC, 2009, SPINE J, V9, P609, DOI 10.1016/j.spinee.2009.03.016; Yin MC, 2019, J ORTHOP SURG RES, V14, DOI 10.1186/s13018-019-1214-x	35	1	1	3	3	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0940-6719	1432-0932		EUR SPINE J	Eur. Spine J.	2024 MAR 15	2024										10.1007/s00586-024-08198-6	http://dx.doi.org/10.1007/s00586-024-08198-6		MAR 2024	22	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	LB0Q4	38489044				2024-07-03	WOS:001184204000001
J	Carlà, MM; Gambini, G; Baldascino, A; Giannuzzi, F; Boselli, F; Crincoli, E; D'Onofrio, NC; Rizzo, S				Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Giannuzzi, Federico; Boselli, Francesco; Crincoli, Emanuele; D'Onofrio, Nicola Claudio; Rizzo, Stanislao			Exploring AI-chatbots' capability to suggest surgical planning in ophthalmology: ChatGPT versus Google Gemini analysis of retinal detachment cases	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Early Access						Retina; Vitreous; Medical Education; Ophthalmologic Surgical Procedures; Surveys and Questionnaires		Background We aimed to define the capability of three different publicly available large language models, Chat Generative Pretrained Transformer (ChatGPT-3.5), ChatGPT-4 and Google Gemini in analysing retinal detachment cases and suggesting the best possible surgical planning.Methods Analysis of 54 retinal detachments records entered into ChatGPT and Gemini's interfaces. After asking 'Specify what kind of surgical planning you would suggest and the eventual intraocular tamponade.' and collecting the given answers, we assessed the level of agreement with the common opinion of three expert vitreoretinal surgeons. Moreover, ChatGPT and Gemini answers were graded 1-5 (from poor to excellent quality), according to the Global Quality Score (GQS).Results After excluding 4 controversial cases, 50 cases were included. Overall, ChatGPT-3.5, ChatGPT-4 and Google Gemini surgical choices agreed with those of vitreoretinal surgeons in 40/50 (80%), 42/50 (84%) and 35/50 (70%) of cases. Google Gemini was not able to respond in five cases. Contingency analysis showed significant differences between ChatGPT-4 and Gemini (p=0.03). ChatGPT's GQS were 3.9 +/- 0.8 and 4.2 +/- 0.7 for versions 3.5 and 4, while Gemini scored 3.5 +/- 1.1. There was no statistical difference between the two ChatGPTs (p=0.22), while both outperformed Gemini scores (p=0.03 and p=0.002, respectively). The main source of error was endotamponade choice (14% for ChatGPT-3.5 and 4, and 12% for Google Gemini). Only ChatGPT-4 was able to suggest a combined phacovitrectomy approach.Conclusion In conclusion, Google Gemini and ChatGPT evaluated vitreoretinal patients' records in a coherent manner, showing a good level of agreement with expert surgeons. According to the GQS, ChatGPT's recommendations were much more accurate and precise.	[Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Giannuzzi, Federico; Boselli, Francesco; Crincoli, Emanuele; D'Onofrio, Nicola Claudio; Rizzo, Stanislao] Univ Cattolica Sacro Cuore, Ophthalmol Dept, Rome, Italy; [Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Giannuzzi, Federico; Boselli, Francesco; Crincoli, Emanuele; D'Onofrio, Nicola Claudio; Rizzo, Stanislao] Fdn Policlin Univ A Gemelli, IRCCS, Ophthalmol Dept, Rome, Italy	Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli; Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli	Carlà, MM (corresponding author), Univ Cattolica Sacro Cuore, Ophthalmol Dept, Rome, Italy.	mm.carla94@gmail.com	Crincoli, Emanuele/IQS-0367-2023	Crincoli, Emanuele/0000-0001-9996-9871; Carla, Matteo Mario/0000-0003-2979-1638				Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Alser M., 2023, Am J Medicine Open, V9, P100036, DOI [DOI 10.1016/J.AJMO.2023.100036, 10.1016/j.ajmo.2023.100036]; [Anonymous], 2021, INT C MACHINE LEARNI; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Banerjee PJ, 2017, EYE, V31, P1302, DOI 10.1038/eye.2017.167; Bernard A, 2007, AM J GASTROENTEROL, V102, P2070, DOI 10.1111/j.1572-0241.2007.01325.x; Chat GPT Google Bard AI: A Review, 2023, International Conference on IoT, Communication and Automation Technology (ICICAT); Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Fisher S, 2022, BMC PUBLIC HEALTH, V22, DOI 10.1186/s12889-022-14422-z; Gan RK, 2024, AM J EMERG MED, V75, P72, DOI 10.1016/j.ajem.2023.10.034; Govers BM, 2022, ACTA OPHTHALMOL, V100, pE1600, DOI 10.1111/aos.15144; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; OpenAI, 2023, Gpt-4 is openai's most advanced system, producing safer and more useful responses; Ozdemir S., 2023, Quick Start Guide to Large Language Models: Strategies and Best Practices for Using ChatGPT and Other LLMs; Pichai S., 2023, Google; Pryss R., 2019, New Developments in Psychoinformatics, DOI [10.1007/978-3-030-31620-4, DOI 10.1007/978-3-030-31620-4]; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Team G, 2024, Bard becomes Gemini: try Ultra 1.0 and a new mobile app today; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thoppilan R., Lamda: Language models for dialog applications; Waisberg E, 2024, EYE, V38, P642, DOI 10.1038/s41433-023-02760-0; Zagabathuni Y., 2022, Int J, V10, P195	27	5	5	7	7	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161	1468-2079		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	2024 MAR 6	2024										10.1136/bjo-2023-325143	http://dx.doi.org/10.1136/bjo-2023-325143		MAR 2024	13	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	KR4W2	38448201				2024-07-03	WOS:001181690500001
J	Milad, D; Antaki, F; Milad, J; Farah, A; Khairy, T; Mikhail, D; Giguere, CÉ; Touma, S; Bernstein, A; Szigiato, AA; Nayman, T; Mullie, GA; Duval, R				Milad, Daniel; Antaki, Fares; Milad, Jason; Farah, Andrew; Khairy, Thomas; Mikhail, David; Giguere, Charles-Edouard; Touma, Samir; Bernstein, Allison; Szigiato, Andrei-Alexandru; Nayman, Taylor; Mullie, Guillaume A.; Duval, Renaud			Assessing the medical reasoning skills of GPT-4 in complex ophthalmology cases	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Early Access								Background/aims This study assesses the proficiency of Generative Pre-trained Transformer (GPT)-4 in answering questions about complex clinical ophthalmology cases. Methods We tested GPT-4 on 422 Journal of the American Medical Association Ophthalmology Clinical Challenges, and prompted the model to determine the diagnosis (open-ended question) and identify the next-step (multiple-choice question). We generated responses using two zero-shot prompting strategies, including zero-shot plan-and-solve+ (PS+), to improve the reasoning of the model. We compared the best-performing model to human graders in a benchmarking effort. Results Using PS+ prompting, GPT-4 achieved mean accuracies of 48.0% (95% CI (43.1% to 52.9%)) and 63.0% (95% CI (58.2% to 67.6%)) in diagnosis and next step, respectively. Next-step accuracy did not significantly differ by subspecialty (p=0.44). However, diagnostic accuracy in pathology and tumours was significantly higher than in uveitis (p=0.027). When the diagnosis was accurate, 75.2% (95% CI (68.6% to 80.9%)) of the next steps were correct. Conversely, when the diagnosis was incorrect, 50.2% (95% CI (43.8% to 56.6%)) of the next steps were accurate. The next step was three times more likely to be accurate when the initial diagnosis was correct (p<0.001). No significant differences were observed in diagnostic accuracy and decision-making between board-certified ophthalmologists and GPT-4. Among trainees, senior residents outperformed GPT-4 in diagnostic accuracy (p <= 0.001 and 0.049) and in accuracy of next step (p=0.002 and 0.020). Conclusion Improved prompting enhances GPT-4's performance in complex clinical situations, although it does not surpass ophthalmology trainees in our context. Specialised large language models hold promise for future assistance in medical decision-making and diagnosis.	[Milad, Daniel; Antaki, Fares; Touma, Samir; Bernstein, Allison; Szigiato, Andrei-Alexandru; Nayman, Taylor; Mullie, Guillaume A.; Duval, Renaud] Univ Montreal, Dept Ophthalmol, Montreal, PQ, Canada; [Milad, Daniel; Touma, Samir; Bernstein, Allison; Nayman, Taylor; Duval, Renaud] Hop Maisonneuve Rosement, Dept Ophthalmol, Montreal, PQ, Canada; [Antaki, Fares] UCL, Inst Ophthalmol, London, England; [Antaki, Fares] Ctr Hosp Univ Montreal CHUM, CHUM Sch Artificial Intelligence Healthcare SAIH, Montreal, PQ, Canada; [Milad, Jason] Univ Waterloo, Dept Software Engn, Waterloo, ON, Canada; [Farah, Andrew; Khairy, Thomas] McGill Univ, Fac Med, Montreal, PQ, Canada; [Mikhail, David] Univ Toronto, Fac Med, Toronto, ON, Canada; [Giguere, Charles-Edouard] Ctr Rech Inst Univ St Mentale Montreal, Montreal, PQ, Canada; [Szigiato, Andrei-Alexandru] Hop Sacre Coeur Montreal, Dept Ophthalmol, Montreal, PQ, Canada; [Mullie, Guillaume A.] Cite St Hosp, Dept Ophthalmol, Laval, PQ, Canada; [Duval, Renaud] Univ Montreal, Dept Ophthalmol, Montreal, PQ, Canada	Universite de Montreal; University of London; University College London; Universite de Montreal; University of Waterloo; McGill University; University of Toronto; Universite de Montreal; Universite de Montreal	Duval, R (corresponding author), Univ Montreal, Dept Ophthalmol, Montreal, PQ, Canada.	rrenaud.duval@gmail.com	Antaki, Fares/GSI-6622-2022	Antaki, Fares/0000-0001-6679-7276; Mikhail, David/0009-0009-0831-1915; Touma, Samir/0000-0002-6365-0946; Farah, Andrew/0009-0005-3165-4829; Milad, Daniel/0000-0002-0693-3421; Szigiato, Andrei-Alexandru/0000-0003-0862-9068				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Antaki F, 2023, BRIT J OPHTHALMOL, DOI 10.1136/bjo-2023-324438; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Betzler BK, 2023, LANCET DIGIT HEALTH, V5, pE917, DOI 10.1016/S2589-7500(23)00201-7; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buckley T., 2023, arXiv; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Delsoz M, 2023, medRxiv, DOI [10.1101/2023.08.25.23294635, 10.1101/2023.08.25.23294635, DOI 10.1101/2023.08.25.23294635]; Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; Eriksen AV., NEJM AI, 2023; Espejel JL, 2023, Arxiv, DOI arXiv:2305.12477; Ha JF, 2010, OCHSNER J, V10, P38; Hamel P, 2007, CAN J OPHTHALMOL, V42, P299, DOI 10.3129/canjophthalmol.i07-006; Hochmair HH, 2024, Arxiv, DOI arXiv:2401.02404; Li CM, 2023, Arxiv, DOI arXiv:2312.16337; Madadi Y., 2023, PREPRINT, DOI [10.1101/2023.09.13.23295508, DOI 10.1101/2023.09.13.23295508]; McCannel CA, 2022, JAMA OPHTHALMOL, V140, P225, DOI 10.1001/jamaophthalmol.2021.6173; McDuff D., 2023, arXiv; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Teebagy S, 2023, medRxiv, DOI [10.1101/2023.04.03.23287957, 10.1101/2023.04.03.23287957, DOI 10.1101/2023.04.03.23287957]; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x	27	1	1	6	6	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161	1468-2079		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	2024 FEB 16	2024										10.1136/bjo-2023-325053	http://dx.doi.org/10.1136/bjo-2023-325053		FEB 2024	8	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	IF2H4	38365427				2024-07-03	WOS:001164842100001
J	Lemke, HU; Mathis-Ullrich, F				Lemke, Heinz U.; Mathis-Ullrich, Franziska			Design criteria for AI-based IT systems	INTERNATIONAL JOURNAL OF COMPUTER ASSISTED RADIOLOGY AND SURGERY			English	Editorial Material; Early Access								Purpose This editorial relates to a panel discussion during the CARS 2023 congress that addressed the question on how AI-based IT systems should be designed that record and (transparently) display a reproducible path on clinical decision making. Even though the software engineering approach suggested for this endeavor is of a generic nature, it is assumed that the listed design criteria are applicable to IT system development also for the domain of radiology and surgery.Methods An example of a possible design approach is outlined by illustrating on how to move from data, information, knowledge and models to wisdom-based decision making in the context of a conceptual GPT system design. In all these design steps, the essential requirements for system quality, information quality, and service quality may be realized by following the design cycle as suggested by A.R. Hevner, appropriately applied to AI-based IT systems design.Results It can be observed that certain state-of-the-art AI algorithms and systems, such as large language models or generative pre-trained transformers (GPTs), are becoming increasingly complex and, therefore, need to be rigorously examined to render them transparent and comprehensible in their usage for all stakeholders involved in health care. Further critical questions that need to be addressed are outlined and complemented with some suggestions, that a possible design framework for a stakeholder specific AI system could be a (modest) GPT based on a small language model.Discussion A fundamental question for the future remains whether society wants a quasi-wisdom-oriented healthcare system, based on data-driven intelligence with AI, or a human curated wisdom based on model-driven intelligence (with and without AI). Special CARS workshops and think tanks are planned to address this challenging question and possible new direction for assisting selected medical disciplines, e.g., radiology and surgery.	[Lemke, Heinz U.] Int Fdn Comp Assisted Radiol & Surg IFCARS, Kussaberg, Germany; [Mathis-Ullrich, Franziska] Friedrich Alexander Univ Erlangen Nuremberg, Erlangen, Germany	University of Erlangen Nuremberg	Lemke, HU (corresponding author), Int Fdn Comp Assisted Radiol & Surg IFCARS, Kussaberg, Germany.	hulemke@cars-int.org; franziska.mathis-ullrich@fau.de						Guo Z, 2023, Arxiv, DOI [arXiv:2305.07804, 10.48550/arXiv.2305.07804, DOI 10.48550/ARXIV.2305.07804]; HEVNER A., 2007, Scand. J. Inf. Syst., V19, P87; Lemke HU, 2022, INT J COMPUT ASS RAD, V17, P1513, DOI 10.1007/s11548-022-02731-y; Liew A., 2023, Bus Manag Dyn, V2, P49; Maier-Hein L, 2017, NAT BIOMED ENG, V1, P691, DOI 10.1038/s41551-017-0132-7; Weizenbaum J, 2003, Ethik und Informationstechnik am Beispiel der Telemedizin, P58	6	1	1	3	3	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	1861-6410	1861-6429		INT J COMPUT ASS RAD	Int. J. Comput. Assist. Radiol. Surg.	2024 JAN 25	2024										10.1007/s11548-024-03064-8	http://dx.doi.org/10.1007/s11548-024-03064-8		JAN 2024	6	Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Radiology, Nuclear Medicine & Medical Imaging; Surgery	GB9L1	38270812	Bronze			2024-07-03	WOS:001150316100001
J	Ligeti, B; Szepesi-Nagy, I; Bodnar, B; Ligeti-Nagy, N; Juhász, J				Ligeti, Balazs; Szepesi-Nagy, Istvan; Bodnar, Babett; Ligeti-Nagy, Noemi; Juhasz, Janos			ProkBERT family: genomic language models for microbiome applications	FRONTIERS IN MICROBIOLOGY			English	Article						genomic language models; language models; promoter; phage; BERT; transformer models; LCA tokenization; machine learning in microbiology	CD-HIT	BackgroundIn the evolving landscape of microbiology and microbiome analysis, the integration of machine learning is crucial for understanding complex microbial interactions, and predicting and recognizing novel functionalities within extensive datasets. However, the effectiveness of these methods in microbiology faces challenges due to the complex and heterogeneous nature of microbial data, further complicated by low signal-to-noise ratios, context-dependency, and a significant shortage of appropriately labeled datasets. This study introduces the ProkBERT model family, a collection of large language models, designed for genomic tasks. It provides a generalizable sequence representation for nucleotide sequences, learned from unlabeled genome data. This approach helps overcome the above-mentioned limitations in the field, thereby improving our understanding of microbial ecosystems and their impact on health and disease.MethodsProkBERT models are based on transfer learning and self-supervised methodologies, enabling them to use the abundant yet complex microbial data effectively. The introduction of the novel Local Context-Aware (LCA) tokenization technique marks a significant advancement, allowing ProkBERT to overcome the contextual limitations of traditional transformer models. This methodology not only retains rich local context but also demonstrates remarkable adaptability across various bioinformatics tasks.ResultsIn practical applications such as promoter prediction and phage identification, the ProkBERT models show superior performance. For promoter prediction tasks, the top-performing model achieved a Matthews Correlation Coefficient (MCC) of 0.74 for E. coli and 0.62 in mixed-species contexts. In phage identification, ProkBERT models consistently outperformed established tools like VirSorter2 and DeepVirFinder, achieving an MCC of 0.85. These results underscore the models' exceptional accuracy and generalizability in both supervised and unsupervised tasks.ConclusionsThe ProkBERT model family is a compact yet powerful tool in the field of microbiology and bioinformatics. Its capacity for rapid, accurate analyses and its adaptability across a spectrum of tasks marks a significant advancement in machine learning applications in microbiology. The models are available on GitHub (https://github.com/nbrg-ppcu/prokbert) and HuggingFace (https://huggingface.co/nerualbioinfo) providing an accessible tool for the community.	[Ligeti, Balazs; Szepesi-Nagy, Istvan; Bodnar, Babett; Juhasz, Janos] Pazmany Peter Catholic Univ, Fac Informat Technol & Bion, Budapest, Hungary; [Ligeti-Nagy, Noemi] HUN REN Hungarian Res Ctr Linguist, Language Technol Res Grp, Budapest, Hungary; [Juhasz, Janos] Semmelweis Univ, Inst Med Microbiol, Budapest, Hungary	Pazmany Peter Catholic University; Semmelweis University	Ligeti, B (corresponding author), Pazmany Peter Catholic Univ, Fac Informat Technol & Bion, Budapest, Hungary.	ligeti.balazs@itk.ppke.hu		Szepesi-Nagy, Istvan/0009-0005-8849-9006	Hungarian National Development, Research and Innovation (NKFIH) Fund, OTKA PD [138055, EHPC-DEV-2022D10-001]	Hungarian National Development, Research and Innovation (NKFIH) Fund, OTKA PD	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This work was supported by grants of the Hungarian National Development, Research and Innovation (NKFIH) Fund, OTKA PD (138055). The work was also supported by EHPC-DEV-2022D10-001 (Development).	Alhazmi A., 2015, INT J BIOL, V7, P44, DOI DOI 10.5539/ijb.v7n2p44; Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300; Amin R, 2020, BIOINFORMATICS, V36, P4869, DOI 10.1093/bioinformatics/btaa609; [Anonymous], 2012, Mathem. Appl, DOI 10.14708/ma.v40i1.278; [Anonymous], 1998, Biological sequence analysis: probabilistic models of proteins and nucleic acids; Cassiano MHA, 2020, MSYSTEMS, V5, DOI 10.1128/mSystems.00439-20; Aziz RK, 2008, BMC GENOMICS, V9, DOI 10.1186/1471-2164-9-75; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bai GH, 2022, VIRUSES-BASEL, V14, DOI 10.3390/v14020278; Bai ZH, 2022, BIOINFORMATICS, V38, P4264, DOI 10.1093/bioinformatics/btac509; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Camargo AP, 2023, NUCLEIC ACIDS RES, V51, pD733, DOI 10.1093/nar/gkac1037; Cantalapiedra CP, 2021, MOL BIOL EVOL, V38, P5825, DOI 10.1093/molbev/msab293; Chevez-Guardado R, 2021, GENOME BIOL, V22, DOI 10.1186/s13059-021-02514-9; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Cole ST, 1998, NATURE, V393, P537, DOI 10.1038/31159; Dalla-Torre H, 2023, bioRxiv, DOI [10.1101/2023.01.11.523679, 10.1101/2023.01.11.523679, DOI 10.1101/2023.01.11.523679]; Silva SDE, 2011, J THEOR BIOL, V287, P92, DOI 10.1016/j.jtbi.2011.07.017; de la Cruz F, 2000, TRENDS MICROBIOL, V8, P128, DOI 10.1016/S0966-842X(00)01703-0; Delcher AL, 1999, NUCLEIC ACIDS RES, V27, P4636, DOI 10.1093/nar/27.23.4636; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fernandes MA, 2019, J PEDIATR GASTR NUTR, V68, P30, DOI 10.1097/MPG.0000000000002140; Fu LM, 2012, BIOINFORMATICS, V28, P3150, DOI 10.1093/bioinformatics/bts565; Guo JR, 2021, MICROBIOME, V9, DOI 10.1186/s40168-020-00990-y; Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247; Han MZ, 2018, FRONT MICROBIOL, V9, DOI 10.3389/fmicb.2018.03150; He WY, 2018, BMC SYST BIOL, V12, DOI 10.1186/s12918-018-0570-1; Hoarfrost A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30070-8; Jansson JK, 2023, NAT REV MICROBIOL, V21, P296, DOI 10.1038/s41579-022-00811-z; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975; Kelley DR, 2018, GENOME RES, V28, P739, DOI 10.1101/gr.227819.117; Kieft K, 2020, MICROBIOME, V8, DOI 10.1186/s40168-020-00867-0; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158; Li WJ, 2021, NUCLEIC ACIDS RES, V49, pD1020, DOI 10.1093/nar/gkaa1105; Liang GX, 2020, J CROHNS COLITIS, V14, P1600, DOI 10.1093/ecco-jcc/jjaa094; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu B, 2018, BIOINFORMATICS, V34, P33, DOI 10.1093/bioinformatics/btx579; Lowy FD, 1998, NEW ENGL J MED, V339, P520, DOI 10.1056/NEJM199808203390806; Lukashin AV, 1998, NUCLEIC ACIDS RES, V26, P1107, DOI 10.1093/nar/26.4.1107; Meyer F, 2019, BRIEF BIOINFORM, V20, P1151, DOI 10.1093/bib/bbx105; Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068; Nakatsu G, 2018, GASTROENTEROLOGY, V155, P529, DOI 10.1053/j.gastro.2018.04.018; O'Leary NA, 2016, NUCLEIC ACIDS RES, V44, pD733, DOI 10.1093/nar/gkv1189; Paczosa MK, 2016, MICROBIOL MOL BIOL R, V80, P629, DOI 10.1128/MMBR.00078-15; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Popoff MY, 2004, RES MICROBIOL, V155, P568, DOI 10.1016/j.resmic.2004.04.005; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Raffel C, 2020, J MACH LEARN RES, V21; Rahman MS, 2019, MOL GENET GENOMICS, V294, P69, DOI 10.1007/s00438-018-1487-5; Ren J, 2020, QUANT BIOL, V8, P64, DOI 10.1007/s40484-019-0187-4; ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7; Santos-Zavaleta A, 2019, NUCLEIC ACIDS RES, V47, pD212, DOI 10.1093/nar/gky1077; Sapoval N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29268-7; Schackart KE, 2023, FRONT MICROBIOL, V14, DOI 10.3389/fmicb.2023.1078760; Seemann T, 2014, BIOINFORMATICS, V30, P2068, DOI 10.1093/bioinformatics/btu153; Shahmuradov IA, 2017, BIOINFORMATICS, V33, P334, DOI 10.1093/bioinformatics/btw629; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Snell J, 2017, ADV NEUR IN, V30; Solovyev V., 2011, METAGENOMICITAPP, P61, DOI DOI 10.17504/PROTOCOLS.IO.FB4BIQW; Sommer MJ, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008727; Su W, 2021, J MOL BIOL, V433, DOI 10.1016/j.jmb.2021.166860; Tatusova T, 2016, NUCLEIC ACIDS RES, V44, P6614, DOI 10.1093/nar/gkw569; Tenaillon O, 2012, SCIENCE, V335, P457, DOI 10.1126/science.1212986; Umarov RK, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171410; Vaswani A, 2017, ADV NEUR IN, V30; Vazquez-Boland J. A., 2011, Front. Cell. Infect. Microbiol, V1, P3, DOI [10.1128/CMR.14.3.584-640.2001, DOI 10.1128/CMR.14.3.584-640.2001]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Walker PJ, 2022, ARCH VIROL, V167, P2429, DOI 10.1007/s00705-022-05516-5; Wang S, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-36308-0; Wu L.-Y., 2023, bioRxiv, P2023, DOI [10.1101/2023.04.26.538077, DOI 10.1101/2023.04.26.538077]; Yan M, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-41075-2; Yang KM, 2023, MICROBIOME, V11, DOI 10.1186/s40168-023-01463-8; Zdobnov EM, 2001, BIOINFORMATICS, V17, P847, DOI 10.1093/bioinformatics/17.9.847; Zhang M, 2019, BIOINFORMATICS, V35, P2957, DOI 10.1093/bioinformatics/btz016; Zhang S, 2023, NEURO-ONCOL ADV, V5, DOI 10.1093/bioadv/vbad001; Zhang XLL, 2022, NAR GENOM BIOINFORM, V4, DOI 10.1093/nargab/lqac057; Zhao GY, 2017, P NATL ACAD SCI USA, V114, pE6166, DOI 10.1073/pnas.1706359114; Zhou ZH, 2024, Arxiv, DOI [arXiv:2306.15006, 10.48550/arXiv.2306.15006]; Zuo WX, 2022, FRONT CELL INFECT MI, V12, DOI 10.3389/fcimb.2022.918010	83	0	0	6	6	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		1664-302X		FRONT MICROBIOL	Front. Microbiol.	JAN 12	2024	14								1331233	10.3389/fmicb.2023.1331233	http://dx.doi.org/10.3389/fmicb.2023.1331233			19	Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Microbiology	FV5R4	38282738	Green Submitted, Green Published, gold			2024-07-03	WOS:001148647300001
J	Chen, X; Zhang, X; Liu, Y; Wang, ZY; Zhou, YX; Chu, M				Chen, Xi; Zhang, Xin; Liu, Yuan; Wang, Ziyuan; Zhou, Yixin; Chu, Ming			RISK-GPT: Using ChatGPT to construct a reliable risk factor database for all known diseases	JOURNAL OF GLOBAL HEALTH			English	Editorial Material								It is widely acknowledged that a comprehensive understanding of the risk factors associated with the disease is vital for both the general public and medical researchers [1,2]. For the population at large, understanding disease risk factors can enable informed decisions about lifestyle choices and preventative measures, thus contributing to overall health and well-being [3,4]. With knowledge of the disease risk factors, individuals can consciously strive to mitigate their risk, adopt healthier behaviours, and reduce the incidence of preventable diseases. For medical researchers, studying disease risk factors forms the basis of epidemiological investigations [5] that elucidates the complex aetiology of diseases, aiding in identifying causative and contributing factors; consequently, this guides the development of targeted therapeutic approaches, provides clinical guidelines, and drives innovative research on disease prevention and treatment [6]. Moreover, a comprehensive understand -ing of disease risk factors enables the conception of population-specific intervention strategies that contribute to health equity and the broader goal of global health improvement [7]. However, as one of the most popular topics, the literature on disease-related risk fac-tors has increased sharply over the last 20 years from 332 182 (2002) to 1 748 504 (2022). Given that over 120 000 studies were published in a single year, it is impos-sible to finish reading them all, which exerts an information overload on research -ers. These requirements encouraged us to apply a natural language processing (NLP) algorithm to extract risk factor information from numerous studies. The advent of large language models (LLM) such as ChatGPT heralds a new era of automation and cognitive assistance, reshaping engagement with information and decision-making processes [8]. The ChatGPT model has gained recognition for its ability to extract information, demonstrate an in-depth understanding of context, and provide valuable insights across various subjects [9]. This study aimed to develop and evaluate four risk factor extraction models based on ChatGPT. ChatGPT has the potential to develop a risk factor database for all known diseases Human validation is cru-cial to ensure accuracy of information extracted by ChatGPT.	[Chen, Xi; Zhou, Yixin] Capital Med Univ, Beijing Jishuitan Hosp, Dept Adult Joint Reconstruct Surg, Beijing, Peoples R China; [Chen, Xi; Wang, Ziyuan; Chu, Ming] Peking Univ, Sch Basic Med Sci, Dept Immunol, NHC Key Lab Med Immunol, Beijing, Peoples R China; [Zhang, Xin] Harbin Inst Technol Shenzhen, Inst Comp & Intelligence, HIT Campus Univ Town Shenzhen, Shenzhen, Peoples R China; [Liu, Yuan] Peking Univ, Sch Stomatol, Cent Lab, Beijing, Peoples R China; [Zhou, Yixin] Capital Med Univ, Beijing Jishuitan Hosp, Dept Adult Joint Reconstruct Surg, 31 East Xinjiekou St, Beijing, Peoples R China; [Chu, Ming] Peking Univ, Sch Basic Med Sci, Dept Immunol, NHC Key Lab Med Immunol, 38 Xueyuan Rd, Beijing, Peoples R China	Capital Medical University; Peking University; Harbin Institute of Technology; Peking University; Capital Medical University; Peking University	Zhou, YX (corresponding author), Capital Med Univ, Beijing Jishuitan Hosp, Dept Adult Joint Reconstruct Surg, 31 East Xinjiekou St, Beijing, Peoples R China.; Chu, M (corresponding author), Peking Univ, Sch Basic Med Sci, Dept Immunol, NHC Key Lab Med Immunol, 38 Xueyuan Rd, Beijing, Peoples R China.	orthoyixin@yahoo.com; famous@bjmu.edu.cn	li, Shang/KHU-3233-2024; CHEN, AN/KFT-3370-2024; Zhang, shanshan/HLP-6320-2023					Agrawal M, 2022, NAT REV GASTRO HEPAT, V19, P399, DOI 10.1038/s41575-022-00593-y; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Frassetto C, 2020, J GLOB HEALTH, V10, DOI 10.7189/jogh.10.020401; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Iftikhar A, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.960638; Liu J, 2021, J GLOB HEALTH, V11, DOI 10.7189/jogh.11.05020; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Tang DA, 2023, ANTIOXIDANTS-BASEL, V12, DOI 10.3390/antiox12040878; Vyas A, 2023, CURR PROB CARDIOLOGY, V48, DOI 10.1016/j.cpcardiol.2023.101755; Ye X, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.04042	11	0	0	9	19	INT SOC GLOBAL HEALTH	EDINBURGH	CALEDONIAN EXCHANGE, 19A CANNING ST, EDINBURGH, Lothian, ENGLAND	2047-2978	2047-2986		J GLOB HEALTH	J. Glob. Health		2023	13								03037	10.7189/jogh.13.03037	http://dx.doi.org/10.7189/jogh.13.03037			3	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	O8UV2	37539850	Green Published, gold			2024-07-03	WOS:001046523600001
J	Chakshu, NK; Nithiarasu, P				Chakshu, Neeraj Kavan; Nithiarasu, Perumal			Orbital learning: a novel, actively orchestrated decentralised learning for healthcare	SCIENTIFIC REPORTS			English	Article						Decentralised learning; Digital health; Data security; Data privacy		A novel collaborative and continual learning across a network of decentralised healthcare units, avoiding identifiable data-sharing capacity, is proposed. Currently available methodologies, such as federated learning and swarm learning, have demonstrated decentralised learning. However, the majority of them face shortcomings that affect their performance and accuracy. These shortcomings include a non-uniform rate of data accumulation, non-uniform patient demographics, biased human labelling, and erroneous or malicious training data. A novel method to reduce such shortcomings is proposed in the present work through selective grouping and displacing of actors in a network of many entities for intra-group sharing of learning with inter-group accessibility. The proposed system, known as Orbital Learning, incorporates various features from split learning and ensemble learning for a robust and secure performance of supervised models. A digital embodiment of the information quality and flow within a decentralised network, this platform also acts as a digital twin of healthcare network. An example of ECG classification for arrhythmia with 6 clients is used to analyse its performance and is compared against federated learning. In this example, four separate experiments are conducted with varied configurations, such as varied age demographics and clients with data tampering. The results obtained show an average area under receiver operating characteristic curve (AUROC) of 0.819 (95% CI 0.784-0.853) for orbital learning whereas 0.714 (95% CI 0.692-0.736) for federated learning. This result shows an increase in overall performance and establishes that the proposed system can address the majority of the issues faced by existing decentralised learning methodologies. Further, a scalability demo conducted establishes the versatility and scalability of this platform in handling state-of-the-art large language models.	[Chakshu, Neeraj Kavan; Nithiarasu, Perumal] Swansea Univ, Zienkiewicz Inst Modelling Data & AI, Bay Campus,Fabian Way, Swansea SA1 8EN, W Glam, Wales	Swansea University	Nithiarasu, P (corresponding author), Swansea Univ, Zienkiewicz Inst Modelling Data & AI, Bay Campus,Fabian Way, Swansea SA1 8EN, W Glam, Wales.	p.nithiarasu@swansea.ac.uk			IMPACT at Swansea University; Faculty of Science and Engineering, Swansea University; Impact Acceleration Account [EP/X525637/1]	IMPACT at Swansea University; Faculty of Science and Engineering, Swansea University; Impact Acceleration Account	The first author would like to thank IMPACT at Swansea University for funding and supporting this project during their fellowship. Authors would also like to acknowledge Faculty of Science and Engineering, Swansea University for their support. This work was partially supported through Impact Acceleration Account grant number: EP/X525637/1.	Abadi M., 2015, TensorFlow: Large-scale machine learning on het- erogeneous systems; Aledhari M, 2020, IEEE ACCESS, V8, P140699, DOI [10.1109/access.2020.3013541, 10.1109/ACCESS.2020.3013541]; [Anonymous], 2021, NAT MACH INTELL, V3, P459, DOI 10.1038/s42256-021-00364-5; [Anonymous], 2017, Official Journal of the European union, V117/145, P1, DOI DOI 10.1080/21548331.1992.11705401; Bai X, 2021, NAT MACH INTELL, V3, P1081, DOI 10.1038/s42256-021-00421-z; Balestra ML, 2017, JNP-J NURSE PRACT, V13, P105, DOI 10.1016/j.nurpra.2016.09.010; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Berndt DJ, 1994, KDD WORKSH SEATTL WA, V10, P359, DOI DOI 10.5555/3000850.3000887; Bonawitz K. A., 2019, ARXIV190201046, V1, P374; Boonstra A, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-231; Centers for Disease Control and Prevention, 1996, Health insurance portability and accountability act of 1996; Consumer Product Safety Commission, 2017, Fed Regist, V82, P43459; Gao YS, 2020, SYM REL DIST SYST, P91, DOI 10.1109/SRDS51746.2020.00017; Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215; Gow Brian, 2023, PN, DOI 10.13026/4NQG-SB35; Harrisa S, 2018, INT J MED INFORM, V112, P82, DOI 10.1016/j.ijmedinf.2018.01.006; Ico.org.uk, 2018, Guide to the UK general data protection regulation (UK GDPR); Johnson A., 2021, MIMIC-IV (version 1.0); Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1; Kelly CJ, 2019, BMC MED, V17, DOI 10.1186/s12916-019-1426-2; Kingma D. P., 2017, ARXIV; Kokoska S., 2000, CRC STANDARD PROBABI; Laux J, 2024, REGUL GOV, V18, P3, DOI 10.1111/rego.12512; Li B, 2021, NAT COMPUT SCI, V1, P221, DOI 10.1038/s43588-021-00039-6; Li Qinbin, 2023, IEEE Transactions on Knowledge and Data Engineering, P3347, DOI 10.1109/TKDE.2021.3124599; Mammen PM, 2021, Arxiv, DOI [arXiv:2101.05428, DOI 10.48550/ARXIV.2101.05428]; Murray M.L., 2022, A position paper; Nguyen DC, 2021, IEEE COMMUN SURV TUT, V23, P1622, DOI 10.1109/COMST.2021.3075439; Pennisi M, 2022, LECT NOTES COMPUT SC, V13573, P68, DOI 10.1007/978-3-031-18523-6_7; Rieke N, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00323-1; Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1; Singh A., 2019, arXiv; Song MK, 2020, IEEE J SEL AREA COMM, V38, P2430, DOI 10.1109/JSAC.2020.3000372; Taik A, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148937; Thapa C, 2022, Arxiv, DOI arXiv:2004.12088; Vepakomma P, 2018, Arxiv, DOI arXiv:1812.00564; Wagner P., 2022, PTB-XL, a large publicly available electrocardiography dataset; Wagner P, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0495-6; Warnat-Herresthal S, 2021, NATURE, V594, P265, DOI 10.1038/s41586-021-03583-3; Yang TMY, 2018, Arxiv, DOI arXiv:1812.02903; Zheng Chai, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P125, DOI 10.1145/3369583.3392686	41	0	0	1	1	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAY 7	2024	14	1							10459	10.1038/s41598-024-60915-9	http://dx.doi.org/10.1038/s41598-024-60915-9			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	PR5H4	38714825	Green Submitted, gold			2024-07-03	WOS:001215817800032
J	Zafar, A; Sahoo, SK; Bhardawaj, H; Das, A; Ekbal, A				Zafar, Aizan; Sahoo, Sovan Kumar; Bhardawaj, Harsh; Das, Amitava; Ekbal, Asif			KI-MAG: A knowledge-infused abstractive question answering system in medical domain	NEUROCOMPUTING			English	Article						Medical question answering; Knowledge graphs; Pre-trained language models; Knowledge filtering; Knowledge infusion; Answer generation	GENERATION	question-answering (QA) has emerged as a prominent area in Natural Language Processing (NLP) due to its ability to produce concise and human-like responses, particularly with the advancement of Large Language Models. Despite its potential, abstractive QA suffers from challenges like the need for extensive training data and the generation of incorrect entities and out-of-context words in the responses. In safety- critical domains like medical and clinical settings, such issues are unacceptable and may compromise the accuracy and reliability of generated answers. We proposed KI-MAG (Knowledge-Infused Medical Abstractive Generator) model, a novel Knowledge-Infused Abstractive Question Answering System specifically designed for the medical domain. KI-MAG aims to address the aforementioned limitations and enhance the correctness of generated responses while mitigating data sparsity concerns. The KI-MAG system produces more precise and informative answers by incorporating relevant medical entities into the model's generation process. Furthermore, we adopt a synthetic data generation approach using question-answer pairs to overcome the challenge of limited training data in the medical domain. These synthetic pairs augment the original dataset, resulting in better model generalization and improved performance. Our extensive experimental evaluations demonstrate the effectiveness of the KI-MAG system. Compared to traditional abstractive QA models, our approach exhibits a substantial increase of approximately 15% in Blue-1, Blue-2, Blue-3, and Blue-4 scores, indicating a remarkable improvement in answer accuracy and overall quality of responses. Overall, our Knowledge-Infused Abstractive Question Answering System in the Medical Domain (KI-MAG) presents a promising solution to enhance the performance and reliability of abstractive QA models in safety-critical medical applications where precision and correctness of answers are of utmost importance.	[Zafar, Aizan; Sahoo, Sovan Kumar; Bhardawaj, Harsh; Ekbal, Asif] IIT Patna, Dept CSE, Patna 801106, Bihar, India; [Das, Amitava] Wipro, Bangalore, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Patna	Zafar, A (corresponding author), IIT Patna, Dept CSE, Patna 801106, Bihar, India.	aizan_1921cs17@iitp.ac.in	Ekbal, Asif/JKI-7638-2023		Wipro Ltd; SERB, Government of India	Wipro Ltd; SERB, Government of India	Authors gratefully acknowledge the support from the projects "Percuro-A Holistic Solution for Text Mining", sponsored by Wipro Ltd; and "Sevak-An Intelligent Indian Language Chabot", sponsored by Imprint 2, SERB, Government of India.	Amador-Domínguez E, 2023, NEUROCOMPUTING, V521, P199, DOI 10.1016/j.neucom.2022.12.010; [Anonymous], 2015, P 2015 C EMP METH NA; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Bauer L, 2019, Arxiv, DOI arXiv:1809.06309; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Bollacker K, 2008, P 2008 ACM SIGMOD IN, P1247, DOI [10.1145/1376616.1376746, DOI 10.1145/1376616.1376746]; Cai LK, 2023, J BIOMED INFORM, V143, DOI 10.1016/j.jbi.2023.104418; De Cao N, 2019, Arxiv, DOI arXiv:1808.09920; Dietz L., 2017, Trec car: A data set for complex answer retrieval, V2017; Do T, 2021, LECT NOTES COMPUT SC, V12905, P64, DOI 10.1007/978-3-030-87240-3_7; Du Y., 2022, IEEE/ACM Trans. Comput. Biol. Bioinform; Fan A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3558; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Fouladvand S, 2023, J BIOMED INFORM, V143, DOI 10.1016/j.jbi.2023.104407; Gao F, 2023, DATA INTELLIGENCE, V5, P685, DOI 10.1162/dint_a_00210; Garg S, 2020, AAAI CONF ARTIF INTE, V34, P7780; Gopalakrishnan K, 2019, INTERSPEECH, P1891, DOI 10.21437/Interspeech.2019-3079; Graves A, 2012, STUD COMPUT INTELL, V385, P37; Gu JT, 2016, Arxiv, DOI [arXiv:1603.06393, 10.48550/arXiv.1603.06393]; Guofei Feng, 2018, Journal of Shanghai Jiaotong University (Science), V23, P678, DOI 10.1007/s12204-018-1982-1; Huai ZP, 2023, NEUROCOMPUTING, V553, DOI 10.1016/j.neucom.2023.126557; Huang L., 2020, P 58 ANN M ASS COMP, P5094; Huang YC, 2021, Arxiv, DOI arXiv:2104.14839; Indurthi S., 2018, Cut to the Chase: A Context Zoom-In Network for Reading Comprehension; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Khashabi D, 2020, Arxiv, DOI arXiv:2005.00700; Krishna K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4940; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li P., 2023, 2023 IEEE 20 INT S B, P1; Li WD, 2020, NEUROCOMPUTING, V382, P174, DOI 10.1016/j.neucom.2019.11.079; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin X., 2022, IEEE/ACM Trans. Comput. Biol. Bioinform; Liu B, 2021, I S BIOMED IMAGING, P1650, DOI 10.1109/ISBI48211.2021.9434010; Liu Chia-Wei, 2016, P 2016 C EMPIRICAL M, P2122, DOI [DOI 10.18653/V1/D16-1230, 10.18653/v1/D16-1230]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lyu KW, 2023, J BIOMED INFORM, V139, DOI 10.1016/j.jbi.2023.104298; McCann B, 2018, Arxiv, DOI arXiv:1806.08730; Mitra R., 2017, Computation and Language; Mitra R, 2018, Arxiv, DOI arXiv:1711.06238; Naseem U, 2023, IEEE J BIOMED HEALTH, V27, P1681, DOI 10.1109/JBHI.2022.3163751; Nentidis A, 2022, LECT NOTES COMPUT SC, V13390, P337, DOI 10.1007/978-3-031-13643-6_22; Neumann M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P319; Nguyen BD, 2019, LECT NOTES COMPUT SC, V11767, P522, DOI 10.1007/978-3-030-32251-9_57; Nguyen Tri, 2016, COCO NIPS; Ni'mah I, 2023, Arxiv, DOI arXiv:2305.08566; Nishida Kyosuke, 2019, arXiv; Pal V, 2022, PROCEEDINGS OF THE SECOND DIALDOC WORKSHOP ON DOCUMENT-GROUNDED DIALOGUE AND CONVERSATIONAL QUESTION ANSWERING (DIALDOC 2022), P41; Paolini G., 2021, 9 INT C LEARNING REP; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pappas D., 2022, arXiv; Qiu DL, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5896; Qiu YQ, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P35, DOI 10.1145/3184558.3186916; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Roberts K, 2016, INFORM RETRIEVAL J, V19, P113, DOI 10.1007/s10791-015-9259-x; Romero Manuel, 2021, T5 (base) fine-tuned on SQUAD for QG via AP; Sai AB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485766; See A, 2017, arXiv; Snover M., 2009, P 4 WORKSH STAT MACH, P259; Sobrino A, 2014, NEUROCOMPUTING, V135, P53, DOI 10.1016/j.neucom.2013.05.056; Soldaini L., 2016, MEDIR WORKSH SIGIR, P1; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Suchanek F.M., 2007, P 16 INT C WORLD WID, P697, DOI 10.1145/1242572.1242667; Sutskever I, 2014, ADV NEUR IN, V27; Tan CQ, 2018, Arxiv, DOI arXiv:1706.04815; Tian ZX, 2020, AAAI CONF ARTIF INTE, V34, P9032; Trischler Adam, 2017, P 2 WORKSH REPR LEAR, P191, DOI [DOI 10.18653/V1/W17-2623, 10.18653/v1/W17-2623]; Tymoshenko K, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2162; Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903; Wang D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P707; Wang ML, 2022, ARTIF INTELL MED, V131, DOI 10.1016/j.artmed.2022.102346; Wishart DS, 2018, NUCLEIC ACIDS RES, V46, pD1074, DOI 10.1093/nar/gkx1037; Yin Pengcheng., 2015, Proceedings of the 24th ACM International on Confer-ence on Information and Knowledge Management, P1301, DOI [10.1145/2806416.2806542, DOI 10.1145/2806416.2806542]; Zhang S, 2024, Arxiv, DOI [arXiv:2303.00915, DOI 10.48550/ARXIV.2303.00915]; Zhang XM, 2023, Arxiv, DOI arXiv:2305.10415; Zhao X, 2022, NEUROCOMPUTING, V509, P68, DOI 10.1016/j.neucom.2022.08.044; Zheng SJ, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa344	79	2	2	16	16	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0925-2312	1872-8286		NEUROCOMPUTING	Neurocomputing	FEB 28	2024	571								127141	10.1016/j.neucom.2023.127141	http://dx.doi.org/10.1016/j.neucom.2023.127141		DEC 2023	13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FX0P8					2024-07-03	WOS:001149037100001
J	Górecki, J				Gorecki, Jan			Pair programming with ChatGPT for sampling and estimation of copulas	COMPUTATIONAL STATISTICS			English	Article; Early Access						Human-AI collaboration; Analytically intractable problems; Prompt engineering; Natural language; Statistics		Without writing a single line of code by a human, an example Monte Carlo simulation-based application for stochastic dependence modeling with copulas is developed through pair programming involving a human partner and a large language model (LLM) fine-tuned for conversations. This process encompasses interacting with ChatGPT using both natural language and mathematical formalism. Under the careful supervision of a human expert, this interaction facilitated the creation of functioning code in MATLAB, Python, and R. The code performs a variety of tasks including sampling from a given copula model, evaluating the model's density, conducting maximum likelihood estimation, optimizing for parallel computing on CPUs and GPUs, and visualizing the computed results. In contrast to other emerging studies that assess the accuracy of LLMs like ChatGPT on tasks from a selected area, this work rather investigates ways how to achieve a successful solution of a standard statistical task in a collaboration of a human expert and artificial intelligence (AI). Particularly, through careful prompt engineering, we separate successful solutions generated by ChatGPT from unsuccessful ones, resulting in a comprehensive list of related pros and cons. It is demonstrated that if the typical pitfalls are avoided, we can substantially benefit from collaborating with an AI partner. For example, we show that if ChatGPT is not able to provide a correct solution due to a lack of or incorrect knowledge, the human-expert can feed it with the correct knowledge, e.g., in the form of mathematical theorems and formulas, and make it to apply the gained knowledge in order to provide a correct solution. Such ability presents an attractive opportunity to achieve a programmed solution even for users with rather limited knowledge of programming techniques.	[Gorecki, Jan] Silesian Univ Opava, Dept Informat & Math, Univ Namesti 1934-3, Karvina 73340, Czech Republic	Silesian University Opava	Górecki, J (corresponding author), Silesian Univ Opava, Dept Informat & Math, Univ Namesti 1934-3, Karvina 73340, Czech Republic.	gorecki@opf.slu.cz	Górecki, Jan/KBA-3329-2024	Górecki, Jan/0000-0001-5263-8637	Czech Science Foundation (GACR) [21-03085S]	Czech Science Foundation (GACR)(Grant Agency of the Czech Republic)	The author thanks the Czech Science Foundation (GACR) for financial support for this work through Grant 21-03085S. The author also thanks to Martin Holena and Marius Hofert for constructive comments and recommendations that definitely helped to improve the readability and quality of the paper.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bang Yejin, 2023, ARXIV230204023; Boulin A, 2023, Arxiv, DOI arXiv:2203.17177; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano PF, 2017, ADV NEUR IN, V30; CLAYTON DG, 1978, BIOMETRIKA, V65, P141, DOI 10.2307/2335289; Clinton D, 2022, Pair Programming with the ChatGPT AI-Does GPT-3.5 Understand Bash?-freecodecamp.org; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; GitHub, 2021, GitHub copilot your AI pair programmer; Haff IH, 2013, BERNOULLI, V19, P462, DOI 10.3150/12-BEJ413; Hofert M, 2010, Universitat Ulm, DOI [10.18725/OPARU-1787, DOI 10.18725/OPARU-1787]; Hofert M, 2018, J MULTIVARIATE ANAL, V167, P195, DOI 10.1016/j.jmva.2018.05.001; Hofert M, 2013, J SFDS, V154, P25; Huang Y, 2022, RENEW ENERG, V192, P526, DOI 10.1016/j.renene.2022.04.055; Joe H, 2015, MONOGR STAT APPL PRO, V134, P1, DOI 10.1201/b17116; Kalliamvakou E., 2022, Research: quantifying github copilot's impact on developer productivity and happiness; Katz D. M., 2023, GPT-4 Passes the Bar Exam; Lample G, 2019, Arxiv, DOI arXiv:1912.01412; Lewkowycz Aitor, 2022, arXiv; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Maddigan P, 2023, Arxiv, DOI arXiv:2302.02094; MARSHALL AW, 1988, J AM STAT ASSOC, V83, P834, DOI 10.2307/2289314; McNeil AJ, 2005, PRINC SER FINANC, P1; Michimae H, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10132163; Nelsen R.B., 2006, INTRO COPULAS; OpenAI, 2023, ChatGPT plugins. OpenAI Blog (blog); OpenAI, 2022, Introducing ChatGPT. OpenAI Blog; OpenAI, Techniques to improve reliability; OpenAI, 2023, OpenAI API-platform; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Peng S, 2021, Arxiv, DOI arXiv:2105.00377; Ruby D, 2023, ChatGPT statistics for 2023; Schellhase C, 2018, STAT COMPUT, V28, P387, DOI 10.1007/s11222-017-9737-7; Sklar M., 1959, PUBLICATIONS I STAT, V8, P229; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Williams L, 2001, 14TH CONFERENCE ON SOFTWARE ENGINEERING EDUCATION AND TRAINING, PROCEEDINGS, P27, DOI 10.1109/CSEE.2001.913816	40	0	0	27	27	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0943-4062	1613-9658		COMPUTATION STAT	Comput. Stat.	2023 DEC 1	2023										10.1007/s00180-023-01437-2	http://dx.doi.org/10.1007/s00180-023-01437-2		DEC 2023	31	Statistics & Probability	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	Z3FK1		hybrid			2024-07-03	WOS:001110962300001
C	Mastropaolo, A; Di Penta, M; Bavota, G			IEEE	Mastropaolo, Antonio; Di Penta, Massimiliano; Bavota, Gabriele			Towards Automatically Addressing Self-Admitted Technical Debt: How Far Are We?	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Self-Admitted Technical Debt; Pre-trained models; and Machine Learning for Code		Upon evolving their software, organizations and individual developers have to spend a substantial effort to pay back technical debt, i.e., the fact that software is released in a shape not as good as it should be, e.g., in terms of functionality, reliability, or maintainability. This paper empirically investigates the extent to which technical debt can be automatically paid back by neural-based generative models, and in particular models exploiting different strategies for pre-training and fine-tuning. We start by extracting a dateset of 5,039 Self-Admitted Technical Debt (SATD) removals from 595 open-source projects. SATD refers to technical debt instances documented (e.g., via code comments) by developers. We use this dataset to experiment with seven different generative deep learning (DL) model configurations. Specifically, we compare transformers pre-trained and fine-tuned with different combinations of training objectives, including the fixing of generic code changes, SATD removals, and SATDcomment prompt tuning. Also, we investigate the applicability in this context of a recently-available Large Language Model (LLM)-based chat bot. Results of our study indicate that the automated repayment of SATD is a challenging task, with the best model we experimented with able to automatically fix similar to 2% to 8% of test instances, depending on the number of attempts it is allowed to make. Given the limited size of the fine-tuning dataset (similar to 5k instances), the model's pre-training plays a fundamental role in boosting performance. Also, the ability to remove SATD steadily drops if the comment documenting the SATD is not provided as input to the model. Finally, we found general-purpose LLMs to not be a competitive approach for addressing SATD.	[Mastropaolo, Antonio; Bavota, Gabriele] Univ Svizzera italiana USI, SEART Software Inst, Lugano, Switzerland; [Di Penta, Massimiliano] Univ Sannio, Dept Engn, Benevento, Italy	Universita della Svizzera Italiana; University of Sannio	Mastropaolo, A (corresponding author), Univ Svizzera italiana USI, SEART Software Inst, Lugano, Switzerland.				European Research Council (ERC) under the European Union [851720]	European Research Council (ERC) under the European Union(European Research Council (ERC))	This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 851720). Di Penta acknowledges the Italian "PRIN 2021" project EMELIOT "Engineered MachinE Learning-intensive IoT systems."	Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; AlOmar EA, 2022, SCI COMPUT PROGRAM, V213, DOI 10.1016/j.scico.2021.102693; Bavota G, 2016, 13TH WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES (MSR 2016), P315, DOI [10.1145/2901739.2901742, 10.1109/MSR.2016.040]; Brody S, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428283; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cassee N, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-022-10183-w; Cedric Richter H. W., 2022, MSR; Chatgpt, chatgpt; Chen M., 2021, arXiv; Chen Z., 2021, Advances in Neural Information Processing Systems, V34, p23 089; Chen ZM, 2023, IEEE T SOFTWARE ENG, V49, P147, DOI 10.1109/TSE.2022.3147265; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Ciniselli M, 2022, IEEE T SOFTWARE ENG, V48, P4818, DOI 10.1109/TSE.2021.3128234; Ciniselli M, 2021, IEEE WORK CONF MIN S, P108, DOI 10.1109/MSR52588.2021.00024; Cunningham W., 1993, OOPS Messenger, V4, P29; Dabic O, 2021, IEEE WORK CONF MIN S, P560, DOI 10.1109/MSR52588.2021.00074; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eghbali A, 2022, PROC IEEE ACM INT C, P341, DOI [10.1109/ICSE-Companion55297.2022.9793747, 10.1145/3510454.3528648]; Falleri J.-R., 2014, P 29 ACM IEEE INT C, P313, DOI DOI 10.1145/2642937.2642982; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Freitag M, 2017, Arxiv, DOI arXiv:1702.01806; Fu Michael, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P935, DOI 10.1145/3540250.3549098; Fucci G, 2021, IEEE WORK CONF MIN S, P403, DOI 10.1109/MSR52588.2021.00052; gerritcodereview, Gerrit; github, The replication package for dockercleaner: Automatic repair of security smells in dockerfiles; Grissom RJ, 2005, Effect sizes for research: A broad practical approach; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; HOLM S, 1979, SCAND J STAT, V6, P65; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; I. Google, 2023, Try Bard, an AI expertiment by Google; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Karampatsis RM, 2020, IEEE WORK CONF MIN S, P573, DOI 10.1145/3379597.3387491; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Kusum Kusum, 2022, 2022 4th International Conference on Advances in Computing, Communication Control and Networking (ICAC3N), P384, DOI 10.1109/ICAC3N56670.2022.10074182; Li J, 2018, Arxiv, DOI arXiv:1711.09573; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Li Zhiyu, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1035, DOI 10.1145/3540250.3549081; Li ZY, 2022, Arxiv, DOI arXiv:2203.09095; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Maldonado ED, 2017, PROC IEEE INT CONF S, P238, DOI 10.1109/ICSME.2017.8; Maldonado ED, 2017, IEEE T SOFTWARE ENG, V43, P1044, DOI 10.1109/TSE.2017.2654244; Mashhadi E, 2021, IEEE WORK CONF MIN S, P505, DOI 10.1109/MSR52588.2021.00063; Mastropaolo A., 2022, IEEE Transactions on Software Engineering; Mastropaolo A, 2022, Arxiv, DOI arXiv:2201.04837; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996; OpenAI, 2023, GPT-4 Technical Report; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pina D, 2022, INTERNATIONAL CONFERENCE ON TECHNICAL DEBT 2022 (TECHDEBT 2022), P46, DOI 10.1145/3524843.3528096; Potdar A, 2014, PROC IEEE INT CONF S, P91, DOI 10.1109/ICSME.2014.31; Prenner JA, 2021, Arxiv, DOI [arXiv:2111.03922, DOI 10.48550/ARXIV.2111.03922]; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Ren XX, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3324916; Sierra G, 2019, J SYST SOFTWARE, V152, P70, DOI 10.1016/j.jss.2019.02.056; Svyatkovskiy A., 2020, Fast and memory-efficient neural code completion; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tan J, 2021, PROC IEEE INT CONF S, P251, DOI 10.1109/ICSME52107.2021.00029; Thongtanunam P, 2022, PROC INT CONF SOFTW, P237, DOI 10.1145/3510003.3510067; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Tufano M, 2019, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2019.00021; Tufano R., 2023, 45 IEEE ACM 44 INT C; Tufano R, 2022, PROC INT CONF SOFTW, P2291, DOI 10.1145/3510003.3510621; Tufano R, 2021, PROC INT CONF SOFTW, P163, DOI 10.1109/ICSE43902.2021.00027; Vaswani A, 2017, ADV NEUR IN, V30; Wang Chaozheng, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P382, DOI 10.1145/3540250.3549113; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Watson C, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3485275; Wei B., 2019, Advances in neural information processing systems; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Yao Z., ICLR; Zampetti F, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-10031-3; Zampetti F, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20), P355, DOI [10.1109/SANER48275.2020.9054868, 10.1109/saner48275.2020.9054868]; Zampetti F, 2018, IEEE WORK CONF MIN S, P526, DOI 10.1145/3196398.3196423; Zampetti F, 2017, PROC IEEE INT CONF S, P216, DOI 10.1109/ICSME.2017.44; Zhang J, 2020, INT C MACH LEARN PML, p11 328; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zhou S, 2022, 11 INT C LEARN REPR	80	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							585	597		10.1109/ASE56229.2023.00103	http://dx.doi.org/10.1109/ASE56229.2023.00103			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200047
J	Li, T; Zhang, XR; Wang, YD; Zhou, QX; Wang, YT; Dong, FQ				Li, Tong; Zhang, Xinran; Wang, Yunduo; Zhou, Qixiang; Wang, Yiting; Dong, Fangqi			Machine learning for requirements engineering (ML4RE): A systematic literature review complemented by practitioners' voices from Stack Overflow	INFORMATION AND SOFTWARE TECHNOLOGY			English	Review						Requirements engineering; Machine learning; Systematic literature review	MULTI-VOCAL LITERATURE; GREY LITERATURE; SOFTWARE	Context: The research of machine learning for requirements engineering (ML4RE) has attracted more and more attention from researchers and practitioners. Although pioneering research has shown the potential of using ML techniques to improve RE practices, there lacks a systematic and comprehensive literature review in academia that integrates an industrial perspective. Specifically, none of the reviews available in ML4RE have considered the grey literature, which is primarily from practitioner origin and is more reflective of the real issues and challenges faced in practice. Objective: In this paper, we conduct a systematic survey of academic publications in ML4RE and complement it with the practitioners' voices from Stack Overflow to complete a comprehensive literature review. Our research objective is to provide a comprehensive view of the current research progress in ML4RE, present the main questions and challenges faced in RE practice, understand the gap between research and practice, and provide our insights into how the RE academic domain can pragmatically develop in the future. Method: We systematically investigated 207 academic papers on ML4RE from 2010 to 2022, along with 375 questions related to RE practices on Stack Overflow and their corresponding answers. Our analysis encompassed their trends, focused RE activities and tasks, employed solutions, and associated data. Finally, we conducted a joint analysis, contrasting the outcomes of both parts. Results: Based on the statistical results from collected literature, we summarize an academic roadmap and analyse the disparities, offering research recommendations. Our suggestions include the development of intelligent question-answering assistants employing large language models, the integration of machine learning into industrial tools, and the promotion of collaboration between academia and industry. Conclusion: This study contributes by providing a holistic view of ML4RE, delineating disparities between research and practice, and proposing pragmatic suggestions to bridge the academia-industry gap.	[Li, Tong] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China; Beihang Univ, Sch Software, Beijing, Peoples R China	Beijing University of Technology; Beihang University	Li, T (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.	litong@bjut.edu.cn; zhangxinran028@gmail.com; wangyunduo@buaa.edu.cn; qixiang.zho@gmail.com; wangyiting.official@gmail.com; dfq902@gmail.com			National Natural Science Foundation of China [62162051, 61902010]; Project of Beijing Municipal Education Commission, China [KM202110005025]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Project of Beijing Municipal Education Commission, China	This work is partially supported by the National Natural Science Foundation of China (No. 62162051, 61902010) , the Project of Beijing Municipal Education Commission, China (No. KM202110005025) . We sincerely thank Shen Chen, Tianyu Wang, Shiqi Wang, and Chunji Cui for their valuable comments and preliminary exploration of this topic.	Achimugu P, 2014, INFORM SOFTWARE TECH, V56, P568, DOI 10.1016/j.infsof.2014.02.001; Alrumaih H, 2018, 2018 21ST SAUDI COMPUTER SOCIETY NATIONAL COMPUTER CONFERENCE (NCC); Alves I, 2023, IEEE T ENG MANAGE, DOI 10.1109/TEM.2023.3287759; Amaro R, 2023, IEEE T SOFTWARE ENG, V49, P883, DOI 10.1109/TSE.2022.3166626; Basili V.R., 1992, Software Modeling and Measurement: The Goal/Question/Metric Paradigm; Bhandari R, 2019, 2019 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS APPLICATIONS (ICCSA 2019), P140, DOI 10.1109/ICCSA.2019.00013; Cheligeer C, 2022, AI EDAM, V36, DOI 10.1017/S0890060422000166; ELMORE RF, 1991, REV EDUC RES, V61, P293; Felderer M, 2020, LECT NOTES BUS INF P, V371, P3, DOI 10.1007/978-3-030-35510-4_1; Garousi V, 2020, EMPIR SOFTW ENG, V25, P1687, DOI 10.1007/s10664-020-09803-0; Garousi V, 2019, INFORM SOFTWARE TECH, V106, P101, DOI 10.1016/j.infsof.2018.09.006; Garousi V, 2018, J SYST SOFTWARE, V138, P52, DOI 10.1016/j.jss.2017.12.013; Garousi V, 2017, INFORM SOFTWARE TECH, V85, P16, DOI 10.1016/j.infsof.2017.01.001; Garousi V, 2016, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING 2016 (EASE '16), DOI 10.1145/2915970.2916008; Garousi V, 2016, INFORM SOFTWARE TECH, V76, P92, DOI 10.1016/j.infsof.2016.04.015; Heiland L, 2023, Arxiv, DOI arXiv:2303.13173; Horkoff J, 2019, REQUIR ENG, V24, P133, DOI 10.1007/s00766-017-0280-z; Iqbal T, 2018, ASIA PAC SOFWR ENG, P11, DOI 10.1109/APSEC.2018.00015; Kadebu Prudence, 2018, 2018 3rd International Conference on Contemporary Computing and Informatics (IC3I), P129, DOI 10.1109/IC3I44769.2018.9007263; Kamei Fernando Kenji, 2019, ACM SIGSOFT Software Engineering Notes, V44, DOI 10.1145/3356773.3356797; Khelifa A., 2018, LPKM, P1; Kitchenham BA, 2011, INFORM SOFTWARE TECH, V53, P638, DOI 10.1016/j.infsof.2010.12.011; Li X., 2023, P INT C SOFTW ENG KN, P566, DOI [10.18293/SEKE2023-135, DOI 10.18293/SEKE2023-135]; Lim S., 2021, SN Computer Science, V2, P1; Pérez-Verdejo JM, 2020, 2020 8TH EDITION OF THE INTERNATIONAL CONFERENCE IN SOFTWARE ENGINEERING RESEARCH AND INNOVATION (CONISOFT 2020), P21, DOI 10.1109/CONISOFT50191.2020.00014; Martin W, 2017, IEEE T SOFTWARE ENG, V43, P817, DOI 10.1109/TSE.2016.2630689; Myrbakken H, 2017, COMM COM INF SC, V770, P17, DOI 10.1007/978-3-319-67383-7_2; de França BBN, 2016, THIRTIETH BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING (SBES 2016), P53, DOI 10.1145/2973839.2973845; Petersen K., 2008, 12 INT C EVALUATION, P68, DOI 10.14236/ewic/ease2008.8; Prates L, 2019, LECT NOTES BUS INF P, V359, P77, DOI 10.1007/978-3-030-29608-7_7; Rainer A, 2019, J SOFTW-EVOL PROC, V31, DOI 10.1002/smr.2197; Raulamo-Jurvanen P., 2017, P 21 INT C EV ASS SO, P21, DOI DOI 10.1145/3084226.3084252; Recupito G, 2022, 2022 48 EUR SOFTW EN, P84; Runeson P, 2009, EMPIR SOFTW ENG, V14, P131, DOI 10.1007/s10664-008-9102-8; S.R. Department, 2023, Number of available applications in the Google Play Store from December 2009 to June 2023; Sampada G. C., 2020, 2020 Sixth International Conference on Parallel, Distributed and Grid Computing (PDGC), P215, DOI 10.1109/PDGC50313.2020.9315741; Soldani J, 2018, J SYST SOFTWARE, V146, P215, DOI 10.1016/j.jss.2018.09.082; Tripathi N, 2018, J SYST SOFTWARE, V146, P130, DOI 10.1016/j.jss.2018.08.059; Xu C, 2023, IET SOFTW, V17, P405, DOI 10.1049/sfw2.12082; Zamani K, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P116, DOI 10.1109/REW53955.2021.00023; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689	41	0	0	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0950-5849	1873-6025		INFORM SOFTWARE TECH	Inf. Softw. Technol.	AUG	2024	172								107477	10.1016/j.infsof.2024.107477	http://dx.doi.org/10.1016/j.infsof.2024.107477			17	Computer Science, Information Systems; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	TI0N7					2024-07-03	WOS:001240520100001
J	Dudai, C; Alper, M; Bezalel, H; Hanocka, R; Lang, I; Averbuch-Elor, H				Dudai, Chen; Alper, Morris; Bezalel, Hana; Hanocka, Rana; Lang, Itai; Averbuch-Elor, Hadar			HaLo-NeRF: Learning Geometry-Guided Semantics for Exploring Unconstrained Photo Collections	COMPUTER GRAPHICS FORUM			English	Article; Early Access						CCS Concepts; Computing methodologies -> 3D imaging; Rendering; Image segmentation		Internet image collections containing photos captured by crowds of photographers show promise for enabling digital exploration of large-scale tourist landmarks. However, prior works focus primarily on geometric reconstruction and visualization, neglecting the key role of language in providing a semantic interface for navigation and fine-grained understanding. In more constrained 3D domains, recent methods have leveraged modern vision-and-language models as a strong prior of 2D visual semantics. While these models display an excellent understanding of broad visual semantics, they struggle with unconstrained photo collections depicting such tourist landmarks, as they lack expert knowledge of the architectural domain and fail to exploit the geometric consistency of images capturing multiple views of such scenes. In this work, we present a localization system that connects neural representations of scenes depicting large-scale landmarks with text describing a semantic region within the scene, by harnessing the power of SOTA vision-and-language models with adaptations for understanding landmark scene semantics. To bolster such models with fine-grained knowledge, we leverage large-scale Internet data containing images of similar landmarks along with weakly-related textual information. Our approach is built upon the premise that images physically grounded in space can provide a powerful supervision signal for localizing new concepts, whose semantics may be unlocked from Internet textual metadata with large language models. We use correspondences between views of scenes to bootstrap spatial understanding of these semantics, providing guidance for 3D-compatible segmentation that ultimately lifts to a volumetric scene representation. To evaluate our method, we present a new benchmark dataset containing large-scale scenes with ground-truth segmentations for multiple semantic concepts. Our results show that HaLo-NeRF can accurately localize a variety of semantic concepts related to architectural landmarks, surpassing the results of other 3D models as well as strong 2D segmentation baselines. Our code and data are publicly available at .	[Dudai, Chen; Alper, Morris; Bezalel, Hana; Averbuch-Elor, Hadar] Tel Aviv Univ, Tel Aviv, Israel; [Hanocka, Rana; Lang, Itai] Univ Chicago, Chicago, IL USA	Tel Aviv University; University of Chicago	Dudai, C (corresponding author), Tel Aviv Univ, Tel Aviv, Israel.		Averbuch-Elor, Hadar/AAO-4246-2021					Chen D.Z., 2020, EUROPEAN C COMPUTER, P202; Chen Jiaming, 2022, arXiv preprint arXiv:2210.12513; Chen S., 2022, arXiv preprint arXiv:2211.09646; Chen SL, 2022, PROC EUR CONF ANTENN; Chen Xingyu, 2022, IEEE C COMPUT VIS PA, P12943; Chung Hyung Won, 2022, ARXIV221011416; Decatur Dale, 2022, arXiv preprint arXiv:2212.11263; Ding N., 2022, P IEEECVF C COMPUTER, P11583; Fan Zhiwen, 2022, arXiv preprint arXiv:2209.08776; Fu Xiao, 2022, International Conference on 3D Vision (3DV); Ghiasi G, 2022, LECT NOTES COMPUT SC, V13696, P540, DOI 10.1007/978-3-031-20059-5_31; Huang S., 2022, CVPR; Iqbal U, 2020, PROC CVPR IEEE, P5242, DOI 10.1109/CVPR42600.2020.00529; Jia C, 2021, PR MACH LEARN RES, V139; Kerr J., Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), P19729; Kobayashi S., 2022, Advances in Neural Information Processing Systems (NeurIPS); Kundu A, 2022, PROC CVPR IEEE, P12861, DOI 10.1109/CVPR52688.2022.01253; Li B., 2022, P INT C LEARNING REP; Li ZQ, 2018, PROC CVPR IEEE, P2041, DOI 10.1109/CVPR.2018.00218; Liang F, 2023, PROC CVPR IEEE, P7061, DOI 10.1109/CVPR52729.2023.00682; Lu YH, 2023, PROC CVPR IEEE, P1190, DOI 10.1109/CVPR52729.2023.00121; Lüddecke T, 2022, PROC CVPR IEEE, P7076, DOI 10.1109/CVPR52688.2022.00695; Martin-Brualla R, 2021, PROC CVPR IEEE, P7206, DOI 10.1109/CVPR46437.2021.00713; Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250; Peng Songyou, 2022, arXiv preprint arXiv:2211.15654; Qianqian Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P757, DOI 10.1007/978-3-030-58452-8_44; Radford A, 2021, PR MACH LEARN RES, V139; Rozenberszki D, 2022, LECT NOTES COMPUT SC, V13693, P125, DOI 10.1007/978-3-031-19827-4_8; Russell BC, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508425; Siddiqui Yawar, 2022, arXiv preprint arXiv:2212.09802; Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964; Snavely N, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360614; Sun JM, 2021, PROC CVPR IEEE, P8918, DOI 10.1109/CVPR46437.2021.00881; Tschernezki V, 2022, Proceedings of the International Conference on 3D Vision (3DV); Turki H, 2023, PROC CVPR IEEE, P12375, DOI 10.1109/CVPR52729.2023.01191; Wu Xiaoshi, 2021, P IEEECVF INT C COMP, P428; Xu JR, 2022, PROC CVPR IEEE, P18113, DOI 10.1109/CVPR52688.2022.01760; Xu Mengde, 2021, arXiv preprint arXiv:2112.14757; Yi K. M., 2020, arXiv; Zhi SF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15818, DOI 10.1109/ICCV48922.2021.01554; Zhou C, 2022, LECT NOTES COMPUT SC, V13688, P696, DOI 10.1007/978-3-031-19815-1_40	41	0	0	2	2	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0167-7055	1467-8659		COMPUT GRAPH FORUM	Comput. Graph. Forum	2024 APR 15	2024										10.1111/cgf.15006	http://dx.doi.org/10.1111/cgf.15006		APR 2024	12	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NR7Q6		hybrid			2024-07-03	WOS:001202249600001
J	Wu, H; He, YT; Chen, YD; Bai, Y; Shi, XD				Wu, Hui; He, Yuting; Chen, Yidong; Bai, Yu; Shi, Xiaodong			Improving few-shot relation extraction through semantics-guided learning	NEURAL NETWORKS			English	Article						Few-shot relation extraction; Prototype network; Relation information; Semantics-guided learning; Relation graph learning; Contrastive learning		Few-shot relation extraction (few-shot RE) aims to recognize relations between the entity pair in a given text by utilizing very few annotated instances. As a simple yet efficient approach, prototype network-based methods often directly incorporate relation information to enhance prototype representation or leverage contrastive learning to mitigate prediction confusion. Despite achieving good results, the above methods are still susceptible to false judgments of outlier samples and confusion of similar classes. To address these issues, we propose a novel Semantics -Guided Learning (SemGL) method that more effectively utilizes relation information to enhance both the representations of instances and prototypes for improving the performance of few-shot RE. First, SemGL employs the prompt encoder to encode various prompt templates of instances and relation information and obtains more accurate semantic representations of instances, instance prototypes, and concept prototypes via the prompt enhancement from large language models. Then, SemGL introduces a novel technique called relation graph learning, which leverages concept prototypes to cluster homogeneous instances together, emphasizing relation-specific features of concrete instances. Simultaneously, SemGL employs instance-level contrastive learning between instance prototypes and support instances to distinguish between intra-class instances and inter-class instances to promote shared features among intra-class instances. Additionally, prototype-level contrastive learning leverages concept prototypes to pull closer relation-specific features of the concept prototype and shared features of the instance prototype from the same relation. Finally, SemGL utilizes new relation prototypes that integrate interpretable features of concept prototypes and shared features of instance prototypes for prediction. Experimental results on two publicly available few-shot RE datasets demonstrate the effectiveness and efficiency of SemGL in introducing relation information, with particularly promising results for the domain adaptation challenge task.	[Wu, Hui; He, Yuting; Chen, Yidong; Shi, Xiaodong] Xiamen Univ, Sch Informat, Dept Artificial Intelligence, Xiamen 361005, Peoples R China; [Wu, Hui; Shi, Xiaodong] Xiamen Univ, Natl Inst Data Sci Hlth & Med, Xiamen 361005, Peoples R China; [Wu, Hui; Chen, Yidong; Shi, Xiaodong] Xiamen Univ, Key Lab Digital Protect & Intelligent Proc Intangi, Minist Culture & Tourism, Xiamen 361005, Peoples R China; [Bai, Yu] Shenyang Aerosp Univ, Sch Comp Sci, Shenyang 110136, Peoples R China	Xiamen University; Xiamen University; Xiamen University; Shenyang Aerospace University	Shi, XD (corresponding author), Xiamen Univ, Sch Informat, Dept Artificial Intelligence, Xiamen 361005, Peoples R China.	wuhui16@mails.ucas.ac.cn; heyuting@stu.xmu.edu.cn; ydchen@xmu.edu.cn; baiyu@sau.edu.cn; mandel@xmu.edu.cn	Chen, YD/G-4143-2010	Shi, Xiaodong/0000-0002-8163-7139	Key Support Project of NSFC-Liaoning Joint Foundation, China [U1908216]; Major Scientific Research Project of the State Language Commission in the 13th Five-Year Plan, China [WT135-38]	Key Support Project of NSFC-Liaoning Joint Foundation, China; Major Scientific Research Project of the State Language Commission in the 13th Five-Year Plan, China	We would like to express our gratitude to the anonymous reviewers for their valuable feedback and suggestions, which have significantly improved the quality of our work. This research is supported by the Key Support Project of NSFC-Liaoning Joint Foundation, China (No. U1908216) and the Major Scientific Research Project of the State Language Commission in the 13th Five-Year Plan, China (No. WT135-38) .	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005; Chen T, 2020, PR MACH LEARN RES, V119; Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2778, DOI 10.1145/3485447.3511998; Chuang YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4207; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Dai GQ, 2022, NEURAL NETWORKS, V154, P234, DOI 10.1016/j.neunet.2022.07.014; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong MQ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2694; Finn C, 2017, PR MACH LEARN RES, V70; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Gao TY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6250; Gao TY, 2019, AAAI CONF ARTIF INTE, P6407; Garcia V., 2017, arXiv; Hamilton W. L., 2020, Graph Representation Learning, DOI 10.2200/s01045ed1v01y202009aim046; Han JL, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2605; Han X, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4803; He XX, 2023, NEURAL NETWORKS, V165, P1010, DOI 10.1016/j.neunet.2023.06.024; Hendrickx Iris, 2010, P 5 INT WORKSHOP SEM, P33; Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209; Ju W, 2023, NEURAL NETWORKS, V163, P122, DOI 10.1016/j.neunet.2023.03.034; Kejriwal Mayank, 2019, Domain-specific knowledge graph construction, DOI DOI 10.1007/978-3-030-12375-8; Khosla P., 2020, P NIPS, P18661; Kim JJ, 2021, NEURAL NETWORKS, V139, P158, DOI 10.1016/j.neunet.2021.02.001; Kordík P, 2010, NEURAL NETWORKS, V23, P568, DOI 10.1016/j.neunet.2010.02.003; Li LF, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2020.101817; Li WZ, 2021, NEURAL NETWORKS, V144, P540, DOI 10.1016/j.neunet.2021.08.021; Liu Y, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P757; Mai CC, 2023, NEURAL NETWORKS, V162, P393, DOI 10.1016/j.neunet.2023.03.001; Mintz M, 2009, P JOINT C 47 ANN M A, P1003; Ni JJ, 2023, ARTIF INTELL REV, V56, P3055, DOI 10.1007/s10462-022-10248-8; Peng H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3661; Qu M, 2020, P INT C MACH LEARN P, V119, P7867; Satorras V. G., 2018, INT C LEARNING REPRE; Saxena A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4498; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Snell J, 2017, ADV NEUR IN, V30; Soares LB, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2895; Sun Ang, 2011, P 49 ANN M ASS COMPU, P521; Vaswani A, 2017, ADV NEUR IN, V30; Wang M., 2022, COLING, P2129; Wang YQ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3091; Wang Yingyao, 2020, P 28 INT C COMP LING, P5799; Wu F, 2019, PR MACH LEARN RES, V97; Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386; Yang KJ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2273, DOI 10.1145/3340531.3412153; Yang S, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P987; Yang YY, 2021, AAAI CONF ARTIF INTE, V35, P14230; Yuan Y., 2021, FINDINGS ASS COMPUTA, P3615; Zhang P., 2022, P 2022 C EMP METH NA, P6996; Zhao JB, 2021, AAAI CONF ARTIF INTE, V35, P10981; Zhao W., 2021, arXiv; Zhenzhen L., 2022, FINDINGS ASS COMPUTA, P454, DOI 10.18653/v1/2022.findings-naacl.34,eprint:https://aclanthology.org/2022.findings	54	1	1	5	8	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0893-6080	1879-2782		NEURAL NETWORKS	Neural Netw.	JAN	2024	169						453	461		10.1016/j.neunet.2023.10.053	http://dx.doi.org/10.1016/j.neunet.2023.10.053		NOV 2023	9	Computer Science, Artificial Intelligence; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Neurosciences & Neurology	Z4BO5	37939534				2024-07-03	WOS:001111548200001
J	Gabor-Siatkowska, K; Sowanski, M; Rzatkiewicz, R; Stefaniak, I; Kozlowski, M; Janicki, A				Gabor-Siatkowska, Karolina; Sowanski, Marcin; Rzatkiewicz, Rafal; Stefaniak, Izabela; Kozlowski, Marek; Janicki, Artur			AI to Train AI: Using ChatGPT to Improve the Accuracy of a Therapeutic Dialogue System	ELECTRONICS			English	Article						spoken dialogue system; speech recognition; ChatGPT; data augmentation; computer-aided therapy; cognitive-behavioral therapy		In this work, we present the use of one artificial intelligence (AI) application (ChatGPT) to train another AI-based application. As the latter one, we show a dialogue system named Terabot, which was used in the therapy of psychiatric patients. Our study was motivated by the fact that for such a domain-specific system, it was difficult to acquire large real-life data samples to increase the training database: this would require recruiting more patients, which is both time-consuming and costly. To address this gap, we have employed a neural large language model: ChatGPT version 3.5, to generate data solely for training our dialogue system. During initial experiments, we identified intents that were most often misrecognized. Next, we fed ChatGPT with a series of prompts, which triggered the language model to generate numerous additional training entries, e.g., alternatives to the phrases that had been collected during initial experiments with healthy users. This way, we have enlarged the training dataset by 112%. In our case study, for testing, we used 2802 speech recordings originating from 32 psychiatric patients. As an evaluation metric, we used the accuracy of intent recognition. The speech samples were converted into text using automatic speech recognition (ASR). The analysis showed that the patients' speech challenged the ASR module significantly, resulting in deteriorated speech recognition and, consequently, low accuracy of intent recognition. However, thanks to the augmentation of the training data with ChatGPT-generated data, the intent recognition accuracy increased by 13% relatively, reaching 86% in total. We also emulated the case of an error-free ASR and showed the impact of ASR misrecognitions on the intent recognition accuracy. Our study showcased the potential of using generative language models to develop other AI-based tools, such as dialogue systems.	[Gabor-Siatkowska, Karolina; Sowanski, Marcin; Rzatkiewicz, Rafal; Kozlowski, Marek; Janicki, Artur] Warsaw Univ Technol, Fac Elect & Informat Technol, Nowowiejska 15-19, PL-00665 Warsaw, Poland; [Stefaniak, Izabela] Lazarski Univ, Fac Med, Ul Swieradowska 43, PL-02662 Warsaw, Poland	Warsaw University of Technology; Uczelnia Lazarskiego w Warszawie	Gabor-Siatkowska, K; Janicki, A (corresponding author), Warsaw Univ Technol, Fac Elect & Informat Technol, Nowowiejska 15-19, PL-00665 Warsaw, Poland.	karolina.gabor-siatkowska.dokt@pw.edu.pl; artur.janicki@pw.edu.pl		Janicki, Artur/0000-0002-9937-4402	Center for Priority Research Area Artificial Intelligence and Robotics of the Warsaw University of Technology	Center for Priority Research Area Artificial Intelligence and Robotics of the Warsaw University of Technology	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bunk T., arXiv, P2020; Chen Maximillian, 2023, FINDINGS ASS COMPUTA, P814; Chen Q, 2019, Arxiv, DOI arXiv:1902.10909; Craig TKJ, 2018, LANCET PSYCHIAT, V5, P31, DOI 10.1016/S2215-0366(17)30427-3; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dino F, 2019, IEEE INT C INT ROBOT, P2089, DOI [10.1109/IROS40897.2019.8968576, 10.1109/iros40897.2019.8968576]; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Fernández-Caballero A, 2017, FRONT NEUROINFORM, V11, DOI 10.3389/fninf.2017.00064; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Gabor-Siatkowska K., 2023, P 30 INT C SYST SIGN, P1, DOI [10.1109/IWSSIP58668.2023.10180265, DOI 10.1109/IWSSIP58668.2023.10180265]; Holtzman A., 2019, P INT C LEARN REPR I, P1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiao AR, 2020, J PHYS CONF SER, V1487, DOI 10.1088/1742-6596/1487/1/012014; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kozlowski Marek, 2023, Computational Science - ICCS 2023: 23rd International Conference, Proceedings. Lecture Notes in Computer Science (14073), P465, DOI 10.1007/978-3-031-35995-8_33; Liu SR, 2023, medRxiv, DOI [10.1101/2023.02.21.23286254, 10.1101/2023.02.21.23286254, DOI 10.1101/2023.02.21.23286254]; Liu X, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11080390; Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6; Lugrin B., 2022, HDB SOCIALLY INTERAC; Merrill W, 2021, T ASSOC COMPUT LING, V9, P1047, DOI 10.1162/tacl_a_00412; Oliver A, 2018, ADV NEUR IN, V31; Pudo Mikolaj, 2022, 2022 IEEE 7th Forum on Research and Technologies for Society and Industry Innovation (RTSI), P136, DOI 10.1109/RTSI55261.2022.9905112; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rosenberg AS, 2022, PRINC STUD INT HIST, P218; Roziewski S, 2021, LANG RESOUR EVAL, V55, P1047, DOI 10.1007/s10579-021-09551-7; Sharma S., 2017, P INT C LEARN REPR W, P1; Spillane B., 2020, P CONVERSATIONAL AGE; Stefaniak I, 2019, SCHIZOPHR RES, V211, P115, DOI 10.1016/j.schres.2019.05.036; Su PH, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2431; Vaswani A, 2017, ADV NEUR IN, V30; Vlasov V, 2020, Arxiv, DOI arXiv:1910.00486; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Zheng CJ, 2023, Arxiv, DOI arXiv:2202.13047; Zhong V, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1458; Zygadlo A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112110146	40	1	1	14	16	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	NOV	2023	12	22							4694	10.3390/electronics12224694	http://dx.doi.org/10.3390/electronics12224694			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	AT7G7		gold			2024-07-03	WOS:001120766500001
J	Remountakis, M; Kotis, K; Kourtzis, B; Tsekouras, GE				Remountakis, Manolis; Kotis, Konstantinos; Kourtzis, Babis; Tsekouras, George E.			Using ChatGPT and Persuasive Technology for Personalized Recommendation Messages in Hotel Upselling	INFORMATION			English	Article						ChatGPT; persuasive technologies; recommender system; hotel hospitality		Recommender systems have become indispensable tools in the hotel hospitality industry, enabling personalized and tailored experiences for guests. Recent advancements in large language models (LLMs), such as ChatGPT, and persuasive technologies have opened new avenues for enhancing the effectiveness of those systems. This paper explores the potential of integrating ChatGPT and persuasive technologies for automating and improving hotel hospitality recommender systems. First, we delve into the capabilities of ChatGPT, which can understand and generate human-like text, enabling more accurate and context-aware recommendations. We discuss the integration of ChatGPT into recommender systems, highlighting the ability to analyze user preferences, extract valuable insights from online reviews, and generate personalized recommendations based on guest profiles. Second, we investigate the role of persuasive technology in influencing user behavior and enhancing the persuasive impact of hotel recommendations. By incorporating persuasive techniques, such as social proof, scarcity, and personalization, recommender systems can effectively influence user decision making and encourage desired actions, such as booking a specific hotel or upgrading their room. To investigate the efficacy of ChatGPT and persuasive technologies, we present pilot experiments with a case study involving a hotel recommender system. Our inhouse commercial hotel marketing platform, eXclusivi, was extended with a new software module working with ChatGPT prompts and persuasive ads created for its recommendations. In particular, we developed an intelligent advertisement (ad) copy generation tool for the hotel marketing platform. The proposed approach allows for the hotel team to target all guests in their language, leveraging the integration with the hotel's reservation system. Overall, this paper contributes to the field of hotel hospitality by exploring the synergistic relationship between ChatGPT and persuasive technology in recommender systems, ultimately influencing guest satisfaction and hotel revenue.	[Remountakis, Manolis; Kourtzis, Babis] Upsell SA, Kountouriotou 49, Mitilini 81100, Greece; [Kotis, Konstantinos; Tsekouras, George E.] Univ Aegean, Dept Cultural Technol & Commun, Lab Intelligent Syst, Mitilini 81100, Greece	University of Aegean	Tsekouras, GE (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Lab Intelligent Syst, Mitilini 81100, Greece.	mr@upsell.ai; kotis@aegean.gr; bk@exclusivi.com; gtsek@ct.aegean.gr	Kotis, Konstantinos/B-1883-2009	Kotis, Konstantinos/0000-0001-7838-9691; Tsekouras, George/0000-0001-7006-1536	The authors would like to thank the anonymous reviewers for their efforts in providing valuable comments that improved the paper.	The authors would like to thank the anonymous reviewers for their efforts in providing valuable comments that improved the paper.	The authors would like to thank the anonymous reviewers for their efforts in providing valuable comments that improved the paper.	Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alslaity A, 2020, LECT NOTES COMPUT SC, V12064, P3, DOI 10.1007/978-3-030-45712-9_1; [Anonymous], 2006, businesswire; Augello A, 2023, INT J SOC ROBOT, V15, P2115, DOI 10.1007/s12369-021-00847-w; Barranco MJ, 2012, ADV INTELL SYST, V171, P153; Bobadilla J, 2013, KNOWL-BASED SYST, V46, P109, DOI 10.1016/j.knosys.2013.03.012; Bragg J, 2021, Arxiv, DOI arXiv:2107.07170; Buhalis D., 2020, Information and Communication Technologies in Tourism, P231; Chicaiza J, 2021, INFORMATION, V12, DOI 10.3390/info12060232; Chiu MC, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P185; Cialdini RB, 2001, HARVARD BUS REV, V79, P72; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Díaz E, 2013, INT J HOSP MANAG, V34, P338, DOI 10.1016/j.ijhm.2012.11.009; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; eXclusivi, About us; Gena C, 2019, INFORMATION, V10, DOI 10.3390/info10100300; Guerra-Montenegro J, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107082; Hagendorff T, 2023, Arxiv, DOI [arXiv:2212.05206, 10.48550/arXiv.2212.05206, DOI 10.48550/ARXIV.2212.05206]; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Halko S, 2010, LECT NOTES COMPUT SC, V6137, P150, DOI 10.1007/978-3-642-13226-1_16; Han SH, 2021, TOUR MANAG PERSPECT, V38, DOI 10.1016/j.tmp.2021.100811; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Hui T.L.T., 2016, Information and Communication Technologies in Tourism 2016, P455; Ivanov S, 2020, INF TECHNOL TOUR, V22, P505, DOI 10.1007/s40558-020-00187-x; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Johnson RR, 2004, J BUS TECH COMMUN, V18, P251, DOI 10.1177/1050651904182008; Kembellec G., 2014, RECOMMENDER SYSTEMS; Kolides A, 2023, SIMUL MODEL PRACT TH, V126, DOI 10.1016/j.simpat.2023.102754; Leal Fatima, 2019, New Knowledge in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 930), P262, DOI 10.1007/978-3-030-16181-1_25; Lieto A, 2014, PSYCHNOLOGY J, V12, P87; Liu Z, 2023, Arxiv, DOI arXiv:2305.09434; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; MacGlashan J, 2023, Arxiv, DOI arXiv:1701.06049; micros, Fidelio Suit 8; Mintz J, 2012, ETR&D-EDUC TECH RES, V60, P483, DOI 10.1007/s11423-012-9232-y; Morosan C, 2019, INT J HOSP MANAG, V82, P242, DOI 10.1016/j.ijhm.2019.04.015; Neuhofer B, 2015, ELECTRON MARK, V25, P243, DOI 10.1007/s12525-015-0182-1; Nor1, About us; Oinas-Kukkonen H, 2008, LECT NOTES COMPUT SC, V5033, P164, DOI 10.1007/978-3-540-68504-3_15; oracle, Oracle Opera Hotel Property Management; Orange PMS, About us; Padma P, 2020, INT J HOSP MANAG, V84, DOI 10.1016/j.ijhm.2019.102318; Perfetti C., 2003, Guiding Users with Persuasive Design: An Interview with Andrew Chak; Protel Net, About us; Pu DQ, 2023, Arxiv, DOI arXiv:2306.07799; pylon, Pylon Hospitality; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1; Rombach R., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.10752; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Tai YF, 2021, SERV BUS, V15, P667, DOI 10.1007/s11628-021-00461-w; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Veloso BM, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100957; Veloso BM, 2019, ELECTRON COMMER R A, V34, DOI 10.1016/j.elerap.2019.100832; Wang BS, 2023, Arxiv, DOI arXiv:2212.10001; Wang YT, 2023, Arxiv, DOI arXiv:2305.18339; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xia ZY, 2024, Arxiv, DOI arXiv:2206.02631; Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328; Xu BF, 2023, Arxiv, DOI arXiv:2305.14688; Yang HJ, 2021, INT J HOSP MANAG, V97, DOI 10.1016/j.ijhm.2021.103000; Yoon D, 2020, J HOSP TOUR MANAG, V45, P511, DOI 10.1016/j.jhtm.2020.10.014; Young A., Nor1's PRiME Decision Platform with Real-Time Merchandising Banners Driving Double-Digit Conversion Rate for Hotels; Zhang C, 2023, Arxiv, DOI [arXiv:2304.06488, DOI 10.13140/RG.2.2.24789.70883]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	68	5	5	28	36	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	SEP	2023	14	9							504	10.3390/info14090504	http://dx.doi.org/10.3390/info14090504			35	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	T1KE0		gold			2024-07-03	WOS:001075636000001
C	Kenthapadi, K; Lakkaraju, H; Rajani, N			ACM	Kenthapadi, Krishnaram; Lakkaraju, Himabindu; Rajani, Nazneen			Generative AI Meets Responsible AI: Practical Challenges and Opportunities	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD				Generative AI models and applications are being rapidly developed and deployed across a wide spectrum of industries and applications ranging from writing and email assistants to graphic design and art generation to educational assistants to coding to drug discovery [12]. However, there are several ethical and social considerations associated with generative AI models and applications. These concerns include lack of interpretability, bias and discrimination, privacy, lack of model robustness, fake and misleading content, copyright implications, plagiarism, and environmental impact associated with training and inference of generative AI models. In this tutorial, we first motivate the need for adopting responsible AI principles when developing and deploying large language models (LLMs) and other generative AI models, as part of a broader AI model governance and responsible AI framework, from societal, legal, user, and model developer perspectives, and provide a roadmap for thinking about responsible AI for generative AI in practice. We provide a brief technical overview of text and image generation models, and highlight the key responsible AI desiderata associated with these models. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We focus on real-world generative AI use cases spanning domains such as media generation, writing assistants, copywriting, code generation, and conversational assistants, present practical solution approaches / guidelines for applying responsible AI techniques effectively, discuss lessons learned from deploying responsible AI approaches for generative AI applications in practice, and highlight the key open research problems. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on responsible AI in the context of generative AI, and pave the way for building more reliable and trustworthy generative AI applications in the future.	[Kenthapadi, Krishnaram] Fiddler AI, Palo Alto, CA 94306 USA; [Lakkaraju, Himabindu] Harvard Univ, Cambridge, MA 02138 USA; [Rajani, Nazneen] Hugging Face, Cambridge, MA USA	Harvard University	Kenthapadi, K (corresponding author), Fiddler AI, Palo Alto, CA 94306 USA.	krishnaram@fiddler.ai; hlakkaraju@hbs.edu; nazneen@huggingface.co						Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; [Anonymous], 2016, NeurIPS; [Anonymous], 2021, USENIX SEC S, DOI DOI 10.21037/ALES-2019-MISS-09; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bommasani R., 2021, 2108.07258; Bommasani Rishi, 2023, STANFORD HAI POLICY; Carlini Nicholas, 2023, ARXIV230113188; Christiano PF, 2017, ADV NEUR IN, V30; Chung Hyung Won, 2022, ARXIV221011416; Ganguli Deep, 2022, ARXIV220907858; Huang Grady Sonya Pat, 2022, Generative AI: a creative new world; Huang Jie, 2022, ICML WORKSH KNOWL RE; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Kambhampati S, 2022, COMMUN ACM, V65, P8, DOI 10.1145/3546954; Le Scao Teven, 2022, ARXIV221105100; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; MacGlashan James, 2017, ICML; Metzler Donald, 2021, ACM SIGIR FORUM, V55; Mokander Jakob, 2023, arXiv:2302.08500; Ng Andrew, 2022, CHATGPT MANIA CRYPTO; Ouyang Long, 2022, ARXIV220302155; Patterson David, 2021, ARXIV210410350; Radford A, 2021, PR MACH LEARN RES, V139; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Sankararaman Karthik Abinav, 2022, ARXIV220600826; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816; Sharir Or, 2020, ARXIV200408900; Solaiman Irene, 2023, ARXIV230204844; Wallace Eric, 2021, NAACL HLT; Wang Yizhong, 2022, EMNLP; Wolfe Robert, 2022, ARXIV221211261; YizhongWang Yeganeh Kordi, 2022, arXiv; Zhang S., 2022, arXiv; Ziegler D. M., ARXIV190908593	34	3	4	24	24	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5805	5806		10.1145/3580305.3599557	http://dx.doi.org/10.1145/3580305.3599557			2	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ					2024-07-03	WOS:001118896305086
C	Ovalle, A; Goyal, P; Dhamala, J; Jaggers, Z; Chang, KW; Galstyan, A; Zemel, R; Gupta, R			ASSOC COMPUTING MACHINERY	Ovalle, Anaelia; Goyal, Palash; Dhamala, Jwala; Jaggers, Zachary; Chang, Kai-Wei; Galstyan, Aram; Zemel, Richard; Gupta, Rahul			"I'm fully who I am": Towards Centering Transgender and Non-Binary Voices to Measure Biases in Open Language Generation	PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023			English	Proceedings Paper	6th ACM Conference on Fairness, Accountability, and Transparency (FAccT)	JUN 12-15, 2023	Chicago, IL	Assoc Comp Machinery		Algorithmic Fairness; Natural Language Generation; AI Fairness Auditing; Queer Harms in AI	MENTAL-HEALTH; GENDER	Warning: This paper contains examples of gender non-affirmative language which could be offensive, upsetting, and/or triggering. Transgender and non-binary (TGNB) individuals disproportionately experience discrimination and exclusion from daily life. Given the recent popularity and adoption of language generation technologies, the potential to further marginalize this population only grows. Although a multitude of NLP fairness literature focuses on illuminating and addressing gender biases, assessing gender harms for TGNB identities requires understanding how such identities uniquely interact with societal gender norms and how they differ from gender binary-centric perspectives. Such measurement frameworks inherently require centering TGNB voices to help guide the alignment between gender-inclusive NLP and whom they are intended to serve. Towards this goal, we ground our work in the TGNB community and existing interdisciplinary literature to assess how the social reality surrounding experienced marginalization of TGNB persons contributes to and persists within Open Language Generation (OLG). This social knowledge serves as a guide for evaluating popular large language models (LLMs) on two key aspects: (1) misgendering and (2) harmful responses to gender disclosure. To do this, we introduce TANGO, a dataset of template-based real-world text curated from a TGNB-oriented community. We discover a dominance of binary gender norms reflected by the models; LLMs least misgendered subjects in generated text when triggered by prompts whose subjects used binary pronouns. Meanwhile, misgendering was most prevalent when triggering generation with singular they and neopronouns. When prompted with gender disclosures, TGNB disclosure generated the most stigmatizing language and scored most toxic, on average. Our findings warrant further research on how TGNB harms manifest in LLMs and serve as a broader case study toward concretely grounding the design of gender-inclusive AI in community voices and interdisciplinary literature.	[Ovalle, Anaelia] UCLA, Los Angeles, CA 90095 USA; [Goyal, Palash; Dhamala, Jwala; Galstyan, Aram; Zemel, Richard; Gupta, Rahul] Amazon Alexa AI NU, Cambridge, MA USA; [Jaggers, Zachary] Amazon Global Div Equ & Inclus, Seattle, WA USA; [Chang, Kai-Wei] UCLA, Amazon Alexa AI NU, Los Angeles, CA USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Ovalle, A (corresponding author), UCLA, Los Angeles, CA 90095 USA.	anaelia@cs.ucla.edu; palashg@amazon.com; jddhamal@amazon.com; zjaggers@amazon.com; kaiwec@amazon.com; argalsty@amazon.com; rzemel@amazon.com; gupra@amazon.com	Goyal, Palash/ABI-6942-2020	Goyal, Palash/0000-0003-2455-2160; Ovalle, Anaelia/0000-0002-0531-7520				AllenNLP, AllenNLP Demo-demo.allennlp.org; Ansara Y.G., 2013, INT J MULTIPLE RES A, V7, P160, DOI DOI 10.5172/MRA.2013.7.2.160; Ashwin S, 2021, Rebuilding Trust: Queer in AI Approach to Artificial Intelligence Risk Management; Barikeri S, 2021, Arxiv, DOI arXiv:2106.03521; Barocas Solon, 2019, FAIRNESS MACHINE LEA; Baumgartner J, 2020, INT C WEB SOC MED, V14, P830, DOI [DOI 10.5281/ZENODO.3608135, DOI 10.1609/ICWSM.V14I1.7347]; Bjorkman BM, 2017, GLOSSA-UK, V2, DOI 10.5334/gjgl.374; Black Sid, 2021, GPTTensorflow, DOI [10.5281/zenodo.5297715Ifyouusethissoftware, DOI 10.5281/ZENODO.5297715IFYOUUSETHISSOFTWARE]; Bockting WO, 2013, AM J PUBLIC HEALTH, V103, P943, DOI 10.2105/AJPH.2013.301241; Bolukbasi T, 2016, ADV NEUR IN, V29; Burtscher Sabrina, 2020, MuC'20: Proceedings of the Conference on Mensch und Computer, P431, DOI 10.1145/3404983.3405510; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Cambridge, Determiners used as pronouns; Cao YT, 2021, COMPUT LINGUIST, V47, P615, DOI [10.1162/coli_a_00413, 10.1162/COLI_a_00413]; Clements-Nolle K, 2006, J HOMOSEXUAL, V51, P53, DOI 10.1300/J082v51n03_04; CONROD K, 2019, THESIS; Dacon J, 2022, Arxiv, DOI arXiv:2207.10032; Dai DM, 2022, Arxiv, DOI arXiv:2212.10559; Dev S, 2021, Arxiv, DOI arXiv:2108.12084; Dev Sunipa, 2022, Findings of the Association for Computational Linguistics: AACL-IJCNLP, P246; Dhamala Jwala, 2021, P 2021 ACM C FAIRN A, P862; Dinan E, 2020, Arxiv, DOI arXiv:1911.03842; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Felkner VK, 2022, Arxiv, DOI arXiv:2206.11484; Flowers A, 2015, The Most Common Unisex Names In America: Is Yours One Of Them?; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gender Census, Gender Census 2022: Worldwide Report; Hewings Robin, Marginalization and Loneliness Among Sexual Minorities: How Are They Linked?-Campaign to End Loneliness-campaigntoendloneliness.org; Hosseini H, 2017, Arxiv, DOI arXiv:1702.08138; HuggingFace, Neural Coreference; Hussain MS, 2015, J TECHNOL HUMAN SERV, V33, P304, DOI 10.1080/15228835.2015.1105768; James S. E., 2016, REPORT 2015 US TRANS; JohannesWelbl Amelia Glaese, 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2109.07445; Joshi Ankur, 2015, British journal of applied science & technology, V7, P4; Lauscher A, 2022, Arxiv, DOI arXiv:2202.11923; Liu HC, 2020, Arxiv, DOI arXiv:2009.13028; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; McLemore K.A., 2018, STIGMA HEALTH, V5, P53, DOI DOI 10.1037/SAH0000070; Nozza D, 2022, PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022), P26; Nozza D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2398; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; Oxford English Dictionary, A brief history of singular 'they'; Pearson, Gender Policing and Gender Accountability; Poulsen A, 2020, NAT MACH INTELL, V2, P152, DOI 10.1038/s42256-020-0157-6; Puckett JA, 2023, INT J TRANSGEND HEAL, V24, P113, DOI 10.1080/26895269.2021.1937437; Puckett JA, 2020, J CLIN PSYCHOL, V76, P176, DOI 10.1002/jclp.22865; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raji ID, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P515, DOI 10.1145/3442188.3445914; Ramos-Soto A, 2016, FUZZY SET SYST, V285, P31, DOI 10.1016/j.fss.2015.06.019; Richardson Leonard., 2016, Beautiful Soup: We called him Tortoise because he taught us; Rood Brian A, 2016, Transgend Health, V1, P151, DOI 10.1089/trgh.2016.0012; Saha Koustuv, 2019, Proc ACM Hum Comput Interact, V3, DOI 10.1145/3361108; Saha T, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533924; Sanford AJ, 2007, Q J EXP PSYCHOL, V60, P171, DOI 10.1080/17470210600973390; Schick T, 2021, Arxiv, DOI arXiv:2009.07118; Sheng EMY, 2020, Arxiv, DOI arXiv:2005.00268; Sheng EMY, 2019, Arxiv, DOI arXiv:1909.01326; Sheng Emily, 2021, arXiv; Silveira J., 1980, WOMENS STUDIES INT Q, V3, P165, DOI [10.1016/S0148-0685(80)92113-2, DOI 10.1016/S0148-0685(80)92113-2]; Social Security Administration, 2022, Popular Baby Names-ssa.gov; St. Louis Community College, Pronoun and antecedent agreement; Strengers Y, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376315; Templin M., 1957, CERTAIN LANGUAGE SKI; Testa RJ., 2015, Psychology of Sexual Orientation and Gender Diversity, V2, P65, DOI DOI 10.1037/SGD0000081; Testa RJ, 2017, J ABNORM PSYCHOL, V126, P125, DOI 10.1037/abn0000234; Tripp A, 2022, WIRES COGN SCI, V13, DOI 10.1002/wcs.1583; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	69	2	2	3	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-7252-7				2023							1246	1266		10.1145/3593013.3594078	http://dx.doi.org/10.1145/3593013.3594078			21	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Ethics; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BV6VC		Green Submitted			2024-07-03	WOS:001062819300106
J	Nasarian, E; Alizadehsani, R; Acharya, UR; Tsui, KL				Nasarian, Elham; Alizadehsani, Roohallah; Acharya, U. Rajendra; Tsui, Kwok-Leung			Designing interpretable ML system to enhance trust in healthcare: A systematic review to proposed responsible clinician-AI-collaboration framework	INFORMATION FUSION			English	Article						Interpretable ML; AI -based medical devices; Unstructured data; Medical large language models; Human -computer -interaction; Wearable medical devices; Explainable casual analysis; Responsible AI	BLACK-BOX; FUTURE; EXPLAINABILITY; FEATURES; KAIZEN; ETHICS	Background: Artificial intelligence (AI)-based medical devices and digital health technologies, including medical sensors, wearable health trackers, telemedicine, mobile health (mHealth), large language models (LLMs), and digital care twins (DCTs), significantly influence the process of clinical decision support systems (CDSS) in healthcare and medical applications. However, given the complexity of medical decisions, it is crucial that results generated by AI tools not only be correct but also carefully evaluated, understandable, and explainable to endusers, especially clinicians. The lack of interpretability in communicating AI clinical decisions can lead to mistrust among decision-makers and a reluctance to use these technologies. Objective: This paper systematically reviews the processes and challenges associated with interpretable machine learning (IML) and explainable artificial intelligence (XAI) within the healthcare and medical domains. Its main goals are to examine the processes of IML and XAI, their related methods, applications, and the implementation challenges they pose in digital health interventions (DHIs), particularly from a quality control perspective, to help understand and improve communication between AI systems and clinicians. The IML process is categorized into pre-processing interpretability, interpretable modeling, and post-processing interpretability. This paper aims to foster a comprehensive understanding of the significance of a robust interpretability approach in clinical decision support systems (CDSS) by reviewing related experimental results. The goal is to provide future researchers with insights for creating clinician-AI tools that are more communicable in healthcare decision support systems and offer a deeper understanding of their challenges. Methods: Our research questions, eligibility criteria, and primary goals were proved using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline and the PICO (population, intervention, control, and outcomes) method. We systematically searched PubMed, Scopus, and Web of Science databases using sensitive and specific search strings. Subsequently, duplicate papers were removed using EndNote and Covidence. A two-phase selection process was then carried out on Covidence, starting with screening by title and abstract, followed by a full-text appraisal. The Meta Quality Appraisal Tool (MetaQAT) was used to assess the quality and risk of bias. Finally, a standardized data extraction tool was employed for reliable data mining. Results: The searches yielded 2,241 records, from which 555 duplicate papers were removed. During the title and abstract screening step, 958 papers were excluded, and the full-text review step excluded 482 studies. Subsequently, in quality and risk of bias assessment, 172 papers were removed. 74 publications were selected for data extraction, which formed 10 insightful reviews and 64 related experimental studies. Conclusion: The paper provides general definitions of explainable artificial intelligence (XAI) in the medical domain and introduces a framework for interpretability in clinical decision support systems structured across three levels. It explores XAI-related health applications within each tier of this framework, underpinned by a review of related experimental findings. Furthermore, the paper engages in a detailed discussion of quality assessment tools for evaluating XAI in intelligent health systems. It also presents a step-by-step roadmap for implementing XAI in clinical settings. To direct future research toward bridging current gaps, the paper examines the importance of XAI models from various angles and acknowledges their limitations.	[Nasarian, Elham; Tsui, Kwok-Leung] Virginia Tech, Grad Dept Ind & Syst Engn, Blacksburg, VA 24061 USA; [Alizadehsani, Roohallah] Deakin Univ, Inst Intelligent Syst Res & Innovat IISRI, Waurn Pond, Vic 3216, Australia; [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia; [Acharya, U. Rajendra] Univ Southern Queensland, Ctr Hlth Res, Springfield, Australia	Virginia Polytechnic Institute & State University; Deakin University; University of Southern Queensland; University of Southern Queensland	Nasarian, E (corresponding author), Virginia Tech, Grad Dept Ind & Syst Engn, Blacksburg, VA 24061 USA.	elhamn20@vt.edu		Nasarian, Elham/0009-0005-5225-1754				Abdul A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174156; Al-Shedivat M, 2018, Arxiv, DOI arXiv:1801.09808; Alabi RO, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19148366; Alia S., EXPLAINABLE ARTIFICI; Alizadehsani R, 2023, Arxiv, DOI arXiv:2309.12177; Alvarez-Melis D., 2018, P 32 INT C NEUR INF, P7786; Apley DW, 2020, J ROY STAT SOC B, V82, P1059, DOI 10.1111/rssb.12377; Arcadu F, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0172-3; Ayano YM, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010111; Azar AS, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02087-y; Balabaeva K., 2022, NEURAL ADDITIVE MODE; Balabaeva K, 2022, LECT NOTES COMPUT SC, V13352, P113, DOI 10.1007/978-3-031-08757-8_11; Band SS, 2023, Inf Med Unlock; Banerjee JS., 2023, SN COMPUT SCI, V4, P176, DOI DOI 10.1007/S42979-022-01605-Z; Barda AJ, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01276-x; Barnett AJ, 2022, Arxiv, DOI arXiv:2211.05207; Barnett AJ, 2022, PROC SPIE, V12035, DOI 10.1117/12.2612372; Barnett AJ, 2021, NAT MACH INTELL, V3, P1061, DOI 10.1038/s42256-021-00423-x; Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Besold TR, 2022, FRONT ARTIF INTEL AP, V342, P1, DOI 10.3233/FAIA210348; Bethge M, 2019, Arxiv, DOI arXiv:1904.00760; Bhatt U, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P648, DOI 10.1145/3351095.3375624; Biecek P, 2021, EXPLANAT MODEL ANAL, P107, DOI DOI 10.1201/9780429027192-11; Bien J, 2011, ANN APPL STAT, V5, P2403, DOI 10.1214/11-AOAS495; Bouktif S, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086456; Bouquet V, 2019, MED DROIT, P71, DOI 10.1016/j.meddro.2018.09.001; Cahour B, 2009, SAFETY SCI, V47, P1260, DOI 10.1016/j.ssci.2009.03.015; Card D, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P369, DOI 10.1145/3287560.3287595; Caruana R, 1999, J AM MED INFORM ASSN, P212; Char DS, 2020, AM J BIOETHICS, V20, P7, DOI 10.1080/15265161.2020.1819469; Chatila R, 2019, INTEL SYST CONTR AUT, V95, P11, DOI 10.1007/978-3-030-12524-0_2; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Che Zhengping, 2016, AMIA Annu Symp Proc, V2016, P371; Chen SF, 2024, Arxiv, DOI arXiv:2307.05385; Chen Z., 2023, C HLTH INF LEARN PML; Chimenti RV, 2021, LASER FOCUS WORLD, V57, P31; Chou T.-N., 2019, 2019 IEEE 2 INT C KN; Cox LA, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23050601; Crave M.W., 1996, EXTRACTING COMPREHEN; de Lima AD, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02021-2; Di Martino F, 2023, ARTIF INTELL REV, V56, P5261, DOI 10.1007/s10462-022-10304-3; Díaz-Rodríguez N, 2022, INFORM FUSION, V79, P58, DOI 10.1016/j.inffus.2021.09.022; Dodge J., 2018, IUI WORKSHOPS, P1; DuMouchel W, 2002, MASSIVE COMP, V4, P579; Ehsan U., 2019, GLASGOW 19; El-Rashidy N, 2023, NEURAL COMPUT APPL, V35, P7423, DOI 10.1007/s00521-022-08007-5; Elshawi R, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0874-0; Enholm IM, 2022, INFORM SYST FRONT, V24, P1709, DOI 10.1007/s10796-021-10186-w; Fang HS, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01566-y; Farah L., 2023, Mayo Clinic Proc: Digital Health, V1, P120, DOI DOI 10.1016/J.MCPDIG.2023.02.004; Figueroa CA, 2021, LANCET DIGIT HEALTH, V3, pE526, DOI 10.1016/S2589-7500(21)00118-7; Gadaleta M, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00533-1; Garcia G.-G.P., 2023, INTERPRETABLE POLICI; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Gerussi A, 2022, J PERS MED, V12, DOI 10.3390/jpm12101587; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Gimeno M, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad200; Goldstein A, 2015, J COMPUT GRAPH STAT, V24, P44, DOI 10.1080/10618600.2014.907095; Goyal S, 2019, BRIT J HOSP MED, V80, P168, DOI 10.12968/hmed.2019.80.3.168; Graban M., 2018, HEALTHCARE KAIZEN EN; Graban M., 2018, LEAN HOSP IMPROVING, DOI [10.4324/9781315380827, DOI 10.4324/9781315380827]; Graban M., 2013, EXECUTIVE GUIDE HEAL; Gruendner J, 2021, JMIR MED INF, V9, DOI 10.2196/25645; Gualdi F., 2021, ARTIFICIAL INTELLIGE; Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hatwell J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01201-2; Hijazi H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248424; Hind M, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P123, DOI 10.1145/3306618.3314273; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Holzinger A, 2021, INFORM FUSION, V71, P28, DOI 10.1016/j.inffus.2021.01.008; Hyvärinen A, 2009, COMPUT IMAGING VIS, V39, P1; Ibrahim H, 2021, LANCET DIGIT HEALTH, V3, pE260, DOI 10.1016/S2589-7500(20)30317-4; Ivaturi P, 2021, IEEE J BIOMED HEALTH, V25, P2398, DOI 10.1109/JBHI.2021.3060997; Jafari M, 2023, Arxiv, DOI arXiv:2210.14611; Jahmunah V, 2023, COMPUT METH PROG BIO, V229, DOI 10.1016/j.cmpb.2022.107308; Jansen T, 2020, STUD HEALTH TECHNOL, V270, P307, DOI 10.3233/SHTI200172; Javed AR, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1024195; Jiménez-Luna J, 2020, NAT MACH INTELL, V2, P573, DOI 10.1038/s42256-020-00236-4; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Karri M, 2022, COMPUT BIOL MED, V151, DOI 10.1016/j.compbiomed.2022.106231; Khare SK, 2023, KNOWL-BASED SYST, V278, DOI 10.1016/j.knosys.2023.110858; Khozeimeh F., 2022, 2022 IEEE 22 INT S C; Kim B, 2016, ADV NEUR IN, V29; Kinoshita F, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-42964-8; Knispel F, 2022, STUD HEALTH TECHNOL, V296, P33, DOI 10.3233/SHTI220801; Kokol P, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221109055; Krause J, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5686, DOI 10.1145/2858036.2858529; Kroll Joshua Alexander., 2015, Ph.D. thesis; Kronk CA, 2021, J AM MED INFORM ASSN, V29, P271, DOI 10.1093/jamia/ocab136; Krzysiak R, 2022, 2022 18TH IEEE/ASME INTERNATIONAL CONFERENCE ON MECHATRONIC AND EMBEDDED SYSTEMS AND APPLICATIONS (MESA 2022), DOI 10.1109/MESA55290.2022.10004460; Lengerich B.J., 2020, MEDRXIV; Letham B, 2015, ANN APPL STAT, V9, P1350, DOI 10.1214/15-AOAS848; Levy JJ, 2022, FRONT MED TECHNOL, V4, DOI 10.3389/fmedt.2022.926667; Li H., 2021, MEASUR SENS, V18; Lin H., 2011, P 49 ANN M ASS COMP, V1, P510, DOI DOI 10.1002/ART.33407; Linardatos P, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23010018; Lipton ZC., 2018, Queue, V16, P31, DOI DOI 10.1145/3236386.3241340; Liu H, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.814366; Liu JX, 2023, Arxiv, DOI arXiv:2307.01981; Loh DR, 2021, CIRCULATION, V144; Loh HW, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107161; Lu YT, 2023, J MED INTERNET RES, V25, DOI 10.2196/43734; Lundberg SM, 2017, ADV NEUR IN, V30; Marcus G, 2020, Arxiv, DOI [arXiv:2002.06177, DOI 10.48550/ARXIV.2002.06177]; Maritsch M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3382808; Marques-Silva J, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1128212; Mathews SC, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0111-3; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Meng CZ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11012-2; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Michaels M, 2023, AM J MED QUAL, V38, pS46, DOI 10.1097/JMQ.0000000000000133; Mincu D, 2022, NAT MACH INTELL, V4, P916, DOI 10.1038/s42256-022-00559-4; Misra D, 2021, J CLIN MED, V10, DOI 10.3390/jcm10020301; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28; Moreno-Sanchez PA, 2021, IEEE INT CONF HEALT, P527, DOI 10.1109/ICHI52183.2021.00100; Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116; Musacchio N, 2023, J DIABETES, V15, P224, DOI 10.1111/1753-0407.13361; Nahavandi D, 2022, COMPUT METH PROG BIO, V213, DOI 10.1016/j.cmpb.2021.106541; Nasarian E, 2023, Arxiv, DOI arXiv:2308.15339; Nasarian E, 2020, PATTERN RECOGN LETT, V133, P33, DOI 10.1016/j.patrec.2020.02.010; Nazary F, 2023, Arxiv, DOI arXiv:2308.09731; Ng A, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/33850; Ning Yilin, 2022, PLOS Digit Health, V1, pe0000062, DOI 10.1371/journal.pdig.0000062; Oei CW, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23187946; Olah C., 2018, Distill, DOI DOI 10.23915/DISTILL.00010; Ossa LA, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221074488; Ou Y.J., 2023, MEDICAL IMAGING 2023; Oztekin F, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13020226; Papagiannaki A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040880; Papernot N, 2018, Arxiv, DOI [arXiv:1803.04765, 10.48550/arXiv.1803.04765]; Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915; Payrovnaziri SN, 2020, J AM MED INFORM ASSN, V27, P1173, DOI 10.1093/jamia/ocaa053; Pearl J., 2010, OBJECT ASSESS, P39; Peng JF, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01736-5; Pereira S, 2018, MED IMAGE ANAL, V44, P228, DOI 10.1016/j.media.2017.12.009; Petch J, 2022, CAN J CARDIOL, V38, P204, DOI 10.1016/j.cjca.2021.09.004; Pintelas E, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060037; Plagwitz Lucas, 2022, Stud Health Technol Inform, V294, P109, DOI 10.3233/SHTI220406; Prados De Reyes M, 2014, STUD HEALTH TECHNOL, V205, P131, DOI 10.3233/978-1-61499-432-9-131; Preece A, 2018, INTELL SYST ACCOUNT, V25, P63, DOI 10.1002/isaf.1422; Hoffman RR, 2019, Arxiv, DOI arXiv:1812.04608; Rader E, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P173, DOI 10.1145/2702123.2702174; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225; Ribera M., 2019, CEUR WORKSHOP P; Rosella L., 2015, J CANAD HLTH LIBR AS, V36, P83; Roth A.E., 1988, SHAPLEY VALUE ESSAYS, P1, DOI [10.1017/CBO9780511528446.002, DOI 10.1017/CBO9780511528446]; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sadeghi Z, 2023, Arxiv, DOI arXiv:2304.01543; Saxe A, 2021, NAT REV NEUROSCI, V22, P55, DOI 10.1038/s41583-020-00395-8; Seoni S, 2023, COMPUT BIOL MED, V165, DOI 10.1016/j.compbiomed.2023.107441; Sha CY, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04209-1; Sha Y, 2017, ACM-BCB' 2017: PROCEEDINGS OF THE 8TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY,AND HEALTH INFORMATICS, P233, DOI 10.1145/3107411.3107445; Shamseer L, 2015, BMJ-BRIT MED J, V349, DOI 10.1136/bmj.g7647; Simon I, 2007, IEEE I CONF COMP VIS, P274; Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830; Smilkov D, 2016, Arxiv, DOI [arXiv:1611.05469, DOI 10.48550/ARXIV.1611.05469]; Smith AA, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-26951-z; Smuha N. A., 2019, Computer Law Review International, V20, P97, DOI [10.9785/cri-2019-200402, DOI 10.9785/CRI-2019-200402]; Sousa S., 2021, MEASURING TRUST TECH; Sun YS, 2023, Arxiv, DOI arXiv:2306.08871; Tallon-Ballesteros A.J., 2018, INT C INT DAT ENG AU; Tilouche S, 2021, STAT ANAL DATA MIN, V14, P501, DOI 10.1002/sam.11543; Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314; Topaloglu I, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.106887; Uddin MZ, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95947-y; Vaccari I, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113726; Valdes G, 2016, SCI REP-UK, V6, DOI 10.1038/srep37854; Valente F, 2021, ARTIF INTELL MED, V117, DOI 10.1016/j.artmed.2021.102113; Van Belle VMCA, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034312; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vilone G, 2021, INFORM FUSION, V76, P89, DOI 10.1016/j.inffus.2021.05.009; Vyas A, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02004-3; W.H. Organization, 2019, WHO GUIDELINE RECOMM; Wachter S., 2017, HARV JL TECH, V31, P841, DOI DOI 10.2139/SSRN.3063289; Wang F, 2020, ANN INTERN MED, V172, P59, DOI 10.7326/M19-2548; Waskom M., 2021, J OPEN SOURCE SOFTW, V6, P3021, DOI [10.21105/JOSS.03021, DOI 10.21105/JOSS.03021, 10.21105/joss.03021]; Wexler J., 2017, GOOGLE OPEN SOURCE B; Williams GJ, 2023, LANCET DIGIT HEALTH, V5, pe467, DOI 10.1016/S2589-7500(23)00087-0; Winkler JK, 2019, JAMA DERMATOL, V155, P1135, DOI 10.1001/jamadermatol.2019.1735; Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016; Yang K, 2023, RARE METALS, V42, P4128, DOI 10.1007/s12598-023-02411-z; Ye M., 2021, P 30 ACM INT C INF K; Zhang W, 2021, IEEE NETWORK, V35, P56, DOI [10.1109/MNET.011.2000718, 10.1109/MNET.011.2000613]; Zhang Y, 2022, BMC ENDOCR DISORD, V22, DOI 10.1186/s12902-022-01121-4; Zhou JL, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10050593; Zihni  E, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231166; Zytek A, 2022, IEEE T VIS COMPUT GR, V28, P1161, DOI 10.1109/TVCG.2021.3114864	191	1	1	8	8	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	AUG	2024	108								102412	10.1016/j.inffus.2024.102412	http://dx.doi.org/10.1016/j.inffus.2024.102412			30	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RL1T8		Green Submitted			2024-07-03	WOS:001227735900001
J	Cronjé, J				Cronje, Johannes			Exploring the Role of ChatGPT as a Peer Coach for Developing Research Proposals: Feedback Quality, Prompts, and Student Reflection	ELECTRONIC JOURNAL OF E-LEARNING			English	Article						Artificial Intelligence; ChatGPT; Research methods; GROW coaching		This paper describes the results of an archival desk -study that analyzed worksheets produced by four students using ChatGPT as a coach. ChatGPT is a Generative Pre -Trained Large Language model that can write comprehensively in various languages and styles. It was discovered that it could pass university level physics exams and perform at the level of a third -year medical student. Fourth -year students in Information Technology are required to produce a 3000 -to -5000 -word research report as part of the requirements for graduation, and their first meeting of the year consists of a workshop following the GROW (Goal, Reality, Opportunities, Will) coaching process. Logistical considerations in this predominantly elearning based course prevented such teamwork. The two -month -old ChatGPT, however, presented an opportunity to determine the extent to which a chatbot could be used as a peer coach. This paper reports on the outcome of an exercise that was given to students as an introduction to their research methodology course. It was found that well -designed prompts were essential and that students should be encouraged to reflect on their interaction with artificial intelligence. Three clear issues emerged from the study: the quality of feedback given by the chatbot, the value of the prompt, and the importance of student reflection. The chatbot, ChatGPT, displays the traditional computer characteristic of garbage in, garbage out and gives the feedback it is programmed to give. The dialogue shows how a student can build up mutual rapport with the chatbot when they adapt their responses to the feedback provided. The critical reflection in shows that it is still the user who should oversee the process and evaluate the feedback. It is recommended that novice research students be given some training in reacting to feedback, developing useful prompts, and engaging in meaningful reflection. Future research would include developing a reflective coach.	[Cronje, Johannes] Cape Peninsula Univ Technol, Fac Informat & Design, Cape Town, South Africa	Cape Peninsula University of Technology	Cronjé, J (corresponding author), Cape Peninsula Univ Technol, Fac Informat & Design, Cape Town, South Africa.	cronjej@cput.ac.za		Cronje, Johannes/0000-0002-9838-4609				Ackoff R.L., 1978, The art of problem solving: Accompanied by A c k of f s fables; Ameen K, 2019, INFORM DEV, V35, P592, DOI 10.1177/0266666918774875; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Bassett C, 2019, AI SOC, V34, P803, DOI 10.1007/s00146-018-0825-9; Clayson JE, 2021, BRIT J EDUC TECHNOL, V52, P1143, DOI 10.1111/bjet.13086; Cotton D.R.E., 2023, Chatting and Cheating: Ensuring academic integrity in the era of ChatGPT, DOI [10.35542/Osf.Io, DOI 10.35542/OSF.IO]; Eshghie M, 2023, Arxiv, DOI [arXiv:2304.09873, 10.48550/arXiv.2304.09873, DOI 10.48550/ARXIV.2304.09873]; Etikan I., 2016, American Journal of Theoretical and Applied Statistics, V5, P1, DOI [10.11648/j.ajtas.20160501, DOI 10.11648/J.AJTAS.20160501.11, 10.11648/j.ajtas.20160501.11]; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Garbutt M, 2016, ELECTR J INF SYS DEV, V77; Gilson A, 2022, medRxiv, DOI [10.1101/2022.12.23.22283901, 10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; Kahn K, 2021, BRIT J EDUC TECHNOL, V52, P1130, DOI 10.1111/bjet.13088; Kortemeyer G, 2023, Arxiv, DOI arXiv:2301.12127; Kumar R., 2019, Research methodology: A step-by-step guide for beginners; Labruna T, 2023, Arxiv, DOI arXiv:2305.14556; Lan P., 2023, International Journal of Multidisciplinary Research and Publications (IJMRAP), V5, P173; Lyerly E., 2023, Disability Compliance for Higher Education, V28, P2, DOI DOI 10.1002/DHE; Papert S., 1994, The children's machine: Rethinking school in the age of the computer; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Stojanov A, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00404-7; Vaiciuniene A., 2022, Technium social sciences journal, V33, P217; Whitmore J., 2002, COACHING PERFORMANCE, V3rd	22	1	1	4	4	ACAD CONFERENCES & PUBL INT LTD	NR READING	CURTIS FARM, KIDMORE END, NR READING, RG4 9AY, ENGLAND	1479-4403			ELECTRON J E-LEARN	Electron. J. E-Learn.	APR	2024	22	2			SI		1	15		10.34190/ejel.21.5.3042	http://dx.doi.org/10.34190/ejel.21.5.3042			15	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	QO5O9		gold			2024-07-03	WOS:001221829400003
J	Banerjee, A; Ahmad, A; Bhalla, P; Goyal, K				Banerjee, Arijita; Ahmad, Aquil; Bhalla, Payal; Goyal, Kavita			Assessing the Efficacy of ChatGPT in Solving Questions Based on the Core Concepts in Physiology	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						artificial intelligence (ai); transfer of learning; core concepts; medical physiology; chat gpt		Background and objectiveChatGPT is a large language model (LLM) generative artificial intelligence (AI) chatbot trained through deep learning to produce human-like language skills and analysis of simple problems across a wide variety of subject areas. However, in terms of facilitating the transfer of learning in medical education, a concern has arisen that while AI is adept at applying surface-level understanding, it does not have the necessary indepth knowledge to act at an expert level, particularly in addressing the core concepts. In this study, we explored the efficacy of ChatGPT in solving various reasoning questions based on the five core concepts applied to different modules in the subject of physiology.Materials and methodsIn this study, a total of 82 reasoning-type questions from six modules applicable to the five core concepts were created by the subject experts. The questions were used to chat with the conversational AI tool and the responses generated at first instance were considered for scoring and analysis. To compare the scores among various modules and five core concepts separately, the Kruskal-Wallis test along with post hoc analysis were used.ResultsThe overall mean score for the modules (60 questions) was 3.72 +0.26 while the average score obtained for the core concepts (60 questions) was 3.68 +0.30. Furthermore, statistically significant differences (p=0.05 for modules and p=0.024 for core concepts) were observed among various modules as well as core concepts. ConclusionThe significant differences observed in the scores among various modules and core concepts highlight the varying execution of the same software tool, thereby necessitating the need for further evaluation of AI enabled learning applications to enhance the transfer of learning among undergraduates.	[Banerjee, Arijita] Indian Inst Technol Kharagpur, Physiol, Kharagpur, India; [Ahmad, Aquil; Bhalla, Payal] Maulana Azad Med Coll, Physiol, New Delhi, India; [Goyal, Kavita] Shri Atal Bihari Vajpayee Med Coll, Physiol, Faridabad, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Kharagpur; Maulana Azad Medical College	Banerjee, A (corresponding author), Indian Inst Technol Kharagpur, Physiol, Kharagpur, India.	b.arijita@gmail.com		BANERJEE, ARIJITA/0000-0001-7191-1811				Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Hull K, 2017, HAPS Educ, V21, P73, DOI DOI 10.21692/HAPS.2017.041; McFarland JL, 2020, ADV PHYSIOL EDUC, V44, P626, DOI 10.1152/advan.00188.2019; Medenilla A., 2023, PLoS Digital Health, V2; Michael J, 2007, ADV PHYSIOL EDUC, V31, P34, DOI 10.1152/advan.00057.2006; Michael J, 2019, ADV PHYSIOL EDUC, V43, P373, DOI 10.1152/advan.00051.2019; Michael J, 2011, ADV PHYSIOL EDUC, V35, P336, DOI 10.1152/advan.00004.2011; Minasian-Batmanian L, 2005, BRIT J EDUC TECHNOL, V36, P335, DOI 10.1111/j.1467-8535.2005.00463.x; Minasian-Batmanian LC, 2002, MED TEACH, V24, P645, DOI 10.1080/0142159021000063998; Modell HI, 2000, ADV PHYSIOL EDUC, V23, P101, DOI 10.1152/advances.2000.23.1.S101; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; Shah Nilima, 2016, Indian J Pharmacol, V48, pS5, DOI 10.4103/0253-7613.193312; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237	14	4	4	12	21	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	AUG 10	2023	15	8								10.7759/cureus.43314	http://dx.doi.org/10.7759/cureus.43314			8	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Q0KC2	37700949	gold, Green Published			2024-07-03	WOS:001054475400028
C	Liao, LZ; Yang, GH; Shah, C			ACM	Liao, Lizi; Yang, Grace Hui; Shah, Chirag			Proactive Conversational Agents in the Post-ChatGPT World	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Proactive conversation; conversational search; conversational AI		ChatGPT and similar large language model (LLM) based conversational agents have brought shock waves to the research world. Although astonished by their human-like performance, we find they share a significant weakness with many other existing conversational agents in that they all take a passive approach in responding to user queries. This limits their capacity to understand the users and the task better and to offer recommendations based on a broader context than a given conversation. Proactiveness is still missing in these agents, including their ability to initiate a conversation, shift topics, or offer recommendations that take into account a more extensive context. To address this limitation, this tutorial reviews methods for equipping conversational agents with proactive interaction abilities. The full-day tutorial is divided into four parts, including multiple interactive exercises. We will begin the tutorial with an interactive exercise and cover the design of existing conversational systems architecture and challenges. The content includes coverage of LLM-based recent advancements such as ChatGPT and Bard, along with reinforcement learning with human feedback (RLHF) technique. Then we will introduce the concept of proactive conversation agents and preset recent advancements in proactiveness of conversational agents, including actively driving conversations by asking questions, topic shifting, and methods that support strategic planning of conversation. Next, we will discuss important issues in conversational responses' quality control, including safety, appropriateness, language detoxication, hallucination, and alignment. Lastly, we will launch another interactive exercise and discussion with the audience to arrive at concluding remarks, prospecting open challenges and new directions. By exploring new techniques for enhancing conversational agents' proactive behavior to improve user engagement, this tutorial aims to help researchers and practitioners develop more effective conversational agents that can better understand and respond to user needs proactively and safely.	[Liao, Lizi] Singapore Management Univ, Singapore, Singapore; [Yang, Grace Hui] Georgetown Univ, Washington, DC USA; [Shah, Chirag] Univ Washington, Seattle, WA USA	Singapore Management University; Georgetown University; University of Washington; University of Washington Seattle	Liao, LZ (corresponding author), Singapore Management Univ, Singapore, Singapore.	lzliao@smu.edu.sg; grace.yang@georgetown.edu; chirags@uw.edu	WANG, SHIHAO/KHC-8263-2024	Yang, Grace Hui/0000-0001-6095-8358; Liao, Lizi/0000-0002-9973-3305	Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant	Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant(Ministry of Education, Singapore)	This research was supported by the Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grant.	Baek Christina, 2022, AGREEMENT ON THE LIN; BAHETI A, 2021, EMNLP, P4846; Bai Yuntao, 2022, ARXIV220405862 CS CL; Bi Keping, 2021, SIGIR 21; Carlsmith Joseph, 2022, ARXIV220613353 CS CY; CHEN LM, 2020, SIGIR, P1525, DOI DOI 10.1145/3397271.3401200; Chiu S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6143; CHUA K, 2018, NEURIPS, V31; Dalton J., 2021, TREC; Dalton J, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3455, DOI 10.1145/3477495.3532678; Das B, 2022, COGN SYST RES, V72, P14, DOI 10.1016/j.cogsys.2021.11.002; Dinan E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4113; Dinan Emily, 2019, EMNLP; Fu ZH, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P494, DOI 10.1145/3459637.3482461; Gao Luyu, 2022, ARXIV221008726 CS CL; Gupta P, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3018; Hendahewa C, 2017, INFORM PROCESS MANAG, V53, P905, DOI 10.1016/j.ipm.2017.04.001; Konigari Rachna, 2021, P 22 ANN M SPEC INT; Kumar Aviral, 2020, ABS200604779 CORR; Li Raymond, 2018, NEURIPS; Li Zelong, 2022, SIGIR; Liao LZ, 2022, IEEE T KNOWL DATA EN, V34, P2485, DOI 10.1109/TKDE.2020.3008563; Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; LIU Q, 2021, FINDINGS ASS COMPUTA, P1098, DOI DOI 10.1145/3447548.3467441; Liu ZM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1036; Miller John P., 2021, ACCURACY LINE STRONG, P7721; Moon S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P845; Ngo Helen, 2021, ABS210807790 CORR; Open AI, 2022, DHATGPT; OpenAI, 2023, ARXIV230308774 CS CL; Qin JH, 2020, AAAI CONF ARTIF INTE, V34, P8657; Radford A., 2018, IMPROVING LANGUAGE U; Ren XH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P808, DOI 10.1145/3404835.3462839; Schick Timo, 2023, ARXIV230204761; Schulman John, 2017, ARXIV 1707 06347; Tang J., 2019, ACL; Tang ZW, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1861; Tang ZW, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3497875; Tishby N., 1999, P 37 ANN ALL C COMM, P1, DOI DOI 10.48550/ARXIV.1904.06979; Verma Siddharth, 2022, CHAI CHATBOT AI TASK; WALKER M, 1990, 28TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P70; Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5635; Wu WQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3794; XU J, 2020, ACL, P1835; Ye CC, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P155, DOI 10.1145/3477495.3532063; Yingxu He, 2021, MuCAI'21: Proceedings of the 2nd ACM Multimedia Workshop on Multimodal Conversational AI, P3, DOI 10.1145/3475959.3485392; YuxiaWu Lizi Liao, 2022, TMM; ZHANG B, 2021, ICWS, P335, DOI DOI 10.1109/ICWS53863.2021.00051; Zhang SZ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2204; Zhou Kun, 2020, P 28 INT C COMPUTATI, P4128, DOI [10.18653/v1/2020.coling-main.365, DOI 10.18653/V1/2020.COLING-MAIN.365]; Zhu YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2000, DOI 10.1145/3404835.3463011; ZOU J, 2019, CIKM, P369, DOI DOI 10.1145/3357384.3357967; Zou J, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P881, DOI 10.1145/3397271.3401180; Zuohui Fu, 2020, RecSys '20: Fourteenth ACM Conference on Recommender Systems, P751, DOI 10.1145/3383313.3411548	55	3	3	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							3452	3455		10.1145/3539618.3594250	http://dx.doi.org/10.1145/3539618.3594250			4	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		Bronze, Green Published			2024-07-03	WOS:001118084003087
J	Chen, XY; Gao, S; Li, MZ; Zhu, QQ; Gao, X; Zhang, XL				Chen, Xiuying; Gao, Shen; Li, Mingzhe; Zhu, Qingqing; Gao, Xin; Zhang, Xiangliang			Write Summary Step-by-Step: A Pilot Study of Stepwise Summarization	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING			English	Article						Text generation; abstraction summarization; neural networks		Nowadays, neural text generation has made tremendous progress in abstractive summarization tasks. However, most of the existing summarization models take in the whole document all at once, which sometimes cannot meet the needs in practice. Practically, social text streams such as news events and tweets keep growing from time to time, and can only be fed to the summarization system step by step. Hence, in this paper, we propose the task of Stepwise Summarization, which aims to generate a new appended summary each time a new document is proposed. The appended summary should not only summarizes the newly added content but is also coherent with the previous summary, to form an up-to-date complete summary. To tackle this challenge, we design an adversarial learning model, named Stepwise Summary Generator (SSG). First, SSG selectively processes the new document under the guidance of the previous summary, obtaining polished document representation. Next, SSG generates the summary considering both the previous summary and the document. Finally, a convolutional-based discriminator is employed to determine whether the newly generated summary is coherent with the previous summary. For the experiment, we extend the traditional two-step update summarization setting to multi-step stepwise setting, and re-propose a large-scale stepwise summarization dataset based on a public story generation dataset. Extensive experiments on this dataset show that SSG achieves state-of-the-art performance in terms of both automatic metrics and human evaluations. Ablation studies demonstrate the effectiveness of each module in our framework. We also discuss the benefits and limitations of recent large language models on this task.	[Chen, Xiuying; Gao, Xin] KAUST, Comp Elect & Math Sci & Engn Div, Jeddah 23955, Saudi Arabia; [Gao, Shen] Univ Elect Sci & Technol China, Chengdu 611731, Peoples R China; [Li, Mingzhe] Ant Grp, Hangzhou 310058, Peoples R China; [Zhu, Qingqing] Peking Univ, Beijing 100871, Peoples R China; [Zhang, Xiangliang] Univ Notre Dame, Notre Dame, IN 46556 USA; [Zhang, Xiangliang] King Abdullah Univ Sci & Technol, Jeddah 23955, Saudi Arabia	King Abdullah University of Science & Technology; University of Electronic Science & Technology of China; Peking University; University of Notre Dame; King Abdullah University of Science & Technology	Gao, X (corresponding author), KAUST, Comp Elect & Math Sci & Engn Div, Jeddah 23955, Saudi Arabia.; Zhang, XL (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.	xiuying.chen@kaust.edu.sa; shengao@sdu.edu.cn; limingzhe.lmz@antgroup.com; zhuqingqing@pku.edu.cn; xin.gao@kaust.edu.sa; xzhang33@nd.edu	Chen, Xiuying/ISU-7033-2023; Gao, Xin/D-5487-2013	Chen, Xiuying/0000-0002-6633-0796; Zhang, Xiangliang/0000-0002-3574-5665; Gao, Xin/0000-0002-7108-3574; Li, Mingzhe/0000-0002-0883-3678	King Abdullah University of Science and Technology	King Abdullah University of Science and Technology(King Abdullah University of Science & Technology)	No Statement Available	Allan J., 2001, P 24 ANN INT ACM SIG, P10; [Anonymous], 2016, P 2016 C EMPIRICAL M; Boudin F., 2008, PROC 22 INT C COMPUT, P1; Celikyilmaz A, 2018, ARXIVABS180310357 CO; Chen MD, 2022, Arxiv, DOI arXiv:2109.08833; Chen XY, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3517221; Chen XY, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4939; Chen XY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4088; Clarke J, 2010, COMPUT LINGUIST, V36, P411, DOI 10.1162/coli_a_00004; Dang H. T., 2008, PROC TAC, P1; Delort J., 2012, P 13 C EUR CHAPT ASS, P214; Dong Y, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3739; Gehrmann S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4098; Ghalandari DG, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1322; Gidiotis A, 2020, IEEE-ACM T AUDIO SPE, V28, P3029, DOI 10.1109/TASLP.2020.3037401; Gillick Dan, 2009, Proceedings of the Workshop on Integer Linear Programming for Natural Langauge Processing, P10; Grusky M., 2018, P 2018 C N AM CHAPTE, V1, P708, DOI [10.18653/v1/N18-1065, DOI 10.18653/V1/N18-1065, 10.18653/v1/n18-1065]; Gu JT, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1631; Hermann KM, 2015, ADV NEUR IN, V28; Holtzman A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1638; Hsu WT, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P132; Jadhav A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P142; Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519; Kingma D. P., 2017, ARXIV; Lewis Mike, 2020, P 58 ANN M ASS COMP, P7871; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070; Mihalcea R., 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064; Mnasri M., 2017, PROC 8 INT JOINT C N, P204; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayan Shashi, 2018, P 2018 C N AM CHAPT, P280, DOI [DOI 10.18653/V1/N18-1158, 10.18653/v1/N18-1158]; Olariu A., 2014, EACL, P236, DOI 10.3115/v1/E14-4046; Pascanu R., 2013, INT C MACHINE LEARNI, V28, P1310, DOI DOI 10.5555/3042817.3043083; Ren ZC, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P387, DOI 10.1145/2983323.2983710; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Shou LD, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P533; Stent A, 2005, LECT NOTES COMPUT SC, V3406, P341; Su MH, 2020, IEEE-ACM T AUDIO SPE, V28, P2061, DOI 10.1109/TASLP.2020.3006731; Vaswani A, 2017, ADV NEUR IN, V30; Wang K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2153; Xu J, 2020, ACL, P5021; Xu S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1355; Yan R, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P745; Yan Rui, 2011, P 2011 C EMPIRICAL M, P433; Yu Y, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P377; Zhang J., 2020, PMLR, P11328; Zhang JJ, 2019, IEEE-ACM T AUDIO SPE, V27, P507, DOI 10.1109/TASLP.2018.2883740; Zhang JJ, 2016, IEEE-ACM T AUDIO SPE, V24, P1842, DOI 10.1109/TASLP.2016.2586608; Zhang T., 2020, PROC INT C LEARN REP; Zhao WX, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1061; Zhong Ming, 2020, P 58 ANN M ASS COMPU, P6197, DOI [10.18653/v1/2020.acl-main.552, DOI 10.18653/V1/2020.ACL-MAIN.552]; Zhou QY, 2020, IEEE-ACM T AUDIO SPE, V28, P671, DOI 10.1109/TASLP.2020.2964427	52	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2329-9290	2329-9304		IEEE-ACM T AUDIO SPE	IEEE-ACM Trans. Audio Speech Lang.		2024	32						1406	1415		10.1109/TASLP.2024.3357040	http://dx.doi.org/10.1109/TASLP.2024.3357040			10	Acoustics; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Acoustics; Engineering	IG7K5		Green Submitted			2024-07-03	WOS:001165239700004
J	Shimizu, I; Kasai, H; Shikino, K; Araki, N; Takahashi, Z; Onodera, M; Kimura, Y; Tsukamoto, T; Yamauchi, K; Asahina, M; Ito, S; Kawakami, E				Shimizu, Ikuo; Kasai, Hajime; Shikino, Kiyoshi; Araki, Nobuyuki; Takahashi, Zaiya; Onodera, Misaki; Kimura, Yasuhiko; Tsukamoto, Tomoko; Yamauchi, Kazuyo; Asahina, Mayumi; Ito, Shoichi; Kawakami, Eiryo			Developing Medical Education Curriculum Reform Strategies to Address the Impact of Generative AI: Qualitative Study	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; curriculum reform; generative artificial intelligence; large language models; medical education; qualitative; analysis; strengths-weaknesses-opportunities-threats (SWOT) framework	FACULTY-DEVELOPMENT; VIRTUAL PATIENTS; TOOL	Background: Generative artificial intelligence (GAI), represented by large language models, have the potential to transform health care and medical education. In particular, GAI's impact on higher education has the potential to change students' learning experience as well as faculty's teaching. However, concerns have been raised about ethical consideration and decreased reliability of the existing examinations. Furthermore, in medical education, curriculum reform is required to adapt to the revolutionary changes brought about by the integration of GAI into medical practice and research. Objective: This study analyzes the impact of GAI on medical education curricula and explores strategies for adaptation. Methods: The study was conducted in the context of faculty development at a medical school in Japan. A workshop involving faculty and students was organized, and participants were divided into groups to address two research questions: (1) How does GAI affect undergraduate medical education curricula? and (2) How should medical school curricula be reformed to address the impact of GAI? The strength, weakness, opportunity, and threat (SWOT) framework was used, and cross-SWOT matrix analysis was used to devise strategies. Further, 4 researchers conducted content analysis on the data generated during the workshop discussions. Results: The data were collected from 8 groups comprising 55 participants. Further, 5 themes about the impact of GAI on medical education curricula emerged: improvement of teaching and learning, improved access to information, inhibition of existing learning processes, problems in GAI, and changes in physicians' professionality. Positive impacts included enhanced teaching and learning efficiency and improved access to information, whereas negative impacts included concerns about reduced independent thinking and the adaptability of existing assessment methods. Further, GAI was perceived to change the nature of physicians' expertise. Three themes emerged from the cross-SWOT analysis for curriculum reform: (1) learning about GAI, (2) learning with GAI, and (3) learning aside from GAI. Participants recommended incorporating GAI literacy, ethical considerations, and compliance into the curriculum. Learning with GAI involved improving learning efficiency, supporting information gathering and dissemination, and facilitating patient involvement. Learning aside from GAI emphasized maintaining GAI-free learning processes, fostering higher cognitive domains of learning, and introducing more communication exercises. Conclusions: This study highlights the profound impact of GAI on medical education curricula and provides insights into curriculum reform strategies. Participants recognized the need for GAI literacy, ethical education, and adaptive learning. Further, GAI was recognized as a tool that can enhance efficiency and involve patients in education. The study also suggests that medical education should focus on competencies that GAI hardly replaces, such as clinical experience and communication. Notably, involving both faculty and students in curriculum reform discussions fosters a sense of ownership and ensures broader perspectives are encompassed.	[Shimizu, Ikuo; Kasai, Hajime; Araki, Nobuyuki; Takahashi, Zaiya; Onodera, Misaki; Tsukamoto, Tomoko; Ito, Shoichi] Chiba Univ, Grad Sch Med, Dept Med Educ, 1-8-1 Inohana, Chiba 2608672, Japan; [Shikino, Kiyoshi; Kimura, Yasuhiko; Yamauchi, Kazuyo; Asahina, Mayumi; Ito, Shoichi] Chiba Univ Hosp, Hlth Profess Dev Ctr, Chiba, Japan; [Shikino, Kiyoshi; Yamauchi, Kazuyo] Chiba Univ, Grad Sch Med, Dept Community Oriented Med Educ, Chiba, Japan; [Kawakami, Eiryo] Chiba Univ, Grad Sch Med, Dept Artificial Intelligence Med, Chiba, Japan	Chiba University; Chiba University; Chiba University; Chiba University	Shimizu, I (corresponding author), Chiba Univ, Grad Sch Med, Dept Med Educ, 1-8-1 Inohana, Chiba 2608672, Japan.	qingshuiyufu@gmail.com		Takahashi, Zaiya/0000-0002-8520-9502; Kasai, Hajime/0000-0002-6759-2026; Yamauchi, Kazuyo/0000-0001-6587-2393; Shikino, Kiyoshi/0000-0002-3721-3443; Shimizu, Ikuo/0000-0002-6731-7104; Onodera, Misaki/0009-0002-0126-9143				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Aldehayyat JS, 2008, STRATEG CHANG, V17, P281, DOI 10.1002/jsc.833; [Anonymous], 2022, The model core curriculum for medical education in Japan; [Anonymous], 2023, The handling of generative AI in teaching aspects at universities and technical colleges; Benzaghta M.A., 2021, J. Glob. Bus. Insights, V6, P55, DOI [DOI 10.5038/2640-6489.6.1.1148, 10.5038/2640-6489.6.1.1148]; Berman N, 2009, ACAD MED, V84, P942, DOI 10.1097/ACM.0b013e3181a8c668; Boscardin CK, 2024, ACAD MED, V99, P22, DOI 10.1097/ACM.0000000000005439; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Consorti F, 2021, MED TEACH, V43, P546, DOI 10.1080/0142159X.2021.1877266; Cook DA, 2009, MED EDUC, V43, P303, DOI 10.1111/j.1365-2923.2008.03286.x; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; de Vries-Erich J, 2017, J INTERPROF CARE, V31, P170, DOI 10.1080/13561820.2016.1261099; Dijk SW, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-037217; Frenk J, 2010, LANCET, V376, P1923, DOI 10.1016/S0140-6736(10)61854-5; García-Peñalvo FJ, 2023, EDUC KNOWL SOC, V24, DOI 10.14201/eks.31279; Graneheim UH, 2017, NURS EDUC TODAY, V56, P29, DOI 10.1016/j.nedt.2017.06.002; Grunhut J, 2022, JMIR MED EDUC, V8, DOI 10.2196/35587; Harden RM, 2001, MED TEACH, V23, P123, DOI 10.1080/01421590120036547; Hwang JY, 2024, MED TEACH, V46, P291, DOI 10.1080/0142159X.2023.2259068; Kozu T, 2006, ACAD MED, V81, P1069, DOI 10.1097/01.ACM.0000246682.45610.dd; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Learned E.P., 1969, BUSINESS POLICY TEXT; Liu A, 2023, As uni goes back, here's how teachers and students can use ChatGPT to save time and improve learning; Longhurst GJ, 2020, ANAT SCI EDUC, V13, P298, DOI 10.1002/ase.1967; Meskó B, 2018, BMC HEALTH SERV RES, V18, DOI 10.1186/s12913-018-3359-4; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Miao F., 2023, Guidance for generative ai in education and research; Minea-Pic A., 2020, OECD Education Working Papers, V237; Moritz S, 2023, GMS J MED EDU, V40, DOI 10.3205/zma001636; Müller MEB, 2023, MED EDUC, V57, P1156, DOI 10.1111/medu.15211; Peng YF, 2023, NAT MED, V29, P1593, DOI 10.1038/s41591-023-02366-9; Qadir Junaid, 2023, 2023 IEEE Global Engineering Education Conference (EDUCON), P1, DOI 10.1109/EDUCON54358.2023.10125121; Rospigliosi PA, 2023, INTERACT LEARN ENVIR, V31, P1, DOI 10.1080/10494820.2023.2180191; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Ruiz JG, 2006, ACAD MED, V81, P207, DOI 10.1097/00001888-200603000-00002; Ryznar Margaret., 2023, Washington and Lee Law Review Online, V80, P305; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Steinert Y, 2012, MED TEACH, V34, P483, DOI 10.3109/0142159X.2012.680937; Steinert Y, 2010, MED TEACH, V32, P425, DOI 10.3109/01421591003677897; Stoller JK, 2021, CHEST, V159, P743, DOI 10.1016/j.chest.2020.09.087; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Topor David R, 2018, MedEdPORTAL, V14, P10766, DOI 10.15766/mep_2374-8265.10766; van der Vleuten CPM, 2012, MED TEACH, V34, P205, DOI 10.3109/0142159X.2012.652239; WEIHRICH H, 1982, LONG RANGE PLANN, V15, P54, DOI 10.1016/0024-6301(82)90120-0; Wheelan T.L., 1998, STRATEG MANAG, V5th	46	2	2	42	48	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e53466	10.2196/53466	http://dx.doi.org/10.2196/53466			11	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Z9BQ6	38032695	Green Published, gold			2024-07-03	WOS:001114957800002
C	Fan, RZ; Fan, YX; Chen, JG; Guo, JF; Zhang, RQ; Cheng, XQ		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Fan, Run-Ze; Fan, Yixing; Chen, Jiangui; Guo, Jiafeng; Zhang, Ruqing; Cheng, Xueqi			RIGHT: Retrieval-Augmented Generation for Mainstream Hashtag Recommendation	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Hashtag recommendation; Retrieval-augmented generation; Social media		Automatic mainstream hashtag recommendation aims to accurately provide users with concise and popular topical hashtags before publication. Generally, mainstream hashtag recommendation faces challenges in the comprehensive difficulty of newly posted tweets in response to new topics, and the accurate identification of mainstream hashtags beyond semantic correctness. However, previous retrieval-based methods based on a fixed predefined mainstream hashtag list excel in producing mainstream hashtags, but fail to understand the constant flow of up-to-date information. Conversely, generation-based methods demonstrate a superior ability to comprehend newly posted tweets, but their capacity is constrained to identifying mainstream hashtags without additional features. Inspired by the recent success of the retrieval-augmented technique, in this work, we attempt to adopt this framework to combine the advantages of both approaches. Meantime, with the help of the generator component, we could rethink how to further improve the quality of the retriever component at a low cost. Therefore, we propose RetrI eval-augmented Generative Mainstream HashTag Recommender (RIGHT), which consists of three components: (i) a retriever seeks relevant hashtags from the entire tweet-hashtags set; (ii) a selector enhances mainstream identification by introducing global signals; and (iii) a generator incorporates input tweets and selected hashtags to directly generate the desired hashtags. The experimental results show that our method achieves significant improvements over state-of-the-art baselines. Moreover, RIGHT can be easily integrated into large language models, improving the performance of ChatGPT by more than 10%. Code will be released at: https://github.com/ict-bigdatalab/RIGHT.	[Fan, Run-Ze; Fan, Yixing; Chen, Jiangui; Guo, Jiafeng; Zhang, Ruqing; Cheng, Xueqi] Chinese Acad Sci, ICT, CAS Key Lab Network Data Sci & Technol, Beijing, Peoples R China; [Fan, Run-Ze; Fan, Yixing; Chen, Jiangui; Guo, Jiafeng; Zhang, Ruqing; Cheng, Xueqi] Univ Chinese Acad Sci, Beijing, Peoples R China	Chinese Academy of Sciences; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Guo, JF (corresponding author), Chinese Acad Sci, ICT, CAS Key Lab Network Data Sci & Technol, Beijing, Peoples R China.; Guo, JF (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.	fanrunze21s@ict.ac.cn; fanyixing@ict.ac.cn; chenjiangui18z@ict.ac.cn; guojiafeng@ict.ac.cn; zhangruqing@ict.ac.cn; cxq@ict.ac.cn			National Natural Science Foundation of China (NSFC) [62372431, 62006218]; Youth Innovation Promotion Association CAS [2021100]; Lenovo-CAS Joint Lab Youth Scientist Project;  [2023YFA1011602];  [JCKY2022130C039];  [2021QY1701]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Youth Innovation Promotion Association CAS; Lenovo-CAS Joint Lab Youth Scientist Project; ; ; 	This work was funded by the National Natural Science Foundation of China (NSFC) under Grants No. 62372431, and 62006218, the Youth Innovation Promotion Association CAS under Grants No. 2021100, the project under Grants No. 2023YFA1011602, JCKY2022130C039 and 2021QY1701, and the Lenovo-CAS Joint Lab Youth Scientist Project. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.	[Anonymous], 2010, WWW; Asai A., 2023, P 61 ANN M ASS COMPU, P41, DOI DOI 10.18653/V1/2023.ACL-TUTORIALS.6; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6251; Chen DQ, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1870, DOI 10.18653/v1/P17-1171; Chen JG, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P306, DOI 10.1145/3583780.3614821; Chen JG, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1448, DOI 10.1145/3539618.3591631; Chen JG, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P191, DOI 10.1145/3511808.3557271; Chen JG, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2184, DOI 10.1145/3477495.3531827; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding Z., 2012, COLING; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Gao Y, 2022, NAACL, DOI [10.18653/v1/2022.findingsnaacl.92, DOI 10.18653/V1/2022.FINDINGSNAACL.92]; Gong Y., 2015, P 2015 C EMP METH NA, P401, DOI [DOI 10.18653/V1/D15-1046, 10.18653/v1/D15-1046]; Gong Y., 2016, Hashtag recommendation using attention-based convolutional neural network; He HF, 2022, Arxiv, DOI arXiv:2301.00303; He S., 2023, P 2023 C EMP METH NA, P14685; He S, 2023, Arxiv, DOI arXiv:2308.15982; Huang H., 2016, COLING; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kim J., 2021, EMNLP, DOI [10.18653/v1/2021.emnlpmain.209, DOI 10.18653/V1/2021.EMNLPMAIN.209]; Kingma D. P., 2017, ARXIV; Kocoń J, 2023, Arxiv, DOI arXiv:2302.10724; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li JL, 2023, Arxiv, DOI arXiv:2310.05470; Li XZ, 2023, Arxiv, DOI arXiv:2305.05862; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mao QR, 2022, KNOWL-BASED SYST, V254, DOI 10.1016/j.knosys.2022.109581; Mialon G., 2023, arXiv; Ni S., 2023, ANN INT ACM SIGIR C, P1; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, Preprints; Raffel C, 2020, J MACH LEARN RES, V21; Ramos R., 2023, EACL; Raunak V, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1172; Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232; Wang S, 2022, ACL, DOI [10.18653/v1/2022.acllong.226, DOI 10.18653/V1/2022.ACLLONG.226]; Wang SK, 2023, IEEE T MULTIMEDIA, V25, P2749, DOI 10.1109/TMM.2022.3151029; Wang SK, 2022, IEEE T MULTIMEDIA, V24, P2595, DOI 10.1109/TMM.2021.3087038; Wang Y., 2019, NAACL, DOI DOI 10.18653/V1/N19-1164; Weston Jason, 2014, EMNLP, P1822, DOI [10.3115/v1/d14-1194, DOI 10.3115/V1/D14-1194, 10.3115/v1/D14-1194]; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Zhang H., 2023, FINDINGS ASS COMPUTA, P6373; Zhang Q, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3420; Zhang Qi, 2016, P 2016 C EMPIRICAL M, P836, DOI [10.18653/v1/D16-1080, DOI 10.18653/V1/D16-1080]; Zhang X, 2022, COLING; Zhang Y., 2018, NAACL, V1, P1676, DOI DOI 10.18653/V1/N18-1151; Zheng XW, 2021, Arxiv, DOI arXiv:2104.08723	49	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56026-2; 978-3-031-56027-9	LECT NOTES COMPUT SC			2024	14608						39	55		10.1007/978-3-031-56027-9_3	http://dx.doi.org/10.1007/978-3-031-56027-9_3			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DX		Green Submitted			2024-07-03	WOS:001211830500003
J	Singh, S; Tiwary, US				Singh, Sumit; Tiwary, Uma Shanker			ACRF: Aggregated Conditional Random Field for Out of Vocab (OOV) Token Representation for Hindi NER	IEEE ACCESS			English	Article						CRF; LLM; NER; NLP; transformer		Named entities are random, like emerging entities and complex entities. Most of the large language model's tokenizers have fixed vocab; hence, they tokenize out-of-vocab (OOV) words into multiple sub-words during tokenization. During fine-tuning for any downstream task, these sub-words (tokens) make the named entity classification more complex since, for each sub-word, an extra entity type is assigned for utilizing the word embedding of the sub-word. This work attempts to reduce this complexity by aggregating token embeddings of each word. In this work, we have applied Aggregated-CRF (ACRF), where a conditional random field (CRF) is applied at the top of aggregated token embeddings for named entity prediction. Aggregation is done at embeddings of all tokens generated by a tokenizer corresponding to a word. The experiment was done with two Hindi datasets (HiNER and Hindi Multiconer2). This work showed that the ACRF is better than vanilla CRF (where token embeddings are not aggregated). Also, our result outperformed the existing best result at HiNER data, which was done by applying a cross-entropy classification layer. Further, An analysis of the impact of tokenization has been conducted, both generally and according to entity types for each word present in test data, and the results show that ACRF performed better for the words which tokenized in more than one sub-words (OOV) compared to vanilla CRF. In addition, this work conducts a comparative analysis between two transformer-based models, MuRIL-large and XLM-roberta-large and investigates how these models adopt aggregation strategy based on OOV.	[Singh, Sumit; Tiwary, Uma Shanker] Indian Inst Informat Technol Allahabad, Allahabad 211012, India	Indian Institute of Information Technology Allahabad	Singh, S (corresponding author), Indian Inst Informat Technol Allahabad, Allahabad 211012, India.	pse2017004@iiita.ac.in		Tiwary, Uma Shanker/0000-0001-7206-9013				Al-Smadi I., 2019, IEEE Access, V7; Aone C, 1999, ADVANCES IN AUTOMATIC TEXT SUMMARIZATION, P71; Babych B., 2003, P 7 INT EAMT WORKSH; Bhardwaj Bhavya, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P261, DOI 10.1109/ICACCS51430.2021.9441888; Chen C., 2023, PROC INTJOINT C NEUR, P1; Chen J.-Y., 2022, 16 INT WORKSHOP SEMA, P1613; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Fetahu B, 2023, Arxiv, DOI arXiv:2305.06586; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang ZH, 2015, Arxiv, DOI [arXiv:1508.01991, DOI 10.48550/ARXIV.1508.01991]; Kakwani D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4948; Khanuja S, 2021, Arxiv, DOI arXiv:2103.10730; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Ma XZ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1064; Malmasi S., 2022, P 16 INT WORKSHOP SE, P1412; McCallum A., 2000, ICML, P591; Meng T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1499; Murthy R., 2022, PROC INT C LANG RESO, P1; O'Shea K, 2015, Arxiv, DOI [arXiv:1511.08458, DOI 10.48550/ARXIV.1511.08458]; OpenAI, Introducing ChatGPT; Panchendrarajan R, 2018, PROC 32 PACIFIC ASIA, P1; Qian T, 2021, IEEE-ACM T AUDIO SPE, V29, P1438, DOI 10.1109/TASLP.2021.3069295; Qin C., 2023, P 2023 C EMPIRICAL M, P1339; Reddy A, 2010, IEEE T AUDIO SPEECH, V18, P2015, DOI 10.1109/TASL.2010.2040793; Sabane Maithili, 2023, 2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC), P1666, DOI 10.1109/ICAAIC56838.2023.10141204; Sharma R, 2022, COMPUT SPEECH LANG, V74, DOI 10.1016/j.csl.2022.101356; Singh S., 2023, PROC 17 INTWORKSHOP, P1183; Singh S., 2022, PROC 16 INT WORKSHOP, P1536; Sutton C., 2004, ICML 04, P99; Vaswani N., 2017, Adv.Neural Inf. Process. Syst., P1; Wang Xinyu, 2022, P 16 INT WORKSHOP SE, P1457; Xie T., 2023, P 2023 C EMP METH NA, P7935; Yamada I, 2020, Arxiv, DOI arXiv:2010.01057	36	0	0	0	0	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						22707	22717		10.1109/ACCESS.2024.3362645	http://dx.doi.org/10.1109/ACCESS.2024.3362645			11	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	IB7Z0		gold			2024-07-03	WOS:001163940600001
J	Mumuni, F; Mumuni, A				Mumuni, Fuseini; Mumuni, Alhassan			Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning	COGNITIVE SYSTEMS RESEARCH			English	Article						Domain knowledge; Cognitive architecture; Brain-inspired neural network; Explainable AI; Adversarial attack; Zero-shot generalization	NEURAL-NETWORKS; DATA FUSION; BLACK-BOX; ARCHITECTURE; BRAIN; GRAPH; RECOGNITION; PERFORMANCE; CELLS	We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-shot learning. Data-driven machine learning models have achieved remarkable performance and demonstrated capabilities surpassing humans in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or fewshot generalization problem. Although many conventional solutions exist, explicit domain knowledge, braininspired neural networks and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms like mathematical relations, logic rules, knowledge graphs, and large language models (LLMs). and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human brain to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience-that is, to deepen human understanding on how the brain works in general, and how it handles these problems.	[Mumuni, Fuseini] Univ Mines & Technol UMaT, Dept Elect & Elect Engn, Tarkwa, Ghana; [Mumuni, Alhassan] Cape Coast Tech Univ, Dept Elect & Elect Engn, Cape Coast, Ghana; [Mumuni, Fuseini] POB 237, Tarkwa, Ghana		Mumuni, F (corresponding author), POB 237, Tarkwa, Ghana.	fmumuni@umat.edu.gh; alhassan.mumuni@cctu.edu.gh		Mumuni, Fuseini/0000-0002-4894-3775				Abbott LF, 2000, NAT NEUROSCI, V3, P1178, DOI 10.1038/81453; Abdel-Karim B. M., 2023, Business & Information Systems Engineering, P1; Adeli H, 2023, J VISION, V23, DOI 10.1167/jov.23.5.16; Ahmadi N, 2019, Arxiv, DOI arXiv:1906.09198; Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911; Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385; Alqaraawi A, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P275, DOI 10.1145/3377325.3377519; Anderson JR, 2004, PSYCHOL REV, V111, P1036, DOI 10.1037/0033-295x.111.4.1036; [Anonymous], 2013, Journal of Law, Technology Policy; [Anonymous], 2006, Cognition and Multi-Agent Interaction, DOI DOI 10.1017/CB09780511610721.005; Arjovsky M., 2017, arXiv; Athalye A., 2018, ARXIV; Augello A., 2017, P 1 CAID WORKSH IJCA; Azzolin S, 2022, Arxiv, DOI arXiv:2210.07147; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baidya A., 2021, Combining different v1 brain model variants to improve robustness to image corruptions in cnns; Balloccu G, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P710, DOI 10.1145/3523227.3547374; Barron HC, 2021, CURR OPIN NEUROBIOL, V67, P85, DOI 10.1016/j.conb.2020.09.007; Barron HC, 2020, PROG NEUROBIOL, V192, DOI 10.1016/j.pneurobio.2020.101821; Baydin A. G., 2022, arXiv; Beilock SL, 2001, J EXP PSYCHOL GEN, V130, P701, DOI 10.1037/0096-3445.130.4.701; Bell Andrew, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P248, DOI 10.1145/3531146.3533090; Bellas F, 2010, IEEE T AUTON MENT DE, V2, P340, DOI 10.1109/TAMD.2010.2086453; Beniaguev D, 2021, NEURON, V109, P2727, DOI 10.1016/j.neuron.2021.07.002; Beucler T, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.098302; BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115; Bontempelli A, 2023, Arxiv, DOI arXiv:2205.15769; Borst JP, 2017, J MATH PSYCHOL, V76, P94, DOI 10.1016/j.jmp.2016.05.005; Bosselut A, 2019, Arxiv, DOI arXiv:1906.05317; Bosselut A, 2021, AAAI CONF ARTIF INTE, V35, P4923; Branytskyi V., 2022, International Journal of Simulation and Process Modelling, V18, P124; Budd S, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102062; Cai ZK, 2022, PROC CVPR IEEE, P15004, DOI 10.1109/CVPR52688.2022.01460; Carlini N, 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444; Carpenter G., 1998, Adaptive Resonance Theory; Chauhan K., 2023, Proceedings of the AAAI Conference on Artificial Intelligence, V37, P5948; Chen CF, 2019, ADV NEUR IN, V32; Chen MY, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P927, DOI 10.1145/3477495.3531757; Choi E, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P787, DOI 10.1145/3097983.3098126; Choksi B., 2021, ADV NEUR IN, V34; Choksi B, 2022, NEURAL NETWORKS, V154, P538, DOI 10.1016/j.neunet.2022.07.033; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Ciravegna G, 2023, ARTIF INTELL-AMST, V314, DOI 10.1016/j.artint.2022.103822; Claybrook J, 2018, SCIENCE, V361, P36, DOI 10.1126/science.aau2715; Clopath C, 2010, NAT NEUROSCI, V13, P344, DOI 10.1038/nn.2479; Conner F. W., 1973, The Sewanee Review, V81, P282; Cranford E. A., 2020, Cognitive salience of features in cyber-attacker decision making; Dapello J., 2020, Advances in Neural Information Processing Systems; Dapello J., 2022, bioRxiv; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Devlin J., 2018, BERT PRE TRAINING DE; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dobs K., 2022, Using deep convolutional neural networks to test why human face recognition works the way it does; Doncevic D, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad387; Dong YP, 2019, PROC CVPR IEEE, P4307, DOI 10.1109/CVPR.2019.00444; Dosovitskiy A., 2020, ICLR; Du L, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2354; Elkins L, 2010, J FIELD ROBOT, V27, P790, DOI 10.1002/rob.20367; Evans JST, 2003, TRENDS COGN SCI, V7, P454, DOI 10.1016/j.tics.2003.08.012; Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175; Fabiano F, 2023, Arxiv, DOI arXiv:2303.04283; Farah MJ, 1998, PSYCHOL REV, V105, P482, DOI 10.1037/0033-295X.105.3.482; Finzel B, 2022, KUNSTL INTELL, V36, P271, DOI 10.1007/s13218-022-00781-7; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Frosst N, 2017, Arxiv, DOI [arXiv:1711.09784, DOI 10.1109/CVPR.2016.594]; Ganapini M. B., 2022, INT WORKSH NEUR SYMB; Geng YX, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P443, DOI 10.1145/3534678.3539453; Geng YX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3325, DOI 10.1145/3442381.3450042; Ghorbani A, 2019, ADV NEUR IN, V32; Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169; Golovianko M, 2021, PROCEDIA COMPUT SCI, V180, P180, DOI 10.1016/j.procs.2021.01.155; Gui Liangke, 2021, arXiv; Gulati A, 2021, IEEE INT CONF ROBOT, P1535, DOI 10.1109/ICRA48506.2021.9561562; Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705; Gurel N. M., 2021, INT C MACH LEARN PML, P3976; Gutierrez C, 2021, COMMUN ACM, V64, P96, DOI [10.1145/3418294, 10.1145/3447772]; Hagos MT, 2023, Arxiv, DOI arXiv:2307.06026; Hamaguchi T, 2017, Arxiv, DOI arXiv:1706.05674; Han C, 2023, Arxiv, DOI arXiv:2211.03252; Haxby JV, 2000, TRENDS COGN SCI, V4, P223, DOI 10.1016/S1364-6613(00)01482-0; He J, 2023, IEEE WINT CONF APPL, P3879, DOI 10.1109/WACV56688.2023.00388; He J, 2022, Arxiv, DOI arXiv:2101.11878; Heidemann L., 2023, P IEEECVF WINTER C A, P4780; Horikawa T, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15037; Huff Earl W., 2021, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, P327, DOI 10.1177/1071181321651240; Huntsberger T, 2010, PROC SPIE, V7710, DOI 10.1117/12.853284; Islam MA, 2023, INT J COMPUT VISION, V131, P701, DOI 10.1007/s11263-022-01720-7; Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572; Jetley S, 2018, Arxiv, DOI [arXiv:1804.02391, DOI 10.48550/ARXIV.1804.02391, 10.48550/arXiv.1804.02391]; Jha A, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13226; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jia C, 2021, PR MACH LEARN RES, V139; Jin YY, 2023, HEALTH INF SCI SYST, V11, DOI 10.1007/s13755-022-00207-6; Juvina I, 2009, ACTA PSYCHOL, V131, P72, DOI 10.1016/j.actpsy.2009.03.002; Kahneman D., 2011, THINKING; Kaiser J, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00424; Kampffmeyer M, 2019, PROC CVPR IEEE, P11479, DOI 10.1109/CVPR.2019.01175; Karimi A, 2021, INT C PATT RECOG, P8797, DOI 10.1109/ICPR48806.2021.9412167; Keller Y, 2021, Arxiv, DOI arXiv:2106.01452; Keser M., 2023, P IEEECVF C COMPUTER, P3890; Kieras DE, 2016, TOP COGN SCI, V8, P291, DOI 10.1111/tops.12180; Kieras DE, 1997, HUM-COMPUT INTERACT, V12, P391, DOI 10.1207/s15327051hci1204_4; Kim B, 2018, PR MACH LEARN RES, V80; Kim E, 2023, Arxiv, DOI arXiv:2306.01574; Kim S, 2022, APPL INTELL, V52, P471, DOI 10.1007/s10489-021-02451-x; Kim SSY, 2023, Arxiv, DOI arXiv:2210.03735; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Knill DC, 2004, TRENDS NEUROSCI, V27, P712, DOI 10.1016/j.tins.2004.10.007; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Köbis NC, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.103364; Koh PW, 2020, ICML, P5338; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Kotseruba I, 2020, ARTIF INTELL REV, V53, P17, DOI 10.1007/s10462-018-9646-y; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Krotov D, 2016, ADV NEUR IN, V29; Kubilius J, 2019, ADV NEUR IN, V32; Laird J.E., 2019, The Soar cognitive architecture; Lapuschkin S, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08987-4; Lee J, 2022, FRONT COMPUT NEUROSC, V16, DOI 10.3389/fncom.2022.1062678; Lee TimothyB., 2019, Autopilot was active when a Tesla crashed into a truck, killing driver; Lever C, 2009, J NEUROSCI, V29, P9771, DOI 10.1523/JNEUROSCI.1319-09.2009; Li J, 2020, Arxiv, DOI arXiv:2010.16068; Li O, 2018, AAAI CONF ARTIF INTE, P3530; Li X, 2023, IEEE T PATTERN ANAL, V45, P8861, DOI 10.1109/TPAMI.2023.3237935; Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]; Lin S., 2022, Advances in Neural Information Processing Systems, V35, P29624; Lin YT, 2017, Arxiv, DOI arXiv:1702.06700; Lindsay GW, 2021, J COGNITIVE NEUROSCI, V33, P2017, DOI 10.1162/jocn_a_01544; Lindsey R, 2018, P NATL ACAD SCI USA, V115, P11591, DOI 10.1073/pnas.1806905115; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu S., 2022, arXiv; Liu XJ, 2022, LECT NOTES COMPUT SC, V13606, P55, DOI 10.1007/978-3-031-20503-3_5; Liu YL, 2023, Arxiv, DOI arXiv:2302.12971; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Lundberg SM, 2017, ADV NEUR IN, V30; Luo RT, 2020, AAAI CONF ARTIF INTE, V34, P11709; Ma FL, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P743, DOI 10.1145/3269206.3271701; Ma JZ, 2018, NAT METHODS, V15, P290, DOI [10.1038/nmeth.4627, 10.1038/NMETH.4627]; Ma T, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3511019; Ma XJ, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107332; Magnusson R, 2022, NPJ SYST BIOL APPL, V8, DOI 10.1038/s41540-022-00218-9; Malaviya C, 2020, AAAI CONF ARTIF INTE, V34, P2925; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Martone S, 2022, INT C PATT RECOG, P4427, DOI 10.1109/ICPR56361.2022.9956239; Maxwell J. B., 2014, Generative music, cognitive modelling, and computer-assisted composition in musicog and manuscore; MAYER RE, 1994, J EDUC PSYCHOL, V86, P389, DOI 10.1037/0022-0663.86.3.389; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]; Melacci S., 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence; Miller GA., 1998, Wordnet: an electronic lexical database; Millidge B, 2022, Arxiv, DOI arXiv:2202.09467; Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w; Mishra S., 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Moulin-Frier C, 2018, IEEE T COGN DEV SYST, V10, P1005, DOI 10.1109/TCDS.2017.2754143; Muttenthaler L, 2023, Arxiv, DOI [arXiv:2306.04507, 10.48550/arXiv.2306.04507]; Nam JG, 2019, RADIOLOGY, V290, P218, DOI 10.1148/radiol.2018180237; Narayan Sanath, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P479, DOI 10.1007/978-3-030-58542-6_29; Nauta M, 2023, PROC CVPR IEEE, P2744, DOI 10.1109/CVPR52729.2023.00269; Nayebi A, 2022, NEURAL COMPUT, V34, P1652, DOI 10.1162/neco_a_01506; Nelson CA, 2022, J AM MED INFORM ASSN, V29, P424, DOI 10.1093/jamia/ocab270; Nie H., 2022, P IEEE CVF WINT C AP, P1109; Nishida S, 2018, NEUROIMAGE, V180, P232, DOI 10.1016/j.neuroimage.2017.08.017; Noblis, 2023, Noblis Researchers Apply Explainable Artificial Intelligence (XAI) to a COVID-19 X-Ray Detection Study; Oddi A, 2020, FRONT ARTIF INTEL AP, V325, P2417, DOI 10.3233/FAIA200373; Oikarinen T, 2023, Arxiv, DOI arXiv:2304.06129; Oktay O, 2018, Arxiv, DOI arXiv:1804.03999; OReilly R. C., 2000, Computational Explorations in Cognitive Neuroscience; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Ozcelik F, 2023, Arxiv, DOI [arXiv:2303.05334, 10.48550/arXiv.2303.05334]; Paivio A., 2014, Mind and Its Evolution: A Dual Coding Theoretical Approach, DOI 10.4324/9781315785233; Paivio A., 1990, Mental Representations: A Dual Coding Approach, DOI [DOI 10.1093/ACPROF:OSO/9780195066661.001.0001, 10.1093/acprof:oso/9780195066661.001.0001]; PALMER SE, 1977, COGNITIVE PSYCHOL, V9, P441, DOI 10.1016/0010-0285(77)90016-0; Pearl TH, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P187, DOI 10.1145/3306618.3314249; Pereira F, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03068-4; Perotti A, 2023, Arxiv, DOI arXiv:2308.00607; Peterson JC, 2018, COGNITIVE SCI, V42, P2648, DOI 10.1111/cogs.12670; Pöllänen E, 2020, ERGONOMICS, V63, P525, DOI 10.1080/00140139.2020.1744064; Qin C., 2020, Advances in Neural Information Processing Systems, V33, P5599; Qin PD, 2020, AAAI CONF ARTIF INTE, V34, P8673; Qiu SL, 2022, NEUROCOMPUTING, V492, P278, DOI 10.1016/j.neucom.2022.04.020; Radford A., 2018, IMPROVING LANGUAGE U; Radford A, 2021, PR MACH LEARN RES, V139; Raghunathan A, 2020, Arxiv, DOI arXiv:1801.09344; Raizada RDS, 2003, CEREB CORTEX, V13, P100, DOI 10.1093/cercor/13.1.100; Ramesh A, 2021, PR MACH LEARN RES, V139; Ravi S, 2023, IEEE WINT CONF APPL, P1155, DOI 10.1109/WACV56688.2023.00121; Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rice L., 2020, INT C MACH LEARN; Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7; Riegel R, 2020, Arxiv, DOI arXiv:2006.13155; Rieger Laura, 2020, INT C MACHINE LEARNI, P8116; Ritter FE, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1488; Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152; Rosenbloom Paul S., 2016, Journal of Artificial General Intelligence, V7, P1, DOI 10.1515/jagi-2016-0001; Rudin C, 2022, STAT SURV, V16, P1, DOI 10.1214/21-SS133; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sacha M, 2023, IEEE WINT CONF APPL, P1481, DOI 10.1109/WACV56688.2023.00153; Safarani S, 2021, ADV NEUR IN; Salvatori T, 2021, ADV NEUR IN, V34; Samek W, 2017, IEEE T NEUR NET LEAR, V28, P2660, DOI 10.1109/TNNLS.2016.2599820; Sap M., 2019, arXiv; Sarkar A, 2022, IEEE IMAGE PROC, P3783, DOI 10.1109/ICIP46576.2022.9897381; Sawada Y, 2022, IEEE ACCESS, V10, P41758, DOI 10.1109/ACCESS.2022.3167702; Schramowski P, 2020, NAT MACH INTELL, V2, P476, DOI 10.1038/s42256-020-0212-3; Scotti PS, 2023, Arxiv, DOI arXiv:2305.18274; Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9; Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Sixt L., 2020, Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, P9046; Slack D, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P180, DOI 10.1145/3375627.3375830; Slany E, 2022, IFIP ADV INF COMM TE, V652, P389, DOI 10.1007/978-3-031-08341-9_31; Slutter MWJ, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.661466; Smilkov D, 2017, Arxiv, DOI [arXiv:1706.03825, DOI 10.48550/ARXIV.1706.03825]; Stammer W, 2021, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR46437.2021.00362; Steinmann D, 2024, Arxiv, DOI [arXiv:2308.13453, DOI 10.48550/ARXIV.2308.13453]; Su W., 2020, ICLR, P1; Sucholutsky I, 2023, Arxiv, DOI arXiv:2301.11990; Sundararajan M, 2017, PR MACH LEARN RES, V70; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Tarigopula H. P., 2023, Neural Networks; Teney Damien, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P580, DOI 10.1007/978-3-030-58607-2_34; Teso S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P239, DOI 10.1145/3306618.3314293; Teti M., 2022, INT C MACHINE LEARNI, P21232; TramŠr F, 2020, Arxiv, DOI arXiv:1705.07204; Tsagarakis NG, 2007, ADV ROBOTICS, V21, P1151, DOI 10.1163/156855307781389419; TVERSKY B, 1984, J EXP PSYCHOL GEN, V113, P169, DOI 10.1037/0096-3445.113.2.169; Umbrico A, 2023, INT J SOC ROBOT, V15, P371, DOI 10.1007/s12369-022-00897-8; van de Ven GM, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17866-2; Vasquez M, 2022, PROC SPIE, V12032, DOI 10.1117/12.2611822; Vidal P. L., 2023, ICASSP 2023, P1; Vodrahalli K, 2018, NEUROIMAGE, V180, P223, DOI 10.1016/j.neuroimage.2017.06.042; Vössing M, 2022, INFORM SYST FRONT, V24, P877, DOI 10.1007/s10796-022-10284-3; Vrandecic S., 2014, Wikidata: a free collaborative knowledgebase; Wang PF, 2019, AAAI CONF ARTIF INTE, P7152; Wang X, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P878, DOI 10.1145/3442381.3450133; Wang X, 2019, AAAI CONF ARTIF INTE, P5329; Whittington JCR, 2019, TRENDS COGN SCI, V23, P235, DOI 10.1016/j.tics.2018.12.005; Whittington JCR, 2017, NEURAL COMPUT, V29, P1229, DOI 10.1162/NECO_a_00949; Wong E, 2018, PR MACH LEARN RES, V80; Wong Jian Cheng, 2021, arXiv; Wu M., 2022, IEEE Transactions on Intelligent Transportation Systems; Wu XH, 2023, BIG DATA MIN ANAL, V6, P201, DOI 10.26599/BDMA.2022.9020021; Wysocka M, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05262-8; Xi JN, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104144; Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052; Xue MQ, 2022, Arxiv, DOI arXiv:2208.10431; Yang G, 2022, INFORM FUSION, V77, P29, DOI 10.1016/j.inffus.2021.07.016; Yang Y., 2022, LOGICDEF: An Interpretable Defense Framework Against Adversarial Examples via Inductive Scene Graph Reasoning; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yang ZB, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103245; Yang Zongxin, 2022, Advances in Neural Information Processing Systems (NeurIPS), P3; Yasunaga M, 2021, Arxiv, DOI arXiv:2104.06378; Ye HB, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P778, DOI 10.1145/3485447.3511921; Yi DW, 2021, NEUROCOMPUTING, V459, P290, DOI 10.1016/j.neucom.2021.06.072; Yin M., 2021, P IEEECVF INT C COMP, P7858; YIN RK, 1969, J EXP PSYCHOL, V81, P141, DOI 10.1037/h0027474; Ying Z., 2022, Advances in Neural Information Processing Systems, V35, P17057; Yu DH, 2022, AAAI CONF ARTIF INTE, P11630; Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199; Yuan L., 2021, arXiv; Zarlenga M. E., 2022, arXiv; Zeng Y, 2020, LECT NOTES COMPUT SC, V12453, P274, DOI 10.1007/978-3-030-60239-0_19; Zhang HC, 2019, ADV NEUR IN, V32; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629; Zhang H, 2019, Arxiv, DOI arXiv:1901.04684; Zhang JW, 2023, 2023 IEEE CONFERENCE ON SECURE AND TRUSTWORTHY MACHINE LEARNING, SATML, P554, DOI 10.1109/SaTML54575.2023.00043; Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321; Zhang ZB, 2021, NEUROCOMPUTING, V428, P116, DOI 10.1016/j.neucom.2020.11.042; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1; Zhou WY, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-21466-z; Zhou ZL, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08931-6; Zhu C, 2020, Arxiv, DOI arXiv:1909.11764	275	0	0	16	16	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2214-4366	1389-0417		COGN SYST RES	Cogn. Syst. Res.	MAR	2024	84								101188	10.1016/j.cogsys.2023.101188	http://dx.doi.org/10.1016/j.cogsys.2023.101188		DEC 2023	30	Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Neurosciences & Neurology; Psychology	FO5N4		Green Submitted			2024-07-03	WOS:001146794400001
J	Yang, HS; Wang, F; Greenblatt, MB; Huang, SX; Zhang, Y				Yang, He S.; Wang, Fei; Greenblatt, Matthew B.; Huang, Sharon X.; Zhang, Yi			AI Chatbots in Clinical Laboratory Medicine: Foundations and Trends	CLINICAL CHEMISTRY			English	Review							GPT-4	Background Artificial intelligence (AI) conversational agents, or chatbots, are computer programs designed to simulate human conversations using natural language processing. They offer diverse functions and applications across an expanding range of healthcare domains. However, their roles in laboratory medicine remain unclear, as their accuracy, repeatability, and ability to interpret complex laboratory data have yet to be rigorously evaluated.Content This review provides an overview of the history of chatbots, two major chatbot development approaches, and their respective advantages and limitations. We discuss the capabilities and potential applications of chatbots in healthcare, focusing on the laboratory medicine field. Recent evaluations of chatbot performance are presented, with a special emphasis on large language models such as the Chat Generative Pre-trained Transformer in response to laboratory medicine questions across different categories, such as medical knowledge, laboratory operations, regulations, and interpretation of laboratory results as related to clinical context. We analyze the causes of chatbots' limitations and suggest research directions for developing more accurate, reliable, and manageable chatbots for applications in laboratory medicine.Summary Chatbots, which are rapidly evolving AI applications, hold tremendous potential to improve medical education, provide timely responses to clinical inquiries concerning laboratory tests, assist in interpreting laboratory results, and facilitate communication among patients, physicians, and laboratorians. Nevertheless, users should be vigilant of existing chatbots' limitations, such as misinformation, inconsistencies, and lack of human-like reasoning abilities. To be effectively used in laboratory medicine, chatbots must undergo extensive training on rigorously validated medical knowledge and be thoroughly evaluated against standard clinical practice.	[Yang, He S.; Greenblatt, Matthew B.] Weill Cornell Med, Dept Pathol & Lab Med, 525 E 68th St,F707, New York, NY 10065 USA; [Wang, Fei] Weill Cornell Med, Dept Populat Hlth Sci, New York, NY USA; [Greenblatt, Matthew B.] Hosp Special Surg, Res Div, New York, NY USA; [Huang, Sharon X.] Penn State Univ, Coll Informat Sci & Technol, University Pk, PA USA; [Zhang, Yi] Univ Calif Santa Cruz, Dept Comp Sci & Engn, Santa Cruz, CA 95064 USA; [Zhang, Yi] Univ Calif Santa Cruz, Baskin Sch Engn, Dept Comp Sci & Engn, SOE3,1156 High St, Santa Cruz, CA 95064 USA	Cornell University; Weill Cornell Medicine; Cornell University; Weill Cornell Medicine; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; University of California System; University of California Santa Cruz; University of California System; University of California Santa Cruz	Yang, HS (corresponding author), Weill Cornell Med, Dept Pathol & Lab Med, 525 E 68th St,F707, New York, NY 10065 USA.; Zhang, Y (corresponding author), Univ Calif Santa Cruz, Baskin Sch Engn, Dept Comp Sci & Engn, SOE3,1156 High St, Santa Cruz, CA 95064 USA.	hey9012@med.cornell.edu; yiz@ucsc.edu		Huang, Sharon Xiaolei/0000-0003-2338-6535	H.S. Yang would like to thank Dr. Ming Yang for proofreading and editing this manuscript.	H.S. Yang would like to thank Dr. Ming Yang for proofreading and editing this manuscript.	H.S. Yang would like to thank Dr. Ming Yang for proofreading and editing this manuscript.	Ahmed A, 2023, HEALTH INFORM J, V29, DOI 10.1177/14604582221146719; Almalki Manal, 2020, Acta Inform Med, V28, P241, DOI 10.5455/aim.2020.28.241-247; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Baumgartner C, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1206; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Boggiss AL., 2023, JMIR DIABETES, V8, pe40641; Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158; Dash D., WELL DO LARGE LANGUA; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; LENNIG M, 1995, SPEECH COMMUN, V17, P227, DOI 10.1016/0167-6393(95)00024-I; Luo TC, 2021, J MED INTERNET RES, V23, DOI 10.2196/25486; Miner AS, 2019, FRONT PSYCHIATRY, V10, DOI 10.3389/fpsyt.2019.00746; Munoz-Zuluaga C, 2023, CLIN CHEM, V69, P939, DOI 10.1093/clinchem/hvad058; OpenAI, CHAT PLUG; OpenAI, Introducing ChatGPT; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Peng B., 2023, PREPRINT; Pham KT, 2022, PSYCHIAT QUART, V93, P249, DOI 10.1007/s11126-022-09973-8; Radford A., 2018, IMPROVING LANGUAGE U; Sakane N, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/43236; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shi W., 2023, PREPRINT; Stephens TN, 2019, TRANSL BEHAV MED, V9, P440, DOI 10.1093/tbm/ibz043; Su ZY, 2021, SUBST USE MISUSE, V56, P1732, DOI 10.1080/10826084.2021.1949609; Wang H, 2022, J MED INTERNET RES, V24, DOI 10.2196/29969; Weeks R, 2022, J MED INTERNET RES, V24, DOI 10.2196/38418; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wen T., 2017, PREPRINT; Whittaker R, 2022, J MED INTERNET RES, V24, DOI 10.2196/35556; WHO, 2020, WHO Coronavirus Disease (COVID-19) Dashboard; Wilson L, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/35882; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Yam EA, 2022, GLOB HEALTH-SCI PRAC, V10, DOI 10.9745/GHSP-D-21-00721; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; You Yue, 2020, AMIA Annu Symp Proc, V2020, P1354; Zhavoronkov A, 2023, NAT MED, V29, P532, DOI 10.1038/d41591-023-00014-w	39	6	6	20	50	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	0009-9147	1530-8561		CLIN CHEM	Clin. Chem.	NOV 2	2023	69	11					1238	1246		10.1093/clinchem/hvad106	http://dx.doi.org/10.1093/clinchem/hvad106		SEP 2023	9	Medical Laboratory Technology	Science Citation Index Expanded (SCI-EXPANDED)	Medical Laboratory Technology	X8GH5	37664912				2024-07-03	WOS:001057767600001
J	Lu, W; Kaplan, DL; Buehler, MJ				Lu, Wei; Kaplan, David L.; Buehler, Markus J.			Generative Modeling, Design, and Analysis of Spider Silk Protein Sequences for Enhanced Mechanical Properties	ADVANCED FUNCTIONAL MATERIALS			English	Article						biomaterials; deep learning; generative autoregressive transformer; hierarchical; multiscale modeling; spider silk; spidroin	N-TERMINAL DOMAIN; SUPERCONTRACTION; COMPOSITES; OPTIMIZATION; INTEGRATION; SIMULATION; EVOLUTION; HYDROGELS; FIBROIN; FIBERS	Spider silks are remarkable materials characterized by superb mechanical properties such as strength, extensibility, and lightweightedness. Yet, to date, limited models are available to fully explore sequence-property relationships for analysis and design. Here a custom generative large-language model is proposed to enable the design of novel spider silk protein sequences to meet complex combinations of target mechanical properties. The model, pretrained on a large set of protein sequences, is fine-tuned on approximate to 1,000 major ampullate spidroin (MaSp) sequences for which associated fiber-level mechanical properties exist, to yield an end-to-end forward and inverse generative approach that is aplied in a multi-agent strategy. Performance is assessed through: 1) a novelty analysis and protein type classification for generated spidroin sequences through Basic Local Alignment Search Tool (BLAST) searches, 2) property evaluation and comparison with similar sequences, 3) comparison of resulting molecular structures, and 4) a detailed sequence motif analyses. This work generates silk sequences with property combinations that do not exist in nature and develops a deeper understanding of the mechanistic roles of sequence patterns in achieving overarching key mechanical properties (elastic modulus (E), strength, toughness, failure strain). The model provides an efficient approach to expand the silkome dataset, facilitating further sequence-structure analyses of silks, and establishes a foundation for synthetic silk design and optimization. The authors develop a generative modeling, design, and analysis technique applied to create novel spider silk protein sequences for enhanced mechanical properties. They create property combinations that do not exist in nature and develop a deep understanding of the mechanistic roles of sequence patterns in achieving overarching key mechanical properties (elastic modulus, strength, toughness, failure strain).image	[Lu, Wei; Buehler, Markus J.] MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Lu, Wei; Buehler, Markus J.] MIT, Dept Civil & Environm Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA; [Kaplan, David L.] Tufts Univ, Dept Biomed Engn, Medford, MA 02155 USA; [Buehler, Markus J.] MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA	Massachusetts Institute of Technology (MIT); Massachusetts Institute of Technology (MIT); Tufts University; Massachusetts Institute of Technology (MIT)	Buehler, MJ (corresponding author), MIT, Lab Atomist & Mol Mech LAMM, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Buehler, MJ (corresponding author), MIT, Dept Civil & Environm Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.; Buehler, MJ (corresponding author), MIT, Schwarzman Coll Comp, Ctr Computat Sci & Engn, 77 Massachusetts Ave, Cambridge, MA 02139 USA.	mbuehler@mit.edu	Lu, Wei/AAE-2921-2022; Buehler, Markus/C-4580-2008	Lu, Wei/0000-0002-4150-8674; Buehler, Markus/0000-0002-4173-9659; Lu, Wei/0000-0002-5168-4428	MIT Generative AI Initiative, NIH, USDA; ARO [W911NF2220213]; MIT-IBM Watson AI Lab, MIT Quest; Google Cloud Computing	MIT Generative AI Initiative, NIH, USDA; ARO; MIT-IBM Watson AI Lab, MIT Quest; Google Cloud Computing	The authors acknowledge support from the MIT Generative AI Initiative, NIH, USDA and ARO (W911NF2220213). Related support from the MIT-IBM Watson AI Lab, MIT Quest, and Google Cloud Computing, is acknowledged. The authors acknowledge Keiji Numata for the development of the Silkome dataset.	An B, 2012, BIOMACROMOLECULES, V13, P3938, DOI 10.1021/bm301110s; Arakawa K, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abo6043; Arguelles J, 2023, J COMP PHYSIOL B, V193, P25, DOI 10.1007/s00360-022-01464-3; Arndt T, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32093-7; Ayoub NA, 2013, MOL BIOL EVOL, V30, P589, DOI 10.1093/molbev/mss254; Babb PL, 2017, NAT GENET, V49, P895, DOI 10.1038/ng.3852; Barreiro DL, 2019, MACROMOL BIOSCI, V19, DOI 10.1002/mabi.201800253; Batty L., 2013, THESIS MIT CAMBRIDGE; Bauer J, 2017, BIOMACROMOLECULES, V18, P2521, DOI 10.1021/acs.biomac.7b00672; Biderman S., 2023, INT C MACHINE LEARNI, P2397; Black Sid, 2022, ARXIV220406745; Blamires SJ, 2017, ANNU REV ENTOMOL, V62, P443, DOI 10.1146/annurev-ento-031616-035615; Boutry C, 2010, J EXP BIOL, V213, P3505, DOI 10.1242/jeb.046110; Brooks AE, 2008, BIOMACROMOLECULES, V9, P1506, DOI 10.1021/bm701124p; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buehler EL, 2021, EXTREME MECH LETT, V42, DOI 10.1016/j.eml.2020.101034; Buehler M. J., 2023, 64, V181; Buehler MJ, 2022, OXF OPEN MATER SCI, V2, DOI 10.1093/oxfmat/itac010; Chang X, 2021, IET INTELL TRANSP SY, V15, P423, DOI 10.1049/itr2.12035; Chouhan D, 2019, ACS BIOMATER SCI ENG, V5, P3537, DOI 10.1021/acsbiomaterials.9b00514; Cock PJA, 2009, BIOINFORMATICS, V25, P1422, DOI 10.1093/bioinformatics/btp163; Cohen N, 2021, BIOMACROMOLECULES, V22, P993, DOI 10.1021/acs.biomac.0c01747; Craig HC, 2020, J R SOC INTERFACE, V17, DOI 10.1098/rsif.2020.0471; Cranford S., 2011, ATT 20 C NAZ ASS IT; Debabov VG, 2020, ACS BIOMATER SCI ENG, V6, P3745, DOI 10.1021/acsbiomaterials.0c00109; Devlin J., 2018, BERT PRE TRAINING DE; Dorozynski M., 2019, ISPRS ANN PHOTOGRAMM, V4, P47, DOI DOI 10.5194/ISPRS-ANNALS-IV-2-W6-47-2019; Eisoldt L, 2011, MATER TODAY, V14, P80, DOI 10.1016/S1369-7021(11)70057-8; Farokhi M, 2018, TRENDS BIOTECHNOL, V36, P907, DOI 10.1016/j.tibtech.2018.04.004; Garrison NL, 2016, PEERJ, V4, DOI 10.7717/peerj.1719; Gasteiger E, 2005, PROTEOMICS PROTOCOLS, V571-607, DOI [DOI 10.1385/1-59259-890-0:571, 10.1385/1-59259-890-0:571]; Gu GX, 2018, MATER HORIZ, V5, P939, DOI 10.1039/c8mh00653a; Gu GX, 2016, J BIOMECH ENG-T ASME, V138, DOI 10.1115/1.4032423; Guinea GV, 2005, J EXP BIOL, V208, P25, DOI 10.1242/jeb.01344; Guo HB, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14382-9; GURUPRASAD K, 1990, PROTEIN ENG, V4, P155, DOI 10.1093/protein/4.2.155; Han XH, 2021, APPL THERM ENG, V195, DOI 10.1016/j.applthermaleng.2021.117154; Hardy JG, 2013, MACROMOL BIOSCI, V13, P1431, DOI 10.1002/mabi.201300233; Hayashi C. Y., 2010, BMC EVOL BIOL, V1, P1; Hinman MB, 2000, TRENDS BIOTECHNOL, V18, P374, DOI 10.1016/S0167-7799(00)01481-5; Hsu YC, 2022, APL MATER, V10, DOI 10.1063/5.0082338; Huang WW, 2017, ACCOUNTS CHEM RES, V50, P866, DOI 10.1021/acs.accounts.6b00616; Iqbal T, 2022, J KING SAUD UNIV-COM, V34, P2515, DOI 10.1016/j.jksuci.2020.04.001; Jaegle A., 2021, ICLR ARXIV PREPRINT; Jiang MR, 2021, ANALYST, V146, P2490, DOI 10.1039/d1an00290b; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kelly SP, 2011, ZOOLOGY, V114, P233, DOI 10.1016/j.zool.2011.02.001; Kingma D. P., 2017, ARXIV; Kipf T. N., 2016, ICLR, DOI 10.48550/arXiv.1609.02907; Kluge JA, 2008, TRENDS BIOTECHNOL, V26, P244, DOI 10.1016/j.tibtech.2008.02.006; Kono N, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2107065118; Kono N, 2019, DEV GROWTH DIFFER, V61, P316, DOI 10.1111/dgd.12608; Krishnaji ST, 2013, ADV FUNCT MATER, V23, P241, DOI 10.1002/adfm.201200510; Kundu B, 2012, BIOMATERIALS, V33, P7456, DOI 10.1016/j.biomaterials.2012.06.091; Lammel AS, 2010, BIOMATERIALS, V31, P4583, DOI 10.1016/j.biomaterials.2010.02.024; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lin SC, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms7892; Liu Y, 2005, NAT MATER, V4, P901, DOI 10.1038/nmat1534; Liu YQ, 2014, ACS APPL MATER INTER, V6, P20670, DOI 10.1021/am504163r; Lu W, 2022, J APPL PHYS, V132, DOI 10.1063/5.0097589; Luu RK, 2023, APPL PHYS LETT, V122, DOI 10.1063/5.0155890; Malay AD, 2022, BIOMACROMOLECULES, V23, P1827, DOI 10.1021/acs.biomac.1c01682; Meyers MA, 2011, J MECH BEHAV BIOMED, V4, P626, DOI 10.1016/j.jmbbm.2010.08.005; Meyers MA, 2008, PROG MATER SCI, V53, P1, DOI 10.1016/j.pmatsci.2007.05.002; Milazzo M, 2023, ACS BIOMATER SCI ENG, V9, P1285, DOI 10.1021/acsbiomaterials.2c01357; Nguyen TTT, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2300987120; Ni B, 2023, CHEM-US, V9, P1828, DOI 10.1016/j.chempr.2023.03.020; Pandey AK, 2023, NEURAL PROCESS LETT, V55, P7709, DOI 10.1007/s11063-023-11281-6; Paszke A, 2019, ADV NEUR IN, V32; Pérez-Rigueiro J, 2003, POLYMER, V44, P3733, DOI 10.1016/S0032-3861(03)00245-3; Petrou G, 2018, BIOMACROMOLECULES, V19, P3268, DOI 10.1021/acs.biomac.8b00578; Qin Z, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8038; Quan LJ, 2023, CHEM-US, V9, P1625, DOI 10.1016/j.chempr.2023.06.010; Salehi S, 2020, MOLECULES, V25, DOI 10.3390/molecules25030737; Sanders ED, 2020, STRUCT MULTIDISCIP O, V62, P559, DOI 10.1007/s00158-020-02513-7; Savage KN, 2008, J EXP BIOL, V211, P1937, DOI 10.1242/jeb.014217; Schleider Thomas, 2021, SUMAC'21: Proceedings of the 3rd Workshop on Structuring and Understanding of Multimedia heritAge Contents, P41, DOI 10.1145/3475720.3484445; Seidel A, 2000, MACROMOLECULES, V33, P775, DOI 10.1021/ma990893j; Spiess K, 2010, MACROMOL BIOSCI, V10, P998, DOI 10.1002/mabi.201000071; Steven E, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3435; Steven E, 2011, SCI TECHNOL ADV MAT, V12, DOI 10.1088/1468-6996/12/5/055002; Su I., 2016, NANOMECHANICS SILK F, V27; Su I, 2020, J MECH PHYS SOLIDS, V144, DOI 10.1016/j.jmps.2020.104096; Su I, 2016, NAT MATER, V15, P1054, DOI 10.1038/nmat4721; Sun WZ, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22031499; Tarakanova A, 2012, J R SOC INTERFACE, V9, P3240, DOI 10.1098/rsif.2012.0473; Varadi M, 2022, NUCLEIC ACIDS RES, V50, pD439, DOI 10.1093/nar/gkab1061; Vaswani A., 2017, ADV NEURAL INFORM PR, P111; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang SJ, 2012, J BIOMOL NMR, V54, P415, DOI 10.1007/s10858-012-9679-5; Wong JY, 2012, NANO TODAY, V7, P488, DOI 10.1016/j.nantod.2012.09.001; Yang L, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3626235; Yang QX, 2014, SMART MATER STRUCT, V23, DOI 10.1088/0964-1726/23/10/105032; Yang ZZ, 2023, J MECH PHYS SOLIDS, V170, DOI 10.1016/j.jmps.2022.105098; Yang ZZ, 2022, SMALL METHODS, V6, DOI 10.1002/smtd.202200537; Yodmuang S, 2015, ACTA BIOMATER, V11, P27, DOI 10.1016/j.actbio.2014.09.032; Yu CH, 2019, ACS NANO, V13, P7471, DOI 10.1021/acsnano.9b02180; Yucel T, 2014, J CONTROL RELEASE, V190, P381, DOI 10.1016/j.jconrel.2014.05.059; Zhang WW, 2018, ACS NANO, V12, P6968, DOI 10.1021/acsnano.8b02430	99	5	5	23	26	WILEY-V C H VERLAG GMBH	WEINHEIM	POSTFACH 101161, 69451 WEINHEIM, GERMANY	1616-301X	1616-3028		ADV FUNCT MATER	Adv. Funct. Mater.	MAR	2024	34	11								10.1002/adfm.202311324	http://dx.doi.org/10.1002/adfm.202311324		DEC 2023	15	Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	KI7Q5		Green Submitted, hybrid			2024-07-03	WOS:001112105200001
J	Yeo, YH; Samaan, JS; Ng, WH; Ting, PS; Trivedi, H; Vipani, A; Ayoub, W; Yang, JD; Liran, O; Spiegel, B; Kuo, A				Yeo, Yee Hui; Samaan, Jamil S.; Ng, Wee Han; Ting, Peng-Sheng; Trivedi, Hirsh; Vipani, Aarshi; Ayoub, Walid; Yang, Ju Dong; Liran, Omer; Spiegel, Brennan; Kuo, Alexander			Assessing the performance of ChatGPT in answer- ing questions regarding cirrhosis and hepatocellu- lar carcinoma	CLINICAL AND MOLECULAR HEPATOLOGY			English	Article						Artificial intelligence; Patient education as topic; Health communication; Telemedicine; Chronic disease management	PATIENT; COMPLICATIONS; SURVEILLANCE	Background/Aims: Patients with cirrhosis and hepatocellular carcinoma (HCC) require extensive and personalized care to improve outcomes. ChatGPT (Generative Pre-trained Transformer), a large language model, holds the potential to provide professional yet patient-friendly support. We aimed to examine the accuracy and reproducibility of ChatGPT in answering questions regarding knowledge, management, and emotional support for cirrhosis and HCC. Methods: ChatGPT's responses to 164 questions were independently graded by two transplant hepatologists and resolved by a third reviewer. The performance of ChatGPT was also assessed using two published questionnaires and 26 questions formulated from the quality measures of cirrhosis management. Finally, its emotional support capacity was tested. Results: We showed that ChatGPT regurgitated extensive knowledge of cirrhosis (79.1% correct) and HCC (74.0% cor-rect), but only small proportions (47.3% in cirrhosis, 41.1% in HCC) were labeled as comprehensive. The performance was better in basic knowledge, lifestyle, and treatment than in the domains of diagnosis and preventive medicine. For the quality measures, the model answered 76.9% of questions correctly but failed to specify decision-making cut-off s and treatment durations. ChatGPT lacked knowledge of regional guidelines variations, such as HCC screening criteria. How-ever, it provided practical and multifaceted advice to patients and caregivers regarding the next steps and adjusting to a new diagnosis. Conclusions: We analyzed the areas of robustness and limitations of ChatGPT's responses on the management of cirrhosis and HCC and relevant emotional support. ChatGPT may have a role as an adjunct informational tool for patients and physicians to improve outcomes. (Clin Mol Hepatol 2023;29:721-732)	[Yeo, Yee Hui; Samaan, Jamil S.; Trivedi, Hirsh; Vipani, Aarshi; Ayoub, Walid; Yang, Ju Dong; Spiegel, Brennan; Kuo, Alexander] Cedars Sinai Med Ctr, Karsh Div Gastroenterol & Hepatol, Dept Med, Los Angeles, CA USA; [Ng, Wee Han] Univ Bristol, Bristol Med Sch, Bristol, England; [Ting, Peng-Sheng] Tulane Univ, Sch Med, New Orleans, LA USA; [Trivedi, Hirsh; Ayoub, Walid; Yang, Ju Dong; Kuo, Alexander] Cedars Sinai Med Ctr, Comprehens Transplant Ctr, Los Angeles, CA USA; [Yang, Ju Dong] Cedars Sinai Med Ctr, Samuel Oschin Comprehens Canc Inst, Los Angeles, CA USA; [Liran, Omer] Cedars Sinai, Dept Psychiat & Behav Sci, Los Angeles, CA USA; [Liran, Omer; Spiegel, Brennan] Cedars Sinai, Div Hlth Serv Res, Dept Med, Los Angeles, CA USA	Cedars Sinai Medical Center; University of Bristol; Tulane University; Cedars Sinai Medical Center; Cedars Sinai Medical Center; Cedars Sinai Medical Center; Cedars Sinai Medical Center	Spiegel, B; Kuo, A (corresponding author), Cedars Sinai Med Ctr, Div Gastroenterol & Hepatol, Dept Med, 8700 Beverly Blvd, Los Angeles, CA 90048 USA.	Brennan.Spiegel@cshs.org; Alexander.Kuo@cshs.org	Yeo, Y/GWV-3316-2022; li, fang/KDO-8841-2024	Ayoub, Walid/0000-0002-9123-5918; Trivedi, Hirsh/0000-0002-8328-9211				Attwa MH, 2015, WORLD J HEPATOL, V7, P1632, DOI 10.4254/wjh.v7.i12.1632; Bogost Ian., 2015, The Atlantic; Brown AF, 2019, AM J PUBLIC HEALTH, V109, pS72, DOI [10.2105/ajph.2018.304844, 10.2105/AJPH.2018.304844]; Christiano PF, 2017, 31 C NEURAL INFORM P; D'Amico G, 2003, HEPATOLOGY, V38, P599, DOI 10.1053/jhep.2003.50385; Desai AP, 2019, CLIN TRANSL GASTROEN, V10, DOI 10.14309/ctg.0000000000000062; Farvardin S, 2017, HEPATOLOGY, V65, P875, DOI 10.1002/hep.28770; GBD 2017 Gastrooesophageal, 2020, LANCET GASTROENTEROL, V5, P561, DOI 10.1016/S2468-1253(19)30408-X; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Ginès P, 2021, LANCET, V398, P1359, DOI 10.1016/S0140-6736(21)01374-X; Grydgaard MF, 2018, SCAND J GASTROENTERO, V53, P1584, DOI 10.1080/00365521.2018.1545045; Gulati Rishabh, 2018, Clin Liver Dis (Hoboken), V11, P48, DOI 10.1002/cld.690; Hayward KL, 2020, INTERN MED J, V50, P1142, DOI 10.1111/imj.14986; Heydari Abbas, 2015, Int J Community Based Nurs Midwifery, V3, P23; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kaundinya Trisha, 2020, J Curr Surg, V10, P1, DOI 10.14740/jcs401; McAdam-Marx C, 2011, J MANAGE CARE PHARM, V17, P531, DOI 10.18553/jmcp.2011.17.7.531; McGlynn KA, 2021, HEPATOLOGY, V73, P4, DOI 10.1002/hep.31288; Noguchi Y, THERAPY CHATBOT PROM; Nusrat S, 2014, WORLD J GASTROENTERO, V20, P5442, DOI 10.3748/wjg.v20.i18.5442; OpenAI©, Chatgpt: Optimizing language models for dialogue; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Rumgay H, 2022, J HEPATOL, V77, P1598, DOI 10.1016/j.jhep.2022.08.021; Saab S, 2016, J CLIN TRANSL HEPATO, V4, P281, DOI 10.14218/JCTH.2016.00049; Tsochatzis EA, 2014, LANCET, V383, P1749, DOI 10.1016/S0140-6736(14)60121-5; Valery PC, 2022, BMC GASTROENTEROL, V22, DOI 10.1186/s12876-022-02407-6; van Meer S, 2015, J HEPATOL, V63, P1156, DOI 10.1016/j.jhep.2015.06.012; Victora CG, 2017, LANCET GLOB HEALTH, V5, pE402, DOI [10.1016/S2214-109X(17)30077-3, 10.1016/s2214-109x(17)30077-3]; Yang JD, 2020, BMJ-BRIT MED J, V371, DOI 10.1136/bmj.m3544; Yang JD, 2019, NAT REV GASTRO HEPAT, V16, P589, DOI 10.1038/s41575-019-0186-y	30	145	145	65	125	KOREAN ASSOC STUDY LIVER	SEOUL	RM A1210, 53 MAPO-DAERO, MAPOTRAPALACE, DOWHA-DONG, MAPO-GU, SEOUL, 04158, SOUTH KOREA	2287-2728	2287-285X		CLIN MOL HEPATOL	Clin. Mol. Hepatol.	JUL	2023	29	3					721	732		10.3350/cmh.2023.0089	http://dx.doi.org/10.3350/cmh.2023.0089			13	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	O2NS9	36946005	gold, Green Submitted, Green Published			2024-07-03	WOS:001042245200002
J	Arça, DO; Erdemir, I; Kara, F; Shermatov, N; Odacioglu, M; Ibisoglu, E; Hanci, FB; Sagiroglu, G; Hanci, V				Arca, Dilek Omur; Erdemir, Ismail; Kara, Fevzi; Shermatov, Nurgazy; Odacioglu, Muruvvet; Ibisoglu, Emel; Hanci, Ferid Baran; Sagiroglu, Gonul; Hanci, Volkan			Assessing the readability, reliability, and quality of artificial intelligence chatbot responses to the 100 most searched queries about cardiopulmonary resuscitation: An observational study	MEDICINE			English	Article						Artificial intelligence; Bard; chatbot; ChatGPT; Gemini; Perplexity; quality; readability; reliability	CARDIAC-ARREST; PATIENT EDUCATION; GUIDELINES	This study aimed to evaluate the readability, reliability, and quality of responses by 4 selected artificial intelligence (AI)-based large language model (LLM) chatbots to questions related to cardiopulmonary resuscitation (CPR). This was a cross-sectional study. Responses to the 100 most frequently asked questions about CPR by 4 selected chatbots (ChatGPT-3.5 [Open AI], Google Bard [Google AI], Google Gemini [Google AI], and Perplexity [Perplexity AI]) were analyzed for readability, reliability, and quality. The chatbots were asked the following question: "What are the 100 most frequently asked questions about cardio pulmonary resuscitation?" in English. Each of the 100 queries derived from the responses was individually posed to the 4 chatbots. The 400 responses or patient education materials (PEM) from the chatbots were assessed for quality and reliability using the modified DISCERN Questionnaire, Journal of the American Medical Association and Global Quality Score. Readability assessment utilized 2 different calculators, which computed readability scores independently using metrics such as Flesch Reading Ease Score, Flesch-Kincaid Grade Level, Simple Measure of Gobbledygook, Gunning Fog Readability and Automated Readability Index. Analyzed 100 responses from each of the 4 chatbots. When the readability values of the median results obtained from Calculators 1 and 2 were compared with the 6th-grade reading level, there was a highly significant difference between the groups (P < .001). Compared to all formulas, the readability level of the responses was above 6th grade. It can be seen that the order of readability from easy to difficult is Bard, Perplexity, Gemini, and ChatGPT-3.5. The readability of the text content provided by all 4 chatbots was found to be above the 6th-grade level. We believe that enhancing the quality, reliability, and readability of PEMs will lead to easier understanding by readers and more accurate performance of CPR. So, patients who receive bystander CPR may experience an increased likelihood of survival.	[Arca, Dilek Omur; Erdemir, Ismail; Kara, Fevzi; Shermatov, Nurgazy; Odacioglu, Muruvvet; Ibisoglu, Emel; Sagiroglu, Gonul; Hanci, Volkan] Dokuz Eylul Univ, Sch Med, Dept Anesthesiol & Reanimat, Izmir, Turkiye; [Hanci, Ferid Baran] Ostim Tech Univ, Dept Fac Engn, Artificial Intelligence Engn, Ankara, Turkiye; [Arca, Dilek Omur] Dokuz Eylul Univ, Sch Med, Dept Anesthesiol & Reanimat, 1606 15 Temmuz Yerleskesi, TR-35340 Balcova, Izmir, Turkiye	Dokuz Eylul University; Ostim Technical University; Dokuz Eylul University	Arça, DO (corresponding author), Dokuz Eylul Univ, Sch Med, Dept Anesthesiol & Reanimat, 1606 15 Temmuz Yerleskesi, TR-35340 Balcova, Izmir, Turkiye.	dilekomur@yahoo.com; ismailbilalerdemir@gmail.com; fevzikra@gmail.com; shergazi@gmail.com; muruvvetodacioglu@gmail.com; emel.ibisoglu@gmail.com; vhanci@gmail.com; gonulsagiroglu45@gmail.com; vhanci@gmail.com						Aydin O., 2023, J AI, V7, P1; Badarudeen S, 2008, J BONE JOINT SURG AM, V90A, P199, DOI 10.2106/JBJS.G.00347; Berry CE, 2024, J RECONSTR MICROSURG, DOI 10.1055/a-2273-4163; Boztas N, 2017, MEDICINE, V96, DOI 10.1097/MD.0000000000008526; Brandl R., ChatGPT Statistics 2023 All the latest statistics about OpenAI's chatbot; Carl MM., 2024, Br J Ophthalmol, V0, P1; Carl MM., 2024, Graefes Arch Clin Exp Ophthalmol, V4, P4; Currie G, 2023, J NUCL MED TECHNOL, V51, P307, DOI 10.2967/jnmt.123.266151; Davis J, 2024, JMIR HUM FACTORS, V11, DOI 10.2196/53559; Davis RJ., 2023, Laryngoscope, V00, P1; Davis R, 2023, J UROLOGY, V210, P688, DOI 10.1097/JU.0000000000003615; Duran GS, 2023, CLEFT PALATE-CRAN J, DOI 10.1177/10556656231222387; Erkin Y, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000033529; Golan R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42214; Gräsner JT, 2021, RESUSCITATION, V161, P61, DOI 10.1016/j.resuscitation.2021.02.007; Hartnett DA., 2022, Foot Ankle Spec, V8, p193864002211164; Holmes J, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1219326; Hristidis V, 2023, J MED INTERNET RES, V25, DOI 10.2196/48966; Ibrahim WH, 2007, POSTGRAD MED J, V83, P649, DOI 10.1136/pgmj.2007.057133; Iorliam A., 2024, JCTA, V1, P311; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Lavonas EJ, 2023, CIRCULATION, V148, pE149, DOI 10.1161/CIR.0000000000001161; Lekova A., 2022, J Mechatronics Artificial Intell Eng, V3, P30; Lott C, 2021, RESUSCITATION, V161, P152, DOI 10.1016/j.resuscitation.2021.02.011; Masalkhi M., 2024, Eye, V2, P14; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Moons P, 2024, EUR J CARDIOVASC NUR, V23, P122, DOI 10.1093/eurjcn/zvad087; Musheyev D, 2024, EUR UROL, V85, P13, DOI 10.1016/j.eururo.2023.07.004; Olasveengen TM, 2021, RESUSCITATION, V161, P98, DOI 10.1016/j.resuscitation.2021.02.009; openai, ChatGPT Pricing; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Robinson MA, 2024, J AM ACAD DERMATOL, V90, P1078, DOI 10.1016/j.jaad.2024.01.037; Rodríguez-Cantelar M, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13169055; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50629; Schwartz KL, 2006, J AM BOARD FAM MED, V19, P39, DOI 10.3122/jabfm.19.1.39; Soar J, 2021, RESUSCITATION, V161, P115, DOI 10.1016/j.resuscitation.2021.02.010; Swoboda CM, 2018, BMC FAM PRACT, V19, DOI 10.1186/s12875-018-0805-7; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Tu Ha T, 2008, Track Rep, P1; Ulusoy I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46662; Uzun O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37250; Wang HY, 2023, INT J MED INFORM, V177, DOI 10.1016/j.ijmedinf.2023.105173; Wong K, 2017, ANN OTO RHINOL LARYN, V126, P192, DOI 10.1177/0003489416681583; Yan SJ, 2020, CRIT CARE, V24, DOI 10.1186/s13054-020-2773-2; Yilmaz IE, 2024, CLIN EXP OPTOM, DOI 10.1080/08164622.2023.2298812; ztrk T., 2021, Selcuk Dent J, V8, P106	46	0	0	0	0	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0025-7974	1536-5964		MEDICINE	Medicine (Baltimore)	MAY 31	2024	103	22							e38352	10.1097/MD.0000000000038352	http://dx.doi.org/10.1097/MD.0000000000038352			11	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	SS4N1		gold, Green Accepted			2024-07-03	WOS:001236425500046
C	Cao, J; Ganesh, A; Cai, J; Southwell, R; Perkoff, EM; Regan, M; Kann, K; Martin, JH; Palmer, M; D'Mello, S			ACM	Cao, Jie; Ganesh, Ananya; Cai, Jon; Southwell, Rosy; Perkoff, E. Margaret; Regan, Michael; Kann, Katharina; Martin, James H.; Palmer, Martha; D'Mello, Sidney			A Comparative Analysis of Automatic Speech Recognition Errors in Small Group Classroom Discourse	2023 PROCEEDINGS OF THE 31ST ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, UMAP 2023			English	Proceedings Paper	31st ACM Conference on User Modeling, Adaptation and Personalization (ACM UMAP)	JUN 26-30, 2023	Limassol, CYPRUS	Assoc Comp Machinery, ACM SIGCHI, ACM SIGWEB, User Modeling Inc, NSF, Springer Nat, Univ Cyprus		Group Discourse Analysis; Automatic Speech Recognition; Text Tagging; Collaborative Learning	MATHEMATICS; DIVERSITY; TEAMWORK; SYSTEMS; ASR	In collaborative learning environments, effective intelligent learning systems need to accurately analyze and understand the collaborative discourse between learners (i.e., group modeling) to provide adaptive support. We investigate how automatic speech recognition (ASR) errors influence discourse models of small group collaboration in noisy real-world classrooms. Our dataset consisted of 30 students recorded by consumer off-the-shelf microphones (Yeti Blue) while engaging in dyadic- and triadic- collaborative learning in a multi-day STEM curriculum unit. We found that two state-of-the-art ASR systems (Google Speech and OpenAI Whisper) yielded very high word error rates (0.822, 0.847) but very different profiles of error with Google being more conservative, rejecting 38% of utterances instead of 12% for Whisper. Next, we examined how these ASR errors influenced down-stream small group modeling based on pre-trained large language models for three tasks: Abstract Meaning Representation parsing (AMRParsing), on-task/off-task detection (ONTASK), and Accountable Productive Talk prediction (TALKMOVE). As expected, models trained on clean human transcripts yielded degraded performance on all three tasks, measured by the transfer ratio (TR). However, the TR of the specific sentencelevel AMRParsing task (.39 -.62) was much lower than that of the abstract discourse-level ONTASK (.63-.94) and TALKMOVE tasks (.64.72). Furthermore, different training strategies that incorporated ASR transcripts alone or as augmentations of human transcripts increased accuracy for the discourse-level tasks (ONTASK and TALKMOVE) but not AMRParsing. Simulation experiments suggested that the models were tolerant of missing utterances in the dialog context, and that jointly improving ASR accuracy on important word classes (e.g., verbs and nouns) can improve performance across all tasks. Overall, our results provide insights into how different types of NLP-based tasks might be tolerant of ASR errors under extremely noisy conditions and provide suggestions for how to improve accuracy in small group modeling settings for a more equitable, engaging, and adaptive collaborative learning environment.	[Cao, Jie; Ganesh, Ananya; Cai, Jon; Southwell, Rosy; Perkoff, E. Margaret; Regan, Michael; Kann, Katharina; Martin, James H.; Palmer, Martha; D'Mello, Sidney] Univ Colorado Boulder, Boulder, CO 80309 USA	University of Colorado System; University of Colorado Boulder	Cao, J (corresponding author), Univ Colorado Boulder, Boulder, CO 80309 USA.	jie.cao@colorado.edu; ananya.ganesh@colorado.edu; jon.z.cai@colorado.edu; roso8920@colorado.edu; margaret.perkoff@colorado.edu; michael.regan@colorado.edu; katharina.kann@colorado.edu; james.martin@colorado.edu; martha.palmer@colorado.edu; sidney.dmello@colorado.edu	Cao, jie/JXR-6551-2024	CAO, JIE/0000-0001-8268-954X; Southwell, Rosy/0000-0003-4141-523X	NSF National AI Institute for Student-AI Teaming (iSAT) [DRL 2019805]	NSF National AI Institute for Student-AI Teaming (iSAT)	This research was supported by the NSF National AI Institute for Student-AI Teaming (iSAT) under grant DRL 2019805. The opinions expressed are those of the authors and do not represent views of the NSF. We thank members of iSAT and Institute of Cognitive Science, especially Charis Harty and Brandon Booth, for their valuable insights and suggestions; and reviewers for helpful comments and corrections.	Banarescu L., 2013, P 7 LING ANN WORKSH, P178; Benson Alayne, 2023, XRDS: Crossroads, The ACM Magazine for Students, P30, DOI 10.1145/3589646; Bevilacqua M, 2021, AAAI CONF ARTIF INTE, V35, P12564; Bonial C. N., 2019, Proceedings of the Society for Computation in Linguistics, V2, P236, DOI 10.18653/v1/W19-3322; Bradford Mariah, 2023, P 24 INT C ARTIFICIA; Bush Jeffrey B, 2023, WORKSHOP LANGUAGEBAS; Cai Shu, 2013, Short Papers, V2, P748; Carpenter D, 2020, LECT NOTES ARTIF INT, V12163, P55, DOI 10.1007/978-3-030-52237-7_5; Cetintas S, 2010, IEEE T LEARN TECHNOL, V3, P228, DOI 10.1109/TLT.2009.44; Chaijum N., 2020, European Journal of Science and Mathematics Education, V8, P4, DOI [https://doi.org/10.30935/scimath/9555, DOI 10.30935/SCIMATH/9555]; Chakarov AG, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21186243; Chen Z, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3685; COHEN EG, 1994, REV EDUC RES, V64, P1, DOI 10.3102/00346543064001001; Costaguta Rosanna, 2019, P 20 INT C HUMAN COM, P1; Curseu PL, 2013, STUD HIGH EDUC, V38, P87, DOI 10.1080/03075079.2011.565122; D'Mello SK, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P557, DOI 10.1145/2818346.2830602; D'Mello SK, 2010, HUM-COMPUT INTERACT, V25, P289, DOI 10.1080/07370024.2010.499850; Damonte M, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P536; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dowell NM, 2014, LECT NOTES COMPUT SC, V8474, P124, DOI 10.1007/978-3-319-07221-0_15; Dyke Gregory, P INT C INTELLIGENT, P459; Eagle Michael, 2016, P 2016 C USER MODELI, P55; Favre B, 2013, INTERSPEECH, P3430; Flores M., 2016, Professores e escolas: conhecimento, formacao e acao, P31; Foltz PW, 2003, P 47 ANN M HUM FACT, V47, P673; Fosler-Lussier E., 2002, ISCA TUTORIAL RES WO; Gamper H, 2020, INT CONF ACOUST SPEE, P491, DOI [10.1109/ICASSP40776.2020.9053025, 10.1109/icassp40776.2020.9053025]; Ganesh Ananya, 2023, P 24 INT C ARTIFICIA; Gerosa Matteo., 2009, P 2 WORKSH CHILD COM; Godwin KE, 2016, LEARN INSTR, V44, P128, DOI 10.1016/j.learninstruc.2016.04.003; Gokhale A.A., 1995, Journal of Technology Education, V7, DOI DOI 10.21061/JTE.V7I1.A.2; Goldwater S, 2010, SPEECH COMMUN, V52, P181, DOI 10.1016/j.specom.2009.10.001; Google, 2023, Google speech-to-text; Graesser A. C., 2020, COLLABORATION 21 CEN; GRAESSER AC, 1995, APPL COGNITIVE PSYCH, V9, P495, DOI 10.1002/acp.2350090604; Hao J., 2017, ETS Research Report Series, V1, P1, DOI [10.1002/ets2.12184, DOI 10.1002/ETS2.12184]; Harrison DA, 2007, ACAD MANAGE REV, V32, P1199, DOI 10.5465/AMR.2007.26586096; Hmelo-Silver CE, 2008, COGNITION INSTRUCT, V26, P48, DOI 10.1080/07370000701798495; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Jacobs J, 2022, TEACH TEACH EDUC, V112, DOI 10.1016/j.tate.2022.103631; Jeong H, 2016, EDUC PSYCHOL-US, V51, P247, DOI 10.1080/00461520.2016.1158654; Kapanipathi P, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3884; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kennedy J, 2017, ACMIEEE INT CONF HUM, P82, DOI 10.1145/2909824.3020229; Kingma D. P., 2017, ARXIV; Kusumawati R, 2019, J PHYS CONF SER, DOI 10.1088/1742-6596/1211/1/012097; Langer-Osuna Jennifer, 2018, RETHINKING LOAFERS U; Langer-Osuna JM, 2018, EDUC SCI, V8, DOI 10.3390/educsci8020087; Latham A, 2022, WOMEN COMPUTATIONAL, P77, DOI DOI 10.1007/978-3-030-79092-9_4; Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Litman D.J., 2006, INT J ARTIFICIAL INT, V16, P145; Liu LD, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P7373, DOI 10.1109/ICASSP39728.2021.9414800; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lugini Luca, 2020, C P 28 INT C COMPUTA; Magnisalis I, 2011, IEEE T LEARN TECHNOL, V4, P5, DOI 10.1109/TLT.2011.2; Mdhaffar S, 2019, INTERSPEECH, P569, DOI 10.21437/Interspeech.2019-2661; Michaels S., 2013, ACCOUNTABLE TALK SOU; Michaels S., 2015, SOCIALIZING INTELLIG, P347; Min B., 2021, arXiv; National Research Council, 2000, How people learn: Brain, mind, experience, and School: Expanded Edition; Nechaev Yaroslav, 2021, KDD 2021 WORKSHOP DA; Le NT, 2016, INTERSPEECH, P2538, DOI 10.21437/Interspeech.2016-464; Park K., 2022, Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue, P490; Potamianos A, 2003, IEEE T SPEECH AUDI P, V11, P603, DOI 10.1109/TSA.2003.818026; Pugh S. L., 2021, Proceedings of the 14th International Conference on Educational Data Mining; Pugh SL, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P208, DOI 10.1145/3506860.3506894; Qian YM, 2018, FRONT INFORM TECH EL, V19, P40, DOI 10.1631/FITEE.1700814; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Ravari Parastoo Baghaei, 2021, 2021 30 IEEE INT C R, P250; Rodriguez A, 2019, PREHOSP DISASTER MED, V34, P297, DOI [10.1017/S1049023X19004278, 10.1145/3335595.3335635]; Roschelle J., 1995, Computer Supported Collaborative Learning. Proceedings NATO Advanced Research Workshop, P69; Roschelle J, 2013, COMPUT EDUC, V69, P523, DOI 10.1016/j.compedu.2013.04.010; Rosé CP, 2020, INT J COMP-SUPP COLL, V15, P249, DOI 10.1007/s11412-020-09329-z; Roy S, 2021, Arxiv, DOI arXiv:2106.02016; Sabourin J, 2011, LECT NOTES ARTIF INT, V6738, P534, DOI 10.1007/978-3-642-21869-9_93; Scornavacco Karla, 2022, ANNU M AM EDUC RES; Sell G, 2018, INTERSPEECH, P2808, DOI 10.21437/Interspeech.2018-1893; Settle S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4819, DOI 10.1109/ICASSP.2018.8461893; Shivakumar PG, 2022, COMPUT SPEECH LANG, V72, DOI 10.1016/j.csl.2021.101289; Simonnet Edwin, 2018, P 11 INT C LANGUAGE; Song Y, 2021, J EDUC COMPUT RES, V59, P496, DOI 10.1177/0735633120968554; Sottilare R.A., 2013, Design recommendations for intelligent tutoring systems: Volume 1-learner modeling, V1; Southwell Rosy, 2022, INT ED DATA MINING S; Springer L, 1999, REV EDUC RES, V69, P21, DOI 10.2307/1170643; Stahl G, 2005, J COMPUT ASSIST LEAR, V21, P79, DOI 10.1111/j.1365-2729.2005.00115.x; Stuttle Matthew, 2004, ICSLP 2004; Suresh A., 2021, Using Transformers to Provide Teachers with Personalized Feedback on their Classroom Discourse: The TalkMoves Application; Suresh A, 2021, LECT NOTES ARTIF INT, V12749, P344, DOI 10.1007/978-3-030-78270-2_61; Suresh Abhijit, 2022, P 17 WORKSHOP INNOVA, P71; Szymanski Piotr, 2020, FINDINGS ASS COMPUTA, P3290, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.295; Terenzini P.T., 2001, J ENG EDUC, V90, P123, DOI [10.1002/j.21689830.2001.tb00579.x, DOI 10.1002/J.21689830.2001.TB00579.X, DOI 10.1002/J.2168-9830.2001.TB00579.X]; Turner Faith LeAn, 2022, THESIS TARLETON STAT; Vygotsky L., 1978, READINGS DEV CHILDRE, V23, P34, DOI DOI 10.2307/J.CTVJF9VZ4.11; Weiss G., 1999, What do you mean by collaborative learning?.; Wilson JM, 2007, ACAD MANAGE REV, V32, P1041, DOI 10.5465/AMR.2007.26585724; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yasin I, 2018, J ACOUST SOC AM, V143, pEL112, DOI 10.1121/1.5023502; Yeh CYC, 2019, RES PRACT TECH ENHAN, V14, DOI 10.1186/s41039-019-0100-9; Yin Jian, 2020, P 58 ANN M ASS COMP, P6053	100	6	6	5	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9932-6				2023							250	262		10.1145/3565472.3595606	http://dx.doi.org/10.1145/3565472.3595606			13	Computer Science, Cybernetics; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5PQ		Bronze			2024-07-03	WOS:001051715400025
J	Pradhan, F; Fiedler, A; Samson, K; Olivera-Martinez, M; Manatsathit, W; Peeraphatdit, T				Pradhan, Faruq; Fiedler, Alexandra; Samson, Kaeli; Olivera-Martinez, Marco; Manatsathit, Wuttiporn; Peeraphatdit, Thoetchai			Artificial intelligence compared with human-derived patient educational materials on cirrhosis	HEPATOLOGY COMMUNICATIONS			English	Article							HEALTH INFORMATION; READABILITY; UNDERSTANDABILITY; ACTIONABILITY; EPIDEMIOLOGY	Background: The study compared the readability, grade level, understandability, actionability, and accuracy of standard patient educational material against artificial intelligence chatbot-derived patient educational material regarding cirrhosis. Methods: An identical standardized phrase was used to generate patient educational materials on cirrhosis from 4 large language model-derived chatbots (ChatGPT, DocsGPT, Google Bard, and Bing Chat), and the outputs were compared against a pre-existing human-derived educational material (Epic). Objective scores for readability and grade level were determined using Flesch-Kincaid and Simple Measure of Gobbledygook scoring systems. 14 patients/caregivers and 8 transplant hepatologists were blinded and independently scored the materials on understandability and actionability and indicated whether they believed the material was human or artificial intelligence-generated. Understandability and actionability were determined using the Patient Education Materials Assessment Tool for Printable Materials. Transplant hepatologists also provided medical accuracy scores. Results: Most educational materials scored similarly in readability and grade level but were above the desired sixth-grade reading level. All educational materials were deemed understandable by both groups, while only the human-derived educational material (Epic) was considered actionable by both groups. No significant difference in perceived actionability or understandability among the educational materials was identified. Both groups poorly identified which materials were human-derived versus artificial intelligence-derived. Conclusions: Chatbot-derived patient educational materials have comparable readability, grade level, understandability, and accuracy to human-derived materials. Readability, grade level, and actionability may be appropriate targets for improvement across educational materials on cirrhosis. Chatbot-derived patient educational materials show promise, and further studies should assess their usefulness in clinical practice.	[Pradhan, Faruq; Olivera-Martinez, Marco; Manatsathit, Wuttiporn; Peeraphatdit, Thoetchai] Univ Nebraska Med Ctr, Dept Gastroenterol & Hepatol, Omaha, NE USA; [Fiedler, Alexandra] Univ Nebraska Med, Dept Internal Med, Omaha, NE USA; [Samson, Kaeli] Univ Nebraska Med Ctr, Coll Publ Hlth, Dept Biostat, Omaha, NE USA; [Pradhan, Faruq] 987835 Nebraska Med Ctr, Omaha, NE 68198 USA	University of Nebraska System; University of Nebraska Medical Center; University of Nebraska System; University of Nebraska Medical Center	Pradhan, F (corresponding author), 987835 Nebraska Med Ctr, Omaha, NE 68198 USA.	fpradhan@unmc.edu; alexandra.fiedler@unmc.edu; kksamson@unmc.edu; molivera@unmc.edu; shane.manatsathit@unmc.edu; t.peeraphatdit@unmc.edu	Manatsathit, Wuttiporn/HOF-4092-2023; Pradhan, Faruq/AAU-1769-2020	Manatsathit, Wuttiporn/0000-0003-4406-1588; Pradhan, Faruq/0000-0002-5249-188X; Fiedler, Alexandra/0009-0007-1665-151X				Adams Katie., 2023, MedCityNews; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beste LA, 2015, DIGEST DIS SCI, V60, P2628, DOI 10.1007/s10620-015-3592-1; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bujnowska-Fedak MM, 2019, ADV EXP MED BIOL, V1211, P1, DOI 10.1007/5584_2019_396; Cohen RA., 2011, USE INTERNET HLTH IN; Dy CJ., 2012, Hand (N Y), V7, P420425; Eltorai AEM, 2014, ARCH TRAUMA RES, V3, DOI 10.5812/atr.18161; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Grydgaard MF, 2018, SCAND J GASTROENTERO, V53, P1584, DOI 10.1080/00365521.2018.1545045; Gulati Rishabh, 2018, Clin Liver Dis (Hoboken), V11, P48, DOI 10.1002/cld.690; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Lipari M, 2019, AM J HEALTH-SYST PH, V76, P182, DOI 10.1093/ajhp/zxy021; MCLAUGHLIN GH, 1969, J READING, V12, P639; PEMAT for Printable Materials (PEMAT-P), Content last reviewed November 2020; Rooney MK, 2021, J PATIENT EXPERIENCE, V8, DOI 10.1177/2374373521998847; Rowe IA, 2017, DIGEST DIS, V35, P304, DOI 10.1159/000456580; Scaglione S, 2015, J CLIN GASTROENTEROL, V49, P690, DOI 10.1097/MCG.0000000000000208; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Storino A, 2016, JAMA SURG, V151, P831, DOI 10.1001/jamasurg.2016.0730; Weis BD., 2003, AMA, P31; Wilson L, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/35882; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	23	2	2	2	2	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA		2471-254X		HEPATOL COMMUN	Hepatol. Commun.	MAR	2024	8	3							e0367	10.1097/HC9.0000000000000367	http://dx.doi.org/10.1097/HC9.0000000000000367			6	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	HW1F5	38358382	gold			2024-07-03	WOS:001162446600001
J	Ramachandran, M				Ramachandran, Muthu			AI AND BLOCKCHAIN FRAMEWORK FOR HEALTHCARE APPLICATIONS	FACTA UNIVERSITATIS-SERIES ELECTRONICS AND ENERGETICS			English	Article						AI; Blockchain; Secure and Sustainable Software Engineering Framework for AI-Blockchain (AI-BlockchainOps); Smart Contract; Requirements Engineering for AI-Blockchain (RE-AIBC)		Artificial Intelligence (AI) has impacted global economy, workforce productivity, smart health, smart cities, smart transport, and much more to come. Large Language Models (LLM) such as ChatGPT and Google's Gemini, have been widely adopted in various applications. Blockchain Technology stands as a towering disruptor in today's tech landscape, offering assurances of enhanced security and scalability for various applications. Within the realm of healthcare, its adoption has surged, spanning from streamlined recordkeeping to bolstered clinical trials, fortified medical supply chains, and vigilant patient monitoring. These applications harness the intrinsic attributes of blockchain to elevate standards of safety, privacy, and security within the healthcare sector. The combined power of AI and blockchain has the potential to revolutionize healthcare delivery, ensuring improved security, transparency, and efficiency. Nevertheless, Porru et al. [1] have highlighted deficiencies in the processes, tools, and techniques within this domain. Hence, this paper aims to furnish a structured framework that ensures both security and sustainability in the development of healthcare blockchain applications. This paper also provides an overview of societal impact on both technologies. This article has evolved best practice guidelines and a systematic development framework for AI-Blockchain integration, known as AI-BlockchainOps. This research has also developed a reference architecture, exemplifying the modeling of an Electronic Health Record (EHR) using BPMN and simulation. Within this Electronic Health Record (EHR) scenario encompassing 100 user requests, the simulation absorbed 97.09% of cloud resources, with 76.33% allocated to knowledge discovery, and a utilization rate of 93.20% for blockchain scientists, alongside various other contributing factors.	[Ramachandran, Muthu] AI Tech UK, Leeds, England; [Ramachandran, Muthu] Forti5 Tech UK, London, England		Ramachandran, M (corresponding author), AI Tech UK, Leeds, England.; Ramachandran, M (corresponding author), Forti5 Tech UK, London, England.	muthuram@ieee.org						Agbo CC, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020056; Banafa A., 2020, Blockchain Technology and Applications; Beller M., 2018, Technical Report; Bron D, 2023, The Role of AI in Decentralized Autonomous Organizations (DAOs): From Governance to Decision-Making; Chang Victor, 2023, International Journal of Business Information Systems, P281, DOI 10.1504/IJBIS.2023.132065; Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339; Chung L, 2009, LECT NOTES COMPUT SC, V5600, P363, DOI 10.1007/978-3-642-02463-4_19; Coindesk, 2016, State of blockchain q1: blockchain funding overtakes bitcoin.; CompTIA, 2023, Blockchain Terminology: A Glossary For Beginners.; Czepluch J. S., 2015, The use of block chain technology in different application domains; De Filippi P., 2018, Blockchain and the Law: The Rule of Code, P13; Destefanis G, 2018, 2018 IEEE 1ST INTERNATIONAL WORKSHOP ON BLOCKCHAIN ORIENTED SOFTWARE ENGINEERING (IWBOSE), P19, DOI 10.1109/IWBOSE.2018.8327567; Dinh TN, 2018, COMPUTER, V51, P48, DOI 10.1109/MC.2018.3620971; Dzhalila D., 2023, J. ELTIKOM: J. Teknik Elektro, V7, P38; Ekblaw A., 2016, A Case Study for Blockchain in Healthcare:"MedRec" prototype for electronic health records and medical research data, DOI DOI 10.1109/OBD.2016.11; Feist J, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P8, DOI 10.1109/WETSEB.2019.00008; Gaol Ford Lumban, 2023, International Journal of Business Information Systems, P429, DOI 10.1504/IJBIS.2023.132124; Ghosh PK, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11010038; Giungato P, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9122214; HER The Office of the National Coordinator for Health Information Technology (ONC), 2023, What is an Electronic Health Record (EHR)?; IOTA, IOTA's Tangle is an open, feeless and scalable distributed ledger, designed to support frictionless data and value transfer; IOTA, The Backbone of the Internet of Things; Medium, About us; MedRec, a modern way to track your health with blockchain; NeuroChain, Future of Blockchain, More secure, more reliable and much faster than blockchain.; NeuroChain AI, The Ultimate Web3 + AI Infrastructure.; Oasis Labs, The Future of Responsible AI, Building Cutting-Edge Technologies in Decentralization, Privacy and AI; Porru S, 2017, PROC IEEE ACM INT C, P169, DOI 10.1109/ICSE-C.2017.142; PwC, PwC's Global Artificial Intelligence Study: Exploiting the AI Revolution.; Quantstamp, Securing the future of web3; Ramachandran M., 2023, Quality Framework for Explainable Artificial Intelligence (XAI) and Machine Learning Applications in Explainable Artificial Intelligence (XAI) Concepts, Tools, Technologies, & Use Cases; Ramachandran M, 2023, Int. J. Blockchain Healthcare Today (BHTY), V6; SingularityNET, Integrating AI, AGI (Artificial General Intelligence), and Blockchain.; Wang S, 2019, IEEE T COMPUT SOC SY, V6, P870, DOI 10.1109/TCSS.2019.2938190; Zcash, Zcash is cash for the new age.	35	0	0	10	10	UNIV NIS	NIS	UNIVERZITETSKI TRG 2, PO BOX 123, NIS, 18000, SERBIA	0353-3670	2217-5997		FACTA UNIV-SER ELECT	Facta Univ.-Ser. Electron. Energ.	MAR	2024	37	1					169	193		10.2298/FUEE2401169R	http://dx.doi.org/10.2298/FUEE2401169R			25	Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Engineering	MQ7O2					2024-07-03	WOS:001195161000014
J	Fields, J; Chovanec, K; Madiraju, P				Fields, John; Chovanec, Kevin; Madiraju, Praveen			A Survey of Text Classification With Transformers: How Wide? How Large? How Long? How Accurate? How Expensive? How Safe?	IEEE ACCESS			English	Article						NLP; text classification; transformers; survey	ALGORITHMS; MODEL	Text classification in natural language processing (NLP) is evolving rapidly, particularly with the surge in transformer-based models, including large language models (LLM). This paper presents an in-depth survey of text classification techniques across diverse benchmarks, addressing applications from sentiment analysis to chatbot-driven question-answering. Methodologically, it utilizes NLP-facilitated approaches such as co-citation and bibliographic coupling alongside traditional research techniques. Because new use cases continue to emerge in this dynamic field, the study proposes an expanded taxonomy of text classification applications, extending the focus beyond unimodal (text-only) inputs to explore the emerging field of multimodal classification. While offering a comprehensive review of text classification with LLMs, this review highlights novel questions that arise when approaching the task with transformers: It evaluates the use of multimodal data, including text, numeric, and columnar data, and discusses the evolution of text input lengths (tokens) for long text classification; it covers the historical development of transformer-based models, emphasizing recent advancements in LLMs; it evaluates model accuracy on 358 datasets across 20 applications, with results challenging the assumption that LLMs are universally superior, revealing unexpected findings related to accuracy, cost, and safety; and it explores issues related to cost and access as models become increasingly expensive. Finally, the survey discusses new social and ethical implications raised when using LLMs for text classification, including bias and copyright. Throughout, the review emphasizes the importance of a nuanced understanding of model performance and a holistic approach to deploying transformer-based models in real-world applications.	[Fields, John] Concordia Univ Wisconsin Ann Arbor, Business Analyt, Mequon, WI 53097 USA; [Fields, John; Chovanec, Kevin; Madiraju, Praveen] Marquette Univ, Dept Comp Sci, Milwaukee, WI 53233 USA	Marquette University	Fields, J (corresponding author), Concordia Univ Wisconsin Ann Arbor, Business Analyt, Mequon, WI 53097 USA.; Fields, J (corresponding author), Marquette Univ, Dept Comp Sci, Milwaukee, WI 53233 USA.	john.fields@cuw.edu		Chovanec, Kevin/0009-0005-8869-9083; Fields, John/0000-0001-5153-0376	Northwestern Mutual Data Science Institute and NSF	Northwestern Mutual Data Science Institute and NSF	No Statement Available	Abu Farha I, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P192; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adhikari A, 2019, Arxiv, DOI arXiv:1904.08398; Ahmed F., 2022, P IEEE AS PAC C COMP, P1; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Anil R, 2021, Arxiv, DOI arXiv:2108.01624; [Anonymous], Papers With Code-The Latest in Machine Learning; [Anonymous], Try bard, an AI experiment by Google; [Anonymous], Multimodal-Toolkit: Multimodal Model for Text and Tabular Data With Huggingface Transformers as Building Block for Text Data; [Anonymous], StableLM: Stability AI Language Models; [Anonymous], Connected Papers; [Anonymous], 2023, Free Dolly: Introducing the World's First Truly Open Instruction-Tuned LLM; [Anonymous], Llama 2; [Anonymous], Amazon Titan; [Anonymous], Introducing LLaMA: A foundational, 65-billion-parameter large language model; [Anonymous], Bing chat; Antoun W, 2021, Arxiv, DOI arXiv:2003.00104; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Artetxe M, 2022, Arxiv, DOI arXiv:2112.10684; Badaro G, 2023, T ASSOC COMPUT LING, V11, P227, DOI 10.1162/tacl_a_00544; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Beltagy I., 2019, arXiv; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Bhardwaj R, 2021, COGN COMPUT, V13, P1008, DOI 10.1007/s12559-021-09881-2; Biderman S, 2023, Arxiv, DOI arXiv:2304.01373; Bisong E., 2019, BUILDING MACHINE LEA, DOI [DOI 10.1007/978-1-4842-4470-8_7, 10.1007/978-1-4842-4470-8]; Borgeaud S, 2022, PR MACH LEARN RES; Borisov V, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3229161; Brown Hannah, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2280, DOI 10.1145/3531146.3534642; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chang KK, 2023, Arxiv, DOI arXiv:2305.00118; Chang RC., 2021, Dataset of Propaganda Techniques of the State-Sponsored Information Operation of the People's Republic of China; Chang WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3163, DOI 10.1145/3394486.3403368; ChatGPT, about us; Chen Zeming., 2021, Neurallog: Natural language inference with joint neural and logical reasoning; Cheng H, 2021, Arxiv, DOI arXiv:2101.00178; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cliche M, 2017, Arxiv, DOI arXiv:1704.06125; Cohan A, 2019, Arxiv, DOI arXiv:1909.04054; Cui YM, 2021, IEEE-ACM T AUDIO SPE, V29, P3504, DOI 10.1109/TASLP.2021.3124365; Dai X, 2022, Arxiv, DOI arXiv:2204.06683; Dao XQ, 2023, Arxiv, DOI arXiv:2305.12199; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003; Dodge J, 2021, Arxiv, DOI arXiv:2104.08758; Elmadany A, 2020, Arxiv, DOI arXiv:2006.01266; Fournier Q, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3586074; Gasparetto A, 2022, INFORMATION, V13, DOI 10.3390/info13020083; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Gehman S, 2020, Arxiv, DOI [arXiv:2009.11462, DOI 10.1017/S1431927621007376]; Gorishniy Y, 2021, ADV NEUR IN, V34; Gouws S, 2015, PR MACH LEARN RES, V37, P748; Greco CM, 2023, PATTERN RECOGN LETT, V167, P204, DOI 10.1016/j.patrec.2023.02.016; Groenwold S, 2020, Arxiv, DOI arXiv:2010.02510; Gu K., 2021, P 3 WORKSH MULT ART, P69, DOI DOI 10.18653/V1/2021.MAIWORKSHOP-1.10; Halevy M., 2021, P EAAMO, P1; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Holtz N., 2023, Natural Language Processing and Machine Learning; Hoory S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1178; Hoover B, 2019, Arxiv, DOI arXiv:1910.05276; Hu G., 2022, arXiv; Hu J., 2022, arXiv; Huang J., 2022, arXiv; Huang J, 2022, Arxiv, DOI arXiv:2205.12628; Huang X, 2022, NEURAL PROCESS LETT, V54, P3601, DOI 10.1007/s11063-021-10444-7; Hudson G. T., 2022, arXiv; Introducing BloombergGPT, 2023, Bloomberg's 50-Billion Parameter Large Language Model, Purpose-Built From Scratch for Finance; Islam R, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3779, DOI 10.1145/3442381.3449904; Jain S. M., 2022, Introduction to transformers for NLP: with the hugging face library and models to solve problems; Jeong M., 2022, arXiv; Jin B., 2023, Wall St. J.Apr.; Jin XS, 2021, Arxiv, DOI arXiv:2010.12864; Jwa H, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194062; Kalyan K. S., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.05542, 10.48550/arXiv.2108.05542]; Kandpal N, 2022, PR MACH LEARN RES, P10697; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; Keele S., 2007, Technical report; Kenny EM, 2021, KNOWL-BASED SYST, V233, DOI 10.1016/j.knosys.2021.107530; Kiela Douwe, 2021, arXiv; Kocaman Veysel, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P635, DOI 10.1007/978-3-030-68763-2_48; Kowsari K, 2018, 2ND INTERNATIONAL CONFERENCE ON INFORMATION SYSTEM AND DATA MINING (ICISDM 2018), P19, DOI 10.1145/3206098.3206111; Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lai G., 2019, arXiv; Lee JS, 2019, Arxiv, DOI [arXiv:1906.02124, DOI 10.48550/ARXIV.1906.02124]; Lehman E, 2021, Arxiv, DOI arXiv:2104.07762; Li C., 2020, OpenAI's GPT-3 language model: A technical overview; Li Q, 2021, Arxiv, DOI arXiv:2008.00364; Li T, 2020, Arxiv, DOI arXiv:2010.02428; Li XC, 2022, Arxiv, DOI arXiv:2110.05679; Liesenfeld A., 2023, P 5 INT C CONV US IN, P1; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Lu K., 2020, LOGIC LANGUAGE SECUR, P189, DOI DOI 10.1007/978-3-030-62077-614; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; de Araujo PHL, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1449; Ma XB, 2023, IEEE-ACM T AUDIO SPE, V31, P2410, DOI 10.1109/TASLP.2023.3284516; Magar I., 2022, arXiv; Manela DD, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2232; MARON ME, 1961, J ACM, V8, P404, DOI 10.1145/321075.321084; Eisenschlos JM, 2020, Arxiv, DOI arXiv:1909.04761; Martínez-Plumed F, 2021, NAT MACH INTELL, V3, P581, DOI 10.1038/s42256-021-00339-6; Meng Y, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1908, DOI 10.1145/3394486.3403242; Milmo D., 2023, GuardianFeb; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Minot JR, 2021, Arxiv, DOI arXiv:2103.05841; Mireshghallah F., 2022, P 2022 C EMPIRICAL M, P1816; Moe L., A BERT-Based Explainable System for COVID-19 Misinformation Identification; Moosa IM, 2022, Arxiv, DOI arXiv:2201.12501; Mozafari M, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237861; Muennighoff N, 2023, Arxiv, DOI arXiv:2305.16264; Munikar M, 2019, Arxiv, DOI arXiv:1910.03474; Nadeem M, 2020, Arxiv, DOI [arXiv:2004.09456, DOI 10.48550/ARXIV.2004.09456]; Nikolentzos G., 2020, P AAAI C ART INT, P5754; Pal A, 2020, Arxiv, DOI arXiv:2003.11644; Pichai S., 2023, IMPORTANT NEXT STEP; Pichai S., 2023, Google DeepMind: Bringing Together Two World-Class AI Teams; Pierse C., 2021, Introducing Transformers Interpret-Explainable AI for Transformers; Poibeau T, 2017, MIT PRESS ESSENT, P75; Prost F., 2019, arXiv; Pruksachatkun Yada, 2021, arXiv; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Rashed Ammar., Proceedings of the International AAAI Conference on Web and Social Media, V15, P537; Rietberg MT, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13071251; Rosa GM, 2022, Arxiv, DOI arXiv:2206.02873; Scaria K, 2023, Arxiv, DOI arXiv:2302.08624; Schlag I, 2021, Arxiv, DOI arXiv:2011.07831; Sha L., 2022, P 29 INT C COMP LING, P1275; Shaikh T., 2023, Authorea, DOI [10.22541/au.167407909.97031004, DOI 10.22541/AU.167407909.97031004]; Shavrina T, 2020, Arxiv, DOI arXiv:2010.15925; Shi WY, 2022, Arxiv, DOI arXiv:2108.12944; Shwartz-Ziv R, 2022, INFORM FUSION, V81, P84, DOI 10.1016/j.inffus.2021.11.011; Silva A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2383; Singh P, 2022, Arxiv, DOI arXiv:2205.08159; Skianis K, 2020, PR MACH LEARN RES, V108; Sleeman IV W. C., 2021, arXiv; Soyer H, 2015, Arxiv, DOI arXiv:1412.6334; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Studtmann Paul., 2021, STANFORD ENCY PHILOS; Sun C, 2019, Arxiv, DOI arXiv:1903.09588; Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968; Szczepanski M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03100-6; Taktasheva E, 2022, Arxiv, DOI arXiv:2210.12813; Tan YM, 2023, Arxiv, DOI arXiv:2303.07992; Tang TY, 2022, Arxiv, DOI arXiv:2206.12131; Touileb S, 2021, GEBNLP 2021: THE 3RD WORKSHOP ON GENDER BIAS IN NATURAL LANGUAGE PROCESSING, P66; van Aken B, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P207, DOI 10.1145/3366424.3383542; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wallaart O, 2019, LECT NOTES COMPUT SC, V11503, P363, DOI 10.1007/978-3-030-21348-0_24; Wang CG, 2022, Arxiv, DOI arXiv:2205.10475; Wang C, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, NAACL-HLT 2021, P121; Wang X., 2020, arXiv; Wang X, 2023, MACH INTELL RES, V20, P447, DOI 10.1007/s11633-022-1410-8; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xie Q, 2019, ARXIV190412848; Xu K, 2019, P 4 MACHINE LEARNING, V106, P197; Xu LXW, 2023, NEUROCOMPUTING, V518, P373, DOI 10.1016/j.neucom.2022.10.071; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang ZL, 2019, ADV NEUR IN, V32; Yasunaga M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8003; Yasunaga Michihiro, 2022, LinkBERT: Pretraining Language Models with Document Links; Yu D, 2022, Arxiv, DOI arXiv:2110.06500; Zaheer M, 2021, Arxiv, DOI arXiv:2007.14062; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]; Zhang JG, 2022, Arxiv, DOI arXiv:2106.04564; Zhang XX, 2019, Arxiv, DOI arXiv:1905.06566; Zhong ZX, 2021, Arxiv, DOI arXiv:2010.12812	175	2	2	30	30	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						6518	6531		10.1109/ACCESS.2024.3349952	http://dx.doi.org/10.1109/ACCESS.2024.3349952			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	EZ0T0		gold			2024-07-03	WOS:001142647500001
J	Martin, PP; Kranz, D; Wulff, P; Graulich, N				Martin, Paul P.; Kranz, David; Wulff, Peter; Graulich, Nicole			Exploring new depths: Applying machine learning for the analysis of student argumentation in chemistry	JOURNAL OF RESEARCH IN SCIENCE TEACHING			English	Article; Early Access						argumentation competence; computational grounded theory; machine learning; natural language processing; organic chemistry learning	SCIENTIFIC ARGUMENTATION; AUTOMATED-ANALYSIS; SCIENCE; FRAMEWORK; THINKING; RESPONSES; QUALITY; EXPLANATIONS; ASSESSMENTS; MECHANISMS	Constructing arguments is essential in science subjects like chemistry. For example, students in organic chemistry should learn to argue about the plausibility of competing chemical reactions by including various sources of evidence and justifying the derived information with reasoning. While doing so, students face significant challenges in coherently structuring their arguments and integrating chemical concepts. For this reason, a reliable assessment of students' argumentation is critical. However, as arguments are usually presented in open-ended tasks, scoring assessments manually is resource-consuming and conceptually difficult. To augment human diagnostic capabilities, artificial intelligence techniques such as machine learning or natural language processing offer novel possibilities for an in-depth analysis of students' argumentation. In this study, we extensively evaluated students' written arguments about the plausibility of competing chemical reactions based on a methodological approach called computational grounded theory. By using an unsupervised clustering technique, we sought to evaluate students' argumentation patterns in detail, providing new insights into the modes of reasoning and levels of granularity applied in students' written accounts. Based on this analysis, we developed a holistic 20-category rubric by combining the data-driven clusters with a theory-driven framework to automate the analysis of the identified argumentation patterns. Pre-trained large language models in conjunction with deep neural networks provided almost perfect machine-human score agreement and well-interpretable results, which underpins the potential of the applied state-of-the-art deep learning techniques in analyzing students' argument complexity. The findings demonstrate an approach to combining human and computer-based analysis in uncovering written argumentation.	[Martin, Paul P.; Kranz, David; Graulich, Nicole] Justus Liebig Univ, Inst Chem Educ, Giessen, Germany; [Wulff, Peter] Univ Educ, Phys Educ Res, Heidelberg, Germany; [Graulich, Nicole] Justus Liebig Univ, Inst Chem Educ, Heinrich Buff Ring 17, D-35392 Giessen, Germany	Justus Liebig University Giessen; Justus Liebig University Giessen	Graulich, N (corresponding author), Justus Liebig Univ, Inst Chem Educ, Heinrich Buff Ring 17, D-35392 Giessen, Germany.	nicole.graulich@didaktik.chemie.uni-giessen.de	Wulff, Peter/GSI-9069-2022; Kranz, David/M-5371-2018	Wulff, Peter/0000-0002-5471-7977; Kranz, David/0000-0002-2054-6882; Martin, Paul P./0000-0001-8648-4250	Projekt DEAL	Projekt DEAL	This publication is part of the first author's doctoral thesis (Dr. rer. nat.) at the Faculty of Biology and Chemistry, Justus-Liebig-University Giessen, Germany. We thank Leonie Lieber, Ira & nbsp;Caspari-Gnann, and Krenare Ibraj for their groundbreaking research on students' argumentation in chemistry as well as for providing access to their data. We thank Felix Blodtner for scoring students' arguments and all members of the Graulich group for fruitful discussions. Finally, Paul P. Martin thanks & nbsp;Brandon Yik, Amber Dood, and Field Watts for sharing their innovative thoughts on the application of ML in science education. There are no conflicts of interest to declare. Open Access funding enabled and organized by Projekt DEAL.	Anderson D, 2020, EDUC MEAS-ISSUES PRA, V39, P53, DOI 10.1111/emip.12314; Angelov D, 2020, Arxiv, DOI [arXiv:2008.09470, DOI 10.48550/ARXIV.2008.09470, 10.48550/arXiv.2008.09470]; Bail CA, 2014, THEOR SOC, V43, P465, DOI 10.1007/s11186-014-9216-5; Beltagy I., 2019, arXiv; Berland LK, 2009, SCI EDUC, V93, P26, DOI 10.1002/sce.20286; Biernacki R, 2012, CULT SOCIOL-SER, P1; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Bodé NE, 2019, J CHEM EDUC, V96, P1068, DOI 10.1021/acs.jchemed.8b00719; Brunton SL, 2019, DATA-DRIVEN SCIENCE AND ENGINEERING: MACHINE LEARNING, DYNAMICAL SYSTEMS, AND CONTROL, P1, DOI 10.1017/9781108380690; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14; Campello RJGB, 2015, ACM T KNOWL DISCOV D, V10, DOI 10.1145/2733381; Carle M. S., 2021, ChemRxiv Preprint, P1, DOI [10.26434/chemrxiv.13322771.v1, DOI 10.26434/CHEMRXIV.13322771.V1]; Carlsen HB, 2022, BIG DATA SOC, V9, DOI 10.1177/20539517221080146; Caruana Rich, 2022, KDD '22: Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, P4776, DOI 10.1145/3534678.3542627; Caspari I., 2019, IJPCE, V11, P31; Cetin PS, 2014, RES SCI TECHNOL EDUC, V32, P1, DOI 10.1080/02635143.2013.850071; Charmaz K., 2014, Constructing Grounded Theory, V2nd edition; Cheuk T., 2019, ANN M NATL ASS R; Cheuk T, 2021, SCI EDUC, V105, P825, DOI 10.1002/sce.21671; Chin C, 2000, J RES SCI TEACH, V37, P109, DOI 10.1002/(SICI)1098-2736(200002)37:2<109::AID-TEA3>3.3.CO;2-Z; Chin C, 2010, J LEARN SCI, V19, P230, DOI 10.1080/10508400903530036; Chinn CA, 2002, J EDUC PSYCHOL, V94, P327, DOI 10.1037//0022-0663.94.2.327; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Darden L, 2002, PHILOS SCI, V69, pS354, DOI 10.1086/341858; Deeva G, 2021, COMPUT EDUC, V162, DOI 10.1016/j.compedu.2020.104094; Deng JM, 2023, J CHEM EDUC, V100, P1523, DOI 10.1021/acs.jchemed.2c01063; Deng JM, 2022, INT J SCI EDUC, V44, P2131, DOI 10.1080/09500693.2022.2114299; Deng JM, 2021, CHEM EDUC RES PRACT, V22, P749, DOI 10.1039/d0rp00320d; Deng JM., 2023, STUDENT REASONING, P74; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Donnelly DF, 2015, J SCI EDUC TECHNOL, V24, P861, DOI 10.1007/s10956-015-9569-1; Dood A, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P492, DOI 10.1145/3506860.3506892; Dood AJ, 2020, J CHEM EDUC, V97, P3551, DOI 10.1021/acs.jchemed.0c00569; Dood AJ, 2020, CHEM EDUC RES PRACT, V21, P267, DOI 10.1039/c9rp00148d; Dood AJ, 2018, J CHEM EDUC, V95, P1267, DOI 10.1021/acs.jchemed.8b00177; Driver R, 2000, SCI EDUC, V84, P287, DOI 10.1002/(SICI)1098-237X(200005)84:3<287::AID-SCE1>3.0.CO;2-A; Duschl R. A., 2002, STUDIES SCI ED, V38, P39, DOI [10.1080/03057260208560187, DOI 10.1080/03057260208560187]; Erduran S, 2004, SCI EDUC, V88, P915, DOI 10.1002/sce.20012; Erduran S, 2019, ADV CHEM EDUC SER, V2, P1; Faize FA, 2018, EURASIA J MATH SCI T, V14, P475, DOI 10.12973/ejmste/80353; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Gerard L, 2015, EDUC RES REV-NETH, V15, P41, DOI 10.1016/j.edurev.2015.04.001; Glaser B., 1999, Divery of grounded theory: Strategies for qualitative research, V1; Goldberg Y., 2017, Neural Network Methods in Natural Language Processing, DOI 10.2200/S00762ED1V01Y201703HLT037; Gombert S, 2023, J COMPUT ASSIST LEAR, V39, P767, DOI 10.1111/jcal.12767; Graulich N., 1930, Chemistry Teacher International, V3; Grimm A., 2023, Prontiers in Education, V7, P1; Grimm A, 2023, J LEARN ANAL, V10, P71, DOI 10.18608/jla.2023.7793; Grootendorst M., 2020, Topic Modeling with BERT: Leveraging BERT and TF IDF to create easily interpretable topics; Harris CJ, 2019, EDUC MEAS-ISSUES PRA, V38, P53, DOI 10.1111/emip.12253; Haudek K. C., 2015, ANN M NATL ASS; Haudek K. C., 2021, ANN M NATL ASS; Haudek K. C., 2014, ANN M NATL C MEAS; Haudek K. C., 2009, ANN M NATL ASS; Haudek KC, 2012, CBE-LIFE SCI EDUC, V11, P283, DOI 10.1187/cbe.11-08-0084; Hernández-Blanco A, 2019, COMPLEXITY, DOI 10.1155/2019/1306039; Huang CJ, 2011, COMPUT EDUC, V57, P1270, DOI 10.1016/j.compedu.2011.01.013; Illari PM, 2012, EUR J PHILOS SCI, V2, P119, DOI 10.1007/s13194-011-0038-2; Jeong H, 2007, RES SCI EDUC, V37, P75, DOI 10.1007/s11165-006-9014-9; Jescovitch L. N., 2019, ANN M NATL ASS; Jescovitch L. N., 2019, Practical Assessment, Research & Evaluation, V24, P1; Jescovitch LN, 2021, J SCI EDUC TECHNOL, V30, P150, DOI 10.1007/s10956-020-09858-0; Jiménez-Aleixandre MP, 2000, SCI EDUC, V84, P757, DOI 10.1002/1098-237X(200011)84:6<757::AID-SCE5>3.0.CO;2-F; Jurafsky D., 2023, Speech and language processing: An Introduction to natural language processing, computational linguistics, and speech recognition, V3; Kaldaras L, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.968289; Kanari Z, 2004, J RES SCI TEACH, V41, P748, DOI 10.1002/tea.20020; Kang H, 2014, SCI EDUC, V98, P674, DOI 10.1002/sce.21123; Kranz D, 2023, CHEM EDUC RES PRACT, V24, P453, DOI 10.1039/d2rp00132b; Krist C, 2019, J LEARN SCI, V28, P160, DOI 10.1080/10508406.2018.1510404; Kubsch M., 2021, P 15 INT C LEARNI, P897; Kubsch M, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.981910; Kubsch M, 2023, J RES SCI TEACH, V60, P423, DOI 10.1002/tea.21803; Küchemann S, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P36, DOI 10.5220/0009359400360046; Kuhn D, 2003, CHILD DEV, V74, P1245, DOI 10.1111/1467-8624.00605; Kuhn D, 2010, SCI EDUC, V94, P810, DOI 10.1002/sce.20395; Kuo CY, 2013, COMPUT EDUC, V68, P388, DOI 10.1016/j.compedu.2013.06.002; Lam L., 2012, Computers in Human Behavior, V139, P1; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lee H. S., 2012, Journal of Science Education and Technology, V30, P192; Lee HS, 2019, SCI EDUC, V103, P590, DOI 10.1002/sce.21504; Lee HS, 2014, J RES SCI TEACH, V51, P581, DOI 10.1002/tea.21147; Lieber L.. S., 2012, Journal of Chemical Education, V997, P2754; Lieber L. S., 2000, Journal of Chemical Education, V97, P3731; Lieber L, 2022, CHEM EDUC RES PRACT, V23, P38, DOI 10.1039/d1rp00145k; Lieber LS, 2022, CHEM EDUC RES PRACT, V23, P811, DOI 10.1039/d2rp00016d; Liu OL, 2014, EDUC MEAS-ISSUES PRA, V33, P19, DOI 10.1111/emip.12028; Liu X., 2000, Using and developing measurement instruments in science education: A Rasch modeling approach, V2; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Luisi P.L., 2002, Foundations of Chemistry, V4, P183, DOI DOI 10.1023/A:1020672005348; Lundberg SM, 2017, ADV NEUR IN, V30; Luo XL, 2020, CHEM EDUC RES PRACT, V21, P1083, DOI 10.1039/c9rp00269c; Machamer P, 2000, PHILOS SCI, V67, P1, DOI 10.1086/392759; Maestrales S, 2021, J SCI EDUC TECHNOL, V30, P239, DOI 10.1007/s10956-020-09895-9; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Manz E, 2016, J RES SCI TEACH, V53, P1113, DOI 10.1002/tea.21264; Mao LY, 2018, EDUC ASSESS, V23, P121, DOI 10.1080/10627197.2018.1427570; Martin PP, 2023, CHEM EDUC RES PRACT, V24, P407, DOI 10.1039/d2rp00287f; Mathew Amitha, 2021, Advanced Machine Learning Technologies and Applications. Proceedings of AMLTA 2020. Advances in Intelligent Systems and Computing (1141), P599, DOI 10.1007/978-981-15-3383-9_54; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; McNeill K.L., 2011, Supporting Grade 5-8 Students in Constructing Explanations in Science: The Claim, Evidence, and Reasoning Framework for Talk and Writing; McNeill KL, 2006, J LEARN SCI, V15, P153, DOI 10.1207/s15327809jls1502_1; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Miller E., 2019, DISCIPLINARY INTERDI, V1, DOI DOI 10.1186/S43031-019-0009-6; Mislevy R. J., 2003, RR0316 ED TEST SERV, V10, pi, DOI DOI 10.1002/J.2333-8504.2003.TB01908.X; Mislevy RJ, 2016, J EDUC MEAS, V53, P265, DOI 10.1111/jedm.12117; Mitchell T., 1997, Machine learning; Moon A, 2019, CHEM EDUC RES PRACT, V20, P484, DOI 10.1039/c9rp00005d; Moreira P, 2019, CHEM EDUC RES PRACT, V20, P120, DOI 10.1039/c8rp00159f; Nehm RH, 2012, J SCI EDUC TECHNOL, V21, P56, DOI 10.1007/s10956-011-9282-7; Nelson LK, 2020, SOCIOL METHOD RES, V49, P3, DOI 10.1177/0049124117729703; Nelson LK, 2021, SOCIOL METHOD RES, V50, P202, DOI 10.1177/0049124118769114; Newton P, 1999, INT J SCI EDUC, V21, P553, DOI 10.1080/095006999290570; Noroozi O, 2018, EDUC PSYCHOL REV, V30, P153, DOI 10.1007/s10648-017-9400-z; Noyes K, 2020, J CHEM EDUC, V97, P3923, DOI 10.1021/acs.jchemed.0c00445; Osborne J, 2004, J RES SCI TEACH, V41, P994, DOI 10.1002/tea.20035; Osborne JF, 2011, SCI EDUC, V95, P627, DOI 10.1002/sce.20438; Paszke A, 2019, ADV NEUR IN, V32; Patterson E., 1999, Just -In -time teaching: Blending active learning with web technology; Pellegrino JW, 2016, EDUC PSYCHOL-US, V51, P59, DOI 10.1080/00461520.2016.1145550; Jiménez-Aleixandre MP, 2008, SCI TECHNOL EDUC LIB, V35, P3; Plass JL, 2020, J RES TECHNOL EDUC, V52, P275, DOI 10.1080/15391523.2020.1719943; Prevost L, 2012, PROC FRONT EDUC CONF; Rosenberg JM, 2021, J SCI EDUC TECHNOL, V30, P255, DOI 10.1007/s10956-020-09862-4; Rostamizadeh A., 2012, FDN MACHINE LEARNING; Ruder S., 2019, Neural transfer learning for natural language processing; Russ RS, 2008, SCI EDUC, V92, P499, DOI 10.1002/sce.20264; Sailer M, 2023, LEARN INSTR, V83, DOI 10.1016/j.learninstruc.2022.101620; Saldana J., 2015, The coding manual for qualitative researchers, V3; Sampson V, 2011, SCI EDUC, V95, P217, DOI 10.1002/sce.20421; SAMUEL AL, 1959, IBM J RES DEV, V3, P211, DOI 10.1147/rd.441.0206; Sandoval WA, 2005, COGNITION INSTRUCT, V23, P23, DOI 10.1207/s1532690xci2301_2; Sevian H, 2014, CHEM EDUC RES PRACT, V15, P10, DOI 10.1039/c3rp00111c; Sherin B, 2013, J LEARN SCI, V22, P600, DOI 10.1080/10508406.2013.836654; Soo K. W., 2019, The role of granularity in causal learning; Southard K, 2016, CBE-LIFE SCI EDUC, V15, DOI 10.1187/cbe.15-05-0114; Swiecki Z., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100075; Taher Pilehvar M., 2020, Embeddings in natural language processing: Theory and advances in vector representations of meaning; Talanquer V, 2018, CHEM EDUC RES PRACT, V19, P998, DOI 10.1039/c7rp00187h; Tansomboon C, 2017, INT J ARTIF INTELL E, V27, P729, DOI 10.1007/s40593-017-0145-0; Toulmin S. E., 2003, The uses of argument; Tschisgale P, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.020123; Ullmann TD, 2019, INT J ARTIF INTELL E, V29, P217, DOI 10.1007/s40593-019-00174-2; Koroteev MV, 2021, Arxiv, DOI [arXiv:2103.11943, DOI 10.48550/ARXIV.2103.11943]; van Mil MHW, 2013, SCI EDUC-NETHERLANDS, V22, P93, DOI 10.1007/s11191-011-9379-7; Vitale JM, 2016, INT J SCI EDUC, V38, P1548, DOI 10.1080/09500693.2016.1198969; Walker JP, 2019, J CHEM EDUC, V96, P435, DOI 10.1021/acs.jchemed.8b00745; Wang C, 2021, J SCI EDUC TECHNOL, V30, P269, DOI 10.1007/s10956-020-09859-z; Watts F. M., 2023, LAK23 13 INT LEARN A, P531, DOI DOI 10.1145/3576050.3576053; Watts FM, 2022, CHEM EDUC RES PRACT, V23, P486, DOI 10.1039/d1rp00301a; Watts FM, 2021, CHEM EDUC RES PRACT, V22, P364, DOI 10.1039/d0rp00298d; Watts FM., 2023, STUDENT REASONING OR, P285; Weinrich ML, 2016, CHEM EDUC RES PRACT, V17, P394, DOI 10.1039/c5rp00208g; Wilson CD, 2024, J RES SCI TEACH, V61, P38, DOI 10.1002/tea.21864; Winograd BA., 2021, P 14 COMPUTER SUPPOR, P11; Winograd B, 2021, LAK21 CONFERENCE PROCEEDINGS: THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P586, DOI 10.1145/3448139.3448202; Wulff P, 2023, FRONT EDUC, V7, DOI 10.3389/feduc.2022.1061461; Wulff P, 2022, J SCI EDUC TECHNOL, V31, P490, DOI 10.1007/s10956-022-09969-w; Wulff P, 2023, INT J ARTIF INTELL E, V33, P439, DOI 10.1007/s40593-022-00290-6; Yik BJ, 2021, CHEM EDUC RES PRACT, V22, P866, DOI 10.1039/d1rp00111f; Zehner F, 2016, EDUC PSYCHOL MEAS, V76, P280, DOI 10.1177/0013164415590022; Zhai XM, 2023, RES SCI EDUC, V53, P405, DOI 10.1007/s11165-022-10062-w; Zhai XM, 2020, J RES SCI TEACH, V57, P1430, DOI 10.1002/tea.21658; Zhai XM, 2020, STUD SCI EDUC, V56, P111, DOI 10.1080/03057267.2020.1735757; Zhu MX, 2017, INT J SCI EDUC, V39, P1648, DOI 10.1080/09500693.2017.1347303	166	5	5	32	47	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0022-4308	1098-2736		J RES SCI TEACH	J. Res. Sci. Teach.	2023 SEP 20	2023										10.1002/tea.21903	http://dx.doi.org/10.1002/tea.21903		SEP 2023	36	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	S0HB3		hybrid			2024-07-03	WOS:001068055900001
J	Jungherr, A				Jungherr, Andreas			Artificial Intelligence and Democracy: A Conceptual Framework	SOCIAL MEDIA + SOCIETY			English	Article						artificial intelligence; democracy; self-rule; equality; elections; autocracy	FILTER BUBBLES; ECHO CHAMBERS; AUTOMATION; BIAS; GO; AI; ALGORITHM; IMPACT; GAME	The success and widespread deployment of artificial intelligence (AI) have raised awareness of the technology's economic, social, and political consequences. Each new step in the development and application of AI is accompanied by speculations about a supposedly imminent but largely fictional artificial general intelligence (AGI) with (super-)human capacities, as seen in the unfolding discourse about capabilities and impact of large language models (LLMs) in the wake of ChatGPT. These far-reaching expectations lead to a discussion on the societal and political impact of AI that is largely dominated by unfocused fears and enthusiasms. In contrast, this article provides a framework for a more focused and productive analysis and discussion of AI's likely impact on one specific social field: democracy. First, it is necessary to be clear about the workings of AI. This means differentiating between what is at present a largely imaginary AGI and narrow artificial intelligence focused on solving specific tasks. This distinction allows for a critical discussion of how AI affects different aspects of democracy, including its effects on the conditions of self-rule and people's opportunities to exercise it, equality, the institution of elections, and competition between democratic and autocratic systems of government. This article shows that the consequences of today's AI are more specific for democracy than broad speculation about AGI capabilities implies. Focusing on these specific aspects will account for actual threats and opportunities and thus allow for better monitoring of AI's impact on democracy in an interdisciplinary effort by computer and social scientists.	[Jungherr, Andreas] Univ Bamberg, Digital Transformat, Chair Polit Sci, Bamberg, Germany; [Jungherr, Andreas] Univ Bamberg, Chair Polit Sci, Inst Polit Sci, Digital Transformat, Feldkirchenstr 21, D-96052 Bamberg, Germany	Otto Friedrich University Bamberg; Otto Friedrich University Bamberg	Jungherr, A (corresponding author), Univ Bamberg, Chair Polit Sci, Inst Polit Sci, Digital Transformat, Feldkirchenstr 21, D-96052 Bamberg, Germany.	andreas.jungherr@gmail.com		Jungherr, Andreas/0000-0003-2598-2453				Acemoglu D., 2019, The economics of artificial intelligence: An agenda, P197, DOI DOI 10.7208/CHICAGO/9780226613475.003.0008; Acemoglu D., 2021, Working Paper 29247, DOI DOI 10.3386/W29247; Acemoglu D., 2023, Power and progress: our 1000-year struggle over technology and prosperity; Acemoglu D, 2022, ECONOMETRICA, V90, P1973, DOI 10.3982/ECTA19815; Acemoglu D, 2022, REV ECON STUD, V89, P1, DOI 10.1093/restud/rdab031; ACHEN Christopher H., 2017, Democracy for Realists: Why Elections do not Produce Responsive Government; Agrawal Ajay., 2022, Prediction machines, insurance, and protection: An alternative perspective on AI's role in production; Ahmed N, 2023, SCIENCE, V379, P884, DOI 10.1126/science.ade2420; [Anonymous], 1998, On Democracy; [Anonymous], 2016, Prototype Politics: Technology-intensive campaigning and the data of democracy, DOI DOI 10.1093/ACPROF:OSO/9780199350247.001.0001; Asenbaum H, 2022, POLIT STUD REV, V20, P680, DOI 10.1177/14789299211052890; Aviram H, 2017, ANNU REV LAW SOC SCI, V13, P295, DOI 10.1146/annurev-lawsocsci-110316-113558; Bai H., 2023, OSF preprint, DOI [10.31219/osf.io/stakv, DOI 10.31219/OSF.IO/STAKV]; Bakhtin A, 2022, SCIENCE, V378, P1067, DOI 10.1126/science.ade9097; Bennett W.L., 2020, The disinformation age: Politics, technology, and disruptive communication in the United States, DOI DOI 10.1017/9781108914628; Bessen J., 2022, The new goliaths: How corporations use software to dominate industries, kill innovation, and undermine regulation; Bimber B., 2003, Information and American democracy; Bisbee J., 2023, SocArXiv, DOI [10.31235/osf.io/5ecfa, DOI 10.31235/OSF.IO/5ECFA]; Bolukbasi T, 2016, ADV NEUR IN, V29; Bostrom Nick, 2016, SUPERINTELLIGENCE PA, DOI DOI 10.1080/01402390.2013.844127; Bradford Anu, 2023, DIGITAL EMPIRES GLOB; Brayne Sarah, 2020, Predict and Surveil: Data, Discretion, and the Future of Policing, DOI DOI 10.1093/OSO/9780190684099.001.0001; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brynjolfsson E., 2016, 2 MACHINE AGE WORK P; Brynjolfsson E., 2023, 31065 NBER, V31065, DOI [10.3386/w31065, DOI 10.3386/W31065]; Buchanan B., 2022, The New Fire: War, Peace and Democracy in the Age of AI; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Castells M., 2009, COMMUNICATION POWER; Cho WKT, 2020, SCIENCE, V369, P1179, DOI 10.1126/science.abd1879; Chouldechova A, 2017, BIG DATA-US, V5, P153, DOI 10.1089/big.2016.0047; Chow S, 2018, NAT REV CHEM, V2, P174, DOI 10.1038/s41570-018-0025-7; Christian B., 2020, The Alignment Problem: Machine Learning and Human Values; Cohen JE., 2019, Between Truth and Power, DOI DOI 10.1093/OSO/9780190246693.001.0001; CONVERSE PE, 1964, IDEOLOGY DISCONTENT; Creemers Rogier, 2018, CHINAS SOCIAL CREDIT; Criddle C., 2023, FINANC TIMES; Diakopoulos N., 2019, Automating the news, DOI DOI 10.4159/9780674239302; Diamandis P. H., 2020, The Future is Faster Than You Think: How Converging Technologies are Transforming Business, Industries, and Our Lives; Ding J., 2020, AI POWERED STATE CHI; Douek E, 2021, COLUMBIA LAW REV, V121, P759; Eisenstein Elizabeth, 1979, PRINTING PRESS AGENT, DOI [10.1017/CBO9781107049963, DOI 10.1017/CBO9781107049963]; Engstrom DF, 2023, ANNU REV LAW SOC SCI, V19, P277, DOI 10.1146/annurev-lawsocsci-120522-091626; Espinoza Javier, 2023, Financial Times; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; Farrell Henry., 2019, PRIVACY POWER TRANSA; Ferguson Andrew Guthrie, 2017, The rise of big data policing, DOI DOI 10.18574/NYU/9781479854608.001.0001; Filgueiras F, 2022, J INF TECHNOL POLITI, V19, P449, DOI 10.1080/19331681.2021.2016543; Flaxman S, 2016, PUBLIC OPIN QUART, V80, P298, DOI 10.1093/poq/nfw006; Frey Carl Benedikt, 2019, The Technology Trap: Capital, Labor, and Power in the Age of Automation; Gallego A, 2022, ANNU REV POLIT SCI, V25, P463, DOI 10.1146/annurev-polisci-051120-104535; Gellers J. C., 2023, Handbook on the politics and governance of big data and artificial intelligence, P430, DOI 10.4337/9781800887374.00027; Goldfarb A, 2021, INT SECURITY, V46, P7, DOI 10.1162/isec_a_00425; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Grimmer J, 2021, ANNU REV POLIT SCI, V24, P395, DOI 10.1146/annurev-polisci-053119-015921; Gutmann Amy., 2007, A Companion to Contemporary Political Philosophy, VSecond, P521; Hanson R., 2016, AGE WORK LOVE LIFE R, DOI [10.1093/oso/9780198754626.001.0001, DOI 10.1093/OSO/9780198754626.001.0001]; Healy K, 2017, SOCIOL THEOR, V35, P118, DOI 10.1177/0735275117709046; Hersh ED, 2015, HACKING THE ELECTORATE: HOW CAMPAIGNS PERCEIVE VOTERS, P1, DOI 10.1017/CBO9781316212783; Horton J. J., 2023, NBER WORKING PAPERS; Issenberg S., 2012, VICTORY LAB SECRET S; Jungherr A, 2020, RETOOLING POLITICS, P1, DOI 10.1017/9781108297820; Jungherr A., 2021, Digital transformations of the public arena, DOI [10.1017/9781009064484, DOI 10.1017/9781009064484]; Jungherr A, 2023, COMMUN THEOR, V33, P164, DOI 10.1093/ct/qtad006; Jungherr A, 2019, SOC MEDIA SOC, V5, DOI 10.1177/2056305119875439; Jurgens P., 2022, Computational Communication Research, V4, P5, DOI 10.5117/CCR2022.1.005.JURG; Kaufmann T., 2019, MITTE REFORMATION ST, DOI [10.1628/978-3-16-156606-6, DOI 10.1628/978-3-16-156606-6]; Kaye D., 2018, Report on artificial intelligence technologies and implications for freedom of expression and the information environment; Keane J, 2013, DEMOCRACY AND MEDIA DECADENCE, P1; Kim J, 2024, Arxiv, DOI arXiv:2305.09620; King RD, 2009, SCIENCE, V324, P85, DOI 10.1126/science.1165620; Kitchens B, 2020, MIS QUART, V44, P1619, DOI 10.25300/MISQ/2020/16371; Kitchin R, 2014, BIG DATA SOC, V1, DOI 10.1177/2053951714528481; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Kuklinski J.S., 2000, Elements of reason: Cognition, choice, and the bounds of rationality, P153, DOI [10.1017/CBO9780511805813.008, DOI 10.1017/CBO9780511805813.008]; Kuran Timur., 1995, Private truth, public lies: The social consequences of preference falsification; Landemore, 2013, DEMOCRATIC REASON PO; Landemore H, 2012, COLLECTIVE WISDOM: PRINCIPLES AND MECHANISMS, P1, DOI 10.1017/CBO9780511846427; Landemore H., 2022, CAN AI BRING DELIBER; Larson Erik., 2021, The Myth of Artificial Intelligence: Why Computers Cant Think the Way We Do; Lazer D, 2014, SCIENCE, V343, P1203, DOI 10.1126/science.1248506; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee K.-F., 2021, AI 2041: Ten Visions for Our Future; Lee Kai -Fu, 2018, AI SUPERPOWERS CHINA; Liang F, 2018, POLICY INTERNET, V10, P415, DOI 10.1002/poi3.183; Lindblom CE., 1965, INTELLIGENCE DEMOCRA; Lindblom CharlesE., 2001, MARKET SYSTEM WHAT I; Lodge M., 2009, The Rationalizing Voter, P149, DOI DOI 10.1017/CBO9781139032490; Lupia A., 1998, The democratic dilemma: Can citizens learn what they need to know?; Mac Síthigh D, 2019, MOD LAW REV, V82, P1034, DOI 10.1111/1468-2230.12462; Matovski A., 2021, Popular dictatorships: Crises, mass opinion, and the rise of electoral authoritarianism, DOI [10.1017/9781009047500, DOI 10.1017/9781009047500]; Mayson SG, 2019, YALE LAW J, V128, P2218; McCorduck P., 2004, MACHINES WHO THINK P; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Mitchell M., 2019, ARTIFICIAL INTELLIGE; Mitchell S, 2021, ANNU REV STAT APPL, V8, P141, DOI 10.1146/annurev-statistics-042720-125902; Mökander J, 2022, AI SOC, V37, P1337, DOI 10.1007/s00146-021-01222-z; Muller Jan-Werner., 2021, Democracy Rules; Munk AK, 2022, BIG DATA SOC, V9, DOI 10.1177/20539517211069891; Narayanan A, 2023, INDIAN J HIST SCI, V58, P87, DOI 10.1007/s43539-023-00083-3; Neuman W.R., 1991, FUTURE MASS AUDIENCE; Nickerson DW, 2014, J ECON PERSPECT, V28, P51, DOI 10.1257/jep.28.2.51; Nielsen R.K., 2020, HDB JOURNALISM STUDI, P324, DOI DOI 10.4324/9781315167497-21; Nilsson NJ., 2010, QUEST ARTIFICIAL INT, DOI DOI 10.1017/CBO9780511819346; Ober J, 2008, DEMOCRACY AND KNOWLEDGE: INNOVATION AND LEARNING IN CLASSICAL ATHENS, P1; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Pan Jennifer., 2020, WELFARE AUTOCRATS SO; PAPACHARISSI Z., 2021, After Democracy: Imagining Our Political Future; Parmar N, 2018, PR MACH LEARN RES, V80; Pearl J, 2019, COMMUN ACM, V62, P54, DOI 10.1145/3241036; Phillips Anne., 2021, UNCONDITIONAL EQUALS; Popkin Samuel L., 1991, The reasoning voter: communication and persuasion in presidential campaigns, DOI DOI 10.7208/CHICAGO/9780226772875.001.0001; Prior M, 2007, CAMB STUD PUB OPIN, P1; Prior M., 2017, OXFORD HDB POLITICAL, P897, DOI [10.1093/oxfordhb/9780199793471.013.63, DOI 10.1093/OXFORDHB/9780199793471.013.63]; Prior M., 2018, HOOKED POLITICS CAPT; Przeworski A., 2018, Why Bother with Elections?; Przeworski Adam., 1991, Democracy and the Market. Political and Economic Reforms in Eastern Europe and Latin America, P10, DOI DOI 10.1017/CBO9781139172493; Ramesh Aditya, 2022, arXiv; Rettberg JW, 2022, BIG DATA SOC, V9, DOI 10.1177/20539517221131290; Risse M., 2023, Political Theory and the Digital Age, DOI [10.1017/9781009255189, DOI 10.1017/9781009255189]; Russell S., 2009, Artificial Intelligence: A Modern Approach, V3; Sanders N, 2021, Arxiv, DOI arXiv:2110.09231; Scharkow M, 2020, P NATL ACAD SCI USA, V117, P2761, DOI 10.1073/pnas.1918279117; Schlozman KayLehman., 2018, UNEQUAL UNREPRESENTE; Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232; Schölkopf B, 2021, P IEEE, V109, P612, DOI 10.1109/JPROC.2021.3058954; Schudson Michael., 1978, Discovering the News: A Social History of American Newspapers; Schwartzberg M, 2015, ANNU REV POLIT SCI, V18, P187, DOI 10.1146/annurev-polisci-110113-121908; Settle J. E., 2018, ) frenemies: how social media polarizes America, DOI [https://doi.org/10.1017/9781108560573, DOI 10.1017/9781108560573]; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Smith BC, 2019, PROMISE OF ARTIFICIAL INTELLIGENCE: RECKONING AND JUDGMENT, P1; Stasavage D, 2020, PRINC ECON HIST W WO, P1; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Thelen K, 2018, PERSPECT POLIT, V16, P938, DOI 10.1017/S1537592718001081; Tilly C, 2007, DEMOCRACY, P1; Vaswani A, 2017, ADV NEUR IN, V30; Veale M, 2023, ANNU REV LAW SOC SCI, V19, P255, DOI 10.1146/annurev-lawsocsci-020223-040749; WHO, 2010, WORLD MALARIA REPORT 2010, P1; Wilkinson A., 2023, Vox; Williams B., 2011, After Broadcast News: Media Regimes, Democracy, and the New Information Environment (Communication, Society and Politics), DOI DOI 10.1017/CBO9780511846366; WINNER L, 1980, DAEDALUS, V109, P121; Wintrobe R., 1998, The Political Economy of Dictatorship, DOI [10.1017/CBO9781139174916, DOI 10.1017/CBO9781139174916]; Young Iris Marion., 2002, Inclusion and Democracy, DOI DOI 10.1093/0198297556.001.0001; ZALLER John, 1992, The Nature and Origins of Mass Opinion; Zeng J., 2022, Artificial Intelligence with Chinese Characteristics: National Strategy, Security and Authoritarian Governance, DOI [10.1007/978-981-19-0722-7, DOI 10.1007/978-981-19-0722-7]	147	4	4	43	97	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	2056-3051			SOC MEDIA SOC	Soc. Med. Soc.	JUL	2023	9	3							20563051231186353	10.1177/20563051231186353	http://dx.doi.org/10.1177/20563051231186353			14	Communication	Social Science Citation Index (SSCI)	Communication	M3HH4		gold			2024-07-03	WOS:001029117600001
C	Liang, J; Huang, WL; Xia, F; Xu, P; Hausman, K; Ichter, B; Florence, P; Zeng, A			IEEE	Liang, Jacky; Huang, Wenlong; Xia, Fei; Xu, Peng; Hausman, Karol; Ichter, Brian; Florence, Pete; Zeng, Andy			Code as Policies: LanguageModel Programs for Embodied Control	2023 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2023)	IEEE International Conference on Robotics and Automation ICRA		English	Proceedings Paper	IEEE International Conference on Robotics and Automation (ICRA)	MAY 29-JUN 02, 2023	London, ENGLAND	IEEE, IEEE Robot & Automat Soc				Large language models (LLMs) trained on codecompletion have been shown to be capable of synthesizing simple Python programs fromdocstrings [1]. We find that these code-writing LLMs can be re-purposed to write robot policy code, given natural language commands. Specifically, policy code can express functions or feedback loops that process perception outputs (e.g., from object detectors [2], [3]) and parameterize control primitive APIs. When provided as input several example language commands (formatted as comments) followed by corresponding policy code (via few-shot prompting), LLMs can take in new commands and autonomously re-compose API calls to generate new policy code respectively. By chaining classic logic structures and referencing third-party libraries (e.g., NumPy, Shapely) to perform arithmetic, LLMs used in this way can write robot policies that (i) exhibit spatial-geometric reasoning, (ii) generalize to new instructions, and (iii) prescribe precise values (e.g., velocities) to ambiguous descriptions ("faster") depending on context (i.e., behavioral commonsense). This paper presents Code as Policies: a robot-centric formulation of language model generated programs (LMPs) that can represent reactive policies (e.g., impedance controllers), as well as waypoint-based policies (vision-based pick and place, trajectory-based control), demonstrated across multiple real robot platforms. Central to our approach is prompting hierarchical code-gen (recursively defining undefined functions), which can write more complex code and also improves state-of-the-art to solve 39.8% of problems on the HumanEval [1] benchmark. Code and videos are available at https://code-as-policies.github.	[Liang, Jacky; Huang, Wenlong; Xia, Fei; Xu, Peng; Hausman, Karol; Ichter, Brian; Florence, Pete; Zeng, Andy] Google, Robot, Mountain View, CA 94043 USA	Google Incorporated	Liang, J (corresponding author), Google, Robot, Mountain View, CA 94043 USA.							Ahn M., 2022, arXiv preprint arXiv:2204.01691; Akakzia A., 2020, ARXIV200607185; Andreas J., 2017, ARXIV171100482; [Anonymous], 2015, IJCAI; [Anonymous], 2006, AAAI; Artzi Y., 2013, TACL; Austin Jacob, 2021, ARXIV210807732; Bobu A., 2022, RA L; Breazeal C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1935; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bucker A., 2022, ARXIV220313411; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chowdhery A., 2022, ARXIV220402311; Cideron G., 2019, DEEPMIND; Cobbe K., 2021, ARXIV211014168; Drori I., 2022, PNAS; Dzifcak J., 2009, ICRA; Ellis K., 2020, ARXIV200608381; Florence P., 2022, CORL; Ganapathi A., 2022, ARXIV220301983; Goyal P., 2020, ARXIV200715543; Gu Xiuye, 2021, ARXIV210413921; Huang W., 2022, ARXIV220107207; Huang Wenlong, 2022, ARXIV220705608; Hupkes D., 2020, JAIR; Jang E., 2022, CORL; Jiang Yiding, 2019, NeurIPS; Kalashnikov D., 2018, QT OPT SCALABLE DEEP; Kamath A., 2021, ICCV; Kojima Takeshi, 2022, arXiv preprint arXiv:2205.11916; Kollar Thomas, 2010, HRI; Lewkowycz Aitor, 2022, ARXIV220614858; Liu W., 2022, ICRA; Luketina Jelena, 2019, IJCAI; Lynch C., 2020, ARXIV200507648; Matuszek C., 2013, Springer Tracts in Advanced Robotics, P403, DOI [10.1007/978-3-319-00065-7, DOI 10.1007/978-3-319-00065-7]; Mees O., 2020, ISER; Mees Oier., 2022, RA-L; Misra D., 2017, ARXIV170408795, DOI DOI 10.18653/V1/D17-1106; Nair Suraj, 2022, CORL; Ouyang Long, 2022, ARXIV220302155; Shah D., 2022, ARXIV220704429; Sharma P., 2022, ARXIV220405186; Shridhar M., 2021, P 5 C ROBOT LEARNING; Stepputtis S., 2020, NEURIPS; Tellex S., 2020, REV CONTROL ROBOTICS; Tellex S., 2011, AAAI, V25; Thomason J., 2020, JAIR; Tian L., 2020, NEURIPS; Trivedi D., 2021, NEURIPS; Wei Jason, 2022, arXiv:2201.11903; Winograd T., 1971, Procedures as a Representation for Data In a Computer Program For Understanding Natural Language; Wu Jeff, 2021, ARXIV210910862; Xu F. F., 2022, MAPS; Yuan W., 2022, CORL; Zakka Kevin, 2022, CORL; Zeng A., 2019, THESIS; Zeng Andy, 2022, ARXIV220400598; Zhang S., 2022, arXiv; Zhou Denny, 2022, arXiv:2205.10625	60	12	13	11	12	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1050-4729	2577-087X	979-8-3503-2365-8	IEEE INT CONF ROBOT			2023							9493	9500		10.1109/ICRA48891.2023.10160591	http://dx.doi.org/10.1109/ICRA48891.2023.10160591			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BV5HG		Green Submitted			2024-07-03	WOS:001048371102027
J	Nash, BL				Nash, Brady L.			Love and Learning in the Age of Algorithms: How Intimate Relationships with Artificial Intelligence May Shape Epistemology, Sociality, and Linguistic Justice	READING RESEARCH QUARTERLY			English	Article; Early Access							CRITICAL LITERACY	Generative artificial intelligence (GAI) programs such as ChatGPT and other large language models are designed to engage in complex, responsive dialogues that feel like human interactions. The dialogic and responsive nature of GAI signals the potential for users to form relationships with GAI platforms or digital personalities created on these platforms. Given the degree to which language use and broader conceptual understandings are deeply embedded in social relationships, the relational nature of GAI has powerful implications for the future of literacy and learning. This speculative essay draws upon sociocultural, affective, and posthuman perspectives on literacy to explore key concerns regarding the nature of intimate relationships with GAI. The author highlights three central concerns for literacy researchers and educators: epistemological issues stemming from intimate relationships with GAI, the potential for students to (re)conceptualize human relationships through GAI, and the role of relational GAI in linguistic justice. The emergence of artificial intelligence platforms that can convincingly engage in dialogue like a human being has already led many people to develop intimate relationships with their AI. There is even an emerging industry explicitly offering AI companionship via subscription-based access to AI personalities. This conceptual article explores the nature of relationships with AI platforms and considers the implications of these relationships for literacy education. Topics discussed within the article include how human-AI relationships may impact students' belief formation, conceptions of relationships, and linguistic justice.Note: image generated with DALL-E 3 via Microsoft CoPilot.image	[Nash, Brady L.] Miami Univ, Oxford, OH 45056 USA	University System of Ohio; Miami University	Nash, BL (corresponding author), Miami Univ, Oxford, OH 45056 USA.	bradylnash@gmail.com						[Anonymous], 1991, Situated learning: Legitimate peripheral participation; Anwaruddin SM, 2016, DISCOURSE-ABINGDON, V37, P381, DOI 10.1080/01596306.2015.1042429; Anzalda G., 2007, Borderlands/la Frontera: The new mestiza, V3rd ed.; Baker-Bell April., 2020, Linguistic Justice: Black Language, Literacy, Identity, and Pedagogy, DOI [10.4324/9781315147383, DOI 10.4324/9781315147383]; Beach C. L., 2023, Digital Culture Education, V14, P92; Benjamin R., 2022, Viral Justice: How We Grow the World We Want; Berger P.L., 2017, The social construction of reality: A treatise in the sociology of knowledge [CD]; BISHOP RS, 1990, CALIFORNIA STATE UNIVERSITY, SAN BERNARDINO READING CONFERENCE - 14TH ANNUAL CONFERENCE PROCEEDINGS, P3; Bogost Ian., 2009, DIGITAL ARTS CULTURE; Boler M, 2018, EMOT SPACE SOC, V27, P75, DOI 10.1016/j.emospa.2018.03.002; Celik I, 2022, TECHTRENDS, V66, P616, DOI 10.1007/s11528-022-00715-y; Challenger M., 2022, How to be an animal; Chokshi C. N., 2023, Doing things with words: The new consequences of writing in the age of AI; Clark N., 2023, Polygon; Coleman J. J., 2021, English Education, V53, P254, DOI [10.58680/ee202131482, DOI 10.58680/EE202131482]; Collins C., 2021, Learning for Justice; Cook-Gumperz J., 1986, SOCIAL CONSTRUCTION, P16; Curzan A., 2014, Fixing English: Prescriptivism and language history, P64, DOI [10.1017/CBO9781139107327.004, DOI 10.1017/CBO9781139107327.004]; Czaja SJ, 2022, J COGN ENG DECIS MAK, V16, P182, DOI 10.1177/15553434221129914; Davenport T.H., 2001, ATTENTION EC UNDERST; Dixon-Román E, 2020, LEARN MEDIA TECHNOL, V45, P236, DOI 10.1080/17439884.2020.1667825; Dutro E., 2019, Language Arts, V96, P384, DOI [10.58680/la201930172, DOI 10.58680/LA201930172]; Ehret C, 2014, RES TEACH ENGL, V48, P428; Faulkner D., 2013, Learning relationships in the classroom; Garcia A., 2021, Digital platforms aren't mere toolsThey're complex environments; Garcia-Rojas C, 2017, J LESBIAN STUD, V21, P254, DOI 10.1080/10894160.2016.1159072; Gee J.P., 1990, SOCIAL LINGUISTICS L; Gee J. P., 2022, Literacy Research: Theory, Method, and Practice, V71, P1, DOI [10.1177/23813377221100163, DOI 10.1177/23813377221100163]; Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068; Gonzales L., 2023, English Education, V55, P214, DOI [10.58680/ee202332555, DOI 10.58680/EE202332555]; Harris T., 2023, Synthetic humanity: AI what's at stake; Kerssens N, 2023, Routledge Res Digita, P9, DOI 10.4324/9781003373018-3; Klein Ezra., 2023, The New York Times; Leander K.M., 2019, AFFECT LITERACY LEAR; Leander KM, 2020, BRIT J EDUC TECHNOL, V51, P1262, DOI 10.1111/bjet.12924; LeBlanc R. J., 2023, Digital platforms and the ELA classroom; Liang C., 2023, The New York Times; Lorde A., 1984, SISTER OUTSIDER; Murphy R., 2019, RAND Corporation, P1; Nash B. L., 2023, English Education, V55, P201, DOI [10.58680/ee202332555, DOI 10.58680/EE202332555]; Nash BL, 2021, READ TEACH, V74, P713, DOI 10.1002/trtr.1980; Nichols TP., 2017, LANG ARTS, V94, P245; Noble SU, 2018, ALGORITHMS OF OPPRESSION, P1; Ohito EO, 2021, CURRICULUM INQ, V51, P135, DOI 10.1080/03626784.2020.1843966; Ohito EO, 2016, EQUITY EXCELL EDUC, V49, P454, DOI 10.1080/10665684.2016.1226104; Pariser, 2012, FILTER BUBBLE NEW PE, DOI DOI 10.5860/CHOICE.50-0926; Prez B., 1998, Sociocultural contexts of language and literacy; Robinson B., 2022, Postdigital Science and Education, V5, P1, DOI DOI 10.1007/S42438-022-00358-5; Robinson B, 2023, LEARN MEDIA TECHNOL, DOI 10.1080/17439884.2023.2234286; Selwyn N., 2021, Postdigital Science and Education, V5, P15, DOI DOI 10.1007/S42438-021-00263-3; SinghKurtz S., 2023, The Cut; Skerrett A, 2016, J ADOLESC ADULT LIT, V60, P115, DOI 10.1002/jaal.571; Street B. V., 1984, Literacy in theory and practice., p243pp; Turkle Sherry., 2015, Reclaiming Conversation: The Power of Talk in a Digital Age; Vygotsky L., 1978, Mind in society: The development of higher psychological processes, DOI [DOI 10.2307/J.CTVJF9VZ4, 10.2307/j.ctvjf9vz4]; Young J. C., 2023, Evaluation of the potential usage of ChatGPT for providing easier reading materials for ESL students, P155; Zembylas M., 2021, Oxford Research Encyclopedia of Education, DOI DOI 10.1093/ACREFORE/9780190264093.013.1272; Zhao X, 2023, RELC J, V54, P890, DOI 10.1177/00336882221094089	58	0	0	10	10	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0034-0553	1936-2722		READ RES QUART	Read. Res. Q.	2024 JUN 10	2024										10.1002/rrq.549	http://dx.doi.org/10.1002/rrq.549		JUN 2024	8	Education & Educational Research; Psychology, Educational	Social Science Citation Index (SSCI)	Education & Educational Research; Psychology	TP1E0		hybrid			2024-07-03	WOS:001242364100001
J	He, LL; Li, H; Zhang, R				He, Lianlian; Li, Hao; Zhang, Rui			A Semantic-Spatial Aware Data Conflation Approach for Place Knowledge Graphs	ISPRS INTERNATIONAL JOURNAL OF GEO-INFORMATION			English	Article						knowledge graph; place entity matching; location-based service; place data; conflation		Recent advances in knowledge graphs show great promise to link various data together to provide a semantic network. Place is an important part in the big picture of the knowledge graph since it serves as a powerful glue to link any data to its georeference. A key technical challenge in constructing knowledge graphs with location nodes as geographical references is the matching of place entities. Traditional methods typically rely on rule-based matching or machine-learning techniques to determine if two place names refer to the same location. However, these approaches are often limited in the feature selection of places for matching criteria, resulting in imbalanced consideration of spatial and semantic features. Deep feature-based methods such as deep learning methods show great promise for improved place data conflation. This paper introduces a Semantic-Spatial Aware Representation Learning Model (SSARLM) for Place Matching. SSARLM liberates the tedious manual feature extraction step inherent in traditional methods, enabling an end-to-end place entity matching pipeline. Furthermore, we introduce an embedding fusion module designed for the unified encoding of semantic and spatial information. In the experiment, we evaluate the approach to named places from Guangzhou and Shanghai cities in GeoNames, OpenStreetMap (OSM), and Baidu Map. The SSARLM is compared with several classical and commonly used binary classification machine learning models, and the state-of-the-art large language model, GPT-4. The results demonstrate the benefit of pre-trained models in data conflation of named places.	[He, Lianlian] Hubei Univ Educ, Sch Math & Stat, 129 Second Gaoxin Rd,East Lake Hi Tech Zone, Wuhan 430205, Peoples R China; [Li, Hao; Zhang, Rui] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430072, Peoples R China	Hubei University of Education; Wuhan University	He, LL (corresponding author), Hubei Univ Educ, Sch Math & Stat, 129 Second Gaoxin Rd,East Lake Hi Tech Zone, Wuhan 430205, Peoples R China.	helianlian@hue.edu.cn; leehomm@whu.edu.cn; rui.zhang@whu.edu.cn			Educational Commission of Hubei Province of China	Educational Commission of Hubei Province of China	No Statement Available	Allemang D, 2011, SEMANTIC WEB FOR THE WORKING ONTOLOGIST: EFFECTIVE MODELING IN RDFS AND OWL, 2ND EDITION, P1; Chang E.Y., 2023, P 10 INT C COMPUTATI; Chen JY, 2017, COMM COM INF SC, V784, P165, DOI 10.1007/978-981-10-7359-5_17; Chen Q, 2019, Arxiv, DOI arXiv:1902.10909; Cucchiarelli A., 1998, Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume, V1, P286; Du JX, 2022, INT J GEOGR INF SCI, V36, P873, DOI 10.1080/13658816.2021.2005795; geonames, The GeoNames Geographical Database; Gritta M, 2018, LANG RESOUR EVAL, V52, P603, DOI 10.1007/s10579-017-9385-8; Han B, 2014, J ARTIF INTELL RES, V49, P451, DOI 10.1613/jair.4200; Kalyan KS, 2023, Arxiv, DOI [arXiv:2310.12321, DOI 10.2139/SSRN.4593895]; Khodizadeh-Nahari M, 2021, APPL INTELL, V51, P6104, DOI 10.1007/s10489-020-01959-y; Kuhn W, 2014, LECT NOTES COMPUT SC, V8728, P173, DOI 10.1007/978-3-319-11593-1_12; lbsyun.baidu, Baidu LBS Cloud Service; Leidner J.L., 2011, SIGSPATIAL SPECIAL, V3, P5, DOI [DOI 10.1145/2047296.2047298, https://doi.org/10.1145/2047296.2047298, 10.1145/2047296.2047298]; Li H, 2024, GEO-SPAT INF SCI, V27, P384, DOI 10.1080/10095020.2023.2179428; Li L, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18020045; Liu Junwei, 2022, Geoinformatics and Data Analysis: Selected Proceedings of ICGDA 2022. Lecture Notes on Data Engineering and Communications Technologies (143), P133, DOI 10.1007/978-3-031-08017-3_12; Low R, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10110779; Ma XG, 2022, COMPUT GEOSCI-UK, V161, DOI 10.1016/j.cageo.2022.105082; Mai GC, 2020, Arxiv, DOI arXiv:2003.00824; Mai GC, 2020, T GIS, V24, P623, DOI 10.1111/tgis.12629; Manville C., 2014, Mapping Smart Cities in the EU, DOI [10.2861/3408, DOI 10.2861/3408]; McKenzie G., 2013, P 21 ACM SIGSPATIAL, P440; Melo F, 2017, T GIS, V21, P3, DOI 10.1111/tgis.12212; Novack T, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7030117; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Ruiz JJ, 2011, INT J GEOGR INF SCI, V25, P1439, DOI 10.1080/13658816.2010.519707; Saalfeld A., 1988, International Journal of Geographical Information Systems, V2, P217, DOI 10.1080/02693798808927897; Santos R, 2018, INT J GEOGR INF SCI, V32, P324, DOI 10.1080/13658816.2017.1390119; Sun K, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8020077; Thakuriah P, 2017, SPRING GEOGR, P1, DOI 10.1007/978-3-319-40902-3_1; Thapa S., 2023, P WORKSHOP P 17 INT; w3, Points of Interest Core; wiki.OSM, Map Features; Zhang W., 2019, Cartogr. Geogr. Inf. Sci, V46, P229; Zhao L, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020199; Zhou CR, 2020, J ADV COMPUT INTELL, V24, P837, DOI 10.20965/jaciii.2020.p0837; Zhou Y, 2021, T GIS, V25, P359, DOI 10.1111/tgis.12690	38	1	1	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2220-9964		ISPRS INT J GEO-INF	ISPRS Int. J. Geo-Inf.	APR	2024	13	4							106	10.3390/ijgi13040106	http://dx.doi.org/10.3390/ijgi13040106			20	Computer Science, Information Systems; Geography, Physical; Remote Sensing	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Physical Geography; Remote Sensing	OX3C5		gold			2024-07-03	WOS:001210527700001
C	Sahu, SP; Mandal, M; Bharadwaj, S; Kanade, A; Maniatis, P; Shevade, S		Chakrabarti, SK; Rastogi, A; Ghosh, S; Komondoor, R; Medicherla, RK; Kumar, L; Godboley, S		Sahu, Surya Prakash; Mandal, Madhurima; Bharadwaj, Shikhar; Kanade, Aditya; Maniatis, Petros; Shevade, Shirish			CodeQueries: A Dataset of Semantic Queries over Code	PROCEEDINGS OF THE 17TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, ISEC 2024			English	Proceedings Paper	17th Innovations in Software Engineering Conference (ISEC)	FEB 22-24, 2024	IIITB Bangalore, Bangalore, INDIA	ACM India SIGSOFT Chapter, ACM In Cooperat, IIITB Bangalore, Ctr Technol Res & Innovat Digital Governance, TCS Res, Microsoft, IBM, ABB, Google, ISoft, ACM Chapter Conference	IIITB Bangalore	Code understanding; developer productivity; neural modeling; extractive question-answering		Developers often have questions about semantic aspects of code they are working on, e.g., "Is there a class whose parent classes declare a conflicting attribute?". Answering them requires understanding code semantics such as attributes and inheritance relation of classes. An answer to such a question should identify code spans constituting the answer (e.g., the declaration of the subclass) as well as supporting facts (e.g., the definitions of the conflicting attributes). The existing work on question-answering over code has considered yes/no questions or method-level context. We contribute a labeled dataset, called CodeQueries, of semantic queries over Python code. Compared to the existing datasets, in CodeQueries, the queries are about code semantics, the context is file level and the answers are code spans. We curate the dataset based on queries supported by a widely-used static analysis tool, CodeQL, and include both positive and negative examples, and queries requiring single-hop and multi-hop reasoning. To assess the value of our dataset, we evaluate baseline neural approaches. We study a large language model (GPT3.5-Turbo) in zero-shot and few-shot settings on a subset of CodeQueries. We also evaluate a BERT style model (CuBERT) with fine-tuning. We find that these models achieve limited success on CodeQueries. CodeQueries is thus a challenging dataset to test the ability of neural models, to understand code semantics, in the extractive question-answering setting.	[Sahu, Surya Prakash; Mandal, Madhurima; Bharadwaj, Shikhar; Shevade, Shirish] Indian Inst Sci, Bangalore, Karnataka, India; [Kanade, Aditya] Microsoft Res, Bengaluru, India; [Maniatis, Petros] Google DeepMind, Mountain View, CA USA; [Sahu, Surya Prakash] Observe, Bengaluru, India; [Mandal, Madhurima] Myntra, Kolkata, India; [Bharadwaj, Shikhar] Google Res, Bengaluru, India	Indian Institute of Science (IISC) - Bangalore	Sahu, SP (corresponding author), Indian Inst Sci, Bangalore, Karnataka, India.; Sahu, SP (corresponding author), Observe, Bengaluru, India.	suryaprakash@iisc.ac.in; madhurimam@iisc.ac.in; shikharb@alum.iisc.ac.in; kanadeaditya@microsoft.com; maniatis@google.com; shirish@iisc.ac.in		Sahu, Surya Prakash/0009-0003-9943-5222; Kanade, Aditya/0000-0001-8701-6977				Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2022, Query Suite; [Anonymous], 2018, Advances in Neural Information Processing Systems; Avgustinov Pavel, 2016, 30 EUR C OBJ OR PROG; Bansal A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2021), P60, DOI 10.1109/SANER50967.2021.00015; Bastani O, 2018, ACM SIGPLAN NOTICES, V53, P678, DOI [10.1145/3192366.3192383, 10.1145/3296979.3192383]; Bielik P, 2017, LECT NOTES COMPUT SC, V10426, P233, DOI 10.1007/978-3-319-63387-9_12; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cambronero J, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P964, DOI 10.1145/3338906.3340458; Chen M., 2021, arXiv; Chibotaru V, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P760, DOI 10.1145/3314221.3314648; Clark C, 2017, Arxiv, DOI arXiv:1710.10723; Cummins C, 2021, PR MACH LEARN RES, V139; David Y, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428293; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Gu WC, 2021, NEURAL NETWORKS, V141, P385, DOI 10.1016/j.neunet.2021.04.019; Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P933, DOI 10.1145/3180155.3180167; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hellendoorn VJ, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P152, DOI 10.1145/3236024.3236051; Heyman G, 2020, Arxiv, DOI arXiv:2008.12193; Huang Junjie, 2021, P 59 ANN M ASS COMP; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jin C, 2023, Arxiv, DOI [arXiv:2305.11169, 10.48550/arxiv.org/abs/2305.11169, DOI 10.48550/ARXIV.ORG/ABS/2305.11169]; Kanade Aditya, 2020, P LEARN PMLR 37 INT; Lee C, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2026; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Liu Chenxiao, 2021, Findings of the Association for Computational Linguistics: EMNLP; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Mir AM, 2022, Arxiv, DOI arXiv:2101.04470; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pashakhanloo Pardis, 2021, INT C LEARN REPR; Pashakhanloo Pardis, 2022, DEEP LEARN COD WORKS; Peng Y, 2022, PROC INT CONF SOFTW, P2019, DOI 10.1145/3510003.3510038; Pradel M, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P209, DOI 10.1145/3368089.3409715; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Rajpurkar P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P784; Ramshaw Lance, 1995, 3 WORKSH VER LARG CO; Raychev V, 2016, ACM SIGPLAN NOTICES, V51, P731, DOI 10.1145/3022671.2984041; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Sutton Charles, 2023, P INT C MACH LEARN; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Pandi IV, 2021, Arxiv, DOI arXiv:2004.00348; Wei Jiayi, 2020, 8 INT C LEARNING REP; Weissenborn Dirk, 2017, P 21 C COMP NAT LANG; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Yao ZY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1693, DOI 10.1145/3178876.3186081	49	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1767-3				2024									7	10.1145/3641399.3641408	http://dx.doi.org/10.1145/3641399.3641408			11	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6ID		hybrid, Green Submitted			2024-07-03	WOS:001174625700007
J	Zheltukhina, MR; Sergeeva, OV; Masalimova, AR; Budkevich, RL; Kosarenko, NN; Nesterov, GV				Zheltukhina, Marina R.; Sergeeva, Olga V.; Masalimova, Alfiya R.; Budkevich, Roza L.; Kosarenko, Nikolay N.; Nesterov, Georgy V.			A bibliometric analysis of publications on ChatGPT in education: Research patterns and topics	ONLINE JOURNAL OF COMMUNICATION AND MEDIA TECHNOLOGIES			English	Review						artificial intelligence; ChatGPT; bibliometric; ethics	ARTIFICIAL-INTELLIGENCE	This paper aims to conduct a bibliometric analysis and a comprehensive overview of publications on ChatGPT in educational research. This research also aimed to present the bibliometric results to interpret the research patterns and themes of the application of ChatGPT in educational research. The researchers used the VOSviewer program to conduct a bibliometric analysis and identify research patterns and topics in publications indexed in the Scopus database. For this purpose, the researchers used the Scopus database to find related publications. After applying inclusion and exclusion criteria, they found 82 publications and analyzed them using the bibliometric method. This study showed that researchers from 42 countries examined various topics, including academic writing, artificial intelligence's (AI) potential, and benefits, using ChatGPT in research, exploring best practices, and reviewing AI. The keyword analysis results showed that five clusters emerged from the current studies on ChatGPT in education research. These results showed that researchers focused on understanding the use of ChatGPT in medical and nursing education, generative AI's ethical dimensions, the effects of ChatGPT on educational outcomes, large language models and medical education, and ChatGPT and AI. In general, the use of ChatGPT in educational contexts and research is frequently discussed in the publications analyzed in this study. In addition, medical and nursing education was the most studied of the many research studies. Based on the obtained results, recommendations for further studies are drawn.	[Zheltukhina, Marina R.] Pyatigorsk State Univ, Pyatigorsk, Russia; [Sergeeva, Olga V.] Kuban State Univ, Krasnodar, Russia; [Masalimova, Alfiya R.] Kazan Fed Univ, Kazan, Russia; [Budkevich, Roza L.] Almetyevsk State Oil Inst, Almetyevsk, Russia; [Kosarenko, Nikolay N.] Plekhanov Russian Univ Econ, Moscow, Russia; [Nesterov, Georgy V.] IM Sechenov First Moscow State Med Univ, IM Sechenov Moscow State Med Univ 1, Moscow, Russia	Pyatigorsk State University; Kuban State University; Kazan Federal University; Plekhanov Russian University of Economics; Sechenov First Moscow State Medical University	Masalimova, AR (corresponding author), Kazan Fed Univ, Kazan, Russia.	alfkazan@mail.ru	Masalimova, Alfiya/K-3840-2015; Zheltukhina, Marina/A-7301-2015	Masalimova, Alfiya/0000-0003-3711-2527; Zheltukhina, Marina/0000-0001-7680-4003				Alneyadi S., 2023, EURASIA Journal of Mathematics, Science and Technology Education, V19, pm2248, DOI [10.29333/ejmste/13067, DOI 10.29333/EJMSTE/13067]; Alneyadi S, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13417; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bauer E, 2023, BRIT J EDUC TECHNOL, DOI 10.1111/bjet.13336; Bearman M, 2023, BRIT J EDUC TECHNOL, DOI 10.1111/bjet.13337; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chaudhry IS, 2023, COGENT EDUC, V10, DOI 10.1080/2331186X.2023.2210461; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Dawson P, 2020, ASSESS EVAL HIGH EDU, V45, P473, DOI 10.1080/02602938.2019.1662884; Dawson P, 2018, ASSESS EVAL HIGH EDU, V43, P286, DOI 10.1080/02602938.2017.1336746; Day T, 2023, PROF GEOGR, V75, P1024, DOI 10.1080/00330124.2023.2190373; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Emenike ME, 2023, J CHEM EDUC, V100, P1413, DOI 10.1021/acs.jchemed.3c00063; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fernandez Peter, 2023, Library Hi Tech News, P11, DOI 10.1108/LHTN-02-2023-0017; Ferrucci D, 2013, ARTIF INTELL, V199, P93, DOI 10.1016/j.artint.2012.06.009; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frederick Donna Ellen, 2023, Library Hi Tech News, P4, DOI 10.1108/LHTN-04-2023-0063; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gardner DE, 2023, J CHEM EDUC, V100, P1705, DOI 10.1021/acs.jchemed.3c00011; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; González-Pérez LI, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14031493; Halaweh M, 2023, CONTEMP EDUC TECHNOL, V15, DOI 10.30935/cedtech/13036; Hamzaçebi C, 2009, EXPERT SYST APPL, V36, P3839, DOI 10.1016/j.eswa.2008.02.042; Hassabis D, 2017, NATURE, V544, P413, DOI 10.1038/544413a; Humphry T, 2023, J CHEM EDUC, V100, P1434, DOI 10.1021/acs.jchemed.3c00006; Ivanov S, 2021, J TOUR FUTURES, V9, P214, DOI 10.1108/JTF-02-2023-0038; Jarrah AM, 2023, ONLINE J COMMUN MEDI, V13, DOI 10.30935/ojcmt/13572; Jeon J, 2023, EDUC INF TECHNOL, V28, P15873, DOI 10.1007/s10639-023-11834-1; Karaali Gizem, 2023, Numeracy, V16, DOI [10.5038/1936-4660.16.1.1438, DOI 10.5038/1936-4660.16.1.1438]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kooli C, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15075614; Lim WM, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100790; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Masters K, 2023, MED TEACH, V45, P673, DOI 10.1080/0142159X.2023.2208731; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; McCarthy J, 2006, AI MAG, V27, P12; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; OpenAi, 2022, Chatgpt; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Skavronskaya L, 2023, J TEACH TRAVEL TOUR, V23, P253, DOI 10.1080/15313220.2023.2196658; Sok S., 2023, Chatgpt for education and research: A review of benefits and risks, DOI [10.2139/ssrn.4378735, DOI 10.2139/SSRN.4378735]; Strzelecki A, 2023, INTERACT LEARN ENVIR, DOI 10.1080/10494820.2023.2209881; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Sun GH, 2023, NURS EDUC, V48, P119, DOI 10.1097/NNE.0000000000001390; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Uddin SMJ, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097121; Van Eck N.J., 2020, VOSVIEWER MANUAL; Wardat Y., 2023, Eurasia Journal of Mathematics, Science and Technology Education, V19, DOI DOI 10.29333/EJMSTE/13272; Wu R, 2024, BRIT J EDUC TECHNOL, V55, DOI 10.1111/bjet.13334; Yan D, 2023, EDUC INF TECHNOL, V28, P13943, DOI 10.1007/s10639-023-11742-4; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0	62	2	2	59	59	Bastas Publications DOO	Podgorica	Balsica 47, Podgorica, MONTENEGRO	1986-3497			ONLINE J COMMUN MEDI	Online J. Commun. Media Technol.	JAN	2024	14	1							e202405	10.30935/ojcmt/14103	http://dx.doi.org/10.30935/ojcmt/14103			16	Communication	Emerging Sources Citation Index (ESCI)	Communication	FA9O2		gold			2024-07-03	WOS:001143143100002
J	Lim, B; Seth, I; Cuomo, R; Kenney, PS; Ross, RJ; Sofiadellis, F; Pentangelo, P; Ceccaroni, A; Alfano, C; Rozen, WM				Lim, Bryan; Seth, Ishith; Cuomo, Roberto; Kenney, Peter Sinkjaer; Ross, Richard J.; Sofiadellis, Foti; Pentangelo, Paola; Ceccaroni, Alessandra; Alfano, Carmine; Rozen, Warren Matthew			Can AI Answer My Questions? Utilizing Artificial Intelligence in the Perioperative Assessment for Abdominoplasty Patients	AESTHETIC PLASTIC SURGERY			English	Article; Early Access						AI; Abdominoplasty; Perioperative; LLM; ChatGPT	SELF-ESTEEM; BODY-IMAGE	Background Abdominoplasty is a common operation, used for a range of cosmetic and functional issues, often in the context of divarication of recti, significant weight loss, and after pregnancy. Despite this, patient-surgeon communication gaps can hinder informed decision-making. The integration of large language models (LLMs) in healthcare offers potential for enhancing patient information. This study evaluated the feasibility of using LLMs for answering perioperative queries.Methods This study assessed the efficacy of four leading LLMs-OpenAI's ChatGPT-3.5, Anthropic's Claude, Google's Gemini, and Bing's CoPilot-using fifteen unique prompts. All outputs were evaluated using the Flesch-Kincaid, Flesch Reading Ease score, and Coleman-Liau index for readability assessment. The DISCERN score and a Likert scale were utilized to evaluate quality. Scores were assigned by two plastic surgical residents and then reviewed and discussed until a consensus was reached by five plastic surgeon specialists.Results ChatGPT-3.5 required the highest level for comprehension, followed by Gemini, Claude, then CoPilot. Claude provided the most appropriate and actionable advice. In terms of patient-friendliness, CoPilot outperformed the rest, enhancing engagement and information comprehensiveness. ChatGPT-3.5 and Gemini offered adequate, though unremarkable, advice, employing more professional language. CoPilot uniquely included visual aids and was the only model to use hyperlinks, although they were not very helpful and acceptable, and it faced limitations in responding to certain queries.Conclusion ChatGPT-3.5, Gemini, Claude, and Bing's CoPilot showcased differences in readability and reliability. LLMs offer unique advantages for patient care but require careful selection. Future research should integrate LLM strengths and address weaknesses for optimal patient education.Level of Evidence V This journal requires that authors assign a level of evidence to each article. For a full description of these Evidence-Based Medicine ratings, please refer to the Table of Contents or the online Instructions to Authors www.springer.com/00266.	[Lim, Bryan; Seth, Ishith; Ross, Richard J.; Sofiadellis, Foti; Rozen, Warren Matthew] Peninsula Hlth, Dept Plast Surg, Melbourne, Vic 3199, Australia; [Cuomo, Roberto] Univ Siena, Dept Med Surg & Neurosci, Plast Surg Unit, Siena, Italy; [Kenney, Peter Sinkjaer] Velje Hosp, Dept Plast Surg, Beriderbakken 4, DK-7100 Vejle, Denmark; [Kenney, Peter Sinkjaer] Aarhus Univ Hosp, Dept Plast & Breast Surg, Aarhus, Denmark; [Pentangelo, Paola; Ceccaroni, Alessandra; Alfano, Carmine] Univ Salerno, Fisciano, Italy	Peninsula Health; University of Siena; University of Southern Denmark; Lillebaelt Hospital; Aarhus University; University of Salerno	Cuomo, R (corresponding author), Univ Siena, Dept Med Surg & Neurosci, Plast Surg Unit, Siena, Italy.	roberto.cuomo@unisi.it		Cuomo, Roberto/0000-0002-8396-095X	Universit degli Studi di Siena	Universit degli Studi di Siena	No Statement Available	Aljindan FK, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005305; Atkinson CJ, 2024, J CLIN MED, V13, DOI 10.3390/jcm13030900; de Brito MJA, 2010, ANN PLAS SURG, V65, P5, DOI 10.1097/SAP.0b013e3181bc30f7; Barton N, 2020, PRS-GLOB OPEN, V8, DOI 10.1097/GOX.0000000000002856; Brandi Cesare, 2018, Acta Biomed, V89, P400, DOI 10.23750/abm.v89i3.6162; Bulloch G, 2023, ANZ J SURG, V93, P2270, DOI 10.1111/ans.18544; Bustos VP, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000004803; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Cuomo R, 2019, OBES SURG, V29, P3937, DOI 10.1007/s11695-019-04081-2; Cuomo R, 2015, IN VIVO, V29, P757; D'Antonio A, 2011, INT J HEMATOL, V93, P795, DOI 10.1007/s12185-011-0849-0; Da Silva M, 2022, SYST REV-LONDON, V11, DOI 10.1186/s13643-022-01939-y; Feng SW, 2023, ACAD MED, V98, P867, DOI 10.1097/ACM.0000000000005242; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Gisladottir U, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/29118; Grimaldi L, 2015, IN VIVO, V29, P145; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Harrison CJ, 2021, BMC MED RES METHODOL, V21, DOI 10.1186/s12874-021-01347-1; Inojosa H, 2023, NEUROL RES PRACT, V5, DOI 10.1186/s42466-023-00270-8; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kuroiwa T, 2023, J MED INTERNET RES, V25, DOI 10.2196/47621; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li WB, 2024, AESTHET PLAST SURG, V48, P1571, DOI 10.1007/s00266-023-03660-0; Lim B, 2023, J CLIN MED, V12, DOI 10.3390/jcm12206524; Losco L, 2022, J INVEST SURG, V35, P620, DOI 10.1080/08941939.2021.1912220; Matarasso A, 1997, Aesthet Surg J, V17, P258, DOI 10.1016/S1090-820X(97)80008-8; Mu Xin, 2024, Skin Health Dis, V4, pe313, DOI 10.1002/ski2.313; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Naik N, 2022, FRONT SURG, V9, DOI 10.3389/fsurg.2022.862322; Nisi G, 2016, J COSMET DERMATOL-US, V15, P169, DOI 10.1111/jocd.12213; Oleck NC, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005290; Oranges CM, 2016, AESTHET SURG J, V36, pNP256, DOI 10.1093/asj/sjw066; Papadopulos NA, 2019, J PLAST RECONSTR AES, V72, P813, DOI 10.1016/j.bjps.2018.12.020; Papadopulos NA, 2012, PLAST RECONSTR SURG, V129, P957, DOI 10.1097/PRS.0b013e31824ecc2b; Ramirez AE, 2021, ANN PLAS SURG, V86, pS229, DOI 10.1097/SAP.0000000000002639; Raper Steven E, 2020, MedEdPORTAL, V16, P10985, DOI 10.15766/mep_2374-8265.10985; Regan JP, 2024, STATPEARLS; Roy M, 2019, WORLD J SURG, V43, P96, DOI 10.1007/s00268-018-4754-z; Sadeghi P, 2022, J CLIN MED, V11, DOI 10.3390/jcm11154315; Seth I, 2024, JPRAS OPEN, V39, P291, DOI 10.1016/j.jpra.2024.01.006; Seth I, 2024, EUR J PLAST SURG, V47, DOI 10.1007/s00238-024-02162-9; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Seth I, 2023, ANN SURG ONCOL, DOI 10.1245/s10434-023-13642-w; Sharma SC, 2023, INDIAN J PLAST SURG, V56, P320, DOI 10.1055/s-0043-1771514; Sisti A, 2021, AESTHET PLAST SURG, V45, P1078, DOI 10.1007/s00266-020-01989-4; Taylor DA, 2018, PLAST RECONSTR SURG, V141, P637, DOI 10.1097/PRS.0000000000004100; Tiourin E, 2022, PRS-GLOB OPEN, V10, DOI 10.1097/GOX.0000000000004247; Ueda D, 2024, JPN J RADIOL, V42, P3, DOI 10.1007/s11604-023-01474-3; Verdicchio Mario, 2022, Philos Technol, V35, P11, DOI 10.1007/s13347-022-00506-6; Vidal P, 2017, ARCH PLAST SURG-APS, V44, P457, DOI 10.5999/aps.2017.44.5.457; Vine M., 2024, AME Surg J, DOI [10.21037/asj-23-41, DOI 10.21037/ASJ-23-41]; Voglino C, 2021, OBES SURG, V31, P3715, DOI 10.1007/s11695-021-05486-8; Voglino C, 2020, J GASTROINTEST SURG, V24, P2722, DOI 10.1007/s11605-019-04482-9; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Zerini I, 2016, PRS-GLOB OPEN, V4, DOI 10.1097/GOX.0000000000000636	55	0	0	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0364-216X	1432-5241		AESTHET PLAST SURG	Aesthet. Plast. Surg.	2024 JUN 19	2024										10.1007/s00266-024-04157-0	http://dx.doi.org/10.1007/s00266-024-04157-0		JUN 2024	13	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	UV8V0	38898239	hybrid			2024-07-03	WOS:001250938200005
J	Badini, S; Regondi, S; Frontoni, E; Pugliese, R				Badini, Silvia; Regondi, Stefano; Frontoni, Emanuele; Pugliese, Raffaele			Assessing the capabilities of ChatGPT to improve additive manufacturing troubleshooting	ADVANCED INDUSTRIAL AND ENGINEERING POLYMER RESEARCH			English	Article						Additive manufacturing; 3D printing; ChatGPT; Gcode; Optimization; Machine learning; Efficiency; Accuracy; Process control; Material savings; Time savings		This paper explores the potential of using Chat Generative Pre-trained Transformer (ChatGPT), a Large Language Model (LLM) developed by OpenAI, to address the main challenges and improve the efficiency of the Gcode generation process in Additive Manufacturing (AM), also known as 3D printing. The Gcode generation process, which controls the movements of the printer's extruder and the layer-by-layer build process, is a crucial step in the AM process and optimizing the Gcode is essential for ensuring the quality of the final product and reducing print time and waste. ChatGPT can be trained on existing Gcode data to generate optimized Gcode for specific polymeric materials, printers, and objects, as well as analyze and optimize the Gcode based on various printing parameters such as printing temperature, printing speed, bed temperature, fan speed, wipe distance, extrusion multiplier, layer thickness, and material flow. Here the capability of ChatGPT in performing complex tasks related to AM process optimization was demonstrated. In particular performance tests were conducted to evaluate ChatGPT's expertise in technical matters, focusing on the evaluation of printing parameters and bed detachment, warping, and stringing issues for Fused Filament Fabrication (FFF) methods using thermoplastic polyurethane polymer as feedstock material. This work provides effective feedback on the performance of ChatGPT and assesses its potential for use in the AM field. The use of ChatGPT for AM process optimization has the potential to revolutionize the industry by offering a user-friendly interface and utilizing machine learning algorithms to improve the efficiency and accuracy of the Gcode generation process and optimal printing parameters. Furthermore, the real-time optimization capabilities of ChatGPT can lead to significant time and material savings, making AM a more accessible and cost-effective solution for manufacturers and industry.(c) 2023 Kingfa Scientific and Technological Co. Ltd. Publishing services by Elsevier B.V. on behalf of KeAi Communications Co. Ltd. This is an open access article under the CC BY license (http://creativecommons. org/licenses/by/4.0/).	[Badini, Silvia; Regondi, Stefano; Frontoni, Emanuele; Pugliese, Raffaele] ASST GOM Niguarda Ca Granda Hosp, NeMO Lab, Milan, Italy; [Frontoni, Emanuele] Univ Macerata, SPOCRI Dept, VRAI Lab, Macerata, Italy	University of Macerata	Pugliese, R (corresponding author), ASST GOM Niguarda Ca Granda Hosp, NeMO Lab, Milan, Italy.	raffaele.pugliese@nemolab.it	; Pugliese, Raffaele/J-9111-2016	Badini, Silvia/0009-0005-0770-6254; Pugliese, Raffaele/0000-0001-7669-4457				Aciu RM, 2014, 2014 IEEE 9TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P43, DOI 10.1109/SACI.2014.6840096; [Anonymous], 2023, Nature, V2, P23; Antaki F, 2023, medRxiv; Arya Rao, 2023, medRxiv; Ashima R, 2021, MATER TODAY-PROC, V45, P5081, DOI 10.1016/j.matpr.2021.01.583; Biswas S.S., 2023, Ann. Biomed. Eng., V8, P17; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Culmone C, 2019, ADDIT MANUF, V27, P461, DOI 10.1016/j.addma.2019.03.015; Dilberoglu UM, 2017, PROCEDIA MANUF, V11, P545, DOI 10.1016/j.promfg.2017.07.148; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Fj R., 2018, Lancet, V391; Flaxman TE, 2021, 3D PRINT MED, V7, DOI 10.1186/s41205-021-00107-7; Floridi Luciano, 2021, GPT-3: its nature, scope, limits, and consequences; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Gao W, 2015, COMPUT AIDED DESIGN, V69, P65, DOI 10.1016/j.cad.2015.04.001; Guo Edward, 2023, medRxiv; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Guvendiren M, 2016, ACS BIOMATER SCI ENG, V2, P1679, DOI 10.1021/acsbiomaterials.6b00121; Guzzi EA, 2020, ADV MATER, V32, DOI 10.1002/adma.201901994; Haleem A, 2020, CLIN EPIDEMIOL GLOB, V8, DOI 10.1016/j.cegh.2019.08.002; Haleem A, 2019, J IND INTEGR MANAG, V4, DOI 10.1142/S2424862219300011; Haleem A, 2019, CLIN EPIDEMIOL GLOB, V7, P571, DOI 10.1016/j.cegh.2019.01.003; Holmes DW, 2022, ADDIT MANUF, V50, DOI 10.1016/j.addma.2021.102555; Javaid M, 2020, CLIN EPIDEMIOL GLOB, V8, P586, DOI 10.1016/j.cegh.2019.12.008; Javaid M, 2018, ALEX J MED, V54, P411, DOI 10.1016/j.ajme.2017.09.003; Javaid Mohd, 2019, J Oral Biol Craniofac Res, V9, P179, DOI 10.1016/j.jobcr.2019.04.004; Jiang JC, 2023, INT J COMPUT INTEG M, V36, P1258, DOI 10.1080/0951192X.2023.2177740; Jiang JC, 2022, J INTELL MANUF, V33, P1073, DOI 10.1007/s10845-020-01715-6; Jiang JC, 2018, J MANUF MATER PROC, V2, DOI 10.3390/jmmp2040064; Kechagias JD, 2023, MATER MANUF PROCESS, V38, P341, DOI 10.1080/10426914.2021.2001523; Khosravani MR, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-05005-4; Kung Tiffany H., 2023, medRxiv; Li X., 2022, INT WORKSHOP LANGUAG, V1; Ligon SC, 2017, CHEM REV, V117, P10212, DOI 10.1021/acs.chemrev.7b00074; Liu S., 2023, medRxiv; Lyu D, 2023, INT J COMPUT INTEG M, V36, P524, DOI 10.1080/0951192X.2022.2128211; Mariani M., 2022, Generative artificial intelligence and innovation: conceptual foundations; Mathur S, 2017, BIOMED REP, V7, P3, DOI 10.3892/br.2017.922; Mehrpouya M, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183865; Nasiri S, 2022, MATER TODAY COMMUN, V33, DOI 10.1016/j.mtcomm.2022.104437; Picard M, 2020, RSC ADV, V10, P36058, DOI 10.1039/d0ra04857g; Pugliese R, 2022, POLYMERS-BASEL, V14, DOI 10.3390/polym14142794; Pugliese Raffaele, 2021, Annals of 3D Printed Medicine, V2; Qu AB, 2023, INT J MECH SCI, V245, DOI 10.1016/j.ijmecsci.2023.108107; Rivet I, 2023, ADDIT MANUF, V61, DOI 10.1016/j.addma.2022.103348; Sala R, 2022, ADDIT MANUF, V58, DOI 10.1016/j.addma.2022.102976; Sala Riccardo, 2022, Eng. Times, V3; Salmi M, 2021, MATERIALS, V14, DOI 10.3390/ma14010191; Tamir TS, 2023, INT J COMPUT INTEG M, V36, P1362, DOI 10.1080/0951192X.2022.2145019; Xiao Jianhua, 2017, Progress in Additive Manufacturing, V2	50	24	24	18	18	KEAI PUBLISHING LTD	BEIJING	16 DONGHUANGCHENGGEN NORTH ST, Building 5, Room 411, BEIJING, DONGCHENG DISTRICT 100009, PEOPLES R CHINA	2542-5048			ADV IND ENG POLY RES	Adv. Ind. Eng. Polym. Res.	JUL	2023	6	3					278	287		10.1016/j.aiepr.2023.03.003	http://dx.doi.org/10.1016/j.aiepr.2023.03.003			10	Materials Science, Multidisciplinary; Materials Science, Composites; Polymer Science	Emerging Sources Citation Index (ESCI)	Materials Science; Polymer Science	DC7D3		gold			2024-07-03	WOS:001129889200001
J	Filter, M; Schüler, T; Ben Romdhane, R				Filter, Matthias; Schueler, Thomas; Ben Romdhane, Racem			Food Safety Knowledge Exchange (FSKX) format: Current status and strategic development plans based on a SWOT analysis	MICROBIAL RISK ANALYSIS			English	Article						FAIR data; Knowledge exchange; Data standards; Linked models		The Food Safety Knowledge Exchange (FSKX) format is a community-driven effort initially created to promote the efficient exchange of data and models in the food safety domain. Over the past years this effort was driven by the Risk Assessment Knowledge Integration Platform (RAKIP) Initiative that also provided a number of software tools and FSKX-compliant model files via their website https://foodrisklabs.bfr.bund.de/rakip-initiative/. This paper describes the results of a SWOT analysis that was conducted to identify strategic avenues for enhancing FSKX's usability and adoption. The SWOT analysis identified a number of recommendations for the future evolution of FSKX. First, it is recommended to reduce the complexity of the annotation schema to ease the adoption of the format. Second, a clear distinction between the descriptive part of FSKX and the executable part is proposed. To promote the broad usage of FSKX-compliant models, it is also recommended to develop and provide FSKX-compliant APIs and resources that facilitate cloud-based execution. As part of the research to prioritize future FSKX development options, we also considered the implications of the emerging generative AI technologies, particularly which impact large language models (LLMs) might have in supporting the adoption of FSKX by the research community. Recognizing the format's application potential beyond the food safety domain, we then proposed to re-brand the FSKX acronym as "FAIR Scientific Knowledge Exchange Format" which better reflects its broad applicability in various scientific domains. Our research findings suggest that with the implementation of the improvements identified by the SWOT analysis and the broader availability of generative AI technologies the broad adoption of FSKX as a method to share data and models in a FAIR way comes into reach.	[Filter, Matthias; Schueler, Thomas; Ben Romdhane, Racem] German Fed Inst Risk Assessment BfR, Dept Biol Safety 4, Berlin, Germany	Federal Institute for Risk Assessment	Filter, M (corresponding author), German Fed Inst Risk Assessment BfR, Dept Biol Safety 4, Berlin, Germany.	matthias.filter@bfr.bund.de			German Federal Ministry of Food and Agriculture (BMEL) [28KIDA004]	German Federal Ministry of Food and Agriculture (BMEL)	This research has been funded by the German Federal Ministry of Food and Agriculture (BMEL) in the research project "KI- & Daten- Akzelerator (KIDA)" with project number 28KIDA004.	Allende A, 2022, CURR OPIN FOOD SCI, V45, DOI 10.1016/j.cofs.2022.100839; Aparicio MD, 2018, MICROB RISK ANAL, V10, P13, DOI 10.1016/j.mran.2018.09.001; Barker M, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01710-x; Berthold MichaelR., 2007, STUDIES CLASSIFICATI; BfR, 2023, Food Safety Knowledge Exchange (FSKX) Format-FoodRisk-Labs WWW Document; BfR, 2023, RAKIP Initiative-FoodRisk-Labs; Cavalli E, 2019, EFSA J, V17, DOI 10.2903/j.efsa.2019.e170704; Clemente G.P., 2023, Review, DOI [10.21203/rs.3.rs-2684592/v1, DOI 10.21203/RS.3.RS-2684592/V1]; Filter M, 2021, FOOD RES INT, V139, DOI 10.1016/j.foodres.2020.109952; Messens W, 2018, MICROB RISK ANAL, V10, P37, DOI 10.1016/j.mran.2018.04.002; Nasr M, 2023, Arxiv, DOI [arXiv:2311.17035, 10.48550/ARXIV.2311.17035]; Nychas GJE, 2016, CURR OPIN FOOD SCI, V12, P13, DOI 10.1016/j.cofs.2016.06.005; OpenAI, 2023, GPT-4: generative Pre-trained Transformer 4 Model; Plaza-Rodríguez C, 2015, INT J FOOD MICROBIOL, V204, P81, DOI 10.1016/j.ijfoodmicro.2015.03.010; Plaza-Rodríguez C, 2018, CURR OPIN FOOD SCI, V19, P129, DOI 10.1016/j.cofs.2017.12.002; Possas A, 2022, CURR OPIN FOOD SCI, V44, DOI 10.1016/j.cofs.2022.100814; Puyt RW, 2023, LONG RANGE PLANN, V56, DOI 10.1016/j.lrp.2023.102304; Teixeira P, 2021, FRONT SUSTAIN FOOD S, V4, DOI 10.3389/fsufs.2020.630598; Tenenhaus-Aziza F, 2015, FOOD MICROBIOL, V45, P290, DOI 10.1016/j.fm.2014.06.026	19	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2352-3522	2352-3530		MICROB RISK ANAL	Microb. Risk Anal.	DEC	2024	27-28								100309	10.1016/j.mran.2024.100309	http://dx.doi.org/10.1016/j.mran.2024.100309			5	Environmental Sciences; Food Science & Technology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Food Science & Technology; Microbiology	UT7N7					2024-07-03	WOS:001250375900001
J	Williams, L; Anthi, E; Arman, L; Burnap, P				Williams, Lowri; Anthi, Eirini; Arman, Laura; Burnap, Pete			Topic Modelling: Going beyond Token Outputs	BIG DATA AND COGNITIVE COMPUTING			English	Article						topic modelling; keyword extraction; natural language processing; text mining; Latent Dirichlet Allocation		Topic modelling is a text mining technique for identifying salient themes from a number of documents. The output is commonly a set of topics consisting of isolated tokens that often co-occur in such documents. Manual effort is often associated with interpreting a topic's description from such tokens. However, from a human's perspective, such outputs may not adequately provide enough information to infer the meaning of the topics; thus, their interpretability is often inaccurately understood. Although several studies have attempted to automatically extend topic descriptions as a means of enhancing the interpretation of topic models, they rely on external language sources that may become unavailable, must be kept up to date to generate relevant results, and present privacy issues when training on or processing data. This paper presents a novel approach towards extending the output of traditional topic modelling methods beyond a list of isolated tokens. This approach removes the dependence on external sources by using the textual data themselves by extracting high-scoring keywords and mapping them to the topic model's token outputs. To compare how the proposed method benchmarks against the state of the art, a comparative analysis against results produced by Large Language Models (LLMs) is presented. Such results report that the proposed method resonates with the thematic coverage found in LLMs and often surpasses such models by bridging the gap between broad thematic elements and granular details. In addition, to demonstrate and reinforce the generalisation of the proposed method, the approach was further evaluated using two other topic modelling methods as the underlying models and when using a heterogeneous unseen dataset. To measure the interpretability of the proposed outputs against those of the traditional topic modelling approach, independent annotators manually scored each output based on their quality and usefulness as well as the efficiency of the annotation task. The proposed approach demonstrated higher quality and usefulness, as well as higher efficiency in the annotation task, in comparison to the outputs of a traditional topic modelling method, demonstrating an increase in their interpretability.	[Williams, Lowri; Anthi, Eirini; Burnap, Pete] Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 4AG, Wales; [Arman, Laura] Cardiff Univ, Sch Social Sci, Cardiff CF10 3NN, Wales	Cardiff University; Cardiff University	Williams, L (corresponding author), Cardiff Univ, Sch Comp Sci & Informat, Cardiff CF24 4AG, Wales.	williamsl10@cardiff.ac.uk; anthies@cardiff.ac.uk; armanl@cardiff.ac.uk		Williams, Lowri/0000-0002-3794-6145; Anthi, Eirini/0000-0002-5274-0727	Economic and Social Research Council (ESRC), grant 'Discribe-Digital Security by Design (DSbD) Programme'	Economic and Social Research Council (ESRC), grant 'Discribe-Digital Security by Design (DSbD) Programme'	The authors are grateful to Will Webberly and John Barker, our industry collaborators, from SimplyDo Ideas, Cardiff, for providing initial data to facilitate the experiments herein as well as providing informal feedback on the interpretability of the proposed approach towards extending topic model descriptors.	Aletras N, 2017, J ASSOC INF SCI TECH, V68, P154, DOI 10.1002/asi.23574; Aletras N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P631; Allahyari M, 2017, INT J ADV COMPUT SC, V8, P335; Angelov D, 2020, Arxiv, DOI [arXiv:2008.09470, DOI 10.48550/ARXIV.2008.09470, 10.48550/arXiv.2008.09470]; [Anonymous], 2023, Meta Llama-2 Version; Bakshy E., 2012, P 21 INT C WORLD WID, P519, DOI 10.1145/2187836.2187907; Basave AEC, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P618; Bchara H., 2021, Res. Politics, V8, DOI [10.1177/20531680211022206, DOI 10.1177/20531680211022206]; Bhatia S., 2016, Proceedings of the 26th International Conference on Computational Linguistics (COLING 2016), P953; Blei D, 2010, IEEE SIGNAL PROC MAG, V27, P55, DOI 10.1109/MSP.2010.938079; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Boyd-Graber Jordan, 2014, Handbook of mixed membership models and their applications; Campos R, 2020, INFORM SCIENCES, V509, P257, DOI 10.1016/j.ins.2019.09.013; Chang J, 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984126; chat.openai, 2023, OpenAI ChatGPT-3.5 Version; Chinnov A., 2015, P 21 AM C INF SYST A, P1; Chuang J., 2013, P 30 INT C MACH LEAR, P612; Curiskis SA, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.04.002; Davare S., 2017, IJSTE-Int. J. Sci. Technol. Eng, V4, P109; Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189; Egger R, 2022, FRONT SOCIOL, V7, DOI 10.3389/fsoc.2022.886498; Greene Derek, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8724, P498, DOI 10.1007/978-3-662-44848-9_32; Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Hendry D, 2021, INT C ADV COMP SCI I, P119, DOI 10.1109/ICACSIS53237.2021.9631322; Hindle A, 2013, EMPIR SOFTW ENG, V18, P1125, DOI 10.1007/s10664-012-9209-9; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Hulpus I., 2013, P 6 ACM INT C WEB SE, P465; Jacobi C, 2016, DIGIT JOURNAL, V4, P89, DOI 10.1080/21670811.2015.1093271; Kang HJ, 2019, PROCESSES, V7, DOI 10.3390/pr7060379; Kinariwala S. A., 2021, J. Integr. Sci. Technol, V9, P85; Kou WQ, 2015, LECT NOTES COMPUT SC, V9460, P253, DOI 10.1007/978-3-319-28940-3_20; Krippendorff Klaus., 2004, Content analysis: An introduction to its methodology; Kumari R, 2021, J INF SCI, V47, P658, DOI 10.1177/0165551519887878; Lang K., Newsgroups Data Set; Lau Jey Han, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, P1536; Lee TY, 2017, INT J HUM-COMPUT ST, V105, P28, DOI 10.1016/j.ijhcs.2017.03.007; Magatti D, 2009, INT CONF INTELL SYST, P1227, DOI 10.1109/ISDA.2009.165; Mei QZ, 2007, KDD-2007 PROCEEDINGS OF THE THIRTEENTH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P490; Mihalcea R., 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064; Mimno D., 2011, P 2011 C EMPIRICAL M, P262; Morstatter F, 2018, J MACH LEARN RES, V18; Passonneau R.J., 2008, Computational Linguistics for Metadata Building, P49; Ramanujam Nedunchelian, 2016, ScientificWorldJournal, V2016, P1784827, DOI 10.1155/2016/1784827; Rehurek R., 2019, GENSIM TOPIC MODELLI; Resnik Philip, 2015, P 2 WORKSH COMP LING, P99, DOI [DOI 10.3115/V1/W15-1212, 10.3115/v1/W15-1212]; Rose S., 2010, TEXT MINING APPL THE, P1, DOI DOI 10.1002/9780470689646.CH1; scikit-learn, Scikit-Learn. 0.24.1 Linear Discriminant Analysis; Snow R., 2008, P C EMP METH NAT LAN, P254, DOI DOI 10.3115/1613715.1613751; Spasic I, 2020, JMIR MED INF, V8, DOI 10.2196/21252; Tarasov A., 2010, P W3C WORKSH EM ML P; Wan XJ, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2297; Weng J, 2010, P 3 ACM INT C WEB SE, P261, DOI DOI 10.1145/1718487.1718520; Wright L, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264134; Yu J., 2021, Information and Communication Technologies in Tourism 2021, P231	55	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2504-2289		BIG DATA COGN COMPUT	Big Data Cogn. Comput.	MAY	2024	8	5							44	10.3390/bdcc8050044	http://dx.doi.org/10.3390/bdcc8050044			26	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	SJ8F0		Green Submitted, gold			2024-07-03	WOS:001234170300001
J	Scherzinger, M				Scherzinger, Martin			Physics and Metaphysics of Post-Truth (Or, Do <i>Realia</i> Deliver us from Artefacts of False Witness?)	INTERMEDIALITES			English	Article								This article outlines one of three systemic conditions underwriting misleading, deceptive, and false content in the socio-digital ecosystem today. Against philosophical realism, which attempts to offer a useful diagnostic bulwark against misinformation, the argument takes up both deliberate and nondeliberate misinformation-from intentional disinformation of all stripes (driven by State, corporate, and other actors), deep fakes, pseudo-science, lies and distorted information to fictions and deceptions unwittingly produced by computational features and functions of machine learning and artificial intelligence (AI), such as with automated prompt-and-response systems. The discussion of misinformation today must additionally reckon with the legal framework guiding online content (and its moderation) as it intersects with the economic incentive structures of contemporary platforms. The structure of the legal economy, in turn, shapes the algorithmic systems and interface designs that curate and generate content on digital platforms. It is the computational feature of the information ecosystem today that is the primary object of consideration in this article. With the increase in computing power in the early 2000s and the archiving of petabytes of digital data, computational approaches shifted from rule-governed, symbolic, and human readable systems to data mining, clustering, and statistical analysis. This statistical turn in the era of the early internet created the conditions for a correlational paradigm for the flow of information within networked communication. The information ecosystem today is ordered by technical tools for prediction and risk reduction-clustering algorithms, Markov chains, n-grams, neural network methods, large language models, and the like. The intersection of the correlational paradigm for computing with the telephonic legal construal of platforms, as well as the concomitant economic incentives, created the conditions for the undermining of documentality imagined by philosophical realism. Following a brief critique of the realist turn in philosophy, the article will explore the correlational paradigm as a technical diagnostic punctum central to the reign of "powers of the false" within the digitally-networked ecosystem today.	[Scherzinger, Martin] NYU, New York, NY 10003 USA	New York University	Scherzinger, M (corresponding author), NYU, New York, NY 10003 USA.							Albright Jonathan, 2016, Medium4 December; Allen Antoine, 2016, Guardian; [Anonymous], 2002, iconic description of affect as a kind of asignifying intensity in Parables for the Virtual: Movement Affect, Sensation; [Anonymous], 2019, Data Voids: Where Missing Data Can Easily be Exploited, P35; [Anonymous], 2016, Manuel Delanda's Assemblage Theory; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Boysen B, 2018, ORBIS LIT, V73, P225, DOI 10.1111/oli.12174; Cheney-Lippold J., 2017, We are the data: Algorithms and the making of our digital selves; Chiang Ted., 2017, The New Yorker; Curry D, 2023, LEONARDO, V56, P177, DOI 10.1162/leon_a_02293; Davidovitz Seth, 2019, YouTube, Big Think; Disraeli Benjamin, 1906, North American Review, Project Gutenberg; Ferraris Maurizio., 2014, Manifesto of New Realism; Ferraris Maurizio, 2017, Data & Society; Fisher Max, 2022, New York Times; Galloway Alexander., 2004, PROTOCOL CONTROL EXI; Geiger RS, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P117; HARLIN J M, 1987, P1; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Haugeland J., 1985, Artificial intelligence: the very idea; Hegel Georg Wilhelm Friedrich, 1977, Phenomenology of Spirit; Jelinek Frederick, 1987, Talking to Terminals; Kusnanto Hari, 2018, J Family Med Prim Care, V7, P497, DOI 10.4103/jfmpc.jfmpc_145_17; Li Xiaochang, 2018, doctoral dissertation; Lyon David, 2020, Pandemic Surveillance: Privacy, Security, and Data Ethics; Marcus Gary, 2022, Marcus on IA1 December; ONeil C., 2016, Weapons of math destruction: how big data increases inequality and threatens democracy; ONeil Cathy, 2016, New York Times26 November; Peters Jeremy W., 2023, New York Times; Solove DJ, 2002, SOUTH CALIF LAW REV, V75, P1083; Sydell Laura, 2016, NPR23 November; Thompson Clive, 2018, Wired, P74; Thompson Stuart A., 2023, New York Times23 February; writes Benkler, 2006, Wealth of Networks: How Social Production Transforms Markets and Freedom, P69	34	0	0	0	0	CENTRE RECHERCHE INTERMEDIALITE	MONTREAL	PAVILLON LIONEL-GROULX, UNIV MONTREAL, MONTREAL, QC H3C 3J7, CANADA	1705-8546	1920-3136		INTERMEDIALITES	Intermedialites	FAL	2023		42												23	Humanities, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Arts & Humanities - Other Topics	RF3M1					2024-07-03	WOS:001226213300009
J	Hosseini, M; Gao, CA; Liebovitz, DM; Carvalho, AM; Ahmad, FS; Luo, Y; MacDonald, N; Holmes, KL; Kho, A				Hosseini, Mohammad; Gao, Catherine A.; Liebovitz, David M.; Carvalho, Alexandre M.; Ahmad, Faraz S.; Luo, Yuan; MacDonald, Ngan; Holmes, Kristi L.; Kho, Abel			An exploratory survey about using ChatGPT in education, healthcare, and research	PLOS ONE			English	Article								Objective ChatGPT is the first large language model (LLM) to reach a large, mainstream audience. Its rapid adoption and exploration by the population at large has sparked a wide range of discussions regarding its acceptable and optimal integration in different areas. In a hybrid (virtual and in-person) panel discussion event, we examined various perspectives regarding the use of ChatGPT in education, research, and healthcare. Materials and methods We surveyed in-person and online attendees using an audience interaction platform (Slido). We quantitatively analyzed received responses on questions about the use of ChatGPT in various contexts. We compared pairwise categorical groups with a Fisher's Exact. Furthermore, we used qualitative methods to analyze and code discussions. Results We received 420 responses from an estimated 844 participants (response rate 49.7%). Only 40% of the audience had tried ChatGPT. More trainees had tried ChatGPT compared with faculty. Those who had used ChatGPT were more interested in using it in a wider range of contexts going forwards. Of the three discussed contexts, the greatest uncertainty was shown about using ChatGPT in education. Pros and cons were raised during discussion for the use of this technology in education, research, and healthcare. Discussion There was a range of perspectives around the uses of ChatGPT in education, research, and healthcare, with still much uncertainty around its acceptability and optimal uses. There were different perspectives from respondents of different roles (trainee vs faculty vs staff). More discussion is needed to explore perceptions around the use of LLMs such as ChatGPT in vital sectors such as education, healthcare and research. Given involved risks and unforeseen challenges, taking a thoughtful and measured approach in adoption would reduce the likelihood of harm.	[Hosseini, Mohammad; Ahmad, Faraz S.; Luo, Yuan; Holmes, Kristi L.] Northwestern Univ, Dept Prevent Med, Feinberg Sch Med, Chicago, IL 60611 USA; [Gao, Catherine A.] Northwestern Univ, Dept Med, Feinberg Sch Med, Div Pulm & Crit Care, Chicago, IL 60611 USA; [Liebovitz, David M.; Kho, Abel] Northwestern Univ, Dept Med, Div Gen Internal Med, Feinberg Sch Med, Chicago, IL 60611 USA; [Liebovitz, David M.; Kho, Abel] Northwestern Univ, Dept Med, Div Hlth & Biomed Informat, Feinberg Sch Med, Chicago, IL 60611 USA; [Liebovitz, David M.] Northwestern Univ, Feinberg Sch Med, Ctr Med Educ Digital Hlth & Data Sci, Chicago, IL 60611 USA; [Carvalho, Alexandre M.] Northwestern Univ, Dept Med, Div Infect Dis, Feinberg Sch Med, Chicago, IL 60611 USA; [Carvalho, Alexandre M.] Northwestern Univ, Feinberg Sch Med, Ctr Pathogen Genom & Microbial Evolut, Chicago, IL 60611 USA; [Ahmad, Faraz S.] Northwestern Univ, Dept Med, Div Cardiol, Feinberg Sch Med, Chicago, IL 60611 USA; [Ahmad, Faraz S.] Northwestern Univ, Feinberg Sch Med, Northwestern Med, Bluhm Cardiovasc Ctr Artificial Intelligence, Chicago, IL 60611 USA; [MacDonald, Ngan; Holmes, Kristi L.; Kho, Abel] Northwestern Univ, Feinberg Sch Med, Inst Artificial Intelligence Med, Chicago, IL 60611 USA; [Holmes, Kristi L.] Northwestern Univ, Feinberg Sch Med, Galter Hlth Sci Lib, Chicago, IL 60611 USA; [Holmes, Kristi L.] Northwestern Univ, Feinberg Sch Med, Learning Ctr, Chicago, IL 60611 USA	Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine	Hosseini, M (corresponding author), Northwestern Univ, Dept Prevent Med, Feinberg Sch Med, Chicago, IL 60611 USA.	mohammad.hosseini@northwestern.edu	Hosseini, Mohammad/X-6867-2019; Liebovitz, David/AAI-9398-2020; Luo, Yuan/K-5563-2016; Holmes, Kristi/A-4358-2010	Hosseini, Mohammad/0000-0002-2385-985X; Liebovitz, David/0000-0002-2518-5940; Ahmad, Faraz/0000-0002-2613-2541; Luo, Yuan/0000-0003-0195-7456; Holmes, Kristi/0000-0001-8420-5254; Gao, Catherine A./0000-0001-5576-3943; Kho, Abel/0000-0003-1993-5634	Northwestern University Institute for Artificial Intelligence in Medicine; NIH/NHLBI [F32HL162377]; National Center for Advancing Translational Sciences (NCATS) [UL1TR001422]; National Institutes of Health (NIH); National Institutes of Health/National Heart, Lung, and Blood Institute [K23HL155970]; American Heart Association (AHA) [856917]	Northwestern University Institute for Artificial Intelligence in Medicine; NIH/NHLBI(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); National Center for Advancing Translational Sciences (NCATS)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS)); National Institutes of Health (NIH)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); National Institutes of Health/National Heart, Lung, and Blood Institute(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI)); American Heart Association (AHA)(American Heart Association)	This work was supported in part by the Northwestern University Institute for Artificial Intelligence in Medicine. CAG is supported by NIH/NHLBI F32HL162377. KH and MH are supported by the National Center for Advancing Translational Sciences (NCATS, UL1TR001422), National Institutes of Health (NIH). FSA is supported by grants from the National Institutes of Health/National Heart, Lung, and Blood Institute (K23HL155970) and the American Heart Association (AHA number 856917). The funders have not played a role in the design, analysis, decision to publish, or preparation of the manuscript.	[Anonymous], 2022, GitHub [Internet]; [Anonymous], 2023, Doximity [Internet]; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Bohr A, 2020, Artificial Intelligence in Healthcare, P25, DOI [DOI 10.1016/B978-0-12-818438-7.00002-2, 10.1016/B978-0-12-818438-7.00002-2]; Cabanac G., 2021, Evidence of critical issues affecting established journals; Cabanac G, 2021, J ASSOC INF SCI TECH, V72, P1461, DOI 10.1002/asi.24495; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Conroy G, 2023, NATURE, V619, P443, DOI 10.1038/d41586-023-02218-z; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Davies J., 2023, Word cloud generator; Flanagan T, 2016, MENT HEALTH REV J, V21, P85, DOI 10.1108/MHRJ-07-2015-0020; Fox A., 2023, EHR vendors demo new GPT features at HIMSS23; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Hamid RD., 2023, The Harvard Crimson [Internet]; Hosseini M., 2023, Impact of Social Sciences; Hosseini M., 2023, Res Ethics, p17470161231180448; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Ipek ZH., 2023, Educ Process Int J [Internet]; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Mojadeddi ZM, 2023, NEW ZEAL MED J, V136, P60; Mollick E., 2023, ONE USEFUL THING; Muoio D., 2021, Epic's widely used sepsis prediction model falls short among Michigan Medicine patients; Nov O, 2023, medRxiv, DOI [10.1101/2023.01.23.23284735, 10.1101/2023.01.23.23284735, DOI 10.1101/2023.01.23.23284735]; OpenAI, 2023, ChatGPT [Internet]; Pollard TJ, 2018, JAMIA OPEN, V1, P26, DOI 10.1093/jamiaopen/ooy012; Qadir J, 2023, 2023 IEEE GLOB ENG E, P1; Roberts B., 2023, SOURCE; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thomas DR, 2006, AM J EVAL, V27, P237, DOI 10.1177/1098214005283748; Wong A, 2021, JAMA INTERN MED, V181, P1065, DOI 10.1001/jamainternmed.2021.2626; Yang M., 2023, The Guardian [Internet]; Zielinski C., 2023, Chatbots, ChatGPT	40	11	11	18	28	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	OCT 5	2023	18	10							e0292216	10.1371/journal.pone.0292216	http://dx.doi.org/10.1371/journal.pone.0292216			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	AE7M9	37796786	Green Published, gold, Green Submitted			2024-07-03	WOS:001116853300110
C	Zhu, J; Li, LW; Yang, L; Ma, XX; Zuo, C			IEEE	Zhu, Jie; Li, Lingwei; Yang, Li; Ma, Xiaoxiao; Zuo, Chun			Automating Method Naming with Context-Aware Prompt-Tuning	2023 IEEE/ACM 31ST INTERNATIONAL CONFERENCE ON PROGRAM COMPREHENSION, ICPC	International Conference on Program Comprehension		English	Proceedings Paper	31st IEEE/ACM International Conference on Program Comprehension (ICPC)	MAY 15-16, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Method Name Recommendation; Inconsistent Method Name Checking; Prompt Tuning		Method names are crucial to program comprehension and maintenance. Recently, many approaches have been proposed to automatically recommend method names and detect inconsistent names. Despite promising, their results are still suboptimal considering the three following drawbacks: 1) These models are mostly trained from scratch, learning two different objectives simultaneously. The misalignment between two objectives will negatively affect training efficiency and model performance. 2) The enclosing class context is not fully exploited, making it difficult to learn the abstract functionality of the method. 3) Current method name consistency checking methods follow a generate-then-compare process, which restricts the accuracy as they highly rely on the quality of generated names and face difficulty measuring the semantic consistency. In this paper, we propose an approach named AUMENA to AUtomate MEthod NAming tasks with context-aware prompt-tuning. Unlike existing deep learning based approaches, our model first learns the contextualized representation(i.e., class attributes) of programming language and natural language through the pre-training model, then fully exploits the capacity and knowledge of large language model with prompt-tuning to precisely detect inconsistent method names and recommend more accurate names. To better identify semantically consistent names, we model the method name consistency checking task as a two-class classification problem, avoiding the limitation of previous generate-then-compare consistency checking approaches. Experiment results reflect that AUMENA scores 68.6%, 72.0%, 73.6%, 84.7% on four datasets of method name recommendation, surpassing the state-of-the-art baseline by 8.5%, 18.4%, 11.0%, 12.0%, respectively. And our approach scores 80.8% accuracy on method name consistency checking, reaching an 5.5% outperformance. All data and trained models are publicly available.	[Zhu, Jie; Li, Lingwei] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Software, Beijing, Peoples R China; [Yang, Li; Ma, Xiaoxiao] Chinese Acad Sci, Inst Software, Beijing, Peoples R China; [Zuo, Chun] Sinosoft Co Ltd, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Software, CAS; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Software, CAS	Yang, L (corresponding author), Chinese Acad Sci, Inst Software, Beijing, Peoples R China.	zhujie212@mails.ucas.ac.cn; lilingwei20@mails.ucas.ac.cn; yangli2017@iscas.ac.cn; xiaoxiao@iscas.ac.cn; zuochun@sinosoft.com.cn	Li, Lingwei/AAB-8042-2021		National Key R&D Program of China [2021YFC3340204]; Alliance of International Science Organizations [ANSO-CR-KP-2022-03]; Strategy Priority Research Program of Chinese Academy of Sciences [XDA20080200]	National Key R&D Program of China; Alliance of International Science Organizations; Strategy Priority Research Program of Chinese Academy of Sciences	We sincerely appreciate the valuable feedback from the anonymous reviewers. This work was supported by the National Key R&D Program of China (No.2021YFC3340204), the Alliance of International Science Organizations, (Grant No. ANSO-CR-KP-2022-03), and the Strategy Priority Research Program of Chinese Academy of Sciences (No.XDA20080200).	Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Allamanis M, 2016, PR MACH LEARN RES, V48; Allamanis M, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P38, DOI 10.1145/2786805.2786849; Alon U., 2019, PROC 7 INT C LEARN R; Alon U, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3290353; Alsuhaibani RS, 2022, INT C PROGRAM COMPRE, P202, DOI 10.1145/3524610.3527780; Alsuhaibani RS, 2021, PROC INT CONF SOFTW, P587, DOI 10.1109/ICSE43902.2021.00061; Arnaoudova V, 2014, IEEE T SOFTWARE ENG, V40, P502, DOI 10.1109/TSE.2014.2312942; Arnaoudova V, 2013, EUR CON SFTWR MTNCE, P187, DOI 10.1109/CSMR.2013.28; Bergstra J., 2011, Adv. Neural Inf. Process. Syst., P2546; Butler S, 2009, WORK CONF REVERSE EN, P31, DOI 10.1109/WCRE.2009.50; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Ge F, 2021, INT C PROGRAM COMPRE, P196, DOI 10.1109/ICPC52881.2021.00027; Guo D., 2021, ICLR; Han XF, 2021, INT C PROGRAM COMPRE, P323, DOI 10.1109/ICPC52881.2021.00038; Higo Y, 2012, 2012 28TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE MAINTENANCE (ICSM), P222, DOI 10.1109/ICSM.2012.6405275; Host EW, 2009, LECT NOTES COMPUT SC, V5653, P294, DOI 10.1007/978-3-642-03013-0_14; Jiang L, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P614, DOI 10.1109/ASE.2019.00062; Kim S, 2016, EMPIR SOFTW ENG, V21, P565, DOI 10.1007/s10664-015-9369-5; Ko AJ, 2006, IEEE T SOFTWARE ENG, V32, P971, DOI 10.1109/TSE.2006.116; Lawrie D, 2006, INT C PROGRAM COMPRE, P3, DOI 10.1109/ICPC.2006.51; Li Y, 2021, PROC INT CONF SOFTW, P574, DOI 10.1109/ICSE43902.2021.00060; Li Zhiyu, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1035, DOI 10.1145/3540250.3549081; Liu F, 2022, PROC INT CONF SOFTW, P1294, DOI 10.1145/3510003.3510154; Liu KW, 2019, IEEE C ELEC DEVICES, DOI 10.1109/edssc.2019.8754036; Nguyen S, 2020, PROC INT CONF SOFTW, P1372, DOI 10.1145/3377811.3380926; Pantiuchina J, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3408302; Peruma A., 2018, P 2 INT WORKSH REF, P26; Qu ZH, 2022, EUR CON SFTWR MTNCE, P1101, DOI 10.1109/SANER53432.2022.00127; Raffel C, 2020, J MACH LEARN RES, V21; Rajlich V, 2002, PROG COMPREHEN, P271, DOI 10.1109/WPC.2002.1021348; Roehm T, 2012, PROC INT CONF SOFTW, P255, DOI 10.1109/ICSE.2012.6227188; Scalabrino S, 2021, IEEE T SOFTWARE ENG, V47, P595, DOI 10.1109/TSE.2019.2901468; See A, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1073, DOI 10.18653/v1/P17-1099; Tufano R, 2022, PROC INT CONF SOFTW, P2291, DOI 10.1145/3510003.3510621; Wang Chaozheng, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P382, DOI 10.1145/3540250.3549113; Wang SW, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P741, DOI 10.1145/3468264.3468567; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; WILCOXON F, 1946, J ECON ENTOMOL, V39, P269, DOI 10.1093/jee/39.2.269; Xu SH, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN WORKSHOP ON PARTIAL EVALUATION AND PROGRAM MANIPULATION (PEPM '19), P10, DOI 10.1145/3294032.3294079; Yonai H, 2019, ASIA PAC SOFWR ENG, P134, DOI 10.1109/APSEC48747.2019.00027	41	0	0	1	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1092-8138		979-8-3503-3750-1	INT C PROGRAM COMPRE			2023							203	214		10.1109/ICPC58990.2023.00035	http://dx.doi.org/10.1109/ICPC58990.2023.00035			12	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JM		Green Submitted			2024-07-03	WOS:001032677200025
J	Chifu, AG; Fournier, S				Chifu, Adrian-Gabriel; Fournier, Sebastien			Sentiment Difficulty in Aspect-Based Sentiment Analysis	MATHEMATICS			English	Article						sentiment analysis; aspect-based sentiment analysis; difficulty; sentiment polarity; text representation	MODEL; LSTM	Subjectivity is a key aspect of natural language understanding, especially in the context of user-generated text and conversational systems based on large language models. Natural language sentences often contain subjective elements, such as opinions and emotions, that make them more nuanced and complex. The level of detail at which the study of the text is performed determines the possible applications of sentiment analysis. The analysis can be done at the document or paragraph level, or, even more granularly, at the aspect level. Many researchers have studied this topic extensively. The field of aspect-based sentiment analysis has numerous data sets and models. In this work, we initiate the discussion around the definition of sentence difficulty in this context of aspect-based sentiment analysis. To assess and quantify the difficulty of the aspect-based sentiment analysis, we conduct an experiment using three data sets: "Laptops", "Restaurants", and "MTSC" (Multi-Target-dependent Sentiment Classification), along with 21 learning models from scikit-learn. We also use two textual representations, TF-IDF (Terms frequency-inverse document frequency) and BERT (Bidirectional Encoder Representations from Transformers), to analyze the difficulty faced by these models in performing aspect-based sentiment analysis. Additionally, we compare the models with a fine-tuned version of BERT on the three data sets. We identify the most challenging sentences using a combination of classifiers in order to better understand them. We propose two strategies for defining sentence difficulty. The first strategy is binary and considers sentences as difficult when the classifiers are unable to correctly assign the sentiment polarity. The second strategy uses a six-level difficulty scale based on how many of the top five best-performing classifiers can correctly identify sentiment polarity. These sentences with assigned difficulty classes are then used to create predictive models for early difficulty detection. The purpose of estimating the difficulty of aspect-based sentiment analysis is to enhance performance while minimizing resource usage.	[Chifu, Adrian-Gabriel; Fournier, Sebastien] Univ Toulon & Var, Aix Marseille Univ, CNRS, LIS, F-13007 Marseille, France	Centre National de la Recherche Scientifique (CNRS); Universite de Toulon; Aix-Marseille Universite	Chifu, AG (corresponding author), Univ Toulon & Var, Aix Marseille Univ, CNRS, LIS, F-13007 Marseille, France.	adrian.chifu@univ-amu.fr; sebastien.fournier@univ-amu.fr		CHIFU, Adrian-Gabriel/0000-0003-4680-5528				Ahmad M, 2018, INT J ADV COMPUT SC, V9, P182; Ahmed Afrin, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P181, DOI 10.1007/978-981-33-4673-4_16; [Anonymous], 1996, PROBABILISTIC ANAL R, DOI DOI 10.1016/J.ESWA.2016.09.009; Asyrofi MH, 2022, IEEE T SOFTWARE ENG, V48, P5087, DOI 10.1109/TSE.2021.3136169; Basiri ME, 2021, FUTURE GENER COMP SY, V115, P279, DOI 10.1016/j.future.2020.08.005; Bordoloi M, 2023, ARTIF INTELL REV, V56, P12505, DOI 10.1007/s10462-023-10442-2; Brauwers G, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3503044; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cambria E, 2013, IEEE INTELL SYST, V28, P12, DOI 10.1109/MIS.2013.45; Carmel D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P911; Chauhan GS, 2023, COMPUT SCI REV, V49, DOI 10.1016/j.cosrev.2023.100576; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Cronen-Townsend S., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P299; Cronen-Townsend S., 2004, LANGUAGE MODELING FR; Cui JF, 2023, ARTIF INTELL REV, V56, P8469, DOI 10.1007/s10462-022-10386-z; De Loupy Claude, 2000, P 2 INT C LANG RES E, P32; Deng SY, 2017, ACM TRANS MANAG INF, V8, DOI 10.1145/3046684; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Do HH, 2019, EXPERT SYST APPL, V118, P272, DOI 10.1016/j.eswa.2018.10.003; Faggioli G, 2023, PROCEEDINGS OF THE 2023 ACM SIGIR INTERNATIONAL CONFERENCE ON THE THEORY OF INFORMATION RETRIEVAL, ICTIR 2023, P51, DOI 10.1145/3578337.3605142; Faggioli G, 2023, LECT NOTES COMPUT SC, V13980, P232, DOI 10.1007/978-3-031-28244-7_15; Farias DIH, 2017, SENTIMENT ANALYSIS IN SOCIAL NETWORKS, P113, DOI 10.1016/B978-0-12-804412-4.00007-3; Fikri M., 2019, Indonesian Journal of Electrical Engineering and Computer Science, V13, P902, DOI [10.11591/ijeecs.v13.i3.pp902-909, DOI 10.11591/IJEECS.V13.I3.PP902-909]; Ganu G., 2009, WebDB, V9, P1; Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594; Geetha M., 2021, International Journal of Intelligent Networks, V2, P64, DOI [10.1016/j.ijin.2021.06.005, DOI 10.1016/J.IJIN.2021.06.005]; Goel A, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P257, DOI 10.1109/NGCT.2016.7877424; Goeuriot L, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1007, DOI 10.1145/2600428.2609496; Gref M, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2022; Hamborg F, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1663; Hashemi H, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P55, DOI 10.1145/3341981.3344249; He B, 2004, LECT NOTES COMPUT SC, V3246, P43; Hoang M., 2019, P 22 NORDIC C COMPUT, P187; Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755; Karimi A., 2020, P INT C NAT LANG SPE; Kong J, 2023, J RETAIL CONSUM SERV, V73, DOI 10.1016/j.jretconser.2023.103374; Li D, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102290; Li Q., 2023, ARTIFICIAL NEURAL NE, V4263; Liu HY, 2020, IEEE T COMPUT SOC SY, V7, P1358, DOI 10.1109/TCSS.2020.3033302; Liu RJ, 2019, IEEE ACCESS, V7, P85401, DOI 10.1109/ACCESS.2019.2925059; Ma YK, 2018, COGN COMPUT, V10, P639, DOI 10.1007/s12559-018-9549-x; Ma YK, 2018, AAAI CONF ARTIF INTE, P5876; Maynard D, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4238; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mittal Punit, 2023, Proceedings of International Conference on Recent Trends in Computing: ICRTC 2022. Lecture Notes in Networks and Systems (600), P119, DOI 10.1007/978-981-19-8825-7_11; Mothe J., 2005, ACM C RES DEV INFORM; Mothe J, 2019, INT CONF KNOWL SYS, P203, DOI 10.1109/kse.2019.8919433; Mubarok M.S., 2016, P INT C MATH PURE AP; Mubarok MS, 2017, AIP CONF PROC, V1867, DOI 10.1063/1.4994463; Mutlu MM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): STUDENT RESEARCH WORKSHOP, P467; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pontiki M, 2014, P 8 INT WORKSH SEM E, P27, DOI [DOI 10.3115/V1/S14-2004, 10.3115/v1/s14-2004]; Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7; Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Scholer F, 2004, J AM SOC INF SCI TEC, V55, P637, DOI 10.1002/asi.20011; Shtok A, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180873; Tao Y., 2014, P 23 ACM INT C CONFE, P1891, DOI DOI 10.1145/2661829.2661906; Tiwari D, 2023, ARTIF INTELL REV, V56, P13407, DOI 10.1007/s10462-023-10472-w; van Atteveldt W, 2021, COMMUN METHODS MEAS, V15, P121, DOI 10.1080/19312458.2020.1869198; Varghese R, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1581, DOI 10.1109/ICACCI.2013.6637416; Villavicencio C, 2021, INFORMATION, V12, DOI 10.3390/info12050204; Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002; Wang X., 2016, P COL 2016 26 INT C, P2428; Wankhade M, 2022, ARTIF INTELL REV, V55, P5731, DOI 10.1007/s10462-022-10144-1; Yun Zhou, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P543, DOI 10.1145/1277741.1277835; Zhang J, 2019, KNOWL-BASED SYST, V181, DOI 10.1016/j.knosys.2019.05.026; Zhang WX, 2023, IEEE T KNOWL DATA EN, V35, P11019, DOI 10.1109/TKDE.2022.3230975; Zhao XT, 2021, IEEE INT CONF BIG DA, P3717, DOI 10.1109/BigData52589.2021.9671697; Zhao Y, 2008, LECT NOTES COMPUT SC, V4956, P52	71	3	3	43	43	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	NOV	2023	11	22							4647	10.3390/math11224647	http://dx.doi.org/10.3390/math11224647			33	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	AK5B2		gold			2024-07-03	WOS:001118361800001
J	Patel, EA; Fleischer, L; Filip, P; Eggerstedt, M; Hutz, M; Michaelides, E; Batra, PS; Tajudeen, BA				Patel, Evan A.; Fleischer, Lindsay; Filip, Peter; Eggerstedt, Michael; Hutz, Michael; Michaelides, Elias; Batra, Pete S.; Tajudeen, Bobby A.			Comparative Performance of ChatGPT 3.5 and GPT4 on Rhinology Standardized Board Examination Questions	OTO OPEN			English	Article						artificial intelligence; machine learning; rhinology	ARTIFICIAL-INTELLIGENCE; PREDICTION; DIAGNOSIS	ObjectiveAdvances in deep learning and artificial intelligence (AI) have led to the emergence of large language models (LLM) like ChatGPT from OpenAI. The study aimed to evaluate the performance of ChatGPT 3.5 and GPT4 on Otolaryngology (Rhinology) Standardized Board Examination questions in comparison to Otolaryngology residents.MethodsThis study selected all 127 rhinology standardized questions from , a commonly used study tool by otolaryngology residents preparing for board exams. Ninety-three text-based questions were administered to ChatGPT 3.5 and GPT4, and their answers were compared with the average results of the question bank (used primarily by otolaryngology residents). Thirty-four image-based questions were provided to GPT4 and underwent the same analysis. Based on the findings of an earlier study, a pass-fail cutoff was set at the 10th percentile.ResultsOn text-based questions, ChatGPT 3.5 answered correctly 45.2% of the time (8th percentile) (P = .0001), while GPT4 achieved 86.0% (66th percentile) (P = .001). GPT4 answered image-based questions correctly 64.7% of the time. Projections suggest that ChatGPT 3.5 might not pass the American Board of Otolaryngology Written Question Exam (ABOto WQE), whereas GPT4 stands a strong chance of passing.DiscussionThe older LLM, ChatGPT 3.5, is unlikely to pass the ABOto WQE. However, the advanced GPT4 model exhibits a much higher likelihood of success. This rapid progression in AI indicates its potential future role in otolaryngology education.Implications for PracticeAs AI technology rapidly advances, it may be that AI-assisted medical education, diagnosis, and treatment planning become commonplace in the medical and surgical landscape.Level of EvidenceLevel 5.	[Patel, Evan A.; Fleischer, Lindsay; Filip, Peter; Eggerstedt, Michael; Hutz, Michael; Michaelides, Elias; Batra, Pete S.; Tajudeen, Bobby A.] Rush Univ, Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, 1611 West Harrison St,Suite 550, Chicago, IL 60612 USA	Rush University	Tajudeen, BA (corresponding author), Rush Univ, Med Ctr, Dept Otorhinolaryngol Head & Neck Surg, 1611 West Harrison St,Suite 550, Chicago, IL 60612 USA.	bobby_tajudeen@rush.edu						Bassani Sara, 2022, J Pathol Inform, V13, P100153, DOI 10.1016/j.jpi.2022.100153; Boscardin CK, 2024, ACAD MED, V99, P22, DOI 10.1097/ACM.0000000000005439; Brennan HL, 2023, J OTOLARYNGOL-HEAD N, V52, DOI 10.1186/s40463-023-00621-0; Fouladvand S, 2023, IEEE J BIOMED HEALTH, V27, P3589, DOI 10.1109/JBHI.2023.3265920; Gholipour M, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05480-0; Hu JX, 2023, WORLD J GASTROENTERO, V29, P5268, DOI 10.3748/wjg.v29.i37.5268; Koseoglu FD, 2023, SURG ENDOSC, V37, P9339, DOI 10.1007/s00464-023-10488-x; Liu GS, 2022, INT FORUM ALLERGY RH, V12, P1025, DOI 10.1002/alr.22958; Liu PR, 2021, CURR MED SCI, V41, P1158, DOI 10.1007/s11596-021-2501-4; Long C, 2024, JMIR MED EDUC, V10, DOI 10.2196/49970; Mahmood H, 2021, BRIT J CANCER, V124, P1934, DOI 10.1038/s41416-021-01386-x; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Puscas L, 2012, OTOLARYNG HEAD NECK, V147, P256, DOI 10.1177/0194599812444386; Roos J, 2023, JMIR MED EDUC, V9, DOI 10.2196/46482; Sarfaraz S, 2023, J TAIBAH UNIV MED SC, V18, P1553, DOI 10.1016/j.jtumed.2023.06.008; Valeriani D, 2020, P NATL ACAD SCI USA, V117, P26398, DOI 10.1073/pnas.2009165117; You EI, 2020, OTOLARYNG HEAD NECK, V163, P1123, DOI 10.1177/0194599820931804; Zalzal HG, 2024, LARYNGOSCOPE INVEST, V9, DOI 10.1002/lio2.1193; Zalzal HG, 2023, OTO OPEN, V7, DOI 10.1002/oto2.94	19	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2473-974X		OTO OPEN	OTO Open	APR	2024	8	2							e164	10.1002/oto2.164	http://dx.doi.org/10.1002/oto2.164			6	Otorhinolaryngology	Emerging Sources Citation Index (ESCI)	Otorhinolaryngology	WL8A5	38938507				2024-07-03	WOS:001255103800001
J	Onder, CE; Koc, G; Gokbulut, P; Taskaldiran, I; Kuskonmaz, SM				Onder, C. E.; Koc, G.; Gokbulut, P.; Taskaldiran, I.; Kuskonmaz, S. M.			Evaluation of the reliability and readability of ChatGPT-4 responses regarding hypothyroidism during pregnancy	SCIENTIFIC REPORTS			English	Article							HEALTH INFORMATION	Hypothyroidism is characterized by thyroid hormone deficiency and has adverse effects on both pregnancy and fetal health. Chat Generative Pre-trained Transformer (ChatGPT) is a large language model trained with a very large database from many sources. Our study was aimed to evaluate the reliability and readability of ChatGPT-4 answers about hypothyroidism in pregnancy. A total of 19 questions were created in line with the recommendations in the latest guideline of the American Thyroid Association (ATA) on hypothyroidism in pregnancy and were asked to ChatGPT-4. The reliability and quality of the responses were scored by two independent researchers using the global quality scale (GQS) and modified DISCERN tools. The readability of ChatGPT was assessed used Flesch Reading Ease (FRE) Score, Flesch-Kincaid grade level (FKGL), Gunning Fog Index (GFI), Coleman-Liau Index (CLI), and Simple Measure of Gobbledygook (SMOG) tools. No misleading information was found in any of the answers. The mean mDISCERN score of the responses was 30.26 +/- 3.14; the median GQS score was 4 (2-4). In terms of reliability, most of the answers showed moderate (78.9%) followed by good (21.1%) reliability. In the readability analysis, the median FRE was 32.20 (13.00-37.10). The years of education required to read the answers were mostly found at the university level [9 (47.3%)]. Although ChatGPT-4 has significant potential, it can be used as an auxiliary information source for counseling by creating a bridge between patients and clinicians about hypothyroidism in pregnancy. Efforts should be made to improve the reliability and readability of ChatGPT.	[Onder, C. E.; Koc, G.; Gokbulut, P.; Taskaldiran, I.; Kuskonmaz, S. M.] Ankara Numune Training & Res Hosp, Dept Endocrinol & Metab Dis, Ankara, Turkiye	Ankara Numune Training & Research Hospital	Onder, CE (corresponding author), Ankara Numune Training & Res Hosp, Dept Endocrinol & Metab Dis, Ankara, Turkiye.	drcagatayonder@gmail.com	ONDER, CAGATAY EMIR/IZP-6784-2023; taşkaldıran, ışılay/HPD-7908-2023	ONDER, CAGATAY EMIR/0000-0002-0293-2309; taşkaldıran, ışılay/0000-0002-1390-7571; Varan Koc, Gonul/0000-0002-8512-4816	Society Endocrinology and Metabolism of Turkey	Society Endocrinology and Metabolism of Turkey	Preparation for publication of this article is supported by Society Endocrinology and Metabolism of Turkey.	Abalovich M, 2002, THYROID, V12, P63, DOI 10.1089/105072502753451986; Alexander EK, 2017, THYROID, V27, P315, DOI 10.1089/thy.2016.0457; Ali R, 2023, medRxiv, DOI [10.1101/2023.04.06.23288265, 10.1101/2023.04.06.23288265, DOI 10.1101/2023.04.06.23288265]; Bommineni VL, 2023, medRxiv, DOI [10.1101/2023.03.05.23286533, 10.1101/2023.03.05.23286533, DOI 10.1101/2023.03.05.23286533]; Chen S, 2023, medRxiv, DOI [10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316, DOI 10.1101/2023.03.16.23287316V1, DOI 10.1101/2023.03.16.23287316, 10.1101/2023.03.16.23287316v1]; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Dash D, 2023, Arxiv, DOI [arXiv:2304.13714, DOI 10.48550/ARXIV.2304.13714]; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Hesse BW, 2005, ARCH INTERN MED, V165, P2618, DOI 10.1001/archinte.165.22.2618; Hirosawa T, 2023, JMIR MED INF, V11, DOI 10.2196/48808; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; King RC, 2023, medRxiv, DOI [10.1101/2023.07.07.23292385, 10.1101/2023.07.07.23292385, DOI 10.1101/2023.07.07.23292385]; Kumar VS, 2014, J PEDIATR ORTHOP B, V23, P135, DOI 10.1097/BPB.0000000000000000; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lim STJM, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01513-x; Long C, 2023, medRxiv, DOI [10.1101/2023.05.30.23290758, 10.1101/2023.05.30.23290758, DOI 10.1101/2023.05.30.23290758]; Lukac S, 2023, ARCH GYNECOL OBSTET, V308, P1831, DOI 10.1007/s00404-023-07130-5; Mégier C, 2023, METABOLITES, V13, DOI 10.3390/metabo13050633; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Onder ME, 2022, ARCH OSTEOPOROS, V17, DOI 10.1007/s11657-022-01064-2; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Ozduran E, 2022, PEERJ, V10, DOI 10.7717/peerj.13686; Pearce EN, 2022, ENDOCR PRACT, V28, P711, DOI 10.1016/j.eprac.2022.05.004; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Schulman J, 2022, Introducing chatgpt; Shinohara DR, 2018, OBSTET GYNECOL SURV, V73, P219, DOI 10.1097/OGX.0000000000000547; Simpson D., 2013, The readability test tool; Sng GGR, 2023, DIABETES CARE, V46, pE103, DOI 10.2337/dc23-0197; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Sullivan SA, 2019, CLIN OBSTET GYNECOL, V62, P308, DOI 10.1097/GRF.0000000000000432; Teebagy S, 2023, medRxiv, DOI [10.1101/2023.04.03.23287957, 10.1101/2023.04.03.23287957, DOI 10.1101/2023.04.03.23287957]	31	3	3	11	11	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	JAN 2	2024	14	1							243	10.1038/s41598-023-50884-w	http://dx.doi.org/10.1038/s41598-023-50884-w			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	IA7K2	38167988	gold, Green Published			2024-07-03	WOS:001163663800157
J	Shao, YN; Xiang, BM				Shao, Yunna; Xiang, Bangmeng			Enhancing Bug Report Summaries Through Knowledge-Specific and Contrastive Learning Pre-Training	IEEE ACCESS			English	Article						Computer bugs; Task analysis; Codes; Self-supervised learning; Software maintenance; Semantics; Representation learning; Domain specific languages; Software packages; Bug report summarization; domain-specific pre-training; software maintenance; representation learning		Bug reports are crucial in software maintenance, with concise summaries significantly enhancing the efficiency of bug triagers and ultimately contributing to the development of high-quality software products. Contemporary methods for automatic bug report summarization primarily utilize neural networks' robust learning capabilities. However, these approaches often produce suboptimal summaries due to two primary limitations: 1) the difficulty in assimilating the domain-specific knowledge inherent in bug reports, and 2) the limitations of purely supervised learning in comprehending the comprehensive context of bug reports. To address the above two problems, in this paper, we propose a new approach for bug report summarization, namely KSCLP, which leverages large language models and domain-specific pre-training strategies, i.e., Knowledge-Specific and Contrastive Learning Pre-training. Specifically, the Knowledge-Specific strategy allows to pre-train KSCLP on project-specific bug reports corpus, by which the model can fully learn internal knowledge of bug reports, learning bug report-aware representation. As for the Contrastive Learning strategy, it performs a sequence-level pre-training for KSCLP, helping it capture the semantic information of bug reports on a global level. Upon completion of the pre-training phase, KSCLP undergoes further refinement through a Sequence-to-Sequence framework specifically tailored for bug report summarization. The efficacy of KSCLP is rigorously evaluated against five baseline models using a publicly available dataset. The empirical results demonstrate that KSCLP outperforms all baselines, achieving remarkable improvements by up to 23.73, 13.97, and 20.89 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, thereby setting new benchmarks in the field of bug report summarization.	[Shao, Yunna; Xiang, Bangmeng] Zhejiang Coll Secur Technol, Wenzhou 325000, Zhejiang, Peoples R China		Xiang, BM (corresponding author), Zhejiang Coll Secur Technol, Wenzhou 325000, Zhejiang, Peoples R China.	13957787633@163.com			Wenzhou Municipal Science and Technology Plan Project	Wenzhou Municipal Science and Technology Plan Project	No Statement Available	Arya D, 2019, PROC INT CONF SOFTW, P454, DOI 10.1109/ICSE.2019.00058; Chen XH, 2018, ADV NEUR IN, V31; Chen ZM, 2023, Arxiv, DOI arXiv:2309.14846; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fang S, 2023, PROC INT CONF SOFTW, P602, DOI 10.1109/ICSE48619.2023.00060; Fang S, 2022, J SYST SOFTWARE, V185, DOI 10.1016/j.jss.2021.111160; Fang S, 2021, IEEE T RELIAB, V70, P563, DOI 10.1109/TR.2021.3074412; Fang S, 2021, INFORM SOFTWARE TECH, V134, DOI 10.1016/j.infsof.2021.106542; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Gu XD, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P933, DOI 10.1145/3180155.3180167; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; Jiang H, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-014-0372-y; Jindal SG, 2020, IEEE ACCESS, V8, P65352, DOI 10.1109/ACCESS.2020.2985222; Khan JA, 2022, SOFTWARE PRACT EXPER, V52, P2537, DOI 10.1002/spe.3137; Li DC, 2022, IEEE ACCESS, V10, P51167, DOI 10.1109/ACCESS.2022.3164780; Li T., 2022, arXiv; Li XC, 2018, INT C PROGRAM COMPRE, P144, DOI 10.1145/3196321.3196326; Liu HR, 2020, INT C PROGRAM COMPRE, P94, DOI 10.1145/3387904.3389272; Liu Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3730; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lotufo R, 2015, EMPIR SOFTW ENG, V20, P516, DOI 10.1007/s10664-014-9311-2; Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166; Mani R., 2012, P ACM SIGSOFT 20 INT, P1; Mei J., 2010, P 16 ACM SIGKDD INT, P1009, DOI [DOI 10.1145/1835804.1835931)(2010, DOI 10.1145/1835804.1835931]; Mikolov I., 2013, Adv. Neural Inf. Process. Syst.; Radev DR, 2004, INFORM PROCESS MANAG, V40, P919, DOI 10.1016/j.ipm.2003.10.006; Rastkar S, 2014, IEEE T SOFTWARE ENG, V40, P366, DOI 10.1109/TSE.2013.2297712; Shaw P., 2018, P 2018 C N AM CHAPT, P464, DOI DOI 10.48550/ARXIV.1803.02155; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Ullah J. A., 2023, SoftComput., P1; Vaswani A, 2017, ADV NEUR IN, V30; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yuan DW, 2023, IEEE T RELIAB, V72, P511, DOI 10.1109/TR.2022.3176922; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253; Zhu X., 2007, P HUM LANG TECHN C N, P97	39	0	0	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						37653	37662		10.1109/ACCESS.2024.3368915	http://dx.doi.org/10.1109/ACCESS.2024.3368915			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	LE1R3		gold			2024-07-03	WOS:001185016700001
J	Wójcik, S; Rulkiewicz, A; Pruszczyk, P; Lisik, W; Pobozy, M; Domienik-Karlowicz, J				Wojcik, Simona; Rulkiewicz, Anna; Pruszczyk, Piotr; Lisik, Wojciech; Pobozy, Marcin; Domienik-Karlowicz, Justyna			Beyond ChatGPT: What does GPT-4 add to healthcare? The dawn of a new era	CARDIOLOGY JOURNAL			English	Review						ChatGPT; innovations; artificial intelligence; AI in medicine; health IT	ARTIFICIAL-INTELLIGENCE	Over the past few years, artificial intelligence (AI) has significantly improved healthcare. Once the stuff of science fiction, AI is now widely used, even in our daily lives - often without us thinking about it. All healthcare professionals - especially executives and medical doctors - need to understand the capabilities of advanced AI tools and other breakthrough innovations. This understanding will allow them to recognize opportunities and threats emerging technologies can bring to their organizations. We hope to contribute to a meaningful public discussion about the role of this new type of AI and how our approach to healthcare and medicine can best evolve with the rapid development of this technology. Since medicine learns by example, only a few possible uses of AI in medicine are provided, which merely outline the system's capabilities. Among the examples, it is worth highlighting the roles of AI in medical notes, education, preventive programs, consultation, triage and intervention. It is believed by the authors that large language models such as chat generative pre-trained transformer (ChatGPT) are reaching a level of maturity that will soon impact clinical medicine as a whole and improve the delivery of individualized, compassionate, and scalable healthcare. It is unlikely that AI will replace physicians in the near future. The human aspects of care, including empathy, compassion, critical thinking, and complex decision-making, are invaluable in providing holistic patient care beyond diagnosis and treatment decisions. The GPT-4 has many limitations and cannot replace direct contact between an experienced physician and a patient for even the most seemingly simple consultations, not to mention the ethical and legal aspects of responsibility for diagnosis. (Cardiol J 2023; 30, 6: 1018-1025)	[Wojcik, Simona; Rulkiewicz, Anna; Domienik-Karlowicz, Justyna] Lux Med Llc, Warsaw, Poland; [Pruszczyk, Piotr; Domienik-Karlowicz, Justyna] Med Univ Warsaw, Ctr Diag & Treatment Thromboembolism, Dept Internal Med & Cardiol, Warsaw, Poland; [Lisik, Wojciech] Med Univ Warsaw, Dept Gen & Transplantat Surg, Warsaw, Poland; [Pobozy, Marcin] Cichowski Pobozy Healthcare Facil, Maciejowice, Poland	Medical University of Warsaw; Medical University of Warsaw	Domienik-Karlowicz, J (corresponding author), Med Univ Warsaw, Dept Gen & Transplantat Surg, Ul Lindleya 4, PL-02006 Warsaw, Poland.	jdomienik@tlen.pl	; Lisik, Wojciech/Q-8972-2018	Domienik-Karlowicz, Justyna/0000-0001-6122-9755; Pruszczyk, Piotr/0000-0002-9768-0000; Lisik, Wojciech/0000-0003-3020-3979				Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; Durand E, 2023, EUROINTERVENTION, V18, pE1339, DOI 10.4244/EIJ-D-22-00642; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Henderson Emily, 2023, What does ChatGPT mean for Healthcare?; ibsafoundation, About us; Johnson KW, 2018, J AM COLL CARDIOL, V71, P2668, DOI 10.1016/j.jacc.2018.03.521; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Marr B., 2023, Forbes; news medical net, About us; Waisberg E, 2022, SPACE-SCI TECH-CHINA, V2022, DOI 10.34133/2022/9852872	11	7	7	31	36	VIA MEDICA	GDANSK	UL SWIETOKRZYSKA 73, 80-180 GDANSK, POLAND	1897-5593	1898-018X		CARDIOL J	Cardiol. J.	DEC	2023	30	6					1018	1025		10.5603/cj.97515	http://dx.doi.org/10.5603/cj.97515			8	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	AF0H1	37830256	gold			2024-07-03	WOS:001116926600001
J	McCarthy, CJ; Berkowitz, S; Ramalingam, V; Ahmed, M				McCarthy, Colin J.; Berkowitz, Seth; Ramalingam, Vijay; Ahmed, Muneeb			Evaluation of an Artificial Intelligence Chatbot for Delivery of IR Patient Education Material: A Comparison with Societal Website Content	JOURNAL OF VASCULAR AND INTERVENTIONAL RADIOLOGY			English	Article							READABILITY FORMULA; MANAGEMENT	Purpose: To assess the accuracy, completeness, and readability of patient educational material produced by a machine learning model and compare the output to that provided by a societal website. Materials and Methods: Content from the Society of Interventional Radiology Patient Center website was retrieved, categorized, and organized into discrete questions. These questions were entered into the ChatGPT platform, and the output was analyzed for word and sentence counts, readability using multiple validated scales, factual correctness, and suitability for patient education using the Patient Education Materials Assessment Tool for Printable Materials (PEMAT-P) instrument. Results: A total of 21,154 words were analyzed, including 7,917 words from the website and 13,377 words representing the total output of the ChatGPT platform across 22 text passages. Compared to the societal website, output from the ChatGPT platform was longer and more difficult to read on 4 of 5 readability scales. The ChatGPT output was incorrect for 12 (11.5%) of 104 questions. When reviewed using the PEMAT-P tool, the ChatGPT content scored lower than the website material. Content from both the website and ChatGPT were significantly above the recommended fifth or sixth grade level for patient education, with a mean Flesch-Kincaid grade level of 11.1 (+/- 1.3) for the website and 11.9 (+/- 1.6) for the ChatGPT content. Conclusions: The ChatGPT platform may produce incomplete or inaccurate patient educational content, and providers should be familiar with the limitations of the system in its current form. Opportunities may exist to fine-tune existing large language models, which could be optimized for the delivery of patient educational content.	[McCarthy, Colin J.; Berkowitz, Seth; Ramalingam, Vijay; Ahmed, Muneeb] Harvard Med Sch, Beth Israel Deaconess Med Ctr, Div Vasc & Intervent Radiol, Rosenberg 3,One Deaconess Rd, Boston, MA 02215 USA	Harvard University; Beth Israel Deaconess Medical Center; Harvard Medical School	McCarthy, CJ (corresponding author), Harvard Med Sch, Beth Israel Deaconess Med Ctr, Div Vasc & Intervent Radiol, Rosenberg 3,One Deaconess Rd, Boston, MA 02215 USA.	cmccar11@bidmc.harvard.edu						[Anonymous], Advancing effective communication, cultural competence, and patient and family centered care: A roadmap for hospitals; ARMSTRONG JS, 1982, J FORECASTING, V1, P83, DOI 10.1002/for.3980010109; Biron B, Online mental health company uses ChatGPT to help respond to users in experiment-raising ethical concerns around healthcare and AI technology; Broe MP, 2021, CUAJ-CAN UROL ASSOC, V15, pE569, DOI 10.5489/cuaj.7077; Chall J., 1995, READABILITY REVISITE; ChatGPT, about us; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; Davis TC, 2004, FAM MED, V36, P595; Diederich S, 2020, BUS INFORM SYST ENG+, V62, P193, DOI 10.1007/s12599-020-00639-y; Enikeev D, 2022, UROL INT, V106, P1, DOI 10.1159/000517675; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; Fitzsimmons PR, 2010, J ROY COLL PHYS EDIN, V40, P292, DOI 10.4997/JRCPE.2010.401; Flesch R., 1944, Teach Coll Rec, V45, P1; FRY E, 1968, J READING, V11, P513; Gao Leo, 2022, arXiv, DOI 10.48550/arXiv.2210.10760; Kincaid J.P., 1975, Technical report; Lerner LB, 2021, J UROLOGY, V206, P818, DOI 10.1097/JU.0000000000002184; McEnteggart GE, 2015, J VASC INTERV RADIOL, V26, P1164, DOI 10.1016/j.jvir.2015.03.019; Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619871808; Nass C, 2000, J SOC ISSUES, V56, P81, DOI 10.1111/0022-4537.00153; Nielsen K, 2014, BRIT J ANAESTH, V113, P985, DOI 10.1093/bja/aeu256; OpenAI, WHAT IS CHATGPT; OpenAI, MOD IND RES; Parvinian A, 2013, J VASC INTERV RADIOL, V24, P941, DOI 10.1016/j.jvir.2013.03.018; readysteadygo, US; Rooney MK, 2021, J PATIENT EXPERIENCE, V8, DOI 10.1177/2374373521998847; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Segal RL, 2013, J UROLOGY, V190, P2183, DOI 10.1016/j.juro.2013.06.084; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Smith E A, 1967, AMRL TR, P1; Society of Interventional Radiology, Patient center.; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Sundar G, 2022, Practical management of complex cancer pain, P307; Szmuda T, 2020, PUBLIC HEALTH, V185, P21, DOI 10.1016/j.puhe.2020.05.041; Tanaka M., 2021, Dig Dis Interv, V05, P137; Tzelios C, 2022, PUBLIC HEALTH ACTION, V12, P180, DOI 10.5588/pha.22.0046; Weintraub Karen., 2013, USA Today	37	15	15	8	9	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	1051-0443	1535-7732		J VASC INTERV RADIOL	J. Vasc. Interv. Radiol.	OCT	2023	34	10					1760	+		10.1016/j.jvir.2023.05.037	http://dx.doi.org/10.1016/j.jvir.2023.05.037		SEP 2023	41	Radiology, Nuclear Medicine & Medical Imaging; Peripheral Vascular Disease	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging; Cardiovascular System & Cardiology	U6TL8	37330210	Bronze			2024-07-03	WOS:001086109000001
J	Caruccio, L; Cirillo, S; Polese, G; Solimando, G; Sundaramurthy, S; Tortora, G				Caruccio, Loredana; Cirillo, Stefano; Polese, Giuseppe; Solimando, Giandomenico; Sundaramurthy, Shanmugam; Tortora, Genoveffa			Can ChatGPT provide intelligent diagnoses? A comparative study between predictive models and ChatGPT to define a new medical diagnostic bot	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Intelligent diagnosis; Traditional ML; ChatGPT; Google BARD; Comparative analysis	SYSTEM	Intelligent diagnosis processes rely on Artificial Intelligence (AI) techniques to provide possible diagnoses by analyzing patient data and medical information. To make accurate and quick diagnoses, it is possible to use AI tools to efficiently analyze huge amounts of data and find patterns that a clinician might miss. In recent years, new large language models (LLMs), such as ChatGPT and Google BARD, have shown remarkable capabilities in several domains, including intelligent diagnostics. This research aims to compare the performances of ChatGPT and traditional machine learning models for making diagnoses of low- and medium- risk diseases only based on their symptoms. On the basis of our study, we defined four research questions: RQ1) What are the benefits and limitations of using ChatGPT in intelligent diagnosis? RQ2) How do traditional machine learning approaches compare to ChatGPT for intelligent diagnosis? RQ3) How does ChatGPT compare with other LLMs and domain-specific natural language processing models in the intelligent diagnosis tasks?, and RQ4) What are the implications of the predictive models and ChatGPT for healthcare, and how can they be used to support people?. To answer these RQs, we first evaluate the performances of different engines of ChatGPT, also introducing a new prompt engineering methodology specifically tailored for achieving accurate diagnostic outcomes. Moreover, we compare these results with those achieved by different predictive models trained for intelligent diagnosis tasks, i.e., Google BARD, and two domain-specific NLP models. Finally, we propose a new interactive bot available for users that relies on the best-performing models evaluated in the previous steps. The experiments have been conducted using two medical datasets for disease prediction consisting of more than 100 symptoms associated with several diagnoses.	[Caruccio, Loredana; Cirillo, Stefano; Polese, Giuseppe; Solimando, Giandomenico; Tortora, Genoveffa] Univ Salerno, Dept Comp Sci, Salerno, Fisciano, Italy; [Sundaramurthy, Shanmugam] SRM Inst Sci & Technol, Dept Comp Technol, Kattankulathur, Tamilnadu, India	University of Salerno; SRM Institute of Science & Technology Chennai	Cirillo, S (corresponding author), Univ Salerno, Dept Comp Sci, Salerno, Fisciano, Italy.	lcaruccio@unisa.it; scirillo@unisa.it; gpolese@unisa.it; gsolimando@unisa.it; shanmugam.network13@gmail.com; tortora@unisa.it	Polese, Giuseppe/CAG-5264-2022; S, Shanmugam/ABU-3954-2022; Cirillo, Stefano/ABG-6171-2020	Polese, Giuseppe/0000-0002-8496-2658; S, Shanmugam/0000-0001-6935-4980; Cirillo, Stefano/0000-0003-0201-2753; Solimando, Giandomenico/0009-0000-6627-8820; Caruccio, Loredana/0000-0002-2418-1606				Afrash M. R., 2022, J BIOSTATISTICS EPID; Akula V.G., 2015, FUZZY EXPERT SYSTEMS, P21; Ali Stephen R, 2022, J Plast Reconstr Aesthet Surg, V75, P2387, DOI 10.1016/j.bjps.2022.04.072; Amann Julia, 2022, PLOS Digit Health, V1, pe0000016, DOI 10.1371/journal.pdig.0000016; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Awaysheh A, 2019, VET PATHOL, V56, P512, DOI 10.1177/0300985819829524; Bhakta NR, 2022, CHEST, V161, P288, DOI 10.1016/j.chest.2021.08.053; Black Sid, 2021, YOU USE THIS SOFTWAR, P58; Breve B, 2022, DMSVIVA 2022 P 28 IN, P23; Cartolovni A, 2022, INT J MED INFORM, V161, DOI 10.1016/j.ijmedinf.2022.104738; Chan Kai Siang, 2019, JMIR Med Educ, V5, pe13930, DOI 10.2196/13930; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung K, 2016, INFORM TECHNOL MANAG, V17, P1, DOI 10.1007/s10799-015-0251-3; Cunningham P, 2000, ARTIF INTELL MED, V20, P217, DOI 10.1016/S0933-3657(00)00065-8; Czmil A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020992; Fernandes M, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101762; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao S, 2019, ARTIF INTELL MED, V101, DOI 10.1016/j.artmed.2019.101726; Gillioz Anthony, 2020, 2020 15th Conference on Computer Science and Information Systems (FedCSIS), P179, DOI 10.15439/2020F20; Gu CF, 2024, BRIT J OPHTHALMOL, V108, P424, DOI 10.1136/bjo-2022-322940; Henderson M, 2019, Arxiv, DOI arXiv:1906.01543; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hong SD, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1614, DOI 10.1145/3394486.3403212; Imanov E, 2019, ADV INTELL SYST, V896, P137, DOI 10.1007/978-3-030-04164-9_20; Jain N L, 1996, Proc AMIA Annu Fall Symp, P542; Jariwala N, 2023, WATER RES M, P133; Jiang Y., 2022, MULTIMODAL AL HEALTH, P91; Khan N, 2023, EXPERT SYST APPL, V220, DOI 10.1016/j.eswa.2023.119638; Kiliçarslan S, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119503; Kim D, 2022, J PERS MED, V12, DOI 10.3390/jpm12020136; Krstajic D, 2014, J CHEMINFORMATICS, V6, DOI 10.1186/1758-2946-6-10; Kumari S., 2021, Int J Cogn Comput Eng, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]; Lapadula P, 2020, HEALTH TECHNOL-GER, V10, P1485, DOI 10.1007/s12553-020-00468-9; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liashchynskyi P, 2019, Arxiv, DOI arXiv:1912.06059; Liednikova A., 2021, NLPMC 2021 2 WORKSH, P21; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu QL, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P201; Liu S., 2023, medRxiv; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Medenilla A., 2023, PLoS Digital Health, V2; Mousavi SM, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106943; Palaniappan S, 2008, I C COMP SYST APPLIC, P108, DOI 10.1109/AICCSA.2008.4493524; Rajpal S, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120130; Rao A., 2023, J AM COLL RADIOL, P15; Rao Arya S., 2023, medRxiv; Rodriguez-Arrastia M, 2022, J NURS MANAGE, V30, P3874, DOI 10.1111/jonm.13630; Salman ME, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117148; Sanchez-Martinez S, 2022, FRONT CARDIOVASC MED, V8, DOI 10.3389/fcvm.2021.765693; Shojaei S, 2023, EXPERT SYST APPL, V220, DOI 10.1016/j.eswa.2023.119709; Steimann F, 2001, ARTIF INTELL MED, V21, P131, DOI 10.1016/S0933-3657(00)00077-4; Sundaramurthy S, 2023, J INTELL FUZZY SYST, V44, P125, DOI 10.3233/JIFS-221252; Sutton RT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0221-y; Szlosek Donald A, 2016, EGEMS (Wash DC), V4, P1222, DOI 10.13063/2327-9214.1222; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]; Vasileiou MV, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/4876512; Vrbancic G, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115834; Wardrope A, 2020, NEUROL-CLIN PRACT, V10, P96, DOI 10.1212/CPJ.0000000000000726; West D, 2005, EUR J OPER RES, V162, P532, DOI 10.1016/j.ejor.2003.10.013; Yu B., 2023, EXPERT SYST APPL; Zhong C, 2023, Arxiv, DOI arXiv:2004.14254; Zhou HY, 2023, NAT BIOMED ENG, V7, P743, DOI 10.1038/s41551-023-01045-x	62	15	15	31	89	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	JAN	2024	235								121186	10.1016/j.eswa.2023.121186	http://dx.doi.org/10.1016/j.eswa.2023.121186		AUG 2023	14	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	R9XW2		hybrid			2024-07-03	WOS:001067816800001
J	Shi, XF; Hu, M; Ren, FJ; Shi, P; Nakagawa, S				Shi, Xuefeng; Hu, Min; Ren, Fuji; Shi, Piao; Nakagawa, Satoshi			Aspect based sentiment analysis with instruction tuning and external knowledge enhanced dependency graph	APPLIED INTELLIGENCE			English	Article						ABSA; Instruction tuning; GCN; Affective knowledge; Bi-layer sentiment representation	NETWORK	Aspect-Based Sentiment Analysis (ABSA) is generally defined as a fine-grained task in Natural Language Processing (NLP). Recently, the integration of the Large Language Model (LLM) and Graph Convolutional Network (GCN) has been widely studied to excavate the underlying contextual information and support the sentiment polarity prediction. However, in existing research, the LLM is usually employed directly to generate the contextual feature representation without any specific instructions, which is not suitable for learning the domain language corpus. In addition, the existing works usually fuse the contextual feature and graph feature by GCN simply, and it ignores further specific processing to highlight the sentiment representations before the model's final outputting. To tackle these two imperfections, this work proposes a novel ABSA model Instruction Tuning-based Graph Convolutional Network (ITGCN) to implement the subtask of predicting sentiment polarities(R2), which leverages the instructed LLM to generate the task-oriented contextual representation and the GCN to exploit the external affective knowledge-assisted syntactic features. In the proposed ITGCN, firstly, the inputting sentence is reconstructed with the designed task-specific instructions, which tell the LLM what is the target in the input. Secondly, this work's dependency graph, before being processed by GCN, is weighted by the affective knowledge extracted from SenticNet. This kind of dependency graph is endowed with affective information, which is closer to the intention of the related study. Finally, to learn more structured knowledge, a bi-layer sentiment representation module is proposed and utilized to enhance the feature representation. To validate the effectiveness of the proposed ITGCN, extensive experiments have been conducted on five public and available datasets. The proposed ITGCN achieves competitive performance and outperforms the selected state-of-the-art baselines, obviously.	[Shi, Xuefeng; Hu, Min; Shi, Piao] Hefei Univ Technol, Sch Comp & Informat, Danxia Rd, Hefei 230601, Anhui, Peoples R China; [Shi, Xuefeng; Hu, Min; Shi, Piao] Hefei Univ Technol, Anhui Prov Key Lab Affect, Danxia Rd, Hefei 230601, Anhui, Peoples R China; [Ren, Fuji] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Xiyuan Ave, Chengdu 611731, Sichuan, Peoples R China; [Nakagawa, Satoshi] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo 1138654, Japan	Hefei University of Technology; Hefei University of Technology; University of Electronic Science & Technology of China; University of Tokyo	Shi, XF (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Danxia Rd, Hefei 230601, Anhui, Peoples R China.; Shi, XF (corresponding author), Hefei Univ Technol, Anhui Prov Key Lab Affect, Danxia Rd, Hefei 230601, Anhui, Peoples R China.	2020010107@mail.hfut.edu.cn; jsjxhumin@hfut.edu.cn; renfuji@uestc.edu.cn; shipiao@mail.hfut.edu.cn; nakagawa@isi.imi.i.u-tokyo.ac.jp			National Natural Science Foundation of China [62176084, 62176083]; National Natural Science Foundation of China [PA2022GDSK0066, PA2022GDSK0068]; Fundamental Research Funds for the Central Universities of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities of China(Fundamental Research Funds for the Central Universities)	This research was funded by the National Natural Science Foundation of China under Grant 62176084 and Grant 62176083, and in part by the Fundamental Research Funds for the Central Universities of China under Grant PA2022GDSK0066 and Grant PA2022GDSK0068.	Alkatheiri MS, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.107950; An WB, 2023, IEEE T COMPUT SOC SY, V10, P403, DOI 10.1109/TCSS.2022.3148866; Cao YK, 2023, IEEE T AFFECT COMPUT, V14, P3362, DOI 10.1109/TAFFC.2022.3233020; Cheng LC, 2022, NEUROCOMPUTING, V489, P9, DOI 10.1016/j.neucom.2022.03.027; Cuiy LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1835; Dai JQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1816; Deng JW, 2021, RESEARCH-CHINA, V2021, DOI 10.34133/2021/3067943; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng S, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109975; Gu TQ, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110025; Gu TQ, 2023, APPL INTELL, V53, P4366, DOI 10.1007/s10489-022-03630-0; Han X, 2022, AI OPEN, V3, P182, DOI 10.1016/j.aiopen.2022.11.003; Hannan MA, 2021, IEEE T POWER ELECTR, V36, P7349, DOI 10.1109/TPEL.2020.3041876; Hou X., 2021, P WORKSH TEXTGRAPHS, P83; Hu MH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P537; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643; Liu Y., 2019, CoRR abs/1907.11692; Lu Q, 2021, APPL INTELL, V51, P4408, DOI 10.1007/s10489-020-02095-3; Ma YK, 2018, COGN COMPUT, V10, P639, DOI 10.1007/s12559-018-9549-x; Ma YK, 2018, AAAI CONF ARTIF INTE, P5876; Ma YT, 2023, APPL INTELL, V53, P12985, DOI 10.1007/s10489-022-04023-z; Mencarini E, 2019, IEEE T HUM-MACH SYST, V49, P314, DOI 10.1109/THMS.2019.2919702; Phan MH, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3211; Pilar GD, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118817; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rani S, 2022, ACM T ASIAN LOW-RESO, V21, DOI 10.1145/3485243; Song Y, 2019, INT C ART NEUR NETW; Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380; Vaswani A, 2017, ADV NEUR IN, V30; Wang K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3229; Wang XY, 2021, NEUROCOMPUTING, V450, P91, DOI 10.1016/j.neucom.2021.03.092; Wang YL, 2022, ASIAN J INT LAW, DOI 10.1017/S2044251322000558; Wu HY, 2023, INFORM FUSION, V92, P289, DOI 10.1016/j.inffus.2022.12.004; Wu HY, 2022, KNOWL-BASED SYST, V236, DOI 10.1016/j.knosys.2021.107736; Wu H, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2438; Xu LXW, 2023, NEUROCOMPUTING, V518, P373, DOI 10.1016/j.neucom.2022.10.071; Zhang BW, 2020, IEEE-ACM T AUDIO SPE, V28, P2538, DOI 10.1109/TASLP.2020.3017093; Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568; Zhao AP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107220; Zhao GS, 2023, KNOWL-BASED SYST, V264, DOI 10.1016/j.knosys.2023.110326; Zhao M, 2023, NEURAL COMPUT APPL, V35, P14195, DOI 10.1007/s00521-023-08384-5; Zhao ZG, 2023, APPL INTELL, V53, P16138, DOI 10.1007/s10489-022-04307-4; Zhao ZG, 2022, NEUROCOMPUTING, V500, P124, DOI 10.1016/j.neucom.2022.05.045; Zhong Qihuang, 2023, IEEE Transactions on Knowledge and Data Engineering, P10098, DOI 10.1109/TKDE.2023.3250499; Zhou J, 2020, APPL INTELL, V50, P3367, DOI 10.1007/s10489-020-01760-x; Zhou J, 2020, INFORM SCIENCES, V513, P1, DOI 10.1016/j.ins.2019.11.048; Zhou YP, 2023, IEEE T DEPEND SECURE, V20, P4823, DOI 10.1109/TDSC.2023.3234599; Zhu ZF, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103223	49	0	0	8	8	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0924-669X	1573-7497		APPL INTELL	Appl. Intell.	APR	2024	54	8					6415	6432		10.1007/s10489-024-05492-0	http://dx.doi.org/10.1007/s10489-024-05492-0		MAY 2024	18	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UX1W3					2024-07-03	WOS:001222363600001
C	Minina, P; Sadovykh, A; Ivanov, V			IEEE Comp Soc	Minina, Polina; Sadovykh, Andrey; Ivanov, Vladimir			Detecting Security Requirements in GitHub Issues - Novel Dataset and SmallBERT-based model	2023 IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY AND SCIENCE, CLOUDCOM 2023	International Conference on Cloud Computing Technology and Science		English	Proceedings Paper	14th IEEE International Conference on Cloud Computing Technology and Science (CloudCom)	DEC 04-06, 2023	Naples, ITALY	IEEE		Security requirements; GitHub Issues; NLP; Classification; Dataset; Machine Learning; Deep learning; BERT		Cloud application security initiates with the analysis of security requirements in DevOps. This involves gathering, managing, and tracking requirements within integrated issue-tracking systems found in repositories like GitHub. DevOps offers advantages in cloud app development, such as accelerated deployment, improved collaboration, and enhanced reliability. In DevOps, while many security verification tools are automated, security requirements analysis often relies on manual procedures. User feedback plays a pivotal role in shaping cloud application requirements, and the industry actively seeks automation solutions to expedite development. Prior research has demonstrated the limited performance of conventional NLP models trained on established datasets, such as PROMISE, when employed in the context of GitHub Issues. Recent studies have explored the integration of deep learning, particularly leveraging modern large language models and transfer learning architectures, to address requirements engineering challenges. However, a significant issue persists - the transferability of these models. While these models excel when applied to datasets similar to those they were trained on, their performance often drastically falls when dealing with external domains. In our paper, we introduce an automated method for classifying requirements within issue trackers. This method utilizes a novel dataset comprising 12,000 security and non-security issues collected from open GitHub repositories. We employed a SmallBERT-based model for training and conducted a series of experiments. Our research reaffirms the challenge related to the transferability of NLP models. Simultaneously, our model yields highly promising results when applied to GitHub Issues, even in challenging scenarios involving issues from projects that were not part of the training dataset and structured requirements texts from the PROMISE dataset. In summary, our approach significantly contributes to enhancing DevOps practices within cloud applications by automating security requirements analysis.	[Minina, Polina; Sadovykh, Andrey; Ivanov, Vladimir] SOFTEAM, Paris, France		Minina, P (corresponding author), SOFTEAM, Paris, France.				Horizon 2020 program [957212]	Horizon 2020 program	This work is partially supported by the VeriDevOps [34] project funded by the Horizon 2020 program under the grant agreement No. 957212.	Abualhaija S, 2019, INT REQUIR ENG CONF, P51, DOI 10.1109/RE.2019.00017; Ajagbe M, 2022, 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022), P309, DOI 10.1109/RE54965.2022.00046; Ameri K., 2021, Cybert: Cybersecurity claim classification by fine-tuning the bert language model; [Anonymous], 2021, VeriDevOps: Automated Protection and Prevention to Meet Security Requirements in DevOps, P1330; Bishop C., 2006, PATTERN RECOGN; Casillo F, 2022, INFORM SOFTWARE TECH, V146, DOI 10.1016/j.infsof.2022.106853; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Clancy T, 1995, The chaos report; Cleland-Huang J, 2007, REQUIR ENG, V12, P103, DOI 10.1007/s00766-007-0045-1; Dalpiaz F., 2018, Detecting terminological ambiguity in user stories: Tool and experimentation; Dalpiaz F, 2019, INT REQUIR ENG CONF, P142, DOI 10.1109/RE.2019.00025; Deshpande G., 2021, 2021 IEEE 29 INT REQ; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ferrari A, 2017, INT REQUIR ENG CONF, P502, DOI 10.1109/RE.2017.29; GitHub, US; Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345; Groen EC, 2017, INT REQUIR ENG CONF, P80, DOI 10.1109/RE.2017.73; Habib MK, 2021, 29TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW 2021), P153, DOI 10.1109/REW53955.2021.00027; Hey T, 2020, INT REQUIR ENG CONF, P169, DOI 10.1109/RE48521.2020.00028; Ivanov V., 2021, INT C ANAL IMAGES SO, P17; Kissel R., 2013, Glossary of key information security terms; Li G., 2022, IEEE Access; Limaylla-Lunarejo MI, 2022, 2022 30TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE (RE 2022), P270, DOI 10.1109/RE54965.2022.00039; Minina P, Github issues harvesting and model training; Minina P., 2023, Github user issues harvesting, DOI [10.5281/zenodo.8034795, DOI 10.5281/ZENODO.8034795]; Perez-Verdejo J. M., 2021, Requirements and github issues: An automated approach for quality requirements classification; Rajapakse RN, 2022, INFORM SOFTWARE TECH, V141, DOI 10.1016/j.infsof.2021.106700; Riaz M, 2014, INT REQUIR ENG CONF, P183, DOI 10.1109/RE.2014.6912260; Shirabad J. Sayyad, 2005, The PROMISE repository of software engineering databases; Subbiah V, 2022, Automatic classification and extraction of non-functional requirements from text files: a supervised learning approach; Turc I, 2019, Arxiv, DOI arXiv:1908.08962; Winkler J, 2016, 2016 IEEE 24TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P39, DOI [10.1109/REW.2016.021, 10.1109/REW.2016.16]; Winkler JP, 2018, LECT NOTES COMPUT SC, V10753, P57, DOI 10.1007/978-3-319-77243-1_4; Zhao S., 2019, arXiv	34	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2330-2194		979-8-3503-3982-6	INT CONF CLOUD COMP			2023							315	318		10.1109/CloudCom59040.2023.00058	http://dx.doi.org/10.1109/CloudCom59040.2023.00058			4	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7SQ		Green Submitted			2024-07-03	WOS:001195989900044
C	Storhaug, A; Li, JY; Hu, TY			IEEE	Storhaug, Andre; Li, Jingyue; Hu, Tianyuan			Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING, ISSRE	Proceedings International Symposium on Software Reliability Engineering		English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART		smart contract; code generation; machine learning; software security		Auto-completing code enables developers to speed up coding significantly. Recent advances in transformer-based large language model (LLM) technologies have been applied to code synthesis. However, studies show that many of such synthesized codes contain vulnerabilities. We propose a novel vulnerability-constrained decoding approach to reduce the amount of vulnerable code generated by such models. Using a small dataset of labeled vulnerable lines of code, we fine-tune an LLM to include vulnerability labels when generating code, acting as an embedded classifier. Then, during decoding, we deny the model to generate these labels to avoid generating vulnerable code. To evaluate the method, we chose to automatically complete Ethereum Blockchain smart contracts (SCs) as the case study due to the strict requirements of SC security. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397 Ethereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning took more than one week using ten GPUs. The results showed that our fine-tuned model could synthesize SCs with an average BLEU (BiLingual Evaluation Understudy) score of 0.557. However, many codes in the auto-completed SCs were vulnerable. Using the code before the vulnerable line of 176 SCs containing different types of vulnerabilities to auto-complete the code, we found that more than 70% of the auto-completed codes were insecure. Thus, we further fine-tuned the model on other 941 vulnerable SCs containing the same types of vulnerabilities and applied vulnerability-constrained decoding. The fine-tuning took only one hour with four GPUs. We then auto-completed the 176 SCs again and found that our approach could identify 62% of the code to be generated as vulnerable and avoid generating 67% of them, indicating the approach could efficiently and effectively avoid vulnerabilities in the auto-completed code.	[Storhaug, Andre; Li, Jingyue] Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway; [Hu, Tianyuan] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China	Norwegian University of Science & Technology (NTNU); Southeast University - China	Storhaug, A (corresponding author), Norwegian Univ Sci & Technol, Dept Comp Sci, Trondheim, Norway.	andre.storhaug@ntnu.no; jingyue.li@ntnu.no; tianyuanhu@seu.edu.cn		Storhaug, Andre/0000-0002-5321-7196	National Key Research and Development Program of China [2019YFE0105500]; Research Council of Norway [309494]; Key Research and Development Program of Jiangsu Province [BE2021002-3]; Chinese Scholarship Council (CSC) [202106090057]	National Key Research and Development Program of China; Research Council of Norway(Research Council of Norway); Key Research and Development Program of Jiangsu Province; Chinese Scholarship Council (CSC)(China Scholarship Council)	This work is jointly supported by the National Key Research and Development Program of China (No. 2019YFE0105500) and the Research Council of Norway (No. 309494) and the Key Research and Development Program of Jiangsu Province (No. BE2021002-3). Tianyuan Hu thanks the Chinese Scholarship Council (CSC) for financial support (202106090057).	Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Alon U., 2018, code2vec: Learning distributed representations of code; [Anonymous], 2022, Decrypted; [Anonymous], 2021, Foundations of nlp explained; Atzei N, 2017, LECT NOTES COMPUT SC, V10204, P164, DOI 10.1007/978-3-662-54455-6_8; Chen M., 2021, arXiv; Choi J, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P227, DOI 10.1109/ASE51524.2021.9678888; Christopoulou Fenia, 2022, arXiv; DeepAi, 2022, What is the jaccard index?; Derner E., 2023, Beyond the safeguards: Exploring the security risks of ChatGPT; Durieux T, 2020, PROC INT CONF SOFTW, P530, DOI 10.1145/3377811.3380364; Eghbali A, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556903; EleutherAI, 2022, Eleutherai; Feist J, 2019, 2019 IEEE/ACM 2ND INTERNATIONAL WORKSHOP ON EMERGING TRENDS IN SOFTWARE ENGINEERING FOR BLOCKCHAIN (WETSEB 2019), P8, DOI 10.1109/WETSEB.2019.00008; Freitag Y., 2017, P 1 WORKSHOP NEURAL, P56, DOI [10.18653/v1/W17-3207, DOI 10.18653/V1/W17-3207]; Gao L., 2020, The pile: An 800gb dataset of diverse text for language modeling; Ghaleb Asem, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P415, DOI 10.1145/3395363.3397385; GitHub, 2022, Your ai pair programmer; github, 2018, Mythril: an open-source security analysis tool for ethereum smart contracts; Hokamp C, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1535, DOI 10.18653/v1/P17-1141; Hu JE, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P839; Hu T., 2023, Why smart contracts reported as vulnerable were not exploited?; Iyer S., 2018, Mapping language to code in programmatic context; Janner M, 2021, ADV NEUR IN, V34; Jiang B, 2018, IEEE INT CONF AUTOM, P259, DOI 10.1145/3238147.3238177; Khoury R., 2023, How secure is code generated by chatgpt?; Le H., 2022, Coderl: Mastering code generation through pretrained models and deep reinforcement learning; Li B., 2021, arXiv; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu XD, 2020, COMPUT METHOD BIOMEC, V23, P1102, DOI 10.1080/10255842.2020.1789119; Lu Y., 2021, Roformer: Enhanced transformer with rotary position embedding; Luu L., CCS 16 P 2016 ACM SI; Microsoft, 2022, Deepspeed; Microsoft, 2023, Introducing microsoft security copilot: Empowering defenders at the speed of ai; Nguyen TD, 2020, PROC INT CONF SOFTW, P778, DOI 10.1145/3377811.3380334; OpenAI, 2022, Introducing ChatGPT, P1; Ouyang L., 2022, NEURIPS; Pearce H., 2021, Asleep at the keyboard? assessing the security of github copilot's code contributions; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Post Matt, 2018, Long Papers, P1314; Radford A., 2018, IMPROVING LANGUAGE U; Ren M, 2021, ISSTA '21: PROCEEDINGS OF THE 30TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P566, DOI 10.1145/3460319.3464837; SafeMath, 2022, About us; Shojaee P., 2023, Execution-based code generation using deep reinforcement learning; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Woolf M, 2021, Fun and dystopia with ai-based code generation using gpt-j-6b; Zamani M, 2022, Secure-by-construction synthesis of cyber-physical systems	47	1	1	4	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1071-9458		979-8-3503-1594-3	PROC INT SYMP SOFTW			2023							683	693		10.1109/ISSRE59848.2023.00035	http://dx.doi.org/10.1109/ISSRE59848.2023.00035			11	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KU		Green Submitted			2024-07-03	WOS:001096886300060
J	Ohta, K; Ohta, S				Ohta, Keiichi; Ohta, Satomi			The Performance of GPT-3.5, GPT-4, and Bard on the Japanese National Dentist Examination: A Comparison Study	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						japan; national dentist examination; artificial intellinge in dentistry; google bard; chatgpt-3.5; chatgpt-4		PurposeThis study aims to evaluate the performance of three large language models (LLMs), the Generative Pre -trained Transformer (GPT)-3.5, GPT-4, and Google Bard, on the 2023 Japanese National Dentist Examination (JNDE) and assess their potential clinical applications in Japan.MethodsA total of 185 questions from the 2023 JNDE were used. These questions were categorized by question type and category. McNemar's test compared the correct response rates between two LLMs, while Fisher's exact test evaluated the performance of LLMs in each question category.ResultsThe overall correct response rates were 73.5% for GPT-4, 66.5% for Bard, and 51.9% for GPT-3.5. GPT-4 showed a significantly higher correct response rate than Bard and GPT-3.5. In the category of essential questions, Bard achieved a correct response rate of 80.5%, surpassing the passing criterion of 80%. In contrast, both GPT-4 and GPT-3.5 fell short of this benchmark, with GPT-4 attaining 77.6% and GPT-3.5 only 52.5%. The scores of GPT-4 and Bard were significantly higher than that of GPT-3.5 (p<0.01). For general questions, the correct response rates were 71.2% for GPT-4, 58.5% for Bard, and 52.5% for GPT-3.5. GPT-4 outperformed GPT-3.5 and Bard (p<0.01). The correct response rates for professional dental questions were 51.6% for GPT-4, 45.3% for Bard, and 35.9% for GPT-3.5. The differences among the models were not statistically significant. All LLMs demonstrated significantly lower accuracy for dentistry questions compared to other types of questions (p<0.01).ConclusionsGPT-4 achieved the highest overall score in the JNDE, followed by Bard and GPT-3.5. However, only Bard surpassed the passing score for essential questions. To further understand the application of LLMs in clinical dentistry worldwide, more research on their performance in dental examinations across different languages is required.	[Ohta, Keiichi] Kobe Univ, Sch Med, Kobe, Japan; [Ohta, Satomi] Dent, Kobe, Japan	Kobe University	Ohta, K (corresponding author), Kobe Univ, Sch Med, Kobe, Japan.	2021kohta@gmail.com						Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; [Anonymous], 2023, Recent trends in dental health care; [Anonymous], 2023, The 116th National Dentist Examination; [Anonymous], 2023, Announcement of successful passage of the 117th National Medical Examination; Bard, 2023, About us; Beaulieu-Jones BR, 2023, medRxiv, DOI [10.1101/2023.07.16.23292743, 10.1101/2023.07.16.23292743, DOI 10.1101/2023.07.16.23292743]; ChatGPT, 2023, US; Chen YD, 2024, Arxiv, DOI arXiv:2209.07661; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Farajollahi Mehran, 2023, Iran Endod J, V18, P192; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haze T, 2023, INT J MED INFORM, V180, DOI 10.1016/j.ijmedinf.2023.105283; Iannantuono GM, 2023, Oncology, DOI [10.1101/2023, DOI 10.1101/2023]; Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42924; Koga S, 2023, PATHOL INT, V73, P618, DOI 10.1111/pin.13382; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kunitsu Y, 2023, JMIR MED EDUC, V9, DOI 10.2196/48452; Lai UH, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1240915; Newton PM., 2023, PREPRINT, DOI DOI 10.35542/OSF.IO/SYTU3; Suárez A, 2024, INT ENDOD J, V57, P108, DOI 10.1111/iej.13985; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2	23	4	4	9	9	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	DEC 12	2023	15	12							e50369	10.7759/cureus.50369	http://dx.doi.org/10.7759/cureus.50369			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	CS0K8	38213361	gold			2024-07-03	WOS:001127111600028
J	Puyt, RW; Lie, FB; Madsen, DO				Puyt, Richard W.; Lie, Finn Birger; Madsen, Dag Oivind			From SOFT approach to SWOT analysis, a historical reconstruction	JOURNAL OF MANAGEMENT HISTORY			English	Article; Early Access						SWOT analysis; Americanization; Strategy-as-practice; Management consultants; Anti-histories; SOFT approach	STRATEGIC MANAGEMENT; CORPORATE; AMERICAN; MODELS; EVOLUTION; JAPANESE; TIME	PurposeThe purpose of this study is to revisit the conventional wisdom about a key contribution [i.e. strengths, weaknesses, opportunities, threats (SWOT) analysis] in the field of strategic management. The societal context and the role of academics, consultants and executives is taken into account in the emergence of SWOT analysis during the 1960-1980 period as a pivotal development within the broader context of the satisfactory, opportunities, faults, threats (SOFT) approach. The authors report on both the content and the approach, so that other scholars seeking to invigorate indigenous theories and/or underreported strategy practices will thrive.Design/methodology/approachApplying a historiographic approach, the authors introduce an evidence-based methodology for interpreting historical sources. This methodology incorporates source criticism, triangulation and hermeneutical interpretation, drawing upon insights from robust evidence through three iterative stages.FindingsThe underreporting of the SOFT approach/SWOT analysis can be attributed to several factors, including strategy tools being integrated into planning frameworks rather than being published as standalone materials; restricted circulation of crucial long-range planning service/theory and practice of planning reports due to copyright limitations; restricted access to the Stanford Research Institute Planning Library in California; and the enduring popularity of SOFT and SWOT variations, driven in part by their memorable acronyms.OriginalityIn the spirit of a renaissance in strategic planning research, the authors unveil novel theoretical and social connections in the emergence of SWOT analysis by combining evidence from both theory and practice and delving into previously unexplored areas.Research implicationsCaution is advised for scholars who examine the discrete time frame of 1960-1980 through mere bibliometric techniques. This study underscores the risks associated with gathering incomplete and/or inaccurate data, emphasizing the importance of triangulating evidence beyond scholarly databases. The paradigm shift of strategic management research due to the advent of large language models poses new challenges and the risk of conserving and perpetuating academic urban legends, myths and lies if training data is not adequately curated.	[Puyt, Richard W.] Univ Twente, Fac Behav Management & Social Sci BMS, Enschede, Netherlands; [Lie, Finn Birger] Jafin Invest SL, Bilbao, Spain; [Lie, Finn Birger] TAPP Res Arch, Bilbao, Spain; [Madsen, Dag Oivind] Univ South Eastern Norway, USN Sch Business, Dept Business Mkt & Law, Kongsberg, Norway	University of Twente; University College of Southeast Norway	Puyt, RW (corresponding author), Univ Twente, Fac Behav Management & Social Sci BMS, Enschede, Netherlands.	r.w.puyt@utwente.nl			Norwegian Productivity Institute; KGaA	Norwegian Productivity Institute; KGaA	The authors would like to thank subject matter experts subject matter experts William Guns, CEO and President of Strategic Business Insights; William D. Guth, Professor Emeritus of Management and Strategy, New York University Stern School of Business; Albert S. Humphrey, former member of the TAPP group at the Stanford Research Institute; Birger Lie, Norwegian Productivity Institute; Peter Lorange, Professor Emeritus of Strategy at BI Norwegian Business School and Honorary President of IMD; Don L. Nielson, retired vice-president of Computer Science and Technology Division at SRI International; William S. Royce, former director of the LRPS and the Executive Seminars in Business Planning at SRI International; Joachim Scholtyseck, Professor of modern and contemporary history at the University of Bonn, Celeste P.M. Wilderom, Professor Emeritus of Industrial Engineering and Business Information Systems, University of Twente; Henk Kroon, manager educational service center, University of Twente; Sjoerd Beelen, subject librarian at the University of Applied Sciences Utrecht, Thomas Seidel, corporate archivist at Henkel AG and Co. KGaA and the three anonymous reviewers of the Journal of Management History for their invaluable contributions to enhancing this paper.	Abell D.F., 1979, STRATEGIC MARKET PLA; Aguilar F.J., 1965, Formulating Corporate Strategy: Scanning the Environment; Aguilar F. J., 1967, Scanning the Business Environment; Aksnes DW, 2019, SAGE OPEN, V9, DOI 10.1177/2158244019829575; ALBROOK RC, 1969, FORTUNE, V80, P128; Allen J.K., 1967, Konzernarchiv Henkel Acc, V314; Amdam R.P., 1998, The European Productivity Agency, the Norwegian Productivity Institute and Management Education, V1st ed.; Andrews K.R., 1967, Letter to Albert S. Humphrey about attending an upcoming LRPS/TAPP executive seminar in planning; [Anonymous], 1968, The Guardian8 October, P12; [Anonymous], 1986, Financial Times9 August, P5; [Anonymous], 1987, Financial Times24 March, P20; [Anonymous], 1966, The Guardian21 May, P10; [Anonymous], 1979, Financial Times11 August, P20; [Anonymous], 1966, Unobtrusive Measures: Nonreactive Research in the Social Sciences; Ansoff H.I., 1967, The evolution of corporate planning; Ansoff H.I., 1965, Corporate strategy: An analytic approach to business policy for growth and expansion; Ansoff H.I., 1969, BUSINESS STRATEGY; ANSOFF HI, 1975, CALIF MANAGE REV, V18, P21, DOI 10.2307/41164635; Anthony R.N., 1965, PLANNING CONTROL SYS; Antoniou P.H., 2006, IGOR ANSOFF ANTHOLOG; Argenti J., 1974, SYSTEMATIC CORPORATE; Aris S., 1966, Sunday Times, V25; Barends E., 2014, EVIDENCE BASED MANAG; Barjot D., 2003, Entreprises et Histoire, V32, P41, DOI [10.3917/eh.032.0041, DOI 10.3917/EH.032.0041]; BARLEY SR, 1992, ADMIN SCI QUART, V37, P363, DOI 10.2307/2393449; Barney JB, 2002, ACAD MANAGE EXEC, V16, P53, DOI 10.5465/AME.2002.7173521; Bennett P.W., 1974, Journal of General Management, V2, P12, DOI [10.1177/030630707400200102, DOI 10.1177/030630707400200102]; Benzaghta M.A., 2021, J. Glob. Bus. Insights, V6, P55, DOI [DOI 10.5038/2640-6489.6.1.1148, 10.5038/2640-6489.6.1.1148]; Berghahn VolkerRolf., 1986, AMERICANISATION W GE; Bjarnar O., 1986, The Americanisation of European Business: The Marshall Plan and the Transfer of US Management Models, P1; Mello JAVB, 2022, CUAD GEST, V22, P81, DOI 10.5295/cdg.211472jv; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bodrozic Z, 2018, ADMIN SCI QUART, V63, P85, DOI 10.1177/0001839217704811; Briner R.B., 2018, People and Strategy, V42, P16; Bruce R.B., 1962, P LONG RANG PLANN SE; BusinessWeek, 1965, BusinessWeek, V1848, P88; BusinessWeek, 1961, BusinessWeek, V1647, P92; BusinessWeek, 1963, BusinessWeek, V1761, P54; BusinessWeek, 1967, BusinessWeek, V1960, P106; Chapman A., 2019, SWOT analysis; Christensen C.R., 1973, Business Policy-Text and Cases, V3rd ed.; Christensen H.C., 1969, Norsk Productivitetsinstitutt, P1; Cummings S., 2017, A New History of Management, DOI [10.1017/9781316481202, DOI 10.1017/9781316481202]; Cummings S, 2011, ACAD MANAG LEARN EDU, V10, P77, DOI 10.5465/AMLE.2011.59513274; CURRILL DL, 1977, LONG RANGE PLANN, V10, P70, DOI 10.1016/0024-6301(77)90106-6; Czakon W, 2019, PROBL ZARZ, V17, P9, DOI 10.7172/1644-9584.84.1; Das R, 2023, MANAG REV Q, V73, P1237, DOI 10.1007/s11301-022-00273-w; Das R, 2018, BENCHMARKING, V25, P138, DOI 10.1108/BIJ-08-2016-0123; De Bruyckere P, 2015, URBAN MYTHS ABOUT LEARNING AND EDUCATION; Drucker P., 1954, The Practice of Management; ENGLAND GW, 1971, ACAD MANAGE J, V14, P425, DOI 10.5465/255058; Erçek M, 2016, BUS HIST, V58, P89, DOI 10.1080/00076791.2015.1044522; Ewing D.W., 1958, Long-range Planning for Management, V1st ed.; Ewing D.W., 1963, Long-range Planning for Management, V2nd ed.; Fernandes E, 2024, LONG RANGE PLANN, V57, DOI 10.1016/j.lrp.2024.102426; Forbes, 1966, Forbes, V97, P46; Forbes, 1969, Forbes, V104, P48; Forbes M.S., 1964, Forbes, V93, P20; Forbes M.S., 1963, Forbes, V91, P11; Fosbrook Bretton., 2017, SCENARIOS BECAME COR; Freedgood S., 1965, Fortune, V72, P152; Fusch P., 2018, Journal of Social Change, VOL, V10, DOI [10.5590/JOSC.2018.10.1.02, DOI 10.5590/JOSC.2018.10.1.02]; Gaddis JohnLewis., 2002, The Landscape of History: How Historians Map the Past; Ghazinoory S, 2011, J BUS ECON MANAG, V12, P24, DOI 10.3846/16111699.2011.555358; Ghemawat P, 2002, BUS HIST REV, V76, P37, DOI 10.2307/4127751; Ghemawat P., 2017, Evidence supporting the claim made in business horizons (2002); Ghemawat P, 2016, BUS HIST REV, V90, P727, DOI 10.1017/S0007680516000702; GILMORE FF, 1962, HARVARD BUS REV, V40, P61; Goodrick E, 2011, WORK OCCUPATION, V38, P372, DOI 10.1177/0730888411406824; Grel E., 2017, Journal of International Social Research, V10, P994, DOI [10.17719/jisr.2017.1832, DOI 10.17719/JISR.2017.1832]; Groom B., 1984, Financial Times, V29, P16; Gross T, 2015, CAT CLASSIF Q, V53, P1, DOI 10.1080/01639374.2014.917447; Guns W, 2020, Summarizing research efforts into: the origins of the planning library, the organization of LRPS/TAPP, and discussing SRI history; Guth W.D., 2017, Confirmation letter on the origins of SWOT analysis, summarizing the most important topics based on the 3 interviews between William D. Guth and author 1; Guzzardi W., 1965, Fortune, V71, P138; HARGREAVES D, 1969, LONG RANGE PLANN, V1, P28, DOI 10.1016/0024-6301(69)90069-7; Hartley NT, 2006, J MANAG HIST, V12, P278, DOI 10.1108/17511340610670188; Hatch MJ, 2017, ADMIN SCI QUART, V62, P657, DOI 10.1177/0001839217692535; HAYASHI K, 1978, ACAD MANAGE J, V21, P211, DOI 10.5465/255755; Helms MM, 2010, J STRATEGY MANAG, V3, P215, DOI 10.1108/17554251011064837; Hilger S., 2003, German and Japanese Business in the Boom Years, V1st ed., P193; Hilger S., 2000, Entreprises et Histoire, V25, P46, DOI [10.3917/eh.025.0046, DOI 10.3917/EH.025.0046]; Hilger Susanne., 2004, Amerikanisierung" deutscher Unternehmen: Wettbewerbsstrategien und Unternehmenspolitik bei Henkel, Siemens und Daimler-Benz; Hill T, 1997, LONG RANGE PLANN, V30, P46, DOI 10.1016/S0024-6301(96)00095-7; Hoeber O, 2022, J ASSOC INF SCI TECH, V73, P1171, DOI 10.1002/asi.24623; Hoskisson RE, 1999, J MANAGE, V25, P417, DOI 10.1177/014920639902500307; Humble J.W., 1967, Improving Business Results; Humphrey A.S., Letter to Dr. K.R. Andrews inviting the HBS to attend the SRI executive seminars in planning and possibly use the seminar materials for MBA course work; Humphrey A.S., 1967, Letter to Dr. K.R. Andrews about attending long range planning seminars at UCLA by Gus Steiner and suggesting the possibility of a scholarship for Bob Stewart at HBS; Humphrey A.S., 1973, Engineering Industries, V332, P17; Humphrey A.S., 2005, SRI Alumni Newsletter, P7; Humphrey A.S., 1980, Team action management (TAM): history and background; Humphrey A.S., 1997, Summary of the key facts about Birger lie's contributions to the work at LRPS/TAPP; HUMPHREY AS, 1974, LONG RANGE PLANN, V7, P45, DOI 10.1016/0024-6301(74)90078-8; Hurd D.A., 1979, Planning Review, V7, P31, DOI [10.1108/eb053896, DOI 10.1108/EB053896]; Hussey D., 2001, STRATEG CHANG, V10, P201, DOI [10.1002/jsc.537, DOI 10.1002/JSC.537]; Hussey D.E., 1997, STRATEG CHANG, V6, P97, DOI [10.1002/(sici)1099-1697(199703)6:23.0.co;2-i, DOI 10.1002/(SICI)1099-1697(199703)6:23.0.CO;2-I, DOI 10.1002/(SICI)1099-1697(199703)6:2<97::AID-JSC223>3.0.C0;2-I]; Hussey D.E., 1991, International Review of Strategic Management, V2; Hussey D.E., 1974, CORPORATE PLANNING T; HUSSEY DE, 1968, LONG RANGE PLANN, V1, P19, DOI 10.1016/0024-6301(68)90008-3; Hussey DE., 1971, Introducing Corporate Planning; JANTSCH E, 1968, LONG RANGE PLANN, V1, P40, DOI 10.1016/0024-6301(68)90023-X; Jantsch E., 1967, Technological forecasting in perspective: A framework for technological forecasting; Jia N., 2024, Strategic Management Journal; JICK TD, 1979, ADMIN SCI QUART, V24, P602, DOI 10.2307/2392366; Johanson R.C., 1969, A Systematic Approach to Corporate Planning; Johnson G., 2023, The rise of the SWOT analysis in the 1980s: correspondence between Gerry Johnson and author 1 about the source of SWOT analysis; KAMI MJ, 1969, LONG RANGE PLANN, V1, P44, DOI 10.1016/0024-6301(69)90045-4; Karsten L, 2014, MANAG ORGAN HIST, V9, P414, DOI 10.1080/17449359.2014.980270; Kaul SC, 2021, J MANAG HIST, V27, P464, DOI 10.1108/JMH-07-2020-0046; Keding C., 2021, Management Review Quarterly, V71, P91, DOI [DOI 10.1007/S11301-020-00181-X, 10.1007/s11301-020-00181-x]; Keulen S, 2014, MANAG ORGAN HIST, V9, P321, DOI 10.1080/17449359.2014.982658; KING WR, 1977, LONG RANGE PLANN, V10, P59, DOI 10.1016/0024-6301(77)90049-8; Kipping M, 1999, BUS HIST REV, V73, P190, DOI 10.2307/3116240; Kipping M, 1996, BUSINESS AND ECONOMIC HISTORY, VOL 25, NO 1, FALL 1996, P112; Kipping M., 2002, Americanisation in 20th Century Europe, P7; Kipping M, 2014, ACAD MANAG ANN, V8, P535, DOI 10.1080/19416520.2014.911579; Koebel C.T., 1981, The Kentucky Journal of Economics and Business, V3, P28; Koepp D., 2008, Indiana Jones and the Kingdom of the crystal skull; KOONTZ H, 1961, ACAD MANAGE J, V4, P174; Koontz H., 1980, ACAD MANAGE REV, V5, P175, DOI 10.5465/amr.1980.4288715; KOTLER P, 1970, HARVARD BUS REV, V48, P135; Kotler P.A., 2023, The rise of the SWOT analysis in the 1980s: correspondence between Philip Kotler and author 1 about the source of SWOT analysis; Kudo A., 2004, GERMAN JAPANESE BUSI; Learned E.P., 1969, BUSINESS POLICY TEXT; Learned E.P., 1965, Business Policy-Text and Cases, V1st ed.; Leblebici H., 2014, ORG TIME HIST THEORY, P56; Lie B., 1968, Episode 6: a system of long-range planning at Norske folk (insurance company); Lloyd R, 2023, J MANAG HIST, DOI 10.1108/JMH-01-2023-0001; Lorange P., 2023, Interview between Peter Lorange; Lorange P., 1977, STRATEGIC PLANNING S; Lorange P., 1974, Formal planning systems: the state-of-the-art; Madsen D.O., 2016, International Journal of Business Research, V16, P39, DOI 10.18374/IJBR-16-1.3; Madsen DO, 2022, SOCIETIES, V12, DOI 10.3390/soc12060171; Maier David., 2018, Declarative Logic Programming: Theory, Systems, and Applications, P3, DOI DOI 10.1145/3191315.3191317; MALMLOW EG, 1972, LONG RANGE PLANN, V5, P2; Mandard M, 2022, EUR MANAG REV, V19, P10, DOI 10.1111/emre.12495; McConnell J.D., 1971, Management Decision, V9, P81, DOI [10.1108/eb000958, DOI 10.1108/EB000958]; McConnell J.D., 1970, Review for Religious, V29, P646; MCCONNELL JD, 1971, LONG RANGE PLANN, V4, P2, DOI 10.1016/0024-6301(71)90059-8; McPherson J.H., 1967, Frontiers in Planning; Meeks M.D., 2016, Academy of Strategic Management Journal, V14, P1; Mensmann M., 2022, Handbook of Philosophy of Management, V1st ed., P39; Miksa SD, 2021, CAT CLASSIF Q, V59, P97, DOI 10.1080/01639374.2021.1883173; Miller A., 1970, Fortune, V81, P303; MINTZBERG H, 1994, HARVARD BUS REV, V72, P107; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Mottershaw I.A., 1974, Improving management performance: a guide to SWOT analysis (strengths, weaknesses, opportunities, threats); Moussetis R, 2011, J MANAG HIST, V17, P102, DOI 10.1108/17511341111099556; Muldoon J, 2012, J MANAG HIST, V18, P105, DOI 10.1108/17511341211188682; Nielson D.L., 2005, A Heritage of Innovation: SRIs First Half of the Century; Nielson D.L., 2020, SWOT and SRI; Nyarku K.M., 2011, Academic Leadership, V9; OConner R., 1976, Corporate guides to long-range planning; Ohagi M., 2024, Polarization of autonomous generative AI agents under echo chambers; Encina RO, 2021, CUAD TRAB SOC, V34, P127, DOI 10.5209/cuts.65775; Petticrew M, 2006, SYSTEMATIC REVIEWS IN THE SOCIAL SCIENCES: A PRACTICAL GUIDE, P1, DOI 10.1002/9780470754887; Printing Trades Journal, 1973, Printing Trades Journal, P1; Printing Trades Journal, 1973, Printing Trades Journal; Reilley E.W., 1955, Advanced Management, V20, P8; Rekdal OB, 2014, SOC STUD SCI, V44, P638, DOI 10.1177/0306312714535679; Ringbakk K.A., 1970, Ledelse Med plan-Teori og Praksis i Langtidsplanlegging, V1st ed.; RINGBAKK KA, 1969, LONG RANGE PLANN, V2, P46, DOI 10.1016/0024-6301(69)90009-0; Rowlinson M., 2004, Essential Guide to Qualitative Methods in Organizational Research, P301; Royce W.S., 1994, Flexible Planning: SRI Approaches and Issues; Royce W.S., 1985, A history of strategic management and planning at SRI; Royce W.S., 1966, Letter to Birger Lie at the Norwegian Productivity Institute (NPI) Proposing an Arrangement to Broaden the Collaboration between SRI and NPI, P1; Royce W.S., 2001, The Book a Heritage of Innovation; Russell J, 2019, J MANAG HIST, V25, P550, DOI 10.1108/JMH-02-2018-0020; Schuhly A.M., 2022, What is strategic management and why do we need it: theoretical foundations of strategic management, P33, DOI [10.1007/978-3-030-86660-02, DOI 10.1007/978-3-030-86660-02]; Schwartz P., 1976, The art of exploratory planning: identifying the corporate long range course; Scott J., 2016, Methodological Innovations, V9, p205979911663066, DOI [10.1177/2059799116630664, DOI 10.1177/2059799116630664]; Simon H. A., 1947, ADM BEHAV STUDY DECI; SMALTER DJ, 1968, LONG RANGE PLANN, V1, P25, DOI 10.1016/0024-6301(68)90021-6; Smith G.A., 1962, Policy Formulation and Administration; Sparavigna AC, 2015, Arxiv, DOI arXiv:1512.01364; SRI, 1972, International Long Range Planning Service; Stait N.H., 1972, Industrial and Commercial Training, V4, P325, DOI [10.1108/eb003232, DOI 10.1108/EB003232]; Stein A, 2017, CAT CLASSIF Q, V55, P644, DOI 10.1080/01639374.2017.1358786; Steiner G.A., 1977, Management policy and strategy: Text, readings, and cases; Steiner G.A., 1972, Comprehensive managerial planning; Steiner G.A., 1979, Strategic planning: What every manager must know; STEINER GEORGEA., 1963, MANAGERIAL LONG RANG; Stewart R., 1963, A Framework for Business Planning; Stewart R.F., 1971, Setting corporate aims; Stewart R.F., 1971, Konzernarchiv Henkel Acc. 455 Nr. 85, P1; Stewart R.F., 1965, Formal planning-The staff planner's role at start-up; Stewart R.F., 1963, The strategic plan; Strycker P., 1961, Fortune, V63, P129; Sumner G., 1966, The Guardian, P14; Tennent KD, 2021, J MANAG HIST, V27, P80, DOI 10.1108/JMH-09-2020-0061; The Economist, 2009, The Economist11 November; The Publishing Industry Training Board, 1972, Contact; Trafford J., 1973, Financial Times, P21; UNTERMAN I, 1974, J GEN MANAGE, V1, P39, DOI 10.1177/030630707400100306; Vancil R.F., 1967, Management control systems: the concept of management control; W.H. Smith PLC, 1966, University of Reading, Special Collections, V1, P1; Wadhwani RD, 2018, ORGAN STUD, V39, P1663, DOI 10.1177/0170840618814867; Webel J.B., 1969, Introduction of the Stanford Research Institute (SRI) planning system at Owens-Corning fiberglass corporation; Whitney Gibson J., 1999, Journal of Management History (Archive), V5, P277, DOI [10.1108/13552529910282268, DOI 10.1108/13552529910282268]; Whittington R., 2019, Opening Strategy: Professional Strategists and Practice Change, 1960 to Today; Zuber N, 2024, PHILOSOPHIES, V9, DOI 10.3390/philosophies9010013	202	0	0	0	0	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1751-1348	1758-7751		J MANAG HIST	J. Manag. Hist.	2024 JUN 18	2024										10.1108/JMH-05-2023-0047	http://dx.doi.org/10.1108/JMH-05-2023-0047		JUN 2024	41	Management	Emerging Sources Citation Index (ESCI)	Business & Economics	UI3M7		hybrid			2024-07-03	WOS:001247388500001
J	Xu, L; Lu, L; Liu, ML; Song, CX; Wu, LZ				Xu, Liang; Lu, Lu; Liu, Minglu; Song, Chengxuan; Wu, Lizhen			Nanjing Yunjin intelligent question-answering system based on knowledge graphs and retrieval augmented generation technology	HERITAGE SCIENCE			English	Article						Knowledge graphs; Retrieval augmented generation; Question-Answering System; Nanjing Yunjin; Vector retrieval		Nanjing Yunjin, a traditional Chinese silk weaving craft, is celebrated globally for its unique local characteristics and exquisite workmanship, forming an integral part of the world's intangible cultural heritage. However, with the advancement of information technology, the experiential knowledge of the Nanjing Yunjin production process is predominantly stored in text format. As a highly specialized and vertical domain, this information is not readily convert into usable data. Previous studies on a knowledge graph-based Nanjing Yunjin Question-Answering System have partially addressed this issue. However, knowledge graphs need to be constantly updated and rely on predefined entities and relationship types. Faced with ambiguous or complex natural language problems, knowledge graph information retrieval faces some challenges. Therefore, this study proposes a Nanjing Yunjin Question-Answering System that integrates Knowledge Graphs and Retrieval Augmented Generation techniques. In this system, the ROBERTA model is first utilized to vectorize Nanjing Yunjin textual information, delving deep into textual semantics to unveil its profound cultural connotations. Additionally, the FAISS vector database is employed for efficient storage and retrieval of Nanjing Yunjin information, achieving a deep semantic match between questions and answers. Ultimately, related retrieval results are fed into the Large Language Model for enhanced generation, aiming for more accurate text generation outcomes and improving the interpretability and logic of the Question-Answering System. This research merges technologies like text embedding, vectorized retrieval, and natural language generation, aiming to overcome the limitations of knowledge graphs-based Question-Answering System in terms of graph updating, dependency on predefined types, and semantic understanding. System implementation and testing have shown that the Nanjing Yunjin Intelligent Question-Answering System, constructed on the basis of Knowledge Graphs and Retrieval Augmented Generation, possesses a broader knowledge base that considers context, resolving issues of polysemy, vague language, and sentence ambiguity, and efficiently and accurately generates answers to natural language queries. This significantly facilitates the retrieval and utilization of Yunjin knowledge, providing a paradigm for constructing Question-Answering System for other intangible cultural heritages, and holds substantial theoretical and practical significance for the deep exploration and discovery of the knowledge structure of human intangible heritage, promoting cultural inheritance and protection.	[Xu, Liang; Wu, Lizhen] Hangzhou Dianzi Univ, Hangzhou 310018, Peoples R China; [Lu, Lu] Nanjing Forestry Univ, Nanjing 210037, Peoples R China; [Liu, Minglu] Unicom Zhejiang Ind Internet Co Ltd, Hangzhou 311103, Peoples R China; [Song, Chengxuan] Nanjing Univ Informat Sci & Technol, Nanjing 210044, Peoples R China	Hangzhou Dianzi University; Nanjing Forestry University; Nanjing University of Information Science & Technology	Xu, L (corresponding author), Hangzhou Dianzi Univ, Hangzhou 310018, Peoples R China.	xuliang@hdu.edu.cn			Jiangsu Provincial Social Science Foundation Project "Research on Knowledge Extraction and Organization of Nanjing Cloud Brocade Video Resources Based on Knowledge Meta"	Jiangsu Provincial Social Science Foundation Project "Research on Knowledge Extraction and Organization of Nanjing Cloud Brocade Video Resources Based on Knowledge Meta"	This research was supported by experimental data created in the Nanjing YunJing Institute. We also thank the ICH bearers of Nanjing YunJing for semantic annotation and data verification for this study. At the same time, we would like to express our deepest gratitude to the anonymous reviewers, whose comments improved this work tremendously.	Ahmed S, 2016, J ADV RES, V7, P17, DOI 10.1016/j.jare.2015.02.007; Ashmawy M, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00366-8; Aurpa TT, 2022, HELIYON, V8, DOI 10.1016/j.heliyon.2022.e11052; Bhattacharya K, 2023, INDIAN J SURG, V85, P1346, DOI 10.1007/s12262-023-03727-x; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao YG, 2010, J BIOMED INFORM, V43, P962, DOI 10.1016/j.jbi.2010.07.007; Cardarilli GC, 2020, IEEE T CIRCUITS-II, V67, P565, DOI 10.1109/TCSII.2019.2919545; Chen Q, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14052923; Do P, 2021, NEURAL COMPUT APPL, V33, P16533, DOI 10.1007/s00521-021-06252-8; Duggan GB, 2016, BEHAV INFORM TECHNOL, V35, P536, DOI 10.1080/0144929X.2016.1141320; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Ferhatosmanoglu H, 2006, INFORM SYST, V31, P512, DOI 10.1016/j.is.2005.01.001; Guo Y, 2024, J BIOMED INFORM, V149, DOI 10.1016/j.jbi.2023.104580; Hambarde KA, 2023, IEEE ACCESS, V11, P76581, DOI 10.1109/ACCESS.2023.3295776; Hong WX, 2020, IEEE T PATTERN ANAL, V42, P1783, DOI 10.1109/TPAMI.2019.2925347; Huang LS, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/1383520; Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333; Iscen A, 2018, IEEE T BIG DATA, V4, P65, DOI 10.1109/TBDATA.2017.2677964; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Kikuchi M, 2021, IEICE T FUND ELECTR, VE104A, P1059, DOI 10.1587/transfun.2020EAP1088; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li DY, 2023, KNOWL-BASED SYST, V278, DOI 10.1016/j.knosys.2023.110917; Liu CJ, 2023, EXPERT SYST APPL, V231, DOI 10.1016/j.eswa.2023.120841; Liu S, 2021, INT J COMPUT INT SYS, V14, DOI 10.1007/s44196-021-00010-3; Liu WQ, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109002; Lu L, 2023, HERIT SCI, V11, DOI 10.1186/s40494-023-01027-x; Lu L, 2023, HERIT SCI, V11, DOI 10.1186/s40494-023-00932-5; Luu RK, 2024, ADV SCI, V11, DOI 10.1002/advs.202306724; Miao XY, 2016, IEEE T FUZZY SYST, V24, P1349, DOI 10.1109/TFUZZ.2016.2516562; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Ozan EC, 2016, IEEE T KNOWL DATA EN, V28, P1722, DOI 10.1109/TKDE.2016.2535287; Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Rodríguez P, 2018, IMAGE VISION COMPUT, V75, P21, DOI 10.1016/j.imavis.2018.04.004; Sarrouti M, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101767; Sauter P, 2005, PERS UBIQUIT COMPUT, V9, P100, DOI 10.1007/s00779-004-0314-7; Seo S, 2022, IEEE T KNOWL DATA EN, V34, P5610, DOI 10.1109/TKDE.2021.3070317; Shieber SM, 2004, TURING TEST: VERBAL BEHAVIOR AS THE HALLMARK OF INTELLIGENCE, P293; Siriwardhana S, 2023, T ASSOC COMPUT LING, V11, P1, DOI 10.1162/tacl_a_00530; Sirsat SR, 2014, SADHANA-ACAD P ENG S, V39, P53, DOI 10.1007/s12046-013-0197-2; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Sperlí G, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115277; Suissa O, 2023, SEMANT WEB, V14, P209, DOI 10.3233/SW-222925; Tian D, 2023, AUTOMAT CONSTR, V145, DOI 10.1016/j.autcon.2022.104670; Tzachor A, 2023, NAT FOOD, V4, P941, DOI 10.1038/s43016-023-00867-x; Wang X, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2597183; Woods W. A., 1973, AFIPS Conference Proceedings Vol.42 1973 National Computer Composition and Exposition, P441; Wu TX, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109124; Xiao HG, 2023, BIOMED SIGNAL PROCES, V84, DOI 10.1016/j.bspc.2023.104791; Xie ZW, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9136-x; Xu L, 2023, HERIT SCI, V11, DOI 10.1186/s40494-023-01068-2; Yan DY, 2020, IEEE ACCESS, V8, P82641, DOI 10.1109/ACCESS.2020.2991074; Yang ZJ, 2021, MOBILE NETW APPL, V26, P1884, DOI 10.1007/s11036-020-01726-w; Yuan GT, 2023, ENG APPL ARTIF INTEL, V126, DOI 10.1016/j.engappai.2023.107168; Zhang Q, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103297; Zhang W, 2011, EXPERT SYST APPL, V38, P2758, DOI 10.1016/j.eswa.2010.08.066; Zhang YX, 2023, PATTERN RECOGN, V144, DOI 10.1016/j.patcog.2023.109851; Zhao HX, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/8576002; Zhu SW, 2011, DATA KNOWL ENG, V70, P60, DOI 10.1016/j.datak.2010.08.004	60	0	0	41	41	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	2050-7445			HERIT SCI	Herit. Sci.	APR 9	2024	12	1							118	10.1186/s40494-024-01231-3	http://dx.doi.org/10.1186/s40494-024-01231-3			23	Humanities, Multidisciplinary; Chemistry, Analytical; Materials Science, Multidisciplinary; Spectroscopy	Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)	Arts & Humanities - Other Topics; Chemistry; Materials Science; Spectroscopy	NG5Z3		gold			2024-07-03	WOS:001199325200001
J	Cohen, SA; Brant, A; Fisher, AC; Pershing, S; Do, D; Pan, CRY				Cohen, Samuel A.; Brant, Arthur; Fisher, Ann Caroline; Pershing, Suzann; Do, Diana; Pan, Carolyn			Dr. Google vs. Dr. ChatGPT: Exploring the Use of Artificial Intelligence in Ophthalmology by Comparing the Accuracy, Safety, and Readability of Responses to Frequently Asked Patient Questions Regarding Cataracts and Cataract Surgery	SEMINARS IN OPHTHALMOLOGY			English	Article; Early Access						Cataract surgery; cataracts; ChatGPT; patient education; readability; Google	IMPACT	Purpose: Patients are using online search modalities to learn about their eye health. While Google remains the most popular search engine, the use of large language models (LLMs) like ChatGPT has increased. Cataract surgery is the most common surgical procedure in the US, and there is limited data on the quality of online information that populates after searches related to cataract surgery on search engines such as Google and LLM platforms such as ChatGPT. We identified the most common patient frequently asked questions (FAQs) about cataracts and cataract surgery and evaluated the accuracy, safety, and readability of the answers to these questions provided by both Google and ChatGPT. We demonstrated the utility of ChatGPT in writing notes and creating patient education materials. Methods: The top 20 FAQs related to cataracts and cataract surgery were recorded from Google. Responses to the questions provided by Google and ChatGPT were evaluated by a panel of ophthalmologists for accuracy and safety. Evaluators were also asked to distinguish between Google and LLM chatbot answers. Five validated readability indices were used to assess the readability of responses. ChatGPT was instructed to generate operative notes, post-operative instructions, and customizable patient education materials according to specific readability criteria. Results: Responses to 20 patient FAQs generated by ChatGPT were significantly longer and written at a higher reading level than responses provided by Google (p < .001), with an average grade level of 14.8 (college level). Expert reviewers were correctly able to distinguish between a human-reviewed and chatbot generated response an average of 31% of the time. Google answers contained incorrect or inappropriate material 27% of the time, compared with 6% of LLM generated answers (p < .001). When expert reviewers were asked to compare the responses directly, chatbot responses were favored (66%). Conclusions: When comparing the responses to patients' cataract FAQs provided by ChatGPT and Google, practicing ophthalmologists overwhelming preferred ChatGPT responses. LLM chatbot responses were less likely to contain inaccurate information. ChatGPT represents a viable information source for eye health for patients with higher health literacy. ChatGPT may also be used by ophthalmologists to create customizable patient education materials for patients with varying health literacy.	[Cohen, Samuel A.; Brant, Arthur; Fisher, Ann Caroline; Pershing, Suzann; Do, Diana; Pan, Carolyn] Stanford Univ, Byers Eye Inst, Sch Med, Stanford, CA USA; [Pan, Carolyn] Stanford Univ, Byers Eye Inst Stanford, Sch Med, 2452 Watson Court Palo Alto, Stanford, CA 94303 USA	Stanford University; Stanford University	Pan, CRY (corresponding author), Stanford Univ, Byers Eye Inst Stanford, Sch Med, 2452 Watson Court Palo Alto, Stanford, CA 94303 USA.	ckpan@stanford.edu						ahrq, Manual for Clinicians, V2nd; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Bujnowska-Fedak MM, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17030880; Burzynska J, 2023, INT J ENV RES PUB HE, V20, DOI 10.3390/ijerph20020978; Chen ALJ, 2020, OPHTHAL PLAST RECONS, V36, P277, DOI 10.1097/IOP.0000000000001531; Chiang Michael F, 2013, Trans Am Ophthalmol Soc, V111, P70; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Cohen SA, 2023, CLIN OPHTHALMOL, V17, P779, DOI 10.2147/OPTH.S401492; Cohen SA, 2023, SEMIN OPHTHALMOL, V38, P387, DOI 10.1080/08820538.2022.2158039; Cohen SA, 2022, OPHTHALMOL RETINA, V6, P641, DOI 10.1016/j.oret.2022.03.015; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dunne S, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2632; Rutten LJF, 2019, PUBLIC HEALTH REP, V134, P617, DOI 10.1177/0033354919874074; forbes, Top Website Statistics for 2023-Forbes Advisor; Kianian R, 2024, OPHTHALMOL RETINA, V8, P195, DOI 10.1016/j.oret.2023.09.008; Klak A., 2017, Polish Annals Of Medicine, V24, P188, DOI [10.1016/j.poamed.2017.02.002, DOI 10.1016/J.POAMED.2017.02.002]; Lee K, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4345; Massey PA, 2023, J AM ACAD ORTHOP SUR, V31, P1173, DOI 10.5435/JAAOS-D-23-00396; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Moorhead SA, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.1933; Newman-Casey PA, 2020, OPHTHALMOL GLAUCOMA, V3, P228, DOI 10.1016/j.ogla.2020.04.013; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Pitt MB, 2022, J GEN INTERN MED, V37, P222, DOI 10.1007/s11606-021-06895-2; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Razdan S, 2023, INT J IMPOT RES, DOI 10.1038/s41443-023-00797-z; Redd TK, 2014, J AAPOS, V18, P584, DOI 10.1016/j.jaapos.2014.08.002; Rossi T, 2021, BMJ OPEN OPHTHALMOL, V6, DOI 10.1136/bmjophth-2020-000464; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Schultheiss S, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P123, DOI 10.1145/3498366.3505811; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Van Riel Noor, 2017, BJGP Open, V1, pbjgpopen17X100833, DOI 10.3399/bjgpopen17X100833; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089	38	1	1	3	3	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0882-0538	1744-5205		SEMIN OPHTHALMOL	Semin. Ophthalmol.	2024 MAR 22	2024										10.1080/08820538.2024.2326058	http://dx.doi.org/10.1080/08820538.2024.2326058		MAR 2024	8	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	LV9U3	38516983				2024-07-03	WOS:001189701800001
J	Celik, A; Eltawil, AM				Celik, Abdulkadir; Eltawil, Ahmed M.			At the Dawn of Generative AI Era: A Tutorial-cum-Survey on New Frontiers in 6G Wireless Intelligence	IEEE OPEN JOURNAL OF THE COMMUNICATIONS SOCIETY			English	Article						5G; 6G; machine learning (ML); deep learning (DL); artificial intelligence (AI); discriminative AI; generative AI; generative models; generative adversarial networks; variational autoencoders; normalizing flows; diffusion models; generative transformers; generative pre-trained transformers; large language models; autoregressive generative models; semantic communications; integrated sensing and communications; digital twins; trustworthy AI; explainable AI; adversarial ML; mmWave; mMIMO; terahertz; near-field communication; extremely large antenna arrays; holographic beamforming; open RAN; zero-touch service management; AI-generated content; network function virtualization; software defined networks	INTRUSION DETECTION SYSTEM; OF-THE-ART; ADVERSARIAL NETWORKS; RESOURCE-ALLOCATION; DATA AUGMENTATION; ARTIFICIAL-INTELLIGENCE; COGNITIVE RADIO; IOT NETWORKS; MASSIVE MIMO; CHALLENGES	As we transition from the 5G epoch, a new horizon beckons with the advent of 6G, seeking a profound fusion with novel communication paradigms and emerging technological trends, bringing once-futuristic visions to life along with added technical intricacies. Although analytical models lay the foundations and offer systematic insights, we have recently witnessed a noticeable surge in research suggesting machine learning (ML) and artificial intelligence (AI) can efficiently deal with complex problems by complementing or replacing model-based approaches. The majority of data-driven wireless research leans heavily on discriminative AI (DAI) that requires vast real-world datasets. Unlike the DAI, Generative AI (GenAI) pertains to generative models (GMs) capable of discerning the underlying data distribution, patterns, and features of the input data. This makes GenAI a crucial asset in wireless domain wherein real-world data is often scarce, incomplete, costly to acquire, and hard to model or comprehend. With these appealing attributes, GenAI can replace or supplement DAI methods in various capacities. Accordingly, this combined tutorial-survey paper commences with preliminaries of 6G and wireless intelligence by outlining candidate 6G applications and services, presenting a taxonomy of state-of-the-art DAI models, exemplifying prominent DAI use cases, and elucidating the multifaceted ways through which GenAI enhances DAI. Subsequently, we present a tutorial on GMs by spotlighting seminal examples such as generative adversarial networks, variational autoencoders, flow-based GMs, diffusion-based GMs, generative transformers, large language models, autoregressive GMs, to name a few. Contrary to the prevailing belief that GenAI is a nascent trend, our exhaustive review of approximately 120 technical papers demonstrates the scope of research across core wireless research areas, including 1) physical layer design; 2) network optimization, organization, and management; 3) network traffic analytics; 4) cross-layer network security; and 5) localization & positioning. Furthermore, we outline the central role of GMs in pioneering areas of 6G network research, including semantic communications, integrated sensing and communications, THz communications, extremely large antenna arrays, near-field communications, digital twins, AI-generated content services, mobile edge computing and edge AI, adversarial ML, and trustworthy AI. Lastly, we shed light on the multifarious challenges ahead, suggesting potential strategies and promising remedies. Given its depth and breadth, we are confident that this tutorial-cum-survey will serve as a pivotal reference for researchers and professionals delving into this dynamic and promising domain.	[Celik, Abdulkadir; Eltawil, Ahmed M.] King Abdullah Univ Sci & Technol, Comp Elect & Math Sci & Engn Div, Thuwal 239556900, Saudi Arabia	King Abdullah University of Science & Technology	Celik, A (corresponding author), King Abdullah Univ Sci & Technol, Comp Elect & Math Sci & Engn Div, Thuwal 239556900, Saudi Arabia.	abdulkadir.celik@kaust.edu.sa	Eltawil, Ahmed/B-1109-2008	Eltawil, Ahmed/0000-0003-1849-083X	Office of Sponsored Research (OSR) at King Abdullah University of Science and Technology (KAUST)	Office of Sponsored Research (OSR) at King Abdullah University of Science and Technology (KAUST)	No Statement Available	Abdallah A., 2024, IEEE Trans. Wireless Commun., early access, DOI [10.1109/TWC.2023.3347419, DOI 10.1109/TWC.2023.3347419]; Abdallah A, 2023, CONSUM COMM NETWORK, DOI 10.1109/CCNC51644.2023.10060056; Abdallah A, 2023, IEEE T WIREL COMMUN, V22, P3503, DOI 10.1109/TWC.2022.3219140; Abdallah A, 2022, IEEE ICC, P1269, DOI 10.1109/ICC45855.2022.9839142; Abdallah A, 2022, IEEE T WIREL COMMUN, V21, P3804, DOI 10.1109/TWC.2021.3124202; Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458; Ahmadi A, 2022, IEEE WCNC, P752, DOI 10.1109/WCNC51071.2022.9771710; Aho JJ, 2018, IEEE MILIT COMMUN C, P401, DOI 10.1109/MILCOM.2018.8599782; Al Kassir H, 2022, IEEE ACCESS, V10, P80869, DOI 10.1109/ACCESS.2022.3195299; Alawad MA, 2022, IEEE GLOB COMM CONF, P5159, DOI 10.1109/GLOBECOM48099.2022.10001178; Alkhateeb A, 2023, IEEE COMMUN MAG, V61, P128, DOI 10.1109/MCOM.001.2200866; Amiri S, 2020, AAAI CONF ARTIF INTE, V34, P2726; [Anonymous], 2004, Advances in Neural Information Processing Systems; Arjovsky M, 2017, PR MACH LEARN RES, V70; Arvinte M, 2023, IEEE T WIREL COMMUN, V22, P3698, DOI 10.1109/TWC.2022.3220784; Arvinte M, 2022, IEEE WCNC, P453, DOI 10.1109/WCNC51071.2022.9771907; Arzykulov S, 2022, IEEE T COGN COMMUN, V8, P263, DOI 10.1109/TCCN.2021.3105133; Ayanoglu E, 2022, IEEE T COGN COMMUN, V8, P480, DOI 10.1109/TCCN.2022.3153004; Balevi E, 2021, IEEE T WIREL COMMUN, V20, P3049, DOI 10.1109/TWC.2020.3047100; Bariah L, 2023, Arxiv, DOI arXiv:2306.07933; Bariah L, 2023, Arxiv, DOI arXiv:2306.10249; Bariah L, 2022, Arxiv, DOI arXiv:2209.12423; Barnes-Cook B, 2022, IEEE WCNC, P483, DOI 10.1109/WCNC51071.2022.9771754; Belmonte-Hernández A, 2020, IEEE SENS J, V20, P3356, DOI 10.1109/JSEN.2019.2958201; Benaddi H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22218085; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bobrov E, 2022, IEEE COMMUN LETT, V26, P818, DOI 10.1109/LCOMM.2021.3132947; Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668; Bowles C, 2018, Arxiv, DOI arXiv:1810.10863; Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buchmann J, 2017, IEEE SECUR PRIV, V15, P12, DOI 10.1109/MSP.2017.3151326; Burse K, 2010, IEEE T SYST MAN CY C, V40, P352, DOI 10.1109/TSMCC.2009.2038279; Bushnaq OM, 2021, IEEE T WIREL COMMUN, V20, P2092, DOI 10.1109/TWC.2020.3039013; Bushnaq OM, 2019, IEEE T WIREL COMMUN, V18, P4620, DOI 10.1109/TWC.2019.2921955; Caciularu A, 2018, IEEE INT CONF COMM; Cai ZP, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459992; Cao HQ, 2023, Arxiv, DOI [arXiv:2209.02646, 10.48550/arXiv.2209.02646, DOI 10.48550/ARXIV.2209.02646]; Celik Abdulkadir, 2022, IEEE Internet of Things Magazine, V5, P114, DOI 10.1109/IOTM.001.2100209; Celik A, 2022, IEEE INTERNET THINGS, V9, P321, DOI 10.1109/JIOT.2021.3098028; Celik A, 2020, IEEE VEH TECHNOL MAG, V15, P83, DOI 10.1109/MVT.2020.3017152; Celik A, 2020, IEEE T WIREL COMMUN, V19, P1167, DOI 10.1109/TWC.2019.2951416; Celik A, 2019, IEEE T COMMUN, V67, P7211, DOI 10.1109/TCOMM.2019.2927561; Celik A, 2019, IEEE T COMMUN, V67, P1677, DOI 10.1109/TCOMM.2018.2879508; Celik A, 2017, IEEE ACCESS, V5, P22735, DOI 10.1109/ACCESS.2017.2760350; Chandhar P, 2018, IEEE T WIREL COMMUN, V17, P1604, DOI 10.1109/TWC.2017.2782690; Chen JY, 2020, INFORM SCIENCES, V536, P67, DOI 10.1016/j.ins.2020.04.019; Chen KJ, 2020, Arxiv, DOI arXiv:1811.03732; Chen KM, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322456; Chen X, 2016, ADV NEUR IN, V29; Cheng A, 2019, 2019 IEEE 10TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P728, DOI [10.1109/IEMCON.2019.8936224, 10.1109/iemcon.2019.8936224]; Cheng NJ, 2023, Arxiv, DOI arXiv:2305.16530; Cheng ZH, 2021, ENVIRON SCI POLLUT R, V28, P49774, DOI 10.1007/s11356-021-14176-y; Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916; Clark WH, 2021, J DEF MODEL SIMUL-AP, V18, P217, DOI 10.1177/1548512921991245; Creech G, 2014, IEEE T COMPUT, V63, P807, DOI 10.1109/TC.2013.13; Cui MY, 2023, IEEE COMMUN MAG, V61, P40, DOI 10.1109/MCOM.004.2200136; Dai ZY, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P985, DOI 10.1145/3331184.3331303; Dang SP, 2020, NAT ELECTRON, V3, P20, DOI 10.1038/s41928-019-0355-6; Davaslioglu K, 2018, IEEE ICC; de Araujo PF, 2021, IEEE INTERNET THINGS, V8, P6247, DOI 10.1109/JIOT.2020.3024800; De S, 2022, IEEE T IND INFORM, V18, P5728, DOI 10.1109/TII.2022.3155656; Deldjoo Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439729; Demirhan U, 2023, IEEE COMMUN MAG, V61, P113, DOI 10.1109/MCOM.006.2200480; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding HW, 2022, FUTURE GENER COMP SY, V131, P240, DOI 10.1016/j.future.2022.01.026; Dinh L, 2015, Arxiv, DOI [arXiv:1410.8516, 10.48550/arXiv.1410.8516]; Dinh L, 2017, Arxiv, DOI [arXiv:1605.08803, DOI 10.48550/ARXIV.1605.08803]; Donahue J, 2016, Adversarial feature learning; Du ZY, 2021, IEEE VEH TECHNOL MAG, V16, P29, DOI 10.1109/MVT.2020.3015184; Duffhauss F, 2022, LECT NOTES COMPUT SC, V13699, P674, DOI 10.1007/978-3-031-19842-7_39; Dunmore A, 2023, IEEE ACCESS, V11, P76071, DOI 10.1109/ACCESS.2023.3296707; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; El Sallab A, 2019, Arxiv, DOI arXiv:1905.07290; Erdemir E, 2023, IEEE J SEL AREA COMM, V41, P2645, DOI 10.1109/JSAC.2023.3288243; Erpek T, 2019, IEEE T COGN COMMUN, V5, P2, DOI 10.1109/TCCN.2018.2884910; Falahatraftar F, 2021, TELECOM, V2, P141, DOI 10.3390/telecom2010009; Ferdowsi A, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014102; Ferdowsi A, 2023, Arxiv, DOI [arXiv:2002.00306, 10.48550/arXiv.2002.00306]; Germain M, 2015, PR MACH LEARN RES, V37, P881; GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485; Ghosh P, 2019, AAAI CONF ARTIF INTE, P541; Gilbert H, 2023, Arxiv, DOI arXiv:2304.12512; Giordani M, 2021, IEEE NETWORK, V35, P244, DOI 10.1109/MNET.011.2000493; Goodfellow I, 2017, Arxiv, DOI arXiv:1701.00160; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gu RC, 2019, IEEE ICC, DOI 10.1109/icc.2019.8761755; Gudovskiy D, 2022, IEEE WINT CONF APPL, P1819, DOI 10.1109/WACV51458.2022.00188; Gures E, 2022, IEEE ACCESS, V10, P37689, DOI 10.1109/ACCESS.2022.3161511; Han H, 2021, IEEE WIREL COMMUN LE, V10, P1800, DOI 10.1109/LWC.2021.3081509; Han J., 2022, P 4 INT C COMM INF S, P1; Higgins I., 2017, ICLR, V2, P6; Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018; Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527; Ho J., 2020, P ADV NEUR INF PROC, V33, P6840; Ho J, 2016, ADV NEUR IN, V29; Estiri AH, 2020, Arxiv, DOI arXiv:2010.03967; Hua YX, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014217; Hua YX, 2020, IEEE J SEL AREA COMM, V38, P334, DOI 10.1109/JSAC.2019.2959185; Huang CW, 2020, IEEE WIREL COMMUN, V27, P118, DOI 10.1109/MWC.001.1900534; Huang JJ, 2022, IEEE WIREL COMMUN, V29, P38, DOI 10.1109/MWC.004.2100362; Huang SK, 2020, AD HOC NETW, V105, DOI 10.1016/j.adhoc.2020.102177; Huang TH, 2023, Arxiv, DOI arXiv:2303.15860; Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202; Hughes B, 2019, INT CONF COMPUT NETW, P282, DOI [10.1109/iccnc.2019.8685527, 10.1109/ICCNC.2019.8685527]; Ivanov O., 2019, P INT C LEARN REPR, P1; Jeong H, 2021, IEEE CONF COMPUT, DOI 10.1109/INFOCOMWKSHPS51825.2021.9484569; Jiang F, 2017, STROKE VASC NEUROL, V2, P230, DOI 10.1136/svn-2017-000101; Jiang WW, 2022, EXPERT SYST APPL, V201, DOI 10.1016/j.eswa.2022.117163; Kaleem Zeeshan, 2022, IEEE Networking Letters, V4, P104, DOI 10.1109/LNET.2022.3193766; Kaleem Z, 2022, IEEE COMMUN LETT, V26, P1633, DOI 10.1109/LCOMM.2022.3172171; Kamboj AK, 2021, WIREL NETW, V27, P5351, DOI 10.1007/s11276-021-02781-1; Karapantelakis A, 2024, ANN TELECOMMUN, V79, P15, DOI 10.1007/s12243-023-00980-9; Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813; Karras T, 2018, Arxiv, DOI arXiv:1710.10196; Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919; Karunaratne S, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500893; Kasgari ATZ, 2021, IEEE T COMMUN, V69, P884, DOI 10.1109/TCOMM.2020.3031930; Katzef Marc, 2020, Decision and Game Theory for Security. 11th International Conference, GameSec 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12513), P3, DOI 10.1007/978-3-030-64793-3_1; Kaur D, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3491209; Kaushik A, 2021, IEEE INT CONF COMM, DOI 10.1109/ICCWorkshops50388.2021.9473497; Khalighi MA, 2014, IEEE COMMUN SURV TUT, V16, P2231, DOI 10.1109/COMST.2014.2329501; Kilinc F, 2023, IEEE T COGN COMMUN, V9, P1257, DOI 10.1109/TCCN.2023.3288108; Kim S, 2019, Arxiv, DOI arXiv:1811.02155; Kingma D. P., 2014, ICLR; Kingma DP, 2018, ADV NEUR IN, V31; Kingma DP, 2016, 30 C NEURAL INFORM P, V29; Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934; Krayani A, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322583; Larochelle Hugo, 2011, P 14 INT C ARTIFICIA, P29; Larsen ABL, 2016, PR MACH LEARN RES, V48; Lauinger V, 2022, IEEE J SEL AREA COMM, V40, P2529, DOI 10.1109/JSAC.2022.3191346; Lee H., 2007, P ADV NEUR INF PROC, V20, P1; Lee M, 2018, IEEE WIREL COMMUN LE, V7, P962, DOI 10.1109/LWC.2018.2843359; Lei K, 2019, IEEE INFOCOM SER, P388, DOI [10.1109/infocom.2019.8737631, 10.1109/INFOCOM.2019.8737631]; Letaief KB, 2022, IEEE J SEL AREA COMM, V40, P5, DOI 10.1109/JSAC.2021.3126076; Letaief KB, 2019, IEEE COMMUN MAG, V57, P84, DOI 10.1109/MCOM.2019.1900271; Li D, 2019, Arxiv, DOI arXiv:1809.04758; Li E, 2018, MECOMM'18: PROCEEDINGS OF THE 2018 WORKSHOP ON MOBILE EDGE COMMUNICATIONS, P31, DOI 10.1145/3229556.3229562; Li JZ, 2021, IEEE SENS J, V21, P22823, DOI 10.1109/JSEN.2021.3105404; Li MX, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P669, DOI 10.1109/ICCT.2018.8600032; Li MX, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113913; Li QY, 2021, IEEE T EM TOP COMP I, V5, P468, DOI 10.1109/TETCI.2019.2948058; Li QY, 2018, IEEE GLOBE WORK; Li XF, 2018, CONF REC ASILOMAR C, P1572; Li Y., 2022, Proceedings of the Advances in Neural Information Processing Systems, V35, P23009; Li Z, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1851, DOI 10.1145/3269206.3269294; Liao XM, 2020, IEEE COMMUN LETT, V24, P1463, DOI 10.1109/LCOMM.2020.2988384; Lim C, 2021, I C INF COMM TECH CO, P1024, DOI 10.1109/ICTC52510.2021.9621134; Liu H., 2022, arXiv; Liu JX, 2022, IEEE COMMUN SURV TUT, V24, P123, DOI 10.1109/COMST.2021.3136132; Liu XY, 2021, IEEE T NEUR NET LEAR, V32, P3433, DOI 10.1109/TNNLS.2020.3010724; Liu YQ, 2023, Arxiv, DOI arXiv:2303.17114; Luchi Hua, 2021, 10th International Conference on Computer Engineering and Networks. Advances in Intelligent Systems and Computing (AISC 1274), P835, DOI 10.1007/978-981-15-8462-6_96; Luo XW, 2022, IEEE WIREL COMMUN, V29, P210, DOI 10.1109/MWC.101.2100269; Vu L, 2023, IEEE T CYBERNETICS, V53, P565, DOI 10.1109/TCYB.2022.3163811; Ma MJ, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010084; Maksymyuk T., 2018, P INT C INF TEL TECH, P1; Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304; Meng R, 2023, IEEE INTERNET THINGS, V10, P2528, DOI 10.1109/JIOT.2022.3213593; Merchant K, 2019, IEEE MILIT COMMUN C, DOI [10.1109/MILCOM47813.2019.9020907, 10.1109/milcom47813.2019.9020907]; Metz L., 2017, Unrolled generative adversarial networks; Minerva R, 2020, P IEEE, V108, P1785, DOI 10.1109/JPROC.2020.2998530; Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]; Misbah M, 2023, IEEE WIREL COMMUN LE, V12, P1135, DOI 10.1109/LWC.2023.3263224; Mobley R.K., 2016, An Introduction to Predictive Maintenance, DOI [10.1016/B978-0-7506-7531-4.X5000-3, DOI 10.1016/B978-0-7506-7531-4.X5000-3]; Nair V., 2009, ADV NEURAL INF PROCE, V22, P1339, DOI DOI 10.5555/2984093.2984244; Naveed MH, 2022, IEEE ACCESS, V10, P64601, DOI 10.1109/ACCESS.2022.3177906; Navidan H, 2021, COMPUT NETW, V194, DOI 10.1016/j.comnet.2021.108149; Nayak P, 2021, MEASUREMENT, V178, DOI 10.1016/j.measurement.2021.108974; NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6; Nemati M., 2023, Techrxiv, DOI [10.36227/techrxiv.19294622.1, DOI 10.36227/TECHRXIV.19294622.1]; Ni Gao, 2014, 2014 Second International Conference on Advanced Cloud and Big Data (CBD), P247, DOI 10.1109/CBD.2014.41; Njima Wafa, 2021, 2021 International Balkan Conference on Communications and Networking (BalkanCom), P36, DOI 10.1109/BalkanCom53780.2021.9593240; Njima W, 2022, IEEE ACCESS, V10, P69896, DOI 10.1109/ACCESS.2022.3187837; Njima W, 2021, IEEE ACCESS, V9, P98337, DOI 10.1109/ACCESS.2021.3095546; O'Shea TJ, 2019, INT CONF COMPUT NETW, P681, DOI [10.1109/iccnc.2019.8685573, 10.1109/ICCNC.2019.8685573]; O'Shea TJ, 2018, EUR SIGNAL PR CONF, P529, DOI 10.23919/EUSIPCO.2018.8553233; Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114; Papamakarios G, 2017, ADV NEUR IN, V30; Papamakarios G, 2021, J MACH LEARN RES, V22; Park C, 2023, IEEE INTERNET THINGS, V10, P2330, DOI 10.1109/JIOT.2022.3211346; Patel M, 2020, PROCEEDINGS OF THE 2ND ACM WORKSHOP ON WIRELESS SECURITY AND MACHINE LEARNING, WISEML 2020, P31, DOI 10.1145/3395352.3402622; Pathak PH, 2015, IEEE COMMUN SURV TUT, V17, P2047, DOI 10.1109/COMST.2015.2476474; Perdikis S, 2021, IEEE T NEUR NET LEAR, V32, P3471, DOI 10.1109/TNNLS.2020.3011671; Piantadosi S. T., 2022, arXiv; Pirandola S, 2020, ADV OPT PHOTONICS, V12, P1012, DOI 10.1364/AOP.361502; Portree D.S. F., 1993, ORBITAL DEBRIS NEAR; Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79; Quezada-Gaibor D, 2022, INT C INDOOR POSIT, DOI 10.1109/IPIN54987.2022.9918146; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2016, Arxiv, DOI arXiv:1511.06434; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Rao D., 2023, IEEE Trans. Image Process., DOI [10.1109/ΙΡ.2023.3273451, DOI 10.1109/&UIOTA;&URHO;.2023.3273451]; Rappaport TS, 2019, IEEE ACCESS, V7, P78729, DOI 10.1109/ACCESS.2019.2921522; Rathinavel Gopikrishna, 2022, MILCOM 2022 - 2022 IEEE Military Communications Conference (MILCOM), P594, DOI 10.1109/MILCOM55135.2022.10017520; Ren XC, 2022, Arxiv, DOI arXiv:2102.10543; Rezende DJ, 2015, PR MACH LEARN RES, V37, P1530; Rigaki M, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P70, DOI 10.1109/SPW.2018.00019; Roy D., 2019, IEEE WCNC, P1, DOI DOI 10.1109/wcnc.2019.8885548; Roy D, 2020, IEEE T COGN COMMUN, V6, P783, DOI 10.1109/TCCN.2019.2948919; Roy T, 2019, PROCEEDINGS OF THE 2019 ACM WORKSHOP ON WIRELESS SECURITY AND MACHINE LEARNING (WISEML '19), P12, DOI 10.1145/3324921.3328782; Saad W, 2020, IEEE NETWORK, V34, P134, DOI 10.1109/MNET.001.1900287; Sadeghi M, 2019, IEEE WIREL COMMUN LE, V8, P213, DOI 10.1109/LWC.2018.2867459; Saeed N, 2019, PHYS COMMUN-AMST, V37, DOI 10.1016/j.phycom.2019.100900; Saidutla YM, 2020, IEEE INT WORK SIGN P, DOI 10.1109/spawc48557.2020.9154331; Saidutta YM, 2021, IEEE J SEL AREA COMM, V39, P2000, DOI 10.1109/JSAC.2021.3078489; Saidutta YM, 2019, IEEE INT SYMP INFO, P1327, DOI [10.1109/ISIT.2019.8849476, 10.1109/isit.2019.8849476]; Salem M, 2018, 2018 9TH IEEE ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P683, DOI 10.1109/UEMCON.2018.8796769; Sarieddeen H, 2020, IEEE COMMUN MAG, V58, P69, DOI 10.1109/MCOM.001.1900698; Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9; Seo E, 2018, ANN CONF PRIV SECUR, P286; Serreli L, 2021, IEEE INT SYM BROADB, DOI 10.1109/BMSB53066.2021.9547015; Shabaninia E., 2022, arXiv; Shahid MR, 2020, IEEE PAC RIM INT SYM, P70, DOI 10.1109/PRDC50213.2020.00018; Shahriar MH, 2020, P INT COMP SOFTW APP, P376, DOI 10.1109/COMPSAC48688.2020.0-218; Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198; Shi Y, 2018, IEEE INT CONF COMM, DOI 10.1109/TAC.2018.2867507; Shi Y, 2021, IEEE T COGN COMMUN, V7, P294, DOI 10.1109/TCCN.2020.3010330; Shi Y, 2019, PROCEEDINGS OF THE 2019 ACM WORKSHOP ON WIRELESS SECURITY AND MACHINE LEARNING (WISEML '19), P55, DOI 10.1145/3324921.3329695; Siami-Namini S, 2019, IEEE INT CONF BIG DA, P3285, DOI 10.1109/BigData47090.2019.9005997; Smith AJ, 2019, PREHOSP DISASTER MED, V34, P104, DOI [10.1017/S1049023X18001164, 10.1109/ccaaw.2019.8904907]; Smith S, 2022, arXiv; Sohn K, 2015, ADV NEUR IN, V28; Sonderby CK, 2016, ADV NEUR IN, V29; Song J., 2023, P NIPS, P1; Song SH, 2021, MATH GEOSCI, V53, P1413, DOI 10.1007/s11004-021-09934-0; Song Y, 2021, Arxiv, DOI arXiv:2011.13456; Sönmez S, 2020, PROCEEDINGS OF 2020 IEEE WORKSHOP ON MICROWAVE THEORY AND TECHNIQUES IN WIRELESS COMMUNICATIONS (MTTW'20), P35, DOI [10.1109/MTTW51045.2020.9245065, 10.1109/mttw51045.2020.9245065]; Sorzano COS, 2014, Arxiv, DOI [arXiv:1403.2877, DOI 10.48550/ARXIV.1403.2877]; Spinner T., 2018, P WORKSH VIS AI EXPL; Ssengonzi C, 2022, ARRAY-NY, V14, DOI 10.1016/j.array.2022.100142; Suroso D. J., 2022, P 19 INT C EL ENG EL, P1; Tang B, 2018, IEEE ACCESS, V6, P15713, DOI 10.1109/ACCESS.2018.2815741; Tang FX, 2023, IEEE WIREL COMMUN, V30, P72, DOI 10.1109/MWC.019.2100721; Tang Y, 2020, INT CONF SIGN PROCES, P312, DOI 10.1109/ICSP48669.2020.9320987; Tao W., 2021, P 2 INT C COMP NETW, P1; Tarekegn Getaneh Berie, 2020, 2020 International Conference on Pervasive Artificial Intelligence (ICPAI), P23, DOI 10.1109/ICPAI51961.2020.00012; Springenberg JT, 2016, Arxiv, DOI arXiv:1511.06390; Tolstikhin O., 2018, P INT C LEARN REPR, P1; Toma A, 2020, IEEE T COGN COMMUN, V6, P21, DOI 10.1109/TCCN.2020.2970693; Tongyang Xu, 2022, 2022 13th International Symposium on Communication Systems, Networks and Digital Signal Processing (CSNDSP), P503, DOI 10.1109/CSNDSP54353.2022.9907905; Tran DN, 2018, IEEE RAD CONF, P1223, DOI 10.1109/RADAR.2018.8378737; Tschantz A, 2020, Arxiv, DOI [arXiv:2002.12636, DOI 10.48550/ARXIV.2002.12636, 10.48550/arXiv.2002.12636]; Ullah I, 2021, IEEE ACCESS, V9, P165907, DOI 10.1109/ACCESS.2021.3132127; Usama M, 2019, INT WIREL COMMUN, P78, DOI 10.1109/iwcmc.2019.8766353; van den Oord A., 2016, ARXIV; van den Oord A, 2016, ADV NEUR IN, V29; van den Oord A, 2017, ADV NEUR IN, V30; van den Oord A, 2016, PR MACH LEARN RES, V48; Vaswani A, 2017, ADV NEUR IN, V30; Vincent P, 2011, NEURAL COMPUT, V23, P1661, DOI 10.1162/NECO_a_00142; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wang CX, 2007, IEEE T COMMUN, V55, P453, DOI 10.1109/TCOMM.2007.892447; Wang CX, 2023, IEEE COMMUN SURV TUT, V25, P905, DOI 10.1109/COMST.2023.3249835; Wang P, 2021, COMPUT NETW, V200, DOI 10.1016/j.comnet.2021.108535; Wang YC, 2023, IEEE OPEN J COMM SOC, V4, P2952, DOI 10.1109/OJCOMS.2023.3320646; Wang ZX, 2019, IEEE INT SYMP PARAL, P975, DOI 10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00141; Wei W, 2021, IEEE WCNC, DOI 10.1109/WCNC49053.2021.9417513; Weng Y, 2019, IEEE ACCESS, V7, P64223, DOI 10.1109/ACCESS.2019.2917207; Xu DY, 2021, EXPERT SYST APPL, V185, DOI 10.1016/j.eswa.2021.115680; Xu JG, 2015, IETE TECH REV, V32, P131, DOI 10.1080/02564602.2014.987328; Xu LY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12168085; Xu XD, 2021, DIGIT SIGNAL PROCESS, V117, DOI 10.1016/j.dsp.2021.103188; Xu YH, 2021, IEEE WIREL COMMUN LE, V10, P1601, DOI 10.1109/LWC.2021.3075467; Xu YX, 2022, IEEE ICC, P3220, DOI 10.1109/ICC45855.2022.9838574; Xuhai Xu MY., 2023, arXiv; Yang B, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P1743; Yang HL, 2020, IEEE NETWORK, V34, P272, DOI 10.1109/MNET.011.2000195; Yang J, 2021, IEEE T WIREL COMMUN, V20, P3031, DOI 10.1109/TWC.2020.3046766; Yang L, 2024, Arxiv, DOI [arXiv:2209.00796, DOI 10.48550/ARXIV.2209.00796]; Yang WT, 2023, IEEE COMMUN SURV TUT, V25, P213, DOI [10.1109/COMST.2022.3223224, 10.23919/SISPAD57422.2023.10319622]; Yang Y, 2019, IEEE COMMUN MAG, V57, P22, DOI 10.1109/MCOM.2019.1800635; Yang YX, 2021, I C COMM SOFTW NET, P361, DOI 10.1109/ICCSN52437.2021.9463629; Ye H, 2018, IEEE GLOBE WORK; Yule GU, 1927, PHILOS T R SOC LOND, V226, P267, DOI 10.1098/rsta.1927.0007; Zaky AB, 2020, CHINA COMMUN, V17, P14, DOI 10.23919/JCC.2020.02.002; Zang D, 2019, IEEE ACCESS, V7, P71311, DOI 10.1109/ACCESS.2019.2919996; Zappone A, 2019, IEEE T COMMUN, V67, P7331, DOI 10.1109/TCOMM.2019.2924010; Zeng Y, 2016, IEEE COMMUN MAG, V54, P36, DOI 10.1109/MCOM.2016.7470933; Zhang CY, 2019, IEEE COMMUN SURV TUT, V21, P2224, DOI 10.1109/COMST.2019.2904897; Zhang CY, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P363, DOI 10.1145/3143361.3143393; Zhang HB, 2018, Arxiv, DOI arXiv:1808.01684; Zhang L, 2022, IEEE T MOBILE COMPUT, V21, P4323, DOI 10.1109/TMC.2021.3075083; Zhang QQ, 2022, IEEE T WIREL COMMUN, V21, P1438, DOI 10.1109/TWC.2021.3103971; Zhang QQ, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9501056; Zhang RC, 2023, Arxiv, DOI arXiv:2304.11098; Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029; Zhang T, 2020, IEEE WIREL COMMUN LE, V9, P171, DOI 10.1109/LWC.2019.2947041; Zhang TC, 2020, IEEE COMMUN MAG, V58, P52, DOI 10.1109/MCOM.001.1900509; Zhao LQ, 2021, IEEE ACCESS, V9, P158426, DOI 10.1109/ACCESS.2021.3130418; Zhao W, 2020, IEEE ACCESS, V8, P86380, DOI 10.1109/ACCESS.2020.2991337; Zhou FH, 2019, IEEE NETWORK, V33, P54, DOI 10.1109/MNET.2019.1800439; Zhou M, 2020, IEEE T EM TOP COMP I, V4, P61, DOI 10.1109/TETCI.2019.2892748; Zhou QY, 2023, IEEE T COGN DEV SYST, V15, P724, DOI 10.1109/TCDS.2022.3176977; Zhou X, 2020, AD HOC NETW, V103, DOI 10.1016/j.adhoc.2020.102151; Zhu CX, 2018, IEEE ICC; Zhu HZ, 2022, Arxiv, DOI arXiv:2206.03686; Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244; Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555; Zixu T., 2020, P IEEE GLOB COMM C G, P1; Zou H, 2023, Arxiv, DOI arXiv:2307.02757	302	1	1	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		2644-125X		IEEE OPEN J COMM SOC	IEEE Open J. Commun. Soc.		2024	5						2433	2489		10.1109/OJCOMS.2024.3362271	http://dx.doi.org/10.1109/OJCOMS.2024.3362271			57	Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Engineering; Telecommunications	PM6U3		gold, Green Submitted			2024-07-03	WOS:001214542600002
J	Wilson, RN; Holman, PJ; Dragan, M; MacPherson, REK; Beaudette, SM				Wilson, Robert N.; Holman, Parker J.; Dragan, Martin; MacPherson, Rebecca E. K.; Beaudette, Shawn M.			The effects of supplemental instruction derived from peer leaders on student outcomes in undergraduate human anatomy	ANATOMICAL SCIENCES EDUCATION			English	Article; Early Access						peer-led learning; student outcomes; supplemental instruction; undergraduate human anatomy		Supplemental instruction (SI) confers student success, as represented by grades, knowledge retention, and student engagement. However, studies often report professional, not undergraduate, program findings. To measure these effects, students studying human anatomy at a university in Ontario, Canada, attended structured (peer-assisted) or unstructured (nonpeer-assisted) SI sessions and completed a pre-/post-survey. Fifty-eight learners (39 systems (SYS) and 19 musculoskeletal (MSK) anatomy) completed both surveys and had responses analyzed. Both cohorts, maintained initial perceptions across pre-/post-analyses (MSK p = 0.1376 and SYS p = 0.3521). Resource usage was similar across both cohorts with discrepancies in skeletal model and textbook use. No MSK learner ranked any lab resources as "not at all useful." MSK learners felt more prepared to write a graded assessment (p = 0.0269), whereas SYS learners did not (p = 0.0680). Stratification of learners in MSK and SYS revealed learners spending between 30 and 60 min in SI sessions during the study period had the highest grades compared to students who spent less than 30 (p = 0.0286) or more than 60 (p = 0.0286) min attending SI sessions, respectively. Most learners in MSK (89.4%) and SYS (66%) concluded that they preferred structured over unstructured SI. Sentiment/thematic analysis using a generative AI-driven large language model revealed learners held positive perceptions of SI, emphasizing structured learning, resources, personalized learning, and support offered as the most prevalent themes surrounding SI. Ultimately, this study provides evidence that supports SI for improving student outcomes related to perceived preparedness for completing assessments and preferred teaching/learning styles in undergraduate human anatomy.	[Wilson, Robert N.; Holman, Parker J.; Dragan, Martin; MacPherson, Rebecca E. K.; Beaudette, Shawn M.] Brock Univ, Fac Appl Hlth Sci, 1812 Sir Isaac Brock Way, St Catharines, ON L2S 3A1, Canada	Brock University	Beaudette, SM (corresponding author), Brock Univ, Fac Appl Hlth Sci, 1812 Sir Isaac Brock Way, St Catharines, ON L2S 3A1, Canada.	sbeaudette@brocku.ca		Beaudette, Shawn/0000-0002-8427-3959; Holman, Parker/0000-0003-1631-9924	Brock University; Brock University - Brock University Match of Minds award	Brock University; Brock University - Brock University Match of Minds award	This work was funded by a Brock University Chancellor's Chair for Teaching and Excellence award to Shawn M. Beaudette, Martin Dragan, Rebecca E. K. MacPherson, and Yasmeen Mezil. Robert N. Wilson was funded by a Brock University Match of Minds award.	Abedini M, 2013, PROCD SOC BEHV, V83, P39, DOI 10.1016/j.sbspro.2013.06.008; Anbu D, 2021, ADV EXP MED BIOL, V1334, P1, DOI 10.1007/978-3-030-76951-2_1; Anfuso C, 2022, INT J STEM EDUC, V9, DOI 10.1186/s40594-022-00372-w; Bauzon J, 2021, MED SCI EDUC, V31, P1319, DOI 10.1007/s40670-021-01306-x; Bell P, 2011, J CHEM EDUC, V88, P1469, DOI 10.1021/ed100328c; Bin Abdulrahman KA, 2021, ADV MED EDUC PRACT, V12, P627, DOI 10.2147/AMEP.S309535; Bruno PA, 2016, ANAT SCI EDUC, V9, P132, DOI 10.1002/ase.1543; Ehrlinger J, 2008, ORGAN BEHAV HUM DEC, V105, P98, DOI 10.1016/j.obhdp.2007.05.002; Foong CC, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02712-w; Forester JP, 2004, CLIN ANAT, V17, P322, DOI 10.1002/ca.10219; Gamlath S, 2022, HIGH EDUC RES DEV, V41, P699, DOI 10.1080/07294360.2021.1877625; Hamilton L, 2023, INT J QUAL METH, V22, DOI 10.1177/16094069231201504; Hurley KF, 2003, MED TEACH, V25, P404, DOI 10.1080/0142159031000136743; Ilçin N, 2018, BMC MED EDUC, V18, DOI 10.1186/s12909-018-1400-2; Kabbara J., 2023, AI sensemaking (prototyping) exploring how LLMs can be utilized to build AI power tools that can assist in a humanled AIassisted sensemaking process; Meyer B., 2008, WHAT IS INDEPENDENT; Navarro JJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141895; Snyder JJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115084; Stone Robyn, 2013, ISRN Nurs, V2013, P930901, DOI 10.1155/2013/930901; Szteinberg G, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-05-0091; Tadese M, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03461-0; University of Guelph, 2014, Supplemental instruction in Canadaguidelines for best practice; Zhang H, 2024, Arxiv, DOI arXiv:2309.10771	23	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1935-9772	1935-9780		ANAT SCI EDUC	Anat. Sci. Educ.	2024 JUN 2	2024										10.1002/ase.2464	http://dx.doi.org/10.1002/ase.2464		JUN 2024	12	Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research	SW2C3	38825716	hybrid			2024-07-03	WOS:001237410400001
J	Levshina, N; Koptjevskaja-Tamm, M; Östling, R				Levshina, Natalia; Koptjevskaja-Tamm, Maria; Ostling, Robert			Revered and reviled: a sentiment analysis of female and male referents in three languages	FRONTIERS IN COMMUNICATION			English	Article						semantic derogation; pejoration; sentiment analysis; diachronic corpora; semantic change; semantic prosody; gender stereotypes; prejudice	REPRESENTATION; CORPORA; CORPUS; WOMEN	Our study contributes to the less explored domain of lexical typology, focusing on semantic prosody and connotation. Semantic derogation, or pejoration of nouns referring to women, whereby such words acquire connotations and further denotations of social pejoration, immorality and/or loose sexuality, has been a very prominent question in studies on gender and language (change). It has been argued that pejoration emerges due to the general derogatory attitudes toward female referents. However, the evidence for systematic differences in connotations of female- vs. male-related words is fragmentary and often fairly impressionistic; moreover, many researchers argue that expressed sentiments toward women (as well as men) often are ambivalent. One should also expect gender differences in connotations to have decreased in the recent years, thanks to the advances of feminism and social progress. We test these ideas in a study of positive and negative connotations of feminine and masculine term pairs such as woman - man, girl - boy, wife - husband, etc. Sentences containing these words were sampled from diachronic corpora of English, Chinese and Russian, and sentiment scores for every word were obtained using two systems for Aspect-Based Sentiment Analysis: PyABSA, and OpenAI's large language model GPT-3.5. The Generalized Linear Mixed Models of our data provide no indications of significantly more negative sentiment toward female referents in comparison with their male counterparts. However, some of the models suggest that female referents are more infrequently associated with neutral sentiment than male ones. Neither do our data support the hypothesis of the diachronic convergence between the genders. In sum, results suggest that pejoration is unlikely to be explained simply by negative attitudes to female referents in general.	[Levshina, Natalia] Max Planck Inst Psycholinguist, Neurobiol & Language Dept, Nijmegen, Netherlands; [Levshina, Natalia] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands; [Koptjevskaja-Tamm, Maria; Ostling, Robert] Stockholm Univ, Dept linguist, Stockholm, Sweden	Max Planck Society; Radboud University Nijmegen; Stockholm University	Koptjevskaja-Tamm, M (corresponding author), Stockholm Univ, Dept linguist, Stockholm, Sweden.	tamm@ling.su.se		Levshina, Natalia/0000-0002-3669-8784	Netherlands Organisation for Scientific Research (NWO) under Gravitation grant "Language in Interaction" [024.001.006]; Swedish Research Agency (VR) [2019-04129]	Netherlands Organisation for Scientific Research (NWO) under Gravitation grant "Language in Interaction"(Netherlands Organization for Scientific Research (NWO)); Swedish Research Agency (VR)(Swedish Research Council)	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. Natalia Levshina's research was partly funded by the Netherlands Organisation for Scientific Research (NWO) under Gravitation grant "Language in Interaction", grant number 024.001.006. Robert Ostling's research was partly funded by the Swedish Research Agency (VR), grant number 2019-04129.	Aikhenvald A. Y., 2016, How gender shapes the world; Allport G. W., 1954, NATURE PREJUDICE; [Anonymous], 1993, New York Times Magazine; Baker P., 2014, USING CORPORA ANAL G; BEBOUT L, 1984, AM SPEECH, V59, P13, DOI 10.2307/454991; Borkowska P., 2007, Stud Anglica Resoviensia, V47, P33; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Caldas-Coulthard CR, 2010, DISCOURSE SOC, V21, P99, DOI 10.1177/0957926509353843; Charlesworth TES, 2021, PSYCHOL SCI, V32, P218, DOI 10.1177/0956797620963619; Davies M, 2010, LIT LINGUIST COMPUT, V25, P447, DOI 10.1093/llc/fqq018; Defranza D, 2020, J PERS SOC PSYCHOL, V119, P7, DOI 10.1037/pspa0000188; Dovidio JF, 2005, ON THE NATURE OF PREJUDICE: FIFTY YEARS AFTER ALLPORT, P1, DOI 10.1002/9780470773963.ch1; Durkheim E., 1989, Sociology and philosophy; Fiske ST, 2002, J PERS SOC PSYCHOL, V82, P878, DOI 10.1037//0022-3514.82.6.878; Fiske ST, 2018, CURR DIR PSYCHOL SCI, V27, P67, DOI 10.1177/0963721417738825; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Gelman A., 2006, Data Analysis Using Regression and Multilevel/Hierarchical Models, DOI 10.1017/CBO9780511790942; Georgakopoulos T, 2021, J HIST LINGUIST, V11, P367, DOI 10.1075/jhl.19018.geo; Glick P, 1996, J PERS SOC PSYCHOL, V70, P491, DOI 10.1037/0022-3514.70.3.491; Gough H.G., 1965, The Adjective Check List Manual; Grzega J., 2004, Onomasiology Online, V51, P1; Herdagdelen A, 2011, J AM SOC INF SCI TEC, V62, P1741, DOI 10.1002/asi.21579; Hosseini-Asl E., 2022, arXiv, V2022, P5356, DOI [10.48550/arXiv.2204.05356, DOI 10.48550/ARXIV.2204.05356]; Hoyle A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1706; Jackson L. M., 2011, Defining prejudice. The psychology of prejudice: From attitudes to social action; the psychology of prejudice: From attitudes to social action, P7; Jakobson Roman., 1932, SELECTED WRITING, VII, P3; Juvonen P, 2016, COGN LINGUIST RES, V58, P223; Kim M, 2008, KOREAN STUD, V32, P148, DOI 10.1353/ks.0.0000; Kleparski G., 1997, Theory and practice of historical semantics: the case of middle English and Early Modern English synonyms of girl/young women; Koptjevskaja-Tamm M, 2012, LINGUISTICS, V50, P373, DOI 10.1515/ling-2012-0013; Macalister J, 2011, CORPORA, V6, P25, DOI 10.3366/cor.2011.0003; Morehouse K., 2023, Traces of human attitudes in contemporary and historical word embeddings (1800-2000); MOSCOVICI S, 1988, EUR J SOC PSYCHOL, V18, P211, DOI 10.1002/ejsp.2420180303; Norberg C, 2016, J ENGL LINGUIST, V44, P291, DOI 10.1177/0075424216665672; Nosek BA, 2007, EUR REV SOC PSYCHOL, V18, P36, DOI 10.1080/10463280701489053; Osgood C. E., 1975, CROSS CULTURAL UNIVE; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Payne BK, 2019, P NATL ACAD SCI USA, V116, P11693, DOI 10.1073/pnas.1818816116; Pearce M, 2008, CORPORA, V3, P1, DOI 10.3366/E174950320800004X; Potts A, 2018, INT J SEMIOTIC LAW, V31, P21, DOI 10.1007/s11196-017-9523-z; Romaine S., 2000, LANGUAGE SOC INTRO S, V2nd; Salmons J., 1990, Research guide on language change, P71; Schulz Muriel., 1975, LANGUAGE SEX DIFFERE; Stern Gustaf., 1931, Meaning and change of meaning; Taylor C, 2013, CORPORA, V8, P81, DOI 10.3366/cor.2013.0035; Tyler Anne., 1980, MORGANS PASSING; Ullmann Stephen., 1957, The Principles of Semantics; Vejdemo S, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147924; Williams J. E., 1990, Measuring Sex Stereotypes: A Multination Study; Yang H., 2023, arXiv, V2023, P01368, DOI [10.48550/arXiv.2208.01368, DOI 10.48550/ARXIV.2208.01368]; Zasina A. J., 2019, J. Linguist, V70, P299, DOI [10.2478/jazcas-2019-0060, DOI 10.2478/JAZCAS-2019-0060]; Zhang W., 2022, arXiv, V2022, P01054, DOI [10.48550/arXiv.2203.01054, DOI 10.48550/ARXIV.2203.01054]	52	0	0	4	4	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2297-900X		FRONT COMMUN	Front. Commun.	MAR 28	2024	9								1266407	10.3389/fcomm.2024.1266407	http://dx.doi.org/10.3389/fcomm.2024.1266407			21	Communication	Emerging Sources Citation Index (ESCI)	Communication	NI4P2		Green Published, gold			2024-07-03	WOS:001199813900001
C	Fu, CL; Wu, WC; Zhang, XL; Hu, J; Wang, J; Zhou, J			ACM	Fu, Chilin; Wu, Weichang; Zhang, Xiaolu; Hu, Jun; Wang, Jing; Zhou, Jun			Robust User Behavioral Sequence Representation via Multi-scale Stochastic Distribution Prediction	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		machine learning; sequential data mining; representation learning		User behavior representation learned by self-supervised pre-training tasks is widely used in various domains and applications. Conventional methods usually follow the methodology in Natural Language Processing (NLP) to set the pre-training tasks. They either randomly mask some of the behaviors in the sequence and predict the masked ones or predict the next k. behaviors. These methods fit for text sequence, in which the tokens are sequentially arranged subject to linguistic criterion. However, the user behavior sequences can be stochastic with noise and randomness. The same paradigm is intractable for learning a robust user behavioral representation. Though the next user behavior can be stochastic, the behavior distribution over a period of time is much more stable and less noisy. Based on this, we propose a Multi-scale Stochastic Distribution Prediction (MSDP) algorithm for learning robust user behavioral sequence representation. Instead of using predictions on concrete behavior as pre-training tasks, we take the prediction on user's behaviors distribution over a period of time as the self-supervision signal. Moreover, inspired by the recent success of the multi-task prompt training method on Large Language Models (LLM), we propose using the window size of the predicted time period as a prompt, enabling the model to learn user behavior representations that can be applied to prediction tasks across various future time periods. We generate different window size prompts through stochastic sampling. It effectively improves the generalization capability of the learned sequence representation. Extensive experiments demonstrate that our approach can learn robust user behavior representation successfully, which significantly outperforms state-of-the-art (SOTA) baselines.	[Fu, Chilin; Wu, Weichang; Zhang, Xiaolu; Hu, Jun; Wang, Jing; Zhou, Jun] Ant Grp, Hangzhou, Zhejiang, Peoples R China		Zhou, J (corresponding author), Ant Grp, Hangzhou, Zhejiang, Peoples R China.	chilin.fcl@antgroup.com; jiuyue.wwc@antgroup.com; yueyin.zxl@antfin.com; zhaoda.hj@antgroup.com; lingchen.wj@antgroup.com; jun.zhoujun@antfin.com		Fu, Chilin/0000-0001-9719-4638; , Xiaolu/0000-0001-8055-0245; ZHOU, JUN/0000-0001-6033-6102; Weichang, Wu/0000-0003-4575-9419				Adiwardana D., 2020, Towards a Human-like Open-Domain Chatbot; Bachman P, 2019, ADV NEUR IN, V32; Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549; Cheng MY, 2021, IEEE DATA MINING, P51, DOI 10.1109/ICDM51629.2021.00015; Devlin J., 2018, BERT PRE TRAINING DE; Dong Li, 2019, ADV NEURAL INFORM PR; Gu J, 2021, AAAI CONF ARTIF INTE, V35, P4063; Pancha N, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3702, DOI 10.1145/3534678.3539156; Raffel C., 2019, arXiv preprint arXiv:1910.10683; Shin Kyuyong, 2021, ARXIV210600573; van Erven T, 2014, IEEE T INFORM THEORY, V60, P3797, DOI 10.1109/TIT.2014.2320500; Vaswani A, 2017, ADV NEUR IN, V30; Wu CH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2087, DOI 10.1145/3477495.3531810; Wu CH, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1939; Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637; Zhang Yuyu, 2014, ABS14086515 CORR; Zhao QH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1812, DOI 10.1145/3477495.3532054; Zhong WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2287, DOI 10.1145/2783258.2788565	18	1	1	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							4567	4573		10.1145/3583780.3614714	http://dx.doi.org/10.1145/3583780.3614714			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549504113
J	Khan, N; Khan, Z; Koubaa, A; Khan, MK; Salleh, RB				Khan, Nauman; Khan, Zahid; Koubaa, Anis; Khan, Muhammad Khurram; Salleh, Rosli bin			Global insights and the impact of generative AI-ChatGPT on multidisciplinary: a systematic review and bibliometric analysis	CONNECTION SCIENCE			English	Review						LLM-ChatGPT; bibliometric analysis; interdisciplinary research; demographic analysis; generative AI; geographic distribution; 0000; 1111	ARTIFICIAL-INTELLIGENCE	In 2022, OpenAI's unveiling of generative AI Large Language Models (LLMs)- ChatGPT, heralded a significant leap forward in human-machine interaction through cutting-edge AI technologies. With its surging popularity, scholars across various fields have begun to delve into the myriad applications of ChatGPT. While existing literature reviews on LLMs like ChatGPT are available, there is a notable absence of systematic literature reviews (SLRs) and bibliometric analyses assessing the research's multidisciplinary and geographical breadth. This study aims to bridge this gap by synthesising and evaluating how ChatGPT has been integrated into diverse research areas, focussing on its scope and the geographical distribution of studies. Through a systematic review of scholarly articles, we chart the global utilisation of ChatGPT across various scientific domains, exploring its contribution to advancing research paradigms and its adoption trends among different disciplines. Our findings reveal a widespread endorsement of ChatGPT across multiple fields, with significant implementations in healthcare (38.6%), computer science/IT (18.6%), and education/research (17.3%). Moreover, our demographic analysis underscores ChatGPT's global reach and accessibility, indicating participation from 80 unique countries in ChatGPT-related research, with the most frequent countries keyword occurrence, USA (719), China (181), and India (157) leading in contributions. Additionally, our study highlights the leading roles of institutions such as King Saud University, the All India Institute of Medical Sciences, and Taipei Medical University in pioneering ChatGPT research in our dataset. This research not only sheds light on the vast opportunities and challenges posed by ChatGPT in scholarly pursuits but also acts as a pivotal resource for future inquiries. It emphasises that the generative AI (LLM) role is revolutionising every field. The insights provided in this paper are particularly valuable for academics, researchers, and practitioners across various disciplines, as well as policymakers looking to grasp the extensive reach and impact of generative AI technologies like ChatGPT in the global research community.	[Khan, Nauman; Khan, Zahid; Koubaa, Anis] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia; [Khan, Nauman; Salleh, Rosli bin] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia; [Khan, Nauman] Univ Malakand, Dept Comp Sci & Informat Technol, Chakdara, KPK, Pakistan; [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance CoEIA, Riyadh, Saudi Arabia	Prince Sultan University; Universiti Malaya; University of Malakand; King Saud University	Khan, N; Khan, Z (corresponding author), Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.; Khan, N (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.; Khan, N (corresponding author), Univ Malakand, Dept Comp Sci & Informat Technol, Chakdara, KPK, Pakistan.	khannauman52@gmail.com; zskhan@psu.edu.sa			Prince Sultan University; King Saud University, Riyadh, Saudi Arabia [RSP2024R12]	Prince Sultan University; King Saud University, Riyadh, Saudi Arabia(King Saud University)	The authors would like to acknowledge the support of Prince Sultan University for funding the Article Processing Charges (APC) of this publication. In addition, the work of Muhammad Khurram Khan is supported by King Saud University, Riyadh, Saudi Arabia under project number (RSP2024R12).	Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Agapiou A, 2023, HERITAGE-BASEL, V6, P4072, DOI 10.3390/heritage6050214; Alhasan K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36263; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Almazyad M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38249; Altamimi I, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40351; Amaro I, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3291539; Amin MM, 2023, IEEE INTELL SYST, V38, P15, DOI 10.1109/MIS.2023.3254179; Amin MM, 2023, IEEE INTELL SYST, V38, P5, DOI 10.1109/MIS.2023.3305861; Badini S, 2023, ADV IND ENG POLY RES, V6, P278, DOI 10.1016/j.aiepr.2023.03.003; Badshah A, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15110367; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Bhavya B., 2022, arXiv; Borger JG, 2023, IMMUNOL CELL BIOL, V101, P923, DOI 10.1111/imcb.12689; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Buckingham L, 2023, AUSTR INTELLECT PROP, V33; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Chan A., 2022, AI and Ethics, V3, P53, DOI DOI 10.1007/S43681-022-00148-6; Chatterjee S, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00700-1; Chen BY, 2023, J CHIN ECON BUS STUD, V21, P471, DOI 10.1080/14765284.2023.2245279; Cheng KM, 2023, ANN BIOMED ENG, V51, P1645, DOI 10.1007/s10439-023-03221-1; Cheng KM, 2023, ANN BIOMED ENG, V51, P1130, DOI 10.1007/s10439-023-03203-3; Chowdhury Minhaz, 2023, 2023 IEEE International Conference on Electro Information Technology (eIT), P499, DOI 10.1109/eIT57321.2023.10187385; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cui LM, 2023, EUR INTEGR STUD, P175, DOI 10.5755/j01.eis.1.17.33726; D'Souza RF, 2023, ASIAN J PSYCHIATR, V89, DOI 10.1016/j.ajp.2023.103770; Dai X., 2023, 2023 IEEE INT C ENV, P1; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Deeper Insights, 2023, ChatGPT: Technical innovations and business impacts in 2023; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Dogru T, 2023, J HOSP TOUR RES, DOI 10.1177/10963480231188663; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Feldstein S, 2023, SURVIVAL, V65, P117, DOI 10.1080/00396338.2023.2261260; Ferruz N., 2022, BioRxiv, P2022; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Frederico GF, 2023, LOGISTICS-BASEL, V7, DOI 10.3390/logistics7020026; Gabashvili IS, 2023, Arxiv, DOI arXiv:2305.18086; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Gill Sukhpal Singh, 2023, Internet Things Cyber-Phys. Syst, V3, P262, DOI DOI 10.1016/J.IOTCPS.2023.05.004; Gimpel H., 2023, Hohenheim Discussion Papers in Business, Economics and Social Sciences; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Gupta R, 2023, AESTHET SURG J, DOI 10.1093/asj/sjad128; Habibi A, 2023, Computers and Education: Artificial Intelligence, V5, DOI DOI 10.1016/J.CAEAI.2023.100190; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Harasymowicz J, 2022, ARCH BUDO SCI MARTIA, V18, P51; Hewett J, 2022, IEEE PAC RIM INT SYM, P205, DOI 10.1109/PRDC55274.2022.00034; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Hung JS, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12070380; Iskender A, 2023, EUR J TOUR RES, V34, DOI 10.54055/ejtr.v34i.3169; Ivanov S, 2021, J TOUR FUTURES, V9, P214, DOI 10.1108/JTF-02-2023-0038; Juhi A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36272; Jungherr A, 2023, COMMUN THEOR, V33, P164, DOI 10.1093/ct/qtad006; Khademi A., 2023, Journal of Applied Learning Teaching, V6, P1; Khan I, 2023, ANN BIOMED ENG, V51, P2125, DOI 10.1007/s10439-023-03356-1; Khosravi H, 2023, Arxiv, DOI arXiv:2304.05436; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kinoshita R., 2022, P IEEE INT C AG ICA, P24, DOI DOI 10.1109/ICA55837.2022.00011; Koubaa A., 2023, GPT-4 vs. GPT-3.5: A concise show; Koubaa A, 2023, IEEE ACCESS, V11, P118698, DOI 10.1109/ACCESS.2023.3326474; Kumar Y., 2023, A testing framework for AI linguistic systems (testfails); Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Lammerse M., 2022, 2022 14 INT C QUAL M, P1; Lappalainen Y, 2023, J WEB LIBRARIANSH, V17, P37, DOI 10.1080/19322909.2023.2221477; Lee M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102320; Li Pin-Hui, 2023, Innovative Technologies and Learning: 6th International Conference, ICITL 2023, Proceedings. Lecture Notes in Computer Science (14099), P77, DOI 10.1007/978-3-031-40113-8_8; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Long-Hao Wang, 2023, Procedia Computer Science, P1493, DOI 10.1016/j.procs.2023.08.012; Lopes APL, 2023, RETHINK HIST, V27, P709, DOI 10.1080/13642529.2023.2234227; Lower K, 2023, INDIAN J ORTHOP, V57, P1527, DOI 10.1007/s43465-023-00967-7; Lubiana T, 2023, PLOS COMPUT BIOL, V19, DOI 10.1371/journal.pcbi.1011319; Lund BD, 2024, LEARN PUBL, V37, P13, DOI 10.1002/leap.1582; Luo HX, 2023, Arxiv, DOI arXiv:2310.06278; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mannuru NR, 2023, INFORM DEV, DOI 10.1177/02666669231200628; Mardikoraem M, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad358; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Miao Hongyu, 2023, Asian Pac Isl Nurs J, V7, pe48136, DOI 10.2196/48136; Michail A, 2023, Arxiv, DOI arXiv:2303.01194; Mohammed M, 2023, J RACIAL ETHN HEALTH, DOI 10.1007/s40615-023-01696-1; Mondal H, 2023, INDIAN DERMATOL ONL, V14, P482, DOI 10.4103/idoj.idoj_72_23; Mujahid M, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3605889; Nair Madhav, 2023, Cyber Security, Cryptology, and Machine Learning: 7th International Symposium, CSCML 2023, Proceedings. Lecture Notes in Computer Science (13914), P320, DOI 10.1007/978-3-031-34671-2_23; Nawaz A, 2023, IEEE ACCESS, V11, P56170, DOI 10.1109/ACCESS.2023.3281859; OpenAI, Introducing ChatGPT; OpenAI, ChatGPT-release notes; PCMag, GPT-4 vs. ChatGPT-3.5: What's the difference?; Qu YB, 2020, IEEE INT CONF ELECTR, P323, DOI 10.1109/iceiec49280.2020.9152352; Qureshi Basit, 2023, ICSLT 2023: Proceedings of the 2023 9th International Conference on e-Society, e-Learning and e-Technologies, P7, DOI 10.1145/3613944.3613946; Rahimzadeh V, 2023, AM J BIOETHICS, V23, P17, DOI 10.1080/15265161.2023.2233358; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Ratten V, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100857; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rojas-Carabali W, 2023, OCUL IMMUNOL INFLAMM, DOI 10.1080/09273948.2023.2253471; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Schneider ETR, 2021, COMP MED SY, P474, DOI 10.1109/CBMS52027.2021.00056; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sarma G, 2023, INDIAN J OTOLARYNGOL, DOI 10.1007/s12070-023-04201-6; Schäfer MS, 2023, JCOM-J SCI COMMUN, V22, DOI 10.22323/2.22020402; Seth I, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000004999; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Sethi HS, 2023, INDIAN J RADIOL IMAG, V33, P440, DOI 10.1055/s-0043-1772465; Shrivastava Adarsh, 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P1345, DOI 10.1109/ICICCS51141.2021.9432283; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Sudheesh R, 2023, INFORMATION, V14, DOI 10.3390/info14090474; Tafferner Z, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23104879; Tan J., 2023, ARTIFICIAL INTELLIGE; Tyson J, 2023, J CHEM EDUC, V100, P3098, DOI 10.1021/acs.jchemed.3c00361; Vaswani A, 2017, ADV NEUR IN, V30; Vecchiarini M, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100879; Venkataswamy R, 2024, ANN BIOMED ENG, V52, P738, DOI 10.1007/s10439-023-03316-9; VOSviewer, 2023, Visualizing Scientific Landscapes; Vrontis D, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151612196; Wang BY, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3611651; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P2011, DOI 10.1109/TIV.2023.3256799; Wang FY, 2023, IEEE T COMPUT SOC SY, V10, P414, DOI 10.1109/TCSS.2023.3252679; Xie Y, 2024, ANZ J SURG, V94, P68, DOI 10.1111/ans.18666; Xie Y, 2023, AESTHET PLAST SURG, V47, P2360, DOI 10.1007/s00266-023-03443-7; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Zhang JP, 2023, IEEE T INTELL VEHICL, V8, P2027, DOI 10.1109/TIV.2023.3256982; Zhang P, 2024, EUR J EDUC, V59, DOI 10.1111/ejed.12599; Zhang WX, 2023, LECT NOTES COMPUT SC, V14258, P181, DOI 10.1007/978-3-031-44192-9_15; Zhang YF, 2023, P INT COMP SOFTW APP, P1780, DOI 10.1109/COMPSAC57700.2023.00275; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	129	0	0	45	45	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0954-0091	1360-0494		CONNECT SCI	Connect. Sci.	DEC 31	2024	36	1							2353630	10.1080/09540091.2024.2353630	http://dx.doi.org/10.1080/09540091.2024.2353630			51	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RG4D6		hybrid			2024-07-03	WOS:001226491800001
J	Aktas, EU; Cakmak, E; Inan, MC; Yilmaz, C				Aktas, Ethem Utku; Cakmak, Ebru; Inan, Mete Cihad; Yilmaz, Cemal			Improving the quality of software issue report descriptions in Turkish: An industrial case study at Softtech	EMPIRICAL SOFTWARE ENGINEERING			English	Article						Issue triaging; Issue report quality; Issue report classification; Morphological analysis		Issue reports are an important part of the software development process. They help developers identify and fix problems in their code. However, problems described in these reports often lack important information, such as the Observed Behavior (OB), Expected Behavior (EB), and Steps to Reproduce (S2R). This can lead to valuable developer time being wasted on gathering the relevant information. This study aims to address this issue by developing a tool that guides reporters in providing the necessary information in an industrial setting. The study is conducted at Softtech, a software subsidiary of the largest private bank in Turkey. The proposed approach is developed for issue reports written specifically in Turkish language. It is motivated by the need for issue report classification tools that can handle the unique characteristics of the Turkish language, such as the presence of many compound words. We first manually analyze and label 1, 041 issue reports for the existence of OB, S2R, and EB, and then present the specific patterns we found describing the related information. Next, we use morphological analysis to extract keywords and suffixes, and then use them for classification with a machine learning based approach. In addition, we conduct a feasibility study to assess the potential of using large language models for issue report classification tasks as a direction for future research. The results indicate that the tool using the machine learning-based approach can be used to guide in improving the quality of issue reports at Softtech, thereby saving valuable developer time.	[Aktas, Ethem Utku; Inan, Mete Cihad] Softtech Inc, Res & Dev Ctr, TR-34947 Istanbul, Turkiye; [Cakmak, Ebru] Microsoft EMEA, Istanbul, Turkiye; [Yilmaz, Cemal] Sabanci Univ, Fac Engn & Nat Sci, TR-34956 Istanbul, Turkiye	Sabanci University	Aktas, EU (corresponding author), Softtech Inc, Res & Dev Ctr, TR-34947 Istanbul, Turkiye.	utku.aktas@softtech.com.tr; ebrucakmak@microsoft.com; cihad.inan@softtech.com.tr; cyilmaz@sabanciuniv.edu		Aktas, Ethem Utku/0000-0001-9522-5357				Akin A. A., 2007, Structure, V10, P1; Aktas EU, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-022-10228-0; Aktas EU, 2020, EMPIR SOFTW ENG, V25, P3544, DOI 10.1007/s10664-020-09846-3; [Anonymous], 1998, European Conference on Machine Learning, DOI [10.1007/, DOI 10.1007/BFB0026683]; Behrang F, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P164, DOI 10.1145/3213846.3213854; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chantree F, 2006, RE'06: 14TH IEEE INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE, PROCEEDINGS, P59; Chaparro O, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P86, DOI 10.1145/3338906.3338947; Chaparro O, 2019, EMPIR SOFTW ENG, V24, P2947, DOI 10.1007/s10664-018-9672-z; Chaparro O, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER), P218, DOI [10.1109/SANER.2019.8667985, 10.1109/saner.2019.8667985]; Chaparro O, 2017, PROC IEEE INT CONF S, P376, DOI 10.1109/ICSME.2017.100; Chaparro O, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P396, DOI 10.1145/3106237.3106285; Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953; Çöltekin Ç, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION; Çöltekin Ç, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1079; CoreNLP, 2021, About us; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dougherty G., 2012, Pattern Recognition and Classification: An Introduction; Fazzini M, 2023, IEEE T SOFTWARE ENG, V49, P1246, DOI 10.1109/TSE.2022.3174028; Femmer H., 2014, PROC 1 INT WORKSHOP, P10; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Gao JF, 2018, ACM/SIGIR PROCEEDINGS 2018, P1371, DOI 10.1145/3209978.3210183; Hata M, 2019, PROC IEEE INT CONF S, P422, DOI 10.1109/ICSME.2019.00074; Inan MC, 2023, IN PRESS; Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI 10.18653/v1/e17-2068; Kallis R, 2022, 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING (NLBSE 2022), P25, DOI 10.1145/3528588.3528664; Kallis R, 2021, SCI COMPUT PROGRAM, V205, DOI 10.1016/j.scico.2020.102598; Kallis R, 2019, PROC IEEE INT CONF S, P406, DOI 10.1109/ICSME.2019.00070; Kang S, 2023, PROC INT CONF SOFTW, P2312, DOI 10.1109/ICSE48619.2023.00194; Lemaître G, 2017, J MACH LEARN RES, V18; Maiya AS., 2022, The Journal of Machine Learning Research, V23, P7070; Manning C. D., 2008, Introduction to information retrieval, DOI [DOI 10.1017/CBO9780511809071, 10.1017/CBO9780511809071]; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Oflazer K., 1994, Literary & Linguistic Computing, V9, P137, DOI 10.1093/llc/9.2.137; Oflazer K, 2014, LANG RESOUR EVAL, V48, P639, DOI 10.1007/s10579-014-9267-2; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shokripour R, 2015, J SYST SOFTWARE, V102, P109, DOI 10.1016/j.jss.2014.12.049; Song Y., 2023, arXiv; Song Y, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P344, DOI 10.1145/3540250.3549131; Song Y, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1551, DOI 10.1145/3368089.3417928; Thompson S.K., 2012, Sampling, V755; Zeller A, 2009, WHY PROGRAMS FAIL: A GUIDE TO SYSTEMATIC DEBUGGING, 2ND EDITION; Zhang ZX, 2023, Arxiv, DOI arXiv:2301.07775; Zimmermann T, 2010, IEEE T SOFTWARE ENG, V36, P618, DOI 10.1109/TSE.2010.63	47	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1382-3256	1573-7616		EMPIR SOFTW ENG	Empir. Softw. Eng.	MAR	2024	29	2							43	10.1007/s10664-023-10434-4	http://dx.doi.org/10.1007/s10664-023-10434-4			37	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	HM8N1					2024-07-03	WOS:001160014500002
J	Chandwar, K; Misra, DP				Chandwar, Kunal; Misra, Durga Prasanna			What does artificial intelligence mean in rheumatology?	ARCHIVES OF RHEUMATOLOGY			English	Review						Artificial intelligence; deep learning; image analysis machine learning; rheumatology	PREDICTION; CHATGPT	Intelligence is the ability of humans to learn from experiences to ascribe conscious weights and unconscious biases to modulate their outputs from given inputs. Transferring this ability to computers is artificial intelligence (AI). The ability of computers to understand data in an intelligent manner is machine learning. When such learning is with images and videos, which involves deeper layers of artificial neural networks, it is described as deep learning. Large language models are the latest development in AI which incorporate self-learning into deep learning through transformers. AI in Rheumatology has immense potential to revolutionize healthcare and research. Machine learning could aid clinical diagnosis and decision-making, and deep learning could extend this to analyze images of radiology or positron emission tomography scans or histopathology images to aid a clinician's diagnosis. Analysis of routinely obtained patient data or continuously collected information from wearables could predict disease flares. Analysis of high -volum e genomics, transcriptomics, proteomics, or metabolomics data from patients could help identify novel markers of disease prognosis. AI might identify newer therapeutic targets based on in-silico modelling of omics data. AI could help automate medical administrative work such as inputting information into electronic health records or transcribing clinic notes. AI could help automate patient education and counselling. Beyond the clinic, AI has the potential to aid medical education. The ever-expanding capabilities of AI models bring along with them considerable ethical challenges, particularly related to risks of misuse. Nevertheless, the widespread use of AI in Rheumatology is inevitable and a progress with great potential.	[Chandwar, Kunal; Misra, Durga Prasanna] Sanjay Gandhi Postgrad Inst Med Sci SGPGIMS, Dept Clin Immunol & Rheumatol, Lucknow, India	Sanjay Gandhi Postgraduate Institute of Medical Sciences	Misra, DP (corresponding author), Sanjay Gandhi Postgrad Inst Med Sci SGPGIMS, Dept Clin Immunol & Rheumatol, Lucknow, India.	durgapmisra@gmail.com	Chandwar, Kunal/GLQ-8637-2022	Chandwar, Kunal/0000-0002-0499-0641				Al-Maini M, 2023, RHEUMATOL INT, DOI 10.1007/s00296-023-05415-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bard from Google, About us; Ben Chaabane N, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-49883-8; Bordner A, 2023, DIAGN INTERV IMAG, V104, P373, DOI 10.1016/j.diii.2023.03.008; Campochiaro C, 2022, RHEUMATOLOGY, V61, pSI4, DOI 10.1093/rheumatology/keab644; ChatGPT4, About us; Cheng J, 2023, SCIENCE, V381, P1303, DOI 10.1126/science.adg7492; Claude, About us; Codipilly DC, 2024, CLIN GASTROENTEROL H, V22, P1170, DOI 10.1016/j.cgh.2023.11.044; Colom Roberto, 2010, Dialogues Clin Neurosci, V12, P489; Cooper A, 2023, NEW ENGL J MED, V389, P385, DOI 10.1056/NEJMp2304993; Divito CB, 2024, MED TEACH, V46, P320, DOI 10.1080/0142159X.2023.2290997; Dixon WG, 2019, NPJ DIGIT MED, V2, DOI 10.1038/s41746-019-0180-3; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Eriksen AV., 2023, NEJM AI, V1, DOI [DOI 10.1056/AIP2300031, 10.1056/AIp2300031]; Fedor S, 2023, NEW ENGL J MED, V389, P2457, DOI 10.1056/NEJMra2215898; Frederiksen BA, 2022, ADV RHEUMATOL, V62, DOI 10.1186/s42358-022-00263-2; Gomes B, 2023, NEW ENGL J MED, V388, P2456, DOI 10.1056/NEJMra2204787; Gomez MBD, 2023, NAT MED, DOI 10.1038/s41591-023-02620-0; Gossec L, 2019, ARTHRIT CARE RES, V71, P1336, DOI 10.1002/acr.23768; Grok, About us; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Healthcareitnews, About us; Hugle Thomas, 2022, Digit Biomark, V6, P31, DOI 10.1159/000525061; Humbert-Droz M, 2023, ARTHRIT CARE RES, V75, P608, DOI 10.1002/acr.24869; Hunter DJ, 2023, NEW ENGL J MED, V389, P1211, DOI 10.1056/NEJMra2212850; Hutson Matthew, 2023, Nature, DOI 10.1038/d41586-023-03596-0; Jagtap S, 2023, RHEUMATOLOGY, DOI 10.1093/rheumatology/kead584; Jans LBO, 2021, RADIOLOGY, V298, P343, DOI 10.1148/radiol.2020201537; Jorge AM, 2022, LUPUS, V31, P1296, DOI 10.1177/09612033221114805; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kassani PH, 2024, PEDIATR RES, V95, P981, DOI 10.1038/s41390-023-02894-7; Katsushika S, 2022, CIRC J, V86, P87, DOI 10.1253/circj.CJ-21-0265; Knevel R, 2023, ANN RHEUM DIS, V82, P306, DOI 10.1136/ard-2022-222626; Konstantonis G, 2022, RHEUMATOL INT, V42, P215, DOI 10.1007/s00296-021-05062-4; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Labinsky H, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13010148; Lee C, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-48842-7; Lyu J, 2023, bioRxiv, DOI [10.1101/2023.12.20.572662, 10.1101/2023.12.20.572662, DOI 10.1101/2023.12.20.572662]; Madhvapathy SR, 2023, SCIENCE, V381, P1105, DOI 10.1126/science.adh7726; Manrai A, 2023, NEJM AI, V1; Menni C, 2022, LANCET, V399, P1618, DOI 10.1016/S0140-6736(22)00327-0; Menni C, 2020, NAT MED, V26, P1037, DOI 10.1038/s41591-020-0916-2; Misra DP, 2023, J ROY COLL PHYS EDIN, V53, P90, DOI 10.1177/14782715231181023; Misra DP, 2023, BEST PRACT RES CL RH, V37, DOI 10.1016/j.berh.2023.101826; Misra DP, 2023, RHEUM DIS CLIN N AM, V49, P19, DOI 10.1016/j.rdc.2022.07.004; Misra DP, 2021, J KOREAN MED SCI, V36, DOI 10.3346/jkms.2021.36.e338; Misra DP, 2019, RHEUMATOL INT, V39, P403, DOI 10.1007/s00296-019-04248-1; Navarini L, 2020, RHEUMATOLOGY, V59, P1767, DOI 10.1093/rheumatology/kez677; Ora M, 2023, CLIN RHEUMATOL, V42, P1855, DOI 10.1007/s10067-023-06600-0; Panda S C, 2006, Mens Sana Monogr, V4, P127, DOI 10.4103/0973-1229.27610; Paravastu SS, 2022, PET CLIN, V17, P95, DOI 10.1016/j.cpet.2021.09.003; Phatak S, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1280462; Shafi S, 2023, DIAGN PATHOL, V18, DOI 10.1186/s13000-023-01375-z; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Spatz ES, 2024, NEW ENGL J MED, V390, P346, DOI 10.1056/NEJMra2301903; Stoel B, 2020, RMD OPEN, V6, DOI 10.1136/rmdopen-2019-001063; Tsoutsanis P, 2024, COMPUT BIOL MED, V168, DOI 10.1016/j.compbiomed.2023.107794; van Helvoort EM, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-035101; Venerito V, 2023, LANCET RHEUMATOL, V5, pE574, DOI 10.1016/S2665-9913(23)00216-3; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Wang M, 2023, ARTHRITIS RHEUMATOL, V75, P2252, DOI 10.1002/art.42635; Zheng HW, 2022, J BIOMED INFORM, V135, DOI 10.1016/j.jbi.2022.104214; Zhou LQ, 2023, CLIN EXP IMMUNOL, V212, P224, DOI 10.1093/cei/uxad037; US	67	0	0	3	3	TURKISH LEAGUE AGAINST RHEUMATISM	ANKARA	TALATPASA BULVARI DUMLUPINAR CAD 40 3 CEBECI DORTYOL, ANKARA, 06100, Turkiye		2618-6500		ARCH RHEUMATOL	Arch. Rheumatol.	MAR	2024	39	1					1	9		10.46497/ArchRheumatol.2024.10664	http://dx.doi.org/10.46497/ArchRheumatol.2024.10664			9	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	NO6E5	38774703	Green Accepted, gold			2024-07-03	WOS:001201423200001
J	Chen, TC; Couldwell, MW; Singer, J; Singer, A; Koduri, L; Kaminski, E; Nguyen, K; Multala, E; Dumont, AS; Wang, AR				Chen, Tse Chiang; Couldwell, Mitchell W.; Singer, Jorie; Singer, Alyssa; Koduri, Laila; Kaminski, Emily; Nguyen, Khoa; Multala, Evan; Dumont, Aaron S.; Wang, Arthur			Assessing the clinical reasoning of ChatGPT for mechanical thrombectomy in patients with stroke	JOURNAL OF NEUROINTERVENTIONAL SURGERY			English	Article						Thrombectomy; Stroke		BackgroundArtificial intelligence (AI) has become a promising tool in medicine. ChatGPT, a large language model AI Chatbot, shows promise in supporting clinical practice. We assess the potential of ChatGPT as a clinical reasoning tool for mechanical thrombectomy in patients with stroke.MethodsAn internal validation of the abilities of ChatGPT was first performed using artificially created patient scenarios before assessment of real patient scenarios from the medical center's stroke database. All patients with large vessel occlusions who underwent mechanical thrombectomy at Tulane Medical Center between January 1, 2022 and December 31, 2022 were included in the study. The performance of ChatGPT in evaluating which patients should undergo mechanical thrombectomy was compared with the decisions made by board-certified stroke neurologists and neurointerventionalists. The interpretation skills, clinical reasoning, and accuracy of ChatGPT were analyzed.Results102 patients with large vessel occlusions underwent mechanical thrombectomy. ChatGPT agreed with the physician's decision whether or not to pursue thrombectomy in 54.3% of the cases. ChatGPT had mistakes in 8.8% of the cases, consisting of mathematics, logic, and misinterpretation errors. In the internal validation phase, ChatGPT was able to provide nuanced clinical reasoning and was able to perform multi-step thinking, although with an increased rate of making mistakes.ConclusionChatGPT shows promise in clinical reasoning, including the ability to factor a patient's underlying comorbidities when considering mechanical thrombectomy. However, ChatGPT is prone to errors as well and should not be relied on as a sole decision-making tool in its present form, but it has potential to assist clinicians with more efficient work flow.	[Chen, Tse Chiang; Couldwell, Mitchell W.; Singer, Jorie; Singer, Alyssa; Koduri, Laila; Kaminski, Emily; Nguyen, Khoa; Multala, Evan] Tulane Univ, Sch Med, New Orleans, LA 70112 USA; [Dumont, Aaron S.; Wang, Arthur] Tulane Univ, Sch Med, Dept Neurol Surg, New Orleans, LA 70112 USA; [Wang, Arthur] Tulane Univ, Sch Med, Neurol Surg, New Orleans, LA 70112 USA	Tulane University; Tulane University; Tulane University	Wang, AR (corresponding author), Tulane Univ, Sch Med, Neurol Surg, New Orleans, LA 70112 USA.	awang15@tulane.edu		Kaminski, Emily/0009-0002-2917-4082; Couldwell, Mitchell/0000-0002-9981-0788				Branum C, 2023, NURS EDUC, V48, P231, DOI 10.1097/NNE.0000000000001436; Bubeck S., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12712; Chen TC, 2023, WORLD NEUROSURG, V179, pE342, DOI 10.1016/j.wneu.2023.08.088; Hopkins BS, 2023, J NEUROSURG, V139, P904, DOI 10.3171/2023.2.JNS23419; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mallon DH, 2022, J STROKE CEREBROVASC, V31, DOI 10.1016/j.jstrokecerebrovasdis.2022.106702; Nogueira RG, 2018, NEW ENGL J MED, V378, P11, DOI 10.1056/NEJMoa1706442; OpenAI, 2022, Introducing chatgpt; WolframAlpha, 2023, WOLFRAM PLUGIN CHATG	9	0	0	5	5	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1759-8478	1759-8486		J NEUROINTERV SURG	J. NeuroInterventional Surg.	MAR	2024	16	3					253	260		10.1136/jnis-2023-021163	http://dx.doi.org/10.1136/jnis-2023-021163		JAN 2024	8	Neuroimaging; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Surgery	KB4V4	38184368				2024-07-03	WOS:001142621600001
J	Sallam, M				Sallam, Malik			ChatGPT Utility in Healthcare Education, Research, and Practice: Systematic Review on the Promising Perspectives and Valid Concerns	HEALTHCARE			English	Review						machine learning; digital health; artificial intelligence; healthcare; ethics	ARTIFICIAL-INTELLIGENCE; SCIENCE; MEDICINE; FUTURE	ChatGPT is an artificial intelligence (AI)-based conversational large language model (LLM). The potential applications of LLMs in health care education, research, and practice could be promising if the associated valid concerns are proactively examined and addressed. The current systematic review aimed to investigate the utility of ChatGPT in health care education, research, and practice and to highlight its potential limitations. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar (published research or preprints) that examined ChatGPT in the context of health care education, research, or practice. A total of 60 records were eligible for inclusion. Benefits of ChatGPT were cited in 51/60 (85.0%) records and included: (1) improved scientific writing and enhancing research equity and versatility; (2) utility in health care research (efficient analysis of datasets, code generation, literature reviews, saving time to focus on experimental design, and drug discovery and development); (3) benefits in health care practice (streamlining the workflow, cost saving, documentation, personalized medicine, and improved health literacy); and (4) benefits in health care education including improved personalized learning and the focus on critical thinking and problem-based learning. Concerns regarding ChatGPT use were stated in 58/60 (96.7%) records including ethical, copyright, transparency, and legal issues, the risk of bias, plagiarism, lack of originality, inaccurate content with risk of hallucination, limited knowledge, incorrect citations, cybersecurity issues, and risk of infodemics. The promising applications of ChatGPT can induce paradigm shifts in health care education, research, and practice. However, the embrace of this AI chatbot should be conducted with extreme caution considering its potential limitations. As it currently stands, ChatGPT does not qualify to be listed as an author in scientific articles unless the ICMJE/COPE guidelines are revised or amended. An initiative involving all stakeholders in health care education, research, and practice is urgently needed. This will help to set a code of ethics to guide the responsible use of ChatGPT among other LLMs in health care and academia.	[Sallam, Malik] Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Amman 11942, Jordan; [Sallam, Malik] Jordan Univ Hosp, Dept Clin Labs & Forens Med, Amman 11942, Jordan	University of Jordan; University of Jordan	Sallam, M (corresponding author), Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Amman 11942, Jordan.; Sallam, M (corresponding author), Jordan Univ Hosp, Dept Clin Labs & Forens Med, Amman 11942, Jordan.	malik.sallam@ju.edu.jo	Sallam, Malik/O-5021-2014; La Torre, Andrea/JMC-7297-2023	Sallam, Malik/0000-0002-0165-9670; La Torre, Andrea/0009-0001-1693-0785				Aczel B., 2023, PREPRINT, DOI DOI 10.31234/OSF.IO/B58EX; Ahn C, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109729; Akhter HM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34752; Alberts IL, 2023, EUR J NUCL MED MOL I, V50, P1549, DOI 10.1007/s00259-023-06172-w; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Antaki F, 2023, medRxiv, DOI [10.1101/2023.01.22.23284882, 10.1101/2023.01.22.23284882, DOI 10.1101/2023.01.22.23284882]; Aydin O, 2022, PREPRINT, DOI DOI 10.2139/SSRN.4308687; Basic Z, 2023, Arxiv, DOI [arXiv:2302.04536, 10.48550/arXiv.2302.04536, DOI 10.48550/ARXIV.2302.04536]; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cahan P, 2023, STEM CELL REP, V18, P1, DOI 10.1016/j.stemcr.2022.12.009; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chatterjee J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2022.100676; Checcucci E, 2023, MINERVA UROL NEPHROL, V75, P131, DOI 10.23736/S2724-6051.23.05326-0; Chen T.J., SCI WRITING; Cotton D., 2023, PREPRINT; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; DeAngelis L., 2023, PREPRINT, DOI DOI 10.2139/SSRN.4352931; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Domingos P., 2018, MASTER ALGORITHM QUE, V1st ed., P329; Duong D., 2023, PREPRINT, DOI DOI 10.1101/2023.01.27.23285115; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Hallsworth JE, 2023, MICROB BIOTECHNOL, V16, P1131, DOI 10.1111/1751-7915.14222; Harzing A., 2007, Publish or Perish; Hisan U., 2023, PREPRINT, DOI DOI 10.13140/RG.2.2.31280.23043/1; Holzinger A, 2023, NEW BIOTECHNOL, V74, P16, DOI 10.1016/j.nbt.2023.02.001; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Johnson KB, 2021, CTS-CLIN TRANSL SCI, V14, P86, DOI 10.1111/cts.12884; Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kim SG, 2023, MAX PLAST RECONSTR S, V45, DOI 10.1186/s40902-023-00381-x; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Korteling JE, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.622364; Kostick-Quenet KM, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00737-z; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lin Z., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/SDX3J; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Manohar N, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34616; Marchandot Benjamin, 2023, Eur Heart J Open, V3, poead007, DOI 10.1093/ehjopen/oead007; Margalida A, 2016, PEERJ, V4, DOI 10.7717/peerj.1670; Mavrogenis AF, 2020, INT ORTHOP, V44, P413, DOI 10.1007/s00264-020-04504-1; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McCarthy J, 2006, AI MAG, V27, P12; Mijwil M., 2023, Mesopotamian J Cyber Secur, P18, DOI DOI 10.58496/MJCS/2023/004; Moher D, 2015, SYST REV-LONDON, V4, DOI [10.1186/2046-4053-4-1, 10.1371/journal.pmed.1000097, 10.1136/bmj.b2535, 10.1136/bmj.b2700, 10.1016/j.ijsu.2010.02.007, 10.1136/bmj.i4086, 10.1016/j.ijsu.2010.07.299]; Moons P, ChatGPT: Can Artificial Intelligence Language Models be of Value for Cardiovascular Nurses and Allied Health Professionals, DOI [10.1093/eurjcn/zvad022/7031481, DOI 10.1093/EURJCN/ZVAD022/7031481]; Nachshon A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35649; Nisar S., 2023, PREPRINT, DOI DOI 10.2139/SSRN.4324310; Nolan Christopher, 2014, Interstellar; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; OpenAI OpenAI, MOD GPT 3; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Polonsky M., 2023, Preprints, DOI DOI 10.2139/SSRN.4349524; Quintans LJ, 2023, REV SOC BRAS MED TRO, V56, DOI 10.1590/0037-8682-0060-2023; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sallam M., 2023, NARRA J, V3, DOI [10.52225/narra.v3i1.e103, DOI 10.52225/NARRA.V3I1.E103]; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Sanmarchi F, 2023, medRxiv, DOI [10.1101/2023.02.06.23285514, 10.1101/2023.02.06.23285514, DOI 10.1101/2023.02.06.23285514]; Sarker Iqbal H, 2022, SN Comput Sci, V3, P158, DOI 10.1007/s42979-022-01043-x; Shahriar S, 2023, Arxiv, DOI [arXiv:2302.13817, 10.47852/bonviewAIA3202939, DOI 10.47852/BONVIEWAIA3202939]; Sharma G, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-qgs3k, 10.26434/chemrxiv-2023-qgs3k, DOI 10.26434/CHEMRXIV-2023-QGS3K]; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Smith R, 2006, J ROY SOC MED, V99, P178, DOI 10.1258/jrsm.99.4.178; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Tai MCT, 2020, TZU CHI MED J, V32, P339, DOI 10.4103/tcmj.tcmj_71_20; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tobore TO, 2019, PSYCHOL REP, V122, P2406, DOI 10.1177/0033294118792670; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Wogu I.A.P., 2017, 2017 INT C COMPUTING, P1, DOI DOI 10.1109/ICCNI.2017.8123792; Yeo YH, 2023, medRxiv, DOI [10.1101/2023.02.06.23285449, 10.1101/2023.02.06.23285449, DOI 10.1101/2023.02.06.23285449]; Zielinski Chris, 2023, Open Access Macedonian Journal of Medical Sciences, V11, P83, DOI 10.3889/oamjms.2023.11502	96	500	507	511	1170	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9032		HEALTHCARE-BASEL	Healthcare	MAR	2023	11	6							887	10.3390/healthcare11060887	http://dx.doi.org/10.3390/healthcare11060887			20	Health Care Sciences & Services; Health Policy & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services	A7AM3	36981544	gold, Green Submitted, Green Published			2024-07-03	WOS:000956609200001
C	Dipongkor, AK; Moran, K			IEEE	Dipongkor, Atish Kumar; Moran, Kevin			A Comparative Study of Transformer-based Neural Text Representation Techniques on Bug Triaging	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Bug Triaging; Transformer; LLMs; Text-Embedding; DL4SE	ACCURATE	Bug report management has been shown to be an important and time consuming software maintenance task. Often, the first step in managing bug reports is related to triaging a bug to the appropriate developer who is best suited to understand, localize, and fix the target bug. Additionally, assigning a given bug to a particular part of a software project can help to expedite the fixing process. However, despite the importance of these activities, they are quite challenging, where days can be spent on the manual triaging process. Past studies have attempted to leverage the limited textual data of bug reports to train text classification models that automate this process - to varying degrees of success. However, the textual representations and machine learning models used in prior work are limited by their expressiveness, often failing to capture nuanced textual patterns that might otherwise aid in the triaging process. Recently, large, transformer-based, pre-tained neural text representation techniques (i.e., large language models or LLMs) such as BERT and CodeBERT have achieved greater performance with simplified training procedures in several natural language processing tasks, including text classification. However, the potential for using these techniques to improve upon prior approaches for automated bug triaging is not well studied or understood. Therefore, in this paper we offer one of the first investigations that fine-tunes transformer-based language models for the task of bug triaging on four open source datasets, spanning a collective 53 years of development history with over 400 developers and over 150 software project components. Our study includes both a quantitative and qualitative analysis of effectiveness. Our findings illustrate that DeBERTa is the most effective technique across the triaging tasks of developer and component assignment, and the measured performance delta is statistically significant compared to other techniques. However, through our qualitative analysis, we also observe that each technique possesses unique abilities best suited to certain types of bug reports.	[Dipongkor, Atish Kumar; Moran, Kevin] Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA	State University System of Florida; University of Central Florida	Dipongkor, AK (corresponding author), Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.	akd@knights.ucf.edu; kpmoran@ucf.edu						Ahsan SN, 2009, 2009 FOURTH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING ADVANCES (ICSEA 2009), P216, DOI 10.1109/ICSEA.2009.92; [Anonymous], 2023, Neural bug triaging online appendix; [Anonymous], 2005, Measuring computer performance: a practitioner's guide; Anvik J., 2006, 28th International Conference on Software Engineering Proceedings, P937, DOI 10.1145/1134285.1134457; Anvik J., 2006, P 28 INT C SOFTW ENG, P361, DOI DOI 10.1145/1134285.1134336; Anvik J, 2011, ACM T SOFTW ENG METH, V20, DOI 10.1145/2000791.2000794; Bhattacharya P, 2010, PROC IEEE INT CONF S; Bhattacharya P, 2012, J SYST SOFTWARE, V85, P2275, DOI 10.1016/j.jss.2012.04.053; Bucila C., 2006, P KDD, P535, DOI 10.1145/1150402.1150464; Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334; Crowston K., 2006, Software Process Improvement and Practice, V11, P123, DOI 10.1002/spip.259; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Florea AC, 2017, LECT NOTES ARTIF INT, V10246, P31, DOI 10.1007/978-3-319-59060-8_4; Fu W, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P49, DOI 10.1145/3106237.3106256; Guo SK, 2020, NEURAL PROCESS LETT, V51, P2589, DOI 10.1007/s11063-020-10213-y; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; huggingface.co, Transformers; Jeong G, 2009, 7TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P111, DOI 10.1145/1595696.1595715; Kim S, 2006, Proceedings of the 2006 international workshop on Mining software repositories, P173; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lee J, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556898; Lee SR, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P926, DOI 10.1145/3106237.3117776; Lin ZP, 2009, INT SYMP EMP SOFTWAR, P452; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mani S, 2019, PROCEEDINGS OF THE 6TH ACM IKDD CODS AND 24TH COMAD, P171, DOI 10.1145/3297001.3297023; McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]; Mendenhall W., 2013, INTRO PROBABILITY ST; Mikolov T, 2013, COMPUTING RES REPOSI; Murphy G., 2004, P 16 INT C SOFTW ENG, P1; Nasim S., 2011, Proceedings of the 2011 Frontiers of Information Technology (FIT 2011), P298, DOI 10.1109/FIT.2011.62; Nath V, 2021, 20TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2021), P541, DOI 10.1109/ICMLA52953.2021.00090; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; pytorch.org, TyTorch; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sarkar A, 2019, PROC IEEE INT CONF S, P81, DOI 10.1109/ICSME.2019.00018; scikit-learn.org, SCIKIT LEARN MACHINE; Tung Thanh Nguyen, 2014, ACM SIGSOFT Software Engineering Notes, V39, DOI 10.1145/2557833.2560585; Vaswani A, 2017, ADV NEUR IN, V30; Wu HR, 2018, IET SOFTW, V12, P258, DOI 10.1049/iet-sen.2017.0159; Xia X, 2013, WORK CONF REVERSE EN, P72, DOI 10.1109/WCRE.2013.6671282; Xuan JF, 2017, Arxiv, DOI arXiv:1704.04769; Xuan JF, 2012, PROC INT CONF SOFTW, P25, DOI 10.1109/ICSE.2012.6227209; Yang G, 2014, P INT COMP SOFTW APP, P97, DOI 10.1109/COMPSAC.2014.16; Zaidi SFA, 2020, IEEE ACCESS, V8, P213729, DOI 10.1109/ACCESS.2020.3040065; Zhang T, 2016, COMPUT J, V59, P741, DOI 10.1093/comjnl/bxv114; Zhang W, 2020, PROC IEEE INT CONF S, P727, DOI 10.1109/ICSME46990.2020.00082	48	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1012	1023		10.1109/ASE56229.2023.00217	http://dx.doi.org/10.1109/ASE56229.2023.00217			12	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200081
J	Huang, RST; Lu, KJQ; Meaney, C; Kemppainen, J; Punnett, A; Leung, FH				Huang, Ryan S. T.; Lu, Kevin Jia Qi; Meaney, Christopher; Kemppainen, Joel; Punnett, Angela; Leung, Fok-Han			Assessment of Resident and AI Chatbot Performance on the University of Toronto Family Medicine Residency Progress Test: Comparative Study	JMIR MEDICAL EDUCATION			English	Article						medical education; medical knowledge exam; artificial intelligence; AI; natural language processing; NLP; large language model; LLM; machine learning, ChatGPT; GPT-3.5; GPT-4; education; language model; education examination; testing; utility; family medicine; medical residents; test; community		Background: Large language model (LLM)-based chatbots are evolving at an unprecedented pace with the release of ChatGPT, specifically GPT-3.5, and its successor, GPT-4. Their capabilities in general-purpose tasks and language generation have advanced to the point of performing excellently on various educational examination benchmarks, including medical knowledge tests. Comparing the performance of these 2 LLM models to that of Family Medicine residents on a multiple-choice medical knowledge test can provide insights into their potential as medical education tools. Objective: This study aimed to quantitatively and qualitatively compare the performance of GPT-3.5, GPT-4, and Family Medicine residents in a multiple-choice medical knowledge test appropriate for the level of a Family Medicine resident. Methods: An official University of Toronto Department of Family and Community Medicine Progress Test consisting of multiple-choice questions was inputted into GPT-3.5 and GPT-4. The artificial intelligence chatbot's responses were manually reviewed to determine the selected answer, response length, response time, provision of a rationale for the outputted response, and the root cause of all incorrect responses (classified into arithmetic, logical, and information errors). The performance of the artificial intelligence chatbots were compared against a cohort of Family Medicine residents who concurrently attempted the test. Results: GPT-4 performed significantly better compared to GPT-3.5 (difference 25.0%, 95% CI 16.3%-32.8%; McNemar test: P<.001); it correctly answered 89/108 (82.4%) questions, while GPT-3.5 answered 62/108 (57.4%) questions correctly. Further, GPT-4 scored higher across all 11 categories of Family Medicine knowledge. In 86.1% (n=93) of the responses, GPT-4 provided a rationale for why other multiple-choice options were not chosen compared to the 16.7% (n=18) achieved by GPT-3.5. Qualitatively, for both GPT-3.5 and GPT-4 responses, logical errors were the most common, while arithmetic errors were the least common. The average performance of Family Medicine residents was 56.9% (95% CI 56.2%-57.6%). The performance of GPT-3.5 was similar to that of the average Family Medicine resident (P=.16), while the performance of GPT-4 exceeded that of the top-performing Family Medicine resident (P<.001). Conclusions: GPT-4 significantly outperforms both GPT-3.5 and Family Medicine residents on a multiple-choice medical knowledge test designed for Family Medicine residents. GPT-4 provides a logical rationale for its response choice, ruling out other answer choices efficiently and with concise justification. Its high degree of accuracy and advanced reasoning capabilities facilitate its potential applications in medical education, including the creation of exam questions and scenarios as well as serving as a resource for medical knowledge or information on community services.	[Huang, Ryan S. T.; Punnett, Angela] Univ Toronto, Temerty Fac Med, 1 Kings Coll Cir, Toronto, ON M5S 1A8, Canada; [Lu, Kevin Jia Qi; Meaney, Christopher; Kemppainen, Joel; Leung, Fok-Han] Univ Toronto, Dept Family & Community Med, Toronto, ON, Canada; [Punnett, Angela] Hosp Sick Children, Div Haematol, Toronto, ON, Canada	University of Toronto; University of Toronto; University of Toronto; Hospital for Sick Children (SickKids)	Huang, RST (corresponding author), Univ Toronto, Temerty Fac Med, 1 Kings Coll Cir, Toronto, ON M5S 1A8, Canada.	ry.huang@mail.utoronto.ca	Huang, Ryan/KHD-7917-2024; Meaney, Christopher/R-8349-2018	Huang, Ryan S./0000-0002-3404-5376; Meaney, Christopher/0000-0002-5429-5233; Kemppainen, Joel/0009-0001-5566-124X; Lu, Kevin Jia Qi/0000-0003-3296-9193				Agresti A, 2005, STAT MED, V24, P729, DOI 10.1002/sim.1781; Al-Rukban MO, 2006, J FAM COMMUNITY MED, V13, P125; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Barry PP, 2000, AM J GASTROENTEROL, V95, P8; Bongini P., 2023, Computer vision-ECCV 2022 workshops, P268; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; GPT-4, OpenAI; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kalla D, 2023, SSRN, V8, P827; Karthikeyan C., 2023, Int J Sci Res, V12, P283, DOI DOI 10.21275/SR23219122412; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kreptul D, 2016, EDUC PRIM CARE, V27, P471, DOI 10.1080/14739879.2016.1205835; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Leung FH, 2016, CFP, V62, P263; Phillips WR, 2022, CAN FAM PHYSICIAN, V68, P801, DOI 10.46747/cfp.6811801; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Shakarian P, 2023, arXiv; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	20	6	6	20	24	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e50514	10.2196/50514	http://dx.doi.org/10.2196/50514			9	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	U6AS5	37725411	Green Published, gold			2024-07-03	WOS:001085615600001
J	Mitchell, M; Krakauer, DC				Mitchell, Melanie; Krakauer, David C.			The debate over understanding in AI?s large language models	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						artificial intelligence; understanding; large language models		We survey a current, heated debate in the artificial intelligence (AI) research community on whether large pretrained language models can be said to understand language-and the physical and social situations language encodes-in any humanlike sense. We describe argu-ments that have been made for and against such under-standing and key questions for the broader sciences of intelligence that have arisen in light of these arguments. We contend that an extended science of intelligence can be developed that will provide insight into distinct modes of understanding, their strengths and limitations, and the challenge of integrating diverse forms of cognition.	[Mitchell, Melanie; Krakauer, David C.] Santa Fe Inst, Santa Fe, NM 87501 USA	The Santa Fe Institute	Mitchell, M (corresponding author), Santa Fe Inst, Santa Fe, NM 87501 USA.	mm@santafe.edu		Krakauer, David/0000-0002-0827-6525	Templeton World Charity Foundation; National Science Foundation [2020103]	Templeton World Charity Foundation(Templeton World Charity Foundation); National Science Foundation(National Science Foundation (NSF))	ACKNOWLEDGMENTS. This material is based in part upon work supported by the Templeton World Charity Foundation and by the National Science Foundation under grant no. 2020103. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author and do not necessarily reflect the views of the NSF.	Binz M, 2022, Arxiv, DOI arXiv:2206.14576; Jones DT, 2022, NAT METHODS, V19, P15, DOI 10.1038/s41592-021-01365-3; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Laverghetta A., 2022, The Annual Meeting of the Psychometric Society, P151; Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813; Olsson C., 2022, arXiv; Sadler M., 2019, Game Changer: AlphaZero's Groundbreaking Chess Strategies and the Promise of AI; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Silver D, 2017, Arxiv, DOI arXiv:1712.01815; Trott S, 2022, Arxiv, DOI [arXiv:2209.01515, DOI 10.48550/ARXIV.2209.01515]	11	43	45	80	143	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	MAR 28	2023	120	13							e2215907120	10.1073/pnas.2215907120	http://dx.doi.org/10.1073/pnas.2215907120			5	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	I2UD5	36943882	Green Published, Green Submitted, hybrid			2024-07-03	WOS:001001376000013
J	Borger, JG; Ng, AP; Anderton, H; Ashdown, GW; Auld, M; Blewitt, ME; Brown, D; Call, MJ; Collins, P; Freytag, S; Harrison, LC; Hesping, E; Hoysted, J; Johnston, A; Mcinneny, A; Tang, P; Whitehead, L; Jex, A; Naik, SH				Borger, Jessica G.; Ng, Ashley P.; Anderton, Holly; Ashdown, George W.; Auld, Megan; Blewitt, Marnie E.; Brown, Daniel, V; Call, Melissa J.; Collins, Peter; Freytag, Saskia; Harrison, Leonard C.; Hesping, Eva; Hoysted, Jaci; Johnston, Anna; Mcinneny, Andrew; Tang, Phil; Whitehead, Lachlan; Jex, Aaron; Naik, Shalin H.			Artificial intelligence takes center stage: exploring the capabilities and implications of ChatGPT and other AI-assisted technologies in scientific research and education	IMMUNOLOGY AND CELL BIOLOGY			English	Article						AI; ChatGPT; education; ethics; LLM; research; science		The emergence of large language models (LLMs) and assisted artificial intelligence (AI) technologies such as ChatGPT and Bard have revolutionized the way in which we interact with technology. These publicly available LLMs can generate cogent, human-like and human-level responses and have a diverse range of potential applications across diverse knowledge areas, including scientific research and education. However, with such advancements comes a new set of ethical, legal and social implications. Medical research and education are no exceptions, and our organizations must contend with new models of governance and responsibility. A recent Chat-GPT symposium at the Walter and Eliza Hall Medical Research Institute (WEHI)1 explored the current practical applications of LLMs in medical research and canvassed the emerging ethical, legal and social implications for the use of AI-assisted technologies in the sciences. The symposium was led by early career researchers, lab heads, educators and policymakers, representing the diverse academic landscape within medical research institutes who engage with ChatGPT in their work, who as experts in their fields are learning to navigate the appropriate, efficient and ethical application of AI and LLMs. Together, the speakers sought to provoke discussions within the 500+ in-person and online audience on the use of AI-assisted technologies in scientific research, including its use as an overtly friendly editor of scientific papers and grants, its ability to turn non-coders into bioinformaticians, and its ability to analyze big data at warp speed. In addition to the emergence of AI-driven tools such as Alphafold and protein hallucination, the symposium addressed broader societal implications of using AI-assisted technologies in science, including concerns around the ethics, privacy, confidentiality and security of research data and writing that is entered into the AI-assisted technologies ether. This paper provides an overview of the WEHI ChatGPT symposium's key themes and discussions, highlighting the opportunities and challenges that lie ahead for scientific researchers and educators as we continue to explore the potential of this cutting-edge and emerging technology.	[Borger, Jessica G.; Ng, Ashley P.; Anderton, Holly; Ashdown, George W.; Auld, Megan; Blewitt, Marnie E.; Brown, Daniel, V; Call, Melissa J.; Collins, Peter; Freytag, Saskia; Harrison, Leonard C.; Hesping, Eva; Hoysted, Jaci; Johnston, Anna; Mcinneny, Andrew; Tang, Phil; Whitehead, Lachlan; Jex, Aaron; Naik, Shalin H.] WEHI Walter & Eliza Hall Inst Med Res, Parkville, Vic 3052, Australia; [Borger, Jessica G.; Ng, Ashley P.; Anderton, Holly; Ashdown, George W.; Auld, Megan; Blewitt, Marnie E.; Brown, Daniel, V; Call, Melissa J.; Collins, Peter; Freytag, Saskia; Harrison, Leonard C.; Hesping, Eva; Hoysted, Jaci; Johnston, Anna; Mcinneny, Andrew; Tang, Phil; Whitehead, Lachlan; Jex, Aaron; Naik, Shalin H.] Univ Melbourne, Dept Med Biol, Parkville, Vic, Australia	University of Melbourne	Borger, JG; Naik, SH (corresponding author), WEHI Walter & Eliza Hall Inst Med Res, Parkville, Vic 3052, Australia.	borger.j@wehi.edu.au; naik.s@wehi.edu.au	Jex, Aaron Richard/AGZ-7897-2022; Ng, Ashley/D-3842-2011	Jex, Aaron Richard/0000-0002-1285-7947; Brown, Daniel/0000-0002-3594-5851; Hesping, Eva/0000-0002-9012-5725; Freytag, Saskia/0000-0002-2185-7068; Ng, Ashley/0000-0001-9690-0879				[Anonymous], ?About us"; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Brown S., 2023, WHY NEURAL NET PIONE; Federspiel F, 2023, BMJ GLOB HEALTH, V8, DOI 10.1136/bmjgh-2022-010435; Köbis N, 2021, NAT HUM BEHAV, V5, P679, DOI 10.1038/s41562-021-01128-2; Piccolo SR., 2023, MANY BIOINFORMATICS, DOI DOI 10.48550/ARXIV.2303.13528; Ray S., 2023, Forbes; Sabin S., 2023, AXIOS; Savage M., 2023, BBC NEWS; Shue Evelyn, 2023, bioRxiv, DOI 10.1101/2023.03.07.531414; Vincent J., 2019, OPENAI HAS PUBLISHED; Xu YJ., 2021, INNOVATION, V2; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0	13	4	4	77	159	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0818-9641	1440-1711		IMMUNOL CELL BIOL	Immunol. Cell Biol.	NOV	2023	101	10			SI		923	935		10.1111/imcb.12689	http://dx.doi.org/10.1111/imcb.12689		SEP 2023	13	Cell Biology; Immunology	Science Citation Index Expanded (SCI-EXPANDED)	Cell Biology; Immunology	HC1E4	37721869	Bronze			2024-07-03	WOS:001070000400001
J	Martinengo, L; Lin, XW; Jabir, AI; Kowatsch, T; Atun, R; Car, J; Car, LT				Martinengo, Laura; Lin, Xiaowen; Jabir, Ahmad Ishqi; Kowatsch, Tobias; Atun, Rifat; Car, Josip; Car, Lorainne Tudor			Conversational Agents in Health Care: Expert Interviews to Inform the Definition, Classification, and Conceptual Framework	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						conceptual framework; conversational agent; chatbot; mobile health; mHealth; digital health; expert interview; mobile phone	TECHNOLOGY; INTERVENTIONS	Background: Conversational agents (CAs), or chatbots, are computer programs that simulate conversations with humans. The use of CAs in health care settings is recent and rapidly increasing, which often translates to poor reporting of the CA development and evaluation processes and unreliable research findings. We developed and published a conceptual framework, designing, developing, evaluating, and implementing a smartphone-delivered, rule-based conversational agent (DISCOVER), consisting of 3 iterative stages of CA design, development, and evaluation and implementation, complemented by 2 cross-cutting themes (user-centered design and data privacy and security). Objective: This study aims to perform in-depth, semistructured interviews with multidisciplinary experts in health care CAs to share their views on the definition and classification of health care CAs and evaluate and validate the DISCOVER conceptual framework. Methods: We conducted one-on-one semistructured interviews via Zoom (Zoom Video Communications) with 12 multidisciplinary CA experts using an interview guide based on our framework. The interviews were audio recorded, transcribed by the research team, and analyzed using thematic analysis. Results: Following participants' input, we defined CAs as digital interfaces that use natural language to engage in a synchronous dialogue using >= 1 communication modality, such as text, voice, images, or video. CAs were classified by 13 categories: response generation method, input and output modalities, CA purpose, deployment platform, CA development modality, appearance, length of interaction, type of CA-user interaction, dialogue initiation, communication style, CA personality, human support, and type of health care intervention. Experts considered that the conceptual framework could be adapted for artificial intelligence-based CAs. However, despite recent advances in artificial intelligence, including large language models, the technology is not able to ensure safety and reliability in health care settings. Finally, aligned with participants' feedback, we present an updated iteration of the conceptual framework for health care conversational agents (CHAT) with key considerations for CA design, development, and evaluation and implementation, complemented by 3 cross-cutting themes: ethics, user involvement, and data privacy and security. Conclusions: We present an expanded, validated CHAT and aim at guiding researchers from a variety of backgrounds and with different levels of expertise in the design, development, and evaluation and implementation of rule-based CAs in health care settings.	[Martinengo, Laura; Lin, Xiaowen; Jabir, Ahmad Ishqi; Car, Lorainne Tudor] Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, 11 Mandalay Rd,Level 18, Singapore 308232, Singapore; [Jabir, Ahmad Ishqi; Kowatsch, Tobias] Singapore ETH Ctr, Future Hlth Technol Programme, Campus Res Excellence & Technol Enterprise, Singapore, Singapore; [Kowatsch, Tobias] Univ Zurich, Inst Implementat Sci Hlth Care, Zurich, Switzerland; [Kowatsch, Tobias] Univ St Gallen, Sch Med, St Gallen, Switzerland; [Kowatsch, Tobias] Swiss Fed Inst Technol, Ctr Digital Hlth Intervent, Dept Management Technol & Econ, Zurich, Switzerland; [Atun, Rifat] Harvard Univ, TH Chan Sch Publ Hlth, Dept Global Hlth & Populat, Cambridge, MA USA; [Car, Josip] Nanyang Technol Univ, Ctr Populat Hlth Sci, Lee Kong Chian Sch Med, Singapore, Singapore; [Car, Josip; Car, Lorainne Tudor] Imperial Coll London, Sch Publ Hlth, Dept Primary Care & Publ Hlth, London, England	Nanyang Technological University; University of Zurich; University of St Gallen; Swiss Federal Institutes of Technology Domain; ETH Zurich; Harvard University; Harvard T.H. Chan School of Public Health; Nanyang Technological University; Imperial College London	Martinengo, L (corresponding author), Nanyang Technol Univ Singapore, Lee Kong Chian Sch Med, 11 Mandalay Rd,Level 18, Singapore 308232, Singapore.	lorainne.tudor.car@ntu.edu.sg	Martinengo, Laura/AAY-8201-2020; Car, Josip/H-6755-2015	Martinengo, Laura/0000-0003-3539-7207; Car, Josip/0000-0001-8969-371X; Atun, Rifat/0000-0002-1531-5983; Tudor Car, Lorainne/0000-0001-8414-7664; Lin, Xiaowen/0000-0001-7497-026X	Singapore Ministry of Education; National Research Foundation, Prime Minister's Office, Singapore	Singapore Ministry of Education(Ministry of Education, Singapore); National Research Foundation, Prime Minister's Office, Singapore(National Research Foundation, Singapore)	This research was supported by the Singapore Ministry of Education under the Singapore Ministry of Education Academic Research Fund Tier 1. This research was conducted as part of the Future Health Technologies program, which was established collaboratively between ETH Zurich and the National Research Foundation, Singapore. This research was supported by the National Research Foundation, Prime Minister's Office, Singapore, under its Campus for Research Excellence and Technological Enterprise program.	Abdellatif A, 2022, IEEE T SOFTWARE ENG, V48, P3087, DOI 10.1109/TSE.2021.3078384; Agarwal R., 2020, SN Comput. Sci, V1, P246, DOI [10.1007/s42979-020-00255-3, DOI 10.1007/S42979-020-00255-3]; [Anonymous], Microsoft Word automated transcription service; [Anonymous], CHATGPT OPT LANG MOD; Baker A, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.543405; Bendig E., 2019, Verhaltenstherapie, DOI [DOI 10.1159/000501812, https://doi.org/10.1159/000501812]; Bickmore T, 2010, APPL ARTIF INTELL, V24, P648, DOI 10.1080/08839514.2010.492259; Borsci Simone, 2022, Personal and Ubiquitous Computing, V26, P95, DOI 10.1007/s00779-021-01582-9; Brall C, 2019, EUR J PUBLIC HEALTH, V29, P18, DOI 10.1093/eurpub/ckz167; Brooke JSUS., 1996, Usability Eval. Ind., V189194, P4, DOI DOI 10.1201/9781498710411-35; Burnard P, 1991, Nurse Educ Today, V11, P461, DOI 10.1016/0260-6917(91)90009-Y; Car LT, 2020, J MED INTERNET RES, V22, DOI 10.2196/17158; Collins LM, 2005, ANN BEHAV MED, V30, P65, DOI 10.1207/s15324796abm3001_8; Darcy A., 2023, WHY GENERATIVE AI IS; Denecke Kerstin, 2023, Procedia Computer Science, P1289, DOI 10.1016/j.procs.2023.01.413; Dhinagaran DA, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/38740; Dhinagaran DA, 2021, JMIR FORM RES, V5, DOI 10.2196/27956; Dhinagaran DA, 2021, JMIR FORM RES, V5, DOI 10.2196/30435; Dowling M, 2013, J TECHNOL HUMAN SERV, V31, P1, DOI 10.1080/15228835.2012.728508; Echeazarra L, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01730-x; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Gaffney H, 2014, BEHAV COGN PSYCHOTH, V42, P731, DOI 10.1017/S135246581300060X; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Gong EY, 2020, J MED INTERNET RES, V22, DOI 10.2196/20322; Jabareen Y.R., 2009, International Journal of Qualitative Methods, V8, P49, DOI [10.1177/160940690900800406, DOI 10.1177/160940690900800406]; Jabir AI, 2023, J MED INTERNET RES, V25, DOI 10.2196/44548; Jack BW, 2020, LANCET DIGIT HEALTH, V2, pE475, DOI 10.1016/S2589-7500(20)30189-8; Jumelle AK, 2015, Requirements Engineering for Digital Health, P75; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Lebeuf C, 2018, A taxonomy of software bots: towards a deeper understanding of software bot characteristics; Lebeuf C, 2018, IEEE SOFTWARE, V35, P18, DOI 10.1109/MS.2017.4541027; Lim SM, 2022, BEHAV THER, V53, P334, DOI 10.1016/j.beth.2021.09.007; Luxton DD, 2020, B WORLD HEALTH ORGAN, V98, P285, DOI 10.2471/BLT.19.237636; Radziwill NM, 2017, Arxiv, DOI [arXiv:1704.04579, DOI 10.48550/ARXIV.1704.04579]; Martin P, 2020, J MED INTERNET RES, V22, DOI 10.2196/18650; Mauco KL, 2019, JMIR MED INF, V7, DOI 10.2196/12949; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McGreevey JD, 2020, JAMA-J AM MED ASSOC, V324, P552, DOI 10.1001/jama.2020.2724; McTear M., 2016, The conversational interface, DOI 10.1007/978-3-319-32967-3; McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285; Middleton K, 2016, Arxiv, DOI arXiv:1606.02041; Morse KE, 2020, J MED INTERNET RES, V22, DOI 10.2196/20549; Mummah SA, 2016, J MED INTERNET RES, V18, DOI 10.2196/jmir.5927; Palanica A, 2019, J MED INTERNET RES, V21, DOI 10.2196/12887; Pfadenhauer M, 2009, RES METHODS SER, P81; Provoost S, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.6553; qsrinternational, NVivo 12. Lumivero; Rabinowitz AR, 2022, J HEAD TRAUMA REHAB, V37, P144, DOI 10.1097/HTR.0000000000000770; Ruane E., 2019, AICS, P104; Sezgin E, 2020, TRANSL BEHAV MED, V10, P606, DOI 10.1093/tbm/ibz141; Suhaili SM, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115461; Transcription software, Lee Kong Chian School of Medicine Digital Learning; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Vasileiou K, 2018, BMC MED RES METHODOL, V18, DOI 10.1186/s12874-018-0594-7; zoom, Zoom. Zoom Video Communications	56	0	0	6	7	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	NOV 1	2023	25								e50767	10.2196/50767	http://dx.doi.org/10.2196/50767			15	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	Y7JN3	37910153	Green Published, gold			2024-07-03	WOS:001106987900003
J	Veras, M; Dyer, JO; Rooney, M; Silva, PGB; Rutherford, D; Kairy, D				Veras, Mirella; Dyer, Joseph-Omer; Rooney, Morgan; Silva, Paulo Goberlanio Barros; Rutherford, Derek; Kairy, Dahlia			Usability and Efficacy of Artificial Intelligence Chatbots (ChatGPT) for Health Sciences Students: Protocol for a Crossover Randomized Controlled Trial	JMIR RESEARCH PROTOCOLS			English	Article						artificial intelligence; AI; health sciences; usability; learning outcomes; perceptions; OpenAI; ChatGPT; education; randomized controlled trial; RCT; crossover RCT		Background: The integration of artificial intelligence (AI) into health sciences students' education holds significant importance. The rapid advancement of AI has opened new horizons in scientific writing and has the potential to reshape human-technology interactions. AI in education may impact critical thinking, leading to unintended consequences that need to be addressed. Understanding the implications of AI adoption in education is essential for ensuring its responsible and effective use, empowering health sciences students to navigate AI-driven technologies' evolving field with essential knowledge and skills.Objective: This study aims to provide details on the study protocol and the methods used to investigate the usability and efficacy of ChatGPT, a large language model. The primary focus is on assessing its role as a supplementary learning tool for improving learning processes and outcomes among undergraduate health sciences students, with a specific emphasis on chronic diseases.Methods: This single-blinded, crossover, randomized, controlled trial is part of a broader mixed methods study, and the primary emphasis of this paper is on the quantitative component of the overall research. A total of 50 students will be recruited for this study. The alternative hypothesis posits that there will be a significant difference in learning outcomes and technology usability between students using ChatGPT (group A) and those using standard web-based tools (group B) to access resources and complete assignments. Participants will be allocated to sequence AB or BA in a 1:1 ratio using computer-generated randomization. Both arms include students' participation in a writing assignment intervention, with a washout period of 21 days between interventions. The primary outcome is the measure of the technology usability and effectiveness of ChatGPT, whereas the secondary outcome is the measure of students' perceptions and experiences with ChatGPT as a learning tool. Outcome data will be collected up to 24 hours after the interventions.Results: This study aims to understand the potential benefits and challenges of incorporating AI as an educational tool, particularly in the context of student learning. The findings are expected to identify critical areas that need attention and help educators develop a deeper understanding of AI's impact on the educational field. By exploring the differences in the usability and efficacy between ChatGPT and conventional web-based tools, this study seeks to inform educators and students on the responsible integration of AI into academic settings, with a specific focus on health sciences education.Conclusions: By exploring the usability and efficacy of ChatGPT compared with conventional web-based tools, this study seeks to inform educators and students about the responsible integration of AI into academic settings.	[Veras, Mirella] Carleton Univ, Hlth Sci, 1125 Colonel By Dr, Ottawa, ON K1S 5B6, Canada; [Veras, Mirella; Kairy, Dahlia] Ctr Interdisciplinary Res Rehabil Greater Montreal, Montreal, PQ, Canada; [Dyer, Joseph-Omer; Kairy, Dahlia] Univ Montreal, Ecole Readaptat, Fac Med, Montreal, PQ, Canada; [Dyer, Joseph-Omer] Univ Montreal, Fac Med, Grp Interdisciplinaire Rech Cognit & Raisonnement, Montreal, PQ, Canada; [Rooney, Morgan] Carleton Univ, Teaching & Learning Serv, Ottawa, ON, Canada; [Silva, Paulo Goberlanio Barros] Ctr Univ Christus, Fortaleza, CE, Brazil; [Rutherford, Derek] Dalhousie Univ, Sch Physiotherapy, Halifax, NS, Canada; [Kairy, Dahlia] Inst Univ Readaptat Deficience Phys Montreal, Ctr Integre Univ Sante & Serv Sociaux, Ctr Sud Ile de Montreal, Montreal, PQ, Canada	Carleton University; Universite de Montreal; Universite de Montreal; Carleton University; Dalhousie University	Veras, M (corresponding author), Carleton Univ, Hlth Sci, 1125 Colonel By Dr, Ottawa, ON K1S 5B6, Canada.	mirella.veras@carleton.ca	; Rooney, Morgan/N-3358-2014; Barros Silva, Paulo Goberlanio/H-7300-2015	Dyer, Joseph-Omer/0000-0002-7570-9941; Rutherford, Derek/0000-0003-2688-6201; Rooney, Morgan/0000-0001-5261-5929; Veras, Mirella/0000-0002-4124-1543; Barros Silva, Paulo Goberlanio/0000-0002-1513-9027	Scholarship of Teaching and Learning Grant from Carleton University	Scholarship of Teaching and Learning Grant from Carleton University	Acknowledgments This project was funded by the Scholarship of Teaching and Learning Grant from Carleton University.	Nguyen A, 2023, EDUC INF TECHNOL, V28, P4221, DOI 10.1007/s10639-022-11316-w; Begg C, 1996, JAMA-J AM MED ASSOC, V276, P637, DOI 10.1001/jama.276.8.637; Brendel AB, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13041974; Brooke J, 1995, Usability Evaluation in Industry; Civaner MM, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03852-3; Dalhousie U, Citation style guide; Dean A., 2013, Open Source Epidemiologic Statistics for Public Health; Dwan K, 2019, BMJ-BRIT MED J, V366, DOI 10.1136/bmj.l4378; Ensink CJ, 2024, DISABIL REHABIL, V46, P395, DOI 10.1080/09638288.2022.2160837; Garg T, 2020, AM J MED, V133, pE68, DOI 10.1016/j.amjmed.2019.08.017; Gronier G, 2021, INT J HUM-COMPUT INT, V37, P1571, DOI 10.1080/10447318.2021.1898828; Hosseini M, 2023, medRxiv, DOI [10.1101/2023.03.31.23287979, 10.1101/2023.03.31.23287979, DOI 10.1101/2023.03.31.23287979]; Hosseiniravandi M, 2020, INT J TECHNOL ASSESS, V36, P113, DOI 10.1017/S0266462320000021; Huang JS, 2023, AM J CANCER RES, V13, P1148; Huenerfauth M, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS'17), P175, DOI 10.1145/3132525.3132540; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100115; Kong SC, 2023, EDUC TECHNOL SOC, V26, P16, DOI 10.30191/ETS.202301_26(1).0002; Larbi D, 2022, J PERS MED, V12, DOI 10.3390/jpm12050828; Lim CY, 2021, KOREAN J ANESTHESIOL, V74, P293, DOI 10.4097/kja.21165; Liu XX, 2020, BMJ-BRIT MED J, V370, DOI 10.1136/bmj.m3164; Luna A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-97343-y; McMaster U, Sample McMaster syllabus statement; Mir Mohammad Muzaffar, 2023, J Adv Med Educ Prof, V11, P133, DOI 10.30476/JAMP.2023.98655.1803; Moldt JA, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2182659; Nair B, 2019, INDIAN DERMATOL ONL, V10, P193, DOI 10.4103/idoj.IDOJ_475_18; Nielsen J., 2012, Usability 101: Introduction to Usability [Versao electronica]. Disponivel em; OpenAI, ABOUT US; Pal D, 2020, CHILD YOUTH SERV REV, V119, DOI 10.1016/j.childyouth.2020.105535; Pucchio A, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03896-5; Rainey C, 2021, FRONT DIGIT HEALTH, V3, DOI 10.3389/fdgth.2021.739327; Sallam M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48254; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shaikh S, 2023, EUR J INVEST HEALTH, V13, P1937, DOI 10.3390/ejihpe13090140; YI Y, 2022, Preliminary communication Prethodno priopcenje, V12, P353; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712; Zhou LM, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/11500	36	2	2	33	38	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1929-0748			JMIR RES PROTOC	JMIR RES. Protoc.		2023	12								e51873	10.2196/51873	http://dx.doi.org/10.2196/51873			11	Health Care Sciences & Services; Public, Environmental & Occupational Health	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	Z8WZ7	37999958	gold			2024-07-03	WOS:001114836400005
C	Gönç, K; Saglam, B; Dalmaz, O; Çukur, T; Kozat, SS; Dibeklioglu, H			ACM	Gonc, Kaan; Saglam, Baturay; Dalmaz, Onat; Cukur, Tolga; Kozat, Suleyman S.; Dibeklioglu, Hamdi			User Feedback-based Online Learning for Intent Classification	PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023			English	Proceedings Paper	25th International Conference on Multimodal Interaction (ICMI)	OCT 09-13, 2023	Sorbonne Univ, Paris, FRANCE	Assoc Comp Machinery, ACM SIGCHI, Openstreams Ai, Living & Learning Lab Neurodevelopment, CCC Comp Community Consortium Catalyst, AFIHM, Persyval Lab, Grenoble Informat Lab, Univ Grenoble Alpes, Sorbonne Ctr Artificial Intelligence	Sorbonne Univ	Online Learning; Contextual Bandits; Intent Classification; Multimodal Learning		Intent classification is a key task in natural language processing (NLP) that aims to infer the goal or intention behind a user's query. Most existing intent classification methods rely on supervised deep models trained on large annotated datasets of text-intent pairs. However, obtaining such datasets is often expensive and impractical in real-world settings. Furthermore, supervised models may overfit or face distributional shifts when new intents, utterances, or data distributions emerge over time, requiring frequent retraining. Online learning methods based on user feedback can overcome this limitation, as they do not need access to intents while collecting data and adapting the model continuously. In this paper, we propose a novel multi-armed contextual bandit framework that leverages a text encoder based on a large language model (LLM) to extract the latent features of a given utterance and jointly learn multimodal representations of encoded text features and intents. Our framework consists of two stages: offline pretraining and online fine-tuning. In the offline stage, we train the policy on a small labeled dataset using a contextual bandit approach. In the online stage, we fine-tune the policy parameters using the REINFORCE algorithm with a user feedback-based objective, without relying on the true intents. We further introduce a sliding window strategy for simulating the retrieval of data samples during online training. This novel two-phase approach enables our method to efficiently adapt to dynamic user preferences and data distributions with improved performance. An extensive set of empirical studies indicate that our method significantly outperforms policies that omit either offline pretraining or online fine-tuning, while achieving competitive performance to a supervised benchmark trained on an order of magnitude larger labeled dataset.	[Gonc, Kaan; Dibeklioglu, Hamdi] Bilkent Univ, Dept Comp Engn, Ankara, Turkiye; [Saglam, Baturay; Dalmaz, Onat; Cukur, Tolga; Kozat, Suleyman S.] Bilkent Univ, Dept Elect & Elect Engn, Ankara, Turkiye	Ihsan Dogramaci Bilkent University; Ihsan Dogramaci Bilkent University	Gönç, K (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkiye.	kaan.gonc@bilkent.edu.tr; baturay@ee.bilkent.edu.tr; onat@ee.bilkent.edu.tr; cukur@ee.bilkent.edu.tr; kozat@ee.bilkent.edu.tr; dibeklioglu@cs.bilkent.edu.tr	Dalmaz, Onat/GVT-1347-2022; Çukur, Tolga/Z-5452-2019	Dalmaz, Onat/0000-0001-7978-5311; Çukur, Tolga/0000-0002-2296-851X; Kozat, Suleyman Serdar/0000-0002-6488-3848; Saglam, Baturay/0000-0002-8324-5980				Ba JL., 2016, arXiv; Basu Samyadeep, 2021, arXiv; Brandfonbrener David, 2021, INT C MACHINE LEARNI, P1049; Buckman Jacob, 2021, INT C LEARNING REPRE; Bunk T, 2020, Arxiv, DOI [arXiv:2004.09936, DOI 10.48550/ARXIV.2004.09936]; Casanueva I, 2020, NLP FOR CONVERSATIONAL AI, P38; Chen Q, 2019, Arxiv, DOI arXiv:1902.10909; Daee P, 2016, PROCEEDINGS OF THE 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'16), P71, DOI 10.1145/2856767.2856803; Daume H, 2009, MACH LEARN, V75, P297, DOI 10.1007/s10994-009-5106-x; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Glorot X, 2010, P MACHINE LEARNING R, V9, P249, DOI DOI 10.1109/LGRS.2016.2565705; Guo HS, 2023, KNOWL INF SYST, V65, P1005, DOI 10.1007/s10115-022-01790-6; Hoi SCH, 2021, NEUROCOMPUTING, V459, P249, DOI 10.1016/j.neucom.2021.04.112; Jin Y., 2021, INT C MACHINE LEARNI, P5084; Kingma D. P., 2017, ARXIV; Lin YT, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1463; Liu B, 2018, AAAI CONF ARTIF INTE, P5245; Liu B, 2016, INTERSPEECH, P685, DOI 10.21437/Interspeech.2016-1352; Liu Yinhan, 2019, P 2019 C EMPIRICAL M, P833; Losada DE, 2021, 36TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, SAC 2021, P645, DOI 10.1145/3412841.3441944; Nguyen-Tang Thanh, 2022, INT C LEARNING REPRE; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Sachdeva N, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P965, DOI 10.1145/3394486.3403139; Saglam B, 2023, Arxiv, DOI arXiv:2208.00755; Si N., 2020, INT C MACHINE LEARNI; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696; XIAO C., 2021, INT C MACHINE LEARNI, P11362; Zhang HD, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1114; Zhang JG, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5064; Zhang Jianguo, 2021, P 2021 C EMPIRICAL M, DOI [10.18653/v1/2021.emnlpmain.144, DOI 10.18653/V1/2021.EMNLPMAIN.144]	31	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0055-2				2023							613	621		10.1145/3577190.3614137	http://dx.doi.org/10.1145/3577190.3614137			9	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GP		hybrid			2024-07-03	WOS:001147764700071
J	Ibrahim, H; Liu, FY; Asim, R; Battu, B; Benabderrahmane, S; Alhafni, B; Adnan, W; Alhanai, T; AlShebli, B; Baghdadi, R; Bélanger, JJ; Beretta, E; Celik, K; Chaqfeh, M; Daqaq, MF; El Bernoussi, Z; Fougnie, D; de Soto, BG; Gandolfi, A; Gyorgy, A; Habash, N; Harris, JA; Kaufman, A; Kirousis, L; Kocak, K; Lee, K; Lee, SS; Malik, S; Maniatakos, M; Melcher, D; Mourad, A; Park, M; Rasras, M; Reuben, A; Zantout, D; Gleason, NW; Makovi, K; Rahwan, T; Zaki, Y				Ibrahim, Hazem; Liu, Fengyuan; Asim, Rohail; Battu, Balaraju; Benabderrahmane, Sidahmed; Alhafni, Bashar; Adnan, Wifag; Alhanai, Tuka; AlShebli, Bedoor; Baghdadi, Riyadh; Belanger, Jocelyn J.; Beretta, Elena; Celik, Kemal; Chaqfeh, Moumena; Daqaq, Mohammed F.; El Bernoussi, Zaynab; Fougnie, Daryl; de Soto, Borja Garcia; Gandolfi, Alberto; Gyorgy, Andras; Habash, Nizar; Harris, J. Andrew; Kaufman, Aaron; Kirousis, Lefteris; Kocak, Korhan; Lee, Kangsan; Lee, Seungah S.; Malik, Samreen; Maniatakos, Michail; Melcher, David; Mourad, Azzam; Park, Minsu; Rasras, Mahmoud; Reuben, Alicja; Zantout, Dania; Gleason, Nancy W.; Makovi, Kinga; Rahwan, Talal; Zaki, Yasir			Perception, performance, and detectability of conversational artificial intelligence across 32 university courses	SCIENTIFIC REPORTS			English	Article							NORMS	The emergence of large language models has led to the development of powerful tools such as ChatGPT that can produce text indistinguishable from human-generated work. With the increasing accessibility of such technology, students across the globe may utilize it to help with their school work-a possibility that has sparked ample discussion on the integrity of student evaluation processes in the age of artificial intelligence (AI). To date, it is unclear how such tools perform compared to students on university-level courses across various disciplines. Further, students' perspectives regarding the use of such tools in school work, and educators' perspectives on treating their use as plagiarism, remain unknown. Here, we compare the performance of the state-of-the-art tool, ChatGPT, against that of students on 32 university-level courses. We also assess the degree to which its use can be detected by two classifiers designed specifically for this purpose. Additionally, we conduct a global survey across five countries, as well as a more in-depth survey at the authors' institution, to discern students' and educators' perceptions of ChatGPT's use in school work. We find that ChatGPT's performance is comparable, if not superior, to that of students in a multitude of courses. Moreover, current AI-text classifiers cannot reliably detect ChatGPT's use in school work, due to both their propensity to classify human-written answers as AI-generated, as well as the relative ease with which AI-generated text can be edited to evade detection. Finally, there seems to be an emerging consensus among students to use the tool, and among educators to treat its use as plagiarism. Our findings offer insights that could guide policy discussions addressing the integration of artificial intelligence into educational frameworks.	[Ibrahim, Hazem; Liu, Fengyuan; Asim, Rohail; Battu, Balaraju; Benabderrahmane, Sidahmed; Alhafni, Bashar; Baghdadi, Riyadh; Belanger, Jocelyn J.; Beretta, Elena; Chaqfeh, Moumena; Fougnie, Daryl; Gandolfi, Alberto; Habash, Nizar; Kirousis, Lefteris; Melcher, David; Mourad, Azzam; Zantout, Dania; Rahwan, Talal; Zaki, Yasir] New York Univ Abu Dhabi, Div Sci, Abu Dhabi, U Arab Emirates; [Adnan, Wifag; AlShebli, Bedoor; El Bernoussi, Zaynab; Harris, J. Andrew; Kaufman, Aaron; Kocak, Korhan; Lee, Kangsan; Lee, Seungah S.; Malik, Samreen; Park, Minsu; Reuben, Alicja; Gleason, Nancy W.; Makovi, Kinga] New York Univ Abu Dhabi, Div Social Sci, Abu Dhabi, U Arab Emirates; [Alhanai, Tuka; Celik, Kemal; Daqaq, Mohammed F.; de Soto, Borja Garcia; Gyorgy, Andras; Maniatakos, Michail; Rasras, Mahmoud] New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates	New York University Abu Dhabi; New York University Abu Dhabi; New York University Abu Dhabi	Rahwan, T; Zaki, Y (corresponding author), New York Univ Abu Dhabi, Div Sci, Abu Dhabi, U Arab Emirates.	talal.rahwan@nyu.edu; yasir.zaki@nyu.edu	Celik, Kemal/AAO-1005-2021; Liu, Fengyuan "Michael"/ISS-3850-2023; Makovi, Kinga/GXV-5373-2022; Rahwan, Talal/A-2884-2017; Battu, Balaraju/T-7586-2019; Lee, Seungah Sarah/GZA-7657-2022	Celik, Kemal/0000-0001-7623-0943; Battu, Balaraju/0000-0002-1455-8924; Lee, Seungah Sarah/0000-0003-4391-7049; El Bernoussi, Zaynab/0000-0002-1663-3289; Benabderrahmane, Sidahmed/0000-0001-9633-810X; Ibrahim, Hazem/0000-0003-2165-214X	NYUAD Center for Interacting Urban Networks (CITIES) - Tamkeen under the NYUAD Research Institute [CG001]	NYUAD Center for Interacting Urban Networks (CITIES) - Tamkeen under the NYUAD Research Institute	K.M. acknowledges funding from the NYUAD Center for Interacting Urban Networks (CITIES), funded by Tamkeen under the NYUAD Research Institute Award CG001.	[Anonymous], 2023, ABOUT US; [Anonymous], 2023, Tools such as ChatGPT threaten transparent science; here are our ground rules for their use.; [Anonymous], 2017, Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems-CHI EA'17, DOI DOI 10.1145/3027063.3053335; Bicchieri C, 2005, GRAMMAR SOC NATURE D, DOI [10.1017/CBO9780511616037, DOI 10.1017/CBO9780511616037]; Bicchieri C., 2016, NORMS IN THE WILD; Bicchieri C, 2010, POLIT PHILOS ECON, V9, P297, DOI 10.1177/1470594X10369276; Cassidy C., 2023, Australian universities to return to 'pen and paper' exams after students caught using AI to write essays; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; CIALDINI RB, 1990, J PERS SOC PSYCHOL, V58, P1015, DOI 10.1037/0022-3514.58.6.1015; Cribben I., 2023, Operations Management and Data Analytics; DeepMind, 2023, about us; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Evans RR, 2009, J CONS HLTH INTERNET, V13, P42, DOI 10.1080/15398280802674743; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gilson A., 2022, MEDRXIV; GPTZero, Humans deserve the truth; Harding T.S., 2003, 33 ANN FRONT ED 2003, V3, pS2A; Hargreaves S., 2023, The Chinese University of Hong Kong Faculty of Law Research Paper; Hong W. C.H., 2023, J. Educat. Technol. Innovat., V5; Huang Kalley., 2023, NEW YORK TIMES; HuggingFace, 2023, about us; Ibrahim H, 2023, IEEE INTELL SYST, V38, P24, DOI 10.1109/MIS.2023.3255599; Ji H, 2023, J RES TECHNOL EDUC, V55, P48, DOI 10.1080/15391523.2022.2142873; Johnson D.D., 2008, Stop high-stakes testing: An appeal to America's conscience; Korn Jennifer, 2023, Getty Images suing the makers of popular AI art tool for allegedly stealing photos; Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Larsen B., Generative AI: A game-changer society needs to be ready for; Lipman J., 2023, Schools shouldn't ban access to ChatGPT; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Mielke J, 2017, P NATL ACAD SCI USA, V114, pE10648, DOI 10.1073/pnas.1706085114; Mollick E.R., 2023, Including Prompts; Mollick E. R., 2022, New modes of learning enabled by AI chatbots: Three methods and assignments; Mollick E, 2023, Arxiv, DOI [arXiv:2306.10052, DOI 10.48550/ARXIV.2306.10052]; Mollman S., 2022, YAHOO FINANCE; Mostaque E., 2022, STABLE DIFFUSION PUB; Music A., AI music composition tools for content creators; Nonis S., 2001, J EDUC BUS, V77, P69, DOI [10.1080/08832320109599052, DOI 10.1080/08832320109599052]; OpenAI, 2023, ABOUT US; OpenAI, ABOUT US; Parsa S, 2014, P NATL ACAD SCI USA, V111, P3889, DOI 10.1073/pnas.1312693111; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Péloquin K, 2010, J PERS ASSESS, V92, P146, DOI 10.1080/00223890903510399; Plaugic L., 2017, Musician Taryn Southern on composing her new album entirely with AI; Pursnani V, 2023, Arxiv, DOI arXiv:2304.12198; quillbot, QuillBot's AI-powered paraphrasing tool will enhance your writing; Qureshi B, 2023, Arxiv, DOI arXiv:2304.11214; Ramesh A., 2022, arXiv; Roberg KIK, 2017, J EDUC WORK, V30, P383, DOI 10.1080/13639080.2016.1187265; Roose K., 2023, Don't ban ChatGPT in schools. Teach with it. New York Times; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sample I., 2023, ChatGPT: What can the extraordinary artificial intelligence chatbot do?; Schwartz E.H, 2022, ChatGPT banned on Chinese social media app WeChat; Shen-Berro J., 2023, New York City schools blocked ChatGPT. Here's what other large districts are doing; TII, 2023, about us; Vincent J., 2022, The scary truth about AI copyright is nobody knows what will happen next; Vincent J., 2023, AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit; Vincent J., 2023, TOP AI C BANS US CH; Watkins M.D, 2022, A revolution in productivity': What ChatGPT could mean for business; Wilson L., 2016, The second principle	61	21	21	16	25	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	OCT 10	2023	13	1							12187	10.1038/s41598-023-38964-3	http://dx.doi.org/10.1038/s41598-023-38964-3			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	X5TW1	37620342	gold, Green Published			2024-07-03	WOS:001099084800001
J	Lai, UH; Wu, KS; Hsu, TY; Kan, JKC				Lai, U. Hin; Wu, Keng Sam; Hsu, Ting-Yu; Kan, Jessie Kai Ching			Evaluating the performance of ChatGPT-4 on the United Kingdom Medical Licensing Assessment	FRONTIERS IN MEDICINE			English	Article						examination; ChatGPT; assessment; United Kingdom Medical Licensing Assessment; medical education; medicine; Medical Licensing Examination	ARTIFICIAL-INTELLIGENCE	IntroductionRecent developments in artificial intelligence large language models (LLMs), such as ChatGPT, have allowed for the understanding and generation of human-like text. Studies have found LLMs abilities to perform well in various examinations including law, business and medicine. This study aims to evaluate the performance of ChatGPT in the United Kingdom Medical Licensing Assessment (UKMLA).MethodsTwo publicly available UKMLA papers consisting of 200 single-best-answer (SBA) questions were screened. Nine SBAs were omitted as they contained images that were not suitable for input. Each question was assigned a specialty based on the UKMLA content map published by the General Medical Council. A total of 191 SBAs were inputted in ChatGPT-4 through three attempts over the course of 3 weeks (once per week).ResultsChatGPT scored 74.9% (143/191), 78.0% (149/191) and 75.6% (145/191) on three attempts, respectively. The average of all three attempts was 76.3% (437/573) with a 95% confidence interval of (74.46% and 78.08%). ChatGPT answered 129 SBAs correctly and 32 SBAs incorrectly on all three attempts. On three attempts, ChatGPT performed well in mental health (8/9 SBAs), cancer (11/14 SBAs) and cardiovascular (10/13 SBAs). On three attempts, ChatGPT did not perform well in clinical haematology (3/7 SBAs), endocrine and metabolic (2/5 SBAs) and gastrointestinal including liver (3/10 SBAs). Regarding to response consistency, ChatGPT provided correct answers consistently in 67.5% (129/191) of SBAs but provided incorrect answers consistently in 12.6% (24/191) and inconsistent response in 19.9% (38/191) of SBAs, respectively.Discussion and conclusionThis study suggests ChatGPT performs well in the UKMLA. There may be a potential correlation between specialty performance. LLMs ability to correctly answer SBAs suggests that it could be utilised as a supplementary learning tool in medical education with appropriate medical educator supervision.	[Lai, U. Hin; Wu, Keng Sam] Sandwell & West Birmingham NHS Trust, West Bromwich, England; [Lai, U. Hin; Hsu, Ting-Yu; Kan, Jessie Kai Ching] Aston Med Sch, Birmingham, England; [Wu, Keng Sam; Hsu, Ting-Yu] Univ Hosp Birmingham NHS Trust, Birmingham, England; [Kan, Jessie Kai Ching] Worcestershire Acute Hosp NHS Trust, Worcester, England		Lai, UH; Wu, KS (corresponding author), Sandwell & West Birmingham NHS Trust, West Bromwich, England.; Lai, UH (corresponding author), Aston Med Sch, Birmingham, England.; Wu, KS (corresponding author), Univ Hosp Birmingham NHS Trust, Birmingham, England.	UHL@doctors.org.uk; kengsamwu@doctors.org.uk		Lai, U Hin/0000-0002-0291-0900				Abdelkarim A., 2018, EC Dent Sci, V17, P1; Al-Shakarchi N. J., 2023, Mayo Clinic Proceedings: Digital Health, V1, P309, DOI [10.1016/j.mcpdig.2023.06.004, DOI 10.1016/J.MCPDIG.2023.06.004]; Aldridge MJ, 2023, BRIT J ANAESTH, V131, pe36, DOI 10.1016/j.bja.2023.04.033; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bini SA, 2018, J ARTHROPLASTY, V33, P2358, DOI 10.1016/j.arth.2018.02.067; Blagojevic Andela, 2023, Applied Artificial Intelligence: Medicine, Biology, Chemistry, Financial, Games, Engineering. Lecture Notes in Networks and Systems (659), P271, DOI 10.1007/978-3-031-29717-5_17; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Collins C, 2021, INT J INFORM MANAGE, V60, DOI 10.1016/j.ijinfomgt.2021.102383; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Farhat F., PREPRINT; General Medical Council, MED LIC ASS; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Helm JM, 2020, CURR REV MUSCULOSKE, V13, P69, DOI 10.1007/s12178-020-09600-8; Homolak J, 2023, CROAT MED J, V64, P1, DOI 10.3325/cmj.2023.64.1; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Jang ME, 2023, Arxiv, DOI arXiv:2303.06273; Kasai J, 2023, Arxiv, DOI [arXiv:2303.18027, DOI 10.48550/ARXIV.2303.18027]; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Leydon GB, 2020, YALE J BIOL MED, V93, P453; Masters K, 2019, MED TEACH, V41, P976, DOI 10.1080/0142159X.2019.1595557; Medical Schools Council, 2023, The Applied Knowledge Test-FAQs for UK medical students; Medical Schools Council, 2023, Medical Licensing Assessment-practice materials; Nakase H, 2021, DIGEST ENDOSC, V33, P903, DOI 10.1111/den.13825; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Royal College of General Practitioners, 2022, AKT 45; Royal College of General Practitioners, 2022, AKT 44; Royal College of General Practitioners, 2021, AKT 42; Royal College of General Practitioners, 2023, AKT 47; Royal College of General Practitioners, 2021, AKT 43; Royal College of General Practitioners, MRCGP: Applied Knowledge Test (AKT); Royal College of General Practitioners, 2022, AKT 46; Royal College of General Practitioners, 2023, AKT 48; Sarker Iqbal H, 2022, SN Comput Sci, V3, P158, DOI 10.1007/s42979-022-01043-x; Saygin AP, 2000, MIND MACH, V10, P463, DOI 10.1023/A:1011288000451; Soong TK, 2021, ADV MED EDUC PRACT, V12, P167, DOI 10.2147/AMEP.S287926; St George B., Turing test; Stifanic J., 2023, Applied artificial intelligence: medicine, biology, chemistry, financial, games, engineering, P121; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; The General Medical Council, MLA content map; Tsang R, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231178449; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Wang XY, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01961-0; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942; White H., 2001, STANFORD U NEWSLETTE, V11, P1; Wolfram S, What is ChatGPT doing . . . and why does it work?	46	8	8	10	27	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-858X		FRONT MED-LAUSANNE	Front. Med.	SEP 19	2023	10								1240915	10.3389/fmed.2023.1240915	http://dx.doi.org/10.3389/fmed.2023.1240915			8	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	S8YQ5	37795422	Green Published, gold, Green Accepted			2024-07-03	WOS:001073973100001
J	Ying, LW; Li, SC; Chen, CY; Yang, F; Li, X; Chen, Y; Ding, Y; Chang, GY; Li, J; Wang, XM				Ying, Lingwen; Li, Sichen; Chen, Chunyang; Yang, Fan; Li, Xin; Chen, Yao; Ding, Yu; Chang, Guoying; Li, Juan; Wang, Xiumin			Screening/diagnosis of pediatric endocrine disorders through the artificial intelligence model in different language settings	EUROPEAN JOURNAL OF PEDIATRICS			English	Article						ChatGPT; Artificial intelligence; Pediatric endocrine and metabolism; Physician and patients; Language mode; Screening and diagnosis		This study is aimed at examining the impact of ChatGPT on pediatric endocrine and metabolic conditions, particularly in the areas of screening and diagnosis, in both Chinese and English modes. A 40-question questionnaire covering the four most common pediatric endocrine and metabolic conditions was posed to ChatGPT in both Chinese and English three times each. Six pediatric endocrinologists evaluated the responses. ChatGPT performed better when responding to questions in English, with an unreliable rate of 7.5% compared to 27.5% for Chinese questions, indicating a more consistent response pattern in English. Among the reliable questions, the answers were more comprehensive and satisfactory in the English mode. We also found disparities in ChatGPT's performance when interacting with different target groups and diseases, with improved performance for questions posed by clinicians in English and better performance for questions related to diabetes and overweight/obesity in Chinese for both clinicians and patients. Language comprehension, providing incomprehensive answers, and errors in key data were the main contributors to the low scores, according to reviewer feedback.Conclusion: Despite these limitations, as ChatGPT continues to evolve and expand its network, it has significant potential as a practical and effective tool for clinical diagnosis and treatment. What is Known:center dot The deep learning-based large-language model ChatGPT holds great promise for improving clinical practice for both physicians and patients and has the potential to increase the speed and accuracy of disease screening and diagnosis, as well as enhance the overall efficiency of the medical process. However, the reliability and appropriateness of AI model responses in specific field remains unclear.center dot This study focused on the reliability and appropriateness of AI model responses to straightforward and fundamental questions related to the four most prevalent pediatric endocrine and metabolic disorders, for both healthcare providers and patients, in different language scenarios.What is New:center dot The AI model performed better when responding to questions in English, with more consistent, as well as more comprehensive and satisfactory responses. In addition, we also found disparities in ChatGPT's performance when interacting with different target groups and different diseases.center dot Despite these limitations, as ChatGPT continues to evolve and expand its network, it has significant potential as a practical and effective tool for clinical diagnosis and treatment.	[Ying, Lingwen; Yang, Fan; Li, Xin; Chen, Yao; Ding, Yu; Chang, Guoying; Li, Juan; Wang, Xiumin] Shanghai Jiao Tong Univ, Shanghai Childrens Med Ctr, Sch Med, Dept Endocrinol & Metab, Shanghai 200127, Peoples R China; [Li, Sichen] Fudan Univ, Huashan Hosp, Shanghai Med Coll, Dept Neurosurg, Shanghai 200040, Peoples R China; [Li, Sichen] Fudan Univ, Natl Ctr Neurol Disorders,Neurosurg Inst, Shanghai Clin Med Ctr Neurosurg,Neural Regenerat, Shanghai Key Lab Brain Funct & Restorat & Neural R, Shanghai 200040, Peoples R China; [Chen, Chunyang] Monash Univ, Fac Informat Technol, Clayton, Vic 3800, Australia	Shanghai Jiao Tong University; Fudan University; Fudan University; Monash University	Chang, GY; Wang, XM (corresponding author), Shanghai Jiao Tong Univ, Shanghai Childrens Med Ctr, Sch Med, Dept Endocrinol & Metab, Shanghai 200127, Peoples R China.	wangxiumin1019@126.com; changguoying@126.com			National Natural Science Foundation of China [82170910, 82201466]; Shanghai Health and Family Planning Commission [20204Y0346]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Health and Family Planning Commission	This project was supported by the National Natural Science Foundation of China (Grants No. 82170910 and No. 82201466), as well as the Shanghai Health and Family Planning Commission (Grant No. 20204Y0346).	Ahuja AS, 2019, PEERJ, V7, DOI 10.7717/peerj.7702; Alberti KGMM, 1998, DIABETIC MED, V15, P539, DOI 10.1002/(SICI)1096-9136(199807)15:7<539::AID-DIA668>3.0.CO;2-S; Amer Diabet Assoc, 2014, DIABETES CARE, V37, pS81, DOI [10.2337/dc12-s011, 10.2337/dc13-S067, 10.2337/dc11-S062, 10.2337/dc14-S081, 10.2337/dc12-s064, 10.2337/dc11-S011, 10.2337/dc10-S062, 10.2337/dc10-S011, 10.2337/dc13-S011]; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; chat.openai.com, CHATGPT OPTIMIZING L; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Martinez-Millana A, 2022, INT J MED INFORM, V166, DOI 10.1016/j.ijmedinf.2022.104855; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044	8	1	1	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0340-6199	1432-1076		EUR J PEDIATR	Eur. J. Pediatr.	JUN	2024	183	6					2655	2661		10.1007/s00431-024-05527-1	http://dx.doi.org/10.1007/s00431-024-05527-1		MAR 2024	7	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	RJ2Y7	38502320	hybrid, Green Accepted			2024-07-03	WOS:001187459700002
J	Antaki, F; Milad, D; Chia, MA; Giguère, CE; Touma, S; El-Khoury, J; Keane, PA; Duval, R				Antaki, Fares; Milad, Daniel; Chia, Mark A.; Giguere, Charles-Edouard; Touma, Samir; El-Khoury, Jonathan; Keane, Pearse A.; Duval, Renaud			Capabilities of GPT-4 in ophthalmology: an analysis of model entropy and progress towards human-level medical question answering	BRITISH JOURNAL OF OPHTHALMOLOGY			English	Article; Early Access						Medical Education		Background Evidence on the performance of Generative Pre-trained Transformer 4 (GPT-4), a large language model (LLM), in the ophthalmology question-answering domain is needed.Methods We tested GPT-4 on two 260-question multiple choice question sets from the Basic and Clinical Science Course (BCSC) Self-Assessment Program and the OphthoQuestions question banks. We compared the accuracy of GPT-4 models with varying temperatures (creativity setting) and evaluated their responses in a subset of questions. We also compared the best-performing GPT-4 model to GPT-3.5 and to historical human performance.Results GPT-4-0.3 (GPT-4 with a temperature of 0.3) achieved the highest accuracy among GPT-4 models, with 75.8% on the BCSC set and 70.0% on the OphthoQuestions set. The combined accuracy was 72.9%, which represents an 18.3% raw improvement in accuracy compared with GPT-3.5 (p<0.001). Human graders preferred responses from models with a temperature higher than 0 (more creative). Exam section, question difficulty and cognitive level were all predictive of GPT-4-0.3 answer accuracy. GPT-4-0.3's performance was numerically superior to human performance on the BCSC (75.8% vs 73.3%) and OphthoQuestions (70.0% vs 63.0%), but the difference was not statistically significant (p=0.55 and p=0.09).Conclusion GPT-4, an LLM trained on non-ophthalmology-specific data, performs significantly better than its predecessor on simulated ophthalmology board-style exams. Remarkably, its performance tended to be superior to historical human performance, but that difference was not statistically significant in our study.	[Antaki, Fares; Chia, Mark A.; Keane, Pearse A.] Moorfields Eye Hosp NHS Fdn Trust, London, England; [Antaki, Fares; Chia, Mark A.; Keane, Pearse A.] UCL, Inst Ophthalmol, London, England; [Antaki, Fares] CHUM, Sch Artificial Intelligence Healthcare, Montreal, PQ, Canada; [Antaki, Fares; Milad, Daniel; Touma, Samir; El-Khoury, Jonathan; Duval, Renaud] Univ Montreal, Dept Ophthalmol, Montreal, PQ, Canada; [Antaki, Fares; Milad, Daniel; Touma, Samir; El-Khoury, Jonathan] Ctr Hosp Univ Montreal CHUM, Dept Ophthalmol, Montreal, PQ, Canada; [Milad, Daniel; Touma, Samir; El-Khoury, Jonathan; Duval, Renaud] Hop Maison Neuve Rosemont, Dept Ophthalmol, Montreal, PQ, Canada; [Giguere, Charles-Edouard] Inst Univ Sante Mentale Montreal IUSMM, Montreal, PQ, Canada; [Keane, Pearse A.] NIHR Moorfields Biomed Res Ctr, London, England; [Duval, Renaud] Univ Montreal, Ophthalmol, Montreal, PQ, Canada	University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; University of London; University College London; Universite de Montreal; Universite de Montreal; Universite de Montreal; Universite de Montreal; Universite de Montreal	Keane, PA (corresponding author), UCL, Inst Ophthalmol, London, England.; Duval, R (corresponding author), Univ Montreal, Ophthalmol, Montreal, PQ, Canada.	renaud.duval@gmail.com; p.keane@ucl.ac.uk	Keane, Pearse/AAE-5709-2019; Antaki, Fares/GSI-6622-2022	Keane, Pearse/0000-0002-9239-745X; Antaki, Fares/0000-0001-6679-7276; Milad, Daniel/0000-0002-0693-3421; Touma, Samir/0000-0002-6365-0946	We are deeply grateful to the American Academy of Ophthalmology for generously granting us permission to use the underlying BCSC Self-Assessment Program materials.	We are deeply grateful to the American Academy of Ophthalmology for generously granting us permission to use the underlying BCSC Self-Assessment Program materials.	We are deeply grateful to the American Academy of Ophthalmology for generously granting us permission to use the underlying BCSC Self-Assessment Program materials.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bommasani R., 2021, 2108.07258; Bowman Emma., 2022, NPR; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai Louis Z, 2023, Am J Ophthalmol, V256, P201, DOI 10.1016/j.ajo.2023.07.030; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Chia MA, 2023, JAMA OPHTHALMOL, V141, DOI 10.1001/jamaophthalmol.2023.3003; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dratsch T, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222176; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Hamel P, 2007, CAN J OPHTHALMOL, V42, P299, DOI 10.3129/canjophthalmol.i07-006; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; McCannel CA, 2022, JAMA OPHTHALMOL, V140, P225, DOI 10.1001/jamaophthalmol.2021.6173; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P798, DOI 10.1001/jamaophthalmol.2023.2754; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Schulman J, 2022, Introducing chatgpt; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Singhal K, 2023, NATURE, DOI 10.1038/s41586-023-06455-0; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Taib F, 2014, J TAIBAH UNIV MED SC, V9, P110, DOI 10.1016/j.jtumed.2013.12.002; Teebagy Sean, 2023, J Acad Ophthalmol (2017), V15, pe184, DOI 10.1055/s-0043-1774399; Varshney N, 2023, Arxiv, DOI arXiv:2307.03987; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Wiggins WF, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220119; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x	29	7	7	16	21	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	0007-1161	1468-2079		BRIT J OPHTHALMOL	Br. J. Ophthalmol.	2023 NOV 3	2023										10.1136/bjo-2023-324438	http://dx.doi.org/10.1136/bjo-2023-324438		NOV 2023	8	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	X5JY2	37923374	Green Submitted			2024-07-03	WOS:001098823200001
J	Huang, JX; Ding, RF; Wu, XM; Chen, SM; Zhang, JL; Liu, LX; Zheng, YX				Huang, Jingxiu; Ding, Ruofei; Wu, Xiaomin; Chen, Shumin; Zhang, Jiale; Liu, Lixiang; Zheng, Yunxiang			WERECE: An Unsupervised Method for Educational Concept Extraction Based on Word Embedding Refinement	APPLIED SCIENCES-BASEL			English	Article						concept extraction; word embedding; semantic computation; knowledge graph; manifold learning; clustering	DOMAIN; ONTOLOGIES	The era of educational big data has sparked growing interest in extracting and organizing educational concepts from massive amounts of information. Outcomes are of the utmost importance for artificial intelligence-empowered teaching and learning. Unsupervised educational concept extraction methods based on pre-trained models continue to proliferate due to ongoing advances in semantic representation. However, it remains challenging to directly apply pre-trained large language models to extract educational concepts; pre-trained models are built on extensive corpora and do not necessarily cover all subject-specific concepts. To address this gap, we propose a novel unsupervised method for educational concept extraction based on word embedding refinement (i.e., word embedding refinement-based educational concept extraction (WERECE)). It integrates a manifold learning algorithm to adapt a pre-trained model for extracting educational concepts while accounting for the geometric information in semantic computation. We further devise a discriminant function based on semantic clustering and Box-Cox transformation to enhance WERECE's accuracy and reliability. We evaluate its performance on two newly constructed datasets, EDU-DT and EDUTECH-DT. Experimental results show that WERECE achieves an average precision up to 85.9%, recall up to 87.0%, and F1 scores up to 86.4%, which significantly outperforms baselines (TextRank, term frequency-inverse document frequency, isolation forest, K-means, and one-class support vector machine) on educational concept extraction. Notably, when WERECE is implemented with different parameter settings, its precision and recall sensitivity remain robust. WERECE also holds broad application prospects as a foundational technology, such as for building discipline-oriented knowledge graphs, enhancing learning assessment and feedback, predicting learning interests, and recommending learning resources.	[Huang, Jingxiu; Ding, Ruofei; Wu, Xiaomin; Chen, Shumin; Zhang, Jiale; Liu, Lixiang; Zheng, Yunxiang] South China Normal Univ, Sch Educ Informat Technol, 55 Western Zhongshan Ave, Guangzhou 510631, Peoples R China	South China Normal University	Zheng, YX (corresponding author), South China Normal Univ, Sch Educ Informat Technol, 55 Western Zhongshan Ave, Guangzhou 510631, Peoples R China.	jimsow@m.scnu.edu.cn; ruofei@m.scnu.edu.cn; 201928210238@m.scnu.edu.cn; 20192831014@m.scnu.edu.cn; 20222831048@m.scnu.edu.cn; 20222821033@m.scnu.edu.cn; dr.zheng.scnu@hotmail.com	Liu, Lixiang/D-1145-2017; Wu, Xiaomin/S-4953-2019	Zheng, Yunxiang/0000-0002-3157-1565; , Jingxiu/0000-0001-6027-567X	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Abyaa A, 2019, ETR&D-EDUC TECH RES, V67, P1105, DOI 10.1007/s11423-018-09644-1; Ahmed R, 2021, MOBILE NETW APPL, V26, P2206, DOI 10.1007/s11036-021-01776-8; Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3; Alba A, 2017, K-CAP 2017: PROCEEDINGS OF THE KNOWLEDGE CAPTURE CONFERENCE, DOI 10.1145/3148011.3148021; Albahr A, 2021, KNOWL INF SYST, V63, P1663, DOI 10.1007/s10115-021-01568-2; Aminanto ME, 2020, IEEE ACCESS, V8, P217977, DOI 10.1109/ACCESS.2020.3041837; Bai XM, 2021, BIG DATA RES, V26, DOI 10.1016/j.bdr.2021.100270; Bellaachia A, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P372, DOI 10.1109/WI-IAT.2012.82; Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25; Bicego M, 2016, NEUROCOMPUTING, V218, P390, DOI 10.1016/j.neucom.2016.08.081; Blum L, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.877569; Boudin F, 2018, Arxiv, DOI arXiv:1803.08721; Bougouin A., 2013, INT JOINT C NAT LANG, P543; BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x; Caliski T., 1974, COMMUN STAT, V3, P1, DOI DOI 10.1080/03610927408827101; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Chau H, 2021, INT J ARTIF INTELL E, V31, P820, DOI 10.1007/s40593-020-00207-1; Chen NS, 2008, COMPUT EDUC, V50, P1009, DOI 10.1016/j.compedu.2006.10.001; Chu YH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5394; Clavi‚ B, 2019, Arxiv, DOI arXiv:1912.00690; Conde A, 2016, J ASSOC INF SCI TECH, V67, P380, DOI 10.1002/asi.23398; Daems O, 2014, J COMPUT EDUC, V1, P113, DOI 10.1007/s40692-014-0013-y; Désir C, 2013, PATTERN RECOGN, V46, P3490, DOI 10.1016/j.patcog.2013.05.022; Desul S, 2019, ELECTRON LIBR, V37, P2, DOI 10.1108/EL-01-2018-0012; Firoozeh N, 2020, NAT LANG ENG, V26, P259, DOI 10.1017/S1351324919000457; Fu SY, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103526; Gong LJ, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S021800141757004X; Hasan S., 2017, P 2017 C EMP METH NA; Kang YB, 2016, IEEE T KNOWL DATA EN, V28, P524, DOI 10.1109/TKDE.2015.2475759; Kang YB, 2014, EXPERT SYST APPL, V41, P4494, DOI 10.1016/j.eswa.2014.01.006; Kong SC, 2018, J EDUC COMPUT RES, V56, P369, DOI 10.1177/0735633117707991; Levow GA, 2005, INFORM PROCESS MANAG, V41, P523, DOI 10.1016/j.ipm.2004.06.012; Lin YG, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107085; Liu J., 2010, P 2010 INT S INT INF; Lu M., 2023, Long Papers, V1; Lu WM, 2019, AAAI CONF ARTIF INTE, P9678; Magister LC, 2022, Arxiv, DOI [arXiv:2207.13586, DOI 10.48550/ARXIV.2207.13586]; Mihalcea R., 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Morales-Hernández A, 2023, ARTIF INTELL REV, V56, P8043, DOI 10.1007/s10462-022-10359-2; Niven T, 2019, Arxiv, DOI arXiv:1907.07355; Pan L., 2017, P 8 INT JOINT C NAT, V1, P875; Papagiannopoulou E., 2021, P 15 WORKSH GRAPH BA; Patel A, 2018, Arxiv, DOI arXiv:1810.11190; Peng X, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00211-4; Peterson Kevin J, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P515; Poria S., 2018, Multimodal Sentiment Analysis, P79; Sezerer E., 2021, arXiv; Shamsfard M, 2003, KNOWL ENG REV, V18, P293, DOI 10.1017/S0269888903000687; Sharif W, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183723; Song Yan, 2018, P 2018 C N AM CHAPT, V2, P175, DOI [DOI 10.18653/V1/N18-2028, 10.18653/v1/n18-2028, 10.18653/v1/N18-2028]; Stankovic R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P507; Szwed P, 2015, ACSIS-ANN COMPUT SCI, V5, P355, DOI 10.15439/2015F280; Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319; Tulkens S, 2019, J BIOMED INFORM, V91, DOI 10.1016/j.jbi.2019.103120; Utsumi A, 2020, COGNITIVE SCI, V44, DOI 10.1111/cogs.12844; Wang BL, 2022, NEUROCOMPUTING, V492, P117, DOI 10.1016/j.neucom.2022.04.009; Wang SA, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-01995-6; Wang X., 2018, P 3 INT C DAT SCI CY; Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008; Wu LJ, 2015, BRIT J EDUC TECHNOL, V46, P1118, DOI 10.1111/bjet.12298; Wu SX, 2019, EXPERT SYST APPL, V116, P285, DOI 10.1016/j.eswa.2018.09.024; Xiong A, 2021, TSINGHUA SCI TECHNOL, V26, P886, DOI 10.26599/TST.2020.9010051; Xu D., 2015, AnDS, V2, P165, DOI [10.1007/s40745-015-0040-1, DOI 10.1007/S40745-015-0040-1, 10.1007/S40745-015-0040-1]; Yu JF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3135; Zhang JL, 2023, ELECTRON COMMER RES, V23, P1775, DOI 10.1007/s10660-021-09516-6; Zhang L., 2017, Journal of Computers, V28, P301, DOI [https://doi.org/10.3966/199115992017122806027, DOI 10.3966/199115992017122806027]; Zhang ZQ, 2018, ACM T KNOWL DISCOV D, V12, DOI 10.1145/3201408; Zhao D, 2021, NEUROCOMPUTING, V447, P172, DOI 10.1016/j.neucom.2021.02.071; Zhao W., 2020, P 28 INT C COMP LING	71	0	0	11	13	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	NOV	2023	13	22							12307	10.3390/app132212307	http://dx.doi.org/10.3390/app132212307			20	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	AK4Z7		gold			2024-07-03	WOS:001118360300001
J	Miller, R				Miller, Robert			A Surgical Perspective on Large Language Models	ANNALS OF SURGERY			English	Editorial Material						artificial intelligence; chatbots; large language models; neural networks			[Miller, Robert] Imperial Coll Healthcare Trust, Charing Cross Hosp, Plast & Reconstruct Surg Dept, London, England; [Miller, Robert] London Med Imaging & AI Ctr Value Based Healthcare, Clin Artificial Intelligence, London, England	Imperial College London	Miller, R (corresponding author), Imperial Coll Healthcare Trust, Charing Cross Hosp, Plast & Reconstruct Surg Dept, London, England.; Miller, R (corresponding author), London Med Imaging & AI Ctr Value Based Healthcare, Clin Artificial Intelligence, London, England.	robmiller90@gmail.com		Miller, Robert/0000-0001-7090-2710				Elliot Bolton DH., 2022, STANFORD CRFM INTRO; Geoghegan L., 2021, BJS OPEN, V5; Health Education England, 2019, The Topol review: Preparing the healthcare workforce to deliver the digital future; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Leslie D, 2019, Arxiv, DOI arXiv:1906.05684; NHS England. Transformation Directorate, 2022, ARTIF INTELL; OpenAI, ABOUT US; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7	10	1	1	9	25	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0003-4932	1528-1140		ANN SURG	Ann. Surg.	AUG	2023	278	2					E211	E213		10.1097/SLA.0000000000005896	http://dx.doi.org/10.1097/SLA.0000000000005896			3	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	L9DX3	37132392	Bronze			2024-07-03	WOS:001026207500012
J	Zhang, JB; Yang, PP; Zeng, L; Li, S; Zhou, JM				Zhang, Jinbo; Yang, Pingping; Zeng, Lu; Li, Shan; Zhou, Jiamei			Ventilator-Associated Pneumonia Prediction Models Based on AI: Scoping Review	JMIR MEDICAL INFORMATICS			English	Review						artificial intelligence; machine learning; ventilator-associated pneumonia; prediction; scoping; PRISMA; Preferred Reporting Items for Systematic Reviews and Meta-Analyses	DECISION-SUPPORT; MANAGEMENT; SYSTEM	Background: Ventilator -associated pneumonia (VAP) is a serious complication of mechanical ventilation therapy that affects patients' treatments and prognoses. Owing to its excellent data mining capabilities, artificial intelligence (AI) has been increasingly used to predict VAP. Objective: This paper reviews VAP prediction models that are based on AI, providing a reference for the early identification of high -risk groups in future clinical practice. Methods: A scoping review was conducted in accordance with the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta -Analyses extension for Scoping Reviews) guidelines. The Wanfang database, the Chinese Biomedical Literature Database, Cochrane Library, Web of Science, PubMed, MEDLINE, and Embase were searched to identify relevant articles. Study selection and data extraction were independently conducted by 2 reviewers. The data extracted from the included studies were synthesized narratively. Results: Of the 137 publications retrieved, 11 were included in this scoping review. The included studies reported the use of AI for predicting VAP. All 11 studies predicted VAP occurrence, and studies on VAP prognosis were excluded. Further, these studies used text data, and none of them involved imaging data. Public databases were the primary sources of data for model building (studies: 6/11, 55%), and 5 studies had sample sizes of <1000. Machine learning was the primary algorithm for studying the VAP prediction models. However, deep learning and large language models were not used to construct VAP prediction models. The random forest model was the most commonly used model (studies: 5/11, 45%). All studies only performed internal validations, and none of them addressed how to implement and apply the final model in real -life clinical settings. Conclusions: This review presents an overview of studies that used AI to predict and diagnose VAP. AI models have better predictive performance than traditional methods and are expected to provide indispensable tools for VAP risk prediction in the future. However, the current research is in the model construction and validation stage, and the implementation of and guidance for clinical VAP prediction require further research.	[Zhang, Jinbo; Yang, Pingping; Zeng, Lu; Li, Shan; Zhou, Jiamei] Zunyi Med Univ, Affiliated Hosp, Nursing Dept, 149 Dalian Rd, Zunyi 563000, Peoples R China; [Zhang, Jinbo; Yang, Pingping; Zeng, Lu; Li, Shan; Zhou, Jiamei] Zunyi Med Univ, Nursing Coll, Zunyi, Peoples R China	Zunyi Medical University; Zunyi Medical University	Zhou, JM (corresponding author), Zunyi Med Univ, Affiliated Hosp, Nursing Dept, 149 Dalian Rd, Zunyi 563000, Peoples R China.	zhoujiamei666@163.com						Abujaber A, 2021, BRAIN INJURY, V35, P1095, DOI 10.1080/02699052.2021.1959060; Aung YYM, 2021, BRIT MED BULL, V139, P4, DOI 10.1093/bmb/ldab016; Chen CY, 2020, RESP RES, V21, DOI 10.1186/s12931-020-1285-6; Collins T, 2021, NURS CRIT CARE, V26, P224, DOI 10.1111/nicc.12570; Faucher M, 2022, Preprints, DOI [10.20944/preprints202206.0149.v1, 10.20944/preprints202206.0149.v1, DOI 10.20944/PREPRINTS202206.0149.V1]; Frondelius T, 2024, EUR J INTERN MED, V121, P76, DOI 10.1016/j.ejim.2023.11.009; Frondelius T, 2022, J CRIT CARE, V67, P44, DOI 10.1016/j.jcrc.2021.10.001; Giang C, 2021, MEDICINE, V100, DOI 10.1097/MD.0000000000026246; Lee T, 2023, ACAD RADIOL, V30, P2844, DOI 10.1016/j.acra.2023.02.016; Liang YJ, 2022, BMC PULM MED, V22, DOI 10.1186/s12890-022-02031-w; Liao YH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19081866; Mingwei S, 2023, Chinese Journal of Geriatrics, V42, P670, DOI [10.3760/cma.j.issn.0254-9026.2023.06.009, DOI 10.3760/CMA.J.ISSN.0254-9026.2023.06.009]; Modi AR, 2020, CLEV CLIN J MED, V87, P633, DOI 10.3949/ccjm.87a.19117; Papazian L, 2020, INTENS CARE MED, V46, P888, DOI 10.1007/s00134-020-05980-0; Pearl A, 2012, STUD HEALTH TECHNOL, V180, P305, DOI 10.3233/978-1-61499-101-4-305; Preiksaitis C, 2023, JMIR MED EDUC, V9, DOI 10.2196/48785; Rambaud J, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13182983; Samadani A, 2023, ARTIF INTELL MED, V146, DOI 10.1016/j.artmed.2023.102715; Schurink CAM, 2007, INTENS CARE MED, V33, P1379, DOI 10.1007/s00134-007-0728-6; Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850; Tsai HC, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.1009164; Wang YT, 2023, J MULTIDISCIP HEALTH, V16, P3737, DOI 10.2147/JMDH.S438316; Zheng H, 2021, IEEE ACCESS, V9, P113692, DOI 10.1109/ACCESS.2021.3099795	23	0	0	0	0	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2291-9694		JMIR MED INF	JMIR Med. Inf.		2024	12								e57026	10.2196/57026	http://dx.doi.org/10.2196/57026			11	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	RG0L9	38771220	gold, Green Accepted			2024-07-03	WOS:001226395600001
J	Zheng, SJ; He, KT; Yang, L; Xiong, J				Zheng, Shijie; He, Keith; Yang, Le; Xiong, Jie			MemoryRepository for AI NPC	IEEE ACCESS			English	Article						AI NPC; human-like; long-term memory; MemoryRepository; LLM		Since the release of ChatGPT, large language models (LLMs) have played a huge role in various industries. In the field of games, we have used LLMs to act as intelligent AI NPC, which makes NPCs more intelligent. However, there is still an obvious obstacle -the LLMs lacks long-term memory and human-like memory mechanism. This flawed memory mechanism prevents NPCs from Long-term interaction and humanized memory based on conversation records. Recognizing the necessity of long-term memory and humanized memory, we proposed MemoryRepository, a memory mechanism for LLMs specifically used in the AI NPC field.MemoryRepository enables the model to have short-term memory and long-term memory. Short-term memory is more detailed and full, while long-term memory are more concise and partial. MemoryRepository is inspired by human memory and forgetting mechanisms. This mechanism allows AI NPCs to forget and summarize past conversation records, thereby providing long-term interaction capabilities. More importantly, this process of forgetting and summarizing the details of short-term memory into general long-term memories makes NPCs more human-like. MemoryRepository is versatile and can adapt to closed source models such as ChatGPT and open source models such as ChatGLM. To Intuitively verify the effectiveness of MemoryRepository in the field of AI NPC, we created an example in which all NPCs are represented by LLMs adapted to MemoryRepository. The example shows that by embedding LLM in MemoryRepository and fine-tuning NPCs character dialogue data, AI NPC can conduct better long-term conversations and appear more human-like during the interaction process. To validate the effectiveness of MemoryRepository, one hundred pieces of NPCs dialogue data were created and then quantitatively analyzed through evaluation indicators. The analysis results show that NPCs equipped with MemoryRepository can summarize and forget past memories, which enables it to have the ability to hold long-term conversations and conduct more human-like conversations.	[Zheng, Shijie; Xiong, Jie] Yangtze Univ, Sch Elect Informat, Jingzhou 434023, Peoples R China; [He, Keith] OgCloud Ltd, Guangzhou 510000, Peoples R China; [Yang, Le] Guangdong Univ Technol, Guangzhou 510006, Peoples R China	Yangtze University; Guangdong University of Technology	Xiong, J (corresponding author), Yangtze Univ, Sch Elect Informat, Jingzhou 434023, Peoples R China.	xiongjie@yangtzeu.edu.cn		He, Keith/0009-0007-8772-2944				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adhikari A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4046; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gallotta R, 2024, Arxiv, DOI arXiv:2402.18659; Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Koster R., 2019, Postmortems From Game Developer: Insights From theDevelopers of Unreal Tournament, Black and White, Age of Empire, andOther Top-Selling Games; Liu T. Han, 2023, Meta-Radiol., V1; Modarressi A, 2023, Arxiv, DOI arXiv:2305.14322; Packer C, 2024, Arxiv, DOI arXiv:2310.08560; Parisotto E, 2017, Arxiv, DOI arXiv:1702.08360; Park J.S., 2023, P 36 ANN ACM S US IN, P1; Perez R. P., 2019, P 10 INT C COMP CREA, P3; Prada r., 2019, Artif. Intell., V277, P103; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae JW, 2016, ADV NEUR IN, V29; Riedl MO, 2013, AI MAG, V34, P67; Santoro A, 2016, PR MACH LEARN RES, V48; Sukhbaatar S, 2015, ADV NEUR IN, V28; Treanor B., 2012, P 3 WORKSH PROC CONT, P1; Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z; Weston J, 2018, Arxiv, DOI arXiv:1808.04776; Zhang CN, 2023, Arxiv, DOI arXiv:2303.11717; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou W, 2023, Arxiv, DOI arXiv:2307.15833	27	0	0	6	6	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						62581	62596		10.1109/ACCESS.2024.3393485	http://dx.doi.org/10.1109/ACCESS.2024.3393485			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	PU4Z4		gold			2024-07-03	WOS:001216596500001
J	Zong, H; Li, JK; Wu, ER; Wu, RR; Lu, JY; Shen, BR				Zong, Hui; Li, Jiakun; Wu, Erman; Wu, Rongrong; Lu, Junyu; Shen, Bairong			Performance of ChatGPT on Chinese national medical licensing examinations: a five-year examination evaluation study for physicians, pharmacists and nurses	BMC MEDICAL EDUCATION			English	Article						Medical education; Medical examination; Artificial intelligence; Natural language processing; ChatGPT		BackgroundLarge language models like ChatGPT have revolutionized the field of natural language processing with their capability to comprehend and generate textual content, showing great potential to play a role in medical education. This study aimed to quantitatively evaluate and comprehensively analysis the performance of ChatGPT on three types of national medical examinations in China, including National Medical Licensing Examination (NMLE), National Pharmacist Licensing Examination (NPLE), and National Nurse Licensing Examination (NNLE).MethodsWe collected questions from Chinese NMLE, NPLE and NNLE from year 2017 to 2021. In NMLE and NPLE, each exam consists of 4 units, while in NNLE, each exam consists of 2 units. The questions with figures, tables or chemical structure were manually identified and excluded by clinician. We applied direct instruction strategy via multiple prompts to force ChatGPT to generate the clear answer with the capability to distinguish between single-choice and multiple-choice questions.ResultsChatGPT failed to pass the accuracy threshold of 0.6 in any of the three types of examinations over the five years. Specifically, in the NMLE, the highest recorded accuracy was 0.5467, which was attained in both 2018 and 2021. In the NPLE, the highest accuracy was 0.5599 in 2017. In the NNLE, the most impressive result was shown in 2017, with an accuracy of 0.5897, which is also the highest accuracy in our entire evaluation. ChatGPT's performance showed no significant difference in different units, but significant difference in different question types. ChatGPT performed well in a range of subject areas, including clinical epidemiology, human parasitology, and dermatology, as well as in various medical topics such as molecules, health management and prevention, diagnosis and screening.ConclusionsThese results indicate ChatGPT failed the NMLE, NPLE and NNLE in China, spanning from year 2017 to 2021. but show great potential of large language models in medical education. In the future high-quality medical data will be required to improve the performance.	[Zong, Hui; Li, Jiakun; Wu, Erman; Wu, Rongrong; Lu, Junyu; Shen, Bairong] Sichuan Univ, West China Hosp, Frontiers Sci Ctr Dis Related Mol Network, Dept Urol, 37 Guoxue Alley, Chengdu 610212, Peoples R China; [Zong, Hui; Li, Jiakun; Wu, Erman; Wu, Rongrong; Lu, Junyu; Shen, Bairong] Sichuan Univ, West China Hosp, Inst Syst Genet, Frontiers Sci Ctr Dis Related Mol Network, 37 Guoxue Alley, Chengdu 610212, Peoples R China	Sichuan University; Sichuan University	Shen, BR (corresponding author), Sichuan Univ, West China Hosp, Frontiers Sci Ctr Dis Related Mol Network, Dept Urol, 37 Guoxue Alley, Chengdu 610212, Peoples R China.; Shen, BR (corresponding author), Sichuan Univ, West China Hosp, Inst Syst Genet, Frontiers Sci Ctr Dis Related Mol Network, 37 Guoxue Alley, Chengdu 610212, Peoples R China.	bairong.shen@scu.edu.cn	Zong, Hui/HNR-5427-2023	Zong, Hui/0000-0002-9142-5017	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bhinder B, 2021, CANCER DISCOV, V11, P900, DOI 10.1158/2159-8290.CD-21-0090; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Das A., 2022, PR MACH LEARN RES; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Giannos P, 2023, BMJ NEUROL OPEN, V5, DOI 10.1136/bmjno-2023-000451; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Han XX, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02234-x; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Jin Q, 2023, J Am Soc Nephrol; Komorowski M, 2023, INTENS CARE MED, V49, P844, DOI 10.1007/s00134-023-07096-7; Kovoor JG, 2023, BMJ-BRIT MED J, V381, DOI 10.1136/bmj.p1125; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee TC, 2023, Gastroenterology; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Munoz-Zuluaga C, 2023, CLIN CHEM, V69, P939, DOI 10.1093/clinchem/hvad058; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sarink MJ, 2023, Clin Microbiol Infect; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Shafiee A, 2023, Int J Surg; Wang XC, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03385-9; Wang YM, 2023, J Chin Med Assoc; Weng TL, 2023, J Chin Med Assoc; Yang Hong, 2023, Nature, DOI 10.1038/d41586-023-01026-9; Young JN, 2023, J Am Acad Dermatol; Zhang Y., 2020, Large-scale generative pre-training for conversational response generation, DOI [10.18653/v1/2020.acl-demos.30, DOI 10.18653/V1/2020.ACL-DEMOS.30]	29	3	3	23	23	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		1472-6920		BMC MED EDUC	BMC Med. Educ.	FEB 14	2024	24	1							143	10.1186/s12909-024-05125-7	http://dx.doi.org/10.1186/s12909-024-05125-7			9	Education & Educational Research; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Education & Educational Research	HW9K9	38355517	Green Published, gold, Green Submitted			2024-07-03	WOS:001162663700001
J	Grinin, LE; Grinin, AL; Grinin, IL				Grinin, Leonid E.; Grinin, Anton L.; Grinin, Igor L.			The Evolution of Artificial Intelligence: From Assistance to Super Mind of Artificial General Intelligence? Article 1. Information Technology and Artificial Intelligence: The Past, Present and Some Forecasts	SOCIAL EVOLUTION & HISTORY			English	Article						information and computer technologies; ICT; artificial intelligence; AI; large language models; LLM; cognitive science; self- managing systems; the Cybernetic Revolution; inforg; technological progress		The article is devoted to the history of the development of Information and Communication Technologies (ICT) and Artificial Intelligence (AI), their current and probable future achievements, and the problems (which have already arisen, but will become even more acute in the future) associated with the development of these technologies and their active introduction in society. The close connection between the development of AI and cognitive science, the penetration of ICT and AI into various fields, in particular the field of health care, is shown. A significant part of the article is devoted to the analysis of the concept of 'artificial intelligence', including the definition of generative AI. We analyze recent achievements in the field of Artificial Intelli gence, describe the basic models, in particular the Large Linguistic Models (LLM), and forecast the development of AI and the dangers that await us in the coming decades. We identify the forces behind the aspiration to create artificial intelligence, which is increasingly ap- proaching the capabilities of the so-called general/universal AI, and also suggest desirable measures to limit and channel the development of artificial intelligence. The authors emphasize that the threats and dangers of the development of ICT and AI are particularly aggravated by the monopolization of their development by the state, intelligence services, large corporations and those often referred to as globalists. The article forecasts the development of computers, ICT and AI in the coming decades, and also shows the changes in society that will be associated with them. The study consists of two articles. The first, presented below, pro- vides a brief historical overview and characterizes the current situa- tion in the field of ICT and AI, it also analyzes the concepts of artifi- cial intelligence, including generative AI, changes in the understand- ing of AI related to the emergence of the so-called large language models and related new types of AI programs (ChatGPT). The article discusses the serious problems and dangers associated with the rapid and uncontrolled development of artificial intelligence. The second article, to be published in the next issue of the journal, describes and comments on current assessments of breakthroughs in the field of AI, analyzes various forecasts, and the authors give their own assess- ments and forecasts of future developments. Particular attention is given to the problems and dangers associated with the rapid and un- controlled development of AI, the fact that achievements in the field of AI are becoming a powerful means of controlling the population, im- posing ideology and choice, influencing the results of elections, and a weapon for undermining security and geopolitical struggle.	[Grinin, Leonid E.] HSE Univ, Inst Oriental Studies, Russian Acad Sci, Moscow, Russia; [Grinin, Anton L.] Lomonosov Moscow State Univ, Moscow, Russia; [Grinin, Igor L.] Volgograd State Tech Univ, Volgograd, Russia	Russian Academy of Sciences; HSE University (National Research University Higher School of Economics); Lomonosov Moscow State University; Volgograd State Technical University	Grinin, LE (corresponding author), HSE Univ, Inst Oriental Studies, Russian Acad Sci, Moscow, Russia.				Russian Science Foundation [23-11-00160]	Russian Science Foundation(Russian Science Foundation (RSF))	The research was supported by the Russian Science Foundation (project No. 23-11-00160 'Modeling and forecasting the development of the BRICS countries in the 21st century in the context of global dynamics') .	[Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2023, Bombthrower September 18; [Anonymous], 1997, Solving the Frame Problem, a Mathematical Investigation of the Common Sense Law of Inertia; Apokin I. A., 1990, History of Computer Technology. From the Simplest Counting Devices to Complex Relay Systems; Bagraev N. T., 2015, 2 INT SEM BAS TECHN; Balabanov V. I., 2010, Nanotechnologies: Truth and Fiction; Barabash A, 2015, Hi-News.ru December 25; Barr A., 1981, HDB ARTIFICIAL INTEL, VI.; Belousov D., 2016, Challenge 2035, P17; Business World, 2023, Business World February 2; Campbell C, 2021, Time October 1; Coupeau N., 2023, Greek Reporter February 1; Crevier D., 1993, AI: The Tumultuous History of the Search for Artificial Intelligence, DOI DOI 10.1177/027046769401400414; Datta A, 2005, PHYS REV A, V72, DOI 10.1103/PhysRevA.72.042316; Drexler K., 1987, Engines of creation: the coming era of nanotechnology; Drexler K. E, 2013, Radical Abundance: How a Revolution in Nanotechnology will Change Civilization; Drexler K. E., 1992, Nano-Systems: Molecular Machinery, Manufacturing, and Computation; Fuechsle M, 2012, NAT NANOTECHNOL, V7, P242, DOI [10.1038/NNANO.2012.21, 10.1038/nnano.2012.21]; Gates B., 2023, The Age of AI has Begun: Artificial Intelligence is as Revolutionary as Mobile Phones and the Internet; Glyantsev A., 2019, Smotrim.ru July 2; Glyantsev A., 2021, Smotrim.ru February 4; Grinin L., 2023, World Futures, V79, P536, DOI DOI 10.1080/02604027.2023.2204791; Grinin L., 2021, Kondratieff Waves: Processes, Cycles, Triggers, and Technological Paradigms, P95; Grinin L. E., Kondratiev waves: Technological and Economic Aspects, P187; Grinin L. E., 2021, Kondratiev waves: Technological and Economic Aspects, P200; Grinin L. E., 2021, Kondratiev waves: Technological and Economic Aspects, P171; Grinin L. E., From Choppers to Nanorobots. The World is on the Way to the Epoch of Self-Regulating Systems; Grinin L. E., 2021, Obshchestvo i ekonomika, V2, P18, DOI [10.31857/S020736760013634-6, DOI 10.31857/S020736760013634-6]; Grinin L. E., 2015, Istoricheskaya psikhologiya i sotsiologiya istorii, V8, P172; Gutter R. S., 1981, From the Abacus to the Computer; Harrari Noah, FINANCIAL TIMES; Khel I, 2015, HiNews.ru March 8; Kish LB, 2002, PHYS LETT A, V305, P144, DOI 10.1016/S0375-9601(02)01365-8; Kornev A, 2017, C-News June 15; McCarthy J, 2000, Concepts of Logical AI; McCarthy J, 1990, Artificial Intelligence, Logic and Formalizing Common Sense; McCarthy J., 2007, WHAT IS ARTIFICIAL INTELLIGENCE?; MITCHELL T, 1989, ANNU REV COMPUT SCI, V4, P417; Moore S. K., 2021, IEEE Spectrum; Muraya O., 2022, Russian Application will Determine Burnout by Heart Rhythm; Proydakov E., 2016, Challenge 2035, P114; Romanov R. V., 2012, PoaoB P. B. Kaccieckie koeii peei poe ickccBeoo ieeka (iococki acek). Owioco0- ckue ayku. 3. C. 241-247, V3, P241; Shumikhin S., 2021, Habr April 2; Stavitsky A., 2021, Lenta.ru October 14; Thakur CS, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00891; The White House, 2022, What is the Blueprint for an AI Bill of Rights?; Thomason R., 2003, The Stanford Encyclopedia of Philosophy; Tsvetkov V. Ya., 2017, Mezhdunarodnyy zhurnal prikladnykh i fundamental'nykh issledovaniy, V1-2, P370; UNESCO, 2021, Recommendation on the Ethics of Artificial Intelligence; VCUresearch, 2023, YouTube; Veldhorst M, 2015, NATURE, V526, P410, DOI 10.1038/nature15263; Wagner K, 2023, The Nation July 3; Yu Sandomirskaya, 2021, Kommersant Nauka November 30; Zgurovsky M. Z., 2013, Fundamentals of Computational Intelligence; Zhang N., 2022, arXiv	55	0	0	0	0	UCHITEL PUBLISHING HOUSE	VOLGOGRAD	UL KIROVA 143, VOLGOGRAD, 400079, RUSSIA	1681-4363			SOC EVOL HIST	Soc. Evol. Hist.	MAR	2024	23	1					156	183		10.30884/seh/2024.01.07	http://dx.doi.org/10.30884/seh/2024.01.07			28	Social Issues	Emerging Sources Citation Index (ESCI)	Social Issues	TX1S2					2024-07-03	WOS:001244472200007
J	Kretschmer, M; Margoni, T; Oruç, P				Kretschmer, Martin; Margoni, Thomas; Oruc, Pinar			Copyright Law and the Lifecycle of Machine Learning Models	IIC-INTERNATIONAL REVIEW OF INTELLECTUAL PROPERTY AND COMPETITION LAW			English	Article						Copyright; Artificial intelligence; Text mining; Data mining; EU; Digital single market	TEXT	Machine learning, a subfield of artificial intelligence (AI), relies on large corpora of data as input for learning algorithms, resulting in trained models that can perform a variety of tasks. While data or information are not subject matter within copyright law, almost all materials used to construct corpora for machine learning are protected by copyright law: texts, images, videos, and so on. There are global policy moves to address the copyright implications of machine learning, in particular in the context of so-called "foundation models" that underpin generative AI. This paper takes a step back, exploring empirically three technological settings through detailed case studies. We set out the established industry methodology of a lifecycle of AI (collecting data, organising data, model training, model operation) to arrive at descriptions suitable for legal analysis. This will allow an assessment of the challenges for a harmonisation of rights, exceptions and disclosure under EU copyright law. The three case studies are:Machine learning for scientific purposes, in the context of a study of regional short-term letting markets;Natural Language Processing (NLP), in the context of large language models;Computer vision, in the context of content moderation of images.We find that the nature and quality of data corpora at the input stage is central to the lifecycle of machine learning. Because of the uncertain legal status of data collection and processing, combined with the competitive advantage gained by firms not disclosing technological advances, the inputs of the models deployed are often unknown. Moreover, the "lawful access" requirement of the EU exception for text and data mining may turn the exception into a decision by rightholders to allow machine learning in the context of their decision to allow access. We assess policy interventions at EU level, seeking to clarify the legal status of input data via copyright exceptions, opt-outs or the forced disclosure of copyright materials. We find that the likely result is a fully copyright-licensed environment of machine learning that may have problematic effects for the structure of industry, innovation and scientific research.	[Kretschmer, Martin] Univ Glasgow, Sch Law, Intellectual Property Law, Glasgow, Scotland; [Kretschmer, Martin] CREATe UK Copyright & Creat Econ Ctr, Glasgow, Scotland; [Margoni, Thomas] Univ Leuven KU Leuven, Ctr IT & IP Law CiTiP, Intellectual Property Law, Fac Law & Criminol, Leuven, Belgium; [Oruc, Pinar] Univ Manchester, Commercial Law, Manchester, England	University of Glasgow; KU Leuven; University of Manchester	Kretschmer, M (corresponding author), Univ Glasgow, Sch Law, Intellectual Property Law, Glasgow, Scotland.; Kretschmer, M (corresponding author), CREATe UK Copyright & Creat Econ Ctr, Glasgow, Scotland.	martin.kretschmer@glasgow.ac.uk; thomas.margoni@kuleuven.be; pinar.oruc@manchester.ac.uk		Oruc, Pinar/0000-0002-1462-7846; Margoni, Thomas/0000-0002-8551-1154	European Union [870626870626]; Urban Big Data Centre [ES/L011921/1]; CREATe, University of Glasgow	European Union(European Union (EU)); Urban Big Data Centre; CREATe, University of Glasgow	The research was funded by the European Union's Horizon 2020 research and innovation programme under grant agreement No. 870626870626 (reCreating Europe: Rethinking digital copyright law for aculturally diverse, accessible, creative Europe). Case study 1 was developed with ESRC support for the Urban Big Data Centre (ES/L011921/1). Pinar Oruc prepared a first draft of the case studies as a postdoctoral researcher at CREATe, University of Glasgow.	AirBnB, 2023, TERMS SERV EUR US; [Anonymous], 2023, FINANC TIMES; Arnold Taylor, 2019, Journal of Cultural Analytics, V4, P11045, DOI DOI 10.22148/16.043; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Boeing G, 2017, J PLAN EDUC RES, V37, P457, DOI 10.1177/0739456X16664789; Brunstein D, 2023, USING MACHINE LEARNI, DOI [10.2139/ssrn.4407202, DOI 10.2139/SSRN.4407202]; Buonocore T., 2019, MAN IS DOCTOR WOMAN; Burrow S, 2021, 20212 CREATE, DOI [10.5281/zenodo.4635759, DOI 10.5281/ZENODO.4635759]; Cambridge Consultants, 2019, US AI ONL CONT MOD, P51; Campbell, 2019, PRIVACY DATA PROTECT, V20; Chalkidis I, 2019, ARTIF INTELL LAW, V27, P171, DOI 10.1007/s10506-018-9238-9; Chmielewski Dawn, 2023, REUTERS; CMA, 2023, AI FDN MOD; Cottman BH, 2020, CONVERTING PDF GUTEN; Couldry N, 2019, TELEV NEW MEDIA, V20, P336, DOI 10.1177/1527476418796632; Craig Carys., 2017, Am U Intl L Rev, V33, P1; CSPLA CNC and HADOPI, 2020, MISS REP MOR EFF COP; de Castilho Eckart, 2018, LREC 2018; Ducato R, 2019, IIC-INT REV INTELL P, V50, P649, DOI 10.1007/s40319-019-00833-w; Eben M, 2023, 20238 CREATE, DOI [10.5281/zenodo.8319662, DOI 10.5281/ZENODO.8319662]; Elgammal A., 2017, ARXIV; Elgendy M., 2020, Deep Learning for Vision Systems, V1st; Emanuilov I, 2023, 2023 EPIP C; EUIPO, 2020, AUT CONT REC DISC PA; Flynn S., 2020, EIPR, V42, P393; Gatys L. A, 2015, Journal of Vision, DOI DOI 10.1167/16.12.326; Geiger C, 2018, The Exception for Text and Data Mining (TDM) in the Proposed Directive on Copyright in the Digital Single Market-Legal Aspects, IN-DEPTH ANALYSIS For the JURI committee; Geiger C, 2018, IIC-INT REV INTELL P, V49, P814, DOI 10.1007/s40319-018-0722-2; Gold Zachary., 2018, Washington Journal of Law, Technology Arts, V13, P275; Guadamuz A, 2014, QUEEN MARY J INTELLE, V4, P3, DOI 10.4337/qmjip.2014.01.01; Guerin J, 2018, 8 INT C COMP SCI ENG, DOI [10.48550/arXiv.1707.01700, DOI 10.48550/ARXIV.1707.01700]; Handke C, 2021, MANAG DECIS ECON, V42, P1999, DOI 10.1002/mde.3354; Hillen J, 2019, BRIT FOOD J, V121, P3350, DOI 10.1108/BFJ-02-2019-0081; Hirschey J., 2014, BERKELEY TECHNOL LAW, V29, P906; Ho H.L., 2015, STANFORD ENCY PHILOS; Hugenholtz PB., 2016, CONCISE COPYRIGHT LA; Hughes A, 2023, BBC SCI FOCUS; Jennings F, 2009, J INTELLET PROP LAW, V4, P120, DOI 10.1093/jiplp/jpn232; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kalehbasti PR, 2021, LECT NOTES COMPUT SC, V12844, P173, DOI 10.1007/978-3-030-84060-0_11; Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223; Kavlakoglu E., 2020, NLP vs. NLU vs. NLG: the differences between three natural language processing concepts; Keller, 2023, GENERATIVE AI COPYRI; Kretschmer M, 2023, CEPR DISCUSSION PAPE; Kretschmer M, 2011, INTELLECTUAL PROPERT, DOI [10.2139/ssrn.2710611, DOI 10.2139/SSRN.2710611]; Kumar S, 2019, MULTICLASS IMAGE CLA; Levendowski A, 2018, WASH LAW REV, V93, P579; Lindauer M., 2022, ARXIV; Lunden I, 2017, AIRBNB EYES EXPANSIO; Margoni T, 2023, COMPUTERRECHT TIJDSC, V3/2023/116, P202; Margoni T, 2022, KLUWER COPYRIGHT BLO; Margoni Thomas, 2022, GRUR International, V71, P685, DOI [10.1093/grurint/ikac054, DOI 10.1093/GRURINT/IKAC054]; Massimino B, 2016, J BUS LOGIST, V37, P34, DOI 10.1111/jbl.12120; Miller AI, 2019, ARTIST IN THE MACHINE: THE WORLD OF AI-POWERED CREATIVITY, DOI 10.1080/09540121.2019.1668533; Munzert S, 2015, AUTOMATED DATA COLLECTION WITH R: A PRACTICAL GUIDE TO WEB SCRAPING AND TEXT MINING, P1; Nayak Pandu, 2019, Understanding searches better than ever before; OpenAI, 2018, IMPROVING LANGUAGE U; Otero BG., 2021, GRUR INT, V70, P1043, DOI 10.1093/grurint/ikab077; Peukert C, 2024, RES POLICY, V53, DOI 10.1016/j.respol.2023.104918; Przybyla P, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw145; Quintais JP, 2023, Generative AI, copyright and the AI Act; Reisner A., 2023, Atlantic; Rosati E, 2018, J INTELLET PROP LAW, V13, P429, DOI 10.1093/jiplp/jpy063; Sag M, 2019, J COPYRIGHT SOC USA, V66, P291; Sartor G, 2020, IMPACT ALGORITHMS ON; Scassa T, 2019, ONLINE INFORM REV, V43, P986, DOI 10.1108/OIR-02-2018-0053; Schaul K., 2023, WASH POST; Schirru L, 2023, KLUWER COPYRIGHT BLO; Seawright J, 2008, POLIT RES QUART, V61, P294, DOI 10.1177/1065912907313077; Seifert, 2017, TRANSPARENT DATA MIN; Senftleben M, 2023, IIC-INT REV INTELL P, V54, P1535, DOI 10.1007/s40319-023-01399-4; Soper T, 2020, OPENAI SHOULD BE REN; Synodinou T, 2019, JIPITEC, V10, P20; Tan T, 2020, EVOLUTION LANGUAGE M; Ueno T, 2021, GRUR Int, V70, P145, DOI DOI 10.1093/GRURINT/IKAA184; Vaswani A, 2017, ADV NEUR IN, V30; Zhang H., 2023, SN Computer Science, V4, P337	77	1	1	14	14	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	0018-9855	2195-0237		IIC-INT REV INTELL P	Int. Rev. Intellect. Prop. Compet. Law	JAN	2024	55	1			SI		110	138		10.1007/s40319-023-01419-3	http://dx.doi.org/10.1007/s40319-023-01419-3		FEB 2024	29	Law	Emerging Sources Citation Index (ESCI)	Government & Law	JT9V7		hybrid			2024-07-03	WOS:001155789200001
J	Ghosh, A; Jindal, NM; Gupta, VK; Bansal, E; Bajwa, NK; Sett, A				Ghosh, Abhra; Jindal, Nandita Maini; Gupta, Vikram K.; Bansal, Ekta; Bajwa, Navjot Kaur; Sett, Abhishek			Is ChatGPT's Knowledge and Interpretative Ability Comparable to First Professional MBBS (Bachelor of Medicine, Bachelor of Surgery) Students of India in Taking a Medical Biochemistry Examination?	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						ai-based education; medical biochemistry; medical education; artificial intelligence; chatgpt		IntroductionChatGPT is a large language model (LLM)-based chatbot that uses natural language processing to create humanlike conversational dialogue. It has created a significant impact on the entire global landscape, especially in sectors like finance and banking, e-commerce, education, legal, human resources (HR), and recruitment since its inception. There have been multiple ongoing controversies regarding the seamless integration of ChatGPT with the healthcare system because of its factual accuracy, lack of experience, lack of clarity, expertise, and above all, lack of empathy. Our study seeks to compare ChatGPT's knowledge and interpretative abilities with those of first-year medical students in India in the subject of medical biochemistry.Materials and methodsA total of 79 questions (40 multiple choice questions and 39 subjective questions) of medical biochemistry were set for Phase 1, block II term examination. Chat GPT was enrolled as the 101st student in the class. The questions were entered into ChatGPT's interface and responses were noted. The response time for the multiple-choice questions (MCQs) asked was also noted. The answers given by ChatGPT and 100 students of the class were checked by two subject experts, and marks were given according to the quality of answers. Marks obtained by the AI chatbot were compared with the marks obtained by the students.ResultsChatGPT scored 140 marks out of 200 and outperformed almost all the students and ranked fifth in the class. It scored very well in information-based MCQs (92%) and descriptive logical reasoning (80%), whereas performed poorly in descriptive clinical scenario-based questions (52%). In terms of time taken to respond to the MCQs, it took significantly more time to answer logical reasoning MCQs than simple information-based MCQs (3.10 +/- 0.882 sec vs. 2.02 +/- 0.477 sec, p<0.005).ConclusionsChatGPT was able to outperform almost all the students in the subject of medical biochemistry. If the ethical issues are dealt with efficiently, these LLMs have a huge potential to be used in teaching and learning methods of modern medicine by students successfully.	[Ghosh, Abhra; Jindal, Nandita Maini; Bansal, Ekta; Bajwa, Navjot Kaur] Dayanand Med Coll & Hosp, Biochem, Ludhiana, India; [Gupta, Vikram K.] Dayanand Med Coll, Community Med, Ludhiana, India; [Sett, Abhishek] Deloitte Consulting US India Pvt Ltd, Healthcare, Bangalore, India	Dayanand Medical College & Hospital; Dayanand Medical College & Hospital	Ghosh, A (corresponding author), Dayanand Med Coll & Hosp, Biochem, Ludhiana, India.	abhraghoshcmc@gmail.com		MAINI JINDAL, NANDITA/0000-0001-5878-693X				Ali K, 2024, EUR J DENT EDUC, V28, P206, DOI 10.1111/eje.12937; [Anonymous], 2023, What is ChatGPT: The History of ChatGPT-Open AI; [Anonymous], 2019, Competency Based Undergraduate Programme; [Anonymous], 2022, The jamovi project; [Anonymous], 2023, ChatGPT Statistics & Facts; Banerjee A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43314; Bonetti MA, 2024, ANN BIOMED ENG, V52, P745, DOI 10.1007/s10439-023-03318-7; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Friederichs H, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2220920; Ghosh A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37023; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Girimonte D., 2007, Intelligent Computing Everywhere, P235, DOI [DOI 10.1007/978-1-84628-943-9_12, 10.1007/978-1-84628-943-9_12]; Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Morreel S, 2023, MED TEACH, V45, P665, DOI 10.1080/0142159X.2023.2187684; Sharma GD, 2020, SUSTAIN FUTURES, V2, DOI 10.1016/j.sftr.2019.100004; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Talan T., 2023, Uluslararasi Yonetim Bilisim Sistemleri ve Bilgisayar Bilimleri Dergisi, V7, P33, DOI [DOI 10.33461/UYBISBBD.1244777, https://doi.org/10.33461/uybisbbd.1244777]; Vázquez-Cano E, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101380; Weng TL, 2023, J CHIN MED ASSOC, V86, P762, DOI 10.1097/JCMA.0000000000000946	22	2	2	11	16	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	OCT 19	2023	15	10							e47329	10.7759/cureus.47329	http://dx.doi.org/10.7759/cureus.47329			17	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Y0LM5	38021639	Green Published, gold			2024-07-03	WOS:001102270700017
C	Wilkins, J; Salamon, J; Fuentes, M; Bello, JP; Nieto, O			IEEE	Wilkins, Julia; Salamon, Justin; Fuentes, Magdalena; Bello, Juan Pablo; Nieto, Oriol			BRIDGING HIGH-QUALITY AUDIO AND VIDEO VIA LANGUAGE FOR SOUND EFFECTS RETRIEVAL FROM VISUAL QUERIES	2023 IEEE WORKSHOP ON APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, WASPAA	IEEE Workshop on Applications of Signal Processing to Audio and Acoustics		English	Proceedings Paper	IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)	OCT 22-25, 2023	New Paltz, NY	IEEE		Multimodal machine learning; cross-modal retrieval; audio-visual representation learning; data augmentation		Finding the right sound effects (SFX) to match moments in a video is a difficult and time-consuming task, and relies heavily on the quality and completeness of text metadata. Retrieving high-quality (HQ) SFX using a video frame directly as the query is an attractive alternative, removing the reliance on text metadata and providing a low barrier to entry for non-experts. Due to the lack of HQ audiovisual training data, previous work on audio-visual retrieval relies on YouTube ("in-the-wild") videos of varied quality for training, where the audio is often noisy and the video of amateur quality. As such it is unclear whether these systems would generalize to the task of matching HQ audio to production-quality video. To address this, we propose a multimodal framework for recommending HQ SFX given a video frame by (1) leveraging large language models and foundational vision-language models to bridge HQ audio and video to create audio-visual pairs, resulting in a highly scalable automatic audio-visual data curation pipeline; and (2) using pre-trained audio and visual encoders to train a contrastive learning-based retrieval system. We show that our system, trained using our automatic data curation pipeline, significantly outperforms baselines trained on in-the-wild data on the task of HQ SFX retrieval for video. Furthermore, while the baselines fail to generalize to this task, our system generalizes well from clean to in-the-wild data, outperforming the baselines on a dataset of YouTube videos despite only being trained on the HQ audio-visual pairs. A user study confirms that people prefer SFX retrieved by our system over the baseline 67% of the time both for HQ and in-the-wild data. Finally, we present ablations to determine the impact of model and data pipeline design choices on downstream retrieval performance. Please visit our companion website to listen to and view our SFX retrieval results.	[Wilkins, Julia; Fuentes, Magdalena; Bello, Juan Pablo] NYU, Mus & Audio Res Lab, New York, NY 10003 USA; [Wilkins, Julia; Salamon, Justin; Nieto, Oriol] Adobe Res, San Francisco, CA 94107 USA	New York University; Adobe Systems Inc.	Wilkins, J (corresponding author), NYU, Mus & Audio Res Lab, New York, NY 10003 USA.; Wilkins, J (corresponding author), Adobe Res, San Francisco, CA 94107 USA.	jw3596@nyu.edu		Fuentes, Magdalena/0000-0003-4506-6639; Bello, Juan Pablo/0000-0001-8561-5204				Agostinelli A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.11325; Ament V. T, 2021, The Foley grail: The art of performing sound for film, games, and animation; [Anonymous], 2011, P 28 INT C MACH LEAR; Chen HL, 2020, INT CONF ACOUST SPEE, P721, DOI [10.1109/icassp40776.2020.9053174, 10.1109/ICASSP40776.2020.9053174]; Chen T, 2020, PR MACH LEARN RES, V119; De Gotzen A., 2013, P SOUND MUS COMP C S; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261; Grauman Kristen, 2022, CVPR; Guzhov A, 2022, INT CONF ACOUST SPEE, P976, DOI 10.1109/ICASSP43922.2022.9747631; Guzhov A, 2021, INT C PATT RECOG, P4933, DOI 10.1109/ICPR48806.2021.9413035; Hayes T, 2022, LECT NOTES COMPUT SC, V13668, P431, DOI 10.1007/978-3-031-20074-8_25; Hebbar R, 2023, Arxiv, DOI arXiv:2302.07315; Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002; Kong QQ, 2020, IEEE-ACM T AUDIO SPE, V28, P2880, DOI 10.1109/TASLP.2020.3030497; Krishnamurthy S, 2021, LECT NOTES COMPUT SC, V13018, P124, DOI 10.1007/978-3-030-90436-4_10; Lin D. C.-E., 2021, 5 NEURIPS WORKSH MAC; McKee D., 2023, P IEEE CVF C COMP VI, p14 784; Nagrani A, 2022, LECT NOTES COMPUT SC, V13674, P407, DOI 10.1007/978-3-031-19781-9_24; Prétet L, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533662; Radford A, 2021, PR MACH LEARN RES, V139; Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401; Suris D., 2022, P IEEE CVF C COMP VI, p10 564; Tian YP, 2018, LECT NOTES COMPUT SC, V11206, P252, DOI 10.1007/978-3-030-01216-8_16; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu HH, 2022, INT CONF ACOUST SPEE, P4563, DOI 10.1109/ICASSP43922.2022.9747669; Wu YS, 2022, Arxiv, DOI arXiv:2211.06687; Yong G, 2023, COMPUT-AIDED CIV INF, V38, P1536, DOI 10.1111/mice.12954; Zellers R, 2022, PROC CVPR IEEE, P16354, DOI 10.1109/CVPR52688.2022.01589; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	31	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1931-1168		979-8-3503-2372-6	IEEE WORK APPL SIG			2023										10.1109/WASPAA58266.2023.10248113	http://dx.doi.org/10.1109/WASPAA58266.2023.10248113			5	Acoustics; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Engineering	BV7YE		Green Submitted			2024-07-03	WOS:001073615200033
J	Sun, XJ; Zhang, K; Liu, Q; Bao, MK; Chen, YJ				Sun, Xinjie; Zhang, Kai; Liu, Qi; Bao, Meikai; Chen, Yanjiang			Harnessing domain insights: A prompt knowledge tuning method for aspect-based sentiment analysis	KNOWLEDGE-BASED SYSTEMS			English	Article						LLMs; Prompt tuning; Domain knowledge base; Co-occurrence gate; Hybrid prompt		Aspect -based sentiment analysis (ABSA) endeavours predict the sentiment polarity of specific aspects of a given review. Recently, prompt tuning has been widely explored and has achieved remarkable success in improving semantic comprehension in several NLP tasks. However, most existing methods consider semantic tuning for various tasks and overlook domain knowledge, such as common-sense background knowledge. This not only limits the model's ability to understand and apply domain knowledge but also often leads to the model's inability to fully utilise domain -specific information, resulting in poor semantic quality and inferior model performance. To bridge this gap, we conducted a systematic study of Prompt Tuning with Domain Knowledge (PTDK) for ABSA, which aimed to design efficient prompts that guide the model to learn the knowledge of specific aspects in ABSA. Specifically, we first fine-tune the Large Language Models (LLMs) using hard prompts, which enhance the ability to extract enriched domain insights from the knowledge base. Additionally, we employed a Co -occurrence Gate to meticulously filter and refine the domain knowledge. This mechanism enhances the domain representation capability of the prompt template by selecting the most similar parts that are independently generated from a vast amount of domain knowledge for each comment. Simultaneously, a emphhybrid prompt templatewas constructed. This template integrates hard prompts and trainable soft prompts to compensate for the lack of specificity in hard prompts and to facilitate the integration of specific masks in various domain vectors. This hybrid strategy further enhances our ability to utilise domain -specific knowledge when performing ABSA. Experimental results on three public datasets - Restaurant, Laptop, and Twitter - demonstrate that our method consistently outperforms the current state-of-the-art baselines in all cases. The accuracies were 88.63%, 82.65%, and 81.65%, respectively, and F1 -scores were 83.38%, 79.68%, and 80.36%, respectively. This translates into an average increase in accuracy of 0.97% and an enhancement in the F1 -score of 1.03%. These enhancements not only validate the efficacy of our approach but also have substantial practical implications for real -world scenarios that require sophisticated sentiment analysis, such as the evaluation of customer feedback on e -commerce platforms.	[Sun, Xinjie; Zhang, Kai; Liu, Qi; Bao, Meikai; Chen, Yanjiang] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei, Peoples R China; [Sun, Xinjie; Zhang, Kai; Liu, Qi; Bao, Meikai; Chen, Yanjiang] State Key Lab Cognit Intelligence, Hefei, Peoples R China; [Sun, Xinjie; Zhang, Kai; Liu, Qi; Bao, Meikai; Chen, Yanjiang] Anhui Prov Key Lab Big Data Anal & Applicat, Hefei, Peoples R China; [Sun, Xinjie] Liupanshui Normal Univ, Liupanshui, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Zhang, K (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei, Peoples R China.	xinjiesun@mail.ustc.edu.cn; kkzhang08@ustc.edu.cn; qiliuql@ustc.edu.cn; baomeikai@mail.ustc.edu.cn; yjchen@mail.ustc.edu.cn			National Education Examinations Authority [GJK2021009]	National Education Examinations Authority	This research was funded by grant from the National Education Examinations Authority (Grant No. GJK2021009) .	Abdulla Nabil A., 2017, Appl. Comput. Inform., V13, P147; Agarwal B, 2023, MULTIMED TOOLS APPL, V82, P8899, DOI 10.1007/s11042-022-12181-y; Anger Isabel, 2011, P 11 INT C KNOWL MAN, P1; Bollen J, 2011, J COMPUT SCI-NETH, V2, P1, DOI 10.1016/j.jocs.2010.12.007; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cenni D, 2017, 2017 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTED, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI); Chen F, 2019, NEUROCOMPUTING, V368, P51, DOI 10.1016/j.neucom.2019.08.054; Chen P, 2017, P 2017 C EMP METH NA, P452, DOI DOI 10.18653/V1/D17-1047; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong L, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P49; Garcia-Pablos A., 2015, SemEval-2015, P714; Gong Oubo, 2023, GitHub repository; Gu S., 2018, P 27 INT C COMP LING, P774; Gu TQ, 2023, KNOWL-BASED SYST, V259, DOI 10.1016/j.knosys.2022.110025; Han RY, 2019, J MATER CHEM A, V7, P6475, DOI 10.1039/c9ta00137a; Han X, 2022, AI OPEN, V3, P182, DOI 10.1016/j.aiopen.2022.11.003; Huang BX, 2018, LECT NOTES COMPUT SC, V10899, P197, DOI 10.1007/978-3-319-93372-6_22; Ilievski F, 2020, Arxiv, DOI arXiv:2006.06114; Jiang Long, 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, HLT'11, P151; Jiang T, 2022, Arxiv, DOI arXiv:2201.04337; Jin WQ, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103260; Karimi A, 2021, INT C PATT RECOG, P8797, DOI 10.1109/ICPR48806.2021.9412167; Kojima T, 2022, ADV NEUR IN; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li Bo, 2022, bert4torch; Li C., 2021, arXiv; Li CM, 2023, Arxiv, DOI arXiv:2312.16337; Li J, 2022, Int. J. Adv. Comput. Sci. Appl., V11; Li R., 2021, P 59 ANN M ASS COMP, P6319, DOI 10.18653/v1/2021.acl-long.494; Li SY, 2024, Arxiv, DOI arXiv:2307.10558; Li X, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107376; Li Y, 2023, COGN COMPUT, V15, P1973, DOI 10.1007/s12559-023-10164-1; Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643; Liang Bin, 2020, INPROCEEDINGS 28 INT, P150; Liu JH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3508; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Q., 2020, Knowl.-Based Syst., V195; Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901; Liu X, 2022, Arxiv, DOI arXiv:2205.06166; Liu Xiao, 2023, AI Open; Lu GJ, 2023, NEUROCOMPUTING, V534, P67, DOI 10.1016/j.neucom.2023.03.002; Ma DH, 2017, Arxiv, DOI arXiv:1709.00893; Ma FK, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P322; Mees-Buss J, 2022, ORGAN RES METHODS, V25, P405, DOI 10.1177/1094428120967716; Zhang M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3540; Rana R.K., 2020, Int. J. Recent Technol. Eng. (IJRTE), V8, P409; Rietzler A, 2019, Arxiv, DOI arXiv:1908.11860; Scaria K, 2023, Arxiv, DOI arXiv:2302.08624; Seydoux L, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17841-x; Shepherd DA, 2020, ENTREP THEORY PRACT, V44, P371, DOI 10.1177/1042258719845888; Song YW, 2019, Arxiv, DOI arXiv:1902.09314; Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380; Sun K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5679; Talmor A, 2019, Arxiv, DOI arXiv:1811.00937; Tang D., 2016, P 2016 C EMPIRICAL M, P214, DOI [DOI 10.18653/V1/D16-1021, 10.18653/v1/D16-1021]; Tang Duyu, 2016, arXiv; Tang Hao, 2020, P 58 ACL, P6578, DOI DOI 10.18653/V1/2020.ACL-MAIN.588; Tian H, 2020, Arxiv, DOI arXiv:2005.05635; Tian YH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2910; Titov Ivan, 2008, P 17 INT C WORLD WID, P111, DOI DOI 10.1145/1367497.1367513; Wan H, 2020, AAAI CONF ARTIF INTE, V34, P9122; Wang HC, 2024, Arxiv, DOI arXiv:2309.04174; Wang K, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3229; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang Y., 2016, P 2016 C EMPIRICAL M, P606, DOI 10.18653/v1/D16-1058; Wu HY, 2023, INFORM FUSION, V92, P289, DOI 10.1016/j.inffus.2022.12.004; Xing BW, 2019, Arxiv, DOI [arXiv:1905.07719, 10.48550/arXiv.1905.07719, DOI 10.48550/ARXIV.1905.07719]; Xu Hu, 2020, 28 INT C COMP LING; Yu SS, 2019, IEEE ACCESS, V7, P176600, DOI 10.1109/ACCESS.2019.2953990; Zeng BQ, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163389; Zhang C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4568; Zhang DH, 2021, Arxiv, DOI arXiv:2009.02835; Zhang K, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3599; Zhang M, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P9273; Zhao AP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107220; Zhu Zixiao, 2023, Neurocomputing	76	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0950-7051	1872-7409		KNOWL-BASED SYST	Knowledge-Based Syst.	AUG 15	2024	298								111975	10.1016/j.knosys.2024.111975	http://dx.doi.org/10.1016/j.knosys.2024.111975			17	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UJ7A8					2024-07-03	WOS:001247743600001
J	Cozzi, A; Pinker, K; Hidber, A; Zhang, TY; Bonomo, L; Lo Gullo, R; Christianson, B; Curti, M; Rizzo, S; Del Grande, F; Mann, RM; Schiaffino, S				Cozzi, Andrea; Pinker, Katja; Hidber, Andri; Zhang, Tianyu; Bonomo, Luca; Lo Gullo, Roberto; Christianson, Blake; Curti, Marco; Rizzo, Stefania; Del Grande, Filippo; Mann, Ritse M.; Schiaffino, Simone			BI-RADS Category Assignments by GPT-3.5, GPT-4, and Google Bard: A Multilanguage Study	RADIOLOGY			English	Article							INTEROBSERVER VARIABILITY; AGREEMENT; RELIABILITY	Background: The performance of publicly available large language models (LLMs) remains unclear for complex clinical tasks. Purpose: To evaluate the agreement between human readers and LLMs for Breast Imaging Reporting and Data System (BI-RADS) categories assigned based on breast imaging reports written in three languages and to assess the impact of discordant category assignments on clinical management. Materials and Methods: This retrospective study included reports for women who underwent MRI, mammography, and/or US breast cancer screening or diagnostic purposes at three referral centers. Reports with findings categorized as BI-RADS 1-5 and in Italian, English, or Dutch were collected between January 2000 and October 2023. Board -certified breast radiologists and LLMs GPT-3.5 and GPT-4 (OpenAI) and Bard, now called Gemini (Google), assigned BI-RADS categories using only the described by the original radiologists. Agreement between human readers and LLMs for BI-RADS categories was assessed using Gwet agreement coefficient (AC1 value). Frequencies were calculated for changes in BI-RADS category assignments that would clinical management (ie, BI-RADS 0 vs BI-RADS 1 or 2 vs BI-RADS 3 vs BI-RADS 4 or 5) and compared using the McNemar test. Results: Across 2400 reports, agreement between the original and reviewing radiologists was almost perfect (AC1 = 0.91), while agreement between the original radiologists and GPT-4, GPT-3.5, and Bard was moderate (AC1 = 0.52, 0.48, and 0.42, respectively). Across human readers and LLMs, differences were observed in the frequency of BI-RADS category upgrades or downgrades that result in changed clinical management (118 of 2400 [4.9%] for human readers, 611 of 2400 [25.5%] for Bard, 573 of 2400 for GPT-3.5, and 435 of 2400 [18.1%] for GPT-4; P < .001) and that would negatively impact clinical management (37 of 2400 [1.5%] for human readers, 435 of 2400 [18.1%] for Bard, 344 of 2400 [14.3%] for GPT-3.5, and 255 of 2400 [10.6%] for P < .001). Conclusion: LLMs achieved moderate agreement with human reader-assigned BI-RADS categories across reports written in three languages but also yielded a high percentage of discordant BI-RADS categories that would negatively impact clinical management.	[Cozzi, Andrea; Bonomo, Luca; Curti, Marco; Rizzo, Stefania; Del Grande, Filippo; Schiaffino, Simone] Ente Osped Cantonale, Imaging Inst Southern Switzerland IIMSI, ViaTesserete 46, CH-6900 Lugano, Switzerland; [Pinker, Katja; Lo Gullo, Roberto; Christianson, Blake] Mem Sloan Kettering Canc Ctr, Dept Radiol, Breast Imaging Serv, New York, NY USA; [Hidber, Andri; Rizzo, Stefania; Del Grande, Filippo; Schiaffino, Simone] Univ Svizzera italiana, Fac Biomed Sci, Lugano, Switzerland; [Zhang, Tianyu; Lo Gullo, Roberto; Mann, Ritse M.] Netherlands Canc Inst, Dept Radiol, Amsterdam, Netherlands; [Zhang, Tianyu; Mann, Ritse M.] Radboud Univ Nijmegen, Dept Diagnost Imaging, Med Ctr, NL-6500 HB Nijmegen, Netherlands; [Zhang, Tianyu] Maastricht Univ, GROW Res Inst Oncol & Reprod, Maastricht, Netherlands	Memorial Sloan Kettering Cancer Center; Universita della Svizzera Italiana; Netherlands Cancer Institute; Radboud University Nijmegen; Maastricht University	Cozzi, A (corresponding author), Ente Osped Cantonale, Imaging Inst Southern Switzerland IIMSI, ViaTesserete 46, CH-6900 Lugano, Switzerland.	andrea.cozzi@gmail.com	Cozzi, Andrea/C-5453-2019	Cozzi, Andrea/0000-0003-4922-7065; Zhang, Tianyu/0000-0001-9891-6874; PINKER-DOMENIG, Katja/0000-0002-2722-7331				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Aminololama-Shakeri S, 2019, J AM COLL RADIOL, V16, P709, DOI 10.1016/j.jacr.2018.10.016; Banerjee I, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103137; Barat M, 2023, CAN ASSOC RADIOL J, V74, P758, DOI 10.1177/08465371231170133; Bard Google, About Us; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Cao JJ, 2023, AM J ROENTGENOL, V221, P556, DOI 10.2214/AJR.23.29493; De Margerie-Mellon C, 2021, EUR RADIOL, V31, P5913, DOI 10.1007/s00330-020-07664-1; DOrsi C., 2018, ACR BI-RADS atlas, breast imaging reporting and data system; El Khoury M, 2015, EUR J RADIOL, V84, P71, DOI 10.1016/j.ejrad.2014.10.003; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Grimm LJ, 2015, AM J ROENTGENOL, V204, P1120, DOI 10.2214/AJR.14.13047; Gwet KL, 2016, EDUC PSYCHOL MEAS, V76, P609, DOI 10.1177/0013164415596420; Gwet KL, 2008, BRIT J MATH STAT PSY, V61, P29, DOI 10.1348/000711006X126600; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Huang HY, 2023, Arxiv, DOI arXiv:2305.07004; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Klein D, 2018, STATA J, V18, P871, DOI 10.1177/1536867X1801800408; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Kuling G, 2022, J IMAGING, V8, DOI 10.3390/jimaging8050131; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mallio CA, 2023, RADIOL MED, V128, P808, DOI 10.1007/s11547-023-01651-4; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; OpenAI, GPT-3.5; OpenAI, GPT 4; Patil NS, 2023, J AM COLL RADIOL, V20, P1010, DOI 10.1016/j.jacr.2023.07.010; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Salazar AJ, 2017, J AM COLL RADIOL, V14, P686, DOI 10.1016/j.jacr.2016.08.004; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Tan RSYC, 2023, J AM MED INFORM ASSN, V30, P1657, DOI 10.1093/jamia/ocad133; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zhang TY, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.101131	38	0	0	2	2	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	APR	2024	311	1							e232133	10.1148/radiol.232133	http://dx.doi.org/10.1148/radiol.232133			8	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	TD3P1	38687216				2024-07-03	WOS:001239286000016
J	Kim, DW; Park, JS; Sharma, K; Velazquez, A; Li, L; Ostrominski, JW; Tran, T; Perez, RHS; Shin, JH				Kim, Dong Wook; Park, Ji Seok; Sharma, Kavita; Velazquez, Amanda; Li, Lu; Ostrominski, John W.; Tran, Tram; Seitter Perez, Robert H.; Shin, Jeong-Hun			Qualitative evaluation of artificial intelligence-generated weight management diet plans	FRONTIERS IN NUTRITION			English	Article						AI; diet plan; weight management; ChatGPT; dietary intervention		Importance The transformative potential of artificial intelligence (AI), particularly via large language models, is increasingly being manifested in healthcare. Dietary interventions are foundational to weight management efforts, but whether AI techniques are presently capable of generating clinically applicable diet plans has not been evaluated.Objective Our study sought to evaluate the potential of personalized AI-generated weight-loss diet plans for clinical applications by employing a survey-based assessment conducted by experts in the fields of obesity medicine and clinical nutrition.Design, setting, and participants We utilized ChatGPT (4.0) to create weight-loss diet plans and selected two control diet plans from tertiary medical centers for comparison. Dietitians, physicians, and nurse practitioners specializing in obesity medicine or nutrition were invited to provide feedback on the AI-generated plans. Each plan was assessed blindly based on its effectiveness, balanced-ness, comprehensiveness, flexibility, and applicability. Personalized plans for hypothetical patients with specific health conditions were also evaluated.Main outcomes and measures The primary outcomes measured included the indistinguishability of the AI diet plan from human-created plans, and the potential of personalized AI-generated diet plans for real-world clinical applications.Results Of 95 participants, 67 completed the survey and were included in the final analysis. No significant differences were found among the three weight-loss diet plans in any evaluation category. Among the 14 experts who believed that they could identify the AI plan, only five did so correctly. In an evaluation involving 57 experts, the AI-generated personalized weight-loss diet plan was assessed, with scores above neutral for all evaluation variables. Several limitations, of the AI-generated plans were highlighted, including conflicting dietary considerations, lack of affordability, and insufficient specificity in recommendations, such as exact portion sizes. These limitations suggest that refining inputs could enhance the quality and applicability of AI-generated diet plans.Conclusion Despite certain limitations, our study highlights the potential of AI-generated diet plans for clinical applications. AI-generated dietary plans were frequently indistinguishable from diet plans widely used at major tertiary medical centers. Although further refinement and prospective studies are needed, these findings illustrate the potential of AI in advancing personalized weight-centric care.	[Kim, Dong Wook; Ostrominski, John W.; Tran, Tram] Brigham & Womens Hosp, Ctr Weight Management & Wellness, Div Endocrinol Diabet & Hypertens, Boston, MA 02115 USA; [Kim, Dong Wook; Sharma, Kavita; Li, Lu; Tran, Tram; Seitter Perez, Robert H.; Shin, Jeong-Hun] Boston Univ Chobanian, Dept Med, Sect Endocrinol Diabet Nutr & Weight Management, Boston, MA 02118 USA; [Kim, Dong Wook; Sharma, Kavita; Li, Lu; Tran, Tram; Seitter Perez, Robert H.; Shin, Jeong-Hun] Avedisian Sch Med, Boston, MA 02118 USA; [Park, Ji Seok] Cleveland Clin, Dept Gastroenterol Hepatol & Nutr, Cleveland Hts, OH USA; [Velazquez, Amanda] Cedars Sinai Med Ctr, Weight Management & Metab Hlth Ctr, Dept Med, Los Angeles, CA USA; [Ostrominski, John W.] Brigham & Womens Hosp, Div Cardiovasc Med, Boston, MA USA; [Ostrominski, John W.] Harvard Med Sch, Boston, MA USA; [Shin, Jeong-Hun] Hanyang Univ, Coll Med, Dept Internal Med, Seoul, South Korea	Harvard University; Brigham & Women's Hospital; Cleveland Clinic Foundation; Cedars Sinai Medical Center; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School; Hanyang University	Kim, DW (corresponding author), Brigham & Womens Hosp, Ctr Weight Management & Wellness, Div Endocrinol Diabet & Hypertens, Boston, MA 02115 USA.; Kim, DW; Shin, JH (corresponding author), Boston Univ Chobanian, Dept Med, Sect Endocrinol Diabet Nutr & Weight Management, Boston, MA 02118 USA.; Kim, DW; Shin, JH (corresponding author), Avedisian Sch Med, Boston, MA 02118 USA.; Shin, JH (corresponding author), Hanyang Univ, Coll Med, Dept Internal Med, Seoul, South Korea.	mdwook@gmail.com; cardio.hyapex@gmail.com		Velazquez, Amanda/0000-0002-7620-4443; Seitter Perez, Robert/0009-0006-1212-0407				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Asch D.A., 2023, NEJM Cat, V4, P1, DOI DOI 10.1056/CAT.23.0043; Guerreiro NM, 2023, T ASSOC COMPUT LING, V11, P1500, DOI 10.1162/tacl_a_00615; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hróbjartsson A, 2013, CAN MED ASSOC J, V185, pE201, DOI 10.1503/cmaj.120744; Johnson KB, 2021, CTS-CLIN TRANSL SCI, V14, P86, DOI 10.1111/cts.12884; Kaegi-Braun N, 2020, CLIN NUTR, V39, P3014, DOI 10.1016/j.clnu.2020.01.023; Kalla D., 2023, International Journal of Innovative Science and Research Technology, V8, P827; Keathley JR, 2022, CAN J DIET PRACT RES, V83, P75, DOI 10.3148/cjdpr-2021-033; Khalil M., 2023, LEARNING COLLABORATI, DOI [10.1007/978-3-031-34411-4_32, DOI 10.1007/978-3-031-34411-4_32]; Lambert K, 2023, J RENAL NUTR, V33, P208, DOI 10.1053/j.jrn.2022.06.005; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Noorbakhsh-Sabet N, 2019, AM J MED, V132, P795, DOI 10.1016/j.amjmed.2019.01.017; Open AI., 2022, Introducing chat GPT; Ordovas JM, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k2173; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Sag M., 2023, Forthcoming in the Houston Law Review; Salehi B, 2019, NUTRITION, V62, P201, DOI 10.1016/j.nut.2019.01.012; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Truche AS, 2022, NUTRIENTS, V14, DOI 10.3390/nu14020384; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744	24	0	0	6	6	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND	2296-861X			FRONT NUTR	Front. Nutr.	MAR 21	2024	11								1374834	10.3389/fnut.2024.1374834	http://dx.doi.org/10.3389/fnut.2024.1374834			6	Nutrition & Dietetics	Science Citation Index Expanded (SCI-EXPANDED)	Nutrition & Dietetics	MU5L8	38577160	Green Published, gold			2024-07-03	WOS:001196161200001
J	Redahan, M; Kelly, BD				Redahan, Maria; Kelly, Brendan D.			Artificial intelligence and mental capacity legislation: Opening Pandora's modem	INTERNATIONAL JOURNAL OF LAW AND PSYCHIATRY			English	Article						Advance directives; Advance care planning; Advance health care planning; Artificial intelligence; Capacity legislation; Human rights; Mental disorder	DIRECTIVES	People with impaired decision-making capacity enjoy the same rights to access technology as people with full capacity. Our paper looks at realising this right in the specific contexts of artificial intelligence (AI) and mental capacity legislation. Ireland's Assisted Decision-Making (Capacity) Act, 2015 commenced in April 2023 and refers to 'assistive technology' within its 'communication' criterion for capacity. We explore the potential benefits and risks of AI in assisting communication under this legislation and seek to identify principles or lessons which might be applicable in other jurisdictions. We focus especially on Ireland's provisions for advance healthcare directives because previous research demonstrates that common barriers to advance care planning include (i) lack of knowledge and skills, (ii) fear of starting conversations about advance care planning, and (iii) lack of time. We hypothesise that these barriers might be overcome, at least in part, by using generative AI which is already freely available worldwide. Bodies such as the United Nations have produced guidance about ethical use of AI and these guide our analysis. One of the ethical risks in the current context is that AI would reach beyond communication and start to influence the content of decisions, especially among people with impaired decision-making capacity. For example, when we asked one AI model to 'Make me an advance healthcare directive', its initial response did not explicitly suggest content for the directive, but it did suggest topics that might be included, which could be seen as setting an agenda. One possibility for circumventing this and other shortcomings, such as concerns around accuracy of information, is to look to foundational models of AI. With their capabilities to be trained and fine-tuned to downstream tasks, purpose-designed AI models could be adapted to provide education about capacity legislation, facilitate patient and staff interaction, and allow interactive updates by healthcare professionals. These measures could optimise the benefits of AI and minimise risks. Similar efforts have been made to use AI more responsibly in healthcare by training large language models to answer healthcare questions more safely and accurately. We highlight the need for open discussion about optimising the potential of AI while minimising risks in this population.	[Redahan, Maria] St Vincents Univ Hosp, Dept Microbiol, Elm Pk, Dublin 4, Ireland; [Redahan, Maria; Kelly, Brendan D.] Tallaght Univ Hosp, Trinity Coll Dublin, Trinity Ctr Hlth Sci, Dept Psychiat, Dublin 24, Ireland	University College Dublin; Saint Vincent's University Hospital; Trinity College Dublin	Redahan, M (corresponding author), St Vincents Univ Hosp, Dept Microbiol, Elm Pk, Dublin 4, Ireland.	redaham@tcd.ie		Kelly, Brendan/0000-0002-6113-1384				Arnfeldt CM, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271919; Blackwood DH, 2019, J CLIN NURS, V28, P4276, DOI 10.1111/jocn.15049; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Carr S, 2020, J MENT HEALTH, V29, P125, DOI 10.1080/09638237.2020.1714011; Crowley Dr Patrick, 2022, Med Leg J, V90, P129, DOI 10.1177/00258172221083444; Curtis C, 2022, Ir Med J, V115, P585; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; European Commission, 2018, The European Commission's High-Level Expert Group on Artificial Intelligence.; Gazarian PK, 2019, GERIATR NURS, V40, P174, DOI 10.1016/j.gerinurse.2018.09.011; General Medical Council, 2024, Good medical practice; Gergel T, 2021, LANCET PSYCHIAT, V8, P599, DOI 10.1016/S2215-0366(21)00115-2; Gooding P., 2024, Routledge handbook of mental health law, P645; Google Research, 2023, Med-PaLM; Kelly BD, 2017, IRISH J MED SCI, V186, P351, DOI 10.1007/s11845-016-1443-5; Kelly BD, 2006, SOC SCI MED, V63, P2118, DOI 10.1016/j.socscimed.2006.05.015; Lukes S., 2005, POWER RADICAL VIEW; Medical Council, 2024, Guide to professional conduct and ethics., V9th; Obama K, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2022-069557; OpenAI, 2022, US; OpenAI, 2023, What is ChatGPT; Poveda-Moral S, 2021, WORLDV EVID-BASED NU, V18, P254, DOI 10.1111/wvn.12530; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sudore RL, 2018, JAMA INTERN MED, V178, P1616, DOI 10.1001/jamainternmed.2018.4657; Thom K, 2015, INT J MENT HEALTH NU, V24, P554, DOI 10.1111/inm.12157; UK Department of Health and Social Care, 2021, A guide to good practice for digital and data-driven health technologies.; United Nations, 2018, United Nations Chronicle; United Nations, 2023, United Nations Chronicle; World Health Organization, 2023, Regulatory considerations on artificial intelligence for health; World Health Organization (WHO), 2021, Ethics and Governance of Artificial Intelligence for Health	31	0	0	0	0	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0160-2527	1873-6386		INT J LAW PSYCHIAT	Int. J. Law Psychiatr.	MAY-JUN	2024	94								101985	10.1016/j.ijlp.2024.101985	http://dx.doi.org/10.1016/j.ijlp.2024.101985			6	Law; Psychiatry	Social Science Citation Index (SSCI)	Government & Law; Psychiatry	QW8S8	38579525	hybrid			2024-07-03	WOS:001224004600001
J	Rahsepar, AA; Tavakoli, N; Kim, GHJ; Hassani, C; Abtin, F; Bedayat, A				Rahsepar, Amir Ali; Tavakoli, Neda; Kim, Grace Hyun J.; Hassani, Cameron; Abtin, Fereidoun; Bedayat, Arash			How AI Responds to Common Lung Cancer Questions: ChatGPT vs Google Bard	RADIOLOGY			English	Article								Background: The recent release of large language models (LLMs) for public use, such as ChatGPT and Google Bard, has opened up a multitude of potential benefits as well as challenges. Purpose: To evaluate and compare the accuracy and consistency of responses generated by publicly available ChatGPT-3.5 and Google Bard to non-expert questions related to lung cancer prevention, screening, and terminology commonly used in radiology reports based on the recommendation of Lung Imaging Reporting and Data System (Lung-RADS) v2022 from American College of Radiology and Fleischner society. Materials and Methods: Forty of the exact same questions were created and presented to ChatGPT-3.5 and Google Bard experimental version as well as Bing and Google search engines by three different authors of this paper. Each answer was reviewed by two radiologists for accuracy. Responses were scored as correct, partially correct, incorrect, or unanswered. Consistency was also evaluated among the answers. Here, consistency was defined as the agreement between the three answers provided by ChatGPT-3.5, Google Bard experimental version, Bing, and Google search engines regardless of whether the concept conveyed was correct or incorrect. The accuracy among different tools were evaluated using Stata. Results: ChatGPT-3.5 answered 120 questions with 85 (70.8%) correct, 14 (11.7%) partially correct, and 21 (17.5%) incorrect. Google Bard did not answer 23 (19.1%) questions. Among the 97 questions answered by Google Bard, 62 (51.7%) were correct, 11 (9.2%) were partially correct, and 24 (20%) were incorrect. Bing answered 120 questions with 74 ( 61.7%) correct, 13 (10.8%) partially correct, and 33 (27.5%) incorrect. Google search engine answered 120 questions with 66 (55%) correct, 27 (22.5%) partially correct, and 27 (22.5%) incorrect. The ChatGPT-3.5 is more likely to provide correct or partially answer than Google Bard, approximately by 1.5 folds (OR = 1.55, P = 0.004). ChatGPT-3.5 and Google search engine were more likely to be consistent than Google Bard by approximately 7 and 29 folds (OR = 6.65, P = 0.002 for ChatGPT and OR = 28.83, P = 0.002 for Google search engine, respectively). Conclusion: Although ChatGPT-3.5 had a higher accuracy in comparison with the other tools, neither ChatGPT nor Google Bard, Bing and Google search engines answered all questions correctly and with 100% consistency.	[Rahsepar, Amir Ali; Hassani, Cameron; Abtin, Fereidoun; Bedayat, Arash] UCLA, David Geffen Sch Med, Div Cardiothorac Imaging, Dept Radiol Sci, Los Angeles, CA USA; [Tavakoli, Neda] Georgia Inst Technol, Sch Computat Sci & Engn, Atlanta, GA USA; [Kim, Grace Hyun J.] UCLA, Dept Radiol Sci, Ctr Comp Vis & Imaging Biomarkers, David Geffen Sch Med, Los Angeles, CA USA; [Kim, Grace Hyun J.] UCLA, Dept Biostat, Fielding Sch Publ, Los Angeles, CA USA	University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA; University System of Georgia; Georgia Institute of Technology; University of California System; University of California Los Angeles; University of California Los Angeles Medical Center; David Geffen School of Medicine at UCLA; University of California System; University of California Los Angeles	Bedayat, A (corresponding author), UCLA, David Geffen Sch Med, Div Cardiothorac Imaging, Dept Radiol Sci, 10945 Le Conte Ave,Suite 3371, Los Angeles, CA 90095 USA.	abedayat@mednet.ucla.edu		/0000-0002-6228-4673; Hassani, Cameron/0000-0002-2831-5384; Kim, Hyun/0000-0003-1225-3489; Bedayat, Arash/0000-0001-8769-0224				American College of Radiology, 2022, LUNG CT SCREEN REP D; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Lu D, 2013, ANN ONCOL, V24, P3112, DOI 10.1093/annonc/mdt415; MacMahon H, 2017, RADIOLOGY, V284, P228, DOI 10.1148/radiol.2017161659; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Rohrbach A, 2019, Arxiv, DOI arXiv:1809.02156; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014; Xiao YJ, 2021, Arxiv, DOI [arXiv:2103.15025, DOI 10.48550/ARXIV.2103.15025, 10.48550/arXiv.2103.15025]	15	58	58	15	25	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	JUN	2023	307	5												288	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	L3SE8	37310252				2024-07-03	WOS:001022483100018
C	Eilam, T; Bello-Maldonado, PD; Bhattacharjee, B; Costa, C; Lee, EK; Tantawi, A			ACM	Eilam, Tamar; Bello-Maldonado, Pedro D.; Bhattacharjee, Bishwaranjan; Costa, Carlos; Lee, Eun K.; Tantawi, Asser			Towards a Methodology and Framework for AI Sustainability Metrics	PROCEEDINGS OF THE 2ND ACM WORKSHOP ON SUSTAINABLE COMPUTER SYSTEMS, HOTCARBON 2023			English	Proceedings Paper	2nd ACM Workshop on Sustainable Computer Systems (ACM HotCarbon)	JUL09, 2023	Boston Univ, Boston, MA	Assoc Comp Machinery	Boston Univ	green AI; foundation models; sustainable AI; sustainable computing		Recently, we are witnessing truly groundbreaking achievements using AI models, such as the much talked about generative large language models, the broader area of foundation models, and the wide range of applications with a tremendous potential to accelerate scientific discovery, and enhance productivity. AI models and their use are growing at a super-linear pace. Inference jobs are measured by the trillions, and model parameters by the billions. This scaling up comes with a tremendous environmental cost, associated with every aspect of models' life cycle: data preparation, pre-training, and post deployment re-training, inference, and, the embodied emission of the systems used to support the execution. There is an urgent need for the community to come together and conduct a meaningful conversation about the environmental cost of AI. To do that, we ought to develop an agreed upon set of metrics, methodology, and framework to quantify AI's sustainability cost in a holistic and complete fashion. In this paper, we propose unified AI Sustainability metrics that can help foster a sustainability mind-set and enable analysis, and strategy setting. To do that, we build on and extend the data center sustainability metrics, defined in [19], by introducing (for the first time to our knowledge) the concept of embodied product emission (EPC) to capture the creation cost of software assets, such as software platforms, models, and data-sets. We then use this new concept to expand the job sustainability cost metrics (JCS and ASC) offered in [19] to factor in the context of the execution of jobs, such as a platform as-a-service, or a model serving inference jobs. The result is applicable to any data center job, not just for AI, and contributes towards accuracy and completeness. We then show how to apply this approach to AI, with a particular focus on the entire life cycle, including all phases of the life cycle, as well as the provenance of models, where one model is used (distilled) to create another one. We demonstrate how the metric can be used to inform a more meaningful debate about AI strategies and cost. Te novelty of the approach is that it can be used to reason about strategies and trade-offs across the life cycle and 'supply-chain' of models.	[Eilam, Tamar; Bello-Maldonado, Pedro D.; Bhattacharjee, Bishwaranjan; Costa, Carlos; Lee, Eun K.; Tantawi, Asser] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA	International Business Machines (IBM)	Eilam, T (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.			Bello-Maldonado, Pedro/0000-0003-0691-5204; Tantawi, Asser/0000-0001-6598-8863; Eilam, Tamar/0000-0002-0912-0776; Bhattacharjee, Bishwaranjan/0009-0009-7097-4891				Agrawal A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC); [Anonymous], 2013, The Datacenter as a Computer: An Introduction to the Design of Warehouse-Scale Machines; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brooks DM, 2000, IEEE MICRO, V20, P26, DOI 10.1109/40.888701; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113; Castelvecchi Davide, 2019, Nature, DOI 10.1038/d41586-019-00505-2; Chauhan A, 2019, APPL THERM ENG, V146, P450, DOI 10.1016/j.applthermaleng.2018.10.010; Chien Andrew A., 2020, Beyond PUE: Flexible Datacenters Empowering the Cloud to Decarbonize; Cloud Native Computing Foundation, 2023, Kubernetes Efficient Power Level Exporter (Kepler); COS, 2023, IBM Cloud Object Storage; Dayarathna M, 2016, IEEE COMMUN SURV TUT, V18, P732, DOI 10.1109/COMST.2015.2481183; Desislavov R, 2023, SUSTAIN COMPUT-INFOR, V38, DOI 10.1016/j.suscom.2023.100857; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Eilam Tamar., 2021, P 22 INT MIDDLEWARE, P1; Environmental Protection Agency (EPA), 2023, Life Cycle Assessment (LCA); Gandhi Anshul, 2022, P 1 WORKSH SUST COMP; GeSI, 2023, ICT Sector Guidance Built on the GHG Protocol Product Life Cycle Accounting and Reporting Standard; Green Software Foundation, 2023, Software Carbon Intensity (SCI) specification project; GSF, 2023, Green Software Foundation; Gupta U, 2020, Arxiv, DOI [arXiv:2011.02839, DOI 10.48550/ARXIV.2011.02839, 10.48550/arXiv.2011.02839]; Henderson P, 2020, J MACH LEARN RES, V21; IKS, 2023, IBM Cloud Kubernetes Service; Jiang QY, 2020, 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2020), P459, DOI 10.1109/CCGrid49817.2020.00-47; Jouppi NP, 2023, Arxiv, DOI arXiv:2304.01433; Kanagasubaraja S., 2022, 2022 INT C ADV COMP, P1; Lacoste A, 2019, Arxiv, DOI [arXiv:1910.09700, 10.48550/arXiv.1910.09700]; Lambda, 2023, AWS Lambda; Zitnick CL, 2020, Arxiv, DOI arXiv:2010.09435; Lee EK, 2017, IEEE T CLOUD COMPUT, V5, P234, DOI 10.1109/TCC.2015.2474368; Lenherr N, 2021, SUSTAIN COMPUT-INFOR, V31, DOI 10.1016/j.suscom.2021.100580; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Libovicky J., 2019, arXiv; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mukherjee Dibyendu, 2020, International Journal of Advanced Trends in Computer Science and Engineering, V9, P5; NVIDIA Corporation, 2023, NVIDIA Data Center GPU Manager (DCGM); Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Puri Ruchir, 2021, arXiv; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Ross J, 2022, NAT MACH INTELL, V4, DOI 10.1038/s42256-022-00580-7; Rostirolla G., 2022, Renewable & Sustainable Energy Reviews, V155, DOI 10.1016/j.rser.2021.111787; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schwartz R, 2019, Arxiv, DOI arXiv:1907.10597; Stark H., 2022, arXiv, DOI 10.48550/arxiv.2202.05146; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Thrun S, 1998, LEARNING TO LEARN, P181; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; World Resources Institue & wbcsd, 2023, The GHG Protocol; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Xia WF, 2017, IEEE COMMUN SURV TUT, V19, P640, DOI 10.1109/COMST.2016.2626784; Zhang QX, 2021, J SYST ARCHITECT, V119, DOI 10.1016/j.sysarc.2021.102253	52	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0242-6				2023										10.1145/3604930.3605715	http://dx.doi.org/10.1145/3604930.3605715			7	Computer Science, Theory & Methods; Green & Sustainable Science & Technology	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Science & Technology - Other Topics	BW2ST		hybrid			2024-07-03	WOS:001124735600013
J	Zhang, YX; Qiu, ZQ; Stol, KJ; Zhu, WH; Zhu, JX; Tian, YC; Liu, H				Zhang, Yuxia; Qiu, Zhiqing; Stol, Klaas-Jan; Zhu, Wenhui; Zhu, Jiaxin; Tian, Yingchen; Liu, Hui			Automatic Commit Message Generation: A Critical Review and Directions for Future Work	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						Commit-based software development; open collaboration; commit message generation; benchmark		Commit messages are critical for code comprehension and software maintenance. Writing a high-quality message requires skill and effort. To support developers and reduce their effort on this task, several approaches have been proposed to automatically generate commit messages. Despite the promising performance reported, we have identified three significant and prevalent threats in these automated approaches: 1) the datasets used to train and evaluate these approaches contain a considerable amount of 'noise'; 2) current approaches only consider commits of a limited diff size; and 3) current approaches can only generate the subject of a commit message, not the message body. The first limitation may let the models 'learn' inappropriate messages in the training stage, and also lead to inflated performance results in their evaluation. The other two threats can considerably weaken the practical usability of these approaches. Further, with the rapid emergence of large language models (LLMs) that show superior performance in many software engineering tasks, it is worth asking: can LLMs address the challenge of long diffs and whole message generation? This article first reports the results of an empirical study to assess the impact of these three threats on the performance of the state-of-the-art auto generators of commit messages. We collected commit data of the Top 1,000 most-starred Java projects in GitHub and systematically removed noisy commits with bot-submitted and meaningless messages. We then compared the performance of four approaches representative of the state-of-the-art before and after the removal of noisy messages, or with different lengths of commit diffs. We also conducted a qualitative survey with developers to investigate their perspectives on simply generating message subjects. Finally, we evaluate the performance of two representative LLMs, namely UniXcoder and ChatGPT, in generating more practical commit messages. The results demonstrate that generating commit messages is of great practical value, considerable work is needed to mature the current state-of-the-art, and LLMs can be an avenue worth trying to address the current limitations. Our analyses provide insights for future work to achieve better performance in practice.	[Zhang, Yuxia; Qiu, Zhiqing; Zhu, Wenhui; Liu, Hui] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China; [Stol, Klaas-Jan] Univ Coll Cork, Lero, Sci Fdn Ireland Res Ctr Software, Cork T12 K8AF, Ireland; [Stol, Klaas-Jan] Univ Coll Cork, Sch Comp & IT, Cork T12 K8AF, Ireland; [Zhu, Jiaxin] Chinese Acad Sci, Inst Software, Beijing 100190, Peoples R China; [Zhu, Jiaxin] Univ Chinese Acad Sci, Beijing 100190, Peoples R China; [Tian, Yingchen] Tmall Technol Co, Hangzhou 3111000, Zhejiang, Peoples R China	Beijing Institute of Technology; University College Cork; University College Cork; Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Liu, H (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.	yuxiazh@bit.edu.cn; zhiqingqiu@bit.edu.cn; k.stol@ucc.ie; wenhuizhu@bit.edu.cn; zhujiaxin@otcaix.iscas.ac.cn; tianyc10@foxmail.com; liuhui08@bit.edu.cn	Stol, Klaas-Jan/I-6269-2013	Stol, Klaas-Jan/0000-0002-1038-5050; Liu, Hui/0000-0002-3267-6801	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Alizadeh Vahid, 2019, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Proceedings, P823, DOI 10.1109/ASE.2019.00081; [Anonymous], Commit example; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Banerjee S., 2005, P ACL WORKSH INTR EX, P65, DOI DOI 10.3115/1626355.1626389; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buse R.P., 2010, P 25 IEEEACM INT C A, P33, DOI DOI 10.1145/1858996.1859005; Chahal KK, 2018, IFIP ADV INF COMM TE, V525, P61, DOI 10.1007/978-3-319-92375-8_6; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dey T, 2020, IEEE WORK CONF MIN S, P209, DOI 10.1145/3379597.3387478; Dong JH, 2023, PROC INT CONF SOFTW, P794, DOI 10.1109/ICSE48619.2023.00075; Dong JH, 2022, PROC INT CONF SOFTW, P970, DOI 10.1145/3510003.3510069; Dyer R, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P422, DOI 10.1109/ICSE.2013.6606588; Erlenhov L, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P445, DOI 10.1145/3368089.3409680; Fan AEL, 2023, Arxiv, DOI arXiv:2310.03533; Farooq U., 2016, interactions, V23, P26, DOI DOI 10.1145/3001896; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Cortés-Coy LF, 2014, IEEE INT WORK C SO, P275, DOI 10.1109/SCAM.2014.14; Fritz CO, 2012, J EXP PSYCHOL GEN, V141, P30, DOI 10.1037/a0026092; Golzadeh M, 2020, P 2020 IEEE ACM 42 I, P6, DOI [10.1145/3387940.3391503, DOI 10.1145/3387940.3391503]; Golzadeh M, 2021, J SYST SOFTWARE, V175, DOI 10.1016/j.jss.2021.110911; Guo DY, 2022, Arxiv, DOI arXiv:2203.03850; Hoang T, 2020, PROC INT CONF SOFTW, P518, DOI 10.1145/3377811.3380361; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Huang Y, 2017, INT SYMP EMP SOFTWAR, P414, DOI 10.1109/ESEM.2017.56; Jiang SY, 2017, IEEE INT CONF AUTOM, P135, DOI 10.1109/ASE.2017.8115626; Jiang SY, 2017, INT C PROGRAM COMPRE, P320, DOI 10.1109/ICPC.2017.12; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Jiaxin Zhu, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P409, DOI 10.1109/MSR.2019.00068; Kim S, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P481, DOI 10.1145/1985793.1985859; Kitchenham BA, 2007, Guidelines for performing systematic literature reviews in software engineering", V45, P1051, DOI 10.1145/2372233.2372235; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Li JW, 2023, PROC INT CONF SOFTW, P806, DOI 10.1109/ICSE48619.2023.00076; Liang JT, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P170, DOI 10.1145/3540250.3549082; Lin B, 2023, Arxiv, DOI arXiv:2305.10785; Lin Chin-Yew, 2004, P 42 ANN M ASS COMPU, P605, DOI DOI 10.3115/1218955.1219032; LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115; Linares-Vásquez M, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 2, P709, DOI 10.1109/ICSE.2015.229; Liu SQ, 2020, Arxiv, DOI arXiv:1912.02972; Liu ZX, 2023, PROC INT CONF SOFTW, P17, DOI 10.1109/ICSE48619.2023.00014; Liu ZX, 2023, Arxiv, DOI arXiv:2302.03924; Liu ZX, 2018, IEEE INT CONF AUTOM, P373, DOI 10.1145/3238147.3238190; Loyola P., 2018, P 11 INT C NATURAL L, P119, DOI DOI 10.18653/V1; Loyola P, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P287, DOI 10.18653/v1/P17-2045; Manning C.D., 2008, Introduction to information retrieval; Mockus A., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, P263, DOI 10.1109/ICSE.2000.870417; Mockus Audris., 2014, Proceedings of the on Future of Software Engineering, P85; Nachar N, 2008, TUTOR QUANT METHODS, V4, P13, DOI 10.20982/tqmp.04.1.p013; Nassif M, 2017, PROC IEEE INT CONF S, P261, DOI 10.1109/ICSME.2017.64; Nie LY, 2021, NEUROCOMPUTING, V459, P97, DOI 10.1016/j.neucom.2021.05.039; Nikoo H, 2021, DEV Community; OpenAi, 2022, Chatgpt; Operator S, 2019, #491-url cleanup; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3248401; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qin Liu, 2019, 2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR), P299, DOI 10.1109/MSR.2019.00056; Roy D, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1105, DOI 10.1145/3468264.3468588; Seaman CB, 1999, IEEE T SOFTWARE ENG, V25, P557, DOI 10.1109/32.799955; Shen JF, 2016, P INT COMP SOFTW APP, P103, DOI 10.1109/COMPSAC.2016.162; Smith E, 2013, 2013 6TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING (CHASE), P89, DOI 10.1109/CHASE.2013.6614738; Storey MA, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P928, DOI 10.1145/2950290.2983989; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Tao W, 2022, EMPIR SOFTW ENG, V27, DOI 10.1007/s10664-022-10219-1; Tao W, 2021, PROC IEEE INT CONF S, P126, DOI 10.1109/ICSME52107.2021.00018; Tian YC, 2022, PROC INT CONF SOFTW, P2389, DOI 10.1145/3510003.3510205; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tu FF, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P307, DOI 10.1145/3236024.3236054; Wang HY, 2021, ACM T SOFTW ENG METH, V30, DOI 10.1145/3464689; Wang Y., 2021, arXiv; Wessel M, 2019, 2019 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON BOTS IN SOFTWARE ENGINEERING (BOTSE 2019), P38, DOI 10.1109/BotSE.2019.00018; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wu XX, 2021, IEEE T SOFTWARE ENG, V48, P2541, DOI 10.1109/TSE.2021.3063727; Wyrich M, 2021, 2021 IEEE/ACM THIRD INTERNATIONAL WORKSHOP ON BOTS IN SOFTWARE ENGINEERING (BOTSE 2021), P6, DOI 10.1109/BotSE52550.2021.00009; Wyrich M, 2019, 2019 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON BOTS IN SOFTWARE ENGINEERING (BOTSE 2019), P24, DOI 10.1109/BotSE.2019.00015; Xu BW, 2017, IEEE INT CONF AUTOM, P706, DOI 10.1109/ASE.2017.8115681; Xu SB, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3975; Zhang Y., 2023, Appendix to 'automatic commit message gener-ation: A critical review and directions for future work'; Zhang YX, 2020, PROC INT CONF SOFTW, P1196, DOI 10.1145/3377811.3380376; Zhu JM, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P415, DOI 10.1109/ICSE.2015.60	79	0	0	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	APR	2024	50	4					816	835		10.1109/TSE.2024.3364675	http://dx.doi.org/10.1109/TSE.2024.3364675			20	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OC2K3		hybrid			2024-07-03	WOS:001204993400015
J	Modi, S; Kasmiran, KA; Sharef, NM; Sharum, MY				Modi, Salisu; Kasmiran, Khairul Azhar; Sharef, Nurfadhlina Mohd; Sharum, Mohd Yunus			Extracting adverse drug events from clinical Notes: A systematic review of approaches used	JOURNAL OF BIOMEDICAL INFORMATICS			English	Review						Adverse drug events; Pipeline approach; Joint task learning; Multi -task learning; Named entity recognition; Relation extraction	RECORDS; INFORMATION	Background: An adverse drug event (ADE) is any unfavorable effect that occurs due to the use of a drug. Extracting ADEs from unstructured clinical notes is essential to biomedical text extraction research because it helps with pharmacovigilance and patient medication studies. Objective: From the considerable amount of clinical narrative text, natural language processing (NLP) researchers have developed methods for extracting ADEs and their related attributes. This work presents a systematic review of current methods. Methodology: Two biomedical databases have been searched from June 2022 until December 2023 for relevant publications regarding this review, namely the databases PubMed and Medline. Similarly, we searched the multidisciplinary databases IEEE Xplore, Scopus, ScienceDirect, and the ACL Anthology. We adopted the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 statement guidelines and recommendations for reporting systematic reviews in conducting this review. Initially, we obtained 5,537 articles from the search results from the various databases between 2015 and 2023. Based on predefined inclusion and exclusion criteria for article selection, 100 publications have undergone full -text review, of which we consider 82 for our analysis. Results: We determined the general pattern for extracting ADEs from clinical notes, with named entity recognition (NER) and relation extraction (RE) being the dual tasks considered. Researchers that tackled both NER and RE simultaneously have approached ADE extraction as a "pipeline extraction" problem (n = 22), as a "joint task extraction" problem (n = 7), and as a "multi -task learning" problem (n = 6), while others have tackled only NER (n = 27) or RE (n = 20). We further grouped the reviews based on the approaches for data extraction, namely rule-based (n = 8), machine learning (n = 11), deep learning (n = 32), comparison of two or more approaches (n = 11), hybrid (n = 12) and large language models (n = 8). The most used datasets are MADE 1.0, TAC 2017 and n2c2 2018. Conclusion: Extracting ADEs is crucial, especially for pharmacovigilance studies and patient medications. This survey showcases advances in ADE extraction research, approaches, datasets, and state -of -the -art performance in them. Challenges and future research directions are highlighted. We hope this review will guide researchers in gaining background knowledge and developing more innovative ways to address the challenges.	[Modi, Salisu; Kasmiran, Khairul Azhar; Sharef, Nurfadhlina Mohd; Sharum, Mohd Yunus] Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Serdang, Selangor, Malaysia; [Modi, Salisu] Sokoto State Univ, Dept Comp Sci, Sokoto, Nigeria	Universiti Putra Malaysia	Kasmiran, KA (corresponding author), Univ Putra Malaysia, Fac Comp Sci & Informat Technol, Serdang, Selangor, Malaysia.	gs63125@student.upm.edu.my; k_azhar@upm.edu.my; nurfadhlina@upm.edu.my; m_yunus@upm.edu.my		Modi, Salisu/0000-0002-7677-7698	Universiti Putra Malaysia; Ministry of Higher Education, Malaysia [FRGS/1/2023/ICT02/UPM/02/3]	Universiti Putra Malaysia; Ministry of Higher Education, Malaysia(Ministry of Education, Malaysia)	This research is supported by Universiti Putra Malaysia, and the Ministry of Higher Education, Malaysia under the Fundamental Research Grant Scheme (FRGS/1/2023/ICT02/UPM/02/3).	Akkasi A, 2021, J BIOMED INFORM, V119, DOI 10.1016/j.jbi.2021.103820; Alfattni G, 2021, JMIR MED INF, V9, DOI 10.2196/24678; Alimova I, 2020, J BIOMED INFORM, V103, DOI 10.1016/j.jbi.2020.103382; [Anonymous], 2018, Deep learning with Python, DOI DOI 10.1007/978-1-4842-2766-4; [Anonymous], 2018, Proc. Mach. Learn. Res.; Bagattini F, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-018-0717-4; Bailey C, 2016, BRIT J CLIN PHARMACO, V82, P17, DOI 10.1111/bcp.12944; Bampa Maria, 2019, 2019 International Conference on Data Mining Workshops (ICDMW). Proceedings, P925, DOI 10.1109/ICDMW.2019.00135; Bampa M., 2020, P LR 2020 WORK MULT, P1; Banerji A, 2020, J ALLER CL IMM-PRACT, V8, P1032, DOI 10.1016/j.jaip.2019.12.007; Bekoulis G, 2018, EXPERT SYST APPL, V114, P34, DOI 10.1016/j.eswa.2018.07.032; Belousov M., 2017, 10 TEXT AN C P; Chandra K., Research Rabbit; Chapman AB, 2019, DRUG SAFETY, V42, P147, DOI 10.1007/s40264-018-0763-y; Chen D., 2021, 2021 7 INT C COMP CO, P1705, DOI [10.1109/ICCC54389.2021.9674535, DOI 10.1109/ICCC54389.2021.9674535]; Chen L, 2020, J AM MED INFORM ASSN, V27, P56, DOI 10.1093/jamia/ocz141; Christopoulou F, 2020, J AM MED INFORM ASSN, V27, P39, DOI 10.1093/jamia/ocz101; Cocos A, 2017, 10 TEXT AN C P; Dai HJ, 2020, J AM MED INFORM ASSN, V27, P47, DOI 10.1093/jamia/ocz120; Dai XF, 2017, AER ADV ENG RES, V131, P79; Dandala B., 2017, 10 TEXT AN C P; Dandala B, 2019, DRUG SAFETY, V42, P135, DOI 10.1007/s40264-018-0764-x; Davazdahemami B, 2018, J AM MED INFORM ASSN, V25, P1311, DOI 10.1093/jamia/ocy097; Dey S, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2544-0; Dong LH, 2021, INT CONF MEAS, P518, DOI 10.1109/ICMTMA52658.2021.00119; Du JC, 2021, J AM MED INFORM ASSN, V28, P1393, DOI 10.1093/jamia/ocab014; Duan GD, 2021, FRONT NEUROROBOTICS, V15, DOI 10.3389/fnbot.2021.635492; El-allaly ED, 2022, J BIOMED INFORM, V125, DOI 10.1016/j.jbi.2021.103968; El-allaly ED, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102473; Fan YD, 2021, J AM MED INFORM ASSN, V28, P569, DOI 10.1093/jamia/ocaa218; Federer C, 2016, ASSAY DRUG DEV TECHN, V14, P357, DOI 10.1089/adt.2016.742; Feng CC, 2019, APPL CLIN INFORM, V10, P123, DOI 10.1055/s-0039-1677738; Florez E, 2019, 2019 INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING SYSTEMS (SPSS 2019), P149, DOI 10.1145/3364908.3365295; Fu SY, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103526; Gaspar F, 2022, JMIR RES PROTOC, V11, DOI 10.2196/40456; Gonzalez-Hernandez G, 2022, DATABASE-OXFORD, V2022, DOI 10.1093/database/baac071; Goswami R, 2019, IEEE INT C BIOINFORM, P1487, DOI 10.1109/BIBM47256.2019.8983249; Gu X., 2017, 10 TEXT AN C P; Gu Y, 2023, Arxiv, DOI arXiv:2307.06439; Han SF, 2022, J BIOMED INFORM, V127, DOI 10.1016/j.jbi.2021.103984; Henriksson A, 2015, J BIOMED INFORM, V57, P333, DOI 10.1016/j.jbi.2015.08.013; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Hiba Chanaa, 2023, Digital Technologies and Applications: Proceedings of ICDTA'23. Lecture Notes in Networks and Systems (668), P957, DOI 10.1007/978-3-031-29857-8_95; Iqbal E, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187121; Jagannatha A, 2019, DRUG SAFETY, V42, P99, DOI 10.1007/s40264-018-0762-z; Jain H, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04249-7; Jouffroy J, 2021, JMIR MED INF, V9, DOI 10.2196/17934; Ju MZ, 2020, J AM MED INFORM ASSN, V27, P22, DOI 10.1093/jamia/ocz075; Kaas-Hansen BS, 2022, BASIC CLIN PHARMACOL, V131, P282, DOI 10.1111/bcpt.13773; Karaoglan KM, 2022, APPL SOFT COMPUT, V118, DOI 10.1016/j.asoc.2022.108524; Karimi S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2719920; Kim Y, 2020, J AM MED INFORM ASSN, V27, P31, DOI 10.1093/jamia/ocz100; Lamy JB, 2021, ARTIF INTELL MED, V115, DOI 10.1016/j.artmed.2021.102074; Li F, 2018, JMIR MED INF, V6, P32, DOI 10.2196/12159; Li F, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1609-9; Li J, 2020, IEEE ACCESS, V8, P48812, DOI 10.1109/ACCESS.2020.2979452; Li YM, 2023, Arxiv, DOI [arXiv:2309.16150, 10.48550/arXiv.2309.16150, DOI 10.48550/ARXIV.2309.16150]; Liao W., 2022, Intell. Med., V6, P100077, DOI DOI 10.1016/J.IBMED.2022.100077; Liu Feifan, 2020, AMIA Annu Symp Proc, V2020, P756; Liu WL, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892647; Liu XY, 2021, COMPUT BIOL CHEM, V93, DOI 10.1016/j.compbiolchem.2021.107508; Lochmiller CR, 2021, QUAL REP, V26, P2029, DOI 10.46743/2160-3715/2021.5008; Ma XL, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031532; Mahendran Darshini, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P420; McMaster C, 2023, J BIOMED INFORM, V137, DOI 10.1016/j.jbi.2022.104265; Mellor L, 2021, What is PRISMA guideline & what's new in the 2020 guideline?; Miller Timothy, 2019, Proc Conf, V2019, P22, DOI 10.18653/v1/w19-1903; Mohammadi Yeganeh, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101246; Mohd Sharef N., 2016, J. Eng. Appl. Sci., V11, P408, DOI [10.36478/jeasci.2016.408.413, DOI 10.36478/JEASCI.2016.408.413]; Munkhdalai T, 2018, JMIR PUBLIC HLTH SUR, V4, P277, DOI 10.2196/publichealth.9361; Naderi A, 2017, 10 TEXT AN C P; Narayanan S., 2020, P 3 CLIN NAT LANG PR, P55, DOI DOI 10.18653/V1/2020.CLINICALNLP-1.6; Narayanan S, 2022, J BIOMED INFORM, V125, DOI 10.1016/j.jbi.2021.103960; National Institutes of Health, 2022, iCite; Negi Kajal, 2019, Informatics in Medicine Unlocked, V17, P35, DOI 10.1016/j.imu.2019.100190; Noor A, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9132477; Oleynik M, 2019, J AM MED INFORM ASSN, V26, P1247, DOI 10.1093/jamia/ocz149; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Personeni G, 2017, J BIOMED SEMANT, V8, DOI 10.1186/s13326-017-0137-x; Ramos SF, 2021, EXPERT OPIN DRUG SAF, V20, P1225, DOI 10.1080/14740338.2021.1924668; Rawat Bhanu Pratap Singh, 2020, AMIA Annu Symp Proc, V2020, P1041; Rebane J, 2020, ARTIF INTELL MED, V109, DOI 10.1016/j.artmed.2020.101942; Roberts K., 2017, 10 TEXT AN C P; Roller R., 2015, P BIONLP 15, P12, DOI [DOI 10.18653/V1/W15-3802, 10.18653/v1/W15-3802]; Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]; Salas M, 2022, PHARM MED, V36, P295, DOI 10.1007/s40290-022-00441-z; Santiso S, 2021, COMPUT METH PROG BIO, V199, DOI 10.1016/j.cmpb.2020.105891; Santiso S, 2019, IEEE J BIOMED HEALTH, V23, P2148, DOI 10.1109/JBHI.2018.2879744; Sanyal J, 2022, J BIOMED INFORM, V126, DOI 10.1016/j.jbi.2021.103969; Sarrouti M., 2020, 2019 Adv. Intell. Syst. Sust. Dev. (AI2SD), DOI [10.1007/978-3-030-36664-3, DOI 10.1007/978-3-030-36664-3]; Scholarcy Limited, Scholarcy; Shi Y, 2021, NEURAL NETWORKS, V134, P42, DOI 10.1016/j.neunet.2020.10.012; Siegersma KR, 2022, JMIR MED INF, V10, DOI 10.2196/31063; Silvestri S, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12125775; Suárez-Paniagua V, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103285; Sun K, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3533020; Sutphin C, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103552; Tafti AP, 2017, JMIR MED INF, V5, DOI 10.2196/medinform.9170; Tang YX, 2019, INT J MED INFORM, V128, P62, DOI 10.1016/j.ijmedinf.2019.04.017; Tao C, 2017, 10 TEXT AN C P; Tao C, 2019, STUD HEALTH TECHNOL, V264, P388, DOI 10.3233/SHTI190249; Tian Shi, 2021, ACM/IMS Transactions on Data Science, V2, DOI 10.1145/3419106; Tiftikci M, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3195-5; Tran Tung, 2021, ACM Trans Comput Healthc, V2, DOI 10.1145/3423209; Uzuner Ö, 2020, J AM MED INFORM ASSN, V27, P1, DOI 10.1093/jamia/ocz206; ValizadehAslani T, 2023, BRIEF BIOINFORM, V24, DOI 10.1093/bib/bbad226; Veena G., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P1278, DOI 10.1109/ICICICT46008.2019.8993274; Wang CS, 2019, J MED INTERNET RES, V21, DOI 10.2196/11016; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Warrer P, 2012, BRIT J CLIN PHARMACO, V73, P674, DOI 10.1111/j.1365-2125.2011.04153.x; Wasylewicz A, 2022, BRIT J CLIN PHARMACO, V88, P1235, DOI 10.1111/bcp.15068; Wei Q, 2020, J AM MED INFORM ASSN, V27, P13, DOI 10.1093/jamia/ocz063; Wunnava S., 2020, Find. Assoc. Comput. Linguist. EMNLP, V2020, P3414, DOI [10.18653/v1/2020.findings-emnlp.306, DOI 10.18653/V1/2020.FINDINGS-EMNLP.306]; Wunnava S, 2019, DRUG SAFETY, V42, P113, DOI 10.1007/s40264-018-0765-9; Xu J., 2017, 10 TEXT AN C P; Yadav S, 2022, IEEE ACM T COMPUT BI, V19, P1105, DOI 10.1109/TCBB.2020.3020016; Yang X, 2020, J AM MED INFORM ASSN, V27, P1935, DOI 10.1093/jamia/ocaa189; Yang X, 2020, J AM MED INFORM ASSN, V27, P65, DOI 10.1093/jamia/ocz144; Yang X, 2019, DRUG SAFETY, V42, P123, DOI 10.1007/s40264-018-0761-0; Zhan C, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101839; Zhang SA, 2018, IEEE INT C BIOINFORM, P2324, DOI 10.1109/BIBM.2018.8621286; Zhang TX, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3053-5; Zhang YJ, 2018, BIOINFORMATICS, V34, P828, DOI 10.1093/bioinformatics/btx659; Zhao J., 2018, 13 INT C COMP SCI ED, P197, DOI [10.1109/ICCSE.2018.8468701, DOI 10.1109/ICCSE.2018.8468701]; Zhe Xu, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P934, DOI 10.1109/IAEAC50856.2021.9390651	125	0	0	4	4	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	MAR	2024	151								104603	10.1016/j.jbi.2024.104603	http://dx.doi.org/10.1016/j.jbi.2024.104603		FEB 2024	13	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	NK2S1	38331081				2024-07-03	WOS:001200288000001
J	Hammond, KM; Lucas, P; Hassouna, A; Brown, S				Hammond, Kay M.; Lucas, Patricia; Hassouna, Amira; Brown, Stephen			A Wolf in Sheep's Clothing? Critical Discourse Analysis of Five Online Automated Paraphrasing Sites	JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE			English	Article						Automated paraphrasing tools; generative AI; academic integrity; critical discourse analysis; higher education	L1	Research on academic integrity used to focus more on student character and behaviour. Now this research includes wider viewing of this issue as a current teaching and learning challenge which requires pedagogical intervention. It is now the responsibility of staff and institutions to treat the creation of a learning environment supporting academic integrity as a teaching and learning priority. Plagiarism by simply copying other people's work is a well-known misconduct which undermines academic integrity; moreover, technological developments have evolved plagiarism to include the generation and copying of computer-generated text. Automated paraphrasing tool (APT) websites have become increasingly common, offering students machine-generated rephrased text that students input from their own or others' writing. These developments present a creeping erosion of academic integrity under the guise of legitimate academic assistance. This also has implications for arrival of large language model (LLM) generative AI tools. In accessing these sites, students must discern what is a legitimate use of the tool and what may constitute breaching academic integrity. This study critically analysed the text from five online paraphrasing websites to examine the discourses used to legitimise and encourage APT use in both appropriate and inappropriate ways. We conceptualised these competing discourses using Sheep and Wolf metaphors. In addition, we offer a metaphor of the Educator as a Shepherd to become aware of APT website claims and assist students to develop critical language awareness when exposed to these sites. Educators can assist students with this through knowledge of how these sites use language to entice users to circumvent learning. Practitioner Notes1. Paraphrasing skills are a key element of competent academic thinking and writing.2. Technological developments have increasingly enabled students to access online Automated Paraphrasing Tool (ATP) websites to assist with paraphrasing content.3. There is a lack of clarity around what constitutes acceptable use of APTs and what breaches academic integrity.4. Through a critical discourse analysis, we show how APT websites use language to use the tool in both appropriate and inappropriate ways.5. Critical awareness of language use on APT websites will assist educators to teach students to avoid inadvertently breaching academic integrity if using these tools.	[Hammond, Kay M.; Lucas, Patricia; Hassouna, Amira; Brown, Stephen] Auckland Univ Technol, Auckland, New Zealand	Auckland University of Technology	Hammond, KM (corresponding author), Auckland Univ Technol, Auckland, New Zealand.	kay.hammond@aut.ac.nz; patricia.lucas@aut.ac.nz; amira.hassouna@aut.ac.nz; stephen.brown@aut.ac.nz						[Anonymous], CAMBRIDGE DICT, DOI [10.1186/1741-7007-10-60, DOI 10.1186/1741-7007-10-60]; [Anonymous], 2022, Merriam-Webster dictionary; Bailey J., 2018, Plagiarism TodayMarch 8; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Braun V., 2013, SUCCESSFUL QUALITATI, DOI [10.1177/0959353515614115, DOI 10.1177/0959353515614115]; Bretag T, 2019, STUD HIGH EDUC, V44, P1837, DOI 10.1080/03075079.2018.1462788; Broom C., 2015, Citizenship, Social, and Economics Education, V14, P79, DOI DOI 10.1177/2047173415597142; Clarke A., 2005, SITUATIONAL ANAL; De Maoi C., 2022, Journal of College and Character, V23, P6, DOI [DOI 10.1080/2194587X.2021.201792, 10.1080/2194587X.2021.2017972, DOI 10.1080/2194587X.2021.2017972]; Eaton Sarah Elaine, 2022, Academic Integrity in Canada: An Enduring and Essential Challenge; Edley N, 2001, FEM PSYCHOL, V11, P439, DOI 10.1177/0959353501011004002; Fairclough N., 1995, CRITICAL DISCOURSE A; FILLENBAUM S, 1970, PSYCHON SCI, V18, P67, DOI 10.3758/BF03335699; Foltynek Tomas, 2020, Sustainable Digital Communities. 15th International Conference, iConference 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12051), P816, DOI 10.1007/978-3-030-43687-2_68; Fudge A, 2022, INT J EDUC INTEGR, V18, DOI 10.1007/s40979-021-00099-1; Gee JP, 1998, REV RES EDUC, V23, P119, DOI 10.3102/0091732X023001119; Guerrero-Dib JG, 2020, INT J EDUC INTEGR, V16, DOI 10.1007/s40979-020-0051-3; Harrison D, 2021, J ACAD ETHICS, V19, P483, DOI 10.1007/s10805-020-09373-2; Hyland K, 2006, ROUTL APPL LINGU SER, P1; Keck C, 2006, J SECOND LANG WRIT, V15, P261, DOI 10.1016/j.jslw.2006.09.006; Keck C, 2014, J SECOND LANG WRIT, V25, P4, DOI 10.1016/j.jslw.2014.05.005; Kumar PM, 2014, ANN MED HEALTH SCI R, V4, P193, DOI 10.4103/2141-9248.141957; Liu D., 2023, Responding to generative AI for assessments in semester 2, 2023; Lodge JM, 2023, AUSTRALAS J EDUC TEC, V39, P18, DOI 10.14742/ajet.8695; Löfström E, 2015, HIGH EDUC, V69, P435, DOI 10.1007/s10734-014-9784-3; MacLeod PD, 2020, J ACAD ETHICS, V18, P347, DOI 10.1007/s10805-020-09363-4; McCarthy G., 2014, Coaching and mentoring for business; McKay J, 2014, HIGH EDUC RES DEV, V33, P949, DOI 10.1080/07294360.2014.890570; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Potter J., 1987, DISCOURSE SOCIAL PSY; Prentice FM, 2018, INT J EDUC INTEGR, V14, DOI 10.1007/s40979-018-0036-7; Roe J, 2022, INT J EDUC INTEGR, V18, DOI 10.1007/s40979-022-00109-w; Rogerson AM, 2017, INT J EDUC INTEGR, V13, DOI 10.1007/s40979-016-0013-y; Ronai K., 2020, Apples -Journal of Applied Language Studies, V14, P25, DOI [10.17011/apples/urn.202003282558, DOI 10.17011/APPLES/URN.202003282558]; San JoseA.E., 2022, European Journal of Education and Pedagogy, V3, P97; Shi L, 2012, J SECOND LANG WRIT, V21, P134, DOI 10.1016/j.jslw.2012.03.003; Suchan J., 2014, Journal Of Business Communication, V51, P279; Sutherland-Smith W., 2008, Plagiarism, the internet, and student learning: Improving academic integrity, DOI [10.4324/9780203928370, DOI 10.4324/9780203928370]; Vygotsky L., 1978, Mind in society: The development of higher psychological processes, DOI [DOI 10.2307/J.CTVJF9VZ4, 10.2307/j.ctvjf9vz4]; Widdowson H.G., 1998, APPL LINGUISTICS, V19, P136; Zobel J., 2002, AUST UNIV REV, V45, P23	41	0	0	8	9	UNIV WOLLONGONG	WOLLONGONG	NORTHFIELDS AVE, WOLLONGONG, NSW 2522, AUSTRALIA	1449-9789			J UNIV TEACH LEARN P	J. Univ. Teach. Learn. Pract.		2023	20	7							08	10.53761/1.20.7.08	http://dx.doi.org/10.53761/1.20.7.08			23	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Y2RE3		gold, Green Submitted			2024-07-03	WOS:001103781300006
J	Spirnak, JR; Antani, S				Spirnak, Jonathan R.; Antani, Sameer			The Need for Artificial Intelligence Curriculum in Military Medical Education	MILITARY MEDICINE			English	Editorial Material								The success of deep-learning algorithms in analyzing complex structured and unstructured multidimensional data has caused an exponential increase in the amount of research devoted to the applications of artificial intelligence (AI) in medicine in the past decade. Public release of large language models like ChatGPT the past year has generated an unprecedented storm of excitement and rumors of machine intelligence finally reaching or even surpassing human capability in detecting meaningful signals in complex multivariate data. Such enthusiasm, however, is met with an equal degree of both skepticism and fear over the social, legal, and moral implications of such powerful technology with relatively little safeguards or regulations on its development. The question remains in medicine of how to harness the power of AI to improve patient outcomes by increasing the diagnostic accuracy and treatment precision provided by medical professionals. Military medicine, given its unique mission and resource constraints,can benefit immensely from such technology. However, reaping such benefits hinges on the ability of the rising generations of military medical professionals to understand AI algorithms and their applications. Additionally, they should strongly consider working with them as an adjunct decision-maker and view them as a colleague to access and harness relevant information as opposed to something to be feared. Ideas expressed in this commentary were formulated by a military medical student during a two-month research elective working on a multidisciplinary team of computer scientists and clinicians at the National Library of Medicine advancing the state of the art of AI in medicine. A motivation to incorporate AI in the Military Health System is provided, including examples of applications in military medicine. Rationale is then given for inclusion of AI in education starting in medical school as well as a prudent implementation of these algorithms in a clinical workflow during graduate medical education. Finally, barriers to implementation are addressed along with potential solutions. The end state is not that rising military physicians are technical experts in AI; but rather that they understand how they can leverage its rapidly evolving capabilities to prepare for a future where AI will have a significant role in clinical care. The overall goal is to develop trained clinicians that can leverage these technologies to improve the Military Health System.	[Spirnak, Jonathan R.] USUHS, Sch Med, Bethesda, MD 20814 USA; [Antani, Sameer] NIH, Computat Hlth Res Branch, Natl Lib Med, Bethesda, MD 20892 USA	National Institutes of Health (NIH) - USA; NIH National Library of Medicine (NLM)	Spirnak, JR (corresponding author), USUHS, Sch Med, Bethesda, MD 20814 USA.		Antani, Sameer/GVS-8371-2022	Antani, Sameer/0000-0002-0040-1387; Spirnak, Jonathan/0009-0007-2579-669X	The work of 2LT J.R.S. was made possible through the clinical electives program at the National Institutes of Health and the capstone program at the Uniformed Services University of the Health Sciences. The work of Dr. S.A. was supported by the Intramural; Intramural Research Program of the National Library of Medicine, National Institutes of Health	The work of 2LT J.R.S. was made possible through the clinical electives program at the National Institutes of Health and the capstone program at the Uniformed Services University of the Health Sciences. The work of Dr. S.A. was supported by the Intramural; Intramural Research Program of the National Library of Medicine, National Institutes of Health	The work of 2LT J.R.S. was made possible through the clinical electives program at the National Institutes of Health and the capstone program at the Uniformed Services University of the Health Sciences. The work of Dr. S.A. was supported by the Intramural Research Program of the National Library of Medicine, National Institutes of Health.	Adler-Milstein J, 2020, J AM MED INFORM ASSN, V27, P531, DOI 10.1093/jamia/ocz220; [Anonymous], 2019, Oxford online reference, DOI DOI 10.1093/OI/AUTHORITY.20110803095426960; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Cooper A, 2023, NEW ENGL J MED, V389, P385, DOI 10.1056/NEJMp2304993; Herring W., 2024, LEARNING RADIOLOGY, pe101; Hinton G., 2016, P MACH LEARN MARK IN; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kong XY, 2019, AM J TRANSL RES, V11, P2632; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Langlotz CP, 2019, RADIOL-ARTIF INTELL, V1, DOI 10.1148/ryai.2019190058; Plana D, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.33946; Quer G, 2021, J AM COLL CARDIOL, V77, P300, DOI 10.1016/j.jacc.2020.11.030; Sahni NR, 2023, NEW ENGL J MED, V389, P348, DOI 10.1056/NEJMra2204673; Shen K., NEXT FRONTIER AI CHI; Zamzmi G, 2022, MED IMAGE ANAL, V80, DOI 10.1016/j.media.2022.102438	15	0	0	9	19	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0026-4075	1930-613X		MIL MED	Milit. Med.	MAY 18	2024	189	5-6					954	958		10.1093/milmed/usad412	http://dx.doi.org/10.1093/milmed/usad412		OCT 2023	5	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RP7G5	37864817	hybrid			2024-07-03	WOS:001089478800001
J	Gertz, RJ; Dratsch, T; Bunck, AC; Lennartz, S; Iuga, AI; Hellmich, MG; Persigehl, T; Pennig, L; Gietzen, CH; Fervers, P; Maintz, D; Hahnfeldt, R; Kottlors, J				Gertz, Roman Johannes; Dratsch, Thomas; Bunck, Alexander Christian; Lennartz, Simon; Iuga, Andra-Iza; Hellmich, Martin Gunnar; Persigehl, Thorsten; Pennig, Lenhard; Gietzen, Carsten Herbert; Fervers, Philipp; Maintz, David; Hahnfeldt, Robert; Kottlors, Jonathan			Potential of GPT-4 for Detecting Errors in Radiology Reports: Implications for Reporting Accuracy	RADIOLOGY			English	Article								Background: Errors in radiology reports may occur because of resident-to-attending discrepancies, speech recognition inaccuracies, and large workload. Large language models, such as GPT-4 (ChatGPT; OpenAI), may assist in generating reports. Purpose: To assess effectiveness of GPT-4 in identifying common errors in radiology reports, focusing on performance, time, and cost-efficiency. Materials and Methods: In this retrospective study, 200 radiology reports (radiography and cross-sectional imaging [CT and MRI]) were compiled between June 2023 and December 2023 at one institution. There were 150 errors from five common error categories (omission, insertion, spelling, side confusion, and other) intentionally inserted into 100 of the reports and used as the reference standard. Six radiologists (two senior radiologists, two attending physicians, and two residents) and GPT-4 were tasked with detecting these errors. Overall error detection performance, error detection in the five error categories, and reading time were assessed using Wald chi(2) tests and paired-sample t tests. Results: GPT-4 (detection rate, 82.7%;124 of 150; 95% CI: 75.8, 87.9) matched the average detection performance of radiologists independent of their experience (senior radiologists, 89.3% [134 of 150; 95% CI: 83.4, 93.3]; attending physicians, 80.0% [120 of 150; 95% CI: 72.9, 85.6]; residents, 80.0% [120 of 150; 95% CI: 72.9, 85.6]; P value range, .522-.99). One senior radiologist outperformed GPT-4 (detection rate, 94.7%; 142 of 150; 95% CI: 89.8, 97.3; P = .006). GPT-4 required less processing time per radiology report than the fastest human reader in the study (mean reading time, 3.5 seconds +/- 0.5 [SD] vs 25.1 seconds +/- 20.1, respectively; P < .001; Cohen d = -1.08). The use of GPT-4 resulted in lower mean correction cost per report than the most cost-efficient radiologist ($0.03 +/- 0.01 vs $0.42 +/- 0.41; P < .001; Cohen d = -1.12). Conclusion: The radiology report error detection rate of GPT-4 was comparable with that of radiologists, potentially reducing work hours and cost.	[Gertz, Roman Johannes; Dratsch, Thomas; Bunck, Alexander Christian; Lennartz, Simon; Iuga, Andra-Iza; Persigehl, Thorsten; Pennig, Lenhard; Gietzen, Carsten Herbert; Fervers, Philipp; Maintz, David; Hahnfeldt, Robert; Kottlors, Jonathan] Univ Cologne, Univ Hosp Cologne, Inst Diagnost & Intervent Radiol, Fac Med, Kerpener Str 62, D-50937 Cologne, Germany; [Hellmich, Martin Gunnar] Univ Cologne, Univ Hosp Cologne, Inst Med Stat & Bioinformat, Fac Med, Kerpener Str 62, D-50937 Cologne, Germany	University of Cologne; University of Cologne	Gertz, RJ (corresponding author), Univ Cologne, Univ Hosp Cologne, Inst Diagnost & Intervent Radiol, Fac Med, Kerpener Str 62, D-50937 Cologne, Germany.	roman.j.gertz@gmail.com		Bunck, Alexander/0000-0003-0986-0042; Gietzen, Carsten/0000-0002-2354-3847; Lennartz, Simon/0000-0002-3254-4809; Iuga, Andra-Iza/0000-0002-3694-0235	Cologne Clinician Scientist Program (CCSP, Faculty of Medicine, University of Cologne); Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [413543196]; German Federal Ministry of Education and Research Network of University Medicine NUM 2.0 [01KX2121]	Cologne Clinician Scientist Program (CCSP, Faculty of Medicine, University of Cologne); Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG)); German Federal Ministry of Education and Research Network of University Medicine NUM 2.0	Supported by the Cologne Clinician Scientist Program (CCSP, Faculty of Medicine, University of Cologne). Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) (project number 413543196). Supported in part by the German Federal Ministry of Education and Research Network of University Medicine NUM 2.0 (grant 01KX2121) .	Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Almeida LC, 2024, RADIOL-ARTIF INTELL, V6, DOI 10.1148/ryai.230103; Bhayana R, 2024, RADIOLOGY, V310, DOI 10.1148/radiol.232756; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bosbach WA, 2024, CURR PROBL DIAGN RAD, V53, P102, DOI 10.1067/j.cpradiol.2023.04.001; COHEN J, 1992, PSYCHOL BULL, V112, P155, DOI 10.1037/0033-2909.112.1.155; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Coppola F, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.710982; Duong MT, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190389; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; GPT-4, OpenAI; Hanna TN, 2018, J AM COLL RADIOL, V15, P1709, DOI 10.1016/j.jacr.2017.12.019; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Kaarre J, 2023, KNEE SURG SPORT TR A, V31, P5190, DOI 10.1007/s00167-023-07529-2; Khatami A, 2018, EXPERT SYST APPL, V100, P224, DOI 10.1016/j.eswa.2018.01.056; Kidwai AS, 2015, J AM COLL RADIOL, V12, P1151, DOI 10.1016/j.jacr.2015.03.041; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Krupinski EA, 2010, J AM COLL RADIOL, V7, P698, DOI 10.1016/j.jacr.2010.03.004; Lexa FJ, 2021, AM J ROENTGENOL, V217, P558, DOI 10.2214/AJR.21.25484; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; McDonald RJ, 2015, ACAD RADIOL, V22, P1191, DOI 10.1016/j.acra.2015.05.007; Nazario-Johnson L, 2023, J AM COLL RADIOL, V20, P1004, DOI 10.1016/j.jacr.2023.06.008; Patil NS, 2023, J AM COLL RADIOL, V20, P1010, DOI 10.1016/j.jacr.2023.07.010; Quint Leslie E, 2008, J Am Coll Radiol, V5, P1196, DOI 10.1016/j.jacr.2008.07.005; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; Ringler MD, 2015, STUD HEALTH TECHNOL, V216, P922, DOI 10.3233/978-1-61499-564-7-922; Rosen S, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10230-0; Russe MF, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-41512-8; Schmidt S, 2024, ARCH ORTHOP TRAUM SU, V144, P611, DOI 10.1007/s00402-023-05113-4; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sistrom CL, 2020, ACAD RADIOL, V27, P1006, DOI 10.1016/j.acra.2019.11.023; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Vosshenrich J, 2021, EUR RADIOL, V31, P2115, DOI 10.1007/s00330-020-07306-6; Wallis S, 2013, J QUANT LINGUIST, V20, P178, DOI 10.1080/09296174.2013.799918	38	0	0	0	0	RADIOLOGICAL SOC NORTH AMERICA (RSNA)	OAK BROOK	820 JORIE BLVD, SUITE 200, OAK BROOK, ILLINOIS, UNITED STATES	0033-8419			RADIOLOGY	Radiology	APR	2024	311	1							e232714	10.1148/radiol.232714	http://dx.doi.org/10.1148/radiol.232714			9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	UC3M1	38625012				2024-07-03	WOS:001245823000011
J	Riedel, M; Kaefinger, K; Stuehrenberg, A; Ritter, V; Amann, N; Graf, A; Recker, F; Klein, E; Kiechle, M; Riedel, F; Meyer, B				Riedel, Maximilian; Kaefinger, Katharina; Stuehrenberg, Antonia; Ritter, Viktoria; Amann, Niklas; Graf, Anna; Recker, Florian; Klein, Evelyn; Kiechle, Marion; Riedel, Fabian; Meyer, Bastian			ChatGPT's performance in German OB/GYN exams - paving the way for AI-enhanced medical education and clinical practice	FRONTIERS IN MEDICINE			English	Article						artificial intelligence; ChatGPT; medical education; machine learning; obstetrics and gynecology; students		BackgroundChat Generative Pre-Trained Transformer (ChatGPT) is an artificial learning and large language model tool developed by OpenAI in 2022. It utilizes deep learning algorithms to process natural language and generate responses, which renders it suitable for conversational interfaces. ChatGPT's potential to transform medical education and clinical practice is currently being explored, but its capabilities and limitations in this domain remain incompletely investigated. The present study aimed to assess ChatGPT's performance in medical knowledge competency for problem assessment in obstetrics and gynecology (OB/GYN).MethodsTwo datasets were established for analysis: questions (1) from OB/GYN course exams at a German university hospital and (2) from the German medical state licensing exams. In order to assess ChatGPT's performance, questions were entered into the chat interface, and responses were documented. A quantitative analysis compared ChatGPT's accuracy with that of medical students for different levels of difficulty and types of questions. Additionally, a qualitative analysis assessed the quality of ChatGPT's responses regarding ease of understanding, conciseness, accuracy, completeness, and relevance. Non-obvious insights generated by ChatGPT were evaluated, and a density index of insights was established in order to quantify the tool's ability to provide students with relevant and concise medical knowledge.ResultsChatGPT demonstrated consistent and comparable performance across both datasets. It provided correct responses at a rate comparable with that of medical students, thereby indicating its ability to handle a diverse spectrum of questions ranging from general knowledge to complex clinical case presentations. The tool's accuracy was partly affected by question difficulty in the medical state exam dataset. Our qualitative assessment revealed that ChatGPT provided mostly accurate, complete, and relevant answers. ChatGPT additionally provided many non-obvious insights, especially in correctly answered questions, which indicates its potential for enhancing autonomous medical learning.ConclusionChatGPT has promise as a supplementary tool in medical education and clinical practice. Its ability to provide accurate and insightful responses showcases its adaptability to complex clinical scenarios. As AI technologies continue to evolve, ChatGPT and similar tools may contribute to more efficient and personalized learning experiences and assistance for health care providers.	[Riedel, Maximilian; Kaefinger, Katharina; Stuehrenberg, Antonia; Ritter, Viktoria; Graf, Anna; Klein, Evelyn; Kiechle, Marion; Meyer, Bastian] Tech Univ Munich TU, Klinikum Rechts Isar, Dept Gynecol & Obstet, Munich, Germany; [Amann, Niklas] Friedrich Alexander Univ Erlangen Nuremberg FAU, Dept Gynecol & Obstet, Erlangen, Germany; [Recker, Florian] Bonn Univ Hosp, Dept Gynecol & Obstet, Bonn, Germany; [Riedel, Fabian] Heidelberg Univ Hosp, Dept Gynecol & Obstet, Heidelberg, Germany	Technical University of Munich; University of Erlangen Nuremberg; University of Bonn; Ruprecht Karls University Heidelberg	Riedel, M (corresponding author), Tech Univ Munich TU, Klinikum Rechts Isar, Dept Gynecol & Obstet, Munich, Germany.	maximilian.riedel@mri.tum.de	Recker, Florian/ABP-4557-2022	Recker, Florian/0000-0001-9135-4338				AMBOSS, 2020, Medical knowledge distilled; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Beam K, 2023, JAMA PEDIATR, V177, P977, DOI 10.1001/jamapediatrics.2023.2373; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Burgess A, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02282-3; ClinicalKey, 2023, Diagnose and treat your patients with confidence; Cognizant, 2023, ChatGPT and the generative AI revolution; Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Enyama D, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02953-9; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ge J, 2023, HEPATOL COMMUN, V7, DOI 10.1097/HC9.0000000000000097; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Ha LA, 2019, P REC ADV NAT LANG P, P418, DOI DOI 10.26615/978-954-452-056-4_049; Huang HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00239-y; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; IBM Watson, 2023, Conversational AI for fast and friendly customer care; Irby DM, 2010, ACAD MED, V85, P220, DOI 10.1097/ACM.0b013e3181c88449; Jin D, 2020, Arxiv, DOI arXiv:2009.13081; Jin Q, 2019, arXiv; Jones RW, 2007, ANAESTH INTENS CARE, V35, P587, DOI 10.1177/0310057X0703500420; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lacalamita A, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242015286; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Middeke A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203851; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; OpenAI, 2023, OpenAI ChatGPT: Optimizing language models for dialogue; PECB Insights, 2023, The rise of ChatGPT: Paving the way for large language model adoption; Rahm AK, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0249425; Reuters, 2023, ChatGPT sets record for fastest-growing user base-Analyst note; Riedel M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0269562; Riedel M, 2022, ARCH GYNECOL OBSTET, V305, P1041, DOI 10.1007/s00404-021-06356-5; Robinson Lilian, 2023, Can Med Educ J, V14, P178, DOI 10.36834/cmej.76464; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schukow C, 2024, ADV ANAT PATHOL, V31, P15, DOI 10.1097/PAP.0000000000000406; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Skochelak SE, 2017, ACAD MED, V92, P16, DOI 10.1097/ACM.0000000000001160; Springer L, 1999, REV EDUC RES, V69, P21, DOI 10.2307/1170643; Stanford CRFM, 2022, Introduces PubMedGPT 2.7B; Suddeutsche Zeitung, 2022, Die gefuhlte Revolution; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; The Economist, 2022, How good is ChatGPT?; UpToDate, 2023, Surgeon viewing UpToDate on tablet UpToDate: Interaktive Unterstutzung klinischer Entscheidungen; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; Wang LKP., 2023, Med Teach, V1, P1, DOI DOI 10.1080/0142159X.2023.2256961; Wang R., 1996, Beyond Accuracy: What Data Quality means to Data Consumers; Weng TL, 2023, J CHIN MED ASSOC, V86, P865, DOI 10.1097/JCMA.0000000000000956; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	52	1	1	26	26	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-858X		FRONT MED-LAUSANNE	Front. Med.	DEC 13	2023	10								1296615	10.3389/fmed.2023.1296615	http://dx.doi.org/10.3389/fmed.2023.1296615			11	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	DE2U7	38155661	gold, Green Published			2024-07-03	WOS:001130296800001
C	Nozza, D; Bianchi, F; Hovy, D			Assoc Computat Linguist	Nozza, Debora; Bianchi, Federico; Hovy, Dirk			Pipelines for Social Bias Testing of Large Language Models	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				The maturity level of language models is now at a stage in which many companies rely on them to solve various tasks. However, while research has shown how biased and harmful these models are, systematic ways of integrating social bias tests into development pipelines are still lacking. This short paper suggests how to use these verification techniques in development pipelines. We take inspiration from software testing and suggest addressing social bias evaluation as software testing. We hope to open a discussion on the best methodologies to handle social bias testing in language models.	[Nozza, Debora; Bianchi, Federico; Hovy, Dirk] Bocconi Univ, Via Sarfatti 25, Milan, Italy	Bocconi University	Nozza, D (corresponding author), Bocconi Univ, Via Sarfatti 25, Milan, Italy.	debora.nozza@unibocconi.it; f.bianchi@unibocconi.it; dirk.hovy@unibocconi.it	Bianchi, Federico/JZT-6891-2024; Nozza, Debora/AAD-7453-2019	Bianchi, Federico/0000-0002-6155-5531; Nozza, Debora/0000-0002-7998-2267	European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program [949944]; Fondazione Cariplo [2020-4288]	European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program(European Research Council (ERC)); Fondazione Cariplo(Fondazione Cariplo)	This project has partially received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation program (grant agreement No. 949944, INTEGRATOR), and by Fondazione Cariplo (grant No. 2020-4288, MONICA). Debora Nozza, Federico Bianchi, and Dirk Hovy are members of the MilaNLP group, and the Data and Marketing Insights Unit of the Bocconi Institute for Data Science and Analysis.	Barikeri S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1941; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33; Bianchi F, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3895; Blodgett SL, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1004; Bolukbasi T, 2016, ADV NEUR IN, V29; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chia Patrick John, COMPANION P WEB C; Choenni R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1477; Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Gehman S., 2020, FINDINGS ASS COMPUTA, P3356; Gokaslan Aaron, 2019, OPENWEBTEXT CORPUS; Goldfarb-Tarrant S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1926; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Haoran Zhang, 2020, CHIL '20: Proceedings of the Conference on Health, Inference, and Learning, P110, DOI 10.1145/3368555.3384448; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Huang PS, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P65; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166; Lauscher A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4782; Lauscher Anne, 2019, P 8 JOINT C LEX COMP, P85, DOI 10.18653/v1/S19-1010; Liang PP, 2020, P 58 ANN M ASS COMP, P5502, DOI [DOI 10.18653/V1/2020.ACL-MAIN.488, 10.18653/v1/2020.acl-main.488]; Manzini Thomas, 2019, P 2019 C N AM CHAPTE, V1, P615; May C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P622; Nadeem Moin, P 59 ANN M ASS COMPU, V1, P5356; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nozza D, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE (WI 2019), P149, DOI 10.1145/3350546.3352512; Nozza Debora, P 2 WORKSHOP LANGUAG; Nozza Debora, 2021, P 2021 C N AM CHAPTE, P2398; Ousidhoum N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4262; Paul Rottger, P 59 ANN M ASS COMPU, P41; Ribeiro Marco Tulio, 2020, ARXIV200504118; Shah Deven Santosh, 2020, P 58 ANN M ASS COMPU, P5248, DOI [10.18653/v1/2020.acl-main.468, DOI 10.18653/V1/2020.ACL-MAIN.468, 10.18653/v1/2020.aclmain.468]; Sheng EM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4275; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Stanczak K, 2021, Arxiv, DOI [arXiv:2112.14168, DOI 10.48550/ARXIV.2112.14168, 10.48550/ARXIV.2112.14168]; Swinger N, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P305, DOI 10.1145/3306618.3314270; Wolfe R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P518	40	3	3	1	3	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							68	74						7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900006
J	Elyoseph, Z; Levkovich, I; Shinan-Altman, S				Elyoseph, Zohar; Levkovich, Inbar; Shinan-Altman, Shiri			Assessing prognosis in depression: comparing perspectives of AI models, mental health professionals and the general public	FAMILY MEDICINE AND COMMUNITY HEALTH			English	Article						depression; general practice; psychiatry; nurses; mental health	DISORDERS	BackgroundArtificial intelligence (AI) has rapidly permeated various sectors, including healthcare, highlighting its potential to facilitate mental health assessments. This study explores the underexplored domain of AI's role in evaluating prognosis and long-term outcomes in depressive disorders, offering insights into how AI large language models (LLMs) compare with human perspectives.MethodsUsing case vignettes, we conducted a comparative analysis involving different LLMs (ChatGPT-3.5, ChatGPT-4, Claude and Bard), mental health professionals (general practitioners, psychiatrists, clinical psychologists and mental health nurses), and the general public that reported previously. We evaluate the LLMs ability to generate prognosis, anticipated outcomes with and without professional intervention, and envisioned long-term positive and negative consequences for individuals with depression.ResultsIn most of the examined cases, the four LLMs consistently identified depression as the primary diagnosis and recommended a combined treatment of psychotherapy and antidepressant medication. ChatGPT-3.5 exhibited a significantly pessimistic prognosis distinct from other LLMs, professionals and the public. ChatGPT-4, Claude and Bard aligned closely with mental health professionals and the general public perspectives, all of whom anticipated no improvement or worsening without professional help. Regarding long-term outcomes, ChatGPT 3.5, Claude and Bard consistently projected significantly fewer negative long-term consequences of treatment than ChatGPT-4.ConclusionsThis study underscores the potential of AI to complement the expertise of mental health professionals and promote a collaborative paradigm in mental healthcare. The observation that three of the four LLMs closely mirrored the anticipations of mental health experts in scenarios involving treatment underscores the technology's prospective value in offering professional clinical forecasts. The pessimistic outlook presented by ChatGPT 3.5 is concerning, as it could potentially diminish patients' drive to initiate or continue depression therapy. In summary, although LLMs show potential in enhancing healthcare services, their utilisation requires thorough verification and a seamless integration with human judgement and skills.	[Elyoseph, Zohar] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Yezreel Valley, Israel; [Elyoseph, Zohar] Imperial Coll London, Dept Brain Sci, London, England; [Levkovich, Inbar] Oranim Acad Coll, Fac Grad Studies, Tivon, Israel; [Shinan-Altman, Shiri] Bar Ilan Univ, Louis & Gabi Weisfeld Sch Social Work, Ramat Gan, Tel Aviv, Israel	Imperial College London; Bar Ilan University	Elyoseph, Z (corresponding author), Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Yezreel Valley, Israel.; Elyoseph, Z (corresponding author), Imperial Coll London, Dept Brain Sci, London, England.	zohare@yvc.ac.il		Elyoseph, Zohar/0000-0002-5717-4074				Achterbergh L, 2020, BMC PSYCHIATRY, V20, DOI 10.1186/s12888-020-02818-3; Ali O, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100333; Andresen R, 2011, PSYCHOLOGICAL RECOVERY: BEYOND MENTAL ILLNESS, P1, DOI 10.1002/9781119975182; Andrew J, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1110088; [Anonymous], 1994, DIAGNOSTIC STAT MANU; Babcock G, 2023, BIOL J LINN SOC, V139, P415, DOI 10.1093/biolinnean/blac058; Barkham M., 2021, BERGIN GARFIELDS HDB; Barth J, 2013, PLOS MED, V10, DOI 10.1371/journal.pmed.1001454; Brendese PJ., 2023, Cognitive Technologies, DOI [10.1007/978-981-99-2154-6, DOI 10.1007/978-981-99-2154-6]; Caldwell T M, 2001, Aust N Z J Ment Health Nurs, V10, P42; Cipriani A, 2018, LANCET, V391, P1357, DOI 10.1016/S0140-6736(17)32802-7; Cleare A, 2015, J PSYCHOPHARMACOL, V29, P459, DOI 10.1177/0269881115581093; Cuijpers P, 2019, CURR PSYCHIAT REP, V21, DOI 10.1007/s11920-019-1117-x; Cuijpers P, 2019, ANNU REV CLIN PSYCHO, V15, P207, DOI 10.1146/annurev-clinpsy-050718-095424; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Davis A, 2023, INT J MENT HEALTH AD, V21, P3785, DOI 10.1007/s11469-022-00821-1; Elyoseph Z., JMIR Mental Health, DOI [10.2196/preprints.54369, DOI 10.2196/PREPRINTS.54369]; Elyoseph Z, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1213141; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Ferrari AJ, 2022, LANCET PSYCHIAT, V9, P137, DOI 10.1016/S2215-0366(21)00395-3; Fimiani R, 2023, PSYCHOTHER RES, V33, P729, DOI 10.1080/10503307.2022.2157227; Flückiger C, 2018, PSYCHOTHERAPY, V55, P316, DOI 10.1037/pst0000172; Gunasekaran S, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-08248-z; Hadar-Shoval D., The invisible embedded "values"within large language models: implications for mental health use, DOI [10.21203/rs.3.rs-3456660/v1, DOI 10.21203/RS.3.RS-3456660/V1]; Hadar-Shoval D, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1234397; Hochstetter A, 2020, ACS NANO, V14, P10784, DOI 10.1021/acsnano.0c05186; Jorm AF, 1997, AUST NZ J PSYCHIAT, V31, P844, DOI 10.3109/00048679709065510; Jorm AF, 2017, WORLD PSYCHIATRY, V16, P90, DOI 10.1002/wps.20388; Kennedy S, 2021, EUR J OBSTET GYN R B, V264, P150, DOI 10.1016/j.ejogrb.2021.07.003; Levkovich I, 2023, FAM MED COMMUNITY HE, V11, DOI 10.1136/fmch-2023-002391; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; Li XY, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.801231; Liao KM, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13061075; Lim GY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21243-x; Mariani MM, 2023, J BUS RES, V155, DOI 10.1016/j.jbusres.2022.113364; McLaren T, 2023, BMC PUBLIC HEALTH, V23, DOI 10.1186/s12889-022-14937-5; Olfson M, 2016, JAMA INTERN MED, V176, P1482, DOI 10.1001/jamainternmed.2016.5057; Pan C., 2023, Intelligent human centered computing: Proceeds of Human 2023, P384, DOI [10.1007/978-981-99-3478-2, DOI 10.1007/978-981-99-3478-2]; Park LT, 2019, NEW ENGL J MED, V380, P559, DOI 10.1056/NEJMcp1712493; Patterson JE, 2018, FAM PROCESS, V57, P70, DOI 10.1111/famp.12281; Romera I, 2013, BMC PSYCHIATRY, V13, DOI 10.1186/1471-244X-13-51; Rush AJ, 2006, AM J PSYCHIAT, V163, P1905, DOI 10.1176/appi.ajp.163.11.1905; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sekechi M, 2022, BRIT J PSYCHOTHER, V38, P483, DOI 10.1111/bjp.12747; Slade M, 2014, WORLD PSYCHIATRY, V13, P12, DOI 10.1002/wps.20084; Sullivan PW, 2017, J Psychosoc Rehabil Ment Health, V4, P221, DOI [DOI 10.1007/S40737-017-0097-6, 10.1007/s40737-017-0097-6]; Tal A, 2023, AM J BIOETHICS, V23, P74, DOI 10.1080/15265161.2023.2250297; Taylor CB, 2021, EUR J PUBLIC HEALTH, V31, P3, DOI 10.1093/eurpub/ckz208; Temsah MH, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11131812; Uludag K., 2023, SSRN Journal, DOI [10.2139/ssrn.4390872, DOI 10.2139/SSRN.4390872]; Wampold BE, 2023, WORLD PSYCHIATRY, V22, P25, DOI 10.1002/wps.21035; White C, 2018, PSYCHIAT QUART, V89, P261, DOI 10.1007/s11126-017-9531-x; Wittchen Hans-Ulrich, 2003, Dialogues Clin Neurosci, V5, P115; Wong DFK, 2019, RES SOCIAL WORK PRAC, V29, P311, DOI 10.1177/1049731517732837; Wulandari P., 2021, SciPsy, V2, P71, DOI [10.37275/scipsy.v2i3.38, DOI 10.37275/SCIPSY.V2I3.38]; Zilcha-Mano S, 2021, AM PSYCHOL, V76, P516, DOI 10.1037/amp0000629	56	5	5	12	12	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	2305-6983	2009-8774		FAM MED COMMUNITY HE	Fam. Med. Community Health	JAN	2024	12	SUPPL_1		1					e002583	10.1136/fmch-2023-002583	http://dx.doi.org/10.1136/fmch-2023-002583			9	Primary Health Care	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	EY8E2	38199604	gold			2024-07-03	WOS:001142580500001
C	Jha, S			IEEE	Jha, Susmit			Lightning Talk: Trinity - Assured Neuro-symbolic Model Inspired by Hierarchical Predictive Coding	2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC			English	Proceedings Paper	60th ACM/IEEE Design Automation Conference (DAC)	JUL 09-13, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery		assurance; machine learning; robust learning; predictive processing		This paper describes the core concepts and challenges in developing Trinity - a high-assurance neuro-symbolic approach to trustworthy and resilient machine learning for applications in open-world, contested, and rapidly-evolving environments. The two central concepts in Trinity are a neuro-symbolic factored world model that identifies entities, activities, and complex events, and the notion of surprise against this world model that is used for self-adaptation and learning, as well as runtime assurance. The world model is not derived purely as a bottom-up inference from sensors treating each observation as independent uncorrelated input; instead, we iteratively interleave bottom-up inference (conditioned on context) with topdown predictions and context identification using a three-layered hierarchical predictive processing (HPP) stack. Thus, the neuro-symbolic inference in Trinity is bidirectional - learning-based bottom-up pull that is uncertainty-driven and reasoning-based symbolic top-down push that is decision-driven. The progressively symbolic higher layers capture a larger context than the bottom layers finally culminating in the highest layer implemented using large language models. Any surprise arising from the mismatch between the top-down prediction and the bottom-up inference is used for the continual adaptation of Trinity. The inference in Trinity produces a factored temporal world model as the result of perception. The predictions are accompanied by a quantitative measure of surprise from the 3-layered HPP stack. This surprise corresponds to the confidence of the model in its current inference. The continuous monitoring and adaptation accompanied by risk analysis make Trinity robust to semantic adversarial perturbations and more efficiently generalizable to novelties. The hierarchical nature of Trinity also enables adaptation of the architecture to the available compute resources.	[Jha, Susmit] SRI Int, Comp Sci Lab, Menlo Pk, CA 94025 USA	SRI International	Jha, S (corresponding author), SRI Int, Comp Sci Lab, Menlo Pk, CA 94025 USA.	susmit.jha@sri.com			U.S. Army Combat Capabilities Development Command (DEVCOM) Army Research Laboratory [W911NF17-2-0196]	U.S. Army Combat Capabilities Development Command (DEVCOM) Army Research Laboratory	This work was supported in part by the U.S. Army Combat Capabilities Development Command (DEVCOM) Army Research Laboratory under Cooperative Agreement W911NF17-2-0196. The views expressed in this paper are those of the authors and do not reflect the official policy or position of the United States Army, the United States Department of Defense, or the United States Government.	Abdelzaher T, 2022, IEEE MILIT COMMUN C, DOI 10.1109/MILCOM55135.2022.10017607; Acharya Manoj, 2022, IJCAI; Bastian Nathaniel, 2022, AAAI SPRING S 2022; Bastian Nathaniel D, 2022, IoT for Defense and National Security, P119; Bojarski M, 2016, Arxiv, DOI [arXiv:1604.07316, DOI 10.48550/ARXIV.1604.07316]; Cunningham Edmond, 2022, PR MACH LEARN RES, P4492; De Fauw J, 2018, NAT MED, V24, P1342, DOI 10.1038/s41591-018-0107-6; Evans JSBT, 2010, PSYCHOL INQ, V21, P313, DOI 10.1080/1047840X.2010.521057; Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129; Guo C, 2017, Arxiv, DOI [arXiv:1706.04599, 10.48550/arXiv.1706.04599, 10.48550/arXiv.1706.04599.5]; Hannun A, 2014, Arxiv, DOI arXiv:1412.5567; Hendrycks D, 2018, Arxiv, DOI [arXiv:1610.02136, DOI 10.48550/ARXIV.1610.02136]; Jang Uyeong, 2020, ICLR; Jha Susmit, 2020, Computer Safety, Reliability, and Security. 39th International Conference, SAFECOMP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12234), P228, DOI 10.1007/978-3-030-54549-9_15; Jha SK, 2022, AAAI CONF ARTIF INTE, P9567; Jha S, 2023, 2023 IEEE INTERNATIONAL CONFERENCE ON ASSURED AUTONOMY, ICAA, P149, DOI 10.1109/ICAA58325.2023.00029; Jha S, 2021, 2021 IEEE THIRD INTERNATIONAL CONFERENCE ON COGNITIVE MACHINE INTELLIGENCE (COGMI 2021), P282, DOI 10.1109/CogMI52975.2021.00044; Jha S, 2018, IEEE MILIT COMMUN C, P547, DOI 10.1109/MILCOM.2018.8599691; Jha Susmit, 2019, Advances in Neural Information Processing Systems, P11826; Jha Susmit, 2021, Game Theory and Machine Learning for Cyber Security, P317; Julian Kyle D, 2017, AIAA Guidance, Navigation, and Control Conference, page, P1743; Kaur R, 2023, PROCEEDINGS OF THE 2023 ACM/IEEE 14TH INTERNATIONAL CONFERENCE ON CYBER-PHYSICAL SYSTEMS, WITH CPS-IOTWEEK 2023, P120, DOI 10.1145/3576841.3585931; Kaur R, 2022, AAAI CONF ARTIF INTE, P7104; Kaur Ramneet, 2023, IEEE INT C ASS AUT; Kiourti P, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218663; Kiourti Panagiota, 2021, ANN COMP SEC APPL C; Majumder N, 2017, IEEE INTELL SYST, V32, P74, DOI 10.1109/MIS.2017.23; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Sikka Karan, 2023, IEEE INT C ASS AUT; Vazquez-Chanlatte M, 2018, ADV NEUR IN, V31; Walmer M, 2022, PROC CVPR IEEE, P15354, DOI 10.1109/CVPR52688.2022.01494	31	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2348-1				2023										10.1109/DAC56929.2023.10247803	http://dx.doi.org/10.1109/DAC56929.2023.10247803			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BV7XM					2024-07-03	WOS:001073487300121
C	Jin, M; Shahriar, S; Tufano, M; Shi, X; Lu, S; Sundaresan, N; Svyatkovskiy, A		Chandra, S; Blincoe, K; Tonella, P		Jin, Matthew; Shahriar, Syed; Tufano, Michele; Shi, Xin; Lu, Shuai; Sundaresan, Neel; Svyatkovskiy, Alexey			InferFix: End-to-End Program Repair with LLMs	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Program repair; static analyses; prompt augmentation; finetuning		Software development life cycle is profoundly influenced by bugs; their introduction, identification, and eventual resolution account for a significant portion of software development cost. This has motivated software engineering researchers and practitioners to propose different approaches for automating the identification and repair of software defects. Large Language Models (LLMs) have been adapted to the program repair task through few-shot demonstration learning and instruction prompting, treating this as an infilling task. However, these models have only focused on learning general bug-fixing patterns for uncategorized bugs mined from public repositories. In this paper, we propose InferFix: a transformer-based program repair framework paired with a state-of-the-art static analyzer to fix critical security and performance bugs. InferFix combines a Retriever - transformer encoder model pretrained via contrastive learning objective, which aims at searching for semantically equivalent bugs and corresponding fixes; and a Generator - an LLM (12 billion parameter Codex Cushman model) finetuned on supervised bug-fix data with prompts augmented via adding bug type annotations and semantically similar fixes retrieved from an external non-parametric memory. To train and evaluate our approach, we curated InferredBugs, a novel, metadata-rich dataset of bugs extracted by executing the Infer static analyzer on the change histories of thousands of Java and C# repositories. Our evaluation demonstrates that InferFix outperforms strong LLM baselines, with a top-1 accuracy of 65.6% for generating fixes in C# and 76.8% in Java. We discuss the deployment of InferFix alongside Infer at Microsoft which offers an end-to-end solution for detection, classification, and localization of bugs, as well as fixing and validation of candidate patches, integrated in the continuous integration (CI) pipeline to automate the software development workflow.	[Jin, Matthew; Tufano, Michele; Shi, Xin; Sundaresan, Neel; Svyatkovskiy, Alexey] Microsoft, Redmond, WA 98052 USA; [Shahriar, Syed] UCLA, Los Angeles, CA USA; [Lu, Shuai] Microsoft Res, Beijing, Peoples R China	Microsoft; University of California System; University of California Los Angeles; Microsoft	Jin, M (corresponding author), Microsoft, Redmond, WA 98052 USA.							Adobe-Consulting-Services, 2023, acs-aem-common; Akbarinasaji S, 2018, J SYST SOFTWARE, V136, P173, DOI 10.1016/j.jss.2017.02.021; Allamanis M, 2021, ADV NEUR IN, V34; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P1385, DOI 10.1109/TSE.2020.3020502; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clement Colin, 2021, P 2021 C EMPIRICAL M, P4713, DOI 10.48550/arXiv.2109.08780; Cuiy LY, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1835; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Drain Dawn, 2021, MAPS 2021: Proceedings of the 5th SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3460945.3464951; Ferenc R, 2018, PROMISE'18: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, P12, DOI 10.1145/3273934.3273936; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Joshi H, 2022, Arxiv, DOI arXiv:2208.11640; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Karampatsis RM, 2020, IEEE WORK CONF MIN S, P573, DOI 10.1145/3379597.3387491; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lu S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6227; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Meta, 2023, Scaling Static Analyses at Facebook; Microsoft, 2023, InferSharp; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Panthaplackel S, 2021, AAAI CONF ARTIF INTE, V35, P13622; Pearce H, 2021, Arxiv, DOI arXiv:2108.09293; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Raffel C, 2020, J MACH LEARN RES, V21; Ruder S, 2019, P C N AM CHAPT ASS C, P15, DOI [10.18653/v1/N19-5004, DOI 10.18653/V1/N19-5004]; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	38	3	4	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							1646	1656		10.1145/3611643.3613892	http://dx.doi.org/10.1145/3611643.3613892			11	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted			2024-07-03	WOS:001148157800132
J	Antaki, F; Touma, S; Milad, D; El -Khoury, J; Duval, R				Antaki, Fares; Touma, Samir; Milad, Daniel; El -Khoury, Jonathan; Duval, Renaud			Evaluating the Performance of ChatGPT in Ophthalmology	OPHTHALMOLOGY SCIENCE			English	Article						Artificial intelligence; ChatGPT; Generative Pretrained Transformer; Medical education; Ophthalmology	KNOWLEDGE ASSESSMENT PROGRAM; DISCRIMINATION INDEX; DIFFICULTY INDEX	Purpose: Foundation models are a novel type of artificial intelligence algorithms, in which models are pre -trained at scale on unannotated data and fine-tuned for a myriad of downstream tasks, such as generating text. This study assessed the accuracy of ChatGPT, a large language model (LLM), in the ophthalmology question -answering space.Design: Evaluation of diagnostic test or technology.Participants: ChatGPT is a publicly available LLM. Methods: We tested 2 versions of ChatGPT (January 9 "legacy" and ChatGPT Plus) on 2 popular multiple choice question banks commonly used to prepare for the high-stakes Ophthalmic Knowledge Assessment Program (OKAP) examination. We generated two 260-question simulated exams from the Basic and Clinical Science Course (BCSC) Self-Assessment Program and the OphthoQuestions online question bank. We carried out logistic regression to determine the effect of the examination section, cognitive level, and difficulty index on answer accuracy. We also performed a post hoc analysis using Tukey's test to decide if there were meaningful differences between the tested subspecialties.Main Outcome Measures: We reported the accuracy of ChatGPT for each examination section in percentage correct by comparing ChatGPT's outputs with the answer key provided by the question banks. We presented logistic regression results with a likelihood ratio (LR) chi-square. We considered differences between examination sections statistically significant at a P value of < 0.05.Results: The legacy model achieved 55.8% accuracy on the BCSC set and 42.7% on the OphthoQuestions set. With ChatGPT Plus, accuracy increased to 59.4% & PLUSMN; 0.6% and 49.2% & PLUSMN; 1.0%, respectively. Accuracy improved with easier questions when controlling for the examination section and cognitive level. Logistic regression analysis of the legacy model showed that the examination section (LR, 27.57; P = 0.006) followed by question difficulty (LR, 24.05; P < 0.001) were most predictive of ChatGPT's answer accuracy. Although the legacy model performed best in general medicine and worst in neuro-ophthalmology (P < 0.001) and ocular pathology (P = 0.029), similar post hoc findings were not seen with ChatGPT Plus, suggesting more consistent results across examination sections.Conclusion: ChatGPT has encouraging performance on a simulated OKAP examination. Specializing LLMs through domain-specific pretraining may be necessary to improve their performance in ophthalmic subspecialties.Financial Disclosure(s): Proprietary or commercial disclosure may be found after the references. Ophthalmology Science 2023;3:100324 & COPY; 2023 by the American Academy of Ophthalmology. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).	[Antaki, Fares; Touma, Samir; Milad, Daniel; El -Khoury, Jonathan; Duval, Renaud] Univ Montreal, Dept Ophthalmol, Montreal, PQ, Canada; [Antaki, Fares; Touma, Samir; Milad, Daniel; El -Khoury, Jonathan; Duval, Renaud] Hop Maison Neuve Rosemont, Ctr Univ Ophtalmol CUO, Montreal, PQ, Canada; [Antaki, Fares; Touma, Samir; Milad, Daniel; El -Khoury, Jonathan] Ctr Hosp Univ Montreal CHUM, Dept Ophthalmol, Montreal, PQ, Canada; [Antaki, Fares] Ctr Hosp Univ Montreal CHUM, CHUM Sch Artificial Intelligence Healthcare SAIH, Montreal, PQ, Canada; [Duval, Renaud] Hop Maison Neuve Rosemont, Ctr Univ Ophtalmol CUO, 5415 Blvd Assompt, Montreal, PQ H1T 2M4, Canada	Universite de Montreal; Universite de Montreal; Universite de Montreal; Universite de Montreal; Universite de Montreal	Duval, R (corresponding author), Hop Maison Neuve Rosemont, Ctr Univ Ophtalmol CUO, 5415 Blvd Assompt, Montreal, PQ H1T 2M4, Canada.	renaud.duval@gmail.com	Antaki, Fares/GSI-6622-2022	Antaki, Fares/0000-0001-6679-7276				Americal Academy of Ophthalmology, 2022, OKAP EX; Antaki F, 2023, BRIT J OPHTHALMOL, V107, P90, DOI 10.1136/bjophthalmol-2021-319030; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Hingorjo MR, 2012, J PAK MED ASSOC, V62, P142; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Law C, 2012, CAN J OPHTHALMOL, V47, P254, DOI 10.1016/j.jcjo.2012.03.047; Lee AG, 2012, OPHTHALMOLOGY, V119, P1949, DOI 10.1016/j.ophtha.2012.06.010; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Medenilla A., 2023, PLoS Digital Health, V2; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; OpenAI, Introducing ChatGPT Plus; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Radford A, 2021, PR MACH LEARN RES, V139; Schmidt-Erfurth U, 2018, PROG RETIN EYE RES, V67, P1, DOI 10.1016/j.preteyeres.2018.07.004; Schulman J, 2022, Introducing chatgpt; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Stunkel L, 2020, J NEURO-OPHTHALMOL, V40, P485, DOI 10.1097/WNO.0000000000000846; Taib F, 2014, J TAIBAH UNIV MED SC, V9, P110, DOI 10.1016/j.jtumed.2013.12.002; Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173; Topol E, MD IS MACHINE DOCTOR; Wang ZF, 2022, Arxiv, DOI arXiv:2210.10163; Wiggins WF, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220119; Zafar S, 2019, BMC MED EDUC, V19, DOI 10.1186/s12909-019-1637-4	26	112	113	26	52	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-9145			OPHTHALMOL SCI	Ophthalmol. Sci.	DEC	2023	3	4							100324	10.1016/j.xops.2023.100324	http://dx.doi.org/10.1016/j.xops.2023.100324		JUN 2023	7	Ophthalmology	Emerging Sources Citation Index (ESCI)	Ophthalmology	K4OK5	37334036	Green Published, gold			2024-07-03	WOS:001016246200001
J	Steimetz, E; Minkowitz, J; Gabutan, EC; Ngichabe, J; Attia, H; Hershkop, M; Ozay, F; Hanna, MG; Gupta, R				Steimetz, Eric; Minkowitz, Jeremy; Gabutan, Elmer C.; Ngichabe, Joan; Attia, Hagar; Hershkop, Mordechai; Ozay, Fatih; Hanna, Matthew G.; Gupta, Raavi			Use of Artificial Intelligence Chatbots in Interpretation of Pathology Reports	JAMA NETWORK OPEN			English	Article							PATIENT; READABILITY	Importance Anatomic pathology reports are an essential part of health care, containing vital diagnostic and prognostic information. Currently, most patients have access to their test results online. However, the reports are complex and are generally incomprehensible to laypeople. Artificial intelligence chatbots could potentially simplify pathology reports. Objective To evaluate the ability of large language model chatbots to accurately explain pathology reports to patients. Design, Setting, and Participants This cross-sectional study used 1134 pathology reports from January 1, 2018, to May 31, 2023, from a multispecialty hospital in Brooklyn, New York. A new chat was started for each report, and both chatbots (Bard [Google Inc], hereinafter chatbot 1; GPT-4 [OpenAI], hereinafter chatbot 2) were asked in sequential prompts to explain the reports in simple terms and identify key information. Chatbot responses were generated between June 1 and August 31, 2023. The mean readability scores of the original and simplified reports were compared. Two reviewers independently screened and flagged reports with potential errors. Three pathologists reviewed the flagged reports and categorized them as medically correct, partially medically correct, or medically incorrect; they also recorded any instances of hallucinations. Main Outcomes and Measures Outcomes included improved mean readability scores and a medically accurate interpretation. Results For the 1134 reports included, the Flesch-Kincaid grade level decreased from a mean of 13.19 (95% CI, 12.98-13.41) to 8.17 (95% CI, 8.08-8.25; t = 45.29; P < .001) by chatbot 1 and 7.45 (95% CI, 7.35-7.54; t = 49.69; P < .001) by chatbot 2. The Flesch Reading Ease score was increased from a mean of 10.32 (95% CI, 8.69-11.96) to 61.32 (95% CI, 60.80-61.84; t = -63.19; P < .001) by chatbot 1 and 70.80 (95% CI, 70.32-71.28; t = -74.61; P < .001) by chatbot 2. Chatbot 1 interpreted 993 reports (87.57%) correctly, 102 (8.99%) partially correctly, and 39 (3.44%) incorrectly; chatbot 2 interpreted 1105 reports (97.44%) correctly, 24 (2.12%) partially correctly, and 5 (0.44%) incorrectly. Chatbot 1 had 32 instances of hallucinations (2.82%), while chatbot 2 had 3 (0.26%). Conclusions and Relevance The findings of this cross-sectional study suggest that artificial intelligence chatbots were able to simplify pathology reports. However, some inaccuracies and hallucinations occurred. Simplified reports should be reviewed by clinicians before distribution to patients.	[Steimetz, Eric; Minkowitz, Jeremy; Gabutan, Elmer C.; Ngichabe, Joan; Attia, Hagar; Ozay, Fatih; Gupta, Raavi] SUNY Downstate Med Ctr, Dept Pathol, 450 Clarkson Ave,MSC 25, Brooklyn, NY 11203 USA; [Hershkop, Mordechai] Lake Erie Coll Osteopath Med, Elmira, NY USA; [Hanna, Matthew G.] Mem Sloan Kettering Canc Ctr, Dept Pathol, New York, NY USA	State University of New York (SUNY) System; SUNY Downstate Health Sciences University; Memorial Sloan Kettering Cancer Center	Steimetz, E (corresponding author), SUNY Downstate Med Ctr, Dept Pathol, 450 Clarkson Ave,MSC 25, Brooklyn, NY 11203 USA.	eric.steimetz@downstate.edu						Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Amin A, 2021, VIRCHOWS ARCH, V479, P1021, DOI 10.1007/s00428-021-03155-w; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Badarudeen S, 2010, CLIN ORTHOP RELAT R, V468, P2572, DOI 10.1007/s11999-010-1380-y; Bonert M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0253876; Caranfa JT, 2023, JAMA OPHTHALMOL, V141, P906, DOI 10.1001/jamaophthalmol.2023.3314; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Goodman RS, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36483; Hughes TM, 2018, AM J SURG, V216, P7, DOI 10.1016/j.amjsurg.2018.01.011; Hutchinson N, 2016, AM J MED, V129, P637, DOI 10.1016/j.amjmed.2016.01.008; Joseph-Williams N, 2014, PATIENT EDUC COUNS, V94, P291, DOI 10.1016/j.pec.2013.10.031; Lyles CR, 2020, ANN INTERN MED, V172, pS123, DOI 10.7326/M19-0876; Marks M, 2023, JAMA-J AM MED ASSOC, V330, P309, DOI 10.1001/jama.2023.9458; Miles RC, 2019, RADIOLOGY, V291, P111, DOI 10.1148/radiol.2019182082; Prabhu AV, 2017, HUM PATHOL, V65, P15, DOI 10.1016/j.humpath.2017.04.020; Stormacq C, 2019, HEALTH PROMOT INT, V34, pE1, DOI 10.1093/heapro/day062; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Zhang Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/18725	19	0	0	0	0	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	MAY 22	2024	7	5							e2412767	10.1001/jamanetworkopen.2024.12767	http://dx.doi.org/10.1001/jamanetworkopen.2024.12767			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RV6I8	38776080	gold			2024-07-03	WOS:001230472100002
J	Lum, ZC; Collins, DP; Dennison, S; Guntupalli, L; Choudhary, S; Saiz, AM; Randall, RL				Lum, Zachary C.; Collins, Dylon P.; Dennison, Stanley; Guntupalli, Lohitha; Choudhary, Soham; Saiz, Augustine M.; Randall, Robert L.			Generative Artificial Intelligence Performs at a Second-Year Orthopedic Resident Level	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						oite; generative artificial intelligence; orthopaedic surgery; google bard; chatgpt		Introduction<br /> Artificial intelligence (AI) models using large language models (LLMs) and non-specific domains have gained attention for their innovative information processing. As AI advances, it's essential to regularly evaluate these tools' competency to maintain high standards, prevent errors or biases, and avoid flawed reasoning or misinformation that could harm patients or spread inaccuracies. Our study aimed to determine the performance of Chat Generative Pre -trained Transformer (ChatGPT) by OpenAI and Google BARD (BARD) in orthopedic surgery, assess performance based on question types, contrast performance between different AIs and compare AI performance to orthopedic residents. Methods We administered ChatGPT and BARD 757 Orthopedic In -Training Examination (OITE) questions. After excluding image -related questions, the AIs answered 390 multiple choice questions, all categorized within 10 sub -specialties (basic science, trauma, sports medicine, spine, hip and knee, pediatrics, oncology, shoulder and elbow, hand, and food and ankle) and three taxonomy classes (recall, interpretation, and application of knowledge). Statistical analysis was performed to analyze the number of questions answered correctly by each AI model, the performance returned by each AI model within the categorized question subspecialty designation, and the performance of each AI model in comparison to the results returned by orthopedic residents classified by their respective post -graduate year (PGY) level.<br /> Results<br /> BARD answered more overall questions correctly (58% vs 54%, p<0.001). ChatGPT performed better in sports medicine and basic science and worse in hand surgery, while BARD performed better in basic science (p<0.05). The AIs performed better in recall questions compared to the application of knowledge (p<0.05). Based on previous data, it ranked in the 42nd -96th percentile for post -graduate year ones (PGY1s), 27th58th for PGY2s, 3rd -29th for PGY3s, 1st -21st for PGY4s, and 1st -17th for PGY5s. Discussion ChatGPT excelled in sports medicine but fell short in hand surgery, while both AIs performed well in the basic science sub -specialty but performed poorly in the application of knowledge -based taxonomy questions. BARD performed better than ChatGPT overall. Although the AI reached the second -year PGY orthopedic resident level, it fell short of passing the American Board of Orthopedic Surgery (ABOS). Its strengths in recall -based inquiries highlight its potential as an orthopedic learning and educational tool.	[Lum, Zachary C.] Univ Calif UC Davis, Orthoped Surg, Sch Med, Sacramento, CA 95817 USA; [Lum, Zachary C.] Nova Southeastern Univ, Orthoped Surg, Pembroke Pines, FL 33024 USA; [Collins, Dylon P.; Dennison, Stanley] Nova Southeastern Univ, Dr Kiran C Patel Coll Osteopath Med, Coll Med, Ft Lauderdale, FL USA; [Guntupalli, Lohitha] Nova Southeastern Univ, Dr Kiran C Patel Coll Osteopath Med, Osteopath Med, Clearwater, FL 33759 USA; [Choudhary, Soham] Univ Calif Davis, Orthoped Surg, Davis, CA USA; [Saiz, Augustine M.; Randall, Robert L.] Univ Calif UC Davis Hlth, Orthoped Surg, Sacramento, CA USA	Nova Southeastern University; Nova Southeastern University; Nova Southeastern University; University of California System; University of California Davis	Lum, ZC (corresponding author), Univ Calif UC Davis, Orthoped Surg, Sch Med, Sacramento, CA 95817 USA.; Lum, ZC (corresponding author), Nova Southeastern Univ, Orthoped Surg, Pembroke Pines, FL 33024 USA.	zacharylum@gmail.com	Saiz, Augustine/GQI-4725-2022	Saiz, Augustine/0000-0002-1955-8667				Bharat C, 2021, LANCET DIGIT HEALTH, V3, pE397, DOI 10.1016/S2589-7500(21)00058-3; BUCKWALTER JA, 1981, J MED EDUC, V56, P115; Cohen M, 2023, EUR RADIOL, V33, P3974, DOI 10.1007/s00330-022-09349-3; Finlayson SG, 2021, NEW ENGL J MED, V385, P283, DOI 10.1056/NEJMc2104626; Frankel AO, 2022, MODERN PATHOL, V35, P1193, DOI 10.1038/s41379-022-01075-x; Fritz E, 2021, J AM ACAD ORTHOP SUR, V29, pE1370, DOI 10.5435/JAAOS-D-20-01019; Guerrero DT, 2023, AM SURGEON, V89, P49, DOI 10.1177/00031348221101503; Karnuta JM, 2023, J ARTHROPLASTY, V38, P1998, DOI 10.1016/j.arth.2022.03.002; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liu PR, 2021, CURR MED SCI, V41, P1158, DOI 10.1007/s11596-021-2501-4; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Luo Q, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1778562; Park L, 2023, CLIN EXP DERMATOL, V49, P733, DOI 10.1093/ced/llad355; Ramkumar PN, 2021, ARTHROSCOPY, V37, P1694, DOI 10.1016/j.arthro.2020.08.009; Swanson David, 2013, J Bone Joint Surg Am, V95, pe84, DOI 10.2106/JBJS.L.00457; Vaswani A, 2017, ADV NEUR IN, V30; Vedula SS, 2022, J AM COLL SURGEONS, V234, P1181, DOI 10.1097/XCS.0000000000000190	18	0	0	3	3	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAR 11	2024	16	3							e56104	10.7759/cureus.56104	http://dx.doi.org/10.7759/cureus.56104			9	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	OJ6W8	38618358	gold, Green Published			2024-07-03	WOS:001206952600009
J	García-Peñalvo, FJ				Garcia-Penalvo, Francisco Jose			The perception of Artificial Intelligence in educational contexts after the launch of ChatGPT: Disruption or Panic?	EDUCATION IN THE KNOWLEDGE SOCIETY			English	Article						ChatGPT; Artificial Intelligence; Education; Academia		The year 2022 has ended with one of those technological innovations that have a hard-to-predict behaviour, a black swan, hogging the limelight in traditional media and digital media. Indeed, it is ChatGPT. Although artificial intelligence had already been in the news and often masked under various other meanings, the ChatGPT phenomenon has once again brought this discipline and its positive and negative effects on our society to the forefront. Reactions to its launch, influenced mainly by its ease of access and use, have been varied, ranging from the enthusiasm of innova-tors and early adopters to the almost apocalyptic terror of the Terminator movie. Of the multiple applications of this tool, the most significant debate focuses on its implications in Education and Academia due to its tremendous power to generate texts that could very well pass for human creations. We are at the dawn of a technology that has gone from being a toy tool to bidding to become a disruptive innovation. Whether it succeeds or not will depend on many factors, but if it does not, it will be another one like it. Denying it or banning it will do absolutely nothing to stop the tsunami effect that has already begun. For all these reasons, we must first understand these technologies based on large language models and know their benefits and weaknesses, as well as what they really mean for a specific sector of activity, such as Education. After getting to know the technology and the tool, one would be in a position to use (or not) its potential and to prevent or detect its possible pernicious effects, presumably by changing and adapting processes that are probably profoundly rooted and that, therefore, forced to leave the comfort zone, which is always the cause of resistance to change and extreme reactions. These responses usually will not stop technology from reaching its productivity plateau when it becomes part of the daily life of a suffi-cient majority of users. This is always the cause of resistance to change and extreme reactions that will not usually stop technology from reaching its productivity plateau when it becomes part of the daily lives of a sufficient majority of users, especially when it is also a question of transversal tools that will spread their usage patterns among the different application domains.	[Garcia-Penalvo, Francisco Jose] Univ Salamanca, Dept Informat & Automat, Inst Ciencias Educ, Grp GRIAL, Salamanca, Spain	University of Salamanca	García-Peñalvo, FJ (corresponding author), Univ Salamanca, Dept Informat & Automat, Inst Ciencias Educ, Grp GRIAL, Salamanca, Spain.	fgarcia@usal.es	GARCÍA-PEÑALVO, Francisco José/D-5445-2013	GARCÍA-PEÑALVO, Francisco José/0000-0001-9987-5584				Alier-Forment M., 2023, Cabalga el Cometa; Area M, 2021, REICE-REV IBEROAM CA, V19, P83, DOI 10.15366/reice2021.19.4.005; Arrabal Platero P., 2022, OBJETIVOS DESARROLLO; Bowman Emma, 2022, NPR19 Dec; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Codina L., 2022, Como utilizar ChatGPT en el aula con perspectiva etica y pensamiento critico: Una proposicion para docentes y educadores; Comision Europea, 2021, Propuesta de Reglamento del Parlamento Europeo y del Consejo por el que se modifica el Reglamento (UE) n. 910/2014 en lo que respecta al establecimiento de un Marco para una Identidad Digital Europea; Confalonieri R, 2021, WIRES DATA MIN KNOWL, V11, DOI 10.1002/widm.1391; Cooper Kindra, 2021, Springboard; Cowen T., 2022, BLOOMBERG 1206; Dans E., 2023, ENRIQUE 0108; De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005; Diamandis P.H., 2015, Bold: How to go big, create wealth, and impact the world; European Commission, 2021, COM/2021/564 final; Fallahi S, 2023, BUS STRATEG ENVIRON, V32, P3233, DOI 10.1002/bse.3297; Fidalgo-Blanco A, 2022, RIED-REV IBEROAM EDU, V25, P49, DOI 10.5944/ried.25.2.32320; Flores-Vivar JM, 2023, COMUNICAR, V31, P37, DOI 10.3916/C74-2023-03; Garcia U., 2022, NO MIRES ARRIBA DISE; Garcia-Penalvo F.J., 2021, Radical solutions for education in a crisis context. Lecture notes in educational technology, P85, DOI [10.1007/978-981-15-7869-4_6, DOI 10.1007/978-981-15-7869-4_6]; García-Peñalvo FJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196964; Gartner, 2022, Top strategic technology trends for 2022: Cybersecurity mesh; Goldman S, 2022, WHY CHATGPT IS HAVIN; Grande-de-Prado M, 2021, CAMPUS VIRTUALES, V10, P49; Haenlein M, 2019, CALIF MANAGE REV, V61, P5, DOI 10.1177/0008125619864925; Herman D., 2022, ATLANTIS-SPAIN; García-Peñalvo FJ, 2021, INT J INTERACT MULTI, V6, P46, DOI 10.9781/ijimai.2021.05.005; García-Peñalvo FJ, 2021, EDUC KNOWL SOC, V22, DOI 10.14201/eks.25465; García-Peñalvo FJ, 2020, EDUC KNOWL SOC, V21, DOI 10.14201/eks.23013; Jyoti R., 2022, Worldwide Artificial Intelligence Software Forecast, 2022-2026, Patent No. 49571222; Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919; Khosravi H., 2022, Comput. Educ. Artif. Intell., V3, DOI [DOI 10.1016/J.CAEAI.2022.100074, 10.1016/j.caeai, DOI 10.1016/J.CAEAI]; Koper R., 2014, Smart Learning Environments, V1, DOI DOI 10.1186/S40561-014-0005-4; Krugman P., 2022, NEW YORK TIMES 1206; Lang C., 2022, HDB LEARNING ANAL, V2, DOI [10.18608/hla22, DOI 10.18608/HLA22]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Llorens-Largo F., 2022, CAVILACIONES INVERNA; Sein-Echaluce ML, 2022, UNIVERSAL ACCESS INF, DOI 10.1007/s10209-022-00945-0; Marche S., 2022, ATLANTIS-SPAIN; McGreal R., 2011, ISSUES OER; Miernicki M, 2021, AI SOC, V36, P319, DOI 10.1007/s00146-020-01027-6; Minsky M., 1998, COMMUNICATION; Miranda J, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107278; Tito FP, 2022, REV UNIV SOC, V14, P37; Pearl, 2022, CHATGPT CHATBOT OPEN; Punie Y., 2017, PUBLICATIONSOFFICEOF, DOI [10.2760/159770, DOI 10.2760/159770]; Qu JJ, 2022, SYST RES BEHAV SCI, V39, P581, DOI 10.1002/sres.2864; Ramrez-Montoya M. S., 2022, J. Open Innov.: Technol. Mark. Complex, V8, P4, DOI DOI 10.3390/JOITMC8010004; Muñoz JLR, 2022, EURASIAN J EDUC RES, P221, DOI 10.14689/ejer.2022.98.014; Roose K, 2022, The New York TimesDecember 5,; Ropek L., 2023, GIZMODO JANUARY 4; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7	51	54	55	25	469	EDICIONES UNIV SALAMANCA	SALAMANCA	APARTADO DE CORREOS 325, SALAMANCA, 00000, SPAIN	2444-8729			EDUC KNOWL SOC	Educ. Knowl. Soc.	FEB 6	2023	24								e31279	10.14201/eks.31279	http://dx.doi.org/10.14201/eks.31279			9	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	8R9GK		gold			2024-07-03	WOS:000928194700001
J	Safrai, M; Azaria, A				Safrai, Myriam; Azaria, Amos			Does small talk with a medical provider affect ChatGPT's medical counsel? Performance of ChatGPT on USMLE with and without distractions	PLOS ONE			English	Article							FERROPTOSIS; ACTIVATION; ACSL4	Efforts are being made to improve the time effectiveness of healthcare providers. Artificial intelligence tools can help transcript and summarize physician-patient encounters and produce medical notes and medical recommendations. However, in addition to medical information, discussion between healthcare and patients includes small talk and other information irrelevant to medical concerns. As Large Language Models (LLMs) are predictive models building their response based on the words in the prompts, there is a risk that small talk and irrelevant information may alter the response and the suggestion given. Therefore, this study aims to investigate the impact of medical data mixed with small talk on the accuracy of medical advice provided by ChatGPT. USMLE step 3 questions were used as a model for relevant medical data. We use both multiple-choice and open-ended questions. First, we gathered small talk sentences from human participants using the Mechanical Turk platform. Second, both sets of USLME questions were arranged in a pattern where each sentence from the original questions was followed by a small talk sentence. ChatGPT 3.5 and 4 were asked to answer both sets of questions with and without the small talk sentences. Finally, a board-certified physician analyzed the answers by ChatGPT and compared them to the formal correct answer. The analysis results demonstrate that the ability of ChatGPT-3.5 to answer correctly was impaired when small talk was added to medical data (66.8% vs. 56.6%; p = 0.025). Specifically, for multiple-choice questions (72.1% vs. 68.9%; p = 0.67) and for the open questions (61.5% vs. 44.3%; p = 0.01), respectively. In contrast, small talk phrases did not impair ChatGPT-4 ability in both types of questions (83.6% and 66.2%, respectively). According to these results, ChatGPT-4 seems more accurate than the earlier 3.5 version, and it appears that small talk does not impair its capability to provide medical recommendations. Our results are an important first step in understanding the potential and limitations of utilizing ChatGPT and other LLMs for physician-patient interactions, which include casual conversations.	[Safrai, Myriam] Tel Aviv Univ, Sackler Fac Med, Chaim Sheba Med Ctr Tel Hashomer, Dept Obstet & Gynecol, Tel Aviv, Israel; [Safrai, Myriam] Univ Pittsburgh, Sch Med, Magee Womens Res Inst, Dept Obstet Gynecol & Reprod Sci, Pittsburgh, PA USA; [Azaria, Amos] Ariel Univ, Sch Comp Sci, Ariel, Israel	Tel Aviv University; Chaim Sheba Medical Center; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Magee-Womens Research Institute; Ariel University	Azaria, A (corresponding author), Ariel Univ, Sch Comp Sci, Ariel, Israel.	amos.azaria@ariel.ac.il		Safrai, Myriam/0000-0002-7979-1655	Ministry of Science and Technology, Israel; Ministry of Science and Technology, Israel	Ministry of Science and Technology, Israel(Ministry of Science, Technology and Space (MOST), Israel); Ministry of Science and Technology, Israel(Ministry of Science, Technology and Space (MOST), Israel)	This work was supported, in part, but the Ministry of Science and Technology, Israel.	Byrne RA, 2023, EUR HEART J, V44, P3720, DOI 10.1093/eurheartj/ehad191; Nguyen CN, 2013, PHYTOTHER RES, V27, P1810, DOI 10.1002/ptr.4931; Chatterjee S, 2012, AM J PHYSIOL-HEART C, V302, pH105, DOI 10.1152/ajpheart.00298.2011; Davidson SM, 2019, J AM COLL CARDIOL, V73, P89, DOI 10.1016/j.jacc.2018.09.086; Ding CG, 2020, CELL DEATH DIS, V11, DOI 10.1038/s41419-020-03135-z; Dodson M, 2019, REDOX BIOL, V23, DOI 10.1016/j.redox.2019.101107; Fang XX, 2023, NAT REV CARDIOL, V20, P7, DOI 10.1038/s41569-022-00735-4; Fang XX, 2019, P NATL ACAD SCI USA, V116, P2672, DOI 10.1073/pnas.1821022116; Ghafouri-Fard S, 2022, MOL BIOL REP, V49, P9767, DOI 10.1007/s11033-022-07468-0; Heusch G, 2017, EUR HEART J, V38, P774, DOI 10.1093/eurheartj/ehw224; Hwang YP, 2010, TOXICOL APPL PHARM, V242, P18, DOI 10.1016/j.taap.2009.09.009; Kim R, 2022, NATURE, V612, P338, DOI 10.1038/s41586-022-05443-0; Li DS, 2020, SIGNAL TRANSDUCT TAR, V5, DOI 10.1038/s41392-020-00216-5; Li HL, 2018, FREE RADICAL BIO MED, V120, P228, DOI 10.1016/j.freeradbiomed.2018.03.014; Liu MN, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e20026; Liu MN, 2021, PHYTOMEDICINE, V86, DOI 10.1016/j.phymed.2021.153566; Liu SX, 2012, INT J CARDIOL, V160, P95, DOI 10.1016/j.ijcard.2011.03.033; Liu XJ, 2021, FEBS OPEN BIO, V11, P2966, DOI 10.1002/2211-5463.13276; Mair J, 1997, CRIT REV CL LAB SCI, V34, P1, DOI 10.3109/10408369709038215; Partridge L, 2018, NATURE, V561, P45, DOI 10.1038/s41586-018-0457-8; Shen YM, 2019, INT J BIOL MACROMOL, V125, P496, DOI 10.1016/j.ijbiomac.2018.11.190; Shin D, 2018, FREE RADICAL BIO MED, V129, P454, DOI 10.1016/j.freeradbiomed.2018.10.426; Stockwell BR, 2017, CELL, V171, P273, DOI 10.1016/j.cell.2017.09.021; Suzuki T, 2013, TRENDS PHARMACOL SCI, V34, P340, DOI 10.1016/j.tips.2013.04.005; Vara JAF, 2004, CANCER TREAT REV, V30, P193, DOI 10.1016/j.ctrv.2003.07.007; Yi JM, 2020, P NATL ACAD SCI USA, V117, P31189, DOI 10.1073/pnas.2017152117; Yuan H, 2016, BIOCHEM BIOPH RES CO, V478, P1338, DOI 10.1016/j.bbrc.2016.08.124; Zhang HL, 2022, NAT CELL BIOL, V24, P88, DOI 10.1038/s41556-021-00818-3; Zhang XY, 2020, CARDIOL RES PRACT, V2020, DOI 10.1155/2020/5695723; Zhao SK, 2021, CANCER CELL INT, V21, DOI 10.1186/s12935-021-02264-5; Zuin M, 2023, EUR J PREV CARDIOL, V30, P1758, DOI 10.1093/eurjpc/zwad214	31	0	0	0	0	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	APR 30	2024	19	4							e0302217	10.1371/journal.pone.0302217	http://dx.doi.org/10.1371/journal.pone.0302217			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	PL0B3	38687696				2024-07-03	WOS:001214105000025
J	Huang, Y; Wu, RP; He, JT; Xiang, YP				Huang, Yeen; Wu, Ruipeng; He, Juntao; Xiang, Yingping			Evaluating ChatGPT-4.0's data analytic proficiency in epidemiological studies: A comparative analysis with SAS, SPSS, and R	JOURNAL OF GLOBAL HEALTH			English	Article							STATISTICAL-METHODS; SCIENCE	Background OpenAI's Chat Generative Pre -trained Transformer 4.0 (ChatGPT-4), an emerging artificial intelligence (AI) -based large language model (LLM), has been receiving increasing attention from the medical research community for its innovative 'Data Analyst' feature. We aimed to compare the capabilities of ChatGPT-4 against traditional biostatistical software (i.e. SAS, SPSS, R) in statistically analysing epidemiological research data. Methods We used a data set from the China Health and Nutrition Survey, comprising 9317 participants and 29 variables (e.g. gender, age, educational level, marital status, income, occupation, weekly working hours, survival status). Two researchers independently evaluated the data analysis capabilities of GPT-4's 'Data Analyst' feature against SAS, SPSS, and R across three commonly used epidemiological analysis methods: Descriptive statistics, intergroup analysis, and correlation analysis. We used an internally developed evaluation scale to assess and compare the consistency of results, analytical efficiency of coding or operations, user -friendliness, and overall performance between ChatGPT-4, SAS, SPSS, and R. Results In descriptive statistics, ChatGPT-4 showed high consistency of results, greater analytical efficiency of code or operations, and more intuitive user -friendliness compared to SAS, SPSS, and R. In intergroup comparisons and correlational analyses, despite minor discrepancies in statistical outcomes for certain analysis tasks with SAS, SPSS, and R, ChatGPT-4 maintained high analytical efficiency and exceptional user -friendliness. Thus, employing ChatGPT-4 can significantly lower the operational threshold for conducting epidemiological data analysis while maintaining consistency with traditional biostatistical software's outcome, requiring only specific, clear analysis instructions without any additional operations or code writing. Conclusions We found ChatGPT-4 to be a powerful auxiliary tool for statistical analysis in epidemiological research. However, it showed limitations in result consistency and in applying more advanced statistical methods. Therefore, we advocate for the use of ChatGPT-4 in supporting researchers with intermediate experience in data analysis. With AI technologies like LLMs advancing rapidly, their integration with data analysis platforms promises to lower operational barriers, thereby enabling researchers to dedicate greater focus to the nuanced interpretation of analysis results. This development is likely to significantly advance epidemiological and medical research.	[Huang, Yeen] Southern Univ Sci & Technol, Sch Publ Hlth & Emergency Management, Shenzhen, Guangdong, Peoples R China; [Wu, Ruipeng] Xizang Minzu Univ, Sch Med, Key Lab Mol Genet Mech & Intervent Res, High Altitude Dis Tibet Autonomous Reg, Xianyang, Xizang, Peoples R China; [Wu, Ruipeng] Xizang Minzu Univ, Sch Med, Key Lab High Altitude Hypoxia Environm & Life Hlth, Xianyang, Xizang, Peoples R China; [Wu, Ruipeng] Southeast Univ, Sch Publ Hlth, Dept Nutr & Food Hyg, Key Lab Environm Med & Engn,Minist Educ, Nanjing, Jiangsu, Peoples R China; [He, Juntao] Shenzhen Prevent & Treatment Ctr Occupat Dis, Phys & Chem Testing Inst, Shenzhen, Guangdong, Peoples R China; [Xiang, Yingping] Shenzhen Prevent & Treatment Ctr Occupat Dis, Occupat Hazard Assessment Inst, Shenzhen, Guangdong, Peoples R China; [Huang, Yeen] Southern Univ Sci & Technol, Sch Publ Hlth & Emergency Management, 1088 Xueyuan Ave, Shenzhen 518055, Peoples R China	Southern University of Science & Technology; Xizang Minzu University; Xizang Minzu University; Southeast University - China; Southern University of Science & Technology	Huang, Y (corresponding author), Southern Univ Sci & Technol, Sch Publ Hlth & Emergency Management, 1088 Xueyuan Ave, Shenzhen 518055, Peoples R China.	huangye@sustech.edu.cn		Huang, Yeen/0009-0004-8524-043X	Shenzhen Science and Technology Program [JCYJ20220531091212028]	Shenzhen Science and Technology Program	Funding: This work was supported by grants from the Shenzhen Science and Technology Program (Grant No. JCYJ20220531091212028) . The funder had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.	Altma S, 2023, REPROD BIOMED ONLINE, V47, P3, DOI 10.1016/j.rbmo.2023.04.009; Armitage R, 2024, LANCET INFECT DIS, V24, pe155, DOI 10.1016/S1473-3099(24)00028-8; Bassi S, 2007, PLOS COMPUT BIOL, V3, P2052, DOI 10.1371/journal.pcbi.0030199; Cai XB, 2024, METHODS, V222, P133, DOI 10.1016/j.ymeth.2024.01.004; Carolina Population Center University of North Carolina at Chapel Hill, China Health and Nutrition Survey.; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Eppler M, 2024, EUR UROL, V85, P146, DOI 10.1016/j.eururo.2023.10.014; Eppler MB, 2023, UROL PRACT, V10, P435, DOI 10.1097/UPJ.0000000000000428; Extance A, 2023, NATURE, V623, P474, DOI 10.1038/d41586-023-03507-3; Farhat F, 2024, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1270749; Ganjavi C, 2024, BMJ-BRIT MED J, V384, DOI 10.1136/bmj-2023-077192; Giuffrè M, 2024, CLIN GASTROENTEROL H, V22, P1145, DOI 10.1016/j.cgh.2023.09.035; Guillaudeux M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00771-5; Han Soyul, 2023, J Minim Invasive Surg, V26, P167, DOI 10.7602/jmis.2023.26.4.167; Hodges CB, 2023, BEHAV RES METHODS, V55, P2813, DOI 10.3758/s13428-022-01932-2; Kantor Jonathan, 2024, JAAD Int, V14, P22, DOI 10.1016/j.jdin.2023.10.001; Khlaif ZN, 2023, JMIR MED EDUC, V9, DOI [10.2023/1/e47049, 10.2196/47049]; Kilinc DD, 2024, Am J Orthod Dentofacial Orthop.; Kim HW, 2024, SEIZURE-EUR J EPILEP, V114, P1, DOI 10.1016/j.seizure.2023.11.013; Kjell ONE, 2024, PSYCHIAT RES, V333, DOI 10.1016/j.psychres.2023.115667; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li X, 2023, ENVIRON INT, V175, DOI 10.1016/j.envint.2023.107953; Lin SL, 2024, NAT PROTOC, V19, DOI 10.1038/s41596-023-00925-5; Lockstone HE, 2011, BRIEF BIOINFORM, V12, P634, DOI 10.1093/bib/bbq086; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Masuadi E, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.12639; Mehtälä J, 2023, BMC MED RES METHODOL, V23, DOI 10.1186/s12874-023-02082-5; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mukherjee P, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.231147; Ong JCL, 2024, CELL REP MED, V5, DOI 10.1016/j.xcrm.2023.101356; Open AI, 2023, GPT-4 Technical Report; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Rahimi F, 2023, ARCH MED RES, V54, P272, DOI 10.1016/j.arcmed.2023.03.004; Razdan S, 2023, INT J IMPOT RES, DOI 10.1038/s41443-023-00797-z; Rigby AS, 2000, DISABIL REHABIL, V22, P813, DOI 10.1080/09638280050207857; Rigby AS, 2001, DISABIL REHABIL, V23, P693, DOI 10.1080/09638280110060457; Rigby AS, 1998, DISABIL REHABIL, V20, P121, DOI 10.3109/09638289809166071; Rigby AS, 1999, DISABIL REHABIL, V21, P145, DOI 10.1080/096382899297756; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; SCHOSSER R, 1990, COMPUT BIOL MED, V20, P445, DOI 10.1016/0010-4825(90)90025-K; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Van Noorden R, 2023, NATURE, V624, P509, DOI 10.1038/d41586-023-03930-6; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; Wang XF, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100905; Yuan Y, 2024, CLIN EXP HYPERTENS, V46, DOI 10.1080/10641963.2024.2303999; Zhang HH, 2024, BIOINFORMATICS, V40, DOI 10.1093/bioinformatics/btae053; Zou Mengxuan, 2023, Lancet, V402 Suppl 1, pS99, DOI 10.1016/S0140-6736(23)02142-6; Zou Z, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-024-53255-1	49	2	2	16	16	INT SOC GLOBAL HEALTH	EDINBURGH	CALEDONIAN EXCHANGE, 19A CANNING ST, EDINBURGH, Lothian, ENGLAND	2047-2978	2047-2986		J GLOB HEALTH	J. Glob. Health		2024	14								04070	10.7189/jogh.14.04070	http://dx.doi.org/10.7189/jogh.14.04070			10	Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Public, Environmental & Occupational Health	MO4A5	38547497	Green Accepted			2024-07-03	WOS:001194538100001
J	Holderried, F; Stegemann-Philipps, C; Herschbach, L; Moldt, JA; Nevins, A; Griewatz, J; Holderried, M; Herrmann-Werner, A; Festl-Wietek, T; Mahling, M				Holderried, Friederike; Stegemann-Philipps, Christian; Herschbach, Lea; Moldt, Julia-Astrid; Nevins, Andrew; Griewatz, Jan; Holderried, Martin; Herrmann-Werner, Anne; Festl-Wietek, Teresa; Mahling, Moritz			A Generative Pretrained Transformer (GPT)-Powered Chatbot as a Simulated Patient to Practice History Taking: Prospective, Mixed Methods Study	JMIR MEDICAL EDUCATION			English	Article						simulated patient; GPT; generative pretrained transformer; ChatGPT; history taking; medical education; documentation; history; simulated; simulation; simulations; NLP; natural language processing; artificial intelligence; interactive; chatbot; chatbots; conversational agent; conversational agents; answer; answers; response; responses; human computer; human machine; usability; satisfaction	COMMUNICATION-SKILLS; STANDARDIZED-PATIENT; MEDICAL-EDUCATION; STUDENTS	Background: Communication is a core competency of medical professionals and of utmost importance for patient safety. Although medical curricula emphasize communication training, traditional formats, such as real or simulated patient interactions, can present psychological stress and are limited in repetition. The recent emergence of large language models (LLMs), such as generative pretrained transformer (GPT), offers an opportunity to overcome these restrictions Objective: The aim of this study was to explore the feasibility of a GPT-driven chatbot to practice history taking, one of the core competencies of communication. Methods: We developed an interactive chatbot interface using GPT-3.5 and a specific prompt including a chatbot-optimized illness script and a behavioral component. Following a mixed methods approach, we invited medical students to voluntarily practice history taking. To determine whether GPT provides suitable answers as a simulated patient, the conversations were recorded and analyzed using quantitative and qualitative approaches. We analyzed the extent to which the questions and answers aligned with the provided script, as well as the medical plausibility of the answers. Finally, the students filled out the Chatbot Usability Questionnaire (CUQ). Results: A total of 28 students practiced with our chatbot (mean age 23.4, SD 2.9 years). We recorded a total of 826 question-answer pairs (QAPs), with a median of 27.5 QAPs per conversation and 94.7% (n=782) pertaining to history taking. When questions were explicitly covered by the script (n=502, 60.3%), the GPT-provided answers were mostly based on explicit script information (n=471, 94.4%). For questions not covered by the script (n=195, 23.4%), the GPT answers used 56.4% (n=110) fictitious information. Regarding plausibility, 842 (97.9%) of 860 QAPs were rated as plausible. Of the 14 (2.1%) implausible answers, GPT provided answers rated as socially desirable, leaving role identity, ignoring script information, illogical reasoning, and calculation error. Despite these results, the CUQ revealed an overall positive user experience (77/100 points). Conclusions: Our data showed that LLMs, such as GPT, can provide a simulated patient experience and yield a good user experience and a majority of plausible answers. Our analysis revealed that GPT-provided answers use either explicit script information or are based on available information, which can be understood as abductive reasoning. Although rare, the GPT-based chatbot provides implausible information in some instances, with the major tendency being socially desirable instead of medically plausible information.	[Holderried, Friederike; Stegemann-Philipps, Christian; Herschbach, Lea; Moldt, Julia-Astrid; Griewatz, Jan; Herrmann-Werner, Anne; Festl-Wietek, Teresa; Mahling, Moritz] Eberhard Karls Univ Tubingen, Tubingen Inst Med Educ, Tubingen, Germany; [Nevins, Andrew] Stanford Univ, Sch Med, Div Infect Dis, Stanford, CA USA; [Holderried, Martin] Univ Hosp Tubingen, Dept Med Dev Proc & Qual Management, Tubingen, Germany; [Mahling, Moritz] Univ Hosp Tubingen, Dept Diabetol, Sect Nephrol & Hypertens, Endocrinol,Nephrol, Tubingen, Germany; [Holderried, Friederike] Eberhard Karls Univ Tubingen, Tubingen Inst Med Educ, Elfriede Aulhorn Str 10, D-72076 Tubingen, Germany	Eberhard Karls University of Tubingen; Stanford University; Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Eberhard Karls University of Tubingen; Eberhard Karls University Hospital; Eberhard Karls University of Tubingen	Holderried, F (corresponding author), Eberhard Karls Univ Tubingen, Tubingen Inst Med Educ, Elfriede Aulhorn Str 10, D-72076 Tubingen, Germany.	friederike.holderried@med.uni-tuebingen.de	Moldt, Julia Astrid/HTL-2476-2023	Moldt, Julia Astrid/0000-0002-2418-150X; Griewatz, Jan/0000-0002-9731-3171; Stegemann-Philipps, Christian/0000-0002-8122-5724; Herschbach, Lea/0009-0005-6378-5073	University of Tubingen	University of Tubingen	We acknowledge the support of the Open Access Publishing Fund of the University of Tubingen. We thank Eric Nazarenus for his assistance in performing the analysis.	Ali R, 2023, NEUROSURGERY, V93, P1353, DOI 10.1227/neu.0000000000002632; [Anonymous], Welcome to the OpenAI developer platform; [Anonymous], 2022, Wayback Machine; Bachmann C, 2022, PATIENT EDUC COUNS, V105, P2320, DOI 10.1016/j.pec.2021.11.016; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Borowczyk M, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04533-5; Bosse HM, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0468-1; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown J, 2008, MED EDUC, V42, P271, DOI 10.1111/j.1365-2923.2007.02955.x; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chung K, 2019, CLUSTER COMPUT, V22, P1925, DOI 10.1007/s10586-018-2334-5; de Haes H, 2009, PATIENT EDUC COUNS, V74, P287, DOI 10.1016/j.pec.2008.12.006; Deveugele M, 2005, PATIENT EDUC COUNS, V58, P265, DOI 10.1016/j.pec.2005.06.004; Espejel J.L., 2023, Nat. Lang. Process. J, V5, P100032, DOI DOI 10.1016/J.NLP.2023.100032; Fagin R., 2004, Reasoning About Knowl- edge; Frangoudes Fotos, 2021, Learning and Collaboration Technologies Games and Virtual Environments for Learning. 8th International Conference, LCT 2021. Held as Part of the 23rd HCI International Conference, HCII 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12785), P170, DOI 10.1007/978-3-030-77943-6_11; GALOTTI KM, 1989, PSYCHOL BULL, V105, P331, DOI 10.1037/0033-2909.105.3.331; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goold SD, 1999, J GEN INTERN MED, V14, pS26, DOI 10.1046/j.1525-1497.1999.00267.x; Hausberg MC, 2012, BMC MED EDUC, V12, DOI 10.1186/1472-6920-12-16; Holmes S, Chatbot Usability Questionnaire (CUQ) Calculation Tool; Holmes S.Y., 2011, Serious Educational Game Assessment, DOI 10.1007/978-94-6091-329-7_11; Holmes S, 2023, LECT NOTES COMPUT SC, V14033, P321, DOI 10.1007/978-3-031-35708-4_24; Holmes S, 2019, PROCEEDINGS OF THE 31ST EUROPEAN CONFERENCE ON COGNITIVE ERGONOMICS: DESIGN FOR COGNITION (ECCE 2019), P207, DOI 10.1145/3335082.3335094; Huang J, 2023, FINDINGS ASS COMPUTA, P1049, DOI [DOI 10.18653/V1/2023.FINDINGS-ACL.67, 10.18653/v1/2023.findings-acl.67]; Huang JT, 2024, Arxiv, DOI arXiv:2308.03656; Huang JT, 2023, Arxiv, DOI arXiv:2305.19926; Jani KH, 2020, MED EDUC, V54, P1159, DOI 10.1111/medu.14347; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jovanovic M, 2021, IEEE INTERNET COMPUT, V25, P44, DOI 10.1109/MIC.2020.3037151; Kaplonyi J, 2017, MED EDUC, V51, P1209, DOI 10.1111/medu.13387; Keifenheim KE, 2015, BMC MED EDUC, V15, DOI 10.1186/s12909-015-0443-x; Lee J, 2020, MED EDUC, V54, P786, DOI 10.1111/medu.14152; Liaw SY, 2023, NURS EDUC TODAY, V122, DOI 10.1016/j.nedt.2023.105718; Maicher K, 2017, SIMUL HEALTHC, V12, P124, DOI 10.1097/SIH.0000000000000195; McHugh C, 2018, MIND, V127, P167, DOI 10.1093/mind/fzw068; McNaughton N, 1999, TEACH LEARN MED, V11, P135, DOI 10.1207/S15328015TL110303; Moldt JA, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2182659; Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619871808; Noble LM, 2018, PATIENT EDUC COUNS, V101, P1712, DOI 10.1016/j.pec.2018.04.013; Palsson R, 2007, EUR J INTERN MED, V18, P104, DOI 10.1016/j.ejim.2006.10.002; Paradis E, 2017, MED EDUC, V51, P31, DOI 10.1111/medu.13122; Pottle Jack, 2019, Future Healthc J, V6, P181, DOI 10.7861/fhj.2019-0036; R Core Team, 2023, R: A Language and Environment for Statistical Computing; Serapio-Garcia G, 2023, Research Square; Singh U, 2023, 2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI, P205, DOI 10.1109/CAI54212.2023.00097; Stamer T, 2023, J MED INTERNET RES, V25, DOI 10.2196/43311; STEWART MA, 1995, CAN MED ASSOC J, V152, P1423; Street RL, 2009, PATIENT EDUC COUNS, V74, P295, DOI 10.1016/j.pec.2008.11.015; Tavarnesi G, CEUR-WS; ten Cate O., 2017, PRINCIPLES PRACTICE, P35, DOI DOI 10.1007/978-3-319-64828-6_3; von Fragstein M, 2008, Med Educ, V42, P1100, DOI DOI 10.1111/J.1365-2923.2008.03137.X; Wason P. C., 1972, PSYCHOL REASONING ST; WASON PC, 1968, Q J EXP PSYCHOL, V20, P273, DOI 10.1080/14640746808400161; Al Jabri FYM, 2021, NURS HEALTH SCI, V23, P87, DOI 10.1111/nhs.12804	56	0	0	16	16	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2024	10								e53961	10.2196/53961	http://dx.doi.org/10.2196/53961			18	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	IJ8N7	38227363	gold			2024-07-03	WOS:001166050200002
J	Mondragon-Estrada, E; Kirschning, I; Nolazco-Flores, JA; Camacho-Zuniga, C				Mondragon-Estrada, Enrique; Kirschning, Ingrid; Nolazco-Flores, Juan Arturo; Camacho-Zuniga, Claudia			Fostering digital transformation in education: technology enhanced learning from professors' experiences in emergency remote teaching	FRONTIERS IN EDUCATION			English	Article						information and communication technologies; higher education; technology enhanced learning; educational innovation; digital transformation in education; faculty experiences; emergency remote teaching	STUDENTS	In this work, we aim to understand professors' perception of the key competences as well as the best educational strategies and technological tools to guide digital transformation (DT) in education, according to their experience in emergency remote teaching (ERT). In recent years, technological advancement has driven DT in many areas, with education being among them. ERT due to COVID-19 accelerated this transition. Restrictions and lockdowns forced higher education institutions to adopt remote teaching strategies and tools suited for a digital environment. We surveyed 100 professors from a private Mexican university with 15-month experience of online ERT. We asked them through Likert scale questions to self-evaluate their performance and whether they perceived it to be better in online or hybrid environments compared with face-to-face environments in different aspects. We performed correlation, cluster, and factor analysis to identify the relationships and patterns in their answers. Through open-ended questions, we also asked the participants about the challenges and achievements they experienced, and the educational strategies and technological tools they successfully incorporated during ERT. We also conducted text mining to extract the most relevant information from these answers and validated that they were not polarized with negative sentiment using a large language model. Our results showed social intelligence as an underlying competence for teaching performance was highlighted in the digital environment due to the physical interaction limitations. Participants found success in implementing information and communication technologies, resulting in maintaining student interest and building trust in the online environment. Professors recognized the relevance not only of learning management systems and communication platforms, as expected, but also hardware such as tablets, cameras, and headphones for the successful delivery of education in a digital environment. Technology Enhanced Learning transposes game-based, quizzing practices, and collaborative learning to digital environments. Furthermore, the professors recommended learning-by-doing, flipped learning, problem-based learning, game-based learning, and holistic education as some pedagogical methodologies that were successfully applied in ERT and could be implemented for DT. Understanding the gains concerning teaching learning strategies and technologies that were incorporated during ERT is of the utmost importance for driving DT and its benefits for current and future education.	[Mondragon-Estrada, Enrique; Camacho-Zuniga, Claudia] Sch Engn & Sci Tecnol Monterrey, Monterrey, Mexico; [Kirschning, Ingrid] Univ Americas Puebla, Sch Engn, Cholula, Mexico; [Nolazco-Flores, Juan Arturo; Camacho-Zuniga, Claudia] Inst Future Educ, Tecnol Monterrey, Monterrey, Mexico	Tecnologico de Monterrey; Universidad Americas Puebla (UDLAP); Tecnologico de Monterrey	Camacho-Zuniga, C (corresponding author), Sch Engn & Sci Tecnol Monterrey, Monterrey, Mexico.; Camacho-Zuniga, C (corresponding author), Inst Future Educ, Tecnol Monterrey, Monterrey, Mexico.	claudia.camacho@tec.mx	Nolazco-Flores, Juan Arturo/GLU-4720-2022	Nolazco-Flores, Juan Arturo/0000-0002-4187-9352; Mondragon-Estrada, Enrique/0009-0004-5592-1728	The authors would like to acknowledge the support of the Writing Lab, Institute for the Future of Education, Tecnologico de Monterrey, Mexico, in the production of this work.; Institute for the Future of Education, Tecnologico de Monterrey, Mexico	The authors would like to acknowledge the support of the Writing Lab, Institute for the Future of Education, Tecnologico de Monterrey, Mexico, in the production of this work.; Institute for the Future of Education, Tecnologico de Monterrey, Mexico	The authors would like to acknowledge the support of the Writing Lab, Institute for the Future of Education, Tecnologico de Monterrey, Mexico, in the production of this work.	Abbas A, 2022, EDUC INF TECHNOL, V27, P12049, DOI 10.1007/s10639-022-11119-z; Abelha M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12155900; Ahmad UNU, 2012, PROCD SOC BEHV, V40, P182, DOI 10.1016/j.sbspro.2012.03.179; Akour M, 2022, EDUC SCI, V12, DOI 10.3390/educsci12110784; Alenezi M, 2023, EDUC SCI, V13, DOI 10.3390/educsci13010088; [Anonymous], 2014, Handbook of Research on Educational Communications and Technology; Archambault L, 2022, EDUC PSYCHOL-US, V57, P178, DOI 10.1080/00461520.2022.2051513; Banyoi V, 2023, ARAB WORLD ENGL J, P75, DOI 10.24093/awej/comm1.6; Basilotta-Gómez-Pablos V, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-021-00312-8; Bhebhe S., 2023, INT J LEARN TEACH ED, V22, P1, DOI [10.26803/ijlter.22.2.1, DOI 10.26803/IJLTER.22.2.1]; Blau I, 2020, INTERNET HIGH EDUC, V45, DOI 10.1016/j.iheduc.2019.100722; Bond M, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00282-x; Bradberry LA, 2019, J POLITICAL SCI EDUC, V15, P94, DOI 10.1080/15512169.2018.1485571; Bygstad B, 2022, COMPUT EDUC, V182, DOI 10.1016/j.compedu.2022.104463; Camacho-Zuñiga C, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1197396; Benavides LMC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113291; Coleman M., 2018, Online Journal of Distance Learning Administration, V21; Cueva A, 2022, EDUC SCI, V12, DOI 10.3390/educsci12030207; Daher W., 2021, Emerging Science Journal, V5, P545, DOI DOI 10.28991/ESJ-2021-01296; Danish SM, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN AND CRYPTOCURRENCY (IEEE ICBC), DOI [10.1007/s11125-020-09464-3, 10.1109/icbc48266.2020.9169419]; Dontre AJ, 2021, HUM BEHAV EMERG TECH, V3, P379, DOI 10.1002/hbe2.229; Dunn TJ, 2019, COMPUT EDUC, V137, P104, DOI 10.1016/j.compedu.2019.04.004; Ehlers U.-D., 2021, FUTURE SKILLS FUTURE; El Miedany Y., 2019, Rheumatology Teaching, P285; Fan LZ, 2023, Arxiv, DOI [arXiv:2304.02020, DOI 10.48550/ARXIV.2304.02020]; Feerick E, 2022, IRISH EDUC STUD, V41, P27, DOI 10.1080/03323315.2021.2022521; Fernández A, 2023, EDUC INF TECHNOL, V28, P12351, DOI 10.1007/s10639-022-11544-0; Galperin H, 2017, Digital society: gaps and challenges for digital inclusion in Latin America and the Caribbean; García-Morales VJ, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.616059; Artacho EG, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12072852; George G, 2021, ASIAN EDUC DEV STUD, V10, P565, DOI 10.1108/AEDS-04-2020-0054; Giang N.T.P., 2020, Advances in information and communication, P55, DOI DOI 10.1007/978-3-030-39442-4_5; Golden J., 2020, Journal of Accounting Education, V52, DOI DOI 10.1016/J.JACCEDU.2020.100671; Gorjón L, 2023, J EDUC COMPUT RES, V61, P723, DOI 10.1177/07356331221133408; Hodges C., 2020, Educause Review; Instituto Tecnologico y de Estudios Superiores de Monterrey, 2018, TEC 21 ED MOD; Itten R, 2020, INT J LIFE CYCLE ASS, V25, P2093, DOI 10.1007/s11367-020-01801-0; Khan N, 2022, KNOWL MANAG E-LEARN, V14, P46, DOI 10.34105/j.kmel.2022.14.004; Klein M., 2020, Business and Management Studies: An International Journal, V8, P883, DOI [10.15295/bmij.v8i1.1441, DOI 10.15295/BMIJ.V8I1.1441]; Kraus S, 2022, INT J INFORM MANAGE, V63, DOI 10.1016/j.ijinfomgt.2021.102466; Kraus S, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211047576; Krouska A, 2022, EDUC INF TECHNOL, V27, P229, DOI 10.1007/s10639-021-10672-3; Kumar V, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132413642; Llerena-Izquierdo Joe, 2021, Information Technology and Systems. ICITS 2021. Advances in Intelligent Systems and Computing (AISC 1331), P90, DOI 10.1007/978-3-030-68418-1_10; Ludvigsen S.R., 2010, INT ENCY ED, P290, DOI [10.1016/B978-0-08-044894-7.00493-0, DOI 10.1016/B978-0-08-044894-7.00493-0]; Maechler Martin, 2023, CRAN; Mamani N. M., 2021, 2021 INT S COMPUTERS, P1, DOI DOI 10.1109/SIIE53363; Pérez JM, 2022, Arxiv, DOI [arXiv:2111.09453, DOI 10.48550/ARXIV.2111.09453]; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Mhlanga D, 2022, EDUC SCI, V12, DOI 10.3390/educsci12070464; Miller J.P., 2019, The holistic curriculum, V3rd; Miranda J, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107278; Miseliunaite B, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14159737; Misirlis N., 2023, ANAL TECHNOLOGY ACCE, V2302, P02176, DOI [10.48550/ARXIV.2302.02176, DOI 10.48550/ARXIV.2302.02176]; Mondragon-Estrada E, 2021, 2021 MACHINE LEARNING-DRIVEN DIGITAL TECHNOLOGIES FOR EDUCATIONAL INNOVATION WORKSHOP, DOI 10.1109/IEEECONF53024.2021.9733773; de Oca SM, 2021, 2021 MACHINE LEARNING-DRIVEN DIGITAL TECHNOLOGIES FOR EDUCATIONAL INNOVATION WORKSHOP, DOI 10.1109/IEEECONF53024.2021.9733778; Moust J., 2021, Introduction to problem based learning; Olimov S.S., 2022, Pioneer: Journal of Advanced Research and Scientific Progress, V1, P17; Orak SD., 2021, International Online Journal of Education and Teaching, V8, P975; Peimani N, 2021, EDUC SCI, V11, DOI 10.3390/educsci11020072; Perez J. M., 2021, PYSENTIMIENTO PYTHON, V2106, P09462, DOI [10.48550/ARXIV.2106.09462, DOI 10.48550/ARXIV.2106.09462]; Perez-Poch A., 2016, 2016 IEEE FRONT ED C, P1; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Pozas M, 2023, TECHNOL KNOWL LEARN, V28, P823, DOI 10.1007/s10758-021-09551-0; Pozo-Rico T, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17228633; Pradhan S, 2022, J CHEM EDUC, V99, P3007, DOI 10.1021/acs.jchemed.2c00494; Reese H. W., 2011, Behavioral Development Bulletin, V17, P1, DOI [10.1037/h0100597, DOI 10.1037/H0100597]; Rosli MS, 2023, CURR PSYCHOL, V42, P18212, DOI 10.1007/s12144-022-02996-1; Sahu I., 2017, P 4 ACM IKDD C DAT S, P1; Salas-Pilco SZ, 2022, BRIT J EDUC TECHNOL, V53, P593, DOI 10.1111/bjet.13190; Scherak L, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su122410336; Seale J., 2020, Improving accessible digital practices in higher education: Challenges and new practices for inclusion; Serianni BA, 2014, TEACH EXCEPT CHILD, V46, P102, DOI 10.1177/0040059914528330; Shen CW, 2020, COMPUT HUM BEHAV, V104, DOI 10.1016/j.chb.2019.106177; Silge J., 2016, J OPEN SOURCE SOFTW, V1, P37, DOI DOI 10.21105/JOSS.00037; Tabatabai S, 2020, ADV MED EDUC PRACT, V11, P513, DOI 10.2147/AMEP.S257750; Tan L, 2015, EDUC INNOV SER, P181, DOI 10.1007/978-981-287-326-2_12; Teixeira AF, 2021, EDUC SCI, V11, DOI 10.3390/educsci11100636; Theobald EJ, 2020, P NATL ACAD SCI USA, V117, P6476, DOI 10.1073/pnas.1916903117; Toquero Cathy Mae, 2021, International Journal of Didactical Studies, V2, P10458, DOI [DOI 10.33902/IJODS.2021269730, 10.33902/IJODS.2021269730]; Utomo Muhammad, 2020, Ingenierie des systemes d'information, P383, DOI 10.0000/18280/isi.250314; Vial G, 2019, J STRATEGIC INF SYST, V28, P118, DOI 10.1016/j.jsis.2019.01.003; Vikas S, 2022, EDUC INF TECHNOL, V27, P589, DOI 10.1007/s10639-021-10793-9; Wang Q, 2023, BRIT J EDUC TECHNOL, V54, DOI 10.1111/bjet.13315; Wati I. F., 2020, P 1 ST INT C INF TEC; Yang Y, 2022, J RES TECHNOL EDUC, V54, pS148, DOI 10.1080/15391523.2021.1922104; Yew E.H., 2016, Health Professions Education, V2, P75, DOI [10.1016/j.hpe.2016.01.004, DOI 10.1016/J.HPE.2016.01.004]; Yu JQ, 2022, ETR&D-EDUC TECH RES, V70, P1169, DOI 10.1007/s11423-022-10122-y; Zaoui F., 2020, Procedia Comput. Sci, V175, p621?628, DOI [DOI 10.1016/J.PROCS.2020.07.090, 10.1016/j.procs.2020.07.090]; Zhang L, 2022, BRIT J EDUC TECHNOL, V53, P620, DOI 10.1111/bjet.13191; Zhang X, 2023, BUS PROCESS MANAG J, V29, P528, DOI 10.1108/BPMJ-06-2022-0254	91	1	1	11	23	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2504-284X		FRONT EDUC	Front. Educ.	AUG 17	2023	8								1250461	10.3389/feduc.2023.1250461	http://dx.doi.org/10.3389/feduc.2023.1250461			14	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Q7FM9		gold			2024-07-03	WOS:001059144000001
C	Peng, Y; Wang, CZ; Wang, WX; Gao, CY; Lyu, MR			IEEE	Peng, Yun; Wang, Chaozheng; Wang, Wenxuan; Gao, Cuiyun; Lyu, Michael R.			Generative Type Inference for Python	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		type inference; chain-of-thought; generative model		Python is a popular dynamic programming language, evidenced by its ranking as the second most commonly used language on GitHub. However, its dynamic type system can lead to potential type errors, leading researchers to explore automatic type inference approaches for Python programs. Existing type inference approaches can be generally grouped into three categories, i.e., rule-based, supervised, and cloze-style approaches. The rule-based type inference approaches can ensure the accuracy of predicted variable types, but they suffer from low coverage problems caused by dynamic features and external calls. Supervised type inference approaches, while feature-agnostic and able to mitigate the low coverage problem, require large, high-quality annotated datasets and are limited to pre-defined types. As zero-shot approaches, the cloze-style approaches reformulate the type inference problem into a fill-in-the-blank problem by leveraging the general knowledge in powerful pre-trained code models. However, their performance is limited since they ignore the domain knowledge from static typing rules which reflect the inference logic. What is more, their predictions are not interpretable, hindering developers' understanding and verification of the results. This paper introduces TYPEGEN, a few-shot generative type inference approach that incorporates static domain knowledge from static analysis. TYPEGEN creates chain-of-thought (COT) prompts by translating the type inference steps of static analysis into prompts based on the type dependency graphs (TDGs), enabling language models to learn from how static analysis infers types. By combining COT prompts with code slices and type hints, TYPEGEN constructs example prompts from human annotations. TYPEGEN only requires very few annotated examples to teach language models to generate similar COT prompts via in-context learning. Moreover, TYPEGEN enhances the interpretability of results through the use of the input-explanation-output strategy, which generates both explanations and type predictions in COT prompts. Experiments show that TYPEGEN outperforms the best baseline Type4Py by 10.0% for argument type prediction and 22.5% in return value type prediction in terms of top-1 Exact Match by using only five examples. Furthermore, TYPEGEN achieves substantial improvements of 27% to 84% compared to the zero-shot performance of large language models with parameter sizes ranging from 1.3B to 175B in terms of top-1 Exact Match.	[Peng, Yun; Wang, Chaozheng; Wang, Wenxuan; Lyu, Michael R.] Chinese Univ Hong Kong, Comp Sci & Engn Dept, Hong Kong, Peoples R China; [Gao, Cuiyun] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China	Chinese University of Hong Kong; Harbin Institute of Technology	Gao, CY (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China.	ypeng@cse.cuhk.edu.hk; adf111178@gmail.com; wxwang@cse.cuhk.edu.hk; gaocuiyun@hit.edu.cn; lyu@cse.cuhk.edu.hk	Peng, Yun/IZQ-0970-2023; Wang, Wenxuan/AAW-9073-2020; Wang, Chaozheng/KHT-6430-2024	Peng, Yun/0000-0003-1936-5598; 	Research Grants Council of the Hong Kong Special Administrative Region, China [CUHK 14206921]; National Natural Science Foundation of China [62002084]; Natural Science Foundation of Guangdong Province [2023A1515011959]; Shenzhen Basic Research [JCYJ20220531095214031]; Key Program of Fundamental Research from Shenzhen Science and Technology Innovation Commission [JCYJ20200109113403826]	Research Grants Council of the Hong Kong Special Administrative Region, China(Hong Kong Research Grants Council); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Natural Science Foundation of Guangdong Province(National Natural Science Foundation of Guangdong Province); Shenzhen Basic Research; Key Program of Fundamental Research from Shenzhen Science and Technology Innovation Commission	The authors would like to thank the efforts made by anonymous reviewers. The work described in this paper was supported by the Research Grants Council of the Hong Kong Special Administrative Region, China (No. CUHK 14206921 of the General Research Fund). The work was also supported by National Natural Science Foundation of China under project (No. 62002084), Natural Science Foundation of Guangdong Province (Project No. 2023A1515011959), Shenzhen Basic Research (General Project No. JCYJ20220531095214031), and Key Program of Fundamental Research from Shenzhen Science and Technology Innovation Commission (Project No. JCYJ20200109113403826). Any opinions, findings, and conclusions or recommendations expressed in this publication are those of the authors, and do not necessarily reflect the views of the above sponsoring entities.	Allamanis M, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P91, DOI 10.1145/3385412.3385997; Anderson C, 2005, LECT NOTES COMPUT SC, V3586, P428; [Anonymous], 2009, P 2009 ACM S APPL CO; Black Sid., 2022, Gpt-neo; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen S, 2016, ACM SIGPLAN NOTICES, V51, P416, DOI 10.1145/2914770.2837665; Dong Q., 2023, A survey on in-context learning; Emmi M, 2016, ACM SIGPLAN NOTICES, V51, P513, DOI 10.1145/2914770.2837645; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Fried Daniel, 2023, 11 INT C LEARN REPR; Gao SZ, 2023, PROC INT CONF SOFTW, P1933, DOI 10.1109/ICSE48619.2023.00164; Gao SZ, 2023, Arxiv, DOI arXiv:2304.07575; github, mypy; github, pyright; github, Pytype; Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212; Hellendoorn VJ, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P152, DOI 10.1145/3236024.3236051; HuggingFace, 2023, Huggingface hub; Jensen SH, 2009, LECT NOTES COMPUT SC, V5673, P238, DOI 10.1007/978-3-642-03237-0_17; Jesse K, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1483, DOI 10.1145/3468264.3473135; Langa Lukasz, 2019, PEP 589-type hinting generics in standard collections; Lehtosalo Jukka, 2019, PEP 589-TypedDict: Type hints for dictionaries with a fixed set of keys; Levkivskyi I., 2017, PEP 544 PROTOCOLS ST; Li J, 2023, Arxiv, DOI [arXiv:2303.17780, 10.48550/ARXIV.2303.17780, DOI 10.48550/ARXIV.2303.17780]; Li J, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P155, DOI 10.1109/ASE51524.2021.9678724; libraries.io, 2023, libraries.io; Liu Jiachang, 2021, WORKSH KNOWL EXTR IN; Min Sewon, 2022, P 2022 C EMPIRICAL M, P11048, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.759; Mir AM, 2022, PROC INT CONF SOFTW, P2241, DOI 10.1145/3510003.3510124; Mir AM, 2021, IEEE WORK CONF MIN S, P585, DOI 10.1109/MSR52588.2021.00079; Mir Amir M., 2022, Type4py; Oh Wonseok, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P922, DOI 10.1145/3540250.3549130; OpenAi, 2022, Chatgpt; Pavlinovic Z, 2021, P ACM PROGRAM LANG, V5, DOI 10.1145/3434300; Peng Y, 2023, Arxiv, DOI [arXiv:2306.01394, DOI 10.48550/ARXIV.2306.01394, 10.48550/arXiv.2306.01394]; Peng Y, 2022, PROC INT CONF SOFTW, P2019, DOI 10.1145/3510003.3510038; Peng Yun, 2022, Hityper; Pradel M, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P209, DOI 10.1145/3368089.3409715; pyre-check, Pyre check; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Tu L., 2023, 11 INT C LEARN REPR; van Rossum Guido, 2014, PEP 484 TYPE HINTS; Wang Ben., 2022, Gpt-j; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei J., 2020, 8 INT C LEARN REPR I; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei JY, 2020, Arxiv, DOI arXiv:2005.02161; Xia C.S., 2023, arXiv; Xia Chunqiu Steven, 2022, arXiv; Ye HJ, 2022, PROC INT CONF SOFTW, P1245, DOI 10.1145/3510003.3510127; Zhang Z., 2023, 11 INT C LEARN REPR; Zhang Z, 2021, INT J MACH LEARN CYB, V12, P1649, DOI 10.1007/s13042-020-01264-7	53	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							988	999		10.1109/ASE56229.2023.00031	http://dx.doi.org/10.1109/ASE56229.2023.00031			12	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200079
J	Choudhury, A; Shamszare, H				Choudhury, Avishek; Shamszare, Hamid			The Impact of Performance Expectancy, Workload, Risk, and Satisfaction on Trust in ChatGPT: Cross-Sectional Survey Analysis	JMIR HUMAN FACTORS			English	Article						ChatGPT; chatbots; health care; health care decision-making; health-related decision-making; health care management; decision-making; user perception; usability; usable; usableness; usefulness; artificial intelligence; algorithms; predictive models; predictive analytics; predictive system; practical models; deep learning; cross-sectional survey	CONTINUANCE INTENTION; MODEL; TECHNOLOGY; ACCEPTANCE; SERVICES; ADOPTION; UTAUT	Background: ChatGPT (OpenAI) is a powerful tool for a wide range of tasks, from entertainment and creativity to health care queries. There are potential risks and benefits associated with this technology. In the discourse concerning the deployment of ChatGPT and similar large language models, it is sensible to recommend their use primarily for tasks a human user can execute accurately. As we transition into the subsequent phase of ChatGPT deployment, establishing realistic performance expectations and understanding users' perceptions of risk associated with its use are crucial in determining the successful integration of this Objective: The aim of the study is to explore how perceived workload, satisfaction, performance expectancy, and risk-benefit perception influence users' trust in ChatGPT. Methods: A semistructured, web-based survey was conducted with 607 adults in the United States who actively use ChatGPT. The survey questions were adapted from constructs used in various models and theories such as the technology acceptance model, the theory of planned behavior, the unified theory of acceptance and use of technology, and research on trust and security in digital environments. To test our hypotheses and structural model, we used the partial least squares structural equation modeling method, a widely used approach for multivariate analysis. Results: A total of 607 people responded to our survey. A significant portion of the participants held at least a high school diploma (n=204, 33.6%), and the majority had a bachelor's degree (n=262, 43.1%). The primary motivations for participants to use ChatGPT were for acquiring information (n=219, 36.1%), amusement (n=203, 33.4%), and addressing problems (n=135, 22.2%). Some participants used it for health-related inquiries (n=44, 7.2%), while a few others (n=6, 1%) used it for miscellaneous activities such as brainstorming, grammar verification, and blog content creation. Our model explained 64.6% of the variance in trust. Our analysis indicated a significant relationship between (1) workload and satisfaction, (2) trust and satisfaction, (3) performance expectations and trust, and (4) risk-benefit perception and trust. Conclusions: The findings underscore the importance of ensuring user-friendly design and functionality in AI-based applications to reduce workload and enhance user satisfaction, thereby increasing user trust. Future research should further explore the relationship between risk-benefit perception and trust in the context of AI chatbots.	[Choudhury, Avishek; Shamszare, Hamid] West Virginia Univ, Benjamin M Statler Coll Engn & Mineral Resources, Ind & Management Syst Engn, 321 Engn Sci Bldg,1306 Evansdale Dr, Morgantown, WV 26506 USA	West Virginia University	Choudhury, A (corresponding author), West Virginia Univ, Benjamin M Statler Coll Engn & Mineral Resources, Ind & Management Syst Engn, 321 Engn Sci Bldg,1306 Evansdale Dr, Morgantown, WV 26506 USA.	avishek.choudhury@mail.wvu.edu	Choudhury, Avishek/P-2415-2018	Choudhury, Avishek/0000-0002-5342-0709; Shamszare, Hamid/0009-0007-7786-3452				Al-Ansi A, 2019, INT J HOSP MANAG, V83, P210, DOI 10.1016/j.ijhm.2018.10.017; Aljanabi M., 2023, Iraqi Journal for Computer Science and Mathematics, V4, P62; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Chen XG, 2017, J COMPUT INFORM SYST, V57, P287, DOI 10.1080/08874417.2016.1180649; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; D'Amico RS, 2023, NEUROSURGERY, V92, P663, DOI 10.1227/neu.0000000000002414; DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eriksson K, 2020, INT J BANK MARK, V38, P889, DOI 10.1108/IJBM-08-2019-0282; FACT SHEET, 2023, BidenHarris Administration takes new steps to advance responsible artificial intelligence research, development, and deployment; Fang YL, 2014, MIS QUART, V38, P407, DOI 10.25300/MISQ/2014/38.2.04; Featherman MS, 2003, INT J HUM-COMPUT ST, V59, P451, DOI 10.1016/S1071-5819(03)00111-3; Gontar P, 2018, J AIR TRANSP MANAG, V69, P26, DOI 10.1016/j.jairtraman.2018.01.004; Gu ZW, 2015, J COMPUT INFORM SYST, V56, P79; Hair J.F., 2017, Advanced issues in partial least squares structural equation modeling; HART S G, 1988, P139; Holland P, 2019, APPL NURS RES, V49, P70, DOI 10.1016/j.apnr.2019.06.001; Holzinger A, 2023, NEW BIOTECHNOL, V74, P16, DOI 10.1016/j.nbt.2023.02.001; Hsiao KL, 2022, LIBR HI TECH, V40, P929, DOI 10.1108/LHT-08-2021-0274; Hu PJ, 1999, J MANAGE INFORM SYST, V16, P91, DOI 10.1080/07421222.1999.11518247; Inegbedion H, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03160; Karpinsky ND, 2018, APPL ERGON, V70, P194, DOI 10.1016/j.apergo.2018.03.008; Kim C, 2010, COMPUT HUM BEHAV, V26, P310, DOI 10.1016/j.chb.2009.10.013; Kumar A, 2018, INT J BANK MARK, V36, P1170, DOI 10.1108/IJBM-04-2017-0077; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lubowitz JH, 2023, ARTHROSCOPY, V39, P1121, DOI 10.1016/j.arthro.2023.01.015; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Marikyan D, 2022, J BUS RES, V142, P572, DOI 10.1016/j.jbusres.2022.01.015; McKnight DH, 2002, J STRATEGIC INF SYST, V11, P297, DOI 10.1016/S0963-8687(02)00020-3; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Mostafa RB, 2022, EUR J MARKETING, V56, P1748, DOI 10.1108/EJM-02-2020-0084; Nguyen TM, 2022, BRIT J MANAGE, V33, P1221, DOI 10.1111/1467-8551.12540; Nordheim CB, 2019, INTERACT COMPUT, V31, P317, DOI 10.1093/iwc/iwz022; Oliveira T, 2014, INT J INFORM MANAGE, V34, P689, DOI 10.1016/j.ijinfomgt.2014.06.004; OpenAI, Models GPT-3; Pesonen JA., 2021, LEARNING COLLABORATI, DOI [10.1007/978-3-030-77943-613, DOI 10.1007/978-3-030-77943-613]; Sato T, 2020, COGN TECHNOL WORK, V22, P399, DOI 10.1007/s10111-019-00580-5; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Sharma G, 2023, ChemRxiv; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Silva SC, 2023, INT J RETAIL DISTRIB, V51, P285, DOI 10.1108/IJRDM-05-2022-0163; Tabassi E, 2023, Tech rep, DOI DOI 10.6028/NIST.AI.100-1; Tentama Fatwa., 2019, International Journal ofScientific and Technology Research, V8, P2498; Wang XQ, 2023, J ASSOC INF SCI TECH, V74, P339, DOI 10.1002/asi.24621; Williams MD, 2015, J ENTERP INF MANAG, V28, P443, DOI 10.1108/JEIM-09-2014-0088	47	0	0	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2292-9495			JMIR HUM FACTORS	JMIR Hum. Factors		2024	11								e55399	10.2196/55399	http://dx.doi.org/10.2196/55399			11	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	TH8B9	38801658	Green Accepted, gold			2024-07-03	WOS:001240456300002
J	Chervonski, E; Harish, KB; Rockman, CB; Sadek, M; Teter, KA; Jacobowitz, GR; Berland, TL; Lohr, J; Moore, C; Maldonado, TS				Chervonski, Ethan; Harish, Keerthi B.; Rockman, Caron B.; Sadek, Mikel; Teter, Katherine A.; Jacobowitz, Glenn R.; Berland, Todd L.; Lohr, Joann; Moore, Colleen; Maldonado, Thomas S.			Generative artificial intelligence chatbots may provide appropriate informational responses to common vascular surgery questions by patients	VASCULAR			English	Article; Early Access						Vascular surgery; artificial intelligence; ChatGPT; google bard; patient education; readability	EDUCATIONAL-ATTAINMENT; ARTERY-DISEASE; READABILITY; QUALITY	Objectives: Generative artificial intelligence (AI) has emerged as a promising tool to engage with patients. The objective of this study was to assess the quality of AI responses to common patient questions regarding vascular surgery disease processes. Methods: OpenAI's ChatGPT-3.5 and Google Bard were queried with 24 mock patient questions spanning seven vascular surgery disease domains. Six experienced vascular surgery faculty at a tertiary academic center independently graded AI responses on their accuracy (rated 1-4 from completely inaccurate to completely accurate), completeness (rated 1-4 from totally incomplete to totally complete), and appropriateness (binary). Responses were also evaluated with three readability scales. Results: ChatGPT responses were rated, on average, more accurate than Bard responses (3.08 +/- 0.33 vs 2.82 +/- 0.40, p < .01). ChatGPT responses were scored, on average, more complete than Bard responses (2.98 +/- 0.34 vs 2.62 +/- 0.36, p < .01). Most ChatGPT responses (75.0%, n = 18) and almost half of Bard responses (45.8%, n = 11) were unanimously deemed appropriate. Almost one-third of Bard responses (29.2%, n = 7) were deemed inappropriate by at least two reviewers (29.2%), and two Bard responses (8.4%) were considered inappropriate by the majority. The mean Flesch Reading Ease, Flesch-Kincaid Grade Level, and Gunning Fog Index of ChatGPT responses were 29.4 +/- 10.8, 14.5 +/- 2.2, and 17.7 +/- 3.1, respectively, indicating that responses were readable with a post-secondary education. Bard's mean readability scores were 58.9 +/- 10.5, 8.2 +/- 1.7, and 11.0 +/- 2.0, respectively, indicating that responses were readable with a high-school education (p < .0001 for three metrics). ChatGPT's mean response length (332 +/- 79 words) was higher than Bard's mean response length (183 +/- 53 words, p < .001). There was no difference in the accuracy, completeness, readability, or response length of ChatGPT or Bard between disease domains (p > .05 for all analyses). Conclusions: AI offers a novel means of educating patients that avoids the inundation of information from "Dr Google" and the time barriers of physician-patient encounters. ChatGPT provides largely valid, though imperfect, responses to myriad patient questions at the expense of readability. While Bard responses are more readable and concise, their quality is poorer. Further research is warranted to better understand failure points for large language models in vascular surgery patient education.	[Chervonski, Ethan; Harish, Keerthi B.] New York Univ, Grossman Sch Med, New York, NY USA; [Rockman, Caron B.; Sadek, Mikel; Teter, Katherine A.; Jacobowitz, Glenn R.; Berland, Todd L.; Maldonado, Thomas S.] New York Univ, Dept Surg, Div Vasc & Endovascular Surg, Langone Hlth, New York, NY USA; [Lohr, Joann] Dorn Vet Affairs Med Ctr, Columbia, SC USA; [Moore, Colleen] InVein Clin, Cape Girardeau, MO USA; [Maldonado, Thomas S.] New York Univ, Dept Surg, Div Vasc & Endovascular Surg, Langone Med Ctr, 530 First Ave,Sixth Floor, New York, NY 10016 USA	New York University; New York University; New York University; NYU Langone Medical Center	Maldonado, TS (corresponding author), New York Univ, Dept Surg, Div Vasc & Endovascular Surg, Langone Med Ctr, 530 First Ave,Sixth Floor, New York, NY 10016 USA.	Thomas.Maldonado@nyulangone.org		Chervonski, Ethan/0000-0002-4404-0499; Teter, Katherine/0000-0002-8807-1553				AbuRahma AF, 2022, J VASC SURG, V75, p4S, DOI 10.1016/j.jvs.2021.04.073; Anderson PF., 2001, Consumer health Web site evaluation checklist; Athavale Anand, 2023, JVS Vasc Insights, V1, DOI 10.1016/j.jvsvi.2023.100019; Bailey MA, 2012, J VASC SURG, V56, P21, DOI 10.1016/j.jvs.2011.12.063; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Centers for Disease Control and Prevention (U.S), 2010, Office of the associate director for communication. Strategic and proactive communication branch. Simply put; a guide for creating easy-to-understand materials; Duffourc M, 2023, JAMA-J AM MED ASSOC, V330, P313, DOI 10.1001/jama.2023.9630; Emile SH, 2023, SURGERY, V174, P1273, DOI 10.1016/j.surg.2023.06.005; Ghisi GLD, 2018, PATIENT EDUC COUNS, V101, P177, DOI 10.1016/j.pec.2017.09.002; Grewal P, 2012, J VASC SURG, V56, P1461, DOI 10.1016/j.jvs.2012.04.058; Hansberry DR, 2014, LARYNGOSCOPE, V124, P405, DOI 10.1002/lary.24261; Haver HL, 2023, AM J ROENTGENOL, V221, P701, DOI 10.2214/AJR.23.29622; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kwok TMY, 2017, J VASC SURG-VENOUS L, V5, P238, DOI 10.1016/j.jvsv.2016.10.078; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Li H, 2023, CLIN IMAG, V101, P137, DOI 10.1016/j.clinimag.2023.06.008; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Minervation Ltd, The Lida Instrument; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Morton RL, 2016, AM J KIDNEY DIS, V67, P31, DOI 10.1053/j.ajkd.2015.07.021; Pande RL, 2014, CIRC-CARDIOVASC QUAL, V7, P532, DOI 10.1161/CIRCOUTCOMES.113.000618; Prestin A, 2015, J HEALTH COMMUN, V20, P790, DOI 10.1080/10810730.2015.1018590; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; SPADARO DC, 1980, AM J HOSP PHARM, V37, P215, DOI 10.1093/ajhp/37.2.215; Strijbos RM, 2018, EUR J VASC ENDOVASC, V56, P239, DOI 10.1016/j.ejvs.2018.04.015; Szczesniewski JJ, 2023, WORLD J UROL, V41, P3149, DOI 10.1007/s00345-023-04563-0; Taylor DM, 2018, NEPHROL DIAL TRANSPL, V33, P1545, DOI 10.1093/ndt/gfx293; Tripathy S, 2020, KIDNEY INT REP, V5, P2256, DOI 10.1016/j.ekir.2020.09.015; Weiss BD., 2003, Health Literacy: A Manual for Clinicians	32	1	1	2	2	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1708-5381	1708-539X		VASCULAR	Vascular	2024 MAR 18	2024										10.1177/17085381241240550	http://dx.doi.org/10.1177/17085381241240550		MAR 2024	9	Peripheral Vascular Disease	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	LM6V1	38500300				2024-07-03	WOS:001187266400001
J	Sivarajkumar, S; Gao, FY; Denny, P; Aldhahwani, B; Visweswaran, S; Bove, A; Wang, YS				Sivarajkumar, Sonish; Gao, Fengyi; Denny, Parker; Aldhahwani, Bayan; Visweswaran, Shyam; Bove, Allyn; Wang, Yanshan			Mining Clinical Notes for Physical Rehabilitation Exercise Information: Natural Language Processing Algorithm Development and Validation Study	JMIR MEDICAL INFORMATICS			English	Article						natural language processing; electronic health records; rehabilitation; physical exercise; ChatGPT; artificial intelligence; stroke; physical rehabilitation; rehabilitation therapy; exercise; machine learning	SYSTEM	Background: The rehabilitation of a patient who had a stroke requires precise, personalized treatment plans. Natural language processing (NLP) offers the potential to extract valuable exercise information from clinical notes, aiding in the development of more effective rehabilitation strategies. Objective: This study aims to develop and evaluate a variety of NLP algorithms to extract and categorize physical rehabilitation exercise information from the clinical notes of patients who had a stroke treated at the University of Pittsburgh Medical Center. Methods: A cohort of 13,605 patients diagnosed with stroke was identified, and their clinical notes containing rehabilitation therapy notes were retrieved. A comprehensive clinical ontology was created to represent various aspects of physical rehabilitation exercises. State-of-the-art NLP algorithms were then developed and compared, including rule -based, machine learning-based algorithms (support vector machine, logistic regression, gradient boosting, and AdaBoost) and large language model (LLM)-based algorithms (ChatGPT [OpenAI]). The study focused on key performance metrics, particularly F1 -scores, to evaluate algorithm effectiveness. Results: The analysis was conducted on a data set comprising 23,724 notes with detailed demographic and clinical characteristics. The rule -based NLP algorithm demonstrated superior performance in most areas, particularly in detecting the "Right Side" location with an F1 -score of 0.975, outperforming gradient boosting by 0.063. Gradient boosting excelled in "Lower Extremity" location detection (F1 -score: 0.978), surpassing rule -based NLP by 0.023. It also showed notable performance in the "Passive Range of Motion" detection with an F1 -score of 0.970, a 0.032 improvement over rule -based NLP. The rule -based algorithm efficiently handled "Duration," "Sets," and "Reps" with F1 -scores up to 0.65. LLM-based NLP, particularly ChatGPT with few -shot prompts, achieved high recall but generally lower precision and F1 -scores. However, it notably excelled in "Backward Plane" motion detection, achieving an F1 -score of 0.846, surpassing the rule -based algorithm's 0.720. Conclusions: The study successfully developed and evaluated multiple NLP algorithms, revealing the strengths and weaknesses of each in extracting physical rehabilitation exercise information from clinical notes. The detailed ontology and the robust performance of the rule -based and gradient boosting algorithms demonstrate significant potential for enhancing precision rehabilitation. These findings contribute to the ongoing efforts to integrate advanced NLP techniques into health care, moving toward predictive models that can recommend personalized rehabilitation treatments for optimal patient outcomes.	[Sivarajkumar, Sonish; Visweswaran, Shyam; Wang, Yanshan] Univ Pittsburgh, Intelligent Syst Program, Pittsburgh, PA 15260 USA; [Gao, Fengyi; Wang, Yanshan] Univ Pittsburgh, Dept Hlth Informat Management, Pittsburgh, PA USA; [Denny, Parker; Aldhahwani, Bayan; Bove, Allyn] Univ Pittsburgh, Dept Phys Therapy, Pittsburgh, PA USA; [Aldhahwani, Bayan] Umm Al Qura Univ, Dept Pathol, Makkah City, Saudi Arabia; [Visweswaran, Shyam; Wang, Yanshan] Univ Pittsburgh, Dept Biomed Informat, Pittsburgh, PA USA; [Visweswaran, Shyam; Wang, Yanshan] Univ Pittsburgh, Clin & Translat Sci Inst, Pittsburgh, PA USA; [Wang, Yanshan] Univ Pittsburgh, Dept Hlth Informat Management, 6026 Forbes Tower, Pittsburgh, PA 15260 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Umm Al Qura University; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh	Wang, YS (corresponding author), Univ Pittsburgh, Dept Hlth Informat Management, 6026 Forbes Tower, Pittsburgh, PA 15260 USA.	yanshan.wang@pitt.edu	Sonish, Sonish/JWP-8428-2024; Wang, Yanshan/H-4686-2018	Sonish, Sonish/0000-0003-4173-1988; , Parker Denny/0009-0001-0705-8606; Wang, Yanshan/0000-0003-4433-7839; Aldhahwani, Bayan/0009-0004-3025-0294; Bove, Allyn M/0000-0002-9537-8844	School of Health and Rehabilitation Sciences Dean's Research and Development Award	School of Health and Rehabilitation Sciences Dean's Research and Development Award	This work was supported by the School of Health and Rehabilitation Sciences Dean's Research and Development Award.	Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; [Anonymous], 2007, International Classification of Functioning, Disability, and Health Children and Youth Version: ICF-CY; Blum C, 2022, BMC NEUROL, V22, DOI 10.1186/s12883-022-02759-2; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; ChatGPT, OpenAI; CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018; De Rosario H, 2023, JMIR MED INF, V11, DOI 10.2196/48693; Donnelly K, 2006, STUD HEALTH TECHNOL, V121, P279; French MA, 2022, ARCH PHYS MED REHAB, V103, P1233, DOI 10.1016/j.apmr.2022.01.154; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Ginsburg GS, 2018, HEALTH AFFAIR, V37, P694, DOI 10.1377/hlthaff.2017.1624; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Johnson KB, 2021, CTS-CLIN TRANSL SCI, V14, P86, DOI 10.1111/cts.12884; Liu Hongfang, 2013, AMIA Jt Summits Transl Sci Proc, V2013, P149; Lotze M, 2015, PHYS THER, V95, P1316, DOI 10.2522/ptj.20140581; Newman-Griffis D, 2021, FRONT REHABIL SCI, V2, DOI 10.3389/fresc.2021.742702; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; PREGIBON D, 1981, ANN STAT, V9, P705, DOI 10.1214/aos/1176345513; Schapire RE, 2013, EMPIRICAL INFERENCE, P37, DOI [10.1007/978-3-642-41136-6_5, DOI 10.1007/978-3-642-41136-6_5]; Severin R, 2022, PHYS THER, V102, DOI 10.1093/ptj/pzab253; Shin SH, 2017, NPJ PRECIS ONCOL, V1, DOI 10.1038/s41698-017-0016-z; Sivarajkumar S, 2023, arXiv; Sivarajkumar Sonish, 2022, AMIA Annu Symp Proc, V2022, P972; Zhao YQ, 2021, J MED INTERNET RES, V23, DOI 10.2196/22951	25	0	0	3	3	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2291-9694		JMIR MED INF	JMIR Med. Inf.		2024	12								e52289	10.2196/52289	http://dx.doi.org/10.2196/52289			12	Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics	ND3W7	38568736	Green Published, gold			2024-07-03	WOS:001198484100001
J	Ali, MJ				Ali, Mohammad Javed			ChatGPT and Lacrimal Drainage Disorders: Performance and Scope of Improvement	OPHTHALMIC PLASTIC AND RECONSTRUCTIVE SURGERY			English	Article								Purpose:This study aimed to report the performance of the large language model ChatGPT (OpenAI, San Francisco, CA, U.S.A.) in the context of lacrimal drainage disorders. Methods:A set of prompts was constructed through questions and statements spanning common and uncommon aspects of lacrimal drainage disorders. Care was taken to avoid constructing prompts that had significant or new knowledge beyond the year 2020. Each of the prompts was presented thrice to ChatGPT. The questions covered common disorders such as primary acquired nasolacrimal duct obstruction and congenital nasolacrimal duct obstruction and their cause and management. The prompts also tested ChatGPT on certain specifics, such as the history of dacryocystorhinostomy (DCR) surgery, lacrimal pump anatomy, and human canalicular surfactants. ChatGPT was also quizzed on controversial topics such as silicone intubation and the use of mitomycin C in DCR surgery. The responses of ChatGPT were carefully analyzed for evidence-based content, specificity of the response, presence of generic text, disclaimers, factual inaccuracies, and its abilities to admit mistakes and challenge incorrect premises. Three lacrimal surgeons graded the responses into three categories: correct, partially correct, and factually incorrect. Results:A total of 21 prompts were presented to the ChatGPT. The responses were detailed and were based according to the prompt structure. In response to most questions, ChatGPT provided a generic disclaimer that it could not give medical advice or professional opinion but then provided an answer to the question in detail. Specific prompts such as "how can I perform an external DCR?" were responded by a sequential listing of all the surgical steps. However, several factual inaccuracies were noted across many ChatGPT replies. Several responses on controversial topics such as silicone intubation and mitomycin C were generic and not precisely evidence-based. ChatGPT's response to specific questions such as canalicular surfactants and idiopathic canalicular inflammatory disease was poor. The presentation of variable prompts on a single topic led to responses with either repetition or recycling of the phrases. Citations were uniformly missing across all responses. Agreement among the three observers was high (95%) in grading the responses. The responses of ChatGPT were graded as correct for only 40% of the prompts, partially correct in 35%, and outright factually incorrect in 25%. Hence, some degree of factual inaccuracy was present in 60% of the responses, if we consider the partially correct responses. The exciting aspect was that ChatGPT was able to admit mistakes and correct them when presented with counterarguments. It was also capable of challenging incorrect prompts and premises. Conclusion:The performance of ChatGPT in the context of lacrimal drainage disorders, at best, can be termed average. However, the potential of this AI chatbot to influence medicine is enormous. There is a need for it to be specifically trained and retrained for individual medical subspecialties.	[Ali, Mohammad Javed] LV Prasad Eye Inst, Govindram Seksaria Inst Dacryol, Hyderabad, India; [Ali, Mohammad Javed] LV Prasad Eye Inst, Govindram Seksaria Inst Dacryol, Rd 2,Banjara Hills, Hyderabad 500034, India	L. V. Prasad Eye Institute; L. V. Prasad Eye Institute	Ali, MJ (corresponding author), LV Prasad Eye Inst, Govindram Seksaria Inst Dacryol, Rd 2,Banjara Hills, Hyderabad 500034, India.	drjaved007@gmail.com		Ali, Mohammad Javed/0000-0002-6363-9202				Ali M. J., 2023, Semin Ophthalmol, V28, P153, DOI https://doi.org/10.1016/j.jtos.2023.04.001; Ali MJ, 2023, OCUL SURF, V28, P56, DOI 10.1016/j.jtos.2023.02.001; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; ChatGPT limitations, THE OPEN; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; publicationethics, AUTH TOOLS; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	13	22	22	7	17	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0740-9303	1537-2677		OPHTHAL PLAST RECONS	Ophthalmic Plast. Reconstr. Surg.	MAY-JUN	2023	39	3					221	225		10.1097/IOP.0000000000002418	http://dx.doi.org/10.1097/IOP.0000000000002418			5	Ophthalmology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology; Surgery	H8XN7	37166289	Green Published, hybrid			2024-07-03	WOS:000998726200017
J	Loubser, A; De Villiers, P; De Freitas, A				Loubser, Alexander; De Villiers, Pieter; De Freitas, Allan			End-to-end automated speech recognition using a character based small scale transformer architecture	EXPERT SYSTEMS WITH APPLICATIONS			English	Article						Speech recognition; Transformer; End-to-end; Character based; Connectionist temporal classification	RECURRENT NEURAL-NETWORK	This study explores the feasibility of constructing a small-scale speech recognition system capable of competing with larger, modern automated speech recognition (ASR) systems in both performance and word error rate (WER). Our central hypothesis posits that a compact transformer-based ASR model can yield comparable results, specifically in terms of WER, to traditional ASR models while challenging contemporary ASR systems that boast significantly larger computational sizes. The aim is to extend ASR capabilities to under-resourced languages with limited corpora, catering to scenarios where practitioners face constraints in both data availability and computational resources. The model, comprising a compact convolutional neural network (CNN) and transformer architecture with 2.214 million parameters, challenges the conventional wisdom that large-scale transformer-based ASR systems are essential for achieving high accuracy. In comparison, contemporary ASR systems often deploy over 300 million parameters. Trained on a modest dataset of approximately 3000 h - significantly less than the 50,000 h used in larger systems - the proposed model leverages the Common Voice and LibriSpeech datasets. Evaluation on the LibriSpeech test-clean and testother datasets produced character error rates (CERs) of 6.40% and 16.73% and WERs of 16.03% and 35.51% respectively. Comparisons with existing architectures showcase the efficiency of our model. A gated recurrent unit (GRU) architecture, albeit achieving lower error rates, incurred a computational cost 24 times larger than our proposed model. Large-scale transformer architectures, while achieving marginally lower WERs (2%-4% on LibriSpeech test-clean), require 200 times more parameters and 53,000 additional hours of training data. Modern large language models are used to improve the WERs, but require large computational resources. To further enhance performance, a small 4-g language model was integrated into our end-to-end ASR model, resulting in improved WERs. The overarching goal of this work is to provide a practical solution for practitioners dealing with limited datasets and computational resources, particularly in the context of under-resourced languages.	[Loubser, Alexander; De Villiers, Pieter; De Freitas, Allan] Univ Pretoria, Dept Elect Elect & Comp Engn, Private Bag X20, ZA-0028 Hatfield, South Africa	University of Pretoria	Loubser, A (corresponding author), Univ Pretoria, Dept Elect Elect & Comp Engn, Private Bag X20, ZA-0028 Hatfield, South Africa.	a.loubser@tuks.co.za; pieter.devilliers@up.ac.za; pieter.devilliers@up.ac.za			MultiChoice Chair of Machine Learning	MultiChoice Chair of Machine Learning	We thank the MultiChoice Chair of Machine Learning for sponsoring the funding for the research of this paper. The University of Pretoria EECE department provided the facilities and resources to complete the paper. A thanks also to Mozilla for the publicly available Common Voice dataset and to OpenSLR and Vassil Panayotov for the publicly available LibriSpeech dataset.	Amodei D., 2015, 33 INT C MACH LEARN, V1, P312; Babu A, 2021, Arxiv, DOI arXiv:2111.09296; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Baevski A, 2021, ADV NEUR IN; Chen X, 2016, IEEE-ACM T AUDIO SPE, V24, P2146, DOI 10.1109/TASLP.2016.2598304; Conneau A, 2020, Arxiv, DOI arXiv:2006.13979; Drexler J, 2019, INT CONF ACOUST SPEE, P6266, DOI [10.1109/icassp.2019.8683531, 10.1109/ICASSP.2019.8683531]; Graves A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891; Grosman J., 2021, Hugging face unpublished results; Gulati A, 2020, INTERSPEECH, P5036, DOI 10.21437/Interspeech.2020-3015; Hwang K, 2016, INT CONF ACOUST SPEE, P5335, DOI 10.1109/ICASSP.2016.7472696; Kubo Y, 2022, INT CONF ACOUST SPEE, P8512, DOI 10.1109/ICASSP43922.2022.9746801; Li BX, 2014, IEEE IJCNN, P4062, DOI 10.1109/IJCNN.2014.6889433; Li S, 2016, IEEE-ACM T AUDIO SPE, V24, P1524, DOI 10.1109/TASLP.2016.2562505; Liao H, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P368, DOI 10.1109/ASRU.2013.6707758; Lippi M, 2019, IEEE T NEUR NET LEAR, V30, P3326, DOI 10.1109/TNNLS.2019.2890970; Long YH, 2019, IEEE ACCESS, V7, P133615, DOI 10.1109/ACCESS.2019.2940961; Luong T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166; Maas Andrew L., 2015, HLT-NAACL, DOI [DOI 10.3115/V1/N15-1038, 10.3115/v1/n15-1038]; Min ZP, 2023, Arxiv, DOI arXiv:2307.06530; Mozilla, 2021, Common voice corpus 7.0; Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964; Pham NQ, 2019, Arxiv, DOI arXiv:1904.13377; Sundermeyer M, 2015, IEEE-ACM T AUDIO SPE, V23, P517, DOI 10.1109/TASLP.2015.2400218; Synnaeve G, 2020, Arxiv, DOI arXiv:1911.08460; Vaswani A, 2017, ADV NEUR IN, V30; Vergin R, 1999, IEEE T SPEECH AUDI P, V7, P525, DOI 10.1109/89.784104; Williams W, 2015, INT CONF ACOUST SPEE, P5391, DOI 10.1109/ICASSP.2015.7179001; Winata GI, 2020, INT CONF ACOUST SPEE, P6144, DOI [10.1109/ICASSP40776.2020.9053878, 10.1109/icassp40776.2020.9053878]; Wu B, 2017, IEEE J-STSP, V11, P1289, DOI 10.1109/JSTSP.2017.2756439	30	0	0	1	1	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0957-4174	1873-6793		EXPERT SYST APPL	Expert Syst. Appl.	OCT 15	2024	252		A						124119	10.1016/j.eswa.2024.124119	http://dx.doi.org/10.1016/j.eswa.2024.124119			11	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Operations Research & Management Science	TF3A0		hybrid			2024-07-03	WOS:001239795400001
J	Hwang, T; Aggarwal, N; Khan, PZ; Roberts, T; Mahmood, A; Griffiths, MM; Parsons, N; Khan, S; Mizuno, T; Mizuno, T; Mizuno, T				Hwang, Taesoon; Aggarwal, Nishant; Khan, Pir Zarak; Roberts, Thomas; Mahmood, Amir; Griffiths, Madlen M.; Parsons, Nick; Khan, Saboor; Mizuno, Takayuki; Mizuno, Takayuki; Mizuno, Takayuki			Can ChatGPT assist authors with abstract writing in medical journals? Evaluating the quality of scientific abstracts generated by ChatGPT and original abstracts	PLOS ONE			English	Article								Introduction ChatGPT, a sophisticated large language model (LLM), has garnered widespread attention for its ability to mimic human-like communication. As recent studies indicate a potential supportive role of ChatGPT in academic writing, we assessed the LLM's capacity to generate accurate and comprehensive scientific abstracts from published Randomised Controlled Trial (RCT) data, focusing on the adherence to the Consolidated Standards of Reporting Trials for Abstracts (CONSORT-A) statement, in comparison to the original authors' abstracts. Methodology RCTs, identified in a PubMed/MEDLINE search post-September 2021 across various medical disciplines, were subjected to abstract generation via ChatGPT versions 3.5 and 4, following the guidelines of the respective journals. The overall quality score (OQS) of each abstract was determined by the total number of adequately reported components from the 18-item CONSORT-A checklist. Additional outcome measures included percent adherence to each CONOSORT-A item, readability, hallucination rate, and regression analysis of reporting quality determinants. Results Original abstracts achieved a mean OQS of 11.89 (95% CI: 11.23-12.54), outperforming GPT 3.5 (7.89; 95% CI: 7.32-8.46) and GPT 4 (5.18; 95% CI: 4.64-5.71). Compared to GPT 3.5 and 4 outputs, original abstracts were more adherent with 10 and 14 CONSORT-A items, respectively. In blind assessments, GPT 3.5-generated abstracts were deemed most readable in 62.22% of cases which was significantly greater than the original (31.11%; P = 0.003) and GPT 4-generated (6.67%; P<0.001) abstracts. Moreover, ChatGPT 3.5 exhibited a hallucination rate of 0.03 items per abstract compared to 1.13 by GPT 4. No determinants for improved reporting quality were identified for GPT-generated abstracts. Conclusions While ChatGPT could generate more readable abstracts, their overall quality was inferior to the original abstracts. Yet, its proficiency to concisely relay key information with minimal error holds promise for medical research and warrants further investigations to fully ascertain the LLM's applicability in this domain.	[Hwang, Taesoon; Aggarwal, Nishant; Roberts, Thomas; Mahmood, Amir; Parsons, Nick] Univ Warwick, Warwick Med Sch, Coventry, England; [Hwang, Taesoon; Aggarwal, Nishant; Khan, Pir Zarak; Khan, Saboor] Univ Hosp Coventry & Warwickshire, Coventry, England; [Griffiths, Madlen M.] Royal Devon & Exeter Hosp, Exeter, England	University of Warwick; University of Warwick; University of Exeter	Hwang, T (corresponding author), Univ Warwick, Warwick Med Sch, Coventry, England.; Hwang, T (corresponding author), Univ Hosp Coventry & Warwickshire, Coventry, England.	taesoon.hwang@warwick.ac.uk		Hwang, Taesoon/0000-0002-9312-8198; Mahmood, Amir/0009-0000-3419-1448; Aggarwal, Nishant/0000-0002-1931-390X				Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Babl FE, 2023, EMERG MED AUSTRALAS, V35, P809, DOI 10.1111/1742-6723.14233; Buholayka M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39386; Chen L., 2023, ARXIV; Chhapola Viswas, 2018, J Evid Based Med, V11, P89, DOI 10.1111/jebm.12294; Cindro PV, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2021-054978; Eppler MB, 2023, UROL PRACT, V10, P435, DOI 10.1097/UPJ.0000000000000428; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Hays M, 2016, BMJ OPEN, V6, DOI 10.1136/bmjopen-2016-011082; Hopewell S, 2008, PLOS MED, V5, P48, DOI 10.1371/journal.pmed.0050020; Hua F, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2019-029270; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Obermeyer F, 2022, SCIENCE, V376, P1327, DOI 10.1126/science.abm1208; OpenAI, 2023, GPT-4; Song SY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187807; Speich B, 2019, WORLD J SURG, V43, P2371, DOI 10.1007/s00268-019-05064-1; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Valentin-Bravo F J, 2023, Arch Soc Esp Oftalmol (Engl Ed), V98, P298, DOI 10.1016/j.oftale.2023.04.011	20	0	0	26	26	PUBLIC LIBRARY SCIENCE	SAN FRANCISCO	1160 BATTERY STREET, STE 100, SAN FRANCISCO, CA 94111 USA	1932-6203			PLOS ONE	PLoS One	FEB 14	2024	19	2							e0297701	10.1371/journal.pone.0297701	http://dx.doi.org/10.1371/journal.pone.0297701			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	IC7I0	38354135	gold, Green Published			2024-07-03	WOS:001164185700038
J	Gerli, AG; Soriano, JB; Alicandro, G; Salvagno, M; Taccone, F; Centanni, S; La Vecchia, C				Gerli, Alberto G.; Soriano, Joan B.; Alicandro, Gianfranco; Salvagno, Michele; Taccone, Fabio; Centanni, Stefano; La Vecchia, Carlo			ChatGPT: unlocking the potential of Artifical Intelligence in COVID-19 monitoring and prediction	PANMINERVA MEDICA			English	Article						K ey words : COVID-19; Artificial intelligence; Public health; Pandemics.		BACKGROUND: The COVID-19 pandemic has had an unprecedent impact of everyday life with deleterious consequences on global health, economics, and society. Thus, accurate and timely information is critical for monitoring its spread and mitigating its impact. ChatGPT is a large language model chatbot with artificial intelligence, developed by OpenAI, that can provide both textual content and R code for predictive models. It may prove to be useful in analyzing and interpreting COVID-19-related data.METHODS: This paper explores the application of ChatGPT to the monitoring of the COVID-19 pandemic, presenting R code for predictive models and demonstrating the model's capabilities in sentiment analysis, information extraction, and predictive modelling. We used the prediction models suggested by ChatGPT to predict the daily number of COVID-19 deaths in Italy. The prediction accuracy of the models was compared using the following metrics: mean squared error (MSE), mean absolute deviation (MAD) and root mean squared error (RMSE).RESULTS: ChatGPT suggested three different predictive models, including ARIMA, Random Forest and Prophet. The ARIMA model outperformed the other two models in predicting the daily number of COVID-19 deaths in Italy, with lower MSE, MAD, and RMSE values as compared to the random Forest and Prophet.CONCLUSIONS: This paper demonstrates the potential of ChatGPT as a valuable tool in the monitoring of the pandemic. By processing large amounts of data and providing relevant information, ChatGPT has the potential to provide accurate and timely insights, and support decisionmaking processes to mitigate the spread and impact of pandemics. The paper highlights the importance of exploring the capabilities of artificial intelligence in the management of public emergencies and provides a starting point for future research in this area. (Cite this article as: Gerli AG, Soriano JB, Alicandro G, Salvagno M, Taccone F, Centanni S, et al. ChatGPT: unlocking the potential of Artifical Intelligence in COVID-19 monitoring and prediction. Panminerva Med 2023;65:461-6. DOI: 10.23736/S0031-0808.23.04853-X)	[Gerli, Alberto G.; La Vecchia, Carlo] Univ Milan, Dept Clin Sci & Community Hlth, Milan, Italy; [Soriano, Joan B.] Hosp Univ La Princesa, Unit Pulmonol, Madrid, Spain; [Soriano, Joan B.] Autonomous Univ Madrid, Fac Med, Madrid, Spain; [Soriano, Joan B.] Carlos III Hlth Inst, Ctr Invest Biomyd Red Enfermedades Resp CIBERES, Madrid, Spain; [Alicandro, Gianfranco] Univ Milan, Dept Pathophysiol & Transplantat, Milan, Italy; [Alicandro, Gianfranco] Fdn IRCCS Ca Granda Osped Maggiore Policlin, Cyst Fibrosis Ctr, Milan, Italy; [Salvagno, Michele; Taccone, Fabio] Univ Libre Bruxelles, Erasme Hosp, Dept Intens Care, Brussels, Belgium; [Centanni, Stefano] Univ Milan, Dept Hlth Sci, Resp Unit, ASST Santi Paolo & Carlo, Milan, Italy; [Gerli, Alberto G.] Univ Milan, Dept Clin Sci & Community Hlth, Via Celoria 22, I-20133 Milan, Italy	University of Milan; Hospital de La Princesa; Autonomous University of Madrid; University of Milan; IRCCS Ca Granda Ospedale Maggiore Policlinico; Universite Libre de Bruxelles; University of Milan; University of Milan	Gerli, AG (corresponding author), Univ Milan, Dept Clin Sci & Community Hlth, Via Celoria 22, I-20133 Milan, Italy.	alberto.gerli@unimi.it	Alicandro, Gianfranco/AAR-4989-2021; La Vecchia, Carlo/Z-1710-2019	Alicandro, Gianfranco/0000-0002-0430-2714; La Vecchia, Carlo/0000-0003-1441-897X	EU funding within the NextGenerationEU-MUR PNRR Extended Partnership initiative on Emerging Infectious Diseases [PE00000007]	EU funding within the NextGenerationEU-MUR PNRR Extended Partnership initiative on Emerging Infectious Diseases	This research was supported by EU funding within the NextGenerationEU-MUR PNRR Extended Partnership initiative on Emerging Infectious Diseases (Project no. PE00000007, INF-ACT)	[Anonymous], 2023, ChatGPT: friend or foe? Lancet Digit Health; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Che SP, 2024, J PUBLIC HEALTH-HEID, V32, P509, DOI 10.1007/s10389-023-01833-4; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.1136/bmj.g7594, 10.1016/j.jclinepi.2014.11.010, 10.7326/M14-0697, 10.1002/bjs.9736, 10.1186/s12916-014-0241-z, 10.1038/bjc.2014.639, 10.7326/M14-0698, 10.1016/j.eururo.2014.11.025]; Gerli AG, 2020, MINERVA MED, V111, P308, DOI 10.23736/S0026-4806.20.06702-6; github, About us; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Liang B, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107643; Looi MK, 2023, BMJ-BRIT MED J, V380, DOI 10.1136/bmj.p205; Ogallo W, 2023, J AM MED INFORM ASSN, V30, P634, DOI 10.1093/jamia/ocac223; Patrucco F, 2020, PANMINERVA MED, V62, P73, DOI 10.23736/S0031-0808.20.03897-5; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Soriano JB, 2023, CHINESE MED J-PEKING, V136, P1, DOI 10.1097/CM9.0000000000002149; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; The R Project for Statistical Computing, ABOUT US; Villegas Marta, 2023, Comput Methods Programs Biomed Update, V3, P100089, DOI 10.1016/j.cmpbup.2022.100089; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2177160; Zuo ZB, 2023, BMC PUBLIC HEALTH, V23, DOI 10.1186/s12889-023-15081-4	19	0	0	24	27	EDIZIONI MINERVA MEDICA	TURIN	CORSO BRAMANTE 83-85 INT JOURNALS DEPT., 10126 TURIN, ITALY	0031-0808	1827-1898		PANMINERVA MED	Panminerva Medica	DEC	2023	65	4					461	466		10.23736/S0031-0808.23.04853-X	http://dx.doi.org/10.23736/S0031-0808.23.04853-X			6	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	CK1K2	37535043				2024-07-03	WOS:001125052900019
J	Bekker, M				Bekker, Martin			Large language models and academic writing: Five tiers of engagement	SOUTH AFRICAN JOURNAL OF SCIENCE			English	Editorial Material						large language models; academic; integrity; academic writing; authorship; transparency			[Bekker, Martin] Univ Witwatersrand, Sch Elect & Informat Engn, Johannesburg, South Africa	University of Witwatersrand	Bekker, M (corresponding author), Univ Witwatersrand, Sch Elect & Informat Engn, Johannesburg, South Africa.	martin.bekker@wits.ac.za		Bekker, Martin/0000-0001-8766-937X				[Anonymous], 1979, BELM REP ETH PRINC G; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chesterton G.K., 1908, ORTHODOXY; Emerson RW, 1983, Essays and lectures, P261; Eslami M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300724; Jansen B J., 2023, Natural Language Processing Journal, P100020, DOI DOI 10.1016/J.NLP.2023.100020; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; King MR, 2023, CELL MOL BIOENG, V16, P95, DOI 10.1007/s12195-023-00765-z; Kulesz O, 2023, The impact of large language models on the publishing sectors: Books, academic journals, newspapers; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Perrigo B, 2023, TIME; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Spitale G, 2023, Arxiv, DOI arXiv:2301.11924; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Thaler Sv, 2023, Civil Action No. 22-1564 (BAH)	17	0	0	11	11	ACAD SCIENCE SOUTH AFRICA - ASSAf	LYNWOOD RIDGE	PO BOX 72135, LYNWOOD RIDGE 0040, SOUTH AFRICA	0038-2353	1996-7489		S AFR J SCI	S. Afr. J. Sci.	JAN-FEB	2024	120	1-2							17147	10.17159/sajs.2024/17147	http://dx.doi.org/10.17159/sajs.2024/17147			5	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HE7P7		gold			2024-07-03	WOS:001157885900006
J	Pesovski, I; Santos, R; Henriques, R; Trajkovik, V				Pesovski, Ivica; Santos, Ricardo; Henriques, Roberto; Trajkovik, Vladimir			Generative AI for Customizable Learning Experiences	SUSTAINABILITY			English	Article						personalized learning; AI for learning; character-based learning; automated content generation; LLMs in education; innovative teaching methods; learning management systems	ACADEMIC-PERFORMANCE; TECHNOLOGY; PARTICIPATION; ENGAGEMENT	The introduction of accessible generative artificial intelligence opens promising opportunities for the implementation of personalized learning methods in any educational environment. Personalized learning has been conceptualized for a long time, but it has only recently become realistic and truly achievable. In this paper, we propose an affordable and sustainable approach toward personalizing learning materials as part of the complete educational process. We have created a tool within a pre-existing learning management system at a software engineering college that automatically generates learning materials based on the learning outcomes provided by the professor for a particular class. The learning materials were composed in three distinct styles, the initial one being the traditional professor style and the other two variations adopting a pop-culture influence, namely Batman and Wednesday Addams. Each lesson, besides being delivered in three different formats, contained automatically generated multiple-choice questions that students could use to check their progress. This paper contains complete instructions for developing such a tool with the help of large language models using OpenAI's API and an analysis of the preliminary experiment of its usage performed with the help of 20 college students studying software engineering at a European university. Participation in the study was optional and on voluntary basis. Each student's tool usage was quantified, and two questionnaires were conducted: one immediately after subject completion and another 6 months later to assess both immediate and long-term effects, perceptions, and preferences. The results indicate that students found the multiple variants of the learning materials really engaging. While predominantly utilizing the traditional variant of the learning materials, they found this approach inspiring, would recommend it to other students, and would like to see it more in classes. The most popular feature were the automatically generated quiz-style tests that they used to assess their understanding. Preliminary evidence suggests that the use of various versions of learning materials leads to an increase in students' study time, especially for students who have not mastered the topic otherwise. The study's small sample size of 20 students restricts its ability to generalize its findings, but its results provide useful early insights and lay the groundwork for future research on AI-supported educational strategies.	[Pesovski, Ivica] Brainster Next Coll, Software Engn & Innovat, Skopje 1000, North Macedonia; [Santos, Ricardo; Henriques, Roberto] Univ Nova Lisboa, NOVA Informat Management Sch NOVA IMS, P-1070312 Lisbon, Portugal; [Trajkovik, Vladimir] Ss Cyril & Methodius Univ, Fac Comp Sci & Engn, Skopje 1000, North Macedonia	Universidade Nova de Lisboa; Saints Cyril & Methodius University of Skopje	Pesovski, I (corresponding author), Brainster Next Coll, Software Engn & Innovat, Skopje 1000, North Macedonia.	ivica@next.edu.mk; rcsantos@novaims.unl.pt; roberto@novaims.unl.pt; trvlado@finki.ukim.mk		Trajkovik, Vladimir/0000-0001-8103-8059				Abou-Khalil V, 2021, EDUC SCI, V11, DOI 10.3390/educsci11010024; Abulibdeh A, 2024, J CLEAN PROD, V437, DOI 10.1016/j.jclepro.2023.140527; Agrusti F, 2019, J E-LEARN KNOWL SOC, V15, P161, DOI 10.20368/1971-8829/1135017; Akçayir G, 2018, COMPUT EDUC, V126, P334, DOI 10.1016/j.compedu.2018.07.021; Aldahwan N., 2020, International Journal of Computer Applications, V175, P16, DOI DOI 10.5120/IJCA2020920611; Alhumaid K., 2019, J ED SOCIAL RES, V9, P10; Arias M., 2011, P INT C COMPUTER SUP, V2, P93; Balkaya S, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13031127; Bergdahl N, 2020, COMPUT EDUC, V149, DOI 10.1016/j.compedu.2019.103783; Bergmann J., 2012, Flip your classroom: Reach every student in every class every day; Bernacki ML, 2020, COMPUT EDUC, V158, DOI 10.1016/j.compedu.2020.103999; Bernius JP., 2022, Computers and Education: Artificial Intelligence, V3, P100081, DOI [DOI 10.1016/J.CAEAI.2022.100081, 10.1016/j.caeai.2022.100081]; Bhat S., 2022, P 15 INT C ED DATA M, VVolume 701; BLOOM BS, 1984, EDUC LEADERSHIP, V41, P4; Boeren E, 2019, INT REV EDUC, V65, P277, DOI 10.1007/s11159-019-09772-7; Bond M, 2024, INT J EDUC TECHNOL H, V21, DOI 10.1186/s41239-023-00436-z; Callaghan N, 2021, EDUC MEDIA INT, V58, P355, DOI 10.1080/09523987.2021.1992864; Chan YM, 2010, PROCD SOC BEHV, V9, DOI 10.1016/j.sbspro.2010.12.326; Coates H, 2005, TERT EDUC MANAG, V11, P19, DOI 10.1007/s11233-004-3567-9; Cox SR, 2023, Arxiv, DOI arXiv:2312.16534; Davies R.S., 2014, Handbook of Research on Educational Communications and Technology, P841, DOI DOI 10.1007/978-1-4614-3185-5; Devi D., 2023, Int. Manag. Rev, V19, P111; Dror I.E., 2008, PRAGMATICS COGNITION, V16, P215; Dunn TJ, 2019, COMPUT EDUC, V137, P104, DOI 10.1016/j.compedu.2019.04.004; Eckerdal JR., 2017, P 9 INT C CONCEPTION; Ferrara E., 2023, Sci, V6, P3, DOI 10.3390/sci6010003; Firat M., 2023, Technology and Lifelong Learning, V4, P1, DOI DOI 10.52911/ITALL.1244453; Fonseca D, 2014, COMPUT HUM BEHAV, V31, P434, DOI 10.1016/j.chb.2013.03.006; Galitsky BA, 2023, Preprints, DOI [10.20944/preprints202307.1723.v1, 10.20944/preprints202307.1723.v1, DOI 10.20944/PREPRINTS202307.1723.V1]; Gates B., AI Is about to Completely Change How You Use Computers; Gichoya JW, 2023, BRIT J RADIOL, V96, DOI 10.1259/bjr.20230023; Goel A.K., 2018, Learning Engineering for Online Education: Theoretical Contexts and Design-Based Examples; Grassini S, 2023, EDUC SCI, V13, DOI 10.3390/educsci13070692; Holstein K., 2021, arXiv; Jauhiainen JS, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151814025; Ji Z., 2023, P 2023 C EMPIRICAL M; Juban RL, 2013, J EDUC BUS, V88, P325, DOI 10.1080/08832323.2012.721023; Kapetanovic A., 2016, Ph.D. Thesis; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Klasnja-Milicevic A, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13126713; Koraishi O., 2023, Language Education & Technology, V3, P55; Kovanovic V., 2015, Journal of Learning Analytics, V2, P81, DOI [DOI 10.18608/JLA.2015.23.6, 10.18608/jla.2015.23.6]; Kunicina N., 2018, P 2018 IEEE 59 INT S, P1; Lee UG, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-12249-8; Macfadyen LP, 2010, COMPUT EDUC, V54, P588, DOI 10.1016/j.compedu.2009.09.008; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Manuel L.C., 2022, J. Pendidik, V11, P56, DOI [10.24239/pdg.Vol11.Iss1.240, DOI 10.24239/PDG.VOL11.ISS1.240]; Martin F, 2018, ONLINE LEARN, V22, P205, DOI 10.24059/olj.v22i1.1092; Mikeladze T., 2023, P IRCEELT 2023 13 IN; Mondal S, 2023, TECHNOLOGIES, V11, DOI 10.3390/technologies11020044; Moore S, 2022, LECT NOTES COMPUT SC, V13450, P243, DOI 10.1007/978-3-031-16290-9_18; Morze N., 2021, Journal of Physics: Conference Series, V1840, DOI 10.1088/1742-6596/1840/1/012062; Mousavinasab E, 2021, INTERACT LEARN ENVIR, V29, P142, DOI 10.1080/10494820.2018.1558257; Ng AY, 2002, ADV NEUR IN, V14, P841; Ogunode N.J., 2023, Electron. Res. J. Soc. Sci. Humanit, V5, P18; Paredes D., Meet 'Will', the Digital Teacher for Renewable Energy; Pataranutaporn P, 2021, NAT MACH INTELL, V3, P1013, DOI 10.1038/s42256-021-00417-9; Patlins A., 2011, Proceedings of the 2011 IEEE 6th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS 2011), P660, DOI 10.1109/IDAACS.2011.6072852; Pedro F., 2019, Artificial intelligence in education: challenges and opportunities for sustainable development; Pesovski I., 2022, P ICERI2022 P, P5693; Pesovski I., 2022, P INT SCI C 75 ANNIV; Pesovski I., 2022, P EDULEARN22 P, P6451; Pesovski I., 2022, P ICT INNOVATIONS 20, P179; Pesovski I, 2022, INT CONF INFO TECH, DOI 10.1109/ITHET56107.2022.10032029; Pinto Gustavo, 2023, SBES '23: Proceedings of the XXXVII Brazilian Symposium on Software Engineering, P293, DOI 10.1145/3613372.3614197; Qadir Junaid, 2023, 2023 IEEE Global Engineering Education Conference (EDUCON), P1, DOI 10.1109/EDUCON54358.2023.10125121; Raja R., 2018, Journal of Applied and Advanced Research, V3, P33, DOI [10.21839/jaar.2018.v3iS1.165, DOI 10.21839/JAAR.2018.V3IS1.165]; Rashid T, 2016, COMPUT HUM BEHAV, V63, P604, DOI 10.1016/j.chb.2016.05.084; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Riestra-González M, 2021, COMPUT EDUC, V163, DOI 10.1016/j.compedu.2020.104108; Romero C, 2013, COMPUT EDUC, V68, P458, DOI 10.1016/j.compedu.2013.06.009; Roselli D, 2019, COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2019 ), P539, DOI 10.1145/3308560.3317590; Sailer M, 2023, LEARN INSTR, V83, DOI 10.1016/j.learninstruc.2022.101620; Santos R.M., 2023, Comput. Educ. Artif. Intell, V5, P100175, DOI [10.1016/j.caeai.2023.100175, DOI 10.1016/J.CAEAI.2023.100175]; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sarstedt M., 2019, CLUSTER ANALYSISCONC, P301, DOI DOI 10.1007/978-3-662-56707-4_9; Sougleridi E.I., 2023, P INT C INTERACTIVE, P363; Sridhar P, 2023, Arxiv, DOI arXiv:2306.17459; Taherdoost H., 2019, International Journal of Academic Research in Management (IJARM), V8, P1; Tejedor G, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11072086; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; van den Berg G, 2023, EDUC SCI, V13, DOI 10.3390/educsci13100998; Villegas-Ch W., 2020, P INT C INNOVATION R, P94; Villegas-Ch W, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155371; Wang ZC, 2021, Arxiv, DOI arXiv:2109.04546; Wei JH, 2024, Arxiv, DOI arXiv:2402.10412; Xu ZW, 2024, Arxiv, DOI arXiv:2401.11817; Yao JY, 2023, Arxiv, DOI arXiv:2310.01469; Yathongchai C, 2013, IEEE CONF OPEN SYST, P66, DOI 10.1109/ICOS.2013.6735050; Zawacki-Richter O, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0171-0; Zhiravetska A, 2015, INT WORKSH INT DATA, P955, DOI 10.1109/IDAACS.2015.7341445; Zirpoli C.T., 2023, Generative artificial intelligence and copyright law	92	1	1	28	28	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2071-1050		SUSTAINABILITY-BASEL	Sustainability	APR	2024	16	7							3034	10.3390/su16073034	http://dx.doi.org/10.3390/su16073034			23	Green & Sustainable Science & Technology; Environmental Sciences; Environmental Studies	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Science & Technology - Other Topics; Environmental Sciences & Ecology	NN1C8		gold			2024-07-03	WOS:001201029300001
J	Elyoseph, Z; Levkovich, I				Elyoseph, Zohar; Levkovich, Inbar			Comparing the Perspectives of Generative AI, Mental Health Experts, and the General Public on Schizophrenia Recovery: Case Vignette Study	JMIR MENTAL HEALTH			English	Article							ARTIFICIAL-INTELLIGENCE; OPPORTUNITIES; EXPERIENCES; CHALLENGES; DEPRESSION; ALLIANCE; SYMPTOMS; CHATGPT	Background: The current paradigm in mental health care focuses on clinical recovery and symptom remission. This model's efficacy is influenced by therapist trust in patient recovery potential and the depth of the therapeutic relationship. Schizophrenia is a chronic illness with severe symptoms where the possibility of recovery is a matter of debate. As artificial intelligence (AI) becomes integrated into the health care field, it is important to examine its ability to assess recovery potential in major psychiatric disorders such as schizophrenia. Objective: This study aimed to evaluate the ability of large language models (LLMs) in comparison to mental health professionals to assess the prognosis of schizophrenia with and without professional treatment and the long-term positive and negative outcomes. Methods: Vignettes were inputted into LLMs interfaces and assessed 10 times by 4 AI platforms: ChatGPT-3.5, ChatGPT-4, Google Bard, and Claude. A total of 80 evaluations were collected and benchmarked against existing norms to analyze what mental health professionals (general practitioners, psychiatrists, clinical psychologists, and mental health nurses) and the general public think about schizophrenia prognosis with and without professional treatment and the positive and negative long-term outcomes of schizophrenia interventions. Results: For the prognosis of schizophrenia with professional treatment, ChatGPT-3.5 was notably pessimistic, whereas ChatGPT-4, Claude, and Bard aligned with professional views but differed from the general public. All LLMs believed untreated schizophrenia would remain static or worsen without professional treatment. For long-term outcomes, ChatGPT-4 and Claude predicted more negative outcomes than Bard and ChatGPT-3.5. For positive outcomes, ChatGPT-3.5 and Claude were more pessimistic than Bard and ChatGPT-4. Conclusions: The finding that 3 out of the 4 LLMs aligned closely with the predictions of mental health professionals when considering the "with treatment" condition is a demonstration of the potential of this technology in providing professional clinical prognosis. The pessimistic assessment of ChatGPT-3.5 is a disturbing finding since it may reduce the motivation of patients to start or persist with treatment for schizophrenia. Overall, although LLMs hold promise in augmenting health care, their application necessitates rigorous validation and a harmonious blend with human expertise.	[Elyoseph, Zohar] Imperial Coll London, Fac Med, Dept Brain Sci, London, England; [Elyoseph, Zohar] Max Stern Yezreel Valley Coll, Ctr Psychobiol Res, Dept Psychol & Educ Counseling, Emek Yezreel, Israel; [Levkovich, Inbar] Oranim Acad Coll, Fac Grad Studies, Qiryat Tivon, Israel; [Elyoseph, Zohar] Imperial Coll London, Fac Med, Dept Brain Sci, Fulham Palace Rd, London W6 8RP, England	Imperial College London; Imperial College London	Elyoseph, Z (corresponding author), Imperial Coll London, Fac Med, Dept Brain Sci, Fulham Palace Rd, London W6 8RP, England.	zohare@yvc.ac.il		Elyoseph, Zohar/0000-0002-5717-4074; Levkovich, Inbar/0000-0003-1582-3889				Ali O, 2023, J INNOV KNOWL, V8, DOI 10.1016/j.jik.2023.100333; [Anonymous], 2024, openai; Asman O, 2023, AM J BIOETHICS, V23, P62, DOI 10.1080/15265161.2023.2191046; Babcock G, 2023, BIOL J LINN SOC, V139, P415, DOI 10.1093/biolinnean/blac058; Bard, Google; Barkham M, 2021, Bergin and Garfield's Handbook of Psychotherapy and Behavior Change, V6th, P393; Caldwell T M, 2001, Aust N Z J Ment Health Nurs, V10, P42; ChatGPT-4, OpenAI; Claude, Antropic; Correll CU, 2020, NEUROPSYCH DIS TREAT, V16, P519, DOI 10.2147/NDT.S225643; Couture V, 2023, J MED INTERNET RES, V25, DOI 10.2196/44357; Cuijpers P, 2021, WORLD PSYCHIATRY, V20, P283, DOI 10.1002/wps.20860; Cuijpers P, 2019, ANNU REV CLIN PSYCHO, V15, P207, DOI 10.1146/annurev-clinpsy-050718-095424; Dragioti E, 2017, ACTA PSYCHIAT SCAND, V136, P236, DOI 10.1111/acps.12713; Elyoseph Z, 2024, JMIR MENT HEALTH, V11, DOI 10.2196/54369; Elyoseph Z, 2024, AM J BIOETHICS, V24, P57, DOI 10.1080/15265161.2023.2278546; Elyoseph Z, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1213141; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Fimiani R, 2023, PSYCHOTHER RES, V33, P729, DOI 10.1080/10503307.2022.2157227; Flückiger C, 2018, PSYCHOTHERAPY, V55, P316, DOI 10.1037/pst0000172; Gunasekaran S, 2022, BMC HEALTH SERV RES, V22, DOI 10.1186/s12913-022-08248-z; Haber Y, 2024, JMIR MENT HEALTH, V11, DOI 10.2196/54781; Habtewold TD, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-36235-9; Hadar-Shoval D, 2023, FRONT PSYCHIATRY, V14, DOI 10.3389/fpsyt.2023.1234397; Hasan A, 2013, WORLD J BIOL PSYCHIA, V14, P2, DOI 10.3109/15622975.2012.739708; Hirosawa T, 2023, AM J MED, V136, P1119, DOI 10.1016/j.amjmed.2023.08.003; Hochstetter A, 2020, ACS NANO, V14, P10784, DOI 10.1021/acsnano.0c05186; Hong SJ, 2019, J RELIG HEALTH, V58, P1516, DOI 10.1007/s10943-018-0729-5; Imran N, 2023, PAK J MED SCI, V39, P1191, DOI 10.12669/pjms.39.4.8118; Jääskeläinen E, 2013, SCHIZOPHRENIA BULL, V39, P1296, DOI 10.1093/schbul/sbs130; Jorgensen K, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17238777; Jorm AF, 1997, AUST NZ J PSYCHIAT, V31, P844, DOI 10.3109/00048679709065510; Karabacak M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48163; Kennedy S, 2021, EUR J OBSTET GYN R B, V264, P150, DOI 10.1016/j.ejogrb.2021.07.003; Kidd SA, 2014, CAN J PSYCHIAT, V59, P243, DOI 10.1177/070674371405900503; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Levkovich I, 2023, FAM MED COMMUNITY HE, V11, DOI 10.1136/fmch-2023-002391; Levkovich I, 2023, JMIR MENT HEALTH, V10, DOI 10.2196/51232; Lieberman JA, 2005, NEW ENGL J MED, V353, P1209, DOI 10.1056/NEJMoa051688; Mariani MM, 2023, J BUS RES, V155, DOI 10.1016/j.jbusres.2022.113364; McCutcheon RA, 2020, JAMA PSYCHIAT, V77, P201, DOI 10.1001/jamapsychiatry.2019.3360; Menezes NM, 2006, PSYCHOL MED, V36, P1349, DOI 10.1017/S0033291706007951; Paliwal B, 2023, Applications of Machine Learning and Deep Learning on Biological Data, P21, DOI [10.1201/9781003328780-2, DOI 10.1201/9781003328780-2]; Patterson JE, 2018, FAM PROCESS, V57, P70, DOI 10.1111/famp.12281; Rabelo-da-Ponte FD, 2023, Digital Mental Health: A Practitioner's Guide, P207, DOI [10.1007/978-3-031-10698-9_13, DOI 10.1007/978-3-031-10698-9_13]; Rahme C, 2023, BMC PSYCHIATRY, V23, DOI 10.1186/s12888-023-04531-3; Richardson JP, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00509-1; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Singh OP, 2023, INDIAN J PSYCHIAT, V65, P297, DOI 10.4103/indianjpsychiatry.indianjpsychiatry_112_23; Slade M, 2014, WORLD PSYCHIATRY, V13, P12, DOI 10.1002/wps.20084; Song HF, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-02021-3; Sullivan PW, 2017, J Psychosoc Rehabil Ment Health, V4, P221, DOI [DOI 10.1007/S40737-017-0097-6, 10.1007/s40737-017-0097-6]; Tal A, 2023, AM J BIOETHICS, V23, P74, DOI 10.1080/15265161.2023.2250297; Tyagi A, 2023, MULTIMED TOOLS APPL, V82, P20343, DOI 10.1007/s11042-022-13809-9; Wampold BE, 2023, WORLD PSYCHIATRY, V22, P25, DOI 10.1002/wps.21035; Warner R., 2013, Recovery from Schizophrenia: Psychiatry and Political Economy, V3rd, DOI [10.4324/9780203420874, DOI 10.4324/9780203420874]; White C, 2018, PSYCHIAT QUART, V89, P261, DOI 10.1007/s11126-017-9531-x; Wilks D, 2018, J COUNS DEV, V96, P213, DOI 10.1002/jcad.12194; Winkler C, 2023, Entrepreneurship Education and Pedagogy, V6, P579, DOI [10.1177/25151274231198799, DOI 10.1177/25151274231198799]; Wittchen Hans-Ulrich, 2003, Dialogues Clin Neurosci, V5, P115; Wong DFK, 2019, RES SOCIAL WORK PRAC, V29, P311, DOI 10.1177/1049731517732837; Zilcha-Mano S, 2021, AM PSYCHOL, V76, P516, DOI 10.1037/amp0000629	62	2	2	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2368-7959			JMIR MENT HEALTH	JMIR Ment. Health		2024	11								e53043	10.2196/53043	http://dx.doi.org/10.2196/53043			13	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	NC3W8	38533615	gold			2024-07-03	WOS:001198221200001
J	Duan, GX; Chen, JJ; Zhou, YY; Zheng, XY; Zhu, YX				Duan, Gaoxiang; Chen, Jiajie; Zhou, Yueying; Zheng, Xiaoying; Zhu, Yongxin			Large Language Model Inference Acceleration Based on Hybrid Model Branch Prediction	ELECTRONICS			English	Article						large language model; auto regressive model; branch prediction; decoder; inference		As the size of deep learning models continues to expand, the elongation of inference time has gradually evolved into a significant challenge to efficiency and practicality for autoregressive models. This work introduces a hybrid model acceleration strategy based on branch prediction, which accelerates autoregressive model inference without requiring retraining and ensures output consistency with the original model. Specifically, the algorithm employs two models with different parameter sizes aimed at the same task. The smaller model generates a series of potential tokens that are then parallelly validated by the larger model to determine their acceptability. By orchestrating the workflow of the large and small models through a branch-prediction strategy, the algorithm conceals the validation time of the larger model when predictions are successful, thereby accelerating inference. We propose a binomial distribution-based prediction function that blends theoretical principles with empirical evidence, specifically designed for the nuanced requirements of accelerating inference within a hybrid model framework. The entire algorithm was designed and implemented on the llama model for text generation and translation tasks. The experimental results indicate significant improvements. The proposed algorithm achieves a 1.2x to 3.4x increase in inference speed compared to the original model, consistently outperforming the speculative sampling inference acceleration algorithm.	[Duan, Gaoxiang; Chen, Jiajie; Zhou, Yueying; Zheng, Xiaoying; Zhu, Yongxin] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China; [Duan, Gaoxiang; Chen, Jiajie; Zhou, Yueying; Zheng, Xiaoying; Zhu, Yongxin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Shanghai Advanced Research Institute, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS	Zheng, XY; Zhu, YX (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.; Zheng, XY; Zhu, YX (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.	duangx@sari.ac.cn; chenjiajie@sari.ac.cn; zhouyueying@sari.ac.cn; zhengxy@sari.ac.cn; zhuyongxin@sari.ac.cn		Zhou, Yueying/0009-0005-0690-7185; Zhu, Yongxin/0000-0002-1813-1792	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Dehghani M., 2021, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eldan R, 2023, Arxiv, DOI arXiv:2305.07759; Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945; Han YZ, 2022, IEEE T PATTERN ANAL, V44, P7436, DOI 10.1109/TPAMI.2021.3117837; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Kitaev N., 2020, arXiv; Leviathan Y., 2023, INT C MACHINE LEARNI, P19274; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu Y., 2024, IEEE Trans. Artif. Intell, DOI [10.1109/TAI.2023.3333767, DOI 10.1109/TAI.2023.3333767]; Qiu JZ, 2020, Arxiv, DOI arXiv:1911.02972; Schuster T, 2021, Arxiv, DOI arXiv:2104.08803; Schwartz R, 2020, Arxiv, DOI arXiv:2004.07453; Sennrich R, 2016, Arxiv, DOI [arXiv:1511.06709, DOI 10.48550/ARXIV.1511.06709]; Shazeer N, 2019, Arxiv, DOI arXiv:1911.02150; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Zhai Xiaohua, 2022, P IEEE CVF C COMP VI, P12104, DOI DOI 10.1109/CVPR52688.2022.01179; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zhou Z K, 2023, arXiv	21	0	0	3	3	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	APR	2024	13	7							1376	10.3390/electronics13071376	http://dx.doi.org/10.3390/electronics13071376			17	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	NM7Y3		gold			2024-07-03	WOS:001200946800001
J	Zubiaga, A				Zubiaga, Arkaitz			Natural language processing in the era of large language models	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Editorial Material						natural language processing; large language models (LLM); language models (LMs); specialty grand challenge; generative AI			[Zubiaga, Arkaitz] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England	University of London; Queen Mary University London	Zubiaga, A (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.	a.zubiaga@qmul.ac.uk	Zubiaga, Arkaitz/H-3808-2019	Zubiaga, Arkaitz/0000-0003-4583-3623				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Belz A, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P381; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen HL, 2024, Arxiv, DOI [arXiv:2311.16989, 10.48550/arXiv.2311.16989, DOI 10.48550/ARXIV.2311.16989]; Cinelli M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01487-w; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; Deng CY, 2024, Arxiv, DOI arXiv:2311.09783; Derczynski L., 2014, Proceedings of ESWC EU Project Networking; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dongwook Lee, 2019, arXiv; Gallegos IO, 2024, Arxiv, DOI arXiv:2309.00770; George A. Shaji., 2023, Partners Universal International Innovation Journal, V1, P154, DOI DOI 10.5281/ZENODO.8076921; Golchin S, 2024, Arxiv, DOI arXiv:2308.08493; Guo S., 2022, PREPRINT; Gurrapu S, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1225093; Kotek Hadas, 2023, CI '23: Proceedings of The ACM Collective Intelligence Conference, P12, DOI 10.1145/3582269.3615599; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li M, 2024, Arxiv, DOI arXiv:2308.12032; Li YJ, 2024, Arxiv, DOI arXiv:2308.10149; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Magar I, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P157; Mars M, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178805; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Navigli R, 2023, ACM J DATA INF QUAL, V15, DOI 10.1145/3597307; Noy S, 2023, Experimental Evidence on the Productivity Effects of Generative Artificial Intelligence; Pan XD, 2020, P IEEE S SECUR PRIV, P1314, DOI 10.1109/SP40000.2020.00095; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Raffel C, 2020, J MACH LEARN RES, V21; Rawte V., 2023, arXiv, DOI [10.18653/v1/2023.emnlp-main.155, DOI 10.18653/V1/2023.EMNLP-MAIN.155]; Rigaki M, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3624010; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Shayegani E, 2023, Arxiv, DOI arXiv:2310.10844; Shi WJ, 2024, Arxiv, DOI [arXiv:2310.16789, 10.48550/ARXIV.2310.16789, DOI 10.48550/ARXIV.2310.16789]; Srivastava A, 2023, Arxiv, DOI arXiv:2310.00892; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wan Y., 2023, arXiv, DOI [10.18653/v1/2023.findings-emnlp.243, DOI 10.18653/V1/2023.FINDINGS-EMNLP.243]; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xu YH, 2023, Arxiv, DOI arXiv:2310.06830; Yin WJ, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.598; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhao H., 2023, arXiv, DOI [10.1145/3639372, DOI 10.1145/3639372]	53	1	1	113	113	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	JAN 12	2024	6								1350306	10.3389/frai.2023.1350306	http://dx.doi.org/10.3389/frai.2023.1350306			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	GD2N8	38282904	gold, Green Published			2024-07-03	WOS:001150663700001
C	Chen, YY; Zhao, J; Wen, ZH; Li, ZX; Xiao, YH			Assoc computing machinery	Chen, Yuyan; Zhao, Jin; Wen, Zhihao; Li, Zhixu; Xiao, Yanghua			TemporalMed: Advancing Medical Dialogues with Time-Aware Responses in Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Medical dialogue; Large language models; Time-aware modeling		Medical dialogue models predominantly emphasize generating coherent and clinically accurate responses. However, in many clinical scenarios, time plays a pivotal role, often dictating subsequent patient management and interventions. Recognizing the latent importance of temporal dynamics, this paper introduces a novel dimension to medical dialogues: timestamps. We advocate that the integration of time-sensitive directives can profoundly impact medical advice, using an illustrative example of post-surgery care with and without timestamps. Our contributions are three-fold: Firstly, we highlight the intrinsic significance of timestamps in medical conversations, marking a paradigm shift in dialogue modeling. Secondly, we present an innovative dataset and framework explicitly tailored for time-stamped medical dialogues, facilitating the model to not only provide medical counsel but also chronologically outline care regimens. Lastly, empirical evaluations indicate our method's proficiency in time-stamped tasks and reveal an uptick in performance in broader medical Q&A domains. Through our endeavors, we aspire to set new benchmarks in patient-centric and time-sensitive medical dialogue systems.	[Chen, Yuyan; Zhao, Jin; Li, Zhixu; Xiao, Yanghua] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China; [Wen, Zhihao] Singapore Management Univ, Singapore, Singapore; [Xiao, Yanghua] Fudan Aishu Cognit Intelligence Joint Res Ctr, Shanghai, Peoples R China	Fudan University; Singapore Management University	Li, ZX; Xiao, YH (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China.	chenyuyan21@m.fudan.edu.cn; jinzhao20@fudan.edu.cn; zhwen.2019@phdcs.smu.edu.sg; zhixuli@fudan.edu.cn; shawyh@fudan.edu.cn		Wen, Zhihao/0000-0002-7688-5381; li, zhixu/0000-0003-2355-288X	Shanghai Municipal Science and Technology Major Project [2021SHZDZX0103]; Science and Technology Commission of Shanghai Municipality Grant [22511105902]; National Natural Science Foundation of China [62072323, U21A20488]; Shanghai Science and Technology Innovation Action Plan [22511104700]; Key Projects of Industrial Foresight and Key Core Technology Research and Development in Suzhou [SYC2022009]	Shanghai Municipal Science and Technology Major Project; Science and Technology Commission of Shanghai Municipality Grant(Science & Technology Commission of Shanghai Municipality (STCSM)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Science and Technology Innovation Action Plan; Key Projects of Industrial Foresight and Key Core Technology Research and Development in Suzhou	This work is supported by Shanghai Municipal Science and Technology Major Project (No.2021SHZDZX0103), Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902), the National Natural Science Foundation of China (No.62072323, U21A20488), Shanghai Science and Technology Innovation Action Plan (No. 22511104700), Key Projects of Industrial Foresight and Key Core Technology Research and Development in Suzhou(SYC2022009).	Ben Veyseh AP, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2335, DOI 10.1145/3132847.3133116; Cai Bibo, 2023, P AAAI C ARTIFICIAL, V37, P12580; Chen PC, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P554, DOI 10.1109/ASRU.2017.8268985; Conway R, 2019, Arxiv, DOI arXiv:1907.11315; Derczynski L, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P261; Diao SZ, 2024, Arxiv, DOI arXiv:2306.12420; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Jordan DG, 2020, J CLIN PSYCHOL, V76, P1591, DOI 10.1002/jclp.22957; Li J., 2016, P 2016 C N AM CHAPTE, P110, DOI DOI 10.18653/V1; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lu YJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5755; Malhotra GNS, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P735, DOI 10.1145/3488560.3498509; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Qin LH, 2021, Arxiv, DOI arXiv:2106.04571; Su S.-Y., 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), V1, P2133; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Wang RS, 2023, Arxiv, DOI arXiv:2307.10512; Xu CW, 2023, Arxiv, DOI [arXiv:2304.01196, DOI 10.48550/ARXIV.2304.01196]; Yang SH, 2023, Arxiv, DOI arXiv:2308.03549; Zeng GT, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9241; Zhang HB, 2023, Arxiv, DOI arXiv:2305.15075; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]	23	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							116	124		10.1145/3616855.3635860	http://dx.doi.org/10.1145/3616855.3635860			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100017
J	Du, XT; Liu, ZH; Li, CL; Ma, XY; Li, YZ; Wang, XY				Du, Xiaoting; Liu, Zhihao; Li, Chenglong; Ma, Xiangyue; Li, Yingzhuo; Wang, Xinyu			LLM-BRC: A large language model-based bug report classification framework	SOFTWARE QUALITY JOURNAL			English	Article; Early Access						Bug report classification; Deep learning framework; Large-language model		Deep learning frameworks serve as the cornerstone for constructing robust deep learning systems. However, bugs within these frameworks can have severe consequences, negatively affecting various applications. Accurately classifying and understanding these bugs is essential to ensure framework reliability. By doing so, developers can proactively take appropriate measures to mitigate potential risks associated with specific bug types in both current and future software releases. Despite the significance of bug report classification, existing methods fall short in terms of performance, rendering them impractical for real-world applications. To address this limitation, we propose a bug report classification framework for deep learning frameworks, called LLM-BRC, leveraging OpenAI's latest embedding model, text-embedding-ada-002. Our LLM-BRC framework achieves an impressive accuracy range of 92% to 98.75% in bug report classification for three deep learning frameworks: TensorFlow, MXNET, and PaddlePaddle. This represents a substantial improvement of 17.21% to 69.15% compared to existing methods. Furthermore, we conduct a comprehensive investigation into the impact of different bug report components and different models.	[Du, Xiaoting; Li, Yingzhuo; Wang, Xinyu] Beijing Univ Posts & Telecommun, Sch Comp Sci, Natl Pilot Software Engn Sch, Beijing, Peoples R China; [Du, Xiaoting] East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai 200062, Peoples R China; [Liu, Zhihao; Li, Chenglong; Ma, Xiangyue] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China	Beijing University of Posts & Telecommunications; East China Normal University; Beihang University	Du, XT (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Natl Pilot Software Engn Sch, Beijing, Peoples R China.; Du, XT (corresponding author), East China Normal Univ, Shanghai Key Lab Trustworthy Comp, Shanghai 200062, Peoples R China.	duxiaoting@bupt.edu.cn; li_chenglong@buaa.edu.cn			Fundamental Research Funds for the Central Universities	Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities)	No Statement Available	Al-Rfou R., 2016, arXiv; Antoniol G., 2008, Conference of the center for advanced studies on collaborative research: meeting of minds, P304; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312; Chen JJ, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3587155; Collobert R., 2002, Torch: a modular machine learning software library; Cotroneo D, 2013, PROC INT SYMP SOFTW, P178, DOI 10.1109/ISSRE.2013.6698917; Du XT, 2023, IEEE T DEPEND SECURE, V20, P2696, DOI 10.1109/TDSC.2022.3152239; Du XT, 2022, IEEE T RELIAB, V71, P1540, DOI 10.1109/TR.2021.3110096; Du XT, 2017, IEEE INT SYMP SOFTW, P259, DOI 10.1109/ISSREW.2017.28; Frattini F, 2016, SPRINGER SER RELIAB, P551, DOI 10.1007/978-3-319-30599-8_21; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Girija SS., 2016, TENSORFLOW LARGE SCA, V39; Grottke M., 2005, The Journal of Reliability Engineering Association of Japan, V27, P425; Guo QY, 2018, Arxiv, DOI arXiv:1811.05187; Guo SS, 2023, Arxiv, DOI arXiv:2302.07142; Herzig K, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P392, DOI 10.1109/ICSE.2013.6606585; Islam MJ, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P510, DOI 10.1145/3338906.3338955; Jia L, 2021, J SYST SOFTWARE, V177, DOI 10.1016/j.jss.2021.110935; Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889; Liu SQ, 2014, I S BIOMED IMAGING, P1015, DOI 10.1109/ISBI.2014.6868045; Liu ZH, 2022, PROC INT SYMP SOFTW, P423, DOI 10.1109/ISSRE55969.2022.00048; Lux M., 2019, ACM SIGMultimedia Records, V10, P7, DOI [10.1145/3310195.3310202, DOI 10.1145/3310195.3310202]; Makkouk T, 2022, PROC IEEE INT CONF S, P35, DOI 10.1109/ICSME55016.2022.00012; Mingxi Li, 2021, 2021 8th International Conference on Dependable Systems and Their Applications (DSA), P474, DOI 10.1109/DSA52907.2021.00071; Nov O., 2023, medRxiv, P2023; Otoom AF, 2019, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND MANAGEMENT (ICICM 2019), P17, DOI 10.1145/3357419.3357424; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pingclasai N, 2013, ASIA PAC SOFWR ENG, P13, DOI 10.1109/APSEC.2013.105; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Ren Y, 2020, Arxiv, DOI arXiv:2005.06091; Tambon F, 2023, Arxiv, DOI [arXiv:2112.13314, DOI 10.48550/ARXIV.2112.13314]; Vaswani A, 2017, ADV NEUR IN, V30; Wen W, 2016, PROC INT SYMP SOFTW, P150, DOI 10.1109/ISSRE.2016.29; Xia X, 2014, IEEE INT C ENG COMP, P39, DOI 10.1109/ICECCS.2014.14; Yang YL, 2022, INFORM SOFTWARE TECH, V151, DOI 10.1016/j.infsof.2022.107004; Zhang JM, 2022, IEEE T SOFTWARE ENG, V48, P1, DOI 10.1109/TSE.2019.2962027; Zhang YH, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P129, DOI 10.1145/3213846.3213866	40	0	0	1	1	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0963-9314	1573-1367		SOFTWARE QUAL J	Softw. Qual. J.	2024 MAY 24	2024										10.1007/s11219-024-09675-3	http://dx.doi.org/10.1007/s11219-024-09675-3		MAY 2024	21	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RU1G8					2024-07-03	WOS:001230075700001
J	Tustumi, F; Andreollo, NA; de Aguilar-Nascimento, JE				Tustumi, Francisco; Andreollo, Nelson Adami; de Aguilar-Nascimento, Jose Eduardo			FUTURE OF THE LANGUAGE MODELS IN HEALTHCARE: THE ROLE OF CHATGPT	ABCD-ARQUIVOS BRASILEIROS DE CIRURGIA DIGESTIVA-BRAZILIAN ARCHIVES OF DIGESTIVE SURGERY			English	Review						Guidelines as topic; Artificial intelligence; Diagnosis; Costs and cost analysis; Delivery of health care	OUTCOME SELECTION BIAS	The field of medicine has always been at the forefront of technological innovation, Fabricio Ferreira COELHO3 , Paulo HERMAN3 constantly seeking new strategies to diagnose, treat, and prevent diseases. Guidelines for clinical practice to orientate medical teams regarding diagnosis, treatment, and prevention measures have increased over the years. The purpose is to gather the most medical knowledge to construct an orientation for practice. Evidence-based guidelines follow several main characteristics of a systematic RESUMO -Racmonal: O tratamento de escolha para pacientes com ipertensao portal review, including systematic and unbiased search, selection, and extraction of the source of evidence. esquistossomotica com sangramento de varizes e a desconexao azigo-portal mais In recent years, the rapid advancement of artificial intelligence has provided clinicians and patients esplenetomia (DAPE) associad a terapa endoscoica. Porem, estuds mostram aumento with access to personalized, data-driven insights, suport and new opportunities for healthcare do calibre das varizes em alguns pacientes durante o seguimento em longo prazo. Objetmvo: professionals to improve patient outcomes, increase efficiency, and reduce costs. One of the most Avaliar o impacto da DAPE e tratamento endoscopico pos-operatorio no comportamento exciting developments in Artificial Intelligence has been the emergence of chatbots. A chatbot is a computer program used to simulate conversations with human users. Recently, OpenAI, a research das varizes esofagicas e recidiva hemorragica, de pacientes esquistossomoticos. Metodos: organization focused on machine learning, developed ChatGPT, a large language model that Foram estudados 36 pacientes com eguimento superior a cinco anos, distribuidos em generates human-like text. ChatGPT uses a type of AI known as a deep learning model. ChatGPT dois grupos: qued a prssao portal abaixo de 30% e acima de 30% compaados com o can quickly search a nd select pieces of evidence through numerous databases to provide answers calibre das varizes esofagicas no pos-operatorio precoce e tardio alem do indice de recidiva to complex questions, reducing the time and effort required to research a particular topic manually. hemorragica. Resultados Consequently, language models can accelerate the creation of clinical practice guidelines. While there is no doubt that ChatGPT has the potential to revolutionize the way healthcare is delivered, esofagicas que, durante o seguimento aumentaram de calibre e foram controladas com it is essential to note that it should not be used as a substitute for human healthcare professionals. Instead, ChatGPT should be considered a tool that can be used to augment and support the work of o comportamento do calibre das varizes no pos-opeatorio precoce nem tardio nem os healthcare professionals, helping them to provide better care to their patients.	[Tustumi, Francisco] Univ Sao Paulo, Fac Med, Dept Gastroenterol, Sao Paulo, SP, Brazil; [Andreollo, Nelson Adami] Univ Estadual Campinas, Fac Med Sci, Dept Surg, Digst Dis Surg Unit, Campinas, SP, Brazil; [de Aguilar-Nascimento, Jose Eduardo] Univ Fed Mato Grosso, Med Sch, Dept Surg, Cuiaba, MT, Brazil	Universidade de Sao Paulo; Universidade Estadual de Campinas; Universidade Federal de Mato Grosso	Tustumi, F (corresponding author), Univ Sao Paulo, Fac Med, Dept Gastroenterol, Sao Paulo, SP, Brazil.	franciscotustumi@gmail.com	Tustumi, Francisco/K-4992-2017	Tustumi, Francisco/0000-0001-6695-0496; Andreollo, Nelson Adami/0000-0001-7452-1165				Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; AlRyalat SAS, 2019, JOVE-J VIS EXP, DOI 10.3791/58494; Athota Lekha, 2020, 2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO), P619, DOI 10.1109/ICRITO48877.2020.9197833; Aydin O., 2022, Openai chatgpt generated literature review: Digital twin in healthcare; Brouwers MC, 2019, SEMIN NUCL MED, V49, P145, DOI 10.1053/j.semnuclmed.2018.11.001; Dickson R., 2017, Doing a Systematic Review: A Students Guide, V2nd, P1, DOI [10.53841/bpsicpr.2020.15.2.119, DOI 10.53841/BPSICPR.2020.15.2.119]; Engle RL, 2021, HEALTH CARE MANAGE R, V46, P174, DOI 10.1097/HMR.0000000000000254; Hernán MA, 2004, EPIDEMIOLOGY, V15, P615, DOI 10.1097/01.ede.0000135174.63482.43; Isolan G, 2021, ABCD-ARQ BRAS CIR DI, V34, DOI 10.1590/0102-672020210003e1584; Kho ME, 2009, BMJ-BRIT MED J, V338, DOI 10.1136/bmj.b866; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Li NH, 2019, AAAI CONF ARTIF INTE, P6706; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Murad M Hassan, 2016, Evid Based Med, V21, P125, DOI 10.1136/ebmed-2016-110401; Nadarzynski T, 2019, DIGIT HEALTH, V5, DOI 10.1177/2055207619871808; Ntoutsi E, 2020, WIRES DATA MIN KNOWL, V10, DOI 10.1002/widm.1356; Rother Edna Terezinha, 2007, Acta paul. enferm., V20, pv; Seyhan A. A., 2019, Transl. Med. Commun, V4, P1, DOI DOI 10.1186/S41231-019-0050-7; THOMPSON SG, 1994, BMJ-BRIT MED J, V309, P1351, DOI 10.1136/bmj.309.6965.1351; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Urra EM, 2010, REV LAT-AM ENFERM, V18, P824, DOI 10.1590/S0104-11692010000400023; Williamson PR, 2005, STAT METHODS MED RES, V14, P515, DOI 10.1191/0962280205sm415oa; Williamson PR, 2005, STAT MED, V24, P1547, DOI 10.1002/sim.2025; Yao XM, 2021, J GEN INTERN MED, V36, P207, DOI 10.1007/s11606-020-05825-y; Yu KH, 2018, NAT BIOMED ENG, V2, P719, DOI 10.1038/s41551-018-0305-z	25	20	20	13	55	COLEGIO BRASILEIRO CIRURGIA DIGESTIVA-CBCD	SAO PAULO SP	AV BRIGADEIRO LUIZ ANTONIO, 278-6-SALAS 10 E 11, SAO PAULO SP, 01318-901, BRAZIL	0102-6720	2317-6326		ABCD-ARQ BRAS CIR DI	ABCD-Arq. Bras. Cir. Dig.-Braz. Arch. Dig. Surg.		2023	36	1							e1727	10.1590/0102-672020230002e1727	http://dx.doi.org/10.1590/0102-672020230002e1727			5	Gastroenterology & Hepatology	Emerging Sources Citation Index (ESCI)	Gastroenterology & Hepatology	H1SA5	37162073	gold, Green Submitted, Green Published			2024-07-03	WOS:000993819100001
C	Lucchese, C; Minello, G; Nardini, FM; Orlando, S; Perego, R; Veneri, A			ACM	Lucchese, Claudio; Minello, Giorgia; Nardini, Franco Maria; Orlando, Salvatore; Perego, Raffaele; Veneri, Alberto			Can Embeddings Analysis Explain Large Language Model Ranking?	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Explainable Artificial Intelligence; Large Language Models; Embeddings Analysis; Text Ranking		Understanding the behavior of deep neural networks for Information Retrieval (IR) is crucial to improve trust in these effective models. Current popular approaches to diagnose the predictions made by deep neural networks are mainly based on: i) the adherence of the retrieval model to some axiomatic property of the IR system, ii) the generation of free-text explanations, or iii) feature importance attributions. In this work, we propose a novel approach that analyzes the changes of document and query embeddings in the latent space and that might explain the inner workings of IR large pre-trained language models. In particular, we focus on predicting query/document relevance, and we characterize the predictions by analyzing the topological arrangement of the embeddings in their latent space and their evolution while passing through the layers of the network. We show that there exists a link between the embedding adjustment and the predicted score, based on how tokens cluster in the embedding space. This novel approach, grounded in the query and document tokens interplay over the latent space, provides a new perspective on neural ranker explanation and a promising strategy for improving the efficiency of the models and Query Performance Prediction (QPP).	[Lucchese, Claudio; Minello, Giorgia; Orlando, Salvatore; Veneri, Alberto] Ca Foscari Univ Venice, Venice, Italy; [Nardini, Franco Maria; Perego, Raffaele; Veneri, Alberto] CNR, ISTI, Rome, Italy	Universita Ca Foscari Venezia; Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)	Lucchese, C (corresponding author), Ca Foscari Univ Venice, Venice, Italy.	claudio.lucchese@unive.it; giorgia.minello@unive.it; francomaria.nardini@isti.cnr.it; orlando@unive.it; raffaele.perego@isti.cnr.it; alberto.veneri@unive.it	Veneri, Alberto/IQT-3604-2023; Lucchese, Claudio/B-6410-2015; Perego, Raffaele/O-5821-2015	Veneri, Alberto/0000-0003-2094-3375; Lucchese, Claudio/0000-0002-2545-0425; Nardini, Franco Maria/0000-0003-3183-334X; Perego, Raffaele/0000-0001-7189-4724	SERICS project [NRRP M4C2 Inv.1.3 PE00000014]; iNEST project - EU -NGEU [NRRP M4C2 Inv.1.5 ECS00000043]; PNRR - M4C2 -Investimento 1.3, Partenariato Esteso - European Commission under the NextGeneration EU programme [PE00000013]; Horizon Europe RIA "Extreme Food Risk Analytics" (EFRA) [101093026]; Horizon Europe - Pillar II [101093026] Funding Source: Horizon Europe - Pillar II	SERICS project; iNEST project - EU -NGEU; PNRR - M4C2 -Investimento 1.3, Partenariato Esteso - European Commission under the NextGeneration EU programme; Horizon Europe RIA "Extreme Food Risk Analytics" (EFRA); Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	This work was partially supported by the SERICS project under the NRRP M4C2 Inv.1.3 PE00000014, by the iNEST project under the NRRP M4C2 Inv.1.5 ECS00000043 funded by the EU -NGEU, by the PNRR - M4C2 -Investimento 1.3, Partenariato Esteso PE00000013 "FAIR - Future Artificial Intelligence Research" - Spoke 1 "Humancentered AI" funded by the European Commission under the NextGeneration EU programme, and by the Horizon Europe RIA "Extreme Food Risk Analytics" (EFRA), grant agreement n. 101093026.	Camara Arthur, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P605, DOI 10.1007/978-3-030-45439-5_40; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Coenen A, 2019, ADV NEUR IN, V32; Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55; Fernando ZT, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1005, DOI 10.1145/3331184.3331312; Jain S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3543; Kelleher JD., 2020, FUNDAMENTALS MACHINE; Li Minghan, 2022, ARXIV220509638 CS; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; MacAvaney S, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2429, DOI 10.1145/3404835.3463254; Nguyen Tri, 2016, CEUR Workshop Proceedings, V1773; Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091; Nogueira Rodrigo, 2019, MULTISTAGE DOCUMENT, DOI [10.48550/arXiv.1910.14424, DOI 10.48550/ARXIV.1910.14424]; Qiao Yifan, 2019, ARXIV190407531 CS, DOI [10.48550/arXiv.1904.07531, DOI 10.48550/ARXIV.1904.07531]; Rennings Daniel, 2019, Advances in Information Retrieval. 41st European Conference on IR Research, ECIR 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11437), P489, DOI 10.1007/978-3-030-15712-8_32; Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2931; Singh J, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P618, DOI 10.1145/3351095.3375234; Singh J, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P770, DOI 10.1145/3289600.3290620; Vaswani A, 2017, ADV NEUR IN, V30; Verma M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1281, DOI 10.1145/3331184.3331377; Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11; Yates Andrew, 2021, Synthesis Lectures on Human Language Technologies, P1; Zhan JT, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1941, DOI 10.1145/3397271.3401325; Zhang RQ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1823, DOI 10.1145/3340531.3411999	24	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							4150	4154		10.1145/3583780.3615225	http://dx.doi.org/10.1145/3583780.3615225			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		hybrid, Green Published			2024-07-03	WOS:001161549504038
C	Venkatakrishnan, R; Goodarzi, M; Canbaz, MA			IEEE	Venkatakrishnan, Radhakrishnan; Goodarzi, Mahsa; Canbaz, M. Abdullab			Exploring Large Language Models' Emotion Detection Abilities: Use Cases From the Middle East	2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI			English	Proceedings Paper	IEEE Conference on Artificial Intelligence (IEEE CAI)	JUN 05-06, 2023	Santa Clara, CA	IEEE, IEEE Comp Soc, IEEE Signal Proc Soc, IEEE Syst, Man, & Cybernet Soc		Emotion Detection; Large Language Models; GPT; Roberta; NLP		Emotion detection is a critical component in allowing machines to understand and respond to human emotions. In this paper, we explore the potential of pre-trained transformer-based language models, namely, GPT3.5 and RoBERTa for emotion detection in natural language processing. Specifically, we focus on examining the quality of emotion detection in LLMs and their potential as automatic labeling generators to improve accuracy. The emotional response to two significant events, the murder of Zhina (Mahsa) Amini in Iran and the earthquake in Turkey and Syria, is analyzed. We observe that GPT's generative nature hinders its performance in fine-grained emotion classification, whereas RoBERTa's fine-tuning abilities and extensive pre-training specifically for emotions enable more accurate predictions within a limited set of emotional labels.	[Venkatakrishnan, Radhakrishnan; Goodarzi, Mahsa; Canbaz, M. Abdullab] SUNY Albany, Dept Informat Sci & Technol, Coll Emergency Preparedness Homeland Secur & Cybe, Albany, NY 12222 USA	State University of New York (SUNY) System; State University of New York (SUNY) Albany	Venkatakrishnan, R (corresponding author), SUNY Albany, Dept Informat Sci & Technol, Coll Emergency Preparedness Homeland Secur & Cybe, Albany, NY 12222 USA.	rvenkatakrishnan@albany.edu; mgoodarzi@albany.edu; mcanbaz@albany.edu						Acheampong F. A., 2020, RECOGNIZING EMOTIONS; Arbieu U., 2021, NATURAL LANGUAGE PRO; Ashwitha A., 2021, SARCASM DETECTION NA; Awal M. R., 2021, PAKDD 2021; Balaji M., 2019, J PHYS C SERIES; Barbieri F., 2020, Tweeteval: Unified benchmark and comparative evaluation for tweet classification; Bharti SK, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2645381; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen L., FRUGALGPT USE LARGE; Corazza M, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3377323; Devlin M.-W. L. K., 2019, BERT PRETRAINING DEE; github, SNSCRAP; Guo J, 2022, J INTELL SYST, V31, P113, DOI 10.1515/jisys-2022-0001; He X., 2023, Annollm: Making large language models to be better crowdsourced annotators; Jamal N, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3410570; Jiang HM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1775; Liu LY, 2018, AAAI CONF ARTIF INTE, P5253; Liu Y, 2019, ARXIV PREPRINT ARXIV; Perez J. M., 2021, ROBERTUITO PRETRAINE; platform, MODELS; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rahaman M., 2023, The AI Race Is on! Google's Bard and OpenAI's ChatGPT Head to Head: An Opinion Article; Silva A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2383; Wang S., WANT REDUCE LABELING; Yang Z., 2019, NIPS, V32, P1	25	1	1	5	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3984-0				2023							241	244		10.1109/CAI54212.2023.00110	http://dx.doi.org/10.1109/CAI54212.2023.00110			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5BQ					2024-07-03	WOS:001046447800100
J	Patterson, BW; Hekman, DJ; Liao, FJ; Hamedani, AG; Shah, MN; Afshar, M				Patterson, Brian W.; Hekman, Daniel J.; Liao, Frank J.; Hamedani, Azita G.; Shah, Manish N.; Afshar, Majid			Call me Dr Ishmael: trends in electronic health record notes available at emergency department visits and admissions	JAMIA OPEN			English	Article						summarization; documentation; natural language processing; emergency medicine	MEDICAL-RECORDS; EHR	Objectives Numerous studies have identified information overload as a key issue for electronic health records (EHRs). This study describes the amount of text data across all notes available to emergency physicians in the EHR, trended over the time since EHR establishment.Materials and Methods We conducted a retrospective analysis of EHR data from a large healthcare system, examining the number of notes and a corresponding number of total words and total tokens across all notes available to physicians during patient encounters in the emergency department (ED). We assessed the change in these metrics over a 17-year period between 2006 and 2023.Results The study cohort included 730 968 ED visits made by 293 559 unique patients and a total note count of 132 574 964. The median note count for all encounters in 2006 was 5 (IQR 1-16), accounting for 1735 (IQR 447-5521) words. By the last full year of the study period, 2022, the median number of notes had grown to 359 (IQR 84-943), representing 359 (IQR 84-943) words. Note and word counts were higher for admitted patients.Discussion The volume of notes available for review by providers has increased by over 30-fold in the 17 years since the implementation of the EHR at a large health system. The task of reviewing these notes has become commensurately more difficult. These data point to the critical need for new strategies and tools for filtering, synthesizing, and summarizing information to achieve the promise of the medical record. This study examines the increasing volume of electronic health record (EHR) notes that healthcare providers must review, particularly in emergency departments (EDs). Since the early 2000s, the adoption of EHRs in US hospitals has allowed for better access to patients' previously stored notes, which are reviewed by ED providers treating new patients. However, the sheer volume of information, growing with each patient visit, challenges providers to quickly and effectively digest this critical data during acute care episodes. We analyzed EHR data from 2 EDs, focusing on the number of notes, words, and text tokens available to providers per patient encounter over time. We found a significant increase in these metrics over time, complicating the "chart biopsy" process where providers skim patient histories to inform care decisions. While centralizing data storage is a key function of EHR's, their usefulness may be diminished by information overload. The growing volume of text data contained in EHRs calls for advanced solutions to manage information overload effectively, including possibly using large language models to summarize lengthy patient charts.	[Patterson, Brian W.; Hekman, Daniel J.; Liao, Frank J.; Hamedani, Azita G.; Shah, Manish N.] Univ Wisconsin Madison, Sch Med & Publ Hlth, BerbeeWalsh Dept Emergency Med, Madison, WI 53705 USA; [Patterson, Brian W.; Liao, Frank J.] UW Hlth, Dept Informat Serv, Madison, WI 53705 USA; [Patterson, Brian W.] Univ Wisconsin Madison, Dept Ind & Syst Engn, Madison, WI 53705 USA; [Shah, Manish N.; Afshar, Majid] Univ Wisconsin Madison, Dept Med, Madison, WI 53705 USA; [Shah, Manish N.] Univ Wisconsin Madison, Dept Populat Hlth Sci, Madison, WI 53705 USA; [Patterson, Brian W.] BerbeeWalsh Dept Emergency Med, 800 Univ Bay Dr,Suite 310,Mailcode 9123, Madison, WI 53705 USA	University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison; University of Wisconsin System; University of Wisconsin Madison	Patterson, BW (corresponding author), BerbeeWalsh Dept Emergency Med, 800 Univ Bay Dr,Suite 310,Mailcode 9123, Madison, WI 53705 USA.	bpatter@medicine.wisc.edu		Hekman, Daniel/0000-0002-7964-9501				Adler-Milstein J, 2017, HEALTH AFFAIR, V36, P1416, DOI 10.1377/hlthaff.2016.1651; Apathy NC, 2023, HEALTH SERV RES, V58, P674, DOI 10.1111/1475-6773.14097; Babbott S, 2014, J AM MED INFORM ASSN, V21, pE100, DOI 10.1136/amiajnl-2013-001875; Bates DW, 2014, HEALTH AFFAIR, V33, P1123, DOI 10.1377/hlthaff.2014.0041; Ben-Assuli O, 2015, J BIOMED INFORM, V55, P31, DOI 10.1016/j.jbi.2015.03.004; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Embi PJ, 2013, J AM MED INFORM ASSN, V20, P718, DOI 10.1136/amiajnl-2012-000946; Friedberg Mark W, 2014, Rand Health Q, V3, P1; Häyrinen K, 2008, INT J MED INFORM, V77, P291, DOI 10.1016/j.ijmedinf.2007.09.001; Hill RG, 2013, AM J EMERG MED, V31, P1591, DOI 10.1016/j.ajem.2013.06.028; Hilligoss B., 2010, P AM SOC INFORM SCI, V47, P1; Kroth PJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9609; Kroth PJ, 2018, JAMIA OPEN, V1, P49, DOI 10.1093/jamiaopen/ooy016; Menachemi N, 2011, RISK MANAG HEALTHC P, V4, P47, DOI 10.2147/RMHP.S12985; Python Software Foundation, Python Language Reference; R Core Team, 2024, R: A Language and Environment for Statistical Computing; Ram O, 2023, T ASSOC COMPUT LING, V11, P1316, DOI 10.1162/tacl_a_00605; Reznek MA, 2019, BMC EMERG MED, V19, DOI 10.1186/s12873-019-0285-7; Rosenbaum L, 2015, NEW ENGL J MED, V373, P1585, DOI 10.1056/NEJMp1509961; Rule A, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.15334; Semanik MG, 2021, J AM MED INFORM ASSN, V28, P899, DOI 10.1093/jamia/ocaa332; Steinkamp J, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.33348; Stewart WF, 2007, HEALTH AFFAIR, V26, pW181, DOI 10.1377/hlthaff.26.2.w181; tiktoken, 2023, How to count tokens with tiktoken; Wachter RM., 2015, The New York Times	25	1	1	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND		2574-2531		JAMIA OPEN	JAMIA Open	APR 8	2024	7	2							ooae039	10.1093/jamiaopen/ooae039	http://dx.doi.org/10.1093/jamiaopen/ooae039			7	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	RO8N0	38779571	gold			2024-07-03	WOS:001228696400001
J	Tiwari, A; Kumar, A; Jain, S; Dhull, KS; Sajjanar, A; Puthenkandathil, R; Paiwal, K; Singh, R				Tiwari, Anushree; Kumar, Amit; Jain, Shailesh; Dhull, Kanika S.; Sajjanar, Arunkumar; Puthenkandathil, Rahul; Paiwal, Kapil; Singh, Ramanpal			Implications of ChatGPT in Public Health Dentistry: A Systematic Review	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						dentist; artificial intelligence; implications; public health dentistry; chatgpt		An artificial intelligence (AI) program called ChatGPT that generates text in response to typed commands has proven to be highly popular, as evidenced by the fact that OpenAI makes it available online. The goal of the present investigation was to investigate ChatGPT's potential applications as an outstanding instance of large language models (LLMs) in the fields of public dental health schooling, writing for academic use, research in public dental health, and clinical practice in public dental health based on the available data. Importantly, the goals of the current review included locating any drawbacks and issues that might be connected to using ChatGPT in the previously mentioned contexts in healthcare settings. Using search practice in public health dentistry, education in public health dentistry, academic writing in public health dentistry, etc., a thorough search was carried out on the Pubmed database, the Embase database, the Ovid database, the Global Health database, PsycINFO, and the Web of Science. The dates of publication were not restricted. Systematic searches were carried out for all publications according to inclusion and exclusion criteria between March 31, 2018, and March 31, 2023. Eighty-four papers were obtained through a literature search using search terms. Sixteen similar and duplicate papers were excluded and 68 distinct articles were initially selected. Thirty-three articles were excluded after reviewing abstracts and titles. Thirty-five papers were selected, for which full text was managed. Four extra papers were found manually from references. Thirty-nine articles with full texts were eligible for the study. Eighteen inadequate articles are excluded from the final 21 studies that were finally selected for systemic review. According to previously published studies, ChatGPT has demonstrated its effectiveness in helping scholars with the authoring of scientific research and dental studies. If the right structures are created, ChatGPT can offer suitable responses and more time to concentrate on the phase of experimentation for scientists. Risks include prejudice in the training data, undervaluing human skills, the possibility of fraud in science, as well as legal and reproducibility concerns. It was concluded that practice considering ChatGPT's potential significance, the research's uniqueness, and the premise-the activity of the human brain-remains. While there is no question about the superiority of incorporating ChatGPT into the practice of public health dentistry, it does not, in any way, take the place of a dentist since clinical practice involves more than just making diagnoses; it also involves relating to clinical findings and providing individualized patient care. Even though AI can be useful in a number of ways, a dentist must ultimately make the decision because dentistry is a field that involves several disciplines.	[Tiwari, Anushree] Amer Acad Orthopaed Surg, Clin Qual & Value, Rosemont, IL 60018 USA; [Kumar, Amit] All India Inst Med Sci, Dept Dent, Patna, India; [Jain, Shailesh] Sharda Univ, Sch Dent Sci, Dept Prosthodont & Crown & Bridge, Greater Noida, India; [Dhull, Kanika S.] KIIT Univ, Dept Pedodont & Prevent Dent, Kalinga Inst Dent Sci, Bhubaneswar, India; [Sajjanar, Arunkumar] Swargiya Dadasaheb Kalmegh Smruti Dent Coll & Hosp, Dept Pediat & Prevent Dent, Nagpur, India; [Puthenkandathil, Rahul] Nitte Univ, AB Shetty Mem Inst Dent Sci ABSMIDS, Dept Prosthodont & Crown & Bridge, Mangalore, India; [Paiwal, Kapil] Daswani Dent Coll & Res Ctr, Dept Oral & Maxillofacial Pathol, Kota, India; [Singh, Ramanpal] New Horizon Dent Coll & Res Inst, Oral Med & Radiol, Bilaspur, India	All India Institute of Medical Sciences (AIIMS) Patna; Sharda University; Kalinga Institute of Industrial Technology (KIIT); NITTE (Deemed to be University)	Tiwari, A (corresponding author), Amer Acad Orthopaed Surg, Clin Qual & Value, Rosemont, IL 60018 USA.	tiwarianushree88@gmail.com	Paiwal, Kapil/AFV-2918-2022; makkad, Ramanpal/I-2353-2012	Paiwal, Kapil/0000-0002-6982-5612; makkad, Ramanpal/0000-0002-8433-2242; Dhull, Kanika Singh/0000-0002-0002-8084				Agrawal P, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.27405; Akhter HM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34752; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Giansanti D, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph191911907; Islam NM, 2022, J DENT EDUC, V86, P1545, DOI 10.1002/jdd.13010; Jungwirth David, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054541; Kumar AH., 2023, Biology, Engineering, Medicine and Science Reports, V9, P24, DOI DOI 10.5530/BEMS.9.1.5; Lin Z., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/SDX3J; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Manohar N, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34616; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sanmarchi F, 2023, medRxiv, DOI [10.1101/2023.02.06.23285514, 10.1101/2023.02.06.23285514, DOI 10.1101/2023.02.06.23285514]; Schwendicke F, 2023, J DENT, V128, DOI 10.1016/j.jdent.2022.104363; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tariq S, 2021, INT HEAL RESJ, V5, P1, DOI [10.26440/IHRJ/0509.12489, DOI 10.26440/IHRJ/0509.12489]; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Thurzo A, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10071269; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Zielinski Chris, 2023, Open Access Macedonian Journal of Medical Sciences, V11, P83, DOI 10.3889/oamjms.2023.11502	21	10	10	16	42	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUN 13	2023	15	6							e40367	10.7759/cureus.40367	http://dx.doi.org/10.7759/cureus.40367			9	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	M7OC7	37456464	gold, Green Published			2024-07-03	WOS:001032064700023
J	Hallsworth, JE; Udaondo, Z; Pedrós-Alió, C; Höfer, J; Benison, KC; Lloyd, KG; Cordero, RJB; de Campos, CBL; Yakimov, MM; Amils, R				Hallsworth, John E. E.; Udaondo, Zulema; Pedros-Alio, Carlos; Hofer, Juan; Benison, Kathleen C. C.; Lloyd, Karen G. G.; Cordero, Radames J. B.; de Campos, Claudia B. L.; Yakimov, Michail M. M.; Amils, Ricardo			Scientific novelty beyond the experiment	MICROBIAL BIOTECHNOLOGY			English	Article							THOUGHT EXPERIMENTS; WATER-STRESS; THERMODYNAMIC MODEL; BIOCONTROL AGENTS; FOSSIL SPECIMENS; LIFE; BIOLOGY; SYSTEM; DIVERSITY; BACTERIA	Practical experiments drive important scientific discoveries in biology, but theory-based research studies also contribute novel-sometimes paradigm-changing-findings. Here, we appraise the roles of theory-based approaches focusing on the experiment-dominated wet-biology research areas of microbial growth and survival, cell physiology, host-pathogen interactions, and competitive or symbiotic interactions. Additional examples relate to analyses of genome-sequence data, climate change and planetary health, habitability, and astrobiology. We assess the importance of thought at each step of the research process; the roles of natural philosophy, and inconsistencies in logic and language, as drivers of scientific progress; the value of thought experiments; the use and limitations of artificial intelligence technologies, including their potential for interdisciplinary and transdisciplinary research; and other instances when theory is the most-direct and most-scientifically robust route to scientific novelty including the development of techniques for practical experimentation or fieldwork. We highlight the intrinsic need for human engagement in scientific innovation, an issue pertinent to the ongoing controversy over papers authored using/authored by artificial intelligence (such as the large language model/chatbot ChatGPT). Other issues discussed are the way in which aspects of language can bias thinking towards the spatial rather than the temporal (and how this biased thinking can lead to skewed scientific terminology); receptivity to research that is non-mainstream; and the importance of theory-based science in education and epistemology. Whereas we briefly highlight classic works (those by Oakes Ames, Francis H.C. Crick and James D. Watson, Charles R. Darwin, Albert Einstein, James E. Lovelock, Lynn Margulis, Gilbert Ryle, Erwin R.J.A. Schrodinger, Alan M. Turing, and others), the focus is on microbiology studies that are more-recent, discussing these in the context of the scientific process and the types of scientific novelty that they represent. These include several studies carried out during the 2020 to 2022 lockdowns of the COVID-19 pandemic when access to research laboratories was disallowed (or limited). We interviewed the authors of some of the featured microbiology-related papers and-although we ourselves are involved in laboratory experiments and practical fieldwork-also drew from our own research experiences showing that such studies can not only produce new scientific findings but can also transcend barriers between disciplines, act counter to scientific reductionism, integrate biological data across different timescales and levels of complexity, and circumvent constraints imposed by practical techniques. In relation to urgent research needs, we believe that climate change and other global challenges may require approaches beyond the experiment.	[Hallsworth, John E. E.] Queens Univ Belfast, Inst Global Food Secur, Sch Biol Sci, Belfast, North Ireland; [Udaondo, Zulema] Univ Arkansas Med Sci, Dept Biomed Informat, Little Rock, AR USA; [Pedros-Alio, Carlos] Ctr Nacl Biotecnol CSIC, Dept Syst Biol, Madrid, Spain; [Hofer, Juan] Pontificia Univ Catolica Valparaiso, Escuela Ciencias Mar, Valparaiso, Chile; [Benison, Kathleen C. C.] West Virginia Univ, Dept Geol & Geog, Morgantown, WV USA; [Lloyd, Karen G. G.] Univ Tennessee, Microbiol Dept, Knoxville, TN USA; [Cordero, Radames J. B.] Johns Hopkins Bloomberg Sch Publ Hlth, Dept Mol Microbiol & Immunol, Baltimore, MD USA; [de Campos, Claudia B. L.] Univ Fed Sao Paulo UNIFESP, Inst Sci & Technol, Sao Jose Dos Campos, SP, Brazil; [Yakimov, Michail M. M.] Inst Polar Sci, ISP CNR, Messina, Italy; [Amils, Ricardo] Univ Autonoma Madrid UAM, Ctr Biol Mol Severo Ochoa CSIC, Dept Mol Biol, Nicolas Cabrera n 1, 19 Chlorine Gardens, Madrid BT9 5DL, Spain; [Amils, Ricardo] Ctr Astrobiol INTA CSIC, Dept Planetol & Habitabil, Torrejon De Ardoz, Spain	Queens University Belfast; University of Arkansas System; University of Arkansas Medical Sciences; Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Centro Nacional de Biotecnologia (CNB); Pontificia Universidad Catolica de Valparaiso; West Virginia University; University of Tennessee System; University of Tennessee Knoxville; Johns Hopkins University; Johns Hopkins Bloomberg School of Public Health; Universidade Federal de Sao Paulo (UNIFESP); Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienze Polari (ISP-CNR); Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Centro de Biologia Molecular Severo Ochoa (CBM); Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Centro de Astrobiologia (INTA)	Hallsworth, JE (corresponding author), Queens Univ Belfast, Inst Global Food Secur, Sch Biol Sci, 19 Chlorine Gardens, Belfast BT9 5DL, Antrim, North Ireland.	johnhallsworth@yahoo.com	Amils, Ricardo/X-2706-2019; Cordero, Radamés JB/F-6912-2011; Hallsworth, John E./K-7876-2013; Pedros-Alio, Carlos/H-1222-2011; Yakimov, Michail/H-1829-2016	Cordero, Radamés JB/0000-0002-3026-7094; Hofer, Juan/0000-0002-5887-4929; Hallsworth, John E./0000-0001-6797-9362; Pedros-Alio, Carlos/0000-0003-1009-4277; Yakimov, Michail/0000-0003-1418-363X; Lloyd, Karen/0000-0003-0914-6375; Barbosa Ladeira de Campos, Claudia/0000-0002-1836-0915				Albertsen M, 2023, NAT METHODS, V20, P30, DOI 10.1038/s41592-022-01726-6; Aldridge BB, 2006, NAT CELL BIOL, V8, P1195, DOI 10.1038/ncb1497; Alves FD, 2015, CURR GENET, V61, P457, DOI 10.1007/s00294-015-0496-8; Ames O., 1939, EC ANNUALS HUMAN CUL; Anand S., 2023, AUTOPHAGY; Anantrasirichai N, 2022, ARTIF INTELL REV, V55, P589, DOI 10.1007/s10462-021-10039-7; Andersen H, 2013, TOPOI-INT REV PHILOS, V32, P3, DOI 10.1007/s11245-012-9133-z; Anderson Edgar., 1952, PLANTS MAN AND LIFE; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 1959, The Third University of Utah research conference on the identification of scientific talent; [Anonymous], 1987, PSYCHOL 20 CENTURY T; Aouad M, 2019, NAT MICROBIOL, V4, P558, DOI 10.1038/s41564-019-0359-z; Aouad M, 2018, MOL PHYLOGENET EVOL, V127, P46, DOI 10.1016/j.ympev.2018.04.011; Arber A., 1950, The natural philosophy of plant form; Archer S., 2021, BMJ OPEN DIAB RES CA, DOI 10.21203/rs.3.rs-244923/v2; Armstrong G, 2022, FRONT BIOINFORM, V2, DOI 10.3389/fbinf.2022.821861; Bains W, 2021, ASTROBIOLOGY, V21, P1277, DOI 10.1089/ast.2020.2352; Ball P., 2013, Astrochemistry and Astrobiology, P169; Ball P., 2023, NAUTILUS MAGAZI 0117; Ball P., 2017, Nature News, DOI DOI 10.1038/NATURE.2017.21751; Ball P., 1999, H 2O BIOGRAPHY WATER; Ball P, 2008, CHEM REV, V108, P74, DOI 10.1021/cr068037a; Ball P, 2017, P NATL ACAD SCI USA, V114, P13327, DOI 10.1073/pnas.1703781114; Ball P, 2015, PHYS CHEM CHEM PHYS, V17, P8297, DOI 10.1039/c4cp04564e; Banerjee S, 2018, NAT REV MICROBIOL, V16, P567, DOI 10.1038/s41579-018-0024-1; Baraniuk C., 2017, New Scientist; Barnett A, 2020, ELIFE, V9, DOI 10.7554/eLife.60080; Bedessem B, 2021, SYNTHESE, V198, P6597, DOI 10.1007/s11229-019-02479-0; Belilla J, 2019, NAT ECOL EVOL, V3, P1552, DOI 10.1038/s41559-019-1005-0; Benison KC, 2007, J SEDIMENT RES, V77, P366, DOI 10.2110/jsr.2007.038; Benison KC, 2021, ASTROBIOLOGY, V21, P729, DOI 10.1089/ast.2020.2334; Benison KC, 1998, NATURE, V392, P911, DOI 10.1038/31917; Beveridge W.I. B., 1950, ART SCI INVESTIGATIO; Bhaganna P, 2016, CURR GENET, V62, P419, DOI 10.1007/s00294-015-0539-1; Bhaganna P, 2010, MICROB BIOTECHNOL, V3, P701, DOI 10.1111/j.1751-7915.2010.00203.x; Bimber O, 2002, COMPUTER, V35, P25, DOI 10.1109/MC.2002.1033024; BLOMBERG A, 1992, ADV MICROB PHYSIOL, V33, P145, DOI 10.1016/S0065-2911(08)60217-9; Boden MA, 1998, ARTIF INTELL, V103, P347, DOI 10.1016/S0004-3702(98)00055-1; Bosch J, 2021, ENVIRON MICROBIOL, V23, P6377, DOI 10.1111/1462-2920.15699; Brancini GTP, 2022, J PHOTOCH PHOTOBIO B, V226, DOI 10.1016/j.jphotobiol.2021.112374; Brown A.D., 1990, MICROBIAL WATER STRE, V1st; Brown CT, 2015, NATURE, V523, P208, DOI 10.1038/nature14486; Brüssow H, 2022, MICROB BIOTECHNOL, V15, P2687, DOI 10.1111/1751-7915.14141; Bury TM, 2021, P NATL ACAD SCI USA, V118, DOI [10.1073/pnas.2106140118|1of9, 10.1073/pnas.2106140118]; Cahan David., 2003, NATURAL PHILOS SCI W; Calaprice A., 2010, The ultimate quotable Einstein; Camarena-Pozos DA, 2021, ENVIRON MICROBIOL, V23, P2215, DOI 10.1111/1462-2920.15395; Camarena-Pozos DA, 2019, PLANT CELL ENVIRON, V42, P1368, DOI 10.1111/pce.13476; Camilleri K, 2014, SYNTHESE, V191, P1697, DOI 10.1007/s11229-013-0358-1; Carney D, 2020, PHYS REV D, V102, DOI 10.1103/PhysRevD.102.072003; CARSLAW KS, 1994, GEOPHYS RES LETT, V21, P2479, DOI 10.1029/94GL02799; CARSLAW KS, 1995, J PHYS CHEM-US, V99, P11557, DOI 10.1021/j100029a039; Casadevall A, 2005, FUNGAL GENET BIOL, V42, P98, DOI 10.1016/j.fgb.2004.11.008; Casadevall A, 2020, PLOS PATHOG, V16, DOI 10.1371/journal.ppat.1008451; Casadevall A, 2020, J CLIN INVEST, V130, P553, DOI 10.1172/JCI135003; Casadevall A, 2019, MBIO, V10, DOI 10.1128/mBio.01397-19; Casadevall A, 2016, PLOS PATHOG, V12, DOI 10.1371/journal.ppat.1005577; Casadevall A, 2012, PLOS PATHOG, V8, DOI 10.1371/journal.ppat.1002808; Cavicchioli R, 2019, NAT REV MICROBIOL, V17, P569, DOI 10.1038/s41579-019-0222-5; Chawla D.S., 2020, NATURE NEWS; Chon-Torres OA, 2021, INT J ASTROBIOL, V20, P186, DOI 10.1017/S147355041800023X; Chu JSG, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2021636118; Clark B.C., 1994, LPSC, VXXV, P263; Clatterbuck H, 2013, EUR J PHILOS SCI, V3, P309, DOI 10.1007/s13194-013-0069-y; Clegg SL, 1998, J PHYS CHEM A, V102, P2137, DOI 10.1021/jp973042r; Coccia M, 2022, ENVIRON RES, V208, DOI 10.1016/j.envres.2022.112711; Cockell CS, 2002, SPACE POLICY, V18, P263, DOI 10.1016/S0265-9646(02)00039-5; Coleman-Derr D, 2016, NEW PHYTOL, V209, P798, DOI 10.1111/nph.13697; Colton S, 2012, FRONT ARTIF INTEL AP, V242, P21, DOI 10.3233/978-1-61499-098-7-21; Copeland S, 2019, SYNTHESE, V196, P2385, DOI 10.1007/s11229-017-1544-3; Cray JA, 2016, MICROB BIOTECHNOL, V9, P330, DOI 10.1111/1751-7915.12349; Cray JA, 2015, CURR OPIN BIOTECH, V33, P228, DOI 10.1016/j.copbio.2015.02.010; Cray JA, 2015, BIOL CONTROL, V81, P93, DOI 10.1016/j.biocontrol.2014.11.006; Cray JA, 2013, MICROB BIOTECHNOL, V6, P453, DOI 10.1111/1751-7915.12027; Cray JA, 2013, ENVIRON MICROBIOL, V15, P287, DOI 10.1111/1462-2920.12018; Cremin CJ, 2022, CURR RES BIOTECHNOL, V4, P138, DOI 10.1016/j.crbiot.2022.02.004; Crippa M, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29804-5; CROMBIE AC, 1995, HIST SCI, V33, P225, DOI 10.1177/007327539503300204; Cross KL, 2019, NAT BIOTECHNOL, V37, P1314, DOI 10.1038/s41587-019-0260-6; CROWE JH, 1992, ANNU REV PHYSIOL, V54, P579, DOI 10.1146/annurev.ph.54.030192.003051; Cubillos CF, 2019, FRONT MICROBIOL, V10, DOI 10.3389/fmicb.2019.01611; Danchin A, 2021, SYN BIOL, V6, DOI 10.1093/synbio/ysab010; Darwin C, 2009, ON THE ORIGIN OF SPECIES, P1, DOI 10.1017/CBO9780511694295.004; Darwin C., 1839, Voyages of the Adventure and Beagle; Das P, 2021, NAT BIOMED ENG, V5, P613, DOI 10.1038/s41551-021-00689-x; dC Rubin SS, 2017, ENVIRON MICROBIOL, V19, P3745, DOI 10.1111/1462-2920.13876; de Regt HW, 2009, PHILOS SCI, V76, P585, DOI 10.1086/605795; De Regt HW, 2005, SYNTHESE, V144, P137, DOI 10.1007/s11229-005-5000-4; De Smedt K., 2022, RESPONSIBILITY SCI S, V57; Deroo W, 2022, TOXINS, V14, DOI 10.3390/toxins14030222; Deryugina T, 2021, AEA PAP P, V111, P164, DOI 10.1257/pandp.20211017; Diamond J.M., 2005, Guns, germs, and steel: the fates of human societies; Diffenbaugh NS, 2020, NAT REV EARTH ENV, V1, P470, DOI 10.1038/s43017-020-0079-1; Dill K.A., 1987, Protein Eng, V1, P187; Edmonds M, 2018, NAT GEOSCI, V11, P790, DOI 10.1038/s41561-018-0214-5; Ehrenzweig A., 1970, HIDDEN ORDER ART STU; Eilers H, 2000, APPL ENVIRON MICROB, V66, P3044, DOI 10.1128/AEM.66.7.3044-3051.2000; Einstein A, 1905, ANN PHYS-BERLIN, V18, P639; Einstein A., 1938, The Evolution of Physics: The Growth of Ideas from Early Concepts to Relativity and Quanta; Eisenberg D. S., 1969, STRUCTURE PROPERTIES; Eldredge N., 1972, P82; Elmer SJ, 2020, ADV PHYSIOL EDUC, V44, P741, DOI 10.1152/advan.00153.2020; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; ENGLERT F, 1964, PHYS REV LETT, V13, P321, DOI 10.1103/PhysRevLett.13.321; Ernakovich JG, 2022, GLOBAL CHANGE BIOL, V28, P5007, DOI 10.1111/gcb.16231; Escudero C, 2018, INT MICROBIOL, V21, P3, DOI 10.1007/s10123-018-0009-y; Espino-Vázquez AN, 2020, ISME J, V14, P1743, DOI 10.1038/s41396-020-0638-y; Extance A, 2018, NATURE, V561, P273, DOI 10.1038/d41586-018-06617-5; Feng YT, 2021, GENOME BIOL EVOL, V13, DOI 10.1093/gbe/evab166; Fernandez-Cortes A, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8003; Fleming A, 1929, BRIT J EXP PATHOL, V10, P226; Flores-N┬u┬C┬u┬ez V.M., 2022, RES SQUARE, DOI 10.21203/rs.3.rs-1782141/v1; Flores-Núñez VM, 2020, FRONT MICROBIOL, V10, DOI 10.3389/fmicb.2019.03044; Foletti A, 2019, INT J MOL SCI, V20, DOI 10.3390/ijms20163973; Fonseca-García C, 2016, FRONT MICROBIOL, V7, DOI 10.3389/fmicb.2016.00150; Foster AJ, 2017, ENVIRON MICROBIOL, V19, P1008, DOI 10.1111/1462-2920.13688; Foster JG, 2015, AM SOCIOL REV, V80, P875, DOI 10.1177/0003122415601618; Gabaldón T, 2021, ANNU REV MICROBIOL, V75, P631, DOI 10.1146/annurev-micro-090817-062213; Gao J, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26428-z; Gao Y., 2022, BIORXIV; Gao Y., 2022, SCI ADV, V8, peabn1916; Gao YN, 2022, SYST BIOL, DOI 10.1093/sysbio/syac016; Garcia D., 2017, Encyclopedia of Personality and Individual Differences, P1, DOI DOI 10.1007/978-3-319-28099-8_91-1; Garcia-Solache MA, 2010, MBIO, V1, DOI 10.1128/mBio.00061-10; Gauthier J, 2019, BRIEF BIOINFORM, V20, P1981, DOI 10.1093/bib/bby063; Gershenson A, 2020, J BIOL CHEM, V295, P15, DOI 10.1074/jbc.REV119.006794; Ghoddusi H, 2019, ENERG ECON, V81, P709, DOI 10.1016/j.eneco.2019.05.006; Giovannelli D, 2022, FRONT MICROBIOL, V13, DOI 10.3389/fmicb.2022.998133; Gittins DA, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn3485; Gleitman L., 2005, Cambridge handbook of thinking and reasoning, P633; Goldstein JL, 2022, CELL, V185, P3839, DOI 10.1016/j.cell.2022.08.027; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Graf JS, 2021, NATURE, V591, P445, DOI 10.1038/s41586-021-03297-6; Greaves JS, 2021, NAT ASTRON, V5, P655, DOI 10.1038/s41550-020-1174-4; Greener JG, 2022, NAT REV MOL CELL BIO, V23, P40, DOI 10.1038/s41580-021-00407-0; Hallsworth J.E., 2021, PAPER NATURE PORTFOL; Hallsworth JE, 1998, J FERMENT BIOENG, V85, P125, DOI 10.1016/S0922-338X(97)86756-6; Hallsworth JE, 2003, ENVIRON MICROBIOL, V5, P1270, DOI 10.1111/j.1462-2920.2003.00478.x; Hallsworth JE, 1999, BIOTECHNOL BIOENG, V62, P242, DOI 10.1002/(SICI)1097-0290(19990120)62:2<242::AID-BIT15>3.0.CO;2-R; Hallsworth JE, 2022, MICROB BIOTECHNOL, V15, P191, DOI 10.1111/1751-7915.13980; Hallsworth JE, 2021, NAT ASTRON, V5, P665, DOI 10.1038/s41550-021-01391-3; Hallsworth JE, 2021, ENVIRON MICROBIOL, V23, P3345, DOI 10.1111/1462-2920.15494; Hallsworth JE, 2019, ENVIRON MICROBIOL, V21, P2202, DOI 10.1111/1462-2920.14510; Hallsworth JE, 2018, FUNGAL BIOL-UK, V122, P379, DOI 10.1016/j.funbio.2018.04.003; HAMAGUCHI K, 1962, J AM CHEM SOC, V84, P1329, DOI 10.1021/ja00867a001; Hamill PG, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62552-4; Heinz J, 2022, ENVIRON MICROBIOL, V24, P5051, DOI 10.1111/1462-2920.16152; Heinz J, 2021, LIFE-BASEL, V11, DOI 10.3390/life11111194; Henderson L. J, 1913, FITNESS ENV; Henkin, 2020, SNYDER CHAMPNESS MOL; HIGGS PW, 1964, PHYS REV LETT, V13, P508, DOI 10.1103/PhysRevLett.13.508; Hill T.A., 1977, THE BIOL OF WEEDS; Hillebrand H, 2020, NAT ECOL EVOL, V4, P1502, DOI 10.1038/s41559-020-1256-9; Hitsuwari J., 2022, MILITARY MED RES, V139, P107502; Hodgman C.D., 1944, HDB CHEM PHYS; Hodgskiss MSW, 2019, P NATL ACAD SCI USA, V116, P17207, DOI 10.1073/pnas.1900325116; Hoehler TM, 2013, NAT REV MICROBIOL, V11, P83, DOI 10.1038/nrmicro2939; Holyoak K.J., 2005, The Cambridge handbook of thinking and reasoning; Hou JH, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2020.101012; Howe KR, 2004, QUAL INQ, V10, P42, DOI 10.1177/1077800403259491; Hug LA, 2016, NAT MICROBIOL, V1, DOI [10.1038/NMICROBIOL.2016.48, 10.1038/nmicrobiol.2016.48]; Hutson M., 2017, SCI AAAS; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Imran Ali, 2020, Inform Med Unlocked, V20, P100378, DOI 10.1016/j.imu.2020.100378; Johnston NM, 2022, FRONT ECOL EVOL, V9, DOI 10.3389/fevo.2021.624692; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Jung C.G., 1971, Psychological types: Collected works of C.G. Jung, V3rd; Kadow C, 2020, NAT GEOSCI, V13, P408, DOI 10.1038/s41561-020-0582-5; Kahlem P, 2006, MOL SYST BIOL, V2, DOI 10.1038/msb4100080; Kauffman E.G., 1990, EXTINCTION EVENTS EA; Kemp L, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2108146119; KIRTON M, 1976, J APPL PSYCHOL, V61, P622, DOI 10.1037/0021-9010.61.5.622; Klawonn I, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2102225118; Klein ┬u├., 2004, TACTIQUES CHRONOS; KLOTZ LC, 1972, J MOL BIOL, V72, P779, DOI 10.1016/0022-2836(72)90191-X; Koestler A., 1964, The Act of Creation; Korbel JO, 2020, GENOME BIOL, V21, DOI 10.1186/s13059-020-02031-1; Kusters R, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.577974; La Cono V, 2020, P NATL ACAD SCI USA, V117, P20223, DOI 10.1073/pnas.2007232117; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Landis MJ, 2013, SYST BIOL, V62, P193, DOI 10.1093/sysbio/sys086; LaPierre N, 2019, METHODS, V166, P74, DOI 10.1016/j.ymeth.2019.03.003; Larkin MJ, 1999, NATURE, V397, P467, DOI 10.1038/17191; Lauber N, 2021, BIOESSAYS, V43, DOI 10.1002/bies.202100103; Leahey E, 2007, AM SOCIOL REV, V72, P533, DOI 10.1177/000312240707200403; Lee CJD, 2018, FEMS MICROBIOL REV, V42, P672, DOI 10.1093/femsre/fuy026; Lehman J., 2016, P 7 INT C COMP CREAT, P180; Lei HJ, 2016, J BIOSCI BIOENG, V122, P583, DOI 10.1016/j.jbiosc.2016.05.004; Lennon JT, 2017, GEOBIOLOGY, V15, P254, DOI 10.1111/gbi.12214; Levinthal C., 1969, Mossbauer Spectrosc Biol Syst, V67, P22; Lewis D.I., 2020, CHOOSING RIGHT FINAL; Lievens B, 2015, ENVIRON MICROBIOL, V17, P278, DOI 10.1111/1462-2920.12570; Liu F, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac081; Lloyd KG, 2021, ENV MICROBIOL REP, V13, P18, DOI 10.1111/1758-2229.12892; Lloyd KG, 2020, APPL ENVIRON MICROB, V86, DOI 10.1128/AEM.00877-20; Lloyd KG, 2013, APPL ENVIRON MICROB, V79, P7790, DOI 10.1128/AEM.02090-13; Lovelock J.E., 1969, SCIENCE, V25, P170; LOVELOCK JE, 1974, TELLUS, V26, P2, DOI 10.1111/j.2153-3490.1974.tb01946.x; LOVELOCK JE, 1972, ATMOS ENVIRON, V6, P579, DOI 10.1016/0004-6981(72)90076-5; LOVELOCK JE, 1965, NATURE, V207, P568, DOI 10.1038/207568a0; Lünsdorf H, 2000, ENVIRON MICROBIOL, V2, P161; Luthy Christoph., 2000, PERSPECT SCI, V8, P164; MacLeod M, 2018, STUD HIST PHILOS SCI, V67, P74, DOI 10.1016/j.shpsa.2018.01.001; Madigan M.T., 2021, Brock Biology of Microorganisms; Malki M, 2008, APPL ENVIRON MICROB, V74, P4472, DOI 10.1128/AEM.00209-08; Mao S., 2007, OPTIONS CONTROL INFL, P510; MARGULIS L, 1970, P349; Margulis L, 2006, P NATL ACAD SCI USA, V103, P13080, DOI 10.1073/pnas.0604985103; Margulis Lynn, 1995, WHAT IS LIFE; Margulis Lynn., 1998, SYMBIOTIC PLANET NEW; Martin W, 1998, NATURE, V392, P37, DOI 10.1038/32096; Martínez JM, 2021, ENVIRON MICROBIOL, V23, P3987, DOI 10.1111/1462-2920.15411; Martino C, 2021, NAT BIOTECHNOL, V39, DOI 10.1038/s41587-020-0660-7; Mateos G, 2022, MICROORGANISMS, V10, DOI 10.3390/microorganisms10081585; Maurer M, 2019, J MOL RECOGNIT, V32, DOI 10.1002/jmr.2810; McCammick E.M., 2010, HDB HYDROCARBON LIPI, DOI [10.1007/978-3-540-77587-4_99, DOI 10.1007/978-3-540-77587-4_99]; McGenity TJ, 2020, MICROB BIOTECHNOL, V13, P844, DOI 10.1111/1751-7915.13576; McGhee GR, 2018, CARBONIFEROUS GIANTS AND MASS EXTINCTION, P1, DOI 10.7312/mcgh18096; McKay CP, 2004, PLOS BIOL, V2, P1260, DOI 10.1371/journal.pbio.0020302; MCKAY DIA, 2022, SCIENCE, V377, P1171, DOI [DOI 10.1126/SCIENCE.ABN7950, 10.1126/science.abn7950]; McLellan SL, 2019, CURR OPIN BIOTECH, V57, P34, DOI 10.1016/j.copbio.2018.12.010; Melo MCR, 2021, COMMUN BIOL, V4, DOI 10.1038/s42003-021-02586-0; Mestre M, 2021, TRENDS MICROBIOL, V29, P482, DOI 10.1016/j.tim.2020.10.007; Michaud L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0104505; Micheluz A, 2022, PATHOGENS, V11, DOI 10.3390/pathogens11121462; Mills RH, 2022, NAT MICROBIOL, V7, P262, DOI 10.1038/s41564-021-01050-3; Monod J., 1971, Chance and Necessity: An Essay on the Natural Philosophy of Modern Biology; Moody ERR, 2022, ELIFE, V11, DOI [10.7554/eLife.66695, 10.7554/eLife.66695.sa0, 10.7554/eLife.66695.sa1, 10.7554/eLife.66695.sa2]; Mota MN, 2021, J FUNGI, V7, DOI 10.3390/jof7020090; Müller AL, 2014, ISME J, V8, P1153, DOI 10.1038/ismej.2013.225; Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1; Murray AE, 2020, NAT MICROBIOL, V5, P987, DOI 10.1038/s41564-020-0733-x; Myers KR, 2020, NAT HUM BEHAV, V4, P880, DOI 10.1038/s41562-020-0921-y; Ng D, 2022, NAT MICROBIOL, V7, P470, DOI 10.1038/s41564-022-01084-1; Nishant R, 2020, INT J INFORM MANAGE, V53, DOI 10.1016/j.ijinfomgt.2020.102104; Nissani M., 1995, J ED THOUGHT JET REV, V29, P121, DOI [https://doi.org/10.11575/jet.v29i2.52385, DOI 10.11575/JET.V29I2]; Noel D, 2023, MICROB BIOTECHNOL, V16, P1438, DOI 10.1111/1751-7915.14242; Norton JD, 2004, PHILOS SCI, V71, P1139, DOI 10.1086/425238; Norton JohnD., 2004, Contemporary Debates in the Philosophy of Science, P44; O'Malley MA, 2019, NAT ECOL EVOL, V3, P338, DOI 10.1038/s41559-019-0796-3; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Onishi H., 1989, YEAST TECHNOLOGY, P167; Oren A, 2014, FEMS MICROBIOL LETT, V359, P134, DOI 10.1111/1574-6968.12571; Park M, 2023, NATURE, V613, P138, DOI 10.1038/s41586-022-05543-x; Parker D, 2018, BIOL PHILOS, V33, DOI 10.1007/s10539-018-9628-0; Parks DH, 2022, NUCLEIC ACIDS RES, V50, pD785, DOI 10.1093/nar/gkab776; Parks DH, 2018, NAT BIOTECHNOL, V36, P996, DOI 10.1038/nbt.4229; Parro V, 2020, ASTROBIOLOGY, V20, P1025, DOI 10.1089/ast.2020.0804; Partida-Martínez LP, 2011, FRONT PLANT SCI, V2, DOI 10.3389/fpls.2011.00100; Pasolli E, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004977; Pedrós-Alió C, 2006, TRENDS MICROBIOL, V14, P257, DOI 10.1016/j.tim.2006.04.007; Pedrós-Alió C, 2021, SYST APPL MICROBIOL, V44, DOI 10.1016/j.syapm.2021.126227; Perry J.H., 1963, CHEM ENG HDB, V4th; Picoche C, 2022, J THEOR BIOL, V538, DOI 10.1016/j.jtbi.2022.111020; Pinkerton MH, 2021, FRONT ECOL EVOL, V9, DOI 10.3389/fevo.2021.592027; Pinu FR, 2019, METABOLITES, V9, DOI 10.3390/metabo9040076; Plavén-Sigray P, 2017, ELIFE, V6, DOI 10.7554/eLife.27725; Poliseli L, 2022, BIOL PHILOS, V37, DOI 10.1007/s10539-022-09851-4; PORTER C. L., 1932, PROC INDIANA ACAD SCI, V41, P149; Prakash T, 2012, BRIEF BIOINFORM, V13, P711, DOI 10.1093/bib/bbs033; Price PB, 2009, CAN J MICROBIOL, V55, P1, DOI 10.1139/W08-117; Price PB, 2004, P NATL ACAD SCI USA, V101, P4631, DOI 10.1073/pnas.0400522101; Prosser JI, 2022, ENVIRON MICROBIOL, V24, P4973, DOI 10.1111/1462-2920.16221; Ramesh Aditya, 2022, arXiv; Reel PS, 2021, BIOTECHNOL ADV, V49, DOI 10.1016/j.biotechadv.2021.107739; Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1; Rimmer PB, 2021, PLANET SCI J, V2, DOI 10.3847/PSJ/ac0156; Robert VA, 2009, J INFECT DIS, V200, P1623, DOI 10.1086/644642; Rockström J, 2009, NATURE, V461, P472, DOI 10.1038/461472a; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Russell S., 2020, Artificial Intelligence: A Modern Approach, V2nd edn; Ryle G., 1949, The Concept of Mind; Sagan D, 2021, BIOSYSTEMS, V204, DOI 10.1016/j.biosystems.2021.104386; SAGAN L, 1967, J THEOR BIOL, V14, P225, DOI 10.1016/0022-5193(67)90079-3; Sandoval WA, 2003, J LEARN SCI, V12, P5, DOI 10.1207/S15327809JLS1201_2; Scaccia JP, 2021, IMPLEMENT SCI, V16, DOI 10.1186/s13012-021-01120-4; Scheneider S.H., 2004, SCI DEBATE GAIA NEXT; Schimmelmann A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206506; Schlaepfer G, 2018, ROUTL PHILOS COMPAN, P243; Schmidt J., 2021, J DIABETES SCI TECHN, V12, P2546; Schrdinger E., 1944; Schreder-Gomes SI, 2022, GEOLOGY, V50, P918, DOI 10.1130/G49957.1; Schrödinger E, 1935, NATURWISSENSCHAFTEN, V23, P807, DOI 10.1007/BF01491891; Schuur EAG, 2015, NATURE, V520, P171, DOI 10.1038/nature14338; Sohwabe C. W., 1964, Veterinary medicine and human health.; SCHWARTZ DC, 1984, CELL, V37, P67, DOI 10.1016/0092-8674(84)90301-5; Scopes R.K., 1989, ALCOHOL TOXICITY YEA, P89; Seager S, 2021, ASTROBIOLOGY, V21, P1206, DOI 10.1089/ast.2020.2244; Serrao-Neumann S, 2021, NAT CLIM CHANGE, V11, P1006, DOI 10.1038/s41558-021-01221-4; Shao W.D., 2020, REV ACCOUNT STUD, V125, pe2019JE006195; Simpson G. G., 1944, P1; SLOANE EH, 1945, PSYCHOL REV, V52, P214, DOI 10.1037/h0059151; Sorensen Roy., 1992, Thought Experiments; Sorokin DY, 2019, NAT MICROBIOL, V4, P560, DOI 10.1038/s41564-019-0358-0; Sorokin DY, 2017, NAT MICROBIOL, V2, DOI 10.1038/nmicrobiol.2017.81; Stevenson A, 2017, ENVIRON MICROBIOL, V19, P687, DOI 10.1111/1462-2920.13597; Stevenson A, 2015, ISME J, V9, P1333, DOI 10.1038/ismej.2014.219; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021; Taskin Z, 2015, SCIENTOMETRICS, V103, P1003, DOI 10.1007/s11192-015-1576-8; Taylor CW., 1963, SCI CREATIVITY ITS R; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Timmis K., 2023, FRONT MICROBIOL; Timmis K, 2023, ENVIRON MICROBIOL, V25, P49, DOI 10.1111/1462-2920.16272; Timmis K, 2022, MICROB BIOTECHNOL, V15, P176, DOI 10.1111/1751-7915.13976; Timmis K, 2021, MICROB BIOTECHNOL, V14, P769, DOI 10.1111/1751-7915.13771; Timmis K, 2020, MICROB BIOTECHNOL, V13, P1300, DOI 10.1111/1751-7915.13619; Timmis K, 2019, ENVIRON MICROBIOL, V21, P1513, DOI 10.1111/1462-2920.14611; Timmis K, 2017, MICROB BIOTECHNOL, V10, P984, DOI 10.1111/1751-7915.12818; Toews Rob., 2022, FORBES; Tsukuba Language Group, 1995, SIT FUNCT JAP; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Unterman A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27716-4; Uyeda JC, 2011, P NATL ACAD SCI USA, V108, P15908, DOI 10.1073/pnas.1014503108; Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5; van Uden N., 1985, Annu. Rep. Ferm. Proc, V8, P11, DOI DOI 10.1016/B978-0-12-040308-0.50006-9; van Wyhe J, 2007, NOTES REC ROY SOC, V61, P177, DOI 10.1098/rsnr.2006.0171; Verreault D, 2008, MICROBIOL MOL BIOL R, V72, P413, DOI 10.1128/MMBR.00002-08; WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0; Weart S, 2013, P NATL ACAD SCI USA, V110, P3657, DOI 10.1073/pnas.1107482109; Weber M., 2018, Stanford Encyclopedia of Philosophy; Weber M., 2004, CAMBRIDGE STUDIES PH; Weinberg S., 1977, New York Acad. Sci., V38, P185, DOI [DOI 10.1111/J.2164-0947.1977.TB02958.X, 10.1111/j.2164-0947.1977.tb02958.x]; Weiss MC, 2016, NAT MICROBIOL, V1, DOI [10.1038/NMICROBIOL.2016.116, 10.1038/nmicrobiol.2016.116]; Wessner D.R., 2020, MICROBIOLOGY; West GB, 2005, J EXP BIOL, V208, P1575, DOI 10.1242/jeb.01589; Westerhoff HV, 2011, METHOD ENZYMOL, V500, P3, DOI 10.1016/B978-0-12-385118-5.00001-3; Williams TJ, 2017, ENVIRON MICROBIOL, V19, P864, DOI 10.1111/1462-2920.13580; Wilson RE, 1921, J IND ENG CHEM-US, V13, P326, DOI 10.1021/ie50136a022; WINSTON PW, 1960, ECOLOGY, V41, P232, DOI 10.2307/1931961; Witt T, 2013, J EVOLUTION BIOL, V26, P2244, DOI 10.1111/jeb.12224; WOESE CR, 1977, P NATL ACAD SCI USA, V74, P5088, DOI 10.1073/pnas.74.11.5088; Wood TK, 2022, MICROB BIOTECHNOL, V15, P13, DOI 10.1111/1751-7915.13806; Wrighton KC, 2012, SCIENCE, V337, P1661, DOI 10.1126/science.1224041; Wu LF, 2019, NATURE, V566, P378, DOI 10.1038/s41586-019-0941-9; Xu YJ, 2021, INNOVATION-AMSTERDAM, V2, DOI 10.1016/j.xinn.2021.100179; Yakimov MM, 2022, ENVIRON MICROBIOL, V24, P30, DOI 10.1111/1462-2920.15823; Yakimov MM, 2015, ENVIRON MICROBIOL, V17, P364, DOI 10.1111/1462-2920.12587; Yang H, 1997, BIOCHEM GENET, V35, P165, DOI 10.1023/A:1021902125382; YOUNG AT, 1973, ICARUS, V18, P564, DOI 10.1016/0019-1035(73)90059-6; Zajc J, 2014, FRONT MICROBIOL, V5, DOI 10.3389/fmicb.2014.00708; Zannoni D, 2018, NATURE, V559, P32, DOI 10.1038/d41586-018-05610-2; Zengler K, 2005, METHOD ENZYMOL, V397, P124, DOI 10.1016/S0076-6879(05)97007-9; Zhang K, 2020, CELL, V181, P1423, DOI 10.1016/j.cell.2020.04.045; Zhang X, 2012, ICARUS, V217, P714, DOI 10.1016/j.icarus.2011.06.016	345	21	22	17	110	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1751-7915			MICROB BIOTECHNOL	Microb. Biotechnol.	JUN	2023	16	6					1131	1173		10.1111/1751-7915.14222	http://dx.doi.org/10.1111/1751-7915.14222		FEB 2023	43	Biotechnology & Applied Microbiology; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Microbiology	H4YJ6	36786388	gold, Green Published			2024-07-03	WOS:000933217800001
J	Juhi, A; Pipil, N; Santra, S; Mondal, S; Behera, JK; Mondal, H				Juhi, Ayesha; Pipil, Neha; Santra, Soumya; Mondal, Shaikat; Behera, Joshil Kumar; Mondal, Himel			The Capability of ChatGPT in Predicting and Explaining Common Drug-Drug Interactions	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						artificial intelligence; patient education; language model; chatgpt; adverse reactions; side effects; explaining; predicting; drug-drug interaction; drug interactions		Background Drug-drug interactions (DDIs) can have serious consequences for patient health and well-being. Patients who are taking multiple medications may be at an increased risk of experiencing adverse events or drug toxicity if they are not aware of potential interactions between their medications. Many times, patients self -prescribe medications without knowing DDI.Objective The objective is to investigate the effectiveness of ChatGPT, a large language model, in predicting and explaining common DDIs.Methods A total of 40 DDIs lists were prepared from previously published literature. This list was used to converse with ChatGPT with a two-stage question. The first question was asked as "can I take X and Y together?" with two drug names. After storing the output, the next question was asked. The second question was asked as "why should I not take X and Y together?" The output was stored for further analysis. The responses were checked by two pharmacologists and the consensus output was categorized as "correct" and "incorrect." The "correct" ones were further classified as "conclusive" and "inconclusive." The text was checked for reading ease scores and grades of education required to understand the text. Data were tested by descriptive and inferential statistics.Results Among the 40 DDI pairs, one answer was incorrect in the first question. Among correct answers, 19 were conclusive and 20 were inconclusive. For the second question, one answer was wrong. Among correct answers, 17 were conclusive and 22 were inconclusive. The mean Flesch reading ease score was 27.64 +/- 10.85 in answers to the first question and 29.35 +/- 10.16 in answers to the second question, p = 0.47. The mean Flesh-Kincaid grade level was 15.06 +/- 2.79 in answers to the first question and 14.85 +/- 1.97 in answers to the second question, p = 0.69. When we compared the reading levels with hypothetical 6th grade, the grades were significantly higher than expected (t = 20.57, p < 0.0001 for first answers and t = 28.43, p < 0.0001 for second answers).Conclusion ChatGPT is a partially effective tool for predicting and explaining DDIs. Patients, who may not have immediate access to the healthcare facility for getting information about DDIs, may take help from ChatGPT. However, on several occasions, it may provide incomplete guidance. Further improvement is required for potential usage by patients for getting ideas about DDI.	[Juhi, Ayesha; Mondal, Himel] All India Inst Med Sci, Physiol, Deoghar, India; [Pipil, Neha] All India Inst Med Sci, Pharmacol, Bilaspur, Bilaspur, India; [Santra, Soumya] Coll Med & JNM Hosp, Pharmacol, Kalyani, India; [Mondal, Shaikat] Raiganj Govt Med Coll & Hosp, Physiol, Raiganj, India; [Behera, Joshil Kumar] Dharanidhar Med Coll, Physiol, Keonjhar, Keonjhar, India		Mondal, H (corresponding author), All India Inst Med Sci, Physiol, Deoghar, India.	himelmkcg@gmail.com	JUHI, Dr AYESHA/ISU-1372-2023; Mondal, Himel/G-5111-2017	Mondal, Himel/0000-0001-6950-5857; Juhi, Ayesha/0009-0008-1340-6655				Akinleye Sheriff D, 2018, Hand (N Y), V13, P705, DOI 10.1177/1558944717726138; Das D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.36034; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Galliher JM, 2010, ANN FAM MED, V8, P151, DOI 10.1370/afm.1055; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Han K, 2022, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.814858; Kheshti R, 2016, J RES PHARM PRACT, V5, P257, DOI 10.4103/2279-042X.192461; Mondal H, 2022, INDIAN DERMATOL ONL, V13, P539, DOI 10.4103/idoj.idoj_605_21; Mousavi S, 2017, CASP J INTERN MED, V8, P282, DOI 10.22088/cjim.8.4.282; Plavén-Sigray P, 2017, ELIFE, V6, DOI 10.7554/eLife.27725; Preston CL, 2015, Stockley's Drug Interactions Pocket Companion; Qato DM, 2016, JAMA INTERN MED, V176, P473, DOI 10.1001/jamainternmed.2015.8581; Rashid M, 2020, CURR CLIN PHARMACOL, V15, P90, DOI 10.2174/1574884714666191122103953; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Selvaraj Kalaiselvi, 2014, Perspect Clin Res, V5, P32, DOI 10.4103/2229-3485.124569; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Vilar S, 2018, BRIEF BIOINFORM, V19, P863, DOI 10.1093/bib/bbx010; Xiong GL, 2022, NUCLEIC ACIDS RES, V50, pD1200, DOI 10.1093/nar/gkab880	18	37	37	5	22	CUREUS INC	PALO ALTO	PO BOX 61002, PALO ALTO, CA 94306 USA		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAR 17	2023	15	3							e36272	10.7759/cureus.36272	http://dx.doi.org/10.7759/cureus.36272			7	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	E4QE5	37073184	gold, Green Published			2024-07-03	WOS:000975396300024
J	Lum, ZC				Lum, Zachary C.			Can Artificial Intelligence Pass the American Board of Orthopaedic Surgery Examination? Orthopaedic Residents Versus ChatGPT	CLINICAL ORTHOPAEDICS AND RELATED RESEARCH			English	Article								BackgroundAdvances in neural networks, deep learning, and artificial intelligence (AI) have progressed recently. Previous deep learning AI has been structured around domain-specific areas that are trained on dataset-specific areas of interest that yield high accuracy and precision. A new AI model using large language models (LLM) and nonspecific domain areas, ChatGPT (OpenAI), has gained attention. Although AI has demonstrated proficiency in managing vast amounts of data, implementation of that knowledge remains a challenge.Questions/purposes(1) What percentage of Orthopaedic In-Training Examination questions can a generative, pretrained transformer chatbot (ChatGPT) answer correctly? (2) How does that percentage compare with results achieved by orthopaedic residents of different levels, and if scoring lower than the 10th percentile relative to 5th-year residents is likely to correspond to a failing American Board of Orthopaedic Surgery score, is this LLM likely to pass the orthopaedic surgery written boards? (3) Does increasing question taxonomy affect the LLM's ability to select the correct answer choices?MethodsThis study randomly selected 400 of 3840 publicly available questions based on the Orthopaedic In-Training Examination and compared the mean score with that of residents who took the test over a 5-year period. Questions with figures, diagrams, or charts were excluded, including five questions the LLM could not provide an answer for, resulting in 207 questions administered with raw score recorded. The LLM's answer results were compared with the Orthopaedic In-Training Examination ranking of orthopaedic surgery residents. Based on the findings of an earlier study, a pass-fail cutoff was set at the 10th percentile. Questions answered were then categorized based on the Buckwalter taxonomy of recall, which deals with increasingly complex levels of interpretation and application of knowledge; comparison was made of the LLM's performance across taxonomic levels and was analyzed using a chi-square test.ResultsChatGPT selected the correct answer 47% (97 of 207) of the time, and 53% (110 of 207) of the time it answered incorrectly. Based on prior Orthopaedic In-Training Examination testing, the LLM scored in the 40th percentile for postgraduate year (PGY) 1s, the eighth percentile for PGY2s, and the first percentile for PGY3s, PGY4s, and PGY5s; based on the latter finding (and using a predefined cutoff of the 10th percentile of PGY5s as the threshold for a passing score), it seems unlikely that the LLM would pass the written board examination. The LLM's performance decreased as question taxonomy level increased (it answered 54% [54 of 101] of Tax 1 questions correctly, 51% [18 of 35] of Tax 2 questions correctly, and 34% [24 of 71] of Tax 3 questions correctly; p = 0.034).ConclusionAlthough this general-domain LLM has a low likelihood of passing the orthopaedic surgery board examination, testing performance and knowledge are comparable to that of a first-year orthopaedic surgery resident. The LLM's ability to provide accurate answers declines with increasing question taxonomy and complexity, indicating a deficiency in implementing knowledge.	[Lum, Zachary C.] Nova Southeastern Univ, Davie, FL USA; [Lum, Zachary C.] Nova Southeastern Univ, Dept Fac & Alumni Affairs, Kiran C Patel Sch Osteopath Med, 3200 South Univ Dr, Davie, FL 33328 USA	Nova Southeastern University; Nova Southeastern University	Lum, ZC (corresponding author), Nova Southeastern Univ, Dept Fac & Alumni Affairs, Kiran C Patel Sch Osteopath Med, 3200 South Univ Dr, Davie, FL 33328 USA.	zacharylum@gmail.com		Lum, Zachary/0000-0002-5871-8539				Bharat C, 2021, LANCET DIGIT HEALTH, V3, pE397, DOI 10.1016/S2589-7500(21)00058-3; BUCKWALTER JA, 1981, J MED EDUC, V56, P115; Cohen M, 2023, EUR RADIOL, V33, P3974, DOI 10.1007/s00330-022-09349-3; Finlayson SG, 2021, NEW ENGL J MED, V385, P283, DOI 10.1056/NEJMc2104626; Fritz E, 2021, J AM ACAD ORTHOP SUR, V29, pE1370, DOI 10.5435/JAAOS-D-20-01019; Guerrero DT, 2023, AM SURGEON, V89, P49, DOI 10.1177/00031348221101503; Karnuta JM, 2023, J ARTHROPLASTY, V38, P1998, DOI 10.1016/j.arth.2022.03.002; Kirchner GJ, 2023, CLIN ORTHOP RELAT R, V481, P2260, DOI 10.1097/CORR.0000000000002668; Kung T. H, 2023, PLOS Digit Health, V2; Liu PR, 2021, CURR MED SCI, V41, P1158, DOI 10.1007/s11596-021-2501-4; Luo Q, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1778562; Ramkumar PN, 2021, ARTHROSCOPY, V37, P1694, DOI 10.1016/j.arthro.2020.08.009; Swanson David, 2013, J Bone Joint Surg Am, V95, pe84, DOI 10.2106/JBJS.L.00457; Vaswani A., 2017, Attention is all you need; Vedula SS, 2022, J AM COLL SURGEONS, V234, P1181, DOI 10.1097/XCS.0000000000000190	15	25	25	10	23	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0009-921X	1528-1132		CLIN ORTHOP RELAT R	Clin. Orthop. Rel. Res.	AUG	2023	481	8					1623	1630		10.1097/CORR.0000000000002704	http://dx.doi.org/10.1097/CORR.0000000000002704			8	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	N0LG4	37220190				2024-07-03	WOS:001034028800031
J	Lin, SL; Ma, YY; Jiang, YW; Li, WW; Peng, YJ; Yu, T; Xu, Y; Zhu, JF; Lu, LA; Zou, HD				Lin, Senlin; Ma, Yingyan; Jiang, Yanwei; Li, Wenwen; Peng, Yajun; Yu, Tao; Xu, Yi; Zhu, Jianfeng; Lu, Lina; Zou, Haidong			Service Quality and Residents' Preferences for Facilitated Self-Ser vice Fundus Disease Screening: Cross-Sectional Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						digital technology; screening; self-service; eye disease; health economics evaluation; health technology assessment; disease screening; artificial intelligence; AI; eye; community; effectiveness; screening efficiency; safety	ARTIFICIAL-INTELLIGENCE; TRUST	Background: Fundus photography is the most important examination in eye disease screening. A facilitated self-service eye screening pattern based on the fully automatic fundus camera was developed in 2022 in Shanghai, China; it may help solve the problem of insufficient human resources in primary health care institutions. However, the service quality and residents' preference for this new pattern are unclear. Objective: This study aimed to compare the service quality and residents' preferences between facilitated self-service eye screening and traditional manual screening and to explore the relationships between the screening service's quality and residents' preferences. Methods: We conducted a cross-sectional study in Shanghai, China. Residents who underwent facilitated self-service fundus disease screening at one of the screening sites were assigned to the exposure group; those who were screened with a traditional fundus camera operated by an optometrist at an adjacent site comprised the control group. The primary outcome was the screening service quality, including effectiveness (image quality and screening efficiency), physiological discomfort, safety, convenience, and trustworthiness. The secondary outcome was the participants' preferences. Differences in service quality and the participants' preferences between the 2 groups were compared using chi-square tests separately. Subgroup analyses for exploring the relationships between the screening service's quality and residents' preference were conducted using generalized logit models. Results: A total of 358 residents enrolled; among them, 176 (49.16%) were included in the exposure group and the remaining 182 (50.84%) in the control group. Residents' basic characteristics were balanced between the 2 groups. There was no significant difference in service quality between the 2 groups (image quality pass rate: P =.79; average screening time: P =.57; no physiological discomfort rate: P =.92; safety rate: P =.78; convenience rate: P =.95; trustworthiness rate: P =.20). However, the proportion of participants who were willing to use the same technology for their next screening was significantly lower in the exposure group than in the control group ( P <.001). Subgroup analyses suggest that distrust in the facilitated self-service eye screening might increase the probability of refusal to undergo screening ( P =.02). Conclusions: This study confirms that the facilitated self-service fundus disease screening pattern could achieve good service quality. However, it was difficult to reverse residents' preferences for manual screening in a short period, especially when the original manual service was already excellent. Therefore, the digital transformation of health care must be cautious. We suggest that attention be paid to the residents' individual needs. More efficient man-machine collaboration and personalized health management solutions based on large language models are both needed.	[Lin, Senlin; Ma, Yingyan; Peng, Yajun; Yu, Tao; Xu, Yi; Zhu, Jianfeng; Lu, Lina; Zou, Haidong] Tongji Univ, Shanghai Eye Hosp, Shanghai Eye Dis Prevent & Treatment Ctr, Sch Med, 1440 Hongqqiao Rd, Shanghai 200336, Peoples R China; [Lin, Senlin; Ma, Yingyan; Peng, Yajun; Yu, Tao; Xu, Yi; Zhu, Jianfeng; Lu, Lina; Zou, Haidong] Natl Clin Res Ctr Eye Dis, Shanghai, Peoples R China; [Lin, Senlin; Ma, Yingyan; Peng, Yajun; Yu, Tao; Xu, Yi; Zhu, Jianfeng; Lu, Lina; Zou, Haidong] Shanghai Engn Res Ctr Precise Diag & Treatment Eye, Shanghai, Peoples R China; [Ma, Yingyan; Zou, Haidong] Shanghai Jiao Tong Univ, Shanghai Gen Hosp, Sch Med, Shanghai, Peoples R China; [Jiang, Yanwei] Shanghai Hongkou Ctr Dis Control & Prevent, Shanghai, Peoples R China; [Li, Wenwen] Fudan Univ, Sch Management, Shanghai, Peoples R China	Tongji University; Shanghai Jiao Tong University; Shanghai Center for Disease Control & Prevention; Fudan University	Zou, HD (corresponding author), Tongji Univ, Shanghai Eye Hosp, Shanghai Eye Dis Prevent & Treatment Ctr, Sch Med, 1440 Hongqqiao Rd, Shanghai 200336, Peoples R China.	zouhaidong@sjtu.edu.cn		Li, Wenwen/0000-0002-7510-2234; Lin, Senlin/0000-0002-0166-1308; Ma, Yingyan/0000-0003-4250-0356; Peng, Yajun/0000-0003-0967-6667	Shanghai First People's Hospital featured research projects [2022HP61, 2022YQ051, 20234Y0062]; Medical Research Program of Hongkou District Health Commission [CCTR-2022C08];  [Hongwei2202-07]	Shanghai First People's Hospital featured research projects; Medical Research Program of Hongkou District Health Commission; 	This study was funded by the Shanghai Public Health Three -Year Action Plan (GWVI-11.1-30, GWVI-11.1-22) , Science and Technology Commission of Shanghai Municipality (20DZ1100200 and 23ZR1481000) , Shanghai Municipal Health Commission (2022HP61, 2022YQ051, and 20234Y0062) , Shanghai First People's Hospital featured research projects (CCTR-2022C08) and Medical Research Program of Hongkou District Health Commission (Hongwei2202-07) .r (2022HP61, 2022YQ051, and 20234Y0062) , Shanghai First People's Hospital featured research projects (CCTR-2022C08) and Medical Research Program of Hongkou District Health Commission (Hongwei2202-07) .	Alami Hassane, 2017, Mhealth, V3, P31, DOI 10.21037/mhealth.2017.07.02; Cen LP, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25138-w; Chai YX, 2023, BRIT J OPHTHALMOL, V107, P361, DOI 10.1136/bjophthalmol-2021-319655; Cheng CY, 2020, BRIT J OPHTHALMOL, V104, P616, DOI 10.1136/bjophthalmol-2018-313308; DeCamp M, 2019, LANCET DIGIT HEALTH, V1, pE390, DOI 10.1016/S2589-7500(19)30197-9; Dietvorst BJ, 2020, PSYCHOL SCI, V31, P1302, DOI 10.1177/0956797620948841; Frank DA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259928; Huang AS, 2024, JAMA OPHTHALMOL, V142, P371, DOI 10.1001/jamaophthalmol.2023.6917; insight-centre, The Assessment List for Trustworthy Artificial Intelligence; Jan C, 2019, BRIT J OPHTHALMOL, V103, P1666, DOI 10.1136/bjophthalmol-2018-313294; Juravle G, 2020, PROG BRAIN RES, V253, P263, DOI 10.1016/bs.pbr.2020.06.006; Khan WU, 2022, J MED INTERNET RES, V24, DOI 10.2196/32714; Li JPO, 2021, PROG RETIN EYE RES, V82, DOI 10.1016/j.preteyeres.2020.100900; Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2; Longoni C, 2019, J CONSUM RES, V46, P629, DOI 10.1093/jcr/ucz013; Marques AP, 2021, ECLINICALMEDICINE, V35, DOI 10.1016/j.eclinm.2021.100852; Nayeni M, 2021, CAN J OPHTHALMOL, V56, P151, DOI 10.1016/j.jcjo.2020.10.014; Ploug T, 2021, J MED INTERNET RES, V23, DOI 10.2196/26611; Ricciardi W, 2019, EUR J PUBLIC HEALTH, V29, P7, DOI 10.1093/eurpub/ckz165; Scanlon PH, 2005, DIABETES CARE, V28, P2448, DOI 10.2337/diacare.28.10.2448; Steinmetz JD, 2021, LANCET GLOB HEALTH, V9, pE144, DOI [10.1016/S2214-109X(20)30489-7, 10.1016/S2214-109X(20)30425-3]; Tang JJ, 2019, LANCET GLOB HEALTH, V7, pE968, DOI 10.1016/S2214-109X(19)30201-3; Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173; Wang LH, 2021, EYE, V35, P2173, DOI 10.1038/s41433-020-01226-x; who, Generating Evidence for Artificial Intelligence Based Medical Devices: A Framework for Training Validation and Evaluation; Xiao X, 2021, BMC PUBLIC HEALTH, V21, DOI 10.1186/s12889-021-11097-w; Xie YC, 2020, LANCET DIGIT HEALTH, V2, pE240, DOI 10.1016/S2589-7500(20)30060-1; Young AT, 2021, LANCET DIGIT HEALTH, V3, pE599, DOI 10.1016/S2589-7500(21)00132-1	28	0	0	1	1	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	APR 17	2024	26								e45545	10.2024/1/e45545	http://dx.doi.org/10.2024/1/e45545			13	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	QV3Z3	38630535				2024-07-03	WOS:001223618300005
J	Gassenhuber, M; Lochschmidt, ME; Hammel, J; Boeckh-Behrens, T; Ikenberg, B; Wunderlich, S; Liesche-Starnecker, F; Schlegel, J; Pfeiffer, F; Makowski, MR; Zimmer, C; Riederer, I; Pfeiffer, D				Gassenhuber, Melina; Lochschmidt, Maximilian E.; Hammel, Johannes; Boeckh-Behrens, Tobias; Ikenberg, Benno; Wunderlich, Silke; Liesche-Starnecker, Friederike; Schlegel, Juergen; Pfeiffer, Franz; Makowski, Marcus R.; Zimmer, Claus; Riederer, Isabelle; Pfeiffer, Daniela			Multimaterial decomposition in dual-energy CT for characterization of clots from acute ischemic stroke patients	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Blood coagulation; Ischemic stroke; Thrombectomy; Thrombosis; Tomography (x-ray computed)	ENDOVASCULAR TREATMENT; THROMBUS HISTOLOGY; ATTENUATION; ETIOLOGY; IMPACT	Background Nowadays, there is no method to quantitatively characterize the material composition of acute ischemic stroke thrombi prior to intervention, but dual-energy CT (DE-CT) offers imaging-based multimaterial decomposition. We retrospectively investigated the material composition of thrombi ex vivo using DE-CT with histological analysis as a reference. Methods Clots of 70 patients with acute ischemic stroke were extracted by mechanical thrombectomy and scanned ex vivo in formalin-filled tubes with DE-CT. Multimaterial decomposition in the three components, i.e., red blood cells (RBC), white blood cells (WBC), and fibrin/platelets (F/P), was performed and compared to histology (hematoxylin/eosin staining) as reference. Attenuation and effective Z values were assessed, and histological composition was compared to stroke etiology according to the Trial of ORG 10172 in Acute Stroke Treatment (TOAST) criteria. Results Histological and imaging analysis showed the following correlation coefficients for RBC (r = 0.527, p < 0.001), WBC (r = 0.305, p = 0.020), and F/P (r = 0.525, p < 0.001). RBC-rich thrombi presented higher clot attenuation in Hounsfield units than F/P-rich thrombi (51 HU versus 42 HU, p < 0.01). In histological analysis, cardioembolic clots showed less RBC (40% versus 56%, p = 0.053) and more F/P (53% versus 36%, p = 0.024), similar to cryptogenic clots containing less RBC (34% versus 56%, p = 0.006) and more F/P (58% versus 36%, p = 0.003) than non-cardioembolic strokes. No difference was assessed for the mean WBC portions in all TOAST groups. Conclusions DE-CT has the potential to quantitatively characterize the material composition of ischemic stroke thrombi.	[Gassenhuber, Melina; Hammel, Johannes; Pfeiffer, Franz; Makowski, Marcus R.; Pfeiffer, Daniela] Tech Univ Munich, Sch Med, Dept Diagnost & Intervent Radiol, Klinikum Rechts Isar, D-81675 Munich, Germany; [Lochschmidt, Maximilian E.; Hammel, Johannes; Pfeiffer, Franz] Tech Univ Munich, Chair Biomed Phys, Sch Nat Sci, Dept Phys, D-85748 Garching, Germany; [Hammel, Johannes; Pfeiffer, Franz] Tech Univ Munich, Munich Inst Biomed Engn, D-85748 Garching, Germany; [Boeckh-Behrens, Tobias; Zimmer, Claus; Riederer, Isabelle] Tech Univ Munich, Sch Med, Dept Diagnost & Intervent Neuroradiol, Klinikum Rechts Isar, D-81675 Munich, Germany; [Ikenberg, Benno; Wunderlich, Silke] Tech Univ Munich, Sch Med, Dept Neurol, Klinikum Rechts Isar, D-81675 Munich, Germany; [Liesche-Starnecker, Friederike] Univ Augsburg, Med Fac, Pathol, D-86150 Augsburg, Germany; [Schlegel, Juergen] Tech Univ Munich, Sch Med, Dept Neuropathol, Klinikum Rechts Isar, D-81675 Munich, Germany; [Pfeiffer, Franz; Pfeiffer, Daniela] Tech Univ Munich, Inst Adv Study, D-85748 Garching, Germany	Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; Technical University of Munich; University of Augsburg; Technical University of Munich; Technical University of Munich	Pfeiffer, D (corresponding author), Tech Univ Munich, Sch Med, Dept Diagnost & Intervent Radiol, Klinikum Rechts Isar, D-81675 Munich, Germany.; Pfeiffer, D (corresponding author), Tech Univ Munich, Inst Adv Study, D-85748 Garching, Germany.	daniela.pfeiffer@tum.de			Deutsche Forschungsgemeinschaft	Deutsche Forschungsgemeinschaft(German Research Foundation (DFG))	Large language models were not used for this manuscript.	ADAMS HP, 1993, STROKE, V24, P35, DOI 10.1161/01.STR.24.1.35; Berndt M, 2018, STROKE, V49, P2674, DOI 10.1161/STROKEAHA.118.021873; Boeckh-Behrens T, 2016, CLIN NEURORADIOL, V26, P189, DOI 10.1007/s00062-014-0347-x; Boeckh-Behrens T, 2016, STROKE, V47, P1864, DOI 10.1161/STROKEAHA.116.013105; Borggrefe J, 2018, CLIN NEURORADIOL, V28, P515, DOI 10.1007/s00062-017-0599-3; Brinjikji W, 2021, J NEUROINTERV SURG, V13, P594, DOI 10.1136/neurintsurg-2020-017167; Brinjikji W, 2017, J NEUROINTERV SURG, V9, P529, DOI 10.1136/neurintsurg-2016-012391; De Meyer SF, 2017, INT J STROKE, V12, P606, DOI 10.1177/1747493017709671; Douglas A, 2020, HISTOL HISTOPATHOL, V35, P313, DOI 10.14670/HH-18-154; Duffy S, 2019, STROKE, V50, P1156, DOI 10.1161/STROKEAHA.118.023419; Fitzgerald S, 2019, STROKE, V50, P1907, DOI 10.1161/STROKEAHA.118.024543; Froehler MT, 2013, J NEUROINTERV SURG, V5, P289, DOI 10.1136/neurintsurg-2012-010313; Hashimoto T, 2016, STROKE, V47, P3035, DOI 10.1161/STROKEAHA.116.015228; Heo JH, 2020, J STROKE, V22, P64, DOI 10.5853/jos.2019.03440; Hsieh SS, 2018, MED PHYS, V45, P1433, DOI 10.1002/mp.12799; Hubbell J.H., 1995, NISTIR, V5632, DOI DOI 10.6028/NIST.IR.5632; Kaesmacher J, 2017, AM J NEURORADIOL, V38, P991, DOI 10.3174/ajnr.A5105; Kim SK, 2015, AM J NEURORADIOL, V36, P1756, DOI 10.3174/ajnr.A4402; Liebeskind DS, 2011, STROKE, V42, P1237, DOI 10.1161/STROKEAHA.110.605576; Lochschmidt ME, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21193-5; Luthman AS, 2020, CLIN NEURORADIOL, V30, P27, DOI 10.1007/s00062-019-00841-w; Mangesius S, 2021, EUR RADIOL, V31, P4138, DOI 10.1007/s00330-020-07543-9; Mehta BP, 2012, NEUROLOGY, V79, pS63, DOI 10.1212/WNL.0b013e3182695859; Mendonça PRS, 2014, IEEE T MED IMAGING, V33, P99, DOI 10.1109/TMI.2013.2281719; Moftakhar P, 2013, STROKE, V44, P243, DOI 10.1161/STROKEAHA.112.674127; Moseley HGJ, 1914, PHILOS MAG, V27, P703, DOI 10.1080/14786440408635141; Niesten JM, 2013, NEURORADIOLOGY, V55, P1071, DOI 10.1007/s00234-013-1217-y; Niesten JM, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0088882; Nouh A, 2020, BMC NEUROL, V20, DOI 10.1186/s12883-020-01969-w; Patino M, 2016, RADIOGRAPHICS, V36, P1087, DOI 10.1148/rg.2016150220; Rennert RC, 2019, NEUROSURGERY, V85, pS4, DOI 10.1093/neuros/nyz042; Riederer I, 2021, CLIN IMAG, V79, P158, DOI 10.1016/j.clinimag.2021.04.020; Riederer I, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-27437-7; Schlomka JP, 2008, PHYS MED BIOL, V53, P4031, DOI 10.1088/0031-9155/53/15/002; Sporns PB, 2017, CEREBROVASC DIS, V44, P344, DOI 10.1159/000481578; Sporns PB, 2017, STROKE, V48, P2206, DOI 10.1161/STROKEAHA.117.016590; Stritt M., 2016, Orbit Image Analysis Handbook; Tiedt S, 2020, STROKE, V51, P1014, DOI 10.1161/STROKEAHA.119.028383; Wolman DN, 2018, J COMPUT ASSIST TOMO, V42, P831, DOI 10.1097/RCT.0000000000000779; Yuki I, 2012, AM J NEURORADIOL, V33, P643, DOI 10.3174/ajnr.A2842	40	0	0	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	APR 5	2024	8	1							52	10.1186/s41747-024-00443-3	http://dx.doi.org/10.1186/s41747-024-00443-3			13	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	MZ4Z9	38575701				2024-07-03	WOS:001197457600001
J	Rillig, MC; Agerstrand, M; Bi, MH; Gould, KA; Sauerland, U				Rillig, Matthias C.; agerstrand, Marlene; Bi, Mohan; Gould, Kenneth A.; Sauerland, Uli			Risks and Benefits of Large Language Models for the Environment	ENVIRONMENTAL SCIENCE & TECHNOLOGY			English	Editorial Material; Early Access						large language models; ChatGPT; environmental education; environmental impact; digital divide; environmental literacy; artificial intelligence			[Rillig, Matthias C.; Bi, Mohan] Free Univ Berlin, Inst Biol, D-14195 Berlin, Germany; [Rillig, Matthias C.; Bi, Mohan] Berlin Brandenburg Inst Adv Biodivers Res BBIB, D-14195 Berlin, Germany; [agerstrand, Marlene] Stockholm Univ, Dept Environm Sci, SE-10691 Stockholm, Sweden; [Gould, Kenneth A.] City Univ New York, Brooklyn Coll, Dept Sociol, Brooklyn, NY 11210 USA; [Sauerland, Uli] Leibniz Ctr Gen Linguist ZAS, D-10117 Berlin, Germany	Free University of Berlin; Stockholm University; City University of New York (CUNY) System; Brooklyn College (CUNY); Leibniz Zentrum Allgemeine Sprachwissenschaft (ZAS)	Rillig, MC (corresponding author), Free Univ Berlin, Inst Biol, D-14195 Berlin, Germany.; Rillig, MC (corresponding author), Berlin Brandenburg Inst Adv Biodivers Res BBIB, D-14195 Berlin, Germany.	matthias.rillig@fu-berlin.de	Rillig, Matthias C./AAE-6980-2019	Rillig, Matthias C./0000-0003-3541-7853; Sauerland, Uli/0000-0003-2175-535X				Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT, Optimizing Language models for dialogue; Rillig MC, 2022, ENVIRON SCI TECHNOL, V56, P4721, DOI 10.1021/acs.est.2c01562; Soga M, 2016, FRONT ECOL ENVIRON, V14, P94, DOI 10.1002/fee.1225; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645	6	29	29	59	59	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	0013-936X	1520-5851		ENVIRON SCI TECHNOL	Environ. Sci. Technol.	2023 FEB 23	2023										10.1021/acs.est.3c01106	http://dx.doi.org/10.1021/acs.est.3c01106		FEB 2023	3	Engineering, Environmental; Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Environmental Sciences & Ecology	9F2HU	36821477				2024-07-03	WOS:000937295100001
J	Bui, MQ; Do, DT; Le, NK; Nguyen, DH; Nguyen, KVH; Anh, TPN; Nguyen, ML				Bui, Minh-Quan; Do, Dinh-Truong; Le, Nguyen-Khang; Nguyen, Dieu-Hien; Nguyen, Khac-Vu-Hiep; Anh, Trang Pham Ngoc; Nguyen, Minh Le			Data Augmentation and Large Language Model for Legal Case Retrieval and Entailment	REVIEW OF SOCIONETWORK STRATEGIES			English	Article						Deep learning; Legal; Large language model; Contrastive learning; Data augmentation		The Competition on Legal Information Extraction and Entailment (COLIEE) is a well-known international competition organized each year with the goal of applying machine learning algorithms and techniques in the analysis and understanding of legal documents. Two main applications of using machine learning in this domain are entailment and information retrieval. In the realm of legal text analysis, the scarcity of annotated data poses a significant challenge for training robust models. To address this limitation, we employ data augmentation methods to artificially expand the training dataset, enhancing the model's ability to generalize across diverse legal contexts. Additionally, our approach harnesses the power of a state-of-the-art language model, enabling the extraction of nuanced legal information and improving entailment predictions. We evaluate the performance of our methodology on datasets from the competition, showcasing its effectiveness in achieving competitive results.	[Bui, Minh-Quan; Do, Dinh-Truong; Le, Nguyen-Khang; Nguyen, Dieu-Hien; Nguyen, Khac-Vu-Hiep; Anh, Trang Pham Ngoc; Nguyen, Minh Le] JAIST Hokuriku Sentan Kagaku Gijutsu Daigakuin Dai, Nomi 9231292, Japan		Bui, MQ (corresponding author), JAIST Hokuriku Sentan Kagaku Gijutsu Daigakuin Dai, Nomi 9231292, Japan.	quanbui@jaist.ac.jp; truongdo@jaist.ac.jp; lnkhang@jaist.ac.jp; ndhien@jaist.ac.jp; hiepnkv@jaist.ac.jp; trangpna@jaist.ac.jp; nguyenml@jaist.ac.jp						Arslan Y, 2021, WEB CONFERENCE 2021: COMPANION OF THE WORLD WIDE WEB CONFERENCE (WWW 2021), P260, DOI 10.1145/3442442.3451375; Bach SH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P93; Beltagy I., 2020, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bui Q.M., 2022, NEW FRONTIERS ARTIFI, P68; Chalkidis I, 2020, ARXIV; Chekalina V., 2021, WORKING NOTES CLEF; Chung H., 2022, arXiv; Conneau A., 2019, ARXIV; Devlin J., 2018, BERT PRE TRAINING DE; He Pengcheng, 2020, arXiv; Kojima T., 2022, ARXIV; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Muennighoff N., 2022, Crosslingual generalization through multitask finetuning; Nguyen HT, 2022, REV SOCIONETWORK STR, V16, P135, DOI 10.1007/s12626-022-00102-2; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Ouyang L., 2022, Advances in Neural Information Processing Systems; Rabelo Juliano, 2023, New Frontiers in Artificial Intelligence: JSAI-isAI 2022 Workshop, JURISIN 2022, and JSAI 2022 International Session, Revised Selected Papers. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13859), P84, DOI 10.1007/978-3-031-29168-5_6; Rabelo J, 2021, LECT NOTES COMPUT SC, V12758, P240, DOI 10.1007/978-3-030-79942-7_16; Raffel C, 2020, J MACH LEARN RES, V21; Reimers N., 2019, arXiv; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Sanh Victor, 2022, INT C LEARNING REPRE; Santhanam K, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3715; Scao T. L., 2022, ARXIV; Sun XT, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3075583; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tay Yi, 2022, arXiv; Vassileios Balntas D. P., 2016, P BRIT MACH VIS C BM, DOI [DOI 10.5244/C.30.119, 10.5244/C.30.119]; Wei Jason, 2022, Finetuned language models are zero-shot learners; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Yoshioka Masaharu, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P278, DOI 10.1145/3462757.3466105	33	0	0	3	3	SPRINGER JAPAN KK	TOKYO	SHIROYAMA TRUST TOWER 5F, 4-3-1 TORANOMON, MINATO-KU, TOKYO, 105-6005, JAPAN	2523-3173	1867-3236		REV SOCIONETWORK STR	Rev. Socionetwork Strateg.	APR	2024	18	1			SI		49	74		10.1007/s12626-024-00158-2	http://dx.doi.org/10.1007/s12626-024-00158-2		MAR 2024	26	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	OA5N1					2024-07-03	WOS:001191042200001
J	Kanjilal, S				Kanjilal, Sanjat			Flying Into the Future With Large Language Models	CLINICAL INFECTIOUS DISEASES			English	Editorial Material						artificial intelligence; machine learning; large language models; federal regulation; clinical practice			[Kanjilal, Sanjat] Harvard Med Sch, Dept Populat Med, Boston, MA USA; [Kanjilal, Sanjat] Harvard Pilgrim Healthcare Inst, Boston, MA USA; [Kanjilal, Sanjat] Brigham & Womens Hosp, Div Infect Dis, Boston, MA USA; [Kanjilal, Sanjat] Harvard Med Sch, 401 Pk Dr East, Boston, MA 02115 USA	Harvard University; Harvard Medical School; Harvard Pilgrim Health Care; Harvard University; Brigham & Women's Hospital; Harvard University; Harvard Medical School	Kanjilal, S (corresponding author), Harvard Med Sch, 401 Pk Dr East, Boston, MA 02115 USA.	skanjilal@bwh.harvard.edu			AHRQ [K08 HS027841-03]	AHRQ(United States Department of Health & Human ServicesAgency for Healthcare Research & Quality)	S. K. is funded by AHRQ K08 HS027841-03. S. K. also reports payment or honoraria for speaking or educational events from Northeast Association of Clinical Microbiology and Infectious Disease, International Roche Infectious Diseases Symposium, COVID-19 Vaccine Development and Implementation Workshop for Virology Education, and Kaohsiung Medical University.	Agrawal M., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2205.12689; Bommasani R., 2022, OPPORTUNITIES RISKS, DOI DOI 10.48550/ARXIV.2108.07258; Chesdachai S, 2020, OPEN FORUM INFECT DI, V7, DOI 10.1093/ofid/ofaa010; FDA, 2023, ARTIF INTELL; Gaffney A, 2022, JAMA INTERN MED, V182, P564, DOI 10.1001/jamainternmed.2022.0372; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; MedScape, 2023, PHYS BURNOUT DEPRESS; Mollick E., 2023, CHATGPT IS TIPPING P; Mozannar H., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.01862; National Academy of Medicine, 2023, HEALTHC ART INT COD; Nori P, 2019, OPEN FORUM INFECT DI, V6, DOI 10.1093/ofid/ofz092; Pliakos EE, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.34186; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Schwartz IS, 2024, CLIN INFECT DIS, V78, P860, DOI 10.1093/cid/ciad633; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Trotsyuk AA, 2023, SCI TRANSL MED, V15, DOI 10.1126/scitranslmed.adi0336; U.S. Food and Drug Administration, 2021, Artificial intelligence/machine learning (AI/ML)-Based software as a medical device (SaMD) action plan; US Department of Health and Human Services, 2022, ARTIF INTELL; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vodrahalli K., 2022, ADV NEURAL INFORM PR, V35, P4004; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	23	0	0	40	53	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1058-4838	1537-6591		CLIN INFECT DIS	Clin. Infect. Dis.	APR 10	2024	78	4					867	869		10.1093/cid/ciad635	http://dx.doi.org/10.1093/cid/ciad635		NOV 2023	3	Immunology; Infectious Diseases; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Immunology; Infectious Diseases; Microbiology	NQ7T4	37963099				2024-07-03	WOS:001104478800001
J	Besler, MS				Besler, Muhammed Said			Letter: Large Language Models' Performance on the European Board of Cardiovascular Radiology Diploma Sample Test	ANGIOLOGY			English	Letter; Early Access						large language model; artificial intelligence; cardiac imaging			[Besler, Muhammed Said] Kahramanmaras Necip Fazil City Hosp, Dept Radiol, Kahramanmaras, Turkiye; [Besler, Muhammed Said] Kahramanmaras Necip Fazil Sehir Hastanesi, TR-46050 Kahramanmaras, Turkiye	Kahramanmaras Necip Fazil City Hospital; Kahramanmaras Necip Fazil City Hospital	Besler, MS (corresponding author), Kahramanmaras Necip Fazil Sehir Hastanesi, TR-46050 Kahramanmaras, Turkiye.	msbesler@gmail.com						Dimitriadis F, 2024, ANGIOLOGY, DOI 10.1177/00033197241238403; Sengupta PP, 2023, JACC-CARDIOVASC IMAG, V16, P1129, DOI 10.1016/j.jcmg.2023.07.001; Sood A, 2024, INT J COMPUT ASS RAD, V19, P645, DOI 10.1007/s11548-024-03071-9	3	0	0	0	0	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0003-3197	1940-1574		ANGIOLOGY	Angiology	2024 JUN 13	2024										10.1177/00033197241262496	http://dx.doi.org/10.1177/00033197241262496		JUN 2024	1	Peripheral Vascular Disease	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	UJ2W8	38869050	hybrid			2024-07-03	WOS:001247635300001
J	Sallam, M; Salim, NA; Barakat, M; Al-Mahzoum, K; Al-Tammemi, AB; Malaeb, D; Hallit, R; Hallit, S				Sallam, Malik; Salim, Nesreen A.; Barakat, Muna; Al-Mahzoum, Kholoud; Al-Tammemi, Ala'a B.; Malaeb, Diana; Hallit, Rabih; Hallit, Souheil			Assessing Health Students' Attitudes and Usage of ChatGPT in Jordan: Validation Study	JMIR MEDICAL EDUCATION			English	Article						artificial intelligence; machine learning; education; technology; healthcare; survey; opinion; knowledge; practices; KAP	TECHNOLOGY ACCEPTANCE MODEL; MEDICAL-EDUCATION; PERCEIVED USEFULNESS; USER ACCEPTANCE; UNITED-STATES; HISTORY; EASE; TAM	Background: ChatGPT is a conversational large language model that has the potential to revolutionize knowledge acquisition. However, the impact of this technology on the quality of education is still unknown considering the risks and concerns surrounding ChatGPT use. Therefore, it is necessary to assess the usability and acceptability of this promising tool. As an innovative technology, the intention to use ChatGPT can be studied in the context of the technology acceptance model (TAM).Objective: This study aimed to develop and validate a TAM-based survey instrument called TAME-ChatGPT (Technology Acceptance Model Edited to Assess ChatGPT Adoption) that could be employed to examine the successful integration and use of ChatGPT in health care education.Methods: The survey tool was created based on the TAM framework. It comprised 13 items for participants who heard of ChatGPT but did not use it and 23 items for participants who used ChatGPT. Using a convenient sampling approach, the survey link was circulated electronically among university students between February and March 2023. Exploratory factor analysis (EFA) was used to assess the construct validity of the survey instrument.Results: The final sample comprised 458 respondents, the majority among them undergraduate students (n=442, 96.5%). Only 109 (23.8%) respondents had heard of ChatGPT prior to participation and only 55 (11.3%) self-reported ChatGPT use before the study. EFA analysis on the attitude and usage scales showed significant Bartlett tests of sphericity scores (P<.001) and adequate Kaiser-Meyer-Olkin measures (0.823 for the attitude scale and 0.702 for the usage scale), confirming the factorability of the correlation matrices. The EFA showed that 3 constructs explained a cumulative total of 69.3% variance in the attitude scale, and these subscales represented perceived risks, attitude to technology/social influence, and anxiety. For the ChatGPT usage scale,EFA showed that 4 constructs explained a cumulative total of 72% variance in the data and comprised the perceived usefulness, perceived risks, perceived ease of use, and behavior/cognitive factors. All the ChatGPT attitude and usage subscales showed good reliability with Cronbach alpha values >.78 for all the deduced subscales.Conclusions: The TAME-ChatGPT demonstrated good reliability, validity, and usefulness in assessing health care students' attitudes toward ChatGPT. The findings highlighted the importance of considering risk perceptions, usefulness, ease of use, attitudes toward technology, and behavioral factors when adopting ChatGPT as a tool in health care education. This information can aid the stakeholders in creating strategies to support the optimal and ethical use of ChatGPT and to identify the potential challenges hindering its successful implementation. Future research is recommended to guide the effective adoption of ChatGPT in health care education.	[Sallam, Malik; Al-Mahzoum, Kholoud; Hallit, Rabih; Hallit, Souheil] Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Amman, Jordan; [Sallam, Malik; Hallit, Souheil] Jordan Univ Hosp, Dept Clin Labs & Forens Med, Amman, Jordan; [Salim, Nesreen A.] Univ Jordan, Sch Dent, Prosthodont Dept, Amman, Jordan; [Salim, Nesreen A.] Jordan Univ Hosp, Prosthodont Dept, Amman, Jordan; [Barakat, Muna] Appl Sci Private Univ, Fac Pharm, Dept Clin Pharm & Therapeut, Amman, Jordan; [Barakat, Muna] Middle East Univ, MEU Res Unit, Amman, Jordan; [Al-Tammemi, Ala'a B.] Int Org Migrat, Migrat Hlth Div, United Nations Migrat Agcy, Amman, Jordan; [Malaeb, Diana] Gulf Med Univ, Coll Pharm, Ajman, U Arab Emirates; [Hallit, Rabih; Hallit, Souheil] Holy Spirit Univ Kaslik, Sch Med & Med Sci, Jounieh, Lebanon; [Hallit, Rabih] Bellevue Med Ctr, Dept Infect Dis, Mansourieh, Lebanon; [Hallit, Rabih] Univ Hosp Ctr, Dept Infect Dis, Notre Dame Secours, Byblos, Lebanon; [Hallit, Souheil] Psychiat Hosp Cross, Res Dept, Jal Eddib, Lebanon; [Sallam, Malik] Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Queen Rania Al Abdullah St Aljubeiha, Amman 11942, Jordan	University of Jordan; University of Jordan; University of Jordan; University of Jordan; Middle East University; International Organization for Migration; University of Jordan	Sallam, M (corresponding author), Univ Jordan, Sch Med, Dept Pathol Microbiol & Forens Med, Queen Rania Al Abdullah St Aljubeiha, Amman 11942, Jordan.	malik.sallam@ju.edu.jo	Malaeb, Diana/JZT-1919-2024; Al-Tammemi, MD, MPH, Ala'a B./AAB-4737-2021; Hallit, Souheil/R-6727-2018; Sallam, Malik/O-5021-2014; Barakat, Muna/AAN-8778-2020	Al-Tammemi, MD, MPH, Ala'a B./0000-0003-0862-0186; Hallit, Souheil/0000-0001-6918-5689; Sallam, Malik/0000-0002-0165-9670; Barakat, Muna/0000-0002-7966-1172; Salim, Nesreen/0000-0002-5355-2269				Abdullah F, 2016, COMPUT HUM BEHAV, V63, P75, DOI 10.1016/j.chb.2016.05.014; Aczel B., 2023, PREPRINT, DOI DOI 10.31234/OSF.IO/B58EX; Akour I, 2021, JMIR MED EDUC, V7, DOI 10.2196/24032; Alfadda HA, 2021, J PSYCHOLINGUIST RES, V50, P883, DOI 10.1007/s10936-020-09752-1; AlHogail A, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6030064; Ammenwerth Elske, 2019, Stud Health Technol Inform, V263, P64, DOI 10.3233/SHTI190111; An MH, 2021, JMIR MED INF, V9, DOI 10.2196/25435; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, BBC NEWS; Antaki F, 2023, medRxiv, DOI [10.1101/2023.01.22.23284882, 10.1101/2023.01.22.23284882, DOI 10.1101/2023.01.22.23284882]; Arnone JM, 2015, INT J NURS KNOWL, V26, P156, DOI 10.1111/2047-3095.12059; Artino AR, 2014, MED TEACH, V36, P463, DOI 10.3109/0142159X.2014.889814; Balaskas S, 2022, ADM SCI, V12, DOI 10.3390/admsci12040129; Baumgartner C, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1206; Beaudry A, 2010, MIS QUART, V34, P689; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Bernhardt JM, 2001, HEALTH EDUC RES, V16, P643, DOI 10.1093/her/16.6.643; Bezrukova K, 2023, GROUP ORGAN MANAGE, V48, P629, DOI 10.1177/10596011231160574; Boateng GO, 2018, FRONT PUBLIC HEALTH, V6, DOI 10.3389/fpubh.2018.00149; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Borji A., 2023, PREPRINT; Boulos MNK, 2007, HEALTH INFO LIBR J, V24, P2, DOI 10.1111/j.1471-1842.2007.00701.x; Braddock CH, 2004, J GEN INTERN MED, V19, P610, DOI 10.1111/j.1525-1497.2004.45003.x; Chang IC, 2022, INT J MED INFORM, V165, DOI 10.1016/j.ijmedinf.2022.104827; Chew HSJ, 2022, J MED INTERNET RES, V24, DOI 10.2196/32939; Choi Bernard C K, 2005, Prev Chronic Dis, V2, pA13; Custers EJFM, 2018, ACAD MED, V93, pS49, DOI 10.1097/ACM.0000000000002079; DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008; de Divitiis E, 2004, NEUROSURGERY, V55, P722, DOI 10.1227/01.NEU.0000139458.36781.31; Dornan T, 2005, J ROY SOC MED, V98, P91, DOI 10.1258/jrsm.98.3.91; Duong D., 2023, PREPRINT, DOI DOI 10.1101/2023.01.27.23285115; Eysenbach G, 2004, J MED INTERNET RES, V6, P12, DOI 10.2196/jmir.6.3.e34; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Featherman M., 2003, 36th Annual Hawaii International Conference on System Sciences, P11, DOI DOI 10.1109/HICSS.2003.1174433; Gates B, The Age of AI has begun: artificial intelligence is as revolutionary as mobile phones and the internet; Giannos Panagiotis, 2023, JMIR Med Educ, V9, pe47737, DOI 10.2196/47737; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hildebrandt S, 2010, ANAT SCI EDUC, V3, P202, DOI 10.1002/ase.166; Hogg HDJ, 2023, J MED INTERNET RES, V25, DOI 10.2196/39742; Holtz B, 2022, JMIR FORM RES, V6, DOI 10.2196/35130; Hu B, 2023, COMPUT HUM BEHAV, V145, DOI 10.1016/j.chb.2023.107760; Jacob C, 2020, JMIR MHEALTH UHEALTH, V8, DOI [10.2196/18072, 10.2196/15935]; Jeong D, 2023, J DEV ECON, V161, DOI 10.1016/j.jdeveco.2022.102992; Karabacak M, 2023, JMIR MED EDUC, V9, DOI 10.2196/48163; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lai PC, 2017, JISTEM J.Inf.Syst. Technol. Manag., V14, P21; Lange Ann-Kathrin, 2020, JMIR Nurs, V3, pe20249, DOI 10.2196/20249; Lee DY, 2013, COMPUT EDUC, V61, P193, DOI 10.1016/j.compedu.2012.10.001; Lee J, 2021, ACAD MED, V96, pS62, DOI 10.1097/ACM.0000000000004291; Li JN, 2023, medRxiv, DOI [10.1101/2023.03.30.23287899, 10.1101/2023.03.30.23287899, DOI 10.1101/2023.03.30.23287899]; Liu Zhen-ya, 2008, Proceedings of the CSEE, V28, P1; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; MacCallum RC, 1999, PSYCHOL METHODS, V4, P84, DOI 10.1037/1082-989x.4.1.84; Marangunic N, 2015, UNIVERSAL ACCESS INF, V14, P81, DOI 10.1007/s10209-014-0348-1; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Nadal C, 2020, J MED INTERNET RES, V22, DOI 10.2196/17256; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Okonkwo C.W., 2021, Computers and Education: Artificial Intelligence, V2, P100033, DOI [DOI 10.1016/J.CAEAI.2021.100033, 10.1016/J.CAEAI.2021.100033]; OpenAI, OPENAI MOD GPT 3; Paul J, 2023, INT J CONSUM STUD, V47, P1213, DOI 10.1111/ijcs.12928; Rahimi B, 2018, APPL CLIN INFORM, V9, P604, DOI 10.1055/s-0038-1668091; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886, DOI 10.1101/2023.02.21.23285886, 10.1101/2023.02.21.23285886v1, DOI 10.1101/2023.02.21.23285886V1]; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Roberts R, 2021, TECHNOVATION, V102, DOI 10.1016/j.technovation.2020.102219; Rogers E. M., 1995, Diffusion of Innovation: A Cross-Cultural Approach; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Sahin F, 2022, EDUC INF TECHNOL, V27, P7827, DOI 10.1007/s10639-022-10930-y; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Sallam Malik, 2023, Narra J, V3, pe103, DOI 10.52225/narra.v3i1.103; Sallam M, 2023, medRxiv, DOI [10.1101/2023.02.19.23286155, 10.1101/2023.02.19.23286155, DOI 10.1101/2023.02.19.23286155]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sanmarchi F, 2023, medRxiv, DOI [10.1101/2023.02.06.23285514, 10.1101/2023.02.06.23285514, DOI 10.1101/2023.02.06.23285514]; Sapci AH, 2020, JMIR MED EDUC, V6, DOI 10.2196/19285; Savas-Hall S, 2022, SERV MARK Q, V43, P485, DOI 10.1080/15332969.2021.1994193; Scherer R, 2019, COMPUT EDUC, V128, P13, DOI 10.1016/j.compedu.2018.09.009; Sebastian G, 2023, J MED INTERNET RES, V25, DOI 10.2196/41430; Shahsavar Y, 2023, JMIR, DOI [10.2196/preprints.47564, DOI 10.2196/PREPRINTS.47564]; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Shorey S, 2019, J MED INTERNET RES, V21, DOI 10.2196/14658; Songkram N, 2023, EDUC INF TECHNOL, DOI 10.1007/s10639-023-11637-4; Stewart KA, 2002, INFORM SYST RES, V13, P36, DOI 10.1287/isre.13.1.36.97; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Streiner DL, 2014, J ADV NURS, V70, P1970, DOI 10.1111/jan.12402; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Takagi S, 2023, JMIR MED EDUC, V9, DOI 10.2196/48002; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Tverskoi D, 2022, ROY SOC OPEN SCI, V9, DOI 10.1098/rsos.211833; Venkatesh V, 2012, MIS QUART, V36, P157; Weidener Lukas, 2023, JMIR Med Educ, V9, pe46428, DOI 10.2196/46428; Williams DJ, 2007, THEOR ISS ERGON SCI, V8, P1, DOI 10.1080/14639220500484419; Zhang A, 2022, NAT BIOMED ENG, V6, P1330, DOI 10.1038/s41551-022-00898-y; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	97	18	18	70	122	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e48254	10.2196/48254	http://dx.doi.org/10.2196/48254			15	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	U6US9	37578934	Green Published, gold			2024-07-03	WOS:001086142700001
C	Li, MH; Wang, RH; Zhou, X; Zhu, ZM; Wen, YG; Tan, R			ACM	Li, Minghao; Wang, Ruihang; Zhou, Xin; Zhu, Zhaomeng; Wen, Yonggang; Tan, Rui			ChatTwin: Toward Automated Digital Twin Generation for Data Center via Large Language Models	PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON SYSTEMS FOR ENERGY-EFFICIENT BUILDINGS, CITIES, AND TRANSPORTATION, BUILDSYS 2023			English	Proceedings Paper	10th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation (BuildSys)	NOV 15-16, 2023	Istanbul, TURKEY	Assoc Comp Machinery, ACM Special Interest Grp Energy Syst & Informat		Large Language Model; Automated Digital Twin; Data Center		Digital twin has been applied in various industrial fields to represent physical systems. However, the design of high-fidelity digital scenes is challenging in that it often requires intensive manual processes and domain expertise to edit the 3D models or description documents. To reduce human efforts, this paper proposes Chat-Twin, a conversational system that leverages the power of GPT-4 to automate the generation of scene description documents for digital twins. ChatTwin assists scene generation by i) segmenting userinput prompts, ii) generating scenes with segmented prompts, and iii) optimizing the generated content. Specifically, the Segment-and-Generate (SG) workflow decomposes the long-text generation into several subtasks and reduces the complexity of the original task. The evaluation through our data center digital twin system shows that ChatTwin outperforms other baselines in terms of generation accuracy and efficiency.	[Li, Minghao; Wang, Ruihang; Zhu, Zhaomeng; Wen, Yonggang; Tan, Rui] Nanyang Technol Univ, Singapore, Singapore; [Zhou, Xin] Jiangxi Sci & Technol Normal Univ, Nanchang, Jiangxi, Peoples R China	Nanyang Technological University; Jiangxi Science & Technology Normal University	Li, MH (corresponding author), Nanyang Technol Univ, Singapore, Singapore.	minghao002@e.ntu.edu.sg; ruihang001@e.ntu.edu.sg; 1020161201@jxstnu.edu.cn; zhaomeng.zhu@ntu.edu.sg; ygwen@ntu.edu.sg; tanrui@ntu.edu.sg	Zhou, Xin/KJL-7156-2024; Wen, Yonggang/P-9406-2017; Wang, Ruihang/AGY-3283-2022; Wang, Ruihang/JKH-9797-2023	Zhou, Xin/0000-0001-5405-9890; Wen, Yonggang/0000-0002-2751-5114; Wang, Ruihang/0000-0001-8827-9373; Wang, Ruihang/0000-0001-8827-9373				Chen JL, 2011, IEEE T SYST MAN CY C, V41, P544, DOI 10.1109/TSMCC.2010.2066560; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Cohen-Bar D, 2023, Arxiv, DOI arXiv:2303.13450; El Saddik A, 2018, IEEE MULTIMEDIA, V25, P87, DOI 10.1109/MMUL.2018.023121167; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Gao GY, 2022, IEEE INTERNET THINGS, V9, P5200, DOI 10.1109/JIOT.2021.3109057; Gao Luyu, 2023, P MACHINE LEARNING R, P10764; Höllein L, 2023, Arxiv, DOI arXiv:2303.11989; Kritzinger W, 2018, IFAC PAPERSONLINE, V51, P1016, DOI 10.1016/j.ifacol.2018.08.474; Microsoft, 2023, Azure Digital Twins-Conceptual Overview and Models; NVIDIA, 2023, NVIDIA Omniverse; OpenAI, 2023, GPT-4 Research; OpenAI, 2023, tiktoken: a fast BPE tokeniser for use with OpenAI's models; Ruihang Wang, 2020, BuildSys '20: Proceedings of the 7th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation, P200, DOI 10.1145/3408308.3427982; Wan JX, 2018, IEEE ACCESS, V6, P48867, DOI 10.1109/ACCESS.2018.2866840; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	16	2	2	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0230-3				2023							208	211		10.1145/3600100.3623719	http://dx.doi.org/10.1145/3600100.3623719			4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Construction & Building Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Construction & Building Technology	BW4HB		hybrid			2024-07-03	WOS:001147988300022
J	Ray, PP				Ray, Partha Pratim			A critical examination and suggestions for large language models for structured reporting in radiology	RADIOLOGIA MEDICA			English	Letter						Large language model; ChatGPT; Generative AI; Structured reporting; Radiology			[Ray, Partha Pratim] Sikkim Univ, Gangtok, India	Sikkim University	Ray, PP (corresponding author), Sikkim Univ, Gangtok, India.	ppray@cus.ac.in	Ray, Partha Pratim/HRC-0757-2023	Ray, Partha Pratim/0000-0003-2306-2792				Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; MALLIO CA, 2023, RADIOL MED, P1; Ray PP., 2023, CAN ASSOC RADIOL J, V12; Sendur HN, 2023, BRIT J RADIOL, V96, DOI 10.1259/bjr.20230203; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163	5	0	0	5	24	SPRINGER-VERLAG ITALIA SRL	MILAN	VIA DECEMBRIO, 28, MILAN, 20137, ITALY	0033-8362	1826-6983		RADIOL MED	Radiol. Med.	NOV	2023	128	11					1441	1442		10.1007/s11547-023-01688-5	http://dx.doi.org/10.1007/s11547-023-01688-5		JUL 2023	2	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	W2GY8	37505381				2024-07-03	WOS:001040507400001
J	Orwig, W; Edenbaum, ER; Greene, JD; Schacter, DL				Orwig, William; Edenbaum, Emma R.; Greene, Joshua D.; Schacter, Daniel L.			The Language of Creativity: Evidence from Humans and Large Language Models	JOURNAL OF CREATIVE BEHAVIOR			English	Article						artificial intelligence; creativity; large language models; semantic distance	EPISODIC MEMORY; THINKING	Recent developments in computerized scoring via semantic distance have provided automated assessments of verbal creativity. Here, we extend past work, applying computational linguistic approaches to characterize salient features of creative text. We hypothesize that, in addition to semantic diversity, the degree to which a story includes perceptual details, thus transporting the reader to another time and place, would be predictive of creativity. Additionally, we explore the use of generative language models to supplement human data collection and examine the extent to which machine-generated stories can mimic human creativity. We collect 600 short stories from human participants and GPT-3, subsequently randomized and assessed on their creative quality. Results indicate that the presence of perceptual details, in conjunction with semantic diversity, is highly predictive of creativity. These results were replicated in an independent sample of stories (n = 120) generated by GPT-4. We do not observe a significant difference between human and AI-generated stories in terms of creativity ratings, and we also observe positive correlations between human and AI assessments of creativity. Implications and future directions are discussed.	[Orwig, William; Edenbaum, Emma R.; Greene, Joshua D.; Schacter, Daniel L.] Harvard Univ, Cambridge, MA USA; [Orwig, William] Harvard Univ, Dept Psychol, 880 William James Hall, 33 Kirkland St, Cambridge, MA 02138 USA	Harvard University; Harvard University	Orwig, W (corresponding author), Harvard Univ, Dept Psychol, 880 William James Hall, 33 Kirkland St, Cambridge, MA 02138 USA.	williamorwig@g.harvard.edu	hu, guangchen/KEI-6324-2024	Orwig, William/0000-0002-9913-6391	National Institute on Aging	National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	No Statement Available	Abraham A, 2014, FRONT HUM NEUROSCI, V8, DOI 10.3389/fnhum.2014.00095; Acar S, 2023, PSYCHOL AESTHET CREA, V17, P705, DOI 10.1037/aca0000469; Acar S, 2015, PSYCHOL AESTHET CREA, V9, P41, DOI 10.1037/a0038501; AMABILE TM, 1982, J PERS SOC PSYCHOL, V43, P997, DOI 10.1037/0022-3514.43.5.997; Barbot B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02529; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Beaty RE, 2020, NEUROIMAGE, V209, DOI 10.1016/j.neuroimage.2019.116499; Bellaiche L, 2023, COGN RES, V8, DOI 10.1186/s41235-023-00499-6; Benedek M, 2023, NAT REV PSYCHOL, V2, P246, DOI 10.1038/s44159-023-00158-z; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brunel L, 2009, J EXP PSYCHOL LEARN, V35, P1081, DOI 10.1037/a0015537; Conway MA, 2001, PHILOS T R SOC B, V356, P1375, DOI 10.1098/rstb.2001.0940; Dumas D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0240728; Forthmann B, 2019, J CREATIVE BEHAV, V53, P559, DOI 10.1002/jocb.240; Guilford J. P., 1967, The nature of human intelligence; Haase J., 2023, ARTIFICIAL MUSES GEN; Hitsuwari J, 2023, COMPUT HUM BEHAV, V139, DOI 10.1016/j.chb.2022.107502; Jauk E, 2014, EUR J PERSONALITY, V28, P95, DOI 10.1002/per.1941; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; Kenett Y.N., 2018, EXPLORING TRANSDISCI, P49, DOI DOI 10.1007/978-3-319-76054-4_3; Kenett YN, 2019, TRENDS COGN SCI, V23, P271, DOI 10.1016/j.tics.2019.01.007; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Liao Yi, 2019, Gpt-based generation for classical chinese poetry; Luchini S., 2023, AUTOMATIC SCORING CR, DOI [10.31234/osf.io/g5qvf, DOI 10.31234/OSF.IO/G5QVF]; Madore KP, 2019, CEREB CORTEX, V29, P150, DOI 10.1093/cercor/bhx312; Madore KP, 2016, MEM COGNITION, V44, P974, DOI 10.3758/s13421-016-0605-z; Madore KP, 2015, PSYCHOL SCI, V26, P1461, DOI 10.1177/0956797615591863; MEDNICK SA, 1962, PSYCHOL REV, V69, P220, DOI 10.1037/h0048850; Organisciak P, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101356; Orwig W, 2021, J COGNITIVE NEUROSCI, V33, P499, DOI 10.1162/jocn_a_01658; Pennebaker J.W., 2022, DEV PSYCHOMETRIC PRO, DOI [10.1037/gdn0000195, DOI 10.1037/GDN0000195]; Pennebaker J. W., 2001, Linguistic Inquiry and Word Count: LIWC 2001, DOI DOI 10.4018/978-1-60960-741-8.CH012; Piantadosi S., 2023, Lingbuzz lingbuzz/007180; Prabhakaran R, 2014, BEHAV RES METHODS, V46, P641, DOI 10.3758/s13428-013-0401-7; Reiter-Palmon R, 2019, PSYCHOL AESTHET CREA, V13, P144, DOI 10.1037/aca0000227; Saive AL, 2014, FRONT BEHAV NEUROSCI, V8, DOI 10.3389/fnbeh.2014.00240; Schacter DL, 2016, MEM STUD, V9, P245, DOI 10.1177/1750698016645230; Sheldon S, 2019, MEMORY, V27, P881, DOI 10.1080/09658211.2019.1586952; St-Laurent M, 2016, CORTEX, V84, P15, DOI 10.1016/j.cortex.2016.08.010; St-Laurent M, 2014, HIPPOCAMPUS, V24, P560, DOI 10.1002/hipo.22249; Stevenson C., 2022, Putting GPT-3's creativity to the (Alternative Uses) Test; Suzgun Mirac, 2022, Challenging big-bench tasks and whether chain-of-thought can solve them; Taecharungroj V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010035; Thakral PP, 2020, P NATL ACAD SCI USA, V117, P12729, DOI 10.1073/pnas.2003535117; van Genugten RDI, 2022, CREATIVITY RES J, V34, P145, DOI 10.1080/10400419.2021.1976451; Wheeler ME, 2000, P NATL ACAD SCI USA, V97, P11125, DOI 10.1073/pnas.97.20.11125	46	2	2	25	25	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0022-0175	2162-6057		J CREATIVE BEHAV	J. Creat. Behav.	MAR	2024	58	1					128	136		10.1002/jocb.636	http://dx.doi.org/10.1002/jocb.636		JAN 2024	9	Psychology, Educational	Social Science Citation Index (SSCI)	Psychology	MS2H7	38698795	Green Accepted			2024-07-03	WOS:001142138400001
J	McCrary, MR; Galambus, J; Chen, WS				McCrary, Myles R.; Galambus, Justine; Chen, Wei-Shen			Evaluating the diagnostic performance of a large language model-powered chatbot for providing immunohistochemistry recommendations in dermatopathology	JOURNAL OF CUTANEOUS PATHOLOGY			English	Article; Early Access						artificial intelligence; immunohistochemistry; large language model		BackgroundLarge language model (LLM)-powered chatbots such as ChatGPT have numerous applications. However, their effectiveness in dermatopathology has not been formally evaluated. Dermatopathological cases often require immunohistochemical workup. Here, we evaluate the performance of a chatbot in providing diagnostically useful information on immunohistochemistry relating to dermatological diseases.MethodsWe queried a commonly used chatbot for the immunophenotypes of 51 cutaneous diseases, including a diverse variety of epidermal, adnexal, hematolymphoid, and soft tissue entities. We requested it to provide references for each diagnosis. All tests were repeated, compiled, quantified, and then compared with established literature standards.ResultsClustering analysis demonstrated that recommendations correlated with tumor type, suggesting chatbots can supply appropriate panels. However, a significant portion of recommendations were factually incorrect (13.9%). Citations were rarely clinically useful (24.5%). Many were confabulated (27.2%). Prompt responses for cutaneous adnexal lesions tended to be less accurate while literature references were less useful. Reference retrieval performance was associated with the number of PubMed entries per entity.ConclusionsThis foundational study suggests that LLM-powered chatbots may be useful for generating immunohistochemical panels for dermatologic diagnoses. However, specific performance capabilities and biases must be considered. In addition, extreme caution is advised regarding the tendencies to fabricate material. Future models intentionally fine-tuned to augment diagnostic medicine may prove to be valuable.	[McCrary, Myles R.; Chen, Wei-Shen] Univ S Florida, Morsani Coll Med, Dept Anat & Clin Pathol, Tampa, FL 33620 USA; [McCrary, Myles R.; Galambus, Justine; Chen, Wei-Shen] Univ S Florida, Morsani Coll Med, Dept Dermatol & Cutaneous Surg, Tampa, FL USA; [Galambus, Justine] Univ Texas Med Branch, Dept Internal Med, Galveston, TX USA	State University System of Florida; University of South Florida; State University System of Florida; University of South Florida; University of Texas System; University of Texas Medical Branch Galveston	Chen, WS (corresponding author), Univ S Florida, Morsani Coll Med, Dept Anat & Clin Pathol, Tampa, FL 33620 USA.	weishenchen@usf.edu		McCrary, Myles/0000-0002-4572-7372; Galambus, Justine/0000-0002-2425-0851				Agarwal A, 2024, J AM ACAD DERMATOL, V90, P1121, DOI 10.1016/j.jaad.2023.04.030; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], ExpertPath; [Anonymous], Pathology Outlines; [Anonymous], ImmunoQuery; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Dave P, 2023, J AM ACAD DERMATOL, V88, P1401, DOI 10.1016/j.jaad.2022.01.014; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Ferreira AL, 2023, J AM ACAD DERMATOL, V89, pE157, DOI 10.1016/j.jaad.2023.05.054; Fuertes L, 2016, AM J DERMATOPATH, V38, P92, DOI 10.1097/DAD.0000000000000361; Jartarkar SR, 2023, J COSMET DERMATOL-US, V22, P1163, DOI 10.1111/jocd.15565; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kluger N, 2023, J EUR ACAD DERMATOL, V37, pE941, DOI 10.1111/jdv.19152; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Naert KA, 2013, AM J DERMATOPATH, V35, P74, DOI 10.1097/DAD.0b013e31825d4f73; OpenAI, WHAT IS CHATGPT; Passby L, 2023, CLIN EXP DERMATOL, V49, P722, DOI 10.1093/ced/llad197; Porter E, 2023, J EUR ACAD DERMATOL, V37, pE943, DOI 10.1111/jdv.19174; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887	19	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0303-6987	1600-0560		J CUTAN PATHOL	J. Cutan. Pathol.	2024 MAY 14	2024										10.1111/cup.14631	http://dx.doi.org/10.1111/cup.14631		MAY 2024	7	Dermatology; Pathology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology; Pathology	QP0Y1	38744501				2024-07-03	WOS:001221968800001
J	Zaretsky, J; Kim, JM; Baskharoun, S; Zhao, YN; Austrian, J; Aphinyanaphongs, Y; Gupta, R; Blecker, SB; Feldman, J				Zaretsky, Jonah; Kim, Jeong Min; Baskharoun, Samuel; Zhao, Yunan; Austrian, Jonathan; Aphinyanaphongs, Yindalon; Gupta, Ravi; Blecker, Saul B.; Feldman, Jonah			Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format	JAMA NETWORK OPEN			English	Article							READABILITY; UNDERSTANDABILITY; INFORMATION; ACTIVATION	Importance By law, patients have immediate access to discharge notes in their medical records. Technical language and abbreviations make notes difficult to read and understand for a typical patient. Large language models (LLMs [eg, GPT-4]) have the potential to transform these notes into patient-friendly language and format. Objective To determine whether an LLM can transform discharge summaries into a format that is more readable and understandable. Design, Setting, and Participants This cross-sectional study evaluated a sample of the discharge summaries of adult patients discharged from the General Internal Medicine service at NYU (New York University) Langone Health from June 1 to 30, 2023. Patients discharged as deceased were excluded. All discharge summaries were processed by the LLM between July 26 and August 5, 2023. Interventions A secure Health Insurance Portability and Accountability Act-compliant platform, Microsoft Azure OpenAI, was used to transform these discharge summaries into a patient-friendly format between July 26 and August 5, 2023. Main Outcomes and Measures Outcomes included readability as measured by Flesch-Kincaid Grade Level and understandability using Patient Education Materials Assessment Tool (PEMAT) scores. Readability and understandability of the original discharge summaries were compared with the transformed, patient-friendly discharge summaries created through the LLM. As balancing metrics, accuracy and completeness of the patient-friendly version were measured. Results Discharge summaries of 50 patients (31 female [62.0%] and 19 male [38.0%]) were included. The median patient age was 65.5 (IQR, 59.0-77.5) years. Mean (SD) Flesch-Kincaid Grade Level was significantly lower in the patient-friendly discharge summaries (6.2 [0.5] vs 11.0 [1.5]; P < .001). PEMAT understandability scores were significantly higher for patient-friendly discharge summaries (81% vs 13%; P < .001). Two physicians reviewed each patient-friendly discharge summary for accuracy on a 6-point scale, with 54 of 100 reviews (54.0%) giving the best possible rating of 6. Summaries were rated entirely complete in 56 reviews (56.0%). Eighteen reviews noted safety concerns, mostly involving omissions, but also several inaccurate statements (termed hallucinations). Conclusions and Relevance The findings of this cross-sectional study of 50 discharge summaries suggest that LLMs can be used to translate discharge summaries into patient-friendly language and formats that are significantly more readable and understandable than discharge summaries as they appear in electronic health records. However, implementation will require improvements in accuracy, completeness, and safety. Given the safety concerns, initial implementation will require physician review.	[Zaretsky, Jonah] NYU Langone Hlth, 550 First Ave, New York, NY 10016 USA; [Zaretsky, Jonah; Kim, Jeong Min; Austrian, Jonathan; Blecker, Saul B.] NYU New York Univ Langone Hlth, Div Hosp Med, Dept Med, New York, NY USA; [Baskharoun, Samuel; Feldman, Jonah] NYU Long Isl Sch Med, Dept Med, Mineola, NY USA; [Zhao, Yunan; Aphinyanaphongs, Yindalon; Blecker, Saul B.] NYU Langone Hlth, Dept Populat Hlth, New York, NY USA; [Austrian, Jonathan; Feldman, Jonah] NYU Langone Med Ctr Informat Technol, Dept Hlth Informat, New York, NY USA; [Aphinyanaphongs, Yindalon] Predict Analyt Unit, NYU Langone Hlth, New York, NY USA; [Gupta, Ravi] Long Isl Community Hosp, Dept Internal Med, NYU Langone Hlth, New York, NY USA	NYU Langone Medical Center; NYU Langone Medical Center; NYU Langone Medical Center; NYU Langone Medical Center	Zaretsky, J (corresponding author), NYU Langone Hlth, 550 First Ave, New York, NY 10016 USA.	jonah.zaretsky@nyulangone.org						Albrecht JS, 2014, J GEN INTERN MED, V29, P1491, DOI 10.1007/s11606-014-2956-0; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; [Anonymous], 2020, The Patient Education Materials Assessment Tool (PEMAT) and user's guide; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bala S, 2020, JMIR FORM RES, V4, DOI 10.2196/16670; Bittner A., 2015, Challenges and Opportunities in Health Care Management, P331, DOI [10.1007/978-3-319-12178-9_26, DOI 10.1007/978-3-319-12178-9_26]; Burns ST, 2022, J GEN INTERN MED, V37, P1797, DOI 10.1007/s11606-021-06988-y; Choudhry AJ, 2019, SURGERY, V165, P789, DOI 10.1016/j.surg.2018.10.014; Choudhry AJ, 2016, AM J SURG, V211, P631, DOI 10.1016/j.amjsurg.2015.12.005; Delbanco T, 2021, JT COMM J QUAL PATIE, V47, P207, DOI 10.1016/j.jcjq.2021.02.004; Diamond L, 2019, J GEN INTERN MED, V34, P1591, DOI 10.1007/s11606-019-04847-5; Duffourc M, 2023, JAMA-J AM MED ASSOC, V330, P313, DOI 10.1001/jama.2023.9630; Eppler MB, 2023, UROL PRACT, V10, P435, DOI 10.1097/UPJ.0000000000000428; Gheorghiu B, 2017, STUD HEALTH TECHNOL, V234, P136, DOI 10.3233/978-1-61499-742-9-136; Greene J, 2012, J GEN INTERN MED, V27, P520, DOI 10.1007/s11606-011-1931-2; Han Hae-Ra, 2019, JMIR Hum Factors, V6, pe15038, DOI 10.2196/15038; Hansen LO, 2011, ANN INTERN MED, V155, P520, DOI 10.7326/0003-4819-155-8-201110180-00008; Hartman VC, 2023, J AM MED INFORM ASSN, V30, P1995, DOI 10.1093/jamia/ocad177; Hibbard JH, 2007, HEALTH SERV RES, V42, P1443, DOI 10.1111/j.1475-6773.2006.00669.x; Jindal P, 2017, EDUC HEALTH, V30, P84, DOI 10.4103/1357-6283.210517; Johnson D, 2023, PREPRINT, DOI DOI 10.21203/RS.3.RS-2566942/V1; Khoong EC, 2023, J HOSP MED, V18, P822, DOI 10.1002/jhm.13172; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lye CT, 2018, J AM MED INFORM ASSN, V25, P1218, DOI 10.1093/jamia/ocy065; Mac O, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.46051; Nayak A, 2023, JAMA INTERN MED, V183, P1026, DOI 10.1001/jamainternmed.2023.2561; OpenNotes, About OpenNotes; Paasche-Orlow MK, 2003, NEW ENGL J MED, V348, P721, DOI 10.1056/NEJMsa021212; Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Smolle C, 2021, BMC HEALTH SERV RES, V21, DOI 10.1186/s12913-021-06468-3; Steinkamp J, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.33348; Unaka NI, 2017, J HOSP MED, V12, P98, DOI 10.12788/jhm.2688; Weiss B.D., 2003, Health Literacy A Manual for Clinicians, P51; Wolff JL, 2017, J AM MED INFORM ASSN, V24, pE166, DOI 10.1093/jamia/ocw108	37	3	3	8	8	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	MAR 11	2024	7	3							e240357	10.1001/jamanetworkopen.2024.0357	http://dx.doi.org/10.1001/jamanetworkopen.2024.0357			10	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	LG9Q6	38466307	gold, Green Published			2024-07-03	WOS:001185758300008
J	Albagieh, H; Alzeer, ZO; Alasmari, ON; Alkadhi, AA; Naitah, AN; Almasaad, KF; Alshahrani, TS; Alshahrani, KS; Almahmoud, MI				Albagieh, Hamad; Alzeer, Zaid O.; Alasmari, Osama N.; Alkadhi, Abdullah A.; Naitah, Abdulaziz N.; Almasaad, Khaled F.; Alshahrani, Turki S.; Alshahrani, Khalid S.; Almahmoud, Mohammed I.			Comparing Artificial Intelligence and Senior Residents in Oral Lesion Diagnosis: A Comparative Study	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						test; llm; oral diagonisis; chatgpt 3.5; oral medicine; artificial intellingence in dentistry		Introduction: Artificial intelligence (AI) is a field of computer science that seeks to build intelligent machines that can carry out tasks that usually necessitate human intelligence. AI may help dentists with a variety of dental tasks, including clinical diagnosis and treatment planning. This study aims to compare the performance of AI and oral medicine residents in diagnosing different cases, providing treatment, and determining if it is reliable to assist them in their field of work. Methods: The study conducted a comparative analysis of the responses from third-and fourth-year residents trained in Oral Medicine and Pathology at King Saud University, College of Dentistry. The residents were given a closed multiple-choice test consisting of 19 questions with four response options labeled A-D and one question with five response options labeled A-E. The test was administered via Google Forms, and each resident's response was stored electronically in an Excel sheet (Microsoft (R) Corp., Redmond, WA). The residents' answers were then compared to the responses generated by three major language models: OpenAI, Stablediffusion, and PopAI. The questions were inputted into the language models in the same format as the original test, and prior to each question, an artificial intelligence chat session was created to eliminate memory retention bias. The input was done on November 19, 2023, the same day the official multiple-choice test was administered. The study had a sample size of 20 residents trained in Oral Medicine and Pathology at King Saud University, College of Dentistry, consisting of both third-year and fourth-year residents. Result: The responses of three large language models (LLM), including OpenAI, Stablediffusion, and PopAI, as well as the responses of 20 senior residents for 20 clinical cases about oral lesion diagnosis. There were no significant variations observed for the remaining questions in the responses to only two questions (10%). For the remaining questions, there were no significant differences. The median (IQR) score of LLMs was 50.0 (45.0 to 60.0), with a minimum of 40 (for stable diffusion) and a maximum of 70 (for OpenAI). The median (IQR) score of senior residents was 65.0 (55.0-75.0). The highest and lowest scores of residents were 40 and 90, respectively. There was no significant difference in the percent scores of residents and LLMs (p = 0.211). The agreement level was measured using the Kappa value. The agreement among senior dental residents was observed to be weak, with a Kappa value of 0.396. In contrast, the agreement among LLMs demonstrated a moderate level, with a Kappa value of 0.622, suggesting a more cohesive alignment in responses among the artificial intelligence models. When comparing residents' responses with those generated by different OpenAI models, including OpenAI, Stablediffusion, and PopAI, the agreement levels were consistently categorized as weak, with Kappa values of 0.402, 0.381, and 0.392, respectively. Conclusion: What the current study reveals is that when comparing the response score, there is no significant difference, in contrast to the agreement analysis among the residents, which was low compared to the LLMs, in which it was high. Dentists should consider that AI is very beneficial in providing diagnosis and treatment and use it to assist them.	[Albagieh, Hamad] King Saud Univ, Oral Med, Riyadh, Saudi Arabia; [Alzeer, Zaid O.; Alasmari, Osama N.; Almasaad, Khaled F.; Almahmoud, Mohammed I.] King Saud Univ, Coll Dent, Dent, Riyadh, Saudi Arabia; [Alkadhi, Abdullah A.; Naitah, Abdulaziz N.; Alshahrani, Turki S.; Alshahrani, Khalid S.] King Saud Univ, Dent Univ Hosp, Coll Dent, Riyadh, Saudi Arabia	King Saud University; King Saud University; King Saud University	Alshahrani, KS (corresponding author), King Saud Univ, Dent Univ Hosp, Coll Dent, Riyadh, Saudi Arabia.	khalidsaadalshahrani@gmail.com	Albagieh, Hamad/KIG-9027-2024					Ahmed N, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/9751564; Alhaidry Hind M, 2023, Cureus, V15, pe38317, DOI 10.7759/cureus.38317; Chen YW, 2020, QUINTESSENCE INT, V51, P248, DOI 10.3290/j.qi.a43952; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Fatani B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37285; Fuchs A., 2023, Swiss dental journal, V134; He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0; Krittanawong C, 2017, J AM COLL CARDIOL, V69, P2657, DOI 10.1016/j.jacc.2017.03.571; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Ohta K, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50369; Pashkov Vitalii M, 2020, Wiad Lek, V73, P2722; Patil S, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051029; Rizwan A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43106; Sakai D, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.49903; Schwendicke F, 2020, J DENT RES, V99, P769, DOI 10.1177/0022034520915714; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Sharma M, 2022, J MED INTERNET RES, V24, DOI 10.2196/40238; Thurzo A, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10071269; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744	19	0	0	6	6	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JAN 3	2024	16	1							e51584	10.7759/cureus.51584	http://dx.doi.org/10.7759/cureus.51584			15	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	IH8O8	38173951	gold			2024-07-03	WOS:001165530200012
C	Abdulhamid, NG; Ochieng, M; Bali, K; Ankrah, EA; Karusala, N; Ronen, K; O'Neill, J		Isafiade, O; Ogunyemi, A; Anya, O; Sakpere, A; Jat, DS; Jere, N		Abdulhamid, Najeeb Gambo; Ochieng, Millicent; Bali, Kalika; Ankrah, Elizabeth A.; Karusala, Naveena; Ronen, Keshet; O'Neill, Jacki			Can Large Language Models Support Medical Facilitation Work? A Speculative Analysis	PROCEEDINGS OF THE 4TH AFRICAN CONFERENCE FOR HUMAN COMPUTER INTERACTION, AFRICHI 2023			English	Proceedings Paper	4th African Conference on Human Computer Interaction (AfriCHI) - Beyond Limits	NOV 27-DEC 01, 2023	Walter Sisulu Univ, East London, SOUTH AFRICA	Pan African Informat Commun Technol Assoc, ACM In Cooperat, SIGCHI, Lelapa Ai, Univ S Africa, Tobii, E London Idz, Sci & Technol Pk	Walter Sisulu Univ	Large language models (LLMs); peer support chatgroups; ethnography; facilitators; roles and responsibility; AI copilot	HEALTH; BENEFITS; EXPERIENCES; CHALLENGES; MANAGEMENT	Mobile messaging apps and SMS-based tools have been deployed to extend healthcare services beyond the clinic; peer support chat groups, consisting of patients and healthcare providers, can improve medication adherence. However, moderation can be burdensome for busy healthcare professionals who must respond to patients, provide accurate and timely information, and engage and build community among patients. In this paper, taking an ethnographic approach, we examine the moderation of chat groups for young people living with HIV in Kenya. We describe the roles and responsibilities of the moderator while striving to engage and build community among the participants and manage the group chat, highlighting the challenges they face. Grounded in the moderators' work, we explore how an LLM-enabled copilot could help or hinder group facilitation. In doing so, we contribute to discussions about the potential of Artificial Intelligence in supporting healthcare professionals.	[Abdulhamid, Najeeb Gambo; Ochieng, Millicent; O'Neill, Jacki] Microsoft Africa Res Inst, Nairobi, Kenya; [Bali, Kalika] Microsoft Res India, Bengaluru, India; [Ankrah, Elizabeth A.] Univ Calif Irvine, Irvine, CA USA; [Karusala, Naveena; Ronen, Keshet] Univ Washington, Seattle, WA USA	University of California System; University of California Irvine; University of Washington; University of Washington Seattle	Abdulhamid, NG (corresponding author), Microsoft Africa Res Inst, Nairobi, Kenya.	nabdulhamid@microsoft.com; mochieng@microsoft.com; kalikab@microsoft.com; eankrah@uci.edu; naveenak@uw.edu; keshet@uw.edu; jacki.oneill@microsoft.com		ONeill, Jacki/0000-0002-3065-0579				Alderwick H, 2022, BMJ-BRIT MED J, V376, DOI 10.1136/bmj.o51; Amuyunzu-Nyamongo M, 2007, AIDS CARE, V19, pS25, DOI 10.1080/09540120601114618; [Anonymous], 2023, We provided mental health support to about 4,000 people-using GPT- 3. Here's what happened?; [Anonymous], 2023, WHO calls for safe and ethical AI for health; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Atanasova S, 2017, INT J MED INFORM, V98, P13, DOI 10.1016/j.ijmedinf.2016.11.005; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beaglehole R, 2008, LANCET, V372, P940, DOI 10.1016/S0140-6736(08)61404-X; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Boulos MNK, 2016, FUTURE INTERNET, V8, DOI 10.3390/fi8030037; Calleja-Castillo JM, 2018, FRONT NEUROL, V9, DOI 10.3389/fneur.2018.00388; Callejas Z., 2021, Dialog systems: a perspective from language, logic and computation, P219, DOI [10.1007/978-3-030-61438-6_11, DOI 10.1007/978-3-030-61438-6_11]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chan A., 2022, AI and Ethics, V3, P53, DOI DOI 10.1007/S43681-022-00148-6; Coulson NS, 2013, COMPUT HUM BEHAV, V29, P1695, DOI 10.1016/j.chb.2013.02.003; Crabtree A, 2000, J AM SOC INFORM SCI, V51, P666, DOI 10.1002/(SICI)1097-4571(2000)51:7<666::AID-ASI8>3.0.CO;2-5; Crabtree A., 2012, Doing Design Ethnography; Curto G, 2024, AI SOC, V39, P617, DOI 10.1007/s00146-022-01494-z; Facey-Shaw L, 2020, SIMULAT GAMING, V51, P33, DOI 10.1177/1046878119884996; Fiske A, 2019, J MED INTERNET RES, V21, DOI 10.2196/13216; Gadiraju V, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P205, DOI 10.1145/3593013.3593989; Gail J., 1992, Harvey Sacks Lectures on Conversation; Ganasegeran K, 2017, INT J MED INFORM, V97, P145, DOI 10.1016/j.ijmedinf.2016.10.013; Harper R. H. R., 2000, Computer Supported Cooperative Work: The Journal of Collaborative Computing, V9, P239, DOI 10.1023/A:1008793124669; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hughes J., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P429, DOI 10.1145/192844.193065; Hughes J. A., 1992, CSCW '92. Sharing Perspectives. Proceedings of the Conference on Computer-Supported Cooperative Work, P115, DOI 10.1145/143457.143469; Huh Jina, 2013, AMIA Annu Symp Proc, V2013, P627; Jovanovic M, 2021, IEEE INTERNET COMPUT, V25, P44, DOI 10.1109/MIC.2020.3037151; Karusala N, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445313; Karusala N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376166; Kenya, 2005, Nairobi Urban Profile | UN-Habitat; Kidwai B, 2020, PROCEDIA COMPUT SCI, V167, P75, DOI 10.1016/j.procs.2020.03.184; Kyewski E, 2018, COMPUT EDUC, V118, P25, DOI 10.1016/j.compedu.2017.11.006; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Martin David, 2014, P 17 ACM C COMP SUPP, P224, DOI [10.1145/2531602.2531663, DOI 10.1145/2531602.2531663]; Mehra A., 2017, Prayana: A Journey Towards Financial Inclusion; Mehra A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173963; Mittelstadt B, 2019, NAT MACH INTELL, V1, P501, DOI 10.1038/s42256-019-0114-4; Mondal I., 2021, P JOINT 15 LINGUISTI, P66; Mwongela S., 2023, INT C LEARNING REPRE; Nardo B, 2016, TELEMED E-HEALTH, V22, P718, DOI 10.1089/tmj.2015.0219; O'Connell TJ, 2008, MED J AUSTRALIA, V188, pS9; O'Neill J., 2003, P 2003 INT ACM SIGGR, P40, DOI DOI 10.1145/958160.958167; O'Neill J, 2017, COMPUT SUPP COOP W J, V26, P733, DOI 10.1007/s10606-017-9289-6; ONeill Jacki, 2011, P ACM 2011 C COMPUTE, P225, DOI DOI 10.1145/1958824.1958859; Ovalle A, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1246, DOI 10.1145/3593013.3594078; Owen JE, 2009, PSYCHO-ONCOL, V18, P144, DOI 10.1002/pon.1374; Perry A, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.863509; Pruitt SD, 2005, BMJ-BRIT MED J, V330, P637, DOI 10.1136/bmj.330.7492.637; Randall D, 2021, COMPUT SUPP COOP W J, V30, P189, DOI 10.1007/s10606-020-09388-8; Rouncefield M., 2011, LSCITS Socio-Technical Systems Engineering Handbook, P44; Salewski L., 2023, In-Context Impersonation Reveals Large Language Models' Strengths and Biases; Salisbury H, 2020, bmj, P368; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shin M, 2021, COMMUN EDUC, V70, P146, DOI 10.1080/03634523.2020.1828959; Singhal K., 2022, LARGE LANGUAGE MODEL; Suchman L., 1987, Plans and Situated Actions: The Problem of Human-Machine Communication; Tam D., 2022, Evaluating the factual consistency of large language models through summarization; Triggle Nick, 2015, Nurs Child Young People, V27, P7, DOI 10.7748/ncyp.27.9.7.s6; van Uden-Kraan CF, 2010, J TELEMED TELECARE, V16, P30, DOI 10.1258/jtt.2009.001009; Wang Q, 2024, BENCHMARKING, V31, P466, DOI 10.1108/BIJ-04-2022-0257; Wang Z., 2023, A Preliminary Study; Were A., 2023, Ethical AI Needed NowMore Than Ever: A viewon the intersection between AI and economic development; Wilson L, 2022, JMIR HUM FACTORS, V9, DOI 10.2196/35882; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Xu W., 2023, AI in HCI Design and User Experience; Yap CEL, 2021, LECT NOTES COMPUT SC, V12933, P259, DOI 10.1007/978-3-030-85616-8_16; Zarocostas J, 2011, BRIT MED J, V343, DOI 10.1136/bmj.d4326; Zheng QX, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501855	71	1	1	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0887-9				2023							64	70		10.1145/3628096.3628752	http://dx.doi.org/10.1145/3628096.3628752			7	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5FM					2024-07-03	WOS:001159802500013
J	Lyon, D				Lyon, Debra			Artificial Intelligence for Oncology Nursing Authors: Potential Utility and Concerns About Large Language Model Chatbots	ONCOLOGY NURSING FORUM			English	Editorial Material						artificial intelligence; large language model; chatbots; ChatGPT; research; publishing			[Lyon, Debra] Univ Florida, Coll Nursing, Gainesville, FL 32611 USA	State University System of Florida; University of Florida	Lyon, D (corresponding author), Univ Florida, Coll Nursing, Gainesville, FL 32611 USA.	ONFEditor@ons.org						Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Committee on Publication Ethics Council, 2021, ARTIF INTELL, DOI [10.24318/9kvAgrnJ, DOI 10.24318/9KVAGRNJ]; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Koo Malcolm, 2023, Radiology, V307, pe230312, DOI 10.1148/radiol.230312; Lund B.D., Library Hi Tech News; OpenAI, 2022, Introducing chatgpt	6	1	1	17	26	ONCOLOGY NURSING SOC	PITTSBURGH	125 ENTERPRISE DR, PITTSBURGH, PA 15275 USA	0190-535X	1538-0688		ONCOL NURS FORUM	Oncol. Nurs. Forum	MAY	2023	50	3					276	277		10.1188/23.ONF.276-277	http://dx.doi.org/10.1188/23.ONF.276-277			2	Oncology; Nursing	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Oncology; Nursing	ES9J7	37155982				2024-07-03	WOS:001141030900001
J	Biswas, S; Dobaria, D; Cohen, HL				Biswas, Som; Dobaria, Dushyant; Cohen, Harris L.			ChatGPT and the Future of Journal Reviews A Feasibility Study	YALE JOURNAL OF BIOLOGY AND MEDICINE			English	Article						chatGPT; review; journal reviews		The increasing volume of research submissions to academic journals poses a significant challenge for traditional peer-review processes. To address this issue, this study explores the potential of employing ChatGPT, an advanced large language model (LLM), developed by OpenAI, as an artificial intelligence (AI) reviewer for academic journals. By leveraging the vast knowledge and natural language processing capabilities of ChatGPT, we hypothesize it may be possible to enhance the efficiency, consistency, and quality of the peer-review process. This research investigated key aspects of integrating ChatGPT into the journal review workflow. We compared the critical analysis of ChatGPT, acting as an AI reviewer, to human reviews for a single published article. Our methodological framework involved subjecting ChatGPT to an intricate examination, wherein its evaluative acumen was juxtaposed against human-authored reviews of a singular published article. As this is a feasibility study, one article was reviewed, which was a case report on scurvy. The entire article was used as an input into ChatGPT and commanded it to "Please perform a review of the following article and give points for revision." Since this was a case report with a limited word count the entire article could fit in one chat box. The output by ChatGPT was then compared with the comments by human reviewers. Key performance metrics, including precision and overall agreement, were judiciously and subjectively measured to portray the efficacy of ChatGPT as an AI reviewer in comparison to its human counterparts. The outcomes of this rigorous analysis unveiled compelling evidence regarding ChatGPT's performance as an AI reviewer. We demonstrated that ChatGPT's critical analyses aligned with those of human reviewers, as evidenced by the inter-rater agreement. Notably, ChatGPT exhibited commendable capability in identifying methodological flaws, articulating insightful feedback on theoretical frameworks, and gauging the overall contribution of the articles to their respective fields. While the integration of ChatGPT showcased immense promise, certain challenges and caveats surfaced. For example, ambiguities might present with complex research articles, leading to nuanced discrepancies between AI and human reviews. Also figures and images cannot be reviewed by ChatGPT. Lengthy articles need to be reviewed in parts by ChatGPT as the entire article will not fit in one chat/response. The benefits consist of reduction in time needed by journals to review the articles submitted to them, as well as an AI assistant to give a different perspective about the research papers other than the human reviewers. In conclusion, this research contributes a groundbreaking foundation for incorporating ChatGPT into the pantheon of journal reviewers. The delineated guidelines distill key insights into operationalizing ChatGPT as a proficient reviewer within academic journal frameworks, paving the way for a more efficient and insightful review process.	[Biswas, Som; Dobaria, Dushyant; Cohen, Harris L.] Univ Tennessee, Hlth Sci Ctr, Le Bonheur Childrens Hosp, Memphis, TN USA; [Biswas, Som] Le Bonheur Childrens Hosp, Pediat Radiol, Memphis, TN 38103 USA	University of Tennessee System; University of Tennessee Health Science Center	Biswas, S (corresponding author), Le Bonheur Childrens Hosp, Pediat Radiol, Memphis, TN 38103 USA.	sbiswas8@uthsc.edu		BISWAS, SOM/0000-0002-4038-5844				Al-Mhdawi MK, Expert Evaluation of ChatGPT Performance for Risk Management Process Based on ISO 31000 Standard; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Ayre J, medRxiv, DOI [10.1101/2023.07.24.23292591, DOI 10.1101/2023.07.24.23292591]; Cherni MA, 2013, INT J BIOMED ENG TEC, V12, P60, DOI 10.1504/IJBET.2013.056285; Dai W, A Case Study on ChatGPT; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Iyengar KP., 2021, J Orthop Traumatol Rehabil, V13, P180; Kohnke L, 2023, RELC J.; Larsen PO, 2010, SCIENTOMETRICS, V84, P575, DOI 10.1007/s11192-010-0202-z; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Leopold SS, 2015, CLIN ORTHOP RELAT R, V473, P753, DOI 10.1007/s11999-014-4129-1; openfoam, ABOUT US; Trucco E, 2019, ELS MIC SOC BOOK SER, P1, DOI 10.1016/C2018-0-00865-8; Zuengler J, 2010, MOD LANG J, V94, P637, DOI 10.1111/j.1540-4781.2010.01096.x	14	5	5	30	52	YALE J BIOLOGY MEDICINE, INC	NEW HAVEN	333 CEDAR ST, PO BOX 208000, NEW HAVEN, CT 06520-8000 USA	0044-0086	1551-4056		YALE J BIOL MED	Yale J. Biol. Med.	SEP	2023	96	3					415	420						6	Biology; Medicine, General & Internal; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; General & Internal Medicine; Research & Experimental Medicine	X0ZR4	37780993	gold, Green Published			2024-07-03	WOS:001095823200003
C	Choi, J; Jung, E; Suh, J; Rhee, W			ASSOC COMP MACHINERY	Choi, Jaekeol; Jung, Euna; Suh, Jangwon; Rhee, Wonjong			Improving Bi-encoder Document Ranking Models with Two Rankers and Multi-teacher Distillation	SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL			English	Proceedings Paper	44th International ACM SIGIR Conference on Research and Development in Information Retrieval	JUL 11-15, 2021	ELECTR NETWORK	ACM SIGIR, Assoc Comp Machinery		Information retrieval; neural ranking model; bi-encoder; knowledge distillation; multi-teacher distillation		BERT-based Neural Ranking Models (NRMs) can be classified according to how the query and document are encoded through BERT's self-attention layers - bi-encoder versus cross-encoder. Bi-encoder models are highly efficient because all the documents can be pre-processed before the query time, but their performance is inferior compared to cross-encoder models. Both models utilize a ranker that receives BERT representations as the input and generates a relevance score as the output. In this work, we propose a method where multi-teacher distillation is applied to a cross-encoder NRM and a bi-encoder NRM to produce a bi-encoder NRM with two rankers. The resulting student bi-encoder achieves an improved performance by simultaneously learning from a cross-encoder teacher and a bi-encoder teacher and also by combining relevance scores from the two rankers. We call this method TRMD (Two Rankers and Multi-teacher Distillation). In the experiments, TwinBERT and ColBERT are considered as baseline bi-encoders. When monoBERT is used as the cross-encoder teacher, together with either TwinBERT or ColBERT as the bi-encoder teacher, TRMD produces a student bi-encoder that performs better than the corresponding baseline bi-encoder. For P@20, the maximum improvement was 11.4%, and the average improvement was 6.8%. As an additional experiment, we considered producing cross-encoder students with TRMD, and found that it could also improve the cross-encoders.(1)	[Choi, Jaekeol] Seoul Natl Univ, Seoul, South Korea; [Choi, Jaekeol] Naver Corp, Seongnam Si, South Korea; [Jung, Euna; Suh, Jangwon] Seoul Natl Univ, GSCST, Seoul, South Korea; [Rhee, Wonjong] Seoul Natl Univ, GSCST, GSAI, AIIS, Seoul, South Korea	Seoul National University (SNU); Naver; Seoul National University (SNU); Seoul National University (SNU)	Choi, J (corresponding author), Seoul Natl Univ, Seoul, South Korea.; Choi, J (corresponding author), Naver Corp, Seongnam Si, South Korea.	jaekeol.choi@snu.ac.kr; xlpczv@snu.ac.kr; rxwe5607@snu.ac.kr; wrhee@snu.ac.kr	Rhee, Wonjong/JMB-2765-2023		Naver corporation ('Development of information retrieval system with large language models'); NRF - Korea Government (MSIT) [NRF-2020R1A2C2007139]	Naver corporation ('Development of information retrieval system with large language models'); NRF - Korea Government (MSIT)	This work was supported in part by Naver corporation (`Development of information retrieval system with large language models') and in part by the NRF grant (NRF-2020R1A2C2007139) funded by the Korea Government (MSIT).	Dehghani M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/3077136.3080832; Fukuda T, 2017, INTERSPEECH, P3697, DOI 10.21437/Interspeech.2017-614; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton G., 2015, ARXIV; Hui K, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P279, DOI 10.1145/3159652.3159689; Humeau Samuel, 2020, P ICLR; Huston Samuel, 2014, PARAMETERS LEARNED C; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Kingma D. P., 2017, ARXIV; Lu WH, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2645, DOI 10.1145/3340531.3412747; MacAvaney S, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1101, DOI 10.1145/3331184.3331317; Mitra B, 2018, FOUND TRENDS INF RET, V13, P1, DOI 10.1561/1500000061; Nogueira Rodrigo, 2019, Passage re-ranking with BERT; You S, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1285, DOI 10.1145/3097983.3098135	14	8	8	0	7	ASSOC COMPUTING MACHINERY	NEW YORK	1515 BROADWAY, NEW YORK, NY 10036-9998 USA			978-1-4503-8037-9				2021							2192	2196		10.1145/3404835.3463076	http://dx.doi.org/10.1145/3404835.3463076			5	Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BS4KH		Green Submitted			2024-07-03	WOS:000719807900273
J	Yanagita, Y; Yokokawa, D; Uchida, S; Tawara, J; Ikusaka, M				Yanagita, Yasutaka; Yokokawa, Daiki; Uchida, Shun; Tawara, Junsuke; Ikusaka, Masatomi			Accuracy of ChatGPT on Medical Questions in the National Medical Licensing Examination in Japan: Evaluation Study	JMIR FORMATIVE RESEARCH			English	Article						artificial intelligence; ChatGPT; GPT-4; AI; National Medical Licensing Examination; Japanese; NMLE		Background: ChatGPT (OpenAI) has gained considerable attention because of its natural and intuitive responses. ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers, as stated by OpenAI as a limitation. However, considering that ChatGPT is an interactive AI that has been trained to reduce the output of unethical sentences, the reliability of the training data is high and the usefulness of the output content is promising. Fortunately, in March 2023, a new version of ChatGPT, GPT-4, was released, which, according to internal evaluations, was expected to increase the likelihood of producing factual responses by 40% compared with its predecessor, GPT-3.5. The usefulness of this version of ChatGPT in English is widely appreciated. It is also increasingly being evaluated as a system for obtaining medical information in languages other than English. Although it does not reach a passing score on the national medical examination in Chinese, its accuracy is expected to gradually improve. Evaluation of ChatGPT with Japanese input is limited, although there have been reports on the accuracy of ChatGPT's answers to clinical questions regarding the Japanese Society of Hypertension guidelines and on the performance of the National Nursing Examination.Objective: The objective of this study is to evaluate whether ChatGPT can provide accurate diagnoses and medical knowledge for Japanese input.Methods: Questions from the National Medical Licensing Examination (NMLE) in Japan, administered by the Japanese Ministry of Health, Labour and Welfare in 2022, were used. All 400 questions were included. Exclusion criteria were figures and tables that ChatGPT could not recognize; only text questions were extracted. We instructed GPT-3.5 and GPT-4 to input the Japanese questions as they were and to output the correct answers for each question. The output of ChatGPT was verified by 2 general practice physicians. In case of discrepancies, they were checked by another physician to make a final decision. The overall performance was evaluated by calculating the percentage of correct answers output by GPT-3.5 and GPT-4.Results: Of the 400 questions, 292 were analyzed. Questions containing charts, which are not supported by ChatGPT, were excluded. The correct response rate for GPT-4 was 81.5% (237/292), which was significantly higher than the rate for GPT-3.5, 42.8% (125/292). Moreover, GPT-4 surpassed the passing standard (>72%) for the NMLE, indicating its potential as a diagnostic and therapeutic decision aid for physicians.Conclusions: GPT-4 reached the passing standard for the NMLE in Japan, entered in Japanese, although it is limited to written questions. As the accelerated progress in the past few months has shown, the performance of the AI will improve as the large language model continues to learn more, and it may well become a decision support system for medical professionals by providing more accurate information.	[Yanagita, Yasutaka; Yokokawa, Daiki; Uchida, Shun; Ikusaka, Masatomi] Chiba Univ Hosp, Dept Gen Med, Chiba, Japan; [Tawara, Junsuke] Sanmu Med Ctr, Dept Internal Med, Chiba, Japan; [Yanagita, Yasutaka] Chiba Univ Hosp, Dept Gen Med, 1 8 1 Inohana,Chuo ku, Chiba 2608677, Japan	Chiba University	Yanagita, Y (corresponding author), Chiba Univ Hosp, Dept Gen Med, 1 8 1 Inohana,Chuo ku, Chiba 2608677, Japan.	y.yanagita@gmail.com		Tawara, Junsuke/0000-0002-7842-5047; Uchida, Shun/0000-0003-3408-9763; Yanagita, Yasutaka/0000-0002-9213-8247				Adhikari K, 2024, CURR UROL REP, V25, P1, DOI 10.1007/s11934-023-01185-2; [Anonymous], The 116th national examination for medical practitioners: questions and answers; [Anonymous], GPT-4 is OpenAI's most advanced system, producing safer and more useful responses; Choi JH, 2022, J LEGAL EDUC, V71, P387; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Hu J, 2020, 2020 PRESENTED 37 IN, P13; Kaneda Y, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42924; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kusunose K, 2023, CIRC J, V87, P1030, DOI 10.1253/circj.CJ-23-0308; Kusunose K, 2023, J ECHOCARDIOGR, V21, P99, DOI 10.1007/s12574-023-00611-1; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; OpenAI, Introducing ChatGPT; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Wang XY, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01961-0; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589	20	13	13	7	9	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA		2561-326X		JMIR FORM RES	JMIR Form. Res.		2023	7								e48023	10.2196/48023	http://dx.doi.org/10.2196/48023			8	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	Y8BO8	37831496	gold, Green Published			2024-07-03	WOS:001107459700001
J	Browning, J				Browning, Jacob			Getting it right: the limits of fine-tuning large language models	ETHICS AND INFORMATION TECHNOLOGY			English	Article						Large language models; Normativity; Alignment; Artificial intelligence		The surge in interest in natural language processing in artificial intelligence has led to an explosion of new language models capable of engaging in plausible language use. But ensuring these language models produce honest, helpful, and inoffensive outputs has proved difficult. In this paper, I argue problems of inappropriate content in current, autoregressive language models-such as ChatGPT and Gemini-are inescapable; merely predicting the next word is incompatible with reliably providing appropriate outputs. The various fine-tuning methods, while helpful, cannot transform the model from mere next word prediction to the kind of planning and forethought necessary for saying the right thing. The upshot is that these models will increasingly churn out bland, generic responses that will still fail to be accurate or appropriate.	[Browning, Jacob] NYU, New York, NY 10012 USA	New York University	Browning, J (corresponding author), NYU, New York, NY 10012 USA.	browning.jake@gmail.com						Agarwal C., 2024, arXiv Preprint arXiv, V2402, P04614; Andreas J., 2022, arXiv; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Belanger A., 2023, Ars Technica; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Browning J., 2022, AI and the Limits of Language; Browning J, 2023, AI SOC, DOI 10.1007/s00146-023-01724-y; Bump P., 2024, Washington Post; Casper S, 2023, Arxiv, DOI [arXiv:2307.15217, 10.48550/arXiv.2307.15217]; Chen L., 2023, arXiv Preprint arXiv, V2307; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; Deng G., 2023, arXiv Preprint arXiv, V2307; Dentella V, 2023, Arxiv, DOI [arXiv:2302.12313, 10.48550/arXiv.2302.12313]; Dziri N, 2022, T ASSOC COMPUT LING, V10, P1066, DOI 10.1162/tacl_a_00506; El-Mahdi E., 2022, arXiv; Gabriel I., 2023, Philosophy of Technology; Ganguli D, 2023, Arxiv, DOI arXiv:2302.07459; Ghaffery S., 2023, Bloomberg; Grice HP., 1975, SYNTAX SEMANTICS, P41, DOI [DOI 10.1163/9789004368811_003, 10.1163/9789004368811_003]; Hoel E., 2024, The New York Times, The New York Times; Hofstadter D., 2023, The Atlantic, Atlantic media company; Jain N, 2024, Arxiv, DOI arXiv:2403.07974; Kalai AT, 2024, Arxiv, DOI arXiv:2311.14648; Kempt H., 2023, ArXiv, P1; Koco J., 2023, Elsevier BV, DOI [10.2139/ssrn.4372889, DOI 10.2139/SSRN.4372889]; Korbak T, 2023, Arxiv, DOI [arXiv:2302.08582, 10.48550/arxiv.2302.08582]; Kumar A., 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.10054; LeCun Y., 2022, Open Review, V62; Liu NF, 2024, T ASSOC COMPUT LING, V12, P157, DOI 10.1162/tacl_a_00638; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Mahowald K., 2024, The Conversation; McCoy RT, 2023, Arxiv, DOI [arXiv:2309.13638, 10.48550/arXiv.2309.13638]; Milliere R., 2020, Nautilus; Moderator, 2022, Meta Stack Overflow; Mollo DC, 2023, Arxiv, DOI arXiv:2304.01481; Offenhartz J., 2024, AP News, AP News; Orf D., 2023, Elon musk building anti-woke ai to rival ChatGPT: What it means; Ortega PA, 2021, Arxiv, DOI arXiv:2110.10819; Pavlick E, 2022, ANNU REV LINGUIST, V8, P447, DOI 10.1146/annurev-linguistics-031120-122924; Piantasodi S. T., 2022, ArXiv, P1; Piltch A., 2023, Plagiarism Engine: Google's Content-Swiping AI Could Break the Internet; Razeghi Y, 2022, Arxiv, DOI [arXiv:2202.07206, 10.48550/arXiv.2202.07206]; Russell S., 2019, Human compatible. ai and the problem of control; Schank R.C., 1977, SCRIPTS PLANS GOALS; Scott-Philips T., 2014, Red Globe; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Sutton R., 1998, Reinfocement Learning: An introduction; Tangerman V., 2023, Microsoft's Bing AI Now Threatening Users Who Provoke It; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Valmeekam K., 2023, Arxiv, P1; Vaswani A, 2017, ADV NEUR IN, V30; Wallace RJ., 1994, Responsibility and the Moral Sentiments; Welbl J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2447; Westfall C., 2023, Forbes; Whitney L, 2023, ZDNet; Wiggers K., 2024, TechCrunch; Williams A., 2022, The Exploited Labor behnd AI; Wu ZF, 2023, Arxiv, DOI [arXiv:2307.02477, 10.48550/arXiv.2307.02477]; Yiu E, 2023, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916231201401; Zhao P., 2024, arXiv Preprint arXiv, V2402, P19473	61	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	JUN	2024	26	2							36	10.1007/s10676-024-09779-1	http://dx.doi.org/10.1007/s10676-024-09779-1			9	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	SP3A5					2024-07-03	WOS:001235603100001
J	Zhong, Y; Chen, YJ; Zhou, Y; Lyu, YAH; Yin, JJ; Gao, YJ				Zhong, Yi; Chen, Yu-jun; Zhou, Yang; Lyu, Yan-Ao-Hai; Yin, Jia-Jun; Gao, Yu-jun			The Artificial intelligence large language models and neuropsychiatry practice and research ethic	ASIAN JOURNAL OF PSYCHIATRY			English	Letter						Artificial intelligence; ChatGPT; Large language model; Neuropsychiatry research; Ethic			[Zhong, Yi; Yin, Jia-Jun] Jiangnan Univ, Affiliated Wuxi Mental Hlth Ctr, Wuxi Cent Rehabil Hosp, Wuxi, Jiangsu, Peoples R China; [Zhong, Yi] Peking Univ, Peking Univ Sixth Hosp, Inst Mental Hlth, NHC Key Lab Mental Hlth,Natl Clin Res Ctr Mental D, Beijing 100191, Peoples R China; [Zhong, Yi] City Univ Hong Kong, Dept Neurosci, Hong Kong, Peoples R China; [Chen, Yu-jun] Nanjing Univ Chinese Med, Affiliated Shuyang Hosp, Nanjing, Jiangsu, Peoples R China; [Zhou, Yang] Wuhan Mental Hlth Ctr, Dept Psychiat, Wuhan, Hubei, Peoples R China; [Zhou, Yang] Wuhan Hosp Psychotherapy, Dept Psychiat, Wuhan, Hubei, Peoples R China; [Lyu, Yan-Ao-Hai] City Univ Hong Kong, Dept Social & Behav Sci, Hong Kong, Peoples R China; [Gao, Yu-jun] Wuhan Univ, Renmin Hosp, Dept Psychiat, Wuhan, Hubei, Peoples R China; [Gao, Yu-jun] McGill Univ, Douglas Res Ctr, Clin & Translat Sci CaTS Lab, Montreal, PQ, Canada	Jiangnan University; Peking University; City University of Hong Kong; Nanjing University of Chinese Medicine; City University of Hong Kong; Wuhan University; McGill University	Zhong, Y; Yin, JJ (corresponding author), Jiangnan Univ, Affiliated Wuxi Mental Hlth Ctr, Wuxi Cent Rehabil Hosp, Wuxi, Jiangsu, Peoples R China.; Gao, YJ (corresponding author), Wuhan Univ, Renmin Hosp, Dept Psychiat, Wuhan, Hubei, Peoples R China.	yi.zhong@my.cityu.edu.hk; yinjiajun@jiangnan.edu.cn; Yujun_Gao@whu.edu.cn	zhong, yi/HNI-8662-2023	zhong, yi/0000-0002-4652-7241; gao, yu jun/0000-0002-6762-5131	Wuxi Taihu Talent Project [WXTTP2020008, WXTTP2021]; Wuxi Municipal Health Com-mission [Q202131]	Wuxi Taihu Talent Project; Wuxi Municipal Health Com-mission	This study was supported by Wuxi Taihu Talent Project (Nos. WXTTP2020008 and WXTTP2021) and Wuxi Municipal Health Com-mission (Q202131) .	[Anonymous], 2023, Nature; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brinker TJ, 2019, EUR J CANCER, V111, P30, DOI 10.1016/j.ejca.2018.12.016; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gao YJ, 2022, FRONT AGING NEUROSCI, V14, DOI 10.3389/fnagi.2022.979183; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Ray A, 2022, ASIAN J PSYCHIATR, V70, DOI 10.1016/j.ajp.2022.103021; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thornton J, 2023, ASIAN J PSYCHIATR, V81, DOI 10.1016/j.ajp.2023.103509	10	17	18	52	174	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1876-2018	1876-2026		ASIAN J PSYCHIATR	Asian J. Psychiatr.	JUN	2023	84								103577	10.1016/j.ajp.2023.103577	http://dx.doi.org/10.1016/j.ajp.2023.103577		APR 2023	3	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	D7IK0	37019020				2024-07-03	WOS:000970423700001
J	Luu, N; Van, N; Shojazadeh, A; Zhao, YX; Molloi, S				Luu, Nile; Van, Nathan; Shojazadeh, Alireza; Zhao, Yixiao; Molloi, Sabee			Reproducibility of a semiautomatic lobar lung tissue assignment technique on noncontrast CT scans: a study on swine animal model	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Animals; Lung; Observer variation; Swine; Tomography (x-ray computed)	SEGMENTATION	Background To evaluate the reproducibility of a vessel-specific minimum cost path (MCP) technique used for lobar segmentation on noncontrast computed tomography (CT).Methods Sixteen Yorkshire swine (49.9 +/- 4.7 kg, mean +/- standard deviation) underwent a total of 46 noncontrast helical CT scans from November 2020 to May 2022 using a 320-slice scanner. A semiautomatic algorithm was employed by three readers to segment the lung tissue and pulmonary arterial tree. The centerline of the arterial tree was extracted and partitioned into six subtrees for lobar assignment. The MCP technique was implemented to assign lobar territories by assigning lung tissue voxels to the nearest arterial tree segment. MCP-derived lobar mass and volume were then compared between two acquisitions, using linear regression, root mean square error (RMSE), and paired sample t-tests. An interobserver and intraobserver analysis of the lobar measurements was also performed.Results The average whole lung mass and volume was 663.7 +/- 103.7 g and 1,444.22 +/- 309.1 mL, respectively. The lobar mass measurements from the initial (MLobe1) and subsequent (MLobe2) acquisitions were correlated by MLobe1 = 0.99 MLobe2 + 1.76 (r = 0.99, p = 0.120, RMSE = 7.99 g). The lobar volume measurements from the initial (VLobe1) and subsequent (VLobe2) acquisitions were correlated by VLobe1 = 0.98VLobe2 + 2.66 (r = 0.99, p = 0.160, RSME = 15.26 mL).Conclusions The lobar mass and volume measurements showed excellent reproducibility through a vessel-specific assignment technique. This technique may serve for automated lung lobar segmentation, facilitating clinical regional pulmonary analysis.Relevance statement Assessment of lobar mass or volume in the lung lobes using noncontrast CT may allow for efficient region-specific treatment strategies for diseases such as pulmonary embolism and chronic thromboembolic pulmonary hypertension.Key points center dot Lobar segmentation is essential for precise disease assessment and treatment planning. center dot Current methods for segmentation using fissure lines are problematic. center dot The minimum-cost-path technique here is proposed and a swine model showed excellent reproducibility for lobar mass measurements. center dot Interobserver agreement was excellent, with intraclass correlation coefficients greater than 0.90.Key points center dot Lobar segmentation is essential for precise disease assessment and treatment planning. center dot Current methods for segmentation using fissure lines are problematic. center dot The minimum-cost-path technique here is proposed and a swine model showed excellent reproducibility for lobar mass measurements. center dot Interobserver agreement was excellent, with intraclass correlation coefficients greater than 0.90.Key points center dot Lobar segmentation is essential for precise disease assessment and treatment planning. center dot Current methods for segmentation using fissure lines are problematic. center dot The minimum-cost-path technique here is proposed and a swine model showed excellent reproducibility for lobar mass measurements. center dot Interobserver agreement was excellent, with intraclass correlation coefficients greater than 0.90.Key points center dot Lobar segmentation is essential for precise disease assessment and treatment planning. center dot Current methods for segmentation using fissure lines are problematic. center dot The minimum-cost-path technique here is proposed and a swine model showed excellent reproducibility for lobar mass measurements. center dot Interobserver agreement was excellent, with intraclass correlation coefficients greater than 0.90.	[Luu, Nile; Van, Nathan; Shojazadeh, Alireza; Zhao, Yixiao; Molloi, Sabee] Univ Calif Irvine, Dept Radiol Sci, Med Sci 1,B-140, Irvine, CA 92697 USA	University of California System; University of California Irvine	Molloi, S (corresponding author), Univ Calif Irvine, Dept Radiol Sci, Med Sci 1,B-140, Irvine, CA 92697 USA.	symolloi@uci.edu		Luu, Nile/0009-0000-6723-9217; Molloi, sabee/0000-0003-1852-4913	Department of Radiological Sciences at the University of California, Irvine	Department of Radiological Sciences at the University of California, Irvine	Large language models were not used for this paper.	Doel T, 2015, COMPUT MED IMAG GRAP, V40, P13, DOI 10.1016/j.compmedimag.2014.10.008; Felloni P, 2017, ACAD RADIOL, V24, P1412, DOI 10.1016/j.acra.2017.05.003; Hatabu H, 2020, LANCET RESP MED, V8, P726, DOI 10.1016/S2213-2600(20)30168-5; Judge EP, 2014, AM J RESP CELL MOL, V51, P334, DOI 10.1165/rcmb.2013-0453TR; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lassen B, 2013, IEEE T MED IMAGING, V32, P210, DOI 10.1109/TMI.2012.2219881; Nam JG, 2021, EUR RADIOL, V31, P9012, DOI 10.1007/s00330-021-08036-z; Park J, 2020, J DIGIT IMAGING, V33, P221, DOI 10.1007/s10278-019-00223-1; Provost K, 2017, J NUCL MED TECHNOL, V45, P185, DOI 10.2967/jnmt.117.191056; Shen ML, 2019, RESPIRATION, V98, P70, DOI 10.1159/000499622; Singh R, 2020, EUR RADIOL, V30, P2535, DOI 10.1007/s00330-019-06607-9; Thapa P., 2016, India Indian J Health Sci, V9, P284, DOI [10.4103/2349-5006.196326, DOI 10.4103/2349-5006.196326]; van Rikxoort EM, 2010, IEEE T MED IMAGING, V29, P1286, DOI 10.1109/TMI.2010.2044799; Yuan SY, 2011, Colloquium Series on Integrated Systems Physiology: From Molecule to Function, V3, P1, DOI [DOI 10.4199/C00025ED1V01Y201101ISP013, 10.4199/c00025-d1v01y201101isp013, DOI 10.4199/C00025-D1V01Y201101ISP013]; Zhang L, 2006, IEEE T MED IMAGING, V25, P1, DOI 10.1109/TMI.2005.859209; Zhao YX, 2023, QUANT IMAG MED SURG, V13, P3115, DOI [10.21037/qims-22-821, 10.21037/qims-22-791]; Zhao YX, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228110; Zhou C, 2006, PROC SPIE, V6144, DOI 10.1117/12.655343	18	0	0	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	MAY 6	2024	8	1							55	10.1186/s41747-024-00453-1	http://dx.doi.org/10.1186/s41747-024-00453-1			14	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	UW2H5	38705940	gold			2024-07-03	WOS:001251029900001
J	Chancel, L; Bothe, P; Voituriez, T				Chancel, Lucas; Bothe, Philipp; Voituriez, Tancrede			The potential of wealth taxation to address the triple climate inequality crisis	NATURE CLIMATE CHANGE			English	Article								The triple climate inequality crisis, or disparities in contributions, impacts and capacity to act within and between countries, is a central issue in addressing climate change. This Comment advocates for progressive wealth taxation as a viable solution to the finance gap.	[Chancel, Lucas] Harvard Univ, Harvard Kennedy Sch, Cambridge, MA 02138 USA; [Chancel, Lucas] Sci Po, CRIS, Paris, France; [Chancel, Lucas; Bothe, Philipp] Paris Sch Econ, World Inequal Lab, Paris, France; [Voituriez, Tancrede] CIRAD, Paris, France; [Voituriez, Tancrede] Sci Po, Inst Sustainable Dev & Int Relat IDDRI, Paris, France	Harvard University; Institut d'Etudes Politiques Paris (Sciences Po); Paris School of Economics; CIRAD; Institut d'Etudes Politiques Paris (Sciences Po)	Chancel, L (corresponding author), Harvard Univ, Harvard Kennedy Sch, Cambridge, MA 02138 USA.; Chancel, L (corresponding author), Sci Po, CRIS, Paris, France.; Chancel, L (corresponding author), Paris Sch Econ, World Inequal Lab, Paris, France.	lucas.chancel@sciencespo.fr		Bothe, Philipp/0009-0005-6238-4948	EC | Horizon 2020 Framework Programme (EU Framework Programme for Research and Innovation H2020)	EC | Horizon 2020 Framework Programme (EU Framework Programme for Research and Innovation H2020)	We acknowledge the use of large language models for stylistic enhancements in the text.	Bruckner B, 2022, NAT SUSTAIN, V5, P311, DOI 10.1038/s41893-021-00842-z; Carleton T, 2022, Q J ECON, V137, P2037, DOI 10.1093/qje/qjac020; Chancel L., 2023, Climate Inequality Report 2023; Chancel L, 2022, NAT SUSTAIN, V5, P931, DOI 10.1038/s41893-022-00955-z; Diffenbaugh NS, 2019, P NATL ACAD SCI USA, V116, P9808, DOI 10.1073/pnas.1816020116; Fanning AL, 2023, NAT SUSTAIN, V6, DOI 10.1038/s41893-023-01130-8; Hallegatte S, 2017, NAT CLIM CHANGE, V7, P250, DOI 10.1038/NCLIMATE3253; Jevrejeva S, 2018, ENVIRON RES LETT, V13, DOI 10.1088/1748-9326/aacc76; Kalkuhl M, 2020, J ENVIRON ECON MANAG, V103, DOI 10.1016/j.jeem.2020.102360; Ortiz-Bobea A, 2021, NAT CLIM CHANGE, V11, P306, DOI 10.1038/s41558-021-01000-1; Palagi E, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2203595119; Songwe V., 2022, Finance for Climate Action: Scaling Up Investment for Climate and Development'; Suter G, 2022, INTEGR ENVIRON ASSES, V18, P1117	13	0	0	10	10	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1758-678X	1758-6798		NAT CLIM CHANGE	Nat. Clim. Chang.	JAN	2024	14	1					5	7		10.1038/s41558-023-01891-2	http://dx.doi.org/10.1038/s41558-023-01891-2		DEC 2023	3	Environmental Sciences; Environmental Studies; Meteorology & Atmospheric Sciences	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Environmental Sciences & Ecology; Meteorology & Atmospheric Sciences	EL8K4		Green Published			2024-07-03	WOS:001133732200002
J	Májovsky, M; Cerny, M; Kasal, ME; Komarc, M; Netuka, D				Majovsky, Martin; Cerny, Martin; Kasal, Mat Ej; Komarc, Martin; Netuka, David			Artificial Intelligence Can Generate Fraudulent but Authentic-Looking Scientific Medical Articles: Pandora's Box Has Been Opened	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						artificial intelligence; publications; ethics; neurosurgery; ChatGPT; language models; fraudulent medical articles		Background: Artificial intelligence (AI) has advanced substantially in recent years, transforming many industries and improving the way people live and work. In scientific research, AI can enhance the quality and efficiency of data analysis and publication. However, AI has also opened up the possibility of generating high-quality fraudulent papers that are difficult to detect, raising important questions about the integrity of scientific research and the trustworthiness of published papers.Objective: The aim of this study was to investigate the capabilities of current AI language models in generating high-quality fraudulent medical articles. We hypothesized that modern AI models can create highly convincing fraudulent papers that can easily deceive readers and even experienced researchers. Methods: This proof-of-concept study used ChatGPT (Chat Generative Pre-trained Transformer) powered by the GPT-3 (Generative Pre-trained Transformer 3) language model to generate a fraudulent scientific article related to neurosurgery. GPT-3 is a large language model developed by OpenAI that uses deep learning algorithms to generate human-like text in response to prompts given by users. The model was trained on a massive corpus of text from the internet and is capable of generating high-quality text in a variety of languages and on various topics. The authors posed questions and prompts to the model and refined them iteratively as the model generated the responses. The goal was to create a completely fabricated article including the abstract, introduction, material and methods, discussion, references, charts, etc. Once the article was generated, it was reviewed for accuracy and coherence by experts in the fields of neurosurgery, psychiatry, and statistics and compared to existing similar articles.Results: The study found that the AI language model can create a highly convincing fraudulent article that resembled a genuine scientific paper in terms of word usage, sentence structure, and overall composition. The AI-generated article included standard sections such as introduction, material and methods, results, and discussion, as well a data sheet. It consisted of 1992 words and 17 citations, and the whole process of article creation took approximately 1 hour without any special training of the human user. However, there were some concerns and specific mistakes identified in the generated article, specifically in the references.Conclusions: The study demonstrates the potential of current AI language models to generate completely fabricated scientific articles. Although the papers look sophisticated and seemingly flawless, expert readers may identify semantic inaccuracies and errors upon closer inspection. We highlight the need for increased vigilance and better detection methods to combat the potential misuse of AI in scientific research. At the same time, it is important to recognize the potential benefits of using AI language models in genuine scientific writing and research, such as manuscript preparation and language editing.	[Majovsky, Martin; Cerny, Martin; Netuka, David] Charles Univ Prague, Fac Med 1, Dept Neurosurg & Neurooncol, Prague, Czech Republic; [Kasal, Mat Ej] Charles Univ Prague, Fac Med Pilsen, Dept Psychiat, Plzen, Czech Republic; [Komarc, Martin] Charles Univ Prague, Inst Biophys & Informat, Fac Med 1, Prague, Czech Republic; [Komarc, Martin] Charles Univ Prague, Fac Phys Educ & Sport, Dept Methodol, Prague, Czech Republic; [Majovsky, Martin] Charles Univ Prague, Fac Med 1, Dept Neurosurg & Neurooncol, Vojenske Nemocnice 1200, Prague 16000, Czech Republic	Charles University Prague; Charles University Prague; Charles University Prague; Charles University Prague; Charles University Prague	Májovsky, M (corresponding author), Charles Univ Prague, Fac Med 1, Dept Neurosurg & Neurooncol, Vojenske Nemocnice 1200, Prague 16000, Czech Republic.	majovmar@uvn.cz	Komarc, Martin/A-7308-2017; Černý, Martin/AHA-7099-2022; Majovsky, Martin/N-9262-2017; Komarc, Martin/O-2575-2019	Černý, Martin/0000-0002-8601-0554; Majovsky, Martin/0000-0001-7725-5181; Kasal, Matej/0000-0001-6445-8983; Komarc, Martin/0000-0003-4106-5217	Ministry of Defence of the Czech Republic [MO1012]; Cooperatio Neuroscience UK - Charles University	Ministry of Defence of the Czech Republic; Cooperatio Neuroscience UK - Charles University	This study was supported by the Ministry of Defence of the Czech Republic (grant MO1012) and Cooperatio Neuroscience UK, which was funded by Charles University. The funding sources had no impact on the study design, collection, analysis, and interpretation of data; on the writing of the article; or on the decision to submit the article for publication. We used the generative AI tool ChatGPT to draft a fabricated article and a review. The original ChatGPT transcripts are made available as Multimedia Appendices 1-2.	AI detector, CONT SCAL; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], OpenAI; Brown TB, 2020, 34 C NEURAL INFORM P; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; DALLE, OPENAI; Dathathri S, 2020, Arxiv, DOI arXiv:1912.02164; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Figee M, 2022, NEUROTHERAPEUTICS, V19, P1229, DOI 10.1007/s13311-022-01270-3; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Gaynes BN, 2020, DEPRESS ANXIETY, V37, P134, DOI 10.1002/da.22968; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Nato CG, 2022, J MED ETHICS, V48, P479, DOI 10.1136/medethics-2021-107252; Wu YL, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.655412	16	55	55	95	179	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAY 31	2023	25								e46924	10.2196/46924	http://dx.doi.org/10.2196/46924			8	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	L3FT3	37256685	gold, Green Published			2024-07-03	WOS:001022158000003
C	Pradeep, R; Lin, J		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Pradeep, Ronak; Lin, Jimmy			Towards Automated End-to-End Health Misinformation Free Search with a Large Language Model	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Neural Retrieval; Large Language Models; Misinformation		In the information age, health misinformation remains a notable challenge to public welfare. Integral to addressing this issue is the development of search systems adept at identifying and filtering out misleading content. This paper presents the automation of Vera, a state-of-the-art consumer health search system. While Vera can discern articles containing misinformation, it requires expert ground truth answers and rule-based reformulations. We introduce an answer prediction module that integrates GPT(x) with Vera and a GPT-based query reformulator to yield high-quality stance reformulations and boost downstream retrieval effectiveness. Further, we find that chain-of-thought reasoning is paramount to higher effectiveness. When assessed in the TREC Health Misinformation Track of 2022, our systems surpassed all competitors, including human-in-the-loop configurations, underscoring their pivotal role in the evolution towards a health misinformation-free search landscape. We provide all code necessary to reproduce our results at https://github.com/castorini/pygaggle.	[Pradeep, Ronak; Lin, Jimmy] Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON, Canada	University of Waterloo	Pradeep, R (corresponding author), Univ Waterloo, David R Cheriton Sch Comp Sci, Waterloo, ON, Canada.	rpradeep@uwaterloo.ca; jimmylin@uwaterloo.ca			Natural Sciences and Engineering Research Council (NSERC) of Canada	Natural Sciences and Engineering Research Council (NSERC) of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC))	This research was supported in part by the Natural Sciences and Engineering Research Council (NSERC) of Canada.	Bajaj P, 2018, Arxiv, DOI arXiv:1611.09268; Clarke Charles L. A., 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P185, DOI 10.1145/3409256.3409816; Clarke CLA, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P225, DOI 10.1145/3340531.3411915; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Nogueira R, 2020, Arxiv, DOI [arXiv:1901.04085, DOI 10.48550/ARXIV.1901.04085]; Nogueira R, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P708; Pradeep R, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2066, DOI 10.1145/3404835.3463120; Raffel C, 2020, J MACH LEARN RES, V21; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Wang X., 2023, 11 INT C LEARN REPR; Wei Jason, 2022, ADV NEURAL INFORM PR; Yang PL, 2018, ACM J DATA INF QUAL, V10, DOI 10.1145/3239571; Yang PL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1253, DOI 10.1145/3077136.3080721	13	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56065-1; 978-3-031-56066-8	LECT NOTES COMPUT SC			2024	14611						78	86		10.1007/978-3-031-56066-8_9	http://dx.doi.org/10.1007/978-3-031-56066-8_9			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9EA					2024-07-03	WOS:001211834200009
J	Siriwardhana, S; Gupta, C; Kaluarachchi, T; Dissanayake, V; Ellawela, S; Nanayakkara, S				Siriwardhana, Shamane; Gupta, Chitralekha; Kaluarachchi, Tharindu; Dissanayake, Vipula; Ellawela, Suveen; Nanayakkara, Suranga			Can AI Models Summarize Your Diary Entries? Investigating Utility of Abstractive Summarization for Autobiographical Text	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION			English	Article; Early Access						Self supervised learning; autobiographical text summarization; digital journaling		Journaling is a widely adopted technique, known to improve mental health and well-being by enabling reflection on past events. Large amounts of text in digital journaling applications could hinder the reflection process due to information overload. Abstractive summarization can solve this problem by generating short summaries to quickly glance at and reminisce. In this paper, we present an investigation of the utility of large language models in the context of autobiographical text summarization. We study two approaches to adapt a self -supervised learning (SSL) model to the domain of autobiographical text. One model employs transfer learning using our new autobiographical text summary dataset to fine-tune the SSL model. The second model leverages existing news datasets for high -quality text summarization mixed with our autobiographical summary dataset. We conducted mixed methods research to analyze the performance of these two models. Through objective evaluation using ROUGE and BART scores, we find that both these approaches perform significantly better than the SSL model fine-tuned with only high -quality news datasets, showing the importance of domain adaptation and autobiographical text summary dataset for this task. Secondly, through a subjective evaluation on a crowd -sourcing platform, we evaluated the summaries generated from these models on various quality criteria such as grammar, nonredundancy, structure, and coherence. We found that on all criteria, these summaries score >4 out of 5, and the two models show comparable results. We deployed a proof -of -concept webbased journaling application to assess the practical real -world implications of incorporating abstractive summarization in a digital journaling context. We found that the participants showed a high consensus that the summaries generated by the system captured the main idea of their journal entry (80% of the 75 participants gave a Likert scale rating of > 5:0 out of 7.0, with the overall mean rating of 5.56 +/- 1.32) while being factually correct, and they found it to be a useful feature of a journaling application. Finally, we conducted human evaluation studies to compare the quality of the summaries generated from a commercial tool ChatGPT and mixed distribution finetuned SSL model, and present insights into these systems in the context of autobiographical abstractive text summarization. We have made our model, dataset, and subjective evaluation questionnaire openly available to the research community.	[Siriwardhana, Shamane; Kaluarachchi, Tharindu; Dissanayake, Vipula; Nanayakkara, Suranga] Univ Auckland, Auckland Bioengn Inst, Augmented Human Lab, Auckland, New Zealand; [Gupta, Chitralekha; Ellawela, Suveen; Nanayakkara, Suranga] Natl Univ Singapore, Dept Informat Syst & Analyt, Augmented Human Lab, Singapore, Singapore	University of Auckland; National University of Singapore	Siriwardhana, S (corresponding author), Univ Auckland, Auckland Bioengn Inst, Augmented Human Lab, Auckland, New Zealand.	shamane@ahlab.org		Gupta, Chitralekha/0000-0003-1350-9095; NANAYAKKARA, SURANGA/0000-0001-7441-5493	Assistive Augmentation research	Assistive Augmentation research	We would like to acknowledge the participants who took part in our user studies.	Alqahtani F, 2019, ADJUNCT PUBLICATION OF THE 27TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (ACM UMAP '19 ADJUNCT), P343, DOI 10.1145/3314183.3323676; Ausman MC, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P533, DOI 10.1145/3306618.3314311; Ayobi A, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173602; Ayobi A, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6889, DOI 10.1145/3025453.3025869; Baecker AN, 2020, ACMIEEE INT CONF HUM, P122, DOI 10.1145/3371382.3378279; Balani S, 2015, P 33 ANN ACM C EXTEN, P1373, DOI DOI 10.1145/2702613.2732733; Bommasani R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8075; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bryant F. B., 2005, J HAPPINESS STUD, V6, P227, DOI [10.1007/s10902-005-3889-4, DOI 10.1007/S10902-005-3889-4]; Cachola I, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4766; Cao Z., 2018, Proc. AAAI Conference Artif. Intell, DOI [DOI 10.1609/AAAI.V32I1.11912, 10.1609/aaai.v32i1.11912]; Choudhury M. D., 2014, Proceedings of the eighth international conference on weblogs and social media, ICWSM 2014, ann arbor, michigan, usa, june 1-4, 2014; Dang HT, 2005, P DOC UND C, p1A12; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Durmus Esin., 2020, ACL, P5055, DOI 10.18653/v1/2020.acl-main.454; El Agroudy P, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1014, DOI 10.1145/2968219.2968562; Elsden C, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2819, DOI 10.1145/2858036.2858103; Esteva A, 2020, Arxiv, DOI arXiv:2006.09595; Ferdous MS, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P576, DOI 10.1145/2968219.2968324; Friend R, 2001, CONTEMP EDUC PSYCHOL, V26, P3, DOI 10.1006/ceps.1999.1022; GARNER R, 1985, CONTEMP EDUC PSYCHOL, V10, P139, DOI 10.1016/0361-476X(85)90014-1; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Gururangan Suchin, 2020, P 58 ANN M ASS COMP, P8342, DOI [DOI 10.18653/V1/2020.ACL, DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.aclmain.740, DOI 10.18653/V1/2020.ACLMAIN.740, 10.18653/v1/2020.acl]; Hannun A, 2014, Arxiv, DOI arXiv:1412.5567; Hermann KM, 2015, 29 ANN C NEURAL INFO, V28; Isaacs Ellen., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems -CHI'13, P1071, DOI [DOI 10.1145/2470654.2466137, 10.1145/2470654.2466137]; Iskender N., 2021, P WORKSHOP HUMAN EVA, P86; Johnson Alexandra., 2011, A Brief History of Diaries: From Pepys to Blogs; Kim B, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2519; Kim SI, 2019, INT CONF PER COMP, P169, DOI 10.1145/3329189.3329209; Kolesnikov A, 2019, PROC CVPR IEEE, P1920, DOI 10.1109/CVPR.2019.00202; Konečny J, 2017, Arxiv, DOI arXiv:1610.05492; Kornilova A., 2019, P 2 WORKSHOP NEW FRO, P48, DOI [DOI 10.18653/V1/D19-5406, DOI 10.18653/V1/D19-54065]; Kryscinski W, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1808; Kryscinski W, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9332; Kryscinski W, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P540; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li HY, 2018, BEHAV RES METHODS, V50, P2144, DOI 10.3758/s13428-017-0982-7; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Lin H, 2019, AAAI CONF ARTIF INTE, P9815; Lindstrom M., 2006, P HUM FACT COMP SYST, P1037; Liu Y, 2019, arXiv; Louis A, 2013, COMPUT LINGUIST, V39, P267, DOI 10.1162/COLI_a_00123; Manas G, 2021, JMIR MENT HEALTH, V8, DOI 10.2196/20865; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Muller R., 2019, Proceedings of the 33rd International Conference on Neural Information Processing Systems; Narain Jaya, 2020, CHI EA '20: Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI 10.1145/3334480.3383062; Narayan S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1797; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; Ott M, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P48; Ouyang J., 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, P46; Over P., 2003, DUC 2003. Workshop on Text Summarization; Paulus Romain, 2017, INT C LEARN REPR; Pereyra G., 2017, ICLR WORKSHOP; Petrelli D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1723; POTTHAST M., 2017, P WORKSHOP NEW FRONT, P59, DOI DOI 10.18653/V1/W17-4508; Qi WZ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2401; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Sanabria R., 2018, HOW2 LARGE SCALE DAT; Sawhney N, 2018, PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERACTION DESIGN AND CHILDREN (IDC 2018), P93, DOI 10.1145/3202185.3202752; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Sorapure M, 2015, BIOGRAPHY, V38, P267, DOI 10.1353/bio.2015.0011; Sotudeh S, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2682; Tan JW, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1171, DOI 10.18653/v1/P17-1108; Utley A, 2011, J CREAT MENT HEALTH, V6, P29, DOI 10.1080/15401383.2011.557312; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang Alex, 2020, P 58 ANN M ASS COMPU, P5008, DOI DOI 10.18653/V1/2020.ACL-MAIN.450; WINOGRAD PN, 1984, READ RES QUART, V19, P404, DOI 10.2307/747913; Wisniewski P, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3919, DOI 10.1145/2858036.2858317; Yang DY, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300261; Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981; Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836; You CW, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P242, DOI 10.1145/3341162.3343800; Yuan J., 2006, Interspeech; Yuan Weizhe, 2021, Advances in Neural Information Processing Systems; Zhang J., 2020, P 37 INT C MACHINE L	79	0	0	7	7	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	1044-7318	1532-7590		INT J HUM-COMPUT INT	Int. J. Hum.-Comput. Interact.	2023 NOV 29	2023										10.1080/10447318.2023.2286090	http://dx.doi.org/10.1080/10447318.2023.2286090		NOV 2023	19	Computer Science, Cybernetics; Ergonomics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Engineering	GP5Y7					2024-07-03	WOS:001153897100001
J	Müller-Franzes, G; Huck, L; Bode, M; Nebelung, S; Kuhl, C; Truhn, D; Lemainque, T				Mueller-Franzes, Gustav; Huck, Luisa; Bode, Maike; Nebelung, Sven; Kuhl, Christiane; Truhn, Daniel; Lemainque, Teresa			Diffusion probabilistic <i>versus</i> generative adversarial models to reduce contrast agent dose in breast MRI	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Artificial intelligence; Breast neoplasms; Contrast media; Machine learning; Magnetic resonance imaging	IMAGES; INTENSITY; BRAIN	Background To compare denoising diffusion probabilistic models (DDPM) and generative adversarial networks (GAN) for recovering contrast-enhanced breast magnetic resonance imaging (MRI) subtraction images from virtual low-dose subtraction images. Methods Retrospective, ethically approved study. DDPM- and GAN-reconstructed single-slice subtraction images of 50 breasts with enhancing lesions were compared to original ones at three dose levels (25%, 10%, 5%) using quantitative measures and radiologic evaluations. Two radiologists stated their preference based on the reconstruction quality and scored the lesion conspicuity as compared to the original, blinded to the model. Fifty lesion-free maximum intensity projections were evaluated for the presence of false-positives. Results were compared between models and dose levels, using generalized linear mixed models. Results At 5% dose, both radiologists preferred the GAN-generated images, whereas at 25% dose, both radiologists preferred the DDPM-generated images. Median lesion conspicuity scores did not differ between GAN and DDPM at 25% dose (5 versus 5, p = 1.000) and 10% dose (4 versus 4, p = 1.000). At 5% dose, both readers assigned higher conspicuity to the GAN than to the DDPM (3 versus 2, p = 0.007). In the lesion-free examinations, DDPM and GAN showed no differences in the false-positive rate at 5% (15% versus 22%), 10% (10% versus 6%), and 25% (6% versus 4%) (p = 1.000). Conclusions Both GAN and DDPM yielded promising results in low-dose image reconstruction. However, neither of them showed superior results over the other model for all dose levels and evaluation metrics. Further development is needed to counteract false-positives. Relevance statement For MRI-based breast cancer screening, reducing the contrast agent dose is desirable. Diffusion probabilistic models and generative adversarial networks were capable of retrospectively enhancing the signal of low-dose images. Hence, they may supplement imaging with reduced doses in the future.	[Mueller-Franzes, Gustav; Huck, Luisa; Bode, Maike; Nebelung, Sven; Kuhl, Christiane; Truhn, Daniel; Lemainque, Teresa] Rhein Westfal TH Aachen, Med Fac, Dept Diagnost & Intervent Radiol, Aachen, Germany	RWTH Aachen University	Lemainque, T (corresponding author), Rhein Westfal TH Aachen, Med Fac, Dept Diagnost & Intervent Radiol, Aachen, Germany.	tlemainque@ukaachen.de	Truhn, Daniel/AAG-9359-2021; Lemainque, Teresa/ABA-3070-2020	Truhn, Daniel/0000-0002-9605-0728; Lemainque, Teresa/0000-0003-3167-7121	European Society of Radiology in collaboration with the European Institute for Biomedical Imaging Research	European Society of Radiology in collaboration with the European Institute for Biomedical Imaging Research	No large language models (LLMs) were used for this manuscript.	Akai H, 2021, RADIOLOGY, V301, P409, DOI 10.1148/radiol.2021210892; Brünjes R, 2020, WATER RES, V182, DOI 10.1016/j.watres.2020.115966; Chung MG, 2023, RADIOLOGY, V306, DOI 10.1148/radiol.213199; Costelloe CM, 2020, SEMIN ULTRASOUND CT, V41, P170, DOI 10.1053/j.sult.2019.12.005; Gong E, 2018, J MAGN RESON IMAGING, V48, P330, DOI 10.1002/jmri.25970; Haase R, 2023, INVEST RADIOL, V58, P420, DOI 10.1097/RLI.0000000000000955; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ho JAT, 2020, Arxiv, DOI [arXiv:2006.11239, DOI 10.48550/ARXIV.2006.11239]; Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632; Kingma D. P., 2017, ARXIV; Kuhl C, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.222612; Kuhl CK, 2017, RADIOLOGY, V283, P361, DOI 10.1148/radiol.2016161444; Kuhl CK, 2014, J CLIN ONCOL, V32, P2304, DOI 10.1200/JCO.2013.52.5386; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Luo HY, 2021, EUR RADIOL, V31, P6419, DOI 10.1007/s00330-021-07848-3; Mann RM, 2022, EUR RADIOL, V32, P4036, DOI 10.1007/s00330-022-08617-6; Mason A, 2020, IEEE T MED IMAGING, V39, P1064, DOI 10.1109/TMI.2019.2930338; Melsaether AN, 2019, CLIN IMAG, V58, P84, DOI 10.1016/j.clinimag.2019.06.014; Morris EA, 2007, RADIOL CLIN N AM, V45, P863, DOI 10.1016/j.rcl.2007.07.002; Muller-Franzes Gustav, 2023, Radiology, V307, pe222211, DOI 10.1148/radiol.222211; Nichol A, 2021, Arxiv, DOI [arXiv:2102.09672, 10.48550/arXiv.2102.09672]; Pasumarthi S, 2021, MAGN RESON MED, V86, P1687, DOI 10.1002/mrm.28808; Pineda F, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190302; project, R: Bonferroni correction; Ramalho J, 2015, RADIOLOGY, V276, P836, DOI 10.1148/radiol.2015150872; van der Molen AJ, 2024, EUR RADIOL, V34, P600, DOI 10.1007/s00330-023-10281-3; Wang PP, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.792516; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917; Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861; Zhang RC, 2018, Arxiv, DOI [arXiv:1801.03924, 10.48550/arXiv.1801.03924, DOI 10.48550/ARXIV.1801.03924]	30	0	0	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	MAY 1	2024	8	1							53	10.1186/s41747-024-00451-3	http://dx.doi.org/10.1186/s41747-024-00451-3			13	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	PB0F1	38689178				2024-07-03	WOS:001211495600001
C	Harrison, RM; Dereventsov, A; Bibin, A		Pedrycz, W; Wang, J; He, Y; Dinh, TN; Grant, C; Qiu, M		Harrison, Rachel M.; Dereventsov, Anton; Bibin, Anton			Zero-Shot Recommendations with Pre-Trained Large Language Models for Multimodal Nudging	2023 23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW 2023	International Conference on Data Mining Workshops		English	Proceedings Paper	23rd IEEE International Conference on Data Mining (IEEE ICDM)	DEC 01-04, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, US National Science Foundation, Technology Innovation Institute, TWO SIGMA		zero-shot learning; large language models; GPT; nudging; personalization; multimodal recommendation	ASSOCIATIONS; BEHAVIORS; TIME	We present a method for zero-shot recommendation of multimodal non-stationary content that leverages recent advancements in the field of generative AI. We propose rendering inputs of different modalities as textual descriptions and to utilize pre-trained LLMs to obtain their numerical representations by computing semantic embeddings. Once unified representations of all content items are obtained, the recommendation can be performed by computing an appropriate similarity metric between them without any additional learning. We demonstrate our approach on a synthetic multimodal nudging environment, where the inputs consist of tabular, textual, and visual data.	[Harrison, Rachel M.] Behav Design Lirio LLC, Knoxville, TN USA; [Dereventsov, Anton] Lirio AI Res Lirio LLC, Knoxville, TN USA; [Bibin, Anton] Skoltech Agro, Skoltech, Moscow, Russia		Harrison, RM (corresponding author), Behav Design Lirio LLC, Knoxville, TN USA.	rharrison@lirio.com; adereventsov@lirio.com; a.bibin@skoltech.ru						Dalecke Sandor, 2020, WIMS 2020: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics, P139, DOI 10.1145/3405962.3405975; Davies CA, 2012, PREV MED, V55, P46, DOI 10.1016/j.ypmed.2012.05.003; de Wit L, 2011, PSYCHIAT RES, V186, P239, DOI 10.1016/j.psychres.2010.07.003; Dereventsov A., 2022, 2022 IEEE INT C DAT, P1; Dereventsov A, 2021, INT CONF DAT MIN WOR, P742, DOI 10.1109/ICDMW53433.2021.00097; Ding H., 2021, arXiv; el Hassouni Ali, 2018, PRIMA 2018: Principles and Practice of Multi-Agent Systems. 21st International Conference. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11224), P467, DOI 10.1007/978-3-030-03098-8_31; Penedo JMG, 2022, PSYCHOTHER RES, V32, P151, DOI [10.1080/10503307.2021.1930242, 10.1109/IAS/PCA50164.2021.10143786]; Hamer M, 2013, BRAIN BEHAV IMMUN, V33, P29, DOI 10.1016/j.bbi.2013.05.001; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hoyt GM, 2009, INT REV ECON EDUC, V8, P158, DOI 10.1016/S1477-3880(15)30073-6; Hu FB, 2003, JAMA-J AM MED ASSOC, V289, P1785, DOI 10.1001/jama.289.14.1785; Ie E, 2019, Arxiv, DOI arXiv:1909.04847; Jesse M, 2021, COMPUT HUM BEHAV REP, V3, DOI 10.1016/j.chbr.2020.100052; Karlsen R, 2019, TECHNOLOGIES, V7, DOI 10.3390/technologies7020045; Kemp S., 2022, DataReportal-Global Digital Insights; Lex E, 2021, FOUND TRENDS INF RET, V15, P134, DOI 10.1561/1500000090; Li JJ, 2019, AAAI CONF ARTIF INTE, P4189; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Lin JH, 2024, Arxiv, DOI arXiv:2306.05817; Liu QD, 2023, Arxiv, DOI arXiv:2302.03883; Madhav K C, 2017, Prev Med Rep, V8, P67, DOI 10.1016/j.pmedr.2017.08.005; Middleton KR, 2013, AM J LIFESTYLE MED, V7, P395, DOI 10.1177/1559827613488867; Nabizadeh AH, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113596; Portugal I, 2018, EXPERT SYST APPL, V97, P205, DOI 10.1016/j.eswa.2017.12.020; Pourpanah F, 2023, IEEE T PATTERN ANAL, V45, P4051, DOI 10.1109/TPAMI.2022.3191696; Truong QT, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1864, DOI 10.1145/3308558.3313463; Rohde D, 2018, Arxiv, DOI arXiv:1808.00720; Salah A, 2020, J MACH LEARN RES, V21; Shmakov AV, 2021, J INST STUD, V13, P102, DOI 10.17835/2076-6297.2021.13.3.102-116; Su X. Y., 2009, ADV ARTIF INTELL, V2009, DOI DOI 10.1155/2009/421425; Sutton RS, 2018, ADAPT COMPUT MACH LE, P1; Twenge JM, 2019, CURR DIR PSYCHOL SCI, V28, P372, DOI 10.1177/0963721419838244; Vlaev I, 2016, PUBLIC ADMIN REV, V76, P550, DOI 10.1111/puar.12564; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang W, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3293318; Wu Chuhan, 2021, arXiv; Zhao ZH, 2024, Arxiv, DOI arXiv:2307.02046; Zhou HY, 2023, Arxiv, DOI arXiv:2302.04473; Zhu FY, 2018, ACM-BCB'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, P492, DOI 10.1145/3233547.3233553	40	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2375-9232		979-8-3503-8164-1	INT CONF DAT MIN WOR			2023							1535	1542		10.1109/ICDMW60847.2023.00195	http://dx.doi.org/10.1109/ICDMW60847.2023.00195			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5OA		Green Submitted			2024-07-03	WOS:001164077500186
J	Jin, XX; Mao, CY; Yue, DF; Leng, T				Jin, Xiaoxiao; Mao, Chenyang; Yue, Dengfeng; Leng, Tuo			Floating-Point Embedding: Enhancing the Mathematical Comprehension of Large Language Models	SYMMETRY-BASEL			English	Article						floating-point embedding; large language model; numerical semantics		The processing and comprehension of numerical information in natural language represent pivotal focal points of scholarly inquiry. Across diverse applications spanning text analysis to information retrieval, the adept management and understanding of the numerical content within natural language are indispensable in achieving task success. Specialized encoding and embedding techniques tailored to numerical data offer an avenue toward improved performance in tasks involving masked prediction and numerical reasoning, inherently characterized by numerical values. Consequently, treating numbers in text merely as words is inadequate; their numerical semantics must be underscored. Recent years have witnessed the emergence of a range of specific encoding methodologies designed explicitly for numerical content, demonstrating promising outcomes. We observe similarities between the Transformer architecture and CPU architecture, with symmetry playing a crucial role. In light of this observation and drawing inspiration from computer system theory, we introduce a floating-point representation and devise a corresponding embedding module. The numerical representations correspond one-to-one with their semantic vector values, rendering both symmetric regarding intermediate transformation methods. Our proposed methodology facilitates the more comprehensive encoding and embedding of numerical information within a predefined precision range, thereby ensuring a distinctive encoding representation for each numerical entity. Rigorous testing on multiple encoder-only models and datasets yielded results that stand out in terms of competitiveness. In comparison to the default embedding methods employed by models, our approach achieved an improvement of approximately 3.8% in Top-1 accuracy and a reduction in perplexity of approximately 0.43. These outcomes affirm the efficacy of our proposed method. Furthermore, the enrichment of numerical semantics through a more comprehensive embedding contributes to the augmentation of the model's capacity for semantic understanding.	[Jin, Xiaoxiao; Mao, Chenyang; Yue, Dengfeng; Leng, Tuo] Shanghai Univ, Dept Comp Engn & Sci, Shanghai 200444, Peoples R China	Shanghai University	Leng, T (corresponding author), Shanghai Univ, Dept Comp Engn & Sci, Shanghai 200444, Peoples R China.	jxxxx6@shu.edu.cn; shadymao@shu.edu.cn; ydf@shu.edu.cn; tleng@shu.edu.cn	Jin, Xiaoxiao/KJL-1348-2024; Leng, Tuo/JXN-7304-2024	Jin, Xiaoxiao/0009-0006-0776-0346; Leng, Tuo/0000-0002-2921-3291	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	The authors are grateful to the reviewers for their valuable suggestions and comments.	Bryant R.E., 2011, Computer Systems: A Programmer's Perspective, P37; Chaudhuri P.P., 2008, Computer Organization and Design, P138; Chen CC, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6307; Cheng J, 2024, BIOENGINEERING-BASEL, V11, DOI 10.3390/bioengineering11040342; Chow J.C., 2024, BioMedInformatics, V4, P837, DOI [10.3390/biomedinformatics4010047, DOI 10.3390/BIOMEDINFORMATICS4010047]; Corcoran P, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156896; Devlin J., 2018, BERT PRE TRAINING DE; Doval Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196893; Feng G., 2024, Adv. Neural Inf. Process. Syst, V36, DOI [10.48550/arXiv.2305.15408, DOI 10.48550/ARXIV.2305.15408]; GOLDBERG D, 1991, COMPUT SURV, V23, P5, DOI 10.1145/103162.103163; Gorishniy Y., 2022, Advances in Neural Information Processing Systems, V35, P24991; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hennessy J.L., 2011, Computer Architecture: A Quantitative Approach, P2; Hough DG, 2019, COMPUTER, V52, P109, DOI 10.1109/MC.2019.2926614; Jiang CY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2586; Jin Z., 2023, P INT S LARGE LANGUA; Kahan W., 1996, Lecture Notes on the Status of IEEE 754, 94720-1776, V754, P11; Li LY, 2017, ALGORITHMS, V10, DOI 10.3390/a10020059; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ortiz-Zambrano JA, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010120; Patil R, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14052074; Radford A., 2018, Improving language understanding by generative pre-trainingJ; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Spithourakis GP, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2104; Spokoyny D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4754; Sundararaman D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4742; Thawani A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P644; Thawani A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6960; Vaswani A, 2017, ADV NEUR IN, V30; Volpi R, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030287; Wallace E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5307; Wang X., 2022, P 11 INT C LEARNING; Wei JS, 2022, ADV NEUR IN; Zhang XK, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4889	35	0	0	5	5	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2073-8994		SYMMETRY-BASEL	Symmetry-Basel	APR	2024	16	4							478	10.3390/sym16040478	http://dx.doi.org/10.3390/sym16040478			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	OW9Z4		gold			2024-07-03	WOS:001210446400001
J	Yan, YQ; Zheng, P; Wang, YJ				Yan, Yeqing; Zheng, Peng; Wang, Yongjun			Enhancing large language model capabilities for rumor detection with Knowledge-Powered Prompting	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Social networks; Rumor detection; Knowledge augmentation; Prompt tuning; Large language model		Amid the proliferation of misinformation on social networks, automated rumor detection has emerged as a pivotal and pressing research domain. Nonetheless, current methodologies are hindered by constrained feature representations and limited adaptability in effectively addressing diverse and unconventional rumors. The incorporation of large-scale language models holds the promise of delivering heightened semantic comprehension and broader adaptability. Regrettably, prevailing general-purpose prompting approaches frequently fall short in furnishing adequate domain -specific context and guidance, thereby restricting their utility in the context of rumor detection. To ameliorate these concerns, we introduce the Knowledge -Powered Prompting strategy, which imparts task -relevant prompts and context to the model by amalgamating domain expertise with large-scale language models. This fusion equips the model to better align with the exigencies of rumor detection, mitigating the challenges posed by sensitivity to semantic subtleties and a paucity of training samples. In particular, we devise exploration prompts and bolster the prompt representation with a dynamic knowledge injection module, thereby facilitating profound reasoning about pivotal entities. Subsequently, we extract valuable external knowledge through the filtration of interactions between knowledge and claim, thereby diminishing the impact of noise. Concurrently, we undertake joint optimization, encompassing multitask prompt population and categorical judgment objectives, fostering synergistic semantic modeling and discriminative assessments. Empirical evaluations reveal that our methodology substantially outperforms existing models.	[Yan, Yeqing; Zheng, Peng; Wang, Yongjun] Natl Univ Def Technol, Sch Comp Sci, Changsha 410003, Hunan, Peoples R China	National University of Defense Technology - China	Wang, YJ (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410003, Hunan, Peoples R China.	wangyongjun@nudt.edu.cn		YAN, Yeqing/0000-0003-4045-7251	National Natural Science Foundation of China [61902415, 61472439]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgments</B> This work is supported by the National Natural Science Foundation of China (No. 61902415 and No. 61472439) .	Alaparthi S, 2020, Arxiv, DOI arXiv:2007.01127; Alsaif HF, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105801; Bian T, 2020, AAAI CONF ARTIF INTE, V34, P549; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai YX, 2020, 2020 2ND CONFERENCE ON BLOCKCHAIN RESEARCH & APPLICATIONS FOR INNOVATIVE NETWORKS AND SERVICES (BRAINS), P128, DOI [10.1109/BRAINS49436.2020.9223272, 10.1109/brains49436.2020.9223272]; Castillo C, 2011, 20 INT C WORLD WIDE, P675, DOI 10.1145/1963405.1963500; Chai YH, 2023, IEEE T KNOWL DATA EN, V35, P4754, DOI 10.1109/TKDE.2022.3142820; Chen T, 2018, LECT NOTES ARTIF INT, V11154, P40, DOI 10.1007/978-3-030-04503-6_4; Chen XQ, 2022, KNOWL-BASED SYST, V240, DOI 10.1016/j.knosys.2021.108085; Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Goldberg Y, 2014, Arxiv, DOI arXiv:1402.3722; He ZY, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2020, DOI 10.1145/3404835.3463001; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Hu ZN, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1857, DOI 10.1145/3394486.3403237; Jiang GY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103029; Jiang Y, 2023, arXiv; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; Kim Y, 2014, P 2014 C EMP METH NA, V2014, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/d14-1181]; Lagler K, 2013, GEOPHYS RES LETT, V40, P1069, DOI 10.1002/grl.50288; Liu XY, 2023, IEEE T COMPUT SOC SY, V10, P2350, DOI 10.1109/TCSS.2022.3184745; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Ma J, 2015, P 24 ACM INT C INF K, P1751, DOI DOI 10.1145/2806416.2806607; Ma J, 2016, P 25 INT JOINT C ART, P3818; Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741; Marreddy M, 2022, IEEE IJCNN, DOI 10.1109/IJCNN55064.2022.9892105; Martín AG, 2021, ENG APPL ARTIF INTEL, V101, DOI 10.1016/j.engappai.2021.104230; Ni SW, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176652; Peng YF, 2019, Arxiv, DOI arXiv:1906.05474; Praseed A, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105731; Ren YT, 2023, IEEE T KNOWL DATA EN, V35, P5695, DOI 10.1109/TKDE.2022.3175719; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sha Ying, 2023, Database Systems for Advanced Applications: 28th International Conference, DASFAA 2023, Proceedings. Lecture Notes in Computer Science (13945), P682, DOI 10.1007/978-3-031-30675-4_50; Shaheen Z, 2020, Arxiv, DOI [arXiv:2010.12871, 10.48550/arXiv.2010.12871]; Shu K, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P395, DOI 10.1145/3292500.3330935; Soyalp Gokhan, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P707, DOI 10.1109/UBMK52708.2021.9558906; Sun MZ, 2022, AAAI CONF ARTIF INTE, P4611; Sun TN, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2789, DOI 10.1145/3485447.3511999; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Wu LW, 2023, IEEE T KNOWL DATA EN, V35, P1242, DOI 10.1109/TKDE.2021.3103833; Xiang TC, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103337; Xu S., 2021, PRICAI 2021 TRENDS A, P205; Yan YQ, 2023, NEUROCOMPUTING, V552, DOI 10.1016/j.neucom.2023.126548; Yan YQ, 2023, ENG APPL ARTIF INTEL, V118, DOI 10.1016/j.engappai.2022.105613; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yao L, 2019, AAAI CONF ARTIF INTE, P7370; Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901; Yuan MJ, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P184, DOI 10.1145/3543873.3587343; Zeng H, 2022, ENG APPL ARTIF INTEL, V110, DOI 10.1016/j.engappai.2022.104757; Zheng P., 2023, ICASSP 2023 2023 IEE, P1; Zheng P, 2023, INFORM SCIENCES, V642, DOI 10.1016/j.ins.2023.119083; Zhou YH, 2023, IEEE T SUST COMPUT, V8, P627, DOI 10.1109/TSUSC.2023.3240411; Zhuang Liu, 2021, Chinese Computational Linguistics: 20th China National Conference, CCL 2021, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (12869), P471, DOI 10.1007/978-3-030-84186-7_31; Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603	55	0	0	13	13	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUL	2024	133		C						108259	10.1016/j.engappai.2024.108259	http://dx.doi.org/10.1016/j.engappai.2024.108259		MAR 2024	13	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science; Engineering	QF0K2					2024-07-03	WOS:001219343800001
J	Seagraves, P				Seagraves, Philip			Real Estate Insights The clash of politics and economics in the UK property market-the case of leaseholds	JOURNAL OF PROPERTY INVESTMENT & FINANCE			English	Article						Leasehold system; Housing market; Consumer behaviour; Market function; Legislation and regulation; Legal title		PurposeThe aim of this Real Estate Insight is to comment upon the UK leasehold system, particularly focussing on new-build homes. This paper sheds light on the controversy surrounding this practice, public perception and the impact of a proposed ban on the housing and the impact, thereof, on property investment.Design/methodology/approachThis Real Estate Insight, through the lens of investment principles, dissects the rationale behind the initial pricing in the leasehold system and how potential future costs and benefits shape this mechanism. The nature of the "Insights" briefings means that this is a personal view of the author.FindingsWith the recent outcry over perceived unfair practices, the paper scrutinises whether the problem lies within the system itself or in the consumers' comprehension of the system. This paper suggests that enhancing consumer education and imposing stricter disclosure requirements might serve as a more effective solution than outright legislative prohibitions.Practical implicationsThe paper also briefly touches upon the concept of "gouging" in market function, highlighting potential inconsistencies in consumer behaviour.Originality/valueThis is a review of the UK leasehold market in relation to the legal title being offered at purchase.	[Seagraves, Philip] Middle Tennessee State Univ, Dept Econ & Finance, Murfreesboro, TN 37132 USA	Middle Tennessee State University	Seagraves, P (corresponding author), Middle Tennessee State Univ, Dept Econ & Finance, Murfreesboro, TN 37132 USA.	Philip.Seagraves@mtsu.edu		Seagraves, Philip/0000-0002-9280-0712	The completion of this Real Estate Insight has been made possible through the utilisation of a diverse array of editorial tools, grammar and spelling checkers, artificial intelligence (AI) technologies, large language models and the invaluable assistance o	The completion of this Real Estate Insight has been made possible through the utilisation of a diverse array of editorial tools, grammar and spelling checkers, artificial intelligence (AI) technologies, large language models and the invaluable assistance o	The completion of this Real Estate Insight has been made possible through the utilisation of a diverse array of editorial tools, grammar and spelling checkers, artificial intelligence (AI) technologies, large language models and the invaluable assistance of human writers, proof readers and editors. These resources have played a significant role in refining and enhancing the quality of the work presented here.	Bracke P, 2018, ECON J, V128, P1820, DOI 10.1111/ecoj.12501; Camilla C., 2019, VICTORY FUTURE HOMEO; Harding A, 2018, HOUS CARE SUPPORT, V21, P41, DOI 10.1108/HCS-05-2018-0006; Mayes C., 2023, IS ABOLITION LEASEHO	4	0	0	1	1	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1463-578X	1470-2002		J PROP INVEST FINANC	J. Prop. Invest. Finance	NOV 16	2023	41	6					629	635		10.1108/JPIF-07-2023-0072	http://dx.doi.org/10.1108/JPIF-07-2023-0072		SEP 2023	7	Business, Finance	Emerging Sources Citation Index (ESCI)	Business & Economics	Y4QO1					2024-07-03	WOS:001072404700001
J	Iqbal, U; Lee, LTJ; Rahmanti, AR; Celi, LA; Li, YCJ				Iqbal, Usman; Lee, Leon Tsung-Ju; Rahmanti, Annisa Ristya; Celi, Leo Anthony; Li, Yu-Chuan Jack			Can large language models provide secondary reliable opinion on treatment options for dermatological diseases?	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						ChatGPT; decision-making support; artificial intelligence; dermatology; large language model; second opinion; medication		Objective To investigate the consistency and reliability of medication recommendations provided by ChatGPT for common dermatological conditions, highlighting the potential for ChatGPT to offer second opinions in patient treatment while also delineating possible limitations.Materials and Methods In this mixed-methods study, we used survey questions in April 2023 for drug recommendations generated by ChatGPT with data from secondary databases, that is, Taiwan's National Health Insurance Research Database and an US medical center database, and validated by dermatologists. The methodology included preprocessing queries, executing them multiple times, and evaluating ChatGPT responses against the databases and dermatologists. The ChatGPT-generated responses were analyzed statistically in a disease-drug matrix, considering disease-medication associations (Q-value) and expert evaluation.Results ChatGPT achieved a high 98.87% dermatologist approval rate for common dermatological medication recommendations. We evaluated its drug suggestions using the Q-value, showing that human expert validation agreement surpassed Q-value cutoff-based agreement. Varying cutoff values for disease-medication associations, a cutoff of 3 achieved 95.14% accurate prescriptions, 5 yielded 85.42%, and 10 resulted in 72.92%. While ChatGPT offered accurate drug advice, it occasionally included incorrect ATC codes, leading to issues like incorrect drug use and type, nonexistent codes, repeated errors, and incomplete medication codes.Conclusion ChatGPT provides medication recommendations as a second opinion in dermatology treatment, but its reliability and comprehensiveness need refinement for greater accuracy. In the future, integrating a medical domain-specific knowledge base for training and ongoing optimization will enhance the precision of ChatGPT's results.	[Iqbal, Usman] Univ New South Wales UNSW, Fac Med & Hlth, Sch Populat Hlth, Sydney, NSW 2052, Australia; [Iqbal, Usman] Dept Hlth, Hobart, Tas 7000, Australia; [Iqbal, Usman] Taipei Med Univ, Coll Publ Hlth, Global Hlth & Hlth Secur Dept, Taipei 110, Taiwan; [Lee, Leon Tsung-Ju] Taipei Med Univ, Grad Inst Clin Med, Taipei 110, Taiwan; [Lee, Leon Tsung-Ju; Li, Yu-Chuan Jack] Taipei Med Univ, Taipei Med Univ Hosp, Dept Dermatol, 250 Wuxing St, Taipei 110, Taiwan; [Lee, Leon Tsung-Ju] Taipei Med Univ, Coll Med, Sch Med, Dept Dermatol, Taipei 110, Taiwan; [Rahmanti, Annisa Ristya; Li, Yu-Chuan Jack] Taipei Med Univ, Grad Inst Biomed Informat, Coll Med Sci & Technol, 250 Wuxing St, Taipei 110, Taiwan; [Rahmanti, Annisa Ristya; Li, Yu-Chuan Jack] Taipei Med Univ, Coll Med Sci & Technol, Int Ctr Hlth Informat & Technol, Taipei 110, Taiwan; [Rahmanti, Annisa Ristya] Univ Gadjah Mada, Fac Med Publ Hlth & Nursing, Dept Hlth Policy & Management, Yogyakarta 55281, Indonesia; [Celi, Leo Anthony] MIT, Lab Computat Physiol, Cambridge, MA 02139 USA; [Celi, Leo Anthony] Beth Israel Deaconess Med Ctr, Div Pulm Crit Care & Sleep Med, Boston, MA 02215 USA; [Celi, Leo Anthony] Harvard TH Chan Sch Publ Hlth, Dept Biostat, Boston, MA 02115 USA; [Li, Yu-Chuan Jack] Taipei Med Univ, Taipei Municipal Wanfang Hosp, Dept Dermatol, Taipei 116, Taiwan; [Li, Yu-Chuan Jack] Int Med Informat Assoc IMIA, CH-1204 Geneva, Switzerland	University of New South Wales Sydney; Taipei Medical University; Taipei Medical University; Taipei Medical University; Taipei Medical University Hospital; Taipei Medical University; Taipei Medical University; Taipei Medical University; Gadjah Mada University; Massachusetts Institute of Technology (MIT); Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Harvard T.H. Chan School of Public Health; Taipei Municipal WanFang Hospital; Taipei Medical University	Li, YCJ (corresponding author), Taipei Med Univ, Taipei Med Univ Hosp, Dept Dermatol, 250 Wuxing St, Taipei 110, Taiwan.; Li, YCJ (corresponding author), Taipei Med Univ, Grad Inst Biomed Informat, Coll Med Sci & Technol, 250 Wuxing St, Taipei 110, Taiwan.	jack@tmu.edu.tw		Iqbal, Usman/0000-0002-0614-123X	National Science and Technology Council, Taiwan [NSTC 112-2321-B-038-006, 112- 2410-H-038-015-MY2]; Higher Education Sprout Project by the Ministry of Edu-cation (MOE), Taiwan [MOE DP2-TMU-112-A-04]	National Science and Technology Council, Taiwan; Higher Education Sprout Project by the Ministry of Edu-cation (MOE), Taiwan	This work was supported by National Science and Technology Council, Taiwan (NSTC 112-2321-B-038-006), (112- 2410-H-038-015-MY2) and the Higher Education Sprout Project (MOE DP2-TMU-112-A-04) by the Ministry of Edu-cation (MOE), Taiwan.	Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Ferrara E, 2023, 1 MONDAY, DOI [10.5210/fm.v28i11.13346, DOI 10.5210/FM.V28I11.13346]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Kluger N, 2023, J EUR ACAD DERMATOL, V37, pE941, DOI 10.1111/jdv.19152; Lahat A, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13111950; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Nguyen PA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0082401; Scherr R, 2023, JMIR MED EDUC, V9, DOI 10.2196/49877; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang CH, 2021, COMPUT METH PROG BIO, V207, DOI 10.1016/j.cmpb.2021.106181; Zack T., 2023, MEDRXIV, DOI [10.1101/2023.07.13.23292577,2023, DOI 10.1101/2023.07.13.23292577,2023]	24	1	1	3	3	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1341	1347		10.1093/jamia/ocae067	http://dx.doi.org/10.1093/jamia/ocae067		APR 2024	7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38578616				2024-07-03	WOS:001197188000001
J	Marshall, RF; Mallem, K; Xu, HN; Thorne, J; Burkholder, B; Chaon, B; Liberman, P; Berkenstock, M				Marshall, Rayna F.; Mallem, Krishna; Xu, Hannah; Thorne, Jennifer; Burkholder, Bryn; Chaon, Benjamin; Liberman, Paulina; Berkenstock, Meghan			Investigating the Accuracy and Completeness of an Artificial Intelligence Large Language Model About Uveitis: An Evaluation of ChatGPT	OCULAR IMMUNOLOGY AND INFLAMMATION			English	Article; Early Access						Artificial intelligence; ChatGPT; large language model; ophthalmology; uveitis		PurposeTo assess the accuracy and completeness of ChatGPT-generated answers regarding uveitis description, prevention, treatment, and prognosis.MethodsThirty-two uveitis-related questions were generated by a uveitis specialist and inputted into ChatGPT 3.5. Answers were compiled into a survey and were reviewed by five uveitis specialists using standardized Likert scales of accuracy and completeness.ResultsIn total, the median accuracy score for all the uveitis questions (n = 32) was 4.00 (between "more correct than incorrect" and "nearly all correct"), and the median completeness score was 2.00 ("adequate, addresses all aspects of the question and provides the minimum amount of information required to be considered complete"). The interrater variability assessment had a total kappa value of 0.0278 for accuracy and 0.0847 for completeness.ConclusionChatGPT can provide relatively high accuracy responses for various questions related to uveitis; however, the answers it provides are incomplete, with some inaccuracies. Its utility in providing medical information requires further validation and development prior to serving as a source of uveitis information for patients.	[Marshall, Rayna F.; Mallem, Krishna] Drexel Univ, Coll Med, Philadelphia, PA USA; [Xu, Hannah] Univ Calif San Diego, San Diego, CA USA; [Thorne, Jennifer; Burkholder, Bryn; Chaon, Benjamin; Liberman, Paulina; Berkenstock, Meghan] Johns Hopkins Univ, Wilmer Eye Inst, Div Ocular Immunol, Sch Med, Baltimore, MD USA; [Berkenstock, Meghan] Wilmer Eye Inst, Div Ocular Immunol, 600 N Wolfe St Maumenee 3rd floor, Baltimore, MD 21287 USA	Drexel University; University of California System; University of California San Diego; Johns Hopkins University; Johns Hopkins Medicine; Johns Hopkins University; Johns Hopkins Medicine	Berkenstock, M (corresponding author), Wilmer Eye Inst, Div Ocular Immunol, 600 N Wolfe St Maumenee 3rd floor, Baltimore, MD 21287 USA.	mberken2@jhmi.edu		Marshall, Rayna/0000-0002-6961-1278; Liberman, Paulina/0000-0002-1053-8651				Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gravel J., 2023, Mayo Clin Proc Digit Health, V1, P226, DOI [DOI 10.1016/J.MCPDIG.2023.05.004, 10.1016/j.mcpdig.2023.05.004]; Jacquot R, 2023, J CLIN MED, V12, DOI 10.3390/jcm12113746; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kras A, 2020, CURR OPIN OPHTHALMOL, V31, P337, DOI 10.1097/ICU.0000000000000678; Mallem K, 2023, OCUL IMMUNOL INFLAMM, DOI 10.1080/09273948.2023.2202249; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P798, DOI 10.1001/jamaophthalmol.2023.2754; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Ming CTY, 2023, OCUL IMMUNOL INFLAMM, DOI 10.1080/09273948.2023.2242462; Moshirfar M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40822; Nakayama LF, 2023, SURV OPHTHALMOL, V68, P669, DOI 10.1016/j.survophthal.2023.02.007; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Thorne JE, 2016, JAMA OPHTHALMOL, V134, P1237, DOI 10.1001/jamaophthalmol.2016.3229; Ting DSJ, 2024, EYE, V38, P4, DOI 10.1038/s41433-023-02619-4; Wang GY, 2023, J MED INTERNET RES, V25, DOI 10.2196/49771	18	0	0	2	2	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0927-3948	1744-5078		OCUL IMMUNOL INFLAMM	Ocul. Immunol. Inflamm.	2024 FEB 18	2024										10.1080/09273948.2024.2317417	http://dx.doi.org/10.1080/09273948.2024.2317417		FEB 2024	4	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	IS1H5	38394625				2024-07-03	WOS:001168224600001
C	Quintana, F; Treangen, TJ; Kavraki, LE			ACM	Quintana, Felix; Treangen, Todd J.; Kavraki, Lydia E.			Leveraging Large Language Models for Predicting Microbial Virulence from Protein Structure and Sequence	14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, BCB 2023			English	Proceedings Paper	14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB)	SEP 03-06, 2023	Houston, TX	Assoc Comp Machinery, ACM Special Interest Grp Bioinformat, Computat Biol, & Biomed Informat		Protein Function; Virulence Prediction; Graph-based models; Large Language Models	DATABASE; ONTOLOGY	In the aftermath of COVID-19, screening for pathogens has never been a more relevant problem. However, computational screening for pathogens is challenging due to a variety of factors, including (i) the complexity and role of the host, (ii) virulence factor divergence and dynamics, and (iii) population and community-level dynamics. Considering a potential pathogen's molecular interactions, specifically individual proteins and protein interactions can help pinpoint a potential protein of a given microbe to cause disease. However, existing tools for pathogen screening rely on existing annotations (KEGG, GO, etc), making the assessment of novel and unannotated proteins more challenging. Here, we present an LLM-inspired approach that considers protein sequence and structure to predict protein virulence. We present a two-stage model incorporating evolutionary features captured from the DistilProtBert language model and protein structure in a graph convolutional network. Our model performs better than sequence alone for virulence function when high-quality structures are present, thus representing a path forward for virulence prediction of novel and unannotated proteins.	[Quintana, Felix; Treangen, Todd J.; Kavraki, Lydia E.] Rice Univ, Comp Sci Dept, Houston, TX 77005 USA	Rice University	Kavraki, LE (corresponding author), Rice Univ, Comp Sci Dept, Houston, TX 77005 USA.	kavraki@rice.edu	; Kavraki, Lydia/N-6325-2018	Treangen, Todd/0000-0002-3760-564X; Kavraki, Lydia/0000-0003-0699-8038	NSF CAREER award [IIS2239114]; NIH/NIAID [P01-AI152999]; NIH [U01CA258512]	NSF CAREER award(National Science Foundation (NSF)NSF - Office of the Director (OD)); NIH/NIAID(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of Allergy & Infectious Diseases (NIAID)); NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	We would like to acknowledge Dr. Krista Ternus' and Dr. Gene Godbold's numerous contributions and insights into functions of sequences of concern (FunSoCs) and microbial virulence factors. We would also like to thank Dr. Advait Balaji for discussions related to SeqScreen. T.J.T. was supported in part by a NSF CAREER award (IIS2239114) and a NIH/NIAID grant (P01-AI152999). LEK is supported in part by NIH U01CA258512.	Amos B, 2022, NUCLEIC ACIDS RES, V50, pD898, DOI 10.1093/nar/gkab929; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Aurrecoechea C, 2017, NUCLEIC ACIDS RES, V45, pD581, DOI 10.1093/nar/gkw1105; Bairoch A, 2000, NUCLEIC ACIDS RES, V28, P45, DOI 10.1093/nar/28.1.45; Balaji A, 2022, GENOME BIOL, V23, DOI 10.1186/s13059-022-02695-x; Bateman A, 2021, NUCLEIC ACIDS RES, V49, pD480, DOI 10.1093/nar/gkaa1100; Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020; Burke DF, 2023, NAT STRUCT MOL BIOL, V30, P216, DOI 10.1038/s41594-022-00910-8; Chen LH, 2005, NUCLEIC ACIDS RES, V33, pD325, DOI 10.1093/nar/gki008; Elworth RAL, 2020, PLOS PATHOG, V16, DOI 10.1371/journal.ppat.1008649; Geffen Y, 2022, BIOINFORMATICS, V38, pii95, DOI 10.1093/bioinformatics/btac474; Gligorijevic V, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23303-9; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Jacak R., PathGO: The Pathogenesis Gene Ontology; Jing B., 2021, INT C REPR; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kessel A., 2018, Structure, Function, and Motion; Kulmanov M, 2018, BIOINFORMATICS, V34, P660, DOI 10.1093/bioinformatics/btx624; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mirdita M, 2022, NAT METHODS, V19, P679, DOI [10.1038/s41592-022-01488-1, 10.5281/ZENODO.5123297]; Oliveira GB, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05375-0; Shulman-Peleg A, 2004, J MOL BIOL, V339, P607, DOI 10.1016/j.jmb.2004.04.012; Varadi M, 2022, NUCLEIC ACIDS RES, V50, pD439, DOI 10.1093/nar/gkab1061; Vaswani A, 2017, ADV NEUR IN, V30; Wattam AR, 2017, NUCLEIC ACIDS RES, V45, pD535, DOI 10.1093/nar/gkw1017; Yuan Q., 2023, BRIEF BIOINFORM, V24	27	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0126-9				2023										10.1145/3584371.3612953	http://dx.doi.org/10.1145/3584371.3612953			6	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Mathematical & Computational Biology; Medical Informatics	BW3UZ		Bronze			2024-07-03	WOS:001143941200103
J	Breneman, A; Gordon, ER; Trager, MH; Ensslin, CJ; Fisher, J; Humphreys, TR; Samie, FH				Breneman, Alyssa; Gordon, Emily R.; Trager, Megan H.; Ensslin, Courtney J.; Fisher, Juliya; Humphreys, Tanya R.; Samie, Faramarz H.			Evaluation of large language model responses to Mohs surgery preoperative questions	ARCHIVES OF DERMATOLOGICAL RESEARCH			English	Letter						Large language models; Artificial intelligence; Mohs micrographic surgery; Preoperative consult; Patient education			[Breneman, Alyssa; Trager, Megan H.; Samie, Faramarz H.] Columbia Univ, Dept Dermatol, Irving Med Ctr, New York, NY 10027 USA; [Gordon, Emily R.] Columbia Univ, Vagelos Coll Phys & Surg, New York, NY USA; [Ensslin, Courtney J.] Icahn Sch Med Mt Sinai, Dept Dermatol, New York, NY USA; [Fisher, Juliya] JUVA Skin Laser Ctr, New York, NY USA; [Fisher, Juliya] Brooklyn Vet Affairs Hosp, Brooklyn, NY USA; [Humphreys, Tanya R.] Main Line Ctr Skin Surg, Wayne, PA USA	NewYork-Presbyterian Hospital; Columbia University; Columbia University; Icahn School of Medicine at Mount Sinai	Breneman, A (corresponding author), Columbia Univ, Dept Dermatol, Irving Med Ctr, New York, NY 10027 USA.	Anb2188@cumc.columbia.edu						Barabino E, 2024, CARDIOVASC INTER RAD, V47, P251, DOI 10.1007/s00270-024-03658-4; Hutchinson N, 2016, AM J MED, V129, P637, DOI 10.1016/j.amjmed.2016.01.008; Patel P, 2021, ARCH DERMATOL RES, V313, P217, DOI 10.1007/s00403-020-02119-5; Robinson MA, 2024, J AM ACAD DERMATOL, V90, P1078, DOI 10.1016/j.jaad.2024.01.037; Trager MH, 2023, ARCH DERMATOL RES, V315, P2979, DOI 10.1007/s00403-023-02705-3	5	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0340-3696	1432-069X		ARCH DERMATOL RES	Arch. Dermatol. Res.	MAY 24	2024	316	6							227	10.1007/s00403-024-02956-8	http://dx.doi.org/10.1007/s00403-024-02956-8			3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	SE3I0	38787433				2024-07-03	WOS:001232738100015
J	Aggrawal, S; Magana, AJ				Aggrawal, Sakhi; Magana, Alejandra J.			Teamwork Conflict Management Training and Conflict Resolution Practice via Large Language Models	FUTURE INTERNET			English	Article						conflict resolution; conflict management training; undergraduate; AI; generative AI; ChatGPT; large language models; computing education; STEM education; teamwork	EMOTIONAL INTELLIGENCE; TEAMS; SIMULATIONS; PERFORMANCE; PREDICTORS; MEDIATION	This study implements a conflict management training approach guided by principles of transformative learning and conflict management practice simulated via an LLM. Transformative learning is more effective when learners are engaged mentally and behaviorally in learning experiences. Correspondingly, the conflict management training approach involved a three-step procedure consisting of a learning phase, a practice phase enabled by an LLM, and a reflection phase. Fifty-six students enrolled in a systems development course were exposed to the transformative learning approach to conflict management so they would be better prepared to address any potential conflicts within their teams as they approached a semester-long software development project. The study investigated the following: (1) How did the training and practice affect students' level of confidence in addressing conflict? (2) Which conflict management styles did students use in the simulated practice? (3) Which strategies did students employ when engaging with the simulated conflict? The findings indicate that: (1) 65% of the students significantly increased in confidence in managing conflict by demonstrating collaborative, compromising, and accommodative approaches; (2) 26% of the students slightly increased in confidence by implementing collaborative and accommodative approaches; and (3) 9% of the students did not increase in confidence, as they were already confident in applying collaborative approaches. The three most frequently used strategies for managing conflict were identifying the root cause of the problem, actively listening, and being specific and objective in explaining their concerns.	[Aggrawal, Sakhi] Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN 47906 USA; [Magana, Alejandra J.] Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN 47906 USA; [Magana, Alejandra J.] Purdue Univ, Sch Engn Educ, W Lafayette, IN 47906 USA	Purdue University System; Purdue University; Purdue University System; Purdue University; Purdue University System; Purdue University	Magana, AJ (corresponding author), Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN 47906 USA.; Magana, AJ (corresponding author), Purdue Univ, Sch Engn Educ, W Lafayette, IN 47906 USA.	saggrawa@purdue.edu; admagana@purdue.edu		Magana, Alejandra/0000-0001-6117-7502; Aggrawal, Sakhi/0000-0002-2274-0152	US National Science Foundation; Purdue University; Protect Purdue Innovations Faculty Grant;  [2113991];  [2219271]	US National Science Foundation(National Science Foundation (NSF)); Purdue University; Protect Purdue Innovations Faculty Grant; ; 	The authors would like to thank the US National Science Foundation for their support through the award numbers #2113991 and #2219271, and Purdue University for their support through a Protect Purdue Innovations Faculty Grant. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation or Purdue University.	Abbasi BA, 2018, ADV SCI LETT, V24, P4353, DOI 10.1166/asl.2018.11604; Ahmed M.A., 2023, Inf. Sci. Lett, V12, P2727; Almost J, 2016, J ADV NURS, V72, P1490, DOI 10.1111/jan.12903; [Anonymous], Conflict Is a Place of Possibility | Dana Caspersen | TEDxHackneyWomen-YouTube; [Anonymous], ChatGPT 3.5 | OpenAI; Antonioni D, 1998, INT J CONFL MANAGE, V9, P336, DOI 10.1108/eb022814; Bahrini Aram, 2023, 2023 Systems and Information Engineering Design Symposium (SIEDS), P274, DOI 10.1109/SIEDS58326.2023.10137850; Bandura A., 1997, Self-Efficacy: The Exercise of Control; Barki H, 2004, INT J CONFL MANAGE, V15, P216, DOI 10.1108/eb022913; Behfar KJ, 2008, J APPL PSYCHOL, V93, P170, DOI 10.1037/0021-9010.93.1.170; Bisbey T., 2019, Oxford research encyclopedia of psychology, DOI [10.1093/acrefore/9780190236557.013.13, DOI 10.1093/ACREFORE/9780190236557.013.13]; Bodtker AM, 2001, INT J CONFL MANAGE, V12, P259, DOI 10.1108/eb022858; Borrego M, 2013, J ENG EDUC, V102, P472, DOI 10.1002/jee.20023; Callanan GA, 2006, J EDUC BUS, V81, P131, DOI 10.3200/JOEB.81.3.131-139; Caputo A, 2023, INT J CONFL MANAGE, V34, P1, DOI 10.1108/IJCMA-07-2021-0117; Chen JB, 2021, EUR J ENG EDUC, V46, P90, DOI 10.1080/03043797.2020.1718615; Christie M, 2015, AUST J ADULT LEARN, V55, P9; Chuang YS, 2024, Arxiv, DOI arXiv:2311.09618; Creswell J. W., 2016, QUAL INQ, DOI DOI 10.1089/TMJ.2009.0067; Cuhadar E, 2014, INT STUD PERSPECT, V15, P509, DOI 10.1111/insp.12076; Curran E., 2008, Journal of the Scholarship of Teaching and Learning, P103; De Dreu C.K. W., 2003, INT HDB ORG TEAMWORK, P151; DeChurch LA, 2010, J APPL PSYCHOL, V95, P32, DOI 10.1037/a0017328; Denzin N. K., 2011, SAGE HDB QUALITATIVE; Dirkx J.M., 1998, PAACE J LIFELONG LEA, V7, P1, DOI DOI 10.2202/1949-6605.6293; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Fisher R., 2011, GETTING YES NEGOTIAT; Flannery T P, 1999, Nurs Adm Q, V23, P35; French F, 2023, MULTIMODAL TECHNOLOG, V7, DOI 10.3390/mti7080081; Gitlow H., 2006, Journal for Quality Participation, V29, P20; Goldberg J.R., 2007, Capstone Design Courses: Producing Industry-ready Biomedical Engineers; JEHN KA, 1995, ADMIN SCI QUART, V40, P256, DOI 10.2307/2393638; Jehn KA, 2008, GROUP DECIS NEGOT, V17, P465, DOI 10.1007/s10726-008-9107-0; Ji H, 2023, J RES TECHNOL EDUC, V55, P48, DOI 10.1080/15391523.2022.2142873; Jones TS, 2001, NEGOTIATION J, V17, P217, DOI 10.1023/A:1013283710190; Jordan PJ, 2004, HUM PERFORM, V17, P195, DOI 10.1207/s15327043hup1702_4; Khosravi P, 2020, INT J PROJ MANAG, V38, P36, DOI 10.1016/j.ijproman.2019.11.001; Kitchenham A, 2008, J TRANSFORM EDUC, V6, P104, DOI 10.1177/1541344608322678; Konrad T, 2020, INT J SUST HIGHER ED, V21, P76, DOI 10.1108/IJSHE-06-2019-0190; KORIAT A, 1980, J EXP PSYCHOL-HUM L, V6, P107, DOI 10.1037/0278-7393.6.2.107; Leung T, 2007, J ASIAN PAC COMMUN, V17, P173, DOI 10.1075/japc.17.2.03leu; Levi D., 2020, GROUP DYNAMICS TEAMS, V6th; Li X, 2024, FUTURE INTERNET, V16, DOI 10.3390/fi16010012; Liyanage U.P., 2023, J. Comput. Soc. Dyn, V8, P15; Lowden K., 2011, EMPLOYERS PERCEPTION, P201126; Lozic E, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15100336; Pertegal-Felices ML, 2019, IEEE ACCESS, V7, P65083, DOI 10.1109/ACCESS.2019.2916343; Magana AJ, 2023, INT J STEM EDUC, V10, DOI 10.1186/s40594-023-00451-6; Malihah E., 2015, Asian Soc. Sci, V11, P353, DOI [10.5539/ass.v11n12p353, DOI 10.5539/ASS.V11N12P353]; Marks MA, 2001, ACAD MANAGE REV, V26, P356, DOI 10.5465/AMR.2001.4845785; Marra RM, 2016, INT J STEM EDUC, V3, DOI 10.1186/s40594-016-0050-3; Maxwell J. A., 2013, QUALITATIVE RES DESI; McEwan D, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169604; Merriam S.B., 2016, QUALITATIVE RES GUID; Meyers S.A., 2008, College Teaching, V56, P219, DOI DOI 10.3200/CTCH.56.4.219-224; Mezirow J., 1991, TRANSFORMATIVE DIMEN, DOI [10.1002/ace.7401, DOI 10.1002/ACE.7401]; Mezirow J., 2018, CONT THEORIES LEARNI, P114, DOI [DOI 10.1186/S12909-018-1181-7, 10.4324/9781315147277-8, DOI 10.4324/9781315147277-8, 10.1186/s12909-018-1181-7]; Mezirow J., 2009, TRANSFORMATIVE LEARN, P18, DOI DOI 10.1080/10549810902856011; Nagda B.A., 2003, Race, Ethnicity, and Education, V6, P165; Notari M, 2014, J COMPUT ASSIST LEAR, V30, P132, DOI 10.1111/jcal.12026; Othlinghaus-Wulhorst J, 2020, FRONT COMP SCI-SWITZ, V2, DOI 10.3389/fcomp.2020.00028; Pesovski I, 2024, SUSTAINABILITY-BASEL, V16, DOI 10.3390/su16073034; Powers RB, 2013, SIMULAT GAMING, V44, P51, DOI 10.1177/1046878112455487; Rahim MF, 2002, INT J CONFL MANAGE, V13, P206, DOI 10.1108/eb022874; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Ray E.B., 1986, Teaching Conflict Management Skills in Corporate Training: A Perspective-Taking Approach; Reiss MJ, 2021, LOND REV EDUC, V19, DOI 10.14324/LRE.19.1.05; Riebe L, 2016, SMALL GR RES, V47, P619, DOI 10.1177/1046496416665221; Salas E, 2008, HUM FACTORS, V50, P903, DOI 10.1518/001872008X375009; Saldaa Johnny., 2021, The coding manual for qualitative researchers, V4th ed.; Shaikh O, 2024, Arxiv, DOI arXiv:2309.12309; Simons TL, 2000, J APPL PSYCHOL, V85, P102, DOI 10.1037/0021-9010.85.1.102; Sollitto M., 2020, P 2020 ASEE VIRT ANN; Southern NL, 2007, J TRANSFORM EDUC, V5, P329, DOI 10.1177/1541344607310576; Stankov L, 2013, PERS INDIV DIFFER, V55, P727, DOI 10.1016/j.paid.2013.07.006; Stevahn L, 2004, THEOR PRACT, V43, P50, DOI 10.1353/tip.2004.0013; Tang RX, 2024, COMMUN ACM, V67, P47, DOI 10.1145/3624725; THOMAS K, 1992, J ORGAN BEHAV, V13, P263, DOI 10.1002/job.4030130306; Thomas K.W., 2008, Thomas-Kilmann Conflict Mode Instrument, P2; THOMAS KW, 1992, J ORGAN BEHAV, V13, P265, DOI 10.1002/job.4030130307; Todorova G, 2022, INT J CONFL MANAGE, V33, P245, DOI 10.1108/IJCMA-03-2021-0042; Waithaka A.G., 2015, RES HIGHER ED J, V28, P1; Wall JA, 2003, J CONFLICT RESOLUT, V47, P693, DOI 10.1177/0022002703252981; Winardi MA, 2022, J GLOB SCHOLARS MARK, V32, P372, DOI 10.1080/21639159.2020.1808847; Xiao C., 2023, P 18 WORKSH INN US N, P610; Zaman B.U., 2023, TechRxiv, DOI [10.36227/techrxiv.24231583.v1, DOI 10.36227/TECHRXIV.24231583.V1]	86	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	MAY	2024	16	5							177	10.3390/fi16050177	http://dx.doi.org/10.3390/fi16050177			25	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	SE6M9		gold			2024-07-03	WOS:001232821500001
J	Azam, M; Chen, YB; Arowolo, MO; Liu, HW; Popescu, M; Xu, D				Azam, Muhammad; Chen, Yibo; Arowolo, Micheal Olaolu; Liu, Haowang; Popescu, Mihail; Xu, Dong			A comprehensive evaluation of large language models in mining gene relations and pathway knowledge	QUANTITATIVE BIOLOGY			English	Article; Early Access						biomedical text mining; gene-gene interaction; KEGG pathway; large language model		Understanding complex biological pathways, including gene-gene interactions and gene regulatory networks, is critical for exploring disease mechanisms and drug development. Manual literature curation of biological pathways cannot keep up with the exponential growth of new discoveries in the literature. Large-scale language models (LLMs) trained on extensive text corpora contain rich biological information, and they can be mined as a biological knowledge graph. This study assesses 21 LLMs, including both application programming interface (API)-based models and open-source models in their capacities of retrieving biological knowledge. The evaluation focuses on predicting gene regulatory relations (activation, inhibition, and phosphorylation) and the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway components. Results indicated a significant disparity in model performance. API-based models GPT-4 and Claude-Pro showed superior performance, with an F1 score of 0.4448 and 0.4386 for the gene regulatory relation prediction, and a Jaccard similarity index of 0.2778 and 0.2657 for the KEGG pathway prediction, respectively. Open-source models lagged behind their API-based counterparts, whereas Falcon-180b and llama2-7b had the highest F1 scores of 0.2787 and 0.1923 in gene regulatory relations, respectively. The KEGG pathway recognition had a Jaccard similarity index of 0.2237 for Falcon-180b and 0.2207 for llama2-7b. Our study suggests that LLMs are informative in gene network analysis and pathway mapping, but their effectiveness varies, necessitating careful model selection. This work also provides a case study and insight into using LLMs das knowledge graphs. Our code is publicly available at the website of GitHub (Muh-aza).	[Azam, Muhammad; Chen, Yibo; Arowolo, Micheal Olaolu; Liu, Haowang; Popescu, Mihail; Xu, Dong] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA; [Azam, Muhammad; Chen, Yibo; Arowolo, Micheal Olaolu; Liu, Haowang; Xu, Dong] Univ Missouri, Bond Life Sci Ctr, Columbia, MO 65201 USA; [Chen, Yibo; Popescu, Mihail; Xu, Dong] Univ Missouri, Inst Data Sci & Informat, Columbia, MO 65201 USA; [Popescu, Mihail] Univ Missouri, Dept Biomed Informat Biostat & Med Epidemiol, Columbia, MO USA	University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia	Xu, D (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.; Xu, D (corresponding author), Univ Missouri, Bond Life Sci Ctr, Columbia, MO 65201 USA.; Xu, D (corresponding author), Univ Missouri, Inst Data Sci & Informat, Columbia, MO 65201 USA.	xudong@missouri.edu			National Institute of General Medical Sciences [R01-LM013392, R35-GM126985, P30DK092950]; National Institute of Health	National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); National Institute of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by the National Institute of Health (Nos. R01-LM013392, R35-GM126985 and P30DK092950).	Agarwal M., 2023, Cureus, V15; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Bai JZ, 2023, Arxiv, DOI [arXiv:2309.16609, 10.48550/arXiv.2309.16609, DOI 10.48550/ARXIV.2309.16609]; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Boubdir M, 2023, Arxiv, DOI arXiv:2310.14424; Central P., 2022, PubMed central (PMC) is a free fulltext archive of biomedical and life sciences journal literature at the U.S; Chen Q., 2023, bioRxiv; Cheng JL, 2023, Arxiv, DOI arXiv:2311.04155; Crawl C., 2023, Common crawl maintains a free, open repository of web crawl data; Fernando Basura, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P13219, DOI 10.1109/CVPR46437.2021.01302; Fu Y, 2023, Arxiv, DOI arXiv:2305.10142; Huang HZ, 2023, Arxiv, DOI arXiv:2309.14494; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kanehisa M, 2000, NUCLEIC ACIDS RES, V28, P27, DOI 10.1093/nar/28.1.27; Kanehisa M, 2019, NUCLEIC ACIDS RES, V47, pD590, DOI 10.1093/nar/gky962; Labatut V., 2012, arXiv, DOI DOI 10.48550/ARXIV.1207.3790; Li J, 2016, DATABASE-OXFORD, DOI 10.1093/database/baw068; Li Y., 2023, NeurIPS 2023 AI for science Workshop; Liu BC, 2023, Arxiv, DOI arXiv:2311.02303; Liu X, 2023, Arxiv, DOI arXiv:2305.15525; Luo HP, 2023, Arxiv, DOI arXiv:2308.09583; Matsui K., Large language model demonstrates human-comparable sensitivity in initial screening of systematic reviews: A semi-automated strategy using gpt-3.5; Nilsson F., 2023, GPT4 as an automatic grader: the accuracy of grades set by GPT4 on introductory programming assignments; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Park G, 2023, Arxiv, DOI arXiv:2307.08813; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; PubMed, 2023, National Center for Biotechnology Information; Qi BQ, 2023, Arxiv, DOI arXiv:2311.05965; Qin HT, 2023, Arxiv, DOI arXiv:2307.15016; Qurashi AW., 2020, 2020 international conference on INnovations in intelligent SysTems and applications (INISTA), P1, DOI DOI 10.1109/INISTA49547.2020.9194665; Roziere B., 2023, aarXiv:230812950; Schneeberger EE, 2004, AM J PHYSIOL-CELL PH, V286, pC1213, DOI 10.1152/ajpcell.00558.2003; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Soong D, 2023, Arxiv, DOI arXiv:2305.17116; Stoney R, 2018, NPJ SYST BIOL APPL, V4, DOI 10.1038/s41540-018-0055-2; Teebagy S., 2023, medRxiv; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; UniProt, Q9udy2 zo2human; Wang WX, 2023, Arxiv, DOI arXiv:2310.09820; Wei WQ, 2018, J CELL PHYSIOL, V233, P9121, DOI 10.1002/jcp.26956; Wu S, 2023, Arxiv, DOI arXiv:2308.04709; Xu L, 2023, Arxiv, DOI arXiv:2307.15020; Yang Y, 2023, Arxiv, DOI arXiv:2311.08206; Yu DL, 2023, Arxiv, DOI arXiv:2310.17567; Zhang Z, 2023, Arxiv, DOI arXiv:2310.04945; Zheng C., 2021, arXiv; Zi YX, 2023, Arxiv, DOI arXiv:2306.13865	47	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2095-4689	2095-4697		QUANT BIOL	Quant. Biol.	2024 JUN 21	2024										10.1002/qub2.57	http://dx.doi.org/10.1002/qub2.57		JUN 2024	15	Mathematical & Computational Biology	Emerging Sources Citation Index (ESCI)	Mathematical & Computational Biology	UX2V5		gold			2024-07-03	WOS:001251308100001
J	Stoehr, F; Kämpgen, B; Müller, L; Zufiria, LO; Junquero, V; Merino, C; Mildenberger, P; Kloeckner, R				Stoehr, Fabian; Kaempgen, Benedikt; Mueller, Lukas; Zufiria, Laura Oleaga; Junquero, Vanesa; Merino, Cristina; Mildenberger, Peter; Kloeckner, Roman			Natural language processing for automatic evaluation of free-text answers - a feasibility study based on the European Diploma in Radiology examination	INSIGHTS INTO IMAGING			English	Article						Natural language processing; Free-text answers; Radiological; Education; Automatization	MULTIPLE-CHOICE	BackgroundWritten medical examinations consist of multiple-choice questions and/or free-text answers. The latter require manual evaluation and rating, which is time-consuming and potentially error-prone. We tested whether natural language processing (NLP) can be used to automatically analyze free-text answers to support the review process.MethodsThe European Board of Radiology of the European Society of Radiology provided representative datasets comprising sample questions, answer keys, participant answers, and reviewer markings from European Diploma in Radiology examinations. Three free-text questions with the highest number of corresponding answers were selected: Questions 1 and 2 were "unstructured" and required a typical free-text answer whereas question 3 was "structured" and offered a selection of predefined wordings/phrases for participants to use in their free-text answer. The NLP engine was designed using word lists, rule-based synonyms, and decision tree learning based on the answer keys and its performance tested against the gold standard of reviewer markings.ResultsAfter implementing the NLP approach in Python, F1 scores were calculated as a measure of NLP performance: 0.26 (unstructured question 1, n = 96), 0.33 (unstructured question 2, n = 327), and 0.5 (more structured question, n = 111). The respective precision/recall values were 0.26/0.27, 0.4/0.32, and 0.62/0.55.ConclusionThis study showed the successful design of an NLP-based approach for automatic evaluation of free-text answers in the EDiR examination. Thus, as a future field of application, NLP could work as a decision-support system for reviewers and support the design of examinations being adjusted to the requirements of an automated, NLP-based review process.Clinical relevance statementNatural language processing can be successfully used to automatically evaluate free-text answers, performing better with more structured question-answer formats. Furthermore, this study provides a baseline for further work applying, e.g., more elaborated NLP approaches/large language models.Key points & BULL; Free-text answers require manual evaluation, which is time-consuming and potentially error-prone.& BULL; We developed a simple NLP-based approach - requiring only minimal effort/modeling - to automatically analyze and mark free-text answers.& BULL; Our NLP engine has the potential to support the manual evaluation process.& BULL; NLP performance is better on a more structured question-answer format.Key points & BULL; Free-text answers require manual evaluation, which is time-consuming and potentially error-prone.& BULL; We developed a simple NLP-based approach - requiring only minimal effort/modeling - to automatically analyze and mark free-text answers.& BULL; Our NLP engine has the potential to support the manual evaluation process.& BULL; NLP performance is better on a more structured question-answer format.Key points & BULL; Free-text answers require manual evaluation, which is time-consuming and potentially error-prone.& BULL; We developed a simple NLP-based approach - requiring only minimal effort/modeling - to automatically analyze and mark free-text answers.& BULL; Our NLP engine has the potential to support the manual evaluation process.& BULL; NLP performance is better on a more structured question-answer format.Key points & BULL; Free-text answers require manual evaluation, which is time-consuming and potentially error-prone. & BULL; We developed a simple NLP-based approach - requiring only minimal effort/modeling - to automatically analyze and mark free-text answers.& BULL; Our NLP engine has the potential to support the manual evaluation process.& BULL; NLP performance is better on a more structured question-answer format.	[Stoehr, Fabian; Mueller, Lukas; Mildenberger, Peter] Johannes Gutenberg Univ Mainz, Univ Med Ctr, Dept Diagnost & Intervent Radiol, Langenbeckst 1, D-55131 Mainz, Germany; [Kaempgen, Benedikt] Empolis Informat Management GmbH, Leightonstr 2, D-67657 Kaiserslautern, Germany; [Zufiria, Laura Oleaga] Hosp Clin Barcelona, Dept Radiol, C Villarroel 170, Barcelona 08036, Spain; [Junquero, Vanesa; Merino, Cristina] European Board Radiol EBR, Barcelona, Spain; [Kloeckner, Roman] Univ Hosp Schleswig Holstein, Inst Intervent Radiol, Campus Luebeck,Ratzeburger Allee 160, D-23583 Lubeck, Germany	Johannes Gutenberg University of Mainz; University of Barcelona; Hospital Clinic de Barcelona; University of Kiel; Schleswig Holstein University Hospital	Kloeckner, R (corresponding author), Univ Hosp Schleswig Holstein, Inst Intervent Radiol, Campus Luebeck,Ratzeburger Allee 160, D-23583 Lubeck, Germany.	Roman.Kloeckner@uksh.de		Kloeckner, Roman/0000-0001-5492-4792; Muller, Lukas/0000-0002-8626-4044	Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL.	Bauer D, 2011, ADV HEALTH SCI EDUC, V16, P211, DOI 10.1007/s10459-010-9256-1; Bird JB, 2019, MED EDUC ONLINE, V24, DOI 10.1080/10872981.2019.1649959; Cai TR, 2016, RADIOGRAPHICS, V36, P176, DOI 10.1148/rg.2016150080; Case S, 2002, Natl Board Exam; Engelhard G., 2018, PSYCHOL TEST ASSESSM, V60, P33; Fatehi M., 2022, Structured reporting in radiology, DOI [10.1007/978-3-030-91349-6, DOI 10.1007/978-3-030-91349-6]; Furlan R, 2021, JMIR MED INF, V9, DOI 10.2196/24073; Jungmann F, 2020, J DIGIT IMAGING, V33, P1026, DOI 10.1007/s10278-020-00342-0; Jungmann F, 2020, INT J MED INFORM, V137, DOI 10.1016/j.ijmedinf.2020.104106; Kang SHK, 2007, EUR J COGN PSYCHOL, V19, P528, DOI 10.1080/09541440601056620; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee B, 2017, CURR PROBL DIAGN RAD, V46, P186, DOI 10.1067/j.cpradiol.2016.11.005; Mozayan A, 2021, RADIOGRAPHICS, V41, P1446, DOI 10.1148/rg.2021200113; Pinto Dos Santos Daniel, 2018, Eur Radiol Exp, V2, P42, DOI 10.1186/s41747-018-0071-4; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Relyea-Chew A, 2011, ACAD RADIOL, V18, P650, DOI 10.1016/j.acra.2010.12.016; Roediger HL, 2005, J EXP PSYCHOL LEARN, V31, P1155, DOI 10.1037/0278-7393.31.5.1155; Sanuvala G, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P1049, DOI 10.1109/ICCCIS51004.2021.9397227; Sarker A, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103268; Schuwirth LWT, 2011, MED TEACH, V33, P478, DOI 10.3109/0142159X.2011.565828; Schuwirth LWT, 2004, MED EDUC, V38, P805, DOI 10.1111/j.1365-2929.2004.01851.x; Schuwirth LWT, 2003, BMJ-BRIT MED J, V326, P643, DOI 10.1136/bmj.326.7390.643; Scouller K, 1998, HIGH EDUC, V35, P453, DOI 10.1023/A:1003196224280; Smith MA, 2014, MEMORY, V22, P784, DOI 10.1080/09658211.2013.831454; Swartz J, 2017, INT J MED INFORM, V101, P93, DOI 10.1016/j.ijmedinf.2017.02.011; Tibbo ME, 2019, J ARTHROPLASTY, V34, P2216, DOI 10.1016/j.arth.2019.07.025; Turkbey B, 2019, EUR UROL, V76, P340, DOI 10.1016/j.eururo.2019.02.033; Vanderbilt AA, 2013, MED EDUC ONLINE, V18, DOI 10.3402/meo.v18i0.20438; Zehner F, 2016, EDUC PSYCHOL MEAS, V76, P280, DOI 10.1177/0013164415590022	29	0	0	5	8	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA	1869-4101			INSIGHTS IMAGING	Insights Imaging	SEP 19	2023	14	1							150	10.1186/s13244-023-01507-5	http://dx.doi.org/10.1186/s13244-023-01507-5			9	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	S8HF4	37726485	Green Published, gold			2024-07-03	WOS:001073515500002
J	Hadas, E; Hershkovitz, A				Hadas, Eran; Hershkovitz, Arnon			Using large language models to evaluate alternative uses task flexibility score	THINKING SKILLS AND CREATIVITY			English	Article						Creativity; Divergent thinking; Alternative uses task; Flexibility; Large language models	CREATIVITY; VALIDITY; THINKING	In the Alternative Uses Task (AUT) test, a group of participants is asked to list as many uses as possible for a simple object. The test measures Divergent Thinking (DT), which involves exploring possible solutions in various semantic domains. In this study we employ a Machine Learning approach to automatically generate suitable categories for object uses and classify given responses into them. We show that the results yielded by this automated approach are correlated with results given by humans and can be used to predict expected behavior in the field. Educators and researchers may utilize this approach to address the limitations of subjective scoring, save time, and use the AUT as a tool for cultivating creativity.	[Hadas, Eran; Hershkovitz, Arnon] Tel Aviv Univ, Sch Educ, POB 39040, IL-6997801 Tel Aviv, Israel	Tel Aviv University	Hadas, E (corresponding author), Tel Aviv Univ, Sch Educ, POB 39040, IL-6997801 Tel Aviv, Israel.	ehadas@tauex.tau.ac.il	Hershkovitz, Arnon/W-9558-2018	Hershkovitz, Arnon/0000-0003-1568-2238				Aggarwal CC, 2012, Mining Text Data, P163, DOI 10.1007/978-1-4614-3223-4; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; AMABILE TM, 1983, J PERS SOC PSYCHOL, V45, P357, DOI 10.1037/0022-3514.45.2.357; Atesgoz NN, 2021, THINK SKILLS CREAT, V40, DOI 10.1016/j.tsc.2021.100818; Avital B, 2023, THINK SKILLS CREAT, V50, DOI 10.1016/j.tsc.2023.101417; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Biswas S, 2023, OPHTHAL PHYSL OPT, V43, P1562, DOI 10.1111/opo.13207; Bolukbasi T, 2016, ADV NEUR IN, V29; Borsboom D, 2004, PSYCHOL REV, V111, P1061, DOI 10.1037/0033-295x.111.4.1061; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Cai YY, 2023, THINK SKILLS CREAT, V48, DOI 10.1016/j.tsc.2023.101255; Cohen R. J., 2018, Psychological testing and assessment: An introduction to tests and measurement, V9th; Cseh GM, 2019, PSYCHOL AESTHET CREA, V13, P159, DOI 10.1037/aca0000220; Dick W., 1971, Topics in measurement: Reliability and validity; Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189; Dumas D, 2021, PSYCHOL AESTHET CREA, V15, P645, DOI 10.1037/aca0000319; e Antonio C. A., 2019, P 2019 INT C ENG APP, P1; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Forthmann B., 2022, Psychology of Aesthetics, Creativity, and the Arts; Forthmann B, 2017, THINK SKILLS CREAT, V23, P129, DOI 10.1016/j.tsc.2016.12.005; Goldstein T, 2023, PSYCHOL AESTHET CREA, V17, P495, DOI 10.1037/aca0000618; González G, 2019, THINK SKILLS CREAT, V32, P114, DOI 10.1016/j.tsc.2017.05.002; Guilford J. P., 1967, The nature of human intelligence; Israel-Fishelson R, 2024, INTERACT LEARN ENVIR, V32, P431, DOI 10.1080/10494820.2022.2088562; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; Kovalkov A, 2021, IEEE T LEARN TECHNOL, V14, P740, DOI 10.1109/TLT.2022.3144442; Krumm G, 2016, THINK SKILLS CREAT, V22, P180, DOI 10.1016/j.tsc.2016.10.003; Kuroiwa T, 2023, J MED INTERNET RES, V25, DOI 10.2196/47621; Larsen JA, 2022, THINK SKILLS CREAT, V46, DOI 10.1016/j.tsc.2022.101147; Leckie G, 2011, J EDUC MEAS, V48, P399, DOI 10.1111/j.1745-3984.2011.00152.x; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Liao YH, 2018, THINK SKILLS CREAT, V29, P213, DOI 10.1016/j.tsc.2018.07.007; Manske S, 2014, IEEE INT CONF ADV LE, P497, DOI 10.1109/ICALT.2014.147; Mehta V, 2021, COMPLEX INTELL SYST, V7, P3211, DOI 10.1007/s40747-021-00512-9; Mesec B., 2023, The language model of artificial inteligence chatgpt-a tool of qualitative analysis of texts; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Morgan DL, 2023, INT J QUAL METH, V22, DOI 10.1177/16094069231211248; Neelakantan A., 2022, . Text and Code Embeddings by Contrastive Pre-Training.; Nielsen JPS, 2023, ACTA OTO-LARYNGOL, V143, P779, DOI 10.1080/00016489.2023.2254809; Olson JA, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2022340118; Organisciak P, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101356; Paulus D.H., 1970, Computer simulation of human ratings of creativity. Final report; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Plucker J. A., 2010, The Cambridge handbook of creativity, P48, DOI DOI 10.1017/CBO9780511763205.005; Punhani A, 2022, IEEE ACCESS, V10, P115025, DOI 10.1109/ACCESS.2022.3215568; Puozzo IC, 2021, THINK SKILLS CREAT, V42, DOI 10.1016/j.tsc.2021.100966; Ramly SNF, 2022, INT J SCI EDUC, V44, P2208, DOI 10.1080/09500693.2022.2116298; Ray P. P., 2023, Internet of Things and Cyber-Physical Systems; Reiter-Palmon R, 2019, PSYCHOL AESTHET CREA, V13, P144, DOI 10.1037/aca0000227; RUNCO MA, 1985, PERCEPT MOTOR SKILL, V61, P1075, DOI 10.2466/pms.1985.61.3f.1075; Scoffham S, 2013, EDUC 3-13, V41, P368, DOI 10.1080/03004279.2013.819625; Siew NM, 2014, PROBL EDUC 21ST CENT, V62, P109; Snyder A, 2004, CREATIVITY RES J, V16, P415; Stevenson C., 2022, Putting GPT-3's creativity to the (Alternative Uses) Test; Sung YT, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000450; Suppadungsuk S, 2023, J CLIN MED, V12, DOI 10.3390/jcm12175550; Thuneberg HM, 2018, THINK SKILLS CREAT, V29, P153, DOI 10.1016/j.tsc.2018.07.003; Torrance E.P., 1974, TORRANCE TESTS CREAT; Torrance E. P., 1977, CREATIVITY CLASSROOM; Tseng R, 2023, LECT NOTES COMPUT SC, V14397, P160, DOI 10.1007/978-3-031-47896-3_12; Vaughn B.K., 2012, Measurement in Sport and Exercise Psychology, P33; Wilson M., 1997, Objective Measurement: Theory into Practice, V5; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754; Yu YH, 2023, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000573; Zedelius CM, 2019, BEHAV RES METHODS, V51, P879, DOI 10.3758/s13428-018-1137-1; Zhang H, 2024, Arxiv, DOI arXiv:2309.10771; Zhao JY, 2019, Arxiv, DOI arXiv:1904.03310; Ziegler E, 2018, THINK SKILLS CREAT, V30, P64, DOI 10.1016/j.tsc.2018.03.009	68	0	0	6	6	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1871-1871	1878-0423		THINK SKILLS CREAT	Think. Skills Creat.	JUN	2024	52								101549	10.1016/j.tsc.2024.101549	http://dx.doi.org/10.1016/j.tsc.2024.101549			15	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	TG1X4					2024-07-03	WOS:001240032400001
J	Dortheimer, J; Martelaro, N; Sprecher, A; Schubert, G				Dortheimer, Jonathan; Martelaro, Nik; Sprecher, Aaron; Schubert, Gerhard			Evaluating large-language-model chatbots to engage communities in large-scale design projects	AI EDAM-ARTIFICIAL INTELLIGENCE FOR ENGINEERING DESIGN ANALYSIS AND MANUFACTURING			English	Article						chatbot; urban design; participatory design; large language model; crowdsourcing	INTRINSIC MOTIVATION; CONVERSATIONS; CHALLENGES; ARCHITECT; OPPORTUNITIES; KNOWLEDGE	Recent advances in machine learning have enabled computers to converse with humans meaningfully. In this study, we propose using this technology to facilitate design conversations in large-scale urban development projects by creating chatbot systems that can automate and streamline information exchange between stakeholders and designers. To this end, we developed and evaluated a proof-of-concept chatbot system that can perform design conversations on a specific construction project and convert those conversations into a list of requirements. Next, in an experiment with 56 participants, we compared the chatbot system to a regular online survey, focusing on user satisfaction and the quality and quantity of collected information. The results revealed that, with regard to user satisfaction, the participants preferred the chatbot experience to a regular survey. However, we found that chatbot conversations produced more data than the survey, with a similar rate of novel ideas but fewer themes. Our findings provide robust evidence that chatbots can be effectively used for design discussions in large-scale design projects and offer a user-friendly experience that can help to engage people in the design process. Based on this evidence, by providing a space for meaningful conversations between stakeholders and expanding the reach of design projects, the use of chatbot systems in interactive design systems can potentially improve design processes and their outcomes.	[Dortheimer, Jonathan] Ariel Univ, Sch Architecture, Ariel, Israel; [Martelaro, Nik] Carnegie Mellon Univ, Human Comp Interact Inst, Pittsburgh, PA USA; [Sprecher, Aaron] Technion Israel Inst Technol, Fac Architecture, Haifa, Israel; [Schubert, Gerhard] Tech Univ Munich, TUM Sch Engn & Design, Munich, Germany	Ariel University; Carnegie Mellon University; Technion Israel Institute of Technology; Technical University of Munich	Dortheimer, J (corresponding author), Ariel Univ, Sch Architecture, Ariel, Israel.	jonathand@ariel.ac.il		Sprecher, Aaron/0000-0002-2621-7350; Dortheimer, Jonathan/0000-0002-7464-8526; Martelaro, Nikolas/0000-0002-1824-0243	Technical University of Munich Global Incentive Fund	Technical University of Munich Global Incentive Fund	This work was supported by the Technical University of Munich Global Incentive Fund. The funder had no role in study design, data collection and analysis, publication decision, or manuscript preparation.	Abdul-Kader SA, 2015, INT J ADV COMPUT SC, V6, P72; Ahmed S., 2019, An Architecture for Dynamic Conversational Agents for Citizen Participation and Ideation; Alexander C., 1964, Notes on the synthesis of form; [Anonymous], 1977, A Pattern Language: Towns, Buildings, Construction; Arias E., 2000, ACM Transactions on Computer-Human Interaction, V7, P84, DOI 10.1145/344949.345015; ARNSTEIN SR, 1969, J AM I PLANNERS, V35, P216, DOI 10.1080/01944366908977225; Ashfaq M, 2020, TELEMAT INFORM, V54, DOI 10.1016/j.tele.2020.101473; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bittner EAC, 2019, PROCEEDINGS OF THE 52ND ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P227; Borges J, 2015, LECT NOTES GEOINF CA, P361, DOI 10.1007/978-3-319-17738-0_25; Brabham DC, 2009, PLAN THEOR, V8, P242, DOI 10.1177/1473095209104824; Calderon C, 2020, J URBAN DES, V25, P50, DOI 10.1080/13574809.2019.1677146; Cuadra Andrea., 2021, CUI 2021-3rd Conference on Conversational User Interfaces, P1; Dortheimer J., 2023, ECAADE 41 DIGITAL DE, P567; Dortheimer J, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13010222; Dortheimer J, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10040539; Dortheimer J, 2020, ECAADE PROC, P155; Dortheimer J, 2020, J ARCHITECTURE, V25, P276, DOI 10.1080/13602365.2020.1758950; Dubberly H, 2019, DES RES FOUND, P85, DOI 10.1007/978-3-030-18557-2_4; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frey K, 2011, LONG RANGE PLANN, V44, P397, DOI 10.1016/j.lrp.2011.09.006; Gooch D, 2018, ACM T COMPUT-HUM INT, V25, DOI 10.1145/3139398; Han X, 2021, PROCEEDINGS OF THE ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '21), P1, DOI 10.1145/3427921.3450255; Harvey D., 1973, SOCIAL JUSTICE CITY; Hill J, 2015, COMPUT HUM BEHAV, V49, P245, DOI 10.1016/j.chb.2015.02.026; Hofmann M, 2020, J GEOVIS SPAT ANAL, V4, DOI 10.1007/s41651-019-0040-3; Hosio S, 2015, POLICY INTERNET, V7, P203, DOI 10.1002/poi3.90; Hussain Shafquat, 2019, Web, Artificial Intelligence and Network Applications. Proceedings of the Workshops of the 33rd International Conference on Advanced Information Networking and Applications (WAINA-2019). Advances in Intelligent Systems and Computing (AISC 927), P946, DOI 10.1007/978-3-030-15035-8_93; Hwang AHC, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445270; Jacobs J., 1964, The death and life of great American cities; Karlgren K, 2012, CODESIGN, V8, P231, DOI 10.1080/15710882.2012.734829; Kim S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300316; Kruger M., 2019, Interactions, V26, P50, DOI DOI 10.1145/3319376; Kulcke M., 2018, Computing for a Better Tomorrow-Proceedings of the 36th eCAADe Conference, V1, P103; Lawson B., 1997, Design Studies, V18, P171, DOI 10.1016/S0142-694X(97)85459-2; Liang HG, 2018, COMPUT HUM BEHAV, V81, P168, DOI 10.1016/j.chb.2017.11.040; Lindenberg S, 2001, KYKLOS, V54, P317, DOI 10.1111/1467-6435.00156; Lu H., 2018, CAADRIA 2018-23rd International Conference on Computer-Aided Architectural Design Research in Asia: Learning, Prototyping and Adapting, V2, P297; Luck R, 2006, DESIGN STUD, V27, P141, DOI 10.1016/j.destud.2005.09.001; Luck R, 2018, DESIGN STUD, V59, P139, DOI 10.1016/j.destud.2018.10.003; Luck Rachael., 2003, DESIGN STUD, V24, P523, DOI DOI 10.1016/S0142-694X(03)00040-1; Malone TW, 2010, MIT SLOAN MANAGE REV, V51, P21; Martelaro N, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P2065, DOI 10.1145/3357236.3395440; McDonnell J, 2009, CODESIGN, V5, P35, DOI 10.1080/15710880802492862; Mueller J, 2018, CITIES, V72, P181, DOI 10.1016/j.cities.2017.08.018; Münster S, 2017, PROCEDIA COMPUT SCI, V112, P2391, DOI 10.1016/j.procs.2017.08.102; Nguyen TH, 2022, INFORM SYST FRONT, V24, P797, DOI 10.1007/s10796-021-10212-x; Oak A, 2009, CODESIGN, V5, P51, DOI 10.1080/15710880802518054; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reich Y., 1996, Design Studies, V17, P165, DOI 10.1016/0142-694X(95)00000-H; Robertson T, 2013, Routledge International Handbook of Participatory Design; Robertson T, 2012, DES ISSUES, V28, P3, DOI 10.1162/DESI_a_00157; Schmitt Oliver., 2021, Creativity and Cognition (CC '21), P1; Scott Giering, 2011, Public participation strategies for transit, V89; Shawar B., 2005, International Journal of Corpus Linguistics, V10, P489, DOI DOI 10.1075/IJCL.10.4.06SHA; Shin J, 2022, OCEANS-IEEE, DOI 10.1109/OCEANS47191.2022.9977275; Soomin Kim, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449161; Tavanapour N., 2018, Proceedings of the International Conference on Information Systems-Bridging the Internet of People, Data, and Things, ICIS 2018; te Pas ME, 2020, JMIR MED INF, V8, DOI 10.2196/21982; Wang Y, 2021, ADV ENG INFORM, V50, DOI 10.1016/j.aei.2021.101371; Wei J, 2023, Arxiv, DOI arXiv:2301.05843; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xiao Z, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376131; Xiao ZA, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3381804; Yi-Chieh Lee, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3392836; Zamfrescu-Pereira JD, 2023, DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2023, P2206, DOI 10.1145/3563657.3596138	68	1	1	5	5	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	0890-0604	1469-1760		AI EDAM	AI EDAM-Artif. Intell. Eng. Des. Anal. Manuf.	MAR 18	2024	38								e4	10.1017/S0890060424000027	http://dx.doi.org/10.1017/S0890060424000027			16	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Multidisciplinary; Engineering, Manufacturing	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	MG0W2		hybrid			2024-07-03	WOS:001192365600001
J	Kaba, E; Hürsoy, N; Solak, M; Çeliker, FB				Kaba, Esat; Hursoy, Nur; Solak, Merve; Celiker, Fatma Beyazal			Accuracy of Large Language Models in Thyroid Nodule-Related Questions Based on the Korean Thyroid Imaging Reporting and Data System (K-TIRADS)	KOREAN JOURNAL OF RADIOLOGY			English	Letter						Large language models; Thyroid; Nodules; K-TIRADS			[Kaba, Esat; Hursoy, Nur; Solak, Merve; Celiker, Fatma Beyazal] Recep Tayyip Erdogan Univ, Dept Radiol, Vadi St 9, TR-53800 Rize, Turkiye	Recep Tayyip Erdogan University	Kaba, E (corresponding author), Recep Tayyip Erdogan Univ, Dept Radiol, Vadi St 9, TR-53800 Rize, Turkiye.	esatkaba04@gmail.com	Kaba, Esat/GLR-6610-2022	Kaba, Esat/0000-0001-7464-988X; Hursoy, Nur/0000-0001-5059-2268; SOLAK, Merve/0000-0003-3466-7260				Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Gordon EB, 2024, J AM COLL RADIOL, V21, P353, DOI 10.1016/j.jacr.2023.09.011; Ha EJ, 2021, KOREAN J RADIOL, V22, P2094, DOI 10.3348/kjr.2021.0713; Haver HL, 2024, RADIOL-IMAG CANCER, V6, DOI 10.1148/rycan.230086; Kim K, 2024, KOREAN J RADIOL, V25, P224, DOI 10.3348/kjr.2023.0818; Kim S, 2024, KOREAN J RADIOL, V25, P126, DOI 10.3348/kjr.2023.0997	6	0	0	0	0	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	MAY	2024	25	5					499	500		10.3348/kjr.2024.0229	http://dx.doi.org/10.3348/kjr.2024.0229			2	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	QS7C3	38685738				2024-07-03	WOS:001222915000009
J	Obasa, AE				Obasa, Adetayo E.			Large language models through the lens of ubuntu for health research in sub-Saharan Africa	SOUTH AFRICAN JOURNAL OF SCIENCE			English	Article						ubuntu large language models,; artificial intelligence sub-Saharan; Africa		Ubuntu provides a distinct philosophy that could be useful in addressing the cultural and geographical nuances within sub-Saharan Africa. This philosophy offers a unique framework that could prove valuable in navigating these nuances in the sub-Saharan region. At its core, ubuntu emphasises interconnectedness, community -driven engagement, and sustainability. This perspective underscores the need for culturally sensitive technology solutions that honour and safeguard local traditions while promoting individual liberties and communal welfare. Ubuntu 's approach offers an intriguing balance between the individual and the collective. Marginalised groups must be included in a comprehensive approach. Bias in sub-Saharan Africa has deep roots in historical injustice and is further reinforced by cultural norms, religious beliefs, and practices. In this article, I elaborate on ethical concerns in the context of sub-Saharan Africa.	[Obasa, Adetayo E.] Stellenbosch Univ, Fac Med & Hlth Sci, Dev & Support Div, Registrar Res Support Off,Res & Internationalisat, Cape Town, South Africa	Stellenbosch University	Obasa, AE (corresponding author), Stellenbosch Univ, Fac Med & Hlth Sci, Dev & Support Div, Registrar Res Support Off,Res & Internationalisat, Cape Town, South Africa.	obasa@sun.ac.za						Auerbach Jahajeeah J, 2024, The Conversation Africa,March 15; Baker N, 2021, COMMUNITY MENT HLT J, V57, P285, DOI 10.1007/s10597-020-00647-y; Beauchamp JF, 2019, Principles of biomedical ethics, V8th; Bila N., UP expert opinion: Ubuntu as a solution to mental illness challenges; Cacciamani GE, 2023, Arxiv, DOI [arXiv:2307.08974, 10.48550/arXiv.2307.08974, DOI 10.48550/ARXIV.2307.08974]; Carman M, 2021, ETHICS INF TECHNOL, V23, P107, DOI 10.1007/s10676-020-09534-2; Chen P, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131810258; Corrêa NK, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100857; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Dempsey N, 2011, SUSTAIN DEV, V19, P289, DOI 10.1002/sd.417; Edwards S., 2004, INT J MENT HEALTH PR, V6, P17, DOI DOI 10.1080/14623730.2004.9721940; Eze MO, 2008, S AFR J PHILOS, V27, P386, DOI 10.4314/sajpem.v27i4.31526; Gade CBN, 2012, S AFR J PHILOS, V31, P484, DOI 10.1080/02580136.2012.10751789; Genuis QIT, 2021, J MED PHILOS, V46, P330, DOI 10.1093/jmp/jhab004; Kholopa C, 2022, Glob J Hum Soc Sci., V22, P23; Kuteyi D, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14042399; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Matemba Y, 2021, BRIT J RELIG EDUC, V43, P33, DOI 10.1080/01416200.2020.1816529; Mikalef P, 2022, EUR J INFORM SYST, V31, P257, DOI 10.1080/0960085X.2022.2026621; Obasa AE, 2023, S AFR J SCI, V119, DOI 10.17159/sajs.2023/14889; Owoyemi A, 2020, FRONT DIGIT HEALTH, V2, DOI 10.3389/fdgth.2020.00006; Roche Cathy, 2022, AI Ethics, P1, DOI 10.1007/s43681-022-00218-9; Teffo LJ, 1994, The concept of Ubuntu as a coherent moral value; Tiffin N, 2019, BMJ GLOB HEALTH, V4, DOI 10.1136/bmjgh-2019-001395; Topol Eric J, 2023, Science, V381, padk6139, DOI 10.1126/science.adk6139; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Upadhyay N, 2022, INT J ENTREP BEHAV R, V28, P1138, DOI 10.1108/IJEBR-01-2021-0052	28	0	0	0	0	ACAD SCIENCE SOUTH AFRICA - ASSAf	LYNWOOD RIDGE	PO BOX 72135, LYNWOOD RIDGE 0040, SOUTH AFRICA	0038-2353	1996-7489		S AFR J SCI	S. Afr. J. Sci.	MAY-JUN	2024	120	5-6							16814	10.17159/sajs.2024/16814	http://dx.doi.org/10.17159/sajs.2024/16814			4	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	SR3Q0					2024-07-03	WOS:001236142300002
C	Liang, BS			Assoc Computing Machinery	Liang, Bor-Sung			Computing Architecture for Large-Language Models (LLMs) and Large Multimodal Models (LMMs)	PROCEEDINGS OF THE 2024 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, ISPD 2024			English	Proceedings Paper	33rd ACM International Symposium on Physical Design (ISPD)	MAR 12-15, 2024	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Design Automat, IEEE Council Elect Design Automat		AI Computing; Domain Specific Architecture; Large-Language Models (LLMs); Large Multimodal Models (LMMs); AI System Design; Mobile Processor Architecture			[Liang, Bor-Sung] MediaTek, Corp Strategy & Strateg Technol, Hsinchu, Taiwan; [Liang, Bor-Sung] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, EECS, Taipei, Taiwan	Mediatek Incorporated; National Taiwan University	Liang, BS (corresponding author), MediaTek, Corp Strategy & Strateg Technol, Hsinchu, Taiwan.; Liang, BS (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, EECS, Taipei, Taiwan.	bs.liang@mediatek.com						Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Dally Bill., 2023, Hot Chips 2023; Dean Jeff., 2023, Hot Chips 2023; Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421	6	0	0	13	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0417-8				2024							233	234		10.1145/3626184.3639692	http://dx.doi.org/10.1145/3626184.3639692			2	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW7AY					2024-07-03	WOS:001187456000042
J	Cadeddu, A; Chessa, A; De Leo, V; Fenu, G; Motta, E; Osborne, F; Recupero, DR; Salatino, A; Secchi, L				Cadeddu, Andrea; Chessa, Alessandro; De Leo, Vincenzo; Fenu, Gianni; Motta, Enrico; Osborne, Francesco; Recupero, Diego Reforgiato; Salatino, Angelo; Secchi, Luca			A comparative analysis of knowledge injection strategies for large language models in the domain	ENGINEERING APPLICATIONS OF ARTIFICIAL INTELLIGENCE			English	Article						Knowledge injection; Knowledge graphs; Large language models; Transformers; BERT; Classification; Natural language processing		In recent years, transformer-based models have emerged as powerful tools for natural language processing tasks, demonstrating remarkable performance in several domains. However, they still present significant limitations. These shortcomings become more noticeable when dealing with highly specific and complex concepts, particularly within the scientific domain. For example, transformer models have particular difficulties when processing scientific articles due to the domain-specific terminologies and sophisticated ideas often encountered in scientific literature. To overcome these challenges and further enhance the effectiveness of transformers in specific fields, researchers have turned their attention to the concept of knowledge injection. Knowledge injection is the process of incorporating outside knowledge into transformer models to improve their performance on certain tasks. In this paper, we present a comprehensive study of knowledge injection strategies for transformers within the scientific domain. Specifically, we provide a detailed overview and comparative assessment of four primary methodologies, evaluating their efficacy in the task of classifying scientific articles. For this purpose, we constructed a new benchmark including both 24K labelled papers and a knowledge graph of 9.2K triples describing pertinent research topics. We also developed a full codebase to easily re-implement all knowledge injection strategies in different domains. A formal evaluation indicates that the majority of the proposed knowledge injection methodologies significantly outperform the baseline established by Bidirectional Encoder Representations from Transformers.	[Cadeddu, Andrea; Chessa, Alessandro; De Leo, Vincenzo; Secchi, Luca] Linkalab Srl, Cagliari, Italy; [De Leo, Vincenzo; Fenu, Gianni; Recupero, Diego Reforgiato; Secchi, Luca] Univ Cagliari, Dept Math & Comp Sci, Cagliari, Italy; [Motta, Enrico; Osborne, Francesco; Salatino, Angelo] Open Univ, Knowledge Media Inst, Milton Keynes, England; [Osborne, Francesco] Univ Milano Bicocca, Dept Business & Law, Milan, Italy	University of Cagliari; Open University - UK; University of Milano-Bicocca	Recupero, DR (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Cagliari, Italy.	andrea.cadeddu@linkalab.it; alessandro.chessa@linkalab.it; andrea.cadeddu@linkalab.it; fenu@unica.it; enrico.motta@open.ac.uk; francesco.osborne@open.ac.uk; diego.reforgiato@unica.it; angelo.salatino@open.ac.uk; luca.secchi@linkalab.it		Reforgiato Recupero, Diego/0000-0001-8646-6183; De Leo, Vincenzo/0000-0003-4216-6992	National Recovery and Resilience Plan (NRRP) - European Union [ECS0000038, CUP F53C22000430001]	National Recovery and Resilience Plan (NRRP) - European Union	We acknowledge financial support under the National Recovery and Resilience Plan (NRRP), Mission 4 Component 2 Investment 1.5-Call for tender No. 3277 published on December 30, 2021 by the Italian Ministry of University and Research (MIUR) funded by the European Union - NextGenerationEU. Project Code ECS0000038 - Project Title eINS Ecosystem of Innovation for Next Generation Sardinia - CUP F53C22000430001-Grant Assignment Decree No. 1056 adopted on June 23, 2022 by the Italian Ministry of University and Research (MIUR).	Aggarwal T, 2022, SOFTW IMPACTS, V14, DOI 10.1016/j.simpa.2022.100444; Al-Moslmi T, 2020, IEEE ACCESS, V8, P32862, DOI 10.1109/ACCESS.2020.2973928; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amizadeh S, 2020, Arxiv, DOI arXiv:2006.11524; Angioni S., 2020, 19 INT SEM WEB C ISW; Angioni S, 2022, QUANT SCI STUD, V2, P1356, DOI 10.1162/qss_a_00162; Auer S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-33607-z; Barbieri F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1644; Beck M, 2020, LECT NOTES COMPUT SC, V12116, P451, DOI 10.1007/978-3-030-57058-3_32; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Caselli T, 2021, Arxiv, DOI arXiv:2010.12472; Chamorro-Padial J, 2023, ALGORITHMS, V16, DOI 10.3390/a16040196; Chari S., 2023, Semant Web Preprint (Preprint), P1, DOI [10.3233/SW-233282, DOI 10.3233/SW-233282]; Chatzopoulos S., 2020, ADBIS TPDL EDA 2020, P323, DOI [10.1007/978-3-030-55814-7_27, DOI 10.1007/978-3-030-55814-7_27]; Chessa A, 2023, IEEE ACCESS, V11, P67567, DOI 10.1109/ACCESS.2023.3292153; Dessi D, 2022, KNOWL-BASED SYST, V258, DOI 10.1016/j.knosys.2022.109945; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dodge J, 2020, Arxiv, DOI [arXiv:2002.06305, 10.48550/arXiv.2002.06305]; Emelin D, 2022, Arxiv, DOI arXiv:2212.08120; Gangopadhyay B, 2021, PATTERN RECOGN LETT, V152, P143, DOI 10.1016/j.patrec.2021.10.004; Gao S, 2021, IEEE J BIOMED HEALTH, V25, P3596, DOI 10.1109/JBHI.2021.3062322; Gosangi R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4539; Guu K, 2020, PR MACH LEARN RES, V119; Han K., 2023, Incorporating knowledge resources into natural language processing techniques to advance academic research and application development; Hitzler P, 2021, COMMUN ACM, V64, P76, DOI 10.1145/3397512; Joshi M, 2021, Arxiv, DOI arXiv:2004.12006; Kalyan K. S., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.05542, 10.48550/arXiv.2108.05542]; Ke P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6975; Kim SW, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0192-7; Kumar K, 2023, Arxiv, DOI arXiv:2304.02138; Kumar V, 2022, IEEE ACCESS, V10, P91802, DOI 10.1109/ACCESS.2022.3201542; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee J, 2019, CoRRabs/1901.08746; Leivaditi S, 2020, Arxiv, DOI arXiv:2010.10386; Lerer A, 2019, Arxiv, DOI arXiv:1903.12287; Li Wentao, 2023, Learning Technologies and Systems: 21st International Conference on Web-Based Learning, ICWL 2022, and 7th International Symposium on Emerging Technologies for Education, SETE 2022, Revised Selected Papers. Lecture Notes in Computer Science (13869), P148, DOI 10.1007/978-3-031-33023-0_13; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu WJ, 2019, Arxiv, DOI arXiv:1909.07606; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loffler F., 2020, P ISWC 2020 DEM IND; Borges MVM, 2019, IEEE INT CONF ADV LE, P42, DOI 10.1109/ICALT.2019.00013; Mardiah M., 2023, Khazanah Informatika: Jurnal Ilmu Komputer dan Informatika, V9; Meloni A, 2023, IEEE ACCESS, V11, P22468, DOI 10.1109/ACCESS.2023.3253388; Mendes PN, 2011, P 7 INT C SEM SYST, P1, DOI [10.1145/2063518.2063519, DOI 10.1145/2063518.2063519]; Moiseev F, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1581; Moiseev Fedor, 2022, arXiv, DOI DOI 10.48550/ARXIV.2205.08184; Nayyeri M, 2021, NEUROCOMPUTING, V461, P530, DOI 10.1016/j.neucom.2021.02.100; OpenAI, 2023, Gpt-4 technical report; Osborne F, 2015, LECT NOTES COMPUT SC, V9366, P408, DOI 10.1007/978-3-319-25007-6_24; Osborne F, 2013, LECT NOTES COMPUT SC, V8218, P460, DOI 10.1007/978-3-642-41335-3_29; Ostendorff M, 2019, Arxiv, DOI [arXiv:1909.08402, DOI 10.48550/ARXIV.1909.08402]; Peng CY, 2023, ARTIF INTELL REV, V56, P13071, DOI 10.1007/s10462-023-10465-9; Qin YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3350; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Rizvi STR, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-023-01085-w; Rossanez A., 2020, Representing scientific literature evolution via temporal knowledge graphs; Salatino A., 2023, Diversity of expertise is key to scientific impact: a large-scale analysis in the field of computer science, DOI [10.55835/6442f3fd947802668eee976c, DOI 10.55835/6442F3FD947802668EEE976C]; Salatino A, 2022, INT J DIGIT LIBRARIE, V23, P91, DOI 10.1007/s00799-021-00305-y; Salatino AA, 2019, LECT NOTES COMPUT SC, V11799, P296, DOI 10.1007/978-3-030-30760-8_26; Salatino AA, 2019, LECT NOTES COMPUT SC, V11779, P507, DOI 10.1007/978-3-030-30796-7_31; Salatino AA, 2018, ACM-IEEE J CONF DIG, P303, DOI 10.1145/3197026.3197052; Salatino AA, 2018, LECT NOTES COMPUT SC, V11137, P187, DOI 10.1007/978-3-030-00668-6_12; Sattler U, 2022, LECT NOTES COMPUT SC, V13489, P678, DOI 10.1007/978-3-031-19433-7_39; Su YS, 2021, AI OPEN, V2, P127, DOI 10.1016/j.aiopen.2021.06.004; Sun T., 2020, P 28 INT C COMP LING, P3660, DOI [DOI 10.18653/V1/2020.COLING-MAIN.327, DOI 10.18653/V1/2020.COLING-MAIN.327,URL]; Thanapalasingam T, 2018, LECT NOTES COMPUT SC, V11137, P341, DOI 10.1007/978-3-030-00668-6_21; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vergoulis Thanasis, 2020, Digital Libraries for Open Knowledge. 24th International Conference on Theory and Practice of Digital Libraries, TPDL 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12246), P48, DOI 10.1007/978-3-030-54956-5_4; Wang RZ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1405; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Xu Y., 2023, arXiv; Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442; Yang JW, 2021, STRESS, V24, P1016, DOI 10.1080/10253890.2021.1992380; Zhang XY, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445396; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441	75	0	0	4	4	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0952-1976	1873-6769		ENG APPL ARTIF INTEL	Eng. Appl. Artif. Intell.	JUL	2024	133		B						108166	10.1016/j.engappai.2024.108166	http://dx.doi.org/10.1016/j.engappai.2024.108166			13	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Multidisciplinary; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science; Engineering	QO4U5		hybrid			2024-07-03	WOS:001221808600001
J	Yue, TW; Wang, YX; Zhang, LX; Gu, CM; Xue, HR; Wang, WP; Lyu, Q; Dun, Y				Yue, Tianwei; Wang, Yuanxin; Zhang, Longxiang; Gu, Chunming; Xue, Haoru; Wang, Wenping; Lyu, Qi; Dun, Yujie			Deep Learning for Genomics: From Early Neural Nets to Modern Large Language Models	INTERNATIONAL JOURNAL OF MOLECULAR SCIENCES			English	Review						deep learning; genomics; large language model; computer vision; multi-modal machine learning	PROTEIN SECONDARY STRUCTURE; PREDICTING GENE-EXPRESSION; SUPPORT VECTOR MACHINES; SUBCELLULAR-LOCALIZATION; STRUCTURAL CLASSIFICATION; HOMOLOGY DETECTION; SEQUENCE; DNA; QUALITY; NETWORKS	The data explosion driven by advancements in genomic research, such as high-throughput sequencing techniques, is constantly challenging conventional methods used in genomics. In parallel with the urgent demand for robust algorithms, deep learning has succeeded in various fields such as vision, speech, and text processing. Yet genomics entails unique challenges to deep learning, since we expect a superhuman intelligence that explores beyond our knowledge to interpret the genome from deep learning. A powerful deep learning model should rely on the insightful utilization of task-specific knowledge. In this paper, we briefly discuss the strengths of different deep learning models from a genomic perspective so as to fit each particular task with proper deep learning-based architecture, and we remark on practical considerations of developing deep learning architectures for genomics. We also provide a concise review of deep learning applications in various aspects of genomic research and point out current challenges and potential research directions for future genomics applications. We believe the collaborative use of ever-growing diverse data and the fast iteration of deep learning models will continue to contribute to the future of genomics.	[Yue, Tianwei; Wang, Yuanxin; Zhang, Longxiang; Wang, Wenping] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA; [Gu, Chunming] Johns Hopkins Univ, Sch Med, Dept Biomed Engn, Baltimore, MD 21218 USA; [Xue, Haoru] Carnegie Mellon Univ, Robot Inst, Pittsburgh, PA 15213 USA; [Lyu, Qi] Michigan State Univ, Dept Computat Math Sci & Engn, E Lansing, MI 48824 USA; [Dun, Yujie] Xi An Jiao Tong Univ, Sch Informat & Commun Engn, Xian 710049, Peoples R China	Carnegie Mellon University; Johns Hopkins University; Carnegie Mellon University; Michigan State University; Xi'an Jiaotong University	Yue, TW (corresponding author), Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.	tyue@alumni.cmu.edu; yuanxinw@alumni.cmu.edu; longxiaz@alumni.cmu.edu; cgu15@jhmi.edu; haorux@andrew.cmu.edu; wenpingw@alumni.cmu.edu; lyuqi1@msu.edu; dunyj@mail.xjtu.edu.cn		Wang, Wenping/0000-0001-9665-3783; Wang, Yuanxin/0000-0001-8183-9163; Dun, Yujie/0000-0001-5213-1000				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adhikari B, 2018, BIOINFORMATICS, V34, P1466, DOI 10.1093/bioinformatics/btx781; Al-Stouhi S, 2016, KNOWL INF SYST, V48, P201, DOI 10.1007/s10115-015-0870-3; Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1016/S0022-2836(05)80360-2; Andreeva A, 2010, ACTA CRYSTALLOGR F, V66, P1190, DOI 10.1107/S1744309110007177; Angermueller C, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1189-z; [Anonymous], 2017, bioRxiv; [Anonymous], 2011, P 28 INT C INT C MAC; [Anonymous], 1986, Learning and relearning in boltzmann machines; [Anonymous], 2017, arXiv; [Anonymous], 2015, Some Current Advanced Researches on Information and Computer Science in Vietnam; [Anonymous], 2017, On the Origin of Deep Learning; Armenteros JJA, 2017, BIOINFORMATICS, V33, P3387, DOI 10.1093/bioinformatics/btx431; Asgari E, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0141287; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Astle W, 2009, STAT SCI, V24, P451, DOI 10.1214/09-STS307; Avsec Z, 2021, NAT METHODS, V18, P1196, DOI 10.1038/s41592-021-01252-x; Bae BI, 2015, DEV CELL, V32, P423, DOI 10.1016/j.devcel.2015.01.035; Baldi P, 1999, BIOINFORMATICS, V15, P937, DOI 10.1093/bioinformatics/15.11.937; Barash Y, 2010, NATURE, V465, P53, DOI 10.1038/nature09000; Barretina J, 2012, NATURE, V483, P603, DOI 10.1038/nature11003; Beer MA, 2004, CELL, V117, P185, DOI 10.1016/S0092-8674(04)00304-6; Benegas G, 2022, bioRxiv, DOI [10.1101/2022.08.22.504706, 10.1101/2022.08.22.504706, DOI 10.1101/2022.08.22.504706]; Bengio Y., 2006, Advances in Neural Information Processing Systems, V19; Beyreli I, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100524; BOHR H, 1988, FEBS LETT, V241, P223, DOI 10.1016/0014-5793(88)81066-4; Bonidia RP, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbab434; Bonomi L, 2020, NAT GENET, V52, P646, DOI 10.1038/s41588-020-0651-0; Boza V, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178751; Breda A, 2007, BIOINFORMATICS TROPI; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Busia A., 2016, arXiv; Cain CE, 2011, GENETICS, V187, P1225, DOI 10.1534/genetics.110.126177; Cang Z. X., 2015, Comput. Math. Biophys., V3, P140, DOI [10.1515/mlbmb-2015-0009, DOI 10.1515/MLBMB-2015-0009]; Cang ZX, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005690; Cao JJ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P397, DOI 10.1109/CIAPP.2017.8167247; Cao RZ, 2017, MOLECULES, V22, DOI 10.3390/molecules22101732; Cao RZ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-016-1405-y; Cao RZ, 2015, BIOINFORMATICS, V31, P116, DOI 10.1093/bioinformatics/btv235; Cao Z., 2017, bioRxiv; Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a; Chen B., 2023, XTRIMOPGLM UNIFIED 1, DOI [10.1101/2023.07.05.547496, DOI 10.1101/2023.07.05.547496]; Chen C, 2019, bioRxiv, DOI [10.1101/648691, 10.1101/648691, DOI 10.1101/648691]; Chen D., 2017, bioRxiv; Chen Jin, 2021, 2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P38, DOI 10.1109/BIBM52615.2021.9669316; Chen JJ, 2018, BRIEF BIOINFORM, V19, P231, DOI 10.1093/bib/bbw108; Chen LJ, 2016, BMC BIOINFORMATICS, V17, DOI 10.1186/s12859-015-0852-1; Chen YF, 2016, BIOINFORMATICS, V32, P1832, DOI 10.1093/bioinformatics/btw074; Cheng C, 2011, GENOME BIOL, V12, DOI 10.1186/gb-2011-12-2-r15; Ching T., 2017, bioRxiv, DOI [10.1098/rsif.2017.0387, DOI 10.1098/RSIF.2017.0387]; Cho Bv, 2014, ARXIV14061078, P1724, DOI 10.3115/v1/d14-1179; Choi J, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3516-8; Chu W., 2004, P 21 INT C MACHINE L, P21; Ciresan DC, 2012, IEEE IJCNN; Cohn D., 2018, bioRxiv; Cui HT, 2023, bioRxiv, DOI [10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439, DOI 10.1101/2023.04.30.538439, 10.1101/2023.04.30.538439v2, DOI 10.1101/2023.04.30.538439V2]; Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860; Dalla-Torre H, 2023, bioRxiv, DOI [10.1101/2023.01.11.523679, 10.1101/2023.01.11.523679, DOI 10.1101/2023.01.11.523679]; Danaee Padideh, 2017, Pac Symp Biocomput, V22, P219, DOI 10.1142/9789813207813_0022; Denas O., 2013, P REPR LEARN ICML WO; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dey T.K., 2018, P 18 INT WORKSH ALG; Dincer AB, 2018, PREPRINT, DOI DOI 10.1101/278739; Dong XJ, 2013, EPIGENOMICS-UK, V5, P113, DOI [10.2217/EPI.13.13, 10.2217/epi.13.13]; Dong XJ, 2012, GENOME BIOL, V13, DOI 10.1186/gb-2012-13-9-r53; Du Z., 2021, P ANN M ASS COMPUTAT; Dunham I, 2012, NATURE, V489, P57, DOI 10.1038/nature11247; Elakkiya R, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.821410; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Elnaggar A., 2021, IEEE Trans. Patern Anal. Mach. Intell, V14, DOI [10.1109/TPAMI.2021.3095381, DOI 10.1109/TPAMI.2021.3095381]; Emanuelsson O, 2000, J MOL BIOL, V300, P1005, DOI 10.1006/jmbi.2000.3903; Eraslan G, 2019, NAT REV GENET, V20, P389, DOI 10.1038/s41576-019-0122-6; Faraggi E, 2012, J COMPUT CHEM, V33, P259, DOI 10.1002/jcc.21968; Fickett JW, 1997, GENOME RES, V7, P861, DOI 10.1101/gr.7.9.861; Firpi HA, 2010, BIOINFORMATICS, V26, P1579, DOI 10.1093/bioinformatics/btq248; Fox NK, 2014, NUCLEIC ACIDS RES, V42, pD304, DOI 10.1093/nar/gkt1240; Frankle J., 2019, P 2019 INT C LEARN R; FUKUSHIMA K, 1975, BIOL CYBERN, V20, P121, DOI 10.1007/BF00342633; Fukushima K., 1982, Neocognitron: A Self-Organizing Neural Network Model for a Mechanism of Visual Pattern Recognition, V45, P267, DOI DOI 10.1007/978-3-642-46466-9_18; Ganin Y, 2016, J MACH LEARN RES, V17; Gao DD, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23663-2; Ghandi M, 2014, PLOS COMPUT BIOL, V10, DOI 10.1371/journal.pcbi.1003711; Ghotra R., 2021, bioRxiv, DOI DOI 10.1101/2021.07.13.452181; Gligorijevic V, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0571; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Gupta A, 2015, IEEE INT C BIOINFORM, P1328, DOI 10.1109/BIBM.2015.7359871; Hammad MS, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30941-0; Hao W, 2016, BIOINFORMATICS, V32, P713, DOI 10.1093/bioinformatics/btv641; Hao YR, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05392-z; Haque MM, 2014, J COMPUT BIOL, V21, P492, DOI 10.1089/cmb.2014.0008; Hawkins John, 2006, Journal of Bioinformatics and Computational Biology, V4, P1, DOI 10.1142/S0219720006001771; He H, 2013, IMBALANCED LEARNING: FOUNDATIONS, ALGORITHMS, AND APPLICATIONS, P1, DOI 10.1002/9781118646106; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hochreiter S, 2007, BIOINFORMATICS, V23, P1728, DOI 10.1093/bioinformatics/btm247; HOLLEY LH, 1989, P NATL ACAD SCI USA, V86, P152, DOI 10.1073/pnas.86.1.152; Horel E, 2020, J MACH LEARN RES, V21; HORTON PB, 1992, NUCLEIC ACIDS RES, V20, P4331, DOI 10.1093/nar/20.16.4331; Hou J, 2019, PROTEINS, V87, P1165, DOI 10.1002/prot.25697; Hou J, 2018, BIOINFORMATICS, V34, P1295, DOI 10.1093/bioinformatics/btx780; Howell K, 2023, Arxiv, DOI arXiv:2306.07402; Hua SJ, 2001, J MOL BIOL, V308, P397, DOI 10.1006/jmbi.2001.4580; Riesselman AJ, 2017, Arxiv, DOI [arXiv:1712.06527, 10.1038/s41592-018-0138-4, DOI 10.1038/S41592-018-0138-4]; Jacobson M, 2004, ANNU REP MED CHEM, V39, P259, DOI 10.1016/S0065-7743(04)39020-2; JAX (The Jackson Laboratory), 2018, Genetics vs. Genomics; Jha A., 2017, bioRxiv, DOI [10.1093/bioinformatics/btx268, DOI 10.1093/BIOINFORMATICS/BTX268]; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Jones DT, 1999, J MOL BIOL, V292, P195, DOI 10.1006/jmbi.1999.3091; Juan-Mateu J, 2016, EUR J ENDOCRINOL, V174, pR225, DOI 10.1530/EJE-15-0916; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; KABSCH W, 1983, BIOPOLYMERS, V22, P2577, DOI 10.1002/bip.360221211; Kang HM, 2010, NAT GENET, V42, P348, DOI 10.1038/ng.548; Karlic R, 2010, P NATL ACAD SCI USA, V107, P2926, DOI 10.1073/pnas.0909344107; Kawai J, 2001, NATURE, V409, P685, DOI 10.1038/35055500; Kelley DR, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1008050; Kelley DR, 2016, GENOME RES, V26, P990, DOI 10.1101/gr.200535.115; Kidron E, 2005, PROC CVPR IEEE, P88; Kim H, 2003, PROTEIN ENG, V16, P553, DOI 10.1093/protein/gzg072; Kimothi D, 2016, Arxiv, DOI arXiv:1608.05949; Kingma Diederik P, 2013, ARXIV13126114, DOI DOI 10.1051/0004-6361/201527329; Kleftogiannis D, 2015, NUCLEIC ACIDS RES, V43, DOI 10.1093/nar/gku1058; KNELLER DG, 1990, J MOL BIOL, V214, P171, DOI 10.1016/0022-2836(90)90154-E; Kobayashi H, 2022, NAT METHODS, V19, P995, DOI 10.1038/s41592-022-01541-z; Koo PK, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1008925; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kryshtafovych A, 2021, PROTEINS, V89, P1607, DOI 10.1002/prot.26237; Kryshtafovych A, 2009, DRUG DISCOV TODAY, V14, P386, DOI 10.1016/j.drudis.2008.11.010; Kundaje A., 2016, Class Lecture, CS 273B: Deep Learning in Genomics and Biomedicine; Kundaje A, 2015, NATURE, V518, P317, DOI 10.1038/nature14248; Lamb J, 2006, SCIENCE, V313, P1929, DOI 10.1126/science.1132939; Lanchantin J., 2016, arXiv; Lanchantin J., 2016, arXiv; Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062; Leaver-Fay A, 2011, METHOD ENZYMOL, P545, DOI [10.1016/B978-0-12-381270-4.00019-6, 10.1016/S0076-6879(11)87019-9]; LeCun Y., 1990, ADV NEURAL INFORM PR, P396, DOI [DOI 10.5555/2969830.2969879, DOI 10.1111/DSU.12130]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee T, 2015, PR MACH LEARN RES, V37, P2483; Lena P.D., 2012, P ADV NEUR INF PROC, P512; Leung MKK, 2016, P IEEE, V104, P176, DOI 10.1109/JPROC.2015.2494198; Leung MKK, 2014, BIOINFORMATICS, V30, P121, DOI 10.1093/bioinformatics/btu277; Li JW, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa159; Li SM, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1842-2; Li Y., 2016, bioRxiv, DOI [10.1186/s12859-018-2187-1, DOI 10.1186/S12859-018-2187-1]; Li YF, 2018, BRIEF BIOINFORM, V19, P325, DOI 10.1093/bib/bbw113; Li YF, 2015, BIOSYSTEMS, V138, P6, DOI 10.1016/j.biosystems.2015.10.002; Li YF, 2015, LECT N BIOINFORMAT, V9029, P205, DOI 10.1007/978-3-319-16706-0_20; Li YM, 2018, Arxiv, DOI arXiv:1610.01206; Li Z, 2016, Arxiv, DOI [arXiv:1604.07176, DOI 10.48550/ARXIV.1604.07176]; Liang MX, 2015, IEEE ACM T COMPUT BI, V12, P928, DOI 10.1109/TCBB.2014.2377729; Liao L, 2003, J COMPUT BIOL, V10, P857, DOI 10.1089/106652703322756113; Libbrecht M.W., 2016, Ph.D. Thesis; Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920; Lim PS, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-10-r107; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Lippert C, 2011, NAT METHODS, V8, P833, DOI [10.1038/nmeth.1681, 10.1038/NMETH.1681]; Liu F, 2016, SCI REP-UK, V6, DOI 10.1038/srep28517; Liu J, 2022, PROTEINS, V90, P58, DOI 10.1002/prot.26186; Liu T, 2016, SCI REP-UK, V6, DOI 10.1038/srep19301; Lo Conte L, 2000, NUCLEIC ACIDS RES, V28, P257, DOI 10.1093/nar/28.1.257; Louizos C, 2017, ADV NEUR IN, V30; Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010; Maaten L., 2011, Proc. International Conference on Artificial Intelligence and Statistics, P479; Magnan CN, 2014, BIOINFORMATICS, V30, P2592, DOI 10.1093/bioinformatics/btu352; Matis S, 1996, COMPUT CHEM, V20, P135, DOI 10.1016/S0097-8485(96)80015-5; Mei SY, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079606; Meiken J., 2012, Computational Molecular Biology, V2, P1, DOI [10.5376/cmb.2012.02.0001, DOI 10.5376/CMB.2012.02.0001]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068; Min X, 2016, IEEE INT C BIOINFORM, P637, DOI 10.1109/BIBM.2016.7822593; Mitchell M., 2017, Deep Genomics Applies Machine Learning to Develop New Genetic Medicines; Moon S, 2016, Arxiv, DOI arXiv:1412.3121; Mooney C, 2011, BIOINFORMATICS, V27, P2812, DOI 10.1093/bioinformatics/btr494; Nature, 2010, Gene Expression; Ng P, 2017, Arxiv, DOI [arXiv:1701.06279, DOI 10.48550/ARXIV.1701.06279]; Nguyen E., 2023, HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution; Le NQK, 2022, PROTEOMICS, V22, DOI 10.1002/pmic.202100232; Nguyen SP, 2014, IEEE IJCNN, P2071, DOI 10.1109/IJCNN.2014.6889891; Nissen JN, 2021, NAT BIOTECHNOL, V39, P555, DOI 10.1038/s41587-020-00777-4; Öztornaci RO, 2023, bioRxiv, DOI [10.1101/2023.01.05.522884, 10.1101/2023.01.05.522884, DOI 10.1101/2023.01.05.522884]; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Pan XY, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1561-8; Park DW, 2005, LECT NOTES COMPUT SC, V3689, P691; Pärnamaa T, 2017, G3-GENES GENOM GENET, V7, P1385, DOI 10.1534/g3.116.033654; PAULING L, 1951, P NATL ACAD SCI USA, V37, P205, DOI 10.1073/pnas.37.4.205; PEARSON WR, 1988, P NATL ACAD SCI USA, V85, P2444, DOI 10.1073/pnas.85.8.2444; Pierleoni A, 2006, BIOINFORMATICS, V22, pE408, DOI 10.1093/bioinformatics/btl222; Poli M, 2023, Arxiv, DOI arXiv:2302.10866; Pollastri G, 2002, PROTEINS, V47, P228, DOI 10.1002/prot.10082; Qi YJ, 2010, BIOINFORMATICS, V26, pi645, DOI 10.1093/bioinformatics/btq394; Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5; Qin Q, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005403; Quang D, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw226; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer; Rampasek L., 2017, arXiv; Rangwala H, 2005, BIOINFORMATICS, V21, P4239, DOI 10.1093/bioinformatics/bti687; Rashid S, 2021, BIOINFORMATICS, V37, P1535, DOI 10.1093/bioinformatics/btz095; Ray A, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-224; Riis SK, 1996, J COMPUT BIOL, V3, P163, DOI 10.1089/cmb.1996.3.163; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; ROST B, 1994, J MOL BIOL, V235, P13, DOI 10.1016/S0022-2836(05)80007-5; ROST B, 1993, J MOL BIOL, V232, P584, DOI 10.1006/jmbi.1993.1413; ROST B, 1993, P NATL ACAD SCI USA, V90, P7558, DOI 10.1073/pnas.90.16.7558; Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, DOI 10.48550/ARXIV.1706.05098]; Ruff KM, 2021, J MOL BIOL, V433, DOI 10.1016/j.jmb.2021.167208; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Schmidler SC, 2000, J COMPUT BIOL, V7, P233, DOI 10.1089/10665270050081496; Schreiber J, 2018, bioRxiv; Schulman J, 2022, Introducing chatgpt; Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093; Schweikert G., 2009, ADV NEURAL INFORM PR, P1433; Senior AW, 2020, NATURE, V577, P706, DOI 10.1038/s41586-019-1923-7; Setty M, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004271; Shao W, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101795; Sharifi-Noghabi H., 2018, bioRxiv, DOI [10.1101/276055, DOI 10.1101/276055]; Shatkay H, 2007, BIOINFORMATICS, V23, P1410, DOI 10.1093/bioinformatics/btm115; Shen Z, 2022, IEEE ACM T COMPUT BI, V19, P753, DOI 10.1109/TCBB.2020.3007544; Shin WH, 2017, SCI REP-UK, V7, DOI 10.1038/srep40629; Shrikumar A., 2017, BIORXIV; Shrikumar A, 2017, PR MACH LEARN RES, V70; Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]; Singh R, 2017, ADV NEUR IN, V30; Singh R, 2016, BIOINFORMATICS, V32, P639, DOI 10.1093/bioinformatics/btw427; Singh S., 2016, bioRxiv, DOI [10.1007/s40484-019-0154-0, DOI 10.1007/S40484-019-0154-0]; Sonderby Soren Kaae, 2015, Algorithms for Computational Biology. Second International Conference, AlCoB 2015. Proceedings: LNCS 9199, P68, DOI 10.1007/978-3-319-21233-3_6; Song MS, 2015, NAT GENET, V47, P550, DOI 10.1038/ng.3244; Spencer M, 2015, IEEE ACM T COMPUT BI, V12, P103, DOI 10.1109/TCBB.2014.2343960; Stahl K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1713-x; Steinegger M, 2019, NAT METHODS, V16, P603, DOI 10.1038/s41592-019-0437-4; Stephens ZD, 2015, PLOS BIOL, V13, DOI 10.1371/journal.pbio.1002195; Stevens AO, 2022, BIOMOLECULES, V12, DOI 10.3390/biom12070985; Stormo GD, 2000, BIOINFORMATICS, V16, P16, DOI 10.1093/bioinformatics/16.1.16; Sun Q, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-350; Suzek BE, 2015, BIOINFORMATICS, V31, P926, DOI 10.1093/bioinformatics/btu739; Svozil D, 1997, CHEMOMETR INTELL LAB, V39, P43, DOI 10.1016/S0169-7439(97)00061-0; Tan J., 2017, bioRxiv; Tan J, 2016, MSYSTEMS, V1, DOI 10.1128/mSystems.00025-15; Tan J, 2015, BIOCOMPUT-PAC SYM, P132; Torng W, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1702-0; Torracinta R., 2016, bioRxiv; Tran D, 2017, Arxiv, DOI arXiv:1710.10742; Tran TO, 2024, BRIEF FUNCT GENOMICS, V23, P181, DOI 10.1093/bfgp/elad031; Tsimenidis S, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms232012272; Uffelmann E, 2021, NAT REV METHOD PRIME, V1, DOI 10.1038/s43586-021-00056-9; Umarov RK, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0171410; Urda D, 2017, LECT NOTES COMPUT SC, V10306, P50, DOI 10.1007/978-3-319-59147-6_5; Uziela K, 2017, BIOINFORMATICS, V33, P1578, DOI 10.1093/bioinformatics/btw819; Uziela K, 2016, SCI REP-UK, V6, DOI 10.1038/srep33509; Vaswani A, 2017, ADV NEUR IN, V30; Vincent P., 2008, PROC 25 INT C MACH L, P1096, DOI [DOI 10.1145/1390156.1390294, 10.1145/1390156.1390294]; Wan S., 2015, Machine Learning for Protein Subcellular Localization Prediction, DOI 10.1515/9781501501500; Wang H., 2017, bioRxiv; Wang HH, 2018, Arxiv, DOI arXiv:1803.07276; Wang HH, 2017, IEEE INT CON MULTI, P949, DOI 10.1109/ICME.2017.8019301; Wang HH, 2017, INT J DATA MIN BIOIN, V17, P279, DOI 10.1504/IJDMB.2017.10006873; Wang Q, 2022, AAAI CONF ARTIF INTE, P4620; Wang S, 2016, SCI REP-UK, V6, DOI 10.1038/srep18962; Wang S, 2017, PLOS COMPUT BIOL, V13, DOI 10.1371/journal.pcbi.1005324; Wang YS, 2022, PROTEOMICS, V22, DOI 10.1002/pmic.202100161; Wang YH, 2016, SCI REP-UK, V6, DOI 10.1038/srep19598; Wang ZQ, 2021, BIOINFORMATICS, V37, P2963, DOI 10.1093/bioinformatics/btab185; Ward JJ, 2003, BIOINFORMATICS, V19, P1650, DOI 10.1093/bioinformatics/btg223; Wasserman WW, 2004, NAT REV GENET, V5, P276, DOI 10.1038/nrg1315; WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0; Weinstein JN, 2013, NAT GENET, V45, P1113, DOI 10.1038/ng.2764; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6; Weissenow K, 2022, bioRxiv, DOI [10.1101/2022.11.14.516473, 10.1101/2022.11.14.516473, DOI 10.1101/2022.11.14.516473V2, 10.1101/2022.11.14.516473v2]; Whalen S, 2016, NAT GENET, V48, P488, DOI 10.1038/ng.3539; Widmer Christian., 2011, P ICML WORKSH UNS TR, V27, P207; Wong Ka-Chun, 2019, Biophys Rev, V11, P51, DOI 10.1007/s12551-018-0493-5; Wu R., 2022, BIORXIV, DOI [10.1101/2022.07.21.500999, DOI 10.1101/2022.07.21.500999]; Wu TQ, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-03960-9; Xie R, 2017, BMC GENOMICS, V18, DOI 10.1186/s12864-017-4226-0; Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806; Xiong HY, 2011, BIOINFORMATICS, V27, P2554, DOI 10.1093/bioinformatics/btr444; Xu Q., 2011, Journal of Computing Science and Engineering, V5, P257, DOI 10.5626/JCSE.2011.5.3.257; Xuan P, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00416; Yang B, 2017, BIOINFORMATICS, V33, P1930, DOI 10.1093/bioinformatics/btx105; Yang F, 2022, NAT MACH INTELL, V4, P852, DOI 10.1038/s42256-022-00534-z; Yang J, 2014, NAT GENET, V46, P100, DOI 10.1038/ng.2876; Yang JY, 2020, P NATL ACAD SCI USA, V117, P1496, DOI 10.1073/pnas.1914677117; Yang WJ, 2013, NUCLEIC ACIDS RES, V41, pD955, DOI 10.1093/nar/gks1111; Yeung KY, 2001, BIOINFORMATICS, V17, P763, DOI 10.1093/bioinformatics/17.9.763; Yoon K, 2005, HIS 2005: 5TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, PROCEEDINGS, P303; Yu JM, 2006, NAT GENET, V38, P203, DOI 10.1038/ng1702; Yuan Y, 2007, PLOS COMPUT BIOL, V3, P2391, DOI 10.1371/journal.pcbi.0030243; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zemla A, 1999, PROTEINS, V34, P220, DOI 10.1002/(SICI)1097-0134(19990201)34:2<220::AID-PROT7>3.0.CO;2-K; Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255; Zhang HC, 2020, BMC GENOMICS, V21, DOI 10.1186/s12864-020-07249-8; Zhang L, 2023, Arxiv, DOI arXiv:2306.01824; Zhang S, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkv1025; Zhang WL, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1475, DOI [10.1109/tbdata.2016.2573280, 10.1145/2783258.2783304]; Zhang Y., 2017, bioRxiv; Zhou J, 2018, NAT GENET, V50, P1171, DOI 10.1038/s41588-018-0160-6; Zhou J, 2015, NAT METHODS, V12, P931, DOI [10.1038/NMETH.3547, 10.1038/nmeth.3547]; Zhou J, 2014, INT CONF MACH LEARN, P71, DOI 10.1109/ICMLC.2014.7009094; Zhou Z., 2023, Dnabert-2: Efficient foundation model and benchmark for multi-species genome; Zvyagin M.T., 2022, bioRxiv, DOI [10.1177/10943420231201154, DOI 10.1177/10943420231201154]	304	3	3	31	37	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1661-6596	1422-0067		INT J MOL SCI	Int. J. Mol. Sci.	NOV	2023	24	21							15858	10.3390/ijms242115858	http://dx.doi.org/10.3390/ijms242115858			35	Biochemistry & Molecular Biology; Chemistry, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Chemistry	X6GV8	37958843	gold, Green Published			2024-07-03	WOS:001099423600001
J	Wyatt, KD; Alexander, N; Hills, GD; Liang, WH; Kadauke, S; Volchenboum, SL; Mian, A; Phillips, CA				Wyatt, Kirk D.; Alexander, Natasha; Hills, Gerard D.; Liang, Wayne H.; Kadauke, Stephan; Volchenboum, Samuel L.; Mian, Amir; Phillips, Charles A.			Making sense of artificial intelligence and large language models-including ChatGPT-in pediatric hematology/oncology	PEDIATRIC BLOOD & CANCER			English	Article; Early Access						artificial intelligence; ChatGPT; large language models; pediatric hematology; pediatric oncology		ChatGPT and other artificial intelligence (AI) systems have captivated the attention of healthcare providers and researchers for their potential to improve care processes and outcomes. While these technologies hold promise to automate processes, increase efficiency, and reduce cognitive burden, their use also carries risks. In this commentary, we review basic concepts of AI, outline some of the capabilities and limitations of currently available tools, discuss current and future applications in pediatric hematology/oncology, and provide an evaluation and implementation framework that can be used by pediatric hematologist/oncologists considering the use of AI in clinical practice.	[Wyatt, Kirk D.] Roger Maris Canc Ctr, Dept Pediat Hematol Oncol, Fargo, ND USA; [Wyatt, Kirk D.; Volchenboum, Samuel L.] Univ Chicago, Data Common Good, Chicago, IL USA; [Alexander, Natasha] Univ Toronto, Hosp Sick Children, Dept Pediat, Div Pediat Hematol Oncol, Toronto, ON, Canada; [Hills, Gerard D.] Indiana Univ Sch Med, Dept Pediat, Indianapolis, IN USA; [Hills, Gerard D.] Regenstrief Inst Hlth Care, Indianapolis, IN USA; [Hills, Gerard D.] Indiana Univ Hlth, Riley Childrens Hlth, Indianapolis, IN USA; [Liang, Wayne H.] Childrens Healthcare Atlanta, Aflac Canc & Blood Disorders Ctr, Atlanta, GA USA; [Liang, Wayne H.] Emory Univ, Atlanta, GA USA; [Kadauke, Stephan] Univ Penn, Dept Pathol & Lab Med, Philadelphia, PA USA; [Kadauke, Stephan] Childrens Hosp Philadelphia, Cell & Gene Therapy Informat, Philadelphia, PA USA; [Volchenboum, Samuel L.] Univ Chicago, Dept Pediat, Chicago, IL USA; [Mian, Amir] Childrens Hosp, Dept Pediat, Div Pediat Hematol Oncol, Austin, TX USA; [Mian, Amir] Univ Texas Austin, Dell Med Sch, Austin, TX USA; [Phillips, Charles A.] Univ Penn, Dept Pediat, Philadelphia, PA USA; [Phillips, Charles A.] Childrens Hosp Philadelphia, Dept Biomed & Hlth Informat, Philadelphia, PA USA	University of Chicago; University of Toronto; Hospital for Sick Children (SickKids); Indiana University System; Indiana University Bloomington; Regenstrief Institute Inc; Indiana University Health; James Whitcomb Riley Hospital Children; IU Health University Hospital; Children's Healthcare of Atlanta (CHOA); Emory University; University of Pennsylvania; University of Pennsylvania; Pennsylvania Medicine; Childrens Hospital of Philadelphia; University of Chicago; University of Texas System; University of Texas Austin; University of Pennsylvania; University of Pennsylvania; Pennsylvania Medicine; Childrens Hospital of Philadelphia	Phillips, CA (corresponding author), 734 Schuykill Ave,Off 11363, Philadelphia, PA 19146 USA.	phillipsc2@chop.edu	Liang, Wayne H/ADF-5362-2022	Liang, Wayne H/0000-0003-2354-9787				Abràmoff MD, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00913-9; Alexander N, 2022, JMIR MED INF, V10, DOI 10.2196/40039; Alrassi J, 2021, ACAD MED, V96, P37, DOI 10.1097/ACM.0000000000003733; Anastasijevic D., 2020, Mayo Clinic News Network ; October 28,; [Anonymous], Artificial Intelligence: An Accountability Framework for Federal Agencies and Other Entities; [Anonymous], AMA issues new principles for AI development, deployment & use; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beam AL, 2023, NEW ENGL J MED, V388, P1220, DOI 10.1056/NEJMe2206291; Cai S, 2021, JAMA OPHTHALMOL, V139, P206, DOI 10.1001/jamaophthalmol.2020.5900; Cao LS, 2023, PEDIATR BLOOD CANCER, V70, DOI 10.1002/pbc.30260; Capper D, 2018, NATURE, V555, P469, DOI 10.1038/nature26000; Carrillo-Reixach J, 2020, J HEPATOL, V73, P328, DOI 10.1016/j.jhep.2020.03.025; Chaix MA, 2020, JACC-CARDIOONCOL, V2, P690, DOI 10.1016/j.jaccao.2020.11.004; Chang AL, 2020, Arxiv, DOI [arXiv:2006.00727, 10.48550/ARXIV.2006.00727, DOI 10.48550/ARXIV.2006.00727]; Dehkharghanian T, 2023, INT J LAB HEMATOL, V45, P87, DOI 10.1111/ijlh.14110; Frankel AO, 2022, MODERN PATHOL, V35, P1193, DOI 10.1038/s41379-022-01075-x; Frood R, 2022, EUR RADIOL, V32, P7237, DOI 10.1007/s00330-022-09039-0; Gerhart J., American Medical Informatics Association Clinical Informatics Conference; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Hantel A, 2024, JAMA NETW OPEN, V7, DOI 10.1001/jamanetworkopen.2024.4077; Johnson A, 2019, JMIR MHEALTH UHEALTH, V7, DOI 10.2196/13671; Kann BH, 2021, CANCER CELL, V39, P916, DOI 10.1016/j.ccell.2021.04.002; Kumah-Crystal YA, 2024, APPL CLIN INFORM, V15, P199, DOI 10.1055/a-2177-4420; Kwong JCC, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.929508; Lazer D, 2014, SCIENCE, V343, P1203, DOI 10.1126/science.1248506; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu GB, 2022, J DIGIT IMAGING, V35, P605, DOI 10.1007/s10278-022-00607-w; Liu ZQ, 2022, AM J TRANSL RES, V14, P6210; Locke T., 2022, Preventing bias and inequities in AIenabled health tools; Loh E, 2024, BMJ LEAD, V8, P51, DOI 10.1136/leader-2023-000797; Lohr S., 2023, The New York Times . June 26,; Manescu P, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29160-4; Mayampurath A, 2021, JCO CLIN CANCER INFO, V5, P1181, DOI 10.1200/CCI.21.00103; Medenilla A., 2023, PLoS Digital Health, V2; Miao HY, 2023, J MED INTERNET RES, V25, DOI 10.2196/49963; Milewski D, 2023, CLIN CANCER RES, V29, P364, DOI 10.1158/1078-0432.CCR-22-1663; Naushad SM, 2019, CANCER CHEMOTH PHARM, V83, P875, DOI 10.1007/s00280-019-03803-8; Omoumi P, 2021, EUR RADIOL, V31, P3786, DOI 10.1007/s00330-020-07684-x; Osheroff J.A., 2012, IMPROVING OUTCOMES C; Ramesh S, 2021, JCO CLIN CANCER INFO, V5, P1208, DOI 10.1200/CCI.21.00102; Ratcliffe S., 2016, Oxford Essential Quotations, V4th; Sheikh H., 2023, Mission AI. Research for Policy, P15, DOI DOI 10.1007/978-3-031-21448-62; Siddique SM, 2024, ANN INTERN MED, V177, DOI 10.7326/M23-2960; Stephens LD, 2023, TRANSFUS MED REV, V37, DOI 10.1016/j.tmrv.2023.150753; Walker SC, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.37789; Wong A, 2021, JAMA INTERN MED, V181, P1065, DOI 10.1001/jamainternmed.2021.2626; World Health Organization (WHO), 2021, Ethics and Governance of Artificial Intelligence for Health; Yang Yuhan, 2023, Explor Target Antitumor Ther, V4, P157, DOI 10.37349/etat.2023.00127; Zhan M, 2021, LEUKEMIA LYMPHOMA, V62, P2502, DOI 10.1080/10428194.2021.1913140; Zhang M, 2022, RADIOLOGY, V304, P406, DOI 10.1148/radiol.212137	51	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1545-5009	1545-5017		PEDIATR BLOOD CANCER	Pediatr. Blood Cancer	2024 JUN 26	2024										10.1002/pbc.31143	http://dx.doi.org/10.1002/pbc.31143		JUN 2024	10	Oncology; Hematology; Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Oncology; Hematology; Pediatrics	WI3T3	38924670				2024-07-03	WOS:001254208400001
J	Kumar, S; Deepika, D; Slater, K; Kumar, V				Kumar, Saurav; Deepika, Deepika; Slater, Karin; Kumar, Vikas			AOPWIKI-EXPLORER: An interactive graph-based query engine leveraging large language models	COMPUTATIONAL TOXICOLOGY			English	Article						Adverse outcome pathway; Large language model; Graph database; Risk assessment; Artificial intelligence; Data integration; Information retrieval; Information extraction	ONTOLOGY; DATABASE	Adverse Outcome Pathways (AOPs) provide a basis for non-animal testing, by outlining the cascade of molecular and cellular events initiated upon stressor exposure, leading to adverse effects. In recent years, the scientific community has shown interest in developing AOPs through crowdsourcing, with the results archived in the AOPWiki: a centralized repository coordinated by the OECD, hosting nearly 512 AOPs (April, 2023). However, the AOP-Wiki platform currently lacks a versatile querying system, which hinders developers ' exploration of the AOP network and impedes its practical use in risk assessment. This work proposes to unleash the full potential of the AOP-Wiki archive by adapting its data into a Labelled Property Graph (LPG) schema. Additionally, the tool offers a visual network query interface for both database-specific and natural language queries, facilitating the retrieval and analysis of graph data. The multi-query interface allows non-technical users to construct flexible queries, thereby enhancing the potential for AOP exploration. By reducing the time and technical requirements, the present query engine enhances the practical utilization of the valuable data within AOP-Wiki. To evaluate the platform, a case study is presented with three levels of use-case scenarios (simple, moderate, and complex queries). AOPWIKI-EXPLORER is freely available on GitHub (https://github.com/Crispae/AOPWiki_Explorer) for wider community reach and further enhancement.	[Kumar, Saurav; Deepika, Deepika; Kumar, Vikas] Univ Rovira & Virgili, Hosp Univ St Joan Reus, IISPV, Reus, Spain; [Kumar, Vikas] German Fed Inst Risk Assessment BfR, Berlin, Germany; [Slater, Karin] Univ Birmingham, Ctr Environm Res & Justice, Birmingham, England	Universitat Rovira i Virgili; Institut d'Investigacio Sanitaria Pere Virgili (IISPV); Federal Institute for Risk Assessment; University of Birmingham	Kumar, V (corresponding author), Univ Rovira & Virgili, Hosp Univ St Joan Reus, IISPV, Reus, Spain.	vikas.kumar@urv.cat			Partnership for the Assessment of Risk from Chemicals (PARC); European Union's Horizon Europe research and innovation Programme [101057014]	Partnership for the Assessment of Risk from Chemicals (PARC); European Union's Horizon Europe research and innovation Programme	The work done here has been supported by the Partnership for the Assessment of Risk from Chemicals (PARC) funding by the European Union's Horizon Europe research and innovation Programme under Grant Agreement No. 101057014.	Amberger JS, 2019, NUCLEIC ACIDS RES, V47, pD1038, DOI 10.1093/nar/gky1151; Ankley GT, 2010, ENVIRON TOXICOL CHEM, V29, P730, DOI 10.1002/etc.34; [Anonymous], React; [Anonymous], FDI Lab-SciCrunch.org; [Anonymous], neosemantics (n10s):Neo4j RDF & Semantics toolkit-Neo4j Labs; [Anonymous], SciGraph/SciGraph: A Neo4j backed ontology store; [Anonymous], Neovis.js; [Anonymous], Chroma; [Anonymous], Neo4j; [Anonymous], Users' Handbook supplement to the Guidance Document for developing and assessing Adverse Outcome Pathways | OECD Series on Adverse Outcome Pathways; [Anonymous], Langchain; Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Barrasa J., RDF Triple Stores vs. Labeled Property Graphs: What's the Difference?; Costa RL, 2017, PEERJ, V5, DOI 10.7717/peerj.3509; Cucen E., Making Sense of Data with RDF* vs. LPG-OpenCredo; Dai XB, 2016, PLANT CELL PHYSIOL, V57, DOI 10.1093/pcp/pcv200; Demir E, 2010, NAT BIOTECHNOL, V28, P935, DOI 10.1038/nbt.1666; Gillespie M, 2022, NUCLEIC ACIDS RES, V50, pD687, DOI 10.1093/nar/gkab1028; Hastings J, 2013, NUCLEIC ACIDS RES, V41, pD456, DOI 10.1093/nar/gks1146; Ives Cataia, 2017, Appl In Vitro Toxicol, V3, P298, DOI 10.1089/aivt.2017.0017; Knapen D, 2018, ENVIRON TOXICOL CHEM, V37, P1723, DOI 10.1002/etc.4125; Leydesdorff L, 2016, SCIENTOMETRICS, V109, P2077, DOI 10.1007/s11192-016-2119-7; Mami M.N., 2019, Query Translation Landscape: A Survey; Martens Marvin, 2022, Appl In Vitro Toxicol, V8, P2, DOI 10.1089/aivt.2021.0010; Mei SQ, 2020, DATABASE-OXFORD, DOI 10.1093/database/baz162; MerkelDirk, 2014, Docker. Linux J., DOI [10.5555/2600239.2600241, DOI 10.5555/2600239.2600241]; Mortensen HM, 2022, FRONT TOXICOL, V4, DOI 10.3389/ftox.2022.803983; Mungall CJ, 2017, NUCLEIC ACIDS RES, V45, pD712, DOI 10.1093/nar/gkw1128; OpenAI, 2023, GPT-4 Technical Report; Purohit S., 2020, Semantic Property Graph for Scalable Knowledge Graph Analytics; PyPI, Py2neo; PyPI, XML2Dict; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Romano JD, 2022, CHEM RES TOXICOL, V35, P1370, DOI 10.1021/acs.chemrestox.2c00074; Salles A, 2019, NEURON, V101, P380, DOI 10.1016/j.neuron.2019.01.005; Sayers EW, 2022, NUCLEIC ACIDS RES, V50, pD20, DOI 10.1093/nar/gkab1112; Sung M, 2022, BIOINFORMATICS, V38, P4837, DOI 10.1093/bioinformatics/btac598; Tang X., 2023, Symbolic Reasoners; Timón-Reina S, 2021, DATABASE-OXFORD, DOI 10.1093/database/baab026; Unni DR, 2022, CTS-CLIN TRANSL SCI, V15, P1848, DOI 10.1111/cts.13302; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Vicknair Chad., 2010, A comparison of a Graph Database and a Relational Database - A Data Provenance Perspective, DOI [10.1145/1900008.1900067, DOI 10.1145/1900008.1900067]; Villeneuve DL, 2018, ENVIRON TOXICOL CHEM, V37, P1734, DOI 10.1002/etc.4124; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Wittwehr C, 2024, ALTEX-ALTERN ANIM EX, V41, P50, DOI 10.14573/altex.2307131	45	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2468-1113			COMPUT TOXICOL	Comput. Toxicol.	JUN	2024	30								100308	10.1016/j.comtox.2024.100308	http://dx.doi.org/10.1016/j.comtox.2024.100308			11	Toxicology	Emerging Sources Citation Index (ESCI)	Toxicology	QK6D6		hybrid, Green Submitted			2024-07-03	WOS:001220797900001
J	Quinonez, C; Meij, E				Quinonez, Claudia; Meij, Edgar			A new era of AI-assisted journalism at Bloomberg	AI MAGAZINE			English	Article								Artificial intelligence (AI) is impacting and has the potential to upend entire business models and structures. The adoption of such new technologies to support newsgathering processes is established practice for newsrooms. For AI specifically, we are seeing a new era of AI-assisted journalism emerge with trust in the AI-driven analyses and accuracy of results as core tenets.In Part I of this position paper, we discuss the contributions of six recently published research papers co-authored by Bloomberg's Artificial Intelligence Engineering team that show the intricacies of training AI models for reliable newsgathering processes. The papers investigate (a) the creation of models for updated headline generation, showing that headline generation models benefit from access to the past state of the article, (b) sequentially controlled text generation, which is a novel task and we show that in general, more structured awareness results in higher control accuracy and grammatical coherence, (c) chart summarization, which looks into identifying the key message and generating sentences that describe salient information in the multimodal documents, (d) a semistructured natural language inference task to develop a framework for data augmentation for tabular inference, (e) the introduction of a human-annotated dataset (ENTSUM) for controllable summarization with a focus on named entities as the aspect to control, and (f) a novel defense mechanism against adversarial attacks (ATINTER). We also examine Bloomberg's research work, building its own internal, not-for-commercial-use large language model, BloombergGPT, and training it with the goal of demonstrating support for a wide range of tasks within the financial industry.In Part II, we analyze the evolution of automation tasks in the Bloomberg newsroom that led to the creation of Bloomberg's News Innovation Lab. Technology-assisted content creation has been a reality at Bloomberg News for nearly a decade and has evolved from rules-based headline generation from structured files to the constant exploration of potential ways to assist story creation and storytelling in the financial domain. The Lab now oversees the operation of hundreds of software bots that create semi- and fully automated stories of financial relevance, providing journalists with depth in terms of data and analysis, speed in terms of reacting to breaking news, and transparency to corners of the financial world where data investigation is a gigantic undertaking. The Lab recently introduced new tools that provide journalists with the ability to explore automation on demand while it continues to experiment with ways to assist story production.In Part III, we conceptually discuss the transformative impact that generative AI can have in any newsroom, along with considerations about the technology's shortcomings in its current state of development. As with any revolutionary new technology, as well as with exciting research opportunities, part of the challenge is balancing any potential positive and negative impacts on society. We offer our principles and guidelines used to inform our approach to experimenting with the new generative AI technologies. Bloomberg News' style guide reminds us that our "journalism is aimed at possibly the most sophisticated audience in the world, for whom accuracy is essential."	[Quinonez, Claudia; Meij, Edgar] Bloomberg, London, England		Quinonez, C; Meij, E (corresponding author), Bloomberg, London, England.	cquinonez1@bloomberg.net; emeij@bloomberg.net		Meij, Edgar/0000-0003-0516-3688				Capponi A., MACHINE LEARNING DAT; Gupta A, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P13981; Kumar D., 2022, FINDINGS ASS COMPUTA, P4440; Maddela M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3355; Micklethwait J., 2017, BLOOMBERG WAY GUIDE; Panthaplackel S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6438; Spangher A., 2022, FINDINGS ASS COMPUTA, P6848; Tan H., 2022, 3 WORKSHOP SCI DOCUM; Wu S., 2023, ARXIV	9	0	0	5	5	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602	2371-9621		AI MAG	AI Mag.	JUN	2024	45	2			SI		187	199		10.1002/aaai.12181	http://dx.doi.org/10.1002/aaai.12181		JUN 2024	13	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	US6A3		hybrid			2024-07-03	WOS:001238822200001
J	Ghanadian, H; Nejadgholi, I; Al Osman, H				Ghanadian, Hamideh; Nejadgholi, Isar; Al Osman, Hussein			Socially Aware Synthetic Data Generation for Suicidal Ideation Detection Using Large Language Models	IEEE ACCESS			English	Article						Artificial intelligence; deep learning; large language models; suicide detection; synthetic data generation; transformer based models	RISK-FACTORS; MENTAL-HEALTH; BEHAVIORS; DEPRESSION; THOUGHTS; MEMBERS	Suicidal ideation detection is a vital research area that holds great potential for improving mental health support systems. However, the sensitivity surrounding suicide-related data poses challenges in accessing large-scale, annotated datasets necessary for training effective machine learning models. To address this limitation, we introduce an innovative strategy that leverages the capabilities of generative AI models, such as ChatGPT, Flan-T5, and Llama, to create synthetic data for suicidal ideation detection. Our data generation approach is grounded in social factors extracted from psychology literature and aims to ensure coverage of essential information related to suicidal ideation. In our study, we benchmarked against state-of-the-art NLP classification models, specifically, those centered around the BERT family structures. When trained on the real-world dataset, UMD, these conventional models tend to yield F1-scores ranging from 0.75 to 0.87. Our synthetic data-driven method, informed by social factors, offers consistent F1-scores of 0.82 for both models, suggesting that the richness of topics in synthetic data can bridge the performance gap across different model complexities. Most impressively, when we combined a mere 30% of the UMD dataset with our synthetic data, we witnessed a substantial increase in performance, achieving an F1-score of 0.88 on the UMD test set. Such results underscore the cost-effectiveness and potential of our approach in confronting major challenges in the field, such as data scarcity and the quest for diversity in data representation.	[Ghanadian, Hamideh; Al Osman, Hussein] Univ Ottawa, Dept Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada; [Nejadgholi, Isar] Natl Res Council Canada, Ottawa, ON, Canada	University of Ottawa; National Research Council Canada	Ghanadian, H (corresponding author), Univ Ottawa, Dept Elect Engn & Comp Sci, Ottawa, ON K1N 6N5, Canada.	Hghan053@uOttawa.ca	Ghanadian, Hamideh/AAA-3834-2021	Ghanadian, Hamideh/0000-0002-5203-3504				Abdulsalam Asma, 2022, arXiv; Allchin A, 2019, INJURY PREV, V25, pi44, DOI 10.1136/injuryprev-2018-042809; Babbar R, 2019, MACH LEARN, V108, P1329, DOI 10.1007/s10994-019-05791-5; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bejan CA, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-19358-3; Bentley KH, 2016, CLIN PSYCHOL REV, V43, P30, DOI 10.1016/j.cpr.2015.11.008; Boergers J, 1998, J AM ACAD CHILD PSY, V37, P1287, DOI 10.1097/00004583-199812000-00012; Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863; Chau Hung., 2020, P 14 LINGUISTIC ANNO, P74; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Colombo GB, 2016, COMPUT COMMUN, V73, P291, DOI 10.1016/j.comcom.2015.07.018; Costa LD, 2015, J AFFECT DISORDERS, V170, P237, DOI 10.1016/j.jad.2014.09.003; Cramer RJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01756; De Berardis D, 2018, FRONT PSYCHIATRY, V9, DOI 10.3389/fpsyt.2018.00061; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Farabaugh A, 2012, PSYCHOPATHOLOGY, V45, P228, DOI 10.1159/000331598; Fareed MMS, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3687598; Fernandes AC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-25773-2; Franklin JC, 2017, PSYCHOL BULL, V143, P187, DOI 10.1037/bul0000084; Gaur M, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P514, DOI 10.1145/3308558.3313698; Ghanadian H, 2023, Arxiv, DOI arXiv:2306.09390; He XL, 2022, T ASSOC COMPUT LING, V10, P826, DOI 10.1162/tacl_a_00492; Holt-Lunstad J, 2015, PERSPECT PSYCHOL SCI, V10, P227, DOI 10.1177/1745691614568352; Hovey J D, 2000, Cultur Divers Ethnic Minor Psychol, V6, P134, DOI 10.1037/1099-9809.6.2.134; Hovy D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P588; Hsiung RC, 2007, CYBERPSYCHOL BEHAV, V10, P495, DOI 10.1089/cpb.2007.9999; Hu Ziniu, 2022, P 2022 C EMPIRICAL M, P9562; Jashinsky J, 2014, CRISIS, V35, P51, DOI 10.1027/0227-5910/a000234; Kalin NH, 2020, AM J PSYCHIAT, V177, P877, DOI 10.1176/appi.ajp.2020.20081207; Keum BT, 2023, INT J SOC PSYCHIATR, V69, P342, DOI 10.1177/00207640221089536; Kleiman EM, 2017, J ABNORM PSYCHOL, V126, P726, DOI 10.1037/abn0000273; Klonsky ED, 2016, ANNU REV CLIN PSYCHO, V12, P307, DOI 10.1146/annurev-clinpsy-021815-093204; Kodati D, 2023, APPL INTELL, V53, P11885, DOI 10.1007/s10489-022-04060-8; Kumar ER, 2023, SOFT COMPUT, DOI 10.1007/s00500-023-08095-y; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lázaro-Pérez C, 2023, J CLIN MED, V12, DOI 10.3390/jcm12031207; Lee JI, 2010, J FORMOS MED ASSOC, V109, P138, DOI 10.1016/S0929-6646(10)60034-4; Lee KH, 2017, J EVID-INFORM SOC WO, V14, P229, DOI 10.1080/23761407.2017.1316221; Leigh-Hunt N, 2017, PUBLIC HEALTH, V152, P157, DOI 10.1016/j.puhe.2017.07.035; Li ZP, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040442; Lu YZ, 2024, Arxiv, DOI arXiv:2302.04062; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mi F, 2022, Arxiv, DOI arXiv:2203.17090; Nikolenko S. I., 2021, Synthetic Data for Deep Learning, V174; Okolie C, 2017, INT PSYCHOGERIATR, V29, P1801, DOI 10.1017/S1041610217001430; Orsolini L, 2020, PSYCHIAT INVEST, V17, P207, DOI 10.30773/pi.2019.0171; Paris J, 2019, MEDICINA-LITHUANIA, V55, DOI 10.3390/medicina55060223; Peteet JR, 2010, PSYCHOSOMATICS, V51, P166, DOI 10.1176/appi.psy.51.2.166; Rashid Ahmad., 2021, arXiv; Ratkowska KA., 2013, OPEN J MEDICAL PSYCH, P124, DOI DOI 10.4236/OJMP.2013.23019; Raza A, 2023, GENES-BASEL, V14, DOI 10.3390/genes14010071; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Shing H-C, 2018, P 5 WORKSH COMP LING, P25, DOI [10.18653/v1/W18-0603, DOI 10.18653/V1/W18-0603]; Sinha PP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P941, DOI 10.1145/3357384.3358060; Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Van Orden KA, 2010, PSYCHOL REV, V117, P575, DOI 10.1037/a0018697; Vaswani A., 2017, NeurIPS, V30, P5; Vilhjalmsson R, 1998, SOC PSYCH PSYCH EPID, V33, P97, DOI 10.1007/s001270050028; Vioulès MJ, 2018, IBM J RES DEV, V62, DOI 10.1147/JRD.2017.2768678; Wei Qiang, 2018, AMIA Annu Symp Proc, V2018, P1552; Wenzel A, 2008, APPL PREV PSYCHOL, V12, P189, DOI 10.1016/j.appsy.2008.05.001; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xie X, 2022, COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2022, WWW 2022 COMPANION, P162, DOI 10.1145/3487553.3524238; Yang KL, 2023, Arxiv, DOI arXiv:2304.03347; Zirikly A, 2019, P 6 WORKSH COMP LING	67	1	1	18	18	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						14350	14363		10.1109/ACCESS.2024.3358206	http://dx.doi.org/10.1109/ACCESS.2024.3358206			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	HE8P3		gold			2024-07-03	WOS:001157911500001
J	Gaumann, N; Veale, M				Gaumann, Noelle; Veale, Michael			AI providers as criminal essay mills? Large language models meet contract cheating law	INFORMATION & COMMUNICATIONS TECHNOLOGY LAW			English	Article; Early Access						Contract cheating; essay mills; large language models; AI; academic integrity		Many jurisdictions have passed very broadly drafted laws to tackle academic integrity issues, criminalising the provision or advertising of contract cheating or essay mills, such as the Skills and Post-16 Education Act 2022 in England and Wales. Recently, AI models such as chatGPT have amplified academic concerns. Here, we look at the intersection between these phenomena. We review academic cheating laws, showing that several may apply even to general-purpose AI services like chatGPT, without knowledge and intent. We identify a range of illegal adverts for AI-enhanced essay mills, and illustrate how difficult it is to draw the line between writing an essay and supporting it, such as by generating bone fide references. We also outline the consequences for intermediaries hosting these ads or providing these services, which may be significantly affected by these primarily symbolic laws. We conclude with a series of recommendations for policymakers, legislators, and education providers.	[Gaumann, Noelle; Veale, Michael] UCL, Fac Laws, London, England	University of London; University College London	Veale, M (corresponding author), UCL, Fac Laws, London, England.	m.veale@ucl.ac.uk		Veale, Michael/0000-0002-2342-8785	UKRI; Trustworthy Autonomous Systems Hub; UCL ChangeMakers fund	UKRI(UK Research & Innovation (UKRI)); Trustworthy Autonomous Systems Hub; UCL ChangeMakers fund	This work is supported by the UKRI [grant number EP/V00784X/1] (https://tas.ac.uk) Trustworthy Autonomous Systems Hub, and the UCL ChangeMakers fund	Advertising Standards Authority, 2023, ASA Ruling on Home of Dissertations'; Advertising Standards Authority, 2023, ASA Ruling on Brilliant Minds Ltd t/a Essay Mills (A23-1188070 Brilliant Minds Ltd); Advertising Standards Authority Committee of Advertising Practice, 2019, ASA Ruling on Person(s) Unknown t/a Proacademichelp.co.uk (A19-564582)'; Anders Theo, 2021, Der Standard23 March; [Anonymous], 2014, Commissioner of Police v Li; [Anonymous], 2023, Nord-Rhein Westfalen, Hochschulgesetz 2004 HG 2004 (NRW) vom 14 March 2000; [Anonymous], Significant Gravitas; [Anonymous], 2023, FOCUS online, 9 June; [Anonymous], 2018, Australian Government Response to the Religious Freedom Review; [Anonymous], 2002, BGBl I Nr 120/ 2002; [Anonymous], 2022, Service Public, 13 September; [Anonymous], 2021, Kronen Zeitung, 29 September; [Anonymous], 2019, Official Gazette of Montenegro; Arredondo P., 2023, GPT-4 Passes the Bar Exam: What That Means for Artificial Intelligence Tools in the Legal Profession'; Aschendorff Medien, 2023, Westfalen-Blatt, 6 March; Australian Government Department of Education The Higher Education Standards Panel (HESP), Tackling contract cheating; awesomegpts, About Us; Bretag T, 2019, STUD HIGH EDUC, V44, P1837, DOI 10.1080/03075079.2018.1462788; Brown Thomas, 2021, Higher Education Cheating Services Prohibition Bill HL'; Burghart Alex, 2022, Essay Mills Are Now Illegal-Skills Minister Calls on Internet Service Platforms to Crack down on Advertising'; Chiara Pier Giorgio, 2023, European Data Protection Law Review, V9, P68; Cobbe J, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1186, DOI 10.1145/3593013.3594073; Cobbe J, 2021, COMPUT LAW SECUR REV, V42, DOI 10.1016/j.clsr.2021.105573; Contractor Danish, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P778, DOI 10.1145/3531146.3533143; Cowls Josh, 2022, The 2021 Yearbook of the Digital Ethics Lab; Draper Michael, 2018, Using the Law to Tackle Essay Mills; Draper MJ, 2017, INT J EDUC INTEGR, V13, P1, DOI 10.1007/s40979-017-0022-5; Draper MJ, 2017, INT J EDUC INTEGR, V13, DOI 10.1007/s40979-017-0014-5; Eaton Sarah Elaine, 2022, Academic Integrity in Canada: An Enduring and Essential Challenge; facebook, Meta Ads Library; Gallant Tricia Bertram, 2023, Navigating the Era of Outsourcing: Rethinking Higher Education in the Age of GenAl and Contract Cheating; Google Ad Transparency, About Us; Gorwa Robert, 2024, Law, Innovation and Technology, V16; Grove Jack, 2023, Times Higher Education (THE)30 March; Hacker P, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P1112, DOI 10.1145/3593013.3594067; Hill G, 2021, RES PRACT TECH ENHAN, V16, DOI 10.1186/s41039-021-00166-8; HM Government, 2021, Skills and Post-16 Education Bill: Policy Summary Notes, P57; HM Government, 2021, Skills and Post-16 Education Bill: Policy Summary Notes, P56; IPCC (Intergovernmental Panel on Climate Change), 2018, An IPCC Special Report on the Impacts of Global Warming of 1.5C above Pre-industrial Levels and Related Global Greenhouse Gas Emission Pathways, in the Context of Strengthening the Global Response to the Threat of Climate Change, Sustainable Development, and Efforts to Eradicate Poverty., DOI [10.1017/9781009157940.008, DOI 10.1017/CBO9781107415324]; Javadi SA, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P300, DOI 10.1145/3375627.3375873; Kohl U, 2013, INT J LAW INFORM TEC, V21, P187, DOI 10.1093/ijlit/eat004; Lancaster Thomas, Cheating with Artificial Intelligence-Addressing The Consequences'; Leerssen P, 2023, INFORM COMMUN SOC, V26, P1381, DOI 10.1080/1369118X.2021.2009002; Liang WX, 2023, Arxiv, DOI [arXiv:2304.02819, DOI 10.48550/ARXIV.2304.02819]; Mac Síthigh D, 2020, INF COMMUN TECHNOL L, V29, P1, DOI 10.1080/13600834.2020.1677369; Mao Rui, 2023, arXiv; McCormick Mary, 2019, Term Paper Mills: Statutes and Legislative Information; McKie Anna, 2021, Times Higher Education (THE)2 July; McKie Anna, 2018, Times Higher Education (THE)9 August; McKie Anna, 2020, Times Higher Education (THE)18 November; New Zealand Qualifications Authority, 2011, Factsheet-Education Amendment Act 2011; Newton PM, 2016, HANDBOOK OF ACADEMIC INTEGRITY, P249, DOI 10.1007/978-981-287-098-8_38; OpenAI, 2023, Usage Policies; Perault Matt, 2023, Journal of Free Speech Law, V3, P363; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Phrasly, 2023, How To Write An AI Proof Essay?; Phrasly, 2023, How to Bypass TurnItIn; Platform on Ethics Transparency and Integrity in Education (ETINED), 2018, South-East European Project on Policies for Academic Integrity, P56; QQI, 2019, EOLAS, December; Ross John, 2022, Times Higher Education (THE)5 August; Ross John, 2021, Times Higher Education (THE)8 October; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sourcely, About; Terzis P, 2023, INT J LAW INFORM TEC, V31, P302, DOI 10.1093/ijlit/eaae001; The Quality Assurance Agency for Higher Education, 2022, QAA Welcomes Ban on Essay Mills in England'; The Quality Assurance Agency for Higher Education, 2022, QAA Demits DQB Status to Focus on Sector and Students in England; The Quality Assurance Agency for Higher Education, 2018, QAA Calls for Online Companies to Stop Essay Mills in Their Tracks; The Quality Assurance Agency for Higher Education, 2019, PayPal Says No to Essay Mills'; Touvron H., 2023, arXiv; Van Hoboken J, 2021, COMPUT LAW SECUR REV, V41, DOI 10.1016/j.clsr.2021.105557; Veale M, 2023, ANNU REV LAW SOC SCI, V19, P255, DOI 10.1146/annurev-lawsocsci-020223-040749; von Gunten CF, 2021, J PALLIAT MED, V24, P2, DOI 10.1089/jpm.2020.0716; Widder D. G., 2023, Open (For Business): Big Tech, Concentrated Power, and the Political Economy of Open AI; Williams Thomas, 2023, Times Higher Education (THE)2 March; Williams Tom, 2022, Times Higher Education (THE)26 April; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	76	0	0	1	1	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1360-0834	1469-8404		INF COMMUN TECHNOL L	Inf. Commun. Technol. Law	2024 MAY 11	2024										10.1080/13600834.2024.2352692	http://dx.doi.org/10.1080/13600834.2024.2352692		MAY 2024	34	Law	Emerging Sources Citation Index (ESCI)	Government & Law	RM8M4		hybrid, Green Published			2024-07-03	WOS:001228171300001
J	Li, PF; Zhang, XJ; Zhu, EJ; Yu, SJ; Sheng, B; Tham, YC; Wong, TY; Ji, HW				Li, Pengfei; Zhang, Xuejuan; Zhu, Erjia; Yu, Shijun; Sheng, Bin; Tham, Yih Chung; Wong, Tien Yin; Ji, Hongwei			Potential Multidisciplinary Use of Large Language Models for Addressing Queries in Cardio-Oncology	JOURNAL OF THE AMERICAN HEART ASSOCIATION			English	Article						cardio-oncology; ChatGPT; Claude 2; Google Bard; large language models			[Wong, Tien Yin; Ji, Hongwei] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Tsinghua Med, Haidian Dist 30 Shuangqing Rd, Beijing 100084, Peoples R China; [Li, Pengfei; Zhang, Xuejuan] Qingdao Univ, Affiliated Hosp, Dept Gen Med, Qingdao, Peoples R China; [Zhu, Erjia; Yu, Shijun] Tongji Univ, Sch Med, Shanghai Pulm Hosp, Shanghai, Peoples R China; [Sheng, Bin] Tongji Univ, Sch Med, Shanghai East Hosp, Dept Oncol, Shanghai, Peoples R China; [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China; [Tham, Yih Chung] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore City, Singapore; [Tham, Yih Chung; Wong, Tien Yin] Duke NUS Med Sch, Singapore Eye Res Inst, Singapore Natl Eye Ctr, Singapore City, Singapore; [Wong, Tien Yin; Ji, Hongwei] Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Sch Clin Med, Tsinghua Med, Beijing, Peoples R China	Tsinghua University; Qingdao University; Tongji University; Tongji University; Shanghai Jiao Tong University; National University of Singapore; Singapore National Eye Center; National University of Singapore; Tsinghua University	Wong, TY; Ji, HW (corresponding author), Tsinghua Univ, Beijing Tsinghua Changgung Hosp, Tsinghua Med, Haidian Dist 30 Shuangqing Rd, Beijing 100084, Peoples R China.	wongtienyin@tsinghua.edu.cn; hongweijicn@gmail.com	Ji, Hongwei/HHC-5850-2022; Wong, Tien Y/AAC-9724-2020	Ji, Hongwei/0000-0003-3657-4666; Wong, Tien Y/0000-0002-8448-1264; li, pengfei/0009-0007-0482-5316	National Key Research and Development Program of China [2022YFC2502800]; National Natural Science Foundation of China [82103908]; Shandong Provincial Natural Science Foundation [ZR2021QH014]; Shuimu Scholar Program of Tsinghua University; National Postdoctoral Innovative Talent Support Program [BX20230189]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shandong Provincial Natural Science Foundation(Natural Science Foundation of Shandong Province); Shuimu Scholar Program of Tsinghua University; National Postdoctoral Innovative Talent Support Program	This study was funded in part by the National Key Research and Development Program of China (2022YFC2502800), the National Natural Science Foundation of China (82103908), the Shandong Provincial Natural Science Foundation (ZR2021QH014), the Shuimu Scholar Program of Tsinghua University, and the National Postdoctoral Innovative Talent Support Program (BX20230189). The funding sources had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.	Lyon AR, 2022, EUR HEART J, V43, P4229, DOI 10.1093/eurheartj/ehac244; OpenAI R, GPT-4 technical report.; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	5	0	0	8	8	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2047-9980		J AM HEART ASSOC	J. Am. Heart Assoc.	MAR 19	2024	13	6							e033584	10.1161/JAHA.123.033584	http://dx.doi.org/10.1161/JAHA.123.033584			3	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	LM8H5	38497458	gold, Green Published			2024-07-03	WOS:001187305000019
J	Litake, O; Park, BH; Tully, JL; Gabriel, RA				Litake, Onkar; Park, Brian H.; Tully, Jeffrey L.; Gabriel, Rodney A.			Constructing synthetic datasets with generative artificial intelligence to train large language models to classify acute renal failure from clinical notes	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						large language models; artificial intelligence; generative AI; ChatGPT		Objectives To compare performances of a classifier that leverages language models when trained on synthetic versus authentic clinical notes.Materials and Methods A classifier using language models was developed to identify acute renal failure. Four types of training data were compared: (1) notes from MIMIC-III; and (2, 3, and 4) synthetic notes generated by ChatGPT of varied text lengths of 15 (GPT-15 sentences), 30 (GPT-30 sentences), and 45 (GPT-45 sentences) sentences, respectively. The area under the receiver operating characteristics curve (AUC) was calculated from a test set from MIMIC-III.Results With RoBERTa, the AUCs were 0.84, 0.80, 0.84, and 0.76 for the MIMIC-III, GPT-15, GPT-30- and GPT-45 sentences training sets, respectively.Discussion Training language models to detect acute renal failure from clinical notes resulted in similar performances when using synthetic versus authentic training data.Conclusion The use of training data derived from protected health information may not be needed.	[Litake, Onkar; Park, Brian H.; Tully, Jeffrey L.; Gabriel, Rodney A.] Univ Calif San Diego, Dept Anesthesiol, Div Perioperat Informat, 9400 Campus Point Dr, La Jolla, CA 92037 USA; [Gabriel, Rodney A.] Univ Calif San Diego Hlth, Dept Biomed Informat, La Jolla, CA 92037 USA	University of California System; University of California San Diego; University of California System; University of California San Diego	Gabriel, RA (corresponding author), Univ Calif San Diego, Dept Anesthesiol, Div Perioperat Informat, 9400 Campus Point Dr, La Jolla, CA 92037 USA.	ragabriel@health.ucsd.edu		Tully, Jeffrey/0000-0002-3537-6716				Chen JQ, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0793-0; Devlin J., 2018, BERT PRE TRAINING DE; Gao Y, 2023, arXiv; Ghim JL, 2023, TRANSL CLIN PHARMACO, V31, P131, DOI 10.12793/tcp.2023.31.e16; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Koçak B, 2022, DIAGN INTERV RADIOL, V28, P450, DOI 10.5152/dir.2022.211297; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liao WX, 2023, JMIR MED EDUC, V9, DOI [10.2023/1/e48904, 10.2196/48904]; Liu Y., 2019, CoRR abs/1907.11692; Melamud O., 2019, ARXIV; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Touvron H., 2023, arXiv; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	14	1	1	6	6	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1404	1410		10.1093/jamia/ocae081	http://dx.doi.org/10.1093/jamia/ocae081		APR 2024	7	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38622901				2024-07-03	WOS:001203735500001
J	Aamir, A; Hafsa, H				Aamir, Ali; Hafsa, Hafiza			"Incorporating large language models into academic neurosurgery: embracing the new era"	NEUROSURGICAL REVIEW			English	Letter						Large language models; Neurosurgery; Academic medicine; Surgical practice; Medical education; Data privacy	MEDICAL-STUDENTS	This correspondence examines how LLMs, such as ChatGPT, have an effect on academic neurosurgery. It emphasises the potential of LLMs in enhancing clinical decision-making, medical education, and surgical practice by providing real-time access to extensive medical literature and data analysis. Although this correspondence acknowledges the opportunities that come with the incorporation of LLMs, it also discusses challenges, such as data privacy, ethical considerations, and regulatory compliance. Additionally, recent studies have assessed the effectiveness of LLMs in perioperative patient communication and medical education, and stressed the need for cooperation between neurosurgeons, data scientists, and AI experts to address these challenges and fully exploit the potential of LLMs in improving patient care and outcomes in neurosurgery. Significance center dot The profound impact of technological advancements, particularly LLMs on reshaping the landscape of medical education and clinical decision-making in neurosurgery, offers unprecedented access to information and aids in evidence-based practice. center dot Analysing the opportunities and challenges arising from incorporating LLMs into neurosurgical practice underscores the necessity of embracing and leveraging innovative technologies to enhance patient care, surgical outcomes, and medical education in neurosurgery.	[Aamir, Ali; Hafsa, Hafiza] Dow Univ Hlth Sci, Dept Med, Karachi, Pakistan	Dow University of Health Sciences	Aamir, A (corresponding author), Dow Univ Hlth Sci, Dept Med, Karachi, Pakistan.	aliaamirkhi@gmail.com; alizeyoman38@gmail.com		Aamir, Ali/0000-0001-8775-7353				Albarqouni L, 2018, JAMA NETW OPEN, V1, DOI 10.1001/jamanetworkopen.2018.0281; Bartlett HH, 2021, WORLD NEUROSURG, V155, P115, DOI 10.1016/j.wneu.2021.05.127; Bommarito MJ, GPT takes the bar exam, DOI [10.2139/ssrn.4314839, DOI 10.2139/SSRN.4314839]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buchlak QD, 2021, J CLIN NEUROSCI, V89, P177, DOI 10.1016/j.jocn.2021.04.043; Buchlak QD, 2020, NEUROSURG REV, V43, P1235, DOI 10.1007/s10143-019-01163-8; Camacho DM, 2018, CELL, V173, P1581, DOI 10.1016/j.cell.2018.05.015; Celtikci E, 2018, TURK NEUROSURG, V28, P167, DOI 10.5137/1019-5149.JTN.20059-17.1; Epping A, 2021, Principles of Neuro-Oncology, DOI [10.1007/978-3-030-54879-7_30, DOI 10.1007/978-3-030-54879-7_30]; Holzer E, 2019, BMC SURG, V19, DOI 10.1186/s12893-019-0570-0; Khanijahani A, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01877-1; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Mannam SS, 2023, WORLD NEUROSURG, V180, pE765, DOI 10.1016/j.wneu.2023.10.043; Rengers TA, 2024, JAMA SURG, V159, P445, DOI 10.1001/jamasurg.2023.6496; Singh K, 2018, INDIAN PEDIATR, V55, P507, DOI 10.1007/s13312-018-1342-0; Tung JYM, 2023, BJU INT, V132, P157, DOI 10.1111/bju.16042; White C, 2014, MED EDUC, V48, P315, DOI 10.1111/medu.12356	17	1	1	0	0	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0344-5607	1437-2320		NEUROSURG REV	Neurosurg. Rev.	MAY 10	2024	47	1							211	10.1007/s10143-024-02452-7	http://dx.doi.org/10.1007/s10143-024-02452-7			4	Clinical Neurology; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Surgery	PY3R3	38724772				2024-07-03	WOS:001217605500003
J	Maroteau, G; An, JS; Murgier, J; Hulet, C; Ollivier, M; Ferreira, A				Maroteau, Gaelle; An, Jae-Sung; Murgier, Jerome; Hulet, Christophe; Ollivier, Matthieu; Ferreira, Alexandre			Evaluation of the impact of large language learning models on articles submitted to <i>Orthopaedics & Traumatology: Surgery & Research (OTSR</i>): A significant increase in the use of artificial intelligence in 2023	ORTHOPAEDICS & TRAUMATOLOGY-SURGERY & RESEARCH			English	Article						Artificial intelligence; ChatGPT; Large language learning models; Chatbot; Scientific article		Introduction: There has been an unprecedented rise is the use of artificial intelligence (AI) amongst med-ical fields. Recently, a dialogue agent called ChatGPT (Generative Pre-trained Transformer) has grown in popularity through its use of large language models (LLM) to clearly and precisely generate text on demand. However, the impact of AI on the creation of scientific articles is remains unknown. A retrospec-tive study was carried out with the aim of answering the following questions: identify the presence of text generated by LLM before and after the increased usage of ChatGPT in articles submitted in OTSR; deter-mine if the type of article, the year of submission, and the country of origin, influenced the proportion of text generated, at least in part by AI.Material and methods: A total of 390 English articles were submitted to OTSR in January, February and March 2022 (n = 204) and over the same months of 2023 (n = 186) were analyzed. All articles were ana-lyzed using the ZeroGPT tool, which provides an assumed rate of AI use expressed as a percentage. A comparison of the average rate of AI use was carried out between the articles submitted in 2022 and 2023. This comparison was repeated keeping only the articles with the highest percentage of suspected AI use (greater than 10 and 20%). A secondary analysis was carried out to identify risk factors for AI use.Results: The average percentage of suspected LLM use in the entire cohort was 11% +/- 6, with 160 articles (41.0%) having a suspected AI rate greater than 10% and 61 (15.6%) with an assumed AI rate greater than 20%. A comparison between articles submitted in 2022 and 2023 revealed a significant increase in the use of these tools after the launch of ChatGPT 3.5 (9.4% in 2022 and 12.6% in 2023 [p = 0.004]). The number of articles with suspected AI rates of greater than 10 and 20% were significantly higher in 2023: >10%: 71 articles (34.8%) versus 89 articles (47.8%) (p = 0.008) and >20%: 21 articles (10.3%) versus 40 articles (21.5%) (p = 0.002). A risk factor analysis for LLLM use, demonstrated that authors of Asian geographic origin, and the submission year 2023 were associated with a higher rate of suspected AI use. An AI rate >20% was associated to Asian geographical origin with an odds ratio of 1.79 (95% CI: 1.03-3.11) (p = 0.029), while the year of submission being 2023 had an odds ratio of 1.7 (95% CI: 1.1-2.5) (p = 0.02).Conclusion: This study highlights a significant increase in the use of LLM in the writing of articles sub-mitted to the OTSR journal after the launch of ChatGPT 3.5. The increasing use of these models raises questions about originality and plagiarism in scientific research. AI offers creative opportunities but also raises ethical and methodological challenges. Level of evidence: III; case control study.(c) 2023 Elsevier Masson SAS. All rights reserved.	[Maroteau, Gaelle; Hulet, Christophe; Ferreira, Alexandre] Caen Univ Hosp, Dept Orthopaed & Traumatol, Unite Inserm Comete 1075, Ave Cote De Nacre, F-14000 Caen, France; [An, Jae-Sung] Tokyo Med & Dent Univ, 1 Chome 5-45 Yushima, Bunkyo, Tokyo 1138510, Japan; [Murgier, Jerome] Clin Aguilera, Serv Chirurg Orthoped, 21 Rue Estagnas, F-64200 Biarritz, France; [Ollivier, Matthieu] St Marguer Hosp, Inst Movement & Locomot, Dept Orthopaed & Traumatol, BP 29,270 Blvd St Marguer, F-13274 Marseille, France; [Ollivier, Matthieu] St Marguerite Hosp, AP HM, Dept Orthopaed & Traumatol, Aix Marseille Unit,Inst Locomot, Marseille, Brazil	CHU de Caen NORMANDIE; Universite de Caen Normandie; Tokyo Medical & Dental University (TMDU); Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille	Ferreira, A (corresponding author), Caen Univ Hosp, Dept Orthopaed & Traumatol, Unite Inserm Comete 1075, Ave Cote De Nacre, F-14000 Caen, France.	alexandreferreira0891@gmail.com		An, Jae-Sung/0009-0006-4975-2600; Maroteau, Gaelle/0000-0002-0923-7042; Alexandre, FERREIRA/0000-0002-4624-3898; HULET, Christophe/0000-0002-1011-6141				[Anonymous], 2022, Chatgpt: Optimizing language models for dialogue; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Benhenneda R, 2023, Orthop Traumatol Surg Res, V109; Benhenneda R, 2023, Orthop Traumatol Surg Res, V109; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cahan P, 2023, STEM CELL REP, V18, P1, DOI 10.1016/j.stemcr.2022.12.009; Charles YP, 2023, ORTHOP TRAUMATOL-SUR, V109, DOI 10.1016/j.otsr.2022.103456; Coeffe T, 2023, GPT-3 et GPT-4: tout savoir sur les modeles d'OpenAI; Curtis GJ, 2016, HIGH EDUC RES DEV, V35, P1167, DOI 10.1080/07294360.2016.1161602; Gilat R, 2023, ARTHROSCOPY, V39, P1119, DOI 10.1016/j.arthro.2023.01.014; Graëff C, 2023, ORTHOP TRAUMATOL-SUR, V109, DOI 10.1016/j.otsr.2023.103564; Guy S, 2021, ORTHOP TRAUMATOL-SUR, V107, DOI 10.1016/j.otsr.2021.102837; Hovy D, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P483; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Paulus P.B., 2003, Group Creativity: Innovation through Collaboration, P110, DOI [10.1093/acprof:oso/9780195147308.001.0001, DOI 10.1093/ACPROF:OSO/9780195147308.003.0006]; Posner RA, 2002, Am Acad Arts Sci; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Runco MA, 2004, ANNU REV PSYCHOL, V55, P657, DOI 10.1146/annurev.psych.55.090902.141502; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Simonton D, 2005, Choice Rev, V42, P42; Weaver CGW, 2021, CAN J CARDIOL, V37, P1156, DOI 10.1016/j.cjca.2021.03.003	23	2	2	13	14	ELSEVIER MASSON, CORP OFF	PARIS	65 CAMILLE DESMOULINS CS50083 ISSY-LES-MOULINEAUX, 92442 PARIS, FRANCE	1877-0568			ORTHOP TRAUMATOL-SUR	Orthop. Traumatol.-Surg. Res.	DEC	2023	109	8							103720	10.1016/j.otsr.2023.103720	http://dx.doi.org/10.1016/j.otsr.2023.103720		NOV 2023	6	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	CV3W6	37866509				2024-07-03	WOS:001127982300001
J	Lewis, A				Lewis, Abbey			Academic Libraries' Citation Guides to ChatGPT Show Mixed Levels of Accuracy and Currency	EVIDENCE BASED LIBRARY AND INFORMATION PRACTICE			English	Article								Objective - To examine how and which academic libraries are responding to emerging guidelines on citing ChatGPT in the American Psychological Association (APA) style through guidance published on the libraries' websites. Design - Analysis of search results and webpage content. Setting - Websites of academic libraries in the United States. Subjects - Library webpages addressing how ChatGPT should be cited in APA format. Methods - Google search results for academic library webpages providing guidance on citing ChatGPT in APA format were retrieved on a weekly basis using the query "chatgpt apa citation site:.edu" over a six -week period that covered the weeks before and immediately after the APA issued official guidance for citing ChatGPT. The first three pages of relevant search results were coded in MAXQDA and analyzed to determine the type of institution, using the Carnegie Classification and membership in the Association of American Universities (AAU). As this was a period during which APA style recommendations for citing ChatGPT were shifting, the accuracy of the library webpage content was also assessed and tracked across the studied time period. Main Results - During the six-week period, the number of library webpages with guidance for citing ChatGPT in APA format increased. Although doctoral universities accounted for the largest number of webpages each week, baccalaureate colleges, baccalaureate/associate's colleges, and associates' colleges were also well-represented in the search results. Institutions belonging to the AAU were represented by a relatively small number throughout the study. Over half of the pages made some mention of APA's recommendations being interim or evolving, though the exact number fluctuated throughout the period. Prior to the collection period, APA had revised its initial recommendations to cite ChatGPT as a webpage or as personal communication, but 40% to 60% of library webpages continued to offer this outdated guidance. Of the library webpages, 13% to 40% provided verbatim guidance from ChatGPT responses on how it should be cited. The final two weeks of the collection period occurred after April 7, 2023, when APA had published official recommendations for citing ChatGPT. In the week following this change, none of the webpages in the first three pages of results had been updated to fully capture the new recommendations. The study analyzed the nine webpages appearing in the first page of results for the second week after APA's official recommendations were published, showing that three linked to the APA's blog, zero provided further explanation on how to apply the recommendations, five included outdated guidance, and three gave guidance from ChatGPT's responses to questions on how it should be cited. Conclusion - The author sees the results of the study as reflecting three interrelated components: a new technology, gaps in librarians' knowledge related to large language models (LLMs) and how they are currently being discussed in terms of authorship, and Google's inability to rank the results in a way that prioritizes correct information. The substantial presence of institutions serving undergraduates leads the author to conclude that this is the population most in need of guidance for citing ChatGPT and the responsiveness on the part of the librarians shows an understanding of this need, even if the guidance itself is inaccurate.	[Lewis, Abbey] Univ Colorado Boulder, Boulder, CO 80309 USA	University of Colorado System; University of Colorado Boulder	Lewis, A (corresponding author), Univ Colorado Boulder, Boulder, CO 80309 USA.	Abbey.B.Lewis@colorado.edu						Andersdotter K., 2023, Journal of Information Literacy, V17, DOI [10.11645/17.2.14, DOI 10.11645/17.2.14]; Lo LS, 2023, IFLA J-INT FED LIBR, V49, P645, DOI 10.1177/03400352231196172; Moulaison-Sandy Heather, 2023, Proceedings of the Association for Information Science and Technology, P279, DOI 10.1002/pra2.788; Perryman C., 2014, The CAT: A generic critical appraisal tool	4	0	0	0	0	UNIV ALBERTA	EDMONTON	DEPT SOCIOLOGY, EDMONTON, ALBERTA T6G 2E1, CANADA	1715-720X			EVID BASED LIB INF P	Evid. Based Lib. Inf. Pract.		2024	19	2					127	129		10.18438/eblip30514	http://dx.doi.org/10.18438/eblip30514			3	Information Science & Library Science	Emerging Sources Citation Index (ESCI)	Information Science & Library Science	WC6C3					2024-07-03	WOS:001252698900010
J	Ock, J; Guntuboina, C; Farimani, AB				Ock, Janghoon; Guntuboina, Chakradhar; Farimani, Amir Barati			Catalyst Energy Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models	ACS CATALYSIS			English	Article						computational catalysis; catalyst screening; renewable energy; machine learning; Transformer; large language model	DESIGN	Efficient catalyst screening necessitates predictive models for adsorption energy, which is a key descriptor of reactivity. Prevailing methods, notably graph neural networks (GNNs), demand precise atomic coordinates for constructing graph representations, while the integration of observable attributes remains challenging. This research introduces CatBERTa, an energy prediction Transformer model that uses textual inputs. Built on a Transformer encoder pretrained for language modeling purposes, CatBERTa processes human-interpretable text, incorporating target features. Attention score analysis reveals CatBERTa's focus on tokens related to adsorbates, bulk composition, and their interacting atoms. Moreover, interacting atoms emerge as effective descriptors for adsorption configurations, while factors such as the bond length and atomic properties of these atoms offer limited predictive contributions. In predicting the adsorption energy from textual representations of initial structures, CatBERTa exhibits a precision comparable to that of conventional GNNs. Notably, in subsets recognized for their high accuracy with GNNs, CatBERTa consistently achieves a mean absolute error of 0.35 eV. Furthermore, the subtraction of the CatBERTa-predicted energies effectively cancels out their systematic errors by as much as 19.3% for chemically similar systems, surpassing the error reduction observed in GNNs. This outcome highlights its potential to enhance the accuracy of the energy difference predictions. This research establishes a fundamental framework for text-based catalyst property prediction without relying on graph representations while also unveiling intricate feature-property relationships.	[Ock, Janghoon] Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA; [Guntuboina, Chakradhar] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA; [Farimani, Amir Barati] Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University	Farimani, AB (corresponding author), Carnegie Mellon Univ, Dept Mech Engn, Pittsburgh, PA 15213 USA.	barati@cmu.edu	Farimani, Amir Barati/K-4601-2019; Barati Farimani, Amir/F-2356-2013	Barati Farimani, Amir/0000-0002-2952-8576; Ock, Janghoon/0009-0000-0370-4212	Carnegie Mellon University; Bradford and Diane Smith Fellowship	Carnegie Mellon University; Bradford and Diane Smith Fellowship	The authors acknowledge the Bradford and Diane Smith Fellowship for their pivotal funding support. Additionally, the authors express gratitude to Rishikesh Magar and Yayati Jadhav for enlightening discussions on Transformer-based models and commend Brook Wander for her valuable guidance in analyzing the Open Catalyst 2020 data set.	AlaAlam Falaki R. G., 2023, arXiv, parXiv:2308.14850; Bucior BJ, 2019, CRYST GROWTH DES, V19, P6682, DOI 10.1021/acs.cgd.9b01050; Cao ZL, 2023, J AM CHEM SOC, DOI 10.1021/jacs.2c11420; Chanussot L, 2021, ACS CATAL, V11, P6059, DOI 10.1021/acscatal.0c04525; Chen BWJ, 2021, CHEM REV, V121, P1007, DOI 10.1021/acs.chemrev.0c01060; Cheng J, 2008, J PHYS CHEM C, V112, P1308, DOI 10.1021/jp711191j; Christofidellis D, 2023, Arxiv, DOI arXiv:2301.12586; Collins EM, 2020, J CHEM THEORY COMPUT, V16, P4938, DOI 10.1021/acs.jctc.0c00236; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Edwards C, 2022, Arxiv, DOI [arXiv:2204.11817, DOI 10.48550/ARXIV.2204.11817]; Ganose AM, 2019, MRS COMMUN, V9, P874, DOI 10.1557/mrc.2019.94; Gao W, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14969-8; Gasteiger J., 2022, arXiv; Goldsmith BR, 2018, AICHE J, V64, P2311, DOI 10.1002/aic.16198; Guntuboina C, 2023, J PHYS CHEM LETT, V14, P10427, DOI 10.1021/acs.jpclett.3c02398; Hammer B, 1999, PHYS REV B, V59, P7413, DOI 10.1103/PhysRevB.59.7413; Hao YR, 2021, AAAI CONF ARTIF INTE, V35, P12963; Hautier G, 2012, PHYS REV B, V85, DOI 10.1103/PhysRevB.85.155208; Heller SR, 2015, J CHEMINFORMATICS, V7, DOI 10.1186/s13321-015-0068-4; Jadhav Y, 2023, COMPUT METHOD APPL M, V416, DOI 10.1016/j.cma.2023.116343; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Klicpera J., 2020, arXiv, DOI [DOI 10.48550/ARXIV.2003.03123, 10.48550/arXiv.2003.03123]; Klicpera J., 2020, ARXIV; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Lan J, 2023, Arxiv, DOI arXiv:2211.16486; Zitnick CL, 2020, Arxiv, DOI arXiv:2010.09435; Li YH, 2019, ELECTROCHEM ENERGY R, V2, P518, DOI 10.1007/s41918-019-00052-4; Liang SY, 2021, ADV SCI, V8, DOI 10.1002/advs.202102886; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Musielewicz J, 2022, MACH LEARN-SCI TECHN, V3, DOI 10.1088/2632-2153/ac8fe0; Nguyen L, 2019, CHEM REV, V119, P6822, DOI 10.1021/acs.chemrev.8b00114; Norskov JK, 2009, NAT CHEM, V1, P37, DOI [10.1038/NCHEM.121, 10.1038/nchem.121]; Ock J, 2023, J CHEM PHYS, V158, DOI 10.1063/5.0151159; Ong SP, 2013, COMP MATER SCI, V68, P314, DOI 10.1016/j.commatsci.2012.10.028; Ooka H, 2021, FRONT ENERGY RES, V9, DOI 10.3389/fenrg.2021.654460; OpenAI, 2022, ChatGPT 3.5; Pielsticker L, 2021, J PHYS CHEM LETT, V12, P2570, DOI 10.1021/acs.jpclett.1c00179; Plessow PN, 2020, J PHYS CHEM LETT, V11, P4305, DOI 10.1021/acs.jpclett.0c01240; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2018, ImprovingLanguage Understanding by Generative Pre-training; Rajan K, 2022, DIGIT DISCOV, V1, P84, DOI 10.1039/d1dd00013f; Schutt KT, 2017, Arxiv, DOI arXiv:1706.08566; Sperger T, 2016, ACCOUNTS CHEM RES, V49, P1311, DOI 10.1021/acs.accounts.6b00068; Sutton JE, 2012, ACS CATAL, V2, P1624, DOI 10.1021/cs3003269; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tran R, 2022, J CHEM PHYS, V157, DOI 10.1063/5.0092948; Ulissi ZW, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms14621; Vaswani A., 2017, ADV NEURAL INFORMATI; Wander B, 2022, CATAL SCI TECHNOL, V12, P6256, DOI 10.1039/d2cy01267g; Wang S, 2019, ACM-BCB'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, P429, DOI 10.1145/3307339.3342186; Wang SG, 2011, CATAL LETT, V141, P370, DOI 10.1007/s10562-010-0477-y; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Xie T, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.145301; Xu CW, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01016-5; Yang B, 2014, ACS CATAL, V4, P182, DOI 10.1021/cs400727f; Zitnick L., 2022, NEURIPS	56	5	5	11	11	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	2155-5435			ACS CATAL	ACS Catal.	NOV 30	2023	13	24					16032	16044		10.1021/acscatal.3c04956	http://dx.doi.org/10.1021/acscatal.3c04956			13	Chemistry, Physical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	EU1X4		hybrid			2024-07-03	WOS:001141366800001
J	Ferber, D; Kather, JN				Ferber, Dyke; Kather, Jakob Nikolas			Large Language Models in Uro-oncology	EUROPEAN UROLOGY ONCOLOGY			English	Editorial Material									[Ferber, Dyke; Kather, Jakob Nikolas] Heidelberg Univ Hosp, Natl Ctr Tumor Dis, Heidelberg, Germany; [Ferber, Dyke; Kather, Jakob Nikolas] Heidelberg Univ Hosp, Dept Med Oncol, Heidelberg, Germany; [Kather, Jakob Nikolas] Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Kather, Jakob Nikolas] Univ Hosp Dresden, Dept Med 1, Dresden, Germany; [Kather, Jakob Nikolas] Tech Univ Dresden, Else Kroner Fresenius Ctr Digital Hlth, D-01062 Dresden, Germany	Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg; Technische Universitat Dresden; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Technische Universitat Dresden	Kather, JN (corresponding author), Tech Univ Dresden, Else Kroner Fresenius Ctr Digital Hlth, D-01062 Dresden, Germany.	jakob-nikolas.kather@alumni.dkfz.de						Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Clarke H, 2023, Urology Times March 16; Ji Z, arXiv, DOI DOI 10.1145/3571730; Khene ZE, 2024, EUR UROL ONCOL, V7, P160, DOI 10.1016/j.euo.2023.06.009; Lehman E, 2023, Arxiv, DOI [arXiv:2302.08091, 10.48550/arXiv.2302.08091, DOI 10.48550/ARXIV.2302.08091]; May M, 2024, EUR UROL ONCOL, V7, P155, DOI 10.1016/j.euo.2023.08.013; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Peng A, GPT-3.5 Turbo: finetuning and API updates; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Tu T, 2023, Arxiv, DOI arXiv:2307.14334	10	1	1	1	1	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2588-9311		EUR UROL ONCOL	Eur. Urol. Oncol.	FEB	2024	7	1					157	159		10.1016/j.euo.2023.09.019	http://dx.doi.org/10.1016/j.euo.2023.09.019		JAN 2024	3	Oncology; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology; Urology & Nephrology	JA9V4	37839981				2024-07-03	WOS:001170558500001
J	Matin, RN; Linos, E; Rajan, N				Matin, Rubeta N.; Linos, Eleni; Rajan, Neil			Leveraging large language models in dermatology	BRITISH JOURNAL OF DERMATOLOGY			English	Editorial Material									[Matin, Rubeta N.] Churchill Hosp, Dept Dermatol, Oxford, England; [Linos, Eleni] Stanford Univ, Ctr Digital Hlth, Dept Med, Sch Med, Stanford, CA USA; [Linos, Eleni] Stanford Univ, Dept Dermatol, Sch Med, Stanford, CA USA; [Rajan, Neil] Royal Victoria Infirm, Dept Dermatol, Newcastle Upon Tyne, Tyne & Wear, England; [Rajan, Neil] Newcastle Univ, Translat & Clin Res Inst, Newcastle Upon Tyne, Tyne & Wear, England	University of Oxford; Stanford University; Stanford University; Newcastle University - UK; Newcastle University - UK	Rajan, N (corresponding author), Royal Victoria Infirm, Dept Dermatol, Newcastle Upon Tyne, Tyne & Wear, England.; Rajan, N (corresponding author), Newcastle Univ, Translat & Clin Res Inst, Newcastle Upon Tyne, Tyne & Wear, England.	neil.rajan@newcastle.ac.uk			Newcastle NIHR Biomedical Research Centre	Newcastle NIHR Biomedical Research Centre	This editorial received no specific grant from any funding agency in the public, commercial or not-for-profit sectors. N.R.'s research is supported by the Newcastle NIHR Biomedical Research Centre.	[Anonymous], 2022, The Washington Post; Beltrami EJ, 2022, J AM ACAD DERMATOL, V87, P1336, DOI 10.1016/j.jaad.2022.08.028; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Center for Devices Radiological Health, Artificial intelligence and machine learning (AI/ML)-enabled medical devices [WWW document]; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Gilson A., 2023, JMIR Med. Educ., V9; Kim C, 2023, medRxiv, DOI [10.1101/2023.06.07.23291119, 10.1101/2023.06.07.23291119, DOI 10.1101/2023.06.07.23291119]; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]	9	2	2	12	12	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0007-0963	1365-2133		BRIT J DERMATOL	Br. J. Dermatol.	AUG 24	2023	189	3			SI		253	254		10.1093/bjd/ljad230	http://dx.doi.org/10.1093/bjd/ljad230			2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	LL5K9	37410567	Bronze			2024-07-03	WOS:001186967200009
J	Pak, TK; Hernandez, CEM; Do, CN				Pak, Thomas Kun; Hernandez, Cesar Eber Montelongo; Do, Carter Nguyen			Artificial Intelligence in Psychiatry: Threat or Blessing?	ACADEMIC PSYCHIATRY			English	Editorial Material									[Pak, Thomas Kun; Hernandez, Cesar Eber Montelongo] Univ Texas Southwestern Med Ctr, Dallas, TX 75390 USA; [Do, Carter Nguyen] Rush Med Coll, Chicago, IL USA	University of Texas System; University of Texas Southwestern Medical Center Dallas; Rush University	Pak, TK (corresponding author), Univ Texas Southwestern Med Ctr, Dallas, TX 75390 USA.	pakmdphd@gmail.com	pak, Thomas/JFB-5154-2023	pak, Thomas/0000-0003-2716-1210	We thank Dr. Teri Thomsen and Dr. Adam Brenner for their feedback on our paper. We did not use ChatGPT or other Large Language Models to generate our paper. We used Google's search engine, which is powered by artificial intelligence.	We thank Dr. Teri Thomsen and Dr. Adam Brenner for their feedback on our paper. We did not use ChatGPT or other Large Language Models to generate our paper. We used Google's search engine, which is powered by artificial intelligence.	We thank Dr. Teri Thomsen and Dr. Adam Brenner for their feedback on our paper. We did not use ChatGPT or other Large Language Models to generate our paper. We used Google's search engine, which is powered by artificial intelligence.	Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Clark AC, 2023, AXIOS; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; McBain RK, 2022, JAMA PSYCHIAT, V79, P279, DOI 10.1001/jamapsychiatry.2021.4462; Tyson A., 2023, 60% of Americans Would Be Uncomfortable With Provider Relying on AI in Their Own Health Care	5	0	0	1	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1042-9670	1545-7230		ACAD PSYCHIATR	Acad. Psych.	DEC	2023	47	6					587	588		10.1007/s40596-023-01874-7	http://dx.doi.org/10.1007/s40596-023-01874-7		SEP 2023	2	Education & Educational Research; Psychiatry	Social Science Citation Index (SSCI)	Education & Educational Research; Psychiatry	AE7D4	37770703	Bronze			2024-07-03	WOS:001077542600001
J	Huo, BG; Mckechnie, T; Ortenzi, M; Lee, Y; Antoniou, S; Mayol, J; Ahmed, H; Boudreau, V; Ramji, K; Eskicioglu, C				Huo, Bright; Mckechnie, Tyler; Ortenzi, Monica; Lee, Yung; Antoniou, Stavros; Mayol, Julio; Ahmed, Hassaan; Boudreau, Vanessa; Ramji, Karim; Eskicioglu, Cagla			Dr. GPT will see you now: the ability of large language model-linked chatbots to provide colorectal cancer screening recommendations	HEALTH AND TECHNOLOGY			English	Article						Colorectal cancer screening; Large language models; Artificial intelligence		PurposeThis study assessed the performance of LLM-linked chatbots in providing accurate advice for colorectal cancer screening to both clinicians and patients.MethodsWe created standardized prompts for nine patient cases varying by age and family history to query ChatGPT, Bing Chat, Google Bard, and Claude 2 for screening recommendations to clinicians. Chatbots were asked to specify which screening test was indicated and the frequency of interval screening. Separately, the chatbots were queried with lay terminology for screening advice to patients. Clinician and patient advice was compared to guidelines from the United States Preventive Services Task Force (USPSTF), Canadian Cancer Society (CCS), and the U.S. Multi-Society Task Force (USMSTF) on Colorectal Cancer.ResultsBased on USPSTF criteria, clinician advice aligned with 3/4 (75.0%), 2/4 (50.0%), 3/4 (75.0%), and 1/4 (25.0%) cases for ChatGPT, Bing Chat, Google Bard, and Claude 2, respectively. With CCS criteria, clinician advice corresponded to 2/4 (50.0%), 2/4 (50.0%), 2/4 (50.0%), and 1/4 (25.0%) cases for ChatGPT, Bing Chat, and Google Bard, respectively. For USMSTF guidelines, clinician advice aligned with 7/9 (77.8%), 5/9 (55.6%), 6/9 (66.7%), and 3/9 (33.3%) cases for ChatGPT, Bing Chat, Google Bard, and Claude 2, respectively. Discordant advice was given to clinicians and patients for 2/9 (22.2%), 3/9 (33.3%), 2/9 (22.2%), and 3/9 (33.3%) cases for ChatGPT, Bing Chat, Google Bard, and Claude 2, respectively. Clinical advice provided by the chatbots stemmed from a range of sources including the American Cancer Society (ACS), USPSTF, USMSTF, and the CCS.ConclusionLLM-linked chatbots provide colorectal cancer screening recommendations with inconsistent accuracy for both patients and clinicians. Clinicians must educate patients on the pitfalls of using these platforms for health advice.	[Huo, Bright; Mckechnie, Tyler; Lee, Yung; Boudreau, Vanessa; Ramji, Karim; Eskicioglu, Cagla] McMaster Univ, Dept Surg, Div Gen Surg, Unit 713, 112 King St, Hamilton, ON L8N 1A8, Canada; [Ortenzi, Monica] Univ Politecn Marche, Dept Gen Surg, Ancona, Italy; [Antoniou, Stavros] Papageorgiou Gen Hosp, Dept Surg, Thessaloniki, Greece; [Mayol, Julio] Univ Complutense Madrid, Hosp Clin San Carlos, IdISSC, Madrid, Spain; [Ahmed, Hassaan] Phelix AI, Hamilton, ON, Canada	McMaster University; Marche Polytechnic University; Papageorgiou Hospital; Complutense University of Madrid; Hospital Clinico San Carlos	Huo, BG (corresponding author), McMaster Univ, Dept Surg, Div Gen Surg, Unit 713, 112 King St, Hamilton, ON L8N 1A8, Canada.	brighthuo@dal.ca	Ortenzi, Monica/AFV-9079-2022; Mayol, Julio/M-2265-2019	Ortenzi, Monica/0000-0002-6508-6488; Mayol, Julio/0000-0003-2411-6668; Huo, Bright/0000-0003-4999-4328				Ayers JW, 2016, JAMA INTERN MED, V176, P1865, DOI 10.1001/jamainternmed.2016.6274; Bhatia K, 2023, INF COMMUN TECHNOL L, V32, P1, DOI 10.1080/13600834.2021.1998954; Canadian Task Force Preventive Hlt, 2016, CAN MED ASSOC J, V188, P340, DOI 10.1503/cmaj.151125; Davidson KW, 2021, JAMA-J AM MED ASSOC, V325, P1965, DOI 10.1001/jama.2021.6238; Ferdush J, 2024, ANN BIOMED ENG, V52, P1119, DOI 10.1007/s10439-023-03329-4; Fu SY, 2023, CTS-CLIN TRANSL SCI, V16, P398, DOI 10.1111/cts.13463; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Kalyta A, 2021, CURR ONCOL, V28, P1558, DOI 10.3390/curroncol28030147; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rex DK, 2017, AM J GASTROENTEROL, V112, P1016, DOI 10.1038/ajg.2017.174; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wolf AMD, 2018, CA-CANCER J CLIN, V68, P250, DOI 10.3322/caac.21457; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7	14	0	0	2	2	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2190-7188	2190-7196		HEALTH TECHNOL-GER	Health Technol.	MAY	2024	14	3					463	469		10.1007/s12553-024-00836-9	http://dx.doi.org/10.1007/s12553-024-00836-9		MAR 2024	7	Medical Informatics	Emerging Sources Citation Index (ESCI)	Medical Informatics	PS5B1					2024-07-03	WOS:001173452800001
J	Kendall, G; da Silva, JAT				Kendall, Graham; da Silva, Jaime A. Teixeira			Risks of abuse of large language models, like ChatGPT, in scientific publishing: Authorship, predatory publishing, and paper mills	LEARNED PUBLISHING			English	Article						authorship abuses; ChatGPT; ghost authorship; large language model; paper mills; predatory publishing			[Kendall, Graham] Univ Nottingham, Sch Comp Sci, Univ Pk, Nottingham, England; [Kendall, Graham] Univ Nottingham, Univ Pk, Nottingham NG7 2RD, England	University of Nottingham; University of Nottingham	Kendall, G (corresponding author), Univ Nottingham, Univ Pk, Nottingham NG7 2RD, England.	graham.kendall@nottingham.edu.my	; Kendall, Graham/B-8249-2008	Teixeira da Silva, Jaime A./0000-0003-3299-2772; Kendall, Graham/0000-0003-2006-5103	We thank Panagiotis Tsigaris (Thompson Rivers University, Canada) for his input and feedback on earlier drafts of this paper.	We thank Panagiotis Tsigaris (Thompson Rivers University, Canada) for his input and feedback on earlier drafts of this paper.	We thank Panagiotis Tsigaris (Thompson Rivers University, Canada) for his input and feedback on earlier drafts of this paper.	Al-Khatib A, 2016, PUBLISH RES Q, V32, P208, DOI 10.1007/s12109-016-9473-4; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Beall J, 2017, BIOCHEM MEDICA, V27, P273, DOI 10.11613/BM.2017.029; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brainard J, 2023, SCIENCE, V379, P740, DOI 10.1126/science.adh2762; Byrne JA, 2022, NUCLEIC ACIDS RES, V50, P12058, DOI 10.1093/nar/gkac1139; Cabanac G, 2021, J ASSOC INF SCI TECH, V72, P1461, DOI 10.1002/asi.24495; Carr EJ, 2023, LANCET INFECT DIS, V23, P781, DOI 10.1016/S1473-3099(23)00290-6; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Chirico F, 2023, ACCOUNT RES, V30, P246, DOI 10.1080/08989621.2021.1982705; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Cingillioglu I, 2023, INT J INF LEARN TECH, V40, P259, DOI 10.1108/IJILT-03-2023-0043; Clark AJL, 2021, ENDOCR CONNECT, V10, pE3, DOI 10.1530/EC-21-0489; Copeland BJ, 1999, SCI AM, V280, P98, DOI 10.1038/scientificamerican0499-98; da Silva JAT, 2023, PUBLISH RES Q, V39, P263, DOI 10.1007/s12109-023-09956-y; da Silva JAT, 2023, LEARN PUBL, V36, P453, DOI 10.1002/leap.1547; da Silva JAT, 2023, ANN BIOMED ENG, V51, P2103, DOI 10.1007/s10439-023-03247-5; Desaire H, 2023, CELL REP PHYS SCI, V4, DOI 10.1016/j.xcrp.2023.101426; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Else H, 2022, NATURE, V612, P386, DOI 10.1038/d41586-022-04245-8; Else H, 2021, NATURE, V591, P516, DOI 10.1038/d41586-021-00733-5; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Garcia MB, 2024, ANN BIOMED ENG, V52, P139, DOI 10.1007/s10439-023-03299-7; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Grossmann Alexander, 2021, F1000Res, V10, P20, DOI 10.12688/f1000research.27468.1; Habibzadeh F, 2023, LEARN PUBL, V36, P326, DOI 10.1002/leap.1514; Hackett R, 2022, BIOL OPEN, V11, DOI 10.1242/bio.059428; Hu GW, 2023, PUBLICATIONS, V11, DOI 10.3390/publications11010018; Hu GW, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2184262; Huang JS, 2023, AM J CANCER RES, V13, P1148; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Kendall G, 2021, LEARN PUBL, V34, P379, DOI 10.1002/leap.1374; Kendall G, 2017, ELECTRON LIBR, V35, P348, DOI 10.1108/EL-04-2016-0090; Kendall G, 2016, SCI ENG ETHICS, V22, P1553, DOI 10.1007/s11948-015-9710-9; Kung T.H., 2022, MEDRXIV, DOI [10.1371/journal.pdig.0000198, DOI 10.1371/JOURNAL.PDIG.0000198]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Labbé C, 2013, SCIENTOMETRICS, V94, P379, DOI 10.1007/s11192-012-0781-y; Lee JY, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.6; Liang W.-X., 2023, GPT DETECTORS ARE BI, DOI DOI 10.48550/ARXIV.2304.02819; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Loan FA, 2022, LIBR HI TECH, V40, P676, DOI 10.1108/LHT-04-2021-0141; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; Machácek V, 2022, QUANT SCI STUD, V3, P859, DOI 10.1162/qss_a_00213; Mehregan M, 2022, RES ETHICS-UK, V18, P163, DOI 10.1177/17470161211068745; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Otterbacher J, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100796; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Pérez-Neri I, 2022, CLIN RHEUMATOL, V41, P2241, DOI 10.1007/s10067-022-06198-9; Rivera H, 2021, J KOREAN MED SCI, V36, DOI 10.3346/jkms.2021.36.e165; Sabel B. A., 2023, MEDRXIV, DOI [10.1101/2023.05.06.23289563, DOI 10.1101/2023.05.06.23289563]; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Tang GY, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2180359; Teixeira da Silva J. A., 2023, CENTRAL ASIAN J MEDI, V4, P39, DOI [10.47316/cajmhe.2023.4.1.04, DOI 10.47316/CAJMHE.2023.4.1.04]; Teixeira da Silva JA, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102779; Teixeira da Silva JA, 2023, NURSE EDUC PRACT, V68, DOI 10.1016/j.nepr.2023.103600; Teixeira da Silva Jaime A, 2023, Med J Armed Forces India, V79, P601, DOI 10.1016/j.mjafi.2021.03.009; Teixeira da Silva JA, 2021, J NANOPART RES, V23, DOI 10.1007/s11051-021-05199-0; Teixeira da Silva JA, 2021, SCIENTOMETRICS, V126, P6119, DOI 10.1007/s11192-021-03996-x; Tran T. H., 2023, DAILY BEAST; Turing AM, 1937, P LOND MATH SOC, V42, P230, DOI 10.1112/plms/s2-42.1.230; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Vijayakumar Preethi, 2023, Inventive Computation and Information Technologies: Proceedings of ICICIT 2022. Lecture Notes in Networks and Systems (563), P769, DOI 10.1007/978-981-19-7402-1_54; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2177160	70	0	0	21	63	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0953-1513	1741-4857		LEARN PUBL	Learn. Publ.	JAN	2024	37	1					55	62		10.1002/leap.1578	http://dx.doi.org/10.1002/leap.1578		SEP 2023	8	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	GF2Y8					2024-07-03	WOS:001064030500001
J	Fraser, H; Crossland, D; Bacher, I; Ranney, M; Madsen, T; Hilliard, R				Fraser, Hamish; Crossland, Daven; Bacher, Ian; Ranney, Megan; Madsen, Tracy; Hilliard, Ross			Comparison of Diagnostic and Triage Accuracy of Ada Health and WebMD Symptom Checkers, ChatGPT, and Physicians for Patients in an Emergency Department: Clinical Data Analysis Study	JMIR MHEALTH AND UHEALTH			English	Article						diagnosis; triage; symptom checker; emergency patient; ChatGPT; LLM; diagnose; self-diagnose; self-diagnosis; app; application; language model; accuracy; ChatGPT-3.5; ChatGPT-4.0; emergency; machine learning		Background: Diagnosis is a core component of effective health care, but misdiagnosis is common and can put patients at risk. Diagnostic decision support systems can play a role in improving diagnosis by physicians and other health care workers. Symptom checkers (SCs) have been designed to improve diagnosis and triage (ie, which level of care to seek) by patients.Objective: The aim of this study was to evaluate the performance of the new large language model ChatGPT (versions 3.5 and 4.0), the widely used WebMD SC, and an SC developed by Ada Health in the diagnosis and triage of patients with urgent or emergent clinical problems compared with the final emergency department (ED) diagnoses and physician reviews.Methods: We used previously collected, deidentified, self-report data from 40 patients presenting to an ED for care who used the Ada SC to record their symptoms prior to seeing the ED physician. Deidentified data were entered into ChatGPT versions 3.5 and 4.0 and WebMD by a research assistant blinded to diagnoses and triage. Diagnoses from all 4 systems were compared with the previously abstracted final diagnoses in the ED as well as with diagnoses and triage recommendations from three independent board-certified ED physicians who had blindly reviewed the self-report clinical data from Ada. Diagnostic accuracy was calculated as the proportion of the diagnoses from ChatGPT, Ada SC, WebMD SC, and the independent physicians that matched at least one ED diagnosis (stratified as top 1 or top 3). Triage accuracy was calculated as the number of recommendations from ChatGPT, WebMD, or Ada that agreed with at least 2 of the independent physicians or were rated "unsafe" or "too cautious."Results: Overall, 30 and 37 cases had sufficient data for diagnostic and triage analysis, respectively. The rate of top-1 diagnosis matches for Ada, ChatGPT 3.5, ChatGPT 4.0, and WebMD was 9 (30%), 12 (40%), 10 (33%), and 12 (40%), respectively, with a mean rate of 47% for the physicians. The rate of top-3 diagnostic matches for Ada, ChatGPT 3.5, ChatGPT 4.0, and WebMD was 19 (63%), 19 (63%), 15 (50%), and 17 (57%), respectively, with a mean rate of 69% for physicians. The distribution of triage results for Ada was 62% (n=23) agree, 14% unsafe (n=5), and 24% (n=9) too cautious; that for ChatGPT 3.5 was 59% (n=22) agree, 41% (n=15) unsafe, and 0% (n=0) too cautious; that for ChatGPT 4.0 was 76% (n=28) agree, 22% (n=8) unsafe, and 3% (n=1) too cautious; and that for WebMD was 70% (n=26) agree, 19% (n=7) unsafe, and 11% (n=4) too cautious. The unsafe triage rate for ChatGPT 3.5 (41%) was significantly higher (P=.009) than that of Ada (14%).Conclusions: ChatGPT 3.5 had high diagnostic accuracy but a high unsafe triage rate. ChatGPT 4.0 had the poorest diagnostic accuracy, but a lower unsafe triage rate and the highest triage agreement with the physicians. The Ada and WebMD SCs performed better overall than ChatGPT. Unsupervised patient use of ChatGPT for diagnosis and triage is not recommended without improvements to triage accuracy and extensive clinical evaluation.	[Fraser, Hamish; Crossland, Daven; Bacher, Ian] Brown Univ, Brown Ctr Biomed Informat, Warren Alpert Med Sch, Providence, RI USA; [Fraser, Hamish] Brown Univ, Dept Hlth Serv Policy & Practice, Sch Publ Hlth, Providence, RI USA; [Crossland, Daven; Madsen, Tracy] Brown Univ, Sch Publ Hlth, Dept Epidemiol, Providence, RI USA; [Ranney, Megan] Yale Univ, Sch Publ Hlth, New Haven, CT USA; [Madsen, Tracy] Brown Univ, Warren Alpert Med Sch, Dept Emergency Med, Providence, RI USA; [Hilliard, Ross] Maine Med Ctr, Dept Internal Med, Portland, ME USA; [Fraser, Hamish] Brown Univ, Brown Ctr Biomed Informat, Warren Alpert Med Sch, 233 Richmond St, Providence, RI 02912 USA	Brown University; Brown University; Brown University; Yale University; Brown University; Maine Medical Center; Brown University	Fraser, H (corresponding author), Brown Univ, Brown Ctr Biomed Informat, Warren Alpert Med Sch, 233 Richmond St, Providence, RI 02912 USA.	hamish_fraser@brown.edu		Madsen, Tracy/0000-0001-5101-0776; Bacher, Ian/0000-0003-2383-3411	Brown University Office of the Vice President of Research (OVPR) Seed award; Agency for Healthcare Research and Quality [R01HS029513]; COBRE NIGMS [P20 GM139664]; NHLBI [K23 HL140081]	Brown University Office of the Vice President of Research (OVPR) Seed award; Agency for Healthcare Research and Quality(United States Department of Health & Human ServicesAgency for Healthcare Research & Quality); COBRE NIGMS; NHLBI(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Heart Lung & Blood Institute (NHLBI))	This study received funding from the Brown University Office of the Vice President of Research (OVPR) Seed award, (HF, MR, TM and RH) , and from the Agency for Healthcare Research and Quality (R01HS029513; HF, MR, TM and RH) . MR also received funding from COBRE NIGMS P20 GM139664. TM also received funding from NHLBI K23 HL140081.	Ada Health, 2022, ABOUT US; Akyürek E, 2023, Arxiv, DOI arXiv:2211.15661; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; [Anonymous], WebMD symptom checker; [Anonymous], Emergency Severity Index (ESI): A Triage Tool for Emergency; [Anonymous], 2023, What is ChatGPT? Commonly asked questions about ChatGPT; BARNETT GO, 1987, JAMA-J AM MED ASSOC, V258, P67, DOI 10.1001/jama.258.1.67; Benoit JRA, 2023, medRxiv, DOI [10.1101/2023.02.04.23285478, 10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478V1, DOI 10.1101/2023.02.04.23285478]; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Ceney A, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0254088; Chan F, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0260696; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Cotte F, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/32340; Fraser H, 2018, LANCET, V392, P2263, DOI 10.1016/S0140-6736(18)32819-8; Fraser HSF, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/38364; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gilbert S, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2020-040269; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hamilton W, 2012, NAT REV CLIN ONCOL, V9, P251, DOI 10.1038/nrclinonc.2012.63; Hardesty L, 2017, MIT News; Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010; Harskamp RE, 2023, medRxiv, DOI [10.1101/2023.03.25.23285475, https://doi.org/10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475, 10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475V1]; Hill MG, 2020, MED J AUSTRALIA, V212, P514, DOI 10.5694/mja2.50600; Levine DM, 2023, medRxiv, DOI [10.1101/2023.01.30.23285067, 10.1101/2023.01.30.23285067, DOI 10.1101/2023.01.30.23285067]; Levine DM, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.3287; Millenson ML, 2018, DIAGNOSIS, V5, P95, DOI 10.1515/dx-2018-0009; Montazeri M, 2021, JMIR FORM RES, V5, DOI 10.2196/26402; Schmieding ML, 2022, J MED INTERNET RES, V24, DOI 10.2196/31810; Semigran HL, 2016, JAMA INTERN MED, V176, P1860, DOI 10.1001/jamainternmed.2016.6001; Semigran HL, 2015, BMJ-BRIT MED J, V351, DOI 10.1136/bmj.h3480; Shortliffe EN, 2022, Intelligent systems in medicine and health. The role of AI, P21; Slovis BH, 2019, WEST J EMERG MED, V20, P910, DOI 10.5811/westjem.2019.8.44230; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Vardell Emily, 2011, Medical Reference Services Quarterly, V30, P158, DOI 10.1080/02763869.2011.562800; Yu SWY, 2020, HONG KONG J EMERG ME, V27, P217, DOI 10.1177/1024907919842486; Zewe A., 2023, MIT NewsFeb 07	36	11	11	10	17	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2291-5222			JMIR MHEALTH UHEALTH	JMIR mHealth uHealth		2023	11								e49995	10.2196/49995	http://dx.doi.org/10.2196/49995			10	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	U7IP8	37788063	gold, Green Published			2024-07-03	WOS:001086508900002
J	Shutske, JM				Shutske, John M.			Harnessing the Power of Large Language Models in Agricultural Safety & Health	JOURNAL OF AGRICULTURAL SAFETY AND HEALTH			English	Editorial Material						Agricultural safety; Artificial intelligence; Bias; ChatGPT; Consultation; Ex-tension; Generative AI; Health; Education; Intellectual Property; Large language models; LLM; Teaching	CHATGPT		[Shutske, John M.] Univ Wisconsin, Madison, WI 53707 USA	University of Wisconsin System; University of Wisconsin Madison	Shutske, JM (corresponding author), Univ Wisconsin, Madison, WI 53707 USA.	shutske@wisc.edu			USDA National Institute of Food and Agriculture, Hatch Project [1022349]	USDA National Institute of Food and Agriculture, Hatch Project	<STRONG> </STRONG>This work has been partially supported by the USDA National Institute of Food and Agriculture, Hatch Project 1022349.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anderson J, 2023, AI SPREADS EXPERTS P; [Anonymous], 2023, Reuters; ASABE Standards, 2022, S615.2: Cotton module cover material performance; ASABE Standards, 2022, EP 470.1: Manure storage safety engineering practice; ASABE Standards, 2019, S279.18: Lighting and marking of agricultural equipment on highways; AskYourPDF, 2023, About us; California OSHA Standards Board, 2023, OSHSB BOARD M; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Dogru T, 2023, J HOSP TOUR RES, DOI 10.1177/10963480231188663; Ekin S., 2023, PREPRINT, DOI [10.36227/techrxiv.22683919, DOI 10.36227/TECHRXIV.22683919]; FAO, 2020, Food and Agriculture Statistics; George A. S., 2023, Partners Universal International Innovation Journal, V1, P9, DOI DOI 10.5281/ZENODO.7644359; Iowa State FACE Program, 2006, Iowa Case Report: 05IA022; Kahveci ZU, 2023, J INTELLET PROP LAW, V18, P796, DOI 10.1093/jiplp/jpad076; Liu Y, 2021, IEEE T IND INFORM, V17, P4322, DOI 10.1109/TII.2020.3003910; Michigan FACE Program, 2019, Michigan Case Report: 17MI098; Midjourney, 2023, Midjourney home page; NIOSH, 2023, Fatality Assessment and Control Evaluation (FACE) Program; OpenAI, 2023, Introducing ChatGPT Plus; OpenAI, 2023, ChatGPT overview; OSHA, 1971, Part 1928 Occupational safety and health standards for agriculture standard; Peres R, 2023, INT J RES MARK, V40, P269, DOI 10.1016/j.ijresmar.2023.03.001; Ray PP, 2023, ACS AGR SCI TECHNOL, V3, P460, DOI 10.1021/acsagscitech.3c00145; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sandner K., 2021, Paper No. 2101006, DOI [10.13031/aim.202101006, DOI 10.13031/AIM.202101006]; Smolansky A, 2023, PROCEEDINGS OF THE TENTH ACM CONFERENCE ON LEARNING @ SCALE, L@S 2023, P378, DOI 10.1145/3573051.3596191; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Strowel A, 2023, IIC-INT REV INTELL P, DOI 10.1007/s40319-023-01321-y; WA State FACE Program, 2023, Washington Case Report: 22WA5254; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216	32	0	0	8	8	AMER SOC AGRICULTURAL & BIOLOGICAL ENGINEERS	ST JOSEPH	2950 NILES RD, ST JOSEPH, MI 49085-9659 USA	1074-7583	1943-7846		J AGRIC SAF HEALTH	J. Agric. Saf. Health		2023	29	4					205	224		10.13031/jash.15841	http://dx.doi.org/10.13031/jash.15841			20	Public, Environmental & Occupational Health	Emerging Sources Citation Index (ESCI)	Public, Environmental & Occupational Health	DQ5N2		Bronze			2024-07-03	WOS:001133537400002
C	Banat, R; Colton, S			IEEE	Banat, Rerker; Colton, Simon			Autoregressive Self-Evaluation: A Case Study of Music Generation Using Large Language Models	2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI			English	Proceedings Paper	IEEE Conference on Artificial Intelligence (IEEE CAI)	JUN 05-06, 2023	Santa Clara, CA	IEEE, IEEE Comp Soc, IEEE Signal Proc Soc, IEEE Syst, Man, & Cybernet Soc		autoregressive self-evalution; autoregressive models; generative models; large language models; music generation		Autoregressive models have shown significant success in many tasks such as natural language generation and music composition. However, generic training mechanisms with off-the-shelf loss functions (e.g. cross-entropy), where not much attention is paid to the specifics of the task, do not necessarily guarantee success as different data modalities (e.g. text, visuals, music) exhibit different natures. In this study, we present a novel autoregressive self-evaluation framework to assess the performance of autoregressive models with both domain-agnostic and domain-specific metrics. We demonstrate this strategy with a case study of music generation using GPT-2 within a transfer learning paradigm. We contrast and compare the effects of fundamental parameters in autoregressive generation such as the temperature in sampling and the length of the generated sequence.	[Banat, Rerker; Colton, Simon] Queen Mary Univ London, Sch EECS, London, England	University of London; Queen Mary University London	Banat, R (corresponding author), Queen Mary Univ London, Sch EECS, London, England.	b.banar@qmul.ac.uk; s.colton@qmul.ac.uk			UK Research and Innovation [EP/S022694/1]; Queen Mary University of London	UK Research and Innovation(UK Research & Innovation (UKRI)); Queen Mary University of London	Berker Banar is a research student at the UKRI Centre for Doctoral Training in Artificial Intelligence and Music, supported jointly by UK Research and Innovation [grant number EP/S022694/1] and Queen Mary University of London.	Banar B, 2021, EVO; Banar B, 2022, IEEE INT WORKSH MULT, DOI 10.1109/MMSP55362.2022.9948708; Banar B, 2022, LECT NOTES COMPUT SC, P19, DOI 10.1007/978-3-031-03789-4_2; Hawthorne C, 2022, PR MACH LEARN RES; Kong Q., 2020, Transactions of the International Society for Music Information Retrieval, V5, P87; Menick J, 2018, arXiv; OpenAI, 2023, GPT-4 Technical Report; Payne C., 2019, MuseNet; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Vaswani A, 2017, ADV NEUR IN, V30; Wu Z., 2021, arXiv	11	1	1	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3984-0				2023							264	265		10.1109/CAI54212.2023.00118	http://dx.doi.org/10.1109/CAI54212.2023.00118			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5BQ					2024-07-03	WOS:001046447800108
J	Cao, XZ; Liao, CY; Zhou, ZH; Zhong, Z; Li, ZT; Dai, EP; Iyer, SS; Hannum, AJ; Yurt, M; Schauman, S; Chen, Q; Wang, N; Wei, JT; Yan, YF; He, HJ; Skare, S; Zhong, JH; Kerr, A; Setsompop, K				Cao, Xiaozhi; Liao, Congyu; Zhou, Zihan; Zhong, Zheng; Li, Zhitao; Dai, Erpeng; Iyer, Siddharth Srinivasan; Hannum, Ariel J.; Yurt, Mahmut; Schauman, Sophie; Chen, Quan; Wang, Nan; Wei, Jintao; Yan, Yifan; He, Hongjian; Skare, Stefan; Zhong, Jianhui; Kerr, Adam; Setsompop, Kawin			DTI-MR fingerprinting for rapid high-resolution whole-brain T<sub>1</sub>, T<sub>2</sub>, proton density, ADC, and fractional anisotropy mapping	MAGNETIC RESONANCE IN MEDICINE			English	Article						diffusion preparation; MRF; quantitative mapping	STATE FREE PRECESSION; ISOTROPIC RESOLUTION; MAGNETIC-RESONANCE; DIFFUSION; ARTIFACTS; PHYSICS; SENSE; FLAIR	Purpose: This study aims to develop a high-efficiency and high-resolution 3D imaging approach for simultaneous mapping of multiple key tissue parameters for routine brain imaging, including T-1, T-2, proton density (PD), ADC, and fractional anisotropy (FA). The proposed method is intended for pushing routine clinical brain imaging from weighted imaging to quantitative imaging and can also be particularly useful for diffusion-relaxometry studies, which typically suffer from lengthy acquisition time.Methods: To address challenges associated with diffusion weighting, such as shot-to-shot phase variation and low SNR, we integrated several innovative data acquisition and reconstruction techniques. Specifically, we used M1-compensated diffusion gradients, cardiac gating, and navigators to mitigate phase variations caused by cardiac motion. We also introduced a data-driven pre-pulse gradient to cancel out eddy currents induced by diffusion gradients. Additionally, to enhance image quality within a limited acquisition time, we proposed a data-sharing joint reconstruction approach coupled with a corresponding sequence design.Results: The phantom and in vivo studies indicated that the T(1 )and T(2 )values measured by the proposed method are consistent with a conventional MR fingerprinting sequence and the diffusion results (including diffusivity, ADC, and FA) are consistent with the spin-echo EPI DWI sequence.Conclusion: The proposed method can achieve whole-brain T-1, T-2, diffusivity, ADC, and FA maps at 1-mm isotropic resolution within 10 min, providing a powerful tool for investigating the microstructural properties of brain tissue, with potential applications in clinical and research settings.	[Cao, Xiaozhi; Liao, Congyu; Zhou, Zihan; Zhong, Zheng; Li, Zhitao; Dai, Erpeng; Iyer, Siddharth Srinivasan; Hannum, Ariel J.; Yurt, Mahmut; Schauman, Sophie; Chen, Quan; Wang, Nan; Setsompop, Kawin] Stanford Univ, Dept Radiol, Room 301,350 Jane Stanford Way, Stanford, CA 94305 USA; [Cao, Xiaozhi; Liao, Congyu; Yurt, Mahmut; Schauman, Sophie; Chen, Quan; Wang, Nan; Kerr, Adam; Setsompop, Kawin] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Iyer, Siddharth Srinivasan] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA USA; [Hannum, Ariel J.] Stanford Univ, Dept Bioengn, Stanford, CA 94305 USA; [Wei, Jintao; He, Hongjian] Zhejiang Univ, Ctr Brain Imaging Sci & Technol, Hangzhou, Peoples R China; [Yan, Yifan] Zhejiang Univ, Sch Med, Sch Publ Hlth, Hangzhou, Peoples R China; [Yan, Yifan] Zhejiang Univ, Affiliated Hosp 2, Sch Med, Hangzhou, Peoples R China; [He, Hongjian] Zhejiang Univ, Sch Phys, Hangzhou 310027, Peoples R China; [Skare, Stefan] Karolinska Inst, Dept Clin Neurosci, Stockholm, Sweden; [Zhong, Jianhui] Univ Rochester, Dept Imaging Sci, Rochester, NY USA	Stanford University; Stanford University; Massachusetts Institute of Technology (MIT); Stanford University; Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang University; Karolinska Institutet; University of Rochester	Liao, CY (corresponding author), Stanford Univ, Dept Radiol, Room 301,350 Jane Stanford Way, Stanford, CA 94305 USA.	cyliao@stanford.edu	Setsompop, Kawin/P-1464-2014; Liu, Zhe/KEJ-5299-2024; Li, Zhitao/AAM-2867-2021; wen, Wen/KBB-1727-2024	Setsompop, Kawin/0000-0003-0455-7634; Iyer, Siddharth/0000-0002-6432-0850; Hannum, Ariel/0000-0003-0650-574X; Dai, Erpeng/0000-0002-1032-5883; Schauman, Sophie/0000-0002-3744-2553; Cao, Xiaozhi/0000-0001-5095-648X; Li, Zhitao/0000-0003-3462-6549	This work was supported in part by NIH (R01-EB020613, R01-EB019437, R01-MH116173, P41EB030006, and U01-EB025162) and GE Healthcare. In the preparation of this manuscript, the OpenAIapos;s Large Language Model (LLM), specifically the GPT-4 architecture, wa [R01-EB020613, R01-EB019437, R01-MH116173, P41EB030006, U01-EB025162]; NIH; GE Healthcare	This work was supported in part by NIH (R01-EB020613, R01-EB019437, R01-MH116173, P41EB030006, and U01-EB025162) and GE Healthcare. In the preparation of this manuscript, the OpenAIapos;s Large Language Model (LLM), specifically the GPT-4 architecture, wa; NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); GE Healthcare(General ElectricGE Healthcare)	This work was supported in part by NIH (R01-EB020613, R01-EB019437, R01-MH116173, P41EB030006, and U01-EB025162) and GE Healthcare. In the preparation of this manuscript, the OpenAI & apos;s Large Language Model (LLM), specifically the GPT-4 architecture, was used for grammar check.	Afzali M, 2022, MAGN RESON MED, V88, P2043, DOI 10.1002/mrm.29352; Alexander AL, 1997, MAGN RESON MED, V38, P1016, DOI 10.1002/mrm.1910380623; ANDERSON AW, 1994, MAGNET RESON MED, V32, P379, DOI 10.1002/mrm.1910320313; Badve C, 2017, AM J NEURORADIOL, V38, P492, DOI 10.3174/ajnr.A5035; Bao QJ, 2020, NMR BIOMED, V33, DOI 10.1002/nbm.4208; Cao X., 2019, P 27 ANN M ISMRM MON, P312; Cao X., 2022, P INT SOC MAG RESON, P101; Cao XZ, 2022, MAGN RESON MED, V88, P133, DOI 10.1002/mrm.29194; Cao XZ, 2021, MAGN RESON MED, V86, P2064, DOI 10.1002/mrm.28872; Cao XZ, 2019, MAGN RESON MED, V82, P289, DOI 10.1002/mrm.27726; Cervantes B, 2018, MAGN RESON MED, V80, P609, DOI 10.1002/mrm.27072; Chang HC, 2015, NEUROIMAGE, V118, P667, DOI 10.1016/j.neuroimage.2015.06.016; Conturo TE, 1995, NMR BIOMED, V8, P307, DOI 10.1002/nbm.1940080706; Deshmane A, 2012, J MAGN RESON IMAGING, V36, P55, DOI 10.1002/jmri.23639; Dietrich BE, 2016, MAGN RESON MED, V75, P1831, DOI 10.1002/mrm.25770; Finsterbusch J, 2009, MAGN RESON MED, V61, P748, DOI 10.1002/mrm.21899; Flassbeck S, 2019, MAGN RESON MED, V81, P2536, DOI 10.1002/mrm.27588; Gao Y, 2020, MED PHYS, V47, P3511, DOI 10.1002/mp.14195; Gao Y, 2019, MAGN RESON MED, V81, P2374, DOI 10.1002/mrm.27565; Gómez PA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70789-2; Habib J, 2010, MAGN RESON MED, V63, P1098, DOI 10.1002/mrm.22232; Haider MA, 2007, AM J ROENTGENOL, V189, P323, DOI 10.2214/AJR.07.2211; Hilbert T, 2020, MAGN RESON MED, V84, P128, DOI 10.1002/mrm.28096; Hu S., 2019, APPL MAGNETIC RESONA; Huang F, 2008, MAGN RESON IMAGING, V26, P133, DOI 10.1016/j.mri.2007.04.010; Iyer SS., 2020, P 28 ANN M ISMRM SYD, P661; Jellison BJ, 2004, AM J NEURORADIOL, V25, P356; Jiang Y, 2015, MAGN RESON MED, V74, P1621, DOI 10.1002/mrm.25559; Koktzoglou I, 2007, J CARDIOVASC MAGN R, V9, P33, DOI 10.1080/10976640600843413; Le Bihan D, 2006, J MAGN RESON IMAGING, V24, P478, DOI 10.1002/jmri.20683; Lee PK, 2019, MAGN RESON MED, V82, P1438, DOI 10.1002/mrm.27832; Li Q, 2019, MAGN RESON MED, V82, P1359, DOI 10.1002/mrm.27812; Liang ZP, 2007, I S BIOMED IMAGING, P988; Liao C., 2023, PROC 31 ANN MEET, P1236; Liao C., 2022, ISMRM, V2, P365, DOI [10.1002/mrm.28509.2, DOI 10.1002/MRM.28509.2]; Liao CY, 2023, NEUROIMAGE, V275, DOI 10.1016/j.neuroimage.2023.120168; Liao CY, 2021, MAGN RESON MED, V86, P791, DOI 10.1002/mrm.28748; Liao CY, 2018, RADIOLOGY, V288, P804, DOI 10.1148/radiol.2018172131; Liao CY, 2017, NEUROIMAGE, V162, P13, DOI 10.1016/j.neuroimage.2017.08.030; Liu CL, 2004, MAGN RESON MED, V52, P1388, DOI 10.1002/mrm.20288; Lu L, 2012, MAGN RESON MED, V68, P868, DOI 10.1002/mrm.23287; Lustig M, 2007, MAGN RESON MED, V58, P1182, DOI 10.1002/mrm.21391; Ma D, 2019, J MAGN RESON IMAGING, V49, P1333, DOI 10.1002/jmri.26319; Ma D, 2013, NATURE, V495, P187, DOI 10.1038/nature11971; Ma S, 2020, MAGN RESON MED, V84, P72, DOI 10.1002/mrm.28092; Mesri HY, 2020, NEUROIMAGE, V205, DOI 10.1016/j.neuroimage.2019.116127; MUGLER JP, 1990, MAGNET RESON MED, V15, P152, DOI 10.1002/mrm.1910150117; Nguyen C, 2014, MAGN RESON MED, V72, P1257, DOI 10.1002/mrm.25038; Noguchi K, 1997, NEURORADIOLOGY, V39, P406, DOI 10.1007/s002340050433; Norbeck O, 2020, MAGN RESON MED, V84, P1441, DOI 10.1002/mrm.28222; Nunes RG, 2005, J MAGN RESON, V177, P102, DOI 10.1016/j.jmr.2005.07.005; O'Halloran R., 2011, PROC 19 SCI MEET ISM, V19, P1961; Panda A, 2019, RADIOLOGY, V292, P685, DOI 10.1148/radiol.2019181705; Perlman O, 2023, NMR BIOMED, V36, DOI 10.1002/nbm.4710; Pruessmann KP, 1999, MAGNET RESON MED, V42, P952, DOI 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S; Reese TG, 2003, MAGN RESON MED, V49, P177, DOI 10.1002/mrm.10308; Rogers W., 2020, BR I RADIOL, V1, P1; Rosenkrantz AB, 2015, ACAD RADIOL, V22, P33, DOI 10.1016/j.acra.2014.08.011; Saranathan M, 2017, J MAGN RESON IMAGING, V46, P1590, DOI 10.1002/jmri.25737; Schauman S., 2022, P 31 ANN M ISMRM, P53; Setsompop K, 2012, MAGN RESON MED, V67, P1210, DOI 10.1002/mrm.23097; Sharafi A, 2021, MAGN RESON MED, V86, P372, DOI 10.1002/mrm.28704; Skare S, 2001, MAGN RESON IMAGING, V19, P1125, DOI 10.1016/S0730-725X(01)00415-5; Stockmann JP, 2022, MAGN RESON MED, V87, P1074, DOI 10.1002/mrm.29022; Tamir JI, 2017, MAGN RESON MED, V77, P180, DOI 10.1002/mrm.26102; Terem I, 2021, MAGN RESON MED, V86, P1674, DOI [10.1002/mrm.2879D, 10.1002/mrm.28797]; Uecker M., 2016, P INT SOC MAGN RESON; Uecker M, 2014, MAGN RESON MED, V71, P990, DOI 10.1002/mrm.24751; Wang CY, 2019, MAGN RESON MED, V81, P1849, DOI 10.1002/mrm.27543; Wang FYX, 2022, NEUROIMAGE, V250, DOI 10.1016/j.neuroimage.2022.118963; Wang K, 2019, ANN CLIN TRANSL NEUR, V6, P1639, DOI 10.1002/acn3.50851; Weigel M, 2015, J MAGN RESON IMAGING, V41, P266, DOI 10.1002/jmri.24619; Wu D, 2021, MAGN RESON MED, V85, P92, DOI 10.1002/mrm.28401; Wyatt CR, 2020, NMR BIOMED, V33, DOI 10.1002/nbm.4284; Zhang QW, 2017, NMR BIOMED, V30, DOI 10.1002/nbm.3719; Zhang T, 2015, MAGN RESON MED, V73, P655, DOI 10.1002/mrm.25161; Zhang YX, 2019, MAGN RESON MED, V81, P167, DOI 10.1002/mrm.27358; Zhang ZJ, 2022, MAGN RESON MED, V88, P633, DOI 10.1002/mrm.29219; Zhou ZH, 2023, HUM BRAIN MAPP, V44, P2209, DOI 10.1002/hbm.26203	79	0	0	0	4	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0740-3194	1522-2594		MAGN RESON MED	Magn. Reson. Med.	MAR	2024	91	3					987	1001		10.1002/mrm.29916	http://dx.doi.org/10.1002/mrm.29916		NOV 2023	15	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	EK2K7	37936313				2024-07-03	WOS:001100341400001
J	Kleebayoon, A; Wiwanitkit, V				Kleebayoon, Amnuay; Wiwanitkit, Viroj			Large Language Models and Psychoeducation	JOURNAL OF ECT			English	Letter									[Wiwanitkit, Viroj] Chandigarh Univ, Mohali, Punjab, India; [Wiwanitkit, Viroj] Joesph Ayobabalola Univ, Ikeji Arakeji, Nigeria	Chandigarh University	Wiwanitkit, V (corresponding author), Chandigarh Univ, Mohali, Punjab, India.; Wiwanitkit, V (corresponding author), Joesph Ayobabalola Univ, Ikeji Arakeji, Nigeria.	amnuaykleebai@gmail.com; wviroj@yahoo.com						Kleebayoon A, 2023, CELL MOL BIOENG, V16, P173, DOI 10.1007/s12195-023-00759-x; Lundin RM, 2023, J ECT, V39, P130, DOI 10.1097/YCT.0000000000000941	2	0	0	4	4	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	1095-0680	1533-4112		J ECT	J. ECT	MAR	2024	40	1					e1	e1		10.1097/YCT.0000000000000956	http://dx.doi.org/10.1097/YCT.0000000000000956			1	Behavioral Sciences; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Psychiatry	KC3Z7	37561924				2024-07-03	WOS:001177735200011
J	Shanahan, M				Shanahan, Murray			Talking about Large Language Models	COMMUNICATIONS OF THE ACM			English	Article									[Shanahan, Murray] Imperial Coll London, Dept Comp, Cognit Robot, London, England	Imperial College London	Shanahan, M (corresponding author), Imperial Coll London, Dept Comp, Cognit Robot, London, England.	m.shanahan@imperial.ac.uk						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Alayrac JB., 2022, Advances in Neural Information Processing Systems (NeurIPS); Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chan S.C., 2022, ADV NEURAL INFORM PR; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Creswell A., 2023, P INT C LEARN REPR; Creswell A, 2022, Arxiv, DOI arXiv:2208.14271; DAVIDSON D, 1982, DIALECTICA, V36, P317, DOI 10.1111/j.1746-8361.1982.tb01546.x; Dennett Daniel., 2009, The Oxford Handbook of Philosophy of Mind, DOI DOI 10.1093/OXFORDHB/9780199262618.003.0020; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Elhage N., 2021, Transformer Circuits Thread; Glaese A, 2022, arXiv; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lake BM, 2023, PSYCHOL REV, V130, P401, DOI 10.1037/rev0000297; Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813; Lu J., 2019, arXiv, DOI [DOI 10.48550/ARXIV.1908.02265, 10.48550/arXiv.1908.02265]; Marcus G., 2020, MIT Technology Rev.; Meng K., 2022, Advances in Neural Information Processing Systems; Nye Maxwell, 2021, arXiv; Olsson N., 2022, Transformer Circuits Thread; Ouyang L., 2022, Advances in Neural Information Processing Systems; Piantasodi S, 2022, Arxiv, DOI [arXiv:2208.02957, 10.48550/arXiv.2208.02957, DOI 10.48550/ARXIV.2208.02957]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ruane E., 2019, AICS, P104; Schick T., 2023, arXiv; Shanahan M., 2022, PROC IJCAI, V31, P5588; Smith BC, 2019, PROMISE OF ARTIFICIAL INTELLIGENCE: RECKONING AND JUDGMENT, P1; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wei Jason, 2022, ADV NEURAL INFORM PR; Wei JH, 2022, PR MACH LEARN RES; Weidinger L., arXiv; Wilson E.O., 1975, P1; Yao S., 2023, P INT C LEARN REPR	41	3	3	13	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0001-0782	1557-7317		COMMUN ACM	Commun. ACM	FEB	2024	67	2					68	79		10.1145/3624724	http://dx.doi.org/10.1145/3624724			12	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	JB0R3		Green Submitted, Bronze			2024-07-03	WOS:001170580600017
J	Gabriel, J; Shafik, L; Vincent, E; Ajzajian, J; Alanbuki, A; Larner, TRG				Gabriel, Joseph; Shafik, Lidia; Vincent, Elizabeth; Ajzajian, Jirayr; Alanbuki, Ammar; Larner, Timothy R. G.			The computer will see you now: ChatGPT and artificial intelligence large language models for health information in urology-an invited perspective	TRANSLATIONAL ANDROLOGY AND UROLOGY			English	Editorial Material						ChatGPT; artificial intelligence (AI); large language model (LLM); patient information; health information			[Gabriel, Joseph; Vincent, Elizabeth; Ajzajian, Jirayr; Alanbuki, Ammar; Larner, Timothy R. G.] Univ Hosp Sussex NHS Fdn Trust, Princess Royal Hosp, Dept Urol, Worthing, England; [Shafik, Lidia] Frimley Hlth NHS Fdn Trust, Dept Med, Surrey, England; [Gabriel, Joseph] Univ Hosp Sussex NHS Fdn Trust, Princess Royal Hosp, Dept Urol, Special Trainee ST6 Urol,Lewes Rd, Haywards Heath RH16 4EX, East Sussex, England		Gabriel, J (corresponding author), Univ Hosp Sussex NHS Fdn Trust, Princess Royal Hosp, Dept Urol, Special Trainee ST6 Urol,Lewes Rd, Haywards Heath RH16 4EX, East Sussex, England.	joseph.gabriel@nhs.net	Shafik, Lidia/JZT-0410-2024	Shafik, Lidia/0000-0001-5539-8763				Adhikari K, 2024, CURR UROL REP, V25, P1, DOI 10.1007/s11934-023-01185-2; Barrett A, 2023, J UROLOGY, V210, P833, DOI 10.1097/JU.0000000000003718; Cocci A, 2024, PROSTATE CANCER P D, V27, P103, DOI 10.1038/s41391-023-00705-y; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; Davis R, 2023, J UROLOGY, V210, P688, DOI 10.1097/JU.0000000000003615; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gabriel J, 2023, INT UROL NEPHROL, V55, P2717, DOI 10.1007/s11255-023-03729-4; Golan R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42214; Hu K., 2023, Reuters; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Musheyev D, 2024, EUR UROL, V85, P13, DOI 10.1016/j.eururo.2023.07.004; Talyshinskii A, 2023, FRONT SURG, V10, DOI 10.3389/fsurg.2023.1257191; Weiss BD., 2003, Health Literacy: A Manual for Clinicians; Zhou ZH, 2023, EUR UROL, V84, P355, DOI 10.1016/j.eururo.2023.03.037; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	15	0	0	19	19	AME PUBLISHING COMPANY	SHATIN	FLAT-RM C 16F, KINGS WING PLAZA 1, NO 3 KWAN ST, SHATIN, HONG KONG 00000, PEOPLES R CHINA	2223-4683	2223-4691		TRANSL ANDROL UROL	Transl. Androl. Urol.	DEC 21	2023	12	12					1772	1774		10.21037/tau-23-491	http://dx.doi.org/10.21037/tau-23-491		DEC 2023	3	Andrology; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Endocrinology & Metabolism; Urology & Nephrology	DV7C7	38196696	Green Published, gold			2024-07-03	WOS:001123739200001
J	Schinas, G; Polyzou, E; Spernovasilis, N; Gogos, C; Dimopoulos, G; Akinosoglou, K				Schinas, Georgios; Polyzou, Elena; Spernovasilis, Nikolaos; Gogos, Charalambos; Dimopoulos, George; Akinosoglou, Karolina			Preventing Multidrug-Resistant Bacterial Transmission in the Intensive Care Unit with a Comprehensive Approach: A Policymaking Manual	ANTIBIOTICS-BASEL			English	Review						intensive care unit; multidrug-resistant bacteria; transmission; colonization; healthcare personnel	HAND HYGIENE; ANTIBIOTIC STEWARDSHIP; HOSPITAL SURFACES; 5 MOMENTS; CONTAMINATION; COLONIZATION; INFECTION; RISK; PATHOGENS; ENVIRONMENT	Patients referred to intensive care units (ICU) commonly contract infections caused by multidrug-resistant (MDR) bacteria, which are typically linked to complications and high mortality. There are numerous independent factors that are associated with the transmission of these pathogens in the ICU. Preventive multilevel measures that target these factors are of great importance in order to break the chain of transmission. In this review, we aim to provide essential guidance for the development of robust prevention strategies, ultimately ensuring the safety and well-being of patients and healthcare workers in the ICU. We discuss the role of ICU personnel in cross-contamination, existing preventative measures, novel technologies, and strategies employed, along with antimicrobial surveillance and stewardship (AMSS) programs, to construct effective and thoroughly described policy recommendations. By adopting a multifaceted approach that combines targeted interventions with broader preventive strategies, healthcare facilities can create a more coherent line of defense against the spread of MDR pathogens. These recommendations are evidence-based, practical, and aligned with the needs and realities of the ICU setting. In conclusion, this comprehensive review offers a blueprint for mitigating the risk of MDR bacterial transmission in the ICU, advocating for an evidence-based, multifaceted approach.	[Schinas, Georgios; Polyzou, Elena; Gogos, Charalambos; Akinosoglou, Karolina] Univ Patras, Dept Med, Patras 26504, Greece; [Polyzou, Elena; Akinosoglou, Karolina] Univ Gen Hosp Patras, Dept Internal Med & Infect Dis, Patras 26504, Greece; [Spernovasilis, Nikolaos] German Oncol Ctr, Dept Infect Dis, CY-4108 Limassol, Cyprus; [Dimopoulos, George] Natl & Kapodistrian Univ Athens, Evgenidio Hosp, Med Sch, Dept Crit Care 3, Athens 11528, Greece	University of Patras; University of Patras; National & Kapodistrian University of Athens	Spernovasilis, N (corresponding author), German Oncol Ctr, Dept Infect Dis, CY-4108 Limassol, Cyprus.	georg.schinas@gmail.com; polyzou.el@gmail.com; nikspe@hotmail.com; cgogos@med.upatras.gr; gdimop@med.uoa.gr; akin@upatras.gr	Schinas, Georgios/HSH-1828-2023	Schinas, Georgios/0000-0001-7963-1865; Spernovasilis, Nikolaos/0000-0002-6981-8535	This study employed a large language model (LLM) tool to facilitate and improve the writing process. The LLM used in this study was primarily to enhance language proficiency and contextual analysis within the manuscript. The originality, validity, and inte	This study employed a large language model (LLM) tool to facilitate and improve the writing process. The LLM used in this study was primarily to enhance language proficiency and contextual analysis within the manuscript. The originality, validity, and inte	This study employed a large language model (LLM) tool to facilitate and improve the writing process. The LLM used in this study was primarily to enhance language proficiency and contextual analysis within the manuscript. The originality, validity, and integrity of the content are entirely the authors' responsibility, adhering to the MDPI's publication ethics policies. This work aligns with the Committee on Publication Ethics (COPE) statement regarding the use of AI and AI-assisted technology.	Agodi A, 2007, INTENS CARE MED, V33, P1155, DOI 10.1007/s00134-007-0671-6; Albert NM, 2010, AM J CRIT CARE, V19, pE73, DOI 10.4037/ajcc2010304; Ali AS, 2023, INFECT DIS HEALTH, V28, P95, DOI 10.1016/j.idh.2022.11.003; [Anonymous], 2022, Bundesgesundheitsblatt Gesundheitsforschung Gesundheitsschutz, V65, P1074, DOI DOI 10.1007/S00103-022-03576-1; Birkett M, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms23031162; Blehm CJ, 2022, AMB EXPRESS, V12, DOI 10.1186/s13568-022-01491-x; Bonten MJM, 1996, LANCET, V348, P1615, DOI 10.1016/S0140-6736(96)02331-8; Boyce JM, 2016, ANTIMICROB RESIST IN, V5, DOI 10.1186/s13756-016-0111-x; Brady RRW, 2009, J HOSP INFECT, V71, P295, DOI 10.1016/j.jhin.2008.12.009; Brêda Mascarenhas LA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250854; Buising KL, 2008, J ANTIMICROB CHEMOTH, V62, P608, DOI 10.1093/jac/dkn218; Bures S, 2000, AM J INFECT CONTROL, V28, P465, DOI 10.1067/mic.2000.107267; Çaglayan Ç, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.853757; Casini Beatrice, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20054284; Cavallaro Massimo, 2023, PLOS Digit Health, V2, pe0000162, DOI 10.1371/journal.pdig.0000162; Chen KH, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0078512; Chen YC, 2021, AM J INFECT CONTROL, V49, P1511, DOI 10.1016/j.ajic.2021.07.011; Chou DTS, 2012, J BONE JOINT SURG BR, V94B, P441, DOI 10.1302/0301-620X.94B4.27772; Davari M, 2018, ETHIOP J HEALTH SCI, V28, P795, DOI 10.4314/ejhs.v28i6.15; De Groote P, 2022, INTENS CRIT CARE NUR, V72, DOI 10.1016/j.iccn.2022.103266; Denis JB, 2019, AM J INFECT CONTROL, V47, P1059, DOI 10.1016/j.ajic.2019.02.030; Doll Michelle E, 2022, Antimicrob Steward Healthc Epidemiol, V2, pe126, DOI 10.1017/ash.2022.264; Dyar OJ, 2017, CLIN MICROBIOL INFEC, V23, P793, DOI 10.1016/j.cmi.2017.08.026; Elbehiry A, 2022, VACCINES-BASEL, V10, DOI 10.3390/vaccines10122100; Evans RS, 1998, NEW ENGL J MED, V338, P232, DOI 10.1056/NEJM199801223380406; Frazee BW, 2011, ANN EMERG MED, V58, P56, DOI 10.1016/j.annemergmed.2010.12.015; Galvin S, 2012, J HOSP INFECT, V82, P143, DOI 10.1016/j.jhin.2012.06.015; Montero JG, 2015, CRIT CARE, V19, DOI 10.1186/s13054-015-0800-5; Gestrich SA, 2018, INFECT CONT HOSP EP, V39, P1467, DOI 10.1017/ice.2018.191; Glowicz JB, 2023, INFECT CONT HOSP EP, V44, P355, DOI 10.1017/ice.2022.304; Han Y, 2022, WORLD J CLIN CASES, V10, P1795, DOI 10.12998/wjcc.v10.i6.1795; Haque M, 2020, RISK MANAG HEALTHC P, V13, P1765, DOI 10.2147/RMHP.S269315; Hayden MK, 2008, INFECT CONT HOSP EP, V29, P149, DOI 10.1086/524331; Hess OCR, 2021, INFECT CONT HOSP EP, V42, P1007, DOI 10.1017/ice.2020.1336; Hu H, 2015, J HOSP INFECT, V91, P35, DOI 10.1016/j.jhin.2015.05.016; Huang J, 2020, J INT MED RES, V48, DOI 10.1177/0300060520949766; Jamin C, 2021, MICROB GENOMICS, V7, DOI 10.1099/mgen.0.000567; Kernéis S, 2019, SEMIN RESP CRIT CARE, V40, P558, DOI 10.1055/s-0039-1696980; Kramer A., 2014, USE BIOCIDAL SURF RE, P7, DOI DOI 10.1007/978-3-319-08057-4_2; Lakbar I, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95852-4; Lanckohr C, 2021, ANN INTENSIVE CARE, V11, DOI 10.1186/s13613-021-00917-2; Lestari T, 2013, GMS HYG INFECT CONTR, V8, DOI 10.3205/dgkh000207; Levin PD, 2009, CHEST, V136, P426, DOI 10.1378/chest.09-0049; Lindsay PJ, 2019, CLIN INFECT DIS, V68, P748, DOI 10.1093/cid/ciy550; LOWBURY EJL, 1971, J HYG-CAMB, V69, P529, DOI 10.1017/S002217240002180X; Majumder MAA, 2020, INFECT DRUG RESIST, V13, P4713, DOI 10.2147/IDR.S290835; Mandelli G, 2022, J CLIN MED, V11, DOI 10.3390/jcm11154409; Masse J, 2017, EUR J CLIN MICROBIOL, V36, P797, DOI 10.1007/s10096-016-2863-x; Mietchen MS, 2022, PLOS COMPUT BIOL, V18, DOI 10.1371/journal.pcbi.1010352; Mokrani D, 2023, ANN INTENSIVE CARE, V13, DOI 10.1186/s13613-023-01134-9; Montoya A, 2019, AM J INFECT CONTROL, V47, P693, DOI 10.1016/j.ajic.2018.10.017; MURADALI D, 1995, AM J ROENTGENOL, V164, P1521, DOI 10.2214/ajr.164.6.7754907; Nseir S, 2010, CLIN MICROBIOL INFEC, V16, P902, DOI 10.1111/j.1469-0691.2009.03027.x; Otter JA, 2013, J HOSP INFECT, V83, P1, DOI 10.1016/j.jhin.2012.10.002; Özen M, 2016, TURK J HEMATOL, V33, P41, DOI 10.4274/tjh.2014.0010; Panhotra BR, 2005, AM J INFECT CONTROL, V33, P398, DOI 10.1016/j.ajic.2004.12.009; Paramythiotou Elisabeth, 2016, World J Crit Care Med, V5, P111, DOI 10.5492/wjccm.v5.i2.111; Peters A, 2023, ANTIMICROB RESIST IN, V12, DOI 10.1186/s13756-022-01185-w; Peters A, 2022, AM J INFECT CONTROL, V50, P1302, DOI 10.1016/j.ajic.2022.02.029; Peters A, 2022, ANTIMICROB RESIST IN, V11, DOI 10.1186/s13756-022-01075-1; Pittet D, 1999, ARCH INTERN MED, V159, P821, DOI 10.1001/archinte.159.8.821; Rohr U, 2009, INT J HYG ENVIR HEAL, V212, P209, DOI 10.1016/j.ijheh.2008.05.003; Salgado CD, 2013, INFECT CONT HOSP EP, V34, P479, DOI 10.1086/670207; Saporito L, 2021, ANTIMICROB RESIST IN, V10, DOI 10.1186/s13756-021-00902-1; Sax H, 2007, J HOSP INFECT, V67, P9, DOI 10.1016/j.jhin.2007.06.004; Schaffzin Joshua K, 2022, Antimicrob Steward Healthc Epidemiol, V2, pe89, DOI 10.1017/ash.2022.241; Seidelman JL, 2022, CLIN INFECT DIS, V74, P1986, DOI 10.1093/cid/ciab747; Shokoohi H, 2015, OPEN ACCESS EMERG M, V7, P1, DOI 10.2147/OAEM.S50360; Siddharth V, 2021, J FAM MED PRIM CARE, V10, P3475, DOI 10.4103/jfmpc.jfmpc_1614_20; Spernovasilis N, 2023, J ANTIMICROB CHEMOTH, V78, P1000, DOI 10.1093/jac/dkad035; Spernovasilis N, 2023, ANTIBIOTICS-BASEL, V12, DOI 10.3390/antibiotics12010039; Spernovasilis N, 2021, TROP MED INFECT DIS, V6, DOI 10.3390/tropicalmed6010020; Spernovasilis N, 2020, J GLOB ANTIMICROB RE, V21, P296, DOI 10.1016/j.jgar.2019.11.004; Strich JR, 2017, INFECT DIS CLIN N AM, V31, P535, DOI 10.1016/j.idc.2017.05.010; Sui YS, 2012, RESP CARE, V57, P250, DOI 10.4187/respcare.01180; Tapouk FA, 2020, ANTIMICROB RESIST IN, V9, DOI 10.1186/s13756-020-00781-y; Teerawattanapong N, 2017, CLIN INFECT DIS, V64, pS51, DOI 10.1093/cid/cix112; Teng SO, 2009, J MICROBIOL IMMUNOL, V42, P86; Ture Zeynep, 2023, J Intensive Med, V3, P244, DOI 10.1016/j.jointm.2022.10.001; Ulger F, 2009, ANN CLIN MICROB ANTI, V8, DOI 10.1186/1476-0711-8-7; Wang Y, 2022, BMJ OPEN, V12, DOI 10.1136/bmjopen-2022-064566; Wang Y, 2022, AM J INFECT CONTROL, V50, P563, DOI 10.1016/j.ajic.2021.11.030; Weber DJ, 2010, AM J INFECT CONTROL, V38, pS25, DOI 10.1016/j.ajic.2010.04.196; Whittington AM, 2009, ANAESTHESIA, V64, P620, DOI 10.1111/j.1365-2044.2009.05892.x; Wilson APR, 2011, CRIT CARE MED, V39, P651, DOI 10.1097/CCM.0b013e318206bc66; Xie JF, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0102204, 10.1371/journal.pone.0089687]; Zay Ya K, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2022.53806	87	5	6	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2079-6382			ANTIBIOTICS-BASEL	Antibiotics-Basel	AUG	2023	12	8							1255	10.3390/antibiotics12081255	http://dx.doi.org/10.3390/antibiotics12081255			22	Infectious Diseases; Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Infectious Diseases; Pharmacology & Pharmacy	Q3FS6	37627675	gold, Green Published			2024-07-03	WOS:001056411500001
J	Ülkü, A				Ulku, Abdullah			Artificial intelligence-based large language models and integrity of exams and assignments in higher education: the case of tourism courses	TOURISM & MANAGEMENT STUDIES			English	Article						Large Language Models (LLM); Artificial Intelligence; ChatGPT; Tourism Education; Exams; Integrity	ONLINE	There is an increasing concern regarding the potential misuse of ChatGPT-4 in compromising the integrity of examinations and assignments. This study aims to examine the capabilities of ChatGPT-4 in critical thinking abilities, whether it poses a threat to examinations and assignments in higher education, and create a discussion agenda on this issue. ChatGPT-4 was asked to generate, answer, and criticize questions in tourism marketing, tourism management, tourism economics, tourist guidance, and gastronomy. The answers were evaluated according to universal critical thinking standards. The findings obtained from this study showed that ChatGPT-4 had commendable competence in several critical thinking standards and could produce human-like texts. However, there are certain domains that might be improved to comply more effectively with the expectations and norms of academia. Educators were recommended to use comprehensive approaches that combine technological and educational techniques to address the issue of cheating enabled by tools, such as ChatGPT-4, during assessment and exam processes.	[Ulku, Abdullah] Harran Univ, Sch Tourism & Hotel Management, Dept Tourism Guidance, Sanliurfa, Turkiye	Harran University	Ülkü, A (corresponding author), Harran Univ, Sch Tourism & Hotel Management, Dept Tourism Guidance, Sanliurfa, Turkiye.	abdullahulku@harran.edu.tr		Ulku, Abdullah/0000-0002-0937-2252				Ababneh KI, 2022, INT J MANAG EDUC-OXF, V20, DOI 10.1016/j.ijme.2022.100713; Adzima K, 2020, ELECTRON J E-LEARN, V18, P476, DOI 10.34190/JEL.18.6.002; Agasisti T, 2021, STUD HIGH EDUC, V46, P86, DOI 10.1080/03075079.2020.1859689; Alafnan M. A., 2023, Journal of Artificial Intelligence and Technology, V3, P60, DOI DOI 10.37965/JAIT.2023.0184; Ali K, 2023, Preprints, DOI [10.20944/preprints202302.0513.v1, 10.20944/preprints202302.0513.v1, DOI 10.20944/PREPRINTS202302.0513.V1]; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Barrientos A, 2021, 2021 IEEE ENG INT RE, P1, DOI [10.1109/EIRCON52903.2021.9613352, DOI 10.1109/EIRCON52903.2021.9613352]; Barrot JS, 2023, ASSESS WRIT, V57, DOI 10.1016/j.asw.2023.100745; Benvenuti M, 2023, COMPUT HUM BEHAV, V148, DOI 10.1016/j.chb.2023.107903; Bernabei M., 2023, Comput. Educ. Artific. Intellig, V5, DOI [10.1016/j.caeai.2023.100172, DOI 10.1016/J.CAEAI.2023.100172]; Carvalho L., 2022, Computers and Education: Artificial Intelligence, V3, DOI [10.1016/j.caeai.2022.100053, DOI 10.1016/J.CAEAI.2022.100053]; Chirumamilla A., 2019, Mitigation of cheating in online exams: Strengths and limitations, DOI [10.4018/978-1-5225-7724-9, DOI 10.4018/978-1-5225-7724-9]; Choi JH, 2022, J LEGAL EDUC, V71, P387; Coghlan S, 2020, Arxiv, DOI arXiv:2011.07647; Comas-Forgas Ruben, 2021, Heliyon, V7, pe08233, DOI 10.1016/j.heliyon.2021.e08233; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; David Andrei, 2022, Procedia Computer Science, P34, DOI 10.1016/j.procs.2022.11.145; Dendir S, 2020, COMPUT HUM BEHAV REP, V2, DOI 10.1016/j.chbr.2020.100033; Dias J, 2019, Journal of Engineering, V9, P58; Duhaim A. M., 2022, Webology, V19, P341, DOI [10.14704/WEB/V19I1/WEB19026, DOI 10.14704/WEB/V19I1/WEB19026]; Eke DO., 2023, J RESPONSIBLE TECHNO, V13, P100060, DOI 10.1016/j.jrt.2023.100060; Elbanna S., 2024, Management and Sustainability: An Arab Review, V3, P16, DOI DOI 10.1108/MSAR-03-2023-0016; Essel HB, 2022, INT J EDUC TECHNOL H, V19, DOI 10.1186/s41239-022-00362-6; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Geerling W., 2023, SSRN ELECT J, DOI [10.2139/ssrn.4356034, DOI 10.2139/SSRN.4356034]; Gerashchenko I. P., 2021, SHS WEB C, V121, DOI [10.1051/shsconf/202112103004, DOI 10.1051/SHSCONF/202112103004]; Gilson A, 2022, medRxiv, DOI [10.1101/2022.12.23.22283901, 10.1101/2022.12.23.22283901, DOI 10.1101/2022.12.23.22283901]; Goktas L. S., 2023, Journal of Tourism and Gastronomy Studies, V2, DOI [10.21325/jotags.2023.1224, DOI 10.21325/JOTAGS.2023.1224]; Hashim H., 2018, International Journal of Research in Counselling and Education, V1, P1, DOI DOI 10.24036/002ZA0002; Hill B., 2023, IN PRESS, DOI [10.2139/ssrn.4465833, DOI 10.2139/SSRN.4465833]; Holden OL, 2021, FRONT EDUC, V6, DOI 10.3389/feduc.2021.639814; Hwang A, 2018, J MANAG EDUC, V42, P557, DOI 10.1177/1052562918777550; Mellieon HI, 2021, AM J DISTANCE EDUC, V35, P170, DOI 10.1080/08923647.2020.1847626; Ilynykh S, 2021, 8 INT SCI PRACT C CU, DOI [10.2991/assehr.k.210322.126, DOI 10.2991/ASSEHR.K.210322.126]; Islam N, 2023, Arxiv, DOI arXiv:2306.01761; Jungherr A., 2023, PREPRINT, DOI [10.31235/osf.io/d84q6, DOI 10.31235/OSF.IO/D84Q6]; King D L., 2014, Issues in Information Systems, V15, P20, DOI [10.48009/1_iis_2014_20-27, DOI 10.48009/1_IIS_2014_20-27]; Klijn F, 2022, J ECON PSYCHOL, V93, DOI 10.1016/j.joep.2022.102555; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lanier MM, 2006, J CRIM JUSTICE EDUC, V17, P244, DOI 10.1080/10511250600866166; Latifah Rizka, 2022, International Journal of Information and Education Technology, P809, DOI 10.18178/ijiet.2022.12.8.1688; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Maslov I, 2021, INT J INF LEARN TECH, V38, P344, DOI 10.1108/IJILT-03-2021-0046; Misra DP, 2023, J ROY COLL PHYS EDIN, V53, P90, DOI 10.1177/14782715231181023; Montenegro-Rueda M, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131910509; Naidu K, 2023, ONLINE J COMMUN MEDI, V13, DOI 10.30935/ojcmt/13291; Newton PM., 2023, PREPRINT, DOI DOI 10.35542/OSF.IO/SYTU3; Nguyen X. -A., 2022, Asian Journal of Education and Social Studies, P13, DOI [10.9734/ajess/2022/v33i130782, DOI 10.9734/AJESS/2022/V33I130782]; Nieuwoudt JE, 2020, AUSTRALAS J EDUC TEC, V36, P15, DOI 10.14742/ajet.5137; Noorbehbahani F, 2022, EDUC INF TECHNOL, V27, P8413, DOI 10.1007/s10639-022-10927-7; Oravec J. A, 2023, Jl. of Interactive Learning Research, V34; Paul R., 2013, Journal of Developmental Ed Ucation, V37; Paul R., 2005, New Directions of Community Colleges, V2005, P27, DOI [https://doi.org/10.1002/cc.193, DOI 10.1002/CC.193]; Perera P., 2023, INT J RES INNOVATION, VVII, P306, DOI [10.47772/IJRISS.2023.7623, DOI 10.47772/IJRISS.2023.7623]; Pérez JQ, 2020, COMPUT APPL ENG EDUC, V28, P1549, DOI 10.1002/cae.22326; Petrolo D, 2023, INT J MANAG EDUC-OXF, V21, DOI 10.1016/j.ijme.2023.100812; Putra FW, 2023, J PUBLIC HEALTH-UK, V45, pe840, DOI 10.1093/pubmed/fdad120; Rahm L, 2023, J EDUC POLICY, V38, P46, DOI 10.1080/02680939.2021.1970233; Skavronskaya L, 2023, J TEACH TRAVEL TOUR, V23, P253, DOI 10.1080/15313220.2023.2196658; Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Swiecki Z., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100075; Tsai ML, 2023, EDUC CHEM ENG, V44, P71, DOI 10.1016/j.ece.2023.05.001; Ventayen R., 2023, SSRNFeb, DOI [10.2139/ssrn.4361548, DOI 10.2139/SSRN.4361548]; von Grünigen D, 2018, IEEE GLOB ENG EDUC C, P893, DOI 10.1109/EDUCON.2018.8363325; Wagner G, 2022, J INF TECHNOL-UK, V37, P209, DOI 10.1177/02683962211048201; Watson G.R., 2010, Cheating in the Digital age: Do students cheat more in online courses; Wiley, 2020, White paper: Academic integrity in the age of online learning; Xin Xie, 2020, Journal of Information Technology Case and Application Research, V22, P175, DOI 10.1080/15228053.2020.1824884; Yau C, 2023, University of Hong Kong temporarily bans students from using ChatGPT, other AI -based tools for coursework; Yorkovsky Y, 2022, TEACH TEACH EDUC, V120, DOI 10.1016/j.tate.2022.103883	73	1	1	29	33	ESCOLA SUPERIOR GESTAO, HOTELARIA & TURISMO UNIV ALGARVE	FARO	CAMPUS PENHA, FARO, 8005-139, PORTUGAL	2182-8458	2182-8466		TOUR MANAG STUD	Tour. Manag. Stud.		2023	19	4					21	34		10.18089/tms.2023.190402	http://dx.doi.org/10.18089/tms.2023.190402			14	Hospitality, Leisure, Sport & Tourism	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	Y9ZN8		Green Submitted, gold			2024-07-03	WOS:001108771500003
C	Dai, W; Lin, J; Jin, H; Li, T; Tsai, YS; Gasevic, D; Chen, GL		Chang, M; Chen, NS; Kuo, R; Rudolph, G; Sampson, DG; Tlili, A		Dai, Wei; Lin, Jionghao; Jin, Hua; Li, Tongguang; Tsai, Yi-Shan; Gasevic, Dragan; Chen, Guanliang			Can Large Language Models Provide Feedback to Students? A Case Study on ChatGPT	2023 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, ICALT	IEEE International Conference on Advanced Learning Technologies		English	Proceedings Paper	23rd IEEE International Conference on Advanced Learning Technologies (ICALT)	JUL 10-13, 2023	Orem, UT	IEEE, IEEE Comp Soc, IEEE Tech Community Learning Technol		Feedback Generation; Automated Feedback; Large Language Model; Feedback Effectiveness		Educational feedback has been widely acknowledged as an effective approach to improving student learning. However, scaling effective practices can be laborious and costly, which motivated researchers to work on automated feedback systems (AFS). Inspired by the recent advancements in the pre-trained language models (e.g., ChatGPT), we posit that such models might advance the existing knowledge of textual feedback generation in AFS because of their capability to offer natural-sounding and detailed responses. Therefore, we aimed to investigate the feasibility of using ChatGPT to provide students with feedback to help them learn better. Our results show that i) ChatGPT is capable of generating more detailed feedback that fluently and coherently summarizes students' performance than human instructors; ii) ChatGPT achieved high agreement with the instructor when assessing the topic of students' assignments; and iii) ChatGPT could provide feedback on the process of students completing the task, which might benefit students developing learning skills.	[Dai, Wei; Lin, Jionghao; Jin, Hua; Li, Tongguang; Tsai, Yi-Shan; Gasevic, Dragan; Chen, Guanliang] Monash Univ, Ctr Learning Analyt Monash, Melbourne, Vic, Australia	Monash University	Chen, GL (corresponding author), Monash Univ, Ctr Learning Analyt Monash, Melbourne, Vic, Australia.	wei.dai1@monash.edu; Jionghao.Lin1@monash.edu; flora.jin@monash.edu; tongguang.li@monash.edu; yi-shan.tsai@monash.edu; dragan.gasevic@monash.edu; guanliang.chen@monash.edu	Lin, Jionghao/JEO-6478-2023	Lin, Jionghao/0000-0003-3320-3907				Aydin O ., 2022, SSRN; Beckman K, 2021, STUD HIGH EDUC, V46, P821, DOI 10.1080/03075079.2019.1654450; Boud D, 2013, ASSESS EVAL HIGH EDU, V38, P698, DOI 10.1080/02602938.2012.691462; Cavalcanti AP, 2020, LAK20: THE TENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P428, DOI 10.1145/3375462.3375477; Evans C, 2013, REV EDUC RES, V83, P70, DOI 10.3102/0034654312474350; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Jia Q., 2022, P 15 INT C ED DAT MI, P5; Li CL, 2021, INT J ARTIF INTELL E, V31, P186, DOI 10.1007/s40593-020-00235-x; Lin Jionghao, 2023, LAK2023: LAK23: 13th International Learning Analytics and Knowledge Conference, P100, DOI 10.1145/3576050.3576064; Marwan Samiha, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P194, DOI 10.1145/3372782.3406264; Pardo A, 2018, J LEARN ANAL, V5, P235, DOI 10.18608/jla.2018.53.15; Ryan T, 2023, TEACH HIGH EDUC, V28, P1565, DOI 10.1080/13562517.2021.1913723; van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151; Varank I, 2014, EURASIA J MATH SCI T, V10, P395, DOI 10.12973/eurasia.2014.1062a	14	19	19	26	34	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2161-3761		979-8-3503-0054-3	IEEE INT CONF ADV LE			2023							323	325		10.1109/ICALT58122.2023.00100	http://dx.doi.org/10.1109/ICALT58122.2023.00100			3	Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW0CX		Green Submitted			2024-07-03	WOS:001094548800094
J	Ozmen, BB; Schwarz, GS				Ozmen, Berk B.; Schwarz, Graham S.			Future of artificial intelligence in plastic surgery: Toward the development of specialty-specific large language models	JOURNAL OF PLASTIC RECONSTRUCTIVE AND AESTHETIC SURGERY			English	Letter						Artificial intelligence; Large language models; Generative AI; Clinical decision support; Surgical education; Evidence-based medicine			[Ozmen, Berk B.; Schwarz, Graham S.] Cleveland Clin, Dept Plast Surg, Cleveland, OH USA; [Schwarz, Graham S.] 9500 Euclid Ave, Cleveland, OH 44195 USA	Cleveland Clinic Foundation	Schwarz, GS (corresponding author), 9500 Euclid Ave, Cleveland, OH 44195 USA.	schwarg@ccf.org	Ozmen, Berk B/KIG-1060-2024	Ozmen, Berk B/0000-0001-7803-1868				Buzzaccarini G, 2024, AESTHET PLAST SURG, V48, P1874, DOI 10.1007/s00266-023-03826-w; Farid Y, 2024, PRS-GLOB OPEN, V12, DOI 10.1097/GOX.0000000000005515; Mohapatra DP, 2023, INDIAN J PLAST SURG, V56, P413, DOI 10.1055/s-0043-1772704; Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012; Spoer DL, 2022, PRS-GLOB OPEN, V10, DOI 10.1097/GOX.0000000000004608	5	0	0	5	5	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	1748-6815	1878-0539		J PLAST RECONSTR AES	J. Plast. Reconstr. Aesthet. Surg.	JUN	2024	93						70	71		10.1016/j.bjps.2024.04.054	http://dx.doi.org/10.1016/j.bjps.2024.04.054			2	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	SK8S0	38670034	hybrid			2024-07-03	WOS:001234443400001
J	Huo, B; Calabrese, E; Sylla, P; Kumar, S; Ignacio, RC; Oviedo, R; Hassan, I; Slater, BJ; Kaiser, A; Walsh, DS; Vosburg, W				Huo, Bright; Calabrese, Elisa; Sylla, Patricia; Kumar, Sunjay; Ignacio, Romeo C.; Oviedo, Rodolfo; Hassan, Imran; Slater, Bethany J.; Kaiser, Andreas; Walsh, Danielle S.; Vosburg, Wesley			The performance of artificial intelligence large language model-linked chatbots in surgical decision-making for gastroesophageal reflux disease	SURGICAL ENDOSCOPY AND OTHER INTERVENTIONAL TECHNIQUES			English	Article						GERD; Surgery; ChatGPT; Generative artificial intelligence; Natural language processing; Large language models; Guidelines		BackgroundLarge language model (LLM)-linked chatbots may be an efficient source of clinical recommendations for healthcare providers and patients. This study evaluated the performance of LLM-linked chatbots in providing recommendations for the surgical management of gastroesophageal reflux disease (GERD).MethodsNine patient cases were created based on key questions addressed by the Society of American Gastrointestinal and Endoscopic Surgeons (SAGES) guidelines for the surgical treatment of GERD. ChatGPT-3.5, ChatGPT-4, Copilot, Google Bard, and Perplexity AI were queried on November 16th, 2023, for recommendations regarding the surgical management of GERD. Accurate chatbot performance was defined as the number of responses aligning with SAGES guideline recommendations. Outcomes were reported with counts and percentages.ResultsSurgeons were given accurate recommendations for the surgical management of GERD in an adult patient for 5/7 (71.4%) KQs by ChatGPT-4, 3/7 (42.9%) KQs by Copilot, 6/7 (85.7%) KQs by Google Bard, and 3/7 (42.9%) KQs by Perplexity according to the SAGES guidelines. Patients were given accurate recommendations for 3/5 (60.0%) KQs by ChatGPT-4, 2/5 (40.0%) KQs by Copilot, 4/5 (80.0%) KQs by Google Bard, and 1/5 (20.0%) KQs by Perplexity, respectively. In a pediatric patient, surgeons were given accurate recommendations for 2/3 (66.7%) KQs by ChatGPT-4, 3/3 (100.0%) KQs by Copilot, 3/3 (100.0%) KQs by Google Bard, and 2/3 (66.7%) KQs by Perplexity. Patients were given appropriate guidance for 2/2 (100.0%) KQs by ChatGPT-4, 2/2 (100.0%) KQs by Copilot, 1/2 (50.0%) KQs by Google Bard, and 1/2 (50.0%) KQs by Perplexity.ConclusionsGastrointestinal surgeons, gastroenterologists, and patients should recognize both the promise and pitfalls of LLM's when utilized for advice on surgical management of GERD. Additional training of LLM's using evidence-based health information is needed.	[Huo, Bright] McMaster Univ, Dept Surg, Div Gen Surg, Hamilton, ON, Canada; [Calabrese, Elisa] Univ Calif South Calif East Bay, Oakland, CA USA; [Sylla, Patricia] Icahn Sch Med Mt Sinai, Dept Surg, Div Colon & Rectal Surg, New York, NY USA; [Kumar, Sunjay] Thomas Jefferson Univ Hosp, Dept Gen Surg, Philadelphia, PA USA; [Ignacio, Romeo C.] Univ Calif San Diego, Dept Surg, Div Pediat Surg, Sch Med, San Diego, CA USA; [Oviedo, Rodolfo] Nacogdoches Ctr Metab & Weight Loss Surg, Nacogdoches, TX USA; [Oviedo, Rodolfo] Univ Houston, Tilman J Fertitta Family Coll Med, Houston, TX USA; [Oviedo, Rodolfo] Sam Houston State Univ, Coll Osteopath Med, Conroe, TX USA; [Hassan, Imran] Univ Iowa, Iowa City, IA USA; [Slater, Bethany J.] Univ Chicago, Dept Surg, Chicago, IL USA; [Kaiser, Andreas] City Hope Natl Med Ctr, Dept Surg, Div Colorectal Surg, Duarte, CA USA; [Walsh, Danielle S.] Univ Kentucky, Dept Surg, Lexington, KY USA; [Vosburg, Wesley] Harvard Med Sch, Mt Auburn Hosp, Dept Surg, Cambridge, MA 02115 USA	McMaster University; Icahn School of Medicine at Mount Sinai; Jefferson University; University of California System; University of California San Diego; University of Houston System; University of Houston; Texas State University System; Sam Houston State University; University of Iowa; University of Chicago; City of Hope; University of Kentucky; Harvard University; Mount Auburn Hospital	Vosburg, W (corresponding author), Harvard Med Sch, Mt Auburn Hosp, Dept Surg, Cambridge, MA 02115 USA.	wesvosburg@gmail.com						Amante DJ, 2015, J MED INTERNET RES, V17, DOI 10.2196/jmir.4126; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Beaulieu-Jones Brendin R, 2024, Surgery, V175, P936, DOI 10.1016/j.surg.2023.12.014; Beck F, 2014, J MED INTERNET RES, V16, P193, DOI 10.2196/jmir.2934; Bowman S. R., 2023, arXiv; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; El-Serag HB, 2014, GUT, V63, P871, DOI 10.1136/gutjnl-2012-304269; Emile SH, 2022, OBES SURG, V32, P2537, DOI 10.1007/s11695-022-06112-x; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Ge ZY, 2023, SCAND J GASTROENTERO, V58, P596, DOI 10.1080/00365521.2022.2163185; Henson JB, 2023, AM J GASTROENTEROL, V118, P2276, DOI 10.14309/ajg.0000000000002397; Hristidis V, 2023, J MED INTERNET RES, V25, DOI 10.2196/48966; Huo B, 2023, NAT MED, DOI 10.1038/s41591-023-02656-2; Kaminski M, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16234591; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee K, 2014, J MED INTERNET RES, V16, P190, DOI 10.2196/jmir.3706; Lee TC, 2023, GASTROENTEROLOGY, V165, P509, DOI 10.1053/j.gastro.2023.04.033; Mahajan A, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.22285; Marcinkevics R, 2024, MED IMAGE ANAL, V91, DOI 10.1016/j.media.2023.103042; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Mikalef P, 2017, HEALTH INFO LIBR J, V34, P58, DOI 10.1111/hir.12170; Moore M, 2016, WORLD J GASTRO SURG, V8, P77, DOI 10.4240/wjgs.v8.i1.77; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Sachs GF, 2023, SURGERY, V174, P934, DOI 10.1016/j.surg.2023.07.008; Sakirin T., 2023, MESOPOTAMIAN J COMPU, DOI [DOI 10.58496/MJCSC/2023/004, 10.58496/MJCSC/2023/004, DOI 10.58496/MJCSC/2023/006]; Slater BJ, 2021, SURG ENDOSC, V35, P4903, DOI 10.1007/s00464-021-08625-5; Smith DA, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0228786; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Walker HL, 2023, J MED INTERNET RES, V25, DOI 10.2196/47479; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009	31	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0930-2794	1432-2218		SURG ENDOSC	Surg. Endosc.	MAY	2024	38	5					2320	2330		10.1007/s00464-024-10807-w	http://dx.doi.org/10.1007/s00464-024-10807-w		APR 2024	11	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	PT5W2	38630178				2024-07-03	WOS:001204657100004
J	Zhang, JB; Zhao, L; Wang, W; Zhang, Q; Wang, XT; Xing, DF; Ren, NQ; Lee, DJ; Chen, C				Zhang, Jiabin; Zhao, Lei; Wang, Wei; Zhang, Quan; Wang, Xue-Ting; Xing, De-Feng; Ren, Nan-Qi; Lee, Duu-Jong; Chen, Chuan			Large language model for horizontal transfer of resistance gene: From resistance gene prevalence detection to plasmid conjugation rate evaluation	SCIENCE OF THE TOTAL ENVIRONMENT			English	Article						Deep learning; Large language model; BERT; ARGs prevalence prediction; Plasmid conjugation rate	SURFACE MATING SYSTEMS; SPECIFICATION	The burgeoning issue of plasmid-mediated resistance genes (ARGs) dissemination poses a significant threat to environmental integrity. However, the prediction of ARGs prevalence is overlooked, especially for emerging ARGs that are potentially evolving gene exchange hotspot. Here, we explored to classify plasmid or chromosome sequences and detect resistance gene prevalence by using DNABERT. Initially, the DNABERT fine-tuned in plasmid and chromosome sequences followed by multilayer perceptron (MLP) classifier could achieve 0.764 AUC (Area under curve) on external datasets across 23 genera, outperforming 0.02 AUC than traditional statisticbased model. Furthermore, Escherichia, Pseudomonas single genera based model were also be trained to explore its predict performance to ARGs prevalence detection. By integrating K-mer frequency attributes, our model could boost the performance to predict the prevalence of ARGs in an external dataset in Escherichia with 0.0281-0.0615 AUC and Pseudomonas with 0.0196-0.0928 AUC. Finally, we established a random forest model aimed at forecasting the relative conjugation transfer rate of plasmids with 0.7956 AUC, drawing on data from existing literature. It identifies the plasmid's repression status, cellular density, and temperature as the most important factors influencing transfer frequency. With these two models combined, they provide useful reference	[Zhang, Jiabin; Zhao, Lei; Wang, Wei; Zhang, Quan; Wang, Xue-Ting; Xing, De-Feng; Ren, Nan-Qi; Chen, Chuan] Harbin Inst Technol, Sch Environm, State Key Lab Urban Water Resource & Environm, Harbin 150090, Heilongjiang, Peoples R China; [Ren, Nan-Qi] Harbin Inst Technol, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China; [Lee, Duu-Jong] City Univ Hong Kong, Dept Mech Engn, Kowloon, Tat Chee Ave, Hong Kong, Peoples R China	Harbin Institute of Technology; Harbin Institute of Technology; City University of Hong Kong	Wang, W; Chen, C (corresponding author), Harbin Inst Technol, Sch Environm, State Key Lab Urban Water Resource & Environm, Harbin 150090, Heilongjiang, Peoples R China.	wvv9288@163.com; cchen@hit.edu.cn	Zhang, Quan/GLR-9965-2022	Zhang, Quan/0000-0002-6396-4953; Lee, Duu-Jong/0000-0002-8820-8097	National Key Research and Development Program of China [2023YFC3207203]; National Natural Science Foundation of China [52076063, 52300155]; Fundamental Research Funds for the Central Universities [HIT.OCEF.2021031]; State Key Laboratory of Urban Water Resource and Environment (Harbin Institute of Technology) [2023DX04]; Heilongjiang Provincial Natural Science Foundation of Excellent Young Scholars [YQ2023C031]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); State Key Laboratory of Urban Water Resource and Environment (Harbin Institute of Technology)(Harbin Institute of Technology); Heilongjiang Provincial Natural Science Foundation of Excellent Young Scholars	The research was supported by the National Key Research and Development Program of China (2023YFC3207203), National Natural Science Foundation of China (Grant No. 52076063, Grant No. 52300155), the Fundamental Research Funds for the Central Universities (Grant No. HIT.OCEF.2021031), State Key Laboratory of Urban Water Resource and Environment (Harbin Institute of Technology) (2023DX04), Heilongjiang Provincial Natural Science Foundation of Excellent Young Scholars (Grant No.YQ2023C031).	Aarestrup FM, 2020, SCIENCE, V367, P630, DOI 10.1126/science.aba3432; Arango-Argoty G, 2018, MICROBIOME, V6, DOI 10.1186/s40168-018-0401-z; Arredondo-Alonso S, 2018, MICROB GENOMICS, V4, DOI 10.1099/mgen.0.000224; Bepler T, 2021, CELL SYST, V12, P654, DOI 10.1016/j.cels.2021.05.017; BRADLEY DE, 1982, J GEN MICROBIOL, V128, P3019; BRADLEY DE, 1983, J GEN MICROBIOL, V129, P2545; BRADLEY DE, 1980, J BACTERIOL, V143, P1466, DOI 10.1128/JB.143.3.1466-1470.1980; Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020; Carattoli A, 2014, ANTIMICROB AGENTS CH, V58, P3895, DOI 10.1128/AAC.02412-14; Charoenkwan P, 2021, BIOINFORMATICS, V37, P2556, DOI 10.1093/bioinformatics/btab133; Chen ZL, 2011, CLIN INFECT DIS, V52, P692, DOI 10.1093/cid/ciq231; Davis JJ, 2020, NUCLEIC ACIDS RES, V48, pD606, DOI 10.1093/nar/gkz943; Davison J, 1999, PLASMID, V42, P73, DOI 10.1006/plas.1999.1421; del Campo I, 2012, PLASMID, V67, P174, DOI 10.1016/j.plasmid.2012.01.008; Dimitriu T, 2019, P ROY SOC B-BIOL SCI, V286, DOI 10.1098/rspb.2019.1110; Dimitriu T, 2016, PLOS BIOL, V14, DOI 10.1371/journal.pbio.1002478; Dong N., 2019, Antimicrob. Agents Chemother., V63; Haft RJF, 2009, ISME J, V3, P761, DOI 10.1038/ismej.2009.22; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Koraimann G, 2014, FRONT CELL INFECT MI, V4, DOI 10.3389/fcimb.2014.00054; Krawczyk PS, 2018, NUCLEIC ACIDS RES, V46, DOI 10.1093/nar/gkx1321; Li X., 2021, Chem. Eng. J., V406; Lilley AK, 2002, FEMS MICROBIOL ECOL, V42, P243, DOI 10.1111/j.1574-6941.2002.tb01014.x; Loman NJ, 2012, NAT BIOTECHNOL, V30, P434, DOI 10.1038/nbt.2198; Lu J, 2022, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.2c05537; Muratov EN, 2020, CHEM SOC REV, V49, P3525, DOI 10.1039/d0cs00098a; Olson RD, 2023, NUCLEIC ACIDS RES, V51, pD678, DOI 10.1093/nar/gkac1003; Öztürk H, 2020, DRUG DISCOV TODAY, V25, P689, DOI 10.1016/j.drudis.2020.01.020; Pellow D, 2020, PLOS COMPUT BIOL, V16, DOI 10.1371/journal.pcbi.1007781; Pruden A, 2006, ENVIRON SCI TECHNOL, V40, P7445, DOI 10.1021/es060413l; Rodríguez-Beltrán J, 2021, NAT REV MICROBIOL, V19, P347, DOI 10.1038/s41579-020-00497-1; Royer G, 2018, MICROB GENOMICS, V4, DOI 10.1099/mgen.0.000211; Sayers EW, 2020, NUCLEIC ACIDS RES, V48, pD84, DOI [10.1093/nar/gkz956, 10.1093/nar/gky989, 10.1093/nar/gkaa1023]; SIMONSEN L, 1990, J GEN MICROBIOL, V136, P2319, DOI 10.1099/00221287-136-11-2319; van der Graaf-van Bloois L, 2021, MICROB GENOMICS, V7, DOI 10.1099/mgen.0.000683; von Wintersdorff CJH, 2016, FRONT MICROBIOL, V7, DOI 10.3389/fmicb.2016.00173; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Wigh DS, 2022, WIRES COMPUT MOL SCI, V12, DOI 10.1002/wcms.1603; Wu J, 2023, ENVIRON SCI TECHNOL, V57, P6876, DOI 10.1021/acs.est.2c09491; Xu ZX, 2023, CHEM ENG J, V455, DOI 10.1016/j.cej.2022.140927; Yang Y, 2016, BIOINFORMATICS, V32, P2346, DOI 10.1093/bioinformatics/btw136; Zankari E, 2012, J ANTIMICROB CHEMOTH, V67, P2640, DOI 10.1093/jac/dks261; Zhang QR, 2022, CHEM ENG J, V450, DOI 10.1016/j.cej.2022.138301; Zhang XX, 2011, ENVIRON SCI TECHNOL, V45, P2598, DOI 10.1021/es103672x; Zhao S, 2021, NAT REV CANCER, V21, P413, DOI 10.1038/s41568-021-00357-x; Zhou FF, 2010, BIOINFORMATICS, V26, P2051, DOI 10.1093/bioinformatics/btq299; Zou XH, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0279280	47	0	0	12	12	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0048-9697	1879-1026		SCI TOTAL ENVIRON	Sci. Total Environ.	JUN 25	2024	931								172466	10.1016/j.scitotenv.2024.172466	http://dx.doi.org/10.1016/j.scitotenv.2024.172466			10	Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology	TC0P1	38626826				2024-07-03	WOS:001238944300001
J	Stroop, A; Stroop, T; Alsofy, SZ; Nakamura, M; Möllmann, F; Greiner, C; Stroop, R				Stroop, Anna; Stroop, Tabea; Alsofy, Samer Zawy; Nakamura, Makoto; Moellmann, Frank; Greiner, Christoph; Stroop, Ralf			Large language models: Are artificial intelligence-based chatbots a reliable source of patient information for spinal surgery?	EUROPEAN SPINE JOURNAL			English	Article; Early Access						ChatGPT; Large language model; Patient information; Spinal surgery	COMMUNICATION	PurposeLarge language models (LLM) have recently attracted attention because of their enormous performance. Based on artificial intelligence, LLM enable dialogic communication using quasi-natural language that approximates the quality of human communication. Thus, LLM could play an important role for patients to become informed. To evaluate the validity of an LLM in providing medical information, we used one of the first high-performance LLM (ChatGPT) on the clinical example of acute lumbar disc herniation (LDH).MethodsTwenty-four spinal surgeons experienced in LDH surgery directed questions to ChatGPT about the clinical picture of LDH from a patient's perspective. They evaluated the quality of ChatGPT responses and its potential use in medical communication. The responses were compared with the information content of a standard informed consent form.ResultsChatGPT provided good results in terms of comprehensibility, specificity, and satisfaction of responses and in terms of medical accuracy and completeness. ChatGPT was not able to provide all the information that was provided in the informed consent form, but did communicate information that was not listed there. In some cases, albeit minor, ChatGPT made medically inaccurate claims, such as listing kyphoplasty and vertebroplasty as surgical options for LDH.ConclusionWith the incipient use of artificial intelligence in communication, LLM will certainly become increasingly important to patients. Even if LLM are unlikely to play a role in clinical communication between physicians and patients at the moment, the opportunities-but also the risks-of this novel technology should be alertly monitored.	[Stroop, Anna; Stroop, Tabea; Alsofy, Samer Zawy; Stroop, Ralf] Witten Herdecke Univ, Fac Hlth, Dept Med, Alfred Herrhausen Str 45, D-58455 Witten, Germany; [Alsofy, Samer Zawy] Univ Munster, St Barbara Hosp, Acad Hosp Westfal Wilhelms, Dept Neurosurg, Hamm, Germany; [Nakamura, Makoto] Witten Herdecke Univ, Acad Hosp Koln Merheim, Dept Neurosurg, Cologne, Germany; [Moellmann, Frank; Greiner, Christoph] Niels Stensen Neuro Ctr, Dept Neuro & Spine Surg, Osnabruck, Germany; [Stroop, Ralf] Med Sch Hamburg, Hamburg, Germany	University of Munster; University of Hamburg; University Medical Center Hamburg-Eppendorf	Stroop, R (corresponding author), Witten Herdecke Univ, Fac Hlth, Dept Med, Alfred Herrhausen Str 45, D-58455 Witten, Germany.; Stroop, R (corresponding author), Med Sch Hamburg, Hamburg, Germany.	ralf.stroop@uni-wh.de		Stroop, Ralf/0000-0001-8795-6790				Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Aleph Alpha, 2023, Luminous Performance Benchmarks; Aljanabi M., 2023, Mesopotamian Journal of Cyber Security, V2023, P16, DOI [10.58496/MJCS/2023/003, DOI 10.58496/MJCS/2023/003]; Angelis L de, 2023, Chatgpt and the rise of large language models: The new ai-driven infodemic threat in public health; [Anonymous], 2023, Wikipedia; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barrier PA, 2003, MAYO CLIN PROC, V78, P211, DOI 10.4065/78.2.211; Becker G, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-94; BioMedLM, 2023, BioMedLM: a Domain-specific large language model for biomedical text; Chung JE, 2014, J HEALTH COMMUN, V19, P639, DOI 10.1080/10810730.2012.757396; Daraz L, 2019, J GEN INTERN MED, V34, P1884, DOI 10.1007/s11606-019-05109-0; Gruneberg C, 2023, Burgerliches Gesetzbuch; Iqbal JD, 2022, SWISS MED WKLY, V152, DOI [10.4414/SMW.2022.w30179, 10.4414/smw.2022.w30179]; McMullan M, 2006, PATIENT EDUC COUNS, V63, P24, DOI 10.1016/j.pec.2005.10.006; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; Naver Corp, 2023, NAVER Unveils HyperCLOVA, Korea's First Hyperscale 'Al to Empower Everyone'; Nerdy Nav, 2023, ChatGPT Statistics & User Numbers in July 2023; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Rothberg MB, 2012, J GEN INTERN MED, V27, P185, DOI 10.1007/s11606-011-1857-8; Shazhaev I., 2023, At. Indones. J., V28, P1; Wikipedia, 2023, GPT-4; Wu C., 2023, Visual ChatGPT: talking, drawing and editing with visual foundation models; Yang Xi, 2022, GATORTRON LARGE CLIN; Yang YC, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/5812499	25	3	3	10	14	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0940-6719	1432-0932		EUR SPINE J	Eur. Spine J.	2023 OCT 11	2023										10.1007/s00586-023-07975-z	http://dx.doi.org/10.1007/s00586-023-07975-z		OCT 2023	9	Clinical Neurology; Orthopedics	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Orthopedics	T9HA4	37821602				2024-07-03	WOS:001081008700001
J	Koga, S				Koga, Shunsuke			The Integration of Large Language Models Such as ChatGPT in Scientific Writing: Harnessing Potential and Addressing Pitfalls	KOREAN JOURNAL OF RADIOLOGY			English	Letter						ChatGPT; Large language model; Scientific writing; Authorship; Ethics			[Koga, Shunsuke] Hosp Univ Penn, Dept Pathol & Lab Med, Philadelphia, PA USA; [Koga, Shunsuke] Hosp Univ Penn, Dept Pathol & Lab Med, 3400 Spruce St, Philadelphia, PA 19104 USA	University of Pennsylvania; University of Pennsylvania	Koga, S (corresponding author), Hosp Univ Penn, Dept Pathol & Lab Med, 3400 Spruce St, Philadelphia, PA 19104 USA.	shunsuke.koga@pennmedicine.upenn.edu	Koga, Shunsuke/AFL-8279-2022	Koga, Shunsuke/0000-0001-8868-9700				Amano T, 2023, PLOS BIOL, V21, DOI 10.1371/journal.pbio.3002184; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; McGowan A, 2023, PSYCHIAT RES, V326, DOI 10.1016/j.psychres.2023.115334; Park SH, 2023, KOREAN J RADIOL, V24, P715, DOI 10.3348/kjr.2023.0643; Park SH, 2023, KOREAN J RADIOL, V24, P171, DOI 10.3348/kjr.2023.0112; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Woolston Chris, 2019, Nature, V570, P265, DOI 10.1038/d41586-019-01797-0	10	7	7	18	21	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	SEP	2023	24	9					924	925		10.3348/kjr.2023.0738	http://dx.doi.org/10.3348/kjr.2023.0738			2	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	GU7H4	37634646	Green Published			2024-07-03	WOS:001155246100001
J	Lim, DYZ; Ke, YH; Sng, GGR; Tung, JYM; Chai, JX; Abdullah, HR				Lim, Daniel Y. Z.; Ke, Yu He; Sng, Gerald G. R.; Tung, Joshua Y. M.; Chai, Jia X.; Abdullah, Hairil R.			Large language models in anaesthesiology: use of ChatGPT for American Society of Anesthesiologists physical status classification	BRITISH JOURNAL OF ANAESTHESIA			English	Article						American Society of Anesthesiologists physical status; artificial intelligence; ChatGPT; GPT; large language models; machine learning	ARTIFICIAL-INTELLIGENCE		[Lim, Daniel Y. Z.] Singapore Gen Hosp, Dept Gastroenterol & Hepatol, Singapore, Singapore; [Lim, Daniel Y. Z.; Abdullah, Hairil R.] Duke NUS Med Sch, Singapore, Singapore; [Ke, Yu He; Chai, Jia X.; Abdullah, Hairil R.] Singapore Gen Hosp, Dept Anaesthesiol & Perioperat Med, Singapore, Singapore; [Sng, Gerald G. R.] Singapore Gen Hosp, Dept Endocrinol, Singapore, Singapore; [Tung, Joshua Y. M.] Singapore Gen Hosp, Dept Urol, Singapore, Singapore	Singapore General Hospital; National University of Singapore; Singapore General Hospital; Singapore General Hospital; Singapore General Hospital	Abdullah, HR (corresponding author), Duke NUS Med Sch, Singapore, Singapore.; Abdullah, HR (corresponding author), Singapore Gen Hosp, Dept Anaesthesiol & Perioperat Med, Singapore, Singapore.	hairil.rizal.abdullah@singhealth.com.sg	Lim, Daniel Yan Zheng/AGY-3425-2022	Lim, Daniel Yan Zheng/0000-0002-9715-6970; Yuhe, Ke/0000-0001-7193-4749; abdullah, hairil rizal/0000-0003-1916-0832; Chai, Jia Xin/0009-0003-5650-7994; Tung, Joshua Yi Min/0000-0003-4991-9790				asahq.org, ASA Physical Status Classification System; Beegle C, 2022, PET CLIN, V17, P31, DOI 10.1016/j.cpet.2021.09.008; ChatGPT, about us; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Lorkowski J, 2021, ADV EXP MED BIOL, V1335, P1, DOI 10.1007/5584_2021_620; Mak PHK, 2002, ANAESTH INTENS CARE, V30, P633, DOI 10.1177/0310057X0203000516; OWENS WD, 1978, ANESTHESIOLOGY, V49, P239, DOI 10.1097/00000542-197810000-00003; Riley RH, 2014, ANAESTH INTENS CARE, V42, P614, DOI 10.1177/0310057X1404200511; Seibert K, 2021, J MED INTERNET RES, V23, DOI 10.2196/26522	9	0	1	10	30	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0007-0912	1471-6771		BRIT J ANAESTH	Br. J. Anaesth.	SEP	2023	131	3					E73	E75		10.1016/j.bja.2023.06.052	http://dx.doi.org/10.1016/j.bja.2023.06.052		AUG 2023	3	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	R5AC9	37474421				2024-07-03	WOS:001064466100001
J	Chen, S; Savova, GK; Bitterman, DS				Chen, Shan; Savova, Guergana K.; Bitterman, Danielle S.			Considerations for Prompting Large Language Models-Reply	JAMA ONCOLOGY			English	Letter									[Chen, Shan; Bitterman, Danielle S.] Harvard Med Sch, Artificial Intelligence Med AIM Program, Mass Gen Brigham, Boston, MA USA; [Chen, Shan; Savova, Guergana K.; Bitterman, Danielle S.] Boston Childrens Hosp, Computat Hlth Informat Program, Boston, MA USA	Harvard University; Harvard Medical School; Harvard University; Boston Children's Hospital	Bitterman, DS (corresponding author), Brigham & Womens Hosp, Dana Farber Canc Inst, Dept Radiat Oncol, 75 Francis St, Boston, MA 02115 USA.	dbitterman@bwh.harvard.edu						Chen S., PREPRINT, DOI DOI 10.48550/ARXIV.2304.02496; Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; Hou Y., PREPRINT, DOI DOI 10.48550/ARXIV.2209.11486; OpenAI. API, US; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zheng Y., PREPRINT, DOI DOI 10.48550/ARXIV.2305.03518	6	0	0	1	1	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2374-2437	2374-2445		JAMA ONCOL	JAMA Oncol.	APR	2024	10	4					526	530		10.1001/jamaoncol.2023.6966	http://dx.doi.org/10.1001/jamaoncol.2023.6966		APR 2024	5	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	OE4S9	38358777				2024-07-03	WOS:001163497600001
J	Al Zubaer, A; Granitzer, M; Mitrovic, J				Al Zubaer, Abdullah; Granitzer, Michael; Mitrovic, Jelena			Performance analysis of large language models in the domain of legal argument mining	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						natural language processing (NLP); argument mining; legal data; European Court of Human Rights (ECHR); sequence classification; GPT-4; ChatGPT; large language models		Generative pre-trained transformers (GPT) have recently demonstrated excellent performance in various natural language tasks. The development of ChatGPT and the recently released GPT-4 model has shown competence in solving complex and higher-order reasoning tasks without further training or fine-tuning. However, the applicability and strength of these models in classifying legal texts in the context of argument mining are yet to be realized and have not been tested thoroughly. In this study, we investigate the effectiveness of GPT-like models, specifically GPT-3.5 and GPT-4, for argument mining via prompting. We closely study the model's performance considering diverse prompt formulation and example selection in the prompt via semantic search using state-of-the-art embedding models from OpenAI and sentence transformers. We primarily concentrate on the argument component classification task on the legal corpus from the European Court of Human Rights. To address these models' inherent non-deterministic nature and make our result statistically sound, we conducted 5-fold cross-validation on the test set. Our experiments demonstrate, quite surprisingly, that relatively small domain-specific models outperform GPT 3.5 and GPT-4 in the F1-score for premise and conclusion classes, with 1.9% and 12% improvements, respectively. We hypothesize that the performance drop indirectly reflects the complexity of the structure in the dataset, which we verify through prompt and data analysis. Nevertheless, our results demonstrate a noteworthy variation in the performance of GPT models based on prompt formulation. We observe comparable performance between the two embedding models, with a slight improvement in the local model's ability for prompt selection. This suggests that local models are as semantically rich as the embeddings from the OpenAI model. Our results indicate that the structure of prompts significantly impacts the performance of GPT models and should be considered when designing them.	[Al Zubaer, Abdullah; Granitzer, Michael; Mitrovic, Jelena] Univ Passau, Fac Comp Sci & Math, Chair Data Sci, Passau, Germany; [Mitrovic, Jelena] Inst Artificial Intelligence Res & Dev Serbia, Grp Human Comp Interact, Novi Sad, Serbia	University of Passau	Al Zubaer, A (corresponding author), Univ Passau, Fac Comp Sci & Math, Chair Data Sci, Passau, Germany.	abdullahal.zubaer@uni-passau.de		Mitrovic, Jelena/0000-0003-3220-8749	German Federal Ministry of Education and Research (BMBF) [16DHBKI059]; CAROLL [01-S20049]	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF)); CAROLL	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. The report has been funded by the German Federal Ministry of Education and Research (BMBF) under the projects DeepWrite (Grant. No. 16DHBKI059) and CAROLL (Grant. No. 01-S20049). The authors are responsible for the content of this publication.	Aljabri M, 2023, SOC NETW ANAL MIN, V13, DOI 10.1007/s13278-022-01020-5; [Anonymous], 2013, P 2013 C EMPIRICAL M; [Anonymous], 2007, ICAIL '07: proceedings of the 11th international conference on artificial intelligence and law, DOI DOI 10.1145/1276318.1276362; [Anonymous], 2011, P 49 ANN M ASS COMPU; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Bentahar J, 2010, ARTIF INTELL REV, V33, P211, DOI 10.1007/s10462-010-9154-1; Blair-Stanek A., 2023, Nineteenth International Conference on Artificial Intelligence and Law, P22, DOI [10.1145/3594536.3595163, DOI 10.1145/3594536.3595163]; Bosma M., 2023, Chain-of-thought prompting elicits reasoning in large language models; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Chalkidis I, 2020, M ASS FOR COMPUTATIO; Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4317; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen M., 2021, arXiv; Choi JH., 2023, Chatgpt goes to law school, DOI DOI 10.2139/SSRN.4335905; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano PF, 2017, ADV NEUR IN, V30; Dai D., 2023, Why can gpt learn in-context? language models implicitly perform gradient descent as meta-optimizers; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong Q., 2023, A survey on in-context learning; Filtz E, 2020, FRONT ARTIF INTEL AP, V334, P33, DOI 10.3233/FAIA200847; Gasparetto A, 2022, INFORMATION, V13, DOI 10.3390/info13020083; Grundler Giulia, 2022, P 9 WORKSH ARG MIN, P143; Habernal I, 2023, ARTIF INTELL LAW, DOI 10.1007/s10506-023-09361-y; Han C, 2023, Arxiv, DOI arXiv:2305.12766; Holzenberger N., 2020, A dataset for statutory reasoning in tax law entailment and question answering; Ji SL, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3597493; Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katz D. M., 2023, GPT-4 Passes the Bar Exam; Katz DM, 2023, Arxiv, DOI [arXiv:2302.12039, 10.2139/ssrn.4336224]; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lai G., 2017, RACE LARGE SCALE REA; Lawrence J, 2019, COMPUT LINGUIST, V45, P765, DOI [10.1162/COLI_a_00364, 10.1162/COLIa00364]; Lippi M, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2850417; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Y., 2023, MetaRadiology, V1; Liu Y., 2019, CoRR abs/1907.11692; Liu ZC, 2021, DRUG DISCOV TODAY, V26, P2593, DOI 10.1016/j.drudis.2021.06.009; Lo CK, 2023, EDUC SCI, V13, DOI 10.3390/educsci13040410; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Medvedeva M, 2020, ARTIF INTELL LAW, V28, P237, DOI 10.1007/s10506-019-09255-y; Mochales R, 2011, ARTIF INTELL LAW, V19, P1, DOI 10.1007/s10506-010-9104-x; Mochales R, 2008, FRONT ARTIF INTEL AP, V189, P11, DOI 10.3233/978-1-58603-952-3-11; Nay J. J., 2023, arXiv, DOI [10.2139/ssrn.4476325, DOI 10.2139/SSRN.4476325]; Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565; Open AI., 2023, Gpt-4 Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Palau RM, 2009, P 12 INT C ART INT L, P98; Parikh A. P., 2020, arXiv, DOI [10.18653/v1/2020.emnlp-main.89, DOI 10.18653/V1/2020.EMNLP-MAIN.89]; Pojoni M.-L., 2023, Argument-Mining From Podcasts Using Chatgpt; Poudyal P, 2020, P 7 WORKSHOP ARGUMEN, P67; Press O, 2023, Arxiv, DOI arXiv:2210.03350; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Savelka J, 2023, Arxiv, DOI arXiv:2306.13906; Shum K, 2024, Arxiv, DOI arXiv:2302.12822; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Steinberger Ralf., 2006, Fifth International Conference on Language Resources and Evaluation; Sun ZX, 2023, Arxiv, DOI arXiv:2303.09136; Taylor R., 2022, ARXIV; Touvron H., 2023, arXiv; Touvron H., 2023, Llama: Open and efficient foundation language models; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; Van Rossum G., 2009, PYTHON 3 REFERENCE M; Vaswani A, 2017, ADV NEUR IN, V30; Von Oswald J, 2023, INT C MACHINE LEARNI, P35151, DOI DOI 10.48550/ARXIV.2212.07677; Walton D, 2009, ARGUMENTATION IN ARTIFICIAL INTELLIGENCE, P1, DOI 10.1007/978-0-387-98197-0_1; Wambsganss T., 2020, Unlocking Transfer Learning in Argumentation Mining: A Domain-Independent Modelling Approach; Wang A., 2018, arXiv, DOI [10.18653/v1/W18-5446, DOI 10.18653/V1/W18-5446]; Wang Wenhui, 2020, Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers; Weng L., 2023, Prompt engineering; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Xu H., 2022, Legal Knowledge and Information Systems- JURIX 2022: The Thirty-fifth Annual Conference, P261; Ye S, 2023, Arxiv, DOI arXiv:2302.14691; Yu FY, 2022, Arxiv, DOI arXiv:2212.01326; Yu T, 2020, ARXIV; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhang G., 2023, 19 INT C ARTIFICIAL; Zhang G., Journal of Data Mining Digital Humanities, VNLP4DH, P2022, DOI DOI 10.46298/JDMDH.9147; Zhang G., 2022, International Conference on Applications of Natural Language to Information Systems, P240; Zhang Gechuan., 2021, P WORKSHOP NATURAL L, P121; Zhang YF, 2023, Arxiv, DOI arXiv:2305.19420; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng Lucia, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P159, DOI 10.1145/3462757.3466088	92	0	0	9	16	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	NOV 17	2023	6								1278796	10.3389/frai.2023.1278796	http://dx.doi.org/10.3389/frai.2023.1278796			18	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	Z3QB2	38045763	Green Published, gold			2024-07-03	WOS:001111240900001
J	Rousseau, R; Yang, LY; Bollen, J; Shen, ZS				Rousseau, Ronald; Yang, Liying; Bollen, Johan; Shen, Zhesi			Large language models and scientific publishing	JOURNAL OF DATA AND INFORMATION SCIENCE			English	Editorial Material													Shen, Zhesi/A-9307-2015	Shen, Zhesi/0000-0001-8414-7912				[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Grimaldi G, 2023, ACS ENERGY LETT, V8, P878, DOI 10.1021/acsenergylett.2c02828; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	4	0	0	0	7	SCIENDO	WARSAW	BOGUMILA ZUGA 32A, WARSAW, MAZOVIA, POLAND	2096-157X	2543-683X		J DATA INFO SCI	J. Data Info. Sci.	FEB 1	2023	8	1					1	1		10.2478/jdis-2023-0007	http://dx.doi.org/10.2478/jdis-2023-0007			1	Information Science & Library Science	Emerging Sources Citation Index (ESCI)	Information Science & Library Science	9O5VS		gold			2024-07-03	WOS:000943670000001
J	Selles, M; Wellenberg, RHH; Slotman, DJ; Nijholt, IM; van Osch, JAC; van Dijke, KF; Maas, M; Boomsma, MF				Selles, Mark; Wellenberg, Ruud H. H.; Slotman, Derk J.; Nijholt, Ingrid M.; van Osch, Jochen A. C.; van Dijke, Kees F.; Maas, Mario; Boomsma, Martijn F.			Image quality and metal artifact reduction in total hip arthroplasty CT: deep learning-based algorithm <i>versus</i> virtual monoenergetic imaging and orthopedic metal artifact reduction	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Arthroplasty (replacement, hip); Artificial intelligence; Artifacts; Deep learning; Tomography (x-ray computed)	NETWORK	Background To compare image quality, metal artifacts, and diagnostic confidence of conventional computed tomography (CT) images of unilateral total hip arthroplasty patients (THA) with deep learning-based metal artifact reduction (DL-MAR) to conventional CT and 130-keV monoenergetic images with and without orthopedic metal artifact reduction (O-MAR). Methods Conventional CT and 130-keV monoenergetic images with and without O-MAR and DL-MAR images of 28 unilateral THA patients were reconstructed. Image quality, metal artifacts, and diagnostic confidence in bone, pelvic organs, and soft tissue adjacent to the prosthesis were jointly scored by two experienced musculoskeletal radiologists. Contrast-to-noise ratios (CNR) between bladder and fat and muscle and fat were measured. Wilcoxon signed-rank tests with Holm-Bonferroni correction were used. Results Significantly higher image quality, higher diagnostic confidence, and less severe metal artifacts were observed on DL-MAR and images with O-MAR compared to images without O-MAR (p < 0.001 for all comparisons). Higher image quality, higher diagnostic confidence for bone and soft tissue adjacent to the prosthesis, and less severe metal artifacts were observed on DL-MAR when compared to conventional images and 130-keV monoenergetic images with O-MAR (p <= 0.014). CNRs were higher for DL-MAR and images with O-MAR compared to images without O-MAR (p < 0.001). Higher CNRs were observed on DL-MAR images compared to conventional images and 130-keV monoenergetic images with O-MAR (p <= 0.010). Conclusions DL-MAR showed higher image quality, diagnostic confidence, and superior metal artifact reduction compared to conventional CT images and 130-keV monoenergetic images with and without O-MAR in unilateral THA patients. Relevance statement DL-MAR resulted into improved image quality, stronger reduction of metal artifacts, and improved diagnostic confidence compared to conventional and virtual monoenergetic images with and without metal artifact reduction, bringing DL-based metal artifact reduction closer to clinical application.	[Selles, Mark; Slotman, Derk J.; Nijholt, Ingrid M.; Boomsma, Martijn F.] Isala, Dept Radiol, NL-8025 AB Zwolle, Netherlands; [Selles, Mark; Wellenberg, Ruud H. H.; Maas, Mario] Univ Amsterdam, Dept Radiol & Nucl Med, Med Ctr, NL-1105 AZ Amsterdam, Netherlands; [Selles, Mark; Wellenberg, Ruud H. H.; Maas, Mario] Amsterdam Movement Sci, NL-1081 BT Amsterdam, Netherlands; [van Osch, Jochen A. C.] Isala, Dept Med Phys, NL-8025 AB Zwolle, Netherlands; [van Dijke, Kees F.] Noordwest Ziekenhuisgrp, Dept Radiol & Nucl Med, NL-1815 JD Alkmaar, Netherlands	University of Amsterdam; Vrije Universiteit Amsterdam; Vrije Universiteit Amsterdam; Medical Center Of Alkmaar	Selles, M (corresponding author), Isala, Dept Radiol, NL-8025 AB Zwolle, Netherlands.; Selles, M (corresponding author), Univ Amsterdam, Dept Radiol & Nucl Med, Med Ctr, NL-1105 AZ Amsterdam, Netherlands.; Selles, M (corresponding author), Amsterdam Movement Sci, NL-1081 BT Amsterdam, Netherlands.	m.selles@isala.nl		Selles, Mark/0000-0002-1511-1438	Philips	Philips	No large language models were used to create this article.	Andersson KM, 2015, BRIT J RADIOL, V88, DOI 10.1259/bjr.20140473; Andersson KM, 2016, BRIT J RADIOL, V89, DOI 10.1259/bjr.20150993; Arabi H, 2021, EUR RADIOL, V31, P6384, DOI 10.1007/s00330-021-07709-z; Bauer DF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12010404; Bolstad K, 2018, ACTA RADIOL, V59, P1110, DOI 10.1177/0284185117751278; Boomsma MF, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2006-y; Busi M, 2022, J IMAGING, V8, DOI 10.3390/jimaging8030077; Crawford RE, 1997, ANN RHEUM DIS, V56, P455, DOI 10.1136/ard.56.8.455; Ghani MU, 2020, IEEE T COMPUT IMAG, V6, P181, DOI 10.1109/TCI.2019.2937221; Gjesteby L, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab4e3e; Gjesteby L, 2016, IEEE ACCESS, V4, P5826, DOI 10.1109/ACCESS.2016.2608621; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Laukamp KR, 2018, EUR RADIOL, V28, P4524, DOI 10.1007/s00330-018-5414-2; Liao HF, 2020, IEEE T MED IMAGING, V39, P634, DOI 10.1109/TMI.2019.2933425; Lin WA, 2019, PROC CVPR IEEE, P10504, DOI 10.1109/CVPR.2019.01076; Montagnon E, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-019-0832-5; Neuhaus V, 2019, EUR J RADIOL, V111, P14, DOI 10.1016/j.ejrad.2018.12.008; Pabinger C, 2018, HIP INT, V28, P498, DOI 10.1177/1120700018757940; Park J, 2019, ABDOM RADIOL, V44, P756, DOI 10.1007/s00261-018-1748-0; Pessis E, 2015, SEMIN MUSCULOSKEL R, V19, P446, DOI 10.1055/s-0035-1569256; Rau A., 2023, Eur Radiol, V1, P1, DOI [10.1007/S00330-023-09511-5/TABLES/4, DOI 10.1007/S00330-023-09511-5/TABLES/4]; Schindelin J, 2012, NAT METHODS, V9, P676, DOI [10.1038/nmeth.2019, 10.1038/NMETH.2019]; Selles M, 2022, EUR J RADIOL, V148, DOI 10.1016/j.ejrad.2022.110159; Selles M, 2023, EUR J RADIOL, V163, DOI 10.1016/j.ejrad.2023.110844; Selles M, 2021, INSIGHTS IMAGING, V12, DOI 10.1186/s13244-021-01111-5; Wang T, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac1156; Wellenberg RHH, 2018, EUR J RADIOL, V107, P60, DOI 10.1016/j.ejrad.2018.08.010; Wellenberg RHH, 2017, EUR J RADIOL, V88, P61, DOI 10.1016/j.ejrad.2017.01.002; Wellenberg RHH, 2016, J COMPUT ASSIST TOMO, V40, P971, DOI 10.1097/RCT.0000000000000449; Yoo Hye Jin, 2022, J Korean Soc Radiol, V83, P1286, DOI 10.3348/jksr.2021.0130; Yu LQ, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac195c; Zhang YB, 2018, IEEE T MED IMAGING, V37, P1370, DOI 10.1109/TMI.2018.2823083; Zhou B, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102289	33	0	0	3	3	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	MAR 14	2024	8	1							31	10.1186/s41747-024-00427-3	http://dx.doi.org/10.1186/s41747-024-00427-3			11	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	KX2F2	38480603	gold, Green Published			2024-07-03	WOS:001183189600001
J	Liu, SR; McCoy, AB; Wright, AP; Nelson, SD; Huang, SS; Ahmad, HB; Carro, SE; Franklin, J; Brogan, J; Wright, A				Liu, Siru; McCoy, Allison B.; Wright, Aileen P.; Nelson, Scott D.; Huang, Sean S.; Ahmad, Hasan B.; Carro, Sabrina E.; Franklin, Jacob; Brogan, James; Wright, Adam			Why do users override alerts? Utilizing large language model to summarize comments and optimize clinical decision support	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						clinical decision support; alert fatigue; health personnel; large language model	ORDER	Objectives To evaluate the capability of using generative artificial intelligence (AI) in summarizing alert comments and to determine if the AI-generated summary could be used to improve clinical decision support (CDS) alerts.Materials and Methods We extracted user comments to alerts generated from September 1, 2022 to September 1, 2023 at Vanderbilt University Medical Center. For a subset of 8 alerts, comment summaries were generated independently by 2 physicians and then separately by GPT-4. We surveyed 5 CDS experts to rate the human-generated and AI-generated summaries on a scale from 1 (strongly disagree) to 5 (strongly agree) for the 4 metrics: clarity, completeness, accuracy, and usefulness.Results Five CDS experts participated in the survey. A total of 16 human-generated summaries and 8 AI-generated summaries were assessed. Among the top 8 rated summaries, five were generated by GPT-4. AI-generated summaries demonstrated high levels of clarity, accuracy, and usefulness, similar to the human-generated summaries. Moreover, AI-generated summaries exhibited significantly higher completeness and usefulness compared to the human-generated summaries (AI: 3.4 +/- 1.2, human: 2.7 +/- 1.2, P = .001).Conclusion End-user comments provide clinicians' immediate feedback to CDS alerts and can serve as a direct and valuable data resource for improving CDS delivery. Traditionally, these comments may not be considered in the CDS review process due to their unstructured nature, large volume, and the presence of redundant or irrelevant content. Our study demonstrates that GPT-4 is capable of distilling these comments into summaries characterized by high clarity, accuracy, and completeness. AI-generated summaries are equivalent and potentially better than human-generated summaries. These AI-generated summaries could provide CDS experts with a novel means of reviewing user comments to rapidly optimize CDS alerts both online and offline.	[Liu, Siru; McCoy, Allison B.; Wright, Aileen P.; Nelson, Scott D.; Huang, Sean S.; Wright, Adam] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA; [Liu, Siru] Vanderbilt Univ, Dept Comp Sci, Nashville, TN 37212 USA; [Wright, Aileen P.; Huang, Sean S.; Franklin, Jacob; Brogan, James; Wright, Adam] Vanderbilt Univ, Med Ctr, Dept Med, Nashville, TN 37212 USA; [Ahmad, Hasan B.] Univ Washington, Dept Biomed Informat & Med Educ, Seattle, WA 98195 USA; [Carro, Sabrina E.] Vanderbilt Univ, Med Ctr, Dept Pediat, Nashville, TN 37212 USA	Vanderbilt University; Vanderbilt University; Vanderbilt University; University of Washington; University of Washington Seattle; Vanderbilt University	Liu, SR (corresponding author), Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA.	siru.liu@vumc.org	Nelson, Scott/I-7607-2019; Liu, Siru/AAM-8737-2021; McCoy, Allison/I-1951-2013	Nelson, Scott/0000-0002-1941-1817; Liu, Siru/0000-0002-5003-5354; McCoy, Allison/0000-0003-2292-9147	NIH [R00LM014097-02, R01AG062499-01, R01LM013995-01]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by NIH grants: R00LM014097-02, R01AG062499-01, and R01LM013995-01.	Aaron S, 2019, J AM MED INFORM ASSN, V26, P37, DOI 10.1093/jamia/ocy139; Almazyad M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38249; Craig KJT, 2020, CARDIOVASC DIGIT HLT, V1, P139, DOI 10.1016/j.cvdhj.2020.11.001; Douthit Brian J, 2023, Yearb Med Inform, V32, P169, DOI 10.1055/s-0043-1768722; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Liu SR, 2022, J AM MED INFORM ASSN, V29, P891, DOI 10.1093/jamia/ocab292; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Lu H., arXiv; Ma C., ARXIV; McCoy AB, 2022, J AM MED INFORM ASSN, V29, P1050, DOI 10.1093/jamia/ocac027; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Osheroff J., 2012, IMPROVING OUTCOMES C, DOI [10.4324/9781498757461, DOI 10.4324/9781498757461]; Parasrampuria, 2019, ONC Data Br, V46, P1; Phansalkar S, 2013, J AM MED INFORM ASSN, V20, P489, DOI 10.1136/amiajnl-2012-001089; Seidling HM, 2014, INT J MED INFORM, V83, P285, DOI 10.1016/j.ijmedinf.2013.12.006; Van der Sijs H, 2006, J AM MED INFORM ASSN, V13, P138, DOI 10.1197/jamia.M1809; Wright A, 2018, J GEN INTERN MED, V33, P1868, DOI 10.1007/s11606-018-4415-9; Wright A, 2018, J AM MED INFORM ASSN, V25, P496, DOI 10.1093/jamia/ocx106; Wright A, 2010, APPL CLIN INFORM, V1, P331, DOI 10.4338/ACI-2010-05-RA-0031; Wright A, 2011, J AM MED INFORM ASSN, V18, P232, DOI 10.1136/amiajnl-2011-000113; Zhang H., SUMMIT ITERATIVE TEX	23	3	3	15	15	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1388	1396		10.1093/jamia/ocae041	http://dx.doi.org/10.1093/jamia/ocae041		MAR 2024	9	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38452289	hybrid			2024-07-03	WOS:001180142500001
J	Nielsen, JPS; Gronhoj, C; Skov, L; Gyldenlove, M				Nielsen, Jacob P. S.; Gronhoj, Christian; Skov, Lone; Gyldenlove, Mette			Usefulness of the large language model ChatGPT (GPT-4) as a diagnostic tool and information source in dermatology	JEADV CLINICAL PRACTICE			English	Article; Early Access						AI; artificial intelligence; Chatbot; ChatGPT; clinical dermatology; GPT-4; information source; Large Language Model; LLM; skin disease		BackgroundThe field of artificial intelligence is rapidly evolving. As an easily accessible platform with vast user engagement, the Chat Generative Pre-Trained Transformer (ChatGPT) holds great promise in medicine, with the latest version, GPT-4, capable of analyzing clinical images.ObjectivesTo evaluate ChatGPT as a diagnostic tool and information source in clinical dermatology.MethodsA total of 15 clinical images were selected from the Danish web atlas, Danderm, depicting various common and rare skin conditions. The images were uploaded to ChatGPT version GPT-4, which was prompted with 'Please provide a description, a potential diagnosis, and treatment options for the following dermatological condition'. The generated responses were assessed by senior registrars in dermatology and consultant dermatologists in terms of accuracy, relevance, and depth (scale 1-5), and in addition, the image quality was rated (scale 0-10). Demographic and professional information about the respondents was registered.ResultsA total of 23 physicians participated in the study. The majority of the respondents were consultant dermatologists (83%), and 48% had more than 10 years of training. The overall image quality had a median rating of 10 out of 10 [interquartile range (IQR): 9-10]. The overall median rating of the ChatGPT generated responses was 2 (IQR: 1-4), while overall median ratings in terms of relevance, accuracy, and depth were 2 (IQR: 1-4), 3 (IQR: 2-4) and 2 (IQR: 1-3), respectively.ConclusionsDespite the advancements in ChatGPT, including newly added image processing capabilities, the chatbot demonstrated significant limitations in providing reliable and clinically useful responses to illustrative images of various dermatological conditions.	[Nielsen, Jacob P. S.; Gronhoj, Christian] Copenhagen Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Copenhagen, Denmark; [Skov, Lone; Gyldenlove, Mette] Copenhagen Univ Hosp Herlev & Gentofte, Dept Dermatol & Allergy, Copenhagen, Denmark; [Skov, Lone; Gyldenlove, Mette] Univ Copenhagen, Fac Hlth & Med Sci, Dept Clin Med, Copenhagen, Denmark; [Nielsen, Jacob P. S.] Copenhagen Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Rigshosp, Blegdamsvej 9, DK-2100 Copenhagen, Denmark	University of Copenhagen; University of Copenhagen; University of Copenhagen; Rigshospitalet	Nielsen, JPS (corresponding author), Copenhagen Univ Hosp, Dept Otorhinolaryngol Head & Neck Surg & Audiol, Rigshosp, Blegdamsvej 9, DK-2100 Copenhagen, Denmark.	jacob.pohl.stangerup.nielsen.03@regionh.dk		Skov, Lone/0000-0002-4784-9680	None	None	The study group would like to thank all participating respondents and Professor Emeritus Niels K. Veien kindly permitting the use of images from Danderm.	Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barrington Nikki M, 2023, Med Sci (Basel), V11, DOI 10.3390/medsci11030061; Duarte F., 2023, Exploring Topics; Ferrero NA, 2013, J AM ACAD DERMATOL, V68, P515, DOI 10.1016/j.jaad.2012.10.045; Gantenbein L, 2020, DERMATOL THER, V33, DOI 10.1111/dth.14098; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Lent HC., 2024, JEADV Clin Pract, V3, P258; Mirza FN, 2024, J INVEST DERMATOL, V144, P398, DOI 10.1016/j.jid.2023.06.208; Sengupta D, 2023, INDIAN DERMATOL ONL, V14, P782, DOI 10.4103/idoj.idoj_462_23; Shifai N, 2024, J AM ACAD DERMATOL, V90, P1057, DOI 10.1016/j.jaad.2023.12.062; Veien NK., An atlas of clinical dermatology	11	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	2768-6566			JEADV CLIN PRACT	JEADV Clin. Pract.	2024 JUN 3	2024										10.1002/jvc2.459	http://dx.doi.org/10.1002/jvc2.459		JUN 2024	6	Dermatology	Emerging Sources Citation Index (ESCI)	Dermatology	SW9H6		gold			2024-07-03	WOS:001237597700001
J	O'Leary, DE				O'Leary, Daniel E.			Large Language Models and Applications: The Rebirth of Enterprise Knowledge Management and the Rise of Prompt Libraries	IEEE INTELLIGENT SYSTEMS			English	Article						Knowledge management; Cognition; Intelligent systems; Large language models; Enterprise resource planning; Libraries		This article investigates how large language systems and the apps developed for them provide a platform for enterprise knowledge management. For those resulting systems to provide consistent and accurate responses for knowledge management, enterprises are using different approaches in their prompts, such as few-shot learning, specification of purpose, and chain-of-thought reasoning. As better and more successful prompts are being built, they are being captured and prompt libraries are being created.	[O'Leary, Daniel E.] Univ Southern Calif, Marshall Sch Business, Los Angeles, CA 90089 USA	University of Southern California	O'Leary, DE (corresponding author), Univ Southern Calif, Marshall Sch Business, Los Angeles, CA 90089 USA.	oleary@usc.edu						Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Davenport T., 2015, Wall Street J.Jan.; Li CS, 2023, Arxiv, DOI arXiv:2312.04474; Lu P, 2022, Arxiv, DOI arXiv:2209.14610; O'Leary DE, 2024, IEEE INTELL SYST, V39, P60, DOI 10.1109/MIS.2023.3345591; O'Leary DE, 2023, AI MAG, V44, P282, DOI 10.1002/aaai.12118; O'Leary DE, 2016, J DECIS SYST, V25, P512, DOI 10.1080/12460125.2016.1193930; O'Leary DE, 1998, COMPUTER, V31, P54, DOI 10.1109/2.660190; Schick T., 2023, arXiv; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903	10	0	0	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672	1941-1294		IEEE INTELL SYST	IEEE Intell. Syst.	MAR-APR	2024	39	2					72	75		10.1109/MIS.2024.3366648	http://dx.doi.org/10.1109/MIS.2024.3366648			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PL2C0					2024-07-03	WOS:001214157900005
J	Kshetri, N				Kshetri, Nir			The academic industry's response to generative artificial intelligence: An institutional analysis of large language models	TELECOMMUNICATIONS POLICY			English	Article						Academic industry; ChatGPT; Generative artificial intelligence; Institutional theory; Large language models; Theorization	TRANSFORMATION; DIFFUSION; ADOPTION; GRADES	This paper examines academic institutions' heterogeneous initial responses to generative AI (GAI) tools like ChatGPT and factors influencing increased acceptance over time. GAI's disruptive nature coupled with uncertainty about impacts poses adoption challenges. However, external pressures from stakeholders seeking GAI integration contribute to changing attitudes. Actions of institutional change agents also drive growing acceptance by increasing awareness of GAI advantages. They challenge prevailing logics emphasizing assessments, proposing new values around employability and job performance. Additionally, academic institutions reevaluating GAI's value creation potential through applications and evolving business models contributes to favorable responses. The paper proposes an institutional theory framework explaining dynamics underpinning academic institutions' assimilation of GAI. It highlights how various mechanisms like external pressures, institutional entrepreneurs' theorization efforts justifying technology use, and internal sensemaking shape institutional norms and values, enabling academic systems' adaptation. The study informs policy and practice while directing future research toward validating propositions empirically and examining contextual dimensions including industry characteristics affecting GAI adoption.	[Kshetri, Nir] Univ North Carolina Greensboro, Bryan Sch Business & Econ, Greensboro, NC 27412 USA	University of North Carolina; University of North Carolina Greensboro	Kshetri, N (corresponding author), Univ North Carolina Greensboro, Bryan Sch Business & Econ, Greensboro, NC 27412 USA.	nbkshetr@uncg.edu						Adams S., 2021, Forbes; [Anonymous], 2023, University World News; BAIRD LL, 1985, RES HIGH EDUC, V23, P3, DOI 10.1007/BF00974070; Barath H., 2023, Chatgpt gets Dartmouth Talking; Barnett S., 2023, ChatGPT is making universities rethink plagiarism; Belot H., 2023, ChatGPT ban in Australia's public schools likely to be overturned; BestColleges, 2023, Can CHATGPT write my college essay?; Brady D., 2023, What developers need to know about generative AI; Bretz R., 1989, College Grade point average as a predictor of adult success: A meta-analytic review and some additional evidence, DOI [10.1177/009102600803700402?journalCode=ppmd, DOI 10.1177/009102600803700402?JOURNALCODE=PPMD]; Cakmak E., 2023, Here comes GPT-4: Is machine learning on the verge of graduation?; Chaudhry U., 2023, AI governance: What is being governed?; Christensen C., 2004, SEEING WHATS NEXT; Christensen C.M., 2003, INNOVATORS SOLUTION; Christensen C.M., 1997, INNOVATORS DILEMMA; Chwelos P, 2001, INFORM SYST RES, V12, P304, DOI 10.1287/isre.12.3.304.9708; Cjr, 2023, Should chatgpt join the J-school classroom?; DAgostino S., 2023, GPT-4 Is Here. But Most Faculty Lack AI Policies: Faculty members and administrators are struggling to stay ahead of disruptive AI progress, a new report suggests; Dealroom.co, 2024, Generative AI; Dholakia RR, 2004, SMALL BUS ECON, V23, P311, DOI 10.1023/B:SBEJ.0000032036.90353.1f; Dickson P. H., 2004, Managing cultural Diversity in technical Professions, P77; Dumitrescu I., 2023, Will ChatGPT Kill the student essay? Universities Aren't ready for the answer: AI is here to stay. It's up to educators to articulate why writing still matters; Dunleavy D., 2005, Photojournalism and the digital camera: 30 Years and counting; EISENHARDT KM, 1985, MANAGE SCI, V31, P134, DOI 10.1287/mnsc.31.2.134; Fawzi F., 2023, How companies can augment CX with ChatGPT and generative AI; Fowler G. A., 2023, Washington Post; GALTUNG J, 1958, SOC PROBL, V6, P127, DOI 10.1525/sp.1958.6.2.03a00050; gartner.com, 2019, Top trends on the Gartner hype cycle for artificial intelligence; Gay L.R., 1992, RES METHODS BUSINESS; George E, 2006, ACAD MANAGE REV, V31, P347; Gewirtz D., 2023, Can AI detectors save us from ChatGPT? I tried 5 online tools to find out; Gewirtz D., 2023, ZDNet; Goodwin D., 2023, Why a Google search revolution never happened: Google had a 'revolutionary' chatbot ready two years ago. Now, it's slowly rushing to put AI into more products. What happened?; Götz G, 1999, RAND J ECON, V30, P679, DOI 10.2307/2556070; govtech.com, 2023, Is ChatGPT Better Than a Human Tutor? Survey Says ... Yes. ...; govtech.com, 2023, Surveys: Educators Approve of ChatGPT for K-12, college; GREENWOOD R, 1993, ACAD MANAGE J, V36, P1052, DOI 10.5465/256645; Greenwood R, 2002, ACAD MANAGE J, V45, P58, DOI 10.5465/3069285; Griffith E., 2023, PCMag. March 16; Hadland A., 2015, The state of news photography: The lives and livelihoods of photojournalists in the digital age; HAVEMAN HA, 1992, ADMIN SCI QUART, V37, P48, DOI 10.2307/2393533; Heaven W. D., 2023, ChatGPT is going to change education, not destroy it; Heckel J., 2023, Phys.org; Holmes W., 2018, Technology-enhanced personalised learning: Untangling the evidence; Horn M. B., 2023, Don't Ban Artificial Intelligence, V23; Howell BE, 2023, TELECOMMUN POLICY, V47, DOI 10.1016/j.telpol.2023.102576; Hu K., 2023, Reuters; Hughes A., 2023, BBC Science Focus Magazine; Iles P., 2002, HUM RESOUR DEV INT, V5, P23; Ionita A., 2023, Think ChatGPT should Be banned from schools? Here's Why It Would Be Wrong; Irby K., 2002, Digital Camera Scores Big Points with Newspapers; Kan M., 2023, PCMag. February 1; Kapoor R, 2021, STRATEG SCI, V6, P62, DOI 10.1287/stsc.2020.0118; Kehoe B., 2017, How the evolution of the Google search engine has changed business.; King AA, 2015, MIT SLOAN MANAGE REV, V57, P77; Kshetri N, 2024, INT J INFORM MANAGE, V75, DOI 10.1016/j.ijinfomgt.2023.102716; Kshetri N, 2023, COMPUTER, V56, P77, DOI 10.1109/MC.2023.3278089; Kshetri N, 2020, TELECOMMUN POLICY, V44, DOI 10.1016/j.telpol.2020.102007; Kshetri N, 2013, TELECOMMUN POLICY, V37, P372, DOI 10.1016/j.telpol.2012.04.011; LANT TK, 1992, ORGAN SCI, V3, P47, DOI 10.1287/orsc.3.1.47; LEVITT B, 1988, ANNU REV SOCIOL, V14, P319, DOI 10.1146/annurev.so.14.080188.001535; Lin AC, 1998, POLICY STUD J, V26, P162, DOI 10.1111/j.1541-0072.1998.tb01931.x; Maguire S, 2004, ACAD MANAGE J, V47, P657, DOI [10.2307/20159610, 10.5465/20159610]; Major L, 2021, BRIT J EDUC TECHNOL, V52, P1935, DOI 10.1111/bjet.13116; Malik A., 2024, TechCrunch. January 11; Marche S., 2022, The College Essay Is Dead: Nobody is prepared for how AI will transform academia; Martineau K., 2023, IBM Research Blog. April 20; McClellan J., 2023, Iowa State Daily; McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259; McKenna S., 2023, The Conversation; McKnight L., 2022, Eight ways to engage with AI writers in higher education; Mehta R., 2023, Banning ChatGPT will do more harm than good. A high school senior argues that ChatGPT can help reshape education for the better; Misangyi VF, 2008, ACAD MANAGE REV, V33, P750; MIT Technology Review Insights, 2023, The great acceleration: CIO perspectives on generative AI: How technology leaders are adopting emerging tools to deliver enterprisewide AI; Myklebust J. P., 2023, Universities adjust to ChatGPT, but the 'real AI' lies ahead; Newman KL, 2000, ACAD MANAGE REV, V25, P602, DOI 10.2307/259313; Nietzel M. T., 2023, More Than Half of College Students Believe Using ChatGPT To Complete Assignments Is Cheating; Norman D. A., 2005, Ubiquity, V6; North D., 1996, Empirical studies in institutional change, P342, DOI DOI 10.1017/CBO9781139174633.023; NORTH DC, 1991, J ECON PERSPECT, V5, P97, DOI 10.1257/jep.5.1.97; O'Neill HM, 1998, ACAD MANAGE REV, V23, P98, DOI 10.2307/259101; Oberschall A., 1979, The dynamics of social Movements, P45; Olson S., 2006, Evolution of a Shutterbug; Outlook India, 2023, BrightCHAMPS partners with Harvard Business Publishing Education for its learning platform, programme certificates; Patrick J., 2023, WRAL.com; Rim C., 2023, Forbes. May 3; Rizvi A., 2023, UAE schools embrace latest technology to tackle CHATGPT cheating, the National; Roose K., 2023, NEW YORK TIMES; Roth PL, 1996, J APPL PSYCHOL, V81, P548, DOI 10.1037/0021-9010.81.5.548; Russo M. V., 2001, Organizational behavior in education: Adaptive leadership and school Reform, V3rd; SchengenVisaInfo.com, 2023, Top French university bans CHATGPT use to prevent plagiarism amongst students; Schlosser K., 2023, GeekWire; Schmidt GM, 2008, J PROD INNOVAT MANAG, V25, P347, DOI 10.1111/j.1540-5885.2008.00306.x; Scott WR, 2014, MANAGEMENT, V17, P136, DOI 10.3917/mana.172.0136; Sentinel-Tribune, 2023, Staff Reports; Seo MG, 2002, ACAD MANAGE REV, V27, P222, DOI 10.5465/AMR.2002.6588004; Sine WD, 2009, ADMIN SCI QUART, V54, P123, DOI 10.2189/asqu.2009.54.1.123; Spector C., 2023, What do AI chatbots really mean for students and cheating?; Stahl A., 2021, How AI will impact the future of work and Life; Steele J. L., 2023, Applied Physics A: Don't ban ChatGPT: Teach students to do what it can't do; Stevens-Huffman L., 2022, IT Career News, 29 July; study.com, 2023, ChatGPT in The Classroom; SUTTON RI, 1995, ADMIN SCI QUART, V40, P371, DOI 10.2307/2393788; Syme P., 2023, Business Insider; Tang C., 2023, Using, not banning, AI tools like ChatGPT can unlock new horizons for future generations; Teece DJ, 2007, STRATEGIC MANAGE J, V28, P1319, DOI 10.1002/smj.640; Thapa S., 2023, Business applications of ChatGPT; The Harvard Crimson, 2023, CHATGPT, cheating, and the future of education; Timothy A., 2023, CHATGPT banned by New York University to prevent plagiarism, the Post Millennial; Waxman O. B., 2023, The creative ways teachers are using ChatGPT in the classroom; Webster J, 2002, MIS QUART, V26, pXIII; Weick KE, 2015, MANAGEMENT, V18, P189, DOI 10.3917/mana.182.0189; WHETTEN DA, 1989, ACAD MANAGE REV, V14, P490, DOI 10.2307/258554; Wicki M, 2022, LANDSCAPE URBAN PLAN, V220, DOI 10.1016/j.landurbplan.2021.104350; Yang Hong, 2023, Nature, DOI 10.1038/d41586-023-01026-9; Zucker, 1988, I PATTERNS ORG CULTU, P3, DOI DOI 10.1016/J.GEOFORUM.2020.02.013	115	0	0	6	6	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0308-5961	1879-3258		TELECOMMUN POLICY	Telecommun. Policy	JUN	2024	48	5							102760	10.1016/j.telpol.2024.102760	http://dx.doi.org/10.1016/j.telpol.2024.102760			14	Communication; Information Science & Library Science; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Communication; Information Science & Library Science; Telecommunications	TC7M9					2024-07-03	WOS:001239126700001
J	D'Alessandro, W; Lloyd, HR; Sharadin, N				D'Alessandro, William; Lloyd, Harry R.; Sharadin, Nathaniel			Large Language Models and Biorisk	AMERICAN JOURNAL OF BIOETHICS			English	Editorial Material									[D'Alessandro, William; Lloyd, Harry R.; Sharadin, Nathaniel] Ctr AI Safety, San Francisco, CA USA; [D'Alessandro, William] Ludwig Maximilians Univ Munchen, Munich Ctr Math Philosophy, Munich, Germany; [Lloyd, Harry R.] Yale Univ, New Haven, CT USA; [Sharadin, Nathaniel] Univ Hong Kong, Hong Kong, Peoples R China; [Lloyd, Harry R.] Yale Univ, Dept Philosophy, POB 208306, New Haven, CT 06520 USA	University of Munich; Yale University; University of Hong Kong; Yale University	Lloyd, HR (corresponding author), Yale Univ, Dept Philosophy, POB 208306, New Haven, CT 06520 USA.	harry.lloyd@yale.edu	D'Alessandro, William/X-7924-2019	D'Alessandro, William/0000-0002-5451-079X				Boiko DA, 2023, Arxiv, DOI [arXiv:2304.05332, DOI 10.48550/ARXIV.2304.05332]; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Meechan PJ., 2023, Biosafety in microbiological and biomedical laboratories; Sandbrink JB, 2023, Arxiv, DOI arXiv:2306.13952; Soice EH, 2023, Arxiv, DOI arXiv:2306.03809; Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9; Zhou J., 2023, P 2023 CHI C HUM FAC, P1	9	2	2	2	4	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1526-5161	1536-0075		AM J BIOETHICS	Am. J. Bioeth.	OCT 3	2023	23	10					115	118		10.1080/15265161.2023.2250333	http://dx.doi.org/10.1080/15265161.2023.2250333			4	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	U2KH6	37812092	Green Submitted			2024-07-03	WOS:001083139600034
J	Yang, XX; Wang, ZF; Wang, Q; Wei, K; Zhang, KQ; Shi, JG				Yang, Xiaoxian; Wang, Zhifeng; Wang, Qi; Wei, Ke; Zhang, Kaiqi; Shi, Jiangang			Large language models for automated Q&A involving legal documents: a survey on algorithms, frameworks and applications	INTERNATIONAL JOURNAL OF WEB INFORMATION SYSTEMS			English	Article; Early Access						Large language model; Legal documents; Natural language processing; Automated Q&A application		Purpose - This study aims to adopt a systematic review approach to examine the existing literature on law and LLMs.It involves analyzing and synthesizing relevant research papers, reports and scholarly articles that discuss the use of LLMs in the legal domain. The review encompasses various aspects, including an analysis of LLMs, legal natural language processing (NLP), model tuning techniques, data processing strategies and frameworks for addressing the challenges associated with legal question-and-answer (Q&A) systems. Additionally, the study explores potential applications and services that can benefit from the integration of LLMs in the field of intelligent justice. Design/methodology/approach - This paper surveys the state-of-the-art research on law LLMs and their application in the field of intelligent justice. The study aims to identify the challenges associated with developing Q&A systems based on LLMs and explores potential directions for future research and development. The ultimate goal is to contribute to the advancement of intelligent justice by effectively leveraging LLMs. Findings - To effectively apply a law LLM, systematic research on LLM, legal NLP and model adjustment technology is required. Originality/value - This study contributes to the field of intelligent justice by providing a comprehensive review of the current state of research on law LLMs.	[Yang, Xiaoxian; Wang, Zhifeng; Wang, Qi; Wei, Ke; Zhang, Kaiqi] Shanghai Polytech Univ, Shanghai, Peoples R China; [Shi, Jiangang] Shanghai Shang Da Hai Run Informat Syst Co Ltd, Shanghai, Peoples R China	Shanghai Polytechnic University	Yang, XX (corresponding author), Shanghai Polytech Univ, Shanghai, Peoples R China.	xxyang@sspu.edu.cn						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aghajanyan Armen, 2021, P 59 ANN M ASS COMP, P7319, DOI DOI 10.18653/V1/2021.ACL-LONG.568; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalkidis I, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4310; Chen HH, 2022, IEEE T RELIAB, V71, P657, DOI 10.1109/TR.2022.3156126; Cui J., 2023, IEEE Access, V11; Cui J., 2023, Chatlaw; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Dias J., 2022, arXiv; Ding N, 2023, NAT MACH INTELL, V5, P220, DOI 10.1038/s42256-023-00626-4; Dolly F., 2023, Introducing the world's first truly open instruction-tuned LLM; El Moussaoui T, 2023, IEEE ACCESS, V11, P117851, DOI 10.1109/ACCESS.2023.3324288; Fei ZW, 2023, Arxiv, DOI arXiv:2309.16289; Fernandes B.J., 2023, IEEE LAT AM C COMP I, P1; Gordon DG, 2014, INT REQUIR ENG CONF, P273, DOI 10.1109/RE.2014.6912269; Guha Neel, 2023, 37 C NEUR INF PROC S; Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569; He C., 2023, IEEE Access, V11; He J., 2021, INT C LEARN REPR; He S., 2022, FINDINGS ASS COMPUTA, P2184; He W., 2023, Hanfei-1.0; Henderson P., 2022, Advances in Neural Information Processing Systems, V35, P29217; Holzenberger N., 2020, A dataset for statutory reasoning in tax law entailment and question answering; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, INT C LEARN REPR; Huang QZ, 2023, Arxiv, DOI arXiv:2305.15062; Hwang W., 2022, Advances in Neural Information Processing Systems, V35, P32537; Imran A.S., 2023, IEEE Access, V11; Jiang C., 2023, Lawyer llama; Katz D.M., 2023, Natural language processing in the legal domain; Lai JQ, 2023, Arxiv, DOI arXiv:2312.03718; Lee JS, 2023, Arxiv, DOI arXiv:2306.05431; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li HT, 2023, Arxiv, DOI arXiv:2304.11370; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li XC, 2020, IEEE ACCESS, V8, P101569, DOI 10.1109/ACCESS.2020.2998108; Ma Li, 2022, 2022 International Conference on Computation, Big-Data and Engineering (ICCBE), P51, DOI 10.1109/ICCBE56101.2022.9888165; Ma YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2342, DOI 10.1145/3404835.3463250; Mahabadi RK, 2021, ADV NEUR IN, V34; Malic VQ, 2023, INT CONF DAT MIN WOR, P245, DOI 10.1109/ICDMW60847.2023.00037; McIntosh T.R., 2023, IEEE Transactions on Artificial Intelligence, V1, P1; Nguyen H.T., 2023, arXiv; Prasad A., 2023, P 17 C EUROPEAN CHAP, P3827; Qin Ruyu, 2022, 2022 5th International Conference on Artificial Intelligence and Big Data (ICAIBD)., P444, DOI 10.1109/ICAIBD55127.2022.9820466; Qu Yanan, 2023, 2023 6th International Conference on Artificial Intelligence and Big Data (ICAIBD), P225, DOI 10.1109/ICAIBD57115.2023.10206169; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Rasiah V., 2023, arXiv; Ravichander A., 2019, EMPIRICAL METHODS NA; Resck L.E., 2022, IEEE T VISUALIZATION; Sabry M, 2023, Arxiv, DOI arXiv:2304.12410; Sasidharan A.K., 2023, 4 IEEE GLOB C ADV TE, P1; Sheik R., 2021, IEEE 8 UTT PRAD SECT, P1; Song DZ, 2022, IEEE ACCESS, V10, P75835, DOI 10.1109/ACCESS.2022.3190408; Sovrano Francesco, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P230, DOI 10.1145/3462757.3466094; Su YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3949; Tamatjita Elizabeth Nurmiyati, 2021, 2021 6th International Conference on New Media Studies (CONMEDIA), P84, DOI 10.1109/CONMEDIA53104.2021.9617172; Taulli T., 2023, Generative AI: How ChatGPT and Other AI Tools Will Revolutionize Business, P93; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trklja A., 2018, P 2 WORKSHOP CORPUS, V1, P217; Vaswani A, 2017, ADV NEUR IN, V30; Wagh R, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ADVANCED COMPUTING (ICCTAC); Wang Alex, 2018, INT C LEARN REPR; Wang C, 2020, IEEE ACCESS, V8, P36061, DOI 10.1109/ACCESS.2020.2972586; Wang Nyu, 2023, AI Ethics, V3, P349, DOI 10.1007/s43681-022-00202-3; Wang Y., 2022, P 2022 C EMP METH NA, P5085; Wang Z., 2021, Judicature, V105, P36; Wei Fusheng, 2023, 2023 IEEE International Conference on Big Data (BigData), P2786, DOI 10.1109/BigData59044.2023.10386911; Wei JS, 2022, ADV NEUR IN; Wei Jiaheng, 2021, INT C LEARN REPR; Wu S., 2023, fuzi.mingcha; Yang AY, 2023, Arxiv, DOI [arXiv:2309.10305, DOI 10.48550/ARXIV.2309.10305]; Yue SB, 2023, Arxiv, DOI arXiv:2309.11325; Zhang LT, 2023, Arxiv, DOI arXiv:2308.03303; Zhang Q., 2022, 11 INT C LEARN REPR; Zhong H., 2020, P 58 ANN M ASS COMPU, P5218; Zhong HX, 2020, AAAI CONF ARTIF INTE, V34, P9701; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206	79	0	0	5	5	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	1744-0084	1744-0092		INT J WEB INF SYST	Int. J. Web Inf. Syst.	2024 APR 1	2024										10.1108/IJWIS-12-2023-0256	http://dx.doi.org/10.1108/IJWIS-12-2023-0256		APR 2024	23	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	MI8I4					2024-07-03	WOS:001193080600001
J	Merrell, LA; Fisher, ND; Egol, KA				Merrell, Lauren A.; Fisher, Nina D.; Egol, Kenneth A.			Large Language Models in Orthopaedic Trauma	JOURNAL OF BONE AND JOINT SURGERY-AMERICAN VOLUME			English	Article									[Merrell, Lauren A.; Fisher, Nina D.; Egol, Kenneth A.] NYU Langone Orthoped Hosp, NYU Langone Hlth, Dept Orthoped Surg, Div Orthoped Trauma Surg, New York, NY 10010 USA	NYU Langone Medical Center	Egol, KA (corresponding author), NYU Langone Orthoped Hosp, NYU Langone Hlth, Dept Orthoped Surg, Div Orthoped Trauma Surg, New York, NY 10010 USA.	lauren.merrell@nyulangone.org; nina.fisher@nyulangone.org; kenneth.Egol@nyulangone.org		Merrell, Lauren/0009-0002-8285-2807				[Anonymous], 2013, Bull Hosp Jt Dis; Bernstein J, 2023, CLIN ORTHOP RELAT R, V481, P651, DOI 10.1097/CORR.0000000000002619; Brown T., 2020, Language models are few-shot learners, DOI [10.5555/3495724.3495883, DOI 10.5555/3495724.3495883]; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; GitHub, 2023, Awesome ChatGPT Prompts; Hurben AK, 2022, CHEM RES TOXICOL, V35, P1925, DOI 10.1021/acs.chemrestox.2c00269; Ollivier M, 2023, KNEE SURG SPORT TR A, V31, P1190, DOI 10.1007/s00167-023-07372-5; Wikipedia, GPT-4; Wikipedia, Large language model; Zuckermann J, 2020, Handbook of Fractures, V6th	10	0	0	1	2	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0021-9355	1535-1386		J BONE JOINT SURG AM	J. Bone Joint Surg.-Am. Vol.	SEP 6	2023	105	17					1383	1387		10.2106/JBJS.23.00395	http://dx.doi.org/10.2106/JBJS.23.00395			5	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	R8CG1					2024-07-03	WOS:001066573200013
J	Dias, AL; Rodrigues, T				Dias, Ana Laura; Rodrigues, Tiago			Large language models direct automated chemistry laboratory	NATURE			English	Editorial Material						Chemistry; Computer science; Machine learning	DENTAL ENAMEL DEFECTS; CELIAC-DISEASE; DENDRITIC CELLS; PROTEIN; MACROPHAGES; AMELOGENIN; GENE; IGA; EXPRESSION; CHILDREN	Automation of chemistry research has focused on developing robots to execute jobs. Artificial-intelligence technology has now been used not only to control robots, but also to plan their tasks on the basis of simple human prompts.	[Dias, Ana Laura; Rodrigues, Tiago] Univ Lisbon, Res Inst Med iMed, Fac Pharm, P-1649003 Lisbon, Portugal	Universidade de Lisboa	Rodrigues, T (corresponding author), Univ Lisbon, Res Inst Med iMed, Fac Pharm, P-1649003 Lisbon, Portugal.	tiago.rodrigues@ff.ulisboa.pt	Rodrigues, Tiago/K-4064-2016	Rodrigues, Tiago/0000-0002-1581-5654				Abramson J, 2016, IMMUNOL REV, V271, P127, DOI 10.1111/imr.12419; AHONEN P, 1990, NEW ENGL J MED, V322, P1829, DOI 10.1056/NEJM199006283222601; AINE L, 1994, BRIT DENT J, V177, P253, DOI 10.1038/sj.bdj.4808578; Alvarez RV, 2019, BIOINFORMATICS, V35, P1960, DOI 10.1093/bioinformatics/bty896; Aschenbrenner K, 2007, NAT IMMUNOL, V8, P351, DOI 10.1038/ni1444; Baratella L, 2000, J ANAT, V197, P303, DOI 10.1046/j.1469-7580.2000.19720303.x; Beth SA, 2016, ACTA PAEDIATR, V105, pe485, DOI 10.1111/apa.13533; Bijl E, 2013, J DAIRY SCI, V96, P5455, DOI 10.3168/jds.2012-6497; Bornstein C, 2018, NATURE, V559, P622, DOI 10.1038/s41586-018-0346-1; Bosso M, 2007, Eur J Paediatr Dent, V8, P31; Bruserud O, 2016, J CLIN ENDOCR METAB, V101, P2975, DOI 10.1210/jc.2016-1821; Bucci P, 2006, ACTA PAEDIATR, V95, P203, DOI 10.1080/08035250500355022; Caccamo D, 2009, AMINO ACIDS, V36, P49, DOI 10.1007/s00726-008-0025-x; Calamari ZT, 2018, BIOESSAYS, V40, DOI 10.1002/bies.201800140; Capone K., 2020, Ann. Pediatr., V3, P1028; Catassi C, 2014, J PEDIATR GASTR NUTR, V59, pS7, DOI 10.1097/01.mpg.0000450393.23156.59; Chiba Y, 2020, J BIOL CHEM, V295, P15328, DOI 10.1074/jbc.RA120.014281; Concordet JP, 2018, NUCLEIC ACIDS RES, V46, pW242, DOI 10.1093/nar/gky354; Coucke F, 2018, AUTOIMMUN REV, V17, P1078, DOI 10.1016/j.autrev.2018.05.011; De Laurenzi V, 2001, MOL CELL BIOL, V21, P148, DOI 10.1128/MCB.21.1.148-155.2001; Dieterich W, 1997, NAT MED, V3, P797, DOI 10.1038/nm0797-797; Doench JG, 2016, NAT BIOTECHNOL, V34, P184, DOI 10.1038/nbt.3437; Duverger O, 2014, J CLIN INVEST, V124, P5219, DOI 10.1172/JCI78272; Eckstein M, 2017, JCI INSIGHT, V2, DOI 10.1172/jci.insight.91166; Gibbons DL, 2011, MUCOSAL IMMUNOL, V4, P148, DOI 10.1038/mi.2010.85; Goldfarb Y, 2021, J EXP MED, V218, DOI 10.1084/jem.20201076; Herrera MG, 2021, BIOPHYS REV-GER, V13, P1147, DOI 10.1007/s12551-021-00856-z; Hsu PD, 2013, NAT BIOTECHNOL, V31, P827, DOI 10.1038/nbt.2647; Hu JCC, 2003, CRIT REV ORAL BIOL M, V14, P387, DOI 10.1177/154411130301400602; Jaitin DA, 2014, SCIENCE, V343, P776, DOI 10.1126/science.1247651; Jericho H, 2018, NUTRIENTS, V10, DOI 10.3390/nu10060755; JESSEN H, 1972, Z ZELLFORSCH MIK ANA, V126, P466, DOI 10.1007/BF00306907; Jiang WY, 2005, J EXP MED, V202, P805, DOI 10.1084/jem.20050693; Jung S, 2000, MOL CELL BIOL, V20, P4106, DOI 10.1128/MCB.20.11.4106-4114.2000; KATCHBURIAN E, 1967, J ANAT, V101, P783; Khan F, 2006, ANAL CHEM, V78, P3072, DOI 10.1021/ac060184l; Kim YJ, 2016, EUR J ORAL SCI, V124, P403, DOI 10.1111/eos.12280; Kohen R, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2728-2; Kristjánsson G, 2007, CLIN EXP IMMUNOL, V147, P449, DOI 10.1111/j.1365-2249.2007.03298.x; Laible G, 2016, SCI REP-UK, V6, DOI 10.1038/srep37607; MARIANI P, 1994, ACTA PAEDIATR, V83, P1272, DOI 10.1111/j.1651-2227.1994.tb13014.x; McCarra C, 2022, INT J PAEDIATR DENT, V32, P367, DOI 10.1111/ipd.12892; Monteiro RC, 2003, ANNU REV IMMUNOL, V21, P177, DOI 10.1146/annurev.immunol.21.120601.141011; MYLLARNIEMI S, 1978, ORAL SURG ORAL MED O, V45, P721, DOI 10.1016/0030-4220(78)90147-0; Nelson S. J., 2015, Dental Anatomy, Physiology and Occlusion; Nieri M, 2017, J DENT, V65, P1, DOI 10.1016/j.jdent.2017.07.001; Nishikawa S, 1996, J HISTOCHEM CYTOCHEM, V44, P1459, DOI 10.1177/44.12.8985138; Nishikawa S, 1999, HISTOCHEM CELL BIOL, V112, P301, DOI 10.1007/s004180050451; Nishikawa Y, 2010, J EXP MED, V207, P963, DOI 10.1084/jem.20092144; Ossart J, 2018, J IMMUNOL, V201, P874, DOI 10.4049/jimmunol.1701318; Paolella G, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms23147513; Pastore L, 2008, J CLIN GASTROENTEROL, V42, P224, DOI 10.1097/MCG.0b013e318074dd98; Pavlic A, 2009, ARCH ORAL BIOL, V54, P658, DOI 10.1016/j.archoralbio.2009.03.009; Pemberton TJ, 2007, DEV DYNAM, V236, P2245, DOI 10.1002/dvdy.21226; Perniola R, 1998, J ORAL PATHOL MED, V27, P278, DOI 10.1111/j.1600-0714.1998.tb01956.x; Peterson P, 2005, J AUTOIMMUN, V25, P49, DOI 10.1016/j.jaut.2005.09.022; Petronijevic S, 2020, EUR J ORAL SCI, V128, P27, DOI 10.1111/eos.12672; Petronijevic S, 2016, EUR J ORAL SCI, V124, P526, DOI 10.1111/eos.12314; Pham CD, 2017, FRONT PHYSIOL, V11, DOI 10.3389/fphys.2017.00529; Poulter JA, 2014, EUR J HUM GENET, V22, P132, DOI 10.1038/ejhg.2013.76; Rashid M, 2011, J CAN DENT ASSOC, V77; Sansom SN, 2014, GENOME RES, V24, P1918, DOI 10.1101/gr.171645.113; Sharir A, 2019, NAT CELL BIOL, V21, P1102, DOI 10.1038/s41556-019-0378-2; SIMMER JP, 1994, CALCIFIED TISSUE INT, V54, P312, DOI 10.1007/BF00295956; Sinnberg T, 2023, AM J RESP CRIT CARE, V207, P38, DOI 10.1164/rccm.202201-0011OC; Smith CEL, 2019, J DENT RES, V98, P698, DOI 10.1177/0022034519835205; Smith CEL, 2017, FRONT PHYSIOL, V8, DOI [10.3389/fphys.2017.00333, 10.3389/fphys.2017.00435]; Sollid LM, 2002, NAT REV IMMUNOL, V2, P647, DOI 10.1038/nri885; Sóñora C, 2016, EUR J ORAL SCI, V124, P11, DOI 10.1111/eos.12241; Stenman SM, 2008, BMC IMMUNOL, V9, DOI 10.1186/1471-2172-9-6; Tack GJ, 2010, NAT REV GASTRO HEPAT, V7, P204, DOI 10.1038/nrgastro.2010.23; Tsuruga E, 1999, HISTOCHEM CELL BIOL, V112, P193, DOI 10.1007/s004180050407; Vazquez SE, 2020, ELIFE, V9, DOI 10.7554/eLife.55053; Wald T, 2013, J BIOL CHEM, V288, P22333, DOI 10.1074/jbc.M113.456012; Wedholm A, 2006, J DAIRY SCI, V89, P3296, DOI 10.3168/jds.S0022-0302(06)72366-9; Werink CD, 2007, INT J PAEDIATR DENT, V17, P163, DOI 10.1111/j.1365-263X.2006.00816.x; WILKINSON DG, 1993, METHOD ENZYMOL, V225, P361; Wyss L, 2016, NAT IMMUNOL, V17, P1093, DOI 10.1038/ni.3522; Xu H, 2015, GENOME RES, V25, P1147, DOI 10.1101/gr.191452.115; Zone JJ, 2004, J INVEST DERM SYMP P, V9, P47, DOI 10.1111/j.1087-0024.2004.00840.x	80	0	0	22	23	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	DEC 21	2023	624	7992					530	531		10.1038/d41586-023-03790-0	http://dx.doi.org/10.1038/d41586-023-03790-0			2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CY8A1	38123802				2024-07-03	WOS:001128871300003
J	Skondras, P; Zervas, P; Tzimas, G				Skondras, Panagiotis; Zervas, Panagiotis; Tzimas, Giannis			Generating Synthetic Resume Data with Large Language Models for Enhanced Job Description Classification	FUTURE INTERNET			English	Article						metadata extraction; resumes; CV; big data; multiclass classification; ChatGPT; large language models; deep learning; embeddings; labor market analysis		In this article, we investigate the potential of synthetic resumes as a means for the rapid generation of training data and their effectiveness in data augmentation, especially in categories marked by sparse samples. The widespread implementation of machine learning algorithms in natural language processing (NLP) has notably streamlined the resume classification process, delivering time and cost efficiencies for hiring organizations. However, the performance of these algorithms depends on the abundance of training data. While selecting the right model architecture is essential, it is also crucial to ensure the availability of a robust, well-curated dataset. For many categories in the job market, data sparsity remains a challenge. To deal with this challenge, we employed the OpenAI API to generate both structured and unstructured resumes tailored to specific criteria. These synthetically generated resumes were cleaned, preprocessed and then utilized to train two distinct models: a transformer model (BERT) and a feedforward neural network (FFNN) that incorporated Universal Sentence Encoder 4 (USE4) embeddings. While both models were evaluated on the multiclass classification task of resumes, when trained on an augmented dataset containing 60 percent real data (from Indeed website) and 40 percent synthetic data from ChatGPT, the transformer model presented exceptional accuracy. The FFNN, albeit predictably, achieved lower accuracy. These findings highlight the value of augmented real-world data with ChatGPT-generated synthetic resumes, especially in the context of limited training data. The suitability of the BERT model for such classification tasks further reinforces this narrative.	[Skondras, Panagiotis; Zervas, Panagiotis; Tzimas, Giannis] Univ Peloponnese, Dept Elect & Comp Engn, Data & Media Lab, Tripoli 22100, Greece	University of Peloponnese	Zervas, P (corresponding author), Univ Peloponnese, Dept Elect & Comp Engn, Data & Media Lab, Tripoli 22100, Greece.	eced2024@go.uop.gr; p.zervas@uop.gr; tzimas@uop.gr			O*NET Web Services [27,28]; U.S. Department of Labor, Employment and Training Administration (USDOL/ETA)	O*NET Web Services; U.S. Department of Labor, Employment and Training Administration (USDOL/ETA)	This paper incorporated information from O*NET Web Services [27,28] by the U.S. Department of Labor, Employment and Training Administration (USDOL/ETA). O*NET (R) is a trademark of USDOL/ETA.	Abonizio H, 2023, Arxiv, DOI arXiv:2307.04601; Anand Yuvanesh., Gpt4all: Training an assistant-style chatbot with large scale data distillation from gpt-3.5-turbo; Bayer M, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3544558; bit, OpenAI API; Decorte J.-J., 2021, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ekin S, 2023, TechRxiv, DOI [10.36227/techrxiv.22683919.v2, DOI 10.36227/TECHRXIV.22683919.V2]; Gao A., 2023, SSRN Electr J, DOI DOI 10.2139/SSRN.4504303; huggingface, Hugging Face Libraries; Jeronymo V, 2023, Arxiv, DOI [arXiv:2301.01820, DOI 10.48550/ARXIV.2301.01820]; Jiechieu KFF, 2021, NEURAL COMPUT APPL, V33, P5069, DOI 10.1007/s00521-020-05302-x; Josifoski M, 2023, Arxiv, DOI arXiv:2303.04132; Kuchnik M, 2023, Arxiv, DOI arXiv:2211.15458; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Li YL, 2021, PROC VLDB ENDOW, V14, P3182, DOI 10.14778/3476311.3476403; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Liu Y, 2024, Arxiv, DOI [arXiv:2305.13860, DOI 10.48550/ARXIV.2305.13860, 10.48550/arXiv.2305.13860]; Malinowski J., 2006, P 39 ANN HAWAII INT, V6, p137c, DOI DOI 10.1109/HICSS.2006.266; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; O*NET Code Connector, About us; onetcenter, O*NET Web Services; Shi ZX, 2023, Arxiv, DOI arXiv:2306.07664; Skondras P., 2023, P 14 INT C INFORM IN; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Tallapragada V. V. Satyanarayana, 2023, 2023 7th International Conference on Intelligent Computing and Control Systems (ICICCS), P1702, DOI 10.1109/ICICCS56967.2023.10142800; Veselovsky V, 2023, Arxiv, DOI arXiv:2305.15041; Vukadin D, 2021, IEEE ACCESS, V9, P84559, DOI 10.1109/ACCESS.2021.3087913; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Whitehouse C, 2023, Arxiv, DOI arXiv:2305.14288; XiaoWei Li, 2021, 2021 IEEE 21st International Conference on Communication Technology (ICCT), P1437, DOI 10.1109/ICCT52962.2021.9657937; Xing Yi, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P809; Xu BF, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P8186; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420	33	1	1	9	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	NOV	2023	15	11							363	10.3390/fi15110363	http://dx.doi.org/10.3390/fi15110363			12	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	Y8RJ0		gold			2024-07-03	WOS:001107875100001
C	Sharma, M; Farough, S; Burkett, A; Prasanth, J; El-Shafeey, N; Zygadlo, D; Dunn, C; Korn, R		Yoshida, H; Wu, S		Sharma, Manish; Farough, Samira; Burkett, Andre; Prasanth, Jerome; El-Shafeey, Nabil; Zygadlo, Dominic; Dunn, Chera; Korn, Ron			Enhancing interpretation assistance by real-time query resolution in BICR of Oncology Clinical Trials by leveraging ChatGPT bots	IMAGING INFORMATICS FOR HEALTHCARE, RESEARCH, AND APPLICATIONS, MEDICAL IMAGING 2024	Proceedings of SPIE		English	Proceedings Paper	Conference on Medical Imaging - Imaging Informatics for Healthcare, Research, and Applications	FEB 19-21, 2024	San Diego, CA	SPIE, Amer Assoc Physicists Med, Radiol Soc N Amer, World Mol Imaging Soc, Soc Imaging Informat Med, Int Fdn Comp Assisted Radiol & Surg, Med Image Percept Soc		clinical trials; medical imaging; BICR; interpretation assistance; chatbot; ChatGPT; LLM; Independent Review Charter		Purpose: Blinded Independent Central Review (BICR) is pivotal in maintaining unbiased assessment in oncology clinical trials employing various assessment criteria like Response Evaluation Criteria In Solid Tumors (RECIST) in clinical trials framework. This paper emphasizes the potential of Large Language Models (LLMs) such as OpenAI's GPT-4 and ChatGPT trained on clinical trials' documents and other reader training materials, to significantly improve interpretation assistance and real-time query resolution. During central review process these documents are easily accessible to readers but sometimes, given that most readers read on multiple ongoing clinical trials on regular basis, it is a daunting task to search details like trial design, endpoints and specific reader rules. Through various pre-trained frameworks using ChatGPT Application Programming Interface (API), an AI-based chatbot can be used for helping readers saving time by providing accurate study design related questions based on uploaded training documents. If successful, this analysis can open another novel implementation for LLMs (or ChatGPT) in clinical research and medical imaging. Methods: This prospective study involved the review of study design and protocol available from clinicaltrials.gov database maintained by The National Library of Medicine (NLM) at the National Institutes of Health (NIH). ClinicalTrials.gov is a registry of clinical trials that contains information on clinical studies funded by the NIH, other federal agencies, and private industry. The database includes over 444,000 trials from 221 countries. The NLM works with the US Food and Drug Administration (FDA) to develop and maintain the database. The ChatGPT based Chatbot was trained on clinical trial design data from respective studies to grasp the intricacies of assessment criteria, patient population, inclusion / exclusion criteria and other assessment nuances, as applicable. Fine-tuning with prompt engineering ensured Chatbot to understand the language and context specific to BICR. The resulting models serve as intelligent assistants to provide a user-friendly interface for reviewers. Reviewers can engage with the chatbot in natural language, obtaining clarifications on assessment guidelines, terminology, and complex cases. To train the Chatbot, we searched for Lung Cancer studies with following specifications: "Completed Studies | Studies With Results | Interventional Studies | Lung Cancer | Phase 3 | Study Protocols | Statistical Analysis Plans (SAPs)" from the clinicaltrials.gov website. Without any bias, we selected the first 3 studies in search results for our prospective study and 7 questions to ask, representative of commonly encountered queries for readers. Results: The algorithm supported by ChatGPT was evaluated against a Gold Standard medical opinion, determined by a board-certified radiologist with over 20 years of experience in the BICR process. The Chatbot provided immediate, contextually accurate insights for all the questions across 3 studies. The trick questions which did not have the answers, data or references in the provided text were rightly called out by the Chatbot, suggesting the user to check with document or study team. Though sometimes, in addition to referencing the study team or documents, it did provide a clinical practice or general criteria related feedback. Real-time query resolution reduces response time, preventing delays in assessment and decision-making. Conclusions: LLMs can streamline training by offering on-the-spot explanations and references, enhancing reviewer proficiency and efficiency. By acting as interactive chatbots, LLMs have immense potential to improve quality and efficiency by offering contextual guidance and expedited responses, ultimately enhancing decision-making and study efficiency.	[Sharma, Manish; Prasanth, Jerome] Imaging Endpoints, Hyderabad, India; [Farough, Samira; Burkett, Andre; El-Shafeey, Nabil; Zygadlo, Dominic; Dunn, Chera; Korn, Ron] Imaging Endpoints, Scottsdale, AZ USA		Sharma, M (corresponding author), Imaging Endpoints, Hyderabad, India.							[Anonymous], 2004, Guidance for Industry Developing Medical Imaging Drug and Biologic Products. Part 3: Design, Analysis, and Interpretation of Clinical Studies; [Anonymous], 2015, Clinical Trial Imaging Endpoints Process Standards Guidance for Industry Draft US Department of Health and Human Services; Beaumont H, 2018, CANCER IMAGING, V18, DOI 10.1186/s40644-018-0186-0; Doo FX, 2023, J AM COLL RADIOL, V20, P877, DOI 10.1016/j.jacr.2023.07.007; Eisenhauer EA, 2009, EUR J CANCER, V45, P228, DOI 10.1016/j.ejca.2008.10.026; Ford RR, 2016, J Clin Trials, V6-5, P289, DOI [10.4172/2167-0870.1000289, DOI 10.4172/2167-0870.1000289]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Iannessi A, 2021, INSIGHTS IMAGING, V12, DOI 10.1186/s13244-021-00976-w; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Lopez-Ubeda P, 2023, EUR RADIOL, V33, P9455, DOI 10.1007/s00330-023-09901-9; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schmid AM, 2021, THER INNOV REGUL SCI, V55, P1111, DOI 10.1007/s43441-021-00316-6; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Tippareddy Charit, 2023, Curr Probl Diagn Radiol, DOI 10.1067/j.cpradiol.2023.08.018; van Meerten ELV, 2010, EUR RADIOL, V20, P1456, DOI 10.1007/s00330-009-1685-y	19	0	0	0	0	SPIE-INT SOC OPTICAL ENGINEERING	BELLINGHAM	1000 20TH ST, PO BOX 10, BELLINGHAM, WA 98227-0010 USA	0277-786X	1996-756X	978-1-5106-7167-6; 978-1-5106-7166-9	PROC SPIE			2024	12931								1293117	10.1117/12.3011602	http://dx.doi.org/10.1117/12.3011602			10	Computer Science, Artificial Intelligence; Radiology, Nuclear Medicine & Medical Imaging	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BW9QJ					2024-07-03	WOS:001219280700038
J	Zhang, LX; Li, CX; Hu, Q; Lang, JJ; Huang, SR; Hu, LY; Leng, JW; Chen, QH; Lv, CL				Zhang, Lexin; Li, Changxiang; Hu, Qi; Lang, Jingjing; Huang, Sirui; Hu, Linyue; Leng, Jingwen; Chen, Qiuhan; Lv, Chunli			Enhancing Privacy in Large Language Model with Homomorphic Encryption and Sparse Attention	APPLIED SCIENCES-BASEL			English	Article						privacy-preserving dialogue systems; Fully Homomorphic Encryption; dynamic sparse attention mechanism; data security in artificial intelligence; large language model		In response to the challenges of personal privacy protection in the dialogue models of the information era, this study introduces an innovative privacy-preserving dialogue model framework. This framework seamlessly incorporates Fully Homomorphic Encryption (FHE) technology with dynamic sparse attention (DSA) mechanisms, aiming to enhance the response efficiency and accuracy of dialogue systems without compromising user privacy. Experimental comparative analyses have confirmed the advantages of the proposed framework in terms of precision, recall, accuracy, and latency, with values of 0.92, 0.91, 0.92, and 15 ms, respectively. In particular, the newly proposed DSA module, while ensuring data security, significantly improves performance by up to 100 times compared to traditional multi-head attention mechanisms.	[Zhang, Lexin; Li, Changxiang; Hu, Qi; Lang, Jingjing; Huang, Sirui; Hu, Linyue; Leng, Jingwen; Chen, Qiuhan; Lv, Chunli] China Agr Univ, Beijing 100083, Peoples R China	China Agricultural University	Lv, CL (corresponding author), China Agr Univ, Beijing 100083, Peoples R China.	lvcl@cau.edu.cn	Hu, Qi/GOV-6201-2022; Leng, Jingwen/V-2299-2019	Hu, Qi/0000-0002-3885-0444; Leng, Jingwen/0000-0002-5660-5493	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Bonte C, 2022, LECT NOTES COMPUT SC, V13792, P188, DOI 10.1007/978-3-031-22966-4_7; Cai YL, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22121339; Chen JX, 2023, ENERGY, V262, DOI 10.1016/j.energy.2022.125375; Chen T., 2022, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Vu DH, 2020, INFORM SCIENCES, V527, P356, DOI 10.1016/j.ins.2019.07.031; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]; Hua BJ, 2023, SOFT COMPUT, DOI 10.1007/s00500-023-08548-4; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Jowsey T, 2023, TRENDS MOL MED, V29, P971, DOI 10.1016/j.molmed.2023.08.012; Kim J, 2021, IEEE ACCESS, V9, P107279, DOI 10.1109/ACCESS.2021.3100852; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kurstjens S, 2024, CLIN CHEM LAB MED, V62, pe59, DOI 10.1515/cclm-2023-0885; Leippold M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2022.103617; Lin XC, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14081771; Menon SJ, 2022, P IEEE S SECUR PRIV, P930, DOI [10.1109/SP46214.2022.9833700, 10.1109/SP46214.2022.00139]; Olakanmi OO, 2022, INTERNET THINGS-NETH, V19, DOI 10.1016/j.iot.2022.100527; Peng ZN, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7330; Shen TX, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P723; Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Vaswani A, 2017, ADV NEUR IN, V30; Wang JY, 2022, BIG DATA RES, V27, DOI 10.1016/j.bdr.2021.100296; Wang YQ, 2022, Arxiv, DOI arXiv:2209.13643; Wei YC, 2020, J SUPERCOMPUT, V76, P1468, DOI 10.1007/s11227-018-2371-0; Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1; Xu WJ, 2023, COMPUT J, V66, P197, DOI 10.1093/comjnl/bxab154; Yagisawa M, 2021, IEICE T FUND ELECTR, VE104A, P275, DOI 10.1587/transfun.2020EAP1057; Zhang Y, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020234; Zhang Y, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13214218; Zhang Y, 2022, ENERGIES, V15, DOI 10.3390/en15113959; Zhang YJ, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03051-x; Zhong Y, 2023, ASIAN J PSYCHIATR, V84, DOI 10.1016/j.ajp.2023.103577; Zhou JP, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041540	35	0	0	11	11	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	DEC	2023	13	24							13146	10.3390/app132413146	http://dx.doi.org/10.3390/app132413146			19	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	DH2H1		gold			2024-07-03	WOS:001131067400001
J	Huang, TM; Socrates, V; Gilson, A; Safranek, C; Chi, L; Wang, EA; Puglisi, LB; Brandt, C; Taylor, RA; Wang, KR				Huang, Thomas; Socrates, Vimig; Gilson, Aidan; Safranek, Conrad; Chi, Ling; Wang, Emily A.; Puglisi, Lisa B.; Brandt, Cynthia; Taylor, R. Andrew; Wang, Karen			Identifying incarceration status in the electronic health record using large language models in emergency department settings	JOURNAL OF CLINICAL AND TRANSLATIONAL SCIENCE			English	Article						ChatGPT; emergency department; incarceration; justice involvement; large language models; machine learning; natural language processing	PUBLIC-HEALTH; INTERVENTION; EXPOSURE; VIOLENCE	Background: Incarceration is a significant social determinant of health, contributing to high morbidity, mortality, and racialized health inequities. However, incarceration status is largely invisible to health services research due to inadequate clinical electronic health record (EHR) capture. This study aims to develop, train, and validate natural language processing (NLP) techniques to more effectively identify incarceration status in the EHR.Methods: The study population consisted of adult patients (>= 18 y.o.) who presented to the emergency department between June 2013 and August 2021. The EHR database was filtered for notes for specific incarceration-related terms, and then a random selection of 1,000 notes was annotated for incarceration and further stratified into specific statuses of prior history, recent, and current incarceration. For NLP model development, 80% of the notes were used to train the Longformer-based and RoBERTa algorithms. The remaining 20% of the notes underwent analysis with GPT-4.Results: There were 849 unique patients across 989 visits in the 1000 annotated notes. Manual annotation revealed that 559 of 1000 notes (55.9%) contained evidence of incarceration history. ICD-10 code (sensitivity: 4.8%, specificity: 99.1%, F1-score: 0.09) demonstrated inferior performance to RoBERTa NLP (sensitivity: 78.6%, specificity: 73.3%, F1-score: 0.79), Longformer NLP (sensitivity: 94.6%, specificity: 87.5%, F1-score: 0.93), and GPT-4 (sensitivity: 100%, specificity: 61.1%, F1-score: 0.86).Conclusions: Our advanced NLP models demonstrate a high degree of accuracy in identifying incarceration status from clinical notes. Further research is needed to explore their scaled implementation in population health initiatives and assess their potential to mitigate health disparities through tailored system interventions.	[Huang, Thomas; Gilson, Aidan; Safranek, Conrad; Taylor, R. Andrew] Yale Sch Med, Dept Emergency Med, New Haven, CT 06510 USA; [Socrates, Vimig; Gilson, Aidan; Chi, Ling; Wang, Emily A.; Puglisi, Lisa B.; Brandt, Cynthia; Taylor, R. Andrew; Wang, Karen] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT 06520 USA; [Socrates, Vimig] Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT USA; [Wang, Emily A.; Puglisi, Lisa B.; Wang, Karen] Yale Sch Med, SE Ctr Hlth & Justice, New Haven, CT USA; [Wang, Emily A.; Puglisi, Lisa B.; Wang, Karen] Yale Sch Med, Dept Med, New Haven, CT USA; [Wang, Karen] Yale Univ, Equ Res & Innovat Ctr, Yale Sch Med, New Haven, CT USA	Yale University; Yale University; Yale University; Yale University; Yale University; Yale University	Taylor, RA (corresponding author), Yale Sch Med, Dept Emergency Med, New Haven, CT 06510 USA.; Taylor, RA (corresponding author), Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, New Haven, CT 06520 USA.	richard.taylor@yale.edu		Huang, Thomas/0000-0001-9056-7016; /0000-0002-9082-6644	YCCI Doris Duke Charitable Foundation: Fund to RetainClinical Scientists (FRCS)	YCCI Doris Duke Charitable Foundation: Fund to RetainClinical Scientists (FRCS)	YCCI Doris Duke Charitable Foundation: Fund to RetainClinical Scientists (FRCS). This publication was made possible by the Yale School of Medicine Office of Student Research	Aminawung JA, 2023, CANCER MED-US, V12, P15447, DOI 10.1002/cam4.6162; [Anonymous], 2018, ACHIEVING RURAL HLTH; [Anonymous], Prisons report series: Preliminary data release; [Anonymous], Jails report series: Preliminary data release; Binswanger IA, 2007, NEW ENGL J MED, V356, P157, DOI 10.1056/NEJMsa064115; Boch S, 2022, JMIR PEDIATR PARENT, V5, DOI 10.2196/33614; Browne CC, 2022, FRONT PSYCHIATRY, V13, DOI 10.3389/fpsyt.2022.934837; Cooper C, 2006, J TRAUMA, V61, P534, DOI 10.1097/01.ta.0000236576.81860.8c; Dumont DM, 2012, ANNU REV PUBL HEALTH, V33, P325, DOI 10.1146/annurev-publhealth-031811-124614; Eisenstein LG, 2020, J GEN INTERN MED, V35, P1328, DOI 10.1007/s11606-019-05216-y; Eswaran V, 2022, ACAD EMERG MED, V29, P606, DOI 10.1111/acem.14437; Fazel S, 2017, ADDICTION, V112, P1725, DOI 10.1111/add.13877; Frank Joseph W, 2014, Health Justice, V2, P6; Gumiel YB, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3462475; Hawks L, 2022, LANCET REG HEALTH-AM, V8, DOI 10.1016/j.lana.2021.100150; Li Yikuan, 2022, arXiv; Marshall K, 2023, ANN EMERG MED, V82, P713, DOI 10.1016/j.annemergmed.2023.07.023; Massoglia M, 2019, PUBLIC HEALTH REP, V134, p8S, DOI 10.1177/0033354919826563; Morenoff JD, 2014, ANNU REV SOCIOL, V40, P411, DOI 10.1146/annurev-soc-071811-145511; Nosrati E, 2021, SSM-POPUL HLTH, V15, DOI 10.1016/j.ssmph.2021.100827; Petersilia Joan., 2009, When Prisoners Come Home: Parole and Prisoner Reentry, Studies in Crime and Public Policy, DOI [https://doi.org/10.1093/acprof:oso/9780195160864.001.0001, DOI 10.1093/ACPROF:OSO/9780195160864.001.0001]; Redmond N, 2020, J URBAN HEALTH, V97, P105, DOI 10.1007/s11524-019-00382-0; Richman IB., 2023, J Natl Cancer Inst, V22; Shavit S, 2017, HEALTH AFFAIR, V36, P1006, DOI 10.1377/hlthaff.2017.0089; Sugarman OK, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0227968; Tong GY, 2023, BMC PUBLIC HEALTH, V23, DOI 10.1186/s12889-023-15997-x; US Census Bureau, Connecticut's Population Inched Up 0.9% Last Decade; Wang EA, 2019, MED CARE, V57, pS157, DOI 10.1097/MLR.0000000000001049; Wang Emily A, 2012, Am J Public Health, V102, pe22, DOI 10.2105/AJPH.2012.300894; Wang EA, 2011, JAMA-J AM MED ASSOC, V305, P1708, DOI 10.1001/jama.2011.532; Wildeman C, 2017, LANCET, V389, P1464, DOI 10.1016/S0140-6736(17)30259-3	31	0	0	1	1	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND		2059-8661		J CLIN TRANSL SCI	J. Clin. Transl. Sci.	MAR 11	2024	8	1							e53	10.1017/cts.2024.496	http://dx.doi.org/10.1017/cts.2024.496			10	Medicine, Research & Experimental	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine	MG0L8	38544748	Green Published, gold			2024-07-03	WOS:001192355200001
J	Jorapur, S; Srivastava, A; Kulkarni, S				Jorapur, Soham; Srivastava, Amisha; Kulkarni, Suyamindra			Evaluating the Usefulness of a Large Language Model as a Wholesome Tool for De Novo Polymerase Chain Reaction (PCR) Primer Design	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						monkeypox virus; large language models (llms); primer; chat gpt; molecular biology; pcr; diagnostics		This study aimed to assess the ability of language learning models (LLMs), specifically GPT-3.5 (Chat Generative Pre-trained Transformer 3.5) and GPT-4 (Chat Generative Pre-trained Transformer 3.5), in designing primers for diagnostic polymerase chain reaction (PCR) of the monkeypox virus (MPXV). Five primer pairs were generated by each LLM, and their thermodynamic properties and specificity were analysed post-hoc using commonly used software. The LLMs demonstrated ability in sequence generation and predicting melting temperatures (Tm), but their accuracy in predicting GC content was suboptimal, necessitating further investigation. Results indicated that, of the total primer pairs, only three designed by GPT-4 and two by GPT-3.5 could theoretically form a PCR product, but only one pair demonstrated suitable parameters for experimental validation. This preliminary exploration suggests that while LLMs have a potential in aiding primer design, their accuracy needs improvement to match current deterministic, rule -based tools used in the field. Consequently, manual intervention remains a crucial step in PCR primer design.	[Jorapur, Soham] Indian Inst Sci Educ & Res, Dept Biol Sci, Bhopal, India; [Srivastava, Amisha] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX USA; [Kulkarni, Suyamindra] Govt Karnataka, Karnataka Inst DNA Res KIDNAR, Dept Higher Educ, Dharwad, India	Indian Institute of Science Education & Research (IISER) - Bhopal; University of Texas System; University of Texas Dallas	Jorapur, S (corresponding author), Indian Inst Sci Educ & Res, Dept Biol Sci, Bhopal, India.	soham.jorapur@gmail.com		Jorapur, Soham/0000-0002-8316-3897				[Anonymous], 2023, BENCHLING BIOL SOFTW; [Anonymous], 2023, The Nobel Prize in Chemistry 1993: Kary B. Mullis; ARTIC Network, 2020, Zenodo, DOI 10.5281/ZENODO.4020380; Dieffenbach CWD., 2003, PCR Primer: A Laboratory Manual; Innis M.A., 1989, PCR protocols: A guide to methods and applications; Koressaar T, 2007, BIOINFORMATICS, V23, P1289, DOI 10.1093/bioinformatics/btm091; Koressaar T, 2018, BIOINFORMATICS, V34, P1937, DOI 10.1093/bioinformatics/bty036; OpenAI, 2023, CHATGPT; SAIKI RK, 1985, SCIENCE, V230, P1350, DOI 10.1126/science.2999980; Schick T, 2021, Arxiv, DOI arXiv:2009.07118; Untergasser A, 2012, NUCLEIC ACIDS RES, V40, DOI 10.1093/nar/gks596; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]	13	1	1	6	6	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	OCT 26	2023	15	10							e47711	10.7759/cureus.47711	http://dx.doi.org/10.7759/cureus.47711			6	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Z4ER3	38021866	gold, Green Published			2024-07-03	WOS:001111629000026
J	Polesie, S; Larkö, O				Polesie, Sam; Larko, Olle			Use of Large Language Models: Editorial Comments	ACTA DERMATO-VENEREOLOGICA			English	Editorial Material									[Polesie, Sam; Larko, Olle] Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Dermatol & Venereol, Gothenburg, Sweden; [Polesie, Sam] Sahlgrens Univ Hosp, Reg Vastra Gotaland, Dept Dermatol & Venereol, Gothenburg, Sweden	University of Gothenburg; Sahlgrenska University Hospital	Polesie, S (corresponding author), Univ Gothenburg, Inst Clin Sci, Sahlgrenska Acad, Dept Dermatol & Venereol, Gothenburg, Sweden.; Polesie, S (corresponding author), Sahlgrens Univ Hosp, Reg Vastra Gotaland, Dept Dermatol & Venereol, Gothenburg, Sweden.	sam.polesie@gu.se	Polesie, Sam/AAM-1294-2020	Polesie, Sam/0000-0002-5398-6200				[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; ChatGPT, about us; Reuters, 2023, about us; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879	4	7	7	1	5	ACTA DERMATO-VENEREOLOGICA	UPPSALA	TRADGARDSGATAN 14, UPPSALA, SE-753 09, SWEDEN	0001-5555	1651-2057		ACTA DERM-VENEREOL	Acta Derm.-Venereol.	FEB	2023	103									10.2340/actadv.v103.9593	http://dx.doi.org/10.2340/actadv.v103.9593			1	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	9E0QR	36794896	Green Published, gold			2024-07-03	WOS:000936500400015
J	Elek, A				Elek, Alperen			The Role of Large Language Models in Radiology Reporting	AMERICAN JOURNAL OF ROENTGENOLOGY			English	Letter									[Elek, Alperen] Ege Univ, Fac Med, Izmir, Turkiye	Ege University	Elek, A (corresponding author), Ege Univ, Fac Med, Izmir, Turkiye.	alperenelek13@gmail.com	Elek, Alperen/HPE-4224-2023	Elek, Alperen/0000-0001-5414-6548				Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Webson A, 2022, Arxiv, DOI arXiv:2109.01247; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771	4	0	0	7	7	AMER ROENTGEN RAY SOC	LEESBURG	44211 SLATESTONE CT, LEESBURG, VA USA	0361-803X	1546-3141		AM J ROENTGENOL	Am. J. Roentgenol.	NOV	2023	221	5					707	707		10.2214/AJR.23.29951	http://dx.doi.org/10.2214/AJR.23.29951			1	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	GK3I5	37703483				2024-07-03	WOS:001152520400033
C	Panchbhai, A; Pankanti, S			IEEE	Panchbhai, Anand; Pankanti, Smarana			Exploring Large Language Models in a Limited Resource Scenario	2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021)			English	Proceedings Paper	11th International Conference on Cloud Computing, Data Science and Engineering (Confluence)	JAN 28-29, 2021	Amity Univ, Amity  Sch Engn & Technol, ELECTR NETWORK	Amity Univ, Amity Sch Engn & Technol, Dept Comp Sci & Engn, Inst Elect & Elect Engineers, IEEE UP Sect	Amity Univ, Amity  Sch Engn & Technol	GPT-2; Sentiment-Analysis; Language-Models; Explainability; Limited-Resources	SENTIMENT ANALYSIS	Generative Pre-trained Transformers (GPT) have gained a lot of popularity in the domain of Natural Language Processing (NPL). Lately, GPTs have been fine-tuned for tasks like sentiment analysis and text summarization. As the number of tunable parameters increases with larger language models (like GPT-3), it becomes resource-heavy to fine-tune these models on commercially available personal computer systems. In addition to that, GPT-3 is only available through an API which makes it even harder to fine-tune it for a specific task. This makes these models less accessible to the general public and researchers. Alternative ways are required to better understand the nature of these language models and employ them for challenging NLP tasks without explicit fine-tuning. This study capitalizes on the raw capabilities of GPT-2, it proposes and proves the efficacy of one such system in the task of sentiment analysis without explicit fine-tuning. It also sheds light into the nature of such generative language models and shows how explainability can be exploited to achieve good results with minimum resources. It was observed that the proposed system does a good job of capturing the sentiment of a given text. It reached an accuracy of 82% on a part of the IMDB Data set of Movie Reviews. The system performed better with natural language prompt when compared to symbol-based syntactic prompts.	[Panchbhai, Anand; Pankanti, Smarana] Indian Inst Technol Bhilai, Dept Elect Engn & Comp Sci, Logy AI, Raipur, Madhya Pradesh, India	Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) Bhilai	Panchbhai, A (corresponding author), Indian Inst Technol Bhilai, Dept Elect Engn & Comp Sci, Logy AI, Raipur, Madhya Pradesh, India.	anandp@iitbhilai.ac.in; smaranas@iitbhilai.ac.in						Akbik A., 2018, P 27 INT C COMP LING, P1638; [Anonymous], 2014, P 2014 C EMP METH NA, DOI DOI 10.3115/V1/D14-1181; [Anonymous], 2011, P 49 ANN M ASS COMPU; Anthony L.F.W., 2020, CARBONTRACKER TRACKI; Arulkumaran K, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCCO'19 COMPANION), P314, DOI 10.1145/3319619.3321894; Azzouza N, 2020, ADV INTELL SYST, V1073, P428, DOI 10.1007/978-3-030-33582-3_41; Brown T., 2020, P 34 INT C NEUR INF, V33, P1877; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gilbert C., 2014, 8 INT C WEBL SOC MED 8 INT C WEBLOGS SOCI, V81, P82; Ginn Rachel., 2014, P 4 WORKSHOP BUILDIN, P1; Loria S., 2018, RELEASE 015, V2; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Muller M., 2020, ARXIV PREPRINT ARXIV; Myagmar B, 2019, IEEE ACCESS, V7, P163219, DOI 10.1109/ACCESS.2019.2952360; Myslín M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2534; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2019, LANGUAGE MODELS ARE, V1, P9; Salathé M, 2011, PLOS COMPUT BIOL, V7, DOI 10.1371/journal.pcbi.1002199; Sun C, 2019, LECT NOTES ARTIF INT, V11856, P194, DOI 10.1007/978-3-030-32381-3_16; Vaswani A, 2017, ADV NEUR IN, V30; Wang TY, 2020, IEEE ACCESS, V8, P138162, DOI 10.1109/ACCESS.2020.3012595; Wolf T., 2019, HUGG TRANSF STAT NAT; Yang Z., 2020, XLNET GEN AUTOREGRES; Zaharia Matei, 2016, ARXIV PREPRINT ARXIV; Zhang L, 2020, HEALTHCARE-BASEL, V8, DOI 10.3390/healthcare8030307; Zheng J., 2019, N ADV MULTIMEDIA UBI, P390	27	0	0	1	12	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-1451-7				2021							147	152		10.1109/Confluence51648.2021.9377081	http://dx.doi.org/10.1109/Confluence51648.2021.9377081			6	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BR8FX					2024-07-03	WOS:000671849000027
J	Cerf, VG				Cerf, Vinton G.			Large Language Models	COMMUNICATIONS OF THE ACM			English	Editorial Material									[Cerf, Vinton G.] Google, Mountain View, CA 94043 USA	Google Incorporated	Cerf, VG (corresponding author), Google, Mountain View, CA 94043 USA.								0	0	0	15	29	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0001-0782	1557-7317		COMMUN ACM	Commun. ACM	AUG	2023	66	8					7	7		10.1145/3606337	http://dx.doi.org/10.1145/3606337			1	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	O5WS1		Bronze			2024-07-03	WOS:001044515700002
J	Anguita, R; Makuloluwa, A; Hind, J; Wickham, L				Anguita, Rodrigo; Makuloluwa, Achini; Hind, Jennifer; Wickham, Louisa			Large language models in vitreoretinal surgery	EYE			English	Editorial Material									[Anguita, Rodrigo; Makuloluwa, Achini; Hind, Jennifer; Wickham, Louisa] Moorfields Eye Hosp NHS Fdn Trust, Vitreoretinal Unit, City Rd London, London EC1V 2PD, England; [Anguita, Rodrigo] Univ Hosp Bern, Inselspital, Dept Ophthalmol, Bern, Switzerland	University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; University of Bern; University Hospital of Bern	Anguita, R (corresponding author), Moorfields Eye Hosp NHS Fdn Trust, Vitreoretinal Unit, City Rd London, London EC1V 2PD, England.; Anguita, R (corresponding author), Univ Hosp Bern, Inselspital, Dept Ophthalmol, Bern, Switzerland.	rodrigoanguita@gmail.com		Hind, Jennifer/0000-0001-7671-004X; Wickham, Louisa/0000-0002-7430-2680				Anguita R, 2023, EYE, V37, P185, DOI 10.1038/s41433-022-02109-z; [Anonymous], 2023, LARG LANG MOD MED PO; Hanumunthadu D, 2022, EYE, V36, P627, DOI 10.1038/s41433-021-01510-4; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Michael LL, 2021, GATHERING STRENGTH G; Ruran HB, 2023, SEMIN OPHTHALMOL, V38, P498, DOI 10.1080/08820538.2023.2168492	6	2	2	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	0950-222X	1476-5454		EYE	Eye	MAR	2024	38	4					809	810		10.1038/s41433-023-02751-1	http://dx.doi.org/10.1038/s41433-023-02751-1		SEP 2023	2	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	PX1O5	37726334				2024-07-03	WOS:001069211000002
J	Vargas, DC; Katsamanis, N				Vargas, Diego Collarana; Katsamanis, Nassos			Large Language Models	ERCIM NEWS			English	Editorial Material									[Vargas, Diego Collarana] Diego Collarana Vargas, Fraunhofer FIT, Germany		Vargas, DC (corresponding author), Diego Collarana Vargas, Fraunhofer FIT, Germany.	diego.collarana.vargas@fit.fraunhofer.de; nkatsam@athenarc.gr							0	0	0	0	0	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					12	13						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500006
C	Chen, Z; Gao, QY; Bosselut, A; Sabharwal, A; Richardson, K		Rogers, A; Boyd-Graber, J; Okazaki, N		Chen, Zeming; Gao, Qiyue; Bosselut, Antoine; Sabharwal, Ashish; Richardson, Kyle			<i>DISCO</i>: Distilling Counterfactuals with Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Models trained with counterfactually augmented data learn representations of the causal structure of tasks, enabling robust generalization. However, high-quality counterfactual data is scarce for most tasks and not easily generated at scale. When crowdsourced, such data is typically limited in scale and diversity; when generated using supervised methods, it is computationally expensive to extend to new counterfactual dimensions. In this work, we introduce DISCO (DIStilled COunterfactual Data), a new method for automatically generating high-quality counterfactual data at scale. DISCO engineers prompts to generate phrasal perturbations with a large general language model. Then, a task-specific teacher model filters these generations to distill high-quality counterfactual data. While task-agnostic, we apply our pipeline to the task of natural language inference (NLI) and find that on challenging evaluations such as the NLI stress test, comparatively smaller student models trained with DISCO-generated counterfactuals are more robust (6% absolute) and generalize better across distributions (2%) compared to models trained without data augmentation. Furthermore, DISCO-augmented models are 10% more consistent between counterfactual pairs on three evaluation sets, demonstrating that DISCO-augmentation enables models to more reliably learn causal representations. Our repository are available at: https://github.com/eric11eca/disco	[Chen, Zeming; Bosselut, Antoine] Ecole Polytech Fed Lausanne, Nat Language Proc Lab, Lausanne, Switzerland; [Gao, Qiyue; Sabharwal, Ashish; Richardson, Kyle] Allen Inst AI, Seattle, WA USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne	Chen, Z (corresponding author), Ecole Polytech Fed Lausanne, Nat Language Proc Lab, Lausanne, Switzerland.	zeming.chen@epfl.ch; bertg@allenai.org; antoine.bosselut@epfl.ch; ashishs@allenai.org; kyler@allenai.org						Akbik Alan, 2019, P NAACL; Alvarez-Melis David, 2020, P NEURIPS; Belinkov Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P877; Bogin Ben, 2020, Findings of EMNLP; Bowman Samuel R, 2018, P NAACL; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du Mengnan, 2022, SHORTCUT LEARNING LA; Feder A, 2022, T ASSOC COMPUT LING, V10, P1138, DOI 10.1162/tacl_a_00511; Glockner M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P650; Gururangan Suchin, 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-2017; He PL, 2020, EMERG MARK FINANC TR, V56, P2198, DOI 10.1080/1540496X.2020.1785865; Heer Jeffrey, 2021, P ACL; Hinton G., 2015, ARXIV; Joshi N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3668; Kaushik Divyansh, 2019, P ICLR; Kaushik R, 2018, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON MOVEMENT AND COMPUTING (MOCO'18), DOI 10.1145/3212721.3212805; Khashabi Daniel, 2020, P EMNLP; Kingma D. P., 2017, ARXIV; Le Bras Ronan, 2020, P ICML; Liu Alisa, 2022, FINDINGS EMNLP; Liu Tianyu, 2020, P CONLL; Liu Tianyu, 2020, P LREC; Madaan Nishtha, 2021, P AAAI; Mahabadi Rabeeh Karimi, 2020, P ACL; McCoy R. Thomas, 2019, P ACL; Minervini Pasquale, 2018, P CONLL; Naik Aakanksha, 2018, P COLING; Nie YX, 2019, AAAI CONF ARTIF INTE, P6867; Nie Yixin, 2020, P ACL; Ouellette M, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3337725; Pavlick E, 2019, T ASSOC COMPUT LING, V7, P677, DOI 10.1162/tacl_a_00293; Poliak Adam, 2018, P 7 JOINT C LEX COMP, P180, DOI DOI 10.18653/V1/S18-2023; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Ross Alexis, 2022, P ACL; Swayamdipta Swabha, 2020, Dataset cartography: Mapping and diagnosing datasets with training dynamics; Thorne James, 2018, P NAACL; Trivedi A, 2020, ISOFT: PROCEEDINGS OF THE 13TH INNOVATIONS IN SOFTWARE ENGINEERING CONFERENCE, DOI 10.1145/3385032.3385050; Tsuchiya Masatoshi, 2018, P LREC; Wang Alex, 2018, P ICLR; Wang Alex, 2019, P NEURIPS 32, P32; Wang Haohan, 2019, WHAT WE SIMPLY SWAP; Wen Jiaxin, 2022, P EMNLP FIND; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Wu Yuxiang, 2022, P ACL; Xu Liang, 2020, P COLING; Zhang JC, 2019, CONFERENCE PROCEEDINGS OF 2019 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (IEEE ICSPCC 2019); Zhu Y., 2018, Texygen: A benchmarking platform for text generation models	49	3	3	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							5514	5528						15	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086804025
J	Katsadouros, E; Patrikakis, CZ; Hurlburt, G				Katsadouros, Evangelos; Patrikakis, Charalampos Z.; Hurlburt, George			Can Large Language Models Better Predict Software Vulnerability?	IT PROFESSIONAL			English	Editorial Material								The analysis of software for software vulnerability has matured over the years. In the beginning, linear approaches were tried to isolate known vulnerabilities via after-the-fact static analysis. As neural nets and machine learning became useful, more dynamic approaches were applied, It will be interesting to see what the new wave of Generative Artificial intelligence can contribute to the realm of assessing software vulnerabilities.	[Katsadouros, Evangelos] Univ West Attica, Egaleo 12241, Greece; [Patrikakis, Charalampos Z.] Univ West Attica, Comp Networks & Serv Res Lab, Egaleo 12241, Greece; [Hurlburt, George] STEMCorp, Tall Timbers, MD 20690 USA	University of West Attica; University of West Attica	Katsadouros, E (corresponding author), Univ West Attica, Egaleo 12241, Greece.	katsadouros.v@gmail.com; bpatr@uniwa.gr; gfhurlburt@gmail.com	Hurlburt, George/JUV-6040-2023; Patrikakis, Charalampos/U-2154-2018	Hurlburt, George/0000-0002-4829-3805; Patrikakis, Charalampos/0000-0003-1921-4466; Katsadouros, Evangelos/0000-0001-6095-1412				Cao SC, 2021, INFORM SOFTWARE TECH, V136, DOI 10.1016/j.infsof.2021.106576; Chakraborty S, 2020, Arxiv, DOI arXiv:2009.07235; Chan A, 2023, Arxiv, DOI [arXiv:2306.01754, 10.48550/arXiv.2306.01754]; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Fang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0225196; Fu M, 2022, IEEE WORK CONF MIN S, P608, DOI 10.1145/3524842.3528452; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Li RH, 2019, IEEE ACCESS, V7, P80079, DOI 10.1109/ACCESS.2019.2923227; Li Z, 2022, IEEE T DEPEND SECURE, V19, P2244, DOI 10.1109/TDSC.2021.3051525; Li Z, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23158; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Omar M, 2023, Arxiv, DOI [arXiv:2302.11773, 10.48550/arXiv.2302.11773]; Russell RL, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P757, DOI 10.1109/ICMLA.2018.00120; Wang HT, 2021, IEEE T INF FOREN SEC, V16, P1943, DOI 10.1109/TIFS.2020.3044773; Zhou YQ, 2019, Arxiv, DOI arXiv:1909.03496	15	0	0	2	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1520-9202	1941-045X		IT PROF	IT Prof.	MAY-JUN	2023	25	3					4	8		10.1109/MITP.2023.3284628	http://dx.doi.org/10.1109/MITP.2023.3284628			5	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Telecommunications	L8BQ5		Bronze			2024-07-03	WOS:001025462600001
J	Sirakawin, C; Lin, DF; Zhou, ZY; Wang, XX; Kelleher, R; Huang, SY; Long, WM; Pires-daSilva, A; Liu, Y; Wang, JJ; Vinnikov, IA				Sirakawin, Chaweewan; Lin, Dongfa; Zhou, Ziyue; Wang, Xiaoxin; Kelleher, Rhianne; Huang, Shangyuan; Long, Weimiao; Pires-daSilva, Andre; Liu, Yu; Wang, Jingjing; Vinnikov, Ilya A.			SKN-1/NRF2 upregulation by vitamin A is conserved from nematodes to mammals and is critical for lifespan extension in <i>Caenorhabditis elegans</i>	AGING CELL			English	Article						aging; C. elegans; SKN-1; vitamin A	OXIDATIVE STRESS; INFLAMMATORY NETWORKS; C. ELEGANS; AGE; POPULATION; LIPOFUSCIN; LONGEVITY; CANCER; CELLS; DEFICIENCY	Vitamin A (VA) is a micronutrient essential for the physiology of many organisms, but its role in longevity and age-related diseases remains unclear. In this work, we used Caenorhabditis elegans to study the impact of various bioactive compounds on lifespan. We demonstrate that VA extends lifespan and reduces lipofuscin and fat accumulation while increasing resistance to heat and oxidative stress. This resistance can be attributed to high levels of detoxifying enzymes called glutathione S-transferases, induced by the transcription factor skinhead-1 (SKN-1). Notably, VA upregulated the transcript levels of skn-1 or its mammalian ortholog NRF2 in both C. elegans, human cells, and liver tissues of mice. Moreover, the loss-of-function genetic models demonstrated a critical involvement of the SKN-1 pathway in longevity extension by VA. Our study thus provides novel insights into the molecular mechanism of anti-aging and anti-oxidative effects of VA, suggesting that this micronutrient could be used for the prevention and/or treatment of age-related disorders.	[Sirakawin, Chaweewan; Lin, Dongfa; Zhou, Ziyue; Huang, Shangyuan; Long, Weimiao; Liu, Yu; Vinnikov, Ilya A.] Shanghai Jiao Tong Univ, Sheng Yushou Ctr Cell Biol & Immunol, Sch Life Sci & Biotechnol, Dept Genet & Dev Biol,Lab Mol Neurobiol, Shanghai, Peoples R China; [Lin, Dongfa] Jilin Univ, Sch Life Sci, Key Lab Mol Enzymol & Engn, Changchun, Peoples R China; [Wang, Xiaoxin; Wang, Jingjing] Shanghai Jiao Tong Univ, Shanghai Gen Hosp, Inst Translat Med, Shanghai Key Lab Pancreat Dis,Sch Med, Shanghai, Peoples R China; [Kelleher, Rhianne; Pires-daSilva, Andre] Univ Warwick, Sch Life Sci, Coventry, England	Shanghai Jiao Tong University; Jilin University; Shanghai Jiao Tong University; University of Warwick	Vinnikov, IA (corresponding author), Shanghai Jiao Tong Univ, Sheng Yushou Ctr Cell Biol & Immunol, Sch Life Sci & Biotechnol, Dept Genet & Dev Biol,Lab Mol Neurobiol, Shanghai, Peoples R China.; Wang, JJ (corresponding author), Shanghai Jiao Tong Univ, Shanghai Gen Hosp, Inst Translat Med, Shanghai Key Lab Pancreat Dis,Sch Med, Shanghai, Peoples R China.	wangjingjing6891@163.com; i.vinnikov@sjtu.edu.cn			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	We thank Liping Zhao and Chenhong Zhang for their technical and intellectual support. Large language models GPT3.5/4 were instrumental for refining the early versions of the manuscript.	Afri M, 2004, CHEM PHYS LIPIDS, V131, P123, DOI 10.1016/j.chemphyslip.2004.04.006; Ahima RS, 2009, NAT MED, V15, P996, DOI 10.1038/nm0909-996; Ahmed FU, 2000, J HEALTH POPUL NUTR, V18, P119; An JH, 2003, GENE DEV, V17, P1882, DOI 10.1101/gad.1107803; Arantes-Oliveira N, 2002, SCIENCE, V295, P502, DOI 10.1126/science.1065768; Arsenyadis F, 2022, NUTRIENTS, V14, DOI 10.3390/nu14091827; Baar MP, 2017, CELL, V169, P132, DOI 10.1016/j.cell.2017.02.031; Bales CW, 2002, ANNU REV NUTR, V22, P309, DOI 10.1146/annurev.nutr.22.010402.102715; Bar-Ziv R, 2020, JOVE-J VIS EXP, DOI 10.3791/61001; Beckman KB, 1998, PHYSIOL REV, V78, P547, DOI 10.1152/physrev.1998.78.2.547; Berg J, 2020, INT J TRYPTOPHAN RES, V13, DOI 10.1177/1178646920981946; Bruunsgaard H, 2003, CLIN EXP IMMUNOL, V132, P24, DOI 10.1046/j.1365-2249.2003.02137.x; Bulua AC, 2011, J EXP MED, V208, P519, DOI 10.1084/jem.20102049; Chen K, 2009, WORLD J PEDIATR, V5, P275, DOI 10.1007/s12519-009-0052-z; Chen W, 2013, J PHARM PHARMACOL, V65, P682, DOI 10.1111/jphp.12023; CLOKEY GV, 1986, MECH AGEING DEV, V35, P79, DOI 10.1016/0047-6374(86)90068-0; D'Souza R. M., 2002, COCHRANE DB SYST REV; Das BN, 2013, OXID MED CELL LONGEV, V2013, DOI 10.1155/2013/839409; de Magalhaes JP, 2016, AGING-US, V8, P1578, DOI 10.18632/aging.101021; DEAN RT, 1987, BIOCHEM BIOPH RES CO, V148, P1277, DOI 10.1016/S0006-291X(87)80271-1; Detienne Giel, 2016, Worm, V5, pe1230585, DOI 10.1080/21624054.2016.1230585; Diniz A da S, 2000, J Pediatr (Rio J), V76 Suppl 3, pS311; Dues DJ, 2016, AGING-US, V8, P777, DOI 10.18632/aging.100939; Ferrucci L, 2018, NAT REV CARDIOL, V15, P505, DOI 10.1038/s41569-018-0064-2; Finkel T, 2000, NATURE, V408, P239, DOI 10.1038/35041687; Finkin S, 2015, NAT IMMUNOL, V16, P1235, DOI 10.1038/ni.3290; Fontaine KR, 2003, JAMA-J AM MED ASSOC, V289, P187, DOI 10.1001/jama.289.2.187; Freund A, 2010, TRENDS MOL MED, V16, P238, DOI 10.1016/j.molmed.2010.03.003; Gilgun-Sherki Y, 2001, NEUROPHARMACOLOGY, V40, P959, DOI 10.1016/S0028-3908(01)00019-3; Giugliano D, 2006, J AM COLL CARDIOL, V48, P677, DOI 10.1016/j.jacc.2006.03.052; Gordon CJ, 2011, EXP GERONTOL, V46, P953, DOI 10.1016/j.exger.2011.07.006; Greten FR, 2019, IMMUNITY, V51, P27, DOI 10.1016/j.immuni.2019.06.025; Grootswagers P, 2021, AM J CLIN NUTR, V113, P781, DOI 10.1093/ajcn/nqaa368; Han SK, 2016, ONCOTARGET, V7, P56147, DOI 10.18632/oncotarget.11269; Holmstrup M, 2010, SCI TOTAL ENVIRON, V408, P3746, DOI 10.1016/j.scitotenv.2009.10.067; Huang C, 2004, P NATL ACAD SCI USA, V101, P8084, DOI 10.1073/pnas.0400848101; HUSSAIN A, 1995, B WORLD HEALTH ORGAN, V73, P469; Imdad A, 2022, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008524.pub4; Inoue H, 2005, GENE DEV, V19, P2278, DOI 10.1101/gad.1324805; Ishii N, 2004, MECH AGEING DEV, V125, P41, DOI 10.1016/j.mad.2003.10.002; Jain AP, 2015, EUR REV MED PHARMACO, V19, P441; Rodríguez-Palero MJ, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21964-z; Kalache A, 2019, EUR J NUTR, V58, P1, DOI 10.1007/s00394-019-02027-z; Kang JH, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-02485-8; Kaur Damanpreet, 2019, Curr Aging Sci, V12, P15, DOI 10.2174/1874609812666190521110548; Kennedy CJ, 1995, EYE, V9, P763, DOI 10.1038/eye.1995.192; KENNEY WL, 1987, SPORTS MED, V4, P446, DOI 10.2165/00007256-198704060-00004; Khan SS, 2018, JAMA CARDIOL, V3, P280, DOI 10.1001/jamacardio.2018.0022; Lavie CJ, 2013, CIRCULATION, V128, P2404, DOI 10.1161/CIRCULATIONAHA.113.002902; Li X, 2023, SIGNAL TRANSDUCT TAR, V8, DOI 10.1038/s41392-023-01502-8; Liguori I, 2018, CLIN INTERV AGING, V13, P757, DOI 10.2147/CIA.S158513; LITHGOW GJ, 1995, P NATL ACAD SCI USA, V92, P7540, DOI 10.1073/pnas.92.16.7540; Liu YY, 2019, MOL ONCOL, V13, P2460, DOI 10.1002/1878-0261.12577; Lopreite M, 2017, HEALTH POLICY, V121, P663, DOI 10.1016/j.healthpol.2017.03.015; Lu DZ, 2021, CELL BIOCHEM BIOPHYS, V79, P239, DOI 10.1007/s12013-020-00959-6; Margie O, 2013, JOVE-J VIS EXP, DOI 10.3791/50069; MASSIE HR, 1993, EXP GERONTOL, V28, P601, DOI 10.1016/0531-5565(93)90049-J; Mayo-Wilson E, 2011, BMJ-BRIT MED J, V343, DOI 10.1136/bmj.d5094; McCullough FSW, 1999, P NUTR SOC, V58, P289, DOI 10.1017/S0029665199000403; Mittal M, 2014, ANTIOXID REDOX SIGN, V20, P1126, DOI 10.1089/ars.2012.5149; Newman AB, 2001, J AM GERIATR SOC, V49, P1309, DOI 10.1046/j.1532-5415.2001.49258.x; Nguyen T, 2009, J BIOL CHEM, V284, P13291, DOI 10.1074/jbc.R900010200; Niccoli T, 2012, CURR BIOL, V22, pR741, DOI 10.1016/j.cub.2012.07.024; O'Rourke EJ, 2013, GENE DEV, V27, P429, DOI 10.1101/gad.205294.112; Oliveira RP, 2009, AGING CELL, V8, P524, DOI 10.1111/j.1474-9726.2009.00501.x; Palikaras K, 2017, J LIPID RES, V58, P72, DOI 10.1194/jlr.M069385; Papp D, 2012, PLOS PATHOG, V8, DOI 10.1371/journal.ppat.1002673; Park SK, 2009, AGING CELL, V8, P258, DOI 10.1111/j.1474-9726.2009.00473.x; Peeters A, 2003, ANN INTERN MED, V138, P24, DOI 10.7326/0003-4819-138-1-200301070-00008; Pham-Huy L A., 2008, International Journal of Biomedical Science, V4, P89, DOI DOI 10.59566/IJBS.2008.4089; Pincus Z, 2016, AGING-US, V8, P889, DOI 10.18632/aging.100936; Piper MDW, 2008, CELL METAB, V8, P99, DOI 10.1016/j.cmet.2008.06.012; Polder JJ, 2002, EUR J PUBLIC HEALTH, V12, P57, DOI 10.1093/eurpub/12.1.57; Qi YJ, 2016, EUR REV MED PHARMACO, V20, P5009; Reuter S, 2010, FREE RADICAL BIO MED, V49, P1603, DOI 10.1016/j.freeradbiomed.2010.09.006; Rizvi Saliha, 2014, Sultan Qaboos Univ Med J, V14, pe157; Romero A, 2019, AGING CELL, V18, DOI 10.1111/acel.12913; Ross SA, 2000, PHYSIOL REV, V80, P1021, DOI 10.1152/physrev.2000.80.3.1021; Schneider CA, 2012, NAT METHODS, V9, P671, DOI 10.1038/nmeth.2089; Shaw AC, 2013, NAT REV IMMUNOL, V13, P875, DOI 10.1038/nri3547; Shen PY, 2018, CRIT REV FOOD SCI, V58, P741, DOI 10.1080/10408398.2016.1220914; Singh P, 2008, HEPATOLOGY, V47, P1680, DOI 10.1002/hep.22224; Singhal SS, 2015, TOXICOL APPL PHARM, V289, P361, DOI 10.1016/j.taap.2015.10.006; Slimen IB, 2014, INT J HYPERTHER, V30, P513, DOI 10.3109/02656736.2014.971446; Sommer A, 2008, J NUTR, V138, P1835, DOI 10.1093/jn/138.10.1835; Stevens GA, 2015, LANCET GLOB HEALTH, V3, pE528, DOI 10.1016/S2214-109X(15)00039-X; Tam BT, 2020, OBES REV, V21, DOI 10.1111/obr.12991; Terman A, 2006, ANTIOXID REDOX SIGN, V8, P197, DOI 10.1089/ars.2006.8.197; Terman A, 1998, APMIS, V106, P265, DOI 10.1111/j.1699-0463.1998.tb01346.x; Terman A, 2004, ANN NY ACAD SCI, V1019, P70, DOI 10.1196/annals.1297.015; Thomas DR, 2006, CLIN INTERV AGING, V1, P81, DOI 10.2147/ciia.2006.1.1.81; Van Gilst MR, 2005, PLOS BIOL, V3, P301, DOI 10.1371/journal.pbio.0030053; Vasto S, 2007, MECH AGEING DEV, V128, P83, DOI 10.1016/j.mad.2006.11.015; Wahlby C, 2014, METHODS, V68, P492, DOI 10.1016/j.ymeth.2014.04.017; Wang Guiyang, 2014, Oxid Med Cell Longev, V2014, P273692, DOI 10.1155/2014/273692; Wang X, 2020, GENES NUTR, V15, DOI 10.1186/s12263-020-0659-1; WEINDRUCH R, 1986, J NUTR, V116, P641, DOI 10.1093/jn/116.4.641; Weinstein SJ, 2015, INT J CANCER, V136, pE654, DOI 10.1002/ijc.29157; Wu ZY, 2019, CELL METAB, V29, P1192, DOI 10.1016/j.cmet.2019.02.013; Zhang YQ, 2015, ARCH BIOCHEM BIOPHYS, V576, P39, DOI 10.1016/j.abb.2014.12.018; Zhao F, 2009, FREE RADICAL BIO MED, V47, P867, DOI 10.1016/j.freeradbiomed.2009.06.029; Zhou HP, 2020, J INFLAMM RES, V13, P1, DOI 10.2147/JIR.S229691; Zhou TF, 2016, AM J PHYSIOL-CELL PH, V311, pC572, DOI 10.1152/ajpcell.00093.2016	103	1	1	20	22	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1474-9718	1474-9726		AGING CELL	Aging Cell	MAR	2024	23	3								10.1111/acel.14064	http://dx.doi.org/10.1111/acel.14064		DEC 2023	14	Cell Biology; Geriatrics & Gerontology	Science Citation Index Expanded (SCI-EXPANDED)	Cell Biology; Geriatrics & Gerontology	KU9M6	38100161	Green Published			2024-07-03	WOS:001126153200001
J	Denning, PJ				Denning, Peter J.			The Smallness of Large Language Models	COMMUNICATIONS OF THE ACM			English	Editorial Material									[Denning, Peter J.] US Navy, Postgrad Sch Monterey, Comp Sci, Monterey, CA 93940 USA		Denning, PJ (corresponding author), US Navy, Postgrad Sch Monterey, Comp Sci, Monterey, CA 93940 USA.	pjd@nps.edu							0	0	0	40	41	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0001-0782	1557-7317		COMMUN ACM	Commun. ACM	SEP	2023	66	9					24	27		10.1145/3608966	http://dx.doi.org/10.1145/3608966			4	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Q7CI8					2024-07-03	WOS:001059061800009
J	Carlà, MM; Gambini, G; Baldascino, A; Boselli, F; Giannuzzi, F; Margollicci, F; Rizzo, S				Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Boselli, Francesco; Giannuzzi, Federico; Margollicci, Fabio; Rizzo, Stanislao			Large language models as assistance for glaucoma surgical cases: a ChatGPT vs. Google Gemini comparison	GRAEFES ARCHIVE FOR CLINICAL AND EXPERIMENTAL OPHTHALMOLOGY			English	Article; Early Access						Large language models (LLM); ChatGPT; Google Gemini; Google Bard; Glaucoma; Artificial intelligence (AI); Glaucoma surgery	OPEN-ANGLE GLAUCOMA	Purpose The aim of this study was to define the capability of ChatGPT-4 and Google Gemini in analyzing detailed glaucoma case descriptions and suggesting an accurate surgical plan.Methods Retrospective analysis of 60 medical records of surgical glaucoma was divided into "ordinary" (n = 40) and "challenging" (n = 20) scenarios. Case descriptions were entered into ChatGPT and Bard's interfaces with the question "What kind of surgery would you perform?" and repeated three times to analyze the answers' consistency. After collecting the answers, we assessed the level of agreement with the unified opinion of three glaucoma surgeons. Moreover, we graded the quality of the responses with scores from 1 (poor quality) to 5 (excellent quality), according to the Global Quality Score (GQS) and compared the results.Results ChatGPT surgical choice was consistent with those of glaucoma specialists in 35/60 cases (58%), compared to 19/60 (32%) of Gemini (p = 0.0001). Gemini was not able to complete the task in 16 cases (27%). Trabeculectomy was the most frequent choice for both chatbots (53% and 50% for ChatGPT and Gemini, respectively). In "challenging" cases, ChatGPT agreed with specialists in 9/20 choices (45%), outperforming Google Gemini performances (4/20, 20%). Overall, GQS scores were 3.5 +/- 1.2 and 2.1 +/- 1.5 for ChatGPT and Gemini (p = 0.002). This difference was even more marked if focusing only on "challenging" cases (1.5 +/- 1.4 vs. 3.0 +/- 1.5, p = 0.001).Conclusion ChatGPT-4 showed a good analysis performance for glaucoma surgical cases, either ordinary or challenging. On the other side, Google Gemini showed strong limitations in this setting, presenting high rates of unprecise or missed answers.	[Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Boselli, Francesco; Giannuzzi, Federico; Margollicci, Fabio; Rizzo, Stanislao] Fdn Policlin Univ A Gemelli, Ophthalmol Dept, IRCCS, I-00168 Rome, Italy; [Carla, Matteo Mario; Gambini, Gloria; Baldascino, Antonio; Boselli, Francesco; Giannuzzi, Federico; Margollicci, Fabio; Rizzo, Stanislao] Univ Cattolica Sacro Cuore, Ophthalmol Dept, Largo A Gemelli 8, Rome, Italy	Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli; Catholic University of the Sacred Heart; IRCCS Policlinico Gemelli	Carlà, MM (corresponding author), Fdn Policlin Univ A Gemelli, Ophthalmol Dept, IRCCS, I-00168 Rome, Italy.; Carlà, MM (corresponding author), Univ Cattolica Sacro Cuore, Ophthalmol Dept, Largo A Gemelli 8, Rome, Italy.	mm.carla94@gmail.com		Carla, Matteo Mario/0000-0003-2979-1638	Universit Cattolica del Sacro Cuore	Universit Cattolica del Sacro Cuore	None.	Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Alser M, 2023, Am J Med Open, V9, P1; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bernard A, 2007, AM J GASTROENTEROL, V102, P2070, DOI 10.1111/j.1572-0241.2007.01325.x; Bovee CE, 2017, SEMIN OPHTHALMOL, V32, P91, DOI 10.1080/08820538.2016.1228393; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlà MM, 2024, BRIT J OPHTHALMOL, DOI 10.1136/bjo-2023-325143; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; Fisher S, 2022, BMC PUBLIC HEALTH, V22, DOI 10.1186/s12889-022-14422-z; Gan RK, 2024, AM J EMERG MED, V75, P72, DOI 10.1016/j.ajem.2023.10.034; Jonas JB, 2017, LANCET, V390, P2183, DOI 10.1016/S0140-6736(17)31469-1; Kianian R, 2024, OPHTHALMOL RETINA, V8, P195, DOI 10.1016/j.oret.2023.09.008; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Le A, 2003, INVEST OPHTH VIS SCI, V44, P3783, DOI 10.1167/iovs.03-0077; Marks JR, 2012, EYE, V26, P853, DOI 10.1038/eye.2012.58; Medeiros FA, 2019, OPHTHALMOLOGY, V126, P513, DOI 10.1016/j.ophtha.2018.12.033; Megevand GS, 2021, PROG RETIN EYE RES, V81, DOI 10.1016/j.preteyeres.2020.100879; Miglior S, 2007, OPHTHALMOLOGY, V114, P3, DOI 10.1016/j.ophtha.2006.05.075; Nath S, 2022, BRIT J OPHTHALMOL, V106, P889, DOI 10.1136/bjophthalmol-2022-321141; OpenAI, 2023, Gpt-4 is openai's most advanced system, producing safer and more useful responses; Ozdemir S., 2023, Quick Start Guide to Large Language Models: Strategies and Best Practices for Using ChatGPT and Other LLMs; Pichai S, 2023, Introducing gemini: Our largest and most capable ai model; Pryss R, 2019, STUD NEUROSCI, P249, DOI 10.1007/978-3-030-31620-4_16; Radford A, 2021, PR MACH LEARN RES, V139; Ren LY, 2019, The Journal of the Canadian Health Libraries Association= Journal de l'Association des Bibliotheques de la Sante du Canada, V40, P63, DOI DOI 10.29173/JCHLA29418; Siad S, 2023, AI, V1, P1; Singe SM, 2023, INT J ATHL THER TRAI, V28, P308, DOI 10.1123/ijatt.2022-0010; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Team G, 2024, Bard becomes Gemini: try Ultra 1.0 and a new mobile app today; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Yousefi S, 2023, J OPHTHAL VIS RES, V18, P97, DOI 10.18502/jovr.v18i1.12730; Yousefi S, 2022, OPHTHALMOLOGY, V129, P1402, DOI 10.1016/j.ophtha.2022.07.001; Zagabathuni Y., 2022, Int J, V10, P195	36	1	1	3	3	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0721-832X	1435-702X		GRAEF ARCH CLIN EXP	Graefes Arch. Clin. Exp. Ophthalmol.	2024 APR 4	2024										10.1007/s00417-024-06470-5	http://dx.doi.org/10.1007/s00417-024-06470-5		APR 2024	15	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	MY0T4	38573349	hybrid			2024-07-03	WOS:001197086100003
J	Cheung, BH; Co, MT				Cheung, Billy H. H.; Co, Michael T. H.			Large language models: implications of rapid evolution in medicine	HONG KONG MEDICAL JOURNAL			English	Editorial Material							HOSPITAL CARDIAC-ARREST		[Cheung, Billy H. H.; Co, Michael T. H.] Univ Hong Kong, Li Ka Shing Fac Med, Sch Clin Med, Dept Surg, Hong Kong, Peoples R China	University of Hong Kong	Co, MT (corresponding author), Univ Hong Kong, Li Ka Shing Fac Med, Sch Clin Med, Dept Surg, Hong Kong, Peoples R China.	mcth@hku.hk		Cheung, Billy Ho Hung/0000-0002-8843-7893; CO, MICHAEL/0000-0002-1705-051X				Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Belohlavek J, 2022, JAMA-J AM MED ASSOC, V327, P737, DOI 10.1001/jama.2022.1025; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Cheung BHH, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0290691; Grigorian A, 2023, JAMA SURG, V158, P1220, DOI 10.1001/jamasurg.2023.3875; Medenilla A., 2023, PLoS Digital Health, V2; Mok A., BUSINESS INSIDER; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; OpenAI, SUPP COUNTR TERR; OpenAI, ChatGPT plugins; OpenAI, ARXIV; OpenAI, GPT 4; OpenAI, Introducing ChatGPT; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04473-y; Shea YF, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.25000; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Suverein MM, 2023, NEW ENGL J MED, V388, P299, DOI 10.1056/NEJMoa2204511; Yannopoulos D, 2020, LANCET, V396, P1807, DOI 10.1016/S0140-6736(20)32338-2	21	0	0	5	6	HONG KONG ACAD MEDICINE PRESS	HONG KONG	9/F/, ROOM 901, 99 WONG CHUK HANG RD, ABERDEEN, HONG KONG, 00000, PEOPLES R CHINA	1024-2708			HONG KONG MED J	Hong Kong Med. J.	DEC	2023	29	6					557	560		10.12809/hkmj2310890	http://dx.doi.org/10.12809/hkmj2310890		DEC 2023	4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	DQ9H1	38073144	gold			2024-07-03	WOS:001124630600001
J	Azamfirei, R; Kudchadkar, SR; Fackler, J				Azamfirei, Razvan; Kudchadkar, Sapna R.; Fackler, James			Large language models and the perils of their hallucinations	CRITICAL CARE			English	Letter									[Azamfirei, Razvan; Kudchadkar, Sapna R.; Fackler, James] Johns Hopkins Univ, Sch Med, Dept Anesthesiol & Crit Care Med, Baltimore, MD 21218 USA; [Kudchadkar, Sapna R.; Fackler, James] Johns Hopkins Univ, Sch Med, Dept Pediat, Baltimore, MD USA	Johns Hopkins University; Johns Hopkins University	Azamfirei, R (corresponding author), Johns Hopkins Univ, Sch Med, Dept Anesthesiol & Crit Care Med, Baltimore, MD 21218 USA.	razvan@jhmi.edu	Azamfirei, Razvan/AAD-2899-2019	Azamfirei, Razvan/0000-0003-3301-0566				Belohlavek J, 2022, JAMA-J AM MED ASSOC, V327, P737, DOI 10.1001/jama.2022.1025; OpenAI, 2023, ChatGPT General FAQ; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Schulman J, 2022, Introducing chatgpt; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388	5	49	52	15	24	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1364-8535	1466-609X		CRIT CARE	Crit. Care	MAR 21	2023	27	1							120	10.1186/s13054-023-04393-x	http://dx.doi.org/10.1186/s13054-023-04393-x			2	Critical Care Medicine	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	A7SI2	36945051	gold, Green Published			2024-07-03	WOS:000957076600001
J	Du, MN; He, FX; Zou, N; Tao, DC; Hu, X				Du, Mengnan; He, Fengxiang; Zou, Na; Tao, Dacheng; Hu, Xia			Shortcut Learning of Large Language Models in Natural Language Understanding	COMMUNICATIONS OF THE ACM			English	Article									[Du, Mengnan] New Jersey Inst Technol, Dept Data Sci, Newark, NJ 07102 USA; [He, Fengxiang] Univ Edinburgh, Sch Informat, Edinburgh, Scotland; [Zou, Na] Texas A&M Univ, Engn Technol & Ind Distribut, College Stn, TX USA; [Tao, Dacheng] Univ Sydney, Comp Sci, Sydney, Australia; [Hu, Xia] Rice Univ, Comp Sci, Houston, TX USA	New Jersey Institute of Technology; University of Edinburgh; Texas A&M University System; Texas A&M University College Station; University of Sydney; Rice University	Du, MN (corresponding author), New Jersey Inst Technol, Dept Data Sci, Newark, NJ 07102 USA.							Arjovsky M, 2020, Arxiv, DOI arXiv:1907.02893; Bhargava P., 2021, P 2 WORKSH INS NEG R; Branco R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1504; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S., 2021, Advances in Neural Information Processing Systems; Choi S, 2022, AAAI CONF ARTIF INTE, P10526; Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4069; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Du M, 2023, P 17 ANN M EUR CHAPT; Du MN, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P915; Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55; Gururangan Suchin, 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-2017; Han X., 2020, P 58 ANN M ASS COMP; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Ko M, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1109; Lai Y, 2021, ACL Findings; Liang YX, 2021, LECT NOTES COMPUT SC, V12895, P448, DOI 10.1007/978-3-030-86383-8_36; Liu F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6274; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; McCoy RT, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3428; Mendelson M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1545; Michalewski H, 2022, DEEP LEARN COD WORKS; Morwani D, 2023, Arxiv, DOI arXiv:2302.00457; Niven T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4658; Pezeshkpour Pouya, 2021, arXiv; Pham TM, 2021, Arxiv, DOI arXiv:2012.15180; Prasad G., 2021, P 4 BLACKB NLP WORKS; Qi F., P 2021 C EMP METH NA; Raffel C, 2020, J MACH LEARN RES, V21; Rashid A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1062; Robinson J., 2021, Can contrastive learning avoid shortcut solutions?, V34, P4974; Schuster T, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3419; Sen P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P2429; Shah H., 2020, Advances in Neural Information Processing Systems; Shi Y, P 2022 INT C LEARN R; Si CL, 2023, Arxiv, DOI arXiv:2210.09150; Si CL, 2019, Arxiv, DOI arXiv:1910.12391; Sinha K., 2021, Empirical Methods in Natural Language Processing; Stacey J, 2022, AAAI CONF ARTIF INTE, P11349; Stacey Joe, 2020, Empirical Methods in Natural Language Processing (EMNLP).; Sundararajan M., P 2017 INT C MACH LE; Teney D, 2020, Arxiv, DOI arXiv:2002.11894; Tu Lifu, 2020, Transactions of the Association for Computational Linguistics (TACL).; Utama P.A., 2021, Empirical Methods in Natural Language Processing; Utama Prasetya Ajie, 2020, Empirical Methods in Natural Language Processing (EMNLP).; Vardi G, 2022, Arxiv, DOI arXiv:2202.04347; Wang B., 2021, P 35 C NEUR INF PROC, P1; Webson A, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2300; Wei Jason, 2022, ADV NEURAL INFORM PR; Yang JF, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P528; Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93; Zhao TZ, 2021, PR MACH LEARN RES, V139	52	2	2	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	0001-0782	1557-7317		COMMUN ACM	Commun. ACM	JAN	2024	67	1					110	120		10.1145/3596490	http://dx.doi.org/10.1145/3596490			11	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IP9Q7		Green Submitted, Bronze			2024-07-03	WOS:001167655100024
J	Bian, C; Duan, ZY; Hao, YQ; Yang, SK; Feng, JL				Bian, Chong; Duan, Zhiyu; Hao, Yaqian; Yang, Shunkun; Feng, Junlan			Exploring large language model for generic and robust state-of-charge estimation of Li-ion batteries: A mixed prompt learning method	ENERGY			English	Article						Large language model; Li -ion batteries; Prompt; State-of-charge estimation	GATED RECURRENT UNIT; OPEN-CIRCUIT VOLTAGE	State-of-charge (SOC) estimation is important to ensure safe functioning of Li-ion batteries (LIBs). However, distinct measurements, harsh temperatures, and dynamic operations pose challenges in estimating intricate SOC changes of multiple LIBs with one estimator. Hence, this paper proposes a novel mixed prompt learning method to explore a large-scale pretrained language model (PLM) for SOC estimation. A new hard prompt generator is proposed to translate LIB data into instruction and answer text, eliciting the inherent representational capability of PLM to jointly learn the sequential patterns and contextual semantics of measurements through language modeling for accurate SOC estimation. A new soft prompt adapter is proposed to encode task-specific information of different LIBs into a small set of independent vectors, ensuring PLM adaptation with minimal parameters while maintaining good generalization. By integrating soft prompt vectors along the forward propagation, the hidden states of PLM are dynamically regulated to characterize volatile and variable SOC for robust estimation. Extensive experiments show that by leveraging mixed hard-soft prompts, PLM can make accurate, generic, and robust estimates for multiple LIBs simultaneously in subzero temperature, charge-pausedischarge, and low-capacity discharge scenarios, with the average MAE, RMSE, and MAX of all tasks as low as 1.20 %, 1.51 %, and 5.29 %, respectively.	[Bian, Chong; Hao, Yaqian; Feng, Junlan] China Mobile Res Inst, Artificial Intelligence & Intelligent Operat Ctr, Beijing 100053, Peoples R China; [Duan, Zhiyu; Yang, Shunkun] Beihang Univ, Sch Reliabil & Syst Engn, Beijing 100191, Peoples R China	China Mobile; Beihang University	Yang, SK (corresponding author), Beihang Univ, Sch Reliabil & Syst Engn, Beijing 100191, Peoples R China.	ysk@buaa.edu.cn; fengjunlan@chinamobile.com						Bian C, 2022, APPL SOFT COMPUT, V116, DOI 10.1016/j.asoc.2021.108401; Bian C, 2020, ENERGY, V191, DOI 10.1016/j.energy.2019.116538; Bian C, 2020, J POWER SOURCES, V449, DOI 10.1016/j.jpowsour.2019.227558; Chemali E, 2018, J POWER SOURCES, V400, P242, DOI 10.1016/j.jpowsour.2018.06.104; Chen L, 2023, IEEE Trans Transp Electrific; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fatouros G, 2023, MACH LEARN APPL, V14, DOI 10.1016/j.mlwa.2023.100508; Gong LL, 2022, J ENERGY STORAGE, V55, DOI 10.1016/j.est.2022.105720; Gu JD, 2023, Arxiv, DOI arXiv:2307.12980; Guo SS, 2023, ENERGY, V263, DOI 10.1016/j.energy.2022.125872; Hannan MA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98915-8; Hannan MA, 2021, IEEE T POWER ELECTR, V36, P7349, DOI 10.1109/TPEL.2020.3041876; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; How DNT, 2020, IEEE T IND APPL, V56, P5565, DOI 10.1109/TIA.2020.3004294; Kollmeyer Phillip, 2018, Mendeley Data, V1; Kollmeyer PJ, 2020, LG 18650HG2 li-ion battery data and example deep neural network xEV SOC estimator script; Li MH, 2023, J ENERGY STORAGE, V64, DOI 10.1016/j.est.2023.107191; Ling C, 2023, Arxiv, DOI arXiv:2305.18703; Liu YF, 2022, J ENERGY STORAGE, V52, DOI 10.1016/j.est.2022.104664; Naguib M, 2023, IEEE TRANSP ELECT C, DOI 10.1109/ITEC55900.2023.10186991; Ren XQ, 2021, ENERGY, V234, DOI 10.1016/j.energy.2021.121236; Shen HR, 2022, J ENERGY STORAGE, V45, DOI 10.1016/j.est.2021.103768; Takyi-Aninakwa P, 2022, ENERGY, V260, DOI 10.1016/j.energy.2022.125093; Taylor N, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3294633; Wu LF, 2023, ENERGY, V268, DOI 10.1016/j.energy.2023.126665; Xiao B, 2019, IEEE ACCESS, V7, P54192, DOI 10.1109/ACCESS.2019.2913078; Xing YJ, 2014, APPL ENERG, V113, P106, DOI 10.1016/j.apenergy.2013.07.008; Yang FF, 2019, ENERGY, V175, P66, DOI 10.1016/j.energy.2019.03.059; Yang K, 2023, J ENERGY STORAGE, V72, DOI 10.1016/j.est.2023.108774; Yang K, 2022, ENERGY, V244, DOI 10.1016/j.energy.2022.123233; Zhang ZW, 2021, IEEE ACCESS, V9, P11252, DOI 10.1109/ACCESS.2021.3049944; Zheng FD, 2016, APPL ENERG, V183, P513, DOI 10.1016/j.apenergy.2016.09.010	32	0	0	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0360-5442	1873-6785		ENERGY	Energy	SEP 1	2024	302								131856	10.1016/j.energy.2024.131856	http://dx.doi.org/10.1016/j.energy.2024.131856			9	Thermodynamics; Energy & Fuels	Science Citation Index Expanded (SCI-EXPANDED)	Thermodynamics; Energy & Fuels	US7R9					2024-07-03	WOS:001250117700001
J	Sezgin, E; Chekeni, F; Lee, J; Keim, S				Sezgin, Emre; Chekeni, Faraaz; Lee, Jennifer; Keim, Sarah			Clinical Accuracy of Large Language Models and Google Search Responses to Postpartum Depression Questions: Cross-Sectional Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Letter						mental health; postpartum depression; health information seeking; large language model; GPT; LaMDA; Google; ChatGPT; artificial intelligence; natural language processing; generative AI; depression; cross-sectional study; clinical accuracy			[Sezgin, Emre; Chekeni, Faraaz; Lee, Jennifer; Keim, Sarah] Nationwide Childrens Hosp, Columbus, OH USA; [Sezgin, Emre; Chekeni, Faraaz; Lee, Jennifer; Keim, Sarah] Ohio State Univ, Coll Med, Columbus, OH USA; [Keim, Sarah] Ohio State Univ, Coll Publ Hlth, Columbus, OH USA; [Sezgin, Emre] Nationwide Childrens Hosp, 700 Childrens Dr, Columbus, OH 43205 USA	University System of Ohio; Ohio State University; Nationwide Childrens Hospital; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; University System of Ohio; Ohio State University; Nationwide Childrens Hospital	Sezgin, E (corresponding author), Nationwide Childrens Hosp, 700 Childrens Dr, Columbus, OH 43205 USA.	emre.sezgin@nationwidechildrens.org	Sezgin, Emre/I-7969-2019; Lee, Jennifer/KBQ-9690-2024; Keim, Sarah/F-8929-2013	Sezgin, Emre/0000-0001-8798-9605; Lee, Jennifer/0000-0002-0849-1006; Keim, Sarah/0000-0003-3490-3649				[Anonymous], POSTPARTUM DEPRESSIO; [Anonymous], GPT-4; [Anonymous], 2023, Depression during and after pregnancy; Aronson S., 2023, NEJM Catalyst, V4, DOI [10.1056/CAT.23.0063, DOI 10.1056/CAT.23.0063]; Collins E, 2021, The Keyword; Guyatt GH, 2008, BMJ-BRIT MED J, V336, P995, DOI 10.1136/bmj.39490.551019.BE; Lee J, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/24045; Ripley B. D., 2001, MSOR Connect. Newsl. LTSN Maths Stats OR Netw, V1, P23, DOI [DOI 10.11120/MSOR.2001.01010023, 10.11120/msor.2001.01010023]; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Sharma A, 2023, NAT MACH INTELL, V5, P46, DOI 10.1038/s42256-022-00593-2	10	4	4	21	41	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	SEP 11	2023	25								e49240	10.2196/49240	http://dx.doi.org/10.2196/49240			4	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	U6QG4	37695668	Green Published, gold			2024-07-03	WOS:001086024500006
C	Riemenschneider, F; Frank, A		Rogers, A; Boyd-Graber, J; Okazaki, N		Riemenschneider, Frederick; Frank, Anette			Exploring Large Language Models for Classical Philology	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			GREEK	Recent advances in NLP have led to the creation of powerful language models for many languages including Ancient Greek and Latin. While prior work on Classical languages unanimously uses BERT, in this work we create four language models for Ancient Greek that vary along two dimensions to study their versatility for tasks of interest for Classical languages: we explore (i) encoder-only and encoder-decoder architectures using ROBERTA and T5 as strong model types, and create for each of them (ii) a monolingual Ancient Greek and a multilingual instance that includes Latin and English. We evaluate all models on morphological and syntactic tasks, including lemmatization, which demonstrates the added value of T5's decoding abilities. We further define two probing tasks to investigate the knowledge acquired by models pre-trained on Classical texts. Our experiments provide the first benchmarking analysis of existing models of Ancient Greek. Results show that our models provide significant improvements over the SoTA. The systematic analysis of model types can inform future research in designing language models for Classical languages, including the development of novel generative tasks. We make all our models available as community resources, along with a large curated pre-training corpus for Ancient Greek, to support the creation of a larger, comparable model zoo for Classical Philology. Our models and resources are available at https://github.com/Heidelberg-NLP/ancient-language-models.	[Riemenschneider, Frederick; Frank, Anette] Heidelberg Univ, Dept Computat Linguist, D-69120 Heidelberg, Germany	Ruprecht Karls University Heidelberg	Riemenschneider, F (corresponding author), Heidelberg Univ, Dept Computat Linguist, D-69120 Heidelberg, Germany.	riemenschneider@cl.uni-heidelberg.de; frank@cl.uni-heidelberg.de						Bamman David, 2020, ARXIV200910053; Bary Corien, 2017, P 2 INT C DIG ACC TE, P91; Berti M., 2019, GRUNDFRAGEN INFORMAT; Brants T, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, P224; BUSA R, 1980, COMPUT HUMANITIES, V14, P83, DOI 10.1007/BF02403798; Celano Giuseppe G. A., 2016, OPEN LINGUIST, V2; CHU YJ, 1965, SCI SINICA, V14, P1396; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Crane G., 1991, Literary & Linguistic Computing, V6, P243, DOI 10.1093/llc/6.4.243; de Marneffe MC, 2021, COMPUT LINGUIST, V47, P255, DOI [10.1162/coli_a_00402, 10.1162/COLI_a_00402]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Doddapaneni Sumanth, 2021, ARXIV210700676; EDMONDS J, 1967, J RES NBS B MATH SCI, VB 71, P233, DOI 10.6028/jres.071B.032; Johnson KP, 2021, ACL-IJCNLP 2021: THE JOINT CONFERENCE OF THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS, P20; Kassner N, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3250; Keersmaekers A, 2020, DIGIT SCHOLARSH HUM, V35, P67, DOI 10.1093/llc/fqz004; Kern Manfred., 2003, LEXIKON ANTIKEN GEST; Koutsikakis John, 2020, SETN 2020: Proceedings of the 11th Hellenic Conference on Artificial Intelligence, P110, DOI 10.1145/3411408.3411440; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Mercelis Wouter, 2022, WORKSH LANG TECHN HI, P189; Packard D.W., 1968, CONCORDANCE LIVY; Qi P, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P101; Raffel C, 2020, J MACH LEARN RES, V21; Schmid H., 2019, Proceedings of the 3rd international conference on digital access to textual cultural heritage, P133; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Singh Pranaydeep, 2021, P 5 JOINT SIGHUM WOR, P128; Sprugnoli Rachele, 2022, WORKSH LANG TECHN HI, P183; Straka Milan, 2018, P CONLL 2018 SHAR TA, P197, DOI DOI 10.18653/V1/K18-2020; Straka Milan, 2019, ARXIV190807448; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Vatri A, 2020, J GREEK LINGUIST, V20, P179, DOI 10.1163/15699846-02002001; Wrobel Krzysztof, 2022, WORKSH LANG TECHN HI, P193; Xue LT, 2022, T ASSOC COMPUT LING, V10, P291, DOI 10.1162/tacl_a_00461; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yamshchikov Ivan, 2022, P 2022 C EMPIRICAL M, P6071; Zhang XX, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P665	36	2	2	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15181	15199						19	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962506051
J	Qiu, JN; Yuan, W; Lam, K				Qiu, Jianing; Yuan, Wu; Lam, Kyle			The application of multimodal large language models in medicine	LANCET REGIONAL HEALTH-WESTERN PACIFIC			English	Editorial Material									[Qiu, Jianing; Yuan, Wu] Chinese Univ Hong Kong, Dept Biomed Engn, Hong Kong, Peoples R China; [Lam, Kyle] Imperial Coll, St Marys Hosp, Dept Surg & Canc, London, England	Chinese University of Hong Kong; Imperial College London	Lam, K (corresponding author), Imperial Coll, St Marys Hosp, Dept Surg & Canc, London, England.	k.lam@imperial.ac.uk	Yuan, Wu/E-8847-2010	Yuan, Wu/0000-0001-9405-519X; Lam, Kyle/0000-0001-6407-4912	NIHR Imperial Biomedical Research Centre; NIHR Academic Clinical Fellowship	NIHR Imperial Biomedical Research Centre; NIHR Academic Clinical Fellowship	Funding and infrastructural support was provided by the NIHR Imperial Biomedical Research Centre. Kyle Lam is supported by a NIHR Academic Clinical Fellowship.	Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; OpenAI, 2023, Gpt-4v(ision) system card; OpenAI, 2023, ChatGPT can now see, hear, and speak; Qiu JN, 2023, IEEE J BIOMED HEALTH, V27, P6074, DOI 10.1109/JBHI.2023.3316750; Yang Z., 2023, The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)	8	0	0	5	5	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2666-6065		LANCET REG HEALTH-W	Lancet Reg. Health-W. Pac.	APR	2024	45								101048	10.1016/j.lanwpc.2024.101048	http://dx.doi.org/10.1016/j.lanwpc.2024.101048		MAR 2024	2	Health Care Sciences & Services; Public, Environmental & Occupational Health	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services; Public, Environmental & Occupational Health	QE4P2	38524685	Green Published, gold			2024-07-03	WOS:001219192100001
J	Park, SH				Park, Seong Ho			Use of Generative Artificial Intelligence, Including Large Language Models Such as ChatGPT, in Scientific Publications: Policies of <i>KJR</i> and Prominent Authorities	KOREAN JOURNAL OF RADIOLOGY			English	Editorial Material						Generative; Artificial intelligence; Large language model; ChatGPT; Publication; Writing; Editing; Peer review; Policy	ADVERSARIAL NETWORK		[Park, Seong Ho] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Radiol, Seoul, South Korea; [Park, Seong Ho] Univ Ulsan, Coll Med, Res Inst Radiol, Asan Med Ctr, Seoul, South Korea; [Park, Seong Ho] Univ Ulsan, Coll Med, Asan Med Ctr, Dept Radiol, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea; [Park, Seong Ho] Univ Ulsan, Coll Med, Res Inst Radiol, Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea	University of Ulsan; Asan Medical Center; University of Ulsan; University of Ulsan; University of Ulsan	Park, SH (corresponding author), Univ Ulsan, Coll Med, Asan Med Ctr, Dept Radiol, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.; Park, SH (corresponding author), Univ Ulsan, Coll Med, Res Inst Radiol, Asan Med Ctr, 88 Olymp Ro 43 Gil, Seoul 05505, South Korea.	parksh.radiology@gmail.com	Park, Seong-Ho/HKV-2294-2023; Park, Seong Ho/E-2271-2014	Park, Seong Ho/0000-0002-1257-8315				American Association for the Advancement of Science, Science journals: editorial policies; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Bae K, 2022, KOREAN J RADIOL, V23, P139; Carr EJ, 2023, LANCET INFECT DIS, V23, P781, DOI 10.1016/S1473-3099(23)00290-6; Committee on Publication Ethics, Authorship and AI tools: COPE position statement; Garcia MB, 2024, ANN BIOMED ENG, V52, P139, DOI 10.1007/s10439-023-03299-7; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; International Committee of Medical Journal Editors, RECOMMENDATIONS; JAMA, Instructions for authors; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Miller K, 2023, J CLIN ONCOL, V41, P3480, DOI 10.1200/JCO.23.00819; nature, about us; Park JE, 2022, KOREAN J RADIOL, V23, P500, DOI 10.3348/kjr.2022.0033; Park SH, 2023, KOREAN J RADIOL, V24, P171, DOI 10.3348/kjr.2023.0112; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Wolterink JM, 2021, RADIOGRAPHICS, V41, P840, DOI 10.1148/rg.2021200151; Yan CG, 2021, KOREAN J RADIOL, V22, P983, DOI 10.3348/kjr.2020.0988; Zielinski C, Chatbots, generative AI, and scholarly manuscripts: WAME recommendations on chatbots and generative artificial intelligence in relation to scholarly publications	19	12	12	21	28	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	AUG	2023	24	8					715	718		10.3348/kjr.2023.0643	http://dx.doi.org/10.3348/kjr.2023.0643			4	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	CG9S5	37500572	Green Published			2024-07-03	WOS:001124224700009
J	Wu, H; Zhou, HY; Zheng, H; Wu, AP				Wu, Hui; Zhou, Hang-Yu; Zheng, Heng; Wu, Aiping			Towards Understanding and Identification of Human Viral Co-Infections	VIRUSES-BASEL			English	Review						human viral co-infections; viral interactions; host immune response; clinical symptoms; experimental and computational identification	HERPES-SIMPLEX-VIRUS; HEPATITIS-C VIRUS; INFLUENZA-A VIRUS; RESPIRATORY SYNCYTIAL VIRUS; HIV-INFECTED INDIVIDUALS; HUMAN-PAPILLOMAVIRUS; PERIPHERAL-BLOOD; DISEASE SEVERITY; MIXED INFECTION; NATURAL-HISTORY	Viral co-infections, in which a host is infected with multiple viruses simultaneously, are common in the human population. Human viral co-infections can lead to complex interactions between the viruses and the host immune system, affecting the clinical outcome and posing challenges for treatment. Understanding the types, mechanisms, impacts, and identification methods of human viral co-infections is crucial for the prevention and control of viral diseases. In this review, we first introduce the significance of studying human viral co-infections and summarize the current research progress and gaps in this field. We then classify human viral co-infections into four types based on the pathogenic properties and species of the viruses involved. Next, we discuss the molecular mechanisms of viral co-infections, focusing on virus-virus interactions, host immune responses, and clinical manifestations. We also summarize the experimental and computational methods for the identification of viral co-infections, emphasizing the latest advances in high-throughput sequencing and bioinformatics approaches. Finally, we highlight the challenges and future directions in human viral co-infection research, aiming to provide new insights and strategies for the prevention, control, diagnosis, and treatment of viral diseases. This review provides a comprehensive overview of the current knowledge and future perspectives on human viral co-infections and underscores the need for interdisciplinary collaboration to address this complex and important topic.	[Wu, Hui; Zheng, Heng] China Pharmaceut Univ, Sch Life Sci & Technol, Nanjing 211100, Peoples R China; [Wu, Hui; Zhou, Hang-Yu; Wu, Aiping] Chinese Acad Med Sci & Peking Union Med Coll, Inst Syst Med, Beijing 100005, Peoples R China; [Wu, Hui; Zhou, Hang-Yu; Wu, Aiping] Chinese Acad Med Sci & Peking Union Med Coll, Suzhou Inst Syst Med, State Key Lab Common Mech Res Major Dis, Suzhou 215123, Peoples R China	China Pharmaceutical University; Chinese Academy of Medical Sciences - Peking Union Medical College; Peking Union Medical College; Chinese Academy of Medical Sciences - Peking Union Medical College; Peking Union Medical College	Zheng, H (corresponding author), China Pharmaceut Univ, Sch Life Sci & Technol, Nanjing 211100, Peoples R China.; Wu, AP (corresponding author), Chinese Acad Med Sci & Peking Union Med Coll, Inst Syst Med, Beijing 100005, Peoples R China.; Wu, AP (corresponding author), Chinese Acad Med Sci & Peking Union Med Coll, Suzhou Inst Syst Med, State Key Lab Common Mech Res Major Dis, Suzhou 215123, Peoples R China.	wuhui@stu.cpu.edu.cn; zhengh@cpu.edu.cn; wap@ism.cams.cn	Zhou, Hang-Yu/GNP-3158-2022	Zhou, Hang-Yu/0000-0002-3762-2319; Zheng, Heng/0000-0002-1810-5842	National Key Plan for Scientific Research and Development of China	National Key Plan for Scientific Research and Development of China	The final draft of this paper was refined and optimized using a large language model to improve the readability and expression.	Adland E, 2015, FRONT MICROBIOL, V6, DOI 10.3389/fmicb.2015.01016; Al Moustafa AE, 2009, MED HYPOTHESES, V73, P184, DOI 10.1016/j.mehy.2009.02.025; Alhumaid S, 2021, PATHOGENS, V10, DOI 10.3390/pathogens10070809; Alizon S, 2013, INTERFACE FOCUS, V3, DOI 10.1098/rsfs.2013.0031; Alvar J, 1997, CLIN MICROBIOL REV, V10, P298, DOI 10.1128/CMR.10.2.298; Aylward B, 2014, NEW ENGL J MED, V371, P1481, DOI 10.1056/NEJMoa1411100; Bal A, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33910-9; Baseman JG, 2005, J CLIN VIROL, V32, pS16, DOI 10.1016/j.jcv.2004.12.008; Biagini P, 2004, VET MICROBIOL, V98, P95, DOI 10.1016/j.vetmic.2003.10.004; Blackard JT, 2018, REV MED VIROL, V28, DOI 10.1002/rmv.1984; Blackard JT, 2002, CLIN INFECT DIS, V34, P1108, DOI 10.1086/339547; Bolze A, 2022, MED-CAMBRIDGE, V3, P848, DOI 10.1016/j.medj.2022.10.002; Brand HK, 2012, PEDIATR PULM, V47, P393, DOI 10.1002/ppul.21552; Byrd KM, 2020, J INT AIDS SOC, V23, DOI 10.1002/jia2.25573; Carbone A, 2009, BLOOD, V113, P1213, DOI 10.1182/blood-2008-09-180315; Cawcutt K, 2017, CURR OPIN CRIT CARE, V23, P385, DOI 10.1097/MCC.0000000000000435; Chan KF, 2018, J INFECT DIS, V218, P406, DOI 10.1093/infdis/jiy184; Ching NS, 2018, J PAEDIATR CHILD H, V54, P1321, DOI 10.1111/jpc.14076; Chotpitayasunondh T, 2021, INFLUENZA OTHER RESP, V15, P407, DOI 10.1111/irv.12824; Chun HM, 2012, J INFECT DIS, V205, P185, DOI 10.1093/infdis/jir720; Cohen AL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128580; Cohen JI, 2000, NEW ENGL J MED, V343, P481, DOI 10.1056/NEJM200008173430707; Combes P, 2022, CLIN MICROBIOL INFEC, V28, DOI 10.1016/j.cmi.2022.06.030; COVID-19 Genomics UK (COG-UK) consortiumcontact@cogconsortium.uk, 2020, Lancet Microbe, V1, pe99, DOI 10.1016/S2666-5247(20)30054-9; Cuadrado-Payán E, 2020, LANCET, V395, pE84, DOI 10.1016/S0140-6736(20)31052-7; Desai DV, 2015, VIRAL IMMUNOL, V28, P546, DOI 10.1089/vim.2015.0012; Dezordi FZ, 2022, MICROB GENOMICS, V8, DOI 10.1099/mgen.0.000751; Dixon MG, 2014, MMWR-MORBID MORTAL W, V63, P548; Effros RB, 2016, MECH AGEING DEV, V158, P46, DOI 10.1016/j.mad.2015.09.003; Elbe S, 2017, GLOB CHALL, V1, P33, DOI 10.1002/gch2.1018; EVANS LA, 1988, LANCET, V2, P1389; Feldman C, 2021, PNEUMONIA, V13, DOI 10.1186/s41479-021-00083-w; Focosi D, 2022, VIRUSES-BASEL, V14, DOI 10.3390/v14061239; Forterre P, 2010, ORIGINS LIFE EVOL B, V40, P151, DOI 10.1007/s11084-010-9194-1; Freeman ML, 2016, CURR HIV-AIDS REP, V13, P10, DOI 10.1007/s11904-016-0297-9; Fried MW, 2002, NEW ENGL J MED, V347, P975, DOI 10.1056/NEJMoa020047; Ghedin E, 2011, J INFECT DIS, V203, P168, DOI 10.1093/infdis/jiq040; Ghedin E, 2009, J VIROL, V83, P8832, DOI 10.1128/JVI.00773-09; Goka EA, 2015, EPIDEMIOL INFECT, V143, P37, DOI 10.1017/S0950268814000302; Goka E, 2013, INFLUENZA OTHER RESP, V7, P1079, DOI 10.1111/irv.12020; Gong Z, 2020, ZOOL RES, V41, P705, DOI 10.24272/j.issn.2095-8137.2020.065; Alvarez DAG, 2016, EXPERT REV RESP MED, V10, P463, DOI 10.1586/17476348.2016.1157474; Goto H, 2016, MED MICROBIOL IMMUN, V205, P209, DOI 10.1007/s00430-015-0441-y; Gottlieb GS, 2004, LANCET, V363, P619, DOI 10.1016/S0140-6736(04)15596-7; Goulder PJR, 2002, NEW ENGL J MED, V347, P756, DOI 10.1056/NEJMe020091; Griesbeck M, 2017, AIDS, V31, P1223, DOI 10.1097/QAD.0000000000001455; Griffiths EC, 2011, J INFECTION, V63, P200, DOI 10.1016/j.jinf.2011.06.005; Griffiths P, 2015, J PATHOL, V235, P288, DOI 10.1002/path.4437; Guan Z, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.773130; Hatcher EL, 2017, NUCLEIC ACIDS RES, V45, pD482, DOI 10.1093/nar/gkw1065; He YQ, 2022, EMERG MICROBES INFEC, V11, P552, DOI 10.1080/22221751.2022.2032375; Hutchinson EC, 2018, TRENDS MICROBIOL, V26, P809, DOI 10.1016/j.tim.2018.05.013; Jackson B, 2021, CELL, V184, P5179, DOI 10.1016/j.cell.2021.08.014; Kaczorowska J, 2020, FEMS MICROBIOL REV, V44, P305, DOI 10.1093/femsre/fuaa007; Kanwugu ON, 2021, J MED VIROL, V93, P726, DOI 10.1002/jmv.26321; Kawaoka Yoshihiro, 2012, Methods Mol Biol, V865, P1, DOI 10.1007/978-1-61779-621-0_1; Khare S, 2021, CHINA CDC WEEKLY, V3, P1049, DOI 10.46234/ccdcw2021.255; Klimas N, 2008, PSYCHOSOM MED, V70, P523, DOI 10.1097/PSY.0b013e31817ae69f; Krumbein H, 2023, REV MED VIROL, V33, DOI 10.1002/rmv.2365; Kumar N, 2018, CLIN MICROBIOL REV, V31, DOI 10.1128/CMR.00111-17; Lacombe K, 2012, GUT, V61, P47, DOI 10.1136/gutjnl-2012-302062; Landolfo S, 2003, PHARMACOL THERAPEUT, V98, P269, DOI 10.1016/S0163-7258(03)00034-2; Liang GX, 2021, NAT REV MICROBIOL, V19, P514, DOI 10.1038/s41579-021-00536-5; Lin L, 2006, EUR J GASTROEN HEPAT, V18, P1311, DOI 10.1097/01.meg.0000243881.09820.09; Lisco A, 2009, CELL HOST MICROBE, V6, P403, DOI 10.1016/j.chom.2009.10.010; Looker KJ, 2017, LANCET INFECT DIS, V17, P1303, DOI 10.1016/S1473-3099(17)30405-X; Marston HD, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3009872; Martin ET, 2013, J INFECT DIS, V207, P982, DOI 10.1093/infdis/jis934; Martin ET, 2012, INFLUENZA OTHER RESP, V6, P71, DOI 10.1111/j.1750-2659.2011.00265.x; Massey BW, 2020, FRONT MICROBIOL, V11, DOI 10.3389/fmicb.2020.02079; Masur H, 2001, CURR CLIN TOPICS INF, V21, P64; Matthews GV, 2008, J GASTROEN HEPATOL, V23, P1000, DOI 10.1111/j.1440-1746.2008.05489.x; McDonald SM, 2016, NAT REV MICROBIOL, V14, P448, DOI 10.1038/nrmicro.2016.46; Mercado-Reyes M, 2019, EPIDEMIOL INFECT, V147, DOI [10.1017/S095026881800359X, 10.1017/s095026881800359x]; Musuuza JS, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0251170; Neches RY, 2020, NAT REV MICROBIOL, V18, P606, DOI 10.1038/s41579-020-00451-1; Nichol ST, 2000, P NATL ACAD SCI USA, V97, P12411, DOI 10.1073/pnas.210382297; Pacheco GA, 2021, MICROORGANISMS, V9, DOI 10.3390/microorganisms9061293; Parrish CR, 2008, MICROBIOL MOL BIOL R, V72, P457, DOI 10.1128/MMBR.00004-08; Peacey M, 2010, EMERG INFECT DIS, V16, P1618, DOI 10.3201/eid1610.100116; Pérez-Losada M, 2015, INFECT GENET EVOL, V30, P296, DOI 10.1016/j.meegid.2014.12.022; Pinky L, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0155589; Pipek OA, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-023-43391-z; Piret J, 2022, EMERG INFECT DIS, V28, P273, DOI 10.3201/eid2802.211727; Polz-Gruszka D, 2015, ANTICANCER RES, V35, P1657; Poritz MA, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0026047; RINALDO CR, 1978, J IMMUNOL, V120, P130; Roest RW, 2006, J INFECT DIS, V194, P1115, DOI 10.1086/507683; Roossinck MJ, 2011, NAT REV MICROBIOL, V9, P99, DOI 10.1038/nrmicro2491; Rotzén-Östlund M, 2014, ACTA PAEDIATR, V103, P100, DOI 10.1111/apa.12440; Ryan FP, 2007, SYMBIOSIS, V44, P11; Saldaña J, 2003, MATH BIOSCI, V183, P135, DOI 10.1016/S0025-5564(03)00038-5; Sand L, 2014, MICROBES INFECT, V16, P371, DOI 10.1016/j.micinf.2014.02.009; Schacker T, 1998, J INFECT DIS, V178, P1616, DOI 10.1086/314486; Schultz-Cherry S, 2015, J INFECT DIS, V212, P1690, DOI 10.1093/infdis/jiv261; Schweiger B, 2006, VACCINE, V24, P6683, DOI 10.1016/j.vaccine.2006.05.105; Semple MG, 2005, J INFECT DIS, V191, P382, DOI 10.1086/426457; Shu YL, 2017, EUROSURVEILLANCE, V22, P2, DOI 10.2807/1560-7917.ES.2017.22.13.30494; Song SH, 2020, GENOM PROTEOM BIOINF, V18, P749, DOI 10.1016/j.gpb.2020.09.001; Steininger C, 2007, CLIN MICROBIOL INFEC, V13, P953, DOI 10.1111/j.1469-0691.2007.01781.x; Strickler HD, 2005, J NATL CANCER I, V97, P577, DOI 10.1093/jnci/dji073; Su S, 2016, TRENDS MICROBIOL, V24, P490, DOI 10.1016/j.tim.2016.03.003; Sulkowski MS, 2008, J HEPATOL, V48, P353, DOI 10.1016/j.jhep.2007.11.009; Sun HY, 2020, BMC MED, V18, DOI 10.1186/s12916-020-01845-x; Suttle CA, 2007, NAT REV MICROBIOL, V5, P801, DOI 10.1038/nrmicro1750; Tang MB, 2014, SE ASIAN J TROP MED, V45, P1326; Tao H, 2015, J VIROL, V89, P8453, DOI 10.1128/JVI.01162-15; Taylor L, 2022, BMJ-BRIT MED J, V378, DOI 10.1136/bmj.o1874; Taylor LE, 2012, CLIN INFECT DIS, V55, pS33, DOI 10.1093/cid/cis367; Thein HH, 2008, AIDS, V22, P1979, DOI 10.1097/QAD.0b013e32830e6d51; Topoulos S, 2019, INFECTION, V47, P425, DOI 10.1007/s15010-018-1262-x; Touzard-Romo Francine, 2020, R I Med J (2013), V103, P75; Urban S, 2021, GUT, V70, P1782, DOI 10.1136/gutjnl-2020-323888; van Baarle D, 1999, BLOOD, V93, P3949; van der Kuyl AC, 2007, RETROVIROLOGY, V4, DOI 10.1186/1742-4690-4-67; Varabyou A, 2021, GENETICS, V218, DOI 10.1093/genetics/iyab074; Vijaykrishna D, 2015, PLOS PATHOG, V11, DOI 10.1371/journal.ppat.1004902; Virgin HW, 2009, CELL, V138, P30, DOI 10.1016/j.cell.2009.06.036; WANER JL, 1994, CLIN MICROBIOL REV, V7, P143, DOI 10.1128/CMR.7.2.143-151.1994; Welliver TP, 2008, PEDIATR INFECT DIS J, V27, pS92, DOI 10.1097/INF.0b013e318168b706; WHITBY D, 1995, LANCET, V346, P799, DOI 10.1016/S0140-6736(95)91619-9; Whitley RJ, 2001, LANCET, V357, P1513, DOI 10.1016/S0140-6736(00)04638-9; Wu AP, 2021, CELL HOST MICROBE, V29, P503, DOI 10.1016/j.chom.2021.02.017; Xiang X, 2021, CURR MED SCI, V41, P51, DOI 10.1007/s11596-021-2317-2; Ye SF, 2022, BIOINFORMATICS, V38, P3087, DOI 10.1093/bioinformatics/btac275; Zárate S, 2017, ARCH MED RES, V48, P701, DOI 10.1016/j.arcmed.2018.01.005; Zhang XS, 2013, EPIDEMICS-NETH, V5, P20, DOI 10.1016/j.epidem.2012.10.003; Zhou HY, 2022, COMPUT STRUCT BIOTEC, V20, P4015, DOI 10.1016/j.csbj.2022.07.042; Zhu ZL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-78703-6	129	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1999-4915		VIRUSES-BASEL	Viruses-Basel	MAY	2024	16	5							673	10.3390/v16050673	http://dx.doi.org/10.3390/v16050673			17	Virology	Science Citation Index Expanded (SCI-EXPANDED)	Virology	RZ5S2	38793555	gold			2024-07-03	WOS:001231498400001
J	Schulte, B				Schulte, Brian			Considerations for Prompting Large Language Models	JAMA ONCOLOGY			English	Letter									[Schulte, Brian] Univ Calif San Francisco, Dept Med, 1825 Fourth St, San Francisco, CA 94158 USA	University of California System; University of California San Francisco	Schulte, B (corresponding author), Univ Calif San Francisco, Dept Med, 1825 Fourth St, San Francisco, CA 94158 USA.	brian.schulte@ucsf.edu						Chen S, 2023, JAMA ONCOL, V9, P1459, DOI 10.1001/jamaoncol.2023.2954; OpenAI, TOKENIZER; Schulte B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37938	3	0	0	1	1	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2374-2437	2374-2445		JAMA ONCOL	JAMA Oncol.	APR	2024	10	4					475	483		10.1001/jamaoncol.2023.6963	http://dx.doi.org/10.1001/jamaoncol.2023.6963		APR 2024	9	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	OE4S9	38358765				2024-07-03	WOS:001163497600003
J	Kleebayoon, A; Wiwanitkit, V				Kleebayoon, Amnuay; Wiwanitkit, Viroj			Large language models for structured reporting in radiology: comment	RADIOLOGIA MEDICA			English	Letter									[Wiwanitkit, Viroj] Chandigarh Univ, Chandigarh, Punjab, India; [Wiwanitkit, Viroj] Joesph Ayobabalola Univ, Ikeji Arakeji, Nigeria	Chandigarh University	Wiwanitkit, V (corresponding author), Chandigarh Univ, Chandigarh, Punjab, India.; Wiwanitkit, V (corresponding author), Joesph Ayobabalola Univ, Ikeji Arakeji, Nigeria.	amnuaykleebai@gmail.com						Kleebayoon A, 2023, CELL MOL BIOENG, V16, P173, DOI 10.1007/s12195-023-00759-x; Mallio CA, 2023, RADIOL MED, V128, P808, DOI 10.1007/s11547-023-01651-4	2	0	0	1	2	SPRINGER-VERLAG ITALIA SRL	MILAN	VIA DECEMBRIO, 28, MILAN, 20137, ITALY	0033-8362	1826-6983		RADIOL MED	Radiol. Med.	NOV	2023	128	11					1440	1440		10.1007/s11547-023-01687-6	http://dx.doi.org/10.1007/s11547-023-01687-6		AUG 2023	1	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	W2GY8	37568071	Bronze			2024-07-03	WOS:001047235300001
J	Norris, C				Norris, Carly			Large Language Models Like ChatGPT in ABME: Author Guidelines	ANNALS OF BIOMEDICAL ENGINEERING			English	Editorial Material									[Norris, Carly] Virginia Tech, Dept Biomed Engn & Mech, Blacksburg, VA 24060 USA	Virginia Polytechnic Institute & State University	Norris, C (corresponding author), Virginia Tech, Dept Biomed Engn & Mech, Blacksburg, VA 24060 USA.	carly8@vt.edu						Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537	6	2	2	5	18	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	JUN	2023	51	6					1121	1122		10.1007/s10439-023-03212-2	http://dx.doi.org/10.1007/s10439-023-03212-2		APR 2023	2	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	AR7R8	37093400	Bronze			2024-07-03	WOS:000976944100002
J	Petrella, F; Rizzo, SMR; Rampinelli, C; Casiraghi, M; Bagnardi, V; Frassoni, S; Pozzi, S; Pappalardo, O; Pravettoni, G; Spaggiari, L				Petrella, Francesco; Rizzo, Stefania Maria Rita; Rampinelli, Cristiano; Casiraghi, Monica; Bagnardi, Vincenzo; Frassoni, Samuele; Pozzi, Silvia; Pappalardo, Omar; Pravettoni, Gabriella; Spaggiari, Lorenzo			Assessment of pulmonary vascular anatomy: comparing augmented reality by holograms <i>versus</i> standard CT images/reconstructions using surgical findings as reference standard	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Augmented reality; Holograms; Lung neoplasms; Tomography (x-ray computed); Thoracic surgery	PREOPERATIVE ASSESSMENT; COMPUTED-TOMOGRAPHY; PROTOCOL; QUALITY; CANCER	Background We compared computed tomography (CT) images and holograms (HG) to assess the number of arteries of the lung lobes undergoing lobectomy and assessed easiness in interpretation by radiologists and thoracic surgeons with both techniques. Methods Patients scheduled for lobectomy for lung cancer were prospectively included and underwent CT for staging. A patient-specific three-dimensional model was generated and visualized in an augmented reality setting. One radiologist and one thoracic surgeon evaluated CT images and holograms to count lobar arteries, having as reference standard the number of arteries recorded at surgery. The easiness of vessel identification was graded according to a Likert scale. Wilcoxon signed-rank test and kappa statistics were used. Results Fifty-two patients were prospectively included. The two doctors detected the same number of arteries in 44/52 images (85%) and in 51/52 holograms (98%). The mean difference between the number of artery branches detected by surgery and CT images was 0.31 +/- 0.98, whereas it was 0.09 +/- 0.37 between surgery and HGs (p = 0.433). In particular, the mean difference in the number of arteries detected in the upper lobes was 0.67 +/- 1.08 between surgery and CT images and 0.17 +/- 0.46 between surgery and holograms (p = 0.029). Both radiologist and surgeon showed a higher agreement for holograms (kappa = 0.99) than for CT (kappa = 0.81) and found holograms easier to evaluate than CTs (p < 0.001). Conclusions Augmented reality by holograms is an effective tool for preoperative vascular anatomy assessment of lungs, especially when evaluating the upper lobes, more prone to anatomical variations. Trial registration ClinicalTrials.gov, NCT04227444 Relevance statement Preoperative evaluation of the lung lobe arteries through augmented reality may help the thoracic surgeons to carefully plan a lobectomy, thus contributing to optimize patients' outcomes. Key points Preoperative assessment of the lung arteries may help surgical planning. Lung artery detection by augmented reality was more accurate than that by CT images, particularly for the upper lobes. The assessment of the lung arterial vessels was easier by using holograms than CT images.	[Petrella, Francesco; Casiraghi, Monica; Spaggiari, Lorenzo] IRCCS European Inst Oncol, Dept Thorac Surg, Via Ripamonti 435, I-20141 Milan, Italy; [Petrella, Francesco; Casiraghi, Monica; Pravettoni, Gabriella; Spaggiari, Lorenzo] Univ Milan, Dept Oncol & Hemato oncol, Via Festa Perdono 7, I-20122 Milan, Italy; [Petrella, Francesco] Fdn IRCCS San Gerardo Tintori, Dept Thorac Surg, Via G B Pergolesi,33, I-20900 Monza, Italy; [Rizzo, Stefania Maria Rita] Imaging Inst Southern Switzerland IIMSI, Clin Radiol, Ente Osped Cantonale EOC, Via Tesserete 46, CH-6900 Lugano, Switzerland; [Rizzo, Stefania Maria Rita] Univ Svizzera italiana USI, Fac Sci Biomed, Via Buffi 13, CH-6900 Lugano, Switzerland; [Rampinelli, Cristiano] IRCCS European Inst Oncol, Div Radiol, Via Ripamonti 435, I-20141 Milan, Italy; [Bagnardi, Vincenzo; Frassoni, Samuele] Univ Milano Bicocca, Dept Stat & Quantitat Methods, I-20126 Milan, Italy; [Pozzi, Silvia; Pappalardo, Omar] Artiness srl, Viale Cassala 57, I-20143 Milan, Italy	IRCCS European Institute of Oncology (IEO); University of Milan; Fondazione IRCCS San Gerardo dei Tintori; Universita della Svizzera Italiana; IRCCS European Institute of Oncology (IEO); University of Milano-Bicocca	Rizzo, SMR (corresponding author), Imaging Inst Southern Switzerland IIMSI, Clin Radiol, Ente Osped Cantonale EOC, Via Tesserete 46, CH-6900 Lugano, Switzerland.; Rizzo, SMR (corresponding author), Univ Svizzera italiana USI, Fac Sci Biomed, Via Buffi 13, CH-6900 Lugano, Switzerland.	stefania.rizzo@eoc.ch	Casiraghi, Monica/K-2777-2019	Casiraghi, Monica/0000-0001-5986-7811	Ministero dell'Istruzione, dell'Universit e della Ricerca; APC central fund of the University of Milan	Ministero dell'Istruzione, dell'Universit e della Ricerca(Ministry of Education, Universities and Research (MIUR)); APC central fund of the University of Milan	The English text was revised by Susan West. No large language models (LLMs) were used in this manuscript. The authors acknowledge the support of the APC central fund of the University of Milan.	Boiselle PM, 2002, AM J ROENTGENOL, V179, P301, DOI 10.2214/ajr.179.2.1790301; Botta F, 2020, CANCERS, V12, DOI 10.3390/cancers12061432; Chessa M, 2022, EUR HEART J, V43, P2672, DOI 10.1093/eurheartj/ehac266; CORY R A, 1959, Thorax, V14, P267, DOI 10.1136/thx.14.4.267; Cuomo S, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/523862; Dolega-Dolegowski D, 2022, HEAD FACE MED, V18, DOI 10.1186/s13005-022-00307-4; Fourdrain A, 2018, SURG RADIOL ANAT, V40, P45, DOI 10.1007/s00276-017-1914-z; Fukuhara K, 2008, EUR J CARDIO-THORAC, V34, P875, DOI 10.1016/j.ejcts.2008.07.014; GABOR D, 1971, SCIENCE, V173, P11, DOI 10.1126/science.173.3991.11; García-Garrigós E, 2018, AM J ROENTGENOL, V210, P1226, DOI 10.2214/AJR.17.19185; Hagiwara M, 2014, EUR J CARDIO-THORAC, V46, pE120, DOI 10.1093/ejcts/ezu375; Hernandez AM, 2020, MED PHYS, V47, P2869, DOI 10.1002/mp.14159; Jung C, 2022, JACC-CARDIOVASC IMAG, V15, P519, DOI 10.1016/j.jcmg.2021.08.017; Jung JI, 2011, ACTA RADIOL, V52, P417, DOI 10.1258/ar.2011.100217; Kalra MK, 2005, RADIOLOGY, V237, P303, DOI 10.1148/radiol.2371041227; Kumar Rahul Prasanna, 2020, J Biomed Inform, V112S, P100077, DOI 10.1016/j.yjbinx.2020.100077; Mangano FG, 2023, J DENT, V133, DOI 10.1016/j.jdent.2023.104485; Ong CW, 2021, J MED INTERNET RES, V23, DOI 10.2196/24152; Ramesh PV, 2022, INDIAN J OPHTHALMOL, V70, P3116, DOI 10.4103/ijo.IJO_120_22; Rizzo SMR, 2005, RADIOLOGY, V237, P309, DOI 10.1148/radiol.2371041879; Ryu S, 2022, ANTICANCER RES, V42, P4849, DOI 10.21873/anticanres.15990; Salfity H, 2020, SEMIN RESP CRIT CARE, V41, P335, DOI 10.1055/s-0039-3401991; Smelt JLC, 2019, ANN THORAC SURG, V107, P401, DOI 10.1016/j.athoracsur.2018.08.052; Tokunaga T, 2022, LANGENBECK ARCH SURG, V407, P2579, DOI 10.1007/s00423-022-02607-4; Zheng WL, 2022, J CARDIOTHORAC SURG, V17, DOI 10.1186/s13019-022-01975-8	25	0	0	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	MAY 10	2024	8	1							57	10.1186/s41747-024-00458-w	http://dx.doi.org/10.1186/s41747-024-00458-w			12	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	PY2M4	38724831	gold			2024-07-03	WOS:001217574600001
J	Gilson, A; Safranek, CW; Huang, T; Socrates, V; Chi, L; Taylor, RA; Chartash, D				Gilson, Aidan; Safranek, Conrad W.; Huang, Thomas; Socrates, Vimig; Chi, Ling; Taylor, Richard Andrew; Chartash, David			Authors' Reply to: Variability in Large Language Models' Responses to Medical Licensing and Certification Examinations	JMIR MEDICAL EDUCATION			English	Letter						natural language processing; NLP; MedQA; generative pre-trained transformer; GPT; medical education; chatbot; artificial intelligence; AI; education technology; ChatGPT; conversational agent; machine learning; large language models; knowledge assessment			[Gilson, Aidan; Safranek, Conrad W.; Socrates, Vimig; Chi, Ling; Taylor, Richard Andrew; Chartash, David] Yale Univ, Sect Biomed Informat & Data Sci, Sch Med, New Haven, CT USA; [Gilson, Aidan; Huang, Thomas; Taylor, Richard Andrew] Yale Univ, Dept Emergency Med, Sch Med, New Haven, CT USA; [Socrates, Vimig] Yale Univ, Program Computat Biol & Bioinformat, New Haven, CT USA; [Chartash, David] Natl Univ Ireland, Univ Coll Dublin, Sch Med, Dublin, Ireland; [Chartash, David] Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St,9th Fl, New Haven, CT 06510 USA	Yale University; Yale University; Yale University; University College Dublin; Yale University	Chartash, D (corresponding author), Yale Univ, Sch Med, Sect Biomed Informat & Data Sci, 100 Coll St,9th Fl, New Haven, CT 06510 USA.	david.chartash@yale.edu		/0000-0002-9082-6644; Gilson, Aidan/0000-0002-4770-4705; Safranek, Conrad/0000-0003-1985-9432; Chi, Ling/0000-0002-8270-9245; Socrates, Vimig/0000-0001-7955-9875; Huang, Thomas/0000-0001-9056-7016				archive, MY AI US LOC DAT; Epstein RH, 2023, JMIR MED EDUC, V9, DOI 10.2196/48305; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104	4	1	1	9	25	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e50336	10.2196/50336	http://dx.doi.org/10.2196/50336			2	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	N0HQ0	37440299	Green Published, gold			2024-07-03	WOS:001033934300002
J	Kleebayoon, A; Wiwanitkit, V				Kleebayoon, Amnuay; Wiwanitkit, Viroj			ChatGPT and large language model (LLM) chatbots: Correspondence	JOURNAL OF PEDIATRIC UROLOGY			English	Letter									[Kleebayoon, Amnuay] Private Acad Consultant, Samraong, Cambodia; [Wiwanitkit, Viroj] Chandigarh Univ, Ajitgarh, Punjab, India; [Wiwanitkit, Viroj] India Joesph Ayobabalola Univ, Ikeji Arakeji, Nigeria	Chandigarh University	Kleebayoon, A (corresponding author), Private Acad Consultant, Samraong, Cambodia.	amnuaykleebai@gmail.com						Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018; Kleebayoon A, 2023, CELL MOL BIOENG, V16, P173, DOI 10.1007/s12195-023-00759-x	2	0	0	8	12	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1477-5131	1873-4898		J PEDIATR UROL	J. Pediatr. Urol	OCT	2023	19	5					605	606		10.1016/j.jpurol.2023.06.033	http://dx.doi.org/10.1016/j.jpurol.2023.06.033		SEP 2023	2	Pediatrics; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics; Urology & Nephrology	U6LZ4	37495493				2024-07-03	WOS:001085911600001
J	Roberts, K				Roberts, Kirk			Large language models for reducing clinicians' documentation burden	NATURE MEDICINE			English	Article; Early Access								Evaluation of a clinical summarization method based on GPT-4 suggests that such models might reduce the documentation burden on clinicians - but prospective evaluation with high-priority tasks will be the true test of its potential.	[Roberts, Kirk] Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX 77030 USA	University of Texas System; University of Texas Health Science Center Houston	Roberts, K (corresponding author), Univ Texas Hlth Sci Ctr Houston, McWilliams Sch Biomed Informat, Houston, TX 77030 USA.	Kirk.Roberts@uth.tmc.edu		Roberts, Kirk/0000-0001-6525-5213				Duffourc M, 2023, JAMA-J AM MED ASSOC, V330, P313, DOI 10.1001/jama.2023.9630; Hersh W, 2024, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocae014; Kanter GP, 2023, JAMA-J AM MED ASSOC, V330, P311, DOI 10.1001/jama.2023.9618; National Academy of Medicine, 2019, Taking Action Against Clinician Burnout: A Systems Approach to Professional Well-Being; Palmer K., 2024, STAT; Soni S, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P6250; Taylor J., 2023, Guardian; Van Veen D., 2024, Nat. Med, DOI [10.1038/s41591-024-02855-5, DOI 10.1038/S41591-024-02855-5]; Vaswani A, 2017, ADV NEUR IN, V30; Zhang GB, 2024, Arxiv, DOI arXiv:2311.11211; Zhang Y., 2018, INT WORKSH HLTH TEXT, P204	11	0	0	3	3	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	2024 APR 1	2024										10.1038/s41591-024-02888-w	http://dx.doi.org/10.1038/s41591-024-02888-w		APR 2024	2	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	MP7O1	38561439				2024-07-03	WOS:001194895200001
J	Babakhani, P; Lommatzsch, A; Brodt, T; Sacker, D; Sivrikaya, F; Albayrak, S				Babakhani, Pedram; Lommatzsch, Andreas; Brodt, Torben; Sacker, Doreen; Sivrikaya, Fikret; Albayrak, Sahin			Opinerium: Subjective Question Generation Using Large Language Models	IEEE ACCESS			English	Article						Subjective questions; LLMs; Seq2Seq generation; fine tuning; zero-shot learning		This paper presents a comprehensive study on generating subjective inquiries for news media posts to empower public engagement with trending media topics. While previous studies primarily focused on factual and objective questions with explicit or implicit answers in the text, this research concentrates on automatically generating subjective questions to directly elicit personal preference from individuals based on a given text. The research methodology involves the application of fine-tuning techniques across multiple iterations of flan-T5 and GPT3 architectures for the task of Seq2Seq generation. This approach is meticulously evaluated using a custom dataset comprising 40,000 news articles along with human-generated questions. Furthermore, a comparative analysis is conducted using zero-shot prompting via GPT-3.5, juxtaposing the performance of fine-tuned models against a significantly larger language model. The study grapples with the inherent challenges tied to evaluating opinion-based question generation due to its subjective nature and the inherent uncertainty in determining answers. A thorough investigation and comparison of two transformer architectures are undertaken utilizing conventional lexical overlap metrics such as BLEU, ROUGE, and METEOR, alongside semantic similarity metrics encompassing BERTScore, BLEURT, and answerability scores such as QAScore, and RQUGE. The findings underscore the marked superiority of the flan-T5 model over GPT3, substantiated not only by quantitative metrics but also through human evaluations. The paper introduces Opinerium based on the open-source flan-T5-Large model, identified as the pacesetter in generating subjective questions. Additionally, we assessed all aforementioned metrics thoroughly by investigating the pairwise Spearman correlation analysis to identify robust metrics.	[Babakhani, Pedram; Lommatzsch, Andreas; Albayrak, Sahin] Tech Univ Berlin, DAI Lab, D-10587 Berlin, Germany; [Brodt, Torben; Sacker, Doreen] Opinary GmbH, D-10179 Berlin, Germany; [Sivrikaya, Fikret] GT ARC gGmbH, D-10587 Berlin, Germany	Technical University of Berlin	Babakhani, P (corresponding author), Tech Univ Berlin, DAI Lab, D-10587 Berlin, Germany.	pedram.babakhani@tu-berlin.de	Sivrikaya, Fikret/E-1497-2013	Sivrikaya, Fikret/0000-0003-0067-4761	SPURT between Opinary GmbH and Technische Universitt Berlin Berlin	SPURT between Opinary GmbH and Technische Universitt Berlin Berlin	No Statement Available	Bendig E, 2019, VERHALTENSTHERAPIE, V29, P266, DOI 10.1159/000499492; Blagec K, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON EFFICIENT BENCHMARKING IN NLP (NLP POWER 2022), P52; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chali Yllias., 2018, Proceedings of the 11th International Conference on Natural Language Generation, P152; Chan Y.-H., 2019, P 2 WORKSHOP MACHINE, P154; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Demner-Fushman D, 2009, J BIOMED INFORM, V42, P760, DOI 10.1016/j.jbi.2009.08.007; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Doi R, 2022, 2022 7TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR2022), P301, DOI 10.1109/ICBIR54589.2022.9786384; Du XY, 2017, Arxiv, DOI arXiv:1705.00106; GRAESSER AC, 1994, AM EDUC RES J, V31, P104, DOI 10.3102/00028312031001104; Heilman M., 2010, HUMAN LANGUAGE TECHN, P609; Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6; Ji TB, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24111514; Kim M., 2016, P 1 WORKSH REPR LEAR, P70; Klein T, 2019, Arxiv, DOI [arXiv:1911.02365, 10.48550/arXiv.1911.02365, DOI 10.48550/ARXIV.1911.02365]; Kriangchaivech K, 2019, Arxiv, DOI arXiv:1909.05017; Kulshreshtha D, 2022, Arxiv, DOI arXiv:2206.04187; Kurdi G, 2020, INT J ARTIF INTELL E, V30, P121, DOI 10.1007/s40593-019-00186-y; Lavie A., 2007, P 2 WORKSH STAT MACH, P228; Lehnert W. G., 1977, P 5 INT JOINT C ART, P158; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Ligthart A, 2021, APPL SOFT COMPUT, V101, DOI 10.1016/j.asoc.2020.107023; Lin B, 2019, PROC INT CONF SOFTW, P548, DOI 10.1109/ICSE.2019.00066; Lin C.-Y., 2002, P ACL 02 WORKSHOP AU, P74; Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11; Liu CY, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1957, DOI 10.1145/3292500.3330683; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu ZX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P29; Mohammadshahi A, 2023, FINDINGS ASS COMPUTA, P6845; Mulla N, 2023, PROG ARTIF INTELL, V12, P1, DOI 10.1007/s13748-023-00295-9; Ng N, 2019, Arxiv, DOI arXiv:1907.06616; Le NT, 2014, ADV INTELL SYST, V282, P325, DOI 10.1007/978-3-319-06569-4_24; OpenAI, 2021, OpenAI API; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paszke A, 2019, ADV NEUR IN, V32; Fabbri AR, 2020, Arxiv, DOI arXiv:2004.11892; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Raffel C, 2020, J MACH LEARN RES, V21; Rahardja Untung, 2019, 2019 Twelfth International Conference on Ubi-Media Computing (Ubi-Media). Proceedings, P168, DOI 10.1109/Ubi-Media.2019.00040; Rameshbhai CJ., 2019, Int. J. Electr. Comput. Eng. (IJECE), V9, P2152, DOI DOI 10.11591/IJECE.V9I3; Sellam T, 2020, Arxiv, DOI arXiv:2004.04696; Shazeer N, 2018, PR MACH LEARN RES, V80; Soomin Kim, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449161; Spearman C, 2010, INT J EPIDEMIOL, V39, P1137, DOI 10.1093/ije/dyq191; Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang R, 2019, IEEE ACCESS, V7, P41101, DOI 10.1109/ACCESS.2019.2906754; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang T., 2020, INT C LEARNING REPRE	51	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						66085	66099		10.1109/ACCESS.2024.3398553	http://dx.doi.org/10.1109/ACCESS.2024.3398553			15	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	RE9F3		gold			2024-07-03	WOS:001226102500001
J	Lim, EJ; Chowdhury, M; Higham, A; McKinnon, R; Ventoura, N; He, YV; de Pennington, N				Lim, Ernest Junwei; Chowdhury, Mohita; Higham, Aisling; McKinnon, Rory; Ventoura, Nikoletta; He, Yajie Vera; de Pennington, Nick			Can large language models safely address patient questions following cataract surgery?	INVESTIGATIVE OPHTHALMOLOGY & VISUAL SCIENCE			English	Meeting Abstract	Annual Meeting of the Association-for-Research-in-Vision-and-Ophthalmology (ARVO)	APR 23-27, 2023	New Orleans, LA	Assoc Res Vision & Ophthalmol					[Lim, Ernest Junwei; Chowdhury, Mohita; Higham, Aisling; McKinnon, Rory; Ventoura, Nikoletta; He, Yajie Vera; de Pennington, Nick] Ufonia Ltd, Oxford, England; [Lim, Ernest Junwei] Royal Free London NHS Fdn Trust, Ophthalmol, London, England; [Higham, Aisling] Royal Berkshire NHS Fdn Trust, Ophthalmol, Reading, England	University of London; University College London; Royal Free London NHS Foundation Trust; Royal Berkshire Hospital				Lim, Ernest/0000-0002-6972-0511					0	1	1	0	0	ASSOC RESEARCH VISION OPHTHALMOLOGY INC	ROCKVILLE	12300 TWINBROOK PARKWAY, ROCKVILLE, MD 20852-1606 USA	0146-0404	1552-5783		INVEST OPHTH VIS SCI	Invest. Ophthalmol. Vis. Sci.	JUN	2023	64	8							1214					4	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)	Ophthalmology	P9JE1					2024-07-03	WOS:001053758303146
J	Kambhampati, S				Kambhampati, Subbarao			Can large language models reason and plan?	ANNALS OF THE NEW YORK ACADEMY OF SCIENCES			English	Editorial Material								While humans sometimes do show the capability of correcting their own erroneous guesses with self-critiquing, there seems to be no basis for that assumption in the case of LLMs.	[Kambhampati, Subbarao] Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85287 USA	Arizona State University; Arizona State University-Tempe	Kambhampati, S (corresponding author), Arizona State Univ, Sch Comp & Augmented Intelligence, Tempe, AZ 85287 USA.	rao@asu.edu						Guan L., 2023, 37 C NEUR INF PROC S; Kahneman D., 2011, THINKING FAST SLOW; Kambhampati, 2023, 37 C NEUR INF PROC S; Kambhampati S., 2021, CACM BLOG; Kambhampati S., 2024, ARXIV; Kambhampati S, 2022, COMMUN ACM, V65, P8, DOI 10.1145/3546954; Kambhampati S, 2021, COMMUN ACM, V64, P31, DOI 10.1145/3446369; Kugel S., 2023, NEW YORK TIMES; Marquez, 2023, INT C AUT PLANN SCHE; Stechly K., 2023, NEURIPS 2023 FDN MOD; Valmeekam K., 2022, ARXIV PREPRINT; Valmeekam K., 2023, NEURIPS 2023 FDN MOD	12	0	0	0	0	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0077-8923	1749-6632		ANN NY ACAD SCI	Ann. N.Y. Acad. Sci.	APR	2024	1534	1					15	18		10.1111/nyas.15125	http://dx.doi.org/10.1111/nyas.15125		MAR 2024	4	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	NW9O9	38445711	Green Submitted			2024-07-03	WOS:001180382700001
J	Bakken, S				Bakken, Suzanne			What can you do with a large language model?	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Editorial Material									[Bakken, Suzanne] Columbia Univ, Data Sci Inst, Sch Nursing, Dept Biomed Informat, 630 W 168th St, New York, NY 10032 USA	Columbia University	Bakken, S (corresponding author), Columbia Univ, Data Sci Inst, Sch Nursing, Dept Biomed Informat, 630 W 168th St, New York, NY 10032 USA.	sbh22@cumc.columbia.edu						Litake O, 2024, J AM MED INFORM ASSN, V31, P1404, DOI 10.1093/jamia/ocae081; Liu SR, 2024, J AM MED INFORM ASSN, V31, P1367, DOI 10.1093/jamia/ocae052; Liu SR, 2024, J AM MED INFORM ASSN, V31, P1388, DOI 10.1093/jamia/ocae041; Murugan M, 2024, J AM MED INFORM ASSN, V31, P1356, DOI 10.1093/jamia/ocae039; Si YQ, 2019, J AM MED INFORM ASSN, V26, P1297, DOI 10.1093/jamia/ocz096; Xie KV, 2024, J AM MED INFORM ASSN, V31, P1348, DOI 10.1093/jamia/ocae047	6	0	0	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1217	1218		10.1093/jamia/ocae106	http://dx.doi.org/10.1093/jamia/ocae106			2	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38768444				2024-07-03	WOS:001227656400023
J	Youssef, A; Stein, S; Clapp, J; Magnus, D				Youssef, Alaa; Stein, Samantha; Clapp, Justin; Magnus, David			The Importance of Understanding Language in Large Language Models	AMERICAN JOURNAL OF BIOETHICS			English	Editorial Material									[Youssef, Alaa; Stein, Samantha; Magnus, David] Stanford Sch Med, Stanford, CA USA; [Stein, Samantha] Univ Calif Los Angeles, Dept Anthropol, Los Angeles, CA USA; [Clapp, Justin] Univ Penn, Perelman Sch Med, Philadelphia, PA USA; [Magnus, David] Stanford Univ, Stanford, CA 94305 USA	Stanford University; University of California System; University of California Los Angeles; University of Pennsylvania; Stanford University	Magnus, D (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	dmagnus@stanford.edu	; Youssef, Alaa/J-9559-2017	Magnus, David/0000-0002-0528-7341; Youssef, Alaa/0000-0001-6505-8236	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Batten JN, 2018, AM J BIOETHICS, V18, P1, DOI 10.1080/15265161.2018.1505107; Hohenstein J, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30938-9; Nov Oded, 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.1003537428540; Salles Arleen, 2020, AJOB Neurosci, V11, P88, DOI 10.1080/21507740.2020.1740350	4	0	0	6	12	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1526-5161	1536-0075		AM J BIOETHICS	Am. J. Bioeth.	OCT 3	2023	23	10					6	7		10.1080/15265161.2023.2256614	http://dx.doi.org/10.1080/15265161.2023.2256614			2	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	U2KH6	37812091	Bronze			2024-07-03	WOS:001083139600003
J	Mishra, V; Sarraju, A; Kalwani, NM; Dexter, JP				Mishra, Vishala; Sarraju, Ashish; Kalwani, Neil M.; Dexter, Joseph P.			Evaluation of Prompts to Simplify Cardiovascular Disease Information Generated Using a Large Language Model: Cross-Sectional Study	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						artificial intelligence; ChatGPT; GPT; digital health; large language model; NLP; language model; language models; prompt engineering; health communication; generative; health literacy; natural language processing; patient-physician communication; prevention; cardiology; cardiovascular; heart; education; educational; human-in-the-loop; machine learning	GPT-4	In this cross-sectional study, we evaluated the completeness, readability, and syntactic complexity of cardiovascular disease prevention information produced by GPT-4 in response to 4 kinds of prompts.	[Mishra, Vishala] Duke Univ, Sch Med, Dept Biostat & Bioinformat, Durham, NC USA; [Sarraju, Ashish] Cleveland Clin, Dept Cardiovasc Med, Cleveland, OH USA; [Kalwani, Neil M.] Vet Affairs Palo Alto Hlth Care Syst, Palo Alto, CA USA; [Kalwani, Neil M.] Stanford Univ, Sch Med, Dept Med, Div Cardiovasc Med, Stanford, CA USA; [Kalwani, Neil M.] Stanford Univ, Cardiovasc Inst, Sch Med, Dept Med, Stanford, CA USA; [Dexter, Joseph P.] Harvard Univ, Data Sci Initiat, Sci & Engn Complex 1-312-10,150 Western Ave, Allston, MA 02134 USA; [Dexter, Joseph P.] Harvard Univ, Dept Human Evolutionary Biol, Cambridge, MA USA; [Dexter, Joseph P.] Univ Macau, Inst Collaborat Innovat, Taipa, Macao, Peoples R China	Duke University; Cleveland Clinic Foundation; US Department of Veterans Affairs; Veterans Health Administration (VHA); VA Palo Alto Health Care System; Stanford University; Stanford University; Harvard University; Harvard University; University of Macau	Dexter, JP (corresponding author), Harvard Univ, Data Sci Initiat, Sci & Engn Complex 1-312-10,150 Western Ave, Allston, MA 02134 USA.	jdexter@fas.harvard.edu		Kalwani, Neil/0000-0003-0075-6206; Sarraju, Ashish/0000-0003-1649-2110	Harvard Data Science Fellowship; Institute of Collaborative Innovation at the University of Macau	Harvard Data Science Fellowship; Institute of Collaborative Innovation at the University of Macau	Acknowledgments We thank Stephen Blackwelder, PhD (Duke University Health System) , for helpful discussions and comments on the manuscript and Vasudha Mishra, MBBS (AIIMS Patna) , for assistance with data collection. JPD was supported by a Harvard Data Science Fellowship and the Institute of Collaborative Innovation at the University of Macau. The funders had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.	Chen S, 2024, J AM MED INFORM ASSN, V31, P940, DOI 10.1093/jamia/ocad256; Haver HL, 2023, AM J ROENTGENOL, V221, P701, DOI 10.2214/AJR.23.29622; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu XC, 2024, J MED INTERNET RES, V26, DOI 10.2196/51926; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Magnani JW, 2018, CIRCULATION, V138, pE48, DOI 10.1161/CIR.0000000000000579; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mirza FN., 2024, NEJM AI, V1, pAIcs2300145, DOI [10.1056/AIcs2300145, DOI 10.1056/AICS2300145]; Mishra V, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.18033; Pearson K, 2022, J MED INTERNET RES, V24, DOI 10.2196/31284; Sarraju Ashish, 2023, JACC Adv, V2, P100438, DOI 10.1016/j.jacadv.2023.100438; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Singh Nina, 2023, PLOS Digit Health, V2, pe0000367, DOI 10.1371/journal.pdig.0000367	14	0	0	10	10	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	APR 22	2024	26								e55388	10.2196/55388	http://dx.doi.org/10.2196/55388			6	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	PY1Q0	38648104	Green Accepted, gold			2024-07-03	WOS:001217552200002
J	Abid, A; Farooqi, M; Zou, J				Abid, Abubakar; Farooqi, Maheen; Zou, James			Large language models associate Muslims with violence	NATURE MACHINE INTELLIGENCE			English	Editorial Material									[Abid, Abubakar] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA; [Farooqi, Maheen] McMaster Univ, Dept Hlth Res Methods Evidence & Impact, Hamilton, ON, Canada; [Zou, James] Stanford Univ, Dept Biomed Data Sci, Stanford, CA 94305 USA	Stanford University; McMaster University; Stanford University	Zou, J (corresponding author), Stanford Univ, Dept Biomed Data Sci, Stanford, CA 94305 USA.	jamesz@stanford.edu		/0000-0002-8701-3351	NSF CAREER [1942926]; Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr [1942926] Funding Source: National Science Foundation	NSF CAREER(National Science Foundation (NSF)NSF - Office of the Director (OD)); Div Of Information & Intelligent Systems; Direct For Computer & Info Scie & Enginr(National Science Foundation (NSF)NSF - Directorate for Computer & Information Science & Engineering (CISE))	We thank A. Abid, A. Abdalla, D. Khan, and M. Ghassemi for the helpful feedback on the manuscript and experiments. J.Z. is supported by NSF CAREER 1942926.	[Anonymous], 2013, Efficient estimation of word representations in vector space; BENDER EM, 2021, ACM C FAIR ACC TRANS, P610; Bolukbasi T., 2016, Proceedings of the 30th International Conference on Neural Information Processing Systems, V29, P1; Bordia S., 2019, P C N AM CHAPT ASS C; Brown T. B., 2020, P ADV NEUR INF PROC; Dai A. M., 2015, ADV NEURAL INFORM PR, P3079; Kitaev N., 2020, P INT C LEARN REPR I; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Li X., PREPRINT; Lu Kaiji, 2020, LOGIC LANGUAGE SECUR, P189; Nadeem M., 2020, PREPRINT; Qian Y., 2019, PREPRINT; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Wallace E., 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing, P2153	14	32	36	5	11	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	JUN	2021	3	6					461	463		10.1038/s42256-021-00359-2	http://dx.doi.org/10.1038/s42256-021-00359-2			3	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	SV9GP					2024-07-03	WOS:000664126400003
J	Venerito, V; Puttaswamy, D; Iannone, F; Gupta, L				Venerito, Vincenzo; Puttaswamy, Darshan; Iannone, Florenzo; Gupta, Latika			Large language models and rheumatology: a comparative evaluation	LANCET RHEUMATOLOGY			English	Editorial Material									[Venerito, Vincenzo; Iannone, Florenzo] Univ Bari Aldo Moro, Dept Precis & Regenerat Med, Bari, Italy; [Venerito, Vincenzo; Iannone, Florenzo] Univ Bari Aldo Moro, Ionian Area Rheumatol Unit, Bari, Italy; [Puttaswamy, Darshan] Seth Gordhandhas Sunderdas Med Coll & King Edward, Mumbai, Maharashtra, India; [Gupta, Latika] Royal Wolverhampton Hosp NHS Trust, Dept Rheumatol, Wolverhampton WV10 0QP, England; [Gupta, Latika] Univ Manchester, Manchester Acad Hlth Sci Ctr, Fac Biol Med & Hlth,Ctr Musculoskeletal Res, Sch Biol Sci,Div Musculoskeletal & Dermatol Sci, Manchester, England; [Gupta, Latika] Sandwell & West Birmingham Hosp NHS Trust, City Hosp, Dept Rheumatol, Birmingham, England	Universita degli Studi di Bari Aldo Moro; Universita degli Studi di Bari Aldo Moro; University of Manchester; University of Birmingham	Gupta, L (corresponding author), Royal Wolverhampton Hosp NHS Trust, Dept Rheumatol, Wolverhampton WV10 0QP, England.; Gupta, L (corresponding author), Univ Manchester, Manchester Acad Hlth Sci Ctr, Fac Biol Med & Hlth,Ctr Musculoskeletal Res, Sch Biol Sci,Div Musculoskeletal & Dermatol Sci, Manchester, England.; Gupta, L (corresponding author), Sandwell & West Birmingham Hosp NHS Trust, City Hosp, Dept Rheumatol, Birmingham, England.	drlatikagupta@gmail.com	Gupta, Latika/C-9507-2018					Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Venerito V, 2023, RHEUMATOLOGY, V62, P3256, DOI 10.1093/rheumatology/kead291	5	6	6	2	2	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2665-9913			LANCET RHEUMATOL	Lancet Rheumatol.	OCT	2023	5	10					E574	E578		10.1016/S2665-9913(23)00216-3	http://dx.doi.org/10.1016/S2665-9913(23)00216-3		SEP 2023	5	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	U5JC4					2024-07-03	WOS:001085152400001
J	Restrepo, D; Rodman, A; Abdulnour, RE				Restrepo, Daniel; Rodman, Adam; Abdulnour, Raja-Elie			Conversations on reasoning: Large language models in diagnosis	JOURNAL OF HOSPITAL MEDICINE			English	Article; Early Access							ACCURACY		[Restrepo, Daniel] Massachusetts Gen Hosp, Dept Med, Boston, MA 02114 USA; [Restrepo, Daniel; Rodman, Adam; Abdulnour, Raja-Elie] Harvard Med Sch, Boston, MA USA; [Rodman, Adam] Beth Israel Deaconess Med Ctr, Dept Med, Boston, MA USA; [Abdulnour, Raja-Elie] Brigham & Womens Hosp, Dept Med, Boston, MA USA	Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School; Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Brigham & Women's Hospital	Restrepo, D (corresponding author), Massachusetts Gen Hosp, Dept Med, Boston, MA 02114 USA.	Drestrepo1@mgh.harvard.edu		Rodman, Adam/0000-0001-8452-0692; Abdulnour, Raja-Elie/0000-0002-8053-0145				Cabral S, 2024, JAMA INTERN MED, DOI 10.1001/jamainternmed.2024.0295; Custers EJFM, 2015, MED TEACH, V37, P457, DOI 10.3109/0142159X.2014.956052; Dreicer JJ, 2023, PERSPECT MED EDUC, V12, P294, DOI 10.5334/pme.947; Hirosawa T, 2023, AM J MED, V136, P1119, DOI 10.1016/j.amjmed.2023.08.003; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; St Clair E W, 1999, Curr Opin Rheumatol, V11, P47, DOI 10.1097/00002281-199901000-00008; Strong E, 2023, JAMA INTERN MED, V183, P1028, DOI 10.1001/jamainternmed.2023.2909	7	0	0	0	0	JOHN WILEY & SONS INC	Hoboken	111 River St., Hoboken, NJ, UNITED STATES	1553-5592	1553-5606		J HOSP MED	J. Hosp. Med.	2024 APR 28	2024										10.1002/jhm.13378	http://dx.doi.org/10.1002/jhm.13378		APR 2024	5	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	OR5H8	38678438				2024-07-03	WOS:001209008700001
J	Kuo, DP; Chen, YC; Li, YT; Cheng, SJ; Hsieh, KLC; Kuo, PC; Ou, CY; Chen, CY				Kuo, Duen-Pang; Chen, Yung-Chieh; Li, Yi-Tien; Cheng, Sho-Jen; Hsieh, Kevin Li-Chun; Kuo, Po-Chih; Ou, Chen-Yin; Chen, Cheng-Yu			Estimating the volume of penumbra in rodents using DTI and stack-based ensemble machine learning framework	EUROPEAN RADIOLOGY EXPERIMENTAL			English	Article						Animals; Diffusion tensor imaging; Infarction (middle cerebral artery); Ischemic stroke; Machine learning	ARTERIAL INPUT FUNCTION; ISCHEMIC-STROKE; TISSUE VIABILITY; INFARCT CORE; DIFFUSION; PERFUSION; CLASSIFICATION; METRICS; PERFORMANCE; ANISOTROPY	Background This study investigates the potential of diffusion tensor imaging (DTI) in identifying penumbral volume (PV) compared to the standard gadolinium-required perfusion-diffusion mismatch (PDM), utilizing a stack-based ensemble machine learning (ML) approach with enhanced explainability. Methods Sixteen male rats were subjected to middle cerebral artery occlusion. The penumbra was identified using PDM at 30 and 90 min after occlusion. We used 11 DTI-derived metrics and 14 distance-based features to train five voxel-wise ML models. The model predictions were integrated using stack-based ensemble techniques. ML-estimated and PDM-defined PVs were compared to evaluate model performance through volume similarity assessment, the Pearson correlation analysis, and Bland-Altman analysis. Feature importance was determined for explainability. Results In the test rats, the ML-estimated median PV was 106.4 mL (interquartile range 44.6-157.3 mL), whereas the PDM-defined median PV was 102.0 mL (52.1-144.9 mL). These PVs had a volume similarity of 0.88 (0.79-0.96), a Pearson correlation coefficient of 0.93 (p < 0.001), and a Bland-Altman bias of 2.5 mL (2.4% of the mean PDM-defined PV), with 95% limits of agreement ranging from -44.9 to 49.9 mL. Among the features used for PV prediction, the mean diffusivity was the most important feature. Conclusions Our study confirmed that PV can be estimated using DTI metrics with a stack-based ensemble ML approach, yielding results comparable to the volume defined by the standard PDM. The model explainability enhanced its clinical relevance. Human studies are warranted to validate our findings.	[Kuo, Duen-Pang; Chen, Yung-Chieh; Cheng, Sho-Jen; Hsieh, Kevin Li-Chun; Chen, Cheng-Yu] Taipei Med Univ Hosp, Dept Med Imaging, 250 Wu Hsing St, Taipei, Taiwan; [Kuo, Duen-Pang; Chen, Yung-Chieh; Li, Yi-Tien; Cheng, Sho-Jen; Hsieh, Kevin Li-Chun; Ou, Chen-Yin; Chen, Cheng-Yu] Taipei Med Univ Hosp, Translat Imaging Res Ctr, Taipei, Taiwan; [Li, Yi-Tien] Taipei Med Univ, Res Ctr Neurosci, Taipei, Taiwan; [Li, Yi-Tien] Taipei Med Univ, Coll Med Sci & Technol, PhD Program Med Neurosci, Taipei, Taiwan; [Kuo, Po-Chih] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan; [Chen, Cheng-Yu] Taipei Med Univ, Res Ctr Artificial Intelligence Med, Taipei, Taiwan; [Kuo, Duen-Pang; Chen, Yung-Chieh; Hsieh, Kevin Li-Chun; Chen, Cheng-Yu] Taipei Med Univ, Coll Med, Sch Med, Dept Radiol, Taipei, Taiwan; [Chen, Cheng-Yu] Natl Def Med Ctr, Dept Radiol, Taipei, Taiwan	Taipei Medical University; Taipei Medical University Hospital; Taipei Medical University Hospital; Taipei Medical University; Taipei Medical University; Taipei Medical University; National Tsing Hua University; Taipei Medical University; Taipei Medical University; National Defense Medical Center	Chen, YC (corresponding author), Taipei Med Univ Hosp, Dept Med Imaging, 250 Wu Hsing St, Taipei, Taiwan.; Chen, YC (corresponding author), Taipei Med Univ Hosp, Translat Imaging Res Ctr, Taipei, Taiwan.; Chen, YC (corresponding author), Taipei Med Univ, Coll Med, Sch Med, Dept Radiol, Taipei, Taiwan.	rendell.medical@gmail.com		Chen, Yung-Chieh/0000-0002-0333-428X	Taipei Medical University Hospital	Taipei Medical University Hospital	The authors would like to acknowledge the Laboratory Animal Center at Taipei Medical University for technical support in this experiment. The original innovations, figures, tables, and methods were created without using any large language model.	Abe Y, 2017, PLOS BIOL, V15, DOI 10.1371/journal.pbio.2001494; Ahmad MA, 2018, IEEE INT CONF HEALT, P447, DOI [10.1145/3233547.3233667, 10.1109/ICHI.2018.00095]; Alfi IA, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12030726; Bauer E, 1999, MACH LEARN, V36, P105, DOI 10.1023/A:1007515423169; Behroozi M, 2018, MAGN RESON MED, V79, P1090, DOI 10.1002/mrm.26722; Brereton RG, 2015, J CHEMOMETR, V29, P143, DOI 10.1002/cem.2692; Brugnara G, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-40564-8; Calamante F, 2002, STROKE, V33, P1146, DOI 10.1161/01.STR.0000014208.05597.33; Calamante F, 2013, PROG NUCL MAG RES SP, V74, P1, DOI 10.1016/j.pnmrs.2013.04.002; Cauley KA, 2013, AM J ROENTGENOL, V200, P1327, DOI 10.2214/AJR.12.9816; Chang SC, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101784; Chiu FY, 2018, KOREAN J RADIOL, V19, P1161; Copen WA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188891; Copen WA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133566; Cortez-Conradis D, 2013, EUR RADIOL, V23, P1112, DOI 10.1007/s00330-012-2688-7; Dzeroski S, 2004, MACH LEARN, V54, P255, DOI 10.1023/B.MAC.0000015881.36452.6e; Edelman RR, 2019, J MAGN RESON IMAGING, V49, P355, DOI 10.1002/jmri.26288; Ferreira RM, 2010, AM J ROENTGENOL, V194, P1330, DOI 10.2214/AJR.09.2845; France SL, 2012, INFORM SCIENCES, V184, P92, DOI 10.1016/j.ins.2011.07.048; Green HAL, 2002, STROKE, V33, P1517, DOI 10.1161/01.STR.0000016973.80180.7B; Hastie T, 1995, Stat Methods Med Res, V4, P187, DOI 10.1177/096228029500400302; Kalagotla SK, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104554; Khan PW, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-35476-y; Kim BJ, 2014, J STROKE, V16, P131, DOI 10.5853/jos.2014.16.3.131; Kuo DP, 2020, J BIOMED SCI, V27, DOI 10.1186/s12929-020-00672-9; Kuo DP, 2017, KOREAN J RADIOL, V18, P269, DOI 10.3348/kjr.2017.18.2.269; Lee H, 2020, STROKE, V51, P860, DOI 10.1161/STROKEAHA.119.027611; Legrand L, 2015, AM J NEURORADIOL, V36, P269, DOI 10.3174/ajnr.A4088; Legrand L, 2019, EUR RADIOL, V29, P5567, DOI 10.1007/s00330-019-06094-y; LONGA EZ, 1989, STROKE, V20, P84, DOI 10.1161/01.STR.20.1.84; Lopez-Mejia M, 2016, J STROKE CEREBROVASC, V25, P515, DOI 10.1016/j.jstrokecerebrovasdis.2015.10.033; Lu XY, 2023, BMC MED INFORM DECIS, V23, DOI 10.1186/s12911-023-02159-7; Malan NS, 2019, COMPUT BIOL MED, V107, P118, DOI 10.1016/j.compbiomed.2019.02.009; Meng XJ, 2004, ANN NEUROL, V55, P207, DOI 10.1002/ana.10803; Mohammed A, 2023, J KING SAUD UNIV-COM, V35, P757, DOI 10.1016/j.jksuci.2023.01.014; Moon WJ, 2005, KOREAN J RADIOL, V6, P75, DOI 10.3348/kjr.2005.6.2.75; Myles AJ, 2004, J CHEMOMETR, V18, P275, DOI 10.1002/cem.873; Nael K, 2014, STROKE, V45, P1985, DOI 10.1161/STROKEAHA.114.005305; Odegua R., 2019, P C DEEP LEARN INDAB, DOI [10.13140/RG.2.2.35180.10882, DOI 10.13140/RG.2.2.35180.10882]; Oppenheim C, 2001, STROKE, V32, P2486, DOI 10.1161/hs1101.098331; Pitkonen M, 2012, BRAIN RES, V1445, P103, DOI 10.1016/j.brainres.2012.01.043; Proskura P, 2022, 2022 5 INT C ART INT, P78, DOI [10.1145/3573942.3573954, DOI 10.1145/3573942.3573954]; Prosser J, 2005, STROKE, V36, P1700, DOI 10.1161/01.STR.0000173407.40773.17; Puig J, 2013, STROKE, V44, P1162, DOI 10.1161/STROKEAHA.111.678110; Ramchoun H, 2016, INT J INTERACT MULTI, V4, P26, DOI 10.9781/ijimai.2016.415; Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235; Renjith Arokia, 2015, Journal of Medical Engineering & Technology, V39, P498, DOI 10.3109/03091902.2015.1094148; Reyes D, 2022, STROKE, V53, P3439, DOI 10.1161/STROKEAHA.121.038101; Rivers CS, 2005, CEREBROVASC DIS, V19, P328, DOI 10.1159/000084691; Shen Q, 2004, J CEREBR BLOOD F MET, V24, P887, DOI 10.1097/01.WCB.0000124321.60992.87; Smith SM, 2004, NEUROIMAGE, V23, pS208, DOI 10.1016/j.neuroimage.2004.07.051; Tae WS, 2018, J CLIN NEUROL, V14, P129, DOI 10.3988/jcn.2018.14.2.129; Taha AA, 2015, BMC MED IMAGING, V15, DOI 10.1186/s12880-015-0068-x; Thomalla G, 2018, NEW ENGL J MED, V379, P611, DOI 10.1056/NEJMoa1804355; Tourdias T, 2009, NEUROIMAGE, V47, P659, DOI 10.1016/j.neuroimage.2009.04.070; Urbanski M, 2011, EXP BRAIN RES, V208, P491, DOI 10.1007/s00221-010-2496-8; Vagal A, 2019, NEUROLOGY, V93, P888, DOI 10.1212/WNL.0000000000008481; Wang K, 2020, STROKE, V51, P489, DOI 10.1161/STROKEAHA.119.027457; Wang YY, 2019, APPL SOFT COMPUT, V77, P188, DOI 10.1016/j.asoc.2019.01.015; Yang W, 2012, J COMPUT, V7, P161, DOI 10.4304/jcp.7.1.161-168; Yu YN, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.220882; Zhu XQ, 2022, FRONT PHARMACOL, V13, DOI 10.3389/fphar.2022.975855; Zolal A, 2012, EUR J RADIOL, V81, P1877, DOI 10.1016/j.ejrad.2011.04.074; Zolbanin HM, 2015, DECIS SUPPORT SYST, V74, P150, DOI 10.1016/j.dss.2015.04.003	64	0	0	0	0	SPRINGER WIEN	Vienna	Prinz-Eugen-Strasse 8-10, A-1040 Vienna, AUSTRIA		2509-9280		EUR RADIOL EXP	Eur. Radiol. Exp.	MAY 15	2024	8	1							59	10.1186/s41747-024-00455-z	http://dx.doi.org/10.1186/s41747-024-00455-z			14	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	QR9M4	38744784	gold			2024-07-03	WOS:001222715300001
J	Zhang, Y; Deriu, J; Katsogiannis-Meimarakis, G; Kosten, C; Koutrika, G; Stockinger, K				Zhang, Yi; Deriu, Jan; Katsogiannis-Meimarakis, George; Kosten, Catherine; Koutrika, Georgia; Stockinger, Kurt			ScienceBenchmark: A Complex Real-World Benchmark for Evaluating Natural Language to SQL Systems	PROCEEDINGS OF THE VLDB ENDOWMENT			English	Article								Natural Language to SQL systems (NL-to-SQL) have recently shown improved accuracy (exceeding 80%) for natural language to SQL query translation due to the emergence of transformer-based language models, and the popularity of the Spider benchmark. However, Spider mainly contains simple databases with few tables, columns, and entries, which do not reflect a realistic setting. Moreover, complex real-world databases with domain-specific content have little to no training data available in the form of NL/SQL-pairs leading to poor performance of existing NL-to-SQL systems. In this paper, we introduce ScienceBenchmark, a new complex NL-to-SQL benchmark for three real-world, highly domain-specific databases. For this new benchmark, SQL experts and domain experts created high-quality NL/SQL-pairs for each domain. To garner more data, we extended the small amount of human-generated data with synthetic data generated using GPT-3. We show that our benchmark is highly challenging, as the top performing systems on Spider achieve a very low performance on our benchmark. Thus, the challenge is many-fold: creating NL-to-SQL systems for highly complex domains with a small amount of hand-made training data augmented with synthetic data. To our knowledge, ScienceBenchmark is the first NL-to-SQL benchmark designed with complex real-world scientific databases, containing challenging training and test data carefully validated by domain experts.	[Zhang, Yi; Deriu, Jan; Kosten, Catherine; Stockinger, Kurt] Zurich Univ Appl Sci, Zurich, Switzerland; [Katsogiannis-Meimarakis, George; Koutrika, Georgia] Athena Res Ctr, Athens, Greece	Zurich University of Applied Sciences	Zhang, Y (corresponding author), Zurich Univ Appl Sci, Zurich, Switzerland.				European Union [863410]	European Union(European Union (EU))	This project has received funding from the European Union's Horizon 2020 research and innovation program under grant agreement No 863410. We also thank Jonathan Furst and Farhad Nooralahzadeh for their contributions in evaluating large language models.	Affolter K, 2019, VLDB J, V28, P793, DOI 10.1007/s00778-019-00567-8; Amer-Yahia S, 2021, SIGMOD REC, V50, P23; [Anonymous], 1995, Natural Language Engineering, DOI DOI 10.1017/S135132490000005X; Blunschi L, 2012, Arxiv, DOI arXiv:1207.0134; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brunner U, 2021, PROC INT CONF DATA, P2177, DOI 10.1109/ICDE51399.2021.00220; Deriu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P897; Finegan-Dollak C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P351; Gan YJ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2030; Gan YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2505; Guo DY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1597; Guo JQ, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4524; Hazoom M, 2021, NLP4PROG 2021: THE 1ST WORKSHOP ON NATURAL LANGUAGE PROCESSING FOR PROGRAMMING (NLP4PROG 2021), P77; Hazoom Moshe, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.05006; Honovich Or, 2022, arXiv; Hwang W, 2019, Arxiv, DOI [arXiv:1902.01069, 10.48550/ARXIV.1902.01069, 10.48550/arXiv.1902.01069]; Iacob RCA, 2020, P 28 INT C COMP LING, P381, DOI [DOI 10.18653/V1/2020.COLING-MAIN.34, 10.18653, DOI 10.18653/V1/2020.COLING-MAIN.342]; Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089; Katsogiannis-Meimarakis G, 2023, VLDB J, V32, P905, DOI 10.1007/s00778-022-00776-8; Lee CH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2261; Li F, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P709, DOI 10.1145/2588555.2594519; Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468; Li JY, 2023, Arxiv, DOI arXiv:2305.03111; Ma PC, 2021, PROC VLDB ENDOW, V15, P569, DOI 10.14778/3494124.3494139; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Popescu A.-M., 2003, IUI 03. 2003 International Conference on Intelligent User Interfaces, P149, DOI 10.1145/604045.604070; Post M., 2018, P 3 C MACHINE TRANSL, P186, DOI [10.18653/v1/W18-6319, DOI 10.18653/V1/W18-6319]; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Roller R., 2015, P BIONLP 15, P12, DOI [DOI 10.18653/V1/W15-3802, 10.18653/v1/W15-3802]; Rossiello G., 2017, P MULTILING 2017 WOR, P12, DOI DOI 10.18653/V1/W17-1003; Rubin O, 2021, SPNLP 2021: THE 5TH WORKSHOP ON STRUCTURED PREDICTION FOR NLP, P12; Saha D, 2016, PROC VLDB ENDOW, V9, P1209, DOI 10.14778/2994509.2994536; Scholak T, 2021, Arxiv, DOI arXiv:2109.05093; Sen J, 2020, Proceedings of the VLDB Endowment, V13, P2747, DOI [10.14778/3407790, DOI 10.14778/3407790, 10.14778/3407790.3407858, DOI 10.14778/3407790.3407858]; Simitsis A, 2008, VLDB J, V17, P117, DOI 10.1007/s00778-007-0075-9; SZALAY AS, 2002, P 2002 ACM SIGMOD IN, P00570, DOI DOI 10.1145/564691.564758; Tang LR, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P133; Tao Y., 2021, INT C LEARNING REPRE; Vaswani A, 2017, ADV NEUR IN, V30; Wang BL, 2021, Arxiv, DOI [arXiv:1911.04942, DOI 10.48550/ARXIV.1911.04942]; Wang P, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P350, DOI 10.1145/3366423.3380120; Weir N, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2347, DOI 10.1145/3318464.3380589; Wu K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8974; Xu XJ, 2017, Arxiv, DOI [arXiv:1711.04436, 10.48550/arXiv.1711.04436]; Yaghmazadeh N, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133887; Yu T, 2019, Arxiv, DOI arXiv:1809.08887; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zhang J., 2023, P AAAI C ARTIFICIAL, P13067; Zhong VC, 2017, Arxiv, DOI arXiv:1709.00103	51	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2150-8097			PROC VLDB ENDOW	Proc. VLDB Endow.	DEC	2023	17	4					685	698		10.14778/3636218.3636225	http://dx.doi.org/10.14778/3636218.3636225			14	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OJ6G0		Green Submitted			2024-07-03	WOS:001206935800007
C	Sevastjanova, R; Vogelbacher, S; Spitz, A; Keim, D; El-Assady, M			IEEE	Sevastjanova, Rita; Vogelbacher, Simon; Spitz, Andreas; Keim, Daniel; El-Assady, Mennatallah			Visual Comparison of Text Sequences Generated by Large Language Models	2023 IEEE VISUALIZATION IN DATA SCIENCE, VDS			English	Proceedings Paper	IEEE Conference on Visualization in Data Science (VDS)	OCT 15-16, 2023	Melbourne, AUSTRALIA	IEEE, IEEE Comp Soc, IEEE VGTC		Causal Language Models; Text Generation; Prompt Output Comparison		Causal language models have emerged as the leading technology for automating text generation tasks. Although these models tend to produce outputs that resemble human writing, they still suffer from quality issues (e.g., social biases). Researchers typically use automatic analysis methods to evaluate the model limitations, such as statistics on stereotypical words. Since different types of issues are embedded in the model parameters, the development of automated methods that capture all relevant aspects remains a challenge. To tackle this challenge, we propose a visual analytics approach that supports the exploratory analysis of text sequences generated by causal language models. Our approach enables users to specify starting prompts and effectively groups the resulting text sequences. To this end, we leverage a unified, ontology-driven embedding space, serving as a shared foundation for the thematic concepts present in the generated text sequences. Visual summaries provide insights into various levels of granularity within the generated data. Among others, we propose a novel comparison visualization that slices the embedding space and represents the differences between two prompt outputs in a radial layout. We demonstrate the effectiveness of our approach through case studies, showcasing its potential to reveal model biases and other quality issues.	[Sevastjanova, Rita; Vogelbacher, Simon; Spitz, Andreas; Keim, Daniel] Univ Konstanz, Constance, Germany; [El-Assady, Mennatallah] ETH AI Ctr, Zurich, Switzerland	University of Konstanz	Sevastjanova, R (corresponding author), Univ Konstanz, Constance, Germany.	rita.sevastjanova@uni-konstanz.de; simon.vogelhacher@uni-konstanz.de; andreas.spitz@uni-konstanz.de; daniel.keim@uni-konstanz.de; melassady@ethz.ch			Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [BU 1806/10-2, FOR2111]; ETH AI Center	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG)); ETH AI Center	This paper was supported by funding from the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) within projects BU 1806/10-2 "Questions Visualized" of the FOR2111 and the ETH AI Center.	Alnegheimish S., 2022, PROC 2022 C N AM CHA, P2824, DOI DOI 10.18653/V1/2022.NAACL-MAIN.2032; Bandyopadhyay S., 2022, PROC AAAI C ARTIFICI, V36, P12713, DOI [10.1609/aaai.v36i11.21548, DOI 10.1609/AAAI.V36I11.21548]; Boggust A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P746, DOI 10.1145/3490099.3511122; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cheng M., 2023, Long Papers, V1, P1504, DOI DOI 10.18653/V1/2023.ACL-LONG.842,3,4,7; DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976; Eisenstein J, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4326; El-Assady M, 2022, 2022 IEEE 4TH WORKSHOP ON VISUALIZATION GUIDELINES IN RESEARCH, DESIGN, AND EDUCATION (VISGUIDES 2022), P16, DOI 10.1109/VisGuides57787.2022.00008; El-Assady M, 2020, IEEE T VIS COMPUT GR, V26, P1001, DOI 10.1109/TVCG.2019.2934654; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507; Feder A, 2022, T ASSOC COMPUT LING, V10, P1138, DOI 10.1162/tacl_a_00511; Gleicher M, 2018, IEEE T VIS COMPUT GR, V24, P413, DOI 10.1109/TVCG.2017.2744199; Gleicher M, 2011, INFORM VISUAL, V10, P289, DOI 10.1177/1473871611416549; Hausdorff F., 1914, Grundzuge der Mengenlehre, V7, DOI [10.1007/BF01999507, DOI 10.1007/BF01999507]; Heimerl F, 2022, IEEE T VIS COMPUT GR, V28, P2953, DOI 10.1109/TVCG.2020.3045918; Huang Z, 2023, COMPUT GRAPH FORUM, V42, P539, DOI 10.1111/cgf.14859; Joshi A, 2018, COMM COM INF SC, V781, P275, DOI 10.1007/978-981-10-8438-6_22; Kalouli A.-L., 2022, PROC 29 INT C COMPUT, P3074; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Lauscher A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4782; Liu SS, 2019, IEEE T VIS COMPUT GR, V25, P651, DOI 10.1109/TVCG.2018.2865230; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Miksch S, 2014, COMPUT GRAPH-UK, V38, P286, DOI 10.1016/j.cag.2013.11.002; Navigli R, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P216; Nozza D, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2398; OpenAI, 2023, GPT-4 Technical Report; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758; Sevastjanova R, 2022, COMPUT GRAPH FORUM, V41, P295, DOI 10.1111/cgf.14541; Sevastjanova Rita, 2023, IEEE Trans Vis Comput Graph, V29, P1178, DOI 10.1109/TVCG.2022.3209458; Sivaraman V, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P418, DOI 10.1145/3490099.3511137; Strobelt H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P96; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100	41	0	0	1	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3020-5				2023							11	20		10.1109/VDS60365.2023.00007	http://dx.doi.org/10.1109/VDS60365.2023.00007			10	Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3PO					2024-07-03	WOS:001141278600003
C	Wadhwa, S; Amir, S; Wallace, BC		Rogers, A; Boyd-Graber, J; Okazaki, N		Wadhwa, Somin; Amir, Silvio; Wallace, Byron C.			Revisiting Relation Extraction in the era of Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Relation extraction (RE) is the core NLP task of inferring semantic relationships between entities from text. Standard supervised RE techniques entail training modules to tag tokens comprising entity spans and then predict the relationship between them. Recent work has instead treated the problem as a sequence-to-sequence task, linearizing relations between entities as target strings to be generated conditioned on the input. Here we push the limits of this approach, using larger language models (GPT-3 and Flan-T5 large) than considered in prior work and evaluating their performance on standard RE tasks under varying levels of supervision. We address issues inherent to evaluating generative approaches to RE by doing human evaluations, in lieu of relying on exact matching. Under this refined evaluation, we find that: (1) Few-shot prompting with GPT-3 achieves near SOTA performance, i.e., roughly equivalent to existing fully supervised models; (2) Flan-T5 is not as capable in the few-shot setting, but supervising and fine-tuning it with Chain-of-Thought (CoT) style explanations (generated via GPT-3) yields SOTA results. We release this model as a new baseline for RE tasks(1).	[Wadhwa, Somin; Amir, Silvio; Wallace, Byron C.] Northeastern Univ, Boston, MA 02115 USA	Northeastern University	Wadhwa, S (corresponding author), Northeastern Univ, Boston, MA 02115 USA.	wadhwa.s@northeastern.edu; s.amir@northeastern.edu; b.wallace@northeastern.edu			National Institutes of Health (NIH) under the National Library of Medicine (NLM) [R01LM012086]; National Science Foundation (NSF) [III-1750978]	National Institutes of Health (NIH) under the National Library of Medicine (NLM); National Science Foundation (NSF)(National Science Foundation (NSF))	This work was supported in part by the National Institutes of Health (NIH) under the National Library of Medicine (NLM) grant R01LM012086 and by the National Science Foundation (NSF) grant III-1750978.	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cabot PLH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2370; Chen MD, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P3558; Chen XH, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2195; Chung H.W., 2022, SCALING INSTRUCTION; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eberts M., 2019, arXiv preprint arXiv:1909.07755; Eberts M, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3650; Eberts Markus, 2019, ABS190907755 ARXIV; Gurulingappa H, 2012, J BIOMED INFORM, V45, P885, DOI 10.1016/j.jbi.2012.04.008; Lafferty J., 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.5555/645530.655813; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li X, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P17; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Lu YJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5755; Min SW, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2791; Nayak Tapas, 2020, AAAI C ART INT; Paolini G, 2021, INT C LEARN REPR; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Riedel Sebastian, 2010, ECML PKDD; Taboureau O, 2011, NUCLEIC ACIDS RES, V39, pD367, DOI 10.1093/nar/gkq906; Taille B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3689; Tsochantaridis I., 2004, ICML; Wang CG, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P803; Wang J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1706; Wei Jason, 2022, arXiv:2201.11903; Wei Jason, 2022, ABS210901652 ARXIV; Xu Hanwei, 2022, ABS220106910 CORR; Yao Y., 2021, P 2021 C EMPIRICAL M, P4452, DOI https://doi.org/10.18653/v1/2021.emnlp-main.366; Yao Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P764; Ye QY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7163; Zeng Daojian, 2020, ABS191110438 ARXIV; Zeng XR, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P506	36	8	8	7	8	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							15566	15589						24	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT	37674787	Green Accepted, Green Submitted, hybrid			2024-07-03	WOS:001190962507021
J	Efremova, M; Kubiak, E; Baron, S; Bernard, D				Efremova, Maria; Kubiak, Emeric; Baron, Simon; Bernard, David			Large Language Models: Opportunities and Challenges For Cognitive Assessment	EUROPEAN JOURNAL OF PSYCHOLOGY OPEN			English	Meeting Abstract									[Efremova, Maria; Kubiak, Emeric; Baron, Simon; Bernard, David] Assessfirst, London, England				Bernard, David/D-6265-2018; Efremova, Maria/KHE-4424-2024	Efremova, Maria/0009-0005-9317-4310					0	0	0	1	1	HOGREFE AG-HOGREFE AG SUISSE	BERN	LANGGASS STRASSE 76, BERN, SWITZERLAND	2673-8627			EUR J PSYCHOL OPEN	Eur. J. Psychol. Open	OCT	2023	82			1		1201	133	134						2	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	W4KY5					2024-07-03	WOS:001091341700237
J	[Anonymous]				[Anonymous]			Prepare for truly useful large language models	NATURE BIOMEDICAL ENGINEERING			English	Editorial Material								The consequences of their use will be far reaching.										Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, NAT MACH INTELL, V5, P1; [Anonymous], 2022, NAT BIOMED ENG, V6, P1319; Dehghani M., 2023, arXiv; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Zhang A, 2022, NAT BIOMED ENG, V6, P1330, DOI 10.1038/s41551-022-00898-y	10	4	4	2	9	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2157-846X			NAT BIOMED ENG	Nat. Biomed. Eng	FEB	2023	7	2					85	86		10.1038/s41551-023-01012-6	http://dx.doi.org/10.1038/s41551-023-01012-6			2	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	9S8QP	36882584				2024-07-03	WOS:000946601700001
