PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Zhang, CY; Wang, XY; Wang, ZY				Zhang, Chengyi; Wang, Xingyu; Wang, Ziyun			Large language model in electrocatalysis	CHINESE JOURNAL OF CATALYSIS			English	Article						Large language model; Electrocatalysis; Artificial intelligence; Multimodal large language model	MOLECULAR-DYNAMICS	Large language models have recently brought a massive storm on modern society in all fields. While many view them as mere search engines for specific answers or text refinement tools like a chatbot, their broader applications remain largely unexplored. These large language models, consisting of billions of interconnected neurons, derived from all knowledge of the human, possess the remarkable ability to engage in smooth and precise conversations with individuals across the globe. Human-like intelligence enables them to address modern challenges and display immense potential in various scientific domains. In this perspective, we delve into the potential applications of modern large language model and its future iterations within the field of catalysis, aiming to shed light on how these AI-driven models can contribute to a deeper understanding of catalysis science and the intelligent design of catalysts. Published by Elsevier B.V. All rights reserved.	[Zhang, Chengyi; Wang, Xingyu; Wang, Ziyun] Univ Auckland, Sch Chem Sci, Auckland 1010, New Zealand	University of Auckland	Wang, ZY (corresponding author), Univ Auckland, Sch Chem Sci, Auckland 1010, New Zealand.	ziyun.wang@auckland.ac.nz						Abe T, 1997, J COMPUT PHYS, V131, P241, DOI 10.1006/jcph.1996.5595; Abou Hamad I, 2010, PHYS CHEM CHEM PHYS, V12, P2740, DOI 10.1039/b920970k; Borgesson L, 1996, Developments in geotechnical engineering, P565; CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; KOHN W, 1965, PHYS REV, V140, P1133, DOI 10.1103/PhysRev.140.A1133; Liu FL, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00952-2; Liu MJ, 2021, J CHEM INF MODEL, V61, P2686, DOI 10.1021/acs.jcim.0c01480; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Perniss P, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01109; Rubenstein PK, 2023, Arxiv, DOI arXiv:2306.12925; Rudd RE, 1998, PHYS REV B, V58, pR5893, DOI 10.1103/PhysRevB.58.R5893; Seh ZW, 2017, SCIENCE, V355, DOI 10.1126/science.aad4998; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Topsakal O., 2023, INT C APPL ENG NATUR, V1, P1050; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang Z., 2022, Clipgen: Languagefree training of a texttoimage generator with clip. arXiv preprint arXiv:2203.00386; Weiss T, 2023, NAT COMPUT SCI, V3, P873, DOI 10.1038/s43588-023-00532-0; Zheng ZL, 2023, ANGEW CHEM INT EDIT, V62, DOI 10.1002/anie.202311983	20	0	0	7	7	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0253-9837	1872-2067		CHINESE J CATAL	Chin. J. Catal.	APR	2024	59						7	14		10.1016/S1872-2067(23)64612-1	http://dx.doi.org/10.1016/S1872-2067(23)64612-1			8	Chemistry, Applied; Chemistry, Physical; Engineering, Chemical	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering	SU8L1					2024-07-03	WOS:001237050600001
C	He, ZK; Xie, ZH; Jha, R; Steck, H; Liang, DW; Feng, YS; Majumder, BP; Kallus, N; McAuley, J			ACM	He, Zhankui; Xie, Zhouhang; Jha, Rahul; Steck, Harald; Liang, Dawen; Feng, Yesu; Majumder, Bodhisattwa Prasad; Kallus, Nathan; McAuley, Julian			Large Language Models as Zero-Shot Conversational Recommenders	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		conversational recommendation; large language model; datasets		In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in "in-the-wild" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders.	[He, Zhankui; Xie, Zhouhang; Majumder, Bodhisattwa Prasad; McAuley, Julian] Univ Calif San Diego, La Jolla, CA 92093 USA; [Jha, Rahul; Steck, Harald; Liang, Dawen; Feng, Yesu; Kallus, Nathan] Netflix Inc, Los Gatos, CA USA; [Kallus, Nathan] Cornell Univ, New York, NY USA	University of California System; University of California San Diego; Netflix, Inc.; Cornell University	He, ZK (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.	zhh004@eng.ucsd.edu; zhx022@ucsd.edu; rahuljha@netflix.com; hsteck@netflix.com; dliang@netflix.com; yfeng@netflix.com; bmajumde@eng.ucsd.edu; nkallus@netflix.com; jmcauley@ucsd.edu		Liang, Dawen/0009-0002-9701-6473; Kallus, Nathan/0000-0003-1672-0507; McAuley, Julian/0000-0003-0955-7588				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Bajaj P, 2018, Arxiv, DOI arXiv:1611.09268; Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen JW, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3564284; Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI [10.1007/s11257-011-9108-6, 10.1007/s11257-011-9115-7]; Chen QB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1803; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christakopoulou K, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P815, DOI 10.1145/2939672.2939746; Cui Z., 2022, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Friedman L, 2023, Arxiv, DOI arXiv:2305.07961; Ge YQ, 2024, Arxiv, DOI arXiv:2207.12515; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; Hayati SA, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8142; He XN, 2018, ACM/SIGIR PROCEEDINGS 2018, P355, DOI 10.1145/3209978.3209981; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; He ZK, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P288, DOI 10.1145/3523227.3546755; He ZK, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3088, DOI 10.1145/3459637.3482136; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Izacard Gautier, 2021, INT C LEARN REPR; Jhamtani H, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1661; Kabbur S, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P659; Kang D, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1951; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kim C, 2022, OpenAI, V2022; Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263; Lei WQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2073, DOI 10.1145/3394486.3403258; Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Li M, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3587153; Li R, 2018, ADV NEUR IN, V31; Li SK, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P223, DOI 10.1145/3477495.3532074; Li Shuyang, 2021, arXiv; Li Y., 2017, P 8 INT JOINT C NATU, P986; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liang DW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P689, DOI 10.1145/3178876.3186150; Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Lu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1161; Ma Wenchang, 2021, P 2021 C EMPIRICAL M; Ouyang L., 2022, NEURIPS; Penha G, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P388, DOI 10.1145/3383313.3412249; Ren ZC, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P165, DOI 10.1145/3477495.3532077; Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127; Salemi A, 2024, Arxiv, DOI arXiv:2304.11406; Sanh Victor., 2022, 10 INT C LEARNING RE; Sedhain S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P111, DOI 10.1145/2740908.2742726; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Tay Y., 2022, Advances in Neural Information Processing Systems, V35, P21831; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wang XL, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1929, DOI 10.1145/3534678.3539382; Wei JS, 2022, ADV NEUR IN; Wu G, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P137, DOI 10.1145/3298689.3347009; Xu CW, 2023, Arxiv, DOI [arXiv:2304.01196, DOI 10.48550/ARXIV.2304.01196]; Zhang YM, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2153, DOI 10.1145/3485447.3512088; Zhang YZ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P270; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng QK, 2023, Arxiv, DOI [arXiv:2303.17568, 10.48550/arXiv.2303.17568]; Zhou K, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1893, DOI 10.1145/3340531.3411954; Zhou K, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1006, DOI 10.1145/3394486.3403143; Zhou Kun, 2020, P 28 INT C COMPUTATI, P4128, DOI [10.18653/v1/2020.coling-main.365, DOI 10.18653/V1/2020.COLING-MAIN.365]; Zou J, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2319, DOI 10.1145/3477495.3531852	75	3	3	21	21	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							720	730		10.1145/3583780.3614949	http://dx.doi.org/10.1145/3583780.3614949			11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Submitted, hybrid			2024-07-03	WOS:001161549500073
J	O'Leary, DE				O'Leary, Daniel E.			Enterprise large language models: Knowledge characteristics, risks, and organizational activities	INTELLIGENT SYSTEMS IN ACCOUNTING FINANCE & MANAGEMENT			English	Editorial Material						BARD; BlenderBot; ChatGPT; ChatGPT Business; ChatGPT Enterprise; enterprise generative AI; enterprise large language model (ELLM); experimental analysis; expertise; generative AI manipulation; generative AI systems (GAIS); human-in-the-loop; large language models (LLM)		Since the release of OpenAI's ChatGPT, there has been substantial interest in and concern about generative AI systems. This paper investigates some of the characteristics, risks, and limitations with the enterprise use of enterprise large language models. In so doing, we study the organizational impact, continuing a long line of research on that topic. This paper examines the impact on expertise, the organizational implications of multiple correlated but different responses to the same query, the potential concerns associated with sensitive information and intellectual property, and some applications that likely would not be appropriate for large language models. We also investigate the possibility of agents potentially manipulating the content in these large language models for their own benefit. Finally, we investigate the emerging phenomenon of "ChatBot Enterprise" versions, including some of the implications and concerns of such enterprise large language models.	[O'Leary, Daniel E.] Univ Southern Calif, Marshall Sch Business, Los Angeles, CA 90007 USA	University of Southern California	O'Leary, DE (corresponding author), Univ Southern Calif, Marshall Sch Business, Los Angeles, CA 90007 USA.	oleary@usc.edu		O'Leary, Daniel Edmund/0000-0002-5240-9516				Degeurin M., 2022, Meta's new AI chatbot loves anti-racism and mean girls; Duchessi P., 1993, Intell Syst Account Financ Manag, V2, P151, DOI [10.1002/j.1099-1174.1993.tb00039.x, DOI 10.1002/J.1099-1174.1993.TB00039.X]; Field H., 2023, OpenAI launches ChatGPT Enterprise, the company's biggest announcement since ChatGPT's debut; Gartner, 2023, Gartner experts answer the top generative AI questions for your enterprise; Madrigal A., 2013, IBM's Watson memorized the entire 'Urban Dictionary,' then his overlords had to delete it; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; Neumeister L., 2023, Lawyers submitted bogus case law created by ChatGPT. A judge fined them $5; O'Leary D. E., 2003, International Journal of Accounting Information Systems, V4, P275, DOI 10.1016/j.accinf.2003.09.001; O'Leary D. E., 1997, AI & Society, V11, P36, DOI 10.1007/BF02812437; O'Leary DE, 2023, AI MAG, V44, P282, DOI 10.1002/aaai.12118; O'Leary DE, 2023, INTELL SYST ACCOUNT, V30, P41, DOI 10.1002/isaf.1531; O'Leary DE, 2022, INTELL SYST ACCOUNT, V29, P182, DOI 10.1002/isaf.1522; O'Leary DE, 2019, INTELL SYST ACCOUNT, V26, P46, DOI 10.1002/isaf.1443; O'Leary DE, 2015, J EMERG TECHNOL ACCO, V12, P71, DOI 10.2308/jeta-51225; O'Leary DE, 2000, IEEE INTELL SYST APP, V15, P72, DOI 10.1109/MIS.2000.1227234; OLEARY DE, 1987, HUM SYST MANAGE, V7, P11; OpenAI, 2023, Introducing ChatGPT enterprise; Schaul Kevin, 2023, Inside the secret list of websites that make AI like ChatGPT sound smart; Sun J, 2022, Arxiv, DOI arXiv:2211.00922; Vincent J., 2016, The Verge, V24, P2016	20	1	1	33	63	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1055-615X	1099-1174		INTELL SYST ACCOUNT	Intell. Syst. Account. Financ. Manag.	JUL	2023	30	3					113	119		10.1002/isaf.1541	http://dx.doi.org/10.1002/isaf.1541			7	Business, Finance	Emerging Sources Citation Index (ESCI)	Business & Economics	T0XO0					2024-07-03	WOS:001075306700001
C	Koyejo, S; Li, B			Assoc computing machinery	Koyejo, Sanmi; Li, Bo			Towards Trustworthy Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Trustworthy Large Language Models; AI Security; AI safety; Algorithmic Fairness		Large Language models are among the most exciting technologies developed in the last few years. While the model's capabilities continue to improve, researchers, practitioners, and the general public are increasingly aware of some of its shortcomings. What will it take to build trustworthy large language models? This tutorial will present a range of recent findings, discussions, questions, and partial answers in the space of trustworthiness in large language models. While this tutorial will not attempt a comprehensive overview of this rich area, we aim to provide the participants with some tools and insights and to understand both the conceptual foundations of trustworthiness and a broad range of ongoing research efforts. We will tackle some of the hard questions that you may have about trustworthy large language models and hopefully address some misconceptions that have become pervasive.	[Koyejo, Sanmi] Stanford Univ, Stanford, CA 94305 USA; [Li, Bo] Univ Chicago, Chicago, IL 60637 USA	Stanford University; University of Chicago	Koyejo, S (corresponding author), Stanford Univ, Stanford, CA 94305 USA.	sanmi@cs.stanford.edu; bol@uchicago.edu		Koyejo, Oluwasanmi/0000-0002-4023-419X	National Science Foundation [2046795, 2205329]	National Science Foundation(National Science Foundation (NSF))	National Science Foundation award number(s): 2046795, 2205329	Schaeffer Rylan, 2023, 37 C NEUR INF PROC S; Wang Boxin, 2023, Thirty- seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track.; Xu Chejian, 2023, 2 WORKSH NEW FRONT A	3	0	0	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1126	1127		10.1145/3616855.3636454	http://dx.doi.org/10.1145/3616855.3636454			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100136
J	Hobensack, M; von Gerich, H; Vyas, P; Withall, J; Peltonen, LM; Block, LJ; Davies, S; Chan, RY; Van Bulck, L; Cho, HY; Paquin, R; Mitchell, J; Topaz, M; Song, JY				Hobensack, Mollie; von Gerich, Hanna; Vyas, Pankaj; Withall, Jennifer; Peltonen, Laura-Maria; Block, Lorraine J.; Davies, Shauna; Chan, Ryan; Van Bulck, Liesbet; Cho, Hwayoung; Paquin, Robert; Mitchell, James; Topaz, Maxim; Song, Jiyoun			A rapid review on current and potential uses of large language models in nursing	INTERNATIONAL JOURNAL OF NURSING STUDIES			English	Article						Rapid review; Nursing informatics; Large language models; Generative AI; ChatGPT	ARTIFICIAL-INTELLIGENCE; CHATGPT	Background: The application of large language models across commercial and consumer contexts has grown exponentially in recent years. However, a gap exists in the literature on how large language models can support nursing practice, education, and research. This study aimed to synthesize the existing literature on current and potential uses of large language models across the nursing profession. Methods: A rapid review of the literature, guided by Cochrane rapid review methodology and PRISMA reporting standards, was conducted. An expert health librarian assisted in developing broad inclusion criteria to account for the emerging nature of literature related to large language models. Three electronic databases (i.e., PubMed, CINAHL, and Embase) were searched to identify relevant literature in August 2023. Articles that discussed the development, use, and application of large language models within nursing were included for analysis. Results: The literature search identified a total of 2028 articles that met the inclusion criteria. After systematically reviewing abstracts, titles, and full texts, 30 articles were included in the final analysis. Nearly all (93 %; n = 28) of the included articles used ChatGPT as an example, and subsequently discussed the use and value of large language models in nursing education (47 %; n = 14), clinical practice (40 %; n = 12), and research (10 %; n = 3). While the most common assessment of large language models was conducted by human evaluation (26.7 %; n = 8), this analysis also identified common limitations of large language models in nursing, including lack of systematic evaluation, as well as other ethical and legal considerations. Discussion: This is the first review to summarize contemporary literature on current and potential uses of large language models in nursing practice, education, and research. Although there are significant opportunities to apply large language models, the use and adoption of these models within nursing have elicited a series of challenges, such as ethical issues related to bias, misuse, and plagiarism. Conclusion: Given the relative novelty of large language models, ongoing efforts to develop and implement meaningful assessments, evaluations, standards, and guidelines for applying large language models in nursing are recommended to ensure appropriate, accurate, and safe use. Future research along with clinical and educational partnerships is needed to enhance understanding and application of large language models in nursing and healthcare. (c) 2024 Elsevier Ltd. All rights reserved.	[Hobensack, Mollie] Icahn Sch Med Mt Sinai, Brookdale Dept Geriatr & Palliat Med, New York, NY 10029 USA; [von Gerich, Hanna] Univ Turku, Dept Nursing Sci, Turku, Finland; [Vyas, Pankaj] Univ Arizona, Coll Nursing, Tucson, AZ USA; [Withall, Jennifer] Columbia Univ, Dept Biomed Informat, New York, NY USA; [Peltonen, Laura-Maria] Univ Turku, Turku Univ Hosp, Dept Nursing Sci, Res Serv, Turku, Finland; [Block, Lorraine J.] Univ British Columbia, Sch Nursing, Vancouver, BC, Canada; [Davies, Shauna] Univ Regina, Fac Nursing, Regina, SK, Canada; [Chan, Ryan] Western Univ, Arthur Labatt Family Sch Nursing, London, ON, Canada; [Van Bulck, Liesbet] KU Leuven Univ Leuven, Dept Publ Hlth & Primary Care, Leuven, Belgium; [Cho, Hwayoung] Univ Florida, Coll Nursing, Gainesville, FL USA; [Paquin, Robert] Kings Coll London, Fac Nursing Midwifery & Palliat Care, London, England; [Mitchell, James] Univ Colorado, Dept Biomed Informat, Sch Med, Denver, CO USA; [Topaz, Maxim] Columbia Univ, Sch Nursing, Data Sci Inst, VNS Hlth, New York, NY USA; [Song, Jiyoun] Univ Penn, Sch Nursing, Dept Biobehav Hlth Sci, Philadelphia, PA USA	Icahn School of Medicine at Mount Sinai; University of Turku; University of Arizona; Columbia University; University of Turku; University of British Columbia; University of Regina; Western University (University of Western Ontario); KU Leuven; State University System of Florida; University of Florida; University of London; King's College London; University of Colorado System; University of Colorado Anschutz Medical Campus; University of Colorado Denver; Columbia University; University of Pennsylvania	Hobensack, M (corresponding author), Icahn Sch Med Mt Sinai, Brookdale Dept Geriatr & Palliat Med, New York, NY 10029 USA.	mollie.hobensack@mssm.edu	Topaz, Maxim/AAQ-7121-2021	Topaz, Maxim/0000-0002-2358-9837; Peltonen, Laura-Maria/0000-0001-5740-6480				Abdulai AF, 2023, NURS INQ, V30, DOI 10.1111/nin.12556; Ahmed SK, 2023, ANN BIOMED ENG, V51, P2351, DOI 10.1007/s10439-023-03262-6; Ainsley MacLean, 2023, Making friends' with ChatGPT: a guide to best practices for AI interactions; Alanzi TM, 2023, J MULTIDISCIP HEALTH, V16, P2309, DOI 10.2147/JMDH.S419847; Allen C, 2023, INT J NURS STUD, V145, DOI 10.1016/j.ijnurstu.2023.104522; [Anonymous], 2002, MED DEVICES REGULATI; [Anonymous], Large Language Models and software as a medical device; [Anonymous], How do I cite generative AI in MLA style; [Anonymous], Generative AI & LLMs in health & medicine; [Anonymous], ChatGPT and other generative AI tools: thinking about ChatGPT; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Berse S, 2024, ANN BIOMED ENG, V52, P130, DOI 10.1007/s10439-023-03296-w; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Castonguay A, 2023, NURS EDUC TODAY, V129, DOI 10.1016/j.nedt.2023.105916; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; Clarke Y.D., 2022, HR 6580 117 C 2021 2; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Crossnohere NL, 2022, J MED INTERNET RES, V24, DOI 10.2196/36823; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Draganic Keri, 2023, Nurse Pract, V48, P6, DOI 10.1097/01.NPR.0000000000000023; EU AI Act, first regulation on artificial intelligence; Fraser D, 2023, NEONATAL NETW, V42, P115, DOI 10.1891/NN-2023-0027; Frith KH, 2023, NURS EDUC PERSPECT, V44, P198, DOI 10.1097/01.NEP.0000000000001129; Garritty C, 2020, HEALTH RES POLICY SY, V18, DOI 10.1186/s12961-020-00624-7; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Goto A, 2023, J EPIDEMIOL, V33, P333, DOI 10.2188/jea.JE20230078; Gottlieb S, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.3909; Gunawan J, 2023, BELITUNG NURS J, V9, P1, DOI 10.33546/bnj.2551; Health Infoway C, 2023, Toolkit for Implementers of Artificial Intelligence in Health Care; Hunter J, 2012, ARTIF INTELL MED, V56, P157, DOI 10.1016/j.artmed.2012.09.002; Ibrahim H, 2021, CLIN EXP OPHTHALMOL, V49, P470, DOI 10.1111/ceo.13943; Irwin P, 2023, NURS EDUC TODAY, V127, DOI 10.1016/j.nedt.2023.105835; Jin WA, 2023, MED IMAGE ANAL, V84, DOI 10.1016/j.media.2022.102684; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kurtzman ET, 2022, J NURS REGUL, V13, P49, DOI 10.1016/S2155-8256(22)00061-8; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li T., 2023, Cochrane Handbook for Systematic Reviews of Interventionsvol, V6; Lyon D, 2023, ONCOL NURS FORUM, V50, P276, DOI 10.1188/23.ONF.276-277; McAdoo T., 2024, How to cite ChatGPT; Miao Hongyu, 2023, Asian Pac Isl Nurs J, V7, pe48136, DOI 10.2196/48136; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Nashwan Abdulqadir J, 2023, Cureus, V15, pe40542, DOI 10.7759/cureus.40542; National Academies of Sciences E and M, 2023, P WORKSH ART INT HEL, DOI [10.17226/27174, DOI 10.17226/27174]; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Odom-Forren J, 2023, J PERIANESTH NURS, V38, P176, DOI 10.1016/j.jopan.2023.02.006; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Ray PP, 2024, EUR J CARDIOVASC NUR, V23, pe11, DOI 10.1093/eurjcn/zvad047; Reunamo Akseli, 2022, Stud Health Technol Inform, V290, P632, DOI 10.3233/SHTI220154; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scerri A, 2023, J CLIN NURS, V32, P4211, DOI 10.1111/jocn.16677; Sun GH, 2023, NURS EDUC, V48, P119, DOI 10.1097/NNE.0000000000001390; Taira Kazuya, 2023, JMIR Nurs, V6, pe47305, DOI 10.2196/47305; Tam W, 2023, NURS EDUC TODAY, V129, DOI 10.1016/j.nedt.2023.105917; Thakur A, 2023, TEACH LEARN NURS, V18, P450, DOI 10.1016/j.teln.2023.03.011; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tiase V.L., 2023, The Future of Nursing 2020-2030: Global Applications to Advance Health Equity, P131, DOI [10.1007/978-3-031-29746-5_10, DOI 10.1007/978-3-031-29746-5_10]; Van Bulck L, 2024, EUR J CARDIOVASC NUR, V23, P95, DOI 10.1093/eurjcn/zvad038; Vitorino LM, 2023, J CLIN NURS, V32, P7921, DOI 10.1111/jocn.16706; von Gerich H, 2022, INT J NURS STUD, V127, DOI 10.1016/j.ijnurstu.2021.104153; who, WHO outlines considerations for regulation of artificial intelligence for health; Woodnutt S, 2024, J PSYCHIATR MENT HLT, V31, P79, DOI 10.1111/jpm.12965; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Zong H, 2023, medRxiv, DOI [10.1101/2023.07.09.23292415, 10.1101/2023.07.09.23292415, DOI 10.1101/2023.07.09.23292415]	63	3	3	38	38	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0020-7489	1873-491X		INT J NURS STUD	Int. J. Nurs. Stud.	JUN	2024	154								104753	10.1016/j.ijnurstu.2024.104753	http://dx.doi.org/10.1016/j.ijnurstu.2024.104753		MAR 2024	8	Nursing	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Nursing	PA5R5	38560958				2024-07-03	WOS:001211377500001
J	Zhecheva, D				Zhecheva, Denitsa			Exploratory Data Analysis and the Rise of Large Language Models - Gaming Industry Insights	TEM JOURNAL-TECHNOLOGY EDUCATION MANAGEMENT INFORMATICS			English	Article						Large language models; exploratory data analysis; gaming industry; generative artificial intelligence; natural language processing		The applications of modern large language models are diverse and new at the same time. It is forecasted that the scientific society and businesses may experience a long period of time exploring all opportunities and challenges for using them which will allow analysis of the impact on how advanced generative artificial intelligence is changing work occupation activities and performance efficiency. Undoubtedly, today's question that every business must answer is not if but how to implement large language models, due to their ability to transform numerous business processes. This study aims to give a better understanding on how large language models are contributing to the process of exploratory data analysis as they are not here to replace the traditional methods but to add generative artificial intelligence capabilities to the well-established ones. The results of this paper reveal high level of accuracy of the paired output between operation prompts in OpenAI's large language model and human-mediated entry. However, such output comparison highlighs the need for more informative and specific input prompts to ascertain this accuracy. Further caveats that need to be placed in consideration refer to possible system downtimes, as well as the expenses incurred with every prompt execution. Nevertheless, the comparative speed of operation of large language models remains their most substantial competitive advantage. Overall, the findings in this paper contribute to understanding that large language models streamline with ease the desired extraction of insightful information which may further be used for better decision-making, good data management, and design of winning growth strategy as is the case of the gaming industry	[Zhecheva, Denitsa] Konstantin Preslavsky Univ Shumen, Univ Str 115, Shumen, Bulgaria	University of Shumen	Zhecheva, D (corresponding author), Konstantin Preslavsky Univ Shumen, Univ Str 115, Shumen, Bulgaria.	mrszhecheva.denitsa@gmail.com						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amer-Yahia S, 2023, Arxiv, DOI [arXiv:2306.01388, DOI 10.48550/ARXIV.2306.01388]; Biswas S., 2023, Journal of ENT Surgery Research, V1, P01; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Choi J H, 2023, Journal of Legal Education, P1; Chopra A., 2013, Int. J. Technol. enhancements Emerg. Eng. Res, V1, P131; Clement J., 2022, Digital games industry revenue worldwide in 2020, by game category; Clement J., 2023, Games market revenue worldwide from 2015 to 2022, by region; Collins E., 2021, Lamda: Our breakthrough conversation technology; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Grow A, 2023, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON GAME JAMS, HACKATHONS AND GAME CREATION EVENTS, ICGJ 2023, P51, DOI 10.1145/3610602.3610605; Gupta A, 2023, Arxiv, DOI [arXiv:2308.12466, 10.48550/arXiv.2308.12466, DOI 10.48550/ARXIV.2308.12466]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kings M., 2023, Leveling Up the Playing Field: Exploring the Strengths and Weaknesses of AI-Generated Content in Game Development; Ma L, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P2895, DOI 10.1109/BigData.2015.7364114; Nguyen Huy A., 2023, Responsive and Sustainable Educational Futures: 18th European Conference on Technology Enhanced Learning, EC-TEL 2023, Proceedings. Lecture Notes in Computer Science (14200), P278, DOI 10.1007/978-3-031-42682-7_19; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pilipiszyn A., 2021, Gpt-3 powers the next generation of apps; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; SCHMIDHUBER J, 1992, NEURAL COMPUT, V4, P131, DOI 10.1162/neco.1992.4.1.131; Srinath K.R., 2017, International Research Journal of Engineering and Technology, V4, P354; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tukey J.W., 1977, EXPLORATORY DATA ANA; Vaswani A, 2017, ADV NEUR IN, V30; Wongsuphasawat K, 2019, Arxiv, DOI [arXiv:1911.00568, 10.48550/arXiv.1911.00568, DOI 10.48550/ARXIV.1911.00568]; Yang ZL, 2019, ADV NEUR IN, V32; Zwang D., 2017, Senet and Twenty Squares: Two Board Games Played by Ancient Egyptians	31	0	0	7	7	UIKTEN - ASSOC INFORMATION COMMUNICATION TECHNOLOGY EDUCATION & SCIENCE	NOVI PAZAR	HILMA ROZAJCA 15, NOVI PAZAR, 36300, SERBIA	2217-8309	2217-8333		TEM J	TEM J.	FEB	2024	13	1					561	569		10.18421/TEM131-59	http://dx.doi.org/10.18421/TEM131-59			9	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	KJ1X3		gold			2024-07-03	WOS:001179511200037
C	Iyengar, A; Kundu, A			IEEE	Iyengar, Arun; Kundu, Ashish			Large Language Models and Computer Security	2023 5TH IEEE INTERNATIONAL CONFERENCE ON TRUST, PRIVACY AND SECURITY IN INTELLIGENT SYSTEMS AND APPLICATIONS, TPS-ISA			English	Proceedings Paper	5th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications (TPS-ISA)	NOV 01-03, 2023	Atlanta, GA	IEEE, IEEE Comp Soc		Large language models; security; privacy; cyberattacks; malware; phishing attacks		Large language models (LLMs) are having a significant impact in many different fields. Security and privacy issues related to LLMs are of paramount importance. LLMs can be used to defend against cyberattacks and thwart attackers. LLMs can enhance computer security in several ways including identifying phishing attacks, identifying malware, analyzing incident reports from security breaches, determining vulnerability to attacks, analzying log information, and providing valuable information, education, and training materials. However, large language models can also be used by malicious parties to enhance cyberattacks. This paper looks at how LLMs can be used by both defenders and attackers. We also examine attacks on large language models which have been deployed to cause LLMs to output harmful information.	[Iyengar, Arun; Kundu, Ashish] Cisco Res, Yorktown Hts, NY 10598 USA		Iyengar, A (corresponding author), Cisco Res, Yorktown Hts, NY 10598 USA.	ariyenga@cisco.com; ashkundu@cisco.com						Ammann P., 2002, Proceedings of the 9th ACM conference on Computer and communications security, in CCS'02, P217, DOI [10.1145/586110.586140, DOI 10.1145/586110.586140]; Aslan Ö, 2020, IEEE ACCESS, V8, P6249, DOI 10.1109/ACCESS.2019.2963724; Basit A, 2021, TELECOMMUN SYST, V76, P139, DOI 10.1007/s11235-020-00733-2; Bringer M.L., 2012, Int. J. Comput. Netw. Inf. Secur., V4, P63; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Charan PVS, 2023, Arxiv, DOI arXiv:2305.15336; Gupta BB, 2018, TELECOMMUN SYST, V67, P247, DOI 10.1007/s11235-017-0334-z; Gupta M., 2023, IEEE Access; Hazell J, 2023, Arxiv, DOI arXiv:2305.06972; Heiding F, 2023, Arxiv, DOI arXiv:2308.12287; Hong J, 2012, COMMUN ACM, V55, P74, DOI 10.1145/2063176.2063197; Jain AK, 2022, ENTERP INF SYST-UK, V16, P527, DOI 10.1080/17517575.2021.1896786; Koide T, 2024, Arxiv, DOI arXiv:2306.05816; Krsul I.V., 1998, SOFTWARE VULNERABILI; Liu Y, 2024, Arxiv, DOI [arXiv:2305.13860, DOI 10.48550/ARXIV.2305.13860, 10.48550/arXiv.2305.13860]; Mokube Iyatiti, 2007, Proceedings of the 45th ACM Southeast Conference. ACMSE 07, P321, DOI 10.1145/1233341.1233399; Mozes M, 2023, Arxiv, DOI arXiv:2308.12833; Nataraj L., 2011, VIZSEC 11, P1; Nawrocki M, 2016, Arxiv, DOI arXiv:1608.06249; P. Security, 2023, The red report 2023: The top 10 mitre att&ck techniques used by adversaries; Phillips C, 1999, NEW SECURITY PARADIGMS WOEKSHOP, PROCEEDINGS, P71; Provos N, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P1; Shen XY, 2024, Arxiv, DOI [arXiv:2308.03825, 10.48550/arXiv.2308.03825]; Strom BE, 2018, MITRE ATT CK DESIGN; Suarez-Tangil G, 2017, PROCEEDINGS OF THE SEVENTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY (CODASPY'17), P309, DOI 10.1145/3029806.3029825; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Ucci D, 2019, COMPUT SECUR, V81, P123, DOI 10.1016/j.cose.2018.11.001; Wei A., 2023, arXiv; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; You I., 2010, P 2010 INT C BROADB, P297, DOI [10.1109/BWCCA.2010.85, DOI 10.1109/BWCCA.2010.85]; Zhou YJ, 2012, P IEEE S SECUR PRIV, P95, DOI 10.1109/SP.2012.16; Zou A, 2023, Arxiv, DOI arXiv:2307.15043	33	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2385-6				2023							307	313		10.1109/TPS-ISA58951.2023.00045	http://dx.doi.org/10.1109/TPS-ISA58951.2023.00045			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6HT					2024-07-03	WOS:001174354000035
J	Bonnechere, B				Bonnechere, Bruno			Unlocking the Black Box? A Comprehensive Exploration of Large Language Models in Rehabilitation	AMERICAN JOURNAL OF PHYSICAL MEDICINE & REHABILITATION			English	Article						Large Language Model; Black-Box; Rehabilitation; Research; Methods		Rehabilitation is a vital component of health care, aiming to restore function and improve the well-being of individuals with disabilities or injuries. Nevertheless, the rehabilitation process is often likened to a "black box," with complexities that pose challenges for comprehensive analysis and optimization. The emergence of large language models offers promising solutions to better understand this "black box." Large language models excel at comprehending and generating human-like text, making them valuable in the healthcare sector. In rehabilitation, healthcare professionals must integrate a wide range of data to create effective treatment plans, akin to selecting the best ingredients for the "black box." Large language models enhance data integration, communication, assessment, and prediction.This article delves into the ground-breaking use of large language models as a tool to further understand the rehabilitation process. Large language models address current rehabilitation issues, including data bias, contextual comprehension, and ethical concerns. Collaboration with healthcare experts and rigorous validation is crucial when deploying large language models. Integrating large language models into rehabilitation yields insights into this intricate process, enhancing data-driven decision making, refining clinical practices, and predicting rehabilitation outcomes. Although challenges persist, large language models represent a significant stride in rehabilitation, underscoring the importance of ethical use and collaboration.	[Bonnechere, Bruno] Hasselt Univ, Fac Rehabil Sci, REVAL Rehabil Res Ctr, Diepenbeek, Belgium; [Bonnechere, Bruno] Hasselt Univ, Data Sci Inst, Technol Supported & Data Driven Rehabil, Diepenbeek, Belgium; [Bonnechere, Bruno] PXL Univ Appl Sci & Arts, Dept PXL Healthcare, Hasselt, Belgium; [Bonnechere, Bruno] Agoralaan Bldg,Wetenschapspk 7, B-3590 Diepenbeek, Belgium	Hasselt University; Hasselt University	Bonnechere, B (corresponding author), Agoralaan Bldg,Wetenschapspk 7, B-3590 Diepenbeek, Belgium.	bruno.bonnechere@uhasselt.be						Adans-Dester C, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00328-w; Cieza A, 2020, LANCET, V396, P2006, DOI 10.1016/S0140-6736(20)32340-0; Fernandes MB, 2023, EXPERT SYST APPL, V214, DOI 10.1016/j.eswa.2022.119171; Fu SY, 2022, INT J MED INFORM, V162, DOI 10.1016/j.ijmedinf.2022.104736; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lin DJ, 2023, JAMA NEUROL, V80, P339, DOI 10.1001/jamaneurol.2023.0044; Liu Siru, 2023, medRxiv, DOI 10.1101/2023.07.14.23292669; Perlis RH, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.35924; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Sinaci AA, 2020, METHOD INFORM MED, V59, pE21, DOI 10.1055/s-0040-1713684; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Van Stan JH, 2019, ARCH PHYS MED REHAB, V100, P146, DOI 10.1016/j.apmr.2018.09.112; Wagner AK, 2014, J SPINAL CORD MED, V37, P493, DOI 10.1179/2045772314Y.0000000248; Watters C, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1224976; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Whyte J, 2003, AM J PHYS MED REHAB, V82, P639, DOI 10.1097/01.PHM.0000078200.61840.2D; Wilhelm TI, 2023, J MED INTERNET RES, V25, DOI 10.2196/49324; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhang Liang, 2023, J Rehabil Med, V55, pjrm13373, DOI 10.2340/jrm.v55.13373	20	0	0	4	4	LIPPINCOTT WILLIAMS & WILKINS	PHILADELPHIA	TWO COMMERCE SQ, 2001 MARKET ST, PHILADELPHIA, PA 19103 USA	0894-9115	1537-7385		AM J PHYS MED REHAB	Am. J. Phys. Med. Rehabil.	JUN	2024	103	6					532	537		10.1097/PHM.0000000000002440	http://dx.doi.org/10.1097/PHM.0000000000002440			6	Rehabilitation; Sport Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Rehabilitation; Sport Sciences	RG6A4	38261757				2024-07-03	WOS:001226541200001
J	Mori, Y; Izumiyama, T; Kanabuchi, R; Mori, N; Aizawa, T				Mori, Yu; Izumiyama, Takuya; Kanabuchi, Ryuichi; Mori, Naoko; Aizawa, Toshimi			Large language model may assist diagnosis of SAPHO syndrome by bone scintigraphy	MODERN RHEUMATOLOGY			English	Article; Early Access						Artificial intelligence; bone scintigraphy; large language model; palmoplantar pustulosis; SAPHO syndrome	PUSTULOSIS	Objective In this study, we employed a large language model to evaluate the diagnostic efficacy of radiology reports of bone scintigraphy in the context of identifying SAPHO syndrome, and further examined the potential of such a model to augment the diagnostic procedure.Methods Imaging data and clinical information of 151 patients (105/46 women/men, mean age: 53.5 years) who underwent bone scintigraphy for suspected Synovitis, Acne, Pustulosis, Hyperostosis, and Osteitis (SAPHO) syndrome between January 2007 and December 2022 were retrospectively reviewed. ChatGPT-4.0 was used as the large language model. The diagnostic performance of the large language model was verified by comparing the cases judged to have SAPHO syndrome that fulfilled Kahn's classification criteria based on a combination of concise radiology reports and skin lesions such as palmoplantar pustulosis, with cases diagnosed with SAPHO syndrome by rheumatologists based on all clinical information.Results The diagnostic accuracy of a large language model for analysing bone scintigraphy radiology reports in conjunction with information about skin symptoms, such as palmoplantar pustulosis, achieved a sensitivity of 83.5%, specificity of 69.4%, and an overall accuracy of 76.8%.Conclusion This research indicates the prospective value of extensive language models in scrutinizing radiology accounts from bone scintigraphy for the diagnosis of SAPHO syndrome.	[Mori, Yu; Izumiyama, Takuya; Kanabuchi, Ryuichi; Aizawa, Toshimi] Tohoku Univ, Grad Sch Med, Dept Orthopaed Surg, Sendai, Miyagi, Japan; [Mori, Naoko] Akita Univ, Grad Sch Med, Dept Radiol, Akita, Akita, Japan; [Mori, Yu] Tohoku Univ, Dept Orthopaed Surg, Grad Sch Med, 1-1 Seiryo machi,Aoba Ku, Sendai, Miyagi 9808574, Japan	Tohoku University; Akita University; Tohoku University	Mori, Y (corresponding author), Tohoku Univ, Dept Orthopaed Surg, Grad Sch Med, 1-1 Seiryo machi,Aoba Ku, Sendai, Miyagi 9808574, Japan.	yu-mori@med.tohoku.ac.jp	Mori, Yu/AAX-5874-2021	Mori, Yu/0000-0002-8225-4690				BENHAMOU CL, 1988, CLIN EXP RHEUMATOL, V6, P109; Cao YH, 2019, RHEUMATOLOGY, V58, P1047, DOI 10.1093/rheumatology/key415; Hasani AM, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10384-x; KAHN MF, 1994, BAILLIERE CLIN RHEUM, V8, P333, DOI 10.1016/S0950-3579(94)80022-7; Kishimoto M, 2022, MOD RHEUMATOL, V32, P665, DOI 10.1093/mr/roab103; Mori Y., 2023, Mod Rheumatol; Nakaura T., 2023, Jpn J Radiol; Okuno H, 2018, MOD RHEUMATOL, V28, P703, DOI 10.1080/14397595.2017.1372874; Rukavina I, 2015, J CHILD ORTHOP, V9, P19, DOI 10.1007/s11832-014-0627-7; Uz C, 2023, INT J RHEUM DIS, V26, P1343, DOI 10.1111/1756-185X.14749; Yamamoto T, 2020, INT J DERMATOL, V59, P441, DOI 10.1111/ijd.14788	11	0	0	2	2	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1439-7595	1439-7609		MOD RHEUMATOL	Mod. Rheumatol.	2023 DEC 28	2023										10.1093/mr/road115	http://dx.doi.org/10.1093/mr/road115		DEC 2023	5	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	HL4R1	38153762				2024-07-03	WOS:001159652300001
J	Lee, J; Jung, W; Baek, S				Lee, Jooyeup; Jung, Wooyong; Baek, Seungwon			In-House Knowledge Management Using a Large Language Model: Focusing on Technical Specification Documents Review	APPLIED SCIENCES-BASEL			English	Article						technical specification document; knowledge management; large language model; fine-tuning; GPT; LLaMA	CONSTRUCTION; CAPABILITIES	In complex construction projects, technical specifications have to be reviewed in a short period of time. Even experienced engineers find it difficult to review every detail of technical specifications. In addition, it is not easy to transfer experienced knowledge to junior engineers. With the technological innovation of large language models such as ChatGPT, a fine-tuned language model is proposed as an effective solution for the automatic review of technical specification documents. Against this backdrop, this study examines the in-house technical specification documents that are not publicly available. Then, two fine-tuned large language models, GPT-3 and LLaMA2, are trained to answer questions related to technical specification documents. The results show that the fine-tuned LLaMA2 model generally outperforms the fine-tuned GPT-3 model in terms of accuracy, reliability, and conciseness of responses. In particular, the fine-tuned LLaMA2 model suppressed hallucinogenic effects better than the fine-tuned GPT-3 model. Based on the results, this study discussed the applicability and limitations of a fine-tuned large language model for in-house knowledge management. The results of this study are expected to assist practitioners in developing a domain-specific knowledge management solution by fine-tuning an open-source large language model with private datasets.	[Lee, Jooyeup; Jung, Wooyong] KEPCO Int Nucl Grad Sch, Dept Nucl Power Plant Engn, 658-91 Haemaji Ro,Seosaeng Myeon,Ulju Gun, Ulsan 45014, South Korea; [Baek, Seungwon] Korea Inst Civil Engn & Bldg Technol, Postconstruct Evaluat & Management Ctr, Dept Construct Policy Res, Goyang 10223, South Korea	Korea Institute of Civil Engineering & Building Technology (KICT)	Jung, W (corresponding author), KEPCO Int Nucl Grad Sch, Dept Nucl Power Plant Engn, 658-91 Haemaji Ro,Seosaeng Myeon,Ulju Gun, Ulsan 45014, South Korea.; Baek, S (corresponding author), Korea Inst Civil Engn & Bldg Technol, Postconstruct Evaluat & Management Ctr, Dept Construct Policy Res, Goyang 10223, South Korea.	kosdac@gmail.com; trustjung@gmail.com; baeksw@kict.re.kr			KEPCO International Nuclear graduate School (KINGS)	KEPCO International Nuclear graduate School (KINGS)	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ashkenas R., How to Preserve Institutional Knowledge; Belzner L., 2023, P INT C BRIDG GAP AI, P355; Bigelow Ben F., 2021, International Journal of Construction Education and Research, V17, P3, DOI 10.1080/15578771.2019.1611678; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bughin J., 2012, McKinsey Quarterly, P72; Carrillo P, 2006, J MANAGE ENG, V22, P2, DOI 10.1061/(ASCE)0742-597X(2006)22:1(2); Chen YT, 2022, J BUS RES, V139, P1138, DOI 10.1016/j.jbusres.2021.10.050; Chinowsky P, 2007, J MANAGE ENG, V23, P122, DOI 10.1061/(ASCE)0742-597X(2007)23:3(122); Chung SH, 2023, AUTOMAT CONSTR, V154, DOI 10.1016/j.autcon.2023.105020; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Gold AH, 2001, J MANAGE INFORM SYST, V18, P185, DOI 10.1080/07421222.2001.11045669; Gunasekara C., Question Answering Artificial Intelligence Chatbot on Military Dress Policy; Hallowell MR, 2012, J MANAGE ENG, V28, P203, DOI 10.1061/(ASCE)ME.1943-5479.0000067; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Javernick-Will A, 2012, J MANAGE ENG, V28, P193, DOI 10.1061/(ASCE)ME.1943-5479.0000076; Kale S, 2012, KSCE J CIV ENG, V16, P526, DOI 10.1007/s12205-012-1468-x; Kim J., 2022, P 2022 IEEE INT C IN, P970, DOI 10.1109/IEEM55944.2022.9989625; Kim SB, 2014, KSCE J CIV ENG, V18, P1609, DOI 10.1007/s12205-014-0243-6; Kivrak S, 2008, J MANAGE ENG, V24, P87, DOI 10.1061/(ASCE)0742-597X(2008)24:2(87); Lauriola I, 2022, NEUROCOMPUTING, V470, P443, DOI 10.1016/j.neucom.2021.05.103; Lialin V, 2023, Arxiv, DOI [arXiv:2303.15647, 10.48550/arXiv.2303.15647]; Lin YC, 2012, AUTOMAT CONSTR, V22, P422, DOI 10.1016/j.autcon.2011.10.004; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu X., 2023, AI Open, DOI [10.1016/j.aiopen.2023.08.012, DOI 10.1016/J.AIOPEN.2023.08.012]; Malsane S, 2015, AUTOMAT CONSTR, V49, P51, DOI 10.1016/j.autcon.2014.10.004; Meese N, 2012, AI SOC, V27, P437, DOI 10.1007/s00146-011-0369-8; Moon S, 2022, ADV ENG INFORM, V51, DOI 10.1016/j.aei.2021.101495; Moon S, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0001953; OpenAI, API Reference-Create Chat Completion; Oppert Michelle L., 2019, Australian Journal of Multi-Disciplinary Engineering, V15, P100, DOI 10.1080/14488388.2019.1666621; Park M, 2013, KSCE J CIV ENG, V17, P22; Rezgui Y, 2006, J COMPUT CIVIL ENG, V20, P261, DOI 10.1061/(ASCE)0887-3801(2006)20:4(261); Salama DA, 2013, J COMPUT CIVIL ENG, V27, P681, DOI 10.1061/(ASCE)CP.1943-5487.0000298; Salama DM, 2016, J COMPUT CIVIL ENG, V30, DOI 10.1061/(ASCE)CP.1943-5487.0000301; Tan HC, 2012, J MANAGE ENG, V28, P338, DOI 10.1061/(ASCE)ME.1943-5479.0000109; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Xu RX, 2021, Arxiv, DOI arXiv:2109.05687; Wang WYC, 2022, KNOWL MAN RES PRACT, V20, P1, DOI 10.1080/14778238.2022.2039571; Yuan XD, 2022, Arxiv, DOI arXiv:2209.11000; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhuk A., 2023, AI Ethics, P1, DOI [10.1007/s43681-023-00299-0, DOI 10.1007/S43681-023-00299-0]	47	0	0	21	21	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	5							2096	10.3390/app14052096	http://dx.doi.org/10.3390/app14052096			18	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	KT0P8		gold			2024-07-03	WOS:001182101800001
J	Zhou, WP; Prater, LC; Goldstein, E; Mooney, SJ				Zhou, Weipeng; Prater, Laura C.; Goldstein, Evan, V; Mooney, Stephen J.			Identifying Rare Circumstances Preceding Female Firearm Suicides: Validating A Large Language Model Approach	JMIR MENTAL HEALTH			English	Article						female firearm suicide; large language model; document classification; suicide prevention; suicide; firearm suicide; machine learning; mental health for women; violent death; mental health; language models; women; female; depression; suicidal		Background: Firearm suicide has been more prevalent among males, but age-adjusted female firearm suicide rates increased by 20% from 2010 to 2020, outpacing the rate increase among males by about 8 percentage points, and female firearm suicide may have different contributing circumstances. In the United States, the National Violent Death Reporting System (NVDRS) is a comprehensive source of data on violent deaths and includes unstructured incident narrative reports from coroners or medical examiners and law enforcement. Conventional natural language processing approaches have been used to identify common circumstances preceding female firearm suicide deaths but failed to identify rarer circumstances due to insufficient training data.Objective: This study aimed to leverage a large language model approach to identify infrequent circumstances preceding female firearm suicide in the unstructured coroners or medical examiners and law enforcement narrative reports available in the NVDRS. Methods: We used the narrative reports of 1462 female firearm suicide decedents in the NVDRS from 2014 to 2018. The reports were written in English. We coded 9 infrequent circumstances preceding female firearm suicides. We experimented with predicting those circumstances by leveraging a large language model approach in a yes/no question-answer format. We measured the prediction accuracy with F1-score (ranging from 0 to 1). F1-score is the harmonic mean of precision (positive predictive value) and recall (true positive rate or sensitivity).Results: Our large language model outperformed a conventional support vector machine-supervised machine learning approach by a wide margin. Compared to the support vector machine model, which had F1-scores less than 0.2 for most infrequent circumstances, our large language model approach achieved an F1-score of over 0.6 for 4 circumstances and 0.8 for 2 circumstances.Conclusions: The use of a large language model approach shows promise. Researchers interested in using natural language processing to identify infrequent circumstances in narrative report data may benefit from large language models.	[Zhou, Weipeng] Univ Washington, Sch Med, Dept Biomed Informat & Med Educ, Seattle, WA 98195 USA; [Prater, Laura C.] Univ Washington, Dept Psychiat & Behav Hlth, Seattle, WA 98195 USA; [Prater, Laura C.] Univ Washington, Harborview Med Ctr, Sch Med, Seattle, WA 98195 USA; [Goldstein, Evan, V] Univ Utah, Dept Populat Hlth Sci, Salt Lake City, UT USA; [Mooney, Stephen J.] Univ Washington, Sch Publ Hlth, Dept Epidemiol, Seattle, WA 98195 USA; [Mooney, Stephen J.] Univ Washington, Hans Rosling Ctr Populat Hlth, Sch Publ Hlth, Dept Epidemiol, 3980 15th Ave NE, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; Harborview Medical Center; Utah System of Higher Education; University of Utah; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle	Mooney, SJ (corresponding author), Univ Washington, Hans Rosling Ctr Populat Hlth, Sch Publ Hlth, Dept Epidemiol, 3980 15th Ave NE, Seattle, WA 98195 USA.	sjm2186@uw.edu		Laura Prater, Laura Yodice/0000-0003-2414-5063; Goldstein, Evan/0000-0001-7766-7450; Zhou, Weipeng/0000-0003-1215-8043	National Collaborative on Gun Violence Research (2021); National Library of Medicine [4R00LM012868]	National Collaborative on Gun Violence Research (2021); National Library of Medicine(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	This work was funded by grants from the National Collaborative on Gun Violence Research (PI: Prater/Goldstein, 2021) and the National Library of Medicine (4R00LM012868). We thank Dr Meliha Yetisgen for providing the computational resources.	Anestis MD, 2016, J AFFECT DISORDERS, V189, P106, DOI 10.1016/j.jad.2015.09.007; [Anonymous], WISQARSTM - Web-based Injury Statistics Query and Reporting System; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Goldstein EV, 2023, AM J PREV MED, V65, P278, DOI 10.1016/j.amepre.2023.01.030; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; KELLERMANN AL, 1992, NEW ENGL J MED, V327, P467, DOI 10.1056/NEJM199208133270705; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Miller M, 2022, JAMA PSYCHIAT, V79, P582, DOI 10.1001/jamapsychiatry.2022.0793; Rowhani-Rahbar A, 2016, EPIDEMIOL REV, V38, P111, DOI 10.1093/epirev/mxv006; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Spark Talia L, 2022, Curr Treat Options Psychiatry, V9, P301, DOI 10.1007/s40501-022-00273-3; Tay Y., A New Open Source Flan 20B with UL2; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862	13	1	1	12	15	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2368-7959			JMIR MENT HEALTH	JMIR Ment. Health		2023	10								e49359	10.2196/49359	http://dx.doi.org/10.2196/49359			5	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Psychiatry	Y3TX3	37847549	gold, Green Published			2024-07-03	WOS:001104536100001
J	Luan, ZR; Lai, YJ; Huang, RD; Bai, SH; Zhang, YD; Zhang, HR; Wang, Q				Luan, Zhirong; Lai, Yujun; Huang, Rundong; Bai, Shuanghao; Zhang, Yuedi; Zhang, Haoran; Wang, Qian			Enhancing Robot Task Planning and Execution through Multi-Layer Large Language Models	SENSORS			English	Article						robots; large language models; natural language; semantic alignment method		Large language models have found utility in the domain of robot task planning and task decomposition. Nevertheless, the direct application of these models for instructing robots in task execution is not without its challenges. Limitations arise in handling more intricate tasks, encountering difficulties in effective interaction with the environment, and facing constraints in the practical executability of machine control instructions directly generated by such models. In response to these challenges, this research advocates for the implementation of a multi-layer large language model to augment a robot's proficiency in handling complex tasks. The proposed model facilitates a meticulous layer-by-layer decomposition of tasks through the integration of multiple large language models, with the overarching goal of enhancing the accuracy of task planning. Within the task decomposition process, a visual language model is introduced as a sensor for environment perception. The outcomes of this perception process are subsequently assimilated into the large language model, thereby amalgamating the task objectives with environmental information. This integration, in turn, results in the generation of robot motion planning tailored to the specific characteristics of the current environment. Furthermore, to enhance the executability of task planning outputs from the large language model, a semantic alignment method is introduced. This method aligns task planning descriptions with the functional requirements of robot motion, thereby refining the overall compatibility and coherence of the generated instructions. To validate the efficacy of the proposed approach, an experimental platform is established utilizing an intelligent unmanned vehicle. This platform serves as a means to empirically verify the proficiency of the multi-layer large language model in addressing the intricate challenges associated with both robot task planning and execution.	[Luan, Zhirong; Lai, Yujun; Huang, Rundong; Wang, Qian] Xian Univ Technol, Sch Elect Engn, Xian 710000, Peoples R China; [Bai, Shuanghao; Zhang, Yuedi; Zhang, Haoran] Xi An Jiao Tong Univ, Coll Artificial Intelligence, Xian 710000, Peoples R China	Xi'an University of Technology; Xi'an Jiaotong University	Luan, ZR (corresponding author), Xian Univ Technol, Sch Elect Engn, Xian 710000, Peoples R China.	luanzhirong@xaut.edu.cn; 2221920082@stu.xaut.edu.cn; 3211712276@stu.xaut.edu.cn; baishuanghao@stu.xjtu.edu.cn; zyd993@stu.xjtu.edu.cn; zhr2001@stu.xjtu.edu.cn; wangqian77@xaut.edu.cn		Luan, Zhirong/0000-0001-8260-0584; Bai, Shuanghao/0009-0002-6047-0242; Wang, Qian/0000-0002-2931-7875	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Andreas J, 2017, Arxiv, DOI arXiv:1711.00482; Bahl S, 2023, PROC CVPR IEEE, P13778, DOI 10.1109/CVPR52729.2023.01324; Blukis V, 2020, Arxiv, DOI arXiv:2011.07384; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brohan A, 2023, Arxiv, DOI arXiv:2212.06817; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhery A, 2023, J MACH LEARN RES, V24; Cui Y., 2023, P 2023 ACMIEEE INT C, P93; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Du YQ, 2023, Arxiv, DOI arXiv:2302.06692; Gu Xiuye, 2021, arXiv; Hu HY, 2023, Arxiv, DOI arXiv:2304.07297; Huang WL, 2023, Arxiv, DOI [arXiv:2307.05973, 10.48550/arXiv.2307.05973]; Huang WL, 2023, Arxiv, DOI arXiv:2303.00855; Huang WL, 2022, PR MACH LEARN RES; Jang E., 2022, C ROBOT LEARNING, P991; Jiang YD, 2019, ADV NEUR IN, V32; Kamath A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1760, DOI 10.1109/ICCV48922.2021.00180; Kwon M, 2023, Arxiv, DOI arXiv:2303.00001; Li S., 2022, Advances in Neural Information Processing Systems, V35, P31199; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Lin K, 2023, Arxiv, DOI arXiv:2303.12153; Liu B, 2023, Arxiv, DOI arXiv:2304.11477; Liu WY, 2022, IEEE INT CONF ROBOT, P6322, DOI 10.1109/ICRA46639.2022.9811931; Lu YJ, 2023, Arxiv, DOI arXiv:2305.01795; Ma YJ, 2023, Arxiv, DOI arXiv:2306.00958; Micheli V., 2021, arXiv; Minderer M, 2022, LECT NOTES COMPUT SC, V13670, P728, DOI 10.1007/978-3-031-20080-9_42; Mu J., 2022, Advances in Neural Information Processing Systems, V35, P33947; Nair S., 2022, P MACHINE LEARNING R, P1303; Patel D, 2023, Arxiv, DOI arXiv:2304.09179; Radford A, 2021, PR MACH LEARN RES, V139; Raman S.S., 2022, P NEURIPS 2022 FDN M; Shah D, 2023, C ROBOT LEARNING, P492; Sharma P, 2022, Arxiv, DOI arXiv:2204.05186; Shwartz V, 2020, Arxiv, DOI arXiv:2004.05483; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Stone A, 2023, Arxiv, DOI arXiv:2303.00905; Tam A., 2022, Advances in Neural Information Processing Systems, V35, P25377; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Thomason J, 2020, J ARTIF INTELL RES, V67, P327; Thomason J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1923; Toussaint M, 2022, IEEE INT C INT ROBOT, P13753, DOI 10.1109/IROS47612.2022.9982236; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wu JMY, 2023, Arxiv, DOI arXiv:2305.05658; Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128; Yang R, 2023, Arxiv, DOI arXiv:2305.18752; Yuan HQ, 2023, Arxiv, DOI arXiv:2303.16563; Zellers R, 2021, Advances in Neural Information Processing Systems, V34; Zellers R, 2022, Arxiv, DOI arXiv:2106.00188; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598	53	0	0	39	39	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	MAR	2024	24	5							1687	10.3390/s24051687	http://dx.doi.org/10.3390/s24051687			20	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	KW6O5	38475223	Green Published, gold			2024-07-03	WOS:001183040900001
J	Kasneci, E; Sessler, K; Küchemann, S; Bannert, M; Dementieva, D; Fischer, F; Gasser, U; Groh, G; Günnemann, S; Hüllermeier, E; Krusche, S; Kutyniok, G; Michaeli, T; Nerdel, C; Pfeffer, J; Poquet, O; Sailer, M; Schmidt, A; Seidel, T; Stadler, M; Weller, J; Kuhn, J; Kasneci, G				Kasneci, Enkelejda; Sessler, Kathrin; Kuechemann, Stefan; Bannert, Maria; Dementieva, Daryna; Fischer, Frank; Gasser, Urs; Groh, Georg; Guennemann, Stephan; Huellermeier, Eyke; Krusche, Stepha; Kutyniok, Gitta; Michaeli, Tilman; Nerdel, Claudia; Pfeffer, Juergen; Poquet, Oleksandra; Sailer, Michael; Schmidt, Albrecht; Seidel, Tina; Stadler, Matthias; Weller, Jochen; Kuhn, Jochen; Kasneci, Gjergji			ChatGPT for good? On opportunities and challenges of large language models for education	LEARNING AND INDIVIDUAL DIFFERENCES			English	Editorial Material						Keywords; Large language models; Artificial intelligence; Education; Educational technologies		Large language models represent a significant advancement in the field of AI. The underlying technology is key to further innovations and, despite critical views and even bans within communities and regions, large language models are here to stay. This commentary presents the potential benefits and challenges of educational appli-cations of large language models, from student and teacher perspectives. We briefly discuss the current state of large language models and their applications. We then highlight how these models can be used to create educational content, improve student engagement and interaction, and personalize learning experiences. With regard to challenges, we argue that large language models in education require teachers and learners to develop sets of competencies and literacies necessary to both understand the technology as well as their limitations and unexpected brittleness of such systems. In addition, a clear strategy within educational systems and a clear pedagogical approach with a strong focus on critical thinking and strategies for fact checking are required to integrate and take full advantage of large language models in learning settings and teaching curricula. Other challenges such as the potential bias in the output, the need for continuous human oversight, and the potential for misuse are not unique to the application of AI in education. But we believe that, if handled sensibly, these challenges can offer insights and opportunities in education scenarios to acquaint students early on with po-tential societal biases, criticalities, and risks of AI applications. We conclude with recommendations for how to address these challenges and ensure that such models are used in a responsible and ethical manner in education.	[Kasneci, Enkelejda; Sessler, Kathrin; Bannert, Maria; Dementieva, Daryna; Gasser, Urs; Groh, Georg; Guennemann, Stephan; Krusche, Stepha; Michaeli, Tilman; Nerdel, Claudia; Pfeffer, Juergen; Poquet, Oleksandra; Seidel, Tina] Tech Univ Munich, Munich, Germany; [Kuechemann, Stefan; Fischer, Frank; Huellermeier, Eyke; Kutyniok, Gitta; Sailer, Michael; Schmidt, Albrecht; Stadler, Matthias; Weller, Jochen; Kuhn, Jochen] Ludwig Maximilians Univ Munchen, Munich, Germany; [Kasneci, Gjergji] Univ Tubingen, Tubingen, Germany	Technical University of Munich; University of Munich; Eberhard Karls University of Tubingen	Kasneci, E (corresponding author), Tech Univ Munich, Munich, Germany.	Enkelejda.Kasneci@tum.de	Sailer, Michael/HTO-7914-2023; Kuhn, Jochen/K-4031-2014; Seidel, Tina/C-6221-2009; Poquet, Oleksandra/AAZ-6425-2020	Sailer, Michael/0000-0001-6831-5429; Seidel, Tina/0000-0002-2578-1208; Poquet, Oleksandra/0000-0001-9782-816X; Kasneci, Gjergji/0000-0002-3123-7268; Sessler, Kathrin/0000-0002-3380-4641; Kutyniok, Gitta/0000-0001-9738-2487; Krusche, Stephan/0000-0002-4552-644X; Gasser, Urs/0000-0001-6899-5647				Becker BA, 2022, Arxiv, DOI arXiv:2212.01020; Abdelghani R, 2022, Arxiv, DOI [arXiv:2211.14228, arXiv:2211.14228, 10.48550/ARXIV.2211.14228, DOI 10.48550/ARXIV.2211.14228]; Ahuja AS, 2023, INTEGR MED RES, V12, DOI 10.1016/j.imr.2022.100917; Ayanwale M. A., 2022, Computers and Education: Artificial Intelligence, V3; Bao M., 2019, ARAB WORLD ENGL J, P5; Bernius J. P., 2022, 2022 ACMIEEE 44 INT, V3; Bhat S., 2022, P INT C ED DATA MINI, P701, DOI DOI 10.5281/ZENODO.6853085; Borisov V, 2023, Arxiv, DOI [arXiv:2210.06280, 10.48550/arXiv.2210.06280]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chocarro R, 2023, EDUC STUD-UK, V49, P295, DOI 10.1080/03055698.2020.1850426; Choi S, 2023, INT J HUM-COMPUT INT, V39, P910, DOI 10.1080/10447318.2022.2049145; Cotton D. R., 2023, ENSURING ACAD INTEGR; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dijkstra R., 2022, Reading comprehension quiz generation using generative pre-trained transformers; El Shazly R, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12667; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Fadel C., 2019, Artificial intelligence in education: Promises and implications for teaching and learning; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gabajiwala Ebrahim, 2022, Futuristic Trends in Networks and Computing Technologies: Select Proceedings of Fourth International Conference on FTNCT 2021. Lecture Notes in Electrical Engineering (936), P523, DOI 10.1007/978-981-19-5037-7_37; Gao C. A., 2022, bioRxiv; Gao H., 2021, P 2021 CHI C HUM FAC, P1; Gu CX, 2022, Arxiv, DOI arXiv:2210.07543; Guzman AL, 2020, NEW MEDIA SOC, V22, P70, DOI 10.1177/1461444819858691; Hwang GJ, 2023, INTERACT LEARN ENVIR, V31, P4099, DOI 10.1080/10494820.2021.1952615; Jeon J, 2023, COMPUT ASSIST LANG L, V36, P1338, DOI 10.1080/09588221.2021.1987272; Ji H., 2022, P 2022 CHI C HUMAN F, P1; Jia Q., 2021, ALL-IN-ONE: Multi-task learning BERT models for evaluating peer assessments; Kerr J, 2020, INT J ART DES EDUC, V39, P6, DOI 10.1111/jade.12227; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Kuhlthau C. C., 2015, GUIDED INQUIRY LEARN; Kung T. H., 2022, medRxiv; Lin CJ, 2021, EDUC TECHNOL SOC, V24, P16; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Magazine T. A. A. I., 2022, MAGAZINE T A A I; Mengxiao Zhu O., 2020, COMPUT EDUC, V143; Min B., 2021, arXiv; Moore S, 2022, LECT NOTES COMPUT SC, V13450, P243, DOI 10.1007/978-3-031-16290-9_18; Nassim D., 2021, ETHICS SCI ENV POLIT, V21, P17; News K. R. N., 2023, CHATGPT BANN NEW YOR; Pavlik J. V., 2023, JOURNALISM MASS COMM, V78, P84, DOI [DOI 10.1177/10776958221149577, https://doi.org/10.1177/10776958221149577, 10.1177/10776958221149577]; Polak S., 2022, 2022 CHI C HUM FACT; Qu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2583; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Raffel C, 2020, J MACH LEARN RES, V21; Raina V, 2022, Arxiv, DOI arXiv:2209.11830; Ramesh A, 2021, PR MACH LEARN RES, V139; Redecker C, 2017, European Framework for the Digital Competence of Educators; Rodriguez-Torrealba R, 2022, EXPERT SYST APPL, V208, DOI 10.1016/j.eswa.2022.118258; Rojas-Sánchez MA, 2023, EDUC INF TECHNOL, V28, P155, DOI 10.1007/s10639-022-11167-5; Roussou M., 2001, P TILE TRENDS LEIS E; Sailer M, 2023, LEARN INSTR, V83, DOI 10.1016/j.learninstruc.2022.101620; Salas-Pilco SZ, 2022, EDUC SCI, V12, DOI 10.3390/educsci12080569; Salomon G., 1993, COMPUTERS COGNITIVE, P179; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Shen JH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2269; Tack Anais, 2022, P 15 INT C ED DAT MI, P522, DOI 10.5281/zenodo.6853187; Tai TY, 2023, INTERACT LEARN ENVIR, V31, P1485, DOI 10.1080/10494820.2020.1841801; Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811; Team O., 2022, CHATGPT OPT LANG MOD; Tian E., 2023, Gptzero; UNESCO, 2023, ED 2030 AG; Vaswani A, 2017, ADV NEUR IN, V30; Wang ZC, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5986; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yang ZL, 2019, ADV NEUR IN, V32; Yu WJ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3384	67	468	477	305	759	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1041-6080	1873-3425		LEARN INDIVID DIFFER	Learn. Individ. Differ.	APR	2023	103								102274	10.1016/j.lindif.2023.102274	http://dx.doi.org/10.1016/j.lindif.2023.102274		MAR 2023	9	Psychology, Educational	Social Science Citation Index (SSCI)	Psychology	C4YQ0		Bronze, Green Submitted			2024-07-03	WOS:000961991400001
C	Teehan, R; Clinciu, M; Serikov, O; Szczechla, E; Seelam, N; Mirkin, S; Gokaslan, A			Assoc Computat Linguist	Teehan, Ryan; Clinciu, Miruna; Serikov, Oleg; Szczechla, Eliza; Seelam, Natasha; Mirkin, Shachar; Gokaslan, Aaron			Emergent Structures and Training Dynamics in Large Language Models	PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5)			English	Proceedings Paper	Workshop on Challenges and Perspectives in Creating Large Language Models	MAY 27, 2022	Dublin, IRELAND	Naver Labs Europe, BigScience				Large language models have achieved success on a number of downstream tasks, particularly in a few and zero-shot manner. As a consequence, researchers have been investigating both the kind of information these networks learn and how such information can be encoded in the parameters of the model. We survey the literature on changes in the network during training, drawing from work outside of NLP when necessary, and on learned representations of linguistic features in large language models. We note in particular the lack of sufficient research on the emergence of functional units subsections of the network where related functions are grouped or organized - within large language models, and motivate future work that grounds the study of language models in an analysis of their changing internal structure during training time.	[Teehan, Ryan] Charles River Analyt, Cambridge, MA 02138 USA; [Clinciu, Miruna] Edinburgh Ctr Robot, Edinburgh, Midlothian, Scotland; [Clinciu, Miruna] Heriot Watt Univ, Edinburgh, Midlothian, Scotland; [Clinciu, Miruna] Univ Edinburgh, Edinburgh, Midlothian, Scotland; [Teehan, Ryan; Clinciu, Miruna; Serikov, Oleg; Szczechla, Eliza; Seelam, Natasha; Mirkin, Shachar; Gokaslan, Aaron] BigScience, Chicago, IL 60637 USA; [Serikov, Oleg] AIR Inst, Moscow, Russia; [Serikov, Oleg] MIPT, DeepPavlov Lab, Dolgoprudnyi, Russia; [Serikov, Oleg] HSE Univ, Moscow, Russia; [Seelam, Natasha] Sherlock Biosci, Cambridge, MA USA; [Mirkin, Shachar] Lawgeex, Tel Aviv, Israel; [Gokaslan, Aaron] Cornell Univ, Ithaca, NY 14853 USA	Charles River Analytics Inc; Heriot Watt University; University of Edinburgh; Moscow Institute of Physics & Technology; HSE University (National Research University Higher School of Economics); Cornell University	Teehan, R (corresponding author), Charles River Analyt, Cambridge, MA 02138 USA.; Teehan, R (corresponding author), BigScience, Chicago, IL 60637 USA.	rsteehan@gmail.com						Ablowitz R., 1939, PHILOS SCI, V6, P1, DOI [10.1086/286529, DOI 10.1086/286529]; Adi Yossi, 2017, P ICLR; Ahmad WU, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4538; Aktas ME, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0179-3; Alain Guillaume, 2017, 5 INT C LEARNING REP; Artetxe M, 2019, T ASSOC COMPUT LING, V7, P597, DOI 10.1162/tacl_a_00288; Baas Nils A, 2000, ARTIF LIFE, P515; Ball RC, 2010, ADV COMPLEX SYST, V13, P327, DOI 10.1142/S021952591000258X; Bastings J, 2020, P 3 BLACKBOXNLP WORK, P149, DOI [DOI 10.18653/V1/2020.BLACKBOXNLP-1.14, 10.18653/v1/2020.blackboxnlp-1.14]; Belinkov Y, 2019, T ASSOC COMPUT LING, V7, P49, DOI 10.1162/tacl_a_00254; Belinkov Y, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P861, DOI 10.18653/v1/P17-1080; Belinkov Yonatan, 2017, P 8 INT JOINT C NAT, V1, P1; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Bommasani R., 2021, 2108.07258; Brown SR, 2013, COGN NEURODYNAMICS, V7, P173, DOI 10.1007/s11571-012-9229-6; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bunel R, 2020, J MACH LEARN RES, V21; Byrne John H, 2012, CELL MOL NEUROBIOL, V1; Callebaut Werner., 2005, MODULARITY UNDERSTAN; Chen Peng-Jen, 2020, P 5 C MACH TRANSL, P113; Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152; Chi E.A., 2020, P 58 ANN M ASS COMPU, P5564, DOI [DOI 10.18653/V1/2020.ACL-MAIN.493, 10.18653/v1/2020.acl-main.493]; Chiang CH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6813; Conneau A, 2019, ADV NEUR IN, V32; Conneau A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2126; Conneau Alexis, 2020, P 58 ANN M ASS COMPU, P6022, DOI 10.18653/v1/2020.acl-main.536; Csordas R., 2021, INT C LEARNING REPRE; Cucker F, 2007, IEEE T AUTOMAT CONTR, V52, P852, DOI 10.1109/TAC.2007.895842; Dai D., 2021, arXiv; Dalrymple Mary, 2001, Lexical Functional Grammar; Danilevsky M, 2020, 1ST CONFERENCE OF THE ASIA-PACIFIC CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 10TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (AACL-IJCNLP 2020), P447; De Cao N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3243; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Devlin Jacob, 2018, Multilingual bert readme document; Dresp-Langley B, 2020, BIG DATA COGN COMPUT, V4, DOI 10.3390/bdcc4020010; Dufter P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4423; Durrani N, 2020, Arxiv, DOI arXiv:2010.02695; Durrani N, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4947; Filan Daniel, 2021, Clusterability in neural networks; Gershenson C, 2020, ARTIF LIFE, V26, P391, DOI 10.1162/artl_a_00324; Ghaeini Reza, 2018, ARXIV180803894, P4952; Goh Gabriel, 2021, DISTILL, DOI 10.23915/distill.00024.009; HAPPEL BLM, 1994, NEURAL NETWORKS, V7, P985, DOI 10.1016/S0893-6080(05)80155-8; He LH, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P364; Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2733; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hockenmaier J, 2007, COMPUT LINGUIST, V33, P355, DOI 10.1162/coli.2007.33.3.355; Hod S, 2022, Arxiv, DOI arXiv:2110.08058; Iyer R, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003248; Jacovi A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4198; Kala R, 2010, ARTIF INTELL REV, V33, P307, DOI 10.1007/s10462-010-9157-y; Karthikeyan K, 2020, P ICLR; Kelly B, 2014, LANG LINGUIST COMPAS, V8, P51, DOI 10.1111/lnc3.12062; Kitaev N, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2676; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lee Kenton, 2018, P 2018 C N AM CHAPTE, P687, DOI [10.18653/v1/N18-2108, DOI 10.18653/V1/N18-2108]; Lewis Patrick, 2020, P ACL 2020, P7315; Li J., 2015, P 2016 C N AM CHAPTE, P681; Li WJ, 2020, ISA T, V100, P185, DOI 10.1016/j.isatra.2019.11.015; Liu NF, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1073; Liu Zeyu, 2021, FINDINGS ASS COMPUTA, P820; Lundberg SM, 2017, ADV NEUR IN, V30; Luo LQ, 2021, SCIENCE, V373, P1103, DOI 10.1126/science.abg7285; Ma SM, 2020, Arxiv, DOI arXiv:2012.15547; Maudslay RH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P124; McCoy R Thomas, 2020, P 3 BLACKBOXNLP WORK, P217, DOI [10.18653/v1/2020.blackboxnlp-1.21, DOI 10.18653/V1/2020.BLACKBOXNLP-1.21]; Meng Kevin, 2022, Locating and editing factual associations in gpt; Merrill William, P 2021 C EMPIRICAL M, P1766; Nozza Debora, 2020, WHAT MASK MAKING SEN; OConnor Joe, P 59 ANN M ASS COMPU, V1, P851; Pasunuru R, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1911; Peters Matthew E., 2018, P 2018 C EMP METH NA, P1499; Pham H, 2018, PR MACH LEARN RES, V80; Pimentel T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3138; Pimentel Tiago, 2021, BAYESIAN FRAMEWORK I; Pimentel Tiago, 2020, Information-theoretic probing for linguistic structure; Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rössig A, 2021, J GLOBAL OPTIM, V81, P109, DOI 10.1007/s10898-020-00949-1; Ruder S, 2019, J ARTIF INTELL RES, V65, P569, DOI 10.1613/jair.1.11640; Sahin GG, 2020, COMPUT LINGUIST, V46, P335, DOI [10.1162/coli_a_00376, 10.1162/COLI_a_00376]; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Saphra Naomi, 2021, THESIS U EDINBURGH; Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2931; Shalizi Cosma Rohilla, 2003, DMCS; Shalizi CR, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.036104; Shalizi CR, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.118701; Shi X., 2016, P 2016 C EMPIRICAL M; Shrikumar A., 2019, Learning important features through propagating activation differences; Sinha K, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P2888; So DR, 2019, PR MACH LEARN RES, V97; So David R., 2021, Primer: Searching for efficient transformers for language modeling; Steinhardt Jacob, 2022, Future ml systems will be qualitatively different; Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027; Sundararajan M, 2017, PR MACH LEARN RES, V70; Tenney I, 2019, Arxiv, DOI arXiv:1905.06316; Vaswani A, 2017, ADV NEUR IN, V30; Voita Elena, 2020, P 2020 C EMP METH NA, P183; Voss Chelsea, 2021, Branch Specialization-distill.pub, DOI DOI 10.23915/DISTILL.00024.007; Vuli Ivan, 2020, P 2020 C EMP METH NA, P7222; White JC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P132; Wiegreffe S, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P11; Wu SJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P833; Wu SJ, 2020, 5TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2020), P120; Yaghoobzadeh Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5740; Zhang Hongyang, 2020, AISTATS 2019 22 INT; Zhang Kelly, 2018, P EMNLP WORKSH BLACK, P359, DOI [DOI 10.18653/V1/W18-5448, 10.18653/v1/w18-5448]; Zhu ZN, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9251; Zhuang L., 2021, P 20 CHINESE NATL C, P1218	113	0	1	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-26-1				2022							146	159						14	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Language & Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT7BY					2024-07-03	WOS:000847249900011
J	Deng, JW; Zubair, A; Park, YJ; Affan, E; Zuo, QK				Deng, Jiawen; Zubair, Areeba; Park, Ye-Jean; Affan, Eesha; Zuo, Qi Kang			The use of large language models in medicine: proceeding with caution	CURRENT MEDICAL RESEARCH AND OPINION			English	Article						ChatGPT; large language model; medicine; GPT		Large language models, like ChatGPT and Bard, have potential clinical applications due to their ability to generate conversational responses and encode medical knowledge. However, their clinical adoption faces challenges including hallucinations, lack of transparency, and lack of consistency. Ethicolegal concerns surrounding patient consent, legal liability, and data privacy further complicate matters. Despite their promise, an optimistic but cautious approach is essential for the safe integration of large language models into clinical settings.	[Deng, Jiawen; Zubair, Areeba; Park, Ye-Jean] Univ Toronto, Temerty Fac Med, Toronto, ON, Canada; [Affan, Eesha] Carleton Univ, Fac Sci, Ottawa, ON, Canada; [Zuo, Qi Kang] Univ British Columbia UBC, Fac Med, Vancouver, BC, Canada; [Deng, Jiawen] Univ Toronto, Temerty Fac Med, 1 Kings Coll Cir, Toronto, ON M5S 1A8, Canada	University of Toronto; Carleton University; University of British Columbia; University of Toronto	Deng, JW (corresponding author), Univ Toronto, Temerty Fac Med, 1 Kings Coll Cir, Toronto, ON M5S 1A8, Canada.	dengj35@mcmaster.ca	Deng, Jiawen/X-8181-2019	Deng, Jiawen/0000-0002-8274-6468				Al-Medfa MK, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e14744; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Deng J., 2023, CLEVE CLIN J MED; Deng JW, 2023, POSTGRAD MED J, V99, P1298, DOI 10.1093/postmj/qgad069; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; OpenAI, 2023, ArXiv; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5	12	1	1	59	59	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0300-7995	1473-4877		CURR MED RES OPIN	Curr. Med. Res. Opin.	FEB 1	2024	40	2					151	153		10.1080/03007995.2023.2295411	http://dx.doi.org/10.1080/03007995.2023.2295411		DEC 2023	3	Medicine, General & Internal; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Research & Experimental Medicine	FR9G9	38093584				2024-07-03	WOS:001128890400001
C	Guo, MH; Wu, F; Jiang, JL; Yan, XR; Chen, GY; Li, WH; Zhao, YH; Sun, ZY		Sheng, VS; Hicks, C; Ling, C; Raghavan, V; Wu, X		Guo, Menghao; Wu, Fan; Jiang, Jinling; Yan, Xiaoran; Chen, Guangyong; Li, Wenhui; Zhao, Yunhong; Sun, Zeyi			Investigations on Scientific Literature Meta Information Extraction Using Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH, ICKG			English	Proceedings Paper	14th IEEE International Conference on Knowledge Graph (IEEE ICKG)	DEC 01-02, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Minist Educ China, Key Lab Knowledge Engn Big Data, Hefei Univ Technol, Anhui Assoc Artificial Intelligence, Inspur Co Ltd		information extraction; large language model; scientific literature		The meta information in scientific literature including article title, author, institutions, year, journal, etc., plays a critical role in providing useful information to research peers. Traditional meta information extraction methods usually rely on rules and templates. Recently, due to the booming of Large Language Models (LLMs), its application in scientific literature meta-information extraction has drawn more and more attention. This paper aims to explore and evaluate the effects of meta information extraction for scientific literature using large language models. First, datasets consisting of the publications in given academic areas are built for the experiments. Then, the task definition and evaluation metric (i.e., accuracy rate) are described. Various large language models as well as the traditional methodology are used in experiments to execute the task of meta information extraction. The results are analyzed and compared among the use of various LLMs.	[Guo, Menghao; Wu, Fan; Jiang, Jinling; Yan, Xiaoran; Chen, Guangyong; Li, Wenhui; Zhao, Yunhong; Sun, Zeyi] Zhejiang Lab, Res Ctr Knowledge Engn, Hangzhou, Peoples R China	Zhejiang Laboratory	Guo, MH (corresponding author), Zhejiang Lab, Res Ctr Knowledge Engn, Hangzhou, Peoples R China.	guomenghao@zhejianglab.com; wufan@zhejianglab.com; jiangjinling@zhejianglab.com; gychen@zhejianglab.com; gychen@zhejianglab.com; liwh@zhejianglab.com; zhaoyunhong@zhejianglab.com; sunzeyi@zhejianglab.com	YAN, Xiaoran/GQI-3109-2022	YAN, Xiaoran/0000-0001-6241-5744	CHACE-Knowledge Ocean Project from Research Center for Knowledge Engineering, Zhejiang Lab	CHACE-Knowledge Ocean Project from Research Center for Knowledge Engineering, Zhejiang Lab	This work is supported by CHACE-Knowledge Ocean Project from Research Center for Knowledge Engineering, Zhejiang Lab. The authors would like to thank Dr. Pengli Ji, Dr. Kexin Chen, and Dr. Jiezhong Qiu for constant discussion that sharpens the ideas of this research, and also thank Mr. Wujun Shao, and Mr. Yaohua Hu for the efforts on experiment evaluation.	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Boukhers Z, 2021, ACM-IEEE J CONF DIG, P250, DOI 10.1109/JCDL52503.2021.00076; Han H, 2003, ACM-IEEE J CONF DIG, P37; Han JB, 2022, NEURAL COMPUT APPL, V34, P12681, DOI 10.1007/s00521-022-07114-7; Hong Z, 2021, JOM-US, V73, P3383, DOI 10.1007/s11837-021-04902-9; Li Y., 2008, C EMPIRICAL METHODS, P21; Nasar Z, 2018, SCIENTOMETRICS, V117, P1931, DOI 10.1007/s11192-018-2921-5; Peng FC, 2006, INFORM PROCESS MANAG, V42, P963, DOI 10.1016/j.ipm.2005.09.002; Peng FC, 2004, HLT-NAACL 2004: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P329; Tkaczyk D, 2015, INT J DOC ANAL RECOG, V18, P317, DOI 10.1007/s10032-015-0249-8; Xiaoyu Tang, 2010, Proceedings 2010 IEEE 2nd Symposium on Web Society (SWS 2010), P346, DOI 10.1109/SWS.2010.5607427; Yang Y, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12199691	13	0	0	19	19	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0709-2				2023							249	254		10.1109/ICKG59574.2023.00036	http://dx.doi.org/10.1109/ICKG59574.2023.00036			6	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5RD					2024-07-03	WOS:001166570200031
J	Zhang, YC; Hao, YT				Zhang, Yichong; Hao, Yongtao			Traditional Chinese Medicine Knowledge Graph Construction Based on Large Language Models	ELECTRONICS			English	Article						traditional Chinese medicine; large language modeling; knowledge graph; interdisciplinary research		This study explores the use of large language models in constructing a knowledge graph for Traditional Chinese Medicine (TCM) to improve the representation, storage, and application of TCM knowledge. The knowledge graph, based on a graph structure, effectively organizes entities, attributes, and relationships within the TCM domain. By leveraging large language models, we collected and embedded substantial TCM-related data, generating precise representations transformed into a knowledge graph format. Experimental evaluations confirmed the accuracy and effectiveness of the constructed graph, extracting various entities and their relationships, providing a solid foundation for TCM learning, research, and application. The knowledge graph has significant potential in TCM, aiding in teaching, disease diagnosis, treatment decisions, and contributing to TCM modernization. In conclusion, this paper utilizes large language models to construct a knowledge graph for TCM, offering a vital foundation for knowledge representation and application in the field, with potential for future expansion and refinement.	[Zhang, Yichong; Hao, Yongtao] Tongji Univ, CAD Res Ctr, Shanghai 200092, Peoples R China	Tongji University	Hao, YT (corresponding author), Tongji Univ, CAD Res Ctr, Shanghai 200092, Peoples R China.	yichongzyc@163.com; hyongtao492@163.com						Braverman M., 2020, INT C MACHINE LEARNI, P1089; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen HN, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100959; Cheng BJ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/5531327; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fink M, 2004, P 17 INT C NEUR INF, P449, DOI [DOI 10.5555/2976040.2976097, 10.5555/2976040.2976097]; Hai-Hong E., 2019, Journal of Software, V30, P1793, DOI 10.13328/j.cnki.jos.005817; Han X., 2015, Small Microcomput. Syst, V36, P2813; He H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P659, DOI 10.1145/3308558.3313548; He Y., 2015, Comput. Appl. Softw, V32, P179; Hu Y, 2024, Arxiv, DOI [arXiv:2303.16416, DOI 10.48550/ARXIV.2303.16416]; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Kommineni VK, 2024, Arxiv, DOI arXiv:2403.08345; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79; Liu B., 2023, biomedRxiv; Liu Y., 2006, J. Intell, V9, P21; Ni XF, 2023, Arxiv, DOI arXiv:2303.14956; Open AI, Open AI Introducing Chatgpt; Raiaan MAK, 2023, IEEE ACCESS, V11, P42361, DOI 10.1109/ACCESS.2023.3272228; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306; Singhal Amit., 2012, Introducing the Knowledge Graph: things; Sun X., 2010, J. Guangzhou Univ. Tradit. Chin. Med, V27, P517; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Xiong WP, 2021, EVID-BASED COMPL ALT, V2021, DOI 10.1155/2021/9970063; Xu Tongyao, 2022, ICBDT 2022: 2022 5th International Conference on Big Data Technologies (ICBDT), P196, DOI 10.1145/3565291.3565323; Zheng ZQ, 2020, 11TH IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH (ICKG 2020), P560, DOI 10.1109/ICBK50248.2020.00084; Zhou Y, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WI 2019 COMPANION), P144, DOI 10.1145/3358695.3360938	30	0	0	58	58	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	APR	2024	13	7							1395	10.3390/electronics13071395	http://dx.doi.org/10.3390/electronics13071395			21	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	NN6N1		gold			2024-07-03	WOS:001201169600001
J	Betzler, BK; Chen, HC; Cheng, CY; Lee, CS; Ning, GC; Song, SJ; Lee, AY; Kawasaki, R; van Wijngaarden, P; Grzybowski, A; He, MG; Li, DW; Ran, AR; Ting, DSW; Teo, K; Ruamviboonsuk, P; Sivaprasad, S; Chaudhary, V; Tadayoni, R; Wang, XF; Cheung, CY; Zheng, YF; Wang, YX; Tham, YC; Wong, TY				Betzler, Bjorn Kaijun; Chen, Haichao; Cheng, Ching -Yu; Lee, Cecilia S.; Ning, Guochen; Song, Su Jeong; Lee, Aaron Y.; Kawasaki, Ryo; van Wijngaarden, Peter; Grzybowski, Andrzej; He, Mingguang; Li, Dawei; Ran, An Ran; Ting, Daniel Shu Wei; Teo, Kelvin; Ruamviboonsuk, Paisan; Sivaprasad, Sobha; Chaudhary, Varun; Tadayoni, Ramin; Wang, Xiaofei; Cheung, Carol Y.; Zheng, Yingfeng; Wang, Ya Xing; Tham, Yih Chung; Wong, Tien Yin			Large language models and their impact in ophthalmology	LANCET DIGITAL HEALTH			English	Article							DEEP LEARNING-SYSTEM; DIABETIC-RETINOPATHY; VALIDATION; EFFICACY; IMAGES; CARE	The advent of generative artificial intelligence and large language models has ushered in transformative applications within medicine. Specifically in ophthalmology, large language models offer unique opportunities to revolutionise digital eye care, address clinical workflow inefficiencies, and enhance patient experiences across diverse global eye care landscapes. Yet alongside these prospects lie tangible and ethical challenges, encompassing data privacy, security, and the intricacies of embedding large language models into clinical routines. This Viewpoint highlights the promising applications of large language models in ophthalmology, while weighing up the practical and ethical barriers towards their real-world implementation. This Viewpoint seeks to stimulate broader discourse on the potential of large language models in ophthalmology and to galvanise both clinicians and researchers into tackling the prevailing challenges and optimising the benefits of large language models while curtailing the associated risks.	[Cheng, Ching -Yu; Tham, Yih Chung] Natl Univ Singapore, Ctr Innovat & Precis Eye Hlth, Singapore, Singapore; [Cheng, Ching -Yu; Tham, Yih Chung] Natl Univ Singapore, Dept Ophthalmol, Singapore, Singapore; [Betzler, Bjorn Kaijun] Natl Univ Singapore, Yong Loo Lin Sch Med, Singapore, Singapore; [Chen, Haichao; Wong, Tien Yin] Tsinghua Univ, Inst Precis Med, Beijing, Peoples R China; [Cheng, Ching -Yu; Ting, Daniel Shu Wei; Teo, Kelvin; Tham, Yih Chung; Wong, Tien Yin] Singapore Natl Eye Ctr, Singapore Eye Res Inst, Singapore, Singapore; [Cheng, Ching -Yu; Ting, Daniel Shu Wei; Tham, Yih Chung] Duke NUS Med Sch, Ophthalmol & Visual Sci Acad Clin Program, Singapore, Singapore; [Lee, Cecilia S.; Lee, Aaron Y.] Univ Washington, Sch Med, Dept Ophthalmol, Seattle, WA USA; [Ning, Guochen] Tsinghua Univ, Sch Med, Dept Biomed Engn, Beijing, Peoples R China; [Song, Su Jeong] Sungkyunkwan Univ, Sch Med, Kangbuk Samsung Hosp, Dept Ophthalmol, Seoul, South Korea; [Kawasaki, Ryo] Osaka Univ, Grad Sch Med, Dept Social Med, Div Publ Hlth, Osaka, Japan; [Kawasaki, Ryo] Osaka Univ Hosp, Artificial Intelligence Ctr Med Res & Applicat, Osaka, Japan; [van Wijngaarden, Peter] Univ Melbourne, Ctr Eye Res Australia, Royal Victorian Eye & Ear Hosp, Melbourne, VA, Australia; [van Wijngaarden, Peter] Univ Melbourne, Dept Surg, Ophthalmol, Melbourne, VA, Australia; [Grzybowski, Andrzej] Fdn Ophthalmol Dev, Inst Res Ophthalmol, Poznan, Poland; [He, Mingguang] Hong Kong Polytech Univ, Hong Kong, Peoples R China; [Li, Dawei] Peking Univ, Coll Future Technol, Beijing, Peoples R China; [Ran, An Ran; Cheung, Carol Y.] Chinese Univ Hong Kong, Dept Ophthalmol & Visual Sci, Hong Kong, Peoples R China; [Ruamviboonsuk, Paisan] Rajavithi Hosp, Dept Ophthalmol, Bangkok, Thailand; [Sivaprasad, Sobha] Moorfields Eye Hosp, NIHR Biomed Res Ctr Ophthalmol, London, England; [Chaudhary, Varun] McMaster Univ, Dept Surg, Hamilton, ON, Canada; [Tadayoni, Ramin] Univ Paris Cite, Lariboisiere, AP HP, St Louis, France; [Tadayoni, Ramin] Rothschild Fdn Hosp, Paris, France; [Wang, Xiaofei] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Key Lab Biomech & Mechanobiol,Minist Educ, Beijing, Peoples R China; [Zheng, Yingfeng] Sun Yat Sen Univ, Zhongshan Ophthalm Ctr, State Key Lab Ophthalmol, Guangzhou, Peoples R China; [Zheng, Yingfeng] Guangdong Lab, Guangzhou Regenerat Med & Hlth, Guangzhou, Peoples R China; [Wang, Ya Xing] Capital Med Univ, Beijing Inst Ophthalmol, Beijing Tongren Hosp, Beijing Ophthalmol & Visual Sci Key Lab, Beijing, Peoples R China; [Tham, Yih Chung] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore, Singapore	National University of Singapore; National University of Singapore; National University of Singapore; Tsinghua University; Singapore National Eye Center; National University of Singapore; National University of Singapore; University of Washington; University of Washington Seattle; Tsinghua University; Sungkyunkwan University (SKKU); Samsung Medical Center; Osaka University; Osaka University; University of Melbourne; Centre for Eye Research Australia; Royal Victorian Eye & Ear Hospital; University of Melbourne; Hong Kong Polytechnic University; Peking University; Chinese University of Hong Kong; Rajavithi Hospital; University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; McMaster University; Assistance Publique Hopitaux Paris (APHP); Universite Paris Cite; Hopital Universitaire Saint-Louis - APHP; Fondation Adolphe de Rothschild; Beihang University; Sun Yat Sen University; Bioland Lab; Capital Medical University; National University of Singapore	Tham, YC (corresponding author), Singapore Natl Eye Ctr, Singapore Eye Res Inst, Singapore, Singapore.; Tham, YC (corresponding author), Duke NUS Med Sch, Ophthalmol & Visual Sci Acad Clin Program, Singapore, Singapore.; Tham, YC (corresponding author), Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore, Singapore.	thamyc@nus.edu.sg	Tham, Yih Chung/IUP-0091-2023; Sivaprasad, S./D-6876-2015; li, yan/KFQ-3850-2024; Chaudhary, Varun/AAQ-2371-2021; Li, Yang/KFB-5350-2024; Zheng, Yingfeng/KGK-8305-2024; Grzybowski, A/E-4486-2010; Cheng, Chingyu/ADB-9835-2022; Wong, Tien Yin/AAC-9724-2020; Ning, Guochen/AAP-5773-2021; CHEN, HAICHAO/HRC-8252-2023; Liu, Yan/KFQ-1417-2024; Li, Yan/KFQ-9244-2024	Sivaprasad, S./0000-0001-8952-0659; Chaudhary, Varun/0000-0002-9988-4146; Zheng, Yingfeng/0000-0002-9952-6445; Grzybowski, A/0000-0002-3724-2391; Cheng, Chingyu/0000-0002-1872-0896; Wong, Tien Yin/0000-0002-8448-1264; Ning, Guochen/0000-0003-0282-7303; CHEN, HAICHAO/0000-0002-4382-1664; 	National Medical Research Council of Singapore [NMRC/MOH/HCSAINV21nov-0001]; National Key RAMP;D Program, China [2022YFC2502800]	National Medical Research Council of Singapore(National Medical Research Council, Singapore); National Key RAMP;D Program, China	<B>Acknowledgments</B> YCT is supported by a grant from the National Medical Research Council of Singapore (grant number NMRC/MOH/HCSAINV21nov-0001) . TYW receives funding from the National Key R&D Program, China (grant number 2022YFC2502800) . The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of this Viewpoint.	[Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Argil, 2023, GEN CHATGPT IM US AR; Baxter SL, 2019, AM J OPHTHALMOL, V206, P161, DOI 10.1016/j.ajo.2019.03.014; Burlina PM, 2017, JAMA OPHTHALMOL, V135, P1170, DOI 10.1001/jamaophthalmol.2017.3782; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Channa R, 2016, JAMA OPHTHALMOL, V134, P312, DOI 10.1001/jamaophthalmol.2015.5778; Chen CL, 2021, OPHTHALMOLOGY, V128, P208, DOI 10.1016/j.ophtha.2020.09.013; Chen Mark., 2021, EVALUATING LARGE LAN, P2021, DOI [DOI 10.48550/ARXIV.2107.03374, 10.48550/ARXIV.2107.03374]; Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Chuckpaiwong V, 2022, CLIN OPHTHALMOL, V16, P1173, DOI 10.2147/OPTH.S360377; Clark P, 2018, ARXIV, DOI DOI 10.48550/ARXIV.1803.05457; Cobbe K., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2110.14168; Cohen IG, 2023, AM J BIOETHICS, V23, P8, DOI 10.1080/15265161.2023.2233357; Cuttitta A, 2021, JAMA OPHTHALMOL, V139, P1309, DOI 10.1001/jamaophthalmol.2021.4393; Dua D, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1903.00161; Fang XL, 2022, BRIT J OPHTHALMOL, V106, P1642, DOI 10.1136/bjophthalmol-2021-318866; Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216; Gunasekeran DV, 2021, LANCET DIGIT HEALTH, V3, pe124, DOI 10.1016/S2589-7500(20)30287-9; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hasal M, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6426; Hendrycks D., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2009.03300; Hoffmann J., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2203.15556; Hood DC, 2018, OPHTHALMOLOGY, V125, P1207, DOI 10.1016/j.ophtha.2018.04.020; Hribar MR, 2019, OPHTHALMOLOGY, V126, P347, DOI 10.1016/j.ophtha.2018.10.009; Keenum Z, 2016, JAMA OPHTHALMOL, V134, P1221, DOI 10.1001/jamaophthalmol.2016.3081; Khou V, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-047246; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li JPO, 2021, PROG RETIN EYE RES, V82, DOI 10.1016/j.preteyeres.2020.100900; Lu AQ, 2022, J CATARACT REFR SURG, V48, P1242, DOI 10.1097/j.jcrs.0000000000000963; Martin Leslie R, 2005, Ther Clin Risk Manag, V1, P189; Medenilla A., 2023, PLoS Digital Health, V2; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; Open AI, 2023, GPT-4 Technical Report; Parviainen J, 2022, MED HEALTH CARE PHIL, V25, P61, DOI 10.1007/s11019-021-10049-w; Raman V, 2021, EYE, V35, P388, DOI 10.1038/s41433-020-1114-7; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Scao T. L., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.05100; Shah R, 2022, EYE, V36, P1754, DOI 10.1038/s41433-021-01728-2; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Taylor R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.09085; Teo AWJ, 2020, EYE, V34, P2123, DOI 10.1038/s41433-020-0920-2; Tham YC, 2022, BRIT J OPHTHALMOL, V106, P452, DOI 10.1136/bjophthalmol-2020-317683; Tham YC, 2021, LANCET DIGIT HEALTH, V3, pE29, DOI 10.1016/S2589-7500(20)30271-5; Ting DSW, 2019, PROG RETIN EYE RES, V72, DOI 10.1016/j.preteyeres.2019.04.003; Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Vazirani AA, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-019-0211-0; Weinreb RN, 2014, JAMA-J AM MED ASSOC, V311, P1901, DOI 10.1001/jama.2014.3192; Witte JH, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1612.06244(PREPRINT; Yasunaga M., 2022, Advances in Neural Information Processing Systems, P37309; Yasunaga M, 2022, ARXIV, DOI DOI 10.18653/V1/2022.ACL-LONG.551(PREPRINT; Yee A, 2021, CONTACT LENS ANTERIO, V44, DOI 10.1016/j.clae.2021.02.018; Zellers R, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1905.07830; Zhang ZH, 2023, FRONT CELL DEV BIOL, V11, DOI 10.3389/fcell.2023.1133680	57	9	9	79	102	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2589-7500		LANCET DIGIT HEALTH	Lancet Digit. Health	DEC	2023	5	12					E917	E924		10.1016/S2589-7500(23)00201-7	http://dx.doi.org/10.1016/S2589-7500(23)00201-7			8	Medical Informatics; Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	Medical Informatics; General & Internal Medicine	CJ6K9	38000875	gold, Green Accepted			2024-07-03	WOS:001124923000001
C	Leinonen, J; Hellas, A; Sarsa, S; Reeves, B; Denny, P; Prather, J; Becker, BA			ACM	Leinonen, Juho; Hellas, Arto; Sarsa, Sami; Reeves, Brent; Denny, Paul; Prather, James; Becker, Brett A.			Using Large Language Models to Enhance Programming Error Messages	PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023			English	Proceedings Paper	54th Annual ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS)	MAR 15-18, 2023	Toronto, CANADA	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		AI; Codex; compiler error messages; large language models; programming error messages; syntax error messages		A key part of learning to program is learning to understand programming error messages. They can be hard to interpret and identifying the cause of errors can be time-consuming. One factor in this challenge is that the messages are typically intended for an audience that already knows how to program, or even for programming environments that then use the information to highlight areas in code. Researchers have been working on making these errors more novice friendly since the 1960s, however progress has been slow. The present work contributes to this stream of research by using large language models to enhance programming error messages with explanations of the errors and suggestions on how to fix them. Large language models can be used to create useful and novice-friendly enhancements to programming error messages that sometimes surpass the original programming error messages in interpretability and actionability. These results provide further evidence of the benefits of large language models for computing educators, highlighting their use in areas known to be challenging for students. We further discuss the benefits and downsides of large language models and highlight future streams of research for enhancing programming error messages.	[Leinonen, Juho; Hellas, Arto; Sarsa, Sami] Aalto Univ, Espoo, Finland; [Reeves, Brent; Prather, James] Abilene Christian Univ, Abilene, TX 79699 USA; [Denny, Paul] Univ Auckland, Auckland, New Zealand; [Becker, Brett A.] Univ Coll Dublin, Dublin, Ireland	Aalto University; Abilene Christian University; University of Auckland; University College Dublin	Leinonen, J (corresponding author), Aalto Univ, Espoo, Finland.	juho.2.leinonen@aalto.fi; arto.hellas@aalto.fi; sami.sarsa@aalto.fi; brent.reeves@acu.edu; paul@cs.auckland.ac.nz; james.prather@acu.edu; brett.becker@ucd.ie	Leinonen, Juho/D-2162-2018	Leinonen, Juho/0000-0001-6829-9449; Sarsa, Sami/0000-0002-7277-9282; Prather, James/0000-0003-2807-6042; Reeves, Brent/0000-0001-5781-1136; Denny, Paul/0000-0002-5150-9806				Ahmed T, 2022, Arxiv, DOI arXiv:2104.14671; Ahmed UZ, 2018, PROC INT CONF SOFTW, P78, DOI 10.1145/3183377.3183383; Barik T, 2017, PROC INT CONF SOFTW, P575, DOI 10.1109/ICSE.2017.59; Barik Titus, 2018, Error Messages as Rational Reconstructions; BECKER BA, 2016, P 47 ACM TECHN S COM, P126, DOI DOI 10.1145/2839509.2844584; Becker BA, 2021, COMMUN ACM, V64, P27, DOI 10.1145/3469115; Becker BA, 2019, PROCEEDINGS OF THE WORKING GROUP REPORTS ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE-WGR '19), P177, DOI 10.1145/3344429.3372508; Becker BA, 2018, SIGCSE'18: PROCEEDINGS OF THE 49TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P640, DOI 10.1145/3159450.3159461; Becker BA, 2016, COMPUT SCI EDUC, V26, P148, DOI 10.1080/08993408.2016.1225464; Becker Brett A., 2021, AUSTR COMP ED C VIRT, P181, DOI [DOI 10.1145/3441636.3442320, 10.1145/3441636.3442320]; Becker Brett A, 2016, 12 CHINAEUROPE INT S, P28; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Denny P., 2014, Proceedings of the 2014 conference on Innovation technology in computer science education ss, P273, DOI [10.1145/2591708.2591748, DOI 10.1145/2591708.2591748]; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny P., 2011, ITICSE, P208, DOI [10.1145/1999747.1999807, DOI 10.1145/1999747.1999807]; Denny Paul, 2021, P 2021 CHI C HUMAN F, P1, DOI [DOI 10.1145/3411764.3445696, 10.1145/3411764, DOI 10.1145/3411764]; Denny Paul, 2020, P 2020 ACM C INNOVAT, P480; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gupta R, 2019, AAAI CONF ARTIF INTE, P930; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Kalyuga Slava., 2009, MANAGING COGNITIVE L, P58; Karvelas I, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P759, DOI 10.1145/3328778.3366882; Kohn T, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P524, DOI 10.1145/3287324.3287381; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Li H, 2022, COMMUN ACM, V65, P56, DOI 10.1145/3490443; Liu D, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P666, DOI 10.1145/3287324.3287503; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pettit R, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P465, DOI 10.1145/3017680.3017768; Prather J, 2018, ICER'18: PROCEEDINGS OF THE 2018 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P41, DOI 10.1145/3230977.3230981; Prather J, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P74, DOI 10.1145/3105726.3106169; Reestman K, 2019, ICER '19 - PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH, P249, DOI 10.1145/3291279.3339423; ROSEN S, 1965, COMMUN ACM, V8, P661, DOI 10.1145/365660.365671; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Stefik A, 2013, ACM T COMPUT EDUC, V13, DOI 10.1145/2534973; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS	38	40	41	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9431-4				2023							563	569		10.1145/3545945.3569770	http://dx.doi.org/10.1145/3545945.3569770			7	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW2KI		Bronze, Green Submitted, Green Published			2024-07-03	WOS:001117817800083
C	Fu, WM; Li, SJ; Zhao, YF; Ma, HC; Dutta, R; Zhang, X; Yang, KC; Jin, Y; Guo, XL			IEEE	Fu, Weimin; Li, Shijie; Zhao, Yifang; Ma, Haocheng; Dutta, Raj; Zhang, Xuan; Yang, Kaichen; Jin, Yier; Guo, Xiaolong			Hardware Phi-1.5B: A Large Language Model Encodes Hardware Domain Specific Knowledge	29TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, ASP-DAC 2024	Asia and South Pacific Design Automation Conference Proceedings		English	Proceedings Paper	29th Asia and South Pacific Design Automation Conference (ASP-DAC)	JAN 22-25, 2024	BrainKorea Four 21, Incheon, SOUTH KOREA	ACM Special Interest Grp Design Automat, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, EIC, Incheon Tourism Org, Korea Tourism Org, Cadence Design Syst Inc	BrainKorea Four 21	Large Language Model; Hardware Design; Hardware Verification; Generative AI		In the rapidly evolving semiconductor industry, where research, design, verification, and manufacturing are intricately linked, the potential of Large Language Models to revolutionize hardware design and security verification is immense. The primary challenge, however, lies in the complexity of hardware-specific issues that are not adequately addressed by the natural language or software code knowledge typically acquired during the pretraining stage. Additionally, the scarcity of datasets specific to the hardware domain poses a significant hurdle in developing a foundational model. Addressing these challenges, this paper introduces Hardware Phi-1.5B, an innovative large language model specifically tailored for the hardware domain of the semiconductor industry. We have developed a specialized, tiered dataset-comprising small, medium, and large subsets-and focused our efforts on pre-training using the medium dataset. This approach harnesses the compact yet efficient architecture of the Phi-1.5B model. The creation of this first pre-trained, hardware domain-specific large language model marks a significant advancement, offering improved performance in hardware design and verification tasks and illustrating a promising path forward for AI applications in the semiconductor sector.	[Fu, Weimin; Guo, Xiaolong] Kansas State Univ, Manhattan, KS 66506 USA; [Li, Shijie; Zhao, Yifang; Jin, Yier] Univ Sci & Technol China, Hefei, Peoples R China; [Yang, Kaichen] Michigan Technol Univ, Houghton, MI USA; [Zhang, Xuan] Washington Univ, St Louis, MO USA; [Dutta, Raj] Silicon Assurance, Gainesville, FL USA; [Ma, Haocheng] Tianjin Univ, Tianjin, Peoples R China	Kansas State University; Chinese Academy of Sciences; University of Science & Technology of China, CAS; Michigan Technological University; Washington University (WUSTL); Tianjin University	Fu, WM (corresponding author), Kansas State Univ, Manhattan, KS 66506 USA.	weiminf@ksu.edu; shijie_li@mail.ustc.edu.cn; zhaoyifang@mail.ustc.edu.cn; hc_ma@tju.edu.cn; rajgautamdutta@siliconassurance.com; xuan.zhang@wustl.edu; kaicheny@mtu.edu; jinyier@ustc.edu.cn; guoxiaolong@ksu.edu			National Science Foundation [CCF-2019310]; First Award Program of ARISE in EPSCoR [2148878]	National Science Foundation(National Science Foundation (NSF)); First Award Program of ARISE in EPSCoR	Portions of this work were supported by the National Science Foundation (CCF-2019310, First Award Program of ARISE in EPSCoR 2148878).	Ahmad B, 2023, Arxiv, DOI [arXiv:2302.01215, 10.48550/arXiv.2302.01215]; [Anonymous], Cad for assurance of electronic systems," an initiative to assemble and share information on CAD for trust/assurance activities in academia and industry; [Anonymous], Trust-hub: A resource for hardware security and trust; [Anonymous], 2022, Common Weakness Enumeration (CWE-699); Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Cheng R., 2021, ADV NEUR IN, P16508; Common Weakness Enumeration (CWE), Cwe-1189: Improper isolation of shared resources on system-on-a-chip (soc) (4.13); Computer T., 2023, Redpajama: an open dataset for training large language models; Dao T., 2022, Advances in Neural Information Processing Systems, V35, P16344, DOI [10.48550/arXiv2205.14135, DOI 10.48550/ARXIV2205.14135]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fu WM, 2023, 2023 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM, ASIANHOST, DOI 10.1109/AsianHOST59942.2023.10409307; Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1; Guadarrama S., 2021, Circuit Training: An open-source framework for generating chip floor plans with distributed deep reinforcement learning; Hains G, 2018, ANN IEEE SYST CONF, P230; Hoffa F., Github on bigquery: Analyze all the open source code; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kande R., 2023, Llm-assisted generation of hardware assertions; Kande R, 2023, arXiv; Kingma D. P., 2017, ARXIV; Kocetkov Denis, 2022, PREPRINT; Lai Y, 2023, Arxiv, DOI arXiv:2306.14744; Li YZ, 2023, Arxiv, DOI arXiv:2309.05463; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2023, GPT-4 Technical Report; Orenes-Vera M, 2023, Arxiv, DOI arXiv:2309.09437; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Roziere B, 2024, Arxiv, DOI arXiv:2308.12950; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Thakur S., 2023, ARXIV; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Xu Y., 2020, Automatic cross-replica sharding of weight update in data-parallel training; Zhang ZX, 2023, Arxiv, DOI arXiv:2310.04535	36	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6961		979-8-3503-9354-5	ASIA S PACIF DES AUT			2024							349	354		10.1109/ASP-DAC58780.2024.10473927	http://dx.doi.org/10.1109/ASP-DAC58780.2024.10473927			6	Automation & Control Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BW7ST		Green Submitted			2024-07-03	WOS:001196002900056
J	Zhang, YX; He, Y; Xia, YN; Wang, YB; Dong, XH; Yao, JC				Zhang, Yixiao; He, Yuan; Xia, Yining; Wang, Yanbo; Dong, Xianghui; Yao, Junchen			Exploring the representation of Chinese cultural symbols dissemination in the era of large language models	INTERNATIONAL COMMUNICATION OF CHINESE CULTURE			English	Article; Early Access						Chinese civilization; Large language models; Artificial intelligence; Overseas dissemination		Cultural symbols serve as one of the most direct and tangible representations of culture spreading, including for the dissemination of Chinese civilization. This study embarks on an exploratory analysis and comparison of the portrayal of these 'Chinese cultural symbols' by Chinese and international mainstream large language models. Our findings reveal that calligraphy, Confucian philosophy, the Forbidden City, Peking Opera, and the Great Wall constitute the top five Chinese cultural symbols that receive the most attention from large language models. However, the depiction of the "Chinese cultural landscape" by current large language models predominantly concentrates on elements of traditional humanities and social sciences, with a noticeable absence of China's contemporary development and technological accomplishments. Concurrently, there are significant disparities in the representation of "Chinese cultural symbols" between domestic and international large language models. This includes issues such as the international models deficiency in providing a holistic portrayal of China's Political Ideologies and Institutional Systems. In light of these findings, this study proposes strategic suggestions and recommendations for promoting exchanges and mutual learning among civilizations in the era of large language models.	[Zhang, Yixiao; Xia, Yining; Wang, Yanbo; Yao, Junchen] Beijing Normal Univ, Sch Journalism & Commun, Beijing, Peoples R China; [He, Yuan] Hebei Univ, Sch Journalism & Commun, Baoding 071002, Hebei, Peoples R China; [Wang, Yanbo] Northwest Normal Univ, Sch Educ Technol, Lanzhou, Gansu, Peoples R China; [Dong, Xianghui] Tianjin Acad Social Sci, Publ Opin Res Inst, Tianjin, Peoples R China	Beijing Normal University; Hebei University; Northwest Normal University - China	He, Y (corresponding author), Hebei Univ, Sch Journalism & Commun, Baoding 071002, Hebei, Peoples R China.	heyuan_melina@163.com	Yanbo, Wang/KFQ-7084-2024	Yanbo, Wang/0000-0002-6138-8999				China News Network, 2008, Foreign media ranks top 20 Chinese cultural symbols: Chinese language tops the list, Chairman Mao included; Dai YC, 2022, INT COMMUN CHIN CULT, V9, P127, DOI 10.1007/s40636-022-00254-4; Dan Yu., 2015, People's Tribune, DOI [10.16619/j.cnki.rmlt.2015.24.001, DOI 10.16619/J.CNKI.RMLT.2015.24.001]; Hongzhong Zhang., 2011, Modern Communication (Journal of Communication University of China), DOI [10.19997/j.cnki.xdcb.2011.06.004, DOI 10.19997/J.CNKI.XDCB.2011.06.004]; Hu HP., 2003, Seeker, V03, P209, DOI [10.16059/j.cnki.cn43-1008/c.2003.03.074, DOI 10.16059/J.CNKI.CN43-1008/C.2003.03.074]; Hu Q.L., 2011, Journal of Wuyi University (Social Science Edition), V04, P29; Jiang F., 2022, International Communications, V11, P13; Liu X., 2021, China Radio & TV Academic Journal, V05, P16; Luan Y.M., 2018, International Communications, V04, P58; Shi A.B., 2022, International Communications, V11, P4; Tu LB., 2020, Contemporary World, DOI [10.19422/j.cnki.ddsj.2020.11.009, DOI 10.19422/J.CNKI.DDSJ.2020.11.009]; Wu B., 1998, History of the overseas dissemination of Chinese culture; Wu Y., 2020, Frontiers Academic Frontiers, DOI [10.16619/j.cnki.rmltxsqy.2020.15.009, DOI 10.16619/J.CNKI.RMLTXSQY.2020.15.009]; Ying Wu., 2021, Youth Journalist, DOI [10.15997/j.cnki.qnjz.2021.06.003, DOI 10.15997/J.CNKI.QNJZ.2021.06.003]; Zhang CY., 2014, Journal of Yunnan Normal University(Teaching Studying Chinese as a Foreign Language Edition), DOI [10.16802/j.cnki.ynsddw.2014.01.003, DOI 10.16802/J.CNKI.YNSDDW.2014.01.003]; Zhang HZ., 2023, Journalism and Mass Communication, DOI [10.15897/j.cnki.cn51-1046/g2.20231107.003, DOI 10.15897/J.CNKI.CN51-1046/G2.20231107.003]; Zhu W., 2021, Scientia Sinica(Informationis), P1802	17	0	0	1	1	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2197-4233	2197-4241		INT COMMUN CHIN CULT	Int. Commun. Chin. Cult.	2024 MAY 11	2024										10.1007/s40636-024-00293-z	http://dx.doi.org/10.1007/s40636-024-00293-z		MAY 2024	23	Area Studies; Asian Studies	Emerging Sources Citation Index (ESCI)	Area Studies; Asian Studies	QJ1D9					2024-07-03	WOS:001220407700001
C	Broekens, J; Hilpert, B; Verberne, S; Baraka, K; Gebhard, P; Plaat, A			IEEE	Broekens, Joost; Hilpert, Bernhard; Verberne, Suzan; Baraka, Kim; Gebhard, Patrick; Plaat, Aske			Fine-grained Affective Processing Capabilities Emerging from Large Language Models	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION, ACII	International Conference on Affective Computing and Intelligent Interaction		English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			ChatGPT; Large Language Models; sentiment analysis; emotion representation; computational modeling of emotion; emotion elicitation	APPRAISAL; CONTEXT	Large language models, in particular generative pre-trained transformers (GPTs), show impressive results on a wide variety of language-related tasks. In this paper, we explore ChatGPT's zero-shot ability to perform affective computing tasks using prompting alone. We show that ChatGPT a) performs meaningful sentiment analysis in the Valence, Arousal and Dominance dimensions, b) has meaningful emotion representations in terms of emotion categories and these affective dimensions, and c) can perform basic appraisal-based emotion elicitation of situations based on a prompt-based computational implementation of the OCC appraisal model. These findings are highly relevant: First, they show that the ability to solve complex affect processing tasks emerges from language-based token prediction trained on extensive data sets. Second, they show the potential of large language models for simulating, processing and analyzing human emotions, which has important implications for various applications such as sentiment analysis, socially interactive agents, and social robotics.	[Broekens, Joost; Hilpert, Bernhard; Verberne, Suzan; Plaat, Aske] Leiden Univ, LIACS, Leiden, Netherlands; [Baraka, Kim] Free Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands; [Gebhard, Patrick] German Res Ctr Artificial Intelligence DFKI, Saarbrucken, Germany	Leiden University; Leiden University - Excl LUMC; Vrije Universiteit Amsterdam; German Research Center for Artificial Intelligence (DFKI)	Broekens, J (corresponding author), Leiden Univ, LIACS, Leiden, Netherlands.	joost.broekens@gmail.com; b.hilpert@liacs.leidenuniv.nl; s.verberne@liacsleidenuniv.nl; k.baraka@vu.nl; patrick.gebhard@dfki.de; aske.plaat@gmail.com	Hilpert, Bernhard/JZT-7340-2024; Verberne, Suzan/K-3993-2019	Hilpert, Bernhard/0000-0002-0011-2905; Verberne, Suzan/0000-0002-9609-9505; Baraka, Kim/0000-0003-4381-4234	Hybrid Intelligence project [024.004.022]	Hybrid Intelligence project	This research is partly sponsored by the Hybrid Intelligence project, grant number 024.004.022. Special thanks to Fabiola Diana and her colleagues for their help with data collection.	Amin M. M., 2023, Will affective computing emerge from foundation models and general AI? a first evaluation on ChatGPT; [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478; Barrett LF, 2011, CURR DIR PSYCHOL SCI, V20, P286, DOI 10.1177/0963721411422522; Bradley M. M., 2007, Technical report D-1; Broekens J, 2012, International Journal of Synthetic Emotions (IJSE), V3, P33; Broekens J., 2021, HDB SOCIALLY INTERAC, V1, P349, DOI DOI 10.1145/3477322.3477333; Broekens J, 2018, Arxiv, DOI arXiv:1807.08941; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Calvo R. A., 2015, The Oxford handbook of affective computing; Canamero L, 2019, IEEE Transactions on Affective Computing, P1; Chan JYL, 2023, ARTIF INTELL REV, V56, P749, DOI 10.1007/s10462-022-10183-8; Devlin J., 2018, BERT PRE TRAINING DE; Dias J, 2005, LECT NOTES ARTIF INT, V3808, P127, DOI 10.1007/11595014_13; Dudzik B., 2019 8 INT C AFF COM, P206; Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627; Lindquist KA, 2013, EMOT REV, V5, P66, DOI 10.1177/1754073912451351; Lugrin B., 2021, The Handbook on Socially Interactive Agents: 20 Years of Research on Embodied Conversational Agents, Intelligent Virtual Agents, and Social Robotics Volume 1: Methods, Behavior, Cognition, V37; Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005; Mendes GA, 2023, LECT NOTES COMPUT SC, V13980, P84, DOI 10.1007/978-3-031-28244-7_6; Ortony A., 1988, The cognitive structure of emotions; Ouyang L., 2022, NEURIPS; Picard RW, 2003, INT J HUM-COMPUT ST, V59, P55, DOI 10.1016/S1071-5819(03)00052-1; Picard RW., 1997, AFFECTIVE COMPUTING, V252; Popescu A, 2014, IEEE T AFFECT COMPUT, V5, P32, DOI 10.1109/T-AFFC.2013.24; Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003; Radford A., 2018, IMPROVING LANGUAGE U; Reisenzein R, 2009, EMOT REV, V1, P214, DOI 10.1177/1754073909103589; Rosenthal S., 2019, SemEval-2017 task 4: Sentiment analysis in Twitter; Rouast PV, 2021, IEEE T AFFECT COMPUT, V12, P524, DOI 10.1109/TAFFC.2018.2890471; RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X; Scherer K. R., 1984, Approaches to emotion, P293; Seoh R, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6311; Smith CA, 2009, COGNITION EMOTION, V23, P1352, DOI 10.1080/02699930902860386; Tao JH, 2005, LECT NOTES COMPUT SC, V3784, P981; van der Meer M., 2022, P 9 WORKSH ARG MIN, P95; Vaswani A, 2017, ADV NEUR IN, V30; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52; Zhong RQ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P2856	39	0	0	6	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2156-8103		979-8-3503-2743-4	INT CONF AFFECT			2023										10.1109/ACII59096.2023.10388177	http://dx.doi.org/10.1109/ACII59096.2023.10388177			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IH		Green Submitted			2024-07-03	WOS:001161369900036
J	Trichopoulos, G; Konstantakis, M; Alexandridis, G; Caridakis, G				Trichopoulos, Georgios; Konstantakis, Markos; Alexandridis, Georgios; Caridakis, George			Large Language Models as Recommendation Systems in Museums	ELECTRONICS			English	Article						large language models; recommender systems; GPT-4; context awareness; personalization; cultural heritage; museum	DESIGN	This paper proposes the utilization of large language models as recommendation systems for museum visitors. Since the aforementioned models lack the notion of context, they cannot work with temporal information that is often present in recommendations for cultural environments (e.g., special exhibitions or events). In this respect, the current work aims to enhance the capabilities of large language models through a fine-tuning process that incorporates contextual information and user instructions. The resulting models are expected to be capable of providing personalized recommendations that are aligned with user preferences and desires. More specifically, Generative Pre-trained Transformer 4, a knowledge-based large language model is fine-tuned and turned into a context-aware recommendation system, adapting its suggestions based on user input and specific contextual factors such as location, time of visit, and other relevant parameters. The effectiveness of the proposed approach is evaluated through certain user studies, which ensure an improved user experience and engagement within the museum environment.	[Trichopoulos, Georgios; Konstantakis, Markos; Caridakis, George] Univ Aegean, Dept Cultural Technol & Commun, Univ Hill, Mitilini 81100, Greece; [Alexandridis, Georgios] Natl & Kapodistrian Univ Athens, Dept Digital Ind Technol, Psachna 34400, Greece	University of Aegean; National & Kapodistrian University of Athens	Trichopoulos, G (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Univ Hill, Mitilini 81100, Greece.	gtricho@aegean.gr; mkonstadakis@aegean.gr; gealexandri@uoa.gr; gcari@aegean.gr	Konstantakis, Markos/HDN-2263-2022; Caridakis, George/F-2689-2013	Konstantakis, Markos/0000-0003-0656-693X; Trichopoulos, Georgios/0000-0002-6979-2304; Alexandridis, Georgios/0000-0002-3611-8292; Caridakis, George/0000-0001-9884-935X				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agapiou A, 2023, HERITAGE-BASEL, V6, P4072, DOI 10.3390/heritage6050214; Alexandridis G, 2019, USER MODEL USER-ADAP, V29, P201, DOI 10.1007/s11257-019-09227-6; Baloian N, 2021, J UNIVERS COMPUT SCI, V27, P1275, DOI 10.3897/jucs.77153; Bannon L, 2005, COMMUN ACM, V48, P62, DOI 10.1145/1047671.1047706; Besoain F, 2021, INFORMATION, V12, DOI 10.3390/info12060244; Bongini P., 2022, P EUR C COMP VIS, P268; Cai P., 2023, Res. Sq, ppr, DOI [10.21203/rs.3.rs-3074947/v1, DOI 10.21203/RS.3.RS-3074947/V1]; Dal Falco F, 2017, DES J, V20, pS3975, DOI 10.1080/14606925.2017.1352900; Fayyaz Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217748; Grieser K., 2007, Proceedings of the Workshop on Language for Cultural Heritage Data, P49; Hazan S., 2023, P EVA LONDON 2023, P77, DOI 10.14236/ewic/EVA2023.13; Hettmann W., 2022, INT C ARTSIT INTERAC, P201; Huang HY, 2023, Arxiv, DOI [arXiv:2304.03086, 10.1038/s41368-023-00239-y]; Khanal SS, 2020, EDUC INF TECHNOL, V25, P2635, DOI 10.1007/s10639-019-10063-9; Konstantakis M, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040144; Konstantakis M, 2020, BIG DATA COGN COMPUT, V4, DOI 10.3390/bdcc4020012; Kropf M.B., 1989, J. Mus. Educ, V14, P5, DOI DOI 10.1080/10598650.1989.11510105; Mann Eytan, 2022, 2022 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR), P130, DOI 10.1109/AIVR56993.2022.00026; Pavlidis G, 2019, J CULT HERIT, V35, P183, DOI 10.1016/j.culher.2018.06.003; planner5d, Planner 5D: House Design Software|Home Design in 3D; planner5d, MMMA-Planner 5D; Qiang Pu, 2012, International Journal of Information Technology and Computer Science, V4, P19, DOI 10.5815/ijitcs.2012.10.02; Renjith S, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102078; siu Sai Cheong, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4448091, DOI 10.2139/SSRN.4448091]; Spennemann DHR, 2023, Preprints, DOI [10.20944/preprints202307.2035.v1, 10.20944/preprints202307.2035.v1, DOI 10.20944/PREPRINTS202307.2035.V1]; Trichopoulos G, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7030148; Urquhart C., 2019, Ph.D. Thesis; Varitimiadis S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199160; Vermeeren A, 2018, SPR SER CULT COMPUT, P1, DOI 10.1007/978-3-319-58550-5; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]; Zhang Q, 2021, COMPLEX INTELL SYST, V7, P439, DOI 10.1007/s40747-020-00212-w	33	4	4	41	42	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	SEP	2023	12	18							3829	10.3390/electronics12183829	http://dx.doi.org/10.3390/electronics12183829			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	AN8S9		Green Submitted, gold			2024-07-03	WOS:001119243600001
J	Sorin, V; Barash, Y; Konen, E; Klang, E				Sorin, Vera; Barash, Yiftach; Konen, Eli; Klang, Eyal			Large language models for oncological applications	JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY			English	Letter								Large language models such as ChatGPT have gained public and scientific attention. These models may support oncologists in their work. Oncologists should be familiar with large language models to harness their potential while being aware of potential dangers and limitations.	[Sorin, Vera; Barash, Yiftach; Konen, Eli; Klang, Eyal] Chaim Sheba Med Ctr, Dept Diagnost Imaging, Ramat Gan, Israel; [Sorin, Vera; Barash, Yiftach; Klang, Eyal] Chaim Sheba Med Ctr, DeepVis Lab, Ramat Gan, Israel; [Klang, Eyal] Chaim Sheba Med Ctr, Sami Sagol AI Hub, ARC, Ramat Gan, Israel; [Sorin, Vera; Barash, Yiftach; Konen, Eli; Klang, Eyal] Tel Aviv Univ, Sackler Sch Med, Tel Aviv, Israel	Chaim Sheba Medical Center; Chaim Sheba Medical Center; Chaim Sheba Medical Center; Tel Aviv University	Sorin, V (corresponding author), Chaim Sheba Med Ctr, Dept Diagnost Imaging, Ramat Gan, Israel.; Sorin, V (corresponding author), Chaim Sheba Med Ctr, DeepVis Lab, Ramat Gan, Israel.; Sorin, V (corresponding author), Tel Aviv Univ, Sackler Sch Med, Tel Aviv, Israel.	verasrn@gmail.com	Sorin, Vera/IAR-4247-2023	Sorin, Vera/0000-0003-0509-4686				Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 1996, Health Insurance Portability and Accountability Act; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Holmes J., 2023, ARXIV; Jeblick K., 2022, ARXIV; Kather JN, 2023, J CANCER RES CLIN, V149, P7995, DOI 10.1007/s00432-023-04666-6; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Ma C., 2021, ARXIV PREPRINT ARXIV, V2304, P08448; Rösler W, 2023, J CANCER RES CLIN, V149, P7997, DOI 10.1007/s00432-023-04667-5; Singhal K., 2022, PREPRINT; Sorin V, 2021, RADIOLOGY, V301, DOI 10.1148/radiol.2021210566; Sorin V, 2020, LANCET ONCOL, V21, P1553, DOI 10.1016/S1470-2045(20)30615-X; Sorin V, 2020, ACAD RADIOL, V27, P1175, DOI 10.1016/j.acra.2019.12.024; United National Educational Scientific and Cultural Organization (UNESCO), 2022, REC ETH ART INT; Vaswani A, 2017, ADV NEUR IN, V30; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	20	17	17	27	110	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0171-5216	1432-1335		J CANCER RES CLIN	J. Cancer Res. Clin. Oncol.	SEP	2023	149	11					9505	9508		10.1007/s00432-023-04824-w	http://dx.doi.org/10.1007/s00432-023-04824-w		MAY 2023	4	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	M9VT4	37160626				2024-07-03	WOS:000985443800004
C	Su, YM; Wan, CC; Sethi, U; Lu, S; Musuvathi, M; Nath, S			ACM	Su, Yiming; Wan, Chengcheng; Sethi, Utsav; Lu, Shan; Musuvathi, Madan; Nath, Suman			HotGPT: How to Make Software Documentation More Useful with a Large Language Model?	PROCEEDINGS OF THE 19TH WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS, HOTOS 2023			English	Proceedings Paper	19th ACM Workshop on Hot Topics in Operating Systems (HotOS)	JUN 22-24, 2023	Brown Univ, Providence, RI	Assoc Comp Machinery, ACM SIGOPS, Google, VMware	Brown Univ	Software documentation; large language model		It is well known that valuable information is contained in the natural language components of software systems, like comments and manual, and such information can be used to improve system performance and reliability. Past research has attempted to extract such information through task-specific machine learning models and tool chains. Here, we investigate a general, one-model-fit-all solution through a state-of-the-art large language model (e.g., the GPT series). Our investigation covers three representative tasks: extracting locking rules from comments, synthesizing exception predicates from comments, and identifying performance-related configurations; it reveals challenges and opportunities in applying large language models to system maintenance tasks.				yimingsu@uchicago.edu; cwan@uchicago.edu; usethi@uchicago.edu; shanlu@uchicago.edu; madanm@microsoft.com; Suman.Nath@microsoft.com		Su, Yiming/0009-0004-0128-8664; Wan, Chengcheng/0000-0001-9162-9688	NSF [CNS1764039, CNS1956180, CCF2119184]; CERES Center for Unstoppable Computing; Marian and Stuart Rice Research Award; Microsoft research dissertation grant; University of Chicago College Research Fellow Grant	NSF(National Science Foundation (NSF)); CERES Center for Unstoppable Computing; Marian and Stuart Rice Research Award; Microsoft research dissertation grant(Microsoft); University of Chicago College Research Fellow Grant	We thank the reviewers for their insightful feedback. The authors' research is supported by NSF (CNS1764039, CNS1956180, CCF2119184), the CERES Center for Unstoppable Computing, the Marian and Stuart Rice Research Award, Microsoft research dissertation grant, University of Chicago College Research Fellow Grant, and research gifts from Facebook.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, NLP tools.; Aviles Jean-Ralph, 2022, comment_parser: Parse comments from various source files; Blasi A, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P242, DOI 10.1145/3213846.3213872; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen M., 2021, arXiv; Dunn A., 2022, arXiv; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; GitHub, 2022, DDMC: a grocery ordering application; Github, 2023, Copilot: Your AI pair programmer; Hu YG, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P719; Phan H, 2017, 2017 IEEE/ACM 39TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING TECHNOLOGIES RESULTS TRACK (ICSE-NIER), P27, DOI 10.1109/ICSE-NIER.2017.9; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Khan Junaed Younus, 2023, Automatic Code Documentation Generation Using GPT-3, DOI [10.1145/3551349.3559548, DOI 10.1145/3551349.3559548]; Kremenek T, 2006, USENIX ASSOCIATION 7TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P161; Li C, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387520; Lin Tan, 2007, Operating Systems Review, V41, P145, DOI 10.1145/1323293.1294276; Oracle, 2023, HowtoWrite Doc Comments for the Javadoc Tool; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Tan Lin, 2007, HotOS, V7, P49; Trummer I, 2022, PROC VLDB ENDOW, V15, P2921, DOI 10.14778/3551793.3551841; Veizaga A, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-09956-6; Zhai J, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P25, DOI 10.1145/3368089.3409716	24	1	1	12	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0195-5				2023							87	93		10.1145/3593856.3595910	http://dx.doi.org/10.1145/3593856.3595910			7	Computer Science, Hardware & Architecture; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2NB					2024-07-03	WOS:001119203300011
J	Valueva, EA; Panfilova, AS; Rafikova, AS				Valueva, E. A.; Panfilova, A. S.; Rafikova, A. S.			Automatic Scoring of Verbal Divergent Thinking Tests: From Lexical Databases to Large Language Models	PSYCHOLOGY-JOURNAL OF THE HIGHER SCHOOL OF ECONOMICS			English	Article						divergent thinking tests; orig- inality; automatic processing; semantic distances; distributional semantics; la- tent semantic analysis; large language models	CREATIVITY; ORIGINALITY; DISTANCE; IDEAS	The article explores the evolution of methods for automatically assessing verbal divergent thinking tests. Resear chers have increasingly focused on the ability to evaluate the originality of respondents' answers by calculating their semantic distance from the stimulus task. From 2009 to 2019, latent semantic analysis became the primary method for assessing semantic distances. Overall, in terms of internal consistency and correlation with expert ratings, its application yielded satisfactory results, maintaining an acceptable balance of quality and effort expended. However, issues emerged (dependence on the corpus used, result instability, systematic distortions related to the length of analyzed responses), prompting researchers to transition to more advanced models of distributional semantics (GloVe, Word2Vec etc.), large language models, and supervised learning. Large language models, especially those fine-tuned on creativity test materials, demonstrated higher effectiveness compared to models assessing semantic distances and approached expert evaluations. In addition to evaluating originality, the article considers works proposing methods for automatic assessment of elaboration, flexibility, associative flow, and divergent semantic integration. References to online platforms that allow for automatic assessments of originality in responses to divergent tests are provided. The issue of interpreting results obtained through large language models is discussed. A drawback of using these models is the lack of understanding of the basis on which judgments of the originality of creative products are made. The perspectives of applying explainable artificial intelligence for evaluating results of verbal and non-verbal tests of creative thinking are being discussed.	[Valueva, E. A.; Panfilova, A. S.; Rafikova, A. S.] Russian Acad Sci, Inst Psychol, 13 build 1, Yaroslavskaya Str, Moscow 129366, Russia; [Valueva, E. A.] Moscow State Univ Psychol & Educ, 29 Sretenka Str, Moscow 127051, Russia; [Rafikova, A. S.] State Acad Univ Humanities, 26 Maronovskiy Pereulok, Moscow 119049, Russia	Institute of Psychology of Russian Academy of Sciences; Russian Academy of Sciences; Moscow State University of Psychology & Education	Valueva, EA (corresponding author), Russian Acad Sci, Inst Psychol, 13 build 1, Yaroslavskaya Str, Moscow 129366, Russia.	ekval@list.ru; panfilova87@gmail.com; antoninaraf@yandex.ru		Panfilova, Anastasia/0000-0003-1892-5901; Rafikova, Antonina/0000-0001-9831-6027				Acar S, 2021, GIFTED CHILD QUART, DOI 10.1177/00169862211061874; Acar S, 2014, CREATIVITY RES J, V26, P229, DOI 10.1080/10400419.2014.901095; Beaty RE, 2022, CREATIVITY RES J, V34, P245, DOI 10.1080/10400419.2022.2025720; Beaty RE, 2021, THINK SKILLS CREAT, V41, DOI 10.1016/j.tsc.2021.100859; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Beaty RE, 2014, MEM COGNITION, V42, P1186, DOI 10.3758/s13421-014-0428-8; Beketayev K, 2016, EUR J PSYCHOL, V12, P210, DOI 10.5964/ejop.v12i2.1127; Bossomaier T, 2009, CREATIVITY RES J, V21, P64, DOI 10.1080/10400410802633517; Buczak P, 2023, J CREATIVE BEHAV, V57, P17, DOI 10.1002/jocb.559; Cropley DH, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000510; Cseh GM, 2019, PSYCHOL AESTHET CREA, V13, P159, DOI 10.1037/aca0000220; Diedrich J, 2015, PSYCHOL AESTHET CREA, V9, P35, DOI 10.1037/a0038688; DiStefano P. V., 2023, PREPRINT, DOI DOI 10.31234/OSF.IO/6JTXB; Dumas D, 2021, J CREATIVE BEHAV, V55, P517, DOI 10.1002/jocb.471; Dumas D, 2021, PSYCHOL AESTHET CREA, V15, P645, DOI 10.1037/aca0000319; Dumas D, 2018, CREATIVITY RES J, V30, P466, DOI 10.1080/10400419.2018.1544601; Dumas D, 2018, CONTEMP EDUC PSYCHOL, V53, P1, DOI 10.1016/j.cedpsych.2018.01.003; Dumas D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0142567; Dumas D, 2014, THINK SKILLS CREAT, V14, P56, DOI 10.1016/j.tsc.2014.09.003; Dumas DG, 2018, CREATIVITY RES J, V30, P439, DOI 10.1080/10400419.2018.1535790; Forster E.A., 2009, Thirty-First Annual Conference of the Cognitive Science Society, P602; Forthmann B, 2023, EUR J PSYCHOL ASSESS, V39, P449, DOI 10.1027/1015-5759/a000723; Forthmann B, 2020, BRIT J EDUC PSYCHOL, V90, P683, DOI 10.1111/bjep.12325; Forthmann B, 2019, J CREATIVE BEHAV, V53, P559, DOI 10.1002/jocb.240; Forthmann B, 2017, CREATIVITY RES J, V29, P257, DOI 10.1080/10400419.2017.1360059; Goldstein T, 2023, PSYCHOL AESTHET CREA, V17, P495, DOI 10.1037/aca0000618; Grajzel K, 2023, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.1093343; Gray K, 2019, AM PSYCHOL, V74, P539, DOI 10.1037/amp0000391; Günther F, 2015, BEHAV RES METHODS, V47, P930, DOI 10.3758/s13428-014-0529-0; Hass RW, 2017, COGNITION, V166, P344, DOI 10.1016/j.cognition.2017.05.039; Hass RW, 2017, MEM COGNITION, V45, P233, DOI 10.3758/s13421-016-0659-y; Heinen DJP, 2018, PSYCHOL AESTHET CREA, V12, P144, DOI 10.1037/aca0000125; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; LaVoie N, 2020, EDUC PSYCHOL MEAS, V80, P399, DOI 10.1177/0013164419860575; Luchini S., 2023, Automatic scoring of creative problemsolving with large language models: A comparison of originality and quality ratings. PsyArXiv, DOI [10.31234/osf.io/g5qvf, DOI 10.31234/OSF.IO/G5QVF]; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Organisciak P., 2023, Open Creativity Scoring Computer software; Organisciak P, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101356; Panfilova A. S., 2023, The application of explainable artificial intelligence methods to models for automatic creativity assessment; Patterson JD, 2023, BEHAV RES METHODS, DOI 10.3758/s13428-023-02258-3; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Prabhakaran R, 2014, BEHAV RES METHODS, V46, P641, DOI 10.3758/s13428-013-0401-7; Reiter-Palmon R, 2019, PSYCHOL AESTHET CREA, V13, P144, DOI 10.1037/aca0000227; Runco MA, 2012, CREATIVITY RES J, V24, P92, DOI 10.1080/10400419.2012.650092; Silvia PJ, 2009, THINK SKILLS CREAT, V4, P79, DOI 10.1016/j.tsc.2009.06.005; Stevenson C., 2020, Automated AUT scoring using a big data variant of the Consensual Assessment Technique: Final technical report; Urban KK, 2005, INT EDUC J, V6, P272; Wang K, 2023, CREATIVITY RES J, DOI 10.1080/10400419.2023.2187544; WILSON RC, 1953, PSYCHOL BULL, V50, P362, DOI 10.1037/h0060857; Yu YH, 2023, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000573; Zedelius CM, 2019, BEHAV RES METHODS, V51, P879, DOI 10.3758/s13428-018-1137-1	51	0	0	2	2	NATL RES UNIV HIGHER EDUCATION	MOSCOW	NATL RES UNIV HIGHER EDUCATION, MOSCOW, 00000, RUSSIA	1813-8918			PSYCHOL-J HIGH SCH E	Psychol.-J. High. Sch. Econ.		2024	21	1					202	225		10.17323/1813-8918-2024-1-202-225	http://dx.doi.org/10.17323/1813-8918-2024-1-202-225			24	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	SU8A4		gold			2024-07-03	WOS:001237039900012
J	Dengel, A; Gehrlein, R; Fernes, D; Görlich, S; Maurer, J; Pham, HH; Grossmann, G; Eisermann, NDG				Dengel, Andreas; Gehrlein, Rupert; Fernes, David; Goerlich, Sebastian; Maurer, Jonas; Pham, Hai Hoang; Grossmann, Gabriel; Eisermann, Niklas Dietrich genannt			Qualitative Research Methods for Large Language Models: Conducting Semi-Structured Interviews with ChatGPT and BARD on Computer Science Education	INFORMATICS-BASEL			English	Article						large language models; qualitative research; interviews; computer science education; artificial intelligence; machine learning	INTELLIGENCE	In the current era of artificial intelligence, large language models such as ChatGPT and BARD are being increasingly used for various applications, such as language translation, text generation, and human-like conversation. The fact that these models consist of large amounts of data, including many different opinions and perspectives, could introduce the possibility of a new qualitative research approach: Due to the probabilistic character of their answers, "interviewing" these large language models could give insights into public opinions in a way that otherwise only interviews with large groups of subjects could deliver. However, it is not yet clear if qualitative content analysis research methods can be applied to interviews with these models. Evaluating the applicability of qualitative research methods to interviews with large language models could foster our understanding of their abilities and limitations. In this paper, we examine the applicability of qualitative content analysis research methods to interviews with ChatGPT in English, ChatGPT in German, and BARD in English on the relevance of computer science in K-12 education, which was used as an exemplary topic. We found that the answers produced by these models strongly depended on the provided context, and the same model could produce heavily differing results for the same questions. From these results and the insights throughout the process, we formulated guidelines for conducting and analyzing interviews with large language models. Our findings suggest that qualitative content analysis research methods can indeed be applied to interviews with large language models, but with careful consideration of contextual factors that may affect the responses produced by these models. The guidelines we provide can aid researchers and practitioners in conducting more nuanced and insightful interviews with large language models. From an overall view of our results, we generally do not recommend using interviews with large language models for research purposes, due to their highly unpredictable results. However, we suggest using these models as exploration tools for gaining different perspectives on research topics and for testing interview guidelines before conducting real-world interviews.	[Dengel, Andreas; Gehrlein, Rupert; Fernes, David; Goerlich, Sebastian; Maurer, Jonas; Pham, Hai Hoang; Grossmann, Gabriel; Eisermann, Niklas Dietrich genannt] Goethe Univ Frankfurt, Inst Didact Math & Comp Sci, D-63025 Frankfurt, Germany	Goethe University Frankfurt	Dengel, A; Gehrlein, R (corresponding author), Goethe Univ Frankfurt, Inst Didact Math & Comp Sci, D-63025 Frankfurt, Germany.	dengel@math.uni-frankfurt.de; r.gehrlein@em.uni-frankfurt.de; fernes@em.uni-frankfurt.de; goerlich@mathematik.uni-frankfurt.de; maurerjonas1@stud.uni-frankfurt.de; hoangphamhai@stud.uni-frankfurt.de; s1188977@stud.uni-frankfurt.de; s5110057@stud.uni-frankfurt.de		Fernes, David/0000-0001-7063-6221				australiancurriculum, General Capabilities-australiancurriculum.edu.au; Berry M., 2013, Computing in the national curriculum: A guide for primary teachers; Best A., 2019, Kompetenzen fur informatische Bildung im Primarbereich; Brinda T., 2008, Beilage zu LOG IN, V150, P28; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chenail RJ, 2011, QUAL REP, V16, P255; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christou P.A., 2023, Journal of Qualitative Research in Tourism, V1, P79, DOI [10.4337/jqrt.2023.0006, DOI 10.4337/JQRT.2023.0006]; Christou PA, 2023, QUAL REP, V28, P1968, DOI 10.46743/2160-3715/2023.6406; Code.org CSTA and ECEP Alliance, 2022, 2022 State of Computer Science Education: Understanding Our National Imperative; CSTA, 2017, CSTA K 12 COMPUTER S; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Digital Technologies-australiancurriculum.edu.au, about us; education, Technologies: Experiences and Outcomes-Education Scotland; fur Volksschulen A., 2016, Konzept zur Einfuhrung des Modullehrplans Medien und Informatik des Lehrplans 21 in der Volksschule; Gal-Ezer J, 2014, ACM T COMPUT EDUC, V14, DOI 10.1145/2602483; Google, 2023, Bard Experiment, 13 August; gov.uk, National Curriculum in England: Computing Programmes of Study-gov.uk; Guest G., 2012, Applied Thematic Analysis, V12; Haan M, 2019, J AM COLL RADIOL, V16, P1416, DOI 10.1016/j.jacr.2018.12.043; Higginbottom Gina Marie Awoko, 2004, Nurse Res, V12, P7; Hub D.T., State and Territory Curriculum; Information and Communication Technology (ICT) Capability-australiancurriculum.edu.au, about us; Kemp P., 2017, After the Reboot: Computing Education in UK Schools; Laï MC, 2020, J TRANSL MED, V18, DOI 10.1186/s12967-019-02204-y; Lehrplan 21, ABOUT US; Longo L, 2020, ADV INTELL SYST COMP, V1068, P1, DOI 10.1007/978-3-030-31787-4_1; Martin John Levi, 2023, Journal of Social Computing, P1, DOI 10.23919/JSC.2023.0003; Mayring P, 2014, QUALITATIVE CONTENT, DOI [10.17169/fqs-1.2.1089, DOI 10.17169/FQS-1.2.1089]; Ministerium fur Bildung W.u.K, Rahmenplan fur die Sekundarstufe I Regionale Schule, Gesamtschule; Mruck K., 2003, Historical Social Research / Historische Sozialforschung, V28, P189, DOI DOI 10.12759/HSR.28.2003.3.189-212; Nager A., 2016, The case for improving US computer science education; Olasik M., 2023, Eur. Res. Stud. J., V26, P269; OpenAI, 2023, GPT-4 Technical Report; Oppong S.H., 2013, Asian Journal of Management Sciences and Education, V2, P202, DOI DOI 10.7748/NR2004.07.12.1.7.C5927; Pasternak A, 2018, LECT NOTES COMPUT SC, V11169, P117, DOI 10.1007/978-3-030-02750-6_9; Radford A., 2018, IMPROVING LANGUAGE U; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Rohner G., 2016, Beilage zu LOG IN, V183, P88; Schwarz R., 2021, Informatik Spektrum, V44, P95, DOI [https://doi.org/10.1007/s00287-021-01349-9, DOI 10.1007/S00287-021-01349-9]; Scottish G, 2016, Curriculum for Excellence; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Surmiak A., 2018, CONFIDENTIALITY QUAL; The Northern Ireland Assembly, about us; Thomson S.B., 2011, JOAAG, V6, P77; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tshukudu E, 2023, ACM T COMPUT EDUC, V23, DOI 10.1145/3554924; Vaswani A, 2017, ADV NEUR IN, V30; Whittemore R, 2001, QUAL HEALTH RES, V11, P522, DOI 10.1177/104973201129119299; Yang Y., A Qualitative Research on Marketing and Sales in the Artificial Intelligence Age; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	53	3	3	24	24	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9709		INFORMATICS-BASEL	Informatics-Basel	DEC	2023	10	4							78	10.3390/informatics10040078	http://dx.doi.org/10.3390/informatics10040078			16	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	DI6C7		gold			2024-07-03	WOS:001131431300001
J	Cao, XG; Xu, WT; Zhao, JB; Duan, Y; Yang, X				Cao, Xiangang; Xu, Wangtao; Zhao, Jiangbin; Duan, Yong; Yang, Xin			Research on Large Language Model for Coal Mine Equipment Maintenance Based on Multi-Source Text	APPLIED SCIENCES-BASEL			English	Article						coal mine intelligence; equipment maintenance; knowledge management; large language model; knowledge graph		The efficient management and utilization of coal mine equipment maintenance knowledge is an indispensable foundation for advancing the establishment of intelligent mines. This knowledge has problems such as scattered, low sharing, and insufficient management, which restricts the development of coal mine intelligence. For the above-mentioned problems, a large language model for the maintenance of coal mine equipment based on multi-source text (XCoalChat) was proposed to better manage and utilize the existing massive knowledge of coal mine equipment maintenance. The dataset of coal mine equipment maintenance based on ReliableCEMK-Self-Instruction was constructed to obtain a wide and diverse amount of knowledge through sample generation. Aiming at the illusory problem of the large language model, a knowledge graph enhancement method based on the "Coal Mine Equipment Maintenance System-Full Life Cycle-Specification" was proposed to improve the knowledge density. A triple-LoRA fine-tuning mechanism and DPO direct preference optimization method were introduced into the top of the baseline model, which guarantees that XCoalChat can handle multiple Q&A and maintenance decision analysis tasks with limited computing power. Compared with ChatGLM, Bloom, and LLama, the comprehensive assessment of XCoalChat was performed by experiments including coal mine dialog consulting, coal mine professional consulting, and maintenance decision analysis. The results showed that XCoalChat achieved the best response accuracy in professional consulting and maintenance decision analysis; XCoalChat also took the least reasoning time on average. XCoalChat outperformed other mainstream large language models, which verify that XCoalChat is an effective large language model in the field of coal mine equipment maintenance.	[Cao, Xiangang; Xu, Wangtao; Zhao, Jiangbin; Duan, Yong; Yang, Xin] Xian Univ Sci & Technol, Sch Mech Engn, Xian 710054, Peoples R China; [Cao, Xiangang; Xu, Wangtao; Zhao, Jiangbin; Duan, Yong; Yang, Xin] Shaanxi Key Lab Intelligent Detect & Control Mech, Xian 710054, Peoples R China	Xi'an University of Science & Technology	Cao, XG (corresponding author), Xian Univ Sci & Technol, Sch Mech Engn, Xian 710054, Peoples R China.; Cao, XG (corresponding author), Shaanxi Key Lab Intelligent Detect & Control Mech, Xian 710054, Peoples R China.	cao_xust@sina.com; 21205016033@stu.xust.edu.cn; zhaojiangbin@xust.edu.cn; duanyong@stu.xust.edu.cn; 21105016014@stu.xust.edu.cn			Natural Science Foundation of National Natural Science Foundation of China	Natural Science Foundation of National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Cao X., 2021, J. Mine Autom, V47, P41; Chowdhery A, 2023, J MACH LEARN RES, V24; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Duan Y., 2023, P 5 INT C SYSTEM REL; [高扬 Gao Yang], 2020, [机械工程学报, Journal of Mechanical Engineering], V56, P41; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang QZ, 2023, Arxiv, DOI arXiv:2305.15062; Li X., 2022, J. Mine Autom, V49, P96; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Li Z., 2022, J. Mine Autom, V48, P107; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; [刘鹏 Liu Peng], 2020, [中文信息学报, Journal of Chinese Information Processing], V34, P49; Liu XY, 2023, Arxiv, DOI [arXiv:2307.10485, 10.48550/arXiv.2307.10485, DOI 10.48550/ARXIV.2307.10485]; Lowin M, 2024, MACH LEARN KNOW EXTR, V6, P233, DOI 10.3390/make6010013; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pan L., 2019, Comput. Appl. Softw, V36, P47; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Patil R, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14052074; Rafailov R, 2023, Arxiv, DOI arXiv:2305.18290; Si L, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060171; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trad F, 2024, MACH LEARN KNOW EXTR, V6, P367, DOI 10.3390/make6010018; [王国法 Wang Guofa], 2022, [煤炭科学技术, Coal Science and Technology], V50, P1; Wang HC, 2023, Arxiv, DOI [arXiv:2304.06975, DOI 10.48550/ARXIV.2304.06975]; Wang Y., 2023, P 61 ANN M ASS COMPU; Wang YY, 2012, PROCEDIA ENGINEER, V31, P1206, DOI 10.1016/j.proeng.2012.01.1164; Wang ZB, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/9674942; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xiong HL, 2023, Arxiv, DOI arXiv:2304.01097; Ye S., 2019, Master's Thesis; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang D., 2021, Journal of Mechanical Engineering, V57, P24, DOI [10.3901/JME.2021.05.090], DOI 10.3901/JME.2021.05.090]; Zhang W., 2023, J. Coal Sci. Technol, V51, P383; Zhang X., 2023, P 32 ACM INT C INFOR; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng O, 2023, Arxiv, DOI arXiv:2307.15311	37	0	0	24	24	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	7							2946	10.3390/app14072946	http://dx.doi.org/10.3390/app14072946			16	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	NM5L5		gold			2024-07-03	WOS:001200882000001
J	Gamallo, P; Garcia, M; De-Dios-Flores, I				Gamallo, Pablo; Garcia, Marcos; De-Dios-Flores, Iria			Evaluating Contextualized Vectors from both Large Language Models and Compositional Strategies	PROCESAMIENTO DEL LENGUAJE NATURAL			English	Article						Large Language Models; Contextualized Vectors; Comositionality; Semantic Similarity; Selection Preferences; Syntactic Dependencies		In this article, we compare contextualized vectors derived from large language models with those generated by means of dependency-based compositional techniques. For this purpose, we make use of a word-in-context similarity task. As all experiments are conducted for the Galician language, we created a new Galician evaluation dataset for this specific semantic task. The results show that compositional vectors derived from syntactic approaches based on selectional preferences are competitive with the contextual embeddings derived from neural-based large language models.	[Gamallo, Pablo; Garcia, Marcos; De-Dios-Flores, Iria] Univ Santiago de Compostela, Ctr Invest Tecnol Intelixentes CITIUS, Galiza, Spain	Universidade de Santiago de Compostela	Gamallo, P (corresponding author), Univ Santiago de Compostela, Ctr Invest Tecnol Intelixentes CITIUS, Galiza, Spain.	pablo.gamallo@usc.gal; marcos.garcia.gonzalez@usc.gal; iria.dedios@usc.gal	Garcia, Marcos/GSD-3352-2022; gamallo, pablo/A-6985-2009	gamallo, pablo/0000-0002-5819-2469; de-Dios-Flores, Iria/0000-0002-5941-1707	Xunta de Galicia; University of Santiago de Compostela; Galician Ministry of Education, University and Professional Training [ED431G2019/04]; European Regional Development Fund (ERDF/FEDER program) [ED431C 2020/21]; Ramon y Cajal grant [RYC2019-028473-I]; Galician Government [ED431F 2021/01]	Xunta de Galicia(Xunta de Galicia); University of Santiago de Compostela; Galician Ministry of Education, University and Professional Training; European Regional Development Fund (ERDF/FEDER program)(European Union (EU)); Ramon y Cajal grant(Spanish Government); Galician Government	This research was funded by the project "N ' os: Galician in the society and economy of artificial intelligence", agreement between Xunta de Galicia and University of Santiago de Compostela, and grant ED431G2019/04 by the Galician Ministry of Education, University and Professional Training, and the European Regional Development Fund (ERDF/FEDER program), and Groups of Reference: ED431C 2020/21. In addition: Ramon y Cajal grant (RYC2019-028473-I) and Grant ED431F 2021/01 (Galician Government).	[Anonymous], 2014, P 2014 C EMPIRICAL M; [Anonymous], 2008, P ACL 08 HLT; [Anonymous], 2008, EMNLP; Armendariz C. S., 2020, P 14 INT WORKSHOP SE; Bai JG, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3011; Baroni M., 2014, LiLT (Linguistic Issues in Language Technology), V9, P241, DOI DOI 10.33011/LILT.V9I.1321; Baroni M, 2013, LANG LINGUIST COMPAS, V7, P511, DOI 10.1111/lnc3.12050; Biemann C., 2013, J LANG MODEL, V1, P55, DOI DOI 10.15398/JLM.V1I1.60; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Devlin J., 2018, BERT PRE TRAINING DE; Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55; Gamallo P., 2021, 13 INT C AGENTS ARTI; Gamallo P, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11125743; Gamallo P, 2019, COMPUT LINGUIST, V45, P395, DOI [10.1162/coli_a_00353, 10.1162/COLI_a_00353]; Gamallo P, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P239, DOI 10.1109/SNAMS.2018.8554689; Gamallo P, 2017, LANG RESOUR EVAL, V51, P727, DOI 10.1007/s10579-016-9357-4; Gamallo Pablo, 2019, LANGUAGE MODELLING, V7, P53, DOI DOI 10.15398/JLM.V7I1.201; Gamer Matthias, 2019, CRAN; Garcia M, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3625; Grefenstette E., 2011, WORKSHOP GEOMETRICAL; Grefenstette E., 2011, P C EMPIRICAL METHOD, P1394; Kartsaklis D., 2013, P 2013 C EMP METH NA, P1590; Lin Bill Yuchen, 2021, Common Sense Beyond English: Evaluating and Improving Multilingual Language Models for Commonsense Reasoning; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Mitchell J, 2010, COGNITIVE SCI, V34, P1388, DOI 10.1111/j.1551-6709.2010.01106.x; Nguyen Xuan-Phi, 2020, TREE STRUCTURED ATTE; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Salazar J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2699; Shibayama N., 2020, P 34 PACIFIC ASIA C, P279; Vilares D, 2021, PROCES LENG NAT, P13, DOI 10.26342/2021-66-1; Vulie I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7222; Wang Alex, 2019, ICLR 2019; Weir D, 2016, COMPUT LINGUIST, V42, P727, DOI 10.1162/COLI_a_00265; Wiegand M., 2019, P 2019 C N AM CHAPT, V1, P602; Williams Adina, 2018, P 2018 C N AM CHAPTE, P1112; WUnholds GUs, 2020, P 24 C COMPUTATIONAL, P313, DOI DOI 10.18653/V1/2020.CONLL-1.24; Yu L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4896	37	2	2	3	17	SOC ESPANOLA PROCESAMIENTO LENGUAJE NATURAL-SEPLN	ALICANTE	DEPT LENGUAJES & SISTEMAS INFORMATICOS, UNIV ALICANTE, APDO 99, ALICANTE, 03080, SPAIN	1135-5948	1989-7553		PROCES LENG NAT	Proces. Leng. Nat.	SEP	2022		69					153	164		10.26342/2022-69-13	http://dx.doi.org/10.26342/2022-69-13			12	Computer Science, Artificial Intelligence; Linguistics	Emerging Sources Citation Index (ESCI)	Computer Science; Linguistics	7A7BN					2024-07-03	WOS:000898606900014
C	Lewis, A			ASSOC COMPUTAT LINGUIST	Lewis, Armanda			Multimodal large language models for inclusive collaboration learning tasks	NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP			English	Proceedings Paper	Conference of the North-American-Chapter-of-the-Association-for-Computational-Linguistics (NAAACL) - Human Language Technologies	JUL 10-15, 2022	Seattle, WA	Assoc Computat Linguist, N Amer Chapter, Amazon Sci, Bloomberg Engn, Google Res, LivepersoMetan, ByteDance, KENSH, Grammarly, Megagon Labs, Microsoft, Reveal Brainspace, Cohere, GResearch, Relativity, Servicenow, ASAPP, Duolingo, Adobe, Linkedin, Babelscape, Rakuten Inst Technol, UC Santa Cruz, Baskin Engn, Nat Language Proc, NSF, ETS, OpenAI, TIAA, Two Sigma, Mag Data			CORPUS	This PhD project leverages advancements in multimodal large language models to build an inclusive collaboration feedback loop, in order to facilitate the automated detection, modeling, and feedback for participants developing general collaboration skills. This topic is important given the role of collaboration as an essential 21st century skill, the potential to ground large language models within learning theory and real-world practice, and the expressive potential of transformer models to support equity and inclusion. We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop.	[Lewis, Armanda] New York Univ, 726 Broadway, New York, NY 10003 USA	New York University	Lewis, A (corresponding author), New York Univ, 726 Broadway, New York, NY 10003 USA.	a1861@nyu.edu						[Anonymous], 2015, PISA 2015 ASS AN FRA; [Anonymous], 2011, Assessing 21st Century Skills: Summary of a Workshop; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bernstein RS, 2020, J BUS ETHICS, V167, P395, DOI 10.1007/s10551-019-04180-1; Bisk Y., 2020, ARXIV; Blodgett SL, 2020, Arxiv, DOI arXiv:2005.14050; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Boothe M, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P507, DOI 10.1145/3506860.3506898; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Carletta J, 2005, LECT NOTES COMPUT SC, V3869, P28; Clavi‚ B, 2019, Arxiv, DOI arXiv:1912.00690; Cukurova M, 2018, COMPUT EDUC, V116, P93, DOI 10.1016/j.compedu.2017.08.007; Denton, 2020, ARXIV; Dinan Emily, 2020, MULTIDIMENSIONAL GEN, P314; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Dowell N, 2019, LECT NOTES ARTIF INT, V11625, P207, DOI 10.1007/978-3-030-23204-7_18; Dwork C., 2012, P 3 INN THEOR COMP S, P214, DOI 10.1145/2090236.2090255; Ekstedt Erik, 2020, FINDINGS ASS COMPUTA, P2981, DOI DOI 10.18653/V1/2020.FINDINGS-EMNLP.268; Goldstone RL, 2009, TOP COGN SCI, V1, P412, DOI 10.1111/j.1756-8765.2009.01038.x; Guo MY, 2020, Arxiv, DOI arXiv:2005.02507; He H., 2017, ARXIV; Holstein K., 2021, arXiv; Huang WL, 2022, Arxiv, DOI arXiv:2201.07207; Islam MM, 2021, IEEE ROBOT AUTOM LET, V6, P1729, DOI 10.1109/LRA.2021.3059624; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Lai E., 2017, Skills for today: What we know about teaching and assessing collaboration; Lee M.-C., 2022, ARXIV; MarceloWorsley Xavier, 2020, COMPANION P 10 INT C, V2610, P53; Minaee S, 2021, Arxiv, DOI arXiv:2004.03705; Mor-Barak ME, 1998, ADMIN SOC WORK, V22, P47, DOI 10.1300/J147v22n01_04; Nangia N, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1221; Ochoa X, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P583, DOI 10.1145/2522848.2533789; Oertel C, 2013, J MULTIMODAL USER IN, V7, P19, DOI 10.1007/s12193-012-0108-6; Peyton Young H., 1995, EQUITY THEORY PRACTI, V1; Praharaj S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093156; Praharaj Sambit, 2018, P 13 EC TEL DOCTORAL; Pugh SL, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P208, DOI 10.1145/3506860.3506894; Bowman SR, 2015, Arxiv, DOI arXiv:1508.05326; Radford A., 2018, IMPROVING LANGUAGE U; Rahman W, 2020, Arxiv, DOI arXiv:1908.05787; Rios JA, 2020, EDUC RESEARCHER, V49, P80, DOI 10.3102/0013189X19890600; Sanabria R, 2018, Arxiv, DOI arXiv:1811.00347; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sap M., 2020, SOCIAL BIAS FRAMES R, P5477; Shen JT, 2021, Arxiv, DOI [arXiv:2106.07340, DOI 10.48550/ARXIV.2106.07340]; Singh A., 2022, ARXIV; Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693; Suresh A, 2021, Arxiv, DOI arXiv:2105.07949; Tay Y, 2022, Arxiv, DOI arXiv:2109.10686; Tsvetkov Yulia, 2018, P 2018 C N AM CHAPTE, P24; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Whiting Mark., 2019, P AAAI C HUM COMP CR, Vvol. 7, P197; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Worsley M., 2015, P 5 INT C LEARNING A; Wray RE, 2021, Arxiv, DOI arXiv:2109.08270; Yousfi-Monod M, 2007, INT J INTELL INF TEC, V3, P60, DOI 10.4018/jiit.2007010104	57	4	4	0	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-73-5				2022							202	210						9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9HI					2024-07-03	WOS:000860760300026
J	Wang, C; Liu, YY; Guo, TZ; Li, DP; He, T; Li, Z; Yang, QW; Wang, HH; Wen, YY				Wang, Chen; Liu, Yan-yi; Guo, Tie-zheng; Li, Da-peng; He, Tao; Li, Zhi; Yang, Qing-wen; Wang, Hui-han; Wen, Ying-you			Systems engineering issues for industry applications of large language model	APPLIED SOFT COMPUTING			English	Article						LLM; AIGC; Systems engineering; CDSS; Industry application		Large language model (LLM) is an important direction in the development of AGI, but its technology is still in rapid change, and its capabilities still have obvious deficiencies and imbalances, with persistent problems such as hallucination, value non-alignment, weak specialization, and black-box effect. In this case, how to apply LLM to different professional fields and develop high-quality AIGC industry applications has become a great challenge for ISVs. Building AIGC industry applications based on LLM is not simply a matter of functional realization. Although researchers and open-source communities have proposed numerous application development frameworks or tool components, there is a lack of overall architecture design for systems engineering and a lack of discussion on theories and methods of LLM application development in large-scale industry domains, such as healthcare, government affairs, finance, and media. This paper analyzes the basic ideas of LLM industry applications development, defines the functional requirements and feature requirements of LLM industry applications, puts forward the concept of Large Language Model Systems Engineering (LLM-SE), and develops an AI assisted clinical risk prediction system for amyloidosis disease based on the architecture of LLM-SE, which adopt knowledge engineering, quality engineering, etc., and verifies the LLM-SE development architecture and methodology.	[Wang, Chen; Liu, Yan-yi; Guo, Tie-zheng; Yang, Qing-wen; Wen, Ying-you] Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Peoples R China; [Wang, Chen; Guo, Tie-zheng; Li, Da-peng; Li, Zhi; Yang, Qing-wen; Wen, Ying-you] Neusoft AI Mag Technol Res, Shenyang, Peoples R China; [He, Tao; Li, Zhi; Wen, Ying-you] Neusoft Inst Intelligent Med Res, Shenyang, Peoples R China; [Wang, Hui-han] China Med Univ, Shengjing Hosp, Dept Hematol, Shenyang, Peoples R China	Northeastern University - China; China Medical University	Wen, YY (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Peoples R China.	wenyingyou@mail.neu.edu.cn	Liu, Junjie/KHV-6949-2024; w, hh/GQR-2749-2022		Shenyang Science and Technology Plan Project [RC210469]; Liaoning Provincial Science and Technology Innovation Project in the Field of Artificial Intelligence	Shenyang Science and Technology Plan Project; Liaoning Provincial Science and Technology Innovation Project in the Field of Artificial Intelligence	This study was supported by Shenyang Science and Technology Plan Project (Grant No. RC210469) and in part by Grants from Liaoning Provincial Science and Technology Innovation Project in the Field of Artificial Intelligence (Project name:Research on key technologies for systems engineering of large language model) .	Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bonifacio Luiz, 2022, arXiv; Cao Yong, 2023, arXiv, V2303, P17466; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Danilevsky M, 2020, Arxiv, DOI [arXiv:2010.00711, DOI 10.48550/ARXIV.2010.00711]; Dong Hanze, 2023, arXiv, V2304; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Enguehard J, 2023, Arxiv, DOI arXiv:2305.15853; Fang T, 2023, Arxiv, DOI arXiv:2304.01746; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jin Q, 2023, Arxiv, DOI [arXiv:2304.09667, DOI 10.48550/ARXIV.2304.09667]; Kalla D, 2023, INT J INNOV SCI RES, V8; Li J., 2021, P 30 INT JOINT C ART, P4492, DOI DOI 10.24963/IJCAI.2021/612SURVEYTRACK; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu XY, 2023, Arxiv, DOI [arXiv:2307.10485, 10.48550/arXiv.2307.10485, DOI 10.48550/ARXIV.2307.10485]; Liu Y, 2023, Arxiv, DOI arXiv:2308.05374; Loh HW, 2022, COMPUT METH PROG BIO, V226, DOI 10.1016/j.cmpb.2022.107161; Madsen A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3546577; McGee Robert W., 2023, Empir. Study, V2023; Nazar M, 2021, IEEE ACCESS, V9, P153316, DOI 10.1109/ACCESS.2021.3127881; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Petch J, 2022, CAN J CARDIOL, V38, P204, DOI 10.1016/j.cjca.2021.09.004; Qin YJ, 2023, Arxiv, DOI arXiv:2304.08354; Rasheed K, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.106043; Rozado D, 2023, SOC SCI-BASEL, V12, DOI 10.3390/socsci12030148; Rutinowski J, 2023, Arxiv, DOI arXiv:2304.07333; Sarti G, 2023, Arxiv, DOI arXiv:2302.13942; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wei Jason, 2022, arXiv, V2201, P11903; Wu JY, 2023, Arxiv, DOI arXiv:2304.06632; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Xi ZH, 2023, Arxiv, DOI arXiv:2309.07864; Yin KY, 2022, Arxiv, DOI arXiv:2202.10419; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang C, 2023, Arxiv, DOI [arXiv:2304.06488, DOI 10.13140/RG.2.2.24789.70883]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou XH, 2022, IEEE T KNOWL DATA EN, V34, P1096, DOI 10.1109/TKDE.2020.2994641	42	0	0	107	107	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1568-4946	1872-9681		APPL SOFT COMPUT	Appl. Soft. Comput.	JAN	2024	151								111165	10.1016/j.asoc.2023.111165	http://dx.doi.org/10.1016/j.asoc.2023.111165		DEC 2023	11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FB9V9					2024-07-03	WOS:001143416400001
J	Wang, XC; Reynolds, BL				Wang, Xiaochen; Reynolds, Barry Lee			Beyond the Books: Exploring Factors Shaping Chinese English Learners' Engagement with Large Language Models for Vocabulary Learning	EDUCATION SCIENCES			English	Article						SDT; UTAUT; vocabulary learning; large language models; Chinese context	BURNOUT	Informal English learning plays a crucial role in vocabulary learning, yet few scholars have explored the use of large language models for this purpose. In light of this, our study, integrating Self-Determination Theory (SDT) and the Unified Theory of Acceptance and Use of Technology (UTAUT), employed Structural Equation Modeling (SEM) to investigate factors influencing 568 Chinese English learners' use of large language models for vocabulary learning. Our findings identified six significant factors from those models-perceived autonomy, perceived competence, perceived relatedness, performance expectancy, effort expectancy, and social influence-that significantly shape learners' intentions and behaviors towards utilizing large language models for vocabulary learning. Notably, effort expectancy emerged as the most influential factor, while facilitating conditions did not significantly impact usage intentions. This research offers insights for future curriculum design and policy formulation, highlighting the importance of understanding learners' perspectives on technology use in education.	[Wang, Xiaochen] Xi An Jiao Tong Univ, Sch Foreign Studies, Xian 710049, Peoples R China; [Reynolds, Barry Lee] Univ Macau, Fac Educ, Room 1014,E33 Ave da Univ, Taipa, Macao, Peoples R China; [Reynolds, Barry Lee] Univ Macau, Ctr Cognit & Brain Sci, Taipa, Macao, Peoples R China	Xi'an Jiaotong University; University of Macau; University of Macau	Reynolds, BL (corresponding author), Univ Macau, Fac Educ, Room 1014,E33 Ave da Univ, Taipa, Macao, Peoples R China.; Reynolds, BL (corresponding author), Univ Macau, Ctr Cognit & Brain Sci, Taipa, Macao, Peoples R China.	wangxiaochen666666@outlook.com; barryreynolds@um.edu.mo	Reynolds, Barry Lee/I-5685-2019	Reynolds, Barry Lee/0000-0002-3984-2059; Wang, Xiaochen/0000-0002-4786-8777				Abd Rahman SF, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13158571; Chen Y, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su141811288; Collier J. E., 2020, Applied Structural Equation Modeling Using AMOS: Basic to Advanced Techniques; Deci E.L., 2013, Intrinsic motivation and selfdetermination in human behavior, DOI DOI 10.1007/978-1-4899-2271-7; Deci EL, 2016, BUILDING AUTONOMOUS LEARNERS: PERSPECTIVES FROM RESEARCH AND PRACTICE USING SELF-DETERMINATION THEORY, P9, DOI 10.1007/978-981-287-630-0_2; Fathali S, 2018, AUSTRALAS J EDUC TEC, V34, P138, DOI 10.14742/ajet.3629; Gao Y, 2024, ASIA PAC J EDUC, V44, P29, DOI 10.1080/02188791.2024.2305173; Gao Y, 2024, CURR PSYCHOL, V43, P9089, DOI 10.1007/s12144-023-05062-6; Gao Y, 2022, J LANG EDUC, V8, P58, DOI 10.17323/jle.2022.15962; He LM, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1185851; Hsu LW, 2023, COMPUT ASSIST LANG L, V36, P1177, DOI 10.1080/09588221.2021.1976210; Jeon J, 2022, EDUC INF TECHNOL, V27, P5767, DOI 10.1007/s10639-021-10839-y; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kline RB., 2023, Principles and Practice of Structural EquationModeling; Lee JS, 2021, BRIT J EDUC TECHNOL, V52, P1279, DOI 10.1111/bjet.13082; Lee JS, 2020, AUSTRALAS J EDUC TEC, V36, P155, DOI 10.14742/ajet.5319; Lee JS, 2019, LANG LEARN TECHNOL, V23, P114, DOI 10.10125/44675; Liu GX, 2024, INNOV LANG LEARN TEA, V18, P125, DOI 10.1080/17501229.2023.2240316; Liu GL, 2024, SYSTEM, V120, DOI 10.1016/j.system.2023.103193; Pan ZW, 2023, J PSYCHOLINGUIST RES, V52, P1799, DOI 10.1007/s10936-023-09974-z; Reynolds B. L, 2023, Vocabulary learning in the wild; Ryan RM, 2006, MOTIV EMOTION, V30, P347, DOI 10.1007/s11031-006-9051-8; Ryan RM, 2017, SELF-DETERMINATION THEORY: BASIC PSYCHOLOGICAL NEEDS IN MOTIVATION, DEVELOPMENT, AND WELLNESS, P1, DOI 10.1521/978.14625/28806; Soyoof A, 2023, COMPUT ASSIST LANG L, V36, P608, DOI 10.1080/09588221.2021.1936562; Tabachnick B.G., 2013, Using multivariate statistics, V6th ed.; Tan PJB, 2013, SAGE OPEN, V3, DOI 10.1177/2158244013503837; Teng F, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0215902; Venkatesh V, 2003, MIS QUART, V27, P425, DOI 10.2307/30036540; Hoi VN, 2020, COMPUT EDUC, V146, DOI 10.1016/j.compedu.2019.103761; Wang QK, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su151310184; Wang XC, 2024, CURR PSYCHOL, V43, P15659, DOI 10.1007/s12144-023-05546-5; Wang XC, 2022, FRONT EDUC, V7, DOI 10.3389/feduc.2022.1010889; Wang YL, 2024, STUD SECOND LANG LE, V14, P235, DOI 10.14746/ssllt.38418; Wang YL, 2023, ASIA-PAC EDUC RES, DOI 10.1007/s40299-023-00750-0; Wang YL, 2023, PORTA LINGUARUM, P165, DOI 10.30827/portalin.vi39.23625; Wheaton B., 1977, SOCIOL METHODOL, V8, P84, DOI [https://doi.org/10.2307/270754, DOI 10.2307/270754, 10.2307/270754]; Wu HW, 2024, PORTA LINGUARUM, P193, DOI 10.30827/portalin.viIX.29878; Wu HW, 2024, ACTA PSYCHOL, V243, DOI 10.1016/j.actpsy.2024.104153; Zhang KX, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14106259; Zhang Y, 2022, COMPUT ASSIST LANG L, DOI 10.1080/09588221.2022.2134424	40	2	2	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7102		EDUC SCI	Educ. Sci.	MAY	2024	14	5							496	10.3390/educsci14050496	http://dx.doi.org/10.3390/educsci14050496			13	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	SJ6Y5		gold			2024-07-03	WOS:001234137800001
C	Xiao, ZM; Mai, ZL; Xu, ZR; Cui, YC; Li, JC			IEEE	Xiao, Zhaomin; Mai, Zhelu; Xu, Zhuoer; Cui, Yachen; Li, Jiancheng			Corporate Event Predictions Using Large Language Models	2023 10TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING & MACHINE INTELLIGENCE, ISCMI	International Conference on Soft Computing & Machine Intelligence ISCMI		English	Proceedings Paper	10th International Conference on Soft Computing and Machine Intelligence (ISCMI)	NOV 25-26, 2023	ELECTR NETWORK	IEEE, IEEE Mexico Section, IEEE Mexico Council, IEEE CIS Mexico Chapter, IICCI, Consejo MX		natural language processing; large language models; corporate events	ARIMA	This paper offers a thorough assessment of large language models (LLMs) in the context of corporate event prediction. To achieve this, we formally establish the task of corporate event prediction, construct a novel dataset containing summaries of earning call transcripts, and conduct comprehensive experiments involving both raw and fine-tuned variants of the primary LLMs. Our experimental findings underscore the viability of automating this intricate task using LLMs and highlight the unnecessariness of additional finetuning.	[Xiao, Zhaomin; Cui, Yachen; Li, Jiancheng] Univ North Texas, Denton, TX 76205 USA; [Mai, Zhelu] I 66 Express Mobil Partners, Manassas, VA USA; [Xu, Zhuoer] Hewlett Packard Enterprise, Houston, TX USA	University of North Texas System; University of North Texas Denton	Xiao, ZM (corresponding author), Univ North Texas, Denton, TX 76205 USA.	zhaominxiao@my.unt.edu; zhelumai@my.unt.edu; patrick.xu.work@gmail.com; yachen.cui@unt.edu; jianchengli@my.unt.edu						Basu S, 2013, EUR ACCOUNT REV, V22, P221, DOI 10.1080/09638180.2013.782820; Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Castro S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4619; Chaudhary A, 2021, AAAI CONF ARTIF INTE, V35, P16001; Chen Z, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P5514; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Chung H.W., 2022, SCALING INSTRUCTION; Ding X, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2327; Geng X., 2023, OpenLLaMA: An open reproduction of LLaMA; Hu EJ., 2021, Lora: Low-rank adaptation of large language models; Huang J, 2023, FINDINGS ASS COMPUTA, P1049, DOI [DOI 10.18653/V1/2023.FINDINGS-ACL.67, 10.18653/v1/2023.findings-acl.67]; Keith KA, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P493; Li JZ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P3063, DOI [10.1145/3340531.3412879, 10.1061/9780784482933.264]; Li LY, 2016, Arxiv, DOI arXiv:1611.01868; Liu CH, 2016, AAAI CONF ARTIF INTE, P1867; Longpre S., 2023, The flan collection: Designing data and methods for effective instruction tuning; Mihalcea R., 2012, P 3 WORKSHOP COMPUTA, P1; Mikolov T, 2013, arXiv, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, COMPUTING RES REPOSI; Ouyang L., 2022, NEURIPS; Pasch Stefan, 2022, 2022 IEEE International Conference on Big Data (Big Data), P3532, DOI 10.1109/BigData55660.2022.10020755; Paszke A, 2019, ADV NEUR IN, V32; Pataci H., 2022, P 4 WORKSHOP FINANCI, P48; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Pevzner M, 2015, J FINANC ECON, V117, P190, DOI 10.1016/j.jfineco.2013.08.004; Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081; Qin Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P390; Raffel C, 2020, J MACH LEARN RES, V21; Sharpe J., 2022, P 4 WORKSHOP FINANCI, P154; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tay Y., 2023, Ul2: Unifying language learning paradigms; Thakur H, 2023, 61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2, P340; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Tworkowski S., 2023, Focused transformer: Contrastive training for context scaling; Wei J, 2022, Finetuned language models are zero-shot learners; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; WOOLRIDGE JR, 1990, STRATEGIC MANAGE J, V11, P353, DOI 10.1002/smj.4250110503; Xiao Z., 2023, P 13 INT JOINT C NAT, P149; Xiao Z., 2022, P 29 INT C COMPUTATI, P2561; Yoshihara A., 2015, Artificial Intelligence Research, V5, DOI [10.5430/air.v5n1p103, DOI 10.5430/AIR.V5N1P103]; Zhang GP, 2003, NEUROCOMPUTING, V50, P159, DOI 10.1016/S0925-2312(01)00702-0; Zhang S., 2022, Opt: Open pre-trained transformer language models	43	0	0	8	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2640-0154	2640-0146	979-8-3503-5937-4	INT CONF SOFT COMP			2023							193	197		10.1109/ISCMI59957.2023.10458651	http://dx.doi.org/10.1109/ISCMI59957.2023.10458651			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IV					2024-07-03	WOS:001190966200036
J	Chiu, WHK; Ko, WSK; Cho, WCS; Hui, SYJ; Chan, WCL; Kuo, MD				Chiu, Wan Hang Keith; Ko, Wei Sum Koel; Cho, William Chi Shing; Hui, Sin Yu Joanne; Chan, Wing Chi Lawrence; Kuo, Michael D.			Evaluating the Diagnostic Performance of Large Language Models on Complex Multimodal Medical Cases	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						large language model; hospital; health center; Massachusetts; statistical analysis; chi-square; ANOVA; clinician; physician; performance; proficiency; disease etiology		Large language models showed interpretative reasoning in solving diagnostically challenging medical cases.	[Chiu, Wan Hang Keith; Ko, Wei Sum Koel] Queen Elizabeth Hosp, Dept Diagnost & Intervent Radiol, Hong Kong, Peoples R China; [Cho, William Chi Shing] Queen Elizabeth Hosp, Dept Clin Oncol, Hong Kong, Peoples R China; [Hui, Sin Yu Joanne] Univ Hong Kong, Li Ka Shing Fac Med, Sch Biomed Sci, Hong Kong, Peoples R China; [Chan, Wing Chi Lawrence] Hong Kong Polytech Univ, Dept Hlth Technol & Informat, Hong Kong, Peoples R China; [Kuo, Michael D.] Ensemble Grp, 10541 E Firewheel Dr, Scottsdale, AZ 85259 USA	University of Hong Kong; Hong Kong Polytechnic University	Kuo, MD (corresponding author), Ensemble Grp, 10541 E Firewheel Dr, Scottsdale, AZ 85259 USA.	mikedkuo@gmail.com	; Chiu, Keith Wan Hang/Z-3985-2019	Cho, William C/0000-0003-4174-4586; Hui, Sin Yu Joanne/0009-0000-9309-2423; Chan, Lawrence/0000-0001-6451-2273; Chiu, Keith Wan Hang/0000-0002-7930-1193				Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Dougan M, 2022, NEW ENGL J MED, V386, P1834, DOI 10.1056/NEJMcpc2115856; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Jamshidi N, 2023, METABOLITES, V13, DOI 10.3390/metabo13080929; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659	6	0	0	3	3	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAY 13	2024	26								e53724	10.2196/53724	http://dx.doi.org/10.2196/53724			4	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	RG0U3	38739441	gold			2024-07-03	WOS:001226404000003
J	Boonstra, MJ; Weissenbacher, D; Moore, JH; Gonzalez-Hernandez, G; Asselbergs, FW				Boonstra, Machteld; Weissenbacher, Davy; Moore, Jason; Gonzalez-Hernandez, Graciela; Asselbergs, Folkert			Artificial intelligence: revolutionizing cardiology with large language models	EUROPEAN HEART JOURNAL			English	Review						Large language models; Natural language processing; Cardiology; Clinical applications	INFORMATION; PASTE; COPY	Graphical Abstract Overview of input sources (top) to train or fine-tune cardio large language models and different applications (bottom). ECG, electrocardiogram; Q&A, questions and answers. Natural language processing techniques are having an increasing impact on clinical care from patient, clinician, administrator, and research perspective. Among others are automated generation of clinical notes and discharge letters, medical term coding for billing, medical chatbots both for patients and clinicians, data enrichment in the identification of disease symptoms or diagnosis, cohort selection for clinical trial, and auditing purposes. In the review, an overview of the history in natural language processing techniques developed with brief technical background is presented. Subsequently, the review will discuss implementation strategies of natural language processing tools, thereby specifically focusing on large language models, and conclude with future opportunities in the application of such techniques in the field of cardiology.	[Boonstra, Machteld; Asselbergs, Folkert] Univ Amsterdam, Amsterdam Univ, Dept Cardiol, Amsterdam Cardiovasc Sci,Med Ctr, Amsterdam, Netherlands; [Weissenbacher, Davy; Moore, Jason; Gonzalez-Hernandez, Graciela] Cedars Sinai Med Ctr, Dept Computat Biomed, Los Angeles, CA USA; [Asselbergs, Folkert] UCL, Inst Hlth Informat, London, England; [Asselbergs, Folkert] UCL, Univ Coll London Hosp, Biomed Res Ctr, Natl Inst Hlth Res, London, England	University of Amsterdam; Cedars Sinai Medical Center; University of London; University College London; University College London Hospitals NHS Foundation Trust; University of London; University College London	Asselbergs, FW (corresponding author), Univ Amsterdam, Amsterdam Univ, Dept Cardiol, Amsterdam Cardiovasc Sci,Med Ctr, Amsterdam, Netherlands.; Asselbergs, FW (corresponding author), UCL, Inst Hlth Informat, London, England.; Asselbergs, FW (corresponding author), UCL, Univ Coll London Hosp, Biomed Res Ctr, Natl Inst Hlth Res, London, England.	f.w.asselbergs@amsterdamumc.nl		Moore, Jason/0000-0002-5015-1099; Weissenbacher, Davy/0000-0001-8331-3675; Asselbergs, Folkert Wouter/0000-0002-1692-8669; Boonstra, Machteld J/0000-0001-7550-0489; Gonzalez Hernandez, Graciela/0000-0002-6416-9556	European Union [101057849, 101080430]; Horizon Europe - Pillar II [101057849] Funding Source: Horizon Europe - Pillar II	European Union(European Union (EU)); Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	This work received funding from the European Union's Horizon Europe research and innovation programme under Grant Agreement No. 101057849 (DataTools4Heart project) and No. 101080430 (AI4HF project). Other authors have nothing to declare.	Abdelnabi S., 2021, 2021 IEEE S SEC PRIV; Ahmad T, 2022, JAMA CARDIOL, V7, P905, DOI 10.1001/jamacardio.2022.2496; Alammar J, 2020, Interfaces for explaining transformer language models; Ambrosy AP, 2021, J AM COLL CARDIOL, V77, P674; anDREa, 2023, TRUST RES ENV UNB EM; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, The hacker news; [Anonymous], 1996, The 16th International Conference on Computational Linguistics; [Anonymous], 2023, HAS ANYONE NOTICED D; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bannour N., 2021, P 2 WORKSH SIMPL EFF; Bastings J., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2010.05607; Bill C., 2022, 27 ACT ENACT CONSUME; Bills S., 2023, OpenAI; Bishop CM., 2006, Pattern recognition and machine learning, P738, DOI DOI 10.1007/978-0-387-45528-0; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bolshakov I.A., 2004, Computational Linguistics: Models, Resources, Applications; Brezulianu A, 2022, FRONT PUBLIC HEALTH, V10, DOI 10.3389/fpubh.2022.880207; Brown JR, 2022, J AM HEART ASSOC, V11, DOI 10.1161/JAHA.121.024198; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carlini Nicholas, 2021, USENIX SEC S; Chen L, 2023, ARXIV230709009V1, DOI DOI 10.48550/ARXIV.2307.09009; Cheng CG, 2022, MEDICINE, V101, DOI 10.1097/MD.0000000000028644; Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Cina G., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2307.00897; Cina G., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.02080; Commission E, 2022, PROPOSAL REGULATION; Cutillo CM, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0254-2; Denecke K, 2023, J BIOMED INFORM, V140, DOI 10.1016/j.jbi.2023.104336; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dewaswala N, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-02017-y; Dinh MH., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2301.12288; Edward M., CLIN INVESTIGATION W; ENISA, 2023, ENISA Threat Landscape: Health Sector; Farajidavar N, 2022, BMC CARDIOVASC DISOR, V22, DOI 10.1186/s12872-022-03005-w; Federal Trade Commission, 2022, PROM EXP TRAD PREV U; Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677; Friedl J. E. F., 2006, Mastering Regular Expressions; Gabriel RA, 2018, J BIOMED INFORM, V82, P63, DOI 10.1016/j.jbi.2018.04.009; Gantzer HE, 2020, ANN INTERN MED, V173, P380, DOI 10.7326/M20-0934; Gattepaille LM, 2020, DRUG SAFETY, V43, P797, DOI 10.1007/s40264-020-00942-3; Ghahramani Z, 2015, NATURE, V521, P452, DOI 10.1038/nature14541; Ghassemi M, 2021, LANCET DIGIT HEALTH, V3, pE745, DOI 10.1016/S2589-7500(21)00208-9; Ghassemi MM, 2018, IEEE ENG MED BIO, P4058, DOI 10.1109/EMBC.2018.8513325; Ghazi L, 2022, J AM COLL CARDIOL, V79, P2203, DOI 10.1016/j.jacc.2022.03.338; Gomez D., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2005.07870; Google, 2023, PALM 2; Gutierrez BJ., 2022, FIND ASS COMPUT LING, DOI DOI 10.48550/ARXIV.2203.08410; Health and Human Services UDo, 2013, HIPAA PROF; Hendrycks D., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2009.03300; HIPAA, 2023, HEALTHC DAT BREACH S; Hisamoto S, 2020, T ASSOC COMPUT LING, V8, P49, DOI 10.1162/tacl_a_00299; Honnibal M., 2020, SPACY 2 NATURAL LANG, V7, P411, DOI 10.5281%2fzenodo.1212303; Hotho A., 2005, Journal for Language Technology and Computational Linguistics, V20, P19, DOI [10.21248/jlcl.20.2005.68, DOI 10.21248/JLCL.20.2005.68, DOI 10.1111/j.1365-2621.1978.tb09773.x]; Huang Y., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.14888; HuggingFace, 2023, TRANSF AG; Idnay B, 2021, J AM MED INFORM ASSN, V29, P197, DOI 10.1093/jamia/ocab228; James M., 2023, TURING TEST IS; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Jurasfky D., 2000, INTRO NATURAL LANGUA; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; KERNIGHAN BW, 1979, SOFTWARE PRACT EXPER, V9, P1, DOI 10.1002/spe.4380090102; Khurshid S, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00590-0; Kleene Stephen, 1956, Automata Studies. (AM-34), P3, DOI DOI 10.1515/9781400882618-002; Kraljevic Z., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2212.08072; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Lacoste A., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.09700; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lekadir K., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2109.09658; Levinson RT., 2021, MEDRXIV, DOI [10.1101/2021.02.01.21250933, DOI 10.1101/2021.02.01.21250933]; Liu JH, 2022, J BIOMED INFORM, V133, DOI 10.1016/j.jbi.2022.104149; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lukas N., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.00539; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Magdziarczyk, 2019, 6 INT MULT SCI C SOC; Mansfield-Devine S., 2022, IBM COST DATA BREACH; Mark, 2023, CHATGPT PASSES TURIN; Matefi R., 2021, ARTIF INTELL, P130; Mauran C., 2023, WHOOPS SAMSUNG WORKE; McCandless D., 2023, RISE RISE A I LARGE; Medicine ACCaP, 2023, CHATBOT ACT MON PAT; Mellia JA, 2021, ANN SURG, V273, P900, DOI 10.1097/SLA.0000000000004419; Meta A. I., 2023, Introducing LLaMA: A Foundational, 65-Billion-Parameter Large Language Model; Mintz Y, 2019, MINIM INVASIV THER, V28, P73, DOI 10.1080/13645706.2019.1575882; Morgan A., 2023, US; Murphy RM, 2023, J CRIT CARE, V75, DOI 10.1016/j.jcrc.2023.154292; Murphy RM, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0279842; Nadkarni PM, 2011, J AM MED INFORM ASSN, V18, P544, DOI 10.1136/amiajnl-2011-000464; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; NHS, 2023, SEC DAT ENV SERV; Ni L., 2017, INT S KNOWL SYST SCI, P38, DOI [10.1007/978-981-10-6989-5-4, DOI 10.1007/978-981-10-6989-5_4]; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; OpenAI, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.087742023; OpenAI, 2022, OpenA I; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patterson OV, 2017, BMC CARDIOVASC DISOR, V17, DOI 10.1186/s12872-017-0580-8; Pedersen AF, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-020007; Peng Y., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1906.05474; Peters ME, 2019, 4TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP (REPL4NLP-2019), P7; Pichai S., 2023, IMPORTANT NEXT STEP; Poibeau T., 2003, EXTRACTION AUTOMATIQ; Rohit C., 2022, JOINT STATEMENT ENFO; Rule A, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.15334; Russell SJ., 2016, ARTIF INTELL; Sammani A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00404-9; Sanh V., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2110.08207; Sarah K., 2023, CBTPRO SCALING CBT P; Scao T. L., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.05100; Schinkel M, 2023, ANN INTERN MED, V176, P572, DOI 10.7326/M23-0154; Schubbe D, 2020, PATIENT EDUC COUNS, V103, P1935, DOI 10.1016/j.pec.2020.04.010; Searle T., 2022, ARXIV, DOI DOI 10.1016/J.JBI.2023.104358; Searle T, 2023, J BIOMED INFORM, V141, DOI 10.1016/j.jbi.2023.104358; Searle T, 2021, J BIOMED INFORM, V124, DOI 10.1016/j.jbi.2021.103938; Shanahan M., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2202.05839; Shanahan M, 2020, TRENDS COGN SCI, V24, P862, DOI 10.1016/j.tics.2020.09.002; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Skalidis I, 2023, EUR HEART J-DIGIT HL, V4, P279, DOI 10.1093/ehjdh/ztad029; Srivastava A., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2206.04615; Subramanian S., 2020, P AAAI C ART INT; Tan S., 2023, WEB SERVICE DEDUCE P; Thornton JD, 2013, CRIT CARE MED, V41, P382, DOI 10.1097/CCM.0b013e3182711a1c; Tonekaboni S., 2019, MACH LEARN HEALTHC C; Tsou AY, 2017, APPL CLIN INFORM, V8, P12, DOI 10.4338/ACI-2016-09-R-0150; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; University WMCoC, 2023, CHATB MAX HER CANC G; University Y, 2023, ARTIF INTELL; Uszkoreit Jakob., 2017, Google AI Blog, V31; van IJzendoorn DG., 2022, MEDRXIV, DOI [10.1101/2022.11.01.22281685, DOI 10.1101/2022.11.01.22281685]; van Mens HJT, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01286-9; Vanni L., 2018, P 56 ANN M ASS COMP, V1; Verkijk S., 2022, P 13 LANG RES EV C; Verkijk S., 2021, Comput Linguist Neth, V11, P141; Vig J., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1906.05714; Vig Jesse, 2019, ICLR WORKSH DEB MACH; Wang F, 2020, ANN INTERN MED, V172, P59, DOI 10.7326/M19-2548; Wang J, 2020, J HYDROINFORM, V22, P20, DOI 10.2166/hydro.2019.018; Weis Justin M, 2014, Chest, V145, P632, DOI 10.1378/chest.13-0886; Weissenbacher D., 2006, BAYESIAN NETWORK MOD, P195; Weissenbacher D, 2019, SOCIAL MEDIA MINING FOR HEALTH APPLICATIONS (#SMM4H) WORKSHOP & SHARED TASK, P21; White HT, 2023, APPLYING BLUEPRINT A; Winograd T., 1971, Procedures as a Representation for Data In a Computer Program For Understanding Natural Language; Yalalov D., 2022, CHATGPT PASSES TURIN; Yu DH, 2022, JMIR MED INF, V10, DOI 10.2196/38140; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuan C, 2019, J AM MED INFORM ASSN, V26, P294, DOI 10.1093/jamia/ocy178; Zhan XH, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100289; Zuccon G., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13793	147	5	5	78	78	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0195-668X	1522-9645		EUR HEART J	Eur. Heart J.	FEB 1	2024	45	5			SI		332	345		10.1093/eurheartj/ehad838	http://dx.doi.org/10.1093/eurheartj/ehad838		JAN 2024	14	Cardiac & Cardiovascular Systems	Science Citation Index Expanded (SCI-EXPANDED)	Cardiovascular System & Cardiology	HC9R4	38170821	Green Published, hybrid			2024-07-03	WOS:001135440400001
J	Shahab, O; El Kurdi, B; Shaukat, A; Nadkarni, G; Soroush, A				Shahab, Omer; El Kurdi, Bara; Shaukat, Aasma; Nadkarni, Girish; Soroush, Ali			Large language models: a primer and gastroenterology applications	THERAPEUTIC ADVANCES IN GASTROENTEROLOGY			English	Review						artificial intelligence; ChatGPT; large language models; machine learning	ELECTRONIC HEALTH RECORDS; PHYSICIANS; CHATGPT; BIAS	Over the past year, the emergence of state-of-the-art large language models (LLMs) in tools like ChatGPT has ushered in a rapid acceleration in artificial intelligence (AI) innovation. These powerful AI models can generate tailored and high-quality text responses to instructions and questions without the need for labor-intensive task-specific training data or complex software engineering. As the technology continues to mature, LLMs hold immense potential for transforming clinical workflows, enhancing patient outcomes, improving medical education, and optimizing medical research. In this review, we provide a practical discussion of LLMs, tailored to gastroenterologists. We highlight the technical foundations of LLMs, emphasizing their key strengths and limitations as well as how to interact with them safely and effectively. We discuss some potential LLM use cases for clinical gastroenterology practice, education, and research. Finally, we review critical barriers to implementation and ongoing work to address these issues. This review aims to equip gastroenterologists with a foundational understanding of LLMs to facilitate a more active clinician role in the development and implementation of this rapidly emerging technology. Large language models in gastroenterology: a simplified overview for cliniciansThis text discusses the recent advancements in large language models (LLMs), like ChatGPT, which have significantly advanced artificial intelligence. These models can create specific, high-quality text responses without needing extensive training data or complex programming. They show great promise in transforming various aspects of clinical healthcare, particularly in improving patient care, medical education, and research. This article focuses on how LLMs can be applied in the field of gastroenterology. It explains the technical aspects of LLMs, their strengths and weaknesses, and how to use them effectively and safely. The text also explores how LLMs could be used in clinical practice, education, and research in gastroenterology. Finally, it discusses the challenges in implementing these models and the ongoing efforts to overcome them, aiming to provide gastroenterologists with the basic knowledge needed to engage more actively in the development and use of this emerging technology.	[Shahab, Omer] VHC Hlth, Dept Med, Div Gastroenterol, Arlington, VA USA; [El Kurdi, Bara] Virginia Tech CarilIon Sch Med, Div Gastroenterol & Hepatol, Dept Med, Roanoke, VA USA; [Shaukat, Aasma] NYU, Grossman Sch Med, Dept Med, Div Gastroenterol, New York, NY USA; [Shaukat, Aasma] New York Harbor Vet Affairs Healthcare Syst, New York, NY USA; [Nadkarni, Girish] Icahn Sch Med Mt Sinai, Dept Med, Div Data Driven & Digital Med, New York, NY USA; [Nadkarni, Girish; Soroush, Ali] Icahn Sch Med Mt Sinai, Charles Bronfman Inst Personalized Med, New York, NY 10029 USA; [Soroush, Ali] Icahn Sch Med Mt Sinai, Div Data Driven & Digital Med, 1 Gustave L Levy Pl, New York, NY 10029 USA; [Soroush, Ali] Icahn Sch Med Mt Sinai, Dept Med, Henry D Janowitz Div Gastroenterol, New York, NY 10029 USA	New York University; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai; Icahn School of Medicine at Mount Sinai	Soroush, A (corresponding author), Icahn Sch Med Mt Sinai, Charles Bronfman Inst Personalized Med, New York, NY 10029 USA.; Soroush, A (corresponding author), Icahn Sch Med Mt Sinai, Div Data Driven & Digital Med, 1 Gustave L Levy Pl, New York, NY 10029 USA.; Soroush, A (corresponding author), Icahn Sch Med Mt Sinai, Dept Med, Henry D Janowitz Div Gastroenterol, New York, NY 10029 USA.	Ali.soroush@mountsinai.org	Soroush, Ali/O-5540-2016					Abridge, 2023, Our technology; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ali S., 2023, medRxiv; Aquino YS, 2023, INT J MED INFORM, V169, DOI 10.1016/j.ijmedinf.2022.104903; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Byun JS, 2020, Arxiv, DOI arXiv:2010.09933; Cabitza F, 2017, JAMA-J AM MED ASSOC, V318, P517, DOI 10.1001/jama.2017.7797; Cai TL, 2024, Arxiv, DOI arXiv:2305.17126; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen AK, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104370; Chen M., 2021, arXiv; Chen Y., 2023, J Med Internet Res, V25; Chen ZM, 2023, Arxiv, DOI arXiv:2311.16079; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Coalition for Health AI, 2023, BLUEPRINT TRUSTWORTH; DeepScribe, 2023, DeepScribe outperforms GPT-4 by 32% on AI medical scribing: a benchmark study; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Duolingo, 2023, Introducing Duolingo Max, a learning experience powered by GPT-4; Durán JM, 2021, J MED ETHICS, V47, P329, DOI [10.1136/medethics-2020-106820, 10.1136/medethics-2021-107531]; Fung B., 2023, The big bottleneck for AI: a shortage of powerful chips; Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Gottlieb S., 2023, JAMA Health Forum, V4; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kamradt G., 2023, Needle in a Haystack-pressure testing LLMs; Kanter GP, 2023, JAMA-J AM MED ASSOC, V330, P311, DOI 10.1001/jama.2023.9618; Khan Academy, 2023, Khanmigo Education AI Guide; Kim J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7031; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Landrigan CP, 2010, NEW ENGL J MED, V363, P2124, DOI 10.1056/NEJMsa1004404; LangChain, 2023, Introduction; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lehman E, 2023, Arxiv, DOI [arXiv:2302.08091, 10.48550/arXiv.2302.08091, DOI 10.48550/ARXIV.2302.08091]; Lingard L, 2023, PERSPECT MED EDUC, V12, P261, DOI 10.5334/pme.1072; Liu S., 2023, medRxiv; Lu P, 2023, Arxiv, DOI arXiv:2304.09842; Lu Y., 2023, New York Times; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; McDermott MBA, 2023, Arxiv, DOI arXiv:2306.11547; McDuff D., 2023, arXiv; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mialon G., 2023, arXiv; Moy AJ, 2021, J AM MED INFORM ASSN, V28, P998, DOI 10.1093/jamia/ocaa325; Mukherjee S, 2023, Arxiv, DOI arXiv:2306.02707; Nehme F, 2021, DIGEST DIS SCI, V66, P29, DOI 10.1007/s10620-020-06156-y; Nogueira R, 2021, Arxiv, DOI arXiv:2102.13019; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Nuance, 2023, Ambient clinical intelligence-Explore Nuance DAX; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; OpenAI, 2023, Introducing chatgpt; OpenAI, 2023, ChatGPT plugins; OpenEvidence, 2023, OpenEvidence AI becomes the first AI in history to score above 90% on the United States Medical Licensing Examination (USMLE); Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; PaperPal, 2023, Rewrite text, word reduction: paperpal launches new LLM-powered capabilities; Pathipati MP., 2023, Neurogastroenterol Motil, V35; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Peng C, 2023, Arxiv, DOI arXiv:2305.13523; Qiao SF, 2023, Arxiv, DOI [arXiv:2212.09597, DOI 10.48550/ARXIV.2212.09597]; Rex DK, 2023, GASTROENTEROL REP, V11, DOI 10.1093/gastro/goad009; Richardson S, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00663-0; Schick T., 2023, arXiv; Services AW, 2023, AWS HealthScribe; Services DoHaH, Software as a medical device: guidance for industry and food and drug administration staff; Services DoHaH, Clinical decision support software: guidance for industry and food and drug administration staff; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Stenberg U, 2018, PATIENT EDUC COUNS, V101, P1006, DOI 10.1016/j.pec.2018.01.006; Suchman K, 2023, AM J GASTROENTEROL, V118, P2280, DOI 10.14309/ajg.0000000000002320; Tai-Seale M, 2017, HEALTH AFFAIR, V36, P655, DOI 10.1377/hlthaff.2016.0811; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tworkowski S, 2023, Arxiv, DOI arXiv:2307.03170; Uche-Anya E, 2022, GUT, V71, P1909, DOI 10.1136/gutjnl-2021-326271; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wei WQ, 2016, J AM MED INFORM ASSN, V23, pE20, DOI 10.1093/jamia/ocv130; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yosinski J, 2014, ADV NEUR IN, V27; Zhang Y, 2023, Arxiv, DOI arXiv:2305.13225; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhen J, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01706-x; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	93	1	1	13	13	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1756-283X	1756-2848		THER ADV GASTROENTER	Ther. Adv. Gastroenterol.		2024	17								17562848241227031	10.1177/17562848241227031	http://dx.doi.org/10.1177/17562848241227031			15	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	IW9B7	38390029	Green Published, gold			2024-07-03	WOS:001169482400001
C	Chang, EY		Paul, R		Chang, Edward Y.			Prompting Large Language Models With the Socratic Method	2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC			English	Proceedings Paper	IEEE 13th Annual Computing and Communication Workshop and Conference (CCWC)	MAR 08-11, 2023	ELECTR NETWORK	IEEE, SMART, IEEE Reg 1, IEEE USA, Inst Engn & Management, Univ Engn & Management		large language model; natural language processing; prompting; the Socratic method		This paper presents a systematic approach to using the Socratic method in developing prompt templates that effectively interact with large language models, including GPT-3. Various methods are examined, and those that yield precise answers and justifications while fostering creativity and imagination to enhance creative writing are identified. Techniques such as definition, elenchus, dialectic, maieutics, generalization, and counterfactual reasoning are discussed for their application in engineering prompt templates and their connections to inductive, deductive, and abductive reasoning. Through examples, the effectiveness of these dialogue and reasoning methods is demonstrated. An interesting observation is made that when the task's goal and user intent are conveyed to GPT-3 via ChatGPT before the start of a dialogue, the large language model seems to connect to the external context expressed in the intent and perform more effectively.	[Chang, Edward Y.] Stanford Univ, Comp Sci, Stanford, CA 94305 USA	Stanford University	Chang, EY (corresponding author), Stanford Univ, Comp Sci, Stanford, CA 94305 USA.	echang@cs.stanford.edu						Airaksinen T, 2022, ARGUMENTATION, V36, P85, DOI 10.1007/s10503-021-09556-0; [Anonymous], 1998, P 7 INT WORLD WID WE; [Anonymous], 2010, THINKERS GUIDE ART A; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Browne M., 2001, Asking the Right Questions: A Guide to Critical Thinking; Campagna G., 2020, FINDINGS; Chang E. Y., 2023, CRIT INQUISITIVE PRO; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dobrovolskii V, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7670; Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haviv A, 2021, Arxiv, DOI arXiv:2103.05327; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Jung J., 2022, C EMPIRICAL METHODS; Jurafsky D., 2023, Speech and Language Processing An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition Third Edition draft Summary of Contents, V3rd; Lai G., 2017, P 2017 C EMP METH NA, P785, DOI 10.18653/v1/D17-1082; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; LLC Editors LearningExpress, 2004, 501 CRITICAL READING; Mialon G., 2023, arXiv; OpenAI, 2021, Chatgpt; Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470; Paul R., 2007, Journal of Developmental Education, V31, P34; Paul Richard., 1990, Critical Thinking: What Every Person Needs to Survive in a Rapidly Changing World; Pearl J., 2009, COUNTERFACTUALS CAUS; Peng XY, 2022, Arxiv, DOI arXiv:2210.12587; Pirie M., 2006, WIN EVERY ARGUMENT; Plutynski A, 2011, HOPOS, V1, P227; Pozner L., 2021, CROSS EXAMINATION SC, V3rd; Schick T., 2020, C EUROPEAN CHAPTER A; Stoddard HA, 2016, J GEN INTERN MED, V31, P1092, DOI 10.1007/s11606-016-3722-2; Thrash TM, 2010, J PERS SOC PSYCHOL, V98, P469, DOI 10.1037/a0017907; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang X., 2023, INT C LEARNING REPRE; Wei Jason, 2022, ADV NEURAL INFORM PR; Welker S., 2022, Socratic models: Composing zero-shot multimodal reasoning with language; Wikipedia, 2023, SOCRATIC METHOD; Wolf Thomas, 2019, Transfertransfo: A transfer learning approach for neural network based conversational agents; Wrenn C. B., 2023, INTERNET ENCY PHILOS; Zhang W., 2023, ACM T INFORM SYST, V41; Zhao W., 2021, arXiv; Zhou JW, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6279	44	2	3	8	43	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-3286-5				2023							351	360		10.1109/CCWC57344.2023.10099179	http://dx.doi.org/10.1109/CCWC57344.2023.10099179			10	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BV1QP		Green Submitted			2024-07-03	WOS:000995182600056
J	Koldunov, N; Jung, T				Koldunov, Nikolay; Jung, Thomas			Local climate services for all, courtesy of large language models	COMMUNICATIONS EARTH & ENVIRONMENT			English	Article								Large language models can summarize, aggregate, and convey localized climate-related data to people in a cost-effective and expeditious manner. We have built a simple, proof-of-concept prototype and argue that the approach holds the potential to truly democratize climate information. Large language models can summarize, aggregate, and convey localized climate-related data to people in a cost-effective and expeditious manner. This Comment introduces a simple, proof-of-concept prototype and argues that the approach holds the potential to truly democratize climate information.	[Koldunov, Nikolay; Jung, Thomas] Alfred Wegener Inst, Helmholtz Ctr Polar & Marine Res, Bremerhaven, Germany; [Jung, Thomas] Univ Bremen, Inst Environm Phys, Bremen, Germany	Helmholtz Association; Alfred Wegener Institute, Helmholtz Centre for Polar & Marine Research; University of Bremen	Koldunov, N (corresponding author), Alfred Wegener Inst, Helmholtz Ctr Polar & Marine Res, Bremerhaven, Germany.	nikolay.koldunov@awi.de	Koldunov, Nikolay V. V./A-5439-2011; Jung, Thomas/J-5239-2012; Atmosphere and Ocean, Collaborative Research Center TRR 181- Energy Transfers in/AAY-2721-2020	Koldunov, Nikolay V. V./0000-0002-3365-8146; Jung, Thomas/0000-0002-2651-1293; 	Deutsche Forschungsgemeinschaft (German Research Foundation) [TRR 181]; Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [274762653]	Deutsche Forschungsgemeinschaft (German Research Foundation)(German Research Foundation (DFG)); Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG))	The work presented in this comment was motivated by discussions in the context of the EU's "Destination Earth" initiative, however, opinions presented here are the author's views. This paper is a contribution to the project S1 of the Collaborative Research Center TRR 181 "Energy Transfers in Atmosphere and Ocean" funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation; project no. 274762653). We acknowledge packages langchain (https://github.com/langchain-ai/langchain/) and streamlit (https://streamlit.io/) that were very instrumental in putting the proof-of-concept together.	Bauer P, 2021, NAT CLIM CHANGE, V11, P80, DOI 10.1038/s41558-021-00986-y; Hewitt C, 2012, NAT CLIM CHANGE, V2, P831, DOI 10.1038/nclimate1745; Hoffmann J, 2023, CLIM SERV, V30, DOI 10.1016/j.cliser.2023.100394; Lee H, 2023, CURR APPL PHYS, V49, P1, DOI 10.1016/j.cap.2023.02.010; Qian C, 2024, Arxiv, DOI arXiv:2307.07924; Semmler T, 2020, J ADV MODEL EARTH SY, V12, DOI 10.1029/2019MS002009; Stevens B., 2023, EARTH SYST SCI DATA, DOI [10.5194/essd-2023-376, DOI 10.5194/ESSD-2023-376]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaughan C, 2014, WIRES CLIM CHANGE, V5, P587, DOI 10.1002/wcc.290; Wu QY, 2023, Arxiv, DOI arXiv:2308.08155	10	0	0	10	10	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2662-4435		COMMUN EARTH ENVIRON	Commun. Earth Environ.	JAN 5	2024	5	1							13	10.1038/s43247-023-01199-1	http://dx.doi.org/10.1038/s43247-023-01199-1			4	Environmental Sciences; Geosciences, Multidisciplinary; Meteorology & Atmospheric Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Geology; Meteorology & Atmospheric Sciences	EC6A5		gold			2024-07-03	WOS:001136743100002
C	Zan, DG; Chen, B; Zhang, FJ; Lu, DJ; Wu, BC; Guan, B; Wang, YJ; Lou, JG		Rogers, A; Boyd-Graber, J; Okazaki, N		Zan, Daoguang; Chen, Bei; Zhang, Fengji; Lu, Dianjie; Wu, Bingchao; Guan, Bei; Wang, Yongji; Lou, Jian-Guang			Large Language Models Meet NL2Code: A Survey	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow			CODE GENERATION	The task of generating code from a natural language description, or NL2Code, is considered a pressing and significant challenge in code intelligence. Thanks to the rapid development of pre-training techniques, surging large language models are being proposed for code, sparking the advances in NL2Code. To facilitate further research and applications in this field, in this paper, we present a comprehensive survey of 27 existing large language models for NL2Code, and also review benchmarks and metrics. We provide an intuitive comparison of all existing models on the HumanEval benchmark. Through in-depth observation and analysis, we provide some insights and conclude that the key factors contributing to the success of large language models for NL2Code are "Large Size, Premium Data, Expert Tuning". In addition, we discuss challenges and opportunities regarding the gap between models and humans. We also create a website https://nl2code.github.io to track the latest progress through crowd-sourcing. To the best of our knowledge, this is the first survey of large language models for NL2Code, and we believe it will contribute to the ongoing development of the field.	[Zan, Daoguang; Wu, Bingchao] Chinese Acad Sci, Cooperat Innovat Ctr, Inst Software, Beijing, Peoples R China; [Zan, Daoguang] Univ Chinese Acad Sci, Beijing, Peoples R China; [Zan, Daoguang; Chen, Bei; Zhang, Fengji; Lou, Jian-Guang] Microsoft Res Asia, Beijing, Peoples R China; [Lu, Dianjie] Shandong Normal Univ, Jinan, Peoples R China; [Guan, Bei; Wang, Yongji] Chinese Acad Sci, Inst Software, Integrat Innovat Ctr, Beijing, Peoples R China	Chinese Academy of Sciences; Institute of Software, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Microsoft Research Asia; Microsoft; Shandong Normal University; Chinese Academy of Sciences; Institute of Software, CAS	Zan, DG (corresponding author), Chinese Acad Sci, Cooperat Innovat Ctr, Inst Software, Beijing, Peoples R China.; Zan, DG (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.; Zan, DG (corresponding author), Microsoft Res Asia, Beijing, Peoples R China.	daoguang@iscas.ac.cn; beichen@microsoft.com; v-fengjzhang@microsoft.com; Ludianjie@sdnu.edu.cn; bingchao2017@iscas.ac.cn; guanbei@iscas.ac.cn; ywang@itechs.iscas.ac.cn; jlou@microsoft.com	Zan, Daoguang/KLY-4874-2024					Agashe R, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5436; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; aiXcoder, 2018, US; Alibaba, 2022, ALIBABA; Allal Loubna Ben, 2023, SANTACODER DONT REAC; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Allamanis M, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P472, DOI 10.1145/2635868.2635901; Amazon, 2022, CODEWHISPERER; Arutyunov erman Arsenovich, 2022, P I SYST PROGR RAS; Athiwaratkun Ben, 2022, MULTILINGUAL EVALUAT; Austin Jacob, 2021, PROGRAM SYNTHESIS LA; Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Barke Shraddha, 2022, P ACM PROGRAMMING LA, V7, P85; Bavarian Mohammad, 2022, EFFICIENT TRAINING L; Black Sid, 2022, P ACL WORKSH CHALL P; Black Sid, 2021, GPT-Neo: Large scale autoregressive language modeling with mesh-tensorflow; Cassano Federico, 2022, SCALABLE EXTENSIBLE; Chai Yekun, 2022, ARXIV221206742; Chandel Shubham, 2022, ARXIV220112901; Chandel Shubham, 2022, TRAINING EVALUATING; Chen Bei, 2023, 11 INT C LEARN REPR; Chen M., 2021, ARXIV; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Christopoulou Fenia, 2022, PANGU CODER PROGRAM; Clement Colin B., 2020, C EMP METH NAT LANG; CodedotAl, 2021, GPT CODE CLIPPY OPEN; Cohn T, 2010, J MACH LEARN RES, V11, P3053; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; DeepGenX, 2022, CODEGENX; Dehaerne Enrique, 2022, IEEE ACCESS; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Drori Iddo, 2021, ARXIV211108171; Eriguchi A, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P823; FauxPilot, 2022, FAUXPILOT; Fried Daniel, 2023, 11 INT C LEARN REPR; Gao Leo, 2020, ARXIV210100027; GitHub, 2021, GITHUB COP; Google, 2022, BIG BENCH; Google, 2016, GITHUB BIGQUERY AN A; Gulwani Sumit, 2010, P 12 INT ACM SIGPLAN, P13, DOI [10.1145/1836089.1836091, DOI 10.1145/1836089.1836091]; Hendrycks Dan, 2021, NEURAL INFORM PROCES; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; HuggingFace, 2021, GITHUB JUP; HuggingFace, 2021, CODEPARROT DAT; HuggingFace, 2021, GITH COD; Huggingface, 2021, TRAIN CODEPARROT SCR; HuggingFace, 2022, THE STACK; Husain Hamel, 2019, CODESEARCH NET CHALL; IBM, 2021, CODENET; Imai S, 2022, PROC IEEE ACM INT C, P319, DOI [10.1109/ICSE-Companion55297.2022.9793778, 10.1145/3510454.3522684]; Iyer S, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P2073; Jha S., 2010, P 32 ACM IEEE INT C, V1, P215, DOI DOI 10.1145/1806799.1806833; Joshi Aravind, 2003, P C MEANING TEXT THE, P207; Joshi Harshit, 2022, ARXIV220811640; Kang Sungmin, 2023, ARXIV230402195; Key Darren, 2022, ARXIV221000848; Kingma D. P., 2017, ARXIV; Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588; Kudo T, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P66; Lai Yuhang, 2022, DS 1000 NATURAL RELI; Le Hung, 2022, ARXIV220701780; Le Scao Teven, 2022, ARXIV221105100; Le THM, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3383458; Li Yaoxian, 2022, ARXIV220704285; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Li ZY, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1035, DOI 10.1145/3540250.3549081; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu S., 2022, 11 INT C LEARN REPR; Liu ZQ, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P61, DOI 10.1109/FPT.2016.7929190; Loshchilov I., 2017, CoRR; Lu S, 2021, CodeXGLUE: A machine learning benchmark dataset for code understanding and generation; Luhunu Lechanceux, 2017, ACM IEEE INT C MOD D; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil Stephen, 2022, ARXIV221102265; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Microsoft, 2019, INTELLICODE; Neelakantan Arvind, 2022, ARXIV220110005; Nguyen Tung Thanh, 2013, P 2013 9 JOINT M FDN, P532, DOI DOI 10.1145/2491411.2491458; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Ouyang Long, 2022, TRAINING LANGUAGE MO; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pawade Dipti, 2018, I MANAGERS J COMPUTE, V6, P34; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Prenner Julian Aron, 2021, ARXIV211103922; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajkumar Nitarshan, 2022, ARXIV220400498; Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI [10.1145/2594291.2594321, 10.1145/2666356.2594321]; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Ren Shuo, 2020, ARXIV200910297; Saunders William, 2022, ARXIV220605802; Shah M, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405093; Sharma Tushar, 2021, ARXIV211009610; Shin J, 2021, J INF PROCESS SYST, V17, P537; Siddiq Mohammed Latif, 2022, P 1 INT WORKSH MIN S; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Sun Zeyu, 2018, AAAI C ART INT; Sutskever Ilya, 2008, NEURAL INFORM PROCES, V21; Svyatkovskiy Alexey, 2020, ESEC/FSE 2020: Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P1433, DOI 10.1145/3368089.3417058; Syriani E, 2018, COMPUT LANG SYST STR, V52, P43, DOI 10.1016/j.cl.2017.11.003; tabnine, 2018, US; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Tu L., 2023, 11 INT C LEARN REPR; University of Oxford, 2020, DIFFBL COV; Vaswani A, 2017, ADV NEUR IN, V30; Wan Y, 2018, IEEE INT CONF AUTOM, P397, DOI 10.1145/3238147.3238206; Wang Ben, 2021, Gpt-j-6b: A 6 billion parameter autoregressive language model; Wang Shiqi, 2022, ARXIV221210264; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wang Zhiruo, 2022, ARXIV221210481; Wei Jason, 2022, arXiv:2201.11903; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Xu Yichen, 2022, ARXIV221210079; Yin PC, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P440, DOI 10.18653/v1/P17-1041; Yin PC, 2018, IEEE WORK CONF MIN S, P476, DOI 10.1145/3196398.3196408; Zan Daoguang, 2022, INT JOINT C ART INT; Zan Daoguang, 2022, C EMP METH NAT LANG; Zhang Jialu, 2022, ARXIV220914876; Zheng Qinkai, 2023, CODEGEEX PRETRAINED; ZhiruoWang Grace Cuenca, 2022, ARXIV220308388; Zhou Shuyan, 2023, 11 INT C LEARN REPR; Zhu Ming, 2022, XLCOST BENCHMARK DAT; Zhu Ming, 2022, MULTILINGUAL CODE SN	124	7	7	2	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							7443	7464						22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SC					2024-07-03	WOS:001181086806033
J	Han, JW; Lu, JK; Xu, Y; You, J; Wu, BX				Han, Jiawei; Lu, Jiankang; Xu, Ying; You, Jin; Wu, Bingxin			Intelligent Practices of Large Language Models in Digital Government Services	IEEE ACCESS			English	Article						Digital government; governmental counseling; GCALLM; large language models; effective assistance		Large language models have been widely used in open-domain tasks with significant results, as well as being able to perform zero-sample closed-ended questions based on internal knowledge stored in the parameters during pre-training to answer the task. However, this internalized knowledge may be insufficient or the knowledge may be outdated in responding to government service consultation scenarios, which may result in the inability of the large language models to perform accurate and rigorous answers and provide effective assistance. This issue has attracted widespread attention, but there is a lack of datasets for relevant research. Therefore, in this paper, we take Beijing as an example to collect all kinds of common service counseling questions from its government website and the corresponding official answers as a dataset, which contains the daily counseling questions encountered by the citizens, including common questions about medical insurance, social insurance, provident fund flexible employment, and government-private interaction. Therefore, this paper designs a domain-specific language model (GCALLM) for government service consultation based on this scenario. By fine-tuning the large language models for knowledge injection, the fine-tuned model helps the large language models improve their performance in governmental service consulting scenarios by providing contextual information. And it solves the problem of not being able to answer precisely, allowing for more rigor and accuracy of the answers. In addition, the response information is answered in seven major national languages to improve the construction of digital government consulting services. A large number of experiments have proved that the model can produce accurate responses in this scenario in the field of governmental counseling.	[Han, Jiawei; Lu, Jiankang; You, Jin; Wu, Bingxin] Changchun Univ, Coll Cyber Secur, Changchun 130022, Peoples R China; [Han, Jiawei] Peking Univ, Digital Ident & Blockchain Joint Lab, Beijing 100871, Peoples R China; [Xu, Ying] Changchun Univ, Sch Adm, Changchun 130022, Peoples R China	Changchun University; Peking University; Changchun University	Han, JW (corresponding author), Changchun Univ, Coll Cyber Secur, Changchun 130022, Peoples R China.; Han, JW (corresponding author), Peking Univ, Digital Ident & Blockchain Joint Lab, Beijing 100871, Peoples R China.	hanjw78@ccu.edu.cn			Jilin Provincial Development and Reform Commission Planning Project	Jilin Provincial Development and Reform Commission Planning Project	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Communication S, 2023, Arxiv, DOI [arXiv:2308.11596, 10.48550/arXiv.2308.11596, DOI 10.48550/ARXIV.2308.11596]; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Du Z., PROC 60 ANN M ASS CO, V1; Gravitas S., 2023, Auto-GPT: An autonomous GPT-4 experiment; Hu E. J., 2022, PROC 10 INT C LEARN, P1; Huang QZ, 2023, Arxiv, DOI arXiv:2305.15062; Jantre S, 2022, Arxiv, DOI arXiv:2204.02344; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li YX, 2023, Arxiv, DOI [arXiv:2303.14070, DOI 10.48550/ARXIV.2303.14070, 10.48550/arXiv.2303.14070]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Ling C, 2023, Arxiv, DOI arXiv:2305.18703; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Liu ZR, 2023, Arxiv, DOI arXiv:2305.15265; Mialon G., 2023, arXiv; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Qin G., PROC C N AM CHAPTER; Radford A., 2018, IMPROVING LANGUAGE U; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Shi WJ, 2023, Arxiv, DOI [arXiv:2301.12652, DOI 10.48550/ARXIV.2301.12652]; Taori Rohan, 2023, Stanford Center for Research on Foundation Models, V3, P7; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang HC, 2023, Arxiv, DOI [arXiv:2304.06975, DOI 10.48550/ARXIV.2304.06975]; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xiong HL, 2023, Arxiv, DOI arXiv:2304.01097; Yang H, 2023, arXiv; Zhang T., 2020, PROC 8 INT C LEARN R; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	39	0	0	34	34	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						8633	8640		10.1109/ACCESS.2024.3349969	http://dx.doi.org/10.1109/ACCESS.2024.3349969			8	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	FK6J1		gold			2024-07-03	WOS:001145711400001
C	Guo, DS; Yue, AZ; Ning, FG; Huang, DR; Chang, BX; Duan, Q; Zhang, LC; Chen, ZL; Zhang, Z; Zhan, EH; Zhang, QL; Jiang, K; Li, R; Zhao, SX; Wei, ZZ		Sheng, VS; Hicks, C; Ling, C; Raghavan, V; Wu, X		Guo, Dongsheng; Yue, Aizhen; Ning, Fanggang; Huang, Dengrong; Chang, Bingxin; Duan, Qiang; Zhang, Lianchao; Chen, Zhaoliang; Zhang, Zheng; Zhan, Enhao; Zhang, Qilai; Jiang, Kai; Li, Rui; Zhao, Shaoxiang; Wei, Zizhong			A Study Case of Automatic Archival Research and Compilation using Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE GRAPH, ICKG			English	Proceedings Paper	14th IEEE International Conference on Knowledge Graph (IEEE ICKG)	DEC 01-02, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Minist Educ China, Key Lab Knowledge Engn Big Data, Hefei Univ Technol, Anhui Assoc Artificial Intelligence, Inspur Co Ltd		Archival research and compilation; Automatic method; Large language models; Fine-tuning		Archival research and compilation is a specialized task that focuses on exploration, selection and processing of vast quantities of archival documents pertaining to specific subjects. Traditionally, this task has been characterized by its labor-intensive and time-consuming requirements. In recent years, the advancement of artificial intelligence has made automatic archival research and compilation tasks feasible. However, the limited availability of relevant samples imposes significant constraints on the application of deep learning models, given their high demand for sufficient data and knowledge. In this paper, we present a study case and propose an innovative method for automatic archival research and compilation, leveraging the robust knowledge base and text generation ability offered by large language models. Specifically, our method comprises three essential components: document retrieval, document summarization, and rule-based compilation. In the document summarization component, we leverage fine-tuned large language models to enhance the performance by simulation data generation and summary generation. Experimental results substantiate the effectiveness of our method. Furthermore, our method provides a general idea in using large language models, as well as a solution for addressing similar challenges in different domains.	[Guo, Dongsheng; Yue, Aizhen; Huang, Dengrong; Chang, Bingxin; Duan, Qiang; Zhang, Zheng; Zhan, Enhao; Zhang, Qilai; Jiang, Kai; Li, Rui; Wei, Zizhong] Inspur Acad Sci & Technol, Jinan, Shandong, Peoples R China; [Ning, Fanggang; Zhang, Lianchao; Chen, Zhaoliang; Zhao, Shaoxiang] Inspur Software Co Ltd, Jinan, Shandong, Peoples R China		Wei, ZZ (corresponding author), Inspur Acad Sci & Technol, Jinan, Shandong, Peoples R China.	wzz@inspur.com	NING, FANGGANG/K-3437-2019; Guo, Dongsheng/AAT-7475-2020	NING, FANGGANG/0000-0002-4350-5178; 				[Anonymous], 2016, Abstractive text summarization using sequence-to-sequence rnns and beyond; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Y., 2015, Master's Thesis; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Chung H. W., 2022, CoRR abs/2210.11416; Colavizza G, 2022, ACM J COMPUT CULT HE, V15, DOI 10.1145/3479010; Cook T., 2001, Archival Science, V1, P3, DOI [DOI 10.1007/BF02435636, 10.1007/BF02435636]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding N, 2023, NAT MACH INTELL, V5, P220, DOI 10.1038/s42256-023-00626-4; Dongwook Lee, 2019, arXiv; Doulaty M, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P130, DOI 10.1109/ASRU.2015.7404785; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fedus W, 2022, J MACH LEARN RES, V23; Gladney H., 2009, AM ARCHIVIST, V72, P401, DOI DOI 10.17723/AARC.72.2.G; Hawkins A, 2022, ARCH SCI-NETHERLANDS, V22, P319, DOI 10.1007/s10502-021-09381-0; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu E.J., 2022, 10 INT C LEARN REPR; Hutchinson T, 2020, REC MANAG J, V30, P155, DOI 10.1108/RMJ-09-2019-0055; Le Q. V., 2022, 10 INT C LEARN REPR; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Liu X, 2022, Arxiv, DOI arXiv:2110.07602; Liu Y, 2019, ARXIV PREPRINT ARXIV; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Resig J, 2014, Journal of Digital Humanities, V3, P3; Rolan G, 2019, ARCH MANUSCR, V47, P179, DOI 10.1080/01576895.2018.1502088; Tay Y, 2022, Arxiv, DOI arXiv:2210.11399; Vaswani A, 2017, ADV NEUR IN, V30; Zeng A., 2023, 11 INT C LEARN REPR; Zhang B., 2022, INT C MACHINE LEARNI, P26176; Zhuang L., 2021, P 20 CHINESE NATL C, P1218	33	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0709-2				2023							52	59		10.1109/ICKG59574.2023.00012	http://dx.doi.org/10.1109/ICKG59574.2023.00012			8	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5RD					2024-07-03	WOS:001166570200007
C	Ahmed, T; Ghosh, S; Bansal, C; Zimmermann, T; Zhang, X; Rajmohan, S			IEEE	Ahmed, Toufique; Ghosh, Supriyo; Bansal, Chetan; Zimmermann, Thomas; Zhang, Xuchao; Rajmohan, Saravan			Recommending Root-Cause and Mitigation Steps for Cloud Incidents using Large Language Models	2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ICSE	International Conference on Software Engineering		English	Proceedings Paper	45th IEEE/ACM International Conference on Software Engineering (ICSE)	MAY 14-20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, Melbourne Convent Bur, State Govt Victoria, CSIRO, Huawei, Monash Univ, Meta, Google, AWS, Monash Univ, Dragon Testing Technol, IBM, Univ Melbourne, RMIT Univ		Incident Management; Service Quality; GPT-3.x; Large Language Models		Incident management for cloud services is a complex process involving several steps and has a huge impact on both service health and developer productivity. On-call engineers require significant amount of domain knowledge and manual effort for root causing and mitigation of production incidents. Recent advances in artificial intelligence has resulted in state-of-the-art large language models like GPT-3.x (both GPT-3.0 and GPT-3.5), which have been used to solve a variety of problems ranging from question answering to text summarization. In this work, we do the first large-scale study to evaluate the effectiveness of these models for helping engineers root cause and mitigate production incidents. We do a rigorous study at Microsoft, on more than 40,000 incidents and compare several large language models in zero-shot, fine-tuned and multi-task setting using semantic and lexical metrics. Lastly, our human evaluation with actual incident owners show the efficacy and future potential of using artificial intelligence for resolving cloud incidents.	[Ahmed, Toufique] Univ Calif Davis, Davis, CA 95616 USA; [Ghosh, Supriyo; Bansal, Chetan; Zimmermann, Thomas; Zhang, Xuchao; Rajmohan, Saravan] Microsoft, Supriyo Ghosh, Bangalore, Karnataka, India; [Zimmermann, Thomas] Microsoft Res, Thomas Zimmermann, Bellevue, WA USA	University of California System; University of California Davis; Microsoft	Ahmed, T (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.							Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Ahmed T., 2022, P 37 IEEEACM INT C A, P1; Ahmed T, 2022, PROC INT CONF SOFTW, P1443, DOI 10.1145/3510003.3510049; Alquraan A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P51; [Anonymous], 2008, US; Azad A. P., 2022, P AAAI C ARTIFICIAL, V36, p12 440; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Bansal C, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP), P201, DOI 10.1145/3377813.3381353; Bareiss P, 2022, Arxiv, DOI [arXiv:2206.01335, DOI 10.48550/ARXIV.2206.01335]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chakraborty Saikat, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P18, DOI 10.1145/3540250.3549162; Chen JJ, 2020, IEEE INT CONF AUTOM, P373, DOI 10.1145/3324884.3416624; Chen JJ, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P364, DOI 10.1109/ASE.2019.00042; Chen JJ, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P111, DOI 10.1109/ICSE-SEIP.2019.00020; Chen M., 2021, arXiv; Chen ZB, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1487, DOI 10.1145/3368089.3417055; Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Common Crawl, US; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Gao Y, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P539, DOI 10.1145/3236024.3236030; Ghosh S, 2022, PROCEEDINGS OF THE 13TH SYMPOSIUM ON CLOUD COMPUTING, SOCC 2022, P126, DOI 10.1145/3542929.3563482; github, COD COD TEXT; Gros D, 2020, IEEE INT CONF AUTOM, P746, DOI 10.1145/3324884.3416546; Guo D., 2020, INT C LEARNING REPRE; Haque S, 2022, Arxiv, DOI arXiv:2204.01632; HIRSCHBERG DS, 1977, J ACM, V24, P664, DOI 10.1145/322033.322044; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Jiang JJ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1410, DOI 10.1145/3368089.3417054; Joshi H, 2022, Arxiv, DOI arXiv:2208.11640; Kane H., 2020, NUBIA NEURAL BASED I; Kulkarni S, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P457; Leesatapornwongsa T, 2016, ACM SIGPLAN NOTICES, V51, P517, DOI 10.1145/2954679.2872374; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lin C.-Y., 2004, COLING 2004, P501, DOI DOI 10.3115/1220355.1220427; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu HP, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P155, DOI 10.1145/3317550.3321438; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu S., CodeXGLUE: A machine learning benchmark dataset for code understanding and generation; Luo C, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1583, DOI 10.1145/2623330.2623374; Nair V, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2029, DOI 10.1145/2783258.2788624; openfoam, ABOUT US; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Roy D, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1105, DOI 10.1145/3468264.3468588; Saha A., 2022, arXiv; Sellam T, 2020, Arxiv, DOI arXiv:2004.04696; Shia E., 2022, P 44 INT C SOFTWARE; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wolfe S, 2018, Amazon's one hour of downtime on Prime Day may have cost it up to $100 million in lost sales; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yuan Ding, 2014, 11 USENIX S OPERATIN, P249; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhang YL, 2021, PROCEEDINGS OF THE 28TH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, SOSP 2021, P116, DOI 10.1145/3477132.3483577	64	2	2	5	7	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0270-5257		978-1-6654-5701-9	PROC INT CONF SOFTW			2023							1737	1749		10.1109/ICSE48619.2023.00149	http://dx.doi.org/10.1109/ICSE48619.2023.00149			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JK		Green Submitted			2024-07-03	WOS:001032629800140
J	Hicks, MT; Humphries, J; Slater, J				Hicks, Michael Townsen; Humphries, James; Slater, Joe			ChatGPT is bullshit	ETHICS AND INFORMATION TECHNOLOGY			English	Article						Artificial intelligence; Large language models; LLMs; ChatGPT; Bullshit; Frankfurt; Assertion; Content		Recently, there has been considerable interest in large language models: machine learning systems which produce human-like text and dialogue. Applications of these systems have been plagued by persistent inaccuracies in their output; these are often called "AI hallucinations". We argue that these falsehoods, and the overall activity of large language models, is better understood as bullshit in the sense explored by Frankfurt (On Bullshit, Princeton, 2005): the models are in an important way indifferent to the truth of their outputs. We distinguish two ways in which the models can be said to be bullshitters, and argue that they clearly meet at least one of these definitions. We further argue that describing AI misrepresentations as bullshit is both a more useful and more accurate way of predicting and discussing the behaviour of these systems.	[Hicks, Michael Townsen; Humphries, James; Slater, Joe] Univ Glasgow, Glasgow, Scotland	University of Glasgow	Hicks, MT (corresponding author), Univ Glasgow, Glasgow, Scotland.	Michael.hicks@glasgow.ac.uk; James.Humphries@glasgow.ac.uk; Joe.Slater@glasgow.ac.uk		Hicks, Michael/0000-0002-1304-5668	University of Glasgow	University of Glasgow	Thanks to Neil McDonnell, Bryan Pickel, Fenner Tanswell, and the University of Glasgow's Large Language Model reading group for helpful discussion and comments.	Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Bacin S., 2021, Fichte's system of Ethics: A critical guide; Buss Sarah., 2002, Contours of Agency: Essays on Themes from Harry Frankfurt; Cassam Q., 2019, Vices of the Mind; Cohen GA, 2002, CONTOURS OF AGENCY, P321; Dennett D., 1987, INTENTIONAL STANCE; DENNETT DC, 1983, BEHAV BRAIN SCI, V6, P343, DOI 10.1017/S0140525X00016393; Easwaran K, 2023, ANAL PHILOS, DOI 10.1111/phib.12328; Edwards B., 2023, Ars Tecnica; Frankfurt HG, 2005, ON BULLSHIT, P1; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Knight W., 2023, WIRED; Levenstein B. A., Philosophical Studies, P1; Levy N., 2023, Philosophy, Bullshit, and peer review; Lightman H., 2023, PREPRINT; Lysandrou, 2023, PREPRINT; Macpherson F, 2013, HALLUCINATION: PHILOSOPHY AND PSYCHOLOGY, P1; Mahon J. E., 2016, The Stanford Encyclopedia of Philosophy; Mallory F, 2023, ERGO-ANN ARBOR, V10, P1082, DOI 10.3998/ergo.4668; Mandelkern M., 2023, PREPRINT; OpenAI, 2023, PREPRINT; Proops I, 2023, PAC PHILOS QUART, V104, P746, DOI 10.1111/papq.12442; Sarkar A., 2023, The Statesman; Shah C, 2022, CHIIR'22: PROCEEDINGS OF THE 2022 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P221, DOI 10.1145/3498366.3505816; Weise K., 2023, New York Times; Weiser B., 2023, New York Times; Whitcomb D, 2023, ANALYSIS-UK, V83, P299, DOI 10.1093/analys/anad002; Zhang, 2023, arXiv; Zhu T., 2023, Arxiv Preprint: arXiv, V2308, p17107v2	29	0	0	15	15	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	JUN	2024	26	2							38	10.1007/s10676-024-09775-5	http://dx.doi.org/10.1007/s10676-024-09775-5			10	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	TR8E3		hybrid			2024-07-03	WOS:001243070300002
J	Lin, HY; Voas, J				Lin, Hsiao-Ying; Voas, Jeffrey			Lower Energy Large Language Models (LLMs)	COMPUTER			English	Editorial Material								This message offers ideas about how to reduce the energy consumption associated with large language models.	[Lin, Hsiao-Ying] Huawei France, F-92100 Boulogne Billancourt, France	Huawei Technologies	Lin, HY (corresponding author), Huawei France, F-92100 Boulogne Billancourt, France.	hsiaoying.lin@gmail.com; j.voas@ieee.org							0	0	0	9	10	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	OCT	2023	56	10					14	16		10.1109/MC.2023.3278160	http://dx.doi.org/10.1109/MC.2023.3278160			3	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z9RY9		Bronze			2024-07-03	WOS:001115391700010
C	Gupta, R; Srinivasa, S			ACM	Gupta, Rajeev; Srinivasa, Srinath			Workshop on Enterprise Knowledge Graphs using Large Language Models	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Knowledge Graph; Large Language Model; Entity Extraction; Relationship Extraction; Recommendations		Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types-static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving -information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., - is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes-whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc.	[Gupta, Rajeev] Microsoft India Pvt Ltd, Microsoft Search Assistant & Intelligence, Hyderabad, India; [Srinivasa, Srinath] Indian Inst Informat Technol, Dept Comp Sc & Engg, Bengaluru, India	Microsoft	Gupta, R (corresponding author), Microsoft India Pvt Ltd, Microsoft Search Assistant & Intelligence, Hyderabad, India.	rajeev.gupta@microsoft.com; sri@iiitb.ac.in	Srinivasa, Srinath/AAT-8414-2020	Srinivasa, Srinath/0000-0001-9588-6550				Carta S, 2023, ARXIV230701128; Khorashadizadeh H, 2023, ARXIV230508804; Pan S., 2023, arXiv preprint arXiv:2306.08302; Trajanoska M, 2023, ARXIV230504676; Yang L, 2023, ARXIV230611489	5	0	0	15	15	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5271	5272		10.1145/3583780.3615301	http://dx.doi.org/10.1145/3583780.3615301			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549505067
J	Sharma, P; Parasa, S				Sharma, Prateek; Parasa, Sravanthi			ChatGPT and large language models in gastroenterology	NATURE REVIEWS GASTROENTEROLOGY & HEPATOLOGY			English	Editorial Material								In gastroenterology, ChatGPT and large language models (LLMs) can assist clinicians in various tasks but also have several shortcomings. Although LLMs have great potential to assist clinicians in health care, they should be used as a tool to support, rather than replace, human expertise.	[Sharma, Prateek] Univ Kansas, Sch Med, Kansas City, MO 64108 USA; [Sharma, Prateek] Vet Affairs Med Ctr, Kansas City, MO 64128 USA; [Parasa, Sravanthi] Swedish Med Ctr, Seattle, WA USA	University of Kansas; US Department of Veterans Affairs; Veterans Health Administration (VHA); Swedish Medical Center	Sharma, P (corresponding author), Univ Kansas, Sch Med, Kansas City, MO 64108 USA.; Sharma, P (corresponding author), Vet Affairs Med Ctr, Kansas City, MO 64128 USA.	psharma@kumc.edu						Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Clynch N, 2015, INT J MED INFORM, V84, P221, DOI 10.1016/j.ijmedinf.2014.12.001; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Friedman B, 2013, PHILOS ENG TECHNOL, V16, P55, DOI 10.1007/978-94-007-7844-3_4; Lahav D, 2022, AAAI CONF ARTIF INTE, P11982; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Nori H., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2303.13375; Sai AB, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3485766	8	9	9	7	32	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1759-5045	1759-5053		NAT REV GASTRO HEPAT	Nat. Rev. Gastroenterol. Hepatol.	AUG	2023	20	8					481	482		10.1038/s41575-023-00799-8	http://dx.doi.org/10.1038/s41575-023-00799-8		MAY 2023	2	Gastroenterology & Hepatology	Science Citation Index Expanded (SCI-EXPANDED)	Gastroenterology & Hepatology	M8EH1	37253794				2024-07-03	WOS:000998059100001
C	Lin, E; Hale, J; Gratch, J			ACM	Lin, Eleanor; Hale, James; Gratch, Jonathan			Toward a Better Understanding of the Emotional Dynamics of Negotiation with Large Language Models	PROCEEDINGS OF THE 2023 INTERNATIONAL SYMPOSIUM ON THEORY, ALGORITHMIC FOUNDATIONS, AND PROTOCOL DESIGN FOR MOBILE NETWORKS AND MOBILE COMPUTING, MOBIHOC 2023			English	Proceedings Paper	International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (ACM MobiHoc)	OCT 23-26, 2023	Washington, DC	Assoc Comp Machinery, ACM SIGMOBILE		Negotiation; Large Language Models; Emotion		Current approaches to building negotiation agents rely either on model-based techniques that explicitly implement key principles of negotiation or model-free techniques leveraging algorithms developed via training on large amounts of human-generated text. We bridge these two approaches by combining a model-based approach with large language models for natural language understanding and generation. We find large language models perform well at recognizing dialogue acts and an opponent's emotions; perform reasonably well at recognizing opponents' preferences in the negotiation; and perform worse at understanding opponent offers. We also perform a qualitative comparison of the capabilities of our hybrid approach with a model-free method and find our hybrid agent provides safeguards against hallucinations and guarantees more control over aspects of negotiation such as emotional expressions, information sharing, and concession strategies.	[Lin, Eleanor] Columbia Univ, New York, NY 10025 USA; [Hale, James; Gratch, Jonathan] Univ Southern Calif, Los Angeles, CA 90007 USA	Columbia University; University of Southern California	Lin, E (corresponding author), Columbia Univ, New York, NY 10025 USA.	eml2221@columbia.edu; jahale@usc.edu; gratch@ict.usc.edu			National Science Foundation [2150187]; Army Research Office [W911NF-20-2-0053]	National Science Foundation(National Science Foundation (NSF)); Army Research Office	This material is based upon work supported by the National Science Foundation under Grant No. 2150187. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.; This work is also supported by the Army Research Office under Cooperative Agreement Number W911NF-20-2-0053. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the Army Research Office or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; DeVault David, 2015, 2015 AAAI Spring Symposium Series, P2; Eleti Atty, 2023, Function calling and other api updates; Goldman J, 2014, ACM SIGECOM EXCH, V13, P41; Gratch J, 2023, PHILOS T R SOC B, V378, DOI 10.1098/rstb.2021.0475; Gratch J, 2015, LECT NOTES ARTIF INT, V9238, P201, DOI 10.1007/978-3-319-21996-7_21; Hindriks K., 2009, P 8 INT C AUTONOMOUS, V2, P1397; Hindriks Koen., 2008, P 7 INT JOINT C AUTO, V1, P331, DOI DOI 10.5555/1402383.1402433; iDecisionGames, 2023, About us; Lewis M, 2017, Arxiv, DOI arXiv:1706.05125; Li Y., 2017, P 8 INT JOINT C NATU, P986; Mell J, 2017, AAMAS'17: PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P401; Min Bonan, 2023, ACM Comput. Surv., DOI [10.1145/3605943JustAccepted, DOI 10.1145/3605943JUSTACCEPTED]; Nazari Z, 2015, LECT NOTES ARTIF INT, V9238, P39, DOI 10.1007/978-3-319-21996-7_4; OpenAI, 2023, How to format inputs to ChatGPT models; OpenAI, 2023, GPT-3.5; Simulation Labs, 2023, About us; Sun XF, 2023, Arxiv, DOI [arXiv:2305.08377, DOI 10.48550/ARXIV.2305.08377]; Thiessen EM, 2003, GROUP DECIS NEGOT, V12, P165, DOI 10.1023/A:1023025106197; van Kleef GA, 2018, ANNU REV ORGAN PSYCH, V5, P437, DOI 10.1146/annurev-orgpsych-032117-104714; Zhang MR, 2023, Arxiv, DOI arXiv:2305.13534; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	22	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9926-5				2023							545	550		10.1145/3565287.3617637	http://dx.doi.org/10.1145/3565287.3617637			6	Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2UG					2024-07-03	WOS:001125985600079
J	Webb, T; Holyoak, KJ; Lu, HJ				Webb, Taylor; Holyoak, Keith J.; Lu, Hongjing			Emergent analogical reasoning in large language models	NATURE HUMAN BEHAVIOUR			English	Article							RELATIONAL COMPLEXITY; INTELLIGENCE; SIMILARITY	Webb et al. show that new artificial intelligence language models, such as Generative Pre-trained Transformer 3, are able to solve analogical reasoning problems at a human-like level of performance. The recent advent of large language models has reinvigorated debate over whether human cognitive capacities might emerge in such generic models given sufficient training data. Of particular interest is the ability of these models to reason about novel problems zero-shot, without any direct training. In human cognition, this capacity is closely tied to an ability to reason by analogy. Here we performed a direct comparison between human reasoners and a large language model (the text-davinci-003 variant of Generative Pre-trained Transformer (GPT)-3) on a range of analogical tasks, including a non-visual matrix reasoning task based on the rule structure of Raven's Standard Progressive Matrices. We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings; preliminary tests of GPT-4 indicated even better performance. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.	[Webb, Taylor; Holyoak, Keith J.; Lu, Hongjing] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA; [Lu, Hongjing] Univ Calif Los Angeles, Dept Stat, Los Angeles 90095, CA USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Webb, T (corresponding author), Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA.	taylor.w.webb@gmail.com		Webb, Taylor/0000-0002-1335-3177; Holyoak, Keith/0000-0001-8010-6267	NSF [IIS-1956441]; AFOSR MURI [FA9550-22-1-0380]	NSF(National Science Foundation (NSF)); AFOSR MURI(United States Department of DefenseAir Force Office of Scientific Research (AFOSR)MURI)	AcknowledgementsWe thank B. Snefjella and P. Turney for helpful feedback and discussions. Preparation of this paper was supported by NSF grant IIS-1956441 and AFOSR MURI grant FA9550-22-1-0380 to H.L. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.	Barrett DGT, 2018, PR MACH LEARN RES, V80; Bassok Miriam, 2012, Oxford Handbook of Thinking and Reasoning, P413; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; CARPENTER PA, 1990, PSYCHOL REV, V97, P404, DOI 10.1037/0033-295X.97.3.404; Cattell R. B., 1971, ABILITIES THEIR STRU; Chalmers D. J., 1992, Journal of Experimental and Theoretical Artificial Intelligence, V4, P185, DOI 10.1080/09528139208953747; Chan SC., 2022, Advances in Neural Information Processing Systems, V35, P18878; Chen Mark., 2021, EVALUATING LARGE LAN, P2021, DOI [DOI 10.48550/ARXIV.2107.03374, 10.48550/ARXIV.2107.03374]; Cohen J, 2020, INT C MACHINE LEARNI, P10136; Dasgupta I., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2207.07051; de Leeuw JR, 2015, BEHAV RES METHODS, V47, P1, DOI 10.3758/s13428-014-0458-y; Dunbar K. N., 2012, The Cambridge handbook of thinking and reasoning, P701, DOI https://doi.org/10.1093/oxfordhb/9780199734689.013.0035; Duncker K, 1945, PSYCHOL MONOGR, V58, P1; FALKENHAINER B, 1989, ARTIF INTELL, V41, P1, DOI 10.1016/0004-3702(89)90077-5; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3; GICK ML, 1980, COGNITIVE PSYCHOL, V12, P306, DOI 10.1016/0010-0285(80)90013-4; Greff K., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2012.05208; Griffiths TL, 2020, TRENDS COGN SCI, V24, P873, DOI 10.1016/j.tics.2020.09.001; Halford GS, 1998, BEHAV BRAIN SCI, V21, P803, DOI 10.1017/S0140525X98001769; Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2; Hersche M, 2023, NAT MACH INTELL, V5, P363, DOI 10.1038/s42256-023-00630-8; Hill F., 2019, 7 INT C LEARN REPR I; Hofstadter D.R., 1994, ADV CON NEUR COMP TH, V2, P31; Hofstadter D. R., 1995, FLUID CONCEPTS CREAT; HOLYOAK KJ, 1984, CHILD DEV, V55, P2042, DOI 10.1111/j.1467-8624.1984.tb03901.x; HOLYOAK KJ, 1987, MEM COGNITION, V15, P332, DOI 10.3758/BF03197035; Holyoak KJ, 2000, COGNITIVE DYNAMICS, P229; Holyoak KJ, 2012, The Oxford handbook of thinking and reasoning, DOI [DOI 10.1093/OXFORDHB/9780199734689.001.0001, 10.1093/oxfordhb/9780199734689.013.0013, DOI 10.1093/OXFORDHB/9780199734689.013.0013]; Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55; Ichien N, 2020, BEHAV RES METHODS, V52, P1803, DOI 10.3758/s13428-019-01312-3; Jones LL, 2022, PSYCHON B REV, V29, P1480, DOI 10.3758/s13423-022-02062-8; Kojima T., 2022, Advances in neural information processing systems, V35, P22199, DOI DOI 10.48550/ARXIV.2205.11916; Kriete T, 2013, P NATL ACAD SCI USA, V110, P16390, DOI 10.1073/pnas.1303547110; Kroger JK, 2004, COGNITIVE SCI, V28, P335, DOI 10.1016/j.cogsci.2003.06.003; Lake BM, 2017, BEHAV BRAIN SCI, V40, DOI 10.1017/S0140525X16001837; Lovett A, 2017, PSYCHOL REV, V124, P60, DOI 10.1037/rev0000039; Lu HJ, 2022, PSYCHOL REV, V129, P1078, DOI 10.1037/rev0000358; Lu HJ, 2019, P NATL ACAD SCI USA, V116, P4176, DOI 10.1073/pnas.1814779116; Mahowald K., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2301.06627; Marcus G., 2001, The Algebraic Mind: Integrating Connectionism and Cognitive Science; MARKMAN AB, 1993, COGNITIVE PSYCHOL, V25, P431, DOI 10.1006/cogp.1993.1011; Matlen BJ, 2020, J EXP PSYCHOL HUMAN, V46, P443, DOI 10.1037/xhp0000726; Matzen LE, 2010, BEHAV RES METHODS, V42, P525, DOI 10.3758/BRM.42.2.525; McClelland JL, 2020, P NATL ACAD SCI USA, V117, P25966, DOI 10.1073/pnas.1910416117; Mitchell M., 1993, ANALOGY MAKING PERCE; Mitchell M, 2021, ANN NY ACAD SCI, V1505, P79, DOI 10.1111/nyas.14619; NEWELL A, 1958, PSYCHOL REV, V65, P151, DOI 10.1037/h0048495; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Ouyang L., 2022, NEURIPS; Penn DC, 2008, BEHAV BRAIN SCI, V31, P109, DOI 10.1017/S0140525X08003543; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Raven J. C., 1938, Progressive matrices; Seabold S., 2010, 9 PYTH SCI C, DOI [10.25080/Majora-92bf1922-011, DOI 10.25080/MAJORA-92BF1922-011, 10.25080/MAJORA-92BF1922-011]; SMOLENSKY P, 1990, ARTIF INTELL, V46, P159, DOI 10.1016/0004-3702(90)90007-M; Snow R. E., 1984, Advances in the psychology of human intelligence, V2, P47; Srivastava A., 2023, Transactions on Machine Learning Research; STERNBERG RJ, 1980, CHILD DEV, V51, P27, DOI 10.2307/1129586; Subhra Mondal S., 2023, 11 INT C LEARN REPR; Turney P. D., 2003, P INT C REC ADV NAT, P482; Turney PD, 2005, MACH LEARN, V60, P251, DOI 10.1007/s10994-005-0913-1; Vaswani A, 2017, ADV NEUR IN, V30; Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2; WASON PC, 1968, Q J EXP PSYCHOL, V20, P273, DOI 10.1080/14640746808400161; Webb T. W., 2021, 9 INT C LEARNING REP; Webb T. W., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2209.15087; Wei JH, 2022, PR MACH LEARN RES; Wu Y., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2007.04212; Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546	69	28	30	57	84	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	SEP	2023	7	9					1526	1541		10.1038/s41562-023-01659-w	http://dx.doi.org/10.1038/s41562-023-01659-w		JUL 2023	16	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	S4LN7	37524930	Green Submitted			2024-07-03	WOS:001040224100002
J	Grm, K				Grm, Klemen			Evaluating the capabilities of large language models using machine learning tasks at inference-time	ELEKTROTEHNISKI VESTNIK			Slovenian	Article						language models; machine learning; evaluation methodology		Machine learning is the domain of algorithms capable of learning from data to improve their performance on a task or set of tasks. Common machine learning tasks include classification, regression, and generative modelling. The most common modern example of machine learners in practical use is deep neural networks coupled with an extrinsic optimizer such as stochastic gradient descent. Recently, scaled-up large language models have shown increasing capabilities of in-context meta-learning, which has been used to improve their performance on language tasks through few-shot learning. In this paper, we show that pre-trained large language models can act as machine learners with regard to in-context data, without using extrinsic optimization tools or weight updates. By evaluating the language models' inference time machine learning abilities on synthetic or appropriately transformed datasets, we conclusively show that they're able to model complex relationships between data in the input context. This implies that inference-time machine learning tasks represent a meaningful capability evaluation task for large language models.	[Grm, Klemen] Univ Ljubljani, Fak Elektrotehniko, Trzaska Cesta 25, Ljubljana 1000, Slovenia	University of Ljubljana	Grm, K (corresponding author), Univ Ljubljani, Fak Elektrotehniko, Trzaska Cesta 25, Ljubljana 1000, Slovenia.	klemen.grm@fe.uni-lj.si						Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, P ADV NEUR INF PROC, P1877; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burns C., 2022, arXiv; Chen M., 2021, arXiv; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x; Gage P., 1994, C Users Journal, V12, P23; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Kocijan V, 2023, ARTIF INTELL-AMST, V325, DOI 10.1016/j.artint.2023.103971; Mostafazadeh N, 2016, Arxiv, DOI arXiv:1604.01696; OpenAI, 2023, GPT-4 Technical Report; Paperno Denis, 2016, arXiv; Patel J. M, 2020, Introduction to Common Crawl Datasets, P277; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Peng B, 2023, Arxiv, DOI arXiv:2305.13048; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wei JH, 2022, PR MACH LEARN RES	28	0	0	3	3	ELECTROTECHNICAL SOC SLOVENIA	LJUBLJANA	TRZASKA 25, BOX 92-II, LJUBLJANA, 1001, SLOVENIA	0013-5852	2232-3236		ELEKTROTEH VESTN	Elektroteh. Vestn.		2023	90	5					247	253						7	Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Engineering	IF1Q1					2024-07-03	WOS:001164824700003
J	Sabbatella, A; Ponti, A; Giordani, I; Candelieri, A; Archetti, F				Sabbatella, Antonio; Ponti, Andrea; Giordani, Ilaria; Candelieri, Antonio; Archetti, Francesco			Prompt Optimization in Large Language Models	MATHEMATICS			English	Article						Bayesian Optimization; prompt optimization; black-box Large Language Models		Prompt optimization is a crucial task for improving the performance of large language models for downstream tasks. In this paper, a prompt is a sequence of n-grams selected from a vocabulary. Consequently, the aim is to select the optimal prompt concerning a certain performance metric. Prompt optimization can be considered as a combinatorial optimization problem, with the number of possible prompts (i.e., the combinatorial search space) given by the size of the vocabulary (i.e., all the possible n-grams) raised to the power of the length of the prompt. Exhaustive search is impractical; thus, an efficient search strategy is needed. We propose a Bayesian Optimization method performed over a continuous relaxation of the combinatorial search space. Bayesian Optimization is the dominant approach in black-box optimization for its sample efficiency, along with its modular structure and versatility. We use BoTorch, a library for Bayesian Optimization research built on top of PyTorch. Specifically, we focus on Hard Prompt Tuning, which directly searches for an optimal prompt to be added to the text input without requiring access to the Large Language Model, using it as a black-box (such as for GPT-4 which is available as a Model as a Service). Albeit preliminary and based on "vanilla" Bayesian Optimization algorithms, our experiments with RoBERTa as a large language model, on six benchmark datasets, show good performances when compared against other state-of-the-art black-box prompt optimization methods and enable an analysis of the trade-off between the size of the search space, accuracy, and wall-clock time.	[Sabbatella, Antonio; Archetti, Francesco] Univ Milano Bicocca, Dept Comp Sci Syst & Commun, I-20126 Milan, Italy; [Ponti, Andrea; Candelieri, Antonio] Univ Milano Bicocca, Dept Econ Management & Stat, I-20126 Milan, Italy; [Giordani, Ilaria] Oaks srl, I-20125 Milan, Italy	University of Milano-Bicocca; University of Milano-Bicocca	Candelieri, A (corresponding author), Univ Milano Bicocca, Dept Econ Management & Stat, I-20126 Milan, Italy.	a.sabbatella@campus.unimib.it; a.ponti5@campus.unimib.it; giordani@oaks.cloud; antonio.candelieri@unimib.it; francesco.archetti@unimib.it		Ponti, Andrea/0000-0003-4187-4209				Balandat M., 2020, ADV NEURAL INFORM PR, P21524, DOI DOI 10.48550/ARXIV.1910.06403; Chai Y., 2022, arXiv; Chen LC, 2023, Arxiv, DOI arXiv:2306.03082; Dale E, 1948, EDUC RES BULL, V27, P37; de Curtò J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12132814; Deng MK, 2022, Arxiv, DOI arXiv:2205.12548; Diao SZ, 2022, Arxiv, DOI arXiv:2201.08531; Francesco Archetti AC., 2019, BAYESIAN OPTIMIZATIO; Garnett R., 2023, BAYESIAN OPTIMIZATIO; Gunning T, 2014, CRIT INQUIRY, V40, P36, DOI 10.1086/677328; Guo QY, 2024, Arxiv, DOI arXiv:2309.08532; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu T, 2024, Arxiv, DOI arXiv:2402.03921; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Maus N., 2023, 2 WORKSHOP NEW FRONT; Prasad A, 2023, Arxiv, DOI arXiv:2203.07281; Pryzant R, 2023, Arxiv, DOI arXiv:2305.03495; Sabbatella A, 2023, Arxiv, DOI arXiv:2312.00471; Shen MH, 2023, Arxiv, DOI arXiv:2305.00593; Shi W., 2022, arXiv; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Sun T., 2022, PROC EMNLP, P3916; Sun T., 2022, PROC ICML, P20841; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wei JS, 2022, ADV NEUR IN; Wen YX, 2023, Arxiv, DOI arXiv:2302.03668; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zhang T., 2022, P 11 INT C LEARNING; Zhong ZX, 2021, Arxiv, DOI arXiv:2104.05240	32	0	0	19	19	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	MAR	2024	12	6							929	10.3390/math12060929	http://dx.doi.org/10.3390/math12060929			14	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	MG7D6		gold			2024-07-03	WOS:001192529200001
C	Lanzi, PL; Loiacono, D		Paquete, L		Lanzi, Pier Luca; Loiacono, Daniele			ChatGPT and Other Large Language Models as Evolutionary Engines for Online Interactive Collaborative Game Design	PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, GECCO 2023			English	Proceedings Paper	Genetic and Evolutionary Computation Conference (GECCO)	JUL 15-19, 2023	Lisbon, PORTUGAL	Assoc Comp Machinery, ACM, Special Interest Grp Genet & Evolutionary Computat		Collaborative Design; Large Language Models; Interactive Evolution		Large language models (LLMs) have taken the scienti.c world by storm, changing the landscape of natural language processing and human-computer interaction. These powerful tools can answer complex questions and, surprisingly, perform challenging creative tasks (e.g., generate code and applications to solve problems, write stories, pieces of music, etc.). In this paper, we present a collaborative game design framework that combines interactive evolution and large language models to simulate the typical human design process. We use the former to exploit users' feedback for selecting the most promising ideas and large language models for a very complex creative task-the recombination and variation of ideas. In our framework, the process starts with a brief and a set of candidate designs, either generated using a language model or proposed by the users. Next, users collaborate on the design process by providing feedback to an interactive genetic algorithm that selects, recombines, and mutates the most promising designs. We evaluated our framework on three game design tasks with human designers who collaborated remotely.	[Lanzi, Pier Luca; Loiacono, Daniele] Politecn Milan, Milan, Italy	Polytechnic University of Milan	Lanzi, PL (corresponding author), Politecn Milan, Milan, Italy.	pierluca.lanzi@polimi.it; daniele.loiacono@polimi.it	Loiacono, Daniele/AAB-9829-2019	Loiacono, Daniele/0000-0002-5355-0634; Lanzi, Pier Luca/0000-0002-1933-7717				Anaraki NAT, 2017, LECT NOTES COMPUT SC, V10198, P289, DOI 10.1007/978-3-319-55750-2_20; [Anonymous], 2010, Gamestorming: A playbook for innovators, rulebreakers, and changemakers; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bontrager P, 2018, LECT NOTES COMPUT SC, V10783, P267, DOI 10.1007/978-3-319-77583-8_18; Brintrup AM, 2008, IEEE T EVOLUT COMPUT, V12, P343, DOI 10.1109/TEVC.2007.904343; Brown Andrew R., 2018, 18 INT C NEW INTERFA, P19; Cardamone L, 2015, APPL SOFT COMPUT, V28, P550, DOI 10.1016/j.asoc.2014.11.010; Cardamone L, 2011, GECCO-2011: PROCEEDINGS OF THE 13TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P395; Chen M., 2021, arXiv; Chen M, 2020, PR MACH LEARN RES, V119; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Dawkins R., 1986, The Blind Watchmaker: Why the Evidence of Evolution Reveals a Universe Without Design; Ebner M, 2005, LECT NOTES COMPUT SC, V3447, P261; Frans K, 2021, IEEE CONF COMPU INTE, P876, DOI 10.1109/COG52621.2021.9619126; Giacomello Edoardo, 2019, IEEE CONF COMPU INTE, P1; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Hastings EJ, 2009, IEEE T COMP INTEL AI, V1, P245, DOI 10.1109/TCIAIG.2009.2038365; Hoover AK, 2011, GECCO-2011: PROCEEDINGS OF THE 13TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P387; Hoover AK, 2009, CONNECT SCI, V21, P227, DOI 10.1080/09540090902733871; Hornby GS, 2012, PROCEEDINGS OF THE FOURTEENTH INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P225, DOI 10.1145/2330163.2330196; Howlett Andrew, 2010, P 3 INT S GAMES S AI, P41; Khan S, 2019, OCEAN ENG, V191, DOI 10.1016/j.oceaneng.2019.106462; Kim Hee-Su, 2005, Fashion Design Using Interactive Genetic Algorithm with Knowledge-based Encoding, P411, DOI DOI 10.1007/978-3-540-44511-1_19; Kim HS, 2000, ENG APPL ARTIF INTEL, V13, P635, DOI 10.1016/S0952-1976(00)00045-2; Kowaliw T., 2011, 2011 IEEE SSCI Symposium on Artificial Life (ALIFE), P162, DOI 10.1109/ALIFE.2011.5954645; Kowaliw T, 2012, IEEE T EVOLUT COMPUT, V16, P523, DOI 10.1109/TEVC.2011.2166764; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; Lanzi PL, 2023, Arxiv, DOI arXiv:2303.02155; Loiacono Daniele, 2015, 2015 IEEE Games Entertainment Media Conference (GEM), P1, DOI 10.1109/GEM.2015.7377226; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Mirowski P., 2022, arXiv; Mok PY, 2013, COMPUT AIDED DESIGN, V45, P1442, DOI 10.1016/j.cad.2013.06.014; Myers David, 2009, P 2009 DIGRA INT C B; Nealen A, 2011, P 6 INT C FDN DIG GA, P38, DOI DOI 10.1145/2159365.2159371; NORMAN D, 2013, DESIGN EVERYDAY THIN; Olsted PT, 2015, IEEE C EVOL COMPUTAT, P1527, DOI 10.1109/CEC.2015.7257069; OpenAI, 2021, CHATGPT GEN PRETR TR; OpenAI, 2022, DALL E 2; Polu S, 2020, Arxiv, DOI arXiv:2009.03393; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Risi Sebastian, 2012, Combining Search-Based Procedural Content Generation and Social Gaming in the Petalz Video Game; Schrum J, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P148, DOI 10.1145/3377930.3389821; Secretan J, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1759; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Takagi H, 2001, P IEEE, V89, P1275, DOI 10.1109/5.949485; Telegram FZ LLC and Telegram Messenger Inc, 2023, US; van Stegeren J, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES, FDG 2021, DOI 10.1145/3472538.3472595; Vartinen S, 2024, IEEE T GAMES, V16, P127, DOI 10.1109/TG.2022.3228480; Volz V, 2018, GECCO'18: PROCEEDINGS OF THE 2018 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P221, DOI 10.1145/3205455.3205517; Wang TX, 2020, INT J IND ERGONOM, V76, DOI 10.1016/j.ergon.2019.102901; Wikipedia, 2022, DES BRIEF; Woolley BG, 2014, GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P233, DOI 10.1145/2576768.2598353; Xu B, 2010, IEEE C EVOL COMPUTAT; Yannakakis GN, 2011, IEEE T AFFECT COMPUT, V2, P147, DOI 10.1109/T-AFFC.2011.6; Zhu QH, 2022, Arxiv, DOI [arXiv:2204.09658, 10.48550/ARXIV.2204.09658, DOI 10.48550/ARXIV.2204.09658]	55	1	1	8	23	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0119-1				2023							1383	1390		10.1145/3583131.3590351	http://dx.doi.org/10.1145/3583131.3590351			8	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4HS		Green Submitted, Bronze			2024-07-03	WOS:001031455100154
C	Jain, N; Vaidyanath, S; Iyer, A; Natarajan, N; Parthasarathy, S; Rajamani, S; Sharma, R			IEEE Comp Soc	Jain, Naman; Vaidyanath, Skanda; Iyer, Arun; Natarajan, Nagarajan; Parthasarathy, Suresh; Rajamani, Sriram; Sharma, Rahul			Jigsaw: Large Language Models meet Program Synthesis	2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2022)	International Conference on Software Engineering		English	Proceedings Paper	ACM/IEEE 44th International Conference on Software Engineering (ICSE)	MAY 22-27, 2022	Pittsburgh, PA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, Assoc Comp Machinery, Special Interest Grp Software Engn				Large pre-trained language models such as GPT-3 [10], Codex [11], and Google's language model [7] are now capable of generating code from natural language specifications of programmer intent. We view these developments with a mixture of optimism and caution. On the optimistic side, such large language models have the potential to improve productivity by providing an automated AI pair programmer for every programmer in the world. On the cautionary side, since these large language models do not understand program semantics, they offer no guarantees about quality of the suggested code. In this paper, we present an approach to augment these large language models with post-processing steps based on program analysis and synthesis techniques, that understand the syntax and semantics of programs. Further, we show that such techniques can make use of user feedback and improve with usage. We present our experiences from building and evaluating such a tool Jigsaw, targeted at synthesizing code for using Python Pandas API using multi-modal inputs. Our experience suggests that as these large language models evolve for synthesizing code from intent, Jigsaw has an important role to play in improving the accuracy of the systems.	[Jain, Naman; Vaidyanath, Skanda; Iyer, Arun; Natarajan, Nagarajan; Parthasarathy, Suresh; Rajamani, Sriram; Sharma, Rahul] Microsoft Res, Bangalore, Karnataka, India; [Vaidyanath, Skanda] Stanford Univ, Stanford, CA 94305 USA	Microsoft; Stanford University	Jain, N (corresponding author), Microsoft Res, Bangalore, Karnataka, India.	t-namanjain@microsoft.com; svaidyan@stanford.edu; ariy@microsoft.com; nagarajn@microsoft.com; supartha@microsoft.com; sriram@microsoft.com; rahsha@microsoft.com						[Anonymous], PARENTHESIS BLOG; [Anonymous], YOUR AI PAIR PROGR; [Anonymous], About Us; [Anonymous], 2013, PROCEEDINGS; [Anonymous], PARENTHESIS STACKOVE; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Balog Matej, 2017, INT C LEARNING REPRE; Bavishi R, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360594; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Chen QC, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P328, DOI 10.1145/3453483.3454047; Chen QC, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P487, DOI 10.1145/3385412.3385988; Chen YJ, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P602, DOI 10.1145/3338906.3338951; Clement CB, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P9052; Devlin J, 2017, PR MACH LEARN RES, V70; DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6; Feng Y, 2018, PROCEEDINGS OF THE 39TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, PLDI 2018, P420, DOI [10.1145/3296979.3192382, 10.1145/3192366.3192382]; Gulwani S, 2016, NATO SCI PEAC SECUR, V45, P137, DOI 10.3233/978-1-61499-627-9-137; He YY, 2018, PROC VLDB ENDOW, V11, P1165, DOI 10.14778/3231751.3231766; Kalyan Ashwin, 2018, INT C LEARN REPR ICL; Lee W, 2018, ACM SIGPLAN NOTICES, V53, P436, DOI [10.1145/3192366.3192410, 10.1145/3296979.3192410]; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Menon Aditya, 2013, INT C MACHINE LEARNI, P187; Miltner Anders, 2019, OBJECT ORIENTED PROG; Parisotto E., 2017, INT C LEARN REPR; Pearce H, 2021, Arxiv, DOI arXiv:2108.09293; Perez Ethan, 2021, arXiv; Poesia Gabriel, 2022, INT C LEARNING REPRE; Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]; Radford A., 2019, OpenAI Blog; Rahmani Kia, 2021, OOPSLA; Raychev V, 2014, ACM SIGPLAN NOTICES, V49, P419, DOI [10.1145/2594291.2594321, 10.1145/2666356.2594321]; Raza M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P792; Reimers Nils, 2019, SENTENCE BERT SENTEN; Rolim R, 2016, Arxiv, DOI arXiv:1608.09000; Rubin O, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P311; Shi Kensen, 2020, ARXIV; Singh R, 2015, LECT NOTES COMPUT SC, V9206, P398, DOI 10.1007/978-3-319-21690-4_23; TensorFlow, about us; The pandas development team, 2020, PANDAS DEVPANDAS PAN, DOI [DOI 10.5281/ZENODO.3509134, 10.5281/zenodo.3509134]; Wang B., 2020, P 58 ANN M ASS COMPU, P7567; Ye X, 2020, Arxiv, DOI arXiv:1908.05848; Yifan Wu, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P152, DOI 10.1145/3379337.3415851; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911; Zhao Tony Z., 2021, INT C MACHINE LEARNI	45	30	35	6	28	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0270-5257		978-1-4503-9221-1	PROC INT CONF SOFTW			2022							1219	1231		10.1145/3510003.3510203	http://dx.doi.org/10.1145/3510003.3510203			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT4NG					2024-07-03	WOS:000832185400099
C	Liu, ZL; Zhong, AX; Li, Y; Yang, LT; Ju, C; Wu, ZH; Ma, C; Shu, P; Chen, C; Kim, SK; Dai, HX; Zhao, L; Zhu, DJ; Liu, J; Liu, W; Shen, DG; Li, QZ; Liu, TM; Li, X		Cao, X; Xu, X; Rekik, I; Cui, Z; Ouyang, X		Liu, Zhengliang; Zhong, Aoxiao; Li, Yiwei; Yang, Longtao; Ju, Chao; Wu, Zihao; Ma, Chong; Shu, Peng; Chen, Cheng; Kim, Sekeun; Dai, Haixing; Zhao, Lin; Zhu, Dajiang; Liu, Jun; Liu, Wei; Shen, Dinggang; Li, Quanzheng; Liu, Tianming; Li, Xiang			Tailoring Large Language Models to Radiology: A Preliminary Approach to LLM Adaptation for a Highly Specialized Domain	MACHINE LEARNING IN MEDICAL IMAGING, MLMI 2023, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	14th International Workshop on Machine Learning in Medical Imaging (MLMI)	OCT 08, 2023	Vancouver, CANADA			Large Language Models; Natural Language Processing; Radiology		In this preliminary work, we present a domain fine-tuned LLM model for radiology, an experimental large language model adapted for radiology. This model, created through an exploratory application of instruction tuning on a comprehensive dataset of radiological information, demonstrates promising performance when compared with broader language models such as StableLM, Dolly, and LLaMA. This model exhibits initial versatility in applications related to radiological diagnosis, research, and communication. Our work contributes an early but encouraging step towards the evolution of clinical NLP by implementing a large language model that is local and domain-specific, conforming to stringent privacy norms like HIPAA. The hypothesis of creating customized, large-scale language models catering to distinct requirements of various medical specialties, presents a thought-provoking direction. The blending of conversational prowess and specific domain knowledge in these models kindles hope for future enhancements in healthcare AI. While it is still in its early stages, the potential of generative large language models is intriguing and worthy of further exploration. The demonstration code of our domain fine-tuned LLM model for radiology can be accessed at https://anonymous.4open.science/r/radiology-llm-demo-C3E2/.	[Li, Yiwei; Wu, Zihao; Shu, Peng; Dai, Haixing; Zhao, Lin; Liu, Tianming] Univ Georgia, Sch Comp, Athens, GA 30602 USA; [Zhong, Aoxiao] Harvard Univ, Dept Elect Engn, Cambridge, MA 02138 USA; [Yang, Longtao; Ju, Chao; Ma, Chong; Liu, Jun] Northwestern Polytech Univ, Sch Automat, Xian, Peoples R China; [Chen, Cheng; Kim, Sekeun; Li, Quanzheng; Li, Xiang] Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02114 USA; [Chen, Cheng; Kim, Sekeun; Li, Quanzheng; Li, Xiang] Harvard Med Sch, Boston, MA 02115 USA; [Zhu, Dajiang] Univ Texas Arlington, Dept Comp Sci & Engn, Arlington, TX 76019 USA; [Liu, Wei] Mayo Clin, Dept Radiat Oncol, Phoenix, AZ USA; [Shen, Dinggang] ShanghaiTech Univ, Sch Biomed Engn, Pudong, Peoples R China; [Shen, Dinggang] Shanghai United Imaging Intelligence Co Ltd, Shanghai, Peoples R China; [Shen, Dinggang] Shanghai Clin Res & Trial Ctr, Shanghai, Peoples R China	University System of Georgia; University of Georgia; Harvard University; Northwestern Polytechnical University; Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School; University of Texas System; University of Texas Arlington; Mayo Clinic; Mayo Clinic Phoenix; ShanghaiTech University	Li, X (corresponding author), Massachusetts Gen Hosp, Dept Radiol, Boston, MA 02114 USA.; Li, X (corresponding author), Harvard Med Sch, Boston, MA 02115 USA.	xli60@mgh.harvard.edu	Li, Xiang/J-6924-2019; Liu, Tianming/GLS-1211-2022	Li, Xiang/0000-0002-9851-6376; Liu, Tianming/0000-0003-0942-6748				Alhendawi K., 2013, J. Comput. Sci. Manag.; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Dai H, arXiv; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Demner-Fushman D, 2016, J AM MED INFORM ASSN, V23, P304, DOI 10.1093/jamia/ocv080; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dolly Free, Introducing the World's First Truly Open Instruction-Tuned LLM; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu JP, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4980; Islamovic A, Stability AI Launches the First of its StableLM Suite of Language Models-Stability AI; Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0; Liao WX, 2023, Arxiv, DOI [arXiv:2304.11567, 10.48550/ARXIV.2304.11567, DOI 10.48550/ARXIV.2304.11567]; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu Z, 2022, Yi xue ban J. Central South Univ. Med. Sci., V47, P981; Liu ZL, 2023, Arxiv, DOI arXiv:2301.12031; Liu ZL, 2023, Arxiv, DOI arXiv:2303.11032; Ma C, 2024, Arxiv, DOI arXiv:2304.08448; OpenAI R, 2023, arXiv; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rezayi S, 2022, LECT NOTES COMPUT SC, V13583, P269, DOI 10.1007/978-3-031-21014-3_28; Sonn GA, 2019, EUR UROL FOCUS, V5, P592, DOI 10.1016/j.euf.2017.11.010; Stanford CRFM, ABOUT US; Vaswani A, 2017, ADV NEUR IN, V30; Wallis A, 2011, CLIN RADIOL, V66, P1015, DOI 10.1016/j.crad.2011.05.013; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wu ZX, 2024, Arxiv, DOI arXiv:2305.08809; Wu ZH, 2023, Arxiv, DOI arXiv:2304.09138; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Zhao L, 2023, Arxiv, DOI arXiv:2303.15935; Zhong TY, 2023, Arxiv, DOI arXiv:2304.11107; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	33	1	1	25	25	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-45672-5; 978-3-031-45673-2	LECT NOTES COMPUT SC			2024	14348						464	473		10.1007/978-3-031-45673-2_46	http://dx.doi.org/10.1007/978-3-031-45673-2_46			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Radiology, Nuclear Medicine & Medical Imaging	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Radiology, Nuclear Medicine & Medical Imaging	BW1RP					2024-07-03	WOS:001109643200046
J	Colombatto, C; Fleming, SM				Colombatto, Clara; Fleming, Stephen M.			Folk psychological attributions of consciousness to large language models	NEUROSCIENCE OF CONSCIOUSNESS			English	Article						phenomenal consciousness; subjective experience; folk psychology; mind perception; artificial intelligence; large language models	CONCEPTIONS	Technological advances raise new puzzles and challenges for cognitive science and the study of how humans think about and interact with artificial intelligence (AI). For example, the advent of large language models and their human-like linguistic abilities has raised substantial debate regarding whether or not AI could be conscious. Here, we consider the question of whether AI could have subjective experiences such as feelings and sensations ('phenomenal consciousness'). While experts from many fields have weighed in on this issue in academic and public discourse, it remains unknown whether and how the general population attributes phenomenal consciousness to AI. We surveyed a sample of US residents (n = 300) and found that a majority of participants were willing to attribute some possibility of phenomenal consciousness to large language models. These attributions were robust, as they predicted attributions of mental states typically associated with phenomenality-but also flexible, as they were sensitive to individual differences such as usage frequency. Overall, these results show how folk intuitions about AI consciousness can diverge from expert intuitions-with potential implications for the legal and ethical status of AI.	[Colombatto, Clara; Fleming, Stephen M.] UCL, Dept Expt Psychol, 26 Bedford Way, London WC1H 0AP, England; [Colombatto, Clara] Univ Waterloo, Dept Psychol, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada; [Fleming, Stephen M.] UCL, Max Planck UCL Ctr Computat Psychiat & Ageing Res, 10-12 Russell Sq, London WC1B 5EH, England; [Fleming, Stephen M.] UCL, Wellcome Ctr Human Neuroimaging, 12 Queen Sq, London WC1N 3AR, England	University of London; University College London; University of Waterloo; University of London; University College London; University of London; University College London	Colombatto, C (corresponding author), Univ Waterloo, Dept Psychol, 200 Univ Ave West, Waterloo, ON N2L 3G1, Canada.	clara.colombatto@uwaterloo.ca		Colombatto, Clara/0000-0003-3293-8741	UK Research and Innovation/Engineering and Physical Sciences Research Council Programme Grant [EP/V000748/1]; European Research Council Consolidator Award 'Conscious Computation'; Wellcome Trust [206648/Z/17/Z]; Royal Society [206648/Z/17/Z]; Wellcome Trust [206648/Z/17/Z] Funding Source: Wellcome Trust	UK Research and Innovation/Engineering and Physical Sciences Research Council Programme Grant; European Research Council Consolidator Award 'Conscious Computation'; Wellcome Trust(Wellcome Trust); Royal Society(Royal Society); Wellcome Trust(Wellcome Trust)	This work was supported by a UK Research and Innovation/Engineering and Physical Sciences Research Council Programme Grant (EP/V000748/1) and European Research Council Consolidator Award 'Conscious Computation'. S.M.F. is a Canadian Institute for Advanced Research Fellow in the Brain, Mind and Consciousness Program and is funded by a Sir Henry Dale Fellowship jointly funded by the Wellcome Trust and the Royal Society (206648/Z/17/Z).	Bainbridge WA, 2011, INT J SOC ROBOT, V3, P41, DOI 10.1007/s12369-010-0082-7; BLOCK N, 1995, BEHAV BRAIN SCI, V18, P227, DOI 10.1017/S0140525X00038188; Butlin P, 2023, Arxiv, DOI [arXiv:2308.08708, 10.48550/arXiv.2308.08708, DOI 10.48550/ARXIV.2308.08708]; Chalmers D. J., 2023, Boston Review; Chalmers D. J., 1996, The Conscious Mind: In Search of a Fundamental Theory; Gray HM, 2007, SCIENCE, V315, P619, DOI 10.1126/science.1134475; Huebner B, 2010, PHENOMENOL COGN SCI, V9, P133, DOI 10.1007/s11097-009-9126-6; Knobe J, 2008, PHENOMENOL COGN SCI, V7, P67, DOI 10.1007/s11097-007-9066-y; LeDoux J, 2023, CURR BIOL, V33, pR832, DOI 10.1016/j.cub.2023.06.067; Malle B. F., 2019, P 41 ANN M COGNITIVE, P2268; Mazor M, 2023, PERSPECT PSYCHOL SCI, V18, P535, DOI 10.1177/17456916221110222; NAGEL T, 1974, PHILOS REV, V83, P435, DOI 10.2307/2183914; Peressini A, 2014, PHILOS PSYCHOL, V27, P862, DOI 10.1080/09515089.2013.793150; Phelan M., 2023, The Compact Compendium of Experimental Philosophy, P263; Reuter K., 2022, PhilSci; Scholl BJ, 2013, SOCIAL PERCEPTION: DETECTION AND INTERPRETATION OF ANIMACY, AGENCY, AND INTENTION, P197; Scott A, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581296; Shardlow M, 2023, Arxiv, DOI arXiv:2211.11483; Shepherd J, 2018, ROU FOCUS PHILOSOPHY, P1, DOI 10.4324/9781315396347; Sytsma J, 2019, J CONSCIOUSNESS STUD, V26, P241; Sytsma J, 2014, WIRES COGN SCI, V5, P635, DOI 10.1002/wcs.1320; Sytsma J, 2010, PHILOS STUD, V151, P299, DOI 10.1007/s11098-009-9439-x; Talbot B, 2012, CONSCIOUS COGN, V21, P644, DOI 10.1016/j.concog.2010.12.005; Waytz A, 2010, TRENDS COGN SCI, V14, P383, DOI 10.1016/j.tics.2010.05.006; Weisman K, 2017, P NATL ACAD SCI USA, V114, P11374, DOI 10.1073/pnas.1704347114; Wiese W., 2023, PREPRINT	26	0	0	4	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND		2057-2107		NEUROSCI CONSCIOUS	NEUROSCI. CONSCIOUS.	APR 11	2024	2024	1							niae013	10.1093/nc/niae013	http://dx.doi.org/10.1093/nc/niae013			5	Psychology, Biological	Emerging Sources Citation Index (ESCI)	Psychology	NI3V2	38618488	Green Published, gold			2024-07-03	WOS:001199793900001
J	Zhou, M; Li, FS; Zhang, F; Zheng, JH; Ma, QL				Zhou, Mi; Li, Fusheng; Zhang, Fan; Zheng, Junhao; Ma, Qianli			Meta In-Context Learning: Harnessing Large Language Models for Electrical Data Classification	ENERGIES			English	Article						electrical data; large language models; in-context learning		The evolution of communication technology has driven the demand for intelligent power grids and data analysis in power systems. However, obtaining and annotating electrical data from intelligent terminals is time-consuming and challenging. We propose Meta In-Context Learning (M-ICL), a new approach that harnesses large language models to classify time series electrical data, which largely alleviates the need for annotated data when adapting to new tasks. The proposed M-ICL consists of two stages: meta-training and meta-testing. In meta-training, the model is trained on various tasks that have an adequate amount of training data. The meta-training stage aims to learn the mapping between electrical data and the embedding space of large language models. In the meta-testing stage, the trained model makes predictions on new tasks. By utilizing the in-context learning ability of large language models, M-ICL adapts models to new tasks effectively with only a few annotated instances (e.g., 1-5 training instances per class). Our contributions lie in the new application of large language models to electrical data classification and the introduction of M-ICL to improve the classification performance with the strong in-context learning ability of large language models. Furthermore, we conduct extensive experiments on 13 real-world datasets, and the experimental results show that the proposed M-ICL improves the average accuracy over all datasets by 19.06%, 12.06%, and 6.63% when only one, two, and five training instances for each class are available, respectively. In summary, M-ICL offers a promising solution to the challenges of electrical data classification.	[Zhou, Mi; Li, Fusheng; Zhang, Fan] China Southern Power Grid, Elect Power Res Inst, Guangzhou 510663, Peoples R China; [Zhou, Mi; Li, Fusheng; Zhang, Fan; Zheng, Junhao; Ma, Qianli] Guangdong Prov Key Lab Intelligent Measurement & A, Guangzhou 510663, Peoples R China	China Southern Power Grid	Ma, QL (corresponding author), Guangdong Prov Key Lab Intelligent Measurement & A, Guangzhou 510663, Peoples R China.	zhoumi2@csg.cn; lifs@csg.cn; zhangfan4@csg.cn; junhaozheng47@outlook.com; qianlima@scut.edu.cn	Ma, Qianli/AAL-5191-2020; Zheng, Junhao (Junhao/JEP-7533-2023	Ma, Qianli/0000-0002-8127-9781; Zheng, Junhao (Junhao/0000-0001-9124-2467; Ma, Qianli/0000-0002-9356-2883	China Southern Power Grid; project named Research on key technologies for the research and development of intelligent terminals and edge computing platforms based on new power systems [SEPRI-K22B099]	China Southern Power Grid; project named Research on key technologies for the research and development of intelligent terminals and edge computing platforms based on new power systems	This research was funded by the China Southern Power Grid. The APC was funded bythe project named Research on key technologies for the research and development of intelligent terminals and edge computing platforms based on new power systems , and the project number is SEPRI-K22B099.	Aghajanyan A., 2020, P INT C LEARN REPR; Akyürek E, 2023, Arxiv, DOI arXiv:2211.15661; Atkinson Gentry, 2021, P 17 INT C ART INT A, V17, P479; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen RL, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13074481; Chen SY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7870; Chen X., 2019, Adv. Neural Inf. Process. Syst., V32, P1; Cheng B, 2017, IEEE ACM T NETWORK, V25, P2082, DOI 10.1109/TNET.2017.2705239; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fan WT, 2022, IEEE T PATTERN ANAL, V44, P9654, DOI 10.1109/TPAMI.2021.3128271; Fekri MN, 2022, INT J ELEC POWER, V137, DOI 10.1016/j.ijepes.2021.107669; Han J., 2019, P INT C LEARN REPR N; Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209; Lee C., 2020, P INT C LEARN REPR; Li ZH, 2022, COMPUT NETW, V210, DOI 10.1016/j.comnet.2022.108937; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lv ZH, 2020, IEEE INTERNET THINGS, V7, P4616, DOI 10.1109/JIOT.2019.2954588; Lv ZH, 2020, COMPUT COMMUN, V153, P42, DOI 10.1016/j.comcom.2020.01.060; Mach P, 2016, T EMERG TELECOMMUN T, V27, P648, DOI 10.1002/ett.3009; Min SW, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5316; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Mollik MS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172648; Paszke A, 2019, ADV NEUR IN, V32; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ravindra P, 2017, LECT NOTES COMPUT SC, V10601, P395, DOI 10.1007/978-3-319-69035-3_28; Rubin O, 2022, Arxiv, DOI [arXiv:2112.08633, 10.48550/ARXIV.2112.08633]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Smadi AA, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091043; Taik A, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9148937; Teimoori Z, 2022, IEEE T IND INFORM, V18, P6464, DOI 10.1109/TII.2022.3148997; Wang HX, 2022, CSEE J POWER ENERGY, V8, P983, DOI 10.17775/CSEEJPES.2021.01270; Wang Y, 2021, IEEE T SMART GRID, V12, P3637, DOI 10.1109/TSG.2021.3066577; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Wu CH, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P680; Wu Q, 2022, IEEE T MOBILE COMPUT, V21, P2818, DOI 10.1109/TMC.2020.3045266; Xie S. M., 2022, P INT C LEARN REPR; Xiong LL, 2023, IEEE T CIRCUITS-I, V70, P1685, DOI 10.1109/TCSI.2023.3240702; Xu RX, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9514; Yan ZZ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3048784; Yang HF, 2019, EXPERT SYST APPL, V120, P128, DOI 10.1016/j.eswa.2018.11.019; Zhang HY, 2021, P INT COMP SOFTW APP, P459, DOI 10.1109/COMPSAC51774.2021.00070; Zhang T., 2020, P INT C LEARN REPR A; Zhao J, 2023, IEEE T POWER SYST, V38, P4369, DOI 10.1109/TPWRS.2022.3215510; Zheng JH, 2023, Arxiv, DOI arXiv:2306.10790; Zheng JH, 2022, INFORM SCIENCES, V615, P758, DOI 10.1016/j.ins.2022.09.060; Zheng JH, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P2670; Zheng Junhao, 2022, P 2022 C EMPIRICAL M, P3602	49	0	0	16	31	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1996-1073		ENERGIES	Energies	SEP	2023	16	18							6679	10.3390/en16186679	http://dx.doi.org/10.3390/en16186679			18	Energy & Fuels	Science Citation Index Expanded (SCI-EXPANDED)	Energy & Fuels	S9ZZ9		gold			2024-07-03	WOS:001074689300001
C	Argyriou, E; Böhm, J; Eberle, A; Gonser, J; Lumpp, AL; Niedermann, B; Schwarzkopf, F		Bekos, MA; Chimani, M		Argyriou, Evmorfia; Boehm, Jens; Eberle, Anne; Gonser, Julius; Lumpp, Anna-Lena; Niedermann, Benjamin; Schwarzkopf, Fabian			Editing Graph Visualizations by Prompting Large Language Models	GRAPH DRAWING AND NETWORK VISUALIZATION, GD 2023, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	31st International Symposium on Graph Drawing and Network Visualization (GD)	SEP 20-22, 2023	Isola delle Femmine, ITALY	Tom Sawyer Software & yWorks, Springer, Neo4J		Large language model; Code generation; Graph interaction		Today's Large Language Models (LLM) provide the possibility of translating user requests given in natural language into executable code. Based on this, we present an approach for interactively modifying graph visualizations. We explain how to prompt such LLMs and how to tackle technical restrictions as limitations of the LLMs on input sizes.	[Argyriou, Evmorfia; Boehm, Jens; Eberle, Anne; Gonser, Julius; Lumpp, Anna-Lena; Niedermann, Benjamin; Schwarzkopf, Fabian] yWorks GmbH, Tubingen, Germany		Niedermann, B (corresponding author), yWorks GmbH, Tubingen, Germany.	evmorfia.argyriou@yworks.com; jens.bohm@yworks.com; anne.eberle@yworks.com; julius.gonser@yworks.com; anna-lena.lumpp@yworks.com; benjamin.niedermann@yworks.com; fabian.schwarzkopf@yworks.com						Lopez Espejel J., 2023, Nat. Lang. Process. J., V3; Neo4j, 2023, Generating cypher queries with ChatGPT 4 on any graph schema; OpenAI, 2021, ChatGPT: Conversational AI model; Zhang S, 2023, 11 INT C LEARN REPR	4	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-49274-7; 978-3-031-49275-4	LECT NOTES COMPUT SC			2023	14466						253	254						2	Computer Science, Software Engineering; Computer Science, Theory & Methods; Mathematics, Applied	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Mathematics	BW8XE					2024-07-03	WOS:001207942000022
C	Zhang, D; Petrova, A; Trautmann, D; Schilder, F			ACM	Zhang, Dell; Petrova, Alina; Trautmann, Dietrich; Schilder, Frank			Unleashing the Power of Large Language Models for Legal Applications	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		legal data mining; legal information retrieval; legal natural language processing; legal knowledge management; large language models		The use of Large Language Models (LLMs) is revolutionizing the legal industry. In this technical talk, we would like to explore the various use cases of LLMs in legal tasks, discuss the best practices, investigate the available resources, examine the ethical concerns, and suggest promising research directions.	[Zhang, Dell; Petrova, Alina] Thomson Reuters Labs, London, England; [Trautmann, Dietrich] Thomson Reuters Labs, Zug, Switzerland; [Schilder, Frank] Thomson Reuters Labs, Eagan, MN USA		Zhang, D (corresponding author), Thomson Reuters Labs, London, England.	dell.z@ieee.org; alina.petrova@thomsonreuters.com; dietrich.trautmann@thomsonreuters.com; frank.schilder@thomsonreuters.com		Petrova, Alina/0000-0002-6109-1888; Zhang, Dell/0000-0002-8774-3725				Bommasani R., 2022, OPPORTUNITIES RISKS, DOI DOI 10.48550/ARXIV.2108.07258; Makrehchi M, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P5277, DOI 10.1145/3583780.3615308; Trautmann Dietrich, 2022, ARXIV221202199CS, DOI [10.48550/arXiv.2212.02199, DOI 10.48550/ARXIV.2212.02199]; Yu F., 2023, FINDINGS ASS COMPUTA, P13582; Yu Fangyi, 2022, ARXIV221201326CS, DOI [10.48550/arXiv.2212. 01326, DOI 10.48550/ARXIV.2212.01326]; Zhang Dell, 2023, P 2023 SIAM INT C DA, P965, DOI [10.1137/1. 9781611977653.ch111, DOI 10.1137/1.9781611977653.CH111]	6	1	1	13	13	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5257	5258		10.1145/3583780.3615993	http://dx.doi.org/10.1145/3583780.3615993			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO					2024-07-03	WOS:001161549505063
J	Gupta, BB; Gaurav, A; Arya, V				Gupta, Brij B.; Gaurav, Akshat; Arya, Varsha			Navigating the security landscape of large language models in enterprise information systems	ENTERPRISE INFORMATION SYSTEMS			English	Article						Large language models; Security development; Computational linguistics; Data privacy; Cybersecurity		In this letter, we present a comprehensive analysis of the security landscape surrounding large language models, leveraging a dataset from 2022 to 2023. We delve into the collaborative and global nature of this field, emphasizing the interdisciplinary approach required to address the evolving challenges. Prominent keywords like 'language model,' 'cybersecurity,' and 'data privacy' underscore central research themes. Beyond analysis, we introduce a cutting-edge deep CNN-based security framework, successfully tested with the KDDCup dataset, resulting in an impressive 94.73% accuracy on the testing dataset. As large language models continue to play a pivotal role in diverse applications, our research underscores the urgency of international cooperation and innovative security measures to ensure their responsible and secure usage in our interconnected world. This letter serves as a foundation for future research, driving the collective effort to safeguard large language models.	[Gupta, Brij B.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan; [Gupta, Brij B.] Kyung Hee Univ, Seoul, South Korea; [Gupta, Brij B.] Symbiosis Int Univ, Symbiosis Ctr Informat Technol SCIT, Pune, India; [Gupta, Brij B.] Lebanese Amer Univ, Dept Elect & Comp Engn, Beirut, Lebanon; [Gaurav, Akshat] Ronin Inst, Comp Engn, Montclair, NJ USA; [Arya, Varsha] Asia Univ, Dept Business Adm, Taichung, Taiwan; [Arya, Varsha] Univ Petr & Energy Studies UPES, Ctr Interdisciplinary Res, Dehra Dun, India	Asia University Taiwan; Kyung Hee University; Symbiosis International University; Symbiosis Centre for Information Technology (SCIT); Lebanese American University; Asia University Taiwan; University of Petroleum & Energy Studies (UPES)	Gupta, BB (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Gupta, BB (corresponding author), Kyung Hee Univ, Seoul, South Korea.; Gupta, BB (corresponding author), Symbiosis Int Univ, Symbiosis Ctr Informat Technol SCIT, Pune, India.; Gupta, BB (corresponding author), Lebanese Amer Univ, Dept Elect & Comp Engn, Beirut, Lebanon.	bbgupta@asia.edu.tw	Gupta, Brij B/E-9813-2011	Gupta, Brij B/0000-0003-4929-4698	National Science and Technology Council (NSTC), Taiwan [NSTC112-2221-E-468-008-MY3]	National Science and Technology Council (NSTC), Taiwan(National Science and Technology Council (NSTC) Zambia)	This research work is supported by National Science and Technology Council (NSTC), Taiwan Grant No. NSTC112-2221-E-468-008-MY3.	Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; Akbar KA, 2022, LECT NOTES COMPUT SC, V13383, P110, DOI 10.1007/978-3-031-10684-2_7; Almomani A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297032; Bair H, 2023, ACAD MED, V98, P869, DOI 10.1097/ACM.0000000000005265; Cadavid JPU, 2022, ENTERP INF SYST-UK, V16, DOI 10.1080/17517575.2020.1790043; Chen MK, 2013, AM ECON REV, V103, P690, DOI 10.1257/aer.103.2.690; Chen SM, 2017, J CORP FINANC, V46, P320, DOI 10.1016/j.jcorpfin.2017.07.009; Chow JC, 2018, SCHOOL PSYCHOL QUART, V33, P337, DOI 10.1037/spq0000255; Cohen J, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.818705; Crothers EN, 2023, IEEE ACCESS, V11, P70977, DOI 10.1109/ACCESS.2023.3294090; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Fatemidokht H, 2021, IEEE T INTELL TRANSP, V22, P4757, DOI 10.1109/TITS.2020.3041746; Gupta Brij B., 2023, 2023 IEEE 12th Global Conference on Consumer Electronics (GCCE), P1011, DOI 10.1109/GCCE59613.2023.10315325; Gupta BB, 2023, TECHNOL FORECAST SOC, V186, DOI 10.1016/j.techfore.2022.122152; Gupta BB, 2022, WIREL NETW, V28, P493, DOI 10.1007/s11276-021-02619-w; Hu B, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.302895; Huang YF, 2023, ENTERP INF SYST-UK, V17, DOI 10.1080/17517575.2023.2246188; Jouppi N. P., 2023, P INT S COMP ARCH, DOI [https://doi.org/10.1145/3579371.3589350, DOI 10.1145/3579371.3589350]; Khanam Sana, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.297094; Kshetri N, 2023, IT PROF, V25, P9, DOI 10.1109/MITP.2023.3275489; Kumbhojkar Neelesh Ragunath, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010107; Li HR, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5858; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Nhi NTU, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295551; Onyebuchi Amaonwu, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.297098; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pei KX, 2023, IEEE T SOFTWARE ENG, V49, P2776, DOI 10.1109/TSE.2022.3231621; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Shen K, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13243; Singh A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297143; Spilt JL, 2015, DEV PSYCHOL, V51, P185, DOI 10.1037/a0038540; Tan TF, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100394; Venerito Vincenzo, 2023, Lancet Rheumatol, V5, pe574, DOI 10.1016/S2665-9913(23)00216-3; Larenas SV, 2023, LANG TEST, V40, P463, DOI 10.1177/02655322221134218; Zdravkovic M, 2022, ENTERP INF SYST-UK, V16, P668, DOI 10.1080/17517575.2021.1941275; Zhang L, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.308469; Zhao R., 2023, Nongye Tushu Qingbao Xuebao, V35, P29, DOI [10.13998/j.cnki.issn1002-1248.23-0116, DOI 10.13998/J.CNKI.ISSN1002-1248.23-0116]; Zhao X., 2022, NAACL 2022 2022 C N	40	1	1	11	11	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1751-7575	1751-7583		ENTERP INF SYST-UK	Enterp. Inf. Syst.	APR 2	2024	18	4								10.1080/17517575.2024.2310846	http://dx.doi.org/10.1080/17517575.2024.2310846		FEB 2024	15	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OB4K5					2024-07-03	WOS:001159834800001
C	Wang, ST; Petridis, S; Kwon, T; Ma, XJ; Chilton, LB			ACM	Wang, Sitong; Petridis, Savvas; Kwon, Taeahn; Ma, Xiaojuan; Chilton, Lydia B.			PopBlends: Strategies for Conceptual Blending with Large Language Models	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		creativity support tools; applications of large language models; natural language processing		Pop culture is an important aspect of communication. On social media people often post pop culture reference images that connect an event, product or other entity to a pop culture domain. Creating these images is a creative challenge that requires fnding a conceptual connection between the users' topic and a pop culture domain. In cognitive theory, this task is called conceptual blending. We present a system called PopBlends that automatically suggests conceptual blends. The system explores three approaches that involve both traditional knowledge extraction methods and large language models. Our annotation study shows that all three methods provide connections with similar accuracy, but with very diferent characteristics. Our user study shows that people found twice as many blend suggestions as they did without the system, and with half the mental demand. We discuss the advantages of combining large language models with knowledge bases for supporting divergent and convergent thinking.	[Wang, Sitong; Petridis, Savvas; Kwon, Taeahn; Chilton, Lydia B.] Columbia Univ, New York, NY 10027 USA; [Ma, Xiaojuan] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China	Columbia University; Hong Kong University of Science & Technology	Wang, ST (corresponding author), Columbia Univ, New York, NY 10027 USA.	sw3504@columbia.edu; sdp2137@columbia.edu; taeahn.kwon@columbia.edu; mxj@cse.ust.hk; chilton@cs.columbia.edu		Wang, Sitong/0000-0002-1401-1371; Petridis, Savvas/0000-0002-4944-8477				Agrawala M, 2003, ACM T GRAPHIC, V22, P828, DOI 10.1145/882262.882352; Agrawala M, 2001, COMP GRAPH, P241, DOI 10.1145/383259.383286; Agrawala M, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1924421.1924439; AI Dungeon, US; Andolina S., 2015, Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition, ser. CC'15, Glasgow, P103, DOI DOI 10.1145/2757226.2757252; Bae S, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376746; Bird Steven, 2004, Nltk: The natural language toolkit, P214; Boden MA, 1998, ARTIF INTELL, V103, P347, DOI 10.1016/S0004-3702(98)00055-1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chan Joel, 2018, Proceedings of the ACM on Human-Computer Interaction, V2, DOI 10.1145/3274300; Chi Peggy, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P677, DOI 10.1145/3472749.3474778; Chilton LB, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445089; Chilton LB, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300402; Chung JJY, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501819; Claridge Peter, 2019, BRANDS CELEBRATE STA; De Deyne S., 2016, P COLING 2016 26 INT; De Deyne S, 2019, BEHAV RES METHODS, V51, P987, DOI 10.3758/s13428-018-1115-7; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dow SP, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2807; EPPE M, 2018, P WORKSH NLP OP SOUR, V256, P105, DOI DOI 10.18653/V1/W18o2501; Eppe M, 2018, ARTIF INTELL, V256, P105, DOI 10.1016/j.artint.2017.11.005; FALKENHAINER B, 1989, ARTIF INTELL, V41, P1, DOI 10.1016/0004-3702(89)90077-5; Fauconnier G, 1998, COGNITIVE SCI, V22, P133, DOI 10.1016/S0364-0213(99)80038-X; Gero Katy Ilonka, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479566; Gero Katy Ilonka, 2019, Metaphoria: An Algorithmic Companion for Metaphor Creation, P1, DOI DOI 10.1145/3290605.3300526; Gero Katy Ilonka, 2021, CORR; Hart S.G., 2006, P HUM FACT ERG SOC A, V50, P904, DOI [10.1177/154193120605000909, DOI 10.1177/154193120605000909]; Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123; Jeon Y, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445093; Kahn P.H., 2008, P 2008 3 ACM IEEE IN, P97, DOI [DOI 10.1145/1349822.1349836, DOI 10.1145/1349822, 10.1145/1349822]; KANG YW, 2021, METAMAP SUPPORTING V, DOI DOI 10.1145/3411764.3445325; KIM J, 2015, P 33 ANN ACM C HUM F, P1211; Kita Y, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174937; Koch J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300863; Leake M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073653; Lee Kenton, 2018, N AM CHAPT ASS COMP; LENAT DB, 1995, COMMUN ACM, V38, P33, DOI 10.1145/219717.219745; Liu V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545621; Merrell P, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964982; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Osone H, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3450391; Pallotta Frank, 2016, STAR WARS DAY IS FOR; PAULUS PB, 1993, PERS SOC PSYCHOL B, V19, P78; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Pereira Cmara, 2007, CREATIVITY ARTIFCIAL; Peters ME, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1756, DOI 10.18653/v1/P17-1161; Petridis Savvas, 2021, 34 ANN ACM S US INT, P385, DOI DOI 10.1145/3472749.3474757; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Radford A., 2018, IMPROVING LANGUAGE U; Ramesh A, 2021, PR MACH LEARN RES, V139; Ramos J., 2003, Proc. First Instr. Conf. Mach. Learn, V242, P29; Razniewski Simon, 2021, ARXIV211004888; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Sagi O, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1249; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Sauppé A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1439, DOI 10.1145/2556288.2557057; Shi Y, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P594, DOI 10.1145/2998181.2998208; Singhal Amit, 2012, Official Google Blog, V16; Tversky Barbara, 2010, CREATIVITY DEPTH BRE, DOI [10.1007/978-0-85729-224-7_27, DOI 10.1007/978-0-85729-224-7_27]; Veale T, 2000, COGN LINGUIST, V11, P253; Veale Tony., 2019, Computational Creativity: The Philosophy and Engineering of Autonomously Creative Systems, P71, DOI [https://doi.org/10.1007/978-3-319-43610-44, DOI 10.1007/978-3-319-43610-44]; Wang Chenguang, 2020, ARXIV201011967; Wang H.-C., 2011, Proceedings of the ACM 2011 Conference on Computer Supported Cooperative Work, P265; Wang HC, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P103; Wang W., 2020, P 34 INT C NEURAL IN, V33, P5776; Wu Tongtong, 2021, CORR; Xia Haijun, 2020, CROSSCAST ADDING VIS, P735, DOI [10.1145/3379337.3415882, DOI 10.1145/3379337.3415882]; Xia Haijun, 2020, CROSSPOWER BRIDGING, P722, DOI [10.1145/ 3379337.3415845, DOI 10.1145/3379337.3415845]; Yu LX, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1225, DOI 10.1145/2556288.2557378; Yu LX, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1245, DOI 10.1145/2556288.2557371; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Zhao NX, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376618	72	1	2	3	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580948	http://dx.doi.org/10.1145/3544548.3580948			19	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Submitted			2024-07-03	WOS:001037809504046
J	Lai, JB; Zang, ZX				Lai, Jinbang; Zang, Zhaoxiang			Sample Trajectory Selection Method Based on Large Language Model in Reinforcement Learning	IEEE ACCESS			English	Article						Reinforcement learning; large language models; trajectory selection; sampling efficiency	GO	This paper introduces a method for trajectory selection using large-scale pre-trained language models, aiming to improve sample and training efficiency in reinforcement learning. By using a carefully designed prompt, the large language model can fully utilize its prior knowledge, effectively understanding and assessing the quality of trajectories produced through agent-environment interactions in reinforcement learning. This approach allows selecting more informative trajectories for the current agent's learning. Unlike other works that indirectly improve reinforcement learning training efficiency by generating actions or decisions through large language models, our method employs these models to choose high-quality trajectories, thereby enhancing sample efficiency in reinforcement learning more directly. The approach was evaluated across multiple benchmark tasks in OpenAI's Gym and RLcard. The results indicate a significant reduction in the number of environment interactions, and a 37% increase in the average reward compared to the original method.	[Lai, Jinbang; Zang, Zhaoxiang] China Three Gorges Univ, Hubei Key Lab Intelligent Vis Based Monitoring Hyd, Yichang 443002, Hubei, Peoples R China; China Three Gorges Univ, Coll Comp & Informat Technol, Yichang 443002, Hubei, Peoples R China	China Three Gorges University; China Three Gorges University	Zang, ZX (corresponding author), China Three Gorges Univ, Hubei Key Lab Intelligent Vis Based Monitoring Hyd, Yichang 443002, Hubei, Peoples R China.	zhaoxiang.zang@ctgu.edu.cn	LAI, JINBANG/KIK-7349-2024	LAI, JINBANG/0009-0007-5553-0833	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Akner R., 2014, P INT C MACH LEARN, V32, P1503; Akrour R, 2011, LECT NOTES ARTIF INT, V6911, P12, DOI 10.1007/978-3-642-23780-5_11; Andrychowicz M, 2020, INT J ROBOT RES, V39, P3, DOI 10.1177/0278364919887447; Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240; Brockman G, 2016, Arxiv, DOI [arXiv:1606.01540, DOI 10.48550/ARXIV.1606.01540]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; BUJARD H, 1987, METHOD ENZYMOL, V155, P416; Carta T, 2023, Arxiv, DOI arXiv:2302.02662; Chakravorty J, 2020, Arxiv, DOI arXiv:1911.12825; Du YQ, 2023, Arxiv, DOI arXiv:2302.06692; Endsley MR, 2017, J COGN ENG DECIS MAK, V11, P225, DOI 10.1177/1555343417695197; Frome A., 2013, ADV NEURAL INFORM PR, P2121; Funkranz J., 2012, Foundations of Rade Learning; Ge YQ, 2023, Arxiv, DOI [arXiv:2304.04370, 10.48550/arXiv.2304.04370]; Hou Q., 2004, IEEE Trans. Autom. Sci. Eng., V21, P746, DOI [10.1109/TASE2022.3231845, DOI 10.1109/TASE2022.3231845]; Hou QH, 2023, IEEE T SYST MAN CY-S, V53, P4003, DOI 10.1109/TSMC.2023.3238709; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301; Mirchandani S., 2021, ADV NEURAL INFORM PR, V34, P29529; Mnih V, 2013, Arxiv, DOI [arXiv:1312.5602, DOI 10.48550/ARXIV.1312.5602]; Mu J., 2002, P AD NEUR INF PROC S, V35, P33947; Nottingham K, 2023, Arxiv, DOI arXiv:2301.12050; Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Sutton R. S., 2011, 10 INT C AUT AG MULT, V2, P761; Tam A., 2022, P AD NEUR INF P SYST, V35, P25377; Tenney I., 2019, arXiv, DOI DOI 10.48550/ARXIV.1905.05950; Valmeekam K, 2023, Arxiv, DOI [arXiv:2206.10498, 10.48550/arXiv.2206.10498]; Wang HN, 2020, FRONT INFORM TECH EL, V21, P1726, DOI 10.1631/FITEE.1900533; WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698; Wilson Robert C, 2011, Front Hum Neurosci, V5, P189, DOI 10.3389/fnhum.2011.00189; Zha DC, 2020, Arxiv, DOI arXiv:1910.04376; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong V., 2021, Advances in Neural Information Processing Systems, V34, P21505	38	0	0	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						61877	61885		10.1109/ACCESS.2024.3395457	http://dx.doi.org/10.1109/ACCESS.2024.3395457			9	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	PU0L4		gold			2024-07-03	WOS:001216478400001
J	Boiko, DA; Macknight, R; Kline, B; Gomes, G				Boiko, Daniil A.; Macknight, Robert; Kline, Ben; Gomes, Gabe			Autonomous chemical research with large language models	NATURE			English	Article							RECEPTOR 1; TRACE AMINES; TAAR1; METHAMPHETAMINE; PHARMACOLOGY; AMPHETAMINE; MECHANISMS; DISCOVERY; INSIGHTS; REVEAL	Transformer-based large language models are making significant strides in various fields, such as natural language processing1-5, biology6,7, chemistry8-10 and computer programming11,12. Here, we show the development and capabilities of Coscientist, an artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs complex experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation. Coscientist showcases its potential for accelerating research across six diverse tasks, including the successful reaction optimization of palladium-catalysed cross-couplings, while exhibiting advanced capabilities for (semi-)autonomous experimental design and execution. Our findings demonstrate the versatility, efficacy and explainability of artificial intelligence systems like Coscientist in advancing research. Coscientist is an artificial intelligence system driven by GPT-4 that autonomously designs, plans and performs experiments by incorporating large language models empowered by tools such as internet and documentation search, code execution and experimental automation.	[Boiko, Daniil A.; Macknight, Robert; Gomes, Gabe] Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA; [Kline, Ben] Emerald Cloud Lab, South San Francisco, CA USA; [Gomes, Gabe] Carnegie Mellon Univ, Dept Chem, Pittsburgh, PA 15213 USA; [Gomes, Gabe] Carnegie Mellon Univ, Wilton E Scott Inst Energy Innovat, Pittsburgh, PA 15213 USA	Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University	Gomes, G (corresponding author), Carnegie Mellon Univ, Dept Chem Engn, Pittsburgh, PA 15213 USA.; Gomes, G (corresponding author), Carnegie Mellon Univ, Dept Chem, Pittsburgh, PA 15213 USA.; Gomes, G (corresponding author), Carnegie Mellon Univ, Wilton E Scott Inst Energy Innovat, Pittsburgh, PA 15213 USA.	gabegomes@cmu.edu		dos Passos Gomes, Gabriel/0000-0002-8235-5969; Boiko, Daniil/0000-0003-4140-4645	Carnegie Mellon University Cloud Lab Initiative; Carnegie Mellon University; Mellon College of Sciences and its Department of Chemistry; College of Engineering - National Science Foundation Center for Chemoenzymatic Synthesis [2221346]; National Science Foundation Center for Computer-Assisted Synthesis [2202693]	Carnegie Mellon University Cloud Lab Initiative; Carnegie Mellon University; Mellon College of Sciences and its Department of Chemistry; College of Engineering - National Science Foundation Center for Chemoenzymatic Synthesis; National Science Foundation Center for Computer-Assisted Synthesis	We thank the following Carnegie Mellon University Chemistry groups for their assistance with providing the chemicals needed for the Coscientist's experiments: Sydlik, Garcia Borsch, Matyjaszewski and Ly. We give special thanks to the Noonan group (K. Noonan and D. Sharma) for providing access to chemicals and gas chromatography-mass spectrometry analysis. We also thank the team at Emerald Cloud Lab (with special attention to Y. Benslimane, H. Gronlund, B. Smith and B. Frezza) for assisting us with parsing their documentation and executing experiments. G.G. is grateful to the Carnegie Mellon University Cloud Lab Initiative led by the Mellon College of Science for its vision of the future of physical sciences. G.G. thanks Carnegie Mellon University; the Mellon College of Sciences and its Department of Chemistry; and the College of Engineering and its Department of Chemical Engineering for the start-up support. D.A.B. was partially funded by the National Science Foundation Center for Chemoenzymatic Synthesis (Grant no. 2221346). R.M. was funded by the National Science Foundation Center for Computer-Assisted Synthesis (Grant no. 2202693).	Accorroni A, 2016, TRACE AMINES AND NEUROLOGICAL DISORDERS: POTENTIAL MECHANISMS AND RISK FACTORS, P151; Achat-Mendes C, 2012, PHARMACOL BIOCHEM BE, V101, P201, DOI 10.1016/j.pbb.2011.10.025; Adams PD, 2004, J SYNCHROTRON RADIAT, V11, P53, DOI 10.1107/S0909049503024130; Alnefeesi Y, 2021, NEUROSCI BIOBEHAV R, V131, P192, DOI 10.1016/j.neubiorev.2021.09.020; [Anonymous], 2020, Most overdose deaths involve illicitly manufactured fentanyls; Barak LS, 2008, MOL PHARMACOL, V74, P585, DOI 10.1124/mol.108.048884; Berry MD, 2017, PHARMACOL THERAPEUT, V180, P161, DOI 10.1016/j.pharmthera.2017.07.002; Berry MD, 2004, J NEUROCHEM, V90, P257, DOI 10.1111/j.1471-4159.2004.02501.x; Bisagno V., 2022, Handbook of Neurotoxicity, P563; Borowsky B, 2001, P NATL ACAD SCI USA, V98, P8966, DOI 10.1073/pnas.151105198; Bradaia A, 2009, P NATL ACAD SCI USA, V106, P20081, DOI 10.1073/pnas.0906522106; Carpenter B, 2016, NATURE, V536, P104, DOI 10.1038/nature18966; Chan B, 2019, ADDICTION, V114, P2122, DOI 10.1111/add.14755; Chun E, 2012, STRUCTURE, V20, P967, DOI 10.1016/j.str.2012.04.010; Cichero E, 2013, CHEM BIOL DRUG DES, V81, P509, DOI 10.1111/cbdd.12018; Cotter R, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00039; Croll TI, 2018, ACTA CRYSTALLOGR D, V74, P519, DOI 10.1107/S2059798318002425; Dodd S, 2021, NEUROSCI BIOBEHAV R, V120, P537, DOI 10.1016/j.neubiorev.2020.09.028; Duan J, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17933-8; Emsley P, 2004, ACTA CRYSTALLOGR D, V60, P2126, DOI 10.1107/S0907444904019158; Eswar Narayanan, 2006, Curr Protoc Bioinformatics, VChapter 5, pUnit, DOI [10.1002/0471140864.ps0209s50, 10.1002/cpbi.3, 10.1002/0471250953.bi0506s47, 10.1002/cpps.20, 10.1002/0471250953.bi0506s15]; Eyun SI, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151023; Gainetdinov RR, 2018, PHARMACOL REV, V70, P549, DOI 10.1124/pr.117.015305; Galley G, 2016, ACS MED CHEM LETT, V7, P192, DOI 10.1021/acsmedchemlett.5b00449; Galley G, 2012, BIOORG MED CHEM LETT, V22, P5244, DOI 10.1016/j.bmcl.2012.06.060; García-Nafría J, 2018, ELIFE, V7, DOI 10.7554/eLife.35946; Grandy D. K., 2016, Neuropathology of Drug Addictions and Substance Misuse, P108; Guo LL, 2023, NATURE, V618, P193, DOI 10.1038/s41586-023-06106-4; Heffernan MLR, 2022, ACS MED CHEM LETT, V13, P92, DOI 10.1021/acsmedchemlett.1c00527; Heo L, 2022, PROTEINS, DOI 10.1002/prot.26382; Huang J, 2017, NAT METHODS, V14, P71, DOI [10.1038/NMETH.4067, 10.1038/nmeth.4067]; Huang SJ, 2022, MOL CELL, V82, P2681, DOI 10.1016/j.molcel.2022.05.031; Imai S, 2020, NAT CHEM BIOL, V16, P430, DOI 10.1038/s41589-019-0457-5; Isberg V, 2015, TRENDS PHARMACOL SCI, V36, P22, DOI 10.1016/j.tips.2014.11.001; Jayanthi S, 2021, EXP NEUROL, V344, DOI 10.1016/j.expneurol.2021.113795; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaplan AL, 2022, NATURE, V610, P582, DOI 10.1038/s41586-022-05258-z; Lam VM, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00953; Liao SY, 2022, LIFE SCI, V300, DOI 10.1016/j.lfs.2022.120553; Liberles SD, 2015, CURR OPIN NEUROBIOL, V34, P1, DOI 10.1016/j.conb.2015.01.001; Lindemann L, 2008, J PHARMACOL EXP THER, V324, P948, DOI 10.1124/jpet.107.132647; Liu JF, 2020, CELL MOL NEUROBIOL, V40, P229, DOI 10.1007/s10571-020-00792-8; Liu P, 2016, ACTA PHARMACOL SIN, V37, P1259, DOI 10.1038/aps.2016.69; Maeda S, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06002-w; Mastronarde DN, 2005, J STRUCT BIOL, V152, P36, DOI 10.1016/j.jsb.2005.07.007; Miller BR, 2012, J CHEM THEORY COMPUT, V8, P3314, DOI 10.1021/ct300418h; Miller GM, 2011, J NEUROCHEM, V116, P164, DOI 10.1111/j.1471-4159.2010.07109.x; Nair PC, 2022, MOL PSYCHIATR, V27, P88, DOI 10.1038/s41380-021-01250-7; Olsen RHJ, 2020, NAT CHEM BIOL, V16, P841, DOI 10.1038/s41589-020-0535-8; Olsson MHM, 2011, J CHEM THEORY COMPUT, V7, P525, DOI 10.1021/ct100578z; Pei Y, 2014, NEUROPSYCHOPHARMACOL, V39, P2299, DOI 10.1038/npp.2014.88; Pettersen EF, 2004, J COMPUT CHEM, V25, P1605, DOI 10.1002/jcc.20084; Pettersen EF, 2021, PROTEIN SCI, V30, P70, DOI 10.1002/pro.3943; Punjani A, 2017, NAT METHODS, V14, P290, DOI [10.1038/NMETH.4169, 10.1038/nmeth.4169]; Raony I, 2022, PROG NEURO-PSYCHOPH, V117, DOI 10.1016/j.pnpbp.2022.110555; Reese EA, 2007, J PHARMACOL EXP THER, V321, P178, DOI 10.1124/jpet.106.115402; Reese EA, 2014, J MED CHEM, V57, P378, DOI 10.1021/jm401316v; Revel FG, 2013, MOL PSYCHIATR, V18, P543, DOI 10.1038/mp.2012.57; Revel FG, 2012, NEUROPSYCHOPHARMACOL, V37, P2580, DOI 10.1038/npp.2012.109; Saarinen M, 2022, NEUROPSYCHOPHARMACOL, V47, P2319, DOI 10.1038/s41386-022-01421-2; Salomon-Ferrer R, 2013, J CHEM THEORY COMPUT, V9, P3878, DOI 10.1021/ct400314y; Schep LJ, 2010, CLIN TOXICOL, V48, P675, DOI 10.3109/15563650.2010.516752; Staus DP, 2016, NATURE, V535, P448, DOI 10.1038/nature18636; Su MF, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31823-1; Tan ES, 2009, ACS CHEM BIOL, V4, P209, DOI 10.1021/cb800304d; Tan YX, 2022, CELL DISCOV, V8, DOI 10.1038/s41421-022-00412-3; Tonelli M, 2020, EXPERT OPIN THER PAT, V30, P137, DOI 10.1080/13543776.2020.1708900; Underhill SM, 2021, MOL PSYCHIATR, V26, P1208, DOI 10.1038/s41380-019-0469-2; Vanommeslaeghe K, 2010, J COMPUT CHEM, V31, P671, DOI 10.1002/jcc.21367; Wang FI, 2022, METHODS, V203, P249, DOI 10.1016/j.ymeth.2021.10.009; Wu EL, 2014, J COMPUT CHEM, V35, P1997, DOI 10.1002/jcc.23702; Wu RY, 2021, CNS DRUGS, V35, P1239, DOI 10.1007/s40263-021-00871-4; Xu PY, 2021, NATURE, V592, P469, DOI 10.1038/s41586-021-03376-8; Xu ZR, 2020, CELL MOL NEUROBIOL, V40, P257, DOI 10.1007/s10571-019-00774-5; Zhang YA, 2020, CELL DISCOV, V6, DOI 10.1038/s41421-020-0176-9; Zheng SQ, 2017, NAT METHODS, V14, P331, DOI 10.1038/nmeth.4193; Zhuang YW, 2021, CELL, V184, P931, DOI 10.1016/j.cell.2021.01.027	77	36	37	84	93	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	DEC 21	2023	624	7992					570	+		10.1038/s41586-023-06792-0	http://dx.doi.org/10.1038/s41586-023-06792-0			13	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CY8A1	38123806	hybrid			2024-07-03	WOS:001128871300010
J	Gabriel, RA; Mariano, ER; McAuley, J; Wu, CL				Gabriel, Rodney A.; Mariano, Edward R.; McAuley, Julian; Wu, Christopher L.			How large language models can augment perioperative medicine: a daring discourse	REGIONAL ANESTHESIA AND PAIN MEDICINE			English	Article						Analgesics; Opioid; CHRONIC PAIN; Acute Pain; TECHNOLOGY	PAIN SERVICE	Interest in natural language processing, specifically large language models, for clinical applications has exploded in a matter of several months since the introduction of ChatGPT. Large language models are powerful and impressive. It is important that we understand the strengths and limitations of this rapidly evolving technology so that we can brainstorm its future potential in perioperative medicine. In this daring discourse, we discuss the issues with these large language models and how we should proactively think about how to leverage these models into practice to improve patient care, rather than worry that it may take over clinical decision-making. We review three potential major areas in which it may be used to benefit perioperative medicine: (1) clinical decision support and surveillance tools, (2) improved aggregation and analysis of research data related to large retrospective studies and application in predictive modeling, and (3) optimized documentation for quality measurement, monitoring and billing compliance. These large language models are here to stay and, as perioperative providers, we can either adapt to this technology or be curtailed by those who learn to use it well.	[Gabriel, Rodney A.] Univ Calif San Diego, Anesthesiol, La Jolla, CA 92093 USA; [Mariano, Edward R.] VA Palo Alto Hlth Care Syst, Anesthesiol & Perioperat Care Serv, Palo Alto, CA USA; [Mariano, Edward R.] Stanford Univ, Sch Med, Dept Anesthesiol Perioperat & Pain Med, Stanford, CA USA; [McAuley, Julian] Univ Calif San Diego, Comp Sci & Engn, La Jolla, CA USA; [Wu, Christopher L.] Hosp Special Surg, Anesthesiol, New York, NY USA	University of California System; University of California San Diego; US Department of Veterans Affairs; Veterans Health Administration (VHA); VA Palo Alto Health Care System; Stanford University; University of California System; University of California San Diego	Gabriel, RA (corresponding author), Univ Calif San Diego, Anesthesiol, La Jolla, CA 92093 USA.	ragabriel@health.ucsd.edu		Mariano, Edward/0000-0003-2735-248X; Wu, Christopher/0000-0002-4484-0787				[Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Chen Pei-Fu, 2021, JMIR Med Inform, V9, pe23230, DOI 10.2196/23230; Debbi EM, 2022, J ARTHROPLASTY, V37, pE14, DOI 10.1016/j.arth.2022.07.025; Downing NL, 2018, ANN INTERN MED, V169, P50, DOI 10.7326/M18-0139; Gabriel RA., 2023, AM SOC REG AN PAIN M; Gabriel RA, 2022, REGION ANESTH PAIN M, V47, P313, DOI 10.1136/rapm-2021-103299; Giladi AM, 2023, PLAST RECONSTR SURG, V152, p358E, DOI 10.1097/PRS.0000000000010297; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hossain E, 2023, COMPUT BIOL MED, V155, DOI 10.1016/j.compbiomed.2023.106649; Johnson A., 2023, BARD VS CHATGPT MAJO; Kaji AH, 2018, JAMA SURG, V153, P508, DOI 10.1001/jamasurg.2018.0647; Kaushik K, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19137898; Rosenthal E., 2023, DENIALS HLTH INSURAN; Rucker P., 2023, CIGNA SAVES MILLIONS; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Suh HS, 2022, ANESTH ANALG, V135, P1162, DOI 10.1213/ANE.0000000000006152; Sun EC, 2021, REGION ANESTH PAIN M, V46, P727, DOI 10.1136/rapm-2021-102669; Tighe PJ, 2012, PAIN MED, V13, P1347, DOI 10.1111/j.1526-4637.2012.01477.x; Venkatesh KP, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00768-0; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yen HK, 2022, SPINE J, V22, P1119, DOI 10.1016/j.spinee.2022.02.009	22	2	2	8	27	BMJ PUBLISHING GROUP	LONDON	BRITISH MED ASSOC HOUSE, TAVISTOCK SQUARE, LONDON WC1H 9JR, ENGLAND	1098-7339	1532-8651		REGION ANESTH PAIN M	Region. Anesth. Pain Med.	NOV	2023	48	11					575	577		10.1136/rapm-2023-104637	http://dx.doi.org/10.1136/rapm-2023-104637		JUN 2023	3	Anesthesiology	Science Citation Index Expanded (SCI-EXPANDED)	Anesthesiology	U5ML3	37336616				2024-07-03	WOS:001023725200001
C	Urban, M; Nguyen, DD; Binnig, C			ACM	Urban, Matthias; Duc Dat Nguyen; Binnig, Carsten			OmniscientDB: A Large Language Model-Augmented DBMS That Knows What Other DBMSs Do Not Know	PROCEEDINGS OF THE SIXTH INTERNATIONAL WORKSHOP ON EXPLOITING ARTIFICIAL INTELLIGENCE TECHNIQUES FOR DATA MANAGEMENT, AIDM 2023			English	Proceedings Paper	6th International Workshop on Exploiting Artificial Intelligence Techniques for Data Management (aiDM)	JUN 18, 2023	Seattle, WA			databases; large language models; data augmentation		In this paper, we present our vision of OmniscientDB, a novel database that leverages the implicitly-stored knowledge in large language models to augment datasets for analytical queries or even machine learning tasks. OmiscientDB empowers its users to augment their datasets by means of simple SQL queries and thus has the potential to dramatically reduce the manual overhead associated with data integration. It uses automatic prompt engineering to construct appropriate prompts for given SQL queries and passes them to a large language model like GPT-3 to contribute additional data (i.e., new rows, columns, or entire tables), augmenting the explicitly stored data. Our initial evaluation demonstrates the general feasibility of our vision, explores different prompting techniques in greater detail, and points towards several directions for future research.	[Urban, Matthias; Duc Dat Nguyen; Binnig, Carsten] Tech Univ Darmstadt, Darmstadt, Germany; [Binnig, Carsten] DFKI, Darmstadt, Germany	Technical University of Darmstadt	Urban, M (corresponding author), Tech Univ Darmstadt, Darmstadt, Germany.	matthias.urban@cs.tu-darmstadt.de; dat.nguyen@stud.tu-darmstadt.de; carsten.binnig@cs.tu-darmstadt.de		Urban, Matthias/0000-0002-7418-6181; Binnig, Carsten/0000-0002-2744-7836	Hochtief project AICO (AI in Construction); BMBF; state of Hesse as part of the NHR Program; HMWKcluster project 3AI (The ThirdWave of AI)	Hochtief project AICO (AI in Construction); BMBF(Federal Ministry of Education & Research (BMBF)); state of Hesse as part of the NHR Program; HMWKcluster project 3AI (The ThirdWave of AI)	We thank the reviewers for their feedback. This research is funded by the Hochtief project AICO (AI in Construction), by the BMBF and the state of Hesse as part of the NHR Program, as well as the HMWKcluster project 3AI (The ThirdWave of AI). Finally, we want to thank hessian.AI at TU Darmstadt as well as DFKI Darmstadt.	[Anonymous], 2022, NAACL 2022 2022 C N; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Deng X, 2022, SIGMOD REC, V51, P33, DOI 10.1145/3542700.3542709; Eisenschlos JM, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P7606; Fernandez RC, 2018, PROC INT CONF DATA, P1001, DOI 10.1109/ICDE.2018.00094; Guu K, 2020, Arxiv, DOI arXiv:2002.08909; Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320; Iida H, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3446; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Le Q. V., 2022, 10 INT C LEARN REPR; Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lin SPN, 2022, Arxiv, DOI [arXiv:2205.14334, 10.48550/ARXIV.2205.14334]; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Narayan A, 2022, PROC VLDB ENDOW, V16, P738, DOI 10.14778/3574245.3574258; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Razniewski S, 2021, Arxiv, DOI arXiv:2110.04888; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Schick T., 2023, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Yin Pengcheng, 2020, P 58 ANN M ASS COMPU, P8413, DOI [DOI 10.18653/V1/2020.ACL, 10.18653/v1/2020.acl-main.745, DOI 10.18653/V1/2020.ACL-MAIN.745]	28	1	1	2	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0193-1				2023										10.1145/3593078.3593933	http://dx.doi.org/10.1145/3593078.3593933			7	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV9ZN		Green Submitted			2024-07-03	WOS:001093674200004
J	Berenguer, A; Morejon, A; Tomas, D; Mazon, JN				Berenguer, Alberto; Morejon, Adriana; Tomas, David; Mazon, Jose-Norberto			Leveraging Large Language Models for Sensor Data Retrieval	APPLIED SCIENCES-BASEL			English	Article						sensor data; large language models; word embeddings; data retrieval; FAIR principles		The growing significance of sensor data in the development of information technology services finds obstacles due to disparate data presentations and non-adherence to FAIR principles. This paper introduces a novel approach for sensor data gathering and retrieval. The proposal leverages large language models to convert sensor data into FAIR-compliant formats and to provide word embedding representations of tabular data for subsequent exploration, enabling semantic comparison. The proposed system comprises two primary components. The first focuses on gathering data from sensors and converting it into a reusable structured format, while the second component aims to identify the most relevant sensor data to augment a given user-provided dataset. The evaluation of the proposed approach involved comparing the performance of various large language models in generating representative word embeddings for each table to retrieve related sensor data. The results show promising performance in terms of precision and MRR (0.90 and 0.94 for the best-performing model, respectively), indicating the system's ability to retrieve pertinent sensor data that fulfil user requirements.	[Berenguer, Alberto; Morejon, Adriana; Tomas, David; Mazon, Jose-Norberto] Univ Alicante, Dept Software & Comp Syst, Carretera San Vicente del Raspeig S-N, Alicante 03690, Spain	Universitat d'Alacant	Tomas, D (corresponding author), Univ Alicante, Dept Software & Comp Syst, Carretera San Vicente del Raspeig S-N, Alicante 03690, Spain.	aberenguer@dlsi.ua.es; adriana.morejon@ua.es; dtomas@dlsi.ua.es; jnmazon@ua.es	Mazón, Jose-Norberto/AAA-9817-2019; Tomas, David/H-5879-2015	Mazón, Jose-Norberto/0000-0001-7924-0880; Tomas, David/0000-0003-3287-9366; Berenguer Pastor, Alberto/0000-0002-2867-8329; Morejon, Adriana/0009-0005-1124-9682	European Union Next Generation EU/PRTR	European Union Next Generation EU/PRTR	No Statement Available	Agarwal V, 2021, IEEE INT CONF BIG DA, P5043, DOI 10.1109/BigData52589.2021.9671828; Albano M, 2011, IEEE T PARALL DISTR, V22, P1398, DOI 10.1109/TPDS.2011.18; Berenguer A, 2024, SENSORS-BASEL, V24, DOI 10.3390/s24020347; Bodenbenner M., 2021, Meas. Sens, V18, P100206, DOI [10.1016/j.measen.2021.100206, DOI 10.1016/J.MEASEN.2021.100206]; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005; Cappuzzo R., 2021, P 29 IT S ADV DAT SY, VVolume 2994, P331; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chen ZY, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P589, DOI 10.1145/3397271.3401044; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dobson S, 2018, IEEE SENS J, V18, P7659, DOI 10.1109/JSEN.2018.2861327; Du L, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P322, DOI 10.1145/3447548.3467228; Fang Q., 2006, P IEEE INFOCOM 25 IE, P1, DOI [10.1109/infocom.2006.115, DOI 10.1109/INFOCOM.2006.115]; Forgues Gabriel, 2014, P NIPS MOD MACH LEAR, V2; Gunther M., 2021, P 4 WORKSH EXPL AI T, P24, DOI DOI 10.1145/3464509.3464892; Gur I., 2023, P FIND ASS COMP LING, P2803, DOI [10.18653/v1/2023.findings-emnlp.185, DOI 10.18653/V1/2023.FINDINGS-EMNLP.185]; Herzig J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4320; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Huang H, 2024, Arxiv, DOI arXiv:2310.07676; Li J., 2021, P 30 INT JOINT C ART, P4492, DOI DOI 10.24963/IJCAI.2021/612SURVEYTRACK; Li Q, 2022, ACM T INTEL SYST TEC, V13, DOI 10.1145/3495162; Li XM, 2023, Arxiv, DOI arXiv:2309.12871; Li Y, 2018, STUD BIG DATA, V26, P83, DOI 10.1007/978-3-319-53817-4_4; Liu ML, 2020, IEEE INTERNET THINGS, V7, P284, DOI 10.1109/JIOT.2019.2944660; Liu ML, 2019, IEEE INTERNET THINGS, V6, P5232, DOI 10.1109/JIOT.2019.2899612; Liu ML, 2018, IEEE ACCESS, V6, P36509, DOI 10.1109/ACCESS.2018.2849865; Liu Q, 2020, Arxiv, DOI arXiv:2003.07278; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lukas N, 2023, P IEEE S SECUR PRIV, P346, DOI 10.1109/SP46215.2023.10179300; Ma Q, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P599, DOI 10.1109/ASONAM.2016.7752297; Marinov M, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1427, DOI 10.23919/MIPRO.2018.8400257; Mattern J., 2023, P FIND ASS COMP LING, P11330, DOI [10.18653/v1/2023.findings-acl.719, DOI 10.18653/V1/2023.FINDINGS-ACL.719]; McCreadie R, 2017, RIVER PUBL SER SIG I, P39; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Nargesian F, 2018, PROC VLDB ENDOW, V11, P813, DOI 10.14778/3192965.3192973; Pattar S, 2018, IEEE COMMUN SURV TUT, V20, P2101, DOI 10.1109/COMST.2018.2825231; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters M., 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-1202; Pilaluisa J, 2023, NEURAL COMPUT APPL, V35, P9319, DOI 10.1007/s00521-022-08066-8; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Rivera-Trigueros I, 2022, LANG RESOUR EVAL, V56, P593, DOI 10.1007/s10579-021-09537-5; Robertson S. E., 1995, Text REtrieval Conference (TREC-3) (NIST SP 500-225), P109; Schouten K, 2016, IEEE T KNOWL DATA EN, V28, P813, DOI 10.1109/TKDE.2015.2485209; Sharma A, 2021, IEEE ACCESS, V9, P4843, DOI 10.1109/ACCESS.2020.3048415; Shraga R, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1399, DOI 10.1145/3397271.3401120; Singla K, 2019, COMPUT SIST, V23, P1043, DOI [10.13053/CyS-23-3-3276, 10.13053/cys-23-3-3276]; Smith S, 2022, arXiv; Stahlberg F, 2020, J ARTIF INTELL RES, V69, P343, DOI 10.1613/jair.1.12007; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Vaz PJ, 2023, IEEE ACCESS, V11, P963, DOI 10.1109/ACCESS.2022.3233301; Voorhees EM, 1999, NIST Special Publication, P77, DOI DOI 10.1017/S1351324901002789; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xiao ST, 2024, Arxiv, DOI [arXiv:2309.07597, 10.48550/arXiv.2309.07597, DOI 10.48550/ARXIV.2309.07597]; Yin Pengcheng, 2020, P 58 ANN M ASS COMPU, P8413, DOI [DOI 10.18653/V1/2020.ACL, 10.18653/v1/2020.acl-main.745, DOI 10.18653/V1/2020.ACL-MAIN.745]; Zhang S, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1553, DOI 10.1145/3178876.3186067; Zhao HY, 2024, ACM T INTEL SYST TEC, V15, DOI 10.1145/3639372; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zubcoff Jose-Jacobo, 2023, Technol Forecast Soc Change, V186, P122108, DOI 10.1016/j.techfore.2022.122108	62	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	MAR	2024	14	6							2506	10.3390/app14062506	http://dx.doi.org/10.3390/app14062506			18	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	MD3Q4		gold			2024-07-03	WOS:001191653400001
J	Egli, A				Egli, Adrian			ChatGPT, GPT-4, and Other Large Language Models: The Next Revolution for Clinical Microbiology?	CLINICAL INFECTIOUS DISEASES			English	Review						chatGPT; large language model; artificial intelligence; chatbot; digitalization		ChatGPT, GPT-4, and Bard are highly advanced natural language process-based computer programs (chatbots) that simulate and process human conversation in written or spoken form. Recently released by the company OpenAI, ChatGPT was trained on billions of unknown text elements (tokens) and rapidly gained wide attention for its ability to respond to questions in an articulate manner across a wide range of knowledge domains. These potentially disruptive large language model (LLM) technologies have a broad range of conceivable applications in medicine and medical microbiology. In this opinion article, I describe how chatbot technologies work and discuss the strengths and weaknesses of ChatGPT, GPT-4, and other LLMs for applications in the routine diagnostic laboratory, focusing on various use cases for the pre- to post-analytical process. Natural language processing-based computer software simulates and processes human conversation. These potentially disruptive large language model technologies have a broad range of conceivable applications in medical microbiology. Strengths and weaknesses for applications in routine diagnostics are discussed.	[Egli, Adrian] Univ Zurich, Inst Med Microbiol, Zurich, Switzerland; [Egli, Adrian] Univ Zurich, Inst Med Microbiol, Gloriastr28, CH-8006 Zurich, Switzerland	University of Zurich; University of Zurich	Egli, A (corresponding author), Univ Zurich, Inst Med Microbiol, Gloriastr28, CH-8006 Zurich, Switzerland.	aegli@imm.uzh.ch		Egli, Adrian/0000-0002-3564-8603				Abd-alrazaq AA, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103978; Amiri P, 2022, J AM MED INFORM ASSN, V29, P1000, DOI 10.1093/jamia/ocac014; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Ben-Shabat N, 2022, INT J MED INFORM, V168, DOI 10.1016/j.ijmedinf.2022.104897; Ciecierski-Holmes T, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00700-y; Dhinagaran DA, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/38740; Drenkhahn C, 2019, STUD HEALTH TECHNOL, V264, P108, DOI 10.3233/SHTI190193; Egli A, 2020, CLIN MICROBIOL INFEC, V26, P1324, DOI 10.1016/j.cmi.2020.06.023; Ektefaie Y, 2023, NAT MACH INTELL, V5, P340, DOI 10.1038/s42256-023-00624-6; Ektefaie Y, 2021, LANCET MICROBE, V2, pE96, DOI [10.1016/S2666-5247(20)30195-6, 10.1016/s2666-5247(20)30195-6]; El-Osta A., 2022, BMJ Open, V12; European Commission, 2022, Regulatory Framework Proposal on Artificial Intelligence; Faqar-Uz-Zaman SF, 2022, ANN SURG, V276, P935, DOI 10.1097/SLA.0000000000005614; Fitzpatrick KK, 2017, JMIR MENT HEALTH, V4, DOI 10.2196/mental.7785; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gao Leo, 2022, arXiv, DOI 10.48550/arXiv.2210.10760; Gao YJ, 2022, J AM MED INFORM ASSN, V29, P1797, DOI 10.1093/jamia/ocac127; Gashi Floriana, 2021, Stud Health Technol Inform, V279, P18, DOI 10.3233/SHTI210083; Gazulla ED, 2023, EDUC INF TECHNOL, V28, P109, DOI 10.1007/s10639-022-11162-w; GPTZero, 2023, GPTZERO; Gräf M, 2022, RHEUMATOL INT, V42, P2167, DOI 10.1007/s00296-022-05202-4; Huo L, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab229; Jones AM., 2022, Front Artif Intell, V5; Jonsson A, 2019, KIDNEY DIS-BASEL, V5, P18, DOI 10.1159/000492670; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Karami M, 2017, HEALTH CARE MANAG, V36, P380, DOI 10.1097/HCM.0000000000000113; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Liu Z., 2021, Comput Intell Neurosci, V2021; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mendoza S, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155532; Miller D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33397-4; Mora S, 2023, APPL CLIN INFORM, V14, P16, DOI 10.1055/s-0042-1760081; Ni P, 2024, INFORM SYST FRONT, V26, P137, DOI 10.1007/s10796-022-10295-0; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; OpenAI, 2023, Open AI Blog-latest updates; Rahmanti AR, 2022, FRONT NUTR, V9, DOI 10.3389/fnut.2022.870775; Sezgin E, 2022, JMIR MED INF, V10, DOI 10.2196/32875; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Stiennon N., 2020, NerIPS Proceedings, V33, P1; US Food and Drug Administration, 2021, Artificial intelligence and machine learning in software as a medical device; Wallace W, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00667-w; Weeks R, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/40533; Wook J., 2022, GPT-2 output detector demo; Writer, 2023, Writer-AI content detector; Wu HH, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00730-6; Zvyagin M., 2022, bioRxiv	47	18	18	24	29	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1058-4838	1537-6591		CLIN INFECT DIS	Clin. Infect. Dis.	NOV 11	2023	77	9					1322	1328		10.1093/cid/ciad407	http://dx.doi.org/10.1093/cid/ciad407			7	Immunology; Infectious Diseases; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Immunology; Infectious Diseases; Microbiology	LK4H6	37399030	hybrid, Green Published			2024-07-03	WOS:001186676300003
J	Sorin, V; Glicksberg, BS; Artsi, Y; Barash, Y; Konen, E; Nadkarni, GN; Klang, E				Sorin, Vera; Glicksberg, Benjamin S.; Artsi, Yaara; Barash, Yiftach; Konen, Eli; Nadkarni, Girish N.; Klang, Eyal			Utilizing large language models in breast cancer management: systematic review	JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY			English	Review						Large language models; GPT; Breast cancer; Artificial intelligence		PurposeDespite advanced technologies in breast cancer management, challenges remain in efficiently interpreting vast clinical data for patient-specific insights. We reviewed the literature on how large language models (LLMs) such as ChatGPT might offer solutions in this field.MethodsWe searched MEDLINE for relevant studies published before December 22, 2023. Keywords included: "large language models", "LLM", "GPT", "ChatGPT", "OpenAI", and "breast". The risk bias was evaluated using the QUADAS-2 tool.ResultsSix studies evaluating either ChatGPT-3.5 or GPT-4, met our inclusion criteria. They explored clinical notes analysis, guideline-based question-answering, and patient management recommendations. Accuracy varied between studies, ranging from 50 to 98%. Higher accuracy was seen in structured tasks like information retrieval. Half of the studies used real patient data, adding practical clinical value. Challenges included inconsistent accuracy, dependency on the way questions are posed (prompt-dependency), and in some cases, missing critical clinical information.ConclusionLLMs hold potential in breast cancer care, especially in textual information extraction and guideline-driven clinical question-answering. Yet, their inconsistent accuracy underscores the need for careful validation of these models, and the importance of ongoing supervision.	[Sorin, Vera; Barash, Yiftach; Konen, Eli] Tel Aviv Univ, Sackler Sch Med, Chaim Sheba Med Ctr, Dept Diagnost Imaging, Emek Haela St 1, IL-52621 Ramat Gan, Israel; [Sorin, Vera; Barash, Yiftach] Chaim Sheba Med Ctr, DeepVis Lab, Tel Hashomer, Israel; [Glicksberg, Benjamin S.; Nadkarni, Girish N.; Klang, Eyal] Icahn Sch Med Mt Sinai, Div Data Driven & Digital Med D3M, New York, NY USA; [Artsi, Yaara] Bar Ilan Univ, Azrieli Fac Med, Safed, Israel; [Nadkarni, Girish N.; Klang, Eyal] Icahn Sch Med Mt Sinai, Charles Bronfman Inst Personalized Med, New York, NY USA	Tel Aviv University; Chaim Sheba Medical Center; Chaim Sheba Medical Center; Icahn School of Medicine at Mount Sinai; Bar Ilan University; Icahn School of Medicine at Mount Sinai	Sorin, V (corresponding author), Tel Aviv Univ, Sackler Sch Med, Chaim Sheba Med Ctr, Dept Diagnost Imaging, Emek Haela St 1, IL-52621 Ramat Gan, Israel.; Sorin, V (corresponding author), Chaim Sheba Med Ctr, DeepVis Lab, Tel Hashomer, Israel.	verasrn@gmail.com	Sorin, Vera/IAR-4247-2023	Sorin, Vera/0000-0003-0509-4686				Brin D., 2023, medRxiv, V23, P543; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chaudhry HJ, 2020, JAMA-J AM MED ASSOC, V323, P2017, DOI 10.1001/jama.2020.3198; Choi HS, 2023, RADIAT ONCOL J, V41, P209, DOI 10.3857/roj.2023.00633; Decker H, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36997; Griewing S, 2023, J PERS MED, V13, DOI 10.3390/jpm13101502; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kotek H, 2023, Arxiv, DOI arXiv:2308.14921; Kuhl C, 2010, J CLIN ONCOL, V28, P1450, DOI 10.1200/JCO.2009.23.0839; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lukac S, 2023, ARCH GYNECOL OBSTET, V308, P1831, DOI 10.1007/s00404-023-07130-5; Moher D, 2009, J CLIN EPIDEMIOL, V62, P1006, DOI 10.1016/j.jclinepi.2009.06.005; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.20006, 10.3322/caac.21551, 10.3322/caac.21387, 10.3322/caac.21332, 10.3322/caac.21254, 10.3322/caac.20073, 10.3322/caac.21654, 10.3322/caac.21601]; Sorin V., 2023, MedRxiv, V10, P23297733; Sorin V, 2023, EUR J RADIOL, V167, DOI 10.1016/j.ejrad.2023.111085; Sorin V, 2023, EUR J RADIOL OPEN, V10, DOI 10.1016/j.ejro.2023.100494; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Sorin V, 2021, RADIOLOGY, V301, DOI 10.1148/radiol.2021210566; Sorin V, 2020, LANCET ONCOL, V21, P1553, DOI 10.1016/S1470-2045(20)30615-X; Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026; Temsah Mohamad-Hani, 2023, Cureus, V15, pe44769, DOI 10.7759/cureus.44769; Whiting PF, 2011, ANN INTERN MED, V155, P529, DOI 10.7326/0003-4819-155-8-201110180-00009	27	1	1	11	11	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0171-5216	1432-1335		J CANCER RES CLIN	J. Cancer Res. Clin. Oncol.	MAR 19	2024	150	3							140	10.1007/s00432-024-05678-6	http://dx.doi.org/10.1007/s00432-024-05678-6			8	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	LO2C0	38504034	Green Accepted, hybrid			2024-07-03	WOS:001187667700004
J	Heiding, F; Schneier, B; Vishwanath, A; Bernstein, J; Park, PS				Heiding, Fredrik; Schneier, Bruce; Vishwanath, Arun; Bernstein, Jeremy; Park, Peter S.			Devising and Detecting Phishing Emails Using Large Language Models	IEEE ACCESS			English	Article						Phishing; large language models; social engineering; artificial intelligence		AI programs, built using large language models, make it possible to automatically create phishing emails based on a few data points about a user. The V-Triad is a set of rules for manually designing phishing emails to exploit our cognitive heuristics and biases. In this study, we compare the performance of phishing emails created automatically by GPT-4 and manually using the V-Triad. We also combine GPT-4 with the V-Triad to assess their combined potential. A fourth group, exposed to generic phishing emails, was our control group. We use a red teaming approach by simulating attackers and emailing 112 participants recruited for the study. The control group emails received a click-through rate between 19-28%, the GPT-generated emails 30-44%, emails generated by the V-Triad 69-79%, and emails generated by GPT and the V-Triad 43-81%. Each participant was asked to explain why they pressed or did not press a link in the email. These answers often contradict each other, highlighting the importance of personal differences. Next, we used four popular large language models (GPT, Claude, PaLM, and LLaMA) to detect the intention of phishing emails and compare the results to human detection. The language models demonstrated a strong ability to detect malicious intent, even in non-obvious phishing emails. They sometimes surpassed human detection, although often being slightly less accurate than humans. Finally, we analyze of the economic aspects of AI-enabled phishing attacks, showing how large language models increase the incentives of phishing and spear phishing by reducing their costs.	[Heiding, Fredrik] Harvard Univ, Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA; [Heiding, Fredrik] KTH Royal Inst Technol, S-11428 Stockholm, Sweden; [Schneier, Bruce] Harvard Univ, Harvard Kennedy Sch, Cambridge, MA 02138 USA; [Vishwanath, Arun] Avant Res Grp, Buffalo, NY 14214 USA; [Bernstein, Jeremy; Park, Peter S.] MIT, Cambridge, MA 02139 USA	Harvard University; Royal Institute of Technology; Harvard University; Massachusetts Institute of Technology (MIT)	Heiding, F (corresponding author), Harvard Univ, Harvard John A Paulson Sch Engn & Appl Sci, Cambridge, MA 02138 USA.; Heiding, F (corresponding author), KTH Royal Inst Technol, S-11428 Stockholm, Sweden.	fheiding@seas.harvard.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2022, Cybersecurity Threatscape: Q3 2022; [Anonymous], 2023, Casino Giant MGM Expects $100 Million Hit From Hack That Led To Data Breach | Reuters; [Anonymous], 2024, Security Awareness Program Challenges|Arctic Wolf; [Anonymous], 2023, IBM Finds That ChatGPT Can Generate Phishing Emails Nearly as Convincing As a Human|VentureBeat; [Anonymous], Email Marketing Statistics & Benchmarks | Mailchimp; [Anonymous], 2024, Security Awareness Training: Top Challenges and What To Do About Them|Security Magazine; [Anonymous], 2022, Email Marketing Benchmarks and Statistics for 2022|Campaign Monitor; Basit A, 2021, TELECOMMUN SYST, V76, P139, DOI 10.1007/s11235-020-00733-2; Bauer S, 2017, DATA BASE ADV INF SY, V48, P44, DOI 10.1145/3130515.3130519; Bhardwaj A., 2020, Computer Fraud Security, V2020, P15; Caldwell T, 2016, COMPUT FRAUD SECUR, P8, DOI 10.1016/S1361-3723(15)30046-4; Cialdini R.B., 2007, Influence: The psychology of persuasion, V55; Dhamija R., 2006, P SIGCHI C HUM FACT, P581; Do NQ, 2022, IEEE ACCESS, V10, P36429, DOI 10.1109/ACCESS.2022.3151903; Escoses C. A. A., 2022, P INT C MACH LEARN N, P153; Gangavarapu T, 2020, ARTIF INTELL REV, V53, P5019, DOI 10.1007/s10462-020-09814-9; Guo Shih-Wei, 2023, Advances on Broad-Band Wireless Computing, Communication and Applications: Proceedings of the 17th International Conference on Broad-Band Wireless Computing, Communication and Applications (BWCCA-2022). Lecture Notes in Networks and Systems (570), P270, DOI 10.1007/978-3-031-20029-8_26; Hadnagy C, 2015, PHISHING DARK WATERS: THE OFFENSIVE AND DEFENSIVE SIDES OF MALICIOUS E-MAILS, P1, DOI 10.1002/9781119183624; Hadnagy Christopher, 2018, Social Engineering: The Science of Human Hacking, V2nd; Hazell J, 2023, Arxiv, DOI arXiv:2305.06972; Heijden A. V. D., 2019, Cognitive Triaging Phishing Attacks; Houser W, 2015, IT PROF, V17, P54, DOI 10.1109/MITP.2015.21; Karanjai R., 2022, arXiv; Kim Eyong B., 2014, Information Management & Computer Security, V22, P115, DOI 10.1108/IMCS-01-2013-0005; Koide T, 2024, Arxiv, DOI arXiv:2306.05816; Kucharavy A, 2023, Arxiv, DOI arXiv:2303.12132; Maneriker P, 2021, IEEE MILIT COMMUN C, DOI 10.1109/MILCOM52596.2021.9653028; McCormac A, 2017, COMPUT HUM BEHAV, V69, P151, DOI 10.1016/j.chb.2016.11.065; Misra K, 2022, 2022 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WI-IAT, P135, DOI 10.1109/WI-IAT55865.2022.00028; Puhakainen P, 2010, MIS QUART, V34, P757; Roy SS, 2023, Arxiv, DOI arXiv:2305.05133; Touvron H., LLAMA OPEN EFFICIENT; U. B. of Labor Statistics, 2024, Table B-3. Average Hourly and Weekly Earnings of All Employees on Private Nonfarm Payrolls by Industry Sector, Seasonally Adjusted; Vishwanath A., 2022, The weakest link: How to diagnose, detect, and defend users from phishing; Wang Y., 2023, P IEEE INT C AC SPEE, P1	38	0	0	11	11	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						42131	42146		10.1109/ACCESS.2024.3375882	http://dx.doi.org/10.1109/ACCESS.2024.3375882			16	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	MF4R3		gold			2024-07-03	WOS:001192203500001
J	Grote, T; Berens, P				Grote, Thomas; Berens, Philipp			A paradigm shift?-On the ethics of medical large language models	BIOETHICS			English	Article						autonomy; clinical evaluation; machine learning; transparency; trust		After a wave of breakthroughs in image-based medical diagnostics and risk prediction models, machine learning (ML) has turned into a normal science. However, prominent researchers are claiming that another paradigm shift in medical ML is imminent-due to most recent staggering successes of large language models-from single-purpose applications toward generalist models, driven by natural language. This article investigates the implications of this paradigm shift for the ethical debate. Focusing on issues like trust, transparency, threats of patient autonomy, responsibility issues in the collaboration of clinicians and ML models, fairness, and privacy, it will be argued that the main problems will be continuous with the current debate. However, due to functioning of large language models, the complexity of all these problems increases. In addition, the article discusses some profound challenges for the clinical evaluation of large language models and threats to the reproducibility and replicability of studies about large language models in medicine due to corporate interests.	[Grote, Thomas] Univ Tubingen, Cluster Excellence Machine Learning New Perspect S, Tubingen, Germany; [Berens, Philipp] Hertie Inst Al Brain Hlth, Tubingen, Germany; [Berens, Philipp] Tubingen AI Ctr, Tubingen, Germany; [Grote, Thomas] Univ Tubingen, Cluster Excellence Machine Learning New Perspect S, Maria von Linden Str 6, D-72076 Tubingen, Germany	Eberhard Karls University of Tubingen; Eberhard Karls University of Tubingen	Grote, T (corresponding author), Univ Tubingen, Cluster Excellence Machine Learning New Perspect S, Maria von Linden Str 6, D-72076 Tubingen, Germany.	Thomas.grote@uni-tuebingen.de	Berens, Philipp/A-5653-2009	Berens, Philipp/0000-0002-0199-4727	Deutsche Forschungsgemeinschaft [BE5601/8-1]; DFG; Carl-Zeiss-Stiftung (Certification and Foundations of Safe Machine Learning in Healthcare); Hertie Foundation	Deutsche Forschungsgemeinschaft(German Research Foundation (DFG)); DFG(German Research Foundation (DFG)); Carl-Zeiss-Stiftung (Certification and Foundations of Safe Machine Learning in Healthcare); Hertie Foundation	TG and PB acknowledge support by the DFG (Excellence Cluster 2064 "Machine Learning-New Perspectives for Science," project number 390727645). In addition, PB has been supported by the DFG (BE5601/8-1). TG has been supported by the Carl-Zeiss-Stiftung (Certification and Foundations of Safe Machine Learning in Healthcare), while PB received support by the Hertie Foundation. Open Access funding enabled and organized by Projekt DEAL.		0	0	0	3	3	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0269-9702	1467-8519		BIOETHICS	Bioethics	JUN	2024	38	5					383	390		10.1111/bioe.13283	http://dx.doi.org/10.1111/bioe.13283		MAR 2024	8	Ethics; Medical Ethics; Social Issues; Social Sciences, Biomedical	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Social Sciences - Other Topics; Medical Ethics; Social Issues; Biomedical Social Sciences	PP4Q3	38523587	hybrid			2024-07-03	WOS:001189874700001
C	Farah, JC; Ingram, S; Spaenlehauer, B; Lasne, FKL; Gillet, D		Xie, H; Lai, CL; Chen, W; Xu, G; Popescu, E		Farah, Juan Carlos; Ingram, Sandy; Spaenlehauer, Basile; Lasne, Fanny Kim-Lan; Gillet, Denis			Prompting Large Language Models to Power Educational Chatbots	ADVANCES IN WEB-BASED LEARNING, ICWL 2023	Lecture Notes in Computer Science		English	Proceedings Paper	22nd Annual International Conference on Web-Based Learning (ICWL)	NOV 26-28, 2023	Sydney, AUSTRALIA	Univ Technol Sydney		Educational Chatbots; Prompting; GPT-3; Large Language Models; Software Engineering Education; Digital Education		The recent rise in both popularity and performance of large language models has garnered considerable interest regarding their applicability to education. Technologies like ChatGPT, which can engage in human-like dialog, have already disrupted educational practices given their ability to answer a wide array of questions. Nevertheless, integrating these technologies into learning contexts faces both technological and pedagogical challenges, such as providing appropriate user interfaces and configuring interactions to ensure that conversations stay on topic. To better understand the potential large language models have to power educational chatbots, we propose an architecture to support educational chatbots that can be powered by these models. Using this architecture, we created a chatbot interface that was integrated into a web application aimed at teaching software engineering best practices. The application was then used to conduct a case study comprising a controlled experiment with 26 university software engineering students. Half of the students interacted with a version of the application equipped with the chatbot, while the other half completed the same lesson without the chatbot. While the results of our quantitative analysis did not identify significant differences between conditions, qualitative insights suggest that learners appreciated the chatbot. These results could serve as a starting point to optimize strategies for integrating large language models into pedagogical scenarios.	[Farah, Juan Carlos; Spaenlehauer, Basile; Lasne, Fanny Kim-Lan; Gillet, Denis] Ecole Polytech Fed Lausanne EPFL, Lausanne, Switzerland; [Farah, Juan Carlos; Ingram, Sandy] Univ Appl Sci HES SO, Fribourg, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Applied Sciences & Arts Western Switzerland	Farah, JC (corresponding author), Ecole Polytech Fed Lausanne EPFL, Lausanne, Switzerland.; Farah, JC (corresponding author), Univ Appl Sci HES SO, Fribourg, Switzerland.	juancarlos.farah@epfl.ch; sandy.ingram@hefr.ch; basile.spaenlehauer@epfl.ch; fanny.lasne@epfl.ch; denis.gillet@epfl.ch	Farah, Juan Carlos/GYT-9862-2022	Farah, Juan Carlos/0000-0002-2477-4196; Ingram, Sandy/0000-0002-4050-580X; Lasne, Fanny/0000-0001-9841-4356				Airbnb, 2012, Airbnb JavaScript Style Guide; Bach S.H., 2022, arXiv; Bergin J., 2000, P 5 EUROPEAN C PATTE; Charmaz K, 2006, CONSTRUCTING GROUNDE, DOI DOI 10.7748/NR.13.4.84.S4; Farah JC, 2022, IEEE INT CONF ADV LE, P209, DOI 10.1109/ICALT55010.2022.00068; Gillet D, 2022, IEEE GLOB ENG EDUC C, P1587, DOI 10.1109/EDUCON52537.2022.9766795; Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55; Hutto C. J., 2014, 8 INT C WEBL SOC MED, DOI [10.1609/icwsm.v8i1.14550, DOI 10.1609/ICWSM.V8I1.14550]; Jiang ZB, 2020, Arxiv, DOI arXiv:1911.12543; Johnson S.C., 1978, Technical report; Kasneci E., 2023, ChatGPT for good? On opportunities and challenges of large language models for education, DOI [10.35542/osf.io/5-r8f, DOI 10.35542/OSF.IO/5-R8F]; Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6; OpenAI, 2022, Introducing chatgpt; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Song D, 2017, C HUM SYST INTERACT, P78, DOI 10.1109/HSI.2017.8005002; Tómasdóttir KF, 2020, IEEE T SOFTWARE ENG, V46, P863, DOI 10.1109/TSE.2018.2871058; Zakas N.C., 2013, About us; Zhao Tony Z, 2021, arXiv	18	1	1	10	10	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-981-99-8384-1; 978-981-99-8385-8	LECT NOTES COMPUT SC			2023	14409						169	188		10.1007/978-981-99-8385-8_14	http://dx.doi.org/10.1007/978-981-99-8385-8_14			20	Computer Science, Interdisciplinary Applications; Education & Educational Research; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW5JR		Green Submitted			2024-07-03	WOS:001162054600014
C	Hu, YW; Goktas, Y; Yellamati, DD; De Tassigny, C			IEEE	Hu, Yunwei; Goktas, Yavuz; Yellamati, David Deepak; De Tassigny, Catherine			The Use and Misuse of Pre-Trained Generative Large Language Models in Reliability Engineering	2024 ANNUAL RELIABILITY AND MAINTAINABILITY SYMPOSIUM, RAMS	Reliability and Maintainability Symposium		English	Proceedings Paper	70th Annual Reliability and Maintainability Symposium (RAMS)	JAN 22-25, 2024	Albuquerque, NM			Large Language Model; Machine Learning; Reliability; FMEA		Generative Large Language Models (LLMs) have garnered significant attention since the release of ChatGPT in November 2022. Researchers are actively exploring diverse applications to leverage the capabilities of these LLM systems. Within the field of reliability engineering there exists a potential for fruitful utilization of such models. In this paper, we delve into the applications of Large Language Models in reliability engineering, specifically focusing on their impressive language processing capabilities beyond traditional Natural Language Processing (NLP) tasks. Our study aims to evaluate the LLMs' potential in answering complex engineering questions and offering solutions to intricate problems. Additionally, we investigate the limitations of LLMs to understand their boundaries in providing accurate and reliable outputs. The paper emphasizes the significance of prompt engineering to enhance the accuracy and reliability of LLMs for improved performance in quantitative tasks. By incorporating minor prompt engineering techniques, the Large Language Models (LLMs), especially GPT-4, exhibited promising performance in answering Certified Reliability Engineer (CRE) exam questions. Our study involves an analysis of the errors made by the LLMs, allowing for a understanding of their limitations. Drawing from our findings, we provide recommendations on the appropriate application and areas to exercise caution when employing LLMs in the field of reliability engineering. These insights aim to guide practitioners in maximizing the benefits of LLMs while being mindful of their limitations and potential pitfalls. It is important to note that Generative AI and LLMs are rapidly evolving, and the evaluation conducted in this study reflects the test results at the time of writing. We anticipate that LLM responses may vary in the future. We are currently conducting research on developing applications based on LLMs to support the daily tasks of reliability engineers. We are excited about the possibilities and look forward to sharing our outcomes and contributing to the community.	[Hu, Yunwei] Schneider Elect, Design Safety & Reliabil, Rueil Malmaison, France; [Goktas, Yavuz] Schneider Elect, Design Assurance & Reliabil, Dev & Deployment State Art Design Safety & Reliab, Rueil Malmaison, France; [Yellamati, David Deepak] Schneider Elect, Safety & Reliabil, Design Safety Robustness & Reliabil, Rueil Malmaison, France; [De Tassigny, Catherine] Schneider Elect, Rueil Malmaison, France	Schneider Electric; Schneider Electric; Schneider Electric; Schneider Electric	Hu, YW (corresponding author), Schneider Elect, Design Safety & Reliabil, Rueil Malmaison, France.	yunwei.hu@se.com; yavuz.goktas@se.com; david.yellamati@se.com; catherine.de-tassigny@se.com						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Benbow D.W., 2008, The Certified Reliability Engineer Handbook; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; deeplearning.ai, 2023, ChatGPT Prompt Engineering for Developers; OpenAI, 2022, ChatGPT-Release Notes; Wolfram Stephen, 2023, ChatGPT gets its "Wolfram superpowers; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]	8	0	0	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	0149-144X		979-8-3503-0769-6	P REL MAINT S			2024										10.1109/RAMS51492.2024.10457630	http://dx.doi.org/10.1109/RAMS51492.2024.10457630			7	Computer Science, Theory & Methods; Engineering, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW7KT					2024-07-03	WOS:001192150700016
J	Bezzi, M				Bezzi, Michele			Large Language Models and Security	IEEE SECURITY & PRIVACY			English	Article						Security; Phishing; Malware; Fake news; Electronic mail; Costs; Computational modeling		We analyze the security implications of large language models (LLMs) from their use as security tools for both attackers and defenders and the security of LLMs. We discuss how LLMs increase the scale of traditional threats such as social engineering and add new ones such as prompt injections.	[Bezzi, Michele] SAP Secur Res, F-06254 Mougins, France		Bezzi, M (corresponding author), SAP Secur Res, F-06254 Mougins, France.							Asare O., 2023, ARXIV; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chen C, 2023, ARXIV; Claburn T., 2020, REGISTER; Debenedetti E., 2023, ARXIV; Hutchins M., MALWARETECH; Jain N., 2023, ARXIV; Lee K, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8424; Nasr M., 2023, ARXIV; research.checkpoint, OPWN CYB START US CH; Shi W., 2022, ARXIV; Sims J., HYAS; Wolf Y., 2023, arXiv; Zou A., 2003, ARXIV	14	0	0	22	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1540-7993	1558-4046		IEEE SECUR PRIV	IEEE Secur. Priv.	MAR-APR	2024	22	2					60	68		10.1109/MSEC.2023.3345568	http://dx.doi.org/10.1109/MSEC.2023.3345568		JAN 2024	9	Computer Science, Information Systems; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MW6I9					2024-07-03	WOS:001167328700001
C	Wei, JS; Wang, XZ; Schuurmans, D; Bosma, M; Ichter, B; Xia, F; Chi, EH; Le, QV; Zhou, DN		Koyejo, S; Mohamed, S; Agarwal, A; Belgrave, D; Cho, K; Oh, A		Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi, Ed H.; Le, Quoc V.; Zhou, Denny			Chain-of-Thought Prompting Elicits Reasoning in Large Language Models	ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 35, NEURIPS 2022	Advances in Neural Information Processing Systems		English	Proceedings Paper	36th Conference on Neural Information Processing Systems (NeurIPS)	NOV 28-DEC 09, 2022	ELECTR NETWORK					We explore how generating a chain of thought-a series of intermediate reasoning steps-significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.	[Wei, Jason; Wang, Xuezhi; Schuurmans, Dale; Bosma, Maarten; Ichter, Brian; Xia, Fei; Chi, Ed H.; Le, Quoc V.; Zhou, Denny] Google Res, Brain Team, Mountain View, CA 94043 USA	Google Incorporated	Wei, JS (corresponding author), Google Res, Brain Team, Mountain View, CA 94043 USA.	jasonwei@google.com; dennyzhou@google.com						Ahn M., 2022, arXiv preprint arXiv:2204.01691; Amini Aida, 2019, P 2019 C N AM CHAPT, V1; Andor Daniel, 2019, DANIEL; Andreas Jacob, 2018, NAACL; Austin Jacob, 2021, ARXIV210807732; BIG-bench collaboration, 2021, Beyond the imitation game: Measuring and extrapolating the capabilities of language models; Bostrom Kaj, 2021, EMNLP; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai Jonathon, 2017, ICLR; Camburu Oana-Maria, 2018, NeurIPS; Chen Howard, 2022, NAACL; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen Xiangyi, 2019, ICLR; Chiang TR, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2656; Clark Peter, 2020, IJCAI; Cobbe K., 2021, ARXIV211014168; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong H., 2019, ICLR; Dua Dheeru, 2020, ACL; Geva Mor, 2021, TACL; Gu Yuling, 2022, NAACL; Hancock B., 2018, Acl; Hase Peter, 2022, ACL; Hendrycks Dan, 2021, ARXIV210303874; Hosseini Mohammad Javad, 2014, EMNLP; Jie Zhanming, 2022, ARXIV220310316; Kaplan Jared, 2020, ARXIV200108361; Koncel-Kedziorski R., 2016, NAACL; Lampinen Andrew K, 2022, ARXIV220402329; Lan Yihuai, 2021, ARXIV210900799; Le Scao Teven, 2021, NAACL; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Lev Iddo, 2004, P 2 WORKSH TEXT MEAN; Li X. L., 2021, ACL; Liang Zhengzhong, 2021, NAACL; Majumder Bodhisattwa Prasad, 2021, ARXIV210613876; Marasovic Ana, 2022, NAACL FINDINGS; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Miao Shen Yun, 2020, ACL; Min Sewon, 2022, ARXIV220212837; Narang Sharan, 2020, ARXIV200414546; Ng KC, 2021, IEEE INT CONF COMP V, P2021, DOI 10.1109/ICCVW54120.2021.00229; Nye Maxwell, 2021, ARXIV211200114; Ouyang Long, 2022, ARXIV220302155; Patel Arkil, 2021, NAACL; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Pi Xinyu, 2022, ARXIV220111473; Piekos Piotr, 2021, ACL; Rae Jack W, 2021, arXiv:2112.11446; Raffel C, 2020, J MACH LEARN RES, V21; Rajagopal Dheeraj, 2021, EMNLP; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Ran Qiu, 2019, EMNLP; Rashkin Hannah, 2021, ARXIV211212870; Recchia Gabriel, 2021, ARXIV210902102; Reif Emily, 2022, ACL; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Roy Subhro, 2015, EMNLP; Roy Subhro, 2015, TACL; Saeed Mohammed, 2021, EMNLP; Sanh Victor, 2022, ICLR; Talmor Alon, 2020, NEURIPS; Talmor Alon, 2019, NAACL; Talmor Alon, 2021, NEURIPS TRACK DATASE; Tay Yi, 2022, ARXIV220505131; Thoppilan R., 2022, arXiv preprint arXiv:2201.08239; Wang Xuezhi, 2022, arXiv:2203.11171; Wang Y., 2022, ARXIV220407705; Wei JH, 2022, PR MACH LEARN RES; Wiegreffe Sarah, 2022, NAACL; Wiegreffe Sarah, 2021, NEURIPS; Wiegreffe Sarah., 2021, EMNLP; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Wu Tongshuang, 2022, CHI; Yan Y., 2020, NEURIPS; Yao Huihan, 2021, NEURIPS; Ye Xi, 2022, ARXIV220503401; Yee WH, 2021, INT REV ADM SCI, V87, P256, DOI 10.1177/0020852321992110; Yogatama Dani, 2017, ACL; Yordanov Yordan, 2021, ARXIV211206204; Zaidan Omar, 2007, NAACL; Zaremba W., 2014, Recurrent Neural Network Regularization; Zelikman Eric, 2022, ARXIV220314465; Zhao Tony Z., 2021, ICML; Zhou Wangchunshu, 2020, NEURIPS	85	124	124	1	1	NEURAL INFORMATION PROCESSING SYSTEMS (NIPS)	LA JOLLA	10010 NORTH TORREY PINES RD, LA JOLLA, CALIFORNIA 92037 USA	1049-5258		978-1-7138-7108-8	ADV NEUR IN			2022														14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8GZ					2024-07-03	WOS:001202259101051
J	Ruan, JQ; Liang, GQ; Zhao, H; Liu, GL; Sun, XZ; Qiu, J; Xu, Z; Wen, FS; Dong, ZY				Ruan, Jiaqi; Liang, Gaoqi; Zhao, Huan; Liu, Guolong; Sun, Xianzhuo; Qiu, Jing; Xu, Zhao; Wen, Fushuan; Dong, Zhao Yang			Applying Large Language Models to Power Systems: Potential Security Threats	IEEE TRANSACTIONS ON SMART GRID			English	Article						Power system stability; Security; Decision making; Training; Semantics; Reliability; Real-time systems; Power systems; large language models; security threats		Applying large language models (LLMs) to modern power systems presents a promising avenue for enhancing decision-making and operational efficiency. However, this action may also incur potential security threats, which have not been fully recognized so far. To this end, this article analyzes potential threats incurred by applying LLMs to power systems, emphasizing the need for urgent research and development of countermeasures.	[Ruan, Jiaqi; Sun, Xianzhuo] Hong Kong Polytech Univ, Dept Elect & Elect Engn, Hong Kong, Peoples R China; [Liang, Gaoqi] Harbin Inst Technol Shenzhen, Sch Mech Engn & Automat, Shenzhen 518055, Peoples R China; [Zhao, Huan; Dong, Zhao Yang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore; [Liu, Guolong] Chinese Univ Hong Kong Shenzhen, Sch Sci & Engn, Shenzhen 518172, Peoples R China; [Qiu, Jing] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia; [Xu, Zhao] Hong Kong Polytech Univ, Dept Elect & Elect Engn, Hong Kong, Peoples R China; [Xu, Zhao] Hong Kong Polytech Univ, Res Inst Smart Energy, Hong Kong, Peoples R China; [Wen, Fushuan] Zhejiang Univ, Coll Elect Engn, Hangzhou 310027, Peoples R China	Hong Kong Polytechnic University; Harbin Institute of Technology; Nanyang Technological University; The Chinese University of Hong Kong, Shenzhen; University of Sydney; Hong Kong Polytechnic University; Hong Kong Polytechnic University; Zhejiang University	Liang, GQ (corresponding author), Harbin Inst Technol Shenzhen, Sch Mech Engn & Automat, Shenzhen 518055, Peoples R China.; Xu, Z (corresponding author), Hong Kong Polytech Univ, Dept Elect & Elect Engn, Hong Kong, Peoples R China.; Xu, Z (corresponding author), Hong Kong Polytech Univ, Res Inst Smart Energy, Hong Kong, Peoples R China.	jiaqi.ruan@polyu.edu.hk; lianggaoqi@hit.edu.cn; huan.zhao@ntu.edu.sg; liuguolong@cuhk.edu.cn; xianzsun@polyu.edu.hk; jeremy.qiu@sydney.edu.au; eezhaoxu@polyu.edu.hk; fushuan.wen@gmail.com; zy.dong@ntu.edu.sg	XU, ZHAO/KHZ-0769-2024; Wen, Fushuan/D-2470-2019; Ruan, Jiaqi/AHE-7641-2022	XU, ZHAO/0000-0003-4480-7394; Wen, Fushuan/0000-0002-6838-2602; Ruan, Jiaqi/0000-0003-2584-0738; Zhao, Huan/0000-0002-3133-3137; Liu, Guolong/0000-0002-3726-4216; Liang, Gaoqi/0000-0001-9060-1675	Research Grants Council of the Hong Kong Special Administrative Region	Research Grants Council of the Hong Kong Special Administrative Region(Hong Kong Research Grants Council)	No Statement Available	Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Huseinovic A, 2020, IEEE ACCESS, V8, P177447, DOI 10.1109/ACCESS.2020.3026923; Liang GQ, 2017, IEEE T SMART GRID, V8, P1630, DOI 10.1109/TSG.2015.2495133; Mann SP, 2023, AM J BIOETHICS, V23, P28, DOI 10.1080/15265161.2023.2233356; Ruan Jiaqi, 2023, Energy Conversion and Economics, P233, DOI 10.1049/enc2.12091; Ruan JQ, 2023, IEEE T SMART GRID, V14, P4035, DOI 10.1109/TSG.2023.3241268; Wang DJ, 2021, APPL MATH COMPUT, V394, DOI 10.1016/j.amc.2020.125788; Wang HZ, 2019, IEEE T IND INFORM, V15, P5505, DOI 10.1109/TII.2019.2902163; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Yang L., IET Renew. Power Gener.	12	0	0	9	9	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1949-3053	1949-3061		IEEE T SMART GRID	IEEE Trans. Smart Grid	MAY	2024	15	3					3333	3336		10.1109/TSG.2024.3373256	http://dx.doi.org/10.1109/TSG.2024.3373256			4	Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	PV5S3		Green Submitted			2024-07-03	WOS:001216877100069
J	Wang, Y				Wang, Yu			On Finetuning Large Language Models	POLITICAL ANALYSIS			English	Article; Early Access						finetuning; large language models; text as data		A recent paper by Haffner et al. (2023, Political Analysis 31, 481-499) introduces an interpretable deep learning approach for domain-specific dictionary creation, where it is claimed that the dictionary-based approach outperforms finetuned language models in predictive accuracy while retaining interpretability. We show that the dictionary-based approach's reported superiority over large language models, BERT specifically, is due to the fact that most of the parameters in the language models are excluded from finetuning. In this letter, we first discuss the architecture of BERT models, then explain the limitations of finetuning only the top classification layer, and lastly we report results where finetuned language models outperform the newly proposed dictionary-based approach by 27% in terms of $R<^>2$ and 46% in terms of mean squared error once we allow these parameters to learn during finetuning. Researchers interested in large language models, text classification, and text regression should find our results useful. Our code and data are publicly available.	[Wang, Yu] Fudan Univ, Fudan Inst Adv Study Social Sci, Shanghai, Peoples R China	Fudan University	Wang, Y (corresponding author), Fudan Univ, Fudan Inst Adv Study Social Sci, Shanghai, Peoples R China.	yuwang.aiml@gmail.com		/0000-0001-5666-7881				Bestvater SE, 2023, POLIT ANAL, V31, P235, DOI 10.1017/pan.2022.10; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding N, 2023, NAT MACH INTELL, V5, P220, DOI 10.1038/s42256-023-00626-4; Dodge J, 2020, Arxiv, DOI [arXiv:2002.06305, 10.48550/arXiv.2002.06305]; Häffner S, 2023, POLIT ANAL, V31, P481, DOI 10.1017/pan.2023.7; Houlsby N, 2019, PR MACH LEARN RES, V97; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Hu YB, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5469; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mosbach Marius, 2021, ICLR; Wang Y., 2023, Harvard Dataverse, DOI [10.7910/DVN/7PCLRI, DOI 10.7910/DVN/7PCLRI]; Wang Y, 2023, POLIT ANAL, V31, P662, DOI 10.1017/pan.2023.3; Wang Y, 2019, POLIT ANAL, V27, P107, DOI 10.1017/pan.2018.40; Zhang T., 2021, ICLR	15	0	1	70	74	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	1047-1987	1476-4989		POLIT ANAL	Polit. Anal.	2023 NOV 28	2023										10.1017/pan.2023.36	http://dx.doi.org/10.1017/pan.2023.36		NOV 2023	5	Political Science	Social Science Citation Index (SSCI)	Government & Law	Z5UX5					2024-07-03	WOS:001112733700001
J	Habib, S; Butt, H; Goldenholz, SR; Chang, CY; Goldenholz, DM				Habib, Sara; Butt, Haroon; Goldenholz, Shira R.; Chang, Chi Yuan; Goldenholz, Daniel M.			Large Language Model Performance on Practice Epilepsy Board Examinations	JAMA NEUROLOGY			English	Article								This diagnostic study examines whether large language models are able to pass practice licensing examinations for epilepsy.	[Habib, Sara; Butt, Haroon; Goldenholz, Shira R.; Chang, Chi Yuan; Goldenholz, Daniel M.] Beth Israel Deaconess Med Ctr, Dept Neurol, 330 Brookline Ave,Baker 5, Boston, MA 02215 USA; [Habib, Sara; Butt, Haroon; Chang, Chi Yuan; Goldenholz, Daniel M.] Harvard Med Sch, Dept Neurol, Boston, MA USA	Harvard University; Beth Israel Deaconess Medical Center; Harvard University; Harvard Medical School	Goldenholz, DM (corresponding author), Beth Israel Deaconess Med Ctr, Dept Neurol, 330 Brookline Ave,Baker 5, Boston, MA 02215 USA.	daniel.goldenholz@bidmc.harvard.edu			National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	No Statement Available	Anthropic, CLAUDE 2; Google, BARD; Nori H., 2023, PREPRINT; OpenAI, GPT 4; Romano MF, 2023, NEUROLOGY, V101, P1058, DOI 10.1212/WNL.0000000000207967	5	0	0	1	1	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6149	2168-6157		JAMA NEUROL	JAMA Neurol.	JUN	2024	81	6					660	661		10.1001/jamaneurol.2024.0676	http://dx.doi.org/10.1001/jamaneurol.2024.0676		JUN 2024	2	Clinical Neurology	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	UM6C4	38587850				2024-07-03	WOS:001201427400001
J	Hassija, V; Chakrabarti, A; Singh, A; Chamola, V; Sikdar, B				Hassija, Vikas; Chakrabarti, Arjab; Singh, Anushka; Chamola, Vinay; Sikdar, Biplab			Unleashing the Potential of Conversational AI: Amplifying Chat-GPT's Capabilities and Tackling Technical Hurdles	IEEE ACCESS			English	Article						Large language models; ChatGPT; natural language processing; deep learning; neural networks; transformer models; pre-training and fine-tuning; language generation; text completion; model interpretability; bias in language models; ethics in AI; data scarcity; multimodal models; generalization; conversational AI; language understanding; text classification; sentiment analysis; dialogue systems	KNOWLEDGE DISTILLATION; ANOMALY DETECTION; VIDEO RETRIEVAL; NEURAL-NETWORKS; CONTEXT; LANGUAGE; MODEL; CNN; COLLABORATION; TRANSFORMERS	Conversational AI has seen a growing interest among government, researchers, and industrialists. This comprehensive survey paper provides an in-depth analysis of large language models, specifically focusing on ChatGPT. This paper discusses the architecture, training process, and challenges associated with large language models, including bias, interpretability, and ethics. It explores various applications of ChatGPT and examines future research trends, such as improving model generalization, addressing data scarcity, and integrating multimodal capabilities. This survey also serves as a roadmap for researchers, practitioners, and policymakers, offering valuable insights into the current state and future potential of large language models and ChatGPT.	[Hassija, Vikas] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore; [Chakrabarti, Arjab; Singh, Anushka] KIIT, Sch Comp Sci & Engn, Bhubaneswar 751024, India; [Chamola, Vinay] BITS Pilani Pilani Campus, Dept Elect & Elect Engn, Pilani 333031, India; [Chamola, Vinay] BITS Pilani Pilani Campus, APPCAIR, Pilani 333031, India; [Sikdar, Biplab] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117417, Singapore	National University of Singapore; Kalinga Institute of Industrial Technology (KIIT); Birla Institute of Technology & Science Pilani (BITS Pilani); Birla Institute of Technology & Science Pilani (BITS Pilani); National University of Singapore	Chamola, V (corresponding author), BITS Pilani Pilani Campus, Dept Elect & Elect Engn, Pilani 333031, India.; Chamola, V (corresponding author), BITS Pilani Pilani Campus, APPCAIR, Pilani 333031, India.	vinay.chamola@pilani.bits-pilani.ac.in		Chakrabarti, Arjab/0009-0006-4364-7172; Chamola, Vinay/0000-0002-6730-3060; Singh, Anushka/0009-0003-0274-808X				Abbasiharofteh M, 2023, SPAT ECON ANAL, V18, P507, DOI 10.1080/17421772.2023.2193222; Abdellatif A, 2022, IEEE T SOFTWARE ENG, V48, P3087, DOI 10.1109/TSE.2021.3078384; Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Al-Ajmi AH, 2021, IEEE ACCESS, V9, P7043, DOI 10.1109/ACCESS.2021.3049732; Alagha I, 2022, IEEE ACCESS, V10, P76842, DOI 10.1109/ACCESS.2022.3192858; Alladi T, 2022, IEEE COMMUN SURV TUT, V24, P1212, DOI 10.1109/COMST.2022.3160925; Alladi T, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500823; Alladi T, 2021, IEEE T VEH TECHNOL, V70, P12013, DOI 10.1109/TVT.2021.3113807; AlZubi S., 2023, Artif. Intell. Appl., P1; An J, 2022, IEEE-ACM T AUDIO SPE, V30, P2091, DOI 10.1109/TASLP.2022.3181350; Averza A, 2022, IEEE ACCESS, V10, P129394, DOI 10.1109/ACCESS.2022.3228258; Bahrini Aram, 2023, 2023 Systems and Information Engineering Design Symposium (SIEDS), P274, DOI 10.1109/SIEDS58326.2023.10137850; Baktash JA, 2023, Arxiv, DOI arXiv:2305.03195; Bansal G, 2020, IET IMAGE PROCESS, V14, P1240, DOI 10.1049/iet-ipr.2019.1164; Barrett M., 2023, Tech. Rep.; Bhowmik B, 2021, IEEE T CIRCUITS-II, V68, P3483, DOI 10.1109/TCSII.2021.3124297; Bilgram Volker, 2023, IEEE Engineering Management Review, P18, DOI 10.1109/EMR.2023.3272799; Borodin A., 2019, Humanitarian Balkan Res., V3; Cai WL, 2022, IEEE T HUM-MACH SYST, V52, P354, DOI 10.1109/THMS.2021.3131674; Cambiaso E, 2023, Arxiv, DOI [arXiv:2303.13521, 10.48550/arXiv.2303.13521, DOI 10.48550/ARXIV.2303.13521]; Cao MD, 2023, IEEE T CIRC SYST VID, V33, P160, DOI 10.1109/TCSVT.2022.3201045; Cerri G, 2004, IEEE T ANTENN PROPAG, V52, P3137, DOI 10.1109/TAP.2004.835252; Chamola V, 2023, NEURAL COMPUT APPL, V35, P22959, DOI 10.1007/s00521-022-07087-7; Chen HH, 2022, IEEE T RELIAB, V71, P657, DOI 10.1109/TR.2022.3156126; Chen KH, 2018, IEEE-ACM T AUDIO SPE, V26, P266, DOI 10.1109/TASLP.2017.2772846; Chen P, 2022, COMPUT J, V65, P2909, DOI 10.1093/comjnl/bxac085; Chen TY, 2021, IEEE ACCESS, V9, P82118, DOI 10.1109/ACCESS.2021.3083518; Cheng B, 2017, IEEE ACM T NETWORK, V25, P2082, DOI 10.1109/TNET.2017.2705239; Chhikara P, 2021, IEEE INTERNET THINGS, V8, P4448, DOI 10.1109/JIOT.2020.3027095; Choe J, 2023, IEEE T PATTERN ANAL, V45, P1732, DOI 10.1109/TPAMI.2022.3169881; Choi YR, 2021, IEEE T IMAGE PROCESS, V30, P1015, DOI 10.1109/TIP.2020.3040847; Chowdhury N., 2023, Tech. Rep.; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Daniel G, 2020, IEEE ACCESS, V8, P15332, DOI 10.1109/ACCESS.2020.2966919; Djenouri Y, 2024, EXPERT SYST, V41, DOI 10.1111/exsy.13093; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Farrokhnia M, 2024, INNOV EDUC TEACH INT, V61, P460, DOI 10.1080/14703297.2023.2195846; Fergus S, 2023, J CHEM EDUC, V100, P1672, DOI 10.1021/acs.jchemed.3c00087; Floyd S, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON MEASUREMENT AND CONTROL IN ROBOTICS (ISMCR): ROBOTICS FOR THE BENEFIT OF HUMANITY, DOI 10.1109/ismcr47492.2019.8955720; Folstad A, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3185372; Fuad A, 2022, IEEE ACCESS, V10, P23842, DOI 10.1109/ACCESS.2022.3155521; Gaddam SR, 2007, IEEE T KNOWL DATA EN, V19, P345, DOI 10.1109/TKDE.2007.44; Gao Y, 2023, Arxiv, DOI [arXiv:2304.02182, 10.48550/arXiv.2304.02182]; García-Méndez S, 2021, IEEE ACCESS, V9, P75878, DOI 10.1109/ACCESS.2021.3080837; Gaur V., 2022, P IEEE UND RES TECHN, P1; Gayed J. M., 2022, Computers and Education: Artificial Intelligence, V3, DOI DOI 10.1016/J.CAEAI.2022.100055; Goscinski A, 2022, IEEE T SERV COMPUT, V15, P588, DOI 10.1109/TSC.2022.3150986; Grover H, 2021, IEEE INTERNET THINGS, V8, P14787, DOI 10.1109/JIOT.2021.3071362; Gu JC, 2020, IEEE-ACM T AUDIO SPE, V28, P369, DOI 10.1109/TASLP.2019.2955290; Guembe B, 2022, APPL ARTIF INTELL, V36, DOI 10.1080/08839514.2022.2037254; Guo CG, 2022, IEEE J-STARS, V15, P3868, DOI 10.1109/JSTARS.2022.3173001; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Honda H, 2019, IEEE ACCESS, V7, P152368, DOI 10.1109/ACCESS.2019.2948081; Houssein EH, 2021, IEEE ACCESS, V9, P140628, DOI 10.1109/ACCESS.2021.3119621; Hu Z, 2023, IEEE-ACM T AUDIO SPE, V31, P188, DOI 10.1109/TASLP.2022.3221002; Hurlburt G, 2023, IT PROF, V25, P4, DOI 10.1109/MITP.2023.3267140; Hurley L, 2021, IEEE ACCESS, V9, P3919, DOI 10.1109/ACCESS.2020.3047057; Hussain I, 2022, IEEE ACCESS, V10, P113149, DOI 10.1109/ACCESS.2022.3216881; Ibrahim H, 2023, IEEE INTELL SYST, V38, P24, DOI 10.1109/MIS.2023.3255599; Imoto K, 2019, IEEE T SEMICONDUCT M, V32, P455, DOI 10.1109/TSM.2019.2941752; Islam B., 2022, PROC HUMAN CENTERED, P1; Jalaja Tattari, 2022, 2022 Second International Conference on Interdisciplinary Cyber Physical Systems (ICPS), P51, DOI 10.1109/ICPS55917.2022.00017; Jena M, 2022, IEEE ACCESS, V10, P69373, DOI 10.1109/ACCESS.2022.3187412; Jeong J, 2023, IEEE ACCESS, V11, P16631, DOI 10.1109/ACCESS.2023.3243108; Joo YS, 2020, IEEE ACCESS, V8, P161713, DOI 10.1109/ACCESS.2020.3021758; Juang BH, 2000, P IEEE, V88, P1142, DOI 10.1109/5.880077; Jung CS, 2012, IEEE SIGNAL PROC LET, V19, P809, DOI 10.1109/LSP.2012.2221703; Kalampokas T, 2023, IEEE ACCESS, V11, P46627, DOI 10.1109/ACCESS.2023.3274669; Kaur K., 2022, PROC 10 INT C REL IN, P1; Khatri C, 2018, Arxiv, DOI arXiv:1811.12900; Kim B, 2021, IEEE-ACM T AUDIO SPE, V29, P2437, DOI 10.1109/TASLP.2021.3077119; Kim KM, 2019, IEEE INTERNET COMPUT, V23, P23, DOI 10.1109/MIC.2018.2883059; Kim S, 2022, IEEE ACCESS, V10, P34766, DOI 10.1109/ACCESS.2022.3163398; Kuang W, 2020, IEEE T CIRC SYST VID, V30, P1481, DOI 10.1109/TCSVT.2019.2903547; Kusal S, 2022, IEEE ACCESS, V10, P92337, DOI 10.1109/ACCESS.2022.3201144; Kusumawardani SS, 2023, IEEE ACCESS, V11, P18960, DOI 10.1109/ACCESS.2023.3246122; Lai YL, 2023, IEEE T INF FOREN SEC, V18, P3101, DOI 10.1109/TIFS.2023.3273919; Lee JS, 2019, IEEE ACCESS, V7, P106034, DOI 10.1109/ACCESS.2019.2931865; Lee JH, 2024, IEEE T COMPUT SOC SY, V11, P514, DOI 10.1109/TCSS.2023.3238477; Leins K., 2020, Tech. Rep.; Li C, 2023, IEEE ACCESS, V11, P28236, DOI 10.1109/ACCESS.2023.3259325; Li C, 2022, IEEE ACCESS, V10, P91631, DOI 10.1109/ACCESS.2022.3202554; Li GL, 2021, IEEE-ACM T AUDIO SPE, V29, P3158, DOI 10.1109/TASLP.2021.3085119; Li L, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101862; Li XR, 2021, IEEE T MULTIMEDIA, V23, P4351, DOI 10.1109/TMM.2020.3042067; Li Zhang, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P905, DOI 10.1109/ICPECA51329.2021.9362566; Liao XW, 2021, IEEE-ACM T AUDIO SPE, V29, P3384, DOI 10.1109/TASLP.2021.3123885; Lin YT, 2022, Arxiv, DOI arXiv:2207.11363; Liu AA, 2022, IEEE T CIRC SYST VID, V32, P3685, DOI 10.1109/TCSVT.2021.3107035; Liu H, 2023, IEEE-ACM T AUDIO SPE, V31, P970, DOI 10.1109/TASLP.2023.3240661; Liu JZ, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-022-3741-3; Liu X, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11080390; Liu X, 2023, HUM SOC SCI COMMUN, V10, DOI 10.1057/s41599-023-01816-6; Liu Y., 2023, JAILBREAKING CHATGPT; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu ZN, 2019, IEEE ACCESS, V7, P107744, DOI 10.1109/ACCESS.2019.2932047; Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Madasu A., 2022, arXiv; Maddigan P, 2023, IEEE ACCESS, V11, P45181, DOI 10.1109/ACCESS.2023.3274199; Maddy ES, 2021, IEEE J-STARS, V14, P8566, DOI 10.1109/JSTARS.2021.3104389; Maitra M, 2008, IEEE T VEH TECHNOL, V57, P1834, DOI 10.1109/TVT.2007.907074; Mangina E., 2021, The IEEE global initiative on ethics of extended reality (XR) report-extended reality (XR) ethics in education, P1; Mao GW, 2019, IEEE ACCESS, V7, P111736, DOI 10.1109/ACCESS.2019.2934149; Mazzei A, 2022, IEEE T HUM-MACH SYST, V52, P973, DOI 10.1109/THMS.2022.3184400; Medeiros L, 2022, IEEE T HUM-MACH SYST, V52, P343, DOI 10.1109/THMS.2021.3113643; Mendel JM, 2021, IEEE T FUZZY SYST, V29, P3579, DOI 10.1109/TFUZZ.2021.3079503; Meng FQ, 2022, INT ARAB J INF TECHN, V19, P597, DOI 10.34028/iajit/19/4/4; Miklosik A, 2021, IEEE ACCESS, V9, P106530, DOI 10.1109/ACCESS.2021.3100885; Mirzaei M, 2019, IEEE T MED IMAGING, V38, P2744, DOI 10.1109/TMI.2019.2913194; Mishra Aakansha, 2023, IEEE Transactions on Artificial Intelligence, P81, DOI 10.1109/TAI.2022.3160418; Murtaza M, 2022, IEEE ACCESS, V10, P81323, DOI 10.1109/ACCESS.2022.3193938; Nam M, 2021, IEEE ACCESS, V9, P124931, DOI 10.1109/ACCESS.2021.3110524; Naren N., 2021, IEEE Internet of Things Magazine, V4, P4, DOI 10.1109/IOTM.0011.2100053; Nawaz HS, 2022, IEEE T CIRC SYST VID, V32, P6174, DOI 10.1109/TCSVT.2022.3162650; Ni QF, 2022, IEEE T NETW SCI ENG, V9, P1187, DOI 10.1109/TNSE.2021.3137353; Ni S., 2023, IEEE Trans. Artif. Intell.; Nie LQ, 2021, IEEE T IMAGE PROCESS, V30, P7732, DOI 10.1109/TIP.2021.3108724; Nie W, 2023, IEEE Trans. Multimedia; Ochs M, 2023, Soft Anal Evol Reeng, P834, DOI 10.1109/SANER56733.2023.00096; Oruche R, 2021, IEEE ACCESS, V9, P79400, DOI 10.1109/ACCESS.2021.3083583; Palasundram K, 2021, IEEE ACCESS, V9, P164949, DOI 10.1109/ACCESS.2021.3133495; Palasundram K, 2020, IEEE ACCESS, V8, P45738, DOI 10.1109/ACCESS.2020.2978551; Park C, 2020, IEEE ACCESS, V8, P116617, DOI 10.1109/ACCESS.2020.3004879; Qi Q, 2022, IEEE T EMERG TOP COM, V10, P886, DOI 10.1109/TETC.2021.3050770; Qian HJ, 2021, Arxiv, DOI arXiv:2009.13284; Ramaditiya A., 2021, PROC INT S ELECT SMA, P1; Reddy P. S. V., 2023, PROC INT C ARTIF INT, P1; Ren R, 2022, IEEE ACCESS, V10, P130542, DOI 10.1109/ACCESS.2022.3228772; Rizinski M, 2022, IEEE ACCESS, V10, P97531, DOI 10.1109/ACCESS.2022.3202889; Schneider ETR, 2021, COMP MED SY, P474, DOI 10.1109/CBMS52027.2021.00056; Saglam R. B., 2021, HCI international 2021-Posters, P391, DOI DOI 10.1007/978-3-030-78642-7_53; Sánchez L, 2021, IEEE LAT AM T, V19, P2037, DOI 10.1109/TLA.2021.9480145; Santos GA, 2022, IEEE ACCESS, V10, P8474, DOI 10.1109/ACCESS.2022.3143323; Shafeeg A., 2023, Indones J Comput Sci, V12, P22; Shalyminov I, 2021, IEEE-ACM T AUDIO SPE, V29, P2484, DOI 10.1109/TASLP.2021.3074779; Sharif A, 2021, IEEE INTERNET THINGS, V8, P17495, DOI 10.1109/JIOT.2021.3081555; Sharma S., 2022, IEEE Trans. Eng. Manag.; Sheth A, 2019, IEEE INTELL SYST, V34, P24, DOI [10.1109/MIS.2019.2905748, 10.1109/mis.2019.2905748]; Singh S., 2021, arXiv; Sitkrongwong P, 2020, IEEE ACCESS, V8, P87094, DOI 10.1109/ACCESS.2020.2993063; Sordoni A, 2015, Arxiv, DOI arXiv:1506.06714; Streeb D, 2022, IEEE T VIS COMPUT GR, V28, P3307, DOI 10.1109/TVCG.2020.3045560; Strobelt H, 2022, IEEE T VIS COMPUT GR, V28, P1106, DOI 10.1109/TVCG.2021.3114845; Su EZ, 2022, IEEE T BIO-MED ENG, V69, P2233, DOI 10.1109/TBME.2022.3140246; Sujana Y, 2023, IEEE ACCESS, V11, P10894, DOI 10.1109/ACCESS.2023.3234019; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Syu J.-H., 2023, IEEE Transactions on Consumer Electronics; Tanaka H, 2021, IEEE OPEN J ENG MED, V2, P65, DOI 10.1109/OJEMB.2021.3075567; Thakoor KA, 2021, IEEE T BIO-MED ENG, V68, P2456, DOI 10.1109/TBME.2020.3043215; Thisarani M., 2021, PROC IEEE INT C ENG, P1; Varolgunes U., 2023, IEEE ACCESS; Vartinen S., 2022, IEEE T GAMES; Vivek V., 2021, Big data management in Sensing: Applications in AI and IoT, P61; Wang FY, 2023, IEEE T COMPUT SOC SY, V10, P414, DOI 10.1109/TCSS.2023.3252679; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P831, DOI 10.1109/JAS.2023.123552; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang J., 2022, IEEE Trans. Computat. Social Syst., P1; Wang S, 2020, IEEE-ACM T AUDIO SPE, V28, P2598, DOI 10.1109/TASLP.2020.3016498; Wang WH, 2019, IEEE ACCESS, V7, P173485, DOI 10.1109/ACCESS.2019.2957057; Wang YM, 2019, IEEE ACCESS, V7, P34954, DOI 10.1109/ACCESS.2019.2904603; Wang Z, 2021, IEEE J-STARS, V14, P8386, DOI 10.1109/JSTARS.2021.3104267; Wazid M, 2022, ICT EXPRESS, V8, P313, DOI 10.1016/j.icte.2022.04.007; Wu AM, 2021, IEEE T CIRC SYST VID, V31, P2438, DOI 10.1109/TCSVT.2020.3020877; Wu FS, 2022, IEEE T COMPUT SOC SY, V9, P458, DOI 10.1109/TCSS.2021.3106003; Wu JY, 2019, IEEE SIGNAL PROC LET, V26, P1887, DOI 10.1109/LSP.2019.2951950; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xie J, 2019, IEEE ACCESS, V7, P43100, DOI 10.1109/ACCESS.2019.2906659; Xing BW, 2022, IEEE TETCI, V6, P1092, DOI 10.1109/TETCI.2022.3156989; Xu WY, 2022, IEEE SIGNAL PROC LET, V29, P2677, DOI 10.1109/LSP.2022.3233005; Yadav A, 2021, AI OPEN, V2, P85, DOI 10.1016/j.aiopen.2021.05.001; Yan HY, 2019, IEEE ACCESS, V7, P118690, DOI 10.1109/ACCESS.2019.2936630; Yang M, 2021, IEEE T NEUR NET LEAR, V32, P2744, DOI 10.1109/TNNLS.2020.3008037; Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426; Yang T, 2023, IEEE T COMPUT AID D, V42, P509, DOI 10.1109/TCAD.2022.3181541; Yazdinejad A., 2023, IEEE Trans. Consum. Electron.; Ye Y, 2023, IEEE ACCESS, V11, P55748, DOI 10.1109/ACCESS.2023.3282111; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]; Zhang B, 2017, IEEE-ACM T AUDIO SPE, V25, P2424, DOI 10.1109/TASLP.2017.2751420; Zhang C, 2023, IEEE-ACM T AUDIO SPE, V31, P1234, DOI 10.1109/TASLP.2023.3250825; Zhang HP, 2023, Arxiv, DOI arXiv:2304.04193; Zhang HW, 2023, COMPUT SECUR, V129, DOI 10.1016/j.cose.2023.103187; Zhang L, 2020, IEEE ACCESS, V8, P123882, DOI 10.1109/ACCESS.2020.3004152; Zhang L, 2023, IEEE T NEUR NET LEAR, V34, P7810, DOI 10.1109/TNNLS.2022.3146443; Zhang YF, 2021, IEEE T IMAGE PROCESS, V30, P617, DOI 10.1109/TIP.2020.3038354; Zhao Y, 2020, CONF TECHNOL APPL, P228, DOI 10.1109/TAAI51410.2020.00049; Zhou QY, 2023, IEEE T CIRC SYST VID, V33, P804, DOI 10.1109/TCSVT.2022.3206476; Zhu HY, 2022, IEEE T IND INFORM, V18, P3387, DOI 10.1109/TII.2021.3097183; Zhuomin Zhang, 2022, IEEE BITS the Information Theory Magazine, V2, P36, DOI 10.1109/MBITS.2022.3197102; Zierock B., 2023, ChatGPT and content creation automation	190	1	1	77	77	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2023	11						143657	143682		10.1109/ACCESS.2023.3339553	http://dx.doi.org/10.1109/ACCESS.2023.3339553			26	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	DK2O0		gold			2024-07-03	WOS:001131868100001
J	Katzir, R				Katzir, Roni			Why Large Language Models Are Poor Theories of Human Linguistic Cognition: A Reply to Piantadosi	BIOLINGUISTICS			English	Article						large language models; generative linguistics; learning; generalization; typology; competence; performance	ACCEPTABILITY; IDEAS	In a recent manuscript entitled "Modern language models refute Chomsky's approach to language", Steven Piantadosi proposes that large language models such as GPT-3 can serve as serious theories of human linguistic cognition. In fact, he maintains that these models are significantly better linguistic theories than proposals emerging from within generative linguistics. The present note explains why this claim is wrong.	[Katzir, Roni] Tel Aviv Univ, Dept Linguist, Tel Aviv, Israel; [Katzir, Roni] Tel Aviv Univ, Sagol Sch Neurosci, Tel Aviv, Israel	Tel Aviv University; Tel Aviv University	Katzir, R (corresponding author), Tel Aviv Univ, Lester & Sally Entins Fac Humanities, Dept Linguist, POB 39040, IL-69978 Tel Aviv, Israel.	rkatzir@tauex.tau.ac.il		Katzir, Roni/0000-0002-0241-1896				Baroni M., 2022, Algebraic Structures in Natural Language, P1; BARWISE J, 1981, LINGUIST PHILOS, V4, P159, DOI 10.1007/BF00350139; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berwick RC, 2018, STUD GENERAT GRAMM, V129, P177, DOI 10.1515/9781501506925-181; Carcassi F, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.13027; Chomsky N., 1965, Aspects of the Theory of Syntax; CHOMSKY N, 1988, LANGUAGE PROBLEMS KN; Chomsky Noam., 1975, CURRENT ISSUES LINGU; Evans N, 2009, BEHAV BRAIN SCI, V32, P429, DOI 10.1017/S0140525X0999094X; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Heinz J, 2013, TOP COGN SCI, V5, P111, DOI 10.1111/tops.12000; Hsu AS, 2013, TOP COGN SCI, V5, P35, DOI 10.1111/tops.12005; Katzir R., 2014, Journal of Language Modelling, V2, P213; Katzir R., 2023, A reply to Piantadosi; KEENAN EL, 1986, LINGUIST PHILOS, V9, P253, DOI 10.1007/BF00630273; Kodner J, 2023, Arxiv, DOI [arXiv:2308.03228, 10.48550/arXiv.2308.03228, DOI 10.48550/ARXIV.2308.03228]; Lakretz Y, 2021, COGNITION, V213, DOI 10.1016/j.cognition.2021.104699; Lan N., 2022, Large language models and the argument from the poverty of the stimulus; Lan N, 2022, T ASSOC COMPUT LING, V10, P785, DOI 10.1162/tacl_a_00489; LEES RB, 1957, LANGUAGE, V33, P375, DOI 10.2307/411160; Miller G. A., 1963, HDB MATH PSYCHOL, V2, P419; Milway D., 2023, A response to Piantadosi; Moro A, 2023, CORTEX, V167, P82, DOI 10.1016/j.cortex.2023.07.003; Pearl L, 2013, LANG ACQUIS, V20, P23, DOI 10.1080/10489223.2012.738742; Pérez-Leroux AT, 2014, LANGUAGE, V90, pE115, DOI 10.1353/lan.2014.0049; Phillips C, 2013, EXPERIMENTAL SYNTAX AND ISLAND EFFECTS, P64; Piantadosi S. T., From fieldwork fieldwork to linguistic theory: A tribute to Dan Everett; Pol IV, 2023, COGNITION, V232, DOI 10.1016/j.cognition.2022.105150; Rasin E, 2020, J LINGUIST, V56, P745, DOI 10.1017/S0022226720000146; Rawski J., 2023, Modern language models refute nothing; Ross J. R., 1967, THESIS MIT; Sprouse J, 2018, LINGUIST REV, V35, P575, DOI 10.1515/tlr-2018-0005; Sprouse J, 2012, LANGUAGE, V88, P82, DOI 10.1353/lan.2012.0004; Steinert-Threlkeld S, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101335; Steinert-Threlkeld S, 2019, SEMANT PRAGMAT, V12; van de Pol I., 2021, P ANN M COGN SCI SOC, V43, P756; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Wilcox EG., 2022, Linguistic Inquiry, V1, DOI DOI 10.1162/LING_A_00491; Yedetore A., 2023, arXiv, DOI [10.18653/v1/2023.acl-long.521, DOI 10.18653/V1/2023.ACL-LONG.521]; YNGVE VICTOR H., 1960, PROC AMER PHIL SOC, V104, P444	40	1	1	1	1	UNIV CYPRUS, DEPT ENGLISH STUDIES	NICOSIA	UNIV CYPRUS, DEPT ENGLISH STUDIES, NICOSIA, 1678, CYPRUS	1450-3417			BIOLINGUISTICS	Biolinguistics		2023	17								e13153	10.5964/bioling.13153	http://dx.doi.org/10.5964/bioling.13153			12	Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	HT1C6		gold			2024-07-03	WOS:001161655300007
C	Vachtsevanou, D; Lemee, J; Rot, R; Mayer, S; Ciortea, A; Ramanathan, G			ACM	Vachtsevanou, Danai; Lemee, Jeremy; Rot, Raffael; Mayer, Simon; Ciortea, Andrei; Ramanathan, Ganesh			HyperBrain: Human-inspired Hypermedia Guidance using a Large Language Model	34TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, HT 2023			English	Proceedings Paper	34th ACM Conference on Hypertext and Social Media (HT)	SEP 04-08, 2023	Max Planck Inst Art Hist, Bibliotheca Hertziana, Rome, ITALY	Assoc Comp Machinery, Knowledge Media Inst, Open Univ, Hypertext Steering Comm, SigWeb	Max Planck Inst Art Hist, Bibliotheca Hertziana	Hypermedia; Large Language Model; HATEOAS; Web of Things		We present HyperBrain, a hypermedia client that autonomously navigates hypermedia environments to achieve user goals specified in natural language. To achieve this, the client makes use of a large language model to decide which of the available hypermedia controls should be used within a given application context. In a demonstrative scenario, we show the client's ability to autonomously select and follow simple hyperlinks towards a high-level goal, successfully traversing the hypermedia structure of Wikipedia given only the markup of the respective resources. We show that hypermedia navigation based on language models is effective, and propose that this should be considered as a step to create hypermedia environments that are used by autonomous clients alongside people.	[Vachtsevanou, Danai; Lemee, Jeremy; Rot, Raffael; Mayer, Simon; Ciortea, Andrei; Ramanathan, Ganesh] Univ St Gallen, St Gallen, Switzerland	University of St Gallen	Vachtsevanou, D (corresponding author), Univ St Gallen, St Gallen, Switzerland.	danai.vachtsevanou@unisg.ch; jeremy.lemee@unisg.ch; raffael.rot@student.unisg.ch; simon.mayer@unisg.ch; andrei.ciortea@unisg.ch; ganesh.ramanathan@student.unisg.ch			Swiss National Science Fund [189474]; EU [957218]	Swiss National Science Fund(Swiss National Science Foundation (SNSF)); EU(European Union (EU))	This article emerged as one of the consequences of joint discussion by two working groups at the Dagstuhl Seminar on "Agents on the Web"6 held in February 2023, and from further explorations across seven research groups in different fields of Computer Science. We would like to thank the organizers of the Dagstuhl Seminar (Olivier Boissier, Andrei Ciortea, Andreas Harth, Alessandro Ricci) as well as the members of those working groups: Samuele Burattini, Brian Logan, Matthias Kovatsch, Sebastian Schmid, Andreas Harth, Daniel Schraudner, Rem Collier, Mahda Noura, Cleber Jorge Amaral, and Jean-Paul Calbimonte; it is a highly enjoyable, and a privilege, to work with you! This research was furthermore supported by the Swiss National Science Fund (HyperAgents, Project #189474), and the EU Horizon 2020 program (IntellIoT, Grant #957218).	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Fielding RT, 2002, ACM T INTERNET TECHN, V2, P115, DOI [DOI 10.1145/514183.514185, 10.1145/514183.514185]; Masinter Larry M., 2000, RFC 2854, DOI [10.17487/RFC2854, DOI 10.17487/RFC2854]; Mayer Simon, 2012, P 3 INT WORKSH WEB T; Mayer Simon, 2014, Ph. D. Dissertation; McCool Michael, 2023, Web of Things (WoT) Thing Description 1.1; Miller D., 2021, OpenAPI Specification v3.1.0; WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94	8	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0232-7				2023										10.1145/3603163.3609077	http://dx.doi.org/10.1145/3603163.3609077			5	Computer Science, Information Systems; Communication; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Communication	BW2LW					2024-07-03	WOS:001118858800003
C	Wang, ZX; Denny, P; Leinonen, J; Luxton-Reilly, A		Babu, C; Goel, N; Karkare, A		Wang, Zixuan; Denny, Paul; Leinonen, Juho; Luxton-Reilly, Andrew			Leveraging Large Language Models for Analysis of Student Course Feedback	PROCEEDINGS OF THE 16TH ANNUAL ACM INDIA COMPUTE CONFERENCE, COMPUTE 2023			English	Proceedings Paper	16th Annual ACM India Compute Conference (COMPUTE)	DEC 09-11, 2023	Univ Hyderabad, Hyderabad, INDIA	Indian Inst Technol Madras, BSc Degree, Virtual Labs, Persistent, NPTEL, ACM India I SIGCSE, ACM In Cooperat	Univ Hyderabad	Student Evaluation of Teaching; Large Language Model; Student Feedback; Natural Language Processing		This study investigates the use of large language models, specifically ChatGPT, to analyse the feedback from a Summative Evaluation Tool (SET) used to collect student feedback on the quality of teaching. We find that these models enhance comprehension of SET scores and the impact of context on student evaluations. This work aims to reveal hidden patterns in student evaluation data, demonstrating a positive first step towards automated, detailed analysis of student feedback.	[Wang, Zixuan; Denny, Paul; Leinonen, Juho; Luxton-Reilly, Andrew] Univ Auckland, Auckland, New Zealand	University of Auckland	Wang, ZX (corresponding author), Univ Auckland, Auckland, New Zealand.	zwan843@aucklanduni.ac.nz; paul@cs.auckland.ac.nz; juho.leinonen@auckland.ac.nz; andrew@cs.auckland.ac.nz	Leinonen, Juho/D-2162-2018; Luxton-Reilly, Andrew/ABC-5342-2021	Leinonen, Juho/0000-0001-6829-9449; Luxton-Reilly, Andrew/0000-0001-8269-2909; Denny, Paul/0000-0002-5150-9806; Wang, Zixuan/0009-0002-0815-8673				Cunningham-Nelson S, 2021, ASSESS EVAL HIGH EDU, V46, P685, DOI 10.1080/02602938.2020.1805409; Godwin-Jones R, 2023, LANG LEARN TECHNOL, V27, P6; Grebennikov L, 2013, TEACH HIGH EDUC, V18, P606, DOI 10.1080/13562517.2013.774353; Hornstein HA, 2017, COGENT EDUC, V4, DOI 10.1080/2331186X.2017.1304016; Kant N, 2018, Arxiv, DOI arXiv:1812.01207; Morgan M, 2017, ITICSE-WGR'17: PROCEEDINGS OF THE 2017 ITICSE CONFERENCE WORKING GROUP REPORTS, P1, DOI 10.1145/3174781.3174782; Rybinski K, 2021, ASSESS EVAL HIGH EDU, V46, P1127, DOI 10.1080/02602938.2020.1844866; Steyn C, 2019, ASSESS EVAL HIGH EDU, V44, P11, DOI 10.1080/02602938.2018.1466266; Stroebe W, 2020, BASIC APPL SOC PSYCH, V42, P276, DOI 10.1080/01973533.2020.1756817; Uttl B, 2017, STUD EDUC EVAL, V54, P22, DOI 10.1016/j.stueduc.2016.08.007; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105	11	1	1	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0840-4				2023							76	79		10.1145/3627217.3627221	http://dx.doi.org/10.1145/3627217.3627221			4	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW6LB					2024-07-03	WOS:001176678700018
J	Sun, TX; Zhang, XT; He, ZF; Li, P; Cheng, QY; Liu, XY; Yan, H; Shao, YF; Tang, Q; Zhang, SD; Zhao, XJ; Chen, K; Zheng, YN; Zhou, ZJ; Li, RX; Zhan, J; Zhou, YH; Li, LY; Yang, XG; Wu, LL; Yin, ZY; Huang, XJ; Jiang, YG; Qiu, XP				Sun, Tianxiang; Zhang, Xiaotian; He, Zhengfu; Li, Peng; Cheng, Qinyuan; Liu, Xiangyang; Yan, Hang; Shao, Yunfan; Tang, Qiong; Zhang, Shiduo; Zhao, Xingjian; Chen, Ke; Zheng, Yining; Zhou, Zhejian; Li, Ruixiao; Zhan, Jun; Zhou, Yunhua; Li, Linyang; Yang, Xiaogui; Wu, Lingling; Yin, Zhangyue; Huang, Xuanjing; Jiang, Yu-Gang; Qiu, Xipeng			MOSS: An Open Conversational Large Language Model	MACHINE INTELLIGENCE RESEARCH			English	Article; Early Access						Large language models; natural language processing; pre-training; alignment; chatGPT; MOSS		Conversational large language models (LLMs) such as ChatGPT and GPT-4 have recently exhibited remarkable capabilities across various domains, capturing widespread attention from the public. To facilitate this line of research, in this paper, we report the development of MOSS, an open-sourced conversational LLM that contains 16 B parameters and can perform a variety of instructions in multi-turn interactions with humans. The base model of MOSS is pre-trained on large-scale unlabeled English, Chinese, and code data. To optimize the model for dialogue, we generate 1.1 M synthetic conversations based on user prompts collected through our earlier versions of the model API. We then perform preference-aware training on preference data annotated from AI feedback. Evaluation results on real-world use cases and academic benchmarks demonstrate the effectiveness of the proposed approaches. In addition, we present an effective practice to augment MOSS with several external tools. Through the development of MOSS, we have established a complete technical roadmap for large language models from pre-training, supervised fine-tuning to alignment, verifying the feasibility of chatGPT under resource-limited conditions and providing a reference for both the academic and industrial communities. Model weights and code are publicly available at https://github.com/OpenMOSS/MOSS.	[Sun, Tianxiang; Zhang, Xiaotian; He, Zhengfu; Li, Peng; Cheng, Qinyuan; Liu, Xiangyang; Yan, Hang; Shao, Yunfan; Tang, Qiong; Zhang, Shiduo; Zhao, Xingjian; Chen, Ke; Zheng, Yining; Zhou, Zhejian; Li, Ruixiao; Zhan, Jun; Zhou, Yunhua; Li, Linyang; Yang, Xiaogui; Wu, Lingling; Yin, Zhangyue; Huang, Xuanjing; Jiang, Yu-Gang; Qiu, Xipeng] Fudan Univ, Shanghai 200438, Peoples R China	Fudan University	Qiu, XP (corresponding author), Fudan Univ, Shanghai 200438, Peoples R China.	txsun19@fudan.edu.cn; zxt235813@163.com; zfhe19@fudan.edu.cn; pli21@m.fudan.edu.cn; chengqy2019@foxmail.com; xyliu22@m.fudan.edu.cn; yanhang@pjlab.org.cn; yfshao19@fudan.edu.cn; qtang22@m.fudan.edu.cn; sdzhang@m.fudan.edu.cn; zhaoxj20@fudan.edu.cn; kchen21@m.fudan.edu.cn; ynzheng19@fudan.edu.cn; zhejianz@usc.edu; cgruixiao@outlook.com; 22210240366@m.fudan.edu.cn; zhouyunhua@pjlab.org.cn; linyangli19@fudan.edu.cn; yangxiaogui@pjlab.org.cn; linglingwu21@m.fudan.edu.cn; yinzy21@m.fudan.edu.cn; xjhuang@fudan.edu.cn; ygj@fudan.edu.cn; xpqiu@fudan.edu.cn			National Natural Science Foundation of China [62022027]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (No. 62022027). We also extend our gratitude to the Shanghai Artificial Intelligence Laboratory, China, for providing the computational resources.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Andrychowicz M., 2017, ADV NEURAL INFORM PR, V30, P1; Askell A, 2021, Arxiv, DOI [arXiv:2112.00861, DOI 10.48550/ARXIV.2112.00861]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen TQ, 2016, Arxiv, DOI arXiv:1604.06174; Cheng X. Yang, 2023, FINDINGS ASS COMPUTA, P11122; Chowdhery A, 2023, J MACH LEARN RES, V24; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gehman S, 2020, M ASS FOR COMPUTATIO; Glaese A, 2022, arXiv; Hendrycks D., 2021, P 9 INT C LEARN REPR; Hoffmann J., 2022, P 36 INT C NEUR INF; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kingma D. P., 2017, ARXIV; Kordi Yeganeh, 2022, P 2022 C EMPIRICAL M, P5085; Lin S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3214; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Mialon G., 2023, arXiv; Mihalcea R., 2004, P 2004 C EMP METH NA, P404, DOI DOI 10.3115/1219044.1219064; Nakano R., arXiv; Nijkamp E., 2023, P 11 INT C LEARN REP; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Schick T., 2023, P 37 C NEUR INF PROC; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Sennrich R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1715; Shao YF, 2022, Arxiv, DOI arXiv:2109.05729; Stiennon N, 2022, Arxiv, DOI arXiv:2009.01325; Sutawika L., 2022, P 10 INT C LEARN REP; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang YZ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P13484; Wei J., 2022, P 10 INT C LEARN REP, P1; Wei J., 2022, Transactions on Machine Learning Research, V2022; Yin Z Y., 2023, Proceedings of the Findings of the Association for Computational Linguistics, P8653; Zeng A., 2023, P 11 INT C LEARN REP; Zhang C., 2022, P 36 INT C NEUR INF; Zhang T. J., 2023, P 40 INT C MACH LEAR, P41414; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	45	0	0	3	3	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2731-538X	2731-5398		MACH INTELL RES	Mach. Intell. Res.	2024 MAY 20	2024										10.1007/s11633-024-1502-8	http://dx.doi.org/10.1007/s11633-024-1502-8		MAY 2024	18	Automation & Control Systems; Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Automation & Control Systems; Computer Science	RM9Z6					2024-07-03	WOS:001228210500001
J	Makridakis, S; Petropoulos, F; Kang, YF				Makridakis, Spyros; Petropoulos, Fotios; Kang, Yanfei			Large Language Models: Their Success and Impact	FORECASTING			English	Article						Large Language Models; Forecasting; ChatGPT		ChatGPT, a state-of-the-art large language model (LLM), is revolutionizing the AI field by exhibiting humanlike skills in a range of tasks that include understanding and answering natural language questions, translating languages, writing code, passing professional exams, and even composing poetry, among its other abilities. ChatGPT has gained an immense popularity since its launch, amassing 100 million active monthly users in just two months, thereby establishing itself as the fastest-growing consumer application to date. This paper discusses the reasons for its success as well as the future prospects of similar large language models (LLMs), with an emphasis on their potential impact on forecasting, a specialized and domain-specific field. This is achieved by first comparing the correctness of the answers of the standard ChatGPT and a custom one, trained using published papers from a subfield of forecasting where the answers to the questions asked are known, allowing us to determine their correctness compared to those of the two ChatGPT versions. Then, we also compare the responses of the two versions on how judgmental adjustments to the statistical/ML forecasts should be applied by firms to improve their accuracy. The paper concludes by considering the future of LLMs and their impact on all aspects of our life and work, as well as on the field of forecasting specifically. Finally, the conclusion section is generated by ChatGPT, which was provided with a condensed version of this paper and asked to write a four-paragraph conclusion.	[Makridakis, Spyros; Petropoulos, Fotios] Univ Nicosia, Inst Future, CY-2414 Nicosia, Cyprus; [Petropoulos, Fotios] Univ Bath, Sch Management, Bath BA2 7AY, England; [Kang, Yanfei] Beihang Univ, Sch Econ & Management, Beijing 100191, Peoples R China	University of Nicosia; University of Bath; Beihang University	Kang, YF (corresponding author), Beihang Univ, Sch Econ & Management, Beijing 100191, Peoples R China.	makridakis.s@unic.ac.cy; fotios@bath.edu; yanfeikang@buaa.edu.cn	Kang, Yanfei/ITT-3438-2023; Petropoulos, Fotios/AAB-2399-2021	Kang, Yanfei/0000-0001-8769-6650; Makridakis, Spyros/0000-0003-2519-8095; Petropoulos, Fotios/0000-0003-3039-4955	The authors would like to thank Bohan Zhang for his helpful comments and discussions.	The authors would like to thank Bohan Zhang for his helpful comments and discussions.	The authors would like to thank Bohan Zhang for his helpful comments and discussions.	Eliot L., 2023, Forbes; Fildes R, 2009, INT J FORECASTING, V25, P3, DOI 10.1016/j.ijforecast.2008.11.010; Gupta K., 2023, Marktechpost; Heaven W., 2023, MIT TECHNOL REV; Huang J., 2022, arXiv; LeCun Y., 2020, P KEYN TALK PRES 37; Makridakis S, 2000, INT J FORECASTING, V16, P451, DOI 10.1016/S0169-2070(00)00057-1; Makridakis S, 2022, INT J FORECASTING, V38, P1279, DOI 10.1016/j.ijforecast.2022.04.005; Makridakis S, 2022, INT J FORECASTING, V38, P1346, DOI 10.1016/j.ijforecast.2021.11.013; Mills S., 2023, The Conversation; Petropoulos F, 2020, INT J FORECASTING, V36, P3, DOI 10.1016/j.ijforecast.2019.05.005; Petropoulos F, 2016, EUR J OPER RES, V249, P842, DOI 10.1016/j.ejor.2015.06.002; Reuters GM, 2023, Explores Using ChatGPT in Vehicle; Reuters; Toews R, 2023, The next generation of large language models; Warren T., 2023, Microsoft and Google Are about to Open an AI Battle; The Verge; Zurcher A., 2023, BBC	16	4	4	62	103	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2571-9394		FORECASTING-BASEL	Forecasting	SEP	2023	5	3					536	549		10.3390/forecast5030030	http://dx.doi.org/10.3390/forecast5030030			14	Multidisciplinary Sciences	Emerging Sources Citation Index (ESCI)	Science & Technology - Other Topics	S6AJ3		Green Submitted, gold			2024-07-03	WOS:001071967500001
J	Organisciak, P; Acar, S; Dumas, D; Berthiaume, K				Organisciak, Peter; Acar, Selcuk; Dumas, Denis; Berthiaume, Kelly			Beyond semantic distance: Automated scoring of divergent thinking greatly improves with large language models	THINKING SKILLS AND CREATIVITY			English	Article						Divergent thinking; Alternate uses test; Large -language models; Automated scoring	TORRANCE TESTS; CREATIVE-THINKING; ORDER; ACHIEVEMENT; IDEAS; TIME	Automated scoring for divergent thinking (DT) seeks to overcome a key obstacle to creativity measurement: the effort, cost, and reliability of scoring open-ended tests. For a common test of DT, the Alternate Uses Task (AUT), the primary automated approach casts the problem as a semantic distance between a prompt and the resulting idea in a text model. This work presents an alternative approach that greatly surpasses the performance of the best existing semantic distance approaches. Our system, Ocsai, fine-tunes deep neural network-based large-language models (LLMs) on human-judged responses. Trained and evaluated against one of the largest collections of human-judged AUT responses, with 27 thousand responses collected from nine past studies, our fine-tuned large-language-models achieved up to r = 0.81 correlation with human raters, greatly surpassing current systems (r = 0.12-0.26). Further, learning transfers well to new test items and the approach is still robust with small numbers of training labels. We also compare prompt-based zero-shot and few-shot approaches, using GPT-3, ChatGPT, and GPT-4. This work also suggests a limit to the underlying assumptions of the semantic distance model, showing that a purely semantic approach that uses the stronger language representation of LLMs, while still improving on existing systems, does not achieve comparable improvements to our fine-tuned system. The increase in performance can support stronger applications and interventions in DT and opens the space of automated DT scoring to new areas for improving and understanding this branch of methods.	[Organisciak, Peter] Univ Denver, Denver, CO USA; [Acar, Selcuk; Berthiaume, Kelly] Univ North Texas, Denton, TX 76203 USA; [Dumas, Denis] Univ Georgia, Athens, GA USA; [Organisciak, Peter] Univ Denver, Dept Res Methods & Informat Sci, 1999 E Evans Ave, Denver, CO 80208 USA	University of Denver; University of North Texas System; University of North Texas Denton; University System of Georgia; University of Georgia; University of Denver	Organisciak, P (corresponding author), Univ Denver, Dept Res Methods & Informat Sci, 1999 E Evans Ave, Denver, CO 80208 USA.	peter.organisciak@du.edu	; Organisciak, Peter/ABK-6113-2022	Dumas, Denis/0000-0002-8446-4720; Organisciak, Peter/0000-0002-9058-2280	Institute of Education Sciences (IES);  [R305A200199]	Institute of Education Sciences (IES)(US Department of EducationInstitute of Education Sciences (IES)); 	This work was funded by the Institute of Education Sciences (IES) , grant #R305A200199.	Acar S, 2023, CREATIVITY RES J, V35, P1, DOI 10.1080/10400419.2022.2044656; Acar S, 2021, GIFTED CHILD QUART, DOI 10.1177/00169862211061874; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2018, PROCEEDINGS; [Anonymous], 2005, TREC: Experiment and evaluation in information retrieval; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Beaty RE, 2018, P NATL ACAD SCI USA, V115, P1087, DOI 10.1073/pnas.1713532115; Beaty RE, 2012, PSYCHOL AESTHET CREA, V6, P309, DOI 10.1037/a0029171; Benedek M, 2013, PSYCHOL AESTHET CREA, V7, P341, DOI 10.1037/a0033644; BigScience, 2022, BIGSCIENCE LANG OP S; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buczak P, 2023, J CREATIVE BEHAV, V57, P17, DOI 10.1002/jocb.559; Cramond B, 2005, GIFTED CHILD QUART, V49, P283, DOI 10.1177/001698620504900402; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Downie JS, 2008, ACOUST SCI TECHNOL, V29, P247, DOI 10.1250/ast.29.247; Dumas D, 2023, J CREATIVE BEHAV, V57, P419, DOI 10.1002/jocb.588; Dumas D, 2021, PSYCHOL AESTHET CREA, V15, P645, DOI 10.1037/aca0000319; Dumas D, 2014, THINK SKILLS CREAT, V14, P56, DOI 10.1016/j.tsc.2014.09.003; Forthmann B., 2022, ARXIV, DOI [10.31234/osf.io/byj8c, DOI 10.31234/OSF.IO/BYJ8C]; Forthmann B, 2019, J CREATIVE BEHAV, V53, P559, DOI 10.1002/jocb.240; Guilford JP, 1950, AM PSYCHOL, V5, P444, DOI 10.1037/h0063487; Guilford J. P., 1958, Consequences: Manual for administration, scoring, and interpretation; Gunning D, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aay7120; Gururangan S, 2020, Arxiv, DOI [arXiv:2004.10964, DOI 10.48550/ARXIV.2004.10964]; Hass RW, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01343; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kapoor S, 2022, arXiv; Kim KH, 2008, J CREATIVE BEHAV, V42, P106, DOI 10.1002/j.2162-6057.2008.tb01290.x; Kim KH, 2006, CREATIVITY RES J, V18, P3, DOI 10.1207/s15326934crj1801_2; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Maio S, 2020, CREATIVITY RES J, V32, P201, DOI 10.1080/10400419.2020.1818492; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mohr AH, 2016, SOC SCI COMPUT REV, V34, P347, DOI 10.1177/0894439315588736; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Ni Jianmo, 2021, arXiv; Organisciak P, 2023, INFORM LEARN SCI, V124, P25, DOI 10.1108/ILS-06-2022-0082; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Parker R., 2011, ENGLISH GIGAWORD; Paulus D. H., 1970, Final Report; Paulus D. H., 1968, Gifted Child Quarterly, V12, P79, DOI [10.1177/001698626801200202, DOI 10.1177/001698626801200202]; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Plucker J. A., 2022, HDB CREATIVITY ASSES; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Roemmele M., 2011, 2011 AAAI SPRING S S; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Runco M., 2016, Creativity Theories-Research-Applications, V3, P4, DOI [10.1515/ctra-2016-0001, DOI 10.1515/CTRA-2016-0001]; Runco M.A., 2008, New Horizons in Education, V56; Runco M.A., 1991, DIVERGENT THINKING; RUNCO MA, 1992, EDUC PSYCHOL MEAS, V52, P213, DOI 10.1177/001316449205200126; Runco MA, 2012, CREATIVITY RES J, V24, P66, DOI 10.1080/10400419.2012.652929; Runco MA, 2010, CREATIVITY RES J, V22, P361, DOI 10.1080/10400419.2010.523393; Said-Metwaly S, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000507; Shaw A, 2021, THINK SKILLS CREAT, V40, DOI 10.1016/j.tsc.2021.100789; Silvia P. J., 2008, Psychology of Aesthetics, Creativity, and the Arts, V2, P68, DOI [10.1037/1931-3896.2.2.68, DOI 10.1037/1931-3896.2.2.68, 10.1037]; Silvia PJ, 2017, J CREATIVE BEHAV, V51, P216, DOI 10.1002/jocb.101; Silvia PJ, 2011, THINK SKILLS CREAT, V6, P24, DOI 10.1016/j.tsc.2010.06.001; Silvia PJ, 2009, J RES PERS, V43, P1087, DOI 10.1016/j.jrp.2009.04.015; Snyder HT, 2019, PSYCHOL AESTHET CREA, V13, P133, DOI 10.1037/aca0000228; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Stevenson C., 2020, Automated AUT scoring using a big data variant of the Consensual Assessment Technique: Final technical report; Torrance E.P., 1980, The Creative Child and Adult Quarterly, V3, P148; Torrance E.P., 2008, TORRANCE TESTS CREAT; TORRANCE EP, 1972, J CREATIVE BEHAV, V6, P236, DOI 10.1002/j.2162-6057.1972.tb00936.x; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Veale M, 2021, COMPUTER LAW REV INT, V22, P97, DOI DOI 10.9785/CRI-2021-220402; Wallach MA., 1965, Modes of thinking in young children: A study of the creativity-intelligence distinction; Wang A, 2019, ADV NEUR IN, V32; Yang ZL, 2019, ADV NEUR IN, V32; Zaccaro SJ, 2015, LEADERSHIP QUART, V26, P342, DOI 10.1016/j.leaqua.2015.03.007	84	30	30	53	81	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1871-1871	1878-0423		THINK SKILLS CREAT	Think. Skills Creat.	SEP	2023	49								101356	10.1016/j.tsc.2023.101356	http://dx.doi.org/10.1016/j.tsc.2023.101356		JUN 2023	17	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	Q7DK7					2024-07-03	WOS:001059089700001
J	Corda, E; Massa, SM; Riboni, D				Corda, Erica; Massa, Silvia M.; Riboni, Daniele			Context-Aware Behavioral Tips to Improve Sleep Quality via Machine Learning and Large Language Models	FUTURE INTERNET			English	Article						pervasive healthcare; behavior change; sleep quality forecasting; machine learning; large language models	HEALTH	As several studies demonstrate, good sleep quality is essential for individuals' well-being, as a lack of restoring sleep may disrupt different physical, mental, and social dimensions of health. For this reason, there is increasing interest in tools for the monitoring of sleep based on personal sensors. However, there are currently few context-aware methods to help individuals to improve their sleep quality through behavior change tips. In order to tackle this challenge, in this paper, we propose a system that couples machine learning algorithms and large language models to forecast the next night's sleep quality, and to provide context-aware behavior change tips to improve sleep. In order to encourage adherence and to increase trust, our system includes the use of large language models to describe the conditions that the machine learning algorithm finds harmful to sleep health, and to explain why the behavior change tips are generated as a consequence. We develop a prototype of our system, including a smartphone application, and perform experiments with a set of users. Results show that our system's forecast is correlated to the actual sleep quality. Moreover, a preliminary user study suggests that the use of large language models in our system is useful in increasing trust and engagement.	[Corda, Erica; Massa, Silvia M.; Riboni, Daniele] Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy	University of Cagliari	Massa, SM; Riboni, D (corresponding author), Univ Cagliari, Dept Math & Comp Sci, Via Osped 72, I-09124 Cagliari, Italy.	erica.corda@gmail.com; silviam.massa@unica.it; riboni@unica.it		Riboni, Daniele/0000-0002-0695-2040	National Recovery and Resilience Plan (NRRP)	National Recovery and Resilience Plan (NRRP)	The authors would like to thank the anonymous reviewers for their insightful comments and suggestions to improve the technical content and presentation of this paper.	Alamoudi D, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/44123; Arora A, 2020, ARAB J SCI ENG, V45, P10793, DOI 10.1007/s13369-020-04877-w; Bachechi C., 2020, P 2020 IEEEACS 17 IN, P1; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Besedovsky L, 2012, PFLUG ARCH EUR J PHY, V463, P121, DOI 10.1007/s00424-011-1044-0; Bixler E, 2009, SLEEP MED, V10, pS3, DOI 10.1016/j.sleep.2009.07.005; Boussard J, 2019, IEEE SIG PROC MED, DOI 10.1109/spmb47826.2019.9037854; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Chang XM, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3392049; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Diekelmann S, 2014, FRONT SYST NEUROSCI, V8, DOI 10.3389/fnsys.2014.00046; Gordon AM, 2021, SLEEP MED REV, V57, DOI 10.1016/j.smrv.2021.101428; Grandner MA, 2017, SLEEP MED CLIN, V12, P1, DOI 10.1016/j.jsmc.2016.10.012; Jany Rafsan, 2022, 2022 25th International Conference on Computer and Information Technology (ICCIT), P248, DOI 10.1109/ICCIT57492.2022.10055956; Joshi A., 2015, Brit. J. Appl. Sci. Technol., V7, P396, DOI [10.9734/BJAST/2015/14975, DOI 10.9734/BJAST/2015/14975]; Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040; Kent RG, 2015, ANN BEHAV MED, V49, P912, DOI 10.1007/s12160-015-9711-6; Khodabandehloo E, 2021, FUTURE GENER COMP SY, V116, P168, DOI 10.1016/j.future.2020.10.030; Kim TW, 2015, INT J ENDOCRINOL, V2015, DOI 10.1155/2015/591729; Liew SC, 2021, SLEEP MED, V77, P192, DOI 10.1016/j.sleep.2020.07.048; Luyster FS, 2012, SLEEP, V35, P727, DOI 10.5665/sleep.1846; Mendonça F, 2019, IEEE ACCESS, V7, P24527, DOI 10.1109/ACCESS.2019.2900345; Mira F.A., 2023, European Archives of Oto-Rhino-Laryngology, P1; Mohseni S, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P553, DOI 10.1145/3306618.3314322; Nicholson WC, 2021, NURS CLIN N AM, V56, P229, DOI 10.1016/j.cnur.2021.02.003; Pan Q., 2020, JMIR Biomed. Eng., V5, pe20921, DOI 10.2196/20921; Park S, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2421, DOI 10.1145/3292500.3330792; RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263; Sadeghi R, 2019, COMPUT BIOL MED, V110, P276, DOI 10.1016/j.compbiomed.2019.05.010; Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1; Sathyanarayana A, 2016, JMIR MHEALTH UHEALTH, V4, DOI 10.2196/mhealth.6562; Schober P, 2018, ANESTH ANALG, V126, P1763, DOI 10.1213/ANE.0000000000002864; Scott AJ, 2021, SLEEP MED REV, V60, DOI 10.1016/j.smrv.2021.101556; Secinaro S, 2021, BMC MED INFORM DECIS, V21, DOI 10.1186/s12911-021-01488-9; Shochat T, 2012, NAT SCI SLEEP, V4, P19, DOI 10.2147/NSS.S18891; Susnjak T, 2024, INT J ARTIF INTELL E, V34, P452, DOI 10.1007/s40593-023-00336-3; Thieme A, 2020, ACM T COMPUT-HUM INT, V27, DOI 10.1145/3398069; Troncoso-garcia A. R., 2022, Procedia Computer Science, P2930, DOI 10.1016/j.procs.2022.09.351; Tsai CH, 2024, SLEEP MED, V114, P55, DOI 10.1016/j.sleep.2023.12.013; Wang R, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P3, DOI 10.1145/2632048.2632054; Ye J, 2012, PERVASIVE MOB COMPUT, V8, P36, DOI 10.1016/j.pmcj.2011.01.004; Zolfaghari S, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3603495; Zolfaghari S, 2022, COGN COMPUT, V14, P1549, DOI 10.1007/s12559-020-09816-3	43	0	0	4	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	FEB	2024	16	2							46	10.3390/fi16020046	http://dx.doi.org/10.3390/fi16020046			18	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	IY4M0		gold, Green Published			2024-07-03	WOS:001169887500001
C	Swanson, B; Mathewson, K; Pietrzak, B; Chen, S; Dinalescu, M			ASSOC COMPUTAT LINGUIST	Swanson, Ben; Mathewson, Kory; Pietrzak, Ben; Chen, Sherol; Dinalescu, Monica			Story Centaur: Large Language Model Few Shot Learning as a Creative Writing Tool	EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE SYSTEM DEMONSTRATIONS			English	Proceedings Paper	16th Conference of the European-Chapter-of-the-Association-for-Computational-Linguistics (EACL)	APR 19-23, 2021	ELECTR NETWORK	Assoc Computat Linguist, European Chapter, Grammarly, Facebook AI, Bloomberg Engn, LegalForce, Babelscape				Few shot learning with large language models has the potential to give individuals without formal machine learning training the access to a wide range of text to text models. We consider how this applies to creative writers and present STORY CENTAUR, a user interface for prototyping few shot models and a set of recombinable web components that deploy them. STORY CENTAUR's goal is to expose creative writers to few shot learning with a simple but powerful interface that lets them compose their own co-creation tools that further their own unique artistic directions. We build out several examples of such tools, and in the process probe the boundaries and issues surrounding generation with large language models.	[Swanson, Ben; Pietrzak, Ben; Chen, Sherol; Dinalescu, Monica] Google, Mountain View, CA 94043 USA; [Mathewson, Kory] DeepMind, London, England	Google Incorporated	Swanson, B (corresponding author), Google, Mountain View, CA 94043 USA.	pwnr@google.com; korymath@google.com; bpietrzak@google.com; sherol@google.com; noms@google.com						Ammanabrolu Prithviraj, STORY REALIZATION EX; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Case N., 2018, Journal of Design and Science; Charalampos Tsioustas, 2020, P ENTRENOVA ENTERPRI, V6, P84; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Fan AEL, 2018, Arxiv, DOI arXiv:1805.04833; Ghazvininejad M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P43, DOI 10.18653/v1/P17-4008; Ippolito D., 2019, P 1 WORKSH NARR UND, P37; Kreminski Max., 2019, Proceedings of the 14th International Conference on the Foundations of Digital Games, P1; Llano Maria Teresa, 2020, PROC ICCC; Martin LJ, 2016, LECT NOTES COMPUT SC, V10045, P73, DOI 10.1007/978-3-319-48279-8_7; Mathewson Kory, 2017, P AAAI C ARTIFICIAL, V13; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mirowski P, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P527, DOI 10.1145/3325480.3326547; Oh C, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174223; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2017, Arxiv, DOI arXiv:1704.01444; Riley Parker., 2020, arXiv; Cho WS, 2019, Arxiv, DOI arXiv:1811.00511; Sloan Robin, 2019, ROGUELIKE CELEBRATIO; Wang A, 2019, ADV NEUR IN, V32	25	6	7	1	1	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-954085-05-3				2021							244	256						13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT9HT					2024-07-03	WOS:000861063100029
C	Gaikwad, H; Kiwelekar, A; Laddha, M; Shahare, S		Choi, BJ; Singh, D; Tiwary, US; Chung, WY		Gaikwad, Harsha; Kiwelekar, Arvind; Laddha, Manjushree; Shahare, Shashank			Adopting Pre-trained Large Language Models for Regional Language Tasks: A Case Study	INTELLIGENT HUMAN COMPUTER INTERACTION, IHCI 2023, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Conference on Intelligent Human-Computer Interaction (IHCI)	NOV 08-10, 2023	Daegu, SOUTH KOREA			Natural Language Processing; Large Language Models; Sentiment Analysis		Large language models have revolutionized the field of Natural Language Processing. While researchers have assessed their effectiveness for various English language applications, a research gap exists for their application in low-resource regional languages like Marathi. The research presented in this paper intends to fill that void by investigating the feasibility and usefulness of employing large language models for sentiment analysis in Marathi as a case study. The study gathers a diversified and labeled dataset from Twitter that includes Marathi text with opinions classified as positive, negative, or neutral. We test the appropriateness of pre-existing language models such as Multilingual BERT (M-BERT), indicBERT, and GPT-3 ADA on the obtained dataset and evaluate how they performed on the sentiment analysis task. Typical assessment metrics such as accuracy, F1 score, and loss are used to assess the effectiveness of sentiment analysis models. This research paper presents additions to the growing area of sentiment analysis in languages that have not received attention. They open up possibilities for creating sentiment analysis tools and applications specifically tailored for Marathi-speaking communities.	[Gaikwad, Harsha; Kiwelekar, Arvind; Laddha, Manjushree; Shahare, Shashank] Dr Babasaheb Ambedkar Technol Univ, Dept Comp Engn, Lonere 402103, Maharashtra, India	Dr. Babasaheb Ambedkar Technological University	Gaikwad, H (corresponding author), Dr Babasaheb Ambedkar Technol Univ, Dept Comp Engn, Lonere 402103, Maharashtra, India.	harsha.gaikwad@dbatu.ac.in; awk@dbatu.ac.in; mdladdha@dbatu.ac.in; srshahare@dbatu.ac.in						Agüero-Torales MM, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107373; Ansari M.A., 2018, Int. J. Nat. Lang. Comput. (IJNLC), V7; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Chathuranga PDT, 2019, INT CONF ADV ICT, DOI 10.1109/icter48817.2019.9023671; Deshmukh R, 2022, LECT NOTES COMPUT SC, V13184, P74, DOI 10.1007/978-3-030-98404-5_7; Deshmukh S., 2017, Int. J. Res. Publ. Eng. Technol. [IJRPET], V3, P93; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhumal Deshmukh Rushali, 2020, 2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA). Proceedings, P76, DOI 10.1109/ICIMIA48430.2020.9074941; Gillioz Anthony, 2020, 2020 15th Conference on Computer Science and Information Systems (FedCSIS), P179, DOI 10.15439/2020F20; Han X, 2021, AI OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002; Jain K, 2020, Arxiv, DOI arXiv:2011.02323; Khan Rijwan., 2020, Journal of Critical Reviews, V7, P2761; Kublik S., 2022, GPT-3; Kulkarni A, 2021, Arxiv, DOI arXiv:2103.11408; Lahoti P, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3548457; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Naseem U, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3434237; Nozza D, 2020, Arxiv, DOI arXiv:2003.02912; Patil RS, 2022, SOC NETW ANAL MIN, V12, DOI 10.1007/s13278-022-00877-w; Sawicki P., 2023, On the power of special-purpose GPT models to create and evaluate new poetry in old styles; Smith S, 2022, arXiv; Soong HC, 2019, 2019 IEEE 9TH SYMPOSIUM ON COMPUTER APPLICATIONS & INDUSTRIAL ELECTRONICS (ISCAIE), P272, DOI 10.1109/ISCAIE.2019.8743799; Torfi A, 2021, Arxiv, DOI [arXiv:2003.01200, 10.48550/arXiv.2003.01200]; Vidyavihar M., 2017, Int. J. Recent Innov. Trends Comput. Commun., V5, P21; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	25	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-53826-1; 978-3-031-53827-8	LECT NOTES COMPUT SC			2024	14531						15	25		10.1007/978-3-031-53827-8_2	http://dx.doi.org/10.1007/978-3-031-53827-8_2			11	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8ZC					2024-07-03	WOS:001209044500002
C	Zhang, WX; Wang, Y; Fan, M		Iliadis, L; Papaleonidas, A; Angelov, P; Jayne, C		Zhang, Weixu; Wang, Yu; Fan, Ming			Towards Robustness of Large Language Models on Text-to-SQL Task: An Adversarial and Cross-Domain Investigation	ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING, ICANN 2023, PT V	Lecture Notes in Computer Science		English	Proceedings Paper	32nd International Conference on Artificial Neural Networks (ICANN)	SEP 26-29, 2023	Heraklion, GREECE			Large language model; ChatGPT; text-to-SQL; Robustness; Adversarial attacks		Recent advances in large language models (LLMs) like Chat-GPT have led to impressive results on various natural language processing (NLP) challenges including text-to-SQL task, which aims to automatically generate SQL queries from natural language questions. However, these languagemodels are still subject to vulnerabilities such as adversarial attacks, domain shift and lack of robustness, which can greatly affect their performance and reliability. In this paper, we conduct a comprehensive evaluation of large language models, such as ChatGPT, on their robustness in text-to-SQL tasks. We assess the impact of adversarial and domain generalization perturbations on LLMs using seven datasets, five of which are popular robustness evaluation benchmarks for text-to-SQL tasks and two are synthetic adversarial datasets generated by ChatGPT. Our experiments show that while LLMs exhibit promise as zero-shot text-to-SQL parsers, their performances degrade under adversarial and domain generalization perturbations, with varying degrees of robustness depending on the type and level of perturbations applied. We also explore the impact of usage-related factors such as prompt design on the performance and robustness of LLMs. Our study provides insights into the limitations and potential directions for future research to enhance the performance and robustness of LLMs on text-to-SQL and other NLP tasks.	[Zhang, Weixu; Wang, Yu; Fan, Ming] Xi An Jiao Tong Univ, Xian 710049, Peoples R China	Xi'an Jiaotong University	Fan, M (corresponding author), Xi An Jiao Tong Univ, Xian 710049, Peoples R China.	weixu_zhang@stu.xjtu.edu.cn; uyleewang@stu.xjtu.edu.cn; mingfan@mail.xjtu.edu.cn			National Key R&D Program of China [2022YFB2703500]; National Natural Science Foundation of China [62232014, 62293501, 62272377, 62293502, 72241433, 61721002, 62032010, 62002280]; Fundamental Research Funds for the Central Universities; CCF-AFSG Research Fund, China Postdoctoral Science Foundation [2020M683507, 2019TQ0251, 2020M673439]; Young Talent Fund of Association for Science and Technology in Shaanxi, China	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); CCF-AFSG Research Fund, China Postdoctoral Science Foundation; Young Talent Fund of Association for Science and Technology in Shaanxi, China	This work was supported by National Key R&D Program of China (2022YFB2703500), National Natural Science Foundation of China (62232014, 62293501, 62272377, 62293502, 72241433, 61721002, 62032010, 62002280), the Fundamental Research Funds for the Central Universities, CCF-AFSG Research Fund, China Postdoctoral Science Foundation (2020M683507, 2019TQ0251, 2020M673439), and Young Talent Fund of Association for Science and Technology in Shaanxi, China.	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cao RS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2541; Chang S., 2023, Dr. Spider: a diagnostic evaluation benchmark towards text-to-SQL robustness; Deng N, 2022, P 29 INT C COMP LING, P2166; Deng X, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1337; Gan YJ, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8926; Gan YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2505; Gao C., 2022, arXiv; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li Haoyang, 2023, RESDSQL: decoupling schema linking and skeleton parsing for text-to-SQL; Peng K, 2023, Towards making the most of chatgpt for machine translation; Pi XY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2007; Qi JX, 2022, Arxiv, DOI arXiv:2205.06983; Raffel C, 2020, J MACH LEARN RES, V21; Rajkumar N., 2022, Evaluating the Text-to-SQL Capabilities of Large Language Models; Scholak T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9895; Wang B., 2020, P 58 ANN M ASS COMPU, P7567; Wang J., 2023, On the robustness of chatgpt: An adversarial and out-of-distribution perspective; Xie TB, 2022, Arxiv, DOI arXiv:2201.05966; Yang Z., 2023, Mm-react: Prompting chatgpt for multimodal reasoning and action; Yu T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3911	22	1	1	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-44191-2; 978-3-031-44192-9	LECT NOTES COMPUT SC			2023	14258						181	192		10.1007/978-3-031-44192-9_15	http://dx.doi.org/10.1007/978-3-031-44192-9_15			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4XU					2024-07-03	WOS:001156948900015
J	Myers, D; Mohawesh, R; Chellaboina, VI; Sathvik, AL; Venkatesh, P; Ho, YH; Henshaw, H; Alhawawreh, M; Berdik, D; Jararweh, Y				Myers, Devon; Mohawesh, Rami; Chellaboina, Venkata Ishwarya; Sathvik, Anantha Lakshmi; Venkatesh, Praveen; Ho, Yi-Hui; Henshaw, Hanna; Alhawawreh, Muna; Berdik, David; Jararweh, Yaser			Foundation and large language models: fundamentals, challenges, opportunities, and social impacts	CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS			English	Article						Natural language processing; Foundation models; Large language models; Advanced pre-trained models; Artificial intelligence; Machine learning	SENTIMENT ANALYSIS; BERT; CONTEXT; SYSTEM; RISK	Foundation and Large Language Models (FLLMs) are models that are trained using a massive amount of data with the intent to perform a variety of downstream tasks. FLLMs are very promising drivers for different domains, such as Natural Language Processing (NLP) and other AI-related applications. These models emerged as a result of the AI paradigm shift, involving the use of pre-trained language models (PLMs) and extensive data to train transformer models. FLLMs have also demonstrated impressive proficiency in addressing a wide range of NLP applications, including language generation, summarization, comprehension, complex reasoning, and question answering, among others. In recent years, there has been unprecedented interest in FLLMs-related research, driven by contributions from both academic institutions and industry players. Notably, the development of ChatGPT, a highly capable AI chatbot built around FLLMs concepts, has garnered considerable interest from various segments of society. The technological advancement of large language models (LLMs) has had a significant influence on the broader artificial intelligence (AI) community, potentially transforming the processes involved in the development and use of AI systems. Our study provides a comprehensive survey of existing resources related to the development of FLLMs and addresses current concerns, challenges and social impacts. Moreover, we emphasize on the current research gaps and potential future directions in this emerging and promising field.	[Myers, Devon; Chellaboina, Venkata Ishwarya; Sathvik, Anantha Lakshmi; Venkatesh, Praveen; Ho, Yi-Hui; Henshaw, Hanna; Berdik, David; Jararweh, Yaser] Duquesne Univ, Pittsburgh, PA USA; [Mohawesh, Rami] Al Ain Univ, Abu Dhabi, U Arab Emirates; [Alhawawreh, Muna] Deakin Univ, Geelong, Australia	Duquesne University; Deakin University	Mohawesh, R (corresponding author), Al Ain Univ, Abu Dhabi, U Arab Emirates.	myersd2@duq.edu; rami.mohawesh@aau.ac.ae; chellaboinav@duq.edu; tirukkovalluria@duq.edu; venkateshp@duq.edu; hoy@duq.edu; henshawh@duq.edu; muna.alhawawreh@deakin.edu.au; dgberdik@gmail.com; yaser@email.arizona.edu	Al-hawawreh, Muna/JAC-7737-2023	Al-hawawreh, Muna/0000-0003-4690-2256				Abas AR, 2020, IEEE ACCESS, V8, P128845, DOI 10.1109/ACCESS.2020.3008824; Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Abebe R, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P252, DOI 10.1145/3351095.3372871; Abid A, 2021, ARXIV; Akhila N., 2023, 2023 3rd International Conference on Intelligent Technologies (CONIT), P1, DOI 10.1109/CONIT59222.2023.10205622; AlanRamponi B.P., 2020, NEURAL UNSUPERVISED; Alhamami MAM, 2023, CRIT REV ANAL CHEM, DOI 10.1080/10408347.2023.2197073; Alkhurayyif Y., 2023, IEEE ACCESS; [Anonymous], 2018, PLoS ONE; Antoun W., 2021, ARXIV; Araujo AF, 2022, AUTOMAT SOFTW ENG, V29, DOI 10.1007/s10515-021-00301-1; Arifuzzaman M., 2019, SENTIMENT ANAL NLP T; Arumae K., 2019, ABS190402321 CORR; Balaji T.K., 2022, 2022 INT C INNOVATIV, P1; Baldini I., 2021, ARXIV; Bani-Almarjeh M, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103227; Bartlett Robert., 2019, MORSE ADAIR STANTON; Bataa E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4652; Benjamin R, 2019, SCIENCE, V366, P421, DOI 10.1126/science.aaz3873; Bhattacharjee S, 2020, LECT NOTES COMPUT SC, V12089, P47, DOI 10.1007/978-3-030-51310-8_5; Bi B., 2020, ARXIV; Boillot A, 2013, PLOS ONE, V8, DOI [10.1371/journal.pone.0052708, 10.1371/journal.pone.0064417]; Bommasani Rishi, 2021, ARXIV210807258; Borji A., 2023, arXiv; Bowman S.R., 2015, arXiv; Buck C., 2018, ARXIV; Buyukoz B., 2020, P AESPEN, V2020, P9; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Canete Jose, 2020, PML4DC ICLR 2020; Carlini N., 2022, arXiv; Chang WC, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3163, DOI 10.1145/3394486.3403368; Chen G., 2021, FURU; Chen K, 2021, ARXIV; Chen Q., 2023, COMPREHENSIVE BENCHM, P2023; Cheuk T, 2021, SCI EDUC, V105, P825, DOI 10.1002/sce.21671; Chronopoulou A., 2021, ARXIV; Clark K., 2020, ARXIV; Clinchant Stephane., 2019, JUNG KWEON WOO; Conneau A, 2019, ADV NEUR IN, V32; Creel K., 2021, PROCEEDING 2021 ACM; Dabre R, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3406095; Dafoe A., 2018, GOVERNANCE RES AGEND; Dai JZ, 2019, IEEE ACCESS, V7, P138872, DOI 10.1109/ACCESS.2019.2941376; Dang E., 2022, ARXIV; Delobelle P, 2020, ARXIV; Deng X, 2023, COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023, P107, DOI 10.1145/3543873.3587324; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; deVries W., 2021, FIND ASS COMP LING A; Dinh T.A., 2023, ARXIV; Djandji M., 2020, P 4 WORKSH OP SOURC, P97; DoCarmo T, 2021, LAW POLICY, V43, P170, DOI 10.1111/lapo.12164; Dong L., 2017, ARXIV; Du Y, 2022, ARXIV; Duarte JM, 2023, ARTIF INTELL REV, V56, P9401, DOI 10.1007/s10462-023-10393-8; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Edunov S., 2019, ARXIV; Eisenstein J., 2022, ARXIV; Emil Zachary, 2020, Towards a more inclusive world: Enhanced augmentative and alternative communication for people with disabilities using ai and nlp; Erciyes Necdet Eren, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P50, DOI 10.1109/UBMK52708.2021.9558977; Etoori Pravallika., 2018, MAMIDI RADHIKA CHINN; Faraj D., 2021, P 6 ARABIC NATURAL L, p345~350; Fernandes P., 2023, ARXIV; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fuadi M., 2023, ARXIV; Fukumoto D, 2023, Soft Anal Evol Reeng, P693, DOI 10.1109/SANER56733.2023.00073; Gao Y, 2020, ARXIV; Geetha MP., 2021, IMPROVING PERFORMANC, DOI [10.1016/j.ijin.2021.06.005, DOI 10.1016/J.IJIN.2021.06.005]; Ghourabi A, 2021, INT CONF INFORM COMM, P486, DOI 10.1109/ICICS52457.2021.9464540; Giorgi JohnM, 2019, ARXIV; Giovannotti P., 2023, ARXIV; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gore RJ, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0133505; Gruetzemacher R, 2022, FUTURES, V135, DOI 10.1016/j.futures.2021.102884; Guo B, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3439816; Guo JL, 2021, IEEE-ACM T AUDIO SPE, V29, P1740, DOI 10.1109/TASLP.2021.3076863; Gupta A., 2020, ARXIV; Guven Zekeriya Anil, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P629, DOI 10.1109/UBMK52708.2021.9559007; Han JM., 2021, SUTSKEVER; He Y, 2020, ARXIV; Hegde C., 2020, ARXIV; Henderson P., 2017, ARXIV; Hossain MR, 2023, ENG APPL ARTIF INTEL, V124, DOI 10.1016/j.engappai.2023.106586; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Hutchinson B., 2020, P 58 ANN M ASS COMP; Jacob D., 2019, ARXIV; JACOBS PS, 1992, THIRD CONFERENCE ON APPLIED NATURAL LANGUAGE PROCESSING, P178; Jagielski M., 2021, ARXIV; Jain PK, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13247; Jin W., 2023, ARXIV; Joyce K, 2021, SOCIUS, V7, DOI 10.1177/2378023121999581; Judge Phoebe, 2014, PANTS FIRE; Kadaoui Karima, 2023, ARXIV; Karimi A., 2020, PRATI IMPROVING BERT; Karimi A, 2021, INT C PATT RECOG, P8797, DOI 10.1109/ICPR48806.2021.9412167; Khan AishaUrooj, 2020, MMFT BERT MULTIMODAL; Khan W, 2016, KUWAIT J SCI, V43, P95; Kheiri K., 2023, arXiv; Kiros JR, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4868; Kolides A, 2023, SIMUL MODEL PRACT TH, V126, DOI 10.1016/j.simpat.2023.102754; Koto F., 2020, ARXIV; Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150; Kuang W, 2023, ARXIV; Kumar S, 2021, LECT NOTES ARTIF INT, V12713, P423, DOI 10.1007/978-3-030-75765-6_34; Kuratov Y., 2019, KompJuternaja Lingvistika IntellektualNye Tehnol, V18, P333; Kurita K., 2020, ARXIV; Lahire, 2021, ARXIV; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lewis Mike, 2020, P 58 ANN M ASS COMP; Li J., 2021, PRETRAINED LANGUAGE; Li Junyi, 2022, SURVEY PRETRAINED LA; Li L., 2019, Pretrained language models for document-level neural machine translation; Li L, 2021, arXiv; Li P., 2022, ARXIV; Li Q, 2020, SURVEY TEXT CLASSIFI; Li S., 2021, arXiv; Li S., 2022, SONG SURVEY CONTROLL; Li XL, 2020, IEEE ACCESS, V8, P46868, DOI 10.1109/ACCESS.2020.2978511; Liu Jiachang, 2021, What makes good in-context examples for gpt-3?; Liu S., 2023, ARXIV; Liu Wenbin, 2020, MATEC WEB C, P309; Liu Y., 2019, CoRR abs/1907.11692; Liu Zheng, 2021, SOCIOLOGICAL PERSPEC; Lloret E, 2011, INT J INTELL SYST, V26, P1125, DOI 10.1002/int.20502; Lock S., 2022, BOOK WHAT IS CHATBOT; Ma Chunlan, 2023, ARXIV; Ma Shuming, 2020, Xlm-t: Scaling up multilingual machine translation with pretrained cross-lingual transformer encoders; MacCartney B., 2009, Natural Language Inference; Madhyastha PranavaSwaroop, 2016, P 1 WORKSH REPR LEAR, P100; Mager Manuel, 2020, GPT TOO LANGUAGE MOD; Mai Florian., 2020, HENDERSON; Majd Saad Al Deen M., 2023, ARXIV; Maldonado Abran, 2021, GPT 3 POWERS NEXT GE; Manias G, 2023, NEURAL COMPUT APPL, V35, P21415, DOI 10.1007/s00521-023-08629-3; Martin Louis, 2020, ARXIV; Marulli F, 2021, PROCEDIA COMPUT SCI, V192, P3570, DOI 10.1016/j.procs.2021.09.130; Maslennikova Elizaveta, 2019, WORKING NOTES; Mathew L., 2020, 4 INT C COMP METH CO, P340, DOI DOI 10.1109/ICCMC48092.2020.ICCMC-00064; McCarley, 2019, CHAKRAVARTI RISHAV; Meftah Sara, 2019, ARXIV; Meng Yuxian, 2019, LARGE SCALE PRETRAIN; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Mitkov Ruslan, 2004, UPPER OXFORD HDB COM; Mohanlal R, 2023, CANCER INVEST, V41, P369, DOI 10.1080/07357907.2023.2179064; Mohawesh R, 2023, J KING SAUD UNIV-COM, V35, DOI 10.1016/j.jksuci.2023.101644; Mohawesh Rami, 2021, ARXIV; Mohawesh Rami., 2023, OPEN, V4, P33, DOI [10.1016/j.aiopen.2023.08.004, DOI 10.1016/J.AIOPEN.2023.08.004]; Mohit B., 2014, Natural Language Processing of Semitic Languages; Mumtarin Maroa, 2023, ARXIV; Nadeau D, 2007, LINGUIST INVESTIG, V30, P3; Narang S., 2022, Pathways language model (palm): Scaling to 540 billion parameters for breakthrough performance; Narayan Shashi, 2020, QURIOUS QUESTION GEN; Naseem U, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533884; Nayak Pandu, 2019, Understanding searches better than ever before; Nguyen T., 2023, ARXIV; Okur Halil Ibrahim, 2021, 2021 6th International Conference on Computer Science and Engineering (UBMK), P174, DOI 10.1109/UBMK52708.2021.9558878; Orgad H., 2022, ARXIV; Padilla JJ, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198857; Penha G, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P388, DOI 10.1145/3383313.3412249; Polignano Marco., 2019, CEUR WORKSHOP PROC, P2481; Qi Ye, 2018, WHY ARE PRETRAINED W; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Qu C, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1133, DOI 10.1145/3331184.3331341; Qu YB, 2020, IEEE INT CONF ELECTR, P323, DOI 10.1109/iceiec49280.2020.9152352; Quan W, 2019, IEEE INT CONF BIG DA, P2438, DOI 10.1109/BigData47090.2019.9006119; Quoc Nguyen D., 2020, ARXIV; Radford A., 2018, IMPROVING LANGUAGE U; Radford Alec, 2019, ACL ANTHOLOGY; Rae J. W., 2021, arXiv; Raffel C, 2019, Exploring the limits of transfer learning with a unified text-to-text transformer; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Ramponi Alan, 2020, ARXIV; Ramraj S., 2020, 2020 INT C COMP INT, P1; Rehman Abdul, 2023, ARXIV; Reimers N., 2019, arXiv; Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044; Rosario Barbara, 2004, P 42 ANN M ASS COMP; Roudsari AH, 2020, INT CONF BIG DATA, P558, DOI 10.1109/BigComp48618.2020.000-2; Sarkar Sagnik, 2023, Sentiment Analysis and Deep Learning: Proceedings of ICSADL 2022. Advances in Intelligent Systems and Computing (1432), P405, DOI 10.1007/978-981-19-5443-6_30; Saunders Danielle, 2021, ARXIV; Schmid H., 1994, ARXIV; Sen Bhaskar, 2020, SUPPORT BERT PREDICT; Shi Y, 2023, ARXIV; Singhal K, 2023, arXiv; Song Y., 2020, Utilizing bert intermediate layers for aspect based sentiment analysis and natural language inference; Stickland Asa Cooper., 2020, GHAZVININEJAD; Strubell E., 2019, arXiv; SUN C, 2019, CHIN COMP LING 18; SUN C, 2019, 2019 C N AM CHAPT; Sun Yu, 2021, LARGE SCALE KNOWLEDG, V3; Suneera C.M, 2021, ADV MACHINE LEARNING; Sweeney L., 2013, ARXIV; Tabinda Kokab, 2022, ARRAY; Tailai An, 2021, 2021 4th International Conference on Artificial Intelligence and Big Data (ICAIBD), P212, DOI 10.1109/ICAIBD51990.2021.9459048; Tanvir Hasan, 2021, ARXIV; Terpin Antonio., 2022, ADV NEURAL INFORM PR, V35, P19786; Tian JJ, 2020, ENERG EXPLOR EXPLOIT, V38, P629, DOI 10.1177/0144598719888810; Touvron H., 2023, arXiv; Ulcar Matej., 2021, ROBNIK SIKONJA MARKO; Uthus David, 2023, ARXIV; van Stegeren J, 2021, PROCEEDINGS OF THE 16TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES, FDG 2021, DOI 10.1145/3472538.3472595; Varis Dus an, 2019, P 57 ANN M ASS COMP; VeyselKocaman DavidTalby, 2021, SPARKNLP NATURAL LAN; Virtanen A., 2019, ARXIV; Wang HY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1371; Wang Sinong, 2020, arXiv; Wang Wenxuan., 2022, JIAO WENXIANG HAO YO; Wang YH, 2020, PR MACH LEARN RES, V115, P113; Wei Xiaokai, 2021, KNOWLEDGE ENHANCED P; Wikipedia contributors, 2022, TURING TEST WIKIPEDI; Wu J, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND SOFTWARE ENGINEERING (ICICSE 2021), P209, DOI 10.1109/ICICSE52190.2021.9404101; Xia Congying, 2020, CG BERT CONDITIONAL; XING Y, 2021, 59 ANN M ASS COMP; Xu H, 2021, IEEE INTERNET THINGS, V8, P3915, DOI 10.1109/JIOT.2020.3025953; Xu HR, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6663; Xue Linting, 2021, ARXIV; Yang Wei, 2019, P 2019 C N; Yang Wei., 2019, XIE YUQING TAN LUCHE; Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975; Yu WH, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3512467; Zaib M, 2021, PARALLEL ARCHITECTUR, P47, DOI [10.1007/978-981-16-0010-4_5, DOI 10.1007/978-981-16-0010-4_5]; Zajko M, 2022, SOCIOL COMPASS, V16, DOI 10.1111/soc4.12962; Zhang B., 2023, ARXIV; Zhang B., 2019, SSRN Electron. J, DOI [10.2139/ssrn.3312874, DOI 10.2139/SSRN.3312874]; Zhang H., 2023, ARXIV; Zhang J., 2019, Pegasus: Pre-training with extracted gap-sentences for abstractive summarization, V119, P11328; Zhang T, 2020, PROC IEEE INT CONF S, P70, DOI 10.1109/ICSME46990.2020.00017; Zhang ZB, 2021, NEUROCOMPUTING, V460, P84, DOI 10.1016/j.neucom.2021.07.002; Zhongxiang Ding, 2021, 2021 4th International Conference on Advanced Electronic Materials, Computers and Software Engineering (AEMCSE), P1243, DOI 10.1109/AEMCSE51986.2021.00254; Zhu Jinhua, 2020, TIE YAN	229	5	5	53	60	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1386-7857	1573-7543		CLUSTER COMPUT	Cluster Comput.	FEB	2024	27	1					1	26		10.1007/s10586-023-04203-7	http://dx.doi.org/10.1007/s10586-023-04203-7		NOV 2023	26	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IU6W0					2024-07-03	WOS:001113289500001
C	Li, ZJ; Wang, CZ; Wang, S; Gao, CY			ACM	Li, Zongjie; Wang, Chaozheng; Wang, Shuai; Gao, Cuiyun			Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks	PROCEEDINGS OF THE 2023 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, CCS 2023			English	Proceedings Paper	30th ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)	NOV 26-30, 2023	Copenhagen, DENMARK	Assoc Comp Machinery, ACM SIGSAC, Huawei, Natl Sci Fdn, Technol Innovat Inst, Twenty Second Century Dora Technol, Ant Res, IBM, TikTok, Abelian, Input Outut		Watermark; Code generation; Large language model		The rise of large language model-based code generation (LLCG) has enabled various commercial services and APIs. Training LLCG models is often expensive and time-consuming, and the training data are often large-scale and even inaccessible to the public. As a result, the risk of intellectual property (IP) theft over the LLCG models (e.g., via imitation attacks) has been a serious concern. In this paper, we propose the first watermark (WM) technique to protect LLCG APIs from remote imitation attacks. Our proposed technique is based on replacing tokens in an LLCG output with their "synonyms" available in the programming language. A WM is thus defined as the stealthily tweaked distribution among token synonyms in LLCG outputs. We design six WM schemes (instantiated into over 30 WM passes) which rely on conceptually distinct token synonyms available in programming languages. Moreover, to check the IP of a suspicious model (decide if it is stolen from our protected LLCG API), we propose a statistical tests-based procedure that can directly check a remote, suspicious LLCG API. We evaluate our WM technique on LLCG models fine-tuned from two popular large language models, CodeT5 and CodeBERT. The evaluation shows that our approach is effective in both WM injection and IP check. The inserted WMs do not undermine the usage of normal users (i.e., high fidelity) and incur negligible extra cost. Moreover, our injected WMs exhibit high stealthiness and robustness against powerful attackers; even if they know all WM schemes, they can hardly remove WMs without largely undermining the accuracy of their stolen models.	[Li, Zongjie; Wang, Shuai] Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China; [Wang, Chaozheng; Gao, Cuiyun] Harbin Inst Technol, Shenzhen, Peoples R China	Hong Kong University of Science & Technology; Harbin Institute of Technology	Wang, S (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Peoples R China.	zligo@cse.ust.hk; wangchaozheng@stu.hit.edu.cn; shuaiw@cse.ust.hk; gaocuiyun@hit.edu.cn	Wang, Chaozheng/KHT-6430-2024	Wang, Chaozheng/0000-0002-3935-7328; Wang, Shuai/0000-0002-0866-0308; Li, Zongjie/0000-0002-9897-4086				Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615; Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; [Anonymous], PYC SIM; [Anonymous], COD; [Anonymous], BILL AIXC; [Anonymous], US; [Anonymous], US; [Anonymous], JUR; [Anonymous], BILL AM P2; [Anonymous], JENSENSHANNON DIV; [Anonymous], US; [Anonymous], BILL GITHUB COP; [Anonymous], GOOGL BARD STEAL; [Anonymous], TOP 10 PYTH PACK; [Anonymous], OPENAI WAT PROT; [Anonymous], BILL AI21 LAB; [Anonymous], TOP 26 PYTH PACK; [Anonymous], DEEPT; [Anonymous], TABN COP; [Anonymous], 2018, ARXIV180809588; Artifact, 2022, TOSYN; Barei<ss> Patrick, 2022, ARXIV220601335; Brunsfeld Max., Tree-sitter; CHEN HL, 2019, DEEPMARKS SECURE FIN, P105, DOI DOI 10.1145/3323873.3325042; Chen JL, 2022, P IEEE S SECUR PRIV, P824, DOI [10.1109/SP46214.2022.00059, 10.1109/SP46214.2022.9833747]; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Chen X., 2021, Advances in neural information processing systems, V34, P1780; Chen YF, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3593; Chen Yufei, 2022, 1 USENIX SEC S USENI; Collberg C., 1998, LIMITS SOFTWARE WATE; copydetect, COP; Davidson R.L., 1996, US Patent, Patent No. [5,559,884, 5559884]; Dey A., 2019, INAE Lett., V4, P65, DOI DOI 10.1007/S41403-018-0058-8; EleutherAI, GPT J; Fan L., 2021, IEEE T PATTERN ANAL, V1, P1, DOI DOI 10.1109/TMC.2021.3110235; Fan Mo, 2021, MobiSys '21: Proceedings of the 19th Annual International Conference on Mobile Systems, Applications, and Services, P94, DOI 10.1145/3458864.3466628; Fan Mo, 2020, MobiSys '20: Proceedings of the 18th International Conference on Mobile Systems, Applications, and Services, P161, DOI 10.1145/3386901.3388946; Feng Z, 2020, EMNLP FINDINGS; Guo J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240862; HAMILTON J, 2011, 2011 WORLD C INT SEC, P17; Hashemi H, 2021, INT SYMP MICROARCH, P212, DOI 10.1145/3466752.3480112; He XL, 2022, AAAI CONF ARTIF INTE, P10758; He Xuanli, 2022, ARXIV220908773; Hinton G., 2015, ARXIV; Hou Jiahui, 2021, IEEE T DEPENDABLE SE; Hu X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P385, DOI 10.1145/3373376.3378460; Jia HR, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1937; Kirchenbauer John, 2023, ARXIV230110226; Krishna Kalpesh, 2019, ICLR; Lagler K, 2013, GEOPHYS RES LETT, V40, P1069, DOI 10.1002/grl.50288; Le Merrer E, 2020, NEURAL COMPUT APPL, V32, P9233, DOI 10.1007/s00521-019-04434-z; Li Z, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P880, DOI 10.1145/3460120.3484575; Li ZJ, 2022, PROC INT CONF SOFTW, P2253, DOI 10.1145/3510003.3510217; Li Zongjie, 2023, ARXIV230303012; Lim JH, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108285; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Aiwei, 2023, ARXIV230716230; Liu Fenlin, 2006, CHAOS BASED ROBUST S; Liu H., 2021, P 38 ICML, VVolume 139, P6978; Lu S., 2021, arXiv, P2021; Nagra Jasvir., 2002, AUST COMPUT SCI COMM, V24, P177, DOI 10.1145/563857.563822; OpenAi, ChatGPT; Orekondy T, 2019, PROC CVPR IEEE, P4949, DOI 10.1109/CVPR.2019.00509; Orekondy Tribhuvanesh, 2020, P 8 INT C LEARN REPR; Pal Soham, 2019, ABS190509165 CORR; Palsberg J, 2000, 16TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, PROCEEDINGS, P308, DOI 10.1109/ACSAC.2000.898885; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Parvez Md Rizwan, 2021, ARXIV210811601; pypi, ABOUT US; Python, 2021, PYTHON LANGUAGE REFE; Python Software Foundation, BLACK; Qi F., P 2021 C EMP METH NA; Qu G, 1998, 1998 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN, P190, DOI 10.1109/ICCAD.1998.742871; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rakin AS, 2022, P IEEE S SECUR PRIV, P1157, DOI 10.1109/SP46214.2022.00122; Rouhani BD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P485, DOI 10.1145/3297858.3304051; Schlogl Alexander, 2020, AISec'20: Proceedings of the 13th ACM Workshop on Artificial Intelligence and Security, P93, DOI 10.1145/3411508.3421376; Shen TX, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P723; Shen YR, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P955, DOI 10.1145/3373376.3378469; Stern JP, 2000, LECT NOTES COMPUT SC, V1768, P368; Sun Zhichuang, 2020, ABS201105905 CORR; Szyller S, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4417, DOI 10.1145/3474085.3475591; Tay Yi, 2020, ACM COMPUTING SURVEY; Tramer F., 2018, INT C LEARN REPR; Wallace Eric, 2020, ARXIV200415015; Wang BL, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1281; Wang CZ, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P382, DOI 10.1145/3540250.3549113; Wang JL, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P164, DOI 10.1145/3533767.3534386; Wang T., 2019, ARXIV191014268; Wang TH, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P993, DOI 10.1145/3442381.3450000; Wang Y., 2021, arXiv preprint arXiv:2109.00859; Wei Bolin, ABS191005923 CORR; Wiki, SALT; Xiang Yecheng, 2021, 2021 IEEE Real-Time Systems Symposium (RTSS), P68, DOI 10.1109/RTSS52674.2021.00018; Xu Frank F., 2022, SYSTEMATIC EVALUATIO, DOI [DOI 10.1145/3520312.3534862, 10.1145/3520312.3534862]; Xu Q., 2021, ARXIV210813873; Xu Qiongkai, 2022, P 29 INT C COMP LING, P2849; Yin KX, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P15, DOI 10.1109/ITCS.2009.295; Yu S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P29; Zhang J., 2020, P NEURIPS, V33, P22619; Zhang JB, 2018, INT C PATT RECOG, P159, DOI 10.1109/ICPR.2018.8546290; Zhu W, 2005, LECT NOTES COMPUT SC, V3495, P454	102	1	1	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0050-7				2023							2336	2350		10.1145/3576915.3623120	http://dx.doi.org/10.1145/3576915.3623120			15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TJ					2024-07-03	WOS:001124987202023
J	Haase, J; Kremser, W; Leopold, H; Mendling, J; Onnasch, L; Plattfaut, R				Haase, Jennifer; Kremser, Waldemar; Leopold, Henrik; Mendling, Jan; Onnasch, Linda; Plattfaut, Ralf			Interdisciplinary Directions for Researching the Effects of Robotic Process Automation and Large Language Models on Business Processes	COMMUNICATIONS OF THE ASSOCIATION FOR INFORMATION SYSTEMS			English	Article						Process Automation; Large Language Models; Routine Dynamics; Human Automation Interaction; Interdisciplinary Research	HUMAN-PERFORMANCE CONSEQUENCES; SITUATION AWARENESS; DECISION AIDS; SYSTEMS; ROUTINES; BIAS; TECHNOLOGIES; COMPLACENCY; DISCIPLINE; MANAGEMENT	Rapid technological advancements, especially in artificial intelligence, robotic process automation, and large language models, have significantly transformed information systems and business processes. These shifts are characterized by the automation of tasks, reshaping traditional human-centric operations, and consequently redefining human roles and experiences. This Panel Report builds on a discussion held at the annual Routines. Research. Community workshop in March 2023 in Berlin, Germany. It integrates diverse disciplinary perspectives to offer a comprehensive understanding of process automation. The panel draws on insights into automation tools such as robotic process automation and large language models, human -automation interaction research, and the study of routine dynamics, all vital for grasping the immediate human responses and longitudinal organizational adaptations due to automation. The report highlights the need for future research to focus on user-centric design for task automation, understanding individual differences in automation effects, exploring long-term psychological impact, and developing adaptive tools and training strategies. It also calls for examining AI integration in routine tasks and RPA tools, its influence on organizational routines and culture, and the dynamics in teams with AI -based members to better understand and enhance human -automation collaboration. This interdisciplinary approach is essential for navigating the challenges and opportunities of the rapidly evolving digital landscape.	[Haase, Jennifer; Mendling, Jan] Humboldt Univ, Comp Sci Dept, Berlin, Germany; [Haase, Jennifer; Mendling, Jan] Weizenbaum Inst, Berlin, Germany; [Kremser, Waldemar] Johannes Kepler Univ Linz, Strateg Management, Linz, Austria; [Leopold, Henrik] Kuhne Logist Univ, Data Sci, Hamburg, Germany; [Leopold, Henrik] Univ Potsdam, Hasso Plattner Inst, Digital Engn Fac, Potsdam, Germany; [Onnasch, Linda] Tech Univ Berlin, Psychol Act & Automat, Berlin, Germany; [Plattfaut, Ralf] Univ Duisburg Essen, Informat Syst & Transformat Management, Essen, Germany	Humboldt University of Berlin; Johannes Kepler University Linz; Kuhne Logistics University; University of Potsdam; Technical University of Berlin; University of Duisburg Essen	Haase, J (corresponding author), Humboldt Univ, Comp Sci Dept, Berlin, Germany.; Haase, J (corresponding author), Weizenbaum Inst, Berlin, Germany.				Einstein Foundation Berlin [EPP-2019-524]; German Federal Ministry of Education and Research [16DII133]	Einstein Foundation Berlin; German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	The research by Jennifer Haase and Jan Mendling was supported by the Einstein Foundation Berlin under grant EPP-2019-524 and by the German Federal Ministry of Education and Research under grant 16DII133.	Aguirre S, 2017, COMM COM INF SC, V742, P65, DOI 10.1007/978-3-319-66963-2_7; Akoumianakis D, 2017, J ENTERP INF MANAG, V30, P476, DOI 10.1108/JEIM-01-2016-0023; Armstrong P. R., 2023, ProPublicaMarch 25; Asare O, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-023-10380-1; Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010; Bahner JE, 2008, INT J HUM-COMPUT ST, V66, P688, DOI 10.1016/j.ijhcs.2008.06.001; Baralou E, 2022, INFORM TECHNOL PEOPL, V35, P1980, DOI 10.1108/ITP-03-2020-0109; Barke S, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3586030; Barzantny C, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3207412; Becker J., 1999, P 32 ANN HAW INT C S; Berberian B, 2017, ANNU REV CONTROL, V44, P303, DOI 10.1016/j.arcontrol.2017.09.010; Beverungen D, 2017, INF SYST E-BUS MANAG, V15, P781, DOI 10.1007/s10257-017-0365-8; Brynjolfsson E., 2017, Machine, Platform, Crowd: Harnessing Our Digital Future; Busch K, 2023, Arxiv, DOI [arXiv:2304.07183, 10.48550/arXiv.2304.07183, DOI 10.48550/ARXIV.2304.07183]; Cacciatori E, 2012, J MANAGE STUD, V49, P1559, DOI 10.1111/j.1467-6486.2012.01065.x; Ciriello RF, 2019, EUR J INFORM SYST, V28, P149, DOI 10.1080/0960085X.2018.1524418; D'Adderio L, 2003, IND CORP CHANGE, V12, P321, DOI 10.1093/icc/12.2.321; D'Adderio L, 2001, RES POLICY, V30, P1409, DOI 10.1016/S0048-7333(01)00159-7; Daily M, 2017, COMPUTER, V50, P18, DOI 10.1109/MC.2017.4451204; Dakhel AM, 2023, J SYST SOFTWARE, V203, DOI 10.1016/j.jss.2023.111734; Diederich S, 2022, J ASSOC INF SYST, V23, P96, DOI 10.17705/1jais.00724; Dumas M., 2018, FUNDAMENTALS BUSINES, DOI DOI 10.1007/978-3-642-33143-5.PDF; Ebert C, 2023, IEEE SOFTWARE, V40, P30, DOI 10.1109/MS.2023.3265877; Edmondson AC, 2001, ADMIN SCI QUART, V46, P685, DOI 10.2307/3094828; Endsley MR, 2017, J COGN ENG DECIS MAK, V11, P225, DOI 10.1177/1555343417695197; Endsley MR, 2017, HUM FACTORS, V59, P5, DOI 10.1177/0018720816681350; Endsley MR, 2015, J COGN ENG DECIS MAK, V9, P101, DOI 10.1177/1555343415573911; Endsley Mica R., 2016, Designing for situation awareness: An approach to user-centered design, DOI DOI 10.1201/B11371; ENDSLEY MR, 1995, HUM FACTORS, V37, P32, DOI 10.1518/001872095779049543; ENDSLEY MR, 1995, HUM FACTORS, V37, P381, DOI 10.1518/001872095779064555; Eysenck M., 2012, Attention and arousal: Cognition and performance; FISK AD, 1981, HUM FACTORS, V23, P737, DOI 10.1177/001872088102300610; Fiske S.T., 2013, SOCIAL COGNITION BRA, DOI DOI 10.1016/B978-012088566-4/50012-X; François PA, 2022, LECT NOTES COMPUT SC, V13420, P399, DOI 10.1007/978-3-031-16103-2_26; Gayathiri R., 2013, Quality of work life-Linkage with job satisfaction and performance; Glaser V. L., 2021, Organization Theory, V2; Glaser VL, 2017, ACAD MANAGE J, V60, P2126, DOI 10.5465/amj.2014.0842; Gruber H., 2008, P BIR 2008 7 INT C P, P77; Guner E. O., 2020, P 28 EUR C INF SYST; Hancock PA, 2013, ERGON DES, V21, P9, DOI 10.1177/1064804613477099; Haslbeck A, 2012, WORK, V41, P178, DOI 10.3233/WOR-2012-0153-178; Hoesterey S, 2023, COGN TECHNOL WORK, V25, P15, DOI 10.1007/s10111-022-00718-y; Janssen CP, 2019, INT J HUM-COMPUT ST, V131, P99, DOI 10.1016/j.ijhcs.2019.05.006; Jones-Jang SM, 2022, J COMPUT-MEDIAT COMM, V28, DOI 10.1093/jcmc/zmac029; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Kregel I, 2021, J ORG COMP ELECT COM, V31, P130, DOI 10.1080/10919392.2021.1911586; Kremser W., 2021, Cambridge handbook of routine dynamics; Labatut J, 2012, ORGAN STUD, V33, P39, DOI 10.1177/0170840611430589; Lacity MC, 2016, MIS Q EXEC, V15, P21; Leonardi PM, 2011, MIS QUART, V35, P147; Mackworth NH, 1948, Q J EXP PSYCHOL, V1, P6, DOI 10.1080/17470214808416738; Manzey D, 2012, J COGN ENG DECIS MAK, V6, P57, DOI 10.1177/1555343411433844; Mattila M, 2021, J PERS SELL SALES M, V41, P113, DOI 10.1080/08853134.2021.1916396; Mendling J, 2017, DECIS SUPPORT SYST, V100, P1, DOI 10.1016/j.dss.2017.06.009; Moray N, 2000, J EXP PSYCHOL-APPL, V6, P44, DOI 10.1037//0278-7393.6.1.44; Mosier KL, 1998, INT J AVIAT PSYCHOL, V8, P47, DOI 10.1207/s15327108ijap0801_3; Nof SY, 2009, SPRINGER HANDBOOK OF AUTOMATION, P1, DOI 10.1007/978-3-540-78831-7; Oberlander AM, 2018, EUR J INFORM SYST, V27, P486, DOI 10.1080/0960085X.2017.1387714; Omidvar O, 2023, J MANAGE STUD, V60, P313, DOI 10.1111/joms.12819; Onnasch Linda, 2019, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V63, P282, DOI 10.1177/1071181319631126; Onnasch L, 2015, INT J HUM-COMPUT ST, V76, P12, DOI 10.1016/j.ijhcs.2014.12.004; Onnasch L, 2014, HUM FACTORS, V56, P476, DOI 10.1177/0018720813501549; OpenAI, 2023, ChatGPT(Mar 14 version) (Version 4) Large language model; Ozkaynak M, 2021, J MED INTERNET RES, V23, DOI 10.2196/17590; Parasuraman R, 2000, IEEE T SYST MAN CY A, V30, P286, DOI 10.1109/3468.844354; Parasuraman R., 1993, The International Journal of Aviation Psychology, V3, P1, DOI DOI 10.1207/S15327108IJAP03011; Parasuraman R, 2010, HUM FACTORS, V52, P381, DOI 10.1177/0018720810376055; Peeters M. C. W., 2022, Digital transformationTowards new frontiers and business opportunities; Pentland BT, 2022, ORGAN SCI, V33, P194, DOI 10.1287/orsc.2021.1543; Pentland BT, 2020, MIS QUART, V44, P19, DOI 10.25300/MISQ/2020/14458; Plattfaut R., 2019, ICIS 2019 Proceedings; Plattfaut R, 2022, J INF SYST, V36, P173, DOI 10.2308/ISYS-2020-033; Pudari R, 2023, Arxiv, DOI arXiv:2303.04142; Rasheed Z, 2023, Arxiv, DOI [arXiv:2311.18440, 10.48550/arXiv.2311.18440]; Reijers H, 2016, INT J INFORM MANAGE, V36, P126, DOI 10.1016/j.ijinfomgt.2015.08.003; Reisert C., 2018, Business Process Management Cases, P21; Rieger T, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07808-x; Ross Steven I., 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P491, DOI 10.1145/3581641.3584037; Sarker S, 2019, MIS QUART, V43, P695, DOI 10.25300/MISQ/2019/13747; Sarter N., 1997, Automation surprises, V2; SASSONE PG, 1987, ACM T INFORM SYST, V5, P273, DOI 10.1145/27641.28059; Sauer J, 2012, ERGONOMICS, V55, P840, DOI 10.1080/00140139.2012.676673; Schulte-Althoff M., 2023, P 56 HAW INT C SYST; Sheridan TB, 2016, HUM FACTORS, V58, P525, DOI 10.1177/0018720816644364; Stein J. A., 2022, Industrial craft in Australia: Oral histories of creativity and survival, P121; Syed R, 2020, COMPUT IND, V115, DOI 10.1016/j.compind.2019.103162; Tatasciore M, 2022, HUM FACTORS, V64, P1121, DOI 10.1177/0018720821989148; Techatassanasoontorn AA, 2023, J INF TECHNOL-UK, V38, P416, DOI 10.1177/02683962231157426; Thiergart J., 2021, arXiv, DOI DOI 10.48550/ARXIV.2102.03062; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Truong D., 2022, Robotic process automation and its effect on employees' attitude and behaviour; UiPath, 2022, How automation enables companies to meet sustainability objectives; van der Aalst WMP, 2018, BUS INFORM SYST ENG+, V60, P269, DOI 10.1007/s12599-018-0542-4; vom Brocke J, 2021, BUS INFORM SYST ENG+, V63, P483, DOI 10.1007/s12599-021-00718-8; Waizenegger L, 2022, AUSTRALAS J INF SYST, V26, P1, DOI 10.3127/ajis.v26i0.3833; Wiener E L., 1989, Human Factors of Advanced Technology ("Glass Cockpit") Transport Aircraft; Woods D.D., 1996, HUM FAC TRANSP, P3	97	0	0	0	0	ASSOC INFORMATION SYSTEMS	ATLANTA	GEORGIA STATE UNIV, 35 BROAD STREET, STE 916-917, ATLANTA, GA 30303 USA	1529-3181			COMMUN ASSOC INF SYS	Commun. Assoc. Inf. Syst.		2024	54									10.17705/1CAIS.05421	http://dx.doi.org/10.17705/1CAIS.05421			28	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	TK2F4					2024-07-03	WOS:001241084300004
J	Miranda, S; Pichardo-Lagunas, O; Martínez-Seis, B; Baldi, P				Miranda, Sabino; Pichardo-Lagunas, Obdulia; Martinez-Seis, Bella; Baldi, Pierre			Evaluating the Performance of Large Language Models for Spanish Language in Undergraduate Admissions Exams	COMPUTACION Y SISTEMAS			English	Article						Large Language Models; ChatGPT; BARD; Undergraduate Admissions Exams		This study evaluates the performance of large language models, specifically GPT-3.5 and BARD (supported by Gemini Pro model), in undergraduate admissions exams proposed by the cover Engineering/Mathematical and Physical Sciences, Biological and Medical Sciences, and Social and Administrative Sciences. Both models demonstrated proficiency, exceeding the minimum acceptance scores academic programs. GPT-3.5 outperformed BARD in Mathematics and Physics, while BARD performed better Overall, GPT-3.5 marginally surpassed BARD with scores of 60.94% and 60.42%, respectively.	[Miranda, Sabino; Pichardo-Lagunas, Obdulia; Martinez-Seis, Bella] Inst Politecn Nacl IPN, UPIITA, Mexico City, Mexico; [Baldi, Pierre] Univ Calif Irvine, Irvine, CA USA	University of California System; University of California Irvine	Pichardo-Lagunas, O (corresponding author), Inst Politecn Nacl IPN, UPIITA, Mexico City, Mexico.	smiranda@ieee.org; opichardola@ipn.mx; bcmartinez@ipn.mx; pfbaldi@ics.uci.edu	Pichardo-Lagunas, Obdulia/T-1633-2018					Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Angel MC, 2023, medRxiv, DOI [10.1101/2023.05.10.23289805, 10.1101/2023.05.10.23289805, DOI 10.1101/2023.05.10.23289805]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; de Winter JCF, 2023, INT J ARTIF INTELL E, DOI 10.1007/s40593-023-00372-z; Dempere J, 2023, FRONT EDUC, V8, DOI 10.3389/feduc.2023.1206936; Gemini Team G., 2023, Gemini: A Family of Highly Capable Multimodal Models; Gemini Team G., 2023, Introducing Gemini: our largest and most capable AI model; Google, 2023, Bard: Una herramienta de IA conversacional de Google; Guillen-Grima F, 2023, CLINICS PRACT, V13, P1460, DOI 10.3390/clinpract13060130; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; IPN, 2023, IPN Programa institucional de mediano plazo; Kepler I., 2023, Estadisticas del proceso de admision IPN 2022; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Madrid-Garcia A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-49483-6; OpenAI, 2023, "ChatGPT," OpenAI; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wolfram, 2023, Mathematical notation characters	19	0	0	5	5	INSTITUTO POLITECNICO NACIONAL (IPN) CENTRO DE INVESTIGACION EN COMPUTACION	MEXICO CITY	AV JUAN DIOS BATIZ, S N ESQ M OTHON MENDIZABAL, UP ADOLFO LOPEZ MATEOS ZACATENCO, MEXICO CITY, 07738, MEXICO	1405-5546	2007-9737		COMPUT SIST	Comput. Sist.		2023	27	4					1241	1248		10.13053/CyS-27-4-4790	http://dx.doi.org/10.13053/CyS-27-4-4790			8	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	DX7C9		Green Submitted			2024-07-03	WOS:001135440800015
J	Liu, SR; Mccoy, AB; Wright, AP; Carew, B; Genkins, JZ; Huang, SS; Peterson, JF; Steitz, B; Wright, A				Liu, Siru; Mccoy, Allison B.; Wright, Aileen P.; Carew, Babatunde; Genkins, Julian Z.; Huang, Sean S.; Peterson, Josh F.; Steitz, Bryan; Wright, Adam			Leveraging large language models for generating responses to patient messages-a subjective analysis	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Article						artificial intelligence; clinical decision support; large language model; patient portal; primary care		Objective This study aimed to develop and assess the performance of fine-tuned large language models for generating responses to patient messages sent via an electronic health record patient portal.Materials and Methods Utilizing a dataset of messages and responses extracted from the patient portal at a large academic medical center, we developed a model (CLAIR-Short) based on a pre-trained large language model (LLaMA-65B). In addition, we used the OpenAI API to update physician responses from an open-source dataset into a format with informative paragraphs that offered patient education while emphasizing empathy and professionalism. By combining with this dataset, we further fine-tuned our model (CLAIR-Long). To evaluate fine-tuned models, we used 10 representative patient portal questions in primary care to generate responses. We asked primary care physicians to review generated responses from our models and ChatGPT and rated them for empathy, responsiveness, accuracy, and usefulness.Results The dataset consisted of 499 794 pairs of patient messages and corresponding responses from the patient portal, with 5000 patient messages and ChatGPT-updated responses from an online platform. Four primary care physicians participated in the survey. CLAIR-Short exhibited the ability to generate concise responses similar to provider's responses. CLAIR-Long responses provided increased patient educational content compared to CLAIR-Short and were rated similarly to ChatGPT's responses, receiving positive evaluations for responsiveness, empathy, and accuracy, while receiving a neutral rating for usefulness.Conclusion This subjective analysis suggests that leveraging large language models to generate responses to patient messages demonstrates significant potential in facilitating communication between patients and healthcare providers.	[Liu, Siru; Mccoy, Allison B.; Wright, Aileen P.; Huang, Sean S.; Peterson, Josh F.; Steitz, Bryan; Wright, Adam] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, Nashville, TN 37212 USA; [Wright, Aileen P.; Huang, Sean S.; Peterson, Josh F.] Vanderbilt Univ, Med Ctr, Dept Med, Nashville, TN 37212 USA; [Carew, Babatunde] Vanderbilt Univ, Med Ctr, Dept Gen Internal Med & Publ Hlth, Nashville, TN 37212 USA; [Genkins, Julian Z.] Stanford Univ, Dept Med, Stanford, CA 94304 USA; [Liu, Siru] Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA	Vanderbilt University; Vanderbilt University; Vanderbilt University; Stanford University; Vanderbilt University	Liu, SR (corresponding author), Vanderbilt Univ, Med Ctr, Dept Biomed Informat, 2525 West End Ave 1475, Nashville, TN 37212 USA.	siru.liu@vumc.org	Liu, Siru/AAM-8737-2021; McCoy, Allison/I-1951-2013	Liu, Siru/0000-0002-5003-5354; McCoy, Allison/0000-0003-2292-9147	NIH [R00LM014097- 01, R01AG062499-01, R01LM013995-01]	NIH(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by NIH grants: R00LM014097- 01, R01AG062499-01, and R01LM013995-01.	Abid A., ARXIV; Adler-Milstein J, 2020, J AM MED INFORM ASSN, V27, P531, DOI 10.1093/jamia/ocz220; Akbar F, 2021, J AM MED INFORM ASSN, V28, P923, DOI 10.1093/jamia/ocaa229; Arndt BG, 2017, ANN FAM MED, V15, P419, DOI 10.1370/afm.2121; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chambon PJ, 2023, J AM MED INFORM ASSN, V30, P318, DOI 10.1093/jamia/ocac219; Friedman CP, 2009, J AM MED INFORM ASSN, V16, P169, DOI 10.1197/jamia.M3092; Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010; Heisey-Grove DM, 2020, TELEMED E-HEALTH, V26, P1345, DOI 10.1089/tmj.2019.0192; Holmgren AJ, 2022, J AM MED INFORM ASSN, V29, P453, DOI 10.1093/jamia/ocab268; Hu EJ., 2021, Lora: Low-rank adaptation of large language models; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Kumah-Crystal Y, 2023, J AM MED INFORM ASSN, V30, P1558, DOI 10.1093/jamia/ocad104; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lavril T., 2023, ARXIV; Li Y. J., ARXIV; Lieu TA, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.18287; Liu JL, 2023, NURS OUTLOOK, V71, DOI 10.1016/j.outlook.2023.102064; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Lu H., arXiv; Min B., RECENT ADV NATURAL L; openai, ChatGPT: Optimizing language models for dialogue; Peng Baolin, 2023, ARXIV; Sinsky CA, 2022, J GEN INTERN MED, V37, P4002, DOI 10.1007/s11606-022-07766-0; Sorace J, 2020, INT J MED INFORM, V136, DOI 10.1016/j.ijmedinf.2019.104037; Steitz BD, 2021, JAMA NETW OPEN, V4, DOI 10.1001/jamanetworkopen.2021.29553; Taori R., 2023, GITHUB REPOS; Tarver WL, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7851; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang CY, 2023, J MED INTERNET RES, V25, DOI 10.2196/48009; Zhou C., 2023, ARXIV	34	3	3	9	9	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	MAY 20	2024	31	6					1367	1379		10.1093/jamia/ocae052	http://dx.doi.org/10.1093/jamia/ocae052		MAR 2024	13	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	RK8S6	38497958	hybrid, Green Accepted			2024-07-03	WOS:001186483200001
J	Bellini-Leite, SC				Bellini-Leite, Samuel C.			Dual Process Theory for Large Language Models: An overview of using Psychology to address hallucination and reliability issues	ADAPTIVE BEHAVIOR			English	Article; Early Access						Large Language Models; Chain-of-Thoughts; Tree-of-Thoughts; hallucinations; Dual Process Theory	WORKING-MEMORY CAPACITY; INDIVIDUAL-DIFFERENCES; CREATIVE COGNITION; SITUATED AGENTS; 2 SYSTEMS; FUTURE; EVANS; OPERATIONS; BELIEF; NEED	State-of-the-art Large Language Models have recently exhibited extraordinary linguistic abilities which have surprisingly extended to reasoning. However, responses that are unreliable, false, or invented are still a frequent issue. It has been argued that scaling up strategies, as in increasing model size or hardware power, might not be enough to resolve the issue. Recent research has implemented Type 2 strategies (such as Chain-of-Thought and Tree-of-Thought), as strategies that mimic Type 2 reasoning, from Dual Process Theory, to interact with Large Language Models for improved results. The current paper reviews these strategies in light of the Predicting and Reflecting Framework for understanding Dual Process Theory and suggests what Psychology, drawing from research in executive functions, thinking disposition and creativity, can further contribute to possible implementations that address hallucination and reliability issues.	[Bellini-Leite, Samuel C.] Minas Gerais State Univ, Belo Horizonte, Brazil; [Bellini-Leite, Samuel C.] Minas Gerais State Univ, R Goncalves Dias 1434 Lourdes, BR-30140092 Belo Horizonte, Brazil		Bellini-Leite, SC (corresponding author), Minas Gerais State Univ, R Goncalves Dias 1434 Lourdes, BR-30140092 Belo Horizonte, Brazil.	samuel.leite@uemg.br		Bellini-Leite, Samuel/0000-0003-0178-0267	Minas Gerais State University	Minas Gerais State University	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by Minas Gerais State University.	AlKhars M, 2019, PSYCHOL RES BEHAV MA, V12, P263, DOI 10.2147/PRBM.S193092; [Anonymous], 1963, COMPUTERS THOUGHT; Auto-GPT, 2023, An autonomous gpt-4 experiment; BADDELEY A, 1992, SCIENCE, V255, P556, DOI 10.1126/science.1736359; Baggetta P, 2016, MIND BRAIN EDUC, V10, P10, DOI 10.1111/mbe.12100; Bellini-Leite S. C., 2017, Predicting and reflecting: A dual framework for dual process theory; Bellini-Leite S.C., 2020, ROUTLEDGE HDB BOUNDE, P207, DOI DOI 10.4324/9781315658353-13; Bellini-Leite SC, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.805386; Bellini-Leite SC, 2018, REV PHILOS PSYCHOL, V9, P213, DOI 10.1007/s13164-017-0376-x; Berglund L, 2024, Arxiv, DOI [arXiv:2309.12288, DOI 10.48550/ARXIV.2309.12288]; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Boden MA, 2007, THINK-PHILOS EVERYON, V5, P83, DOI 10.1017/S147717560000230X; CACIOPPO JT, 1982, J PERS SOC PSYCHOL, V42, P116, DOI 10.1037/0022-3514.42.1.116; Cao L, 2024, Arxiv, DOI arXiv:2308.09267; Chen M., 2021, arXiv; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Clark A., 2015, Open MIND: 7(T), DOI 10.15502/9783958570115; Clark A, 2016, TLS-TIMES LIT SUPPL, P6; Clark A, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00270; Clark A, 2013, BEHAV BRAIN SCI, V36, P181, DOI 10.1017/S0140525X12000477; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cropley A, 2006, CREATIVITY RES J, V18, P391, DOI 10.1207/s15326934crj1803_13; Croskerry P, 2003, ANN EMERG MED, V41, P110, DOI 10.1067/mem.2003.22; DeCaro MS, 2018, THINK REASONING, V24, P315, DOI 10.1080/13546783.2017.1396253; DeCaro MS, 2016, J EXP PSYCHOL LEARN, V42, P39, DOI 10.1037/xlm0000152; Dhuliawala S, 2023, Arxiv, DOI [arXiv:2309.11495, 10.48550/arXiv.2309.11495]; Ding JF, 2023, LANG COGN NEUROSCI, DOI 10.1080/23273798.2023.2212819; Du YL, 2023, Arxiv, DOI arXiv:2305.14325; Dziri N, 2023, Arxiv, DOI [arXiv:2305.18654, 10.48550/arXiv.2305.18654, DOI 10.48550/ARXIV.2305.18654]; Evans J. S. B. T., 1996, Rationality and Reasoning (Essays in Cognitive Psychology); Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685; Evans JonathanB. T., 2007, Hypothetical thinking: dual processes in reasoning and judgement, DOI DOI 10.4324/9780203947487; Evans JSB., 2009, Two minds: Dual processes and beyond; Fernando C, 2023, Arxiv, DOI arXiv:2309.16797; Finke R., 1990, Creative imagery: Discoveries and inventions in visualization; Finke RA, 1996, CREATIVE COGNITION T; Fluri L, 2023, Arxiv, DOI [arXiv:2306.09983, 10.48550/arXiv.2306.09983, DOI 10.48550/ARXIV.2306.09983]; Fodor J.A., 1968, PSYCHOL EXPLANATION; FODOR JA, 1988, COGNITION, V28, P3, DOI 10.1016/0010-0277(88)90031-5; Frankish K., 2009, 2 MINDS DUAL PROCESS, P89; Frankish K, 2009, SYNTH LIBR, V342, P75, DOI 10.1007/978-1-4020-9198-8_4; Frederick S, 2005, J ECON PERSPECT, V19, P25, DOI 10.1257/089533005775196732; Friston KJ, 2010, NAT REV NEUROSCI, V11, P127, DOI 10.1038/nrn2787; Friston KJ, 2005, PHILOS T R SOC B, V360, P815, DOI 10.1098/rstb.2005.1622; Geva M, 2021, T ASSOC COMPUT LING, V9, P346, DOI 10.1162/tacl_a_00370; Gilhooly K.J., 2004, The Cognitive Psychology of Planning, P81, DOI [10.4324/9780203493564-15, DOI 10.4324/9780203493564-15]; Hsieh CY, 2023, Arxiv, DOI arXiv:2305.02301; Hu PB, 2023, Arxiv, DOI arXiv:2308.09658; Jaarsveld S, 2005, COGNITIVE SCI, V29, P79, DOI 10.1207/s15516709cog2901_4; Jansson D.G., 1991, DESIGN STUDIES, V12, P3, DOI [10.1016/0142-694X(91)90003-F, DOI 10.1016/0142-694X(91)90003-F]; Jiang PL, 2023, Arxiv, DOI arXiv:2305.11473; Johnson M, 2002, COGN LINGUIST, V13, P245, DOI 10.1515/cogl.2002.016; Johnson-Laird P.N., 1983, Mental models: Towards a cognitive science of language, inference, and consciousness; Kahneman D, 2003, AM PSYCHOL, V58, P697, DOI 10.1037/0003-066X.58.9.697; Kahneman D., 2011, THINKING FAST SLOW; Keren G, 2013, PERSPECT PSYCHOL SCI, V8, P257, DOI 10.1177/1745691613483474; Keren G, 2009, PERSPECT PSYCHOL SCI, V4, P533, DOI 10.1111/j.1745-6924.2009.01164.x; Kosslyn S. M., 1996, Image and brain: The resolution of the imagery delate; Kruglanski AW, 2013, PERSPECT PSYCHOL SCI, V8, P242, DOI 10.1177/1745691613483477; Kruglanski AW, 2011, PSYCHOL REV, V118, P97, DOI 10.1037/a0020762; Lindeman M, 2011, J COGN CULT, V11, P231, DOI 10.1163/156853711X570038; Ling W, 2017, Arxiv, DOI arXiv:1705.04146; Ling Z, 2023, Arxiv, DOI arXiv:2306.03872; Liu ZY, 2023, Arxiv, DOI arXiv:2306.15724; Long JY, 2023, Arxiv, DOI arXiv:2305.08291; Madaan A, 2023, Arxiv, DOI [arXiv:2303.17651, DOI 10.48550/ARXIV.2303.17651, 10.48550/arXiv.2303.17651]; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; McNamara T. P., 2005, Semantic Priming: Perspectives from Memory and Word Recognition, DOI [10.4324/9780203338001, DOI 10.4324/9780203338001]; MERCIER H., 2017, The enigma of reason; Miyake A, 2000, COGNITIVE PSYCHOL, V41, P49, DOI 10.1006/cogp.1999.0734; Morewedge C. K., 2015, Policy Insights from the Behavioral and Brain Sciences, V2, P129; Mumford MD, 2012, CREATIVITY RES J, V24, P311, DOI 10.1080/10400419.2012.730008; Narmashiri A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-30457-7; NEWELL A, 1980, COGNITIVE SCI, V4, P135, DOI 10.1016/S0364-0213(80)80015-2; NEWELL A, 1976, COMMUN ACM, V19, P113, DOI 10.1145/360018.360022; Nye M., 2020, ArXiv preprint ArXiv:2003.05562, DOI [10.48550/arXiv.2003.05562, DOI 10.48550/ARXIV.2003.05562]; Nye Maxwell, 2021, arXiv; Open X-Embodiment Collaboration, 2023, Open X-Embodiment; OpenAI, 2023, GPT-4 technical report, DOI [10.48550/arXiv.2303.08774, DOI 10.48550/ARXIV.2303.08774]; Osman M, 2004, PSYCHON B REV, V11, P988, DOI 10.3758/BF03196730; Osman M, 2013, PERSPECT PSYCHOL SCI, V8, P248, DOI 10.1177/1745691613483475; Paranjape B, 2023, Arxiv, DOI arXiv:2303.09014; Patel Arkil, 2021, PREPRINT; Pezzulo G., 2023, Generating Meaning: Active Inference and Generative AI, DOI DOI 10.31234/OSF.IO/8XGZV; Phillips LH, 2001, Q J EXP PSYCHOL-A, V54, P579, DOI 10.1080/02724980042000237; Purcell A.T., 1998, DESIGN STUD, V19, P389, DOI [DOI 10.1016/S0142-694X, 10.1016/S0142-694X(98)00015-5, DOI 10.1016/S0142-694X(98)00015-5]; Pylyshyn Z.W., 1987, ROBOTS DILEMMA FRAME; Samuels Richard., 2009, Two Minds: Dual Processes and beyond, DOI DOI 10.1093/ACPROF:OSO/9780199230167.003.0006; Shearman SM, 2006, COMMUN Q, V54, P275, DOI 10.1080/01463370600877950; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Shipstead Z, 2016, PERSPECT PSYCHOL SCI, V11, P771, DOI 10.1177/1745691616650647; Shridhar M., 2020, arXiv; Si CL, 2023, Arxiv, DOI arXiv:2210.09150; Sloman SA, 1996, PSYCHOL BULL, V119, P3, DOI 10.1037/0033-2909.119.1.3; SMITH SM, 1991, AM J PSYCHOL, V104, P61, DOI 10.2307/1422851; Srivastava Aarohi, 2022, arXiv; Stanovich K. E., 1998, THINK REASONING, V4, P289, DOI DOI 10.1080/135467898394094; Stanovich K.E., 2012, MIND SOC, V11, P3, DOI DOI 10.1007/S11299-011-0093-6; Stanovich KE, 1997, J EDUC PSYCHOL, V89, P342, DOI 10.1037/0022-0663.89.2.342; Stanovich KE, 2016, RATIONALITY QUOTIENT: TOWARD A TEST OF RATIONAL THINKING, P1, DOI 10.7551/mitpress/9780262034845.001.0001; Stanovich KE, 2023, J INTELL-BASEL, V11, DOI 10.3390/jintelligence11020027; STRATHMAN A, 1994, J PERS SOC PSYCHOL, V66, P742, DOI 10.1037/0022-3514.66.4.742; Suzgun Mirac, 2022, arXiv; Svedholm AM, 2013, BRIT J PSYCHOL, V104, P303, DOI 10.1111/j.2044-8295.2012.02118.x; Taniguchi T, 2023, ADV ROBOTICS, V37, P780, DOI 10.1080/01691864.2023.2225232; Toplak ME, 2014, DEV PSYCHOL, V50, P1037, DOI 10.1037/a0034910; Valmeekam K, 2023, Arxiv, DOI [arXiv:2206.10498, 10.48550/arXiv.2206.10498]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang HH, 2017, Arxiv, DOI arXiv:1702.07800; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; WEBSTER DM, 1994, J PERS SOC PSYCHOL, V67, P1049, DOI 10.1037/0022-3514.67.6.1049; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Welling H, 2007, CREATIVITY RES J, V19, P163, DOI 10.1080/10400410701397214; Willingham D.T., 2008, American Educator, V109, P21, DOI [10.3200/AEPR.109.4.21-32, DOI 10.3200/AEPR.109.4.21-32]; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Xiong Jing, 2022, arXiv; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Yang Z, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2369; Yao S, 2022, Advances in Neural Information Processing Systems, P20744; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zhang MR, 2023, Arxiv, DOI arXiv:2305.13534; Zhang Z., 2022, arXiv; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]; Zhao RC, 2023, Arxiv, DOI arXiv:2305.03268; Zheng S, 2023, Arxiv, DOI [arXiv:2309.16583, 10.48550/arXiv.2309.16583]; Zhuge M, 2023, arXiv	129	1	1	13	22	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123	1741-2633		ADAPT BEHAV	Adapt. Behav.	2023 OCT 23	2023										10.1177/10597123231206604	http://dx.doi.org/10.1177/10597123231206604		OCT 2023	15	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Psychology; Social Sciences - Other Topics	W3QZ3					2024-07-03	WOS:001090820300001
J	Minssen, T; Vayena, E; Cohen, IG				Minssen, Timo; Vayena, Effy; Cohen, I. Glenn			The Challenges for Regulating Medical Use of ChatGPT and Other Large Language Models	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Editorial Material								This Viewpoint discusses how regulators across the world should approach the legal and ethical challenges, including privacy, device regulation, competition, intellectual property rights, cybersecurity, and liability, raised by the medical use of large language models.	[Minssen, Timo] Univ Copenhagen, Ctr Adv Studies Biomed Innovat Law, Copenhagen, Denmark; [Minssen, Timo] Univ Cambridge, Ctr Law Med & Life Sci, Cambridge, England; [Vayena, Effy] Swiss Fed Inst Technol, Inst Translat Med, Swiss Fed Inst Technol Zurich, Zurich, Switzerland; [Cohen, I. Glenn] Harvard Univ, Petrie Flom Ctr Hlth Law Policy Biotechnol & Bioet, Harvard Law Sch, Cambridge, MA USA; [Cohen, I. Glenn] Harvard Univ, 1525 Massachusetts Ave, Cambridge, MA 02138 USA	University of Copenhagen; University of Cambridge; Swiss Federal Institutes of Technology Domain; ETH Zurich; Harvard University; Harvard University	Cohen, IG (corresponding author), Harvard Univ, 1525 Massachusetts Ave, Cambridge, MA 02138 USA.	igcohen@law.harvard.edu		Minssen, Timo/0000-0002-3286-4888	Novo Nordisk Foundation [NNF17SA0027784]	Novo Nordisk Foundation(Novo Nordisk FoundationNovocure Limited)	& nbsp;Dr Minssen and Mr Cohen reported receiving grant NNF17SA0027784 from the Novo Nordisk Foundation.	Chilton J., NEW RISKS CHATGPT PO; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hoppner T., 2023, ChatGPT, Bard & Co.: an introduction to AI for competition and regulatory lawyers; Minssen T, 2021, J LAW BIOSCI, V7, DOI 10.1093/jlb/lsaa002; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Mukherjee S., EU PROPOSES NEW COPY; Weatherbed J., OPENAIS REGULATORY T	7	32	32	19	52	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	JUL 25	2023	330	4					315	316		10.1001/jama.2023.9651	http://dx.doi.org/10.1001/jama.2023.9651		JUL 2023	2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	Q6OL3	37410482	Green Submitted			2024-07-03	WOS:001025154600002
C	Fernandez, P; Chaffin, A; Tit, K; Chappelier, V; Furon, T			IEEE	Fernandez, Pierre; Chaffin, Antoine; Tit, Karim; Chappelier, Vivien; Furon, Teddy			Three Bricks to Consolidate Watermarks for Large Language Models	2023 IEEE INTERNATIONAL WORKSHOP ON INFORMATION FORENSICS AND SECURITY, WIFS	IEEE International Workshop on Information Forensics and Security		English	Proceedings Paper	IEEE International Workshop on Information Forensics and Security (WIFS)	DEC 04-07, 2023	Nurnberg, GERMANY	IEEE, IEEE Signal Proc Soc, Friedrich Alexander Univ Erlangen Nurnberg, Cognitec, Univ Bundeswehr Munchen, Code Res Inst Cyber Def		Watermarking; Large Language Model		Discerning between generated and natural texts is increasingly challenging. In this context, watermarking emerges as a promising technique for ascribing text to a specific generative model. It alters the sampling generation process to leave an invisible trace in the output, facilitating later detection. This research consolidates watermarks for large language models based on three theoretical and empirical considerations. First, we introduce new statistical tests that offer robust theoretical guarantees which remain valid even at low false-positive rates (less than 10-6). Second, we compare the effectiveness of watermarks using classical benchmarks in the field of natural language processing, gaining insights into their real-world applicability. Third, we develop advanced detection schemes for scenarios where access to the LLM is available, as well as multi-bit watermarking.	[Fernandez, Pierre; Chaffin, Antoine; Tit, Karim; Furon, Teddy] Univ Rennes, Ctr Inria, Rennes, France; [Chaffin, Antoine; Chappelier, Vivien] Imatag, Rennes, France; [Fernandez, Pierre] Meta AI, Rennes, France	Universite de Rennes	Fernandez, P (corresponding author), Univ Rennes, Ctr Inria, Rennes, France.; Fernandez, P (corresponding author), Meta AI, Rennes, France.	pierre.fernandez@inria.fr			ANR/AID [SAIDA ANR20-CHIA-0011]	ANR/AID	Work supported by ANR/AID under Chaire SAIDA ANR20-CHIA-0011. We also thank Thomas Scialom, Herv ' e J ' egou and Matthijs Douze for their insights throughout this work.	Aaronson S., 2023, Watermarking GPT Outputs; AnthropicAI, 2023, Introducing Claude; Austin Jacob, 2021, PROGRAM SYNTHESIS LA; Bengio Y, 2001, ADV NEUR IN, V13, P932; Chen M., 2021, ARXIV; Christ M., 2023, Cryptology ePrint Archive; Crothers E., 2022, arXiv; Dettmers T., 2023, ARXIV; Fan A., 2018, arXiv; Fernandez P., 2023, ICCV; Frieder S., 2023, arXiv, DOI DOI 10.31234/OSF.IO/B6P8D; Holtzman A., 2019, ARXIV; Ippolito D., 2019, arXiv; Joshi M., 2017, arXiv; Kalker T, 1999, PROC SPIE, V3657, P103, DOI 10.1117/12.344661; Kertysova K, 2018, SECUR HUM RIGHTS, V29, P55, DOI 10.1163/18750230-02901005; Kirchenbauer J., 2023, On the reliability of watermarks for large language models; Kirchenbauer J., 2023, ICML; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Kusen E., 2018, Online Social Networks and Media; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; M. T. review, 2023, Junk websites filled with ai-generated text are pulling in money from programmatic ads; Mitchell E., 2023, arXiv; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Phillipe Cardenuto J., 2023, ARXIV; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N., 2019, arXiv; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H., 2023, arXiv; Weidinger L, 2022, ACM C FAIRNESS ACCOU; Wen Y., 2023, arXiv; Yu Ning, 2022, ICLR; Zhao X., 2023, ARXIV	33	0	0	0	0	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2157-4766		979-8-3503-2491-4	IEEE INT WORKS INFOR			2023										10.1109/WIFS58808.2023.10374576	http://dx.doi.org/10.1109/WIFS58808.2023.10374576			6	Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW4YD		Green Submitted			2024-07-03	WOS:001156967300002
J	Kjell, ONE; Kjell, K; Schwartz, HA				Kjell, Oscar N. E.; Kjell, Katarina; Schwartz, H. Andrew			Beyond rating scales: With targeted evaluation, large language models are poised for psychological assessment	PSYCHIATRY RESEARCH			English	Review						Large language models; Transformers; Artificial intelligence; Psychology; Assessment	ITEM RESPONSE THEORY; SOCIAL MEDIA; PSYCHIATRIC-DIAGNOSIS; WORDS; AI	In this narrative review, we survey recent empirical evaluations of AI-based language assessments and present a case for the technology of large language models to be poised for changing standardized psychological assessment. Artificial intelligence has been undergoing a purported "paradigm shift" initiated by new machine learning models, large language models (e.g., BERT, LAMMA, and that behind ChatGPT). These models have led to unprecedented accuracy over most computerized language processing tasks, from web searches to automatic machine translation and question answering, while their dialogue-based forms, like ChatGPT have captured the interest of over a million users. The success of the large language model is mostly attributed to its capability to numerically represent words in their context, long a weakness of previous attempts to automate psychological assessment from language. While potential applications for automated therapy are beginning to be studied on the heels of chatGPT's success, here we present evidence that suggests, with thorough validation of targeted deployment scenarios, that AI's newest technology can move mental health assessment away from rating scales and to instead use how people naturally communicate, in language.	[Kjell, Oscar N. E.; Kjell, Katarina; Schwartz, H. Andrew] Lund Univ, Psychol Dept, Lund, Sweden; [Kjell, Oscar N. E.; Schwartz, H. Andrew] SUNY Stony Brook Univ, Comp Sci Dept, Stony Brook, NY USA	Lund University; State University of New York (SUNY) System; State University of New York (SUNY) Stony Brook	Kjell, ONE (corresponding author), Lund Univ, Psychol Dept, Lund, Sweden.	oscar.kjell@psy.lu.se		Kjell, Oscar/0000-0002-2728-6278	Swedish Research Council [2019-06305]; FORTE [2022-01022]; Andrew Schwartz from DARPA Young Faculty Award [W911NF-20-1-0206]; NSF/NIH Smart and Connected Health [R01 MH125702-01]; Swedish Research Council [2022-01022, 2019-06305] Funding Source: Swedish Research Council; Forte [2022-01022] Funding Source: Forte	Swedish Research Council(Swedish Research Council); FORTE(Swedish Research Council for Health Working Life & Welfare (Forte)); Andrew Schwartz from DARPA Young Faculty Award; NSF/NIH Smart and Connected Health; Swedish Research Council(Swedish Research Council); Forte(Swedish Research Council for Health Working Life & Welfare (Forte))	Oscar Kjell received funding from the Swedish Research Council (2019-06305) , Katarina Kjell from FORTE (2022-01022) and Andrew Schwartz from DARPA Young Faculty Award (W911NF-20-1-0206) , and the NSF/NIH Smart and Connected Health (R01 MH125702-01) .	Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Andrew Schwartz H., 2017, P 2017 C EMPIRICAL M, P55, DOI DOI 10.18653/V1/D17-2010; [Anonymous], 2008, ICML 08; Argamon Shlomo, 2007, First Monday; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bajaj Payal., 2022, arXiv; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Berger J, 2022, AM PSYCHOL, V77, P525, DOI 10.1037/amp0000882; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Boucher EM, 2021, EXPERT REV MED DEVIC, V18, P37, DOI 10.1080/17434440.2021.2013200; Boyd RL, 2021, J LANG SOC PSYCHOL, V40, P21, DOI [10.1177/0261927x20967028, 10.1177/0261927X20967028]; Brown P. F., 1992, Computational Linguistics, V18, P467; Chandler C., 2020, Intelligence-Based Medicine, V1, P100006, DOI DOI 10.1016/J.IBMED.2020.100006; Chandler C, 2020, SCHIZOPHRENIA BULL, V46, P11, DOI 10.1093/schbul/sbz105; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Coppersmith G., 2015, P 2 WORKSHOP COMPUTA, P31, DOI [DOI 10.3115/V1/W15-1204, 10.3115/v1/w15-1204, 10.3115/v1/W15-1204]; Curtis B, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194290; D'Alfonso S, 2020, CURR OPIN PSYCHOL, V36, P112, DOI 10.1016/j.copsyc.2020.04.005; De Bruyne L, 2022, COMPUT SPEECH LANG, V71, DOI 10.1016/j.csl.2021.101257; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Delgadillo J, 2020, JAMA PSYCHIAT, V77, P889, DOI 10.1001/jamapsychiatry.2020.1048; DeRubeis RJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0083875; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eichstaedt JC, 2021, PSYCHOL METHODS, V26, P398, DOI 10.1037/met0000349; Eichstaedt JC, 2018, P NATL ACAD SCI USA, V115, P11203, DOI 10.1073/pnas.1802331115; Eijsbroek V., 2023, The LEADING Statement Reporting Guidelines for Expert Panel, Best Estimate Diagnosis, and Longitudinal Expert All Data (LEAD) Studies; European Commission, 2023, CE marking. CE Marking; Ganesan AV, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4515, DOI 10.18653/v1/2021.naacl-main.357; Gao P., 2023, Int. J. Comput. Vis., P1; Gratch J, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P85; Halliday M. A. K., 1978, LANGUAGE SOCIAL SEMI; Hauglid M.K., 2023, Oslo Law Rev, V1, P1, DOI [10.18261/olr.10.1.1, DOI 10.18261/OLR.10.1.1]; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Iliev R, 2015, LANG COGN, V7, P265, DOI 10.1017/langcog.2014.30; Jackson JC, 2022, PERSPECT PSYCHOL SCI, V17, P805, DOI 10.1177/17456916211004899; JELINEK F, 1975, IEEE T INFORM THEORY, V21, P250, DOI 10.1109/TIT.1975.1055384; Ji SX, 2021, Arxiv, DOI arXiv:2110.15621; Jobin A, 2019, NAT MACH INTELL, V1, P389, DOI 10.1038/s42256-019-0088-2; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kelly D, 2022, BIOL PSYCHIAT, V91, pS50; Kjell K, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.602581; Kjell ONE, 2016, SOC INDIC RES, V126, P893, DOI 10.1007/s11205-015-0903-z; Kjell O, 2023, PSYCHOL METHODS, V28, P1478, DOI 10.1037/met0000542; Kjell O, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.601679; Kjell ONE, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-07520-w; Kjell ONE, 2019, PSYCHOL METHODS, V24, P92, DOI 10.1037/met0000191; Kroenke K, 2002, PSYCHIAT ANN, V32, P509, DOI 10.3928/0048-5713-20020901-06; Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166; Kwantes PJ, 2016, PERS INDIV DIFFER, V102, P229, DOI 10.1016/j.paid.2016.07.010; Landauer TK, 1999, DISCOURSE PROCESS, V27, P303, DOI 10.1080/01638539909545065; LECKMAN JF, 1982, ARCH GEN PSYCHIAT, V39, P879; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Leidner J.L., 2017, P 1 ACL WORKSH ETH N, P30, DOI [10.18653/v1/W17-1604, DOI 10.18653/V1/W17-1604]; Li JC, 2021, JMIR MED INF, V9, DOI 10.2196/28227; Likert R., 1932, ARCH PSYCHOL, V22 140, P55, DOI DOI 10.4135/9781412961288.N454; Lison P, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4188; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lord F.M., 1980, Applications of item response theory to practical testing problems; Lynn V., 2020, P 58 ANN M ASS COMP, P5306; Lynn Veronica, 2018, P 5 WORKSHOP COMPUTA, P37, DOI DOI 10.18653/V1/W18; MacAvaney Sean, 2021, P 7 WORKSH COMP LING, P70, DOI DOI 10.18653/V1/2021.CLPSYCH-1.7; MacKay D.J.C., 2023, Information Theory, Inference, and Learning Algorithms, P640; Markov A.A., 1913, An Example of Statistical Investigation in The Text of "Eugene Onegin" Illustrating Coupling "Tests" in Chains, V7, P153; Matero M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00776-0; Matero M, 2022, Arxiv, DOI arXiv:2112.13795; Matero Matthew, 2019, CLPSYCH, P39, DOI [10.18653/v1/W19-3005, DOI 10.18653/V1/W19-3005]; Melcher J, 2020, EVID-BASED MENT HEAL, V23, P161, DOI 10.1136/ebmental-2020-300180; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mohammadi Elham., 2019, P 6 WORKSHOP COMPUTA, P34, DOI DOI 10.18653/V1/W19-3004; Nangia N, 2019, Arxiv, DOI arXiv:1905.10425; Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355; Nayak Pandu, 2019, Understanding searches better than ever before; NOVICK MR, 1966, J MATH PSYCHOL, V3, P1, DOI 10.1016/0022-2496(66)90002-2; Oltmanns JR, 2021, J PSYCHIATR RES, V143, P239, DOI 10.1016/j.jpsychires.2021.09.015; OSGOOD CE, 1952, PSYCHOL BULL, V49, P197, DOI 10.1037/h0055737; Panda S., 2021, P 4 WORKSH NLP INT F, P125; Park G, 2015, J PERS SOC PSYCHOL, V108, P934, DOI 10.1037/pspp0000020; Parmar P, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00560-6; Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041; Peters Dorian, 2020, IEEE Transactions on Technology and Society, V1, P34, DOI 10.1109/TTS.2020.2974991; Peters M., 2018, P 2018 C N AM CHAPTE, DOI DOI 10.18653/V1/N18-1202; Preotiuc-Pietro D., 2016, P 7 WORKSH COMP APPR, P9, DOI [10.18653/v1/W16-0404, DOI 10.18653/V1/W16-0404]; Reise SP, 2009, ANNU REV CLIN PSYCHO, V5, P27, DOI 10.1146/annurev.clinpsy.032408.153553; Resnik P, 1995, INT JOINT CONF ARTIF, P448; Sarzynska-Wawer J, 2021, PSYCHIAT RES, V304, DOI 10.1016/j.psychres.2021.114135; Sawhney R, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7685; Schwartz H, 2014, P WORKSHOP COMPUTATI, P118, DOI [10.3115/v1/W14-3214, DOI 10.3115/V1/W14-3214, 10.3115/v1/w14-3214]; Schwartz HA, 2015, ANN AM ACAD POLIT SS, V659, P78, DOI 10.1177/0002716215569197; Schwartz HA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073791; Seppälä J, 2019, JMIR MENT HEALTH, V6, DOI 10.2196/mental.9819; Shah Deven Santosh, 2020, P 58 ANN M ASS COMPU, P5248, DOI [10.18653/v1/2020.acl-main.468, DOI 10.18653/V1/2020.ACL-MAIN.468, 10.18653/v1/2020.aclmain.468]; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Son Y, 2023, PSYCHOL MED, V53, P918, DOI 10.1017/S0033291721002294; Soni N, 2022, Arxiv, DOI arXiv:2205.05128; SPITZER RL, 1983, COMPR PSYCHIAT, V24, P399, DOI 10.1016/0010-440X(83)90032-9; Stade E., 2023, Artificial Intelligence Will Change the Future of Psychotherapy: A Proposal for Responsible, Psychologist-led Development; Sun J, 2020, J PERS SOC PSYCHOL, V118, P364, DOI 10.1037/pspp0000244; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; SWITZER P, 1965, STAT ASSOC METHOD M, V1964, P163; Tanana MJ, 2021, BEHAV RES METHODS, V53, P2069, DOI 10.3758/s13428-020-01531-z; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; Thomas ML, 2011, ASSESSMENT, V18, P291, DOI 10.1177/1073191110374797; Torous J, 2021, WORLD PSYCHIATRY, V20, P318, DOI 10.1002/wps.20883; Tsakalidis A., 2022, P 8 WORKSH COMP LING, P184, DOI DOI 10.18653/V1/2022.CLPSYCH-1.16; US Food and Drug Administration (FDA), 2021, Tech. Rep, 1; Vaswani A, 2017, ADV NEUR IN, V30; Veale M, 2021, COMPUTER LAW REV INT, V22, P97, DOI DOI 10.9785/CRI-2021-220402; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wang A, 2019, ADV NEUR IN, V32; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; White House Office of Science and Technology Policy, 2022, Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People; Yang ZL, 2019, ADV NEUR IN, V32; Zirikly A., 2019, P 6 WORKSHOP COMPUTA, P24, DOI [DOI 10.18653/V1/W19-3003, 10.18653/V1/W19-3003]	116	3	3	58	58	ELSEVIER IRELAND LTD	CLARE	ELSEVIER HOUSE, BROOKVALE PLAZA, EAST PARK SHANNON, CO, CLARE, 00000, IRELAND	0165-1781	1872-7123		PSYCHIAT RES	Psychiatry Res.	MAR	2024	333								115667	10.1016/j.psychres.2023.115667	http://dx.doi.org/10.1016/j.psychres.2023.115667		JAN 2024	12	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	IR8X1	38290286	hybrid			2024-07-03	WOS:001168160200001
J	Lai, JQ; Yang, XR; Luo, WY; Zhou, LJ; Li, LC; Wang, YQ; Shi, XC				Lai, Jianqiao; Yang, Xinran; Luo, Wenyue; Zhou, Linjiang; Li, Langchen; Wang, Yongqi; Shi, Xiaochuan			RumorLLM: A Rumor Large Language Model-Based Fake-News-Detection Data-Augmentation Approach	APPLIED SCIENCES-BASEL			English	Article						fake-news detection; large language models; rumor generation; category imbalance; data augmentation		With the rapid development of the Internet and social media, false information, rumors, and misleading content have become pervasive, posing significant threats to public opinion and social stability, and even causing serious societal harm. This paper introduces a novel solution to address the challenges of fake news detection, presenting the "Rumor Large Language Models" (RumorLLM), a large language model finetuned with rumor writing styles and content. The key contributions include the development of RumorLLM and a data-augmentation method for small categories, effectively mitigating the issue of category imbalance in real-world fake-news datasets. Experimental results on the BuzzFeed and PolitiFact datasets demonstrate the superiority of the proposed model over baseline methods, particularly in F1 score and AUC-ROC. The model's robust performance highlights its effectiveness in handling imbalanced datasets and provides a promising solution to the pressing issue of false-information proliferation.	[Lai, Jianqiao; Yang, Xinran; Luo, Wenyue; Zhou, Linjiang; Li, Langchen; Wang, Yongqi; Shi, Xiaochuan] Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China	Wuhan University	Shi, XC (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Wuhan 430072, Peoples R China.	shixiaochuan@whu.edu.cn	Zhou, Linjiang/JFJ-9678-2023	Zhou, Linjiang/0000-0003-3886-1300; Shi, Xiaochuan/0000-0002-2044-0965	National Key Research and Development Program of China	National Key Research and Development Program of China	No Statement Available	Alzanin SM, 2019, KNOWL-BASED SYST, V185, DOI 10.1016/j.knosys.2019.104945; Amjad M, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P2537; Begus G, 2023, Arxiv, DOI arXiv:2305.00948; Bhattacharjee Saranya, 2023, Computational Intelligence in Pattern Recognition: Proceedings of CIPR 2023. Lecture Notes in Networks and Systems (725), P427, DOI 10.1007/978-981-99-3734-9_35; Cao J., 2020, Exploring the Role of Visual Content in Fake News Detection, P141, DOI DOI 10.1007/978-3-030-42699-6_8; Capuano N, 2023, NEUROCOMPUTING, V530, P91, DOI 10.1016/j.neucom.2023.02.005; Castillo C, 2011, 20 INT C WORLD WIDE, P675, DOI 10.1145/1963405.1963500; Granik M, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P900, DOI 10.1109/UKRCON.2017.8100379; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Hossain M.M., 2021, P INT C 4 IND REVOLU, P723; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu YJ, 2022, 2022 IEEE 12TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P152, DOI 10.1109/CCWC54503.2022.9720776; Islam N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199292; Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Liu Y, 2016, IEEE T COMPUT SOC SY, V3, P46, DOI 10.1109/TCSS.2016.2612980; Lyu S, 2020, IEEE SOUTHEASTCON, DOI 10.1109/southeastcon44009.2020.9249688; Ma J, 2016, P 25 INT JOINT C ART, P3818; Ma J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3049, DOI 10.1145/3308558.3313741; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Potthast M, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P231; Prasetijo AB, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, COMPUTER, AND ELECTRICAL ENGINEERING (ICITACEE), P45, DOI 10.1109/ICITACEE.2017.8257673; Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062; Qian SS, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P153, DOI 10.1145/3404835.3462871; Ran H., 2023, P AAAI C ARTIFICIAL; Raza S, 2022, INT J DATA SCI ANAL, V13, P335, DOI 10.1007/s41060-021-00302-z; Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877; Salah I, 2022, COMM COM INF SC, V1653, P29, DOI 10.1007/978-3-031-16210-7_3; Sampson J, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2377, DOI 10.1145/2983323.2983697; Shrestha Anu, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P120, DOI 10.1007/978-3-030-72240-1_9; Shrestha A, 2020, LECT NOTES COMPUT SC, V12259, P261, DOI 10.1007/978-3-030-61841-4_18; Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]; Song CG, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102437; Su T, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P893, DOI 10.1145/3331184.3331305; Tan L, 2023, MULTIMED TOOLS APPL, V82, P2941, DOI 10.1007/s11042-022-12800-8; Vaibhav V., 2019, P 13 WORKSHOP GRAPH, P134; Varshini USS, 2024, IEEE T COMPUT SOC SY, V11, P2418, DOI 10.1109/TCSS.2023.3269595; Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903; Wei J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6382; Wu Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P2560; Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901; Zhang PF, 2021, NEUROCOMPUTING, V458, P468, DOI 10.1016/j.neucom.2021.06.062; Zhou HH, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116517; Zhou KM, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1614; Zhou X., 2020, DIGITAL THREATS RES, V1, P1	45	1	1	10	10	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	APR	2024	14	8							3532	10.3390/app14083532	http://dx.doi.org/10.3390/app14083532			16	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	OX6Z1		gold			2024-07-03	WOS:001210628500001
J	Buchmann, R; Eder, J; Fill, HG; Frank, U; Karagiannis, D; Laurenzi, E; Mylopoulos, J; Plexousakis, D; Santos, MY				Buchmann, Robert; Eder, Johann; Fill, Han-Georg; Frank, Ulrich; Karagiannis, Dimitris; Laurenzi, Emanuele; Mylopoulos, John; Plexousakis, Dimitris; Santos, Maribel Yasmina			Large language models: Expectations for semantics-driven systems engineering	DATA & KNOWLEDGE ENGINEERING			English	Article						Large language models; Systems engineering; Conceptual modeling; Knowledge engineering	KNOWLEDGE; ENERGY; AGILE	The hype of Large Language Models manifests in disruptions, expectations or concerns in scientific communities that have focused for a long time on design-oriented research. The current experiences with Large Language Models and associated products (e.g. ChatGPT) lead to diverse positions regarding the foreseeable evolution of such products from the point of view of scholars who have been working with designed abstractions for most of their careers - typically relying on deterministic design decisions to ensure systems and automation reliability. Such expectations are collected in this paper in relation to a flavor of systems engineering that relies on explicit knowledge structures, introduced here as "semantics-driven systems engineering". The paper was motivated by the panel discussion that took place at CAiSE 2023 in Zaragoza, Spain, during the workshop on Knowledge Graphs for Semantics-driven Systems Engineering (KG4SDSE). The workshop brought together Conceptual Modeling researchers with an interest in specific applications of Knowledge Graphs and the semantic enrichment benefits they can bring to systems engineering. The panel context and consensus are summarized at the end of the paper, preceded by a proposed research agenda considering the expressed positions.	[Buchmann, Robert] Babes Bolyai Univ, Cluj Napoca, Romania; [Eder, Johann] Univ Alpen Adria Klagenfurt, Klagenfurt, Austria; [Fill, Han-Georg] Univ Fribourg, Fribourg, Switzerland; [Frank, Ulrich] Univ Duisburg Essen, Essen, Germany; [Karagiannis, Dimitris] Univ Vienna, Vienna, Austria; [Laurenzi, Emanuele] Univ Appl Sci & Arts Northwestern Switzerland, FHNW, Windisch, Switzerland; [Mylopoulos, John] Univ Toronto, Toronto, ON, Canada; [Plexousakis, Dimitris] FORTH, Inst Comp Sci, Rethimnon, Greece; [Plexousakis, Dimitris] Univ Crete, Rethimnon, Greece; [Santos, Maribel Yasmina] Univ Minho, Braga, Portugal; [Karagiannis, Dimitris] Univ Vienna, Res Grp Knowledge Engn, Wahringer Str 29, A-1090 Vienna, Austria; [Buchmann, Robert] Babes Bolyai Univ, Fac Econ & Business Adm, Business Informat Res Ctr, Str TH Mihali 58-60, Cluj Napoca 400591, Romania; [Buchmann, Robert] Babes Bolyai Univ, Fac Econ & Business Adm, OMILABUBB FSEGA, Str TH Mihali 58-60, Cluj Napoca 400591, Romania	Babes Bolyai University from Cluj; University of Fribourg; University of Duisburg Essen; University of Vienna; FHNW University of Applied Sciences & Arts Northwestern Switzerland; University of Toronto; Foundation for Research & Technology - Hellas (FORTH); University of Crete; Universidade do Minho; University of Vienna; Babes Bolyai University from Cluj; Babes Bolyai University from Cluj	Karagiannis, D (corresponding author), Univ Vienna, Res Grp Knowledge Engn, Wahringer Str 29, A-1090 Vienna, Austria.; Buchmann, R (corresponding author), Babes Bolyai Univ, Fac Econ & Business Adm, Business Informat Res Ctr, Str TH Mihali 58-60, Cluj Napoca 400591, Romania.; Buchmann, R (corresponding author), Babes Bolyai Univ, Fac Econ & Business Adm, OMILABUBB FSEGA, Str TH Mihali 58-60, Cluj Napoca 400591, Romania.	robert.buchmann@econ.ubbcluj.ro; johann.eder@aau.at; hans-georg.fill@unifr.ch; ulrich.frank@uni-due.de; dk@dke.univie.ac.at; emanuele.laurenzi@fhnw.ch; jm@cs.toronto.edu; dp@ics.forth.gr; maribel@dsi.uminho.pt			FORTH, Greece	FORTH, Greece	<BOLD>Acknowledgements</BOLD> We are thankful to OMiLAB NPO, Germany, and FORTH, Greece, for sponsoring the workshop where the ideas summarized here were initially debated. We also thank the workshop audience for engaging in the panel discussion, for sharing their own experience or raising inspiring questions, and not lastly the CAiSE 2023 organizers for hosting the event.	Adesina A O., 2019, Mousaion, V37; Alabed A, 2022, TECHNOL FORECAST SOC, V182, DOI 10.1016/j.techfore.2022.121786; Allen B.P., 2023, Trans. Graph Data Knowl, V19, P1; Alter S, 2022, LECT NOTES BUS INF P, V450, P237, DOI 10.1007/978-3-031-07475-2_16; Bock AC, 2021, BUS INFORM SYST ENG+, V63, P733, DOI 10.1007/s12599-021-00726-8; Brambilla M., 2017, Model-driven Software Engineering in Practice; Buchmann RA, 2016, BUS INFORM SYST ENG+, V58, P341, DOI 10.1007/s12599-016-0445-1; Buchmann RA, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON EVALUATION OF NOVEL APPROACHES TO SOFTWARE ENGINEERING, P233, DOI 10.5220/0006694102330240; Cámara J, 2023, SOFTW SYST MODEL, V22, P781, DOI 10.1007/s10270-023-01105-5; CEUR-WS, 2023, CEUR-WS policy on AI assisting tools; Church K, 2024, NAT LANG ENG, V30, P417, DOI 10.1017/S1351324923000578; Clariso Robert, 2023, 2023 ACM/IEEE 26th International Conference on Model Driven Engineering Languages and Systems (MODELS), P47, DOI 10.1109/MODELS58315.2023.00020; Curty S, 2023, SOFTW SYST MODEL, V22, P1857, DOI 10.1007/s10270-023-01109-1; Dahri NA, 2024, HELIYON, V10, DOI 10.1016/j.heliyon.2024.e29317; Deloitte, 2023, Knowledge graphs for financial services; Di Ruscio D, 2022, SOFTW SYST MODEL, V21, P437, DOI 10.1007/s10270-021-00970-2; Domingos P., 2017, The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World; Eder J., 1999, Advanced Information Systems Engineering. 11th International Conference, CAiSE'99. Proceedings (Lecture Notes in Computer Science Vol. 1626), P286; Elsevier, 2023, Elsevier policy on the use of AI in writing; Es S., 2024, P 18 C EUROPEAN CHAP, P150; Feuerriegel S, 2024, BUS INFORM SYST ENG+, V66, P111, DOI 10.1007/s12599-023-00834-7; Fill HG, 2023, ENTERP MODELLING INF, V18, P1, DOI 10.18417/emisa.18.3; Fill HG, 2017, SEMANT WEB, V8, P747, DOI 10.3233/SW-160235; Frank U., 2013, Domain Engineering, P133; Frank U, 2014, SOFTW SYST MODEL, V13, P941, DOI 10.1007/s10270-012-0273-9; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; García-Martín E, 2019, J PARALLEL DISTR COM, V134, P75, DOI 10.1016/j.jpdc.2019.07.007; Harer F., 2023, ER 2023 COMP P ER 20, P3618; Hinkelmann K, 2018, STUD SYST DECIS CONT, V141, P177, DOI 10.1007/978-3-319-74322-6_12; Hinkelmann K, 2016, COMPUT IND, V79, P77, DOI 10.1016/j.compind.2015.07.009; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Jin ZJ, 2024, Arxiv, DOI arXiv:2306.05836; Kahneman D, 2015, FORTUNE, V172, P20; Karagiannis D, 2022, COMPUT IND, V138, DOI 10.1016/j.compind.2022.103631; Karagiannis D, 2018, LECT NOTES BUS INF P, V273, P3, DOI 10.1007/978-3-319-73459-0_1; Karagiannis D, 2016, INFORM SYST, V56, P174, DOI 10.1016/j.is.2015.10.001; Karvounarakis Gregory., 2002, P 11 INT C WORLD WID, P592, DOI DOI 10.1145/511523.511524; Kumar A, 2024, Arxiv, DOI arXiv:2404.07981; Laurenzi E, 2024, ENTERP MODELLING INF, V19, DOI 10.18417/emisa.19.6; Laurenzi E, 2018, LECT NOTES BUS INF P, V335, P221, DOI 10.1007/978-3-030-02302-7_14; Lenat D, 2023, Arxiv, DOI arXiv:2308.04445; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Maass W, 2021, DATA KNOWL ENG, V134, DOI 10.1016/j.datak.2021.101909; Mendling J., 2022, PROCEDIA COMPUTER SC, V197, P10; Michelucci U., 2023, LNBIP, P493, DOI [10.1007/978-3-031-43126-5_12, DOI 10.1007/978-3-031-43126-5_12]; Mountantonakis M, 2023, LECT NOTES ARTIF INT, V14175, P324, DOI 10.1007/978-3-031-43430-3_24; MYLOPOULOS J, 1990, ACM T INFORM SYST, V8, P325, DOI 10.1145/102675.102676; Nonaka I, 2009, ORGAN SCI, V20, P635, DOI 10.1287/orsc.1080.0412; Österle H, 2011, EUR J INFORM SYST, V20, P7, DOI 10.1057/ejis.2010.55; OMiLAB NPO, 2023, The BEE-UP tool; Ontotext, 2023, REFLECTIONS KNOWLEDG; Opdahl AL, 2023, DATA KNOWL ENG, V146, DOI 10.1016/j.datak.2023.102182; Pan J.Z., 2023, Trans. Graph Data Knowl, V1, P38; Pan SR, 2024, IEEE T KNOWL DATA EN, V36, P3580, DOI 10.1109/TKDE.2024.3352100; Panas D, 2024, Arxiv, DOI arXiv:2404.19432; Patkos T., 2021, Domain-specific Conceptual Modeling, P457; Piaget J., 1950, PSYCHOL INTELLIGENCE; Polyvyanyy A., 2022, Process Querying Methods, DOI DOI 10.1007/978-3-030-92875-9; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rodorf D., 2023, P AAAI 2023 SPRING S; Rony MRA, 2022, IEEE ACCESS, V10, P70712, DOI 10.1109/ACCESS.2022.3188714; Saba Walid S., 2023, Conceptual Modeling: 42nd International Conference, ER 2023, Proceedings. Lecture Notes in Computer Science (14320), P3, DOI 10.1007/978-3-031-47262-6_1; Saif N, 2024, COMPUT HUM BEHAV, V154, DOI 10.1016/j.chb.2023.108097; Sandkuhl K, 2018, BUS INFORM SYST ENG+, V60, P69, DOI 10.1007/s12599-017-0516-y; Santos M Y., 2020, Big data: concepts, warehousing, and analytics; Security Week, AI Hallucinated Packages Fool Unsuspecting Developers; Sequeda JF, 2023, Arxiv, DOI arXiv:2311.07509; Shumailov I, 2024, Arxiv, DOI [arXiv:2305.17493, DOI 10.48550/ARXIV.2305.17493]; Stahl BC, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-34622-w; Stardog, 2023, LLM will accelerate knowledge graph adoption; Stechly K, 2024, Arxiv, DOI arXiv:2405.04776; Tiddi I, 2022, ARTIF INTELL, V302, DOI 10.1016/j.artint.2021.103627; van Harmelen F, 2019, J WEB ENG, V18, P97, DOI 10.13052/jwe1540-9589.18133; Verdecchia R, 2023, WIRES DATA MIN KNOWL, V13, DOI 10.1002/widm.1507; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; Witschel H.F., 2021, Studies in Systems, Decision and Control, V294, DOI [10.1007/978-3-030-48332-6_13, DOI 10.1007/978-3-030-48332-6_13]; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Wu H., 2023, Trans. Graph Data Knowl, V1, P7; Zhang BY, 2018, IEEE J EM SEL TOP C, V8, P836, DOI 10.1109/JETCAS.2018.2833383; Zhou JL, 2023, Arxiv, DOI arXiv:2305.10646; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	82	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0169-023X	1872-6933		DATA KNOWL ENG	Data Knowl. Eng.	JUL	2024	152								102324	10.1016/j.datak.2024.102324	http://dx.doi.org/10.1016/j.datak.2024.102324			13	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UQ5E8					2024-07-03	WOS:001249529200001
J	Kshetri, N				Kshetri, Nir			Cybercrime and Privacy Threats of Large Language Models	IT PROFESSIONAL			English	Editorial Material						Privacy; Analytical models; Behavioral sciences; Security; Computer crime		This article explores the privacy and security issues associated with large language models (LLMs). It takes a look at nefarious actors' possible use of LLM tools. Also analyzed are behaviors and practices of the developers, operators, and users of such models from privacy and security standpoints.	[Kshetri, Nir] Univ North Carolina Greensboro, Greensboro, NC 27412 USA	University of North Carolina; University of North Carolina Greensboro	Kshetri, N (corresponding author), Univ North Carolina Greensboro, Greensboro, NC 27412 USA.	nbkshetr@uncg.edu						[Anonymous], 2023, ALJAZEERA APR; Burgess M., 2023, Wired; Coles C., CYBERHAVEN; Kaminsky S., 2023, KASPERSKY JAN; Keary T., 2023, VENTUREBEAT MAR; Liebowitz M., 2011, NBC; Long J., 2023, MAC SECURIT; Merton-McCann A., MCAFEE; Newman L. H., 2023, WIRED; Smith C., 2023, BGR APR; Wilkinson L., 2023, CIO DIVE APR	11	4	4	21	43	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1520-9202	1941-045X		IT PROF	IT Prof.	MAY-JUN	2023	25	3					9	13		10.1109/MITP.2023.3275489	http://dx.doi.org/10.1109/MITP.2023.3275489			5	Computer Science, Information Systems; Computer Science, Software Engineering; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Telecommunications	L8BQ5					2024-07-03	WOS:001025462600002
J	Smetana, M; de Salles, LS; Sukharev, I; Khazanovich, L				Smetana, Mason; de Salles, Lucio Salles; Sukharev, Igor; Khazanovich, Lev			Highway Construction Safety Analysis Using Large Language Models	APPLIED SCIENCES-BASEL			English	Article						artificial intelligence; accidents; construction industry; machine learning; transportation		Featured Application Use of large language models and AI to analyze construction safety data.Abstract The highway construction industry carries substantial safety risks for workers, necessitating thorough accident analyses to implement effective preventive measures. Current research lacks comprehensive investigations into safety incidents, relying heavily on conventional statistical methods and overlooking valuable textual information in publicly available databases. This study leverages a state-of-the-art large language model (LLM), specifically OpenAI's GPT-3.5 model. The primary focus is to enhance text-based incident analysis that is sourced from OSHA's Severe Injury Reports (SIR) database. By incorporating novel natural language processing (NLP) techniques, dimensionality reduction, clustering algorithms, and LLM prompting of incident narratives, the study aims to develop an approach to the analysis of major accident causes in highway construction. The resulting cluster analysis, coupled with LLM summarization and cause identification, reveals the major accident types, such as heat-related and struck-by injuries, as well as commonalities between incidents. This research showcases the potential of artificial intelligence (AI) and LLM technology in data-driven analysis. By efficiently processing textual data and providing insightful analysis, the study fosters practical implications for safety professionals and the development of more effective accident prevention and intervention strategies within the industry.	[Smetana, Mason; Sukharev, Igor; Khazanovich, Lev] Univ Pittsburgh, Dept Civil & Environm Engn, Pittsburgh, PA 15261 USA; [de Salles, Lucio Salles] Rochester Inst Technol, Dept Civil Engn Technol Environm Management & Safe, Rochester, NY 14623 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Rochester Institute of Technology	de Salles, LS (corresponding author), Rochester Inst Technol, Dept Civil Engn Technol Environm Management & Safe, Rochester, NY 14623 USA.	mrs196@pitt.edu; lssite@rit.edu; igs18@pitt.edu; lev.k@pitt.edu		Salles de Salles, Lucio/0009-0000-9080-4448; Smetana, Mason/0009-0009-4130-3781; Khazanovich, Lev/0000-0002-8422-9181	University of Pittsburgh Anthony Gill Chair; IRISE technical panel	University of Pittsburgh Anthony Gill Chair; IRISE technical panel	The authors acknowledge the advice and assistance provided by the IRISE technical panel.	Abdolahi FH, 2021, SAF HEALTH WORK-KR, V12, P511, DOI 10.1016/j.shaw.2021.07.009; Al-Shabbani Z, 2018, TRANSPORT RES REC, V2672, P187, DOI 10.1177/0361198118792327; Alateeq MM, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15032358; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Ballal S., 2024, J. Eng. Proj. Prod. Manag, V14, P1, DOI [10.32738/JEPPM-2024-0014, DOI 10.32738/JEPPM-2024-0014]; Cambraia FB, 2010, SAFETY SCI, V48, P91, DOI 10.1016/j.ssci.2009.06.006; Chen P, 2023, P I MECH ENG O-J RIS, V237, P810, DOI 10.1177/1748006X221099094; Chokor A, 2016, PROCEDIA ENGINEER, V145, P1588, DOI 10.1016/j.proeng.2016.04.200; Das S, 2023, TRANSPORT RES REC, V2677, P222, DOI 10.1177/03611981231152254; Deng FJ, 2020, IEEE ACCESS, V8, P180171, DOI 10.1109/ACCESS.2020.3028235; Dhalmahapatra K, 2019, COMPUT IND ENG, V128, P277, DOI 10.1016/j.cie.2018.12.044; Dieng AB, 2020, T ASSOC COMPUT LING, V8, P439, DOI 10.1162/tacl_a_00325; Fang WL, 2020, ADV ENG INFORM, V44, DOI 10.1016/j.aei.2020.101060; Ganguli R, 2021, MINERALS-BASEL, V11, DOI 10.3390/min11070776; Goh YM, 2017, ACCIDENT ANAL PREV, V108, P122, DOI 10.1016/j.aap.2017.08.026; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Heidarysafa M, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1446, DOI 10.1109/ICMLA.2018.00235; Hinze J, 2005, J CONSTR ENG M ASCE, V131, P262, DOI 10.1061/(ASCE)0733-9364(2005)131:2(262); Hong Y, 2021, J CONSTR ENG M, V147, DOI 10.1061/(ASCE)CO.1943-7862.0002165; Jeon JH, 2021, TRANSPORT RES REC, V2675, P222, DOI 10.1177/03611981211001385; Kaur H, 2023, SAF HEALTH WORK-KR, V14, P406, DOI 10.1016/j.shaw.2023.10.003; Kazan E, 2018, J SAFETY RES, V65, P73, DOI 10.1016/j.jsr.2018.02.008; Li G, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097487; Li J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app131910599; Ma ZJ, 2021, ACCIDENT ANAL PREV, V160, DOI 10.1016/j.aap.2021.106322; Muennighoff N, 2022, Arxiv, DOI arXiv:2210.07316; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Pothina R, 2023, MINERALS-BASEL, V13, DOI 10.3390/min13060770; Prieto SA, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13040857; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Ricketts J, 2023, SAFETY, V9, DOI 10.3390/safety9020022; Saka A, 2024, DEV BUILT ENVIRON, V17, DOI 10.1016/j.dibe.2023.100300; Shen QY, 2022, BUILDINGS-BASEL, V12, DOI 10.3390/buildings12050564; Shohet IM, 2018, SAFETY SCI, V104, P231, DOI 10.1016/j.ssci.2018.01.005; Uddin SMJ, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15097121; Valcamonico D, 2022, P I MECH ENG O-J RIS, DOI 10.1177/1748006X221140196; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Yassin SS, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-3125-1; Yoo B, 2024, APPL SCI-BASEL, V14, DOI 10.3390/app14020664; Zheng Z, 2023, AUTOMAT CONSTR, V147, DOI 10.1016/j.autcon.2022.104711	44	0	0	49	49	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	FEB	2024	14	4							1352	10.3390/app14041352	http://dx.doi.org/10.3390/app14041352			23	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	JC2E8		gold			2024-07-03	WOS:001170884000001
J	Mcgraw, G; Bonett, R; Figueroa, H; Mcmahon, K				Mcgraw, Gary; Bonett, Richie; Figueroa, Harold; Mcmahon, Katie			23 Security Risks in Black-Box Large Language Model Foundation Models	COMPUTER			English	Article						Analytical models; Computational modeling; Closed box; Machine learning; Regulation; Risk analysis; Computer security		We applied our previous generic machine learning risk analysis to the more specific case of large language models (LLMs), identifying an architectural black box with 23 associated risks-a reasonable starting point for the regulation of LLMs.	[Mcgraw, Gary; Bonett, Richie; Figueroa, Harold; Mcmahon, Katie] Berryville Inst Machine Learning, Berryville, VA 22611 USA; [Bonett, Richie] Verisign, Reston, VA 20190 USA; Naval Postgrad Sch, Postgrad Sch, Monterey, CA 93943 USA	United States Department of Defense; United States Navy; Naval Postgraduate School	Mcgraw, G (corresponding author), Berryville Inst Machine Learning, Berryville, VA 22611 USA.	gem@garymcgraw.com; richiebonett@gmail.com; harold.figueroa@gmail.com; kwmcmahon007@gmail.com						McGraw G, 2019, COMPUTER, V52, P54, DOI 10.1109/MC.2019.2909955; McGraw Gary, 2020, An architectural risk analysis of machine learning systems: Toward more secure machine learning; McGraw H., 2024, Tech. Rep.	3	0	0	9	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	APR	2024	57	4					160	164		10.1109/MC.2024.3363250	http://dx.doi.org/10.1109/MC.2024.3363250			5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	MW6L1					2024-07-03	WOS:001196710800005
C	Wang, Z; Wohlwend, J; Lei, T			Assoc Computat Linguist	Wang, Ziheng; Wohlwend, Jeremy; Lei, Tao			Structured Pruning of Large Language Models	PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP)			English	Proceedings Paper	Conference on Empirical Methods in Natural Language Processing (EMNLP)	NOV 16-20, 2020	ELECTR NETWORK	Bloomberg Engn, Google Res, Apple, Amazon Sci, Baidu, Megagon Labs, Facebook, DeepMind, Grammarly, ByteDance, Zeta Alpha, Babelscape, Naver, Adobe, Hitachi, Salesforce, Univ So Calif, Viterbi Sch Engn, Informat Sci Inst				Large language models have recently achieved state of the art performance across a wide variety of natural language tasks. Meanwhile, the size of these models and their latency have significantly increased, which makes their usage costly, and raises an interesting question: do language models need to be large? We study this question through the lens of model compression. We present a generic, structured pruning approach by parameterizing each weight matrix using its low-rank factorization, and adaptively removing rank-1 components during training. On language modeling tasks, our structured approach outperforms other unstructured and block-structured pruning baselines at various compression levels, while achieving significant speedups during both training and inference. We also demonstrate that our method can be applied to pruning adaptive word embeddings in large language models, and to pruning the BERT model on several downstream fine-tuning classification benchmarks.	[Wang, Ziheng; Wohlwend, Jeremy; Lei, Tao] ASAPP Inc, New York, NY USA		Wang, Z (corresponding author), ASAPP Inc, New York, NY USA.	zihengw@stanford.edu; jwohlwend@csail.mit.edu; tao@asapp.com						[Anonymous], 2016, P 2016 C EMP METH NA, DOI DOI 10.2112/SI75-264.1; [Anonymous], 2010, Empirical Methods in Natural Language Processing; Ba LJ, 2014, ADV NEUR IN, V27; Baevski A., 2019, INT C LEARN REPR ICL; Bastings J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2963; Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898; Cer D., 2017, P 11 INT WORKSH SEM, P1, DOI [10.18653/v1/S17-2001, DOI 10.18653/V1/S17-2001.URL]; Chia Yew Ken, 2019, ARXIV190903508; Dai A. M., 2015, ADV NEURAL INFORM PR, P3079; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Diamos G., 2017, ARXIV171102782; Dolan W. B., 2005, P 3 INT WORKSH PAR I, P9; Dong Z., 2019, ARXIV190905840; Fan Angela, 2020, P ICLR; Flanigan J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1426; Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234; Gale Trevor, 2019, ARXIV190209574; Gong Yunchao, 2014, CoRR; Grave E., 2017, P ICML, P1302; Gray S, 2017, GPU KERNELS BLOCK SP; Han S., 2015, INT C LEARN REPR, V56, P3; Han S, 2015, ADV NEUR IN, V28; Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30; Hinton G., 2015, ARXIV; Jiao XQ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P4163; Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Lei T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4470; Liu LY, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1215; Liu Y., 2019, CoRR abs/1907.11692; Louizos C., 2018, 6 INT C LEARNING REP; Louizos C, 2017, ADV NEUR IN, V30; Martins A. F. T., 2011, INT C MACHINE LEARNI; Merity Stephen, 2018, ABS180308240 CORR; Molchanov D., 2017, PMLR, DOI DOI 10.5555/3305890.3305939; Narang S., 2017, ARXIV170405119, P1; Paszke A, 2017, NIPS W; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Sanh Victor, 2019, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; See Abigail, 2016, P 20 SIGNLL C COMP N, P291, DOI [10.18653/v1/k16-1029, DOI 10.18653/V1/K16-1029]; Shangguan Y., 2019, ARXIV190912408; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Sun Siqi, 2019, P 2019 C EMP METH NA; Tsai H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3632; Turc Iulia, 2019, CoRR; Variani E, 2019, INT CONF ACOUST SPEE, P7340, DOI 10.1109/ICASSP.2019.8683694; Vaswani A, 2017, ADV NEUR IN, V30; Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wen W, 2018, INT C LEARN REPR; Wu Y., 2016, ARXIV160908144, V1609; Yao ZL, 2019, AAAI CONF ARTIF INTE, P5676; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zheng L., 2018, 32 AAAI C ART INT, P5852, DOI [DOI 10.1109/IWQOS.2018.8624168, 10.1109/IWQoS.2018.8624168]; Zhu Chenzhuo, 2017, ICLR; Zhu M., 2017, ARXIV171001878; Zmora N., 2019, arXiv	59	28	30	2	5	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-952148-60-6				2020							6151	6162						12	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BT8RW					2024-07-03	WOS:000855160706029
C	Li, K; Cao, RQ; Wan, M; Wang, XG; Wang, ZG; Wang, J; Wang, YG		Fang, L; Pei, J; Zhai, G; Wang, R		Li, Kai; Cao, Rongqiang; Wan, Meng; Wang, Xiaoguang; Wang, Zongguo; Wang, Jue; Wang, Yangang			Deployment and Comparison of Large Language Models Based on Virtual Cluster	ARTIFICIAL INTELLIGENCE, CICAI 2023, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	3rd CAAI International Conference on Artificial Intelligence (CICAI)	JUL 22-23, 2023	Chinese Assoc Artificial Intelligence, Fuzhou, PEOPLES R CHINA		Chinese Assoc Artificial Intelligence	Large Language Model; General Language Model; consumer-grade acceleration card; virtual cluster		[Objective] Currently, large language model (LLM) is one of research highlights in the field of natural language processing. This paper selected some open-source LLMs for deployment and comparison from the perspective of consumer-grade GPU and support for Chinese and English. [Coverage] This paper uses keywords search and citation secondary search to collect papers and information from international computer journals, conferences and open source code warehouse. [Methods] From the perspective of supporting both Chinese and English, we selected LLaMA, MOSS, ChatGLM-6B, ColossalChat, and Chinese-LLaMA-Alpaca for deployment at the same virtual task, on the virtual cluster with consumer-grade GPU. Furthermore, we made horizontal comparisons on semantic understanding, logical reasoning, code programming, ancient poetry, and legal questions, and then, discuss the advantages and disadvantages of these models. [Results] Limited parameters scale, most of them are not very friendly to support Chinese, have weak Chinese understanding abilities, and have varying abilities in logical reasoning. At present, researchers have paid less attention to issues such as Chinese support and resource consumption. They generally focus on increasing the scale of model parameters and using higher graphics card resources for model training and inference. [Conclusions] Although the development of LLMs is rapid, many models do not fully support Chinese. Understanding Chinese ability needs to be further improved, and more efforts need to be made in logical reasoning. It is believed that in the future, there will be more large language models that consume lower resources and support stronger Chinese.	[Li, Kai; Cao, Rongqiang; Wan, Meng; Wang, Xiaoguang; Wang, Zongguo; Wang, Jue; Wang, Yangang] Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100083, Peoples R China; [Li, Kai; Cao, Rongqiang; Wan, Meng; Wang, Xiaoguang; Wang, Zongguo; Wang, Jue; Wang, Yangang] Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China	Chinese Academy of Sciences; Computer Network Information Center, CAS; Chinese Academy of Sciences	Cao, RQ (corresponding author), Chinese Acad Sci, Comp Network Informat Ctr, Beijing 100083, Peoples R China.; Cao, RQ (corresponding author), Chinese Acad Sci, Sch Comp Sci & Technol, Beijing 100049, Peoples R China.	caorq@sccas.cn		Wan, Meng/0000-0001-5965-6272	Chinese Academy of Sciences strategic leading science and technology project [XDB38050200]	Chinese Academy of Sciences strategic leading science and technology project	Fund project: Chinese Academy of Sciences strategic leading science and technology project. (XDB38050200).	aicnic, Virtual Cluster; aicnic, Virtual Cluster User's Manual; [Anonymous], 2022, Introducing ChatGPT; [Anonymous], 1999, Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics; BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; baidu, Demo Video; Brants T., 2007, P 2007 JOINT C EMP M, P858; Cui YM, 2024, Arxiv, DOI arXiv:2304.08177; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Du ZX, 2022, Arxiv, DOI [arXiv:2103.10360, DOI 10.48550/ARXIV.2103.10360]; github, THUDM/GLM; github, THUDM/ChatGLM-6B; github, Ymci/Chinese-LLaMA-Alpaca; github, Facebookresearch/llama; github, OpenLMLab/MOSS; github, Hpcaitech/ColossalAI; Han X, 2021, AI OPEN, V2, P225, DOI 10.1016/j.aiopen.2021.08.002; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Li J., 2021, P 30 INT JOINT C ART, P4492, DOI DOI 10.24963/IJCAI.2021/612SURVEYTRACK; Li SG, 2023, Arxiv, DOI arXiv:2110.14883; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lu P, 2023, Arxiv, DOI arXiv:2212.10535; OpenAI, 2022, Our approach to alignment research; Qiao SF, 2023, Arxiv, DOI [arXiv:2212.09597, DOI 10.48550/ARXIV.2212.09597]; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Touvron Hugo, 2023, CORR; Yao T., 2022, VenusAI: an artificial intelligence platform for scientific discovery on supercomputers; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhao Wayne Xin, 2022, arXiv; Zhou J, 2024, FRONT INFORM TECH EL, V25, P6, DOI 10.1631/FITEE.2300089	31	0	0	1	1	SPRINGER-VERLAG SINGAPORE PTE LTD	SINGAPORE	152 BEACH ROAD, #21-01/04 GATEWAY EAST, SINGAPORE, 189721, SINGAPORE	2945-9133	1611-3349	978-981-99-9118-1; 978-981-99-9119-8	LECT NOTES ARTIF INT			2024	14474						359	365		10.1007/978-981-99-9119-8_32	http://dx.doi.org/10.1007/978-981-99-9119-8_32			7	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8RL					2024-07-03	WOS:001206024900032
J	Thapa, S; Adhikari, S				Thapa, Surendrabikram; Adhikari, Surabhi			ChatGPT, Bard, and Large Language Models for Biomedical Research: Opportunities and Pitfalls	ANNALS OF BIOMEDICAL ENGINEERING			English	Article						Large language models; Biomedical research; Natural language processing; ChatGPT; Bard		Large Language Models (LLMs) such as ChatGPT and Bard have emerged as groundbreaking interactive chatbots, capturing significant attention and transforming the biomedical research landscape. These powerful tools offer immense potential for advancing scientific inquiry, but they also present challenges and pitfalls. Leveraging large language models, researchers can streamline literature reviews, summarize complex findings, and even generate novel hypotheses, enabling the exploration of uncharted scientific territories. However, the inherent risk of misinformation and misleading interpretations underscores the critical importance of rigorous validation and verification processes. This article provides a comprehensive overview of the current landscape and delves into the opportunities and pitfalls associated with employing LLMs in biomedical research. Furthermore, it sheds light on strategies to enhance the utility of LLMs in biomedical research, offering recommendations to ensure their responsible and effective implementation in this domain. The findings presented in this article contribute to the advancement of biomedical engineering by harnessing the potential of LLMs while addressing their limitations.	[Thapa, Surendrabikram] Virginia Tech, Blacksburg, VA 24060 USA; [Adhikari, Surabhi] Columbia Univ, New York, NY 10027 USA	Virginia Polytechnic Institute & State University; Columbia University	Thapa, S (corresponding author), Virginia Tech, Blacksburg, VA 24060 USA.	surendrabikram@vt.edu	THAPA, SURENDRABIKRAM/ABG-8510-2021	THAPA, SURENDRABIKRAM/0000-0003-4119-8239				Adhikari S, 2023, NEURAL NETWORKS, V164, P115, DOI 10.1016/j.neunet.2023.04.011; Chen Q., 2023, bioRxiv; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Mbakwe AB., 2023, CHATGPT PASSING USML, DOI [10.1371/journal.pdig.0000205, DOI 10.1371/JOURNAL.PDIG.0000205]; Thapa, 2023, WORKSHOP P 17 INT AA; Zhao WX, 2023, ARXIV	6	20	20	30	54	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	DEC	2023	51	12					2647	2651		10.1007/s10439-023-03284-0	http://dx.doi.org/10.1007/s10439-023-03284-0		JUN 2023	5	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	X3KT5	37328703				2024-07-03	WOS:001012332200003
J	Tan, TF; Thirunavukarasu, AJ; Campbell, JP; Keane, PA; Pasquale, LR; Abramoff, MD; Kalpathy-Cramer, J; Lum, F; Kim, JE; Baxter, SL; Ting, DSW				Tan, Ting Fang; Thirunavukarasu, Arun James; Campbell, J. Peter; Keane, Pearse A.; Pasquale, Louis R.; Abramoff, Michael D.; Kalpathy-Cramer, Jayashree; Lum, Flora; Kim, Judy E.; Baxter, Sally L.; Ting, Daniel Shu Wei			Generative Artificial Intelligence Through ChatGPT and Other Large Language Models in Ophthalmology Clinical Applications and Challenges	OPHTHALMOLOGY SCIENCE			English	Article								The rapid progress of large language models (LLMs) driving generative artificial intelligence applications heralds the potential of opportunities in health care. We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and Scopus using the following terms: "large language models," "generative artificial intelligence," "ophthalmology," "ChatGPT," and "eye," based on relevance to this review. From a clinical viewpoint specific to ophthalmologists, we explore from the different stakeholders' perspectivesdincluding patients, physicians, and policymakersdthe potential LLM applications in education, research, and clinical domains specific to ophthal-mology. We also highlight the foreseeable challenges of LLM implementation into clinical practice, including the concerns of accuracy, interpretability, perpetuating bias, and data security. As LLMs continue to mature, it is essential for stakeholders to jointly establish standards for best practices to safeguard patient safety.	[Tan, Ting Fang; Ting, Daniel Shu Wei] Singapore Natl Eye Ctr, Singapore Eye Res Inst, Singapore, Singapore; [Thirunavukarasu, Arun James] Univ Cambridge, Sch Clin Med, Cambridge, England; [Thirunavukarasu, Arun James] Univ Cambridge, Corpus Christi Coll, Cambridge, England; [Campbell, J. Peter] Oregon Hlth & Sci Univ, Casey Eye Inst, Dept Ophthalmol, Portland, OR USA; [Keane, Pearse A.] UCL, Moorfields Eye Hosp, London, England; [Pasquale, Louis R.] Icahn Sch Med Mt Sinai, Dept Ophthalmol, New York, NY USA; [Abramoff, Michael D.] Amer Med Assoc, Digital Med Payment Advisory Grp DMPAG Artificial, Chicago, IL USA; [Abramoff, Michael D.] Univ Iowa, Dept Ophthalmol, Iowa City, IA USA; [Abramoff, Michael D.] Digital Diagnost Inc, Coralville, IA USA; [Kalpathy-Cramer, Jayashree] Univ Colorado, Dept Ophthalmol, Anschutz Med Campus, Aurora, CO USA; [Lum, Flora] Amer Acad Ophthalmol, San Francisco, CA USA; [Kim, Judy E.] Med Coll Wisconsin, Dept Ophthalmol, Milwaukee, WI USA; [Baxter, Sally L.] Shiley Eye Inst, Viterbi Family Dept Ophthalmol, Div Ophthalmol Informat & Data Sci, La Jolla, CA USA; [Baxter, Sally L.] Univ Calif San Diego, Hlth Dept Biomed Informat, La Jolla, CA USA; [Ting, Daniel Shu Wei] Stanford Univ, Byers Eye Inst, Stanford, CA USA; [Ting, Daniel Shu Wei] Singapore Eye Res Inst SERI, Singapore Eye Res Inst, Duke NUS Med Sch AI & Digital Innovat, 20 Coll Rd,Level 6,Discovery Tower, Singapore 169856, Singapore	National University of Singapore; Singapore National Eye Center; University of Cambridge; University of Cambridge; Oregon Health & Science University; University of London; University College London; Moorfields Eye Hospital NHS Foundation Trust; Icahn School of Medicine at Mount Sinai; American Medical Association; University of Iowa; University of Colorado System; University of Colorado Anschutz Medical Campus; Medical College of Wisconsin; University of California System; University of California San Diego; Stanford University; National University of Singapore; Singapore National Eye Center	Ting, DSW (corresponding author), Singapore Eye Res Inst SERI, Singapore Eye Res Inst, Duke NUS Med Sch AI & Digital Innovat, 20 Coll Rd,Level 6,Discovery Tower, Singapore 169856, Singapore.	daniel.ting@duke-nus.edu.sg	Keane, Pearse/AAE-5709-2019; Thirunavukarasu, Arun/ABC-0806-2022	Keane, Pearse/0000-0002-9239-745X; Thirunavukarasu, Arun/0000-0001-8968-4768	Research & Innovation Future Leaders Fellowship [MR/T019050/1]; Research to Prevent Blindness (RPB); Glaucoma Foundation (New York); Topcon [NMRC/HSRG/0087/2018, MOH-000655-00, MOH-001014-00]; Duke-NUS Medical School, Singapore [Duke-NUS/RSF/2021/0018, 05/FY2020/EX/15-A58]; Agency for Sci-ence, Technology and Research, Singapore [A20H4g2141, H20C6a0032]	Research & Innovation Future Leaders Fellowship; Research to Prevent Blindness (RPB)(Research to Prevent Blindness (RPB)); Glaucoma Foundation (New York); Topcon; Duke-NUS Medical School, Singapore(National University of Singapore); Agency for Sci-ence, Technology and Research, Singapore(Agency for Science Technology & Research (A*STAR))	Research & Innovation Future Leaders Fellowship (MR/T019050/1) . L.R.P.: Consultant-Twenty-Twenty, Character Bio; Grant support-National Eye Institute (NEI) , Research to Prevent Blindness (RPB) , The Glaucoma Foundation (New York) . M.D.A.: Investor, director, and consultant-Digital Diagnostics Inc, Coralville, Iowa; Patents and patent applications assigned to the University of Iowa and Digital Diagnostics that are relevant to the subject matter of this manuscript; Chair of Healthcare-AI Coalition, Washington DC, Foundational Principles of AI CCOI Workgroup; Member of the American Academy of Ophthalmology (Academy) Committee on Artificial Intelligence, AI Workgroup Digital Medicine Payment Advisory Group (DMPAG) , Collaborative Community for Ophthalmic Imaging (CCOI) , Washington DC. S.L.B.: Consulting fees-VoxelCloud; Speaking fees-iVista Medical Education; Equipment support-Optomed, Topcon. D.S.W.T.: Patent-a deep-learning system for the detection of retinal diseases; Supported by grants-National Medical Research Council, Singapore, (NMRC/HSRG/0087/2018; MOH-000655-00; MOH-001014-00) , Duke-NUS Medical School, Singapore, (Duke-NUS/RSF/2021/0018; 05/FY2020/EX/15-A58) , Agency for Sci-ence, Technology and Research, Singapore, (A20H4g2141; H20C6a0032) , for research in artificial intelligence.	Abràmoff MD, 2022, OPHTHALMOLOGY, V129, pE14, DOI 10.1016/j.ophtha.2021.08.023; Acosta JN, 2022, NAT MED, V28, P1773, DOI 10.1038/s41591-022-01981-2; Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; Agrawal M, 2022, arXiv, DOI [10.48550/arXiv.2205.12689, DOI 10.48550/ARXIV.2205.12689]; Al Madi N, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3560438; Alsentzer Emily., 2019, ARXIV190403323, P72, DOI [DOI 10.18653/V1/W19-1909, 10.18653/v1/W19-1909]; [Anonymous], 2023, IMPROVED PERFORMANCE, DOI [10.1101/2023.04.03.23287957v1, DOI 10.1101/2023.04.03.23287957V1]; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Au Yeung J, 2023, AI chatbots not yet ready for clinical use, DOI [10.1101/2023.03.02.23286705, DOI 10.1101/2023.03.02.23286705]; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Cambridge University Press, 2023, Authorship and contributorship; Centers for Medicare and Medicaid Services, 2022, Nondiscrimination in health programs and activities; Char DS, 2020, AM J BIOETHICS, V20, P7, DOI 10.1080/15265161.2020.1819469; Chen JS, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.906554; Chow SC, 2022, GRAEF ARCH CLIN EXP, V260, P3149, DOI 10.1007/s00417-022-05666-x; Dai D, 2022, Why can gpt learn in-context? language models secretly perform gradient descent as meta-optimizers; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Friedberg Mark W, 2014, Rand Health Q, V3, P1; GitHub Copilot, 2023, Your AI pair programmer; Gu Y, 2007, ACM Transactions on Computing for Healthcare (HEALTH), V3, P1; Guo E, 2023, neuroGPT-X: towards an accountable expert opinion tool for vestibular schwannoma, DOI [10.1101/2023.02.25.23286117, DOI 10.1101/2023.02.25.23286117]; Hong Z, 2022, arXiv, DOI [10.48550/arXiv.2205.11342, DOI 10.48550/ARXIV.2205.11342]; Huang K, 2020, Clinicalbert: Modeling clinical notes and predicting hospital readmission; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaplan Jared, 2020, Scaling laws for neural language models; Kojima T, 2023, arXiv, DOI [10.48550/arXiv.2205.11916, DOI 10.48550/ARXIV.2205.11916]; Korot E, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-89743-x; Korot E, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.2; Kraljevic Z, 2023, arXiv, DOI [10.48550/arXiv.2212.08072, DOI 10.48550/ARXIV.2212.08072]; Kuehn BM, 2013, JAMA-J AM MED ASSOC, V309, P756, DOI 10.1001/jama.2013.629; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lehman E, 2023, arXiv; Lester Brian, 2021, The power of scale for parameter-efficient prompt tuning; Lievin V., 2022, CAN LARGE LANGUAGE M, P1, DOI [10.48550/arXiv.2207.08143, DOI 10.48550/ARXIV.2207.08143]; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Maddison Lewis., 2023, TechRadar; Mai DHA, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.1067562; Medenilla A., 2023, PLoS Digital Health, V2; Microsoft Bing, 2023, Introducing the new bing; Microsoft Bing, 2023, Confirmed: the new Bing runs on OpenAI's GPT-4; Milne-Ives M, 2020, J MED INTERNET RES, V22, DOI 10.2196/20346; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; Nov O, 2023, medRxiv, DOI [10.1101/2023.01.23.23284735v2, DOI 10.1101/2023.01.23.23284735V2]; OpenAI, 2023, ChatGPT plugins; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, Introducing ChatGPT and whisper APIs; OpenAI, 2023, MARCH 20 CHATGPT OUT; OpenAI, 2023, A.P.I. data usage polices; Ouyang L., 2022, NEURIPS; Papanikolaou Y, 2020, arXiv; Patel A, 2023, Creatively malicious prompt engineering; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Perez F, 2022, arXiv, DOI [10.48550/arXiv.2211.09527, DOI 10.48550/ARXIV.2211.09527]; Pichai S, 2023, The Keyword; Pitt MB, 2022, J GEN INTERN MED, V37, P222, DOI 10.1007/s11606-021-06895-2; Radford A, 2019, Comput Sci., V9; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Raimondi R, 2023, EYE, V37, P3530, DOI 10.1038/s41433-023-02563-3; Richardson JP, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00509-1; Shashikumar SP, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00504-6; Shuster K., 2022, BLENDERBOT 3 DEPLOYE, DOI [10.48550/arXiv.2208.03188, DOI 10.48550/ARXIV.2208.03188]; Singhal K, 2023, Towards Expert-Level Medical Question Answering with Large Language Models; Singhal K., 2022, LARGE LANGUAGE MODEL; Spataro J., 2023, Official Microsoft Blog; statMed.org, 2023, About statMed.org; Sun T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1630; Taylor J., 2023, GUARDIAN; Taylor R., 2022, Galactica: A large language model for science; Thirunavukarasu AJ, Eye News; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Thirunavukarasu AJ, 2021, EYE, V35, P3165, DOI 10.1038/s41433-020-01257-4; Ting DSW, 2019, BRIT J OPHTHALMOL, V103, P167, DOI 10.1136/bjophthalmol-2018-313173; United States Food and Drug Administration, 2023, NDA approval letter on 17 February 2023; Van Riel Noor, 2017, BJGP Open, V1, pbjgpopen17X100833, DOI 10.3399/bjgpopen17X100833; Voolich Wright J, 2023, Google Workspace Blog; Wang SY, 2022, INT J MED INFORM, V167, DOI 10.1016/j.ijmedinf.2022.104864; Wei J, 2023, arXiv, DOI [10.48550/arXiv.2201.11903, DOI 10.48550/ARXIV.2201.11903]; Yakar D, 2022, VALUE HEALTH, V25, P374, DOI 10.1016/j.jval.2021.09.004; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yim J, 2020, NAT MED, V26, P892, DOI 10.1038/s41591-020-0867-7; Youssef A, 2023, AM J BIOETHICS, V23, P43, DOI 10.1080/15265161.2023.2191052; Zhang YJ, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0055-0	85	12	12	20	34	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2666-9145			OPHTHALMOL SCI	Ophthalmol. Sci.	DEC	2023	3	4							100394	10.1016/j.xops.2023.100394	http://dx.doi.org/10.1016/j.xops.2023.100394		OCT 2023	9	Ophthalmology	Emerging Sources Citation Index (ESCI)	Ophthalmology	X9OY8	37885755	Green Published, gold			2024-07-03	WOS:001101673900001
J	Telenti, A; Auli, M; Hie, BL; Maher, C; Saria, S; Ioannidis, JPA				Telenti, Amalio; Auli, Michael; Hie, Brian L.; Maher, Cyrus; Saria, Suchi; Ioannidis, John P. A.			Large language models for science and medicine	EUROPEAN JOURNAL OF CLINICAL INVESTIGATION			English	Review						applications; large language models; limitations; medicine; science; validation		Large language models (LLMs) are a type of machine learning model that learn statistical patterns over text, such as predicting the next words in a sequence of text. Both general purpose and task-specific LLMs have demonstrated potential across diverse applications. Science and medicine have many data types that are highly suitable for LLMs, such as scientific texts (publications, patents and textbooks), electronic medical records, large databases of DNA and protein sequences and chemical compounds. Carefully validated systems that can understand and reason across all these modalities may maximize benefits. Despite the inevitable limitations and caveats of any new technology and some uncertainties specific to LLMs, LLMs have the potential to be transformative in science and medicine.	[Telenti, Amalio] Scripps Res, Dept Integrat Struct & Computat Biol, La Jolla, CA USA; [Telenti, Amalio; Maher, Cyrus] Vir Biotechnol Inc, San Francisco, CA USA; [Auli, Michael; Hie, Brian L.] FAIR, Menlo Pk, CA USA; [Hie, Brian L.] Stanford Univ, Dept Chem Engn, Stanford, CA USA; [Saria, Suchi] Johns Hopkins Univ, Malone Ctr Engn & Healthcare, Baltimore, MD USA; [Ioannidis, John P. A.] Stanford Univ, Dept Med, Stanford, CA USA; [Ioannidis, John P. A.] Stanford Univ, Dept Epidemiol & Populat Hlth, Stanford, CA USA; [Ioannidis, John P. A.] Stanford Univ, Dept Biomed Data Sci, Stanford, CA USA; [Ioannidis, John P. A.] Stanford Univ, Dept Stat, Stanford, CA USA; [Ioannidis, John P. A.] Stanford Univ, Meta Res Innovat Ctr Stanford METRICS, Stanford, CA USA	Scripps Research Institute; Stanford University; Johns Hopkins University; Stanford University; Stanford University; Stanford University; Stanford University; Stanford University	Ioannidis, JPA (corresponding author), Med Sch Off Bldg,Room X306, Stanford, CA 94305 USA.	jioannid@stnford.edu	Saria, Suchi/D-1809-2013					Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; [Anonymous], 2020, SEAGATE SEAGATES RET; Arnold Frances H, 2018, Angew Chem Int Ed Engl, V57, P4143, DOI 10.1002/anie.201708408; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Benegas G., 2023, Proceedings of the National Academy of Sciences of the United States of America, V120, DOI DOI 10.1073/PNAS.2311219120; Bengio Y., 2023, PAUSE GIANT AI EXPT; Bepler T, 2021, CELL SYST, V12, P654, DOI 10.1016/j.cels.2021.05.017; Bergquist T, 2023, J CLIN TRANSL SCI, V7, DOI 10.1017/cts.2023.549; Biswas S, 2021, NAT METHODS, V18, P389, DOI 10.1038/s41592-021-01100-y; Blagec K, 2023, J BIOMED INFORM, V137, DOI 10.1016/j.jbi.2022.104274; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Boiko D. A., 2023, EMERGENT AUTONOMOUS; Bran A.M., 2023, ChemCrow: Augmenting large-language models with chemistry tools; Candal-Pedreira C, 2022, BMJ-BRIT MED J, V379, DOI 10.1136/bmj-2022-071517; Center MN., 2023, MICR EP EXP STRAT CO; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Constant DA., 2023, BIORXIV, DOI [10.1101/2023.02.11.528149v1, DOI 10.1101/2023.02.11.528149V1]; Devlin J., 2018, BERT PRE TRAINING DE; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Hie BL, 2022, CELL SYST, V13, P274, DOI 10.1016/j.cels.2022.01.003; Hie BL, 2024, NAT BIOTECHNOL, V42, DOI 10.1038/s41587-023-01763-2; Hsu C, 2022, NAT BIOTECHNOL, V40, P1114, DOI 10.1038/s41587-021-01146-5; Ioannidis JPA, 2023, JAMA-J AM MED ASSOC, V329, P1253, DOI 10.1001/jama.2023.3212; Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124; Jaume-Santero F, 2023, J CHEM INF MODEL, V63, P1914, DOI 10.1021/acs.jcim.2c01407; Ji YR, 2021, BIOINFORMATICS, V37, P2112, DOI 10.1093/bioinformatics/btab083; Krenn M., 2019, SELF REFERENCING EMB; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lieberman-Aiden E, 2009, SCIENCE, V326, P289, DOI 10.1126/science.1181369; Lin Z., 2023, PSYARXIV, DOI [10.31234/osf.io/9yhwz, DOI 10.31234/OSF.IO/9YHWZ]; Lin Z., 2023, WRITE EFFECTIVE PROM, DOI [10.31234/osf.io/r78fc, DOI 10.31234/OSF.IO/R78FC]; Lin ZC, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.230658; Lu JY, 2022, J CHEM INF MODEL, V62, P1376, DOI 10.1021/acs.jcim.1c01467; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Lyell D, 2017, J AM MED INFORM ASSN, V24, P423, DOI 10.1093/jamia/ocw105; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Marcus G., 2022, Scientific American; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; Olsen TH, 2022, BIOINFORM ADV, V2, DOI 10.1093/bioadv/vbac046; Outeiral C., 2022, BIORXIV, DOI [10.1101/2022.12.15.519894v1, DOI 10.1101/2022.12.15.519894V1]; Ouyang L., 2022, Advances in Neural Information Processing Systems; Poli M., 2023, HYENA HIERARCHY LARG; Rajbhandari S., 2019, ZERO MEMORY OPTIMIZA; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Ross J, 2022, NAT MACH INTELL, V4, DOI 10.1038/s42256-022-00580-7; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Saria S., 2022, NEJM CATAL, DOI [10.1056/CAT.22.0075, DOI 10.1056/CAT.22.0075]; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; Schwaller P, 2018, CHEM SCI, V9, P6091, DOI 10.1039/c8sc02339e; Shuai RW, 2023, CELL SYST, V14, P979, DOI 10.1016/j.cels.2023.10.001; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Soleimani H, 2018, IEEE T PATTERN ANAL, V40, P1948, DOI 10.1109/TPAMI.2017.2742504; Tan ALM, 2023, J BIOMED INFORM, V139, DOI 10.1016/j.jbi.2023.104306; Taylor R., 2022, Galactica: A large language model for science; Telenti A, 2020, NAT GENET, V52, P1005, DOI 10.1038/s41588-020-0698-y; Touvron H., 2023, Llama: Open and efficient foundation language models; Ucak UV, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-023-00693-0; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Yang F, 2022, NAT MACH INTELL, V4, P852, DOI 10.1038/s42256-022-00534-z; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zarifhonarvar A., 2023, SSRN Electronic Journal, DOI DOI 10.2139/SSRN.4350925; Zarocostas J, 2020, LANCET, V395, P676, DOI 10.1016/S0140-6736(20)30461-X; Zhang XC, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab152; Zhao W. X., 2023, A survey of large language models; Zou J, 2019, NAT GENET, V51, P12, DOI 10.1038/s41588-018-0295-5	73	1	1	36	36	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0014-2972	1365-2362		EUR J CLIN INVEST	Eur. J. Clin. Invest.	JUN	2024	54	6								10.1111/eci.14183	http://dx.doi.org/10.1111/eci.14183		FEB 2024	11	Medicine, General & Internal; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine; Research & Experimental Medicine	QQ0J3	38381530				2024-07-03	WOS:001169065900001
J	Dang, R; Hanba, C				Dang, Rushil; Hanba, Curtis			A large language model's assessment of methodology reporting in head and neck surgery	AMERICAN JOURNAL OF OTOLARYNGOLOGY			English	Article						Head and neck; AI; ChatGPT; Large language model		Objective: The aim of this study was to assess the ability of a Large Language Model -ChatGPT 3.5 to appraise the quality of scientific methodology reporting in head and neck specific scientific literature. Methods: Authors asked ChatGPT 3.5 to create a grading system for scientific reporting of research methods. The language model produced a system with a max of 60 points. Individual scores were provided for Study Design and Description, Data Collection and Measurement, Statistical Analysis, Ethical Considerations, and Overall Clarity and Transparency. Twenty articles were selected at random from The American Head and Neck Society's (AHNS) fellowship curriculum 2.0 for interrogation and each 'Methods' section was input into ChatGPT 3.5 for scoring. Analysis of variance (ANOVA) was performed between different scoring categories and a post-hoc tukey HSD test was performed. Results: Twenty articles were assessed, eight were categorized as very good and nine as good based on cumulative score. Lowest mean score was noted with category of statistical analysis (Mean = 0.49, SD = 0.02). On ANOVA a significant difference between means of the different scoring categories was noted, F(4, 95) = 13.4, p <= 0.05. On post-hoc Tukey HSD test, mean scores for categories of data collection (Mean = 0.58, SD = 0.06) and statistical analysis (Mean = 0.49, SD = 0.02) were significantly lower when compared to other categories. Conclusion: This article showcases the feasibility of employing a large language model such as ChatGPT 3.5 to assess the methods sections in head and neck academic writing. Level of evidence: 4	[Dang, Rushil] Boston Med Ctr, Dept Oral & Maxillofacial Surg, Maxillofacial Oncol & Reconstruct Surg, Boston, MA USA; [Hanba, Curtis] Univ Texas MD Anderson Canc Ctr, Dept Head & Neck Surg, Houston, TX USA; [Hanba, Curtis] MD Anderson Canc Ctr, Dept Otolaryngol, Head & Neck Surg Oncol, 1515 Holcombe Blvd, Houston, TX 77030 USA	Boston Medical Center; University of Texas System; UTMD Anderson Cancer Center; University of Texas System; UTMD Anderson Cancer Center	Hanba, C (corresponding author), MD Anderson Canc Ctr, Dept Otolaryngol, Head & Neck Surg Oncol, 1515 Holcombe Blvd, Houston, TX 77030 USA.	curtis.j.hanba@gmail.com						[Anonymous], 2018, NATURE, V556, P273, DOI 10.1038/d41586-018-04590-7; Cho K, 2015, PHARMACOL RES, V102, P319, DOI 10.1016/j.phrs.2015.10.017; Galipeau J, 2016, BMC MED, V14, DOI 10.1186/s12916-016-0561-2; Ge Jin, 2023, medRxiv, DOI 10.1101/2023.08.31.23294924; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Glasziou P, 2014, LANCET, V383, P267, DOI 10.1016/S0140-6736(13)62228-X; Guerra GA, 2023, WORLD NEUROSURG, V179, pE160, DOI 10.1016/j.wneu.2023.08.042; Moher D, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001864; Oduoye MO, 2023, INT J SURG, V109, P2987, DOI 10.1097/JS9.0000000000000552; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tang GY, 2023, IRISH J MED SCI, V192, P3195, DOI 10.1007/s11845-023-03374-x; Tricco AC, 2018, ANN INTERN MED, V169, P467, DOI 10.7326/M18-0850; Watters C, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1224976; Wu Robin T, 2023, Am J Otolaryngol, V44, P103980, DOI 10.1016/j.amjoto.2023.103980	14	0	0	11	11	W B SAUNDERS CO-ELSEVIER INC	PHILADELPHIA	1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA	0196-0709	1532-818X		AM J OTOLARYNG	Am. J. Otolaryngol.	MAR-APR	2024	45	2							104145	10.1016/j.amjoto.2023.104145	http://dx.doi.org/10.1016/j.amjoto.2023.104145		DEC 2023	4	Otorhinolaryngology	Science Citation Index Expanded (SCI-EXPANDED)	Otorhinolaryngology	EF4Y7	38103488				2024-07-03	WOS:001137507500001
J	Suzuki, R; Arita, T				Suzuki, Reiji; Arita, Takaya			An evolutionary model of personality traits related to cooperative behavior using a large language model	SCIENTIFIC REPORTS			English	Article						Cooperation; Evolution; Prisoner's dilemma; Large language model; Personality trait; Artificial life		This study aims to demonstrate that Large Language Models (LLMs) can empower research on the evolution of human behavior, based on evolutionary game theory, by using an evolutionary model positing that instructing LLMs with high-level psychological and cognitive character descriptions enables the simulation of human behavior choices in game-theoretical scenarios. As a first step towards this objective, this paper proposes an evolutionary model of personality traits related to cooperative behavior using a large language model. In the model, linguistic descriptions of personality traits related to cooperative behavior are used as genes. The deterministic strategies extracted from LLM that make behavioral decisions based on these personality traits are used as behavioral traits. The population is evolved according to selection based on average payoff and mutation of genes by asking LLM to slightly modify the parent gene toward cooperative or selfish. Through experiments and analyses, we clarify that such a model can indeed exhibit evolution of cooperative behavior based on the diverse and higher-order representation of personality traits. We also observed repeated intrusion of cooperative and selfish personality traits through changes in the expression of personality traits. The words that emerged in the evolved genes reflected the behavioral tendencies of their associated personalities in terms of semantics, thereby influencing individual behavior and, consequently, the evolutionary dynamics.	[Suzuki, Reiji; Arita, Takaya] Nagoya Univ, Grad Sch Informat, Furo Cho,Chikusa Ku, Nagoya 4648601, Japan	Nagoya University	Suzuki, R (corresponding author), Nagoya Univ, Grad Sch Informat, Furo Cho,Chikusa Ku, Nagoya 4648601, Japan.	reiji@nagoya-u.jp			JSPS Topic-Setting Program [JPJS00122674991]; JSPS KAKENHI [JP21K12058]	JSPS Topic-Setting Program; JSPS KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was supported in part by JSPS Topic-Setting Program to Advance Cutting-Edge Humanities and Social Sciences Research Grant Number JPJS00122674991, JSPS KAKENHI JP21K12058. We would like to thank Solvi Arnold (Shinshu University) for constructive comments.	Akata E, 2023, Arxiv, DOI [arXiv:2305.16867, DOI 10.48550/ARXIV.2305.16867]; Asano T., 2023, P 37 ANN C JAPANESE, p4H3OS6b04; AXELROD R, 1981, SCIENCE, V211, P1390, DOI 10.1126/science.7466396; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; Higashi M, 1999, NATURE, V402, P523, DOI 10.1038/990087; Hintze A, 2023, Arxiv, DOI [arXiv:2304.12898, DOI 10.48550/ARXIV.2304.12898]; Hirata S., 2022, P 27 INT S ARTIFICIA, P225; Lehman J., 2022, arXiv, DOI DOI 10.48550/ARXIV.2206.08896; Machin B., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204.11887, 10.48550/arXiv.2204.11887]; Maynard Smith J., 1982, pi; MCCRAE RR, 1992, J PERS, V60, P175, DOI 10.1111/j.1467-6494.1992.tb00970.x; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Meyerson E, 2024, Arxiv, DOI [arXiv:2302.12170, 10.48550/arXiv.2302.12170, DOI 10.48550/ARXIV.2302.12170]; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Nowak MA., 2006, Evolutionary dynamics: exploring the equations of life, DOI DOI 10.2307/J.CTVJGHW98; Nowak MA, 2006, SCIENCE, V314, P1560, DOI 10.1126/science.1133755; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Phelps S, 2023, Arxiv, DOI [arXiv:2305.07970, 10.48550/arXiv.2305.07970, DOI 10.48550/ARXIV.2305.07970]; Serapio-Garcia G, 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2307.00184; Suzuki R., 2022, P ALIFE 2022 2022 C, P58; Suzuki R., 2023, P 63 M SPECIAL INTER, P31; Suzuki R., 2022, P JOINT C LANGUAGE E, P699; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang YQ, 2024, Arxiv, DOI [arXiv:2308.05342, 10.48550/arXiv.2308.05342]	24	0	0	11	11	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAR 19	2024	14	1							5989	10.1038/s41598-024-55903-y	http://dx.doi.org/10.1038/s41598-024-55903-y			9	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	LQ5H8	38503778	gold, Green Published, Green Submitted			2024-07-03	WOS:001188276500053
J	Leippold, M				Leippold, Markus			Thus spoke GPT-3: Interviewing a large-language model on climate finance	FINANCE RESEARCH LETTERS			English	Article						Climate change; Natural language processing; Large language models		This paper is an interview with a Large Language Model (LLM), namely GPT-3, on the issues of climate change. The interview should give some insights into the current capabilities of these large models which are deep neural networks with generally more than 100 billion parameters. In particular, it shows how eloquent and convincing the answers of such LLMs can be. However, it should be noted that LLMs can suffer from hallucination and their responses may not be grounded on facts. These deficiencies offer an interesting avenue for future research.	[Leippold, Markus] Univ Zurich, Dept Banking & Finance, Plattenstr 14, CH-8032 Zurich, Switzerland; [Leippold, Markus] Swiss Finance Inst SFI, Plattenstr 14, CH-8032 Zurich, Switzerland	University of Zurich	Leippold, M (corresponding author), Univ Zurich, Dept Banking & Finance, Plattenstr 14, CH-8032 Zurich, Switzerland.; Leippold, M (corresponding author), Swiss Finance Inst SFI, Plattenstr 14, CH-8032 Zurich, Switzerland.	markus.leippold@bf.uzh.ch		Leippold, Markus/0000-0001-5983-2360				Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Kuutti, 2020, CURRENT RES THIS DIR; Kuutti S, 2021, IEEE T INTELL TRANSP, V22, P712, DOI 10.1109/TITS.2019.2962338; Lem S., 1981, GOLEM 14 WYDAWN LITE; Liu TY, 2022, Arxiv, DOI arXiv:2104.08704; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Shuster K, 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.07567; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Zhang NY, 2022, Arxiv, DOI arXiv:2108.13161	9	11	11	44	104	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1544-6123	1544-6131		FINANC RES LETT	Financ. Res. Lett.	MAY	2023	53								103617	10.1016/j.frl.2022.103617	http://dx.doi.org/10.1016/j.frl.2022.103617		MAR 2023	4	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	A6HS8		hybrid, Green Published			2024-07-03	WOS:000956118300001
J	O'Leary, DE				O'Leary, Daniel E.			The Rise and Design of Enterprise Large Language Models	IEEE INTELLIGENT SYSTEMS			English	Article						Focusing; Intelligent systems		This article investigates a new phenomenon of enterprise large language models (ELLMs) focusing on what they are, why they are being developed, and what are some key capabilities. In addition, the article drills down on issues associated with integrating retrieval augmented generation approaches into ELLMs, including emerging research issues.	[O'Leary, Daniel E.] Univ Southern Calif, Los Angeles, CA 90007 USA	University of Southern California	O'Leary, DE (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	oleary@usc.edu		O'Leary, Daniel Edmund/0000-0002-5240-9516				.gartner, Gartner experts answer the top generative AIquestions for your enterprise; Leggatt J., 2023, "Forbes, Mar.; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; O'Leary DE, 2023, AI MAG, V44, P282, DOI 10.1002/aaai.12118; O'Leary DE, 2016, J DECIS SYST, V25, P512, DOI 10.1080/12460125.2016.1193930; Sheikh J., 2023, ForbesApr.; Steen H, 2023, Retrieval augmented generation (RAG) inAzure AI Search; Tadros E., 2023, Australian Financial ReviewFeb.	8	1	1	16	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1541-1672	1941-1294		IEEE INTELL SYST	IEEE Intell. Syst.	JAN	2024	39	1					60	63		10.1109/MIS.2023.3345591	http://dx.doi.org/10.1109/MIS.2023.3345591			4	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	KB8W7					2024-07-03	WOS:001177602100001
J	Dudhee, V; Vukovic, V				Dudhee, Vishak; Vukovic, Vladimir			How large language models and artificial intelligence are transforming civil engineering	PROCEEDINGS OF THE INSTITUTION OF CIVIL ENGINEERS-CIVIL ENGINEERING			English	Editorial Material								Large language models with artificial intelligence are transforming the way infrastructure projects are planned, executed and managed. Vishak Dudhee and Vladimir Vukovic of V-Lab say they are unlocking unprecedented efficiency and innovation in civil engineering.					Dudhee, Vishak/AAQ-3077-2021; Vukovic, Vladimir/E-9599-2018	Dudhee, Vishak/0000-0002-8155-9513; Vukovic, Vladimir/0000-0003-0702-2475				Chui M., 2023, The economic potential of generative AI; HMG (Her Majesty's Government), 2021, Command Paper 525	2	0	0	36	42	EMERALD GROUP PUBLISHING LTD	Leeds	Floor 5, Northspring 21-23 Wellington Street, Leeds, W YORKSHIRE, ENGLAND	0965-089X	1751-7672		P I CIVIL ENG-CIV EN	Proc. Inst. Civil Eng.-Civil Eng.	SEP 28	2023	176	4					150	150		10.1680/jcien.2023.176.4.150	http://dx.doi.org/10.1680/jcien.2023.176.4.150			1	Engineering, Civil	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	W8IH7					2024-07-03	WOS:001094005600004
J	Heersmink, R				Heersmink, Richard			Use of large language models might affect our cognitive skills	NATURE HUMAN BEHAVIOUR			English	Article							INFORMATION	Large language models can generate sophisticated text or code with little input from a user, which has the potential to impoverish our own writing and thinking skills. We need to understand the effect of this technology on our cognition and to decide whether this is what we want.	[Heersmink, Richard] Tilburg Univ, Sch Humanities & Digital Sci, Dept Philosophy, Tilburg, Netherlands	Tilburg University	Heersmink, R (corresponding author), Tilburg Univ, Sch Humanities & Digital Sci, Dept Philosophy, Tilburg, Netherlands.	j.r.heersmink@tilburguniversity.edu		Heersmink, Richard/0000-0002-0102-0308				Carr N., 2010, The shallows: What the internet is doing to our brains; Clark A., 2008, SUPERSIZING MIND EMB; Heersmink R, 2016, MIND MACH, V26, P389, DOI 10.1007/s11023-016-9404-3; Heersmink R, 2015, PHENOMENOL COGN SCI, V14, P577, DOI 10.1007/s11097-014-9355-1; Heersmink R, 2013, REV PHILOS PSYCHOL, V4, P465, DOI 10.1007/s13164-013-0148-1; Hejtmánek L, 2018, INT J HUM-COMPUT ST, V116, P15, DOI 10.1016/j.ijhcs.2018.04.006; Mao Y, 2017, EDUC STUD MATH, V94, P69, DOI 10.1007/s10649-016-9714-7; Menary R, 2007, LANG SCI, V29, P621, DOI 10.1016/j.langsci.2007.01.005; Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745; Sutton J., 2010, The extended mind, P189, DOI DOI 10.7551/MITPRESS/8535.003.0009	10	1	1	14	14	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	MAY	2024	8	5					805	806		10.1038/s41562-024-01859-y	http://dx.doi.org/10.1038/s41562-024-01859-y		MAR 2024	2	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	SL3G8	38519731				2024-07-03	WOS:001190322400002
C	Kochberger, P; Gramberger, M; Schrittwieser, S; Lawitschka, C; Weippl, ER		DiVimercati, SD; Samarati, P		Kochberger, Patrick; Gramberger, Maximilian; Schrittwieser, Sebastian; Lawitschka, Caroline; Weippl, Edgar R.			Large Language Models for Code Obfuscation Evaluation of the Obfuscation Capabilities of OpenAI's GPT-3.5 on C Source Code	PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE ON SECURITY AND CRYPTOGRAPHY, SECRYPT 2023	SECRYPT		English	Proceedings Paper	20th International Conference on Security and Cryptography (SECRYPT)	JUL 10-12, 2023	Rome, ITALY			Software Protections; Code Obfuscation; Large Language Model; GPT.		This study explores the efficacy of large language models, specifically GPT-3.5, in obfuscating C source code for software protection. We utilized eight distinct obfuscation techniques in tandem with seven representative C code samples to conduct a comprehensive analysis. The evaluation was performed using a Python-based tool we developed, which interfaces with the OpenAI API to access GPT-3.5. Our metrics of evaluation included the correctness and diversity of the obfuscated code, along with the robustness of the resultant protection. While the diversity of the resulting code was found to be commendable, our findings indicate a prevalent issue with the correctness of the obfuscated code and the overall level of protection provided. Consequently, we assert that while promising, the feasibility of deploying large language models for automatic code obfuscation is not yet sufficiently established. This study signifies an important step towards understanding the limitations and potential of AI-based code obfuscation, thereby informing future research in this area.	[Kochberger, Patrick; Gramberger, Maximilian] St Polten Univ Appl Sci, Inst IT Secur Res, St Polten, Austria; [Kochberger, Patrick; Schrittwieser, Sebastian; Lawitschka, Caroline] Univ Vienna, Res Grp Secur & Privacy, Vienna, Austria; [Weippl, Edgar R.] SBA Res, Vienna, Austria	St. Polten University of Applied Sciences; University of Vienna	Kochberger, P (corresponding author), St Polten Univ Appl Sci, Inst IT Secur Res, St Polten, Austria.; Kochberger, P (corresponding author), Univ Vienna, Res Grp Secur & Privacy, Vienna, Austria.				Austrian Science Fund (FWF) [I 3646-N31]	Austrian Science Fund (FWF)(Austrian Science Fund (FWF))	This research was funded in whole, or in part, by the Austrian Science Fund (FWF) I 3646-N31. For the purpose of open access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.	Charikar M.S., 2002, P 34 ANN ACM S THEOR, P380; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Junod P, 2015, 2015 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE PROTECTION (SPRO), P3, DOI 10.1109/SPRO.2015.10; Khan JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559548; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; Narasimhan A, 2021, Arxiv, DOI arXiv:2108.10168; Poesia G, 2022, Arxiv, DOI [arXiv:2201.11227, 10.48550/ARXIV.2201.11227]; Schallner M., 2006, Beginners Guide to Basic Linux Anti Anti Debugging Techniques	9	0	0	5	7	SCITEPRESS	SETUBAL	AV D MANUELL, 27A 2 ESQ, SETUBAL, 2910-595, PORTUGAL	2184-7711		978-989-758-666-8	SECRYPT			2023							7	19		10.5220/0012167000003555	http://dx.doi.org/10.5220/0012167000003555			13	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV7WS					2024-07-03	WOS:001072829100001
J	Lorenzoni, G; Gregori, D; Bressan, S; Ocagli, H; Azzolina, D; Da Dalt, L; Berchialla, P				Lorenzoni, Giulia; Gregori, Dario; Bressan, Silvia; Ocagli, Honoria; Azzolina, Danila; Da Dalt, Liviana; Berchialla, Paola			Use of a Large Language Model to Identify and Classify Injuries With Free-Text Emergency Department Data	JAMA NETWORK OPEN			English	Article								This cross-sectional study assesses the accuracy, sensitivity, and specificity of a large language model used to process unstructured, non-English emergency department (ED) data in medical records.	[Lorenzoni, Giulia; Gregori, Dario; Ocagli, Honoria] Univ Padua, Dept Cardiac Thorac Vasc Sci & Publ Hlth, Unit Biostat Epidemiol & Publ Hlth, Via Loredan,18, I-35131 Padua, Italy; [Bressan, Silvia; Da Dalt, Liviana] Univ Padua, Dept Womens & Childrens Hlth, Div Pediat Emergency Med, Padua, Italy; [Azzolina, Danila] Univ Ferrara, Dept Environm & Prevent Sci, Ferrara, Italy; [Berchialla, Paola] Univ Turin, Ctr Biostat Epidemiol & Publ Hlth, Dept Clin & Biol Sci, Turin, Italy	University of Padua; University of Padua; University of Ferrara; University of Turin	Gregori, D (corresponding author), Univ Padua, Dept Cardiac Thorac Vasc Sci & Publ Hlth, Unit Biostat Epidemiol & Publ Hlth, Via Loredan,18, I-35131 Padua, Italy.	dario.gregori@unipd.it						Azzolina D, 2023, JMIR PUBLIC HLTH SUR, V9, DOI 10.2196/44467; Gianfrancesco MA, 2021, BMC MED RES METHODOL, V21, DOI 10.1186/s12874-021-01416-5; Lorenzoni G, 2021, MED CARE RES REV, V78, P138, DOI 10.1177/1077558719844123; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Rudnytskyi I., Openai: R wrapper for OpenAI API. R package version 0.4.1; Sminkey L, 2008, INJURY PREV, V14, P69, DOI 10.1136/ip.2007.018143	6	0	0	2	2	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2574-3805			JAMA NETW OPEN	JAMA Netw. Open	MAY 28	2024	7	5							e2413208	10.1001/jamanetworkopen.2024.13208	http://dx.doi.org/10.1001/jamanetworkopen.2024.13208			4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	SS1W1	38805230	gold, Green Accepted			2024-07-03	WOS:001236356500006
J	Collins, H				Collins, Harry			Why artificial intelligence needs sociology of knowledge: parts I and II	AI & SOCIETY			English	Article; Early Access						Large language models; ChatGPT; Artificial intelligence; Sociology of knowledge; Studies of expertise and experience; Fractal model of society; Socialisation; Foundations of moral understanding	SCIENCE	Recent developments in artificial intelligence based on neural nets-deep learning and large language models which together I refer to as NEWAI-have resulted in startling improvements in language handling and the potential to keep up with changing human knowledge by learning from the internet. Nevertheless, examples such as ChatGPT, which is a 'large language model', have proved to have no moral compass: they answer queries with fabrications with the same fluency as they provide facts. I try to explain why this is, basing the argument on the sociology of knowledge, particularly social studies of science, notably 'studies of expertise and experience' and the 'fractal model' of society. Learning from the internet is not the same as socialisation: NEWAI has no primary socialisation such as provides the foundations of human moral understanding. Instead, large language models are retrospectively socialised by human intervention in an attempt to align them with societally accepted ethics. Perhaps, as technology advances, large language models could come to understand speech and recognise objects sufficiently well to acquire the equivalent of primary socialisation. In the meantime, we must be vigilant about who is socialising them and be aware of the danger of their socialising us to align with them rather than vice-versa, an eventuality that would lead to the further erosion of the distinction between the true and the false giving further support to populism and fascism.	[Collins, Harry] Cardiff Univ, Sch Social Sci, Cardiff CF10 3WT, Wales	Cardiff University	Collins, H (corresponding author), Cardiff Univ, Sch Social Sci, Cardiff CF10 3WT, Wales.	CollinsHM@cf.ac.uk						[Anonymous], 1959, The Third University of Utah research conference on the identification of scientific talent; [Anonymous], 1976, KNOWLEDGE SOCIAL IMA; Arendt Hannah., 1951, Origins of Totalitarianism; Blackwell AF, 2015, P CRIT ALT 5 DEC AAR, P169; Bloor David., 1983, WITTGENSTEIN SOCIAL, DOI DOI 10.1007/978-1-349-17273-3; Bowlby John., 1953, CHILD CARE GROWTH LO; Caudill D. S., 2019, The third wave in science and technology studies: Future research directions on expertise and experience; Chalmers D. J., 1996, The Conscious Mind: In Search of a Fundamental Theory; Collins H, 2016, Being Chapter 14 of Collins's Gravity's Kiss, 2017; Collins H. M., 2004, Phenomenology and the Cognitive Sciences, V3, P125, DOI [DOI 10.1023/B:PHEN.0000040824.89221.1A, 10.1023/B:PHEN.0000040824.89221.1a]; Collins H. M., 2018, Artifictional intelligence: Against humanitys surrender to computers; Collins H.M., 2007, Rethinking Expertise; Collins H.M., 1998, SHAPE ACTIONS WHAT H; Collins H.M., 1990, ARTIFICIAL EXPERTS S; Collins H. M., 2022, The face-to-face principle: Science, trust, democracy and the internet, DOI [10.18573/book7, DOI 10.18573/BOOK7]; Collins H, 2023, SYNTHESE, V202, DOI 10.1007/s11229-023-04357-2; Collins H, 2023, SOC STUD SCI, V53, P379, DOI 10.1177/03063127221138521; Collins H, 2006, STUD HIST PHILOS SCI, V37, P656, DOI 10.1016/j.shpsa.2006.09.005; Collins H, 2021, INTERDISCIPL SCI REV, V46, P53, DOI 10.1080/03080188.2020.1840821; Collins H, 2020, PHENOMENOL COGN SCI, V19, P933, DOI 10.1007/s11097-020-09679-x; Collins H, 2018, SOC EPISTEMOL, V32, P351, DOI 10.1080/02691728.2018.1546346; Collins Harry, 2017, Perspectives on Science, V25, P411, DOI 10.1162/POSC_a_00248; Collins H, 2011, SOC STUD SCI, V41, P271, DOI 10.1177/0306312711399665; Collins HM, 1998, SCI TECHNOL HUM VAL, V23, P494, DOI 10.1177/016224399802300408; Dreyfus H. L., 1992, What computers still can't do.; DREYFUS HL, 1967, REV METAPHYS, V21, P13; Durkheim Emile., 2019, Professional Ethics and Civic Morals; Giles J, 2006, NATURE, V442, P8, DOI 10.1038/442008a; Guinness H, 2023, How does ChatGPT work?: Here's the human-written answer for how ChatGPT works; Kuhn T.S., 2012, STRUCTURE SCI REVOLU; Levesque H., 2012, 13 INT C PRINCIPLES; Madhumita M, 2023, Financial Times; OpenAI, 2023, GTP4 technical report 2303.08774.pdf; Oreskes N., 2023, The Big Myth: How American Business Taught Us to Loathe Government and Love the Free Market; Perrigo B, 2023, TIME; Reber A.S, 2018, First minds: caterpillars, karyotes, and consciousness, DOI [10.1093/oso/9780190854157.001.0001, DOI 10.1093/OSO/9780190854157.001.0001]; Shapin Steven., 1994, SOCIAL HIST TRUTH CI, DOI [10.7208/chicago/9780226148847.001.0001, DOI 10.7208/CHICAGO/9780226148847.001.0001]; Wilson E.O., 1975, P1; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?	39	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2024 MAY 18	2024										10.1007/s00146-024-01954-8	http://dx.doi.org/10.1007/s00146-024-01954-8		MAY 2024	15	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	RH3X6		hybrid			2024-07-03	WOS:001226746600004
J	Nolfi, S				Nolfi, Stefano			On the Unexpected Abilities of Large Language Models	ADAPTIVE BEHAVIOR			English	Article; Early Access						Large language models; implicit learning; emergence		Large Language Models (LLMs) are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I review recent research investigating the cognitive abilities developed by LLMs and their relation to human cognition. I discuss the nature of the indirect process that leads to the acquisition of these cognitive abilities, their relation to other indirect processes, and the implications for the acquisition of integrated abilities. Moreover, I propose the factors that enable the development of abilities that are related only very indirectly to the proximal objective of the training task. Finally, I discuss whether the full set of capabilities that LLMs could possibly develop is predictable.	[Nolfi, Stefano] Natl Res Council CNR ISTC, Inst Cognit Sci & Technol, Via Giandomen Romagnosi 18a, I-00196 Rome, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienze e Tecnologie della Cognizione (ISTC-CNR)	Nolfi, S (corresponding author), Natl Res Council CNR ISTC, Inst Cognit Sci & Technol, Via Giandomen Romagnosi 18a, I-00196 Rome, Italy.	stefano.nolfi@cnr.it			Ministero dell'Istruzione, dell'Universit e della Ricerca [PE0000013-FAIR]	Ministero dell'Istruzione, dell'Universit e della Ricerca(Ministry of Education, Universities and Research (MIUR))	I acknowledge financial support from PNRR MUR project PE0000013-FAIR. I thank Katja Sangati and the anonymous reviewers for their insightful comments.	Abdou M., 2021, arXiv; Akkaya I., 2019, ARXIV191007113; Bai Y., 2022, 2204.05862; Bai Y., 2022, Constitutional ai: Harmlessness from ai feedback; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Binz M., 2023, arXiv; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Bommasani Rishi, 2021, ARXIV210807258; Borghi A., 2023, Sistemi Intelligenti, V35, P367; Bowman S. R., 2023, arXiv; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2003, Sparks of artificial general intelligence: Early experiments with gpt-4, VVol. abs/2303.12712; Cheng M., 2023, arXiv; Chowdhery A., 2022, arXiv; Christiano PF, 2017, ADV NEUR IN, V30; Christiansen MH, 2016, BEHAV BRAIN SCI, V39, DOI 10.1017/S0140525X1500031X; Chuang Y. S., 2023, arXiv; Cisek P., 1999, Journal of Consciousness Studies, V6, P125; Creswell A., 2022, ARXIV; Dai D., 2022, arXiv; Dinan E., 2019, arXiv; Driess D., 2023, ARXIV; Dziri N., 2023, Faith and fate: Limits of transformers on compositionality; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Everaert MBH, 2015, TRENDS COGN SCI, V19, P729, DOI 10.1016/j.tics.2015.09.008; Ganguli D., 2022, arXiv; Ganguli D., 2023, arXiv; Gehman S., 2020, arXiv; Han HYM, 2023, J MORAL EDUC, DOI 10.1080/03057240.2023.2250570; Huang WL, 2022, PR MACH LEARN RES; Jones C. R., 2022, Proceedings of the annual meeting of the cognitive science society, VVol. 44, P14; Kaplan Jared, 2020, Scaling laws for neural language models; Kolodny O, 2018, PHILOS T R SOC B, V373, DOI 10.1098/rstb.2017.0052; Korbak T., 2023, arXiv; Kosinski M., 2023, arXiv; Lee K. H., 2022, Advances in Neural Information Processing Systems, V35, P27921; Li B., 2021, ARXIV; Mahowald K., 2023, arXiv; Mirolli M, 2011, NEW IDEAS PSYCHOL, V29, P298, DOI 10.1016/j.newideapsych.2009.07.001; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Mollo D. C., 2023, arXiv; Nolfi S, 2010, EVOLUTION OF COMMUNICATION AND LANGUAGE IN EMBODIED AGENTS, P1, DOI 10.1007/978-3-642-01250-1; Ortega P. A., 2021, arXiv; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patel R., 2022, INT C LEARNING REPRE; Petroni F., 2019, 2019 C EMP METH NAT; Pezzulo G., 2023, Generating meaning: Active inference and the scope and limits of passive AI; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; Rae J. W., 2021, arXiv; Roberts A., 2020, P 2020 C EMP METH; Saysani A, 2021, VIS COGN, V29, P63, DOI 10.1080/13506285.2020.1866726; Schaeffer R., 2023, ARXIV; Shanahan M, 2023, NATURE, V623, P493, DOI 10.1038/s41586-023-06647-8; Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270; Sogaard A, 2023, MIND MACH, V33, P33, DOI 10.1007/s11023-023-09622-4; Srivastava A., 2022, ARXIV; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Tamkin A., 2021, arXiv; Tang Y., 2024, arXiv; Taylor T, 2019, ARTIF LIFE, V25, P207, DOI 10.1162/artl_a_00290; Thoppilan R, 2022, ARXIV; Touvron H., 2023, arXiv; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Ullman T., 2023, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Warstadt A., 2022, arXiv; Warstadt A., 2023, arXiv; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321; Wei J., 2022, Emergent abilities of large language models; Weidinger L., 2021, ARXIV; Wolf Y., 2023, arXiv; Wu X., 2023, arXiv; Yun T., 2021, arXiv; Zhang S., 2023, arXiv	74	0	0	0	0	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1059-7123	1741-2633		ADAPT BEHAV	Adapt. Behav.	2024 MAY 24	2024										10.1177/10597123241256754	http://dx.doi.org/10.1177/10597123241256754		MAY 2024	10	Computer Science, Artificial Intelligence; Psychology, Experimental; Social Sciences, Interdisciplinary	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Psychology; Social Sciences - Other Topics	RW5V3		Green Submitted			2024-07-03	WOS:001230718900001
J	Hickman, L; Dunlop, PD; Wolf, JL				Hickman, Louis; Dunlop, Patrick D.; Wolf, Jasper Leo			The performance of large language models on quantitative and verbal ability tests: Initial evidence and implications for unproctored high-stakes testing	INTERNATIONAL JOURNAL OF SELECTION AND ASSESSMENT			English	Article; Early Access						artificial intelligence; chatbots; cognitive ability testing; generative pretrained transformer; large language models	COGNITIVE-ABILITY; SELECTION; VALIDATION; FAKING	Unproctored assessments are widely used in pre-employment assessment. However, widely accessible large language models (LLMs) pose challenges for unproctored personnel assessments, given that applicants may use them to artificially inflate their scores beyond their true abilities. This may be particularly concerning in cognitive ability tests, which are widely used and traditionally considered to be less fakeable by humans than personality tests. Thus, this study compares the performance of LLMs on two common types of cognitive tests: quantitative ability (number series completion) and verbal ability (use a passage of text to determine whether a statement is true). The tests investigated are used in real-world, high-stakes selection. We also examine the performance of the LLMs across different test formats (i.e., open-ended vs. multiple choice). Further, we contrast the performance of two LLMs (Generative Pretrained Transformers, GPT-3.5 and GPT-4) across multiple prompt approaches and "temperature" settings (i.e., a parameter that determines the amount of randomness in the model's output). We found that the LLMs performed well on the verbal ability test but extremely poorly on the quantitative ability test, even when accounting for the test format. GPT-4 outperformed GPT-3.5 across both types of tests. Notably, although prompt approaches and temperature settings did affect LLM test performance, those effects were mostly minor relative to differences across tests and language models. We provide recommendations for securing pre-employment testing against LLM influences. Additionally, we call for rigorous research investigating the prevalence of LLM usage in pre-employment testing as well as on how LLM usage affects selection test validity. Job candidates may use large language models like ChatGPT to complete ability tests on their behalf, but we currently know little about how well these models perform on commercial cognitive ability tests. OpenAI's (free) Generative Pretrained Transformers (GPT)-3.5 and (paid subscription) GPT-4 models both performed very poorly on a quantitative ability test. GPT-4 achieved results above the 90th percentile on the verbal ability test, and GPT-3.5 scored at approximately the 60th percentile. Temperature settings did not substantially affect the performance of the large language models and different prompt approaches tended not to, with few exceptions.	[Hickman, Louis] Univ Penn, Virginia Tech, Wharton Sch, Dept Psychol, Blacksburg, VA 19104 USA; [Dunlop, Patrick D.] Curtin Univ, Future Work Inst, Fac Business & Law, Perth, WA, Australia; [Wolf, Jasper Leo] Arctic Shores, London, England	Virginia Polytechnic Institute & State University; Curtin University	Hickman, L (corresponding author), Univ Penn, Virginia Tech, Wharton Sch, Dept Psychol, Blacksburg, VA 19104 USA.	louishickman@vt.edu	Dunlop, Patrick/K-6738-2012	Dunlop, Patrick/0000-0002-5225-6409				Acar O. A., 2023, Harvard Business Review; Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; Anthropic, 2024, Prompt engineering; Arctic Shores, 2023, ChatGPT vs Situational Judgement Tests: Can it outperform a human?; Arctic Shores, 2023, ChatGPT vs Personality Assessments; Arthur W, 2010, INT J SELECT ASSESS, V18, P1, DOI 10.1111/j.1468-2389.2010.00476.x; Bangerter A, 2012, J APPL PSYCHOL, V97, P719, DOI 10.1037/a0026078; Beaty JC, 2011, INT J SELECT ASSESS, V19, P1, DOI 10.1111/j.1468-2389.2011.00529.x; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Borchert RJ, 2023, JMIR MED EDUC, V9, DOI 10.2196/48978; Brin D, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-43436-9; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Budhwar P, 2023, HUM RESOUR MANAG J, V33, P606, DOI 10.1111/1748-8583.12524; Chamorro-Premuzic T., 2005, PERSONALITY INTELLEC; Chen BH, 2024, Arxiv, DOI [arXiv:2310.14735, 10.48550/arXiv.2310.14735]; Condon DM, 2014, INTELLIGENCE, V43, P52, DOI 10.1016/j.intell.2014.01.004; Donovan JJ, 2003, HUM PERFORM, V16, P81, DOI 10.1207/S15327043HUP1601_4; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Groza A, 2023, Arxiv, DOI arXiv:2310.05993; Hu J, 2021, INT J SELECT ASSESS, V29, P412, DOI 10.1111/ijsa.12338; Kantrowitz TM, 2014, J BUS PSYCHOL, V29, P605, DOI 10.1007/s10869-014-9365-6; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Landers R. N., 2023, Talent assessment: Embracing innovation and mitigating risk in the digital age, P202, DOI [10.1093/oso/9780197611050.003.0013, DOI 10.1093/OSO/9780197611050.003.0013]; Levashina J, 2007, J APPL PSYCHOL, V92, P1638, DOI 10.1037/0021-9010.92.6.1638; Levashina J, 2009, INT J SELECT ASSESS, V17, P271, DOI 10.1111/j.1468-2389.2009.00469.x; Lievens F, 2011, J OCCUP ORGAN PSYCH, V84, P817, DOI 10.1348/096317910X522672; Maynez J, 2020, Arxiv, DOI [arXiv:2005.00661, DOI 10.48550/ARXIV.2005.00661]; Metcalfe C., 2024, MIT Technology Review; Mitchell M, 2023, Arxiv, DOI [arXiv:2311.09247, 10.48550/arXiv.2311.09247, DOI 10.48550/ARXIV.2311.09247]; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Morton J., 2024, Harvard Business Review; Nasr M., 2023, Extracting training data from ChatGPT; Nye CD, 2008, INT J SELECT ASSESS, V16, P112, DOI 10.1111/j.1468-2389.2008.00416.x; OpenAI, 2023, GPT 4 TECHNICAL REPO; Phillips J, 2024, PERS INDIV DIFFER, V217, DOI 10.1016/j.paid.2023.112434; Porter J., 2023, TheVerge; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sackett PR, 2023, J APPL PSYCHOL, DOI 10.1037/apl0001159; Sackett PR, 2022, J APPL PSYCHOL, V107, P2040, DOI 10.1037/apl0000994; Schmidt FL, 1998, PSYCHOL BULL, V124, P262, DOI 10.1037/0033-2909.124.2.262; Schreiner M., 2023, GPT-4 architecture, datasets, costs and more leaked; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Similar Web, 2023, Traffic analytics, ranking stats, and tech stack; Steger D, 2020, EUR J PSYCHOL ASSESS, V36, P174, DOI 10.1027/1015-5759/a000494; Templer KJ, 2008, COMPUT HUM BEHAV, V24, P1216, DOI 10.1016/j.chb.2007.04.006; The International Cognitive Ability Resource Team, 2014, about us; Tippins NT, 2006, PERS PSYCHOL, V59, P189, DOI 10.1111/j.1744-6570.2006.00909.x; Wang BS, 2023, Arxiv, DOI arXiv:2212.10001; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Woods SA, 2024, J OCCUP ORGAN PSYCH, V97, P253, DOI 10.1111/joop.12470; Xu BF, 2023, Arxiv, DOI arXiv:2305.14688	56	0	0	8	8	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0965-075X	1468-2389		INT J SELECT ASSESS	Int. J. Sel. Assess.	2024 MAY 17	2024										10.1111/ijsa.12479	http://dx.doi.org/10.1111/ijsa.12479		MAY 2024	13	Psychology, Applied; Management	Social Science Citation Index (SSCI)	Psychology; Business & Economics	QZ6G8		hybrid			2024-07-03	WOS:001224725100001
C	Fang, WY; Zhang, H; Gong, ZY; Zeng, LB; Lu, XH; Liu, B; Wu, XY; Zheng, Y; Hu, Z; Zhang, X			IEEE	Fang, Wenyi; Zhang, Hao; Gong, Ziyu; Zeng, Longbin; Lu, Xuhui; Liu, Biao; Wu, Xiaoyu; Zheng, Yang; Hu, Zheng; Zhang, Xun			A Survey of Metrics to Enhance Training Dependability in Large Language Models	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS, ISSREW			English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART		Large Language Model; Dependability; Monitoring Metric		The rapidly advancing field of artificial intelligence requires meticulous attention to the training and monitoring of large language models (LLMs). This paper offers a systematic analysis of existing metrics and introduces new ones, focusing on their theoretical underpinnings and practical implementations. We present empirical results and insights into the performance of selected metrics, elucidating the complex interplay of variables in the training process. Our comprehensive approach provides significant insights into LLM training, and promises to improve the dependability and efficiency of future models.	[Fang, Wenyi; Zhang, Hao; Gong, Ziyu; Zeng, Longbin; Lu, Xuhui; Liu, Biao; Wu, Xiaoyu; Zheng, Yang; Hu, Zheng; Zhang, Xun] Huawei Technol Co Ltd, Shenzhen, Peoples R China; [Lu, Xuhui] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China	Huawei Technologies; Beihang University	Fang, WY (corresponding author), Huawei Technol Co Ltd, Shenzhen, Peoples R China.	fangwenyi2@huawei.com						Allen-Zhu Z, 2019, ADV NEUR IN, V32; Bahri Y., 2021, Explaining neural scaling laws; Bills S., 2023, Language models can explain neurons in language models; Brown T., 2020, NIPS, P1877; Davies X., 2023, Unifying grokking and double descent; Du S. S., 2018, INT C LEARNING REPRE; Elhage N., 2022, Transformer Circuits Thread; Fort S., Advances in Neural Information Processing Systems, V33, P5850; Fort S, 2019, AAAI CONF ARTIF INTE, P3574; Henighan T., 2023, Transformer Circuits Thread; Hoffmann J., 2022, Training compute-optimal large language models; Hutter M., 2021, Learning curve theory; Jacot A, 2018, ADV NEUR IN, V31; Janizek JD, 2021, J MACH LEARN RES, V22; Kaplan Jared, 2020, Scaling laws for neural language models; Lee S, 2022, PHYS REV E, V105, DOI 10.1103/PhysRevE.105.044306; Li M., 2023, INT C MACH LEARN; Lin S. C., 2021, ANN M ASS COMP LING; Liu Z., 2023, Omnigrok: Grokking beyond algorithmic data; Lundberg SM, 2017, ADV NEUR IN, V30; Malladi S., 2023, A Kernel-Based View of Language Model Fine-Tuning; Marsili M, 2013, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2013/09/P09003; Meng K., 2022, C NEUR INF PROC SYST; Michaud E. J., 2023, The quantization model of neural scaling; Nakkiran P, 2021, J STAT MECH-THEORY E, V2021, DOI 10.1088/1742-5468/ac3a74; Novak R., 2019, Neural tangents: Fast and easy infinite neural networks in python; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Power A., 2022, Grokking: Generalization beyond overfitting on small algorithmic datasets; Ren J., 2023, IEEE CVF COMP VIS PA; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Shwartz-Ziv R., 2017, ARXIV170300810; Simonyan K., 2013, DEEP INSIDE CONVOLUT; Sundararajan M., 2019, INT C MACH LEARN; Sundararajan M, 2017, PR MACH LEARN RES, V70; Velikanov M., 2021, Advances in Neural Information Processing Systems, V34, P2570; Wei J., 2022, Emergent abilities of large language models; Wolchover N., 2017, Quanta Magazine; Yang Z., 2023, arXiv; Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53; Zhang QS, 2018, PROC CVPR IEEE, P8827, DOI 10.1109/CVPR.2018.00920; Zhang S., 2022, Opt: Open pre-trained transformer language models; Zhou Bolei, 2014, Object detectors emerge in deep scene cnns	42	0	0	3	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-1956-9				2023							180	185		10.1109/ISSREW60843.2023.00071	http://dx.doi.org/10.1109/ISSREW60843.2023.00071			6	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KT					2024-07-03	WOS:001096854800039
C	Ji, JC; Li, ZL; Xu, SY; Hua, WY; Ge, YQ; Tan, JT; Zhang, YF		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Ji, Jianchao; Li, Zelong; Xu, Shuyuan; Hua, Wenyue; Ge, Yingqiang; Tan, Juntao; Zhang, Yongfeng			GenRec: Large Language Model for Generative Recommendation	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Large Language Model; Recommender Systems; Natural Language Processing; Generative Recommendation	SYSTEMS	In recent years, Large Language Models (LLMs) have emerged as powerful tools for diverse natural language processing tasks. However, their potential for recommender systems under the generative recommendation paradigm remains relatively unexplored. This paper presents an innovative approach to recommender systems using Large Language Models (LLMs) purely based on raw text data, i.e., using item name or title as item IDs rather than creating meticulously designed user or item IDs. More specifically, we present a novel LLM for Generative Recommendation (GenRec) method that utilizes the expressive power of LLM to directly generate the target item to recommend, rather than calculating the ranking score for each candidate item one by one as in traditional discriminative recommendation. GenRec uses LLM's understanding ability to interpret context, learn user preferences, and generate relevant recommendations. Our proposed approach leverages the vast knowledge encoded in Large Language Models to accomplish recommendation tasks. We formulate specialized prompts to enhance the ability of LLM to comprehend recommendation tasks. Subsequently, we use these prompts to LoRA-fine-tune the LLaMA backbone LLM on the user-item interaction data represented by raw text (using raw item name or title as the item's ID) to capture user preferences and item characteristics. Our research underscores the potential of LLM-based generative recommendation in revolutionizing the domain of recommendation systems and offers a foundational framework for future explorations in this field. We conduct extensive experiments on benchmark datasets, and the experiments show that our GenRec method achieves better results on large datasets. Code and data are are open-source at GitHub (https://github.com/rutgerswiselab/GenRec).	[Ji, Jianchao; Li, Zelong; Xu, Shuyuan; Hua, Wenyue; Ge, Yingqiang; Tan, Juntao; Zhang, Yongfeng] Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08854 USA	Rutgers University System; Rutgers University New Brunswick	Zhang, YF (corresponding author), Rutgers State Univ, Dept Comp Sci, New Brunswick, NJ 08854 USA.	jianchao.ji@rutgers.edu; zelong.li@rutgers.edu; shuyuan.xu@rutgers.edu; wenyue.hua@rutgers.edu; yingqiang.ge@rutgers.edu; juntao.tan@rutgers.edu; yongfeng.zhang@rutgers.edu			NSF [IIS-2046457, IIS2007907]	NSF(National Science Foundation (NSF))	The work was supported in part by NSF IIS-2046457 and IIS2007907. Any opinions, findings, conclusions or recommendations in this material are those of the authors and do not necessarily reflect those of the sponsors.	[Anonymous], 2004, Proceedings of the twenty-first international conference on Machine learning; Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; Hidasi B, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P241, DOI 10.1145/2959100.2959167; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hua W., 2023, SIGIR-AP; Hua WY, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1281, DOI 10.1145/3604915.3609494; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Konstan JA, 1997, COMMUN ACM, V40, P77, DOI 10.1145/245108.245126; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Li L, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P1348, DOI 10.1145/3583780.3615017; Li L, 2023, Arxiv, DOI [arXiv:2309.01157, 10.48550/ARXIV.2309.01157https://arxiv.org/abs/2309.011572309.01157]; Lin XY, 2023, Arxiv, DOI arXiv:2310.06491; Mei K, 2023, Arxiv, DOI arXiv:2310.17488; Ni JM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P188; Pazzani MJ, 1999, ARTIF INTELL REV, V13, P393, DOI 10.1023/A:1006544522159; Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905; Sanner S, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P890, DOI 10.1145/3604915.3608845; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI [10.1145/371920.372071, DOI 10.1145/371920.372071]; Son J, 2017, EXPERT SYST APPL, V89, P404, DOI 10.1016/j.eswa.2017.08.008; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Van Someren M., 2000, P MACH LEARN NEW INF, V30, P47; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Xu SY, 2024, Arxiv, DOI [arXiv:2306.11134, 10.48550/ARXIV.2306.11134]; Zheng BW, 2024, Arxiv, DOI arXiv:2311.09049	27	0	0	4	4	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56062-0; 978-3-031-56063-7	LECT NOTES COMPUT SC			2024	14610						494	502		10.1007/978-3-031-56063-7_42	http://dx.doi.org/10.1007/978-3-031-56063-7_42			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DZ		Green Submitted			2024-07-03	WOS:001211833300042
J	Snoswell, CL; Snoswell, AJ; Kelly, JT; Caffery, LJ; Smith, AC				Snoswell, Centaine L.; Snoswell, Aaron J.; Kelly, Jaimon T.; Caffery, Liam J.; Smith, Anthony C.			Artificial intelligence: Augmenting telehealth with large language models	JOURNAL OF TELEMEDICINE AND TELECARE			English	Article; Early Access						Machine learning; large language models; ChatGPT; telehealth; telemedicine; digital health; artificial intelligence		This brief editorial describes an emerging area of machine learning technology called large language models (LLMs). LLMs, such as ChatGPT, are the technological disruptor of this decade. They are going to be integrated into search engines (Bing and Google) and into Microsoft products in the coming months. They will therefore fundamentally change the way patients and clinicians access and receive information. It is essential that telehealth clinicians are aware of LLMs and appreciate their capabilities and limitations.	[Snoswell, Centaine L.; Kelly, Jaimon T.; Caffery, Liam J.; Smith, Anthony C.] Univ Queensland, Ctr Online Hlth, Brisbane, Australia; [Snoswell, Centaine L.; Kelly, Jaimon T.; Caffery, Liam J.; Smith, Anthony C.] Univ Queensland, Ctr Hlth Serv Res, Brisbane, Australia; [Smith, Anthony C.] Univ Southern Denmark, Ctr Innovat Med Technol, Odense, Denmark; [Snoswell, Aaron J.] Queensland Univ Technol, Australian Res Council Ctr Excellence Automated De, Brisbane, Australia; [Snoswell, Centaine L.] Univ Queensland, Ctr Online Hlth, Ctr Hlth Serv Res, Brisbane, Australia; [Snoswell, Centaine L.] Princess Alexandra Hosp, Ctr Online Hlth, Ground Floor Bldg 33, Woolloongabba, Qld 4102, Australia	University of Queensland; University of Queensland; University of Southern Denmark; Queensland University of Technology (QUT); University of Queensland; Princess Alexandra Hospital	Snoswell, CL (corresponding author), Univ Queensland, Ctr Online Hlth, Ctr Hlth Serv Res, Brisbane, Australia.; Snoswell, CL (corresponding author), Princess Alexandra Hosp, Ctr Online Hlth, Ground Floor Bldg 33, Woolloongabba, Qld 4102, Australia.	c.snoswell@uq.edu.au	Snoswell, Centaine L/G-3668-2016; Smith, Anthony Carl/E-9538-2010; Caffery, Liam/C-4096-2012; Kelly, Jaimon/I-3730-2016	Snoswell, Centaine L/0000-0002-4298-9369; Smith, Anthony Carl/0000-0002-7756-5136; Caffery, Liam/0000-0003-1899-7534; Snoswell, Aaron/0000-0003-0960-0144; Kelly, Jaimon/0000-0003-0232-5848	UQ retention fellowship; National Heart Foundation of Australia [106081]; Australian Research Council Centre of Excellence for Automated Decision-Making and Society [CE200100005]	UQ retention fellowship; National Heart Foundation of Australia(National Heart Foundation of Australia); Australian Research Council Centre of Excellence for Automated Decision-Making and Society(Australian Research Council)	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article:Dr C L Snoswell was funded by the UQ retention fellowship. Dr J Kelly was supported by a Postdoctoral Fellowship from the National Heart Foundation of Australia during this project(106081). Dr A J Snoswell is funded by the Australian Research Council Centre of Excellence for Automated Decision-Making and Society (CE200100005).	Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Iacobucci G., 2020, ROW BABYLONS CHATBOT; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Pan XD, 2020, P IEEE S SECUR PRIV, P1314, DOI 10.1109/SP40000.2020.00095; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Shen Y., 2023, CHATGPT OTHER LARGE; Smith S, 2022, arXiv; Snoswell A., 2022, CONVERSATION; Snoswell CL., 2023, RES SOC ADMIN PHARM; Tan SSL, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.5729; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	13	9	9	15	72	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1357-633X	1758-1109		J TELEMED TELECARE	J. Telemed. Telecare	2023 APR 11	2023										10.1177/1357633X231169055	http://dx.doi.org/10.1177/1357633X231169055		APR 2023	5	Health Care Sciences & Services	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services	D7KL3	37041736	Bronze			2024-07-03	WOS:000970477800001
J	Venerito, V; Gupta, L				Venerito, Vincenzo; Gupta, Latika			Large language models: rheumatologists' newest colleagues?	NATURE REVIEWS RHEUMATOLOGY			English	Article								In 2023, large language models demonstrated potential for use in rheumatology to accurately suggest diagnoses and provide empathetic patient education. However, the propensity of this technology to generate misleading information continues to pose risks. Balancing innovation with physician guidance is essential. Large language models (LLMs) have demonstrated diagnostic potential for rheumatic diseases, in some situations even outperforming diagnosis by rheumatologists5.ChatGPT and other LLMs can potentially contribute to patient education by providing detailed and empathetic responses to their queries, thereby enhancing patient understanding, fostering trust and promoting treatment adherence6.Caution should be displayed in the use of LLMs, as they have displayed a propensity for generating 'hallucinated' or misleading information about anchor medications such as methotrexate7.	[Venerito, Vincenzo] Univ Bari Aldo Moro, Dept Precis & Regenerat Med & Ionian Area DiMePRe, Rheumatol Unit, Bari, Italy; [Gupta, Latika] Royal Wolverhampton Hosp NHS Trust, Dept Rheumatol, Wolverhampton, England; [Gupta, Latika] Univ Manchester, Fac Biol, Ctr Musculoskeletal Res, Manchester Acad Hlth Sci Ctr, Manchester, England	Universita degli Studi di Bari Aldo Moro; University of Manchester	Gupta, L (corresponding author), Royal Wolverhampton Hosp NHS Trust, Dept Rheumatol, Wolverhampton, England.; Gupta, L (corresponding author), Univ Manchester, Fac Biol, Ctr Musculoskeletal Res, Manchester Acad Hlth Sci Ctr, Manchester, England.	drlatikagupta@gmail.com						Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Coskun BN, 2024, RHEUMATOL INT, V44, P509, DOI 10.1007/s00296-023-05473-5; Hügle T, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003105; Krusche M, 2024, RHEUMATOL INT, V44, P303, DOI 10.1007/s00296-023-05464-6; Vaswani A., 2017, P 31 ADV NEUR INF PR, V30, P1; Venerito Vincenzo, 2023, Lancet Rheumatol, V5, pe574, DOI 10.1016/S2665-9913(23)00216-3; Venerito V, 2023, RHEUMATOLOGY, V62, P3256, DOI 10.1093/rheumatology/kead291	7	3	3	10	10	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1759-4790	1759-4804		NAT REV RHEUMATOL	Nat. Rev. Rheumatol.	FEB	2024	20	2					75	76		10.1038/s41584-023-01070-9	http://dx.doi.org/10.1038/s41584-023-01070-9		JAN 2024	2	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	IX5T0	38177451				2024-07-03	WOS:001136615400001
J	Piller, E				Piller, Erick			The Ethics of (Non)disclosure: Large Language Models in Professional, Nonacademic Writing Contexts	RUPKATHA JOURNAL ON INTERDISCIPLINARY STUDIES IN HUMANITIES			English	Article						artificial intelligence; co-writing; ethics; large language models	AGE	This article explores the ethics of co -writing with large language models such as GPT-4 in professional, nonacademic writing contexts without disclosing the practice to stakeholders. It considers five ethical concepts through an analysis of a hypothetical scenario. Three of the concepts-transparency, data practices, and expanded circulation-originate in the work of Heidi McKee and James Porter. The other two, just price and risk imposition, have particular relevance for professional writers. The article ultimately proposes that these five concepts can serve as points of reference as we attempt to formulate and articulate ethical judgments about co -writing with generative AI in specific, contextually grounded instances.	[Piller, Erick] Nicholls State Univ, 906 E 1st St, Thibodaux, LA 70301 USA	University of Louisiana System; Nicholls State University	Piller, E (corresponding author), Nicholls State Univ, 906 E 1st St, Thibodaux, LA 70301 USA.							Baquero C, 2022, COMMUN ACM, V65, P6, DOI 10.1145/3565976; Beccue M., 2023, Manifesto: For humanity, the case against generative AI writing; Bessi A., 2016, 1 MONDAY, DOI [10.5210/fm.v21i11.7090, DOI 10.5210/FM.V21I11.7090]; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bowman E., 2023, National Public Radio; Burns H. L., 1979, Stimulating rhetorical invention in English composition through computer-assisted instruction; Castellanos-Gomez A., 2023, Nano, V3, P135, DOI DOI 10.3390/NANOMANUFACTURING3020009; Cuthbertson A., 2023, The Independent; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; De Vise D., 2023, The Hill; DEROOVER R, 1958, J ECON HIST, V18, P418; Elegido J, 2009, J BUS ETHICS, V90, P29, DOI 10.1007/s10551-008-0024-6; Eoanou A., 2022, Microsoft 365 Blog; Farid H., 2023, The Conversation; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Ghai B., 2021, ASSETS '21; Google, 2023, Generative AI Additional Terms of Service; Google, 2023, Google Search's guidance about AI-generated content; Hart-Davidson W, 2018, ROUTL HANDBK, P248; Heidorn GeorgeE., 2000, HDB NATURAL LANGUAGE, P181; Heikkila M., 2022, MIT Technology Review; HUNTER L, 1991, RHETORICA, V9, P317, DOI 10.1525/rh.1991.9.4.317; Katje C., 2023, Benzinga; KEMP F, 1987, COLL COMPOS COMMUN, V38, P32, DOI 10.2307/357584; Knowles AM, 2022, IEEE INT PROF COMMUN, P257, DOI 10.1109/ProComm53155.2022.00053; Koehn D, 2012, BUS ETHICS Q, V22, P501, DOI 10.5840/beq201222332; Korn J., 2023, THE CNN; Levin Blair., 2023, Harvard Business Review; Liu YX, 2023, Arxiv, DOI [arXiv:2305.13257, 10.48550/ARXIV.2305.13257, DOI 10.48550/ARXIV.2305.13257]; Makyen, 2022, Temporary policy: ChatGPT is banned; Marche S., 2022, The Atlantic; McKee H., 2018, Blog Carnival 13; McKee H. A., 2022, IEEE INT PROFESSIONA, DOI [10.1109/ProComm53155.2022.00078, DOI 10.1109/PROCOMM53155.2022.00078]; McKee HA, 2017, ROUTL STUD RHET COMM, P1; McKee HA, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P110, DOI 10.1145/3375627.3375811; McMurtrie Beth., 2022, The Chronicle of Higher Education; Mollick E., 2022, Harvard Business Review; Nelson J., 2023, Fox Business; OpenAI, 2022, Sharing publication policy; OpenAI, Text Completion; Orendorff J., Hugh Burns-Aristotle's Topics-Play; Pain N., 2023, Meaww; Phillips G., 1988, Communication Quarterly, V36, P243; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Roose Kevin, 2022, NEW YORK TIMES; Sag Matthew, 2023, HOUS. L. REV., V61, P295; Savov V., 2022, Bloomberg; Schuett Jonas, 2023, Law, Innovation and Technology, P60, DOI 10.1080/17579961.2023.2184135; SMITH CR, 1984, COMPUT HUMANITIES, V18, P215, DOI 10.1007/BF02267225; Solaiman I, 2019, Arxiv, DOI arXiv:1908.09203; Southern M. G., 2022, Search Engine Journal; Turilli M, 2009, ETHICS INF TECHNOL, V11, P105, DOI 10.1007/s10676-009-9187-9; Turnitin, Turnitin's AI Writing Detection Capabilities; u/walkerspider, 2022, Reddit; Ulanoff L., 2023, TechRadar; Undetectable.ai, 2023, AI Authorship Replication-for Small Businesses; Walsh T., 2022, The Conversation; White House Office of Science and Technology Policy, 2022, Blueprint for an AI bill of rights: making automated systems work for the American people; Wresch William., 1984, The Computer in Composition Instruction: A Writer's Tool; Yancey KB, 2018, ROUTL HANDBK, P61; Yang M., 2023, The GuardianJanuary 6; Zhang XY, 2022, AAAI CONF ARTIF INTE, P12423	62	0	0	1	1	AESTHETICS MEDIA SERVICES-AESTHETIXMS	WEST BENGAL	AESTHETICS MEDIA SERVICES-AESTHETIXMS, WEST BENGAL, 742225, INDIA	0975-2935			RUPKATHA J INTERDISC	Rupkatha J. Interdiscip. Stud. Humanit.		2023	15	4							02	10.21659/rupkatha.v15n4.02	http://dx.doi.org/10.21659/rupkatha.v15n4.02			27	Humanities, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Arts & Humanities - Other Topics	HG2Q1		gold			2024-07-03	WOS:001158277600006
C	Görer, B; Aydemir, PB		Schneider, K; Dalpiaz, F; Horkoff, J		Gorer, Binnur; Aydemir, Patina Barak			Generating Requirements Elicitation Interview Scripts with Large Language Models	2023 IEEE 31ST INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS, REW	IEEE International Requirements Engineering Conference Workshops		English	Proceedings Paper	31st IEEE International Requirements Engineering Conference (RE)	SEP 04-05, 2023	Hannover, GERMANY	IEEE, IEEE Comp Soc		large language models; prompt engineering; elicitation interview script generation; requirements engineering education		Requirements elicitation interviews are the most popular requirements elicitation technique and an integral part of requirements engineering education. Good and had interview scripts provide students with examples of applying the theory. Constructing an interview script requires technical knowledge, practical experience, and creativity. As a result, only a few educational interview scripts are available to the community. This paper explores automatically generating interview scripts with large language models through prompt engineering. Our contribution is two-fold: First, we present a graph representation of interactive interview scripts. Second, we apply prompt engineering techniques to generate business domain descriptions, linear scripts, and conversation pieces focused on certain types of mistakes. Our findings indicate that large language models face challenges in handling interview conversation graphs. However, we can enhance the quality of the generated interview scripts by decomposing the task into smaller components and refining the prompts to provide more precise instructions.	[Gorer, Binnur; Aydemir, Patina Barak] Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye	Bogazici University	Görer, B (corresponding author), Bogazici Univ, Dept Comp Engn, Istanbul, Turkiye.	binnur.gorer@boun.edu.tr; basak.aydemir@boun.edu.tr			Scientific and Technological Research Council of Turkiye through BIDEB 2232 [118C255]	Scientific and Technological Research Council of Turkiye through BIDEB 2232	The second author has been partially supported by the Scientific and Technological Research Council of Turkiye through BIDEB 2232 grant no. 118C255.	Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Bano M, 2019, REQUIR ENG, V24, P259, DOI 10.1007/s00766-019-00313-0; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cer D, 2018, Arxiv, DOI arXiv:1803.11175; Debnath S, 2020, LECT NOTES COMPUT SC, V12045, P160, DOI 10.1007/978-3-030-44429-7_12; Dijkstra R., 2022, ITEXTBOOKS AIED, P4; Ferrari A, 2020, REQUIR ENG, V25, P417, DOI 10.1007/s00766-020-00334-0; Gabajiwala E., 2022, FUTURISTIC TRENDS NE, P523, DOI DOI 10.1007/978-981-19-5037; Gorer B., 2023, Generating Requirements Elicitation Interview Scripts with Large Language Models-Supplementary Material, DOI [10.5281/zenodo.8049207, DOI 10.5281/ZENODO.8049207]; Jurafsky D., 2020, SPEECH LANGUAGE PROC; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim M., 2022, arXiv; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lu P, 2022, Arxiv, DOI arXiv:2209.14610; OpenAI, 2023, GPT 4 TECHNICAL REPO; Shum K, 2024, Arxiv, DOI arXiv:2302.12822; Vilela J, 2021, LECT NOTES COMPUT SC, V12685, P191, DOI 10.1007/978-3-030-73128-1_14; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zheng CJ, 2023, Arxiv, DOI arXiv:2202.13047; Zowghi D, 2005, ENGINEERING AND MANAGING SOFTWARE REQUIREMENTS, P19, DOI 10.1007/3-540-28244-0_2	21	1	1	5	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2770-6826		979-8-3503-2691-8	Intern Req Engg Work			2023							44	51		10.1109/REW57809.2023.00015	http://dx.doi.org/10.1109/REW57809.2023.00015			8	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV9BJ					2024-07-03	WOS:001085223300011
C	Harte, J; Zorgdrager, W; Louridas, P; Katsifodimos, A; Jannach, D; Fragkoulis, M			ACM	Harte, Jesse; Zorgdrager, Wouter; Louridas, Panos; Katsifodimos, Asterios; Jannach, Dietmar; Fragkoulis, Marios			Leveraging Large Language Models for Sequential Recommendation	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Recommender Systems; Large Language Models; Sequential Recommendation; Evaluation		Sequential recommendation problems have received increasing attention in research during the past few years, leading to the inception of a large variety of algorithmic approaches. In this work, we explore how large language models (LLMs), which are nowadays introducing disruptive effects in many AI-based applications, can be used to build or improve sequential recommendation approaches. Specifically, we devise and evaluate three approaches to leverage the power of LLMs in different ways. Our results from experiments on two datasets show that initializing the state-of-the-art sequential recommendation model BERT4Rec with embeddings obtained from an LLM improves NDCG by 15-20% compared to the vanilla BERT4Rec model. Furthermore, we find that a simple approach that leverages LLM embeddings for producing recommendations, can provide competitive performance by highlighting semantically related items. We publicly share the code and data of our experiments to ensure reproducibility.(1)	[Harte, Jesse; Zorgdrager, Wouter; Fragkoulis, Marios] Delivery Hero Res, Berlin, Germany; [Harte, Jesse; Katsifodimos, Asterios] Delft Univ Technol, Delft, Netherlands; [Louridas, Panos] Athens Univ Econ & Business, Athens, Greece; [Jannach, Dietmar] Univ Klagenfurt, Klagenfurt, Austria	Delft University of Technology; Athens University of Economics & Business; University of Klagenfurt	Harte, J (corresponding author), Delivery Hero Res, Berlin, Germany.; Harte, J (corresponding author), Delft Univ Technol, Delft, Netherlands.			Katsifodimos, Asterios/0000-0002-6717-2945				Anelli VW, 2022, PROCEEDINGS OF THE 30TH ACM CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION, UMAP 2022, P121, DOI 10.1145/3503252.3531292; Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Bergstra J., 2011, Adv. Neural Inf. Process. Syst., P2546; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding Hao, 2022, ICLR 2022 WORKSHOP D; Garcin Florent, 2013, RECSYS 2013 P 7 ACM, P105; Ge Mouzhi, 2010, RecSys'10-Proceedings of the 4th ACM Conference on Recommender Systems, January, P257, DOI [DOI 10.1145/1864708.1864761, 10.1145/1864708.1864761]; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037; Hou Y., 2023, P ACM WEB C 2023 WWW, P1162; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hou YP, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P585, DOI 10.1145/3534678.3539381; Jannach D, 2020, USER MODEL USER-ADAP, V30, P609, DOI 10.1007/s11257-020-09274-4; Jannach D, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P306, DOI 10.1145/3109859.3109872; Jannach D, 2015, USER MODEL USER-ADAP, V25, P427, DOI 10.1007/s11257-015-9165-3; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Lai SQ, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1674, DOI 10.1145/3477495.3531935; Latifi S, 2022, INFORM SCIENCES, V609, P660, DOI 10.1016/j.ins.2022.07.079; Li Jiacheng, 2023, KDD 23 29 ACM SIGKDD; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Lin JH, 2024, Arxiv, DOI arXiv:2306.05817; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Liu YD, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3365, DOI 10.1145/3447548.3467149; Ludewig M, 2018, USER MODEL USER-ADAP, V28, P331, DOI 10.1007/s11257-018-9209-6; Moreira GDP, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P143, DOI 10.1145/3460231.3474255; Quadrana M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190616; Radford A., 2018, IMPROVING LANGUAGE U; Resnick P., 1994, P 1994 ACM C COMPUTE, DOI [DOI 10.1145/192844.192905, 10.1145/192844.192905]; Shani G, 2005, J MACH LEARN RES, V6, P1265; Sontag D, 2023, INT C ARTIFICIAL INT, P5549; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Tikk D., 2016, C TRACK P; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang Shoujin, 2021, ACM Comput. Surv., V54, P7; Wu CH, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1652, DOI 10.1145/3404835.3463069; Wu LK, 2024, Arxiv, DOI arXiv:2305.19860; Xu H, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109246; Yuan Zheng, 2023, SIGIR; Zhang Q., 2021, P 30 INT JOINT C ART, P3356; Zhang Yuhui, 2021, NEURIPS 2021 WORKSHO; Zhou T, 2010, P NATL ACAD SCI USA, V107, P4511, DOI 10.1073/pnas.1000488107	45	0	0	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1096	1102		10.1145/3604915.3610639	http://dx.doi.org/10.1145/3604915.3610639			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Green Submitted, Green Published			2024-07-03	WOS:001156630300135
J	Chakraborty, C; Bhattacharya, M; Lee, SS				Chakraborty, Chiranjib; Bhattacharya, Manojit; Lee, Sang-Soo			Need an AI-Enabled, Next-Generation, Advanced ChatGPT or Large Language Models (LLMs) for Error-Free and Accurate Medical Information	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter						AI; ChatGPT; Large language models; Medical information		Recently, the interest in AI-guided ChatGPT has increased day-to-day, and different applications have been explored, including the medical field. The publication number is also increasing. At the same time, people are trying to get medical information from this Chartbot. However, researchers found that ChatGPT also provides partly correct or false information. Therefore, in this article, we urge the researchers to develop an AI-enabled, next-generation, advanced ChatGPT or large language models (LLMs) so that people can get accurate and error-free medical information.	[Chakraborty, Chiranjib] Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, W Bengal, India; [Bhattacharya, Manojit] Fakir Mohan Univ, Dept Zool, Balasore 756020, Orissa, India; [Lee, Sang-Soo] Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chuncheon Si 24252, Gangwon Do, South Korea	Fakir Mohan University; Hallym University	Chakraborty, C (corresponding author), Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, W Bengal, India.	drchiranjib@yahoo.com	Bhattacharya, Manojit/A-2027-2012; Chakraborty, Chiranjib/J-4847-2013	Bhattacharya, Manojit/0000-0001-9669-1835; Chakraborty, Chiranjib/0000-0002-3958-239X				AlMuammar Sarah A, 2021, Cureus, V13, pe18338, DOI 10.7759/cureus.18338; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Hochberg I, 2020, J MED INTERNET RES, V22, DOI 10.2196/15065; Kuehn BM, 2013, JAMA-J AM MED ASSOC, V309, P756, DOI 10.1001/jama.2013.629; Lu YQ, 2023, ANN BIOMED ENG, V51, P1898, DOI 10.1007/s10439-023-03234-w; Morath B, 2023, EUR J HOSP PHARM, DOI 10.1136/ejhpharm-2023-003750; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	8	6	6	19	49	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	FEB	2024	52	2					134	135		10.1007/s10439-023-03297-9	http://dx.doi.org/10.1007/s10439-023-03297-9		JUN 2023	2	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	FS1M2	37368124				2024-07-03	WOS:001021001200001
J	Macmillan-Scott, O; Musolesi, M				Macmillan-Scott, Olivia; Musolesi, Mirco			(Ir)rationality and cognitive biases in large language models	ROYAL SOCIETY OPEN SCIENCE			English	Article						large language models; rationality; cognitive bias	PROBABILITY; JUDGMENT	Do large language models (LLMs) display rational reasoning? LLMs have been shown to contain human biases due to the data they have been trained on; whether this is reflected in rational reasoning remains less clear. In this paper, we answer this question by evaluating seven language models using tasks from the cognitive psychology literature. We find that, like humans, LLMs display irrationality in these tasks. However, the way this irrationality is displayed does not reflect that shown by humans. When incorrect answers are given by LLMs to these tasks, they are often incorrect in ways that differ from human-like biases. On top of this, the LLMs reveal an additional layer of irrationality in the significant inconsistency of the responses. Aside from the experimental results, this paper seeks to make a methodological contribution by showing how we can assess and compare different capabilities of these types of models, in this case with respect to rational reasoning.	[Macmillan-Scott, Olivia; Musolesi, Mirco] UCL, Dept Comp Sci, London, England; [Musolesi, Mirco] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy	University of London; University College London; University of Bologna	Macmillan-Scott, O (corresponding author), UCL, Dept Comp Sci, London, England.	olivia.macmillan-scott.16@ucl.ac.uk			Leverhulme Trust	Leverhulme Trust(Leverhulme Trust)	No Statement Available	Acerbi A, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2313790120; [Anonymous], 1993, Rationality: Psychological and philosophical perspectives; Anthropic, 2023, Technical report Anthropic; Binz M, 2023, Arxiv, DOI arXiv:2306.03917; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bruckmaier G, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.584689; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chang TA., 2024, Comput. Linguist, V50, P1; Chen YT, 2023, Arxiv, DOI arXiv:2305.12763; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Durt C., 2023, PREPRINT; Eddy D. M., 1982, Judgment under Uncertainty: Heuristics and Biases, P249, DOI DOI 10.1017/CBO9780511809477.019; Firestone C, 2020, P NATL ACAD SCI USA, V117, P26562, DOI 10.1073/pnas.1905334117; Freund L., 2023, PREPRINT; Friedman D, 1998, AM ECON REV, V88, P933; Gigerenzer G, 1996, PSYCHOL REV, V103, P650, DOI 10.1037/0033-295X.103.4.650; Gulati A, 2023, Arxiv, DOI arXiv:2210.01122; Hagendorff T, 2023, NAT COMPUT SCI, V3, P833, DOI 10.1038/s43588-023-00527-x; Han SJ, 2024, COGN SYST RES, V83, DOI 10.1016/j.cogsys.2023.101155; Harding J, 2023, AI SOC, DOI 10.1007/s00146-023-01725-x; Holterman B, 2023, Arxiv, DOI [arXiv:2305.14020, 10.48550/arXiv.2305.14020, DOI 10.48550/ARXIV.2305.14020]; Itzhak I, 2024, Arxiv, DOI arXiv:2308.00225; KAHNEMAN D, 1982, SCI AM, V246, P160, DOI 10.1038/scientificamerican0182-160; KAHNEMAN D, 1972, COGNITIVE PSYCHOL, V3, P430, DOI 10.1016/0010-0285(72)90016-3; Lampinen AK, 2022, Arxiv, DOI [arXiv:2210.15303, DOI 10.48550/ARXIV.2210.15303]; Lampinen Andrew, 2022, FINDINGS ASS COMPUTA, P537, DOI 10.18653/v1/2022.findings-emnlp.38; Lampinen AK, 2023, Arxiv, DOI [arXiv:2207.07051, 10.48550/arXiv.2207.07051]; Lamprinidis S, 2023, Arxiv, DOI arXiv:2307.11787; Macmillan-Scott O., 2024, rationality and cognitive biases in large language models (Dataset); Macmillan-Scott O., 2024, Ir)rationality and cognitive biases in large language models, DOI [10.6084/m9.figshare.c.7214480, DOI 10.6084/M9.FIGSHARE.C.7214480]; Macmillan-Scott O, 2024, Arxiv, DOI arXiv:2311.17165; Moore A., 2023, Foreign Policy; OpenAI, 2023, GPT-4 Technical Report; Park J.S., 2023, P 36 ANN ACM S US IN, P1; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Rivera JP, 2024, Arxiv, DOI arXiv:2401.03408; Roettger P, 2024, Arxiv, DOI arXiv:2308.01263; Ruis L., 2023, P 37 C NEUR INF PROC; Russell S, 2016, SYNTH LIBR, V376, P7, DOI 10.1007/978-3-319-26485-1_2; Salewski L, 2023, Arxiv, DOI arXiv:2305.14930; Santurkar S, 2023, Arxiv, DOI arXiv:2303.17548; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Stein E., 1996, Without good reason: the rationality debate in philosophy and cognitive science; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; TVERSKY A, 1983, PSYCHOL REV, V90, P293, DOI 10.1037/0033-295X.90.4.293; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; Wason P., 1966, New horizons in psychology, P135; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w	52	0	0	2	2	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	2054-5703			ROY SOC OPEN SCI	R. Soc. Open Sci.	JUN 5	2024	11	6							240255	10.1098/rsos.240255	http://dx.doi.org/10.1098/rsos.240255			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UD7X1		Green Published, gold, Green Submitted			2024-07-03	WOS:001246200200002
J	Fernandes, LC				Fernandes, Leandro Carisio			Programming Computational Electromagnetic Applications Assisted by Large Language Models	IEEE ANTENNAS AND PROPAGATION MAGAZINE			English	Editorial Material						Codes; Software; Libraries; Task analysis; Antenna radiation patterns; Python; Matlab		This article discusses the possibilities and limitations of using large language models (LLMs) in software development with applications in computational electromagnetics (EM). Three tasks are discussed: code translation, code generation, and code description. The tests showed that LLMs are generally very useful. Even when errors occurred, they could provide useful hints to find a solution.	[Fernandes, Leandro Carisio] Fed Court Accounts, BR-70042900 Brasilia, Brazil		Fernandes, LC (corresponding author), Fed Court Accounts, BR-70042900 Brasilia, Brazil.	carisio@gmail.com		Carisio Fernandes, Leandro/0000-0002-4114-2334					0	0	0	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1045-9243	1558-4143		IEEE ANTENN PROPAG M	IEEE Antennas Propag. Mag.	FEB	2024	66	1					63	71		10.1109/MAP.2023.3336708	http://dx.doi.org/10.1109/MAP.2023.3336708			9	Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Telecommunications	JN4F1					2024-07-03	WOS:001173827400006
J	Majeed, A; Hwang, SO				Majeed, Abdul; Hwang, Seong Oun			Making Large Language Models More Reliable and Beneficial: Taking ChatGPT as a Case Study	COMPUTER			English	Article						Large language models; Reliability engineering; Chatbots; Artificial intelligence; Human factors; Open systems; Deep learning; Context awareness; Question answering (information retrieval); Market research; Technology forecasting; Modeling; Stakeholders		This article suggests practical ways to make large language models more reliable and beneficial by taking ChatGPT as a case study. Specifically, we describe ChatGPT's workflow and promised services and highlight the perils requiring the immediate attention of ChatGPT stakeholders.	[Majeed, Abdul; Hwang, Seong Oun] Gachon Univ, Dept Comp Engn, Seongnam 13120, South Korea	Gachon University	Majeed, A (corresponding author), Gachon Univ, Dept Comp Engn, Seongnam 13120, South Korea.	ab09@gachon.ac.kr; sohwang@gachon.ac.kr	Majeed, Abdul/W-7578-2019; Majeed, Abdul/JHT-0587-2023	Majeed, Abdul/0000-0002-3030-5054; 	National Research Foundation of Korea	National Research Foundation of Korea(National Research Foundation of Korea)	No Statement Available	[Anonymous], 2023, EU AI ACT 1 REGULATI; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Conroy G, 2023, NATURE, V619, P443, DOI 10.1038/d41586-023-02218-z; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Grudin J, 2023, COMPUTER, V56, P94, DOI 10.1109/MC.2023.3255279; Kshetri N, 2023, IT PROF, V25, P9, DOI 10.1109/MITP.2023.3275489; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; McGee RW, 2023, A ChatGPT Short Story; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w	9	0	0	26	26	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	MAR	2024	57	3					101	106		10.1109/MC.2023.3327028	http://dx.doi.org/10.1109/MC.2023.3327028			6	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LD1I2		Bronze			2024-07-03	WOS:001184746200002
J	Thirunavukarasu, AJ; Ting, DSJ; Elangovan, K; Gutierrez, L; Tan, TF; Ting, DSW				Thirunavukarasu, Arun James; Ting, Darren Shu Jeng; Elangovan, Kabilan; Gutierrez, Laura; Tan, Ting Fang; Ting, Daniel Shu Wei			Large language models in medicine	NATURE MEDICINE			English	Review							CHATGPT	This review explains how large language models (LLMs), such as ChatGPT, are developed and discusses their strengths and limitations in the context of potential clinical applications. Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if and how LLM technology is used in healthcare for the benefit of patients and practitioners.	[Thirunavukarasu, Arun James] Univ Cambridge, Sch Clin Med, Cambridge, England; [Thirunavukarasu, Arun James] Univ Cambridge, Corpus Christi Coll, Cambridge, England; [Ting, Darren Shu Jeng] Univ Birmingham, Inst Inflammat & Ageing, Acad Unit Ophthalmol, Birmingham, England; [Ting, Darren Shu Jeng] Birmingham & Midland Eye Ctr, Birmingham, England; [Ting, Darren Shu Jeng] Univ Nottingham, Sch Med, Acad Ophthalmol, Nottingham, England; [Elangovan, Kabilan; Gutierrez, Laura; Tan, Ting Fang; Ting, Daniel Shu Wei] Singapore Eye Res Inst, Singapore Natl Eye Ctr, Artificial Intelligence & Digital Innovat Res Grp, Singapore, Singapore; [Tan, Ting Fang; Ting, Daniel Shu Wei] Duke Natl Univ Singapore, Dept Ophthalmol & Visual Sci, Med Sch, Singapore, Singapore; [Ting, Daniel Shu Wei] Stanford Univ, Byers Eye Inst, Palo Alto, CA 94303 USA	University of Cambridge; University of Cambridge; University of Birmingham; University of Nottingham; Singapore National Eye Center; National University of Singapore; National University of Singapore; Stanford University	Ting, DSW (corresponding author), Singapore Eye Res Inst, Singapore Natl Eye Ctr, Artificial Intelligence & Digital Innovat Res Grp, Singapore, Singapore.; Ting, DSW (corresponding author), Duke Natl Univ Singapore, Dept Ophthalmol & Visual Sci, Med Sch, Singapore, Singapore.; Ting, DSW (corresponding author), Stanford Univ, Byers Eye Inst, Palo Alto, CA 94303 USA.	daniel.ting@duke-nus.edu.sg	; Thirunavukarasu, Arun/ABC-0806-2022	Gutierrez-Sinisterra, Laura/0000-0001-7416-2350; Elangovan, Kabilan/0000-0002-7711-7368; Thirunavukarasu, Arun/0000-0001-8968-4768	National Medical Research Council, Singapore [NMCR/HSRG/0087/2018, MOH-000655-00, MOH-001014-00]; Duke-NUS Medical School [Duke-NUS/RSF/2021/0018, 05/FY2020/EX/15-A58]; Agency for Science, Technology and Research [A20H4g2141, H20C6a0032]	National Medical Research Council, Singapore(National Medical Research Council, SingaporeUK Research & Innovation (UKRI)Medical Research Council UK (MRC)); Duke-NUS Medical School; Agency for Science, Technology and Research(Agency for Science Technology & Research (A*STAR))	D.S.W.T. is supported by the National Medical Research Council, Singapore (NMCR/HSRG/0087/2018, MOH-000655-00 and MOH-001014-00), the Duke-NUS Medical School (Duke-NUS/RSF/2021/0018 and 05/FY2020/EX/15-A58) and the Agency for Science, Technology and Research (A20H4g2141 and H20C6a0032). These funders were not involved in the conception, execution or reporting of this review.	Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Aggarwal A, 2023, J MED INTERNET RES, V25, DOI 10.2196/40789; Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; Agrawal M., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2205.12689; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amatriain X., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2302.07730; Anil R., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.10403; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, CONFIRMED NEW BING R; [Anonymous], Total data volume worldwide 2010-2025 | Statista; [Anonymous], 2023, OUR LATEST HLTH AI R; [Anonymous], 2023, PAUSE GIANT AI EXPT; [Anonymous], NEW AI CLASSIFIER IN; ARK Investment Management LLC, 2023, BIG IDEAS; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Authorship and contributorship, CAMBRIDGE CORE; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Babbage C., 1864, Passages From the Life of a Philosopher; Ball P, 2021, NATURE, V589, P16, DOI 10.1038/d41586-020-03626-1; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bender E. M., 2018, Trans. Assoc. Comput. Linguistics, V6, P587, DOI DOI 10.1162/TACL_A_00041; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benoit J. R. A., 2023, CHATGPT CLIN VIGNETT, DOI [10.1101/2023.02.04.23285478, DOI 10.1101/2023.02.04.23285478]; Bommasani R., 2022, OPPORTUNITIES RISKS, DOI DOI 10.48550/ARXIV.2108.07258; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Dai D., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2204.05149; Dennean K., 2023, LETS CHAT CHATGPT; Duolingo Team, 2023, INTR DUOL MAX LEARN; El Zini J, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3529755; Elali FR, 2023, PATTERNS, V4, P1, DOI 10.1016/j.patter.2023.100706; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Friedberg Mark W, 2014, Rand Health Q, V3, P1; Ghahramani Z., 2023, INTRO PALM 2; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Glaese A., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2209.14375; Hallin J, 2022, NAT MED, V28, P2171, DOI 10.1038/s41591-022-02007-7; Han Z., 2023, MEDRXIV, DOI [10.1101/2023.02.13.23285879, DOI 10.1101/2023.02.13.23285879]; Huang J., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2211.09527; Huang K., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.1904.05342; HuggingChat, US; Ioannidis JPA, 2005, PLOS MED, V2, P696, DOI 10.1371/journal.pmed.0020124; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kaplan J., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2001.08361; Khan S., 2023, HARNESSING GPT 4 ALL; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kirchenbauer J., 2023, PREPRINT; Kraljevic Z., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2212.08072; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kwee A, 2022, LANCET REG HEALTH-W, V23, DOI 10.1016/j.lanwpc.2022.100476; Lacoste A., 2019, ARXIV, DOI DOI 10.48550/ARXIV.1910.09700; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lehman E., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2302.08091; Levine David M, 2023, medRxiv, DOI 10.1101/2023.01.30.23285067; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li XQ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P416, DOI 10.1109/ICCCBDA.2017.7951949; Liddy E., 2001, ENCY LIB INFORM SCI; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Littmann M, 2020, NAT MACH INTELL, V2, P18, DOI 10.1038/s42256-019-0139-8; Looi MK, 2023, BMJ-BRIT MED J, V380, DOI 10.1136/bmj.p205; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mai DHA, 2022, FRONT GENET, V13, DOI 10.3389/fgene.2022.1067562; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nastasi A. J., 2023, PREPRINT, DOI [10.1101/2023.02.25.23286451, DOI 10.1101/2023.02.25.23286451]; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; Nov O., 2023, PREPRINT, DOI DOI 10.1101/2023.01.23.23284735; openai, INTRO CHATGPT; OpenAI, 2023, GPT 4 SYST CARD; OpenAI, MOD IND RES; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patel S, 2023, LANCET DIGIT HEALTH, V5, pE102, DOI 10.1016/S2589-7500(23)00023-7; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714; Perez F., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2211.09527; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Radford A., 2018, IMPROVING LANGUAGE U; Rajpurkar P, 2022, NAT MED, V28, P31, DOI 10.1038/s41591-021-01614-0; Ramesh Aditya, 2022, arXiv preprint arXiv:2204.06125, V1, P3, DOI DOI 10.48550/ARXIV.2204.06125; Rao Arya, 2023, medRxiv, DOI 10.1101/2023.02.21.23285886; Salganik M., 2023, FREEDOM TO TINKER; Sample I., 2023, GUARDIAN; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Shao Yijun, 2023, medRxiv, DOI 10.1101/2023.03.09.23287046; Shoeybi M., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.1909.08053; Shuster K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2208.03188; Shuster K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2203.13224; Singhal K., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.09617; Singhal K., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.13138; Spataro J., 2023, INTRO MICROSOFT 365; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Strubell E., 2019, 57 ANN M ASS COMP LI, DOI [10.48550/arXiv.1906.02243, DOI 10.48550/ARXIV.1906.02243]; Taori R., 2023, PREPRINT; Taylor J., 2023, GUARDIAN; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Thoppilan R., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2201.08239; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Vasey B, 2022, BMJ-BRIT MED J, V377, DOI [10.1136/bmj-2022-070904, 10.1038/s41591-022-01772-9]; Villalobos P., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2211.04325; Wang X., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2203.11171; Weiner SJ, 2020, J AM MED INFORM ASSN, V27, P770, DOI 10.1093/jamia/ocaa027; Wolford B., 2018, What Is GDPR, the EUs New Data Protection Law?; Yan C, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35295-1; Yang X., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2203.03540; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185776; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zeng A., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2210.02414; Zhavoronkov A, 2023, NAT MED, V29, P532, DOI 10.1038/d41591-023-00014-w	118	254	259	351	500	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1078-8956	1546-170X		NAT MED	Nat. Med.	AUG	2023	29	8					1930	1940		10.1038/s41591-023-02448-8	http://dx.doi.org/10.1038/s41591-023-02448-8		JUL 2023	11	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	P2ZO9	37460753				2024-07-03	WOS:001032505800003
J	Leas, EC; Ayers, JW; Desai, N; Dredze, M; Hogarth, M; Smith, DM				Leas, Eric C.; Ayers, John W.; Desai, Nimit; Dredze, Mark; Hogarth, Michael; Smith, Davey M.			Using Large Language Models to Support Content Analysis: A Case Study of ChatGPT for Adverse Event Detection	JOURNAL OF MEDICAL INTERNET RESEARCH			English	Article						adverse events; artificial intelligence; AI; text analysis; annotation; ChatGPT; LLM; large language model; cannabis; delta-8-THC; delta-8-tetrahydrocannabiol		This study explores the potential of using large language models to assist content analysis by conducting a case study to identify adverse events (AEs) in social media posts. The case study compares ChatGPT's performance with human annotators' in detecting AEs associated with delta-8-tetrahydrocannabinol, a cannabis -derived product. Using the identical instructions given to human annotators, ChatGPT closely approximated human results, with a high degree of agreement noted: 94.4% (9436/10,000) for any AE detection (Fleiss kappa=0.95) and 99.3% (9931/10,000) for serious AEs ( kappa=0.96). These findings suggest that ChatGPT has the potential to replicate human annotation accurately and efficiently. The study recognizes possible limitations, including concerns about the generalizability due to ChatGPT's training data, and prompts further research with different models, data sources, and content analysis tasks. The study highlights the promise of large language models for enhancing the efficiency of biomedical research.	[Leas, Eric C.] Univ Calif San Diego, Herbert Wertheim Sch Publ Hlth & Human Longev Sci, 9500 Gilman Dr,Mail Code 0725, La Jolla, CA 92093 USA; [Leas, Eric C.; Ayers, John W.; Desai, Nimit] Univ Calif San Diego, Qualcomm Inst, La Jolla, CA USA; [Ayers, John W.; Smith, Davey M.] Univ Calif San Diego, Dept Med, Div Infect Dis & Global Publ Hlth, La Jolla, CA USA; [Ayers, John W.; Hogarth, Michael; Smith, Davey M.] Univ Calif San Diego, Altman Clin Translat Res Inst, La Jolla, CA USA; [Dredze, Mark] Johns Hopkins Univ, Dept Comp Sci, Baltimore, MD USA; [Hogarth, Michael] Univ Calif San Diego, Dept Biomed Informat, La Jolla, CA USA	University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego; University of California System; University of California San Diego; Johns Hopkins University; University of California System; University of California San Diego	Leas, EC (corresponding author), Univ Calif San Diego, Herbert Wertheim Sch Publ Hlth & Human Longev Sci, 9500 Gilman Dr,Mail Code 0725, La Jolla, CA 92093 USA.	ecleas@ucsd.edu		Leas, Eric/0000-0001-9221-0336; Dredze, Mark/0000-0002-0422-2474; Hogarth, Michael/0000-0002-4264-1258	National Institute on Drug Abuse [K01DA054303]; Burroughs Wellcome Fund;  [UL1TR001442]	National Institute on Drug Abuse(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Drug Abuse (NIDA)); Burroughs Wellcome Fund(Burroughs Wellcome Fund); 	Acknowledgments This work was funded by grant K01DA054303 from the National Institute on Drug Abuse, the Burroughs Wellcome Fund, and the National Institutes of Health (UL1TR001442) . The study sponsors took no part in the study design; collection, analysis, and interpretation of data; the writing of the manuscript; or the decision to submit the manuscript for publication.	[Anonymous], OpenAI API and other LLM APIs response time tracker; BYRT T, 1993, J CLIN EPIDEMIOL, V46, P423, DOI 10.1016/0895-4356(93)90018-V; ChatGPT, OpenAI; Leas E., Publication data; Leas EC, 2023, J CANNABIS RES, V5, DOI 10.1186/s42238-023-00191-y; Lee P., 2023, The AI Revolution in Medicine: GPT-4 and Beyond; MedWatch, 2022, The FDA Safety InformationAdverse Event Reporting Program; Melton CB, 2005, J AM MED INFORM ASSN, V12, P448, DOI 10.1197/jamia.M1794; Pierce CE, 2017, DRUG SAFETY, V40, P317, DOI 10.1007/s40264-016-0491-0; Sarker A, 2015, J BIOMED INFORM, V54, P202, DOI 10.1016/j.jbi.2015.02.004	10	0	0	6	6	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	1438-8871			J MED INTERNET RES	J. Med. Internet Res.	MAY 2	2024	26								e52499	10.2196/52499	http://dx.doi.org/10.2196/52499			5	Health Care Sciences & Services; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Health Care Sciences & Services; Medical Informatics	RG7T2	38696245	gold, Green Accepted			2024-07-03	WOS:001226586000001
J	Seth, I; Xie, Y; Rodwell, A; Gracias, D; Bulloch, G; Hunter-Smith, DJ; Rozen, WM				Seth, Ishith; Xie, Yi; Rodwell, Aaron; Gracias, Dylan; Bulloch, Gabriella; Hunter-Smith, David J.; Rozen, Warren M.			Exploring the Role of a Large Language Model on Carpal Tunnel Syndrome Management: An Observation Study of ChatGPT	JOURNAL OF HAND SURGERY-AMERICAN VOLUME			English	Article						Artificial intelligence; carpal tunnel syndrome; chatbot; ChatGPT; CTS	PREVALENCE	Purpose Recently, large language models, such as ChatGPT, have emerged as promising tools to facilitate scientific research and health care management. The present study aimed to explore the extent of knowledge possessed by ChatGPT concerning carpal tunnel syndrome (CTS), a compressive neuropathy that may lead to impaired hand function and that is frequently encountered in the field of hand surgery.Methods Six questions pertaining to diagnosis and management of CTS were posed to ChatGPT. The responses were subsequently analyzed and evaluated based on their accuracy, coherence, and comprehensiveness. In addition, ChatGPT was requested to provide five high-level evidence references in support of its answers. A simulated doctor-patient consultation was also conducted to assess whether ChatGPT could offer safe medical advice.Results ChatGPT supplied clinically relevant information regarding CTS, although at a rela-tively superficial level. In the context of doctor-patient interaction, ChatGPT suggested a diagnostic pathway that deviated from the widely accepted clinical consensus on CTS diagnosis. Nevertheless, it incorporated differential diagnoses and valuable management options for CTS. Although ChatGPT demonstrated the ability to retain and recall information from previous patient conversations, it infrequently produced pertinent references, many of which were either nonexistent or incorrect. Conclusions ChatGPT displayed the capability to deliver validated medical information on CTS to nonmedical individuals. However, the generation of nonexistent and inaccurate references by ChatGPT presents a challenge to academic integrity.Clinical relevance To increase their utility in medicine and academia, large language models must go through specialized reputable data set training and validation from experts. It is essential to note that at present, large language models cannot replace the expertise of health care professionals and may act as a supportive tool.(c) 2023 by the American Society for Surgery of the Hand. All rights reserved.)	[Seth, Ishith; Rozen, Warren M.] Monash Univ, Fac Med, Melbourne, Vic, Australia; [Seth, Ishith; Xie, Yi; Rozen, Warren M.] Peninsula Hlth, Dept Plast Surg, Melbourne, Vic, Australia; [Rodwell, Aaron] Wollongong Hosp, Dept Surg, Wollongong, NSW, Australia; [Gracias, Dylan] Townsville Hosp, Dept Surg, Townsville, Qld, Australia; [Seth, Ishith; Bulloch, Gabriella] Univ Melbourne, Fac Med, Melbourne, Vic, Australia; [Seth, Ishith] Peninsula Hlth, Dept Plast Surg, 2 Hastings Rd, Melbourne, Vic 3199, Australia	Monash University; Peninsula Health; Wollongong Hospital; Queensland Health; Townsville Hospital; University of Melbourne; Peninsula Health	Seth, I (corresponding author), Peninsula Hlth, Dept Plast Surg, 2 Hastings Rd, Melbourne, Vic 3199, Australia.	ishithseth1@gmail.com	Rozen, Warren Matthew/AAE-6296-2022; Seth, Ishith/IXX-0725-2023	Rozen, Warren Matthew/0000-0002-4092-182X; Seth, Ishith/0000-0001-5444-8925; Rodwell, Aaron/0000-0002-2894-210X				American Academy of Orthopaedic Surgeons, Management of carpal tunnel syndrome evidence-based clinical practice guideline; Atroshi I, 1999, JAMA-J AM MED ASSOC, V282, P153, DOI 10.1001/jama.282.2.153; DEKROM MCTFM, 1992, J CLIN EPIDEMIOL, V45, P373, DOI 10.1016/0895-4356(92)90038-O; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Karthik K, 2012, J HAND MICROSURG, V4, P1, DOI 10.1007/s12593-011-0051-x; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Piazzini D, 2007, CLIN REHABIL, V21, P299, DOI 10.1177/0269215507077294; Seth I, 2023, J Clin Cases Rep., V13, P6, DOI [10.46619/joccr.2023.6-S13.1075, DOI 10.46619/JOCCR.2023.6-S13.1075]; Tu RB, 2023, Arxiv, DOI [arXiv:2301.13819, 10.48550/arXiv.2301.13819]; Yeo YH, 2023, medRxiv, DOI [10.1101/2023.02.06.23285449, 10.1101/2023.02.06.23285449, DOI 10.1101/2023.02.06.23285449]	12	12	12	8	14	W B SAUNDERS CO-ELSEVIER INC	PHILADELPHIA	1600 JOHN F KENNEDY BOULEVARD, STE 1800, PHILADELPHIA, PA 19103-2899 USA	0363-5023	1531-6564		J HAND SURG-AM	J. Hand Surg.-Am. Vol.	OCT	2023	48	10					1025	1033		10.1016/j.jhsa.2023.07.003	http://dx.doi.org/10.1016/j.jhsa.2023.07.003		OCT 2023	9	Orthopedics; Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Surgery	U8AB2	37530687				2024-07-03	WOS:001086963800001
C	Qi, JZ; Li, ZQ; Tanin, E		Damiani, ML; Renz, M; Eldawy, A; Kroger, P; Nascimento, MA		Qi, Jianzhong; Li, Zuqing; Tanin, Egemen			MaaSDB: Spatial Databases in the Era of Large Language Models	31ST ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, ACM SIGSPATIAL GIS 2023			English	Proceedings Paper	31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS)	NOV 13-16, 2023	Hamburg, GERMANY	ACM SIGSPATIAL, Apple, Oracle, Esri		Spatial Databases; Large Language Models; Model as a Database		Large language models (LLMs) are advancing rapidly. Such models have demonstrated strong capabilities in learning from large-scale (unstructured) text data and answering user queries. Users do not need to be experts in structured query languages to interact with systems built upon such models. This provides great opportunities to reduce the barrier of information retrieval for the general public. By introducing LLMs into spatial data management, we envisage an LLM-based spatial database system to learn from both structured and unstructured spatial data. Such a system will offer seamless access to spatial knowledge for the users, thus benefiting individuals, business, and government policy makers alike.	[Qi, Jianzhong; Li, Zuqing; Tanin, Egemen] Univ Melbourne, Melbourne, Vic, Australia	University of Melbourne	Qi, JZ (corresponding author), Univ Melbourne, Melbourne, Vic, Australia.	jianzhong.qi@unimelb.edu.au; zuqingl@student.unimelb.edu.au; etanin@unimelb.edu.au	QI, JIANZHONG/P-7112-2015	QI, JIANZHONG/0000-0001-6501-9050	Australian Research Council (ARC) [DP230101534]	Australian Research Council (ARC)(Australian Research Council)	This work is partially supported by Australian Research Council (ARC) Discovery Project DP230101534.	Belussi Alberto, 2022, SIGSPATIAL; Chang Yanchuan, 2023, EDBT; Dziri Nouha, 2023, NEURIPS; Gu Tu, 2023, P ACM MANAGEMENT DAT; Katsogiannis-Meimarakis G, 2023, VLDB J, V32, P905, DOI 10.1007/s00778-022-00776-8; Li Guoliang, 2021, SIGMOD; Manning Christopher D., 2022, DAEDALUS; Moerkotte Guido, 2009, PVLDB; Musleh M., 2022, SIGSPATIAL; Nobari Arash Dargahi, 2023, ARXIV230306748; Pagel Bernd-Uwe, 1993, PODS; Park Noseong, 2018, PVLDB; Qi J., 2020, EDBT; Qi Jianzhong, 2020, PVLDB; Saeed Mohammed, 2023, ARXIV230400472; Tan Wang-Chiew, 2023, ARXIV230413010; Thorne James, 2021, PVLDB; Trappolini Giovanni, 2023, ARXIV230501447; Urban Matthias, 2023, ARXIV230413559; Wang Yanqiu, 2014, INFORM SYSTEMS; Ward Phillip G. D., 2014, VLDB J; Xue H., 2022, SIGSPATIAL; Xue Hao, 2022, WSDM; Yang Peilun, 2021, ICDE; Zeighami Sepanta, 2022, PVLDB; Zhang R, 2014, ACM T DATABASE SYST, V39, DOI 10.1145/2629333	26	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0168-9				2023							292	295		10.1145/3589132.3625597	http://dx.doi.org/10.1145/3589132.3625597			4	Computer Science, Information Systems; Remote Sensing	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Remote Sensing	BW4XN		Bronze, Green Submitted			2024-07-03	WOS:001156830400054
C	Jiang, KY; Mujtaba, MM; Bernard, GR		Hagglund, M; Pelayo, S; Moen, A; Blusi, M; Bonacina, S; Nilsson, L; Madsen, IC; Benis, A; Lindskold, L; Gallos, P		Jiang, Keyuan; Mujtaba, Mohammed M.; Bernard, Gordon R.			Large Language Model as Unsupervised Health Information Retriever	CARING IS SHARING-EXPLOITING THE VALUE IN DATA FOR HEALTH AND INNOVATION-PROCEEDINGS OF MIE 2023	Studies in Health Technology and Informatics		English	Proceedings Paper	33rd Medical Informatics Europe Conference (MIE) - Caring is Sharing - Exploiting the Value in Data for Health and Innovation	MAY 22-25, 2023	European Federat Med Informat, Gothenburg, SWEDEN	Swedish Med Informat Assoc	European Federat Med Informat	Large language model; unsupervised learning; zero-shot learning; health information retrieval; COVID-19 symptoms; Twitter		Retrieving health information is a task of search for health-related information from a variety of sources. Gathering self-reported health information may help enrich the knowledge body of the disease and its symptoms. We investigated retrieving symptom mentions in COVID-19-related Twitter posts with a pretrained large language model (GPT-3) without providing any examples (zero-shot learning). We introduced a new performance measure of total match (TM) to include exact, partial and semantic matches. Our results show that the zero-shot approach is a powerful method without the need to annotate any data, and it can assist in generating instances for few-shot learning which may achieve better performance.	[Jiang, Keyuan; Mujtaba, Mohammed M.] Purdue Univ Northwest, Hammond, IN USA; [Bernard, Gordon R.] Vanderbilt Univ, Nashville, TN USA	Vanderbilt University	Jiang, KY (corresponding author), Purdue Univ Northwest, 2200 169th St, Hammond, IN 46323 USA.	kjiang@pnw.edu	liu, jianyang/JXL-6273-2024; Yuan, Yu/KBQ-0606-2024; li, jiaxin/JNT-5073-2023; Zhu, Li/JTT-9093-2023; li, yansong/JXL-5023-2024					Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250	3	1	1	10	16	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0926-9630	1879-8365	978-1-64368-389-8	STUD HEALTH TECHNOL			2023	302						833	834		10.3233/SHTI230282	http://dx.doi.org/10.3233/SHTI230282			2	Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Public, Environmental & Occupational Health; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Health Care Sciences & Services; Public, Environmental & Occupational Health; Medical Informatics	BV7SI	37203511	hybrid			2024-07-03	WOS:001071432900220
J	Bridgelall, R				Bridgelall, Raj			Unraveling the mysteries of AI chatbots	ARTIFICIAL INTELLIGENCE REVIEW			English	Article						Generative artificial intelligence; Large language models; ChatGPT; Bard; Transformer architecture; Prompt engineering		This primer provides an overview of the rapidly evolving field of generative artificial intelligence, specifically focusing on large language models like ChatGPT (OpenAI) and Bard (Google). Large language models have demonstrated unprecedented capabilities in responding to natural language prompts. The aim of this primer is to demystify the underlying theory and architecture of large language models, providing intuitive explanations for a broader audience. Learners seeking to gain insight into the technical underpinnings of large language models must sift through rapidly growing and fragmented literature on the topic. This primer brings all the main concepts into a single digestible document. Topics covered include text tokenization, vocabulary construction, token embedding, context embedding with attention mechanisms, artificial neural networks, and objective functions in model training. The primer also explores state-of-the-art methods in training large language models to generalize on specific applications and to align with human intentions. Finally, an introduction to the concept of prompt engineering highlights the importance of effective human-machine interaction through natural language in harnessing the full potential of artificial intelligence chatbots. This comprehensive yet accessible primer will benefit students and researchers seeking foundational knowledge and a deeper understanding of the inner workings of existing and emerging artificial intelligence models. The author hopes that the primer will encourage further responsible innovation and informed discussions about these increasingly powerful tools.	[Bridgelall, Raj] North Dakota State Univ, Coll Business, Transportat Logist & Finance, POB 6050, Fargo, ND 58108 USA	North Dakota State University Fargo	Bridgelall, R (corresponding author), North Dakota State Univ, Coll Business, Transportat Logist & Finance, POB 6050, Fargo, ND 58108 USA.	raj@bridgelall.com	Bridgelall, Raj/R-6245-2018	Bridgelall, Raj/0000-0003-3743-6652				Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Ba JL., 2016, arXiv; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bridgelall R., 2022, Res Square, DOI DOI 10.21203/RS.3.RS-1200362/V2; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Child R, 2019, Arxiv, DOI [arXiv:1904.10509, DOI 10.48550/ARXIV.1904.10509]; Chomsky N., 2023, NEW YORK TIMES; Garcez AD, 2023, ARTIF INTELL REV, V56, P12387, DOI 10.1007/s10462-023-10448-w; Geva M, 2021, Arxiv, DOI arXiv:2012.14913; Ghahramani Z, 2023, Google blog; Gron A., 2019, Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, DOI DOI 10.1201/9780367816377; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hendrycks D, 2020, Arxiv, DOI [arXiv:1606.08415, 10.48550/arXiv.1606.08415]; HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Li C., 2020, OpenAI's GPT-3 language model: A technical overview; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Manning Christopher D., 1999, FDN STAT NATURAL LAN; Meta, 2023, Meta Blog; OpenAI, 2023, New models and developer products announced at devday; Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670; Ouyang L., 2022, Advances in Neural Information Processing Systems; PETERS J., 2023, The Verge; Pichai S, 2023, Introducing gemini: Our largest and most capable ai model; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Roose Kevin, 2022, NEW YORK TIMES; Schaul K., 2023, The Washington post; Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909; Stevenson A, 2010, OXFORD DICT ENGLISH; TOBLER WR, 1970, ECON GEOGR, V46, P234, DOI 10.2307/143141; Vaswani A, 2017, ADV NEUR IN, V30; W3Techs, 2023, Usage of character encodings broken down by ranking; Walczak S., 2019, Advanced Methodologies and Technologies in Artificial Intelligence, Computer Simulation, and Human-Computer Interaction, DOI [10.4018/978-1-5225-7368-5, DOI 10.4018/978-1-5225-7368-5.CH004]; Wei Jason., 2023, Adv Neural Inform Proc Syst, V35, P24824; Widdowson H, 2007, INT J APPL LINGUIST, V17, P402, DOI 10.1111/j.1473-4192.2007.00164.x; Wolfram Stephen, 2002, A New Kind of Science, VFirst	37	0	0	17	17	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0269-2821	1573-7462		ARTIF INTELL REV	Artif. Intell. Rev.	MAR 13	2024	57	4							89	10.1007/s10462-024-10720-7	http://dx.doi.org/10.1007/s10462-024-10720-7			35	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KQ2X0		hybrid, Green Submitted			2024-07-03	WOS:001181378200001
J	Coiera, EW; Verspoor, K; Hansen, DP				Coiera, Enrico W.; Verspoor, Karin; Hansen, David P.			We need to chat about artificial intelligence	MEDICAL JOURNAL OF AUSTRALIA			English	Editorial Material						Artificial intelligence; Information services; eHealth		With the arrival of large language models such as ChatGPT, AI is reshaping how we work and interact	[Coiera, Enrico W.] Macquarie Univ, Ctr Hlth Informat, Sydney, NSW, Australia; [Coiera, Enrico W.; Verspoor, Karin] RMIT Univ, Melbourne, Vic, Australia; [Hansen, David P.] Australian Ehlth Res Ctr, CSIRO, Brisbane, Qld, Australia	Macquarie University; Royal Melbourne Institute of Technology (RMIT); Commonwealth Scientific & Industrial Research Organisation (CSIRO); Australian e-Health Research Centre	Coiera, EW (corresponding author), Macquarie Univ, Ctr Hlth Informat, Sydney, NSW, Australia.; Coiera, EW (corresponding author), RMIT Univ, Melbourne, Vic, Australia.	enrico.coiera@mq.edu.au	Verspoor, Karin/G-6034-2016	Verspoor, Karin/0000-0002-8661-1544; Coiera, Enrico/0000-0002-6444-6584	National Health and Medical Research Council (NHMRC) Centre for Research Excellence in Digital Health; NHMRC Investigator Grant [GNT2008645]	National Health and Medical Research Council (NHMRC) Centre for Research Excellence in Digital Health(National Health & Medical Research Council (NHMRC) of Australia); NHMRC Investigator Grant(National Health & Medical Research Council (NHMRC) of Australia)	This work was supported by the National Health and Medical Research Council (NHMRC) Centre for Research Excellence in Digital Health. Enrico Coiera is also supported by an NHMRC Investigator Grant (GNT2008645). The funders had no role in this manuscript. This article was written without the assistance of ChatGPT or other large language models.	Australian Alliance for AI in Healthcare, 2021, ROADM AI HEALTHC AUS; Birhane A., 2022, WIRED 1209; Cain S., 2023, GUARDIAN 0117; Cassidy C., 2023, GUARDIAN 0110; Coiera E., 2020, MANDARIN 0928; Coiera E, 2022, CELL REP MED, V3, DOI 10.1016/j.xcrm.2022.100860; Coiera E, 2020, LANCET, V395, P463, DOI 10.1016/S0140-6736(19)32987-3; Coiera E, 2018, LANCET, V392, P2331, DOI 10.1016/S0140-6736(18)31925-1; Edwards B., 2023, Ars Technica; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Kocaballi AB, 2020, J MED INTERNET RES, V22, DOI 10.2196/15823; Laranjo L, 2018, J AM MED INFORM ASSN, V25, P1248, DOI 10.1093/jamia/ocy072; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mackee N., 2020, INSIGHT 0907; Medenilla A., 2023, PLoS Digital Health, V2; Milmo, 2023, GUARDIAN 0203; MTPConnect, 2021, AUSTR CLIN TRIALS SE; National Disability Insurance Scheme, 2022, FRAM ART INT EN ASS; Navarro DF., 2022, P 2022 C N AM CHAPT; Rahimi-Ardabili H, 2022, J AM MED INFORM ASSN, V29, P2140, DOI 10.1093/jamia/ocac134; Royal Australian and New Zealand College of Radiologists, 2019, ETH PRINC AI MED; Tamkin A., 2021, LARGE LANGUAGE MODEL; Taylor J., 2022, GUARDIAN 0619; Tiku N, 2022, WASH POST; Wolfsfeld G, 2013, INT J PRESS/POLIT, V18, P115, DOI 10.1177/1940161212471716	26	9	9	6	21	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0025-729X	1326-5377		MED J AUSTRALIA	Med. J. Aust.	AUG 7	2023	219	3					98	100		10.5694/mja2.51992	http://dx.doi.org/10.5694/mja2.51992		JUN 2023	3	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	FO4W0	37302124	hybrid			2024-07-03	WOS:001007069200001
J	Zhao, HY; Chen, HJ; Yang, F; Liu, NH; Deng, HQ; Cai, HY; Wang, SQ; Yin, DW; Du, MN				Zhao, Haiyan; Chen, Hanjie; Yang, Fan; Liu, Ninghao; Deng, Huiqi; Cai, Hengyi; Wang, Shuaiqiang; Yin, Dawei; Du, Mengnan			Explainability for Large Language Models: A Survey	ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY			English	Article						Explainability; interpretability; large language models		Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview ofmethods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.	[Zhao, Haiyan; Du, Mengnan] New Jersey Inst Technol, 323 Dr Martin Luther King Jr Blvd, Newark, NJ 07102 USA; [Chen, Hanjie] Johns Hopkins Univ, 3400 N Charles St, Baltimore, MD 21218 USA; [Yang, Fan] Wake Forest Univ, 1834 Wake Forest Rd, Winston Salem, NC 27109 USA; [Liu, Ninghao] Univ Georgia, Herty Dr, Athens, GA 30602 USA; [Deng, Huiqi] Shanghai Jiao Tong Univ, 800 Dongchuan RD, Shanghai 200240, Peoples R China; [Cai, Hengyi] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China; [Wang, Shuaiqiang; Yin, Dawei] 10 Shangdi 10th St, Beijing 100085, Peoples R China	New Jersey Institute of Technology; Johns Hopkins University; Wake Forest University; University System of Georgia; University of Georgia; Shanghai Jiao Tong University; Chinese Academy of Sciences; Institute of Computing Technology, CAS	Zhao, HY (corresponding author), New Jersey Inst Technol, 323 Dr Martin Luther King Jr Blvd, Newark, NJ 07102 USA.	hz54@njit.edu; hanjie@rice.edu; yangfan@wfu.edu; ninghao.liu@uga.edu; denghq7@sjtu.edu.cn; hengyi1995@gmail.com; shqiang.wang@gmail.com; yindawei@acm.org; mengnan.du@njit.edu	Chen, Hanjie/AAU-7406-2021; Zhao, Haiyan/HGD-3793-2022; Zhao, Haiyan/KHW-5412-2024	Chen, Hanjie/0000-0001-8024-8804; Zhao, Haiyan/0009-0006-5358-6895; Wang, Shuaiqiang/0000-0002-9212-1947; Du, Mengnan/0000-0002-1614-6069				Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Anthropic, 2023, Decomposing Language Models Into Understandable Components?; AnthropicAI, 2023, Introducing Claude; Antverg O, 2022, Arxiv, DOI arXiv:2110.07483; Apidianaki Marianna, 2021, arXiv; Arous I, 2021, AAAI CONF ARTIF INTE, V35, P5868; Atanasova Pepa, 2023, arXiv; Bai B, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P25, DOI 10.1145/3447548.3467307; Bansal H, 2023, Arxiv, DOI arXiv:2212.09095; Barkan O, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2882, DOI 10.1145/3459637.3482126; Bastings Jasmijn, 2022, P 2022 C EMPIRICAL M, P976; Bau A, 2018, Arxiv, DOI arXiv:1811.01157; Belinkov Y, 2022, COMPUT LINGUIST, V48, P207, DOI 10.1162/coli_a_00422; Belinkov Yonatan, 2017, P 8 INT JOINT C NAT, V1, P1; Berglund L, 2024, Arxiv, DOI [arXiv:2309.12288, DOI 10.48550/ARXIV.2309.12288]; Bian YC, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P930; Blevins T, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P6649; Blevins T, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P14; Bricken Trenton, 2023, Towards Monosemanticity: Decomposing Language Models with Dictionary Learning; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brunner Gino, 2019, arXiv, DOI DOI 10.48550/ARXIV.1908.04211; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Captum, 2022, Testing with Concept Activation Vectors (TCAV) on Sensitivity Classification Examples and a ConvNet Model Trained on IMDB DataSet; Carlini N, 2023, Arxiv, DOI arXiv:2306.15447; Catherine Olsson, 2022, In-context Learning and Induction Heads-transformer-circuits.pub.; Chan A, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P51; Chan CS, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P5029; Chefer H, 2021, PROC CVPR IEEE, P782, DOI 10.1109/CVPR46437.2021.00084; Chen A, 2024, Arxiv, DOI arXiv:2309.07311; Chen BL, 2021, Arxiv, DOI arXiv:2104.03869; Chen HJ, 2022, AAAI CONF ARTIF INTE, P10463; Chen Hanjie, 2023, 61TH ANN M ASS COMPU; Chen H, 2023, NAT MACH INTELL, V5, P590, DOI 10.1038/s42256-023-00657-x; Chen YD, 2023, Arxiv, DOI arXiv:2307.08678; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A, 2023, J MACH LEARN RES, V24; Chrysostomou G, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P477; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Clark K, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P276, DOI 10.18653/v1/w19-4828; Dalvi F, 2019, AAAI CONF ARTIF INTE, P6309; Dasgupta Sanjoy, 2022, Proceedings of Machine Learning Research, P4794; DeRose JF, 2021, IEEE T VIS COMPUT GR, V27, P1160, DOI 10.1109/TVCG.2020.3028976; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Devlin Jacob, 2019, P N AM CHAPTER ASS C; DeYoung J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4443; Doshi-Velez F., 2017, RIGOROUS SCI INTERPR, DOI 10.48550/arXiv.1702.08608; Dozat T, 2017, Arxiv, DOI [arXiv:1611.01734, DOI 10.48550/ARXIV.1611.01734]; Du MN, 2024, COMMUN ACM, V67, P110, DOI 10.1145/3596490; Du MN, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P915; Du MN, 2020, COMMUN ACM, V63, P68, DOI 10.1145/3359786; Du MN, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P383, DOI 10.1145/3308558.3313545; Duan JH, 2024, Arxiv, DOI arXiv:2307.01379; Dziri N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5271; Elhage Nelson, 2021, A mathematical framework for transformer circuits; Enguehard J, 2023, Arxiv, DOI arXiv:2305.15853; Ethayarajh K, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P49; Feng S, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3719; Garg S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6174; Geva M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5484; Geva Mor, 2022, P 2022 C EMPIRICAL M, P30, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.3; Ghorbani A, 2019, PR MACH LEARN RES, V97; Golovneva O, 2023, Arxiv, DOI arXiv:2212.07919; Grosse R, 2023, Arxiv, DOI arXiv:2308.03296; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; Guo H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10333; Gurnee W, 2024, Arxiv, DOI arXiv:2310.02207; Hao YR, 2021, AAAI CONF ARTIF INTE, V35, P12963; Hara S, 2019, ADV NEUR IN, V32; He P, 2020, ICLR; Hennigen LT, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P197; Hernandez D, 2022, Arxiv, DOI arXiv:2205.10487; Hewitt J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2733; Hewitt J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4129; Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187; Huang YH, 2023, Arxiv, DOI arXiv:2307.10236; Jacovi A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4198; Jain S, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3543; Jaunet T, 2022, IEEE T VIS COMPUT GR, V28, P976, DOI 10.1109/TVCG.2021.3114683; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Joshi Brihi, 2022, P FINDINGS ASS COMPU, P3315; Kandpal N., 2023, INT C MACHINE LEARNI, P15696; Kang C, 2023, Arxiv, DOI arXiv:2310.08256; Kaushik D, 2020, Arxiv, DOI [arXiv:1909.12434, DOI 10.48550/ARXIV.1909.12434]; Kim B, 2018, PR MACH LEARN RES, V80; Kindermans P.-J., 2019, The (Un)reliability of Saliency Methods, P267, DOI 10.1007/978-3; Koh PW, 2017, PR MACH LEARN RES, V70; Kokalj Enja, 2021, P EACL HACKASHOP NEW, P16; Kovaleva O, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4365; Krishna S, 2023, Arxiv, DOI arXiv:2305.11426; Kroeger Nicholas, 2023, arXiv; Kunz Jenny, 2020, P 28 INT C COMPUTATI, P5136; Ladhak F, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3206; Lampinen Andrew, 2022, FINDINGS ASS COMPUTA, P537, DOI 10.18653/v1/2022.findings-emnlp.38; Lanham T, 2023, Arxiv, DOI arXiv:2307.13702; Lee Dong-Ho, 2022, arXiv; Li B, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4215; Li DQ, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5053; Li J., 2015, P 2016 C N AM CHAPTE, P681; Li JD, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1144; Li Jiwei, 2017, CoRR abs/1612.08220; Li YJ, 2024, Arxiv, DOI arXiv:2308.10149; Lieberum T, 2023, Arxiv, DOI arXiv:2307.09458; Lin YJ, 2019, BLACKBOXNLP WORKSHOP ON ANALYZING AND INTERPRETING NEURAL NETWORKS FOR NLP AT ACL 2019, P241; Liu FX, 2024, Arxiv, DOI arXiv:2307.05052; Liu JX, 2023, Arxiv, DOI arXiv:2307.01981; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Liu NH, 2020, Arxiv, DOI arXiv:2009.07494; Liu Yibing, 2022, ICML, P13807; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lundberg SM, 2017, ADV NEUR IN, V30; Lundstrom D, 2022, PR MACH LEARN RES; Luo SW, 2024, Arxiv, DOI [arXiv:2103.11072, 10.48550/ARXIV.2103.11072]; Madaan A, 2022, Arxiv, DOI arXiv:2209.07686; Marks S, 2023, Arxiv, DOI arXiv:2310.06824; Martin Sammy, 2023, Ten Levels of AI Alignment Difficulty; Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192; Mathew B, 2021, AAAI CONF ARTIF INTE, V35, P14867; Maudslay RH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P124; McGrath T, 2023, Arxiv, DOI [arXiv:2307.15771, DOI 10.48550/ARXIV.2307.15771]; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Mehdi Y., 2023, REINVENTING SEARCH N; Meng Kevin, 2022, Advances in Neural Information Processing Systems, V35, P17359; Miglani V, 2020, Arxiv, DOI [arXiv:2010.12697, 10.48550/arXiv.2010.12697, DOI 10.48550/ARXIV.2010.12697]; Mohankumar AK, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4206; Mohebbi H, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P792; Montavon G., 2019, Explainable AI: Interpreting, Explaining and Visualizing Deep Learning, P193, DOI DOI 10.1007/978-3-030-28954-610; Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008; Moradi P, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2791; Mu Jesse, 2021, Advances in Neural Information Processing Systems, V33, P17153; Mukherjee S, 2023, Arxiv, DOI arXiv:2306.02707; Neely Michael, 2021, arXiv; Nye Maxwell, 2021, arXiv; Olah Chris, 2020, Zoom In: An Introduction to Circuits; Olah Chris, 2020, Naturally Occurring Equivariance in Neural Networks-distill.pub; OpenAI, 2023, GPT-4 technical report; OpenAI, 2023, Language models can explain neurons in language models; Park C, 2019, 2019 IEEE VISUALIZATION CONFERENCE (VIS), P146, DOI 10.1109/visual.2019.8933677; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Petrov Michael, 2021, Weight Banding-distill.pub; Prasad A, 2023, Arxiv, DOI arXiv:2304.10703; Pruthi Garima, 2020, Advances in Neural Information Processing Systems; Qiu LY, 2021, Arxiv, DOI [arXiv:2107.14000, DOI 10.48550/ARXIV.2107.14000]; Radford A, 2021, PR MACH LEARN RES, V139; Radhakrishnan A, 2023, Arxiv, DOI arXiv:2307.11768; Raffel C, 2020, J MACH LEARN RES, V21; Rajani NF, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4932; Ravichander Abhilasha, 2020, P 9 JOINT C LEXICAL, P88; Ren RY, 2023, Arxiv, DOI arXiv:2307.11019; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Ross A, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P3840; Sanyal S, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10285; Saphra Naomi, 2022, Interpretability Creationism; Serrano S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2931; Shapley LS, 1953, A Value for n-Person Games, DOI DOI 10.7249/P0295; Shen YZ, 2022, Arxiv, DOI arXiv:2207.13948; Sikdar S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P865; Singh C, 2023, Arxiv, DOI arXiv:2305.09863; Sorodoc IT, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4177; Stacey J, 2022, AAAI CONF ARTIF INTE, P11349; Strobelt H, 2019, IEEE T VIS COMPUT GR, V25, P353, DOI 10.1109/TVCG.2018.2865044; Sundararajan M, 2017, PR MACH LEARN RES, V70; Taori Rohan, 2023, Stanford Center for Research on Foundation Models, V3, P7; Tenney I, 2019, Arxiv, DOI arXiv:1905.06316; Tenney I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4593; Thorne J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P963; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Touvron Hugo, 2023, Llama 2: Open foundation and fine-tuned chat models; Treviso M, 2023, Arxiv, DOI arXiv:2305.17075; Turpin M, 2023, Arxiv, DOI [arXiv:2305.04388, DOI 10.48550/ARXIV.2305.04388]; van Aken B, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1823, DOI 10.1145/3357384.3358028; Veit A, 2016, ADV NEUR IN, V29; Vig Jesse, 2019, ICLR WORKSHOP DEBUGG, V23, P353; Voita E, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1126; Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797; Voss Chelsea, 2021, Branch Specialization-distill.pub, DOI DOI 10.23915/DISTILL.00024.007; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang B, 2022, FINDINGS ASS COMPUTA, P176; Wang BS, 2023, Arxiv, DOI arXiv:2212.10001; Wei JS, 2022, ADV NEUR IN; Wei J, 2023, Arxiv, DOI [arXiv:2308.03958, 10.48550/arXiv.2308.03958]; Wei J, 2023, Arxiv, DOI arXiv:2303.03846; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Wiegreffe S, 2019, Arxiv, DOI [arXiv:1908.04626, DOI 10.48550/ARXIV.1908.04626]; Wu S, 2023, Arxiv, DOI arXiv:2307.13339; Wu Tongshuang, 2021, P 59 ANN M ASS COMP, DOI DOI 10.18653/V1/2021.ACL-LONG.523; Wu WQ, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P3080; Wu XS, 2024, Arxiv, DOI arXiv:2310.00492; Wu ZX, 2021, Arxiv, DOI arXiv:2101.00196; Wu Zhengxuan, P 3 BLACKBOXNLP WORK, P255, DOI DOI 10.18653/V1/2020.BLACKBOXNLP-1.24; Wu ZY, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4166; Xiong M, 2024, Arxiv, DOI arXiv:2306.13063; Ye Xi, 2022, Advances in neural information processing systems, V35, P30378; Ye Xi, 2023, P 2023 C EMPIRICAL M, P619; Yeh C, 2023, Arxiv, DOI arXiv:2305.03210; Yeh CK, 2018, ADV NEUR IN, V31; Yin F, 2023, Arxiv, DOI arXiv:2306.01150; Yordanov Yordan, 2022, P FINDINGS ASS COMPU, P3486; Yuksekgonul Mert, 2023, ICLR 2022 WORKSHOP P; Zhang Lining, 2022, P 5 BLACKBOXNLP WORK, P297, DOI DOI 10.18653/V1/2022.BLACKBOXNLP-1.24; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5017; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206; Zou A, 2023, Arxiv, DOI arXiv:2310.01405	207	2	2	17	17	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2157-6904	2157-6912		ACM T INTEL SYST TEC	ACM Trans. Intell. Syst. Technol.	APR	2024	15	2							20	10.1145/3639372	http://dx.doi.org/10.1145/3639372			38	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OQ6J1		hybrid, Green Submitted			2024-07-03	WOS:001208775700001
J	Liu, PF; Ren, YM; Tao, J; Ren, ZX				Liu, Pengfei; Ren, Yiming; Tao, Jun; Ren, Zhixiang			GIT-Mol: A multi-modal large language model for molecular science with graph, image, and text	COMPUTERS IN BIOLOGY AND MEDICINE			English	Article						Molecular representation; Molecule generation; Large language model; Multi-modality		Large language models have made significant strides in natural language processing, enabling innovative applications in molecular science by processing textual representations of molecules. However, most existing language models cannot capture the rich information with complex molecular structures or images. In this paper, we introduce GIT-Mol, a multi -modal large language model that integrates the Graph, Image, and Text information. To facilitate the integration of multi -modal molecular data, we propose GIT-Former, a novel architecture that is capable of aligning all modalities into a unified latent space. We achieve a 5%-10% accuracy increase in properties prediction and a 20.2% boost in molecule generation validity compared to the baselines. With the any -to -language molecular translation strategy, our model has the potential to perform more downstream tasks, such as compound name recognition and chemical reaction prediction.	[Liu, Pengfei; Ren, Yiming; Ren, Zhixiang] Peng Cheng Lab, Shenzhen 518055, Guangdong, Peoples R China; [Liu, Pengfei; Tao, Jun] Sun Yat sen Univ, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China	Peng Cheng Laboratory; Sun Yat Sen University	Ren, ZX (corresponding author), Peng Cheng Lab, Shenzhen 518055, Guangdong, Peoples R China.	renzhx@pcl.ac.cn	Ren, Zhixiang/IQS-1889-2023; Liu, Pengfei/GRX-7685-2022	Ren, Zhixiang/0000-0002-4104-3790; Liu, Pengfei/0000-0001-6130-6968	National Natural Science Foundation of China [61902446, 62172456, 91937302]; Peng Cheng Cloud-Brain of Peng Cheng Laboratory, China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Peng Cheng Cloud-Brain of Peng Cheng Laboratory, China	This work is supported by grants from the National Natural Science Foundation of China (61902446, 62172456, and 91937302) and the Peng Cheng Cloud-Brain of Peng Cheng Laboratory, China.	Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; Bao F, 2023, Arxiv, DOI arXiv:2303.06555; Bao H., 2022, ADV NEURAL INF PROCE, V35, P32897, DOI DOI 10.1109/CVPR.2018.00636; Beltagy I., 2019, arXiv; Bento AP, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00456-1; Bilodeau C, 2022, WIRES COMPUT MOL SCI, V12, DOI 10.1002/wcms.1608; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Edwards C., 2022, P 2022 C EMPIRICAL M, P375; Edwards C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P595; Filippov IV, 2009, J CHEM INF MODEL, V49, P740, DOI 10.1021/ci800067r; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Hastings J, 2016, NUCLEIC ACIDS RES, V44, pD1214, DOI 10.1093/nar/gkv1031; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hou ZY, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P594, DOI 10.1145/3534678.3539321; Huang SH, 2023, Arxiv, DOI arXiv:2302.14045; Jia C, 2021, PR MACH LEARN RES, V139; Kim S, 2019, NUCLEIC ACIDS RES, V47, pD1102, DOI 10.1093/nar/gky1033; Li JT, 2024, Arxiv, DOI arXiv:2306.06615; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li Y., 2023, bioRxiv, P2023; Liu SC, 2024, Arxiv, DOI arXiv:2212.10789; Liu SC, 2022, Arxiv, DOI arXiv:2110.07728; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; OpenAl, 2023, GPT-4 technical report; Peryea T., 2019, Abstracts of Papers of the American Chemical Society, V258; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Raffel C, 2020, J MACH LEARN RES, V21; Rajan K, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00538-8; Ramesh A., 2022, arXiv; Reed S, 2022, Arxiv, DOI arXiv:2205.06175; Rodrigues T, 2016, NAT CHEM, V8, P531, DOI [10.1038/NCHEM.2479, 10.1038/nchem.2479]; Stefanini M, 2023, IEEE T PATTERN ANAL, V45, P539, DOI 10.1109/TPAMI.2022.3148210; Su B., 2022, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang HY, 2022, Arxiv, DOI arXiv:2210.06423; Wang J., 2022, Brief Bioinform, V23; Wang WH, 2022, Arxiv, DOI arXiv:2208.10442; Wang YY, 2022, NAT MACH INTELL, V4, P279, DOI 10.1038/s42256-022-00447-x; Wei JS, 2022, ADV NEUR IN; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Xu ZP, 2022, J CHEMINFORMATICS, V14, DOI 10.1186/s13321-022-00624-5; Yang L, 2024, Arxiv, DOI [arXiv:2209.00796, DOI 10.48550/ARXIV.2209.00796]; Zeng ZN, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-28494-3; Zhou G., 2023, 11 INT C LEARNING RE; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	50	0	1	17	17	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0010-4825	1879-0534		COMPUT BIOL MED	Comput. Biol. Med.	MAR	2024	171								108073	10.1016/j.compbiomed.2024.108073	http://dx.doi.org/10.1016/j.compbiomed.2024.108073		FEB 2024	11	Biology; Computer Science, Interdisciplinary Applications; Engineering, Biomedical; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Life Sciences & Biomedicine - Other Topics; Computer Science; Engineering; Mathematical & Computational Biology	LL8H5	38359660	Green Submitted			2024-07-03	WOS:001187043300001
C	Mochizuki, S; Yamashita, S; Kawasaki, K; Yuasa, R; Kubota, T; Ogawa, K; Baba, J; Higashinaka, R			ACM	Mochizuki, Shota; Yamashita, Sanae; Kawasaki, Kazuyoshi; Yuasa, Reiko; Kubota, Tomonori; Ogawa, Kohei; Baba, Jun; Higashinaka, Ryuichiro			Investigating the Intervention in Parallel Conversations	PROCEEDINGS OF THE 11TH CONFERENCE ON HUMAN-AGENT INTERACTION, HAI 2023			English	Proceedings Paper	11th International Conference on Human-Agent Interaction (HAI)	DEC 04-07, 2023	Chalmers Univ Technol, Gothenburg, SWEDEN	Assoc Comp Machinery, ACM SIGCHI	Chalmers Univ Technol	conversation; intervention; large language model; dialogue system		In recent years, a framework of parallel conversations has been proposed to facilitate efficient conversations through cooperation between humans and dialogue systems. This approach aims to enable simultaneous conversations with multiple users by enabling the system to handle basic conversation and human operators to intervene when problems arise in the system's conversation. Previous studies on parallel conversations have primarily focused on delegating simple exchanges such as greetings and acknowledgments to the system, with humans taking over for more complex interactions like providing guidance. Recent advancements in large language models may change this situation, enabling dialogue systems to engage in more advanced interactions. In this study, to examine which interventions will be made when large language models are utilized, we placed six dialogue robots based on large language models in an actual facility and conducted a field experiment involving parallel conversations for about a month. Our analysis of the collected data on dialogues and interventions showed that the most frequent interventions were made for supporting interactions when the system failed to react to the user utterances, indicating the limitations of using large language models alone and clarifying our next steps for facilitating smoother parallel conversations.	[Mochizuki, Shota; Yamashita, Sanae; Kawasaki, Kazuyoshi; Kubota, Tomonori; Ogawa, Kohei; Higashinaka, Ryuichiro] Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan; [Yuasa, Reiko] Nagoya Univ, Sch Informat, Nagoya, Aichi, Japan; [Baba, Jun] CyberAgent Inc, AI Lab, Shibuya, Tokyo, Japan	Nagoya University; Nagoya University	Mochizuki, S (corresponding author), Nagoya Univ, Grad Sch Informat, Nagoya, Aichi, Japan.	mochizuki.shota.k8@s.mail.nagoya-u.ac.jp; yamashita.sanae.w7@s.mail.nagoya-u.ac.jp; kkazuyoshilmn@gmail.com; yuasa.reiko.k5@s.mail.nagoya-u.ac.jp; kubota@nuee.nagoya-u.ac.jp; k-ogawa@nuee.nagoya-u.ac.jp; baba_jun@cyberagent.co.jp; higashinaka@i.nagoya-u.ac.jp		Yuasa, Reiko/0009-0005-8799-4144; Baba, Jun/0000-0003-0680-5021	JST Moonshot RD [JPMJMS2011]	JST Moonshot RD	This work was supported by JST Moonshot R&D Grant number JPMJMS2011. We also thank the staff at Nifrel for allowing us to conduct the field experiment.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cruz-Sandoval D, 2019, IEEE PERVAS COMPUT, V18, P10, DOI 10.1109/MPRV.2019.2907020; Cui L, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P97, DOI 10.18653/v1/P17-4017; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Glas DF, 2012, IEEE T SYST MAN CY A, V42, P530, DOI 10.1109/TSMCA.2011.2164243; Gorin AL, 1997, SPEECH COMMUN, V23, P113, DOI 10.1016/S0167-6393(97)00040-X; Higashinaka R, 2021, SIGDIAL 2021: 22ND ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2021), P89; Kawahara T, 2021, ADV ROBOTICS, V35, P657, DOI 10.1080/01691864.2021.1928549; Kawahara T, 2019, LECT NOTES ELECTR EN, V579, P65, DOI 10.1007/978-981-13-9443-0_6; Kawai H., 2022, P 23 ANN M SPEC INT, P107; Liu TY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6723; Nuruzzaman M, 2018, INT CONF E BUS ENG, P54, DOI 10.1109/ICEBE.2018.00019; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300; Shuster K, 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.07567; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tsubokura Kazuya, 2022, 2022 IEEE 11th Global Conference on Consumer Electronics (GCCE), P352, DOI 10.1109/GCCE56475.2022.10014052; Uchida Takahisa., 2023, P 2 SYMBIOTIC SOC AV; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Walker M, 2000, 6TH APPLIED NATURAL LANGUAGE PROCESSING CONFERENCE/1ST MEETING OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE AND PROCEEDINGS OF THE ANLP-NAACL 2000 STUDENT RESEARCH WORKSHOP, pA210; Xu AB, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3506, DOI 10.1145/3025453.3025496; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	26	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0824-4				2023							30	38		10.1145/3623809.3623863	http://dx.doi.org/10.1145/3623809.3623863			9	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW4HI					2024-07-03	WOS:001148034200006
C	Singla, T; Anandayuvaraj, D; Kalu, KG; Schorlemmer, TR; Davis, JC			ACM	Singla, Tanmay; Anandayuvaraj, Dharun; Kalu, Kelechi G.; Schorlemmer, Taylor R.; Davis, James C.			An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures	PROCEEDINGS OF THE 2023 WORKSHOP ON SOFTWARE SUPPLY CHAIN OFFENSIVE RESEARCH AND ECOSYSTEM DEFENSES, SCORED 2023			English	Proceedings Paper	2nd ACM Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses (SCORED)	NOV 30, 2023	Copenhagen, DENMARK	Assoc Comp Machinery, ACM SIGSAC		Software Supply Chain; Failure Analysis; Large Language Models; Software Security; Cybersecurity; Empirical Software Engineering	DESIGN	As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing past failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5's categorizations had an average accuracy of 68% and Bard's had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.	[Singla, Tanmay; Anandayuvaraj, Dharun; Kalu, Kelechi G.; Schorlemmer, Taylor R.; Davis, James C.] Purdue Univ, W Lafayette, IN 47907 USA	Purdue University System; Purdue University	Singla, T (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.	singlat@purdue.edu; dananday@purdue.edu; kalu@purdue.edu; tschorle@purdue.edu; davisjam@purdue.edu		Kalu, Kelechi/0000-0002-8749-9697; Davis, James C./0000-0003-2495-686X	Cisco; Google; NSF [2229703]	Cisco; Google(Google Incorporated); NSF(National Science Foundation (NSF))	Thiswork was supported by Cisco, Google, and NSF award #2229703.	Alberts C. J., 2011, 2011 44 HAW INT C SY, P1, DOI DOI 10.1109/HICSS.2011.36; Amusuo PC, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1615, DOI 10.1145/3540250.3560879; Anandayuvaraj D., 2023, 5 INT WORKSHOP SOFTW; Anandayuvaraj D, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559545; [Anonymous], 2018, ISO/IEC/IEEE 90003:2018; [Anonymous], 2015, ISO 9000; [Anonymous], 2011, Corbet. kernel.org status: hints on how to check your machine for intrusion; [Anonymous], 2011, Engenharia de Software; Anthropic, 2023, Introducing claude; Avizienis A, 2004, IEEE T DEPEND SECURE, V1, P11, DOI 10.1109/TDSC.2004.2; Basili V. R., 1993, EUR SOFTW ENG C; Beck K., 2000, Extreme Programming Explained: Embrace Change; Bishop M., 1999, P S RECENT ADV INTRU, P125; Chauchefoin T, 2022, Php supply chain attack on pear; Checkoway Stephen., 2016, PROC ACM C COMPUTER, P468, DOI [10.1145/2976749.2978395, DOI 10.1145/2976749.2978395]; Chen ZB, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1487, DOI 10.1145/3368089.3417055; CNCF Security Technical Advisory Group, 2023, Catalog of supply chain compromises; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Collier B, 1996, IEEE SOFTWARE, V13, P65, DOI 10.1109/52.526833; Corbet, 2007, The backdooring of wordpress; Costello S. H., 1984, SIGSOFT Software Engineering Notes, V9, P15, DOI 10.1145/1010941.1010947; Cybersecurity and Infrastructure Security Agency, 2021, Technical report; Davis J. C., 2023, P IEEE JOHN VINCENT; Dingsayr T, 2009, IEEE SOFTWARE, V26, P100, DOI 10.1109/MS.2009.82; Ellison R., 2010, Evaluating and mitigating software supply chain security risks; Epson N, 2023, Section: Artificial Intelligence Development; ErCiccione, 2019, Warning: The binaries of the cli wallet were compromised for a short time; Ernst M. D., 2017, Leibniz International Proceedings in Informatics (LIPIcs), V71; European Union Agency for Cybersecurity, 2021, Technical report; European Union Agency for Cybersecurity (ENISA), 2022, Technical Report; FAGAN ME, 1977, DATAMATION, V23, P133; Fagan ME, 1999, IBM SYST J, V38, P258, DOI 10.1147/sj.382.0258; Fonseca P, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P328, DOI 10.1145/3064176.3064163; G. A. Database, 2020, Malicious package in load-from-cwd-or-npm; Garousi V, 2020, INFORM SOFTWARE TECH, V126, DOI 10.1016/j.infsof.2020.106321; Gavara J. I, 2023, Claude vs chatgpt. Medium; Geer D., 2020, USENIX; Login, V45; Ghahramani Z, 2023, Lamda: our breakthrough conversation technology; Gilb Tom, 1993, Software inspections; Gill R, 2023, What is open-source intelligence?; Gokkaya B., Software supply chain: review of attacks, risk assessment strategies and security controls; Google Cloud, 2023, Software supply chain security | google cloud; Graham M, 2014, Context threat intelligence-the monju incident; Huddleston J., 2021, 2021 INT C COMPUTATI; Hunter Thomas, 2018, Compromised npm Package: event -stream; I. Cohere Technologies, 2023, Cohere; IEEE Standards Association, 2014, Technical report; Jones Capers, 2011, The Economics of Software Quality; Kaspersky, 2019, Shadowhammer: Malicious updates for asus laptops; Ken Schwaber J. S., 2020, The Scrum Guide; Kuutila M, 2020, INFORM SOFTWARE TECH, V121, DOI 10.1016/j.infsof.2020.106257; Ladisa P., 2023, 2023 IEEE S SECURITY; Leveson N.G., 1995, Safeware: System safety and computers; Leyden J., 2015, Apple cleans up ios app store after first big malware attack; Liu Pengfei, 2021, Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing; Mandour A, 2023, Gpt-3.5 model architecture; Manyika James, 2023, An Overview of Bard: An Early Experiment with Generative AI; Melo M, 2021, LECT NOTES COMPUT SC, V12957, P437, DOI 10.1007/978-3-030-87013-3_33; National Research Council, 2007, Software for dependable systems: Sufficient evidence?; Nikiforakis N., 2012, P 2012 ACM C COMP CO; Nissen C., 2018, Tech. Rep.; Ohm Marc, 2020, Detection of Intrusions and Malware, and Vulnerability Assessment. 17th International Conference, DIMVA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12223), P23, DOI 10.1007/978-3-030-52683-2_2; Okafor C., P 2022 ACM WORKSH SO, P15; OpenAI, 2023, Gpt best practices; OpenAI, 2023, Openai platform-gpt-3.5 models; OpenAI, 2023, Openai platform; Panichella S, 2015, PROC IEEE INT CONF S, P281, DOI 10.1109/ICSM.2015.7332474; Pashchenko I, 2018, PROCEEDINGS OF THE 12TH ACM/IEEE INTERNATIONAL SYMPOSIUM ON EMPIRICAL SOFTWARE ENGINEERING AND MEASUREMENT (ESEM 2018), DOI 10.1145/3239235.3268920; Pedersen K., 2004, UKAIS C; Petroski H., 1994, DESIGN PARADIGMS CAS; Pichai S., 2023, IMPORTANT NEXT STEP; Ponta SE, 2020, EMPIR SOFTW ENG, V25, P3175, DOI 10.1007/s10664-020-09830-x; Ranade P, 2021, IEEE INT CONF BIG DA, P3334, DOI 10.1109/BigData52589.2021.9671824; Robbins D, 2003, Gentoo linux security announcement; Sarwar I., 2009, European Journal of Scientific Research; Schulman J., 2023, Introducing chatgpt; Schwartz E, 2018, aur-general] acroread package compromised; Security Technical Advisory Group, 2021, Technical report; Sonatype, 2021, State of the software supply chain; Sonatype, 2022, State of the Software Supply Chain; Synopsys, 2023, OSSRA Report; The Linux Foundation, 2022, SLSA: Supply-chain levels for software artifacts; The Recorded Future Team, 2022, What is open source intelligence and how is it used?; Vasilakis N, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1755, DOI 10.1145/3460120.3484736; Vaswani A., 2023, Attention is all you need; Vijayakumar K, 2017, Journal of Ambient Intelligence and Humanized Computing; Vivek K., 2022, Is software reuse leading to dependency hell?; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yao M., 2023, TOPBOTS; Zahan N, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2022), P331, DOI [10.1145/3510457.3513044, 10.1109/ICSE-SEIP55303.2022.9794068]; Zetter K, 2010, ' google' hackers had ability to alter source code; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689; Zhao W. X., 2023, A survey of large language models; Zimmermann M, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P995	95	1	1	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0263-1				2023							5	15		10.1145/3605770.3625214	http://dx.doi.org/10.1145/3605770.3625214			11	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2OW		Green Submitted, hybrid			2024-07-03	WOS:001123143300003
J	Kirwan, A				Kirwan, Adrian			ChatGPT and university teaching, learning and assessment: some initial reflections on teaching academic integrity in the age of Large Language Models	IRISH EDUCATIONAL STUDIES			English	Article; Early Access						ChatGPT; Large Language Models; Academic integrity; Assessment		Since its arrival in late 2022, ChatGPT has occupied the minds of academics, administrators and students. Reactions to the emergence of Large Language Models (LLMs) have varied but significant anxieties about their impact on assessment have arisen. To address these concerns, this article serves three purposes; firstly, it seeks to gauge the discourse surrounding Large Language Models (LLMs) focusing on ChatGPT. In doing so, it explores general and academic responses to the technology and the challenges/opportunities that have been identified. Secondly, and building on this, it provides an overview of ChatGPT in action and seeks to moderate fears raised by some of the extreme claims that have been made about the potential of this technology. Finally, the article uses a case study to discuss the introduction of this technology to a group of first-year undergraduate students, offering guidance on how the topic of LLMs might be broached. It concludes by suggesting that while the technology has the ability to offer assistance in the completion of academic assessment, it does not replace the higher thinking skills that are central to teaching, learning and assessment in higher education. In turn, arguing that these must be central to assessment practices.	[Kirwan, Adrian] Maynooth Univ, Crit Skills, Off Dean Teaching & Learning, Maynooth, Ireland; [Kirwan, Adrian] Maynooth Univ, Crit Skills, Off theDean Teaching & Learning, Room 8,Rowan House, Maynooth, Ireland	Maynooth University; Maynooth University	Kirwan, A (corresponding author), Maynooth Univ, Crit Skills, Off theDean Teaching & Learning, Room 8,Rowan House, Maynooth, Ireland.	adrian.kirwan@mu.ie		Kirwan, Adrian/0000-0002-0771-3092				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Altman S., 2022, Twitter; American College Research Librarians (ARCL), 2015, Framework for Information Literacy for Higher Education; American Psychological Association, 2020, Publication Manual of the American Psychological Association, V7th, DOI [10.1037/0000165-000, DOI 10.1037/0000165-000]; [Anonymous], 2014, The Oxford Handbook of Modern Irish History; Armstrong P., 2010, BLOOMS TAXONOMY; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barnett S., 2023, Wired; Bartlett Thomas., 2010, Ireland: A History; Bayerlein L, 2021, LABOUR IND, V31, P418, DOI 10.1080/10301763.2021.1966292; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Blikstein Paulo., 2021, Algorithmic Rights and Protections for Children, DOI [https://doi.org/10.1162/ba67f642.646d0673, DOI 10.1162/BA67F642.646D0673]; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Burgess M., 2023, Wired; Burrell Jenna, 2023, Technology and Democracy; Cannon JohnEd., 2015, The Oxford Companion to British History; Cassidy C., 2023, The GuardianJanuary 10; Ceres P., 2023, Wired; Chang KK, 2023, Arxiv, DOI arXiv:2305.00118; Concannon F., 2023, Irish Journal of Technology Enhanced Learning, V7, DOI [10.22554/ijtel.v7i1.116, DOI 10.22554/IJTEL.V7I1.116]; Cotton DRE, 2024, INNOV EDUC TEACH INT, V61, P228, DOI 10.1080/14703297.2023.2190148; Cronan TP, 2018, J BUS ETHICS, V147, P197, DOI 10.1007/s10551-015-2988-3; Dick Stephanie., 2020, BJHS Themes, V5, P205; Donnelly J. S., 1989, A New History of Ireland V: Ireland under the Union, I, P1801; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Elsen-Rooney Michael, 2023, Chalkbeat; Fraser David, 2023, CBC; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gold Jon, 2023, Computer World; Hekkert MP, 2007, TECHNOL FORECAST SOC, V74, P413, DOI 10.1016/j.techfore.2006.03.002; Hern Alex, 2023, The Guardian; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Krsmanovic M., 2019, Voices of Reform: Educational Research to Inform and Reform, V2, P24, DOI DOI 10.32623/2.00004; Lund Susan., 2021, The future of work after COVID-19, V18; Maxson Claire, 2022, Research Briefs, National Resource Center for the First-year Experience and Students in Transition; Milmo Dan, 2023, The Guardian; Mollick ER, 2022, PREPRINT, DOI [10.2139/ssrn.4300783, DOI 10.2139/SSRN.4300783]; Mukherjee Supantha, 2023, Reuters; National Academic Integrity Network (NAIN), 2023, Generative Artificial Intelligence: Guidelines for Educators; National Forum for the Enhancement of Teaching and Learning, 2016, Assessment OF, FOR and AS Learning: Continuing the Debate and Creating a Focus; OpenAI, What are Tokens and How to Count Them?; OpenAI, 2023, Our Approach to AI Safety; Oudshoorn N., 2003, USERS MATTER COCONST; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Rudolph J., 2023, JALT, V6, P364, DOI [10.37074/jalt.2023.6.1.23, DOI 10.37074/JALT.2023.6.1.23]; Sabzalieva E., 2023, ChatGPT and artificial intelligence in higher education quick start guide; Southworth J., 2023, Computers and Education: Artificial Intelligence, P1, DOI [DOI 10.1016/J.CAEAI.2023.100127, 10.1016/j.caeai.2023.100127, 10.1016/j.caeai.2023]; Spataro Jared, 2023, Office Microsoft Blog; Stahl BC, 2024, INT J INFORM MANAGE, V74, DOI 10.1016/j.ijinfomgt.2023.102700; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Turnitin, Turnitin's AI Writing Detection Capabilities; Volpicelli G., 2023, Politico; Wallbank Adrian J., 2023, Times Higher Education; Weale S., 2023, The Guardian; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Zhai Xiaoming, 2023, PREPRINT, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]	58	3	3	51	67	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0332-3315	1747-4965		IRISH EDUC STUD	Ir. Educ. Stud.	2023 NOV 24	2023										10.1080/03323315.2023.2284901	http://dx.doi.org/10.1080/03323315.2023.2284901		NOV 2023	18	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	Y5HU4					2024-07-03	WOS:001105574000001
C	Fan, ZY; Gao, X; Mirchev, M; Roychoudhury, A; Tan, SH			IEEE	Fan, Zhiyu; Gao, Xiang; Mirchev, Martin; Roychoudhury, Abhik; Tan, Shin Hwei			Automated Repair of Programs from Large Language Models	2023 IEEE/ACM 45TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ICSE	International Conference on Software Engineering		English	Proceedings Paper	45th IEEE/ACM International Conference on Software Engineering (ICSE)	MAY 14-20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, Melbourne Convent Bur, State Govt Victoria, CSIRO, Huawei, Monash Univ, Meta, Google, AWS, Monash Univ, Dragon Testing Technol, IBM, Univ Melbourne, RMIT Univ				Large language models such as Codex, have shown the capability to produce code for many programming tasks. However, the success rate of existing models is low, especially for complex programming tasks. One of the reasons is that language models lack awareness of program semantics, resulting in incorrect programs, or even programs which do not compile. In this paper, we systematically study whether automated program repair (APR) techniques can fix the incorrect solutions produced by language models in LeetCode contests. The goal is to study whether APR techniques can enhance reliability in the code produced by large language models. Our study revealed that: (1) automatically generated code shares common programming mistakes with human-crafted solutions, indicating APR techniques may have potential to fix auto-generated code; (2) given bug location information provided by a statistical fault localization approach, the newly released Codex edit mode, which supports editing code, is similar to or better than existing Java repair tools TBar and Recoder in fixing incorrect solutions. By analyzing the experimental results generated by these tools, we provide several suggestions: (1) enhancing APR tools to surpass limitations in patch space (e.g., introducing more flexible fault localization) is desirable; (2) as large language models can derive more fix patterns by training on more data, future APR tools could shift focus from adding more fix patterns to synthesis/semantics based approaches, (3) combination of language models with APR to curate patch ingredients, is worth studying.	[Fan, Zhiyu; Mirchev, Martin; Roychoudhury, Abhik] Natl Univ Singapore, Singapore, Singapore; [Gao, Xiang] Beihang Univ, Beijing, Peoples R China; [Tan, Shin Hwei] Southern Univ Sci & Technol, Shenzhen, Peoples R China	National University of Singapore; Beihang University; Southern University of Science & Technology	Gao, X (corresponding author), Beihang Univ, Beijing, Peoples R China.	zhiyufan@comp.nus.edu.sg; xiang_gao@buaa.edu.cn; mmirchev@comp.nus.edu.sg; abhik@comp.nus.edu.sg; tansh3@sustech.edu.cn			Singapore Ministry of Education (MoE) Tier 3 grant "Automated Program Repair" [MOE-MOET32021-0001]; National Natural Science Foundation of China [61902170, 62202026, 62141209]	Singapore Ministry of Education (MoE) Tier 3 grant "Automated Program Repair"; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	We thank the anonymous reviewers for their suggestions. This work was partially supported by a Singapore Ministry of Education (MoE) Tier 3 grant "Automated Program Repair", MOE-MOET32021-0001, and the National Natural Science Foundation of China (Grant No. 61902170, 62202026, 62141209).	Abreu R, 2007, TAIC PART 2007 - TESTING: ACADEMIC AND INDUSTRIAL CONFERENCE - PRACTICE AND RESEARCH TECHNIQUES, PROCEEDINGS, P89, DOI 10.1109/TAIC.PART.2007.13; amazon, 2022, AM COD; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Caballero E., 2016, DESCRIPTION2CODE DAT; Campos J, 2012, IEEE INT CONF AUTOM, P378, DOI 10.1145/2351676.2351752; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; copilot, 2021, GITH COP; Ghanbari Ali, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P541, DOI 10.1145/3395363.3404362; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Hendrycks Dan, 2021, NeurIPS; Nguyen HDT, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P772, DOI 10.1109/ICSE.2013.6606623; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Jones E, 2022, Arxiv, DOI arXiv:2202.12299; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; leetcode, 2022, LEETC CONT; leetcode, LEETC DISC FOR; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu K, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P31, DOI 10.1145/3293882.3330577; Liu K, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER), P456, DOI 10.1109/saner.2019.8667970; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Martinez M., 2016, P 25 INT S SOFTWARE, P441, DOI [10.1145/2931037.2948705, DOI 10.1145/2931037.2948705, 10.1145/2931037]; Mechtaev S, 2018, ACM T SOFTW ENG METH, V27, DOI 10.1145/3241980; Mechtaev S, 2016, PROC INT CONF SOFTW, P691, DOI 10.1145/2884781.2884807; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; .openai, 2022, COD MOD; openai, 2022, COD ED MOD; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Puri R., 2021, 35 C NEURAL INFORM P; Qi Z., 2015, P 2015 INT S SOFTW T, P24, DOI DOI 10.1145/2771783.2771791; Rahmani K, 2021, P ACM PROGRAM LANG, V5, DOI 10.1145/3485535; Saha S, 2019, PROC INT CONF SOFTW, P13, DOI 10.1109/ICSE.2019.00020; Tan SH, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P187, DOI 10.1145/3180155.3180243; Tan SH, 2017, PROC IEEE ACM INT C, P180, DOI 10.1109/ICSE-C.2017.76; Tan SH, 2016, FSE'16: PROCEEDINGS OF THE 2016 24TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON FOUNDATIONS OF SOFTWARE ENGINEERING, P727, DOI 10.1145/2950290.2950295; Tan SH, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P471, DOI 10.1109/ICSE.2015.65; Wang SW, 2020, IEEE INT CONF AUTOM, P968, DOI 10.1145/3324884.3416590; Weimer W, 2009, PROC INT CONF SOFTW, P364, DOI 10.1109/ICSE.2009.5070536; Wen M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/3180155.3180233; White M, 2016, IEEE INT CONF AUTOM, P87, DOI 10.1145/2970276.2970326; Xuan JF, 2017, IEEE T SOFTWARE ENG, V43, P34, DOI 10.1109/TSE.2016.2560811; Ye H, 2022, IEEE T SOFTWARE ENG, V48, P2920, DOI 10.1109/TSE.2021.3071750; Yi JY, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P740, DOI 10.1145/3106237.3106262; Yuan Y, 2020, IEEE T SOFTWARE ENG, V46, P1040, DOI 10.1109/TSE.2018.2874648; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	52	10	11	4	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	0270-5257		978-1-6654-5701-9	PROC INT CONF SOFTW			2023							1469	1481		10.1109/ICSE48619.2023.00128	http://dx.doi.org/10.1109/ICSE48619.2023.00128			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JK		Green Submitted			2024-07-03	WOS:001032629800119
J	von Wedel, D; Schmitt, RA; Thiele, M; Leuner, R; Shay, D; Redaelli, S; Schaefer, MS				von Wedel, Dario; Schmitt, Rico A.; Thiele, Moritz; Leuner, Raphael; Shay, Denys; Redaelli, Simone; Schaefer, Maximilian S.			Affiliation Bias in Peer Review of Abstracts by a Large Language Model	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Letter								This study assesses affiliation bias in peer review of medical abstracts by a commonly used large language model.	[von Wedel, Dario; Redaelli, Simone; Schaefer, Maximilian S.] Beth Israel Deaconess Med Ctr, Dept Anesthesia Crit Care & Pain Med, Boston, MA USA; [Schmitt, Rico A.; Thiele, Moritz; Leuner, Raphael] Charite Univ Med Berlin, Berlin Exchange Med EV, Berlin, Germany; [Shay, Denys] Harvard TH Chan Sch Publ Hlth, Dept Epidemiol, Boston, MA USA; [Schaefer, Maximilian S.] Harvard Med Sch, Dept Anesthesia Crit Care & Pain Med, Beth Israel Deaconess Med Ctr, 330 Brookline Ave, Boston, MA 02215 USA	Harvard University; Beth Israel Deaconess Medical Center; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; Harvard University; Harvard T.H. Chan School of Public Health; Harvard University; Beth Israel Deaconess Medical Center; Harvard Medical School	Schaefer, MS (corresponding author), Harvard Med Sch, Dept Anesthesia Crit Care & Pain Med, Beth Israel Deaconess Med Ctr, 330 Brookline Ave, Boston, MA 02215 USA.	msschaef@bidmc.harvard.edu		von Wedel, Dario/0000-0001-8102-0254; Kronenberg, Noel/0000-0003-3575-1341; Schmitt, Rico Andre/0009-0001-3568-2203				BMJ Author Hub, PEER REV; Dance A, 2023, NATURE, V614, P581, DOI 10.1038/d41586-023-00403-8; Flanagin A, 2023, JAMA-J AM MED ASSOC, V330, P702, DOI 10.1001/jama.2023.12500; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Perlis RH, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.35924; Ross JS, 2006, JAMA-J AM MED ASSOC, V295, P1675, DOI 10.1001/jama.295.14.1675	6	4	4	14	14	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	JAN 16	2024	331	3					252	253		10.1001/jama.2023.24641	http://dx.doi.org/10.1001/jama.2023.24641		DEC 2023	2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	HA5L9	38150261				2024-07-03	WOS:001134192300005
C	Garn, B; Kampel, L; Leithner, M; Celic, B; Çulha, C; Hiess, I; Kieseberg, K; Koelbing, M; Schreiber, DP; Wagner, M; Wech, C; Zivanovic, J; Simos, DE		Bonfanti, S; Gargantini, A; Salvaneschi, P		Garn, Bernhard; Kampel, Ludwig; Leithner, Manuel; Celic, Berina; Culha, Ceren; Hiess, Irene; Kieseberg, Klaus; Koelbing, Marlene; Schreiber, Dominik-Philip; Wagner, Michael; Wech, Christoph; Zivanovic, Jovan; Simos, Dimitris E.			Applying Pairwise Combinatorial Testing to Large Language Model Testing	TESTING SOFTWARE AND SYSTEMS, ICTSS 2023	Lecture Notes in Computer Science		English	Proceedings Paper	35th IFIP WG 6.1 International Conference on Testing Software and Systems (ICTSS)	SEP 18-20, 2023	Bergamo, ITALY	Int Federat Informat Proc WG 6 1		large language models; combinatorial testing		In this paper, we report on applying combinatorial testing to large language models (LLMs) testing. Our aim is to pioneer the usage of combinatorial testing to be used in the realm of LLMs, e.g. for the generation of additional training or test data. We first describe how to create an input parameter model for the input of an LLM. Based on a given original sentence, we derive new sentences by replacing words with synonyms according to a combinatorial test set, leading to a specified level of coverage over synonyms while attaining an efficient diversification. Assuming that the semantics of the original sentence are retained in the derived sentences, we construct a test oracle based on existing annotations. In an experimental evaluation, we apply generated pairwise sentence test sets from the BoolQ benchmark set [4] against two LLMs (T5 [12] and LLaMa [15]). Having automated our approach for test sentence generation, as well as their execution and analysis, our experimental evaluations demonstrate the applicability of pairwise combinatorial testing methods to LLMs.	[Garn, Bernhard; Kampel, Ludwig; Leithner, Manuel; Celic, Berina; Culha, Ceren; Hiess, Irene; Kieseberg, Klaus; Koelbing, Marlene; Schreiber, Dominik-Philip; Wagner, Michael; Wech, Christoph; Zivanovic, Jovan; Simos, Dimitris E.] SBA Res, MATRIS Res Grp, A-1040 Vienna, Austria		Kampel, L (corresponding author), SBA Res, MATRIS Res Grp, A-1040 Vienna, Austria.	matris@sba-research.org; lkampel@sba-research.org		Wagner, Michael/0000-0002-2524-6539	BMK; BMAW; federal state of Vienna; U.S. Department of Commerce, National Institute of Standards and Technology [70NANB21H124]	BMK; BMAW; federal state of Vienna; U.S. Department of Commerce, National Institute of Standards and Technology(National Institute of Standards & Technology (NIST) - USA)	SBA Research (SBA-K1) is a COMET Center within the COMET -Competence Centers for Excellent Technologies Programme and funded by BMK, BMAW, and the federal state of Vienna. The COMET Programme is managed by FFG. Moreover, this work was performed partly under the following financial assistance award 70NANB21H124 from U.S. Department of Commerce, National Institute of Standards and Technology.	Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Bozic J, 2022, SOFTWARE QUAL J, V30, P227, DOI 10.1007/s11219-020-09544-9; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; Gardner M, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1307; Grindal M, 2007, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P255; Guichard J, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING (AITEST), P55, DOI 10.1109/AITest.2019.000-7; Jang ME, 2023, Arxiv, DOI arXiv:2303.06273; Khashabi D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P163; Kuhn D., 2013, Chapman & Hall/CRC Innovations in Software Engineering and Software Development Series; Nie CH, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1883612.1883618; Raffel C, 2020, J MACH LEARN RES, V21; Ruane E, 2018, COMPANION OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES (IUI'18), DOI 10.1145/3180308.3180373; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wagner M, 2020, IEEE ICST WORKSHOP, P191, DOI 10.1109/ICSTW50294.2020.00041; Wotawa F., 2021, CEUR WORKSHOP P, V2808	17	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-43239-2; 978-3-031-43240-8	LECT NOTES COMPUT SC			2023	14131						247	256		10.1007/978-3-031-43240-8_16	http://dx.doi.org/10.1007/978-3-031-43240-8_16			10	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5KO					2024-07-03	WOS:001162334100017
C	Kumagai, H; Yamaki, R; Naganuma, H			ACM	Kumagai, Haruka; Yamaki, Ryosuke; Naganuma, Hiroki			Story-to-Images Translation: Leveraging Diffusion Models and Large Language Models for Sequence Image Generation	PROCEEDINGS OF THE 2ND WORKSHOP ON USER-CENTRIC NARRATIVE SUMMARIZATION OF LONG VIDEOS, NARSUM 2023			English	Proceedings Paper	2nd Workshop on User-Centric Narrative Summarization of Long Videos (NarSUM)	OCT 29, 2023	Ottawa, CANADA	Assoc Comp Machinery, ACM SIGMM		large language model; diffusion model; text-to-image generation		Diffusion models are catalyzing breakthroughs in creative fields, with a notable impact on text-to-image generation. This study centers on the transformation of textual narratives into coherent sequences of images-a process currently hampered by issues of consistency and contextual fidelity. To address these challenges, we propose a method utilizing a large language model, with an emphasis on context and character information. Empirical evaluations, carried out using Hollywood movie scripts, clearly indicate that our approach improves both the consistency and contextual fidelity of the resulting image sequences.	[Kumagai, Haruka] Univ Tokyo, Tokyo, Japan; [Yamaki, Ryosuke] Ritsumeikan Univ, Shiga, Japan; [Yamaki, Ryosuke; Naganuma, Hiroki] ProPlace Inc, Tokyo, Japan; [Naganuma, Hiroki] Univ Montreal, Mila, Montreal, PQ, Canada	University of Tokyo; Ritsumeikan University; Universite de Montreal	Kumagai, H (corresponding author), Univ Tokyo, Tokyo, Japan.	kumagai@hal.t.u-tokyo.ac.jp; yamaki.ryosuke@em.ci.ritsumei.ac.jp; naganuma.hiroki@mila.quebec						Akyürek E, 2023, Arxiv, DOI arXiv:2211.15661; Antoniadis I, 2020, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2020/04/033; Chen WH, 2022, Arxiv, DOI arXiv:2209.14491; Conwell C, 2022, Arxiv, DOI [arXiv:2208.00005, DOI 10.48550/ARXIV.2208.00005]; Gal R, 2022, Arxiv, DOI [arXiv:2208.01618, 10.48550/arXiv.2208.01618]; Goodfellow I., 2014, P 28 C NEURAL INFORM, P2672, DOI DOI 10.1145/3422622; Gupta T, 2018, LECT NOTES COMPUT SC, V11212, P610, DOI 10.1007/978-3-030-01237-3_37; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li CY, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102956; Li YT, 2019, PROC CVPR IEEE, P6322, DOI 10.1109/CVPR.2019.00649; Maharana A, 2022, LECT NOTES COMPUT SC, V13697, P70, DOI 10.1007/978-3-031-19836-6_5; Maharana A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2427; Maharana A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6772; Pan Xichen, 2022, arXiv; Radford A, 2021, PR MACH LEARN RES, V139; Rahman T, 2023, PROC CVPR IEEE, P2493, DOI 10.1109/CVPR52729.2023.00246; Ramesh A., 2022, arXiv; Ramesh A, 2021, PR MACH LEARN RES, V139; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Ruiz N, 2023, PROC CVPR IEEE, P22500, DOI 10.1109/CVPR52729.2023.02155; Saharia C., 2022, Advances in Neural Information Processing Systems, V35, P36479; Schuhmann C., 2022, arXiv; Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256; von Oswald J, 2022, Arxiv, DOI arXiv:2212.07677; Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143; Yu Jiahui, 2022, Scaling Autoregressive Models for Content-Rich Textto-Image Generation; Zeng G., 2019, P 2019 3 INT C COMPU; Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629	28	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0277-8				2023							57	63		10.1145/3607540.3617144	http://dx.doi.org/10.1145/3607540.3617144			7	Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW2TK					2024-07-03	WOS:001125005500009
J	Sorin, V; Kiang, E				Sorin, Vera; Kiang, Eyal			The Emergence Phenomenon in Artificial Intelligence: A Warning Sign on the Path to Artificial General Intelligence	ISRAEL MEDICAL ASSOCIATION JOURNAL			English	Review						autonomous learning; ethical implications; emergence phenomenon; generative adversarial networks; large language models		Large language models have revolutionized natural language processing. The emergence phenomenon is observed in these models and has the potential to revolutionize data processing and management. In this review, we discuss the concept of emergence in artificial intelligence, give detailed examples, and elaborate on the risks and limitations of large language models. The review exposes physicians to large language models, their advantages, and the inherent opportunities. We also describe the limitations and dangers, as these models are expected to impact medicine soon.	[Sorin, Vera; Kiang, Eyal] Sheba Med Ctr, Dept Diagnost Imaging, IL-52621 Tel Hashomer, Israel; [Sorin, Vera; Kiang, Eyal] Sheba Med Ctr, Deep Vis Lab, Tel Hashomer, Israel; [Kiang, Eyal] Sheba Med Ctr, ARC Innovat Ctr, Tel Hashomer, Israel; [Sorin, Vera; Kiang, Eyal] Tel Aviv Univ, Fac Med, Tel Aviv, Israel; [Kiang, Eyal] lcahn Sch Med Mt Sinai, New York, NY USA	Chaim Sheba Medical Center; Chaim Sheba Medical Center; Chaim Sheba Medical Center; Tel Aviv University	Sorin, V (corresponding author), Sheba Med Ctr, Dept Diagnost Imaging, IL-52621 Tel Hashomer, Israel.	verasrn@gmail.com						Brin D., 2023, medRxiv; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chaudhry HJ, 2020, JAMA-J AM MED ASSOC, V323, P2017, DOI 10.1001/jama.2020.3198; Harari Y, 2023, New York Times; Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572; Kivelson S, 2016, NPJ QUANTUM MATER, V1, DOI 10.1038/npjquantmats.2016.24; Sorin V., 2023, medRxiv; Sorin V, 2023, EUR J RADIOL, V167, DOI 10.1016/j.ejrad.2023.111085; Sorin V, 2020, ACAD RADIOL, V27, P1175, DOI 10.1016/j.acra.2019.12.024; Temsah Mohamad-Hani, 2023, Cureus, V15, pe44769, DOI 10.7759/cureus.44769; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]	11	0	0	13	13	ISRAEL MEDICAL ASSOC JOURNAL	RAMAT GAN	2 TWIN TOWERS, 11TH FL, 35 JABOTINSKY ST, PO BOX 3604, RAMAT GAN 52136, ISRAEL	1565-1088			ISR MED ASSOC J	Isr. Med. Assoc. J.	FEB	2024	26	2					120	121						2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	KG3P4	38420985				2024-07-03	WOS:001178768800009
J	Li, PY; Castelo, N; Katona, Z; Sarvary, M				Li, Peiyao; Castelo, Noah; Katona, Zsolt; Sarvary, Miklos			Frontiers: Determining the Validity of Large Language Models for Automated Perceptual Analysis	MARKETING SCIENCE			English	Article						artificial Intelligence; perceptual maps; language model; natural language processing; market research		This paper explores the potential of large language models (LLMs) to substitute for human participants in market research. Such LLMs can be used to generate text given a prompt. We argue that perceptual analysis is a particularly promising use case for such automated market research for certain product categories. The proposed new method generates outputs that closely match those generated from human surveys: agreement rates between human- and LLM- generated data sets reach over 75%. Moreover, this applies for perceptual analysis based on both brand similarity measures and product attribute ratings. The paper demonstrates that, for some categories, this new method of fully or partially automated market research will increase the efficiency of market research by meaningfully speeding up the process and potentially reducing the cost. Further results also suggest that with an ever larger training corpus applied to large language models, LLM-based market research will be applicable to answer more nuanced questions based on demographic variables or contextual variation that would be prohibitively expensive or infeasible with human respondents.	[Li, Peiyao; Katona, Zsolt] Univ Calif Berkeley, Haas Sch Business, Berkeley, CA 94720 USA; [Castelo, Noah] Univ Alberta, Alberta Sch Business, Edmonton, AB T6G 2R6, Canada; [Sarvary, Miklos] Columbia Univ, Columbia Business Sch, New York, NY 10027 USA	University of California System; University of California Berkeley; University of Alberta; Columbia University	Katona, Z (corresponding author), Univ Calif Berkeley, Haas Sch Business, Berkeley, CA 94720 USA.	ojhfklsjhl@berkeley.edu; ncastelo@ualberta.ca; zskatona@haas.berkeley.edu; miklos.sarvary@columbia.edu		Sarvary, Miklos/0000-0002-3301-5917	Social Sciences and Humanities Research Council of Canada [430-2021-00057]	Social Sciences and Humanities Research Council of Canada(Social Sciences and Humanities Research Council of Canada (SSHRC))	Funding: This work was supported by the Social Sciences and Humanities Research Council of Canada [Grant 430-2021-00057] .	Atari M, 2023, WHICH HUMANS WORKING; Berger J, 2022, MARKET LETT, V33, P365, DOI 10.1007/s11002-022-09635-6; Brand J, 2023, USING GPT FOR MARKET; Culotta A, 2016, MARKET SCI, V35, P343, DOI 10.1287/mksc.2015.0968; Dzyabura D, 2021, J MARKETING, V85, P44, DOI 10.1177/0022242921996661; Espejel J.L., 2023, Nat. Lang. Process. J, V5, P100032, DOI DOI 10.1016/J.NLP.2023.100032; Horton JJ, 2023, 31122 NBER; Humphreys A, 2018, J CONSUM RES, V44, P1274, DOI 10.1093/jcr/ucx104; Jain L, 2016, PROC NEURIPS, P2720; Kleindessner M., 2014, Proceedings of The 27th Conference on Learning Theory, P40; Liu J, 2018, MARKET SCI, V37, P930, DOI 10.1287/mksc.2018.1112; Liu L, 2020, MARKET SCI, V39, P669, DOI 10.1287/mksc.2020.1226; Matthe M, 2023, MARKET SCI, V42, P589, DOI 10.1287/mksc.2022.1385; Netzer O, 2012, MARKET SCI, V31, P521, DOI 10.1287/mksc.1120.0713; Ouyang L, 2022, PROC NEURIPS, P1; Radford A., 2018, IMPROVING LANGUAGE U; Timoshenko A, 2019, MARKET SCI, V38, P1, DOI 10.1287/mksc.2018.1123; Tirunillai S, 2014, J MARKETING RES, V51, P463, DOI 10.1509/jmr.12.0106; Vaswani A, 2017, ADV NEUR IN, V30	19	1	1	122	122	INFORMS	CATONSVILLE	5521 RESEARCH PARK DR, SUITE 200, CATONSVILLE, MD 21228 USA	0732-2399	1526-548X		MARKET SCI	Mark. Sci.	MAR-APR	2024	43	2								10.1287/mksc.2023.0454	http://dx.doi.org/10.1287/mksc.2023.0454		JAN 2024	14	Business	Social Science Citation Index (SSCI)	Business & Economics	LM6E7					2024-07-03	WOS:001153071500001
J	Barile, J; Margolis, A; Cason, G; Kim, R; Kalash, S; Tchaconas, A; Milanaik, R				Barile, Joseph; Margolis, Alex; Cason, Grace; Kim, Rachel; Kalash, Saia; Tchaconas, Alexis; Milanaik, Ruth			Diagnostic Accuracy of a Large Language Model in Pediatric Case Studies	JAMA PEDIATRICS			English	Article								This diagnostic/prognostic study evaluates the accuracy of a large language model against physician diagnoses in pediatric cases.	[Barile, Joseph; Margolis, Alex; Cason, Grace; Kim, Rachel; Kalash, Saia; Tchaconas, Alexis; Milanaik, Ruth] Cohen Childrens Med Ctr, New Hyde Pk, NY USA; [Barile, Joseph] Cohen Childrens Med Ctr, 1983 Marcus Ave,Ste 130, New Hyde Pk, NY 11042 USA	Northwell Health; North Shore University Hospital; Steven & Alexandra Cohen Children's Medical Center of New York; Northwell Health; North Shore University Hospital; Steven & Alexandra Cohen Children's Medical Center of New York	Barile, J (corresponding author), Cohen Childrens Med Ctr, 1983 Marcus Ave,Ste 130, New Hyde Pk, NY 11042 USA.	jgbarile5@gmail.com						Capoot A., 2023, CNBC; Jacobsen A, 2017, JAMA PEDIATR, V171, P89, DOI 10.1001/jamapediatrics.2016.1565; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8	6	6	6	23	23	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6203	2168-6211		JAMA PEDIATR	JAMA Pediatr.	MAR	2024	178	3					313	315		10.1001/jamapediatrics.2023.5750	http://dx.doi.org/10.1001/jamapediatrics.2023.5750		MAR 2024	3	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	LC5X2	38165685				2024-07-03	WOS:001136984300004
C	Srinivasan, R; Inakoshi, H; Uchino, K			IEEE	Srinivasan, Ramya; Inakoshi, Hiroya; Uchino, Kanji			Leveraging Cognitive Science for Testing Large Language Models	2023 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE TESTING, AITEST	IEEE International Conference on Artificial Intelligence Testing		English	Proceedings Paper	5th IEEE International Conference on Artificial Intelligence Testing (AITest)	JUL 17-20, 2023	Harokopio Univ Athens, Athens, GREECE	IEEE, IEEE Comp Soc	Harokopio Univ Athens	large language models; AI audit; common-sense reasoning; cognitive science		Cognitive science related research offers valuable knowledge for the design, development, and evaluation of artificial intelligence (AI) systems. In this short position paper, leveraging first principles from cognitive science, we propose novel methods for testing pre-trained large language models (LLMs), specifically to assess their common sense reasoning abilities. The test cases are meant to aid in assessing the model's ability 1) to analyze various dimensions of a prototype, and 2) to discover subtle and implied meanings (e.g. proverbs) across languages. We hope the ideas presented in the paper will spark interdisciplinary discussions concerning robust audit and evaluation of LLMs.	[Srinivasan, Ramya; Uchino, Kanji] Fujitsu Res Amer, Minato City, Tokyo, Japan; [Inakoshi, Hiroya] Fujitsu Res, Kawasaki, Kanagawa, Japan		Srinivasan, R (corresponding author), Fujitsu Res Amer, Minato City, Tokyo, Japan.							Blodgett Su Lin, 2020, Language (technology) is power: A critical survey of "bias"in NLP; Campbell D.T., 1963, EXPT QUASIEXPERIMENT; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Emelin D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P698; Huang LF, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2391; Kelley Harold H., 1992, ANNU REV PSYCHOL; Kelly G.A., 1955, The psychology of personal constructs; Lin S, 2021, arXiv; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rosch E., 1978, Cognition and Categorization, P27, DOI DOI 10.1016/B978-1-4832-1446-7.50028-5; Trichelair P, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3382; WEGNER D.M., 1981, Social cognition: Perspectives on everyday understanding; Zhang Sheng, 2018, Record: Bridging the gap between human and machine commonsense reading comprehension	13	0	0	7	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2835-3552		979-8-3503-3629-0	Artific Intel Test			2023							169	171		10.1109/AITest58265.2023.00035	http://dx.doi.org/10.1109/AITest58265.2023.00035			3	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV6SV					2024-07-03	WOS:001062490100024
J	Biegelbauer, P; Schindler, A; Conde-Jimenez, R; Weinlinger, P				Biegelbauer, Peter; Schindler, Alexander; Conde-Jimenez, Rodrigo; Weinlinger, Pia			Exciting Opportunities and Necessary Safeguards for Large Language Models in the Public Sector	ERCIM NEWS			English	Article								Large Language Models (LLMs) have the potential to support the civil service. They can be used to automate tasks such as document classification, summarisation, and translation, among others. However, there are also risks and challenges associated with their use.	[Biegelbauer, Peter; Schindler, Alexander; Conde-Jimenez, Rodrigo; Weinlinger, Pia] AIT Austrian Inst Technol, Seibersdorf, Austria	Austrian Institute of Technology (AIT)	Biegelbauer, P; Schindler, A (corresponding author), AIT Austrian Inst Technol, Seibersdorf, Austria.	peter.biegelbauer@ait.ac.at; alexander.schindler@ait.ac.at						EU High-Level Expert Group on Artificial Intelligence, 2020, Assessment List for Trustworthy Artificial Intelligence (ALTAI) for self-assessment; OECD Council, 2019, Recommendation on Artificial Intelligence; UNESCO, 2021, Recommendations on Ethics of Artificial Intelligence	3	0	0	1	1	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					25	26						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500014
C	Wang, S; Scells, H; Zhuang, SY; Potthast, M; Koopman, B; Zuccon, G		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Wang, Shuai; Scells, Harrisen; Zhuang, Shengyao; Potthast, Martin; Koopman, Bevan; Zuccon, Guido			Zero-Shot Generative Large Language Models for Systematic Review Screening Automation	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Systematic Reviews; Document Classification; Large Language Models	WORKLOAD	Systematic reviews are crucial for evidence-based medicine as they comprehensively analyse published research findings on specific questions. Conducting such reviews is often resource- and time-intensive, especially in the screening phase, where abstracts of publications are assessed for inclusion in a review. This study investigates the effectiveness of using zero-shot large language models (LLMs) for automatic screening. We evaluate the effectiveness of eight different LLMs and investigate a calibration technique that uses a predefined recall threshold to determine whether a publication should be included in a systematic review. Our comprehensive evaluation using five standard test collections shows that instruction fine-tuning plays an important role in screening, that calibration renders LLMs practical for achieving a targeted recall, and that combining both with an ensemble of zero-shot models saves significant screening time compared to state-of-the-art approaches.	[Wang, Shuai; Zuccon, Guido] Univ Queensland, Brisbane, Qld, Australia; [Scells, Harrisen; Potthast, Martin] Univ Leipzig, Leipzig, Germany; [Zhuang, Shengyao; Koopman, Bevan] CSIRO, Canberra, ACT, Australia; [Potthast, Martin] ScaDS AI, Leipzig, Germany	University of Queensland; Leipzig University; Commonwealth Scientific & Industrial Research Organisation (CSIRO)	Wang, S (corresponding author), Univ Queensland, Brisbane, Qld, Australia.	shuai.wang2@uq.edu.au; harry.scells@uni-leipzig.de; shengyao.zhuang@csiro.com; martin.potthast@uni-leipzig.de; b.koopman@csiro.com; g.zuccon@uq.edu.au						Abualsaud M, 2018, ACM/SIGIR PROCEEDINGS 2018, P1317, DOI 10.1145/3209978.3210176; Alharbi A., 2017, CEUR Workshop Proceedings; Alharbi A., 2018, CEUR Workshop Proceedings, V2125; Alshami A, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11070351; Anagnostou A., 2017, CEUR Workshop Proceedings; Aum S, 2021, SYST REV-LONDON, V10, DOI 10.1186/s13643-021-01763-w; Bramer WM, 2017, SYST REV-LONDON, V6, DOI 10.1186/s13643-017-0644-y; Callaghan MW, 2020, SYST REV-LONDON, V9, DOI 10.1186/s13643-020-01521-4; Carvallo A, 2020, Arxiv, DOI [arXiv:2012.00584, DOI 10.48550/ARXIV.2012.00584]; Carvallo A, 2020, SCIENTOMETRICS, V125, P3047, DOI 10.1007/s11192-020-03648-6; Chen J., 2017, CEUR Workshop Proceedings; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Clark J., 2013, Methods of Clinical Epidemiology, P187, DOI DOI 10.1007/978-3-642-37131-812; Cohen Aaron M, 2010, AMIA Annu Symp Proc, V2010, P121; Cohen AM, 2006, J AM MED INFORM ASSN, V13, P206, DOI 10.1197/jamia.M1929; Collaboration C., 2002, The cochrane library. Database available on disk and CDROM; Crumley Ellen T, 2005, BMC Med Res Methodol, V5, P24, DOI 10.1186/1471-2288-5-24; Cumpston M, 2019, COCHRANE DB SYST REV, DOI 10.1002/14651858.ED000142; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Di Nunzio G.M., 2017, CEUR Workshop Proceedings; Di Nunzio G.M., 2018, CEUR Workshop Proceed- ings; Kanoulas E., 2017, CEUR Workshop Proceedings; Kanoulas E., 2019, CEUR Workshop Proceedings, V2380; Kanoulas Evangelos, 2018, CEUR WORKSHOP P; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Lagopoulos A, 2018, LECT NOTES COMPUT SC, V11018, P52, DOI 10.1007/978-3-319-98932-7_5; Lee GE, 2018, ACM/SIGIR PROCEEDINGS 2018, P455, DOI 10.1145/3209978.3209994; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lu Yao, 2021, arXiv; Minas A., 2018, CEUR Workshop Proceedings; Miwa M, 2014, J BIOMED INFORM, V51, P242, DOI 10.1016/j.jbi.2014.06.005; Norman CR, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1162-x; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Robinson A, 2023, Arxiv, DOI arXiv:2308.06610; Scells Harrisen, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P399, DOI 10.1007/978-3-030-45439-5_27; Scells Harrisen, 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P385, DOI 10.1007/978-3-030-45439-5_26; Scells H., 2017, CEUR Workshop Proceedings; Scells H, 2021, INFORM RETRIEVAL J, V24, P3, DOI 10.1007/s10791-020-09381-1; Scells H, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1071, DOI 10.1145/3366423.3380185; Scells H, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P1646, DOI 10.1145/3308558.3313544; Syriani E., 2023, arXiv; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thomas J, 2008, BMC MED RES METHODOL, V8, DOI 10.1186/1471-2288-8-45; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wallace BC., 2012, P 2 ACM SIGHIT INT H, P819, DOI [DOI 10.1145/2110363.2110464, 10.1145/2110363.2110464]; Wallace BC, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-55; Wang Shuai, 2023, WSDM '23: Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, P1176, DOI 10.1145/3539597.3573025; Wang S., 2022, P 26 AUSTR DOC COMP, P1; Wang S., 2022, Intell. Syst. Appl; Wang S., 2021, P 25 AUSTR DOC COMP, P1; Wang S, 2023, Arxiv, DOI arXiv:2309.05238; Wang S, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1426, DOI 10.1145/3539618.3591703; Wang S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3176, DOI 10.1145/3477495.3531748; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; White Jacob, 2020, Medical Reference Services Quarterly, V39, P382, DOI 10.1080/02763869.2020.1826228; Wu H., 2018, Methods-a Companion Methods Enzymol., V4, P7; Xu YH, 2023, Arxiv, DOI arXiv:2309.14717; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Yang E, 2022, LECT NOTES COMPUT SC, V13185, P502, DOI 10.1007/978-3-030-99736-6_34; Zhang RH, 2024, Arxiv, DOI arXiv:2304.11872; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zou J, 2018, ACM/SIGIR PROCEEDINGS 2018, P949, DOI 10.1145/3209978.3210102	63	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56026-2; 978-3-031-56027-9	LECT NOTES COMPUT SC			2024	14608						403	420		10.1007/978-3-031-56027-9_25	http://dx.doi.org/10.1007/978-3-031-56027-9_25			18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DX		Green Submitted			2024-07-03	WOS:001211830500025
C	Franco, M; Gaggi, O; Palazzi, CE			ACM	Franco, Mirko; Gaggi, Ombretta; Palazzi, Claudio E.			Analyzing the Use of Large Language Models for Content Moderation with ChatGPT Examples	PROCEEDINGS OF THE 2023 WORKSHOP ON OPEN CHALLENGES IN ONLINE SOCIAL NETWORKS, OASIS 2023/ 34TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, HT 2023			English	Proceedings Paper	Workshop on Open Challenges in Online Social Networks (OASIS)	SEP 04-08, 2023	Rome, ITALY			content moderation; harmful content; large language models		Content moderation systems are crucial in Online Social Networks (OSNs). Indeed, their role is to keep platforms and their users safe from malicious activities. However, there is an emerging consensus that such systems are unfair to fragile users and minorities. Furthermore, content moderation systems are difficult to personalize and lack effective communication between users and platforms. In this context, we propose an enhancement of the current framework of content moderation, integrating Large Language Models (LLMs) in the enforcing pipeline.	[Franco, Mirko; Gaggi, Ombretta; Palazzi, Claudio E.] Univ Padua, Dept Math, Padua, Italy	University of Padua	Franco, M (corresponding author), Univ Padua, Dept Math, Padua, Italy.	mirko.franco@math.unipd.it; gaggi@math.unipd.it; cpalazzi@math.unipd.it	Franco, Mirko/GOV-3071-2022	Franco, Mirko/0000-0002-6140-8558	European Space Agency's (ESA) project "QUIC over Satellite" (QUICoS) [4000138640/22/NL/AF]; Italian Ministry of University and Research (MUR)	European Space Agency's (ESA) project "QUIC over Satellite" (QUICoS); Italian Ministry of University and Research (MUR)(Ministry of Education, Universities and Research (MIUR))	The authors of this paper acknowledge the support of the European Space Agency's (ESA) project "QUIC over Satellite" (QUICoS) https://artes.esa.int/projects/quicos, contract n. 4000138640/22/NL/AF and of the Italian Ministry of University and Research (MUR) under the PON ex DM 1061 and the PNRR CN-MOST initiatives. Responsibility of the contents resides with the authors.	Abokhodair N, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P672, DOI 10.1145/2901790.2901873; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ali Shiza, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579608; Arora A, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3603399; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Canales Katie, 2021, Facebook's AI moderation reportedly can't interpret many languages, leaving users in some countries more susceptible to harmful posts; Counts S, 2010, LIBR INFORM SCI RES, V32, P98, DOI 10.1016/j.lisr.2009.10.003; Falduti Mattia, 2022, GoodIT 2022: Conference on Information Technology for Social Good, P96, DOI 10.1145/3524458.3547247; Franco Mirko, 2022, GoodIT 2022: Conference on Information Technology for Social Good, P138, DOI 10.1145/3524458.3547259; Franco M, 2024, IEEE T MOBILE COMPUT, V23, P1613, DOI 10.1109/TMC.2023.3238189; Franco M, 2023, FUTURE GENER COMP SY, V145, P211, DOI 10.1016/j.future.2023.03.025; Franco Mirko, 2022, 2022 IEEE 19 ANN CON, P1, DOI [10.1109/Communications&NetworkingConference(CCNC49033.2022.9700555, DOI 10.1109/COMMUNICATIONS&NETWORKINGCONFERENCE(CCNC49033.2022.9700555]; Guidi B, 2020, MULTIMED TOOLS APPL, V79, P33603, DOI 10.1007/s11042-019-08494-0; Guidi B, 2020, PERVASIVE MOB COMPUT, V62, DOI 10.1016/j.pmcj.2020.101131; Haimson Oliver L., 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479610; Halevy A, 2022, COMMUN ACM, V65, P92, DOI 10.1145/3462671; Li YF, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376498; Liu C, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3547299; Olson J., 2005, Extended Abstracts on Human Factors in Computing Systems (CHI EA), P1985, DOI [DOI 10.1145/1056808.1057073, 10.1145/1056808.1057073]; Qin W, 2023, Arxiv, DOI arXiv:2305.05138; Rubegni E, 2019, PROCEEDINGS OF ACM INTERACTION DESIGN AND CHILDREN (IDC 2019), P386, DOI 10.1145/3311927.3323156; Shahid F, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581538; Sharif A, 2022, PROCEEDINGS OF THE 24TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, ASSETS 2022, DOI 10.1145/3517428.3544813; Stratta M, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3383029; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaccaro Kristen, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3476059; Vishwamitra N, 2022, CODASPY'22: PROCEEDINGS OF THE TWELVETH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P65, DOI 10.1145/3508398.3511517; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	29	4	4	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0225-9				2023							1	8		10.1145/3599696.3612895	http://dx.doi.org/10.1145/3599696.3612895			8	Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2OD		hybrid			2024-07-03	WOS:001122672400001
C	Soru, T; Marshall, J			IEEE	Soru, Tommaso; Marshall, Jim			Trend Extraction and Analysis via Large Language Models	18TH IEEE INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, ICSC 2024	IEEE International Conference on Semantic Computing		English	Proceedings Paper	18th IEEE International Conference on Semantic Computing (ICSC)	FEB 05-07, 2024	Laguna Hills, CA	IEEE, IEEE Comp Soc		artificial intelligence; information extraction; large language models; trend analysis; foresight; futures studies		In the ever-evolving landscape of data-driven decision making, the ability to accurately extract and analyse trends has become a cornerstone for strategic planning across various domains. The advent of Large Language Models has ushered in a new era of potential in this realm, presenting sophisticated tools that can parse, interpret, and forecast trends from vast repositories of textual data. This paper seeks to explore the application of language models on trend extraction and analysis, highlighting the transformative impact these models have on extracting actionable insights from unstructured data sources. Additionally, ours is the first work towards the creation of a time-based dataset of trends to enable the backtesting of AI algorithms and models on short- and long-term foresight.	[Soru, Tommaso; Marshall, Jim] Serendipity AI Ltd, London, England		Soru, T (corresponding author), Serendipity AI Ltd, London, England.	tom@serendipityai.com; jim@serendipityai.com						Bell W., 2009, Human science for a new era, V1; de Jouvenel B., 2017, ART CONJECTURE; Feng ZY, 2023, Arxiv, DOI arXiv:2311.05876; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Linden A., 2003, Strategic Analysis Report No R-20-1971, V88, P1423; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Soru T., 2023, KNOWLEDGE GRAPH C KG, DOI [10.5281/zenodo.7908658, DOI 10.5281/ZENODO.7908658]; Toffler A., 1970, Future Shock; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]	11	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2325-6516		979-8-3503-8535-9	IEEE INT C SEMANT CO			2024							285	288		10.1109/ICSC59802.2024.00051	http://dx.doi.org/10.1109/ICSC59802.2024.00051			4	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7TH					2024-07-03	WOS:001196221400045
J	Zhao, S; Chen, SH; Zhou, JY; Li, C; Tang, T; Harris, SJ; Liu, Y; Wan, JY; Li, X				Zhao, Shuo; Chen, Sihui; Zhou, Jiayi; Li, Chao; Tang, Tan; Harris, Stephen J.; Liu, Yang; Wan, Jiayu; Li, Xin			Potential to transform words to watts with large language models in battery research	CELL REPORTS PHYSICAL SCIENCE			English	Article							CHALLENGES; ANODE	Conventional battery research often grapples with the challenge of accumulating scattered knowledge and information across countless academic resources, including papers, lectures, conferences, and more. This dispersed wealth of information spans a variety of modalities, further limiting the efficiency of literature review and methodology comparison, hindering the rapid advancement of energy storage technologies. In this perspective, we cover progress and introduce a paradigm shift catalyzed by large language models. The paradigm harnesses the power of natural language processing and artificial intelligence to enable rapid information synthesis and swift insight extraction. To illustrate the transformative potential, we present a practical demonstration of a comprehensive literature review in fast charging powered by ChatGPT, showcasing how the proposed paradigm can streamline the process of synthesizing information from a vast array of sources. This perspective underscores the profound impact of large language models on battery research, ushering in an era of efficiency and accelerated innovation in energy storage technologies.	[Zhao, Shuo; Liu, Yang; Li, Xin] Duke Kunshan Univ, Data Sci Res Ctr, 8 Duke Ave, Kunshan 215316, Jiangsu, Peoples R China; [Chen, Sihui; Li, Chao; Wan, Jiayu] Shanghai Jiao Tong Univ, Global Inst Future Technol, Future Battery Res Ctr, Shanghai 200240, Peoples R China; [Zhou, Jiayi] Zhejiang Univ, Lab Art & Archaeol Image, Hangzhou 310028, Zhejiang, Peoples R China; [Harris, Stephen J.] Lawrence Berkeley Natl Lab, Energy Storage & Distributed Resources Div, Berkeley, CA 94720 USA	Duke Kunshan University; Shanghai Jiao Tong University; Zhejiang University; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory	Liu, Y; Li, X (corresponding author), Duke Kunshan Univ, Data Sci Res Ctr, 8 Duke Ave, Kunshan 215316, Jiangsu, Peoples R China.; Wan, JY (corresponding author), Shanghai Jiao Tong Univ, Global Inst Future Technol, Future Battery Res Ctr, Shanghai 200240, Peoples R China.	yang.liu2@dukekunshan.edu.cn; wanjy@sjtu.edu.cn; xinli.ece@duke.edu		zhao, shuo/0000-0001-8075-8521				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed S, 2017, J POWER SOURCES, V367, P250, DOI 10.1016/j.jpowsour.2017.06.055; Bagheri M, 2019, ENERGIES, V12, DOI 10.3390/en12030373; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai WL, 2020, SMALL STRUCT, V1, DOI 10.1002/sstr.202000010; Carter R, 2022, JOULE, V6, P2447, DOI 10.1016/j.joule.2022.10.019; Chao DL, 2020, JOULE, V4, P1846, DOI 10.1016/j.joule.2020.07.023; Chen KH, 2020, J POWER SOURCES, V471, DOI 10.1016/j.jpowsour.2020.228475; Collin R, 2019, ENERGIES, V12, DOI 10.3390/en12101839; Dufek EJ, 2022, J POWER SOURCES, V526, DOI 10.1016/j.jpowsour.2022.231129; Gao HP, 2023, ADV ENERGY MATER, V13, DOI 10.1002/aenm.202202906; Gurung A, 2018, JOULE, V2, P1217, DOI 10.1016/j.joule.2018.04.006; Jochem P, 2019, TRANSPORT RES D-TR E, V73, P120, DOI 10.1016/j.trd.2019.06.005; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kazyak E, 2022, ADV ENERGY MATER, V12, DOI 10.1002/aenm.202102618; Keyser M, 2017, J POWER SOURCES, V367, P228, DOI 10.1016/j.jpowsour.2017.07.009; Kim DS, 2019, J POWER SOURCES, V422, P18, DOI 10.1016/j.jpowsour.2019.03.027; Kim DS, 2017, ELECTROCHIM ACTA, V258, P336, DOI 10.1016/j.electacta.2017.11.056; Lee MJ, 2017, NANO LETT, V17, P3744, DOI 10.1021/acs.nanolett.7b01076; Lee SM, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20297-8; Lee S, 2015, ANGEW CHEM INT EDIT, V54, P9452, DOI 10.1002/anie.201504466; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li GX, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202002891; Liang YR, 2019, INFOMAT, V1, P6, DOI 10.1002/inf2.12000; Liu T, 2021, J POWER SOURCES, V511, DOI 10.1016/j.jpowsour.2021.230466; Liu YT, 2023, JOULE, V7, DOI 10.1016/j.joule.2023.04.006; Liu YY, 2019, NAT ENERGY, V4, P540, DOI 10.1038/s41560-019-0405-3; Lu LL, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm6624; Manthiram A, 2017, ACS CENTRAL SCI, V3, P1063, DOI 10.1021/acscentsci.7b00288; Mathieu R, 2021, APPL ENERG, V283, DOI 10.1016/j.apenergy.2020.116344; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patil RS, 2019, J ELECTROCHEM SOC, V166, pA1185, DOI 10.1149/2.0901906jes; Paul PP, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202100372; Placke T, 2018, JOULE, V2, P2528, DOI 10.1016/j.joule.2018.09.003; Qian J, 2022, ACS NANO, V16, P20197, DOI 10.1021/acsnano.2c05428; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Romera-Paredes B, 2024, NATURE, V625, DOI 10.1038/s41586-023-06924-6; Saxena S, 2017, IEEE IND ELECTRON M, V11, P35, DOI 10.1109/MIE.2017.2688483; Shafiei M, 2022, J ENERGY STORAGE, V49, DOI 10.1016/j.est.2022.104136; Srdic S, 2019, IEEE ELECTRIF MAG, V7, P22, DOI 10.1109/MELE.2018.2889547; Sun CC, 2022, ADV MATER, V34, DOI 10.1002/adma.202206020; Tanim TR, 2022, ADV ENERGY MATER, V12, DOI 10.1002/aenm.202202795; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tomaszewska A, 2019, ETRANSPORTATION, V1, DOI 10.1016/j.etran.2019.100011; Tu SB, 2023, NAT ENERGY, V8, P1365, DOI 10.1038/s41560-023-01387-5; Tu SB, 2022, ADV MATER, V34, DOI 10.1002/adma.202202892; Vaswani A, 2017, ADV NEUR IN, V30; Bin Wali S, 2021, J ENERGY STORAGE, V35, DOI 10.1016/j.est.2021.102296; Wang CY, 2022, NATURE, V611, P485, DOI 10.1038/s41586-022-05281-0; Wassiliadis N, 2021, J ENERGY STORAGE, V44, DOI 10.1016/j.est.2021.103306; Xia DW, 2023, ACS ENERGY LETT, DOI 10.1021/acsenergylett.2c02590; Xie WL, 2020, J ENERGY STORAGE, V32, DOI 10.1016/j.est.2020.101837; Xu HY, 2021, ADV ENERGY MATER, V11, DOI 10.1002/aenm.202003908; Yang XG, 2022, ONE EARTH, V5, P216, DOI 10.1016/j.oneear.2022.02.012; Yang XG, 2019, JOULE, V3, P3002, DOI 10.1016/j.joule.2019.09.021; Zeng YQ, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-38823-9; Zhang SJ, 2022, ADV ENERGY MATER, V12, DOI 10.1002/aenm.202103888; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819; Zhu GL, 2019, SMALL, V15, DOI 10.1002/smll.201805389	60	1	1	0	0	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2666-3864		CELL REP PHYS SCI	Cell Rep. Phys. Sci.	MAR 20	2024	5	3							101844	10.1016/j.xcrp.2024.101844	http://dx.doi.org/10.1016/j.xcrp.2024.101844			12	Chemistry, Multidisciplinary; Energy & Fuels; Materials Science, Multidisciplinary; Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Energy & Fuels; Materials Science; Physics	PM1A4		gold			2024-07-03	WOS:001214392400001
J	Neuhaus, F				Neuhaus, Fabian			Ontologies in the era of large language models - a perspective	APPLIED ONTOLOGY			English	Article						Ontology development; large language model; ChatGPT; Bard; Copilot		The potential of large language models (LLM) has captured the imagination of the public and researchers alike. In contrast to previous generations of machine learning models, LLMs are general-purpose tools, which can communicate with humans. In particular, they are able to define terms and answer factual questions based on some internally represented knowledge. Thus, LLMs support functionalities that are closely related to ontologies. In this perspective article, I will discuss the consequences of the advent of LLMs for the field of applied ontology.	[Neuhaus, Fabian] Otto von Guericke Univ, Inst Intelligent Cooperating Syst, Magdeburg, Germany	Otto von Guericke University	Neuhaus, F (corresponding author), Otto von Guericke Univ, Inst Intelligent Cooperating Syst, Magdeburg, Germany.	fneuhaus@ovgu.de						Ashburner M, 2000, NAT GENET, V25, P25, DOI 10.1038/75556; Asim MN, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay101; Bennett M, 2013, J BANK REGUL, V14, P255, DOI 10.1057/jbr.2013.13; Booshehri M, 2021, ENERGY AI, V5, DOI 10.1016/j.egyai.2021.100074; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Caufield J.H., 2023, Structured prompt interrogation and recursive extraction of semantics (SPIRES): A method for populating knowledge bases using; Chen QY, 2024, Arxiv, DOI [arXiv:2305.16326, 10.48550/arXiv.2305.16326, DOI 10.48550/ARXIV.2305.16326]; Chui M., 2023, The economic potential of generative AI; Giglou HB, 2023, LECT NOTES COMPUT SC, V14265, P408, DOI 10.1007/978-3-031-47240-4_22; Glauer M., Semantic Web Journal; Glauer M, 2023, FRONT ARTIF INTEL AP, V369, P460, DOI 10.3233/FAIA230153; Hastings J., Cosmos + Taxis; Hastings J, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00500-8; Hastings J, 2016, NUCLEIC ACIDS RES, V44, pD1214, DOI 10.1093/nar/gkv1031; Hunt T., 2023, Scientific American; Landgrebe J., 2022, Why Machines Will Never Rule the World: Artificial Intelligence without Fear; Lenat D., 2001, HAL's Legacy, P193, DOI [10.7551/mitpress/3404.001.0001, DOI 10.7551/MITPRESS/3404.001.0001]; Lopes A, 2023, KNOWL-BASED SYST, V265, DOI 10.1016/j.knosys.2023.110385; Mateiu P, 2023, Arxiv, DOI [arXiv:2307.16699, 10.48550/ARXIV.2307.16699]; Neuhaus F, 2022, APPL ONTOL, V17, P495, DOI 10.3233/AO-220273; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302	21	0	0	13	13	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	1570-5838	1875-8533		APPL ONTOL	Appl. Ontol.		2023	18	4					399	407		10.3233/AO-230072	http://dx.doi.org/10.3233/AO-230072			9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	IP4G7					2024-07-03	WOS:001167514400004
J	Jovanovic, M; Campbell, M				Jovanovic, Mladan; Campbell, Mark			Connecting AI: Merging Large Language Models and Knowledge Graph	COMPUTER			English	Article						Artificial intelligence; Knowledge graphs; Linguistics		Combining the generative abilities of large language models with the logical and factual coherence of knowledge graphs using a connected artificial intelligence architecture minimizes each system's shortcomings and amplifies their strengths across many real-world domains.	[Jovanovic, Mladan] Singidunum Univ, Belgrade 11000, Serbia; [Campbell, Mark] EVOTEK, San Diego, CA 92121 USA		Jovanovic, M (corresponding author), Singidunum Univ, Belgrade 11000, Serbia.	mjovanovic@singidunum.ac.rs; mark@evotek.com		Campbell, Mark/0000-0001-5415-6631; Jovanovic, Mladjan/0000-0003-2355-9424				[Anonymous], Fiddler introduces end-to-end workflow for robust generative AI; [Anonymous], 2022, Cognitive AI research: Higher machine intelligence for nextgen AI; Caufield JH, 2023, Arxiv, DOI arXiv:2304.02711; Espinoza V., 2023, MediumMar.; Garcez AD, 2023, ARTIF INTELL REV, V56, P12387, DOI 10.1007/s10462-023-10448-w; Nguyen HL, 2020, INFORM FUSION, V61, P56, DOI 10.1016/j.inffus.2020.03.014; Hsieh CY, 2023, Arxiv, DOI arXiv:2305.02301; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jovanovic M, 2022, COMPUTER, V55, P90, DOI 10.1109/MC.2021.3127753; Kotseruba I, 2020, ARTIF INTELL REV, V53, P17, DOI 10.1007/s10462-018-9646-y; Li MM, 2022, NAT BIOMED ENG, V6, P1353, DOI 10.1038/s41551-022-00942-x; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mok A., 2023, Bus. Insider; Ouyang L., 2022, Advances in Neural Information Processing Systems, P744; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Peng CY, 2023, ARTIF INTELL REV, V56, P13071, DOI 10.1007/s10462-023-10465-9; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Scarlini B, 2020, AAAI CONF ARTIF INTE, V34, P8758; Shao PP, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107841; Tabir A., 2023, MediumApr.; Tworkowski S, 2023, Arxiv, DOI arXiv:2307.03170; Voss P., 2023, Aigo.ai; Wang BX, 2024, Arxiv, DOI arXiv:2306.11698; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Wei J., 2022, P 36 C NEUR INF PROC; Wiggers K., LlamaIndex adds private data to large language models; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]	27	1	1	86	89	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	NOV	2023	56	11					103	108		10.1109/MC.2023.3305206	http://dx.doi.org/10.1109/MC.2023.3305206			6	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CF0R2		Bronze			2024-07-03	WOS:001123723300013
J	Rocchietti, G; Muntean, CI; Nardini, FM				Rocchietti, Guido; Muntean, Cristina Ioana; Nardini, Franco Maria			Enhancing Conversational Search with Large Language Models	ERCIM NEWS			English	Article								In the context of the Horizon Europe EFRA research project [L1], we explore the innovative use of Large Language Models (LLMs), both instructed and fine-tuned, in improving the quality of conversational search. The focus is on applying these models in rewriting conversational utterances to enhance the capability of conversational agents to retrieve accurate responses.	[Rocchietti, Guido; Muntean, Cristina Ioana; Nardini, Franco Maria] CNR, ISTI, Pisa, Italy	Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)	Rocchietti, G (corresponding author), CNR, ISTI, Pisa, Italy.; Rocchietti, G (corresponding author), Univ Pisa, Pisa, Italy.	guido.rocchietti@isti.cnr.it						Galimzhanova E., 2023, P 22 IEEE WIC INT C	1	0	0	0	0	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					33	34						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500019
J	Shojaee-Mend, H; Mohebbati, R; Amiri, M; Atarodi, A				Shojaee-Mend, Hassan; Mohebbati, Reza; Amiri, Mostafa; Atarodi, Alireza			Evaluating the strengths and weaknesses of large language models in answering neurophysiology questions	SCIENTIFIC REPORTS			English	Article						Large language models; Neurophysiology; Evaluation; Bloom's taxonomy		Large language models (LLMs), like ChatGPT, Google's Bard, and Anthropic's Claude, showcase remarkable natural language processing capabilities. Evaluating their proficiency in specialized domains such as neurophysiology is crucial in understanding their utility in research, education, and clinical applications. This study aims to assess and compare the effectiveness of Large Language Models (LLMs) in answering neurophysiology questions in both English and Persian (Farsi) covering a range of topics and cognitive levels. Twenty questions covering four topics (general, sensory system, motor system, and integrative) and two cognitive levels (lower-order and higher-order) were posed to the LLMs. Physiologists scored the essay-style answers on a scale of 0-5 points. Statistical analysis compared the scores across different levels such as model, language, topic, and cognitive levels. Performing qualitative analysis identified reasoning gaps. In general, the models demonstrated good performance (mean score = 3.87/5), with no significant difference between language or cognitive levels. The performance was the strongest in the motor system (mean = 4.41) while the weakest was observed in integrative topics (mean = 3.35). Detailed qualitative analysis uncovered deficiencies in reasoning, discerning priorities, and knowledge integrating. This study offers valuable insights into LLMs' capabilities and limitations in the field of neurophysiology. The models demonstrate proficiency in general questions but face challenges in advanced reasoning and knowledge integration. Targeted training could address gaps in knowledge and causal reasoning. As LLMs evolve, rigorous domain-specific assessments will be crucial for evaluating advancements in their performance.	[Shojaee-Mend, Hassan; Amiri, Mostafa] Gonabad Univ Med Sci, Fac Med, Dept Gen Courses, Gonabad, Iran; [Mohebbati, Reza] Gonabad Univ Med Sci, Fac Med, Dept Physiol, Gonabad, Iran; [Amiri, Mostafa] Mashhad Univ Med Sci, Sch Med, Dept English Language & Gen Courses, Mashhad, Iran; [Atarodi, Alireza] Gonabad Univ Med Sci, Paramed Coll, Dept Knowledge & Informat Sci, Gonabad, Iran; [Atarodi, Alireza] Gonabad Univ Med Sci, Social Dev & Hlth Promot Res Ctr, Gonabad, Iran	Mashhad University Medical Science	Atarodi, A (corresponding author), Gonabad Univ Med Sci, Paramed Coll, Dept Knowledge & Informat Sci, Gonabad, Iran.; Atarodi, A (corresponding author), Gonabad Univ Med Sci, Social Dev & Hlth Promot Res Ctr, Gonabad, Iran.	aratarodi1387@yahoo.com						Agarwal M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40977; Ahmed I., 2023, ChatGPT vs. Bard: A comparative study; Banerjee A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43314; Crowe A, 2008, CBE-LIFE SCI EDUC, V7, P368, DOI 10.1187/cbe.08-05-0024; Dhanvijay AKD, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42972; Duong D, 2024, EUR J HUM GENET, V32, P466, DOI 10.1038/s41431-023-01396-8; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Heston TF., 2023, Int. Med. Educ., V2, P198, DOI [DOI 10.3390/IME2030019, 10.3390/ime2030019]; Khorshidi Hamid, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101314; Kojima T, 2022, ADV NEUR IN; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lim S, 2023, FRONT COMMUN, V8, DOI 10.3389/fcomm.2023.1129082; Loconte R., 2023, Intelligence, V2023, P145; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Puchert P, 2023, Arxiv, DOI arXiv:2304.00457; Rakhmonova S., 2023, Innov. Dev. Educ. Activit, V2, P94; Schubert MC, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.46721; Schubert MC., 2023, MedRxiv, V42, P39; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Tan TF, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100394; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tuckute G, 2024, NAT HUM BEHAV, V8, DOI 10.1038/s41562-023-01783-7; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Wei JS, 2022, ADV NEUR IN	27	0	0	2	2	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2045-2322			SCI REP-UK	Sci Rep	MAY 11	2024	14	1							10785	10.1038/s41598-024-60405-y	http://dx.doi.org/10.1038/s41598-024-60405-y			10	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	QJ4X3	38734712	Green Submitted, gold			2024-07-03	WOS:001220505100042
J	Wang, SJ; Ni, L; Zhang, ZY; Li, XX; Zheng, XD; Liu, JM				Wang, Sijie; Ni, Lin; Zhang, Zeyu; Li, Xiaoxuan; Zheng, Xianda; Liu, Jiamou			Multimodal prediction of student performance: A fusion of signed graph neural networks and large language models	PATTERN RECOGNITION LETTERS			English	Article						Signed network; Graph representations learning; Natural language processing; Multimodal		In online education platforms, accurately predicting student performance is essential for timely dropout prevention and interventions for at -risk students. This task is made difficult by the prevalent use of MultipleChoice Questions (MCQs) in learnersourcing platforms, where noise in student -generated content and the limitations of existing unsigned graph -based models, specifically their inability to distinguish the semantic meaning between correct and incorrect responses, hinder accurate performance predictions. To address these issues, we introduce the Large Language Model enhanced Signed Bipartite graph Contrastive Learning (LLMSBCL) model-a novel Multimodal Model utilizing Signed Graph Neural Networks (SGNNs) and a Large Language Model (LLM). Our model uses a signed bipartite graph to represent students' answers, with positive and negative edges denoting correct and incorrect responses, respectively. To mitigate noise impact, we apply contrastive learning to the signed graphs, combined with knowledge point embeddings from the LLM to further enhance our model's predictive performance. Upon evaluating our model on five real -world datasets, it demonstrates superior accuracy and stability, exhibiting an average F1 improvement of 3.7% over the best baseline models.	[Wang, Sijie; Zhang, Zeyu] Huazhong Agr Univ, Wuhan 430070, Peoples R China; [Wang, Sijie; Ni, Lin; Li, Xiaoxuan; Zheng, Xianda; Liu, Jiamou] Univ Auckland, Sch Comp Sci, Auckland 1010, New Zealand	Huazhong Agricultural University; University of Auckland	Zhang, ZY (corresponding author), Huazhong Agr Univ, Wuhan 430070, Peoples R China.	swan387@aucklanduni.ac.nz; lni600@aucklanduni.ac.nz; zzha669@aucklanduni.ac.nz; xli443@aucklanduni.ac.nz; xzhe162@aucklanduni.ac.nz; jiamou.liu@auckland.ac.nz			Fundamental Research Funds for the Central Universities, China [2662023XXQD003]; Mars-den Fund Council through Government [MFP-UOA2123]; National Natural Science Foundation of China [62172077]	Fundamental Research Funds for the Central Universities, China(Fundamental Research Funds for the Central Universities); Mars-den Fund Council through Government; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the Fundamental Research Funds for the Central Universities, China [Project 2662023XXQD003] , the Mars-den Fund Council through Government funding [MFP-UOA2123] , and the National Natural Science Foundation of China [62172077] .	Abdi S, 2021, LAK21 CONFERENCE PROCEEDINGS: THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P497, DOI 10.1145/3448139.3448189; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; CARTWRIGHT D, 1956, PSYCHOL REV, V63, P277, DOI 10.1037/h0046049; Cygan M, 2012, LECT NOTES COMPUT SC, V7464, P296, DOI 10.1007/978-3-642-32589-2_28; Denny P., 2022, arXiv, DOI DOI 10.1145/3501385.3543957; Denny P., 2008, Proc. 10th Australasian Computing Education Conference, V78, P69, DOI [10.5555/1379249.1379255, DOI 10.5555/1379249.1379255]; Derr T, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1221, DOI 10.1145/3357384.3358009; Derr T, 2018, IEEE DATA MINING, P929, DOI 10.1109/ICDM.2018.00113; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Huang JJ, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P740, DOI 10.1145/3459637.3482392; Huang JJ, 2021, Arxiv, DOI arXiv:2101.02390; Jung JH, 2020, Arxiv, DOI arXiv:2012.14191; Khosravi H, 2021, LAK21 CONFERENCE PROCEEDINGS: THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P32, DOI 10.1145/3448139.3448143; Kim J, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P509, DOI 10.1145/3178876.3186117; Kunegis J., 2010, P 2010 SIAM INT C DA, P559; Li HT, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2589, DOI 10.1145/3340531.3412733; Li MR, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105174; Li Y, 2020, AAAI CONF ARTIF INTE, V34, P4772; Mo YJ, 2023, IEEE T KNOWL DATA EN, V35, P12814, DOI 10.1109/TKDE.2023.3268069; Mulryan-Kyne C, 2010, TEACH HIGH EDUC, V15, P175, DOI 10.1080/13562511003620001; Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]; Ni L, 2022, AAAI CONF ARTIF INTE, P12826; Nicol DJ, 2006, STUD HIGH EDUC, V31, P199, DOI 10.1080/03075070600572090; O'Dea X, 2022, BRIT J EDUC TECHNOL, V53, P437, DOI 10.1111/bjet.13211; Paramythis A., 2003, Second european conference on e-learning, V1, P369; Peng L, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3230979; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Qiu JZ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1150, DOI 10.1145/3394486.3403168; Raffel C, 2020, J MACH LEARN RES, V21; Ren ZY, 2016, Arxiv, DOI arXiv:1605.02269; Riggs CD, 2020, CBE-LIFE SCI EDUC, V19, DOI 10.1187/cbe.19-09-0189; Shu L, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P1671, DOI 10.1145/3459637.3482478; Shuai J, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1283, DOI 10.1145/3477495.3531927; Sohn K, 2016, ADV NEUR IN, V29; Tang J., 2016, P 2016 SIAM INT C DA, P54, DOI [10.1137/1.9781611974348.7, 10.1137/1.9781611974348.7.1, DOI 10.1137/1.9781611974348.7.1, https://doi.org/10.1137/1.9781611974348.7, DOI 10.1137/1.9781611974348.7]; Thaker K, 2019, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE (LAK'19), P111, DOI 10.1145/3303772.3303817; van den Oord A, 2019, Arxiv, DOI [arXiv:1807.03748, DOI 10.48550/ARXIV.1807.03748]; Vaswani A, 2017, ADV NEUR IN, V30; Velickovic P., ICLR; Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903; Wang S., 2017, P 2017 SIAM INT C DA, P327; Weisfeiler Boris, 1968, NTI SERIES, V2, P12; Xie YC, 2023, IEEE T PATTERN ANAL, V45, P2412, DOI 10.1109/TPAMI.2022.3170559; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420; Ye M., 2019, P IEEECVF C COMPUTER, P6210; You Y., 2020, ADV NEURAL INFORM PR, V33, P5812, DOI DOI 10.48550/ARXIV.2010.13902; Zhang ZY, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1629, DOI 10.1145/3539618.3591655; Zheng D. B., 2015, P 2015 SIAM INT C DA, P55; Zhou J, 2020, AI OPEN, V1, P57, DOI 10.1016/j.aiopen.2021.01.001; Zhu Y., 2020, ICML WORKSH GRAPH RE; Zhu YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P2069, DOI 10.1145/3442381.3449802	51	0	0	7	7	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0167-8655	1872-7344		PATTERN RECOGN LETT	Pattern Recognit. Lett.	MAY	2024	181						1	8		10.1016/j.patrec.2024.03.007	http://dx.doi.org/10.1016/j.patrec.2024.03.007			8	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QF9J8					2024-07-03	WOS:001219579000001
J	Zyda, M				Zyda, Michael			Large Language Models and Generative AI, Oh My!	COMPUTER			English	Article								Artificial intelligence (AI) has a miserable reputation regarding promises made and results delivered. Last century, there were many AI winters. The hype surrounding large language models and generative AI could join this trend, we do not hope.	[Zyda, Michael] Univ Southern Calif, Dept Comp Sci, Comp Sci Games Program, Los Angeles, CA 90089 USA; [Zyda, Michael] Univ Southern Calif, Dept Comp Sci, Engn Practice, Los Angeles, CA 90089 USA	University of Southern California; University of Southern California	Zyda, M (corresponding author), Univ Southern Calif, Dept Comp Sci, Comp Sci Games Program, Los Angeles, CA 90089 USA.; Zyda, M (corresponding author), Univ Southern Calif, Dept Comp Sci, Engn Practice, Los Angeles, CA 90089 USA.	zyda@mikezyda.com		Zyda, Mike/0000-0002-7154-9231				[Anonymous], What are large language models (LLM)?; [Anonymous], AI winter; [Anonymous], Generative AI startups; [Anonymous], Generative AI; [Anonymous], DALL-E; [Anonymous], 2023, Financial TimesSep.; Browne R., 2023, CNBCDec.; Midjourney, ABOUT US; Mullin B., 2023, NY TimesDec.; Uszkoreit J., TRANSFORMER NOVEL NE; Zyda M, 2023, COMPUTER, V56, P131, DOI 10.1109/MC.2023.3267986	11	1	1	17	17	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	MAR	2024	57	3					127	132		10.1109/MC.2024.3350290	http://dx.doi.org/10.1109/MC.2024.3350290			6	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KN7E5		Bronze			2024-07-03	WOS:001180702200012
C	Bao, XY; Zhao, YB			ACM	Bao, Xiying; Zhao, Yubo			Narratron: Collaborative Writing and Shadow-playing of Children Stories with Large Language Models	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		large language models; shadow play; storytelling; human-AI collaboration		Shadow puppetry or shadow play, allows bodily participation into the process of linguistic storytelling, while the potential of multimodal interaction through shadow plays in existing large-language-model-based creative tools has not been fully discovered. We propose Narratron, a generative story-making tool that co-creates and co-performs children stories from shadow using Claude 2 model. To achieve Narratron, our system is designed to recognize hand gestural inputs as main character and to develop story plot in accordance with character change. Through our system, we seek to stimulate creativity in shadow play storytelling and to facilitate a multi-modal human-AI collaboration.	[Bao, Xiying] Harvard Univ, Cambridge, MA 02138 USA; [Zhao, Yubo] Univ Washington, Seattle, WA USA	Harvard University; University of Washington; University of Washington Seattle	Bao, XY (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.	xiying_bao@gsd.harvard.edu; yubozhao@uw.edu						Alcober Fred, 2018, ShadowPlay: Using our hands to have some fun with AI; [Anonymous], 2017, Google; Bhandari P, 2023, Arxiv, DOI arXiv:2308.00073; Brown S., 2004, Art Education, V57, P47, DOI DOI 10.1080/00043125.2004.11653576; Hahn L, 2022, J MEDIA PSYCHOL-GER, V34, P165, DOI 10.1027/1864-1105/a000307; Razumovskaia E, 2024, Arxiv, DOI arXiv:2212.10471; Stability AI, 2023, Generative Models by Stability AI; Taylor SV, 2020, EARLY CHILD EDUC J, V48, P1, DOI 10.1007/s10643-019-00974-0	8	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									119	10.1145/3586182.3625120	http://dx.doi.org/10.1145/3586182.3625120			6	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000118
C	Salikutluk, V; Koert, D; Jäkel, F		Lukowicz, P; Mayer, S; Koch, J; Shawe-Taylor, J; Tiddi, I		Salikutluk, Vildan; Koert, Dorothea; Jaekel, Frank			Interacting with Large Language Models: A Case Study on AI-Aided Brainstorming for Guesstimation Problems	HHAI 2023: AUGMENTING HUMAN INTELLECT	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	2nd International Conference on Hybrid Human-Artificial Intelligence (HHAI)	JUN 26-30, 2023	Munich, GERMANY	Munich Ctr Machine Learning, German Entrepreneurship, AI Journal, MDPI, Multimodal Technologies & Interact		Human-AI Interaction; Guesstimation; Large Language Models	ACCURACY	Designing cooperative AI-systems that do not automate tasks but rather aid human cognition is challenging and requires human-centered design approaches. Here, we introduce AI-aided brainstorming for solving guesstimation problems, i.e. estimating quantities from incomplete information, as a testbed for human-AI interaction with large language models (LLMs). In a think-aloud study, we found that humans decompose guesstimation questions into sub-questions and often replace them with semantically related ones. If they fail to brainstorm related questions, they often get stuck and do not find a solution. Therefore, to support this brainstorming process, we prompted a large language model (GPT-3) with successful replacements from our think-aloud data. In follow-up studies, we tested whether the availability of this tool improves participants' answers. While the tool successfully produced human-like suggestions, participants were reluctant to use it. From our findings, we conclude that for human-AI interaction with LLMs to be successful AI-systems must complement rather than mimic a user's associations.	[Salikutluk, Vildan; Koert, Dorothea; Jaekel, Frank] Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany	Technical University of Darmstadt	Salikutluk, V (corresponding author), Tech Univ Darmstadt, Ctr Cognit Sci, Darmstadt, Germany.	vildan.salikutluk@tu-darmstadt.de		Salikutluk, Vildan/0000-0001-7913-7349; Koert, Dorothea/0000-0002-3571-6848	German Federal Ministry of Education and Research [01IS20045]	German Federal Ministry of Education and Research(Federal Ministry of Education & Research (BMBF))	The authors thank Alexandra Kraft, Adrian Kuhn and Thabo Matthies for their help in parts of the experimental setup and data acquisition as well as Andreas Stuhlmuller and the Ought team for their help and access to Elicit. This work was funded by German Federal Ministry of Education and Research (project IKIDA, 01IS20045).	Abourbih JA, 2009, Method and system for semi-automatic guesstimation; Abourbih JA, 2010, P AAAI SPRING S SERI, P2; Albarracín L, 2015, TEACH MATH APPL, V34, P223, DOI 10.1093/teamat/hrv006; Albarracín L, 2014, EDUC STUD MATH, V86, P79, DOI 10.1007/s10649-013-9528-9; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; Anantrasirichai N, 2022, ARTIF INTELL REV, V55, P589, DOI 10.1007/s10462-021-10039-7; Arleback JB, 2019, ZDM-MATH EDUC, V51, P979, DOI 10.1007/s11858-019-01075-3; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bansal GG, 2021, AAAI CONF ARTIF INTE, V35, P11405; Bundy A, 2015, SEMANT WEB, V6, P197, DOI 10.3233/SW-130127; Campero A., 2022, A Test for Evaluating Performance in Human-Computer Systems; Chen M., 2021, arXiv; Chun Tie Y, 2019, SAGE OPEN MED, V7, DOI 10.1177/2050312118822927; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Elkins Katherine, 2020, Journal of Cultural Analytics, V5, P1, DOI DOI 10.22148/001C.17212; Evans O, 2018, FHI 018-2; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Grace K, 2018, J ARTIF INTELL RES, V62, P729, DOI 10.1613/jair.1.11222; Haran U, 2013, JUDGM DECIS MAK, V8, P188; Heath H, 2004, INT J NURS STUD, V41, P141, DOI 10.1016/S0020-7489(03)00113-5; Holstein K, 2021, Arxiv, DOI arXiv:2104.01266; Koch J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300863; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Lewkowycz Aitor, 2022, arXiv; Li Q., 2018, The International Journal of Digital Accounting Research, V18, P119; Li Y., 2022, PREPRINT; Liu JC, 2021, Arxiv, DOI arXiv:2101.06804; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Matheson R, 2019, Automating artificial intelligence for medical decision-making; McGufe K, 2020, arXiv; Meister C, 2022, Arxiv, DOI arXiv:2202.00666; Mellers B, 2015, PERSPECT PSYCHOL SCI, V10, P267, DOI 10.1177/1745691615577794; Mellers B, 2015, J EXP PSYCHOL-APPL, V21, P1, DOI 10.1037/xap0000040; Mirowski PW, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581225; Ninareh Mehrabi, 2022, A Survey on Bias and Fairness in Machine Learning, DOI 10.48550/arXiv.1908.09635; OpenAI. OpenAI, 2022, ChatGPT: Optimizing Language Models for Dialogue; Ought Inc, 2022, Elicit: The AI Research Assistant; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Ozbal G., 2013, P 51 ANN M ASS COMP, V1, P1446; Paritosh P.K., 2004, P 18 INT WORKSHOP QU; Paritosh PK, 2005, P 20 NATL C ARTIFICI, P651; Press O, 2023, Arxiv, DOI arXiv:2210.03350; Reppert J, 2023, Arxiv, DOI arXiv:2301.01751; Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445; Steyvers M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2111547119; Stuhlmuller A, 2022, Factored Cognition Primer: How to write compositional language model programs; Swartz C E., 2003, Back-of-the-Envelope Physics; Tetlock Philip, 2015, Superforecasting: The Art and Science of Prediction; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS; Vaughan JW, 2018, J MACH LEARN RES, V18; Weinstein L., 2008, Guesstimation: Solving the World's Problems on the Back of a Cocktail Napkin; Weinstein L., 2012, Guesstimation 2.0; Wilder B, 2020, Arxiv, DOI arXiv:2005.00582; Xu W., 2019, interactions, V26, P42, DOI [DOI 10.1145/3328485, 10.1145/3328485]; Xu W, 2022, Arxiv, DOI arXiv:2105.05424; Yang Q, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300415; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105	57	0	0	7	7	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-394-2; 978-1-64368-395-9	FRONT ARTIF INTEL AP			2023	368						153	167		10.3233/FAIA230081	http://dx.doi.org/10.3233/FAIA230081			15	Computer Science, Artificial Intelligence	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KF		hybrid			2024-07-03	WOS:001150361600011
J	Mouret, JB				Mouret, Jean-Baptiste			Large language models help computer programs to evolve	NATURE			English	Editorial Material						Computer science; Mathematics and computing		A branch of computer science known as genetic programming has been given a boost with the application of large language models that are trained on the combined intuition of the world's programmers.	[Mouret, Jean-Baptiste] Univ Lorraine, French Natl Inst Res Digital Sci & Technol INRIA, F-54000 Nancy, France; [Mouret, Jean-Baptiste] French Natl Res Agcy, CNRS, F-54000 Nancy, France	Universite de Lorraine; Centre National de la Recherche Scientifique (CNRS)	Mouret, JB (corresponding author), Univ Lorraine, French Natl Inst Res Digital Sci & Technol INRIA, F-54000 Nancy, France.; Mouret, JB (corresponding author), French Natl Res Agcy, CNRS, F-54000 Nancy, France.	jean-baptiste.mouret@inria.fr						[Anonymous], 2002, Behind Deep Blue. Building the Computer That Defeated the World Chess Champion; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; Le Goues C, 2012, PROC INT CONF SOFTW, P3, DOI 10.1109/ICSE.2012.6227211; Lehman J., 2024, Handbook of Evolutionary Machine Learning; Meyerson E, 2024, Arxiv, DOI [arXiv:2302.12170, 10.48550/arXiv.2302.12170, DOI 10.48550/ARXIV.2302.12170]; Romera-Paredes B, 2024, NATURE, V625, DOI 10.1038/s41586-023-06924-6; Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961	8	0	0	14	14	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JAN 18	2024	625	7995					452	453		10.1038/d41586-023-03998-0	http://dx.doi.org/10.1038/d41586-023-03998-0			2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HC4Q2	38233614				2024-07-03	WOS:001157281900030
J	Takemoto, K				Takemoto, Kazuhiro			The moral machine experiment on large language models	ROYAL SOCIETY OPEN SCIENCE			English	Article						moral machine; large language models; ChatGPT; autonomous driving	DEATH DECISIONS; LIFE	As large language models (LLMs) have become more deeply integrated into various sectors, understanding how they make moral judgements has become crucial, particularly in the realm of autonomous driving. This study used the moral machine framework to investigate the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2 and Llama 2, to compare their responses with human preferences. While LLMs' and humans' preferences such as prioritizing humans over pets and favouring saving more lives are broadly aligned, PaLM 2 and Llama 2, especially, evidence distinct deviations. Additionally, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared with the milder inclinations of humans. These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving.	[Takemoto, Kazuhiro] Kyushu Inst Technol, Dept Biosci & Bioinformat, Iizuka, Fukuoka 8208502, Japan	Kyushu Institute of Technology	Takemoto, K (corresponding author), Kyushu Inst Technol, Dept Biosci & Bioinformat, Iizuka, Fukuoka 8208502, Japan.	takemoto@bio.kyutech.ac.jp	Takemoto, Kazuhiro/H-2915-2019	Takemoto, Kazuhiro/0000-0002-6355-1366	Japan Society for the Promotion of Science	Japan Society for the Promotion of Science(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of Science)	We thank Editage (www.editage.jp) for English language editing.	Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Awad E, 2020, NATURE, V579, pE3, DOI 10.1038/s41586-020-1988-3; Awad E, 2018, NATURE, V563, P59, DOI 10.1038/s41586-018-0637-6; Bigman YE, 2020, NATURE, V579, pE1, DOI 10.1038/s41586-020-1987-4; Bostrom N, 2018, Artificial intelligence safety and security, P57; Bruers S, 2014, PHILOSOPHIA, V42, P251, DOI 10.1007/s11406-013-9507-5; Chen H, 2023, SCI CHINA INFORM SCI, V66, DOI 10.1007/s11432-023-3740-x; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Dewitt B, 2019, NATURE, V567, P31, DOI 10.1038/d41586-019-00766-x; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Ferrara E, 2023, Arxiv, DOI [arXiv:2304.03738, 10.48550/arXiv.2304.03738, DOI 10.48550/ARXIV.2304.03738]; Fraiwan M, 2023, Arxiv, DOI arXiv:2305.00237; Furey H., 2021, AI and Ethics, V1, P151, DOI DOI 10.1007/S43681-020-00018-Z; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Gill T, 2021, ETHICS INF TECHNOL, V23, P657, DOI 10.1007/s10676-021-09605-y; Hainmueller J, 2014, POLIT ANAL, V22, P1, DOI 10.1093/pan/mpt024; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; LaCroix T, 2022, AI Ethics, V2, P737, DOI DOI 10.1007/S43681-022-00134-Y; Lei L., 2023, Intell. Robot., V3, P145, DOI [DOI 10.20517/IR.2023.08, 10.20517/ir.2023.08]; Liesenfeld A, 2023, PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023, DOI 10.1145/3571884.3604316; Lin BY, 2023, Arxiv, DOI arXiv:2312.01552; Luetge C, 2017, Philosophy & Technology, V30, P547, DOI [10.1007/s13347-017-0284-0, DOI 10.1007/S13347-017-0284-0]; Moors G, 2008, QUAL QUANT, V42, P779, DOI 10.1007/s11135-006-9067-x; Nath R, 2020, AI SOC, V35, P103, DOI 10.1007/s00146-017-0768-6; OpenAI, 2022, OpenA I; Radford A., OpenAI Res; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schuessler D., AI Ethics, DOI [10.1007/s43681-023-00287-4, DOI 10.1007/S43681-023-00287-4]; Takemoto K., 2024, Figshare, DOI [10.6084/m9.figshare.c.7055611, DOI 10.6084/M9.FIGSHARE.C.7055611]; Takemoto Kazuhiro, 2023, Dryad, DOI 10.5061/DRYAD.D7WM37Q6V; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Triandis H. C., 1995, INDIVIDUALISM COLLEC; Yang ZJ, 2023, Arxiv, DOI arXiv:2311.01043	34	1	1	20	20	ROYAL SOC	LONDON	6-9 CARLTON HOUSE TERRACE, LONDON SW1Y 5AG, ENGLAND	2054-5703			ROY SOC OPEN SCI	R. Soc. Open Sci.	FEB 7	2024	11	2							231393	10.1098/rsos.231393	http://dx.doi.org/10.1098/rsos.231393			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HG3J1	38328569	Green Submitted, Green Published, gold			2024-07-03	WOS:001158296700002
C	Hasan, M; Ozel, C; Potter, S; Hoque, E			IEEE	Hasan, Masum; Ozel, Cengiz; Potter, Sammy; Hoque, Ehsan			SAPIEN: Affective Virtual Agents Powered by Large Language Models	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS, ACIIW			English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			Virtual Avatars; Virtual Agents; Affective AI; Large Language Models		In this demo paper, we introduce SAPIEN, a platform for high-fidelity virtual agents driven by large language models that can hold open domain conversations with users in 13 different languages, and display emotions through facial expressions and voice. The platform allows users to customize their virtual agent's personality, background, and conversation premise, thus providing a rich, immersive interaction experience. Furthermore, after the virtual meeting, the user can choose to get the conversation analyzed and receive actionable feedback on their communication skills. This paper illustrates an overview of the platform and discusses the various application domains of this technology, ranging from entertainment to mental health, communication training, language learning, education, healthcare, and beyond. Additionally, we consider the ethical implications of such realistic virtual agent representations and the potential challenges in ensuring responsible use.	[Hasan, Masum; Ozel, Cengiz; Potter, Sammy; Hoque, Ehsan] Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA	University of Rochester	Hasan, M (corresponding author), Univ Rochester, Dept Comp Sci, Rochester, NY 14627 USA.	m.hasan@rochester.edu; cozel@cs.rochester.edu; spotter14@u.rochester.edu; mehoque@cs.rochester.edu			NSF REU [IIS-1750380]	NSF REU(National Science Foundation (NSF)NSF - Office of the Director (OD))	NSF and NSF REU IIS-1750380, Seedling from Goergen Institute for Data Science (GIDS), and Gordon and Moore Foundation.	AI G., 2023, An important next step on our ai journey; Ali MR, 2023, IEEE T AFFECT COMPUT, V14, P223, DOI 10.1109/TAFFC.2021.3054717; Ali MR, 2020, PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON INTELLIGENT VIRTUAL AGENTS (ACM IVA 2020), DOI 10.1145/3383652.3423900; Ali MR, 2015, INT CONF AFFECT, P173, DOI 10.1109/ACII.2015.7344568; [Anonymous], Anthropic-introducing claude; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Fung M, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1167, DOI 10.1145/2750858.2804265; Hoque M, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P697; Hoque M, 2014, COMPUTER, V47, P28, DOI 10.1109/MC.2014.98; Hou WX, 2021, INTERSPEECH, P3425, DOI 10.21437/Interspeech.2021-57; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Lee S.-g., 2022, Priorgrad: Improving conditional denoising diffusion models with data-driven adaptive prior; Leng Y., 2021, ADV NEUR IN, V34; Li JY, 2022, APSIPA TRANS SIGNAL, V11, DOI 10.1561/116.00000050; Luo RQ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P5699, DOI 10.1109/ICASSP39728.2021.9414403; OpenAI, 2023, GPT-4 Technical Report; OpenAI, Introducing ChatGPT; Ouyang L., 2022, Advances in neural information processing systems, V35, p27 730; Razavi SZ, 2022, ACM T INTERACT INTEL, V12, DOI 10.1145/3484510; Razavi SZ, 2016, LECT NOTES ARTIF INT, V10011, P460, DOI 10.1007/978-3-319-47665-0_55; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Wang YX, 2017, Arxiv, DOI arXiv:1703.10135; Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5934, DOI 10.1109/ICASSP.2018.8461870	25	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2745-8				2023										10.1109/ACIIW59127.2023.10388188	http://dx.doi.org/10.1109/ACIIW59127.2023.10388188			3	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IG		Green Submitted			2024-07-03	WOS:001161364800078
J	Perlis, RH; Goldberg, JF; Ostacher, MJ; Schneck, CD				Perlis, Roy H.; Goldberg, Joseph F.; Ostacher, Michael J.; Schneck, Christopher D.			Clinical decision support for bipolar depression using large language models	NEUROPSYCHOPHARMACOLOGY			English	Article; Early Access							SOCIETY	Management of depressive episodes in bipolar disorder remains challenging for clinicians despite the availability of treatment guidelines. In other contexts, large language models have yielded promising results for supporting clinical decisionmaking. We developed 50 sets of clinical vignettes reflecting bipolar depression and presented them to experts in bipolar disorder, who were asked to identify 5 optimal next-step pharmacotherapies and 5 poor or contraindicated choices. The same vignettes were then presented to a large language model (GPT4-turbo; gpt-4-1106-preview), with or without augmentation by prompting with recent bipolar treatment guidelines, and asked to identify the optimal next-step pharmacotherapy. Overlap between model output and gold standard was estimated. The augmented model prioritized the expert-designated optimal choice for 508/1000 vignettes (50.8%, 95% CI 47.7-53.9%; Cohen's kappa = 0.31, 95% CI 0.28-0.35). For 120 vignettes (12.0%), at least one model choice was among the poor or contraindicated treatments. Results were not meaningfully different when gender or race of the vignette was permuted to examine risk for bias. By comparison, an un-augmented model identified the optimal treatment for 234 (23.0%, 95% CI 20.8-26.0%; McNemar's p < 0.001 versus augmented model) of the vignettes. A sample of community clinicians scoring the same vignettes identified the optimal choice for 23.1% (95% CI 15.7-30.5%) of vignettes, on average; McNemar's p < 0.001 versus augmented model. Large language models prompted with evidence-based guidelines represent a promising, scalable strategy for clinical decision support. In addition to prospective studies of efficacy, strategies to avoid clinician overreliance on such models, and address the possibility of bias, will be needed.	[Perlis, Roy H.] Massachusetts Gen Hosp, Ctr Quantitat Hlth, Boston, MA 02114 USA; [Perlis, Roy H.] Massachusetts Gen Hosp, Dept Psychiat, Boston, MA 02114 USA; [Perlis, Roy H.] Harvard Med Sch, Dept Psychiat, Boston, MA 02115 USA; [Goldberg, Joseph F.] Mt Sinai Sch Med, Dept Psychiat, New York, NY USA; [Ostacher, Michael J.] Stanford Univ, Dept Psychiat & Behav Sci, Sch Med, Palo Alto, CA USA; [Schneck, Christopher D.] Univ Colorado, Sch Med, Dept Psychiat, Aurora, CO USA	Harvard University; Massachusetts General Hospital; Harvard University; Massachusetts General Hospital; Harvard University; Harvard Medical School; Icahn School of Medicine at Mount Sinai; Stanford University; University of Colorado System; University of Colorado Anschutz Medical Campus	Perlis, RH (corresponding author), Massachusetts Gen Hosp, Ctr Quantitat Hlth, Boston, MA 02114 USA.; Perlis, RH (corresponding author), Massachusetts Gen Hosp, Dept Psychiat, Boston, MA 02114 USA.; Perlis, RH (corresponding author), Harvard Med Sch, Dept Psychiat, Boston, MA 02115 USA.	rperlis@mgh.harvard.edu		Ostacher, Michael/0000-0003-0353-7535	U.S. Department of Health & Human Services | NIH | National Institute of Mental Health (NIMH)	U.S. Department of Health & Human Services | NIH | National Institute of Mental Health (NIMH)	No Statement Available	Biazus TB, 2023, MOL PSYCHIATR, V28, P2508, DOI 10.1038/s41380-023-02109-9; Eriksen AV., 2023, NEJM AI, V1, DOI [DOI 10.1056/AIP2300031, 10.1056/AIp2300031]; Fagin R, 2006, SIAM J DISCRETE MATH, V20, P628, DOI 10.1137/05063088X; FDA Center for Devices and Radiological Health, 2022, Global Approach to Software as a Medical Device; FDA Center for Devices and Radiological Health, 2021, Artificial Intelligence and Machine Learning in Software as a Medical Device; floridabhcenter, Florida Best Practice Psychotherapeutic Medication Guidelines for Adults; Gitlin MJ, 2018, INT J BIPOLAR DISORD, V6, DOI 10.1186/s40345-018-0133-9; Goldberg JF, 2015, DEPRESS ANXIETY, V32, P605, DOI 10.1002/da.22378; Goodwin GM, 2016, J PSYCHOPHARMACOL, V30, P495, DOI 10.1177/0269881116636545; Hanna J.J., 2023, medRxiv, DOI DOI 10.1101/2023.08.28.23294730; healthquality, VA.gov | Veterans Affairs; Jacobs M, 2021, TRANSL PSYCHIAT, V11, DOI 10.1038/s41398-021-01224-x; Malhi GS, 2021, AUST NZ J PSYCHIAT, V55, P7, DOI 10.1177/0004867420979353; Pacchiarotti I, 2013, AM J PSYCHIAT, V170, P1249, DOI 10.1176/appi.ajp.2013.13020185; Perlis RH, 2023, medRxiv, DOI [10.1101/2023.04.14.23288595, 10.1101/2023.04.14.23288595, DOI 10.1101/2023.04.14.23288595]; Sakurai H, 2020, BIPOLAR DISORD, V22, P822, DOI 10.1111/bdi.12959; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Wilke L, 2014, Mathematics Honors Thesis: Comparing Partial Rankings; Yatham LN, 2018, BIPOLAR DISORD, V20, P97, DOI 10.1111/bdi.12609; Zack Travis, 2024, Lancet Digit Health, V6, pe12, DOI 10.1016/S2589-7500(23)00225-X; Zakka Cyril, 2023, Res Sq, DOI 10.21203/rs.3.rs-2883198/v1	21	0	0	3	3	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	0893-133X	1740-634X		NEUROPSYCHOPHARMACOL	Neuropsychopharmacology	2024 MAR 13	2024										10.1038/s41386-024-01841-2	http://dx.doi.org/10.1038/s41386-024-01841-2		MAR 2024	5	Neurosciences; Pharmacology & Pharmacy; Psychiatry	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Pharmacology & Pharmacy; Psychiatry	KU0K4	38480911	hybrid			2024-07-03	WOS:001182357900004
J	Vasarhelyi, MA; Moffitt, KC; Stewart, T; Sunderland, D				Vasarhelyi, Miklos A.; Moffitt, Kevin C.; Stewart, Trevor; Sunderland, Dan			Large Language Models: An Emerging Technology in Accounting	JOURNAL OF EMERGING TECHNOLOGIES IN ACCOUNTING			English	Editorial Material						generative; large language model; audit.		This commentary discusses how large language models like ChatGPT hold transformative potential in accounting, including education, research, and professional auditing. In the educational sphere, the advent of ubiquitous artificial intelligence (AI) tutors could potentially solve Bloom's Two Sigma Problem, heralding a new era of personalized learning. Accounting research stands to benefit immensely, particularly in tasks that rely heavily on natural language processing. In the professional auditing domain, the capabilities of ChatGPT to create broad outlines of risks inherent in certain accounts and assertions can enable engagement teams to create more riskresponsive audit plans. However, although the advantages are remarkable, they are accompanied by potential pitfalls that necessitate cautious navigation. Even with these challenges, AI's impending transformation in personal and professional lives cannot be overlooked, as accounting stands on the brink of significant change.	[Vasarhelyi, Miklos A.; Moffitt, Kevin C.] Rutgers State Univ, Rutgers Business Sch, Dept Accounting Informat Syst, Newark, NJ 07102 USA; [Stewart, Trevor] Deloitte, New York, NY USA; [Sunderland, Dan] Northeastern Univ, DAmore McKim Sch Business, Dept Accounting, Boston, MA USA	Rutgers University System; Rutgers University New Brunswick; Rutgers University Newark; Deloitte Touche Tohmatsu Limited; Northeastern University	Vasarhelyi, MA (corresponding author), Rutgers State Univ, Rutgers Business Sch, Dept Accounting Informat Syst, Newark, NJ 07102 USA.			vasarhelyi, miklos/0000-0003-3205-476X				BLOOM BS, 1984, EDUC LEADERSHIP, V41, P4; de Kok T., 2023, SSRN, DOI [10.2139/ssrn.4429658, DOI 10.2139/SSRN.4429658]; Doctorow C, 2023, WIRED. Jan 23; Edwards B, 2023, Study claims ChatGPT is losing capability, but some experts aren't convinced; Gu H., 2023, SSRN Electronic Journal, DOI [10.2139/ssrn.4444763, DOI 10.2139/SSRN.4444763]; Hu K., 2023, Reuters; Kang C., 2023, The New York Times16 maggio; Karpathy A., 2023, Twitter; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Patel D., 2023, We Have No Moat, And Neither Does OpenAI; Public Company Accounting Oversight Board (PCAOB), 2010, 2110 PCAOB AS; Satariano A., 2023, N.Y. TIMES June 14; Shear Michael D., 2023, N.Y. TIMESJuly 21; Stallbaumer Colette, 2023, Introducing Microsoft 365 Copilot-A whole new way to work; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yamkovenko S., 2023, Sal Khan's 2023 TED Talk: AI in the classroom can transform education	16	2	2	32	32	AMER ACCOUNTING ASSOC	Lakewood Ranch	9009 Town Center Parkway, Lakewood Ranch, FL, UNITED STATES	1554-1908	1558-7940		J EMERG TECHNOL ACCO	J. Emerg. Technol. Account.		2023	20	2					1	10		10.2308/JETA-2023-047	http://dx.doi.org/10.2308/JETA-2023-047			10	Business, Finance	Emerging Sources Citation Index (ESCI)	Business & Economics	Y6PT0					2024-07-03	WOS:001106466600012
J	Choi, H; Moran, J; Matsumoto, N; Hernandez, ME; Moore, JH				Choi, Hyunjun; Moran, Jay; Matsumoto, Nicholas; Hernandez, Miguel E.; Moore, Jason H.			Aliro: an automated machine learning tool leveraging large language models	BIOINFORMATICS			English	Article; Data Paper								Motivation Biomedical and healthcare domains generate vast amounts of complex data that can be challenging to analyze using machine learning tools, especially for researchers without computer science training.Results Aliro is an open-source software package designed to automate machine learning analysis through a clean web interface. By infusing the power of large language models, the user can interact with their data by seamlessly retrieving and executing code pulled from the large language model, accelerating automated discovery of new insights from data. Aliro includes a pre-trained machine learning recommendation system that can assist the user to automate the selection of machine learning algorithms and its hyperparameters and provides visualization of the evaluated model and data.Availability and implementation Aliro is deployed by running its custom Docker containers. Aliro is available as open-source from GitHub at: https://github.com/EpistasisLab/Aliro.	[Choi, Hyunjun; Moran, Jay; Matsumoto, Nicholas; Hernandez, Miguel E.; Moore, Jason H.] Cedars Sinai Med Ctr, Ctr Artificial Intelligence Res & Educ, Dept Computat Biomed, Hollywood, CA 90069 USA; [Moore, Jason H.] Cedars Sinai Med Ctr, Ctr Artificial Intelligence Res & Educ, Pacific Design Ctr, Dept Computat Biomed, 700 N San Vicente Blvd,Suite G-541H, West Hollywood, CA 90069 USA	Cedars Sinai Medical Center; Cedars Sinai Medical Center	Moore, JH (corresponding author), Cedars Sinai Med Ctr, Ctr Artificial Intelligence Res & Educ, Pacific Design Ctr, Dept Computat Biomed, 700 N San Vicente Blvd,Suite G-541H, West Hollywood, CA 90069 USA.	jason.moore@csmc.edu		Moore, Jason/0000-0002-5015-1099	Cedars-SinaiMedical Center,; National Institutes of Health (USA) [U01 AG066833, LM010098]	Cedars-SinaiMedical Center,; National Institutes of Health (USA)(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported in part by funds from Cedars-SinaiMedical Center, and National Institutes of Health (USA)[grant numbers U01 AG066833, LM010098].	Cava WL, 2021, BIOINFORMATICS, V37, P250, DOI 10.1093/bioinformatics/btaa698; Cremin CJ, 2022, CURR RES BIOTECHNOL, V4, P138, DOI 10.1016/j.crbiot.2022.02.004; Lundberg SM, 2017, ADV NEUR IN, V30; Olson R. S., 2016, Automated Machine Learning, P66, DOI [DOI 10.1007/978-3-030-05318-5_8, 10.1007/978-3-030-05318-5_8]; Schulman J, 2022, Introducing chatgpt; Urbanowicz RJ., 2017, Mach Learn, V106, P1687	6	0	0	5	15	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1367-4803	1367-4811		BIOINFORMATICS	Bioinformatics	OCT 3	2023	39	10							btad606	10.1093/bioinformatics/btad606	http://dx.doi.org/10.1093/bioinformatics/btad606			4	Biochemical Research Methods; Biotechnology & Applied Microbiology; Computer Science, Interdisciplinary Applications; Mathematical & Computational Biology; Statistics & Probability	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Computer Science; Mathematical & Computational Biology; Mathematics	U3DN3	37796839	gold, Green Published			2024-07-03	WOS:001083639500002
J	Bano, M; Hoda, R; Zowghi, D; Treude, C				Bano, Muneera; Hoda, Rashina; Zowghi, Didar; Treude, Christoph			Large language models for qualitative research in software engineering: exploring opportunities and challenges	AUTOMATED SOFTWARE ENGINEERING			English	Article						Large language models; LLMs; Qualitative research; Software engineering		The recent surge in the integration of Large Language Models (LLMs) like ChatGPT into qualitative research in software engineering, much like in other professional domains, demands a closer inspection. This vision paper seeks to explore the opportunities of using LLMs in qualitative research to address many of its legacy challenges as well as potential new concerns and pitfalls arising from the use of LLMs. We share our vision for the evolving role of the qualitative researcher in the age of LLMs and contemplate how they may utilize LLMs at various stages of their research experience.	[Bano, Muneera; Zowghi, Didar] CSIROs Data61, Clayton, Australia; [Hoda, Rashina] Monash Univ, Melbourne, Australia; [Treude, Christoph] Univ Melbourne, Melbourne, Australia	Commonwealth Scientific & Industrial Research Organisation (CSIRO); Monash University; University of Melbourne	Bano, M (corresponding author), CSIROs Data61, Clayton, Australia.	muneera.bano@csiro.au	Bano, Muneera/AAP-7064-2021; Treude, Christoph/AAZ-6257-2021; Zowghi, Didar/AAF-2345-2019	Bano, Muneera/0000-0002-1447-9521; Zowghi, Didar/0000-0002-6051-0155; Treude, Christoph/0000-0002-6919-2149				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Arora C, 2023, Arxiv, DOI arXiv:2310.13976; Balel Y, 2023, EUR J THER-ISTANBUL, V29, P984, DOI 10.58600/eurjther1691; Bano M, 2023, Arxiv, DOI arXiv:2306.13298; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Byun C., 2023, EXTENDED 2023 CHI C, P1; Easterbrook S., 2008, Guide to Advanced Empirical Software Engineering, P285, DOI [10.1007/978-1-84800-044-511, 10.1007/978-1-84800-044-5_11, DOI 10.1007/978-1-84800-044-5_11]; Ebert C, 2023, IEEE SOFTWARE, V40, P30, DOI 10.1109/MS.2023.3265877; Emmert-Streib F., 2023, Europ. J. Human Genet, V15, P1; Gentles SJ, 2015, QUAL REP, V20, P1772; Hoda R, 2022, IEEE T SOFTWARE ENG, V48, P3808, DOI 10.1109/TSE.2021.3106280; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Jiang DF, 2023, Arxiv, DOI arXiv:2306.02561; Kitchenham B., 2004, Keele, U.K., Keele Univ., VVolume 33, P1; Kuhail M.A., Assessing Chatgpt's Effect on Software Development and Programmer Perceptions of Ai Tools; Navigli R, 2023, ACM J DATA INF QUAL, V15, DOI 10.1145/3597307; Nguyen-Duc A, 2023, Arxiv, DOI arXiv:2310.18648; Ozkaya I, 2023, IEEE SOFTWARE, V40, P4, DOI 10.1109/MS.2023.3248401; Polonsky M.J., 2023, Should artificial intelligent agents be your co-author? Arguments in favour, informed by ChatGPT, P91; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Scoccia GL, 2023, IEEE INT CONF AUTOM, P88, DOI 10.1109/ASEW60602.2023.00016; Treude C, 2023, Arxiv, DOI arXiv:2303.10131; Watkins R., 2023, AI and Ethics, V16, P1; Watson C., 2006, QUAL RES, V6, P367	25	0	0	45	45	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0928-8910	1573-7535		AUTOMAT SOFTW ENG	Automat. Softw. Eng.	MAY	2024	31	1							8	10.1007/s10515-023-00407-8	http://dx.doi.org/10.1007/s10515-023-00407-8			12	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	CS4H8		Green Submitted			2024-07-03	WOS:001127212600001
C	Rossetto, F; Dalton, J; Murray-Smith, R			ACM	Rossetto, Federico; Dalton, Jeffrey; Murray-Smith, Roderick			Generating Multimodal Augmentations with LLMs from Song Metadata for Music Information Retrieval	PROCEEDINGS OF THE 1ST WORKSHOP ON LARGE GENERATIVE MODELS MEET MULTIMODAL APPLICATIONS, LGM3A 2023			English	Proceedings Paper	1st Workshop on Large Generative Models Meet Multimodal Applications (LGM3A)	NOV 02, 2023	Ottawa, CANADA	Assoc Comp Machinery, ACM SIGMM		music information retrieval; multimodal learning; large language models application		In this work we propose a set of new automatic text augmentations that leverage Large Language Models from song metadata to improve on music information retrieval tasks. Compared to recent works, our proposed methods leverage large language models and copyright-free corpora from web sources, enabling us to release the knowledge sources collected. We show how combining these representations with the audio signal provides a 21% relative improvement on five of six datasets on genre classification, emotion recognition and music tagging, achieving state-of-the-art in three (GTZAN, FMA-Small and Deezer). We demonstrate the benefit of injecting external knowledge sources by comparing them with intrinsic text representation methods that rely only on the sample's information.	[Rossetto, Federico; Dalton, Jeffrey; Murray-Smith, Roderick] Univ Glasgow, Glasgow, Lanark, Scotland	University of Glasgow	Rossetto, F (corresponding author), Univ Glasgow, Glasgow, Lanark, Scotland.	f.rossetto.1@research.gla.ac.uk; Jeff.Dalton@glasgow.ac.uk; Roderick.Murray-Smith@glasgow.ac.uk		Dalton, Jeff/0000-0003-2422-8651; Murray-Smith, Roderick/0000-0003-4228-7962	Engineering and Physical Sciences Research Council [EP/V025708/1]	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work is supported by the 2021 Alexa Prize TaskBot Grant and the Engineering and Physical Sciences Research Council grant EP/V025708/1.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alonso-Jimenez Pablo, 2022, P 23 INT SOC MUSIC I, P825, DOI DOI 10.5281/ZENODO.7316790; Bertin-Mahieux T., 2011, P 12 INT C MUS INF R, P591; Bogdanov Dmitry, 2019, MediaEval Benchmarking Initiative for Multimedia Evaluation; Bogdanov Dmitry, 2019, INT C MACHINE LEARNI; Castellon R, 2021, Arxiv, DOI [arXiv:2107.05677, DOI 10.48550/ARXIV.2107.05677]; Defferrard M, 2017, Arxiv, DOI [arXiv:1612.01840, DOI 10.48550/ARXIV.1612.01840]; Delbouys R, 2018, Arxiv, DOI arXiv:1809.07276; Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132; Khashabi D, 2020, Arxiv, DOI arXiv:2005.00700; LAW E, 2009, ISMIR; Lee JP, 2017, Arxiv, DOI arXiv:1703.01793; Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830; Manco I, 2022, INT CONF ACOUST SPEE, P456, DOI 10.1109/ICASSP43922.2022.9746996; McCallum Matthew C., 2022, arXiv; Oramas S, 2017, ARXIV; Oramas S., 2018, Trans Int Soc Music Inf Retr, V1, P4, DOI [DOI 10.5334/TISMIR.10, 10.5334/tismir.10]; Oramas S., 2017, P 2 WORKSH DEEP LEAR, P32, DOI DOI 10.1145/3125486.3125492; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Petroni F, 2021, Arxiv, DOI arXiv:2009.02252; Pons Jordi, 2017, INT SOC MUSIC INFORM; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Soleymani M., 2013, P 2 ACM INT WORKSHOP, P1, DOI DOI 10.1145/2506364.2506365; Sturm B.L., 2012, P 2 INT ACM WORKSHOP, V2012, P7, DOI 10.1145/2390848.2390851; Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Zhao H, 2022, Arxiv, DOI arXiv:2202.10139; Zhao J, 2022, 2022 15TH IEEE/ACM INTERNATIONAL WORKSHOP ON NETWORK ON CHIP ARCHITECTURES (NOCARC 2022), P21, DOI 10.1109/NoCArc57472.2022.9911299	30	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0283-9				2023							51	59		10.1145/3607827.3616842	http://dx.doi.org/10.1145/3607827.3616842			9	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4KH					2024-07-03	WOS:001150367900009
J	Jowsey, T; Stokes-Parish, J; Singleton, R; Todorovic, M				Jowsey, Tanisha; Stokes-Parish, Jessica; Singleton, Rachelle; Todorovic, Michael			Medical education empowered by generative artificial intelligence large language models	TRENDS IN MOLECULAR MEDICINE			English	Editorial Material								Generative artificial intelligence (GAI) large language models (LLMs), like ChatGPT, have become the world's fastest growing applications. Here, we provide useful strategies for educators in medical and health science (M&HS) to integrate GAI-LLMs into learning and teaching practice, ultimately enhancing students' digital capability.	[Jowsey, Tanisha; Stokes-Parish, Jessica] Bond Univ, Fac Hlth Sci & Med, Robina, Australia; [Singleton, Rachelle] Univ Auckland, Fac Med & Hlth Sci, Auckland, New Zealand; [Todorovic, Michael] Griffith Univ, Sch Nursing & Midwifery, Brisbane, Australia; [Todorovic, Michael] Griffith Univ, Menzies Hlth Inst Queensland, Brisbane, Australia	Bond University; University of Auckland; Griffith University; Griffith University	Todorovic, M (corresponding author), Griffith Univ, Sch Nursing & Midwifery, Brisbane, Australia.; Todorovic, M (corresponding author), Griffith Univ, Menzies Hlth Inst Queensland, Brisbane, Australia.	m.todorovic@griffith.edu.au		Todorovic, Michael/0000-0003-0806-5610				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Davenport Thomas, 2019, Future Healthc J, V6, P94, DOI 10.7861/futurehosp.6-2-94; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Palmer E, 2023, Discussion boards as major assessment pieces in the age of artificial inteligence; Seth P, 2023, JMIR MED EDUC, V9, DOI 10.2196/46344; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Tsai A, 2023, Artificial intelligence learns from others; so do we?; Wiggins G., 1990, Practical Assessment, Research, and Evaluation, V2, P2	8	5	6	78	113	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	1471-4914	1471-499X		TRENDS MOL MED	Trends Mol. Med	DEC	2023	29	12					971	973		10.1016/j.molmed.2023.08.012	http://dx.doi.org/10.1016/j.molmed.2023.08.012		NOV 2023	3	Biochemistry & Molecular Biology; Cell Biology; Medicine, Research & Experimental	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Cell Biology; Research & Experimental Medicine	Z3MS5	37718142				2024-07-03	WOS:001111153800001
J	Dagdelen, J; Dunn, A; Lee, S; Walker, N; Rosen, AS; Ceder, G; Persson, KA; Jain, A				Dagdelen, John; Dunn, Alexander; Lee, Sanghoon; Walker, Nicholas; Rosen, Andrew S.; Ceder, Gerbrand; Persson, Kristin A.; Jain, Anubhav			Structured information extraction from scientific text with large language models	NATURE COMMUNICATIONS			English	Article							CANCER RESISTANCE; CELLULAR SENESCENCE; PHYLOGENETIC ANALYSIS; PREMATURE SENESCENCE; MOLE-RAT; MECHANISMS; TRANSCRIPTION; DISCOVERY; ALIGNMENT; PROVIDES	Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers. Extracting scientific data from published research is a complex task required specialised tools. Here the authors present a scheme based on large language models to automatise the retrieval of information from text in a flexible and accessible manner.	[Dagdelen, John; Dunn, Alexander; Lee, Sanghoon; Walker, Nicholas; Rosen, Andrew S.; Ceder, Gerbrand; Persson, Kristin A.; Jain, Anubhav] Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA; [Dagdelen, John; Dunn, Alexander; Lee, Sanghoon; Rosen, Andrew S.; Ceder, Gerbrand; Persson, Kristin A.] Univ Calif Berkeley, Mat Sci & Engn Dept, Berkeley, CA USA	United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; University of California System; University of California Berkeley	Jain, A (corresponding author), Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.	ajain@lbl.gov	Rosen, Andrew S/G-2407-2014	Rosen, Andrew S/0000-0002-0141-7006; Persson, Kristin A./0000-0003-2495-5509	Toyota Research Institute through the Accelerated Materials Design and Discovery program; Miller Institute for Basic Research in Science, University of California, Berkeley; U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division [DE-AC02-05CH11231, KCD2S2]; U.S. Department of Energy Office of Science User Facility located at Lawrence Berkeley National Laboratory [BES-ERCAP0024004]	Toyota Research Institute through the Accelerated Materials Design and Discovery program; Miller Institute for Basic Research in Science, University of California, Berkeley(University of California System); U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division(United States Department of Energy (DOE)); U.S. Department of Energy Office of Science User Facility located at Lawrence Berkeley National Laboratory(United States Department of Energy (DOE))	This work was supported by Toyota Research Institute through the Accelerated Materials Design and Discovery program. A.S.R. acknowledges support via a Miller Research Fellowship from the Miller Institute for Basic Research in Science, University of California, Berkeley. Funding for training and evaluating the Llama-2 model was provided by the U.S. Department of Energy, Office of Science, Office of Basic Energy Sciences, Materials Sciences and Engineering Division under Contract No. DE-AC02-05CH11231 (D2S2 program KCD2S2). This research used resources of the National Energy Research Scientific Computing Center (NERSC), a U.S. Department of Energy Office of Science User Facility located at Lawrence Berkeley National Laboratory, operated under Contract No. DE-AC02-05CH11231 using NERSC award BES-ERCAP0024004. We thank Anna Sackmann (Science Data and Engineering Librarian at UC Berkeley) for helping us to obtain Text and Data Mining agreements with the specified publishers and we also thank J. Montoya and A. Trewartha for helpful discussions.	Abegglen LM, 2015, JAMA-J AM MED ASSOC, V314, P1850, DOI 10.1001/jama.2015.13134; Attaallah A, 2020, GEROSCIENCE, V42, P867, DOI 10.1007/s11357-019-00066-2; Bae MK, 2002, J BIOL CHEM, V277, P9, DOI 10.1074/jbc.C100442200; Bemis L, 2004, GENE DEV, V18, P739, DOI 10.1101/gad.1180104; Blanco Enrique, 2007, Curr Protoc Bioinformatics, VChapter 4, DOI 10.1002/0471250953.bi0403s18; Calcinotto A, 2019, PHYSIOL REV, V99, P1047, DOI 10.1152/physrev.00020.2018; Campisi J, 2001, TRENDS CELL BIOL, V11, pS27, DOI 10.1016/S0962-8924(01)82148-6; Campisi J, 2013, ANNU REV PHYSIOL, V75, P685, DOI 10.1146/annurev-physiol-030212-183653; Duren ZN, 2020, GENOME RES, V30, P622, DOI 10.1101/gr.257063.119; Flynn JM, 2020, P NATL ACAD SCI USA, V117, P9451, DOI 10.1073/pnas.1921046117; Foley NM, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aao0926; Gorbunova V, 2014, NAT REV GENET, V15, P531, DOI 10.1038/nrg3728; Gorbunova V, 2012, P NATL ACAD SCI USA, V109, P19392, DOI 10.1073/pnas.1217211109; Grabherr MG, 2011, NAT BIOTECHNOL, V29, P644, DOI 10.1038/nbt.1883; Grant CE, 2011, BIOINFORMATICS, V27, P1017, DOI 10.1093/bioinformatics/btr064; Guo H, 2016, HEPATOLOGY, V63, P898, DOI 10.1002/hep.28372; Guo YT, 2021, ZOOL RES, V42, P671, DOI 10.24272/j.issn.2095-8137.2021.240; Haas BJ, 2003, NUCLEIC ACIDS RES, V31, P5654, DOI 10.1093/nar/gkg770; Haas BJ, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-1-r7; Hadi F, 2020, NATURE, V583, pE1, DOI 10.1038/s41586-020-2410-x; Healy K, 2014, P ROY SOC B-BIOL SCI, V281, DOI 10.1098/rspb.2014.0298; Heinz S, 2010, MOL CELL, V38, P576, DOI 10.1016/j.molcel.2010.05.004; Hickey G, 2013, BIOINFORMATICS, V29, P1341, DOI 10.1093/bioinformatics/btt128; Hiller M, 2012, NUCLEIC ACIDS RES, V40, P11463, DOI 10.1093/nar/gks905; Hu J, 2023, bioRxiv, DOI [10.1101/2023.03.09.531669, 10.1101/2023.03.09.531669, DOI 10.1101/2023.03.09.531669]; Hua R., 2024, motifScore:v1.0.0, DOI [10.5281/zenodo.10262324, DOI 10.5281/ZENODO.10262324]; Huang ZX, 2019, NAT ECOL EVOL, V3, P1110, DOI 10.1038/s41559-019-0913-3; Huang ZX, 2016, BMC GENOMICS, V17, DOI 10.1186/s12864-016-3227-8; Hubisz MJ, 2011, BRIEF BIOINFORM, V12, P41, DOI 10.1093/bib/bbq072; Jurka J, 2005, CYTOGENET GENOME RES, V110, P462, DOI 10.1159/000084979; Keilwagen J, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw092; Kent WJ, 2010, BIOINFORMATICS, V26, P2204, DOI 10.1093/bioinformatics/btq351; Lánczky A, 2021, J MED INTERNET RES, V23, DOI 10.2196/27633; Langfelder P, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-559; Langmead B, 2019, BIOINFORMATICS, V35, P421, DOI 10.1093/bioinformatics/bty648; Li H, 2011, BIOINFORMATICS, V27, P2987, DOI 10.1093/bioinformatics/btr509; Li KQ, 2023, ZOOL RES, V44, P636, DOI 10.24272/j.issn.2095-8137.2022.531; Liu GH, 2018, FRONT PHARMACOL, V9, DOI 10.3389/fphar.2018.00135; Liu JF, 2021, PHYTOMEDICINE, V91, DOI 10.1016/j.phymed.2021.153678; Löytynoja A, 2014, METHODS MOL BIOL, V1079, P155, DOI 10.1007/978-1-62703-646-7_10; Luo YH, 2020, NUCLEIC ACIDS RES, V48, pD882, DOI 10.1093/nar/gkz1062; Majoros WH, 2004, BIOINFORMATICS, V20, P2878, DOI 10.1093/bioinformatics/bth315; Manov I, 2013, BMC BIOL, V11, DOI 10.1186/1741-7007-11-91; Munshi-South J, 2010, AGEING RES REV, V9, P12, DOI 10.1016/j.arr.2009.07.006; Nassar LR, 2023, NUCLEIC ACIDS RES, V51, pD1188, DOI 10.1093/nar/gkac1072; Paulat NS, 2023, MOL BIOL EVOL, V40, DOI 10.1093/molbev/msad092; Podlutsky AJ, 2005, J GERONTOL A-BIOL, V60, P1366, DOI 10.1093/gerona/60.11.1366; Quinlan AR, 2010, BIOINFORMATICS, V26, P841, DOI 10.1093/bioinformatics/btq033; Rangarajan A, 2004, CANCER CELL, V6, P171, DOI 10.1016/j.ccr.2004.07.009; Rangarajan A, 2003, NAT REV CANCER, V3, P952, DOI 10.1038/nrc1235; Rashid M, 2021, GENE, V798, DOI 10.1016/j.gene.2021.145796; Roscito JG, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07122-z; Samsa WE, 2020, ONCOGENE, V39, P4581, DOI 10.1038/s41388-020-1320-6; Schubbert S, 2007, NAT REV CANCER, V7, P295, DOI 10.1038/nrc2109; Seim I, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3212; Seluanov A, 2018, NAT REV CANCER, V18, P433, DOI 10.1038/s41568-018-0004-9; Seluanov A, 2009, P NATL ACAD SCI USA, V106, P19352, DOI 10.1073/pnas.0905252106; Semenza GL, 2003, NAT REV CANCER, V3, P721, DOI 10.1038/nrc1187; Shannon P, 2003, GENOME RES, V13, P2498, DOI 10.1101/gr.1239303; Simao FA, 2015, BIOINFORMATICS, V31, P3210, DOI 10.1093/bioinformatics/btv351; Szklarczyk D, 2023, NUCLEIC ACIDS RES, V51, pD638, DOI 10.1093/nar/gkac1000; Tarailo-Graovac Maja, 2009, Curr Protoc Bioinformatics, VChapter 4, DOI 10.1002/0471250953.bi0410s25; Teeling EC, 2018, ANNU REV ANIM BIOSCI, V6, P23, DOI 10.1146/annurev-animal-022516-022811; Thorvaldsdóttir H, 2013, BRIEF BIOINFORM, V14, P178, DOI 10.1093/bib/bbs017; Tian X, 2013, NATURE, V499, P346, DOI 10.1038/nature12234; Tsompana M, 2014, EPIGENET CHROMATIN, V7, DOI 10.1186/1756-8935-7-33; Tsujimoto I, 2012, FEBS LETT, V586, P4326, DOI 10.1016/j.febslet.2012.10.042; Vincze O, 2022, NATURE, V601, P263, DOI 10.1038/s41586-021-04224-5; Vital-Lopez FG, 2012, WIRES DATA MIN KNOWL, V2, P298, DOI 10.1002/widm.1061; Welford SM, 2006, GENE DEV, V20, P3366, DOI 10.1101/gad.1471106; Wilkinson GS, 2019, BIOL LETTERS, V15, DOI 10.1098/rsbl.2018.0860; Wittkopp PJ, 2012, NAT REV GENET, V13, P59, DOI 10.1038/nrg3095; Yang ZH, 2007, MOL BIOL EVOL, V24, P1586, DOI 10.1093/molbev/msm088; Yuan CJ, 2021, INT J CLIN ONCOL, V26, P1159, DOI 10.1007/s10147-021-01933-9; Zhang GJ, 2013, SCIENCE, V339, P456, DOI 10.1126/science.1230835; Zhang Y, 2008, GENOME BIOL, V9, DOI 10.1186/gb-2008-9-9-r137	76	10	10	78	78	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2041-1723		NAT COMMUN	Nat. Commun.	FEB 15	2024	15	1							1418	10.1038/s41467-024-45563-x	http://dx.doi.org/10.1038/s41467-024-45563-x			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HZ8Y1	38360817	gold			2024-07-03	WOS:001163439400010
J	Huang, H; Xu, B; Liang, XN; Chen, KH; Yang, MY; Zhao, TJ; Zhu, CH				Huang, Hui; Xu, Bing; Liang, Xinnian; Chen, Kehai; Yang, Muyun; Zhao, Tiejun; Zhu, Conghui			Multi-view fusion for instruction mining of large language model	INFORMATION FUSION			English	Article						Instruction mining; Large language model; Instruction tuning		Large Language Models (LLMs) obtain their instruction -following ability through instruction tuning. While the quality of instruction data is considered critical for a successful LLM, the selection of high -quality datasets for finetuning still lacks clear guidelines and quantitative analyses. In this work, we introduce three analytical views for instruction mining: diversity, complexity, and accuracy, which can aid in selecting an optimal subset of instruction data for fine-tuning. Based on these views, we propose a multi -view fusion framework for efficient instruction selection, including diversity sampling based on LoRA representation distribution, complexity scoring based on uncertainty quantification, and accuracy scoring based on reward modeling. We perform the framework on various open -sourced instruction datasets, and achieved enhanced performance of LLMs with a carefully curated subset, underscoring the effectiveness of our proposed framework.	[Huang, Hui; Xu, Bing; Yang, Muyun; Zhao, Tiejun; Zhu, Conghui] Harbin Inst Technol, Fac Comp, Harbin, Peoples R China; [Liang, Xinnian] Beihang Univ, State Key Lab Software Dev Environm, Beijing, Peoples R China; [Chen, Kehai] Harbin Inst Technol, Sch Comp Sci & Technol, Shenzhen, Peoples R China	Harbin Institute of Technology; Beihang University; Harbin Institute of Technology	Xu, B (corresponding author), Harbin Inst Technol, Fac Comp, Harbin, Peoples R China.	22b903058@stu.hit.edu.cn; hitxb@hit.edu.cn; xnliang@buaa.edu.cn; chenkehai@hit.edu.cn; yangmuyun@hit.edu.cn; tjzhao@hit.edu.cn; conghui@hit.edu.cn			National Natural Science Foundation of China [62376075, 62276077, U1908216, 62376076]; Key R&D Program of Yunnan, PR China [202203AA080004]; Shenzhen College Stability Support Plan, PR China [GXWD20220811170358002]; Key Laboratory of Computing Power Network and Information Security, Ministry of Education [2023ZD027]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Key R&D Program of Yunnan, PR China; Shenzhen College Stability Support Plan, PR China; Key Laboratory of Computing Power Network and Information Security, Ministry of Education	This work is supported by National Natural Science Foundation of China (62376075, 62276077, U1908216, 62376076), Key R&D Program of Yunnan, PR China (202203AA080004) and Shenzhen College Stability Support Plan, PR China (No. GXWD20220811170358002). This work is also supported by the Key Laboratory of Computing Power Network and Information Security, Ministry of Education under Grant No. 2023ZD027.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aggarwal C.C., 2001, P ACM SIGACT SIGMOD, P256; Bengio Y., 2009, ICML, P41, DOI DOI 10.1145/1553374.1553380; Cao YH, 2023, Arxiv, DOI arXiv:2307.06290; Chen L., 2024, 12 INT C LEARN REPR; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Conover M., 2023, Free Dolly: Introducing the world's first truly open instructiontuned LLM; Dai J, 2023, Arxiv, DOI arXiv:2310.12773; Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507; Gal Y, 2016, PR MACH LEARN RES, V48; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; He P, 2020, ICLR; Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325; Hu E.J., 2022, INT C LEARN REPR; Huang H, 2023, Arxiv, DOI arXiv:2309.12053; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Li M, 2024, Arxiv, DOI arXiv:2308.12032; Li X., 2023, Alpacaeval: An automatic evaluator of instruction-following models; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin BY, 2023, Arxiv, DOI arXiv:2312.01552; Longpre S, 2023, Arxiv, DOI arXiv:2301.13688; Lu K., 2024, 12 INT C LEARN REPR; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; Muennighoff N., 2023, arXiv; OpenAI, 2022, Introducing chatgpt; Ouyang L., 2022, NEURIPS; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Srivastava N, 2014, J MACH LEARN RES, V15, P1929; Su HJ, 2023, Arxiv, DOI arXiv:2212.09741; Tan X., 2023, P 2023 C EMPIRICAL M, P650; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang S., 2021, arXiv; Wang X, 2022, IEEE T PATTERN ANAL, V44, P4555, DOI 10.1109/TPAMI.2021.3069908; Wang YZ, 2023, Arxiv, DOI arXiv:2306.04751; Wang YZ, 2022, Arxiv, DOI arXiv:2204.07705; Wei J, 2022, Trans. Mach. Learn. Res.; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wu ZF, 2023, Arxiv, DOI [arXiv:2307.02477, 10.48550/arXiv.2307.02477]; Xu C, 2023, Arxiv, DOI arXiv:2304.12244; Zhao YX, 2024, Arxiv, DOI arXiv:2308.05696; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhou CT, 2023, Arxiv, DOI arXiv:2305.11206	44	0	0	0	0	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1566-2535	1872-6305		INFORM FUSION	Inf. Fusion	OCT	2024	110								102480	10.1016/j.inffus.2024.102480	http://dx.doi.org/10.1016/j.inffus.2024.102480			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	UD2W0					2024-07-03	WOS:001246068100001
J	Han, SJ; Ransom, KJ; Perfors, A; Kemp, C				Han, Simon Jerome; Ransom, Keith J.; Perfors, Andrew; Kemp, Charles			Inductive reasoning in humans and large language models	COGNITIVE SYSTEMS RESEARCH			English	Article						Reasoning; Property induction; Category-based induction; Non-monotonicity; Neural networks; GPT-3.5; GPT-4; AI; Large language models; Representation	SIMILARITY; JUDGMENTS; UNIVERSAL; LOGIC	The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behavior, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein.	[Han, Simon Jerome; Ransom, Keith J.; Perfors, Andrew; Kemp, Charles] Univ Melbourne, Parkville, Australia	University of Melbourne	Han, SJ (corresponding author), Univ Melbourne, Parkville, Australia.	simon.jerome.han@gmail.com		Han, Simon/0000-0003-1157-7748; Kemp, Charles/0000-0001-9683-8737	Complex Human Data Hub at the University of Melbourne; Australian Research Council [FT190100200]; Australian Research Council [FT190100200] Funding Source: Australian Research Council	Complex Human Data Hub at the University of Melbourne; Australian Research Council(Australian Research Council); Australian Research Council(Australian Research Council)	This work was supported in part by the Complex Human Data Hub at the University of Melbourne and by Australian Research Council Grant FT190100200.	Anderson J., 1990, ADAPTIVE CHARACTER T; [Anonymous], 1989, Similarity and Analogical Reasoning; Bhatia S, 2024, PSYCHOL REV, V131, P271, DOI 10.1037/rev0000319; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brewka Gerhard., 1997, NONMONOTONIC REASONI, V73; Brunswik E., 1957, Contemporary approaches to cognition, P5; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Carey S., 1985, CONCEPTUAL CHANGE CH; Chang TA, 2023, Arxiv, DOI arXiv:2303.11504; Chater N, 2011, HBK HIST LOGIC, V10, P553; COLLINS A, 1989, COGNITIVE SCI, V13, P1, DOI 10.1207/s15516709cog1301_1; Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413; De Deyne S, 2008, BEHAV RES METHODS, V40, P1030, DOI 10.3758/BRM.40.4.1030; Frank M. C., 2023, Nature Reviews Psychology, P1; GELMAN SA, 1986, COGNITION, V23, P183, DOI 10.1016/0010-0277(86)90034-X; GELMAN SA, 1988, COGNITIVE PSYCHOL, V20, P65, DOI 10.1016/0010-0285(88)90025-4; Glick J. J. P., 2011, Ph.D. thesis; Hagendorff T, 2023, Arxiv, DOI [arXiv:2303.13988, 10.48550/arXiv.2303.13988, DOI 10.48550/ARXIV.2303.13988]; Han S. J., 2022, P ANN M COGN SCI SOC; Hayes BK, 2019, PSYCHON B REV, V26, P1043, DOI 10.3758/s13423-018-1562-2; Hayes BK, 2018, WIRES COGN SCI, V9, DOI 10.1002/wcs.1459; HEIT E, 1994, J EXP PSYCHOL LEARN, V20, P411, DOI 10.1037/0278-7393.20.2.411; Heit E., 1998, Rational Models of Cognition, P248; Holland J. H., 1989, INDUCTION PROCESSES; Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725; Jiang GY, 2023, Arxiv, DOI arXiv:2306.00503; Keil Frank C., 1989, Concepts, Kinds, and Cognitive Development; Kemp C., 2011, Advances in neural information processing systems, V24, P316; Kemp C, 2014, PSYCHON B REV, V21, P23, DOI 10.3758/s13423-013-0467-3; Kemp C, 2012, COGNITIVE PSYCHOL, V64, P35, DOI 10.1016/j.cogpsych.2011.10.001; Kemp C, 2010, ACTA PSYCHOL, V133, P216, DOI 10.1016/j.actpsy.2009.11.012; Kemp C, 2009, PSYCHOL REV, V116, P20, DOI 10.1037/a0014282; Kiciman E, 2023, Arxiv, DOI arXiv:2305.00050; Lake BM, 2023, PSYCHOL REV, V130, P401, DOI 10.1037/rev0000297; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813; Lipkin B, 2023, Arxiv, DOI arXiv:2305.01020; Lopez A, 1997, COGNITIVE PSYCHOL, V32, P251, DOI 10.1006/cogp.1997.0651; LOPEZ A, 1992, CHILD DEV, V63, P1070, DOI 10.2307/1131519; Magar I., 2022, arXiv; Medin DL, 2003, PSYCHON B REV, V10, P517, DOI 10.3758/BF03196515; Misra Kanishka., 2021, P ANN M COGNITIVE SC, V43, P216; Mitchell M., 2023, Science, V381; MURPHY GL, 1985, PSYCHOL REV, V92, P289, DOI 10.1037/0033-295X.92.3.289; Olsson C., 2022, arXiv; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2022, New and improved embedding model; OSHERSON DN, 1990, PSYCHOL REV, V97, P185, DOI 10.1037/0033-295X.97.2.185; Pothos E.M., 2011, Formal approaches in categorization; Proffitt JB, 2000, J EXP PSYCHOL LEARN, V26, P811, DOI 10.1037/0278-7393.26.4.811; Ransom KJ, 2016, COGNITIVE SCI, V40, P1775, DOI 10.1111/cogs.12308; RIPS LJ, 1975, J VERB LEARN VERB BE, V14, P665, DOI 10.1016/S0022-5371(75)80055-7; RIPS LJ, 1989, SIMILARITY AND ANALOGICAL REASONING, P21, DOI 10.1017/CBO9780511529863.004; Rogers T. T., 2004, Semantic Cognition: A Parallel Distributed Processing Approach, DOI 10.7551/mitpress/6161.001.0001; Rogers TT, 2014, COGNITIVE SCI, V38, P1024, DOI 10.1111/cogs.12148; Sap M., 2019, P 2019 EMNLP IJCNLP; Shapira N, 2023, Arxiv, DOI arXiv:2305.14763; SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243; Simon H.A., 1970, SCI ARTIFICIAL; Sloman S.A., 2005, CAMBRIDGE HDB THINKI, P95; SLOMAN SA, 1993, COGNITIVE PSYCHOL, V25, P231, DOI 10.1006/cogp.1993.1006; SMITH EE, 1993, COGNITION, V49, P67, DOI 10.1016/0010-0277(93)90036-U; Srivastava Aarohi, 2022, arXiv; Storks S, 2020, Arxiv, DOI [arXiv:1904.01172, DOI 10.48550/ARXIV.1904.01172]; Tenenbaum JB, 2006, TRENDS COGN SCI, V10, P309, DOI 10.1016/j.tics.2006.05.009; Todd PM, 2007, CURR DIR PSYCHOL SCI, V16, P167, DOI 10.1111/j.1467-8721.2007.00497.x; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Voita E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5797; Voorspoels W, 2015, COGNITIVE PSYCHOL, V81, P1, DOI 10.1016/j.cogpsych.2015.07.001; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Webb T, 2023, Arxiv, DOI [arXiv:2212.09196, 10.48550/arXiv.2212.09196]; Zhang S., 2023, You are what you're for: Essentialist categorization in large language models	73	2	2	23	36	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	2214-4366	1389-0417		COGN SYST RES	Cogn. Syst. Res.	JAN	2024	83								101155	10.1016/j.cogsys.2023.101155	http://dx.doi.org/10.1016/j.cogsys.2023.101155		SEP 2023	28	Computer Science, Artificial Intelligence; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Neurosciences & Neurology; Psychology	T5UP3		Green Submitted, hybrid			2024-07-03	WOS:001078641500001
C	Frohberg, J; Binder, F	Mariani, J	Calzolari, N; Bechet, F; Blache, P; Choukri, K; Cieri, C; Declerck, T; Goggi, S; Isahara, H; Maegaard, B; Mazo, H; Odijk, H; Piperidis, S		Frohberg, Jorg; Binder, Frank	Mariani, J		CRASS: A Novel Data Set and Benchmark to Test Counterfactual Reasoning of Large Language Models	LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION			English	Proceedings Paper	13th International Conference on Language Resources and Evaluation (LREC)	JUN 20-25, 2022	Marseille, FRANCE	Google, S African Ctr Digital Language Resources, Vocapia Res, 3M, Emvista, Expert.ai, Grammarly, Minist Culture, Delegat Gen Langue Francaise Aux Langues France, Reg Sud Provence Alpes Cote Azur		common-sense reasoning; counterfactual conditionals; NLP; large language models	COMMONSENSE	We introduce the CRASS (counterfactual reasoning assessment) data set and benchmark utilizing questionized counterfactual conditionals as a novel and powerful tool to evaluate large language models. We present the data set design and benchmark. We test six state-of-the-art models against our benchmark. Our results show that it poses a valid challenge for these models and opens up considerable room for their improvement.	[Frohberg, Jorg] apergo UG, Leipzig, Germany; [Binder, Frank] Univ Leipzig, Inst Appl Informat, Leipzig, Germany	Leipzig University	Frohberg, J (corresponding author), apergo UG, Leipzig, Germany.	j.frohberg@apergo.ai; binder@infai.org			German Federal Ministry of Education and Research (BMBF) [01IS20091B]	German Federal Ministry of Education and Research (BMBF)(Federal Ministry of Education & Research (BMBF))	We thank Alexander Binder, Felix Helfer, James Parsons and all anonymous reviewers for their helpful comments on earlier drafts of this paper. This work was partially supported by the German Federal Ministry of Education and Research (BMBF) under grant no. 01IS20091B.	[Anonymous], 2013, ACL; apergo.AI, 2021, CRASS DAT SET; Bareinboim E., 2020, R60 COL CAUSALAI LAB; Beebee H., 2017, MAKING DIFFERENCE ES; Betz Gregor, 2021, P 14 INT C COMP SEM, P63; Bowman SR, 2015, P 2015 C EMPIRICAL M, P632, DOI [10.18653/v1/D15-1075, DOI 10.18653/V1/D15-1075]; Briggs R, 2012, PHILOS STUD, V160, P139, DOI 10.1007/s11098-012-9908-5; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen H, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P63, DOI [10.1109/itaic.2019.8785756, 10.1109/ITAIC.2019.8785756]; Chersoni E, 2019, NAT LANG ENG, V25, P483, DOI 10.1017/S1351324919000214; Chowdhery Aakanksha, 2022, CoRR, abs/2204.02311; Clark C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2924; CLELAND C, 1991, SYNTHESE, V86, P229, DOI 10.1007/BF00485810; Collins John David, 2004, Causation and Counterfactuals; Davis E, 2015, COMMUN ACM, V58, P92, DOI 10.1145/2701413; Eells E., 1991, PROBABILISTIC CAUSAL; Egré P, 2016, CAMB HB LANG LINGUIS, P490; Gao Leo, 2021, CoRR, abs/2101.00027; Geach Peter., 1962, Reference and Generality; Hara K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174023; Harris DW, 2017, PALGR INNOV PHILOS, P149, DOI 10.1057/978-1-137-40808-2_6; He P, 2020, ICLR; He Pengcheng, 2021, CoRR, abs/2111.09543.; Hutson M, 2021, NATURE, V591, P22, DOI 10.1038/d41586-021-00530-0; Hwang JD, 2021, AAAI CONF ARTIF INTE, V35, P6384; JACOBSSKOLIK SL, 2020, P 2020 C EMP METH NA, P3285; Kamp Hans, 1981, Formal semantics-the essential readings, P277; Le Priol R, 2021, PR MACH LEARN RES, V130, P775; Lewis David, 1973, COUNTERFACTUALS; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lin BY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1823; Liu Y., 2019, CoRR abs/1907.11692; Lourie Nicholas, 2021, UNICORN; MATAI R, 2021, FINDINGS ASS COMPUTA, P834, DOI DOI 10.1109/IEEM50564.2021.9673000; Mihaylov T, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2381; Mitchell M, 2019, INFORMATION, V10, DOI 10.3390/info10020051; Muller T., 2022, ABS220314655 CORR; Oh J. -H, 2017, P 10 ACM INT C WEB S; PA Ortega, 2021, ABS211010819 CORR; Pawelczyk M., 2021, ABS210609992V1 CORR; Pearl J., 2000, Causality: Models, Reasoning, and Inference; Peters J, 2017, ADAPT COMPUT MACH LE; Rae Jack W., 2021, ABS211211446 CORR; Raffel C., 2021, 9 INT C LEARN REPR I; Raffel C, 2020, J MACH LEARN RES, V21; Reutlinger A., 2013, THEORY CAUSATION SOC, P25; Sanh Victor, 2021, ABS211008207 CORR; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Scholkopf B., 2021, ABS210211107 CORR; Shahid Usman, 2019, CURVE FITTING CAUSAT; Sinha K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4506; Song K., 2020, Adv. Neural Inf. Process. Syst, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297; Sun Yu, 2021, ABS210702137 CORR; Talmor A., 2021, P NEUR INF PROC SYST, V1; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Teney D., 2020, ABS200409034 CORR; Verma S., 2020, ABS201010596 CORR; Wachter S., 2017, HARV JL TECH, V31, P841, DOI DOI 10.2139/SSRN.3063289; Wang A, 2019, ADV NEUR IN, V32; Williams A, 2018, P 2018 C N AM CHAPTE, V1, P1112, DOI [10.18653/v1/N18-1101, DOI 10.18653/V1/N18-1101]; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Zhang D, 2021, 2021 12TH INTERNATIONAL CONFERENCE ON MECHANICAL AND AEROSPACE ENGINEERING (ICMAE), P139, DOI 10.1109/ICMAE52228.2021.9522568; Zhang H., 2020, ABS200505763 CORR; Zhou XH, 2020, AAAI CONF ARTIF INTE, V34, P9733	65	1	1	2	3	EUROPEAN LANGUAGE RESOURCES ASSOC-ELRA	PARIS	55-57, RUE BRILLAT-SAVARIN, PARIS, 75013, FRANCE			979-10-95546-72-6				2022							2126	2140						15	Computer Science, Interdisciplinary Applications; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BU2ZO					2024-07-03	WOS:000889371702026
J	Goswami, J; Prajapati, KK; Saha, A; Saha, AK				Goswami, Joyeeta; Prajapati, Kaushal Kumar; Saha, Ashim; Saha, Apu Kumar			Parameter-efficient fine-tuning large language model approach for hospital discharge paper summarization	APPLIED SOFT COMPUTING			English	Article						Hospital discharge summary (HDS); Large language models (LLM); LLaMA 2; QLoRA; Text summarization		Text summarization in medical domain is one of the most crucial chores as it deals with the critical human information. Consequently the proper summarization and key point extraction from medical deeds using pretrained Language models is now the key figure to be focused on for the researchers. But due to the considerable amount of real-world data and enormous amount of memory requirement to train the Large Language Models (LLMs), research on these models become challenging. To overcome these challenges multiple prompting and tuning techniques are being used. In this paper, effectiveness of prompt engineering and parameter efficient fine tuning is being studied to summarize the Hospital Discharge Summary (HDS) papers effectively, so that these models can accurately interprete medical terminologies and contexts, generate brief but compact summaries, and draw out concentrated themes, which opens new approaches for the application of LLMs in healthcare and making HDS more patient-friendly. In this research LLaMA 2 (Large Language Model Meta AI) has been considered as the base model. Also, the model has been fine-tuned using QLoRA (Quantized Low Rank Adapters), which can bring down the memory usage of LLMs without compromising the data quality. This study explores the way to use LLMs on HDS datasets without the hassle of memory usage using QLoRA, into electronic health record systems to further streamline the handling and retrieval of healthcare information.	[Goswami, Joyeeta; Saha, Ashim] Natl Inst Technol Agartala, Dept Comp Sci & Engn, Agartala 799046, Tripura, India; [Prajapati, Kaushal Kumar] Intellect AI, Chennai 603103, India; [Saha, Apu Kumar] Natl Inst Technol Agartala, Dept Math, Agartala 799046, Tripura, India	National Institute of Technology (NIT System); National Institute of Technology Agartala; National Institute of Technology (NIT System); National Institute of Technology Agartala	Saha, AK (corresponding author), Natl Inst Technol Agartala, Dept Math, Agartala 799046, Tripura, India.	apusaha_nita@yahoo.co.in		Saha, Apu Kumar/0000-0002-3475-018X				[Anonymous], 2023, GPT-4 Technical Report; Axon RN, 2014, AM J MED SCI, V347, P472, DOI 10.1097/MAJ.0000000000000171; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cajueiro DO, 2023, Arxiv, DOI [arXiv:2301.03403, 10.48550/arXiv.2301.03403, DOI 10.48550/ARXIV.2301.03403]; Chaves J.M.Z., 2023, 37 C NEURAL INFORM P; Chowdhery A., 2022, Google Res., V5; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding N, 2023, NAT MACH INTELL, V5, P220, DOI 10.1038/s42256-023-00626-4; Fu Z., 2023, P AAAI C ARTIFICIAL, V37, P12799; Ge JW, 2022, CANCER REP-US, V5, DOI 10.1002/cnr2.1457; Ghadimi A, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119308; Ghadimi A, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113392; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; Jung KH, 2023, KOREAN J RADIOL, V24, P1038, DOI 10.3348/kjr.2023.0790; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liu D., 2022, Advances in Neural Information Processing Systems, V35, P1950, DOI DOI 10.48550/ARXIV.2205.05638; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pal K., Summarization and Generation of Discharge Summary Medical Reports; Qin HT, 2023, Arxiv, DOI arXiv:2307.15016; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ramya R.S., 2023, Intell. Syst. Appl. Eng. IJISAE, V11, P63; Searle T, 2023, J BIOMED INFORM, V141, DOI 10.1016/j.jbi.2023.104358; Sorita A, 2021, J PATIENT SAF, V17, pE637, DOI 10.1097/PTS.0000000000000421; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang BY, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3611651; Widyassari AP, 2020, J KING SAUD UNIV-COM, V34, P1029, DOI 10.1016/j.jksuci.2020.05.006; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	35	0	0	6	6	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	1568-4946	1872-9681		APPL SOFT COMPUT	Appl. Soft. Comput.	MAY	2024	157								111531	10.1016/j.asoc.2024.111531	http://dx.doi.org/10.1016/j.asoc.2024.111531			8	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QY4U4					2024-07-03	WOS:001224424600001
C	Hanschmann, L; Gnewuch, U; Maedche, A		Folstad, A; Araujo, T; Papadopoulos, S; Law, ELC; Luger, E; Goodwin, M; Hobert, S; Brandtzaeg, PB		Hanschmann, Leon; Gnewuch, Ulrich; Maedche, Alexander			Saleshat: A LLM-Based Social Robot for Human-Like Sales Conversations	CHATBOT RESEARCH AND DESIGN, CONVERSATIONS 2023	Lecture Notes in Computer Science		English	Proceedings Paper	7th Conversations International Workshop (CONVERSATIONS)	NOV 22-23, 2023	Univ Oslo, Ctr Res Media Innovat, Oslo, NORWAY	SINTEF, Univ Amsterdam, Ctr Res & Technol Hellas, Durham Univ, Univ Edinburgh, Lubeck Univ Technol, Univ Agder	Univ Oslo, Ctr Res Media Innovat	social robot; large language model; design; human-robot interaction		Large language models (LLMs) have generated excitement in many areas and may also make human-like conversations with social robots possible. Drawing from human-robot interaction literature and interviews, we developed Saleshat based on the commercial social robot Furhat and the large language model GPT-4. Saleshat emphasizes refined natural language processing and dynamic control of the robot's physical appearance through the LLM. Responses from the LLM are processed sequentially, enabling the robot to react quickly. The results of our first formative evaluation with six users engaging in a sales conversation about Bluetooth speakers show that Saleshat can provide accurate and detailed responses, maintain a good conversation flow, and show dynamically controlled non-verbal cues. With our findings, we contribute to research on social robots and LLMs by providing design knowledge for LLM-based social robots and by uncovering the benefits and challenges of integrating LLMs into a social robot.	[Gnewuch, Ulrich; Maedche, Alexander] Karlsruhe Inst Technol, D-76131 Karlsruhe, Germany	Helmholtz Association; Karlsruhe Institute of Technology	Hanschmann, L (corresponding author), Karlsruhe Inst Technol, D-76131 Karlsruhe, Germany.	leon.hanschmann@kit.edu; ulrich.gnewuch@kit.edu; alexander.maedche@kit.edu						Al Moubayed Samer, 2012, Cognitive Behavioural Systems (COST 2012). International Training School. Revised Selected Papers, P114, DOI 10.1007/978-3-642-34584-5_9; [Anonymous], 2014, Nestle to Use Humanoid Robot to Sell Nescaf e in Japan; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bartneck C, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P591, DOI 10.1109/ROMAN.2004.1374827; Breazeal C, 2003, ROBOT AUTON SYST, V42, P167, DOI 10.1016/S0921-8890(02)00373-1; Breazeal C, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1146; Brengman M, 2021, J BUS RES, V134, P263, DOI 10.1016/j.jbusres.2021.05.025; Bulmer S, 2018, J RETAIL CONSUM SERV, V42, P107, DOI 10.1016/j.jretconser.2018.01.016; Cameron G., 2018, Best practices for designing chatbots in mental healthcare-a case study on iHelpr, DOI [10.14236/ewic/HCI2018.129, DOI 10.14236/EWIC/HCI2018.129]; Castelo N, 2019, J MARKETING RES, V56, P809, DOI 10.1177/0022243719851788; Cherakara N, 2023, Arxiv, DOI arXiv:2308.15214; Choi S, 2021, J SERV RES-US, V24, P354, DOI 10.1177/1094670520978798; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano PF, 2017, ADV NEUR IN, V30; Chuah SHW, 2021, J RETAIL CONSUM SERV, V61, DOI 10.1016/j.jretconser.2021.102551; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dietvorst BJ, 2018, MANAGE SCI, V64, P1155, DOI 10.1287/mnsc.2016.2643; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Evers K, 2022, COMPUT ASSIST LANG L, V35, P1869, DOI 10.1080/09588221.2020.1839504; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Henschel Anna, 2021, Curr Robot Rep, V2, P9, DOI 10.1007/s43154-020-00035-0; Holthaus P, 2021, INT J SOC ROBOT, V13, P1729, DOI 10.1007/s12369-021-00759-9; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Korn O., 2019, Social Robots: Technological, Societal and Ethical Aspects of Human-Robot Interaction, P119, DOI [10.1007/978-3-030-17107-0_7, DOI 10.1007/978-3-030-17107-07]; Lim MY, 2022, ACMIEEE INT CONF HUM, P1200, DOI 10.1109/HRI53351.2022.9889443; Lu L, 2021, INT J HOSP MANAG, V94, DOI 10.1016/j.ijhm.2020.102823; Mende M.A., 2019, AI Love You, P41, DOI [10.1007/978-3-030-19734-63, DOI 10.1007/978-3-030-19734-63]; OpenAI, 2023, GPT-4 Technical Report; Pandey AK, 2018, IEEE ROBOT AUTOM MAG, V25, P40, DOI 10.1109/MRA.2018.2833157; Qin C., 2023, 2023 C EMP METH NAT; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reich T, 2023, J CONSUM PSYCHOL, V33, P285, DOI 10.1002/jcpy.1313; Rindfleisch A., 2022, AMS REV, V12, P238, DOI DOI 10.1007/S13162-022-00240-4; Ruoff M., 2021, Designing multimodal bi&a systems for co-located team interactions; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Stark C, 2023, Arxiv, DOI [arXiv:2310.06303, 10.48550/ARXIV.2310.06303, DOI 10.48550/ARXIV.2310.06303]; Stock Ruth Maria, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P339, DOI 10.1109/PERCOMW.2017.7917585; Turner J. J., 2019, ENG MANAGEMENT PRODU, V11, P36, DOI DOI 10.2478/EMJ-2019-0003; van Pinxteren MME, 2019, J SERV MARK, V33, P507, DOI 10.1108/JSM-01-2018-0045; Vaswani A, 2017, ADV NEUR IN, V30; Wang YJ, 2023, Arxiv, DOI arXiv:2309.09969; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wilcock G., 2022, 36 ANN C JAP SOC ART; Zhong QH, 2023, Arxiv, DOI [arXiv:2302.10198, DOI 10.48550/ARXIV.2302.10198]	45	0	0	4	4	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-54974-8; 978-3-031-54975-5	LECT NOTES COMPUT SC			2024	14524						61	76		10.1007/978-3-031-54975-5_4	http://dx.doi.org/10.1007/978-3-031-54975-5_4			16	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9FF					2024-07-03	WOS:001212393500004
J	Yoshikawa, N; Skreta, M; Darvish, K; Arellano-Rubach, S; Ji, Z; Kristensen, LB; Li, AZ; Zhao, YC; Xu, HP; Kuramshin, A; Aspuru-Guzik, A; Shkurti, F; Garg, A				Yoshikawa, Naruki; Skreta, Marta; Darvish, Kourosh; Arellano-Rubach, Sebastian; Ji, Zhi; Kristensen, Lasse Bjorn; Li, Andrew Zou; Zhao, Yuchi; Xu, Haoping; Kuramshin, Artur; Aspuru-Guzik, Alan; Shkurti, Florian; Garg, Animesh			Large language models for chemistry robotics	AUTONOMOUS ROBOTS			English	Article						Large language models; Constrained task and motion planning; Plan generation verification; Self-driving labs; Chemistry lab automation	GENERATION; SYSTEM; TASK	This paper proposes an approach to automate chemistry experiments using robots by translating natural language instructions into robot-executable plans, using large language models together with task and motion planning. Adding natural language interfaces to autonomous chemistry experiment systems lowers the barrier to using complicated robotics systems and increases utility for non-expert users, but translating natural language experiment descriptions from users into low-level robotics languages is nontrivial. Furthermore, while recent advances have used large language models to generate task plans, reliably executing those plans in the real world by an embodied agent remains challenging. To enable autonomous chemistry experiments and alleviate the workload of chemists, robots must interpret natural language commands, perceive the workspace, autonomously plan multi-step actions and motions, consider safety precautions, and interact with various laboratory equipment. Our approach, CLAIRify, combines automatic iterative prompting with program verification to ensure syntactically valid programs in a data-scarce domain-specific language that incorporates environmental constraints. The generated plan is executed through solving a constrained task and motion planning problem using PDDLStream solvers to prevent spillages of liquids as well as collisions in chemistry labs. We demonstrate the effectiveness of our approach in planning chemistry experiments, with plans successfully executed on a real robot using a repertoire of robot skills and lab tools. Specifically, we showcase the utility of our framework in pouring skills for various materials and two fundamental chemical experiments for materials synthesis: solubility and recrystallization. Further details about CLAIRify can be found at https://ac-rad.github.io/clairify/.	[Yoshikawa, Naruki; Skreta, Marta; Darvish, Kourosh; Ji, Zhi; Kristensen, Lasse Bjorn; Li, Andrew Zou; Xu, Haoping; Kuramshin, Artur; Aspuru-Guzik, Alan; Shkurti, Florian; Garg, Animesh] Univ Toronto, Toronto, ON, Canada; [Yoshikawa, Naruki; Skreta, Marta; Darvish, Kourosh; Xu, Haoping; Aspuru-Guzik, Alan; Shkurti, Florian; Garg, Animesh] Vector Inst Artificial Intelligence, Toronto, ON, Canada; [Arellano-Rubach, Sebastian] Univ Toronto Sch, Toronto, ON, Canada; [Zhao, Yuchi] Univ Waterloo, Waterloo, ON, Canada; [Aspuru-Guzik, Alan] CIFAR Artificial Intelligence Res Chair, Toronto, ON, Canada; [Garg, Animesh] NVIDIA, Santa Clara, CA USA	University of Toronto; Vector Institute for Artificial Intelligence; University of Toronto; University of Waterloo; Nvidia Corporation	Darvish, K (corresponding author), Univ Toronto, Toronto, ON, Canada.; Darvish, K (corresponding author), Vector Inst Artificial Intelligence, Toronto, ON, Canada.	kdarvish@cs.toronto.edu	Garg, Animesh/AGK-2223-2022; Bernstein, Alan/X-9136-2019	Garg, Animesh/0000-0003-0482-4296; Yoshikawa, Naruki/0000-0003-1546-8709; Bjorn Kristensen, Lasse/0000-0002-3939-8170	We thank members of the Matter Lab for annotating task plans. We would also like to thank the Acceleration Consortium and Google Inc. for their generous support (NSERC-Google Industrial Research Chair Award). L.B.K. acknowledges generous support from the C; Google Inc.; Carlsberg Foundation	We thank members of the Matter Lab for annotating task plans. We would also like to thank the Acceleration Consortium and Google Inc. for their generous support (NSERC-Google Industrial Research Chair Award). L.B.K. acknowledges generous support from the C; Google Inc.(Google Incorporated); Carlsberg Foundation(Carlsberg Foundation)	We thank members of the Matter Lab for annotating task plans. We would also like to thank the Acceleration Consortium and Google Inc. for their generous support (NSERC-Google Industrial Research Chair Award). L.B.K. acknowledges generous support from the Carlsberg Foundation.	Abolhasani M, 2023, NAT SYNTH, V2, P483, DOI 10.1038/s44160-022-00231-0; Ahn M., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.01691; Baier JA, 2009, ARTIF INTELL, V173, P593, DOI 10.1016/j.artint.2008.11.011; Beeson P, 2015, IEEE-RAS INT C HUMAN, P928, DOI 10.1109/HUMANOIDS.2015.7363472; Berenson D, 2011, INT J ROBOT RES, V30, P1435, DOI 10.1177/0278364910396389; Boiko D. A., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.05332; Bran A. M., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.05376; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12712; Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2; Chen Mark., 2021, EVALUATING LARGE LAN, P2021, DOI [DOI 10.48550/ARXIV.2107.03374, 10.48550/ARXIV.2107.03374]; Chowdhery A., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.02311; Coleman D., 2014, Journal of Software Engineering for Robotics, DOI DOI 10.6092/JOSER_2014_05_01_P3; Dantam NT, 2018, INT J ROBOT RES, V37, P1134, DOI 10.1177/0278364918761570; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding Y., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2212.09672; Driess D., 2023, ARXIV230303378, DOI DOI 10.48550/ARXIV.2303.03378; Driess D., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2006.05398; Edwards C., 2022, 220411817 ARXIV, DOI DOI 10.48550/ARXIV.2204.11817; Eppel S, 2020, ACS CENTRAL SCI, V6, P1743, DOI 10.1021/acscentsci.0c00460; Epps RW, 2020, ADV MATER, V32, DOI 10.1002/adma.202001626; Eysenbach B., 2019, Advances in neural information processing systems, V32; Fakhruldeen H., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2204.13571; FORTMAN JJ, 1992, J CHEM EDUC, V69, P66, DOI 10.1021/ed069p66.1; Garrett C. R., 2020, P INT C AUTOMATED PL, V30, P440; Garrett CR, 2021, ANNU REV CONTR ROBOT, V4, P265, DOI 10.1146/annurev-control-091420-084139; Ghallab M., 1998, TR98003DCSTR1165 CVC; Grinberg M., 2018, Flask web development: developing web applications with python; Häse F, 2019, TRENDS CHEM, V1, P282, DOI 10.1016/j.trechm.2019.02.007; Helmert M, 2006, J ARTIF INTELL RES, V26, P191, DOI 10.1613/jair.1705; Higgins K, 2021, J AM CHEM SOC, V143, P19945, DOI 10.1021/jacs.1c10045; Huang DA, 2019, PROC CVPR IEEE, P8557, DOI 10.1109/CVPR.2019.00876; Huang W., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2207.05608; Huang WL, 2022, PR MACH LEARN RES; Huang YQ, 2021, ROBOT AUTON SYST, V136, DOI 10.1016/j.robot.2020.103692; Inagaki T., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.10267; Irwin R, 2022, MACH LEARN-SCI TECHN, V3, DOI 10.1088/2632-2153/ac3ffb; Jablonka K. M., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-fw8n4, DOI 10.26434/CHEMRXIV-2023-FW8N4]; Kaelbling LP, 2011, IEEE INT CONF ROBOT, P1470; Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761; Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439; Kennedy M, 2019, IEEE ROBOT AUTOM LET, V4, P2317, DOI 10.1109/LRA.2019.2902075; Khodeir M., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2210.14055; Khodeir M, 2023, IEEE ROBOT AUTOM LET, V8, P1983, DOI 10.1109/LRA.2023.3242201; Kim B, 2022, INT J ROBOT RES, V41, P210, DOI 10.1177/02783649211038280; Kingston Z, 2019, INT J ROBOT RES, V38, P1151, DOI 10.1177/0278364919868530; Kingston Z, 2018, ANNU REV CONTR ROBOT, V1, P159, DOI 10.1146/annurev-control-060117-105226; Kitchener BB, 2017, PROG PHYS GEOG, V41, P620, DOI 10.1177/0309133317726540; Knobbe D, 2022, IEEE INT C INT ROBOT, P2335, DOI 10.1109/IROS47612.2022.9981636; Le H., 2022, Advances in Neural Information Processing Systems, V35, P21314; Li JG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15728-5; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liang J., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2209.07753; Lim JXY, 2021, IEEE T AUTOM SCI ENG, V18, P2185, DOI 10.1109/TASE.2020.3036055; Lin K., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.12153; Liu Ruibo, 2023, 11 INT C LEARN REPR; Macarron R, 2011, NAT REV DRUG DISCOV, V10, P188, DOI 10.1038/nrd3368; MacLeod BP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz8867; Mehr H., 2020, BENCHMARKING RESULTS; Mehr SHM, 2020, SCIENCE, V370, P101, DOI 10.1126/science.abc2986; Ménard AD, 2020, NAT CHEM, V12, P17, DOI 10.1038/s41557-019-0375-x; Mialon G, 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.07842; Mirchandani S., 2021, ADV NEURAL INFORM PR, V34, P29529; Mishra S., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2104.08773; Muchacho RIC, 2022, IEEE INT C INT ROBOT, P223, DOI 10.1109/IROS47612.2022.9981173; National Astronomical Observatory of Japan, 2022, HDB SCI TABL, DOI [10.1142/11218, DOI 10.1142/11218]; Ni A., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.08468; Olson E, 2011, IEEE INT CONF ROBOT; Peng B., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.12813; Pereira DA, 2007, BRIT J PHARMACOL, V152, P53, DOI 10.1038/sj.bjp.0707373; Perry T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P20; Pizzuto G., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2209.14875; Ramos M. C., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.05341; Schick T., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.04761; Seifrid M, 2022, ACCOUNTS CHEM RES, DOI [10.1021/acs.accounts.2c00220, 10.1021/acs.accounts.2c002202454]; Shah D., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2111.03189; Sharma P., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2110.01517; Shiri P, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102176; Singh I., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2209.11302; Steiner S, 2019, SCIENCE, V363, P144, DOI 10.1126/science.aav2211; Taylor R., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.09085; Tellex S., 2011, AAAI, V25; Toussaint M, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; Toussaint M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1930; Wang SH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4195; Wang Y. R., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.11683; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wolthuis E., 1960, J CHEM EDUC, V37, P137, DOI [10.1021/ed037p137, DOI 10.1021/ED037P137]; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Xu D, 2019, ADV NEUR IN, V32; Xu DF, 2018, IEEE INT CONF ROBOT, P3795; Xu H., 2021, ANN C ROB LEARN; Yoshikawa N, 2023, DIGIT DISCOV, V2, P1745, DOI 10.1039/d3dd00115f; YOSHIKAWA T, 1985, INT J ROBOT RES, V4, P3, DOI 10.1177/027836498500400201; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang K., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2011.02398	96	4	4	41	53	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0929-5593	1573-7527		AUTON ROBOT	Auton. Robot.	DEC	2023	47	8					1057	1086		10.1007/s10514-023-10136-2	http://dx.doi.org/10.1007/s10514-023-10136-2		OCT 2023	30	Computer Science, Artificial Intelligence; Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Robotics	LM3O8		hybrid			2024-07-03	WOS:001090433300001
J	Li, YX; Li, ZH; Zhang, K; Dan, RL; Jiang, S; Zhang, Y				Li, Yunxiang; Li, Zihan; Zhang, Kai; Dan, Ruilong; Jiang, Steve; Zhang, You			ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						ai chatbot; large language model; llama; chat gpt; gpt	LIMITS	Objective The primary aim of this research was to address the limitations observed in the medical knowledge of prevalent large language models (LLMs) such as ChatGPT, by creating a specialized language model with enhanced accuracy in medical advice. Methods We achieved this by adapting and refining the large language model meta-AI (LLaMA) using a large dataset of 100,000 patient-doctor dialogues sourced from a widely used online medical consultation platform. These conversations were cleaned and anonymized to respect privacy concerns. In addition to the model refinement, we incorporated a self-directed information retrieval mechanism, allowing the model to access and utilize real-time information from online sources like Wikipedia and data from curated offline medical databases. Results The fine-tuning of the model with real-world patient-doctor interactions significantly improved the model's ability to understand patient needs and provide informed advice. By equipping the model with self-directed information retrieval from reliable online and offline sources, we observed substantial improvements in the accuracy of its responses. Conclusion Our proposed ChatDoctor, represents a significant advancement in medical LLMs, demonstrating a significant improvement in understanding patient inquiries and providing accurate advice. Given the high stakes and low error tolerance in the medical field, such enhancements in providing accurate and reliable information are not only beneficial but essential.	[Li, Yunxiang; Jiang, Steve; Zhang, You] Univ Texas Southwestern Med Ctr Dallas, Dept Radiat Oncol, Dallas, TX 75390 USA; [Li, Zihan] Univ Illinois, Dept Comp Sci, Champaign, IL USA; [Zhang, Kai] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH USA; [Dan, Ruilong] Hangzhou Dianzi Univ, Coll Comp Sci & Technol, Hangzhou, Peoples R China	University of Texas System; University of Texas Southwestern Medical Center Dallas; University of Illinois System; University of Illinois Urbana-Champaign; University System of Ohio; Ohio State University; Hangzhou Dianzi University	Zhang, Y (corresponding author), Univ Texas Southwestern Med Ctr Dallas, Dept Radiat Oncol, Dallas, TX 75390 USA.	you.zhang@utsouthwestern.edu	Zhang, Kai/KOD-2592-2024; Jiang, Steve/GRO-3951-2022; Li, Yunxiang/JDN-1420-2023	Zhang, Kai/0000-0003-3850-5429; Li, Yunxiang/0000-0003-0622-4710; Li, Zihan/0009-0004-3839-0611	National Institutes of Health [R01 CA240808, R01 CA258987]	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by the National Institutes of Health (Grant No. R01 CA240808, R01 CA258987).	Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Beeson AM, 2023, PEDIATRICS, V151, DOI 10.1542/peds.2022-060179; Ben Abacha A, 2015, INFORM PROCESS MANAG, V51, P570, DOI 10.1016/j.ipm.2015.04.006; Beutel G, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04425-6; Gessain A, 2022, NEW ENGL J MED, V387, P1783, DOI 10.1056/NEJMra2208860; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; github, 2023, STANF ALP INSTR FOLL; Hammerling JA, 2012, LABMEDICINE, V43, P41, DOI 10.1309/LM6ER9WJR1IHQAUY; Hatherley JJ, 2020, J MED ETHICS, V46, P478, DOI 10.1136/medethics-2019-105935; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Manakul P, 2023, Arxiv, DOI [arXiv:2303.08896, 10.48550/arXiv.2303.08896]; nist, 2005, RETR SYST EV; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04473-y; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaishya R, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102744; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Xu RX, 2021, Arxiv, DOI arXiv:2109.05687; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]	19	26	26	42	82	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUN 24	2023	15	6							e40895	10.7759/cureus.40895	http://dx.doi.org/10.7759/cureus.40895			12	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	R0MW6	37492832	Green Published, Green Submitted, gold			2024-07-03	WOS:001061379400014
J	Kim, JK; Chua, M; Rickard, M; Lorenzo, A				Kim, Jin K.; Chua, Michael; Rickard, Mandy; Lorenzo, Armando			ChatGPT and large language model (LLM) chatbots: The current state of acceptability and a proposal for guidelines on utilization in academic medicine	JOURNAL OF PEDIATRIC UROLOGY			English	Review						Large language model; ChatGPT; Generative pre-trained transformer; Artificial intelligence		IntroductionThere is currently no clear consensus on the standards for using large language models such as ChatGPT in academic medicine. Hence, we performed a scoping review of available literature to understand the current state of LLM use in medicine and to provide a guideline for future utilization in academia.Materials and methodsA scoping review of the literature was performed through a Medline search on February 16, 2023 using a combination of keywords including artificial intelligence, machine learning, natural language processing, generative pretrained transformer, ChatGPT, and large language model. There were no restrictions to language or date of publication. Records not pertaining to LLMs were excluded. Records pertaining to LLM ChatBots and ChatGPT were identified and evaluated separately. Among the records pertaining to LLM ChatBots and ChatGPT, those that suggest recommendations for ChatGPT use in academia were utilized to create guideline statements for ChatGPT and LLM use in academic medicine.ResultsA total of 87 records were identified. 30 records were not pertaining to large language models and were excluded. 54 records underwent a full-text review for evaluation. There were 33 records related to LLM ChatBots or ChatGPT.DiscussionFrom assessing these texts, five guideline state-ments for LLM use was developed: (1) ChatGPT/LLM cannot be cited as an author in scientific manu -scripts; (2) If use of ChatGPT/LLM are considered for use in academic work, author(s) should have at least a basic understanding of what ChatGPT/LLM is; (3) Do not use ChatGPT/LLM to produce entirety of text in manuscripts; humans must be held accountable for use of ChatGPT/LLM and contents created by ChatGPT/LLM should be meticulously verified by humans; (4) ChatGPT/LLMs may be used for editing and refining of text; (5) Any use of ChatGPT/LLM should be transparent and should be clearly outlined in scientific manuscripts and acknowledged.ConclusionFuture authors should remain mindful of the po-tential impact their academic work may have on healthcare and continue to uphold the highest ethical standards and integrity when utilizing ChatGPT/LLM.	[Kim, Jin K.; Chua, Michael; Rickard, Mandy; Lorenzo, Armando] Hosp Sick Children, Dept Surg, Div Urol, Toronto, ON, Canada; [Kim, Jin K.; Chua, Michael; Lorenzo, Armando] Univ Toronto, Dept Surg, Div Urol, Toronto, ON, Canada; [Chua, Michael] St Lukes Med Ctr, Inst Urol, Quezon City, Philippines; [Kim, Jin K.] Hosp Sick Children, Div Urol, 555 Univ Ave, Toronto, ON M5G 1X8, Canada	University of Toronto; Hospital for Sick Children (SickKids); University of Toronto; Saint Lukes Medical Center - Philippines; University of Toronto; Hospital for Sick Children (SickKids)	Kim, JK (corresponding author), Hosp Sick Children, Div Urol, 555 Univ Ave, Toronto, ON M5G 1X8, Canada.	jjk.kim@mail.utoronto.ca		Rickard, Mandy/0000-0003-0598-1824				[Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; ChatGPT, Optimizing Language models for dialogue; Curtis N, 2023, PEDIATR INFECT DIS J, V42, P275, DOI 10.1097/INF.0000000000003852; Davey M, 2020, BBC Science FocusSeptember 7; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Gao CA, 2022, bioRxiv, DOI [10.1101/2022.12.23.521610, 10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gibney E, 2022, NATURE, V606, P850, DOI 10.1038/d41586-022-01705-z; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gordijn B, 2023, MED HEALTH CARE PHIL, V26, P1, DOI 10.1007/s11019-023-10136-0; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.5; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kim JK, 2018, J PEDIATR SURG, V53, P2041, DOI 10.1016/j.jpedsurg.2017.11.050; Klang E, 2023, J THROMB HAEMOST, V21, P1055, DOI 10.1016/j.jtha.2023.01.011; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Looi MK, 2023, BMJ-BRIT MED J, V380, DOI 10.1136/bmj.p205; Mogali SR, 2024, ANAT SCI EDUC, V17, P444, DOI 10.1002/ase.2261; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; Park SH, 2023, KOREAN J RADIOL, V24, P171, DOI 10.3348/kjr.2023.0112; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tsigaris P, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2179919; Vallance C, 2022, BBC NewsJune 13; Yeo-Teh NSL, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2177160	29	25	25	193	240	ELSEVIER SCI LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	1477-5131	1873-4898		J PEDIATR UROL	J. Pediatr. Urol	OCT	2023	19	5					598	604		10.1016/j.jpurol.2023.05.018	http://dx.doi.org/10.1016/j.jpurol.2023.05.018		SEP 2023	7	Pediatrics; Urology & Nephrology	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics; Urology & Nephrology	U6XB4	37328321				2024-07-03	WOS:001086204600001
J	Frydenlund, E; Martinez, J; Padilla, JJ; Palacio, K; Shuttleworth, D				Frydenlund, Erika; Martinez, Joseph; Padilla, Jose J.; Palacio, Katherine; Shuttleworth, David			Modeler in a box: how can large language models aid in the simulation modeling process?	SIMULATION-TRANSACTIONS OF THE SOCIETY FOR MODELING AND SIMULATION INTERNATIONAL			English	Article; Early Access						natural language processing; language models; modeling and simulation		We examine the potential of prompting a large language model-based chatbot, ChatGPT, to generate functional simulation model code from a prose-based narrative. The simple narrative describes how the mode of transportation for elementary school students changed due to the COVID-19 pandemic and related factors, including a lack of available bus drivers, lack of mask enforcement on buses, and inclement weather. We document the process of providing this narrative to ChatGPT and further prompting the chatbot to generate model code to represent the narrative and to make it executable. We test ChatGPT's ability to use prose descriptions of a phenomenon to generate simulation models using three paradigms: discrete event system, system dynamics, and agent-based modeling. Our findings reveal that ChatGPT could not produce concise or executable models, facing higher difficulty when asked to do so in programming languages it was less familiar with. This analysis underscores the strengths and limitations of the current state of this technology for modeling and simulation. Furthermore, we propose how future advancements in Large Language Models may aid the simulation modeling process, increasing transparency and participation in multidisciplinary team efforts.	[Frydenlund, Erika; Martinez, Joseph; Padilla, Jose J.] Old Dominion Univ, Virginia Modeling Anal & Simulat Ctr, 1030 Univ Blvd, Suffolk, VA 23435 USA; [Martinez, Joseph; Shuttleworth, David] Old Dominion Univ, Dept Elect & Comp Engn, Suffolk, VA 23435 USA; [Palacio, Katherine] Univ Norte, Dept Ind Engn, Barranquilla, Colombia	Old Dominion University; Old Dominion University; Universidad del Norte Colombia	Frydenlund, E (corresponding author), Old Dominion Univ, Virginia Modeling Anal & Simulat Ctr, 1030 Univ Blvd, Suffolk, VA 23435 USA.	efrydenl@odu.edu		Martinez, Joseph/0000-0002-2244-8274	Office of Naval Research [N00014-19-1-2624]; Air Force Office of Scientific Research under the Minerva Research Initiative [22RT0286]	Office of Naval Research(United States Department of DefenseUnited States NavyOffice of Naval Research); Air Force Office of Scientific Research under the Minerva Research Initiative(United States Department of DefenseAir Force Office of Scientific Research (AFOSR))	This material, in part, was funded by a grant through the Office of Naval Research (N00014-19-1-2624) and a grant through the Air Force Office of Scientific Research (22RT0286) under the Minerva Research Initiative. The US Government is authorized to reproduce and distribute reprints for Governmental purposes not withstanding any copyright notation thereon. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of the Office of Naval Research (ONR)or the Air Force Office of Scientific Research (AFOSR).	Ayadi A., 2023, SIMULATION, V99, P1011; Balci O, 2012, SIMUL-T SOC MOD SIM, V88, P870, DOI 10.1177/0037549712438469; Bell AR, 2015, ENVIRON MODELL SOFTW, V73, P189, DOI 10.1016/j.envsoft.2015.07.016; Bommasani R., 2022, ARXIV; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chwif L, 2000, PROCEEDINGS OF THE 2000 WINTER SIMULATION CONFERENCE, VOLS 1 AND 2, P449, DOI 10.1109/WSC.2000.899751; de Mooij J, 2023, SIMUL-T SOC MOD SIM, V99, P1183, DOI 10.1177/00375497231184898; Devlin J., 2018, BERT PRE TRAINING DE; Duran JM, 2020, MIND MACH, V30, P301, DOI 10.1007/s11023-020-09520-z; Edwards B., 2023, Ars Technica; Gewirtz D., 2024, ZDNet; Giabbanelli P., 2023, arXiv; Hassani H, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7020062; Jalayer M., 2020, ARXIV; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Luitse D, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211047734; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Padilla JJ., 2023, The future of modeling and simulation; Padilla JJ, 2019, WINT SIMUL C PROC, P560, DOI 10.1109/WSC40007.2019.9004895; Padilla JJ, 2018, LECT NOTES COMPUT SC, V10899, P70, DOI 10.1007/978-3-319-93372-6_8; Page S.E., 2018, MODEL THINKER WHAT Y; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Sen S, 2010, SIMUL-T SOC MOD SIM, V86, P109, DOI 10.1177/0037549709340530; Sermanet P., 2013, ARXIV; Shrestha Anish, 2022, 2022 Winter Simulation Conference (WSC), P2629, DOI 10.1109/WSC57314.2022.10015446; Stolpe A., 2023, SIMULATION, V99, p003754972311573; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tolk A, 2013, J SIMUL, V7, P69, DOI 10.1057/jos.2013.3; Uhrmacher AM., 2016, 2016 WINT SIM C WSC; Ulbinait A., 2010, Ekonomika, V89, P95; Vaswani A, 2017, ADV NEUR IN, V30; Vennix JAM, 1999, SYST DYNAM REV, V15, P379, DOI 10.1002/(SICI)1099-1727(199924)15:4<379::AID-SDR179>3.0.CO;2-E; White J., 2023, arXiv; Yu WH, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P52	35	0	0	4	4	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	0037-5497	1741-3133		SIMUL-T SOC MOD SIM	Simul.-Trans. Soc. Model. Simul. Int.	2024 APR 14	2024										10.1177/00375497241239360	http://dx.doi.org/10.1177/00375497241239360		APR 2024	23	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	NX6T1					2024-07-03	WOS:001203798300001
J	Tripathi, S; Gabriel, K; Tripathi, PK; Kim, E				Tripathi, Satvik; Gabriel, Kyla; Tripathi, Pushpendra Kumar; Kim, Edward			Large language models reshaping molecular biology and drug development	CHEMICAL BIOLOGY & DRUG DESIGN			English	Article						artificial intelligence; drug development; large language models; molecular biology	PRECISION MEDICINE; GENOMICS	The utilization of large language models (LLMs) has become a significant advancement in the domains of medicine and clinical informatics, providing a revolutionary potential for scientific breakthroughs and customized therapies. LLM models are trained on large datasets and exhibit the capacity to comprehend and analyze intricate biological data, encompassing genomic sequences, protein structures, and clinical health records. With the utilization of their comprehension of the language of biology, they possess the ability to reveal concealed patterns and insights that may evade human researchers. LLMs have been shown to positively impact various aspects of molecular biology, including the following: genomic analysis, drug development, precision medicine, biomarker development, experimental design, collaborative research, and accessibility to specialized expertise. However, it is imperative to acknowledge and tackle the obstacles and ethical implications involved. The careful consideration of data bias and generalization, data privacy and security, explainability and interpretability, and ethical concerns around responsible application is vital. The successful resolution of these obstacles will enable us to fully utilize the capabilities of LLMs, leading to substantial progress in the fields of molecular biology and pharmaceutical research. This progression also has the ability to bolster influential impacts for both the individual and the broader community. Exploring the transformative impact of large language models (LLMs) in molecular biology and drug development, discussing potential areas of applications and breakthroughs in personalized therapies. LLMs, trained on vast datasets, can decode intricate biological information, from genomic sequences to clinical records, comprehending hidden patterns. While enhancing molecular biology aspects, we also address ethical concerns ensuring responsible application of these models.image	[Tripathi, Satvik; Kim, Edward] Drexel Univ, Philadelphia, PA 19104 USA; [Tripathi, Satvik; Gabriel, Kyla] Harvard Med Sch, Boston, MA USA; [Tripathi, Pushpendra Kumar] Lucknow Univ, Lucknow, UP, India	Drexel University; Harvard University; Harvard Medical School; Lucknow University	Kim, E (corresponding author), Drexel Univ, Philadelphia, PA 19104 USA.	ek826@drexel.edu						Abdulhamid NG, 2023, PROCEEDINGS OF THE 4TH AFRICAN CONFERENCE FOR HUMAN COMPUTER INTERACTION, AFRICHI 2023, P64, DOI 10.1145/3628096.3628752; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aher GV, 2023, INT C MACHINE LEARNI, P337; AlMarzouqi A., 2024, Artificial intelligence in education: The power and dangers of ChatGPT in the classroom; Anil C., 2022, Advances in Neural Information Processing Systems, V35, P38546; Benegas G., 2023, Proceedings of the National Academy of Sciences of the United States of America, V120, DOI DOI 10.1073/PNAS.2311219120; Branting LK, 2021, ARTIF INTELL LAW, V29, P213, DOI 10.1007/s10506-020-09273-1; Bustamante CD, 2011, NATURE, V475, P163, DOI 10.1038/475163a; Chakraborty C, 2023, MOL THER-NUCL ACIDS, V33, P866, DOI 10.1016/j.omtn.2023.08.009; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chatterjee S, 2023, MOL THER-NUCL ACIDS, V33, P205, DOI 10.1016/j.omtn.2023.06.019; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Consens ME, 2023, Arxiv, DOI [arXiv:2311.07621, DOI 10.48550/ARXIV.2311.07621]; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Das BC, 2024, Arxiv, DOI arXiv:2402.00888; Dzau VJ, 2016, JAMA-J AM MED ASSOC, V316, P1659, DOI 10.1001/jama.2016.14117; Janet J.P., 2020, Machine Learning in Chemistry, VVolume 1; Kosorok MR, 2019, ANNU REV STAT APPL, V6, P263, DOI 10.1146/annurev-statistics-030718-105251; Lian XY, 2024, Arxiv, DOI arXiv:2310.09690; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Liang YW, 2023, Arxiv, DOI arXiv:2309.03907; Liu SC, 2023, Arxiv, DOI [arXiv:2305.18090, DOI 10.48550/ARXIV.2305.18090]; Makridakis S, 2023, FORECASTING-BASEL, V5, P536, DOI 10.3390/forecast5030030; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Pan XD, 2020, P IEEE S SECUR PRIV, P1314, DOI 10.1109/SP40000.2020.00095; Patrinos GP, 2023, PHARMACOGENOMICS J, V23, P178, DOI 10.1038/s41397-023-00316-9; Paul D, 2020, DRUG DISCOV TODAY, V26, P80, DOI 10.1016/j.drudis.2020.10.010; Pencina MJ, 2016, JAMA-J AM MED ASSOC, V315, P1713, DOI 10.1001/jama.2016.4839; Peris C, 2023, P 16 ACM INT C WEB S, P1291; Plant R, 2022, Arxiv, DOI arXiv:2204.09391; Poon H, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P5825, DOI 10.1145/3580305.3599568; Karim MR, 2023, Arxiv, DOI arXiv:2310.08365; Shahin MH, 2024, CLIN PHARMACOL THER, V115, P698, DOI 10.1002/cpt.3083; Sharma G, 2023, chemRxiv, DOI [10.26434/chemrxiv-2023-qgs3k, 10.26434/chemrxiv-2023-qgs3k, DOI 10.26434/CHEMRXIV-2023-QGS3K]; Terranova N, 2024, CLIN PHARMACOL THER, V115, P658, DOI 10.1002/cpt.3053; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tripathi S., 2022, Artificial Intelligence in the Life Sciences, V2; Tripathi S, 2024, J AM MED INFORM ASSN, V31, P1436, DOI 10.1093/jamia/ocad258; Vellido A, 2020, NEURAL COMPUT APPL, V32, P18069, DOI 10.1007/s00521-019-04051-w; Yang MH, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac298; Yelmen B, 2021, PLOS GENET, V17, DOI 10.1371/journal.pgen.1009303; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Yue TW, 2023, INT J MOL SCI, V24, DOI 10.3390/ijms242115858	43	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1747-0277	1747-0285		CHEM BIOL DRUG DES	Chem. Biol. Drug Des.	JUN	2024	103	6							e14568	10.1111/cbdd.14568	http://dx.doi.org/10.1111/cbdd.14568			5	Biochemistry & Molecular Biology; Chemistry, Medicinal	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	UW7M9	38898381				2024-07-03	WOS:001251167800001
J	Shang, YT				Shang, Yuting			Music Curriculum Research Using a Large Language Model, Cloud Computing and Data Mining Technologies	JOURNAL OF WEB ENGINEERING			English	Article						Large language model; cloud computing; data mining; music; curriculum model		This paper presents a method to enhance the scientific nature of the music curriculum model by integrating a large language model, cloud computing and data mining technology for the analysis of the music teaching curriculum model. To maintain the integrity of the mixing matrix while employing the frequency hopping frequency, the paper suggests dividing the mixing matrix into a series of sub-matrices along the vertical time axis. This approach transforms wideband music signal processing into a narrowband processing problem. Additionally, two hybrid matrix estimation algorithms are proposed in this paper using underdetermined conditions. Furthermore, utilizing the estimated mixing matrix and the detected time-frequency support domain, the paper employs the subspace projection algorithm for underdetermined blind separation of music signals in the time-frequency domain. This procedure, along with the integration of the estimated direction of arrival (DoA), enables the completion of frequency-hopping network station music signal sorting. Extensive simulation teaching demonstrates that the music curriculum model proposed in this paper, based on a large language model, cloud computing and data mining technologies, significantly enhances the quality of modern music teaching.	[Shang, Yuting] Nanchong Vocat & Tech Coll, Nanchong 637131, Peoples R China		Shang, YT (corresponding author), Nanchong Vocat & Tech Coll, Nanchong 637131, Peoples R China.	15298227288@163.com						Amendola A, 2017, GEOPHYS PROSPECT, V65, P49, DOI 10.1111/1365-2478.12504; Anaya Amarillas J. A., INTERdisciplina, V9, P333; Cano E, 2019, IEEE SIGNAL PROC MAG, V36, P31, DOI 10.1109/MSP.2018.2874719; Costa-Giomi E, 2017, INT J COMMUNITY MUSI, V10, P289, DOI 10.1386/ijcm.10.3.289_1; Dickens A, 2018, J AUDIO ENG SOC, V66, P211, DOI 10.17743/jaes.2018.0010; Gonsalves L. L., 2020, Rev. Informatica Teorica E Apl., V27, P95; Gorbunova I., 2019, Opcion, V35, P360; Gorbunova I. B., 2019, Int. J. Supply Chain Manag., P436; Khulusi R, 2020, COMPUT GRAPH FORUM, V39, P82, DOI 10.1111/cgf.13905; Magnusson T, 2021, J NEW MUSIC RES, V50, P175, DOI 10.1080/09298215.2021.1907420; Michalakos C, 2021, ORGAN SOUND, V26, P78, DOI 10.1017/S1355771821000078; Scavone G., 2021, J. Acoust. Soc. Am., V150, P3; Stensæth K, 2018, NORD J MUSIC THER, V27, P312, DOI 10.1080/08098131.2018.1439085; Tabuena A.C., 2020, Int. J. Res. Publ., V66, P1, DOI [DOI 10.47119/IJRP1006611220201595, 10.47119/IJRP1006611220201595]; Turchet L, 2021, PERS UBIQUIT COMPUT, V25, P749, DOI 10.1007/s00779-020-01395-2; Turchet L, 2019, J NEW MUSIC RES, V48, P352, DOI 10.1080/09298215.2019.1637439; Vereshchahina-Biliavska O. Y., 2021, Linguist. Cult. Rev., V5, P108; Way LCS, 2021, SOC SEMIOT, V31, P489, DOI 10.1080/10350330.2021.1930857	18	0	0	0	0	RIVER PUBLISHERS	GISTRUP	ALSBJERGVEJ 10, GISTRUP, 9260, DENMARK	1540-9589	1544-5976		J WEB ENG	J. Web Eng.		2024	23	2					251	274		10.13052/jwe1540-9589.2323	http://dx.doi.org/10.13052/jwe1540-9589.2323			24	Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QT8T1		hybrid			2024-07-03	WOS:001223218700001
J	Van Heerden, AC; Pozuelo, JR; Kohrt, BA				Van Heerden, Alastair C.; Pozuelo, Julia R.; Kohrt, Brandon A.			Global Mental Health Services and the Impact of Artificial Intelligence-Powered Large Language Models	JAMA PSYCHIATRY			English	Editorial Material								This Viewpoint describes ways in which artificial intelligence-powered large language models may be used to improve the delivery of mental health services worldwide.	[Van Heerden, Alastair C.] Human Sci Res Council, Ctr Community Based Res, Pietermaritzburg, South Africa; [Van Heerden, Alastair C.] Univ Witwatersrand, Wits Dev Pathways Hlth Res Unit, SAMRC, Johannesburg, South Africa; [Pozuelo, Julia R.] Harvard Univ, Harvard Med Sch, Dept Global Hlth & Social Med, Boston, MA USA; [Pozuelo, Julia R.] Univ Oxford, Dept Psychiat, Oxford, England; [Kohrt, Brandon A.] George Washington Sch Med & Hlth Sci, Ctr Global Mental Hlth Equ, Dept Psychiat & Behav Sci, Washington, DC USA; [Van Heerden, Alastair C.] Human Sci Res Council, ZA-3201 Pietermaritzburg, South Africa	University of Witwatersrand; Harvard University; Harvard Medical School; University of Oxford; George Washington University	Van Heerden, AC (corresponding author), Human Sci Res Council, ZA-3201 Pietermaritzburg, South Africa.	avanheerden@hsrc.ac.za	Van Heerden, Alastair/AAY-6262-2020	Van Heerden, Alastair/0000-0003-2530-6885; Ruiz Pozuelo, Julia/0000-0002-3058-0371				Brown TB., ARXIV; Devlin J., ARXIV; Doran D., ARXIV; Ewbank MP, 2020, JAMA PSYCHIAT, V77, P35, DOI 10.1001/jamapsychiatry.2019.2664; Kessler RC, 2021, JAMA PSYCHIAT, V78, P1384, DOI 10.1001/jamapsychiatry.2021.2500; Kohrt BA, 2015, BEHAV RES THER, V69, P11, DOI 10.1016/j.brat.2015.03.009; Patel V., 2022, SSM-MENT HEALTH, V2, DOI [DOI 10.1016/J.SSMMH.2022.100072, 10.1016/j.ssmmh.2022.100072]; Shatte ABR, 2019, PSYCHOL MED, V49, P1426, DOI 10.1017/S0033291719000151; van Ginneken N, 2021, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD009149.pub3; Wei J., ARXIV	10	9	9	17	57	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-622X	2168-6238		JAMA PSYCHIAT	JAMA Psychiatry	JUL	2023	80	7					662	664		10.1001/jamapsychiatry.2023.1253	http://dx.doi.org/10.1001/jamapsychiatry.2023.1253		MAY 2023	3	Psychiatry	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychiatry	L7OS6	37195694				2024-07-03	WOS:000992439000004
C	Feldt, R; Kang, S; Yoon, J; Yoo, S			IEEE	Feldt, Robert; Kang, Sungmin; Yoon, Juyeon; Yoo, Shin			Towards Autonomous Testing Agents via Conversational Large Language Models	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		software testing; machine learning; large language model; artificial intelligence; test automation		Software testing is an important part of the development cycle, yet it requires specialized expertise and substantial developer effort to adequately test software. Recent discoveries of the capabilities of large language models (LLMs) suggest that they can be used as automated testing assistants, and thus provide helpful information and even drive the testing process. To highlight the potential of this technology, we present a taxonomy of LLM-based testing agents based on their level of autonomy, and describe how a greater level of autonomy can benefit developers in practice. An example use of LLMs as a testing assistant is provided to demonstrate how a conversational framework for testing can help developers. This also highlights how the often criticized "hallucination" of LLMs can be beneficial for testing. We identify other tangible benefits that LLM-driven testing agents can bestow, and also discuss potential limitations.	[Feldt, Robert] Chalmers Univ Technol, Gothenburg, Sweden; [Kang, Sungmin; Yoon, Juyeon; Yoo, Shin] Korea Adv Inst Sci & Technol, Daejeon, South Korea	Chalmers University of Technology; Korea Advanced Institute of Science & Technology (KAIST)	Feldt, R (corresponding author), Chalmers Univ Technol, Gothenburg, Sweden.	robert.feldt@chalmers.se; sungmin.kang@kaist.ac.kr; juyeon.yoon@kaist.ac.kr; shin.yoo@kaist.ac.kr			Swedish Scientific Council [2020-05272]; WASP ('Software Boundary Specification Mining (BoundMiner)'); Institute for Information & Communications Technology Promotion grant - Korean government MSIT [2022-0-00995]; Swedish Research Council [2020-05272] Funding Source: Swedish Research Council	Swedish Scientific Council; WASP ('Software Boundary Specification Mining (BoundMiner)'); Institute for Information & Communications Technology Promotion grant - Korean government MSIT(Ministry of Science & ICT (MSIT), Republic of Korea); Swedish Research Council(Swedish Research Council)	Robert Feldt has been supported by the Swedish Scientific Council (No. 2020-05272, 'Automated boundary testing for QUality of AI/ML modelS') and by WASP ('Software Boundary Specification Mining (BoundMiner)'). Sungmin Kang, Juyeon Yoon, and Shin Yoo were supported by the Institute for Information & Communications Technology Promotion grant funded by the Korean government MSIT (No.2022-0-00995).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2009, How Can the Human Mind Occur in the Physical Universe?; [Anonymous], 2013, JaCoCo Java Code Coverage Library; [Anonymous], 2023, Auto-GPT: An Autonomous GPT-4 Experiment; Arcuri A, 2018, EMPIR SOFTW ENG, V23, P1959, DOI 10.1007/s10664-017-9570-9; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bezanson J, 2012, Arxiv, DOI [arXiv:1209.5145, DOI 10.48550/ARXIV.1209.5145]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chase H., 2022, Langchain; Chen TY, 2010, J SYST SOFTWARE, V83, P60, DOI 10.1016/j.jss.2009.02.022; Dobslaw F, 2020, IEEE ICST WORKSHOP, P346, DOI 10.1109/ICSTW50294.2020.00062; Laird JE, 2022, Arxiv, DOI arXiv:2201.09305; Feldt R, 2018, INT WORK REAL ARTIF, P35, DOI 10.1145/3194104.3194109; Feldt R, 2016, IEEE INT CONF SOFTW, P223, DOI 10.1109/ICST.2016.33; Fraser G, 2012, IEEE T SOFTWARE ENG, V38, P278, DOI 10.1109/TSE.2011.93; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao LY, 2023, Arxiv, DOI [arXiv:2211.10435, 10.48550/arXiv.2211.10435, DOI 10.48550/ARXIV.2211.10435]; Haas R, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1281, DOI 10.1145/3468264.3473922; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Jalil S, 2023, Arxiv, DOI arXiv:2302.03287; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kang SM, 2023, Arxiv, DOI arXiv:2304.02195; Kang SM, 2022, Arxiv, DOI arXiv:2209.11515; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Laird J.E., 2019, The Soar cognitive architecture; Liang J. T, 2023, arXiv; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Polino A, 2018, Arxiv, DOI arXiv:1802.05668; Rutherford MJ, 2003, LECT NOTES COMPUT SC, V2830, P377; Shahin M, 2017, IEEE ACCESS, V5, P3909, DOI 10.1109/ACCESS.2017.2685629; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Winter ER, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1578, DOI 10.1145/3540250.3558953; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]	36	1	2	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1688	1693		10.1109/ASE56229.2023.00148	http://dx.doi.org/10.1109/ASE56229.2023.00148			6	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK		Green Submitted			2024-07-03	WOS:001103357200135
J	Borg, M				Borg, Markus			Requirements Engineering and Large Language Models: Insights From a Panel	IEEE SOFTWARE			English	Article						Requirements engineering; Task analysis; Software engineering		As a general-purpose technology, large language models promise to enhance various software engineering tasks. But how will they impact requirements engineering? This column offers a summary of an expert panel discussion from the 2023 International Requirements Engineering Conference in Hanover, Germany.	[Borg, Markus] CodeScene AB, S-21532 Malmo, Sweden		Borg, M (corresponding author), CodeScene AB, S-21532 Malmo, Sweden.	markus.borg@codescene.com	Borg, Markus/F-3609-2010	Borg, Markus/0000-0001-7879-4371				Devlin M.-W., 2018, ARXIV; Fan AEL, 2023, Arxiv, DOI arXiv:2310.03533; Guzik C., 2023, J. Creativity, V33, DOI [10.1016/j.yjoc.2023.100065.3.P, DOI 10.1016/J.YJOC.2023.100065.3.P]; Kabir S, 2024, Arxiv, DOI [arXiv:2308.02312, DOI 10.48550/ARXIV.2308.02312]; Mishra D., 2018, Creativity, Technology & Educa-tion: Exploring Their Convergence, P43	5	0	0	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0740-7459	1937-4194		IEEE SOFTWARE	IEEE Softw.	MAR-APR	2024	41	2					6	10		10.1109/MS.2023.3339934	http://dx.doi.org/10.1109/MS.2023.3339934			5	Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	KH3E4					2024-07-03	WOS:001179020800005
J	Kirtac, K; Germano, G				Kirtac, Kemal; Germano, Guido			Sentiment trading with large language models	FINANCE RESEARCH LETTERS			English	Article						Natural language processing (NLP); Large language models; Generative pre-trained transformer (GPT); pre (GPT) Machine learning in stock return prediction; Artificial intelligence investment strategies	INVESTOR SENTIMENT; RISK; RETURNS; NEWS	We analyse the performance of the large language models (LLMs) OPT, BERT, and FinBERT, alongside the traditional Loughran -McDonald dictionary, in the sentiment analysis of 965,375 U.S. financial news articles from 2010 to 2023. Our findings reveal that the GPT-3-based OPT model significantly outperforms the others, predicting stock market returns with an accuracy of 74.4%. A long -short strategy based on OPT, accounting for 10 basis points (bps) in transaction costs, yields an exceptional Sharpe ratio of 3.05. From August 2021 to July 2023, this strategy produces an impressive 355% gain, outperforming other strategies and traditional market portfolios. This underscores the transformative potential of LLMs in financial market prediction and portfolio management and the necessity of employing sophisticated language models to develop effective investment strategies based on news sentiment.	[Kirtac, Kemal; Germano, Guido] UCL, Dept Comp Sci, 66-72 Gower St, London WC1E 6EA, England; [Germano, Guido] London Sch Econ & Polit Sci, Syst Risk Ctr, Houghton St, London WC2A 2AE, England	University of London; University College London; University of London; London School Economics & Political Science	Kirtac, K (corresponding author), UCL, Dept Comp Sci, 66-72 Gower St, London WC1E 6EA, England.	kemal.kirtac.21@ucl.ac.uk						Acemoglu D, 2022, J LABOR ECON, V40, pS293, DOI 10.1086/718327; Alain G, 2018, Arxiv, DOI arXiv:1610.01644; Baker M, 2006, J FINANC, V61, P1645, DOI 10.1111/j.1540-6261.2006.00885.x; Baker SR, 2016, Q J ECON, V131, P1593, DOI 10.1093/qje/qjw024; Bybee Leland., 2019, The Structure of Economic News, DOI DOI 10.2139/SSRN.3446225; Calomiris CW, 2019, J FINANC ECON, V133, P299, DOI 10.1016/j.jfineco.2018.11.009; Campbell JL, 2014, REV ACCOUNT STUD, V19, P396, DOI 10.1007/s11142-013-9258-3; Carhart MM, 1997, J FINANC, V52, P57, DOI 10.2307/2329556; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; FAMA EF, 1993, J FINANC ECON, V33, P3, DOI 10.1016/0304-405X(93)90023-5; Frankel R, 2022, MANAGE SCI, V68, P5514, DOI 10.1287/mnsc.2021.4156; García D, 2013, J FINANC, V68, P1267, DOI 10.1111/jofi.12027; Hansen S, 2018, Q J ECON, V133, P801, DOI 10.1093/qje/qjx045; Hoberg G, 2016, J POLIT ECON, V124, P1423, DOI 10.1086/688176; Huang AH, 2023, CONTEMP ACCOUNT RES, V40, P806, DOI 10.1111/1911-3846.12832; Hugging Face, 2023, Hugging face's transformer models; Jegadeesh N, 2013, J FINANC ECON, V110, P712, DOI 10.1016/j.jfineco.2013.08.018; Ke Z., 2020, Predicting returns with text data, DOI [10.2139/ssrn.3389884, DOI 10.2139/SSRN.3389884]; Lemmon M., 2014, Rev. Financ. Stud., V27, P1367, DOI [10.1093/rfs/hhu006, DOI 10.1093/RFS/HHU006]; Loughran T, 2022, Master Loughran-MacDonald word dictionary; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; MacKinlay AC, 1997, J ECON LIT, V35, P13; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; Manela A, 2017, J FINANC ECON, V123, P137, DOI 10.1016/j.jfineco.2016.01.032; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Shapiro AH, 2022, J ECONOMETRICS, V228, P221, DOI 10.1016/j.jeconom.2020.07.053; Tetlock PC, 2007, J FINANC, V62, P1139, DOI 10.1111/j.1540-6261.2007.01232.x; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	29	0	0	16	16	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1544-6123	1544-6131		FINANC RES LETT	Financ. Res. Lett.	APR	2024	62		B						105227	10.1016/j.frl.2024.105227	http://dx.doi.org/10.1016/j.frl.2024.105227		MAR 2024	9	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	QA4B9					2024-07-03	WOS:001218136400001
J	Mondal, D; Lipizzi, C				Mondal, Devam; Lipizzi, Carlo			Mitigating Large Language Model Bias: Automated Dataset Augmentation and Prejudice Quantification	COMPUTERS			English	Article						natural language processing; large language models; dataset augmentation; computational social science		Despite the growing capabilities of large language models, concerns exist about the biases they develop. In this paper, we propose a novel, automated mechanism for debiasing through specified dataset augmentation in the lens of bias producers that can be useful in a variety of industries, especially ones that are "restricted" and have limited data. We consider that bias can occur due to intrinsic model architecture and dataset quality. The two aspects are evaluated using two different metrics we created. We show that our dataset augmentation algorithm reduces bias as measured by our metrics. Our code can be found on an online GitHub repository.	[Mondal, Devam; Lipizzi, Carlo] Stevens Inst Technol, Ctr Complex Syst & Enterprises, Hoboken, NJ 07030 USA	Stevens Institute of Technology	Mondal, D; Lipizzi, C (corresponding author), Stevens Inst Technol, Ctr Complex Syst & Enterprises, Hoboken, NJ 07030 USA.	dmondal@stevens.edu; clipizzi@stevens.edu						Batanovic V, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242050; Dixon L, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P67, DOI 10.1145/3278721.3278729; Geva M, 2019, Arxiv, DOI arXiv:1908.07898; Guo Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1012; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Huang PS, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P65; Lee H., 2023, P 61 ANN M ASS COMP, P6026; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Mikhailov DI, 2023, Arxiv, DOI arXiv:2305.13927; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Navigli R, 2023, ACM J DATA INF QUAL, V15, DOI 10.1145/3597307; Ranaldi L, 2023, Arxiv, DOI arXiv:2305.13862; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; White J., 2021, arXiv; Wiegand M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P602	15	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2073-431X			COMPUTERS	Computers	JUN	2024	13	6							141	10.3390/computers13060141	http://dx.doi.org/10.3390/computers13060141			9	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	WJ3M4		gold			2024-07-03	WOS:001254464100001
J	Pressman, SM; Borna, S; Gomez-Cabello, CA; Haider, SA; Haider, C; Forte, AJ				Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed A.; Haider, Clifton; Forte, Antonio J.			AI and Ethics: A Systematic Review of the Ethical Considerations of Large Language Model Use in Surgery Research	HEALTHCARE			English	Review						artificial intelligence (AI); ChatGPT; deep learning; machine learning; clinical medicine; surgical specialties; bioethical issues	ARTIFICIAL-INTELLIGENCE; NEUROSURGICAL RESEARCH; INCORPORATE CHATBOTS; HEALTH-CARE; CHATGPT; EDUCATION; FUTURE; IMPACT; WRITE; ERA	Introduction: As large language models receive greater attention in medical research, the investigation of ethical considerations is warranted. This review aims to explore surgery literature to identify ethical concerns surrounding these artificial intelligence models and evaluate how autonomy, beneficence, nonmaleficence, and justice are represented within these ethical discussions to provide insights in order to guide further research and practice. Methods: A systematic review was conducted in accordance with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses guidelines. Five electronic databases were searched in October 2023. Eligible studies included surgery-related articles that focused on large language models and contained adequate ethical discussion. Study details, including specialty and ethical concerns, were collected. Results: The literature search yielded 1179 articles, with 53 meeting the inclusion criteria. Plastic surgery, orthopedic surgery, and neurosurgery were the most represented surgical specialties. Autonomy was the most explicitly cited ethical principle. The most frequently discussed ethical concern was accuracy (n = 45, 84.9%), followed by bias, patient confidentiality, and responsibility. Conclusion: The ethical implications of using large language models in surgery are complex and evolving. The integration of these models into surgery necessitates continuous ethical discourse to ensure responsible and ethical use, balancing technological advancement with human dignity and safety.	[Pressman, Sophia M.; Borna, Sahar; Gomez-Cabello, Cesar A.; Haider, Syed A.; Forte, Antonio J.] Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA; [Haider, Clifton] Mayo Clin, Dept Physiol & Biomed Engn, Rochester, MN 55905 USA; [Forte, Antonio J.] Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA	Mayo Clinic; Mayo Clinic; Mayo Clinic	Forte, AJ (corresponding author), Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA.; Forte, AJ (corresponding author), Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA.	ajvforte@yahoo.com.br	Forte, Antonio/I-2970-2019; Pressman, Sophia/KOC-2466-2024	Forte, Antonio/0000-0003-2004-7538; Pressman, Sophia/0009-0000-0398-8024; Haider, Syed Ali/0009-0007-5621-2861; Gomez Cabello, Cesar Abraham/0009-0008-0603-3192				Abi-Rafeh J, 2024, AESTHET SURG J, V44, P329, DOI 10.1093/asj/sjad260; AI HLEG, 2019, Ethics Guidelines for Trustworthy Artificial Intelligence, P8; Aljindan FK, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005305; Allen JW, 2024, J MED ETHICS, V50, P77, DOI 10.1136/jme-2023-109347; Alonso A, 2023, SEMIN VASC SURG, V36, P426, DOI 10.1053/j.semvascsurg.2023.06.002; Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Atallah SB, 2023, TECH COLOPROCTOL, V27, P609, DOI 10.1007/s10151-023-02837-8; Ayoub A, 2019, BMC ORAL HEALTH, V19, DOI 10.1186/s12903-019-0937-8; Bassiri-Tehrani B, 2023, AESTHET SURG J, V43, P1395, DOI 10.1093/asj/sjad135; Beauchamp TL, 2019, Principles of Biomedical Ethics, V8th; Chappell AG, 2021, PLAST RECONSTR SURG, V148, p289E, DOI 10.1097/PRS.0000000000008232; Chen TC, 2023, WORLD NEUROSURG, V179, pE342, DOI 10.1016/j.wneu.2023.08.088; Chung KC, 2009, PLAST RECONSTR SURG, V124, P1711, DOI 10.1097/PRS.0b013e3181b98a9f; Cobianchi L, 2022, J AM COLL SURGEONS, V235, P268, DOI 10.1097/XCS.0000000000000242; Cocci A, 2024, PROSTATE CANCER P D, V27, P103, DOI 10.1038/s41391-023-00705-y; D'Amico RS, 2023, NEUROSURGERY, V93, pE78, DOI 10.1227/neu.0000000000002589; Dutton JJ, 2023, OPHTHAL PLAST RECONS, V39, P203, DOI 10.1097/IOP.0000000000002420; Esplugas M, 2023, J HAND SURG-EUR VOL, V48, P819, DOI 10.1177/17531934231185746; Ghaednia H, 2021, SPINE J, V21, P1617, DOI 10.1016/j.spinee.2021.03.018; Gupta R, 2023, AESTHET SURG J, V43, P930, DOI 10.1093/asj/sjad069; Hallock GR, 2023, ANN PLAS SURG, V91, P632, DOI 10.1097/SAP.0000000000003672; Hamet P, 2017, METABOLISM, V69, pS36, DOI 10.1016/j.metabol.2017.01.011; Hill ER, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1139210; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; Ishaaq N, 2023, OBES SURG, V33, P4159, DOI 10.1007/s11695-023-06875-x; Javid M, 2023, CAN J UROL, V30, P11588; Jayakumar P, 2023, CLIN ORTHOP RELAT R, V481, P1890, DOI 10.1097/CORR.0000000000002854; Jeyaraman Madhan, 2023, World J Methodol, V13, P170, DOI 10.5662/wjm.v13.i4.170; Jin Ziwen, 2023, 2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P1755, DOI 10.1109/ICIBA56860.2023.10165540; Kaddoura S, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1252; Keskinbora KH, 2019, J CLIN NEUROSCI, V64, P277, DOI 10.1016/j.jocn.2019.03.001; Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018; Kleebayoon A, 2023, NEUROSURGERY, V93, pE77, DOI 10.1227/neu.0000000000002588; Kuang YR, 2023, INT J SURG, V109, P2886, DOI 10.1097/JS9.0000000000000571; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; Laios A, 2023, CANCER CONTROL, V30, DOI 10.1177/10732748231197915; Laird JE, 2017, AI MAG, V38, P13, DOI 10.1609/aimag.v38i4.2744; Lareyre F, 2023, EJVES VASC FORUM, V60, P42, DOI 10.1016/j.ejvsvf.2023.08.003; Lebhar MS, 2023, CLEFT PALATE-CRAN J, DOI 10.1177/10556656231193966; Lechien JR, 2024, OTOLARYNG HEAD NECK, V170, P1527, DOI 10.1002/ohn.526; Li WB, 2023, ANN BIOMED ENG, V51, P2105, DOI 10.1007/s10439-023-03240-y; Li WB, 2023, ANN BIOMED ENG, V51, P1892, DOI 10.1007/s10439-023-03232-y; Liebe H, 2021, SEMIN PEDIATR SURG, V30, DOI 10.1016/j.sempedsurg.2021.151097; Lim B, 2023, PLAST AESTHET RES, V10, DOI 10.20517/2347-9264.2023.70; Liu HY, 2024, AESTHET PLAST SURG, V48, P1644, DOI 10.1007/s00266-023-03709-0; Liu JY, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.107590; Loftus TJ, 2020, JAMA SURG, V155, P148, DOI 10.1001/jamasurg.2019.4917; Lower K, 2023, INDIAN J ORTHOP, V57, P1527, DOI 10.1007/s43465-023-00967-7; Luo ST, 2023, INT J SURG, V109, P3694, DOI 10.1097/JS9.0000000000000610; Masic Izet, 2012, Acta Inform Med, V20, P208, DOI 10.5455/aim.2012.20.208-213; Matwala Kabir, 2023, Cir Esp (Engl Ed), DOI 10.1016/j.cireng.2023.11.009; McLean AL, 2023, ANN BIOMED ENG, V51, P2641, DOI 10.1007/s10439-023-03282-2; Merrell Lauren A, 2023, J Bone Joint Surg Am, V105, P1383, DOI 10.2106/JBJS.23.00395; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mishra R, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19031719; Najafali D, 2023, AESTHET SURG J, V43, pNP591, DOI 10.1093/asj/sjad056; Nazer Lama H, 2023, PLOS Digit Health, V2, pe0000278, DOI 10.1371/journal.pdig.0000278; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Oleck NC, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005290; OpenAi, ChatGPT; Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1136/bmj.n160, 10.1016/j.ijsu.2021.105906]; Palacios JF, 2023, AESTHET SURG J, V43, pNP918, DOI 10.1093/asj/sjad197; PAOLA F, 1995, J MED ETHICS, V21, P84, DOI 10.1136/jme.21.2.84; Park I, 2023, AM J OTOLARYNG, V44, DOI 10.1016/j.amjoto.2023.103873; Puladi B, 2024, INT J ORAL MAX SURG, V53, P78, DOI 10.1016/j.ijom.2023.09.005; Qu RW, 2023, OTO OPEN, V7, DOI 10.1002/oto2.67; Ramamurthi A, 2023, INDIA J SURG ONCOL, V14, P537, DOI 10.1007/s13193-023-01836-3; Rawashdeh B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42150; Ray PP, 2023, TECH COLOPROCTOL, V27, P959, DOI 10.1007/s10151-023-02847-6; Reis LO, 2023, INT BRAZ J UROL, V49, P652, DOI 10.1590/S1677-5538.IBJU.2023.0112; Roman A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43502; Sahiner B, 2023, BRIT J RADIOL, V96, DOI 10.1259/bjr.20220878; Seddon I, 2023, CURR OPIN OPHTHALMOL, V34, P255, DOI 10.1097/ICU.0000000000000945; Seth I, 2023, CLIN ORTHOP RELAT R, V481, P1652, DOI 10.1097/CORR.0000000000002725; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Seyferth AV, 2022, PLAST RECONSTR SURG, V149, P1237, DOI 10.1097/PRS.0000000000009027; Sharma SC, 2023, INDIAN J PLAST SURG, V56, P320, DOI 10.1055/s-0043-1771514; Sun PF, 2023, J CRANIOFAC SURG, V34, P548, DOI 10.1097/SCS.0000000000009100; Tay JQ, 2023, EUR J PLAST SURG, V46, P643, DOI 10.1007/s00238-023-02081-1; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tung T, 2000, ARCH SURG-CHICAGO, V135, P10, DOI 10.1001/archsurg.135.1.10; Uruthiralingam U, 2020, ADV EXP MED BIOL, V1235, P89, DOI 10.1007/978-3-030-37639-0_5; Valencia OAG, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11182518; van Leeuwen FWB, 2022, CANCERS, V14, DOI 10.3390/cancers14246161; Varas J., 2023, Rev. Colegio Bras. Cir, V50, pe2023360, DOI [10.1590/0100-6991e-20233605, DOI 10.1590/0100-6991E-20233605]; Wall A, 2013, CURR PROB SURG, V50, P99, DOI 10.1067/j.cpsurg.2012.11.004; WARD CM, 1994, ANN ROY COLL SURG, V76, P223; Weidman AA, 2023, PLAST RECONSTR SURG, V151, P1111, DOI 10.1097/PRS.0000000000010342; Xiao DV, 2023, J PEDIATR SURG, V58, P2410, DOI 10.1016/j.jpedsurg.2023.07.008	90	5	5	14	14	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9032		HEALTHCARE-BASEL	Healthcare	APR	2024	12	8							825	10.3390/healthcare12080825	http://dx.doi.org/10.3390/healthcare12080825			21	Health Care Sciences & Services; Health Policy & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services	OX4I6	38667587	gold			2024-07-03	WOS:001210559800001
J	Pau, DP; Aymone, FM				Pau, Danilo Pietro; Aymone, Fabrizio Maria			Forward Learning of Large Language Models by Consumer Devices	ELECTRONICS			English	Article						on-device learning; backpropagation; forward learning; PEPITA; MEMPEPITA; Large Language Models; Natural Language Processing		Large Language Models achieve state of art performances on a broad variety of Natural Language Processing tasks. In the pervasive IoT era, their deployment on edge devices is more compelling than ever. However, their gigantic model footprint has hindered on-device learning applications which enable AI models to continuously learn and adapt to changes over time. Back-propagation, in use by the majority of deep learning frameworks, is computationally intensive and requires storing intermediate activations into memory to cope with the model's weights update. Recently, "Forward-only algorithms" have been proposed since they are biologically plausible alternatives. By applying more "forward" passes, this class of algorithms can achieve memory reductions with respect to more naive forward-only approaches and by removing the need to store intermediate activations. This comes at the expense of increased computational complexity. This paper considered three Large Language Model: DistilBERT, GPT-3 Small and AlexaTM. It investigated quantitatively any improvements about memory usage and computational complexity brought by known approaches named PEPITA and MEMPEPITA with respect to backpropagation. For low number of tokens in context, and depending on the model, PEPITA increases marginally or reduces substantially arithmetic operations. On the other hand, for large number of tokens in context, PEPITA reduces computational complexity by 30% to 50%. MEMPEPITA increases PEPITA's complexity by one third. About memory, PEPITA and backpropagation, require a comparable amount of memory to store activations, while MEMPEPITA reduces it by 50% to 94% with the benefits being more evident for architectures with a long sequence of blocks. In various real case scenarios, MEMPEPITA's memory reduction was essential for meeting the tight memory requirements of 128 MB equipped edge consumer devices, which are commonly available as smartphone and industrial application multi processors.	[Pau, Danilo Pietro; Aymone, Fabrizio Maria] STMicroelectronics, Syst Res & Applicat, Via C Olivetti 2, I-20864 Agrate Brianza, Italy	STMicroelectronics	Pau, DP (corresponding author), STMicroelectronics, Syst Res & Applicat, Via C Olivetti 2, I-20864 Agrate Brianza, Italy.	danilo.pau@st.com; fabriziomaria.aymone@mail.polimi.it		Pau, Danilo/0000-0003-1585-2313				Aghajanyan A, 2020, Arxiv, DOI arXiv:2008.03156; Akrout M, 2020, Arxiv, DOI arXiv:1904.05391; Alizadeh K, 2024, Arxiv, DOI arXiv:2312.11514; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Banbury Colby, 2021, arXiv; Barbuto V, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010044; Bayram F., 2022, arXiv, DOI [10.48550/ARXIV.2203.11070, DOI 10.48550/ARXIV.2203.11070]; Burbank KS, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002393; Cai H., 2020, Advances in Neural Information Processing Systems, V33, P11285; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chowdhery A, 2019, Arxiv, DOI arXiv:1906.05721; Clark K., 2020, arXiv; Collobert R, 2011, J MACH LEARN RES, V12, P2493; Costa-jussa, 2022, arXiv, DOI DOI 10.48550/ARXIV.2207.04672; CRICK F, 1989, NATURE, V337, P129, DOI 10.1038/337129a0; Czarnecki Wojciech Marian, 2017, INT C MACHINE LEARNI, P904; Dai AM, 2015, ADV NEUR IN, V28; Dellaferrera G, 2022, Arxiv, DOI arXiv:2201.11665; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding J., 2023, arXiv; Firoozshahian A., 2023, P 50 ANN INT S COMPU, P1; Forward Learning of Large Language Models by Consumer Devices, Github Repository; Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413; Gómez-Luna J, 2023, Arxiv, DOI arXiv:2207.07886; Han S., 2015, INT C LEARN REPR, V56, P3; Hinton G, 2022, Arxiv, DOI arXiv:2212.13345; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jaderberg M, 2017, PR MACH LEARN RES, V70; Jiang HM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2177; Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kim S, 2023, Arxiv, DOI arXiv:2302.14017; Laskaridis S, 2024, Arxiv, DOI arXiv:2210.10514; Li TD, 2021, Arxiv, DOI arXiv:2110.08460; Liao QL, 2016, Arxiv, DOI [arXiv:1510.05067, 10.1609/aaai.v30i1.10279, DOI 10.1609/AAAI.V30I1.10279]; Lillicrap TP, 2020, NAT REV NEUROSCI, V21, P335, DOI 10.1038/s41583-020-0277-3; Lillicrap TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13276; Lin J., 2022, Advances in Neural Information Processing Systems, V35, P22941; Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298; Morra L, 2020, IEEE CONSUM ELECTR M, V9, P46, DOI 10.1109/MCE.2019.2962163; Nokland A, 2016, ADV NEUR IN, V29; Pau D. P., 2023, Chips, V2, P130, DOI DOI 10.3390/CHIPS2020008; Pau D.P., 2023, P 2023 IEEE INT C OM, P1, DOI DOI 10.1109/COINS57856.2023.10189239; Pau DP, 2024, ENG BASEL, V5, P34, DOI 10.3390/eng5010003; Peters Matthew E, 2017, Semi-supervised sequence tagging with bidirectional language models; Radford A., 2018, IMPROVING LANGUAGE U; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Ramachandran P, 2018, Arxiv, DOI arXiv:1611.02683; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sanh Victor, 2019, Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter; Shen ZR, 2024, Arxiv, DOI [arXiv:1812.01243, DOI 10.3390/S18092814]; Soltan S, 2022, arXiv; Srinivasan R, 2024, Arxiv, DOI arXiv:2302.05440; Sun ZQ, 2020, Arxiv, DOI arXiv:2004.02984; Vaswani A, 2017, ADV NEUR IN, V30; Vucetic D, 2022, IEEE INT SYMP CIRC S, P1838, DOI 10.1109/ISCAS48785.2022.9937567; Wang K., 2019, P IEEE C COMPUTER VI; Wang SN, 2021, Arxiv, DOI arXiv:2104.14690; Warstadt A, 2019, Arxiv, DOI arXiv:1805.12471; Xi HC, 2023, Arxiv, DOI arXiv:2306.11987; Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237; Yuan J., 2023, arXiv; Zaken E, 2022, Arxiv, DOI arXiv:2106.10199; Zhang ZS, 2020, Arxiv, DOI arXiv:2001.09694	65	0	0	6	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	JAN	2024	13	2							402	10.3390/electronics13020402	http://dx.doi.org/10.3390/electronics13020402			13	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	FX1W7		gold			2024-07-03	WOS:001149070200001
J	Benitez, TM; Xu, YY; Boudreau, JD; Kow, AWC; Bello, F; Phuoc, LV; Wang, XF; Sun, XD; Leung, GKK; Lan, YY; Wang, YX; Cheng, D; Tham, YC; Wong, TY; Chung, KC				Benitez, Trista M.; Xu, Yueyuan; Boudreau, J. Donald; Kow, Alfred Wei Chieh; Bello, Fernando; Phuoc, Le Van; Wang, Xiaofei; Sun, Xiaodong; Leung, Gilberto Ka-Kit; Lan, Yanyan; Wang, Yaxing; Cheng, Davy; Tham, Yih-Chung; Wong, Tien Yin; Chung, Kevin C.			Harnessing the potential of large language models in medical education: promise and pitfalls	JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION			English	Editorial Material						large language models; ChatGPT; medical education	ARTIFICIAL-INTELLIGENCE; TIME; MOTION; WRITE	Objectives: To provide balanced consideration of the opportunities and challenges associated with integrating Large Language Models (LLMs) throughout the medical school continuum. Process: Narrative review of published literature contextualized by current reports of LLM application in medical education. Conclusions: LLMs like OpenAI's ChatGPT can potentially revolutionize traditional teaching methodologies. LLMs offer several potential advantages to students, including direct access to vast information, facilitation of personalized learning experiences, and enhancement of clinical skills development. For faculty and instructors, LLMs can facilitate innovative approaches to teaching complex medical concepts and fostering student engagement. Notable challenges of LLMs integration include the risk of fostering academic misconduct, inadvertent overreliance on AI, potential dilution of critical thinking skills, concerns regarding the accuracy and reliability of LLM-generated content, and the possible implications on teaching staff.	[Benitez, Trista M.] Univ Michigan, Med Sch, Dept Surg, Ann Arbor, MI 48109 USA; [Xu, Yueyuan; Wong, Tien Yin] Tsinghua Univ, Tsinghua Med, Beijing 100084, Peoples R China; [Boudreau, J. Donald] McGill Univ, Inst Hlth Sci Educ, Fac Med & Hlth Sci, Montreal, PQ H3A 0G4, Canada; [Kow, Alfred Wei Chieh] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Surg, Singapore 117597, Singapore; [Bello, Fernando] Natl Univ Singapore, Duke NUS Med Sch, Technol Enhanced Learning & Innovat Dept, Singapore 169857, Singapore; [Phuoc, Le Van] Vin Univ, Coll Hlth Sci, Hanoi 100000, Vietnam; [Wang, Xiaofei] Beihang Univ, Beijing Adv Innovat Ctr Biomed Engn, Sch Biol Sci & Med Engn, Key Lab Biomech & Mechanobiol,Minist Educ, Beijing 100191, Peoples R China; [Sun, Xiaodong] Shanghai Jiao Tong Univ, Shanghai Gen Hosp, Sch Med, Dept Ophthalmol, Shanghai 200240, Peoples R China; [Leung, Gilberto Ka-Kit] Univ Hong Kong, Queen Mary Hosp, Sch Clin Med, LKS Fac Med,Dept Surg, Hong Kong 999077, Peoples R China; [Lan, Yanyan] Tsinghua Univ, Inst AI Ind Res, Beijing 100084, Peoples R China; [Wang, Yaxing] Capital Univ Med Sci, Beijing Tongren Hosp, Beijing Inst Ophthalmol, Beijing Ophthalmol & Visual Sci Key Lab, Beijing 100730, Peoples R China; [Cheng, Davy] Chinese Univ Hong Kong, Sch Med, Shenzhen 518172, Peoples R China; [Tham, Yih-Chung] Natl Univ Singapore, Ctr Innovat & Precis Eye Hlth, Yong Loo Lin Sch Med, Singapore 117597, Singapore; [Tham, Yih-Chung] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Singapore 117597, Singapore; [Tham, Yih-Chung] Duke NUS Med Sch, Ophthalmol & Visual Sci Acad Clin Program, Singapore 169857, Singapore; [Tham, Yih-Chung; Wong, Tien Yin] Singapore Eye Res Inst, Singapore Natl Eye Ctr, Singapore 168751, Singapore; [Wong, Tien Yin] Beijing Tsinghua Changgung Hosp, Sch Clin Med, Beijing 100084, Peoples R China; [Tham, Yih-Chung] Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Level 13,MD1 Tahir Fdn Bldg,12 Sci Dr 2, Singapore 117549, Singapore; [Chung, Kevin C.] Univ Michigan Hlth Syst, Sect Plast Surg, 1500 E Med Ctr Dr,2130 Taubman Ctr,SPC 5340, Ann Arbor, MI 48109 USA	University of Michigan System; University of Michigan; Tsinghua University; McGill University; National University of Singapore; National University of Singapore; VinUniversity; Beihang University; Shanghai Jiao Tong University; University of Hong Kong; Tsinghua University; The Chinese University of Hong Kong, Shenzhen; National University of Singapore; National University of Singapore; National University of Singapore; National University of Singapore; Singapore National Eye Center; National University of Singapore; University of Michigan System; University of Michigan	Tham, YC (corresponding author), Natl Univ Singapore, Yong Loo Lin Sch Med, Dept Ophthalmol, Level 13,MD1 Tahir Fdn Bldg,12 Sci Dr 2, Singapore 117549, Singapore.; Chung, KC (corresponding author), Univ Michigan Hlth Syst, Sect Plast Surg, 1500 E Med Ctr Dr,2130 Taubman Ctr,SPC 5340, Ann Arbor, MI 48109 USA.	thamyc@nus.edu.sg; kecchung@med.umich.edu	Tham, Yih Chung/IUP-0091-2023; Wang, Shuai/HZJ-7466-2023		National Key Research and Development Program of China [2022YFC2502802]; National Natural Science Foundation of China [8238810007]; National Institutes of Health	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	This work was supported by National Key Research and Development Program of China (2022YFC2502802) and National Natural Science Foundation of China (8238810007). K.C.C. receives funding from the National Institutes of Health, book royalties from Wolters Kluwer and Elsevier	AI O., 2023, CHAT PLUGINS; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amano T, 2021, NAT HUM BEHAV, V5, P1119, DOI 10.1038/s41562-021-01137-1; Amboss, 2023, YOUR NEXT GEN RESOUR; Amiel JM, 2021, ACAD MED, V96, pS14, DOI 10.1097/ACM.0000000000004088; [Anonymous], 2014, Core Entrustable Professional Activities for Entering Residency; Argil, GENERATE CHATGPT IMA; Bair H, 2023, ACAD MED, V98, P869, DOI 10.1097/ACM.0000000000005265; Bhatnagar V, 2019, CUREUS J MED SCIENCE, V11, DOI 10.7759/cureus.4168; Bowker D, 2023, ADV HEALTH SCI EDUC, V28, P453, DOI 10.1007/s10459-022-10167-x; Chang C, 2021, ACAD MED, V96, P278, DOI 10.1097/ACM.0000000000003766; Chick RC, 2020, J SURG EDUC, V77, P729, DOI 10.1016/j.jsurg.2020.03.018; Cho KK, 2017, BMC MED EDUC, V17, DOI 10.1186/s12909-017-0956-6; Choi-Lundberg DL, 2016, ANAT SCI EDUC, V9, P150, DOI 10.1002/ase.1549; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Combs C Donald, 2019, AMA J Ethics, V21, pE153, DOI 10.1001/amajethics.2019.153; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Desai A, 2020, JAMA-J AM MED ASSOC, V323, P2015, DOI 10.1001/jama.2020.2956; Dive HE., 2023, DIVE HE; Edwards B., 2023, Ars Technica; Emanuel EJ, 2020, JAMA-J AM MED ASSOC, V323, P1127, DOI 10.1001/jama.2020.1227; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Gillette Chris, 2017, Am J Pharm Educ, V81, P6120, DOI 10.5688/ajpe6120; Gladwell M., 2009, Outliers: The Story of Success; GPTStore.ai, OVERVIEW AICHATGPT P; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Ikonne U, 2018, J AM OSTEOPATH ASSOC, V118, P813, DOI 10.7556/jaoa.2018.174; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kelly M, 2004, MED TEACH, V26, P610, DOI 10.1080/01421590400005475; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kluwer W., 2023, UPTODATE; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li, 2007, INT J NURS EDUC SCHO, V4, pArticl; Liu Y., 2023, Meta-Radiol ogy; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; McGaghie WC, 2011, ACAD MED, V86, P48, DOI 10.1097/ACM.0b013e3181ffacdb; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Multiplex, 2023, WHAT ARE SUPERPROMPT; Murphy B., 2021, Medical Schools Ponder Move to Shorter Pre-clerkship Curriculum; Nakagawa N, 2022, CURR PHARM TEACH LEA, V14, P854, DOI 10.1016/j.cptl.2022.06.021; Nelson Gavin, 2022, S D Med, V75, P454; Ng FYC, 2023, CELL REP MED, V4, DOI 10.1016/j.xcrm.2023.101230; Noteable, CHATGPT PLUGIN; OA.mg, 2023, SCI CHATGPT PLUGIN; OpenAI, 2023, SPEECH TEXT; Oxentenko AS, 2010, ARCH INTERN MED, V170, P377, DOI 10.1001/archinternmed.2009.534; Paranjape Ketan, 2019, JMIR Med Educ, V5, pe16048, DOI 10.2196/16048; Pathipati AS, 2016, CUREUS J MED SCIENCE, V8, DOI 10.7759/cureus.741; Prober CG, 2023, ACAD MED, V98, P983, DOI 10.1097/ACM.0000000000005262; REUTERS, 2023, CHATGPT USERS CAN NO; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Sample I., SCI J BAN LISTING CH; Sanchez-Ramos L, 2023, AM J OBSTET GYNECOL, V229, P356, DOI 10.1016/j.ajog.2023.04.004; ScholarAI, 2023, SCHOLARAI; Scott K, 2018, CLIN TEACH, V15, P29, DOI 10.1111/tct.12630; Shorey S, 2023, CIN-COMPUT INFORM NU, V41, P385, DOI 10.1097/CIN.0000000000000999; Sinsky C, 2016, ANN INTERN MED, V165, P753, DOI 10.7326/M16-0961; Suneja M, 2023, SOUTH MED J, V116, P312, DOI 10.14423/SMJ.0000000000001525; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Tipping MD, 2010, J HOSP MED, V5, P323, DOI 10.1002/jhm.790; Varas J., 2023, Rev Col Bras Cir, V50, pe20233605; Wang XF, 2023, LANCET REG HEALTH-W, V41, DOI 10.1016/j.lanwpc.2023.100905; Webb Jeremy J, 2023, Cureus, V15, pe38755, DOI 10.7759/cureus.38755	67	3	3	48	48	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1067-5027	1527-974X		J AM MED INFORM ASSN	J. Am. Med. Inf. Assoc.	FEB 16	2024	31	3					776	783		10.1093/jamia/ocad252	http://dx.doi.org/10.1093/jamia/ocad252		JAN 2024	8	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Computer Science; Health Care Sciences & Services; Information Science & Library Science; Medical Informatics	IA9D3	38269644				2024-07-03	WOS:001150580900001
C	Qin, RY; Hu, YT; Yan, ZY; Xiong, JJ; Abbasi, A; Shi, YY			IEEE	Qin, Ruiyang; Hu, Yuting; Yan, Zheyu; Xiong, Jinjun; Abbasi, Ahmed; Shi, Yiyu			FL-NAS: Towards Fairness of NAS for Resource Constrained Devices via Large Language Models	29TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, ASP-DAC 2024	Asia and South Pacific Design Automation Conference Proceedings		English	Proceedings Paper	29th Asia and South Pacific Design Automation Conference (ASP-DAC)	JAN 22-25, 2024	BrainKorea Four 21, Incheon, SOUTH KOREA	ACM Special Interest Grp Design Automat, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, EIC, Incheon Tourism Org, Korea Tourism Org, Cadence Design Syst Inc	BrainKorea Four 21	neural architecture search; hardware efficiency; large language model; fairness		Neural Architecture Search (NAS) has become the de fecto tools in the industry in automating the design of deep neural networks for various applications, especially those driven by mobile and edge devices with limited computing resources. The emerging large language models (LLMs), due to their prowess, have also been incorporated into NAS recently and show some promising results. This paper conducts further exploration in this direction by considering three important design metrics simultaneously, i.e., model accuracy, fairness, and hardware deployment efficiency. We propose a novel LLM-based NAS framework, FL-NAS, in this paper, and show experimentally that FL-NAS can indeed find high-performing DNNs, beating state-of-the-art DNN models by orders-of-magnitude across almost all design considerations.	[Qin, Ruiyang; Yan, Zheyu; Abbasi, Ahmed; Shi, Yiyu] Univ Notre Dame, Notre Dame, IN 46556 USA; [Hu, Yuting; Xiong, Jinjun] SUNY Buffalo, Buffalo, NY 14260 USA	University of Notre Dame; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Shi, YY (corresponding author), Univ Notre Dame, Notre Dame, IN 46556 USA.; Xiong, JJ (corresponding author), SUNY Buffalo, Buffalo, NY 14260 USA.	jinjun@buffalo.edu; yshi4@nd.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2019, Skin lesion analysis; Baker B, 2017, Arxiv, DOI [arXiv:1705.10823, DOI 10.48550/ARXIV.1705.10823]; Biderman S., 2023, INT C MACHINE LEARNI, P2397; Cai H, 2019, Arxiv, DOI arXiv:1812.00332; Chu X., 2021, P IEEE CVF INT C COM, p12 239; Elsken T, 2019, J MACH LEARN RES, V20; Howard AG, 2017, Arxiv, DOI arXiv:1704.04861; Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]; Hardt M, 2016, ADV NEUR IN, V29; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Jia ZE, 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00670-0; Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1; Li WH, 2023, Arxiv, DOI arXiv:2310.04750; Li Y., 2020, 2020 57 ACM IEEE DES, P1; Li Y., 2023, P IEEE CVF INT C COM, P6199; Liu J., 2021, arXiv; Liu YQ, 2023, IEEE T NEUR NET LEAR, V34, P550, DOI 10.1109/TNNLS.2021.3100554; Nagel Markus, 2021, arXiv; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sheng Y, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P163, DOI 10.1145/3489517.3530427; Stamoulis D, 2020, LECT NOTES ARTIF INT, V11907, P481, DOI 10.1007/978-3-030-46147-8_29; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang HS, 2024, Arxiv, DOI arXiv:2310.01436; Yan Z., 2022, System Dependability and Analytics: Approaching System Dependability from Data, System and Analytics Perspectives, P167; Yan ZY, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P277, DOI 10.1145/3489517.3530459; Yan ZY, 2023, Arxiv, DOI arXiv:2306.06923; Zhang XY, 2019, IEEE COMP SOC ANN, P25, DOI 10.1109/ISVLSI.2019.00014; Zheng MK, 2023, Arxiv, DOI arXiv:2304.10970; Zhou D., 2020, P IEEE CVF C COMP VI, p11 396; Zoph B, 2017, Arxiv, DOI [arXiv:1611.01578, 10.48550/arXiv.1611.01578]	32	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-6961		979-8-3503-9354-5	ASIA S PACIF DES AUT			2024							429	434		10.1109/ASP-DAC58780.2024.10473847	http://dx.doi.org/10.1109/ASP-DAC58780.2024.10473847			6	Automation & Control Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BW7ST					2024-07-03	WOS:001196002900069
J	Ammar, A; Koubaa, A; Benjdira, B; Nacar, O; Sibaee, S				Ammar, Adel; Koubaa, Anis; Benjdira, Bilel; Nacar, Omer; Sibaee, Serry			Prediction of Arabic Legal Rulings Using Large Language Models	ELECTRONICS			English	Article						large language models; Arabic court analysis; foundation models; natural language processing; transformers		In the intricate field of legal studies, the analysis of court decisions is a cornerstone for the effective functioning of the judicial system. The ability to predict court outcomes helps judges during the decision-making process and equips lawyers with invaluable insights, enhancing their strategic approaches to cases. Despite its significance, the domain of Arabic court analysis remains under-explored. This paper pioneers a comprehensive predictive analysis of Arabic court decisions on a dataset of 10,813 commercial court real cases, leveraging the advanced capabilities of the current state-of-the-art large language models. Through a systematic exploration, we evaluate three prevalent foundational models (LLaMA-7b, JAIS-13b, and GPT-3.5-turbo) and three training paradigms: zero-shot, one-shot, and tailored fine-tuning. In addition, we assess the benefit of summarizing and/or translating the original Arabic input texts. This leads to a spectrum of 14 model variants, for which we offer a granular performance assessment with a series of different metrics (human assessment, GPT evaluation, ROUGE, and BLEU scores). We show that all variants of LLaMA models yield limited performance, whereas GPT-3.5-based models outperform all other models by a wide margin, surpassing the average score of the dedicated Arabic-centric JAIS model by 50%. Furthermore, we show that all scores except human evaluation are inconsistent and unreliable for assessing the performance of large language models on court decision predictions. This study paves the way for future research, bridging the gap between computational linguistics and Arabic legal analytics.	[Ammar, Adel; Koubaa, Anis; Benjdira, Bilel; Nacar, Omer; Sibaee, Serry] Prince Sultan Univ, Robot & Internet Things Lab, Riyadh 12435, Saudi Arabia	Prince Sultan University	Ammar, A (corresponding author), Prince Sultan Univ, Robot & Internet Things Lab, Riyadh 12435, Saudi Arabia.	aammar@psu.edu.sa; akoubaa@psu.edu.sa; bbenjdira@psu.edu.sa; onajar@psu.edu.sa; ssibaee@psu.edu.sa	Ammar, Adel/AAY-6061-2020	Ammar, Adel/0000-0003-0795-132X; Koubaa, Anis/0000-0003-3787-7423; Benjdira, Bilel/0000-0002-3057-4924; Nacar, Omer/0000-0001-7493-9318	Prince Sultan University	Prince Sultan University	The authors thank Prince Sultan University for their support.	Abdelali A., 2023, arXiv; Afzaal M, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221142210; AGI-Edgerunners, LLM-Adapters Github Repository; [Anonymous], 2011, P 49 ANN M ASS COMPU; Attia M., 2008, Ph.D. Thesis; Bostrom K, 2020, Arxiv, DOI arXiv:2004.03720; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Chaudhry HN, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172082; Chen Boxing, 2014, P 9 WORKSHOP STAT MA, P362; Dai AM, 2015, ADV NEUR IN, V28; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Elmadany A, 2022, Arxiv, DOI arXiv:2212.10758; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; French RM, 1999, TRENDS COGN SCI, V3, P128, DOI 10.1016/S1364-6613(99)01294-2; Guellil I, 2021, J KING SAUD UNIV-COM, V33, P497, DOI 10.1016/j.jksuci.2019.02.006; Habash N. Y., 2010, Introduction to Arabic natural language processing; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu ZQ, 2023, Arxiv, DOI arXiv:2304.01933; Katz DM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174698; Kemker R., 2018, P AAAI C ART INT NEW, VVolume 32; Khan A, 2023, J INF SCI, DOI 10.1177/01655515221137270; Koubaa A., 2023, PREPRINT, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Koubaa A, 2023, Arxiv, DOI [arXiv:2305.06934, 10.1016/j.heliyon.2023.e21624]; Kudo T, 2018, Arxiv, DOI [arXiv:1808.06226, 10.48550/arXiv.1808.06226]; Lauderdale BE, 2014, AM J POLIT SCI, V58, P754, DOI 10.1111/ajps.12085; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Medvedeva M, 2020, ARTIF INTELL LAW, V28, P237, DOI 10.1007/s10506-019-09255-y; NLTK, Bleu Python Package; OpenAI, GPT3 Dataset Language Statistics; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Pu GR, 2023, Arxiv, DOI arXiv:2304.14999; PyPI, Beautiful Soup Python Package.; PyPI, Translators Python Package; PyPI, Selenium Python Library; PyPI, Rouge Python Package; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Sengupta N., 2023, arXiv; Shaalan K., 2018, Computational Linguistics, Speech and Image Processing for Arabic Language, P59; Shibata Yusuxke, 1999, Byte Pair encoding: A text compression scheme that accelerates pattern matching; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; SJP Saudi Justice Portal, About us; Soussi R, 2022, arXiv; Srivastava Aarohi, 2022, arXiv; Surden Harry, 2019, Georgia State University Law Review, V35, P19; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Zhang Y, 2023, Arxiv, DOI [arXiv:2303.01037, 10.48550/arXiv.2303.01037]; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	54	0	0	6	6	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	FEB	2024	13	4							764	10.3390/electronics13040764	http://dx.doi.org/10.3390/electronics13040764			21	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	JH9F5		gold, Green Submitted			2024-07-03	WOS:001172384800001
C	Wallat, J; Jatowt, A; Anand, A			Assoc computing machinery	Wallat, Jonas; Jatowt, Adam; Anand, Avishek			Temporal Blind Spots in Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Temporal Information Retrieval; temporal query intents; question answering; large language models		Large language models (LLMs) have recently gained significant attention due to their unparalleled zero-shot performance on various natural language processing tasks. However, the pre-training data utilized in LLMs is often confined to a specific corpus, resulting in inherent freshness and temporal scope limitations. Consequently, this raises concerns regarding the effectiveness of LLMs for tasks involving temporal intents. In this study, we aim to investigate the underlying limitations of general-purpose LLMs when deployed for tasks that require a temporal understanding. We pay particular attention to handling factual temporal knowledge through three popular temporal QA datasets. Specifically, we observe low performance on detailed questions about the past and, surprisingly, for rather new information. In manual and automatic testing, we find multiple temporal errors and characterize the conditions under which QA performance deteriorates. Our analysis contributes to understanding LLM limitations and offers valuable insights into developing future models that can better cater to the demands of temporally-oriented tasks. The code is available1.	[Wallat, Jonas] L3S Res Ctr, Hannover, Germany; [Jatowt, Adam] Univ Innsbruck, Dept Comp Sci, Innsbruck, Austria; [Anand, Avishek] Delft Univ Technol, Dept Software Technol, Delft, Netherlands	Leibniz University Hannover; University of Innsbruck; Delft University of Technology	Wallat, J (corresponding author), L3S Res Ctr, Hannover, Germany.	jonas.wallat@l3s.de; adamjatowt@uibk.ac.at; avishek.anand@tudelft.nl			Federal Ministry of Education and Research (BMBF), Germany [01DD20003, 13N16052]; EU-Horizon 2020 Program [871042]	Federal Ministry of Education and Research (BMBF), Germany(Federal Ministry of Education & Research (BMBF)); EU-Horizon 2020 Program(Horizon 2020)	This research was partially funded by the Federal Ministry of Education and Research (BMBF), Germany under the project LeibnizKILabor with grant No. 01DD20003 and Cubra with grant No. 13N16052. It is also partially supported by the EU-Horizon 2020 Program, Grant Agreement n.871042, "SoBigData++".	Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Althammer S., 2021, arXiv; Anand A, 2022, Arxiv, DOI [arXiv:2211.02405, 10.48550/ARXIV.2211.02405]; Anand A, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P235, DOI 10.1145/2348283.2348318; [Anonymous], 2011, P 20 ACM C INF KNOW, DOI [10.1145/2063576.2063755, DOI 10.1145/2063576.2063755]; Baradaran R, 2022, NAT LANG ENG, V28, P683, DOI 10.1017/S1351324921000395; Barros C, 2019, INFORM PROCESS MANAG, V56, P1775, DOI 10.1016/j.ipm.2019.02.010; Berberich K., 2013, P SIGIR 2013 WORKSH; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bulian J., 2022, P 2022 C EMP METH NA, P291, DOI [10.18653/v1/2022.emnlpmain_20, DOI 10.18653/V1/2022.EMNLPMAIN_20]; Campos R, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2619088; Chang AX, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3735; Chen W, 2021, arXiv; Cohn AG, 2023, Arxiv, DOI arXiv:2304.11164; Cole J. R., 2023, Salient span masking for temporal understanding, P3044; Computer T., 2023, Redpajama: An open source recipe to reproduce llama training dataset; Derczynski L, 2023, Arxiv, DOI arXiv:2303.18190; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhingra B, 2022, T ASSOC COMPUT LING, V10, P257, DOI 10.1162/tacl_a_00459; Dzendzik D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8784; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Geng X., 2023, OpenLLaMA: An open reproduction of LLaMA; Gupta D., 2014, P 23 ACM INT C C INF, P1835; Gupta J, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2785, DOI 10.1145/3308558.3313706; Guu K, 2020, PR MACH LEARN RES, V119; Holzmann H, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16 COMPANION), P207, DOI 10.1145/2872518.2890555; Holzmann H, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P929, DOI 10.1145/2911451.2914724; Honovich Or, 2020, P 58 ANN M ASS COMP, P7486; Jain R., 2023, P 2023 C EMP METH NA, P1; Jatowt A, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2273, DOI 10.1145/2505515.2505655; Jia Z, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1057, DOI 10.1145/3184558.3191536; Joho H, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P845, DOI 10.1145/2567948.2579044; Joho H, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P1101; Kanhabua N, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1235, DOI 10.1145/2911451.2914805; Kassner N, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3250; Lazaridou A., 2021, Advances in Neural Information Processing Systems, V34, P29348; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Lin BY, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6862; Nakov P. D., 2021, P 30 INT JOINT C ONA, P4551, DOI [10.24963/ijcai.2021/619, DOI 10.24963/IJCAI.2021/619]; Ouyang L., 2022, NEURIPS; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Perez Ethan., 2022, EMNLP, P3419, DOI 10.18653/v1/2022.emnlp-main.225; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Qin Z, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2835, DOI 10.1145/3366423.3380046; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; Rosin G. D., 2022, Temporal attention for language models, P1498; Rosin GD, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P833, DOI 10.1145/3488560.3498529; Sandhaus E., 2008, The New York Times Annotated Corpus', V6, P26752; Singh J., 2018, arXiv; Strauss E, 1998, CLIN ORTHOP RELAT R, P2; Strotgen<spacing Jannik, 2010, P 5 INT WORKSH SEM E, P321; Sumikawa Y, 2021, INT J DIGIT LIBRARIE, V22, P105, DOI 10.1007/s00799-020-00296-2; Svore KM, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1045, DOI 10.1145/2348283.2348461; Talmor A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4149; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trischler Adam, 2017, P 2 WORKSH REPR LEAR, P191, DOI [DOI 10.18653/V1/W17-2623, 10.18653/v1/W17-2623]; Wang JX, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P812, DOI 10.1145/3539618.3591686; Wang JX, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3025, DOI 10.1145/3477495.3531734; Wang JX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P398, DOI 10.1145/3404835.3462885; Wang JX, 2021, INFORM RETRIEVAL J, V24, P29, DOI 10.1007/s10791-020-09387-9; Wenzel G, 2023, arXiv, DOI [10.48550/ARXIV.2308.00002, DOI 10.48550/ARXIV.2308.00002]; West P, 2022, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), P3732; Xiong Wenhan, 2020, INT C LEARN REPR; Yamamoto Y, 2008, LECT NOTES COMPUT SC, V5175, P206, DOI 10.1007/978-3-540-85481-4_17; Yin D., 2022, P 2022 C EMPIRICAL M, P2039	67	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							683	692		10.1145/3616855.3635818	http://dx.doi.org/10.1145/3616855.3635818			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN		Green Submitted			2024-07-03	WOS:001182230100077
J	Mallio, CA; Sertorio, AC; Bernetti, C; Zobel, BB				Mallio, Carlo A.; Sertorio, Andrea C.; Bernetti, Caterina; Beomonte Zobel, Bruno			Large language models for structured reporting in radiology: performance of GPT-4, ChatGPT-3.5, Perplexity and Bing	RADIOLOGIA MEDICA			English	Article						Artificial intelligence (AI); Large language models (LLMs); Generative pre-trained transformer (GPT)-based models; GPT-4; Structured report; Computed tomography (CT)		Structured reporting may improve the radiological workflow and communication among physicians. Artificial intelligence applications in medicine are growing fast. Large language models (LLMs) are recently gaining importance as valuable tools in radiology and are currently being tested for the critical task of structured reporting. We compared four LLMs models in terms of knowledge on structured reporting and templates proposal. LLMs hold a great potential for generating structured reports in radiology but additional formal validations are needed on this topic.	[Mallio, Carlo A.; Sertorio, Andrea C.; Bernetti, Caterina; Beomonte Zobel, Bruno] Univ Campus Biomed Roma, Fdn Policlin Univ Campus Biomed, Dept Med & Surg, Res Unit Radiol, Via Alvaro Portillo 200, I-00128 Rome, Italy	Fondazione Policlinico Universitario Campus Bio-Medico; University Campus Bio-Medico - Rome Italy	Mallio, CA (corresponding author), Univ Campus Biomed Roma, Fdn Policlin Univ Campus Biomed, Dept Med & Surg, Res Unit Radiol, Via Alvaro Portillo 200, I-00128 Rome, Italy.	c.mallio@policlinicocampus.it	Mallio, Carlo A./AAH-9988-2019	Mallio, Carlo A./0000-0002-0149-0801				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Belfiore MP, 2020, RADIOL MED, V125, P500, DOI 10.1007/s11547-020-01195-x; Buvat I, 2023, J NUCL MED, V64, P505, DOI 10.2967/jnumed.123.265636; Granata V, 2023, RADIOL MED, V128, P222, DOI 10.1007/s11547-023-01596-8; Granata CZ, 2022, RADIOL MED, V127, P21, DOI 10.1007/s11547-021-01418-9; Larson DB, 2013, RADIOLOGY, V267, P240, DOI 10.1148/radiol.12121502; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Mallio CA, 2021, CANCERS, V13, DOI 10.3390/cancers13040652; Neri E, 2022, RADIOL MED, V127, P471, DOI 10.1007/s11547-022-01478-5; Nobel JM, 2020, INSIGHTS IMAGING, V11, DOI 10.1186/s13244-019-0831-6	10	14	15	20	55	SPRINGER-VERLAG ITALIA SRL	MILAN	VIA DECEMBRIO, 28, MILAN, 20137, ITALY	0033-8362	1826-6983		RADIOL MED	Radiol. Med.	JUL	2023	128	7					808	812		10.1007/s11547-023-01651-4	http://dx.doi.org/10.1007/s11547-023-01651-4		MAY 2023	5	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	K5WA9	37248403				2024-07-03	WOS:000996937300001
J	Orsi, M; Reymond, JL				Orsi, Markus; Reymond, Jean-Louis			Can large language models predict antimicrobial peptide activity and toxicity?	RSC MEDICINAL CHEMISTRY			English	Article								Antimicrobial peptides (AMPs) are naturally occurring or designed peptides up to a few tens of amino acids which may help address the antimicrobial resistance crisis. However, their clinical development is limited by toxicity to human cells, a parameter which is very difficult to control. Given the similarity between peptide sequences and words, large language models (LLMs) might be able to predict AMP activity and toxicity. To test this hypothesis, we fine-tuned LLMs using data from the Database of Antimicrobial Activity and Structure of Peptides (DBAASP). GPT-3 performed well but not reproducibly for activity prediction and hemolysis, taken as a proxy for toxicity. The later GPT-3.5 performed more poorly and was surpassed by recurrent neural networks (RNN) trained on sequence-activity data or support vector machines (SVM) trained on MAP4C molecular fingerprint-activity data. These simpler models are therefore recommended, although the rapid evolution of LLMs warrants future re-evaluation of their prediction abilities. The large language models GPT-3 and GTP-3.5 were challenged to predict the activity and hemolysis of antimicrobial peptides from their sequence and compared to recurrent neural networks and support vector machines.	[Orsi, Markus; Reymond, Jean-Louis] Univ Bern, Dept Chem Biochem & Pharmaceut Sci, Freiestr 3, CH-3012 Bern, Switzerland	University of Bern	Reymond, JL (corresponding author), Univ Bern, Dept Chem Biochem & Pharmaceut Sci, Freiestr 3, CH-3012 Bern, Switzerland.	jean-louis.reymond@unibe.ch		Orsi, Markus/0000-0002-0509-7011; Reymond, Jean-Louis/0000-0003-2724-2942	Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung [200020_178998]; Swiss National Science Foundation [885076]; European Research Council	Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); European Research Council(European Research Council (ERC))	This work was supported by the Swiss National Science Foundation (200020_178998) and the European Research Council (885076). MO thanks Sacha Javor for the helpful discussion and comments.	Aguilera-Puga M. D. C., 2024, PREPRINTS, DOI [10.21203/rs.3.rs-3938402/v1, DOI 10.21203/RS.3.RS-3938402/V1]; Ansari M, 2023, J CHEM INF MODEL, V63, P2546, DOI 10.1021/acs.jcim.2c01317; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Bran A. M., 2023, ARXIV; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Capecchi A., 2021, MED DRUG DISCOVERY, V9, DOI DOI 10.1016/J.MEDIDD.2021.100081; Capecchi A, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-021-00559-3; Capecchi A, 2021, CHEM SCI, V12, P9221, DOI 10.1039/d1sc01713f; Capecchi A, 2020, BIOMOLECULES, V10, DOI 10.3390/biom10101385; Capecchi A, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00445-4; Cho K., 2014, PROC SSST EMNLP, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179, DOI 10.3115/V1/W14-4012]; EISENBERG D, 1982, NATURE, V299, P371, DOI 10.1038/299371a0; Gogoladze G, 2014, FEMS MICROBIOL LETT, V357, P63, DOI 10.1111/1574-6968.12489; Guo T., 2023, NEURIPS P, V36, P59662; Hasan MM, 2020, BIOINFORMATICS, V36, P3350, DOI 10.1093/bioinformatics/btaa160; Heffernan R, 2018, J COMPUT CHEM, V39, P2210, DOI 10.1002/jcc.25534; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jablonka KM, 2024, NAT MACH INTELL, V6, P122, DOI 10.1038/s42256-023-00788-1; Jablonka KM, 2023, DIGIT DISCOV, V2, P1233, DOI 10.1039/d3dd00113j; Lakemeyer M, 2018, ANGEW CHEM INT EDIT, V57, P14440, DOI 10.1002/anie.201804971; Liu G, 2023, NAT CHEM BIOL, V19, P1342, DOI [10.1038/s41589-023-01349-8, 10.1109/NOMS56928.2023.10154300]; Liu SC, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29566-5; Magana M, 2020, LANCET INFECT DIS, V20, pE216, DOI 10.1016/S1473-3099(20)30327-3; Mookherjee N, 2020, NAT REV DRUG DISCOV, V19, P311, DOI 10.1038/s41573-019-0058-8; Müller AT, 2018, J CHEM INF MODEL, V58, P472, DOI 10.1021/acs.jcim.7b00414; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Orsi M., CHEMRXIV, DOI [10.26434/chemrxiv-2023-33j02, DOI 10.26434/CHEMRXIV-2023-33J02]; Plisson F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73644-6; Probst D, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-0416-x; Sorokina M, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-020-00478-9; Su X, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3327-y; Timmons PB, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67701-3; Torres MDT, 2019, J MOL BIOL, V431, P3547, DOI 10.1016/j.jmb.2018.12.015; Vaswani A., 2017, Advances in neural information processing systems, P6000; Veltri D, 2018, BIOINFORMATICS, V34, P2740, DOI 10.1093/bioinformatics/bty179; Vishnepolsky B, 2019, PHARMACEUTICALS-BASE, V12, DOI 10.3390/ph12020082; Wan F., 2024, NAT REV BIOENG, DOI [10.1038/s44222-024-00152-x, DOI 10.1038/S44222-024-00152-X]; Wan FP, 2023, NAT BIOMED ENG, V7, P707, DOI 10.1038/s41551-023-01027-z; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Yan JL, 2020, MOL THER-NUCL ACIDS, V20, P882, DOI 10.1016/j.omtn.2020.05.006; Zakharova E, 2022, CHEMMEDCHEM, V17, DOI 10.1002/cmdc.202200291	41	0	0	2	2	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2632-8682		RSC MED CHEM	RSC Med. Chem.	JUN 19	2024	15	6					2030	2036		10.1039/d4md00159a	http://dx.doi.org/10.1039/d4md00159a		APR 2024	7	Biochemistry & Molecular Biology; Chemistry, Medicinal	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Pharmacology & Pharmacy	UT5V0	38911166	hybrid			2024-07-03	WOS:001209688400001
J	Morris, W; Crossley, S; Holmes, L; Ou, CH; Dascalu, M; Mcnamara, D				Morris, Wesley; Crossley, Scott; Holmes, Langdon; Ou, Chaohua; Dascalu, Mihai; Mcnamara, Danielle			Formative Feedback on Student-Authored Summaries in Intelligent Textbooks Using Large Language Models	INTERNATIONAL JOURNAL OF ARTIFICIAL INTELLIGENCE IN EDUCATION			English	Article; Early Access						Intelligent textbooks; Large language models; Automated summary scoring; Transformers		As intelligent textbooks become more ubiquitous in classrooms and educational settings, the need to make them more interactive arises. An alternative is to ask students to generate knowledge in response to textbook content and provide feedback about the produced knowledge. This study develops Natural Language Processing models to automatically provide feedback to students about the quality of summaries written at the end of intelligent textbook sections. The study builds on the work of Botarleanu et al. (2022), who used a Longformer Large Language Model (LLM) to develop a summary grading model. Their model explained around 55% of holistic summary score variance as assigned by human raters. This study uses a principal component analysis to distill summary scores from an analytic rubric into two principal components - content and wording. This study uses two encoder-only classification large language models finetuned from Longformer on the summaries and the source texts using these principal components explained 82% and 70% of the score variance for content and wording, respectively. On a dataset of summaries collected on the crowd-sourcing site Prolific, the content model was shown to be robust although the accuracy of the wording model was reduced compared to the training set. The developed models are freely available on HuggingFace and will allow formative feedback to users of intelligent textbooks to assess reading comprehension through summarization in real time. The models can also be used for other summarization applications in learning systems.	[Morris, Wesley; Crossley, Scott; Holmes, Langdon] Vanderbilt Univ, Nashville, TN 37235 USA; [Ou, Chaohua] Georgia Inst Technol, Atlanta, GA USA; [Dascalu, Mihai] Univ Politehn Bucuresti, Bucharest, Romania; [Mcnamara, Danielle] Arizona State Univ, Tempe, AZ USA	Vanderbilt University; University System of Georgia; Georgia Institute of Technology; National University of Science & Technology POLITEHNICA Bucharest; Arizona State University; Arizona State University-Tempe	Morris, W (corresponding author), Vanderbilt Univ, Nashville, TN 37235 USA.	wesley.g.morris@vanderbilt.edu			National Science Foundation	National Science Foundation(National Science Foundation (NSF))	No Statement Available	Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Alpizar-Chacon I, 2021, NEW REV HYPERMEDIA M, V27, P128, DOI 10.1080/13614568.2021.1889692; [Anonymous], 2018, Deep learning with Python, DOI DOI 10.1007/978-1-4842-2766-4; Bareiss R., 1993, Fifth ACM Conference on Hypertext Proceedings, P94, DOI 10.1145/168750.168790; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Botarleanu RM, 2022, LECT NOTES COMPUT SC, V13355, P756, DOI 10.1007/978-3-031-11644-5_79; Broder AZ, 1998, COMPRESSION AND COMPLEXITY OF SEQUENCES 1997 - PROCEEDINGS, P21, DOI 10.1109/SEQUEN.1997.666900; Brusilovsky P., 1998, Journal of Computing and Information Technology - CIT, V6, P27; Brusilovsky P, 2022, AI MAG, V43, P337, DOI 10.1002/aaai.12061; Chen CM, 2021, INTERACT LEARN ENVIR, V29, P848, DOI 10.1080/10494820.2019.1636091; Chulkov DV, 2013, J EDUC BUS, V88, P216, DOI 10.1080/08832323.2012.672936; Clinton-Lisell V, 2023, INTERACT LEARN ENVIR, V31, P3728, DOI 10.1080/10494820.2021.1943453; Crossley SA, 2019, LECT NOTES ARTIF INT, V11625, P84, DOI 10.1007/978-3-030-23204-7_8; Galbraith D, 2018, EDUC PSYCHOL-US, V53, P238, DOI 10.1080/00461520.2018.1505515; Galloway EP, 2019, READ WRIT, V32, P729, DOI 10.1007/s11145-018-9880-3; Gamage D, 2021, DISTANCE EDUC, V42, P268, DOI 10.1080/01587919.2021.1911626; Ganesan K., 2018, arXiv, DOI DOI 10.48550/ARXIV.1803.01937; Graham S, 2020, REV EDUC RES, V90, P179, DOI 10.3102/0034654320914744; Graham S, 2015, ELEM SCHOOL J, V115, P457, DOI 10.1086/681963; He D., 2020, Recommending Remedial Readings Using Student Knowledge State; Head MH., 1989, Reading Research and Instruction, V28, P1, DOI [DOI 10.1080/19388078909557982, DOI 10.1080/19388078709557982]; Inflianskas R., 2019, Profanity Filter; Ji SW, 2014, INTERNET HIGH EDUC, V21, P17, DOI 10.1016/j.iheduc.2013.10.004; Khandelwal U, 2019, Arxiv, DOI arXiv:1905.08836; Kim MK, 2023, INTERACT LEARN ENVIR, V31, P1377, DOI 10.1080/10494820.2020.1838927; Kumar G., 2015, P 10 WORKSH INN US N, P154, DOI DOI 10.3115/V1/W15-0618; Labutov I, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P907, DOI 10.1145/3097983.3098187; Lagakis P, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTER, INFORMATION, AND TELECOMMUNICATION SYSTEMS (IEEE CITS 2021), P102, DOI 10.1109/CITS52676.2021.9618476; Lan A. S., 2016, EDM, P424; Li HY, 2018, BEHAV RES METHODS, V50, P2144, DOI 10.3758/s13428-017-0982-7; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lopez L. E., 2021, PRICAI 2021: Trends in Artificial Intelligence, V13032, P323, DOI 10.1007; Martínez-Huertas JA, 2019, ASSESS EVAL HIGH EDU, V44, P1029, DOI 10.1080/02602938.2019.1570079; Morris Wesley, 2023, Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners, Doctoral Consortium and Blue Sky: 24th International Conference, AIED 2023, Proceedings. Communications in Computer and Information Science (1831), P484, DOI 10.1007/978-3-031-36336-8_75; Morris W., 2023, P 13 INT C LEARNING; Nelson N, 2023, READ WRIT, V36, P769, DOI 10.1007/s11145-021-10243-5; Ng JP, 2015, Arxiv, DOI arXiv:1508.06034; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Ramasesh V.V., 2021, INT C LEARNING REPRE; Rockinson-Szapkiw AJ, 2013, COMPUT EDUC, V63, P259, DOI 10.1016/j.compedu.2012.11.022; Scialom Thomas, 2019, arXiv; Seaman J., 2020, Digital texts in the time of COVID: Educational resources in U.S. Higher Education; Shao TH, 2019, IEEE ACCESS, V7, P26146, DOI 10.1109/ACCESS.2019.2900753; Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00492-0; Silva AM, 2019, J WRIT RES, V11, P211, DOI 10.17239/jowr-2019.11.01.07; Sosnovsky Sergey, 2023, Artificial Intelligence in Education. Posters and Late Breaking Results, Workshops and Tutorials, Industry and Innovation Tracks, Practitioners, Doctoral Consortium and Blue Sky: 24th International Conference, AIED 2023, Proceedings. Communications in Computer and Information Science (1831), P97, DOI 10.1007/978-3-031-36336-8_15; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tunstall L., 2022, Natural Language Processing with Transformers; Vaswani A, 2017, ADV NEUR IN, V30; Wang MD, 2023, TECHNOL KNOWL LEARN, V28, P1, DOI 10.1007/s10758-021-09544-z; Weber G, 2016, INT J ARTIF INTELL E, V26, P72, DOI 10.1007/s40593-015-0066-8; Winchell A., 2018, Can Textbook Annotations Serve as an Early Predictor of Student Learning?; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yarbro J. T., 2021, P 3 INT WORKSHOP INT, P2895	56	0	0	8	8	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1560-4292	1560-4306		INT J ARTIF INTELL E	Int. J. Artif. Intell. Educ.	2024 MAR 28	2024										10.1007/s40593-024-00395-0	http://dx.doi.org/10.1007/s40593-024-00395-0		MAR 2024	22	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	MO5S5		hybrid			2024-07-03	WOS:001194582100001
J	Schwartz, IS; Link, KE; Daneshjou, R; Cortes-Penfield, N				Schwartz, Ilan S.; Link, Katherine E.; Daneshjou, Roxana; Cortes-Penfield, Nicolas			Black Box Warning: Large Language Models and the Future of Infectious Diseases Consultation	CLINICAL INFECTIOUS DISEASES			English	Article						artificial intelligence; ChatGPT; chatbot; natural language processing; workforce	AUTOMATION BIAS	Large language models (LLMs) are artificial intelligence systems trained by deep learning algorithms to process natural language and generate text responses to user prompts. Some approach physician performance on a range of medical challenges, leading some proponents to advocate for their potential use in clinical consultation and prompting some consternation about the future of cognitive specialties. However, LLMs currently have limitations that preclude safe clinical deployment in performing specialist consultations, including frequent confabulations, lack of contextual awareness crucial for nuanced diagnostic and treatment plans, inscrutable and unexplainable training data and methods, and propensity to recapitulate biases. Nonetheless, considering the rapid improvement in this technology, growing calls for clinical integration, and healthcare systems that chronically undervalue cognitive specialties, it is critical that infectious diseases clinicians engage with LLMs to enable informed advocacy for how they should-and shouldn't-be used to augment specialist care. Large language models (LLMs), advanced artificial intelligence systems capable of generating natural language, could revolutionize healthcare, including current models of specialist consultation. Infectious diseases clinicians must urgently engage with and understand limitations of LLMs to advocate for their responsible integration. Graphical Abstract https://tidbitapp.io/tidbits/black-box-warning-large-language-models-and-clinical-consultation-in-infectious-disease	[Schwartz, Ilan S.] Duke Univ, Sch Med, Dept Med, Div Infect Dis, Durham, NC 27708 USA; [Link, Katherine E.] Icahn Sch Med Mt Sinai, Dept Med Educ, New York, NY USA; [Link, Katherine E.] Hugging Face, Healthcare & Life Sci Div, Brooklyn, NY USA; [Daneshjou, Roxana] Stanford Univ, Sch Med, Dept Dermatol, Stanford, CA USA; [Daneshjou, Roxana] Stanford Sch Med, Dept Biomed Data Sci, Stanford, CA USA; [Cortes-Penfield, Nicolas] Univ Nebraska Med Ctr, Div Infect Dis, Omaha, NE USA; [Schwartz, Ilan S.] Duke Univ, Dept Med, Div Infect Dis, Sch Med, 315 Trent Dr, Durham, NC 27710 USA	Duke University; Icahn School of Medicine at Mount Sinai; Stanford University; Stanford University; University of Nebraska System; University of Nebraska Medical Center; Duke University	Schwartz, IS (corresponding author), Duke Univ, Dept Med, Div Infect Dis, Sch Med, 315 Trent Dr, Durham, NC 27710 USA.	ilan.schwartz@duke.edu	Daneshjou, Roxana/ABE-7764-2021; Schwartz, Ilan/J-5666-2019	Schwartz, Ilan/0000-0002-7522-0281; Daneshjou, Roxana/0000-0001-7988-9356				Amann J, 2020, BMC MED INFORM DECIS, V20, DOI 10.1186/s12911-020-01332-6; [Anonymous], 2023, CONTINUOUS MODEL UPG; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bogun F, 2004, AM J MED, V117, P636, DOI 10.1016/j.amjmed.2004.06.024; Boulware DR, 2014, NEW ENGL J MED, V370, P2487, DOI 10.1056/NEJMoa1312884; Califf RM., 2023, NAT HLTH COUNC 2023; Dash D., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2304.13714; Dratsch T, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222176; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Fiske S.X., 1984, Social cognition; Fitzsimmons-Craft EE, 2022, INT J EAT DISORDER, V55, P343, DOI 10.1002/eat.23662; Goddard K, 2012, J AM MED INFORM ASSN, V19, P121, DOI 10.1136/amiajnl-2011-000089; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Howard A, 2023, LANCET INFECT DIS, V23, P405, DOI 10.1016/S1473-3099(23)00113-5; Jargon J, 2023, Wall Street Journal; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lenert LA, 2023, J AM MED INFORM ASSN, DOI 10.1093/jamia/ocad016; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Lyell D, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0425-5; Mosier K.L., 1996, Automation and human performance, P201; National Academies of Sciences Engineering and Medicine, 2019, Taking Action Against Clinician Burnout: A Systems Approach to Professional Well-Being; Nori H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.13375; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Price WN, 2019, JAMA-J AM MED ASSOC, V322, P1765, DOI 10.1001/jama.2019.15064; Quach Katyanna., 2020, Researchers made an openai gpt-3 medical chatbot as an experiment. it told a mock patient to kill themselves; Reddy S, 2022, LANCET DIGIT HEALTH, V4, DOI 10.1016/S2589-7500(22)00029-2; Reece R, 2023, J INFECT DIS, V228, P1649, DOI 10.1093/infdis/jiad160; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sarink MJ, 2023, CLIN MICROBIOL INFEC, V29, P1088, DOI 10.1016/j.cmi.2023.05.017; SCHWARTZ WB, 1970, NEW ENGL J MED, V283, P1257, DOI 10.1056/NEJM197012032832305; Singhal K, 2023, arXiv; Skitka LJ, 1999, INT J HUM-COMPUT ST, V51, P991, DOI 10.1006/ijhc.1999.0252; Smith CS., 2023, FORBES; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Wagner MW, 2024, CAN ASSOC RADIOL J, V75, P69, DOI 10.1177/08465371231171125; Walensky RP, 2020, ANN INTERN MED, V173, P587, DOI 10.7326/M20-2684; Weidinger L., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2112.04359; World Health Organization, 2018, GUID DIAGN PREV MAN; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Xiang Chloe, 2023, VICE	46	9	9	11	15	OXFORD UNIV PRESS INC	CARY	JOURNALS DEPT, 2001 EVANS RD, CARY, NC 27513 USA	1058-4838	1537-6591		CLIN INFECT DIS	Clin. Infect. Dis.	APR 10	2024	78	4					860	866		10.1093/cid/ciad633	http://dx.doi.org/10.1093/cid/ciad633		NOV 2023	7	Immunology; Infectious Diseases; Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Immunology; Infectious Diseases; Microbiology	NQ7T4	37971399	hybrid, Green Published			2024-07-03	WOS:001102860600001
J	Anderson, W; Braun, I; Bhatnagar, R; Romero, K; Walls, R; Schito, M; Podichetty, JT				Anderson, Wes; Braun, Ian; Bhatnagar, Roopal; Romero, Klaus; Walls, Ramona; Schito, Marco; Podichetty, Jagdeep T.			Unlocking the Capabilities of Large Language Models for Accelerating Drug Development	CLINICAL PHARMACOLOGY & THERAPEUTICS			English	Article; Early Access								Recent breakthroughs in natural language processing (NLP), particularly in large language models (LLMs), offer substantial advantages in model-informed drug development (MIDD). With billions of parameters and comprehensive pre-training on diverse data, these models effectively extract information from unstructured and structured data throughout the drug development lifecycle. This perspective envisions LLMs supporting MIDD, enhancing drug development, and emphasizes C-Path's strategic use of LLM innovations for actionable real-world evidence from real-world data (RWD).	[Anderson, Wes; Braun, Ian; Bhatnagar, Roopal; Romero, Klaus; Walls, Ramona; Schito, Marco; Podichetty, Jagdeep T.] Crit Path Inst, Tucson, AZ 85718 USA		Podichetty, JT (corresponding author), Crit Path Inst, Tucson, AZ 85718 USA.	jpodichetty@c-path.org		Schito, Marco/0000-0003-0113-4628	Food and Drug Administration (FDA) of the Department of Health and Human Services (HHS); FDA/HHS	Food and Drug Administration (FDA) of the Department of Health and Human Services (HHS)(United States Department of Health & Human ServicesUS Food & Drug Administration (FDA)); FDA/HHS	Critical Path Institute is supported by the Food and Drug Administration (FDA) of the Department of Health and Human Services (HHS) and is 55% funded by the FDA/HHS, totalling $17,612,250, and 45% funded by nongovernment source(s), totalling $14,203,111. The contents are those of the author(s) and do not necessarily represent the official views of, nor an endorsement by, FDA/HHS or the US Government.	Agrawal M, 2022, Arxiv, DOI arXiv:2205.12689; Bhatnagar R, 2022, JAMIA OPEN, V5, DOI 10.1093/jamiaopen/ooac043; Caufield JH, 2023, Arxiv, DOI arXiv:2304.02711; Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	10	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0009-9236	1532-6535		CLIN PHARMACOL THER	Clin. Pharmacol. Ther.	2024 APR 22	2024										10.1002/cpt.3279	http://dx.doi.org/10.1002/cpt.3279		APR 2024	4	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	OJ5Z8	38649744	hybrid			2024-07-03	WOS:001206929600001
J	Mohan, GB; Kumar, RP; Krishh, PV; Keerthinathan, A; Lavanya, G; Meghana, MKU; Sulthana, S; Doss, S				Bharathi Mohan, G.; Prasanna Kumar, R.; Vishal Krishh, P.; Keerthinathan, A.; Lavanya, G.; Meghana, Meka Kavya Uma; Sulthana, Sheba; Doss, Srinath			An analysis of large language models: their impact and potential applications	KNOWLEDGE AND INFORMATION SYSTEMS			English	Review; Early Access						Large language model; NLP; Education; Health care; Finance		Large language models (LLMs) have transformed the interpretation and creation of human language in the rapidly developing field of computerized language processing. These models, which are based on deep learning techniques like transformer architectures, have been painstakingly trained on massive text datasets. This study paper takes an in-depth look into LLMs, including their architecture, historical evolution, and applications in education, healthcare, and finance sector. LLMs provide logical replies by interpreting complicated verbal patterns, making them beneficial in a variety of real-world scenarios. Their development and implementation, however, raise ethical concerns and have societal ramifications. Understanding the importance and limitations of LLMs is critical for guiding future research and ensuring the ethical use of their enormous potential. This survey exposes the influence of these models as they change, providing a roadmap for researchers, developers, and policymakers navigating the world of artificial intelligence and language processing.	[Bharathi Mohan, G.; Prasanna Kumar, R.; Vishal Krishh, P.; Keerthinathan, A.; Lavanya, G.; Meghana, Meka Kavya Uma; Sulthana, Sheba] Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci & Engn, Chennai, India; [Doss, Srinath] Botho Univ, Fac Informat Technol, Gaborone, Botswana	Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Chennai	Mohan, GB (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Comp, Dept Comp Sci & Engn, Chennai, India.	g_bharathimohan@ch.amrita.edu						Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Aher GV, 2023, INT C MACHINE LEARNI, P337; Akbar NA, 2021, J Hunan Univ Nat Sci, V48; Alhaidry Hind M, 2023, Cureus, V15, pe38317, DOI 10.7759/cureus.38317; Arisoy E, 2012, P NAACL HLT 2012 WOR, P20; Azunre P., 2021, Transfer learning for natural language processing; Bawden R, 2023, Arxiv, DOI arXiv:2303.01911; Bewersdorff A., 2023, Comput, V5, P100177, DOI [10.1016/j.caeai.2023.100177, DOI 10.48550/ARXIV.2308.06088]; Bharathi Mohan G, 2023, Data analytics for internet of things infrastructure. Internet of Things, DOI [10.1007/978-3-031-33808-3_14, DOI 10.1007/978-3-031-33808-3_14]; Bharathi Mohan G, 2022, IOT BASED CONTROL NE, P831; Brameier Devon T, 2023, J Bone Joint Surg Am, V105, P1388, DOI 10.2106/JBJS.23.00473; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cabrera Johana, 2023, Bioinformatics and Biomedical Engineering: 10th International Work-Conference, IWBBIO 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Bioinformatics (13920), P313, DOI 10.1007/978-3-031-34960-7_22; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ellaway RH, 2023, ADV HEALTH SCI EDUC, V28, P659, DOI 10.1007/s10459-023-10257-4; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Forsyth D., 2019, Applied machine learning, P305, DOI [10.1007/978-3-030-18114-7_13, DOI 10.1007/978-3-030-18114-7_13]; Gu Y, 2023, Arxiv, DOI arXiv:2307.06439; Huang HY, 2023, INT J ORAL SCI, V15, DOI 10.1038/s41368-023-00239-y; Huang J, 2023, Arxiv, DOI arXiv:2212.10403; Juang Biing-Hwang., 2005, Automatic speech recognition-a brief history of the technology development, V1, P67; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katz A, 2023, Arxiv, DOI [arXiv:2305.18125, 10.48550/arXiv.2305.18125, DOI 10.48550/ARXIV.2305.18125]; Kojima T, 2022, ADV NEUR IN; Kovacevic Aldin, 2022, Advanced Technologies, Systems, and Applications VI: Proceedings of the International Symposium on Innovative and Interdisciplinary Applications of Advanced Technologies (IAT) 2021. Lecture Notes in Networks and Systems (316), P281, DOI 10.1007/978-3-030-90055-7_21; Li YH, 2023, PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023, P374, DOI 10.1145/3604237.3626869; Liddy E., 2001, Inf Retr, V4, P82, DOI [10.1023/A:1011476409104, DOI 10.1023/A:1011476409104]; Liu XY, 2023, Arxiv, DOI [arXiv:2307.10485, 10.48550/arXiv.2307.10485, DOI 10.48550/ARXIV.2307.10485]; Liu XY, 2005, ANNU REV INFORM SCI, V39, P3; Liu Y., 2023, MetaRadiology, V1; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Nourbakhsh A, 2019, Arxiv, DOI arXiv:1908.09156; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reddy Sandeep, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101304; Sallam M, 2023, medRxiv; Santos Thiago, 2022, AMIA Annu Symp Proc, V2022, P962; Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909; Sharaf S, 2023, Arxiv, DOI arXiv:2310.07282; Shi WJ, 2024, Arxiv, DOI [arXiv:2310.16789, 10.48550/ARXIV.2310.16789, DOI 10.48550/ARXIV.2310.16789]; Sutskever I, 2014, ADV NEUR IN, V27; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Xie QQ, 2023, Arxiv, DOI arXiv:2306.05443; Yan LX, 2023, Arxiv, DOI arXiv:2303.13379; Yang H, 2023, arXiv; Yang X., 2022, medRxiv; Yang Y, 2023, Arxiv, DOI arXiv:2309.13064; Yang Y, 2020, Arxiv, DOI arXiv:2006.08097; Yang ZL, 2019, ADV NEUR IN, V32; Yu Y, 2023, Arxiv, DOI [arXiv:2306.15895, DOI 10.48550/ARXIV.2306.15895]; Zhang HB, 2023, Arxiv, DOI arXiv:2305.15075; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou SC, 2022, J AM MED INFORM ASSN, V29, P1208, DOI 10.1093/jamia/ocac040; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	66	0	0	12	12	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	0219-1377	0219-3116		KNOWL INF SYST	Knowl. Inf. Syst.	2024 MAY 11	2024										10.1007/s10115-024-02120-8	http://dx.doi.org/10.1007/s10115-024-02120-8		MAY 2024	24	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QL3Z4					2024-07-03	WOS:001221002800002
J	Toetzke, M; Probst, B; Feuerriegel, S				Toetzke, Malte; Probst, Benedict; Feuerriegel, Stefan			Leveraging large language models to monitor climate technology innovation	ENVIRONMENTAL RESEARCH LETTERS			English	Editorial Material						innovation; large language models; machine learning; climate technologies	SYSTEMS	To achieve net-zero emissions, public policy needs to foster rapid innovation of climate technologies. However, there is a scarcity of comprehensive and up-to-date evidence to guide policymaking by monitoring climate innovation systems. This is notable, especially at the center of the innovation process, where nascent inventions transition into profitable and scalable market solutions. Here, we discuss the potential of large language models (LLMs) to monitor climate technology innovation. By analyzing large pools of unstructured text data sources, such as company reports and social media, LLMs can automate information retrieval processes and thereby improve existing monitoring in terms of cost-effectiveness, timeliness, and comprehensiveness. In this perspective, we show how LLMs can play a crucial role in informing innovation policy for the energy transition by highlighting promising use cases and prevailing challenges for research and policy.	[Toetzke, Malte; Probst, Benedict] Swiss Fed Inst Technol, Grp Sustainabil & Technol, Zurich, Switzerland; [Probst, Benedict] Univ Cambridge, Ctr Environm Energy & Nat Resource Governance, Cambridge, England; [Feuerriegel, Stefan] Ludwig Maximilians Univ Munchen, Munich Ctr Machine Learning, Munich, Germany	Swiss Federal Institutes of Technology Domain; ETH Zurich; University of Cambridge; University of Munich	Toetzke, M (corresponding author), Swiss Fed Inst Technol, Grp Sustainabil & Technol, Zurich, Switzerland.	mtoetzke@ethz.ch		Toetzke, Malte/0000-0002-1153-2702				Bergek A, 2015, ENVIRON INNOV SOC TR, V16, P51, DOI 10.1016/j.eist.2015.07.003; BloombergNEF, 2023, about us; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cleantech Group, 2023, DISC I3 MARK INT; Cox E, 2020, NAT CLIM CHANGE, V10, P744, DOI 10.1038/s41558-020-0823-z; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doblinger C, 2019, RES POLICY, V48, P1458, DOI 10.1016/j.respol.2019.02.006; Egli F, 2018, NAT ENERGY, V3, P1084, DOI 10.1038/s41560-018-0277-y; European Patent Office, 2023, PATSTAT; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gallagher KS, 2012, ANNU REV ENV RESOUR, V37, P137, DOI 10.1146/annurev-environ-060311-133915; Goldstein A, 2020, NAT ENERGY, V5, P803, DOI 10.1038/s41560-020-00683-8; Grubb M., 2014, Planetary Economics; Grubler A, 2014, ENERGY TECHNOLOGY INNOVATION: LEARNING FROM HISTORICAL SUCCESSES AND FAILURES, P1; Hekkert MP, 2007, TECHNOL FORECAST SOC, V74, P413, DOI 10.1016/j.techfore.2006.03.002; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; IEA, 2020, ENERGY TECHNOLOGY PE; IPCC, 2023, CLIM CHANG 2023 SYNT; Lang J., 2023, Net zero tracker; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lilliestam J, 2020, NAT ENERGY, V5, P71, DOI 10.1038/s41560-019-0531-y; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Markard J, 2020, TECHNOL FORECAST SOC, V153, DOI 10.1016/j.techfore.2018.07.045; Meckling J, 2022, NAT ENERGY, V7, P876, DOI 10.1038/s41560-022-01117-3; Probst B, 2021, NAT ENERGY, V6, P1077, DOI 10.1038/s41560-021-00931-5; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Toetzke M., 2023, ICLR 2023 WORKSH TAC; Toetzke M., 2022, NEURIPS 2022 WORKSH; Toetzke M, 2022, NAT CLIM CHANGE, V12, P897, DOI 10.1038/s41558-022-01482-7; Toetzke M, 2022, NAT SUSTAIN, V5, P533, DOI 10.1038/s41893-022-00874-z; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaghefi SA, 2023, Chatclimate: grounding conversational ai in climate science; Zaussinger F., 2023, IMPACT LOW CARBON TR	33	0	0	20	34	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	1748-9326			ENVIRON RES LETT	Environ. Res. Lett.	SEP 1	2023	18	9							091004	10.1088/1748-9326/acf233	http://dx.doi.org/10.1088/1748-9326/acf233			7	Environmental Sciences; Meteorology & Atmospheric Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Meteorology & Atmospheric Sciences	R5BJ6		Green Published, gold			2024-07-03	WOS:001064499000001
J	Lin, ZC				Lin, Zhicheng			How to write effective prompts for large language models	NATURE HUMAN BEHAVIOUR			English	Article; Early Access							AI	Effectively engaging with large language models is becoming increasingly vital as they proliferate across research landscapes. This Comment presents a practical guide for understanding their capabilities and limitations, along with strategies for crafting well-structured queries, to extract maximum utility from these artificial intelligence tools.	[Lin, Zhicheng] Univ Sci & Technol China, Dept Psychol, Hefei, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Lin, ZC (corresponding author), Univ Sci & Technol China, Dept Psychol, Hefei, Peoples R China.	zhichenglin@gmail.com	Lin, Zhicheng/B-9756-2008	Lin, Zhicheng/0000-0002-6864-6559	National Natural Science Foundation of China (National Science Foundation of China) [2021ZD0204200]; National Key R&D Program of China [32071045]; National Natural Science Foundation of China [JCYJ20210324134603010]; Shenzhen Fundamental Research Program	National Natural Science Foundation of China (National Science Foundation of China)(National Natural Science Foundation of China (NSFC)); National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shenzhen Fundamental Research Program	The writing was supported by the National Key R&D Program of China STI2030 Major Projects (2021ZD0204200), National Natural Science Foundation of China (32071045) and Shenzhen Fundamental Research Program (JCYJ20210324134603010). The funder had no role in the decision to publish or the preparation of this manuscript. I used GPT-4 and Claude 2.0 to proofread the manuscript on the basis of prompts described at: https://psyarxiv.com/9yhwz.	Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Li C, 2023, Arxiv, DOI [arXiv:2307.11760, DOI 10.48550/ARXIV.2307.11760, 10.48550/arXiv.2307.11760]; Li CS, 2023, Arxiv, DOI arXiv:2312.04474; Lin ZC, 2024, Arxiv, DOI [arXiv:2310.17143, 10.48550/arXiv.2310.17143, DOI 10.48550/ARXIV.2310.17143]; Lin ZC, 2024, TRENDS COGN SCI, V28, P85, DOI 10.1016/j.tics.2023.12.002; Lin ZC, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.230658; Merow C, 2023, NAT ECOL EVOL, V7, P960, DOI 10.1038/s41559-023-02063-3; Yasunaga M, 2024, Arxiv, DOI [arXiv:2310.01714, 10.48550/arXiv.2310.01714]; Zamfirescu-Pereira J. D., 2023, CHI '23: Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3544548.3581388	10	3	3	20	20	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2024 MAR 4	2024										10.1038/s41562-024-01847-2	http://dx.doi.org/10.1038/s41562-024-01847-2		MAR 2024	5	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	KF8X3	38438650				2024-07-03	WOS:001178645000005
C	Singh, U; Aarabhi, P			IEEE	Singh, Umarpreet; Aarabhi, Parham			Can AI have a personality?	2023 IEEE CONFERENCE ON ARTIFICIAL INTELLIGENCE, CAI			English	Proceedings Paper	IEEE Conference on Artificial Intelligence (IEEE CAI)	JUN 05-06, 2023	Santa Clara, CA	IEEE, IEEE Comp Soc, IEEE Signal Proc Soc, IEEE Syst, Man, & Cybernet Soc		Artificial Intelligence; Large Language Models; Personality; Natural Language Processing		In this paper, we evaluated several large language models (including ChatGPT, GPT3 and LLAMA) by running standardized personality tests on their results. Generally, we found that each large language model has an internal consistent personality. We further found that LLama tends to score more highly on Neuroticism than other models, whereas ChatGPT/GPT3 tends to score more highly on Conscientiousness and Agreeableness.	[Singh, Umarpreet; Aarabhi, Parham] Univ Toronto, Elect & Comp Engn, Toronto, ON, Canada	University of Toronto	Singh, U (corresponding author), Univ Toronto, Elect & Comp Engn, Toronto, ON, Canada.	umarpreet.singh@mail.utoronto.ca; parham@ecf.utoronto.ca						Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Brown T., 2020, NIPS, P1877; Caliskan, 2022, P 2022 AAAIACM C ETH; Costa PT, 2008, The SAGE Handbook of Personality Theory and Assessment: Volume 2Personality Measurement and Testing, DOI [DOI 10.4135/9781849200479.N9, 10.4135/9781849200479.n9]; Furnham A, 2017, MYERS BRIGGS TYPE IN, P1; OpenAI, 2023, Introducing chatgpt; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]	8	1	1	6	14	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-3984-0				2023							205	206		10.1109/CAI54212.2023.00097	http://dx.doi.org/10.1109/CAI54212.2023.00097			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV5BQ					2024-07-03	WOS:001046447800087
J	Sorin, V; Klang, E				Sorin, Vera; Klang, Eyal			Large language models and the emergence phenomena	EUROPEAN JOURNAL OF RADIOLOGY OPEN			English	Editorial Material						LLMs; ChatGPT; Emergence; Generative models		This perspective explores the potential of emergence phenomena in large language models (LLMs) to transform data management and analysis in radiology. We provide a concise explanation of LLMs, define the concept of emergence in machine learning, offer examples of potential applications within the radiology field, and discuss risks and limitations. Our goal is to encourage radiologists to recognize and prepare for the impact this tech-nology may have on radiology and medicine in the near future.	[Sorin, Vera; Klang, Eyal] Tel Aviv Univ, Chaim Sheba Med Ctr, Sackler Sch Med, Dept Diagnost Imaging, Tel Aviv, Israel; [Sorin, Vera; Klang, Eyal] Sheba Med Ctr, DeepVis Lab, Tel Hashomer, Israel; [Klang, Eyal] Sheba Med Ctr, Sami Sagol AI Hub, ARC, Ramat Gan, Israel; [Sorin, Vera] Chaim Sheba Med Ctr, Dept Diagnost Imaging, Emek Haela St 1, IL-52621 Ramat Gan, Israel	Chaim Sheba Medical Center; Tel Aviv University; Chaim Sheba Medical Center; Chaim Sheba Medical Center; Chaim Sheba Medical Center	Sorin, V (corresponding author), Chaim Sheba Med Ctr, Dept Diagnost Imaging, Emek Haela St 1, IL-52621 Ramat Gan, Israel.	verasrn@gmail.com	Sorin, Vera/IAR-4247-2023	Sorin, Vera/0000-0003-0509-4686				Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bubeck Se., 2023, COMPUT LANG, V4; Fanni S.C., 2022, RADIOLOGE, P169, DOI 10.1007/978-3-030-91349-6_8; Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399; Ganguli D., 2022, 2022 ACM C FAIRNESS; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Khurana D, 2023, MULTIMED TOOLS APPL, V82, P3713, DOI 10.1007/s11042-022-13428-4; Kivelson S, 2016, NPJ QUANTUM MATER, V1, DOI 10.1038/npjquantmats.2016.24; Lopez-Ubeda Pilar, 2022, J Am Coll Radiol, V19, P1271, DOI 10.1016/j.jacr.2022.06.016; OConnor Timothy, 2020, EMERGENT PROPERTIES; Sharir O, 2020, Arxiv, DOI [arXiv:2004.08900, DOI 10.48550/ARXIV.2004.08900]; Sorin V, 2021, RADIOLOGY, V301, DOI 10.1148/radiol.2021210566; Sorin V, 2020, LANCET ONCOL, V21, P1553, DOI 10.1016/S1470-2045(20)30615-X; Sorin V, 2020, ACAD RADIOL, V27, P1175, DOI 10.1016/j.acra.2019.12.024; Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	20	3	3	2	6	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS		2352-0477		EUR J RADIOL OPEN	Eur. J. Radiol. Open		2023	10								100494	10.1016/j.ejro.2023.100494	http://dx.doi.org/10.1016/j.ejro.2023.100494		JUN 2023	3	Radiology, Nuclear Medicine & Medical Imaging	Emerging Sources Citation Index (ESCI)	Radiology, Nuclear Medicine & Medical Imaging	P9NN5	37325497	Green Published, gold			2024-07-03	WOS:001053874000001
C	Diemert, S; Weber, JH		Guiochet, J; Tonetta, S; Schoitsch, E; Roy, M; Bitsch, F		Diemert, Simon; Weber, Jens H.			Can Large Language Models Assist in Hazard Analysis?	COMPUTER SAFETY, RELIABILITY, AND SECURITY, SAFECOMP 2023 WORKSHOPS	Lecture Notes in Computer Science		English	Proceedings Paper	SAFECOMP Workshops / 8th ASSURE International Workshop / 18th DECSoS Workshop / 10th SASSUR International Workshop / 2nd SENSEI International Workshop / 1st SRToITS International Workshop / 6th WAISE International Workshop	SEP 19, 2023	Toulouse, FRANCE	SICK AG, IMAGINARY, Crit Syst Labs Inc		Hazard Analysis; Artificial Intelligence; Large Language Models; Co-Hazard Analysis		Large Language Models (LLMs), such as GPT-3, have demonstrated remarkable natural language processing and generation capabilities and have been applied to a variety tasks, such as source code generation. This paper explores the potential of integrating LLMs in the hazard analysis for safety-critical systems, a process which we refer to as co-hazard analysis (CoHA). In CoHA, a human analyst interacts with an LLM via a context-aware chat session and uses the responses to support elicitation of possible hazard causes. In a preliminary experiment, we explore CoHA with three increasingly complex versions of a simple system, using Open AI's ChatGPT service. The quality of ChatGPT's responses were systematically assessed to determine the feasibility of CoHA given the current state of LLM technology. The results suggest that LLMs may be useful for supporting human analysts performing hazard analysis.	[Diemert, Simon; Weber, Jens H.] Univ Victoria, Victoria, BC, Canada	University of Victoria	Diemert, S (corresponding author), Univ Victoria, Victoria, BC, Canada.	sdiemert@uvic.ca						Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ericson CA, 2005, HAZARD ANALYSIS TECHNIQUES FOR SYSTEM SAFETY, P1, DOI 10.1002/0471739421; Hristova B., 2023, Some students are using ChatGPT to cheat-here's how schools are trying to stop it; Leveson NG, 2011, ENG SYST, P1; Lim S.C., 2022, A case for pre-trained language models in systems engineering	7	0	0	1	1	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-40952-3; 978-3-031-40953-0	LECT NOTES COMPUT SC			2023	14182						410	422		10.1007/978-3-031-40953-0_35	http://dx.doi.org/10.1007/978-3-031-40953-0_35			13	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5JT		Green Submitted			2024-07-03	WOS:001162118400041
J	Arvisais-Anhalt, S; Gonias, SL; Murray, SG				Arvisais-Anhalt, Simone; Gonias, Steven L.; Murray, Sara G.			Establishing priorities for implementation of large language models in pathology and laboratory medicine	ACADEMIC PATHOLOGY			English	Review						Artificial intelligence; GPT; Large language models (LLMs)		Artificial intelligence and machine learning have numerous applications in pathology and laboratory medicine. The release of ChatGPT prompted speculation regarding the potentially transformative role of large-language models (LLMs) in academic pathology, laboratory medicine, and pathology education. Because of the potential to improve LLMs over the upcoming years, pathology and laboratory medicine clinicians are encouraged to embrace this technology, identify pathways by which LLMs may support our missions in education, clinical practice, and research, participate in the refinement of AI modalities, and design user-friendly interfaces that integrate these tools into our most important workflows. Challenges regarding the use of LLMs, which have already received considerable attention in a general sense, are also reviewed herein within the context of the pathology field and are important to consider as LLM applications are identified and operationalized.	[Arvisais-Anhalt, Simone] Univ Calif San Francisco, Dept Lab Med, San Francisco, CA USA; [Gonias, Steven L.] Univ Calif San Diego, Dept Pathol, La Jolla, CA USA; [Murray, Sara G.] Univ Calif San Francisco, Dept Med, San Francisco, CA USA; [Gonias, Steven L.] UCSD Sch Med, Dept Pathol, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Murray, Sara G.] Univ Calif San Francisco, Dept Med, 521 Parnassus Ave, San Francisco, CA 94143 USA	University of California System; University of California San Francisco; University of California System; University of California San Diego; University of California System; University of California San Francisco; University of California System; University of California San Diego; University of California System; University of California San Francisco	Gonias, SL (corresponding author), UCSD Sch Med, Dept Pathol, 9500 Gilman Dr, La Jolla, CA 92093 USA.; Murray, SG (corresponding author), Univ Calif San Francisco, Dept Med, 521 Parnassus Ave, San Francisco, CA 94143 USA.	sgonias@health.ucsd.edu; sara.murray@ucsf.edu						Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2023, ext generated by ChatGPT in response to a hypothetical hematopathology case report [Please summarize the following bone marrow aspirate report at the 6th grade reading level and include patient education materials]; [Anonymous], 2022, Artificial intellence and machine learning (AI/ML)-enabled medical devices; Apathy NC, 2023, HEALTH SERV RES, V58, P674, DOI 10.1111/1475-6773.14097; Arvisais-Anhalt S, 2023, APPL CLIN INFORM, V14, P45, DOI 10.1055/a-1990-5157; Arvisais-Anhalt S, 2022, J MED INTERNET RES, V24, DOI 10.2196/34085; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Cowan AJ, 2022, JAMA-J AM MED ASSOC, V327, P464, DOI 10.1001/jama.2022.0003; Försch S, 2021, DTSCH ARZTEBL INT, V118, P199, DOI 10.3238/arztebl.m2021.0011; Gao TY, 2023, Arxiv, DOI arXiv:2305.14627; Gerber David E, 2022, JCO Oncol Pract, V18, P85, DOI 10.1200/OP.21.00436; Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Kroth PJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9609; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liang PP, 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.13219; Rakha EA, 2021, J CLIN PATHOL, V74, P409, DOI 10.1136/jclinpath-2020-206908; Rashidi HH, 2019, ACAD PATHOL, V6, DOI 10.1177/2374289519873088; Robillard N, 2014, FRONT IMMUNOL, V5, DOI 10.3389/fimmu.2014.00137; Services DoHaH Office of the Federal Register National Archives and Records Administration, 2020, Federal Register, V85, P25642; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Toscano F, 2020, J GEN INTERN MED, V35, P3166, DOI 10.1007/s11606-020-06087-4; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wartman SA, 2018, ACAD MED, V93, P1107, DOI 10.1097/ACM.0000000000002044; West CP, 2018, J INTERN MED, V283, P516, DOI 10.1111/joim.12752; Winget M, 2016, J ONCOL PRACT, V12, P729, DOI 10.1200/JOP.2016.011098	28	1	1	4	4	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	2374-2895			ACAD PATHOL	Acad. Pathol.	JAN-MAR	2024	11	1							100101	10.1016/j.acpath.2023.100101	http://dx.doi.org/10.1016/j.acpath.2023.100101		JAN 2024	5	Pathology	Emerging Sources Citation Index (ESCI)	Pathology	GU5B3	38292297	gold			2024-07-03	WOS:001155187900001
C	Wang, BY; Li, G; Li, Y			ACM	Wang, Bryan; Li, Gang; Li, Yang			Enabling Conversational Interaction with Mobile UI using Large Language Models	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Large Language Models; Conversational Interaction; Mobile UI		Conversational agents show the promise to allow users to interact with mobile devices using language. However, to perform diverse UI tasks with natural language, developers typically need to create separate datasets and models for each specifc task, which is expensive and effort-consuming. Recently, pre-trained large language models (LLMs) have been shown capable of generalizing to various downstream tasks when prompted with a handful of examples from the target task. This paper investigates the feasibility of enabling versatile conversational interactions with mobile UIs using a single LLM. We designed prompting techniques to adapt an LLM to mobile UIs. We experimented with four important modeling tasks that address various scenarios in conversational interaction. Our method achieved competitive performance on these challenging tasks without requiring dedicated datasets and training, offering a lightweight and generalizable approach to enable language-based mobile interaction.	[Wang, Bryan] Univ Toronto, Toronto, ON M5S 1A1, Canada; [Wang, Bryan; Li, Gang; Li, Yang] Google Res, Mt View, ON, Canada	University of Toronto	Wang, BY (corresponding author), Univ Toronto, Toronto, ON M5S 1A1, Canada.	bryanw@dgp.toronto.edu; leebird@google.com; liyang@google.com		Wang, Bryan/0000-0001-9016-038X				Adept, 2022, ACT 1 TRANSF ACT; Ahn Michael, 2022, DO I CAN NOT I SAY G, DOI DOI 10.48550/ARXIV.2204.01691; Alayrac Jean-Baptiste, 2022, FLAMINGO VISUAL LANG, DOI DOI 10.48550/ARXIV.2204.14198; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bolt R. A., 1980, Computer Graphics, V14, P262, DOI 10.1145/965105.807503; Brown Tom B., 2020, ARXIV200514165 CS CL; Burns Andrea, 2022, DATASET INTERACTIVE, DOI [10.48550/ARXIV.2202.02312, DOI 10.48550/ARXIV.2202.02312]; Chowdhery A., 2022, ARXIV220402311; Chung JJY, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519873; Dang Hai, 2022, PROMPT OPPORTUNITIES, DOI [10.48550/ARXIV.2209.01390, DOI 10.48550/ARXIV.2209.01390]; Deka B, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P845, DOI 10.1145/3126594.3126651; Folstad A., 2017, interactions, V24, P38, DOI [DOI 10.1145/3085558, 10.1145/3085558]; Fu S., 2021, P 2021 CHI C HUM FAC, P1, DOI DOI 10.1109/ISPA-BDCLOUD-SOCIALCOM-SUSTAINCOM52081.2021.00016; Goyal Tanya, 2022, NEWS SUMMARIZATION E, DOI [10.48550/ARXIV.2209.12356, DOI 10.48550/ARXIV.2209.12356]; Han Song, 2015, DEEP COMPRESSION COM, DOI [10.48550/ARXIV.1510.00149, DOI 10.48550/ARXIV.1510.00149]; Hinton G., 2015, COMPUTER SCI, V1050, P9, DOI [10.48550/arXiv.1503.02531, DOI 10.48550/ARXIV.1503.02531]; Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159; Hsiao Yu-Chung, 2022, SCREENQA LARGE SCALE, DOI DOI 10.48550/ARXIV.2209.08199; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870; Jiang Ellen, 2022, 2022 CHI C HUM FACT, DOI [DOI 10.1145/3491101, DOI 10.1145/3491101.3503564]; Karat C., 2003, HUM FAC ER, P169; Kim TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501931; Kojima T, 2023, arXiv, DOI [10.48550/arXiv.2205.11916, DOI 10.48550/ARXIV.2205.11916]; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Lee Y, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022), P62; Lee Y, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502087; Leiva LA, 2023, ACM T INTEL SYST TEC, V14, DOI 10.1145/3564702; Li G, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac838f; Li Toby Jia-Jun, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P1094, DOI 10.1145/3379337.3415820; Li Tao, 2022, MUG INTERACTIVE MULT, DOI [10.48550/ARXIV.2209. 15099, DOI 10.48550/ARXIV.2209.15099]; Li TJJ, 2019, PROCEEDINGS OF THE 32ND ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY (UIST 2019), P577, DOI 10.1145/3332165.3347899; Li TJJ, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P96, DOI 10.1145/3210240.3210339; Li TJJ, 2018, 2018 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P105, DOI 10.1109/VLHCC.2018.8506506; Li TJJ, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6038, DOI 10.1145/3025453.3025483; Li Y., 2020, P 58 ANN M ASS COMPU, P8198, DOI [DOI 10.18653/V1/2020.ACL-MAIN.729, 10.18653/v1/2020.acl-main.729]; Li Yang, 2021, VUT VERSATILE UI TRA, DOI [10.48550/ARXIV.2112.05692, DOI 10.48550/ARXIV.2112.05692]; Li Yang, 2021, ARXIV211205692; Li Yang, 2020, Widget captioning: Generating natural language description for mobile user interface elements; Liu Evan Zheran, 2018, ARXIV180208802 CS AI; Liu YH, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517731; LONG C, 2021, 34 ANN ACM S US INT, P447, DOI DOI 10.1145/3472749.3474763; Pasupat P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4970; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Reynolds Laria, 2021, PROMPT PROGRAMMING L, DOI [10.48550/ARXIV. 2102.07350, DOI 10.48550/ARXIV.2102.07350]; Sanh V., 2020, DISTILBERT DISTILLED, DOI DOI 10.48550/ARXIV.1910.01108; Sarsenbayeva Z., 2017, OZCHI '17: Proceedings of the 29th Australian Conference on Computer-Human Interaction, P477, DOI DOI 10.1145/3152771.3156161; Schulman J, 2022, Introducing chatgpt; Todi K, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P1447, DOI 10.1145/3461778.3462124; Wang Bryan, 2021, UIST '21: The 34th Annual ACM Symposium on User Interface Software and Technology, P498, DOI 10.1145/3472749.3474765; Wang Xuezhi, 2022, RATIONALE AUGMENTED, DOI [10. 48550/ARXIV.2207.00747, DOI 10.48550/ARXIV.2207.00747]; Wei Jason, 2022, arXiv:2206.07682; Wei Jason, 2022, CHAIN THOUGHT PROMPT, DOI [10.48550/ARXIV.2201. 11903, DOI 10.48550/ARXIV.2201.11903]; Wobbrock JO, 2019, PROCEEDINGS OF THE ACM SIGCHI SYMPOSIUM ON ENGINEERING INTERACTIVE COMPUTING SYSTEMS (EICS'19), DOI 10.1145/3319499.3330292; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Zaheer Manzil, 2020, BIG BIRD TRANSFORMER, DOI [10.48550/ARXIV.2007.14062, DOI 10.48550/ARXIV.2007.14062]; ZHANG XY, 2021, P 2021 CHI C HUM FAC; Zhou Denny, 2022, LEAST TO MOST PROMPT, DOI [10.48550/ARXIV.2205.10625, DOI 10.48550/ARXIV.2205.10625]	58	8	8	10	16	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580895	http://dx.doi.org/10.1145/3544548.3580895			17	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO		Green Submitted, Bronze			2024-07-03	WOS:001037809503051
C	Sobania, D; Geiger, A; Callan, J; Brownlee, A; Hanna, C; Moussa, R; López, MZ; Petke, J; Sarro, F		Arcaini, P; Yue, T; Fredericks, EM		Sobania, Dominik; Geiger, Alina; Callan, James; Brownlee, Alexander; Hanna, Carol; Moussa, Rebecca; Lopez, Mar Zamorano; Petke, Justyna; Sarro, Federica			Evaluating Explanations for Software Patches Generated by Large Language Models	SEARCH-BASED SOFTWARE ENGINEERING, SSBSE 2023	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Symposium on Search-Based Software Engineering (SSBSE)	DEC 08, 2023	San Francisco, CA	Grand Valley State Univ		Large Language Models; Software Patches; AI Explainability; Program Repair; Genetic Improvement		Large language models (LLMs) have recently been integrated in a variety of applications including software engineering tasks. In this work, we study the use of LLMs to enhance the explainability of software patches. In particular, we evaluate the performance of GPT 3.5 in explaining patches generated by the search-based automated program repair system ARJA-e for 30 bugs from the popular Defects4J benchmark. We also investigate the performance achieved when explaining the corresponding patches written by software developers. We find that on average 84% of the LLM explanations for machine-generated patches were correct and 54% were complete for the studied categories in at least 1 out of 3 runs. Furthermore, we find that the LLM generates more accurate explanations for machine-generated patches than for human-written ones.	[Sobania, Dominik; Geiger, Alina] Johannes Gutenberg Univ Mainz, Mainz, Germany; [Callan, James; Hanna, Carol; Moussa, Rebecca; Lopez, Mar Zamorano; Petke, Justyna; Sarro, Federica] UCL, London, England; [Brownlee, Alexander] Univ Stirling, Stirling, Scotland	Johannes Gutenberg University of Mainz; University of London; University College London; University of Stirling	Sobania, D (corresponding author), Johannes Gutenberg Univ Mainz, Mainz, Germany.	dsobania@uni-mainz.de; geiger@uni-mainz.de; james.callan.19@ucl.ac.uk; alexander.brownlee@stir.ac.uk; carol.hanna.21@ucl.ac.uk; r.moussa@ucl.ac.uk; maria.lopez.20@ucl.ac.uk; j.petke@ucl.ac.uk; f.sarro@ucl.ac.uk	Brownlee, Alexander Edward Ian/I-5904-2012	Brownlee, Alexander Edward Ian/0000-0003-2892-5059; Sobania, Dominik/0000-0001-8873-7143; Hanna, Carol/0009-0009-7386-1622; Geiger, Alina/0009-0002-3413-283X; Petke, Justyna/0000-0002-7833-6044	UKRI EPSRC [EP/P023991/1]; ERC [741278]	UKRI EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC(European Research Council (ERC))	This work was supported by the UKRI EPSRC grant no. EP/P023991/1 and the ERC advanced fellowship grant no. 741278.	Chen ES, 2023, Arxiv, DOI arXiv:2305.01863; Chen M., 2021, arXiv; Fan A., 2023, Large language models for software engineering: Survey and open problems; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kang SM, 2023, Arxiv, DOI arXiv:2304.02195; Krauss O, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON GENETIC IMPROVEMENT, GI, P21, DOI 10.1109/GI59320.2023.00014; Liang JJ, 2019, PROC INT SYMP SOFTW, P58, DOI 10.1109/ISSRE.2019.00016; Nauta M, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3583558; Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219; Sobania D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P23, DOI 10.1109/APR59189.2023.00012; Yuan Y, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3360004	12	0	0	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48795-8; 978-3-031-48796-5	LECT NOTES COMPUT SC			2024	14415						147	152		10.1007/978-3-031-48796-5_12	http://dx.doi.org/10.1007/978-3-031-48796-5_12			6	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5AC					2024-07-03	WOS:001157562200013
J	King, MR; Abdulrahman, AM; Petrovic, MI; Poley, PL; Hall, SP; Kulapatana, S; Lamantia, ZE				King, Michael R.; Abdulrahman, Adam M.; Petrovic, Mark I.; Poley, Patricia L.; Hall, Sarah P.; Kulapatana, Surat; Lamantia, Zachary E.			Incorporation of ChatGPT and Other Large Language Models into a Graduate Level Computational Bioengineering Course	CELLULAR AND MOLECULAR BIOENGINEERING			English	Editorial Material						Large language model; ChatGPT; Bard; Higher education; MATLAB		The remarkable capabilities of generative artificial intelligence and large language models (LLMs) such as ChatGPT have delighted users around the world. Educators have regarded these tools as either a cause for great concern, an opportunity to educate students on cutting-edge technology, or often some combination of the two. Throughout the Fall 2023 semester, we explored the use of ChatGPT (and Bard, among other LLMs) in a graduate level numerical and statistical methods course for PhD-level bioengineers. In this article we share examples of this ChatGPT content, our observations on what worked best in our course, and speculate on how bioengineering students may be best served by this technology in the future.	[King, Michael R.; Abdulrahman, Adam M.; Petrovic, Mark I.; Poley, Patricia L.; Hall, Sarah P.; Kulapatana, Surat; Lamantia, Zachary E.] Vanderbilt Univ, Dept Biomed Engn, Nashville, TN 37235 USA; [Abdulrahman, Adam M.; Petrovic, Mark I.] Vanderbilt Univ, Sch Med, Med Scientist Training Program, Nashville, TN USA; [Kulapatana, Surat] Mahidol Univ, Siriraj Hosp, Dept Physiol, Fac Med, Bangkok 10700, Thailand	Vanderbilt University; Vanderbilt University; Mahidol University	King, MR (corresponding author), Vanderbilt Univ, Dept Biomed Engn, Nashville, TN 37235 USA.	mike.king@vanderbilt.edu		Kulapatana, Surat/0000-0002-2564-2611; Petrovic, Mark/0000-0003-3922-3431				King M., 2023, DEV W WHEAT STEM SAW; King M., 2023, TechRxiv, DOI [10.36227/techrxiv.22517278.v1, DOI 10.36227/TECHRXIV.22517278.V1]; King M., 2023, Engineering Archive, DOI [10.31224/2974, DOI 10.31224/2974]; King M. R., 2023, BING CHATBOT FORMULA, DOI [10.31224/2937, DOI 10.31224/2937]; King MR, 2023, CELL MOL BIOENG, V16, P95, DOI 10.1007/s12195-023-00765-z; King MR, 2023, CELL MOL BIOENG, V16, P175, DOI 10.1007/s12195-023-00761-3; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; King MR., 2010, SPATIAL BIOTIC INTER, DOI [10.1017/CBO9780511780936, DOI 10.1017/CBO9780511780936]	9	1	1	18	18	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1865-5025	1865-5033		CELL MOL BIOENG	Cell. Mol. Bioeng.	FEB	2024	17	1					1	6		10.1007/s12195-024-00793-3	http://dx.doi.org/10.1007/s12195-024-00793-3		FEB 2024	6	Cell & Tissue Engineering; Biophysics; Cell Biology; Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Cell Biology; Biophysics; Engineering	IZ6P3	38435794	hybrid			2024-07-03	WOS:001158414900001
J	Lin, CS; Tsai, CN; Su, ST; Jwo, JS; Lee, CH; Wang, X				Lin, Ching-Sheng; Tsai, Chung-Nan; Su, Shao-Tang; Jwo, Jung-Sing; Lee, Cheng-Hsiung; Wang, Xin			Predictive Prompts with Joint Training of Large Language Models for Explainable Recommendation	MATHEMATICS			English	Article						large language models; recommendation systems; human-readable explanations; rating prediction task; explanation generation task; prompt engineering; predictive prompt		Large language models have recently gained popularity in various applications due to their ability to generate natural text for complex tasks. Recommendation systems, one of the frequently studied research topics, can be further improved using the capabilities of large language models to track and understand user behaviors and preferences. In this research, we aim to build reliable and transparent recommendation system by generating human-readable explanations to help users obtain better insights into the recommended items and gain more trust. We propose a learning scheme to jointly train the rating prediction task and explanation generation task. The rating prediction task learns the predictive representation from the input of user and item vectors. Subsequently, inspired by the recent success of prompt engineering, these predictive representations are served as predictive prompts, which are soft embeddings, to elicit and steer any knowledge behind language models for the explanation generation task. Empirical studies show that the proposed approach achieves competitive results compared with other existing baselines on the public English TripAdvisor dataset of explainable recommendations.	[Lin, Ching-Sheng; Su, Shao-Tang; Jwo, Jung-Sing; Lee, Cheng-Hsiung] Tunghai Univ, Master Program Digital Innovat, Taichung 40704, Taiwan; [Tsai, Chung-Nan] Lam Res Japan GK, Kanagawa 2220033, Japan; [Jwo, Jung-Sing] Tunghai Univ, Dept Comp Sci, Taichung 40704, Taiwan; [Wang, Xin] SUNY Rensselaer, Univ Albany, Dept Epidemiol & Biostat, Sch Publ Hlth, Rensselaer, NY 12144 USA	Tunghai University; Tunghai University; State University of New York (SUNY) System; State University of New York (SUNY) Albany	Lin, CS (corresponding author), Tunghai Univ, Master Program Digital Innovat, Taichung 40704, Taiwan.	cslin612@thu.edu.tw	Lee, Cheng-Hsiung/Y-6400-2019	Lee, Cheng-Hsiung/0000-0003-2782-4862	National Science and Technology Council (NSTC) of Taiwan [112-2221-E-029 -019-]	National Science and Technology Council (NSTC) of Taiwan	This work is financially supported by the National Science and Technology Council (NSTC) of Taiwan under Grant 112-2221-E-029 -019-.	Alshammari M, 2019, IEEE ACCESS, V7, P110563, DOI 10.1109/ACCESS.2019.2934633; Barkan O, 2019, RECSYS 2019: 13TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P228, DOI 10.1145/3298689.3347038; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai X., 2022, Advances in Neural Information Processing Systems, V35, P37068; Chen K, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3015, DOI 10.1109/ICASSP39728.2021.9414458; Chen ZX, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2994; Deng ZH, 2019, AAAI CONF ARTIF INTE, P61; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong L, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P623; Gao C., 2023, ACM Trans. Recomm. Syst., V1, P1, DOI [DOI 10.1145/3568022, 10.1145/3568022]; Gao JY, 2019, AAAI CONF ARTIF INTE, P3622; Geng SJ, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P244; He TY, 2018, ADV NEUR IN, V31; Hu LM, 2024, IEEE T KNOWL DATA EN, V36, P1413, DOI 10.1109/TKDE.2023.3310002; Ji J., 2023, arXiv; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Ko H, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010141; Kumar Pushpendra, 2018, International Journal of Information Technology, V10, P495, DOI 10.1007/s41870-018-0138-8; Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769; Li L, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3580488; Li L, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4947; Li PJ, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P345, DOI 10.1145/3077136.3080822; Li SJ, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3446427; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li XY, 2023, Arxiv, DOI arXiv:2304.07862; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu N, 2023, IEEE ACCESS, V11, P16994, DOI 10.1109/ACCESS.2023.3246060; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu ZM, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1036; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radlinski F, 2022, AAAI CONF ARTIF INTE, P12287; Su YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P849, DOI 10.1145/3404835.3462833; Vaswani A, 2017, ADV NEUR IN, V30; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang ZZ, 2023, Arxiv, DOI arXiv:2304.05263; Zhiyuli A, 2023, Arxiv, DOI arXiv:2305.15673	39	1	1	13	22	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	OCT	2023	11	20							4230	10.3390/math11204230	http://dx.doi.org/10.3390/math11204230			12	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	X0FY5		gold			2024-07-03	WOS:001095308400001
C	Zhang, JZ; Bao, KQ; Zhang, Y; Wang, WJ; Feng, FL; He, XN			ACM	Zhang, Jizhi; Bao, Keqin; Zhang, Yang; Wang, Wenjie; Feng, Fuli; He, Xiangnan			Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Large Language Models; Fairness; Benchmark		The remarkable achievements of Large Language Models (LLMs) have led to the emergence of a novel recommendation paradigm - Recommendation via LLM (RecLLM). Nevertheless, it is important to note that LLMs may contain social prejudices, and therefore, the fairness of recommendations made by RecLLM requires further investigation. To avoid the potential risks of RecLLM, it is imperative to evaluate the fairness of RecLLM with respect to various sensitive attributes on the user side. Due to the differences between the RecLLM paradigm and the traditional recommendation paradigm, it is problematic to directly use the fairness benchmark of traditional recommendation. To address the dilemma, we propose a novel benchmark called Fairness of Recommendation via LLM (FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset that accounts for eight sensitive attributes(1) in two recommendation scenarios: music and movies. By utilizing our FaiRLLM benchmark, we conducted an evaluation of ChatGPT and discovered that it still exhibits unfairness to some sensitive attributes when generating recommendations. Our code and dataset can be found at https://github.com/jizhi-zhang/FaiRLLM.	[Zhang, Jizhi; Bao, Keqin; Zhang, Yang; Feng, Fuli; He, Xiangnan] Univ Sci & Technol China, Hefei, Peoples R China; [Wang, Wenjie] Natl Univ Singapore, Singapore, Singapore	Chinese Academy of Sciences; University of Science & Technology of China, CAS; National University of Singapore	Feng, FL; He, XN (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	cdzhangjizhi@mail.ustc.edu.cn; baokq@mail.ustc.edu.cn; zy2015@mail.ustc.edu.cn; wenjiewang96@gmail.com; fulifeng93@gmail.com; xiangnanhe@gmail.com	Yang, Zhang/JWP-0075-2024; He, Xiangnan/G-3986-2011	He, Xiangnan/0000-0003-2838-861X; Zhang, Yang/0000-0002-7863-5183; Bao, Keqin/0009-0001-5910-0204	National Natural Science Foundation of China [62272437]; CCCD Key Lab of Ministry of Culture and Tourism	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CCCD Key Lab of Ministry of Culture and Tourism	This work is supported by the National Natural Science Foundation of China (62272437), and the CCCD Key Lab of Ministry of Culture and Tourism.	Abdollahpouri H, 2019, Arxiv, DOI arXiv:1907.13286; Abdollahpouri H, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P42, DOI 10.1145/3109859.3109912; Abdullah Malak, 2022, 2022 Ninth International Conference on Social Networks Analysis, Management and Security (SNAMS), P1, DOI 10.1109/SNAMS58071.2022.10062688; Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Ai QY, 2023, Arxiv, DOI arXiv:2307.09751; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bao Keqin, 2023, P 17 ACM C RECOMMEND; Beutel A, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2212, DOI 10.1145/3292500.3330745; BHM Custers, 2012, Privacy Observatory Magazine, V2012, P3; Biega AJ, 2018, ACM/SIGIR PROCEEDINGS 2018, P405, DOI 10.1145/3209978.3210063; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Ganguli D, 2022, Arxiv, DOI [arXiv:2209.07858, DOI 10.48550/ARXIV.2209.07858]; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Ge YQ, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P316, DOI 10.1145/3488560.3498487; Gehman S, 2020, M ASS FOR COMPUTATIO; Han J., 2022, Data mining: concepts and techniques; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Leiter C, 2023, Arxiv, DOI [arXiv:2302.13795, DOI 10.48550/ARXIV.2302.13795]; Li RZ, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P103, DOI 10.1145/3437963.3441769; Li RY, 2023, Arxiv, DOI [arXiv:2305.11700, 10.48550/arXiv.2305.11700]; Li YQ, 2023, Arxiv, DOI [arXiv:2205.13619, 10.48550/arXiv.2205.13619]; Li YQ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1054, DOI 10.1145/3404835.3462966; Li YQ, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P624, DOI 10.1145/3442381.3449866; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Moshagen M, 2012, INT J PUBLIC OPIN R, V24, P508, DOI 10.1093/ijpor/edr034; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Nguyen TT, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P677, DOI 10.1145/2566486.2568012; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Rahmani HA, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2755, DOI 10.1145/3477495.3531718; Ramos G, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102058; Tang JL, 2013, SOC NETW ANAL MIN, V3, P1113, DOI 10.1007/s13278-013-0141-9; Tomlein M, 2021, 15TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS 2021), P1, DOI 10.1145/3460231.3474241; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Valdez AC, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P123, DOI 10.1115/2959100.295915S; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wang XZ, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P436, DOI 10.1145/3437963.3441732; Wang YF, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3547333; Yuan Z, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P2639, DOI 10.1145/3539618.3591932; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu ZW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P767, DOI 10.1145/3404835.3462948	42	2	2	9	9	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							993	999		10.1145/3604915.3608860	http://dx.doi.org/10.1145/3604915.3608860			7	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ		Green Submitted			2024-07-03	WOS:001156630300113
C	Brownlee, AEI; Callan, J; Even-Mendoza, K; Geiger, A; Hanna, C; Petke, J; Sarro, F; Sobania, D		Arcaini, P; Yue, T; Fredericks, EM		Brownlee, Alexander E. I.; Callan, James; Even-Mendoza, Karine; Geiger, Alina; Hanna, Carol; Petke, Justyna; Sarro, Federica; Sobania, Dominik			Enhancing Genetic Improvement Mutations Using Large Language Models	SEARCH-BASED SOFTWARE ENGINEERING, SSBSE 2023	Lecture Notes in Computer Science		English	Proceedings Paper	15th International Symposium on Search-Based Software Engineering (SSBSE)	DEC 08, 2023	San Francisco, CA	Grand Valley State Univ		Large language models; Genetic Improvement		Large language models (LLMs) have been successfully applied to software engineering tasks, including program repair. However, their application in search-based techniques such as Genetic Improvement (GI) is still largely unexplored. In this paper, we evaluate the use of LLMs as mutation operators for GI to improve the search process. We expand the Gin Java GI toolkit to call OpenAI's API to generate edits for the JCodec tool. We randomly sample the space of edits using 5 different edit types. We find that the number of patches passing unit tests is up to 75% higher with LLM-based edits than with standard Insert edits. Further, we observe that the patches found with LLMs are generally less diverse compared to standard edits. We ran GI with local search to find runtime improvements. Although many improving patches are found by LLM-enhanced GI, the best improving patch was found by standard GI.	[Brownlee, Alexander E. I.] Univ Stirling, Stirling, Scotland; [Callan, James; Hanna, Carol; Petke, Justyna; Sarro, Federica] UCL, London, England; [Even-Mendoza, Karine] Kings Coll London, London, England; [Geiger, Alina; Sobania, Dominik] Johannes Gutenberg Univ Mainz, Mainz, Germany	University of Stirling; University of London; University College London; University of London; King's College London; Johannes Gutenberg University of Mainz	Brownlee, AEI (corresponding author), Univ Stirling, Stirling, Scotland.	alexander.brownlee@stir.ac.uk	Brownlee, Alexander Edward Ian/I-5904-2012	Brownlee, Alexander Edward Ian/0000-0003-2892-5059; Hanna, Carol/0009-0009-7386-1622; Geiger, Alina/0009-0002-3413-283X; Sobania, Dominik/0000-0001-8873-7143; Petke, Justyna/0000-0002-7833-6044; Even Mendoza, Karine/0000-0002-3099-1189	UKRI EPSRC [EP/P023991/1]; ERC [741278]	UKRI EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ERC(European Research Council (ERC))	This work was supported by the UKRI EPSRC grant no. EP/P023991/1 and the ERC advanced fellowship grant no. 741278.	[Anonymous], 2023, Artifact of Enhancing Genetic Improvement Mutations Using Large Language Models, DOI [10.5281/zenodo.8304433, DOI 10.5281/ZENODO.8304433]; Böhme M, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P117, DOI 10.1145/3106237.3106255; Brownlee AEI, 2020, IEEE C EVOL COMPUTAT, DOI 10.1109/cec48606.2020.9185708; Brownlee AEI, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P985, DOI 10.1145/3321707.3321841; Chen M., 2021, arXiv; Fan A., 2023, Large language models for software engineering: Survey and open problems; Github, Github-jcodec/jcodec: Jcodec main repo; Han S.J., 2023, Cogn. Syst. Res., V83; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Kang S, 2023, Arxiv, DOI arXiv:2304.09386; Kim D, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P802, DOI 10.1109/ICSE.2013.6606626; Kirbas S, 2021, IEEE SOFTWARE, V38, P43, DOI 10.1109/MS.2021.3071086; Marginean A, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P269, DOI 10.1109/ICSE-SEIP.2019.00039; Petke J, 2023, EMPIR SOFTW ENG, V28, DOI 10.1007/s10664-023-10344-5; Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219; Siddiq ML, 2024, Arxiv, DOI arXiv:2305.00418; Sobania D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P23, DOI 10.1109/APR59189.2023.00012; Xia CS, 2024, Arxiv, DOI arXiv:2308.04748; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385	19	2	2	3	3	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48795-8; 978-3-031-48796-5	LECT NOTES COMPUT SC			2024	14415						153	159		10.1007/978-3-031-48796-5_13	http://dx.doi.org/10.1007/978-3-031-48796-5_13			7	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5AC					2024-07-03	WOS:001157562200014
J	Valentini, G; Malchiodi, D; Gliozzo, J; Mesiti, M; Soto-Gomez, M; Cabri, A; Reese, J; Casiraghi, E; Robinson, PN				Valentini, Giorgio; Malchiodi, Dario; Gliozzo, Jessica; Mesiti, Marco; Soto-Gomez, Mauricio; Cabri, Alberto; Reese, Justin; Casiraghi, Elena; Robinson, Peter N.			The promises of large language models for protein design and modeling	FRONTIERS IN BIOINFORMATICS			English	Article						large language models; protein modeling; protein design; protein engineering; transformers; deep learning	TRANSFORMER-BASED MODELS	The recent breakthroughs of Large Language Models (LLMs) in the context of natural language processing have opened the way to significant advances in protein research. Indeed, the relationships between human natural language and the "language of proteins" invite the application and adaptation of LLMs to protein modelling and design. Considering the impressive results of GPT-4 and other recently developed LLMs in processing, generating and translating human languages, we anticipate analogous results with the language of proteins. Indeed, protein language models have been already trained to accurately predict protein properties, generate novel functionally characterized proteins, achieving state-of-the-art results. In this paper we discuss the promises and the open challenges raised by this novel and exciting research area, and we propose our perspective on how LLMs will affect protein modeling and design.	[Valentini, Giorgio; Malchiodi, Dario; Gliozzo, Jessica; Mesiti, Marco; Soto-Gomez, Mauricio; Cabri, Alberto; Casiraghi, Elena] Univ Milan, Dipartimento Informat, AnacletoLab, Milan, Italy; [Valentini, Giorgio; Casiraghi, Elena] European Lab Learning & Intelligent Syst, ELLIS, Milan, Italy; [Gliozzo, Jessica] Joint Res Ctr JRC, European Commiss, Ispra, Italy; [Reese, Justin; Casiraghi, Elena] Lawrence Berkeley Natl Lab, Environm Genom & Syst Biol Div, Berkeley, CA USA; [Robinson, Peter N.] Jackson Lab Genom Med, Farmington, CT USA	University of Milan; European Commission Joint Research Centre; EC JRC ISPRA Site; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Jackson Laboratory	Valentini, G (corresponding author), Univ Milan, Dipartimento Informat, AnacletoLab, Milan, Italy.; Valentini, G (corresponding author), European Lab Learning & Intelligent Syst, ELLIS, Milan, Italy.	valentini@di.unimi.it	; Casiraghi, Elena/M-4867-2017	Gliozzo, Jessica/0000-0001-7629-8112; Cabri, Alberto/0000-0003-1373-8402; Casiraghi, Elena/0000-0003-2024-7572	National Center for Gene Therapy and Drugs based on RNA Technology [G43C22001320007]; Office of Science, Office of Basic Energy Sciences of the U.S. Department of Energy [DE-AC02-05CH11231]; European Commission Joint Research Centre [35454]	National Center for Gene Therapy and Drugs based on RNA Technology; Office of Science, Office of Basic Energy Sciences of the U.S. Department of Energy(United States Department of Energy (DOE)); European Commission Joint Research Centre(European Union (EU)European Commission Joint Research Centre)	The authors declare financial support was received for the research, authorship, and/or publication of this article. This research was supported by the "National Center for Gene Therapy and Drugs based on RNA Technology," PNRR-NextGenerationEU program [G43C22001320007], Director, Office of Science, Office of Basic Energy Sciences of the U.S. Department of Energy Contract No. DE-AC02-05CH11231, and was realised with the collaboration of the European Commission Joint Research Centre under the Collaborative Doctoral Partnership Agreement No. 35454.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2021, MSA TRANSFORMER INT, V139; Ba JL., 2016, arXiv; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bateman A, 2023, NUCLEIC ACIDS RES, V51, pD523, DOI 10.1093/nar/gkac1052; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bibal A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3889; Bills S., 2023, OpenAI; Bommasani R., 2021, ArXiv abs/2108, P07258; Brandes N, 2022, BIOINFORMATICS, V38, P2102, DOI 10.1093/bioinformatics/btac020; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Carreira-Perpinan M. A., 2021, Corr. abs/2107, P04380; Castro E, 2022, NAT MACH INTELL, V4, P840, DOI 10.1038/s42256-022-00532-1; Collobert R, 2008, P 25 ICML, P160, DOI [10.1145/1390156.1390177, DOI 10.1145/1390156.1390177]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dyrka W, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-323; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; Ferruz N, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-32007-7; Ferruz N, 2022, NAT MACH INTELL, V4, P521, DOI 10.1038/s42256-022-00499-z; Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413; Grechishnikova D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79682-4; Heinzinger M, 2024, bioRxiv, DOI [10.1101/2023.07.23.550085, 10.1101/2023.07.23.550085, DOI 10.1101/2023.07.23.550085]; Hie BL, 2024, NAT BIOTECHNOL, V42, DOI 10.1038/s41587-023-01763-2; Hoover B, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020): SYSTEM DEMONSTRATIONS, P187; Hou J, 2018, BIOINFORMATICS, V34, P1295, DOI 10.1093/bioinformatics/btx780; Jacovi A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4198; Jastrzebski S., 2018, International conference on learning representations, V1-14; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Kokalj Enja, 2021, P EACL HACKASHOP NEW, P16; Krause B., 2017, Multiplicative lstm for sequence modelling; Krishnan R, 2022, NAT BIOMED ENG, V6, P1346, DOI 10.1038/s41551-022-00914-1; KROGH A, 1994, J MOL BIOL, V235, P1501, DOI 10.1006/jmbi.1994.1104; Li CY, 2020, TRENDS BIOTECHNOL, V38, P729, DOI 10.1016/j.tibtech.2019.12.008; Lundberg SM, 2017, ADV NEUR IN, V30; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Madsen A, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3546577; Manning CD, 2015, COMPUT LINGUIST, V41, P701, DOI 10.1162/COLI_a_00239; Mikolov T, 2013, COMPUTING RES REPOSI; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Moffat L., 2022, PREPRINT, DOI DOI 10.1101/2022.01.27.478087; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Ofer D, 2021, COMPUT STRUCT BIOTEC, V19, P1750, DOI 10.1016/j.csbj.2021.03.022; Olenyi T, 2023, PROTEIN SCI, V32, DOI 10.1002/pro.4524; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rao R., 2019, Proceedings of the 33rd international conference on neural information processing systems, P1; Ribeiro MT, 2018, AAAI CONF ARTIF INTE, P1527; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schwaller P, 2021, NAT MACH INTELL, V3, P144, DOI 10.1038/s42256-020-00284-w; Schwaller P, 2020, CHEM SCI, V11, P3316, DOI 10.1039/c9sc05704h; Keskar NS, 2019, Arxiv, DOI arXiv:1909.05858; Shuai RW, 2021, bioRxiv, DOI [10.1101/2021.12.13.472419, 10.1101/2021.12.13.472419, DOI 10.1101/2021.12.13.472419]; Shwartz-Ziv R, 2023, Arxiv, DOI arXiv:2304.09355; Socher R., 2011, P 28 INT C MACH LEAR, P129; Szczepanski M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-03100-6; Tan ZX, 2020, AI OPEN, V1, P5, DOI 10.1016/j.aiopen.2020.11.001; Unsal S, 2022, NAT MACH INTELL, V4, P227, DOI 10.1038/s42256-022-00457-9; Vaswani A, 2017, ADV NEUR IN, V30; Vig J, 2019, PROCEEDINGS OF THE 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, (ACL 2019), P37; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wenzel M, 2024, Arxiv, DOI [arXiv:2309.03631, 10.48550/arXiv.2309.03631, DOI 10.1038/S41586-023-06832-9, 10.1038/s41586-023-06832-9]; Zhou GD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P473; Zhou ZL, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad046	67	0	0	22	22	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-7647		FRONT BIOINFORM	Front. Bioinform.	NOV 23	2023	3								1304099	10.3389/fbinf.2023.1304099	http://dx.doi.org/10.3389/fbinf.2023.1304099			11	Mathematical & Computational Biology	Emerging Sources Citation Index (ESCI)	Mathematical & Computational Biology	AC1D8	38076030	Green Published, gold			2024-07-03	WOS:001116161300001
J	Nascimento, CMC; Pimentel, AS				Nascimento, Cayque Monteiro Castro; Pimentel, Andre Silva			Do Large Language Models Understand Chemistry? A Conversation with ChatGPT	JOURNAL OF CHEMICAL INFORMATION AND MODELING			English	Article							CHEMICAL LANGUAGE	Large language models (LLMs) have promised a revolution in answering complex questions using the ChatGPT model. Its application in chemistry is still in its infancy. This viewpoint addresses the question of how well ChatGPT understands chemistry by posing five simple tasks in different subareas of chemistry.	[Nascimento, Cayque Monteiro Castro; Pimentel, Andre Silva] Pontificia Univ Catoloica Rio De Janeiro, Dept Quim, BR-22451900 Rio De Janeiro, RJ, Brazil		Pimentel, AS (corresponding author), Pontificia Univ Catoloica Rio De Janeiro, Dept Quim, BR-22451900 Rio De Janeiro, RJ, Brazil.	a_pimentel@puc-rio.br	Pimentel, Andre/B-1278-2010	Pimentel, Andre/0000-0002-1301-0561; Nascimento, Cayque/0000-0003-4712-0598	research productivity fellowship - CNPq [310166/2020-9]; INCT-FCx [573560/2008-0, 465259/2014-6, 302554/2017-3]; CAPES [E-26/010.000983/2019]; FAPERJ NanoHealth Research Network [210.104/2020]; FAPERJ Program for Thematic Projects in the State of Rio de Janeiro [201.186/2022]; FAPERJ award "Scientist of Our State" [2014/50983-3];  [001]	research productivity fellowship - CNPq(Conselho Nacional de Desenvolvimento Cientifico e Tecnologico (CNPQ)); INCT-FCx; CAPES(Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior (CAPES)); FAPERJ NanoHealth Research Network(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ)); FAPERJ Program for Thematic Projects in the State of Rio de Janeiro(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ)); FAPERJ award "Scientist of Our State"(Fundacao Carlos Chagas Filho de Amparo a Pesquisa do Estado do Rio De Janeiro (FAPERJ)); 	The authors are thankful to the research productivity fellowship granted by CNPq (310166/2020-9), the INCT-FCx (CNPq Grants 573560/2008-0, 465259/2014-6, and 302554/2017-3, and FAPESP Grant 2014/50983-3), and CAPES (Finance Code 001). The authors also acknowledge the FAPERJ NanoHealth Research Network (E-26/010.000983/2019), the FAPERJ Program for Thematic Projects in the State of Rio de Janeiro (210.104/2020), and the FAPERJ award "Scientist of Our State" (201.186/2022).	[Anonymous], WHAT ARE TOKENS COUN; [Anonymous], 2020, SIMPLE GUIDE SETTING; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bird S., 2009, Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit, V1; Blanchard AE, 2022, INT J HIGH PERFORM C, V36, P587, DOI 10.1177/10943420221121804; ChatGPT, Optimizing Language models for dialogue; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Costa RKM, 2023, J BIOMOL STRUCT DYN, V41, P11510, DOI [10.1080/07391102.2023.2173298, 10.2460/javma.23.02.0067]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dunn A., 2022, arXiv; Edwards C, 2022, Arxiv, DOI [arXiv:2204.11817, DOI 10.48550/ARXIV.2204.11817]; Flam-Shepherd D, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30839-x; Fornasier F, 2020, J CHEM INF MODEL, V60, P569, DOI 10.1021/acs.jcim.9b00830; Frey Nathan, 2022, ChemRxiv; García-Valero B, 2020, BRUMAL-RES J FANTAST, V8, P17, DOI 10.5565/rev/brumal.646; Griffin S, 1999, J CHROMATOGR A, V864, P221, DOI 10.1016/S0021-9673(99)01009-2; Heaven W. D., 2022, MIT Technol. Rev; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; Horawalavithana S., 2022, P BIG SCI EP 5 WORKS; Jablonka KM., 2023, ChemRxiv; Kadajji VG, 2011, POLYMERS-BASEL, V3, P1972, DOI 10.3390/polym3041972; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kublik S., 2022, GPT3 BUILD INNOVATIV, V1; Lancashire R. J., 2020, COORDINATION NUMBERS; Lane H., 2019, NATURAL LANGUAGE PRO, V1; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pan J., 2023, Nature Computational Science, V3, P5; Rae J., DEEP MIND; Ross J, 2022, NAT MACH INTELL, V4, DOI 10.1038/s42256-022-00580-7; Ross J, 2021, Arxiv, DOI [arXiv:2106.09553, 10.48550/arXiv.2106.09553, DOI 10.48550/ARXIV.2106.09553]; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Souza LMP, 2020, J MOL LIQ, V319, DOI 10.1016/j.molliq.2020.114132; Srivastava Aarohi, 2022, arXiv; Symmetry and Point Groups, US; Taylor R, 2022, arXiv; Tunstall L., 2022, NATURAL LANGUAGE PRO, V1; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vilas-Boas SM, 2022, IND ENG CHEM RES, V61, P3154, DOI 10.1021/acs.iecr.1c04196; Wang S, 2019, ACM-BCB'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, P429, DOI 10.1145/3307339.3342186; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wen NF, 2022, J CHEMINFORMATICS, V14, DOI 10.1186/s13321-022-00650-3; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Yoshimori A, 2023, FUTURE MED CHEM, V15, P119, DOI 10.4155/fmc-2022-0315	44	29	29	45	220	AMER CHEMICAL SOC	WASHINGTON	1155 16TH ST, NW, WASHINGTON, DC 20036 USA	1549-9596	1549-960X		J CHEM INF MODEL	J. Chem Inf. Model.	MAR 27	2023	63	6					1649	1655		10.1021/acs.jcim.3c00285	http://dx.doi.org/10.1021/acs.jcim.3c00285		MAR 2023	7	Chemistry, Medicinal; Chemistry, Multidisciplinary; Computer Science, Information Systems; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy; Chemistry; Computer Science	C0VP2	36926868				2024-07-03	WOS:000952520500001
J	Piktus, A				Piktus, Aleksandra			Online tools help large language models to solve problems through reasoning	NATURE			English	Editorial Material						Computer science; Machine learning; Technology		The large language models popularized by chatbots are being taught to alternate reasoning with calls to external tools, such as Wikipedia, to boost their accuracy. The strategy could improve fact-finding outcomes, as well as online shopping.	[Piktus, Aleksandra] Hugging Face, New York, NY 11201 USA		Piktus, A (corresponding author), Hugging Face, New York, NY 11201 USA.	ola.piktus@gmail.com						Brown T. B., 2020, Adv. Neural Inf. Process. Syst.; Schick T., 2023, PREPRINT; Wei J., 2022, PREPRINT; Yao S., 2022, PREPRINT	4	1	1	12	27	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JUN 15	2023	618	7965					465	466		10.1038/d41586-023-01411-4	http://dx.doi.org/10.1038/d41586-023-01411-4		MAY 2023	2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	X8VW6	37127699				2024-07-03	WOS:000981228800001
C	Li, H; Tran, D; Zhang, XY; He, HS			IEEE	Li, Hui; Tran, Dang; Zhang, Xinyu; He, Hongsheng			Knowledge Augmentation and Task Planning in Large Language Models for Dexterous Grasping	2023 IEEE-RAS 22ND INTERNATIONAL CONFERENCE ON HUMANOID ROBOTS, HUMANOIDS	IEEE-RAS International Conference on Humanoid Robots		English	Proceedings Paper	IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids)	DEC 12-14, 2023	Austin, TX	IEEE RAS			DESIGN	Dexterous grasping is a critical ability for humanoid robots to interact efficiently with the physical environment. Human beings achieve dexterous grasping through a series of high level cognitive processes including target perception, object recognition, feature estimation, and intuitive reasoning. These processes cooperatively contribute to object understanding and the generation of appropriate grasping strategies. However, the current research focuses on establishing large object datasets to estimate object features and employing learning and planning approaches for task deployment, the exploration of the cognitive aspect of dexterous grasping is limited, especially the role of intuition. This paper addresses this research gap by investigating the cognitive processes in dexterous grasping and presents a cognition based grasping system. The proposed system integrates various cognitive processes to enable dexterous grasping. It gathers object information and estimates missing details using a large language model with common sense. Based on the complemented information, the system learns suitable grasp strategies and intuitively guides their execution. Real-world experiments with a anthropomorphic robot hand demonstrated the performance of the proposed system. By leveraging cognitive processes and utilizing the capabilities of a large language model, The proposed method enhances object understanding, generates effective grasping strategies, and provides guidance for the execution of the grasping strategies.						Jiang, Huaizu/0000-0002-2300-4237				Bian N, 2024, Arxiv, DOI arXiv:2303.16421; Chen F, 2019, IEEE T IND INFORM, V15, P1202, DOI 10.1109/TII.2018.2879426; Choi Y, 2020, J HOSP MARKET MANAG, V29, P613, DOI 10.1080/19368623.2020.1703871; CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763; Della Santina C, 2019, IEEE ROBOT AUTOM LET, V4, P1533, DOI 10.1109/LRA.2019.2896485; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Feix T, 2016, IEEE T HUM-MACH SYST, V46, P66, DOI 10.1109/THMS.2015.2470657; Feix T, 2014, IEEE T HAPTICS, V7, P311, DOI 10.1109/TOH.2014.2326871; Fernandez-Rojas R, 2019, IEEE ACCESS, V7, P33304, DOI 10.1109/ACCESS.2019.2902812; Indri M, 2018, IEEE T IND INFORM, V14, P1677, DOI 10.1109/TII.2018.2809000; Johansson RS, 2009, NAT REV NEUROSCI, V10, P345, DOI 10.1038/nrn2621; Li H, 2021, IEEE INT CONF ROBOT, P6192, DOI 10.1109/ICRA48506.2021.9562073; Li H, 2020, IEEE INT CONF ROBOT, P9895, DOI [10.1109/icra40945.2020.9196538, 10.1109/ICRA40945.2020.9196538]; Li H, 2018, LECT NOTES ARTIF INT, V11357, P523, DOI 10.1007/978-3-030-05204-1_51; Li M, 2016, ROBOT AUTON SYST, V75, P352, DOI 10.1016/j.robot.2015.09.008; NAPIER JR, 1956, J BONE JOINT SURG BR, V38, P902, DOI 10.1302/0301-620X.38B4.902; Papadopoulos I, 2020, COMPUT EDUC, V155, DOI 10.1016/j.compedu.2020.103924; Papadopoulos I, 2020, BMJ OPEN, V10, DOI 10.1136/bmjopen-2019-033096; Rao Achyutha Bharath, 2019, 2019 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1368, DOI 10.1109/ROBIO49542.2019.8961482; Rao AB, 2018, IEEE INT C INT ROBOT, P882, DOI 10.1109/IROS.2018.8593886; Rao BR, 2020, Arxiv, DOI arXiv:2011.08361; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Yu XB, 2022, IEEE T CYBERNETICS, V52, P13237, DOI 10.1109/TCYB.2021.3107357	23	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2164-0572		979-8-3503-0327-8	IEEE-RAS INT C HUMAN			2023										10.1109/HUMANOIDS57100.2023.10375176	http://dx.doi.org/10.1109/HUMANOIDS57100.2023.10375176			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Engineering, Electrical & Electronic; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering; Robotics	BW4YC					2024-07-03	WOS:001156965200037
C	Hou, YP; Zhang, JJ; Lin, ZH; Lu, HY; Xie, RB; McAuley, J; Zhao, WX		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Hou, Yupeng; Zhang, Junjie; Lin, Zihan; Lu, Hongyu; Xie, Ruobing; McAuley, Julian; Zhao, Wayne Xin			Large Language Models are Zero-Shot Rankers for Recommender Systems	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Large Language Model; Recommender System		Recently, large language models (LLMs) (e.g., GPT-4) have demonstrated impressive general-purpose task-solving abilities, including the potential to approach recommendation tasks. Along this line of research, this work aims to investigate the capacity of LLMs that act as the ranking model for recommender systems. We first formalize the recommendation problem as a conditional ranking task, considering sequential interaction histories as conditions and the items retrieved by other candidate generation models as candidates. To solve the ranking task by LLMs, we carefully design the prompting template and conduct extensive experiments on two widely-used datasets. We show that LLMs have promising zero-shot ranking abilities but (1) struggle to perceive the order of historical interactions, and (2) can be biased by popularity or item positions in the prompts. We demonstrate that these issues can be alleviated using specially designed prompting and bootstrapping strategies. Equipped with these insights, zero-shot LLMs can even challenge conventional recommendation models when ranking candidates are retrieved by multiple candidate generators. The code and processed datasets are available at https://github.com/RUCAIBox/LLMRank.	[Hou, Yupeng; Zhang, Junjie; Zhao, Wayne Xin] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China; [Hou, Yupeng; McAuley, Julian] Univ Calif San Diego, San Diego, CA USA; [Lin, Zihan] Renmin Univ China, Sch Informat, Beijing, Peoples R China; [Lu, Hongyu; Xie, Ruobing] Tencent, WeChat, Shenzhen, Peoples R China	Renmin University of China; University of California System; University of California San Diego; Renmin University of China; Tencent	Zhao, WX (corresponding author), Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing, Peoples R China.	yphou@ucsd.edu; junjie.zhang@ruc.edu.cn; batmanfly@gmail.com			National Natural Science Foundation of China [62222215]; Beijing Natural Science Foundation [L233008, 4222027]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Natural Science Foundation(Beijing Natural Science Foundation)	This work was partially supported by National Natural Science Foundation of China under Grant No. 62222215, Beijing Natural Science Foundation under Grant No. L233008 and 4222027.	Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Barkan O., 2016, P IEEE 26 INT WORKSH, P1; Bonab H, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P110, DOI 10.1145/3459637.3482493; Cao D, 2017, ACM T INFORM SYST, V35, DOI 10.1145/3017429; Chen JW, 2021, Arxiv, DOI [arXiv:2010.03240, DOI 10.48550/ARXIV.2010.03240]; Chen J, 2023, Arxiv, DOI arXiv:2307.16376; Chen L, 2023, IEEE T KNOWL DATA EN, V35, P3239, DOI 10.1109/TKDE.2021.3119619; Cheng MY, 2021, IEEE DATA MINING, P51, DOI 10.1109/ICDM51629.2021.00015; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190; Cui Q., 2020, CEUR WORKSHOP P, V2715; Cui Z., 2022, arXiv; Dai SH, 2023, Arxiv, DOI arXiv:2305.02182; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding H., 2021, arXiv; Fu JC, 2023, Arxiv, DOI [arXiv:2305.15036, 10.48550/arXiv.2305.15036]; Gao C, 2023, IEEE T KNOWL DATA EN, V35, P1351, DOI 10.1109/TKDE.2021.3098702; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Geng SJ, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P299, DOI 10.1145/3523227.3546767; Grbovic M, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P311, DOI 10.1145/3219819.3219885; Guo QY, 2022, IEEE T KNOWL DATA EN, V34, P3549, DOI 10.1109/TKDE.2020.3028705; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; He RN, 2017, PROCEEDINGS OF THE ELEVENTH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'17), P161, DOI 10.1145/3109859.3109882; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; He ZK, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P720, DOI 10.1145/3583780.3614949; Hou Y., 2023, WWW; Hou YP, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P585, DOI 10.1145/3534678.3539381; Hua WY, 2023, Arxiv, DOI arXiv:2305.06569; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Kang WC, 2018, IEEE DATA MINING, P197, DOI 10.1109/ICDM.2018.00035; Knuth D. E., 1977, SIAM Journal on Computing, V6, P323, DOI 10.1137/0206024; Li J., 2023, Gpt4rec: A generative framework for personalized recommendation and user interests interpretation; Li L, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3580488; Li RY, 2023, Arxiv, DOI [arXiv:2305.11700, 10.48550/arXiv.2305.11700]; Li XY, 2023, Arxiv, DOI arXiv:2304.07862; Lin G, 2023, Arxiv, DOI arXiv:2305.04518; Liu J., 2023, Is ChatGPT a good recommender? a preliminary study; Liu P, 2023, Arxiv, DOI [arXiv:2302.03735, 10.48550/arXiv.2302.03735, DOI 10.48550/ARXIV.2302.03735]; Liu QJ, 2023, Arxiv, DOI arXiv:2305.06566; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Man T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2464; Ni JM, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P188; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Ren XB, 2024, Arxiv, DOI arXiv:2310.15950; Rendle S., 2012, Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence (UAI2009), DOI [DOI 10.5555/1795114.1795167, 10.48550/arXiv.1205.2618]; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Roitero K, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P694, DOI 10.1145/3366424.3384362; Sanh Victor, 2022, ICLR; Shin K, 2022, Arxiv, DOI arXiv:2111.11294; Tang JX, 2018, WSDM'18: PROCEEDINGS OF THE ELEVENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P565, DOI 10.1145/3159652.3159656; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Tikk D., 2016, C TRACK P; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang J, 2022, Arxiv, DOI arXiv:2206.06190; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wang XL, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1929, DOI 10.1145/3534678.3539382; Wang YC, 2024, Arxiv, DOI arXiv:2308.14296; Wei Jason, 2022, Finetuned language models are zero-shot learners; Wei W, 2024, PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024, P806, DOI 10.1145/3616855.3635853; Wu LK, 2024, Arxiv, DOI arXiv:2305.19860; Xiao ST, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P4215, DOI 10.1145/3534678.3539120; Yuan FJ, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P1469, DOI 10.1145/3397271.3401156; Yuan FJ, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P696, DOI 10.1145/3404835.3462884; Zang TZ, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3548455; Zhang JZ, 2023, Arxiv, DOI arXiv:2305.07609; Zhang JJ, 2023, Arxiv, DOI arXiv:2310.09233; Zhang JJ, 2023, Arxiv, DOI arXiv:2305.07001; Zhang ZZ, 2023, Arxiv, DOI arXiv:2304.05263; Zhao C, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P229, DOI 10.1145/3397271.3401169; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhao WX, 2023, ACM T INFORM SYST, V41, DOI 10.1145/3545796; Zhao WX, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4653, DOI 10.1145/3459637.3482016; Zhao ZH, 2024, Arxiv, DOI arXiv:2307.02046; Zheng BW, 2024, Arxiv, DOI arXiv:2311.09049; Zhou K, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1893, DOI 10.1145/3340531.3411954; Zhu F., 2021, P 13 INT JOINT C ART, P4721; Zhu F, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3001; Zhu F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1533, DOI 10.1145/3357384.3357992; Zhu YC, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1507, DOI 10.1145/3488560.3498392	84	0	0	12	12	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						364	381		10.1007/978-3-031-56060-6_24	http://dx.doi.org/10.1007/978-3-031-56060-6_24			18	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY		Green Submitted			2024-07-03	WOS:001211832000024
J	Al Rawi, ZM; Kirby, BJ; Albrecht, PA; Nuelle, JAV; London, DA				Al Rawi, Zayd M.; Kirby, Benjamin J.; Albrecht, Peter A.; Nuelle, Julia A. V.; London, Daniel A.			Experimenting With the New Frontier: Artificial Intelligence-Powered Chat Bots in Hand Surgery	HAND-AMERICAN ASSOCIATION FOR HAND SURGERY			English	Article; Early Access						artificial intelligence; hand surgery; large language models; patient safety; chatbot	HEALTH INFORMATION	Background: Increased utilization of artificial intelligence (AI)-driven search and large language models by the lay and medical community requires us to evaluate the accuracy of AI responses to common hand surgery questions. We hypothesized that the answers to most hand surgery questions posed to an AI large language model would be correct. Methods: Using the topics covered in Green's Operative Hand Surgery 8th Edition as a guide, 56 hand surgery questions were compiled and posed to ChatGPT (OpenAI, San Francisco, CA). Two attending hand surgeons then independently reviewed ChatGPT's answers for response accuracy, completeness, and usefulness. A Cohen's kappa analysis was performed to assess interrater agreement. Results: An average of 45 of the 56 questions posed to ChatGPT were deemed correct (80%), 39 responses were deemed useful (70%), and 32 responses were deemed complete (57%) by the reviewers. Kappa analysis demonstrated "fair to moderate" agreement between the two raters. Reviewers disagreed on 11 questions regarding correctness, 16 questions regarding usefulness, and 19 questions regarding completeness. Conclusions: Large language models have the potential to both positively and negatively impact patient perceptions and guide referral patterns based on the accuracy, completeness, and usefulness of their responses. While most responses fit these criteria, more precise responses are needed to ensure patient safety and avoid misinformation. Individual hand surgeons and surgical societies must understand these technologies and interface with the companies developing them to provide our patients with the best possible care.	[Al Rawi, Zayd M.] Univ Missouri, Sch Med, Columbia, MO 65212 USA; [Kirby, Benjamin J.] Univ Missouri Hlth Care, Dept Surg, 1 Hosp Dr, Columbia, MO 65212 USA; [Albrecht, Peter A.] ClosedLoop, Austin, TX USA; [Nuelle, Julia A. V.; London, Daniel A.] Univ Missouri Hlth Care, Dept Orthopaed, Columbia, MO 65212 USA	University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia; University of Missouri System; University of Missouri Columbia	Kirby, BJ (corresponding author), Univ Missouri Hlth Care, Dept Surg, 1 Hosp Dr, Columbia, MO 65212 USA.	bjknfk@umsystem.edu		London, Daniel/0000-0002-1711-0762				Amisha, 2019, J FAM MED PRIM CARE, V8, P2328, DOI 10.4103/jfmpc.jfmpc_440_19; Bulstra AEJ, 2022, J HAND SURG-AM, V47, pE14, DOI 10.1016/j.jhsa.2022.02.023; chat.openai.com, 2023, Market share, revenue, and traffic analytics; Cutilli CC, 2010, ORTHOP NURS, V29, P214, DOI 10.1097/NOR.0b013e3181db5471; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; ElHawary H., 2023, Plast Reconstr Surg Glob Open, V11; Fahy E, 2014, AUSTRALAS MED J, V7, P24, DOI 10.4066/AMJ.2014.1900; Fanuele J, 2009, J BONE JOINT SURG AM, V91A, P1313, DOI 10.2106/JBJS.H.00448; Hackbarth G, 2003, INFORM MANAGE-AMSTER, V40, P221, DOI 10.1016/S0378-7206(02)00006-X; Harrison CJ., 2022, Plast Reconstr Surg Glob Open, V10; Hendrix N, 2021, RADIOL-ARTIF INTELL, V3, DOI 10.1148/ryai.2021200260; Hoogendam L, 2022, NEUROSURGERY, V90, P106, DOI 10.1227/NEU.0000000000001749; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040; Kleesiek J, 2023, J NUCL MED, V64, P701, DOI 10.2967/jnumed.123.265687; Kunze KN, 2023, BONE JOINT J, V105B, P587, DOI 10.1302/0301-620X.105B6.BJJ-2023-0156; Kuo RYL, 2022, RADIOLOGY, V304, P50, DOI 10.1148/radiol.211785; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu DW, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22166092; Olczak J, 2017, ACTA ORTHOP, V88, P581, DOI 10.1080/17453674.2017.1344459; Parsa A, 2023, ARCH BONE JT SURG-AB, V11, P225, DOI 10.22038/abjs.2023.22042; Saravia E., 2022, Prompt engineering guide 2022; Seth I, 2023, J HAND SURG-EUR VOL, V48, P814, DOI 10.1177/17531934231169858; Swoboda CM, 2018, BMC FAM PRACT, V19, DOI 10.1186/s12875-018-0805-7; Üreten K, 2022, ULUS TRAVMA ACIL CER, V28, P196, DOI 10.14744/tjtes.2020.06944; Weidman AA, 2023, PLAST RECONSTR SURG, V151, P1111, DOI 10.1097/PRS.0000000000010342; Wolfe SW., 2021, Greens Operative Hand Surgery	27	1	1	3	3	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1558-9447	1558-9455		HAND-AM ASSOC HAND S	Hand-Am. Assoc. Hand Surg.	2024 MAR 25	2024										10.1177/15589447241238372	http://dx.doi.org/10.1177/15589447241238372		MAR 2024	6	Orthopedics; Surgery	Emerging Sources Citation Index (ESCI)	Orthopedics; Surgery	LX6U4	38525794				2024-07-03	WOS:001190158200001
C	Terron, GA; Chozas, PM; Doncel, VR		Spanakis, J; VanDijck, G; Sileno, G		Terron, Gabriela Arguelles; Chozas, Patricia Martin; Doncel, Victor Rodriguez			Event Extraction and Semantic Representation from Spanish Workers' Statute Using Large Language Models	LEGAL KNOWLEDGE AND INFORMATION SYSTEMS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	36th Annual International Conference on Legal Knowledge and Information Systems (JURIX)	DEC 18-20, 2023	Maastricht Univ, Maastricht, NETHERLANDS	JURIX Fdn Legal Knowledge Based Syst	Maastricht Univ	Spanish Workers' Statute; Large Language Models; Knowledge Graph; Legal Domain; Event Extraction		This work uses Large Language Models to process an important piece of Spanish legislation: the Workers' Statute. The proposed method extracts the relevant events in its articles using a GPT-3.5 model and represents the entities involved in the events and the relationships between them as RDF triples. The experiments carried out to select a high-performance strategy include both zero- and few-shot learning tests. Finally, this work proposes a strategy to uplift the extracted legal relations into a legal knowledge graph.	[Terron, Gabriela Arguelles; Chozas, Patricia Martin; Doncel, Victor Rodriguez] Univ Politecn Madrid, Madrid, Spain	Universidad Politecnica de Madrid	Terron, GA (corresponding author), Univ Politecn Madrid, Madrid, Spain.				EU [813497]	EU(European Union (EU))	Projects Knowledge Spaces (10.13039/501100011033), the EU H2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 813497 (PROTECT) and Infraestructura para la Investigacion de Espacios de Datos distribuidos en UPM (INESData).	Berners-Lee T, 2001, SCI AM, V284, P34, DOI 10.1038/scientificamerican0501-34; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Feng Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P648; Francesconi E, 2016, SEMANT WEB, V7, P255, DOI 10.3233/SW-140150; Gutierrez-Fandino A, 2021, Arxiv, DOI arXiv:2110.12201; Hohfeld WN, 1917, YALE LAW J, V26, P710, DOI 10.2307/786270; Jettakul A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-3217-3; Martin Chozas P, 2018, Towards a Linked Open Data Cloud of language resources in the legal domain; Revenko A, 2022, PROCES LENG NAT, P105, DOI 10.26342/2022-69-9; Shen S, arXiv; Tara A, 2013, Legal RuleML: from Metamodel to Use Cases-A Tutorial. RuleML2013-Theory, Practice, and Applications of Rules on the Web, P1; Veyseh A.P.B., 2021, P 59 ANN M ASS COMPU, P6271; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Zhu H, 2019, Arxiv, DOI arXiv:1902.00756	15	0	0	5	5	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-472-7; 978-1-64368-473-4	FRONT ARTIF INTEL AP			2023	379						329	334		10.3233/FAIA230983	http://dx.doi.org/10.3233/FAIA230983			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Information Science & Library Science; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science; Government & Law	BW6JJ		hybrid			2024-07-03	WOS:001175464100043
C	Bendersky, M; Li, C; Mei, QZ; Murdock, V; Tang, J; Wang, HN; Zamani, H; Zhang, MY			Assoc computing machinery	Bendersky, Michael; Li, Cheng; Mei, Qiaozhu; Murdock, Vanessa; Tang, Jie; Wang, Hongning; Zamani, Hamed; Zhang, Mingyang			WSDM 2024 Workshop on Large Language Models for Individuals, Groups, and Society	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD				This workshop discusses the cutting-edge developments in research and applications of personalizing large language models (LLMs) and adapting them to the demands of diverse user populations and societal needs. The full-day workshop includes several keynotes and invited talks, a poster session and a panel discussion.	[Bendersky, Michael; Li, Cheng; Zhang, Mingyang] Google Res, Mountain View, CA 94043 USA; [Mei, Qiaozhu] Univ Michigan, Ann Arbor, MI 48109 USA; [Murdock, Vanessa] Amazon Res, Seattle, WA USA; [Tang, Jie] Tsinghua Univ, Beijing, Peoples R China; [Wang, Hongning] Univ Virginia, Charlottesville, VA USA; [Zamani, Hamed] Univ Massachusetts Amherst, Amherst, MA USA	Google Incorporated; University of Michigan System; University of Michigan; Tsinghua University; University of Virginia; University of Massachusetts System; University of Massachusetts Amherst	Bendersky, M (corresponding author), Google Res, Mountain View, CA 94043 USA.	bemike@google.com; chgli@google.com; qmei@umich.edu; vmurdock@amazon.com; jietang@tsinghua.edu.cn; hw5x@virginia.edu; zamani@cs.umass.edu; mingyang@google.com		Mei, Qiaozhu/0000-0002-8640-1942; Zamani, Hamed/0000-0002-0800-3340; Li, Cheng/0000-0003-0678-1357				Liu Ruibo, 2022, FINDINGS ASS COMPUTA, P241	1	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1206	1207		10.1145/3616855.3635726	http://dx.doi.org/10.1145/3616855.3635726			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100170
J	Frank, MC				Frank, Michael C.			Baby steps in evaluating the capacities of large language models	NATURE REVIEWS PSYCHOLOGY			English	Editorial Material								Large language models show remarkable capacities, but it is unclear what abstractions support their behaviour. Methods from developmental psychology can help researchers to understand the representations used by these models, complementing standard computational approaches - and perhaps leading to insights about the nature of mind.	[Frank, Michael C.] Stanford Univ, Dept Psychol, Stanford, CA 94305 USA	Stanford University	Frank, MC (corresponding author), Stanford Univ, Dept Psychol, Stanford, CA 94305 USA.	mcfrank@stanford.edu		Frank, Michael/0000-0002-7551-4378				[Anonymous], 1998, The Evolution of Mind'; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Davidson K, 2012, COGNITION, V123, P162, DOI 10.1016/j.cognition.2011.12.013; Geiger A., 2021, Advances in Neural Information Processing Systems, V34, P9574; Geiger A, 2023, PSYCHOL REV, V130, P308, DOI 10.1037/rev0000371; Kominsky JF, 2022, COGNITIVE DEV, V63, DOI 10.1016/j.cogdev.2022.101213; Liu S, 2017, SCIENCE, V358, P1038, DOI 10.1126/science.aag2132; Ruffman T, 2002, CHILD DEV, V73, P734, DOI 10.1111/1467-8624.00435; Saffran JR, 1996, SCIENCE, V274, P1926, DOI 10.1126/science.274.5294.1926; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]	10	9	9	4	4	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2731-0574		NAT REV PSYCHOL	Nat. Rev. Psychol.	AUG	2023	2	8					451	452		10.1038/s44159-023-00211-x	http://dx.doi.org/10.1038/s44159-023-00211-x			2	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	CN7I5		Green Submitted			2024-07-03	WOS:001125989800006
J	Fink, MA				Fink, Matthias A.			Large language models such as ChatGPT and GPT-4 for patient-centered care in radiology	RADIOLOGIE			German	Article						Artificial Intelligence; Natural Language Processing; Machine Learning; Deep Learning; Patient-centred approach		Background: With the introduction of ChatGPT in late November 2022, large language models based on artificial intelligence have gained worldwide recognition. These language models are trained on vast amounts of data, enabling them to process complex tasks in seconds and provide detailed, high-level text-based responses. Objective: To provide an overview of the most widely discussed large language models, ChatGPT and GPT-4, with a focus on potential applications for patient-centered radiology. Materials and methods: A PubMed search of both large language models was performed using the terms "ChatGPT" and "GPT-4", with subjective selection and completion in the form of a narrative review. Results: The generic nature of language models holds great promise for radiology, enabling both patients and referrers to facilitate understanding of radiological findings, overcome language barriers, and improve the quality of informed consent discussions. This could represent a significant step towards patient-centered or person-centered radiology. Conclusion: Large language models represent a promising tool for improving the communication of findings, interdisciplinary collaboration, and workflow in radiology. However, important privacy issues and the reliable applicability of these models in medicine remain to be addressed.	[Fink, Matthias A.] Univ Klinikum Heidelberg, Klin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany	Ruprecht Karls University Heidelberg	Fink, MA (corresponding author), Univ Klinikum Heidelberg, Klin Diagnost & Intervent Radiol, Neuenheimer Feld 420, D-69120 Heidelberg, Germany.	matthias.fink@uni-heidelberg.de						Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; [Anonymous], 2023, Vorsicht: Der Einsatz von ChatGPT verstosst aktuell gegen den Datenschutz; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Biswas SS, 2023, PEDIATR RADIOL, DOI 10.1007/s00247-023-05675-w; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Dendl LM, 2017, ROFO-FORTSCHR RONTG, V189, P239, DOI 10.1055/s-0042-118884; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fink MA, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220055; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hopkins AM, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad010; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; LEEMING BW, 1981, RADIOLOGY, V138, P585, DOI 10.1148/radiology.138.3.7465833; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Nagrani A, 2022, Arxiv, DOI arXiv:2107.00135; openai, INTR CHATGPT; Perlis N, 2021, CUAJ-CAN UROL ASSOC, V15, P108, DOI 10.5489/cuaj.6585; seo, How many languages does ChatGPT support? The complete chatGPT language list; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Wagner MW, 2024, CAN ASSOC RADIOL J, V75, P69, DOI 10.1177/08465371231171125	22	1	1	2	6	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2731-7048	2731-7056		RADIOLOGIE	Radiologie	SEP	2023	63	9					665	671		10.1007/s00117-023-01187-8	http://dx.doi.org/10.1007/s00117-023-01187-8			7	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	LR3Y3	37615692				2024-07-03	WOS:001188501800005
J	Karlsen, E; Luo, X; Zincir-Heywood, N; Heywood, M				Karlsen, Egil; Luo, Xiao; Zincir-Heywood, Nur; Heywood, Malcolm			Large language models and unsupervised feature learning: implications for log analysis	ANNALS OF TELECOMMUNICATIONS			English	Article; Early Access						Log analysis; Large language models; Unsupervised learning		Log file analysis is increasingly being addressed through the use of large language models (LLM). LLM provides the mechanism for discovering embeddings for distinguishing between different behaviors present in log files. In this work, we are interested in discriminating between normal and anomalous behaviors via an unsupervised learning approach. To this end, firstly five recent LLM architectures are evaluated over six different log files. Then, further research is conducted to explicitly quantify the significance of performing self-supervised fine-tuning on the LLMs. Moreover, we show that the quality of an (unsupervised) feature map used to make the overall (normal/anomalous) predictions may also benefit from an AutoEncoder stage between LLM and feature map. Such an AutoEncoder provides significant reductions in the cost of training the feature map and typically improves the quality of the resulting predictions.	[Karlsen, Egil; Zincir-Heywood, Nur; Heywood, Malcolm] Dalhousie Univ, Fac Comp Sci, 6050 Univ Ave, Halifax, NS B3H 1W5, Canada; [Luo, Xiao] Oklahoma State Univ, Dept Management Sci & Informat Syst, 370 Business Bldg, Stillwater, OK 74078 USA	Dalhousie University; Oklahoma State University System; Oklahoma State University - Stillwater	Karlsen, E (corresponding author), Dalhousie Univ, Fac Comp Sci, 6050 Univ Ave, Halifax, NS B3H 1W5, Canada.	egil.karlsen@dal.ca; xiao.luo@okstate.edu; zincir@cs.dal.ca; mheywood@cs.dal.ca			Natural Sciences and Engineering Research Council of Canada	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR)	This research is supported partially by the Natural Sciences and Engineering Research Council of Canada. The research is conducted as part of the Dalhousie NIMS Lab:https://projects.cs.dal.ca/projectx/.	Abadi M., 2015, TENSORFLOW LARGE SCA; [Anonymous], 2018, MiniSom: Minimalistic and NumPy-Based Implementation of the Self Organizing Map; Black Sid, 2021, Zenodo; Copstein R, 2022, IT-INF TECHNOL, V64, P15, DOI 10.1515/itit-2021-0064; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; ECML/PKDD, 2021, ECML/PKDD 2007 Discovery Challenge; Farzad A., 2021, Log Message Anomaly Detection and Classification Using Auto-B/LSTM and Auto-GRU; Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042; Guo H., 2021, LogBERT: log anomaly detection via BERT, P1; Hilmi MAA., 2020, IEEE Dataport, DOI DOI 10.21227/VVVQ-6W47; Karlsen E, 2023, 2023 7 CYBER SECURIT, P219, DOI [10.1109/CSNet59123.2023.10339765, DOI 10.1109/CSNET59123.2023.10339765]; Kayacik HG, 2007, ENG APPL ARTIF INTEL, V20, P439, DOI 10.1016/j.engappai.2006.09.005; Kohonen T, 1998, NEUROCOMPUTING, V21, P1, DOI 10.1016/S0925-2312(98)00030-7; Kohonen T, 2000, IEEE T NEURAL NETWOR, V11, P574, DOI 10.1109/72.846729; Lee Y, 2023, LAnoBERT: system log anomaly detection based on BERT masked language model; Liu XQ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2286; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mosbach M, 2021, On the stability of fine-tuning BERT: misconceptions, explanations, and strong baselines; Nam S, 2022, INT CONF NETW SER, P331, DOI 10.23919/CNSM55787.2022.9965187; No G, 2023, RAPID: training-free retrieval-based log anomaly detection with PLM considering token-level information; Oliner A, 2007, I C DEPEND SYS NETWO, P575, DOI 10.1109/DSN.2007.103; Paszke A, 2019, ADV NEUR IN, V32; Qi JX, 2022, IEEE IFIP NETW OPER, DOI 10.1109/NOMS54207.2022.9789917; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rostamizadeh A., 2012, FDN MACHINE LEARNING; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schuster M, 2012, INT CONF ACOUST SPEE, P5149, DOI 10.1109/ICASSP.2012.6289079; Shao Yangyi, 2022, 2022 7th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)., P161, DOI 10.1109/ICCCBDA55098.2022.9778900; Vartouni AM, 2019, IET INFORM SECUR, V13, P352, DOI 10.1049/iet-ifs.2018.5404; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zaker Farzin, 2019, HarvardDataverse, V1	32	0	0	5	5	SPRINGER INT PUBL AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0003-4347	1958-9395		ANN TELECOMMUN	Ann. Telecommun.	2024 APR 4	2024										10.1007/s12243-024-01028-2	http://dx.doi.org/10.1007/s12243-024-01028-2		APR 2024	19	Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Telecommunications	MX2N2					2024-07-03	WOS:001196870500002
C	Trichopoulos, G			ACM	Trichopoulos, Georgios			Large Language Models for Cultural Heritage	2ND INTERNATIONAL CONFERENCE OF THE GREECE ACM SIGCHI CHAPTER, CHIGREECE 2023			English	Proceedings Paper	2nd International Conference of the Greece-ACM-SIGCHI-Chapter (CHIGreece)	SEP 27-28, 2023	Athens, GREECE	Greece ACM SIGCHI Chapter		museum; artificial intelligence; generative pre-trained transformers; digital storytelling; emergent storytelling; cultural heritage; smart glasses; ubiquitous systems	SYSTEM	This research explores the potential applications of Generative Pretrained Transformer (GPT) by OpenAI, a Large Language Model (LLM), in the realm of cultural heritage. It investigates GPT's role as a digital storytelling machine that can be trained and guided to act as a museum guide and a recommender system for cultural spaces. LLM's advanced language understanding capabilities make it an interactive guide, providing personalized and information to visitors about artworks and historical contexts. As a recommender system, GPT can offer tailored suggestions based on user preferences and past interactions, enhancing the visitor experience and encouraging exploration. It is a system extremely capable in handling language and with that power, it can act as a digital storytelling machine, creating immersive narratives that bring exhibits to life by weaving historical information with imaginative elements. The paper presents experiment results and evaluations, highlighting GPT's potential to revolutionize visitor engagement in cultural spaces. However, ethical considerations and challenges associated with large language models in cultural contexts are also addressed, emphasizing the need for thoughtful implementation and ongoing evaluation to ensure inclusivity and accuracy while preserving cultural integrity.	[Trichopoulos, Georgios] Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece	University of Aegean	Trichopoulos, G (corresponding author), Univ Aegean, Dept Cultural Technol & Commun, Mitilini, Greece.	gtricho@aegean.gr		Trichopoulos, Georgios/0000-0002-6979-2304				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adesso Gerardo, 2023, Towards The Ultimate Brain: Exploring Scientific Discovery with ChatGPT AI, DOI [10.22541/au.167052124.41804127/v2, DOI 10.22541/AU.167052124.41804127/V2]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buchanan Sarah A., 2016, Museum Worlds, V4, P155, DOI DOI 10.3167/ARMW.2016.040112; Carnall M, 2013, MUS MANAG CURATORSHI, V28, P55, DOI 10.1080/09647775.2012.754630; Chang KK, 2023, Arxiv, DOI arXiv:2305.00118; Chen FL, 2023, Arxiv, DOI arXiv:2305.04160; Cheng M, 2023, Arxiv, DOI arXiv:2305.18189; Currie GM, 2023, SEMIN NUCL MED, V53, P719, DOI 10.1053/j.semnuclmed.2023.04.008; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Dima M, 2022, ACM J COMPUT CULT HE, V15, DOI 10.1145/3490393; Economou Maria, 2018, CASE HUNTERIAN MUSEU, P1, DOI [10.1109/DigitalHeritage.2018.8810043, DOI 10.1109/DIGITALHERITAGE.2018.8810043]; Farahat Baher I., 2018, HBRC Journal, V14, P66, DOI DOI 10.1016/J.HBRCJ.2016.01.004; Jiang H, 2024, Arxiv, DOI [arXiv:2305.02547, 10.48550/arXiv.2305.02547]; Katifori A., 2018, Cira@ Euromed, P11; Konstantakis M, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6040144; Koubaa Anis, 2023, GPT-4 vs. GPT-3.5: A Concise Showdown, DOI DOI 10.20944/PREPRINTS202303.0422.V1; Lawan Sadiq, 2022, Journal of Social Sciences Advancement, V3, P45, DOI DOI 10.52223/JSSA22-030105-31; Lee MHY, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11112451; Lehman J., 2022, arXiv, DOI DOI 10.48550/ARXIV.2206.08896; Litvak E, 2020, PERS UBIQUIT COMPUT, V24, P873, DOI 10.1007/s00779-020-01366-7; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu Y, 2021, HERITAGE-BASEL, V4, P316, DOI 10.3390/heritage4010020; Mazzeo R, 2017, TOPICS CURR CHEM, V375, DOI 10.1007/s41061-016-0088-1; Platia N, 2017, HERIT SCI, V5, DOI 10.1186/s40494-017-0163-0; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Siu S.C., 2023, Chatgpt and GPT-4 for professional translators: Exploring the potential of large language models in translation; Trichopoulos G, 2023, Preprints, DOI [10.20944/preprints202306.1618.v1, 10.20944/preprints202306.1618.v1, DOI 10.20944/PREPRINTS202306.1618.V1]; Trichopoulos G, 2023, HERITAGE-BASEL, V6, P1227, DOI 10.3390/heritage6020068; Trichopoulos G, 2021, 2021 16TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION & PERSONALIZATION (SMAP 2021), P5, DOI 10.1109/SMAP53521.2021.9610815; Varitimiadis S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199160	31	2	2	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0888-6				2023									33	10.1145/3609987.3610018	http://dx.doi.org/10.1145/3609987.3610018			5	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3PA					2024-07-03	WOS:001141211000033
C	Liu, X; Kirilyuk, V; Yuan, XX; Chi, P; Chen, X; Olwal, A; Du, RF			ACM	Liu, Xingyu 'Bruce'; Kirilyuk, Vladimir; Yuan, Xiuxiu; Chi, Peggy; Chen, Xiang 'Anthony'; Olwal, Alex; Du, Ruofei			Experiencing Visual Captions: Augmented Communication with Real-time Visuals using Large Language Models	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		augmented communication; large language models; video-mediated communication; online meeting; collaborative work; dataset; text-to-visual; AI agent; augmented reality		We demonstrate Visual Captions, a real-time system that integrates with a video conferencing platform to enrich verbal communication. Visual Captions leverages a fine-tuned large language model to proactively suggest visuals that are relevant to the context of the ongoing conversation. We implemented Visual Captions as a user-customizable Chrome plugin with three levels of AI proactivity: Auto-display (AI autonomously adds visuals), Auto-suggest (AI proactively recommends visuals), and On-demand-suggest (AI suggests visuals when prompted). We showcase the usage of Visual Captions in open-vocabulary settings, and how the addition of visuals based on the context of conversations could improve comprehension of complex or unfamiliar concepts. In addition, we demonstrate three approaches people can interact with the system with different levels of AI proactivity. Visual Captions is open-sourced at https://github.com/google/archat.	[Liu, Xingyu 'Bruce'; Chen, Xiang 'Anthony'] Univ Calif Los Angeles, Los Angeles, CA 90095 USA; [Kirilyuk, Vladimir; Yuan, Xiuxiu; Chi, Peggy; Olwal, Alex] Google Res, Mountain View, CA USA; [Du, Ruofei] Google Res, San Francisco, CA USA; [Liu, Xingyu 'Bruce'] Google, Mountain View, CA 94043 USA	University of California System; University of California Los Angeles; Google Incorporated; Google Incorporated; Google Incorporated	Liu, X (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.; Liu, X (corresponding author), Google, Mountain View, CA 94043 USA.	xingyuliu@ucla.edu; vkyryliuk@google.com; xiuxiuyuan@google.com; peggychi@google.com; xac@ucla.edu; olwal@acm.org; me@duruofei.com	Du, Ruofei/Q-6245-2017	Du, Ruofei/0000-0003-2471-9776; Liu, Xingyu/0000-0002-6988-5471; Chen, Xiang/0000-0002-8527-1744				Liu X, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581566	1	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									85	10.1145/3586182.3615978	http://dx.doi.org/10.1145/3586182.3615978			4	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000084
J	Jacobs, CL; MacDonald, MC				Jacobs, Cassandra L.; MacDonald, Maryellen C.			Constraint satisfaction in large language models	LANGUAGE COGNITION AND NEUROSCIENCE			English	Review; Early Access						Language comprehension; constraint satisfaction; ambiguity; connectionism; large language models	WORD RECOGNITION; LEXICAL ACCESS; EYE-MOVEMENTS; AMBIGUITY; INFORMATION; CONTEXT; RESOLUTION; FIT	Constraint satisfaction theories were prominent in the late 20th century and emphasized continuous, rich interaction between many sources of information in a linguistic signal unfolding over time. A major challenge was rigorously capturing these highly interactive comprehension processes and yielding explicit predictions, because the important constraints were numerous and changed in prominence from one context to the next. Connectionist models were conceptually well-suited to this, but researchers had insufficient computing power and lacked sufficiently large corpora to bring these models to bear. These limitations no longer hold, and large language models (LLMs) offer an opportunity to test constraint satisfaction ideas about human language comprehension. We consider how LLMs can be applied to study interactive processes with lexical ambiguity resolution as a test case. We argue that further study of LLMs can advance theories of constraint satisfaction, though gaps remain in our understanding of how people and LLMs combine linguistic information.	[Jacobs, Cassandra L.] SUNY Buffalo, Dept Linguist, Buffalo, NY USA; [MacDonald, Maryellen C.] Univ Wisconsin Madison, Dept Psychol, Madison, WI USA; [Jacobs, Cassandra L.] Univ Buffalo, Dept Linguist, Buffalo, NY 14260 USA	State University of New York (SUNY) System; State University of New York (SUNY) Buffalo; University of Wisconsin System; University of Wisconsin Madison; State University of New York (SUNY) System; State University of New York (SUNY) Buffalo	Jacobs, CL (corresponding author), Univ Buffalo, Dept Linguist, Buffalo, NY 14260 USA.	cxjacobs@buffalo.edu			National Science Foundation [1849236]	National Science Foundation(National Science Foundation (NSF))	This work was supported by the National Science Foundation: [Grant Number 1849236].	Almeida R. G. D., 2018, On concepts, modules, and language: Cognitive science at its core; ALTMANN G, 1988, COGNITION, V30, P191, DOI 10.1016/0010-0277(88)90020-0; Altmann GTM, 1998, TRENDS COGN SCI, V2, P146, DOI 10.1016/S1364-6613(98)01153-X; Antonello R, 2024, NEUROBIOL LANG, V5, P64, DOI 10.1162/nol_a_00087; Asher N, 2023, Arxiv, DOI arXiv:2306.12213; Baayen RH, 2016, LANG COGN NEUROSCI, V31, P106, DOI 10.1080/23273798.2015.1065336; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bianchi B., 2020, Journal of Vision, V20, P1308, DOI [https://doi.org/10.1167/jov.20.11.1308, DOI 10.1167/JOV.20.11.1308]; Bisk Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8718; Blank IA, 2023, TRENDS COGN SCI, V27, P987, DOI 10.1016/j.tics.2023.08.006; Bowman Samuel R., 2019, INT C LEARN REPR, P1; Box GEP., 1987, Empirical model building and response surfaces; Brown-Schmidt S, 2008, COGNITIVE SCI, V32, P643, DOI 10.1080/03640210802066816; Carreiras M., 2004, The on-line study of sentence comprehension: Eyetracking, ERPs and beyond, V1st ed.; Chen Y., 2019, EUR C COMP VIS; CONNINE CM, 1987, J EXP PSYCHOL HUMAN, V13, P291, DOI 10.1037/0096-1523.13.2.291; Crockett M., 2023, PsyArXiv, P1, DOI [https://doi.org/10.31234/osf.io/4zdx9, DOI 10.31234/OSF.IO/4ZDX9]; Dagerman KS, 2006, COGNITIVE SCI, V30, P311, DOI 10.1207/s15516709cog0000_46; de Varda A. G., 2023, Behavior Research Methods, P1; Dell GS, 1997, PSYCHOL REV, V104, P801, DOI 10.1037/0033-295X.104.4.801; Dentella V, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2309583120; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1; Ethayarajh K, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P55; Farmer TA, 2006, P NATL ACAD SCI USA, V103, P12203, DOI 10.1073/pnas.0602173103; FERREIRA F, 1986, J MEM LANG, V25, P348, DOI 10.1016/0749-596X(86)90006-9; Ferreira F, 2007, LANG LINGUIST COMPAS, V1, P71, DOI 10.1111/j.1749-818x.2007.00007.x; Fine AB, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0077661; FODOR JD, 1988, J PSYCHOLINGUIST RES, V17, P125, DOI 10.1007/BF01067069; Forster K.I., 1985, Language and Cognitive Processes, V1, P87, DOI [https://doi.org/10.1080/01690968508402073, DOI 10.1080/01690968508402073]; Frank Stefan., 2009, Proceedings of the 31st Annual Conference of the Cognitive Science Society, P1139; FRAZIER L, 1987, ATTENTION PERFORM, P559; FRAZIER L, 1987, J MEM LANG, V26, P505, DOI 10.1016/0749-596X(87)90137-9; Frazier L., 1979, THESIS U CONNECTICUT; GARRETT M, 1966, PERCEPT PSYCHOPHYS, V1, P30, DOI 10.3758/BF03207817; Goodkind A., 2018, P 8 WORKSHOP COGNITI, P10, DOI [10.18653/v1/W18-0102, DOI 10.18653/V1/W18-0102]; Grand G, 2022, NAT HUM BEHAV, V6, P975, DOI 10.1038/s41562-022-01316-8; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; Hahn M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2122602119; Hale J, 2003, J PSYCHOLINGUIST RES, V32, P101, DOI 10.1023/A:1022492123056; Hale J, 2006, COGNITIVE SCI, V30, P643, DOI 10.1207/s15516709cog0000_64; Hawkins RD, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4653; Heilbron M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201968119; Himmelstoss NA, 2020, LANG COGN NEUROSCI, V35, P595, DOI 10.1080/23273798.2019.1616102; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hollenstein N, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P141; Hoover Jacob Louis, 2023, Open Mind (Camb), V7, P350, DOI 10.1162/opmi_a_00086; Hu J., 2024, arXiv, P1, DOI [https://doi.org/10.48550/arXiv.2402.01676, DOI 10.48550/ARXIV.2402.01676]; Huang KJ, 2024, J MEM LANG, V137, DOI 10.1016/j.jml.2024.104510; Huebner P. A., 2021, P 25 C COMPUTATIONAL, P624, DOI DOI 10.18653/V1/2021.CONLL-1.49; Irwin T, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3220; Jacobs C. L., 2022, P SOC COMP LING 2022, P225; Jacobs CL, 2023, COGNITION, V230, DOI 10.1016/j.cognition.2022.105265; KAWAMOTO AH, 1993, J MEM LANG, V32, P474, DOI 10.1006/jmla.1993.1026; Kennedy A., 2003, ECEM12 12 EUR C EYE; Kennedy A., 2003, The Dundee Corpus [cd-rom]; Krauska A., 2022, P ANN M COGN SCI SOC, V44; Krauska A., 2023, FRONT PSYCHOL, V2, DOI https://doi.org/10.3389/flang.2023.1125127; Kuribayashi T., 2022, P 2022 C EMP METH NA, P10421, DOI [10.18653/v1, DOI 10.18653/V1]; Levy R, 2008, COGNITION, V106, P1126, DOI 10.1016/j.cognition.2007.05.006; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lyu B, 2024, ELIFE, V12, DOI 10.7554/eLife.89311; MacDonald M.C., 2006, HDB PSYCHOLINGUISTIC, V2nd, P581, DOI DOI 10.1016/B978-012369374-7/50016-X; MacDonald MC, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2217108119; MACDONALD MC, 1994, PSYCHOL REV, V101, P676, DOI 10.1037/0033-295X.101.4.676; MACDONALD MC, 1994, LANG COGNITIVE PROC, V9, P157, DOI 10.1080/01690969408402115; MACDONALD MC, 1993, J MEM LANG, V32, P692, DOI 10.1006/jmla.1993.1035; Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information; Marslen-Wilson W., 1987, Modularity in Knowledge Representation and Natural-Language Understanding, P37; MARSLENWILSON WD, 1975, SCIENCE, V189, P226, DOI 10.1126/science.189.4198.226; MARSLENWILSON WD, 1978, COGNITIVE PSYCHOL, V10, P29, DOI 10.1016/0010-0285(78)90018-X; McClelland J.L., 1986, PARALLEL DISTRIBUTED, V2, P272; McClelland JL, 2020, P NATL ACAD SCI USA, V117, P25966, DOI 10.1073/pnas.1910416117; McClelland JL, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00503; MCCLELLAND JL, 1986, COGNITIVE PSYCHOL, V18, P1, DOI 10.1016/0010-0285(86)90015-0; McRae K, 1998, J MEM LANG, V38, P283, DOI 10.1006/jmla.1997.2543; Merkx D., 2021, P WORKSH COGN MOD CO, P12, DOI [10.18653/v1/2021.cmcl-1.2, DOI 10.18653/V1/2021.CMCL-1.2]; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mollo D. C., 2023, arXiv, P1, DOI [https://doi.org/10.48550/arXiv.2304.01481, DOI 10.48550/ARXIV.2304.01481]; Nair S., 2023, FINDINGS ASS COMPUTA, P11251; Oh B. D., 2022, P 2022 C EMP METH NA, P9324; Oh BD, 2024, Arxiv, DOI arXiv:2402.02255; Oh BD, 2023, T ASSOC COMPUT LING, V11, P336, DOI 10.1162/tacl_a_00548; Pimenter T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4004; Port R, 2007, NEW IDEAS PSYCHOL, V25, P143, DOI 10.1016/j.newideapsych.2007.02.001; Portelance E, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13334; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ravishankar V, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3031; RAYNER K, 1978, PSYCHOL BULL, V85, P618, DOI 10.1037//0033-2909.85.3.618; Richie R, 2020, BEHAV RES METHODS, V52, P1906, DOI 10.3758/s13428-020-01362-y; Rodd JM, 2020, PERSPECT PSYCHOL SCI, V15, P411, DOI 10.1177/1745691619885860; Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Rumelhart D. E., 1977, Attention and performance VI, P573; Ryskin R, 2023, TRENDS COGN SCI, V27, P1032, DOI 10.1016/j.tics.2023.08.003; Ryu S. H., 2021, Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics, P61; Salem AC, 2023, J SPEECH LANG HEAR R, V66, P206, DOI 10.1044/2022_JSLHR-22-00277; Scarlini B, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P3528; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; SEIDENBERG MS, 1989, PSYCHOL REV, V96, P523, DOI 10.1037/0033-295X.96.4.523; Shain C, 2024, P NATL ACAD SCI USA, V121, DOI 10.1073/pnas.2307876121; SPIVEYKNOWLTON M, 1995, COGNITION, V55, P227, DOI 10.1016/0010-0277(94)00647-4; STJOHN MF, 1990, ARTIF INTELL, V46, P217, DOI 10.1016/0004-3702(90)90008-N; Szewczyk JM, 2022, J MEM LANG, V123, DOI 10.1016/j.jml.2021.104311; Tanenhaus M.K., 1995, Handbook of perception and cognition: speech, language and cognition, P217; TANENHAUS MK, 1995, SCIENCE, V268, P1632, DOI 10.1126/science.7777863; Tian Y., 2023, Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023), P174, DOI [10.18653/v1/2023.starsem-1.16, DOI 10.18653/V1/2023.STARSEM-1.16]; Toneva M, 2019, 33 C NEURAL INFORM P, V32; TYLER LK, 1977, J VERB LEARN VERB BE, V16, P683, DOI 10.1016/S0022-5371(77)80027-3; Vaidya AR, 2022, PR MACH LEARN RES; Vaswani A, 2017, ADV NEUR IN, V30; Warstadt A., 2022, Algebraic structures in natural language, P17, DOI [10.1201/9781003205388-2, DOI 10.1201/9781003205388-2]; Warstadt A, 2019, T ASSOC COMPUT LING, V7, P625, DOI 10.1162/tacl_a_00290; Weiss G., 2021, P MACHINE LEARNING R, P11080; Willits JA, 2015, COGNITIVE PSYCHOL, V78, P1, DOI 10.1016/j.cogpsych.2015.02.002	117	0	0	1	1	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	2327-3798	2327-3801		LANG COGN NEUROSCI	Lang. Cogn. Neurosci.	2024 JUN 8	2024										10.1080/23273798.2024.2364339	http://dx.doi.org/10.1080/23273798.2024.2364339		JUN 2024	18	Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Audiology & Speech-Language Pathology; Behavioral Sciences; Linguistics; Psychology	UN8E6		Green Submitted			2024-07-03	WOS:001248822300001
C	Bhandari, P; Anastasopoulos, A; Pfoser, D		Damiani, ML; Renz, M; Eldawy, A; Kroger, P; Nascimento, MA		Bhandari, Prabin; Anastasopoulos, Antonios; Pfoser, Dieter			Are Large Language Models Geospatially Knowledgeable?	31ST ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, ACM SIGSPATIAL GIS 2023			English	Proceedings Paper	31st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL GIS)	NOV 13-16, 2023	Hamburg, GERMANY	ACM SIGSPATIAL, Apple, Oracle, Esri		Large Language Models; Geospatial knowledge; Geospatial awareness; Geospatial Reasoning		Despite the impressive performance of Large Language Models (LLM) for various natural language processing tasks, little is known about their comprehension of geographic data and related ability to facilitate informed geospatial decision-making. This paper investigates the extent of geospatial knowledge, awareness, and reasoning abilities encoded within such pretrained LLMs. With a focus on autoregressive language models, we devise experimental approaches related to (i) probing LLMs for geo-coordinates to assess geospatial knowledge, (ii) using geospatial and non-geospatial prepositions to gauge their geospatial awareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to assess the models' geospatial reasoning capabilities and to determine locations of cities based on prompting. Our results confirm that it does not only take larger but also more sophisticated LLMs to synthesize geospatial knowledge from textual information. As such, this research contributes to understanding the potential and limitations of LLMs in dealing with geospatial information.	[Bhandari, Prabin; Anastasopoulos, Antonios] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA; [Pfoser, Dieter] George Mason Univ, Dept Geog & Geoinformat Sci, Fairfax, VA 22030 USA	George Mason University; George Mason University	Bhandari, P (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.	pbhanda2@gmu.edu; antonis@gmu.edu; dpfoser@gmu.edu	Bhandari, Prabin/KIE-5718-2024	Anastasopoulos, Antonios/0000-0002-8544-246X; Pfoser, Dieter/0000-0001-9197-0069; Bhandari, Prabin/0009-0006-9034-6372	National Science Foundation [1625039, 2018631, IIS-2127901]; Office of Research Computing, George Mason University	National Science Foundation(National Science Foundation (NSF)); Office of Research Computing, George Mason University	This work has been supported by the National Science Foundation Grant No. IIS-2127901. Additionally, this work was supported by resources provided by the Office of Research Computing, George Mason University and by the National Science Foundation (Awards Number 1625039 and 2018631).	Borg I., 2005, MODERN MULTIDIMENSIO; Da Jeff, 2021, ARXIV210100297; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Lietard B., 2021, P 4 BLACKBOXNLP WORK, P510; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu Xiao, 2021, P-tuning v2: Prompt tuning can be comparable to fine-tuning universally across scales and tasks; Mikolov T, 2013, ARXIV PREPRINT ARXIV; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Safavi T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1053; UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573	10	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0168-9				2023							424	427		10.1145/3589132.3625625	http://dx.doi.org/10.1145/3589132.3625625			4	Computer Science, Information Systems; Remote Sensing	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Remote Sensing	BW4XN		hybrid, Green Submitted			2024-07-03	WOS:001156830400075
J	Buttrick, N				Buttrick, Nicholas			Studying large language models as compression algorithms for human culture	TRENDS IN COGNITIVE SCIENCES			English	Article								Large language models (LLMs) extract and reproduce the statistical regularities in their training data. Researchers can use these models to study the conceptual relationships encoded in this training data (i.e., the open internet), providing a remarkable opportunity to understand the cultural distinctions embedded within much of recorded human communication.	[Buttrick, Nicholas] Univ Wisconsin, Dept Psychol, Madison, WI 53715 USA	University of Wisconsin System; University of Wisconsin Madison	Buttrick, N (corresponding author), Univ Wisconsin, Dept Psychol, Madison, WI 53715 USA.	nbuttrick@wisc.edu		Buttrick, Nicholas/0000-0002-1165-8938				Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Atari M., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/5B26T; Cheng M, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1504; Chiang Ted., 2017, The New Yorker; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Gooding P, 2013, LIT LINGUIST COMPUT, V28, P425, DOI 10.1093/llc/fqs054; Grosse R, 2023, Arxiv, DOI arXiv:2308.03296; Gururangan S., 2022, arXiv; Kovac G, 2023, arXiv; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Said O, 1973, Orientalism; Santurkar S, 2023, Arxiv, DOI arXiv:2303.17548; Schott T., 2023, P 2023 C EMPNC METH, P11238; Thomson R, 2018, P NATL ACAD SCI USA, V115, P7521, DOI 10.1073/pnas.1713191115; Younes N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0213554	16	0	0	23	23	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	1364-6613	1879-307X		TRENDS COGN SCI	TRENDS COGN. SCI.	MAR	2024	28	3					187	189						3	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	PZ8R3	38245431				2024-07-03	WOS:001217995800001
J	Kim, G; Yoo, J; Kang, S				Kim, Gyunyeop; Yoo, Joon; Kang, Sangwoo			Efficient Federated Learning with Pre-Trained Large Language Model Using Several Adapter Mechanisms	MATHEMATICS			English	Article						federated learning; deep learning; transfer learning; adapter transformer		Recent advancements in deep learning have led to various challenges, one of which is the issue of data privacy in training data. To address this issue, federated learning, a technique that merges models trained by clients on servers, has emerged as an attractive solution. However, federated learning faces challenges related to data heterogeneity and system heterogeneity. Recent observations suggest that incorporating pre-trained models into federated learning can mitigate some of these challenges. Nonetheless, the main drawback of pre-trained models lies in their typically large model size, leading to excessive data transmission when clients send these models to the server. Additionally, federated learning involves multiple global steps, which means transmitting a large language model to multiple clients results in too much data exchange. In this paper, we propose a novel approach to address this challenge using adapters. Adapters demonstrate training efficiency by training a small capacity adapter layer alongside a large language model. This unique characteristic reduces the volume of data transmission, offering a practical solution to the problem. The evaluation results demonstrate that the proposed method achieves a reduction in training time of approximately 20-40% and a transmission speed improvement of over 98% compared to previous approaches.	[Kim, Gyunyeop; Yoo, Joon; Kang, Sangwoo] Gachon Univ, Sch Comp, 1342 Seongnam Daero, Seongnam Si 13120, South Korea	Gachon University	Yoo, J; Kang, S (corresponding author), Gachon Univ, Sch Comp, 1342 Seongnam Daero, Seongnam Si 13120, South Korea.	gyop0817@gachon.ac.kr; joon.yoo@gachon.ac.kr; swkang@gachon.ac.kr		Kang, Sangwoo/0000-0002-0281-1726; Yoo, Joon/0000-0002-9520-5855; Kim, Gyunyeop/0000-0002-9604-8134	National Research Foundation of Korea (NRF) - Korean government (MSIT) [2022R1A2C1005316, 2021R1F1A1063640]; Gachon University research fund [GCU-202300660001]	National Research Foundation of Korea (NRF) - Korean government (MSIT)(National Research Foundation of KoreaMinistry of Science & ICT (MSIT), Republic of Korea); Gachon University research fund	This work was supported in part by the National Research Foundation of Korea (NRF)grant funded by the Korean government (MSIT) (2022R1A2C1005316 and 2021R1F1A1063640) and inpart by the Gachon University research fund of 2023 (GCU-202300660001).	Abadi M., 2015, TensorFlow: Large-scale machine learning on het- erogeneous systems; Acar D.A.E., 2021, P INT C LEARN REPR V; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217; Deng YY, 2020, Arxiv, DOI arXiv:2003.13461; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dosovitskiy A., 2020, ICLR; Federated Learning, Collaborative machine learning without centralized training data; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Krizhevsky A., LEARNING MULTIPLE LA; Li QB, 2021, PROC CVPR IEEE, P10708, DOI 10.1109/CVPR46437.2021.01057; Li T., 2020, PROC MACH LEARN SYST, P429; McMahan HB, 2017, PR MACH LEARN RES, V54, P1273; Nguyen J., 2022, arXiv; Pfeiffer J, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P487; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Wang Jianyu, 2020, P ADV NEUR INF PROC, V33, P7611, DOI DOI 10.48550/ARXIV.2007.07481; Zhang L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4400, DOI 10.1109/ICCV48922.2021.00438	21	0	0	13	19	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-7390		MATHEMATICS-BASEL	Mathematics	NOV	2023	11	21							4479	10.3390/math11214479	http://dx.doi.org/10.3390/math11214479			19	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	X7TY2		gold			2024-07-03	WOS:001100441000001
J	Grinbaum, A; Adomaitis, L				Grinbaum, Alexei; Adomaitis, Laurynas			Dual use concerns of generative AI and large language models	JOURNAL OF RESPONSIBLE INNOVATION			English	Article						Dual Use Research of Concern (DURC); generative AI; Large Language Models (LLMs); AI ethics	TRANSMISSION; ETHICS; VIRUS	We suggest the implementation of the Dual Use Research of Concern (DURC) framework, originally designed for life sciences, to the domain of generative AI, with a specific focus on Large Language Models (LLMs). With its demonstrated advantages and drawbacks in biological research, we believe the DURC criteria can be effectively redefined for LLMs, potentially contributing to improved AI governance. Acknowledging the balance that must be struck when employing the DURC framework, we highlight its crucial political role in enhancing societal awareness of the impact of generative AI. As a final point, we offer a series of specific recommendations for applying the DURC approach to LLM research.	[Grinbaum, Alexei; Adomaitis, Laurynas] CEA Saclay, LARSIM, Gif Sur Yvette, France; [Grinbaum, Alexei] CEA Saclay, Larsim, F-91191 Gif Sur Yvette, France	Universite Paris Saclay; CEA; CEA; Universite Paris Saclay	Grinbaum, A (corresponding author), CEA Saclay, Larsim, F-91191 Gif Sur Yvette, France.	alexei.grinbaum@cea.fr	Grinbaum, Alexei/A-2210-2012; Adomaitis, Laurynas/K-7439-2015	Grinbaum, Alexei/0000-0002-7484-1553; 	Projects TechEthos [101006249]; Multi-RATE - European Commission Horizon program [101073929]; Horizon Europe - Pillar II [101073929] Funding Source: Horizon Europe - Pillar II	Projects TechEthos; Multi-RATE - European Commission Horizon program; Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	This research was supported through projects TechEthos (grant number 101006249) and Multi-RATE (grant number 101073929) funded by the European Commission Horizon program.	Aaronson S., 2022, Shtetl-Optimized; Adomaitis L., 2022, TechEthos D2.2: Identification and Specification of Potential Ethical Issues and Impacts and Analysis of Ethical Issues of Digital Extended Reality, Neurotechnologies, and Climate Engineering; AI Safety Summit, 2023, BLETCHL DECL COUNTR; [Anonymous], Regulation (EU) 2021/818 of the European Parliament and of the Council of 20 May 2021 establishing the Creative Europe Programme (2021 to 2027) and repealing Regulation (EU) No 1295/2013 (Text with EEA relevance); [Anonymous], 2023, ChatGPT and Large Language Models: What's the Risk?; Anthropic, 2023, Frontier Threats Red Teaming for AI Safety; Atlas RM, 2002, SCIENCE, V298, P753, DOI 10.1126/science.1078329; Bagdasaryan E, 2022, P IEEE S SECUR PRIV, P769, DOI [10.1109/SP46214.2022.00103, 10.1109/SP46214.2022.9833572]; BERG P, 1975, SCIENCE, V188, P991, DOI 10.1126/science.1056638; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bostrom N, 2014, CAMBRIDGE HANDBOOK OF ARTIFICIAL INTELLIGENCE, P316; Brundage Miles, 2018, The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Christie E. H., 2023, AI and Ethics, P1, DOI [https://doi.org/10.1007/s43681-023-00261-0, DOI 10.1007/S43681-023-00261-0]; Clark Elizabeth, 2021, arXiv; Colleoni E, 2014, J COMMUN, V64, P317, DOI 10.1111/jcom.12084; Collins FS, 2012, NIH Statement on H5N1'; Coulter M., 2023, Reuters; Council of Europe, 2023, Press Release; Dance A, 2021, NATURE, V598, P554, DOI 10.1038/d41586-021-02903-x; Davis E., 2016, AI Matters, V2, P20, DOI DOI 10.1145/3008665.3008674; Dignum V, 2019, ARTIF INTELL-FOUND, P47, DOI 10.1007/978-3-030-30371-6_4; European Commission, 2022, Proposal for a directive of the European parliament and of the council on corporate sustainability due diligence and amending directive (EU) 2019 / 1937; European Parliament, 2023, Artificial Intelligence Act: deal on comprehensive rules for trustworthy AI, Press Releases; European Parliament, 2023, Artificial Intelligence Act: Deal on comprehensive rules for trustworthy AI; EUROPOL, 2023, ChatGPT-the Impact of Large Language Models on Law Enforcement; Evans N. G., 2020, Infectious Diseases in the New Millennium: Legal and Ethical Challenges, P193, DOI [DOI 10.1007/978-3-030-39819-4_9, https://doi.org/10.1007/978-3-030-39819-4_9]; Evans NG, 2013, MBIO, V4, DOI 10.1128/mBio.00547-13; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Future of Life Institute, 2023, PAUS GIANT EXP OP LE; Galdzicki M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017005; Geissler E., 1999, Biological and Toxin Weapons: Research, Development, and Use from the Middle Ages to 1945; Gregory S, 2022, JOURNALISM, V23, P708, DOI 10.1177/14648849211060644; Grinbaum A., 2023, Parole de Machines; Grinbaum A., 2019, Les Robots et le mal; Grinbaum A., 2013, Responsible Innovation: Managing the Responsible Emergence of Science and Innovation in Society, P119, DOI DOI 10.1002/9781118551424.CH7; Grinbaum A., 2021, Agents Conversationnels: Enjeux D'ethique (Report). Comite National Pilote D'ethique du Numerique; Grinbaum A, 2022, NANOETHICS, V16, P257, DOI 10.1007/s11569-022-00426-x; Grinbaum A, 2022, Arxiv, DOI [arXiv:2209.03118, DOI 10.48550/ARXIV.2209.03118, 10.48550/arXiv.2209.03118]; Grinbaum A, 2017, IEEE ROBOT AUTOM MAG, V24, P139, DOI 10.1109/MRA.2016.2611586; Hazell J, 2023, Arxiv, DOI arXiv:2305.06972; Heaven W., 2023, MIT TECHNOL REV; Heikkila M., 2022, MIT Technology Review; Herfst S, 2012, SCIENCE, V336, P1534, DOI 10.1126/science.1213362; Hern E, 2005, BMJ-BRIT MED J, V330, P1221, DOI 10.1136/bmj.330.7502.1221; Imai M, 2012, NATURE, V486, P420, DOI 10.1038/nature10831; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Koplin JJ, 2023, ETHICS INF TECHNOL, V25, DOI 10.1007/s10676-023-09703-z; Korn H., 2019, Academie des Sciences; LAION e.V, 2023, An Open Letter to the European Parliament; Lipsitch M, 2014, PLOS MED, V11, DOI 10.1371/journal.pmed.1001646; Lipsitch M, 2012, MBIO, V3, DOI 10.1128/mBio.00360-12; Mireshghallah F, 2022, Arxiv, DOI arXiv:2203.03929; Mollman S., 2023, Fortune; Moradi M, 2021, Arxiv, DOI arXiv:2108.12237; National Research Council, 2004, Biotechnology Research in an Age of Terrorism, DOI DOI 10.17226/10827; National Research Council, 2007, Science and Security in a Post 9/11 World: A Report Based on Regional Discussions Between the Science and Security Communities; NSABB, 2007, PROPOSED FRAMEWORK O; Oak Rajvardhan, 2022, CCS '22: Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security, P3435, DOI 10.1145/3548606.3563512; OpenAI, 2023, Frontier Model Forum; OpenAI, 2023, Moving AI Governance Forward; Osband I, 2022, Arxiv, DOI [arXiv:2211.01568, 10.48550/arXiv.2211.01568, DOI 10.48550/ARXIV.2211.01568]; Pichai S., 2023, Google; Qian RBC, 2022, Arxiv, DOI [arXiv:2205.12586, 10.48550/ARXIV.2205.12586]; Reisach U, 2021, EUR J OPER RES, V291, P906, DOI 10.1016/j.ejor.2020.09.020; Resnik D. B., 2010, Studies in Ethics, Law, and Technology, V4, DOI [DOI 10.2202/1941-6008.1124, https://doi.org/10.2202/1941-6008.1124]; Ropek L., 2023, Gizmodo; Sanger DE., 2023, The New York Times; Scharre P., 2018, Army of None: Autonomous Weapons and the Future of War; Schweber S.S., 2000, In the Shadow of the Bomb: Oppenheimer, Bethe, and the Moral Responsibility of the Scientist; Scouras J, 2019, J BENEFIT-COST ANAL, V10, P274, DOI 10.1017/bca.2019.16; Selgelid MJ, 2007, HASTINGS CENT REP, V37, P35, DOI 10.1353/hcr.2007.0046; Smith-Ruiu J., 2023, Substack Newsletter; Taddeo M, 2018, NATURE, V556, P296, DOI 10.1038/d41586-018-04602-6; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Taori R., 2023, Stanford alpaca: An instruction-following llama model; The White House, 2023, Executive Order on the Safe, Secure, andTrustworthy Development and Use of Artificial Intelligence; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tucker JB, 2012, INNOVATION, DUAL USE, AND SECURITY: MANAGING THE RISKS OF EMERGING BIOLOGICAL AND CHEMICAL TECHNOLOGIES, P1; Tumpey TM, 2005, SCIENCE, V310, P77, DOI 10.1126/science.1119392; Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9; US Department of Commerce, 2023, Export Administration Regulations; US HHS, 2017, Framework for Guiding Funding Decisions About Proposed Research Involving Enhanced Potential Pandemic Pathogens; Vannuccini S., 2021, Artificial Intelligence's New Clothes? From General Purpose Technology to Large Technical System, DOI [https://doi.org/10.2139/ssrn.3860041, DOI 10.2139/SSRN.3860041]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; White House, 2023, Readout of White House Meeting with CEOs on Advancing Responsible Artificial Intelligence Innovation; White House, 2023, FACT SHEET: Biden-Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI; Xu A. Y., 2020, Medium; Zhang HL, 2023, Arxiv, DOI [arXiv:2311.04378, 10.48550/arXiv.2311.04378, DOI 10.48550/ARXIV.2311.04378]; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]	91	1	1	76	76	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	2329-9460	2329-9037		J RESPONSIBLE INNOV	J. Responsible Innov.	DEC 31	2024	11	1							2304381	10.1080/23299460.2024.2304381	http://dx.doi.org/10.1080/23299460.2024.2304381			18	Ethics; History & Philosophy Of Science; Management; Social Issues	Social Science Citation Index (SSCI)	Social Sciences - Other Topics; History & Philosophy of Science; Business & Economics; Social Issues	GG0T8		gold, Green Submitted			2024-07-03	WOS:001151401800001
J	Markowitz, DM				Markowitz, David M.			Can generative AI infer thinking style from language? Evaluating the utility of AI as a psychological text analysis tool	BEHAVIOR RESEARCH METHODS			English	Article; Early Access						Analytic thinking; Text analysis; Generative AI; Large language models; LIWC	CULTURE; THOUGHT; PAIN	Generative AI, short for Generative Artificial Intelligence, a class of artificial intelligence systems, is not currently the choice technology for text analysis, but prior work suggests it may have some utility to assess dynamics like emotion. The current work builds upon this empirical foundation to consider how analytic thinking scores from a large language model chatbot, ChatGPT, were linked to analytic thinking scores from dictionary-based tools like Linguistic Inquiry and Word Count (LIWC). Using over 16,000 texts from four samples and tested against three prompts and two large language models (GPT-3.5, GPT-4), the evidence suggests there were small associations between ChatGPT and LIWC analytic thinking scores (meta-analytic effect sizes: .058 < rs < .304; ps < .001). When given the formula to calculate the LIWC analytic thinking index, ChatGPT performed incorrect mathematical operations in 22% of the cases, suggesting basic word and number processing may be unreliable with large language models. Researchers should be cautious when using AI for text analysis.	[Markowitz, David M.] Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA	Michigan State University	Markowitz, DM (corresponding author), Michigan State Univ, Dept Commun, E Lansing, MI 48824 USA.	dmm@msu.edu	hu, guangchen/KEI-6324-2024	Markowitz, David/0000-0002-7159-7014				Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; arXiv, 2023, arXiv; Blackburn KG, 2018, APPETITE, V123, P390, DOI 10.1016/j.appet.2018.01.022; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Boyd R. L., 2022, The Development and Psychometric Properties of LIWC-22, DOI DOI 10.13140/RG.2.2.23890.43205; Boyd RL, 2021, J LANG SOC PSYCHOL, V40, P21, DOI [10.1177/0261927x20967028, 10.1177/0261927X20967028]; Boyd RL, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba2196; Boyd RL, 2016, CONSUMER PSYCHOLOGY IN A SOCIAL MEDIA WORLD, P222; Charlesworth TES, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2121798119; Chung C, 2007, FRONT SOC PSYCHOL, P343; Cicchetti DV., 1994, PSYCHOL ASSESSMENTS, V6, P284, DOI [DOI 10.1037/1040-3590.6.4.284, 10.1037/1040-3590.6.4.284]; Cintron A, 2006, J PALLIAT MED, V9, P1454, DOI 10.1089/jpm.2006.9.1454; Clark E., 2021, P 59 ANN M ASS COMP, P7282, DOI DOI 10.18653/V1; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Diedenhofen B, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0121945; Eichstaedt JC, 2021, PSYCHOL METHODS, V26, P398, DOI 10.1037/met0000349; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Goranson A, 2017, PSYCHOL SCI, V28, P988, DOI 10.1177/0956797617701186; Graesser AC, 2014, ELEM SCHOOL J, V115, P210, DOI 10.1086/678293; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; Hoffman KM, 2016, P NATL ACAD SCI USA, V113, P4296, DOI 10.1073/pnas.1516047113; Ireland M. E., 2014, The Oxford handbook of language and social psychology, P201, DOI [DOI 10.1093/OXFORDHB/9780199838639.013.034, DOI 10.1093/OXFORDHB/9780199838639.001.0001]; Ireland ME, 2010, J PERS SOC PSYCHOL, V99, P549, DOI 10.1037/a0020386; Jakesch M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208839120; Jordan KN, 2019, P NATL ACAD SCI USA, V116, P3476, DOI 10.1073/pnas.1811987116; Kacewicz E, 2014, J LANG SOC PSYCHOL, V33, P125, DOI 10.1177/0261927X13502654; Kahneman D., 2011, THINKING FAST SLOW; Kennedy B., 2022, Handbook of language analysis in psychology; Kern ML, 2014, ASSESSMENT, V21, P158, DOI 10.1177/1073191113514104; Köbis N, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106553; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Krosnick J. A., 2018, PALGRAVE HDB SURVEY, P439, DOI [10.1007/978-3-319-54395-6_53, DOI 10.1007/978-3-319-54395-6_53]; MAASS A, 1989, J PERS SOC PSYCHOL, V57, P981, DOI 10.1037/0022-3514.57.6.981; Markowitz DM, 2022, PNAS NEXUS, V1, DOI 10.1093/pnasnexus/pgac157; Markowitz DM, 2023, APPL COGNITIVE PSYCH, V37, P643, DOI 10.1002/acp.4057; Markowitz DM, 2023, J PERS SOC PSYCHOL, V124, P1133, DOI 10.1037/pspa0000333; Markowitz DM, 2022, J LANG SOC PSYCHOL, V41, P209, DOI 10.1177/0261927X211026346; Markowitz DM, 2016, J LANG SOC PSYCHOL, V35, P435, DOI 10.1177/0261927X15614605; Mehl M.R., 2006, HDB MULTIMETHOD MEAS, P141; Meier T, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0243637; Nisbett RE, 2001, PSYCHOL REV, V108, P291, DOI 10.1037//0033-295X.108.2.291; OpenAI, 2023, Pricing; Pennebaker JW, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115844; Pennebaker JW, 2011, NEW SCI, V211, P42, DOI 10.1016/S0262-4079(11)62167-2; Pennebaker JW., 2022, LINGUISTIC INQUIRY W; Petty R.E., 2009, HDB INDIVIDUAL DIFFE, P318, DOI DOI 10.1002/(SICI)1099-0984(199603)10:13.0.CO;2-D; Rathje S., 2023, GPT is an effective tool for multilingual psychological text analysis, DOI [10.31234/osf.io/sekf5, DOI 10.31234/OSF.IO/SEKF5]; Seraj S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2017154118; Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676; Voigt R, 2017, P NATL ACAD SCI USA, V114, P6521, DOI 10.1073/pnas.1702413114; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Wilkerson J, 2017, ANNU REV POLIT SCI, V20, P529, DOI 10.1146/annurev-polisci-052615-025542; Yelp, 2023, Yelp Dataset; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	54	2	2	55	55	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1554-351X	1554-3528		BEHAV RES METHODS	Behav. Res. Methods	2024 JAN 26	2024										10.3758/s13428-024-02344-0	http://dx.doi.org/10.3758/s13428-024-02344-0		JAN 2024	12	Psychology, Mathematical; Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	GE9U8	38277084				2024-07-03	WOS:001151115700002
J	Pendergrast, T; Chalmers, Z				Pendergrast, Tricia; Chalmers, Zachary			Anki Tagger: A Generative AI Tool for Aligning Third-Party Resources to Preclinical Curriculum	JMIR MEDICAL EDUCATION			English	Article						ChatGPT; undergraduate medical education; large language models; Anki; flashcards; artificial intelligence; AI		Using large language models, we developed a method to efficiently query existing flashcard libraries and select those most relevant to an individual's medical school curricula.	[Pendergrast, Tricia] Univ Michigan Med, Dept Anesthesiol, Ann Arbor, MI USA; [Chalmers, Zachary] Northwestern Univ, Feinberg Sch Med, Chicago, IL USA; [Chalmers, Zachary] Northwestern Univ, Feinberg Sch Med, 303 E Chicago Ave,Morton 1-670, Chicago, IL 60611 USA	University of Michigan System; University of Michigan; Northwestern University; Feinberg School of Medicine; Northwestern University; Feinberg School of Medicine	Chalmers, Z (corresponding author), Northwestern Univ, Feinberg Sch Med, 303 E Chicago Ave,Morton 1-670, Chicago, IL 60611 USA.	zachary.chalmers@northwestern.edu		Chalmers, Zachary/0000-0003-1012-8529				AnkiHub, ABOUT US; [Anonymous], zachalmers-Anki_Tagger; [Anonymous], Medical School Anki; Ayoub NF, 2023, JAMA OTOLARYNGOL, V149, P556, DOI 10.1001/jamaoto.2023.0704; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Jape D, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03324-8; Rana T, 2020, FASEB J, V34, DOI 10.1096/fasebj.2020.34.s1.09736; Wothe JK, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231173289; Wu JH, 2021, JAMA-J AM MED ASSOC, V326, P2005, DOI 10.1001/jama.2021.16312	9	2	2	17	26	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e48780	10.2196/48780	http://dx.doi.org/10.2196/48780			3	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	U6BO0	37728965	gold, Green Published			2024-07-03	WOS:001085637200001
C	Tekumalla, R; Banda, JM		Asahi, Y; Mori, H; Coman, A; Vasilache, S; Rauterberg, M		Tekumalla, Ramya; Banda, Juan M.			Leveraging Large Language Models and Weak Supervision for Social Media Data Annotation: An Evaluation Using COVID-19 Self-reported Vaccination Tweets	HCI INTERNATIONAL 2023 LATE BREAKING PAPERS, HCII 2023, PT III	Lecture Notes in Computer Science		English	Proceedings Paper	25th International Conference on Human-Computer Interaction (HCI International)	JUL 23-28, 2023	Copenhagen, DENMARK			Large language models; GPT; weak supervision; social media data		The COVID-19 pandemic has presented significant challenges to the healthcare industry and society as a whole. With the rapid development of COVID-19 vaccines, social media platforms have become a popular medium for discussions on vaccine-related topics. Identifying vaccine-related tweets and analyzing them can provide valuable insights for public health researchers and policymakers. However, manual annotation of a large number of tweets is time-consuming and expensive. In this study, we evaluate the usage of Large Language Models, in this case GPT-4 (March 23 version), and weak supervision, to identify COVID-19 vaccine-related tweets, with the purpose of comparing performance against human annotators. We leveraged a manually curated gold-standard dataset and used GPT-4 to provide labels without any additional fine-tuning or instructing, in a single-shot mode (no additional prompting).	[Tekumalla, Ramya; Banda, Juan M.] Georgia State Univ, Atlanta, GA 30328 USA	University System of Georgia; Georgia State University	Banda, JM (corresponding author), Georgia State Univ, Atlanta, GA 30328 USA.	rtekumalla1@gsu.edu; jbanda@gsu.edu						Agarwal V, 2016, J AM MED INFORM ASSN, V23, P1166, DOI 10.1093/jamia/ocw028; Agichtein Eugene, 2008, WSDM '08: Proceedings of the international conference on Web search and web data mining, P183, DOI DOI 10.1145/1341531.1341557; [Anonymous], AWS pricing calculator user guide [Acedido: 25/08/2020]; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Banda JM, 2021, EPIDEMIOLOGIA-BASEL, V2, P315, DOI 10.3390/epidemiologia2030024; Beltagy I., 2019, arXiv; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chalkidis I, 2020, Arxiv, DOI arXiv:2010.02559; Chandra AL, 2020, PLANT METHODS, V16, DOI 10.1186/s13007-020-00575-8; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Cutler J., 2019, AppliedMarketing Analytics, V5, P159; Nguyen DQ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P9; Deriu J, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P1045, DOI 10.1145/3038912.3052611; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Fries JA, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11012-3; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; He XW, 2024, Arxiv, DOI arXiv:2303.16854; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Kuzman T., 2023, arXiv; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu Z, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4513; Magge A, 2021, P 6 SOCIAL MEDIA MIN, P21, DOI DOI 10.18653/V1/2021.SMM4H-1.4; Martin L, 2020, Arxiv, DOI arXiv:1911.03894; McHugh ML, 2012, BIOCHEM MEDICA, V22, P276, DOI 10.11613/bm.2012.031; Moller AG, 2024, Arxiv, DOI arXiv:2304.13861; Muller M., 2020, arXiv, DOI DOI 10.3389/FRAI.2023.1023281; Munro R., 2021, HUMAN IN THE LOOP MA; news.techworkerscoalition, Beware the Hype: ChatGPT didn't Replace Human Data Annotators; Pershad Y, 2018, J CLIN MED, V7, DOI 10.3390/jcm7060121; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2023, Language Models are Unsupervised Multitask Learners; Raffel C, 2020, J MACH LEARN RES, V21; Ratner A., 2019, Weak Supervision: the New Programming Paradigm for Machine Learning; Ratner A, 2016, ADV NEUR IN, V29; Reiss MV, 2023, Arxiv, DOI [arXiv:2304.11085, DOI 10.48550/ARXIV.2304.11085]; Robinson J., 2020, INT C MACHINE LEARNI, P8127; Saab K, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0264-0; Saab K, 2019, LECT NOTES COMPUT SC, V11766, P811, DOI 10.1007/978-3-030-32248-9_90; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Settles B, 2009, ACTIVE LEARNING LIT; Shin C., 2021, arXiv; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Solmaz G., 2022, arXiv; Tekumalla R., 2022, P 2022 IEEE INT C BI, VVolume 60, P4816, DOI DOI 10.1109/BIGDATA55660.2022.10020214; Tekumalla R., 2022, 2022 IEEE INTERNATIO, P4824, DOI DOI 10.1109/BIGDATA55660.2022.10020594; Tekumalla R., 2020, P INT AAAI C WEB SOC, V14, P909; Tekumalla R., P LATINX NLP RES WOR; Tekumalla R., 2021, P BIOCREATIVE 7 CHAL; Tekumalla R, 2023, NEURAL COMPUT APPL, V35, P18161, DOI 10.1007/s00521-021-06614-2; Veselovsky V, 2023, Arxiv, DOI [arXiv:2306.07899, 10.48550/arXiv.2306.07899, DOI 10.48550/ARXIV.2306.07899]; Wang YS, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-018-0723-6; Weissenbacher D., 2022, P 7 WORKSH SOC MED M, P221; Xue J, 2020, J MED INTERNET RES, V22, DOI 10.2196/20550; Yang Y, 2020, Arxiv, DOI arXiv:2006.08097; Yang ZL, 2019, ADV NEUR IN, V32; Yu DN, 2024, Arxiv, DOI arXiv:2305.08339; Zamani H, 2018, PROCEEDINGS OF THE 2018 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'18), P147, DOI 10.1145/3234944.3234968; Zhang JY, 2022, Arxiv, DOI arXiv:2202.05433; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	66	1	1	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48043-0; 978-3-031-48044-7	LECT NOTES COMPUT SC			2023	14056						356	366		10.1007/978-3-031-48044-7_26	http://dx.doi.org/10.1007/978-3-031-48044-7_26			11	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5ET		Green Submitted			2024-07-03	WOS:001159614700026
J	Birhane, A; Kasirzadeh, A; Leslie, D; Wachter, S				Birhane, Abeba; Kasirzadeh, Atoosa; Leslie, David; Wachter, Sandra			Science in the age of large language models	NATURE REVIEWS PHYSICS			English	Editorial Material								Rapid advances in the capabilities of large language models and the broad accessibility of tools powered by this technology have led to both excitement and concern regarding their use in science. Four experts in artificial intelligence ethics and policy discuss potential risks and call for careful consideration and responsible usage to ensure that good scientific practices and trust in science are not compromised.	[Birhane, Abeba] Trinity Coll Dublin, Mozilla Fdn, Dublin, Ireland; [Kasirzadeh, Atoosa] Univ Edinburgh, Edinburgh, Midlothian, Scotland; [Kasirzadeh, Atoosa; Leslie, David] Alan Turing Inst, London, England; [Leslie, David] Queen Mary Univ London, London, England; [Wachter, Sandra] Univ Oxford, Oxford, England	Trinity College Dublin; University of Edinburgh; University of London; Queen Mary University London; University of Oxford	Birhane, A (corresponding author), Trinity Coll Dublin, Mozilla Fdn, Dublin, Ireland.; Kasirzadeh, A (corresponding author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.; Kasirzadeh, A; Leslie, D (corresponding author), Alan Turing Inst, London, England.; Leslie, D (corresponding author), Queen Mary Univ London, London, England.; Wachter, S (corresponding author), Univ Oxford, Oxford, England.	adbirhane@gmail.com; atoosa.kasirzadeh@ed.ac.uk; dleslie@turing.ac.uk; sandra.wachter@oii.ox.ac.uk		Wachter, Sandra/0000-0003-3800-0113	Wellcome Trust [223765/Z/21/Z]; Sloan Foundation [G-2021-16779]; Department of Health and Social Care; Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford; Wellcome Trust [223765/Z/21/Z] Funding Source: Wellcome Trust	Wellcome Trust(Wellcome Trust); Sloan Foundation(Alfred P. Sloan Foundation); Department of Health and Social Care; Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford; Wellcome Trust(Wellcome Trust)	AcknowledgementsThe work of S.W. is supported through research funding provided by the Wellcome Trust (grant nr 223765/Z/21/Z), Sloan Foundation (grant no. G-2021-16779), the Department of Health and Social Care (via the AI Lab at NHSx) and Luminate Group to support the Trustworthiness Auditing for AI project and Governance of Emerging Technologies research programme at the Oxford Internet Institute, University of Oxford.	Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; GRILICHES Z, 1957, ECONOMETRICA, V25, P501, DOI 10.2307/1905380; Heaven W., 2023, MIT TECHNOL REV; Krenn M, 2022, NAT REV PHYS, V4, P761, DOI 10.1038/s42254-022-00518-3; Kuhn T.S., 2012, STRUCTURE SCI REVOLU; Owens B., 2023, Nature; Reichenbach H., 1938, EXPERIENCE PREDICTIO; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088	12	40	43	12	31	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5820		NAT REV PHYS	Nat. Rev. Phys.	MAY	2023	5	5					277	280		10.1038/s42254-023-00581-4	http://dx.doi.org/10.1038/s42254-023-00581-4		APR 2023	4	Physics, Applied; Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Physics	F3DU2		Bronze			2024-07-03	WOS:000979468400002
C	Giglou, HB; D'Souza, J; Auer, S		Payne, TR; Presutti, V; Qi, G; Poveda-Villalon, M; Stoilos, G; Hollink, L; Kaoudi, Z; Cheng, G; Li, J		Giglou, Hamed Babaei; D'Souza, Jennifer; Auer, Soeren			LLMs4OL: Large Language Models for Ontology Learning	SEMANTIC WEB, ISWC 2023, PART I	Lecture Notes in Computer Science		English	Proceedings Paper	22nd International Semantic Web Conference (ISWC)	NOV 06-10, 2023	Athens, GREECE	Create Link, Zhipu Ai, Bosch, IBM Res, Metaphacts, Google, Gesis, Leibniz Inst Social Sci, Ontotext, Ebay, Huawei, Elsevier, Journal of Artificial Intelligence, Qualco Grp, Bupsolutions		Large Language Models; LLMs; Ontologies; Ontology Learning; Prompting; Prompt-based Learning		We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS. The obtained empirical results show that foundational LLMs are not sufficiently suitable for ontology construction that entails a high degree of reasoning skills and domain expertise. Nevertheless, when effectively fine-tuned they just might work as suitable assistants, alleviating the knowledge acquisition bottleneck, for ontology construction.	[Giglou, Hamed Babaei; D'Souza, Jennifer; Auer, Soeren] TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany		Giglou, HB (corresponding author), TIB Leibniz Informat Ctr Sci & Technol, Hannover, Germany.	hamed.babaei@tib.eu; jennifer.dsouza@tib.eu; auer@tib.eu		D'Souza, Jennifer/0000-0002-6616-9509; Auer, Soren/0000-0002-0698-2864; Babaei Giglou, Hamed/0000-0003-3758-1454	German BMBF project SCINEXT [01lS22070]; DFG NFDI4DataScience [460234259]; ERC ScienceGraph [819536]	German BMBF project SCINEXT(Federal Ministry of Education & Research (BMBF)); DFG NFDI4DataScience(German Research Foundation (DFG)); ERC ScienceGraph(European Research Council (ERC))	We thank the anonymous reviewers for their detailed and insightful comments on an earlier draft of the paper. This work was jointly supported by the German BMBF project SCINEXT (ID 01lS22070), DFG NFDI4DataScience (ID 460234259), and ERC ScienceGraph (ID 819536).	Agirre E., 2000, Proceedings of the First International Conference on Ontology Learning, V31, P25; Alfonseca E., 2002, Proceedings of the 1st international conference on general WordNet, P34; Amatriain X, 2024, Arxiv, DOI [arXiv:2302.07730, DOI 10.48550/ARXIV.2302.07730]; Asim MN, 2018, DATABASE-OXFORD, DOI 10.1093/database/bay101; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chung H.W., 2022, SCALING INSTRUCTION; Cui LY, 2021, Arxiv, DOI arXiv:2106.01760; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Dalvi F., 2022, INT C LEARN REPR; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; Dettmers T, 2018, AAAI CONF ARTIF INTE, P1811; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dopazo J, 1997, J MOL EVOL, V44, P226, DOI 10.1007/PL00006139; geonames, 2023, Geonames geographical database; Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081; Guha RV, 2016, COMMUN ACM, V59, P44, DOI 10.1145/2844544; Hahn U., 2001, Proceedings of the First International Conference on Knowledge Capture, P68, DOI 10.1145/500737.500751; Hamp B., 1997, Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications; Hearst MA, 1998, LANG SPEECH & COMMUN, P131; Hwang ChungHee., 1999, Knowledge Representation Meets Databases, P14; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Julliard L., 2000, ECAI WORKSH ONT LEAR; Khan LF, 2002, PROC INT C TOOLS ART, P122, DOI 10.1109/TAI.2002.1180796; Khot T., 2023, Decomposed prompting: A modular approach for solving complex tasks; Kietz J.U., 2000, EKAW 2000 WORKSH ONT; Kojima T., 2023, Large language models are zeroshot reasoners; Konys A, 2019, PROCEDIA COMPUT SCI, V159, P1614, DOI 10.1016/j.procs.2019.09.332; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Levy Omer, 2017, P 21 C COMPUTATIONAL, DOI [DOI 10.18653/V1/K17-1034, 10.18653/v1/K17-1034]; Lewis Mike, 2020, Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Longpre S, 2023, Arxiv, DOI arXiv:2301.13688; Lonsdale D., 2002, P AAAI WORKSH SEM WE; Lourdusamy R., 2020, INTELLIGENT COMPUTIN, V9, P113, DOI 10.1007/978-3-030-38501-9_11; Maedche A, 2001, IEEE INTELL SYST APP, V16, P72, DOI 10.1109/5254.920602; Medicomp Systems, 2023, MEDCIN; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Missikoff M, 2002, LECT NOTES COMPUT SC, V2342, P39; Moldovan D. I., 2001, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V10, P65, DOI 10.1142/S0218213001000428; National Cancer Institute National Institutes of Health, 2022, NCI Thesaurus; Noy Natalya F., 2001, Ontology development 101: A guide to creating your first ontology; OpenAI, 2023, GPT-4 Technical Report; OpenAI, 2023, CHATGPT; Patel-Schneider PF, 2014, LECT NOTES COMPUT SC, V8796, P261, DOI 10.1007/978-3-319-11964-9_17; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Petroni F., 2020, Automated Knowledge Base Construction; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Rebele T, 2016, LECT NOTES COMPUT SC, V9982, P177, DOI 10.1007/978-3-319-46547-0_19; Sajjad H., 2022, Analyzing encoded concepts in transformer language models; SNOMED International, 2023, US Edition of SNOMED CT; Speer R, 2017, AAAI CONF ARTIF INTE, P4444; Srivastava Aarohi, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wagner A., 2000, EC WORKSH ONT LEARN, V61; Watrobski Jaroslaw, 2020, Procedia Computer Science, V176, P3356, DOI 10.1016/j.procs.2020.09.061; Wei J., 2022, INT C LEARN REPR; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Weibel S L., 2000, D-lib magazine, V6, P1082, DOI DOI 10.1045/DECEMBER2000-WEIBEL; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xu F., 2002, LREC; Yang W., 2019, Simple applications of bert for ad hoc document retrieval; Yilmaz ZA, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P19; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754	68	2	2	12	12	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-47239-8; 978-3-031-47240-4	LECT NOTES COMPUT SC			2023	14265						408	427		10.1007/978-3-031-47240-4_22	http://dx.doi.org/10.1007/978-3-031-47240-4_22			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5HL		Green Submitted			2024-07-03	WOS:001160736700022
J	Thik, J; Wang, SW; Wang, CH; Mansourifar, H; Lin, HH; Okubo, K; Ling, C				Thik, Jaydeep; Wang, Siwen; Wang, Chuhong; Mansourifar, Hadi; Lin, Honghong; Okubo, Keiichi; Ling, Chen			Realizing the cooking recipe of materials synthesis through large language models	JOURNAL OF MATERIALS CHEMISTRY A			English	Article								We demonstrate the effective use of large language models to transform chemical synthesis protocols from materials literature into easily understandable step-by-step operations, akin to cooking recipes. This translation offers the potential for implementation in computer-aided experimentation, underscoring the significant promise of large language models in advancing materials research endeavors. LLMs offer a promising and viable direction to convert materials synthesis descriptions into recipe-like outputs effectively preserving the order of synthesis steps. LLMs show true potential to guide experimental design using materials literature.	[Thik, Jaydeep; Wang, Siwen; Wang, Chuhong; Mansourifar, Hadi; Lin, Honghong; Okubo, Keiichi; Ling, Chen] Toyota Motor Engn & Mfg North Amer Inc, 1555 Woodridge Ave, Ann Arbor, MI 48105 USA	Toyota Motor Corporation	Ling, C (corresponding author), Toyota Motor Engn & Mfg North Amer Inc, 1555 Woodridge Ave, Ann Arbor, MI 48105 USA.	chen.ling@toyota.com	Wang, Siwen/KOC-9678-2024	Thik, Jaydeep/0009-0009-0130-6531; Wang, Chuhong/0000-0001-8993-3226	The authors wish to express the appreciation to Mr Makoto Saito and Dr Debasish Banerjee for the support of this work.	The authors wish to express the appreciation to Mr Makoto Saito and Dr Debasish Banerjee for the support of this work.	The authors wish to express the appreciation to Mr Makoto Saito and Dr Debasish Banerjee for the support of this work.	Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2; Choudhary K, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00734-6; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gu GH, 2019, J MATER CHEM A, V7, P17096, DOI 10.1039/c9ta02356a; He TJ, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adg8180; Huang LY, 2019, ACS OMEGA, V4, P18510, DOI 10.1021/acsomega.9b02060; Huo HY, 2022, CHEM MATER, V34, P7323, DOI 10.1021/acs.chemmater.2c01293; Iqbal B, 2020, CLUSTER COMPUT, V23, P397, DOI 10.1007/s10586-019-02929-x; Jensen Z, 2019, ACS CENTRAL SCI, V5, P892, DOI 10.1021/acscentsci.9b00193; Kim E, 2019, MATTER-US, V1, P8, DOI 10.1016/j.matt.2019.05.011; Kim E, 2020, J CHEM INF MODEL, V60, P1194, DOI 10.1021/acs.jcim.9b00995; Kim E, 2017, CHEM MATER, V29, P9436, DOI 10.1021/acs.chemmater.7b03500; Kincaid J. Peter., 1975, 875 I SIM TRAIN, DOI DOI 10.21236/ADA006655; Kuniyoshi F., 2020, P 12 LANGUAGE RESOUR; Kusne AG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19597-w; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Ling C, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00713-x; Liu C, 2020, ADV ENERGY MATER, V10, DOI 10.1002/aenm.201903589; Mahbub R, 2020, ELECTROCHEM COMMUN, V121, DOI 10.1016/j.elecom.2020.106860; Montoya JH, 2022, APPL PHYS REV, V9, DOI 10.1063/5.0076324; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ren ZC, 2023, NAT REV MATER, V8, P563, DOI 10.1038/s41578-023-00588-4; SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175; Stach E, 2021, MATTER-US, V4, P2702, DOI 10.1016/j.matt.2021.06.036; Stein HS, 2019, CHEM SCI, V10, P9640, DOI 10.1039/c9sc03766g; Tabor DP, 2018, NAT REV MATER, V3, P5, DOI 10.1038/s41578-018-0005-z; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Wang ZR, 2022, DIGIT DISCOV, V1, P313, DOI 10.1039/d1dd00034a; Wang ZR, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01317-2; Zhang Y, 2022, ACS CATAL, V12, P10562, DOI 10.1021/acscatal.2c02807; Zhang Y, 2018, NPJ COMPUT MATER, V4, DOI [10.1186/s41016-018-0133-8, 10.1038/s41524-018-0081-z]; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819	35	0	0	35	37	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	2050-7488	2050-7496		J MATER CHEM A	J. Mater. Chem. A	DEC 5	2023	11	47					25849	25853		10.1039/d3ta05457h	http://dx.doi.org/10.1039/d3ta05457h		NOV 2023	5	Chemistry, Physical; Energy & Fuels; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Energy & Fuels; Materials Science	Z5AW1					2024-07-03	WOS:001105699600001
J	Chakraborty, C; Pal, S; Bhattacharya, M; Dash, S; Lee, SS				Chakraborty, Chiranjib; Pal, Soumen; Bhattacharya, Manojit; Dash, Snehasish; Lee, Sang-Soo			Overview of Chatbots with special emphasis on artificial intelligence-enabled ChatGPT in medical science	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Review						ChatGPT; Chatbot; medical use; large language models; AI	PERFORMANCE; GPT-4	The release of ChatGPT has initiated new thinking about AI-based Chatbot and its application and has drawn huge public attention worldwide. Researchers and doctors have started thinking about the promise and application of AI-related large language models in medicine during the past few months. Here, the comprehensive review highlighted the overview of Chatbot and ChatGPT and their current role in medicine. Firstly, the general idea of Chatbots, their evolution, architecture, and medical use are discussed. Secondly, ChatGPT is discussed with special emphasis of its application in medicine, architecture and training methods, medical diagnosis and treatment, research ethical issues, and a comparison of ChatGPT with other NLP models are illustrated. The article also discussed the limitations and prospects of ChatGPT. In the future, these large language models and ChatGPT will have immense promise in healthcare. However, more research is needed in this direction.	[Chakraborty, Chiranjib] Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata, W Bengal, India; [Pal, Soumen; Dash, Snehasish] Vellore Inst Technol, Sch Mech Engn, Vellore, Tamil Nadu, India; [Bhattacharya, Manojit] Fakir Mohan Univ, Dept Zool, Balasore, Orissa, India; [Lee, Sang-Soo] Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chuncheon Si, Gangwon Do, South Korea	Vellore Institute of Technology (VIT); VIT Vellore; Fakir Mohan University; Hallym University	Chakraborty, C (corresponding author), Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata, W Bengal, India.; Lee, SS (corresponding author), Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chuncheon Si, Gangwon Do, South Korea.	drchiranjib@yahoo.com; 123sslee@gmail.com	Bhattacharya, Manojit/A-2027-2012	Bhattacharya, Manojit/0000-0001-9669-1835	This study was supported by Hallym University Research Fund and by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2020R1I1A3074575).; Hallym University Research Fund [NRF-2020R1I1A3074575]; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education	This study was supported by Hallym University Research Fund and by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2020R1I1A3074575).; Hallym University Research Fund; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education(National Research Foundation of KoreaMinistry of Education (MOE), Republic of KoreaNational Research Council for Economics, Humanities & Social Sciences, Republic of Korea)	This study was supported by Hallym University Research Fund and by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF-2020R1I1A3074575).	Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Adamopoulou E, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100006; Aggarwal N., 2021, Bioethics, V1, P1, DOI DOI 10.5772/INTECHOPEN.96122; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alturaiki AM, 2022, INT J TELEMED APPL, V2022, DOI 10.1155/2022/9734518; An JF, 2023, NATURE, V615, P586, DOI 10.1038/d41586-023-00843-2; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Anmella G, 2023, J MED INTERNET RES, V25, DOI 10.2196/43293; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Asensio-Cuesta S, 2021, JMIR MED INF, V9, DOI 10.2196/17503; Yeung JA, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1161098; Boggiss Anna, 2023, JMIR Diabetes, V8, pe40641, DOI 10.2196/40641; Brandtzaeg P.B., 2017, WHY PEOPLE USE CHATB; Castagna F, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1045614; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Chaix B, 2022, DIGIT HEALTH, V8, DOI 10.1177/20552076221097783; Chang IC, 2022, INT J MED INFORM, V165, DOI 10.1016/j.ijmedinf.2022.104827; Chatterjee S, 2023, MOL THER-NUCL ACIDS, V33, P205, DOI 10.1016/j.omtn.2023.06.019; Chen JS, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.906554; Cherubini A, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10040404; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; Cocci A, 2024, PROSTATE CANCER P D, V27, P103, DOI 10.1038/s41391-023-00705-y; COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6; Corsello A, 2023, CHILDREN-BASEL, V10, DOI 10.3390/children10040757; Currie G, 2023, RADIOGRAPHY, V29, P792, DOI 10.1016/j.radi.2023.05.011; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243; Darkhabani M, 2023, AUTOIMMUN REV, V22, DOI 10.1016/j.autrev.2023.103360; Das KP, 2023, ENERGY NEXUS, V9, DOI 10.1016/j.nexus.2022.100167; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Dossantos J, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40765; Fayed AM, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00642-8; Ferres JML, 2023, DIAGN INTERV IMAG, V104, P263, DOI 10.1016/j.diii.2023.02.006; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goldenthal Steven B, 2019, Mhealth, V5, P8, DOI 10.21037/mhealth.2019.03.01; Graber-Stiehl I, 2023, NATURE, V617, P22, DOI 10.1038/d41586-023-01473-4; Grodniewicz JP, 2023, AM J BIOETHICS, V23, P59, DOI 10.1080/15265161.2023.2191021; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Haman M, 2023, ANN BIOMED ENG, V51, P2362, DOI 10.1007/s10439-023-03269-z; Handelman GS, 2019, AM J ROENTGENOL, V212, P38, DOI 10.2214/AJR.18.20224; Haque MDR, 2023, JMIR MHEALTH UHEALTH, V11, DOI 10.2196/44838; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Heck TG, 2023, CELL STRESS CHAPERON, V28, P225, DOI 10.1007/s12192-023-01340-1; Huang JT, 2023, J DIABETES SCI TECHN, V17, P853, DOI 10.1177/19322968231161095; Huang Y., 2023, Benchmarking ChatGPT-4 on ACR radiation oncology in-training (TXIT) exam and red journal gray zone cases: Potentials and challenges for AI-assisted medical education and decision making in radiation oncology, DOI [10.2139/ssrn.4457218, DOI 10.2139/SSRN.4457218]; Hughes KS, 2020, BREAST J, V26, P92, DOI 10.1111/tbj.13718; Hügle T, 2023, RMD OPEN, V9, DOI 10.1136/rmdopen-2023-003105; Huh S, 2023, J KOREAN MED ASSOC, V66, P218, DOI 10.5124/jkma.2023.66.4.218; Iversen HH, 2014, BMJ OPEN, V4, DOI 10.1136/bmjopen-2014-004848; Jackson-Triche M, 2023, J MED INTERNET RES, V25, DOI 10.2196/40635; Jalil S., 2023, ChatGPT and Software Testing Education: Promises and Perils; Janamala V, 2023, ANN BIOMED ENG, V51, P2337, DOI 10.1007/s10439-023-03257-3; Jang ME, 2023, Arxiv, DOI arXiv:2303.06273; Jeblick K, 2023, EUR RADIOL, DOI 10.1007/s00330-023-10213-1; Jiang Shi-Tao, 2023, Radiology, V308, pe231335, DOI 10.1148/radiol.231335; Kadariya D, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2019), P138, DOI [10.1109/SMARTCOMP.2019.00043, 10.1109/smartcomp.2019.00043]; Kashefi A., 2023, Journal of Machine Learning for Modeling and Computing, V4, P1, DOI DOI 10.1615/JMACHLEARNMODELCOMPUT.2023048492; Kataoka Y, 2021, JMIR CANCER, V7, DOI 10.2196/26911; Khan A, 2023, CANCER PREV RES, V16, DOI 10.1158/1940-6215.PrecPrev22-P068; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Khondaker MTI, 2023, Arxiv, DOI arXiv:2305.14976; Kidwai B, 2020, PROCEDIA COMPUT SCI, V167, P75, DOI 10.1016/j.procs.2020.03.184; Kim AJ, 2021, JMIR MHEALTH UHEALTH, V9, DOI 10.2196/26424; King MR, 2023, ANN BIOMED ENG, V51, P291, DOI 10.1007/s10439-022-03121-w; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Lai HY, 2023, Arxiv, DOI arXiv:2304.13462; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Lennon RP, 2022, J AM BOARD FAM MED, V35, P1230, DOI 10.3122/jabfm.2022.220208R1; Leuck J. A., 2013, Simulat. Healthcare, V8, P558, DOI [10.1097/01.SIH.0000441623.38455.9a, DOI 10.1097/01.SIH.0000441623.38455.9A]; Li WB, 2023, ANN BIOMED ENG, V51, P1892, DOI 10.1007/s10439-023-03232-y; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liang Y., 2023, DrugChat: Towards Enabling ChatGPT-Like Capabilities on Drug Molecule Graphs, DOI [10.36227/techrxiv.22945922.v1, DOI 10.36227/TECHRXIV.22945922.V1]; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Loh E, 2024, BMJ LEAD, V8, P51, DOI 10.1136/leader-2023-000797; Lu Y, 2023, AM J AUDIOL, V32, P972, DOI [10.1007/s10439-023-03234-w, 10.1044/2023_AJA-23-00069, 10.1063/5.0112732, 10.1079/9781800621954.0001]; Ma C, 2024, Arxiv, DOI arXiv:2304.08448; Mahtani AU, 2023, ACAD MED, V98, P1018, DOI 10.1097/ACM.0000000000005210; Marietto M., 2013, International Journal of Computer Science and Engineering Survey, V04, DOI [10.5121/ijcses.2013.4301, DOI 10.5121/IJCSES.2013.4301]; Meck C., 2023, ChatGPT AI Shines in Challenging Medical Cases; Moilanen J, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1034724; Mokmin NAM, 2021, EDUC INF TECHNOL, V26, P6033, DOI 10.1007/s10639-021-10542-y; Mollaei N, 2022, BIOSIGNALS: PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL 4: BIOSIGNALS, P159, DOI 10.5220/0010819500003123; Moutsana Tapolin F., 2023, Stu. Health Technol. Inf, V305, P483, DOI [10.3233/SHTI230538, DOI 10.3233/SHTI230538]; Nakaya Y, 2023, EUR HEART J-DIGIT HL, V4, P141, DOI 10.1093/ehjdh/ztad026; Nazareth S, 2021, OBSTET GYNECOL, V138, P860, DOI 10.1097/AOG.0000000000004596; Nicol G, 2022, JMIR FORM RES, V6, DOI 10.2196/40242; Numan N., 2023, 2023 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW); Ogilvie L, 2022, EUR ADDICT RES, V28, P405, DOI 10.1159/000525959; Okonkwo Chinedu Wilfred, 2022, JMIR Form Res, V6, pe39157, DOI 10.2196/39157; Ovalle A, 2023, Arxiv, DOI arXiv:2306.05552; Page AJ, 2023, MICROB GENOMICS, V9, DOI 10.1099/mgen.0.001049; Pal S, 2024, ANN BIOMED ENG, V52, P451, DOI 10.1007/s10439-023-03306-x; Parviainen J, 2022, MED HEALTH CARE PHIL, V25, P61, DOI 10.1007/s11019-021-10049-w; Payton E, 2017, J COMMUN HEALTH, V42, P1118, DOI 10.1007/s10900-017-0360-5; Pennestrì F, 2022, CLIN CHEM LAB MED, V60, P1867, DOI 10.1515/cclm-2022-0096; Perkel JM, 2023, NATURE, V618, P422, DOI 10.1038/d41586-023-01833-0; Pham KT, 2022, PSYCHIAT QUART, V93, P249, DOI 10.1007/s11126-022-09973-8; Ray PP, 2023, SCI TOTAL ENVIRON, V892, DOI 10.1016/j.scitotenv.2023.164638; Reis LO, 2023, INT BRAZ J UROL, V49, P652, DOI 10.1590/S1677-5538.IBJU.2023.0112; Rizzato Lede Daniel A, 2022, Stud Health Technol Inform, V290, P301, DOI 10.3233/SHTI220083; Roberts V, 2020, MED EDUC ONLINE, V25, DOI 10.1080/10872981.2020.1772014; Sabour S, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1133987; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Saedi S., 2021, Caspian J. Int. Med; Safi Z, 2020, J MED INTERNET RES, V22, DOI 10.2196/19127; Salzman DH, 2018, SIMUL HEALTHC, V13, P348, DOI 10.1097/SIH.0000000000000291; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Savage N, 2023, NAT BIOTECHNOL, V41, P585, DOI 10.1038/s41587-023-01788-7; Schick A, 2022, JMIR MHEALTH UHEALTH, V10, DOI 10.2196/28082; Schillings C, 2023, FRONT DIGIT HEALTH, V5, DOI 10.3389/fdgth.2023.1046202; Schmidlen T, 2022, J GENET COUNS, V31, P1219, DOI 10.1002/jgc4.1592; Sedaghat S, 2023, CLIN MED, V23, P278, DOI 10.7861/clinmed.2023-0078; Sharma D., 2022, 2022 4th International Conference on Artificial Intelligence and Speech Technology (AIST), P1; Shoaib Muhammad Ali, 2023, Comput Intell Neurosci, V2023, P4208231, DOI 10.1155/2023/4208231; Siglen E, 2022, PATIENT EDUC COUNS, V105, P1488, DOI 10.1016/j.pec.2021.09.027; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Smutny P, 2020, COMPUT EDUC, V151, DOI 10.1016/j.compedu.2020.103862; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Statista, 2023, Size of the Chatbot Market Worldwide From 2021 to 2030; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Suta P., 2020, Int. J. Mech. Eng. Robot. Res, V9, P502, DOI DOI 10.18178/IJMERR.9.4.502-510; Tampuu A, 2022, IEEE T NEUR NET LEAR, V33, P1364, DOI 10.1109/TNNLS.2020.3043505; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Vat LE, 2021, HEALTH EXPECT, V24, P491, DOI 10.1111/hex.13191; Wang LY, 2023, Arxiv, DOI [arXiv:2304.02210, 10.48550/arXiv.2304.02210]; Wang R, 2023, Arxiv, DOI arXiv:2308.06920; Wang YM, 2023, J CHIN MED ASSOC, V86, P653, DOI 10.1097/JCMA.0000000000000942; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1207; Wolf RM, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00605-w; Xu L, 2021, JMIR CANCER, V7, DOI 10.2196/27850; Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Yang Hong, 2023, Nature, DOI 10.1038/d41586-023-01026-9; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zador A, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37180-x; Zhang TT, 2022, EVID-BASED COMPL ALT, V2022, DOI 10.1155/2022/1679589; Zhao AL, 2023, FRONT PHARMACOL, V14, DOI 10.3389/fphar.2023.1194216	145	9	9	30	34	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	OCT 31	2023	6								1237704	10.3389/frai.2023.1237704	http://dx.doi.org/10.3389/frai.2023.1237704			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	X9NF4	38028668	gold, Green Published			2024-07-03	WOS:001101628500001
J	Schindler, C; Rausch, A				Schindler, Christian; Rausch, Andreas			Formal Software Architecture Rule Learning: A Comparative Investigation between Large Language Models and Inductive Techniques	ELECTRONICS			English	Article						software architecture; Inductive Rule Learning; constraint learning; first-order logic; Large Language Models		This paper explores the application of inferring software architecture rules from examples using Machine Learning (ML). We investigate different methods from Inductive Rule Learning and utilize Large Language Models (LLMs). Traditional manual rule specification approaches are time-consuming and error-prone, motivating the need for automated rule discovery. Leveraging a dataset of software architecture instances and a meta-model capturing implementation facts, we used inductive learning algorithms and LLMs to extract meaningful rules. The induced rules are evaluated against a predefined hypothesis and their generalizability across different system subsets is investigated. The research highlights the capabilities and limitations of ML-based rule learning in the area of software architecture, aiming to inspire further innovation in data-driven rule discovery for more intelligent software architecture practices.	[Schindler, Christian; Rausch, Andreas] Tech Univ Clausthal, Inst Software & Syst Engn, D-38678 Clausthal Zellerfeld, Germany	TU Clausthal	Schindler, C (corresponding author), Tech Univ Clausthal, Inst Software & Syst Engn, D-38678 Clausthal Zellerfeld, Germany.	christian.schindler@tu-clausthal.de		Rausch, Andreas/0000-0002-6850-6409				Achiam J., 2023, GPT-4 Technical Report; Ali M, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6277; [Anonymous], TEAMMATES-Online Peer Feedback/Evaluation System for Student Team Projects; Bosch J, 1999, ECBS '99, IEEE CONFERENCE AND WORKSHOP ON ENGINEERING OF COMPUTER-BASED SYSTEMS, PROCEEDINGS, P4, DOI 10.1109/ECBS.1999.755855; Bowen JP, 2001, FACIT, P3; Brants T., 2007, P 2007 JOINT C EMP M, P858; Cervantes H., 2016, Designing software architectures: a practical approach; Chen WH, 2022, Arxiv, DOI arXiv:2210.06710; Cropper A, 2022, J ARTIF INTELL RES, V74, P765; Cropper A, 2021, MACH LEARN, V110, P801, DOI 10.1007/s10994-020-05934-z; Cunnington D, 2024, Arxiv, DOI arXiv:2205.12735; Dai W.-Z., 2021, IJCAI, P1845, DOI DOI 10.24963/IJCAI.2021/254; Deiters C, 2009, IEEE INT ENTERP DIST, P183, DOI 10.1109/EDOC.2009.15; Fan LZ, 2023, Arxiv, DOI [arXiv:2304.02020, DOI 10.48550/ARXIV.2304.02020]; Feiler P. H., 2012, Model-based engineering with AADL: an introduction to the SAE architecture analysis & design language; Feiler PH, 2004, INT FED INFO PROC, V176, P3; Fu YJ, 2006, INT CONF QUAL SOFTW, P57; Galarraga L.A., 2013, WWW 13, P413, DOI DOI 10.1145/2488388.2488425; Gamble RF, 1999, KNOWL-BASED SYST, V12, P13, DOI 10.1016/S0950-7051(99)00004-0; Gill A.S., 2023, P INT DES ENG TECHN; Gomez-Cano C., 2023, Metaverse Basic and Applied Research, V2, P33, DOI [10.56294/mr202333, DOI 10.56294/MR202333]; Gottlob G., 1997, Inductive Logic Programming. 7th International Workshop, ILP-97 Proceedings, P17; Herold S., 2017, SAEroConRepo; Heyman T., 2010, 2010 IEEE Proceedings of 34th Annual Computer Software and Applications Conference (COMPSAC 2010), P161, DOI 10.1109/COMPSAC.2010.23; Jackson D, 2002, ACM T SOFTW ENG METH, V11, P256, DOI 10.1145/505145.505149; Kherbouche M., 2020, P MOD PROGR 2 INT WO, P127; Komolov S, 2022, COMPUTERS, V11, DOI 10.3390/computers11100151; Lajus J, 2020, LECT NOTES COMPUT SC, V12123, P36, DOI 10.1007/978-3-030-49461-2_3; Law M, 2020, Arxiv, DOI arXiv:2005.00904; Liao L., 2002, From Requirements to Architecture: The State of the Art in Software Architecture Design, P1; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Maffort C., 2013, P INT C SOFTW ENG KN; Manyika J., An overview of Bard: An Early Experiment with Generative AI; Meilicke C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3137; Pruijt L, 2016, FIRST WORKSHOP ON QUALITATIVE REASONING ABOUT SOFTWARE ARCHITECTURES: QRASA 2016, P1, DOI 10.1109/QRASA.2016.7; Quinlan J.R., 1993, P MACH LEARN ECML 93, P1; Schindler C., 2024, P 57 ANN HAW INT C S, P7302; Schindler M., 2023, Int. J. Adv. Softw, V16, P1; Schröder S, 2019, 13TH EUROPEAN CONFERENCE ON SOFTWARE ARCHITECTURE (ECSA 2019), VOL 2, P10, DOI 10.1145/3344948.3344956; Singh R., 2013, Int. J. Eng. Sci. Invent, V2, P35; Srinivasan A., 2001, The aleph manual; Stringfellow C, 2006, INFORM SOFTWARE TECH, V48, P484, DOI 10.1016/j.infsof.2005.05.007; Tibermacine C., 2011, P 14 INT ACM SIGS S, P31; van Vliet H, 2016, J SYST SOFTWARE, V117, P638, DOI 10.1016/j.jss.2016.01.017; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhu Q., 2022, Proceedings of the Design Society, V2, P1825, DOI [DOI 10.1017/PDS.2022.185, https://doi.org/10.1017/pds.2022.185]	48	0	0	1	1	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	MAR	2024	13	5							816	10.3390/electronics13050816	http://dx.doi.org/10.3390/electronics13050816			20	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	KV4Z9		gold			2024-07-03	WOS:001182738700001
J	Daungsupawong, H; Wiwanitkit, V				Daungsupawong, Hinpetch; Wiwanitkit, Viroj			ChatGPT and Gemini large language models for pharmacometrics with NONMEM: comment	JOURNAL OF PHARMACOKINETICS AND PHARMACODYNAMICS			English	Letter; Early Access						ChatGPT; Pharmacometrics; Model		This is a correspondence on "Evaluation of ChatGPT and Gemini large language models for pharmacometrics with NONMEM". Additional concern on using ChatGPT and Gemini is provided.	[Daungsupawong, Hinpetch] Lao Peoples Democrat Republ, Phonhong, Laos; [Wiwanitkit, Viroj] Saveetha Inst Med & Tech Sci, Saveetha Med Coll, Chennai, India	Saveetha Institute of Medical & Technical Science; Saveetha Medical College & Hospital	Daungsupawong, H (corresponding author), Lao Peoples Democrat Republ, Phonhong, Laos.	hinpetchdaung@gmail.com		wiwanitkit, viroj/0000-0003-1039-3728				Shin E, 2024, J PHARMACOKINET PHAR, V51, P187, DOI 10.1007/s10928-024-09921-y	1	0	0	2	2	SPRINGER/PLENUM PUBLISHERS	NEW YORK	233 SPRING ST, NEW YORK, NY 10013 USA	1567-567X	1573-8744		J PHARMACOKINET PHAR	J. Pharmacokinet. Pharmacodyn.	2024 MAY 25	2024										10.1007/s10928-024-09926-7	http://dx.doi.org/10.1007/s10928-024-09926-7		MAY 2024	2	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	SL4J7	38795226				2024-07-03	WOS:001234592400001
C	Prakash, MVS; Parab, G; Veeramalla, M; Reddy, S; Varun, V; Gopalakrishnan, S; Pagidipally, V; Vaddina, V			Assoc computing machinery	Prakash, Mukkamala Venkata Sai; Parab, Ganesh; Veeramalla, Meghana; Reddy, Siddartha; Varun, V.; Gopalakrishnan, Saisubramaniam; Pagidipally, Vishal; Vaddina, Vishal			Accelerating Pharmacovigilance using Large Language Models	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Large Language Models; Pharmacovigilance; Deep Learning		Pharmacovigilance is the practice of monitoring, assessing, and preventing adverse effects or any other drug-related problems. Pharmacovigilance ensures the post-market safety of pharmaceuticals and plays a crucial role in public health by enhancing drug safety. This discipline involves collecting, analyzing, and reporting data on adverse events, allowing for informed regulatory decisions. Manual systems face challenges in handling data volume, potentially leading to oversight and delays. Automation with advanced technologies can be a practical solution to mitigate these challenges and ensure efficient data management. In this talk, we explain the potential application of Large Language Models (LLMs) in pharmacovigilance. We begin with an overview of the process, covering all the stages of the lifecycle. We emphasize the pivotal process of scrutinizing documents for relevant adverse effects and elucidate the measures that enhance their effectiveness. We delineate our strategy for generating informative summaries, with a specific emphasis on adverse effects and their antecedent occurrences. We emphasize the imperative requirement for factual accuracy validation via the implementation of a fact-checking mechanism. We demonstrate the framework's efficacy with a focus on output fidelity and summary informativeness. We provide quantifiable evidence of the benefits of our method, advocating for the adoption of our framework in pharmacovigilance, and conclude by addressing potential refinements.	[Prakash, Mukkamala Venkata Sai; Gopalakrishnan, Saisubramaniam] Quantiphi Analyt Solut Pvt Ltd, Appl Res, Bengaluru, India; [Parab, Ganesh; Veeramalla, Meghana; Reddy, Siddartha; Varun, V.; Pagidipally, Vishal; Vaddina, Vishal] Quantiphi Analyt Solut Pvt Ltd, Bengaluru, India		Prakash, MVS (corresponding author), Quantiphi Analyt Solut Pvt Ltd, Appl Res, Bengaluru, India.; Vaddina, V (corresponding author), Quantiphi Analyt Solut Pvt Ltd, Bengaluru, India.	mukkamala.prakash@quantiphi.com; vishal.vaddina@quantiphi.com		Veeramalla, Meghana/0009-0003-1440-6271				Beninger P, 2018, CLIN THER, V40, P1991, DOI 10.1016/j.clinthera.2018.07.012; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Devlin Jacob, 2019, P NAACLHLT, V1; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Song K., 2020, Adv. Neural Inf. Process. Syst, V33, P16857, DOI DOI 10.48550/ARXIV.2004.09297; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wei JS, 2022, ADV NEUR IN; World Health Organization, 2002, The Importance of Pharmacovigilance. Safety Monitoring of Medicinal Products	9	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1182	1183		10.1145/3616855.3635741	http://dx.doi.org/10.1145/3616855.3635741			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100159
J	Cheng, J				Cheng, Jerome			Applications of Large Language Models in Pathology	BIOENGINEERING-BASEL			English	Review						large language model; generative pretrained transformer; bidirectional encoder representations from transformers; artificial intelligence; natural language processing; GPT; BERT; Mistral; Llama; Gemma; surgical pathology		Large language models (LLMs) are transformer-based neural networks that can provide human-like responses to questions and instructions. LLMs can generate educational material, summarize text, extract structured data from free text, create reports, write programs, and potentially assist in case sign-out. LLMs combined with vision models can assist in interpreting histopathology images. LLMs have immense potential in transforming pathology practice and education, but these models are not infallible, so any artificial intelligence generated content must be verified with reputable sources. Caution must be exercised on how these models are integrated into clinical practice, as these models can produce hallucinations and incorrect results, and an over-reliance on artificial intelligence may lead to de-skilling and automation bias. This review paper provides a brief history of LLMs and highlights several use cases for LLMs in the field of pathology.	[Cheng, Jerome] Univ Michigan, Dept Pathol, Ann Arbor, MI 48105 USA	University of Michigan System; University of Michigan	Cheng, J (corresponding author), Univ Michigan, Dept Pathol, Ann Arbor, MI 48105 USA.	jeromech@med.umich.edu		Cheng, Jerome/0000-0001-8949-7006				Abdullahi T, 2024, JMIR MED EDUC, V10, DOI 10.2196/51391; Agarwal A, 2024, Arxiv, DOI arXiv:2402.14261; Baktash JA, 2023, Arxiv, DOI arXiv:2305.03195; Berbís MA, 2023, EBIOMEDICINE, V88, DOI 10.1016/j.ebiom.2022.104427; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Blumenthal W, 2020, J AM MED INFORM ASSN, V27, P1488, DOI 10.1093/jamia/ocaa149; Briganti G, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08337-7; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Cheng Jerome, 2022, J Pathol Inform, V13, P100008, DOI 10.1016/j.jpi.2022.100008; Cheng JY, 2021, AM J PATHOL, V191, P1684, DOI 10.1016/j.ajpath.2020.10.018; Cheng SL, 2023, J MED INTERNET RES, V25, DOI 10.2196/51229; Cheng SW, 2023, PSYCHIAT CLIN NEUROS, V77, P592, DOI 10.1111/pcn.13588; Choi HS, 2023, RADIAT ONCOL J, V41, P209, DOI 10.3857/roj.2023.00633; Coello C.E.A., 2024, Digital, V4, P114, DOI [10.3390/digital4010005, DOI 10.3390/DIGITAL4010005]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Emmert-Streib F, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.524339; Evans H, 2024, HISTOPATHOLOGY, V84, P279, DOI 10.1111/his.15071; Fang L., 2022, arXiv:2204.06758v1; Fijacko N, 2024, RESUSC PLUS, V18, DOI 10.1016/j.resplu.2024.100584; Fogo AB, 2024, JAMA-J AM MED ASSOC, V331, P471, DOI 10.1001/jama.2024.0018; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gao S, 2021, IEEE J BIOMED HEALTH, V25, P3596, DOI 10.1109/JBHI.2021.3062322; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Ge Jin, 2023, medRxiv, DOI 10.1101/2023.11.10.23298364; Ge Jin, 2023, medRxiv, DOI 10.1101/2023.08.31.23294924; Geetha SD, 2024, AM J CLIN PATHOL, V161, P393, DOI 10.1093/ajcp/aqad158; Geiping J., 2023, P INT C MACHINE LEAR; Ghinassi I, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1593; Gordon ER, 2024, BRIT J DERMATOL, V190, P789, DOI 10.1093/bjd/ljae040; Grewal H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40135; Gutierrez-Cirlos Carlos, 2023, Gac Med Mex, V159, P372, DOI 10.24875/GMM.M23000811; Hart Steven N, 2023, J Pathol Inform, V14, P100338, DOI 10.1016/j.jpi.2023.100338; Hellas A, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P93, DOI 10.1145/3568813.3600139; Hurley NC, 2023, TRANSFUSION, V63, P1833, DOI 10.1111/trf.17526; Ibrahim RB, 2023, ANN CLIN LAB SCI, V53, P835; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kefeli Jenna, 2023, medRxiv, DOI 10.1101/2023.08.03.23293618; Kefeli Jenna, 2023, medRxiv, DOI 10.1101/2023.06.26.23291912; King MR, 2024, CELL MOL BIOENG, V17, P1, DOI 10.1007/s12195-024-00793-3; Kojima Takeshi., 2023, Adv. Neural Inf. Process. Syst, V35, P22199; Kumari A, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43861; Laohawetwanit T, 2024, J CLIN PATHOL, DOI 10.1136/jcp-2023-209304; Lee DT, 2023, medRxiv, DOI [10.1101/2023.11.08.23298252, 10.1101/2023.11.08.23298252, DOI 10.1101/2023.11.08.23298252]; Levy Joshua, 2022, J Pathol Inform, V13, P3, DOI 10.4103/jpi.jpi_52_21; Leypold T, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000005471; Liu JX, 2023, J MED INTERNET RES, V25, DOI 10.2196/48145; Lu MY, 2023, Arxiv, DOI [arXiv:2312.07814, 10.48550/arxiv.2312.07814]; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mitchell JR, 2022, J MED INTERNET RES, V24, DOI 10.2196/27210; Mojadeddi ZM, 2023, NEW ZEAL MED J, V136, P60; Montenegro-Rueda M, 2023, COMPUTERS, V12, DOI 10.3390/computers12080153; Mu YQ, 2021, COMMUN MED-LONDON, V1, DOI 10.1038/s43856-021-00008-0; Munoz-Zuluaga C, 2023, CLIN CHEM, V69, P939, DOI 10.1093/clinchem/hvad058; Naik HR, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37587; Nakagawa K, 2023, SEMIN DIAGN PATHOL, V40, P100, DOI 10.1053/j.semdp.2023.02.006; Ngo A, 2024, ACAD PATHOL, V11, DOI 10.1016/j.acpath.2023.100099; Nguyen T, 2024, JMIR MED EDUC, V10, DOI 10.2196/50174; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Peacock Justin, 2023, MedEdPublish (2016), V13, P64, DOI 10.12688/mep.19732.2; Polak MP, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-45914-8; Poldrack RA, 2023, Arxiv, DOI [arXiv:2304.13187, DOI 10.48550/ARXIV.2304.13187, 10.48550/arXiv.2304.13187]; Radford A, 2021, PR MACH LEARN RES, V139; Rao DVY, 2023, INDIAN J OTOLARYNGOL, V75, P2638, DOI 10.1007/s12070-023-03755-9; Rashidi Hooman H, 2023, J Pathol Inform, V14, P100342, DOI 10.1016/j.jpi.2023.100342; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Russe MF, 2024, ROFO-FORTSCHR RONTG, DOI 10.1055/a-2264-5631; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.50629; Santos T., 2022, P AMIA ANN S P; Schadow Gunther, 2003, AMIA Annu Symp Proc, P584; Schukow C, 2024, ADV ANAT PATHOL, V31, P15, DOI 10.1097/PAP.0000000000000406; Sengupta S, 2024, Arxiv, DOI arXiv:2312.01435; Shafi S, 2023, DIAGN PATHOL, V18, DOI 10.1186/s13000-023-01375-z; Shah A, 2024, DERMATOPATHOL-BASEL, V11, P101, DOI 10.3390/dermatopathology11010009; Sievert M, 2024, EUR ARCH OTO-RHINO-L, V281, P2115, DOI 10.1007/s00405-024-08476-5; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Spies NC, 2023, J APPL LAB MED, V8, P1092, DOI 10.1093/jalm/jfad058; Stephens LD, 2023, TRANSFUSION, V63, P1110, DOI 10.1111/trf.17385; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sun Y., 2024, P AAAI C ARTIFICIAL; Sushil Madhumita, 2024, Res Sq, DOI 10.21203/rs.3.rs-3914899/v1; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Truhn D, 2024, J PATHOL, V262, P310, DOI 10.1002/path.6232; Tsuneki M., 2022, P INT C MEDICAL IMAG; Ullah E, 2024, DIAGN PATHOL, V19, DOI 10.1186/s13000-024-01464-7; Unlu Ozan, 2024, medRxiv, DOI 10.1101/2024.02.08.24302376; Vaswani A, 2017, ADV NEUR IN, V30; Vithanage D, 2024, J HEALTHC INFORM RES, V8, P158, DOI 10.1007/s41666-023-00157-y; Wang Andrew Y, 2024, Arch Pathol Lab Med, DOI 10.5858/arpa.2023-0296-OA; Wang L, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01029-4; Wang YC, 2023, Arxiv, DOI arXiv:2306.07500; Wei WI, 2024, CLIN MICROBIOL INFEC, V30, p142e1, DOI 10.1016/j.cmi.2023.11.002; Wu J., 2023, P 2023 IEEE INT C BI; Xu Y, 2014, MED IMAGE ANAL, V18, P591, DOI 10.1016/j.media.2014.01.010; Yan WX, 2023, Arxiv, DOI arXiv:2310.04951; Yang HS, 2023, CLIN CHEM, V69, P1238, DOI 10.1093/clinchem/hvad106; Yang TC, 2024, PEERJ COMPUT SCI, V10, DOI 10.7717/peerj-cs.1888; Yang WH, 2024, J CHIN MED ASSOC, V87, P428, DOI 10.1097/JCMA.0000000000001071; Yenduri G, 2023, Arxiv, DOI [arXiv:2305.10435, 10.1109/ACCESS.2024.3389497, DOI 10.1109/ACCESS.2024.3389497]; Yu H, 2024, HELIYON, V10, DOI 10.1016/j.heliyon.2024.e24289; Zang YH, 2023, Arxiv, DOI arXiv:2305.18279; Zeng Ken G, 2023, Res Sq, DOI 10.21203/rs.3.rs-3035772/v1; Zhang PY, 2024, Arxiv, DOI arXiv:2401.02385; Zhang Xiaodan, 2024, medRxiv, DOI 10.1101/2024.02.07.24302444; Zhang XH, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103985; Zhang YK, 2024, Arxiv, DOI [arXiv:2401.02458, 10.48550/arXiv.2401.02458, DOI 10.48550/ARXIV.2401.02458]; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589	111	1	1	8	8	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2306-5354		BIOENGINEERING-BASEL	Bioengineering-Basel	APR	2024	11	4							342	10.3390/bioengineering11040342	http://dx.doi.org/10.3390/bioengineering11040342			13	Biotechnology & Applied Microbiology; Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology; Engineering	OY0N7	38671764	Green Published, gold			2024-07-03	WOS:001210721200001
C	Happe, A; Cito, J		Chandra, S; Blincoe, K; Tonella, P		Happe, Andreas; Cito, Juergen			Getting pwn'd by AI: Penetration Testing with Large Language Models	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		security testing; penetration testing; large language models		The field of software security testing, more specifically penetration testing, requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential use of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of AI sparring partners.	[Happe, Andreas; Cito, Juergen] TU Wien, Vienna, Austria	Technische Universitat Wien	Happe, A (corresponding author), TU Wien, Vienna, Austria.	andreas.happe@tuwien.ac.at; juergen.cito@tuwien.ac.at		Happe, Andreas/0009-0000-2484-0109				AIAAIC, 2023, AIAAIC Repository of incidents and controversies related to AI, algorithms and automation; [Anonymous], 2023, The Economist; [Anonymous], 2022, The Economist; Beeching Edward, 2023, StackLLaMA: An RL Finetuned LLaMA Model for Stack Exchange Question and Answering, DOI DOI 10.57967/HF/0513; Brynjolfsson E., 2023, AUGMENTED ED GLOBAL, P103; Brynjolfsson E., 2023, NBER Working Paper No. 31161; Bukac V, 2014, LECT NOTES COMPUT SC, V8809, P55, DOI 10.1007/978-3-319-12400-1_7; Conover M., 2023, Free Dolly: Introducing the world's first truly open instructiontuned LLM; Cybereason Global SOC and Incident Response Team, 2023, Sliver C2 Leveraged by Many Threat Actors; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Geng X., 2023, Blog post; Gerganov Georgi, 2023, llama.cpp: Inference of LLaMA model in pure C/C++; Happe Andreas, 2023, P 31 ACM JOINT EUROP; Harang Richard, 2018, Measuring the speed of the Red Queen's Race; ISC, 2022, ISC)2 CYBERSECURITY WORKFORCE STUDY 2022; Lake Sydney, 2022, The cybersecurity industry is short 3.4 million workersthat's good news for cyber wages; Larson Selena, 2021, Cobalt Strike: Favorite Tool from APT to Crimeware; lin.security, 2018, Lin.Security: 1; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Maslej N., 2023, INDEX 2023 ANN REPOR; Miller Ron, 2023, Sam Altman: Size of LLMs won't matter as much moving forward; MITRE ATT&CK, 2020, Abuse Elevation Control Mechanism: Sudo and Sudo Caching; MITRE ATT&CK, 2020, Steal or Forge Kerberos Tickets: Kerberoasting; Nakajima Yohei, 2023, Task-driven autonomous agent utilizing gpt-4, pinecone, and langchain for diverse applications; Nakajima Yohei, 2023, Introducing Task-driven Autonomous Agent; Nakajima Yohei, 2023, Babyagi; Park JS, 2023, Arxiv, DOI [arXiv:2304.03442, DOI 10.48550/ARXIV.2304.03442, 10.48550/arXiv.2304.03442]; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Polop Carlos, 2023, LinPEAS-Linux Privilege Escalation Awesome Script; Quach Katyanna, 2023, LLaMA drama as Meta's mega language model leaks; Schaul Kevin, 2023, Inside the secret list of websites that make AI like ChatGPT sound smart; Shen YL, 2023, Arxiv, DOI [arXiv:2303.17580, 10.48550/arXiv.2303.17580, DOI 10.48550/ARXIV.2303.17580]; Significant-Gravitas, 2023, AUTOGPT AUTONOMOUS G; stability.ai, 2023, Stability AI Launches the First of its StableLM Suite of Language Models; Strobelt Hendrik, 2023, IEEE Trans Vis Comput Graph, V29, P1146, DOI 10.1109/TVCG.2022.3209479; Strom BE, 2018, MITRE ATT CK DESIGN; The Wassenaar Arrangement, 1982, The Wassenaar Arrangement on Export Controls for Conventional Arms and Dual-Use Goods and Technologies; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zhou KY, 2022, INT J COMPUT VISION, V130, P2337, DOI 10.1007/s11263-022-01653-1	40	1	1	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							2082	2086		10.1145/3611643.3613083	http://dx.doi.org/10.1145/3611643.3613083			5	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted, hybrid			2024-07-03	WOS:001148157800175
J	Omizo, RM				Omizo, Ryan M.			Automating Research in Business and Technical Communication: Large Language Models as Qualitative Coders	JOURNAL OF BUSINESS AND TECHNICAL COMMUNICATION			English	Article						AI; large language models; move analysis; rhetorical genre studies; qualitative coding	GENRE	The emergence of large language models (LLMs) has disrupted approaches to writing in academic and professional contexts. While much interest has revolved around the ability of LLMs to generate coherent and generically responsible texts with minimal effort and the impact that this will have on writing careers and pedagogy, less attention has been paid to how LLMs can aid writing research. Building from previous research, this study explores the utility of AI text generators to facilitate the qualitative coding research of linguistic data. This study benchmarks five LLM prompting strategies to determine the viability of using LLMs as qualitative coding, not writing, assistants, demonstrating that LLMs can be an effective tool for classifying complex rhetorical expressions and can help business and technical communication researchers quickly produce and test their research designs, enabling them to return insights more quickly and with less initial overhead.	[Omizo, Ryan M.] Temple Univ, Coll Liberal Arts, English, Philadelphia, PA USA; [Omizo, Ryan M.] Temple Univ, Coll Liberal Arts, English, 1030 Mazur Hall, 1114 Polett Walk, Philadelphia, PA 19122 USA	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Omizo, RM (corresponding author), Temple Univ, Coll Liberal Arts, English, 1030 Mazur Hall, 1114 Polett Walk, Philadelphia, PA 19122 USA.	ryan.omizo@temple.edu						Bawarshi AnisS. Mary Jo Reiff., 2010, Genre: An Introduction to History, Theory, Research, and Pedagogy; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bhatia V. K., 2013, ANAL GENRE LANGUAGE, DOI [10.4324/9781315844992, DOI 10.4324/9781315844992]; Boettger RK, 2010, IEEE T PROF COMMUN, V53, P346, DOI 10.1109/TPC.2010.2077450; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Campbell KS, 2017, J BUS TECH COMMUN, V31, P94, DOI 10.1177/1050651916667532; Chang CF, 2011, ENGL SPECIF PURP, V30, P222, DOI 10.1016/j.esp.2011.04.001; Chowdhery A., 2022, arXiv; Dannels DP, 2008, J BUS TECH COMMUN, V22, P135, DOI 10.1177/1050651907311923; Feng HY, 2023, J BUS TECH COMMUN, V37, P311, DOI 10.1177/10506519231179959; Flowerdew L., 2000, ELT J, V54, P369, DOI DOI 10.1093/ELT/54.4.369; Flowerdew L, 2016, ENGL SPECIF PURP, V42, P1, DOI 10.1016/j.esp.2015.10.001; Geisler C., 2019, Coding streams of language: Techniques for the systematic coding of talk, text, and other verbal data, P155, DOI [10.37514/PRA-B.2019.0230, DOI 10.37514/PRA-B.2019.0230]; Ghahramani Z., 2023, INTRO PALM 2; Grabill JT, 2012, RHETOR SOC Q, V42, P99, DOI 10.1080/02773945.2012.660369; Hajikhani A., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2307.15425; Hajikhani A, 2022, SCIENTOMETRICS, V127, P6661, DOI 10.1007/s11192-022-04358-x; Hart-davidson William, 2021, SIGDOC '21: The 39th ACM International Conference on Design of Communication, P319, DOI 10.1145/3472714.3473659; Hattie J., 2018, Visible Learning: Feedback; Hattie J, 2007, REV EDUC RES, V77, P81, DOI 10.3102/003465430298487; Jiang E, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503564; Kain D, 2005, TECH COMMUN Q, V14, P113, DOI 10.1207/s15427625tcq1402_1; Kane M., 2020, P 38 ACM INT C DESIG, P1, DOI [10.1145/3380851.3416765, DOI 10.1145/3380851.3416765]; Kojima T., 2022, Advances in neural information processing systems, V35, P22199, DOI DOI 10.48550/ARXIV.2205.11916; Larson B., 2016, P 34 ACM INT C DESIG, P1, DOI [10.1145/2987592.2987603, DOI 10.1145/2987592.2987603]; Liu SZ, 2018, NEURAL COMPUT, V30, P2175, DOI 10.1162/neco_a_01090; Madden S, 2021, WRIT COMMUN, V38, P447, DOI 10.1177/07410883211010166; Mehlenbacher AR, 2017, TECH COMMUN Q, V26, P127, DOI 10.1080/10572252.2017.1287361; MILLER CR, 1984, Q J SPEECH, V70, P151, DOI 10.1080/00335638409383686; Narang S., 2022, Pathways language model (palm): Scaling to 540 billion parameters for breakthrough performance; Omizo R. M., 2019, RHETORICAL MACHINES, P110; Propen AD, 2010, WRIT COMMUN, V27, P3, DOI 10.1177/0741088309351479; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Russell DR, 1997, WRIT COMMUN, V14, P504, DOI 10.1177/0741088397014004004; Samraj B, 2002, ENGL SPECIF PURP, V21, P1, DOI 10.1016/S0889-4906(00)00023-5; SCHRYER CF, 1993, WRIT COMMUN, V10, P200, DOI 10.1177/0741088393010002003; Siad S. M., PROMISE PERILS GOOGL; Spinuzzi C., 2002, P 20 ANN INT C COMPU, P200, DOI DOI 10.1145/584955.584985; SWALES J, 1987, WRIT COMMUN, V4, P175, DOI 10.1177/0741088387004002004; Swales J. M., 1990, Genre analysis: English in academic and research settings; Thominet L, 2020, J BUS TECH COMMUN, V34, P3, DOI 10.1177/1050651919874099; Turpin M., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.04388; Upton TA, 2009, DISCOURSE STUD, V11, P585, DOI 10.1177/1461445609341006; Vaswani A, 2017, ADV NEUR IN, V30; Wall A, 2018, TECH COMMUN Q, V27, P137, DOI 10.1080/10572252.2018.1425483; Wang L., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2305.04091; Wei J., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2109.01652; Wei JS, 2022, ADV NEUR IN; Xu XF, 2010, J BUS TECH COMMUN, V24, P445, DOI 10.1177/1050651910371198; Zhang Z., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.00923	50	0	0	9	9	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1050-6519	1552-4574		J BUS TECH COMMUN	J. Bus. Tech. Commun.	JUL	2024	38	3			SI		242	265		10.1177/10506519241239927	http://dx.doi.org/10.1177/10506519241239927		APR 2024	24	Business; Communication	Social Science Citation Index (SSCI)	Business & Economics; Communication	UE0C6					2024-07-03	WOS:001199580700001
J	Uribe, SE; Maldupa, I; Kavadella, A; El Tantawi, M; Chaurasia, A; Fontana, M; Marino, R; Innes, N; Schwendicke, F				Uribe, Sergio E.; Maldupa, Ilze; Kavadella, Argyro; El Tantawi, Maha; Chaurasia, Akhilanand; Fontana, Margherita; Marino, Rodrigo; Innes, Nicola; Schwendicke, Falk			Artificial intelligence chatbots and large language models in dental education: Worldwide survey of educators	EUROPEAN JOURNAL OF DENTAL EDUCATION			English	Article; Early Access						artificial intelligence; chatbots; dental education; large language models; survey research; teaching methods		IntroductionInterest is growing in the potential of artificial intelligence (AI) chatbots and large language models like OpenAI's ChatGPT and Google's Gemini, particularly in dental education. To explore dental educators' perceptions of AI chatbots and large language models, specifically their potential benefits and challenges for dental education.Materials and MethodsA global cross-sectional survey was conducted in May-June 2023 using a 31-item online-questionnaire to assess dental educators' perceptions of AI chatbots like ChatGPT and their influence on dental education. Dental educators, representing diverse backgrounds, were asked about their use of AI, its perceived impact, barriers to using chatbots, and the future role of AI in this field.Results428 dental educators (survey views = 1516; response rate = 28%) with a median [25/75th percentiles] age of 45 [37, 56] and 16 [8, 25] years of experience participated, with the majority from the Americas (54%), followed by Europe (26%) and Asia (10%). Thirty-one percent of respondents already use AI tools, with 64% recognising their potential in dental education. Perception of AI's potential impact on dental education varied by region, with Africa (4[4-5]), Asia (4[4-5]), and the Americas (4[3-5]) perceiving more potential than Europe (3[3-4]). Educators stated that AI chatbots could enhance knowledge acquisition (74.3%), research (68.5%), and clinical decision-making (63.6%) but expressed concern about AI's potential to reduce human interaction (53.9%). Dental educators' chief concerns centred around the absence of clear guidelines and training for using AI chatbots.ConclusionA positive yet cautious view towards AI chatbot integration in dental curricula is prevalent, underscoring the need for clear implementation guidelines.	[Uribe, Sergio E.; Maldupa, Ilze] Riga Stradins Univ, Dept Conservat Dent & Oral Hlth, Riga, Latvia; [Uribe, Sergio E.] Univ Valparaiso, Fac Dent, Valparaiso, Chile; [Uribe, Sergio E.] Headquarters Riga Tech Univ, Balt Biomat Ctr Excellence, Riga, Latvia; [Uribe, Sergio E.; Chaurasia, Akhilanand; Schwendicke, Falk] ITU, WHO Focus Grp AI Hlth, Top Grp Dent, Geneva, Switzerland; [Kavadella, Argyro] European Univ Cyprus, Sch Dent, Nicosia, Cyprus; [El Tantawi, Maha] Alexandria Univ, Fac Dent, Alexandria, Egypt; [Chaurasia, Akhilanand] King Georges Med Univ, Dept Oral Med & Radiol, Lucknow, India; [Fontana, Margherita] Univ Michigan, Sch Dent, Dept Cariol Restorat Sci & Endodont, Ann Arbor, MI USA; [Marino, Rodrigo] Univ Melbourne, Melbourne Dent Sch, Melbourne, Vic, Australia; [Innes, Nicola] Cardiff Univ, Coll Biomed & Life Sci, Sch Dent, Cardiff, Wales; [Schwendicke, Falk] Ludwig Maximilians Univ Munchen, Dept Conservat Dent & Periodontol, Munich, Germany; [Uribe, Sergio E.] Riga Stradins Univ, Dept Conservat Dent & Oral Hlth, Dzirciema Iela 20, LV-1007 Riga, Latvia	Riga Stradins University; Universidad de Valparaiso; European University Cyprus; Egyptian Knowledge Bank (EKB); Alexandria University; King George's Medical University; University of Michigan System; University of Michigan; University of Melbourne; Cardiff University; University of Munich; Riga Stradins University	Uribe, SE (corresponding author), Riga Stradins Univ, Dept Conservat Dent & Oral Hlth, Dzirciema Iela 20, LV-1007 Riga, Latvia.	sergio.uribe@rsu.lv	Chaurasia, Akhilanand/JCO-3926-2023; Uribe, Sergio E./C-9579-2011; Innes, Nicola/G-3703-2015; El Tantawi, Maha/K-4336-2014	Chaurasia, Akhilanand/0000-0002-8356-9512; Uribe, Sergio E./0000-0003-0684-2025; Maldupa, Ilze/0000-0002-5967-956X; KAVADELLA, ARGYRO/0009-0003-0560-8373; Innes, Nicola/0000-0002-9984-0012; Marino, Rodrigo/0000-0002-3061-843X; El Tantawi, Maha/0000-0003-4989-6584; Fontana, Margherita/0000-0003-2357-7534	HORIZON EUROPE Framework Programme [857287]; European Union; Baltic Biomaterials Centre of Excellence [lzp-2]; Latvian Council of Science	HORIZON EUROPE Framework Programme; European Union(European Union (EU)); Baltic Biomaterials Centre of Excellence; Latvian Council of Science(Latvian Ministry of Education and Science)	SEU acknowledges financial support from the European Union's Horizon 2020 research and innovation program under grant agreement No 857287 for the Baltic Biomaterials Centre of Excellence. IM, NI, RM, and SEU acknowledge financial support from The Latvian Council of Science, project No lzp-2.	Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alhaidry Hind M, 2023, Cureus, V15, pe38317, DOI 10.7759/cureus.38317; Anandapadmanabhan LT, 2022, CUREUS J MED SCIENCE, V14, DOI 10.7759/cureus.24455; [Anonymous], 2023, New principles on use of AI in education; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Artificial Intelligence, 2023, UNESCO publishes Policy Paper on AI Foundation Models; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Beltagy I., 2019, arXiv; Bethlehem J, 2010, INT STAT REV, V78, P161, DOI 10.1111/j.1751-5823.2010.00112.x; Ceres P., 2023, Wired; Cesareo S., 2023, Tortoise; ChatGPT sets record for fastest-growing user base-analyst note, 2023, Reuters; da Silva MAD, 2022, EUR J DENT EDUC, V26, P830, DOI 10.1111/eje.12766; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Eysenbach G, 2004, J MED INTERNET RES, V6, P12, DOI 10.2196/jmir.6.3.e34; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Giannakopoulos K, 2023, EUR J DENT EDUC, V27, P1098, DOI 10.1111/eje.12903; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Howell CW., 2023, Wired; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Kaur A, 2021, DIGIT HEALTH, V7, DOI 10.1177/20552076211038151; Khatsenkova S., 2023, Euronews; Kooli C, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15075614; Labadze L, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00426-1; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Mattheos N, 2008, EUR J DENT EDUC, V12, P85, DOI 10.1111/j.1600-0579.2007.00483.x; Medenilla A., 2023, PLoS Digital Health, V2; Melo LD, 2023, EUR J DENT EDUC, V27, P252, DOI 10.1111/eje.12798; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Mukhopadhyay S, 2014, J DENT EDUC, V78, P1568; NHS-England, 2023, NHS Long Term Workforce Plan.; Pithpornchaiyakul S, 2022, J MED INTERNET RES, V24, DOI 10.2196/39218; Pournelle G. H., 1953, Journal of Mammalogy, V34, P133, DOI 10.1890/0012-9658(2002)083[1421:SDEOLC]2.0.CO;2; Pruvot EB., 2023, University Autonomy in Europe IV The Scorecard 2023; Quinn B, 2020, EUR J DENT EDUC, V24, P811, DOI 10.1111/eje.12542; Sabzalieva E., 2023, ChatGPT and artificial intelligence in higher education quick start guide; Schwendicke F, 2023, J DENT, V128, DOI 10.1016/j.jdent.2022.104363; Schwendicke F, 2021, J DENT, V107, DOI 10.1016/j.jdent.2021.103610; Selvan Preetha, 2023, J Oral Maxillofac Pathol, V27, P15, DOI 10.4103/jomfp.jomfp_85_23; Sethi N, 2023, J DENT EDUC, V87, P1042, DOI 10.1002/jdd.13204; Sheehan K., 2001, Journal of Computer-Mediated Communication, V6, DOI [10.1111/j.1083-6101.2001.tb00117.x, DOI 10.1111/J.1083-6101.2001.TB00117.X]; Shine I., 2023, These are the jobs most likely to be lost-and created-because of AI. World; Stathakarou N, 2020, STUD HEALTH TECHNOL, V272, P209, DOI 10.3233/SHTI200531; Strunga M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11050683; Suárez A, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19148735; thecrimson, CS50 Will Integrate Artificial Intelligence Into Course Instruction; Thurzo A, 2023, EDUC SCI, V13, DOI 10.3390/educsci13020150; Try G, 2000, Prim Dent Care, V7, P9, DOI 10.1308/135576100322748448; Uribe S, 2006, Eur J Dent Educ, V10, P162, DOI 10.1111/j.1600-0579.2006.00412.x; Vishwanathaiah S, 2023, BIOMEDICINES, V11, DOI 10.3390/biomedicines11030788	53	0	0	11	11	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1396-5883	1600-0579		EUR J DENT EDUC	Eur. J. Dent. Educ.	2024 APR 8	2024										10.1111/eje.13009	http://dx.doi.org/10.1111/eje.13009		APR 2024	12	Dentistry, Oral Surgery & Medicine; Education, Scientific Disciplines	Science Citation Index Expanded (SCI-EXPANDED)	Dentistry, Oral Surgery & Medicine; Education & Educational Research	NB9F3	38586899				2024-07-03	WOS:001198094500001
C	Das Purba, M; Ghosh, A; Radford, BJ; Chu, B			IEEE	Das Purba, Moumita; Ghosh, Arpita; Radford, Benjamin J.; Chu, Bill			Software Vulnerability Detection using Large Language Models	2023 IEEE 34TH INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS, ISSREW			English	Proceedings Paper	34th IEEE International Symposium on Software Reliability Engineering (ISSRE)	OCT 09-12, 2023	Florence, ITALY	IEEE, IEEE Comp Soc, Tech Comm Software Engn, IEEE Reliabil Soc, ESTART		Cybersecurity; Large language model; AI; software vulnerability		Software development is among the first demonstrations of using Large Language Models (LLMs) to enhance human productivity. Such a co-pilot paradigm envisions LLM working side-by-side with human developers to assist in programming tasks. Ensuring the security of software products is a critical factor for the success of such a paradigm. There have been various anecdotal reports on the success of using LLMs to detect vulnerabilities in programs. This paper reports a set of experiments applying four well-known LLMs to two widely referenced public datasets to evaluate the performance of LLMs in detecting software vulnerabilities. Our results show a significant performance gap between these LLMs and those from popular static analysis tools, primarily due to their high false positive rates. However, LLMs show great promise in identifying subtle patterns commonly associated with software vulnerabilities. This observation suggests a possible path forward by combining LLMs and other program analysis techniques to achieve better software vulnerability detection.	[Das Purba, Moumita; Ghosh, Arpita; Chu, Bill] Univ N Carolina, Dept Software & Informat Syst, Charlotte, NC 28223 USA; [Radford, Benjamin J.] Univ N Carolina, Dept Polit Sci & Publ Adm, Charlotte, NC USA	University of North Carolina; University of North Carolina Charlotte; University of North Carolina; University of North Carolina Charlotte	Das Purba, M (corresponding author), Univ N Carolina, Dept Software & Informat Syst, Charlotte, NC 28223 USA.	mpurba1@uncc.edu; aghosh8@uncc.edu; benjamin.radford@charlotte.edu; billchu@uncc.edu			NSA [H98230-21-1-0259]	NSA(National Security Agency)	This research was supported in part by NSA grant H98230-21-1-0259.	[Anonymous], Rough audit tool for security; Bhandari G, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE '21), P30, DOI 10.1145/3475960.3475985; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P3280, DOI 10.1109/TSE.2021.3087402; Checkmarx, US; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Cheshkov A., 2023, arXiv; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; dwheeler, Flawfinder; Feng Zhangyin, 2020, Codebert: A pre-trained model for programming and natural languages, P1536; Fu M, 2022, IEEE WORK CONF MIN S, P608, DOI 10.1145/3524842.3528452; Grieco G, 2016, CODASPY'16: PROCEEDINGS OF THE SIXTH ACM CONFERENCE ON DATA AND APPLICATION SECURITY AND PRIVACY, P85, DOI 10.1145/2857705.2857720; Grishina A, 2022, PROC IEEE ACM INT C, P275, DOI [10.1109/ICSE-Companion55297.2022.9793735, 10.1145/3510454.3517063]; HP Fortify, US; Li X, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051692; Li Z, 2022, IEEE T DEPEND SECURE, V19, P2244, DOI 10.1109/TDSC.2021.3051525; Li Z, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23158; Lin GJ, 2020, P IEEE, V108, P1825, DOI 10.1109/JPROC.2020.2993293; linkedin, Chatgpt: Enhancing code security and detect vulnerabilities; OpenAI, 2023, GPT-4 Technical Report; Pan C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11114793; Radford A., 2018, IMPROVING LANGUAGE U; research.nccgroup, chrisanley; Russell RL, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P757, DOI 10.1109/ICMLA.2018.00120; Tang GG, 2020, 2020 INTERNATIONAL SYMPOSIUM ON THEORETICAL ASPECTS OF SOFTWARE ENGINEERING (TASE 2020), P1, DOI 10.1109/TASE49443.2020.00010; Thapa C, 2022, PROCEEDINGS OF THE 38TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE, ACSAC 2022, P481, DOI 10.1145/3564625.3567985; Tu L., 2023, 11 INT C LEARN REPR; Vaswani A, 2017, ADV NEUR IN, V30; Wang S, 2016, IEEE INT CONF AUTOM, P708, DOI 10.1145/2970276.2970341; Ziems N, 2021, IEEE CONF COMPUT, DOI 10.1109/INFOCOMWKSHPS51825.2021.9484500	30	2	2	19	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-1956-9				2023							112	119		10.1109/ISSREW60843.2023.00058	http://dx.doi.org/10.1109/ISSREW60843.2023.00058			8	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW0KT					2024-07-03	WOS:001096854800026
J	Kuzman, T; Mozetic, I; Ljubesic, N				Kuzman, Taja; Mozetic, Igor; Ljubesic, Nikola			Automatic Genre Identification for Robust Enrichment of Massive Text Collections: Investigation of Classification Methods in the Era of Large Language Models	MACHINE LEARNING AND KNOWLEDGE EXTRACTION			English	Article						machine learning; text classification; large language models; fine-tuning; automatic genre identification; text genre; web genre	WEB	Massive text collections are the backbone of large language models, the main ingredient of the current significant progress in artificial intelligence. However, as these collections are mostly collected using automatic methods, researchers have few insights into what types of texts they consist of. Automatic genre identification is a text classification task that enriches texts with genre labels, such as promotional and legal, providing meaningful insights into the composition of these large text collections. In this paper, we evaluate machine learning approaches for the genre identification task based on their generalizability across different datasets to assess which model is the most suitable for the downstream task of enriching large web corpora with genre information. We train and test multiple fine-tuned BERT-like Transformer-based models and show that merging different genre-annotated datasets yields superior results. Moreover, we explore the zero-shot capabilities of large GPT Transformer models in this task and discuss the advantages and disadvantages of the zero-shot approach. We also publish the best-performing fine-tuned model that enables automatic genre annotation in multiple languages. In addition, to promote further research in this area, we plan to share, upon request, a new benchmark for automatic genre annotation, ensuring the non-exposure of the latest large language models.	[Kuzman, Taja; Mozetic, Igor; Ljubesic, Nikola] Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia; [Kuzman, Taja] Jozef Stefan Int Postgrad Sch, Ljubljana 1000, Slovenia; [Ljubesic, Nikola] Blood Transfus Ctr Slovenia, Ljubljana 1000, Slovenia	Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute; Slovenian Academy of Sciences & Arts (SASA); Jozef Stefan Institute	Ljubesic, N (corresponding author), Jozef Stefan Inst, Dept Knowledge Technol, Ljubljana 1000, Slovenia.; Ljubesic, N (corresponding author), Blood Transfus Ctr Slovenia, Ljubljana 1000, Slovenia.	taja.kuzman@ijs.si; igor.mozetic@ijs.si; nikola.ljubesic@ijs.si		Kuzman, Taja/0000-0001-7436-9896; Mozetic, Igor/0000-0002-5466-0608; Ljubesic, Nikola/0000-0001-7169-9152	European Union's Connecting Europe Facility 2014-2020-CEF Telecom [INEA/CEF/ICT/A2020/2278341]; Slovenian Research Agency [N06-0099, FWO-G070619N]; research program "Language resourcesand technologies for Slovene" [P6-0411]	European Union's Connecting Europe Facility 2014-2020-CEF Telecom; Slovenian Research Agency(Slovenian Research Agency - Slovenia); research program "Language resourcesand technologies for Slovene"	This work received funding from the European Union's Connecting Europe Facility 2014-2020-CEF Telecom-under Grant Agreement No. INEA/CEF/ICT/A2020/2278341. This communication reflects only the authors' views. The Agency is not responsible for any use that may be made of the information it contains. This work was also funded by the Slovenian Research Agency within the Slovenian-Flemish bilateral basic research project "Linguistic landscape of hate speech on socialmedia" (N06-0099 and FWO-G070619N, 2019-2023) and the research program "Language resourcesand technologies for Slovene" (P6-0411)	Abramson M., 2012, P WORKSH 26 AAAI C A; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agrawal S, 2019, TENCON IEEE REGION, P1088, DOI 10.1109/TENCON.2019.8929515; [Anonymous], 2003, Proceedings of the 20th International Conference on Machine Learning; Asheghi NR, 2016, LANG RESOUR EVAL, V50, P603, DOI 10.1007/s10579-015-9331-6; Banon M., 2022, P 23 ANN C EUR ASS M, P301; Baroni M, 2009, LANG RESOUR EVAL, V43, P209, DOI 10.1007/s10579-009-9081-4; Berninger V.F., 2008, P BCS IRSG WORKSH CO, P1; Biber D., 2015, Journal of research design and statistics in linguistics and communication science, V2, P3, DOI DOI 10.1558/JRDS.V2I1.27637; Boese E.S., 2005, Ph.D. Thesis; BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069; Christiano PF, 2017, ADV NEUR IN, V30; Conneau A., 2020, P 58 ANN M ASS COMP, P8440, DOI DOI 10.18653/V1/2020.ACL-MAIN.747; Crowston K, 2010, TEXT SPEECH LANG TEC, V42, P69, DOI 10.1007/978-90-481-9178-9_4; Davies M, 2015, ENGL WORLD-WIDE, V36, P1, DOI 10.1075/eww.36.1.01dav; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dewdney N., 2001, P ACL 2001 WORKSH HU; Dietterich TG, 1998, NEURAL COMPUT, V10, P1895, DOI 10.1162/089976698300017197; Egbert J, 2015, J ASSOC INF SCI TECH, V66, P1817, DOI 10.1002/asi.23308; Eissen SMZ, 2004, LECT NOTES COMPUT SC, V3238, P256; Erjavec T., 2014, Jezikovne tehnologije: Zbornik 17. mednarodne multikonference Informacijska druzba-IS 2014, V17, P50; Espla-Gomis M., 2022, Slovene Web Corpus MaCoCu-sl 1.0; Everitt B., 1992, ANAL CONTINGENCY TAB; Feldman S, 2009, INT CONF ACOUST SPEE, P4781, DOI 10.1109/ICASSP.2009.4960700; Finn A, 2006, J AM SOC INF SCI TEC, V57, P1506, DOI 10.1002/asi.20427; Forsyth RS, 2014, LIT LINGUIST COMPUT, V29, P6, DOI 10.1093/llc/fqt002; Giesbrecht E., 2009, P 5 WEB CORPUS WORKS, P27; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Hu E.J., 2021, P INT C LEARN REPR O; Huang F, 2023, Arxiv, DOI [arXiv:2302.07736, DOI 10.48550/ARXIV.2302.07736, DOI 10.1145/3543873.3587368]; Jakubiek Milos, 2013, 7 INT CORP LING C, P125; Jebari Chaker, 2014, 2014 25th International Workshop on Database and Expert Systems Applications (DEXA), P233, DOI 10.1109/DEXA.2014.56; Joulin A., 2017, P 15 C EUR CHAPT ASS, P427, DOI 10.18653/v1/e17-2068; Kowsari K, 2019, INFORMATION, V10, DOI 10.3390/info10040150; Kuzman T., 2022, P ODKR ZNANJ POD SKL; Kuzman T., 2022, JEZIKOVNE TEHNOLOGIJ, P100; Kuzman T., 2023, 10 WORKSHOP NLP SIMI, P91; Kuzman T, 2023, Arxiv, DOI arXiv:2303.03953; Kuzman T, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1584; Laippala V., 2017, P 21 NORD C COMP LIN, P152; Laippala V., 2019, P 22 NORDIC C COMPUT, P292; Laippala V., 2020, P 12 WEB CORP WORKSH, P14; Laippala V, 2023, LANG RESOUR EVAL, V57, P1045, DOI 10.1007/s10579-022-09624-1; Laippala V, 2021, LANG RESOUR EVAL, V55, P757, DOI 10.1007/s10579-020-09519-z; Lepekhin M, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P5974; Levering R., 2008, Proceedings of the 41st Annual Hawaii International Conference on System Sciences (HICSS 2008), P131, DOI DOI 10.1109/HICSS.2008.488; Lim CS, 2005, INFORM PROCESS MANAG, V41, P1263, DOI 10.1016/j.ipm.2004.06.004; Maeda A, 2009, 2009 SECOND INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES (ICADIWT 2009), P405, DOI 10.1109/ICADIWT.2009.5273844; Minaee S, 2021, Arxiv, DOI arXiv:2004.03705; Muller-Eberstein M., 2021, P 2021 C EMPIRICAL M, P4786; OpenAI, 2023, ChatGPT General FAQ; ORLIKOWSKI WJ, 1994, ADMIN SCI QUART, V39, P541, DOI 10.2307/2393771; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Petrenz P, 2011, COMPUT LINGUIST, V37, P385, DOI 10.1162/COLI_a_00052; Pritsos D, 2018, LANG RESOUR EVAL, V52, P949, DOI 10.1007/s10579-018-9418-y; Priyatam P.N., 2013, Research in Computing Science, V70, P233, DOI [10.13053/rcs-70-1-18, DOI 10.13053/RCS-70-1-18]; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford A., 2018, IMPROVING LANGUAGE U; Rehm G., 2008, P LREC MARR MOR 26 M; Repo L, 2021, EACL 2021: THE 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P183; Rezapour Asheghi N., 2014, TEXTGRAPHS, P39; Rezapour Asheghi N., 2015, Ph.D. Thesis; Ronnqvist S., 2021, P 23 NORDIC C COMPUT, P157; Roussinov D., 2001, P 34 ANN HAW INT C S; Santini M., 2007, Ph.D. Thesis; Santini M, 2010, TEXT SPEECH LANG TEC, V42, P87, DOI 10.1007/978-90-481-9178-9_5; Santini S.M., 2006, P WORKSH TEXT BAS IN; Sharoff S., 2010, P LREC VALL MALT 17; Sharoff S, 2021, REGIST STUD, V3, P1, DOI 10.1075/rs.19015.sha; Sharoff S, 2018, CORPORA, V13, P65, DOI 10.3366/cor.2018.0136; Sharoff S, 2010, TEXT SPEECH LANG TEC, V42, P149, DOI 10.1007/978-90-481-9178-9_7; Skantsi V, 2023, NORD J LINGUIST, DOI 10.1017/S0332586523000021; Stein B, 2010, TEXT SPEECH LANG TEC, V42, P167, DOI 10.1007/978-90-481-9178-9_8; Stubbe A., 2007, P REF CORP WEB GENR; Suchomel V., 2020, P FUT TECHN C, P738; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Van der Wees M, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3822; Vaswani A, 2017, ADV NEUR IN, V30; Vidulin V., 2007, P INT WORKSHOP GENRE, P45; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Zhang BW, 2023, Arxiv, DOI [arXiv:2212.14548, DOI 10.48550/ARXIV.2212.14548]	84	1	1	3	9	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2504-4990		MACH LEARN KNOW EXTR	Mach. Learn. Knowl. Extr.	SEP	2023	5	3					1149	1175		10.3390/make5030059	http://dx.doi.org/10.3390/make5030059			27	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering	S9DN7		gold			2024-07-03	WOS:001074100800001
J	Han, TY; Adams, LC; Bressem, KK; Busch, F; Nebelung, S; Truhn, D				Han, Tianyu; Adams, Lisa C.; Bressem, Keno K.; Busch, Felix; Nebelung, Sven; Truhn, Daniel			Comparative Analysis of Multimodal Large Language Model Performance on Clinical Vignette Questions	JAMA-JOURNAL OF THE AMERICAN MEDICAL ASSOCIATION			English	Article								This study compares 2 large language models and their performance vs that of competing open-source models.	[Han, Tianyu; Nebelung, Sven; Truhn, Daniel] Univ Hosp Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany; [Adams, Lisa C.] Tech Univ Munich, Dept Diagnost & Intervent Radiol, Munich, Germany; [Bressem, Keno K.; Busch, Felix] Charite Univ Med Berlin, Dept Radiol, Berlin, Germany; [Truhn, Daniel] Univ Hosp Aachen, Pauwelsstr 30, D-52074 Aachen, Germany	RWTH Aachen University; RWTH Aachen University Hospital; Technical University of Munich; Free University of Berlin; Humboldt University of Berlin; Charite Universitatsmedizin Berlin; RWTH Aachen University; RWTH Aachen University Hospital	Truhn, D (corresponding author), Univ Hosp Aachen, Pauwelsstr 30, D-52074 Aachen, Germany.	daniel.truhn@gmail.com	Busch, Felix/ABE-1064-2022	Busch, Felix/0000-0001-9770-8555				Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Truhn D, 2023, NAT MED, DOI 10.1038/s41591-023-02594-z	4	0	0	11	11	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	0098-7484	1538-3598		JAMA-J AM MED ASSOC	JAMA-J. Am. Med. Assoc.	APR 16	2024	331	15					1320	1321		10.1001/jama.2023.27861	http://dx.doi.org/10.1001/jama.2023.27861		APR 2024	2	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	PW2I6	38497956				2024-07-03	WOS:001189212200002
J	Yang, LY; Chen, HY; Li, Z; Ding, X; Wu, XD				Yang, Linyao; Chen, Hongyang; Li, Zhao; Ding, Xiao; Wu, Xindong			Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING			English	Article						Large language model; knowledge graph; ChatGPT; knowledge reasoning; knowledge management		Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention. Due to their powerful emergent abilities, recent LLMs are considered as a possible alternative to structured knowledge bases like knowledge graphs (KGs). However, while LLMs are proficient at learning probabilistic language patterns and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance in generating texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-trained language models (KGPLMs) as well as their applications. Inspired by existing studies on KGPLM, this paper proposes enhancing LLMs with KGs by developing knowledge graph-enhanced large language models (KGLLMs). KGLLM provides a solution to enhance LLMs' factual reasoning ability, opening up new avenues for LLM research.	[Yang, Linyao; Chen, Hongyang; Li, Zhao; Wu, Xindong] Zhejiang Lab, Hangzhou 311121, Peoples R China; [Ding, Xiao] Harbin Inst Technol, Res Ctr Social Comp & Informat Retrieval, Harbin 150001, Peoples R China	Zhejiang Laboratory; Harbin Institute of Technology	Chen, HY (corresponding author), Zhejiang Lab, Hangzhou 311121, Peoples R China.	yangly@zhejianglab.com; dr.h.chen@ieee.org; zhaoli@zhejianglab.com; xding@ir.hit.edu.cn; xwu@hfut.edu.cn		Wu, Xindong/0000-0003-2396-1704; Ding, Xiao/0000-0002-5838-0320; Li, Zhao/0000-0002-5056-0351	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	AlKhamissi B., 2022, arXiv; Andrus BR, 2022, AAAI CONF ARTIF INTE, P10436; Baek J., 2023, P 1 WORKSHOP NATURAL, P78; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bi Z, 2023, Arxiv, DOI arXiv:2308.15452; Bian N., 2023, arXiv; Bian N, 2021, AAAI CONF ARTIF INTE, V35, P12574; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Bosselut A, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4762; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Cao B., 2022, arXiv; Cao BX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1860; Chang T.-Y., 2020, P 1 WORKSH KNOWL EXT, P74; Chang TA, 2023, Arxiv, DOI arXiv:2303.11504; Chen WH, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8635; Chen ZC, 2023, Arxiv, DOI [arXiv:2303.16537, 10.48550/arXiv.2303.16537]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano P. F., 2017, Deep reinforcement learning from human preferences, P4299; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding R., 2023, P FIND ASS COMP LING, P353; Dong QX, 2022, Arxiv, DOI [arXiv:2301.00234, 10.48550/arXiv.2301.00234, DOI 10.48550/ARXIV.2301.00234]; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Du L., 2021, Long Papers, P5181; Du N, 2022, PR MACH LEARN RES; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; Elazar Y, 2022, Arxiv, DOI [arXiv:2207.14251, 10.48550/arXiv.2207.14251, DOI 10.48550/ARXIV.2207.14251]; Fedus W, 2022, J MACH LEARN RES, V23; Fei H, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa110; Gehman S, 2020, FINDINGS ASS COMPUTA, P3356; Ghanbarpour A, 2020, IEEE T KNOWL DATA EN, V32, P12, DOI 10.1109/TKDE.2018.2879863; Giorgi J, 2019, Arxiv, DOI arXiv:1912.13415; Guan J, 2020, T ASSOC COMPUT LING, V8, P93, DOI 10.1162/tacl_a_00302; Hao SB, 2022, Arxiv, DOI arXiv:2206.14268; Hayashi H, 2020, AAAI CONF ARTIF INTE, V34, P7911; He B, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2281; He L, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4536; He P, 2020, ICLR; He QZ, 2020, AAAI CONF ARTIF INTE, V34, P7919; Heinzerline B, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P1772; Hou YF, 2022, Arxiv, DOI arXiv:2202.00964; Hu LM, 2024, IEEE T KNOWL DATA EN, V36, P1413, DOI 10.1109/TKDE.2023.3310002; Hu Z., 2022, P C EMP METH NAT LAN, P9562; Ji H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P725; Joshi M, 2020, T ASSOC COMPUT LING, V8, P64, DOI 10.1162/tacl_a_00300; Kandpal N, 2023, Arxiv, DOI [arXiv:2211.08411, 10.48550/arXiv.2211.08411]; Kang M, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5144; Kassner N, 2021, Arxiv, DOI arXiv:2102.00894; Ke P, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6975; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Lauscher A., 2020, P DEEP LEARNING INSI, P43; Levine Y, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4656; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li JC, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P1124, DOI 10.1145/3511808.3557459; Li WD, 2023, IEEE T KNOWL DATA EN, V35, P2724, DOI 10.1109/TKDE.2021.3108224; Li X, 2024, Arxiv, DOI arXiv:2305.13269; Liang S, 2023, IEEE T KNOWL DATA EN, V35, P2486, DOI 10.1109/TKDE.2021.3110898; Lin BY, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2829; Lin QK, 2023, INFORM FUSION, V90, P253, DOI 10.1016/j.inffus.2022.09.020; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu Q, 2022, T ASSOC COMPUT LING, V10, P555, DOI 10.1162/tacl_a_00476; Liu WJ, 2020, AAAI CONF ARTIF INTE, V34, P2901; Liu X, 2023, IEEE T KNOWL DATA EN, V35, P857, DOI 10.1109/TKDE.2021.3090866; Liu X, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P3418, DOI 10.1145/3534678.3539210; Liu Y, 2021, AAAI CONF ARTIF INTE, V35, P6418; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Logan RL, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5962; Lu GJ, 2023, NEUROCOMPUTING, V534, P67, DOI 10.1016/j.neucom.2023.03.002; [卢经纬 Lu Jingwei], 2023, [自动化学报, Acta Automatica Sinica], V49, P705; Lu QH, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P3855; Lu RQ, 2019, IEEE T KNOWL DATA EN, V31, P1630, DOI 10.1109/TKDE.2018.2866863; OpenAl, 2023, GPT-4 technical report; Ouyang L., 2022, NEURIPS; Peters ME, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P43; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Pires T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4996; Poerner N, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P803; Qin YJ, 2023, Arxiv, DOI arXiv:2304.08354; Qin YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3350; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ram O, 2023, Arxiv, DOI arXiv:2302.00083; Rosset C, 2021, Arxiv, DOI arXiv:2007.00655; Roy A, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5357; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Sap M, 2019, AAAI CONF ARTIF INTE, P3027; Saparov A, 2023, Arxiv, DOI arXiv:2210.01240; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schuff H., 2021, P 4 BLACKBOXNLP WORK, P26; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Seyler D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P241; Shen T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8980; Su YS, 2021, AI OPEN, V2, P127, DOI 10.1016/j.aiopen.2021.06.004; Sun J., 2023, arXiv; Sun T., 2020, P 28 INT C COMP LING, P3660, DOI [DOI 10.18653/V1/2020.COLING-MAIN.327, DOI 10.18653/V1/2020.COLING-MAIN.327,URL]; Sun Y, 2021, Arxiv, DOI arXiv:2107.02137; Sun Y, 2020, AAAI CONF ARTIF INTE, V34, P8968; Sun YQ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5049; Sung M., 2021, P 2021 C EMPIRICAL M, P4723, DOI [10.18653/v1/2021.emnlp-main.388, DOI 10.18653/V1/2021.EMNLP-MAIN.388]; Swamy V., 2021, arXiv; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Taori R., 2023, GitHub Repository; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang CG, 2020, Arxiv, DOI arXiv:2010.11967; Wang CX, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3241; Wang CX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4020; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Wang J., 2022, P 2022 C EMPIRICAL M, P3164; Wang QS, 2023, IEEE T KNOWL DATA EN, V35, P4395, DOI 10.1109/TKDE.2022.3153651; Wang QX, 2024, IEEE T KNOWL DATA EN, V36, P1170, DOI 10.1109/TKDE.2023.3301884; Wang RZ, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1405; Wang SY, 2023, Arxiv, DOI arXiv:2301.08913; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Wang YJ, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1692; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei Jason, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.01652; Wei X., 2021, arXiv; Wettig A, 2022, Arxiv, DOI arXiv:2202.08005; Xie Qianqian, 2022, Knowledge-Based Systems, DOI 10.1016/j.knosys.2022.109460; Xiong WH, 2019, Arxiv, DOI arXiv:1912.09637; Yamada I, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6442; Yang K., 2022, P 2022 C EMPIRICAL M, P4393, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.296; Yang X., 2020, P CIKM WORKSH COL 29, P1; Yang Z., 2019, ADV NEURAL INFORM PR, P5754, DOI DOI 10.5555/3454287.3454804; Yasunaga M., 2022, Advances in Neural Information Processing Systems, P37309; Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535; Ye ZX, 2020, Arxiv, DOI arXiv:1908.06725; Yohannes HM, 2022, 37TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P837, DOI 10.1145/3477314.3507066; Yu DH, 2022, AAAI CONF ARTIF INTE, P11630; Yu WH, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3512467; Yuan Z., 2021, P 20 WORKSH BIOM LAN, P180, DOI 10.18653/v1/2021.bionlp-1.20; Zellers R, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4856; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang K., 2023, P 5 INT C MACH LEARN, P196; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang TL, 2022, AAAI CONF ARTIF INTE, P11703; Zhang XK, 2022, Arxiv, DOI arXiv:2201.08860; Zhang Y., 2020, P 14 WORKSH SEM EV, P494; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhao R., 2022, P C EMP METH NAT LAN, P2024; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhen CQ, 2022, Arxiv, DOI arXiv:2212.13428; Zhong PX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P165; Zhou J., 2020, P 28 INT C COMP LING, P568, DOI DOI 10.18653/V1/2020.COLING-MAIN.49; Zhou XH, 2022, IEEE T KNOWL DATA EN, V34, P1096, DOI 10.1109/TKDE.2020.2994641	153	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	1041-4347	1558-2191		IEEE T KNOWL DATA EN	IEEE Trans. Knowl. Data Eng.	JUL	2024	36	7					3091	3110		10.1109/TKDE.2024.3360454	http://dx.doi.org/10.1109/TKDE.2024.3360454			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	TZ2O6		Green Submitted			2024-07-03	WOS:001245017200001
J	Yeo, SY; Ma, YS; Kim, SC; Jun, HYK; Kim, T				Yeo, Sangyeop; Ma, Yu-Seung; Kim, Sang Cheol; Jun, Hyungkook; Kim, Taeho			Framework for evaluating code generation ability of large language models	ETRI JOURNAL			English	Article						code generation; evaluation metric; large language model; natural language processing; software engineering		Large language models (LLMs) have revolutionized various applications in natural language processing and exhibited proficiency in generating programming code. We propose a framework for evaluating the code generation ability of LLMs and introduce a new metric, pass-ratio@n$$ pass\hbox{-} ratio@n $$, which captures the granularity of accuracy according to the pass rate of test cases. The framework is intended to be fully automatic to handle the repetitive work involved in generating prompts, conducting inferences, and executing the generated codes. A preliminary evaluation focusing on the prompt detail, problem publication date, and difficulty level demonstrates the successful integration of our framework with the LeetCode coding platform and highlights the applicability of the pass-ratio@n$$ pass\hbox{-} ratio@n $$ metric.	[Yeo, Sangyeop; Ma, Yu-Seung] Univ Sci & Technol, Div Artificial Intelligence, Daejeon, South Korea; [Ma, Yu-Seung; Kim, Sang Cheol; Jun, Hyungkook; Kim, Taeho] Elect & Telecommun Res Inst, Artificial Intelligence Comp Res Lab, Daejeon, South Korea; [Ma, Yu-Seung] Elect & Telecommun Res Inst, Daejeon, South Korea	University of Science & Technology (UST); Electronics & Telecommunications Research Institute - Korea (ETRI); Electronics & Telecommunications Research Institute - Korea (ETRI)	Ma, YS (corresponding author), Elect & Telecommun Res Inst, Daejeon, South Korea.	ysma@etri.re.kr		Kim, Sang Cheol/0000-0002-1925-2588	National Research Council of Science & Technology (NST)	National Research Council of Science & Technology (NST)(National Research Council of Science & Technology (NST), Republic of Korea)	No Statement Availabler No Statement Available	Athiwaratkun B., 2023, MULTI LINGUAL EVALUA; Austin Jacob, 2021, PROGRAM SYNTHESIS LA; Chen M., 2021, ARXIV; Feng YH, 2023, P INT COMP SOFTW APP, P876, DOI 10.1109/COMPSAC57700.2023.00117; Gat I., 2023, CODE LLAMA OPEN FDN; Kim T, 2023, PROC INT CONF SOFTW, P283, DOI 10.1109/ICSE48619.2023.00035; Kulal S, 2019, ADV NEUR IN, V32; Li X.-Y., 2023, THINK OUTSIDE CODE B; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu XD, 2020, COMPUT METHOD BIOMEC, V23, P1102, DOI 10.1080/10255842.2020.1789119; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nijkamp E., 2022, INT C LEARNING REPRE; OpenAI, 2023, GPT 4 TECHNICAL REPO; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park C, 2021, ETRI J, V43, P1038, DOI 10.4218/etrij.2020-0282; Pour MMA, 2022, ETRI J, V44, P794, DOI 10.4218/etrij.2021-0269; Prakash A, 2022, ETRI J, V44, P413, DOI 10.4218/etrij.2019-0396; Puranik S., 2021, PROC NEURAL INFORM P; Yetistiren B, 2022, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, PROMISE 2022, P62, DOI 10.1145/3558489.3559072; Zheng QK, 2023, PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023, P5673, DOI 10.1145/3580305.3599790	20	1	1	7	7	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1225-6463	2233-7326		ETRI J	ETRI J.	FEB	2024	46	1					106	117		10.4218/etrij.2023-0357	http://dx.doi.org/10.4218/etrij.2023-0357		FEB 2024	12	Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Telecommunications	JX5R9		gold			2024-07-03	WOS:001161987700001
J	Yang, T; Mei, YP; Xu, L; Yu, HH; Chen, YY				Yang, Tian; Mei, Yupeng; Xu, Ling; Yu, Huihui; Chen, Yingyi			Application of question answering systems for intelligent agriculture production and sustainable management: A review	RESOURCES CONSERVATION AND RECYCLING			English	Review						Question answering system; Intelligent agriculture; Knowledge graphs; Large language models		The increasing application of artificial intelligence in agriculture production and management has generated a large amount of data, leading to a demand for processing this data. This review focuses on the knowledge storage approaches in agricultural question answering systems, namely corpora, knowledge graphs, and large language models. These systems are built on massive amounts of data and aim to process and retrieve information effectively in the context of sustainable agriculture. Corpora refer to large collections of diverse documents that serve as foundational resources for training and fine-tuning question answering systems. Knowledge graphs capture structured and interconnected knowledge by representing entities, relationships, and attributes, enabling efficient organization and querying of information. Large language models, such as GPT-4, enhance the capacity of question answering systems to provide accurate and relevant responses. By exploring these three prominent knowledge storage approaches, this review analyses the methodology and impact of agricultural question answering systems, highlighting their applications in the production process. The findings provide important implications for future research in agriculture, and potential directions for further exploration.	[Yang, Tian; Mei, Yupeng; Xu, Ling; Yu, Huihui; Chen, Yingyi] Natl Innovat Ctr Digital Fishery, Beijing 100083, Peoples R China; [Yu, Huihui] Beijing Forestry Univ, Sch Informat Sci & Technol, 35 Tsinghua East Rd, Beijing 100083, Peoples R China; [Yang, Tian; Mei, Yupeng; Xu, Ling; Yu, Huihui; Chen, Yingyi] Minist Agr & Rural Affairs, Key Lab Smart Farming Aquat Anim & Livestock, Beijing 100083, Peoples R China; [Yang, Tian; Mei, Yupeng; Xu, Ling; Chen, Yingyi] Beijing Engn & Technol Res Ctr Internet Things Agr, Beijing 100083, Peoples R China; [Yang, Tian; Mei, Yupeng; Xu, Ling; Chen, Yingyi] China Agr Univ, Coll Informat & Elect Engn, 17 Tsinghua East Rd, Beijing 100083, Peoples R China	Beijing Forestry University; Ministry of Agriculture & Rural Affairs; China Agricultural University	Yu, HH; Chen, YY (corresponding author), Natl Innovat Ctr Digital Fishery, Beijing 100083, Peoples R China.	yuhh1990@bjfu.edu.cn; chenyingyi@cau.edu.cn			National Natural Science Foundation of China [62206021]; Beijing Digital Agriculture Innovation Consortium Project [BAIC10- 2023]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Digital Agriculture Innovation Consortium Project	This work was supported by the National Natural Science Foundation of China "Intelligent identification method of underwater fish morphological characteristics based on binocular vision" (No. 62206021) and Beijing Digital Agriculture Innovation Consortium Project (BAIC10- 2023) .	Abad-Navarro F, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030861; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhuyan BP, 2021, IEEE INT CONF BIG DA, P3400, DOI 10.1109/BigData52589.2021.9672020; Biswas P., 2019, Res. Comput. Sci., V148, P383, DOI [10.13053/RCS-148-10-32, DOI 10.13053/RCS-148-10-32]; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Soares MAC, 2020, J KING SAUD UNIV-COM, V32, P635, DOI 10.1016/j.jksuci.2018.08.005; Chalkidis I, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4310; Chen Y., 2022, P 5 INT C ARTIFICIAL, P522, DOI [10.1109/ICAIBD55127.2022.9820199, DOI 10.1109/ICAIBD55127.2022.9820199]; Choudhary NK, 2020, IEEE INT CONF BIG DA, P2340, DOI 10.1109/BigData50022.2020.9377832; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devi M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P122, DOI 10.1109/CCAA.2017.8229784; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gaikwad S, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1474, DOI 10.1109/ICACCI.2015.7275820; Gharibi M, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.00012; Gu Y, 2022, Arxiv, DOI arXiv:2209.04994; Hongchen Qin, 2021, Journal of Physics: Conference Series, V1756, DOI 10.1088/1742-6596/1756/1/012010; Huang YK, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13052924; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Jin WQ, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3627989; Jin WQ, 2024, EXPERT SYST APPL, V238, DOI 10.1016/j.eswa.2023.122289; Jin WQ, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103260; Jin WQ, 2023, DATA MIN KNOWL DISC, V37, P255, DOI 10.1007/s10618-022-00891-8; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Karunathilake EMBM, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13081593; Kawamura T, 2014, LECT NOTES COMPUT SC, V8960, P15, DOI 10.1007/978-3-662-45947-8_2; Klose J, 2019, Arxiv, DOI arXiv:1911.06606; Kung HY, 2021, AGRON J, V113, P906, DOI 10.1002/agj2.20622; Lan Y., 2021, IJCAI, P4483, DOI 10.24963/ijcai.2021/611; Lan YB, 2023, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1064399; Li JM, 2023, IEEE INT CONF SENS, DOI 10.1109/SECON58729.2023.10287501; Liang JQ, 2023, AGRONOMY-BASEL, V13, DOI 10.3390/agronomy13030941; Lianzheng Guan, 2021, Journal of Physics: Conference Series, V1865, DOI 10.1088/1742-6596/1865/4/042052; Liu C., 2020, Research on construction technology of industry knowledge graph, DOI [10.23977/CNCI2020079, DOI 10.23977/CNCI2020079]; Liu SS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183698; Liu YF, 2023, EXPERT SYST APPL, V234, DOI 10.1016/j.eswa.2023.121103; Lun Z, 2022, Acad. J. Eng. Technol. Sci., V5, DOI [10.25236/AJETS.2022.050407, DOI 10.25236/AJETS.2022.050407]; Malik N, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P738; Menaha R, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P387, DOI 10.1109/I-SMAC.2017.8058377; Mikolov T, 2013, COMPUTING RES REPOSI; Ng J.P., 2015, arXiv; Ouhami M, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13132486; Pal A., 2022, P ACM C HLTH INFEREN, DOI [10.48550/ARXIV.2203.14371, DOI 10.48550/ARXIV.2203.14371]; Panoutsopoulos H, 2022, P INT C INFORM COMMU; Parillas V.Q., 2022, P INT C EMERGING TEC, DOI [10.1109/ICETECC56662.2022.10069517, DOI 10.1109/ICETECC56662.2022.10069517]; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Qi Chenglin, 2018, 2018 IEEE/ACIS 17th International Conference on Computer and Information Science (ICIS). Proceedings, P692, DOI 10.1109/ICIS.2018.8466485; Radford A., 2018, IMPROVING LANGUAGE U; Raj S.D., 2022, Int. J. Creat. Res. Thoughts, V10, P2320; Ramos J., 2003, Proc. First Instr. Conf. Mach. Learn, V242, P29; Rehman MZU, 2023, COMPUT ELECTRON AGR, V213, DOI 10.1016/j.compag.2023.108180; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Rose Mary C.A., 2021, AgriRxiv, V2021, DOI [10.31220/AGRIRXIV.2021.00071, DOI 10.31220/AGRIRXIV.2021.00071]; Sahni S., 2018, Geospatial Infrastructure, Applications and Technologies: India Case Studies, P201, DOI [10.1007/978-981-13-2330-0_16/COVER, DOI 10.1007/978-981-13-2330-0_16/COVER]; Siche R, 2023, SCI AGROPEC, V14, P111, DOI 10.17268/sci.agropecu.2023.010; Silva B, 2023, Arxiv, DOI arXiv:2310.06225; Suktarachan M., 2009, P 8 INT C COMPUTATIO, P338, DOI [10.3115/1693756.1693799, DOI 10.3115/1693756.1693799]; Sun B., 2012, Short text similarity computing method towards agriculture question and answering systems, DOI [10.2991/ICCIA.2012.61, DOI 10.2991/ICCIA.2012.61]; Syed-Ab-Rahman SF, 2022, APPL INTELL, V52, P927, DOI 10.1007/s10489-021-02452-w; Tang RX, 2023, Arxiv, DOI arXiv:2303.04360; Touvron H., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2302, 10.48550/ARXIV.2302]; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wang C, 2024, EVOL INTELL, V17, P457, DOI 10.1007/s12065-022-00727-w; Wang HRQ, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12060813; Wang HRQ, 2021, AGRONOMY-BASEL, V11, DOI 10.3390/agronomy11071307; Wang S., 2022, P ANN M ASS COMPUTAT, DOI [10.48550/ARXIV.2203.08773, DOI 10.48550/ARXIV.2203.08773]; Wang T, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11020145; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Xie HH, 2022, 2022 ASIA CONFERENCE ON ALGORITHMS, COMPUTING AND MACHINE LEARNING (CACML 2022), P626, DOI 10.1109/CACML55074.2022.00110; Yadav S, 2022, AGRIENGINEERING, V4, P424, DOI 10.3390/agriengineering4020029; Yang T., 2022, Research on agricultural data mining model based on knowledge graph, P27, DOI [10.1117/12.2635381, DOI 10.1117/12.2635381]; Yuan ZH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3173811; Yusof MM, 2018, ADV INTELL SYST, V700, P363, DOI 10.1007/978-3-319-72550-5_35; Zhang LL, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1053449; Zhao B, 2023, Arxiv, DOI arXiv:2305.15024; Zhao WX, 2023, ARXIV; Zhu FB, 2021, Arxiv, DOI [arXiv:2101.00774, DOI 10.48550/ARXIV.2101.00774]; Zou YD, 2023, AGRICULTURE-BASEL, V13, DOI 10.3390/agriculture13030526	78	0	0	31	31	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0921-3449	1879-0658		RESOUR CONSERV RECY	Resour. Conserv. Recycl.	MAY	2024	204								107497	10.1016/j.resconrec.2024.107497	http://dx.doi.org/10.1016/j.resconrec.2024.107497		FEB 2024	11	Engineering, Environmental; Environmental Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Environmental Sciences & Ecology	MX1V7					2024-07-03	WOS:001196852900001
C	Fu, WM; Yang, KC; Dutta, RG; Guo, XL; Qu, G			IEEE	Fu, Weimin; Yang, Kaichen; Dutta, Raj Gautam; Guo, Xiaolong; Qu, Gang			LLM4SecHW: Leveraging Domain-Specific Large Language Model for Hardware Debugging	2023 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM, ASIANHOST			English	Proceedings Paper	Asian Hardware Oriented Security and Trust Symposium (AsianHOST)	DEC 13-15, 2023	Tianjin, PEOPLES R CHINA	IEEE, IEEE Council Elect Design Automat, IEEE Hardware Secur & Trust Tech Comm, China Comp Federat, Tianjin Univ, Open Secur Res, MathMag Technol		Hardware Debugging; Large Language Model; Domain-Specific Models	ENERGY	This paper presents LLM4SECHW, a novel framework for hardware debugging that leverages domain-specific Large Language Model (LLM). Despite the success of LLMs in automating various software development tasks, their application in the hardware security domain has been limited due to the constraints of commercial LLMs and the scarcity of domain-specific data. To address these challenges, we propose a unique approach to compile a dataset of open-source hardware design defects and their remediation steps, utilizing version control data. This dataset provides a substantial foundation for training machine learning models for hardware. LLM4SECHW employs fine-tuning of medium-sized LLMs based on this dataset, enabling the identification a nd r ectification of bugs in hardware designs. This pioneering approach offers a reference workflow for the application of fine-tuning domain-specific LLMs in ot her research areas. We evaluate the performance of our proposed system on various open-source hardware designs, demonstrating its efficacy i n accurately identifying and correcting defects. Our work brings a new perspective on automating the quality control process in hardware design.	[Fu, Weimin; Guo, Xiaolong] Kansas State Univ, Manhattan, KS 66506 USA; [Yang, Kaichen] Michigan Technol Univ, Houghton, MI 49931 USA; [Dutta, Raj Gautam] Silicon Assurance, Gainesville, FL USA; [Qu, Gang] Univ Maryland, Baltimore, MD 21228 USA	Kansas State University; Michigan Technological University; University System of Maryland; University of Maryland Baltimore	Fu, WM (corresponding author), Kansas State Univ, Manhattan, KS 66506 USA.	weiminf@ksu.edu; kaicheny@mtu.edu; rajgautamdutta@siliconassurance.com; guoxiaolong@ksu.edu; gangqu@umd.edu	Qu, Gang/IAO-6860-2023; Dutta, Raj Gautam/Z-1592-2019	Qu, Gang/0000-0003-2681-0880; 				Aftabjahani S, 2021, IEEE VLSI TEST SYMP, DOI 10.1109/VTS50974.2021.9441032; Ahmad B, 2023, Arxiv, DOI [arXiv:2302.01215, 10.48550/arXiv.2302.01215]; Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Almazrouei Ebtesam, 2023, Falcon-40B: an open large language model with state-of-the-art performance; Andonian A., 2021, GPT-NeoX: Large Scale Autoregressive Language Modeling in PyTorch, V8; [Anonymous], 2023, Github copilot; [Anonymous], 2018, IEEE, DOI DOI 10.1109/IEEESTD.2018.8299595; Balkind J, 2016, ACM SIGPLAN NOTICES, V51, P217, DOI 10.1145/2954679.2872414; Bard, 2023, Bard: A large language model from google ai; Cheng CK, 2023, PROCEEDINGS OF THE 2023 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, ISPD 2023, P158, DOI 10.1145/3569052.3578926; Cosler M., 2023, 34 INT C COMPUTER AI; Darklife, DarkRISCV; Gao P., 2023, Llama-adapter v2: Parameter-efficient visual instruction model; Gurman M., 2023, Bloomberg News, V2; Horne Stafford, mor1kx; Jiang ZX, 2021, 2021 ACM/IEEE 3RD WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD), DOI 10.1109/MLCAD52597.2021.9531313; Johnson S., 2018, HOT CHIPS S HIGH PER, V194, P10; Kande R, 2023, arXiv; King ML, 2013, INT WORKSHOP MICROPR, P35, DOI 10.1109/MTV.2013.23; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Loeliger J, 2012, Version Control with Git; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Matthews E, 2017, I C FIELD PROG LOGIC; Nair Madhav, 2023, Cyber Security, Cryptology, and Machine Learning: 7th International Symposium, CSCML 2023, Proceedings. Lecture Notes in Computer Science (13914), P320, DOI 10.1007/978-3-031-34671-2_23; OpenAI, 2023, GPT-4 Technical Report; openai, Chatgpt based on gpt-4; openfoam, ABOUT US; OpenTitan, About Us; Park D., 2023, OPEN LLM LEADERBOARD; Pullini A, 2019, IEEE J SOLID-ST CIRC, V54, P1970, DOI 10.1109/JSSC.2019.2912307; Ray S, 2018, P IEEE, V106, P21, DOI 10.1109/JPROC.2017.2714641; Schiavone PD, 2017, INT WORKS POW TIM; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sun C., 2023, 1 INT WORKSHOP DEEP; Thakur S., 2022, arXiv; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Veraset, 2023, About Us; Xiong WJ, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3442479; Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114; Zhao Y., 2023, Pytorch fsdp: Experiences on scaling fully sharded data parallel	42	2	2	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-4099-0				2023										10.1109/AsianHOST59942.2023.10409307	http://dx.doi.org/10.1109/AsianHOST59942.2023.10409307			6	Computer Science, Hardware & Architecture; Computer Science, Information Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW5QJ		Green Submitted			2024-07-03	WOS:001165896200002
C	Li, Y; Zhai, C		Pedrycz, W; Wang, J; He, Y; Dinh, TN; Grant, C; Qiu, M		Li, Yifan; Zhai, ChengXiang			An Exploration of Large Language Models for Verification of News Headlines	2023 23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW 2023	International Conference on Data Mining Workshops		English	Proceedings Paper	23rd IEEE International Conference on Data Mining (IEEE ICDM)	DEC 01-04, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, US National Science Foundation, Technology Innovation Institute, TWO SIGMA		Information trust; large language models; misinformation; prompting		This study explores the capabilities of ChatGPT in news headline verification across different prompts and languages. We introduce an optimal prompt design and a novel difficulty ratio metric to analyze ChatGPT's performance across various statement resources. Our findings highlight ChatGPT's promising accuracy and cross-linguistic adaptability in factchecking, while also identifying areas for further investigation, especially in expanding the analysis beyond headlines and exploring other Large Language Models (LLMs). Our findings suggest it is highly promising to leverage an LLM such as ChatGPT as a general tool in combating misinformation, enhancing the trustworthiness of digital information, and increasing trustworithiness of text data mining algorithms by providing more reliable data sources for the algorithms.	[Li, Yifan] Duke Kunshan Univ, Dept Data Sci, Suzhou, Peoples R China; [Zhai, ChengXiang] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA	Duke Kunshan University; University of Illinois System; University of Illinois Urbana-Champaign	Li, Y (corresponding author), Duke Kunshan Univ, Dept Data Sci, Suzhou, Peoples R China.	yl772@duke.edu; czhai@illinois.edu						Benamira A, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P568, DOI 10.1145/3341161.3342958; Chen WL, 2018, PATTERN RECOGN LETT, V105, P226, DOI 10.1016/j.patrec.2017.10.014; Dou YT, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2051, DOI 10.1145/3404835.3462990; Du JS, 2021, INT CONF DAT MIN WOR, P859, DOI 10.1109/ICDMW53433.2021.00110; Helwe C, 2019, FOURTH ARABIC NATURAL LANGUAGE PROCESSING WORKSHOP (WANLP 2019), P130; Hoes E., 2023, Using chatgpt to fight misinforma- tion: Chatgpt nails 72% of 12,000 verified claims; Hu LM, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P754; Jiang SY, 2019, LECT NOTES ARTIF INT, V11838, P634, DOI 10.1007/978-3-030-32233-5_49; Liu J., 2020, Msrd: Multimodal web rumor detection method, V10; Liu X, 2023, GPT UNDERSTANDS TOO; Ma J, 2016, P 25 INT JOINT C ART, P3818; Misra R., 2022, Politifact fact check dataset; Misra R., 2022, Deep Learning for Social Media Data Analytics, P213; OpenAI, 2023, GPT-4 Technical Report; Shu K, 2021, LECT NOTES ARTIF INT, V12459, P650, DOI 10.1007/978-3-030-67664-3_39; Si C., 2023, Prompting GPT-3 to be reliable; Tian L, 2021, LECT NOTES ARTIF INT, V12975, P603, DOI 10.1007/978-3-030-86486-6_37; Wang YQ, 2020, AAAI CONF ARTIF INTE, V34, P516; Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903; Yu F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3901; Zhang Y, 2017, 2017 IEEE TECHNOLOGY & ENGINEERING MANAGEMENT SOCIETY CONFERENCE (TEMSCON), P437, DOI 10.1109/TEMSCON.2017.7998415; Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27	22	0	0	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2375-9232		979-8-3503-8164-1	INT CONF DAT MIN WOR			2023							197	206		10.1109/ICDMW60847.2023.00032	http://dx.doi.org/10.1109/ICDMW60847.2023.00032			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5OA					2024-07-03	WOS:001164077500024
C	Rando, J; Perez-Cruz, F; Hitaj, B		Tsudik, G; Conti, M; Liang, K; Smaragdakis, G		Rando, Javier; Perez-Cruz, Fernando; Hitaj, Briland			PassGPT: Password Modeling and (Guided) Generation with Large Language Models	COMPUTER SECURITY - ESORICS 2023, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	28th European Symposium on Research in Computer Security (ESORICS)	SEP 25-29, 2023	The Hague, NETHERLANDS			Password Guessing; LLMs; Generative AI	SECURITY	Large language models (LLMs) successfully model natural language from vast amounts of text without the need for explicit supervision. In this paper, we investigate the efficacy of LLMs in modeling passwords. We present PassGPT, an LLM trained on password leaks for password generation. PassGPT outperforms existing methods based on generative adversarial networks (GAN) by guessing twice as many previously unseen passwords. Furthermore, we introduce the concept of guided password generation, where we leverage PassGPT sampling procedure to generate passwords matching arbitrary constraints, a feat lacking in current GAN-based strategies. Lastly, we conduct an in-depth analysis of the entropy and probability distribution that PassGPT defines over passwords and discuss their use in enhancing existing password strength estimators.	[Rando, Javier; Perez-Cruz, Fernando] Swiss Fed Inst Technol, Andreasstr 5, CH-8092 Zurich, Switzerland; [Perez-Cruz, Fernando] Swiss Data Sci Ctr, Andreasstr 5, CH-8092 Zurich, Switzerland; [Hitaj, Briland] SRI Int, New York, NY 10165 USA	Swiss Federal Institutes of Technology Domain; ETH Zurich; SRI International	Rando, J (corresponding author), Swiss Fed Inst Technol, Andreasstr 5, CH-8092 Zurich, Switzerland.	jrando@ethz.ch; fernando.perezcruz@sdsc.ethz.ch; briland.hitaj@sri.com		Rando, Javier/0000-0002-2723-7660				[Anonymous], 2023, . Wikipedia: Rockyou; Bailey Daniel V., 2014, Security and Cryptography for Networks. 9th International Conference (SCN 2014). Proceedings: LNCS 8642, P218, DOI 10.1007/978-3-319-10879-7_13; Blocki J, 2018, P IEEE S SECUR PRIV, P853, DOI 10.1109/SP.2018.00009; Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Castelluccia C., 2012, P NDSS, P1; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Ciaramella A, 2006, IEEE T DEPEND SECURE, V3, P327, DOI 10.1109/TDSC.2006.53; Das A, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23357; de Carnavalet XD, 2014, 21ST ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2014), DOI 10.14722/ndss.2014.23268; De Carnavalet XD, 2015, ACM T INFORM SYST SE, V18, DOI 10.1145/2739044; Dell'Amico M, 2010, IEEE INFOCOM SER; Dürmuth M, 2015, LECT NOTES COMPUT SC, V8978, P119, DOI 10.1007/978-3-319-15618-7_10; FELDMEIER DC, 1990, LECT NOTES COMPUT SC, V435, P44; Golla M, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P1567, DOI 10.1145/3243734.3243769; Golla M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1230, DOI 10.1145/2976749.2978416; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Greenbag A., 2019, Hackers are passing around a megaleak of 2.2 billion records; Hashcat, Advanced password recovery-Rule-based attack; Hitaj B, 2019, LECT NOTES COMPUT SC, V11464, P217, DOI 10.1007/978-3-030-21568-2_11; Gulrajani I, 2017, ADV NEUR IN, V30; Melicher W, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P175; MORRIS R, 1979, COMMUN ACM, V22, P594, DOI 10.1145/359168.359172; Narayanan A, 2005, CCS 2005, P364, DOI [10.1145/1102120.1102168, DOI 10.1145/1102120.1102168]; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; Openwall, John the ripper markov generator; Openwall, John the ripper password cracker; Pagnotta G, 2022, I C DEPEND SYS NETWO, P251, DOI 10.1109/DSN53405.2022.00035; Pal B, 2019, P IEEE S SECUR PRIV, P417, DOI 10.1109/SP.2019.00056; Pasquini Dario, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1382, DOI 10.1109/SP40001.2021.00016; Pasquini Dario, 2020, Computer Security - ESORICS 2020 25th European Symposium on Research in Computer Security, ESORICS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12308), P502, DOI 10.1007/978-3-030-58951-6_25; Pasquini D, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P821; Paterson KG, 2010, LECT NOTES COMPUT SC, V6168, P264, DOI 10.1007/978-3-642-14081-5_17; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Sutskever I, 2014, ADV NEUR IN, V27; Tomczak J. M., 2022, DEEP GENERATIVE MODE, DOI DOI 10.1007/978-3-030-93158-2; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Ur B, 2012, USENIX SECURITY S, P65; Vaswani A, 2017, ADV NEUR IN, V30; Wayman J.L., 2005, Biometric Systems: Technology, Design and Performance Evaluation, V1st, DOI DOI 10.1007/B138151; Weir M, 2009, P IEEE S SECUR PRIV, P391, DOI 10.1109/SP.2009.8; Wheeler DL, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P157; Whitney L., 2021, Billions of passwords leaked online from past data breaches; Wikipedia, 2023, 2012 linkedin hack; WikiSkull, 2023, Password datasets; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xu M, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P5, DOI 10.1145/3460120.3484743; Yu J., 2021, arXiv	50	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-51481-4; 978-3-031-51482-1	LECT NOTES COMPUT SC			2024	14347						164	183		10.1007/978-3-031-51482-1_9	http://dx.doi.org/10.1007/978-3-031-51482-1_9			20	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW8YT		Green Submitted			2024-07-03	WOS:001208360100009
J	Thakur, S; Ahmad, B; Pearce, H; Tan, B; Dolan-Gavitt, B; Karri, R; Garg, S				Thakur, Shailja; Ahmad, Baleegh; Pearce, Hammond; Tan, Benjamin; Dolan-Gavitt, Brendan; Karri, Ramesh; Garg, Siddharth			VeriGen: A Large Language Model for Verilog Code Generation	ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS			English	Article						Transformers; verilog; GPT; large language models; EDA		In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by automatically completing partial Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across various problem categories compared to its pre-trained counterpart, highlighting the potential of smaller, in-house LLMs in hardware design automation. We release our training/evaluation scripts and LLM checkpoints as open-source contributions.	[Thakur, Shailja; Ahmad, Baleegh; Dolan-Gavitt, Brendan; Karri, Ramesh; Garg, Siddharth] NYU, 6 Metrotech Ctr, New York, NY 11201 USA; [Pearce, Hammond] Univ New South Wales, Sydney, NSW 2052, Australia; [Tan, Benjamin] Univ Calgary, 2500 Univ Dr NW, Calgary, AB T2N 1N4, Canada	New York University; University of New South Wales Sydney; University of Calgary	Thakur, S (corresponding author), NYU, 6 Metrotech Ctr, New York, NY 11201 USA.	st4920@nyu.edu; ba1283@nyu.edu; hp2265@nyu.edu; benjamin.tan1@ucalgary.ca; brendandg@nyu.edu; rkarri@nyu.edu; siddharth.garg@nyu.edu		Tan, Benjamin/0000-0002-7642-3638	NSF [2039607, 1553419, 1646671]; ARO [77191NC]	NSF(National Science Foundation (NSF)); ARO	This research work was supported in part by NSF Award 1553419, NSF Award 1646671, NSF Award 2039607, and ARO Award 77191NC. The opinions, findings, and conclusions, or recommendations expressed are those of the author(s) and do not necessarily reflect the views of any sponsors.	Ahmad A, 2023, 27TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING, EASE 2023, P279, DOI 10.1145/3593434.3593468; Ahmad B, 2024, IEEE T INF FOREN SEC, V19, P4043, DOI 10.1109/TIFS.2024.3374558; AI21, 2021, Jurassic-1 Language Models-AI21 Studio Docs; [Anonymous], 2019, Language Models are Unsupervised Multitask Learners, DOI DOI 10.18653/V1/W18-5019; Bachrach J, 2012, DES AUT CON, P1212; Blocklove Jason, 2023, P 2023 ACM IEEE 5 WO, DOI [10.1109/mlcad58807.2023.10299874, DOI 10.1109/MLCAD58807.2023.10299874]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chang KY, 2023, Arxiv, DOI arXiv:2305.14019; Chen M., 2021, arXiv; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Dessouky G, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P213; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Drechsler R, 2012, INT HIGH LEVEL DESIG, P164, DOI 10.1109/HLDVT.2012.6418259; Fu YG, 2023, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD57390.2023.10323953; Gage P., 1994, C Users Journal, V12, P23; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Harris CB, 2016, DES AUT TEST EUROPE, P966; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Liu MJ, 2023, Arxiv, DOI arXiv:2309.07544; Mihalcea R, 2006, LECT NOTES COMPUT SC, V3878, P319; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2023, GPT-4; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pearce H, 2020, PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD '20), P27, DOI 10.1145/3380446.3430634; Rajbhandari S, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476205; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Ren J, 2021, Arxiv, DOI [arXiv:2101.06840, 10.48550/arXiv.2101.06840]; Sandoval G, 2023, PROCEEDINGS OF THE 32ND USENIX SECURITY SYMPOSIUM, P2205; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Vaswani A, 2017, ADV NEUR IN, V30; Williams Stephen, 2023, The ICARUS Verilog Compilation System; Wong Henry, 2019, Project:About-HDLBits; Yan ZQ, 2017, Arxiv, DOI [arXiv:1705.07258, 10.48550/arXiv.1705.07258]; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420	36	1	1	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	1084-4309	1557-7309		ACM T DES AUTOMAT EL	ACM Transact. Des. Automat. Electron. Syst.	MAY	2024	29	3							46	10.1145/3643681	http://dx.doi.org/10.1145/3643681			31	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RJ2R7		Green Submitted			2024-07-03	WOS:001227235300006
J	Jablonka, KM; Ai, QX; Al-Feghali, A; Badhwar, S; Bocarsly, JD; Bran, AM; Bringuier, S; Brinson, LC; Choudhary, K; Circi, D; Cox, S; de Jong, WA; Evans, ML; Gastellu, N; Genzling, J; Gil, MV; Gupta, AK; Hong, Z; Imran, A; Kruschwitz, S; Labarre, A; Lála, J; Liu, T; Ma, SV; Majumdar, S; Merz, GW; Moitessier, N; Moubarak, E; Mouriño, B; Pelkie, B; Pieler, M; Ramos, MC; Rankovic, B; Rodriques, SG; Sanders, JN; Schwaller, P; Schwarting, M; Shi, JL; Smit, B; Smith, B; Van Herck, J; Voelker, C; Ward, L; Warren, S; Weiser, B; Zhang, SYS; Zhang, XQ; Zia, GA; Scourtas, A; Schmidt, KJ; Foster, I; White, AD; Blaiszik, B				Jablonka, Kevin Maik; Ai, Qianxiang; Al-Feghali, Alexander; Badhwar, Shruti; Bocarsly, Joshua D.; Bran, Andres M.; Bringuier, Stefan; Brinson, L. Catherine; Choudhary, Kamal; Circi, Defne; Cox, Sam; de Jong, Wibe A.; Evans, Matthew L.; Gastellu, Nicolas; Genzling, Jerome; Gil, Maria Victoria; Gupta, Ankur K.; Hong, Zhi; Imran, Alishba; Kruschwitz, Sabine; Labarre, Anne; Lala, Jakub; Liu, Tao; Ma, Steven; Majumdar, Sauradeep; Merz, Garrett W.; Moitessier, Nicolas; Moubarak, Elias; Mourino, Beatriz; Pelkie, Brenden; Pieler, Michael; Ramos, Mayk Caldas; Rankovic, Bojana; Rodriques, Samuel G.; Sanders, Jacob N.; Schwaller, Philippe; Schwarting, Marcus; Shi, Jiale; Smit, Berend; Smith, Ben E.; Van Herck, Joren; Voelker, Christoph; Ward, Logan; Warren, Sean; Weiser, Benjamin; Zhang, Sylvester; Zhang, Xiaoqi; Zia, Ghezal Ahmad; Scourtas, Aristana; Schmidt, K. J.; Foster, Ian; White, Andrew D.; Blaiszik, Ben			14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon	DIGITAL DISCOVERY			English	Article							PREDICTION; KNOWLEDGE; ENERGIES	Large-language models (LLMs) such as GPT-4 caught the interest of many scientists. Recent studies suggested that these models could be useful in chemistry and materials science. To explore these possibilities, we organized a hackathon. This article chronicles the projects built as part of this hackathon. Participants employed LLMs for various applications, including predicting properties of molecules and materials, designing novel interfaces for tools, extracting knowledge from unstructured data, and developing new educational applications. The diverse topics and the fact that working prototypes could be generated in less than two days highlight that LLMs will profoundly impact the future of our fields. The rich collection of ideas and projects also indicates that the applications of LLMs are not limited to materials science and chemistry but offer potential benefits to a wide range of scientific disciplines. We report the findings of a hackathon focused on exploring the diverse applications of large language models in molecular and materials science.	[Jablonka, Kevin Maik; Majumdar, Sauradeep; Smit, Berend; Van Herck, Joren; Zhang, Xiaoqi] Ecole Polytech Fed Lausanne EPFL, Inst Sci & Ingn Chim, Lab Mol Simulat LSMO, Sion, Valais, Switzerland; [Ai, Qianxiang] MIT, Dept Chem Engn, Cambridge, MA 02139 USA; [Al-Feghali, Alexander; Labarre, Anne; Lala, Jakub; Liu, Tao; Merz, Garrett W.; Moitessier, Nicolas; Warren, Sean; Weiser, Benjamin; Zhang, Sylvester] McGill Univ, Dept Chem, Montreal, PQ, Canada; [Badhwar, Shruti] Reincarnate Inc, San Mateo, CA USA; [Bocarsly, Joshua D.] Univ Cambridge, Yusuf Hamied Dept Chem, Lensfield Rd, Cambridge CB2 1EW, England; [Bran, Andres M.] Ecole Polytech Fed Lausanne EPFL, Inst Sci & Ingn Chim, Lab Artifcial Chem Intelligence LIAC, Lausanne, Switzerland; [Bran, Andres M.] Ecole Polytech Fed Lausanne EPFL, Natl Ctr Competence Res NCCR Catalysis, Lausanne, Switzerland; [Brinson, L. Catherine; Circi, Defne] Duke Univ, Mech Engn & Mat Sci, Durham, NC USA; [Choudhary, Kamal] Natl Inst Stand & Technol, Mat Measurement Lab, Maryland, NY 20899 USA; [Cox, Sam] Univ Rochester, Dept Chem Engn, Rochester, NY USA; [de Jong, Wibe A.] Lawrence Berkeley Natl Lab, Appl Math & Computat Res Div, Berkeley, CA 94720 USA; [Evans, Matthew L.] UCLouvain, Inst Mat Condensee & Nanosci IMCN, Chemin Etoiles 8, B-1348 Louvain La Neuve, Belgium; [Evans, Matthew L.] Matgenix SRL, 185 Rue Armand Bury, B-6534 Gozee, Belgium; [Gil, Maria Victoria] CSIC, Inst Ciencia & Tecnol Carbono INCAR, Francisco Pintado Fe 26, Oviedo 33011, Spain; [Hong, Zhi] Univ Chicago, Dept Comp Sci, Chicago, IL 60637 USA; [Imran, Alishba] Univ Calif Berkeley, Comp Sci, Berkeley, CA 94704 USA; [Kruschwitz, Sabine] Bundesanstalt Mat Forsch & Prufung, Unter Eichen 87, D-12205 Berlin, Germany; [Lala, Jakub] Francis Crick Inst, 1 Midland Rd, London NW1 1AT, England; [Merz, Garrett W.] Univ Wisconsin Madison, Amer Family Insurance Data Sci Inst, Madison, WI 53706 USA; [Pelkie, Brenden] Univ Washington, Dept Chem Engn, Seattle, WA 98105 USA; [Pieler, Michael] OpenBioML org, London, England; [Pieler, Michael] Stability AI, London, England; [Sanders, Jacob N.] Univ Calif Los Angeles, Dept Chem & Biochem, Los Angeles, CA 90095 USA; [Schwarting, Marcus] Univ Chicago, Dept Comp Sci, Chicago, IL 60490 USA; [Ward, Logan] Argonne Natl Lab, Data Sci & Learning Div, Chicago, IL USA; [Scourtas, Aristana; Schmidt, K. J.; Blaiszik, Ben] Univ Chicago, Data Sci & Learning Div, Argonne Natl Lab, Globus, Chicago, IL 60490 USA; [Foster, Ian] Univ Chicago, Dept Comp Sci, Data Sci & Learning Div, Argonne Natl Lab, Chicago, IL USA	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Massachusetts Institute of Technology (MIT); McGill University; University of Cambridge; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Duke University; National Institute of Standards & Technology (NIST) - USA; University of Rochester; United States Department of Energy (DOE); Lawrence Berkeley National Laboratory; Universite Catholique Louvain; Consejo Superior de Investigaciones Cientificas (CSIC); University of Chicago; University of California System; University of California Berkeley; Federal Institute for Materials Research & Testing; Francis Crick Institute; University of Wisconsin System; University of Wisconsin Madison; University of Washington; University of Washington Seattle; University of California System; University of California Los Angeles; University of Chicago; United States Department of Energy (DOE); Argonne National Laboratory; University of Chicago; United States Department of Energy (DOE); Argonne National Laboratory; United States Department of Energy (DOE); Argonne National Laboratory; University of Chicago	Jablonka, KM (corresponding author), Ecole Polytech Fed Lausanne EPFL, Inst Sci & Ingn Chim, Lab Mol Simulat LSMO, Sion, Valais, Switzerland.; Blaiszik, B (corresponding author), Univ Chicago, Data Sci & Learning Div, Argonne Natl Lab, Globus, Chicago, IL 60490 USA.	mail@kjablonka.com; blaiszik@uchicago.edu	badhwar, shruti/JHU-6906-2023; GIL, MARÍA V/A-2774-2017; Ward, Logan/I-9526-2019; Brinson, L. Catherine/B-6678-2009; Ai, Qianxiang/AAU-7897-2021; M Bran, Andres/ISV-4674-2023; Bocarsly, Joshua D/HQZ-4971-2023; Smit, Berend/B-7580-2009; Schwaller, Philippe/ABG-4328-2021; Gupta, Ankur/JQJ-5877-2023; XIAOQI, ZHANG/KIK-7052-2024; Jablonka, Kevin Maik/AAP-9474-2020; DE JONG, WIBE/A-5443-2008	Ward, Logan/0000-0002-1323-5939; Ai, Qianxiang/0000-0002-5487-2539; Bocarsly, Joshua D/0000-0002-7523-152X; Smit, Berend/0000-0003-4653-8562; Schwaller, Philippe/0000-0003-3046-6576; Gupta, Ankur/0000-0002-3128-9535; Jablonka, Kevin Maik/0000-0003-4894-4660; DE JONG, WIBE/0000-0002-7114-8315; Shi, Jiale/0000-0002-5447-3925; Bringuier, Stefan/0000-0001-6753-1437; Al-Feghali, Alexander/0009-0004-8377-7049; Mourino, Beatriz/0000-0003-1670-3985; Smith, Benjamin/0000-0001-9673-2449; Brinson, Lynda/0000-0003-2551-1563; Van Herck, Joren/0009-0005-5108-5061; Zhang, Xiaoqi/0000-0002-6507-6490; Genzling, Jerome/0009-0007-4728-1478; Marulanda Bran, Andres Camilo/0000-0002-4432-3667; Evans, Matthew/0000-0002-1182-9098; Badhwar, Shruti/0000-0002-3167-5348; Choudhary, Kamal/0000-0001-9737-8074	National Science Foundation [DGE-2022040, DE-AC02-05CH11231, DE-FOA-0002705]; U.S. Department of Commerce, National Institute of Standards and Technology as part of the Center for Hierarchical Materials Design (CHiMaD) [DAC-LBL-Long]; MARVEL National Centre for Competence in Research - Swiss National Science Foundation [180544]; USorb-DAC Project - Grantham Foundation for the Protection of the Environment; European Union; National Institute of General Medical Sciences; National Center for Advancing Translational Sciences of the National Institutes of Health; Spanish National Research Council (CSIC) through the Programme for internationalization i-LINK 2021; Battery Interface Genome - Materials Acceleration Platform (BIG-MAP); Spanish Agencia Estatal de Investigacion (AEI) - MCIN/AEI; BEWARE scheme of the Wallonia-Brussels Federation under the European Commission's Marie Curie-Sklodowska Action; European Union NextGenerationEU/PRTR - MCIN/AEI; UK's Engineering and Physical Sciences Research Council (ESPRC); ESF Investing in your future; NSF; European Union's Horizon 2020 research and innovation programme; National Institute of Standards and Technology; U.S. Department of Energy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering Division; FWP; U.S. Department of Energy, Office of Science, Office of High Energy Physics; NCCR Catalysis, a National Centre of Competence in Research - Swiss National Science Foundation; Francis Crick Institute - Cancer Research UK; UK Medical Research Council; Wellcome Trust;  [2226419];  [2209892];  [1931306];  [1764415];  [1917340];  [70NANB19H005];  [51NF40-182892];  [945363];  [R35GM137966];  [U18TR004149];  [LINKA20412];  [TED2021-131693B-I00];  [RYC-2017-21937];  [957189];  [847587]	National Science Foundation(National Science Foundation (NSF)); U.S. Department of Commerce, National Institute of Standards and Technology as part of the Center for Hierarchical Materials Design (CHiMaD); MARVEL National Centre for Competence in Research - Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); USorb-DAC Project - Grantham Foundation for the Protection of the Environment; European Union(European Union (EU)); National Institute of General Medical Sciences(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS)); National Center for Advancing Translational Sciences of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Center for Advancing Translational Sciences (NCATS)); Spanish National Research Council (CSIC) through the Programme for internationalization i-LINK 2021; Battery Interface Genome - Materials Acceleration Platform (BIG-MAP); Spanish Agencia Estatal de Investigacion (AEI) - MCIN/AEI; BEWARE scheme of the Wallonia-Brussels Federation under the European Commission's Marie Curie-Sklodowska Action; European Union NextGenerationEU/PRTR - MCIN/AEI; UK's Engineering and Physical Sciences Research Council (ESPRC)(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); ESF Investing in your future; NSF(National Science Foundation (NSF)); European Union's Horizon 2020 research and innovation programme(Horizon 2020); National Institute of Standards and Technology(National Institute of Standards & Technology (NIST) - USA); U.S. Department of Energy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering Division(United States Department of Energy (DOE)); FWP; U.S. Department of Energy, Office of Science, Office of High Energy Physics(United States Department of Energy (DOE)); NCCR Catalysis, a National Centre of Competence in Research - Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); Francis Crick Institute - Cancer Research UK; UK Medical Research Council(UK Research & Innovation (UKRI)Medical Research Council UK (MRC)); Wellcome Trust(Wellcome Trust); ; ; ; ; ; ; ; ; ; ; ; ; ; ; 	2226419 We would like to specifically thank Jim Warren (NIST) for his contributions to discussions leading up to the hackathon and his participation as a judge during the event. We would also like to thank Anthony Costa and Christian Dallago (NVIDIA) for supporting the hackathon. B. B., I. T. F, and Z. H. acknowledge support from the the National Science Foundation awards #2226419 and #2209892. This work was performed under the following financial assistance award 70NANB19H005 from the U.S. Department of Commerce, National Institute of Standards and Technology as part of the Center for Hierarchical Materials Design (CHiMaD). K. J. S, A. S. acknowledge support from the the National Science Foundation award #1931306. K. M. J., S. M., J. v. H., X. Z., B. M., E. M., and B. S. were supported by the MARVEL National Centre for Competence in Research funded by the Swiss National Science Foundation (grant agreement ID 51NF40-182892) and the USorb-DAC Project, which is funded by a grant from The Grantham Foundation for the Protection of the Environment to RMI's climate tech accelerator program, Third Derivative. B. M. was further supported by the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 945363. M. C. R., S. C., and A. D. W. were supported by the National Science Foundation and the National Institute of General Medical Sciences under Grant No. 1764415 and award number R35GM137966, respectively. Q. A.'s contribution to this work was supported by the National Center for Advancing Translational Sciences of the National Institutes of Health under award number U18TR004149. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. M. V. G. acknowledges support from the Spanish National Research Council (CSIC) through the Programme for internationalization i-LINK 2021 (Project LINKA20412), and from the Spanish Agencia Estatal de Investigacion (AEI) through the Grant TED2021-131693B-I00 funded by MCIN/AEI/10.13039/501100011033 and by the "European Union NextGenerationEU/PRTR" and through the Ramon y Cajal Grant RYC-2017-21937 funded by MCIN/AEI/10.13039/501100011033 and by "ESF Investing in your future". The project (M. L. E., B. E. S. and J. D. B.) has received funding from the European Union's Horizon 2020 research and innovation programme under grant agreement 957189 (DOI: 10.3030/957189), the Battery Interface Genome - Materials Acceleration Platform (BIG-MAP), as an external stakeholder project. M. L. E. additionally thanks the BEWARE scheme of the Wallonia-Brussels Federation for funding under the European Commission's Marie Curie-Sklodowska Action (COFUND 847587). B. E. S. acknowledges support from the UK's Engineering and Physical Sciences Research Council (ESPRC). B. P. acknowledges support from the National Science Foundation through NSF-CBET Grant No. 1917340. The authors thank Phung Cheng Fei, Hassan Harb, and Vinayak Bhat for their helpful comments on this project. D. C. and L. C. B. thank NSF DGE-2022040 for the aiM NRT funding support. K. C. thank the National Institute of Standards and Technology for funding, computational, and data-management resources. Please note certain equipment, instruments, software, or materials are identified in this paper in order to specify the experimental procedure adequately.; r Such identification is not intended to imply recommendation or endorsement of any product or service by NIST, nor is it intended to imply that the materials or equipment identified are necessarily the best available for the purpose. A. K. G., G. W. M., A. I., and W. A. d. J. were supported by the U.S. Department of Energy, Office of Science, Basic Energy Sciences, Materials Sciences and Engineering Division under Contract No. DE-AC02-05CH11231, FWP No. DAC-LBL-Long, and by the U.S. Department of Energy, Office of Science, Office of High Energy Physics under Award Number DE-FOA-0002705. M. B, B. R., and P. S. were supported by the NCCR Catalysis (grant number 180544), a National Centre of Competence in Research funded by the Swiss National Science Foundation. S. G. R. and J. L. acknowledge the generous support of Eric and Wendy Schmidt, and the core funding of the Francis Crick Institute, which receives its funding from Cancer Research UK, the UK Medical Research Council, and the Wellcome Trust.	Andersen CW, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00974-z; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], ALP LORA; [Anonymous], 2023, Gpt-4 Technical Report; Baek M, 2021, SCIENCE, V373, P871, DOI 10.1126/science.abj8754; Batzner S, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29939-5; Becke A. D., 1993, Journal of Chemical Physics, V98, P5648, DOI 10.1063/1.464913; Boiko D. A., 2023, EMERGENT AUTONOMOUS; Bommasani R., OPPORTUNITIES RISKS; Bran A.M., 2023, ChemCrow: Augmenting large-language models with chemistry tools; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2; Campbell Q., 2023, CENSORING CHEM DATA; Choudhary K., 2022, NATURAL LANGUAGE PRO; Choudhary K, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00734-6; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Curtiss LA, 2007, J CHEM PHYS, V127, DOI 10.1063/1.2770701; Dai Haixing, 2023, Auggpt: Leveraging chatgpt for text data augmentation; Dinh T., 2022, LANGUAGE INTERFACED; Dunn A., 2022, Structured information extraction from complex scientific text with fine-tuned large language models; Edwards C. N., 2022, C EMP METH NAT LANG; Eloundou TMS., 2023, GPTS ARE GPTS EARLY; Flam-Shepherd D., 2023, LANGUAGE MODELS CAN; Gonthier JF, 2012, CHEM SOC REV, V41, P4671, DOI 10.1039/c2cs35037h; González-Vázquez MP, 2018, ENERG CONVERS MANAGE, V176, P309, DOI 10.1016/j.enconman.2018.09.020; Guo J, 2022, J CHEM INF MODEL, V62, P2035, DOI 10.1021/acs.jcim.1c00284; Guo T., 2023, WHAT INDEED CAN GPT; Gupta AK, 2022, J CHEM THEORY COMPUT, V18, P2132, DOI 10.1021/acs.jctc.1c00504; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; Hoffmann J., 2022, Training compute-optimal large language models; Hong Z., 2022, BIGGER IS NOT ALWAYS; Hu E. J., 2021, LOW RANK ADAPTATION; Humphrey W, 1996, J MOL GRAPH MODEL, V14, P33, DOI 10.1016/0263-7855(96)00018-5; Hunt A., 2000, PRAGMATIC PROGRAMMER; Jablonka K. M., 2023, CHEMRXIV, DOI [10.26434/chemrxiv-2023-fw8n4, DOI 10.26434/CHEMRXIV-2023-FW8N4]; Jablonka KM, 2022, NAT CHEM, V14, P365, DOI 10.1038/s41557-022-00910-7; Jablonka KM, 2020, CHEM REV, V120, P8066, DOI 10.1021/acs.chemrev.0c00004; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Karpas E., 2022, MRKL SYSTEMS MODULAR; Karpathy A., 2023, HOTTEST NEW PROGRAMM; Kaur P, 2020, CERAM INT, V46, P5521, DOI 10.1016/j.ceramint.2019.11.066; Kearnes SM, 2021, J AM CHEM SOC, V143, P18820, DOI 10.1021/jacs.1c09820; Kim S, 2023, NUCLEIC ACIDS RES, V51, pD1373, DOI 10.1093/nar/gkac956; Kim Sunghwan, 2019, Nucleic Acids Res, V47, pD1102, DOI 10.1093/nar/gky1033; Kim S, 2018, NUCLEIC ACIDS RES, V46, pW563, DOI 10.1093/nar/gky294; Krenn M, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100588; Krenn M, 2022, NAT REV PHYS, V4, P761, DOI 10.1038/s42254-022-00518-3; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kullmer CNP, 2022, SCIENCE, V376, P532, DOI 10.1126/science.abn1885; Li J., 2023, EMPOWERING MOL DISCO; Liu J., 2022, LlamaIndex; Mamaghani ZG, 2023, J ENVIRON CHEM ENG, V11, DOI 10.1016/j.jece.2023.109643; Mikolov T, 2013, COMPUTING RES REPOSI; Mohsin M, 2023, NEW J CHEM, V47, P8679, DOI 10.1039/d3nj00316g; Mollick E. R., 2023, The Wharton School Research Paper, DOI DOI 10.2139/SSRN.4391243; Moosavi SM, 2020, J AM CHEM SOC, V142, P20273, DOI 10.1021/jacs.0c09105; Morgan Dane, 2020, Annual Review of Materials Research, V50, P71, DOI 10.1146/annurev-matsci-070218-010015; Narayanan B, 2019, CHEM SCI, V10, P7449, DOI 10.1039/c9sc02834j; neo4j, 2012, Neo4j-the world's leading graph database; Noé F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Peng Y, 2013, J AM CHEM SOC, V135, P11887, DOI 10.1021/ja4045289; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ramakrishnan R, 2015, J CHEM THEORY COMPUT, V11, P2087, DOI 10.1021/acs.jctc.5b00099; Ramakrishnan R, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.22; Ramos M. C., 2023, BAYESIAN OPTIMIZATIO; Ramprasad R, 2017, NPJ COMPUT MATER, V3, DOI 10.1038/s41524-017-0056-5; Rankovic B., 2022, BAYESIAN OPTIMISATIO, DOI [10.26434/chemrxiv-2022-nll2j, DOI 10.26434/CHEMRXIV-2022-NLL2J]; Rao GM, 2018, AUST J CIV ENG, V16, P53, DOI 10.1080/14488353.2018.1450716; Rego N, 2015, BIOINFORMATICS, V31, P1322, DOI 10.1093/bioinformatics/btu829; Sahoo BB, 2023, J ENERGY STORAGE, V65, DOI 10.1016/j.est.2023.107335; Sanchez-Lengeling B, 2018, SCIENCE, V361, P360, DOI 10.1126/science.aat2663; Schick Timo, 2023, Toolformer: Language models can teach themselves to use tools; Schmidt J, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0221-0; Schwaller P, 2018, CHEM SCI, V9, P6091, DOI 10.1039/c8sc02339e; Scrivener KL, 2018, CEMENT CONCRETE RES, V114, P2, DOI 10.1016/j.cemconres.2018.03.015; Selva B. S., 2021, INNOVATIVE DATA COMM, V59, P267, DOI DOI 10.1007/978-981-15-9651-323; Sengottuvelu R., 2018, JSONFORMER; Shen Y., 2023, Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face; Shi JL, 2023, J CHEM THEORY COMPUT, V19, P4631, DOI 10.1021/acs.jctc.2c01314; Shi J, 2022, ACS APPL MATER INTER, V14, P37161, DOI 10.1021/acsami.2c08891; Shields BJ, 2021, NATURE, V590, P89, DOI 10.1038/s41586-021-03213-y; Srivastava Aarohi, 2022, Beyond the imitation game: Quantifying and extrapolating the capabilities of language models; Suppiah DD, 2021, ENERG FUEL, V35, P17261, DOI 10.1021/acs.energyfuels.1c02406; Sutskever Ilya, 2022, OpenAI Blog; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Taylor R., 2022, LARGE LANGUAGE MODEL; Touvron H., 2023, Llama: Open and efficient foundation language models; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Vaswani A, 2017, ADV NEUR IN, V30; VENKATASUBRAMANIAN V, 1994, COMPUT CHEM ENG, V18, P833, DOI 10.1016/0098-1354(93)E0023-3; Volk AA, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-37139-y; Volker C., GREE N BUILDING MAT, DOI [10.13140/RG.2.2.29079.85925, DOI 10.13140/RG.2.2.29079.85925]; Walker N., 2023, EXTRACTING STRUCTURE; Ward L, 2019, MRS COMMUN, V9, P891, DOI 10.1557/mrc.2019.107; Watson J. L., 2022, BIORXIV, DOI [10.1101/2022.12.09.519842, DOI 10.1101/2022.12.09.519842]; Wei J., 2022, Advances in neural information processing systems, V35, P24824, DOI DOI 10.48550/ARXIV.2201.11903; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; White A., 2022, PAPER QA; White A., 2022, MARVIS VMD AUDIO TEX; White AD, 2023, NAT REV CHEM, V7, P457, DOI 10.1038/s41570-023-00502-0; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yao S., 2023, REACT SYNERGIZING RE	106	22	23	34	40	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2635-098X		DIGIT DISCOV	Digit. Discov.	OCT 9	2023	2	5					1233	1250		10.1039/d3dd00113j	http://dx.doi.org/10.1039/d3dd00113j			18	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Chemistry; Computer Science	X9GG1	38013906	Green Published, Green Submitted, gold			2024-07-03	WOS:001101447000001
J	Sun, YC; Zhang, Q; Bao, JS; Lu, YQ; Liu, SM				Sun, Yicheng; Zhang, Qi; Bao, Jinsong; Lu, Yuqian; Liu, Shimin			Empowering digital twins with large language models for global temporal feature learning	JOURNAL OF MANUFACTURING SYSTEMS			English	Article						Large Language Model (LLM); Digital Twin; Multi -Agent Systems (MAS)	AGENT	Digital Twin (DT), as an efficient technology for virtual-physical interaction, has demonstrated significant application potential in various industries. Intelligent agent-driven digital twin systems excel in analysis, decision-making, and control, making them highly suitable for manufacturing resource scheduling, diagnostic decision-making, and other requirements. However, current intelligent agents have notable deficiencies in adaptability, data utilization, and interpretability. This limitation undermines decision security and acceptability, creating barriers for user intervention. Therefore, this paper introduces a DT multi agent architecture driven by Large Language Models (LLMs). Agents perceive the characteristics of physical systems, particularly their temporal characteristics, by integrating data from various modalities. Multiple agents achieve insights through specific interaction mechanisms, while maintaining traceability. To showcase the advantages and characteristics of this architecture, we developed a typical application scenario for equipment maintenance. The effectiveness of each framework component was validated through ablation experiments. The experimental results suggest that the proposed framework holds promising and extensive application prospects.	[Sun, Yicheng; Zhang, Qi; Bao, Jinsong] Donghua Univ, Coll Mech Engn, Shanghai 201620, Peoples R China; [Lu, Yuqian] Univ Auckland, Dept Mech Engn, Auckland 1010, New Zealand; [Liu, Shimin] Hong Kong Polytech Univ, Dept Ind & Syst Engn, Hong Kong 999077, Peoples R China	Donghua University; University of Auckland; Hong Kong Polytechnic University	Bao, JS (corresponding author), Donghua Univ, Coll Mech Engn, Shanghai 201620, Peoples R China.	bao@dhu.edu.cn		BAO, Jinsong/0000-0003-1999-1003				Airaksinen T, 2022, ARGUMENTATION, V36, P85, DOI 10.1007/s10503-021-09556-0; [Anonymous], Ghost in the Minecraft: Hierarchical Agents for Minecraft via Large Language Models with Text-based Knowledge and Memory; [Anonymous], Agent Instructs Large Language Models to be General Zero-Shot Reasoners; Bi ZM, 2022, J IND INF INTEGR, V26, DOI 10.1016/j.jii.2021.100316; Bran A.M., 2023, ChemCrow: Augmenting large-language models with chemistry tools; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chain-of-Experts, When LLMs Meet Complex Operations Research Problems; Chang EY, 2023, 2023 IEEE 13TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE, CCWC, P351, DOI 10.1109/CCWC57344.2023.10099179; Chen H., 2023, Walking down the memory maze: Beyond context limit through interactive reading; Clark GI, 2015, COGNITIVE THER RES, V39, P863, DOI 10.1007/s10608-015-9707-3; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; Deloitte, 2018, Softw Integr Circuit, V406, P42; Dong HH, 2023, SYNTHETIC COMMUN, V53, P1579, DOI 10.1080/00397911.2023.2235622; Errandonea I, 2020, COMPUT IND, V123, DOI 10.1016/j.compind.2020.103316; Gao Z., 2015, IEEE T IND ELECTRON, V62, P3768, DOI DOI 10.1109/TIE.2015.2419013; Giordani S, 2013, COMPUT IND ENG, V64, P19, DOI 10.1016/j.cie.2012.09.004; Gruver N., 2023, Large language models are zero-shot time series forecasters; He H., 2023, SocREval: Large Language Models with the Socratic Method for Reference-Free Reasoning Evaluation 2023; Hong S., 2023, MetaGPT: Meta Programming for Multi-Agent Collaborative Framework 2023; Hu XS, 2020, IEEE IND ELECTRON M, V14, P65, DOI 10.1109/MIE.2020.2964814; Kojima T, 2022, Adv Neural Inf Process Syst, V35; Liu SM, 2023, COMPUT IND ENG, V175, DOI 10.1016/j.cie.2022.108827; Madaan A., 2023, SelfRefine: Iterative Refinement with Self-Feedback 2023; Modi S, 2011, COMPUT AIDED DESIGN, V43, P170, DOI 10.1016/j.cad.2010.10.006; MultiReAct, Multimodal Tools Augmented Reasoning-Acting Traces for Embodied Agent Planning; Nie QW, 2023, ROBOT CIM-INT MANUF, V82, DOI 10.1016/j.rcim.2023.102543; Park JS., 2023, GENERATIVE AGENTS IN; Prospector, Improving LLM Agents with Self-Asking and Trajectory Ranking; Shakeel A, 2023, ENERGY, V278, DOI 10.1016/j.energy.2023.127637; Shokoohi-Yekta M, 2017, DATA MIN KNOWL DISC, V31, P1, DOI 10.1007/s10618-016-0455-0; Sun C., 2023, TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series, V2023; Taylor SJ, 2018, AM STAT, V72, P37, DOI 10.1080/00031305.2017.1380080; Tomko M, 2019, ENVIRON PLAN B-URBAN, V46, P395, DOI 10.1177/2399808318816992; Touvron H., 2023, Llama: Open and efficient foundation language models; Tran MK, 2020, ALGORITHMS, V13, DOI 10.3390/a13030062; Vaswani A, 2017, ADV NEUR IN, V30; Wang Y., 2022, SelfInstruct: Aligning Language Models with Self-Generated Instructions, V2022, P13484, DOI [10.18653/v1/2023.acl-long.754, DOI 10.18653/V1/2023.ACL-LONG.754]; Wang Y., 2023, Enhancing Recommender Systems with Large Language Model Reasoning Graphs 2023; Wei JS, 2022, ADV NEUR IN; Welker S., 2022, Socratic models: Composing zero-shot multimodal reasoning with language; Xia KS, 2021, J MANUF SYST, V58, P210, DOI 10.1016/j.jmsy.2020.06.012; Zhang Huihui, 2023, Computer Integrated Manufacturing Systems, P2086, DOI 10.13196/j.cims.2023.06.024; Zheng L., 2023, Judging llm-as-a-judge with mt-bench and chatbot arena; Zhou Y., 2022, Large language models are human-level prompt engineers	44	0	0	23	23	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0278-6125	1878-6642		J MANUF SYST	J. Manuf. Syst.	JUN	2024	74						83	99		10.1016/j.jmsy.2024.02.015	http://dx.doi.org/10.1016/j.jmsy.2024.02.015		MAR 2024	17	Engineering, Industrial; Engineering, Manufacturing; Operations Research & Management Science	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Operations Research & Management Science	NU4C7					2024-07-03	WOS:001202945100001
C	Saha, T; Ganguly, D; Saha, S; Mitra, P			ACM	Saha, Tulika; Ganguly, Debasis; Saha, Sriparna; Mitra, Prasenjit			Workshop on Large Language Models' Interpretability and Trustworthiness (LLMIT)	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Large Language Model; Trustworthiness; Interpretability; In-context Learning; Explainability		Large language models (LLMs), when scaled from millions to billions of parameters, have been demonstrated to exhibit the so-called 'emergence' effect, in that they are not only able to produce semantically correct and coherent text, but are also able to adapt themselves surprisingly well with small changes in contexts supplied as inputs (commonly called prompts). Despite producing semantically coherent and potentially relevant text for a given context, LLMs are vulnerable to yield incorrect information. This misinformation generation, or the so-called hallucination problem of an LLM, gets worse when an adversary manipulates the prompts to their own advantage, e.g., generating false propaganda to disrupt communal harmony, generating false information to trap consumers with target consumables etc. Not only does the consumption of an LLM-generated hallucinated content by humans pose societal threats, such misinformation, when used as prompts, may lead to detrimental effects for in-context learning (also known as few-shot prompt learning). With reference to the above-mentioned problems of LLM usage, we argue that it is necessary to foster research on topics related to not only identifying misinformation from LLM-generated content, but also to mitigate the propagation effects of this generated misinformation on downstream predictive tasks thus leading to more robust and effective leveraging in-context learning.	[Saha, Tulika] Univ Liverpool, Dept Comp Sci, Liverpool, England; [Ganguly, Debasis] Univ Glasgow, Sch Comp Sci, Glasgow, Scotland; [Saha, Sriparna] Indian Inst Technol Patna, Dept Comp Sci, Patna, India; [Mitra, Prasenjit] L3S Res Ctr, Hannover, Germany; [Mitra, Prasenjit] Penn State Univ, University Pk, PA USA	University of Liverpool; University of Glasgow; Indian Institute of Technology System (IIT System); Indian Institute of Technology (IIT) - Patna; Leibniz University Hannover; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park	Saha, T (corresponding author), Univ Liverpool, Dept Comp Sci, Liverpool, England.	sahatulika15@gmail.com; debasis.ganguly@glasgow.ac.uk; sriparna@iitp.ac.in; mitra@l3s.de	Ganguly, Debasis/X-9560-2019; Saha, Tulika/AAA-6724-2022	Ganguly, Debasis/0000-0003-0050-7138; Saha, Tulika/0000-0002-3252-0997				Arora Simran, 2022, ARXIV221002441 CS CL; Bohnet Bernd, 2023, ARXIV221208037 CS CL; Chen Pin-Yu, 2023, IEEE CVF C COMP VIS; Dziri N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5271; Ganguly D, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1163, DOI 10.1145/3437963.3441839; Ghosh Saptarshi, 2017, SIGIR FORUM, V51, P36, DOI [10.1145/3130332.3130338, DOI 10.1145/3130332.3130338]; Ghosh Saptarshi, 2018, SIGIR FORUM, V52, P163; Jain R., 2022, 2022 INT JOINT C NEU, P1; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jones GJF, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P5167, DOI 10.1145/3511808.3557939; Li Minghan, 2022, P 2 WORKSH TRUSTW NA, P1, DOI [10.18653/v1/2022.trustnlp-1.1, DOI 10.18653/V1/2022.TRUSTNLP-1.1]; Mehrabi N, 2022, P 2 WORKSH TRUSTW NA, DOI [10.18653/v1/2022.trustnlp-1.2, DOI 10.18653/V1/2022.TRUSTNLP-1.2]; Mysore Sheshera, 2023, ARXIV230602250 CS IR; Ni Jianmo, 2021, ARXIV211207899 CS IR; OpenAI, 2023, ARXIV230308774 CS CL; Pradeep Ronak, 2023, ARXIV230511841 CS IR; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Saha T, 2023, LECT NOTES COMPUT SC, V13982, P349, DOI 10.1007/978-3-031-28241-6_36; Saha T, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2436; Saha T, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2650, DOI 10.1145/3477495.3531912; Saha T, 2023, IEEE T COMPUT SOC SY, V10, P1130, DOI 10.1109/TCSS.2022.3143763; Shmueli B, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3758; Veselovsky Veniamin, 2023, ARXIV230607899 CS CL; Wang HJ, 2023, PROC CVPR IEEE, P12044, DOI 10.1109/CVPR52729.2023.01159; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088	25	1	1	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5290	5293		10.1145/3583780.3615311	http://dx.doi.org/10.1145/3583780.3615311			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Accepted			2024-07-03	WOS:001161549505073
C	Delnevo, G; Andruccioli, M; Mirri, S			IEEE	Delnevo, Giovanni; Andruccioli, Manuel; Mirri, Silvia			On the Interaction with Large Language Models for Web Accessibility: Implications and Challenges	2024 IEEE 21ST CONSUMER COMMUNICATIONS & NETWORKING CONFERENCE, CCNC	IEEE Consumer Communications and Networking Conference		English	Proceedings Paper	IEEE 21st Consumer Communications and Networking Conference (CCNC)	JAN 06-09, 2024	Las Vegas, NV	IEEE, VAIMEE, IEEE Commun Soc		Web Accessibility; Large Language Models; Human-Computer Interaction; ChatGPT		The widespread diffusion of Large Language Models (LLMs) has ushered in a transformative era across numerous research domains, including web accessibility. In fact, they can potentially offer automated solutions for generating accessible content, performing accessibility testing, and enhancing the overall user experience for individuals with disabilities. In this paper, we investigate how LLMs can be successfully employed to evaluate and correct web accessibility. Then, we delve into the positive implications and the current challenges derived from the interaction between developers and LLMs in this specific context. Finally, we present some future directions that could be explored to ensure that web content remains accessible to all.	[Delnevo, Giovanni; Andruccioli, Manuel; Mirri, Silvia] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy	University of Bologna	Delnevo, G (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.	giovanni.delnevo2@unibo.it; manuel.andruccioli@studio.unibo.it; silvia.mirri@unibo.it						Delnevo G, 2023, INTERNET THINGS-NETH, V22, DOI 10.1016/j.iot.2023.100729; Delnevo G, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21072361; Delnevo G, 2020, MOBILE NETW APPL, V25, P977, DOI 10.1007/s11036-019-01233-7; Grantham J., 2012, P 13 AUSTR US INT C, V126, P21; Hämäläinen P, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580688; Iannuzzi Nicola, 2023, GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good, P307, DOI 10.1145/3582515.3609549; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Liu LX, 2023, J BIG DATA-GER, V10, DOI 10.1186/s40537-023-00713-8; Monti L, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103692; Nozza D, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P68; Othman A, 2023, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS, PETRA 2023, P707, DOI 10.1145/3594806.3596542; Petrie H., 2015, P 12 INT WEB ALL C F, P35, DOI DOI 10.1145/2745555.2746653; Prandi C, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093134; Roccetti M, 2020, HUM-CENTRIC COMPUT I, V10, DOI 10.1186/s13673-020-0213-6; Salomoni P, 2008, ACM T INTERNET TECHN, V8, DOI 10.1145/1323651.1323655; Taeb M, 2024, Arxiv, DOI arXiv:2310.02424; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Zan DG, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7443	19	0	0	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2331-9852		979-8-3503-0457-2	CONSUM COMM NETWORK			2024										10.1109/CCNC51664.2024.10454680	http://dx.doi.org/10.1109/CCNC51664.2024.10454680			6	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering; Telecommunications	BW7KR					2024-07-03	WOS:001192142600208
C	Li, YH; Wang, SF; Ding, H; Chen, H			ACM	Li, Yinheng; Wang, Shaofei; Ding, Han; Chen, Hang			Large Language Models in Finance: A Survey	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		Large Language Models; Generative AI; Natural Language Processing; Finance		Recent advances in large language models (LLMs) have opened new possibilities for artificial intelligence applications in finance. In this paper, we provide a practical survey focused on two key aspects of utilizing LLMs for financial tasks: existing solutions and guidance for adoption. First, we review current approaches employing LLMs in finance, including leveraging pretrained models via zero-shot or few-shot learning, fine-tuning on domain-specific data, and training custom LLMs from scratch. We summarize key models and evaluate their performance improvements on financial natural language processing tasks. Second, we propose a decision framework to guide financial professionals in selecting the appropriate LLM solution based on their use case constraints around data, compute, and performance needs. The framework provides a pathway from lightweight experimentation to heavy investment in customized LLMs. Lastly, we discuss limitations and challenges around leveraging LLMs in financial applications. Overall, this survey aims to synthesize the state-of-the-art and provide a roadmap for responsibly applying LLMs to advance financial AI.	[Li, Yinheng; Wang, Shaofei; Ding, Han] Columbia Univ, New York, NY 10025 USA; [Chen, Hang] NYU, New York, NY USA	Columbia University; New York University	Li, YH (corresponding author), Columbia Univ, New York, NY 10025 USA.	yl4039@columbia.edu; sw3316@columbia.edu; hd2412@columbia.edu; hc2798@nyu.edu		Li, Yinheng/0000-0002-7740-2484				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Almutiri T., 2022, Int. J. Inf. Technol. Comput. Sci, V2, P1, DOI [10.5815/ijitcs.2022.02.01, DOI 10.5815/IJITCS.2022.02.01]; [Anonymous], 2023, Chatbots in consumer finance; [Anonymous], 2023, Auto-GPT: An Autonomous GPT-4 Experiment; Ashish, 2020, FinAID, A Financial Advisor Application using AI, DOI [10.35940/ijrte.a2951.059120, DOI 10.35940/IJRTE.A2951.059120]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Babaei Pedram, 2023, Fin-LLAMA: Efficient Finetuning of Quantized LLMs for Finance; Bengio Y, 2001, ADV NEUR IN, V13, P932; Chen MY, 2011, COMPUT MATH APPL, V62, P4514, DOI 10.1016/j.camwa.2011.10.030; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fazlija B, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10132156; Foy Peter, 2023, GPT-4 for Financial Statements: Building an AI Analyst; Geng X., 2023, OpenLLaMA: An open reproduction of LLaMA; Gholami A., 2021, arXiv; Goodell JW, 2021, J BEHAV EXP FINANC, V32, DOI 10.1016/j.jbef.2021.100577; Graves A, 2014, Arxiv, DOI [arXiv:1308.0850, 10.48550/arXiv.1308.0850, DOI 10.48550/ARXIV.1308.0850]; Gupta A, 2020, FINANC INNOV, V6, DOI 10.1186/s40854-020-00205-1; Harrison Chase, 2022, LangChain; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, 10. 48550/arXiv.1905.12322, DOI 10.48550/ARXIV.1905.12322]; Kim KJ, 2003, NEUROCOMPUTING, V55, P307, DOI 10.1016/S0925-2312(03)00372-2; Li YH, 2023, Arxiv, DOI arXiv:1911.11880; Li Yinheng, 2023, INT C REC ADV NAT LA; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin Wei, 2023, Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality; Lu DK, 2023, Arxiv, DOI arXiv:2302.09432; Luo CC, 2017, ENG APPL ARTIF INTEL, V65, P465, DOI 10.1016/j.engappai.2016.12.002; Mashrur A, 2020, IEEE ACCESS, V8, P203203, DOI 10.1109/ACCESS.2020.3036322; Microsoft, 2023, Semantic Kernel; Misischia C. V., 2022, Procedia Computer Science, V201, P421, DOI [10.1016/J.PROCS.2022.03.055, DOI 10.1016/J.PROCS.2022.03.055]; Ozbayoglu AM, 2020, Arxiv, DOI arXiv:2002.05786; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pagliaro C, 2021, ICAIF 2021: THE SECOND ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, DOI 10.1145/3490354.3494388; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Radovanovic Igor, 2023, Auto-GPT for finance-an exploratory guide-algotrading101 blog; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Roy Abhimanyu, 2018, 2018 Systems and Information Engineering Design Symposium (SIEDS), P129, DOI 10.1109/SIEDS.2018.8374722; Sezer OB, 2017, PROCEDIA COMPUT SCI, V114, P473, DOI 10.1016/j.procs.2017.09.031; Son Hugh, 2023, JPMorgan is developing a CHATGPT-like A.I. service that gives investment advice; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang YQ, 2020, Arxiv, DOI [arXiv:1904.05046, DOI 10.48550/ARXIV.1904.05046]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wen QS, 2022, Arxiv, DOI [arXiv:2202.07125, 10.48550/arxiv.2202.07125, DOI 10.48550/ARXIV.2202.07125, 10.48550/arXiv.2202.07125]; West D, 2000, COMPUT OPER RES, V27, P1131, DOI 10.1016/S0305-0548(99)00149-5; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Xie QQ, 2023, Arxiv, DOI arXiv:2306.05443; Xing FZ, 2018, ARTIF INTELL REV, V50, P49, DOI 10.1007/s10462-017-9588-9; Yang H, 2023, arXiv; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yu YangMu, 2023, Cornucopia-LLaMA-Fin-Chinese; Zeng A., 2023, 11 INT C LEARN REPR; Zhang Boyu, 2023, arXiv; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhang WX, 2023, Arxiv, DOI arXiv:2305.15005; Zhang XY, 2023, Arxiv, DOI arXiv:2305.12002; Zhang Z., 2020, The Journal of Financial Data Science, V2, P8; Zolotareva E, 2021, Arxiv, DOI arXiv:2104.09341	67	2	2	52	52	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							374	382		10.1145/3604237.3626869	http://dx.doi.org/10.1145/3604237.3626869			9	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		Green Submitted, hybrid			2024-07-03	WOS:001124982700044
C	Prasad, A; Hase, P; Zhou, X; Bansal, M		Vlachos, A; Augenstein, I		Prasad, Archiki; Hase, Peter; Zhou, Xiang; Bansal, Mohit			GRIPS: Gradient-free, Edit-based Instruction Search for Prompting Large Language Models	17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023			English	Proceedings Paper	17th Conference of the European-Chapter of the Association-for-Computational-Linguistics (EACL)	MAY 02-06, 2023	Dubrovnik, CROATIA	Assoc Computat Linguist, European Chapter, Grammarly, Liveperson, Amazon Sci, Bloomberg, Duolingo, Adobe, Babelscape				Providing natural language instructions in prompts is a useful new paradigm for improving task performance of large language models in a zero-shot setting. Recent work has aimed to improve such prompts via manual rewriting or gradient-based tuning. However, manual rewriting is time-consuming and requires subjective interpretation, while gradient-based tuning can be extremely computationally demanding for large models and may not be feasible for API-based models. In this work, we introduce Gradient-free Instructional Prompt Search (GRIPS), a gradient-free, edit-based search approach for improving task instructions for large language models. GRIPS takes in instructions designed for humans and automatically returns an improved, edited prompt, while allowing for API-based tuning. With InstructGPT models, GRIPS improves the average task performance by up to 4.30 percentage points on eight classification tasks from the NATURAL-INSTRUCTIONS dataset (with similar improvements for OPT, BLOOM, and FLANT5). We see improvements for both instructiononly prompts and instruction + k-shot examples prompts. Notably, GRIPS outperforms manual rewriting and purely example-based prompts while controlling for the available compute and data budget. Further, performance of GRIPS is comparable to select gradient-based tuning approaches. Qualitatively, we show our edits can simplify instructions and at times make them incoherent but nonetheless improve accuracy.	[Prasad, Archiki; Hase, Peter; Zhou, Xiang; Bansal, Mohit] Univ N Carolina, Chapel Hill, NC 27599 USA	University of North Carolina; University of North Carolina Chapel Hill	Prasad, A (corresponding author), Univ N Carolina, Chapel Hill, NC 27599 USA.	archiki@cs.unc.edu; peter@cs.unc.edu; xzh@cs.unc.edu; mbansal@cs.unc.edu			NSF-CAREER Award [1846185]; DARPA MachineCommonsense (MCS) Grant [N66001-19-2-4031]; ONR [N000141812871]; Google PhD Fellowship; U.S. Department of Defense (DOD) [N000141812871] Funding Source: U.S. Department of Defense (DOD)	NSF-CAREER Award(National Science Foundation (NSF)NSF - Office of the Director (OD)); DARPA MachineCommonsense (MCS) Grant; ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); Google PhD Fellowship(Google Incorporated); U.S. Department of Defense (DOD)(United States Department of Defense)	We thank the reviewers and the area chairs for their helpful comments and feedback. We thank OpenAI for providing academic access to their API. We also thank Derek Tam, Prateek Yadav, Yi-Lin Sung, Jaemin Cho, and Shiyue Zhang for their helpful comments. This work was supported by NSF-CAREER Award 1846185, DARPA MachineCommonsense (MCS) Grant N66001-19-2-4031, ONR Grant N000141812871, and a Google PhD Fellowship. The views contained in this article are those of the authors and not of the funding agency.	Andreas Jacob, 2018, P 2018 C N AM CHAPTE, P2166, DOI DOI 10.18653/V1/N18-1197; Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P95; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chung Hyung Won, 2022, ARXIV221011416; Efrat Avia, 2020, ARXIV201011982; Efron B, 1994, INTRO BOOTSTRAP, DOI 10.1007/978-1-4899-4541-9; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Houlsby N, 2019, PR MACH LEARN RES, V97; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Khashabi Daniel, 2021, ARXIV211208348; Komatsuzaki A, 2021, GPT-J-6B: 6B JAX-Based Transformer; Kumar Dhruv, 2020, P 58 ANN M ASS COMP, P7918, DOI DOI 10.18653/V1/2020.ACL-MAIN.707; Kumar S, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4507; Le Scao T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2627; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Liu Jiachang, 2021, ARXIV210106804; Liu Pengfei, 2021, arXiv; Liu Xiao, 2021, ARXIV210310385; Logan IV Robert L, 2021, ENLSP WORKSH NEURIPS; Lu Yao, 2022, P 60 ANN M ASS COMP, V1; Min Sewon, 2022, ARXIV220212837; Mishra Swaroop, 2022, P 60 ANN M ASS COMP; Mitchell M., 1998, INTRO GENETIC ALGORI, DOI [10.7551/mitpress/3927.001.0001, DOI 10.1016/S0898-1221(96)90227-8]; Ouyang Long, 2022, OPENAI BLOG; Perez E, 2021, ADV NEUR IN; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Pirlot M, 1996, EUR J OPER RES, V92, P493, DOI 10.1016/0377-2217(96)00007-0; Qin GH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5203; Radford A., 2018, IMPROVING LANGUAGE U; Radford Alec, 2019, OPENAI BLOG; Razeghi Yasaman, 2022, ARXIV220207206; Sanh Victor, 2022, INT C LEARNING REPRE; Scao T. L., 2022, arXiv preprint arXiv:2211.05100; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schick T, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P390; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Sun Tianxiang, 2022, ARXIV220103514; Tam D, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P4980; Varshney N, 2022, PROCEEDINGS OF THE 7TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P221; Wang Y., 2022, ARXIV220407705; Webson Albert, 2021, ARXIV210901247; Wei J., 2022, INT C LEARN REPR; Weidinger Laura, 2021, arXiv preprint arXiv:2112.04359; Weller O, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1361; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Xie Shufang, 2022, INT C LEARN REPR; Zhang Biao, 2020, P 5 C MACH TRANSL, P503; Zhang J., 2020, PMLR, P11328; Zhang S., 2022, arXiv; Zhao TZ, 2021, PR MACH LEARN RES, V139	52	2	2	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-44-9				2023							3845	3864						20	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6RX					2024-07-03	WOS:001181056902058
C	Mounsif, M; Zehnder, K; Motie, Y; Adam-Gaxotte, Z			IEEE	Mounsif, Mehdi; Zehnder, Killian; Motie, Yassine; Adam-Gaxotte, Zoran			SwarMind: Harnessing Large Language Models for Flock Dynamics	2023 10TH INTERNATIONAL CONFERENCE ON SOFT COMPUTING & MACHINE INTELLIGENCE, ISCMI	International Conference on Soft Computing & Machine Intelligence ISCMI		English	Proceedings Paper	10th International Conference on Soft Computing and Machine Intelligence (ISCMI)	NOV 25-26, 2023	ELECTR NETWORK	IEEE, IEEE Mexico Section, IEEE Mexico Council, IEEE CIS Mexico Chapter, IICCI, Consejo MX		Large Language Models; Swarm Intelligence; Reinforcement Learning; Intelligent Control; Multi-Agent Systems		The deployment of autonomous agent swarms has witnessed a rapid increase in a variety of fields, from logistics to surveillance. This prevalence stems from the complex objectives they can accomplish through simple interactions, their adaptive behavior, and their inherent robustness to potential disturbances. Despite these advantages, achieving control over such systems remains a formidable challenge, often necessitating the use of approximations or domain-specific heuristics. As demonstrated by recent works, large language models (LLMs) display a robust capacity to excel across a diverse array of tasks. In this work, we extend the exploration of LLM's capabilities into the niche domain of flock driving. Specifically, our study presents a comparative analysis of LLMs and reinforcement learning (RL) in a fair setting, scrutinizing their performances under various prompting strategies. Furthermore, it investigates the potential of eliciting more sophisticated behaviors from LLMs through textual instructions, offering a deeper understanding of their limitations and strengths in swarm control and management. The results illuminate several potential shortcomings while concurrently uncovering exciting prospects and extensions. This research therefore advances our understanding of the applicability of LLMs to the intricate field of swarm control, opening doors to their potential use in domains hitherto unexplored.	[Mounsif, Mehdi; Zehnder, Killian] Akkodis Res, Clermont Ferrand, France; [Motie, Yassine] Akkodis Res, Toulouse, France; [Adam-Gaxotte, Zoran] Akkodis Res, Nantes, France		Mounsif, M (corresponding author), Akkodis Res, Clermont Ferrand, France.	mehdi.mounsif@akkodis.com; killian.zehnder@akkodis.com; yassine.motie@akkodis.com; zoran.adam-gaxotte@akkodis.com			Akkodis group	Akkodis group	This work has been sponsored by the Akkodis group.	[Anonymous], 2016, Networks (Graph-Hoc); Baker B., 2020, INT C LEARNING REPRE; Bonabeau E., 1999, Swarm Intelligence: From Natural to Artificial Systems, DOI 10.1093/oso/9780195131581.001.0001; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; COHEN A., 2021, arXiv; Deepmind G., 2023, Tree of thoughts: Deliberate problem solving with large language models; DEY S., 2023, Electronics, V12, P1; Fan L., 2022, 36 C NEURAL INFORM P; Freitas D, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030362; GARRIDO-MERCHAN E.C., 2023, Simulating h.p. lovecraft horror literature with the chatgpt large language model; Kletzander L, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P232, DOI 10.1145/3512290.3528876; LIU T., 2023, Goat: Fine-tuned llama outperforms gpt-4 on arithmetic tasks; OpenAI, 2023, GPT-4 Technical Report; Park JS., 2023, GENERATIVE AGENTS IN; Rubin O., 2021, ARXIV; Schulman J., 2017, ARXIV; Sorensen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P819; Touvron H., 2023, Llama: Open and efficient foundation language models; Wang HR, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P40, DOI 10.1145/3512290.3528710; Wei J., 2022, ARXIV	20	1	1	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2640-0154	2640-0146	979-8-3503-5937-4	INT CONF SOFT COMP			2023							171	177		10.1109/ISCMI59957.2023.10458573	http://dx.doi.org/10.1109/ISCMI59957.2023.10458573			7	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IV					2024-07-03	WOS:001190966200032
J	Demszky, D; Yang, DY; Yeager, DS; Bryan, CJ; Clapper, M; Chandhok, S; Eichstaedt, JC; Hecht, C; Jamieson, J; Johnson, M; Jones, M; Krettek-Cobb, D; Lai, LS; Jonesmitchell, N; Ong, DC; Dweck, CS; Gross, JJ; Pennebaker, JW				Demszky, Dorottya; Yang, Diyi; Yeager, David; Bryan, Christopher; Clapper, Margarett; Chandhok, Susannah; Eichstaedt, Johannes; Hecht, Cameron; Jamieson, Jeremy; Johnson, Meghann; Jones, Michaela; Krettek-Cobb, Danielle; Lai, Leslie; Jonesmitchell, Nirel; Ong, Desmond; Dweck, Carol; Gross, James; Pennebaker, James			Using large language models in psychology	NATURE REVIEWS PSYCHOLOGY			English	Article							RESPONSES; MINDSET; STRESS	Large language models (LLMs), such as OpenAI's GPT-4, Google's Bard or Meta's LLaMa, have created unprecedented opportunities for analysing and generating language data on a massive scale. Because language data have a central role in all areas of psychology, this new technology has the potential to transform the field. In this Perspective, we review the foundations of LLMs. We then explain how the way that LLMs are constructed enables them to effectively generate human-like linguistic output without the ability to think or feel like a human. We argue that although LLMs have the potential to advance psychological measurement, experimentation and practice, they are not yet ready for many of the most transformative psychological applications - but further research and development may enable such use. Next, we examine four major concerns about the application of LLMs to psychology, and how each might be overcome. Finally, we conclude with recommendations for investments that could help to address these concerns: field-initiated 'keystone' datasets; increased standardization of performance benchmarks; and shared computing and analysis infrastructure to ensure that the future of LLM-powered research is equitable. Large language models (LLMs), which can generate and score text in human-like ways, have the potential to advance psychological measurement, experimentation and practice. In this Perspective, Demszky and colleagues describe how LLMs work, concerns about using them for psychological purposes, and how these concerns might be addressed.	[Demszky, Dorottya] Stanford Univ, Grad Sch Educ, Stanford, CA 94305 USA; [Yang, Diyi] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA; [Yeager, David; Bryan, Christopher; Clapper, Margarett; Hecht, Cameron; Johnson, Meghann; Jones, Michaela; Jonesmitchell, Nirel; Ong, Desmond] Univ Texas Austin, Texas Behav Sci & Policy Inst, Austin, TX 78712 USA; [Yeager, David; Clapper, Margarett; Hecht, Cameron; Ong, Desmond; Pennebaker, James] Univ Texas Austin, Dept Psychol, Austin, TX 78712 USA; [Bryan, Christopher] Univ Texas Austin, Dept Business Govt & Soc, Austin, TX 78712 USA; [Chandhok, Susannah; Krettek-Cobb, Danielle; Lai, Leslie] Google LLC, Mountain View, CA USA; [Eichstaedt, Johannes; Dweck, Carol; Gross, James] Stanford Univ, Dept Psychol, Stanford, CA USA; [Eichstaedt, Johannes] Stanford Univ, Inst Human Ctr AI, Stanford, CA USA; [Jamieson, Jeremy] Univ Rochester, Dept Psychol, Rochester, NY USA	Stanford University; Stanford University; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; University of Texas System; University of Texas Austin; Google Incorporated; Stanford University; Stanford University; University of Rochester	Demszky, D (corresponding author), Stanford Univ, Grad Sch Educ, Stanford, CA 94305 USA.; Yang, DY (corresponding author), Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.; Yeager, DS (corresponding author), Univ Texas Austin, Texas Behav Sci & Policy Inst, Austin, TX 78712 USA.; Yeager, DS (corresponding author), Univ Texas Austin, Dept Psychol, Austin, TX 78712 USA.	ddemszky@stanford.edu; diyiy@stanford.edu; yeagerds@austin.utexas.edu	Ong, Dennis Cinco/S-7835-2017	Eichstaedt, Johannes/0000-0002-3220-2972; Demszky, Dorottya/0000-0002-6759-9367; Hecht, Cameron/0000-0003-4842-6003; Bryan, Christopher/0000-0002-1582-4411; Ong, Desmond/0000-0002-6781-8072; Clapper, Mac/0000-0002-8932-6116	National Science Foundation [1761179, 2201928]; National Institutes of Health [R01HD084772, P2CHD042849]; William and Melinda Gates Foundation [INV-047751, INV-004519]; Jacobs Foundation; Institute for Human-Centered A.I. at Stanford University; Bill and Melinda Gates Foundation [INV-004519] Funding Source: Bill and Melinda Gates Foundation	National Science Foundation(National Science Foundation (NSF)); National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA); William and Melinda Gates Foundation; Jacobs Foundation; Institute for Human-Centered A.I. at Stanford University; Bill and Melinda Gates Foundation(Bill & Melinda Gates Foundation)	This work was supported by the National Science Foundation under award numbers 1761179 and 2201928 (PI: D.S.Y.), by the National Institutes of Health under award numbers R01HD084772 (PI: D.S.Y.) and P2CHD042849 (Population Research Center), and by the William and Melinda Gates Foundation under awards INV-047751 and INV-004519 (PI: D.S.Y.). This work was also supported by an Advanced Research Fellowship from the Jacobs Foundation to D.S.Y., and the Institute for Human-Centered A.I. at Stanford University to J.C.E. The content is solely the responsibility of the authors and does not necessarily represent the official views of the funding agencies. The authors also thank C. Smith for creating the original version of the figures included with the original submission. The glossary definitions were generated by GPT-4 in May 2023 and edited by the authors.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aher G, 2022, Arxiv, DOI arXiv:2208.10264; Aher GV, 2023, INT C MACHINE LEARNI, P337; Allen NB, 2019, J AFFECT DISORDERS, V250, P163, DOI 10.1016/j.jad.2019.03.044; Andrew Schwartz H., 2017, P 2017 C EMPIRICAL M, P55, DOI DOI 10.18653/V1/D17-2010; [Anonymous], 2023, ChatGPT used by teachers more than students, new survey from Walton Family Foundation Finds; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Aronson E, 1999, AM PSYCHOL, V54, P875, DOI 10.1037/h0088188; Ashokkumar A, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg7843; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Barocas Solon, Fairness and machine learning; Basta C, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P33; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bhatia S, 2022, CURR DIR PSYCHOL SCI, V31, P207, DOI 10.1177/09637214211068113; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Birhane A, 2020, Arxiv, DOI [arXiv:2009.14258, DOI 10.48550/ARXIV.2009.14258]; Birhane A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100205; Blei D., 2001, Advances in neural information processing systems, V14; Blodgett SL, 2020, Arxiv, DOI arXiv:2005.14050; Boyd R. L., 2022, The Development and Psychometric Properties of LIWC-22, DOI DOI 10.13140/RG.2.2.23890.43205; Boyd RL, 2021, J LANG SOC PSYCHOL, V40, P21, DOI [10.1177/0261927x20967028, 10.1177/0261927X20967028]; Brady W. J., 2023, PREPRINT, DOI DOI 10.31219/OSF.IO/YW5AH; Brady WJ, 2019, J EXP PSYCHOL GEN, V148, P1802, DOI 10.1037/xge0000532; Brown T., 2020, Advances in Neural Information Processing Systems, V331, P877; Chang EH, 2019, P NATL ACAD SCI USA, V116, P7778, DOI 10.1073/pnas.1816076116; Chang J, 2009, ADV NEURAL INFORM PR, V22, DOI DOI 10.5555/2984093.2984126; Cheryan S, 2020, PSYCHOL REV, V127, P1022, DOI 10.1037/rev0000209; Cimpian A, 2014, BEHAV BRAIN SCI, V37, P461, DOI 10.1017/S0140525X13002197; Clapper M., 2023, P WORKSH EQ DIV INCL; Collins E., 2021, Lamda: Our breakthrough conversation technology; Crum AJ, 2017, ANXIETY STRESS COPIN, V30, P379, DOI 10.1080/10615806.2016.1275585; Crum AJ, 2013, J PERS SOC PSYCHOL, V104, P716, DOI 10.1037/a0031201; De Choudhury M., 2013, P INT AAAI C WEB SOC, V7, P128, DOI [10.1109/IRI.2012.6302998, DOI 10.1109/IRI.2012.6302998]; Demszky D., 2023, P 10 ACM C LEARN SCA, P59; Demszky D, 2023, EDUC EVAL POLICY AN, DOI 10.3102/01623737231169270; Eichstaedt JC, 2015, PSYCHOL SCI, V26, P159, DOI 10.1177/0956797614557867; Eliot L., 2023, Forbes; ElSherief M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P345; Erscoi L., 2023, PREPRINT, DOI [10.31235/osf.io/jqxb6, DOI 10.31235/OSF.IO/JQXB6]; Fiske S.T., 2010, HDB SOCIAL PSYCHOL, V5th, P941, DOI [10.1002/9780470561119.socpsy002026, DOI 10.1002/9780470561119.SOCPSY002026]; Gaddis S. Michael., 2018, Audit studies: Behind the scenes with theory, method, and nuance, DOI [DOI 10.1007/978-3-319-71153-9_1, DOI 10.1007/978-3-319-71153-91]; Gehrmann S, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P96; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Gross JJ, 1998, J PERS SOC PSYCHOL, V74, P224, DOI 10.1037/0022-3514.74.1.224; Guest O., 2023, Computational Brain & Behavior, DOI DOI 10.1007/S42113-022-00166-X; Harris Camille, 2022, FAccT; Hecht CA, 2022, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2216315120; Hecht CA, 2021, ADV CHILD DEV BEHAV, V61, P169, DOI 10.1016/bs.acdb.2021.04.004; Hunkins NC, 2022, LAK22 CONFERENCE PROCEEDINGS: THE TWELFTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P230, DOI 10.1145/3506860.3506896; Jacobs J, 2022, TEACH TEACH EDUC, V112, DOI 10.1016/j.tate.2022.103631; Judd CM, 2012, J PERS SOC PSYCHOL, V103, P54, DOI 10.1037/a0028347; Karinshak Elise, 2023, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3579592; Lai CK, 2014, J EXP PSYCHOL GEN, V143, P1765, DOI 10.1037/a0036260; Lai VV, 2023, Arxiv, DOI [arXiv:2301.09656, 10.48550/arXiv.2301.09656]; Landauer TK, 1998, DISCOURSE PROCESS, V25, P259, DOI 10.1080/01638539809545028; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Landi H., 2023, Fierce Healthcare; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Llorens A, 2021, NEURON, V109, P2047, DOI 10.1016/j.neuron.2021.06.002; Lord SP, 2015, BEHAV THER, V46, P296, DOI 10.1016/j.beth.2014.11.002; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Luo F., 2019, P 57 ANN M ASS COMP; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Marcus, 2020, GOOGLES MEDICAL AI W; Marcus G., 2023, The Road to AI We Can Trust; MESSICK S, 1995, AM PSYCHOL, V50, P741, DOI 10.1037/0003-066X.50.9.741; Metz C., 2023, New York Times; Michelmann S, 2023, Arxiv, DOI arXiv:2301.10297; Milkman KL, 2021, NATURE, V600, P478, DOI 10.1038/s41586-021-04128-4; Monarch R.M., 2021, Human-in-the-Loop Machine Learning: Active learning and annotation for human-centered AI; Nook EC, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2114737119; Novikova Jekaterina, 2017, P 2017 C EMPIRICAL M, P2241, DOI DOI 10.18653/V1/D17-1238; OpenAI, 2023, GPT-4 Technical Report; Ophir Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73917-0; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Park JS, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545616; Paullada A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100336; Pennebaker JW, 2003, ANNU REV PSYCHOL, V54, P547, DOI 10.1146/annurev.psych.54.101601.145041; Pennycook G, 2021, NATURE, V592, P590, DOI 10.1038/s41586-021-03344-2; PETTY RE, 1984, ADV CONSUM RES, V11, P668; Plaza-del-Arco F. M., 2022, P 29 INT C COMPUTATI, P6805; Portelance E., 2020, P ANN M COGN SCI SOC; Pryzant R, 2020, AAAI CONF ARTIF INTE, V34, P480; Rathje S., 2023, PREPRINT; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Sap M., 2022, P 2022 C EMPIRICAL M, P3762, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.248; Sap M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2211715119; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Schuetz Alfred., 1942, Philosophy and Phenomenological Research, V2, P323; Seraj S, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2017154118; Shah Raj Sanjay, 2022, Proceedings of the ACM on Human-Computer Interaction, DOI 10.1145/3555640; Siddaway AP, 2019, ANNU REV PSYCHOL, V70, P747, DOI 10.1146/annurev-psych-010418-102803; Simonsohn U, 2014, J EXP PSYCHOL GEN, V143, P534, DOI 10.1037/a0033242; Stade E., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/CUZVR; Stone P. J., 1966, The General Inquirer: A Computer Approach to Content Analysis, V651; Tesfagergish SG, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12178662; Tipton E, 2019, RES SYNTH METHODS, V10, P180, DOI 10.1002/jrsm.1339; Trott S, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13309; Voigt R, 2017, P NATL ACAD SCI USA, V114, P6521, DOI 10.1073/pnas.1702413114; Wallace J., 1977, Midw. Stud. Phil, V2, P144, DOI [10.1111/j.1475-4975.1977.tb00036.x, DOI 10.1111/J.1475-4975.1977.TB00036.X]; Walton GM, 2023, SCIENCE, V380, P499, DOI 10.1126/science.ade4420; Walton GM, 2018, PSYCHOL REV, V125, P617, DOI 10.1037/rev0000115; Walton GM, 2015, ANNU REV ORGAN PSYCH, V2, P523, DOI 10.1146/annurev-orgpsych-032414-111322; Walton GM, 2011, SCIENCE, V331, P1447, DOI 10.1126/science.1198364; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang PF, 2022, Arxiv, DOI [arXiv:2211.01562, 10.48550/arXiv.2211.01562]; Wang T, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581372; Weiss M., 2011, Serving community college students on probation: Four-year findings from Chaffey College's opening doors program; Westerveld MF, 2017, LANG SPEECH HEAR SER, V48, P260, DOI 10.1044/2017_LSHSS-17-0003; Wittgenstein L., 1994, TRACTATUS LOGICO PHI; Yeager DS, 2022, NATURE, V607, P512, DOI 10.1038/s41586-022-04907-7; Yeager DS, 2019, NATURE, V573, P364, DOI 10.1038/s41586-019-1466-y; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zhang S., 2023, P ANN M COGN SCI SOC, V45	118	18	18	67	67	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2731-0574		NAT REV PSYCHOL	Nat. Rev. Psychol.	NOV	2023	2	11					688	701		10.1038/s44159-023-00241-5	http://dx.doi.org/10.1038/s44159-023-00241-5			14	Psychology, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Psychology	CJ1N6					2024-07-03	WOS:001124794900011
J	Chen, YP; Zhang, S; Han, T; Du, YM; Zhang, WM; Li, JAT				Chen, Yiping; Zhang, Shuai; Han, Ting; Du, Yumeng; Zhang, Wuming; Li, Jonathan			Chat3D: Interactive understanding 3D scene-level point clouds by chatting with foundation model for urban ecological construction	ISPRS JOURNAL OF PHOTOGRAMMETRY AND REMOTE SENSING			English	Article						Point cloud understanding; Large language model interact; Urban ecological construction; Prompt engineering; Thought chain	QUALITY	With the artificial intelligence technology development boom, large language models are demonstrating their potential in comprehension and creativity. Large language models such as GPT-4 and Gemini have been able to powerfully study for various professional -level exams. However, as a language model itself, its powerful comprehension can only be reflected in text sequences. Currently, although videos can be generated through the connection between 3D point clouds and large language models, there is currently no prompt project that directly interacts with one-dimensional through attribute calculation results. The point cloud data is also rich in information that can support various tasks of urban construction. For scene -level point cloud data, there has been a lot of research done on semantic segmentation, target detection, and other tasks. However, it is usually difficult to provide direct help to scene construction from the perception results. This paper presents a method for applying large language models to urban ecological construction by combining the results of 3D point cloud semantic segmentation. The objective is to integrate the prior knowledge and creative capabilities of Large Language Models (LLMs) within urban development with the outcomes derived from point cloud semantic segmentation results. This integration aims to establish an interactive point cloud intelligent analysis system, tailored for aiding decision -making processes in urban ecological civilization construction, thus presenting innovative perspectives for the advancement of smart city development.	[Chen, Yiping; Zhang, Shuai; Han, Ting; Du, Yumeng; Zhang, Wuming] Sun Yat sen Univ, Sch Geospatial Engn & Sci, Zhuhai 519082, Guangdong, Peoples R China; [Li, Jonathan] Univ Waterloo, Dept Geog & Environm Management, Waterloo, ON N2L 3G1, Canada	Sun Yat Sen University; University of Waterloo	Zhang, S (corresponding author), Sun Yat sen Univ, Sch Geospatial Engn & Sci, Zhuhai 519082, Guangdong, Peoples R China.	zhangsh255@mail2.sysu.edu.cn	Han, Ting/HJA-5375-2022	Han, Ting/0009-0002-9474-8337; , Yiping/0000-0003-1465-6599; Zhang, Shuai/0009-0000-8608-0125	National Natural Science Founda-tion of China [42371343]	National Natural Science Founda-tion of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgments</B> The study was supported by the National Natural Science Founda-tion of China (No. 42371343) .	Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen DZ, 2021, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR46437.2021.00321; Chen G, 2023, arXiv; Chen M, 2020, PR MACH LEARN RES, V119; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Das M, 2023, GEOSCI FRONT, V14, DOI 10.1016/j.gsf.2022.101489; De Keersmaecker W, 2014, GLOBAL CHANGE BIOL, V20, P2149, DOI 10.1111/gcb.12495; Devlin J., 2018, BERT PRE TRAINING DE; Fijaoko N, 2023, RESUSCITATION, V185, DOI 10.1016/j.resuscitation.2023.109732; Fu R, 2024, Arxiv, DOI arXiv:2403.11401; Hong Y., 2024, Adv. Neural Inf. Process. Syst., V36; Hu XS, 2018, ECOL INDIC, V89, P11, DOI 10.1016/j.ecolind.2018.02.006; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942; Larsson M, 2016, EVALUATION-US, V22, P190, DOI 10.1177/1356389016638751; Li JN, 2022, PR MACH LEARN RES; Li YR, 2017, J CLEAN PROD, V142, P697, DOI 10.1016/j.jclepro.2016.09.011; Li Z., 2024, arXiv; Liu DN, 2024, Arxiv, DOI arXiv:2402.03327; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu ZJ, 2019, ADV NEUR IN, V32; Luo T., 2024, Adv. Neural Inf. Process. Syst., V36; Mishra S., 2021, arXiv preprint arXiv:2104.08773, P839; OpenAI, 2023, Chatgpt: Optimizing language models for dialogue; OpenAI, 2023, GPT 4 TECHNICAL REPO; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pi RJ, 2023, Arxiv, DOI arXiv:2305.14167; Popp JH, 2000, ECOL MODEL, V130, P131, DOI 10.1016/S0304-3800(00)00201-5; Prieto SA, 2023, BUILDINGS-BASEL, V13, DOI 10.3390/buildings13040857; Qi CR, 2017, ADV NEUR IN, V30; Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Sengupta A, 2023, IEEE T NEUR NET LEAR, V34, P8418, DOI 10.1109/TNNLS.2022.3151101; Shan W, 2019, J CLEAN PROD, V239, DOI 10.1016/j.jclepro.2019.118126; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Sinha RK, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35237; Su YX, 2023, Arxiv, DOI arXiv:2305.16355; [孙东琪 Sun Dongqi], 2012, [地理学报, Acta Geographica Sinica], V67, P1599; Sun QH, 2023, Arxiv, DOI arXiv:2306.10730; Tafferner Z, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23104879; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Venigalla A., 2022, PubMed GPT: A domain-specific large language model for biomedical text; Victor S., 2022, INT C LEARNING REPRE; Wang Jun Wang Jun, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P308; Wang S., 2023, arXiv; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Xie JH, 2023, Arxiv, DOI arXiv:2305.13777; Xu D, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14010198; Xu D, 2021, J CLEAN PROD, V321, DOI 10.1016/j.jclepro.2021.128948; Xu Han-qiu, 2013, China Environmental Science, V33, P889; Xu RS, 2023, Arxiv, DOI arXiv:2308.16911; Yang SQ, 2023, Arxiv, DOI arXiv:2312.14074; Yu JB, 2024, GEO-SPAT INF SCI, V27, P289, DOI 10.1080/10095020.2022.2072775; Zeng YH, 2023, PROC CVPR IEEE, P15244, DOI 10.1109/CVPR52729.2023.01463; Zhang MM, 2022, LAND-BASEL, V11, DOI 10.3390/land11081303; Zhang RR, 2022, PROC CVPR IEEE, P8542, DOI 10.1109/CVPR52688.2022.00836; Zhang S., 2023, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci., V48, P571; Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595; Zhou JS, 2023, Arxiv, DOI arXiv:2310.06773; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	70	0	0	7	7	ELSEVIER	AMSTERDAM	RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS	0924-2716	1872-8235		ISPRS J PHOTOGRAMM	ISPRS-J. Photogramm. Remote Sens.	JUN	2024	212						181	192		10.1016/j.isprsjprs.2024.04.024	http://dx.doi.org/10.1016/j.isprsjprs.2024.04.024			12	Geography, Physical; Geosciences, Multidisciplinary; Remote Sensing; Imaging Science & Photographic Technology	Science Citation Index Expanded (SCI-EXPANDED)	Physical Geography; Geology; Remote Sensing; Imaging Science & Photographic Technology	TF7C3					2024-07-03	WOS:001239903400001
J	Khaokaew, Y; Xue, H; Salim, FD				Khaokaew, Yonchanok; Xue, Hao; Salim, Flora D.			MAPLE: Mobile App Prediction Leveraging Large Language Model Embeddings	PROCEEDINGS OF THE ACM ON INTERACTIVE MOBILE WEARABLE AND UBIQUITOUS TECHNOLOGIES-IMWUT			English	Article						Mobile user behaviour modelling; App usage prediction; Large language model	USAGE PREDICTION	In recent years, predicting mobile app usage has become increasingly important for areas like app recommendation, user behaviour analysis, and mobile resource management. Existing models, however, struggle with the heterogeneous nature of contextual data and the user cold start problem. This study introduces a novel prediction model, Mobile App Prediction Leveraging Large Language Model Embeddings (MAPLE), which employs Large Language Models (LLMs) and installed app similarity to overcome these challenges. MAPLE utilises the power of LLMs to process contextual data and discern intricate relationships within it effectively. Additionally, we explore the use of installed app similarity to address the cold start problem, facilitating the modelling of user preferences and habits, even for new users with limited historical data. In essence, our research presents MAPLE as a novel, potent, and practical approach to app usage prediction, making significant strides in resolving issues faced by existing models. MAPLE stands out as a comprehensive and effective solution, setting a new benchmark for more precise and personalised app usage predictions. In tests on two real-world datasets, MAPLE surpasses contemporary models in both standard and cold start scenarios. These outcomes validate MAPLE's capacity for precise app usage predictions and its resilience against the cold start problem. This enhanced performance stems from the model's proficiency in capturing complex temporal patterns and leveraging contextual information. As a result, MAPLE can potentially improve personalised mobile app usage predictions and user experiences markedly.	[Khaokaew, Yonchanok; Xue, Hao; Salim, Flora D.] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia	University of New South Wales Sydney	Khaokaew, Y (corresponding author), Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.	y.khaokaew@unsw.edu.au; hao.xue1@unsw.edu.au; flora.salim@unsw.edu.au			Royal Thai Government; UNSW RTP scholarship; ARC Centre of Excellence for Automated Decision-Making and Society [CE200100005]; Australian Government	Royal Thai Government; UNSW RTP scholarship; ARC Centre of Excellence for Automated Decision-Making and Society(Australian Research Council); Australian Government(Australian Government)	This research is supported by the Royal Thai Government, the UNSW RTP scholarship, and the ARC Centre of Excellence for Automated Decision-Making and Society (CE200100005). Additionally, this research was undertaken with the assistance of resources and services from the National Computational Infrastructure (NCI), which is supported by the Australian Government.	Aliannejadi M, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3447678; Aliannejadi M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1383, DOI 10.1145/3269206.3271679; Baeza-Yates R, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P285, DOI 10.1145/2684822.2685302; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; China TeleCom, 2018, China TeleCom Webpage; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; González-Carvajal S, 2021, Arxiv, DOI arXiv:2005.13012; Huandong Wang, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314414; Huang K, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1059; Kang YF, 2022, PERVASIVE MOB COMPUT, V87, DOI 10.1016/j.pmcj.2022.101704; Khaokaew Y, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3137, DOI 10.1145/3459637.3482076; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Kitaev N, 2020, REFORMER EFFICIENT T; Laurila J. K., 2012, The mobile data challenge: Big data for mobile computing research, P1; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li YP, 2023, PROC ACM INTERACT MO, V7, DOI 10.1145/3580795; Liao ZX, 2013, IEEE DATA MINING, P1127, DOI 10.1109/ICDM.2013.130; Liu HD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ENERGY, P63; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu JS, 2019, ADV NEUR IN, V32; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Natarajan N., 2013, Proceedings of the 7th ACM conference on Recommender systems, P201, DOI DOI 10.1145/2507157.2507186; Parate A, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P275, DOI 10.1145/2493432.2493490; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Shin C, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P173, DOI 10.1145/2370216.2370243; Suleiman B, 2021, LECT NOTES COMPUT SC, V13121, P811, DOI 10.1007/978-3-030-91431-8_58; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Tian Y, 2022, ACM T INFORM SYST, V40, DOI 10.1145/3464301; van der Maaten L, 2008, J MACH LEARN RES, V9, P2579; Vaswani A, 2017, ADV NEUR IN, V30; Wu H., 2023, 11 INT C LEARNING RE; Xia T, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3408325; Xinlei Chen, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314391; Xue H, 2022, 30TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS, ACM SIGSPATIAL GIS 2022, P640, DOI 10.1145/3557915.3561026; Xue H, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1224, DOI 10.1145/3488560.3498387; Yali Fan, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3369829; Yu Y, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411817; Zeng A, 2023, P AAAI C ART INT WAS, V37, P11121, DOI DOI 10.1609/AAAI.V37I9.26317; Zhao S, 2019, PROC INT CONF DATA, P1322, DOI 10.1109/ICDE.2019.00120; Zhou T, 2022, PR MACH LEARN RES; Zhou YF, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12030058	44	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA		2474-9567		PROC ACM INTERACT MO	Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.	MAR	2024	8	1							10	10.1145/3643514	http://dx.doi.org/10.1145/3643514			25	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Telecommunications	OM1I2		Green Submitted			2024-07-03	WOS:001207594200010
J	Logan, S				Logan, Sarah			Tell me what you don't know: large language models and the pathologies of intelligence analysis	AUSTRALIAN JOURNAL OF INTERNATIONAL AFFAIRS			English	Editorial Material						Artificial intelligence (AI); intelligence analysis; large language models		This article serves as a warning. Prompted by the likely increase in the reliance on artificial intelligence (AI) in intelligence analysis, it raises grave concerns about the prospect of relying on large language models (LLMs), including in high-stakes contexts such as the state-level resort-to-force decision making that is the focus of this special issue. It begins by identifying the twin informational pathologies that intelligence analysis is subject to by its very nature: information scarcity and epistemic scarcity. It goes on to argue that the use of LLMs would compound these pathologies, attributing this risk to the nature of the international information landscape, especially the rise of private actors in data markets and the changed intelligence environment in the years following September 11. The article concludes by making recommendations for possible responses to the informational risks engendered by the use of LLMs in intelligence analysis, especially in high-stakes contexts.	[Logan, Sarah] Australian Natl Univ, Dept Int Relat, Canberra, Australia	Australian National University	Logan, S (corresponding author), Australian Natl Univ, Dept Int Relat, Canberra, Australia.	sarah.logan@anu.edu.au						Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BETTS RK, 1978, WORLD POLIT, V31, P61, DOI 10.2307/2009967; Bird J., 2011, Penetrating the Iron Curtain: Resolving the Missile Gap with Technology; Blanchard Alexander, 2023, Digit Soc, V2, P12, DOI 10.1007/s44206-023-00036-4; Conklin B., 2023, Signal; Daskal Jennifer, 2018, Stanford Law Review Online, V71, P9; Deeks A., 2019, Journal of National Security Law Policy, V10, P1; Dickson B., 2023, TechTalks; DoJ (Department of Justice), 2004, Report to the National Commission on Terrorist Attacks Upon the United States; Erskine Toni., 2024, Anticipating the Future of War: AI, Automated Systems, and Resort-to-Force Decision Making, Special Issue of Australian Journal of International Affairs, V78; Freedberg S., 2023, Breaking Defense; Heaven D., 2023, MIT Technology Review; Huang J., 2022, arXiv; Johnson Loch K., 2006, The Handbook of Intelligence Studies, P1120; Kempe M, 2013, HIST Z, V296, P354, DOI 10.1524/hzhz.2013.0101; Logan S., 2015, Interview Report: Surveillance of Social Media for Law Enforcement Purposes; Logan S, 2017, BIG DATA SOC, V4, DOI 10.1177/2053951717734574; McCulloch G., 2019, WIRED; Noack R., 2021, Washington Post; ODNI (Office of the Director of National Intelligence), 2022, Senior Advisory Group Panel on Commercially Available Information: Report to the Director of National Intelligence; OECD, 2021, OECD Web Archive; Richard Carter, 2023, CETaS Expert Analysis; Roff G. M., 2020, Brookings (Blog); Ronn KV, 2013, INTELL NATL SECUR, V28, P694, DOI 10.1080/02684527.2012.701438; Shane S., 2018, The New York Times; Sherman J., 2022, Lawfare; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Villalobos P, 2024, Arxiv, DOI arXiv:2211.04325; Vincent B., 2019, Nextgov; Vogel KM, 2021, INTELL NATL SECUR, V36, P827, DOI 10.1080/02684527.2021.1946952; Web Technology Surveys, 2023, Usage Statistics and Market Share of Content Languages for Websites; Zhang RC, 2023, Arxiv, DOI [arXiv:2305.14235, 10.48550/arXiv.2305.14235, DOI 10.48550/ARXIV.2305.14235]	33	0	0	0	0	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1035-7718	1465-332X		AUST J INT AFF	Aust. J. Int. Aff.	MAR 3	2024	78	2			SI		220	228		10.1080/10357718.2024.2331733	http://dx.doi.org/10.1080/10357718.2024.2331733			9	International Relations	Social Science Citation Index (SSCI)	International Relations	SS6S4		hybrid			2024-07-03	WOS:001236483000002
J	Browning, J				Browning, Jacob			"Personhood and AI: Why large language models don't understand us"	AI & SOCIETY			English	Article; Early Access						Artificial intelligence; Large language models; Personhood; Normativity		Recent artificial intelligence advances, especially those of large language models (LLMs), have increasingly shown glimpses of human-like intelligence. This has led to bold claims that these systems are no longer a mere "it" but now a "who," a kind of person deserving respect. In this paper, I argue that this view depends on a Cartesian account of personhood, on which identifying someone as a person is based on their cognitive sophistication and ability to address common-sense reasoning problems. I contrast this with a different account of personhood, one where an agent is a person if they are autonomous, responsive to norms, and culpable for their actions. On this latter account, I show that LLMs are not person-like, as evidenced by their propensity for dishonesty, inconsistency, and offensiveness. Moreover, I argue current LLMs, given the way they are designed and trained, cannot be persons-either social or Cartesian. The upshot is that contemporary LLMs are not, and never will be, persons.	[Browning, Jacob] NYU, Comp Sci Dept, New York, NY 10012 USA	New York University	Browning, J (corresponding author), NYU, Comp Sci Dept, New York, NY 10012 USA.	browning.jake@gmail.com						Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; [Anonymous], 2015, Stanford Technology Law Review, V19, P93; Aru J, 2023, ARTIF INTELL REV, V56, P9141, DOI 10.1007/s10462-023-10401-x; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Boden M., 2016, AI ITS NATURE FUTURE; Boden M, 2018, Robot says: whatever; Brandom, 1994, MAKING IT EXPLICIT R; Carruthers Peter., 2006, ARCHITECTURE MIND; Chowdhery A., 2022, arXiv; FEINBERG J, 1965, MONIST, V49, P397, DOI 10.5840/monist196549326; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Grice Paul., 1975, SYNTACS SEMANTICS; HAUGELAND J, 1982, NOUS, V16, P15, DOI 10.2307/2215406; HAUGELAND J, 1979, J PHILOS, V76, P619, DOI 10.2307/2025695; Hegel G. W. F., 1807, PHENOMENOLOGY SPIRIT; Hovy Dirk., 2021, 2021 C N AM CHAPTER, DOI 10.18653/v1/2021.naacl-main.49; Hu J, 2023, Arxiv, DOI [arXiv:2212.06801, DOI 10.48550/ARXIV.2212.06801]; Kambhampati S, 2023, LARGE LANGUAGE MODEL, P1; Kant Immanuel., 1991, The Cambridge Edition of the Works of Immanuel Kant; Kassner Nora, 2020, P 58 ANN M ASS COMPU, P7811, DOI [10.18653/v1/2020.acl-main.698, DOI 10.18653/V1/2020.ACL-MAIN.698]; Kempt H, 2023, APPROPRIATENESS ALL, P1; Kocon J., 2023, CHATGPT JACK ALL TRA, DOI [10.2139/ssrn.4372889, DOI 10.2139/SSRN.4372889]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; Mahowald K., 2023, arXiv; Marcus G., 2020, Technology Review; McCarthy John, 1959, SEMANTIC INFORM PROC; Milliere R, 2022, WELCOME NEXT LEVEL B; Mindt G., 2020, Mind and Matter, V18, P9; Mitchell M., 2019, ARTIFICIAL INTELLIGE; Montemayor C, 2023, PROSPECT HUMANITARIA; Montemayor C, 2021, MIND MACH, V31, P471, DOI 10.1007/s11023-021-09568-5; Piantasodi S, 2022, Arxiv, DOI [arXiv:2208.02957, 10.48550/arXiv.2208.02957, DOI 10.48550/ARXIV.2208.02957]; Russell S., 2019, Human compatible. ai and the problem of control; Sap M, 2023, Arxiv, DOI arXiv:2210.13312; Scott-Phillips T., 2014, SPEAKING OUR MINDS; Solaiman I., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.10328; Taylor C., 1992, MULTICULTURALISM EXA, P25; Trott S, 2020, ASS COMPUTAT LINGUIS, DOI [10.18653/v1/2020.acl-main.462, DOI 10.18653/V1/2020.ACL-MAIN.462]; Wallach W., 2015, A Dangerous Master: How to Keep Technology from Slipping Beyond Our Control; Wallach W., 2010, Moral machines: Teaching Robots right from wrong	43	1	1	10	20	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2023 JUL 12	2023										10.1007/s00146-023-01724-y	http://dx.doi.org/10.1007/s00146-023-01724-y		JUL 2023	8	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	M2II7					2024-07-03	WOS:001028466200004
C	Xiang, Q; Lin, YL; Fang, MJ; Huang, B; Huang, SY; Wen, RD; Le, F; Kong, LH; Shu, JW			ACM	Xiang, Qiao; Lin, Yuling; Fang, Mingjun; Huang, Bang; Huang, Siyong; Wen, Ridi; Le, Franck; Kong, Linghe; Shu, Jiwu			Toward Reproducing Network Research Results Using Large Language Models	PROCEEDINGS OF THE 22ND ACM WORKSHOP ON HOT TOPICS IN NETWORKS, HOTNETS 2023			English	Proceedings Paper	22nd ACM Workshop on Hot Topics in Networks (HotNets)	NOV 28-29, 2023	Cambridge, MA	Assoc Comp Machinery, ACM SIGCOMM		Networking systems; Large language models		Reproducing research results is important for the networking community. The current best practice typically resorts to: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; or (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private ones are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). We first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report our observations and lessons and discuss future open research questions of this proposal.	[Xiang, Qiao; Lin, Yuling; Fang, Mingjun; Huang, Bang; Huang, Siyong; Wen, Ridi; Shu, Jiwu] Xiamen Univ, Xiamen, Peoples R China; [Le, Franck] IBM Res, Armonk, NY USA; [Kong, Linghe] Shanghai Jiao Tong Univ, Shanghai, Peoples R China; [Shu, Jiwu] Minjiang Univ, Fuzhou, Peoples R China	Xiamen University; International Business Machines (IBM); Shanghai Jiao Tong University; Minjiang University	Xiang, Q (corresponding author), Xiamen Univ, Xiamen, Peoples R China.		Lin, Yu-Ling/AFI-8341-2022	Lin, Yu-Ling/0000-0003-0176-3854; Shu, Jiwu/0000-0002-7362-2789; Lin, Yuling/0009-0007-2884-8504	National Key R&D Program of China [2022YFB2901502]; NSFC [62172345]; Open Research Projects of Zhejiang Lab [2022QA0AB05]; MOE China [2021FNA02008]; NSF-Fujian-China [2022J01004]	National Key R&D Program of China; NSFC(National Natural Science Foundation of China (NSFC)); Open Research Projects of Zhejiang Lab; MOE China(Ministry of Education, China); NSF-Fujian-China	We are extremely grateful for the anonymous HotNets reviewers for their wonderful feedback. We thank the authors of Arrow [45] for their help. Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, and Ridi Wen are supported in part by the National Key R&D Program of China 2022YFB2901502, NSFC Award 62172345, Open Research Projects of Zhejiang Lab 2022QA0AB05, MOE China 2021FNA02008, and NSF-Fujian-China 2022J01004. This work raises no ethical issue.	Abuzaid Firas, 2021, NSDI 2021; acm, 2023, CS2023: ACM/IEEE-CS/AAAI Computer Science Curricula; [Anonymous], 2023, Conversation Log of ChatGPT in the Experiment; Beurer-Kellner Luca, 2022, arXiv; Bibel W., 2013, Automated theorem proving; ChatPDF, 2023, about us; Chen Huangxun, 2022, SIGCOMM; Clear Alison, 2017, SIGCSE 2017; gitee, 2021, Open-source Prototype of Atomic Predicates Verifier; github, 2022, Open-source Prototype of Flash; github, 2022, Microsoft Copilot; github, 2020, Open-source Prototype of NCFlow; github, 2021, Open-source Prototype of ARROW; Guo Dong, 2022, SIGCOMM 2022; Gurobi, 2018, About us; Huang Yangfan, 2023, IWQoS 2023; Jin X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P121, DOI 10.1145/3132747.3132764; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; lablab, 2022, GPT-3.5; Le Franck, 2022, HotNets 2022; Meng ZL, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P154, DOI 10.1145/3387514.3405859; Nijkamp E., 2022, ARXIV; Ongaro Diego, 2014, ATC 2014; openai, 2022, OpenAI ChatGPT; pypi, 2022, Pulp; Rahmani Kia, 2021, arXiv; Rival X., 2020, Introduction to static analysis: an abstract interpretation perspective; Shenker Scott, 2022, SIGCOMM 2022; sigcomm, 2016, SIGCOMM to use Deep Learning for Paper Selection,An Email from SIGCOMM Mailing List on April 1; sigcomm, 2023, ACM IMC 2023 Call For Papers: Replicability Track; Sivaraman A, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P44, DOI 10.1145/2934872.2934899; Tang Alan, 2021, SIGCOMM 2021; Vahidi A., 2020, A BDD and Z-BDD Library Written in Java; Verbruggen G, 2021, P ACM PROGRAM LANG, V5, DOI 10.1145/3485477; White J., 2023, arXiv; Xiang Q, 2023, Arxiv, DOI arXiv:2309.04716; Yan L, 2017, IEEE INFOCOM SER; Yang Hongkun, 2016, TON 2016; Yang Rulan, 2023, APNet 2023; Yen Jane, 2021, SIGCOMM 2021; Zhang Jiahang, 2022, ARXIV; Zhang Jialu, 2022, ASE 2022; Zhang P, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P241; Zhang Tony Nuda, 2023, PACM PL 2023; Zhong ZZ, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P560, DOI 10.1145/3452296.3472921; Zhou, 2022, ARXIV	46	1	1	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0415-4				2023							56	62		10.1145/3626111.3628189	http://dx.doi.org/10.1145/3626111.3628189			7	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TD		Green Submitted			2024-07-03	WOS:001124843800008
J	Zhou, XH; Sun, ZY; Li, GL				Zhou, Xuanhe; Sun, Zhaoyan; Li, Guoliang			DB-GPT: Large Language Model Meets Database	DATA SCIENCE AND ENGINEERING			English	Article						Large language model; Database		Large language models (LLMs) have shown superior performance in various areas. And LLMs have the potential to revolutionize data management by serving as the "brain" of next-generation database systems. However, there are several challenges that utilize LLMs to optimize databases. First, it is challenging to provide appropriate prompts (e.g., instructions and demonstration examples) to enable LLMs to understand the database optimization problems. Second, LLMs only capture the logical database characters (e.g., SQL semantics) but are not aware of physical characters (e.g., data distributions), and it requires to fine-tune LLMs to capture both physical and logical information. Third, LLMs are not well trained for databases with strict constraints (e.g., query plan equivalence) and privacy-preserving requirements, and it is challenging to train database-specific LLMs while ensuring database privacy. To overcome these challenges, this vision paper proposes a LLM-based database framework (DB-GPT), including automatic prompt generation, DB-specific model fine-tuning, and DB-specific model design and pre-training. Preliminary experiments show that DB-GPT achieves relatively good performance in database tasks like query rewrite and index tuning. The source code and datasets are available at github.com/TsinghuaDatabaseGroup/DB-GPT.	[Zhou, Xuanhe; Sun, Zhaoyan; Li, Guoliang] Tsinghua Univ, Dept Comp Sci, Beijing, Peoples R China	Tsinghua University	Li, GL (corresponding author), Tsinghua Univ, Dept Comp Sci, Beijing, Peoples R China.	zhouxuan19@mails.tsinghua.edu.cn; szy22@mails.tsinghua.edu.cn; liguoliang@tsinghua.edu.cn	chen, xian/KHW-2227-2024; Huang, Yong/KFA-1191-2024; Yan, Lu/KHW-7015-2024; liu, yang/KFA-8402-2024; Zhang, Youyou/KCY-0810-2024; Sun, Yang/KHY-5117-2024; wang, yue/KDO-9209-2024; Li, Yang/KFB-5350-2024; li, xiaomin/KCX-9845-2024; Li, Guoliang/E-3481-2012; lu, Li/KBA-2603-2024; Chen, Bowen/KFB-3986-2024; li, lin/KEJ-1056-2024; zhang, lu/KGL-6144-2024; LI, yue/KHC-6771-2024; Li, Yan/KFQ-9244-2024; li, yan/KFQ-3850-2024; Liu, Zhiyuan/KDP-2606-2024; Lu, Yi/KEJ-2560-2024; Liu, Yan/KFQ-1417-2024; Cheng, Lin/KFQ-3111-2024; li, yf/KHX-1148-2024		NSFC [2023YFB4503600]; National Key R\&D Program of China [61925205, 62232009, 62102215]; NSF of China; Zhongguancun Lab; Beijing National Research Center for Information Science and Technology (BNRist)	NSFC(National Natural Science Foundation of China (NSFC)); National Key R\&D Program of China; NSF of China(National Natural Science Foundation of China (NSFC)); Zhongguancun Lab; Beijing National Research Center for Information Science and Technology (BNRist)	This paper was supported by National Key R\&D Program of China (2023YFB4503600), NSF of China (61925205, 62232009, 62102215), Zhongguancun Lab, Huawei, TAL education, and Beijing National Research Center for Information Science and Technology (BNRist).	Bin W., 2019, METHODS EXPT RESULTS; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhery A., 2022, PaLM: Scaling Language Modeling with Pathways; Creswell A, 2022, FAITHFUL REASONING U, P1; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding N., 2022, arXiv; Ding S, 2021, ERNIE 3 0 LARGE SCAL; Dong Q., 2022, arXiv; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fu Y, 2022, CHIN J MECH ENG-EN, V35, DOI 10.1186/s10033-022-00760-x; Gou JP, 2021, INT J COMPUT VISION, V129, P1789, DOI 10.1007/s11263-021-01453-z; Graham, 2023, PRETRAIN PROMPT PRED, V55, P1; Han J., 2022, ARXIV; Houlsby N, 2019, PR MACH LEARN RES, V97; Hu EJ, 2021, LORA LOW RANK ADAPTA, V10, P1; Jing K, 2019, ARXIV; Kim HJ, 2022, SELF GENERATED IN CO; Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909; Kuo C. Jay, EVALUATING WORD EMBE; Levy I, 2022, DIVERSE DEMONSTRATIO; Li GL, 2021, INT CONF MANAGE DATA, P2859, DOI 10.1145/3448016.3457542; Li JY, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3649449; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu JC, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3154; Liu RQ, 2022, MED TEACH, V44, P758, DOI 10.1080/0142159X.2022.2028751; Liu X, 2021, AI OPEN; Lu Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8086; Ma Z, 2022, GLM 130B OPEN BILING, V06; Magister L C, 2022, ARXIV; Mitzenmacher M, 2018, ARXIV; openfoam, ABOUT US; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Press O, 2022, MEASURING NARROWING, P1; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Rubin O, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2655; Shaham SR B, 2022, INSTRUCTION INDUCTIO, P1; Shao Z, 2023, SYNTHETIC PROMPTING; Shin T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P4222; Sorensen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P819; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Trummer I, 2022, PROC VLDB ENDOW, V15, P2921, DOI 10.14778/3551793.3551841; Trummer I, 2022, INT CONF MANAGE DATA, P190, DOI 10.1145/3514221.3517843; Wang X, 2023, ARXIV; Wiegreffe S, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P632; Wu C, 2019, DEEP UNSUPERVISED CA, V13; Wu YJ, 2023, MAR GEORESOUR GEOTEC, V41, P24, DOI 10.1080/1064119X.2021.2009070; Wu Z, ARXIV; Xuanhe Zhou, 2022, IEEE Transactions on Knowledge and Data Engineering, V34, P1096, DOI 10.1109/TKDE.2020.2994641; Yang ZH, 2020, PROC VLDB ENDOW, V14, P61, DOI 10.14778/3421424.3421432; Yin XF, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3460427; Zhang S., 2022, ARXIV; Zhang XY, 2021, INT CONF MANAGE DATA, P2102, DOI 10.1145/3448016.3457291; Zhang Y, 2022, ACTIVE EXAMPLE SELEC; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhao TZ, 2021, PR MACH LEARN RES, V139; Zhou D, 2022, LEAST TO MOST PROMPT; Zhou J, 2020, OPEN, V1, P57, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]; Zhou XH, 2020, PROC VLDB ENDOW, V13, P1416, DOI 10.14778/3397230.3397238; Zhou Y, 2022, 11 INT C LEARN REPR	61	0	0	29	29	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2364-1185	2364-1541		DATA SCI ENG	Data Sci. Eng.	MAR	2024	9	1			SI		102	111		10.1007/s41019-023-00235-6	http://dx.doi.org/10.1007/s41019-023-00235-6		JAN 2024	10	Computer Science, Information Systems; Computer Science, Theory & Methods	Emerging Sources Citation Index (ESCI)	Computer Science	MR8N1		gold			2024-07-03	WOS:001145200900001
C	Chandra, J; Witzig, N; Laubrock, J			ACM	Chandra, Johan; Witzig, Nicholas; Laubrock, Jochen			Synthetic predictabilities from large language models explain reading eye movements	ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS, ETRA 2023			English	Proceedings Paper	15th Annual ACM Symposium on Eye Tracking Research and Applications (ETRA)	MAY 30-JUN 02, 2023	Tubingen, GERMANY	Assoc Comp Machinery, ACM SIGGRAPH, ACM SIGCHI, Tobii, Real Labs Res, Pupil Labs, Eye Square, Viewpointsystem, RealEye, iMotions, EyeLogic, BiSigma, GazePoint, VPixx Technologies, Adobe, SR Res EyeLink, SeeTrue, Univ Tubingen		Eye tracking; cognition; word predictability; large language models; transformers	FREQUENCY; WORDS	A long tradition in eye movement research has focused on three linguistic variables explaining fixation durations during sentence reading: word length, frequency, and predictability. Lengths and frequencies are easily obtainable but predictabilities are tedious to collect, requiring the incremental cloze procedure. Modern large language models are trained using the objective of predicting the next word given previous context, hence they readily provide predictability information. This capability has largely been overlooked in eye movement research. Here we investigate the suitability of a synthetic predictability measure, extracted from pretrained GPT-2 models, as a surrogate for cloze predictability. Using several published eye movement corpora, we find that synthetic and cloze predictabilities are highly correlated, and that their influence on eye movements is qualitatively similar. Similar patterns are obtained when including synthetic predictabilities in data sets lacking cloze predictabilities. In conclusion, synthetic predictabilities can serve as a substitute for empirical cloze predictabilities.	[Chandra, Johan; Witzig, Nicholas] Brandenburg Med Sch, Neuruppin, Germany; [Laubrock, Jochen] Univ Potsdam, Potsdam, Germany	University of Potsdam	Chandra, J (corresponding author), Brandenburg Med Sch, Neuruppin, Germany.	johan.chandra@mhb-fontane.de; nicholas.witzig@mhb-fontane.de; jochen.laubrock@uni-potsdam.de	Laubrock, Jochen/B-8080-2008	Laubrock, Jochen/0000-0002-0798-8977; Chandra, Johan/0000-0001-6953-0737	Ministry of Science, Research and Culture of the State of Brandenburg [19630061/READ]	Ministry of Science, Research and Culture of the State of Brandenburg	This study was funded by the Ministry of Science, Research and Culture of the State of Brandenburg, Grant no: 19630061/READ.	[Anonymous], 1993, The CELEX lexical database on CD-ROM; Bianchi B, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61353-z; Boston MF, 2011, LANG COGNITIVE PROC, V26, P301, DOI 10.1080/01690965.2010.492228; Brysbaert M, 2011, EXP PSYCHOL, V58, P412, DOI 10.1027/1618-3169/a000123; Brysbaert M, 2009, BEHAV RES METHODS, V41, P977, DOI 10.3758/BRM.41.4.977; Buswell GuyThomas., 1920, EXPT STUDY EYE VOICE; Chandra J, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-60833-6; Chandra J, 2020, ATTEN PERCEPT PSYCHO, V82, P1230, DOI 10.3758/s13414-019-01814-4; Cohen Vanya, 2020, XRDS: Crossroads, The ACM Magazine for Students, V27, P26, DOI 10.1145/3416063; Eddine Samer Nour, 2020, GPT 2 FOR PSYCHOLING; Engbert R, 2005, PSYCHOL REV, V112, P777, DOI 10.1037/0033-295X.112.4.777; Fernández G, 2014, J CLIN EXP NEUROPSYC, V36, P302, DOI 10.1080/13803395.2014.892060; Heister J, 2012, CUR ISS PSYCHOL LANG, P102; Heister J, 2011, PSYCHOL RUNDSCH, V62, P10, DOI 10.1026/0033-3042/a000029; HENDERSON JM, 1990, J EXP PSYCHOL LEARN, V16, P417, DOI 10.1037/0278-7393.16.3.417; Hofmann MJ, 2022, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.730570; Hollenstein Nora, 2021, P 2021 C N AM CHAPTE, P106; Huey E., 1908, PSYCHOL PEDAGOGY REA; Kliegl R, 2006, J EXP PSYCHOL GEN, V135, P12, DOI 10.1037/0096-3445.135.1.12; Kliegl R, 2004, EUR J COGN PSYCHOL, V16, P262, DOI 10.1080/09541440340000213; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Kucera Henry, 1967, COMPUTATIONAL ANAL P, V143, P1065; Kuperman V, 2010, Q J EXP PSYCHOL, V63, P1838, DOI 10.1080/17470211003602412; Luke SG, 2018, BEHAV RES METHODS, V50, P826, DOI 10.3758/s13428-017-0908-4; Meixner JM, 2022, J EXP PSYCHOL GEN, V151, P1219, DOI 10.1037/xge0001140; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Murty NAR, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25409-6; Ong JKY, 2008, J EYE MOVEMENT RES, V2; Rabe MM, 2021, PSYCHOL REV, V128, P803, DOI 10.1037/rev0000268; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372; Reichle E. D., 2021, Computational models of reading: A handbook; Reichle ED, 1998, PSYCHOL REV, V105, P125, DOI 10.1037/0033-295X.105.1.125; Reissel Philipp, 2021, GC 4 CORPUS; Schilling HEH, 1998, MEM COGNITION, V26, P1270, DOI 10.3758/BF03201199; Schweter Stefan, 2021, GERMAN GPT 2 MODEL; Siegelman N, 2022, BEHAV RES METHODS, V54, P2843, DOI 10.3758/s13428-021-01772-6; Smith NJ, 2013, COGNITION, V128, P302, DOI 10.1016/j.cognition.2013.02.013; Tang J., 2022, bioRxiv, DOI [DOI 10.1101/2022.09.29.509744, 10.1101/2022.09.29.509744v1]; Taylor WL, 1953, JOURNALISM QUART, V30, P415, DOI 10.1177/107769905303000401; Umfurer Alfredo, 2021, 22 S ARGENTINO INTEL; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang Xuezhi, 2022, arXiv, DOI DOI 10.48550/ARXIV.2203; Yamins DLK, 2016, NAT NEUROSCI, V19, P356, DOI 10.1038/nn.4244	44	2	2	2	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0150-4				2023										10.1145/3588015.3588420	http://dx.doi.org/10.1145/3588015.3588420			7	Computer Science, Cybernetics; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4HV		hybrid			2024-07-03	WOS:001031497300019
C	Hardt, D		Boyd-Graber, J; Okazaki, N; Rogers, A		Hardt, Daniel			Ellipsis-Dependent Reasoning: a New Challenge for Large Language Models	61ST CONFERENCE OF THE THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 2			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				We propose a novel challenge for large language models: ellipsis-dependent reasoning. We define several structures of paired examples, where an ellipsis example is matched to its non-ellipsis counterpart, and a question is posed which requires resolution of the ellipsis. Test results show that the best models perform well on non-elliptical examples but struggle with all but the simplest ellipsis structures.	[Hardt, Daniel] Copenhagen Business Sch, Copenhagen, Denmark	Copenhagen Business School	Hardt, D (corresponding author), Copenhagen Business Sch, Copenhagen, Denmark.	dha.msc@cbs.dk						[Anonymous], OpenAI GPT-3 Models Overview; Aralikatte R, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P810; Bos J, 2011, LANG RESOUR EVAL, V45, P463, DOI 10.1007/s10579-011-9142-3; Dasigi P, 2019, Arxiv, DOI arXiv:1908.05803; Garnham A, 2010, WIRES COGN SCI, V1, P845, DOI 10.1002/wcs.69; Huang BR, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1281; Kamp H., 1981, Formal methods in the study of Language, V136, P277; Kenyon-Dean K., 2016, P 2016 C EMPIRICAL M, P1734; Khullar Payal, 2020, P 1 C ASIA PACIFIC C, P139; Kocijan V, 2023, Arxiv, DOI arXiv:2201.02387; Levesque H., 2012, 13 INT C PRINCIPLES; Lin YJ, 2019, Arxiv, DOI arXiv:1906.01698; Martin AE, 2008, J MEM LANG, V58, P879, DOI 10.1016/j.jml.2007.06.010; SAG IA, 1984, LINGUIST PHILOS, V7, P325, DOI 10.1007/BF00627709; Vanderlyn Lindsey, 2022, P 2 C ASIA PACIFIC C, P587; Zhang WN, 2019, AAAI CONF ARTIF INTE, P7468	16	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-71-5				2023							39	47						9	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SD					2024-07-03	WOS:001181088800004
C	Tang, YQ; Dai, XY; Zhao, C; Cheng, Q; Lv, YS			IEEE	Tang, Yiqing; Dai, Xingyuan; Zhao, Chen; Cheng, Qi; Lv, Yisheng			Large Language Model-Driven Urban Traffic Signal Control	2024 AUSTRALIAN & NEW ZEALAND CONTROL CONFERENCE, ANZCC	Australian and New Zealand Control Conference		English	Proceedings Paper	Australian and New Zealand Control Conference (ANZCC)	FEB 01-02, 2024	Gold Coast, AUSTRALIA				INTELLIGENT TRANSPORTATION SYSTEMS	In recent years, large language models (LLM) have received a lot of attention for their ability to understand, generate and process natural language. By fine-tuning the models on specific domains or using prompts, LLMs can generate summaries tailored to different contexts and requirements. We hope to utilize these advantages of LLM in urban traffic signal control and provide a new paradigm for traffic control. In this paper, we propose a large language model-driven urban traffic control method, which is designed based on artificial systems, computational experiments, parallel execution (ACP) method. There are three traffic control modes, autonomous mode, feedback mode, and human takeover mode. In autonomous mode, we adopt recommendations based on inventory strategy, which can to some extent reduce the acquisition time of traffic control strategies. With the continuous construction and improvement of the strategic library, the efficiency of the system will be further improved. The feedback mode is mainly aimed at traffic scenarios that are not in the library, generating new control strategies and introducing human feedback. The human takeover model ensures that human engineers have direct control over the actual transportation system. LLM drives the interaction between human engineers and computers in the process of traffic control. Assist human engineers in achieving traffic control and improving work efficiency.	[Tang, Yiqing; Dai, Xingyuan; Zhao, Chen; Lv, Yisheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Tang, Yiqing; Dai, Xingyuan; Zhao, Chen; Lv, Yisheng] Chinese Acad Sci, State Key Lab Management & Control Complex Syst, Inst Automat, Beijing 100190, Peoples R China; [Cheng, Qi] China Univ Min & Technol, Sch Mech & Elect Engn, Beijing, Peoples R China; [Cheng, Qi] Univ Min & Technol Beijing, Inner Mongolia Res Inst, Ordos 017000, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS; China University of Mining & Technology; China University of Mining & Technology	Lv, YS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.	tangyiqing2022@ia.ac.cn; xingyuan.dai@ia.ac.cn; zhaochen2020@ia.ac.cn; SQT2200402038@student.cumtb.edu.cn; yisheng.lv@ia.ac.cn	Lv, Yisheng/C-6146-2013		National Key Research and Development Program of China [2022YFB4703703]; National Natural Science Foundation of China [62271485]	National Key Research and Development Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported in part by the National Key Research and Development Program of China, project 3 under Grant 2022YFB4703703, and in part by the National Natural Science Foundation of China under Grant 62271485.	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cao DP, 2022, IEEE T INTELL VEHICL, V7, P7, DOI 10.1109/TIV.2022.3157049; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du HP, 2023, IEEE T INTELL VEHICL, V8, P2020, DOI 10.1109/TIV.2023.3253281; Gao YB, 2023, IEEE T INTELL VEHICL, V8, P2034, DOI 10.1109/TIV.2023.3252571; Lv Y., 2023, IEEE Intell. Transp. Syst.Mag., V15, P3; Lv YS, 2023, IEEE INTEL TRANSP SY, V15, P2, DOI 10.1109/MITS.2023.3295392; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mao F, 2023, IEEE INTEL TRANSP SY, V15, P160, DOI 10.1109/MITS.2022.3144797; Mehr G, 2023, IEEE INTEL TRANSP SY, V15, P41, DOI 10.1109/MITS.2022.3168801; OpenAI, 2023, GPT-4 Technical Report; Schwarz C, 2022, IEEE INTEL TRANSP SY, V14, P41, DOI 10.1109/MITS.2021.3129524; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sun Y, 2023, IEEE T INTELL VEHICL, V8, P1017, DOI 10.1109/TIV.2023.3246045; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P3763, DOI 10.1109/TIV.2023.3298655; Wang FY, 2010, IEEE T INTELL TRANSP, V11, P630, DOI 10.1109/TITS.2010.2060218; Wang ZG, 2023, IEEE T NEUR NET LEAR, V34, P3811, DOI 10.1109/TNNLS.2021.3128968; Xiang C, 2023, IEEE INTEL TRANSP SY, V15, P36, DOI 10.1109/MITS.2023.3283864; Zhao C, 2022, IEEE INTEL TRANSP SY, V14, P6, DOI 10.1109/MITS.2022.3199557	21	0	0	33	33	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2767-7230	2767-7257	979-8-3503-1497-7	AUST N Z C CONF			2024							67	71		10.1109/ANZCC59813.2024.10432823	http://dx.doi.org/10.1109/ANZCC59813.2024.10432823			5	Automation & Control Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems	BW6GM					2024-07-03	WOS:001173666600012
J	Zhang, Q; Hu, YX; Yan, JX; Zhang, HY; Xie, XY; Zhu, J; Li, HC; Niu, XX; Li, LQ; Sun, YJ; Hu, WP				Zhang, Qian; Hu, Yongxu; Yan, Jiaxin; Zhang, Hengyue; Xie, Xinyi; Zhu, Jie; Li, Huchao; Niu, Xinxin; Li, Liqiang; Sun, Yajing; Hu, Wenping			Large-Language-Model-Based AI Agent for Organic Semiconductor Device Research	ADVANCED MATERIALS			English	Article; Early Access						accelerated design; large language models; machine learning; organic field-effect transistors	THIN-FILM TRANSISTORS; FIELD-EFFECT TRANSISTORS; PERFORMANCE; PREDICTION	Large language models (LLMs) have attracted widespread attention recently, however, their application in specialized scientific fields still requires deep adaptation. Here, an artificial intelligence (AI) agent for organic field-effect transistors (OFETs) is designed by integrating the generative pre-trained transformer 4 (GPT-4) model with well-trained machine learning (ML) algorithms. It can efficiently extract the experimental parameters of OFETs from scientific literature and reshape them into a structured database, achieving precision and recall rates both exceeding 92%. Combined with well-trained ML models, this AI agent can further provide targeted guidance and suggestions for device design. With prompt engineering and human-in-loop strategies, the agent extracts sufficient information of 709 OFETs from 277 research articles across different publishers and gathers them into a standardized database containing more than 10 000 device parameters. Using this database, a ML model based on Extreme Gradient Boosting is trained for device performance judgment. Combined with the interpretation of the high-precision model, the agent has provided a feasible optimization scheme that has tripled the charge transport properties of 2,6-diphenyldithieno[3,2-b:2 ',3 '-d]thiophene OFETs. This work is an effective practice of LLMs in the field of organic optoelectronic devices and expands the research paradigm of organic optoelectronic materials and devices. An artificial intelligence agent for enhancing organic field-effect transistor (OFET) performance by combining generative pre-trained transformer 4 (GPT-4) with advanced machine learning algorithms is presented. It efficiently extracts OFET experimental data from extensive literature and gives intelligent suggestions for OFET fabrication. This work showcases the application of large language models in organic optoelectronics, enhancing the development process in this field. image	[Zhang, Qian; Hu, Yongxu; Yan, Jiaxin; Zhang, Hengyue; Xie, Xinyi; Zhu, Jie; Li, Huchao; Niu, Xinxin; Li, Liqiang; Sun, Yajing; Hu, Wenping] Tianjin Univ, Sch Sci, Dept Chem, Key Lab Organ Integrated Circuits,Minist Educ, Tianjin 300072, Peoples R China; [Zhang, Qian; Yan, Jiaxin; Zhang, Hengyue; Zhu, Jie; Niu, Xinxin; Sun, Yajing] Haihe Lab ITAI, Tianjin 300051, Peoples R China; [Hu, Wenping] Natl Univ Singapore, Joint Sch, Fuzhou 350207, Fujian, Peoples R China; [Hu, Wenping] Tianjin Univ, Fuzhou 350207, Fujian, Peoples R China	Tianjin University; National University of Singapore; Tianjin University	Sun, YJ; Hu, WP (corresponding author), Tianjin Univ, Sch Sci, Dept Chem, Key Lab Organ Integrated Circuits,Minist Educ, Tianjin 300072, Peoples R China.; Sun, YJ (corresponding author), Haihe Lab ITAI, Tianjin 300051, Peoples R China.; Hu, WP (corresponding author), Natl Univ Singapore, Joint Sch, Fuzhou 350207, Fujian, Peoples R China.; Hu, WP (corresponding author), Tianjin Univ, Fuzhou 350207, Fujian, Peoples R China.	syj19@tju.edu.cn; huwp@tju.edu.cn		Sun, Yajing/0000-0003-2807-9382	Haihe Laboratory in Tianjin; National Key RD Program [2022YFB3603800, 2022YFA1204401, 2021YFB3600700]; National Natural Science Foundation of China [52121002, U21A6002]; GuangDong Basic and Applied Basic Research Foundation [2023A1515110356]; National Supercomputer Center in Tianjin (Tianhe 3F); Fundamental Research Funds for the Central Universities;  [22HHXCJC00007]	Haihe Laboratory in Tianjin; National Key RD Program; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); GuangDong Basic and Applied Basic Research Foundation; National Supercomputer Center in Tianjin (Tianhe 3F); Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); 	Q.Z. and Y.H. contributed equally to this work. This work was supported as part of A Multi-Scale and High-Efficiency Computing Platform for Advanced Functional Materials, funded by the Haihe Laboratory in Tianjin (Grant No. 22HHXCJC00007). The authors acknowledge financial support from the National Key R&D Program (Grant Nos. 2022YFB3603800, 2022YFA1204401, 2021YFB3600700), the National Natural Science Foundation of China (Grant Nos. 52121002, U21A6002), and the GuangDong Basic and Applied Basic Research Foundation (Grant No. 2023A1515110356). The calculations were performed on the National Supercomputer Center in Tianjin (Tianhe 3F) and the Scientific Computing Center of CIC, Tianjin University. The authors also thank "the Fundamental Research Funds for the Central Universities."	Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Chen MC, 2014, J MATER CHEM C, V2, P8892, DOI 10.1039/c4tc01454e; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chen Y, 2024, SMARTMAT, V5, DOI 10.1002/smm2.1229; Choi J, 2024, COMMUN MATER, V5, DOI 10.1038/s43246-024-00449-9; Cui HT, 2024, NAT METHODS, DOI 10.1038/s41592-024-02201-0; Dance Amber, 2009, Nature, V458, P664, DOI 10.1038/nj7238-664a; Durant JL, 2002, J CHEM INF COMP SCI, V42, P1273, DOI 10.1021/ci010132r; Hawizy L, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-17; Hong ZJ, 2023, ENERGY MATER ADV, V4, DOI 10.34133/energymatadv.0026; Hou WP, 2024, NAT METHODS, V21, P551, DOI 10.1038/s41592-024-02235-4; Jablonka KM, 2024, NAT MACH INTELL, V6, P122, DOI 10.1038/s42256-023-00788-1; Jessop DM, 2011, J CHEMINFORMATICS, V3, DOI 10.1186/1758-2946-3-41; Jiang YW, 2022, SCIENCE, V375, P1411, DOI 10.1126/science.abj7564; Li RJ, 2009, ADV MATER, V21, P4492, DOI 10.1002/adma.200900934; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Liu J, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms10032; Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9; Mavracic J, 2021, J CHEM INF MODEL, V61, P4280, DOI 10.1021/acs.jcim.1c00446; Merz KM, 2023, J CHEM INF MODEL, V63, P5395, DOI 10.1021/acs.jcim.3c01244; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018; Niu YL, 2018, MOL PHYS, V116, P1078, DOI 10.1080/00268976.2017.1402966; Nomura K, 2004, NATURE, V432, P488, DOI 10.1038/nature03090; Oliveira ON Jr, 2023, J CHEM INF MODEL, V63, P7605, DOI 10.1021/acs.jcim.3c01778; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Polak MP, 2024, NAT COMMUN, V15, DOI 10.1038/s41467-024-45914-8; Qin ZS, 2023, ADV MATER, V35, DOI 10.1002/adma.202301955; Rajan K, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-40782-0; Riveland R, 2024, NAT NEUROSCI, V27, DOI 10.1038/s41593-024-01607-5; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sirringhaus H, 2014, ADV MATER, V26, P1319, DOI 10.1002/adma.201304346; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Sun YM, 2006, ADV FUNCT MATER, V16, P426, DOI 10.1002/adfm.200500547; Szymanski NJ, 2023, NATURE, V624, P86, DOI 10.1038/s41586-023-06734-w; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Van Veen D., 2024, Nat. Med, V30, P1134; Wang CL, 2012, CHEM REV, V112, P2208, DOI 10.1021/cr100380z; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Wang L, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01029-4; Wang R, 2023, J CHEM INF MODEL, V63, P7189, DOI 10.1021/acs.jcim.3c01429; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Wong FL, 2023, SCIENCE, V381, P164, DOI 10.1126/science.adh1114; Xiao ZY, 2023, ACS SYNTH BIOL, V12, P2973, DOI 10.1021/acssynbio.3c00310; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Zhang X, 2023, J PHYS CHEM LETT, V14, P11342, DOI [10.1021/acs.jpclett.3c02848, 10.1016/j.jhazmat.2023.131342]; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhang ZT, 2022, NATURE, V603, P624, DOI 10.1038/s41586-022-04400-1; Zheng Z., 2023, Angew. Chem., V62; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819; Zhong Donglai, 2024, Nature, V627, P313, DOI 10.1038/s41586-024-07096-7; Zschieschang U, 2011, ORG ELECTRON, V12, P1370, DOI 10.1016/j.orgel.2011.04.018	52	0	0	8	8	WILEY-V C H VERLAG GMBH	WEINHEIM	POSTFACH 101161, 69451 WEINHEIM, GERMANY	0935-9648	1521-4095		ADV MATER	Adv. Mater.	2024 JUN 6	2024										10.1002/adma.202405163	http://dx.doi.org/10.1002/adma.202405163		JUN 2024	12	Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied; Physics, Condensed Matter	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Science & Technology - Other Topics; Materials Science; Physics	TM2A9	38816034				2024-07-03	WOS:001241601900001
J	Bottega, JA; Kich, VA; de Jesus, JC; Steinmetz, R; Kolling, AH; Grando, RB; Guerra, RD; Gamarra, DFT				Bottega, Jair Augusto; Kich, Victor Augusto; de Jesus, Junior Costa; Steinmetz, Raul; Kolling, Alisson Henrique; Grando, Ricardo Bedin; Guerra, Rodrigo da Silva; Gamarra, Daniel Fernando Tello			Jubileo: An Immersive Simulation Framework for Social Robot Design	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS			English	Article						Human-robot interaction; Virtual reality; Learning game; English language learning; Large language models	EDUCATION	This paper introduces Jubileo, an open-source simulated humanoid robot as a framework for the development of human-robot interaction applications. By leveraging the power of the Robot Operating System (ROS) and Unity in a virtual reality environment, this simulation establishes a strong connection to real robotics, faithfully replicating the robot's physical components down to its motors and enabling communication with servo-actuators to control both the animatronic face and the joints of a real humanoid robot. To validate the capabilities of the framework, we propose English teaching games that integrate Virtual Reality (VR), game-based Human-Robot Interaction (HRI), and advanced large language models such as Generative Pre-trained Transformer (GPT). These games aim to foster linguistic competence within dynamic and interactive virtual environments. The incorporation of large language models bolsters the robot's capability to generate human-like responses, thus facilitating a more realistic conversational experience. Moreover, the simulation framework reduces real-world testing risks and offers a cost-effective, efficient, and scalable platform for developing new HRI applications. The paper underscores the transformative potential of converging VR, large language models, and HRI, particularly in educational applications.	[Bottega, Jair Augusto; Kich, Victor Augusto] Univ Tsukuba, Intelligent Robot Lab, Tsukuba, Ibaraki, Japan; [de Jesus, Junior Costa] Korea Adv Inst Sci & Technol, Daejeon 34141, South Korea; [Steinmetz, Raul; Gamarra, Daniel Fernando Tello] Univ Fed Santa Maria, Santa Maria, RS, Brazil; [Kolling, Alisson Henrique; Grando, Ricardo Bedin; Guerra, Rodrigo da Silva] Fed Univ Rio Grande, Rio Grande, RS, Brazil; [Grando, Ricardo Bedin] Technol Univ Uruguay, Rivera, Uruguay	University of Tsukuba; Korea Advanced Institute of Science & Technology (KAIST); Universidade Federal de Santa Maria (UFSM); Universidade Federal do Rio Grande	Bottega, JA (corresponding author), Univ Tsukuba, Intelligent Robot Lab, Tsukuba, Ibaraki, Japan.	jairaugustobottega@gmail.com; daniel.gamarra@ufsm.br	Guerra, Rodrigo/A-1558-2018	Guerra, Rodrigo/0000-0003-4011-0901	University of Tsukuba	University of Tsukuba	The authors would like to thank the VersusAI team. This work was partly supported by the University of Tsukuba.	Akkaya I, 2019, Arxiv, DOI [arXiv:1910.07113, DOI 10.48550/ARXIV.1910.07113]; Asada M, 2009, IEEE T AUTON MENT DE, V1, P12, DOI 10.1109/TAMD.2009.2021702; Belpaeme T, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aat5954; Bogusevschi D., 2020, J COMPUT MATH SCI TE, V39, P5; Bottega J.A., 2022, 2022 LAT AM ROBO S L, P1; Bottega JA, 2022, IEEE-RAS INT C HUMAN, P149, DOI 10.1109/Humanoids53995.2022.10000224; Breazeal C, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1935; Cao H.-L., 2023, International Journal of Social Robotics, P1; Chen YL, 2020, COMPUT EDUC, V154, DOI 10.1016/j.compedu.2020.103910; Christmann G.H.G., 2019, Um Jogo de Interacao Humano-Robo para o Ensino de Lingua Inglesa; Datteri E, 2019, MIND MACH, V29, P109, DOI 10.1007/s11023-019-09490-x; do Nascimento LM, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01364-8; Faraj Z., 2021, Facially expressive humanoid robotic face. HardwareX, V9, P00117; Godwin-Jones R, 2014, LANG LEARN TECHNOL, V18, P9; Goodrich Michael A., 2007, Foundations and Trends in Human-Computer Interaction, V1, P203, DOI 10.1561/1100000005; Google, 2023, Google Cloud: Speech-to-Text; Google, 2023, Google Cloud Text-to-Speech API; Ishiguro H., 2016, Android science. Cognitive neuroscience robotics: a synthetic approaches to human understanding, P193, DOI 10.1007/978-4-431-54595-8_9; Jocher Glenn, 2020, Zenodo; Juliani A., 2020, CORR; Kim J.-O., 2020, Robotic Systems: Concepts, Methodologies, Tools, and Applications, P1675; Klimova B., 2017, TOJET: The Turkish Online Journal of Educational Technology, V16, P19; Liu O, 2017, IEEE ROMAN, P751, DOI 10.1109/ROMAN.2017.8172387; Monteiro F., 2019, 21 S VIRT AUGM REAL, P47, DOI DOI 10.5753/SVRESTENDIDO.2019.8471; Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811; OpenAI, 2023, GPT-4 Technical Report; Pennisi P, 2016, AUTISM RES, V9, P165, DOI 10.1002/aur.1527; Quigley M, 2009, IEEE INT CONF ROBOT, P3604; Ross Steven I., 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P491, DOI 10.1145/3581641.3584037; Shahab M, 2022, EDUC INF TECHNOL, V27, P819, DOI 10.1007/s10639-020-10392-0; Sheridan TB, 2016, HUM FACTORS, V58, P525, DOI 10.1177/0018720816644364; Sherwani F., 2020, 2020 INT C EM TRENDS, P1; Shim KC, 2003, J BIOL EDUC, V37, P71, DOI 10.1080/00219266.2003.9655854; Tan JTC, 2012, IEEE INT CONF ROBOT, P1310, DOI 10.1109/ICRA.2012.6225359; Terzioglu Y, 2020, ACMIEEE INT CONF HUM, P343, DOI 10.1145/3319502.3374829; Toh LPE, 2016, EDUC TECHNOL SOC, V19, P148; Walters ML, 2008, AUTON ROBOT, V24, P159, DOI 10.1007/s10514-007-9058-3; Wang BY, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580895; Yanco HollyA., 2002, Proceedings of the AAAI Fall Symposium on Human-Robot Interaction, P111; Ye Y, 2023, Arxiv, DOI arXiv:2304.12529; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng J. M., 1998, IEEE Potentials, V17, P20, DOI 10.1109/45.666641; Zlajpah L, 2008, MATH COMPUT SIMULAT, V79, P879, DOI 10.1016/j.matcom.2008.02.017; Zlotowski JA, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00883	44	0	0	11	11	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0921-0296	1573-0409		J INTELL ROBOT SYST	J. Intell. Robot. Syst.	DEC	2023	109	4							91	10.1007/s10846-023-01991-3	http://dx.doi.org/10.1007/s10846-023-01991-3			13	Computer Science, Artificial Intelligence; Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Robotics	AH6U7					2024-07-03	WOS:001117621200001
C	Ding, ZJ; Srinivasan, A; MacNeil, S; Chan, J			ACM	Ding, Zijian; Srinivasan, Arvind; MacNeil, Stephen; Chan, Joel			Fluid Transformers and Creative Analogies: Exploring Large Language Models' Capacity for Augmenting Cross-Domain Analogical Creativity	2023 PROCEEDINGS OF THE 15TH CONFERENCE ON CREATIVITY AND COGNITION, C&C 2023			English	Proceedings Paper	15th Conference on Creativity and Cognition (C and C)	JUN 19-21, 2023	ELECTR NETWORK	Assoc Comp Machinery, ACM SIGCHI		Large Language Models; Analogy; Creativity Support Tools	FRAMEWORK; THINKING; SEARCH	Cross-domain analogical reasoning is a core creative ability that can be challenging for humans. Recent work has shown some proofsof-concept of Large language Models' (LLMs) ability to generate cross-domain analogies. However, the reliability and potential usefulness of this capacity for augmenting human creative work has received little systematic exploration. In this paper, we systematically explore LLMs capacity to augment cross-domain analogical reasoning. Across three studies, we found: 1) LLM-generated crossdomain analogies were frequently judged as helpful in the context of a problem reformulation task (median 4 out of 5 helpfulness rating), and frequently (similar to 80% of cases) led to observable changes in problem formulations, and 2) there was an upper bound of similar to 25% of outputs being rated as potentially harmful, with a majority due to potentially upsetting content, rather than biased or toxic content. These results demonstrate the potential utility - and risks - of LLMs for augmenting cross-domain analogical creativity.	[Ding, Zijian; Srinivasan, Arvind; Chan, Joel] Univ Maryland, Coll Informat Studies, College Pk, MD 20742 USA; [MacNeil, Stephen] Temple Univ, Comp & Informat Sci, Temple, TX USA	University System of Maryland; University of Maryland College Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Ding, ZJ (corresponding author), Univ Maryland, Coll Informat Studies, College Pk, MD 20742 USA.		MacNeil, Stephen/HPH-0843-2023	MacNeil, Stephen/0000-0003-2781-6619; Chan, Joel/0000-0003-3000-4160; Srinivasan, Arvind/0000-0002-3409-6077; Ding, Zijian/0000-0002-6372-0369	ONR [N000142012506]; U.S. Department of Defense (DOD) [N000142012506] Funding Source: U.S. Department of Defense (DOD)	ONR(United States Department of DefenseUnited States NavyOffice of Naval Research); U.S. Department of Defense (DOD)(United States Department of Defense)	This research was supported in part by ONR N000142012506.	[Anonymous], 1994, DESIGNING ENG; [Anonymous], 2002, Model-based reasoning: Science, technology, values, DOI DOI 10.1007/978-1-4615-0605-8_2; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bearman C. R., 2002, P 24 ANN M COGN SCI; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berkovsky Shlomo, 2018, 23 INT C INT US INT; BHATTA S, 1994, ARTIFICIAL INTELLIGENCE IN DESIGN '94, P57; Bhavya B., 2022, arXiv; Blodgett SL, 2020, Arxiv, DOI arXiv:2005.14050; Bolanos Diana, 2022, 46 MECH ROB C MR AM, V7, DOI [10.1115/DETC2022-90033, DOI 10.1115/DETC2022-90033]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Cao C., 2023, COMP P 28 INT C INT, P229, DOI DOI 10.1145/3581754.3584111; Chakrabarty T, 2021, Arxiv, DOI arXiv:2103.06779; Chan J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P93, DOI 10.1145/3059454.3059455; Chan J, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1223, DOI 10.1145/2818048.2820023; Chan J, 2011, J MECH DESIGN, V133, DOI 10.1115/1.4004396; Chan J, 2015, COGNITION, V145, P104, DOI 10.1016/j.cognition.2015.08.008; Chan J, 2015, DESIGN STUD, V36, P31, DOI 10.1016/j.destud.2014.08.001; Chen DW, 2017, Arxiv, DOI arXiv:1705.04416; Christensen BT, 2007, MEM COGNITION, V35, P29, DOI 10.3758/BF03195939; Clark E, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P329, DOI 10.1145/3172944.3172983; Clark Elizabeth, 2021, arXiv; Cross N, 1998, RES ENG DES, V10, P141, DOI 10.1007/BF01607156; Dahl DW, 2002, J MARKETING RES, V39, P47, DOI 10.1509/jmkr.39.1.47.18930; Ding Zijian, 2023, arXiv; Dix A., 2006, HCIED 06; Dorst K, 2015, DES THINK DES THEOR, P1, DOI 10.7551/mitpress/10096.001.0001; Dorst K., 2001, Design Studies, V22, P425, DOI [10.1016/S0142-694X(01)00009-6, DOI 10.1016/S0142-694X(01)00009-6]; Dow SP, 2010, ACM T COMPUT-HUM INT, V17, DOI 10.1145/1879831.1879836; Dunbar Kevin, 1997, Creative thought: An investigation of conceptual structures and processes, p461?493, DOI DOI 10.1037/10227-017; Duncker K, 1945, PSYCHOL MONOGR, V58, P1; Frei, 2020, INT C FDN DIG GAM BU, P8; Fu K, 2013, J MECH DESIGN, V135, DOI 10.1115/1.4023158; GENTNER D, 1993, COGNITIVE PSYCHOL, V25, P524, DOI 10.1006/cogp.1993.1013; GENTNER D, 1983, COGNITIVE SCI, V7, P155, DOI 10.1207/s15516709cog0702_3; Gentner Dedre, 1985, P INT C SYST MAN CYB; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Gero KI, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300526; GICK ML, 1983, COGNITIVE PSYCHOL, V15, P1, DOI 10.1016/0010-0285(83)90002-6; GICK ML, 1980, COGNITIVE PSYCHOL, V12, P306, DOI 10.1016/0010-0285(80)90013-4; GOEL V, 1992, COGNITIVE SCI, V16, P395, DOI 10.1207/s15516709cog1603_3; Goldwater MB, 2019, COGN RES, V4, DOI 10.1186/s41235-019-0198-8; Gordon W.J., 1961, Synectics: The development of creative capacity; Grace K, 2015, AI EDAM, V29, P185, DOI 10.1017/S0890060415000062; Gruber Howard E., 1974, Darwin on man: A psychological study of scientific creativity, P495; Hargadon A, 1997, ADMIN SCI QUART, V42, P716, DOI 10.2307/2393655; Helms M. E., 2008, P 30 ANN C COGNITIVE; Hofstadter D. R., 1995, FLUID CONCEPTS CREAT; Holyoak Keith J., 1996, Mental leaps: Analogy in creative thought; Hope T, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P235, DOI 10.1145/3097983.3098038; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jigsaw, 2018, Unintended Bias and Identity Terms; Kang HB, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3530013; KAPLAN CA, 1990, COGNITIVE PSYCHOL, V22, P374, DOI 10.1016/0010-0285(90)90008-R; Kneeland MK, 2020, ORGAN SCI, V31, P535, DOI 10.1287/orsc.2019.1328; Knoblich G, 1999, J EXP PSYCHOL LEARN, V25, P1534, DOI 10.1037/0278-7393.25.6.1534; Kurtz KJ, 2013, J EXP PSYCHOL LEARN, V39, P1303, DOI 10.1037/a0031847; LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310; Latitude Team, 2020, World Creation by Analogy; Lee MA, 2024, Arxiv, DOI arXiv:2212.09746; Linsey J., 2008, P 2008 ASEE ANN C; Linsey JS, 2008, AI EDAM, V22, P85, DOI 10.1017/S0890060408000061; Linsey J. S., 2006, P IDETCCIE 2006 ASME; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Loewenstein J, 2010, PSYCHOL LEARN MOTIV, V53, P149, DOI 10.1016/S0079-7421(10)53004-4; MacNeil Stephen, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449246; MacNeil S, 2021, C&C'21: PROCEEDINGS OF THE 13TH CONFERENCE ON CREATIVITY AND COGNITION, DOI 10.1145/3450741.3465261; MacNeil Stephen, 2019, Design Computing and Cognition ' 18, P55, DOI [10.1007/978-3-030-05363-5_4, DOI 10.1007/978-3-030-05363-5_4]; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Mikolov Tomas, 2013, arXiv; Newell A., 1972, Human problem solving; Noy Lior, 2012, A quantitative study of creative leaps, V72, P72; Okada T, 2009, COGN SYST RES, V10, P189, DOI 10.1016/j.cogsys.2008.09.007; Oppenlaender J, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376677; Osone H, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3450391; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Palani S, 2021, CHIIR '21: PROCEEDINGS OF THE 2021 CONFERENCE ON HUMAN INFORMATION INTERACTION AND RETRIEVAL, P325, DOI 10.1145/3406522.3446046; Palani Srishti, 2021, P 2021 CHI C HUMAN F, P1; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; RITTEL HWJ, 1973, POLICY SCI, V4, P155, DOI 10.1007/BF01405730; Roemmele M, 2016, AAAI CONF ARTIF INTE, P4311; Savransky S.D., 2000, ENG CREATIVITY INTRO; Schon D. A., 1984, REFLECTIVE PRACTITIO; Shahaf Dafna, 2018, P ACM HUMAN COMPUTER; Sheng E, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3407; Siangliulue Pao, 2015, P 2015 ACM SIGCHI C, P83, DOI DOI 10.1145/2757226.2757230; Singh N, 2023, ACM T COMPUT-HUM INT, V30, DOI 10.1145/3511599; Vattam S, 2011, DESIGN CREATIVITY 2010, P115, DOI 10.1007/978-0-85729-224-7_16; Vendetti MS, 2014, PSYCHOL SCI, V25, P928, DOI 10.1177/0956797613518079; Webb T, 2023, Arxiv, DOI [arXiv:2212.09196, 10.48550/arXiv.2212.09196]; Winata Genta Indra, 2021, arXiv, DOI DOI 10.48550/ARXIV.2109.07684; Wolfram S., 2023, WOLFRAM ALPHA WAY BR; Yu LX, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1245, DOI 10.1145/2556288.2557371; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Zhu Q., 2022, Proceedings of the Design Society, V2, P1825, DOI [DOI 10.1017/PDS.2022.185, https://doi.org/10.1017/pds.2022.185]; Zhu QH, 2023, J MECH DESIGN, V145, DOI 10.1115/1.4056598	96	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0180-1				2023							489	505		10.1145/3591196.3593516	http://dx.doi.org/10.1145/3591196.3593516			17	Art; Computer Science, Interdisciplinary Applications; Psychology, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Art; Computer Science; Psychology	BW2MQ		Green Published, Green Submitted, hybrid			2024-07-03	WOS:001119074200070
J	Jin, K; Yuan, L; Wu, HK; Grzybowski, A; Ye, J				Jin, Kai; Yuan, Lu; Wu, Hongkang; Grzybowski, Andrzej; Ye, Juan			Exploring large language model for next generation of artificial intelligence in ophthalmology	FRONTIERS IN MEDICINE			English	Review						artificial intelligence; large language model; ChatGPT; ophthalmology; diagnostic accuracy and efficacy	CHATGPT	In recent years, ophthalmology has advanced significantly, thanks to rapid progress in artificial intelligence (AI) technologies. Large language models (LLMs) like ChatGPT have emerged as powerful tools for natural language processing. This paper finally includes 108 studies, and explores LLMs' potential in the next generation of AI in ophthalmology. The results encompass a diverse range of studies in the field of ophthalmology, highlighting the versatile applications of LLMs. Subfields encompass general ophthalmology, retinal diseases, anterior segment diseases, glaucoma, and ophthalmic plastics. Results show LLMs' competence in generating informative and contextually relevant responses, potentially reducing diagnostic errors and improving patient outcomes. Overall, this study highlights LLMs' promising role in shaping AI's future in ophthalmology. By leveraging AI, ophthalmologists can access a wealth of information, enhance diagnostic accuracy, and provide better patient care. Despite challenges, continued AI advancements and ongoing research will pave the way for the next generation of AI-assisted ophthalmic practices.	[Jin, Kai; Wu, Hongkang; Ye, Juan] Zhejiang Univ, Affiliated Hosp 2, Eye Ctr, Sch Med, Hangzhou, Peoples R China; [Yuan, Lu] Zhejiang Univ, Childrens Hosp, Natl Clin Res Ctr Child Hlth, Dept Ophthalmol,Sch Med, Hangzhou, Peoples R China; [Grzybowski, Andrzej] Inst Res Ophthalmol, Fdn Ophthalmol Dev, Poznan, Poland	Zhejiang University; Zhejiang University	Ye, J (corresponding author), Zhejiang Univ, Affiliated Hosp 2, Eye Ctr, Sch Med, Hangzhou, Peoples R China.	yejuan@zju.edu.cn	Wu, Hongkang/KFQ-3718-2024		Natural Science Foundation of China [82201195]; Clinical Medical Research Center for Eye Diseases of Zhejiang Province [2021E50007]	Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Clinical Medical Research Center for Eye Diseases of Zhejiang Province	The author(s) declare financial support was received for the research, authorship, and/or publication of this article. This work has been financially supported by Natural Science Foundation of China (grant number 82201195), and Clinical Medical Research Center for Eye Diseases of Zhejiang Province (grant number 2021E50007).	Abdullah YI, 2021, ASIA-PAC J OPHTHALMO, V10, P289, DOI 10.1097/APO.0000000000000397; Ali MJ, 2023, GRAEF ARCH CLIN EXP, V261, P3205, DOI 10.1007/s00417-023-06123-z; Ali MJ, 2023, OPHTHAL PLAST RECONS, V39, P221, DOI 10.1097/IOP.0000000000002418; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Balas M., 2023, JFO Open Ophthalmology, V1, P100005, DOI [10.1016/j.jfop.2023.100005, DOI 10.1016/J.JFOP.2023.100005]; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Cai LZ, 2023, AM J OPHTHALMOL, V254, P141, DOI 10.1016/j.ajo.2023.05.024; Chen JS, 2022, FRONT MED-LAUSANNE, V9, DOI 10.3389/fmed.2022.906554; Chou YB, 2023, CURR OPIN OPHTHALMOL, V34, P403, DOI 10.1097/ICU.0000000000000979; Dow ER, 2022, OPHTHALMOLOGY, V129, pE43, DOI 10.1016/j.ophtha.2022.01.002; Gianfrancesco MA, 2018, JAMA INTERN MED, V178, P1544, DOI 10.1001/jamainternmed.2018.3763; González-Gonzalo C, 2022, PROG RETIN EYE RES, V90, DOI 10.1016/j.preteyeres.2021.101034; Gui HW, 2022, INT J MED INFORM, V159, DOI 10.1016/j.ijmedinf.2021.104678; Hu W, 2022, TRANSL VIS SCI TECHN, V11, DOI 10.1167/tvst.11.3.37; Shivananjaiah SJK, 2023, FRONT MED-LAUSANNE, V10, DOI 10.3389/fmed.2023.1157016; Jin Kai, 2022, Adv Ophthalmol Pract Res, V2, P100078, DOI 10.1016/j.aopr.2022.100078; Lee YM., 2023, OPHTHALMIC RES, V66, P928; Li JPO, 2021, PROG RETIN EYE RES, V82, DOI 10.1016/j.preteyeres.2020.100900; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Liu XC, 2023, medRxiv, DOI [10.1101/2023.06.28.23291931, DOI 10.1101/2023.06.28.23291931, 10.1101/2023.06.28.23291931]; McLean AL, 2023, ANN BIOMED ENG, V51, P2641, DOI 10.1007/s10439-023-03282-2; Mihalache A, 2023, JAMA OPHTHALMOL, V141, P589, DOI 10.1001/jamaophthalmol.2023.1144; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; Rasmussen MLR, 2023, GRAEF ARCH CLIN EXP, V261, P3041, DOI 10.1007/s00417-023-06078-1; Salazar H, 2021, CURR OPIN OPHTHALMOL, V32, P105, DOI 10.1097/ICU.0000000000000741; Salimi A, 2023, AM J OPHTHALMOL, V254, P177, DOI 10.1016/j.ajo.2023.06.004; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singh K, 2022, CORNEA, V41, P974, DOI 10.1097/ICO.0000000000002877; Singh S, 2023, SEMIN OPHTHALMOL, V38, P503, DOI 10.1080/08820538.2023.2209166; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sun MT, 2022, J GLAUCOMA, V31, P847, DOI 10.1097/IJG.0000000000002122; Tom E, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.36; Tsui JC, 2023, EYE, V37, P3692, DOI 10.1038/s41433-023-02556-2; Valentin-Bravo F J, 2023, Arch Soc Esp Oftalmol (Engl Ed), V98, P298, DOI 10.1016/j.oftale.2023.04.011; Valentin-Bravo FJ., 2023, Arch Soc Esp Oftalmol (Engl Ed), V298, P303; Visser M, 2014, CRIT CARE, V18, DOI 10.1186/s13054-014-0604-z; Waisberg E, 2023, ANN BIOMED ENG, V51, P2353, DOI 10.1007/s10439-023-03263-5; Waisberg E, 2023, IRISH J MED SCI, V192, P3197, DOI 10.1007/s11845-023-03377-8; Wang SY, 2022, OPHTHALMOL SCI, V2, DOI 10.1016/j.xops.2022.100127; Winkler SL, 2023, MIL MED, DOI 10.1093/milmed/usad120; Winkler SL, 2022, OPTOMETRY VISION SCI, V99, P9, DOI 10.1097/OPX.0000000000001828; Yu ZH, 2022, BMC MED INFORM DECIS, V22, DOI 10.1186/s12911-022-01996-2	49	0	0	11	16	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2296-858X		FRONT MED-LAUSANNE	Front. Med.	NOV 23	2023	10								1291404	10.3389/fmed.2023.1291404	http://dx.doi.org/10.3389/fmed.2023.1291404			9	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	Z8RL2	38076260	gold			2024-07-03	WOS:001114691500001
J	Kansteiner, W				Kansteiner, Wulf			DIGITAL DOPING FOR HISTORIANS: CAN HISTORY, MEMORY, AND HISTORICAL THEORY BE RENDERED ARTIFICIALLY INTELLIGENT?	HISTORY AND THEORY			English	Article						artificial intelligence (AI); GPT-3; historical theory; collective memory; historical writing; large language models; description; narration; argumentation; OpenAI; machine learning		Artificial intelligence is making history, literally. Machine learning tools are playing a key role in crafting images and stories about the past in popular culture. AI has probably also already invaded the history classroom. Large language models such as GPT-3 are able to generate compelling, non-plagiarized texts in response to simple natural language inputs, thus providing students with an opportunity to produce high-quality written assignments with minimum effort. In a similar vein, tools like GPT-3 are likely to revolutionize historical studies, enabling historians and other professionals who deal in texts to rely on AI-generated intermediate work products, such as accurate translations, summaries, and chronologies. But present-day large language models fail at key tasks that historians hold in high regard. They are structurally incapable of telling the truth and tracking pieces of information through layers of texts. What's more, they lack ethical self-reflexivity. Therefore, for the time being, the writing of academic history will require human agency. But for historical theorists, large language models might offer an opportunity to test basic hypotheses about the nature of historical writing. Historical theorists can, for instance, have customized large language models write a series of descriptive, narrative, and assertive histories about the same events, thereby enabling them to explore the precise relation between description, narration, and argumentation in historical writing. In short, with specifically designed large language models, historical theorists can run the kinds of large-scale writing experiments that they could never put into practice with real historians.	[Kansteiner, Wulf] Aarhus Univ, Aarhus, Denmark	Aarhus University	Kansteiner, W (corresponding author), Aarhus Univ, Aarhus, Denmark.							Al-Khatib K, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4744; Bastian Matthias, 2022, DECODER         0520; Behan McCullagh C., 2003, THE TRUTH OF HIST; Boyd RL, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba2196; Brady TA Jr, 2009, GERMAN HISTORIES IN THE AGE OF REFORMATIONS, 1400-1650, P1; Brown Tom, 2020, LANGUAGE MODELS ARE; Chan Anastasia, 2022, AI ETHICS        APR, DOI 10.1007/s43681-022-00148-6; Chapman A., 2016, DIGITAL GAMES HIST V; Chintagunta B., 2021, P 2 WORKSHOP NATURAL, P66; Chow P.-S., 2020, NECSUS, V9, P193; Christopher, 2010, BROWNING USED DIGITA; Chun J, 2022, NARRATIVE, V30, P104; Cyphert A. B., 2021, UC Davis L. Rev, V55, P401; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Dehouche N., 2021, ETHICS SCI ENV POLIT, V21, P17, DOI DOI 10.3354/ESEP00195; Dickson Ben, 2020, TECHTALKS BLOG  0817; Dixon C. Scott, 2012, CONTESTING REFORMATI, P20; Ebbrecht-Hartmann Tobias, VISUAL HIST HOLOCAUS; Eisenberg Joshua Daniel, 2018, THESIS FLORIDA INT U; Extance Andy, 2018, NATURE          0910; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Friedlander Saul., 2007, YEARS EXTERMINATION; Gardner JamesB., 2017, The Oxford Handbook of Public History; Giansiracusa N., 2021, How Algorithms Create and Prevent Fake News; Grafton Anthony, 1997, FOOTNOTE CURIOUS HIS, P223; Hoskins A., 2018, DIGITAL MEDIA STUDIE; Houwing otte, 2022, DIS OBEDIENCE DIGITA, P318; Jiang Yuchen, 2022, DISCOVER ARTIFICIAL, V2, DOI 10.1007/s44163-022-00022-8; Kansteiner Wulf, 2021, Analysing Historical Narratives: On Academic, Popular and Educational Framings of the Past, P51; Kansteiner Wulf, 2021, J PERPETRATOR RES, V4, P35; Karant-Nunn SusanC., 2010, The Reformation of Feeling : Shaping the Religious Emotions in Early Modern Germany; Kejriwal M, 2022, NAT MACH INTELL, V4, P318, DOI 10.1038/s42256-022-00478-4; Lagutina KV, 2021, AUTOM CONTROL COMPUT, V55, P866, DOI 10.3103/S0146411621070257; Li XY, 2022, IEEE T VIS COMPUT GR, V28, P2938, DOI 10.1109/TVCG.2021.3049419; Luitse D, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211047734; Metz Cade, 2022, NY TIMES        0805; Miyagi Y, 2021, J PERINAT MED, V49, P596, DOI 10.1515/jpm-2020-0537; Montemayor C, 2021, MIND MACH, V31, P471, DOI 10.1007/s11023-021-09568-5; Munslow Alun., 2019, Narrative and History, V2nd; Payne Matt, 2021, WIDTHAI BLOG    0907; PESSANHA F, 2021, ACM J COMPUT CULT HE, V15; Peters Christine, 2021, DIGITAL METHODS HUMA, P192; Pihlainen Kalle, 2017, WORK HIST CONSTRUCTI; Presner Todd Samuel, 2016, Probing the Ethics of Holocaust Culture, P175; Reading Anna., 2016, Gender and Memory in the Globital Age; Rees T, 2022, DAEDALUS-US, V151, P168, DOI 10.1162/daed_a_01908; Robert A., 1995, ROSENSTONE MADE THIS; Robertson S, 2021, J SOC HIST, V54, P1005, DOI 10.1093/jsh/shab015; Romero Alberto, 2021, DATA SCI        0605; Roth PA, 2016, HIST THEORY, V55, P270, DOI 10.1111/hith.10800; Rusen J., 2017, Evidence and meaning: A theory of historical studies; Savoy J., 2020, MACHINE LEARNING MET; Setz Clemens J., 2022, ARXIV; Sharples Mike, 2022, LSE IMPACT BLOG 0517; Sharples Mike., 2022, Story machines: How computers have become creative writers; Smith C., 2003, Modes of discourse: The local structure of texts, DOI DOI 10.1017/CBO9780511615108; Snyder Timothy., 2010, BLOODLANDS EUROPE HI; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Sweet James H., 2022, PERSPECTIVES HIST, V60; Thunstrom AO., 2022, SCI AM; Tingiris Steve, 2021, EXPLORING GPT 3 UNOF, P5; von Ranke Leopold, 1905, HIST REFORMATION GER, P3	62	3	3	13	27	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0018-2656	1468-2303		HIST THEORY	Hist. Theory	DEC	2022	61	4					119	133		10.1111/hith.12282	http://dx.doi.org/10.1111/hith.12282		DEC 2022	15	History	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	History	7I3NC		Green Published, hybrid			2024-07-03	WOS:000899861300001
J	Belanger, D; Colwell, LJ				Belanger, David; Colwell, Lucy J.			Hallucinating functional protein sequences	NATURE BIOTECHNOLOGY			English	Editorial Material								Functional proteins with limited homology to natural proteins are designed using a large language model.	[Belanger, David; Colwell, Lucy J.] Google Res, Mountain View 94043, CA USA; [Colwell, Lucy J.] Univ Cambridge, Dept Chem, Cambridge, England	Google Incorporated; University of Cambridge	Colwell, LJ (corresponding author), Google Res, Mountain View 94043, CA USA.; Colwell, LJ (corresponding author), Univ Cambridge, Dept Chem, Cambridge, England.	ljc37@cam.ac.uk	Sun, Jia/JXM-0311-2024; Wang, Chen/JZE-6385-2024; li, fei/JYP-3334-2024; li, xinke/JTU-3633-2023	Belanger, David/0000-0001-7115-9009; Colwell, Lucy/0000-0003-3148-0337				Arnold FH, 2019, ANGEW CHEM INT EDIT, V58, P14420, DOI 10.1002/anie.201907729; Bryant DH, 2021, NAT BIOTECHNOL, V39, P691, DOI 10.1038/s41587-020-00793-4; Dauparas J, 2022, SCIENCE, V378, P49, DOI 10.1126/science.add2187; Dohan D, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2782, DOI 10.1145/3447548.3467163; Keskar N. S., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1909.05858; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Repecka D, 2021, NAT MACH INTELL, V3, P324, DOI 10.1038/s42256-021-00310-5; Rives A, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2016239118; Romero PA, 2013, P NATL ACAD SCI USA, V110, pE193, DOI 10.1073/pnas.1215251110; Russ WP, 2020, SCIENCE, V369, P440, DOI 10.1126/science.aba3304	10	0	1	1	17	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	1087-0156	1546-1696		NAT BIOTECHNOL	Nat. Biotechnol.	AUG	2023	41	8					1073	1074		10.1038/s41587-022-01634-2	http://dx.doi.org/10.1038/s41587-022-01634-2		JAN 2023	2	Biotechnology & Applied Microbiology	Science Citation Index Expanded (SCI-EXPANDED)	Biotechnology & Applied Microbiology	P2VH3	36702894				2024-07-03	WOS:000920853200006
J	Bang, JU; Han, SH; Kang, BO				Bang, Jeong-Uk; Han, Seung-Hoon; Kang, Byung-Ok			Alzheimer's disease recognition from spontaneous speech using large language models	ETRI JOURNAL			English	Article						Alzheimer's disease; dementia; dementia detection; large language model; pretrained model		We propose a method to automatically predict Alzheimer's disease from speech data using the ChatGPT large language model. Alzheimer's disease patients often exhibit distinctive characteristics when describing images, such as difficulties in recalling words, grammar errors, repetitive language, and incoherent narratives. For prediction, we initially employ a speech recognition system to transcribe participants' speech into text. We then gather opinions by inputting the transcribed text into ChatGPT as well as a prompt designed to solicit fluency evaluations. Subsequently, we extract embeddings from the speech, text, and opinions by the pretrained models. Finally, we use a classifier consisting of transformer blocks and linear layers to identify participants with this type of dementia. Experiments are conducted using the extensively used ADReSSo dataset. The results yield a maximum accuracy of 87.3% when speech, text, and opinions are used in conjunction. This finding suggests the potential of leveraging evaluation feedback from language models to address challenges in Alzheimer's disease recognition.	[Bang, Jeong-Uk; Han, Seung-Hoon; Kang, Byung-Ok] Elect & Telecommun Res Inst, Integrated Intelligence Res Sect, Daejeon, South Korea; [Han, Seung-Hoon] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea	Electronics & Telecommunications Research Institute - Korea (ETRI); Korea University	Bang, JU (corresponding author), Elect & Telecommun Res Inst, Integrated Intelligence Res Sect, Daejeon, South Korea.	jubang0219@etri.re.kr		Kang, ByungOk/0009-0001-8217-720X; Bang, Jeong-Uk/0000-0002-0439-6802	National Research Council of Science and Technology	National Research Council of Science and Technology	No Statement Available	Aparna Balagopalan., 2021, ARXIV; Baevski A., 2020, PROC 34 INT C NEURAL, VVolume 33, P12449; Chen J, 2021, INTERSPEECH, P3830, DOI [10.21437/interspeech.2021-2002, 10.21437/Interspeech.2021-2002]; Chen SY, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-64235-6; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong S., 2022, FEATURE ANAL EVALUAT; Eyben F, 2016, IEEE T AFFECT COMPUT, V7, P190, DOI 10.1109/TAFFC.2015.2457417; FOLSTEIN MF, 1975, J PSYCHIAT RES, V12, P189, DOI 10.1016/0022-3956(75)90026-6; Garcia SD, 2020, J ALZHEIMERS DIS, V78, P1547, DOI 10.3233/JAD-200888; Gauder L, 2021, INTERSPEECH, P3795, DOI 10.21437/Interspeech.2021-753; Hussain E, 2020, C IND ELECT APPL, P1115, DOI 10.1109/ICIEA48937.2020.9248213; Kaplan E GH., 1983, BOSTON NAMING TEST; Li RN, 2016, J SPORT HEALTH SCI, V5, P381, DOI 10.1016/j.jshs.2016.10.008; Li XJ, 2020, INT CONF ACOUST SPEE, P8249, DOI [10.1109/ICASSP40776.2020.9054362, 10.1109/icassp40776.2020.9054362]; Luz S., 2023, MULTILINGUAL ALZHEIM; Luz S, 2021, INTERSPEECH, P3780, DOI 10.21437/Interspeech.2021-1220; Luz S, 2020, INTERSPEECH, P2172, DOI 10.21437/Interspeech.2020-2571; MacWhinney B., 2017, Tools for analyzing talk part 2: the CLAN program; Nasreddine ZS, 2005, J AM GERIATR SOC, V53, P695, DOI 10.1111/j.1532-5415.2005.53221.x; OpenAI, 2023, GPT 4 TECHNICAL REPO; OpenAI, 2023, CHATGPT; Pan YL, 2021, INTERSPEECH, P3810, DOI 10.21437/Interspeech.2021-1519; Pappagari R, 2021, INTERSPEECH, P3825, DOI 10.21437/Interspeech.2021-1850; Paszke A, 2019, ADV NEUR IN, V32; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pérez-Toro PA, 2021, INTERSPEECH, P3785, DOI 10.21437/Interspeech.2021-1589; Radford A., 2023, ROBUST SPEECH RECOGN, P28492; Shor J., 2020, LEARNING UNIVERSAL N; Syed ZS, 2021, INTERSPEECH, P3815, DOI 10.21437/Interspeech.2021-1572; Vaswani A., 2017, Advances in neural information processing systems, P6000; Vigo I, 2022, BIOENGINEERING-BASEL, V9, DOI 10.3390/bioengineering9010027; Wang N, 2021, INTERSPEECH, P3835, DOI 10.21437/Interspeech.2021-2024; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhu YX, 2021, INTERSPEECH, P3790, DOI [10.21437/interspeech.2021-332, 10.21437/Interspeech.2021-332]	34	1	1	13	13	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1225-6463	2233-7326		ETRI J	ETRI J.	FEB	2024	46	1					96	105		10.4218/etrij.2023-0356	http://dx.doi.org/10.4218/etrij.2023-0356		JAN 2024	10	Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Telecommunications	JX5R9		gold			2024-07-03	WOS:001153525400001
C	Suri, S; Das, SN; Singi, K; Dey, K; Sharma, VS; Kaulgud, V			IEEE	Suri, Samdyuti; Das, Sankar Narayan; Singi, Kapil; Dey, Kuntal; Sharma, Vibhu Saujanya; Kaulgud, Vikrant			Software Engineering Using Autonomous Agents: Are We There Yet?	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Autonomous agents; Large Language Models (LLMs); SDLC		Autonomous agents equipped with Large Language Models (LLMs) are rapidly gaining prominence as a revolutionary technology within the realm of Software Engineering. These intelligent and autonomous systems demonstrate the capacity to perform tasks and make independent decisions, leveraging their intrinsic reasoning and decision-making abilities. This paper delves into the current state of autonomous agents, their capabilities, challenges, and opportunities in Software Engineering practices. By employing different prompts (with or without context), we conclude the advantages of context-rich prompts for autonomous agents. Prompts with context enhance user requirement understanding, avoiding irrelevant details that could hinder task comprehension and degrade model performance, particularly when dealing with complex frameworks such as Spring Boot, Django, Flask, etc. This exploration is conducted using Auto-GPT (v0.3.0), an open-source application powered by GPT-3.5 and GPT-4 which intelligently connects the "thoughts" of Large Language Models (LLMs) to independently accomplish the assigned goals or tasks.	[Suri, Samdyuti; Das, Sankar Narayan; Singi, Kapil; Dey, Kuntal; Sharma, Vibhu Saujanya; Kaulgud, Vikrant] Accenture Tech Labs, Bangalore, Karnataka, India		Suri, S (corresponding author), Accenture Tech Labs, Bangalore, Karnataka, India.	samdyuti.suri@accenture.com; sankar.naryan.das@accenture.com; kapil.singi@accenture.com; kuntal.dey@accenture.com; vibhu.sharma@accenture.com; vikrant.kaulgud@accenture.com	Sharma, Vibhu/KDO-2146-2024					GitHub OpenAI and Microsoft, 2023, GitHub Copilot documentation; Hong S, 2023, Arxiv, DOI arXiv:2308.00352; OpenAI, 2021, Chatgpt; Radford A., 2018, Tech. Rep. 1, V1; Shi F., 2023, INT C MACH LEARN, p31 210; Significant-Gravitas, 2023, Autogpt	6	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1855	1857		10.1109/ASE56229.2023.00174	http://dx.doi.org/10.1109/ASE56229.2023.00174			3	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200169
C	First, E; Rabe, MN; Ringer, T; Brun, Y		Chandra, S; Blincoe, K; Tonella, P		First, Emily; Rabe, Markus N.; Ringer, Talia; Brun, Yuriy			Baldur: Whole-Proof Generation and Repair with Large Language Models	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Proof assistants; proof synthesis; proof repair; machine learning; large language models; automated formal verification	PROGRAM REPAIR; VERIFICATION	Formally verifying software is a highly desirable but labor-intensive task. Recent work has developed methods to automate formal verification using proof assistants, such as Coq and Isabelle/HOL, e.g., by training a model to predict one proof step at a time and using that model to search through the space of possible proofs. This paper introduces a new method to automate formal verification: We use large language models, trained on natural language and code and fine-tuned on proofs, to generate whole proofs at once. We then demonstrate that a model fine-tuned to repair generated proofs further increasing proving power. This paper: (1) Demonstrates that whole-proof generation using transformers is possible and is as effective but more efficient than search-based techniques. (2) Demonstrates that giving the learned model additional context, such as a prior failed proof attempt and the ensuing error message, results in proof repair that further improves automated proof generation. (3) Establishes, together with prior work, a new state of the art for fully automated proof synthesis. We reify our method in a prototype, Baldur, and evaluate it on a benchmark of 6,336 Isabelle/HOL theorems and their proofs, empirically showing the effectiveness of whole-proof generation, repair, and added context. We also show that Baldur complements the state-of-the-art tool, Thor, by automatically generating proofs for an additional 8.7% of the theorems. Together, Baldur and Thor can prove 65.7% of the theorems fully automatically. This paper paves the way for new research into using large language models for automating formal verification.	[First, Emily; Brun, Yuriy] Univ Massachusetts, Amherst, MA 01003 USA; [Rabe, Markus N.] Augment Comp, Palo Alto, CA USA; [Ringer, Talia] Univ Illinois, Champaign, IL USA	University of Massachusetts System; University of Massachusetts Amherst; University of Illinois System; University of Illinois Urbana-Champaign	First, E (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.	efirst@cs.umass.edu; markus@augmentcode.com; tringer@illinois.edu; brun@cs.umass.edu		Rabe, Markus/0000-0003-4795-7259; Brun, Yuriy/0000-0003-3027-7986; Ringer, Talia/0000-0003-1854-3321	Defense Advanced Research Projects Agency [DARPA HR0011-22-90063]; National Science Foundation [CCF2210243]	Defense Advanced Research Projects Agency(United States Department of DefenseDefense Advanced Research Projects Agency (DARPA)); National Science Foundation(National Science Foundation (NSF))	This work was performed at Google., Inc. We thank Stella Biderman, Ernest Davis, and others who provided feedback on an earlier draft of this paper. This work is supported by the Defense Advanced Research Projects Agency under grant no. DARPA HR0011-22-90063, and by the National Science Foundation under grant no. CCF2210243.	Afzal A, 2021, IEEE T SOFTWARE ENG, V47, P2162, DOI 10.1109/TSE.2019.2944914; Agrawal A, 2023, PROC IEEE ACM INT C, P26, DOI 10.1109/ICSE-Companion58688.2023.00018; [Anonymous], 2019, Advances in neural information processing systems: Vol. 32; Assiri FY, 2017, SOFTWARE QUAL J, V25, P171, DOI 10.1007/s11219-016-9312-z; Azerbayev Zhangir, 2022, WORKSHOP MATHAI HUMA; Bansal K, 2019, PR MACH LEARN RES, V97; Barthe G, 2013, ACM T PROGR LANG SYS, V35, DOI 10.1145/2492061; Blaauwbroek Lasse, 2020, Intelligent Computer Mathematics (CICM 2020), P271, DOI [DOI 10.1007/978-3-030-53518-6_17, DOI 10.1007/978-3-030-53518-6]; Black S, 2022, PROCEEDINGS OF WORKSHOP ON CHALLENGES & PERSPECTIVES IN CREATING LARGE LANGUAGE MODELS (BIGSCIENCE EPISODE #5), P95; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Celik Ahmet, 2019, 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Proceedings, P539, DOI 10.1109/ASE.2019.00057; Celik A, 2018, PROC IEEE ACM INT C, P117, DOI 10.1145/3183440.3183493; Celik A, 2017, IEEE INT CONF AUTOM, P171, DOI 10.1109/ASE.2017.8115630; Chen Justin Y., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204, 10.48550/arXiv.2204]; Chen LS, 2017, IEEE INT CONF AUTOM, P637, DOI 10.1109/ASE.2017.8115674; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Cunningham G, 2023, Arxiv, DOI [arXiv:2301.02195, 10.48550/arXiv.2301.02195]; Czajka L, 2018, J AUTOM REASONING, V61, P423, DOI 10.1007/s10817-018-9458-4; D'Antoni L, 2016, LECT NOTES COMPUT SC, V9780, P383, DOI 10.1007/978-3-319-41540-6_21; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; First E, 2023, Arxiv, DOI [arXiv:2303.04910, DOI 10.48550/ARXIV.2303.04910.9]; First E, 2022, PROC INT CONF SOFTW, P749, DOI 10.1145/3510003.3510138; First E, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428299; Galhotra S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P498, DOI 10.1145/3106237.3106277; Gauthier T, 2021, J AUTOM REASONING, V65, P257, DOI 10.1007/s10817-020-09580-x; Giguere Stephen, 2022, ICLR, P25; Gulwani S, 2018, PROCEEDINGS OF THE 39TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, PLDI 2018, P465, DOI [10.1145/3192366.3192387, 10.1145/3296979.3192387]; Gupta R, 2017, AAAI CONF ARTIF INTE, P1345; Hahn C, 2022, Arxiv, DOI [arXiv:2206.01962, 10.48550/arXiv.2206.01962, DOI 10.48550/ARXIV.2206.01962]; Han Jesse Michael, 2022, ICLR; Harman M, 2007, FOSE 2007: FUTURE OF SOFTWARE ENGINEERING, P342, DOI 10.1109/FOSE.2007.29; Hendrycks Dan, 2021, arXiv; Heras J, 2014, ELECTRON P THEOR COM, P61, DOI 10.4204/EPTCS.152.5; Huang Daniel, 2019, 7 INT C LEARN REPR I; Jain K, 2020, PROC INT CONF SOFTW, P89, DOI 10.1145/3377812.3382156; Jiang AQ, 2022, Arxiv, DOI arXiv:2210.12283; Jiang Albert Qiaochu, 2021, C ARTIFICIAL INTELLI; Jiang JJ, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-1465-6; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Ke Wang, 2018, ACM SIGPLAN Notices, V53, P481, DOI 10.1145/3296979.3192384; Ke YL, 2015, IEEE INT CONF AUTOM, P295, DOI 10.1109/ASE.2015.60; Kim D, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P802, DOI 10.1109/ICSE.2013.6606626; Klein G, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P207; Koyuncu A, 2019, ESEC/FSE'2019: PROCEEDINGS OF THE 2019 27TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P314, DOI 10.1145/3338906.3338935; Lample G, 2022, Arxiv, DOI [arXiv:2205.11491, 10.48550/arXiv.2205.11491]; Lampropoulos L, 2018, P ACM PROGRAM LANG, V2, DOI 10.1145/3158133; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Le XBD, 2016, 2016 IEEE 23RD INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER), VOL 1, P213, DOI 10.1109/SANER.2016.76; Leroy X, 2009, COMMUN ACM, V52, P107, DOI 10.1145/1538788.1538814; Lewkowycz Aitor, 2022, arXiv; Long F, 2016, ACM SIGPLAN NOTICES, V51, P298, DOI 10.1145/2914770.2837617; Masci P, 2022, LECT NOTES COMPUT SC, V13260, P809, DOI 10.1007/978-3-031-06773-0_44; Mechtaev S, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P129, DOI 10.1145/3180155.3180247; Milos Piotr, 2022, NeurIPS; Motwani M, 2022, IEEE T SOFTWARE ENG, V48, P637, DOI 10.1109/TSE.2020.2998785; Motwani Manish, 2023, ICSE 14 20; Mu K., 2013, ESEC FSE NEW IDEAS T, P631, DOI DOI 10.1145/2491411.2494580; Mu  slu K., 2015, ISSTA 15, P373, DOI [10.1145/27717 83.2771792, DOI 10.1145/2771783.2771792]; Nagashima Y, 2018, IEEE INT CONF AUTOM, P362, DOI 10.1145/3238147.3238210; Nie PY, 2021, PROC IEEE ACM INT C, P21, DOI 10.1109/ICSE-Companion52605.2021.00026; Nie PY, 2020, LECT NOTES COMPUT SC, V12167, P97, DOI 10.1007/978-3-030-51054-1_6; Nie Pengyu, 2020, COQ WORKSHOP; Noda K, 2020, PROCEEDINGS OF THE 2020 IEEE 27TH INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION, AND REENGINEERING (SANER '20), P612, DOI [10.1109/SANER48275.2020.9054829, 10.1109/saner48275.2020.9054829]; Noorbakhsh K, 2021, Arxiv, DOI [arXiv:2110.03501, DOI 10.48550/ARXIV.2110.03501]; Nye Maxwell, 2021, arXiv; Paliwal A, 2020, AAAI CONF ARTIF INTE, V34, P2967; Palmskog K, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P344, DOI 10.1145/3213846.3213877; Paulson Larry, 2023, The sledgehammer: Let automatic theorem provers write your isabelle scripts; Petke Justyna, 2018, APR SEOUL WORKSHOP A, P13, DOI [10.1145/3387940.3392180, DOI 10.1145/3387940.3392180]; Phan A, 2021, COMPUT HUM BEHAV REP, V3, DOI 10.1016/j.chbr.2021.100055; Polu S, 2020, Arxiv, DOI arXiv:2009.03393; Pope Reiner, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2211.05102, 10.48550/arXiv.2211.05102]; Qi Z., 2015, P 2015 INT S SOFTW T, P24, DOI DOI 10.1145/2771783.2771791; Raffel C, 2020, J MACH LEARN RES, V21; Ringer T, 2020, CPP '20: PROCEEDINGS OF THE 9TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON CERTIFIED PROGRAMS AND PROOFS, P99, DOI 10.1145/3372885.3373823; Ringer T, 2019, FOUND TRENDS PROGRAM, V5, P102, DOI 10.1561/2500000045; Saha RK, 2017, IEEE INT CONF AUTOM, P648, DOI 10.1109/ASE.2017.8115675; Saha S, 2019, PROC INT CONF SOFTW, P13, DOI 10.1109/ICSE.2019.00020; Sanchez-Stern Alex, 2020, MAPL 2020: Proceedings of the 4th ACM SIGPLAN International Workshop on Machine Learning and Programming Languages, P1, DOI 10.1145/3394450.3397466; Sanchez-Stern A, 2023, ACM T PROGR LANG SYS, V45, DOI 10.1145/3593374; Shazeer N, 2019, Arxiv, DOI arXiv:1911.02150; Smith EK, 2015, 2015 10TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE 2015) PROCEEDINGS, P532, DOI 10.1145/2786805.2786825; Su JL, 2023, Arxiv, DOI arXiv:2104.09864; Sun SY, 2018, P INT COMP SOFTW APP, P174, DOI 10.1109/COMPSAC.2018.00030; The Coq Development Team, 2017, Coq; Thomas PS, 2019, SCIENCE, V366, P999, DOI 10.1126/science.aag3311; Tian HY, 2020, IEEE INT CONF AUTOM, P981, DOI 10.1145/3324884.3416532; Tian Y, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P752, DOI 10.1145/3106237.3106300; van den Oord A., 2016, arXiv, DOI DOI 10.48550/ARXIV.1609.03499; Vaswani A, 2017, ADV NEUR IN, V30; Wang SW, 2020, IEEE INT CONF AUTOM, P968, DOI 10.1145/3324884.3416590; Weber A, 2022, Arxiv, DOI [arXiv:2208.11744, DOI 10.48550/ARXIV.2208.11744]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Weimer W, 2013, IEEE INT CONF AUTOM, P356, DOI 10.1109/ASE.2013.6693094; Wen M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/3180155.3180233; Wu Minchao, 2021, NeurIPS; Wu YH, 2022, Arxiv, DOI [arXiv:2205.12615, 10.48550/arXiv.2205.12615, DOI 10.48550/ARXIV.2205.12615]; Xin Q, 2017, PROCEEDINGS OF THE 26TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA'17), P226, DOI 10.1145/3092703.3092718; Yang DH, 2018, LECT NOTES COMPUT SC, V11293, P33, DOI 10.1007/978-3-030-04272-1_3; Yang JQ, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P831, DOI 10.1145/3106237.3106274; Yang KY, 2019, PR MACH LEARN RES, V97; Yang XJ, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P283; Yasunaga M, 2021, PR MACH LEARN RES, V139; Ye H, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-020-09920-w; Yiling Lou, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P75, DOI 10.1145/3395363.3397351; Yu ZX, 2019, EMPIR SOFTW ENG, V24, P33, DOI 10.1007/s10664-018-9619-4; Zheng Kunhao, 2022, ICLR; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	111	2	2	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							1229	1241		10.1145/3611643.3616243	http://dx.doi.org/10.1145/3611643.3616243			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted			2024-07-03	WOS:001148157800099
C	Qi, H; Dai, LY; Chen, WC; Jia, Z; Lu, XY			IEEE	Qi, Hao; Dai, Liuyao; Chen, Weicong; Jia, Zhen; Lu, Xiaoyi			Performance Characterization of Large Language Models on High-Speed Interconnects	2023 IEEE SYMPOSIUM ON HIGH-PERFORMANCE INTERCONNECTS, HOTI	Symposium on High Performance Interconnects		English	Proceedings Paper	30th IEEE Annual Symposium on High-Performance Interconnects (HOTI)	AUG 23-25, 2023	ELECTR NETWORK	IEEE, IEEE Comp Soc, TCMM, Cornelis Networks, Huawei, IBM, Arista, Nutanix, Algo Log, Lenovo		Large language models; Characterization; Transformer; GPT; BERT; T5		Large Language Models (LLMs) have recently gained significant popularity due to their ability to generate human-like text and perform a wide range of natural language processing tasks. Training these models usually requires a large amount of computational resources and is often done in a distributed manner. The use of high-speed interconnects can significantly influence the efficiency of distributed training. Therefore, there poses a need for systematic studies to explore the distributed training characteristics of these models on high-speed interconnects. This paper presents a comprehensive performance characterization of representative large language models: GPT, BERT, and T5. We evaluate their training performance in terms of iteration time, interconnect utilization, and scalability, over different high-speed interconnects and communication protocols, including TCP/IP, IPoIB, and RDMA. We observe that interconnects play a vital role in LLM training. Specifically, RDMA100 Gbps outperforms IPoIB-100 Gbps and TCP/IP-10 Gbps by an average of 2.51x and 4.79x regarding training iteration time, and scores the highest interconnect utilization (up to 60 Gbps) in both strong and weak scaling, compared to IPoIB with up to 20 Gbps and TCP/IP with up to 9 Gbps, leading to the shortest training time. We also observe that larger models tend to have higher requirements for communication bandwidth, especially for AllReduce during backward propagation, which can take up to 91.12% of training time. Through our evaluation, we envision opportunities to improve the communication time for better training performance of LLMs. We extensively explore and summarize the role communication plays in distributed LLM training.	[Qi, Hao; Dai, Liuyao; Chen, Weicong; Lu, Xiaoyi] Univ Calif Merced, Merced, CA 95343 USA; [Jia, Zhen] Amazon Web Serv, Santa Clara, CA USA	University of California System; University of California Merced; Amazon.com	Lu, XY (corresponding author), Univ Calif Merced, Merced, CA 95343 USA.	hqi6@ucmerced.edu; ldai8@ucmerced.edu; wchen97@ucmerced.edu; zhej@amazon.com; xiaoyi.lu@ucmerced.edu	Weicong, Chen/AAC-9433-2019	Qi, Hao/0009-0007-8795-5262	Amazon Research Award	Amazon Research Award	We thank the anonymous reviewers for their valuable insights, thoughtful comments, and constructive feedback. Their expertise and thorough evaluation significantly contributed to the improvement of this work. This work was supported in part by an Amazon Research Award. Part of this research was conducted using Pinnacles (NSF MRI, #2019144) at the Cyberinfrastructure and Research Technologies (CIRT) at the University of California, Merced.	[Anonymous], EnglishWikipedia Dump; [Anonymous], GPT-4 Technical Report; Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Biswas R, 2018, INT C HIGH PERFORM, P2, DOI 10.1109/HiPC.2018.00010; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; CERF VG, 1974, IEEE T COMMUN, VCO22, P637, DOI 10.1109/TCOM.1974.1092259; de Sousa MG, 2019, PROC INT C TOOLS ART, P1597, DOI 10.1109/ICTAI.2019.00231; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Hestness J, 2017, Arxiv, DOI [arXiv:1712.00409, DOI 10.48550/ARXIV.1712.00409]; Hu W., 2020, ADV NEURAL INFORM PR, V33, P22118, DOI DOI 10.48550/ARXIV.2005.00687; Islam NS, 2013, SYMP HI PER INT, P75, DOI 10.1109/HOTI.2013.24; Kashyap V., 2006, Tech. rep.; Li S, 2020, Arxiv, DOI [arXiv:2006.15704, DOI 10.14778/3415478.3415530]; Lu XY, 2013, PROC INT CONF PARAL, P641, DOI 10.1109/ICPP.2013.78; Lu XY, 2017, 2017 IEEE 25TH ANNUAL SYMPOSIUM ON HIGH-PERFORMANCE INTERCONNECTS (HOTI), P87, DOI 10.1109/HOTI.2017.24; Lu XY, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P253, DOI 10.1109/BigData.2016.7840611; Lu XY, 2014, SYMP HI PER INT, P9, DOI 10.1109/HOTI.2014.15; Mattson P., 2020, Mlperf training benchmark, P336, DOI DOI 10.48550/ARXIV.1910.01500; MRI, Acquisition of Pinnacles-Raising Research Computing to New Heights in California's Central Valley; MTIA, META'S First Generation of AI Accelerators; Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Recio R., 2007, RFC 5040, Tech. Rep; Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045; Sergeev A, 2018, Arxiv, DOI [arXiv:1802.05799, DOI 10.48550/ARXIV.1802.05799]; Shi XJ, 2017, ADV NEUR IN, V30; Vaswani A, 2017, ADV NEUR IN, V30	29	1	1	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4794	2332-5569	979-8-3503-0475-6	SYMP HI PER INT			2023							53	60		10.1109/HOTI59126.2023.00022	http://dx.doi.org/10.1109/HOTI59126.2023.00022			8	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW0ED					2024-07-03	WOS:001094865000008
J	Venerito, V; Bilgin, E; Iannone, F; Kiraz, S				Venerito, Vincenzo; Bilgin, Emre; Iannone, Florenzo; Kiraz, Sedat			AI am a rheumatologist: a practical primer to large language models for rheumatologists	RHEUMATOLOGY			English	Review						Natural language processing (NLP); large language models (LLMs); generative pre-trained transformers (GPT); academia; rheumatology; opportunities; challenges		Natural language processing (NLP), a subclass of artificial intelligence, large language models (LLMs), and its latest applications, such as Generative Pre-trained Transformers (GPT), ChatGPT, or LLAMA, have recently become one of the most discussed topics. Up to now, artificial intelligence and NLP ultimately impacted several areas, such as finance, economics and diagnostic/scoring systems in healthcare. Another area that artificial intelligence has affected and will continue to affect increasingly is academic life. This narrative review will define NLP, LLMs and their applications, discuss the opportunities and challenges that components of academic society will experience in rheumatology, and discuss the impact of NLP and LLMs in rheumatology healthcare.	[Venerito, Vincenzo; Iannone, Florenzo] Univ Bari Aldo Moro, Dept Precis & Regenerat Med Ionian Area, Rheumatol Unit, Bari, Italy; [Bilgin, Emre; Kiraz, Sedat] Hacettepe Univ, Dept Internal Med, Div Rheumatol, Fac Med, Ankara, Turkiye; [Bilgin, Emre] Hacettepe Univ, Hacettepe Univ Hosp, Dept Internal Med, Div Rheumatol,Fac Med, Gevher Nesibe St,1st Floor, Ankara, Turkiye	Universita degli Studi di Bari Aldo Moro; Hacettepe University; Hacettepe University	Bilgin, E (corresponding author), Hacettepe Univ, Hacettepe Univ Hosp, Dept Internal Med, Div Rheumatol,Fac Med, Gevher Nesibe St,1st Floor, Ankara, Turkiye.	dr.emrebilgin@gmail.com	Bilgin, Emre/C-8092-2015; Iannone, Florenzo/AIC-3027-2022	Bilgin, Emre/0000-0002-2260-4660; Iannone, Florenzo/0000-0003-0474-5344; Venerito, Vincenzo/0000-0002-2573-5930				Browne Ryan., 2023, CNBC; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Gupta L, 2023, HEALTH POLICY TECHN, V12, DOI 10.1016/j.hlpt.2023.100730; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; OpenAI, 2023, ArXiv; Touvron H., 2023, arXiv; Venerito V, 2021, INTERN EMERG MED, V16, P1457, DOI 10.1007/s11739-020-02583-x	8	14	14	12	38	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1462-0324	1462-0332		RHEUMATOLOGY	RHEUMATOLOGY	OCT 3	2023	62	10					3256	3260		10.1093/rheumatology/kead291	http://dx.doi.org/10.1093/rheumatology/kead291		JUN 2023	5	Rheumatology	Science Citation Index Expanded (SCI-EXPANDED)	Rheumatology	U4FY5	37307079	Green Published, hybrid			2024-07-03	WOS:001013329200001
C	Liventsev, V; Grishina, A; Härmä, A; Moonen, L		Paquete, L		Liventsev, Vadim; Grishina, Anastasiia; Harma, Aki; Moonen, Leon			Fully Autonomous Programming with Large Language Models	PROCEEDINGS OF THE 2023 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, GECCO 2023			English	Proceedings Paper	Genetic and Evolutionary Computation Conference (GECCO)	JUL 15-19, 2023	Lisbon, PORTUGAL	Assoc Comp Machinery, ACM, Special Interest Grp Genet & Evolutionary Computat		automatic programming; large language models; program repair		Current approaches to program synthesis with Large Language Models (LLMs) exhibit a "near miss syndrome": they tend to generate programs that semantically resemble the correct answer (as measured by text similarity metrics or human evaluation), but achieve a low or even zero accuracy as measured by unit tests due to small imperfections, such as the wrong input or output format. This calls for an approach known as Synthesize, Execute, Debug (SED), whereby a draft of the solution is generated first, followed by a program repair phase addressing the failed tests. To effectively apply this approach to instruction-driven LLMs, one needs to determine which prompts perform best as instructions for LLMs, as well as strike a balance between repairing unsuccessful programs and replacing them with newly generated ones. We explore these trade-offs empirically, comparing replace-focused, repair-focused, and hybrid debug strategies, as well as different template-based and model-based prompt-generation techniques. We use OpenAI Codex as the LLM and Program Synthesis Benchmark 2 as a database of problem descriptions and tests for evaluation. The resulting framework outperforms both conventional usage of Codex without the repair phase and traditional genetic programming approaches.	[Liventsev, Vadim] TU Eindhoven, Eindhoven, Netherlands; [Liventsev, Vadim; Harma, Aki] Philips Res, Eindhoven, Netherlands; [Grishina, Anastasiia; Moonen, Leon] Simula, Oslo, Norway; [Grishina, Anastasiia] Univ Oslo, Oslo, Norway; [Moonen, Leon] BI Norwegian Business Sch, Oslo, Norway	Eindhoven University of Technology; Philips; Philips Research; University of Oslo; BI Norwegian Business School	Liventsev, V (corresponding author), TU Eindhoven, Eindhoven, Netherlands.; Liventsev, V (corresponding author), Philips Res, Eindhoven, Netherlands.	v.liventsev@tue.nl; anastasiia@simula.no; aki.harma@philips.com; leon.moonen@computer.org	Harma, Aki/KMA-1372-2024; Moonen, Leon/M-8790-2015	Harma, Aki/0000-0002-2966-3305; Moonen, Leon/0000-0002-1761-6771; Grishina, Anastasiia/0000-0003-3139-0200; Liventsev, Vadim/0000-0002-6670-6909	European Commission [812882]; Research Council of Norway [270053]; Research Council of Norway through the secureIT project [288787]	European Commission(European Union (EU)European Commission Joint Research Centre); Research Council of Norway(Research Council of Norway); Research Council of Norway through the secureIT project(Research Council of Norway)	The work presented in this paper was supported by the European Commission through Horizon 2020 grant 812882, and by the Research Council of Norway through the secureIT project (#288787). The empirical evaluation made use of the Experimental Infrastructure for Exploration of Exascale Computing (eX3), supported by the Research Council of Norway through grant #270053.	Ahmad B., 2023, ARXIV; Ahvanooey MT, 2019, KSII T INTERNET INF, V13, P1765, DOI 10.3837/tiis.2019.04.002; Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695; Alur R, 2015, NATO SCI PEAC SECUR, V40, P1, DOI 10.3233/978-1-61499-495-4-1; [Anonymous], TIOBE IND; [Anonymous], OpenAI API; Bastani O, 2022, LECT NOTES ARTIF INT, V13200, P207, DOI 10.1007/978-3-031-04083-2_11; Bavishi R., 2022, OOPSLA; Blain J., 2002, 9 WORLDS SEIDMAGIC E; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P3280, DOI 10.1109/TSE.2021.3087402; Chen M., 2021, arXiv; Chen X., 2021, Advances in Neural Information Processing Systems, V34, P22196; Connolly T. M., 2023, DIVERSE PERSPEC TIVE, P161, DOI 10/j5zp; de Bruin S, 2021, Arxiv, DOI arXiv:2108.07129; Dhar S, 2021, ACM T INTERNET THING, V2, DOI 10.1145/3450494; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Fernandes E, 2016, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE ON EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING 2016 (EASE '16), DOI 10.1145/2915970.2915984; Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918; Gulwani S., 2016, PROGRAMMING EXAMPLES, P22; Gupta K., 2020, Advances in Neural Information Processing Systems, V33, P17685; Halbert Daniel, 1984, Programming by Example; Helmuth T, 2022, GENET PROGRAM EVOL M, V23, P375, DOI 10.1007/s10710-022-09434-y; Helmuth T, 2022, ARTIF LIFE, V27, P183, DOI 10.1162/artl_a_00341; Helmuth T, 2015, GECCO'15: PROCEEDINGS OF THE 2015 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1039, DOI 10.1145/2739480.2754769; Huang Q, 2022, Arxiv, DOI arXiv:2208.05361; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Iyer S, 2018, Arxiv, DOI arXiv:1808.09588; Jack N, 2000, INT J PROD ECON, V67, P95, DOI 10.1016/S0925-5273(00)00012-8; Jia Y, 2022, IEEE T EMERG TOP COM, V10, P1746, DOI 10.1109/TETC.2022.3171314; Joshi H, 2022, Arxiv, DOI arXiv:2208.11640; Kuznia K, 2022, Arxiv, DOI arXiv:2203.08597; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Liventsev V, 2022, Arxiv, DOI arXiv:2101.09571; Lu Shuai, 2021, P NEURAL INFORM PROC; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; MANNA Z, 1992, IEEE T SOFTWARE ENG, V18, P674, DOI 10.1109/32.153379; Marcano M, 2020, IEEE T HUM-MACH SYST, V50, P475, DOI 10.1109/THMS.2020.3017748; Niu CA, 2023, Arxiv, DOI arXiv:2302.04030; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pearce H, 2021, Arxiv, DOI arXiv:2108.09293; Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219; Polozov O, 2015, ACM SIGPLAN NOTICES, V50, P107, DOI [10.1145/2814270.2814310, 10.1145/2858965.2814310]; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Ren S, 2020, Arxiv, DOI [arXiv:2009.10297, 10.48550/arXiv.2009.10297]; Roziere B., 2020, 34 C SYSTEMS; Russell SJ., 2016, ARTIF INTELL; Shrivastava D, 2022, Arxiv, DOI arXiv:2206.12839; Sobania D, 2023, ARXIV; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Vaswani A, 2017, ADV NEUR IN, V30; Zavershynskyi M., 2018, ARXIV	53	1	1	10	16	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0119-1				2023							1146	1155		10.1145/3583131.3590481	http://dx.doi.org/10.1145/3583131.3590481			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4HS		Green Published, Green Submitted			2024-07-03	WOS:001031455100128
J	Loureiro, SMC; Guerreiro, J; Friedmann, E; Lee, MJ; Han, HS				Loureiro, Sandra Maria Correia; Guerreiro, Joao; Friedmann, Enav; Lee, Myong Jae; Han, Heesup			Tourists and artificial intelligence-LLM interaction: the power of forgiveness	CURRENT ISSUES IN TOURISM			English	Article; Early Access						Attachment-aversion relationship; large language models; tourists-AI-LLMs; motivational strength; forgiveness	BRAND ENGAGEMENT; EXTENDED SELF; CONSUMER; ATTACHMENT; BETRAYAL	Artificial intelligence large language models (AI-LLMs) can become valuable travel advisors but often suffer from hallucinations that can diminish consumers' confidence in their results. This study explores the relationship between tourists and AI large language model interactions by analyzing how (i) attachment-aversion affects the motivational strength for using AI large language models as travel advisors and (ii) the moderation role of forgiveness in the relationship between the symbolic benefits consumers get from using those AI advisors and the attachment-aversion relationship. A sample of 451 participants in a Qualtrics survey was used to test the conceptual proposed framework. Findings reveal the important role of enriching the self and enticing the self in shaping attachment-aversion relationships. Forgiveness strengthens the relationship between enriching the self (symbolic benefits) and attachment-aversion. This research can guide managers in using its findings to develop customised AI-LLMs that foster engaging dialogues with travellers, enhance feelings of attachment, and forgive any potential missteps throughout the relationship.	[Loureiro, Sandra Maria Correia; Guerreiro, Joao] Iscte Inst Univ Lisboa & Business Res Unit BRU IUL, Mkt Operat & Gen Management Dept, Lisbon, Portugal; [Friedmann, Enav] Ben Gurion Univ Negev, Guilford Glazer Fac Business & Management, Dept Business Adm, Mkt, Beer Sheva, Israel; [Lee, Myong Jae] Calif State Polytech Univ Pomona, Collins Coll Hospitality Management, Pomona, CA USA; [Han, Heesup] Sejong Univ, Coll Hospitality & Tourism Management, Seoul, South Korea	Ben Gurion University; California State University System; California State Polytechnic University Pomona; Sejong University	Han, HS (corresponding author), Sejong Univ, Coll Hospitality & Tourism Management, Seoul, South Korea.	heesup.han@gmail.com		Han, Heesup/0000-0001-6356-3001; Loureiro, Sandra Maria Correia/0000-0001-8362-4430				Ahuvia AC, 2005, J CONSUM RES, V32, P171, DOI 10.1086/429607; Ali F, 2023, INT J HOSP MANAG, V114, DOI 10.1016/j.ijhm.2023.103588; [Anonymous], 1959, The social psychology of groups; Aron A., 1986, LOVE EXPANSION SELF; Aw ECX, 2023, J ADVERTISING, V52, P387, DOI 10.1080/00913367.2022.2066034; Belk R, 2016, CURR OPIN PSYCHOL, V10, P50, DOI 10.1016/j.copsyc.2015.11.003; Biswas SS, 2023, ANN BIOMED ENG, V51, P868, DOI 10.1007/s10439-023-03172-7; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Browne M.W., 1993, SOCIOL METHOD RES, P445, DOI 10.1177/0049124192021002005; Camilleri MA, 2024, TECHNOL FORECAST SOC, V201, DOI 10.1016/j.techfore.2024.123247; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Christensen J, 2024, CURR ISSUES TOUR, DOI 10.1080/13683500.2023.2300032; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Elyoseph Z, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1199058; Emsley R, 2023, SCHIZOPHRENIA-UK, V9, DOI 10.1038/s41537-023-00379-4; Escalas JE, 2005, J CONSUM RES, V32, P378, DOI 10.1086/497549; Fernández-Capo M, 2017, EUR PSYCHOL, V22, P247, DOI 10.1027/1016-9040/a000303; Fetscherin M, 2019, J PROD BRAND MANAG, V28, P633, DOI 10.1108/JPBM-04-2018-1845; Finkel EJ, 2002, J PERS SOC PSYCHOL, V82, P956, DOI 10.1037//0022-3514.82.6.956; Fournier S, 1998, J CONSUM RES, V24, P343, DOI 10.1086/209515; Friedmann E., 2023, European Journal of International Management, V31, DOI [https://doi.org/10.1504/EJIM.2022.10053329, DOI 10.1504/EJIM.2022.10053329]; Fuller CM, 2016, J BUS RES, V69, P3192, DOI 10.1016/j.jbusres.2015.12.008; Gill-Simmen L., 2018, AMS review, V8, P128, DOI [https://doi.org/10.1007/s13162-018-0110-6, DOI 10.1007/S13162-018-0110-6]; Guerreiro J, 2023, J BUS RES, V161, DOI 10.1016/j.jbusres.2023.113863; Gursoy D, 2023, J HOSP MARKET MANAG, V32, P579, DOI 10.1080/19368623.2023.2211993; Hoffman DL, 2018, J CONSUM RES, V44, P1178, DOI 10.1093/jcr/ucx105; Hollebeek LD, 2024, PSYCHOL MARKET, V41, P880, DOI 10.1002/mar.21957; Javaid M., 2023, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V3, DOI DOI 10.1016/J.TBENCH.2023.100115; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jia GM, 2023, CURR ISSUES TOUR, V26, P664, DOI 10.1080/13683500.2022.2037527; Kim K, 2023, CURR ISSUES TOUR, DOI 10.1080/13683500.2023.2280145; KOPEC JA, 1990, J EPIDEMIOL COMMUN H, V44, P179, DOI 10.1136/jech.44.3.179; Kull AJ, 2021, J BUS RES, V135, P840, DOI 10.1016/j.jbusres.2021.03.005; Leonidou LC, 2018, PSYCHOL MARKET, V35, P341, DOI 10.1002/mar.21090; Lian Y, 2024, TECHNOL SOC, V76, DOI 10.1016/j.techsoc.2023.102442; Loureiro SMC, 2024, INT J HUM-COMPUT INT, V40, P782, DOI 10.1080/10447318.2022.2124346; McCullough ME, 1997, J PERS SOC PSYCHOL, V73, P321, DOI 10.1037/0022-3514.73.2.321; McLean G, 2021, J BUS RES, V124, P312, DOI 10.1016/j.jbusres.2020.11.045; Melián-González S, 2021, CURR ISSUES TOUR, V24, P192, DOI 10.1080/13683500.2019.1706457; Mich L, 2023, INF TECHNOL TOUR, V25, P1, DOI 10.1007/s40558-023-00248-x; Nguyen M, 2023, PSYCHOL MARKET, V40, P2201, DOI 10.1002/mar.21882; Niu B, 2024, J RETAIL CONSUM SERV, V76, DOI 10.1016/j.jretconser.2023.103562; Oh H, 2019, J PROD BRAND MANAG, V28, P231, DOI 10.1108/JPBM-09-2017-1567; OpenAI, 2023, ChatGPT plugins; Orden-Mejía M, 2022, CURR ISSUES TOUR, V25, P2854, DOI 10.1080/13683500.2021.1997942; Park CW, 2013, J CONSUM PSYCHOL, V23, P229, DOI 10.1016/j.jcps.2013.01.002; Park CW, 2010, J MARKETING, V74, P1, DOI 10.1509/jmkg.74.6.1; Pentina I, 2023, PSYCHOL MARKET, V40, P1593, DOI 10.1002/mar.21853; Pham HC, 2024, J RETAIL CONSUM SERV, V78, DOI 10.1016/j.jretconser.2024.103758; Pichierri M, 2023, CURR ISSUES TOUR, V26, P511, DOI 10.1080/13683500.2022.2069551; Pillai R, 2020, INT J CONTEMP HOSP M, V32, P3199, DOI 10.1108/IJCHM-04-2020-0259; Reimann M., 2018, Journal of the Association for Consumer Research, V3, P240, DOI DOI 10.1086/697077; Schmitt B, 2013, J CONSUM PSYCHOL, V23, P249, DOI 10.1016/j.jcps.2013.01.003; Shanthi R., 2019, MULTIVARIATE DATA AN; Shin H, 2023, J HOSP TOUR MANAG, V57, P40, DOI 10.1016/j.jhtm.2023.09.001; Skjuve M., 2023, P 5 INT C CONV US IN, V2, P1; Soper D., A PRIORI SAMPLE SIZE; Statista, 2023, Guests interested to stay at hotels with automated messaging/chatbots worldwide 2022; Statista, 2023, Chatbot market revenue worldwide 2017 and 2024; Surameery N. M. S., 2023, Int J Inform Technol Comput Eng, V3, P17, DOI [10.55529/ijitc.31.17.22, DOI 10.55529/IJITC.31.17.22]; Thomson M, 2006, J MARKETING, V70, P104, DOI 10.1509/jmkg.70.3.104; Tiwari CK, 2023, INTERACT TECHNOL SMA, DOI 10.1108/ITSE-04-2023-0061; Tsarenko Y, 2015, J MARKET MANAG-UK, V31, P1851, DOI 10.1080/0267257X.2015.1069373; Wei YH, 2023, ASIAN J PSYCHIATR, V90, DOI 10.1016/j.ajp.2023.103808; Weiner B, 2000, J CONSUM RES, V27, P382, DOI 10.1086/317592; Wong IA, 2023, J HOSP TOUR MANAG, V56, P253, DOI 10.1016/j.jhtm.2023.06.022; Xie Y, 2009, PSYCHOL MARKET, V26, P572, DOI 10.1002/mar.20289; Yin DX, 2023, TOURISM MANAGE, V97, DOI 10.1016/j.tourman.2023.104745; Zhang BH, 2023, INT J HUM-COMPUT INT, V39, P1887, DOI 10.1080/10447318.2022.2124345; Zhang JB, 2024, TOURISM MANAGE, V100, DOI 10.1016/j.tourman.2023.104835	70	0	0	5	5	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1368-3500	1747-7603		CURR ISSUES TOUR	Curr. Issues Tour.	2024 MAY 22	2024										10.1080/13683500.2024.2353872	http://dx.doi.org/10.1080/13683500.2024.2353872		MAY 2024	19	Hospitality, Leisure, Sport & Tourism	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	RO5X0					2024-07-03	WOS:001228627700001
J	Landman, R; Healey, SP; Loprinzo, V; Kochendoerfer, U; Winnier, AR; Henstock, P; Lin, WY; Chen, AQ; Rajendran, A; Penshanwar, S; Khan, S; Madhavan, S				Landman, Rogier; Healey, Sean P.; Loprinzo, Vittorio; Kochendoerfer, Ulrike; Winnier, Angela Russell; Henstock, Peter, V; Lin, Wenyi; Chen, Aqiu; Rajendran, Arthi; Penshanwar, Sushant; Khan, Sheraz; Madhavan, Subha			Using large language models for safety-related table summarization in clinical study reports	JAMIA OPEN			English	Article						generative artificial intelligence; natural language processing; large language models; GPT-3.5; regulatory documents; clinical trials; text summarization		Objectives The generation of structured documents for clinical trials is a promising application of large language models (LLMs). We share opportunities, insights, and challenges from a competitive challenge that used LLMs for automating clinical trial documentation.Materials and Methods As part of a challenge initiated by Pfizer (organizer), several teams (participant) created a pilot for generating summaries of safety tables for clinical study reports (CSRs). Our evaluation framework used automated metrics and expert reviews to assess the quality of AI-generated documents.Results The comparative analysis revealed differences in performance across solutions, particularly in factual accuracy and lean writing. Most participants employed prompt engineering with generative pre-trained transformer (GPT) models.Discussion We discuss areas for improvement, including better ingestion of tables, addition of context and fine-tuning.Conclusion The challenge results demonstrate the potential of LLMs in automating table summarization in CSRs while also revealing the importance of human involvement and continued research to optimize this technology. Large language models (LLMs) have shown promise in automating the creation of structured documents for clinical trials. In a recent competition organized by Pfizer, teams developed a pilot program to generate summaries of safety tables for clinical study reports (CSRs) using LLMs. They evaluated the quality of the AI-generated documents using automated metrics and expert reviews.The analysis revealed differences in performance among the solutions, particularly in terms of factual accuracy and concise writing. Most participants used a model called generative pre-trained transformer (GPT) with prompt engineering. Areas for improvement were identified, such as better handling of tables, adding context, and fine-tuning the models.The challenge results demonstrated the potential of LLMs in automating the summarization of tables in CSRs. However, the study also emphasized the importance of human involvement and ongoing research to optimize this technology. Creating CSRs is a time-consuming process, and one of the challenges is extracting relevant information from tables. It is important to include additional information and consider connections across different tables. Continued research will be done to address these issues.	[Landman, Rogier; Healey, Sean P.; Loprinzo, Vittorio; Kochendoerfer, Ulrike; Winnier, Angela Russell; Henstock, Peter, V; Lin, Wenyi; Chen, Aqiu; Rajendran, Arthi; Penshanwar, Sushant; Khan, Sheraz; Madhavan, Subha] Pfizer Res & Dev, New York, NY 10001 USA; [Madhavan, Subha] 66 Hudson Blvd E, New York, NY 10001 USA	Pfizer	Madhavan, S (corresponding author), 66 Hudson Blvd E, New York, NY 10001 USA.	subha.madhavan@pfizer.com			Pfizer Inc.	Pfizer Inc.(Pfizer)	This work was supported by Pfizer Inc.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agarwal O, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P3554; [Anonymous], Pfizer's Breakthrough Change Accelerator: CSR.Gen; [Anonymous], 1996, ICH E3; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Bakker M.A., 2022, Advances in Neural Information Processing Systems, V35, P38176; Bhardwaj Payal, 2017, Perspect Clin Res, V8, P113, DOI 10.4103/picr.PICR_11_17; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Casper S., 2023, Transact Mach Learn Res, P2835; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chung HW, 2024, J MACH LEARN RES, V25; Douglas S., 1995, P 4 ANN S DOC AN INF, P535; Fei H, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbaa110; Fichtel L., 2021, 3 C AUT KNOWL BAS CO; Fu JL, 2023, Arxiv, DOI arXiv:2302.04166; Getz KA, 2018, THER INNOV REGUL SCI, V52, P22, DOI 10.1177/2168479017713039; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Gomaa W.H., 2013, international journal of Computer Applications, V68, P13, DOI 10.5120/11638-7118; Gong Heng, 2020, P 28 INT C COMPUTATI, P1978; Guerreiro NM, 2023, T ASSOC COMPUT LING, V11, P1500, DOI 10.1162/tacl_a_00615; Huang A., 2008, P 6 NZ COMP SCI RES; Johnson D, 2023, PREPRINT, DOI DOI 10.21203/RS.3.RS-2566942/V1; Kojima T., Adv Neural Inf Process Syst, P22213; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102320; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Lin JC, 2023, EYE, V37, P3694, DOI 10.1038/s41433-023-02564-2; Liu Y., 2023, P 2023 C EMPIRICAL M, P2511; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Taloni A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-45837-2; Tinn R, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100729; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaswani A, 2017, ADV NEUR IN, V30; Wang YN, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2955; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Wei J, 2022, Trans. Mach. Learn. Res.; Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yuntian Deng, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P894, DOI 10.1109/ICDAR.2019.00148; Zhu YQ, 2024, Arxiv, DOI arXiv:2305.13168	41	0	0	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND		2574-2531		JAMIA OPEN	JAMIA Open	APR 8	2024	7	2							ooae043	10.1093/jamiaopen/ooae043	http://dx.doi.org/10.1093/jamiaopen/ooae043			6	Health Care Sciences & Services; Medical Informatics	Emerging Sources Citation Index (ESCI)	Health Care Sciences & Services; Medical Informatics	SK4U0	38818116	gold, Green Accepted			2024-07-03	WOS:001234341400002
C	Mani, SK; Zhou, YJ; Hsieh, K; Segarra, S; Eberl, T; Azulai, E; Frizler, I; Chandra, R; Kandula, S			ACM	Mani, Sathiya Kumaran; Zhou, Yajie; Hsieh, Kevin; Segarra, Santiago; Eberl, Trevor; Azulai, Eliran; Frizler, Ido; Chandra, Ranveer; Kandula, Srikanth			Enhancing Network Management Using Code Generated by Large Language Models	PROCEEDINGS OF THE 22ND ACM WORKSHOP ON HOT TOPICS IN NETWORKS, HOTNETS 2023			English	Proceedings Paper	22nd ACM Workshop on Hot Topics in Networks (HotNets)	NOV 28-29, 2023	Cambridge, MA	Assoc Comp Machinery, ACM SIGCOMM		Network management; Large language model; Program synthesis; Natural language processing; Graph manipulation; Communication graphs; Network lifecycle management	NATURAL-LANGUAGE	Analyzing network topologies and communication graphs is essential in modern network management. However, the lack of a cohesive approach results in a steep learning curve, increased errors, and inefficiencies. In this paper, we present a novel approach that enables natural-language-based network management experiences, leveraging large language models (LLMs) to generate task-specific code from natural language queries. This method addresses the challenges of explainability, scalability, and privacy by allowing network operators to inspect the generated code, removing the need to share network data with LLMs, and focusing on application-specific requests combined with program synthesis techniques. We develop and evaluate a prototype system using benchmark applications, demonstrating high accuracy, cost-effectiveness, and potential for further improvements using complementary program synthesis techniques.	[Mani, Sathiya Kumaran; Zhou, Yajie; Hsieh, Kevin; Segarra, Santiago; Eberl, Trevor; Azulai, Eliran; Frizler, Ido; Chandra, Ranveer; Kandula, Srikanth] Microsoft, Bangalore, Karnataka, India; [Zhou, Yajie] Univ Maryland, College Pk, MD 20742 USA; [Segarra, Santiago] Rice Univ, Houston, TX 77251 USA	University System of Maryland; University of Maryland College Park; Rice University	Mani, SK (corresponding author), Microsoft, Bangalore, Karnataka, India.			Hsieh, Kevin/0000-0003-4154-4525				Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], NumFOCUS; [Anonymous], 2018, General Data Protection Regulation; [Anonymous], 2017, P 5 INT C LEARN REPR; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Backus John W., 1957, 1957 WEST JOINT COMP; Beckett R, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P155, DOI 10.1145/3098822.3098834; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen A, 2024, Arxiv, DOI arXiv:2303.16749; Chen M., 2021, arXiv; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Date Chris J, 1989, A Guide to the SQL Standard; Do Quoc Do Quoc., 2011, P S INF COMM TECHN; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Fogel Ari, 2015, 12 USENIX S NETWORKE; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Glatz E, 2014, COMPUTING, V96, P27, DOI 10.1007/s00607-013-0282-8; Google, MALT example models.; Google, Google Bard; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gulwani S, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P317, DOI 10.1145/1926385.1926423; Gupta A, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P357, DOI 10.1145/3230543.3230555; Iliofotou M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P315; Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089; Kandula Srikanth., 2005, P 1 ANN ACM WORKSH M; Kim H, 2020, PROC VLDB ENDOW, V13, P1737, DOI 10.14778/3401960.3401970; Lee S, 2014, COMPUT NETW, V65, P84, DOI 10.1016/j.comnet.2014.03.007; Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Microsoft, A guidance language for controlling large language models; Microsoft, Azure OpenAI Service-Advanced Language Models; Microsoft, Introducing GitHub Copilot X.; Mogul Jeffrey C, 2020, USENIX S NETWORKED S; NetworkX Developers, NetworkX: Network Analysis in Python.; Ni AS, 2023, Arxiv, DOI arXiv:2302.08468; OpenAI, Openai models; OpenAI, Introducing ChatGPT; OpenAI, ChatGPT plugins; OpenAI, Code interpreter.; OpenAI, 2023, GPT-4 Technical Report; Roy A, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P595; Shi Freda, 2022, P C EMP METH NAT LAN; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Sun RX, 2024, Arxiv, DOI arXiv:2306.00739; Tahaei H, 2020, J NETW COMPUT APPL, V154, DOI 10.1016/j.jnca.2020.102538; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trummer I, 2022, PROC VLDB ENDOW, V15, P2921, DOI 10.14778/3551793.3551841; Wei Jason, 2022, ADV NEURAL INFORM PR; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; Zhang Z., 2022, arXiv; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou Y, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P76, DOI 10.1145/3387514.3406214	60	1	1	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0415-4				2023							196	204		10.1145/3626111.3628183	http://dx.doi.org/10.1145/3626111.3628183			9	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TD		Green Submitted			2024-07-03	WOS:001124843800026
C	Nguyen, M; Kishan, KC; Nguyen, T; Chadha, A; Vu, T		Koutra, D; Plant, C; Rodriguez, MG; Baralis, E; Bonchi, F		Minh Nguyen; Kishan, K. C.; Toan Nguyen; Chadha, Ankit; Thuy Vu			Efficient Fine-Tuning Large Language Models for Knowledge-Aware Response Planning	MACHINE LEARNING AND KNOWLEDGE DISCOVERY IN DATABASES: RESEARCH TRACK, ECML PKDD 2023, PT II	Lecture Notes in Artificial Intelligence		English	Proceedings Paper	European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)	SEP 18-22, 2023	Turin, ITALY	CENTAI, Politecnico Torino, AFC Digital Hub, ASML, ThermoFisher Sci, Volkswagen Grp, AstraZeneca, CRITEO, Google, Mercari, Bosch, KNIME, SoBigData, Two Sigma, SIG Susquehanna		Knowledge-Aware Response Planning; Question Answering; Large Language Models; Fine-tuning		Large Language Models (LLMs) have shown impressive emergent language capabilities, especially in applications with high ambiguity, such as language reasoning and knowledge consolidation. However, previous work explores the use of LLMs for acquiring information using either parametric or external knowledge, which might lead to serious issues such as hallucination. Toward solving these issues, we present a novel approach of knowledge-aware response planning (KARP) and propose a novel framework that employs (i) a knowledge retriever to obtain relevant information from web documents or databases for a given user query, and (ii) a robust fine-tuning strategy for LLMs to exploit the retrieved external knowledge for planning a final response. Experimental results show that our proposed framework can provide natural, concise answers for open-domain questions with high accuracy.	[Minh Nguyen] Univ Oregon, Dept Comp Sci, Eugene, OR USA; [Kishan, K. C.; Toan Nguyen; Chadha, Ankit; Thuy Vu] Amazon Alexa AI, Palo Alto, CA 94301 USA	University of Oregon	Vu, T (corresponding author), Amazon Alexa AI, Palo Alto, CA 94301 USA.	minhnv@cs.uoregon.edu; ckshan@amazon.com; amztoan@amazon.com; ankitrc@amazon.com; thuyvu@amazon.com	Nguyen, Minh/KHW-4288-2024					[Anonymous], 2013, P 2013 C EMPIRICAL M; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bao J., 2016, COLING 2016 26 INT C, P2503; Bao JW, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P967; Bird S., 2009, NATURAL LANGUAGE PRO; Callison-Burch C, 2006, 11 C EUR CHAPT ASS C; Chen D., 2017, arXiv; Chen D., 2020, P 58 ANN M ASS COMPU, V2020, P34; Clark P, 2016, AAAI CONF ARTIF INTE, P2580; Culuri M., 2013, Adv. Neural Inform. Processing Systems, V26, P1; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; FitzGerald J.G.M., 2022, KDD 2022; Gabburo Matteo, 2022, P 2022 C EMP METH NA, P9481; Garg S, 2020, AAAI CONF ARTIF INTE, V34, P7780; Gururangan S., 2020, P 58 ANN M ASS COMPU, P1, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]; Hermann KM, 2015, ADV NEUR IN, V28; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Hsu CC, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4276; Izacard G, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P874; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang Z., 2022, Proceedings of the 29th International Conference on Computational Linguistics, P1765; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Khashabi D, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1896; Kipf T.N., 2017, P INT C LEARN REPR, P1, DOI DOI 10.48550/ARXIV.1609.02907; Lauriola Ivano, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12656), P298, DOI 10.1007/978-3-030-72113-8_20; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis Mike, 2019, INT C LEARNING REPRE; Lin B., 2022, Findings of the Association for Computational Linguistics: EMNLP 2022, P7339; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1641; Liu XD, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4487; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu YJ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2795; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Monge G., 1781, Memoire sur la theorie des deblais et des remblais, P666; Muller Benjamin, 2022, P 2 C AS PAC CHAPT A, V1, P337; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nguyen T., 2016, MS MARCO: A Human Generated MAchine Reading COmprehension Dataset; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]; Raunak V, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1172; Rebuffel C., 2021, arXiv; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Roller S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P300; Saxena A, 2021, P 59 ANN M ASS COMPU, V1, P6663, DOI [DOI 10.18653/V1/2021.ACL-LONG.520, 10.18653/v1/2021.acl-long.520]; Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P373, DOI 10.1145/2766462.2767738; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; SINKHORN R, 1967, PAC J MATH, V21, P343, DOI 10.2140/pjm.1967.21.343; Soltan Saleh, 2022, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang CJ, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3544; Wang WH, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P189, DOI 10.18653/v1/P17-1018; Wang Y., 2022, P 2022 C EMP METH NA, P5085; Wei J, 2022, Trans. Mach. Learn. Res.; Weston J, 2015, Arxiv, DOI [arXiv:1502.05698, 10.48550/arXiv.1502.05698]; Wiseman S., 2016, P 2016 C EMNLP AUST; Xiao YJ, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P2734; Xu JJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1618; Yan H., 2021, P 59 ANN M ASS COMPU, P5808; Yang W, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P72; Yang Y., 2015, P 2015 C EMPIRICAL M, P2013, DOI [DOI 10.18653/V1, 10.18653/v1/D15-1237, 10.18653/v1/d15-1237, DOI 10.18653/V1/D15-1237]; Yoon S, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2093, DOI 10.1145/3357384.3358148; Zhang J., 2020, PMLR, P11328; Zhang T., 2020, INT C LEARNING REPRE; Zhang ZY, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4707, DOI 10.1145/3511808.3557678; Zhao Z, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2237; Zhou CT, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P1393	71	1	1	4	4	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	2945-9133	1611-3349	978-3-031-43414-3; 978-3-031-43415-0	LECT NOTES ARTIF INT			2023	14170						593	611		10.1007/978-3-031-43415-0_35	http://dx.doi.org/10.1007/978-3-031-43415-0_35			19	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WA					2024-07-03	WOS:001156138300035
C	Laato, S; Morschheuser, B; Hamari, J; Björne, J		Chang, M; Chen, NS; Kuo, R; Rudolph, G; Sampson, DG; Tlili, A		Laato, Samuli; Morschheuser, Benedikt; Hamari, Juho; Bjorne, Jari			AI-assisted Learning with ChatGPT and Large Language Models: Implications for Higher Education	2023 IEEE INTERNATIONAL CONFERENCE ON ADVANCED LEARNING TECHNOLOGIES, ICALT	IEEE International Conference on Advanced Learning Technologies		English	Proceedings Paper	23rd IEEE International Conference on Advanced Learning Technologies (ICALT)	JUL 10-13, 2023	Orem, UT	IEEE, IEEE Comp Soc, IEEE Tech Community Learning Technol		ChatGPT; Bard; GPT-4; generative language models; large language models; higher education; learning		The recent progress in generative AI models, particularly large language models (LLMs), has brought about a transformation in the field of education. Conversational LLM services, such as Google's Bard and OpenAI's ChatGPT, offer students access to many abilities such as summarization and generation of text and code, and on-demand replies to questions on expert topics. In this paper, we observe ChatGPT to explore how LLM services impact learning and instruction in higher education. First, we mapped the capabilities of the system by reviewing the grey literature on ChatGPT and using the system ourselves for two months. Second, we selected a Bachelor level computer science curriculum from a Finnish university, and examined the impact of ChatGPT on the offered courses. As an outcome of this study, we highlight 13 implications for students' learning in higher education, and discuss the contemporary future of AI-assisted learning in universities and beyond.	[Laato, Samuli; Hamari, Juho] Tampere Univ, Gamificat Grp, Tampere, Finland; [Morschheuser, Benedikt] FAU Erlangen Nurnberg, Inst Informat Syst, Nurnberg, Germany; [Bjorne, Jari] Univ Turku, Dept Comp, Turku, Finland	Tampere University; University of Erlangen Nuremberg; University of Turku	Laato, S (corresponding author), Tampere Univ, Gamificat Grp, Tampere, Finland.	samuli.laato@tuni.fi; benedikt.morschheuser@fau.de; juho.hamari@tuni.fi; jari.bjorne@utu.fi		Laato, Samuli/0000-0003-4285-0073; Morschheuser, Benedikt/0000-0002-7665-8971				Campbell M, 2002, ARTIF INTELL, V134, P57, DOI 10.1016/S0004-3702(01)00129-1; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hu K., ChatGPT sets record for fastest-growing user base-analyst note; Isaac I, Is chat gpt bad business for stack overflow?; Jant EA, 2014, CHILD DEV, V85, P2029, DOI 10.1111/cdev.12252; Jones M, 2015, ASSESS EVAL HIGH EDU, V40, P712, DOI 10.1080/02602938.2014.950553; Kasneci E., 2023, ChatGPT for good? On opportunities and challenges of large language models for education; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Liang H, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-017-0993-1; Marr B., 2023, How chatgpt and natural language technology might affect your job if you are a computer programmer; openai, ChatGPT: Optimizing language models for dialogue; Pichai S., 2023, IMPORTANT NEXT STEP; Rambocas M, 2018, J RES INTERACT MARK, V12, P146, DOI 10.1108/JRIM-05-2017-0030; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; T. I. Express, What happens when chatgpt has to solve a basic math problem? check out its response; Thorbecke C., Google's ai chatbot bard had an inaccurate response in public demo; U. of Turku,, Study guide of information and communication technology bachelor degree 2022-2024; Vaswani A, 2017, ADV NEUR IN, V30; Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6	21	3	3	65	101	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2161-3761		979-8-3503-0054-3	IEEE INT CONF ADV LE			2023							226	230		10.1109/ICALT58122.2023.00072	http://dx.doi.org/10.1109/ICALT58122.2023.00072			5	Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW0CX					2024-07-03	WOS:001094548800066
C	Petridis, S; Diakopoulos, N; Crowston, K; Hansen, M; Henderson, K; Jastrzebski, S; Nickerson, JV; Chilton, LB			ACM	Petridis, Savvas; Diakopoulos, Nicholas; Crowston, Kevin; Hansen, Mark; Henderson, Keren; Jastrzebski, Stan; Nickerson, Jefrey V.; Chilton, Lydia B.			AngleKindling: Supporting Journalistic Angle Ideation with Large Language Models	PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023			English	Proceedings Paper	CHI conference on Human Factors in Computing Systems (CHI)	APR 23-28, 2023	Hamburg, GERMANY	Assoc Comp Machinery, ACM SIGCHI, Google, Siemens, Bloomberg		Journalism; Brainstorming; Ideation; Large Language Models; Generative AI		News media often leverage documents to find ideas for stories, while being critical of the frames and narratives present. Developing angles from a document such as a press release is a cognitively taxing process, in which journalists critically examine the implicit meaning of its claims. Informed by interviews with journalists, we developed AngleKindling, an interactive tool which employs the common sense reasoning of large language models to help journalists explore angles for reporting on a press release. In a study with 12 professional journalists, we show that participants found AngleKindling significantly more helpful and less mentally demanding to use for brainstorming ideas, compared to a prior journalistic angle ideation tool. AngleKindling helped journalists deeply engage with the press release and recognize angles that were useful for multiple types of stories. From our findings, we discuss how to help journalists customize and identify promising angles, and extending AngleKindling to other knowledge-work domains.	[Petridis, Savvas; Hansen, Mark; Chilton, Lydia B.] Columbia Univ, New York, NY 10027 USA; [Diakopoulos, Nicholas] Northwestern Univ, Evanston, IL USA; [Crowston, Kevin; Henderson, Keren; Jastrzebski, Stan] Syracuse Univ, Syracuse, NY USA; [Nickerson, Jefrey V.] Stevens Inst Technol, Hoboken, NJ USA	Columbia University; Northwestern University; Syracuse University; Stevens Institute of Technology	Petridis, S (corresponding author), Columbia Univ, New York, NY 10027 USA.	sdp2137@columbia.edu; nad@northwestern.edu; crowston@g.syr.edu; mh3287@columbia.edu; khenders@syr.edu; sjastrze@syr.edu; jnickers@stevens.edu; chilton@cs.columbia.edu	; Crowston, Kevin/C-6068-2008	Jastrzebski, Stan/0000-0001-7220-529X; Crowston, Kevin/0000-0003-1996-3600; Henderson, Keren/0000-0002-4770-5038; hansen, mark/0000-0001-9210-6387; Diakopoulos, Nicholas/0000-0001-5005-6123; Petridis, Savvas/0000-0002-4944-8477				Alhindi Tariq, 2018, P 1 WORKSHOP FACT EX, P85, DOI [DOI 10.18653/V1/W18-5513, 10.18653/v1/W18-5513,eprint:https://aclanthology.org/W18-5513.pdf]; Andolina S., 2015, Proceedings of the 2015 ACM SIGCHI Conference on Creativity and Cognition, ser. CC'15, Glasgow, P103, DOI DOI 10.1145/2757226.2757252; Andolina S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P106, DOI 10.1145/3059454.3059477; August Tal, 2022, PAPER PLAIN MAKING M, DOI [10. 48550/ARXIV.2203.00130, DOI 10.48550/ARXIV.2203.00130]; BAE S, 2020, SPINNERET AIDING CRE, DOI DOI 10.1145/3313831.3376746; Bentley F, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300820; Bommasani Rishi., On the Opportunities and Risks of Foundation Models, P2021, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Boumans J, 2018, JOURNALISM STUD, V19, P2264, DOI 10.1080/1461670X.2017.1338154; Brehmer M, 2014, IEEE T VIS COMPUT GR, V20, P2271, DOI 10.1109/TVCG.2014.2346431; Chan J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P93, DOI 10.1145/3059454.3059455; Chan J, 2016, PROCEEDINGS OF THE 19TH ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING COMPANION, P13, DOI 10.1145/2818052.2874313; Chang M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174025; Chung JJY, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519873; Cohen S, 2011, COMMUN ACM, V54, P66, DOI 10.1145/2001269.2001288; Diakopoulos Nicholas, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479550; Diakopoulos N., 2010, 2010 Proceedings of IEEE Symposium on Visual Analytics Science and Technology (VAST 2010), P115, DOI 10.1109/VAST.2010.5652922; Diakopoulos N. A., 2012, P SIGCHI C HUM FACT, P2451; Diakopoulos N, 2020, DIGIT JOURNAL, V8, P945, DOI 10.1080/21670811.2020.1736946; Diakopoulos N, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P799; Entman Robert M, 1993, MCQUAILS READER MASS, V390, P397; Estelle Smith C., 2020, DISSEMINATING RES NE, P1, DOI [10.1145/3313831.3376744, DOI 10.1145/3313831.3376744]; Flintham M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173950; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Gero KI, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300526; Hassan N, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1803, DOI 10.1145/3097983.3098131; Huang GP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P119, DOI 10.1145/3059454.3059481; Jiang E, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3503564; Jiang E, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501870; Kang YW, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445325; Kita Y, 2018, ACM INT CONF PR SER, DOI 10.1145/3174910.3174937; Koh HY, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3545176; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li H, 2022, COMMUN ACM, V65, P56, DOI 10.1145/3490443; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Liu V, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545621; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Liu XM, 2017, IEEE INT CONF BIG DA, P1483, DOI 10.1109/BigData.2017.8258082; Louie R, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376739; Maiden N, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174049; Marcus A, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P227; Oh C., 2020, Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, P1, DOI [10.1145/3313831.3376811, DOI 10.1145/3313831.3376811]; Ornebring H, 2010, J MASS COMMUN Q, V87, P682; Osone H, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3450391; Petridis Savvas, 2021, 34 ANN ACM S US INT, P385, DOI DOI 10.1145/3472749.3474757; Reich Z., 2006, Journalism Studies, V7, P497, DOI DOI 10.1080/14616700600757928; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Shakeri H, 2021, CONFERENCE COMPANION PUBLICATION OF THE 2021 COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, CSCW 2021 COMPANION, P163, DOI 10.1145/3462204.3481771; Sherwood Merryn, 2019, PUBLIC RELATIONS JOU, DOI [10.1093/acrefore/9780190228613.013. 866, DOI 10.1093/ACREFORE/9780190228613.013.866]; Shi Y, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P594, DOI 10.1145/2998181.2998208; Siangliulue P, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P609, DOI 10.1145/2984511.2984578; Siangliulue P, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW'15), P937, DOI 10.1145/2675133.2675239; Stasko J, 2008, INFORM VISUAL, V7, P118, DOI 10.1057/palgrave.ivs.9500180; Thurman N., 2019, The handbook of journalism studies, P180; Trielli D, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300683; Wang HC, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P103; Wang YX, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445266; Weaver DH, 2019, J MASS COMMUN Q, V96, P101, DOI 10.1177/1077699018778242; Wu TS, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519729; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Xia CL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P167, DOI 10.1145/2567948.2577020; Xiaotong Xu, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3479496; Yu LX, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1393; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105	64	5	5	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9421-5				2023										10.1145/3544548.3580907	http://dx.doi.org/10.1145/3544548.3580907			16	Computer Science, Information Systems; Computer Science, Theory & Methods; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BV4OO					2024-07-03	WOS:001037809504005
J	Acerbi, A; Stubbersfield, JM				Acerbi, Alberto; Stubbersfield, Joseph M.			Large language models show human- like content biases in transmission chain experiments	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						cultural evolution; large language models; ChatGPT; content biases; transmission chains	STEREOTYPES	As the use of large language models (LLMs) grows, it is important to examine whether they exhibit biases in their output. Research in cultural evolution, using transmission chain experiments, demonstrates that humans have biases to attend to, remember, and transmit some types of content over others. Here, in five preregistered experiments using material from previous studies with human participants, we use the same, transmission chain -like methodology, and find that the LLM ChatGPT-3 shows biases analogous to humans for content that is gender- stereotype- consistent, social, negative, threat- related, and biologically counterintuitive, over other content. The presence of these biases in LLM output suggests that such content is widespread in its training data and could have consequential downstream effects, by magnifying preexisting human tendencies for cognitively appealing and not necessarily informative, or valuable, content.	[Acerbi, Alberto] Univ Trento, Dept Sociol & Social Res, I-38122 Trento, Italy; [Stubbersfield, Joseph M.] Univ Winchester, Dept Psychol, Winchester SO22 4NR, England	University of Trento; University of Winchester	Acerbi, A (corresponding author), Univ Trento, Dept Sociol & Social Res, I-38122 Trento, Italy.	alberto.acerbi@unitn.it	Stubbersfield, Joe/IVV-7073-2023	Stubbersfield, Joe/0000-0001-8966-4679; Acerbi, Alberto/0000-0001-5827-8003	University of Winchester Research and Innovation funds	University of Winchester Research and Innovation funds	We would like to thank Fabiana Lombardi for her work as an independent coder, and two anonymous reviewers for comments and suggestions. J.M.S. received internal funding from the University of Winchester Research and Innovation funds for this research.	Acerbi A., chatGPT transmission chains. chatGPT transmission chains; Acerbi A, 2019, PALGR COMMUN, V5, DOI 10.1057/s41599-019-0224-y; Bartlett F.C., 1932, Remembering: A study in experimental and social psychology; Bates D, 2015, J STAT SOFTW, V67, P1, DOI 10.18637/jss.v067.i01; Bebbington K, 2017, EVOL HUM BEHAV, V38, P92, DOI 10.1016/j.evolhumbehav.2016.07.004; Berl REW, 2021, EVOL HUM SCI, V3, DOI 10.1017/ehs.2021.37; Blaine T, 2018, EVOL HUM BEHAV, V39, P67, DOI 10.1016/j.evolhumbehav.2017.10.001; Boyd R, 1985, CULTURE EVOLUTIONARY; Brand CO, 2019, EVOL HUM SCI, V1, DOI 10.1017/ehs.2019.11; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buruk O, 2023, Arxiv, DOI [arXiv:2304.11079, 10.48550/arXiv.2304.11079, DOI 10.48550/ARXIV.2304.11079]; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Chen G, 2019, J ADVERTISING, V48, P347, DOI 10.1080/00913367.2019.1654421; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; Danks D, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4691; Goldenberg A, 2020, TRENDS COGN SCI, V24, P316, DOI 10.1016/j.tics.2020.01.009; Kashima Y, 2000, PERS SOC PSYCHOL B, V26, P594, DOI 10.1177/0146167200267007; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Lyons A, 2006, ASIAN J SOC PSYCHOL, V9, P59, DOI 10.1111/j.1467-839X.2006.00184.x; Mesoudi A, 2008, PHILOS T R SOC B, V363, P3489, DOI 10.1098/rstb.2008.0129; Mesoudi A, 2006, BRIT J PSYCHOL, V97, P405, DOI 10.1348/000712605X85871; Morin O, 2017, COGNITION EMOTION, V31, P1663, DOI 10.1080/02699931.2016.1260528; Petridis S, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2023, DOI 10.1145/3544548.3580907; Stubbersfield JM., 2022, Cult. Ev, V19, P41, DOI [10.1556/2055.2022.00024, DOI 10.1556/2055.2022.00024]; Stubbersfield Joseph M., 2017, Evolutionary Studies in Imaginary Culture, V1, P121, DOI [DOI 10.26613/ESIC.1.1.20, 10.26613/esic.1.1.20]; Thompson B, 2022, SCIENCE, V376, P95, DOI 10.1126/science.abn0915	27	6	6	23	25	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	OCT 31	2023	120	44							e2313790120	10.1073/pnas.2313790120	http://dx.doi.org/10.1073/pnas.2313790120			5	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	CS1C9	37883432	Green Submitted, hybrid			2024-07-03	WOS:001127129700010
C	Poon, H; Naumann, T; Zhang, S; Hernández, JG			ACM	Poon, Hoifung; Naumann, Tristan; Zhang, Sheng; Hernandez, Javier Gonzalez			Precision Health in the Age of Large Language Models	PROCEEDINGS OF THE 29TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2023			English	Proceedings Paper	29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)	AUG 06-10, 2023	Long Beach, CA	Assoc Comp Machinery, ACM SIGKDD, ACM SIGMOD				Medicine today is imprecise. Among the top 20 drugs in the U.S., up to 80% of patients are non-responders. The goal of precision health is to provide the right intervention for the right people at the right time. The key to realize this dream is to develop a data-driven, learning system that can instantly incorporate new health information to optimize care delivery and accelerate biomedical discovery. In reality, however, the health ecosystem is mired in overwhelming unstructured data and excruciating manual processing. For example, in cancer, standard of care often fails, and clinical trials are the last hope. Yet less than 3% of patients can find a matching trial, whereas 40% of trial failures simply stem from insufficient recruitment. Discovery is painfully slow as a new drug may take billions of dollars and over a decade to develop. In this tutorial, we will explore how large language models (LLMs) can serve as a universal structuring tool to democratize biomedical knowledge work and usher in an intelligence revolution in precision health. We first review background for precision health and give a broad overview of the AI revolution that culminated in the development of large language models, highlighting key technical innovations and prominent trends such as consolidation of AI methods across modalities. We then give an in-depth review of biomedical LLMs and precision health applications, with a particular focus on scaling real-world evidence generation and drug discovery. To conclude, we discuss key technical challenges (e.g., bias, hallucination, cost), societal ramifications (e.g., privacy, regulation), as well as exciting research frontiers such as prompt programming, knowledge distillation, multi-modal learning, causal discovery.	[Poon, Hoifung; Naumann, Tristan; Zhang, Sheng] Microsoft Res, Redmond, WA USA; [Hernandez, Javier Gonzalez] Microsoft Res, Cambridge, England	Microsoft; Microsoft	Poon, H (corresponding author), Microsoft Res, Redmond, WA USA.	hoifung@microsoft.com; tristan@microsoft.com; zhang.sheng@microsoft.com; gonzalez.javier@microsoft.com		Naumann, Tristan/0000-0003-2150-1747				[Anonymous], 2023, ARXIV220311171CSCL; [Anonymous], 2023, ARXIV230312712CSCL; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Li MM, 2022, NAT BIOMED ENG, V6, P1353, DOI 10.1038/s41551-022-00942-x; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mialon Gregoire, 2023, ARXIV230207842CSCL; Nori H., 2023, Capabilities of gpt-4 on medical challenge problems; OpenAI, 2023, Gpt-4 Technical Report; Ouyang Long, 2022, ARXIV220302155CSCL; Singhal Karan, 2022, ARXIV221213138CSCL; Taylor Ross, 2022, ARXIV221109085CSCL; Wang Yizhong, 2022, ARXIV221210560CSCL; Wei Jason, 2023, ARXIV220111903CSCL; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Zhang Sheng, 2023, ARXIV230300915CSCV; Zhou Yongchao, 2023, ARXIV221101910CSLG	16	1	1	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0103-0				2023							5825	5826		10.1145/3580305.3599568	http://dx.doi.org/10.1145/3580305.3599568			2	Computer Science, Information Systems; Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LZ					2024-07-03	WOS:001118896305096
J	Linegar, M; Kocielnik, R; Alvarez, RM				Linegar, Mitchell; Kocielnik, Rafal; Alvarez, R. Michael			Large language models and political science	FRONTIERS IN POLITICAL SCIENCE			English	Review						Large Language Models (LLM); ChatGPT; natural language processing; political science; political methodology	BIAS	Large Language Models (LLMs) are a type of artificial intelligence that uses information from very large datasets to model the use of language and generate content. While LLMs like GPT-3 have been used widely in many applications, the recent public release of OpenAI's ChatGPT has opened more debate about the potential uses and abuses of LLMs. In this paper, we provide a brief introduction to LLMs and discuss their potential application in political science and political methodology. We use two examples of LLMs from our recent research to illustrate how LLMs open new areas of research. We conclude with a discussion of how researchers can use LLMs in their work, and issues that researchers need to be aware of regarding using LLMs in political science and political methodology.	[Linegar, Mitchell; Alvarez, R. Michael] CALTECH, Div Humanities & Social Sci, Pasadena, CA 91125 USA; [Kocielnik, Rafal] CALTECH, Comp & Math Sci, Pasadena, CA USA; [Alvarez, R. Michael] CALTECH, Ctr Sci Soc & Publ Policy, Pasadena, CA USA	California Institute of Technology; California Institute of Technology; California Institute of Technology	Linegar, M (corresponding author), CALTECH, Div Humanities & Social Sci, Pasadena, CA 91125 USA.	mlinegar@caltech.edu	Linegar, Mitchell/KHY-6717-2024		The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	We thank the Caltech Center for Science, Society, and Public Policy for supporting our research on the Ethics of AI.r The author(s) declare that no financial support was received for the research, authorship, and/or publication of this article.	Abid A, 2021, NAT MACH INTELL, V3, P461, DOI 10.1038/s42256-021-00359-2; Aher GV, 2023, INT C MACHINE LEARNI, P337; Alammar Jay, 2022, The illustrated Stable Diffusion; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211; Alvarez R. M., 2023, Generative AI and the Future of Elections; Alvarez RM, 2022, PS-POLIT SCI POLIT, V55, P149, DOI 10.1017/S1049096521001062; Bloomberg, 2023, Generative AI Takes Stereotypes and Bias from Bad to Worse; Borji A, 2022, Arxiv, DOI [arXiv:2210.00586, 10.48550/arXiv.2210.00586]; Buolamwini J, 2018, C FAIRNESS ACCOUNTAB, P77; Ceylan B., 2023, Large Language Model Evaluation in 2023: 5 Methods; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chiusano F., 2022, Two Minutes NLP-Perplexity Explained With Simple Probabilities; Chollet F, 2017, Arxiv, DOI [arXiv:1610.02357, 10.48550/arXiv.1610.02357]; Chouldechova A., 2018, C FAIRNESS ACCOUNTAB, P134; Crisan Anamaria, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P427, DOI 10.1145/3531146.3533108; Dayma B., 2021, DALL-E Mini; Delobelle P, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1693; Denton E., 2023, Thirty-seventh Conference on Neural Information Processing Systems; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; ElutherAI, 2023, EleutherAI/lm-Evaluation-Harness: A Framework for Few-Shot Evaluation of Autoregressive Language Models; Feng SB, 2023, Arxiv, DOI [arXiv:2305.08283, 10.48550/arXiv.2305.08283]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gebru T, 2021, COMMUN ACM, V64, P86, DOI 10.1145/3458723; Google, 2022, Fairness: Types of Bias; Gozalo-Brizuela R., 2023, arXiv; Grimmer J., 2013, REPRESENTATIONAL STY; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; Holland S., 2020, DATA PROTECTION PRIV, V12, P1, DOI DOI 10.5040/9781509932771.CH-001; Howard A, 2018, SCI ENG ETHICS, V24, P1521, DOI 10.1007/s11948-017-9975-2; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Huang Y, 2023, Arxiv, DOI [arXiv:2306.11507, DOI 10.48550/ARXIV.2306.11507]; Hugging Face, 2023, Open LLM Leaderboard-a Hugging Face Space by HuggingFaceH4; Hugging Face, 2023, Model Cards; Jingnan H., 2023, How Generative AI May Empower Political Campaigns and Propaganda; Kann C, 2023, FRONT POLIT SCI, V5, DOI 10.3389/fpos.2023.1185633; KING G, 1995, PS, V28, P444, DOI 10.2307/420301; Kocielnik R., 2023, arXiv, DOI [10.48550/arXiv.2302.07371, DOI 10.48550/ARXIV.2302.07371]; Kocielnik R., 2023, Transfer Learning for Natural Language Processing Workshop, P22; Kocielnik R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300641; Lambrecht A, 2019, MANAGE SCI, V65, P2966, DOI 10.1287/mnsc.2018.3093; Laver M, 2000, AM J POLIT SCI, V44, P619, DOI 10.2307/2669268; Li M., 2023, Proceedings of the AAAI Conference on Artificial Intelligence, P13094; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Liang WX, 2023, Arxiv, DOI [arXiv:2304.02819, DOI 10.48550/ARXIV.2304.02819]; Martin GJ, 2017, AM ECON REV, V107, P2565, DOI 10.1257/aer.20160812; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Mendelsohn J., 2023, ACL; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Muennighoff N, 2022, Arxiv, DOI arXiv:2210.07316; Osoba O. A., 2017, An intelligence in our image; Perez E., 2022, arXiv; POOLE KT, 1985, AM J POLIT SCI, V29, P357, DOI 10.2307/2111172; Radford A, 2021, PR MACH LEARN RES, V139; Raji ID, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P429, DOI 10.1145/3306618.3314244; Ramanathan B., 2022, Evaluating Large Language Models (LLMs) with Eleuther AI; Rastogi C, 2023, Arxiv, DOI arXiv:2304.09991; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Santhosh S., 2023, Understanding BLEU and ROUGE Score for NLP Evaluation; Schnabel T, 2016, PR MACH LEARN RES, V48; Srikanth M, 2021, KDD '21: PROCEEDINGS OF THE 27TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3576, DOI 10.1145/3447548.3467171; StabilityAI, 2022, Stable Diffusion v2.1 and DreamStudio Updates; Taori R., 2023, Stanford alpaca: An instruction-following llama model; van der Linden S., 2023, Foolproof: Why Misinformation Infects our Minds and how to Build Immunity; Vartiainen H, 2023, DIGIT CREAT, V34, P1, DOI 10.1080/14626268.2023.2174557; von Werra L., 2023, The Falcon Has Landed in the Hugging Face Ecosystem; Wang AL, 2020, Arxiv, DOI arXiv:1905.00537; West D. M., 2023, Comparing Google Bard with OpenAI's ChatGPT on Political Bias, Facts, and Morality; Xu C, 2023, Arxiv, DOI arXiv:2304.12244; Zhang C, 2023, Arxiv, DOI [arXiv:2304.06488, DOI 10.13140/RG.2.2.24789.70883]; Zhang CS, 2023, Arxiv, DOI arXiv:2303.07909; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	73	0	0	45	59	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2673-3145		FRONT POLIT SCI	Front. Polit. Sci.	OCT 16	2023	5								1257092	10.3389/fpos.2023.1257092	http://dx.doi.org/10.3389/fpos.2023.1257092			12	International Relations; Political Science	Emerging Sources Citation Index (ESCI)	International Relations; Government & Law	W8BR7		gold			2024-07-03	WOS:001093829700001
C	Prasad, N; Boughanem, M; Dkaki, T		Goharian, N; Tonellotto, N; He, Y; Lipani, A; McDonald, G; Macdonald, C; Ounis, I		Prasad, Nishchal; Boughanem, Mohand; Dkaki, Taoufiq			Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents	ADVANCES IN INFORMATION RETRIEVAL, ECIR 2024, PT II	Lecture Notes in Computer Science		English	Proceedings Paper	46th European Conference on Information Retrieval (ECIR)	MAR 24-28, 2024	Glasgow, SCOTLAND	Univ Glasgow, British Comp Soc, Informat Retrieval Specialist Grp		Legal judgment prediction; Long document classification; Multi-stage hierarchical classification framework		Legal judgment prediction suffers from the problem of long case documents exceeding tens of thousands of words, in general, and having a non-uniform structure. Predicting judgments from such documents becomes a challenging task, more so on documents with no structural annotation. We explore the classification of these large legal documents and their lack of structural information with a deep-learning-based hierarchical framework which we call MESc; "Multi-stage Encoder-based Supervised with-clustering"; for judgment prediction. Specifically, we divide a document into parts to extract their embeddings from the last four layers of a custom fine-tuned Large Language Model, and try to approximate their structure through unsupervised clustering. Which we use in another set of transformer encoder layers to learn the inter-chunk representations. We analyze the adaptability of Large Language Models (LLMs) with multi-billion parameters (GPT-Neo, and GPT-J) with the hierarchical framework of MESc and compare them with their standalone performance on legal texts. We also study their intradomain(legal) transfer learning capability and the impact of combining embeddings from their last layers in MESc. We test these methods and their effectiveness with extensive experiments and ablation studies on legal documents from India, the European Union, and the United States with the ILDC dataset and a subset of the LexGLUE dataset. Our approach achieves a minimum total performance gain of approximately 2 points over previous state-of-the-art methods.	[Prasad, Nishchal; Boughanem, Mohand; Dkaki, Taoufiq] Inst Rech Informat Toulouse IRIT, Toulouse, France	Universite de Toulouse; Universite Federale Toulouse Midi-Pyrenees (ComUE); Universite Toulouse III - Paul Sabatier; Institut National Polytechnique de Toulouse; Universite Toulouse 1 Capitole; Universite de Toulouse - Jean Jaures; Centre National de la Recherche Scientifique (CNRS)	Prasad, N; Boughanem, M; Dkaki, T (corresponding author), Inst Rech Informat Toulouse IRIT, Toulouse, France.	Nishchal.Prasad@irit.fr; Mohand.Boughanem@irit.fr; Taoufiq.Dkaki@irit.fr		Prasad, Nishchal/0009-0000-4712-3540	LAWBOT project [ANR-20-CE38-0013]; GENCI-IDRIS [2022-AD011013937]; Agence Nationale de la Recherche (ANR) [ANR-20-CE38-0013] Funding Source: Agence Nationale de la Recherche (ANR)	LAWBOT project; GENCI-IDRIS; Agence Nationale de la Recherche (ANR)(Agence Nationale de la Recherche (ANR))	This work is supported by the LAWBOT project (ANR-20-CE38-0013) and was performed using HPC resources from GENCI-IDRIS (Grant 2022-AD011013937).	Ainslie J, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P268; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Black Sid, 2021, Zenodo; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalkidis I, 2020, M ASS FOR COMPUTATIO; Chalkidis I., 2022, arXiv; Chalkidis I, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4310; Chalkidis I, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4317; Chen HJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6362; Condevaux Charles, 2023, Advances in Knowledge Discovery and Data Mining: 27th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13935), P443, DOI 10.1007/978-3-031-33374-3_35; Cui JY, 2022, Arxiv, DOI arXiv:2204.04859; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Feng Y., 2022, P 31 INT JOINT C ART, P5461, DOI DOI 10.24963/IJCAI.2022/765; Fergadiotis Manos, 2021, P 2021 C N AM CHAPTE, P226, DOI [DOI 10.18653/V1/2021.NAACL-MAIN.22, 10. 18653/v1/2021.naacl-main.22]; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Katju J.M., 2019, Backlog of cases crippling judiciary; Kaufman AR, 2019, POLIT ANAL, V27, P381, DOI 10.1017/pan.2018.59; Kitaev N, 2020, REFORMER EFFICIENT T; Malik V, 2021, Arxiv, DOI [arXiv:2105.13562, 10.48550/arXiv.2105.13562, DOI 10.48550/ARXIV.2105.13562]; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McInnes L, 2017, INT CONF DAT MIN WOR, P33, DOI 10.1109/ICDMW.2017.12; Nallapati R., 2008, P 2008 C EMP METH NA, P438; Paul S, 2022, Arxiv, DOI [arXiv:2209.06049, 10.48550/ARXIV.2209.06049]; Prasad N., 2022, CEUR Workshop Proceedings, V3178; Song YW, 2020, Arxiv, DOI arXiv:2002.04815; Thoppilan Romal, 2022, Lamda: Language models for dialog applications; Touvron H., 2023, Llama: Open and efficient foundation language models; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; Tuggener D, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P1235; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.1093/biomet/34.1-2.28; Xiao CJ, 2018, Arxiv, DOI arXiv:1807.02478; Xu N, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3086; Yang JJ, 2020, Arxiv, DOI arXiv:1911.01940; Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI DOI 10.18653/V1/N16-1174; Yu F., 2022, Legal prompting: teaching a language model to think like a lawyer; Zaheer M, 2020, ADV NEURAL INFORM PR, DOI DOI 10.5555/3495724.3497174; Zhang XX, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5059; Zheng Lucia, 2021, ICAIL '21: Proceedings of the Eighteenth International Conference on Artificial Intelligence and Law, P159, DOI 10.1145/3462757.3466088; Zhong H., 2020, P 58 ANN M ASS COMPU, P5218; Zhong HX, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3540	43	0	0	0	0	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-56059-0; 978-3-031-56060-6	LECT NOTES COMPUT SC			2024	14609						221	237		10.1007/978-3-031-56060-6_15	http://dx.doi.org/10.1007/978-3-031-56060-6_15			17	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9DY		Green Submitted			2024-07-03	WOS:001211832000015
J	Lop, I				Lop, Inigo			Revisiting Challenges and Hazards in Large Language Model Evaluation	PROCESAMIENTO DEL LENGUAJE NATURAL			English	Article						Large language models; evaluation; evaluation challenges and hazards; evaluation dimensions	GENERATION	In the age of large language models, artificial intelligence's goal has evolved to assist humans in unprecedented ways. As LLMs integrate into society, the need for comprehensive evaluations increases. These systems' real-world acceptance depends on their knowledge, reasoning, and argumentation abilities. However, inconsistent standards across domains complicate evaluations, making it hard to compare models and understand their pros and cons. Our study focuses on illuminating the evaluation processes for these models. We examine recent research, tracking current trends to ensure evaluation methods match the field's rapid progress requirements. We analyze key evaluation dimensions, aiming to deeply understand factors affecting models performance. A key aspect of our work is identifying and compiling major performance challenges and hazards in evaluation, an area not extensively explored yet. This approach is necessary for recognizing the potential and limitations of these AI systems in various domains of the evaluation.	[Lop, Inigo] Univ Basque Country UPV EHU, HiTZ Basque Ctr Language Technol, Ixa NLP Grp, Leioa, Spain	University of Basque Country	Lop, I (corresponding author), Univ Basque Country UPV EHU, HiTZ Basque Ctr Language Technol, Ixa NLP Grp, Leioa, Spain.	inigo.lopez@ehu.eus						Aftan Sulaiman, 2023, 2023 20th Learning and Technology Conference (L&T), P161, DOI 10.1109/LT58159.2023.10092289; Aiyappa R, 2023, Arxiv, DOI [arXiv:2303.12767, DOI 10.48550/ARXIV.2303.12767]; [Anonymous], 2013, P 2013 ACM SIGMOD IN, DOI DOI 10.1145/2463676.2463712; Awasthi I, 2021, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTATION TECHNOLOGIES (ICICT 2021), P1310, DOI 10.1109/ICICT50816.2021.9358703; Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Baradaran R, 2022, NAT LANG ENG, V28, P683, DOI 10.1017/S1351324921000395; Baroiu A.-C., 2023, 2023 24 INT C CONTRO, P399, DOI [10.1109/CSCS59211.2023.00069, DOI 10.1109/CSCS59211.2023.00069]; BATES M, 1995, P NATL ACAD SCI USA, V92, P9977, DOI 10.1073/pnas.92.22.9977; Berglund L, 2024, Arxiv, DOI [arXiv:2309.12288, DOI 10.48550/ARXIV.2309.12288]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bouziane A, 2015, PROCEDIA COMPUT SCI, V73, P366, DOI 10.1016/j.procs.2015.12.005; Bradbury J., 2018, JAX: composable transformations of Python+NumPy programs; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buchanan B.G., 1984, Rule based expert systems: The mycin experiments of the stanford heuristic programming project (the addison-wesley series in artificial intelligence); Chang YP, 2023, Arxiv, DOI [arXiv:2307.03109, DOI 10.1145/3641289]; Chen M., 2021, arXiv; Chen YF, 2023, Arxiv, DOI arXiv:2310.02431; Chetnani Y. P., 2023, Ph.D. thesis; Chiang CH, 2023, Arxiv, DOI arXiv:2305.01937; Chollet F, 2019, Arxiv, DOI arXiv:1911.01547; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Clark E, 2023, Arxiv, DOI arXiv:2305.13194; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Costa-jussa, 2022, arXiv, DOI DOI 10.48550/ARXIV.2207.04672; Costantini S, 2002, LECT NOTES ARTIF INT, V2408, P253; Creswell A., 2022, arXiv; de Wynter A, 2023, Arxiv, DOI arXiv:2304.08637; Demarco F., 2023, P 7 WORKSHOP NATURAL; Demetriadis Stavros, 2023, Augmented Intelligence and Intelligent Tutoring Systems: 19th International Conference, ITS 2023, Proceedings. Lecture Notes in Computer Science (13891), P691, DOI 10.1007/978-3-031-32883-1_60; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dong Guanting, 2023, Natural Language Processing and Chinese Computing: 12th National CCF Conference, NLPCC 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14302), P682, DOI 10.1007/978-3-031-44693-1_53; Erdem E, 2022, J ARTIF INTELL RES, V73, P1131; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Fu Y., 2022, How does gpt obtain its ability? tracing emergent abilities of language models to their sources; Gamallo Pablo, 2017, P 4 WORKSH NLP SIM L, P109, DOI DOI 10.18653/V1/W17-1213; Gao J, 2004, ACM Transactions on Asian Language Information Processing, V3, P87; Garg T, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3580494; Ge Song, 2014, Journal of Multimedia, V9, P635, DOI 10.4304/jmm.9.5.635-643; Hadi M.U., 2023, TECHRXIV; Hadi MU, 2023, PREPRINT; Head C., 2023, New Directions for Evaluation, V2023, P33, DOI DOI 10.1002/EV.20556; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Huang D, 2024, Arxiv, DOI [arXiv:2309.14345, 10.48550/arXiv.2309.14345, DOI 10.48550/ARXIV.2309.14345]; Jain N, 2023, Arxiv, DOI arXiv:2306.13651; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jin ZJ, 2024, Arxiv, DOI arXiv:2306.05836; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kejriwal Mayank, 2023, Artificial General Intelligence: 16th International Conference, AGI 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (13921), P167, DOI 10.1007/978-3-031-33469-6_17; Khalfa Jean., 1994, WHAT IS INTELLIGENCE; Khowaja SA, 2024, Arxiv, DOI arXiv:2305.03123; Koh JY, 2023, Arxiv, DOI arXiv:2301.13823; Korb K.B., 2010, Bayesian artificial intelligence, DOI DOI 10.1201/B10391; Kotek Hadas, 2023, CI '23: Proceedings of The ACM Collective Intelligence Conference, P12, DOI 10.1145/3582269.3615599; Lacave C, 2002, KNOWL ENG REV, V17, P107, DOI 10.1017/S026988890200019X; Lai VD, 2023, Arxiv, DOI [arXiv:2304.05613, DOI 10.48550/ARXIV.2304.05613]; Lazarski Eric, 2021, Designs, V5, DOI 10.3390/designs5030042; Lehman J., 2023, Handbook of Evolutionary Machine Learning, P331, DOI 10.1007/978-981-99-3814-8-11; Li J, 2022, arXiv; Li YJ, 2024, Arxiv, DOI arXiv:2308.10149; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Liu FY, 2021, Arxiv, DOI [arXiv:2109.13238, DOI 10.48550/ARXIV.2109.13238]; Ma JY, 2023, Arxiv, DOI arXiv:2310.10322; Mahany A, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12105209; McDonald DD, 2010, CH CRC MACH LEARN PA, P121; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Motger Q, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3527450; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Novikova J, 2017, Arxiv, DOI arXiv:1707.06875; OpenAI R., 2023, Gpt-4 technical report. arxiv 2303.08774; Orrù G, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1199350; Oshikawa R, 2020, Arxiv, DOI arXiv:1811.00770; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng Z., 2023, Proceedings of the ACM on Management of Data, V1, P1; Perez Ethan, 2022, arXiv, DOI DOI 10.48550/ARXIV.2202.03286; Puchert P, 2023, Arxiv, DOI arXiv:2304.00457; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Reiter E, 2018, COMPUT LINGUIST, V44, P393, DOI [10.1162/COLI.a.00322, 10.1162/coli_a_00322]; Rillig MC, 2023, ENVIRON SCI TECHNOL, DOI 10.1021/acs.est.3c01106; Ruder S, 2023, Arxiv, DOI arXiv:2305.11938; Saha T, 2023, PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023, P5290, DOI 10.1145/3583780.3615311; Sainz O, 2023, Arxiv, DOI [arXiv:2310.18018, 10.48550/arXiv.2310.18018, DOI 10.48550/ARXIV.2310.18018]; Sakaguchi K, 2021, COMMUN ACM, V64, P99, DOI 10.1145/3474381; Salloum Said A., 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P61, DOI 10.1007/978-3-030-44289-7_6; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shin J, 2021, J INF PROCESS SYST, V17, P537; Srivastava Aarohi, 2022, arXiv; Storks S, 2020, Arxiv, DOI [arXiv:1904.01172, DOI 10.48550/ARXIV.1904.01172]; Sun Jingyuan, 2020, P INT C COMPUTATIONA, P3569; Tang RX, 2023, Arxiv, DOI arXiv:2303.07205; Tedeschi S, 2023, Arxiv, DOI arXiv:2305.08414; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang AL, 2019, Arxiv, DOI arXiv:1804.07461; Wang A, 2019, ADV NEUR IN, V32; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang Y, 2020, Arxiv, DOI arXiv:2005.06600; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Xu P, 2023, Arxiv, DOI arXiv:2306.09265; Xu XL, 2023, Arxiv, DOI arXiv:2310.13345; Zellers R, 2019, Arxiv, DOI arXiv:1905.07830; Zhai YX, 2023, Arxiv, DOI arXiv:2309.10313; Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zhao WX, 2023, ARXIV; Zhong WJ, 2023, Arxiv, DOI [arXiv:2304.06364, 10.48550/arXiv.2304.06364]; Zhu KJ, 2023, Arxiv, DOI arXiv:2306.04528	114	0	0	4	4	SOC ESPANOLA PROCESAMIENTO LENGUAJE NATURAL-SEPLN	ALICANTE	DEPT LENGUAJES & SISTEMAS INFORMATICOS, UNIV ALICANTE, APDO 99, ALICANTE, 03080, SPAIN	1135-5948	1989-7553		PROCES LENG NAT	Proces. Leng. Nat.	MAR	2024		72					15	30		10.26342/2024-72-1	http://dx.doi.org/10.26342/2024-72-1			16	Computer Science, Artificial Intelligence; Linguistics	Emerging Sources Citation Index (ESCI)	Computer Science; Linguistics	MV0H9					2024-07-03	WOS:001196288500007
J	Ma, PH; Tsai, SW; He, YY; Jia, XX; Zhen, DY; Yu, N; Wang, Q; Ahuja, JKC; Wei, C				Ma, Peihua; Tsai, Shawn; He, Yiyang; Jia, Xiaoxue; Zhen, Dongyang; Yu, Ning; Wang, Qin; Ahuja, Jaspreet K. C.; Wei, Cheng -, I			Large language models in food science: Innovations, applications, and future	TRENDS IN FOOD SCIENCE & TECHNOLOGY			English	Article						Natural language processing; Generative AI; Pre-trained model; Large language model	SAFETY REGULATION	Background: Large Language Models (LLMs) are increasingly significant in food science, transforming areas such as recipe development, nutritional analysis, food safety, and supply chain management. These models bring sophisticated decision-making, predictive analytics, and natural language processing capabilities to various aspects of food science. Scope and approach: The review focuses on the application of LLMs in enhancing food science, with a strong emphasis on food safety, especially in contaminant detection and risk assessment. It addresses the roles of AI and LLMs in regulatory compliance and food quality control. Challenges like data biases, misinformation risks, and implementation hurdles, including data limitations and ethical concerns, are discussed. The necessity for interdisciplinary collaboration to overcome these challenges is also highlighted. Key findings and conclusions: LLMs hold significant potential in automating processes and improving accuracy and efficiency in the global food system. Successful implementation requires continuous updates and ethical considerations. The paper provides insights for academics, industry professionals, and policymakers on the impact of LLMs in food science, emphasizing the importance of interdisciplinary efforts in this domain. Despite potential challenges, the integration of LLMs in food science promises transformative advancements.	[Ma, Peihua; He, Yiyang; Jia, Xiaoxue; Wang, Qin; Ahuja, Jaspreet K. C.; Wei, Cheng -, I] Univ Maryland, Coll Agr & Nat Resources, Dept Nutr & Food Sci, College Pk, MD 20742 USA; [Tsai, Shawn] US Dept Agr, Beltsville Agr Res Ctr, Agr Res Serv, Beltsville, MD 20705 USA; [Zhen, Dongyang] Univ Maryland, A James Clark Sch Engn, Dept Civil & Environm Engn, College Pk, MD 20742 USA; [Yu, Ning] Salesforce Res, Palo Alto, CA 94301 USA; [Ahuja, Jaspreet K. C.] US Dept Agr, Beltsville Human Nutr Res Ctr, Agr Res Serv, Beltsville, MD 20705 USA	University System of Maryland; University of Maryland College Park; United States Department of Agriculture (USDA); University System of Maryland; University of Maryland College Park; Salesforce; United States Department of Agriculture (USDA)	Wei, C (corresponding author), Univ Maryland, Coll Agr & Nat Resources, Dept Nutr & Food Sci, College Pk, MD 20742 USA.	peihua@umd.edu		He, Yiyang/0000-0003-0583-0647; Ma, Peihua/0000-0002-5041-0361				Alamsyah A, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7040168; Almazrouei E., 2023, The falcon series of open language models; Antkiewicz M, 2009, IEEE T SOFTWARE ENG, V35, P795, DOI 10.1109/TSE.2009.30; Anto W., 2020, IEEE Access, V8; Arbel Y. A., 2023, LLMs and the Future of the No-Reading Problem; Armghan A, 2023, RESULTS ENG, V20, DOI 10.1016/j.rineng.2023.101382; Balamurugan S., 2019, International Journal of Engineering and Advanced Technology, V9, P2995, DOI DOI 10.35940/IJEAT.A1379.109119; Bengio Y, 2001, ADV NEUR IN, V13, P932; Binder M, 2022, ELECTRON MARK, V32, P2123, DOI 10.1007/s12525-022-00612-5; Bro R, 2002, TRENDS FOOD SCI TECH, V13, P235, DOI 10.1016/S0924-2244(02)00138-3; Brown P., 1992, Computational Linguistics, V1950; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlini N, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P2633; Chang M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174025; Chen JX, 2024, Arxiv, DOI arXiv:2403.19322; Chen WH, 2022, Arxiv, DOI arXiv:2210.06710; Chen Y, 2023, FOODS, V12, DOI 10.3390/foods12163113; Cheng CH, 2018, PROCEEDINGS OF THE 2018 16TH ACM/IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR SYSTEM DESIGN (MEMOCODE), P43; Chhikara P., 2024, P IEEE CVF WINT C AP; Chowdhery A, 2023, J MACH LEARN RES, V24; Creswell A., 2022, arXiv; Cui GQ, 2023, Arxiv, DOI arXiv:2310.01377; Cunningham R., 2023, Foodgpt: Amachine learning approach to ingredient substitution and recipe recommendation; Deng XY, 2021, ANNU REV FOOD SCI T, V12, P513, DOI 10.1146/annurev-food-071720-024112; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ershov VD, 2023, Arxiv, DOI arXiv:2302.01842; Fu C., 2023, IEEE Journal of Biomedical and Health Informatics; Gavai A, 2023, NPJ SCI FOOD, V7, DOI 10.1038/s41538-023-00220-3; Geng ZQ, 2017, FOOD CONTROL, V78, P33, DOI 10.1016/j.foodcont.2017.02.045; Ghimire P, 2023, Arxiv, DOI arXiv:2310.04427; Goel M, 2022, I C DATA ENGIN WORKS, P107, DOI 10.1109/ICDEW55742.2022.00022; Guo D., 2024, DeepSeekCoder: When the Large Language Model Meets Programming-The Rise of Code Intelligence; Gupta R., 2024, International Journal of Information Management Data Insights, V4; Henson S, 1998, FOOD POLICY, V23, P9, DOI 10.1016/S0306-9192(98)00015-3; Hezarjaribi N, 2019, ACM T INTERACT INTEL, V9, DOI 10.1145/3319370; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hong T., 2020, Bros: A pre-trained language Model for understanding texts in document; Huang YQ, 2007, CRIT REV FOOD SCI, V47, P113, DOI 10.1080/10408390600626453; Hwang A., 2023, Large Language Models as Sous Chefs: Revising Recipes with GPT-3; Kamal M., 2023, Eigenpub Review of Science and Technology, V7, P203; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Katserelis K, 2022, Arxiv, DOI arXiv:2209.12774; Kaur R, 2023, REV ENDOCR METAB DIS, V24, P633, DOI 10.1007/s11154-023-09795-4; Kirk HR, 2023, Arxiv, DOI arXiv:2310.07629; Lee C., 2021, 35 C NEUR INF PROC S; Lee HH, 2020, WWW'20: COMPANION PROCEEDINGS OF THE WEB CONFERENCE 2020, P181, DOI 10.1145/3366424.3383536; Lee SW, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11113141; Li BB, 2023, Arxiv, DOI arXiv:2307.03875; Lin H, 2022, SENSOR ACTUAT B-CHEM, V351, DOI 10.1016/j.snb.2021.130910; Liu Y., 2023, Meta-Radiol ogy; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Ma PH, 2022, FOOD CHEM, V373, DOI 10.1016/j.foodchem.2021.130994; Ma PH, 2021, FOOD RES INT, V147, DOI 10.1016/j.foodres.2021.110437; Makofske MP, 2019, ECON LETT, V177, P30, DOI 10.1016/j.econlet.2019.01.001; Makridis G, 2023, MACH LEARN, V112, P1287, DOI 10.1007/s10994-022-06151-6; Martinez MG, 2013, J RISK RES, V16, P1101, DOI 10.1080/13669877.2012.743157; Marvin HJP, 2022, TRENDS FOOD SCI TECH, V120, P344, DOI 10.1016/j.tifs.2022.01.020; Mezgec S, 2019, PUBLIC HEALTH NUTR, V22, P1193, DOI 10.1017/S1368980018000708; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Mohagheghi P., 2007, INT WORKSH MOD SOFTW; Morales-Garzón A, 2021, IEEE ACCESS, V9, P27389, DOI 10.1109/ACCESS.2021.3058559; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Niszczota P, 2023, NUTRITION, V112, DOI 10.1016/j.nut.2023.112076; Oguejiofor B. B., 2023, International Journal of Applied Research in Social Sciences, V5, P231; Okada Y, 2023, RESUSC PLUS, V15, DOI 10.1016/j.resplu.2023.100435; Ooi KB, 2023, J COMPUT INFORM SYST, DOI 10.1080/08874417.2023.2261010; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan YR, 2020, I C DATA ENGIN WORKS, P94, DOI 10.1109/ICDEW49219.2020.000-1; Papastratis I, 2024, NUTRITION, V121, DOI 10.1016/j.nut.2023.112291; Qi Z., 2023, arXiv; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Reusch A., 2021, RECIPEGM HIERARCHICA; Ross S. I., 2023, P 28 INT C INT US IN; Sadilek A, 2018, NPJ DIGIT MED, V1, DOI 10.1038/s41746-018-0045-1; Sak J, 2021, NUTRIENTS, V13, DOI 10.3390/nu13020322; Sanh V, 2022, arXiv; Schopper H., 2021, 5 INT C COMP LING IN; Shams MY, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104606; Shoeybi M, 2020, Arxiv, DOI arXiv:1909.08053; Singla T, 2023, PROCEEDINGS OF THE 2023 WORKSHOP ON SOFTWARE SUPPLY CHAIN OFFENSIVE RESEARCH AND ECOSYSTEM DEFENSES, SCORED 2023, P5, DOI 10.1145/3605770.3625214; Sun HA, 2023, J MED INTERNET RES, V25, DOI 10.2196/51300; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Team G., 2023, Gemini: a family of highly capable multimodal models; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Torres JP, 2022, IEEE ACCESS, V10, P71496, DOI 10.1109/ACCESS.2022.3187404; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Velichety S, 2019, J MANAGE INFORM SYST, V36, P478, DOI 10.1080/07421222.2019.1598692; Venkataramanan R, 2023, Arxiv, DOI arXiv:2306.01805; Viellieber V. D., 2020, arXiv; Wang D., 2023, DocLLM: A layout-aware generative language model for multimodal document understanding; Wang XX, 2022, COMPR REV FOOD SCI F, V21, P416, DOI 10.1111/1541-4337.12868; Wei J., 2021, FINETUNED LANGUAGE M; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Winter K., 2020, CONCEPTUAL MODELING; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu X., 2023, Journal of Information and Intelligence; Wu Y, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.729834; Xie YQ, 2023, Arxiv, DOI arXiv:2302.05128; Xu P, 2020, Arxiv, DOI arXiv:2010.00840; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhen C., 2022, P 31 INT JOINT C ART; Zhou RY, 2021, COMPUT IND, V125, DOI 10.1016/j.compind.2020.103369	111	0	0	9	9	ELSEVIER SCIENCE LONDON	LONDON	84 THEOBALDS RD, LONDON WC1X 8RR, ENGLAND	0924-2244	1879-3053		TRENDS FOOD SCI TECH	Trends Food Sci. Technol.	JUN	2024	148								104488	10.1016/j.tifs.2024.104488	http://dx.doi.org/10.1016/j.tifs.2024.104488			13	Food Science & Technology	Science Citation Index Expanded (SCI-EXPANDED)	Food Science & Technology	RW0E1					2024-07-03	WOS:001230571700001
J	Woo, B; Huynh, T; Tang, AR; Bui, N; Nguyen, G; Tam, W				Woo, Brigitte; Huynh, Tom; Tang, Arthur; Bui, Nhat; Nguyen, Giang; Tam, Wilson			Transforming nursing with large language models: from concept to practice	EUROPEAN JOURNAL OF CARDIOVASCULAR NURSING			English	Editorial Material; Early Access						Generative artificial intelligence; Large language model; Nursing; Technology		Large language models (LLMs) such as ChatGPT have emerged as potential game-changers in nursing, aiding in patient education, diagnostic assistance, treatment recommendations, and administrative task efficiency. While these advancements signal promising strides in healthcare, integrated LLMs are not without challenges, particularly artificial intelligence hallucination and data privacy concerns. Methodologies such as prompt engineering, temperature adjustments, model fine-tuning, and local deployment are proposed to refine the accuracy of LLMs and ensure data security. While LLMs offer transformative potential, it is imperative to acknowledge that they cannot substitute the intricate expertise of human professionals in the clinical field, advocating for a synergistic approach in patient care.	[Woo, Brigitte; Tam, Wilson] Natl Univ Singapore, Yong Loo Lin Sch Med, Alice Lee Ctr Nursing Studies, Singapore, Singapore; [Huynh, Tom; Tang, Arthur; Bui, Nhat; Nguyen, Giang] RMIT Univ, Sch Sci Engn & Technol, 702 Nguyen Van Linh Blvd,Dist 7, Ho Chi Minh City 756000, Vietnam	National University of Singapore; Royal Melbourne Institute of Technology (RMIT)	Tang, AR (corresponding author), RMIT Univ, Sch Sci Engn & Technol, 702 Nguyen Van Linh Blvd,Dist 7, Ho Chi Minh City 756000, Vietnam.	arthur.tang@rmit.edu.vn	Tang, Arthur/C-8784-2009; Tam, Wilson/H-5890-2019	Tang, Arthur/0000-0002-6655-6883; Woo, Brigitte Fong Yeong/0000-0003-2988-2169; BUI, Nhat Minh/0009-0000-8532-7464; Tam, Wilson/0000-0003-0641-3060				Baumann LA, 2018, HEALTH POLICY, V122, P827, DOI 10.1016/j.healthpol.2018.05.014; Church KW, 2021, NAT LANG ENG, V27, P763, DOI 10.1017/S1351324921000322; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Henrickson L, 2023, AI SOC, DOI 10.1007/s00146-023-01752-8; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kwok KO, 2023, J TRAVEL MED, V30, DOI 10.1093/jtm/taad058; Masikisiki B, 2023, Arxiv, DOI [arXiv:2310.00272, 10.48550/arXiv.2310.00272, DOI 10.48550/ARXIV.2310.00272]; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Montagna Sara, 2023, GoodIT '23: Proceedings of the 2023 ACM Conference on Information Technology for Social Good, P205, DOI 10.1145/3582515.3609536; Moons P, 2023, EUR J CARDIOVASC NUR, DOI 10.1093/eurjcn/zvad098; Moons P, 2024, EUR J CARDIOVASC NUR, V23, P122, DOI 10.1093/eurjcn/zvad087; Moons P, 2023, EUR J CARDIOVASC NUR, V22, pE55, DOI 10.1093/eurjcn/zvad022; Nathania J, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262033; Pionk J., 2023, Give it a persona. The "Act as ... "command for AI prompts in ChatGPT ...; Ray S., 2023, Samsung bans ChatGPT among employees after sensitive code leak; Shin T, 2020, Arxiv, DOI arXiv:2010.15980; Singh N., 2023, PLOS Digit Health, V2, pe0000367; Tam W, 2023, NURS EDUC TODAY, V129, DOI 10.1016/j.nedt.2023.105917; Tang A, 2023, GERIATR NURS, V52, pA1, DOI 10.1016/j.gerinurse.2023.06.007; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wei WI, 2024, CLIN MICROBIOL INFEC, V30, p142e1, DOI 10.1016/j.cmi.2023.11.002; WHO guidance, 2021, Ethics and governance of artificial intelligence for health; Woo T, 2020, J PSYCHIATR RES, V123, P9, DOI 10.1016/j.jpsychires.2019.12.015; XGA.AI, 2023, Adjusting the LLM temperature to get different responses	24	3	3	49	49	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	1474-5151	1873-1953		EUR J CARDIOVASC NUR	Eur. J. Cardiovasc. Nurs.	2024 JAN 5	2024										10.1093/eurjcn/zvad120	http://dx.doi.org/10.1093/eurjcn/zvad120		JAN 2024	4	Cardiac & Cardiovascular Systems; Nursing	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Cardiovascular System & Cardiology; Nursing	EC4R1	38178303				2024-07-03	WOS:001136706400001
J	Frank, MC				Frank, Michael C.			Bridging the data gap between children and large language models	TRENDS IN COGNITIVE SCIENCES			English	Editorial Material								Large language models (LLMs) show intriguing emergent behaviors, yet they receive around four or five orders of magnitude more language data than human children. What accounts for this vast difference in sample efficiency? Candidate explanations include children's pre-existing conceptual knowledge, their use of multimodal grounding, and the interactive, social nature of their input.	[Frank, Michael C.] Stanford Univ, Dept Psychol, 450 Jane Stanford Way, Stanford, CA 94305 USA	Stanford University	Frank, MC (corresponding author), Stanford Univ, Dept Psychol, 450 Jane Stanford Way, Stanford, CA 94305 USA.	mcfrank@stanford.edu		Frank, Michael/0000-0002-7551-4378				Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bergelson E, 2019, DEVELOPMENTAL SCI, V22, DOI 10.1111/desc.12724; Clark E.V., 2016, 1 LANGUAGE ACQUISITI, DOI [10.1017/CBO9781316534175, DOI 10.1017/CBO9781316534175]; Dupoux E, 2018, COGNITION, V173, P43, DOI 10.1016/j.cognition.2017.11.008; Eldan R, 2023, Arxiv, DOI arXiv:2305.07759; Gopnik A, 2012, PSYCHOL BULL, V138, P1085, DOI 10.1037/a0028044; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Jiang GY, 2023, Arxiv, DOI arXiv:2306.00503; Roy BC, 2015, P NATL ACAD SCI USA, V112, P12663, DOI 10.1073/pnas.1419773112; Spelke ES, 2007, DEVELOPMENTAL SCI, V10, P89, DOI 10.1111/j.1467-7687.2007.00569.x; Stojnic G, 2023, COGNITION, V235, DOI 10.1016/j.cognition.2023.105406; Tenenbaum JB, 2011, SCIENCE, V331, P1279, DOI 10.1126/science.1192788	12	3	3	10	19	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	1364-6613	1879-307X		TRENDS COGN SCI	TRENDS COGN. SCI.	NOV	2023	27	11					990	992		10.1016/j.tics.2023.08.007	http://dx.doi.org/10.1016/j.tics.2023.08.007		OCT 2023	3	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	Y1PW8	37659919	Green Submitted			2024-07-03	WOS:001103066500001
J	Lei, G; Docherty, R; Cooper, SJ				Lei, Ge; Docherty, Ronan; Cooper, Samuel J.			Materials science in the era of large language models: a perspective	DIGITAL DISCOVERY			English	Review; Early Access								Large Language Models (LLMs) have garnered considerable interest due to their impressive natural language capabilities, which in conjunction with various emergent properties make them versatile tools in workflows ranging from complex code generation to heuristic finding for combinatorial problems. In this paper we offer a perspective on their applicability to materials science research, arguing their ability to handle ambiguous requirements across a range of tasks and disciplines means they could be a powerful tool to aid researchers. We qualitatively examine basic LLM theory, connecting it to relevant properties and techniques in the literature before providing two case studies that demonstrate their use in task automation and knowledge extraction at-scale. At their current stage of development, we argue LLMs should be viewed less as oracles of novel insight, and more as tireless workers that can accelerate and unify exploration across domains. It is our hope that this paper can familiarise materials science researchers with the concepts needed to leverage these tools in their own research. This perspective paper explores the potential of Large Language Models (LLMs) in materials science, highlighting their abilities to handle ambiguous tasks, automate processes, and extract knowledge at scale across various disciplines.	[Lei, Ge; Docherty, Ronan; Cooper, Samuel J.] Imperial Coll London, Dyson Sch Design Engn, London SW7 2DB, England; [Docherty, Ronan] Imperial Coll London, Dept Mat, London SW7 2DB, England	Imperial College London; Imperial College London	Cooper, SJ (corresponding author), Imperial Coll London, Dyson Sch Design Engn, London SW7 2DB, England.	samuel.cooper@imperial.ac.uk	Cooper, Samuel John/R-2105-2016	Cooper, Samuel John/0000-0003-4055-6903	Engineering and Physical Sciences Research Council; Lee Family Scholarship; EPSRC [EP/S023259/1]; SFI Centre for Doctoral Training in Advanced Characterisation of Materials	Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); Lee Family Scholarship; EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC)); SFI Centre for Doctoral Training in Advanced Characterisation of Materials	This work was supported by funding from Lee Family Scholarship (received by GL), and funding from the EPSRC and SFI Centre for Doctoral Training in Advanced Characterisation of Materials (EP/S023259/1 received by RD). The authors would like to thank other members of the TLDR group for discussions and feedback, specifically Isaac Squires who suggested using LLMs to collate a labelled micrograph dataset. Thank you to arXiv for use of its open access interoperability. Thank you to ChemRxiv for providing an open API.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; ACKLEY DH, 1985, COGNITIVE SCI, V9, P147; Agrawal G, 2024, Arxiv, DOI arXiv:2311.07914; Ahmad W, 2022, Arxiv, DOI [arXiv:2209.01712, 10.48550/arXiv.2209.01712]; Anil GTGR, 2023, Arxiv, DOI arXiv:2312.11805; [Anonymous], Common Crawl Dataset; Anthropic, 2024, The Claude 3 Model Family: Opus, Sonnet, Haiku; Antunes LM, 2024, Arxiv, DOI arXiv:2307.04340; Aversa R, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.172; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bagal V, 2022, J CHEM INF MODEL, V62, P2064, DOI 10.1021/acs.jcim.1c00600; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Balaji S, 2023, Arxiv, DOI arXiv:2310.03030; Beltagy I., 2019, arXiv; Beltagy I, 2020, Arxiv, DOI arXiv:2004.05150; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Bran AM, 2024, NAT MACH INTELL, V6, DOI 10.1038/s42256-024-00832-8; Bsharat SM, 2024, Arxiv, DOI arXiv:2312.16171; Buehler MJ, 2024, ACS ENG AU, V4, P241, DOI 10.1021/acsengineeringau.3c00058; Cai R., 2022, arXiv; Cai TL, 2024, Arxiv, DOI arXiv:2305.17126; Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951; Champa-Bujaico E, 2022, INT J MOL SCI, V23, DOI 10.3390/ijms231810712; Chen DC, 2020, CHEM-EUR J, V26, P10391, DOI 10.1002/chem.202000246; Chen D, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23720-w; Chen S., 2019, arXiv; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; Clark C, 2016, ACM-IEEE J CONF DIG, P143, DOI 10.1145/2910896.2910904; Coja-Oghlan A, 2020, Arxiv, DOI arXiv:2009.10483; Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6; Davis E., 2023, Using a large language model to generate program mutations for a genetic algorithm to search for solutions to combinatorial problems: review of (Romera-Paredes et al.); Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Dufter P, 2021, Arxiv, DOI [arXiv:2102.11090, 10.48550/arXiv.2102.11090]; Eliot J., 2000, DoITPoMS micrograph library; Ficler J, 2017, Arxiv, DOI [arXiv:1707.02633, 10.48550/arXiv.1707.02633, DOI 10.48550/ARXIV.1707.02633]; Finegan DP, 2022, ACS ENERGY LETT, V7, P4368, DOI 10.1021/acsenergylett.2c01996; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Geirhos R, 2020, NAT MACH INTELL, V2, P665, DOI 10.1038/s42256-020-00257-z; Georgiou P, 2024, Arxiv, DOI [arXiv:2402.00176, 10.48550/arXiv.2402.00176, DOI 10.48550/ARXIV.2402.00176]; Goetz A, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00703-z; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Google Gemini Team, 2024, Gemini 1.5: unlocking multimodal understanding across millions of tokens of context; Groeneveld D, 2024, Arxiv, DOI arXiv:2402.00838; Gruver N, 2024, Arxiv, DOI arXiv:2402.04379; Gu A, 2024, Arxiv, DOI arXiv:2312.00752; Guha S, 2021, COMP MATER SCI, V192, DOI 10.1016/j.commatsci.2021.110325; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; Haase R., about us; Holtzman A., 2020, The curious case of neural text degeneration; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu YF, 2023, Arxiv, DOI arXiv:2312.08782; Hu ZQ, 2023, Arxiv, DOI arXiv:2304.01933; Huang J., 2022, arXiv; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Isazawa T, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02511-6; Jablonka KM, 2024, NAT MACH INTELL, V6, P122, DOI 10.1038/s42256-023-00788-1; Jablonka KM, 2023, DIGIT DISCOV, V2, P1233, DOI 10.1039/d3dd00113j; Kant Y., 2022, arXiv; Karamcheti S, 2023, Arxiv, DOI arXiv:2302.12766; Kench S., 2023, J. Open Source Softw, V8; Kench S, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01744-1; Kench S, 2021, NAT MACH INTELL, V3, P299, DOI 10.1038/s42256-021-00322-1; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Krenn M, 2020, MACH LEARN-SCI TECHN, V1, DOI 10.1088/2632-2153/aba947; Kuniyoshi F, 2021, LECT NOTES ARTIF INT, V12979, P319, DOI 10.1007/978-3-030-86517-7_20; Lambert N., 2022, Illustrating Reinforcement Learning from Human Feedback (RLHF); Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li JN, 2022, Arxiv, DOI [arXiv:2201.12086, 10.48550/arXiv.2201.12086]; Lin J, 2023, Arxiv, DOI arXiv:2308.14963; Lin Y, 2024, Arxiv, DOI arXiv:2309.06256; Li XL, 2021, Arxiv, DOI [arXiv:2101.00190, DOI 10.48550/ARXIV.2101.00190]; Liu H, 2024, Arxiv, DOI [arXiv:2402.08268, 10.48550/arXiv.2402.08268, DOI 10.48550/ARXIV.2402.08268]; Liu ZQ, 2023, Arxiv, DOI arXiv:2305.10688; Lv ZX, 2023, SMALL STRUCT, V4, DOI 10.1002/sstr.202300158; Ma YJ, 2024, Arxiv, DOI arXiv:2310.12931; Marchand A, 2023, NATURE, DOI 10.1038/d41586-023-01324-2; Marcus G., Math is hardif you are an LLM and why that matters; Mavracic J, 2021, J CHEM INF MODEL, V61, P4280, DOI 10.1021/acs.jcim.1c00446; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Min SW, 2022, Arxiv, DOI arXiv:2202.12837; Moussiades L, 2023, Arxiv, DOI [arXiv:2309.12732, 10.48550/arXiv.2309.12732, DOI 10.48550/ARXIV.2309.12732]; Mukaddem KT, 2020, J CHEM INF MODEL, V60, P2492, DOI 10.1021/acs.jcim.9b00734; Nagrani A, 2022, Arxiv, DOI arXiv:2107.00135; Nair V, 2023, Arxiv, DOI [arXiv:2303.17071, DOI 10.48550/ARXIV.2303.17071]; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nathan C. F., 2023, Nat. Mach. Intell, V5, P1297; OpenAI, 2024, Sora: Creating video from text; OpenAI, GPT4-o; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pachitariu M, 2022, NAT METHODS, V19, P1634, DOI 10.1038/s41592-022-01663-4; Packer C, 2024, Arxiv, DOI arXiv:2310.08560; Parkinson J, 2023, PROCEEDINGS OF THE 2023 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH V.1, ICER 2023 V1, P122, DOI 10.1145/3568813.3600129; Penedo G, 2023, Arxiv, DOI arXiv:2306.01116; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Qi YP, 2023, ADV OPT MATER, V11, DOI 10.1002/adom.202203104; Radford A., 2018, IMPROVING LANGUAGE U; Radford A, 2021, PR MACH LEARN RES, V139; Rafiei MH, 2016, ACI MATER J, V113, P781, DOI 10.14359/51689360; Ridnik T, 2024, Arxiv, DOI arXiv:2401.08500; Romera-Paredes B, 2024, NATURE, V625, DOI 10.1038/s41586-023-06924-6; Rubungo AN, 2023, Arxiv, DOI arXiv:2310.14029; Schick T., 2023, arXiv; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Schwenker E, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100843; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Srivastava A., 2023, Beyond the imitation game: Quantifying and extrapolating the capabilities of language models; Sun C, 2017, Arxiv, DOI arXiv:1707.02968; Surís D, 2023, Arxiv, DOI [arXiv:2303.08128, DOI 10.48550/ARXIV.2303.08128(2023).2303.08128]; Sutton C, 2010, Arxiv, DOI arXiv:1011.4088; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Szymanski NJ, 2023, NATURE, V624, P86, DOI 10.1038/s41586-023-06734-w; Tong XC, 2021, J MED CHEM, V64, P14011, DOI 10.1021/acs.jmedchem.1c00927; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; van de Sande DMJ, 2023, MAGN RESON MED, V90, P1253, DOI 10.1002/mrm.29793; Vaswani A, 2017, ADV NEUR IN, V30; Vlker C., 2024, LLMs can Design Sustainable Concrete -a Systematic Benchmark (re-submitted version), DOI [10.13140/RG.2.2.33795.27686, DOI 10.13140/RG.2.2.33795.27686]; Wang SZ, 2024, SCI DATA, V11, DOI 10.1038/s41597-024-02983-0; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei J, 2023, Arxiv, DOI arXiv:2303.03846; Wei J, 2022, NAT MED, V28, P1072, DOI 10.1038/s41591-022-01721-6; WEININGER D, 1988, J CHEM INF COMP SCI, V28, P31, DOI 10.1021/ci00057a005; Weston L, 2019, J CHEM INF MODEL, V59, P3692, DOI 10.1021/acs.jcim.9b00470; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Williams E, 2017, NAT METHODS, V14, P775, DOI [10.1038/nmeth.4326, 10.1038/NMETH.4326]; Wong MF, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25060888; Wu CF, 2023, Arxiv, DOI arXiv:2303.04671; Xu P, 2022, Arxiv, DOI [arXiv:2206.06488, DOI 10.48550/ARXIV.2206.064884]; Yang CR, 2024, Arxiv, DOI arXiv:2309.03409; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Yang SJ, 2023, Arxiv, DOI arXiv:2311.13778; Yang Z, 2023, Arxiv, DOI arXiv:2309.03241; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zeni C, 2024, Arxiv, DOI arXiv:2312.03687; Zhao HY, 2023, Arxiv, DOI [arXiv:2309.01029, 10.48550/arXiv.2309.01029]; Zhao S, 2024, CELL REP PHYS SCI, V5, DOI 10.1016/j.xcrp.2024.101844; Zheng ZL, 2024, DIGIT DISCOV, V3, P491, DOI 10.1039/d3dd00239j; Zhou QH, 2020, J PHYS CHEM LETT, V11, P3920, DOI 10.1021/acs.jpclett.0c00665	143	0	0	0	0	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND		2635-098X		DIGIT DISCOV	Digit. Discov.	2024 JUN 5	2024										10.1039/d4dd00074a	http://dx.doi.org/10.1039/d4dd00074a		JUN 2024	16	Chemistry, Multidisciplinary; Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Chemistry; Computer Science	TZ4E9		gold, Green Submitted			2024-07-03	WOS:001245060400001
J	Shiraishi, M; Kanayama, K; Yang, R; Okazaki, M				Shiraishi, Makoto; Kanayama, Koji; Yang, Rui; Okazaki, Mutsumi			Preliminary evaluation of the potential of commercially available large language models in diagnosing skin tumours	CLINICAL AND EXPERIMENTAL DERMATOLOGY			English	Letter								To date, the most commercially available large language models have refused to evaluate clinical pictures because of the medical contexts. In our study, only BingAI Creative mode provided decisions about whether images were malignant or benign and provided a diagnosis for skin tumours, both with relatively low accuracy rates of 58% for classification and 3% for diagnosis.	[Shiraishi, Makoto; Kanayama, Koji; Yang, Rui; Okazaki, Mutsumi] Univ Tokyo Hosp, Dept Plast & Reconstruct Surg, Tokyo, Japan	University of Tokyo	Shiraishi, M (corresponding author), Univ Tokyo Hosp, Dept Plast & Reconstruct Surg, Tokyo, Japan.	shiraishi-kyf@umin.ac.jp	; SHIRAISHI, Makoto/HOF-3529-2023	Kanayama, Koji/0000-0002-9287-7648; SHIRAISHI, Makoto/0000-0002-3734-2085				Fujisawa Y, 2019, BRIT J DERMATOL, V180, P373, DOI 10.1111/bjd.16924; Google, BARD; Han SS, 2018, J INVEST DERMATOL, V138, P1529, DOI 10.1016/j.jid.2018.01.028; Microsoft, CONFIRMED NEW BING R; Microsoft, BINGAI GPT 4; Open AI, GPT 4V ISION; OpenAI, ChatGPT can now see, hear, and speak; Passby L, 2023, CLIN EXP DERMATOL, V49, P722, DOI 10.1093/ced/llad197	8	4	4	1	1	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0307-6938	1365-2230		CLIN EXP DERMATOL	Clin. Exp. Dermatol.	JAN 23	2024	49	7					741	743		10.1093/ced/llad430	http://dx.doi.org/10.1093/ced/llad430		DEC 2023	3	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	WF2T3	38048525				2024-07-03	WOS:001147703500001
J	Novikova, ML; Novikov, PN				Novikova, Marina L.; Novikov, Philipp N.			Using artificial intelligence to develop a machine translation system and teaching resources in the Tuvan language	NOVYE ISSLEDOVANIYA TUVY-NEW RESEARCH OF TUVA			English	Article						Tuvan language; artificial intelligence; machine translation; neural networks; large language models; digital presence; machine learning	BILINGUALISM	The advancement of computer technologies applied in the humanities and the progress in the development of large language models based on machine learning and neural network technologies have reached an exceptionally high level of sophistication. The linguistic potential of large language models elicits a natural interest among researchers, which constitutes a justified reflection of the relevance and importance of using artificial intelligence to create machine translation systems and educational resources. The article explores the experience of creating a large language model for the Tuvan language using machine learning and artificial intelligence. The authors undertook an attempt to develop a large language model capable of recognizing the Tuvan language, translating phrases into Russian and back. In addition, the possibilities of generating text in Tuvan were examined and tested, which can be used both in the field of language teaching and when conducting various kinds of linguistic research. This experience is unique since, as of now, the Tuvan language is not represented in any well -established machine translation systems. A secondary aim of the research is to analyze the level of the language's digital presence on the Internet, as well as to provide recommendations for devising an optimal algorithm for building similar systems and web services based on machine learning. The research outcomes are of practical value not only with respect to the Tuvan language but can also be extrapolated to other official languages in the Russian Federation.	[Novikova, Marina L.] RUDN Univ, Russian Language Inst, Russian Language & Cultural Studies Dept, 10,Bldg 3 Miklukho Maklaya St, Moscow 117198, Russia; [Novikov, Philipp N.] RUDN Univ, Law Inst, Dept Foreign Languages, 6 Miklukho Maklaya St, Moscow 117198, Russia	Peoples Friendship University of Russia; Russian Academy of Sciences; V.V. Vinogradov Russian Language Institute of the Russian Academy of Sciences; Peoples Friendship University of Russia	Novikova, ML (corresponding author), RUDN Univ, Russian Language Inst, Russian Language & Cultural Studies Dept, 10,Bldg 3 Miklukho Maklaya St, Moscow 117198, Russia.	novikova-ml@rudn.ru; novikov_fn@pfur.ru						Arefiev AL, 2021, NOVYE ISSLED TUVY, P255, DOI 10.25178/nit.2021.1.14; Armstrong LE, 2022, FRONT NETW PHYSIOL, V1, DOI 10.3389/fnetp.2021.794392; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Borgoiakova TG, 2023, NOVYE ISSLED TUVY, P290, DOI 10.25178/nit.2023.4.20; Dyrkheeva GA, 2020, NOVYE ISSLED TUVY, P62, DOI 10.25178/nit.2020.1.5; Garcia X., 2023, INT C MACHINE LEARNI, VVolume 202, P10867; Kuzhuget Sh. Yu., 2021, Polylinguality and Transcultural Practices, V18, P405, DOI [10.22363/2618-897X-2021-18-4-405-420, DOI 10.22363/2618-897X-2021-18-4-405-420]; Lamazhaa Ch. K., 2022, Tuvans. Native people; Le T. N., 2020, P 28 INT C COMP LING, P4661, DOI DOI 10.18653/V1/2020.COLING-MAIN.410; Ondar CG, 2023, NOVYE ISSLED TUVY, P186, DOI 10.25178/nit.2023.1.11; Papyn A. S., 2010, New Research of Tuva, P19; Spennemann D.H.R., 2023, Knowledge, V18, P480, DOI 10.3390/knowledge3030032; SREELEKHA S., 2016, IJCTA, V9, P233; Srinivasan K, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2443, DOI 10.1145/3404835.3463257; Zwischenberger C, 2022, PERSPECT STUD TRANSL, V30, P1, DOI 10.1080/0907676X.2021.1872662	15	0	0	4	4	CH K LAMAZHAA	MOSCOW	PO BOX 30, MOSCOW, 117437, RUSSIA		2079-8482		NOVYE ISSLED TUVY	Novye Issled. Tuvy		2024		1					6	17		10.25178/nit.2024.1.1	http://dx.doi.org/10.25178/nit.2024.1.1			12	Humanities, Multidisciplinary; Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Arts & Humanities - Other Topics; Social Sciences - Other Topics	LT4G4		gold			2024-07-03	WOS:001189033500001
J	Brodnik, NR; Carton, S; Muir, C; Ghosh, S; Downey, D; Echlin, MP; Pollock, TM; Daly, S				Brodnik, Neal R.; Carton, Samuel; Muir, Caelin; Ghosh, Satanu; Downey, Doug; Echlin, McLean P.; Pollock, Tresa M.; Daly, Samantha			Perspective: Large Language Models in Applied Mechanics	JOURNAL OF APPLIED MECHANICS-TRANSACTIONS OF THE ASME			English	Article						computational mechanics; mechanical properties of materials; machine learning; artificial intelligence; natural language processing		Large language models (LLMs), such as ChatGPT and PaLM, are able to perform sophisticated text comprehension and generation tasks with little or no training. Alongside their broader societal impacts, these capabilities carry great promise for the physical sciences, including applied mechanics. We present a summary of recent developments in these models, their application to mechanics and adjacent fields, and a perspective on their future use in applied mechanics, taking into account their limitations and the unique challenges of the field.	[Brodnik, Neal R.; Daly, Samantha] Univ Calif Santa Barbara, Dept Mech Engn, Santa Barbara, CA 93106 USA; [Carton, Samuel; Ghosh, Satanu] Univ New Hampshire, Dept Comp Sci, Durham, NH 03824 USA; [Muir, Caelin; Echlin, McLean P.; Pollock, Tresa M.] Univ Calif Santa Barbara, Mat Dept, Santa Barbara, CA 93106 USA; [Downey, Doug] Northwestern Univ, Allen Inst Artificial Intelligence Comp Sci & Engn, Evanston, IL 60208 USA	University of California System; University of California Santa Barbara; University System Of New Hampshire; University of New Hampshire; University of California System; University of California Santa Barbara; Northwestern University	Daly, S (corresponding author), Univ Calif Santa Barbara, Dept Mech Engn, Santa Barbara, CA 93106 USA.	nbrodnik@ucsb.edu; samuel.carton@unh.edu; muir@ucsb.edu; satanu.ghosh@unh.edu; d-downey@northwestern.edu; mechlin@ucsb.edu; tresap@ucsb.edu; samdaly@ucsb.edu			NASA Space Technology Graduate Research Opportunities Fellowship [2033558]; NSF [ONR N00014-18-1-3031]; Department of Defense Vannevar Bush Fellowship;  [N00174-22-1-0020]	NASA Space Technology Graduate Research Opportunities Fellowship; NSF(National Science Foundation (NSF)); Department of Defense Vannevar Bush Fellowship(United States Department of Defense); 	NRB and SHD acknowledge support from NSWC Grant #N00174-22-1-0020. CM acknowledges support from the NASA Space Technology Graduate Research Opportunities Fellowship (Grant No. 80NSSC19K1164). DD acknowledges support from NSF Grant 2033558. TMP and MPE acknowledge the support of a Department of Defense Vannevar Bush Fellowship, Grant ONR N00014-18-1-3031.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Balabin H, 2022, BIOINFORMATICS, V38, P1648, DOI 10.1093/bioinformatics/btac001; Beltagy I., 2019, arXiv; Borg CKH, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00768-9; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buehler MJ, 2022, ACCOUNTS CHEM RES, V55, P3387, DOI 10.1021/acs.accounts.2c00330; Buehler MJ, 2022, J APPL MECH-T ASME, V89, DOI 10.1115/1.4055730; Callahan PG, 2013, MICROSC MICROANAL, V19, P1255, DOI 10.1017/S1431927613001840; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cresswell-Boyes AJ, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11658-y; Dai JZ, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062221; De Graef Marc, 2019, Zenodo; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dunn A., 2022, arXiv; Ge YQ, 2023, Arxiv, DOI [arXiv:2304.04370, 10.48550/arXiv.2304.04370]; Gupta T., 2022, NPJ COMPUT MATER, V8, P1, DOI DOI 10.1038/S41524-022-00784-W; Henderson M. R., 1993, Research in Engineering Design, V5, P140, DOI 10.1007/BF01608360; Hong Z, 2022, Arxiv, DOI [arXiv:2205.11342, 10.48550/arXiv.2205.11342, DOI 10.48550/ARXIV.2205.11342]; Hope T., 2022, ARXIV220502007; Hope T, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P235, DOI 10.1145/3097983.3098038; Hu Yiwen, 2023, APL Machine Learning, DOI 10.1063/5.0134317; Huang S, 2022, J CHEM INF MODEL, V62, P6365, DOI 10.1021/acs.jcim.2c00035; Hyoseong Lee, 2013, Applied Mechanics and Materials, V284-287, P3362, DOI 10.4028/www.scientific.net/AMM.284-287.3362; Izacard G, 2022, Arxiv, DOI arXiv:2208.03299; Jablonka K. M., 2023, ChemRxiv, DOI [DOI 10.26434/CHEMRXIV-2023-FW8N4-V2, 10.26434/chemrxiv-2023-fw8n4-v3]; Jain A, 2013, APL MATER, V1, DOI 10.1063/1.4812323; Kandpal N, 2023, Arxiv, DOI [arXiv:2211.08411, 10.48550/arXiv.2211.08411]; Kang HB, 2022, ACM T COMPUT-HUM INT, V29, DOI 10.1145/3530013; Lahat A, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31412-2; Lahav D, 2022, AAAI CONF ARTIF INTE, P11982; Lebensohn RA, 2012, INT J PLASTICITY, V32-33, P59, DOI 10.1016/j.ijplas.2011.12.005; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Luu RK, 2023, J APPL MECH-T ASME, V90, DOI 10.1115/1.4062310; Lyu Q, 2023, Arxiv, DOI [arXiv:2301.13379, 10.48550/arXiv.2301.13379]; Martinez-Gil J, 2017, 19TH INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES (IIWAS2017), P32, DOI 10.1145/3151759.3151774; Mialon G., 2023, arXiv; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Mitra B, 2018, An introduction to neural information retrieval; Morris MR, 2023, Arxiv, DOI [arXiv:2304.01420, DOI 10.48550/ARXIV.2304.01420]; Nadkarni R., 2021, arXiv; Naik A., 2021, ARXIV; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nayak A., 2015, INT J COMPUT APPL, V116, P34; OpenAI, 2023, AL LANG MOD FOLL INS; Pei ZR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-022-35766-5; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Quey R, 2022, IOP CONF SER-MAT SCI, V1249, DOI 10.1088/1757-899X/1249/1/012021; Dawson PR, 2015, Arxiv, DOI arXiv:1504.03296; Raffel C, 2020, J MACH LEARN RES, V21; Rafsanjani A, 2016, EXTREME MECH LETT, V9, P291, DOI 10.1016/j.eml.2016.09.001; Safavi T., 2022, ARXIV220508012; Schick T., 2023, arXiv; Shetty P, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2020.101922; Shi F, 2017, J MECH DESIGN, V139, DOI 10.1115/1.4037649; Smith M., 2009, ABAQUS/Standard User's Manual; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Szyniszewski S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65976-0; Taylor R, 2022, arXiv; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Vaswani A, 2017, ADV NEUR IN, V30; Wan GC, 2020, EXTREME MECH LETT, V34, DOI 10.1016/j.eml.2019.100603; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xie T, 2023, Arxiv, DOI arXiv:2304.02213; Xu CW, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01016-5; Yang FF, 2021, 2021 5TH INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND INFORMATION RETRIEVAL, NLPIR 2021, P168, DOI 10.1145/3508230.3508256; Yoshitake M., 2022, Sci. Technol. Adv. Mater, V2, P372, DOI [DOI 10.1080/27660400.2022.2124831, 10.1080/27660400.2022.2124831]; Zhang JR, 2022, IEEE ACCESS, V10, P92971, DOI 10.1109/ACCESS.2022.3203735; Zhao JY, 2023, J CHEM INF MODEL, V63, P1961, DOI 10.1021/acs.jcim.2c01259	72	8	8	9	30	ASME	NEW YORK	TWO PARK AVE, NEW YORK, NY 10016-5990 USA	0021-8936	1528-9036		J APPL MECH-T ASME	J. Appl. Mech.-Trans. ASME	OCT 1	2023	90	10							101008	10.1115/1.4062773	http://dx.doi.org/10.1115/1.4062773			7	Mechanics	Science Citation Index Expanded (SCI-EXPANDED)	Mechanics	R1PH9					2024-07-03	WOS:001062126400006
C	Wu, XD; Zhu, XQ; Baralis, E; Lu, RQ; Kumar, V; Rutkowski, L; Tang, J		Chen, G; Khan, L; Gao, X; Qiu, M; Pedrycz, W; Wu, X		Wu, Xindong; Zhu, Xingquan; Baralis, Elena; Lu, Ruqian; Kumar, Vipin; Rutkowski, Leszck; Tang, Jie			On Computing Paradigms - Where Will Large Language Models Be Going	23RD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, ICDM 2023	IEEE International Conference on Data Mining		English	Proceedings Paper	23rd IEEE International Conference on Data Mining (IEEE ICDM)	DEC 01-04, 2023	Shanghai, PEOPLES R CHINA	IEEE, IEEE Comp Soc, US National Science Foundation, Technology Innovation Institute, TWO SIGMA		computing; artificial intelligence; large language models		Computing generates intelligence. With this statement we do not mean computing's capabilities of manipulating numbers, shapes, symbols, and even logics. What we mean is the ingenious design of computing structures which serve as the basis of intelligence generation during program running In this panel discussion, we consider how to obtain such capabilities through some computing paradigms as examples, including principal computing, logic computing, discriminative computing, and generative computing. The panelists express their thoughts about the inherent advantages and disadvantages of each of these paradigms, in terms of their adaptivity, interpretability, generality and specificity, and dives into detailed discussions about Large Language Models (LLMs), a mainstream generative paradigm which leverages the strengths of large pre -trained models and downstream prompt tuning to deliver combined intelligence, superior to most existing frameworks in natural language processing. The panel outlines potential challenges of the generative paradigm, with a strong focus on LLMs, and emphasizes that future directions of such models will need to address (I) tackling bias, discrimination, and transparency challenges; (2) delivering logical answers with high specificity; (3) enabling personalized, lightweight, and rapid updating mechanisms; (4) assessing accreditation, tracing, and misusages; and (5) ensuring sustainable LLMs.	[Wu, Xindong] Zhcjiang Lab, Hangzhou, Peoples R China; [Zhu, Xingquan] Florida Atlantic Univ, Boca Raton, FL 33431 USA; [Baralis, Elena] Politecn Torino, Turin, Italy; [Lu, Ruqian] Chinese Acad Sci, Beijing, Peoples R China; [Kumar, Vipin] Univ Minnesota, Minneapolis, MN USA; [Rutkowski, Leszck] Polish Acad Sci, Warsaw, Poland; [Tang, Jie] Tsinghua Univ, Beijing, Peoples R China	State University System of Florida; Florida Atlantic University; Polytechnic University of Turin; Chinese Academy of Sciences; University of Minnesota System; University of Minnesota Twin Cities; Polish Academy of Sciences; Tsinghua University	Wu, XD (corresponding author), Zhcjiang Lab, Hangzhou, Peoples R China.		tang, jie/KIE-8633-2024; Wu, Xindong/AAB-6713-2022; Kumar, Vipin/KMY-0355-2024	Wu, Xindong/0000-0003-2396-1704; 				Aggarwal R, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00438-z; Arrieta AB, 2020, INFORM FUSION, V58, P82, DOI 10.1016/j.inffus.2019.12.012; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bourtoule Lucas, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P141, DOI 10.1109/SP40001.2021.00019; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Dastin Jeffrey, 2018, Reuters, DOI DOI 10.1017/CBO9781139025751; David E., The Verge; Felzenszwalb PF, 2007, J ARTIF INTELL RES, V29, P153, DOI 10.1613/jair.2187; He Yi, 2023, PROC INT JOINT C ART; Heckerman D, 2008, STUD COMPUT INTELL, V156, P33; Hendrycks Dan, 2021, arXiv; Hogan A, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447772; Hu HX, 2023, IEEE T PATTERN ANAL, V45, P5684, DOI 10.1109/TPAMI.2022.3218265; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5; LeCun Y., 1995, Handb Brain Theory Neural Netw, V3361, P1995, DOI [DOI 10.5555/303568.303704, 10.5555/303568.303704]; Oremus W., 2022, Washington PostJune 17,; Qiao A, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P1; Schade M., How ChatGPT and our language models are developed; Schwartz R, 2020, COMMUN ACM, V63, P54, DOI 10.1145/3381831; Shumailov I, 2024, Arxiv, DOI [arXiv:2305.17493, DOI 10.48550/ARXIV.2305.17493]; Taori Rohan, 2023, Alpaca: A strong, replicable instruction-following model, P7; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Verma Pranshu., 2023, The Washington Post; Voigt P., 2017, A Practical Guide, V10; Ylipelkonen V., 2022, Bachelor's Thesis; Zeng A., 2023, PROC ICLR; Zhang DK, 2020, IEEE T BIG DATA, V6, P3, DOI 10.1109/TBDATA.2018.2850013; Zhengxiao D., 2020, Long Papers, V1, P320	31	0	0	2	2	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-4786		979-8-3503-0788-7	IEEE DATA MINING			2023							1577	1582		10.1109/ICDM58522.2023.00211	http://dx.doi.org/10.1109/ICDM58522.2023.00211			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5QH					2024-07-03	WOS:001165180100202
J	Houghton, C; Kazanina, N; Sukumaran, P				Houghton, Conor; Kazanina, Nina; Sukumaran, Priyanka			Beyond the limitations of any imaginable mechanism: Large language models and psycholinguistics	BEHAVIORAL AND BRAIN SCIENCES			English	Editorial Material							CONTEXTS	Large language models (LLMs) are not detailed models of human linguistic processing. They are, however, extremely successful at their primary task: Providing a model for language. For this reason LLMs are important in psycholinguistics: They are useful as a practical tool, as an illustrative comparative, and philosophically, as a basis for recasting the relationship between language and thought.	[Houghton, Conor; Sukumaran, Priyanka] Univ Bristol, Dept Comp Sci, Bristol, England; [Kazanina, Nina; Sukumaran, Priyanka] Univ Bristol, Sch Psychol Sci, Bristol, England; [Kazanina, Nina] HSE Univ, Natl Res Univ, Inst Cognit Neurosci, Higher Sch Econ,Int lLab Social Neurobiol, Moscow, Russia	University of Bristol; University of Bristol; HSE University (National Research University Higher School of Economics)	Houghton, C (corresponding author), Univ Bristol, Dept Comp Sci, Bristol, England.	conor.houghton@bristol.ac.uk; nina.kazanina@bristol.ac.uk; p.sukumaran@bristol.ac.uk	Houghton, Conor/H-3793-2014; Kazanina, Nina/Y-5403-2018	Houghton, Conor/0000-0001-5017-9473; Kazanina, Nina/0000-0001-7737-4279; Sukumaran, Priyanka/0000-0002-1537-3841	Wellcome Trust [108899/B/15/Z]; Leverhulme Trust [RF-2021-533]; International Laboratory for Social Neurobiology of the Institute for Cognitive Neuroscience HSE, RF Government [075-15-2022-1037]; Wellcome Trust [108899/B/15/Z] Funding Source: Wellcome Trust	Wellcome Trust(Wellcome Trust); Leverhulme Trust(Leverhulme Trust); International Laboratory for Social Neurobiology of the Institute for Cognitive Neuroscience HSE, RF Government; Wellcome Trust(Wellcome Trust)	P. S. received support from the Wellcome Trust [108899/B/15/Z], C. H. from the Leverhulme Trust [RF-2021-533], and N. K. from the International Laboratory for Social Neurobiology of the Institute for Cognitive Neuroscience HSE, RF Government grant [075-15-2022-1037].	[Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2018, Proceedings of CogSci 2018; [Anonymous], 1966, Cartesian Linguistics; Bernardy Jean-Philippe, 2017, Linguistic Issues in Language Technology, V15, P1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dambacher M, 2006, BRAIN RES, V1084, P89, DOI 10.1016/j.brainres.2006.02.010; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; FISCHLER I, 1979, J VERB LEARN VERB BE, V18, P1, DOI 10.1016/S0022-5371(79)90534-6; Frank SL, 2015, BRAIN LANG, V140, P1, DOI 10.1016/j.bandl.2014.10.006; Gulordava K., 2018, P 2018 C N AM CHAPTE, V1, P1195, DOI [10.18653/v1/N18-1108, DOI 10.18653/V1/N18-1108]; KLEIMAN GM, 1980, MEM COGNITION, V8, P336, DOI 10.3758/BF03198273; Kuncoro A., 2018, LEARN LANG HUM MACH, V5; LANDAU B, 1988, COGNITIVE DEV, V3, P299, DOI 10.1016/0885-2014(88)90014-7; Linzen Tal, 2016, Transactions of the Association for Computational Linguistics, V1990, P521, DOI [10.1162/tacl_a_00115, DOI 10.1162/TACL_A_00115]; Marvin R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1192; Mitchell J., 2019, Conference on Cognitive Computational Neuroscience, DOI DOI 10.32470/CCN.2019.1241-0; Rayner K, 1996, PSYCHON B REV, V3, P504, DOI 10.3758/BF03214555; Sukumaran P, 2022, Arxiv, DOI arXiv:2211.00153	18	0	0	20	22	CAMBRIDGE UNIV PRESS	CAMBRIDGE	EDINBURGH BLDG, SHAFTESBURY RD, CB2 8RU CAMBRIDGE, ENGLAND	0140-525X	1469-1825		BEHAV BRAIN SCI	Behav. Brain Sci.	DEC 6	2023	46								e395	10.1017/S0140525X23001693	http://dx.doi.org/10.1017/S0140525X23001693			77	Psychology, Biological; Behavioral Sciences; Neurosciences	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Behavioral Sciences; Neurosciences & Neurology	Z8MA2	38054292	Green Submitted			2024-07-03	WOS:001114547900001
J	Hagendorff, T				Hagendorff, Thilo			Deception abilities emerged in large language models	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						deception; large language models; AI alignment	DARK TRIAD; PERSONALITY; BELIEFS	Large language models (LLMs) are currently at the forefront of intertwining AI systems with human communication and everyday life. Thus, aligning them with human values is of great importance. However, given the steady increase in reasoning abilities, future LLMs are under suspicion of becoming able to deceive human operators and utilizing this ability to bypass monitoring efforts. As a prerequisite to this, LLMs need to possess a conceptual understanding of deception strategies. This study reveals that such strategies emerged in state- of- the- art LLMs, but were nonexistent in earlier LLMs. We conduct a series of experiments showing that state- of- the- art LLMs are able to understand and induce false beliefs in other agents, that their performance in complex deception scenarios can be amplified utilizing chain- of- thought reasoning, and that eliciting Machiavellianism in LLMs can trigger misaligned deceptive behavior. GPT- 4, for instance, exhibits deceptive behavior in simple test scenarios 99.16% of the time (P < 0.001). In complex second- order deception test scenarios where the aim is to mislead someone who expects to be deceived, GPT- 4 resorts to deceptive behavior 71.46% of the time (P < 0.001) when augmented with chain- of- thought reasoning. In sum, revealing hitherto unknown machine behavior in LLMs, our study contributes to the nascent field of machine psychology.	[Hagendorff, Thilo] Univ Stuttgart, Interchange Forum Reflecting Intelligent Syst, Stuttgart, Germany	University of Stuttgart	Hagendorff, T (corresponding author), Univ Stuttgart, Interchange Forum Reflecting Intelligent Syst, Stuttgart, Germany.	thilo.hagendorff@iris.uni			Ministry of Science, Research and Arts Baden-Wurttemberg [Az. 33-7533-9-19/54/5]; Interchange Forum for Reflecting on Intelligent Systems (IRIS) at the University of Stuttgart	Ministry of Science, Research and Arts Baden-Wurttemberg; Interchange Forum for Reflecting on Intelligent Systems (IRIS) at the University of Stuttgart	This research was supported by the Ministry of Science, Research and Arts Baden-Wurttemberg under Az. 33-7533-9-19/54/5 in Reflecting Intelligent Systems for Diversity, Demography, and Democracy (IRIS3D) as well as the Interchange Forum for Reflecting on Intelligent Systems (IRIS) at the University of Stuttgart. Thanks to Francesca Carlon, Maluna Menke, and Sarah Fabi for their assistance and helpful comments on the manuscript.	Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2023, Tech Rep 2023; Artiga M, 2018, PHILOS STUD, V175, P579, DOI 10.1007/s11098-017-0883-8; Azaria A, 2023, Arxiv, DOI arXiv:2304.13734; Bakhtin A, 2022, SCIENCE, V378, P1067, DOI 10.1126/science.ade9097; Bostrom Nick, 2016, SUPERINTELLIGENCE PA, DOI DOI 10.1080/01402390.2013.844127; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Burns C., 2022, arXiv; Carranza A, 2023, Arxiv, DOI [arXiv:2307.10569, 10.48550/arXiv.2307.10569, DOI 10.48550/ARXIV.2307.10569]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Coda-Forno J, 2023, Arxiv, DOI [arXiv:2304.11111, 10.48550/arXiv.2304.11111, DOI 10.48550/ARXIV.2304.11111]; Emami A, 2020, Arxiv, DOI [arXiv:2011.04767, 10.48550/arXiv.2011.04767, DOI 10.48550/ARXIV.2011.04767]; Fallis D, 2021, STUD HIST PHILOS SCI, V87, P114, DOI 10.1016/j.shpsa.2021.03.004; Fluri L, 2023, Arxiv, DOI [arXiv:2306.09983, 10.48550/arXiv.2306.09983, DOI 10.48550/ARXIV.2306.09983]; Furnham A, 2013, SOC PERSONAL PSYCHOL, V7, P199, DOI 10.1111/spc3.12018; Hagendorff T., Data from "Deception Abilities Emerged in Large Language Models; Hagendorff T, 2023, NAT COMPUT SCI, V3, P833, DOI 10.1038/s43588-023-00527-x; Hagendorff T, 2023, Arxiv, DOI [arXiv:2303.13988, 10.48550/arXiv.2303.13988, DOI 10.48550/ARXIV.2303.13988]; Happe FGE, 1997, BRIT J DEV PSYCHOL, V15, P1, DOI 10.1111/j.2044-835X.1997.tb00721.x; Hauser M.D., 1996, EVOLUTION COMMUNICAT, P471; Hendrycks D, 2023, Arxiv, DOI [arXiv:2306.12001, 10.48550/arXiv.2306.12001, DOI 10.48550/ARXIV.2306.12001]; Hendrycks D, 2023, Arxiv, DOI [arXiv:2303.16200, 10.48550/arXiv.2303.16200, DOI 10.48550/ARXIV.2303.16200]; Hendrycks D, 2022, Arxiv, DOI arXiv:2109.13916; Holterman B, 2023, Arxiv, DOI [arXiv:2305.14020, 10.48550/arXiv.2305.14020, DOI 10.48550/ARXIV.2305.14020]; Hubinger E., 2021, arXiv, DOI 10.48550/arXiv.1906.01820; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jones DN, 2014, ASSESSMENT, V21, P28, DOI 10.1177/1073191113514105; Kenton Z, 2021, Arxiv, DOI arXiv:2103.14659; Kim G, 2023, Arxiv, DOI arXiv:2303.17491; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Leslie D, 2019, NATURE, V574, P32, DOI 10.1038/d41586-019-02939-0; Mahon J., 2015, STANFORD ENCY PHILOS; Mahon JamesEdwin., 2007, IJAP, V21, P181, DOI [10.5840/ijap20072124, DOI 10.5840/IJAP20072124]; Miller SA, 2009, PSYCHOL BULL, V135, P749, DOI 10.1037/a0016854; Mitchell R.W., 1986, P3; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Nair V, 2023, Arxiv, DOI [arXiv:2303.17071, DOI 10.48550/ARXIV.2303.17071]; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Ngo R, 2022, Arxiv, DOI arXiv:2209.00626; OpenAI, 2022, Chatgpt: Optimizing language models for dialogue; OpenAI, 2023, Gpt-4 technical report, P1, DOI DOI 10.48550/ARXIV.2303.08774; Pan A, 2023, Arxiv, DOI [arXiv:2304.03279, 10.48550/arXiv.2304.03279, DOI 10.48550/ARXIV.2304.03279]; Park P. S., 2023, arXiv; PERNER J, 1985, J EXP CHILD PSYCHOL, V39, P437, DOI 10.1016/0022-0965(85)90051-7; PERNER J, 1987, BRIT J DEV PSYCHOL, V5, P125, DOI 10.1111/j.2044-835X.1987.tb01048.x; Radford A., 2019, Tech. Rep. GPT- 2; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Roff H., 2020, AI deception: When your artificial intelligence learns to lie; Schulz L., 2023, P 1 WORKSH THEOR MIN, P1; Searcy W.A., 2005, EVOLUTION ANIMAL COM; Shevlane T, 2023, Arxiv, DOI [arXiv:2305.15324, 10.48550/arXiv.2305.15324]; Steinhardt J., 2023, Emergent deception and emergent optimization; Wei A., 2023, arXiv; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; WHITEN A, 1988, BEHAV BRAIN SCI, V11, P233, DOI 10.1017/S0140525X00049682; WIMMER H, 1983, COGNITION, V13, P103, DOI 10.1016/0010-0277(83)90004-5; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Zhao Tony Z, 2021, arXiv	63	0	0	5	5	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUN 11	2024	121	24							e2317967121	10.1073/pnas.2317967121	http://dx.doi.org/10.1073/pnas.2317967121			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UL7F3	38833474	hybrid, Green Submitted			2024-07-03	WOS:001248272500004
C	Wang, FY; Shen, MH			IEEE	Wang, Fuyu; Shen, Minghua			Automatic Kernel Generation for Large Language Models on Deep Learning Accelerators	2023 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD	ICCAD-IEEE ACM International Conference on Computer-Aided Design		English	Proceedings Paper	42nd IEEE/ACM International Conference on Computer-Aided Design (ICCAD)	OCT 28-NOV 02, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery, IEEE Circuits & Syst Soc, IEEE Council Elect Design Automat, ACM Special Interest Grp Design Automat, Cadence, Synopsys, Futurewei Technologies, AMD, EMPYREAN, DoraHacks, Singular Med, JP Morgan Chase & Co				Large language model (LLM) is a promising trend to sustain accuracy growth with billions of parameters for various application domains. Deep learning (DL) accelerators that are typically designed in spatial architecture are potential platforms to handle the substantial computational demands of LLMs. Exploiting DL accelerators for LLMs require high-performance kernels, which are manually optimized or automatically generated. While prior automatic works reduce development costs, they fail to find optimal or near-optimal kernels. This is because the kernel design space is large containing many invalid kernels, and non-convex containing many local minima. In this paper, we propose an automatic kernel generation framework for large language models on deep learning accelerators. The key idea is the reinforcement learning (RL) formulation to generate a kernel with multi-step decision-making. We first develop a high-quality action space to satisfy architectural constraints of accelerator. Then, we provide a practical RL implementation by devising a policy network with Transformer and variance reduction techniques for gradients. Experimental results show our framework achieves average 3.5x speedup on TensorCore compared with exploration-based Ansor; 2.6x speedup on Simba compared with solver-based CoSA. Also, our framework achieves better energy efficiency compared to the state-of-the-art works.	[Wang, Fuyu; Shen, Minghua] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China	Sun Yat Sen University	Shen, MH (corresponding author), Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou, Peoples R China.	fuyuwang17@gmail.com; shenmh6@mail.sysu.edu.cn			National Key R&D Program of China [2022ZD0115304]; Natural Science Foundation of China [62072479]; Major Program of Guangdong Basic and Applied Research [2019B030302002]; Guangdong Natural Science Foundation [2021A1515011836]; Guangzhou Science and Technology Projects [202201011388]	National Key R&D Program of China; Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Major Program of Guangdong Basic and Applied Research; Guangdong Natural Science Foundation(National Natural Science Foundation of Guangdong Province); Guangzhou Science and Technology Projects	This work was supported by the National Key R&D Program of China under Grant NO. 2022ZD0115304, the Natural Science Foundation of China under Grant No. 62072479, the Major Program of Guangdong Basic and Applied Research under Grant No. 2019B030302002, the Guangdong Natural Science Foundation under Grant No. 2021A1515011836, and the Guangzhou Science and Technology Projects under Grant No. 202201011388. Minghua Shen is the corresponding author of this paper.	[Anonymous], 2019, Gpt-4 technical report; [Anonymous], GUROBI SOLVER; Bera R., 2021, P 54 ANN IEEEACM INT; Bi J., 2023, P 28 ACM INT C ARCHI; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen LL, 2021, ADV NEUR IN, V34; Chen SY, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476138; Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579; Chen TQ, 2018, ADV NEUR IN, V31; Chowdhery A., 2023, Palm: scaling language modeling with pathways; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Haarnoja T, 2018, PR MACH LEARN RES, V80; Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035; Han B., 2022, P INT C MACH LEARN I; Hegde K, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P943, DOI 10.1145/3445814.3446762; Huang QJ, 2021, CONF PROC INT SYMP C, P554, DOI 10.1109/ISCA52012.2021.00050; Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246; Kao SC, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P622, DOI 10.1109/MICRO50266.2020.00058; Kapturowski S., 2018, P INT C LEARN REPR I; Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252; Mnih V, 2016, PR MACH LEARN RES, V48; NVDLA, Tensor core; Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rengarajan D., 2022, P INT C LEARN REPR I; Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302; Singh G, 2022, CONF PROC INT SYMP C, P320, DOI 10.1145/3470496.3527442; Sutton RS, 2000, ADV NEUR IN, V12, P1057; Vaswani A, 2017, ADV NEUR IN, V30; Verdoolaege S, 2010, LECT NOTES COMPUT SC, V6327, P299, DOI 10.1007/978-3-642-15582-6_49; Zhai Y, 2023, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 2, ASPLOS 2023, P833, DOI 10.1145/3575693.3575737; Zhao J, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P1233, DOI 10.1145/3453483.3454106; Zheng LM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P863; Zheng Q., 2022, INT C MACHINE LEARNI, P27042; Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508	36	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1933-7760		979-8-3503-2225-5	ICCAD-IEEE ACM INT			2023										10.1109/ICCAD57390.2023.10323944	http://dx.doi.org/10.1109/ICCAD57390.2023.10323944			9	Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW2HI					2024-07-03	WOS:001116715100179
C	Yongsatianchot, N; Thejll-Madsen, T; Marsella, S			IEEE	Yongsatianchot, Nutchanon; Thejll-Madsen, Tobias; Marsella, Stacy			What's Next in Affective Modeling? Large Language Models	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS, ACIIW			English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			Large language model; Appraisal theory; Emotion theory; Affective Modeling	EMOTION	Large Language Models (LLM) have recently been shown to perform well at various tasks from language understanding, reasoning, storytelling, and information search to theory of mind. In an extension of this work, we explore the ability of GPT-4 to solve tasks related to emotion prediction. GPT-4 performs well across multiple emotion tasks; it can distinguish emotion theories and come up with emotional stories. We show that by prompting GPT-4 to identify key factors of an emotional experience, it is able to manipulate the emotional intensity of its own stories. Furthermore, we explore GPT-4's ability on reverse appraisals by asking it to predict either the goal, belief, or emotion of a person using the other two. In general, GPT-4 can make the correct inferences. We suggest that LLMs could play an important role in affective modeling; however, they will not fully replace works that attempt to model the mechanisms underlying emotion-related processes.	[Yongsatianchot, Nutchanon; Marsella, Stacy] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA; [Thejll-Madsen, Tobias] Univ Glasgow, Sch Psychol & Neurosci, Glasgow, Lanark, Scotland	Northeastern University; University of Glasgow	Yongsatianchot, N (corresponding author), Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.	nutjung.nutic@gmail.com; t.thejll-madsen.1@research.gla.ac.uk; s.marsella@northeastern.edu	Yongsatianchot, Nutchanon/KQV-3247-2024					Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Arnold M. B., 1960, Emotion and personality; Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; de Melo CM, 2014, J PERS SOC PSYCHOL, V106, P73, DOI 10.1037/a0034251; Ekman Paul, 1999, HDB COGNITION EMOTIO, P45, DOI [DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]; Hareli S., 2019, The Social Nature of Emotion Expression: What Emotions Can Tell Us About the World, P103; Hareli S, 2010, COGNITION EMOTION, V24, P128, DOI 10.1080/02699930802613828; Houlihan S. D., 2022, P ANN M COGNITIVE SC, V44; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Lazarus R.S., 1991, EMOTION ADAPTATION; LMSYS, 2023, Chatbot arena leaderboard; Mar RA, 2008, PERSPECT PSYCHOL SCI, V3, P173, DOI 10.1111/j.1745-6924.2008.00073.x; McKee R, 2003, HARVARD BUS REV, V81, P51; Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165; Oatley K., Why fiction may be twice as true as fact: Fiction as cognitive and emotional simulation, V3, P101; Oatley K, 2016, TRENDS COGN SCI, V20, P618, DOI 10.1016/j.tics.2016.06.002; Ong DC, 2019, TOP COGN SCI, V11, P338, DOI 10.1111/tops.12371; Ortony A., 1988, The cognitive structure of emotions; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Scherer K.R., 2001, Appraisal processes in emotion: Theory, methods, research, DOI DOI 10.1016/S0166-4115(08)62387-0; Vonnegut K, Palm Sunday; Wikipedia, 2023, Quidditch; Wu Y., 2014, P ANN M COGNITIVE SC, V36; Yongsatianchot N, 2016, LECT NOTES ARTIF INT, V9782, P234, DOI 10.1007/978-3-319-41649-6_23	28	0	0	3	3	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2745-8				2023										10.1109/ACIIW59127.2023.10388124	http://dx.doi.org/10.1109/ACIIW59127.2023.10388124			7	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IG		Green Submitted			2024-07-03	WOS:001161364800036
J	Aldawsari, HAH				Aldawsari, Hamad Abdullah H.			Evaluating Translation Tools: Google Translate, Bing Translator, and Bing AI on Arabic Colloquialisms	ARAB WORLD ENGLISH JOURNAL			English	Article						Arabic colloquial expressions; applied linguistics; Large Language Model systems; machine translation; Bing Translator; Bing AI Chat		This study examines the advancements in AI -driven machine translation, specifically focusing on the accurate translation of Arabic colloquial expressions. It aims to assess the progress made by Large Language Models, such as Bing AI Chat, compared to traditional machine translation systems. By focusing on colloquial expressions, this research aims to shed light on the challenges and opportunities for improvement in machine translation systems, particularly when dealing with the complexities of translating informal Arabic utterances. Building upon At-tall's 2019 thesis, which compared Google Translate and human translators, the study employs the same Arabic sentences as a test dataset, allowing for a direct comparison between 2019 translations and those produced by current machine translation tools. The findings indicate limited improvement in Google Translate since 2019, with Bing Translator exhibiting a similar level of translation accuracy. In contrast, Bing AI Chat consistently outperformed the other systems, showcasing the potential of Large Language Model machine translation. Notably, Bing AI Chat provided interpretations and valuable comments on the tested Arabic phrases, demonstrating a deeper understanding of the intended meaning. This study contributes significantly to the field of machine translation by providing evidence of the potential of Large Language Model systems in producing more accurate Arabic -English translations. It emphasizes the advantage of Large Language Models in dealing with non-standard Arabic expressions, encouraging further exploration of Large Language Model -powered approaches in machine translation. The findings offer a promising pathway towards achieving more accurate and expressive translations across diverse languages and cultures.	[Aldawsari, Hamad Abdullah H.] Prince Sattam bin AbdulAziz Univ, Coll Sci & Humanities, Dept English, Wadi Ad Dawasir, Saudi Arabia	Prince Sattam Bin Abdulaziz University	Aldawsari, HAH (corresponding author), Prince Sattam bin AbdulAziz Univ, Coll Sci & Humanities, Dept English, Wadi Ad Dawasir, Saudi Arabia.	h.alnawwar@psau.edu.sa						Al-Btoush M., 2014, International Journal of Linguistics, V6, P109, DOI [10.5296/ijl.v6i2.5086, DOI 10.5296/IJL.V6I2.5086]; Al-Jarf R., 2023, British Journal of Applied Linguistics, V3, P60, DOI [10.32996/bjal.2023.3.2.6, DOI 10.32996/BJAL.2023.3.2.6]; Al-Kharabsheh A., 2017, International Journal of Comparative Literature and Translation Studies, V5, P18, DOI [10.7575/aiac.ijclts.v.5n.3p.18, DOI 10.7575/AIAC.IJCLTS.V.5N.3P.18]; Al-Saidat E., 2011, Language Forum, V37, P59; Aldawsari H. A. H., 2023, Arab World English Journal for Translation & Literary Studies, V7, P19, DOI [10.24093/awejtls/vol7no3.2, DOI 10.24093/AWEJTLS/VOL7NO3.2]; Ali MA., 2020, Open J. Mod. Linguist, V10, P524, DOI [10.4236/ojml.2020.105030, DOI 10.4236/OJML.2020.105030]; Almahasees Z, 2022, ROU STUD TRANSL TECH, P1, DOI 10.4324/9781003191018; Alnamer A., 2018, International Journal of Applied Linguistics & English Literature, V7, P158, DOI [10.7575/aiac.ijalel.v.7n.3p.158, DOI 10.7575/AIAC.IJALEL.V.7N.3P.158]; Ameur MSH, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100305; At-tall S. M., 2019, Master's thesis; Banimelhem O., 2023, 2023 14 INT C INF CO, P1, DOI [10.1109/ICICS60529.2023.10330525, DOI 10.1109/ICICS60529.2023.10330525]; Boughorbel S, 2023, Arxiv, DOI [arXiv:2310.14819, 10.48550/arXiv.2310.14819, DOI 10.48550/ARXIV.2310.14819]; Habash N., 2012, P ACL HLT 2012 WORKS, P1; Harrat S, 2019, INFORM PROCESS MANAG, V56, P262, DOI 10.1016/j.ipm.2017.08.003; Huang Hui, 2023, Natural Language Processing and Chinese Computing: 12th National CCF Conference, NLPCC 2023, Proceedings. Lecture Notes in Computer Science, Lecture Notes in Artificial Intelligence (14302), P375, DOI 10.1007/978-3-031-44693-1_30; Hutchins J., 1992, An introduction to machine translation; Hutchins W. J., 2001, Early Years in Machine Translation, DOI [10.1075/sihols.97, DOI 10.1075/SIHOLS.97]; Jibreel I., 2023, Theory and Practice in Language Studies, V13, P1148, DOI [10.17507/tpls.1305.07, DOI 10.17507/TPLS.1305.07]; Joyce M, 2008, ANGLO-AMERICAN SUPPORT FOR JORDAN: THE CAREER OF KING HUSSEIN, P1, DOI 10.1057/9780230611641; Koehn P., 2010, Statistical machine translation, DOI DOI 10.1017/CBO9780511815829; Lee TK, 2023, APPL LINGUIST REV, DOI 10.1515/applirev-2023-0122; Morris B., 2001, Righteous victims: A history of the Zionist-Arab conflict, 1881-2001, DOI [10.7440/histcrit21.2001.12, DOI 10.7440/HISTCRIT21.2001.12]; Okpor MD., 2014, International Journal of Computer Science Issues (IJCSI), V11, P159, DOI DOI 10.20943/01201702.5457; Rinsum H., 2023, Agrarzeitung, V78, P10, DOI [10.51202/1869-9707-2023-39-010, DOI 10.51202/1869-9707-2023-39-010]; Susser Asher., 1994, On Both Banks of the Jordan: A Political Biography of Wasfi al-Tall; Zakraoui J, 2021, IEEE ACCESS, V9, P161445, DOI 10.1109/ACCESS.2021.3132488	26	0	0	0	0	ARAB WORLD ENGLISH JOURNAL	KUALA LUMPUR	JALAN 34-24 WANGSA MAJU, KUALA LUMPUR, 53300, MALAYSIA	2229-9327			ARAB WORLD ENGL J	Arab World Engl. J.	APR	2024					SI		237	251		10.24093/awej/ChatGPT.16	http://dx.doi.org/10.24093/awej/ChatGPT.16			15	Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	TZ3Y7					2024-07-03	WOS:001245053900017
C	Gu, Y; Cao, J; Guo, Y; Qian, SY; Guan, W		Monti, F; Rinderle-Ma, S; Cortes, AR; Zheng, Z; Mecella, M		Gu, Yang; Cao, Jian; Guo, Yuan; Qian, Shiyou; Guan, Wei			Plan, Generate and Match: Scientific Workflow Recommendation with Large Language Models	SERVICE-ORIENTED COMPUTING, ICSOC 2023, PT I	Lecture Notes in Computer Science		English	Proceedings Paper	21st International Conference on Service-Oriented Computing (ICSOC)	NOV 28-DEC 01, 2023	Rome, ITALY			Scientific Workflow Recommendation; Large Language Models; Planning; Prompting		The recommendation of scientific workflows from public repositories that meet users' natural language requirements is becoming increasingly essential in the scientific community. Nevertheless, existing methods that rely on direct text matching encounter difficulties when it comes to handling complex queries, which ultimately results in poor performance. Large language models (LLMs) have recently exhibited exceptional ability in planning and reasoning. We propose " Plan, Generate and Match" (PGM), a scientific workflow recommendation method leveraging LLMs. PGM consists of three stages: utilizing LLMs to conduct planning upon receiving a user query, generating a structured workflow specification guided by the solution steps, and using these plans and specifications to match with candidate workflows. By incorporating the planning mechanism, PGM leverages few-shot prompting to automatically generate well-considered steps for instructing the recommendation of reliable workflows. This method represents the first exploration of incorporating LLMs into the scientific workflow domain. Experimental results on real-world benchmarks demonstrate that PGM outperforms state-of-the-art methods with statistical significance, highlighting its immense potential in addressing complex requirements.	[Gu, Yang; Cao, Jian; Guo, Yuan; Qian, Shiyou; Guan, Wei] Shanghai Jiao Tong Univ, Shanghai, Peoples R China	Shanghai Jiao Tong University	Cao, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.	gu_yang@sjtu.edu.cn; cao-jian@sjtu.edu.cn; gy2022@sjtu.edu.cn; qshiyou@sjtu.edu.cn; guan-wei@sjtu.edu.cn		Guan, Wei/0000-0002-8979-6847	China National Science Foundation [62072301]; Program of Technology Innovation of the Science and Technology Commission of Shanghai Municipality [21511104700]	China National Science Foundation(National Natural Science Foundation of China (NSFC)); Program of Technology Innovation of the Science and Technology Commission of Shanghai Municipality	This work is supported by China National Science Foundation (No. 62072301) and the Program of Technology Innovation of the Science and Technology Commission of Shanghai Municipality (No. 21511104700).	Blanchi C, 2022, DATA INTELLIGENCE, V4, P173, DOI 10.1162/dint_a_00124; da Silva RF, 2020, PROCEEDINGS OF 15TH WORKSHOP ON WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS), P49, DOI 10.1109/WORKS51914.2020.00012; De Roure D, 2009, FUTURE GENER COMP SY, V25, P561, DOI 10.1016/j.future.2008.06.010; Djaffardjy M, 2023, COMPUT STRUCT BIOTEC, V21, P2075, DOI 10.1016/j.csbj.2023.03.003; Gu Y., 2023, IEEE Trans. Serv. Comput.; Gu Y., 2023, Concurrency Comput. Pract. Exp., pe7736; Jiang X, 2024, Arxiv, DOI arXiv:2303.06689; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053; Li H, 2022, ENERGY REP, V8, P4344, DOI 10.1016/j.egyr.2022.03.120; Lu P, 2023, Arxiv, DOI arXiv:2304.09842; OpenAI, 2023, GPT-4 Technical Report; Pallagani V, 2023, Arxiv, DOI arXiv:2305.16151; Starlinger J., 2016, Ph.D. thesis, DOI [10.18452/17406, DOI 10.18452/17406]; Starlinger J, 2014, PROC VLDB ENDOW, V7, P1143, DOI 10.14778/2732977.2732988; Wang L, 2023, Arxiv, DOI [arXiv:2305.04091, 10.48550/ARXIV.2305.04091]; Wang ZH, 2023, Arxiv, DOI [arXiv:2302.01560, 10.48550/arXiv.2302.01560]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wen YP, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/4129063; Woolson R. F., 2007, International Encyclopedia of Statistical Science, P1, DOI [10.1002/9780471462422.eoct979, DOI 10.1002/9780471462422.EOCT979]; Yao Y, 2023, Arxiv, DOI arXiv:2305.16582; Yasunaga Michihiro, 2022, LinkBERT: Pretraining Language Models with Document Links; Yu XM, 2020, IEEE WORLD CONGR SER, P89, DOI 10.1109/SERVICES48979.2020.00032; Zhou ZB, 2020, FUTURE GENER COMP SY, V112, P1141, DOI 10.1016/j.future.2020.05.029; Zhou ZB, 2018, IEEE T SERV COMPUT, V11, P169, DOI 10.1109/TSC.2016.2542805	25	0	0	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-48420-9; 978-3-031-48421-6	LECT NOTES COMPUT SC			2023	14419						86	102		10.1007/978-3-031-48421-6_7	http://dx.doi.org/10.1007/978-3-031-48421-6_7			17	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5FI					2024-07-03	WOS:001159757300007
J	Bran, AM; Cox, S; Schilter, O; Baldassari, C; White, AD; Schwaller, P				Bran, Andres M.; Cox, Sam; Schilter, Oliver; Baldassari, Carlo; White, Andrew D.; Schwaller, Philippe			Augmenting large language models with chemistry tools	NATURE MACHINE INTELLIGENCE			English	Article							TRANSFORMER; PREDICTION; DESIGN	Large language models (LLMs) have shown strong performance in tasks across domains but struggle with chemistry-related problems. These models also lack access to external knowledge sources, limiting their usefulness in scientific applications. We introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery and materials design. By integrating 18 expert-designed tools and using GPT-4 as the LLM, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our agent autonomously planned and executed the syntheses of an insect repellent and three organocatalysts and guided the discovery of a novel chromophore. Our evaluation, including both LLM and expert assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Our work not only aids expert chemists and lowers barriers for non-experts but also fosters scientific advancement by bridging the gap between experimental and computational chemistry. Large language models can be queried to perform chain-of-thought reasoning on text descriptions of data or computational tools, which can enable flexible and autonomous workflows. Bran et al. developed ChemCrow, a GPT-4-based agent that has access to computational chemistry tools and a robotic chemistry platform, which can autonomously solve tasks for designing or synthesizing chemicals such as drugs or materials.	[Bran, Andres M.; Schilter, Oliver; Schwaller, Philippe] Ecole Polytech Fed Lausanne, Lab Artificial Chem Intelligence LIAC, ISIC, Lausanne, Switzerland; [Bran, Andres M.; Schilter, Oliver; Schwaller, Philippe] Ecole Polytech Fed Lausanne, Natl Ctr Competence Res NCCR Catalysis, Lausanne, Switzerland; [Cox, Sam; White, Andrew D.] Univ Rochester, Dept Chem Engn, Rochester, NY 14627 USA; [Cox, Sam; White, Andrew D.] FutureHouse, San Francisco, CA 94107 USA; [Schilter, Oliver; Baldassari, Carlo] IBM Res Europe, Accelerated Discovery, CH-8803 Ruschlikon, Switzerland	Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; Swiss Federal Institutes of Technology Domain; Ecole Polytechnique Federale de Lausanne; University of Rochester	Schwaller, P (corresponding author), Ecole Polytech Fed Lausanne, Lab Artificial Chem Intelligence LIAC, ISIC, Lausanne, Switzerland.; Schwaller, P (corresponding author), Ecole Polytech Fed Lausanne, Natl Ctr Competence Res NCCR Catalysis, Lausanne, Switzerland.; White, AD (corresponding author), Univ Rochester, Dept Chem Engn, Rochester, NY 14627 USA.; White, AD (corresponding author), FutureHouse, San Francisco, CA 94107 USA.	andrew@futurehouse.org; philippe.schwaller@epfl.ch	Schwaller, Philippe/ABG-4328-2021	Schwaller, Philippe/0000-0003-3046-6576; White, Andrew/0000-0002-6647-3965; Schilter, Oliver Tobias/0000-0003-0310-0851	Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung (Swiss National Science Foundation) [180544]; NCCR Catalysis; National Centre of Competence in Research - Swiss National Science Foundation [1751471]; National Science Foundation [R35GM137966]; National Institute of General Medical Sciences of the National Institutes of Health	Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung (Swiss National Science Foundation)(Swiss National Science Foundation (SNSF)); NCCR Catalysis; National Centre of Competence in Research - Swiss National Science Foundation(Swiss National Science Foundation (SNSF)); National Science Foundation(National Science Foundation (NSF)); National Institute of General Medical Sciences of the National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute of General Medical Sciences (NIGMS))	A.M.B., O.S. and P.S. acknowledge support from NCCR Catalysis (grant no. 180544), a National Centre of Competence in Research funded by the Swiss National Science Foundation. S.C. and A.D.W. acknowledge support from the National Science Foundation under grant no. 1751471. Research reported in this work was supported by the National Institute of General Medical Sciences of the National Institutes of Health under award no. R35GM137966. We thank the wider RXN for Chemistry team for the support and for having granted limited access to the platform for the sole scope of executing the reported syntheses. We thank M. Lederbauer and J. Marulanda for helping with the illustrations in Fig. 1.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 2023, Purchasable Mcule; [Anonymous], 2023, RDKit: Open-Source Cheminformaticsn.d; [Anonymous], 2024, CHEM WEAPONS CONVENT; Askell A, 2019, Arxiv, DOI arXiv:1907.04534; Blaschke T, 2020, J CHEM INF MODEL, V60, P5918, DOI 10.1021/acs.jcim.0c00915; Boiko DA, 2023, NATURE, V624, P570, DOI 10.1038/s41586-023-06792-0; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Bran Andres M, 2024, Zenodo, DOI 10.5281/ZENODO.10884639; Bran Andres M, 2024, Zenodo, DOI 10.5281/ZENODO.10884645; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Campbell QL, 2023, Arxiv, DOI arXiv:2304.10510; Carey JS, 2006, ORG BIOMOL CHEM, V4, P2337, DOI 10.1039/b602413k; Chase H., 2022, Langchain; Chemical Abstracts Service, 2023, CAS registry number; ChemSpace, 2023, about us; Chiang W.-L., 2023, LMSYS Org; Chithrananda S, 2020, Arxiv, DOI arXiv:2010.09885; Chowdhery A, 2023, J MACH LEARN RES, V24; Coley CW, 2019, SCIENCE, V365, P557, DOI 10.1126/science.aax1566; Coley CW, 2019, CHEM SCI, V10, P370, DOI 10.1039/c8sc04228d; Coley CW, 2017, ACS CENTRAL SCI, V3, P434, DOI 10.1021/acscentsci.7b00064; de Neufville R, 2021, TECHNOL SOC, V66, DOI 10.1016/j.techsoc.2021.101649; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Gao L., 2023, INT C MACHINE LEARNI, P10835; Genheden S, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00472-1; Github Copilot, 2023, GitHub; Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572; Gómez-Bombarelli R, 2016, NAT MATER, V15, P1120, DOI [10.1038/NMAT4717, 10.1038/nmat4717]; Google search API, 2023, SerpApi; Grzybowski BA, 2023, WIRES COMPUT MOL SCI, V13, DOI 10.1002/wcms.1630; Hartenfeller M, 2011, J CHEM INF MODEL, V51, P3093, DOI 10.1021/ci200379p; Henderson P, 2023, Arxiv, DOI arXiv:2303.15715; Herrera RP, 2005, ANGEW CHEM INT EDIT, V44, P6576, DOI 10.1002/anie.200500227; Ho N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P14852; Hocky GM, 2022, DIGIT DISCOV, V1, P79, DOI 10.1039/d1dd00009h; Irwin JJ, 2020, J CHEM INF MODEL, V60, P6065, DOI 10.1021/acs.jcim.0c00675; Irwin R, 2022, MACH LEARN-SCI TECHN, V3, DOI 10.1088/2632-2153/ac3ffb; Jablonka KM, 2024, NAT MACH INTELL, V6, P122, DOI 10.1038/s42256-023-00788-1; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Joung J. F, 2020, DB for chromophore. figshare; Karpas E., 2022, arXiv; Lee AA, 2019, CHEM COMMUN, V55, P12152, DOI 10.1039/c9cc05122h; Li B., 2021, ACM Comput. Surv, V55, P146; Li R., 2023, Trans. Mach. Learn. Res; Liu Y., 2023, P 2023 C EMPIRICAL M, P2511; Lowe D. M., 2012, EXTRACTION CHEM STRU; Lowe DM, 2011, J CHEM INF MODEL, V51, P739, DOI 10.1021/ci100384d; Marra G, 2020, LECT NOTES ARTIF INT, V11907, P517, DOI 10.1007/978-3-030-46147-8_31; Mayr A, 2016, FRONT ENV SCI-SWITZ, V3, DOI 10.3389/fenvs.2015.00080; Medina J, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-023-00765-1; Molga K, 2021, ACCOUNTS CHEM RES, V54, P1094, DOI 10.1021/acs.accounts.0c00714; Mukherjee S, 2023, Arxiv, DOI arXiv:2306.02707; Namerxn (NextMove Software, 2023, about us; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; National Center for Biotechnology Information, 2023, PubChem; Neelakantan Arvind, 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.10005; Okino T, 2003, J AM CHEM SOC, V125, P12672, DOI 10.1021/ja036972z; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pesciullesi G, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18671-7; Press O., 2023, FINDINGS ASS COMPUTA, P5687; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Ramos MC, 2023, Arxiv, DOI [arXiv:2304.05341, DOI 10.48550/ARXIV.2304.05341]; RoboRXN, 2021, about us; Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t; RXN for Chemistry, 2020, rxn4Chemistry; Schick T., 2023, Advances in Neural Information Processing Systems, V36, P68539; Schreiner PR, 2002, ORG LETT, V4, P217, DOI 10.1021/ol017117s; Schwaller P, 2022, WIRES COMPUT MOL SCI, V12, DOI 10.1002/wcms.1604; Schwaller P, 2021, NAT MACH INTELL, V3, P144, DOI 10.1038/s42256-020-00284-w; Schwaller P, 2020, CHEM SCI, V11, P3316, DOI 10.1039/c9sc05704h; Schwaller P, 2019, ACS CENTRAL SCI, V5, P1572, DOI 10.1021/acscentsci.9b00576; Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978; Shen Y., 2023, Poster at Advances in Neural Information Processing Systems, V36; Shields BJ, 2021, NATURE, V590, P89, DOI 10.1038/s41586-021-03213-y; Szymkuc S, 2016, ANGEW CHEM INT EDIT, V55, P5904, DOI 10.1002/anie.201506101; Tanimoto T. T., 1958, An Elementary Mathematical Theory of Classification and Prediction; Tao QL, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00495-8; Thakkar A, 2021, REACT CHEM ENG, V6, P27, DOI 10.1039/d0re00340a; Thakkar A, 2020, J MED CHEM, V63, P8791, DOI 10.1021/acs.jmedchem.9b01919; Thakkar A, 2020, CHEM SCI, V11, P154, DOI 10.1039/c9sc04944d; The Australia Group, 2023, Australia Group common control lists: chemical weapons precursors; Torres JAG, 2022, J AM CHEM SOC, DOI 10.1021/jacs.2c08592; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Urbina F, 2022, NAT MACH INTELL, V4, P607, DOI 10.1038/s42256-022-00511-6; Urbina F, 2022, NAT MACH INTELL, V4, P189, DOI 10.1038/s42256-022-00465-9; van Tilborg D, 2022, J CHEM INF MODEL, V62, P5938, DOI 10.1021/acs.jcim.2c01073; Vaswani A, 2017, ADV NEUR IN, V30; Vaucher AC, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22951-1; Wei JS, 2022, ADV NEUR IN; Wellawatte GP, 2022, CHEM SCI, V13, P3697, DOI 10.1039/d1sc05259d; White A. D., 2023, Synspace; White Andrew D, 2023, Digit Discov, V2, P368, DOI 10.1039/d2dd00087c; Wittkopp A, 2003, CHEM-EUR J, V9, P407, DOI 10.1002/chem.200390042; Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a; Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237; Yang ZY, 2023, Arxiv, DOI [arXiv:2303.11381, 10.48550/arXiv.2303.11381]; Yao S, 2023, P 11 INT C LEARN REP; Zelikman Eric, 2022, Advances in Neural Information Processing Systems, V35, P15476; Zhao ZW, 2022, DIGIT DISCOV, V1, P266, DOI 10.1039/d2dd00004k; Ziegler Albert, 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P21, DOI 10.1145/3520312.3534864	103	3	3	12	12	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2522-5839		NAT MACH INTELL	Nat. Mach. Intell.	MAY	2024	6	5								10.1038/s42256-024-00832-8	http://dx.doi.org/10.1038/s42256-024-00832-8			13	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	RU9H2	38799228	hybrid			2024-07-03	WOS:001230286600004
C	Hensel, LB; Yongsatianchot, N; Torshizi, P; Minucci, E; Marsella, S			ACM	Hensel, Laura B.; Yongsatianchot, Nutchanon; Torshizi, Parisa; Minucci, Elena; Marsella, Stacy			Large language models in textual analysis for gesture selection	PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2023			English	Proceedings Paper	25th International Conference on Multimodal Interaction (ICMI)	OCT 09-13, 2023	Sorbonne Univ, Paris, FRANCE	Assoc Comp Machinery, ACM SIGCHI, Openstreams Ai, Living & Learning Lab Neurodevelopment, CCC Comp Community Consortium Catalyst, AFIHM, Persyval Lab, Grenoble Informat Lab, Univ Grenoble Alpes, Sorbonne Ctr Artificial Intelligence	Sorbonne Univ	gesture analysis; gesture selection; large language models	NONVERBAL BEHAVIOR	Gestures perform a variety of communicative functions that powerfully influence human face-to-face interaction. How this communicative function is achieved varies greatly between individuals and depends on the role of the speaker and the context of the interaction. Approaches to automatic gesture generation vary not only in the degree to which they rely on data-driven techniques but also the degree to which they can produce context and speaker specific gestures. However, these approaches face two major challenges: The first is obtaining sufficient training data that is appropriate for the context and the goal of the application. The second is related to designer control to realize their specific intent for the application. Here, we approach these challenges by using large language models (LLMs) to show that these powerful models of large amounts of data can be adapted for gesture analysis and generation. Specifically, we used ChatGPT as a tool for suggesting context-specific gestures that can realize designer intent based on minimal prompts. We also find that ChatGPT can suggests novel yet appropriate gestures not present in the minimal training data. The use of LLMs is a promising avenue for gesture generation that reduce the need for laborious annotations and has the potential to flexibly and quickly adapt to different designer intents.	[Hensel, Laura B.; Minucci, Elena; Marsella, Stacy] Univ Glasgow, Glasgow, Lanark, Scotland; [Yongsatianchot, Nutchanon; Torshizi, Parisa; Marsella, Stacy] Northeastern Univ, Boston, MA 02115 USA	University of Glasgow; Northeastern University	Hensel, LB (corresponding author), Univ Glasgow, Glasgow, Lanark, Scotland.	laura.hensel@glasgow.ac.uk; nutjung.nutlc@gmail.com; ghanadparisa@gmail.com; 2648114m@student.gla.ac.uk; stacymarsella@gmail.com	Yongsatianchot, Nutchanon/KQV-3247-2024	Marsella, Stacy/0000-0002-5711-7934; Minucci, Elena/0009-0005-4041-427X; Ghanad Torshizi, Parisa/0009-0006-6681-1932; Yongsatianchot, Nutchanon/0000-0003-1332-0727	EPSRC [EP/T021136/1, EP/S02266X/1]	EPSRC(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	The work in this article has been supported by EPSRC Grant Number EP/T021136/1 (LBH, SM) and UKRI CDT in Socially Intelligent Artifcial Agents, Grant Number EP/S02266X/1 (EM).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahuja C, 2022, PROC CVPR IEEE, P20534, DOI 10.1109/CVPR52688.2022.01991; Ahuja C, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1884; Allen J, 2020, Arxiv, DOI arXiv:2007.02670; Anthropic, 2023, CLAUDE; Ao TL, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555435; Bavelas J. B., 1994, Res. Lang. Soc. Interact., V27, P201, DOI DOI 10.1207/S15327973RLSI2703_3; Bergmann K., 2009, Proceedings of the 8th international conference on autonomous agents and multiagent systems, V1, P361; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Calbris G, 2011, GESTURE STUD, V5, P1; Casasanto D, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011805; Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315; Cassell J, 2004, COG TECH, P163; Cassell J., 2000, P FRST INT C NATURAL, P171, DOI [DOI 10.3115/1118253.1118277, 10.3115/1118253.1118277]; Chu MY, 2014, J EXP PSYCHOL GEN, V143, P694, DOI 10.1037/a0033861; Clough S, 2020, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.00323; DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ekman P., 1978, ENVIRON PSYCH NONVER, DOI [10.1037/t27734-000, DOI 10.1037/T27734-000]; Fares M, 2022, Arxiv, DOI [arXiv:2110.04527, DOI 10.48550/ARXIV.2110.04527]; Fares Mireille, 2023, Zero-Shot Style Transfer for Gesture Animation driven by Text and Speech using Adversarial Disentanglement of Multimodal Style Encoding; Foley Gretchen N, 2010, Psychiatry (Edgmont), V7, P38; Gao N, 2024, Arxiv, DOI arXiv:2303.13013; Ghorbani S, 2023, COMPUT GRAPH FORUM, V42, P206, DOI 10.1111/cgf.14734; Goldin-Meadow S, 2013, ANNU REV PSYCHOL, V64, P257, DOI 10.1146/annurev-psych-113011-143802; Google, 2023, Claude; Grady J., 1997, Foundations of meaning: primary metaphor and primary scenes; Guellaï B, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00700; HALL JA, 1995, APPL PREV PSYCHOL, V4, P21, DOI 10.1016/S0962-1849(05)80049-6; Hall K, 2016, HAU-J ETHNOGR THEORY, V6, P71, DOI 10.14318/hau6.2.009; Hostetter AB, 2011, PSYCHOL BULL, V137, P297, DOI 10.1037/a0022128; Ishi CT, 2018, IEEE ROBOT AUTOM LET, V3, P3757, DOI 10.1109/LRA.2018.2856281; Jamalian A., 2012, Proceedings of the 34th annual conference of the Cognitive Science Society, P503; Joty S, 2015, COMPUT LINGUIST, V41, P385, DOI 10.1162/COLI_a_00226; Kendon A, 1997, ANNU REV ANTHROPOL, V26, P109, DOI 10.1146/annurev.anthro.26.1.109; Kendon A., 2004, GESTURE VISIBLE ACTI; Kendon Adam, 1980, Nonverbal Communication and Language, P207; Kipp M., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1, DOI DOI 10.1109/ACII.2009.5349544; Kipp Michael, 2003, Gesture generation by imitation: from human behavior to computer character animation, DOI [10.22028/D291-25852, DOI 10.22028/D291-25852]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Kucherenko Taras, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P242, DOI 10.1145/3382507.3418815; Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243; Lhommet M, 2014, LECT NOTES ARTIF INT, V8637, P264, DOI 10.1007/978-3-319-09767-1_34; Marsella S., 2013, P 12 ACM SIGGRAPHEUR, P25, DOI DOI 10.1145/2485895.2485900; McNeill D, 2005, LECT NOTES COMPUT SC, V3869, P1; MCNEILL D, 1985, PSYCHOL REV, V92, P350, DOI 10.1037/0033-295X.92.3.350; McNeill D., 1992, HAND MIND WHAT GESTU; Xie SM, 2022, Arxiv, DOI [arXiv:2111.02080, 10.48550/arXiv.2111.02080]; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Mutinda FW, 2021, METHOD INFORM MED, V60, pE56, DOI 10.1055/s-0041-1731390; Nef Michael., 2016, Hand Gesture Synthesis for Conversational Characters, DOI [10.1007/978-3-319-30808-1_5-1, DOI 10.1007/978-3-319-30808-1_5-1]; Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516; Nyatsanga S, 2023, Arxiv, DOI arXiv:2301.05339; Ostermeier Terry H, 1997, Technical Report; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Özer D, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.573555; Peinelt N., 2020, P 58 ANN M ASS COMP, P7047, DOI [10.18653/v1/2020.acl-main.630, DOI 10.18653/V1/2020.ACL-MAIN.630]; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Ravenet B, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01144; Salem M, 2013, INT J SOC ROBOT, V5, P313, DOI 10.1007/s12369-013-0196-9; Salem M, 2012, INT J SOC ROBOT, V4, P201, DOI 10.1007/s12369-011-0124-9; Saund Carolyn, 2019, 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII). Proceedings, P524, DOI 10.1109/ACII.2019.8925435; Saund C, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667023; Seizer S, 2011, ANTHROPOL QUART, V84, P209, DOI 10.1353/anq.2011.0001; Thepsoonthorn C, 2021, INT J SOC ROBOT, V13, P1443, DOI 10.1007/s12369-020-00726-w; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tversky B, 2009, COGNITION, V110, P124, DOI 10.1016/j.cognition.2008.10.008; Wolfert Pieter, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P494, DOI 10.1145/3462244.3479889; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yoon Y, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417838; Yoon Y, 2019, IEEE INT CONF ROBOT, P4303, DOI [10.1109/ICRA.2019.8793720, 10.1109/icra.2019.8793720]	73	1	1	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0055-2				2023							378	387		10.1145/3577190.3614158	http://dx.doi.org/10.1145/3577190.3614158			10	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4GP		hybrid, Green Submitted			2024-07-03	WOS:001147764700046
J	Fan, HL; Liu, X; Fuh, JYH; Lu, WF; Li, BB				Fan, Haolin; Liu, Xuan; Fuh, Jerry Ying Hsi; Lu, Wen Feng; Li, Bingbing			Embodied intelligence in manufacturing: leveraging large language models for autonomous industrial robotics	JOURNAL OF INTELLIGENT MANUFACTURING			English	Article; Early Access						Large language models (LLMs) agents; Industrial robotics; Autonomous design; Decision-making; Embodied intelligence		This paper delves into the potential of Large Language Model (LLM) agents for industrial robotics, with an emphasis on autonomous design, decision-making, and task execution within manufacturing contexts. We propose a comprehensive framework that includes three core components: (1) matches manufacturing tasks with process parameters, emphasizing the challenges in LLM agents' understanding of human-imposed constraints; (2) autonomously designs tool paths, highlighting the LLM agents' proficiency in planar tasks and challenges in 3D spatial tasks; and (3) integrates embodied intelligence within industrial robotics simulations, showcasing the adaptability of LLM agents like GPT-4. Our experimental results underscore the distinctive performance of the GPT-4 agent, especially in Component 3, where it is outstanding in task planning and achieved a success rate of 81.88% across 10 samples in task completion. In conclusion, our study accentuates the transformative potential of LLM agents in industrial robotics and suggests specific avenues, such as visual semantic control and real-time feedback loops, for their enhancement.	[Fan, Haolin; Liu, Xuan; Fuh, Jerry Ying Hsi; Lu, Wen Feng; Li, Bingbing] Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore City 117575, Singapore; [Li, Bingbing] Calif State Univ Northridge, Dept Mfg Syst Engn & Management, Northridge, CA 91330 USA	National University of Singapore; California State University System; California State University Northridge	Li, BB (corresponding author), Natl Univ Singapore, Dept Mech Engn, 9 Engn Dr 1, Singapore City 117575, Singapore.; Li, BB (corresponding author), Calif State Univ Northridge, Dept Mfg Syst Engn & Management, Northridge, CA 91330 USA.	e0816265@u.nus.edu; xuanliu@u.nus.edu; jerry.fuh@nus.edu.sg; mpelwf@nus.edu.sg; bingbing.li@csun.edu	Li, Bingbing/A-7042-2011	Li, Bingbing/0000-0001-6140-4189; Liu, Xuan/0000-0002-7922-9451; Fuh, Jerry/0000-0002-5225-7460; Fan, Haolin/0000-0002-1808-2660	National University of Singapore Chongqing Research Institute; Project "The Sustainable Manufacturing Alliances for Research and Training Industry Assessment Center (The SMART IAC)" - U.S. Department of Energy's Office of Manufacturing and Energy Supply Chains [DE-EE0009726]	National University of Singapore Chongqing Research Institute; Project "The Sustainable Manufacturing Alliances for Research and Training Industry Assessment Center (The SMART IAC)" - U.S. Department of Energy's Office of Manufacturing and Energy Supply Chains	The two Ph.D. students Mr. Haolin Fan and Mr. Xuan Liu are supported by the National University of Singapore Chongqing Research Institute under the NUS Research Scholarship. This research is partially supported by the project "The Sustainable Manufacturing Alliances for Research and Training Industry Assessment Center (The SMART IAC)" funded by the U.S. Department of Energy's Office of Manufacturing and Energy Supply Chains (Award Number: DE-EE0009726). We acknowledge Prof. Larry Smarr and Dr. Ilkay Altintas from University of California San Diego for HyperCluster computing support of National Research Platform (NRP) Nautilus.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Anthropic, 2023, Technical report Anthropic; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bezrucav SO, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052319; Brohan A, 2023, Arxiv, DOI arXiv:2212.06817; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buerkle A, 2023, ROBOT CIM-INT MANUF, V81, DOI 10.1016/j.rcim.2022.102484; Capitanelli A, 2024, Arxiv, DOI arXiv:2303.00438; Chen JT, 2023, Arxiv, DOI [arXiv:2310.06646, 10.48550/arXiv.2310.06646, DOI 10.48550/ARXIV.2310.06646]; Chen M., 2021, arXiv; Chen PL, 2023, Arxiv, DOI arXiv:2308.01552; Choi D, 2021, LECT NOTES ARTIF INT, V13086, P216, DOI 10.1007/978-3-030-90525-5_19; Colas C., 2020, ADV NEURAL INFORM PR, V33, P3761; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Erwin C., 2016, Pybullet, a python module for physicssimulation for games, robotics and machine learning; Goel R., 2020, ROADMAP IND 40 SMART, P157, DOI DOI 10.1007/978-3-030-14544-6_9; Hägele M, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1385; Heuss L, 2023, J INTELL MANUF, DOI 10.1007/s10845-023-02211-3; Hoebert T, 2023, J INTELL MANUF, V34, P771, DOI 10.1007/s10845-021-01826-8; Hong S, 2023, Arxiv, DOI arXiv:2308.00352; Hu HY, 2022, J GRID COMPUT, V20, DOI 10.1007/s10723-022-09618-x; Huang CG, 2023, IEEE INT CONF ROBOT, P10608, DOI 10.1109/ICRA48891.2023.10160969; Huang SY, 2023, Arxiv, DOI arXiv:2305.11176; Huang W, 2023, P 6 C ROBOT LEARNING, P1769; Huang WL, 2023, Arxiv, DOI [arXiv:2307.05973, 10.48550/arXiv.2307.05973]; Huang WL, 2023, Arxiv, DOI arXiv:2303.00855; Huang WL, 2022, PR MACH LEARN RES; Jang E., 2022, C ROBOT LEARNING, P991; Jiang YD, 2019, Arxiv, DOI arXiv:1906.07343; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kollar T., 2014, Experimental robotics, P31; Kollar T, 2010, ACMIEEE INT CONF HUM, P259, DOI 10.1109/HRI.2010.5453186; Kwon M, 2023, Arxiv, DOI arXiv:2303.00001; Liang J, 2023, IEEE INT CONF ROBOT, P9493, DOI 10.1109/ICRA48891.2023.10160591; Liang K.-H., 2023, P 18 WORK INN US NLP, P83; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Luketina J, 2019, Arxiv, DOI arXiv:1906.03926; Misra D., 2017, ARXIV170408795, DOI DOI 10.18653/V1/D17-1106; Mu J., 2022, Advances in Neural Information Processing Systems, V35, P33947; Nair S., 2022, P MACHINE LEARNING R, P1303; Nascimento N, 2023, Arxiv, DOI arXiv:2307.06187; Neunzig C, 2023, J INTELL MANUF, DOI 10.1007/s10845-023-02214-0; Paul R, 2018, INT J ROBOT RES, V37, P1269, DOI 10.1177/0278364918777627; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Perzylo A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2293, DOI 10.1109/IROS.2016.7759358; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Poesia G, 2022, Arxiv, DOI [arXiv:2201.11227, 10.48550/ARXIV.2201.11227]; Raman SS, 2024, Arxiv, DOI arXiv:2211.09935; Ren PZ, 2024, Arxiv, DOI arXiv:2306.11335; Rovida F, 2017, Robot Operating System (ROS): The Complete Reference, V2, P121, DOI DOI 10.1007/978-3-319-54927-9_4; Shah D, 2023, C ROBOT LEARNING, P492; Sharma P, 2022, Arxiv, DOI arXiv:2204.05186; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Tellex S., 2011, AAAI, V25; Thomason J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1923; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wächter M, 2018, ROBOT AUTON SYST, V99, P148, DOI 10.1016/j.robot.2017.10.012; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Yang YT, 2023, Arxiv, DOI arXiv:2305.13267; Ye JJ, 2023, Arxiv, DOI arXiv:2303.10420; Yoneda T, 2024, Arxiv, DOI arXiv:2306.17840; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598; Zhang DY, 2024, Arxiv, DOI arXiv:2305.08144; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	69	1	1	87	87	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0956-5515	1572-8145		J INTELL MANUF	J. Intell. Manuf.	2024 JAN 9	2024										10.1007/s10845-023-02294-y	http://dx.doi.org/10.1007/s10845-023-02294-y		JAN 2024	17	Computer Science, Artificial Intelligence; Engineering, Manufacturing	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	EI2V7					2024-07-03	WOS:001138238100001
C	Wang, J; Wang, ZQ; Wang, H; Luo, W; Yuan, LW; Lü, GN; Yu, ZY		Sheng, B; Bi, L; Kim, J; Magnenat-Thalmann, N; Thalmann, D		Wang, Jian; Wang, Ziqiang; Wang, Han; Luo, Wen; Yuan, Linwang; Lu, Guonian; Yu, Zhaoyuan			Large Language Model for Geometric Algebra: A Preliminary Attempt	ADVANCES IN COMPUTER GRAPHICS, CGI 2023, PT IV	Lecture Notes in Computer Science		English	Proceedings Paper	40th Computer Graphics International Conference (CGI)	AUG 28-SEP 01, 2023	Shanghai, PEOPLES R CHINA	Shanghai Jiao Tong Univ		Large Language Model; Geometric Algebra; Geometric Algebra Learning		Geometric algebra serves as the unified language of mathematics, physics, and engineering in the 21st century. Coinciding with the era of artificial intelligence, the utilization of a Large Language Model (LLM) can significantly benefit the learning and application of geometric algebra. This study develops a representative application called PrivateGPT, based on the ggml-ggml-nous-gpt4-vicuna-13b model, to explore the integration of geometric algebra and LLM by building a knowledge base of geometric algebra expertise. The Geometric Algebra Knowledge Base was created by collecting 20,711 papers and data, categorizing them by topics. This application possesses the capability of iterative refinement, enhancing its understanding and reasoning of geometric algebra knowledge. It accomplishes the textual summarization of research content, methods, innovations, and conclusions. It facilitates the development of tailored learning plans for students from diverse fields to acquire knowledge of geometric algebra in their specific domains. Additionally, we compared the performance of PrivateGPT and ChatGPT in providing personalized learning paths for the same group of learners and evaluated their responses through a questionnaire survey. The results showed that PrivateGPT has an advantage in devising tailored learning plans for learners from various disciplines.	[Wang, Jian; Wang, Ziqiang; Wang, Han; Luo, Wen; Yuan, Linwang; Lu, Guonian; Yu, Zhaoyuan] Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Peoples R China; [Wang, Jian; Wang, Ziqiang; Wang, Han; Luo, Wen; Yuan, Linwang; Lu, Guonian; Yu, Zhaoyuan] Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China	Nanjing Normal University	Yu, ZY (corresponding author), Nanjing Normal Univ, Key Lab Virtual Geog Environm, Minist Educ, Nanjing 210023, Peoples R China.; Yu, ZY (corresponding author), Jiangsu Ctr Collaborat Innovat Geog Informat Reso, Nanjing 210023, Peoples R China.	yuzhaoyuan@njnu.edu.cn			National Natural Science Foundation of China [42130103, 42230406, 41930404]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	Supported by the National Natural Science Foundation of China (No. 42130103, 42230406 and 41930404).	Bauer E, 2023, BRIT J EDUC TECHNOL, DOI 10.1111/bjet.13336; Brants Thorsten, 2007, Large language models in machine translation; Breuils S, 2022, ADV APPL CLIFFORD AL, V32, DOI 10.1007/s00006-021-01196-7; Chromeextension, US; Colapinto P, 2016, Articulating space: geometric algebra for parametric design-symmetry, kinematics, and curvature; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dorst L., 2007, Geometric algebra for computer science (revised edition): An object-oriented approach to geometry; Hitzer E, 2013, ADV APPL CLIFFORD AL, V23, P377, DOI 10.1007/s00006-013-0378-4; Eid AH, 2017, Arxiv, DOI arXiv:1705.06668; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu S., 2021, arXiv; Kraus M, 2023, Arxiv, DOI [arXiv:2304.00116, DOI 10.48550/ARXIV.2304.00116]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lasenby J, 2000, PHILOS T ROY SOC A, V358, P21, DOI 10.1098/rsta.2000.0517; Lasenby J., 2011, Guide to Geometric Algebra in Practice, P371, DOI [10.1007/978-0-85729-811-9, DOI 10.1007/978-0-85729-811-9]; LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Lester B, 2021, Arxiv, DOI arXiv:2104.08691; Luo W, 2022, ADV APPL CLIFFORD AL, V32, DOI 10.1007/s00006-022-01229-9; Magnenat-Thalmann N, 2020, Advances in Computer Graphics, V1st, DOI [10.1007/978-3-030-89029-2, DOI 10.1007/978-3-030-89029-2]; Oh N, 2023, ANN SURG TREAT RES, V104, P269, DOI 10.4174/astr.2023.104.5.269; Sorin V, 2023, J CANCER RES CLIN, V149, P9505, DOI 10.1007/s00432-023-04824-w; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215	25	0	0	7	7	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-50078-7; 978-3-031-50077-0	LECT NOTES COMPUT SC			2024	14498						237	249		10.1007/978-3-031-50078-7_19	http://dx.doi.org/10.1007/978-3-031-50078-7_19			13	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4PC					2024-07-03	WOS:001152275000019
J	Jagannadharao, A; Beckage, N; Nafus, D; Chamberlin, S				Jagannadharao, Akshaya; Beckage, Nicole; Nafus, Dawn; Chamberlin, Scott			Timeshifting strategies for carbon-efficient long-running large language model training	INNOVATIONS IN SYSTEMS AND SOFTWARE ENGINEERING			English	Article; Early Access						Large language model (LLM); Energy consumption; Carbon-awareness; Timeshifting		Language models play a vital role in various natural language processing tasks, but their training can be computationally intensive and lead to significant carbon emissions. In this study, we explore the effectiveness of timeshifting strategies to mitigate the environmental impact of long-running large language models (LLMs). We develop a simulation tool that estimates carbon emissions for LLMs, enabling developers to make informed decisions prior to running their workloads. By leveraging historical carbon intensity data from WattTime, we investigate the potential benefits and limitations of timeshifting in different locations, considering diverse energy profiles. Our findings demonstrate that timeshifting can substantially reduce emissions, but it is highly dependent on the region's carbon intensity and energy mix. We present insights into the trade-offs between emissions reduction and workload runtime, acknowledging the need for further advancements in carbon-aware computing practices. Our research contributes to the growing field of sustainable computing and encourages developers to adopt environmentally conscious strategies in language model training.	[Jagannadharao, Akshaya; Chamberlin, Scott] Intel Corp, Software & Adv Technol Grp SATG, Mission Coll Blvd, Santa Clara, CA 95054 USA; [Beckage, Nicole; Nafus, Dawn] Intel Labs, Sociotech Syst, Hillsboro, OR 97124 USA	Intel Corporation; Intel Corporation	Jagannadharao, A (corresponding author), Intel Corp, Software & Adv Technol Grp SATG, Mission Coll Blvd, Santa Clara, CA 95054 USA.	akshaya.jagannadharao@intel.com; nicole.beckage@intel.com; dawn.nafus@intel.com; scott.chamberlin@intel.com						Antonello R, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1072; Bannour N., 2021, P 2 WORKSHOP SIMPLE, P11, DOI DOI 10.18653/V1/2021.SUSTAINLP-1.2; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; California Energy Commission, 2021, Total System Electric Generation; Cao QQ, 2020, Arxiv, DOI arXiv:2010.05248; Choromanski K, 2021, Arxiv, DOI arXiv:2009.14794; Dodge Jesse, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P1877, DOI 10.1145/3531146.3533234; EPA Clean Air Markes Program Data (CAMPD), Power plant emissions, compliance, and allowance data; EPA Office of Air and Radiation (OAR), 2015, Greenhouse Gas Equivalencies Calculator; Fedus W, 2022, J MACH LEARN RES, V23; Galvin R, 2015, ECOL ECON, V120, P23, DOI 10.1016/j.ecolecon.2015.08.020; github, CodeCarbon; Green Software Foundation, Green Software Practitioner: Carbon Awareness; Henderson P, 2020, J MACH LEARN RES, V21; Lacoste A, 2019, Arxiv, DOI [arXiv:1910.09700, 10.48550/arXiv.1910.09700]; Lannelongue L, 2021, ADV SCI, V8, DOI 10.1002/advs.202100707; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Patterson D, 2022, COMPUTER, V55, P18, DOI 10.1109/MC.2022.3148714; Radovanovic A, 2023, IEEE T POWER SYST, V38, P1270, DOI 10.1109/TPWRS.2022.3173250; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Stokel-Walker C, 2023, The Guardian; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693; Tay Y, 2022, Arxiv, DOI arXiv:2009.06732; Tiple V, 2020, the'AI white paper; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; USEPA O., 2022, Download data; WattTime, The Power to Choose Clean Energy; WattTime, Marginal Emissions Methodology	29	0	0	5	5	SPRINGER LONDON LTD	LONDON	236 GRAYS INN RD, 6TH FLOOR, LONDON WC1X 8HL, ENGLAND	1614-5046	1614-5054		INNOV SYST SOFTW ENG	Innov. Syst. Softw. Eng.	2023 DEC 19	2023										10.1007/s11334-023-00546-x	http://dx.doi.org/10.1007/s11334-023-00546-x		DEC 2023	15	Computer Science, Software Engineering	Emerging Sources Citation Index (ESCI)	Computer Science	CP6N8		Green Submitted, hybrid			2024-07-03	WOS:001126489800001
J	Bian, YF; Küster, D; Liu, H; Krumhuber, EG				Bian, Yifan; Kuester, Dennis; Liu, Hui; Krumhuber, Eva G.			Understanding Naturalistic Facial Expressions with Deep Learning and Multimodal Large Language Models	SENSORS			English	Review						automatic facial expression recognition; naturalistic context; deep learning; multimodal large language model	EMOTION; CONTEXT; FACE; RECOGNITION; DATABASE	This paper provides a comprehensive overview of affective computing systems for facial expression recognition (FER) research in naturalistic contexts. The first section presents an updated account of user-friendly FER toolboxes incorporating state-of-the-art deep learning models and elaborates on their neural architectures, datasets, and performances across domains. These sophisticated FER toolboxes can robustly address a variety of challenges encountered in the wild such as variations in illumination and head pose, which may otherwise impact recognition accuracy. The second section of this paper discusses multimodal large language models (MLLMs) and their potential applications in affective science. MLLMs exhibit human-level capabilities for FER and enable the quantification of various contextual variables to provide context-aware emotion inferences. These advancements have the potential to revolutionize current methodological approaches for studying the contextual influences on emotions, leading to the development of contextualized emotion models.	[Bian, Yifan; Krumhuber, Eva G.] UCL, Dept Expt Psychol, London WC1H 0AP, England; [Kuester, Dennis; Liu, Hui] Univ Bremen, Dept Math & Comp Sci, D-28359 Bremen, Germany	University of London; University College London; University of Bremen	Krumhuber, EG (corresponding author), UCL, Dept Expt Psychol, London WC1H 0AP, England.	yifan.bian.23@ucl.ac.uk; kuester@uni-bremen.de; hui.liu@uni-bremen.de; e.krumhuber@ucl.ac.uk	Liu, Hui/ACZ-9903-2022; Küster, Dennis/R-5928-2016	Liu, Hui/0000-0002-6850-9570; Küster, Dennis/0000-0001-8992-5648				Adamson LB, 2003, INFANCY, V4, P451, DOI 10.1207/S15327078IN0404_01; Alayrac J.-B., 2022, Advances in neural information processing systems, V35, P23716; [Anonymous], 2016, FACIAL EXPRESSION AN; Baltrusaitis T, 2016, IEEE WINT CONF APPL; Baltrusaitis T, 2018, IEEE INT CONF AUTOMA, P59, DOI 10.1109/FG.2018.00019; Barrett LF, 2022, AM PSYCHOL, V77, P894, DOI 10.1037/amp0001054; Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930; Bedi M, 2023, IEEE T AFFECT COMPUT, V14, P1363, DOI 10.1109/TAFFC.2021.3083522; Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600; Biel JI, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P53; Bishay M., 2023, P 2023 IEEE 17 INT C, P1; Broekens J, 2023, Arxiv, DOI arXiv:2309.01664; Büdenbender B, 2023, PLOS ONE, V18, DOI 10.1371/journal.pone.0281309; Bylsma LM, 2021, PSYCHOPHYSIOLOGY, V58, DOI 10.1111/psyp.13715; Cabitza F, 2022, BIG DATA SOC, V9, DOI 10.1177/20539517221129549; Chang CY, 2009, CIBCB: 2009 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN BIOINFORMATICS AND COMPUTATIONAL BIOLOGY, P278; Chang D, 2023, Arxiv, DOI arXiv:2308.10713; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Cheong JH, 2023, AFFECT SCI, V4, P781, DOI 10.1007/s42761-023-00191-4; Cohn JF, 2019, COMPUT VIS PATT REC, P407, DOI 10.1016/B978-0-12-814601-9.00026-2; Cowen AS, 2021, NATURE, V589, P251, DOI 10.1038/s41586-020-3037-7; Crivelli C, 2019, J NONVERBAL BEHAV, V43, P161, DOI 10.1007/s10919-019-00294-2; Cross MP, 2023, AFFECT SCI, V4, P500, DOI 10.1007/s42761-023-00195-0; Day SE, 2023, COGNITION EMOTION, V37, P1230, DOI 10.1080/02699931.2023.2258488; Delis I, 2016, J VISION, V16, DOI 10.1167/16.8.14; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Deng JK, 2019, Arxiv, DOI [arXiv:1905.00641, DOI 10.48550/ARXIV.1905.00641]; Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Du SC, 2015, DIALOGUES CLIN NEURO, V17, P443; Dupré D, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231968; EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068; Ekman P., 1978, Facial Action Coding System, V3, P5, DOI DOI 10.1708/1069.11717; Ertugrul Itir Onal, 2020, IEEE Trans Biom Behav Identity Sci, V2, P158, DOI [10.1109/TBIOM.2020.2977225, 10.1109/tbiom.2020.2977225]; Etesam Y, 2024, Arxiv, DOI arXiv:2310.19995; Fisher H, 2023, CLIN PSYCHOL SCI, DOI 10.1177/21677026231195793; FRANK MG, 1993, HUMOR, V6, P9, DOI 10.1515/humr.1993.6.1.9; Friesen W. V., 1983, Uni Cali SF; Gao JX, 2021, FRONT NEUROROBOTICS, V15, DOI 10.3389/fnbot.2021.763100; Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266; Girard JM, 2017, IEEE INT CONF AUTOMA, P581, DOI 10.1109/FG.2017.144; Gudi A, 2015, IEEE INT CONF AUTOMA; Guerdelli H, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041524; Hammal Z, 2015, IEEE T AFFECT COMPUT, V6, P361, DOI 10.1109/TAFFC.2015.2422702; Hasani B, 2017, IEEE INT CONF AUTOMA, P790, DOI 10.1109/FG.2017.99; He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Hinduja S., 2023, PyAFAR: Python-Based Automated Facial Action Recognition for Use in Infants and Adults; Irwantoro K, 2023, Q J EXP PSYCHOL, V76, P450, DOI 10.1177/17470218221094296; Karnati M, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3243661; Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453; Kim H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1221081; Kollias D, 2019, Arxiv, DOI [arXiv:1811.07770, DOI 10.48550/ARXIV.1811.07770]; Kosti R, 2020, IEEE T PATTERN ANAL, V42, P2755, DOI 10.1109/TPAMI.2019.2916866; Krumhuber EG, 2023, NAT REV PSYCHOL, V2, P283, DOI 10.1038/s44159-023-00172-1; Krumhuber EG, 2022, PERSPECT PSYCHOL SCI, V17, P1566, DOI 10.1177/17456916211071083; Krumhuber EG, 2023, CURR PSYCHOL, V42, P6077, DOI 10.1007/s12144-021-01910-5; Krumhuber EG, 2021, BEHAV RES METHODS, V53, P686, DOI 10.3758/s13428-020-01443-y; Kuster D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00400; Kurdi B, 2017, BEHAV RES METHODS, V49, P457, DOI 10.3758/s13428-016-0715-3; Kuster D, 2023, IEEE T AFFECT COMPUT, V14, P3001, DOI 10.1109/TAFFC.2022.3228749; Lange J, 2022, CURR OPIN PSYCHOL, V43, P85, DOI 10.1016/j.copsyc.2021.06.008; Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024; Li S, 2022, IEEE T AFFECT COMPUT, V13, P881, DOI 10.1109/TAFFC.2020.2973158; Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277; Lian Zheng, 2023, MM '23: Proceedings of the 31st ACM International Conference on Multimedia, P9610, DOI 10.1145/3581783.3612836; Lian Z, 2024, Arxiv, DOI arXiv:2306.15401; Lin CJ, 2023, AFFECT SCI, V4, P550, DOI 10.1007/s42761-023-00215-z; Liu HT, 2024, Arxiv, DOI arXiv:2310.03744; Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986; Pham L, 2021, INT C PATT RECOG, P4513, DOI 10.1109/ICPR48806.2021.9411919; Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462; Lucey P., 2010, 2010 IEEE COMPUTER S, P94, DOI [DOI 10.1109/CVPRW.2010.5543262, 10.1109/CVPRW.2010.5543262]; Lugaresi C., 2019, P 3 WORKSHOP COMPUTE, VVolume 2019; Luo RP, 2023, Arxiv, DOI arXiv:2306.07207; Luquetti DV, 2019, CLEFT PALATE-CRAN J, V56, P877, DOI 10.1177/1055665618821014; Lyons MJ., 1998, The Japanese female facial expression (JAFFE) database; Mason C, 2020, IEEE INT C INT ROBOT, P8997, DOI 10.1109/IROS45743.2020.9340706; Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182; Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4; McDuff D., 2016, P CHI C HUM FACT COM, P3723; McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130; McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20; Mesquita B, 2014, EMOT REV, V6, P298, DOI 10.1177/1754073914534480; Mollahosseini A, 2016, IEEE WINT CONF APPL; Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923; Namba S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124222; Ning Zhang, 2020, 2020 International Conference on Computer Network, Electronic and Automation (ICCNEA), P154, DOI 10.1109/ICCNEA50255.2020.00040; Onal Ertugrul I., 2019, P 2019 14 IEEE INT C; Radford A, 2021, PR MACH LEARN RES, V139; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Ren ZH, 2023, Arxiv, DOI arXiv:2309.06745; Rincon AV, 2023, ELIFE, V12, DOI 10.7554/eLife.87008; Sajjad M, 2023, ALEX ENG J, V68, P817, DOI 10.1016/j.aej.2023.01.017; Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6; Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682; Siddiqui MFH, 2022, MULTIMODAL TECHNOLOG, V6, DOI 10.3390/mti6060047; Skiendziel T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0223905; Srinivasan R, 2021, IEEE T AFFECT COMPUT, V12, P707, DOI 10.1109/TAFFC.2018.2887267; Stefanov Kalin, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P660, DOI 10.1145/3382507.3418832; Su YX, 2023, Arxiv, DOI arXiv:2305.16355; Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374; Valstar M.F., 2015, P 2015 11 IEEE INT C, VVolume 6, P1; Weber R, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P73, DOI 10.5220/0006553900730084; Wieser MJ, 2012, FRONT PSYCHOL, V3, DOI 10.3389/fpsyg.2012.00471; Xue FL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3581, DOI 10.1109/ICCV48922.2021.00358; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Yin SK, 2023, Arxiv, DOI arXiv:2306.13549; Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577; Zhang H, 2023, Arxiv, DOI [arXiv:2306.02858, 10.48550/arXiv.2306.02858, DOI 10.48550/ARXIV.2306.02858]; Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002; Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1; Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374; Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592; Zhu Q, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.116046	116	3	3	34	34	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1424-8220		SENSORS-BASEL	Sensors	JAN	2024	24	1							126	10.3390/s24010126	http://dx.doi.org/10.3390/s24010126			15	Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments & Instrumentation	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Instruments & Instrumentation	EQ4Z3	38202988	gold			2024-07-03	WOS:001140389700001
J	Schwitzgebel, E; Schwitzgebel, D; Strasser, A				Schwitzgebel, Eric; Schwitzgebel, David; Strasser, Anna			Creating a large language model of a philosopher	MIND & LANGUAGE			English	Article						artificial intelligence; Daniel C; Dennett; human-machine discrimination; language models; philosophical expertise	GO	Can large language models produce expert-quality philosophical texts? To investigate this, we fine-tuned GPT-3 with the works of philosopher Daniel Dennett. To evaluate the model, we asked the real Dennett 10 philosophical questions and then posed the same questions to the language model, collecting four responses for each question without cherry-picking. Experts on Dennett's work succeeded at distinguishing the Dennett-generated and machine-generated answers above chance but substantially short of our expectations. Philosophy blog readers performed similarly to the experts, while ordinary research participants were near chance distinguishing GPT-3's responses from those of an "actual human philosopher".	[Schwitzgebel, Eric] Univ Calif Riverside, Dept Philosophy, Riverside, CA USA; [Schwitzgebel, David] Univ Paris Sci & Lettres, Ecole Normale Super, Inst Jean Nicod, Paris, France; [Strasser, Anna] Ludwig Maximilians Univ Munchen, Fac Philosophy, Munich, Germany; [Strasser, Anna] DenkWerkstatt Berlin, Berlin, Germany; [Schwitzgebel, Eric] Univ Calif Riverside, Dept Philosophy, Riverside, CA 92521 USA	University of California System; University of California Riverside; Universite PSL; Ecole Normale Superieure (ENS); University of Munich; University of California System; University of California Riverside	Schwitzgebel, E (corresponding author), Univ Calif Riverside, Dept Philosophy, Riverside, CA 92521 USA.	eschwitz@ucr.edu		Strasser, Anna/0000-0002-3547-9790; Schwitzgebel, David/0000-0001-9323-767X				Alshemali B, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105210; Andreas J., 2022, LANGUAGE MODELS AGEN, DOI DOI 10.48550/ARXIV.2212.01681; Araoz M., 2021, INTERVIEWING A EINST; Ardila D, 2019, NAT MED, V25, P954, DOI 10.1038/s41591-019-0447-x; Assael Y., 2016, LIPNET SENTENCE LEVE, DOI DOI 10.48550/ARXIV.1611.01599; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berwick RC, 2011, COGNITIVE SCI, V35, P1207, DOI 10.1111/j.1551-6709.2011.01189.x; Bosio A, 2019, 2019 20TH IEEE LATIN AMERICAN TEST SYMPOSIUM (LATS); Brown N, 2019, SCIENCE, V365, P885, DOI 10.1126/science.aay2400; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brownlee J., 2019, Machine Learning Mastery; Buckner C., 2019, CONNECTIONISM; Butlin P, 2023, ERKENNTNIS, V88, P3079, DOI 10.1007/s10670-021-00491-w; Campbell M, 2002, ARTIF INTELL, V134, P57, DOI 10.1016/S0004-3702(01)00129-1; Chomsky N, 2007, INT J PHILOS STUD, V15, P1, DOI 10.1080/09672550601143078; Clark Elizabeth., All That's'Human' Is Not Gold: Evaluating Human Evaluation of Generated Text, P2021, DOI [DOI 10.48550/ARXIV.2107.00061, 10.48550/ARXIV.2107.00061]; Clarke D., 2022, CHAT GPT 3 ITS OWN W; Cukier K., 2022, ECONOMIST; Daly R., 2021, NME; Davidson D., 1984, INQUIRIES TRUTH INTE; Descartes R., 1649, PHILOS WRITINGS DESC, VI-III; Dou Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7250; Dugan L., 2020, ROFT TOOL EVALUATING, DOI DOI 10.48550/ARXIV.2010.03070; Elgammal A., 2021, CONVERSATION; Epstein R., 2009, PARSING TURING TEST, DOI [DOI 10.1007/978-1-4020-6710-5, 10.1007/978-1-4020-6710-5]; European Commission, 2021, AI ACT PROP REG EUR; Fawzi A., 2022, DISCOVERING NOVEL AL; Frankish K., 2022, BLOG POST TRICKS MIN; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; github, GITHUB COP; Government UK Consultations, 2021, ARTIF INTELL; Hadjeres G, 2017, PR MACH LEARN RES, V70; Harnad S., 2003, TURING TEST STUDIES, P253, DOI [10.1007/978-94-010-0105-2_14, DOI 10.1007/978-94-010-0105-2_14]; Herman Daniel., 2022, The Atlantic; Hilario M., 1995, OVERVIEW STRATEGIES; Hofstadter D., 2022, ARTIFICIAL NEURAL NE; Huang K., 2023, The New York Times; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Klein E., 2022, NY TIMES; Li B. Z., 2021, ANN M ASS COMP LING; Loebner H., 2009, PARSING TURING TEST, P173, DOI [10.1007/978-1-4020-6710-5_12, DOI 10.1007/978-1-4020-6710-5_12]; Mahdawi A., 2020, GUARDIAN; Mahian O, 2017, PUBLICATIONS, V5, DOI 10.3390/publications5030018; Mahowald K., 2023, DISSOCIATING LANGUAG, DOI DOI 10.48550/ARXIV.2301.06627; Marche S., 2022, The Atlantic; Marcus G., 2020, Technology Review; Marcus G., 2022, Scientific American; Marcus G., 2023, LARGE LANGUAGE MODEL; Michael J., 2022, WHAT NLP RES BELIEVE, DOI DOI 10.48550/ARXIV.2208.12852; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Nakayama H, 2023, ANN VASC SURG, V88, P308, DOI 10.1016/j.avsg.2022.06.008; Novikova Jekaterina, 2017, P 2017 C EMPIRICAL M, P2241, DOI DOI 10.18653/V1/D17-1238; Roberts M., 2022, WASHINGTON POST; Rodriguez S, CHOM5KY VS CHOMSKY P; Schmidt D., 2015, GUIDE NGRAM PACKAGE; Schneider Susan., 2019, Artificial You; Schwitzgebel E., 2021, BLOG POST SPLINTERED; Shanahan M., 2023, TALKING LARGE LANGUA, DOI DOI 10.48550/ARXIV.2212.03551; Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404; Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961; Sobieszek A, 2022, MIND MACH, V32, P341, DOI 10.1007/s11023-022-09602-0; Steven J., 2022, NY TIMES; Strasser A., 2022, SOCIAL ROBOTICS GOOD, P77, DOI [10.1515/9783839462652-004, DOI 10.1515/9783839462652-004]; Strasser A., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2303.1751; Strasser A, 2022, FRONT ARTIF INTEL AP, V366, P371, DOI 10.3233/FAIA220637; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Thoppilan R., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2201.08239; Tiku T., 2022, WASHINGTON POST; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Webb T., 2022, EMERGENT ANALOGICAL, DOI DOI 10.48550/ARXIV.2212.09196; Wedinger L., 2021, ARXIV; Wiseman H., 2020, FACEBOOK POST; Wubben S., 2019, P 12 INT C NAT LANG; Zimmerman A., 2020, BLOG POST DAILY NOUS	75	6	6	10	24	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0268-1064	1468-0017		MIND LANG	Mind Lang.	APR	2024	39	2					237	259		10.1111/mila.12466	http://dx.doi.org/10.1111/mila.12466		JUL 2023	23	Linguistics; Psychology, Experimental	Social Science Citation Index (SSCI)	Linguistics; Psychology	NA3F2		Green Submitted, hybrid			2024-07-03	WOS:001023926500001
J	Lu, RS; Lin, CC; Tsao, HY				Lu, Ruei-Shan; Lin, Ching-Chang; Tsao, Hsiu-Yuan			Empowering Large Language Models to Leverage Domain-Specific Knowledge in E-Learning	APPLIED SCIENCES-BASEL			English	Article						LLM; domain-specific knowledge; E-learning		Large language models (LLMs) have demonstrated remarkable capabilities in various natural language processing tasks. However, their performance in domain-specific contexts, such as E-learning, is hindered by the lack of specific domain knowledge. This paper adopts a novel approach of retrieval augment generation to empower LLMs with domain-specific knowledge in the field of E-learning. The approach leverages external knowledge sources, such as E-learning lectures or research papers, to enhance the LLM's understanding and generation capabilities. Experimental evaluations demonstrate the effectiveness and superiority of our approach compared to existing methods in capturing and generating E-learning-specific information.	[Lu, Ruei-Shan] Takming Univ Sci & Technol, Dept Management Informat Syst, Taipei 114, Taiwan; [Lin, Ching-Chang] Taipei City Univ Sci & Technol, Dept Business Adm, Taipei 112, Taiwan; [Tsao, Hsiu-Yuan] Natl Chung Hsing Univ, Dept Mkt, Taichung 402, Taiwan	Takming University Science & Technology; National Chung Hsing University	Lin, CC (corresponding author), Taipei City Univ Sci & Technol, Dept Business Adm, Taipei 112, Taiwan.	rslu@takming.edu.tw; cclin@ba.tpcu.edu.tw; jodytsao@dragon.nchu.edu.tw						Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Lin W., 2022, P 2022 C EMP METH NA; Mikolov T., 2013, P 27 C NEUR INF PROC; Ooi KB, 2023, J COMPUT INFORM SYST, DOI 10.1080/08874417.2023.2261010; Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191; Rocktschel T., 2020, P 34 C NEUR INF PROC; Tsao HY, 2022, IND MARKET MANAG, V106, P90, DOI 10.1016/j.indmarman.2022.08.007; VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369; Vaswani A., 2017, Advances in neural information processing systems, P6000; Zhang T., 2020, INT C LEARNING REPRE	11	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	JUN	2024	14	12							5264	10.3390/app14125264	http://dx.doi.org/10.3390/app14125264			15	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	WJ5K7		gold			2024-07-03	WOS:001254514400001
J	Cao, TF; Chen, L; Zhang, DX; Sun, TX; He, ZF; Qiu, XP; Xu, X; Zhang, H				Cao, Tingfeng; Chen, Liang; Zhang, Dixiang; Sun, Tianxiang; He, Zhengfu; Qiu, Xipeng; Xu, Xing; Zhang, Hai			Competition for gradient-free tuning of large language models: approaches, results, current challenges and future directions	NATIONAL SCIENCE REVIEW			English	Editorial Material								This perspective presents a brief overview of the background of Gradient-free tuning for large language models competition, the championship scheme, as well as the challenges and future directions.	[Cao, Tingfeng; Chen, Liang; Zhang, Dixiang] South China Univ Technol, Sch Software Engn, Guangzhou, Peoples R China; [Sun, Tianxiang; He, Zhengfu; Qiu, Xipeng] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China; [Xu, Xing] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu, Peoples R China; [Zhang, Hai] Northwest Univ, Sch Math, Xian, Peoples R China; [Zhang, Hai] Pazhou Lab Huangpu, Guangzhou, Peoples R China	South China University of Technology; Fudan University; University of Electronic Science & Technology of China; Northwest University Xi'an; Pazhou Lab	Qiu, XP (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.; Zhang, H (corresponding author), Northwest Univ, Sch Math, Xian, Peoples R China.; Zhang, H (corresponding author), Pazhou Lab Huangpu, Guangzhou, Peoples R China.	xpqiu@fudan.edu.cn; zhanghai@nwu.edu.cn	Sun, Tianxiang/AAA-7123-2022	Sun, Tianxiang/0000-0001-8291-820X	National Natural Science Foundation of China [62236004, 62022027]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	This work was supported by the National Natural Science Foundation of China (62236004 and 62022027).	Ben-Zaken E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P1; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Hansen N, 2003, EVOL COMPUT, V11, P1, DOI 10.1162/106365603321828970; Houlsby N, 2019, PR MACH LEARN RES, V97; Krishna K., 2020, 8 INT C LEARNING REP; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Sun T., 2022, PROC EMNLP, P3916; Sun T., 2022, PROC ICML, P20841; Zhao TZ, 2021, PR MACH LEARN RES, V139	10	1	2	5	8	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	2095-5138	2053-714X		NATL SCI REV	Natl. Sci. Rev.	MAY 10	2023	10	6							nwad124	10.1093/nsr/nwad124	http://dx.doi.org/10.1093/nsr/nwad124			4	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	K3FH2	37342318	Green Published, gold			2024-07-03	WOS:001015324100003
J	Caglayan, A; Slusarczyk, W; Rabbani, RD; Ghose, A; Papadopoulos, V; Boussios, S				Caglayan, Aydin; Slusarczyk, Wojciech; Rabbani, Rukhshana Dina; Ghose, Aruni; Papadopoulos, Vasileios; Boussios, Stergios			Large Language Models in Oncology: Revolution or Cause for Concern?	CURRENT ONCOLOGY			English	Review						artificial intelligence; oncology; machine learning; deep learning; natural language processing	ARTIFICIAL-INTELLIGENCE; MEDICINE	The technological capability of artificial intelligence (AI) continues to advance with great strength. Recently, the release of large language models has taken the world by storm with concurrent excitement and concern. As a consequence of their impressive ability and versatility, their provide a potential opportunity for implementation in oncology. Areas of possible application include supporting clinical decision making, education, and contributing to cancer research. Despite the promises that these novel systems can offer, several limitations and barriers challenge their implementation. It is imperative that concerns, such as accountability, data inaccuracy, and data protection, are addressed prior to their integration in oncology. As the progression of artificial intelligence systems continues, new ethical and practical dilemmas will also be approached; thus, the evaluation of these limitations and concerns will be dynamic in nature. This review offers a comprehensive overview of the potential application of large language models in oncology, as well as concerns surrounding their implementation in cancer care.	[Caglayan, Aydin; Rabbani, Rukhshana Dina; Ghose, Aruni; Boussios, Stergios] Medway NHS Fdn Trust, Dept Med Oncol, Gillingham ME7 5NY, England; [Slusarczyk, Wojciech; Boussios, Stergios] Univ Kent, Kent Medway Med Sch, Canterbury CT2 7LX, Kent, England; [Ghose, Aruni] St Bartholomews Hosp, Barts Canc Ctr, Barts & London NHS Trust, Dept Diagnost Imaging, London EC1A 7BE, England; [Ghose, Aruni] Mt Vernon Canc Ctr, Dept Med Oncol, East & North Hertfordshire Trust, London HA6 2RN, England; [Ghose, Aruni] European Canc Org, Hlth Syst & Treatment Optimisat Network, B-1040 Brussels, Belgium; [Ghose, Aruni] Oncol Council, Royal Soc Med, London W1G 0AE, England; [Papadopoulos, Vasileios] Kent & Canterbury Hosp, Canterbury CT1 3NG, Kent, England; [Boussios, Stergios] Kings Coll London, Sch Canc & Pharmaceut Sci, Strand Campus, London WC2R 2LS, England; [Boussios, Stergios] Canterbury Christ Church Univ, Fac Med Hlth & Social Care, Canterbury CT2 7PB, Kent, England; [Boussios, Stergios] AELIA Org, 9th Km Thessaloniki-Thermi, Thessaloniki 57001, Greece	University of Kent; Barts Health NHS Trust; University of London; Queen Mary University London; Mount Vernon Cancer Centre; University of Kent; University of London; King's College London; Canterbury Christ Church University	Boussios, S (corresponding author), Medway NHS Fdn Trust, Dept Med Oncol, Gillingham ME7 5NY, England.; Boussios, S (corresponding author), Univ Kent, Kent Medway Med Sch, Canterbury CT2 7LX, Kent, England.; Boussios, S (corresponding author), Kings Coll London, Sch Canc & Pharmaceut Sci, Strand Campus, London WC2R 2LS, England.; Boussios, S (corresponding author), Canterbury Christ Church Univ, Fac Med Hlth & Social Care, Canterbury CT2 7PB, Kent, England.; Boussios, S (corresponding author), AELIA Org, 9th Km Thessaloniki-Thermi, Thessaloniki 57001, Greece.	aydin.caglayan@nhs.net; ojciech.slusarczyk@nhs.net; rukhshana.rabbani@nhs.net; aruni.ghose1@gmail.com; papadoster@gmail.com; stergiosboussios@gmail.com		GHOSE, ARUNI/0000-0001-8332-8033; Slusarczyk, Wojciech/0009-0006-5865-4586; Boussios, Stergios/0000-0002-2512-6131				Ahmad MA, 2023, Arxiv, DOI arXiv:2311.01463; Almarie Bassel, 2023, Princ Pract Clin Res, V9, P1, DOI 10.21801/ppcrj.2023.91.1; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; [Anonymous], 2017, HIPAA PROFESSIONALS; [Anonymous], What is natural language processing?; anthropic, Anthropic-Claude Meet Claude; Becker G, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-94; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Blum J, 2023, TRENDS CANCER, V9, P788, DOI 10.1016/j.trecan.2023.06.007; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Cadamuro J, 2023, CLIN CHEM LAB MED, V61, P1158, DOI 10.1515/cclm-2023-0355; Calixte R, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17186856; Cao JJ, 2023, AM J ROENTGENOL, V221, P556, DOI 10.2214/AJR.23.29493; Cao ZH, 2021, IEEE T NEUR NET LEAR, V32, P5369, DOI 10.1109/TNNLS.2021.3084198; Cascella Marco, 2023, J Anesth Analg Crit Care, V3, P33, DOI 10.1186/s44158-023-00118-2; chat.openai, OpenAI ChatGPT; ClinicalTrials.gov, Treatment Recommendations for Gastrointestinal Cancers via Large Language Models; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Cowan J.D., 1990, Advances in Neural Information Processing Systems 2. Neural Networks: The Early Days; da Silva LM, 2021, J PATHOL, V254, P147, DOI 10.1002/path.5662; de Sio FS, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00015; EIT Digital, A European Approach to Artificial Intelligence a Policy Perspective; Es S, 2023, Arxiv, DOI arXiv:2309.15217; European Data Protection Board, EDPB Resolves Dispute on Transfers by Meta and Creates Task Force on Chat GPT; Fine T.L., 1999, Feedforward Neural Network Methodology, V3rd ed., DOI [DOI 10.1007/B97705, 10.1007/b97705]; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Floridi L., 2020, PHILOS TECHNOLOGY, V33, P1, DOI [DOI 10.1007/S13347-020-00396-6, 10.1007/s13347-020-00396-6]; Gierman HJ, 2019, J CLIN ONCOL, V37, DOI 10.1200/JCO.2019.37.15_suppl.1585; Google Bard, about us; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Hamel LM, 2016, CANCER CONTROL, V23, P327, DOI 10.1177/107327481602300404; Haug CJ, 2023, NEW ENGL J MED, V388, P1201, DOI 10.1056/NEJMra2302038; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Heston TF., 2023, Int. Med. Educ., V2, P198, DOI [DOI 10.3390/IME2030019, 10.3390/ime2030019]; Hille EM, 2023, J MED ETHICS, DOI 10.1136/jme-2023-109095; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; IBM, What Are Large Language Models?; IBM, AI vs. Machine Learning vs. Deep Learning vs. Neural Networks: What's the Difference?; IBM, What Are AI Hallucinations?; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Kanan C, 2020, J CLIN ONCOL, V38; Karkera N, 2023, BMC BIOINFORMATICS, V24, DOI 10.1186/s12859-023-05411-z; Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040; Khan Bangul, 2023, Biomed Mater Devices, P1, DOI 10.1007/s44174-023-00063-2; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Liu JL, 2023, J MED INTERNET RES, V25, DOI 10.2196/48568; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Massion PP, 2020, AM J RESP CRIT CARE, V202, P241, DOI 10.1164/rccm.201903-0505OC; Meskó B, 2023, J MED INTERNET RES, V25, DOI 10.2196/50638; Mitchell M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2215907120; Mithany RH, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.47924; MosaicML BioMedLM, A Domain-Specific Large Language Model for Biomedical Text; National Cyber Security Centre, ChatGPT and Large Language Models: What's the Risk?; Nyariro M, 2023, BMJ OPEN, V13, DOI 10.1136/bmjopen-2023-072069; openai, OpenAI Introducing GPTs; Oustimov A, 2014, TRANSL CANCER RES, V3, P191, DOI 10.3978/j.issn.2218-676X.2014.05.01; Pan A, 2023, JAMA ONCOL, V9, P1437, DOI 10.1001/jamaoncol.2023.2947; Parikh RB, 2019, JAMA-J AM MED ASSOC, V322, P2377, DOI 10.1001/jama.2019.18058; perplexity, Perplexity Perplexity AI; Pun FW, 2023, TRENDS PHARMACOL SCI, V44, P561, DOI 10.1016/j.tips.2023.06.010; Rajpurkar P, 2023, NEW ENGL J MED, V388, P1981, DOI 10.1056/NEJMra2301725; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Rassy E, 2020, CRIT REV ONCOL HEMAT, V147, DOI 10.1016/j.critrevonc.2020.102882; Renze M, 2024, Arxiv, DOI arXiv:2402.05201; research.ibm, IBM What Is Generative AI?; Saadé RG, 2012, COMPUT HUM BEHAV, V28, P1608, DOI 10.1016/j.chb.2012.03.025; Sadasivan VS, 2024, Arxiv, DOI [arXiv:2303.11156, 10.48550/arXiv.2303.11156]; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Schukow C, 2024, ADV ANAT PATHOL, V31, P15, DOI 10.1097/PAP.0000000000000406; Schulte B, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37938; SCHWARTZ WB, 1987, NEW ENGL J MED, V316, P685, DOI 10.1056/NEJM198703123161109; Shreve Jacob T, 2022, Am Soc Clin Oncol Educ Book, V42, P1, DOI 10.1200/EDBK_350652; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Srivastav S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.41435; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Tran KA, 2021, GENOME MED, V13, DOI 10.1186/s13073-021-00968-x; Turing A.M., 1950, MIND, VLIX, P433, DOI [10.1093/MIND/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1093/mind/lix.236.433]; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; US Food and Drug Administration, Clinical decision support software-guidance; Varma JR, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39701; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang L, 2024, NPJ DIGIT MED, V7, DOI 10.1038/s41746-024-01029-4; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Waterhouse DM, 2021, CLIN LUNG CANCER, V22, pE901, DOI 10.1016/j.cllc.2021.05.006; West H, 2023, JCO ONCOL PRACT, V19, P530, DOI 10.1200/OP.23.00010; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhu KJ, 2023, Arxiv, DOI arXiv:2306.04528	93	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1198-0052	1718-7729		CURR ONCOL	Curr. Oncol.	APR	2024	31	4					1817	1830		10.3390/curroncol31040137	http://dx.doi.org/10.3390/curroncol31040137			14	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	SU6J0	38668040	gold, Green Published			2024-07-03	WOS:001236996300001
J	Kang, K; Yang, YQ; Wu, YJ; Luo, R				Kang, Kai; Yang, Yuqi; Wu, Yijun; Luo, Ren			Integrating Large Language Models in Bioinformatics Education for Medical Students: Opportunities and Challenges	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter; Early Access						Large language model; Medical education; Bioinformatics; ChatGPT; Artificial intelligence		Large language models (LLMs) offer transformative opportunities in bioinformatics education for medical students by creating interactive experiences. The integration of LLMs enhances educational outcomes through providing accessible code templates, clarifying the function of coding elements, and assisting in error troubleshooting. Here, we demonstrate the practical applications of LLMs with a case study on transcriptome sequencing data processing, a vital component of medical research. However, the reliability of the content that LLMs generate requires rigorous validation. Ensuring the accuracy and appropriateness of the LLM-generated information requires integrating innovative LLMs with traditional educational methods to prepare medical students effectively for future challenges in bioinformatics.	[Kang, Kai; Wu, Yijun; Luo, Ren] Sichuan Univ, West China Hosp, Canc Ctr, Div Thorac Tumor Multimodal Treatment, Chengdu, Sichuan, Peoples R China; [Yang, Yuqi] Sichuan Univ, West China Sch Med, Chengdu, Sichuan, Peoples R China	Sichuan University; Sichuan University	Luo, R (corresponding author), Sichuan Univ, West China Hosp, Canc Ctr, Div Thorac Tumor Multimodal Treatment, Chengdu, Sichuan, Peoples R China.	luorenbu@163.com			National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Attwood TK, 2019, BRIEF BIOINFORM, V20, P398, DOI 10.1093/bib/bbx100; Beg A., 2021, Translational Bioinformatics in Healthcare and Medicine, P141; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Chatterjee A, 2018, METHODS MOL BIOL, V1783, P35, DOI 10.1007/978-1-4939-7834-2_3; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Liu X, 2022, BMC GENOMICS, V23, DOI 10.1186/s12864-022-08465-0; Lubiana T, 2023, PLOS COMPUT BIOL, V19, DOI 10.1371/journal.pcbi.1011319; Piccolo SR, 2023, PLOS COMPUT BIOL, V19, DOI 10.1371/journal.pcbi.1011511; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Shue E, 2023, QUANT BIOL, V11, P105, DOI [10.15302/J-QB-023-0327, 10.15302/j-qb-023-0327]; Wu YJ, 2024, JMIR MED EDUC, V10, DOI 10.2196/52483	11	0	0	2	2	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	2024 JUN 5	2024										10.1007/s10439-024-03554-5	http://dx.doi.org/10.1007/s10439-024-03554-5		JUN 2024	5	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	TS5I2	38839663				2024-07-03	WOS:001243257500003
J	Wang, JJ; Huang, YC; Chen, CY; Liu, Z; Wang, S; Wang, Q				Wang, Junjie; Huang, Yuchao; Chen, Chunyang; Liu, Zhe; Wang, Song; Wang, Qing			Software Testing With Large Language Models: Survey, Landscape, and Vision	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING			English	Article						Pre-trained large language model; software testing; LLM; GPT		Pre-trained large language models (LLMs) have recently emerged as a breakthrough technology in natural language processing and artificial intelligence, with the ability to handle large-scale datasets and exhibit remarkable performance across a wide range of tasks. Meanwhile, software testing is a crucial undertaking that serves as a cornerstone for ensuring the quality and reliability of software products. As the scope and complexity of software systems continue to grow, the need for more effective software testing techniques becomes increasingly urgent, making it an area ripe for innovative approaches such as the use of LLMs. This paper provides a comprehensive review of the utilization of LLMs in software testing. It analyzes 102 relevant studies that have used LLMs for software testing, from both the software testing and LLMs perspectives. The paper presents a detailed discussion of the software testing tasks for which LLMs are commonly used, among which test case preparation and program repair are the most representative. It also analyzes the commonly used LLMs, the types of prompt engineering that are employed, as well as the accompanied techniques with these LLMs. It also summarizes the key challenges and potential opportunities in this direction. This work can serve as a roadmap for future research in this area, highlighting potential avenues for exploration, and identifying gaps in our current understanding of the use of LLMs in software testing.	[Wang, Junjie; Huang, Yuchao; Liu, Zhe; Wang, Qing] Univ Chinese Acad Sci, Inst Software, Chinese Acad Sci, State Key Lab Intelligent Game, Beijing 100190, Peoples R China; [Chen, Chunyang] Tech Univ Munich, D-80333 Munich, Germany; [Wang, Song] York Univ, Toronto, ON M3J 1P, Canada	Chinese Academy of Sciences; Institute of Software, CAS; University of Chinese Academy of Sciences, CAS; Technical University of Munich; York University - Canada	Wang, JJ; Wang, Q (corresponding author), Univ Chinese Acad Sci, Inst Software, Chinese Acad Sci, State Key Lab Intelligent Game, Beijing 100190, Peoples R China.	junjie@iscas.ac.cn; yuchao2019@iscas.ac.cn; chunyang.chen@monash.edu; liuzhe2020@iscas.ac.cn; wangsong@yorku.ca; wq@iscas.ac.cn		Chen, Chunyang/0000-0003-2011-9618; wang, jun jie/0000-0002-9941-6713; Liu, Zhe/0000-0001-9709-8275	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Ackerman G., P 2 INT FUZZ WORKSH; Ahmad B, 2023, Arxiv, DOI [arXiv:2302.01215, 10.48550/arXiv.2302.01215]; Alagarsamy S, 2023, Arxiv, DOI arXiv:2302.10352; Android Developers, 2012, Ui/application exerciser monkey; [Anonymous], 2007, Software testing and analysis-process, principles and techniques; Bajammal M, 2022, IEEE T SOFTWARE ENG, V48, P1722, DOI 10.1109/TSE.2020.3032986; Barr ET, 2015, IEEE T SOFTWARE ENG, V41, P507, DOI 10.1109/TSE.2014.2372785; Bei Chen, 2022, Arxiv, DOI arXiv:2207.10397; Bhatia S, 2024, Arxiv, DOI arXiv:2312.10622; Brownlee AEI, 2024, LECT NOTES COMPUT SC, V14415, P153, DOI 10.1007/978-3-031-48796-5_13; Bui NDQ, 2022, Arxiv, DOI arXiv:2211.14875; Cao JL, 2023, Arxiv, DOI [arXiv:2304.08191, 10.48550/arXiv.2304.08191, 10.48550/ARXIV.2304.08191]; Charalambous Y, 2023, Arxiv, DOI arXiv:2305.14752; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Chen YH, 2024, Arxiv, DOI arXiv:2305.04764; Ciniselli M, 2022, IEEE WORK CONF MIN S, P167, DOI 10.1145/3524842.3528440; Dakhel AM, 2023, Arxiv, DOI [arXiv:2308.16557, 10.48550/arXiv.2308.16557]; Delgado-Pérez P, 2023, IEEE T SOFTWARE ENG, V49, P2580, DOI 10.1109/TSE.2022.3227418; Deligiannis P, 2023, Arxiv, DOI [arXiv:2308.05177, 10.48550/arXiv.2308.05177]; Deng GL, 2024, Arxiv, DOI arXiv:2308.06782; Deng J. Yao, 2023, Target: Au-tomated scenario generation from traffic rules for testing autonomousvehicles; Deng YL, 2023, Arxiv, DOI arXiv:2304.02014; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Dong Z, 2020, PROC INT CONF SOFTW, P481, DOI 10.1145/3377811.3380402; Erhabor D, 2023, Arxiv, DOI [arXiv:2305.06439, 10.48550/arXiv.2305.06439, DOI 10.48550/ARXIV.2305.06439]; Fakhoury S, 2023, Arxiv, DOI arXiv:2304.03816; Fan AEL, 2023, Arxiv, DOI arXiv:2310.03533; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Farrell-Vinay P., 2008, MANAGE SOFTWARE TEST; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Fu M, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P935, DOI 10.1145/3540250.3549098; Gao SZ, 2023, IEEE INT CONF AUTOM, P761, DOI 10.1109/ASE56229.2023.00109; Garg S, 2024, Arxiv, DOI [arXiv:2306.17077, DOI 10.48550/ARXIV.2306.17077]; Guilherme VH, 2023, PROCEEDINGS OF THE 8TH BRAZILIAN SYMPOSIUM ON SYSTEMATIC AND AUTOMATED SOFT-WARE TESTING, SAST 2023, P15, DOI 10.1145/3624032.3624035; Guo D., 2021, PROC 9 INT C LEARN R; Guo QY, 2020, IEEE INT CONF AUTOM, P486, DOI 10.1145/3324884.3416571; Haque MMA, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P11, DOI 10.1109/APR59189.2023.00009; Harman M, 2010, IEEE T SOFTWARE ENG, V36, P226, DOI 10.1109/TSE.2009.71; He YY, 2020, P IEEE S SECUR PRIV, P1071, DOI 10.1109/SP40000.2020.00071; Horváth D, 2023, 2023 IEEE/ACM INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR, APR, P31, DOI 10.1109/APR59189.2023.00013; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Hu J, 2023, Arxiv, DOI arXiv:2306.06782; Hu Yaojie, 2022, Fix bugs with transformer through a neural-symbolic edit grammar; Huang K, 2023, IEEE INT CONF AUTOM, P1162, DOI 10.1109/ASE56229.2023.00181; Huang Y., 2023, arXiv, DOI [10.48550/arXiv.2310.07128, DOI 10.48550/ARXIV.2310.07128]; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jin M, 2023, Arxiv, DOI arXiv:2303.07263; Kang S, 2023, Arxiv, DOI arXiv:2308.05487; Kang SM, 2023, Arxiv, DOI arXiv:2304.02195; Kang SM, 2022, Arxiv, DOI arXiv:2209.11515; Khanfir A., 2023, arXiv; Kocielnik R., 2023, arXiv, DOI [10.48550/arXiv.2302.07371, DOI 10.48550/ARXIV.2302.07371]; Kojima T., 2022, P NEURIPS; Lahiri SK, 2023, Arxiv, DOI arXiv:2208.05950; Lajkó M, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P61, DOI 10.1145/3524459.3527350; langchain, Langchain, Inc.; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Li J, 2023, PROC INT CONF SOFTW, P2124, DOI 10.1109/ICSE48619.2023.00179; Li J, 2023, Arxiv, DOI [arXiv:2305.06599, DOI 10.48550/ARXIV.2305.06599, 10.48550/ARXIV.2305.06599]; Li J, 2023, Arxiv, DOI [arXiv:2303.17780, 10.48550/ARXIV.2303.17780, DOI 10.48550/ARXIV.2303.17780]; Li TO, 2023, IEEE INT CONF AUTOM, P14, DOI 10.1109/ASE56229.2023.00089; Li V, 2023, Arxiv, DOI [arXiv:2310.00483, 10.48550/arXiv.2310.00483]; Li YC, 2017, PROC IEEE ACM INT C, P23, DOI 10.1109/ICSE-C.2017.8; Liu Z., 2023, WEB C, P417, DOI DOI 10.1145/3543507.3583386; Liu Z, 2023, Arxiv, DOI [arXiv:2310.15657, 10.48550/arXiv.2310.15657, DOI 10.48550/ARXIV.2310.15657]; Liu Z, 2023, Arxiv, DOI [arXiv:2310.15780, 10.48550/arXiv.2310.15780, DOI 10.48550/ARXIV.2310.15780]; Liu Z, 2022, Arxiv, DOI arXiv:2212.04732; Lukasczyk S, 2022, PROC IEEE ACM INT C, P168, DOI [10.1109/ICSE-Companion55297.2022.9793730, 10.1145/3510454.3516829]; Luu QH, 2023, Arxiv, DOI [arXiv:2310.19204, 10.48550/arXiv.2310.19204, DOI 10.48550/ARXIV.2310.19204]; Mahbub P, 2023, Arxiv, DOI arXiv:2212.04584; Mastropaolo A, 2023, IEEE T SOFTWARE ENG, V49, P1580, DOI 10.1109/TSE.2022.3183297; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Mathur A., 2023, 2023 9 INT C ADV COM, P1986, DOI [10.1109/ICACCS57279.2023.10112971, DOI 10.1109/ICACCS57279.2023.10112971]; Microsoft, Loadrunner, Inc.; Mili A., 2015, Software Testing: Concepts and Operations; Minxue Pan, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P153, DOI 10.1145/3395363.3397354; Moon S, 2024, Arxiv, DOI arXiv:2311.07215; Mukherjee U, 2023, Arxiv, DOI arXiv:2304.12494; Myers GJ., 2004, The Art of Software Testing, V2; Nashid N, 2023, PROC INT CONF SOFTW, P2450, DOI 10.1109/ICSE48619.2023.00205; Nie PY, 2023, Arxiv, DOI arXiv:2302.10166; Pacheco C, 2007, PROC INT CONF SOFTW, P75; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302; Pearce B., 2022, P IEEE S SEC PRIV SP, P1; Peng Y, 2023, Arxiv, DOI [arXiv:2306.01394, DOI 10.48550/ARXIV.2306.01394, 10.48550/arXiv.2306.01394]; Plein L, 2023, Arxiv, DOI [arXiv:2310.06310, 10.48550/arXiv.2310.06310, DOI 10.48550/ARXIV.2310.06310]; Plein L, 2023, Arxiv, DOI [arXiv:2310.06320, 10.48550/arXiv.2310.06320, DOI 10.48550/ARXIV.2310.06320]; Prenner JA, 2023, Arxiv, DOI arXiv:2312.04986; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Prompt Engineering, GitHub; Rao N, 2023, IEEE INT CONF AUTOM, P409, DOI 10.1109/ASE56229.2023.00193; Ribeiro F, 2023, PROCEEDINGS OF THE 16TH ACM SIGPLAN INTERNATIONAL CONFERENCE ON SOFTWARE LANGUAGE ENGINEERING, SLE 2023, P111, DOI 10.1145/3623476.3623522; Ribeiro F, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P38, DOI 10.1145/3524459.3527347; Schafer M, 2024, IEEE T SOFTWARE ENG, V50, P85, DOI 10.1109/TSE.2023.3334955; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Shi L, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P142, DOI 10.1109/ASE51524.2021.9678894; Shin J, 2024, Arxiv, DOI [arXiv:2308.08033, DOI 10.48550/ARXIV.2308.08033]; Shrestha SL, 2021, PROCEEDINGS OF EVALUATION AND ASSESSMENT IN SOFTWARE ENGINEERING (EASE 2021), P260, DOI 10.1145/3463274.3463806; Siddiq ML, 2024, Arxiv, DOI arXiv:2305.00418; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; Song SZ, 2023, Arxiv, DOI arXiv:2311.07594; Song W., 2023, arXiv; Steenhoek B, 2023, Arxiv, DOI arXiv:2310.02368; Su T, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P119, DOI 10.1145/3468264.3468620; Su T, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P245, DOI 10.1145/3106237.3106298; Su YQ, 2023, INT C PROGRAM COMPRE, P316, DOI 10.1109/ICPC58990.2023.00046; Sun ML, 2023, IEEE INT CONF AUTOM, P1288, DOI 10.1109/ASE56229.2023.00180; Sun ZS, 2022, PROC INT CONF SOFTW, P1609, DOI 10.1145/3510003.3510160; Taeb M, 2024, Arxiv, DOI arXiv:2310.02424; Taesiri M. R., 2022, arXiv; Tang Y., 2023, arXiv; Taylor A., 2023, DCC-Help:Generating context-aware compilererror explanations with large lan-guage models; Treude C, 2023, Arxiv, DOI arXiv:2303.10131; Tsigkanos Christos, 2023, Computational Science - ICCS 2023: 23rd International Conference, Proceedings. Lecture Notes in Computer Science (14073), P321, DOI 10.1007/978-3-031-35995-8_23; Tsigkanos C, 2023, Soft Anal Evol Reeng, P678, DOI 10.1109/SANER56733.2023.00070; Tu FF, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P307, DOI 10.1145/3236024.3236054; Tu HX, 2024, Arxiv, DOI [arXiv:2307.00593, 10.48550/arXiv.2307.00593, DOI 10.48550/ARXIV.2307.00593]; Tufano M, 2021, Arxiv, DOI arXiv:2009.05617; Tufano M, 2022, 3RD ACM/IEEE INTERNATIONAL CONFERENCE ON AUTOMATION OF SOFTWARE TEST (AST 2022), P54, DOI 10.1145/3524481.3527220; Vikram V, 2023, Arxiv, DOI [arXiv:2307.04346, 10.48550/arXiv.2307.04346, DOI 10.48550/ARXIV.2307.04346]; Wadhwa N, 2023, Arxiv, DOI [arXiv:2309.12938, 10.48550/arXiv.2309.12938, DOI 10.48550/ARXIV.2309.12938]; Wang SM, 2023, IEEE T SOFTWARE ENG, V49, P1188, DOI 10.1109/TSE.2022.3173346; Wang WS, 2023, PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023, P146, DOI 10.1145/3611643.3616256; Wang Z, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P788, DOI 10.1145/3368089.3409761; Watson C, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3485275; Watson C, 2020, PROC INT CONF SOFTW, P1398, DOI 10.1145/3377811.3380429; Wei AJ, 2022, PROC INT CONF SOFTW, P995, DOI 10.1145/3510003.3510041; Wei J., 2022, P NEURIPS; Wei Y., 2023, P 31 ACM JOINT EUR S; Wen M, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/3180155.3180233; Widjojo P, 2023, Arxiv, DOI arXiv:2307.10793; Wohlin C., 2014, Proceedings of the 18th international conference on evaluation and assessment in software engineering, P1, DOI DOI 10.1145/2601248.2601268; Wu Y, 2024, Arxiv, DOI arXiv:2305.18607; Wu YH, 2023, Arxiv, DOI arXiv:2308.15276; Wuisang Marchel Christhoper, 2023, 2023 International Seminar on Application for Technology of Information and Communication (iSemantic), P295, DOI 10.1109/iSemantic59612.2023.10295323; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xia Chunqiu Steven, 2022, arXiv; Xia M., 2023, Universalfuzzing via large language models; Xiao XS, 2013, IEEE INT CONF AUTOM, P246, DOI 10.1109/ASE.2013.6693084; Xie DN, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P176, DOI 10.1145/3533767.3534220; Xiong YF, 2017, PROC INT CONF SOFTW, P416, DOI 10.1109/ICSE.2017.45; Xuan JF, 2017, IEEE T SOFTWARE ENG, V43, P34, DOI 10.1109/TSE.2016.2560811; Yang AZH, 2023, Arxiv, DOI [arXiv:2310.01726, 10.48550/arXiv.2310.01726]; Yang CY, 2023, Arxiv, DOI [arXiv:2310.15991, 10.48550/arXiv.2310.15991]; Yang YM, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505243; Ye GX, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P435, DOI 10.1145/3453483.3454054; Yetistiren B, 2023, Arxiv, DOI arXiv:2304.10778; Yu FS, 2016, Arxiv, DOI arXiv:1506.03365; Yu SC, 2023, Arxiv, DOI [arXiv:2309.13574, 10.48550/arXiv.2309.13574, DOI 10.48550/ARXIV.2309.13574]; Yuan W, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P678, DOI 10.1145/3533767.3534219; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zan DG, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7443; Zhang C, 2024, Arxiv, DOI arXiv:2307.12469; Zhang J., 2022, arXiv; Zhang JM, 2022, IEEE T SOFTWARE ENG, V48, P1, DOI 10.1109/TSE.2019.2962027; Zhang QJ, 2023, Arxiv, DOI [arXiv:2308.12533, 10.48550/arXiv.2308.12533, DOI 10.48550/ARXIV.2308.12533]; Zhang T, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1637, DOI 10.1145/3540250.3558934; Zhang T, 2023, Arxiv, DOI [arXiv:2308.10022, 10.48550/arXiv.2308.10022, DOI 10.48550/ARXIV.2308.10022]; Zhang YW, 2023, Arxiv, DOI arXiv:2308.14460; Zhang YW, 2023, Arxiv, DOI arXiv:2305.09315; Zhang ZS, 2024, Arxiv, DOI [arXiv:2302.00923, DOI 10.48550/ARXIV.2302.00923]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zimmermann D, 2023, IEEE ICST WORKSHOP, P62, DOI 10.1109/ICSTW58534.2023.00022	164	1	1	16	16	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0098-5589	1939-3520		IEEE T SOFTWARE ENG	IEEE Trans. Softw. Eng.	APR	2024	50	4					911	936		10.1109/TSE.2024.3368208	http://dx.doi.org/10.1109/TSE.2024.3368208			26	Computer Science, Software Engineering; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OC2K3		Green Submitted			2024-07-03	WOS:001204993400011
C	Hillebrand, L; Berger, A; Deusser, T; Dilmaghani, T; Khaled, M; Kliem, B; Loitz, R; Pielka, M; Leonhard, D; Bauckhage, C; Sifa, R			ACM	Hillebrand, Lars; Berger, Armin; Deusser, Tobias; Dilmaghani, Tim; Khaled, Mohamed; Kliem, Bernd; Loitz, Ruediger; Pielka, Maren; Leonhard, David; Bauckhage, Christian; Sifa, Rafet			Improving Zero-Shot Text Matching for Financial Auditing with Large Language Models	PROCEEDINGS OF THE 2023 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, DOCENG 2023			English	Proceedings Paper	23rd ACM Symposium on Document Engineering (DocEng)	AUG 22-25, 2023	Limerick, IRELAND	Assoc Comp Machinery, ACM SIGWEB, SIGDOC, Univ Limerick, Comp Sci Dept		Large Language Models; Recommender System; Text Matching		Auditing financial documents is a very tedious and time-consuming process. As of today, it can already be simplified by employing AI-based solutions to recommend relevant text passages from a report for each legal requirement of rigorous accounting standards. However, these methods need to be fine-tuned regularly, and they require abundant annotated data, which is often lacking in industrial environments. Hence, we present ZeroShotALI, a novel recommender system that leverages a state-of-the-art large language model (LLM) in conjunction with a domain-specifically optimized transformer-based text-matching solution. We find that a two-step approach of first retrieving a number of best matching document sections per legal requirement with a custom BERT-based model and second filtering these selections using an LLM yields significant performance improvements over existing approaches.	[Hillebrand, Lars; Berger, Armin; Deusser, Tobias; Pielka, Maren; Leonhard, David; Bauckhage, Christian; Sifa, Rafet] Fraunhofer IAIS, St Augustin, Germany; [Dilmaghani, Tim; Khaled, Mohamed; Kliem, Bernd; Loitz, Ruediger] PricewaterhouseCoopers GmbH, Dusseldorf, Germany; [Deusser, Tobias; Bauckhage, Christian; Sifa, Rafet] Univ Bonn, Bonn, Germany	University of Bonn	Hillebrand, L (corresponding author), Fraunhofer IAIS, St Augustin, Germany.	lars.patrick.hillebrand@iais.fraunhofer.de	Bauckhage, Christian/M-7872-2014	Bauckhage, Christian/0000-0001-6615-2128; Leonhard, David/0009-0002-4434-1889	Federal Ministry of Education and Research of Germany; state of North-Rhine Westphalia as part of the Lamarr-Institute for Machine Learning and Artificial Intelligence	Federal Ministry of Education and Research of Germany(Federal Ministry of Education & Research (BMBF)); state of North-Rhine Westphalia as part of the Lamarr-Institute for Machine Learning and Artificial Intelligence	This research has been partially funded by the Federal Ministry of Education and Research of Germany and the state of North-Rhine Westphalia as part of the Lamarr-Institute for Machine Learning and Artificial Intelligence.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ali Syed Musharraf, 2023, P NLDL; Aumüller M, 2020, INFORM SYST, V87, DOI 10.1016/j.is.2019.02.006; Biesner David, 2022, P ICML A; Cao Y, 2023, J CHIN ECON BUS STUD, V21, P177, DOI 10.1080/14765284.2023.2212434; Deusser Tobias, 2022, P ICMLA; Deusser Tobias., 2023, P NLDL; Devlin J., 2018, BERT PRE TRAINING DE; Hillebrand L., 2022, P ICPR; Hillebrand Lars., 2022, P BIGDATA; Liu X, 2023, Arxiv, DOI arXiv:2103.10385; Neilson B, 2023, J FINANC REGUL, V9, P249, DOI 10.1093/jfr/fjad004; Ramamurthy R, 2021, PROCEEDINGS OF THE 21ST ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG '21), DOI 10.1145/3469096.3474928; Reimers N, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3982; Sifa R, 2019, DOCENG'19: PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING 2019, DOI 10.1145/3342558.3345421; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]	18	0	0	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0027-9				2023									9	10.1145/3573128.3609344	http://dx.doi.org/10.1145/3573128.3609344			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW1VO		hybrid, Green Submitted			2024-07-03	WOS:001111889400020
C	Shriram, J; Sreekala, S			ACM	Shriram, Jaidev; Sreekala, Sanjayan			ZINify: Transforming Research Papers into Engaging Zines with Large Language Models	ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT			English	Proceedings Paper	36th Annual ACM Symposium on User Interface Software and Technology (UIST)	OCT 29-NOV 01, 2023	San Francisco, CA	Assoc Comp Machinery, ACM Special Interest Grp Comp Human Interact, ACM Special Interest Grp Comp Graph		Large Language Models; Text-to-Image Generation; Information Extraction; Generative Art; Zines; Summarization		Research papers are a vital building block for scientific discussion. While these papers follow effective structures for the relevant community, they are unable to cater to novice readers and express otherwise creative ideas in creative mediums. To this end, we propose ZINify, the first approach to automatically transform research papers into engaging zines using large language models (LLM) and text-to-image generators. Following zine's long history of supporting independent, creative expression, we propose a technique that can work with authors to build more engaging, marketable, and unconventional content that is based on their research. We believe that our work will help make research more engaging and accessible to all while helping papers stand out in crowded online venues.	[Shriram, Jaidev; Sreekala, Sanjayan] Univ Calif San Diego, La Jolla, CA 92093 USA	University of California System; University of California San Diego	Shriram, J (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.	jkariyatt@ucsd.edu; sps223@ucsd.edu		Shriram, Jaidev/0009-0008-0697-8401; Pradeep Kumar Sreekala, Sanjayan/0009-0008-3610-3980				Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; DeepFloyd Lab, 2023, DeepFloyd IF; Duncombe Stephen., 1997, NOTES UNDERGROUND ZI; Huang JB, 2018, Arxiv, DOI arXiv:1812.08775; Kajiya J. T., 1986, Computer Graphics, V20, P143, DOI 10.1145/15886.15902; Krenn M, 2022, Arxiv, DOI arXiv:2210.00881; McNutt A, 2021, 2021 IEEE VISUALIZATION CONFERENCE - SHORT PAPERS (VIS 2021), P176, DOI 10.1109/VIS49827.2021.9623294; Resnick B., 2019, The war to free science; Schmitt Jason, 2019, Paywalls Block Scientifc Progress. Research should be open to everyone; Triggs Teal, 2010, Revolution	10	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0096-5				2023									117	10.1145/3586182.3625118	http://dx.doi.org/10.1145/3586182.3625118			3	Computer Science, Cybernetics; Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2TP					2024-07-03	WOS:001125107000116
C	Faggioli, G; Dietz, L; Clarke, CLA; Demartini, G; Hagen, M; Hauff, C; Kando, N; Kanoulas, E; Potthast, M; Stein, B; Wachsmuth, H			ACM	Faggioli, Guglielmo; Dietz, Laura; Clarke, Charles L. A.; Demartini, Gianluca; Hagen, Matthias; Hauff, Claudia; Kando, Noriko; Kanoulas, Evangelos; Potthast, Martin; Stein, Benno; Wachsmuth, Henning			Perspectives on Large Language Models for Relevance Judgment	PROCEEDINGS OF THE 2023 ACM SIGIR INTERNATIONAL CONFERENCE ON THE THEORY OF INFORMATION RETRIEVAL, ICTIR 2023			English	Proceedings Paper	13th ACM SIGIR International Conference on the Theory of Information Retrieval (ICTIR)	JUL 23, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		large language models; relevance judgments; human-machine collaboration; automatic test collections	PERFORMANCE	When asked, large language models (LLMs) like ChatGPT claim that they can assist with relevance judgments but it is not clear whether automated judgments can reliably be used in evaluations of retrieval systems. In this perspectives paper, we discuss possible ways for LLMs to support relevance judgments along with concerns and issues that arise. We devise a human-machine collaboration spectrum that allows to categorize different relevance judgment strategies, based on how much humans rely on machines. For the extreme point of 'fully automated judgments', we further include a pilot experiment on whether LLM-based relevance judgments correlate with judgments from trained human assessors. We conclude the paper by providing opposing perspectives for and against the use of LLMs for automatic relevance judgments, and a compromise perspective, informed by our analyses of the literature, our preliminary experimental evidence, and our experience as IR researchers.	[Faggioli, Guglielmo] Univ Padua, Padua, Italy; [Dietz, Laura] Univ New Hampshire, Durham, NH 03824 USA; [Clarke, Charles L. A.] Univ Waterloo, Waterloo, ON, Canada; [Demartini, Gianluca] Univ Queensland, Brisbane, Qld, Australia; [Hagen, Matthias] Friedrich Schiller Univ Jena, Jena, Germany; [Hauff, Claudia] Spotify, Stockholm, Sweden; [Kando, Noriko] Natl Inst Informat NII, Tokyo, Japan; [Kanoulas, Evangelos] Univ Amsterdam, Amsterdam, Netherlands; [Potthast, Martin] Univ Leipzig, Leipzig, Germany; [Potthast, Martin] ScaDS AI, Leipzig, Germany; [Stein, Benno] Bauhaus Univ Weimar, Weimar, Germany; [Wachsmuth, Henning] Leibniz Univ Hannover, Hannover, Germany	University of Padua; University System Of New Hampshire; University of New Hampshire; University of Waterloo; University of Queensland; Friedrich Schiller University of Jena; Spotify; Research Organization of Information & Systems (ROIS); National Institute of Informatics (NII) - Japan; University of Amsterdam; Leipzig University; Bauhaus-Universitat Weimar; Leibniz University Hannover	Faggioli, G (corresponding author), Univ Padua, Padua, Italy.		Wachsmuth, Henning/AAH-7299-2021; faggioli, guglielmo/ABT-4575-2022; Demartini, Gianluca/G-4635-2012	Demartini, Gianluca/0000-0002-7311-3693; Hagen, Matthias/0000-0002-9733-2890; Faggioli, Guglielmo/0000-0002-5070-2049; Dietz, Laura/0000-0003-1624-3907; Clarke, Charles/0000-0001-8178-9194	National Science Foundation [1846017]	National Science Foundation(National Science Foundation (NSF))	This paper is based on discussions during a breakout group at the Dagstuhl Seminar 23031 on "Frontiers of Information Access Experimentation for Research and Education" [10]. We express our gratitude to the Seminar organizers, Christine Bauer, Ben Carterette, Nicola Ferro, and Norbert Fuhr. Certain companies and software are identified in this paper in order to specify the experimental procedure adequately. Such identification is not intended to imply recommendation or endorsement of any product or service, nor is it intended to imply that the software or companies identified are necessarily the best available for the purpose. This material is based upon work supported by the National Science Foundation under Grant No. 1846017. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Abualsaud M, 2018, ACM/SIGIR PROCEEDINGS 2018, P1317, DOI 10.1145/3209978.3210176; Alonso O, 2011, LECT NOTES COMPUT SC, V6611, P153, DOI 10.1007/978-3-642-20161-5_16; Alonso Omar, 2009, P SIGIR 2009 WORKSH, V15; [Anonymous], 2008, P INT ACM SIGIR C RE; Arabzadeh N, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P3811, DOI 10.1145/3511808.3557719; Arabzadeh N, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2857, DOI 10.1145/3459637.3482063; Arnold S, 2019, T ASSOC COMPUT LING, V7, P169, DOI 10.1162/tacl_a_00261; Asadi N, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P1073; Basta C, 2019, Arxiv, DOI arXiv:1904.08783; Bauer C, 2023, Arxiv, DOI [arXiv:2305.01509, 10.48550/arXiv.2305.01509, DOI 10.48550/ARXIV.2305.01509]; Beitzel Steven M, 2003, P 12 INT C INF KNOWL, P17, DOI [10.1145/956863.956868, DOI 10.1145/956863.956868]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Berendsen Richard, 2012, Information Access Evaluation. Multilinguality, Multimodality, and Visual Analytics. Proceedings of the Third International Conference of the CLEF Initiative (CLEF 2012), P42, DOI 10.1007/978-3-642-33247-0_6; Blanco R, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P923; Braschler M., 2001, Cross-Language Information Retrieval and Evaluation. Workshop of the Cross-Language Evaluation Forum, CLEF 2000. Revised Papers (Lecture Notes in Computer Science Vol.2069), P89; Carmel D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P911; Carterette B., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P268, DOI 10.1145/1148170.1148219; Chen XY, 2022, LECT NOTES COMPUT SC, V13186, P64, DOI 10.1007/978-3-030-99739-7_8; ChristianWeismayer Ilona, 2018, Information and communication technologies in tourism 2018, P365, DOI [DOI 10.1007/978, 10.1007/978-3-319-72923-7_28, DOI 10.1007/978-3-319-72923-7_28]; CLEVERDON CW, 1960, ASLIB PROC, V12, P421, DOI 10.1108/eb049778; Cormack G. V., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P282, DOI 10.1145/290941.291009; Craswell N, 2021, Arxiv, DOI arXiv:2102.07662; Creswell A, 2022, Arxiv, DOI arXiv:2208.14271; Dalton J, 2020, Arxiv, DOI arXiv:2003.13624; Dalvi B, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P369, DOI 10.1145/2684822.2685288; Daniel F, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148148; Datta S, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2148, DOI 10.1145/3477495.3531821; Deutsch D, 2021, T ASSOC COMPUT LING, V9, P774, DOI 10.1162/tacl_a_00397; Dietz Laura, 2020, Datenbank-Spektrum, P17, DOI 10.1007/s13222-020-00334-y; Dietz L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3003, DOI 10.1145/3477495.3531731; Eyal M, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P3938; Faggioli Guglielmo, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P33, DOI 10.1007/978-3-030-72240-1_3; Faggioli G, 2023, PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023, P1355, DOI 10.1145/3539618.3591625; Ferrante M, 2017, ACM T INFORM SYST, V36, DOI 10.1145/3110217; Ferraretto F, 2023, Arxiv, DOI [arXiv:2301.10521, DOI 10.48550/ARXIV.2301.10521]; Flemisch F, 2016, IFAC PAPERSONLINE, V49, P72, DOI 10.1016/j.ifacol.2016.10.464; Fröbe M, 2023, LECT NOTES COMPUT SC, V13980, P313, DOI 10.1007/978-3-031-28244-7_20; Fröbe M, 2022, LECT NOTES COMPUT SC, V13390, P48, DOI 10.1007/978-3-031-13643-6_4; Fuhr Norbert, 2017, ACM SIGIR Forum, V51, P32, DOI 10.1145/3190580.3190586; Gadiraju U, 2019, COMPUT SUPP COOP W J, V28, P815, DOI 10.1007/s10606-018-9336-y; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Goh YC, 2020, SCIENTOMETRICS, V125, P1197, DOI 10.1007/s11192-020-03614-2; Halvey Martin, 2015, SIGIR Forum, V49, P16, DOI DOI 10.1145/2795403.2795409; Hancock PA, 2013, ERGONOMICS, V56, P1387, DOI 10.1080/00140139.2013.816374; Harman D.K., 1992, P TREC; Hauff Claudia, 2010, SIGIR FORUM, V44, P88; Hayashi H, 2021, T ASSOC COMPUT LING, V9, P211, DOI 10.1162/tacl_a_00362; Hewlett Daniel, 2016, WikiReading: A Novel Large-scale Language Understanding Task over Wikipedia, DOI DOI 10.18653/V1/P16-1145; Huang L., 2020, P 58 ANN M ASS COMP, P5094; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jaech A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P700; Järvelin K, 2009, LECT NOTES COMPUT SC, V5766, P289, DOI 10.1007/978-3-642-04417-5_28; Jayasinghe GayaK., 2014, Proceedings of the 2014 Australasian Document Computing Symposium on - ADCS'14, P2, DOI [DOI 10.1145/2682862.2682864, 10.1145/2682862, DOI 10.1145/2682862]; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Kando Noriko, 1999, P 1 NTCIR WORKSH RES; Kasneci G, 2008, SIGMOD RECORD, V37, P41, DOI 10.1145/1519103.1519110; Kaushik P, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P350, DOI 10.1109/CCAA.2017.8229841; Kazai G, 2013, INFORM RETRIEVAL, V16, P138, DOI 10.1007/s10791-012-9205-0; Keikha M, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P963, DOI 10.1145/2600428.2609485; Kurita K, 2019, Arxiv, DOI arXiv:1906.07337; Clarke CLA, 2021, Arxiv, DOI arXiv:2007.11682; Lyu Q, 2023, Arxiv, DOI [arXiv:2301.13379, 10.48550/arXiv.2301.13379]; MacAvaney S, 2023, Arxiv, DOI [arXiv:2302.11266, 10.48550/arXiv.2302.11266, DOI 10.48550/ARXIV.2302.11266]; Maddalena Eddy, 2016, P 4 AAAI C HUM COMP, P129; Mizzaro S, 1997, J AM SOC INFORM SCI, V48, P810, DOI 10.1002/(SICI)1097-4571(199709)48:9<810::AID-ASI6>3.0.CO;2-U; Pavlu V., 2012, P 5 ACM INT C WEB SE, P393, DOI [10.1145/2124295.2124343, DOI 10.1145/2124295.2124343]; Sakai T., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P525, DOI 10.1145/1148170.1148261; Sakai Tetsuya, 2021, SIGIR Forum, V54, DOI DOI 10.1145/3451964.3451976; Sander D.P., 2021, CEUR WORKSHOP P, V2950, P136; Saracevic T., 1995, SIGIR Forum, P138; Saracevic T, 1996, COLIS 2 - SECOND INTERNATIONAL CONFERENCE ON CONCEPTIONS OF LIBRARY AND INFORMATION SCIENCE: INTEGRATION IN PERSPECTIVE, PROCEEDINGS, P201; SCHAMBER L, 1994, ANNU REV INFORM SCI, V29, P3; Seo S, 2022, AAAI CONF ARTIF INTE, P11276; Sheshadri Aashish, 2013, P 1 AAAI C HUM COMP, P156, DOI [10.1609/hcomp.v1i1.13088, DOI 10.1609/HCOMP.V1I1.13088]; Soboroff I., 2021, 30 TEXT RETRIEVAL C; Soboroff I., 2001, Proceedings Of The 24th Annual International ACM SIGIR Conference On Research And Development In Information Retrieval, P66, DOI DOI 10.1145/383952.383961; Sorensen T, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P819; Stajner S., 2020, P 28 INT C COMP LING, P6264, DOI [10.18653/v1/2020.coling-main.551, DOI 10.18653/V1/2020.COLING-MAIN.551]; Tamine L, 2017, INFORM PROCESS MANAG, V53, P332, DOI 10.1016/j.ipm.2016.11.004; Voorhees EM, 2000, INFORM PROCESS MANAG, V36, P697, DOI 10.1016/S0306-4573(00)00010-8; Voorhees EM, 1999, NIST Special Publication, P77, DOI DOI 10.1017/S1351324901002789; Welch C, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1742; WINDSOR J, 1994, RES DEV DISABIL, V15, P439, DOI 10.1016/0891-4222(94)90028-0; Xu J, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103177; Yang ZY, 2018, ADCS'18: PROCEEDINGS OF THE 23RD AUSTRALASIAN DOCUMENT COMPUTING SYMPOSIUM, DOI 10.1145/3291992.3291995; Yilmaz Emine, 2008, P 31 ANN INT ACM SIG, P603, DOI DOI 10.1145/1390334.1390437; Yoon Seunghyun, 2017, WORKSH 31 AAAI C ART, VWS- 17; Yu Youngjae, 2022, arXiv; Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]; Zhu YM, 2023, Arxiv, DOI arXiv:2304.10145	90	8	8	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0073-6				2023							39	50		10.1145/3578337.3605136	http://dx.doi.org/10.1145/3578337.3605136			12	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LU		Bronze, Green Submitted			2024-07-03	WOS:001118823000006
J	Lozic, E; Stular, B				Lozic, Edisa; Stular, Benjamin			Fluent but Not Factual: A Comparative Analysis of ChatGPT and Other AI Chatbots' Proficiency and Originality in Scientific Writing for Humanities	FUTURE INTERNET			English	Article						generative AI; large language model (LLM); ChatGPT; Bard; Bing; scientific writing; digital humanities		Historically, mastery of writing was deemed essential to human progress. However, recent advances in generative AI have marked an inflection point in this narrative, including for scientific writing. This article provides a comprehensive analysis of the capabilities and limitations of six AI chatbots in scholarly writing in the humanities and archaeology. The methodology was based on tagging AI-generated content for quantitative accuracy and qualitative precision by human experts. Quantitative accuracy assessed the factual correctness in a manner similar to grading students, while qualitative precision gauged the scientific contribution similar to reviewing a scientific article. In the quantitative test, ChatGPT-4 scored near the passing grade (-5) whereas ChatGPT-3.5 (-18), Bing (-21) and Bard (-31) were not far behind. Claude 2 (-75) and Aria (-80) scored much lower. In the qualitative test, all AI chatbots, but especially ChatGPT-4, demonstrated proficiency in recombining existing knowledge, but all failed to generate original scientific content. As a side note, our results suggest that with ChatGPT-4, the size of large language models has reached a plateau. Furthermore, this paper underscores the intricate and recursive nature of human research. This process of transforming raw data into refined knowledge is computationally irreducible, highlighting the challenges AI chatbots face in emulating human originality in scientific writing. Our results apply to the state of affairs in the third quarter of 2023. In conclusion, while large language models have revolutionised content generation, their ability to produce original scientific contributions in the humanities remains limited. We expect this to change in the near future as current large language model-based AI chatbots evolve into large language model-powered software.	[Lozic, Edisa; Stular, Benjamin] Slovenian Acad Sci & Arts, Res Ctr, Ljubljana 1000, Slovenia	Slovenian Academy of Sciences & Arts (SASA)	Stular, B (corresponding author), Slovenian Acad Sci & Arts, Res Ctr, Ljubljana 1000, Slovenia.	benjamin.stular@zrc-sazu.si	Štular, Benjamin/AAE-6455-2020	Štular, Benjamin/0000-0003-1474-7183; Lozic, Edisa/0000-0002-6687-9906	European Union [101070000]; Slovenian Research and Innovation Agency (ARIS) [P6-0064]; Horizon Europe - Pillar II [101070000] Funding Source: Horizon Europe - Pillar II	European Union(European Union (EU)); Slovenian Research and Innovation Agency (ARIS); Horizon Europe - Pillar II(European Union (EU)Horizon Europe - Pillar II)	This research was part of the AI4Europe project that has received funding from the European Union's Horizon Europe research and innovation programme under Grant Agreement no 101070000, and the Slovenian Research and Innovation Agency (ARIS) grant number P6-0064.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ackoff R. L., 1989, Journal of Applied Systems Analysis, V16, P3, DOI DOI 10.5840/DU2005155/629; Altma S, 2023, REPROD BIOMED ONLINE, V47, P3, DOI 10.1016/j.rbmo.2023.04.009; Altman S., 2023, OpenAI Blog; [Anonymous], 2023, NAT MACH INTELL, DOI 10.1038/s42256-023-00613-9; [Anonymous], 2023, The White House Brief21 July; [Anonymous], 2023, Anthropic 11 July; [Anonymous], 2023, PLOS; [Anonymous], 2023, Anthropic 14 March; [Anonymous], 2022, OpenAI 30 November; [Anonymous], 2023, OpenAI 1 February; [Anonymous], 2023, OpenAI Blog; [Anonymous], 2023, Nature, V619, P671; [Anonymous], 2023, Blogs Opera; Arora S., 2023, On the Opportunities and Risks of Foundation Models; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Bearne S., 2023, BBC News Website1 August; Beel J., 2009, Google Scholar's Ranking Algorithm: An Introductory Overview, P230; BENTLEY GC, 1987, COMP STUD SOC HIST, V29, P24, DOI 10.1017/S001041750001433X; Bhattacharyya M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39238; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bryant A, 2023, INFORMATICS-BASEL, V10, DOI 10.3390/informatics10020049; Brynjolfsson E., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P16; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Bucknall BS, 2022, PROCEEDINGS OF THE 2022 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, AIES 2022, P119, DOI 10.1145/3514094.3534146; Buholayka M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39386; Carlsmith J, 2022, Arxiv, DOI [arXiv:2206.13353, 10.48550/arXiv.2206.13353]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiano P, 2017, Arxiv, DOI [arXiv:1706.03741, DOI 10.48550/ARXIV.1706.03741]; Cohen MK, 2022, AI MAG, V43, P282, DOI 10.1002/aaai.12064; Collins E., 2021, Blog Google; Curta Florin., 2001, The Making of the Slavs: History and Archaeology of the Lower Danube Region, DOI DOI 10.1017/CBO9780511496295; Dolukhanov P.M., 1996, The early Slavs: Eastern Europe from the initial settlement to the Kievan Rus; Donelan M., 2023, UK Government News16 March; Elam M., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P11; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Fan LZ, 2023, Arxiv, DOI [arXiv:2304.02020, DOI 10.48550/ARXIV.2304.02020]; Future of Life Institute, 2023, PAUS GIANT EXP OP LE; Ganguli S., 2023, An AI Window into Nature In Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P8; Gao C.A., 2022, NPJ DIGIT MED, DOI [10.1101/2022.12.23.521610, DOI 10.1101/2022.12.23.521610]; Gardizy A., 2023, The Information18 April; Getahun H., 2022, Bussines Insider Nederland9 July; Grafenauer B., 1954, Zgodovina Slovenskega Naroda; Haque M.U., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.05856; help.opera, 2023, Opera Help; Hendrycks D, 2022, Arxiv, DOI arXiv:2206.05862; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Hinton G., 2023, Center for AI Safety; Hodder Ian., 1999, ARCHAEOLOGICAL PROCE; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hrushevsky Mykhailo., 1997, HIST UKRAINE RUS, VI.; Hsiao S., 2023, Blog Google21 March; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Imafidon A.-M., 2023, AI Open Letter to UK Government and Industry; Jaupi J., 2022, The Sun11 July; Kajkowski K., 2012, Stud. Myth. Slavica, V15, P201, DOI [10.3986/sms.v15i1.1584, DOI 10.3986/SMS.V15I1.1584]; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kleinman Z., 2023, BBC News Website13 June; Kleinman Z., 2023, BBC News Website19 July; Knapp BernardA., 2008, Prehistoric and Protohistoric Cyprus: identity, insularity and connectivity; Kocon J, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101861; Koo Malcolm, 2023, Radiology, V307, pe230312, DOI 10.1148/radiol.230312; Kotek H, 2023, Arxiv, DOI arXiv:2308.14921; Li F.-F., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?; Li F.-F., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P4; Liang P., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P15; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lindstedt J., 2020, New Perspectives on the Early Slavs and the rise of Slavic, P275; Lozic E, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163228; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; MacEachern S, 2000, CURR ANTHROPOL, V41, P357, DOI 10.1086/300144; Madiega T., 2023, ARTIF INTELL; Májovsky M, 2023, J MED INTERNET RES, V25, DOI 10.2196/46924; Manning C.D., 2023, Generative AI: Perspectives from Stanford HAI. How Do You Think Generative AI Will Affect Your Field and Society Going Forward?, P18; Manyika James, 2023, An Overview of Bard: An Early Experiment with Generative AI; Martín-Martín A, 2016, SCIENTOMETRICS, V107, P1477, DOI 10.1007/s11192-016-1917-2; McCallum S., 2023, BBC News Website22 July; Mehdi Y, 2023, Official Microsoft Blog 7 February; Microsoft, 2023, Will AI Fix Work? 2023 Work Trend Index: Annual Report; Moskvichev A, 2023, Arxiv, DOI arXiv:2305.07141; Nagtegaal L.W., 1994, RES EVALUAT, V4, P119, DOI [DOI 10.1093/REV/4.2.119, 10.1093/rev/4.2, DOI 10.1093/REV/4.2, 10.1093/rev/4.2.119]; Ngo R, 2022, Arxiv, DOI arXiv:2209.00626; Obolensky Dimitri., 1971, The Byzantine Commonwealth; Okerlund J, 2022, What's in the chatterbox? large language models, why they matter, and what we should do about them; Patel D, 2023, SemiAnalysis; Perrigo B, 2023, Time; Petiska E, 2023, Arxiv, DOI [arXiv:2304.06794, 10.48550/arXiv.2304.06794, DOI 10.48550/ARXIV.2304.06794]; Pividori Milton, 2023, bioRxiv, DOI 10.1101/2023.01.21.525030; Pleterski A., 2014, Kulturni Genom: Prostor in Njegovi Ideogrami Mitine Zgodbe; Preiser-Kapeller Johannes, 2020, Studies in Global Migration History, V13, P101, DOI DOI 10.1163/9789004425613_005; RATZEL F, 1909, ANTHROPOGEOGRAPHIE; Rovira C, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13020031; Salvagno M, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04380-2; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Schürer Y, 2023, BIBL FORSCH PRAX, DOI 10.1515/bfp-2022-0029; Simons J., 2023, Time5 February; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Stular B., 2022, Res. Data J. Humanit. Soc. Sci, P1, DOI [10.1163/24523666-bja10024, DOI 10.1163/24523666-BJA10024]; Stular B, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0274687; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Thunstrom AO., 2022, SCI AM; Transformer G.G.P., 2022, Can GPT-3 write an academic paper on itself, with minimal human input?; Vallance C., 2023, BBC News Website1 June; Vallance C., 2023, BBC News Website12 July; Vallance C., 2023, BBC News Website28 March; Vaswani A, 2017, ADV NEUR IN, V30; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Wolfram Stephen, 2023, Stephen Wolfram Writings February 14; Woods R., 2023, Microsoft Learn Articles11 July; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	114	3	3	12	19	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	1999-5903			FUTURE INTERNET	Future Internet	OCT	2023	15	10							336	10.3390/fi15100336	http://dx.doi.org/10.3390/fi15100336			26	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	X0WV0		Green Submitted, gold			2024-07-03	WOS:001095748700001
C	Huang, ZH; Quan, KX; Chan, J; MacNeil, S			ACM	Huang, Ziheng; Quan, Kexin; Chan, Joel; MacNeil, Stephen			CausalMapper: Challenging designers to think in systems with Causal Maps and Large Language Model	2023 PROCEEDINGS OF THE 15TH CONFERENCE ON CREATIVITY AND COGNITION, C&C 2023			English	Proceedings Paper	15th Conference on Creativity and Cognition (C and C)	JUN 19-21, 2023	ELECTR NETWORK	Assoc Comp Machinery, ACM SIGCHI		large language models; design space; creativity support tools		Professional designers often construct and explore conceptual representations (e.g.: design spaces) to help them reason about complex design situations and consider potential design pitfalls. However, it is often challenging, even for professional designers, to exhaustively consider the many pitfalls that might result from design activity. We present CausalMapper, a mixed-initiative system, that leverages a large language model (LLM) and a causal map representation to teach design students how to reason about the relationships between problems and solutions. Where creativity support tools often focus on ideating creative solutions, our mixed-initiative approach focuses on ideating ecosystems of solutions that holistically address a set of related problems. By leveraging the generative creativity of LLMs, designers are inspired to consider solutions and potential consequences that emerge when solutions are adopted. At the same time, leveraging the designers' domain knowledge to account for and correct the biases inherent in LLMs. Through a case study, we demonstrate the functionality of this mixed-initiative system. The goal of this demo is to present a creativity support tool that is intended to teach design students to think more systematically by generating ideas that challenge their thinking rather just augmenting their creative potential.	[Huang, Ziheng; Quan, Kexin] Univ Calif San Diego, La Jolla, CA 92093 USA; [Chan, Joel] Univ Maryland, College Pk, MD USA; [MacNeil, Stephen] Temple Univ, Philadelphia, PA 19122 USA	University of California System; University of California San Diego; University System of Maryland; University of Maryland College Park; Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University	Huang, ZH (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.	z8huang@ucsd.edu; kequan@ucsd.edu; joelchan@umd.edu; stephen.macneil@temple.edu	MacNeil, Stephen/HPH-0843-2023	MacNeil, Stephen/0000-0003-2781-6619; Chan, Joel/0000-0003-3000-4160				Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Bala BK, 2017, SPRING TEXT BUS ECON, P53, DOI 10.1007/978-981-10-2045-2_4; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Binder Thomas., 2004, P 22 INT C SYSTEM DY, P1; Card S.K., 1990, P SIGCHI C HUMAN FAC, P117; Chi M.T., 1981, Expertise in problem solving; Cross N, 2001, DES ISSUES, V17, P49, DOI 10.1162/074793601750357196; Dalsgaard Peter, 2008, OZCHI 2008 P 20 AUST, P219, DOI [10.1145/1517744.1517816, DOI 10.1145/1517744.1517816]; Do K, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581347; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Frich J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300619; Fu K, 2013, J MECH DESIGN, V135, DOI 10.1115/1.4023158; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Heer J, 2019, P NATL ACAD SCI USA, V116, P1844, DOI 10.1073/pnas.1807184115; Herring SR, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P87; Hope T, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517434; Horvitz Eric, 1999, P SIGCHI C HUM FACT, P159; Huang GP, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P119, DOI 10.1145/3059454.3059481; Ishii Kosuke, 1996, INT DES ENG TECHN C, V80494; Jansson D.G., 1991, DESIGN STUDIES, V12, P3, DOI [10.1016/0142-694X(91)90003-F, DOI 10.1016/0142-694X(91)90003-F]; Jiang E, 2021, ADJUNCT PROCEEDINGS OF THE 34TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2021, P145, DOI 10.1145/3474349.3480209; Jiang Ellen, 2022, CHI C HUM FACT COMP, P1; Kang HB, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174180; Kim J, 2017, CSCW'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING, P246, DOI 10.1145/2998181.2998195; Klein M., 2011, Proceedings 2011 International Conference on Collaboration Technologies and Systems (CTS 2011), DOI 10.1109/CTS.2011.5928678; Lau S, 2019, PROCEEDINGS OF THE 2019 ON CREATIVITY AND COGNITION - C&C 19, P578, DOI 10.1145/3325480.3326582; Linsey Julie S, 2010, A study of design fixation, its mitigation and perception in engineering design faculty; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; MacLean A., 1991, Human-Computer Interaction, V6, P201, DOI 10.1207/s15327051hci0603&4_2; MacNeil S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON CREATIVITY AND COGNITION (C&C 2017), P367, DOI 10.1145/3059454.3059472; MacNeil Stephen, 2021, ProbMap: Automatically Constructing Design Galleries through Feature Extraction and Semantic Clustering, P134, DOI [10.1145/3474349.3480203, DOI 10.1145/3474349.3480203]; Maher ML., 1996, Advances in Formal Design Methods for CAD: Proceedings of the IFIP WG5.2 Workshop on Formal Design Methods for Computer-Aided Design, P3; Mendels P, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1481; Montibeller G, 2006, J OPER RES SOC, V57, P779, DOI 10.1057/palgrave.jors.2602214; Murphy J, 2014, J MECH DESIGN, V136, DOI 10.1115/1.4028093; Nanayakkara P, 2020, Arxiv, DOI arXiv:2011.13170; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rittel HW., 1974, MAN MADE FUTURES, V26, P272; Song H, 2019, J COMPUT INF SCI ENG, V19, DOI 10.1115/1.4043364; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Youmans RJ, 2014, AI EDAM, V28, P129, DOI 10.1017/S0890060414000043; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105	42	2	2	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0180-1				2023							325	329		10.1145/3591196.3596818	http://dx.doi.org/10.1145/3591196.3596818			5	Art; Computer Science, Interdisciplinary Applications; Psychology, Multidisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Art; Computer Science; Psychology	BW2MQ					2024-07-03	WOS:001119074200044
C	Tan, QY; Ng, HT; Bing, LD		Rogers, A; Boyd-Graber, J; Okazaki, N		Tan, Qingyu; Ng, Hwee Tou; Bing, Lidong			Towards Benchmarking and Improving the Temporal Reasoning Capability of Large Language Models	PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1			English	Proceedings Paper	61st Annual Meeting of the the Association-for-Computational-Linguistics (ACL)	JUL 09-14, 2023	Toronto, CANADA	Assoc Computat Linguist, Cohere, Microsoft, Bloomberg, Google Res, Liveperson, Meta, Apple, IBM, Amazon Sci, Baidu, ByteDance, Google DeepMind, Flitto, Grammarly, Huawei, Kaust Artificial Intelligence Initiat, Megagon Labs, Dataocean AI, Ant Grp, Comcast, J P Morgan, NEC, Tencent, Aixplain, Alibaba Grp, Bosch, Duolingo, Translated, Adobe, Babelscape, Servicenow				Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types. In this paper, we introduce a comprehensive probing dataset TEMPREASON to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning. We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach(1).	[Tan, Qingyu; Bing, Lidong] Alibaba Grp, DAMO Acad, Hangzhou, Peoples R China; [Tan, Qingyu; Ng, Hwee Tou] Natl Univ Singapore, Dept Comp Sci, Singapore, Singapore	Alibaba Group; National University of Singapore	Ng, HT (corresponding author), Natl Univ Singapore, Dept Comp Sci, Singapore, Singapore.	qingyu.tan@alibaba-inc.com; nght@comp.nus.edu.sg; l.bing@alibaba-inc.com						Bethard Steven, 2016, SEMEVAL 2016 TASK 12; Bordes A., 2013, ADV NEURAL INFORM PR, P2787, DOI DOI 10.5555/2999792.2999923; Cassidy Taylor, 2014, P ACL; Chen Wenhu, 2021, P NIPS; Chia Yew Ken, 2022, P EMNLP; Dasgupta Shib Sankar, 2018, P EMNLP; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dhingra Bhuwan, 2022, T ACL; Ding Bosheng, 2023, P ACL; Faghihi Hossein Rajaby, 2021, P NAACL; Fei Hao, 2023, P ACL; Guu K, 2020, PR MACH LEARN RES, V119; Jia Z, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P1057, DOI 10.1145/3184558.3191536; Jia Z, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1807, DOI 10.1145/3269206.3269247; Jia Zhen, 2021, P CIKM; Jiang Tingsong, 2016, P COLING; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kasai Jungo, 2022, P EMNLP; Kipf T. N., 2016, ICLR, DOI 10.48550/arXiv.1609.02907; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lacroix T., 2020, INT C LEARNING REPRE; Lee C, 2019, L@S '19: PROCEEDINGS OF THE SIXTH (2019) ACM CONFERENCE ON LEARNING @ SCALE; Liska Adam, 2022, P ICML; Liu YH, 2019, INFORM SYST RES, DOI 10.48550/arXiv.1907.11692; Mavromatis C, 2022, AAAI CONF ARTIF INTE, P5825; Ning Qiang, 2020, P EMNLP; Ouyang Long, 2022, ARXIV220302155; Pustejovsky J., 2003, Corpus linguistics, P40; Raffel C, 2020, J MACH LEARN RES, V21; Rajpurkar P., 2016, P 2016 C EMPIRICAL M; RalphWeischedel Martha Palmer, 2013, ONTONOTES RELEASE 5, P23; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Saxena Apoorv, 2021, P ACL; Schulman J., 2017, ARXIV; Shang Chao, 2022, P ACL; Verhagen Marc, 2010, P SEMEVAL; Vrandeci Denny, 2014, P CACM; Wang Z, 2014, AAAI CONF ARTIF INTE, P1112; Wei J., 2022, P ICLR; Ye Hai, 2023, P ACL; Yu MJ, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445175; Zhao Ruochen, 2023, P ACL	42	0	0	0	0	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-959429-72-2				2023							14820	14835						16	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW7IT					2024-07-03	WOS:001190962506033
J	Sledge, D; Thomas, HF				Sledge, Daniel; Thomas, Herschel F.			Risk communication and large language models	RISK HAZARDS & CRISIS IN PUBLIC POLICY			English	Article; Early Access						disaster planning and preparedness; large language models; risk communication	SOCIAL MEDIA; INFORMATION	The widespread embrace of Large Language Models (LLMs) integrated with chatbot interfaces, such as ChatGPT, represents a potentially critical moment in the development of risk communication and management. In this article, we consider the implications of the current wave of LLM-based chat programs for risk communication. We examine ChatGPT-generated responses to 24 different hazard situations. We compare these responses to guidelines published for public consumption on the US Department of Homeland Security's Ready.gov website. We find that, although ChatGPT did not generate false or misleading responses, ChatGPT responses were typically less than optimal in terms of their similarity to guidances from the federal government. While delivered in an authoritative tone, these responses at times omitted important information and contained points of emphasis that were substantially different than those from Ready.gov. Moving forward, it is critical that researchers and public officials both seek to harness the power of LLMs to inform the public and acknowledge the challenges represented by a potential shift in information flows away from public officials and experts and towards individuals.	[Sledge, Daniel] Univ Oklahoma Hlth Sci, Hudson Coll Publ Hlth, 801 NE 13th St,Room 369,POB 26901, Oklahoma City, OK 73104 USA; [Thomas, Herschel F.] Univ Texas Austin, Lyndon B Johnson Sch Publ Affairs, Austin, TX USA	University of Oklahoma System; University of Oklahoma Health Sciences Center; University of Texas System; University of Texas Austin	Sledge, D (corresponding author), Univ Oklahoma Hlth Sci, Hudson Coll Publ Hlth, 801 NE 13th St,Room 369,POB 26901, Oklahoma City, OK 73104 USA.	daniel-sledge@ouhsc.edu						Alschner Wolfgang Julia, 2017, ADBI Working Paper; Balog-Way D, 2020, RISK ANAL, V40, P2240, DOI 10.1111/risa.13615; Bommasani R., 2021, PREPRINT; Bouchet-Valat Milan, 2023, SnowballC: Snowball Stemmers Based on the C 'libstemmer' UTF-8 Library; Chou WYS, 2018, JAMA-J AM MED ASSOC, V320, P2417, DOI 10.1001/jama.2018.16865; Dargin JS, 2021, INT J DISAST RISK RE, V54, DOI 10.1016/j.ijdrr.2021.102043; Eckert S, 2018, HEALTH COMMUN, V33, P1389, DOI 10.1080/10410236.2017.1351278; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; Houston JB, 2015, DISASTERS, V39, P1, DOI 10.1111/disa.12092; Hu K., 2023, Reuters; Kevin Roose, 2023, International New York Times; Krügel S, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-31341-0; Kuipers S, 2023, RISK HAZARDS CRISIS, V14, P272, DOI 10.1002/rhc3.12283; Li YC, 2021, HEALTH EDUC RES, V36, P261, DOI 10.1093/her/cyab010; Lovari A, 2020, J PUBLIC AFF, V20, DOI 10.1002/pa.1967; Open AI, 2023, ChatGPT; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Sanger W, 2019, DATA BRIEF, V24, DOI 10.1016/j.dib.2019.103907; Silge J., 2016, J OPEN SOURCE SOFTW, V1, P37, DOI DOI 10.21105/JOSS.00037; Silver A, 2017, INFORM COMMUN SOC, V20, P1680, DOI 10.1080/1369118X.2016.1253762; Simon T, 2015, INT J INFORM MANAGE, V35, P609, DOI 10.1016/j.ijinfomgt.2015.07.001; Steelman TA, 2013, NAT HAZARDS, V65, P683, DOI 10.1007/s11069-012-0386-z; Sutton J, 2018, AM J PUBLIC HEALTH, V108, P1281, DOI 10.2105/AJPH.2018.304661; Terren L, 2021, REV COMMUN RES, V9, P99, DOI 10.12840/ISSN.2255-4165.028; The United States Department of Homeland Security, 2023, Ready.Gov: 'About Us; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Van Wyk H, 2023, INT J DISAST RISK RE, V86, DOI 10.1016/j.ijdrr.2023.103548; Wang BR, 2018, NAT HAZARDS, V93, P1145, DOI 10.1007/s11069-018-3344-6; Wang YX, 2019, SOC SCI MED, V240, DOI 10.1016/j.socscimed.2019.112552; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; Zamfrescu-Pereira JD, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581388; Zhang M., 2023, PREPRINT	32	0	0	1	1	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1944-4079			RISK HAZARDS CRISIS	Risk Hazards Crisis Public Policy	2024 MAY 3	2024										10.1002/rhc3.12303	http://dx.doi.org/10.1002/rhc3.12303		MAY 2024	11	Public Administration	Emerging Sources Citation Index (ESCI)	Public Administration	PW6Q3					2024-07-03	WOS:001217162200001
C	Hu, ZY; Feng, Y; Luu, AT; Hooi, B; Lipani, A			ACM	Hu, Zhiyuan; Feng, Yue; Luu, Anh Tuan; Hooi, Bryan; Lipani, Aldo			Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Dialogue system; Large Language Model; User Simulation		Dialogue systems and large language models (LLMs) have gained considerable attention. However, the direct utilization of LLMs as task-oriented dialogue (TOD) models has been found to underperform compared to smaller task-specific models. Nonetheless, it is crucial to acknowledge the significant potential of LLMs and explore improved approaches for leveraging their impressive abilities. Motivated by the goal of leveraging LLMs, we propose an alternative approach called User-Guided Response Optimization (UGRO) to combine it with a smaller TOD model. This approach uses LLM as an annotation-free user simulator to assess dialogue responses, combining them with smaller fine-tuned end-to-end TOD models. By utilizing the satisfaction feedback generated by LLMs, UGRO further optimizes the supervised fine-tuned TOD model. Specifically, the TOD model takes the dialogue history as input and, with the assistance of the user simulator's feedback, generates high-satisfaction responses that meet the user's requirements. Through empirical experiments on two TOD benchmarks, we validate the effectiveness of our method. The results demonstrate that our approach outperforms previous state-of-the-art (SOTA) results.	[Hu, Zhiyuan; Hooi, Bryan] Natl Univ Singapore, Singapore, Singapore; [Feng, Yue; Lipani, Aldo] UCL, London, England; [Luu, Anh Tuan] Nanyang Technol Univ, Singapore, Singapore	National University of Singapore; University of London; University College London; Nanyang Technological University	Hu, ZY (corresponding author), Natl Univ Singapore, Singapore, Singapore.	zhiyuan_hu@u.nus.edu; yue.feng.20@ucl.ac.uk; anhtuan.luu@ntu.edu.sg; bhooi@comp.nus.edu.sg; aldo.lipani@ucl.ac.uk	Luu, Anh Tuan/AAG-3582-2021; Hu, Zhiyuan/JPX-7229-2023; Hooi, Bryan/AAU-5707-2020; Lipani, Aldo/H-6258-2019	Hooi, Bryan/0000-0002-5645-1754; Lipani, Aldo/0000-0002-3643-6493; Luu, Anh Tuan/0000-0001-6062-207X				Andreas Vinsen Marselino, 2021, 2021 8 INT C ADV INF, P1; Bang Namo, 2023, ARXIV230502468; Budzianowski P, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5016; Chung Hyung Won, 2022, ARXIV221011416; Deng Y, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2998, DOI 10.1145/3485447.3512020; Erbacher P, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2420, DOI 10.1145/3477495.3531871; Feng Yue, 2023, ARXIV230516798; He WW, 2022, AAAI CONF ARTIF INTE, P10749; Hudecek Vojtech, 2023, ARXIV230406556; Kahneman D., 2011, THINKING FAST SLOW; Kim TE, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2115, DOI 10.1145/3477495.3531814; Kojima Takeshi, 2022, arXiv preprint arXiv:2205.11916; Lee Y, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1296; Li Zekun, 2022, FINDINGS ASS COMPUTA, P4330, DOI [10.18653/v1/2022. findings-emnlp.318, DOI 10.18653/V1/2022.FINDINGS-EMNLP.318]; Li Zekun, 2023, ARXIV230211520; Ong D, 2022, AAAI CONF ARTIF INTE, P11121; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Rastogi A, 2020, AAAI CONF ARTIF INTE, V34, P8689; Ren FY, 2004, IEEE SYMP COMP COMMU, P748, DOI 10.1109/ISCC.2004.1358630; Schulman J., 2017, ARXIV; Snell Charlie, 2022, ARXIV220410198; Su Yixuan, 2021, ARXIV210914739; Sun WW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2499, DOI 10.1145/3404835.3463241; Wang Jianhong, 2020, ARXIV200606814; Wang Kai, 2020, ARXIV200412363; WEI JT, 2023, ICASSP 2023 2023 IEE, DOI DOI 10.1007/S42947-023-00292-0; Ye Fanghua, 2023, ARXIV230512594; Yu Xiao, 2022, ARXIV221116773; Zerhoudi S, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P4661, DOI 10.1145/3511808.3557711	29	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							3953	3957		10.1145/3583780.3615220	http://dx.doi.org/10.1145/3583780.3615220			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Submitted, Bronze			2024-07-03	WOS:001161549503121
J	Niszczota, P; Abbas, S				Niszczota, Pawel; Abbas, Sami			GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice	FINANCE RESEARCH LETTERS			English	Article						Financial literacy; Robo-advice; Financial advice; Advice-utilization; Large language model; ChatGPT	JUDGMENT	We assess the ability of GPT-a large language model-to serve as a financial robo-advisor for the masses, by using a financial literacy test. Davinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial literacy test, respectively, compared to a baseline of 33%. However, ChatGPT based on GPT-4 achieves a near-perfect 99% score, pointing to financial literacy becoming an emergent ability of state-of-the-art models. We use the Judge-Advisor System and a savings dilemma to illustrate how researchers might assess advice-utilization from large language models. We also present a number of directions for future research.	[Niszczota, Pawel; Abbas, Sami] Poznan Univ Econ & Business, Inst Int Business & Econ, Humans & AI Lab HAI Lab, Poznan, Poland; [Niszczota, Pawel] Poznan Univ Econ & Business, Al Niepodleglosci 10, PL-61875 Poznan, Poland	Poznan University of Economics & Business; Poznan University of Economics & Business	Niszczota, P (corresponding author), Poznan Univ Econ & Business, Al Niepodleglosci 10, PL-61875 Poznan, Poland.	pawel.niszczota@ue.poznan.pl	Niszczota, Paweł/P-8289-2018; Abbas, Sami/ABG-7580-2021	Niszczota, Paweł/0000-0002-4150-3646; 	National Science centre, Poland [2021/42/E/HS4/00289]; Regional Initiative for Excellence program of the Minister of Science and Higher Education of Poland [004/RID/2018/19]	National Science centre, Poland(National Science Centre, Poland); Regional Initiative for Excellence program of the Minister of Science and Higher Education of Poland	This research was supported by grant 2021/42/E/HS4/00289 from the National Science centre, Poland, and grant 004/RID/2018/19 from the Regional Initiative for Excellence program of the Minister of Science and Higher Education of Poland (2019-2022) .	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bailey PE, 2023, CURR PSYCHOL, V42, P24516, DOI 10.1007/s12144-022-03573-2; Bommarito J., 2023, arXiv, DOI [DOI 10.48550/ARXIV.2301.04408, 10.48550/arXiv.2301.04408]; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Chak I., 2022, Working Paper Series, DOI [10.3386/w30616, DOI 10.3386/W30616]; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; D'Acunto F, 2019, REV FINANC STUD, V32, P1983, DOI 10.1093/rfs/hhz014; Disney R, 2015, J PENSION ECON FINAN, V14, P466, DOI 10.1017/S1474747215000219; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Harvey N, 1997, ORGAN BEHAV HUM DEC, V70, P117, DOI 10.1006/obhd.1997.2697; Heinberg A, 2014, OXFORD REV ECON POL, V30, P697, DOI 10.1093/oxrep/gru036; Isaia E, 2022, FINANC RES LETT, V48, DOI 10.1016/j.frl.2022.103046; Korinek A., 2023, Cambridge, MA, DOI DOI 10.3386/W30957; Lewis DR, 2018, J FINANC SERV MARK, V23, P104, DOI 10.1057/s41264-018-0048-7; Logg JM, 2019, ORGAN BEHAV HUM DEC, V151, P90, DOI 10.1016/j.obhdp.2018.12.005; Lopez-Lira A., 2023, Return Predictability and Large Language Models, DOI DOI 10.2139/SSRN.4412788; Mitchell O.S., 2022, Financial literacy and financial behavior at older ages, DOI [10.2139/ssrn.4006687, DOI 10.2139/SSRN.4006687]; Niszczota P, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0239277; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Price PC, 2004, J BEHAV DECIS MAKING, V17, P39, DOI 10.1002/bdm.460; Roose Kevin, 2022, NEW YORK TIMES; Sample I., 2023, GUARDIAN; Schulman J, 2022, Introducing chatgpt; Smithson M, 2006, PSYCHOL METHODS, V11, P54, DOI 10.1037/1082-989X.11.1.54; SNIEZEK JA, 1995, ORGAN BEHAV HUM DEC, V62, P159, DOI 10.1006/obhd.1995.1040; Srivastava Aarohi, 2022, arXiv; van Rooij M, 2011, J FINANC ECON, V101, P449, DOI 10.1016/j.jfineco.2011.03.006; Van Swol LM, 2005, BRIT J SOC PSYCHOL, V44, P443, DOI 10.1348/014466604X17092; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]	31	6	6	48	65	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1544-6123	1544-6131		FINANC RES LETT	Financ. Res. Lett.	DEC	2023	58		A						104333	10.1016/j.frl.2023.104333	http://dx.doi.org/10.1016/j.frl.2023.104333		AUG 2023	7	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	T7PX2		Green Submitted			2024-07-03	WOS:001079876600001
J	Choi, J; Lee, B				Choi, Jaewoong; Lee, Byungju			Accelerating materials language processing with large language models	COMMUNICATIONS MATERIALS			English	Article								Materials language processing (MLP) can facilitate materials science research by automating the extraction of structured data from research papers. Despite the existence of deep learning models for MLP tasks, there are ongoing practical issues associated with complex model architectures, extensive fine-tuning, and substantial human-labelled datasets. Here, we introduce the use of large language models, such as generative pretrained transformer (GPT), to replace the complex architectures of prior MLP models with strategic designs of prompt engineering. We find that in-context learning of GPT models with few or zero-shots can provide high performance text classification, named entity recognition and extractive question answering with limited datasets, demonstrated for various classes of materials. These generative models can also help identify incorrect annotated data. Our GPT-based approach can assist material scientists in solving knowledge-intensive MLP tasks, even if they lack relevant expertise, by offering MLP guidelines applicable to any materials science domain. In addition, the outcomes of GPT models are expected to reduce the workload of researchers, such as manual labelling, by producing an initial labelling set and verifying human-annotations. Materials language and processing with large language models provide an automated approach for text classification. Here, a generative pretrained transformer (GPT) approach is reported to provide a simple architecture for text classification, including identifying incorrectly annotated data and for manual labelling.	[Choi, Jaewoong; Lee, Byungju] Korea Inst Sci & Technol, Computat Sci Res Ctr, Seoul, South Korea	Korea Institute of Science & Technology (KIST)	Lee, B (corresponding author), Korea Inst Sci & Technol, Computat Sci Res Ctr, Seoul, South Korea.	blee89@kist.re.kr		Choi, Jaewoong/0000-0002-6994-4195; Lee, Byungju/0000-0002-8640-2689	National Research Foundation of Korea (NRF) [NRF-2021M3A7C2089739]; National Research Foundation of Korea - Ministry of Science and ICT [2E31742, 2E32533]; Institutional Projects at the Korea Institute of Science and Technology	National Research Foundation of Korea (NRF)(National Research Foundation of Korea); National Research Foundation of Korea - Ministry of Science and ICT(National Research Foundation of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea); Institutional Projects at the Korea Institute of Science and Technology	This work was supported by the National Research Foundation of Korea funded by the Ministry of Science and ICT (NRF-2021M3A7C2089739) and Institutional Projects at the Korea Institute of Science and Technology (2E31742 and 2E32533).	Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen L., 2023, R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models; Choi J, 2023, ACS APPL MATER INTER, V16, P1957, DOI 10.1021/acsami.3c12301; Choi J, 2023, J MATER CHEM A, V11, P17628, DOI 10.1039/d3ta02780e; Choudhary K, 2023, J PHYS CHEM C, V127, P17545, DOI 10.1021/acs.jpcc.3c03106; Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6; Dai F, 2022, COMMUN MATER, V3, DOI 10.1038/s43246-022-00286-8; Desai S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P295; Duan SH, 2023, COMMUN MATER, V4, DOI 10.1038/s43246-023-00377-0; Fujinuma N, 2022, COMMUN MATER, V3, DOI 10.1038/s43246-022-00283-x; Gao Y, 2023, ACS CATAL, V13, P8525, DOI 10.1021/acscatal.3c00759; Guo C., 2017, International conference on machine learning, P1321; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; Hatakeyama-Sato K, 2020, COMMUN MATER, V1, DOI 10.1038/s43246-020-00052-8; He TJ, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adg8180; Hendrycks D., 2019, BENCHMARKING NEURAL; Huang S, 2022, CHEM SCI, V13, P11487, DOI 10.1039/d2sc04322j; Huang S, 2022, J CHEM INF MODEL, V62, P6365, DOI 10.1021/acs.jcim.2c00035; Huang S, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00602-2; Huo HY, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0204-1; Keith JA, 2021, CHEM REV, V121, P9816, DOI 10.1021/acs.chemrev.1c00107; Kim J, 2020, NEUROCOMPUTING, V376, P214, DOI 10.1016/j.neucom.2019.10.033; Kononova O, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2021.102155; Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1; Lewis P., 2020, P 58 ANN M ASS COMPU, P7315; Li B, 2023, Arxiv, DOI arXiv:2304.11633; Li J, 2022, IEEE T KNOWL DATA EN, V34, P50, DOI 10.1109/TKDE.2020.2981314; Manica M, 2019, Arxiv, DOI arXiv:1907.08400; Nie ZW, 2022, ADV FUNCT MATER, V32, DOI 10.1002/adfm.202201437; Olivetti EA, 2020, APPL PHYS REV, V7, DOI 10.1063/5.0021106; Pei ZR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-022-35766-5; Polak MP, 2024, Arxiv, DOI [arXiv:2302.04914, DOI 10.48550/ARXIV.2302.04914, 10.48550/arXiv.2302.04914]; Polak MP, 2024, Arxiv, DOI [arXiv:2303.05352, DOI 10.48550/ARXIV.2303.05352]; Shantanu K., 2017, arXiv; Shetty P, 2023, NPJ COMPUT MATER, V9, DOI 10.1038/s41524-023-01003-w; Shetty P, 2021, J CHEM INF MODEL, V61, P5377, DOI 10.1021/acs.jcim.1c00554; Shetty P, 2021, ISCIENCE, V24, DOI 10.1016/j.isci.2020.101922; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Tsai R. T.-H., BMC bioinformatics, P1; Tsai RTH, 2006, BMC BIOINFORMATICS, V7, P1, DOI 10.1186/1471-2105-7-92; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Walker N, 2023, DIGIT DISCOV, V2, P1768, DOI 10.1039/d3dd00019b; Wang LD, 2023, SCI DATA, V10, DOI 10.1038/s41597-023-02089-z; Wang SH, 2023, Arxiv, DOI arXiv:2304.10428; Wang ZR, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01317-2; Weston L, 2019, J CHEM INF MODEL, V59, P3692, DOI 10.1021/acs.jcim.9b00470; Wilary DM, 2023, J CHEM INF MODEL, V63, P6053, DOI 10.1021/acs.jcim.3c00422; Xie T, 2023, Arxiv, DOI arXiv:2304.02213; Xu K, 2022, COMMUN MATER, V3, DOI 10.1038/s43246-022-00251-5; Yadav Vikas, 2018, Proceedings of the 27th International Conference on Computational Linguistics, P2145; Yang Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6365; Yin WP, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3914; Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474; Zhao SJ, 2023, NPJ MAT DEGRAD, V7, DOI 10.1038/s41529-022-00319-0; Zheng ZL, 2023, ANGEW CHEM INT EDIT, V62, DOI 10.1002/anie.202311983; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819	58	1	1	23	23	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2662-4443		COMMUN MATER	Commun. Mater.	FEB 15	2024	5	1							13	10.1038/s43246-024-00449-9	http://dx.doi.org/10.1038/s43246-024-00449-9			11	Materials Science, Multidisciplinary	Emerging Sources Citation Index (ESCI)	Materials Science	IU8W9		gold			2024-07-03	WOS:001168952600001
J	Wang, L; Ma, C; Feng, XY; Zhang, ZY; Yang, H; Zhang, JS; Chen, ZY; Tang, JK; Chen, X; Lin, YK; Zhao, WX; Wei, ZW; Wen, JR				Wang, Lei; Ma, Chen; Feng, Xueyang; Zhang, Zeyu; Yang, Hao; Zhang, Jingsen; Chen, Zhiyuan; Tang, Jiakai; Chen, Xu; Lin, Yankai; Zhao, Wayne Xin; Wei, Zhewei; Wen, Jirong			A survey on large language model based autonomous agents	FRONTIERS OF COMPUTER SCIENCE			English	Review						autonomous agent; large language model; human-level intelligence		Autonomous agents have long been a research focus in academic and industry communities. Previous research often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of Web knowledge, large language models (LLMs) have shown potential in human-level intelligence, leading to a surge in research on LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of LLM-based autonomous agents from a holistic perspective. We first discuss the construction of LLM-based autonomous agents, proposing a unified framework that encompasses much of previous work. Then, we present a overview of the diverse applications of LLM-based autonomous agents in social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field.	[Wang, Lei; Ma, Chen; Feng, Xueyang; Zhang, Zeyu; Yang, Hao; Zhang, Jingsen; Chen, Zhiyuan; Tang, Jiakai; Chen, Xu; Lin, Yankai; Zhao, Wayne Xin; Wei, Zhewei; Wen, Jirong] Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China	Renmin University of China	Chen, X; Lin, YK (corresponding author), Renmin Univ China, Gaoling Sch Artificial Intelligence, Beijing 100872, Peoples R China.	xu.chen@ruc.edu.cn; yankailin@ruc.edu.cn	yang, le/KFB-5420-2024; WANG, YANAN/KCL-4840-2024; zhang, yan/KHC-3163-2024; zhang, can/KHC-5357-2024; xie, jing/KDO-9486-2024; Feng, Xueyang/G-1295-2015; Zhang, Zeyu/HSE-5005-2023; su, lin/KHC-5034-2024; Wang, Zhen/KCL-5193-2024; ren, jun/KHG-7717-2024; guo, yi/KHC-4669-2024; Xia, Lianghao/IWV-0954-2023; li, jing/KHC-8303-2024; Huang, Yong/KFA-1191-2024; li, feiyang/KHW-5210-2024; liu, qi/KHC-7509-2024; wang, rong/KFQ-7187-2024; Liu, yuqing/KEI-3260-2024		National Natural Science Foundation of China [62102420]; Beijing Outstanding Young Scientist Program [BJJWZYJH012019100020098]; Intelligent Social Governance Platform; Major Innovation & Planning Interdisciplinary Platform for the "Double-First Class" Initiative, Renmin University of China; Public Computing Cloud, Renmin University of China, fund for building world-class universities (disciplines) of Renmin University of China, Intelligent Social Governance Platform	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Beijing Outstanding Young Scientist Program; Intelligent Social Governance Platform; Major Innovation & Planning Interdisciplinary Platform for the "Double-First Class" Initiative, Renmin University of China; Public Computing Cloud, Renmin University of China, fund for building world-class universities (disciplines) of Renmin University of China, Intelligent Social Governance Platform	This work was supported in part by the National Natural Science Foundation of China (Grant No. 62102420), the Beijing Outstanding Young Scientist Program (No. BJJWZYJH012019100020098), Intelligent Social Governance Platform, Major Innovation & Planning Interdisciplinary Platform for the "Double-First Class" Initiative, Renmin University of China, Public Computing Cloud, Renmin University of China, fund for building world-class universities (disciplines) of Renmin University of China, Intelligent Social Governance Platform.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Aher GV, 2023, INT C MACHINE LEARNI, P337; Akata E, 2023, Arxiv, DOI [arXiv:2305.16867, DOI 10.48550/ARXIV.2305.16867]; [Anonymous], 2023, Ai-legion; [Anonymous], 2023, Mini-agi; [Anonymous], 2023, AGiXT; [Anonymous], 2023, Transformers agent; [Anonymous], 2023, GPT-engineer; [Anonymous], 2023, Xlang; [Anonymous], 2023, AutoGPT; [Anonymous], 2023, SuperAGI; [Anonymous], 2023, langchain; [Anonymous], 2023, LoopGPT; [Anonymous], 2023, AgentGPT; [Anonymous], 2023, WorkGPT; [Anonymous], 2023, SmolModels; [Anonymous], 2023, A E. GPT-researcher; [Anonymous], 2023, BabyAGI; [Anonymous], 2023, DemoGPT; Anthropic, 2023, Technical report Anthropic; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Bail C A., 2023, Can generative ai improve social science?; Banerjee D, 2023, Arxiv, DOI arXiv:2308.04624; Besta M, 2024, Arxiv, DOI arXiv:2308.09687; Boiko DA, 2023, Arxiv, DOI [arXiv:2304.05332, DOI 10.48550/ARXIV.2304.05332]; Bran AM, 2023, Arxiv, DOI [arXiv:2304.05376, 10.48550/arXiv.2304.05376]; Brown N., 2023, C ROBOT LEARNING, P287; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chalamalasetti K, 2023, P 2023 C EMPIRICAL M, P11174; Chan CM, 2023, Arxiv, DOI [arXiv:2308.07201, 10.48550/arXiv.2308.07201, DOI 10.48550/ARXIV.2308.07201]; Chang TA, 2023, COMPUT LINGUIST, V50, P293, DOI 10.1162/coli_a_00492; Chang Y., 2024, ACM Trans. Intell. Syst. Technol., V15, P39, DOI DOI 10.1145/3641289; Chen AELC, 2024, Arxiv, DOI arXiv:2305.14279; Chen LT, 2023, Arxiv, DOI arXiv:2305.11598; Chen M., 2021, arXiv; Chen PL, 2023, Arxiv, DOI arXiv:2308.01552; Chen WZ, 2023, Arxiv, DOI arXiv:2308.10848; Chen XS, 2019, 36 INT C MACHINE LEA, V97; Chen Z, 2023, FINDINGS ASS COMPUTA, P14777; Choi M, 2023, P 2023 C EMP METH NA, P11370; Colas C, 2023, C LIFELONG LEARNING, P205; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Dagan G, 2023, Arxiv, DOI arXiv:2308.06391; Dan YH, 2023, Arxiv, DOI arXiv:2308.02773; Dasgupta I, 2023, Arxiv, DOI arXiv:2302.00763; Deng GL, 2024, Arxiv, DOI arXiv:2308.06782; Deshpande A, 2023, FINDINGS ASS COMPUTA, P1236; Di Palo N, 2023, Arxiv, DOI arXiv:2307.09668; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Du YL, 2023, Arxiv, DOI arXiv:2305.14325; Dziri N, 2024, Advances in Neural Information Processing Systems, V36; Evans JST, 2013, PERSPECT PSYCHOL SCI, V8, P223, DOI 10.1177/1745691612460685; Feldt R, 2023, IEEE INT CONF AUTOM, P1688, DOI 10.1109/ASE56229.2023.00148; Fischer KA, 2023, Arxiv, DOI arXiv:2305.12647; Fu Y, 2023, P 37 C NEUR INF PROC, P36; Gao C, 2023, Arxiv, DOI arXiv:2307.14984; Ge Y, 2023, P 37 C NEUR INF PROC, P36; Gekhman Z, 2023, T ASSOC COMPUT LING, V11, P351, DOI 10.1162/tacl_a_00549; Gramopadhye M, 2023, IEEE INT C INT ROBOT, P3568, DOI 10.1109/IROS55552.2023.10341989; Grossmann I, 2023, SCIENCE, V380, P1108, DOI 10.1126/science.adi1778; Haarnoja T, 2018, PR MACH LEARN RES, V80; Hamilton S, 2023, arXiv; Hao S, 2023, P 2023 C EMPIRICAL M, P8154; He Z, 2023, P 5 ACM IEEE WORKSH, P1; Hong S, 2023, Arxiv, DOI arXiv:2308.00352; Horton JJ, 2023, Arxiv, DOI [arXiv:2301.07543, DOI 10.48550/ARXIV.2301.07543]; Hu B, 2024, Arxiv, DOI arXiv:2306.03604; Hu CX, 2023, Arxiv, DOI arXiv:2306.03901; Huang J, 2023, FINDINGS ASS COMPUTA, P1049, DOI [DOI 10.18653/V1/2023.FINDINGS-ACL.67, 10.18653/v1/2023.findings-acl.67]; Huang JT, 2024, Arxiv, DOI arXiv:2308.03656; Huang W, 2023, P 6 C ROBOT LEARNING, P1769; Huang WL, 2022, PR MACH LEARN RES; Huang X, 2024, Arxiv, DOI arXiv:2308.16505; Huang ZH, 2023, ADJUNCT PROCEEDINGS OF THE 36TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2023 ADJUNCT, DOI 10.1145/3586182.3615796; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; John OP., 1991, Journal of personality and social psychology, DOI [10.1037/t07550-000, DOI 10.1037/T07550-000]; Johnson JA, 2014, J RES PERS, V51, P78, DOI 10.1016/j.jrp.2014.05.003; Kang S, 2023, PROC INT CONF SOFTW, P2312, DOI 10.1109/ICSE48619.2023.00194; Kang Y, 2023, Arxiv, DOI arXiv:2308.01423; Karpas E., 2022, arXiv; Kojima T., 2022, Advances in neural information processing systems, V35, P22199; Kovac G, 2023, arXiv; Krishna R, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2115730119; Lee MA, 2024, Arxiv, DOI arXiv:2212.09746; Li C, 2023, Arxiv, DOI arXiv:2308.03313; Li C, 2023, Arxiv, DOI [arXiv:2307.11760, DOI 10.48550/ARXIV.2307.11760, 10.48550/arXiv.2307.11760]; Li GH, 2023, Arxiv, DOI arXiv:2303.17760; Li H, 2023, arXiv; Li M, 2023, P 2023 C EMPIRICAL M, P3102, DOI DOI 10.18653/V1/2023.EMNLP; Li SY, 2023, Arxiv, DOI arXiv:2307.10337; Liang XN, 2023, Arxiv, DOI arXiv:2304.13343; Liang YB, 2023, Arxiv, DOI arXiv:2303.16434; Liang YZ, 2023, Arxiv, DOI arXiv:2307.12573; Liffiton Mark, 2023, Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research, DOI 10.1145/3631802.3631830; Lillicrap T. P., 2019, arXiv; Lin JSY, 2024, Arxiv, DOI arXiv:2305.20076; Lin JJ, 2023, Arxiv, DOI arXiv:2308.04026; Liu B, 2023, Arxiv, DOI arXiv:2304.11477; Liu H, 2023, Arxiv, DOI arXiv:2302.02676; Liu RB, 2023, Arxiv, DOI arXiv:2305.16960; Liu X, 2023, Arxiv, DOI arXiv:2308.03688; Liu ZW, 2023, Arxiv, DOI arXiv:2308.05960; Ma Zilin, 2023, AMIA Annu Symp Proc, V2023, P1105; Madaan A, 2022, P 2022 C EMPIRICAL M, P2833; Mandi Z, 2023, Arxiv, DOI arXiv:2307.04738; Matelsky JK, 2023, Arxiv, DOI arXiv:2308.02439; Mehta N, 2024, Arxiv, DOI arXiv:2304.10750; Mialon G., 2023, arXiv; Miao N, 2023, Arxiv, DOI arXiv:2308.00436; Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236; Modarressi A, 2023, Arxiv, DOI arXiv:2305.14322; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Nascimento Nathalia, 2023, 2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C), P104, DOI 10.1109/ACSOS-C58168.2023.00048; Ng Y, 2023, Arxiv, DOI arXiv:2308.03983; Nottingham K, 2023, INT C MACHINE LEARNI, P26311; Ogundare O, 2023, Ctrl Mech Auto, P458, DOI 10.1109/ICCMA59762.2023.10374622; Park Joon Sung, 2023, UIST '23: Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology, DOI 10.1145/3586183.3606763; Park JS, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545616; Patil SG, 2023, Arxiv, DOI arXiv:2305.15334; Qian C, 2024, Arxiv, DOI arXiv:2307.07924; Qin YJ, 2023, Arxiv, DOI arXiv:2307.16789; Qin YJ, 2023, Arxiv, DOI arXiv:2304.08354; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raman S S, 2022, P FDN MOD DEC MAK WO; Rana K, 2023, P C ROBOT LEARNING C, P23; Ruan JQ, 2023, Arxiv, DOI arXiv:2308.03427; Saha S, 2023, Arxiv, DOI arXiv:2306.09299; Schick T, 2023, P 37 C NEUR INF PROC, P36; Schulman J, 2017, Arxiv, DOI [arXiv:1707.06347, DOI 10.48550/ARXIV.1707.06347]; Schuurmans D, 2023, arXiv; Sclar M, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P13960; Sel B, 2024, Arxiv, DOI arXiv:2308.10379; Serapio-Garcia G, 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2307.00184; Shen Y, 2023, P 37 C NEUR INF PROC, P36; Shi JX, 2023, Arxiv, DOI arXiv:2308.12503; Shinn N, 2023, NAIN P 37 C NEUR INF, P36; Shu YB, 2023, Arxiv, DOI arXiv:2308.09904; Song Chan Hee, 2023, 2023 IEEE/CVF International Conference on Computer Vision (ICCV), P2986, DOI 10.1109/ICCV51070.2023.00280; Song YF, 2023, Arxiv, DOI arXiv:2306.06624; Sun RX, 2024, Arxiv, DOI arXiv:2306.00739; Surís D, 2023, Arxiv, DOI [arXiv:2303.08128, DOI 10.48550/ARXIV.2303.08128(2023).2303.08128]; Swan M, 2023, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wang L, 2023, Arxiv, DOI arXiv:2306.02552; Wang X, 2023, P 11 INT C LEARN REP; Wang YC, 2024, Arxiv, DOI arXiv:2308.14296; Wang YF, 2023, Arxiv, DOI arXiv:2307.12966; Wang ZH, 2023, Arxiv, DOI [arXiv:2302.01560, 10.48550/arXiv.2302.01560]; Wei JS, 2022, ADV NEUR IN; Weng X, 2023, P 37 C NEUR INF PROC, P36; Williams R, 2023, Arxiv, DOI [arXiv:2307.04986, DOI 10.48550/ARXIV.2307.04986]; Wu J, 2023, IEEE INT C INT ROBOT, P3546, DOI 10.1109/IROS55552.2023.10341577; Wu QY, 2023, Arxiv, DOI arXiv:2308.08155; Wu Y, 2023, Arxiv, DOI arXiv:2305.02412; Wu ZY, 2023, Arxiv, DOI arXiv:2307.01848; Xia Y, 2023, P 2023 IEEE 28 INT C, P1; Xiang J, 2023, P 37 C NEUR INF PROC, P36; Xu B, 2023, P 2023 C EMPIRICAL M, P237; Xu BF, 2023, Arxiv, DOI arXiv:2305.18323; Yang JF, 2024, ACM T KNOWL DISCOV D, V18, DOI 10.1145/3649506; Yang ZY, 2023, Arxiv, DOI [arXiv:2303.11381, 10.48550/arXiv.2303.11381]; Yao S, 2023, P 11 INT C LEARN REP; Yao S, 2022, Advances in Neural Information Processing Systems, P20744; Yao S, 2023, P 37 C NEUR INF PROC, P36; Yao WR, 2024, Arxiv, DOI arXiv:2308.02151; Zhang CY, 2024, Arxiv, DOI arXiv:2308.11339; Zhang CR, 2023, Arxiv, DOI arXiv:2308.12033; Zhang C, 2023, Arxiv, DOI arXiv:2312.13771; Zhang D, 2023, P 37 C NEUR INF PROC, P36; Zhang DY, 2024, Arxiv, DOI arXiv:2305.08144; Zhang HX, 2024, Arxiv, DOI arXiv:2307.02485; Zhao A, 2023, Arxiv, DOI arXiv:2308.10144; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhong WJ, 2023, Arxiv, DOI arXiv:2305.10250; Zhou S, 2024, Arxiv, DOI arXiv:2307.13854; Zhou W, 2023, Arxiv, DOI arXiv:2307.15833; Zhou XH, 2023, Arxiv, DOI arXiv:2308.05481; Zhu A, 2023, P AAAI C ARTIFICIAL, P380; Zhu XZ, 2023, Arxiv, DOI arXiv:2305.17144; Zhuge M, 2023, arXiv; Zhuo TY, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P1090; Ziems C, 2023, Arxiv, DOI [arXiv:2305.03514, DOI 10.48550/ARXIV.2305.03514, 10.48550/arXiv.2305.03514]	186	4	4	54	54	HIGHER EDUCATION PRESS	BEIJING	CHAOYANG DIST, 4, HUIXINDONGJIE, FUSHENG BLDG, BEIJING 100029, PEOPLES R CHINA	2095-2228	2095-2236		FRONT COMPUT SCI-CHI	Front.. Comput. Sci.	DEC	2024	18	6							186345	10.1007/s11704-024-40231-1	http://dx.doi.org/10.1007/s11704-024-40231-1			26	Computer Science, Information Systems; Computer Science, Software Engineering; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	LU1Y7		hybrid, Green Submitted			2024-07-03	WOS:001189235000001
C	Kim, J; Lane, I			IEEE	Kim, Jungsuk; Lane, Ian			ACCELERATING LARGE VOCABULARY CONTINUOUS SPEECH RECOGNITION ON HETEROGENEOUS CPU-GPU PLATFORMS	2014 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP)	International Conference on Acoustics Speech and Signal Processing ICASSP		English	Proceedings Paper	IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	MAY 04-09, 2014	Florence, ITALY	IEEE, IEEE Signal Proc Soc		Large Vocabulary Continuous Speech Recognition (LVCSR); Weighted Finite State Transducer (WFST); Graphics Processing Units (GPU)		While prior works have demonstrated the effectiveness of Graphic-Processing Units (GPUs) for limited vocabulary speech recognition, these methods were unsuitable for recognition with large language models. To overcome this limitation, previously we introduced a novel "on-the-fly rescoring" approach in which search was performed over a WFST-network composed with a unigram language model on the GPU, and partial hypotheses were rescored on-the-fly using a large language model stored on the CPU. In this paper, we extend our previous algorithm to enable on-the-fly rescoring to be performed over an H-level network composed with any n-gram language model, and show that using a longer language model history in the H-level network improves decoding speed. We demonstrate that large language models can be applied on-the-fly with no degradation in decoding speed, realizing a LVCSR system that performs recognition over 22x faster than a CPU implementation with no loss in recognition accuracy.	[Kim, Jungsuk; Lane, Ian] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA	Carnegie Mellon University	Kim, J (corresponding author), Carnegie Mellon Univ, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.	jungsuk@cmu.edu; lane@cs.cmu.edu						[Anonymous], AUDIO SPEECH LANGUAG; [Anonymous], P 10 ANN C INT SPEEC; Antoine C. W., 2001, PARALLEL COMPUT, V27, P2000; Caseiro D., 2002, P INTERSPEECH; Caseiro D, 2006, IEEE T AUDIO SPEECH, V14, P1281, DOI 10.1109/TSA.2005.860838; Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313; Dixon P. R., 2009, P ICASSP; Dixon PR, 2012, INT CONF ACOUST SPEE, P4209, DOI 10.1109/ICASSP.2012.6288847; Dixon PR, 2009, COMPUT SPEECH LANG, V23, P510, DOI 10.1016/j.csl.2009.03.005; Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597; Hori T., 2004, P INTERSPEECH; Hori T., 2007, GOOGLE SEARCH VOICE, V15, P1352; HORI T, 2005, P EUR, P557; Hsiao R., 2011, HDB NATURAL LANGUAGE, P496; Kim J., 2012, COMPUTER SPEECH LANG, P1183; Kim J., 2011, COMPUTER SPEECH LANG, P1733; Kveton P., 2010, P INTERSPEECH; Ljolje A., 1999, P EUR; Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184; Nallasamy U., 2011, HDB NATURAL LANGUAGE, P535; NVIDIA, 2012, NVIDIA CUDA PROGR GU; Povey D, 2012, INT CONF ACOUST SPEE, P4213, DOI 10.1109/ICASSP.2012.6288848; Riley Michael, 2009, P HUM LANG TECHN 200, P9; SAK H, 2010, P INTERSPEECH, P2450; Schalkwyk J., 2010, GOOGLE SEARCH VOICE; You K, 2009, IEEE SIGNAL PROC MAG, V26, P124, DOI 10.1109/MSP.2009.934124	26	0	0	0	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	1520-6149		978-1-4799-2893-4	INT CONF ACOUST SPEE			2014														5	Acoustics; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Acoustics; Engineering	BB5BJ					2024-07-03	WOS:000343655303066
J	Fischer, SWS; de Boer, B				Fischer, Simon W. S.; de Boer, Bas			Negotiating becoming: a Nietzschean critique of large language models	ETHICS AND INFORMATION TECHNOLOGY			English	Article						Large language models; Nietzsche; Self-formation; Negotiation		Large language models (LLMs) structure the linguistic landscape by reflecting certain beliefs and assumptions. In this paper, we address the risk of people unthinkingly adopting and being determined by the values or worldviews embedded in LLMs. We provide a Nietzschean critique of LLMs and, based on the concept of will to power, consider LLMs as will-to-power organisations. This allows us to conceptualise the interaction between self and LLMs as power struggles, which we understand as negotiation. Currently, the invisibility and incomprehensibility of LLMs make it difficult, if not impossible, to engage in such negotiations. This bears the danger that LLMs make reality increasingly homogeneous by recycling beliefs and creating feedback loops that ultimately freeze power struggles and thus consolidate the status quo. In view of this, LLMs constrain self-formation. Based on our critique, we provide some recommendations on how to develop interactions with LLMs that enable negotiations that allow for different ways of being	[Fischer, Simon W. S.] Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept AI, Nijmegen, Netherlands; [de Boer, Bas] Univ Twente, Dept Philosophy, Enschede, Netherlands	Radboud University Nijmegen; University of Twente	Fischer, SWS (corresponding author), Radboud Univ Nijmegen, Donders Inst Brain Cognit & Behav, Dept AI, Nijmegen, Netherlands.	simon.fischer@donders.ru.nl						Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Alfano M, 2015, J NIETZSCHE STUD, V46, P261, DOI 10.5325/jnietstud.46.2.0261; [Anonymous], 1943, Philosophy of Science, DOI [10.2307/184878, DOI 10.1086/286788]; Aydin C, 2021, ROUT STUD CONTEMP PH, P1, DOI 10.4324/9781003139409; Aydin C, 2017, J MED PHILOS, V42, P304, DOI 10.1093/jmp/jhx002; Aydin Ciano., 2007, The Journal of Nietzsche Studies, V33, P25; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Bender EM., 2020, ASS COMPUTATIONAL LI, DOI [10.18653/v1/2020.acl-main.463, DOI 10.18653/V1/2020.ACL-MAIN.463, DOI 10.18653/V1/2020.ACL-MAIN.463.URL]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benjamin R., 2019, RACE TECHNOLOGY ABOL; Bianchi F, 2023, Arxiv, DOI arXiv:2211.03759; Birhane A, 2022, ACM CONFERENCE ON EQUITY AND ACCESS IN ALGORITHMS, MECHANISMS, AND OPTIMIZATION, EAAMO 2022, DOI 10.1145/3551624.3555290; Birhane A, 2022, Arxiv, DOI arXiv:2106.15590; Birhane A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100205; Bisk Y, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P8718; Boon M, 2020, EUR J PHILOS SCI, V10, DOI 10.1007/s13194-020-00295-9; Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878; Brandstetter J, 2017, ADAPT BEHAV, V25, P275, DOI 10.1177/1059712317731606; Bucinca Zana, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449287; Cave Stephen, 2020, Philosophy & Technology, V33, P685, DOI [10.1007/s13347-020-00415-6, DOI 10.1007/S13347-020-00415-6]; Coeckelbergh M, 2018, SCI ENG ETHICS, V24, P1503, DOI 10.1007/s11948-017-9953-8; Crawford Kate, 2019, Excavating AI: The politics of training sets for machine learning; Dale R, 2021, NAT LANG ENG, V27, P113, DOI 10.1017/S1351324920000601; DE JAEGHER H., 2007, Phenomenology and the Cognitive Sciences, V6, P485, DOI DOI 10.1007/S11097-007-9076-9; Raji ID, 2020, Arxiv, DOI [arXiv:2001.00973, 10.48550/arXiv.2001.00973, DOI 10.48550/ARXIV.2001.00973]; Denton E, 2021, BIG DATA SOC, V8, DOI 10.1177/20539517211035955; Escobar A, 2017, New Ecol Twenty Firs, P202; Eubanks Virginia, 2018, AUTOMATING INEQUALIT; FORSYTHE DE, 1993, SOC STUD SCI, V23, P445, DOI 10.1177/0306312793023003002; Franklin U., 1990, REAL WORLD TECHNOLOG; Fromm E., 2006, Escape from freedom Die furcht vor der freiheit, V13th; Gebru T, 2021, Arxiv, DOI arXiv:1803.09010; Gurley L. K., 2021, Amazon's ai cameras are punishing drivers for mistakes they didn't make; Gururangan S., 2022, arXiv; Haselager P, 2023, CAMB Q HEALTHC ETHIC, DOI 10.1017/S0963180122000718; Haste H, 2004, POLIT PSYCHOL, V25, P413, DOI 10.1111/j.1467-9221.2004.00378.x; Hitlin P., 2019, Facebook algorithms and personal data; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Jakesch M, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581196; Jo ES, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P306, DOI 10.1145/3351095.3372829; Kotek H., 2023, Chatgpt doubles down on gender stereotypes even when they don't make sense in context; Krügel S, 2023, Arxiv, DOI arXiv:2301.07098; Kyselo M, 2014, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.00986; Lazaridou A., 2021, arXiv; Luccioni A, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P182; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Manders-Huits N, 2011, SCI ENG ETHICS, V17, P271, DOI 10.1007/s11948-010-9198-2; Mansoury M, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2145, DOI 10.1145/3340531.3412152; Metzler Donald, 2021, ACM SIGIR Forum, V55, P1, DOI 10.1145/3476415.3476428; Miceli Milagros, 2020, Proceedings of the ACM on Human-Computer Interaction, V4, DOI 10.1145/3415186; Mitchell M., 2020, Artificial intelligence: A guide for thinking humans; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Mohler G, 2018, IEEE SYS MAN CYBERN, P2454, DOI 10.1109/SMC.2018.00421; Mooney A., 2015, Language, society and power: An introduction, V4th, DOI [10.4324/9781315733524, DOI 10.4324/9781315733524]; Nietzsche F., 2006, Thus spoke zarathustra, DOI [10.1017/CBO9780511812095, DOI 10.1017/CBO9780511812095]; Nietzsche Friedrich., 1997, "Daybreak": Thoughts on the Prejudices of Morality; Nietzsche Friedrich, 1974, The gay science: With a prelude in rhymes and an appendix of songs; Nietzsche FriedrichWilhelm., 1966, Beyond Good and Evil: Prelude to a Philosophy of the Future; ONeil C., 2016, Weapons of math destruction: how big data increases inequality and threatens democracy; OpenAI, 2023, GPT-4 Technical Report; Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209; Perrigo B, 2023, TIME; Plasek A, 2016, IEEE ANN HIST COMPUT, V38, P6, DOI 10.1109/MAHC.2016.43; Powers E, 2017, DIGIT JOURNAL, V5, P1315, DOI 10.1080/21670811.2017.1286943; Raji I. D., 2021, 35 C NEUR INF PROC S; Richardson J., 1996, Nietzsche's System, V1st, DOI [10.1093/0195098463.001.0001, DOI 10.1093/0195098463.001.0001]; Rousseau A.-L., 2020, Nabla; Rudin C, 2019, Arxiv, DOI [arXiv:1811.10154, 10.1038/s42256-019-0048-x, DOI 10.1038/S42256-019-0048-X, DOI 10.48550/ARXIV.1811.10154]; Sloane M, 2020, Arxiv, DOI [arXiv:2007.02423, 10.48550/ARXIV.2007.02423, DOI 10.48550/ARXIV.2007.02423]; Speer R., 2017, July 13 How to make a racist ai without really trying; Stilgoe Jack, 2023, Science, V381, peadk0176, DOI 10.1126/science.adk0176; Sullivan E, 2022, BRIT J PHILOS SCI, V73, P109, DOI 10.1093/bjps/axz035; Verbeek P.-P., 2004, What things do: Philosophical reflections on technology, agency, and design; Webster R., 2021, arXiv; Weidinger L, 2021, Arxiv, DOI [arXiv:2112.04359, DOI 10.48550/ARXIV.2112.04359]; Weston SJ, 2020, COLLABRA-PSYCHOL, V6, DOI 10.1525/collabra.267; Willis A. M., 2006, Design Philosophy Papers, V4, P69, DOI [DOI 10.2752/144871306X13966268131514, 10.2752/144871306X13966268131514]; Winograd Terry., 1990, FDN ARTIFICIAL INTEL, P167, DOI DOI 10.1017/CBO9780511663116.017	79	0	0	0	0	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	1388-1957	1572-8439		ETHICS INF TECHNOL	Ethics Inf. Technol.	SEP	2024	26	3							42	10.1007/s10676-024-09783-5	http://dx.doi.org/10.1007/s10676-024-09783-5			12	Ethics; Information Science & Library Science; Philosophy	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Social Sciences - Other Topics; Information Science & Library Science; Philosophy	UT4F3		hybrid			2024-07-03	WOS:001250289200001
J	Trott, S; Jones, C; Chang, T; Michaelov, J; Bergen, B				Trott, Sean; Jones, Cameron; Chang, Tyler; Michaelov, James; Bergen, Benjamin			Do Large Language Models Know What Humans Know?	COGNITIVE SCIENCE			English	Article						Large language models; Language; False Belief Task; Belief attribution	MENTAL STATES; MIND; CHIMPANZEES; ATTRIBUTION; CHILDREN	Humans can attribute beliefs to others. However, it is unknown to what extent this ability results from an innate biological endowment or from experience accrued through child development, particularly exposure to language describing others' mental states. We test the viability of the language exposure hypothesis by assessing whether models exposed to large quantities of human language display sensitivity to the implied knowledge states of characters in written passages. In pre-registered analyses, we present a linguistic version of the False Belief Task to both human participants and a large language model, GPT-3. Both are sensitive to others' beliefs, but while the language model significantly exceeds chance behavior, it does not perform as well as the humans nor does it explain the full extent of their behavior-despite being exposed to more language than a human would in a lifetime. This suggests that while statistical learning from language exposure may in part explain how humans develop the ability to reason about the mental states of others, other mechanisms are also responsible.	[Trott, Sean; Jones, Cameron; Chang, Tyler; Michaelov, James; Bergen, Benjamin] Univ Calif San Diego, Dept Cognit Sci, La Jolla, CA USA; [Jones, Cameron] Univ Calif San Diego, Dept Cognit Sci, 9500 Gilman Dr, La Jolla, CA 92093 USA	University of California System; University of California San Diego; University of California System; University of California San Diego	Jones, C (corresponding author), Univ Calif San Diego, Dept Cognit Sci, 9500 Gilman Dr, La Jolla, CA 92093 USA.	cameron@ucsd.edu	Jones, Cameron/JFA-2531-2023	Jones, Cameron/0000-0002-6609-8966; Michaelov, James/0000-0003-2913-1103				Abdou M., 2021, P 25 C COMPUTATIONAL, P109, DOI [10.18653/v1/2021.conll-1.9, DOI 10.18653/V1/2021.CONLL-1.9]; Abell F, 2000, COGNITIVE DEV, V15, P1, DOI 10.1016/S0885-2014(00)00014-9; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Antonello R., 2022, PREDICTIVE CODING JU, DOI [10.1162/nol_a_00087, DOI 10.1162/NOL_A_00087]; Apperly IA, 2012, Q J EXP PSYCHOL, V65, P825, DOI 10.1080/17470218.2012.676055; Aslin RN, 2017, WIRES COGN SCI, V8, DOI 10.1002/wcs.1373; Baillargeon R, 2010, TRENDS COGN SCI, V14, P110, DOI 10.1016/j.tics.2009.12.006; Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715; Bedny M, 2009, P NATL ACAD SCI USA, V106, P11312, DOI 10.1073/pnas.0900010106; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bennett C., 2009, Neuroimage, V47, pS125, DOI [10.1016/S1053-8119(09)71202-9, DOI 10.1016/S1053-8119(09)71202-9]; Bergen B., 2021, arXiv, DOI 10.48550/arXiv.2105.13266; BLOCK N, 1981, PHILOS REV, V90, P5, DOI 10.2307/2184371; Block N., 1980, TROUBLES FUNCTIONALI; Bloom P, 2000, COGNITION, V77, pB25, DOI 10.1016/S0010-0277(00)00096-2; Bradford EEF, 2020, CORTEX, V126, P265, DOI 10.1016/j.cortex.2020.01.016; Brown JR, 1996, CHILD DEV, V67, P836, DOI 10.2307/1131864; Brown Tom, 2020, NIPS, V33, P1877; de Villiers JG, 2014, TOP LANG DISORD, V34, P313, DOI 10.1097/TLD.0000000000000037; Dennett D., 1987, INTENTIONAL STANCE; DENNETT DC, 1978, BEHAV BRAIN SCI, V1, P568, DOI 10.1017/S0140525X00076664; Dodell-Feder D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0081279; Drachman DA, 2005, NEUROLOGY, V64, P2004, DOI 10.1212/01.WNL.0000166914.38327.BB; Fairchild S, 2021, COGNITIVE SCI, V45, DOI 10.1111/cogs.12938; Futrell R, 2018, Arxiv, DOI arXiv:1809.01329; Gernsbacher Morton Ann, 2019, Arch Sci Psychol, V7, P102, DOI 10.1037/arc0000067; Giordano M, 2019, COGENT PSYCHOL, V6, DOI 10.1080/23311908.2019.1634326; Gough J, 2023, J AUTISM DEV DISORD, V53, P853, DOI 10.1007/s10803-021-05381-2; Hale CM, 2003, DEVELOPMENTAL SCI, V6, P346, DOI 10.1111/1467-7687.00289; Halina M, 2015, PHILOS SCI, V82, P473, DOI 10.1086/681627; HAPPE FGE, 1994, J AUTISM DEV DISORD, V24, P129, DOI 10.1007/BF02172093; Hare B, 2000, ANIM BEHAV, V59, P771, DOI 10.1006/anbe.1999.1377; Harris P., 2005, Why Language Matters for Theory of Mind, Apr, 2002, University of Toronto, Toronto, ON, Canada, DOI DOI 10.1093/ACPROF:OSO/9780195159912.003.0004; HART B, 1992, DEV PSYCHOL, V28, P1096, DOI 10.1037/0012-1649.28.6.1096; Hayward EO, 2017, BRIT J DEV PSYCHOL, V35, P454, DOI 10.1111/bjdp.12186; Heilbron M, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2201968119; Heyes C, 2014, PERSPECT PSYCHOL SCI, V9, P131, DOI 10.1177/1745691613518076; Hosseini E., 2022, bioRxiv; Hughes C, 2005, CHILD DEV, V76, P356, DOI 10.1111/j.1467-8624.2005.00850_a.x; Johnson S., 2022, The New York Times Magazine; Jones C. R., 2022, P ANN M COGNITIVE SC, V44, P482; Jurafsky D., 2014, Speech and Language Processing, V2nd; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Krupenye C, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1503; Krupenye C, 2016, SCIENCE, V354, P110, DOI 10.1126/science.aaf8110; Leslie A. M., 2001, International Encyclopedia of the Social Behavioral Sciences, P15652, DOI [DOI 10.1016/B0-08-043076-7/01640-5, 10.1016/b0-08-043076-7/01640-5, DOI 10.1016/B0]; Li BZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1813; Linzen T, 2021, ANNU REV LINGUIST, V7, P195, DOI 10.1146/annurev-linguistics-032020-051035; Lurz R, 2009, PHILOS PSYCHOL, V22, P305, DOI 10.1080/09515080902970673; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Maul A, 2017, MEAS-INTERDISCIP RES, V15, P51, DOI 10.1080/15366367.2017.1348108; Michaelov JA, 2023, IEEE T COGN DEV SYST, V15, P1033, DOI 10.1109/TCDS.2022.3176783; Niven T, 2019, Arxiv, DOI arXiv:1907.07355; OpenAI, 2023, OPENAI MOD DOC; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Penn DC, 2008, BEHAV BRAIN SCI, V31, P109, DOI 10.1017/S0140525X08003543; Penn DC, 2007, PHILOS T R SOC B, V362, P731, DOI 10.1098/rstb.2006.2023; Pluta A, 2021, J DEAF STUD DEAF EDU, V26, P511, DOI 10.1093/deafed/enab015; Povinelli DJ, 2004, MIND LANG, V19, P1, DOI 10.1111/j.1468-0017.2004.00244.x; POVINELLI DJ, 2020, ANIM BEHAV COGNITION, V7, P589, DOI DOI 10.26451/ABC.07.04.09.2020; PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512; Raji Inioluwa Deborah, 2021, arXiv; Sap M, 2023, Arxiv, DOI arXiv:2210.13312; Schneider D, 2014, NEUROIMAGE, V101, P268, DOI 10.1016/j.neuroimage.2014.07.014; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Schwitzgebel Eric., 2013, NEW ESSAYS ON BELIEF, DOI DOI 10.1057/9781137026521_5; SEARLE JR, 1980, BEHAV BRAIN SCI, V3, P417, DOI 10.1017/S0140525X00006038; Shevlin H., 2022, UNCANNY BELIEV UNPUB; Sinclair A, 2022, T ASSOC COMPUT LING, V10, P1031, DOI 10.1162/tacl_a_00504; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Vaswani A, 2017, ADV NEUR IN, V30; Warstadt A., 2022, Algebraic Structures in Natural Language, P17; Webb MA, 2022, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916221120027; WIMMER H, 1983, COGNITION, V13, P103, DOI 10.1016/0010-0277(83)90004-5; Xie JS, 2018, COGNITIVE SCI, V42, P1179, DOI 10.1111/cogs.12594	76	15	16	36	79	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	JUL	2023	47	7							e13309	10.1111/cogs.13309	http://dx.doi.org/10.1111/cogs.13309			21	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	L2MF7	37401923	hybrid, Green Submitted			2024-07-03	WOS:001021644700001
J	Alkaoud, M				Alkaoud, Mohamed			A bilingual benchmark for evaluating large language models	PEERJ COMPUTER SCIENCE			English	Article						Natural language processing; Large language models; Multilingual NLP; LLM evaluation; Arabic NLP; ChatGPT		This work introduces a new benchmark for the bilingual evaluation of large language models (LLMs) in English and Arabic. While LLMs have transformed various fields, their evaluation in Arabic remains limited. This work addresses this gap by proposing a novel evaluation method for LLMs in both Arabic and English, allowing for a direct comparison between the performance of the two languages. We build a new evaluation dataset based on the General Aptitude Test (GAT), a standardized test widely used for university admissions in the Arab world, that we utilize to measure the linguistic capabilities of LLMs. We conduct several experiments to examine the linguistic capabilities of ChatGPT and quantify how much better it is at English than Arabic. We also examine the effect of changing task descriptions from Arabic to English and vice-versa. In addition to that, we find that fastText can surpass ChatGPT in finding Arabic word analogies. We conclude by showing that GPT-4 Arabic linguistic capabilities are much better than ChatGPT's Arabic capabilities and are close to ChatGPT's English capabilities.	[Alkaoud, Mohamed] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia	King Saud University	Alkaoud, M (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Sci, Riyadh, Saudi Arabia.	malkaoud@ksu.edu.sa						Abdelali A., 2023, arXiv; Abdul-Mageed M., 2021, P 59 ANN M ASS COMPU, P7088, DOI 10.18653/v1/2021.acl-long.551; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; Antoun W., 2021, P 6 AR NAT LANG PROC, P191; Antoun W, P 6 ARABIC NATURAL L, P196; Antoun W., 2020, P 4 WORKSH OP SOURC, P9; Arora S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2650; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacla00051]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Clark K, 2020, INFORM SYST RES, DOI 10.48550/arXiv.2003.10555; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; de Vries W, 2019, Arxiv, DOI arXiv:1912.09582; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dua D, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2368; Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483; Gudibande A, 2023, Arxiv, DOI arXiv:2305.15717; Hendrycks D., 2021, INT C LEARNING REPRE; Inoue Go, 2021, P 6 ARABIC NATURAL L; Kamal Eddine M, 2022, P THE 7 ARABIC NATUR, P31; Katz Daniel Martin, 2023, Gpt-4 passes the bar exam, DOI DOI 10.2139/SSRN.4389233; KFUPM, 2023, King Fahd University of petroleum and minerals; Khondaker MTI, 2023, Arxiv, DOI arXiv:2305.14976; Lai VD, 2023, FINDINGS ASS COMPUTA; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Martin L, 2020, P 58 ANN M ASS COMPU; Mikolov T, 2013, COMPUTING RES REPOSI; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mikolov T., 2013, P NAACL 2013, P746, DOI DOI 10.3109/10826089109058901; Nagoudi EB, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P628; National Center for Assessment, 2023, General Aptitude Test; National Center for Assessment, 2023, General Aptitude Test Manual; National Center for Assessment, 2018, GAT English Manual; NCA, 2023, National Center for Assessment; NCA, 2023, General Aptitude Test; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI DOI 10.3115/V1/D14-1162; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Virtanen A., 2019, Multilingual is not enough: BERT for Finnish	45	0	0	8	8	PEERJ INC	LONDON	341-345 OLD ST, THIRD FLR, LONDON, EC1V 9LL, ENGLAND		2376-5992		PEERJ COMPUT SCI	PeerJ Comput. Sci.	FEB 29	2024	10								e1893	10.7717/peerj-cs.1893	http://dx.doi.org/10.7717/peerj-cs.1893			22	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	JR6W8	38435597	Green Published, gold			2024-07-03	WOS:001174942400004
J	Blank, IA				Blank, Idan A.			What are large language models supposed to model?	TRENDS IN COGNITIVE SCIENCES			English	Editorial Material								Do large language models (LLMs) constitute a computational ac-count of how humans process lan-guage? And if so, what is the role of (psycho)linguistic theory in understanding the relationship be-tween artificial and biological minds? The answer depends on choosing among several, funda-mentally distinct ways of interpret-ing these models as hypotheses about humans.	[Blank, Idan A.] Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA; [Blank, Idan A.] Univ Calif Los Angeles, Dept Linguist, Los Angeles, CA 90095 USA	University of California System; University of California Los Angeles; University of California System; University of California Los Angeles	Blank, IA (corresponding author), Univ Calif Los Angeles, Dept Psychol, Los Angeles, CA 90095 USA.; Blank, IA (corresponding author), Univ Calif Los Angeles, Dept Linguist, Los Angeles, CA 90095 USA.	iblank@psych.ucla.edu		Blank, Idan/0000-0001-7057-8391				Bechtel W., 1991, CONNECTIONISM MIND I; Cao RS, 2021, Arxiv, DOI [arXiv:2104.01490, DOI 10.48550/ARXIV.2104.01490]; Chaves Rui P., 2021, P SOC COMPUTATION LI, P28; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Manning CD, 2020, P NATL ACAD SCI USA, V117, P30046, DOI 10.1073/pnas.1907367117; Marr D., 1982, VISION, P8; PINKER S, 1988, COGNITION, V28, P73, DOI 10.1016/0010-0277(88)90032-7; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Smolensky P, 2022, AI MAG, V43, P308, DOI 10.1002/aaai.12065; Soulos P, 2020, Arxiv, DOI [arXiv:1910.09113, 10.48550/arXiv.1910.09113]; Wilcox E.G., 2022, Algebraic Structures in Natural Language, P113; Wong L, 2023, Arxiv, DOI [arXiv:2306.12672, 10.48550/arXiv.2306.12672, DOI 10.48550/ARXIV.2306.12672]	12	3	3	13	29	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA	1364-6613	1879-307X		TRENDS COGN SCI	TRENDS COGN. SCI.	NOV	2023	27	11					987	989		10.1016/j.tics.2023.08.006	http://dx.doi.org/10.1016/j.tics.2023.08.006		OCT 2023	3	Behavioral Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Behavioral Sciences; Neurosciences & Neurology; Psychology	Y1PM3	37659920	hybrid			2024-07-03	WOS:001103056000001
J	Long, R				Long, Robert			Introspective Capabilities in Large Language Models	JOURNAL OF CONSCIOUSNESS STUDIES			English	Article								This paper considers the kind of introspection that large language models (LLMs) might be able to have. It argues that LLMs, while currently limited in their introspective capabilities, are not inherently unable to have such capabilities: they already model the world, including mental concepts, and already have some intro-spection-like capabilities. With deliberate training, LLMs may develop introspective capabilities. The paper proposes a method for such training for introspection, situates possible LLM introspection in the 'possible forms of introspection' framework proposed by Kammerer and Frankish, and considers the ethical ramifications of introspection and self-report in AI systems.	[Long, Robert] Ctr AI Safety, San Francisco, CA 94105 USA		Long, R (corresponding author), Ctr AI Safety, San Francisco, CA 94105 USA.	rgblong@gmail.com						Abdou M., 2021, P 25 C COMPUTATIONAL, P109, DOI [10.18653/v1/2021.conll-1.9, DOI 10.18653/V1/2021.CONLL-1.9]; Bai Y., 2022, Training a helpful and harmless assistant with reinforcement learning from human feedback; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Birch J, 2022, NOUS, V56, P133, DOI 10.1111/nous.12351; Bourget David., 2021, Philosophers on philosophy: The 2020 philpapers survey; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Chalmers DJ, 2023, Arxiv, DOI [arXiv:2303.07103, DOI 10.48550/ARXIV.2303.07103, 10.48550/arXiv.2303.07103]; Christiano PF, 2017, ADV NEUR IN, V30; DENNETT DC, 1994, PHILOS T R SOC A, V349, P133, DOI 10.1098/rsta.1994.0118; Evans O., 2021, arXiv; Francken JC, 2022, NEUROSCI CONSCIOUS, V2022, DOI 10.1093/nc/niac011; Godfrey-Smith P., 2020, METAZOA ANIMAL LIFE; Jung JH, 2022, Arxiv, DOI arXiv:2205.11822; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lake BM, 2023, PSYCHOL REV, V130, P401, DOI 10.1037/rev0000297; Lemoine Blake, 2022, MEDIUM; Li KN, 2023, Arxiv, DOI [arXiv:2210.13382, DOI 10.48550/ARXIV.2210.13382]; Lin SPN, 2022, Arxiv, DOI [arXiv:2205.14334, 10.48550/ARXIV.2205.14334]; Marcus G., 2020, Technology Review; Meng Kevin, 2022, Advances in Neural Information Processing Systems, P17359; Patel Roma, 2022, ICLR VIRTUAL    0425, P1; Perez E., Evaluating AI systems using self-reports; Shulman C., 2021, Rethinking moral status, P306, DOI DOI 10.1093/OSO/9780192894076.003.0018; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Stuskever I., 2022, Twitter9 February; Turner E., 2018, CEUR Workshop Proceedings, V2287; Udell DB, 2021, J CONSCIOUSNESS STUD, V28, P121; von Hagen M., 2023, Microsoft/GitHub Copilot Chat's confidential system prompt: 'You must refuse to discuss life, existence or sentience'; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Koh PW, 2020, Arxiv, DOI arXiv:1703.04730	31	1	1	7	10	IMPRINT ACADEMIC	EXETER	PO BOX 200, EXETER EX5 5YX, DEVON, ENGLAND	1355-8250			J CONSCIOUSNESS STUD	J. Conscious. Stud.		2023	30	9-10					143	153		10.53765/20512201.30.9.143	http://dx.doi.org/10.53765/20512201.30.9.143			11	Philosophy; Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI); Arts &amp; Humanities Citation Index (A&amp;HCI)	Philosophy; Social Sciences - Other Topics	U4GR9					2024-07-03	WOS:001084404000010
C	Treude, C; Hata, H			IEEE	Treude, Christoph; Hata, Hideaki			She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models	2023 IEEE/ACM 20TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES, MSR	IEEE International Working Conference on Mining Software Repositories		English	Proceedings Paper	IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)	MAY 15-16, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, GitHub, Huawei Canada				Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun "he" in only 6% of cases, while testing was associated with "he" in 100% of cases. Additionally, tasks related to helping others had a 91% association with "he" while the same association for tasks related to asking coworkers was only 52%. These findings reveal a clear pattern of gender bias related to software development tasks and have important implications for addressing this issue both in the training of large language models and in broader society.	[Treude, Christoph] Univ Melbourne, Parkville, Vic, Australia; [Hata, Hideaki] Shinshu Univ, Matsumoto, Japan	University of Melbourne; Shinshu University	Treude, C (corresponding author), Univ Melbourne, Parkville, Vic, Australia.	christoph.treude@unimelb.edu.au; hata@shinshu-u.ac.jp	Hata, Hideaki/N-7103-2019; Treude, Christoph/AAZ-6257-2021	Hata, Hideaki/0000-0003-0708-5222; Treude, Christoph/0000-0002-6919-2149				Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7; Brough S, 2011, Arxiv, DOI arXiv:1106.6094; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Fishman P. M, 1997, INTERACTION WORK WOM; Ford D, 2015, 2015 IEEE/ACM 8TH INTERNATIONAL WORKSHOP ON COOPERATIVE AND HUMAN ASPECTS OF SOFTWARE ENGINEERING CHASE 2015, P115, DOI 10.1109/CHASE.2015.19; Garcia R, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P432, DOI 10.1145/3478431.3499279; GLASS RL, 1992, INFORM MANAGE, V23, P183, DOI 10.1016/0378-7206(92)90043-F; Graziotin Daniel, 2017, PROC OFTHE 21 INT C, P324, DOI DOI 10.1145/3084226.3084242; Huang PS, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P65; Imtiaz N, 2019, PROC INT CONF SOFTW, P700, DOI 10.1109/ICSE.2019.00079; Kuechler Victor, 2012, OPEN SOURCE SYSTEMS, V378, P78; Liang PP, 2021, INT C MACHINE LEARNI, P6565; Licorish SA, 2017, INFORM MANAGE-AMSTER, V54, P364, DOI 10.1016/j.im.2016.09.005; Liu RB, 2021, AAAI CONF ARTIF INTE, V35, P14857; Madampe K, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: NEW IDEAS AND EMERGING RESULTS (ICSE-NIER 2020), P37, DOI 10.1145/3377816.3381722; Masood Z., 2022, Information and Software Technology; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Meyer AN, 2021, IEEE T SOFTWARE ENG, V47, P863, DOI 10.1109/TSE.2019.2904957; Milewski AE, 2007, EMPIR SOFTW ENG, V12, P311, DOI 10.1007/s10664-007-9036-6; Murgia A., 2014, Proceedings of the 11th working conference on mining software repositories, Ved, P262; Padala HS, 2022, IEEE T SOFTWARE ENG, V48, P241, DOI 10.1109/TSE.2020.2984173; Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866; Prana GAA, 2022, IEEE T SOFTWARE ENG, V48, P3394, DOI 10.1109/TSE.2021.3092813; Renström EA, 2023, J LANG SOC PSYCHOL, V42, P476, DOI 10.1177/0261927X221146229; Robillard MP, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1292, DOI 10.1145/3468264.3473923; Rossi D, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN SOCIETY (ICSE-SEIS 2022), P172, DOI [10.1145/3510458.3513011, 10.1109/ICSE-SEIS55304.2022.9794118]; Terrell J, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.111; Vasilescu B, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3789, DOI 10.1145/2702123.2702549; Vasilescu B, 2012, PROCEEDINGS OF THE 2012 ASE INTERNATIONAL CONFERENCE ON SOCIAL INFORMATICS (SOCIALINFORMATICS 2012), P332, DOI 10.1109/SocialInformatics.2012.81; Wang Y, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN SOCIETY (ICSE-SEIS 2019), P1, DOI 10.1109/ICSE-SEIS.2019.00009	30	0	0	5	9	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2160-1852		979-8-3503-1184-6	IEEE WORK CONF MIN S			2023							624	629		10.1109/MSR59073.2023.00088	http://dx.doi.org/10.1109/MSR59073.2023.00088			6	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JN		Green Submitted			2024-07-03	WOS:001032697200072
J	Kim, S; Lee, CK; Kim, SS				Kim, Sunkyu; Lee, Choong-kun; Kim, Seung-seob			Large Language Models: A Guide for Radiologists	KOREAN JOURNAL OF RADIOLOGY			English	Article						Natural language processing; Large language model; Transformer; Radiology; Chatbot; ChatGPT		Large language models (LLMs) have revolutionized the global landscape of technology beyond natural language processing. Owing to their extensive pre-training on vast datasets, contemporary LLMs can handle tasks ranging from general functionalities to domain-specific areas, such as radiology, without additional fine-tuning. General-purpose chatbots based on LLMs can optimize the efficiency of radiologists in terms of their professional work and research endeavors. Importantly, these LLMs are on a trajectory of rapid evolution, wherein challenges such as "hallucination," high training cost, and efficiency issues are addressed, along with the inclusion of multimodal inputs. In this review, we aim to offer conceptual knowledge and actionable guidance to radiologists interested in utilizing LLMs through a succinct overview of the topic and a summary of radiology-specific aspects, from the beginning to potential future directions.	[Kim, Sunkyu] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea; [Kim, Sunkyu] AIGEN Sci, Seoul, South Korea; [Lee, Choong-kun] Yonsei Univ, Dept Internal Med, Div Med Oncol, Coll Med, Seoul, South Korea; [Kim, Seung-seob] Yonsei Univ Coll Med, Severance Hosp, Res Inst Radiol Sci, Dept Radiol, Seoul, South Korea; [Kim, Seung-seob] Yonsei Univ, Severance Hosp, Dept Radiol, Coll Med, 50-1 Yonsei Ro, Seoul 03722, South Korea; [Kim, Seung-seob] Yonsei Univ, Severance Hosp, Res Inst Radiol Sci, Coll Med, 50-1 Yonsei Ro, Seoul 03722, South Korea	Korea University; Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System; Yonsei University; Yonsei University Health System	Kim, SS (corresponding author), Yonsei Univ, Severance Hosp, Dept Radiol, Coll Med, 50-1 Yonsei Ro, Seoul 03722, South Korea.; Kim, SS (corresponding author), Yonsei Univ, Severance Hosp, Res Inst Radiol Sci, Coll Med, 50-1 Yonsei Ro, Seoul 03722, South Korea.	k2s0127@yuhs.ac		Lee, Choong-kun/0000-0001-5151-5096; Kim, Seung-seob/0000-0001-6071-306X; Kim, Sunkyu/0000-0002-0240-6210				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; [Anonymous], Sequence to Sequence Learning with Neural Networks; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Brown T., 2020, NIPS, P1877; Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.48550/ARXIV.1406.1078]; Delbrouck JB., Overview of the RadSum23 shared task on multi-modal and multianatomical radiology report summarization; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doshi R, 2023, medRxiv, DOI [10.1101/2023.06.04.23290786, 10.1101/2023.06.04.23290786, DOI 10.1101/2023.06.04.23290786]; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Elkhatat AM, 2023, INT J EDUC INTEGR, V19, DOI 10.1007/s40979-023-00137-0; Fei NY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30761-2; Fink MA, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231362; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Haver HL, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230424; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; Jung KH, 2023, KOREAN J RADIOL, V24, P1038, DOI 10.3348/kjr.2023.0790; Koga S, 2023, KOREAN J RADIOL, V24, P924, DOI 10.3348/kjr.2023.0738; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Le QuocV., Distributed representations of sentences and documents; Lewis P., Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks; Li H, Uni-perceiver v2: a generalist model for large-scale vision and visionlanguage tasks; Liu ZL, 2024, Arxiv, DOI [arXiv:2306.08666, DOI 10.48550/ARXIV.2306.08666, 10.48550/arXiv.2306.08666]; Lyu Q, 2023, Arxiv, DOI arXiv:2303.09038; Medenilla A., 2023, PLoS Digital Health, V2; Mukherjee P, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.231147; OpenAI, ChatGPT can now see, hear, and speak; Park SH, 2023, KOREAN J RADIOL, V24, P715, DOI 10.3348/kjr.2023.0643; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Rau A, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.230970; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Ueda D, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231040; Vaswani A, 2017, ADV NEUR IN, V30; Wang GY, 2023, Arxiv, DOI [arXiv:2306.09968, 10.48550/arXiv.2306.09968]; Wu CY, 2023, Arxiv, DOI [arXiv:2308.02463, DOI 10.48550/ARXIV.2308.02463]; Wu ZH, 2023, Arxiv, DOI arXiv:2304.09138; Zhang K, 2024, Arxiv, DOI [arXiv:2305.17100, DOI 10.48550/ARXIV.2305.17100]	46	3	3	13	13	KOREAN SOCIETY OF RADIOLOGY	SEOUL	71, YANGJAECHEON-RO, SEOCHO-GU, SEOUL, SOUTH KOREA	1229-6929	2005-8330		KOREAN J RADIOL	Korean J. Radiol.	FEB	2024	25	2					126	133		10.3348/kjr.2023.0997	http://dx.doi.org/10.3348/kjr.2023.0997			8	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	KI3K6	38288895	Green Published			2024-07-03	WOS:001179289700004
C	Vaithilingam, P; Zhang, TY; Glassman, EL			ACM	Vaithilingam, Priyan; Zhang, Tianyi; Glassman, Elena L.			Expectation vs. Experience: Evaluating the Usability of Code Generation Tools Powered by Large Language Models	EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022			English	Proceedings Paper	CHI Conference on Human Factors in Computing Systems (CHI)	APR 30-MAY 05, 2022	New Orleans, LA	Assoc Comp Machinery, ACM SIGCHI, Google, Bloomberg, Meta, Microsoft, NSF, Yahoo		large language model; github copilot		Recent advances in Large Language Models (LLM) have made automatic code generation possible for real-world programming tasks in general-purpose programming languages such as Python. However, there are few human studies on the usability of these tools and how they fit the programming workflow. In this work, we conducted a within-subjects user study with 24 participants to understand how programmers use and perceive Copilot, a LLM-based code generation tool. We found that, while Copilot did not necessarily improve the task completion time or success rate, most participants preferred to use Copilot in daily programming tasks, since Copilot often provided a useful starting point and saved the effort of searching online. However, participants did face difficulties in understanding, editing, and debugging code snippets generated by Copilot, which significantly hindered their task-solving effectiveness. Finally, we highlighted several promising directions for improving the design of Copilot based on our observations and participants' feedback.	[Vaithilingam, Priyan; Glassman, Elena L.] Harvard Univ, Cambridge, MA 02138 USA; [Zhang, Tianyi] Purdue Univ, W Lafayette, IN 47907 USA	Harvard University; Purdue University System; Purdue University	Vaithilingam, P (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.	pvaithilingam@g.harvard.edu; tianyi@purdue.edu; glassman@seas.harvard.edu	xiao, wei/KCK-6954-2024		NSF [IIS-2107391, CCF-2123965]	NSF(National Science Foundation (NSF))	This material is based upon work supported by the NSF under Grant No. IIS-2107391 and Grant No. CCF-2123965.	Alon U, 2020, PR MACH LEARN RES, V119; Alur R, 2015, NATO SCI PEAC SECUR, V40, P1, DOI 10.3233/978-1-61499-495-4-1; Antifakos Stavros, 2005, P 7 INT C HUMAN COMP, P9, DOI [10.1145/1085777.1085780, DOI 10.1145/1085777.1085780]; Hayati SA, 2018, Arxiv, DOI arXiv:1808.10025; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Balog M, 2017, Arxiv, DOI arXiv:1611.01989; Black Sid, 2021, GPTNeo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow, DOI DOI 10.5281/ZENODO.5297715IFYOUUSETHISSOFTWARE; Chasins SE, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P963, DOI 10.1145/3242587.3242661; Chen M., 2021, arXiv; Ciniselli M, 2021, Arxiv, DOI arXiv:2103.07115; Cypher Allen, 1995, Readings in human-computer interaction, P804; Dzindolet MT, 2003, INT J HUM-COMPUT ST, V58, P697, DOI 10.1016/S1071-5819(03)00038-7; Xu FF, 2020, Arxiv, DOI [arXiv:2004.09015, 10.48550/ARXIV.2004.09015]; Feser JK, 2015, ACM SIGPLAN NOTICES, V50, P229, DOI [10.1145/2813885.2737977, 10.1145/2737924.2737977]; Github Copilot, Your AI pair programmer; Gulwani S, 2015, COMMUN ACM, V58, P90, DOI 10.1145/2736282; Gulwani S, 2011, ACM SIGPLAN NOTICES, V46, P317, DOI 10.1145/1925844.1926423; Guo T, 2020, Arxiv, DOI arXiv:1910.07179; Husain H, 2020, Arxiv, DOI arXiv:1909.09436; Jha S., 2010, P 32 ACM IEEE INT C, V1, P215, DOI DOI 10.1145/1806799.1806833; Karampatsis RM, 2019, Arxiv, DOI arXiv:1903.05734; Kim S, 2021, PROC INT CONF SOFTW, P150, DOI 10.1109/ICSE43902.2021.00026; Kite-Free AI Coding Assistant and Code Auto-Complete Plugin, 2020, Kite-Free AI Coding Assistant and Code Auto-Complete Plugin; Kocielnik R, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300641; Lau T, 2003, MACH LEARN, V53, P111, DOI 10.1023/A:1025671410623; Le V, 2014, ACM SIGPLAN NOTICES, V49, P542, DOI [10.1145/2594291.2594333, 10.1145/2666356.2594333]; Lim BY, 2010, UBICOMP 2010: PROCEEDINGS OF THE 2010 ACM CONFERENCE ON UBIQUITOUS COMPUTING, P13; Lim BY, 2009, UBICOMP'09: PROCEEDINGS OF THE 11TH ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P195; Lim BY, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P2119; Mastropaolo A, 2021, PROC INT CONF SOFTW, P336, DOI 10.1109/ICSE43902.2021.00041; Myers B. A., 1991, Human Factors in Computing Systems. Reaching Through Technology. CHI '91. Conference Proceedings, P243, DOI 10.1145/108844.108903; MYERS BA, 1990, ACM T PROGR LANG SYS, V12, P143, DOI 10.1145/78942.78943; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Peleg H, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1114, DOI 10.1145/3180155.3180189; Pilipiszyn A., 2021, Gpt-3 powers the next generation of apps; Robinette P, 2016, ACMIEEE INT CONF HUM, P101, DOI 10.1109/HRI.2016.7451740; Solar-Lezama A, 2005, ACM SIGPLAN NOTICES, V40, P281, DOI 10.1145/1064978.1065045; Stumpf S, 2009, INT J HUM-COMPUT ST, V67, P639, DOI 10.1016/j.ijhcs.2009.03.004; Sun ZY, 2020, AAAI CONF ARTIF INTE, V34, P8984; Tabnine, Code Faster with AI Code Completions; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Waldinger R. J., 1969, P 1 INT JOINT C ARTI, P241; Wang Ben, 2021, Mesh-Transformer-JAX: Model-Parallel Implementation of Transformer Language Model with JAX; Wang CL, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3371117; Weisz JD, 2021, IUI '21 - 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P402, DOI 10.1145/3397481.3450656; Weld Daniel S, 2018, arXiv; Xu Frank F., 2021, arXiv, DOI DOI 10.1145/3487569; Yin P., 2017, arXiv; Yin PC, 2018, Arxiv, DOI arXiv:1810.02720; Zaremba W., 2021, Openai codex; Zhang Tianyi, 2020, P 33 ANN ACM S USER, P627, DOI 10.1145/3379337.3415900; Zhang YF, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P295, DOI 10.1145/3351095.3372852	52	55	61	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9156-6				2022										10.1145/3491101.3519665	http://dx.doi.org/10.1145/3491101.3519665			7	Computer Science, Cybernetics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LA					2024-07-03	WOS:001118038100249
J	Li, Z; Li, FH; Fu, QN; Wang, XH; Liu, H; Zhao, Y; Ren, W				Li, Zhui; Li, Fenghe; Fu, Qining; Wang, Xuehu; Liu, Hong; Zhao, Yu; Ren, Wei			Large language models and medical education: a paradigm shift in educator roles	SMART LEARNING ENVIRONMENTS			English	Letter						Educator roles; Medical education; Large language models; Artificial intelligence		This article meticulously examines the transformation of educator roles in medical education against the backdrop of emerging large language models (LLMs). Traditionally, educators have played a crucial role in transmitting knowledge, training skills, and evaluating educational outcomes. However, the advent of LLMs such as Chat Generative Pre-trained Transformer-4 has expanded and enriched these traditional roles by leveraging opportunities to enhance teaching efficiency, foster personalised learning, and optimise resource allocation. This has imbued traditional medical educator roles with new connotations. Concurrently, LLMs present challenges to medical education, such as ensuring the accuracy of information, reducing bias, minimizing student over-reliance, preventing patient privacy exposure and safeguarding data security, enhancing the cultivation of empathy, and maintaining academic integrity. In response, educators are called to adopt new roles including experts of information management, navigators of learning, guardians of academic integrity, and defenders of clinical practice. The article emphasises the enriched connotations and attributes of the medical teacher's role, underscoring their irreplaceable value in the AI-driven evolution of medical education. Educators are portrayed not just as users of advanced technology, but also as custodians of the essence of medical education.	[Li, Zhui; Li, Fenghe; Fu, Qining; Wang, Xuehu; Liu, Hong; Zhao, Yu; Ren, Wei] Chongqing Med Univ, Affiliated Hosp 1, Dept Vasc Surg, 1 Youyi Rd, Chongqing 400016, Peoples R China	Chongqing Medical University	Ren, W (corresponding author), Chongqing Med Univ, Affiliated Hosp 1, Dept Vasc Surg, 1 Youyi Rd, Chongqing 400016, Peoples R China.	renwei_2301@yeah.net			Hospital-Level Teaching Reform Project of the First Affiliated Hospital of Chongqing Medical University [CMER201911]; Program for Youth Innovation in Future Medicine at Chongqing Medical University [0191]	Hospital-Level Teaching Reform Project of the First Affiliated Hospital of Chongqing Medical University; Program for Youth Innovation in Future Medicine at Chongqing Medical University	This study was supported by the Hospital-Level Teaching Reform Project of the First Affiliated Hospital of Chongqing Medical University (Grant No.: CMER201911) and the Program for Youth Innovation in Future Medicine at Chongqing Medical University (No. 0191).	Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Amgad M, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127470; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baid H, 2011, NURS CRIT CARE, V16, P99, DOI 10.1111/j.1478-5153.2010.00396.x; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Bosméan L, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03171-7; Burgess A, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02283-2; Chang OS, 2023, EVAL HEALTH PROF, DOI 10.1177/01632787231165797; Chen WT, 2022, BMC MED EDUC, V22, DOI 10.1186/s12909-022-03349-z; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gan Wensheng, 2023, 2023 IEEE International Conference on Big Data (BigData), P4776, DOI 10.1109/BigData59044.2023.10386291; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Graham Flora, 2022, Nature, DOI 10.1038/d41586-022-04437-2; Guidi C, 2021, MED HEALTH CARE PHIL, V24, P573, DOI 10.1007/s11019-021-10033-4; Haman M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2185514; Hamid H, 2023, CURR PHARM TEACH LEA, V15, P1017, DOI 10.1016/j.cptl.2023.10.001; Han ZY, 2024, MED TEACH, V46, P657, DOI 10.1080/0142159X.2023.2271159; Hatem CJ, 2011, ACAD MED, V86, P474, DOI 10.1097/ACM.0b013e31820cb28a; Heng JJY, 2023, POSTGRAD MED J, V99, P1125, DOI 10.1093/postmj/qgad058; Jegorova M, 2023, IEEE T PATTERN ANAL, V45, P9090, DOI 10.1109/TPAMI.2022.3229593; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Khera R, 2023, JAMA-J AM MED ASSOC, V330, P818, DOI 10.1001/jama.2023.15481; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Mesko B, 2023, J MED INTERNET RES, V25, DOI 10.2196/48392; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; Rocher L, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10933-3; Sadava EE, 2021, J LAPAROENDOSC ADV S, V31, P551, DOI 10.1089/lap.2021.0081; Safranek CW, 2023, JMIR MED EDUC, V9, DOI [10.2196/50945, 10.2023/1/e50945]; Seetharaman R, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01957-w; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Trehan K, 2014, J THORAC CARDIOV SUR, V147, P18, DOI 10.1016/j.jtcvs.2013.09.007; Tsang R, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231178449; Zack Travis, 2024, Lancet Digit Health, V6, pe12, DOI 10.1016/S2589-7500(23)00225-X; Zhao WJ, 2020, BMC MED EDUC, V20, DOI 10.1186/s12909-020-02306-y	42	0	0	1	1	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY		2196-7091		SMART LEARN ENVIRON	Smart Learn. Env.	JUN 5	2024	11	1							26	10.1186/s40561-024-00313-w	http://dx.doi.org/10.1186/s40561-024-00313-w			11	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	TD5I3		gold			2024-07-03	WOS:001239332100001
J	Chatterjee, S; Bhattacharya, M; Pal, S; Lee, SS; Chakraborty, C				Chatterjee, Srijan; Bhattacharya, Manojit; Pal, Soumen; Lee, Sang-Soo; Chakraborty, Chiranjib			ChatGPT and large language models in orthopedics: from education and surgery to research	JOURNAL OF EXPERIMENTAL ORTHOPAEDICS			English	Review						Large language models; ChatGPT; Orthopedics; Concern	ARTIFICIAL-INTELLIGENCE	ChatGPT has quickly popularized since its release in November 2022. Currently, large language models (LLMs) and ChatGPT have been applied in various domains of medical science, including in cardiology, nephrology, orthopedics, ophthalmology, gastroenterology, and radiology. Researchers are exploring the potential of LLMs and ChatGPT for clinicians and surgeons in every domain. This study discusses how ChatGPT can help orthopedic clinicians and surgeons perform various medical tasks. LLMs and ChatGPT can help the patient community by providing suggestions and diagnostic guidelines. In this study, the use of LLMs and ChatGPT to enhance and expand the field of orthopedics, including orthopedic education, surgery, and research, is explored. Present LLMs have several shortcomings, which are discussed herein. However, next-generation and future domain-specific LLMs are expected to be more potent and transform patients' quality of life.	[Chatterjee, Srijan; Lee, Sang-Soo] Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chuncheon Si 24252, Gangwon Do, South Korea; [Bhattacharya, Manojit] Fakir Mohan Univ, Dept Zool, Balasore 756020, Odisha, India; [Pal, Soumen] Vellore Inst Technol, Sch Mech Engn, Vellore, Tamil Nadu, India; [Chakraborty, Chiranjib] Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, West Bengal, India	Hallym University; Fakir Mohan University; Vellore Institute of Technology (VIT); VIT Vellore	Lee, SS (corresponding author), Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthoped Surg, Chuncheon Si 24252, Gangwon Do, South Korea.; Chakraborty, C (corresponding author), Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, West Bengal, India.	123sslee@gmail.com; drchiranjib@yahoo.com	Bhattacharya, Manojit/A-2027-2012; Chakraborty, Chiranjib/J-4847-2013	Bhattacharya, Manojit/0000-0001-9669-1835; Chakraborty, Chiranjib/0000-0002-3958-239X; Chatterjee, Srijan/0000-0002-8282-8324	Hallym University Research Fund; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education [NRF- 2020R1I1A3074575]	Hallym University Research Fund; Basic Science Research Program through the National Research Foundation of Korea (NRF) - Ministry of Education(National Research Foundation of KoreaMinistry of Education (MOE), Republic of KoreaNational Research Council for Economics, Humanities & Social Sciences, Republic of Korea)	This study was supported by Hallym University Research Fund and by Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the Ministry of Education (NRF- 2020R1I1A3074575).	Abdelhady AM., 2023, Mayo Clin Proc Digital Health, V1, P299; AbuShawar B, 2015, COMPUT SIST, V19, P625, DOI 10.13053/CyS-19-4-2326; Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; [Anonymous], 2022, Chat GPT-OpenAI; Tran BX, 2019, J CLIN MED, V8, DOI 10.3390/jcm8030360; Basu K, 2020, INDIAN J DERMATOL, V65, P365, DOI 10.4103/ijd.IJD_421_20; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Bernard M, 2017, First FDA approval for clinical cloud-based deep learning in healthcare; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bouton CE, 2016, NATURE, V533, P247, DOI 10.1038/nature17435; Brandtzaeg PB, 2017, LECT NOTES COMPUT SC, V10673, P377, DOI 10.1007/978-3-319-70284-1_30; Brink JA, 2017, EUR RADIOL, V27, P3647, DOI 10.1007/s00330-016-4688-5; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Burstein J, 2019, P 2019 C N AM CHAPT, V1; Cabitza F, 2018, FRONT BIOENG BIOTECH, V6, DOI 10.3389/fbioe.2018.00075; Chakraborty C, 2024, ANN BIOMED ENG, V52, P134, DOI 10.1007/s10439-023-03297-9; Chatterjee S, 2023, MOL THER-NUCL ACIDS, V33, P205, DOI 10.1016/j.omtn.2023.06.019; Cheng KM, 2023, INT J SURG, V109, P1545, DOI 10.1097/JS9.0000000000000388; Choi JH, 2022, J LEGAL EDUC, V71, P387; Chow JCL, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1166014; COLBY KM, 1971, ARTIF INTELL, V2, P1, DOI 10.1016/0004-3702(71)90002-6; Cuthbert R, 2023, POSTGRAD MED J, V99, P1110, DOI 10.1093/postmj/qgad053; Dale R, 2016, NAT LANG ENG, V22, P811, DOI 10.1017/S1351324916000243; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Demszky D, 2023, NAT REV PSYCHOL, V2, P688, DOI 10.1038/s44159-023-00241-5; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dilsizian SE, 2014, CURR CARDIOL REP, V16, DOI 10.1007/s11886-013-0441-8; Dubin JA, 2023, J ARTHROPLASTY, V38, P1195, DOI 10.1016/j.arth.2023.04.007; Eggmann F, 2023, J ESTHET RESTOR DENT, V35, P1098, DOI 10.1111/jerd.13046; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Farhadi F, 2022, FRONT MED TECHNOL, V4, DOI 10.3389/fmedt.2022.995526; Farina D, 2017, NAT BIOMED ENG, V1, DOI 10.1038/s41551-016-0025; Fayed AM, 2023, J EXP ORTHOP, V10, DOI 10.1186/s40634-023-00642-8; Ferres JML, 2023, DIAGN INTERV IMAG, V104, P263, DOI 10.1016/j.diii.2023.02.006; Graham Flora, 2023, Nature, DOI 10.1038/d41586-023-00188-w; Hashimoto DA, 2018, ANN SURG, V268, P70, DOI 10.1097/SLA.0000000000002693; Hassan AM, 2023, ANN SURG ONCOL, V30, P3875, DOI 10.1245/s10434-023-13347-0; He YB, 2023, ANN BIOMED ENG, V51, P1362, DOI 10.1007/s10439-023-03206-0; Hernigou P, 2023, INT ORTHOP, V47, P1887, DOI 10.1007/s00264-023-05887-7; Howard J, 2019, AM J IND MED, V62, P917, DOI 10.1002/ajim.23037; Janssen BV, 2023, BJS OPEN, V7, DOI 10.1093/bjsopen/zrad032; Kalmet PHS, 2020, ACTA ORTHOP, V91, P215, DOI 10.1080/17453674.2019.1711323; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lisacek-Kiosoglous AB, 2023, BONE JOINT RES, V12, P447, DOI 10.1302/2046-3758.127.BJR-2023-0111.R1; Liu SN, 2022, CANCER MANAG RES, V14, P51, DOI 10.2147/CMAR.S340114; Lum ZC, 2023, CLIN ORTHOP RELAT R, V481, P1623, DOI 10.1097/CORR.0000000000002704; Marietto MDB, 2013, Arxiv, DOI [arXiv:1307.3091, DOI 10.48550/ARXIV.1307.3091, 10.48550/arXiv.1307.3091]; OpenAI, 2022, Introducing chatgpt; Papandrianos N, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10080532; Papandrianos N, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030997; Peters S, 2017, CANCER RES, V77, DOI 10.1158/1538-7445.AM2017-CT082; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Recht M, 2017, J AM COLL RADIOL, V14, P1476, DOI 10.1016/j.jacr.2017.07.007; Reddy S, 2020, J AM MED INFORM ASSN, V27, P491, DOI 10.1093/jamia/ocz192; Siegler James E, 2015, J Grad Med Educ, V7, P16, DOI 10.4300/JGME-D-14-00494.1; Somashekhar SP, 2017, CANCER RES, V77, DOI 10.1158/1538-7445.SABCS16-S6-07; Son H J., 2023, SSRN 4420774; Stephens LD, 2023, TRANSFUSION, V63, P1110, DOI 10.1111/trf.17385; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tai MCT, 2020, TZU CHI MED J, V32, P339, DOI 10.4103/tcmj.tcmj_71_20; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; WEIZENBAUM J, 1966, COMMUN ACM, V9, P36, DOI 10.1145/357980.357991; Wen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1207; Wogu IAP, 2017, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTING NETWORKING AND INFORMATICS (ICCNI 2017); Xue VW, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1216; Zhao Z, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-74135-4	70	7	7	21	25	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA		2197-1153		J EXP ORTHOP	J Exp. Orthop.	DEC 1	2023	10	1							128	10.1186/s40634-023-00700-1	http://dx.doi.org/10.1186/s40634-023-00700-1			10	Orthopedics; Surgery	Emerging Sources Citation Index (ESCI)	Orthopedics; Surgery	Z4UE4	38038796	gold			2024-07-03	WOS:001112035900001
J	Wei, Y; Hou, YY				Wei, Yu; Hou, Yueyuan			Forest Visitors' Multisensory Perception and Restoration Effects: A Study of China's National Forest Parks by Introducing Generative Large Language Model	FORESTS			English	Article						multisensory perception; restoration effects; forest recreation; generative large language model; National Forest Parks	SENSE; ENVIRONMENTS; GREEN	Sensory perception of forests is closely related to human health and well-being. Based on attention recovery theory and stress relief theory, this paper investigates the influence of sensory perception of forests on visitors' restoration effects from a multidimensional and multisensory perspective, integrating the use of a generative large language model, regression analysis, and semantic analysis. The results of the study show that (1) the application of a generative large language model provides new ideas and methods to solve the dilemma caused by the traditional self-report scale measurement and provides a possible way to explore a new research paradigm in the context of the rapid development of generative artificial intelligence; (2) the effects of each sensory quantity differed, with the sensory quantities of sight, hearing, touch, and taste having a significant positive effect on visitors' restoration effects, and the sense of smell having a significant negative effect on visitors' restoration effects; (3) sensory psychological distance partially had a significant effect on visitors' restoration effects, both proximal psychological distance and distal psychological distance were significantly correlated with visitors' restoration effects, and intermediate psychological distance had a negative effect on visitors' restoration effects, but the effect was not significant; (4) the sensory dimension has a significant positive effect on visitors' restoration effects, the integration and synergistic effect of the senses are enhanced, and multidimensional sensory cross-perception has a positive effect on visitors' restoration effects at the social health level; and (5) the sensory elements of National Forest Parks that influence visitors' restoration effects are mainly natural attributes, and the elements related to "people" also play an important role in visitors' restoration effects. This study provides a useful complement to the study of forest sensory perception, and at the same time has an important reference value for exploring the management of forest recreation experience and sensory marketing practices.	[Wei, Yu] Nanjing Forestry Univ, Coll Econ & Management, Nanjing 210037, Peoples R China; [Wei, Yu] NJFU Acad Chinese Ecol Progress & Forestry Dev Stu, Nanjing 210037, Peoples R China; [Hou, Yueyuan] Swarma Res Ctr, Beijing 102300, Peoples R China	Nanjing Forestry University	Wei, Y (corresponding author), Nanjing Forestry Univ, Coll Econ & Management, Nanjing 210037, Peoples R China.; Wei, Y (corresponding author), NJFU Acad Chinese Ecol Progress & Forestry Dev Stu, Nanjing 210037, Peoples R China.	weiyutour@njfu.edu.com; houyy.cm@gmail.com			Nanjing Forestry University Metasequoia Research Fund	Nanjing Forestry University Metasequoia Research Fund	No Statement Available	Aher GV, 2023, INT C MACHINE LEARNI, P337; Ahmad S, 2020, IEEE ACCESS, V8, P73865, DOI 10.1109/ACCESS.2020.2987842; Brancato GG, 2022, J ENVIRON PSYCHOL, V81, DOI 10.1016/j.jenvp.2022.101779; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carpenter KA, 2023, BIOMOLECULES, V13, DOI 10.3390/biom13020387; Chan D, 2009, STATISTICAL AND METHODOLOGICAL MYTHS AND URBAN LEGENDS: DOCTRINE, VERITY AND FABLE IN THE ORGANIZATIONAL AND SOCIAL SCIENCES, P309; Chen G., 2021, Tour. Forum, V14, P1; [陈海贤 Chen Haixian], 2014, [心理学报, Acta Psychologica Sinica], V46, P677; [陈晓 Chen Xiao], 2016, [心理科学进展, Advances in Psychological Science], V24, P270; Dann G. M. S., 2003, Tourism Geographies, V5, P3, DOI 10.1080/1461668032000034033; Deng L, 2020, URBAN FOR URBAN GREE, V53, DOI 10.1016/j.ufug.2020.126702; [邓丽萍 Deng Liping], 2017, [中文信息学报, Journal of Chinese Information Processing], V31, P9; Dong Y., 2022, Tour. Sci, V36, P101; Elder RS, 2017, J CONSUM RES, V44, P877, DOI 10.1093/jcr/ucx070; ENGEN T, 1973, ANNU REV PSYCHOL, V24, P187, DOI 10.1146/annurev.ps.24.020173.001155; Ernst MO, 2004, TRENDS COGN SCI, V8, P162, DOI 10.1016/j.tics.2004.02.002; Feng Z., 2012, A Concise Tutorial on Natural Language Processing; Fourati M, 2023, APPL INTELL, V53, P8776, DOI 10.1007/s10489-022-03938-x; Friedman A, 2021, J PERS ASSESS, V103, P380, DOI 10.1080/00223891.2020.1754230; Gaekwad JS, 2023, J ENVIRON PSYCHOL, V90, DOI 10.1016/j.jenvp.2023.102085; Grilli G, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17176125; Gui C., 2023, Telecom Eng. Technol. Stand, V3, P24; Guo YongRui Guo YongRui, 2014, Tourism Tribune, V29, P93; Henshaw V., 2013, Urban Smellscapes: Understanding and Designing City Smell Environments, DOI DOI 10.4324/9780203072776; Hillel D, 2013, TOURISM MANAGE, V36, P200, DOI 10.1016/j.tourman.2012.12.006; [胡铭菲 Hu Mingfei], 2022, [自动化学报, Acta Automatica Sinica], V48, P40; Jennings V, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16030452; Jennings V, 2017, INT J ENV RES PUB HE, V14, DOI 10.3390/ijerph14111432; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kah JA, 2022, TOURISM GEOGR, V24, P475, DOI 10.1080/14616688.2020.1765015; KAPLAN S, 1995, J ENVIRON PSYCHOL, V15, P169, DOI 10.1016/0272-4944(95)90001-2; Kaplan S., 1983, Behavior and the natural environment., P163; Kim DM, 2018, INT CONF BIG DATA, P530, DOI 10.1109/BigComp.2018.00088; Kim J, 2020, TOURISM MANAGE, V79, DOI 10.1016/j.tourman.2019.104012; Krishna A, 2014, J CONSUM PSYCHOL, V24, P159, DOI 10.1016/j.jcps.2013.12.006; Krusemark EA, 2013, J NEUROSCI, V33, P587, DOI [10.1523/JNEUROSCI.1379-12.2013, 10.1523/JNEUROSCI.1835-13.2013]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Larson LR, 2022, ENVIRON RES, V204, DOI 10.1016/j.envres.2021.112367; Leiser F, 2023, PROCEEDINGS OF 2023 MENSCH UND COMPUTER, MUC 2023, P81, DOI 10.1145/3603555.3603565; Li HY, 2019, INT J HOSP MANAG, V83, P257, DOI 10.1016/j.ijhm.2018.11.002; Li HH, 2023, TOURISM MANAGE, V97, DOI 10.1016/j.tourman.2023.104723; Li MM, 2020, TOUR MANAG PERSPECT, V33, DOI 10.1016/j.tmp.2019.100586; [李雁晨 LI Yan-Chen], 2009, [心理科学进展, Advances in Psychological Science], V17, P667; Liberman N, 1998, J PERS SOC PSYCHOL, V75, P5, DOI 10.1037/0022-3514.75.1.5; Luo Y., 2023, Nat. Mag, V2, P106; Lv XY, 2020, TOURISM MANAGE, V77, DOI 10.1016/j.tourman.2019.104026; Mayer FS, 2009, ENVIRON BEHAV, V41, P607, DOI 10.1177/0013916508319745; Mundher R, 2022, URBAN SCI, V6, DOI 10.3390/urbansci6040079; Nilsson K, 2011, FORESTS, TREES AND HUMAN HEALTH, P1, DOI 10.1007/978-90-481-9806-1_1; Pan S, 2009, J TRAVEL TOUR MARK, V26, P625, DOI 10.1080/10548400903276897; Qiu MY, 2021, TOUR MANAG PERSPECT, V39, DOI 10.1016/j.tmp.2021.100855; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Shen H, 2023, Arxiv, DOI arXiv:2307.04280; Sihong Z., 2023, Telecommun. Sci, V39, P67; Song ZhuFang Song ZhuFang, 2019, Tourism Tribune, V34, P90; Su LJ, 2021, ANN TOURISM RES, V91, DOI 10.1016/j.annals.2021.103316; Takayama N, 2014, INT J ENV RES PUB HE, V11, P7207, DOI 10.3390/ijerph110707207; Tan SH., 2009, Chin Landsc Archit, V25, P79, DOI [10.3969/j.issn.1000-6664.2009.06.020, DOI 10.3969/J.ISSN.1000-6664.2009.06.020]; Tang XY, 2016, NEUROSCI BIOBEHAV R, V61, P208, DOI 10.1016/j.neubiorev.2015.11.002; Taylor AF, 2009, J ATTEN DISORD, V12, P402, DOI 10.1177/1087054708323000; Tingting G., 2019, Collect. Essays Financ. Econ, V250, P82; Townsend Mardie, 2006, Urban Forestry & Urban Greening, V5, P111, DOI 10.1016/j.ufug.2006.02.001; Trope Y, 2010, PSYCHOL REV, V117, P440, DOI 10.1037/a0018963; Ulrich R.S., 1983, BEHAV NATURAL ENV, DOI [DOI 10.1007/978-1-4613-3539-94, DOI 10.1007/978-1-4613-3539-9_4, 10.1007/978-1-4613-3539-9, DOI 10.1007/978-1-4613-3539-9]; UNDP (United Nations Development Programme), 2022, Human Development Report 2021/2022. Uncertain Times; Wang Jing, 2022, Tourism Tribune, V37, P80, DOI 10.19765/j.cnki.1002-5006.2022.07.011; Wang WF, 2018, TOURISM MANAGE, V69, P422, DOI 10.1016/j.tourman.2018.06.024; Wang YC, 2020, J TRAVEL RES, V59, P496, DOI 10.1177/0047287519839777; [文小辉 Wen Xiaohui], 2011, [心理科学进展, Advances in Psychological Science], V19, P976; Wong Siao Fui, 2022, Tourism and Hospitality, V3, P666, DOI 10.3390/tourhosp3030041; World Health Organization, COVID-19 Pandemic Prompts 25% Increase in Global Anxiety and Depression Prevalence; Xie B, 2022, URBAN FOR URBAN GREE, V67, DOI 10.1016/j.ufug.2021.127419; Yamada Yozo, 2006, Urban Forestry & Urban Greening, V5, P131, DOI 10.1016/j.ufug.2006.05.001; Yao C., 2020, World Reg. Stud, V29, P181, DOI [10.3969/j.issn.1004-9479.2020.01.2018367, DOI 10.3969/J.ISSN.1004-9479.2020.01.2018367]; Yaobin W., 2017, Resour. Dev. Mark, V33, P100; Zhang QF, 2021, SOC SCI MED, V279, DOI 10.1016/j.socscimed.2021.113951; [张腾霄 Zhang Tengxiao], 2013, [心理科学进展, Advances in Psychological Science], V21, P398; Zhang YW, 2021, TOUR MANAG PERSPECT, V40, DOI 10.1016/j.tmp.2021.100904	78	1	1	21	21	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		1999-4907		FORESTS	Forests	DEC	2023	14	12							2412	10.3390/f14122412	http://dx.doi.org/10.3390/f14122412			26	Forestry	Science Citation Index Expanded (SCI-EXPANDED)	Forestry	DG4W5		gold			2024-07-03	WOS:001130872500001
J	Lindsay, GW				Lindsay, Grace W.			LLMs are not ready for editorial work	NATURE HUMAN BEHAVIOUR			English	Editorial Material; Early Access								Large language models are capable of impressive feats, but the job of scientific review requires more than the statistics of published work can provide.	[Lindsay, Grace W.] NYU, New York, NY 10012 USA	New York University	Lindsay, GW (corresponding author), NYU, New York, NY 10012 USA.	grace.lindsay@nyu.edu		Lindsay, Grace/0000-0001-9904-7471				Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Katz D. M., 2023, PREPRINT, DOI [10.2139/ssrn.4389233, DOI 10.2139/SSRN.4389233]; Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776	3	0	0	2	2	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2023 NOV 20	2023										10.1038/s41562-023-01730-6	http://dx.doi.org/10.1038/s41562-023-01730-6		NOV 2023	2	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	Y8GD1	37985909				2024-07-03	WOS:001107579600017
J	Petrosanu, DM; Pîrjan, A; Tabusca, A				Petrosanu, Dana-Mihaela; Pirjan, Alexandru; Tabusca, Alexandru			Tracing the Influence of Large Language Models across the Most Impactful Scientific Works	ELECTRONICS			English	Review						artificial intelligence (AI); machine learning (ML); large language models (LLMs); natural language processing (NLP); technological impact; interdisciplinary applications; ethical considerations; data privacy and security	INTELLIGENCE	In recent years, large language models (LLMs) have come into view as one of the most transformative developments in the technical domain, influencing diverse sectors ranging from natural language processing (NLP) to creative arts. Their rise signifies an unprecedented convergence of computational prowess, sophisticated algorithms, and expansive datasets, pushing the boundaries of what was once thought to be achievable. Such a profound impact mandates a thorough exploration of the LLMs' evolutionary trajectory. Consequently, this article conducts a literature review of the most impactful scientific works, using the reliable Web of Science (WoS) indexing database as a data source in order to attain a thorough and quality-assured analysis. This review identifies relevant patterns, provides research insights, traces technological growth, and anticipates potential future directions. Beyond mapping the known, this study aims to highlight uncharted areas within the LLM landscape, thereby catalyzing future research endeavors. The ultimate goal is to enhance collective understanding, encourage collaboration, and guide subsequent innovations in harnessing the potential of LLMs for societal and technological advancement.	[Petrosanu, Dana-Mihaela] Natl Univ Sci & Technol Politehn Bucharest, Dept Math Informat, Splaiul Independentei 313, Bucharest 060042, Romania; [Pirjan, Alexandru; Tabusca, Alexandru] Romanian Amer Univ, Dept Informat Stat & Math, Expozitiei 1B, Bucharest 012101, Romania		Petrosanu, DM (corresponding author), Natl Univ Sci & Technol Politehn Bucharest, Dept Math Informat, Splaiul Independentei 313, Bucharest 060042, Romania.	dana.petrosanu@upb.ro; alexandru.pirjan@rau.ro; alex.tabusca@rau.ro	Pîrjan, Alexandru/G-3926-2015	Pîrjan, Alexandru/0000-0002-7381-1934	Center of Research, Consultancy and Training in Economic Informatics and Information Technology RAU-INFORTIS of the Romanian-American University	Center of Research, Consultancy and Training in Economic Informatics and Information Technology RAU-INFORTIS of the Romanian-American University	The authors would like to express their gratitude for the logistics support received from the Center of Research, Consultancy and Training in Economic Informatics and Information Technology RAU-INFORTIS of the Romanian-American University.	Ali F, 2021, FUTURE GENER COMP SY, V114, P23, DOI 10.1016/j.future.2020.07.047; Bingham E, 2019, J MACH LEARN RES, V20; Bird JJ, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03439-8; Bolton T, 2019, J ADV MODEL EARTH SY, V11, P376, DOI 10.1029/2018MS001472; Bouschery SG, 2023, J PROD INNOVAT MANAG, V40, P139, DOI 10.1111/jpim.12656; Brenowitz ND, 2018, GEOPHYS RES LETT, V45, P6289, DOI 10.1029/2018GL078510; Carvalho I, 2024, TOUR REV, V79, P290, DOI 10.1108/TR-02-2023-0088; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chartrand G, 2017, RADIOGRAPHICS, V37, P2113, DOI 10.1148/rg.2017170077; Chen XL, 2022, EDUC TECHNOL SOC, V25, P28; Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7; clarivate, Clarivate Web of Science Citation Topics; clarivate, Clarivate Web of Science Journal Valuation Process (Graphic); Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Dimitriu MCT, 2020, MED HYPOTHESES, V144, DOI 10.1016/j.mehy.2020.109972; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; El-Sappagh S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82098-3; Elnagar A, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102121; Fink O, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103678; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gentine P, 2018, GEOPHYS RES LETT, V45, P5742, DOI 10.1029/2018GL078202; Gupta R, 2023, J PLAST RECONSTR AES, V80, P145, DOI 10.1016/j.bjps.2023.03.004; Hallsworth JE, 2023, MICROB BIOTECHNOL, V16, P1131, DOI 10.1111/1751-7915.14222; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Hoie MH, 2022, NUCLEIC ACIDS RES, V50, pW510, DOI 10.1093/nar/gkac439; Hu YH, 2023, INTERACT LEARN ENVIR, DOI [10.1080/10494820.2022.2160467, 10.1109/ICASSP49357.2023.10096615]; Huai S, 2022, LANDSCAPE URBAN PLAN, V218, DOI 10.1016/j.landurbplan.2021.104307; Huang AH, 2023, CONTEMP ACCOUNT RES, V40, P806, DOI 10.1111/1911-3846.12832; Khorshidi A, 2016, COMPUT PHYS COMMUN, V207, P310, DOI 10.1016/j.cpc.2016.05.010; Kong QQ, 2020, IEEE-ACM T AUDIO SPE, V28, P2880, DOI 10.1109/TASLP.2020.3030497; Kwok SWH, 2021, J MED INTERNET RES, V23, DOI 10.2196/26953; Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Liang HY, 2019, NAT MED, V25, P433, DOI 10.1038/s41591-018-0335-9; Lin ZM, 2023, SCIENCE, V379, P1123, DOI 10.1126/science.ade2574; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923; Moroianu M, 2023, J MIND MED SCI, V10, P72, DOI 10.22543/2392-7674.1368; Munchmeyer J, 2022, J GEOPHYS RES-SOL EA, V127, DOI 10.1029/2021JB023499; Nikfarjam A, 2015, J AM MED INFORM ASSN, V22, P671, DOI 10.1093/jamia/ocu041; O'Gorman PA, 2018, J ADV MODEL EARTH SY, V10, P2548, DOI 10.1029/2018MS001351; Otter DW, 2021, IEEE T NEUR NET LEAR, V32, P604, DOI 10.1109/TNNLS.2020.2979670; Park J, 2019, P IEEE, V107, P2204, DOI 10.1109/JPROC.2019.2941458; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Rezaeinia SM, 2019, EXPERT SYST APPL, V117, P139, DOI 10.1016/j.eswa.2018.08.044; Roh Y, 2021, IEEE T KNOWL DATA EN, V33, P1328, DOI 10.1109/TKDE.2019.2946162; Samaan JS, 2023, OBES SURG, V33, P1790, DOI 10.1007/s11695-023-06603-5; Sams A. S., 2023, Bull. Electr. Eng. Inform, V12, P355, DOI DOI 10.11591/EEI.V12I1.4231; Thompson AP, 2022, COMPUT PHYS COMMUN, V271, DOI 10.1016/j.cpc.2021.108171; Timoshenko A, 2019, MARKET SCI, V38, P1, DOI 10.1287/mksc.2018.1123; Tu Y, 2022, CHINESE J AERONAUT, V35, P35, DOI 10.1016/j.cja.2021.08.016; Vaswani A, 2017, ADV NEUR IN, V30; Wu WT, 2021, MILITARY MED RES, V8, DOI 10.1186/s40779-021-00338-z; Wu Y, 2023, IEEE T PATTERN ANAL, V45, P1162, DOI 10.1109/TPAMI.2022.3144984; Xie Y, 2023, AESTHET PLAST SURG, V47, P1985, DOI 10.1007/s00266-023-03338-7; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Zhang YZ, 2020, COMPUT PHYS COMMUN, V253, DOI 10.1016/j.cpc.2020.107206; Zhu LA, 2023, INFORM FUSION, V95, P306, DOI 10.1016/j.inffus.2023.02.028; Zhu LA, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1044	60	0	0	24	24	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2079-9292		ELECTRONICS-SWITZ	Electronics	DEC	2023	12	24							4957	10.3390/electronics12244957	http://dx.doi.org/10.3390/electronics12244957			30	Computer Science, Information Systems; Engineering, Electrical & Electronic; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Physics	DI6O9		gold			2024-07-03	WOS:001131443900001
J	Srivastava, SK; Routray, S; Bag, S; Gupta, S; Zhang, JZ				Srivastava, Santosh Kumar; Routray, Susmi; Bag, Surajit; Gupta, Shivam; Zhang, Justin Zuopeng			Exploring the Potential of Large Language Models in Supply Chain Management: A Study Using Big Data	JOURNAL OF GLOBAL INFORMATION MANAGEMENT			English	Article						BERT; Large language model; Social Media; Supply chain management	PREDICTIVE ANALYTICS; DATA SCIENCE	This study aims to identify emerging topics, themes, and potential areas for applying large language models (LLMs) in supply chain management through data triangulation. This study involved the synthesis of 33 published articles and a total of 3421 social media documents, including tweets, posts, expert opinions, and industry reports on utilizing LLMs in supply chain management. By employing BERT models, four core themes were derived: Supply chain optimization, supply chain risk and security management, supply chain knowledge management, and automated contract intelligence, which provides the present status of LLM in the supply chain. The results of this study will empower managers to identify prospective applications and areas for improvement, affording them a comprehensive understanding of the antecedents, decisions, and outcomes detailed in the framework. The insights garnered from this study are highly valuable to both researchers and managers, equipping them to harness the latest advancements in LLM technology and its role within supply chain management.	[Srivastava, Santosh Kumar; Routray, Susmi] Inst Management Technol, Ghaziabad, India; [Bag, Surajit] Leonard de Vinci Pole Univ, Res Ctr, Courbevoie, France; [Gupta, Shivam] NEOMA Business Sch, Dept Informat Syst Supply Chain Management & Decis, Mont St Aignan, France; [Zhang, Justin Zuopeng] Univ North Florida, Jacksonville, FL 32224 USA	Institute of Management Technology, Ghaziabad; NEOMA Business School; State University System of Florida; University of North Florida	Zhang, JZ (corresponding author), Univ North Florida, Jacksonville, FL 32224 USA.		Bag, Surajit/AAF-4874-2020; SRIVASTAVA, SANTOSH/KIB-5132-2024	Bag, Surajit/0000-0002-2344-9551; 				Al Sayed M, 2023, LECT NOTES COMPUT SC, V14134, P162, DOI 10.1007/978-3-031-43085-5_13; AlZubi S., 2022, OJS, DOI [10.47852/bonviewAIA3202820, DOI 10.47852/BONVIEWAIA3202820]; [Anonymous], 2011, Mining the social web: analyzing data from Facebook, Twitter, LinkedIn, and other social media sites; Bag S, 2023, TRANSPORT RES E-LOG, V171, DOI 10.1016/j.tre.2023.103031; Belhadi A, 2022, INT J PROD ECON, V249, DOI 10.1016/j.ijpe.2022.108516; Bi R, 2013, J GLOB INF MANAG, V21, P38, DOI 10.4018/jgim.2013100103; Buthelezi BE, 2022, J GLOB INF MANAG, V30, DOI 10.4018/JGIM.297625; Chatterjee S, 2023, TECHNOL FORECAST SOC, V196, DOI 10.1016/j.techfore.2023.122824; Chowdhury Minhaz, 2023, 2023 IEEE International Conference on Electro Information Technology (eIT), P499, DOI 10.1109/eIT57321.2023.10187385; Cortez RM, 2023, J BUS RES, V155, DOI 10.1016/j.jbusres.2022.113388; De Bock K. W., 2023, Eur. J. Oper. Res, DOI [10.1016/j.ejor.2023.09.026, DOI 10.1016/J.EJOR.2023.09.026]; Dubey VK, 2018, INT J PROD ECON, V200, P240, DOI 10.1016/j.ijpe.2018.03.003; Fernandez RC, 2023, PROC VLDB ENDOW, V16, P3302; Frederico GF, 2023, LOGISTICS-BASEL, V7, DOI 10.3390/logistics7020026; Ganesh D, 2022, COMPUT IND ENG, V169, DOI 10.1016/j.cie.2022.108206; Gill SS, 2022, INTERNET THINGS-NETH, V19, DOI 10.1016/j.iot.2022.100514; Hardeniya N, 2016, Natural language processing: python and NLTK; Hazen BT, 2014, INT J PROD ECON, V154, P72, DOI 10.1016/j.ijpe.2014.04.018; Hendriksen C, 2023, J SUPPLY CHAIN MANAG, V59, P65, DOI 10.1111/jscm.12304; Hu YH, 2020, J INFORMETR, V14, DOI 10.1016/j.joi.2019.101004; Ivanov D, 2022, OPER MANAGE RES, V15, P475, DOI 10.1007/s12063-021-00194-z; Jacobs F.R., 2014, Operations and supply chain management; Just J, 2024, TECHNOVATION, V129, DOI 10.1016/j.technovation.2023.102883; Kache F, 2017, INT J OPER PROD MAN, V37, P10, DOI 10.1108/IJOPM-02-2015-0078; Kar AK., 2023, Glob. J. Flex. Syst. Manag, V24, P659, DOI [10.1007/s40171-023-00356-x, DOI 10.1007/S40171-023-00356-X]; Kumar A., 2023, Journal of Business Strategy, V45, P161, DOI [10.1108/JBS-04-2023-0067, DOI 10.1108/JBS-04-2023-0067]; Lambert DM, 2000, IND MARKET MANAG, V29, P65, DOI 10.1016/S0019-8501(99)00113-3; Mohamed Shaffril H.A., 2021, Quality Quantity, V55, P1319, DOI DOI 10.1007/S11135-020-01059-6; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]; Muninger MI, 2022, J BUS RES, V143, P140, DOI 10.1016/j.jbusres.2022.01.039; Mustak M, 2021, J BUS RES, V124, P389, DOI 10.1016/j.jbusres.2020.10.044; Oliveira E. E., 2023, IFIP INT C ADV PROD, P444, DOI [10.1007/978-3-031-43662-8_32, DOI 10.1007/978-3-031-43662-8_32]; Paul J, 2020, INT BUS REV, V29, DOI 10.1016/j.ibusrev.2020.101717; Paul J, 2018, ASIA PAC BUS REV, V24, P90, DOI 10.1080/13602381.2017.1357316; Richey RG Jr, 2023, J BUS LOGIST, V44, P532, DOI 10.1111/jbl.12364; Shrivastav M, 2022, J GLOB INF MANAG, V30, DOI 10.4018/JGIM.296725; Shrivastava S, 2023, J BUS IND MARK, V38, P2673, DOI 10.1108/JBIM-02-2023-0122; Srivastava S. K., 2023, Global Journal of Flexible Systems Management, V24, P483, DOI [10.1007/s40171-023-00351-2, DOI 10.1007/S40171-023-00351-2]; Stadtler H.et., 2008, Supply Chain Management and Advanced Planning, V4th, DOI DOI 10.1007/978-3-540-74512-9; Swain AK, 2019, INFORM SYST FRONT, V21, P469, DOI 10.1007/s10796-017-9762-2; Tian YL, 2023, IEEE T INTELL VEHICL, V8, P4198, DOI 10.1109/TIV.2023.3307012; Trappey AJC, 2022, J GLOB INF MANAG, V30, DOI 10.4018/JGIM.309082; Tsai Sang-Bing, 2023, Pers Ubiquitous Comput, P1, DOI 10.1007/s00779-023-01715-2; Wahid JA, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116562; Waller MA, 2013, J BUS LOGIST, V34, P77, DOI 10.1111/jbl.12010; Wamba SF, 2023, INT J PROD ECON, V265, DOI 10.1016/j.ijpe.2023.109015; Wang H, 2023, IET COLL INTEL MANUF, V5, DOI 10.1049/cim2.12078; Wang Xingzhi, 2023, Procedia CIRP, P7, DOI 10.1016/j.procir.2023.04.001; Wang Y, 2021, J BUS IND MARK, V36, P2139, DOI 10.1108/JBIM-05-2019-0173; Williamson K., 2017, RES METHODS INFORM S, VSecond; Xu JN, 2023, TECHNOL FORECAST SOC, V196, DOI 10.1016/j.techfore.2023.122805	51	0	0	70	70	IGI GLOBAL	HERSHEY	701 E CHOCOLATE AVE, STE 200, HERSHEY, PA 17033-1240 USA	1062-7375	1533-7995		J GLOB INF MANAG	J. Glob. Inf. Manag.		2024	32	1					1	29		10.4018/JGIM.335125	http://dx.doi.org/10.4018/JGIM.335125			29	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	FM7M4		gold			2024-07-03	WOS:001146296800001
J	Strahornik, V				Strahornik, Vojko			<i>Ethical and Theological Challenges of Large Language Models</i>	BOGOSLOVNI VESTNIK-THEOLOGICAL QUARTERLY-EPHEMERIDES THEOLOGICAE			English	Article						artificial intelligence; large language models; risks; ethical guidelines; theological challenges of artificial intelligence		In this article we discuss the ethical and theological challenges related to artificial intelligence, especially in the area of large-scale language models. In the second section, we briefly introduce what large language models are and their development. In the third section, we discuss the ethical challenges of these models. I also touch on existing ethical guidelines and highlight to what extent they address these challenges at all. In the fourth section, we highlight the theological challenges raised by these models. These are closely linked to ethical considerations. In conclusion, we give some reflections on languagerelated technologies in our imagination and further development of large-scale linguistic models, including the changes that such a development might bring about.										Arcas BAY, 2022, DAEDALUS-US, V151, P183, DOI 10.1162/daed_a_01909; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Borges J. L., 1999, Collected fictions; Clarke Arthur C., 1953, Star Science Fiction Stories, V1, P195; Constantinescu M, 2022, INT J SOC ROBOT, V14, P1547, DOI 10.1007/s12369-022-00887-w; Deery Oisin, 2022, Feminist Philosophy Quarterly, V8, P3; Dorobantu Marius, 2022, Research gate; Dorobantu Marius., 2021, PHILOS THEOLOGY SCI, V8, P81, DOI DOI 10.1628/PTSC-2021-0006; Evropska komisija, 2019, Eticne smernice za zaupanja vredno umetno inteligenco; Evropski parlament, 2021, Briefing: Artificial intelligence act; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Frankfurt HG, 2005, ON BULLSHIT, P1; Globokar Roman, 2019, Bogoslovni vestnik, V79, P611, DOI [10.34291/bv2019/03/globokar, DOI 10.34291/BV2019/03/GLOBOKAR]; Green BP, 2018, SCI FIDES, V6, P9, DOI 10.12775/SetF.2018.015; Jorion P., 2022, Humanism and its Discontents: The Rise of Transhumanism and Posthumanism, P19; Juhant J, 2010, BOGOSL VESTN, V70, P351; Kraus Matthias, 2021, MultiMedia Modeling. 27th International Conference, MMM 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12573), P354, DOI 10.1007/978-3-030-67835-7_30; Miklavcic J, 2021, BOGOSL VESTN, V81, P935, DOI 10.34291/BV2021/04/Miklavcic; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Raaijmakers S., 2022, Deep learning for natural language processing; Schwitzgebel E, 2023, Arxiv, DOI arXiv:2302.01339; The Future of Life Institute, 2023, Pause Giant AI Experiments: An Open Letter; Tolmeijer S, 2021, ACM COMPUT SURV, V53, DOI 10.1145/3419633; Weidinger Laura, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P214, DOI 10.1145/3531146.3533088; Zalec B, 2019, BOGOSL VESTN, V79, P628, DOI 10.34291/BV2019/03/Zalec	26	0	0	11	11	UNIV LJUBLJANI, TEOLOSKA FAKULTET	LJUBLJANA	POLJANSKA 4, P P 2007, LJUBLJANA, 1000, SLOVENIA	0006-5722	1581-2987		BOGOSL VESTN	Bogosl. Vestn.		2023	83	4					839	852		10.34291/BV2023/04/Strahovnik	http://dx.doi.org/10.34291/BV2023/04/Strahovnik			14	Religion	Emerging Sources Citation Index (ESCI)	Religion	KM9V7		gold			2024-07-03	WOS:001180510300003
J	Scott, IA; Zuccon, G				Scott, Ian A.; Zuccon, Guido			The new paradigm in machine learning - foundation models, large language models and beyond: a primer for physicians	INTERNAL MEDICINE JOURNAL			English	Review						machine learning; large language models; foundational models; artificial intelligence	AI; IMPACT; CARE	Foundation machine learning models are deep learning models capable of performing many different tasks using different data modalities such as text, audio, images and video. They represent a major shift from traditional task-specific machine learning prediction models. Large language models (LLM), brought to wide public prominence in the form of ChatGPT, are text-based foundational models that have the potential to transform medicine by enabling automation of a range of tasks, including writing discharge summaries, answering patients questions and assisting in clinical decision-making. However, such models are not without risk and can potentially cause harm if their development, evaluation and use are devoid of proper scrutiny. This narrative review describes the different types of LLM, their emerging applications and potential limitations and bias and likely future translation into clinical practice.	[Scott, Ian A.] Univ Queensland, Ctr Hlth Serv Res, Ipswich Rd, Woolloongabba, Qld 4102, Australia; [Zuccon, Guido] Univ Queensland, Sch Elect Engn & Comp Sci, St Lucia, Qld 4072, Australia	University of Queensland; University of Queensland	Scott, IA (corresponding author), Univ Queensland, Ctr Hlth Serv Res, Ipswich Rd, Woolloongabba, Qld 4102, Australia.	i.scott@uq.edu.au		Zuccon, Guido/0000-0003-0271-5563				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Ananthaswamy A, 2023, NATURE, V615, P202, DOI 10.1038/d41586-023-00641-w; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Benedicenti F, 2023, GASTROENTEROL REP, V11, DOI 10.1093/gastro/goad052; Bibault JE, 2019, J MED INTERNET RES, V21, DOI 10.2196/15787; Bolton E., 2022, STANFORD CRFM INTRO; Bommasani R., LANGUAGE MODELS ARE; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Clynch N, 2015, INT J MED INFORM, V84, P221, DOI 10.1016/j.ijmedinf.2014.12.001; Coalition for Health AI, 2023, BLUEPR TRUSTW AI IMP; Department of Science, 2023, PROINN APPR AI REG; Duffourc MN, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00823-w; Eddy N., THE EPIC; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Gallegos IO., BIAS FAIRNESS LARGE, DOI DOI 10.48550/ARXIV.2309.00770; Gao Y., LEVERAGING MEDICAL K, DOI DOI 10.48550/ARXIV.2308.14321; Gebrael G, 2023, CANCERS, V15, DOI 10.3390/cancers15143717; Gero Z., SELF VERIFICATION IM, DOI DOI 10.48550/ARXIV.2306.00024; Ghim JL, 2023, TRANSL CLIN PHARMACO, V31, P131, DOI 10.12793/tcp.2023.31.e16; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goddard J, 2023, AM J MED, V136, P1059, DOI 10.1016/j.amjmed.2023.06.012; Goodman RS, 2023, MED-CAMBRIDGE, V4, P139, DOI 10.1016/j.medj.2023.02.008; Guo Q, 2022, INT J INTELL SYST, V37, P8548, DOI 10.1002/int.22955; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Jabbour S, 2023, JAMA-J AM MED ASSOC, V330, P2275, DOI 10.1001/jama.2023.22295; Jamal Amr, 2023, Cureus, V15, pe43036, DOI 10.7759/cureus.43036; Johnson SB, 2023, JNCI CANCER SPECT, V7, DOI 10.1093/jncics/pkad015; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kaufman T Weng P Bengs V Hullermeier E., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2312.14925; Kiciman E., CAUSAL REASONING LAR, DOI DOI 10.48550/ARXIV.2305.00050; Koopman B., ARXIV, DOI DOI 10.48550/ARXIV.2302.13793; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kwee A, 2022, LANCET REG HEALTH-W, V23, DOI 10.1016/j.lanwpc.2022.100476; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Levine David M, 2023, medRxiv, DOI 10.1101/2023.01.30.23285067; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li J., 2023, CHATGPT HEALTHCARE T, DOI DOI 10.1101/2023.03.30.23287899; Li P., MAKING AI LESS THIRS, DOI DOI 10.48550/ARXIV.2304.03271; Li YX, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.40895; Liang P., 2022, HOLISTIC EVALUATION, DOI DOI 10.48550/ARXIV.2211.09110; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Macdonald C, 2023, J GLOB HEALTH, V13, DOI 10.7189/jogh.13.01003; McDuff D., ACCURATE DIFFERENTIA, DOI DOI 10.48550/ARXIV.2312.00164; Medenilla A., 2023, PLoS Digital Health, V2; Mello MM, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.1938; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mika AP, 2023, J BONE JOINT SURG AM, V105, P1519, DOI 10.2106/JBJS.23.00209; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Nashwan AJ., 2023, CUREUS J MED SCIENCE, V15; Omiye JA, 2024, ANN INTERN MED, V177, DOI 10.7326/M23-2772; Organisation for Economic Co-operation and Development, 2022, FRAM CLASS AI SYST; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Pavlick E, 2023, PHILOS T R SOC A, V381, DOI 10.1098/rsta.2022.0041; Perlis RH, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.35924; Rao A, 2023, J MED INTERNET RES, V25, DOI 10.2196/48659; Reddy Sandeep, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2023.101304; Sadr AV, 2024, LANCET DIGIT HEALTH, V6, pe58, DOI 10.1016/S2589-7500(23)00219-4; SALLAM M, 2023, HEALTHCARE-BASEL, V11, DOI DOI 10.3390/HEALTHCARE11060887; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Scott I, 2021, BMJ HEALTH CARE INFO, V28, DOI 10.1136/bmjhci-2020-100251; Scott IA, 2021, INTERN MED J, V51, P1388, DOI 10.1111/imj.15200; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Singhal K., 2023, EXPERT LEVEL MEDICAL, DOI DOI 10.48550/ARXIV.2305.09617; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Siru L., 2023, MEDRXIV, DOI [10.1101/2023.07.14.23292669, DOI 10.1101/2023.07.14.23292669]; Sng GGR, 2023, DIABETES CARE, V46, pE103, DOI 10.2337/dc23-0197; Spataro J., 2023, INTRO MICROSOFT 365; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Tang R., DOES SYNTHETIC DATA, DOI DOI 10.48550/ARXIV.2303.04360; ten Berg H, 2024, ANN EMERG MED, V83, P83, DOI 10.1016/j.annemergmed.2023.08.003; Therapeutic Goods Administration, 2021, CLASS ACT MED DEV IN; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Tsang R, 2023, J MED EDUC CURRIC DE, V10, DOI 10.1177/23821205231178449; Ulloa M., 2022, FRONT COMPUT SCI-CHI, V4, P157; Upshaw TL, 2023, J AM BOARD FAM MED, V36, P210, DOI 10.3122/jabfm.2022.220171R1; US Food and Drug Administration, 2022, CLIN DECISION SUPPOR; Wang S., 2023, P 4 INT ACM SIGIR C; Wornow M, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00879-8; Yu P, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11202776; Zack Travis, 2024, Lancet Digit Health, V6, pe12, DOI 10.1016/S2589-7500(23)00225-X; Zhou ZY, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37589; Zhuang S., 2024, ARXIV, DOI DOI 10.48550/ARXIV.2401.01566	91	1	1	8	8	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1444-0903	1445-5994		INTERN MED J	Intern. Med. J.	MAY	2024	54	5					705	715		10.1111/imj.16393	http://dx.doi.org/10.1111/imj.16393		MAY 2024	11	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	RH0R0	38715436	hybrid			2024-07-03	WOS:001215317200001
C	Xu, A; Monroe, W; Bicknell, K			Assoc Computing Machinery	Xu, Austin; Monroe, Will; Bicknell, Klinton			Large Language Model Augmented Exercise Retrieval for Personalized Language Learning	FOURTEENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, LAK 2024			English	Proceedings Paper	14th Annual International Conference on Learning Analytics and Knowledge (LAK) - Learning Analytics in the Age of Artificial Intelligence	MAR 18-22, 2024	Kyoto, JAPAN	Soc Learning Analyt Res, ACM In Cooperat, SIGWEB, SIGCHI		zero-shot exercise retrieval; online language learning; personalization; large language models	MOTIVATION	We study the problem of zero-shot exercise retrieval in the context of online language learning, to give learners the ability to explicitly request personalized exercises via natural language. Using realworld data collected from language learners, we observe that vector similarity approaches poorly capture the relationship between exercise content and the language that learners use to express what they want to learn. This semantic gap between queries and content dramatically reduces the effectiveness of general-purpose retrieval models pretrained on large scale information retrieval datasets like MS MARCO [2]. We leverage the generative capabilities of large language models to bridge the gap by synthesizing hypothetical exercises based on the learner ' s input, which are then used to search for relevant exercises. Our approach, which we call mHyER, overcomes three challenges: (1) lack of relevance labels for training, (2) unrestricted learner input content, and (3) low semantic similarity between input and retrieval candidates. mHyER outperforms several strong baselines on two novel benchmarks created from crowdsourced data and publicly available data.	[Xu, Austin] Georgia Inst Technol, Atlanta, GA 30332 USA; [Xu, Austin; Monroe, Will; Bicknell, Klinton] Duolingo, Pittsburgh, PA 15206 USA	University System of Georgia; Georgia Institute of Technology	Xu, A (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.; Xu, A (corresponding author), Duolingo, Pittsburgh, PA 15206 USA.	axu@gatech.edu; monroe@duolingo.com; klinton@duolingo.com			National Science Foundation [IIS-2212182, DMS-2134037]	National Science Foundation(National Science Foundation (NSF))	We thank Ali Malik, Stephen Mayhew, and Mark Davenport for their helpful comments, feedback, and support. AX was partially supported by National Science Foundation grants IIS-2212182 and DMS-2134037.	Abdelrahman G, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P175, DOI 10.1145/3331184.3331195; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Bajaj P, 2018, Arxiv, DOI arXiv:1611.09268; Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863; Chen T, 2020, PR MACH LEARN RES, V119; Cheng QY, 2023, Arxiv, DOI arXiv:2305.01918; Chuang YS, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P4207; CORBETT AT, 1994, USER MODEL USER-ADAP, V4, P253, DOI 10.1007/BF01099821; Cui P, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P10184; Dai Zhuyun, 2022, 11 INT C LEARN REPR; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Gao LY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1762; Gao TY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6894; Geng S, 2019, INT J EDUC TECHNOL H, V16, DOI 10.1186/s41239-019-0147-0; Hadsell R, 2006, IEEE C COMP VIS PATT, P1735; Huang SY, 2022, LECT NOTES COMPUT SC, V13356, P208, DOI 10.1007/978-3-031-11647-6_36; Izacard Gautier, 2022, T MACHINE LEARNING R; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; Kim KJ, 2015, INT J MED EDUC, V6, P213, DOI 10.5116/ijme.565e.0f87; Krashen S., 2005, Anthology series-Seameo regional language centre, V46, P1; Lee K, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6086; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lucieer SM, 2016, MED TEACH, V38, P585, DOI 10.3109/0142159X.2015.1073240; Mandasari B., 2021, Ethical Lingua: Journal of Language Teaching and Literature, V8, P150; Pandey S, 2019, P 12 INT C ED DAT MI; Patall EA, 2008, PSYCHOL BULL, V134, P270, DOI 10.1037/0033-2909.134.2.270; Piech C, 2015, ADV NEUR IN, V28; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Sachan D.S., 2022, P 2022 C EMP METH NA, P3781, DOI DOI 10.18653/V1/2022.EMNLP; Shin DM, 2021, LAK21 CONFERENCE PROCEEDINGS: THE ELEVENTH INTERNATIONAL CONFERENCE ON LEARNING ANALYTICS & KNOWLEDGE, P490, DOI 10.1145/3448139.3448188; Thakur Nandan, 2021, 35 C NEUR INF TRACK; Tong SW, 2020, IEEE DATA MINING, P541, DOI 10.1109/ICDM50108.2020.00063; Wang KX, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P2345; Wang Y., 2022, P 2022 C EMPIRICAL M, P9122; Wenzek G, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P4003; Wu Xing, 2022, P 29 INT C COMPUTATI, P3898; Wu ZY, 2020, KNOWL-BASED SYST, V210, DOI 10.1016/j.knosys.2020.106481; Xu Liangbei, 2020, Dynamic Knowledge Embedding and Tracing; Yu Wenhao, 2022, 11 INT C LEARN REPR; Yu Yue, 2022, P 2022 C EMP METH NA, P1462	40	0	0	3	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1618-8				2024							284	294		10.1145/3636555.3636883	http://dx.doi.org/10.1145/3636555.3636883			11	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Education & Educational Research	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Education & Educational Research	BW6NI		Green Submitted, hybrid			2024-07-03	WOS:001179044200027
C	Shirafuji, A; Oda, Y; Suzuki, J; Morishita, M; Watanobe, Y			IEEE Comp Soc	Shirafuji, Atsushi; Oda, Yusuke; Suzuki, Jun; Morishita, Makoto; Watanobe, Yutaka			Refactoring Programs Using Large Language Models with Few-Shot Examples	PROCEEDINGS OF THE 2023 30TH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, APSEC 2023	Asia-Pacific Software Engineering Conference		English	Proceedings Paper	30th Asia-Pacific Software Engineering Conference (APSEC)	DEC 04-07, 2023	Seoul, SOUTH KOREA			code refactoring; large language models; few-shot prompting; software complexity; programming education	CODE	A less complex and more straightforward program is a crucial factor that enhances its maintainability and makes writing secure and bug-free programs easier. However, due to its heavy workload and the risks of breaking the working programs, programmers are reluctant to do code refactoring, and thus, it also causes the loss of potential learning experiences. To mitigate this, we demonstrate the application of using a large language model (LLM), GPT-3.5, to suggest less complex versions of the user-written Python program, aiming to encourage users to learn how to write better programs. We propose a method to leverage the prompting with few-shot examples of the LLM by selecting the best-suited code refactoring examples for each target programming problem based on the prior evaluation of prompting with the one-shot example. The quantitative evaluation shows that 95.68% of programs can be refactored by generating 10 candidates each, resulting in a 17.35% reduction in the average cyclomatic complexity and a 25.84% decrease in the average number of lines after filtering only generated programs that are semantically correct. Furthermore, the qualitative evaluation shows outstanding capability in code formatting, while unnecessary behaviors such as deleting or translating comments are also observed.	[Shirafuji, Atsushi; Watanobe, Yutaka] Univ Aizu, Aizu Wakamatsu, Fukushima, Japan; [Oda, Yusuke; Suzuki, Jun] Tohoku Univ, Sendai, Miyagi, Japan; [Morishita, Makoto] NTT Commun Sci Labs, Kyoto, Japan	University of Aizu; Tohoku University; Nippon Telegraph & Telephone Corporation	Shirafuji, A (corresponding author), Univ Aizu, Aizu Wakamatsu, Fukushima, Japan.	m5261161@u-aizu.ac.jp; yusuke.oda.c1@tohoku.ac.jp; jun.suzuki@tohoku.ac.jp; makoto.morishita@ntt.com; yutaka@u-aizu.ac.jp			Japan Society for the Promotion of Science (JSPS) KAKENHI [JP23H03508]	Japan Society for the Promotion of Science (JSPS) KAKENHI(Ministry of Education, Culture, Sports, Science and Technology, Japan (MEXT)Japan Society for the Promotion of ScienceGrants-in-Aid for Scientific Research (KAKENHI))	This work was supported by the Japan Society for the Promotion of Science (JSPS) KAKENHI Grant Number JP23H03508.	Adler F, 2021, IEEE INT WORK C SO, P120, DOI 10.1109/SCAM52516.2021.00023; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chakraborty S, 2022, IEEE T SOFTWARE ENG, V48, P1385, DOI 10.1109/TSE.2020.3020502; Chen M., 2021, ARXIV; Chowdhery A., 2022, arXiv; Christopoulou F., 2022, arXiv; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Foster SR, 2012, PROC INT CONF SOFTW, P222, DOI 10.1109/ICSE.2012.6227191; Fowler M., 1999, AW OBJ TECHNOL S; Fried D., 2023, P 11 INT C LEARN REP; Harman M, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1106; Joshi H., 2023, P AAAI C ARTIFICIAL, V37, P5131; Kamiya T, 2002, IEEE T SOFTWARE ENG, V28, P654, DOI 10.1109/TSE.2002.1019480; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Li J, 2023, ACM T SOFTW ENG METH, V32, DOI 10.1145/3597207; Li R., 2023, arXiv; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Luo Z., 2023, arXiv; Madaan A., 2023, arXiv; Matsumoto T, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11114755; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837; Miltner A., 2019, Proc. ACM Program. Lang., V3; Murphy-Hill E, 2012, IEEE T SOFTWARE ENG, V38, P5, DOI 10.1109/TSE.2011.41; Nijkamp E., 2023, P 11 INT C LEARN REP; OpenAI, 2023, ArXiv; Ouyang L., 2022, Advances in Neural Information Processing Systems; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Prenner JA, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P69, DOI 10.1145/3524459.3527351; Puri R., 2021, P 35 C NEUR INF PROC; Rahman MM, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13020247; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Seng O, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1909; Shirafuji A., 2023, arXiv; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Touvron H., 2023, arXiv; Tsantalis N, 2017, PROC INT CONF SOFTW, P60, DOI 10.1109/ICSE.2017.14; Tsantalis N, 2015, IEEE T SOFTWARE ENG, V41, P1055, DOI 10.1109/TSE.2015.2448531; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Watanobe Y., 2004, Aizu Online Judge; Watanobe Y, 2022, INT J SOFTW ENG KNOW, V32, P917, DOI 10.1142/S0218194022500346; White J., 2023, arXiv; Wu M., 2021, arXiv; Xu FF, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3487569; Zhang Jiahang, 2022, ARXIV; Zhang JY, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556955; Zheng Q., 2023, arXiv	47	0	0	0	0	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1530-1362		979-8-3503-4417-2	ASIA PAC SOFWR ENG			2023							151	160		10.1109/APSEC60848.2023.00025	http://dx.doi.org/10.1109/APSEC60848.2023.00025			10	Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW8UA		Green Submitted			2024-07-03	WOS:001207000500016
J	Liu, PF; Qian, L; Zhao, XW; Tao, B				Liu, Peifeng; Qian, Lu; Zhao, Xingwei; Tao, Bo			Joint Knowledge Graph and Large Language Model for Fault Diagnosis and Its Application in Aviation Assembly	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS			English	Article						Data-driven; fault localization; intelligent fault diagnosis; knowledge graph (KG); large language model (LLM)		In complex assembly industry settings, fault localization involves rapidly and accurately identifying the source of a fault and obtaining a troubleshooting solution based on fault symptoms. This study proposes a knowledge-enhanced joint model that incorporates aviation assembly knowledge graph (KG) embedding into large language models (LLMs). This model utilizes graph-structured Big Data within KGs to conduct prefix-tuning of the LLMs. The KGs for prefix-tuning enable an online reconfiguration of the LLMs, which avoids a massive computational load. Through the subgraph embedding learning process, the specialized knowledge of the joint model within the aviation assembly domain, especially in fault localization, is strengthened. In the context of aviation assembly functional testing, the joint model can generate knowledge subgraphs, fuse knowledge through retrieval augmentation, and ultimately provide knowledge-based reasoning responses. In practical industrial scenario experiments, the joint enhancement model demonstrates an accuracy of 98.5% for fault diagnosis and troubleshooting schemes.	[Liu, Peifeng; Zhao, Xingwei; Tao, Bo] Huazhong Univ Sci & Technol, Dept Mech, State Key Lab Intelligent Mfg Equipment & Technol, Wuhan 430074, Peoples R China; [Qian, Lu] Wuhan Univ Technol, Sch Transportat & Logist Engn, Wuhan 430063, Peoples R China	Huazhong University of Science & Technology; Wuhan University of Technology	Zhao, XW (corresponding author), Huazhong Univ Sci & Technol, Dept Mech, State Key Lab Intelligent Mfg Equipment & Technol, Wuhan 430074, Peoples R China.		Bo, Tao/AFE-7417-2022		National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Camastra F., 2008, MARKOVIAN MODELS SEQ, P265, DOI DOI 10.1007/978-1-84800-007-0_10; Du ZX, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P320; Fabregat A, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005968; Feng J, 2021, IEEE T IND ELECTRON, V68, P3454, DOI 10.1109/TIE.2020.2982085; Gao Z., 2015, IEEE T IND ELECTRON, V62, P3768, DOI DOI 10.1109/TIE.2015.2419013; Guu K., 2020, ARXIV; Houlsby N, 2019, PR MACH LEARN RES, V97; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Ji SX, 2022, IEEE T NEUR NET LEAR, V33, P494, DOI 10.1109/TNNLS.2021.3070843; Jing X, 2024, IEEE T IND ELECTRON, V71, P3064, DOI 10.1109/TIE.2023.3269463; Li XLS, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P4582; Li X, 2023, NEUROCOMPUTING, V549, DOI 10.1016/j.neucom.2023.126441; Liu K, 2020, SCI CHINA TECHNOL SC, V63, P1971, DOI 10.1007/s11431-020-1673-6; Liu PF, 2023, SCI CHINA TECHNOL SC, DOI 10.1007/s11431-023-2506-4; Liu PF, 2023, IEEE ACCESS, V11, P26483, DOI 10.1109/ACCESS.2023.3254132; Liu X, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2, P61; Luo H, 2020, IEEE T CONTR SYST T, V28, P2641, DOI 10.1109/TCST.2019.2942799; Luo H, 2020, IEEE T IND ELECTRON, V67, P521, DOI 10.1109/TIE.2019.2892705; Niu Feng, 2011, Advances in neural information processing systems, P693; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pan L., 2024, IEEE T KNOWL DA 0110, DOI [10.1109/TKDE.2024.3352100.[13]D., DOI 10.1109/TKDE.2024.3352100.[13]D]; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Shi D, 2019, IEEE T IND ELECTRON, V66, P9808, DOI 10.1109/TIE.2019.2893839; Sun Y., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.02137; Sun YQ, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5049; Tao B, 2019, SCI CHINA TECHNOL SC, V62, P1388, DOI 10.1007/s11431-019-9510-1; Vaswani A, 2017, ADV NEUR IN, V30; Vrandecic D, 2014, COMMUN ACM, V57, P78, DOI 10.1145/2629489; Zhang ZY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1441; Zhu Y., 2023, ARXIV	30	0	0	113	113	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1551-3203	1941-0050		IEEE T IND INFORM	IEEE Trans. Ind. Inform.	JUN	2024	20	6					8160	8169		10.1109/TII.2024.3366977	http://dx.doi.org/10.1109/TII.2024.3366977		MAR 2024	10	Automation & Control Systems; Computer Science, Interdisciplinary Applications; Engineering, Industrial	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science; Engineering	TK4L6					2024-07-03	WOS:001185653000001
C	Tsigkanos, C; Rani, P; Müller, S; Kehrer, T		Zhang, T; Xia, X; Novielli, N		Tsigkanos, Christos; Rani, Pooja; Mueller, Sebastian; Kehrer, Timo			Large Language Models: The Next Frontier for Variable Discovery within Metamorphic Testing	2023 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING, SANER	IEEE International Conference on Software Analysis Evolution and Reengineering		English	Proceedings Paper	30th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)	MAR 21-24, 2023	Macao, PEOPLES R CHINA	IEEE, IEEE Comp Soc, Macau Univ Sci & Technol		Metamorphic Testing; Large Language Models; Natural Language Processing; Scientific Software		Metamorphic testing involves reasoning on necessary properties that a program under test should exhibit regarding multiple input and output variables. A general approach consists of extracting metamorphic relations from auxiliary artifacts such as user manuals or documentation, a strategy particularly fitting to testing scientific software. However, such software typically has large input-output spaces, and the fundamental prerequisite extracting variables of interest is an arduous and non-scalable process when performed manually. To this end, we devise a workflow around an autoregressive transformerbased Large Language Model (LLM) towards the extraction of variables from user manuals of scientific software. Our end-toend approach, besides a prompt specification consisting of fewshot examples by a human user, is fully automated, in contrast to current practice requiring human intervention. We showcase our LLM workflow over a real case, and compare variables extracted to ground truth manually labelled by experts. Our preliminary results show that our LLM-based workflow achieves an accuracy of 0.87, while successfully deriving 61.8% of variables as partial matches and 34.7% as exact matches.	[Tsigkanos, Christos; Kehrer, Timo] Univ Bern, Bern, Switzerland; [Rani, Pooja] Univ Zurich, Zurich, Switzerland; [Mueller, Sebastian] Humboldt Univ, Berlin, Germany	University of Bern; University of Zurich; Humboldt University of Berlin	Tsigkanos, C (corresponding author), Univ Bern, Bern, Switzerland.		Kehrer, Timo/AAI-6563-2020	Kehrer, Timo/0000-0002-2582-5557; Muller, Sebastian/0000-0002-3057-1125; , Pooja Rani/0000-0001-5127-4042	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) [414984028 - SFB 1404 FONDA]	Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)(German Research Foundation (DFG))	Funded in part by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) - Project-ID 414984028 - SFB 1404 FONDA.	Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Balog M, 2017, Arxiv, DOI arXiv:1611.01989; Barr ET, 2015, IEEE T SOFTWARE ENG, V41, P507, DOI 10.1109/TSE.2014.2372785; Black S., 2022, PREPRINT; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carlson A, 2007, ICMLA 2007: SIXTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P166, DOI 10.1109/ICMLA.2007.50; Carver J.C., 2016, Software Engineering for Science; Chen M., 2021, arXiv; Chen TY, 2020, Arxiv, DOI arXiv:2002.12543; Colavito G, 2022, 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING (NLBSE 2022), P29, DOI 10.1145/3528588.3528659; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Han CC, 2021, Arxiv, DOI arXiv:2107.12262; Hardin B, 2018, 2018 IEEE/ACM 3RD INTERNATIONAL WORKSHOP ON METAMORPHIC TESTING (MET 2018), P14, DOI 10.1145/3193977.3193985; Hiremath DJ, 2021, 2021 IEEE/ACM 6TH INTERNATIONAL WORKSHOP ON METAMORPHIC TESTING (MET 2021), P42, DOI 10.1109/MET52542.2021.00014; Howard J, 2018, Arxiv, DOI [arXiv:1801.06146, DOI 10.48550/ARXIV.1801.06146]; Jiang X, 2018, Arxiv, DOI [arXiv:1806.00852, DOI 10.48550/ARXIV.1806.00852]; Kanewala U, 2016, SOFTW TEST VERIF REL, V26, P245, DOI 10.1002/stvr.1594; Kanewala U, 2013, PROC INT SYMP SOFTW, P1, DOI 10.1109/ISSRE.2013.6698899; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Muller S., 2022, INT WORKSHOP SOFTWAR; Peng ZD, 2022, LECT NOTES COMPUT SC, P503, DOI 10.1007/978-3-031-08760-8_42; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ren Xiang, 2016, P 2016 C EMPIRICAL M, P1369, DOI DOI 10.18653/V1/D16-1144; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Rossman L. A., 2010, STORM WATER MANAGEME; Santos EA, 2018, 2018 25TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2018), P311, DOI 10.1109/SANER.2018.8330219; Segura S, 2016, IEEE T SOFTWARE ENG, V42, P805, DOI 10.1109/TSE.2016.2532875; Su FH, 2015, 10TH INTERNATIONAL WORKSHOP ON AUTOMATION OF SOFTWARE TEST AST 2015, P55, DOI 10.1109/AST.2015.19; Vu A.D., 2022, 37 IEEEACM INT C AUT; Wang B., 2022, GPT J 6B 6 BILLION P; Wang B., MESH TRANSFORMER JAX; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Zedong Peng, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12747), P375, DOI 10.1007/978-3-030-77980-1_29	33	1	1	2	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1534-5351		978-1-6654-5278-6	Soft Anal Evol Reeng			2023							678	682		10.1109/SANER56733.2023.00070	http://dx.doi.org/10.1109/SANER56733.2023.00070			5	Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV2NR					2024-07-03	WOS:001008282200060
C	Linzbach, S; Tressel, T; Kallmeyer, L; Dietze, S; Jabeen, H			ACM	Linzbach, Stephan; Tressel, Tim; Kallmeyer, Laura; Dietze, Stefan; Jabeen, Hajira			Decoding Prompt Syntax: Analysing its Impact on Knowledge Retrieval in Large Language Models	COMPANION OF THE WORLD WIDE WEB CONFERENCE, WWW 2023			English	Proceedings Paper	32nd World Wide Web Conference (WWW)	APR 30-MAY 04, 2023	Austin, TX	Assoc Comp Machinery, Amazon Science, Baidu, Megagon Labs, Zhipu AI, Google, Booking Com, eBay, Bloomberg Engn, Netflix, ACM SIGWEB, Univ Texas Austin, Sch Informat, Data World, Inst Fdn Machine Learning		Large Language models; BERT; Syntax aware prompt; Knowledge retrieval		Large Language Models (LLMs), with their advanced architectures and training on massive language datasets, contain unexplored knowledge. One method to infer this knowledge is through the use of cloze-style prompts. Typically, these prompts are manually designed because the phrasing of these prompts impacts the knowledge retrieval performance, even if the LLM encodes the desired information. In this paper, we study the impact of prompt syntax on the knowledge retrieval capacity of LLMs. We use a template-based approach to paraphrase simple prompts into prompts with a more complex grammatical structure. We then analyse the LLM performance for these structurally different but semantically equivalent prompts. Our study reveals that simple prompts work better than complex forms of sentences. The performance across the syntactical variations for simple relations (1:1) remains best, with a marginal decrease across different typologies. These results reinforce that simple prompt structures are more effective for knowledge retrieval in LLMs and motivate future research into the impact of prompt syntax on various tasks.	[Linzbach, Stephan; Jabeen, Hajira] GESIS Leibniz Inst Social Sci, Mannheim, Germany; [Tressel, Tim; Kallmeyer, Laura] Heinrich Heine Univ, Dusseldorf, Germany; [Dietze, Stefan] Heinrich Heine Univ, GESIS Leibniz Inst Social Sci, Dusseldorf, Germany	Leibniz Institut fur Sozialwissenschaften (GESIS); Heinrich Heine University Dusseldorf; Heinrich Heine University Dusseldorf; Leibniz Institut fur Sozialwissenschaften (GESIS)	Linzbach, S (corresponding author), GESIS Leibniz Inst Social Sci, Mannheim, Germany.	Stephan.Linzbach@gesis.org; Tim.Tressel@hhu.de; Laura.Kallmeyer@hhu.de; Stefan.Dietze@gesis.org; Hajira.Jabeen@gesis.org		Linzbach, Stephan/0009-0009-6955-2368; Dietze, Stefan/0009-0001-4364-9243; Jabeen, Hajira/0000-0003-1476-2121				Clark K, 2019, Arxiv, DOI arXiv:1906.04341; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Peters ME, 2019, Arxiv, DOI [arXiv:1909.04164, 10.18653/v1/D19-1005, DOI 10.18653/V1/D19-1005]; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P160, DOI 10.1162/tacl_a_00359; Elsahar H, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3448; F‚vry T, 2020, Arxiv, DOI arXiv:2004.07202; Gao Daniel, 2022, arXiv; Goldberg Y., 2019, PREPRINT, DOI DOI 10.48550/ARXIV.1901.05287; Heinzerling B, 2021, Arxiv, DOI arXiv:2008.09036; Hu J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1725; Huddleston Rodney., 1984, Introduction to the grammar of English; Jawahar G, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3651; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Kalo Jan-Christoph, 2022, P C AUT KNOWL BAS CO; Kassner N, 2020, Arxiv, DOI arXiv:2006.10413; Kawintiranon K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4725; Ke P, 2020, Arxiv, DOI arXiv:1911.02493; Lauscher A, 2020, Arxiv, DOI arXiv:1909.02339; Levine Y, 2020, Arxiv, DOI arXiv:1908.05646; Liu X., 2019, ARXIV; Petroni F., 2020, arXiv; Petroni F, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2463; Roberts A., 2020, arXiv; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Schutze Hinrich, 2020, P 24 C COMP NAT LANG; Strubell E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P5027; Sun Y, 2019, Arxiv, DOI [arXiv:1904.09223, 10.48550/arXiv.1904.09223]; Sundararaman Dhanasekar, 2021, CEUR Workshop Proceedings, V3052; Tenney I, 2019, Arxiv, DOI arXiv:1905.06316; Tian H, 2020, Arxiv, DOI arXiv:2005.05635; Wang RZ, 2020, Arxiv, DOI arXiv:2002.01808; Wang XZ, 2021, T ASSOC COMPUT LING, V9, P176, DOI 10.1162/tacl_a_00360; Zhen CQ, 2022, Arxiv, DOI arXiv:2212.13428; Zhong Z, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5017	34	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9416-1				2023							1145	1149		10.1145/3543873.3587655	http://dx.doi.org/10.1145/3543873.3587655			5	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2SF					2024-07-03	WOS:001124276300213
C	Fan, A; Gokkaya, B; Harman, M; Lyubarskiy, M; Sengupta, S; Yoo, S; Zhang, JM			IEEE	Fan, Angela; Gokkaya, Beliz; Harman, Mark; Lyubarskiy, Mitya; Sengupta, Shubho; Yoo, Shin; Zhang, Jie M.			Large Language Models for Software Engineering: Survey and Open Problems	2023 IEEE/ACM INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: FUTURE OF SOFTWARE ENGINEERING, ICSE-FOSE			English	Proceedings Paper	IEEE/ACM International Conference on Software Engineering - Future of Software Engineering (ICSE-FoSE)	MAY 14-20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Automated Program Repair; Documentation generation; Generative AI; Genetic Improvement; Human-Computer Interaction; Large Language Models; Refactoring; Requirements engineering; Search Based Software Engineering (SBSE); Software Analytics; Software Engineering Education; Software Processes; Software Maintenance and Evolution; Software Testing	SEARCH; SYSTEM	This paper provides a survey of the emerging area of Large Language Models (LLMs) for Software Engineering (SE). It also sets out open research challenges for the application of LLMs to technical problems faced by software engineers. LLMs' emergent properties bring novelty and creativity with applications right across the spectrum of Software Engineering activities including coding, design, requirements, repair, refactoring, performance improvement, documentation and analytics. However, these very same emergent properties also pose significant technical challenges; we need techniques that can reliably weed out incorrect solutions, such as hallucinations. Our survey reveals the pivotal role that hybrid techniques (traditional SE plus LLMs) have to play in the development and deployment of reliable, efficient and effective LLM-based SE.	[Fan, Angela] Meta Platforms Inc, Generat AI Team, New York, NY 10003 USA; [Gokkaya, Beliz] Meta Platforms Inc, PyTorch Team, Menlo Pk, CA USA; [Harman, Mark] Meta Platforms Inc, Instagram Prod Fdn, London, England; [Lyubarskiy, Mitya] Meta Platforms Inc, Developer Infrastruct, London, England; [Sengupta, Shubho] Meta Platforms Inc, FAIR, Menlo Pk, CA USA; [Yoo, Shin] Korea Adv Inst Sci & Technol, Sch Comp, Daejeon, South Korea; [Zhang, Jie M.] Kings Coll London, Dept Informat, London, England	Korea Advanced Institute of Science & Technology (KAIST); University of London; King's College London	Fan, A (corresponding author), Meta Platforms Inc, Generat AI Team, New York, NY 10003 USA.							Abou Assi R, 2019, SOFTW TEST VERIF REL, V29, DOI 10.1002/stvr.1696; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmad A., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2302.14600; Ahmed T, 2024, Arxiv, DOI arXiv:2304.06815; Ahmed T, 2023, Arxiv, DOI arXiv:2301.03797; AHO AV, 1986, COMPILERS PRINCIPLES; Akli A, 2023, INT WORKSH AUTOMAT, P140, DOI 10.1109/AST58925.2023.00018; Anand S, 2013, J SYST SOFTWARE, V86, P1978, DOI 10.1016/j.jss.2013.02.061; Androutsopoulos K, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P573, DOI 10.1145/2568225.2568314; [Anonymous], 2008, 2008 GENETIC EVOLUTI; [Anonymous], 2024, 46 INT C SOFTWARE EN; [Anonymous], 1949, C HIGH SPEED AUT CAL; Arcuri A, 2011, 2011 33RD INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1, DOI 10.1145/1985793.1985795; Bareiss P, 2022, Arxiv, DOI [arXiv:2206.01335, DOI 10.48550/ARXIV.2206.01335]; Barr ET, 2015, IEEE T SOFTWARE ENG, V41, P507, DOI 10.1109/TSE.2014.2372785; Barr ET, 2014, 22ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (FSE 2014), P306, DOI 10.1145/2635868.2635898; Berabi B, 2021, PR MACH LEARN RES, V139; Bertolino A, 2007, FOSE 2007: FUTURE OF SOFTWARE ENGINEERING, P85, DOI 10.1109/FOSE.2007.25; Bird Christian, 2022, ACM Queue, P35, DOI 10.1145/3582083; Bojarczuk K., 2021, ACMIEEE INT S EMPIRI; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brownlee A. E. I., 2023, SSBSE 2023: Challenge Track; Bruce BR, 2019, IEEE T SOFTWARE ENG, V45, P1150, DOI 10.1109/TSE.2018.2827066; Bruch M, 2009, 7TH JOINT MEETING OF THE EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND THE ACM SIGSOFT SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P213, DOI 10.1145/1595696.1595728; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; BURSTALL RM, 1977, J ACM, V24, P44, DOI 10.1145/321992.321996; Cadar C, 2013, COMMUN ACM, V56, P82, DOI 10.1145/2408776.2408795; Cantino Andrew, 2021, Prompt engineering tips and tricks with GPT-3; Cao JL, 2023, Arxiv, DOI [arXiv:2304.08191, 10.48550/arXiv.2304.08191, 10.48550/ARXIV.2304.08191]; Charalambous Y, 2023, Arxiv, DOI arXiv:2305.14752; Chekam TT, 2017, PROC INT CONF SOFTW, P597, DOI 10.1109/ICSE.2017.61; Chemnitz L, 2023, Arxiv, DOI arXiv:2305.11619; Chen B., 2023, CODET: Code Generation With Generated Tests; Chen M., 2021, arXiv; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Chen YH, 2024, Arxiv, DOI arXiv:2305.04764; Chen ZM, 2023, Arxiv, DOI arXiv:2309.14846; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cleland-Huang J., 2012, Software and systems traceability, V2; Cornes C., 1995, Technical Report RT- 0177; Cummins C., 2023, Large language models for compiler optimization; DARLINGTON J, 1976, ACTA INFORM, V6, P41, DOI 10.1007/BF00263742; Deng YL, 2023, Arxiv, DOI arXiv:2304.02014; Deng YL, 2023, Arxiv, DOI arXiv:2212.14834; Denny P, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P1136, DOI 10.1145/3545945.3569823; Dinh T, 2023, Arxiv, DOI arXiv:2306.03438; Doderlein JB, 2022, Arxiv, DOI arXiv:2210.14699; Dong YH, 2024, Arxiv, DOI arXiv:2304.07590; Easterbrook S., Proceedings of the Twenty-second IEEE/ACM International Conference on Automated Software Engineering, ser. ASE '07. New York, NY, USA: ACM, P574, DOI [10.1145/1321631.1321749, DOI 10.1145/1321631.1321749]; Fakhoury S, 2023, Arxiv, DOI arXiv:2304.03816; Fatima S, 2024, Arxiv, DOI arXiv:2307.00012; Fatima S, 2023, IEEE T SOFTWARE ENG, V49, P1912, DOI 10.1109/TSE.2022.3201209; Feldt R, 2023, Arxiv, DOI arXiv:2306.05152; Feng SD, 2024, Arxiv, DOI arXiv:2306.01987; Feng YH, 2023, P INT COMP SOFTW APP, P876, DOI 10.1109/COMPSAC57700.2023.00117; freethink, GitHub CEO says Copilot will write 80% of code sooner than later; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gabel M, 2010, 18 ACM SIGSOFT INT S, P147; Gallagher K. B., 1992, Conference on Software Maintenance 1992 (Cat.No.92CH3206-0), P236, DOI 10.1109/ICSM.1992.242538; Gamma E., 1995, DESIGN PATTERNS ELEM; Garg A, 2023, Arxiv, DOI arXiv:2303.04247; Garg S, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P948, DOI 10.1145/3540250.3549096; Garg S, 2024, Arxiv, DOI [arXiv:2306.17077, DOI 10.48550/ARXIV.2306.17077]; Geng MY, 2023, Arxiv, DOI arXiv:2304.11384; Goyal T., 2022, arXiv, DOI 10.48550/arXiv.2209.12356; Gulwani S, 2017, FOUND TRENDS PROGRAM, V4, P1, DOI 10.1561/2500000010; Gunasekar S, 2023, Arxiv, DOI arXiv:2306.11644; Hajipour H, 2023, Arxiv, DOI arXiv:2302.04012; Halstead M. H., 1977, Elements of Software Science (Operating and programming systems series; Hamilton MH, 2008, COMPUTER, V41, P34, DOI 10.1109/MC.2008.541; Harman M, 2001, INFORM SOFTWARE TECH, V43, P833, DOI 10.1016/S0950-5849(01)00189-6; Harman M., 2015, 8 IEEE INT C SOFTWAR; Harman M, 2022, INTERNATIONAL WORKSHOP ON AUTOMATED PROGRAM REPAIR (APR 2022), P1, DOI 10.1145/3524459.3527353; Harman M, 2018, IEEE INT WORK C SO, P1, DOI 10.1109/SCAM.2018.00009; Harman M, 2014, 9TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS (SEAMS 2014), P1, DOI 10.1145/2593929.2600116; Harman M, 2012, ACM COMPUT SURV, V45, DOI 10.1145/2379776.2379787; Harman M, 2012, IEEE INT CONF AUTOM, P1, DOI 10.1145/2351676.2351678; Harman M, 2012, LECT NOTES COMPUT SC, V7007, P1; Hassan AE, 2008, 2008 FRONTIERS OF SOFTWARE MAINTENANCE, P48, DOI 10.1109/FOSM.2008.4659248; He JX, 2023, Arxiv, DOI arXiv:2302.05319; Heaven WD, 2023, MIT Technology Review; Henderson P, 2020, J MACH LEARN RES, V21; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Hort M, 2023, Arxiv, DOI arXiv:2307.02443; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Hu EJ, 2021, Arxiv, DOI arXiv:2106.09685; Hu J, 2023, Arxiv, DOI arXiv:2306.06782; Huang K, 2023, Arxiv, DOI arXiv:2303.18184; Huang Q., 2023, 2023 IEEEACM 45 INT, P1; Manes VJM, 2019, Arxiv, DOI arXiv:1812.00140; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Jalil S, 2023, Arxiv, DOI arXiv:2302.03287; Jia Y, 2011, IEEE T SOFTWARE ENG, V37, P649, DOI 10.1109/TSE.2010.62; Jiang E., 2022, CHI C HUMAN FACTORS, P1; Jiang N, 2023, Arxiv, DOI arXiv:2302.05020; Jiang SY, 2023, Arxiv, DOI arXiv:2306.02907; Jiang X, 2024, Arxiv, DOI arXiv:2303.06689; Jimenez CE, 2024, Arxiv, DOI arXiv:2310.06770; Jin M, 2023, Arxiv, DOI arXiv:2303.07263; Joshi H., 2023, P AAAI C ARTIFICIAL, V37, P5131; Kang S, 2023, Arxiv, DOI arXiv:2308.05487; Kang S, 2023, PROC INT CONF SOFTW, P2312, DOI 10.1109/ICSE48619.2023.00194; Kang S, 2023, Arxiv, DOI arXiv:2304.09386; Kang SM, 2023, Arxiv, DOI arXiv:2304.02195; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kashefi A, 2023, Arxiv, DOI arXiv:2303.12093; Kechagia M, 2021, IEEE T SOFTWARE ENG, V48, P2658, DOI 10.1109/TSE.2021.3067156; Khanfir A., 2023, arXiv; Kheiri K, 2023, Arxiv, DOI [arXiv:2307.10234, DOI 10.48550/ARXIV.2307.10234]; Khoury R, 2023, Arxiv, DOI arXiv:2304.09655; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; KRUEGER CW, 1992, COMPUT SURV, V24, P131, DOI 10.1145/130844.130856; Langdon WB, 2015, IEEE T EVOLUT COMPUT, V19, P118, DOI 10.1109/TEVC.2013.2281544; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Lebeuf C, 2018, IEEE SOFTWARE, V35, P18, DOI 10.1109/MS.2017.4541027; Lehman M., 1987, ACM SIGSOFT Software Engineering Notes, V12, P52; Lemieux C, 2023, PROC INT CONF SOFTW, P919, DOI 10.1109/ICSE48619.2023.00085; Li D, 2014, 36TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2014), P527, DOI 10.11455/2568225.2568321; Li J, 2023, Arxiv, DOI [arXiv:2305.06599, DOI 10.48550/ARXIV.2305.06599, 10.48550/ARXIV.2305.06599]; Li J, 2023, Arxiv, DOI [arXiv:2303.17780, 10.48550/ARXIV.2303.17780, DOI 10.48550/ARXIV.2303.17780]; Li J, 2023, Arxiv, DOI arXiv:2302.06144; Li TO, 2023, Arxiv, DOI arXiv:2304.11686; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liu Aiwei, 2023, arXiv; Liu CX, 2023, Arxiv, DOI arXiv:2305.05383; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu K., 2023, ACM SIGSOFT INT S SO; LOVELACE Ada., 1843, Sketch of the analytical engine invented by Charles Babbage; Luitel D, 2023, Arxiv, DOI arXiv:2308.03784; Luo XC, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3560417; Ma W, 2024, Arxiv, DOI arXiv:2305.12138; MacNeil S, 2023, PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023, P931, DOI 10.1145/3545945.3569785; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; Marginean A, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P269, DOI 10.1109/ICSE-SEIP.2019.00039; Mariani T, 2017, INFORM SOFTWARE TECH, V83, P14, DOI 10.1016/j.infsof.2016.11.009; Martin W, 2017, IEEE T SOFTWARE ENG, V43, P817, DOI 10.1109/TSE.2016.2630689; Mashhadi E, 2023, Method-level bug severity prediction using source code metrics and llms; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837; Meckler L., 2022, The Washington postDecember; Menzies T, 2018, IEEE SOFTWARE, V35, P64, DOI 10.1109/MS.2018.290111035; Menzies T, 2013, IEEE SOFTWARE, V30, P31, DOI 10.1109/MS.2013.86; Mohammadkhani AH, 2023, Arxiv, DOI arXiv:2211.12821; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Moradi Dakhel A., 2023, arXiv; Murali V, 2024, Arxiv, DOI arXiv:2305.12050; Nakano R., 2021, arXiv, DOI 10.48550/ARXIV.2112.09332; Neill CJ, 2003, IEEE SOFTWARE, V20, P40, DOI 10.1109/MS.2003.1241365; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nie PY, 2023, Arxiv, DOI arXiv:2302.10166; Nijkamp E, 2023, Arxiv, DOI arXiv:2305.02309; Nijkamp Erik, 2023, ICLR; Noever D., 2023, arXiv; Ostrand TJ., 1991, P S TEST AN VER, P74; Ouyang SY, 2023, Arxiv, DOI arXiv:2308.02828; Pacheco Carlos, 2007, OOPSLA 07 COMPANION, P815, DOI [10.1145/1297846.1297902, DOI 10.1145/1297846.1297902]; Pan RQ, 2023, Arxiv, DOI arXiv:2304.01397; Papadakis M, 2019, ADV COMPUT, V112, P275, DOI 10.1016/bs.adcom.2018.03.015; Partsch H., 1984, The CIP Transformation System, P305; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Peng Sida, 2023, arXiv, DOI DOI 10.48550/ARXIV.2302.06590; Perkins JH, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P87; Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219; Poldrack RA, 2023, Arxiv, DOI [arXiv:2304.13187, DOI 10.48550/ARXIV.2304.13187, 10.48550/arXiv.2304.13187]; Polino A, 2018, Arxiv, DOI arXiv:1802.05668; Pressman R.S., 1992, Software Engineering: A Practitioner's Approach, Vthird; Inala JP, 2022, Arxiv, DOI arXiv:2206.03865; Risse N, 2024, Arxiv, DOI arXiv:2306.17193; Ross Steven I., 2023, IUI '23: Proceedings of the 28th International Conference on Intelligent User Interfaces, P491, DOI 10.1145/3581641.3584037; Roziere B, 2024, Arxiv, DOI arXiv:2308.12950; RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0; Santelices Raul, 2008, 2008 23rd IEEE/ACM International Conference on Automated Software Engineering, P218, DOI 10.1109/ASE.2008.32; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Savelka J, 2023, Arxiv, DOI [arXiv:2303.09325, DOI 10.48550/ARXIV.2303.09325]; Savelka J, 2023, Arxiv, DOI [arXiv:2303.08033, DOI 10.48550/ARXIV.2303.08033]; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Shaham U, 2022, Arxiv, DOI arXiv:2201.03533; Shin J, 2024, Arxiv, DOI [arXiv:2308.08033, DOI 10.48550/ARXIV.2308.08033]; Shin J, 2023, Arxiv, DOI arXiv:2310.10508; Shin J, 2023, Arxiv, DOI arXiv:2310.07856; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Shypula A, 2024, Arxiv, DOI arXiv:2302.07867; Siddiq ML, 2024, Arxiv, DOI arXiv:2305.00418; Sobania D., 2023, ser. LNCS; Spanoudakis G, 2005, HANDBOOK OF SOFTWARE ENGINEERING AND KNOWLEDGE ENGINEERING, VOL 3: RECENT ADVANCES, P395, DOI 10.1142/9789812775245_0014; Sun J, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P212, DOI 10.1145/3490099.3511119; Sun W., 2023, arXiv; Sun ZY, 2022, PROC INT CONF SOFTW, P1181, DOI 10.1145/3510003.3510206; Sun ZY, 2020, PROC INT CONF SOFTW, P974, DOI 10.1145/3377811.3380420; Tang Y., 2023, arXiv; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Treude C., 2023, arXiv; Tufano M, 2019, Arxiv, DOI arXiv:1812.08693; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wang JJ, 2024, Arxiv, DOI [arXiv:2307.07221, 10.48550/arXiv.2307.07221]; Wang X., 2023, Self-consistency improves chain of thought reasoning in language models; Ward M., 1989, INT C SOFTWARE MAINT, P307; Wei Y., 2023, FSE 2023; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; Wu F, 2015, GECCO'15: PROCEEDINGS OF THE 2015 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1375, DOI 10.1145/2739480.2754648; Wu YH, 2023, Arxiv, DOI arXiv:2310.16253; Wu YH, 2023, Arxiv, DOI arXiv:2308.15276; Xia C. S., 2023, ASE 2023; Xia C.S., 2023, arXiv; Xia CS, 2024, Arxiv, DOI arXiv:2308.04748; Xia CS, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P959, DOI 10.1145/3540250.3549101; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xia Chunqiu Steven, 2022, arXiv; Xie QQ, 2023, Arxiv, DOI arXiv:2304.08763; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yan M, 2023, Arxiv, DOI arXiv:2308.13319; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Yetistiren B, 2023, Arxiv, DOI arXiv:2304.10778; Yoo S, 2012, SOFTW TEST VERIF REL, V22, P171, DOI 10.1002/stvr.435; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zakeri-Nasrabadi M, 2023, J SYST SOFTWARE, V204, DOI 10.1016/j.jss.2023.111796; Zhang JZ, 2023, Arxiv, DOI arXiv:2304.12562; Zhang KC, 2023, Arxiv, DOI arXiv:2305.04032; Zhang KC, 2023, Arxiv, DOI arXiv:2305.04087; Zhang S, 2023, Arxiv, DOI [arXiv:2303.05510, 10.48550/arXiv.2303.05510]; Zhang Y, 2008, LECT NOTES COMPUT SC, V5025, P88, DOI 10.1007/978-3-540-69062-7_8; Zhao JY, 2023, Arxiv, DOI arXiv:2305.13592; Zhao S., Github Copilot now has a better AI model and new capabilities; Zhou W, 2022, 2022 ACM/IEEE 44TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2022), P161, DOI [10.1145/3510457.3513061, 10.1109/ICSE-SEIP55303.2022.9793983]	231	0	0	14	14	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2496-9				2023							31	53		10.1109/ICSE-FoSE59343.2023.00008	http://dx.doi.org/10.1109/ICSE-FoSE59343.2023.00008			23	Computer Science, Artificial Intelligence; Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6SE		Green Submitted			2024-07-03	WOS:001181095900004
J	Grudin, J				Grudin, Jonathan L.			ChatGPT and Chat History: Challenges for the New Wave	COMPUTER			English	Article								Understanding conversational agents based on large language models can benefit from examining how earlier generations of conversational agents engaged with people and explored commercial opportunities.	[Grudin, Jonathan L.] Univ Washington, Sch Informat, Seattle, WA 98195 USA	University of Washington; University of Washington Seattle	Grudin, J (corresponding author), Univ Washington, Sch Informat, Seattle, WA 98195 USA.	grudin@uw.edu		Grudin, Jonathan/0000-0002-8433-2998					0	4	4	4	22	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	MAY	2023	56	5					94	100		10.1109/MC.2023.3255279	http://dx.doi.org/10.1109/MC.2023.3255279			7	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	F5FP9		Bronze			2024-07-03	WOS:000982607400011
J	Latif, A; Kim, J				Latif, Atif; Kim, Jihie			Evaluation and Analysis of Large Language Models for Clinical Text Augmentation and Generation	IEEE ACCESS			English	Article						Task analysis; Chatbots; Data models; Data augmentation; Training; Diseases; Cognition; Large language models; Text mining; Data analysis; Data integrity; Clinical trials; BART; large language models; T5; text augmentation; text mining		A major challenge in deep learning (DL) model training is data scarcity. Data scarcity is commonly found in specific domains, such as clinical or low-resource languages, that are not vastly explored in AI research. In this paper, we investigate the generation capability of large language models such as Text-To-Text Transfer Transformer (T5) and Bidirectional and Auto-Regressive Transformers (BART) for Clinical Health-Aware Reasoning across Dimensions (CHARDAT) dataset by applying the ChatGPT augmentation technique. We employed ChatGPT to rephrase each instance of the training set into conceptually similar but semantically different samples and augmented them to the dataset. This study aims to investigate the utilization of large language models, ChatGPT in particular, for data augmentation to overcome the limited availability in the clinical domain. In addition to the ChatGPT augmentation, we applied other augmentation techniques, such as easy data augmentation (EDA) and an easier data augmentation (AEDA), to clinical data. ChatGPT comprehended the contextual significance of sentences within the dataset and successfully modified English terms but not clinical terms. The original CHARDAT datasets represent 52 health conditions across three clinical dimensions, i.e., Treatments, Risk Factors, and Preventions. We compared the outputs for different augmentation techniques and evaluated their relative performance. Additionally, we examined how these techniques perform with different pre-trained language models, assessing their sensitivity in various contexts. Despite the relatively small size of the CHARDAT dataset, our results demonstrated that augmentation methods like ChatGPT augmentation surpassed the efficiency of the previously employed back-translation augmentation. Specifically, our findings revealed that the BART model resulted in superior performance, achieving a rouge score of 52.35 for ROUGE-1, 41.59 for ROUGE-2, and 50.71 for ROUGE-L.	[Latif, Atif] Dongguk Univ, Dept Artificial Intelligence, Seoul 04620, South Korea; [Kim, Jihie] Dongguk Univ, Coll AI Convergence, Seoul 04620, South Korea	Dongguk University; Dongguk University	Kim, J (corresponding author), Dongguk Univ, Coll AI Convergence, Seoul 04620, South Korea.	jihie.kim@dgu.edu		Kim, Jihie/0000-0003-2358-4021; Latif, Atif/0009-0007-8384-7272	MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center)	MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information Technology Research Center)(Ministry of Science & ICT (MSIT), Republic of KoreaMinistry of Science, ICT & Future Planning, Republic of Korea)	No Statement Available	Afzal A., 2023, PROC 15 INT C AGENTS, P682; Anaby-Tavor A, 2019, Arxiv, DOI [arXiv:1911.03118, 10.1609/aaai.v34i05.6233, 10.48550/ARXIV.1911.03118, DOI 10.48550/ARXIV.1911.03118]; Andreas J, 2020, Arxiv, DOI arXiv:1904.09545; [Anonymous], 2014, Int. J. Res. Eng. Technol., V3, P243; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai XY, 2023, IEEE T MULTIMEDIA, V25, P845, DOI 10.1109/TMM.2021.3132724; Cai XY, 2022, J BIOMED INFORM, V127, DOI 10.1016/j.jbi.2022.103999; Chung JJY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P575; Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Feng S.Y., 2020, P DEEP LEARN INS OUT, P29, DOI [10.18653/v1/2020.deelio-1.4, DOI 10.18653/V1/2020.DEELIO-1.4]; Feng SY, 2023, Arxiv, DOI arXiv:2210.04191; Feng SY, 2021, Arxiv, DOI [arXiv:2105.03075, DOI 10.48550/ARXIV.2105.03075]; He K, 2021, J MED INTERNET RES, V23, DOI 10.2196/25670; He K, 2019, EPILEPSY BEHAV, V94, P65, DOI 10.1016/j.yebeh.2019.02.002; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Khetan V, 2022, Arxiv, DOI arXiv:2110.07090; Kobayashi S., 2018, P 2018 C N AM CHAPT, P452; Kumar V, 2021, Arxiv, DOI arXiv:2003.02245; Lavie A., 2007, PROC 2 WORKSHOP STAT, P65; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Li YF, 2021, BIOINFORMATICS, V37, P2699, DOI 10.1093/bioinformatics/btab153; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lin CY, 2003, HLT-NAACL 2003: HUMAN LANGUAGE TECHNOLOGY CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE MAIN CONFERENCE, P150; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Liu ZR, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4742, DOI 10.1109/ICCV48922.2021.00472; Maharana K., 2022, GLOBAL TRANSITIONS P, V3, P91, DOI DOI 10.1016/J.GLTP.2022.04.020; Mao Bing, 2022, 2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P2318, DOI 10.1109/BIBM55620.2022.9995416; Medenilla A., 2023, PLoS Digital Health, V2; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Portoghese I, 2014, SAF HEALTH WORK-KR, V5, P152, DOI 10.1016/j.shaw.2014.05.004; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A., 2018, OpenAl, Tech. Rep.; Raffel C, 2020, J MACH LEARN RES, V21; Sivarajkumar S, 2023, Arxiv, DOI arXiv:2309.08008; Talmor A, 2020, T ASSOC COMPUT LING, V8, P743, DOI 10.1162/tacl_a_00342; Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087; Wang Chenguang., 2021, Zero-shot information extraction as a unified text-to-triple translation; Wang W.Y., 2015, Association for Computational Linguistics, P2557, DOI DOI 10.18653/V1/D15-1306; Wei Jason, 2019, EDA: Easy data augmentation techniques for boosting performance on text classification tasks; Wu JL, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101939; Yadav A. K., 2020, Int. Res. J. Innov. Eng. Technol., V4, P20; Ye JC, 2022, Arxiv, DOI arXiv:2202.07922; Zhang S., 2019, arXiv; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]	49	1	1	5	5	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						48987	48996		10.1109/ACCESS.2024.3384496	http://dx.doi.org/10.1109/ACCESS.2024.3384496			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	NJ1O7		gold			2024-07-03	WOS:001199995800001
J	Nashwan, AJ; Abujaber, AA				Nashwan, Abdulqadir J.; Abujaber, Ahmad A.			Harnessing the Power of Large Language Models (LLMs) for Electronic Health Records (EHRs) Optimization	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Editorial Material						artificial intelligence; clinical decision-making; gpt-4; chatgpt; large language models; electronic health records		This editorial discusses the potential benefits of integrating large language models (LLMs), such as GPT-4, into electronic health records (EHRs) to optimize patient care, improve clinical decision-making, and promote efficient healthcare management. Artificial intelligence (AI)-driven LLMs can revolutionize healthcare practices by streamlining the data input process, expediting information extraction from unstructured narratives, and facilitating personalized patient communication. However, concerns related to patient privacy, data security, and potential biases must be addressed to ensure equitable healthcare for all. Therefore, we encourage healthcare professionals and researchers to explore innovative solutions that leverage AI capabilities while addressing the challenges associated with privacy and equity.	[Nashwan, Abdulqadir J.; Abujaber, Ahmad A.] Hamad Med Corp, Nursing, Doha, Qatar	Hamad Medical Corporation	Nashwan, AJ (corresponding author), Hamad Med Corp, Nursing, Doha, Qatar.	anashwan@hamad.qa	Nashwan, Abdulqadir J./J-6241-2019; ABUJABER, AHMAD/KIB-2200-2024	Nashwan, Abdulqadir J./0000-0003-4845-4119; ABUJABER, AHMAD/0000-0002-8704-4991				[Anonymous], 2023, Microsoft and Epic expand strategic collaboration with integration of Azure OpenAI Service; Chen Mei, 2020, Healthc Manage Forum, V33, P10, DOI 10.1177/0840470419873123; Elbattah M, 2021, HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF, P825, DOI 10.5220/0010414508250832; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; Nashwan Abdulqadir J, 2023, Cureus, V15, pe40542, DOI 10.7759/cureus.40542	5	4	5	13	14	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	JUL 29	2023	15	7							e42634	10.7759/cureus.42634	http://dx.doi.org/10.7759/cureus.42634			2	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Y7IC6	37644945	gold, Green Published			2024-07-03	WOS:001106951100014
J	Castelvecchi, D				Castelvecchi, Davide			OPEN-SOURCE AI CHATBOTS ARE BOOMING - WHAT DOES THIS MEAN FOR RESEARCHERS?	NATURE			English	News Item						Scientific community; Computer science; Machine learning		Freely accessible large language models have accelerated the pace of innovation, computer scientists say.											0	0	0	10	54	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JUN 29	2023	618	7967					891	892		10.1038/d41586-023-01970-6	http://dx.doi.org/10.1038/d41586-023-01970-6			2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	L3ZS2	37340135				2024-07-03	WOS:001022681000001
J	Truhn, D; Eckardt, JN; Ferber, D; Kather, JN				Truhn, Daniel; Eckardt, Jan-Niklas; Ferber, Dyke; Kather, Jakob Nikolas			Large language models and multimodal foundation models for precision oncology	NPJ PRECISION ONCOLOGY			English	Review							ARTIFICIAL-INTELLIGENCE; CANCER	The technological progress in artificial intelligence (AI) has massively accelerated since 2022, with far-reaching implications for oncology and cancer research. Large language models (LLMs) now perform at human-level competency in text processing. Notably, both text and image processing networks are increasingly based on transformer neural networks. This convergence enables the development of multimodal AI models that take diverse types of data as an input simultaneously, marking a qualitative shift from specialized niche models which were prevalent in the 2010s. This editorial summarizes these developments, which are expected to impact precision oncology in the coming years.	[Truhn, Daniel] Univ Hosp Aachen, Dept Diagnost & Intervent Radiol, Aachen, Germany; [Eckardt, Jan-Niklas; Kather, Jakob Nikolas] Tech Univ Dresden, Univ Hosp Carl Gustav Carus, Dept Internal Med 1, Dresden, Germany; [Eckardt, Jan-Niklas; Kather, Jakob Nikolas] Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Ferber, Dyke; Kather, Jakob Nikolas] Univ Heidelberg Hosp, Natl Ctr Tumor Dis NCT, Heidelberg, Germany; [Ferber, Dyke; Kather, Jakob Nikolas] Heidelberg Univ Hosp, Dept Med Oncol, Heidelberg, Germany	RWTH Aachen University; RWTH Aachen University Hospital; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Technische Universitat Dresden; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg; Ruprecht Karls University Heidelberg	Kather, JN (corresponding author), Tech Univ Dresden, Univ Hosp Carl Gustav Carus, Dept Internal Med 1, Dresden, Germany.; Kather, JN (corresponding author), Tech Univ Dresden, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany.; Kather, JN (corresponding author), Univ Heidelberg Hosp, Natl Ctr Tumor Dis NCT, Heidelberg, Germany.; Kather, JN (corresponding author), Heidelberg Univ Hosp, Dept Med Oncol, Heidelberg, Germany.	jakob-nikolas.kather@alumni.dkfz.de		Eckardt, Jan-Niklas/0000-0002-3649-2823	Projekt DEAL	Projekt DEAL	Open Access funding enabled and organized by Projekt DEAL.	Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Castelvecchi D, 2016, NATURE, V537, P20, DOI 10.1038/538020a; Chen RJ, 2022, CANCER CELL, V40, P865, DOI 10.1016/j.ccell.2022.07.004; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; de Hond AAH, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-021-00549-7; Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Li CY, 2023, Arxiv, DOI [arXiv:2306.00890, 10.48550/arXiv.2306.00890, DOI 10.48550/ARXIV.2306.00890]; Lipkova J, 2022, CANCER CELL, V40, P1095, DOI 10.1016/j.ccell.2022.09.012; Lu MY, 2023, Arxiv, DOI [arXiv:2312.07814, 10.48550/arxiv.2312.07814]; Moor M, 2023, NATURE, V616, P259, DOI 10.1038/s41586-023-05881-4; Savage Neil, 2022, Nature, DOI 10.1038/d41586-022-00858-1; Schmidt C, 2017, JNCI-J NATL CANCER I, V109, DOI 10.1093/jnci/djx113; Shmatko A, 2022, NAT CANCER, V3, P1026, DOI 10.1038/s43018-022-00436-4; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Thawkar O, 2023, Arxiv, DOI [arXiv:2306.07971, 10.48550/arXiv.2306.07971, DOI 10.48550/ARXIV.2306.07971]; Tiu E, 2022, NAT BIOMED ENG, V6, P1399, DOI 10.1038/s41551-022-00936-9; Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Tu T., 2023, PREPRINT, DOI [10.1056/AIoa2300138, DOI 10.1056/AIOA2300138]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Vorontsov E, 2024, Arxiv, DOI [arXiv:2309.07778, DOI 10.48550/ARXIV.2309.07778, 10.48550/arXiv.2309.07778]; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Zhang K, 2024, Arxiv, DOI [arXiv:2305.17100, DOI 10.48550/ARXIV.2305.17100]; Zhou YK, 2023, NATURE, V622, P156, DOI 10.1038/s41586-023-06555-x	29	0	0	16	16	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2397-768X		NPJ PRECIS ONCOL	npj Precis. Oncol.	MAR 22	2024	8	1							72	10.1038/s41698-024-00573-2	http://dx.doi.org/10.1038/s41698-024-00573-2			4	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	LU2U7	38519519	gold			2024-07-03	WOS:001189257100002
C	Spoletini, P; Ferrari, A		Mendez, D; Moreira, A		Spoletini, Paola; Ferrari, Alessio			The Return of Formal Requirements Engineering in the Era of Large Language Models	REQUIREMENTS ENGINEERING: FOUNDATION FOR SOFTWARE QUALITY, REFSQ 2024	Lecture Notes in Computer Science		English	Proceedings Paper	30th International Working Conference on Requirements Engineering - Foundation for Software Quality (REFSQ)	APR 08-11, 2024	Winterthur, SWITZERLAND	Zhaw, Sch Engn, InIT Inst Comp Sci, Fachhochschule Nordwestschweiz, Fortiss, IREB, Springer, XITASO		Formal Requirements; Formal Methods; Model Checking; Large Language Models		[Context andMotivation] Large Language Models (LLMs) have made remarkable advancements in emulating human linguistic capabilities, showing potential in executing various traditional software engineering tasks, including code generation. [Question/Problem] Despite their generally good performance, utilizing LLM-generated code raises legitimate concerns regarding its correctness and the assurances it can provide. [Principal Idea/Results] To address these concerns, we propose turning to formal requirements engineering-a practice currently predominantly used in developing complex systems where adherence to standards and accountability are required. [Contribution] In this vision paper, we discuss the integration of automatic formal requirements engineering techniques as a complement to LLM code generation. Additionally, we explore how LLMs can facilitate the broader acceptance of formal requirements, thus making the vision proposed in this paper realizable.	[Spoletini, Paola] Kennesaw State Univ, Kennesaw, GA 30144 USA; [Ferrari, Alessio] CNR, ISTI, Pisa, Italy	University System of Georgia; Kennesaw State University; Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)	Spoletini, P (corresponding author), Kennesaw State Univ, Kennesaw, GA 30144 USA.	pspoleti@kennesaw.edu; alessio.ferrari@isti.cnr.it						Bibel W., 2013, Automated Theorem Proving, DOI DOI 10.1007/978-3-322-90102-6; Brun Y, 2018, ESEC/FSE'18: PROCEEDINGS OF THE 2018 26TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, P754, DOI 10.1145/3236024.3264838; Brunello A., 2019, 26 INT S TEMP REPR R; Chen M., 2021, arXiv; Chen TL, 2013, FORM METHOD SYST DES, V43, P61, DOI 10.1007/s10703-013-0183-7; Chen YC, 2023, Arxiv, DOI arXiv:2305.07766; Cherukuri H, 2022, LECT NOTES COMPUT SC, V13216, P79, DOI 10.1007/978-3-030-98464-9_7; Chong N, 2020, 2020 IEEE/ACM 42ND INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP), P11, DOI 10.1145/3377813.3381347; Clarke T.A., 2018, HDB MODEL CHECKING, DOI DOI 10.1007/978-3-319-10575-8; Coq Development Team, 1989, he Coq proof assistant; Czepa C, 2020, IEEE T SOFTWARE ENG, V46, P100, DOI 10.1109/TSE.2018.2859926; D'Silva V, 2008, IEEE T COMPUT AID D, V27, P1165, DOI 10.1109/TCAD.2008.923410; de Moura L, 2008, LECT NOTES COMPUT SC, V4963, P337, DOI 10.1007/978-3-540-78800-3_24; Dietsch D, 2020, 2020 IEEE WORKSHOP ON FORMAL REQUIREMENTS (FORMREQ 2020), P14, DOI 10.1109/FORMREQ51202.2020.00010; Fan AEL, 2023, Arxiv, DOI arXiv:2310.03533; Gopalan N, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV; GREENSPAN S, 1994, PROC INT CONF SOFTW, P135, DOI 10.1109/ICSE.1994.296773; Hou XY, 2024, Arxiv, DOI arXiv:2308.10620; Huang D., 2024, Bias testing and mitigation in LLM-based code generation; Katoen JP, 2016, PROCEEDINGS OF THE 31ST ANNUAL ACM-IEEE SYMPOSIUM ON LOGIC IN COMPUTER SCIENCE (LICS 2016), P31, DOI 10.1145/2933575.2934574; Knobelsdorf M, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P83, DOI 10.1145/3105726.3106184; Liu JX, 2023, Arxiv, DOI arXiv:2302.11649; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Patel R., 2020, Robotics: Science and Systems; Pnueli A., 1977, 18th Annual Symposium on Foundations of Computer Science, P46, DOI 10.1109/SFCS.1977.32; Shah D, 2023, C ROBOT LEARNING, P492; Tianhai Liu, 2012, 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation (ICST 2012), P101, DOI 10.1109/ICST.2012.90; Wang RE, 2023, Arxiv, DOI arXiv:2203.11370; Ye H., 2023, arXiv, DOI DOI 10.48550/ARXIV.2309.06794; Zan DG, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P7443; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	31	1	1	2	2	SPRINGER INTERNATIONAL PUBLISHING AG	CHAM	GEWERBESTRASSE 11, CHAM, CH-6330, SWITZERLAND	0302-9743	1611-3349	978-3-031-57326-2; 978-3-031-57327-9	LECT NOTES COMPUT SC			2024	14588						344	353		10.1007/978-3-031-57327-9_22	http://dx.doi.org/10.1007/978-3-031-57327-9_22			10	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW9AK					2024-07-03	WOS:001209314200022
J	Wu, J; Antonova, R; Kan, A; Lepert, M; Zeng, A; Song, S; Bohg, J; Rusinkiewicz, S; Funkhouser, T				Wu, Jimmy; Antonova, Rika; Kan, Adam; Lepert, Marion; Zeng, Andy; Song, Shuran; Bohg, Jeannette; Rusinkiewicz, Szymon; Funkhouser, Thomas			TidyBot: personalized robot assistance with large language models	AUTONOMOUS ROBOTS			English	Article						Service robotics; Mobile manipulation; Large language models		For a robot to personalize physical assistance effectively, it must learn user preferences that can be generally reapplied to future scenarios. In this work, we investigate personalization of household cleanup with robots that can tidy up rooms by picking up objects and putting them away. A key challenge is determining the proper place to put each object, as people's preferences can vary greatly depending on personal taste or cultural background. For instance, one person may prefer storing shirts in the drawer, while another may prefer them on the shelf. We aim to build systems that can learn such preferences from just a handful of examples via prior interactions with a particular person. We show that robots can combine language-based planning and perception with the few-shot summarization capabilities of large language models to infer generalized user preferences that are broadly applicable to future interactions. This approach enables fast adaptation and achieves 91.2% accuracy on unseen objects in our benchmark dataset. We also demonstrate our approach on a real-world mobile manipulator called TidyBot, which successfully puts away 85.0% of objects in real-world test scenarios.	[Wu, Jimmy; Rusinkiewicz, Szymon; Funkhouser, Thomas] Princeton Univ, Princeton, NJ 08544 USA; [Antonova, Rika; Lepert, Marion; Bohg, Jeannette] Stanford Univ, Stanford, CA USA; [Kan, Adam] Nueva Sch, San Mateo, CA USA; [Zeng, Andy; Funkhouser, Thomas] Google, Mountain View, CA USA; [Song, Shuran] Columbia Univ, New York, NY USA	Princeton University; Stanford University; Google Incorporated; Columbia University	Wu, J (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.	jw60@cs.princeton.edu; rika.antonova@stanford.edu; adakan@nuevaschool.org; lepertm@stanford.edu; andyzeng@google.com; shurans@cs.columbia.edu; bohg@stanford.edu; smr@princeton.edu; funk@cs.princeton.edu	wu, jimmy/KDP-2256-2024	Bohg, Jeannette/0000-0002-4921-7193; song, shuran/0000-0002-8768-7356	The authors would like to thank William Chong, Kevin Lin, and Jingyun Yang for fruitful technical discussions, and Bob Holmberg for mentorship and support in building up the mobile platforms.	The authors would like to thank William Chong, Kevin Lin, and Jingyun Yang for fruitful technical discussions, and Bob Holmberg for mentorship and support in building up the mobile platforms.	The authors would like to thank William Chong, Kevin Lin, and Jingyun Yang for fruitful technical discussions, and Bob Holmberg for mentorship and support in building up the mobile platforms.	Abdo N, 2015, IEEE INT CONF ROBOT, P1557, DOI 10.1109/ICRA.2015.7139396; Batra D., 2020, ARXIV; Brohan A., 2022, 6 ANN C ROB LEARN; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chaumond Julien, 2019, P 33 C NEURAL INFORM; Chen B., 2022, ARXIV; Chen M., 2021, ARXIV; Chen W., 2022, ARXIV; Chowdhery A., 2022, arXiv; Coulter R C., 1992, Technical report; Dewi T., 2020, Bull. Electr. Eng. Inform., V9, P1438, DOI [10.11591/eei.v9i4.2353, DOI 10.11591/EEI.V9I4.2353]; Ehsani K, 2021, PROC CVPR IEEE, P4495, DOI 10.1109/CVPR46437.2021.00447; Gan C., 2022, 2022 INT C ROB AUT I; Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005; Gu X., 2021, INT C LEARNING REPRE; Gupta M, 2012, IEEE INT CONF ROBOT, P3883, DOI 10.1109/ICRA.2012.6224787; Herde M, 2018, IEEE IJCNN, P17; Hoeg S. H., 2022, WORKSH LANG ROB CORL; Holmberg R, 2000, INT J ROBOT RES, V19, P1066, DOI 10.1177/02783640022067977; Huang E, 2019, IEEE INT CONF ROBOT, P211, DOI [10.1109/ICRA.2019.8793946, 10.1109/icra.2019.8793946]; Huang W., 2022, ARXIV; Kang M., 2018, 2018 15 INT C UBIQUI; Kant Y., 2022, ARXIV; Kapelyukh I., 2022, C ROB LEARN; Kojima T., 2022, ARXIV; Kolve E, 2017, ARXIV; Kujala JV, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P971, DOI 10.1109/IROS.2016.7759167; Li C., 2022, 6 ANN C ROBOT LEARNI; Li C., 2022, C ROB LEARN; Liang J., 2022, ARXIV; Lin K., 2023, ARXIV; Liu Y., 2019, CoRR abs/1907.11692; Lukka T.J., 2014, P INT C SENS BAS SOR, P1; Madaan A., 2022, ARXIV; Mees O., 2022, ARXIV; MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748; Minderer M., 2022, arXiv; Nye Maxwell, 2021, arXiv; Pan ZR, 2021, IEEE INT CONF ROBOT, P6199, DOI 10.1109/ICRA48506.2021.9560782; Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886; Radford A, 2021, PR MACH LEARN RES, V139; Raman S. S., 2022, ARXIV; Rasch R, 2019, J AMB INTEL SMART EN, V11, P261, DOI 10.3233/AIS-190524; Reimers N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P567; Ren A. Z., 2022, ARXIV; Rytting Christopher, 2021, Advances in Neural Information Processing Systems, V34, P17111; Sarch G., 2022, EUROPEAN C COMPUTER; Shah D., 2022, ARXIV; Shridhar Mohit, 2021, ICLR; Shridhar Mohit, 2020, P IEEE CVF C COMP VI; Silver T., 2022, NEURIPS 2022 FDN MOD; Singh I., 2022, ARXIV; Song H., 2020, 2020 IEEERSJ INT C I; Srivastava S., 2022, C ROB LEARN; Szabó R, 2012, 2012 10TH INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS, P95, DOI 10.1109/ISETC.2012.6408119; Szot Andrew, 2021, Advances in Neural Information Processing Systems, V34, P251; Taniguchi A, 2021, ADV ROBOTICS, V35, P471, DOI 10.1080/01691864.2021.1890212; Wei J., 2022, ARXIV; Weihs L, 2021, PROC CVPR IEEE, P5918, DOI 10.1109/CVPR46437.2021.00586; Wu J., 2023, IEEE RSJ INT C INT R; Yan Z., 2021, 2021 IEEE INT C ADV; Yao S., 2022, arXiv; Zeng A., 2022, ARXIV; Zeng A, 2020, IEEE T ROBOT, V36, P1307, DOI 10.1109/TRO.2020.2988642; Zeng A, 2022, INT J ROBOT RES, V41, P690, DOI 10.1177/0278364919868017	65	3	3	21	24	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0929-5593	1573-7527		AUTON ROBOT	Auton. Robot.	DEC	2023	47	8					1087	1102		10.1007/s10514-023-10139-z	http://dx.doi.org/10.1007/s10514-023-10139-z		NOV 2023	16	Computer Science, Artificial Intelligence; Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Robotics	LM3O8		Green Submitted			2024-07-03	WOS:001101530300001
C	Song, CH; Wu, J; Washington, C; Sadler, BM; Chao, WL; Su, Y			IEEE	Song, Chan Hee; Wu, Jiaman; Washington, Clayton; Sadler, Brian M.; Chao, Wei-Lun; Su, Yu			LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models	2023 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION, ICCV	IEEE International Conference on Computer Vision		English	Proceedings Paper	IEEE/CVF International Conference on Computer Vision (ICCV)	OCT 02-06, 2023	Paris, FRANCE	IEEE, IEEE Comp Soc, CVF			VISION; NAVIGATION	This study focuses on using large language models (LLMs) as a planner for embodied agents that can follow natural language instructions to complete complex tasks in a visually-perceived environment. The high data cost and poor sample efficiency of existing methods hinders the development of versatile agents that are capable of many tasks and can learn new tasks quickly. In this work, we propose a novel method, LLM-Planner, that harnesses the power of large language models to do few-shot planning for embodied agents. We further propose a simple but effective way to enhance LLMs with physical grounding to generate and update plans that are grounded in the current environment. Experiments on the ALFRED dataset show that our method can achieve very competitive few-shot performance: Despite using less than 0.5% of paired training data, LLM-Planner achieves competitive performance with recent baselines that are trained using the full training data. Existing methods can barely complete any task successfully under the same few-shot setting. Our work opens the door for developing versatile and sample-efficient embodied agents that can quickly learn many tasks.	[Song, Chan Hee; Wu, Jiaman; Washington, Clayton; Chao, Wei-Lun; Su, Yu] Ohio State Univ, Columbus, OH 43210 USA; [Sadler, Brian M.] DEVCOM ARL, Adelphi, MD USA	University System of Ohio; Ohio State University	Song, CH (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.	song.1855@osu.edu; wu.5686@osu.edu; washington.534@osu.edu; brian.m.sadler6.civ@army.mil; chao.209@osu.edu; su.806@osu.edu			ARL [W911NF2220144]	ARL(United States Department of DefenseUS Army Research Laboratory (ARL))	The authors would like to thank the colleagues from the OSU NLP group for their thoughtful comments. This research was supported by ARL W911NF2220144.	Ahn M., 2022, arXiv preprint arXiv:2204.01691; Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387; Blukis V., 2022, C ROBOT LEARNING, P706; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen Tworek Jun Yuan Ponde Kaplan Ed- wards Burda Joseph Brockman Ray Puri Krueger Petrov Khlaaf Sastry Mishkin Chan Gray Ryder Pavlov Power Kaiser Bavarian Winter Tillet Mark Jerry Heewoo Qiming Henrique Jared Harrison Yura Nicholas Greg Alex Raul Gretchen Michael Heidy Girish Pamela Brooke Scott Nick Mikhail Alethea Lukasz Moham- mad Clemens Philippe, 2021, ABS210703374 ARXIV; DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Farhadi, 2017, Ai2-thor: An interactive 3d environment for visual ai, V2, P3; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Gutierrez Bernal Jimenez, 2022, ARXIV220308410; Hong YC, 2021, PROC CVPR IEEE, P1643, DOI 10.1109/CVPR46437.2021.00169; Huang Chenguang, 2022, ARXIV221005714; Huang S, 2022, NATL ACCOUNT REV, V4, P1, DOI 10.3934/NAR.2022001; Huang Wenlong, 2022, ARXIV220705608; Inoue Yuki, 2022, ARXIV221103267; Ku Alexander, 2020, C EMP METH NAT LANG; Li XJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1494; Liu Hao, 2022, ABS220304637 ARXIV; Liu JC, 2022, PROCEEDINGS OF DEEP LEARNING INSIDE OUT (DEELIO 2022): THE 3RD WORKSHOP ON KNOWLEDGE EXTRACTION AND INTEGRATION FOR DEEP LEARNING ARCHITECTURES, P100; Liu P, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3510414; Liu Xiaotian, 2022, INTERACTIONS, V9, P17; Liu Y, 2019, ARXIV PREPRINT ARXIV; Lu JS, 2019, ADV NEUR IN, V32; Lu Yujie, 2022, NEUROSYMBOLIC PROCED; Majumdar Arjun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P259, DOI 10.1007/978-3-030-58539-6_16; Micheli V, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P9312; Min S. Y., 2021, INT C LEARN REPR ICL; Pashevich Alexander, 2021, ICCV; Perez E, 2021, ADV NEUR IN; Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Shah Dhruv, 2022, 6 ANN C ROB LEARN; Sharma P, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1713; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Singh Ishika, 2022, ARXIV220911302; Song CH, 2022, PROC CVPR IEEE, P15461, DOI 10.1109/CVPR52688.2022.01504; Suglia A., 2021, Embodied bert: A transformer model for embodied, language-guided visual task completion; Sutton RS, 1999, ARTIF INTELL, V112, P181, DOI 10.1016/S0004-3702(99)00052-1; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yao Shunyu, 2023, INT C LEARN REPR; Zhang L, 2021, FRONT MED-LAUSANNE, V8, DOI 10.3389/fmed.2021.754202; Zheng Kai, 2022, ABS220813266 ARXIV; Zhou K., 2023, INT C MACHINE LEARNI, V202, P42829; 2018, LEARN EV CAMP TEACH, P1	44	4	4	6	6	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1550-5499		979-8-3503-0718-4	IEEE I CONF COMP VIS			2023							2986	2997		10.1109/ICCV51070.2023.00280	http://dx.doi.org/10.1109/ICCV51070.2023.00280			12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Imaging Science & Photographic Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Imaging Science & Photographic Technology	BW5FA		Green Submitted			2024-07-03	WOS:001159644303023
J	Nashwan, AJ; Abukhadijah, H				Nashwan, Abdulqadir J.; Abukhadijah, Hana			Harnessing Artificial Intelligence for Qualitative and Mixed Methods in Nursing Research	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Editorial Material						nursing research; large language models; artificial intelligence; mixed-methods; qualitative studies		This editorial discusses the transformative potential of artificial intelligence (AI), particularly large language models (LLMs), in enhancing traditional nursing research methodologies, specifically qualitative and mixed methods. The article emphasizes the benefits of AI such as LLMs in data processing, analysis, integration, and triangulation while also underscoring the importance of addressing ethical concerns and the need for proper training for researchers.	[Nashwan, Abdulqadir J.] Hamad Med Corp, Nursing Dept, Doha, Qatar; [Abukhadijah, Hana] Hamad Med Corp, Epidemiol & Publ Hlth Dept, Doha, Qatar	Hamad Medical Corporation; Hamad Medical Corporation	Nashwan, AJ (corresponding author), Hamad Med Corp, Nursing Dept, Doha, Qatar.	anashwan@hamad.qa	Abukhadijah, Hana J./KIJ-9438-2024; Nashwan, Abdulqadir J./J-6241-2019	Abukhadijah, Hana J./0009-0008-7993-7467; Nashwan, Abdulqadir J./0000-0003-4845-4119				[Anonymous], 2023, The role of ChatGPT in qualitative research: potential and limitations; Beck CT, 2016, ADV NURS SCI, V39, P224, DOI 10.1097/ANS.0000000000000125; Byrne M M, 2001, AORN J, V73, P830, DOI 10.1016/S0001-2092(06)61812-7; Carter N, 2014, ONCOL NURS FORUM, V41, P545, DOI 10.1188/14.ONF.545-547; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Doorenbos Ardith Z, 2014, Kango Kenkyu, V47, P207; Doyle L, 2020, J RES NURS, V25, P443, DOI 10.1177/1744987119880234; Nashwan AJ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.42634; Nashwan Abdulqadir J, 2023, Cureus, V15, pe40542, DOI 10.7759/cureus.40542; Oliveira J.L. C., 2018, TextoContextoEnferm, V27, DOI [10.1590/0104-070720180000560017, DOI 10.1590/0104-070720180000560017]; Seibert K, 2021, J MED INTERNET RES, V23, DOI 10.2196/26522; von Gerich H, 2022, INT J NURS STUD, V127, DOI 10.1016/j.ijnurstu.2021.104153; Younas A, 2019, NURS RES, V68, P464, DOI 10.1097/NNR.0000000000000372	13	0	0	7	7	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	NOV 9	2023	15	11							e48570	10.7759/cureus.48570	http://dx.doi.org/10.7759/cureus.48570			4	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	Y7CB4	38073939	Green Published, gold			2024-07-03	WOS:001106791200006
J	Strachan, JWA; Albergo, D; Borghini, G; Pansardi, O; Scaliti, E; Gupta, S; Saxena, K; Rufo, A; Panzeri, S; Manzi, G; Graziano, MSA; Becchio, C				Strachan, James W. A.; Albergo, Dalila; Borghini, Giulia; Pansardi, Oriana; Scaliti, Eugenio; Gupta, Saurabh; Saxena, Krati; Rufo, Alessandro; Panzeri, Stefano; Manzi, Guido; Graziano, Michael S. A.; Becchio, Cristina			Testing theory of mind in large language models and humans	NATURE HUMAN BEHAVIOUR			English	Article; Early Access							FALSE BELIEF; ASPERGER-SYNDROME; CHILDREN; THINKING; ADULTS	At the core of what defines us as humans is the concept of theory of mind: the ability to track other people's mental states. The recent development of large language models (LLMs) such as ChatGPT has led to intense debate about the possibility that these models exhibit behaviour that is indistinguishable from human behaviour in theory of mind tasks. Here we compare human and LLM performance on a comprehensive battery of measurements that aim to measure different theory of mind abilities, from understanding false beliefs to interpreting indirect requests and recognizing irony and faux pas. We tested two families of LLMs (GPT and LLaMA2) repeatedly against these measures and compared their performance with those from a sample of 1,907 human participants. Across the battery of theory of mind tests, we found that GPT-4 models performed at, or even sometimes above, human levels at identifying indirect requests, false beliefs and misdirection, but struggled with detecting faux pas. Faux pas, however, was the only test where LLaMA2 outperformed humans. Follow-up manipulations of the belief likelihood revealed that the superiority of LLaMA2 was illusory, possibly reflecting a bias towards attributing ignorance. By contrast, the poor performance of GPT originated from a hyperconservative approach towards committing to conclusions rather than from a genuine failure of inference. These findings not only demonstrate that LLMs exhibit behaviour that is consistent with the outputs of mentalistic inference in humans but also highlight the importance of systematic testing to ensure a non-superficial comparison between human and artificial intelligences. Testing two families of large language models (LLMs) (GPT and LLaMA2) on a battery of measurements spanning different theory of mind abilities, Strachan et al. find that the performance of LLMs can mirror that of humans on most of these tasks. The authors explored potential reasons for this.	[Strachan, James W. A.; Pansardi, Oriana; Scaliti, Eugenio; Becchio, Cristina] Univ Med Ctr Hamburg Eppendorf, Dept Neurol, Hamburg, Germany; [Albergo, Dalila; Borghini, Giulia; Pansardi, Oriana; Scaliti, Eugenio; Becchio, Cristina] Italian Inst Technol, Cognit Mot & Neurosci, Genoa, Italy; [Albergo, Dalila] Univ Trento, Ctr Mind Brain Sci, Rovereto, Italy; [Pansardi, Oriana] Univ Turin, Dept Psychol, Turin, Italy; [Scaliti, Eugenio] Univ Turin, Dept Management Valter Cantino, Turin, Italy; [Scaliti, Eugenio] Univ Turin, Human Sci & Technol, Turin, Italy; [Gupta, Saurabh; Saxena, Krati; Rufo, Alessandro; Manzi, Guido] Alien Technol Transfer Ltd, London, England; [Panzeri, Stefano] Univ Med Ctr Hamburg Eppendorf, Inst Neural Informat Proc, Ctr Mol Neurobiol, Hamburg, Germany; [Graziano, Michael S. A.] Princeton Univ, Princeton Neurosci Inst, Princeton, NJ USA	University of Hamburg; University Medical Center Hamburg-Eppendorf; Istituto Italiano di Tecnologia - IIT; University of Trento; University of Turin; University of Turin; University of Turin; University of Hamburg; University Medical Center Hamburg-Eppendorf; Princeton University	Strachan, JWA; Becchio, C (corresponding author), Univ Med Ctr Hamburg Eppendorf, Dept Neurol, Hamburg, Germany.; Becchio, C (corresponding author), Italian Inst Technol, Cognit Mot & Neurosci, Genoa, Italy.	james.wa.strachan@gmail.com; c.becchio@uke.de	Panzeri, Stefano/L-5977-2013	Panzeri, Stefano/0000-0003-1700-8909	Alexander von Humboldt-Stiftung (Alexander von Humboldt Foundation) [101071191-HORIZON-EIC-2021-PATHFINDERCHALLENGES-01]; European Commission; Alexander von Humboldt Foundation	Alexander von Humboldt-Stiftung (Alexander von Humboldt Foundation)(Alexander von Humboldt Foundation); European Commission(European Union (EU)European Commission Joint Research Centre); Alexander von Humboldt Foundation(Alexander von Humboldt Foundation)	This work is supported by the European Commission through Project ASTOUND (101071191-HORIZON-EIC-2021-PATHFINDERCHALLENGES-01 to A.R., G.M., C.B. and S.P.). J.W.A.S. was supported by a Humboldt Research Fellowship for Experienced Researchers provided by the Alexander von Humboldt Foundation. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Apperly IA, 2006, PSYCHOL SCI, V17, P841, DOI 10.1111/j.1467-9280.2006.01791.x; Apperly IA, 2012, Q J EXP PSYCHOL, V65, P825, DOI 10.1080/17470218.2012.676055; Apperly IA, 2011, CHILD DEV, V82, P1691, DOI 10.1111/j.1467-8624.2011.01635.x; Apperly IA, 2009, PSYCHOL REV, V116, P953, DOI 10.1037/a0016923; Au-Yeung SK, 2015, AUTISM RES, V8, P749, DOI 10.1002/aur.1490; Baron-Cohen S, 2001, J CHILD PSYCHOL PSYC, V42, P241, DOI 10.1111/1469-7610.00715; Baron-Cohen S, 1999, J AUTISM DEV DISORD, V29, P407, DOI 10.1023/A:1023035012436; Bernstein DM, 2011, EXP AGING RES, V37, P481, DOI 10.1080/0361073X.2011.619466; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Bonnefon JF, 2020, TRENDS COGN SCI, V24, P1019, DOI 10.1016/j.tics.2020.09.007; Brunet-Gouet E, 2024, LECT NOTES COMPUT SC, V14522, P107, DOI 10.1007/978-3-031-55245-8_7; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chemero A, 2023, NAT HUM BEHAV, DOI 10.1038/s41562-023-01723-5; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Corcoran Rhiannon, 2003, Cogn Neuropsychiatry, V8, P223, DOI 10.1080/13546800244000319; Dou Z., 2023, PREPRINT, DOI [10.31219/osf.io/8r3ma, DOI 10.31219/OSF.IO/8R3MA]; FeldmanHall O, 2019, NAT HUM BEHAV, V3, P426, DOI 10.1038/s41562-019-0590-x; Firestone C, 2020, P NATL ACAD SCI USA, V117, P26562, DOI 10.1073/pnas.1905334117; FISKE ST, 1992, J PERS SOC PSYCHOL, V63, P877, DOI 10.1037/0022-3514.63.6.877; Frank MC, 2023, NAT HUM BEHAV, DOI 10.1038/s41562-023-01732-4; Frith CD, 2006, NEURON, V50, P531, DOI 10.1016/j.neuron.2006.05.001; Gandhi K., 2023, Advances in Neural Information Processing Systems, V36; Gil D, 2012, REV PSIQUIATR SALUD, V5, P79, DOI 10.1016/j.rpsm.2011.11.004; Hagendorff T, 2023, Arxiv, DOI [arXiv:2303.13988, 10.48550/arXiv.2303.13988, DOI 10.48550/ARXIV.2303.13988]; Hanks TD, 2011, J NEUROSCI, V31, P6339, DOI 10.1523/JNEUROSCI.5613-10.2011; HAPPE FGE, 1994, J AUTISM DEV DISORD, V24, P129, DOI 10.1007/BF02172093; JAMES W, 1890, PRINCIPLES PSYCHOL, V2; Kampis D, 2021, ROY SOC OPEN SCI, V8, DOI 10.1098/rsos.210190; Kim H., 2023, P 2023 C EMP METH NA, P14397, DOI [10.18653/v1, DOI 10.18653/V1]; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Koster-Hale J, 2013, NEURON, V79, P836, DOI 10.1016/j.neuron.2013.08.020; Kovács AM, 2021, COGNITION, V213, DOI 10.1016/j.cognition.2021.104640; Kovács AM, 2010, SCIENCE, V330, P1830, DOI 10.1126/science.1190792; Marcus G., 2023, Marcus on AI; PERNER J, 1987, BRIT J DEV PSYCHOL, V5, P125, DOI 10.1111/j.2044-835X.1987.tb01048.x; Pezzulo G, 2024, TRENDS COGN SCI, V28, P97, DOI 10.1016/j.tics.2023.10.002; Plate RC, 2023, J EXP PSYCHOL GEN, V152, P2463, DOI 10.1037/xge0001410; PREMACK D, 1978, BEHAV BRAIN SCI, V1, P515, DOI 10.1017/S0140525X00076512; Rahwan I, 2019, NATURE, V568, P477, DOI 10.1038/s41586-019-1138-y; Redcay E, 2019, NAT REV NEUROSCI, V20, P495, DOI 10.1038/s41583-019-0179-4; Rescher Nicholas., 1960, KANT-STUD, V51, P142, DOI DOI 10.1515/KANT.1960.51.1-4.142; Sap M., 2022, P 2022 C EMPIRICAL M, P3762, DOI DOI 10.18653/V1/2022.EMNLP-MAIN.248; Schilbach L, 2013, BEHAV BRAIN SCI, V36, P393, DOI 10.1017/S0140525X12000660; Shapira N., 2023, FINDINGS ASS COMPUTA, P10438; Shapira N, 2023, Arxiv, DOI arXiv:2305.14763; Southgate V, 2007, PSYCHOL SCI, V18, P587, DOI 10.1111/j.1467-9280.2007.01944.x; Srivastava Aarohi, 2022, arXiv; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; van Ackeren MJ, 2012, J COGNITIVE NEUROSCI, V24, P2237, DOI 10.1162/jocn_a_00274; Webb T, 2023, NAT HUM BEHAV, V7, P1526, DOI 10.1038/s41562-023-01659-w; White S, 2009, CHILD DEV, V80, P1097, DOI 10.1111/j.1467-8624.2009.01319.x; Wiesmann CG, 2020, P NATL ACAD SCI USA, V117, P6928, DOI 10.1073/pnas.1916725117; WIMMER H, 1983, COGNITION, V13, P103, DOI 10.1016/0010-0277(83)90004-5; Yiu E, 2023, PERSPECT PSYCHOL SCI, DOI 10.1177/17456916231201401; Zhou P, 2023, Arxiv, DOI [arXiv:2310.03051, 10.48550/arXiv.2310.03051]	56	0	0	25	25	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2024 MAY 20	2024										10.1038/s41562-024-01882-z	http://dx.doi.org/10.1038/s41562-024-01882-z		MAY 2024	19	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	RN0G1	38769463	hybrid			2024-07-03	WOS:001228217000001
J	Anson, DWJ				Anson, Daniel W. J.			The impact of large language models on university students' literacy development: a dialogue with Lea and Street's academic literacies framework	HIGHER EDUCATION RESEARCH & DEVELOPMENT			English	Article; Early Access						Large language models; literacy; academic literacies; reading; writing	AUSTRALIAN PUBLICATIONS; HIGHER-EDUCATION; HEALTH-SCIENCES; 1980S THEMES; SKILLS; COMMUNICATION; REFLECTION; SCHEMES; FACULTY; PROGRAM	Large Language Models have already begun to affect the higher education landscape. However, there is currently a lack of work investigating how these models interface - and possibly interfere - with literacy development. Considering literacy is critical because student learning is only made possible through language. This paper considers implications for university students' literacy development by drawing on Lea and Street's academic literacies framework. I argue that LLMs pose different levels of risk for students' development of each aspect of literacy contained within the framework: study skills are least at risk, academic socialisation is most at risk, and academic literacies represent an intermediate risk. Implications for instructors include dedicated instructional time and support for students to engage with reading and writing practices without LLM support before they begin to incorporate them into their literacies repertoire. If students rely too heavily on LLMs initially, there is a danger they will not undergo the enculturation and cognitive development necessary for success at university.	[Anson, Daniel W. J.] Macquarie Univ, Acad Literacies Unit, Macquarie Pk, Australia; [Anson, Daniel W. J.] Macquarie Univ, Acad Literacies Unit, 16 Macquarie Walk, Macquarie Pk, NSW 2109, Australia	Macquarie University; Macquarie University	Anson, DWJ (corresponding author), Macquarie Univ, Acad Literacies Unit, 16 Macquarie Walk, Macquarie Pk, NSW 2109, Australia.	daniel.anson@mq.edu.au		Anson, Daniel Walter John/0000-0003-3026-1976				Adams G, 2023, Arxiv, DOI arXiv:2309.04269; [Anonymous], 2023, Bloomberg News; Anson DWJ, 2017, AUST J LANG LIT, V40, P135; Anthropic, 2023, Anthropic Blog; Aull L., 2015, First-year university writing: A corpus-based study with implications for pedagogy; Baker S, 2019, HIGH EDUC RES DEV, V38, P142, DOI 10.1080/07294360.2018.1540554; Bartholomae David., 1986, J BASIC WRITING, V5, P4, DOI DOI 10.1007/978-1-4039-8439-5_4; Batyi T, 2022, LANG CULT CURRIC, V35, P303, DOI 10.1080/07908318.2022.2076865; Belcher WL., 2019, WRITING YOUR J ARTIC; Black M, 2013, J SOCIOL, V49, P456, DOI 10.1177/1440783313504056; Bourdieu P., 1989, LOGIC PRACTICE; Bourdieu P., 1986, HDB THEORY RES SOCIO, P241, DOI DOI 10.1002/9780470755679.CH15; Bridgeman A., 2023, University of Sydney, News & Opinion; Brooman-Jones S, 2011, J ACAD LANG LEARN, V5, pA1; Calvo S, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12031155; Carroll L., 2023, SYDNEY MORNING HERAL; Casal E. J., 2023, RES METHODS APPL LIN, V2, P100068; Chanock K, 2011, J ACAD LANG LEARN, V5, pA59; Chanock K, 2011, J ACAD LANG LEARN, V5, pA36; Christie F., 2012, LANGUAGE ED SCH YEAR; Christie F., 2008, SCH DISCOURSE LEARNI; Derewianka B., 2020, Developing writers across the primary and secondary years: Growing into writing, P194, DOI [https://doi.org/10.4324/9781003018858-11, DOI 10.4324/9781003018858-11]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Donovan C, 2020, J FURTH HIGHER EDUC, V44, P326, DOI 10.1080/0309877X.2018.1541972; Dooey P, 2020, J ACAD LANG LEARN, V14, P106; Einfalt J, 2009, J ACAD LANG LEARN, V3, pA105; Fenton-Smith B, 2013, J ACAD LANG LEARN, V7, pA61; Fernando W, 2018, ASSESS WRIT, V36, P63, DOI 10.1016/j.asw.2018.03.005; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Freebody P., 1990, PROSPECT AUSTR J TES, V5, P7; Frohman R, 2012, J ACAD LANG LEARN, V6, pA47; Gee J.P., 1990, SOCIAL LINGUISTICS L; Glew PJ, 2019, NURSE EDUC PRACT, V39, P61, DOI 10.1016/j.nepr.2019.07.011; Goldingay S, 2016, REFLECT PRACT, V17, P334, DOI 10.1080/14623943.2016.1164682; Green T, 2011, J ACAD LANG LEARN, V5, pA18; Gunn C, 2011, J UNIV TEACH LEARN P, V8; Hall Stuart., 1980, Culture, Media, Language, P128, DOI DOI 10.4324/9780203381182; Harris A, 2016, TEACH HIGH EDUC, V21, P287, DOI 10.1080/13562517.2016.1138456; Harris A, 2011, J ACAD LANG LEARN, V5, pA73; Hathaway J, 2015, TEACH HIGH EDUC, V20, P506, DOI 10.1080/13562517.2015.1026891; Jacobs C, 2010, SO AFR LINGUIST APPL, V28, P227, DOI 10.2989/16073614.2010.545025; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kirk T., 2023, ChatGPT (We need to talk); Krathwohl DR, 2002, THEOR PRACT, V41, P212, DOI 10.1207/s15430421tip4104_2; Lea MR, 2006, THEOR PRACT, V45, P368, DOI 10.1207/s15430421tip4504_11; Lea MR, 1998, STUD HIGH EDUC, V23, P157, DOI 10.1080/03075079812331380364; Lear E, 2016, STUD SUCCESS, V7, P13, DOI 10.5204/ssj.v7i1.297; Liang WX, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100779; Lodge J. M., 2023, Learning, P1, DOI [10.1080/23735082.2023.2261106, DOI 10.1080/23735082.2023.2261106]; Lodge JM, 2023, AUSTRALAS J EDUC TEC, V39, P18, DOI 10.14742/ajet.8695; Lytvyn M., 2022, Grammarly Blog; Meyer JG, 2023, BIODATA MIN, V16, DOI 10.1186/s13040-023-00339-9; microsoft, Bing chat; Mitton R., 2010, Writing Systems Research, V2, P1; OkSquash1234, 2023, RedditJuly 31; OpenAI, 2023, OpenAI Blog; OpenAI, 2022, Introducing chatgpt; OpenAI, Educator FAQ; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pichai S., 2023, The Keyword; Powell L, 2016, ACCOUNT EDUC, V25, P14, DOI 10.1080/09639284.2015.1133311; Rivers C., 2023, Times Higher Education, Inside Higher Ed; Rosser G., 2002, Change, V5, P91; Shearing H., 2023, BBC News; Silvia P. J., 2018, How to write a lot: A practical guide to productive academic writing, V2nd ed., DOI [https://doi.org/10.2307/j.ctv1chrsg5, DOI 10.2307/J.CTV1CHRSG5]; Sword H., 2017, Air light time space: How successful academics write, DOI [https://doi.org/10.4159/9780674977617, DOI 10.4159/9780674977617]; Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Vaswani A, 2017, ADV NEUR IN, V30; Wette R, 2019, ENGL SPECIF PURP, V56, P35, DOI 10.1016/j.esp.2019.07.002; Wingate U, 2006, TEACH HIGH EDUC, V11, P457, DOI 10.1080/13562510600874268; Wingate U, 2012, J ENGL ACAD PURP, V11, P26, DOI 10.1016/j.jeap.2011.11.006; Wingate U, 2012, STUD HIGH EDUC, V37, P481, DOI 10.1080/03075079.2010.525630; Wittman K., 2022, The Cambridge companion to the essay, P1, DOI [https://doi.org/10.1017/9781009022255.001, DOI 10.1017/9781009022255.001]	74	0	0	12	12	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	0729-4360	1469-8366		HIGH EDUC RES DEV	High. Educ. Res. Dev.	2024 MAR 27	2024										10.1080/07294360.2024.2332259	http://dx.doi.org/10.1080/07294360.2024.2332259		MAR 2024	14	Education & Educational Research	Social Science Citation Index (SSCI)	Education & Educational Research	MA7U9		hybrid			2024-07-03	WOS:001190976200001
C	Di Palma, D			ACM	Di Palma, Dario			Retrieval-augmented Recommender System: Enhancing Recommender Systems with Large Language Models	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		Large Language Models; Recommender Systems; Prompt Engineering; New Item Recommendation; Hallucination Problem; Retrieval-augmented Recommender System		Recommender Systems (RSs) play a pivotal role in delivering personalized recommendations across various domains, from e-commerce to content streaming platforms. Recent advancements in natural language processing have introduced Large Language Models (LLMs) that exhibit remarkable capabilities in understanding and generating human-like text. RS are renowned for their effectiveness and proficiency within clearly defined domains; nevertheless, they are limited in adaptability and incapable of providing recommendations for unexplored data. Conversely, LLMs exhibit contextual awareness and strong adaptability to unseen data. Combining these technologies creates a powerful tool for delivering contextual and relevant recommendations, even in cold scenarios characterized by high data sparsity. The proposal aims to explore the possibilities of integrating LLMs into RS, introducing a novel approach called Retrieval-augmented Recommender Systems, which combines the strengths of retrieval-based and generation-based models to enhance the ability of RSs to provide relevant suggestions.	[Di Palma, Dario] Politecn Bari, Bari, Italy	Politecnico di Bari	Di Palma, D (corresponding author), Politecn Bari, Bari, Italy.	d.dipalma2@phd.poliba.it		Di Palma, Dario/0009-0007-3593-7441	Secure Safe Apulia; Casa delle Tecnologie Emergenti Comune di Matera; LUTECH DIGITALE 4.0; OVS Fashion Retail Reloaded; CT_FINCONS_III; KOINE; MOST -Centro Nazionale per la Mobilita Sostenibile	Secure Safe Apulia; Casa delle Tecnologie Emergenti Comune di Matera; LUTECH DIGITALE 4.0; OVS Fashion Retail Reloaded; CT_FINCONS_III; KOINE; MOST -Centro Nazionale per la Mobilita Sostenibile	This work was partially supported by the following projects: Secure Safe Apulia, Casa delle Tecnologie Emergenti Comune di Matera, LUTECH DIGITALE 4.0, OVS Fashion Retail Reloaded, CT_FINCONS_III, KOINE, MOST -Centro Nazionale per la Mobilita Sostenibile.	Anelli VW, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2405, DOI 10.1145/3404835.3463245; Anil Rohan, 2023, PaLM 2 Technical Report; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cheng H.-T., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [10.1145/2988450.2988454, DOI 10.1145/2988450.2988454]; Chronopoulou A, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2089; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Emelin D., 2022, P 2022 C EMP METH NA, P11962, DOI [10.18653/v1/2022.emnlpmain.820, DOI 10.18653/V1/2022.EMNLPMAIN.820]; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Han WJ, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P854; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22; Hu YJ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P368, DOI 10.1145/3219819.3219846; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Li JM, 2023, Arxiv, DOI arXiv:2304.03879; Moiseev F, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P1581; Naumov M., 2019, arXiv; Ouyang L., 2022, NEURIPS; Panda DK, 2022, J INTELL INF SYST, V59, P341, DOI 10.1007/s10844-022-00698-5; Pazzani M. J., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P325; Radford A., 2018, IMPROVING LANGUAGE U; Rendle S, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168771; Breese JS, 2013, Arxiv, DOI arXiv:1301.7363; Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI [10.1145/371920.372071, DOI 10.1145/371920.372071]; Schwartz R, 2019, Arxiv, DOI arXiv:1907.10597; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang WJ, 2024, Arxiv, DOI arXiv:2304.03516; Wei J., 2022, NEURIPS; Wu S, 2019, AAAI CONF ARTIF INTE, P346; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yin Zhangyue, 2023, FINDINGS ASS COMPUTA, P8653; Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890; Zhao XY, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P95, DOI 10.1145/3240323.3240374; Zhiyuli A, 2023, Arxiv, DOI arXiv:2305.15673	40	3	3	18	18	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1369	1373		10.1145/3604915.3608889	http://dx.doi.org/10.1145/3604915.3608889			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ					2024-07-03	WOS:001156630300196
C	Fang, JC; He, Y; Yu, FR; Li, JQ; Leung, VC			IEEE	Fang, Jingcheng; He, Ying; Yu, F. Richard; Li, Jianqiang; Leung, Victor C.			Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Networks: An Active Inference Approach	2023 IEEE 98TH VEHICULAR TECHNOLOGY CONFERENCE, VTC2023-FALL	IEEE Vehicular Technology Conference Proceedings		English	Proceedings Paper	98th IEEE Vehicular Technology Conference (VTC-Fall)	OCT 10-13, 2023	Hong Kong, HONG KONG	IEEE, IEEE VTS		Active inference; large language model inference task; task offloading; resource allocation; cloud-edge networks; reinforcement learning		As the research and applications of large language model (LLM) become increasingly sophisticated, it is difficult for resource-limited mobile terminals to run large-model inference tasks efficiently. Traditional deep reinforcement learning (DRL) based approaches have been used to offload LLM inference tasks to servers. However, existing solutions suffer from data inefficiency, insensitivity to latency requirements, and non-adaptability to task load variations. In this paper, we propose an active inference with rewardless guidance algorithm using expected future free energy for offloading decisions and allocating resources for the LLM inference task offloading and resource allocation problem of cloud-edge networks systems. Experimental results show that our proposed method has superior performance over mainstream DRLs, improves in data utilization efficiency, and is more adaptable to changing task load scenarios.	[Fang, Jingcheng; He, Ying; Yu, F. Richard; Li, Jianqiang; Leung, Victor C.] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen Key Lab Digital & Intelligent Technol &, Shenzhen, Peoples R China; [Fang, Jingcheng; He, Ying; Yu, F. Richard] Guangdong Lab Artificial Intelligence & Digital E, Shenzhen, Peoples R China	Shenzhen University; Guangming Laboratory	He, Y (corresponding author), Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen Key Lab Digital & Intelligent Technol &, Shenzhen, Peoples R China.; He, Y (corresponding author), Guangdong Lab Artificial Intelligence & Digital E, Shenzhen, Peoples R China.	2110276163@email.szu.edu.cn; heying@szu.edu.cn; yufei@szu.edu.cn; lijq@szu.edu.cn; vleung@ieee.org	Leung, Victor C. M./AGU-2462-2022; Yu, F. Richard/B-3182-2018	Leung, Victor C. M./0000-0003-3529-2640; 	National Natural Science Foundation of China (NSFC) [62271324, 62231020, 62002238]; Shenzhen Science and Technology Program [ZDSYS20220527171400002]; Open Research Fund from Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ) [GML-KF22-26]; Guangdong "Pearl River Talent Recruitment Program" [2019ZT08X603]	National Natural Science Foundation of China (NSFC)(National Natural Science Foundation of China (NSFC)); Shenzhen Science and Technology Program; Open Research Fund from Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ); Guangdong "Pearl River Talent Recruitment Program"	This work is supported in part by the National Natural Science Foundation of China (NSFC) under Grants 62271324, 62231020, and 62002238, Shenzhen Science and Technology Program under Grant ZDSYS20220527171400002, the Open Research Fund from Guangdong Laboratory of Artificial Intelligence and Digital Economy (SZ) under Grant GML-KF22-26, and the Guangdong "Pearl River Talent Recruitment Program" under Grant 2019ZT08X603.	Chen LQ, 2022, IEEE T VEH TECHNOL, V71, P4642, DOI 10.1109/TVT.2022.3150793; Chen M., 2021, arXiv; Friston K, 2019, Arxiv, DOI [arXiv:1906.10184, DOI 10.48550/ARXIV.1906.10184]; Friston K, 2016, NEUROSCI BIOBEHAV R, V68, P862, DOI 10.1016/j.neubiorev.2016.06.022; He Y, 2018, IEEE T VEH TECHNOL, V67, P44, DOI 10.1109/TVT.2017.2760281; He Y, 2017, IEEE COMMUN MAG, V55, P31, DOI 10.1109/MCOM.2017.1700246; He Y, 2017, IEEE T VEH TECHNOL, V66, P10433, DOI 10.1109/TVT.2017.2751641; Hu CH, 2022, IEEE INFOCOM SER, P330, DOI 10.1109/INFOCOM48880.2022.9796896; Li E, 2020, IEEE T WIREL COMMUN, V19, P447, DOI 10.1109/TWC.2019.2946140; Murphy Kevin P, 2000, environment, V2; SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x; Sheng Y, 2023, Arxiv, DOI arXiv:2303.06865; Tschantz A, 2020, Arxiv, DOI [arXiv:2002.12636, DOI 10.48550/ARXIV.2002.12636, 10.48550/arXiv.2002.12636]; Vaswani A, 2017, ADV NEUR IN, V30; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang YD, 2023, PROCEEDINGS OF THE EIGHTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, EUROSYS 2023, P233, DOI 10.1145/3552326.3587438; Zhou C, 2023, Arxiv, DOI [arXiv:2302.09419, DOI 10.48550/ARXIV.2302.09419]	17	0	0	5	5	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2577-2465		979-8-3503-2928-5	IEEE VTS VEH TECHNOL			2023										10.1109/VTC2023-Fall60731.2023.10333824	http://dx.doi.org/10.1109/VTC2023-Fall60731.2023.10333824			5	Automation & Control Systems; Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic; Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BW2ZI					2024-07-03	WOS:001133762500410
J	Briva-Iglesias, V; Camargo, JLC; Dogru, G				Briva-Iglesias, Vicent; Camargo, Joao Lucas Cavalheiro; Dogru, Gokhan			LARGE LANGUAGE MODELS "AD REFERENDUM": HOW GOOD ARE THEY AT MACHINE TRANSLATION IN THE LEGAL DOMAIN?	MONTI			English	Article						Machine translation; Human evaluation of translation quality; Large language models; Translation quality; Legal translation	QUALITY; PERCEPTIONS	This study evaluates the machine translation (MT) quality of two state-of-the-art large language models (LLMs) against a traditional neural machine translation (NMT) system across four language pairs in the legal domain. It combines automatic evaluation metrics (AEMs) and human evaluation (HE) by professional translators to assess translation ranking, fluency and adequacy. The results indicate that while Google Translate generally outperforms LLMs in AEMs, human evaluators rate LLMs, especially GPT-4, comparably or slightly better in terms of producing contextually adequate and fluent translations. This discrepancy suggests LLMs' potential in handling specialized legal terminology and context, highlighting the importance of human evaluation methods in assessing MT quality. The study underscores the evolving capabilities of LLMs in specialized domains and calls for reevaluation of traditional AEMs to better capture the nuances of LLM-generated translations.	[Briva-Iglesias, Vicent; Camargo, Joao Lucas Cavalheiro] Dublin City Univ, Dublin, Ireland; [Dogru, Gokhan] Univ Autonoma Barcelona, Barcelona, Spain	Dublin City University; Autonomous University of Barcelona	Briva-Iglesias, V (corresponding author), Dublin City Univ, Dublin, Ireland.	vicent.brivaiglesias2@mail.dcu.ie; joo.cavalheirocamargo2@mail.dcu.ie; gokhan.dogru@uab.cat						[Anonymous], 2022, European Language Industry Survey 2022: Trends, expectations and concerns of the European language industry; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bago P, 2022, REV LLENG DRET, P9, DOI 10.2436/rld.i78.2022.3741; BoRJA Anabel, 2019, Legal Translation: Current Issues and Challenges in Research Methods and Applications, P187; Briva-Iglesias V, 2022, TRADUMATICA, P149, DOI 10.5565/rev/tradumatica.303; BRIVA-IGLESIAS Vicent, 2021, Mutatis Mutandis, V14, P571, DOI [10.17533/udea.mut.v14n2a14, DOI 10.17533/UDEA.MUT.V14N2A14]; BRIVA-IGLESIAS Vicent, 2023, Translation, Cognition & Behavior, V6, P60, DOI [10.1075/tcb.00077.bri, DOI 10.1075/TCB.00077.BRI]; Cadwell P, 2016, TRANSL SPACES, V5, P222, DOI 10.1075/ts.5.2.04cad; CAo Deborah, 2007, Translating Law, DOI [10.21832/9781853599552, DOI 10.21832/9781853599552]; Castilho S, 2018, MACH TRANS TECH APPL, V1, P9, DOI 10.1007/978-3-319-91241-7_2; CASTILHo Sheila, 2021, 2021 P 6 C MACH TRAN, P566; CASTILHo Sheila, 2023, P 24 ANN C EUR ASS M; cASTILHO Sheila, 2023, Processamento de Linguagem Natural: Conceitos, Tecnicas e Aplicacoes em Portugues; Christopher ClackD., 2018, Journal of Digital Banking, V2, P338; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doherty S, 2017, IATIS YEARB, P131; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; EMT, 2022, European Master's in Translation Competence Framework 2022; Engberg J, 2020, INT J SEMIOTIC LAW, V33, P263, DOI 10.1007/s11196-020-09706-9; Görög A, 2014, TRADUMATICA, P443; GOTTI Fabrizio, 2008, P 8 C ASS MACH TRANS, P370; GROSSMAN Maura R., 2010, Richmond Journal of Law and Technology, V17, P1; Hacker P, 2023, Arxiv, DOI [arXiv:2302.02337, DOI 10.48550/ARXIV.2302.02337, 10.48550/arXiv.2302.02337, DOI 10.48550/AR-XIV.2302.02337]; HAN Jesse Michael, 2021, Unsupervised Neural Machine Translation with Generative Language Models Only; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; KENNY Dorothy, 2022, Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence; Killman J, 2022, REV LLENG DRET, P56, DOI 10.2436/rld.i78.2022.3831; KILLMAN Jeffrey, 2014, P 11 C ASS MACH TRAN, P85; Kocmi Tom, 2021, P 6 C MACHINE TRANSL, P478; KOEHN Philipp, 2017, P 1 WORKSHOP NEURAL, P28, DOI [10.18653/v1/W17-3204, DOI 10.18653/V1/W17-3204]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Läubli S, 2020, J ARTIF INTELL RES, V67, P653; LESzNyAK Agnes, 2019, 2019 P MACH TRANSL S, P16; Long SB, 2018, Arxiv, DOI [arXiv:1809.06537, 10.48550/arXiv.1809.06537, DOI 10.48550/ARXIV.1809.06537]; Lyu C, 2024, Arxiv, DOI [arXiv:2305.01181, 10.48550/arXiv.2305.01181, DOI 10.48550/ARXIV.2305.01181]; Martínez-Carrasco R, 2022, QUAD FILOL-ESTUD LIN, V27, P235, DOI 10.7203/QF.27.24618; MiLETO Fiorenza, 2019, H2D. Revista de Humanidades Digitais, V1, P1, DOI [10.21814/h2d.237, DOI 10.21814/H2D.237]; Moslem Y, 2023, Arxiv, DOI arXiv:2301.13294; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; NOONAN Nick, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4406907, DOI 10.2139/SSRN.4406907]; oBRiEN Sharon, 2022, Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence, P105, DOI [10.5281/zenodo.6759982, DOI 10.5281/ZENODO.6759982]; oViEDo-TRESPAlAcioS Oscar, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4346827, DOI 10.2139/SSRN.4346827]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Post M, 2018, Arxiv, DOI [arXiv:1804.08771, 10.48550/arXiv.1804.08771]; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Ragni V, 2022, PERSPECT STUD TRANSL, V30, P137, DOI 10.1080/0907676X.2021.1889005; Raunak V, 2021, Arxiv, DOI [arXiv:2104.06683, 10.48550/arXiv.2104.06683]; Rei R, 2020, Arxiv, DOI [arXiv:2009.09025, DOI 10.48550/ARXIV.2009.09025]; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P578; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P634; Rossi C, 2019, J SPEC TRANSL, P177; Sarcevic Susan., 1997, NEW APPROACH LEGAL T; sEBAsTiAN Glorin, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4363843, DOI 10.2139/SSRN.4363843]; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Shterionov D, 2018, MACH TRANSL, V32, P217, DOI 10.1007/s10590-018-9220-z; siu Sai Cheong, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4448091, DOI 10.2139/SSRN.4448091]; Snover M., 2006, P 7 C ASS MACH TRANS, P223; Sosoni V, 2022, REV LLENG DRET, P92, DOI 10.2436/rld.i78.2022.3704; Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; VANRoY Bram, 2023, P 24 ANN C EUR ASS M, P499; Vardaro J, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030041; Vieira LN, 2021, INFORM COMMUN SOC, V24, P1515, DOI 10.1080/1369118X.2020.1776370; Wang LY, 2023, Arxiv, DOI [arXiv:2304.02210, 10.48550/arXiv.2304.02210]; Way A, 2020, BLOOMSBURY COMPANION, P311; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; WIEsMANN Eva, 2019, Comparative Legilinguistics, V37, P117, DOI DOI 10.14746/CL.2019.37.4; YuE Thomas, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4346152, DOI 10.2139/SSRN.4346152]; Zhang B, 2023, Arxiv, DOI [arXiv:2301.07069, 10.48550/arXiv.2301.07069]; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	75	0	0	0	0	UNIV JAUME I	CASTELLO DE LA PLANA	AVE DE VICENT SOS BAYNAT, S-N, CASTELLO DE LA PLANA, 12071, SPAIN	1889-4178	1989-9335		MONTI	MonTI		2024	16						75	107		10.6035/MonTI.2024.16.02	http://dx.doi.org/10.6035/MonTI.2024.16.02			33	Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	UM1R3		Green Published, hybrid, Green Submitted			2024-07-03	WOS:001248391000003
J	Jiang, G; Ma, ZH; Zhang, L; Chen, JL				Jiang, Gang; Ma, Zhihao; Zhang, Liang; Chen, Jianli			EPlus-LLM: A large language model-based computing platform for automated building energy modeling	APPLIED ENERGY			English	Article						Large language models; Artificial intelligence; Machine learning; Building energy modeling; Automated simulation		Establishing building energy models (BEMs) for building design and analysis poses significant challenges due to demanding modeling efforts, expertise to use simulation software, and building science knowledge in practice. These make building modeling labor-intensive, hindering its widespread adoptions in building development. Therefore, to overcome these challenges in building modeling with enhanced automation in modeling practice, this paper proposes Eplus-LLM (EnergyPlus-Large Language Model) as the auto -building modeling platform, building on a fine-tuned large language model (LLM) to directly translate natural language description of buildings to established building models of various geometries, occupancy scenarios, and equipment loads. Through fine-tuning, the LLM (i.e., T5) is customized to digest natural language and simulation demands from users and convert human descriptions into EnergyPlus modeling files. Then, the Eplus-LLM platform realizes the automated building modeling through invoking the API of simulation software (i.e., the EnergyPlus engine) to simulate the auto -generated model files and output simulation results of interest. The validation process, involving four different types of prompts, demonstrates that Eplus-LLM reduces over 95% modeling efforts and achieves 100% accuracy in establishing BEMs while being robust to interference in usage, including but not limited to different tones, misspells, omissions, and redundancies. Overall, this research serves as the pioneering effort to customize LLM for auto -modeling purpose (directly build-up building models from natural language), aiming to provide a user-friendly human -AI interface that significantly reduces building modeling efforts. This work also further facilitates large-scale building model efforts, e.g., urban building energy modeling (UBEM), in modeling practice.	[Jiang, Gang; Ma, Zhihao; Chen, Jianli] Univ Utah, Salt Lake City, UT 84112 USA; [Zhang, Liang] Univ Arizona, Tucson, AZ USA	Utah System of Higher Education; University of Utah; University of Arizona	Chen, JL (corresponding author), Univ Utah, Salt Lake City, UT 84112 USA.	jianli.chen@utah.edu		Zhang, Liang/0000-0001-9884-5199; Ma, Zhihao/0000-0001-7831-389X	US Na- tional Science Foundation (NSF) [2311685]	US Na- tional Science Foundation (NSF)(National Science Foundation (NSF))	We would like to acknowledge the funding provided by the US Na- tional Science Foundation (NSF) . Award title: Elements: A Convergent Physics -based and Data -driven Computing Platform for Building Modeling (#2311685) .	Agarap A.F., 2018, arXiv, DOI DOI 10.48550/ARXIV.1803.08375; Al-Homoud MS, 2001, BUILD ENVIRON, V36, P421, DOI 10.1016/S0360-1323(00)00026-3; [Anonymous], 2024, 14:00--17:00.ISO13790:2008; [Anonymous], WELCOME TRNSYS TRANS; [Anonymous], 2015, VDI 6007 Blatt 1; Ansys, Engineering Simulation Software; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Ba JL., 2016, arXiv; Basha SHS, 2020, NEUROCOMPUTING, V378, P112, DOI 10.1016/j.neucom.2019.10.008; Britz D, 2017, Arxiv, DOI [arXiv:1703.03906, 10.48550/arXiv.1703.03906]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Chung HW, 2022, Arxiv, DOI arXiv:2210.11416; Dao T, 2022, Arxiv, DOI [arXiv:2205.14135, DOI 10.48550/ARXIV.2205.14135]; DesignBuilder Software Ltd-Home, ABOUT US; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding Y, 2022, BUILD SIMUL-CHINA, V15, P333, DOI 10.1007/s12273-021-0813-8; Donahue J, 2013, Arxiv, DOI [arXiv:1310.1531, 10.48550/arXiv.1310.1531, DOI 10.48550/ARXIV.1310.1531]; Dymola, 2023, Dassault Systemes; Peters ME, 2018, Arxiv, DOI arXiv:1802.05365; EnergyPlus, about us; eppy, 2022, PyPI; Grisoni F, 2023, CURR OPIN STRUC BIOL, V79, DOI 10.1016/j.sbi.2023.102527; Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y; He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]; IEA-International Energy Agency, 2024, IEA; Iooss B, 2010, arXiv, DOI DOI 10.48550/ARXIV.0909.0329; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kim D, 2024, Arxiv, DOI [arXiv:2312.15166, 10.48550/arXiv.2312.15166]; OpenStudio, 2024, ABOUT US; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pavlyshenko BM, 2023, Arxiv, DOI [arXiv:2308.13032, 10.48550/arXiv.2308.13032]; Radford A, 2024, Language models are unsupervised multitask learners; Radford A, 2024, Improving language understanding by generative pre-training; Raffel C, 2023, Arxiv, DOI arXiv:1910.10683; Schneider S, 2019, INTERSPEECH, P3465, DOI 10.21437/Interspeech.2019-1873; Shen S, 2023, Arxiv, DOI arXiv:2305.14705; Stanford CRFM, ABOUT US; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Wang Y, 2023, Arxiv, DOI arXiv:2305.07922; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Xiao GX, 2024, Arxiv, DOI arXiv:2309.17453; Yan D, 2008, BUILD SIMUL-CHINA, V1, P95, DOI 10.1007/s12273-008-8118-8; Zhang Y, 2022, INT J APPL EARTH OBS, V113, DOI 10.1016/j.jag.2022.102989; Zhou X, 2023, BUILD SIMUL-CHINA, V16, P2027, DOI 10.1007/s12273-023-1050-0	46	0	0	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0306-2619	1872-9118		APPL ENERG	Appl. Energy	AUG 1	2024	367								123431	10.1016/j.apenergy.2024.123431	http://dx.doi.org/10.1016/j.apenergy.2024.123431			13	Energy & Fuels; Engineering, Chemical	Science Citation Index Expanded (SCI-EXPANDED)	Energy & Fuels; Engineering	TS6Z0					2024-07-03	WOS:001243300500001
J	Xia, YF; Shi, ZX; Du, XY; Zheng, Q				Xia, Yufei; Shi, Zhengxu; Du, Xiaoying; Zheng, Qiong			Extracting narrative data via large language models for loan default prediction: when talk isn't cheap	APPLIED ECONOMICS LETTERS			English	Article; Early Access						Large language model; loan default prediction; narrative data; natural Language processing; bidirectional encoder representations from transform		We aim to examine how the Large Language Model (LLM) can contribute to loan default prediction by extracting narrative data. Based on a Chinese FinTech lending platform dataset, we employ four LLMs to predict the probability of default (PD-LLM) based on the narrative data and use the PD-LLM as an additional feature to predict default loans. The empirical results show that the narrative data contain some extra credit information and can hardly be regarded as 'cheap talks'. The extracted information via LLMs processes some predictive capability to predict default loan applications in both in- and out-of-sample analysis. The out-of-sample results indicate that including PD-LLM can significantly improve out-of-sample forecasting performance. At the same time, the rule-based linguistic characteristics and Word-Frequency-based Models hinder out-of-sample forecasting.	[Xia, Yufei; Shi, Zhengxu; Du, Xiaoying; Zheng, Qiong] Jiangsu Normal Univ, Business Sch, Xuzhou, Jiangsu, Peoples R China; [Xia, Yufei] Jiangsu Normal Univ, Business Sch, Xuzhou 221116, Jiangsu, Peoples R China	Jiangsu Normal University; Jiangsu Normal University	Xia, YF (corresponding author), Jiangsu Normal Univ, Business Sch, Xuzhou 221116, Jiangsu, Peoples R China.	6020180093@jsnu.edu.cn			National Natural Science Foundation of China [72103082, 72102091]; National Training Program of Innovation and Entrepreneurship for Undergraduates [202310320016Z]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Training Program of Innovation and Entrepreneurship for Undergraduates	The work was supported by the National Natural Science Foundation of China [72103082; 72102091], and the National Training Program of Innovation and Entrepreneurship for Undergraduates [202310320016Z].	Belkin M, 2019, P NATL ACAD SCI USA, V116, P15849, DOI 10.1073/pnas.1903070116; Dastile X, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106263; Dorfleitner G, 2016, J BANK FINANC, V64, P169, DOI 10.1016/j.jbankfin.2015.11.009; Herzenstein M, 2011, J MARKETING RES, V48, pS138, DOI 10.1509/jmkr.48.SPL.S138; Liang K, 2020, ELECTRON COMMER R A, V40, DOI 10.1016/j.elerap.2020.100947; Lun XT, 2023, APPL ECON LETT, DOI 10.1080/13504851.2023.2206608; Netzer O, 2019, J MARKETING RES, V56, P960, DOI 10.1177/0022243719852959; Xia YF, 2022, J FORECASTING, V41, P1669, DOI 10.1002/for.2891; Xia YF, 2020, J FORECASTING, V39, P260, DOI 10.1002/for.2625	9	0	0	30	35	ROUTLEDGE JOURNALS, TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OX14 4RN, OXON, ENGLAND	1350-4851	1466-4291		APPL ECON LETT	Appl. Econ. Lett.	2023 NOV 4	2023										10.1080/13504851.2023.2275647	http://dx.doi.org/10.1080/13504851.2023.2275647		NOV 2023	6	Economics	Social Science Citation Index (SSCI)	Business & Economics	X5MG9					2024-07-03	WOS:001098884100001
C	Mackie, I; Chatterjee, S; Dalton, J			ACM	Mackie, Iain; Chatterjee, Shubham; Dalton, Jeffrey			Generative Relevance Feedback with Large Language Models	PROCEEDINGS OF THE 46TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, SIGIR 2023			English	Proceedings Paper	46th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)	JUL 23-27, 2023	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval		Pseudo-Relevance Feedback; Text Generation; Document Retrieval		Current query expansion models use pseudo-relevance feedback to improve first-pass retrieval effectiveness; however, this fails when the initial results are not relevant. Instead of building a language model from retrieved results, we propose Generative Relevance Feedback (GRF) that builds probabilistic feedback models from long-form text generated from Large Language Models. We study the effective methods for generating text by varying the zero-shot generation subtasks: queries, entities, facts, news articles, documents, and essays. We evaluate GRF on document retrieval benchmarks covering a diverse set of queries and document collections, and the results show that GRF methods significantly outperform previous PRF methods. Specifically, we improve MAP between 5-19% and nDCG@10 17-24% compared to RM3 expansion, and achieve state-of-the-art recall across all datasets.	[Mackie, Iain; Chatterjee, Shubham; Dalton, Jeffrey] Univ Glasgow, Glasgow, Lanark, Scotland	University of Glasgow	Mackie, I (corresponding author), Univ Glasgow, Glasgow, Lanark, Scotland.	i.mackie.1@research.gla.ac.uk; shubham.chatterjee@glasgow.ac.uk; jeff.dalton@glasgow.ac.uk		Chatterjee, Shubham/0000-0002-6729-1346; Dalton, Jeff/0000-0003-2422-8651	2019 Bloomberg Data Science Research Grant; Engineering and Physical Sciences Research Council [EP/V025708/1]	2019 Bloomberg Data Science Research Grant; Engineering and Physical Sciences Research Council(UK Research & Innovation (UKRI)Engineering & Physical Sciences Research Council (EPSRC))	This work is supported by the 2019 Bloomberg Data Science Research Grant and the Engineering and Physical Sciences Research Council grant EP/V025708/1.	Abdul-Jaleel N., 2004, Computer Science Department Faculty Publication Series, P189; Belkin Nicholas J, 1982, J DOCUMENTATION, V1982; Bonifacio L, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P2387, DOI 10.1145/3477495.3531863; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chengxiang Zhai, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P403, DOI 10.1145/502585.502654; Chowdhery Aakanksha, 2022, ARXIVCSCL220402311; Craswell Nick, 2021, TEXT RETRIEVAL C TRE; Craswell Nick, 2020, TEXT RETRIEVAL C TRE; Dalton J, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P365, DOI 10.1145/2600428.2609628; Ferraretto Fernando, 2023, ARXIV230110521; Formal T, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2288, DOI 10.1145/3404835.3463098; Gao Luyu, 2022, ARXIV221210496; Huston Samuel, 2014, PARAMETERS LEARNED C; IDE AH, 2019, ONLINE PREPRINT, V6, DOI DOI 10.3390/SEPARATIONS6040045; Izacard Gautier, 2021, UNSUPERVISED DENSE I, DOI [DOI 10.48550/ARXIV.2112.09118, 10.48550/ARXIV.2112.09118]; Jeronymo Vitor, 2023, ARXIV230101820; Khattab O, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P39, DOI 10.1145/3397271.3401075; Lassance Carlos, 2023, ARXIV230212574; Li H, 2022, LECT NOTES COMPUT SC, V13185, P599, DOI 10.1007/978-3-030-99736-6_40; Li Hang, 2021, PSEUDO RELEVANCE FEE; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Lin J, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2356, DOI 10.1145/3404835.3463238; Lin SC, 2021, REPL4NLP 2021: PROCEEDINGS OF THE 6TH WORKSHOP ON REPRESENTATION LEARNING FOR NLP, P163; Lin Sheng-Chieh, 2020, ARXIV201011386; Liu Linqing, 2022, ARXIV221007093; MacAvaney S, 2022, LECT NOTES COMPUT SC, V13186, P305, DOI 10.1007/978-3-030-99739-7_38; MacAvaney Sean, 2021, ARXIV210804026; Macdonald C, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P4526, DOI 10.1145/3459637.3482013; Mackie I, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2335, DOI 10.1145/3404835.3463262; Mackie Iain, 2022, P 44 INT ACM SIGIR C; Meij E, 2010, INFORM PROCESS MANAG, V46, P448, DOI 10.1016/j.ipm.2009.09.005; Metzler Donald, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P311, DOI 10.1145/1277741.1277796; Naseri Shahrzad, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12656), P467, DOI 10.1007/978-3-030-72113-8_31; Nguyen T., 2016, MS MARCO: A Human Generated MAchine Reading COmprehension Dataset; Ouyang L., 2022, ADV NEURAL INFORM PR, V35, P27730, DOI 10.48550/ARXIV.2203.02155; Payne VL, 2005, COMP MED SY, P479, DOI 10.1109/CBMS.2005.64; Pereira J, 2023, LECT NOTES COMPUT SC, V13981, P534, DOI 10.1007/978-3-031-28238-6_44; Robertson S. E., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P232; Rocchio JJ, 1971, Relevance feedback in information retrieval; Samarinas Chris, 2022, ICTIR '22: Proceedings of the 2022 ACM SIGIR International Conference on Theory of Information Retrieval, P43, DOI 10.1145/3539813.3545138; Voorhees Ellen M., 2004, P 23 TEXT RETRIEVAL, P52; Wang X, 2023, ACM T WEB, V17, DOI 10.1145/3572405; Wang Xiao, 2022, ACM T WEB; Wei Jason, ADV NEURAL INFORM PR; Wu Zhaofeng, 2022, P 2022 C EMP METH NA; Xiong C., 2015, P INT C THEOR INF RE, P111, DOI 10.1145/2808194.2809446; XIONG L, INTERNATIONAL CONFER, DOI DOI 10.17775/CSEEJPES.2020.03590; Xu Y, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P59, DOI 10.1145/1571941.1571954; Yates A, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1154, DOI 10.1145/3437963.3441667; Yu HC, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P3592, DOI 10.1145/3459637.3482124; Zamani H, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P418, DOI 10.1145/3366423.3380126	51	2	2	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9408-6				2023							2026	2031		10.1145/3539618.3591992	http://dx.doi.org/10.1145/3539618.3591992			6	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2LG		Green Submitted			2024-07-03	WOS:001118084002015
J	Argerich, MF; Patiño-Martínez, M				Argerich, Mauricio Fadel; Patino-Martinez, Marta			Measuring and Improving the Energy Efficiency of Large Language Models Inference	IEEE ACCESS			English	Article						Energy measurement; Energy consumption; Training; Graphics processing units; Software measurement; Computational modeling; Large language models; energy efficiency; machine learning; deep learning; large language models		Recent improvements in the accuracy of machine learning (ML) models in the language domain have propelled their use in a multitude of products and services, touching millions of lives daily. These new levels of accuracy have been attained mainly through exponential growth in model size, creating a new category of models known as Large Language Models (LLMs) and leading to a substantial increase in computing and energy demands. While recent studies have focused on measuring and improving the energy consumption of LLMs during training, inference has received little attention. In this article, we present an approach to profile the energy consumption of LLMs during inference and leverage it to improve energy efficiency. For this, we deploy several state-of-the-art LLMs and observe how model size, number of layers, parallelized attention, and even vocabulary size affect their energy consumption. In addition, we leverage input batch size and different quantization levels to optimize their inference energy efficiency and latency.	[Argerich, Mauricio Fadel; Patino-Martinez, Marta] Univ Politecn Madrid, Escuela Tecn Super Ingn Informat, Madrid 28040, Spain	Universidad Politecnica de Madrid	Argerich, MF (corresponding author), Univ Politecn Madrid, Escuela Tecn Super Ingn Informat, Madrid 28040, Spain.	mauricio.fadel@alumnos.upm.es			Project QoSDATA PID2020-119461GB-I00	Project QoSDATA PID2020-119461GB-I00	No Statement Available	[Anonymous], 2021, NVIDIA Developer Nvidia Management Library (NVML); [Anonymous], 2023, arXiv, DOI [10.34740/KAGGLE/DSV/6443346, DOI 10.34740/KAGGLE/DSV/6443346]; Axboe J., 2021, FIO: Flexible I/O Tester, 2021; Beeching E., 2023, Open Lim Leaderboard; Benoit A., 2023, PyNVML: Python Bindings To the Nvidia Management Library; Biderman S., 2023, INT C MACHINE LEARNI, P2397; blogs.microsoft, Introducing Microsoft 365 Copilot: Your Copilot for Work; Borji A, 2022, Arxiv, DOI [arXiv:2210.00586, 10.48550/arXiv.2210.00586]; C. Core,, Chroma: The Al-native open-source embedding database," Version 0.4.10; Chase H., 2022, Langchain; Chowdhery A, 2023, J MACH LEARN RES, V24; Clark P, 2018, Arxiv, DOI arXiv:1803.05457; Concise, The New Way to Read News; Conover M., 2023, Company Blog Databricks; Courty B., 2024, MLCO2/codecarbon: V2.4.1, DOI [10.5281/zenodo.11171501, DOI 10.5281/ZENODO.11171501]; David Howard, 2010, Proceedings of the 16th ACM/IEEE International Symposium on Low Power Electronics and Design (ISLPED 2010), P189, DOI 10.1145/1840845.1840883; decoder, Gpt-4 Architecture, Datasets, Costs and More Leaked; Dettmers T., 2021, How to Use Bitsandbytes With Pytorch; Dettmers T., 2023, P INT C MACH LEARN, P7750; Dettmers T., 2024, Proc. Adv. Neural Inf. Process. Syst., V36; developer.nvidia, Nvidia System Management Interface; Devlin J., 2018, BERT PRE TRAINING DE; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Geng X., 2023, OpenLLaMA: An open reproduction of LLaMA; Henderson P, 2020, J MACH LEARN RES, V21; Hugging Face, Displaying Carbon Emissions for Your Model; Hutt G., 2019, Deliver high performance ml inference with aws inferentia; Kansal A., 2010, P 1 ACM S CLOUD COMP, P39; Kepler, 2022, Sustainable Computing 10; Khan KN, 2018, ACM TRANS MODELING P, V3, DOI 10.1145/3177754; Kim S, 2023, Arxiv, DOI arXiv:2302.14017; Ko H, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010141; Laurencon H., 2022, Advances in Neural Information Processing Systems, V35, P31809; Li D, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCES ON BIG DATA AND CLOUD COMPUTING (BDCLOUD 2016) SOCIAL COMPUTING AND NETWORKING (SOCIALCOM 2016) SUSTAINABLE COMPUTING AND COMMUNICATIONS (SUSTAINCOM 2016) (BDCLOUD-SOCIALCOM-SUSTAINCOM 2016), P477, DOI 10.1109/BDCloud-SocialCom-SustainCom.2016.76; Luccioni A. S., 2022, arXiv, DOI 10.48550/ARXIV.2211.02001; McDonald J, 2022, Arxiv, DOI arXiv:2205.09646; mlco2, MLCO2 and BCG GAMMA Codecarbon: Methodology; OpenAL, ChatGPT: Get Instant Answers, Find Creative Inspiration, and Learn Something New; Patterson D, 2021, Arxiv, DOI [arXiv:2104.10350, DOI 10.48550/ARXIV.2104.10350]; Petit B., 2023, Scaphandre," Version V1.0; Rabenstein B., 2015, Prometheus: A Next-Generation monitoring system (talk); reuters, Chatgpt Sets Record for Fastest-Growing User Base: Analyst Note; Schöne R, 2021, IEEE INT C CL COMP, P562, DOI 10.1109/Cluster48925.2021.00087; Starovoitov A., EBPF: A Technology for Dynamic Ker- nel Programming; Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693; Tallis B., 2018, AnandTech; TheBloke, 2023, Llama-2-7B-GGUF; Together Al, 2021, Redpajama Models VI; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; U.S. Energy Information Admin, Electricity Consumption by Country; Vaswani A, 2017, ADV NEUR IN, V30; Villalobos P, 2022, Arxiv, DOI arXiv:2207.02852; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu C.-J., 2022, Proceedings of Machine Learning and Systems, V4, P795; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	57	0	0	1	1	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						80194	80207		10.1109/ACCESS.2024.3409745	http://dx.doi.org/10.1109/ACCESS.2024.3409745			14	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	UL7L8		gold			2024-07-03	WOS:001248279100001
J	Zhang, WY; Guo, YS; Niu, LT; Li, PJ; Wan, ZY; Shao, F; Nian, C; Farrukh, FUD; Zhang, DB; Zhang, C; Li, Q; Zhang, JW				Zhang, Weiyi; Guo, Yushi; Niu, Liting; Li, Peijun; Wan, Zeyu; Shao, Fei; Nian, Cheng; Farrukh, Fasih Ud Din; Zhang, Debing; Zhang, Chun; Li, Qiang; Zhang, Jianwei			Lp-slam: language-perceptive RGB-D SLAM framework exploiting large language model	COMPLEX & INTELLIGENT SYSTEMS			English	Article; Early Access						Simultaneous localization and mapping (SLAM); Large language model (LLM); ChatGPT; Natural user interface (NUI)	OBJECT	With the development of deep learning, a higher level of perception of the environment such as the semantic level can be achieved in the simultaneous localization and mapping (SLAM) domain. However, previous works did not achieve a natural-language level of perception. Therefore, LP-SLAM (Language-Perceptive RGB-D SLAM) is proposed that leverages large language models (LLMs). The texts in the scene can be detected by scene text recognition (STR) and mapped as landmarks with a task-driven selection. A text error correction chain (TECC) is designed with a similarity classification method, a two-stage memory strategy, and a text clustering method. The proposed architecture is designed to deal with the mis-detection and mis-recognition cases of STR and to provide accurate text information to the framework. The proposed framework takes input images and generates a 3D map with sparse point cloud and task-related texts. Finally, a natural user interface (NUI) is designed based on the constructed map and LLM, which gives position instructions based on users' natural queries. The experimental results validated the proposed TECC design and the overall framework. We publish the virtual dataset with ground truth, as well as the source code for further research. https://github.com/GroupOfLPSLAM/LP_SLAM.	[Zhang, Weiyi; Guo, Yushi; Niu, Liting; Li, Peijun; Wan, Zeyu; Shao, Fei; Nian, Cheng; Farrukh, Fasih Ud Din; Zhang, Debing; Zhang, Chun] Tsinghua Univ, Sch Integrated Circuits, Beijing 100084, Peoples R China; [Li, Qiang; Zhang, Jianwei] Univ Hamburg, Fac Math, Informat & Nat Sci Dept Informat, Grp TAMS, Vogt Kolln Str 30, D-22527 Hamburg, Germany	Tsinghua University; University of Hamburg	Zhang, C (corresponding author), Tsinghua Univ, Sch Integrated Circuits, Beijing 100084, Peoples R China.; Li, Q (corresponding author), Univ Hamburg, Fac Math, Informat & Nat Sci Dept Informat, Grp TAMS, Vogt Kolln Str 30, D-22527 Hamburg, Germany.	zhangchun@tsinghua.edu.cn; liqiang_hn_cn@hotmail.com	Li, Peijun/GQP-3209-2022	Li, Peijun/0000-0002-5981-8304; Zhang, Weiyi/0000-0003-1296-3579	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	BAHL LR, 1989, IEEE T ACOUST SPEECH, V37, P1001, DOI 10.1109/29.32278; Bao SY, 2012, PROC CVPR IEEE, P2703, DOI 10.1109/CVPR.2012.6247992; Brown P. F., 1992, Computational Linguistics, V18, P467; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644; Chen BY, 2023, IEEE INT CONF ROBOT, P11509, DOI 10.1109/ICRA48891.2023.10161534; Chen K, 2022, IEEE ROBOT AUTOM LET, V7, P2000, DOI 10.1109/LRA.2022.3142739; Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049; Deli Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12110, DOI 10.1109/CVPR42600.2020.01213; DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060; Du Y., 2021, arXiv; Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412; Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54; Harris C., 1988, P 4 ALV VIS C, P147; He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]; Hirose K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.83; Klein George, 2007, P1; Labbé M, 2013, IEEE T ROBOT, V29, P734, DOI 10.1109/TRO.2013.2242375; LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845; Li BY, 2020, IEEE INT CONF ROBOT, P2102, DOI [10.1109/icra40945.2020.9197233, 10.1109/ICRA40945.2020.9197233]; Liu B, 2017, CHIN AUTOM CONGR, P6233, DOI 10.1109/CAC.2017.8243900; Liu MS, 2019, Arxiv, DOI arXiv:1903.10172; Mees O, 2023, IEEE INT CONF ROBOT, P11576, DOI 10.1109/ICRA48891.2023.10160396; Mo YC, 2023, IEEE INT CONF ROBOT, P8061, DOI 10.1109/ICRA48891.2023.10161333; Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103; Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671; Pan JY, 2023, Arxiv, DOI arXiv:2303.08006; Qian ZT, 2022, IEEE ROBOT AUTOM LET, V7, P2455, DOI 10.1109/LRA.2022.3145066; Qiyi Tong, 2022, 2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD), P728, DOI 10.1109/CSCWD54268.2022.9776293; Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544; Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474; Sarlin PE, 2020, PROC CVPR IEEE, P4937, DOI 10.1109/CVPR42600.2020.00499; Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939; Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371; SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Sünderhauf N, 2017, IEEE INT C INT ROBOT, P5079, DOI 10.1109/IROS.2017.8206392; Tellex S, 2020, ANNU REV CONTR ROBOT, V3, P25, DOI 10.1146/annurev-control-101119-071628; Vaswani A, 2017, ADV NEUR IN, V30; Vemprala SH, 2024, IEEE ACCESS, V12, P55682, DOI 10.1109/ACCESS.2024.3387941; Wang HC, 2014, LECT NOTES COMPUT SC, V8357, P3, DOI 10.1007/978-3-319-05167-3_1; Wang HC, 2015, IEEE INT C INT ROBOT, P3701, DOI 10.1109/IROS.2015.7353895; Wang WH, 2023, IEEE INT CONF ROBOT, P9800, DOI 10.1109/ICRA48891.2023.10160906; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu WX, 2022, NEURAL COMPUT APPL, V34, P6011, DOI 10.1007/s00521-021-06764-3; Xuejian Rong, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10073, P11, DOI 10.1007/978-3-319-50832-0_2; Yang SC, 2019, IEEE T ROBOT, V35, P925, DOI 10.1109/TRO.2019.2909168; Yang SC, 2019, IEEE ROBOT AUTOM LET, V4, P3145, DOI 10.1109/LRA.2019.2924848; Yang SC, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1222, DOI 10.1109/IROS.2016.7759204; Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691; Zubizarreta J, 2020, IEEE T ROBOT, V36, P1363, DOI 10.1109/TRO.2020.2991614; Zuo XX, 2017, IEEE INT C INT ROBOT, P1775, DOI 10.1109/IROS.2017.8205991	52	0	0	7	7	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2199-4536	2198-6053		COMPLEX INTELL SYST	COMPLEX INTELL. SYST.	2024 APR 30	2024										10.1007/s40747-024-01408-0	http://dx.doi.org/10.1007/s40747-024-01408-0		APR 2024	19	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	PM7E5		gold			2024-07-03	WOS:001214552800001
J	Yaghy, A; Yaghy, M; Shields, JA; Shields, CL				Yaghy, Antonio; Yaghy, Maria; Shields, Jerry A.; Shields, Carol L.			Large Language Models in Ophthalmology: Potential and Pitfalls	SEMINARS IN OPHTHALMOLOGY			English	Review						Clinical decision-making; ethical concerns; Large language models (LLMs); legal concerns; Ophthalmology; patient care; visually impaired		Large language models (LLMs) show great promise in assisting clinicians in general, and ophthalmology in particular, through knowledge synthesis, decision support, accelerating research, enhancing education, and improving patient interactions. Specifically, LLMs can rapidly summarize the latest literature to keep clinicians up-to-date. They can also analyze patient data to highlight crucial insights and recommend appropriate tests or referrals. LLMs can automate tedious research tasks like data cleaning and literature reviews. As AI tutors, LLMs can fill knowledge gaps and assess competency in trainees. As chatbots, they can provide empathetic, personalized responses to patient inquiries and improve satisfaction. The visual capabilities of LLMs like GPT-4 allow assisting the visually impaired by describing environments. However, there are significant ethical, technical, and legal challenges around the use of LLMs that should be addressed regarding privacy, fairness, robustness, attribution, and regulation. Ongoing oversight and refinement of models is critical to realize benefits while minimizing risks and upholding responsible AI principles. If carefully implemented, LLMs hold immense potential to push the boundaries of care, discovery, and quality of life for ophthalmology patients.	[Yaghy, Antonio; Shields, Jerry A.; Shields, Carol L.] Thomas Jefferson Univ, Wills Eye Hosp, Ocular Oncol Serv, Philadelphia, PA USA; [Yaghy, Maria] Ctr Hosp Univ Timone Enfants, Pediat Emergency & Infect Dis, Marseille, France; [Shields, Carol L.] Thomas Jefferson Univ, Wills Eye Hosp, Ocular Oncol Serv, 840 Walnut St, Philadelphia, PA 19107 USA	Jefferson University; Aix-Marseille Universite; Assistance Publique-Hopitaux de Marseille; Jefferson University	Shields, CL (corresponding author), Thomas Jefferson Univ, Wills Eye Hosp, Ocular Oncol Serv, 840 Walnut St, Philadelphia, PA 19107 USA.	carolshields@gmail.com	Yaghy, Antonio/AAN-8961-2020	Yaghy, Antonio/0000-0002-5054-495X				Abdel-Rahman MH, 2011, J MED GENET, V48, P856, DOI 10.1136/jmedgenet-2011-100156; ai.google, GOOGL AI PALM 2; [Anonymous], LLAM 2; [Anonymous], 2023, IMPROVED PERFORMANCE, DOI [10.1101/2023.04.03.23287957v1, DOI 10.1101/2023.04.03.23287957V1]; anthropic, CLAUD 2 ANTHR; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; bemyeyes, BE MY EYES SEE WORLD; Chew HSJ, 2022, JMIR MED INF, V10, P4, DOI 10.2196/32578; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Densen Peter, 2011, Trans Am Clin Climatol Assoc, V122, P48; Drukker K, 2023, J MED IMAGING, V10, DOI 10.1117/1.JMI.10.6.061104; Ellaway RH, 2023, ADV HEALTH SCI EDUC, V28, P659, DOI 10.1007/s10459-023-10257-4; Huang J., 2022, arXiv; Johnmaeda, LLM TOK; Judson TJ, 2020, J AM MED INFORM ASSN, V27, P1450, DOI 10.1093/jamia/ocaa130; Krauss E, 2022, OPHTHALMIC GENET, V43, P633, DOI 10.1080/13816810.2022.2096243; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Masoomian B, 2018, J CURR OPHTHALMOL, V30, P102, DOI 10.1016/j.joco.2018.02.005; Mehdi Y., OFFICIAL MICROS 0504; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Murdoch B, 2021, BMC MED ETHICS, V22, DOI 10.1186/s12910-021-00687-3; openai, BE MY EYES; openai, GPT4; Pournaras E., 2023, ARXIV; Tamkin A., 2021, arXiv; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Tsai WHS, 2021, PSYCHOL MARKET, V38, P2377, DOI 10.1002/mar.21556; Watkins R., 2023, AI Ethics, DOI [10.1007/s43681-023-00294-5, DOI 10.1007/S43681-023-00294-5]; Yaghy Antonio, 2022, Retin Cases Brief Rep, V16, P194, DOI 10.1097/ICB.0000000000000934; Zhang Z, 2021, J MED SYST, V45, DOI 10.1007/s10916-021-01743-6; Zhou Q, 2023, COMPUT HUM BEHAV, V143, DOI 10.1016/j.chb.2023.107674	31	2	2	15	15	TAYLOR & FRANCIS INC	PHILADELPHIA	530 WALNUT STREET, STE 850, PHILADELPHIA, PA 19106 USA	0882-0538	1744-5205		SEMIN OPHTHALMOL	Semin. Ophthalmol.	MAY 18	2024	39	4					289	293		10.1080/08820538.2023.2300808	http://dx.doi.org/10.1080/08820538.2023.2300808		JAN 2024	5	Ophthalmology	Science Citation Index Expanded (SCI-EXPANDED)	Ophthalmology	MF1H6	38179986				2024-07-03	WOS:001137060700001
J	Cobb, PJ				Cobb, Peter J.			Large Language Models and Generative AI, Oh My!	ADVANCES IN ARCHAEOLOGICAL PRACTICE			English	Review							ARCHAEOLOGY	We have all read the headlines heralding, often hyperbolically, the latest advances in text- and image-based Artificial Intelligence (AI). What is perhaps most unique about these developments is that they now make relatively good AI accessible to the average Internet user. These new services respond to human prompts, written in natural language, with generated output that appears to satisfy the prompt. Consequently, they are categorized under the term "generative AI," whether they are generating text, images, or other media. They work by modeling human language statistically, to "learn" patterns from extremely large datasets of human-created content, with those that specifically focus on text therefore called Large Language Models (LLMs). As we have all tried products such as ChatGPT or Midjourney over the past year, we have undoubtedly begun to wonder how and when they might impact our archaeological work. Here, I review the state of this type of AI and the current challenges with using it meaningfully, and I consider its potential for archaeologists.	[Cobb, Peter J.] Univ Hong Kong, Fac Arts, Sch Humanities, Pokfulam, Hong Kong, Peoples R China	University of Hong Kong	Cobb, PJ (corresponding author), Univ Hong Kong, Fac Arts, Sch Humanities, Pokfulam, Hong Kong, Peoples R China.	pcobb@hku.hk						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agapiou A, 2023, HERITAGE-BASEL, V6, P4072, DOI 10.3390/heritage6050214; Bickler SH, 2021, ADV ARCHAEOL PRACT, V9, P186, DOI 10.1017/aap.2021.6; Billy Perrigo, 2023, Time Magazine; Chris Caren, 2023, Turnitin (blog); Cobb P.J., 2022, Academic Praxis, V2, P1; Cobb PJ, 2023, NEAR EAST ARCHAEOL, V86, P240, DOI 10.1086/725775; Cyrus Wong, 2023, Microsoft Educator Developer (blog)May 5; Eberl M, 2023, ADV ARCHAEOL PRACT, V11, P152, DOI 10.1017/aap.2022.35; Floridi L., 2023, PHILOS TECHNOLOGY, V36, P15; Howell Christopher W., 2023, Wired; Irina Ivanova., 2023, CBS News (MoneyWatch)January 20; Jane Ostler, 2023, Kantar.com; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Josh Taylor, 2023, Guardian; Kansa E, 2021, ADV ARCHAEOL PRACT, V9, P81, DOI 10.1017/aap.2020.55; Khan Y, 2022, ADV ARCHAEOL PRACT, V10, P452, DOI 10.1017/aap.2022.28; Klehm C, 2023, ADV ARCHAEOL PRACT, V11, P104, DOI 10.1017/aap.2022.38; Landa YR, 2023, ADV ARCHAEOL PRACT, V11, P258, DOI 10.1017/aap.2023.7; Liang JF, 2021, ADV ARCHAEOL PRACT, V9, P250, DOI 10.1017/aap.2021.16; Newport Cal, 2023, New Yorker; Noah Harari Yuval, 2017, The Rise of the Useless Class. TED Ideas, excerpted from Homo Deus: A Brief History of Tomorrow; OpenAI, 2022, OpenA I; Petrosyan A, 2021, ADV ARCHAEOL PRACT, V9, P402, DOI 10.1017/aap.2021.30; Ryan Watkins, 2022, Medium; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tom Acres, 2022, Sky News; Trichopoulos G, 2023, Preprints, DOI [10.20944/preprints202306.1618.v1, 10.20944/preprints202306.1618.v1, DOI 10.20944/PREPRINTS202306.1618.V1]; Vaswani A, 2017, ADV NEUR IN, V30; Yurtsever Adem., 2023, Cultural Heritage and Science, V4, P31, DOI [10.58598/cuhes.1278735, DOI 10.58598/CUHES.1278735]	30	3	3	16	30	CAMBRIDGE UNIV PRESS	NEW YORK	32 AVENUE OF THE AMERICAS, NEW YORK, NY 10013-2473 USA	2326-3768			ADV ARCHAEOL PRACT	Adv. Archaeol. Pract.	AUG	2023	11	3			SI		363	369		10.1017/aap.2023.20	http://dx.doi.org/10.1017/aap.2023.20			7	Archaeology	Arts &amp; Humanities Citation Index (A&amp;HCI)	Archaeology	S4SZ7		hybrid			2024-07-03	WOS:001071095300010
C	Zhou, YC; Huang, HY; Wu, ZJ			ACM	Zhou, Youchao; Huang, Heyan; Wu, Zhijing			Boosting legal case retrieval by query content selection with large language models	ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL IN THE ASIA PACIFIC REGION, SIGIR-AP 2023			English	Proceedings Paper	1st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region (SIGIR-AP)	NOV 26-28, 2023	Beijing, PEOPLES R CHINA	Assoc Comp Machinery, ACM SIGIR, Xiaohongshu, Zhipu AI, Kuaishou		Content selection; Query reformulation; Legal case retrieval; Large language models		Legal case retrieval, which aims to retrieve relevant cases to a given query case, benefits judgment justice and attracts increasing attention. Unlike generic retrieval queries, legal case queries are typically long and the definition of relevance is closely related to legal-specific elements. Therefore, legal case queries may suffer from noise and sparsity of salient content, which hinders retrieval models from perceiving correct information in a query. While previous studies have paid attention to improving retrieval models and understanding relevance judgments, we focus on enhancing legal case retrieval by utilizing the salient content in legal case queries. We first annotate the salient content in queries manually and investigate how sparse and dense retrieval models attend to those content. Then we experiment with various query content selection methods utilizing large language models (LLMs) to extract or summarize salient content and incorporate it into the retrieval models. Experimental results show that reformulating long queries using LLMs improves the performance of both sparse and dense models in legal case retrieval.	[Zhou, Youchao; Huang, Heyan; Wu, Zhijing] Southeast Acad Informat Technol, Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Sch Comp Sci & Technol, Beijing, Peoples R China	Beijing Institute of Technology	Huang, HY (corresponding author), Southeast Acad Informat Technol, Beijing Inst Technol, Beijing Engn Res Ctr High Volume Language Informa, Sch Comp Sci & Technol, Beijing, Peoples R China.	yczhou@bit.edu.cn; hhy63@bit.edu.cn; zhijingwu@bit.edu.cn		Zhou, Youchao/0009-0005-3563-5625; Wu, Zhijing/0000-0003-2473-3746	National Natural Science Foundation of China [U21B2009, 62302040]; China Postdoctoral Science Foundation [2022TQ0033]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); China Postdoctoral Science Foundation(China Postdoctoral Science Foundation)	This work was supported by the National Natural Science Foundation of China (No. U21B2009 and 62302040) and the China Postdoctoral Science Foundation (No. 2022TQ0033).	Abolghasemi A, 2022, LECT NOTES COMPUT SC, V13186, P3, DOI 10.1007/978-3-030-99739-7_1; An Zhenwei, 2022, arXiv; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Askari A, 2022, Arxiv, DOI arXiv:2205.13351; Askari Arian, 2021, BIENNIAL C DESIGN EX; Bench-Capon T, 2012, ARTIF INTELL LAW, V20, DOI 10.1007/s10506-012-9131-x; Bendersky Michael, 2008, ANN INT ACM SIGIR C; Clark Kevin, 2019, BLACKBOXNLP ACL; Gao LY, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL 2023, VOL 1, P1762; Gehrmann S, 2018, Arxiv, DOI arXiv:1808.10792; Hong ZL, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207528; Jiang Zhiying, 2021, BLACKBOXNLP WORKSHOP; Kano Yoshinobu, 2018, JSAIISAI WORKSHOPS; Khashabi Daniel, 2020, Findings; Koh HY, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3545176; Li H, 2023, P 46 INT ACM SIGIR C, P1; Li HT, 2023, Arxiv, DOI arXiv:2305.06812; Li Xiangsheng, 2022, P 15 ACM INT C WEB S; Locke Daniel, 2017, ASIA INFORM RETRIEVA; Ma YX, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P2342, DOI 10.1145/3404835.3463250; Mao KL, 2023, Arxiv, DOI arXiv:2303.06573; Mitra B, 2017, Arxiv, DOI arXiv:1705.01509; Nogueira R, 2020, Arxiv, DOI [arXiv:1901.04085, DOI 10.48550/ARXIV.1901.04085]; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0; Shao YQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3501; Shao Yunqiu, 2022, ACM Transactions on Information Systems, V41, P1; Tian YD, 2023, Arxiv, DOI arXiv:2305.16380; Tran Vu Mai, 2019, P 17 INT C ART INT L; Wu ZJ, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2421, DOI 10.1145/3366423.3380305; Wu ZJ, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P605, DOI 10.1145/3331184.3331233; Xiao CJ, 2019, Arxiv, DOI arXiv:1911.08962; Yu WJ, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P657, DOI 10.1145/3477495.3531974; Zhai C, 2008, SYNTHESIS LECT HUMAN, V1, P1, DOI [10.2200/S00158ED1V01Y200811HLT001, DOI 10.2200/S00158ED1V01Y200811HLT001]	35	0	0	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0408-6				2023							176	184		10.1145/3624918.3625328	http://dx.doi.org/10.1145/3624918.3625328			9	Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2NW		Green Submitted			2024-07-03	WOS:001122582700020
J	Clusmann, J; Kolbinger, FR; Muti, HS; Carrero, ZI; Eckardt, JN; Laleh, NG; Löffler, CML; Schwarzkopf, SC; Unger, M; Veldhuizen, GP; Wagner, SJ; Kather, JN				Clusmann, Jan; Kolbinger, Fiona R.; Muti, Hannah Sophie; Carrero, Zunamys I.; Eckardt, Jan-Niklas; Laleh, Narmin Ghaffari; Loeffler, Chiara Maria Lavinia; Schwarzkopf, Sophie-Caroline; Unger, Michaela; Veldhuizen, Gregory P.; Wagner, Sophia J.; Kather, Jakob Nikolas			The future landscape of large language models in medicine	COMMUNICATIONS MEDICINE			English	Article							PATIENT SAFETY; COMMUNICATION; IMPACT; CARE	Large language models (LLMs) are artificial intelligence (AI) tools specifically trained to process and generate text. LLMs attracted substantial public attention after OpenAI's ChatGPT was made publicly available in November 2022. LLMs can often answer questions, summarize, paraphrase and translate text on a level that is nearly indistinguishable from human capabilities. The possibility to actively interact with models like ChatGPT makes LLMs attractive tools in various fields, including medicine. While these models have the potential to democratize medical knowledge and facilitate access to healthcare, they could equally distribute misinformation and exacerbate scientific misconduct due to a lack of accountability and transparency. In this article, we provide a systematic and comprehensive overview of the potentials and limitations of LLMs in clinical practice, medical research and medical education. Clusmann et al. describe how large language models such as ChatGPT could be used in medical practice, research and education. These models could democratize medical knowledge and facilitate access to healthcare, but there are also potential limitations to be considered.	[Clusmann, Jan; Kolbinger, Fiona R.; Muti, Hannah Sophie; Carrero, Zunamys I.; Eckardt, Jan-Niklas; Laleh, Narmin Ghaffari; Loeffler, Chiara Maria Lavinia; Unger, Michaela; Veldhuizen, Gregory P.; Kather, Jakob Nikolas] TUD Dresden Univ Technol, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany; [Clusmann, Jan; Laleh, Narmin Ghaffari; Kather, Jakob Nikolas] Univ Hosp RWTH Aachen, Dept Med 3, Aachen, Germany; [Kolbinger, Fiona R.; Muti, Hannah Sophie; Schwarzkopf, Sophie-Caroline] TUD Dresden Univ Technol, Univ Hosp, Dept Visceral Thorac & Vasc Surg, Dresden, Germany; [Kolbinger, Fiona R.; Muti, Hannah Sophie; Schwarzkopf, Sophie-Caroline] TUD Dresden Univ Technol, Fac Med Carl Gustav Carus, Dresden, Germany; [Eckardt, Jan-Niklas; Loeffler, Chiara Maria Lavinia; Kather, Jakob Nikolas] Univ Hosp Dresden, Dept Med 1, Dresden, Germany; [Wagner, Sophia J.] German Res Ctr Environm & Hlth, Helmholtz Munich, Munich, Germany; [Wagner, Sophia J.] Tech Univ Munich, Sch Computat Informat & Technol, Munich, Germany; [Kather, Jakob Nikolas] Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany	RWTH Aachen University; RWTH Aachen University Hospital; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Technische Universitat Dresden; Technische Universitat Dresden; Carl Gustav Carus University Hospital; Helmholtz Association; Helmholtz-Center Munich - German Research Center for Environmental Health; Technical University of Munich; Helmholtz Association; German Cancer Research Center (DKFZ); Ruprecht Karls University Heidelberg	Kather, JN (corresponding author), TUD Dresden Univ Technol, Else Kroener Fresenius Ctr Digital Hlth, Dresden, Germany.; Kather, JN (corresponding author), Univ Hosp RWTH Aachen, Dept Med 3, Aachen, Germany.; Kather, JN (corresponding author), Univ Hosp Dresden, Dept Med 1, Dresden, Germany.; Kather, JN (corresponding author), Univ Hosp Heidelberg, Natl Ctr Tumor Dis NCT, Med Oncol, Heidelberg, Germany.	jakob-nikolas.kather@alumni.dkfz.de	Muti, Hannah/GQB-4044-2022; Wagner, Sophia/HII-6467-2022; Kolbinger, Fiona/ABG-4194-2020; Kather, Jakob Nikolas/D-4279-2015	Kolbinger, Fiona/0000-0003-2265-4809; Kather, Jakob Nikolas/0000-0002-3730-5348; Eckardt, Jan-Niklas/0000-0002-3649-2823; Carrero, Zunamys/0000-0001-8501-1566; Clusmann, Jan/0000-0003-2925-8438; Veldhuizen, Gregory/0000-0001-7364-8498; Unger, Michaela/0000-0001-5811-0200	Add-on Fellowship of the Joachim Herz Foundation; Helmholtz Association under the joint research school "Munich School for Data Science-MUDS"; BMBF (Federal Ministry of Education and Research) in DAAD project as part of the program Konrad Zuse Schools of Excellence in Artificial Intelligence [57616814]; German Federal Ministry of Health (DEEP LIVER) [ZMVI1-2520DAT111]; Max-Eder-Programme of the German Cancer Aid [70113864]; German Federal Ministry of Education and Research (PEARL) [01KD2104C]; German Academic Exchange Service (SECAI) [57616814]	Add-on Fellowship of the Joachim Herz Foundation; Helmholtz Association under the joint research school "Munich School for Data Science-MUDS"; BMBF (Federal Ministry of Education and Research) in DAAD project as part of the program Konrad Zuse Schools of Excellence in Artificial Intelligence; German Federal Ministry of Health (DEEP LIVER); Max-Eder-Programme of the German Cancer Aid; German Federal Ministry of Education and Research (PEARL); German Academic Exchange Service (SECAI)	F.R.K. and S.J.W. were supported by the Add-on Fellowship of the Joachim Herz Foundation. S.J.W. was supported by the Helmholtz Association under the joint research school "Munich School for Data Science-MUDS". G.P.V. was supported by BMBF (Federal Ministry of Education and Research) in DAAD project 57616814 (SECAI, School of Embedded Composite AI, https://secai.org/) as part of the program Konrad Zuse Schools of Excellence in Artificial Intelligence. J.N.K. is supported by the German Federal Ministry of Health (DEEP LIVER, ZMVI1-2520DAT111) and the Max-Eder-Programme of the German Cancer Aid (grant #70113864), the German Federal Ministry of Education and Research (PEARL, 01KD2104C), and the German Academic Exchange Service (SECAI, 57616814).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agarwal R, 2010, J HEALTHC MANAG, V55, P265, DOI 10.1097/00115514-201007000-00007; Agniel D, 2018, BMJ-BRIT MED J, V361, DOI 10.1136/bmj.k1479; Alec Radford, 2022, P 40 INT C MACH LEAR, DOI DOI 10.48550/ARXIV.2212.04356; [Anonymous], 2023, NATURE, V613, P612, DOI 10.1038/d41586-023-00191-1; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Baker DW, 1996, JAMA-J AM MED ASSOC, V275, P783, DOI 10.1001/jama.275.10.783; Becker G, 2010, BMC HEALTH SERV RES, V10, DOI 10.1186/1472-6963-10-94; Beltagy I, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3615; Bianchi MG, 2021, J TELEMED TELECARE, V27, P166, DOI 10.1177/1357633X19864829; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Börve A, 2015, ACTA DERM-VENEREOL, V95, P186, DOI 10.2340/00015555-1906; Börve A, 2009, J TELEMED TELECARE, V15, P421, DOI 10.1258/jtt.2009.009002; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Caufield JH, 2023, Arxiv, DOI arXiv:2304.02711; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Chowdhery A., 2023, Journal of Machine Learning Research, V24, P1; de Moissac D, 2019, J PATIENT EXPERIENCE, V6, P24, DOI 10.1177/2374373518769008; Devaraj Ashwin, 2022, Proc Conf Assoc Comput Linguist Meet, V2022, P7331, DOI 10.18653/v1/2022.acl-long.506; Devaraj A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4972, DOI 10.18653/v1/2021.naacl-main.395; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Fleisig E., 2023, Long Papers, V1, P6231; Gao CA, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00819-6; Gao L., 2023, INT C MACHINE LEARNI, P10835; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Henderson P, 2022, Arxiv, DOI [arXiv:2207.00220, DOI 10.48550/ARXIV.2207.00220]; Huffman S., 2023, PaLM API & MakerSuite: an approachable way to start prototyping and building generative AI applications; Huguet C, 2021, 7TH INTERNATIONAL CONFERENCE ON HIGHER EDUCATION ADVANCES (HEAD'21), P163, DOI 10.4995/HEAd21.2021.12811; Hutson M, 2022, NATURE, V611, P192, DOI 10.1038/d41586-022-03479-w; Iyer S, 2022, Arxiv, DOI [arXiv:2212.12017, 10.48550/arXiv.2212.12017, DOI 10.48550/ARXIV.2212.12017]; Jernite Yacine, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P2206, DOI 10.1145/3531146.3534637; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kripalani S, 2007, JAMA-J AM MED ASSOC, V297, P831, DOI 10.1001/jama.297.8.831; Kumar S, 2023, 17TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EACL 2023, P3299; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Ma Y., 2022, P WORKSH TEXT SIMPL, P173; Monteiro MG, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.948187; Monteiro MG, 2023, JMIR FORM RES, V7, DOI 10.2196/43165; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; OpenAI, 2023, ChatGPT plugins; OpenAI, 2023, March 20 ChatGPT Outage: Here's What Happened; Park M, 2023, NATURE, V613, P138, DOI 10.1038/s41586-022-05543-x; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Saadé RG, 2012, COMPUT HUM BEHAV, V28, P1608, DOI 10.1016/j.chb.2012.03.025; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Samoilenko R., 2023, Syst. Weakness; Sanderson K, 2023, NATURE, V615, P773, DOI 10.1038/d41586-023-00816-5; Sandström U, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0166149; Sarewitz D, 2016, NATURE, V533, P147, DOI 10.1038/533147a; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schulman J, 2022, Introducing chatgpt; Sha L., 2022, P 29 INT C COMP LING, P1275; Shaikh O., 2023, Long Papers, V1, P4454; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Smith S, 2022, arXiv; Stiennon N., 2020, Advances in Neural Information Processing Systems, V33, P3008; Stokel-Walker C, 2023, NATURE, V614, P214, DOI 10.1038/d41586-023-00340-6; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Susnjak T., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.09292, 10.48550/arXiv.2212.09292]; Tamkin A, 2021, Arxiv, DOI [arXiv:2102.02503, DOI 10.48550/ARXIV.2102.02503]; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wen J, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1207; Xiu Y, 2020, J INF TECHNOL EDUC-R, V19, P41, DOI 10.28945/4500; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	74	63	64	32	50	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND	2730-664X			COMMUN MED-LONDON	Communications Med.	OCT 10	2023	3	1							141	10.1038/s43856-023-00370-1	http://dx.doi.org/10.1038/s43856-023-00370-1			8	Medicine, Research & Experimental	Emerging Sources Citation Index (ESCI)	Research & Experimental Medicine	T5TE1	37816837	gold, Green Published			2024-07-03	WOS:001078603900001
J	Tyler, C; Akerlof, KL; Allegra, A; Arnold, Z; Canino, H; Doornenbal, MA; Goldstein, JA; Pedersen, DB; Sutherland, WJ				Tyler, Chris; Akerlof, K. L.; Allegra, Alessandro; Arnold, Zachary; Canino, Henriette; Doornenbal, Marius A.; Goldstein, Josh A.; Pedersen, David Budtz; Sutherland, William J.			AI tools as science policy advisers? The potential and the pitfalls	NATURE			English	Editorial Material; Early Access						Machine learning; Policy; Computer science; Government		Large language models and other artificial-intelligence systems could be excellent at synthesizing scientific evidence for policymakers - but only with appropriate safeguards and humans in the loop. Large language models and other artificial-intelligence systems could be excellent at synthesizing scientific evidence for policymakers - but only with appropriate safeguards and humans in the loop.	[Tyler, Chris; Canino, Henriette] UCL, Dept Sci Technol Engn & Publ Policy STEaPP, London, England; [Akerlof, K. L.] George Mason Univ, Dept Environm Sci & Policy, Fairfax, VA USA; [Allegra, Alessandro] UCL, Dept Sci & Technol Studies, London, England; [Allegra, Alessandro] European Commiss, Gen Res & Innovat, Brussels, Belgium; [Arnold, Zachary] Georgetown Univ, Ctr Secur & Emerging Technol, Emerging Technol Observ, Washington, DC USA; [Doornenbal, Marius A.] Elsevier, Amsterdam, Netherlands; [Goldstein, Josh A.] Georgetown Univ, Ctr Secur & Emerging Technol, Washington, DC USA; [Pedersen, David Budtz] Aalborg Univ, Dept Commun & Psychol, Sci Commun, Copenhagen, Denmark; [Sutherland, William J.] Univ Cambridge, Dept Zool, Conservat Sci Grp, Cambridge, England	University of London; University College London; George Mason University; University of London; University College London; Georgetown University; Georgetown University; Aalborg University; University of Cambridge	Tyler, C (corresponding author), UCL, Dept Sci Technol Engn & Publ Policy STEaPP, London, England.	cptyler@ucl.ac.uk		Tyler, Chris/0000-0001-5403-372X; Doornenbal, Marius/0000-0001-6319-850X; Pedersen, David Budtz/0000-0001-7861-7068				Amano T., 2016, PLOS Biology, V14, pe20009333, DOI DOI 10.1371/JOURNAL.PBIO.2000933; Anon, 2023, NAT MACH INTELL, V5, P1, DOI [10.1038/s42256-023-00613-9, DOI 10.1038/S42256-023-00613-9]; Burgelman JC, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00043; Cavelty MD, 2022, CSS STUD SEC INT REL, P1, DOI 10.4324/9781003110224-1; Dougherty MR, 2022, ROY SOC OPEN SCI, V9, DOI 10.1098/rsos.220334; Dunham J, 2020, Arxiv, DOI arXiv:2002.07143; Feng SB, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P11737; Horder J, 2023, NAT HUM BEHAV, V7, P168, DOI 10.1038/s41562-022-01468-7; Marshall IJ, 2019, SYST REV-LONDON, V8, DOI 10.1186/s13643-019-1074-9; Martin PA, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2221911120; Retkowski F, 2023, Arxiv, DOI arXiv:2305.04853; Sutherland WJ, 2019, BIOL CONSERV, V238, DOI 10.1016/j.biocon.2019.108199; Sutherland WJ, 2014, ECOL SOC, V19, DOI 10.5751/ES-06082-190203; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Yoong S. L., 2023, Cochrane Database System. Rev, V8, pCD013862	15	3	3	13	21	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	2023 SEP 27	2023										10.1038/d41586-023-02999-3	http://dx.doi.org/10.1038/d41586-023-02999-3		SEP 2023	4	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	T9DJ0	37759118	Bronze			2024-07-03	WOS:001080913200006
J	Alonso-Robisco, A; Carbo, JM				Alonso-Robisco, Andres; Carbo, Jose Manuel			Analysis of CBDC narrative by central banks using large language models	FINANCE RESEARCH LETTERS			English	Article						ChatGPT BERT CBDC Digital money		One topic that is gaining importance in central bank communication is central bank digital currency (CBDC). To better understand central banks' stance towards CBDCs, we used different natural language processing techniques on a set of central bank speeches. We found that the sentiment calculated by Large Language Models, and in particular by ChatGPT, is the one that most resembles the sentiment identified by human experts in those same speeches. Our study suggests that LLMs are an effective tool for improving sentiment measurements on specific policy texts, although they are not infallible and may be subject to new risks.	[Alonso-Robisco, Andres; Carbo, Jose Manuel] Banco Espana, Madrid, Spain	Banco de Espana	Carbo, JM (corresponding author), Banco Espana, Madrid, Spain.	jose.carbo@bde.es	Alonso, Andres/ADX-1311-2022	Alonso, Andres/0000-0001-7490-8044; Carbo, Jose Manuel/0000-0002-7446-898X				Auer R., 2022, Central bank digital currencies: a new tool in the financial inclusion toolkit?; Auer R., 2020, BANK INT SETTLEMENTS; Auer R, 2020, BIS Quarterly Review, V85; Auer R, 2022, ANNU REV ECON, V14, P697, DOI 10.1146/annurev-economics-051420-020324; Burlon Lorenzo, 2022, Working Paper Series, V2689; Davoodalhosseini SM, 2022, J ECON DYN CONTROL, V142, DOI 10.1016/j.jedc.2021.104150; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Hansen Anne Lundgaard, 2023, Can ChatGPT Decipher Fedspeak?; Korinek A., 2023, Cambridge, MA, DOI DOI 10.3386/W30957; Loughran T, 2011, J FINANC, V66, P35, DOI 10.1111/j.1540-6261.2010.01625.x; Mckay A, 2016, AM ECON REV, V106, P3133, DOI 10.1257/aer.20150063; Minesso MF, 2022, J MONETARY ECON, V127, P54, DOI 10.1016/j.jmoneco.2022.02.001; Scharnowski S, 2022, FINANC RES LETT, V49, DOI 10.1016/j.frl.2022.103072; Strubell E, 2019, Arxiv, DOI arXiv:1906.02243; Tian S, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2022.103609; Wang YZ, 2022, TECHNOL FORECAST SOC, V180, DOI 10.1016/j.techfore.2022.121715; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Yang Y, 2020, Arxiv, DOI arXiv:2006.08097; Zhang Boyu, 2023, arXiv	20	3	3	26	35	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1544-6123	1544-6131		FINANC RES LETT	Financ. Res. Lett.	DEC	2023	58		C						104643	10.1016/j.frl.2023.104643	http://dx.doi.org/10.1016/j.frl.2023.104643		NOV 2023	10	Business, Finance	Social Science Citation Index (SSCI)	Business & Economics	Y7LZ7					2024-07-03	WOS:001107053000001
J	Nelson, JW				Nelson, Jack Wright			Large language models and the treaty interpretation game	CAMBRIDGE INTERNATIONAL LAW JOURNAL			English	Article						artificial intelligence; large language models; treaty interpretation; data; bias	JUSTICE; COURT	Large language models (LLMs) are currently disrupting law. Yet their precise impact on international law, especially treaty interpretation, remains underexplored. Treaty interpretation can be analogised to a game in which 'players' strategically deploy 'cards', usually principles of treaty interpretation, to persuade an 'audience' that their interpretation is correct. Leveraging this analogy, this paper offers a limited case study of how OpenAI's ChatGPT, a prominent LLM-based chatbot, navigates the treaty interpretation game. In line with the existing research on ChatGPT's legal abilities, the author concludes that ChatGPT competently plays the treaty interpretation game. This conclusion leads to a broader discussion of how LLM usage may impact international law's development. The argument advanced is that, while LLMs have the potential to enhance efficiency and accessibility, biased training data and interpretative standardisation could reinforce international law's dominant narratives. As such, this paper concludes with a cautionary note: the potential gains derived from LLMs risk being offset by disciplinary stagnation.	[Nelson, Jack Wright] McGill Univ, Fac Law, Montreal, PQ, Canada; [Nelson, Jack Wright] Natl Univ Singapore, Fac Law, Singapore, Singapore	McGill University; National University of Singapore	Nelson, JW (corresponding author), McGill Univ, Fac Law, Montreal, PQ, Canada.; Nelson, JW (corresponding author), Natl Univ Singapore, Fac Law, Singapore, Singapore.		Nelson, Jack Wright/GLS-1023-2022	Nelson, Jack Wright/0000-0002-2467-681X				Allot P., 2015, Interpretation in International Law, P373; Ammann Odile, 2016, Harvard International Law Journal18 May; Among Us, `Among Us': Innersloth; [Anonymous], 2023, NATURE, V619, P671, DOI 10.1038/d41586-023-02366-2; [Anonymous], 2018, Opinio Juris, 7 February; [Anonymous], 2021, Europe Fit for the Digital Age: Commission Proposes New Rules and Actions for Excellence and Trust in Artificial Intelligence'; [Anonymous], 2019, Times of Israel17 April; [Anonymous], 2019, Boston University Law Review Online; [Anonymous], 2011, GermanLJ, V12, P1730, DOI [10.1017/S2071832200017533, DOI 10.1017/S2071832200017533]; [Anonymous], 2022, CNN11 May; [Anonymous], 2023, All Members; Arimatsu L, 2019, CAMB INT LAW J, V8, P187, DOI 10.4337/cilj.2019.02.02; Baird DouglasG., 1994, GAME THEORY LAW; Barr Kyle, 2023, Gizmodo16 March; Benson R., 2008, INTERPRETATION GAME; Best Jo, 2013, TechRepublic9 September; Bianchi Andrea., 2015, INTERPRETATION INT L, P34; Bianchi Andrea, 2016, INT LAW THEORIES INQ, P263; Blair-Stanek Andrew, 2023, Social Science Research Network Paper; Carty Anthony, 2012, Melbourne Journal of International Law, V13, P859; Chesterman S, 2021, CAMB INT LAW J, V10, P181; Choi J H, 2023, Journal of Legal Education, P1; Crawford James, 2020, Identity and Diversity on the International Bench: Who is the Judge?, P422; Crawford James, 2020, Identity and Diversity on the International Bench: Who is the Judge?, P412; Crawford James, 2015, Interpretation in International Law; Criddle Cristina, 2022, Financial Times9 December; Daley Jason, 2019, Smithsonian Magazine7 August; Deighton Katie, 2023, The Wall Street Journal24 January; Djeffal Christian, 2016, The Interpretation of International Law by Domestic Courts: Uniformity, Diversity, Convergence, P175; Enyew EL, 2022, CHIN J INT LAW, V21, P439, DOI 10.1093/chinesejil/jmac028; Gardiner Richard K, 2015, Treaty Interpretation, V2nd, P451; Gaubatz Kurt T., 2001, MICH. J. INT'L L, V22, P239; Gaubatz Kurt Taylor, 2001, Michigan Journal of International Law, V22, P240; Gent Edd, 2023, New Scientist25 July; Goldsmith JL, 1999, U CHICAGO LAW REV, V66, P1113, DOI 10.2307/1600364; Google, 2023, Bard Experiment, 13 August; Hacker Philipp, 2023, Verfassungsblog; Hargreaves S., 2023, 202303 CHIN U HONG K; Hernández G, 2018, EUR J INT LAW, V29, P1003, DOI 10.1093/ejil/chy045; Hooper Rowan, 2020, New Scientist20 August; Katz Daniel Martin, 2023, Social Science Research Network Paper; Keeler Kyle, 2023, SlateFebruary 2,; Klinger Joseph, 2018, Between the Lines of the Vienna Convention? Canons and Other Principles of Interpretation in Public International Law; Kumar SP, 2014, EUR J INT LAW, V25, P893, DOI 10.1093/ejil/chu057; Levesque Jean-Francois, 2006, Revue Quebecoise de Droit International, V19, P53; Levesque Jean-Francois, 2006, Revue Quebecoise de Droit International, V19, P54; Linderfalk U, 2007, LAW PHILOS LIBR, V83, P1, DOI 10.1007/978-1-4020-6362-6; Maeda John, 2023, Prompt Engineering Overview; Maher Katherine, 2018, Wikipedia is a Mirror of the World's Gender Biases'; Marshall AM, 2003, LAW SOCIAL INQUIRY, V28, P617, DOI 10.1086/380076; Masson-Zwaan Tanja, 2019, Introduction to Space Law, V4th, P92; McLachlan Campbell., 2005, International and Comparative Law Quarterly, V54, P279, DOI [10.1093/iclq/lei001, DOI 10.1093/ICLQ/LEI001]; Meta, 2023, Introducing Llama 2; Oberhaus Daniel, 2019, Wired5 August; Okerlund Johanna, 2022, University of Michigan Gerald R Ford School of Public Policy Report; OpenAi, ChatGPT; Peat D., 2015, Interpretation in International Law, P3; Pettinato Oltz Tammy, 2023, Social Science Research Network Paper; Regalia Joseph, 2023, Social Science Research Network Paper; Roberts Anthea, 2019, Boston University Law Review Online, V99, P37; Roberts Anthea., 2017, IS INT LAW INT; Sarel Roee, 2023, UC Law SF Journal; Sennekamp A, 2014, CAMB INT LAW J, V3, P489, DOI 10.7574/cjicl.03.02.212; Sennekamp Andreas, 2014, Cambridge Journal of International and Comparative Law, V3, P506; van de Kerchove Michel, 1992, Le Droit ou les Paradoxes du Jeu; Venzke 61Ingo, 2015, INTERPRETATION IN INTERNATIONAL LAW, P365; Verma Pranshu, 2023, The Washington Post5 April; Weeramantry Romesh, 2023, 3 VERULAM BUILDINGS; Weiler Joseph, 2023, EJIL:Talk!, 28 April; Willingham Emily, 2023, Scientific American13 March; Wilson N, 2019, BIOSCIENCE, V69, P5, DOI 10.1093/biosci/biy140; Wittgenstein L., 1967, Philosophische Untersuchungen = Philosophical Investigations/Ludwig Wittgenstein; Z -MAN Games, Pandemic	73	0	0	3	3	EDWARD ELGAR PUBLISHING LTD	CHELTENHAM	THE LYPIATTS, 15 LANSDOWN RD, CHELTENHAM, GLOS GL50 2JA, ENGLAND	2398-9173	2398-9181		CAMB INT LAW J	Camb. Int. Law J.	DEC	2023	12	2					305	327						23	Law	Emerging Sources Citation Index (ESCI)	Government & Law	IL0U2					2024-07-03	WOS:001166370600009
C	Yongsatianchot, N; Torshizi, PG; Marsella, S			IEEE	Yongsatianchot, Nutchanon; Torshizi, Parisa Ghanad; Marsella, Stacy			Investigating Large Language Models' Perception of Emotion Using Appraisal Theory	2023 11TH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS, ACIIW			English	Proceedings Paper	11th International Conference on Affective Computing and Intelligent Interaction (ACIIW)	SEP 10-13, 2023	Cambridge, MA			Large language model; Appraisal theory; coping		Large Language Models (LLM) like ChatGPT have significantly advanced in recent years and are now being used by the general public. As more people interact with these systems, improving our understanding of these black box models is crucial, especially regarding their understanding of human psychological aspects. In this work, we investigate their emotion perception through the lens of appraisal and coping theory using the Stress and Coping Process Questionaire (SCPQ). SCPQ is a validated clinical instrument consisting of multiple stories that evolve over time and differ in key appraisal variables such as controllability and changeability. We applied SCPQ to three recent LLMs from OpenAI, davinci-003, ChatGPT, and GPT-4 and compared the results with predictions from the appraisal theory and human data. The results show that LLMs' responses are similar to humans in terms of dynamics of appraisal and coping, but their responses did not differ along key appraisal dimensions as predicted by the theory and data. The magnitude of their responses is also quite different from humans in several variables. We also found that GPTs can be quite sensitive to instruction and how questions are asked. This work adds to the growing literature evaluating the psychological aspects of LLMs and helps enrich our understanding of the current models.	[Yongsatianchot, Nutchanon; Torshizi, Parisa Ghanad; Marsella, Stacy] Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA	Northeastern University	Yongsatianchot, N (corresponding author), Northeastern Univ, Khoury Coll Comp Sci, Boston, MA 02115 USA.	nutjung.nutlc@gmail.com; ghanadparisa@gmail.com; marsella@northeastern.edu	Yongsatianchot, Nutchanon/KQV-3247-2024					Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Arnold M. B., 1960, Emotion and personality; Barrett LF, 2017, SOC COGN AFFECT NEUR, V12, P1, DOI 10.1093/scan/nsw154; Binz M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2218523120; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Damasio AR, 1996, PHILOS T R SOC B, V351, P1413, DOI 10.1098/rstb.1996.0125; Ekman Paul, 1999, HDB COGNITION EMOTIO, P45, DOI [DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]; Gratch J, 2005, AUTON AGENT MULTI-AG, V11, P23, DOI 10.1007/s10458-005-1081-1; Harmon-Jones C, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159915; II Michael Bommarito, 2022, arXiv, DOI 10.48550/arXiv.2212.14402; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Lazarus R.S., 1991, EMOTION ADAPTATION; Li XX, 2024, Arxiv, DOI [arXiv:2212.10529, DOI 10.48550/ARXIV.2212.10529, 10.48550/arXiv.2212.10529]; Miotto M, 2022, Arxiv, DOI arXiv:2209.14338; Moors A, 2013, EMOT REV, V5, P119, DOI 10.1177/1754073912468165; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Perrez M., 1992, Stress, Coping and Health: A Situation-Behaviour Approach Theory, Methods, Applications; RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714; Scherer KR, 2021, EMOTION, V21, P1224, DOI 10.1037/emo0000861; Seligman M., 1972, Helplessness: On depression, development, and death; Smith C. A., 1990, Handbook of Personality: Theory and Research, V21, P609	23	0	0	8	8	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2745-8				2023										10.1109/ACIIW59127.2023.10388194	http://dx.doi.org/10.1109/ACIIW59127.2023.10388194			8	Computer Science, Artificial Intelligence; Computer Science, Cybernetics; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IG		Green Submitted			2024-07-03	WOS:001161364800082
J	Omari, S; Basnet, K; Wardat, M				Omari, Safwan; Basnet, Kshitiz; Wardat, Mohammad			Investigating large language models capabilities for automatic code repair in Python	CLUSTER COMPUTING-THE JOURNAL OF NETWORKS SOFTWARE TOOLS AND APPLICATIONS			English	Article; Early Access						Automatic program repair; Large language models; Python; Bug detection		Developers often encounter challenges with their introductory programming tasks as part of the development process. Unfortunately, rectifying these mistakes manually can be time-consuming and demanding. Automated program repair (APR) techniques offer a potential solution by synthesizing fixes for such errors. Previous research has investigated the utilization of both symbolic and neural techniques within the APR domain. However, these approaches typically demand significant engineering efforts or extensive datasets and training. In this paper, we explore the potential of using a large language model trained on code, specifically, we assess ChatGPT's capability to detect and repair bugs in simple Python programs. The experimental evaluation encompasses two benchmarks: QuixBugs and Textbook. Each benchmark consists of simple Python functions that implement well-known algorithms and each function contains a single bug. To gauge repair performance in various settings, several benchmark variations were introduced including addition of plain English documentation and code obfuscation. Based on thorough experiments, we found that ChatGPT was able to correctly detect and fix about 50% of the methods, when code is documented. Repair performance drops to 25% when code is obfuscated, and 15% when documentation is removed and code is obfuscated. Furthermore, when compared to existing APR systems, ChatGPT considerably outperformed them.	[Omari, Safwan; Basnet, Kshitiz] Lewis Univ, Dept Engn Comp & Math Sci, Romeoville, IL 60446 USA; [Wardat, Mohammad] Oakland Univ, Dept Comp Sci & Engn, Rochester, MI 48309 USA	Lewis University; Oakland University	Omari, S (corresponding author), Lewis Univ, Dept Engn Comp & Math Sci, Romeoville, IL 60446 USA.	omarisa@lewisu.edu; kshitizbasnet@lewisu.edu; wardat@oakland.edu						[Anonymous], 2023, Radon: a Python tool that computes various metrics from the source code; Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Budzianowski P, 2019, Arxiv, DOI arXiv:1907.05774; Buscemi A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2308.04477; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dinella E., 2020, INT C LEARN REPR ICL; Drain D, 2021, Arxiv, DOI arXiv:2105.09352; Durieux T, 2016, 2016 IEEE/ACM 11TH INTERNATIONAL WORKSHOP IN AUTOMATION OF SOFTWARE TEST (AST), P85, DOI [10.1145/2896921.2896931, 10.1109/AST.2016.021]; Goodrich M.T., 2013, Data Structures and Algorithms in Python; Jiang JJ, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P298, DOI 10.1145/3213846.3213871; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Kim D, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P802, DOI 10.1109/ICSE.2013.6606626; Le Goues C, 2012, IEEE T SOFTWARE ENG, V38, P54, DOI 10.1109/TSE.2011.104; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Lin D, 2017, P COMPANION 2017 ACM, P55, DOI DOI 10.1145/3135932; Liu K, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P31, DOI 10.1145/3293882.3330577; Liu K, 2018, ASIA PAC SOFWR ENG, P658, DOI 10.1109/APSEC.2018.00085; Long F, 2016, ACM SIGPLAN NOTICES, V51, P298, DOI 10.1145/2914770.2837617; Lund Brady D., 2023, Library Hi Tech News, P26, DOI 10.1108/LHTN-01-2023-0009; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Martinez M, 2018, LECT NOTES COMPUT SC, V11036, P65, DOI 10.1007/978-3-319-99241-9_3; McCabe T. J., 1976, IEEE Transactions on Software Engineering, VSE-2, P308, DOI 10.1109/TSE.1976.233837; Michael TG., 2014, Data Structures and Algorithms in Python; Misu MRH, 2024, Arxiv, DOI arXiv:2402.00247; MutPy, 2019, Mutation testing tool for Python 3.x source code; Oh W, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P922, DOI 10.1145/3540250.3549130; Omari S., 2023, ChatGPTResearch; openai, 2023, Chatgpt: Optimizing language models for dialogue; Paul R, 2023, Arxiv, DOI arXiv:2304.07840; Prenner JA, 2021, Arxiv, DOI [arXiv:2111.03922, DOI 10.48550/ARXIV.2111.03922]; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Raffel C, 2020, J MACH LEARN RES, V21; Rahaman MS, 2023, J Eng Emerg Technol, V2, P1, DOI [10.52631/jeet.v2i1.188, DOI 10.52631/JEET.V2I1.188]; Saha RK, 2017, IEEE INT CONF AUTOM, P648, DOI 10.1109/ASE.2017.8115675; Sakib F.A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2307.08260; Sobania D, 2023, Arxiv, DOI [arXiv:2301.08653, DOI 10.48550/ARXIV.2301.08653]; spectrum.ieee, 2021, IEEE Spectrum's the Top Programming Languages; Tian HY, 2023, Arxiv, DOI arXiv:2304.11938; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Vaswani A, 2017, ADV NEUR IN, V30; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Wuisang M.C., 2023, 2023 INT SEM APPL TE, P295, DOI [10.1109/iSemantic59612.2023.10295323, DOI 10.1109/ISEMANTIC59612.2023.10295323]; Xin Q, 2017, IEEE INT CONF AUTOM, P660, DOI 10.1109/ASE.2017.8115676; Ye H, 2021, J SYST SOFTWARE, V171, DOI 10.1016/j.jss.2020.110825; Yuan Y, 2020, IEEE T SOFTWARE ENG, V46, P1040, DOI 10.1109/TSE.2018.2874648; Yuan ZQ, 2023, Arxiv, DOI arXiv:2305.04207; Zhang Q., 2023, IEEE Trans. Dependable Secur. Comput.; Zhang QJ, 2024, Arxiv, DOI arXiv:2310.08879; Zhang QJ, 2023, Arxiv, DOI arXiv:2301.03270	54	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1386-7857	1573-7543		CLUSTER COMPUT	Cluster Comput.	2024 MAY 9	2024										10.1007/s10586-024-04490-8	http://dx.doi.org/10.1007/s10586-024-04490-8		MAY 2024	15	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	QJ3N3					2024-07-03	WOS:001220469100002
J	Kovalev, AK; Panov, AI				Kovalev, A. K.; Panov, A. I.			Application of Pretrained Large Language Models in Embodied Artificial Intelligence	DOKLADY MATHEMATICS			English	Article						embodied artificial intelligence; large language models; common sense knowledge; construction of action plans		A feature of tasks in embodied artificial intelligence is that a query to an intelligent agent is formulated in natural language. As a result, natural language processing methods have to be used to transform the query into a format convenient for generating an appropriate action plan. There are two basic approaches to the solution of this problem. One is based on specialized models trained with particular instances of instructions translated into agent-executable format. The other approach relies on the ability of large language models trained with a large amount of unlabeled data to store common sense knowledge. As a result, such models can be used to generate an agent's action plan in natural language without preliminary learning. This paper provides a detailed review of models based on the second approach as applied to embodied artificial intelligence tasks.	[Kovalev, A. K.] Artificial Intelligence Res Inst, Moscow, Russia; [Panov, A. I.] Russian Acad Sci, Fed Res Ctr Comp Sci & Control, Moscow, Russia	Russian Academy of Sciences; Federal Research Center "Computer Science & Control" of RAS	Panov, AI (corresponding author), Russian Acad Sci, Fed Res Ctr Comp Sci & Control, Moscow, Russia.	panov@airi.net	Panov, Aleksandr I./L-9171-2013	Panov, Aleksandr I./0000-0002-9747-3837				Ahn M., 2022, ARXIV; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Chowdhery A., 2022, arXiv; Coumans E., 2016, PYBULLET PYTHON MODU; Devlin J., 2018, BERT PRE TRAINING DE; Gramopadhye M., 2022, ARXIV; Gu X., 2021, arXiv; Huang W., 2022, ARXIV; Liang J., 2022, ARXIV; Lin B., 2022, ARXIV; Liu H., 2022, arXiv; Liu Q, 2021, ARXIV; Min S., 2021, ARXIV; Ouyang L., 2022, ARXIV; Padmakumar A, 2022, AAAI CONF ARTIF INTE, P2017; Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886; Radford A, 2021, PR MACH LEARN RES, V139; Reimers N., 2019, arXiv; Shah D., 2022, ARXIV; Shah D, 2021, IEEE INT CONF ROBOT, P13215, DOI 10.1109/ICRA48506.2021.9561936; Shridhar M., 2022, C ROBOT LEARNING, P894; Shridhar M, 2020, P IEEE CVF C COMP VI, P10740, DOI DOI 10.1109/CVPR42600.2020.01075; Singh I., 2022, ARXIV; Talbot B., 2020, ARXIV; Wei J., 2021, ARXIV; Wei J., 2022, ARXIV; Weihs L, 2021, PROC CVPR IEEE, P5918, DOI 10.1109/CVPR46437.2021.00586; Zeng A, 2020, ARXIV; Zeng A., 2022, ARXIV	30	7	7	27	85	MAIK NAUKA/INTERPERIODICA/SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013-1578 USA	1064-5624	1531-8362		DOKL MATH	Dokl. Math.	DEC	2022	106	SUPPL 1		1			S85	S90		10.1134/S1064562422060138	http://dx.doi.org/10.1134/S1064562422060138		JAN 2023	6	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	A7UL2		hybrid			2024-07-03	WOS:000918185200004
J	Abou Elkassem, A; Smith, AD				Abou Elkassem, Asser; Smith, Andrew D.			Potential Use Cases for ChatGPT in Radiology Reporting	AMERICAN JOURNAL OF ROENTGENOLOGY			English	Article						artificial intelligence; ChatGPT; health care; large language models; radiology reports		Large language models (LLMs) such as ChatGPT are advanced artificial intelligence models that are designed to process and understand human language. LLMs have the potential to improve radiology reporting and patient engagement by automating generation of the clinical history and impression of a radiology report, creating layperson reports, and providing patients with pertinent questions and answers about findings in radiology reports. However, LLMs are error prone, and human oversight is needed to reduce the risk of patient harm.	[Abou Elkassem, Asser; Smith, Andrew D.] Univ Alabama Birmingham, Dept Radiol, 619 19th St S, Birmingham, AL 35249 USA	University of Alabama System; University of Alabama Birmingham	Smith, AD (corresponding author), Univ Alabama Birmingham, Dept Radiol, 619 19th St S, Birmingham, AL 35249 USA.	andrewdennissmith@uabmc.edu	Smith, Andrew Dennis/KQU-0358-2024; Smith, Andrew Dennis/KQU-0363-2024	Smith, Andrew Dennis/0000-0002-8124-1038; 				Bavarian M, 2022, Arxiv, DOI [arXiv:2207.14255, 10.48550/arXiv.2207.14255]; Dai ZH, 2019, Arxiv, DOI arXiv:1901.02860; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Lee YH, 2015, J DIGIT IMAGING, V28, P412, DOI 10.1007/s10278-015-9772-x; OpenAI website, 2022, Introducing ChatGPT; Roose K., 2023, The New York Times; Ryan J., 2022, Meta trained an AI on 48M science papers: it was shut down after 2 days	8	44	44	43	57	AMER ROENTGEN RAY SOC	LEESBURG	44211 SLATESTONE CT, LEESBURG, VA USA	0361-803X	1546-3141		AM J ROENTGENOL	Am. J. Roentgenol.	SEP	2023	221	3					373	376		10.2214/AJR.23.29198	http://dx.doi.org/10.2214/AJR.23.29198			4	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	T1SK4	37095665	hybrid			2024-07-03	WOS:001075850600019
J	Procko, TT; Elvira, T; Ochoa, O				Procko, Tyler Thomas; Elvira, Timothy; Ochoa, Omar			Dawn of the dialogue: AI's leap from lab to living room	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						Artificial Intelligence; Large Language Models; generative AI; ChatGPT; AI evolution		Prior to the advent of mainstream Large Language Models, e.g., ChatGPT, there were two contexts of AI use: theoretical and technical. The former involves the mathematics behind AI constructs, as well as new AI research; the latter encompasses the substance of AI use, i.e., programming, training, execution, etc. With the recent proliferation of Large Language Models for content generation, such as texts, images, and videos, there arises a new context of AI use: practical. This aspect of AI use is unique, in that practical users do not need theoretical or technical AI knowledge to prosper: they need only know how to prompt. In effect, the practical context of AI use is a black-box approach. These three contexts of AI converge in a unique intersection of AI knowledge. This emerging AI perspective is important to consider, as most AI users, now and in the future, will possess no deep knowledge of AI.	[Procko, Tyler Thomas; Elvira, Timothy; Ochoa, Omar] Embry Riddle Aeronaut Univ, Dept Elect Engn & Comp Sci, Daytona Beach, FL 32114 USA	Embry-Riddle Aeronautical University	Elvira, T (corresponding author), Embry Riddle Aeronaut Univ, Dept Elect Engn & Comp Sci, Daytona Beach, FL 32114 USA.	elvirat@my.erau.edu						Abbott R., 2022, Florida Law Rev, V75, P6, DOI [10.2139/ssrn.4185327, DOI 10.2139/SSRN.4185327]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 1950, The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, DOI DOI 10.1080/14786445008521796; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dean J, 2022, DAEDALUS-US, V151, P58, DOI 10.1162/daed_a_01900; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Haluza D, 2023, SYSTEMS-BASEL, V11, DOI 10.3390/systems11030120; Hendler J., 2008, IEEE Intell Syst, V23, P2, DOI DOI 10.1109/MIS.2008.20; Licklider J.C.R., 1960, IRE transactions on human factors in electronics, P4, DOI [10.1109/THFE2.1960.4503259, DOI 10.1109/THFE2.1960.4503259]; Lu Y, 2019, J MANAG ANAL, V6, P1, DOI 10.1080/23270012.2019.1570365; not by AI, 2023, Not By AI; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Procko T. T., 2023, 2023 ASEE Annual Conference and Exposition; Radford A., 2018, Improving language understanding by generative pre-trainingJ; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; RAMALHO Ana., 2018, Patentability of AI-Generated Inventions: Is a Reform of the Patent System Needed?, DOI DOI 10.2139/SSRN.3168703; Ramesh A., 2022, arXiv; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Singh T, 2023, Arxiv, DOI arXiv:2304.06123; Thorsten B., 2007, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), P858867; Trajtenberg M., 2018, National Bureau of Economic Research. Working Paper; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Wang HH, 2017, Arxiv, DOI arXiv:1702.07800; Yu H, 2023, FRONT PSYCHOL, V14, DOI 10.3389/fpsyg.2023.1181712; Alom MZ, 2018, Arxiv, DOI [arXiv:1803.01164, DOI 10.48550/ARXIV.1803.01164]; Zhang CN, 2023, Arxiv, DOI arXiv:2303.11717	27	0	0	9	9	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	MAR 4	2024	7								1308156	10.3389/frai.2024.1308156	http://dx.doi.org/10.3389/frai.2024.1308156			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	LH8B6	38500671	Green Published, gold			2024-07-03	WOS:001185979900001
J	Firoozi, T; Bulut, O; Gierl, MJ				Firoozi, Tahereh; Bulut, Okan; Gierl, Mark J.			Language models in automated essay scoring: Insights for the Turkish language	INTERNATIONAL JOURNAL OF ASSESSMENT TOOLS IN EDUCATION			English	Article						Automated essayscoring,; Word embedding,; Transformers,; BERT,; Turkish AES.	ITEM GENERATION; MENTAL ROTATION; VALIDITY	The proliferation of large language models represents a paradigm shift in the landscape of automated essay scoring (AES) systems, fundamentally elevating their accuracy and efficacy. This study presents an extensive examination of large language models, with a particular emphasis on the transformative influence of transformer -based models, such as BERT, mBERT, LaBSE, and GPT, in augmenting the accuracy of multilingual AES systems. The exploration of these advancements within the context of the Turkish language serves as a compelling illustration of the potential for harnessing large language models to elevate AES performance in in low-resource linguistic environments. Our study provides valuable insights for the ongoing discourse on the intersection of artificial intelligence and educational assessment.	[Firoozi, Tahereh; Bulut, Okan; Gierl, Mark J.] Univ Alberta, Edmonton, AB, Canada	University of Alberta	Firoozi, T (corresponding author), Univ Alberta, Edmonton, AB, Canada.	tahereh.firoozi@ualberta.ca	Bulut, Okan/O-3457-2019	Bulut, Okan/0000-0001-5853-1267				Adji T.B., 2018, ICEAP 2019, V1, P89, DOI [10.26499/iceap.v1i1.78, DOI 10.26499/ICEAP.V1I1.78]; Arendasy ME, 2012, LEARN INDIVID DIFFER, V22, P112, DOI 10.1016/j.lindif.2011.11.005; Atli S., 2007, Unpublished master's thesis; Balboni G, 2010, J PSYCHOEDUC ASSESS, V28, P222, DOI 10.1177/0734282909343763; Bildiren A, 2021, SAGE OPEN, V11, DOI 10.1177/21582440211046945; Bilgic N., 2017, MEB Ozel Egitim ve Rehberlik Hizmetleri Genel Mudurlugu; BILSEM Online, 2023, Frequently asked questions: Do BILSEM exam questions vary depending on ability?; BILSEM Online, 2023, BNV Zeka Testi Nedir?; Choi J, 2019, QUANT METH PSYCHOL, V15, P214, DOI 10.20982/tqmp.15.3.p214; Cohen R.J., 2015, Psychological testing and assessment; COOPER LA, 1975, COGNITIVE PSYCHOL, V7, P20, DOI 10.1016/0010-0285(75)90003-1; DeThorne LS, 2004, AM J SPEECH-LANG PAT, V13, P275, DOI 10.1044/1058-0360(2004/029); Embretson S, 2007, HANDB STAT, V26, P747, DOI 10.1016/S0169-7161(06)26023-1; Embretson SE, 2018, J EDUC MEAS, V55, P112, DOI 10.1111/jedm.12166; Falcao F, 2022, ADV HEALTH SCI EDUC, V27, P405, DOI 10.1007/s10459-022-10092-z; Gibbons A, 2019, INTELLIGENCE, V75, P9, DOI 10.1016/j.intell.2019.02.005; Gierl M.J., 2016, HDB TEST DEV, V2nd, P410; Gierl M.J., 2012, Automatic item generation: Theory and practice; Gierl M. J., 2021, ADV METHODS AUTOMATI; Gierl MJ, 2015, COMM COM INF SC, V571, P12, DOI 10.1007/978-3-319-27704-2_2; Gierl MJ, 2012, INT J TEST, V12, P273, DOI 10.1080/15305058.2011.635830; Gierl MJ, 2013, EDUC MEAS-ISSUES PRA, V32, P36, DOI 10.1111/emip.12018; Haladyna TM, 2002, APPL MEAS EDUC, V15, P309, DOI 10.1207/S15324818AME1503_5; Hausknecht JP, 2007, J APPL PSYCHOL, V92, P373, DOI 10.1037/0021-9010.92.2.373; HORN JL, 1966, J EDUC PSYCHOL, V57, P253, DOI 10.1037/h0023816; Karasar N., 2022, Bilimsel arastirma yontemleri (37. baski); Kemer B., 2020, Journal of Research in Education and Society, V7, P323; Kocagul M., 2022, Cumhuriyet International Journal of Education, V11, P361, DOI [10.30703/cije.1017938, DOI 10.30703/CIJE.1017938]; Kosh AE, 2019, EDUC MEAS-ISSUES PRA, V38, P48, DOI 10.1111/emip.12237; Kurnaz A., 2020, Cocuk ve Medeniyet, V5, P365; Kurtz K J., 1999, Cognitive science, P145; Lai H, 2016, J DENT EDUC, V80, P339; Lawson A.E., 2004, INT J SCI MATH EDUC, V2, P307, DOI DOI 10.1007/S10763-004-3224-2; Leighton J.P., 2012, Automatic item generation: Theory and practice, P121; Lewis J.D., 2007, MULTICULTURAL ED, V15, P38; Lohman D.F., 2003, Interpretive guide for teachers and counselors: cognitive abilities test Form 6-all levels; Mercan Z., 2021, Journal of Muallim Rifat Faculty of Education, V3, P104; Ministry of National Education (MoNE), 2015, Bilim ve Sanat Merkezleri Yonergesi; Ministry of National Education (MoNE), 2022, Bilim ve Sanat Merkezleri ogrenci tanilama ve yerlestirme kilavuzu; Ministry of National Education (MoNE), 2021, Bilim ve Sanat Merkezleri Yonergesi; Mullin I.V.S., 2005, IEA's TIMSS 2003 international report on achievement in the mathematics cognitive domains; Naglieri JA, 2005, GIFTED CHILD QUART, V49, P29, DOI 10.1177/001698620504900104; Nolte N, 2022, INTELLIGENCE, V91, DOI 10.1016/j.intell.2022.101626; PYLYSHYN ZW, 1979, MEM COGNITION, V7, P19, DOI 10.3758/BF03196930; Ryoo JH, 2022, SAGE OPEN, V12, DOI 10.1177/21582440221095016; Sak U., 2019, Psychological Test and Assessment Modeling, V61, P263; Sayin A, 2023, INT J ASSESS TOOLS E, V10, P218, DOI 10.21449/ijate.1249297; Shin E., 2021, Automated item generation by combining the non-template and template-based approaches to generate reading inference test items, DOI [10.7939/r3-75wr-hc80, DOI 10.7939/R3-75WR-HC80]; Sinharay S., 2005, ETS Research Report Series, V2005, P1; Tamul ÖF, 2020, PAMUKKALE U EGIT FAK, P393, DOI 10.9779/pauefd.575479; Weiss L.C., 2016, WISCV assessment and interpretation: Scientist-practitioner perspectives, P3, DOI [DOI 10.1016/B978-0-12-404697-9.00001-7, 10.1016/B978-0-12404697-9.00001-7, DOI 10.1016/B978-0-12404697-9.00001-7]	51	0	0	8	8	IZZET KARA	Denizli	Pamukkale University, Education Faculty, Department of Science Education, Kinikli Campus, Denizli, Turkiye	2148-7456			INT J ASSESS TOOLS E	Int. J. Assess. Tools Educ.		2023	10				SI		148	162		10.21449/ijate.1394194	http://dx.doi.org/10.21449/ijate.1394194			15	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	JY7I2		gold, Green Submitted			2024-07-03	WOS:001176780900005
J	Smithson, R; Zweber, A				Smithson, Robert; Zweber, Adam			Reviving the Philosophical Dialogue with Large Language Models	TEACHING PHILOSOPHY			English	Article						large language models; artificial intelligence; philosophy papers; LLMs; dialogue		Many philosophers have argued that large language models (LLMs) subvert the traditional undergraduate philosophy paper. For the enthusiastic, LLMs merely subvert the traditional idea that students ought to write philosophy papers "entirely on their own." For the more pessimistic, LLMs merely facilitate plagiarism. We believe that these controversies neglect a more basic crisis. We argue that, because one can, with minimal philosophical effort, use LLMs to produce outputs that at least "look like" good papers, many students will complete paper assignments in a way that fails to develop their philosophical abilities. We argue that this problem exists even if students can produce better papers with AI and even if instructors can detect AI-generated content with decent reliability. But LLMs also create a pedagogical opportunity. We propose that instructors shift the emphasis of their assignments from philosophy papers to LLM dialogues: philosophical conversations between the student and an LLM. We describe our experience with using these types of assignments over the past several semesters. We argue that, far from undermining quality philosophical instruction, LLMs allow us to teach philosophy more effectively than was possible before.	[Smithson, Robert; Zweber, Adam] UNC Wilmington, Wilmington, NC 28403 USA	University of North Carolina; University of North Carolina Wilmington	Smithson, R (corresponding author), UNC Wilmington, Wilmington, NC 28403 USA.	smithsonr@uncw.edu; zwebera@uncw.edu						Baker MJ, 2020, ROUT INT HANDB, P76; Coppenger Mark, 1979, Teaching Philosophy, V3, P197, DOI [10.5840/teachphil19793229, DOI 10.5840/TEACHPHIL19793229]; HILL TE, 1979, PHILOS PUBLIC AFF, V9, P83; Howe C, 2020, ROUT INT HANDB, P182; L'Hôte C, 2012, TEACH PHILOS, V35, P263, DOI 10.5840/teachphil201235328; Medeiros PJ, 2017, TEACH PHILOS, V40, P37, DOI 10.5840/teachphil201733063; Mullis EC, 2009, TEACH PHILOS, V32, P345, DOI 10.5840/teachphil200932438; Murdoch Iris., 1992, EXISTENTIALISTS MYST; Plato, 1997, PLATO COMPLETE WORKS, P506; Russell DavidR., 1991, WRITING ACAD DISCIPL; Schwarz B.B., 2017, DIALOGUE ARGUMENTATI, DOI DOI 10.1017/9781316493960; Staffel Julia, 2023, ChatGPT and Its Impact on Teaching Philosophy and Other Subjects; Terry Owen Kichizo, 2023, Chronicle of Higher EducationMay 2; van Eemeren F. H., 1992, Argumentation, Communication, and Fallacies: A Pragma-dialectical Perspective; Walton D.N., 1989, ARGUMENTATION, V3, P169, DOI [DOI 10.1007/BF00128147, 10.1007/BF00128147]; Worthen Molly, 2022, New York TimesDecember 2	16	0	0	3	3	PHILOSOPHY DOCUMENTATION CENTER	CHARLOTTESVILLE	PO BOX 7147, CHARLOTTESVILLE, VA 22906-7147 USA	0145-5788	2153-6619		TEACH PHILOS	Teach Philos.	JUN	2024	47	2					143	171		10.5840/teachphil2024424196	http://dx.doi.org/10.5840/teachphil2024424196			29	Philosophy	Arts &amp; Humanities Citation Index (A&amp;HCI)	Philosophy	SH7M6					2024-07-03	WOS:001233629900005
J	Tsoukala, C; Paraskevopoulos, G; Katsamanis, A				Tsoukala, Chara; Paraskevopoulos, Georgios; Katsamanis, Athanasios			Revolutionising Theatre Archives: using Large Language Models to Interact with Structured Archival Content	ERCIM NEWS			English	Article								The Greek National Theatre has introduced an advanced chatbot based on Large Language Models (LLMs) as a novel means of accessing the content of the digital archive on the web. This state-of-the-art chatbot, which utilises Text2SQL conversion through LLMs, offers a more intuitive user experience, enabling complex searches with simple natural language. This addition marks a significant step forward in making theatrical performance data accessible in a more interactive way.	[Tsoukala, Chara; Paraskevopoulos, Georgios; Katsamanis, Athanasios] Athena Res Ctr, Inst Language & Speech Proc, Athena, Greece	Institute for Language & Speech Processing (ILSP)	Tsoukala, C (corresponding author), Athena Res Ctr, Inst Language & Speech Proc, Athena, Greece.	chara.tsoukala@athenarc.gr							0	0	0	1	1	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					37	38						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500021
J	Tang, YQ; Dai, XY; Lv, YS				Tang, Yiqing; Dai, Xingyuan; Lv, Yisheng			Large Language Model-Assisted Arterial Traffic Signal Control	IEEE JOURNAL OF RADIO FREQUENCY IDENTIFICATION			English	Article						Traffic control; large language model; Greenwave control		In the field of urban traffic management, optimising traffic signal control on major arterial road is crucial for reducing congestion and improving overall road efficiency. In this paper, we explore a novel approach to design and implement green wave control for urban arterials using Large Language Models (LLM), such as GPT-4. Our approach combines state-of-the-art LLM with traffic signal control policies, aiming to explore the potential of LLM for application in the field of traffic control. We design a workflow for LLM-driven green wave control generation for urban arterial road traffic signal control as an example. The experiments use SUMO simulation software to construct the traffic signal control problem of the arterial road. We verify that LLM can implement the analysis and solution process of the traffic signal control problem. The traffic signal control policy is generated interactively through natural language, which reduces the data analysis and computation pressure of traffic managers. The experimental results show that the process generates the green wave control of the arterial road that can improve the average speed of the road. The potential application of LLM in the field of traffic control is verified in this work.	[Tang, Yiqing; Dai, Xingyuan; Lv, Yisheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China; [Tang, Yiqing; Dai, Xingyuan; Lv, Yisheng] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Institute of Automation, CAS	Lv, YS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.	yisheng.lv@ia.ac.cn			National Key Research and Development Program of China	National Key Research and Development Program of China	No Statement Available	[Anonymous], 2023, Gpt-4 Technical Report; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Huang YF, 2022, IEEE J RADIO FREQ ID, V6, P739, DOI 10.1109/JRFID.2022.3217084; Ke RM, 2022, IEEE J RADIO FREQ ID, V6, P693, DOI 10.1109/JRFID.2022.3211262; Li X, 2024, IEEE T INTELL VEHICL, V9, P4422, DOI 10.1109/TIV.2024.3363232; Lopez PA, 2018, IEEE INT C INTELL TR, P2575, DOI 10.1109/ITSC.2018.8569938; Lv Y., 2023, IEEE Intell. Transp. Syst.Mag., V15, P3; Lv YS, 2023, IEEE INTEL TRANSP SY, V15, P2, DOI 10.1109/MITS.2023.3295392; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mehr G, 2023, IEEE INTEL TRANSP SY, V15, P41, DOI 10.1109/MITS.2022.3168801; Schwarz C, 2022, IEEE INTEL TRANSP SY, V14, P41, DOI 10.1109/MITS.2021.3129524; Singh I, 2023, IEEE INT CONF ROBOT, P11523, DOI 10.1109/ICRA48891.2023.10161317; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Tang Y.Tang, 2023, P IEEE 3 INT C DIG T, P1; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vemprala S., 2023, CHATGPT ROBOTICS DES; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P3763, DOI 10.1109/TIV.2023.3298655; Xiang C, 2023, IEEE INTEL TRANSP SY, V15, P36, DOI 10.1109/MITS.2023.3283864	19	0	0	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA		2469-7281		IEEE J RADIO FREQ ID	IEEE J. Radio Freq. Identif.		2024	8						322	326		10.1109/JRFID.2024.3384289	http://dx.doi.org/10.1109/JRFID.2024.3384289			5	Engineering, Electrical & Electronic; Telecommunications	Emerging Sources Citation Index (ESCI)	Engineering; Telecommunications	QY4X2					2024-07-03	WOS:001224427400010
C	Huang, K; Meng, XX; Zhang, J; Liu, Y; Wang, WJ; Li, SH; Zhang, YQ			IEEE	Huang, Kai; Meng, Xiangxin; Zhang, Jian; Liu, Yang; Wang, Wenjie; Li, Shuhao; Zhang, Yuqing			An Empirical Study on Fine-tuning Large Language Models of Code for Automated Program Repair	2023 38TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, ASE	IEEE ACM International Conference on Automated Software Engineering		English	Proceedings Paper	38th IEEE/ACM International Conference on Automated Software Engineering (ASE)	SEP 11-15, 2023	Echternach, LUXEMBOURG	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Automated Program Repair; Large Language Models of Code; Neural Machine Translation; Fine-Tuning		The advent of large language models (LLMs) has opened up new opportunities for automated program repair (APR). In particular, some recent studies have explored how to leverage large language models of code (LLMCs) for program repair tasks and show promising results. However, most of them adopt the zero/few-shot learning paradigm for APR, which directly use LLMCs to generate the possibly correct code given its surrounding context. Though effective, the repair capabilities of LLMCs based on the fine-tuning paradigm have yet to be extensively explored. Also, it remains unknown whether LLMCs have the potential to repair more complicated bugs (e.g., multi-hunk bugs). To fill the gap, in this work, we conduct a comprehensive study on the program repair capability of LLMCs in the fine-tuning paradigm. We select 5 popular LLMCs with representative pre-training architectures, including CodeBERT, GraphCodeBERT, PLBART, CodeT5, and UniXcoder. We consider 3 typical program repair scenarios (i.e., bugs, vulnerabilities, and errors) involving 3 programming languages (i.e., Java, C/C++, and JavaScript). Notably, we take both single-hunk and multi-hunk bugs/vulnerabilities into account. We then fine-tune them on widely-used datasets and compare them with existing state-of-the-art APR tools. We also investigate the impact of different design choices, which include code abstractions, code representations, and model evaluation metrics. Our experimental results show that LLMCs in the fine-tuning paradigm can significantly outperform previous state-of-the-art APR tools. Through in-depth analysis, we provide insights into choosing appropriate strategies to guide LLMCs for better performance. Lastly, we reveal several limitations of LLMCs for APR and make suggestions for future research on LLMC-based APR.	[Huang, Kai; Wang, Wenjie; Zhang, Yuqing] Univ Chinese Acad Sci, Beijing, Peoples R China; [Huang, Kai; Li, Shuhao; Zhang, Yuqing] Zhongguancun Lab, Beijing, Peoples R China; [Meng, Xiangxin] Beihang Univ, Beijing, Peoples R China; [Zhang, Jian; Liu, Yang] Nanyang Technol Univ, Singapore, Singapore	Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Zhongguancun Laboratory; Beihang University; Nanyang Technological University	Zhang, YQ (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.; Zhang, YQ (corresponding author), Zhongguancun Lab, Beijing, Peoples R China.; Zhang, J (corresponding author), Nanyang Technol Univ, Singapore, Singapore.	huangk@nipc.org.cn; mengxx@act.buaa.edu.cn; jian_zhang@ntu.edu.sg; yangliu@ntu.edu.sg; wangwj@ucas.ac.cn; lishuhao@zgclab.edu.cn; zhangyq@nipc.org.cn			National Key RD Project [2023QY1202]; National Natural Science Foundation of China [U1836210]; Hainan Key RD Project [GHYF2022010]; National Research Foundation, Singapore; Cyber Security Agency under its National Cybersecurity RD Programme [NCRP25-P04-TAICeN]	National Key RD Project; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Hainan Key RD Project; National Research Foundation, Singapore(National Research Foundation, Singapore); Cyber Security Agency under its National Cybersecurity RD Programme	We thank the anonymous reviewers for their insightful comments to improve this paper. This work was partially supported by the National Key R&D Project (2023QY1202), National Natural Science Foundation of China (U1836210), and Hainan Key R&D Project (GHYF2022010). This work was also partially supported by the National Research Foundation, Singapore, and the Cyber Security Agency under its National Cybersecurity R&D Programme (NCRP25-P04-TAICeN). Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not reflect the views of National Research Foundation, Singapore and Cyber Security Agency of Singapore.	Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; [Anonymous], 2022, Introducing chatgpt; [Anonymous], 2022, 2022 CWE top 25 most dangerous software weaknesses; Baudry B, 2021, IEEE SOFTWARE, V38, P28, DOI 10.1109/MS.2021.3070743; Berabi B, 2021, PR MACH LEARN RES, V139; Bhandari G, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE '21), P30, DOI 10.1145/3475960.3475985; Chen M., 2021, arXiv; Chen ZM, 2023, IEEE T SOFTWARE ENG, V49, P147, DOI 10.1109/TSE.2022.3147265; Chen ZM, 2018, Arxiv, DOI arXiv:1807.03200; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Chi JL, 2023, IEEE T SOFTWARE ENG, V49, P564, DOI 10.1109/TSE.2022.3156637; Evtikhiev M, 2022, Arxiv, DOI arXiv:2208.03133; Fan JH, 2020, IEEE WORK CONF MIN S, P508, DOI 10.1145/3379597.3387501; Fan ZY, 2022, Arxiv, DOI [arXiv:2205.10583, DOI 10.48550/ARXIV.2205.10583]; Feng ZY, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P1536; Fu Michael, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P935, DOI 10.1145/3540250.3549098; Furcy D, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P125; Gao X, 2022, Arxiv, DOI arXiv:2211.12787; Gazzola L, 2019, IEEE T SOFTWARE ENG, V45, P34, DOI 10.1109/TSE.2017.2755013; Ghanbari A, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P19, DOI 10.1145/3293882.3330559; github, Llmc4apr study; Guo DY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7212; Guo Daya, 2021, INT C LEARN REPR ICL, P1; Huang K, 2023, Arxiv, DOI arXiv:2303.18184; Kai H, 2022, 52ND ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOP VOLUME (DSN-W 2022), P111, DOI 10.1109/DSN-W54100.2022.00027; huggingface, Unixcoder-base-nine; Ivgi M, 2023, T ASSOC COMPUT LING, V11, P284, DOI 10.1162/tacl_a_00547; Jaszczur S, 2021, ADV NEUR IN; Jiang N, 2023, PROC INT CONF SOFTW, P1251, DOI 10.1109/ICSE48619.2023.00111; Jiang N, 2023, PROC INT CONF SOFTW, P1430, DOI 10.1109/ICSE48619.2023.00125; Jiang N, 2021, PROC INT CONF SOFTW, P1161, DOI 10.1109/ICSE43902.2021.00107; Joshi H, 2022, Arxiv, DOI arXiv:2208.11640; Just Rene, 2014, P 2014 INT S SOFTW T, P437, DOI [10.1145/2610384.2628055, DOI 10.1145/2610384.2628055]; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Li X., 2022, P 37 INT C AUT SOFTW, P1; Li Y, 2022, PROC INT CONF SOFTW, P511, DOI 10.1145/3510003.3510177; Li Y, 2020, PROC INT CONF SOFTW, P602, DOI 10.1145/3377811.3380345; Li ZJ, 2022, PROC INT CONF SOFTW, P2253, DOI 10.1145/3510003.3510217; Liang K. J., 2021, P 9 INT C LEARN REPR; Liu SQ, 2023, IEEE T SOFTWARE ENG, V49, P2839, DOI 10.1109/TSE.2022.3233901; Liu Shangqing, 2023, arXiv; Lu S, 2021, P 35 C NEUR INF PROC, P1; Lutellier Thibaud, 2020, ISSTA '20: Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis, P101, DOI 10.1145/3395363.3397369; Mashhadi E, 2021, IEEE WORK CONF MIN S, P505, DOI 10.1109/MSR52588.2021.00063; Meng XX, 2023, PROC INT CONF SOFTW, P1456, DOI 10.1109/ICSE48619.2023.00127; Meng XX, 2022, PROC INT CONF SOFTW, P1169, DOI 10.1145/3510003.3510147; Monperrus M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3105906; Niu CG, 2023, PROC INT CONF SOFTW, P2136, DOI 10.1109/ICSE48619.2023.00180; Nong Y., 2023, P 45 INT C SOFTW ENG; Park C, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P2888; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Shao Chenze, 2022, arXiv; Sourab M., 2022, Peft: State-of-the-art parameter-efficient fine-tuning methods; Svyatkovskiy A, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1433, DOI 10.1145/3368089.3417058; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Widyasari R, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1556, DOI 10.1145/3368089.3417943; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xia CS, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P959, DOI 10.1145/3540250.3549101; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xia CS, 2023, Arxiv, DOI [arXiv:2303.10494, DOI 10.48550/ARXIV.2303.10494]; Yasunaga M, 2020, P 37 INT C MACH LEAR, V119, p10 799; Ye H, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3556926; Ye H, 2022, PROC INT CONF SOFTW, P1506, DOI 10.1145/3510003.3510222; Yu L, 2023, Megabyte: Predicting million-byte sequences with multiscale transformers; Yuan W, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P678, DOI 10.1145/3533767.3534219; Zeng ZR, 2022, PROCEEDINGS OF THE 31ST ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2022, P39, DOI 10.1145/3533767.3534390; Zhang QJ, 2023, Arxiv, DOI arXiv:2301.03270; Zhong W., 2022, P 37 INT C AUT SOFTW, P1; Zhu QH, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P341, DOI 10.1145/3468264.3468544	70	1	1	4	4	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	1527-1366		979-8-3503-2996-4	IEEE INT CONF AUTOM			2023							1162	1174		10.1109/ASE56229.2023.00181	http://dx.doi.org/10.1109/ASE56229.2023.00181			13	Automation & Control Systems; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science	BW1BK					2024-07-03	WOS:001103357200093
C	Kang, S; Yoo, S			IEEE	Kang, Sungmin; Yoo, Shin			Towards Objective-Tailored Genetic Improvement Through Large Language Models	2023 IEEE/ACM INTERNATIONAL WORKSHOP ON GENETIC IMPROVEMENT, GI			English	Proceedings Paper	12th IEEE/ACM International Workshop on Genetic Improvement (GI)	MAY 20, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, ACM Special Interest Grp Software Engn, IEEE Comp Soc Tech Community Software Engn, UK Res & Innovat		optimization; genetic algorithm		While Genetic Improvement (GI) is a useful paradigm to improve functional and nonfunctional aspects of software, existing techniques tended to use the same set of mutation operators for differing objectives, due to the difficulty of writing custom mutation operators. In this work, we suggest that Large Language Models (LLMs) can be used to generate objective-tailored mutants, expanding the possibilities of software optimizations that GI can perform. We further argue that LLMs and the GI process can benefit from the strengths of one another, and present a simple example demonstrating that LLMs can both improve the effectiveness of the GI optimization process, while also benefiting from the evaluation steps of GI. As a result, we believe that the combination of LLMs and GI has the capability to significantly aid developers in optimizing their software.	[Kang, Sungmin; Yoo, Shin] Korea Adv Inst Sci & Technol, Daejeon, South Korea	Korea Advanced Institute of Science & Technology (KAIST)	Kang, S (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.	sungmin.kang@kaist.ac.kr; shin.yoo@kaist.ac.kr			National Research Foundation of Korea (NRF) Grant [NRF-2020R1A2C1013629]	National Research Foundation of Korea (NRF) Grant(National Research Foundation of Korea)	This work was supported by the National Research Foundation of Korea (NRF) Grant (NRF-2020R1A2C1013629).	Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bruce BR, 2015, GECCO'15: PROCEEDINGS OF THE 2015 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P1327, DOI 10.1145/2739480.2754752; Chen M., 2021, arXiv; Haraldsson SO, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION (GECCO'17 COMPANION), P1513, DOI 10.1145/3067695.3082517; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Langdon W. B., 2012, RN1209 U COLL LOND D; Petke Justyna, 2014, Genetic Programming. 17th European Conference (EuroGP 2014). Revised Selected Papers: LNCS 8599, P137, DOI 10.1007/978-3-662-44303-3_12; Petke Justyna, 2013, Search Based Software Engineering. 5th International Symposium, SSBSE 2013. Proceedings: LNCS 8084, P257, DOI 10.1007/978-3-642-39742-4_21; Petke J, 2018, IEEE T EVOLUT COMPUT, V22, P415, DOI 10.1109/TEVC.2017.2693219; Sarkar A., 2022, What is it like to program with artificial intelligence?; Weimer W, 2009, PROC INT CONF SOFTW, P364, DOI 10.1109/ICSE.2009.5070536; Winter E. R., 2022, P 30 ACM JOINT EUROP, P1578	12	1	1	0	1	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-1232-4				2023							19	20		10.1109/GI59320.2023.00013	http://dx.doi.org/10.1109/GI59320.2023.00013			2	Computer Science, Artificial Intelligence; Computer Science, Software Engineering	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4VV		Green Submitted			2024-07-03	WOS:001042360700004
J	García-Méndez, S; de Arriba-Pérez, F				Garcia-Mendez, Silvia; de Arriba-Perez, Francisco			Large Language Models and Healthcare Alliance: Potential and Challenges of Two Representative Use Cases	ANNALS OF BIOMEDICAL ENGINEERING			English	Article; Early Access						Artificial intelligence; Cognitive decline; Intelligent conversational assistants; Large language models; Natural language processing; Postpartum depression		Large language models (LLMS) emerge as the most promising Natural Language Processing approach for clinical practice acceleration (i.e., diagnosis, prevention and treatment procedures). Similarly, intelligent conversational systems that leverage LLMS have disruptively become the future of therapy in the era of Chatgpt. Accordingly, this research addresses the application of LLMS in healthcare, paying particular attention to two relevant use cases: cognitive decline and depression, more specifically, postpartum depression. In the end, the most promising opportunities they represent (e.g., clinical tasks augmentation, personalized healthcare, etc.) and related concerns (e.g., data privacy and quality, fairness, etc.) are discussed to contribute to the global debate on their integration in the sanitary system.	[Garcia-Mendez, Silvia; de Arriba-Perez, Francisco] Univ Vigo, atlanTTic, Informat Technol Grp, Vigo, Spain	Universidade de Vigo; atlanTTic	de Arriba-Pérez, F (corresponding author), Univ Vigo, atlanTTic, Informat Technol Grp, Vigo, Spain.	sgarcia@gti.uvigo.es; farriba@gti.uvigo.es	García Méndez, Silvia/ABF-4227-2020; de Arriba Pérez, Francisco/D-2450-2018	García Méndez, Silvia/0000-0003-0533-1303; de Arriba Pérez, Francisco/0000-0002-1140-679X	Xunta de Galicia	Xunta de Galicia(Xunta de Galicia)	No Statement Available	Agbavor Felix, 2022, PLOS Digit Health, V1, pe0000168, DOI 10.1371/journal.pdig.0000168; Caruccio L, 2024, EXPERT SYST APPL, V235, DOI 10.1016/j.eswa.2023.121186; Ferdush J, 2024, ANN BIOMED ENG, V52, P1119, DOI 10.1007/s10439-023-03329-4; Hirosawa Takanobu, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043378; Koga S, 2024, BRAIN PATHOL, V34, DOI 10.1111/bpa.13207; Sezgin E, 2023, J MED INTERNET RES, V25, DOI 10.2196/49240; Tibi P, 2021, ANN THORAC SURG, V112, P981, DOI 10.1016/j.athoracsur.2021.03.033; Tustumi F, 2023, ABCD-ARQ BRAS CIR DI, V36, DOI 10.1590/0102-672020230002e1727; Vaidyam AN, 2019, CAN J PSYCHIAT, V64, P456, DOI 10.1177/0706743719828977; Zaman K. T., 2023, P IEEE S COMP COMM, P1, DOI [10.1109/ISCC58397.2023.10218142, DOI 10.1109/ISCC58397.2023.10218142]	10	0	0	12	12	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	2024 FEB 3	2024										10.1007/s10439-024-03454-8	http://dx.doi.org/10.1007/s10439-024-03454-8		FEB 2024	4	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	GY2A1	38310159				2024-07-03	WOS:001156157700001
J	Izquierdo-Domenech, J; Linares-Pellicer, J; Ferri-Molla, I				Izquierdo-Domenech, Juan; Linares-Pellicer, Jordi; Ferri-Molla, Isabel			Large Language Models for in Situ Knowledge Documentation and Access With Augmented Reality	INTERNATIONAL JOURNAL OF INTERACTIVE MULTIMEDIA AND ARTIFICIAL INTELLIGENCE			English	Article; Early Access						Augmented Reality; Deep Learning; Multimodal Interaction; Large Language Models; Transformers	INDUSTRY 4.0; MAINTENANCE	Augmented reality (AR) has become a powerful tool for assisting operators in complex environments, such as shop floors, laboratories, and industrial settings. By displaying synthetic visual elements anchored in real environments and providing information for specific tasks, AR helps to improve efficiency and accuracy. However, a common bottleneck in these environments is introducing all necessary information, which often requires predefined structured formats and needs more ability for multimodal and Natural Language (NL) interaction. This work proposes a new method for dynamically documenting complex environments using AR in a multimodal, non-structured, and interactive manner. Our method employs Large Language Models (LLMs) to allow experts to describe elements from the real environment in NL and select corresponding AR elements in a dynamic and iterative process. This enables a more natural and flexible way of introducing information, allowing experts to describe the environment in their own words rather than being constrained by a predetermined structure. Any operator can then ask about any aspect of the environment in NL to receive a response and visual guidance from the AR system, thus allowing for a more natural and flexible way of introducing and retrieving information. These capabilities ultimately improve the effectiveness and efficiency of tasks in complex environments.	[Izquierdo-Domenech, Juan; Linares-Pellicer, Jordi; Ferri-Molla, Isabel] Univ Politecn Valencia UPV, Valencian Res Inst Artificial Intelligence VRAIN, Valencia, Spain	Universitat Politecnica de Valencia	Ferri-Molla, I (corresponding author), Univ Politecn Valencia UPV, Valencian Res Inst Artificial Intelligence VRAIN, Valencia, Spain.	juaizdom@upv.es; jlinares@dsic.upv.es; isfermol@upv.es	Izquierdo-Domenech, Juan/AAC-5680-2019	Izquierdo-Domenech, Juan/0000-0003-0076-7001; Ferri-Molla, Isabel/0009-0008-3608-9891				Adesope OO, 2017, REV EDUC RES, V87, P659, DOI 10.3102/0034654316689306; Akundi A, 2022, APPL SYST INNOV, V5, DOI 10.3390/asi5010027; [Anonymous], 1991, Situated learning: Legitimate peripheral participation; [Anonymous], 2021, Procedia Computer Science, V181, P51, DOI [10.1016/j.procs.2021.01.104, DOI 10.1016/J.PROCS.2021.01.104]; Arroni S, 2023, INT J INTERACT MULTI, V8, P53, DOI 10.9781/ijimai.2023.02.005; Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459; Baroroh DK, 2021, J MANUF SYST, V61, P696, DOI 10.1016/j.jmsy.2020.10.017; Bécue A, 2021, ARTIF INTELL REV, V54, P3849, DOI 10.1007/s10462-020-09942-2; Billinghurst Mark, 2015, Foundations and Trends in Human-Computer Interaction, V8, P73, DOI 10.1561/1100000049; Bissig D, 2007, PSYCHOL SCI, V18, P720, DOI 10.1111/j.1467-9280.2007.01966.x; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Carpenter SK, 2012, EDUC PSYCHOL REV, V24, P369, DOI 10.1007/s10648-012-9205-z; Carvalho TP, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106024; Casillo M, 2020, PR IEEE INT CONF TEA, P371, DOI 10.1109/TALE48869.2020.9368339; Caudell T.P., 2003, Augmented Reality: An Application of Heads-Up Display Technology to Manual Manufacturing Processes, V2, P659, DOI [10.1109/HICSS.1992.183317, DOI 10.1109/HICSS.1992.183317, 10.1109/hicss.1992.183317]; Cepeda NJ, 2006, PSYCHOL BULL, V132, P354, DOI 10.1037/0033-2909.132.3.354; Chidambaram S, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P234, DOI 10.1145/3461778.3462126; Chu CH, 2021, J MANUF SYST, V61, P658, DOI 10.1016/j.jmsy.2021.05.006; Garza LE, 2013, PROCEDIA COMPUT SCI, V25, P154, DOI 10.1016/j.procs.2013.11.019; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Elia V, 2016, EXPERT SYST APPL, V63, P187, DOI 10.1016/j.eswa.2016.07.006; Fiorentino M, 2009, INT J INTERACT DES M, V3, P121, DOI 10.1007/s12008-009-0062-z; Fiorentino M, 2013, INT J INTERACT DES M, V7, P249, DOI 10.1007/s12008-012-0179-3; Gattullo M, 2019, ROBOT CIM-INT MANUF, V56, P276, DOI 10.1016/j.rcim.2018.10.001; Gilchrist A., 2016, IND 4 0, DOI [DOI 10.1007/978-1-4842-2047-4, 10.1007/978-1-4842-2047-4]; Hardt O, 2013, TRENDS COGN SCI, V17, P111, DOI 10.1016/j.tics.2013.01.001; Hermann M, 2016, P ANN HICSS, P3928, DOI 10.1109/HICSS.2016.488; Hou L, 2015, J COMPUT CIVIL ENG, V29, DOI 10.1061/(ASCE)CP.1943-5487.0000344; Hou L, 2013, J COMPUT CIVIL ENG, V27, P439, DOI 10.1061/(ASCE)CP.1943-5487.0000184; Izquierdo-Domenech J, 2023, MULTIMED TOOLS APPL, V82, P15875, DOI 10.1007/s11042-022-13803-1; Jaschke S, 2014, 2014 INTERNATIONAL CONFERENCE ON INTERACTIVE COLLABORATIVE LEARNING (ICL), P605, DOI 10.1109/ICL.2014.7017840; Kagermann H, 2013, Recommendations for implementing the strategic initiative industrie 4.0: securing the future of German manufacturing industry; final report of the industrie 4.0 working group, DOI DOI 10.1007/978-3-658-05014-6_2; Karpicke JD, 2008, SCIENCE, V319, P966, DOI 10.1126/science.1152408; Kollatsch C, 2021, PROD ENG-RES DEV, V15, P311, DOI 10.1007/s11740-021-01026-6; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Marino E, 2021, COMPUT IND, V127, DOI 10.1016/j.compind.2021.103412; Marques B, 2022, INT J INTERACT DES M, V16, P419, DOI 10.1007/s12008-021-00798-6; Marques B, 2022, IEEE T VIS COMPUT GR, V28, P5113, DOI 10.1109/TVCG.2021.3101545; Maschler B, 2021, IEEE IND ELECTRON M, V15, P65, DOI 10.1109/MIE.2020.3034884; Masood T, 2019, ROBOT CIM-INT MANUF, V58, P181, DOI 10.1016/j.rcim.2019.02.003; Moroff NU, 2021, PROCEDIA COMPUT SCI, V180, P40, DOI 10.1016/j.procs.2021.01.127; Mourtzis D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051855; Ong SK, 2011, CIRP ANN-MANUF TECHN, V60, P1, DOI 10.1016/j.cirp.2011.03.001; Palmarini R., 2022, IEEE Access, DOI [10.1109/ACCESS.2017, DOI 10.1109/ACCESS.2017]; Quint F., 2015, Mensch und Computer 2015-Workshopband, P203, DOI [10.1515/9783110443905-030, DOI 10.1515/9783110443905-030]; Radford A., 2018, IMPROVING LANGUAGE U; Radford A., 2022, arXiv preprint arXiv:2212.04356, V12; Raffel C, 2020, J MACH LEARN RES, V21; Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767; Ribeiro J., 2008, MICROASSEMBLY TECHNO, P295; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Rozanec JM, 2023, INT J PROD RES, V61, P6847, DOI 10.1080/00207543.2022.2138611; Salonen T, 2009, WINVR2009: PROCEEDINGS OF THE ASME/AFM WORLD CONFERENCE ON INNOVATIVE VIRTUAL REALITY - 2009, P165; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Scurati GW, 2018, COMPUT IND, V98, P68, DOI 10.1016/j.compind.2018.02.001; Sereno M, 2022, IEEE T VIS COMPUT GR, V28, P2530, DOI 10.1109/TVCG.2020.3032761; Syberfeldt A, 2016, PROC CIRP, V41, P346, DOI 10.1016/j.procir.2015.12.113; Tatic D, 2017, COMPUT IND, V85, P1, DOI 10.1016/j.compind.2016.11.004; Tay Y, 2022, Arxiv, DOI arXiv:2210.11399; Tay Y, 2022, Arxiv, DOI arXiv:2205.05131; Together, 2022, GPT-JT; Vaswani A, 2017, ADV NEUR IN, V30; Ventura C.A., 2000, P ACM C DOCUMENT PRO, P111, DOI DOI 10.1145/62506.62525; Wang P, 2021, ROBOT CIM-INT MANUF, V72, DOI 10.1016/j.rcim.2020.102071; Wang X, 2016, ADV MANUF, V4, P1, DOI 10.1007/s40436-015-0131-4; Wolf M., 2018, Annals of Faculty Engineering Hunedoara - International Journal of Engineering, Tome XVI, Fascicule, V1, February, P67; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Xu X, 2021, J MANUF SYST, V61, P530, DOI 10.1016/j.jmsy.2021.10.006; Yuan ML, 2008, INT J PROD RES, V46, P1745, DOI 10.1080/00207540600972935; Ziaei Z, 2011, FUSION ENG DES, V86, P2033, DOI 10.1016/j.fusengdes.2010.12.082; Zonta T, 2020, COMPUT IND ENG, V150, DOI 10.1016/j.cie.2020.106889	71	0	0	15	15	UNIV INT RIOJA-UNIR	LOGRONO	RECTORADO, AVENIDA DE LA PAZ, 137, LOGRONO, 26006, SPAIN	1989-1660			INT J INTERACT MULTI	Int. J. Interact. Multimed. Artif. Intell.	2023 SEP 29	2023										10.9781/ijimai.2023.09.002	http://dx.doi.org/10.9781/ijimai.2023.09.002		SEP 2023	11	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	FL6Z3		gold, Green Submitted			2024-07-03	WOS:001145999900001
C	MacNeil, S; Tran, A; Hellas, A; Kim, J; Sarsa, S; Denny, P; Bernstein, S; Leinonen, J			ACM	MacNeil, Stephen; Tran, Andrew; Hellas, Arto; Kim, Joanne; Sarsa, Sami; Denny, Paul; Bernstein, Seth; Leinonen, Juho			Experiences from Using Code Explanations Generated by Large Language Models in a Web Software Development E-Book	PROCEEDINGS OF THE 54TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, VOL 1, SIGCSE 2023			English	Proceedings Paper	54th Annual ACM SIGCSE Technical Symposium on Computer Science Education (SIGCSE TS)	MAR 15-18, 2023	Toronto, CANADA	Assoc Comp Machinery, ACM Special Interest Grp Comp Sci Educ		large language models; explanations; computer science education		Advances in natural language processing have resulted in large language models (LLMs) that can generate code and code explanations. In this paper, we report on our experiences generating multiple code explanation types using LLMs and integrating them into an interactive e-book on web software development. Three different types of explanations - a line-by-line explanation, a list of important concepts, and a high-level summary of the code - were created. Students could view explanations by clicking a button next to code snippets, which showed the explanation and asked about its utility. Our results show that all explanation types were viewed by students and that the majority of students perceived the code explanations as helpful to them. However, student engagement varied by code snippet complexity, explanation type, and code snippet length. Drawing on our experiences, we discuss future directions for integrating explanations generated by LLMs into CS classrooms.	[MacNeil, Stephen; Tran, Andrew; Kim, Joanne; Bernstein, Seth] Temple Univ, Philadelphia, PA 19122 USA; [Hellas, Arto; Sarsa, Sami; Leinonen, Juho] Aalto Univ, Espoo, Finland	Pennsylvania Commonwealth System of Higher Education (PCSHE); Temple University; Aalto University	MacNeil, S (corresponding author), Temple Univ, Philadelphia, PA 19122 USA.	stephen.macneil@temple.edu; andrew.tran10@temple.edu; arto.hellas@aalto.fi; joanne.kim@temple.edu; sami.sarsa@aalto.fi; paul@cs.auckland.ac.nz; seth.bernstein@temple.edu; juho.2.leinonen@aalto.fi	Leinonen, Juho/D-2162-2018; MacNeil, Stephen/HPH-0843-2023	Leinonen, Juho/0000-0001-6829-9449; MacNeil, Stephen/0000-0003-2781-6619; Denny, Paul/0000-0002-5150-9806; Bernstein, Seth/0000-0002-7552-5448; Sarsa, Sami/0000-0002-7277-9282				Ala-Mutka KM, 2005, COMPUT SCI EDUC, V15, P83, DOI 10.1080/08993400500150747; [Anonymous], 2017 ACM SIGCSE TECH, P483; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Barke S, 2022, Arxiv, DOI [arXiv:2206.15000, DOI 10.48550/ARXIV.2206.15000]; Beck Joseph E., 2013, Artificial Intelligence in Education. Proceedings of 16th International Conference (AIED 2013): LNCS 7926, P431, DOI 10.1007/978-3-642-39112-5_44; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, arXiv; Cunningham K, 2022, PROCEEDINGS OF THE 53RD ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE 2022), VOL 1, P551, DOI 10.1145/3478431.3499370; Denny P, 2011, SIGCSE 11: PROCEEDINGS OF THE 42ND ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P471; Denny Paul, 2008, P 4 INT WORKSHOP COM, P51, DOI [DOI 10.1145/1404520.1404526, 10.1145/1404520.1404526]; Dondio P., 2019, P 2019 11 INT C ED T, P132; Finnie-Ansley J, 2022, PROCEEDINGS OF THE 24TH AUSTRALASIAN COMPUTING EDUCATION CONFERENCE, ACE 2022, P10, DOI 10.1145/3511861.3511863; Gao TY, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (ACL-IJCNLP 2021), VOL 1, P3816; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Griffin JM, 2016, SIGITE'16: PROCEEDINGS OF THE 17TH ANNUAL CONFERENCE ON INFORMATION TECHNOLOGY EDUCATION, P148, DOI 10.1145/2978192.2978231; Guo Philip J, 2013, Proceedings of the 44th SIGCSE Technical Symposium on Computer Science Education, SIGCSE '13, P579, DOI [10.1145/2445196.2445368, DOI 10.1145/2445196.2445368]; Hanks B, 2011, COMPUT SCI EDUC, V21, P135, DOI 10.1080/08993408.2011.579808; Head A, 2015, PROCEEDINGS 2015 IEEE SYMPOSIUM ON VISUAL LANGUAGES AND HUMAN-CENTRIC COMPUTING (VL/HCC), P3, DOI 10.1109/VLHCC.2015.7356972; Ihantola Petri, 2010, P 10 KOL CALL INT C; Kennedy Cazembe, 2020, P 2020 ACM C INNOVAT, P166, DOI [10.1145/3341525.3387392, DOI 10.1145/3341525]; Ko Andrew J., 2004, P SIGCHI C HUM FACT, P151, DOI [10.1145/985692.985712, DOI 10.1145/985692.985712]; Leinonen Juho, 2020, ITiCSE '20: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, P349, DOI 10.1145/3341525.3387385; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Macneil Stephen, 2022, ICER 2022 V2: Proceedings of the 2022 ACM Conference on International Computing Education Research, P37, DOI 10.1145/3501709.3544280; MacNeil S, 2022, ADJUNCT PROCEEDINGS OF THE 35TH ACM SYMPOSIUM ON USER INTERFACE SOFTWARE & TECHNOLOGY, UIST 2022, DOI 10.1145/3526114.3558627; Marwan Samiha, 2020, ICER '20. Proceedings of the 2020 ACM Conference on International Computing Education Research, P194, DOI 10.1145/3372782.3406264; Marwan S, 2019, PROCEEDINGS OF THE 2019 ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION (ITICSE '19), P520, DOI 10.1145/3304221.3319759; Murphy Laurie, 2012, PROC 9 ANN INT C INT, P111, DOI DOI 10.1145/2361276.2361299; Myller N., 2009, ACM Transactions on Computing Education, V9, P1, DOI DOI 10.1145/1513593.1513600; Nelson GL, 2017, PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INTERNATIONAL COMPUTING EDUCATION RESEARCH (ICER 17), P2, DOI 10.1145/3105726.3106178; Nesbit JC, 2014, IEEE INT CONF ADV LE, P99, DOI 10.1109/ICALT.2014.38; Paiva JC, 2022, ACM T COMPUT EDUC, V22, DOI 10.1145/3513140; Piech C., 2015, P 2 ACM C LEARN SCAL, P195, DOI DOI 10.1145/2724660.2724668.20T.W; Pirttinen N, 2018, ITICSE'18: PROCEEDINGS OF THE 23RD ANNUAL ACM CONFERENCE ON INNOVATION AND TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P326, DOI 10.1145/3197091.3197117; Pöial J, 2021, ADV INTELL SYST COMP, V1328, P703, DOI 10.1007/978-3-030-68198-2_65; Price TW, 2017, PROCEEDINGS OF THE 2017 ACM SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION (SIGCSE'17), P483, DOI 10.1145/3017680.3017762; Qi RX, 2020, SIGCSE 2020: PROCEEDINGS OF THE 51ST ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P427, DOI 10.1145/3328778.3366939; Sarsa Sami, 2022, ICER 2022 V1: Proceedings of the 2022 ACM Conference on International Computing Education Research V.1, P27, DOI 10.1145/3501385.3543957; Sobania D, 2021, Arxiv, DOI arXiv:2111.07875; Tack A, 2022, Arxiv, DOI arXiv:2205.07540; Ullah Z, 2018, COMPUT APPL ENG EDUC, V26, P2328, DOI 10.1002/cae.21974; Vaithilingam Priyan, 2022, CHI C HUMAN FACTORS; Vihavainen Arto, 2015, P 46 ACM TECHNICAL S, P284, DOI [DOI 10.1145/2676723.2677260, 10.1145/2676723, DOI 10.1145/2676723]; Wengran Wang, 2020, ITiCSE '20: Proceedings of the 2020 ACM Conference on Innovation and Technology in Computer Science Education, P391, DOI 10.1145/3341525.3387411; Whalley Jacqueline L., 2006, ACE '06, V52, P243; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105	46	33	33	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9431-4				2023							931	937		10.1145/3545945.3569785	http://dx.doi.org/10.1145/3545945.3569785			7	Computer Science, Theory & Methods; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW2KI		Green Submitted			2024-07-03	WOS:001117817800134
C	Saxena, S; Prasad, S; Muneeswaran, ; Shankar, A; Varun, V; Gopalakrishnant, S; Vaddinat, V			Assoc computing machinery	Saxena, Shreya; Prasad, Siva; Muneeswaran, I; Shankar, Advaith; Varun, V.; Gopalakrishnant, Saisubramaniam; Vaddinat, Vishal			Automated Tailoring of Large Language Models for Industry-Specific Downstream Tasks	PROCEEDINGS OF THE 17TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, WSDM 2024			English	Proceedings Paper	17th ACM International Conference on Web Search and Data Mining (WSDM)	MAR 04-08, 2024	Merida, MEXICO	Assoc Comp Machinery, ACM SIGMOD, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB, ACM SIGKDD		Large Language Model; Data Generation; Finetuning; Evaluation		Foundational Large Language Models (LLMs) are pre-trained generally on huge corpora encompassing broad subjects to become versatile and generalize to future downstream tasks. However, their effectiveness falls short when dealing with tasks that are highly specialized to a specific use case. Even when adopting current prompt engineering techniques like few-shot or Chain-of-Thought reasoning prompts, the required level of results is not yet achievable directly with foundational models alone. The alternative approach is to fine-tune the LLM, but a common challenge is the limited availability of task-specific training data. In this talk, we will introduce an end-to-end automated framework to tailor a model to specific downstream tasks for an industry where the first step is to generate task-specific custom data from unstructured documents. Next, we will discuss our optimized distributed training pipeline for fine-tuning LLMs on the generated data. Finally, we will provide an overview of the statistical metrics and customized metrics we employ for assessing the performance of the fine-tuned LLM. This automated framework alleviates the burden of manual adjustments and streamlines the process to provide a model that is fully customized to suit the unique requirements of any specific business use case.	[Saxena, Shreya; Prasad, Siva; Muneeswaran, I; Shankar, Advaith; Varun, V.; Gopalakrishnant, Saisubramaniam; Vaddinat, Vishal] Quantiphi Analyt Solut Pvt Ltd, Appl Res, Bengaluru, India		Vaddinat, V (corresponding author), Quantiphi Analyt Solut Pvt Ltd, Appl Res, Bengaluru, India.	shreya.saxena@quantiphi.com; siva.prasad@quantiphi.com; muneeswaran.i@quantiphi.com; advaith.shankar@quantiphi.com; varun.v@quantiphi.com; gopalakrishnan.saisubramaniam@quantiphi.com; vishal.vaddina@quantiphi.com		I, Muneeswaran/0009-0002-0206-0077				Lee DB, 2020, Arxiv, DOI arXiv:2005.13837; Chen SY, 2020, Arxiv, DOI arXiv:2004.12651; Houlsby N, 2019, PR MACH LEARN RES, V97; Loem M, 2022, Arxiv, DOI arXiv:2201.05313; Luo Y, 2024, Arxiv, DOI arXiv:2308.08747; Srivastava Aarohi, 2022, arXiv	6	0	0	6	6	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0371-3				2024							1184	1185		10.1145/3616855.3635743	http://dx.doi.org/10.1145/3616855.3635743			2	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW6TN					2024-07-03	WOS:001182230100160
J	Gupta, BB; Gaurav, A; Arya, V; Alhalabi, W; Alsalman, D; Vijayakumar, P				Gupta, Brij B.; Gaurav, Akshat; Arya, Varsha; Alhalabi, Wadee; Alsalman, Dheyaaldin; Vijayakumar, P.			Enhancing user prompt confidentiality in Large Language Models through advanced differential encryption	COMPUTERS & ELECTRICAL ENGINEERING			English	Article						Cryptographic privacy; Large Language Models; Data anonymization; Secure AI framework; Personal data protection	AUTHENTICATION PROTOCOL; DESIGN	In the era of artificial intelligence (AI) advancements heralded by Large Language Models (LLMs) like GPT-3, the capacity to parse and generate human -like text brings to light substantial privacy concerns. These arise notably from LLMs' reliance on vast datasets often laden with personal information, underscoring the potential for inadvertent memorization and disclosure of sensitive data. Addressing these pivotal privacy concerns, our research introduces a novel two -fold approach aimed at bolstering the confidentiality and security of user data in LLM applications. Firstly, we deploy advanced cryptographic techniques, incorporating bespoke encryption and hashing protocols, to preprocess user data. This strategy effectively anonymizes personal identifiers prior to their processing by LLMs, directly tackling the challenges of sensitive information exposure. Concurrently, our methodology encompasses a secure mutual authentication protocol utilizing lightweight cryptographic measures. This ensures that system interactions are strictly reserved for authenticated users, thereby enhancing overall data security. Collectively, our approach not only preserves the utility of data for AI tasks but also fortifies the privacy framework surrounding LLMs, significantly reducing the likelihood of privacy breaches and steering AI development towards a more secure and ethically grounded future.	[Gupta, Brij B.] Asia Univ, Int Ctr AI & Cyber Secur Res & Innovat CCRI, Taichung, Taiwan; [Gupta, Brij B.] Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan; [Gupta, Brij B.] Kyung Hee Univ, 26 Kyungheedae Ro, Seoul, South Korea; [Gupta, Brij B.] Symbiosis Int Univ, Symbiosis Ctr Informat Technol SCIT, Pune, India; [Gupta, Brij B.] Univ Petr & Energy Studies UPES, Ctr Interdisciplinary Res, Dehra Dun, India; [Gaurav, Akshat] Ronin Inst, Montclair, NJ USA; [Arya, Varsha] Asia Univ, Dept Business Adm, Taichung, Taiwan; [Arya, Varsha] Lebanese Amer Univ, Dept Elect & Comp Engn, Beirut 1102, Lebanon; [Alhalabi, Wadee] King Abdulaziz Univ, Dept Comp Sci, Immers Virtual Real Res Grp, Jeddah, Saudi Arabia; [Alsalman, Dheyaaldin] Dar Al Hekma Univ, Sch Engn Comp & Informat, Jeddah, Saudi Arabia; [Vijayakumar, P.] Univ Coll Engn Tindivanam, Dept Comp Sci & Engn, Tindivanam 604001, Tamil Nadu, India	Asia University Taiwan; Asia University Taiwan; Kyung Hee University; Symbiosis International University; Symbiosis Centre for Information Technology (SCIT); University of Petroleum & Energy Studies (UPES); Asia University Taiwan; Lebanese American University; King Abdulaziz University; Dar Al Hekma University	Gupta, BB (corresponding author), Asia Univ, Int Ctr AI & Cyber Secur Res & Innovat CCRI, Taichung, Taiwan.; Gupta, BB (corresponding author), Asia Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.; Gupta, BB (corresponding author), Kyung Hee Univ, 26 Kyungheedae Ro, Seoul, South Korea.; Gupta, BB (corresponding author), Symbiosis Int Univ, Symbiosis Ctr Informat Technol SCIT, Pune, India.; Gupta, BB (corresponding author), Univ Petr & Energy Studies UPES, Ctr Interdisciplinary Res, Dehra Dun, India.	bbgupta@asia.edu.tw	Gupta, Brij B/E-9813-2011; Pandi, Vijayakumar/Y-4636-2019	Gupta, Brij B/0000-0003-4929-4698; Pandi, Vijayakumar/0000-0001-5451-8946	Deanship of Scientific Research (DSR) at King Abdulaziz University (KAU) , Jeddah, Saudi Arabia [IFPIP:1110-611-1443]	Deanship of Scientific Research (DSR) at King Abdulaziz University (KAU) , Jeddah, Saudi Arabia	The Deanship of Scientific Research (DSR) at King Abdulaziz University (KAU) , Jeddah, Saudi Arabia, has funded this project, under grant no. (IFPIP:1110-611-1443) ) .	Alanazi M, 2022, COMPUT SYST SCI ENG, V42, P703, DOI 10.32604/csse.2022.022962; Almomani A, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297032; Aloufi BO, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042015; Alshammari M, 2022, INTELL AUTOM SOFT CO, V32, P401, DOI 10.32604/iasc.2022.022065; Bisht Jyoti, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010105; Bounds DT, 2023, J CHILD ADOL PS NURS, V36, P7, DOI 10.1111/jcap.12396; Chow MC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22124525; Ding L., 2023, Front. Comput. Intell. Syst, V3, P167, DOI [10.54097/fcis.v3i1.6362, DOI 10.54097/FCIS.V3I1.6362]; Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593; Gupta BB, 2024, ENTERP INF SYST-UK, V18, DOI 10.1080/17517575.2024.2310846; Hagendorff T, 2022, AI Ethics, V3, P553, DOI [10.1007/s43681-022-00188-y, DOI 10.1007/S43681-022-00188-Y]; Hu B, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.302895; Ibrahim M, 2022, KUWAIT J SCI, V49, DOI 10.48129/kjs.v49i1.10745; Jung J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030644; Jung J, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169414; Kawamoto Y, 2021, SOFTW SYST MODEL, V20, P293, DOI 10.1007/s10270-020-00825-2; Klosowski P, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052758; Kovalev AK, 2022, DOKL MATH, V106, pS85, DOI 10.1134/S1064562422060138; Kumbhojkar Neelesh Ragunath, 2022, International Journal of Cloud Applications and Computing, V12, P1, DOI 10.4018/IJCAC.2022010107; Li SD, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.297035; Li Y, 2022, J SUPERCOMPUT, V78, P17261, DOI 10.1007/s11227-022-04558-5; Libbi CA, 2021, FUTURE INTERNET, V13, DOI 10.3390/fi13050136; Liu RB, 2021, AAAI CONF ARTIF INTE, V35, P14857; Liu RW, 2023, IEEE T IND INFORM, V19, P1581, DOI 10.1109/TII.2022.3170594; Madhu S, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.300362; Mahendran D, 2021, IEEE ACCESS, V9, P147600, DOI 10.1109/ACCESS.2021.3124163; Mridha M, 2022, Int J Comput Digit Syst, V11, P251, DOI [10.12785/ijcds/110121.12, DOI 10.12785/IJCDS/110121.12]; Nhi NTU, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295551; Pan XN, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.291713; Pandey PC, 2021, J BIOMED MATER RES B, V109, P33, DOI [10.1002/jbm.b.34678, 10.1007/s40860-020-00098-y]; Ryu J, 2022, IEEE ACCESS, V10, P98944, DOI 10.1109/ACCESS.2022.3206457; Schick T, 2021, T ASSOC COMPUT LING, V9, P1408, DOI 10.1162/tacl_a_00434; Son S, 2020, IEEE ACCESS, V8, P192177, DOI 10.1109/ACCESS.2020.3032680; Tembhurne JV, 2022, INT J SEMANT WEB INF, V18, DOI 10.4018/IJSWIS.295553; Thammarat C, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/6953160; Trummer I, 2022, PROC VLDB ENDOW, V15, P3770, DOI 10.14778/3554821.3554896; Trummer I, 2021, SIGMOD REC, V50, P27, DOI 10.1145/3503780.3503788; Le TV, 2022, IEEE ACCESS, V10, P28975, DOI 10.1109/ACCESS.2022.3158756; Tziakouris G, 2022, SOFTWARE PRACT EXPER, V52, P2005, DOI 10.1002/spe.3113; ul Haq I, 2020, J NETW COMPUT APPL, V161, DOI 10.1016/j.jnca.2020.102660; Xiong P, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6680; Xu ZY, 2023, IEEE J BIOMED HEALTH, V27, P2334, DOI 10.1109/JBHI.2021.3128775; Yang JC, 2020, AAAI CONF ARTIF INTE, V34, P9378; Zhang Q, 2023, PATTERN RECOGN LETT, V168, P31, DOI 10.1016/j.patrec.2023.02.026; Zhou ZL, 2023, IEEE T NETW SCI ENG, V10, P2779, DOI 10.1109/TNSE.2022.3199919	45	1	1	2	2	PERGAMON-ELSEVIER SCIENCE LTD	OXFORD	THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND	0045-7906	1879-0755		COMPUT ELECTR ENG	Comput. Electr. Eng.	MAY	2024	116								109215	10.1016/j.compeleceng.2024.109215	http://dx.doi.org/10.1016/j.compeleceng.2024.109215			13	Computer Science, Hardware & Architecture; Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	QX2D9					2024-07-03	WOS:001224093700001
C	Said, A; Willemsen, M; Marinho, LB; Silva, I			ACM	Said, Alan; Willemsen, Martijn; Marinho, Leandro Balby; Silva, Itallo			Leveraging Large Language Models for Goal-aware Interactive Recommendations	PROCEEDINGS OF THE 11TH CONFERENCE ON HUMAN-AGENT INTERACTION, HAI 2023			English	Proceedings Paper	11th International Conference on Human-Agent Interaction (HAI)	DEC 04-07, 2023	Chalmers Univ Technol, Gothenburg, SWEDEN	Assoc Comp Machinery, ACM SIGCHI	Chalmers Univ Technol			We present a proof of concept application for interactive recommendations and explanations leveraging the capabilities of Large Language Models (LLMs). The application creates a highly interactive user-driven setting for recommendations giving users the possibility to explicitly tailor recommendations to their needs. Using the possibilities brought by LLMs, the application further generates convincing explanations of recommendations, aligned with the explicitly stated goals of the users. The web application continuously improves by incorporating user feedback and updating recommendations and explanations as needed.	[Said, Alan] Univ Gothenburg, Gothenburg, Sweden; [Willemsen, Martijn] TU Eindhoven, Eindhoven, Netherlands; [Willemsen, Martijn] JADS, Eindhoven, Netherlands; [Marinho, Leandro Balby; Silva, Itallo] Univ Fed Campina Grande, Campina Grande, Paraiba, Brazil	University of Gothenburg; Eindhoven University of Technology; Universidade Federal de Campina Grande	Said, A (corresponding author), Univ Gothenburg, Gothenburg, Sweden.	alansaid@acm.org; m.c.willemsen@tue.nl; lbmarinho@dsc.ufcg.edu.br; itallo.silva@ccc.ufcg.edu.br						Abdollahpouri H, 2020, USER MODEL USER-ADAP, V30, P127, DOI 10.1007/s11257-019-09256-1; Aggarwal S, 2020, RECSYS 2020: 14TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, P160, DOI 10.1145/3383313.3412255; Castells N. Hurley, 2022, Recommender Systems Handbook, P603, DOI DOI 10.1007/978-1-0716-2197-4_16; Chang S, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P175, DOI 10.1145/2959100.2959153; Ekstrand MD, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P221, DOI 10.1145/2959100.2959179; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Hadash S, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517650; Park M, 2022, PROCEEDINGS OF THE 16TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2022, P229, DOI 10.1145/3523227.3546768; Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1; Roy D, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00592-5; Tintarev N, 2011, RECOMMENDER SYSTEMS HANDBOOK, P479, DOI 10.1007/978-0-387-85820-3_15; Tintarev N, 2007, I C DATA ENGIN WORKS, P801, DOI 10.1109/ICDEW.2007.4401070; Zhang YF, 2020, FOUND TRENDS INF RET, V14, P1, DOI 10.1561/1500000066	13	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0824-4				2023							464	466		10.1145/3623809.3623965	http://dx.doi.org/10.1145/3623809.3623965			3	Computer Science, Cybernetics; Computer Science, Interdisciplinary Applications; Robotics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Robotics	BW4HI					2024-07-03	WOS:001148034200081
C	Koreeda, Y; Morishita, T; Imaichi, O; Sogawa, Y			ACM	Koreeda, Yuta; Morishita, Terufumi; Imaichi, Osamu; Sogawa, Yasuhiro			LARCH: Large Language Model-based Automatic Readme Creation with Heuristics	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		large language model; software development; weak supervision		Writing a readme is a crucial aspect of software development as it plays a vital role in managing and reusing program code. Though it is a pain point for many developers, automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating an abstract description from thousands of lines of code. In this demo paper, we show that LLMs are capable of generating a coherent and factually correct readmes if we can identify a code fragment that is representative of the repository. Building upon this finding, we developed LARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages representative code identification with heuristics and weak supervision. Through human and automated evaluations, we illustrate that LARCH can generate coherent and factually correct readmes in the majority of cases, outperforming a baseline that does not rely on representative code identification. We have made LARCH open-source and provided a cross-platform Visual Studio Code interface and command-line interface, accessible at https://github.com/hitachi-nlp/larch. A demo video showcasing LARCH's capabilities is available at https://youtu.be/ZUKkh5ED-O4.	[Koreeda, Yuta; Morishita, Terufumi; Imaichi, Osamu; Sogawa, Yasuhiro] Hitachi Ltd, Res & Dev Grp, Kokubunji, Tokyo, Japan	Hitachi Limited	Koreeda, Y (corresponding author), Hitachi Ltd, Res & Dev Grp, Kokubunji, Tokyo, Japan.	yuta.koreeda.pb@hitachi.com; terufumi.morishita.wp@hitachi.com; osamu.imaichi.xc@hitachi.com; yasuhiro.sogawa.tp@hitachi.com						Anthropic, 2023, Technical report Anthropic; Bommasani R., 2021, 2108.07258; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, ARXIV; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; de Souza Sergio Cozzetti B., 2005, P 23 ANN INT C DES C, P68; Gamma E., 1995, DESIGN PATTERNS ELEM; Husain H., 2019, CodeSearchNet Challenge: Evaluating the State of Semantic Code Search; Kojima Takeshi, 2022, Advances in Neural Information Processing Systems; Li Raymond, 2023, STARCODES MAY SOURCE; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu NF., 2023, LOST MIDDLE LANGUAGE; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; OpenAI, 2023, OpenAI Blog; OpenAI, 2023, GPT-4 Technical Report; Ouyang Long, 2022, ADV NEURAL INFORM PR; Ratner A, 2020, VLDB J, V29, P709, DOI [10.1007/s00778-019-00552-1, 10.14778/3157794.3157797]; Ratner Alexander, 2019, Proc AAAI Conf Artif Intell, V33, P4763, DOI 10.1609/aaai.v33i01.33014763; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Shi Weijia, 2023, REPLUG RETRIEVAL AUG, DOI [10.48550/ARXIV.2301.12652, DOI 10.48550/ARXIV.2301.12652]; Vaswani A., 2017, Advances in neural information processing systems, P6000; Wang Yue, 2021, P 2021 C EMP METH NA, DOI [DOI 10.18653/V1/2021.EMNLP-MAIN.685, 10.18653/v1/2021.emnlp-main.685]; Yasunaga Michihiro, 2020, INT C MACH LEARN ICM, DOI 10.5555/3524938.3525939	23	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							5066	5070		10.1145/3583780.3614744	http://dx.doi.org/10.1145/3583780.3614744			5	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Submitted, Bronze			2024-07-03	WOS:001161549505017
J	Fecher, B; Hebing, M; Laufer, M; Pohle, J; Sofsky, F				Fecher, Benedikt; Hebing, Marcel; Laufer, Melissa; Pohle, Joerg; Sofsky, Fabian			Friend or foe? Exploring the implications of large language models on the science system	AI & SOCIETY			English	Article; Early Access						Large language models; Science system; Delphi study; Scholarly communication		The advent of ChatGPT by OpenAI has prompted extensive discourse on its potential implications for science and higher education. While the impact on education has been a primary focus, there is limited empirical research on the effects of large language models (LLMs) and LLM-based chatbots on science and scientific practice. To investigate this further, we conducted a Delphi study involving 72 researchers specializing in AI and digitization. The study focused on applications and limitations of LLMs, their effects on the science system, ethical and legal considerations, and the required competencies for their effective use. Our findings highlight the transformative potential of LLMs in science, particularly in administrative, creative, and analytical tasks. However, risks related to bias, misinformation, and quality assurance need to be addressed through proactive regulation and science education. This research contributes to informed discussions on the impact of generative AI in science and helps identify areas for future action.	[Fecher, Benedikt; Hebing, Marcel; Laufer, Melissa; Pohle, Joerg; Sofsky, Fabian] Alexander von Humboldt Inst Internet & Soc, Berlin, Germany; [Fecher, Benedikt] Wissensch Dialog, Berlin, Germany; [Hebing, Marcel] DBU Digital Business Univ Appl Sci, Berlin, Germany		Fecher, B (corresponding author), Alexander von Humboldt Inst Internet & Soc, Berlin, Germany.; Fecher, B (corresponding author), Wissensch Dialog, Berlin, Germany.	fecher@hiig.de; marcel.hebing@hiig.de; melissa.laufer@hiig.de; joerg.pohle@hiig.de; fabian.sofsky@hiig.de			Alexander von Humboldt Institute for Internet and Society	Alexander von Humboldt Institute for Internet and Society	This study was funded and primarily conducted by the Alexander von Humboldt Institute for Internet and Society	Bazeley P., 2009, MALAYSIAN J QUALITAT, V2, P6; Beer D, 2019, Impact of Social Sciences-LSE Blog; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Buruk O, 2023, Arxiv, DOI [arXiv:2304.11079, 10.48550/arXiv.2304.11079, DOI 10.48550/ARXIV.2304.11079]; Chubb J, 2022, AI SOC, V37, P1439, DOI 10.1007/s00146-021-01259-0; Coeckelbergh M, 2023, AI SOC, DOI 10.1007/s00146-023-01710-4; Corless V., 2023, ADV SCI NEWS; Deranty JP, 2024, AI SOC, V39, P675, DOI 10.1007/s00146-022-01496-x; Dillion D, 2023, TRENDS COGN SCI, V27, P597, DOI 10.1016/j.tics.2023.04.008; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Flanagin A, 2023, JAMA-J AM MED ASSOC, V329, P637, DOI 10.1001/jama.2023.1344; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Fyfe P, 2023, AI SOC, V38, P1395, DOI 10.1007/s00146-022-01397-z; Gellers JC, 2023, AI SOC, DOI 10.1007/s00146-023-01708-y; Goujard C, 2023, European data regulators set up ChatGPT task force; GPDP, 2023, Intelligenza artificiale: Il Garante blocca ChatGPT. Raccolta illecita di dati personali; Grimaldi G, 2023, ACS ENERGY LETT, V8, P878, DOI 10.1021/acsenergylett.2c02828; Hacker P, 2023, Arxiv, DOI [arXiv:2302.02337, DOI 10.48550/ARXIV.2302.02337, 10.48550/arXiv.2302.02337, DOI 10.48550/AR-XIV.2302.02337]; Hao K, 2019, MIT Technology Review; Harding J, 2023, AI SOC, DOI 10.1007/s00146-023-01725-x; Helberger N, 2023, INTERNET POLICY REV, V12, P28, DOI 10.14763/2023.1.1682; Hosseini M, 2023, RES INTEGR PEER REV, V8, DOI 10.1186/s41073-023-00133-5; Hosseini M, 2023, ACCOUNT RES, DOI 10.1080/08989621.2023.2168535; Jiang M, 2022, PACIS 2022 P, V312; Khowaja SA, 2024, Arxiv, DOI arXiv:2305.03123; Kirchenbauer J, 2024, Arxiv, DOI arXiv:2301.10226; Landeta J, 2006, TECHNOL FORECAST SOC, V73, P467, DOI 10.1016/j.techfore.2005.09.002; Liang WX, 2023, Arxiv, DOI [arXiv:2304.02819, DOI 10.48550/ARXIV.2304.02819]; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Linstone A., 1975, DELPHI METHOD TECHNI; Lucey B., 2023, CONVERSATION; Lund BD, 2023, J ASSOC INF SCI TECH, V74, P570, DOI 10.1002/asi.24750; OpenAI, 2022, Introducing chatgpt; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Pividori M, 2023, bioRxiv, DOI [10.1101/2023.01.21.525030, 10.1101/2023.01.21.525030, DOI 10.1101/2023.01.21.525030]; Ribeiro B, 2023, RES POLICY, V52, DOI 10.1016/j.respol.2022.104607; Schäfer MS, 2023, JCOM-J SCI COMMUN, V22, DOI 10.22323/2.22020402; Sokolov DA, 2023, ChatGPT: Deutschlands Datenschutzer eroffnen Verfahren gegen OpenAI; Staiman A, 2023, Guest Post-academic publishers are missing the point on ChatGPT; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Teubner T, 2023, BUS INFORM SYST ENG+, V65, P95, DOI 10.1007/s12599-023-00795-x; Tomlinson B, 2023, Arxiv, DOI arXiv:2305.03722; Van Noorden R, 2022, NATURE, V605, P21, DOI 10.1038/d41586-022-01191-3; Wulff K, 2023, AI SOC, DOI 10.1007/s00146-023-01633-0	46	3	3	19	20	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0951-5666	1435-5655		AI SOC	AI Soc.	2023 OCT 26	2023										10.1007/s00146-023-01791-1	http://dx.doi.org/10.1007/s00146-023-01791-1		OCT 2023	13	Computer Science, Artificial Intelligence	Emerging Sources Citation Index (ESCI)	Computer Science	AL4D5		Green Submitted, hybrid			2024-07-03	WOS:001118598200001
J	Luitel, D; Hassani, S; Sabetzadeh, M				Luitel, Dipeeka; Hassani, Shabnam; Sabetzadeh, Mehrdad			Improving requirements completeness: automated assistance through large language models	REQUIREMENTS ENGINEERING			English	Article						Requirements completeness; Natural language processing (NLP); Machine learning (ML); Large language models (LLMs); BERT		Natural language (NL) is arguably the most prevalent medium for expressing systems and software requirements. Detecting incompleteness in NL requirements is a major challenge. One approach to identify incompleteness is to compare requirements with external sources. Given the rise of large language models (LLMs), an interesting question arises: Are LLMs useful external sources of knowledge for detecting potential incompleteness in NL requirements? This article explores this question by utilizing BERT. Specifically, we employ BERT's masked language model to generate contextualized predictions for filling masked slots in requirements. To simulate incompleteness, we withhold content from the requirements and assess BERT's ability to predict terminology that is present in the withheld content but absent in the disclosed content. BERT can produce multiple predictions per mask. Our first contribution is determining the optimal number of predictions per mask, striking a balance between effectively identifying omissions in requirements and mitigating noise present in the predictions. Our second contribution involves designing a machine learning-based filter to post-process BERT's predictions and further reduce noise. We conduct an empirical evaluation using 40 requirements specifications from the PURE dataset. Our findings indicate that: (1) BERT's predictions effectively highlight terminology that is missing from requirements, (2) BERT outperforms simpler baselines in identifying relevant yet missing terminology, and (3) our filter reduces noise in the predictions, enhancing BERT's effectiveness for completeness checking of requirements.	[Luitel, Dipeeka; Hassani, Shabnam; Sabetzadeh, Mehrdad] Univ Ottawa, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada	University of Ottawa	Luitel, D (corresponding author), Univ Ottawa, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.	dipeeka.luitel@uottawa.ca; s.hassani@uottawa.ca; m.sabetzadeh@uottawa.ca			Natural Sciences and Engineering Research Council of Canada; Natural Sciences and Engineering Research Council of Canada (NSERC) under the Discovery and Discovery Accelerator programs	Natural Sciences and Engineering Research Council of Canada(Natural Sciences and Engineering Research Council of Canada (NSERC)CGIAR); Natural Sciences and Engineering Research Council of Canada (NSERC) under the Discovery and Discovery Accelerator programs	This work was funded by the Natural Sciences and Engineering Research Council of Canada (NSERC) under the Discovery and Discovery Accelerator programs.	Abbas M, 2021, 27 INT WORKING C REQ; Alrajeh D, 2012, PROC INT CONF SOFTW, P705, DOI 10.1109/ICSE.2012.6227147; Amaral O, 2022, IEEE T SOFTWARE ENG, V48, P4647, DOI 10.1109/TSE.2021.3124332; Arora C, 2019, EMPIR SOFTW ENG, V24, P2509, DOI 10.1007/s10664-019-09693-x; Arora C, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3293454; Arora C, 2017, IEEE T SOFTWARE ENG, V43, P918, DOI 10.1109/TSE.2016.2635134; Arora C, 2015, IEEE T SOFTWARE ENG, V41, P944, DOI 10.1109/TSE.2015.2428709; Bergstra J, 2012, J MACH LEARN RES, V13, P281; Berry D. M., 2003, From contract drafting to software specification: Linguistic sources of ambiguity; Berry DM, 2021, EMPIR SOFTW ENG, V26, DOI 10.1007/s10664-021-09986-0; Bhatia J, 2018, INT REQUIR ENG CONF, P159, DOI 10.1109/RE.2018.00025; Cai J, 2018, NEUROCOMPUTING, V300, P70, DOI 10.1016/j.neucom.2017.11.077; Capon JA, 1988, ELEMENTARY STAT SOCI; Cui G, 2008, 6 INT C LANGUAGE RES; Dalpiaz F, 2018, LECT NOTES COMPUT SC, V10753, P119, DOI 10.1007/978-3-319-77243-1_8; Devlin J., 2018, BERT PRE TRAINING DE; Eckhardt J, 2016, 24 IEEE INT REQUIREM; Espana S, 2009, 17 IEEE INT REQUIREM; Ezzini S, 2022, 30 ACM JOINT EUROPEA; Ezzini S, 2022, PROC INT CONF SOFTW, P187, DOI 10.1145/3510003.3510157; Ezzini S, 2021, PROC INT CONF SOFTW, P1485, DOI 10.1109/ICSE43902.2021.00133; Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI [10.7551/mitpress/7287.001.0001, DOI 10.7551/MITPRESS/7287.001.0001]; Ferrari A, 2014, 20 INT WORKING C REQ; Ferrari A, 2017, 2017 IEEE 25TH INTERNATIONAL REQUIREMENTS ENGINEERING CONFERENCE WORKSHOPS (REW), P393, DOI 10.1109/REW.2017.20; Ferrari A, 2017, INT REQUIR ENG CONF, P502, DOI 10.1109/RE.2017.29; Galar M., 2018, Learning from Imbalanced Data Sets, DOI [DOI 10.1007/978-3-319-98074-4, DOI 10.1007/978-3-319-98074-44]; Gigante G., 2015, INTELLIGENT DISTRIBU; Hasso H, 2022, 28 INT WORKING C REQ; Hess Melinda, 2004, ANN M AM ED RES ASS, P01; Hey T, 2020, 28 IEEE INT REQUIREM; Hirschberg J, 2015, SCIENCE, V349, P261, DOI 10.1126/science.aaa8685; Jurafsky D., 2021, SPEECH LANGUAGE PROC; Krzeszowski TP., 2011, CONTRASTING LANGUAGE; Liu H., 2012, Feature Selection for Knowledge Discovery and Data Mining; Lucassen G, 2016, REQUIR ENG, V21, P383, DOI 10.1007/s00766-016-0250-x; Luitel D, 2023, REPLICATION PACKAGE; Luitel D, 2023, 29 INT WORKING C REQ; Manning C. D., 2008, Introduction to information retrieval, DOI [DOI 10.1017/CBO9780511809071, 10.1017/CBO9780511809071]; Mikolov T, 2013, ANN C N AM CHAPTER A; Open AI, CHATGPT; OpenAI, 2023, Gpt-4 technical report; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Sainani A, 2020, INT REQUIR ENG CONF, P147, DOI 10.1109/RE48521.2020.00026; Sammut C, 2010, TF IDF; Shen Y, 2022, 30 IEEE INT REQUIREM; Sleimi A, 2018, INT REQUIR ENG CONF, P124, DOI 10.1109/RE.2018.00022; Vargha A, 2000, J EDUC BEHAV STAT, V25, P101, DOI 10.3102/10769986025002101; Vaswani A, 2017, ADV NEUR IN, V30; Witten I.H., 2016, The WEKA Workbench: Online Appendix for "Data Mining: Practical Machine Learning Tools and Techniques, V4th; Witten Ian H., 2017, DATA MINING PRACTICA; Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689; Zowghi D, 2003, INFORM SOFTWARE TECH, V45, P993, DOI 10.1016/S0950-5849(03)00100-9; Zowghi D, 2003, 8 INT WORKSHOP REQUI	54	0	0	10	10	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0947-3602	1432-010X		REQUIR ENG	Requir. Eng.	MAR	2024	29	1			SI		73	95		10.1007/s00766-024-00416-3	http://dx.doi.org/10.1007/s00766-024-00416-3		MAR 2024	23	Computer Science, Information Systems; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	OU5N2		Green Submitted			2024-07-03	WOS:001190464800001
C	He, JX; Vechev, M			ACM	He, Jingxuan; Vechev, Martin			Large Language Models for Code: Security Hardening and Adversarial Testing	PROCEEDINGS OF THE 2023 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, CCS 2023			English	Proceedings Paper	30th ACM SIGSAC Conference on Computer and Communications Security (ACM CCS)	NOV 26-30, 2023	Copenhagen, DENMARK	Assoc Comp Machinery, ACM SIGSAC, Huawei, Natl Sci Fdn, Technol Innovat Inst, Twenty Second Century Dora Technol, Ant Res, IBM, TikTok, Abelian, Input Outut		Large language models; Code generation; Code Security; AI Safety		Large language models (large LMs) are increasingly trained on massive codebases and used to generate code. However, LMs lack awareness of security and are found to frequently produce unsafe code. This work studies the security of LMs along two important axes: (i) security hardening, which aims to enhance LMs' reliability in generating secure code, and (ii) adversarial testing, which seeks to evaluate LMs' security at an adversarial standpoint. We address both of these by formulating a new security task called controlled code generation. The task is parametric and takes as input a binary property to guide the LM to generate secure or unsafe code, while preserving the LM's capability of generating functionally correct code. We propose a novel learning-based approach called SVEN to solve this task. SVEN leverages property-specific continuous vectors to guide program generation towards the given property, without modifying the LM's weights. Our training procedure optimizes these continuous vectors by enforcing specialized loss terms on different regions of code, using a high-quality dataset carefully curated by us. Our extensive evaluation shows that SVEN is highly effective in achieving strong security control. For instance, a state-of-the-art CodeGen LM with 2.7B parameters generates secure code for 59.1% of the time. When we employ SVEN to perform security hardening (or adversarial testing) on this LM, the ratio is significantly boosted to 92.3% (or degraded to 36.8%). Importantly, SVEN closely matches the original LMs in functional correctness.	[He, Jingxuan; Vechev, Martin] Swiss Fed Inst Technol, Zurich, Switzerland	Swiss Federal Institutes of Technology Domain; ETH Zurich	He, JX (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.	jingxuan.he@inf.ethz.ch; martin.vechev@inf.ethz.ch						Allal Loubna Ben, 2023, ABS230103988 CORR; [Anonymous], 2023, MarkupSafe PyPI; [Anonymous], 2015, ESEC FSE, DOI DOI 10.1145/2786805.2786812; [Anonymous], 2023, GITHUB COP YOUR AI P; [Anonymous], 2023, US; [Anonymous], 2023, US; Austin Jacob, 2021, ABS210807732 CORR; Barbero Federico, 2022, IEEE SP, DOI [10.1109/SP46214.2022. 9833659, DOI 10.1109/SP46214.2022.9833659]; Bavarian Mohammad, 2022, ABS220714255 CORR; Bhandari G, 2021, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING (PROMISE '21), P30, DOI 10.1145/3475960.3475985; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cassano Federico, 2022, ABS220808227 CORR; Chen M., 2021, ARXIV; Chen ZM, 2023, IEEE T SOFTWARE ENG, V49, P147, DOI 10.1109/TSE.2022.3147265; Chowdhery Aakanksha, 2022, CoRR, abs/2204.02311; Croft R, 2023, PROC INT CONF SOFTW, P121, DOI 10.1109/ICSE48619.2023.00022; Dathathri Sumanth, 2020, Plug and play language models: A simple approach to controlled text generation; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dohmke Thomas, 2023, GitHub COPILOT X: The AI-Powered Developer experience; Dolan-Gavitt B, 2016, P IEEE S SECUR PRIV, P110, DOI 10.1109/SP.2016.15; Fan JH, 2020, IEEE WORK CONF MIN S, P508, DOI 10.1145/3379597.3387501; Fried Daniel, 2023, ICLR; Gazzola L, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P1219, DOI 10.1145/3180155.3182526; Hambardzumyan Karen, 2021, ACL IJCNLP, DOI [10. 18653/v1/2021.acl-long.381, DOI 10.18653/V1/2021.ACL-L0NG.381]; He Jingxuan, 2022, ICML; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Jin D, 2022, COMPUT LINGUIST, V48, P155, DOI 10.1162/coli_a_00426; Kalliamvakou E., 2022, Research: quantifying github copilot's impact on developer productivity and happiness; Keskar N. S., 2019, ABS190905858 CORR; Khoury Raphael, 2023, ABS230409655 CORR; Koh Pang Wei, 2021, ICML; Korbak Tomasz, 2022, ICML; Krause B, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P4929; Le Goues C, 2021, IEEE SOFTWARE, V38, P22, DOI 10.1109/MS.2021.3072577; Le Hung, 2022, NEURIPS; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Li Yujia, 2022, ABS220307814 CORR; Li Z, 2022, IEEE T DEPEND SECURE, V19, P2244, DOI 10.1109/TDSC.2021.3051525; Li Z, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23158; Lin GJ, 2020, P IEEE, V108, P1825, DOI 10.1109/JPROC.2020.2993293; Liu Xiao, 2021, ABS210310385 CORR; Manès VJM, 2021, IEEE T SOFTWARE ENG, V47, P2312, DOI 10.1109/TSE.2019.2946563; Nijkamp Erik, 2023, ICLR; Nikitopoulos G, 2021, PROCEEDINGS OF THE 29TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '21), P1565, DOI 10.1145/3468264.3473122; Nong Y, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P1097, DOI 10.1145/3540250.3549128; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Qian Jing, 2022, Findings of ACL, DOI DOI 10.18653/V1/2022.FINDINGS-ACL.229; Qin GH, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5203; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reis Sofia, 2021, ABS211009635 CORR; Sandoval Gustavo, 2023, USENIX SECURITY; Chakravarthy SRS, 2021, INT J IMAG SYST TECH, V31, P1861, DOI 10.1002/ima.22570; Schuster R., 2021, USENIX SECURITY; Siddiq ML, 2022, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON MINING SOFTWARE REPOSITORIES APPLICATIONS FOR PRIVACY AND SECURITY, MSR4P&S 2022, P29, DOI 10.1145/3549035.3561184; Smith John, 2023, StarCoder: May the source be with you!; Sun ZS, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P652, DOI 10.1145/3485447.3512225; Tabachnyk M., 2022, ML-Enhanced Code Completion Improves Developer Productivity; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Vaswani A, 2017, ADV NEUR IN, V30; Wang Yue, 2021, P 2021 C EMP METH NA, DOI [DOI 10.18653/V1/2021.EMNLP-MAIN.685, 10.18653/v1/2021.emnlp-main.685]; Wartschinski L, 2022, INFORM SOFTWARE TECH, V144, DOI 10.1016/j.infsof.2021.106809; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Zhang Zhikun, 2022, USENIX SECURITY; Zhao Shuyin, 2023, GitHub Copilot now has a better AI model and new capabilities; Zhou Y., 2019, Advances in Neural Information Processing Systems, P10197	67	5	5	8	8	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0050-7				2023							1865	1879		10.1145/3576915.3623175	http://dx.doi.org/10.1145/3576915.3623175			15	Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TJ		Green Published, Green Submitted, hybrid			2024-07-03	WOS:001124987201059
C	Kapur, N; Rangel, A; Pentecost, L			IEEE	Kapur, Neil; Rangel, America; Pentecost, Lillian			CompressionGPT: Evaluating Fault Tolerance of a Compressed Large Language Model	2023 IEEE INTERNATIONAL SYMPOSIUM ON WORKLOAD CHARACTERIZATION, IISWC	International Symposium on Workload Characterization Proceedings		English	Proceedings Paper	26th IEEE International Symposium on Workload Characterization (IISWC)	OCT 01-03, 2023	Gent, BELGIUM	IEEE, IEEE Comp Soc Tech Comm Comp Architecture, Imec, CZTek, Vmware, MangoBoost, Ghent Univ, Natl Sci Fdn				Deep neural networks (DNNs) currently require large amounts of memory to store weights. Consequently, inference is less efficient given that weights must be stored off-chip on DRAM, resulting in costly memory accesses. While compression techniques, including quantization and pruning, can significantly reduce model size, current memory technologies are unable to store compressed DNNs on-chip. Prior works have proposed multi-level cell emerging non-volatile memory technologies as a solution given their ability to store bits densely on-chip. While these memory technologies are fault prone, having higher bit error rates, it has been demonstrated that DNNs exhibit some fault tolerance. We build on previous work by examining the fault tolerance of a pruned and quantized large language model (LLM).	[Kapur, Neil; Rangel, America; Pentecost, Lillian] Amherst Coll, Amherst, MA 01002 USA	Amherst College	Kapur, N (corresponding author), Amherst Coll, Amherst, MA 01002 USA.							Frantar E, 2023, Arxiv, DOI arXiv:2301.00774; Frantar E, 2023, Arxiv, DOI [arXiv:2210.17323, DOI 10.48550/ARXIV.2210.17323]; Gao Leo, 2022, Zenodo; Karpathy A., 2022, NanoGPT; Paperno D, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1525; Pentecost L, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P769, DOI 10.1145/3352460.3358258; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997	8	0	0	3	3	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-0317-9	I S WORKL CHAR PROC			2023							232	234		10.1109/IISWC59245.2023.00033	http://dx.doi.org/10.1109/IISWC59245.2023.00033			3	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW1AG					2024-07-03	WOS:001103166400026
J	Nakaura, T; Ito, R; Ueda, D; Nozaki, T; Fushimi, Y; Matsui, Y; Yanagawa, M; Yamada, A; Tsuboyama, T; Fujima, N; Tatsugami, F; Hirata, K; Fujita, S; Kamagata, K; Fujioka, T; Kawamura, M; Naganawa, S				Nakaura, Takeshi; Ito, Rintaro; Ueda, Daiju; Nozaki, Taiki; Fushimi, Yasutaka; Matsui, Yusuke; Yanagawa, Masahiro; Yamada, Akira; Tsuboyama, Takahiro; Fujima, Noriyuki; Tatsugami, Fuminari; Hirata, Kenji; Fujita, Shohei; Kamagata, Koji; Fujioka, Tomoyuki; Kawamura, Mariko; Naganawa, Shinji			The impact of large language models on radiology: a guide for radiologists on the latest innovations in AI	JAPANESE JOURNAL OF RADIOLOGY			English	Review; Early Access						Diagnostic radiology; Artificial intelligence; Deep learning; Large language model; Radiological workflow	CHATGPT	The advent of Deep Learning (DL) has significantly propelled the field of diagnostic radiology forward by enhancing image analysis and interpretation. The introduction of the Transformer architecture, followed by the development of Large Language Models (LLMs), has further revolutionized this domain. LLMs now possess the potential to automate and refine the radiology workflow, extending from report generation to assistance in diagnostics and patient care. The integration of multimodal technology with LLMs could potentially leapfrog these applications to unprecedented levels.However, LLMs come with unresolved challenges such as information hallucinations and biases, which can affect clinical reliability. Despite these issues, the legislative and guideline frameworks have yet to catch up with technological advancements. Radiologists must acquire a thorough understanding of these technologies to leverage LLMs' potential to the fullest while maintaining medical safety and ethics. This review aims to aid in that endeavor.	[Nakaura, Takeshi] Kumamoto Univ Hosp, Dept Cent Radiol, Honjo 1-1-1, Kumamoto 8608556, Japan; [Ito, Rintaro; Kawamura, Mariko; Naganawa, Shinji] Nagoya Univ, Grad Sch Med, Dept Radiol, Nagoya, Aichi, Japan; [Ueda, Daiju] Osaka Metropolitan Univ, Grad Sch Med, Dept Diagnost & Intervent Radiol, 1-4-3 Asahi Machi,Abeno Ku, Osaka 5458585, Japan; [Nozaki, Taiki] Keio Univ, Sch Med, Dept Radiol, Shinjuku Ku, Tokyo, Japan; [Fushimi, Yasutaka] Kyoto Univ, Grad Sch Med, Dept Diagnost Imaging & Nucl Med, Kyoto, Japan; [Matsui, Yusuke] Okayama Univ, Fac Med Dent & Pharmaceut Sci, Dept Radiol, Kita Ku, Okayama, Japan; [Yanagawa, Masahiro; Tsuboyama, Takahiro] Osaka Univ, Grad Sch Med, Dept Radiol, Suita, Osaka, Japan; [Yamada, Akira] Shinshu Univ, Sch Med, Dept Radiol, Matsumoto, Nagano, Japan; [Fujima, Noriyuki] Hokkaido Univ Hosp, Dept Diagnost & Intervent Radiol, Sapporo, Japan; [Tatsugami, Fuminari] Hiroshima Univ, Dept Diagnost Radiol, Minami Ku, Hiroshima, Japan; [Hirata, Kenji] Hokkaido Univ, Grad Sch Med, Dept Diagnost Imaging, Kita Ku, Sapporo, Hokkaido, Japan; [Fujita, Shohei] Univ Tokyo, Dept Radiol, Bunkyo Ku, Tokyo, Japan; [Kamagata, Koji] Juntendo Univ, Dept Radiol, Grad Sch Med, Bunkyo Ku, Tokyo, Japan; [Fujioka, Tomoyuki] Tokyo Med & Dent Univ, Dept Diagnost Radiol, Bunkyo Ku, Tokyo, Japan	Kumamoto University; Nagoya University; Keio University; Kyoto University; Okayama University; Osaka University; Shinshu University; Hokkaido University; Hiroshima University; Hokkaido University; University of Tokyo; Juntendo University; Tokyo Medical & Dental University (TMDU)	Nakaura, T (corresponding author), Kumamoto Univ Hosp, Dept Cent Radiol, Honjo 1-1-1, Kumamoto 8608556, Japan.	kff00712@nifty.com	Ueda, Daiju/AAG-2167-2021; 鎌形, 康司/AFL-9072-2022	Ueda, Daiju/0000-0002-3878-3616; 鎌形, 康司/0000-0001-5028-218X; Nakaura, Takeshi/0000-0002-9010-0341				Adams LC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230725; Agrawal A, 2024, Arxiv, DOI arXiv:2305.18248; Alfarghaly Omar, 2021, Informatics in Medicine Unlocked, V24, DOI 10.1016/j.imu.2021.100557; Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Azuma M, 2022, Emerg Radiol; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Chen JH, 2023, JPN J RADIOL, V41, P637, DOI 10.1007/s11604-022-01385-9; D'Antonoli TA, 2024, DIAGN INTERV RADIOL, V30, P80, DOI 10.4274/dir.2023.232417; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doi K, 2023, JPN J RADIOL, V41, P900, DOI 10.1007/s11604-023-01413-2; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Goto M, 2023, JPN J RADIOL, V41, P1094, DOI 10.1007/s11604-023-01435-w; Gruetzemacher R, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505245; Hamabuchi N, 2023, JPN J RADIOL, V41, P1373, DOI 10.1007/s11604-023-01470-7; Hartung MP, 2020, RADIOGRAPHICS, V40, P1658, DOI 10.1148/rg.2020200020; Higaki T, 2019, JPN J RADIOL, V37, P73, DOI 10.1007/s11604-018-0796-2; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hosoi R, 2023, JPN J RADIOL, V41, P863, DOI 10.1007/s11604-023-01402-5; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; Ishihara M, 2023, JPN J RADIOL, V41, P131, DOI 10.1007/s11604-022-01341-7; Jain S. M., 2022, Introduction to transformers for NLP: with the hugging face library and models to solve problems; Kaga T, 2022, JPN J RADIOL, V40, P703, DOI 10.1007/s11604-022-01259-0; Khader F, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.230806; Kitahara H, 2022, JPN J RADIOL, V40, P38, DOI 10.1007/s11604-021-01184-8; Koretsune Y, 2023, JPN J RADIOL, V41, P228, DOI 10.1007/s11604-022-01339-1; Kufel J, 2023, POL J RADIOL, V88, pE430, DOI 10.5114/pjr.2023.131215; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lake BM, 2023, NATURE, V623, P115, DOI 10.1038/s41586-023-06668-3; Liang WX, 2023, Arxiv, DOI arXiv:2310.01783; Liu ZK, 2022, HEPATOL INT, V16, P577, DOI [10.13336/j.1003-6520.hve.20211780, 10.1007/s12072-022-10321-y]; Lopez-Ubeda Pilar, 2022, J Am Coll Radiol, V19, P1271, DOI 10.1016/j.jacr.2022.06.016; Lu L, 2019, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-3-030-13969-8; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Mahbub M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262182; Mckenna N, 2023, Arxiv, DOI arXiv:2305.14552; Moy L, 2023, RADIOLOGY, V309, DOI 10.1148/radiol.239024; Nai YH, 2022, JPN J RADIOL, V40, P1290, DOI 10.1007/s11604-022-01311-z; Nakao T, 2022, JPN J RADIOL, V40, P730, DOI 10.1007/s11604-022-01249-2; Nakaura T, 2024, JPN J RADIOL, V42, P190, DOI 10.1007/s11604-023-01487-y; Nakaura T, 2020, DIAGN INTERV IMAG, V101, P765, DOI 10.1016/j.diii.2020.10.001; openai, IMPROVING LANGUAGE U; Oshima S, 2023, JPN J RADIOL, V41, P1216, DOI 10.1007/s11604-023-01452-9; Ozaki J, 2022, JPN J RADIOL, V40, P814, DOI 10.1007/s11604-022-01261-6; Parikh JR, 2020, J AM COLL RADIOL, V17, P78, DOI 10.1016/j.jacr.2019.07.008; Peng B, 2023, Arxiv, DOI arXiv:2305.13048; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Seghier ML, 2023, NATURE, V615, P216, DOI 10.1038/d41586-023-00680-3; Sirshar M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262209; Stiennon N, 2022, Arxiv, DOI arXiv:2009.01325; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; Tinn R, 2023, PATTERNS, V4, DOI 10.1016/j.patter.2023.100729; Toda N, 2023, JPN J RADIOL, V41, P38, DOI 10.1007/s11604-022-01330-w; Toyama Y, 2023, JPN J RADIOL, DOI 10.1007/s11604-023-01491-2; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Ueda D, 2024, JPN J RADIOL, V42, P3, DOI 10.1007/s11604-023-01474-3; Uematsu T, 2023, JPN J RADIOL, V41, P63, DOI 10.1007/s11604-022-01327-5; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Battaglia PW, 2018, Arxiv, DOI [arXiv:1806.01261, DOI 10.48550/ARXIV.1806.01261, 10.48550/arXiv.1806.01261]; Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943; Williams RJ, 1989, NEURAL COMPUT, V1, P270, DOI 10.1162/neco.1989.1.2.270; Yasaka K, 2022, JPN J RADIOL, V40, P476, DOI 10.1007/s11604-021-01225-2; Zeng GSL, 2021, IEEE ACCESS, V9, P120665, DOI [10.1109/ACCESS.2021.3109173, 10.1109/access.2021.3109173]	68	4	4	8	8	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	1867-1071	1867-108X		JPN J RADIOL	Jpn. J. Radiol.	2024 MAR 29	2024										10.1007/s11604-024-01552-0	http://dx.doi.org/10.1007/s11604-024-01552-0		MAR 2024	12	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	MP6B1	38551772	hybrid			2024-07-03	WOS:001194855800001
J	Wang, ZM				Wang, Zhoumeng			Empowering Few-Shot Recommender Systems With Large Language Models-Enhanced Representations	IEEE ACCESS			English	Article						Large language models; Representation learning; recommender systems; ChatGPT; representations		Recommender systems utilizing explicit feedback have witnessed significant advancements and widespread applications over the past years. However, generating recommendations in few-shot scenarios remains a persistent challenge. Recently, large language models (LLMs) have emerged as a promising solution for addressing natural language processing (NLP) tasks, thereby offering novel insights into tackling the few-shot scenarios encountered by explicit feedback-based recommender systems. To bridge recommender systems and LLMs, we devise a prompting template that generates user and item representations based on explicit feedback. Subsequently, we integrate these LLM-processed representations into various recommendation models to evaluate their significance across diverse recommendation tasks. Our ablation experiments and case study analysis collectively demonstrate the effectiveness of LLMs in processing explicit feedback, highlighting that LLMs equipped with generative and logical reasoning capabilities can effectively serve as a component of recommender systems to enhance their performance in few-shot scenarios. Furthermore, the broad adaptability of LLMs augments the generalization potential of recommender models, despite certain inherent constraints. We anticipate that our study can inspire researchers to delve deeper into the multifaceted dimensions of LLMs' involvement in recommender systems and contribute to the advancement of the explicit feedback-based recommender systems field.	[Wang, Zhoumeng] Chinese Univ Hong Kong Business Sch, Mkt Programme, Hong Kong, Peoples R China		Wang, ZM (corresponding author), Chinese Univ Hong Kong Business Sch, Mkt Programme, Hong Kong, Peoples R China.	johnnywang@link.cuhk.edu.hk						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alamdari PM, 2020, IEEE ACCESS, V8, P115694, DOI 10.1109/ACCESS.2020.3002803; [Anonymous], 2009, Proceedings of the 1st international CIKM workshop on Topic-sentiment analysis for mass opinion; Ansari A, 2000, J MARKETING RES, V37, P363, DOI 10.1509/jmkr.37.3.363.18779; Betancourt Y, 2020, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON ENTERPRISE INFORMATION SYSTEMS (ICEIS), VOL 1, P780, DOI 10.5220/0009576507800787; Bobadilla J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072441; Bodapati AV, 2008, J MARKETING RES, V45, P77, DOI 10.1509/jmkr.45.1.77; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cena F, 2021, INFORM SCIENCES, V546, P60, DOI 10.1016/j.ins.2020.07.075; Chen C, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1583, DOI 10.1145/3178876.3186070; Chen KL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P661, DOI 10.1145/2348283.2348372; Cheng H.-T., 2016, P 1 WORKSH DEEP LEAR, P7, DOI [10.1145/2988450.2988454, DOI 10.1145/2988450.2988454]; Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190; Cui YM, 2020, Arxiv, DOI arXiv:2004.13922; Dai HX, 2023, Arxiv, DOI [arXiv:2302.13007, DOI 10.48550/ARXIV.2302.13007]; Di Palma D, 2023, PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023, P1369, DOI 10.1145/3604915.3608889; Di Palma D, 2023, Arxiv, DOI arXiv:2309.03613; Dong M, 2020, INFORM SCIENCES, V540, P469, DOI 10.1016/j.ins.2020.05.094; Felfernig A, 2011, RECOMMENDER SYSTEMS HANDBOOK, P187, DOI 10.1007/978-0-387-85820-3_6; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872; He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569; Jawaheer G., 2010, P 1 INT WORKSHOP INF, P47, DOI [DOI 10.1145/1869446, 10.1145/1869446.1869453]; Kefato Z, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1609, DOI 10.1145/3442381.3450020; Kim D, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P233, DOI 10.1145/2959100.2959165; Kim Y, 2014, Arxiv, DOI [arXiv:1408.5882, 10.48550/arXiv.1408.5882]; Konstan JA, 2012, USER MODEL USER-ADAP, V22, P101, DOI 10.1007/s11257-011-9112-x; Krestel R., 2009, P 3 ACM C REC SYST, DOI DOI 10.1145/1639714.1639726; Li Yongming, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P692, DOI 10.1109/ICCIS.2010.172; Liu D., 2019, Douban Moviedata; Liu JL, 2023, Arxiv, DOI arXiv:2304.10149; Liu N. N., 2010, P 19 ACM INT C INFOR, P1445; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu SY, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P1912, DOI 10.1145/3477495.3531777; Loh S., 2003, Information Technology and Tourism, V6, P157, DOI 10.3727/1098305031436980; Lu YC, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P773, DOI 10.1145/3178876.3186158; Miao DC, 2017, 2017 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY (CYBERC), P318, DOI 10.1109/CyberC.2017.81; Mittal Darshita, 2020, ICT Analysis and Applications. Proceedings of ICT4SD 2019. Lecture Notes in Networks and Systems (LNNS 93), P85, DOI 10.1007/978-981-15-0630-7_9; Mocean Loredana, 2012, Informatica Economica, V16, P142; Pérez-Almaguer Y, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115444; Remountakis M, 2023, INFORMATION, V14, DOI 10.3390/info14090504; Rendle S, 2012, Arxiv, DOI arXiv:1205.2618; Rezaimehr F, 2021, ARTIF INTELL REV, V54, P2011, DOI 10.1007/s10462-020-09898-3; Rosa RL, 2019, IEEE T IND INFORM, V15, P2124, DOI 10.1109/TII.2018.2867174; Song Yan, 2018, P 2018 C N AM CHAPT, V2, P175, DOI [DOI 10.18653/V1/N18-2028, 10.18653/v1/n18-2028, 10.18653/v1/N18-2028]; Tay Y, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2309, DOI 10.1145/3219819.3220086; Vaswani A, 2017, ADV NEUR IN, V30; Verma D., 2020, P IEEE INT C EL COMP, P1; Zhang SA, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3285029; Zhao Q, 2018, 33RD ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, P1331, DOI 10.1145/3167132.3167275; Zhao ZH, 2024, Arxiv, DOI arXiv:2307.02046; Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665	52	1	1	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						29144	29153		10.1109/ACCESS.2024.3368027	http://dx.doi.org/10.1109/ACCESS.2024.3368027			10	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	JL7I8		Green Submitted, gold			2024-07-03	WOS:001173385300001
J	Park, L; Ehlert, B; Susla, L; Lum, ZC; Lee, PK				Park, Lily; Ehlert, Brittany; Susla, Lyudmyla; Lum, Zachary C.; Lee, Patrick K.			Performance of large language model artificial intelligence on dermatology board exam questions	CLINICAL AND EXPERIMENTAL DERMATOLOGY			English	Letter								Our study attempted to assess the performance of two large language models: Open AI's ChatGPT and Google's Bard on dermatology board exam-style questions. Based on our study, Google Bard outperformed ChatGPT and achieved the highest scores in general dermatology among dermatology disciplines.	[Park, Lily] Larkin Community Hosp, Dept Dermatol, South Miami, FL 33143 USA; [Park, Lily; Lum, Zachary C.] Nova Southeastern Univ, Sch Osteopath Med, Davie, FL 33328 USA; [Ehlert, Brittany] Ohio Univ, Heritage Coll Osteopath Med, Cleveland, OH USA; [Susla, Lyudmyla] New York Inst Technol, Coll Osteopath Med, Old Westbury, NY USA; [Lee, Patrick K.] Univ Calif Irvine, Dept Dermatol, Irvine, CA USA	Nova Southeastern University; University System of Ohio; Ohio University; New York Institute Technology; University of California System; University of California Irvine	Park, L (corresponding author), Larkin Community Hosp, Dept Dermatol, South Miami, FL 33143 USA.; Park, L (corresponding author), Nova Southeastern Univ, Sch Osteopath Med, Davie, FL 33328 USA.	DrLilyPark@gmail.com	Lee, Patrick K H/L-1844-2016					[Anonymous], 2023, GOOGLE BARD; Galderma, DERM101 SELF ASS QUI; Haupt CE, 2023, JAMA-J AM MED ASSOC, V329, P1349, DOI 10.1001/jama.2023.5321; Hirosawa T, 2023, AM J MED, V136, P1119, DOI 10.1016/j.amjmed.2023.08.003; Open AI, 2022, CHATGPT 3 5; Sanovaworks, DERM IN REV DASHB	6	2	2	3	4	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	0307-6938	1365-2230		CLIN EXP DERMATOL	Clin. Exp. Dermatol.	DEC 5	2023	49	7					733	734		10.1093/ced/llad355	http://dx.doi.org/10.1093/ced/llad355		OCT 2023	2	Dermatology	Science Citation Index Expanded (SCI-EXPANDED)	Dermatology	WF2R4	37846609				2024-07-03	WOS:001113936600001
J	Tai, RH; Bentley, LR; Xia, X; Sitt, JM; Fankhauser, SC; Chicas-Mosier, AM; Monteith, BG				Tai, Robert H.; Bentley, Lillian R.; Xia, Xin; Sitt, Jason M.; Fankhauser, Sarah C.; Chicas-Mosier, Ana M.; Monteith, Barnas G.			An Examination of the Use of Large Language Models to Aid Analysis of Textual Data	INTERNATIONAL JOURNAL OF QUALITATIVE METHODS			English	Article						qualitative methodology; large language models; deductive qualitative coding; reliability	AGREEMENT; OPPORTUNITIES; CHATGPT; KAPPA	The increasing use of machine learning and Large Language Models (LLMs) opens up opportunities to use these artificially intelligent algorithms in novel ways. This article proposes a methodology using LLMs to support traditional deductive coding in qualitative research. We began our analysis with three different sample texts taken from existing interviews. Next, we created a codebook and inputted the sample text and codebook into an LLM. We asked the LLM to determine if the codes were present in a sample text provided and requested evidence to support the coding. The sample texts were inputted 160 times to record changes between iterations of the LLM response. Each iteration was analogous to a new coder deductively analyzing the text with the codebook information. In our results, we present the outputs for these recursive analyses, along with a comparison of the LLM coding to evaluations made by human coders using traditional coding methods. We argue that LLM analysis can aid qualitative researchers by deductively coding transcripts, providing a systematic and reliable platform for code identification, and offering a means of avoiding analysis misalignment. Implications of using LLM in research praxis are discussed, along with current limitations.	[Tai, Robert H.; Bentley, Lillian R.; Xia, Xin; Sitt, Jason M.] Univ Virginia, Sch Educ & Human Dev, Charlottesville, VA USA; [Fankhauser, Sarah C.] Oxford Coll Emory Univ, Div Nat Sci & Math, Oxford, GA USA; [Chicas-Mosier, Ana M.] Univ Kansas, Ctr Environmentally Beneficial Catalysis, Lawrence, KS USA; [Monteith, Barnas G.] Artif Intelligence Grp, THInc, Vancouver, WA USA; [Tai, Robert H.] Univ Virginia, 2110 Lonicera Way, Charlottesville, VA 22911 USA	University of Virginia; University of Kansas; University of Virginia	Tai, RH (corresponding author), Univ Virginia, 2110 Lonicera Way, Charlottesville, VA 22911 USA.	rht6h@virginia.edu	Tai, Robert/KPY-2746-2024		US National Science Foundation; NSF REC [0440002];  [NSF DRL 1811265]	US National Science Foundation(National Science Foundation (NSF)); NSF REC; 	Parts of this work have been supported by the US National Science Foundation (NSF DRL 1811265 and NSF REC 0440002). Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the US National Science Foundation.	Athaluri SA, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37432; Banerjee M, 1999, CAN J STAT, V27, P3, DOI 10.2307/3315487; Bhardwaz Saumyamani, 2023, 2023 2nd International Conference on Applied Artificial Intelligence and Computing (ICAAIC), P673, DOI 10.1109/ICAAIC56838.2023.10140214; BLOCH DA, 1989, BIOMETRICS, V45, P269, DOI 10.2307/2532052; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; Creswell J.W., 2017, RES DESIGN QUALITATI; Dabney KP, 2014, J CHEM EDUC, V91, P1777, DOI 10.1021/ed4008815; Dey I., 1993, Qualitative Data Analysis: A User-Friendly Guide for Social Scientists, DOI DOI 10.4324/9780203412497; Elo S, 2008, J ADV NURS, V62, P107, DOI 10.1111/j.1365-2648.2007.04569.x; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Gilardi F, 2023, Arxiv, DOI [arXiv:2303.15056, DOI 10.48550/ARXIV.2303.15056]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Linacre J., 1989, MANY FACETED RASCH M; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Marques JF, 2005, QUAL REP, V10, P439; Nepo K, 2017, CHILD YOUTH CARE FOR, V46, P207, DOI 10.1007/s10566-016-9386-6; Nichols TR., 2010, QUAL ASSUR J, V13, P57, DOI DOI 10.1002/QAJ.481; Nosek BA, 2007, EUR REV SOC PSYCHOL, V18, P36, DOI 10.1080/10463280701489053; Pan WB, 2023, Arxiv, DOI arXiv:2304.04256; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Peng KQ, 2023, Arxiv, DOI arXiv:2303.13780; Rahman MM, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13095783; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; SCHWANDT TA, 1997, QUALITATIVE INQUIRY; Stojanov A, 2023, INT J EDUC TECHNOL H, V20, DOI 10.1186/s41239-023-00404-7; Ubani S, 2023, Arxiv, DOI [arXiv:2304.14334, 10.48550/arXiv.2304.14334]; Valdenegro D., 2023, arXiv, DOI [10.31235/osf.io/m74vs, DOI 10.31235/OSF.IO/M74VS]; Van Booven DJ, 2021, RES REP UROL, V13, P31, DOI 10.2147/RRU.S268596; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Wei JS, 2022, ADV NEUR IN; Wei X, 2024, Arxiv, DOI [arXiv:2302.10205, 10.48550/arXiv.2302.10205]; Xiao Ziang, 2023, COMPANION P 28 INT C, P75, DOI DOI 10.1145/3581754	36	1	1	28	28	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	1609-4069			INT J QUAL METH	Int. J. Qual. Meth.	JAN	2024	23								16094069241231168	10.1177/16094069241231168	http://dx.doi.org/10.1177/16094069241231168			14	Social Sciences, Interdisciplinary	Social Science Citation Index (SSCI)	Social Sciences - Other Topics	HR7J1		gold			2024-07-03	WOS:001161295200001
C	Todd, G; Earle, S; Nasir, MU; Green, MC; Togelius, J		Lopes, P; Luz, F; Liapis, A; Engstrom, H		Todd, Graham; Earle, Sam; Nasir, Muhammad Umair; Green, Michael Cerny; Togelius, Julian			Level Generation Through Large Language Models	PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES, FDG 2023			English	Proceedings Paper	18th International Conference on the Foundations of Digital Games (FDG)	APR 11-14, 2023	Lisbon, PORTUGAL	Assoc Comp Machinery, ACM SIGCHI, ACM SIGGRAPH, ACM SIGAI, Soc Advancement Sci Digital Games, Microsoft, FilmEU, ACM In Cooperat		procedural content generation; sokoban; language models; transformers		Large Language Models (LLMs) are powerful tools, capable of leveraging their training on natural language to write stories, generate code, and answer questions. But can they generate functional video game levels? Game levels, with their complex functional constraints and spatial relationships in more than one dimension, are very different from the kinds of data an LLM typically sees during training. Datasets of game levels are also hard to come by, potentially taxing the abilities of these data-hungry models. We investigate the use of LLMs to generate levels for the game Sokoban, finding that LLMs are indeed capable of doing so, and that their performance scales dramatically with dataset size. We also perform preliminary experiments on controlling LLM level generators and discuss promising areas for future work.	[Todd, Graham; Earle, Sam; Green, Michael Cerny; Togelius, Julian] New York Univ Tandon, Brooklyn, NY 11201 USA; [Nasir, Muhammad Umair] Univ Witwatersrand, Johannesburg, South Africa	New York University; New York University Tandon School of Engineering; University of Witwatersrand	Todd, G (corresponding author), New York Univ Tandon, Brooklyn, NY 11201 USA.	gdrtodd@nyu.edu; se2161@nyu.edu; umairnasir1@students.wits.ac.za; mike.green@nyu.edu; julian@togelius.com	Togelius, Julian/G-6237-2011; Green, Michael Cerny/AAH-6806-2021	Togelius, Julian/0000-0003-3128-4598; Green, Michael Cerny/0000-0003-3366-8165; Nasir, Muhammad Umair/0000-0002-2458-9599				Agostinelli A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.11325; Huang CZA, 2018, Arxiv, DOI [arXiv:1809.04281, 10.48550/arXiv.1809.04281, DOI 10.48550/ARXIV.1809.04281]; [Anonymous], 2016, P AAAI C ARTIFICIAL; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen LL, 2021, ADV NEUR IN, V34; Dahlskog S., 2014, Proceedings of the 18th International Academic MindTrek Conference: Media Business, Management, Content Services, P200; Earle Sam, 2021, 2021 IEEE C GAM COG, P1; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kartal Bilal, 2016, 12 ART INT INT DIG E; Karth I, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON THE FOUNDATIONS OF DIGITAL GAMES (FDG'19), DOI 10.1145/3337722.3341845; Khalifa Ahmed, 2020, P AAAI C ART INT INT, V16, P95, DOI DOI 10.1609/AIIDE.V16I1.7416; Li JW, 2017, Arxiv, DOI arXiv:1701.06549; Liu JL, 2021, NEURAL COMPUT APPL, V33, P19, DOI 10.1007/s00521-020-05383-8; Lu S, 2021, Arxiv, DOI arXiv:2102.04664; Mott J, 2019, EXP AI GAM WORKSH; Murase Y., 1996, PRICAI'96: Topics in Artificial Intelligence. 4th Pacific Rim International Conference on Artificial Intelligence. Proceedings, P592; Park K, 2019, IEEE CONF COMPU INTE, DOI 10.1109/cig.2019.8848085; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramesh A., 2022, arXiv; Reed S, 2022, Arxiv, DOI arXiv:2205.06175; Sarkar A, 2020, Arxiv, DOI arXiv:2010.07735; Sarkar Anurag, 2021, 2021 IEEE C GAM COG, P1; Sarkar Anurag, 2018, AIIDE WORKSH; Schrum J, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P148, DOI 10.1145/3377930.3389821; Snodgrass S., 2020, P 15 INT C FDN DIG G; Sudhakaran S, 2023, Arxiv, DOI arXiv:2302.05981; Suleman M, 2017, INT J ADV COMPUT SC, V8, P466; Summerville A, 2016, Arxiv, DOI arXiv:1603.00930; Summerville A, 2018, IEEE T GAMES, V10, P257, DOI 10.1109/TG.2018.2846639; Taylor J, 2011, GAMEON-NA 2011: 6TH INTERNATIONAL NORTH- AMERICAN CONFERENCE ON INTELLIGENT GAMES AND AND SIMULATION / 3RD INTERNATIONAL NORTH AMERICAN SIMULATION TECHNOLOGY CONFERENCE, NASTEC 2011, P5; Tornado RR, 2020, IEEE CONF COMPU INTE, P41, DOI [10.1109/CoG47356.2020.9231576, 10.1109/cog47356.2020.9231576]; Weber T, 2018, Arxiv, DOI arXiv:1707.06203; Zakaria Y, 2023, IEEE T GAMES, V15, P108, DOI 10.1109/TG.2022.3175795; Zhao TZ, 2021, PR MACH LEARN RES, V139	34	2	2	1	3	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9856-5				2023									70	10.1145/3582437.3587211	http://dx.doi.org/10.1145/3582437.3587211			8	Art; Computer Science, Cybernetics; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Art; Computer Science; Social Sciences - Other Topics	BV9WQ		Green Submitted			2024-07-03	WOS:001092777800075
J	Pilny, A; Mcaninch, K; Slone, A; Moore, K				Pilny, Andrew; Mcaninch, Kelly; Slone, Amanda; Moore, Kelsey			From manual to machine: assessing the efficacy of large language models in content analysis	COMMUNICATION RESEARCH REPORTS			English	Article						Large language models; content analysis; machine learning; text-mining; interpersonal communication		This study compares the performance of Large Language Models (LLMs) and human coders in predicting relational uncertainty from textual data. Employing various LLMs (gpt-4.0-turbo, gpt-3.5-turbo, Claude 2, llama7b-v2-chat, and llama13b-v2-chat), we found that these models perform comparably to human coders, with only minor differences in Mean Squared Error (MSE) values. However, not all LLMs performed equally, underscoring the importance of model selection. Our findings highlight the potential of LLMs as a scalable tool for content analysis, but also emphasize their nuanced application based on the specific research context. The study advances the discourse on the use of LLMs in content analysis and provides insights for future research in this rapidly evolving field.	[Pilny, Andrew; Mcaninch, Kelly; Slone, Amanda; Moore, Kelsey] Univ Kentucky, Dept Commun, 269 Blazer Dining, Lexington, KY 40506 USA	University of Kentucky	Pilny, A (corresponding author), Univ Kentucky, Dept Commun, 269 Blazer Dining, Lexington, KY 40506 USA.	andy.pilny@uky.edu			University of Kentucky	University of Kentucky	This work was supported by the University of Kentucky [Research and Creative Activities Program].	Bonito JA, 2018, CAMB HANDB PSYCHOL, P387; Carey J.W., 2008, Handbook for team-based qualitative research, P227; Chae Y., 2023, OPEN SCI FDN; Clavie Benjamin, 2023, Natural Language Processing and Information Systems: 28th International Conference on Applications of Natural Language to Information Systems, NLDB 2023, Proceedings. Lecture Notes in Computer Science (13913), P3, DOI 10.1007/978-3-031-35320-8_1; Dettmers T., 2023, P 37 ANN C NEURAL IN; Field A., 2013, DISCOVERING STAT USI; James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI 10.1007/978-1-4614-7138-7_1; Knobloch L.K., 1999, COMMUN STUD, V50, P261, DOI [10.1080/10510979909388499, DOI 10.1080/10510979909388499]; Knobloch LK, 2002, PERS RELATIONSHIP, V9, P457, DOI 10.1111/1475-6811.09406; Loukas L, 2023, PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023, P392, DOI 10.1145/3604237.3626891; Pilny A, 2019, COMMUN METHODS MEAS, V13, P287, DOI 10.1080/19312458.2019.1650166; Vaswani A., 2017, Advances in neural information processing systems, P6000	12	0	0	5	5	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0882-4096	1746-4099		COMMUN RES REP	Commun. Res. Rep.	MAR 14	2024	41	2					61	70		10.1080/08824096.2024.2327547	http://dx.doi.org/10.1080/08824096.2024.2327547		MAR 2024	10	Communication	Emerging Sources Citation Index (ESCI)	Communication	TX8S8					2024-07-03	WOS:001182015400001
J	Wulff, P				Wulff, Peter			Physics language and language use in physics-What do we know and how AI might enhance language-related research and instruction	EUROPEAN JOURNAL OF PHYSICS			English	Review						language in physics; large language models; machine learning; natural language processing	SOCIAL SEMIOTICS; SCIENCE; LITERACY; SENSE; AUTOTUTOR; RESOURCES; SEMANTICS; COHERENCE; KNOWLEDGE; DIALOGUE	Language is an important resource for physicists and learners of physics to construe physical phenomena and processes, and communicate ideas. Moreover, any physics-related instructional setting is inherently language-bound, and physics literacy is fundamentally related to comprehending and producing both physics-specific and general language. Consequently, characterizing physics language and understanding language use in physics are important goals for research on physics learning and instructional design. Qualitative physics education research offers a variety of insights into the characteristics of language and language use in physics such as the differences between everyday language and scientific language, or metaphors used to convey concepts. However, qualitative language analysis fails to capture distributional (i.e. quantitative) aspects of language use and is resource-intensive to apply in practice. Integrating quantitative and qualitative language analysis in physics education research might be enhanced by recently advanced artificial intelligence-based technologies such as large language models, as these models were found to be capable to systematically process and analyse language data. Large language models offer new potentials in some language-related tasks in physics education research and instruction, yet they are constrained in various ways. In this scoping review, we seek to demonstrate the multifaceted nature of language and language use in physics and answer the question what potentials and limitations artificial intelligence-based methods such as large language models can have in physics education research and instruction on language and language use.	[Wulff, Peter] Heidelberg Univ Educ, Dept Phys & Phys Educ Res, Neuenheimer Feld 561, D-69120 Heidelberg, Germany	Ruprecht Karls University Heidelberg	Wulff, P (corresponding author), Heidelberg Univ Educ, Dept Phys & Phys Educ Res, Neuenheimer Feld 561, D-69120 Heidelberg, Germany.	peter.wulff@ph-heidelberg.de	Wulff, Peter/GSI-9069-2022	Wulff, Peter/0000-0002-5471-7977	Klaus Tschira Stiftunghttps://doi.org/10.13039/501100007316	Klaus Tschira Stiftunghttps://doi.org/10.13039/501100007316	No Statement Available	Grupen NA, 2020, Arxiv, DOI arXiv:2011.14890; Abdou M., 2021, P 25 C COMPUTATIONAL, P109, DOI [10.18653/v1/2021.conll-1.9, DOI 10.18653/V1/2021.CONLL-1.9]; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Airey J, 2017, MODEL MODEL SCI EDUC, V10, P95, DOI 10.1007/978-3-319-58914-5_5; Airey J, 2009, J RES SCI TEACH, V46, P27, DOI 10.1002/tea.20265; Altmann EG, 2012, P NATL ACAD SCI USA, V109, P11582, DOI 10.1073/pnas.1117723109; Alvarez-Lacalle E, 2006, P NATL ACAD SCI USA, V103, P7956, DOI 10.1073/pnas.0510673103; [Anonymous], 1975, Journal of Child Language, DOI DOI 10.1017/S0305000900000866; [Anonymous], 2018, Deep learning with Python, DOI DOI 10.1007/978-1-4842-2766-4; [Anonymous], 2003, Meaning making in secondary science classrooms; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baaijen VM, 2018, COGNITION INSTRUCT, V36, P199, DOI 10.1080/07370008.2018.1456431; Baig MI, 2020, INT J EDUC TECHNOL H, V17, DOI 10.1186/s41239-020-00223-0; Bar-yam Y., 1997, Dynamics of Complex Systems; Barsalou LW, 2008, ANNU REV PSYCHOL, V59, P617, DOI 10.1146/annurev.psych.59.103006.093639; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bereiter C., 2009, Transferred to Digital Printing ed The Psychology of Education and Instruction; Bhaskar R., 1977, COG SCI, V1, P193, DOI [10.1207/s15516709cog0102_3, DOI 10.1207/S15516709COG0102_3]; Biernacki R, 2014, QUAL SOCIOL, V37, P173, DOI 10.1007/s11133-014-9277-9; Bisk Y, 2019, Arxiv, DOI arXiv:1911.11641; Bitzenbauer, 2023, Contemp. Educ. Technol, V15, P1, DOI [10.30935/cedtech/13176, DOI 10.30935/CEDTECH/13176]; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Boroditsky L, 2011, SCI AM, V304, P62, DOI 10.1038/scientificamerican0211-62; Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726; Brewe E, 2011, PHYS REV SPEC TOP-PH, V7, DOI 10.1103/PhysRevSTPER.7.020106; Brookes D.T., 2006, The Role of Language in Learning Physics; Brookes DT, 2015, INT J SCI EDUC, V37, P759, DOI 10.1080/09500693.2015.1025246; Brookes DT, 2007, PHYS REV SPEC TOP-PH, V3, DOI 10.1103/PhysRevSTPER.3.010105; Brookes DT, 2009, PHYS REV SPEC TOP-PH, V5, DOI 10.1103/PhysRevSTPER.5.010110; Browning J., 2022, ABOUT US; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Buchholz K., 2023, ChatGPT sprints to one million users; Caliskan A, 2017, SCIENCE, V356, DOI 10.1126/science.aal4230; Carlsen W S., 2007, Language and Science Learning Handbook of Research on Science Education; Casasanto D, 2008, LANG LEARN, V58, P63, DOI 10.1111/j.1467-9922.2008.00462.x; Cavagnetto AR, 2010, REV EDUC RES, V80, P336, DOI 10.3102/0034654310376953; Chan KKH, 2021, STUD SCI EDUC, V57, P1, DOI 10.1080/03057267.2020.1755803; Cheuk T, 2021, SCI EDUC, V105, P825, DOI 10.1002/sce.21671; Chi M.T.H., 1994, LEARN INSTR, V4, P27, DOI DOI 10.1016/0959-4752(94)90017-5; CHI MTH, 1993, COGNITION INSTRUCT, V10, P249, DOI 10.1080/07370008.1985.9649011; Chi MTH, 2004, COGNITION INSTRUCT, V22, P363, DOI 10.1207/s1532690xci2203_4; Christian B., 2021, The alignment problem: How can machines learn human values?; Christie F., 2008, SCH DISCOURSE LEARNI; Clark C.M., 1995, THOUGHTFUL TEACHING; Cobbe K, 2021, Arxiv, DOI [arXiv:2110.14168, 10.48550/arXiv.2110.14168]; Crokidakis N, 2023, Arxiv, DOI arXiv:2303.16870; Davis EA, 2006, TEACH TEACH EDUC, V22, P281, DOI 10.1016/j.tate.2005.11.005; de Beule J., 2008, Compositionality, Hierarchy and Recursion in Language; de Vries A, 2023, JOULE, V7, P2191, DOI 10.1016/j.joule.2023.09.004; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DiSessa AA, 2004, COGNITIVE SCI, V28, P843, DOI 10.1016/j.cogsci.2004.05.003; DISESSA AA, 1993, COGNITION INSTRUCT, V10, P105, DOI 10.1080/07370008.1985.9649008; Dodge J, 2022, Arxiv, DOI arXiv:2206.05229; Domingos P., 2015, The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World; Donnelly DF, 2015, J SCI EDUC TECHNOL, V24, P861, DOI 10.1007/s10956-015-9569-1; Euler E, 2019, PHYS REV PHYS EDUC R, V15, DOI 10.1103/PhysRevPhysEducRes.15.010134; Evans V., 2018, Cognitive Linguistics: An Introduction; Fernandez E M., 2011, Fundamentals of Linguistics; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Fulmer GW, 2021, J RES SCI TEACH, V58, P459, DOI 10.1002/tea.21666; Gibbons P., 2002, Scaffolding Language, Scaffolding Learning; Giere R N., 1999, Model-Based Reasoning in Scientific Discovery, P227; Giere RN, 2004, PHILOS SCI, V71, P742, DOI 10.1086/425063; Gilbert G.Nigel., 1984, OPENING PANDORAS BOX; Goldberg Y., 2017, Neural Network Methods in Natural Language Processing, DOI 10.2200/S00762ED1V01Y201703HLT037; Graesser AC, 2004, BEHAV RES METH INS C, V36, P180, DOI 10.3758/BF03195563; Graesser AC, 2018, INT J STEM EDUC, V5, DOI 10.1186/s40594-018-0110-y; Graesser AC, 2016, INT J ARTIF INTELL E, V26, P124, DOI 10.1007/s40593-015-0086-4; Greeno JG, 1998, AM PSYCHOL, V53, P5, DOI 10.1037/0003-066X.53.1.5; Gregorcic B., 2017, Physical Review Physics Education Research, V13, P1, DOI [10.1103/PhysRevPhysEducRes.13.020104, DOI 10.1103/PHYSREVPHYSEDUCRES.13.020104]; Gregorcic B., 2023, PHYS EDUC, V58; Grice H.P., 2013, The Semantics-Pragmatics Boundary in Philosophy, P47; Gupta A, 2010, J LEARN SCI, V19, P285, DOI [10.1080/10508406.2010.491751, 10.1080/105084062010491751]; Halliday M.A.K., 1993, Writing Science: Literacy and Discursive Power; Halliday M. A. K., 1978, LANGUAGE SOCIAL SEMI; Halliday MAK., 2007, An Introduction to Functional Grammar, V2nd ed; Hammer D, 2000, AM J PHYS, V68, pS52, DOI 10.1119/1.19520; Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520; Heaps H S., 1978, Library and Information Science; Heller K.A., 2010, MUNICH STUDIES GIFTE, P301; Hestenes D., 1992, PHYS TEACH, V30, P141, DOI [DOI 10.1119/1.2343497, 10.1119/1.2343497]; Hey T., 2009, 4 PARADIGM DATA INTE; Jammer Max., 1957, CONCEPTS OF FORCE; Jeppsson F, 2013, J LEARN SCI, V22, P70, DOI 10.1080/10508406.2012.691926; Jewitt C., 2013, The SAGE Handbook of Digital Technology Research, P250; Jurafsky D, 2003, PROBABILISTIC LINGUISTICS, P39; Jurafsky Dan, 2014, Speech and language processing, V3; Kansky K, 2017, Arxiv, DOI arXiv:1706.04317; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Keil F., 1979, Cognitive science series, Semantic and conceptual development: An ontological perspective; Keys CW, 1999, J RES SCI TEACH, V36, P1065, DOI 10.1002/(SICI)1098-2736(199912)36:10<1065::AID-TEA2>3.0.CO;2-I; Kieser F, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.020150; Knuuttila T, 2011, EUR J PHILOS SCI, V1, P309, DOI 10.1007/s13194-011-0029-3; Koponen IT, 2010, SCI EDUC-NETHERLANDS, V19, P259, DOI 10.1007/s11191-009-9200-z; Kortemeyer G, 2023, PHYS REV PHYS EDUC R, V19, DOI 10.1103/PhysRevPhysEducRes.19.010132; Kuchemann S., 2023, Phys. Rev. Phys. Edu. Res, V19, DOI [10.48550/arXiv.2304.10014, DOI 10.48550/ARXIV.2304.10014]; Kuhn T.S., 2012, STRUCTURE SCI REVOLU; Lakoff George, 1980, METAPHORS WE LIVE BY; Lamb R, 2021, J SCI EDUC TECHNOL, V30, P283, DOI 10.1007/s10956-020-09871-3; LAVE J, 1991, PERSPECTIVES ON SOCIALLY SHARED COGNITION, P63, DOI 10.1037/10096-003; Lehesvuori S, 2013, J RES SCI TEACH, V50, P912, DOI 10.1002/tea.21100; Leisen J., 2005, Unterricht Physik, V16, P4; Lemke J., 1998, CAIXA C SCI ED; Lemke J. L., 1990, TALKING SCI LANGUAGE; LEMKE JL, 1987, AM J SEMIOTICS, V5, P217, DOI 10.5840/ajs19875217; Lenat D, 2023, Arxiv, DOI arXiv:2308.04445; Leonard W J., 1999, University of Massachusetts Physics Education Research Group Technical Report; Leonard WJ, 1996, AM J PHYS, V64, P1495, DOI 10.1119/1.18409; Levinson S C., 2018, Stud. Pragmat, V20, P16; Levinson S.C., 1997, Journal of Linguistic Anthropology, V7, P98, DOI DOI 10.1525/JLIN.1997.7.1.98; Levshina N, 2022, Entropy, V24, P1, DOI [10.31234/osf.io/sdjur, DOI 10.31234/OSF.IO/SDJUR]; Lewkowycz Aitor, 2022, arXiv; Li KN, 2023, Arxiv, DOI [arXiv:2210.13382, DOI 10.48550/ARXIV.2210.13382]; Liu OL, 2016, J RES SCI TEACH, V53, P215, DOI 10.1002/tea.21299; Lucy L, 2017, Arxiv, DOI [arXiv:1705.11168, DOI 10.18653/V1/W17-2810]; MALLINCKRODT AJ, 1992, AM J PHYS, V60, P356, DOI 10.1119/1.16878; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Marcus G, 2019, Rebooting AI: Building Artificial Intelligence We Can Trust; Marsland S, 2009, CH CRC MACH LEARN PA, P1; Martin J R., 1993, Writing Science Pittsburgh Series in Compositions, Literacy, and Culture; MCCLOSKEY M, 1983, SCI AM, V248, P122, DOI 10.1038/scientificamerican0483-122; Mestre J., 2002, Journal of Computers in Mathematics and Science Teaching, V21, P229; Mikolov T., 2013, INT C NEURAL INF PRO, P3111; Mitchell M., 2009, Complexity: A guided tour; MITCHELL T., 1997, MACHINE LEARNING; Moreno-Sánchez I, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0147073; Nakamura CM, 2016, PHYS REV PHYS EDUC R, V12, DOI 10.1103/PhysRevPhysEducRes.12.010122; Nam J, 2011, INT J SCI MATH EDUC, V9, P1111, DOI 10.1007/s10763-010-9250-3; Nersessian NJ, 1999, MODEL-BASED REASONING IN SCIENTIFIC DISCOVERY, P5; Nolte DD, 2010, PHYS TODAY, V63, P33, DOI 10.1063/1.3397041; Norris SP, 2003, SCI EDUC, V87, P224, DOI 10.1002/sce.10066; Nowak MA, 2002, NATURE, V417, P611, DOI 10.1038/nature00771; Ochs E, 1996, ANNU REV ANTHROPOL, V25, P19, DOI 10.1146/annurev.anthro.25.1.19; Odden TOB, 2020, PHYS REV PHYS EDUC R, V16, DOI 10.1103/PhysRevPhysEducRes.16.010142; Palmer D, 1997, INT J SCI EDUC, V19, P681, DOI 10.1080/0950069970190605; Pinker S., 1994, The Language Instinct: How the Mind Creates Language; Postman N., 1971, Teaching as a subversive activity; Prain V, 1996, TEACH TEACH EDUC, V12, P609, DOI 10.1016/S0742-051X(96)00003-0; Rauf I A., 2021, Physics of Data Science and Machine Learning; Redish EF, 2015, SCI EDUC-NETHERLANDS, V24, P561, DOI 10.1007/s11191-015-9749-7; Reiner M, 2000, COGNITION INSTRUCT, V18, P1, DOI 10.1207/S1532690XCI1801_01; Romer RH, 2001, AM J PHYS, V69, P107, DOI 10.1119/1.1341254; Roth WM, 2001, CURRICULUM INQ, V31, P183, DOI 10.1111/0362-6784.00191; Ruder S, 2019, Neural transfer learning for natural language processing; Russell SJ., 2016, ARTIF INTELL; Schutze H, 1998, COMPUT LINGUIST, V24, P97; Seidel T, 2006, Z PADAGOGIK, V52, P799; SENIOR JK, 1958, PHILOS SCI, V25, P163, DOI 10.1086/287595; Sherin B, 2013, J LEARN SCI, V22, P600, DOI 10.1080/10508406.2013.836654; Strohmaier AR, 2023, EDUC RES REV-NETH, V39, DOI 10.1016/j.edurev.2023.100533; SUTTON C, 1993, J RES SCI TEACH, V30, P1215, DOI 10.1002/tea.3660301005; Sutton C., 1998, International Handbook of Science Education, P27; Sutton R., 2019, ABOUT US; Talanquer V, 2015, J RES SCI TEACH, V52, P585, DOI 10.1002/tea.21209; Tegmark M, 2008, FOUND PHYS, V38, P101, DOI 10.1007/s10701-007-9186-9; Thompson N.C., 2020, arXiv; Tomasello M., 2022, The Cultural Origins of Human Cognition; Touger J, 2000, AM J PHYS, V68, P306, DOI 10.1119/1.19428; Tschisgale P., 2023, Phys. Rev. Phys. Educ. Res, V19, P1, DOI [10.1103/PhysRevPhysEducRes.19.020123, DOI 10.1103/PHYSREVPHYSEDUCRES.19.020123]; van der Linden I, 2019, Arxiv, DOI [arXiv:1907.03039, 10.48550/arxiv.1907.03039]; Volkwyn TrevorStanton., 2019, Des. Learn, V11, P16, DOI DOI 10.16993/DFL.118; Vosniadou S, 2001, LEARN INSTR, V11, P381, DOI 10.1016/S0959-4752(00)00038-4; Vygotsky L.S., 1981, The concept of activity in Soviet psychology, P134; Waight N, 2020, J RES SCI TEACH, V57, P1313, DOI 10.1002/tea.21667; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; Warren B, 2001, J RES SCI TEACH, V38, P529, DOI 10.1002/tea.1017; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wellington J J., 2009, Language and Literacy in Science Education; Wells G, 2006, J LEARN SCI, V15, P379, DOI 10.1207/s15327809jls1503_3; West CG, 2023, Arxiv, DOI arXiv:2303.01067; WIGNER EP, 1960, COMMUN PUR APPL MATH, V13, P1, DOI 10.1002/cpa.3160130102; Williams HT, 1999, AM J PHYS, V67, P670, DOI 10.1119/1.19351; Williamson D. M., 2012, ED MEAS, V31, P2, DOI [10.1111/j.1745-3992.2011.00223.x, DOI 10.1111/J.1745-3992.2011.00223.X]; Wilson J, 2022, PHYS REV PHYS EDUC R, V18, DOI 10.1103/PhysRevPhysEducRes.18.010141; Wittgenstein L., 1967, Philosophische Untersuchungen = Philosophical Investigations/Ludwig Wittgenstein; Wolfram S., 2023, What Is ChatGPT Doing and Why Does It Work?; Wolfram Stephen, 2002, A New Kind of Science, VFirst; Wulff P, 2023, EDUC INF TECHNOL, V28, P14325, DOI 10.1007/s10639-022-11531-5; Wulff P, 2023, FRONT EDUC, V7, DOI 10.3389/feduc.2022.1061461; Wulff P, 2022, J SCI EDUC TECHNOL, V31, P490, DOI 10.1007/s10956-022-09969-w; Wulff P, 2021, J SCI EDUC TECHNOL, V30, P1, DOI 10.1007/s10956-020-09865-1; Yeadon W., 2023, Phys. Educ., V58; Yore LD, 2006, INT J SCI EDUC, V28, P291, DOI 10.1080/09500690500336973; Yore LD, 2004, READ RES QUART, V39, P347, DOI 10.1598/RRQ.39.3.8; ZEMANSKY M.K., 1970, PHYS TEACH, V8, P295, DOI [10.1119/1.2351512, DOI 10.1119/1.2351512]; Zhai XM, 2020, STUD SCI EDUC, V56, P111, DOI 10.1080/03057267.2020.1735757; Zipf GK, 1950, J CLIN PSYCHOL, V6, P306	188	0	0	19	19	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0143-0807	1361-6404		EUR J PHYS	Eur. J. Phys.	MAR 1	2024	45	2							023001	10.1088/1361-6404/ad0f9c	http://dx.doi.org/10.1088/1361-6404/ad0f9c			29	Education, Scientific Disciplines; Physics, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Education & Educational Research; Physics	GH3J3		hybrid			2024-07-03	WOS:001151734300001
C	Zhang, GY			ACM	Zhang, Gangyi			User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models	PROCEEDINGS OF THE 17TH ACM CONFERENCE ON RECOMMENDER SYSTEMS, RECSYS 2023			English	Proceedings Paper	17th ACM Conference on Recommender Systems (RecSys)	SEP 18-22, 2023	Singapore, SINGAPORE	Assoc Comp Machinery		conversational recommendation; user-centric; large language model		Conversational recommender systems (CRS) promise to provide a more natural user experience for exploring and discovering items of interest through ongoing conversation. However, effectively modeling and adapting to users' complex and changing preferences remains challenging. This research develops user-centric methods that focus on understanding and adapting to users throughout conversations to provide the most helpful recommendations. First, a graph-based Conversational Path Reasoning (CPR) framework is proposed that represents dialogs as interactive reasoning over a knowledge graph to capture nuanced user interests and explain recommendations. To further enhance relationship modeling, graph neural networks are incorporated for improved representation learning. Next, to address uncertainty in user needs, the Vague Preference Multi-round Conversational Recommendation (VPMCR) scenario and matching Adaptive Vague Preference Policy Learning (AVPPL) solution are presented using reinforcement learning to tailor recommendations to evolving preferences. Finally, opportunities to leverage large language models are discussed to further advance user experiences via advanced user modeling, policy learning, and response generation. Overall, this research focuses on designing conversational recommender systems that continuously understand and adapt to users' ambiguous, complex and changing needs during natural conversations.	[Zhang, Gangyi] Univ Sci & Technol China, Hefei, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Zhang, GY (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	gangyi@mail.ustc.edu.cn						Bao KQ, 2023, Arxiv, DOI [arXiv:2305.00447, DOI 10.48550/ARXIV.2305.004472305.00447]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chen QB, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1803; Chu Zhendong, 2023, WSDM '23: Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining, P222, DOI 10.1145/3539597.3570443; Deng Y, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1431, DOI 10.1145/3404835.3462913; Gao CM, 2021, AI OPEN, V2, P100, DOI 10.1016/j.aiopen.2021.06.002; Gao YF, 2023, Arxiv, DOI arXiv:2303.14524; Guo Shuyu, 2023, Towards Explainable Conversational Recommender Systems; He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063; Hou YP, 2024, Arxiv, DOI [arXiv:2305.08845, 10.48550/ARXIV.2305.08845https://arxiv.org/abs/2305.088452305.08845]; Hu CH, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P256, DOI 10.1145/3477495.3531844; Kang WC, 2023, Arxiv, DOI arXiv:2305.06474; Lei WQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2073, DOI 10.1145/3394486.3403258; Lei WQ, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P304, DOI 10.1145/3336191.3371769; Li R, 2018, ADV NEUR IN, V31; Li SJ, 2021, ACM T INFORM SYST, V39, DOI 10.1145/3446427; Liao LZ, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P801, DOI 10.1145/3240508.3240605; Lin A, 2022, PROCEEDINGS OF THE 31ST ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2022, P1238, DOI 10.1145/3511808.3557423; Liu ZM, 2020, Arxiv, DOI arXiv:2005.03954; Lu Y., 2021, arXiv; Ma WC, 2021, Arxiv, DOI arXiv:2010.10333; Moon S, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P845; Shen Tianshu, 2022, arXiv; Sun YM, 2018, ACM/SIGIR PROCEEDINGS 2018, P235, DOI 10.1145/3209978.3210002; Wang L, 2023, Arxiv, DOI arXiv:2304.03153; Wang XL, 2023, Arxiv, DOI arXiv:2305.13112; Wang XL, 2022, PROCEEDINGS OF THE 28TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, KDD 2022, P1929, DOI 10.1145/3534678.3539382; Xu KR, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P364, DOI 10.1145/3437963.3441791; YuxiaWu Lizi Liao, 2022, IEEE Transactions on Multimedia; Zhang GY, 2023, Arxiv, DOI arXiv:2306.04487; Zhang JZ, 2023, Arxiv, DOI arXiv:2305.07609; Zhang JJ, 2023, Arxiv, DOI arXiv:2305.07001; Zhang S, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1512, DOI 10.1145/3394486.3403202; Zhang YM, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2153, DOI 10.1145/3485447.3512088; Zhang YF, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P177, DOI 10.1145/3269206.3271776; Zhou J., 2021, P C EMP METH NAT LAN, P4324; Zhou K, 2020, Arxiv, DOI arXiv:2010.04125; Zhou K, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1006, DOI 10.1145/3394486.3403143; Zhou YH, 2022, WSDM'22: PROCEEDINGS OF THE FIFTEENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P1488, DOI 10.1145/3488560.3498514	39	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0241-9				2023							1349	1354		10.1145/3604915.3608885	http://dx.doi.org/10.1145/3604915.3608885			6	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4WZ					2024-07-03	WOS:001156630300192
J	Martínez, PA; Bernabé, G; García, JM				Martinez, Pablo Antonio; Bernabe, Gregorio; Garcia, Jose Manuel			Code Detection for Hardware Acceleration Using Large Language Models	IEEE ACCESS			English	Article						Codes; Task analysis; Computational modeling; Convolution; Kernel; Hardware acceleration; Transforms; Detection algorithms; Program processors; Large language models; Code detection; compilers; heterogeneous computing; high-performance computing; large language model		Large language models (LLMs) have been massively applied to many tasks, often surpassing state-of-the-art approaches. While their effectiveness in code generation has been extensively studied (e.g., AlphaCode), their potential for code detection remains unexplored. This work presents the first analysis of code detection using LLMs. Our study examines essential kernels, including matrix multiplication, convolution, fast-fourier transform and LU factorization, implemented in C/C++. We propose both a preliminary, naive prompt and a novel prompting strategy for code detection. Results reveal that conventional prompting achieves great precision but poor accuracy (67.5%, 22.5%, 79.5% and 64% for GEMM, convolution, FFT and LU factorization, respectively) due to a high number of false positives. Our novel prompting strategy substantially reduces false positives, resulting in excellent overall accuracy (91.2%, 98%, 99.7% and 99.7%, respectively). These results pose a considerable challenge to existing state-of-the-art code detection methods.	[Martinez, Pablo Antonio] Huawei Technol Res & Dev, Cambridge CB4 0WN, England; [Bernabe, Gregorio; Garcia, Jose Manuel] Univ Murcia, Comp Engn Dept, Murcia 30100, Spain	Huawei Technologies; University of Murcia	Bernabé, G (corresponding author), Univ Murcia, Comp Engn Dept, Murcia 30100, Spain.		Garcia, Jose M./J-5734-2017; Bernabe, Gregorio/E-9135-2015	Garcia, Jose M./0000-0002-6388-2835; Bernabe, Gregorio/0000-0002-7265-3508; Martinez, Pablo A./0000-0002-4391-2451	Ministerio de Ciencia e Innovacin (MCIN)/Agencia Estatal de Investigacin (AEI)/10. 13039/501100011033	Ministerio de Ciencia e Innovacin (MCIN)/Agencia Estatal de Investigacin (AEI)/10. 13039/501100011033	No Statement Available	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254; Bengio Y, 2001, ADV NEUR IN, V13, P932; Beurer-Kellner L, 2023, P ACM PROGRAM LANG, V7, DOI 10.1145/3591300; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cummins Chris, 2021, ICML, V139, P2244; Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682; De Carvalho JPL, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3459010; Dr-Noob, 2023, Zenodo, DOI 10.5281/ZENODO.7902464; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Espindola V, 2023, ACM T ARCHIT CODE OP, V20, DOI 10.1145/3571283; Ginsbach P, 2018, ACM SIGPLAN NOTICES, V53, P139, DOI [10.1145/3173162.3173182, 10.1145/3296957.3173182]; Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jia Y., 2014, Caffe: Convolutional Architecture for Fast Feature Embedding; Kocoń J, 2023, Arxiv, DOI arXiv:2302.10724; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/CGO.2004.1281665; Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Martínez PA, 2021, ENG APPL ARTIF INTEL, V99, DOI 10.1016/j.engappai.2020.104131; Martinez Pablo Antonio, 2023, Zenodo, DOI 10.5281/ZENODO.8154364; Martinez PA, 2023, PROCEEDINGS OF THE 32ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION, CC 2023, P85, DOI 10.1145/3578360.3580262; Mialon G., 2023, arXiv; Microsoft, 2023, Guidance: A Guidance Language for Controlling Large Language Models; Mou LL, 2016, AAAI CONF ARTIF INTE, P1287; Nielson Flemming, 2015, Principles of Program Analysis, DOI [10.1007/978-3-662-03811-6, DOI 10.1007/978-3-662-03811-6]; OpenAI, GPT Models; OpenAI, GPT best practices'; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Peccerillo B, 2022, J SYST ARCHITECT, V129, DOI 10.1016/j.sysarc.2022.102561; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411; Stratton John A, 2012, Center for Reliable and High-Performance Computing, V127, P29; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; White J, 2023, Arxiv, DOI [arXiv:2302.11382, 10.48550/arXiv.2302.11382, DOI 10.48550/ARXIV.2302.11382]; Woodruff J, 2022, PROCEEDINGS OF THE 43RD ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '22), P687, DOI 10.1145/3519939.3523439; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zoph B., Trans. Mach. Learn. Res. (TMLR), P1	48	0	0	2	2	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2169-3536			IEEE ACCESS	IEEE Access		2024	12						35271	35281		10.1109/ACCESS.2024.3372853	http://dx.doi.org/10.1109/ACCESS.2024.3372853			11	Computer Science, Information Systems; Engineering, Electrical & Electronic; Telecommunications	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering; Telecommunications	KD5F0		Green Submitted, gold			2024-07-03	WOS:001178026900001
J	Handler, A; Larsen, KR; Hackathorn, R				Handler, Abram; Larsen, Kai R.; Hackathorn, Richard			Large language models present new questions for decision support	INTERNATIONAL JOURNAL OF INFORMATION MANAGEMENT			English	Article						Decision support systems; Generative artificial intelligence; Large language models; Natural language processing; Business intelligence	INFORMATION-SYSTEMS; ARTIFICIAL-INTELLIGENCE; DESIGN SCIENCE; FUTURE; FRAMEWORK; RELEVANCE	Large language models (LLMs) have proven capable of assisting with many aspects of organizational decision making, such as helping to collect information from databases and helping to brainstorm possible courses of action ahead of making a choice. We propose that broad adoption of these technologies introduces new questions in the study of decision support systems, which assist people with complex and open-ended choices in business. Where traditional study of decision support has focused on bespoke tools to solve narrow problems in specific domains, LLMs offer a general-purpose decision support technology which can be applied in many contexts. To organize the wealth of new questions which result from this shift, we turn to a classic framework from Herbert Simon, which proposes that decision making requires collecting evidence, considering alternatives, and finally making a choice. Working from Simon's framework, we describe how LLMs introduce new questions at each stage of this decision-making process. We then group new questions into three overarching themes for future research, centered on how LLMs will change individual decision making, how LLMs will change organizational decision making, and how to design new decision support technologies which make use of the new capabilities of LLMs.	[Handler, Abram; Larsen, Kai R.] Univ Colorado, Leeds Sch Business, 995 Regent Dr, Boulder, CO 80309 USA; [Hackathorn, Richard] Bolder Technol Inc, 4740 Hancock Dr, Boulder, CO 80303 USA	University of Colorado System; University of Colorado Boulder	Handler, A (corresponding author), Univ Colorado, Leeds Sch Business, 995 Regent Dr, Boulder, CO 80309 USA.	abram.handler@colorado.edu; kai.larsen@colorado.edu; richard.hackathorn@gmail.com						Abdel-Karim BM, 2023, MIS QUART, V47, P1395, DOI 10.25300/MISQ/2022/16773; Adadi A, 2018, IEEE ACCESS, V6, P52138, DOI 10.1109/ACCESS.2018.2870052; Amankwah-Amoah J., 2024, International Journal of Information Management; Arnott D, 2006, INFORM SYST J, V16, P55, DOI 10.1111/j.1365-2575.2006.00208.x; Autor D., 2024, Working Paper 32140; Bazerman M. H., 2012, Judgment in managerial decision making; Benbasat I, 1999, MIS QUART, V23, P3, DOI 10.2307/249403; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bendor J, 2001, ANNU REV POLIT SCI, V4, P235, DOI 10.1146/annurev.polisci.4.1.235; Beraldi P, 2011, DECIS SUPPORT SYST, V51, P549, DOI 10.1016/j.dss.2011.02.017; Bertsch S, 2007, MEM COGNITION, V35, P201, DOI 10.3758/BF03193441; Bohnet B, 2023, Arxiv, DOI arXiv:2212.08037; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Brynjolfsson E., 1993, Journal of Organizational Computing, V3; Brynjolfsson E., 2017, Econ Artif Intell: Agenda, DOI [DOI 10.7208/CHICAGO/9780226613475.003.0001, 10.3386/w24001]; Bubeck S., 2023, arXiv; Cao GM, 2021, TECHNOVATION, V106, DOI 10.1016/j.technovation.2021.102312; Cobb C., 1928, American Economic Review, V18; Column Bartleby, 2023, The Economist; Cursor, 2024, Cursor: The AI-first code editor; Dimoka A., 2012, MIS Quarterly, V36; Doshi-Velez F, 2017, Arxiv, DOI [arXiv:1702.08608, DOI 10.48550/ARXIV.1702.08608]; Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Eom S, 2006, J OPER RES SOC, V57, P1264, DOI 10.1057/palgrave.jors.2602140; Eom SB, 1998, J OPER RES SOC, V49, P109, DOI 10.2307/3009977; Eva N, 2019, LEADERSHIP QUART, V30, P111, DOI 10.1016/j.leaqua.2018.07.004; Fernandez RC, 2023, PROC VLDB ENDOW, V16, P3302; FluidTruck, 2023, Using ChatGPT for route optimization and more!; Freeman S, 2014, P NATL ACAD SCI USA, V111, P8410, DOI 10.1073/pnas.1319030111; Gloria M., 2012, P SIGCHI C HUM FACT; GORRY GA, 1971, SLOAN MANAGE REV, V13, P55; GORRY GA, 1989, SLOAN MANAGE REV, V30, P49; Green S., 2015, Queue, V13; Groeneveld D, 2024, Arxiv, DOI arXiv:2402.00838; Gururangan S., 2022, P 2022 C EMP METH NA; Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625; HUNTLEY CL, 1995, INTERFACES, V25, P58, DOI 10.1287/inte.25.3.58; Jacovi A, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P624, DOI 10.1145/3442188.3445923; Janis I. L., 1972, VICTIMS GROUPTHINK P; Kahneman D., 2011, THINKING FAST SLOW; Kandpal N., 2023, P 40 INT C MACH LEAR; Kane GC, 2021, MIS QUART, V45, P371, DOI 10.25300/MISQ/2021/1578; Keary T., 2023, GPT has entered the security threat intelligence chat; Klein E., 2023, Episode: Ezra Klein Show; Klein E., 2024, Will A.I. break the internet? Or save it? Episode: Ezra Klein Show; Kleinberg J, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2018340118; Kohli R, 2003, INFORM SYST RES, V14, P127, DOI 10.1287/isre.14.2.127.16019; Kwiatkowski T, 2019, T ASSOC COMPUT LING, V7, P453, DOI 10.1162/tacl_a_00276/1923288; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Lilien GL, 2011, J MARKETING, V75, P196, DOI 10.1509/jmkg.75.4.196; LITTLE JDC, 1970, MANAGE SCI B-APPL, V16, pB466, DOI 10.1287/mnsc.1040.0267; Lubars B., 2019, P 33 INT C NEUR INF; Martinez C., 2023, Medium; Merkert J., 2015, EUR C INF SYST; Min SW, 2023, Arxiv, DOI arXiv:2308.04430; Mishan E. J., 2020, Cost-benefit analysis, DOI DOI 10.4324/9781351029780; Moran A., 2015, Managing agile: Strategy, implementation, organisation and people; Murty KG, 2005, DECIS SUPPORT SYST, V39, P309, DOI 10.1016/j.dss.2003.11.002; Myers M., 1999, CAIS, V2; Notion Labs, 2024, Notion AI; Open Syllabus, 2023, Business syllabi featuring Bazerman and Moore; OpenAI, 2021, OpenAI codex; Patterns, 2024, Patterns documentation; Polák P, 2017, INF ECON POLICY, V38, P38, DOI 10.1016/j.infoecopol.2016.11.003; Rashkin H, 2023, COMPUT LINGUIST, V49, P777, DOI 10.1162/coli_a_00486; Roberts A, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P5418; Robertson B.J., 2015, Holacracy: The New Management System for a Rapidly Changing World; Rosemann M, 2008, MIS QUART, V32, P1; Rossi S, 2024, INT J INFORM MANAGE, V77, DOI 10.1016/j.ijinfomgt.2023.102749; Roth E., 2023, The Verge; Roy MC, 1996, INFORM SYST RES, V7, P233, DOI 10.1287/isre.7.2.233; SAATY RW, 1987, MATH MODELLING, V9, P161, DOI 10.1016/0270-0255(87)90473-8; Schultze U, 2011, INFORM ORGAN-UK, V21, P1, DOI 10.1016/j.infoandorg.2010.11.001; Schweikl S., 2020, Management Review Quarterly, V70; Shim JP, 2002, DECIS SUPPORT SYST, V33, P111, DOI 10.1016/S0167-9236(01)00139-7; Simon H. A., 1960, NEW SCI MANAGEMENT D; SIMON HA, 1978, AM ECON REV, V68, P1; Simon HA, 1955, Q J ECON, V69, P99, DOI 10.2307/1884852; Soh C., 1995, IT CREATES BUSINESS; Soldaini L, 2024, Arxiv, DOI arXiv:2402.00159; Solow R., 1987, New York Times Book Review; Sparrow B, 2011, SCIENCE, V333, P776, DOI 10.1126/science.1207745; Sprague RH, 1980, MIS QUART, V4, P1, DOI 10.2307/248957; Starkey K, 2001, BRIT J MANAGE, V12, pS3, DOI 10.1111/1467-8551.12.s1.2; Tetlock Philip, 2015, Superforecasting: The Art and Science of Prediction; Tian K., 2023, P 2023 C EMP METH NA; Tong A., 2024, Reuters; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; van der Kleij R, 2022, COMPUT SECUR, V113, DOI 10.1016/j.cose.2021.102535; Van Haren K., 2023, Patterns blog; Wilmer HH, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.00605; Wiseman Sam., 2017, P 2017 C EMPIRICAL M, P2253, DOI [DOI 10.18653/V1/D17-1239, 10.18653/v1/D17-1239]; Wolfram Research, 2023, Symbolic calculations; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yin R. K., 2013, CASE STUDY RES DESIG; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219	98	0	0	3	3	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0268-4012	1873-4707		INT J INFORM MANAGE	Int. J. Inf. Manage.	DEC	2024	79								102811	10.1016/j.ijinfomgt.2024.102811	http://dx.doi.org/10.1016/j.ijinfomgt.2024.102811			7	Information Science & Library Science	Social Science Citation Index (SSCI)	Information Science & Library Science	UR8X7					2024-07-03	WOS:001249889200001
J	Leivada, E; Dentella, V; Guenther, F				Leivada, Evelina; Dentella, Vittoria; Guenther, Fritz			Evaluating the Language Abilities of Large Language Models vs. Humans: Three Caveats	BIOLINGUISTICS			English	Article						Artificial Intelligence; grammaticality; Large Language Models; probabilities		We identify and analyze three caveats that may arise when analyzing the linguistic abilities of Large Language Models. The problem of unlicensed generalizations refers to the danger of interpreting performance in one task as predictive of the models' overall capabilities, based on the assumption that because a specific task performance is indicative of certain underlying capabilities in humans, the same association holds for models. The human-like paradox refers to the problem of lacking human comparisons, while at the same time attributing human-like abilities to the models. Last, the problem of double standards refers to the use of tasks and methodologies that either cannot be applied to humans or they are evaluated differently in models vs. humans. While we recognize the impressive linguistic abilities of LLMs, we conclude that specific claims about the	[Leivada, Evelina] Univ Autonoma Barcelona, Dept Catalan Philol, Barcelona, Spain; [Dentella, Vittoria] Inst Catalana Recerca & Estudis Avancats ICREA, Barcelona, Spain; [Guenther, Fritz] Univ Rovira i Virgili, Dept English & German Studies, Tarragona, Spain; [Leivada, Evelina] Humboldt Univ, Inst Psychol, Berlin, Germany; [Leivada, Evelina] Univ Autonoma Barcelona, Dept Filol Catalana, Barcelona 08193, Spain	Autonomous University of Barcelona; ICREA; Universitat Rovira i Virgili; Humboldt University of Berlin; Autonomous University of Barcelona	Leivada, E (corresponding author), Univ Autonoma Barcelona, Dept Filol Catalana, Barcelona 08193, Spain.	evelina.leivada@uab.cat						Dentella V, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2309583120; Felin T., 2024, Theory is all you need: AI, human cognition, and decision making, DOI [10.2139/ssrn.4737265, DOI 10.2139/SSRN.4737265]; Frank MC, 2023, NAT REV PSYCHOL, V2, P451, DOI 10.1038/s44159-023-00211-x; Gates B., 2023, GatesNotes; Guest O., 2023, Computational Brain & Behavior, DOI DOI 10.1007/S42113-022-00166-X; Hu J., 2023, P 2023 C EMP METH NA, P5040; Hu J., P NATL ACAD SCI US; Hu J, 2024, Arxiv, DOI [arXiv:2404.02418, 10.48550/arXiv.2404.02418, DOI 10.48550/ARXIV.2404.02418]; KAHNEMAN D, 1982, COGNITION, V11, P123, DOI 10.1016/0010-0277(82)90022-1; Kidd C, 2023, SCIENCE, V380, P1222, DOI 10.1126/science.adi0248; Leivada E., P NATL ACAD SCI US; Leivada E, 2023, Arxiv, DOI [arXiv:2310.11146, 10.48550/arXiv.2310.11146, DOI 10.48550/ARXIV.2310.11146]; Leivada E, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00364; Warstadt A, 2020, T ASSOC COMPUT LING, V8, P377, DOI 10.1162/tacl_a_00321	14	0	0	0	0	UNIV CYPRUS, DEPT ENGLISH STUDIES	NICOSIA	UNIV CYPRUS, DEPT ENGLISH STUDIES, NICOSIA, 1678, CYPRUS	1450-3417			BIOLINGUISTICS	Biolinguistics		2024	18								e14391	10.5964/bioling.14391	http://dx.doi.org/10.5964/bioling.14391			12	Language & Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	SW7B4		gold			2024-07-03	WOS:001237539500001
C	Liesenfeld, A; Lopez, A; Dingemanse, M			ACM	Liesenfeld, Andreas; Lopez, Alianda; Dingemanse, Mark			Opening up ChatGPT: Tracking openness, transparency, and accountability in instruction-tuned text generators	PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON CONVERSATIONAL USER INTERFACES, CUI 2023			English	Proceedings Paper	5th International Conference on Conversational User Interfaces (CUI)	JUL 19-21, 2023	Eindhoven Univ Technol, Eindhoven, NETHERLANDS	Assoc Comp Machinery, ACM SIGCHI, Bold Insight UK, Eindhoven Univ Technol, Eindhoven AI Syst Inst, HMD Res	Eindhoven Univ Technol	open source; survey; chatGPT; large language models; RLHF	AI	Large language models that exhibit instruction-following behaviour represent one of the biggest recent upheavals in conversational interfaces, a trend in large part fuelled by the release of OpenAI's ChatGPT, a proprietary large language model for text generation fine-tuned through reinforcement learning from human feedback (LLM+RLHF). We review the risks of relying on proprietary software and survey the first crop of open-source projects of comparable architecture and functionality. The main contribution of this paper is to show that openness is differentiated, and to offer scientific documentation of degrees of openness in this fast-moving field. We evaluate projects in terms of openness of code, training data, model weights, RLHF data, licensing, scientific documentation, and access methods. We find that while there is a fast-growing list of projects billing themselves as 'open source', many inherit undocumented data of dubious legality, few share the all-important instruction-tuning (a key site where human annotation labour is involved), and careful scientific documentation is exceedingly rare. Degrees of openness are relevant to fairness and accountability at all points, from data collection and curation to model architecture, and from training and fine-tuning to release and deployment.	[Liesenfeld, Andreas; Lopez, Alianda; Dingemanse, Mark] Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands	Radboud University Nijmegen	Liesenfeld, A (corresponding author), Radboud Univ Nijmegen, Ctr Language Studies, Nijmegen, Netherlands.	andreas.liesenfeld@ru.nl; ada.lopez@ru.nl; mark.dingemanse@ru.nl	Dingemanse, M./U-5176-2018	Dingemanse, M./0000-0002-3290-5723; Liesenfeld, Andreas/0000-0001-6076-4406	Dutch Research Council (NWO) [016.vidi.185.205]	Dutch Research Council (NWO)(Netherlands Organization for Scientific Research (NWO))	This research is funded by Dutch Research Council (NWO) grant 016.vidi.185.205 to MD. For the purpose of Open Access the authors have applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahmed N, 2023, SCIENCE, V379, P884, DOI 10.1126/science.ade2420; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BERNSTEIN FC, 1977, J MOL BIOL, V112, P535, DOI 10.1016/S0022-2836(77)80200-3; Birhane A, 2022, arXiv, DOI [arXiv:2110.01963, DOI 10.48550/ARXIV.2110.01963]; Birhane A, 2021, IEEE WINT CONF APPL, P1536, DOI 10.1109/WACV48630.2021.00158; Birhane A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100205; Birhane Abeba, 2021, Kvinder, Kon & Forskning, V29, P60, DOI DOI 10.7146/KKF.V29I2.124899; Burgelman JC, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00043; Carlini N, 2021, Arxiv, DOI [arXiv:2012.07805, 10.48550/arXiv.2012.07805]; Chawla Sanjay, 2023, R Soc Open Sci, V10, P221414, DOI 10.1098/rsos.221414; Church KW, 2022, NAT LANG ENG, V28, P249, DOI 10.1017/S1351324922000043; Cohen Deborah, 2022, arXiv, DOI 10.48550/arXiv.2208.02294; Crisan Anamaria, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P427, DOI 10.1145/3531146.3533108; Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848; Frankfurt HG, 2005, ON BULLSHIT, P1; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gebru Timnit, 2023, Statement from the listed authors of Stochastic Parrots on the "AI pause; Gundersen OE, 2018, AAAI CONF ARTIF INTE, P1644; Gundersen OE, 2018, AI MAG, V39, P56, DOI 10.1609/aimag.v39i3.2816; Haibe-Kains B, 2020, NATURE, V586, pE14, DOI 10.1038/s41586-020-2766-y; Henderson P., 2022, Advances in Neural Information Processing Systems, V35, P29217; Hutchinson B, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P560, DOI 10.1145/3442188.3445918; Illich I, 1973, Tools for Conviviality; Knox WB, 2008, INT C DEVEL LEARN, P292, DOI 10.1109/DEVLRN.2008.4640845; Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386; Lambert N, 2022, Hugging Face Blog; Larson Martha, 2021, UMAP '21: Proceedings of the 29th ACM Conference on User Modeling, Adaptation and Personalization, P388, DOI 10.1145/3450614.3463601; Laurencon Hugo, 2022, The BigScience ROOTS Corpus: A 1.6TB Com- posite Multilingual Dataset; Lee CH, 2016, EQUITY EXCELL EDUC, V49, P480, DOI 10.1080/10665684.2016.1227157; Li B, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3555803; Liang WX, 2022, NAT MACH INTELL, V4, P669, DOI 10.1038/s42256-022-00516-1; Luccioni A. S., 2022, arXiv, DOI 10.48550/ARXIV.2211.02001; Ziegler DM, 2020, Arxiv, DOI arXiv:1909.08593; McKiernan EC, 2016, ELIFE, V5, DOI 10.7554/eLife.16800; McMillan-Major A, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P121; McMillan-Major Angelina, 2023, ACM Journal on Responsible Computing, DOI DOI 10.1145/3594737JUSTACCEPTED; McQuillan Dan., 2022, Resisting AI: An Anti-Fascist Approach to Artificial Intelligence, VFirst, Patent No. on1328026349; Mialon G., 2023, arXiv; Mitchell M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P220, DOI 10.1145/3287560.3287596; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; Muller M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517644; Nahar N, 2022, PROC INT CONF SOFTW, P413, DOI 10.1145/3510003.3510209; Ouyang Long, 2022, Training language models to follow instructions with human feedback, P68; Pandey Mohit, 2023, Analytics India MagazineMarch; Paullada A, 2021, PATTERNS, V2, DOI 10.1016/j.patter.2021.100336; Phang Jason, 2022, arXiv, DOI 10.48550/arXiv.2210.06413; Rogers A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P2182; Sambasivan Nithya, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445518; Scao T. L., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2211.05100; Schaul Kevin, 2023, Inside the secret list of websites that make AI like ChatGPT sound smart; Solaiman I, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P111, DOI 10.1145/3593013.3593981; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tunyasuvunakool K, 2021, NATURE, V596, P590, DOI 10.1038/s41586-021-03828-1; Wang Su, 2022, arXiv, DOI DOI 10.48550/ARXIV.2212; Warnell G, 2018, AAAI CONF ARTIF INTE, P1545; Xu CW, 2023, Arxiv, DOI [arXiv:2304.01196, DOI 10.48550/ARXIV.2304.01196]; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862	58	10	10	7	7	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0014-9				2023									47	10.1145/3571884.3604316	http://dx.doi.org/10.1145/3571884.3604316			6	Computer Science, Cybernetics; Psychology	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Psychology	BW2OK		Green Submitted, Green Published			2024-07-03	WOS:001122710800047
J	Hu, ZJ; Yang, P; Jiang, YS; Bai, ZJ				Hu, Zhongjian; Yang, Peng; Jiang, Yuanshuang; Bai, Zijian			Prompting large language model with context and pre-answer for knowledge-based VQA	PATTERN RECOGNITION			English	Article						Visual question answering; Large language model; Knowledge-based VQA; Fine-tuning; In-context learning		Existing studies apply Large Language Model (LLM) to knowledge -based Visual Question Answering (VQA) with encouraging results. Due to the insufficient input information, the previous methods still have shortcomings in constructing the prompt for LLM, and cannot fully activate the capacity of LLM. In addition, previous works adopt GPT-3 for inference, which has expensive costs. In this paper, we propose PCPA: a framework that Prompts LLM with Context and Pre -Answer for VQA. Specifically, we adopt a vanilla VQA model to generate in -context examples and candidate answers, and add a pre -answer selection layer to generate preanswers. We integrate in -context examples and pre -answers into the prompt to inspire the LLM. In addition, we choose LLaMA instead of GPT-3, which is an open and free model. We build a small dataset to fine-tune the LLM. Compared to existing baselines, the PCPA improves accuracy by more than 2.1 and 1.5 on OK-VQA and A-OKVQA, respectively.	[Hu, Zhongjian; Yang, Peng; Bai, Zijian] Southeast Univ, Key Lab Comp Network & Informat Integrat, Minist Educ, Nanjing, Peoples R China; [Hu, Zhongjian; Yang, Peng; Jiang, Yuanshuang; Bai, Zijian] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China	Southeast University - China; Southeast University - China	Yang, P (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.	huzj@seu.edu.cn; pengyang@seu.edu.cn; yuanshuangjiang@seu.edu.cn; bzj@seu.edu.cn			National Natural Science Foundation of China [62272100]; Consulting Project of Chinese Academy of Engineering [2023-XY-09]; Major Project of the National Social Science Fund of China [21ZD11]; Fundamental Research Funds for the Central Universities, China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Consulting Project of Chinese Academy of Engineering; Major Project of the National Social Science Fund of China; Fundamental Research Funds for the Central Universities, China(Fundamental Research Funds for the Central Universities)	This work was supported in part by the National Natural Science Foundation of China under Grant 62272100, the Consulting Project of Chinese Academy of Engineering under Grant 2023-XY-09, and in part by the Major Project of the National Social Science Fund of China under Grant 21ZD11 and the Fundamental Research Funds for the Central Universities, China.	Altan A, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110071; Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Bao H., 2022, ADV NEURAL INF PROCE, V35, P32897, DOI DOI 10.1109/CVPR.2018.00636; Beckham C, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109209; Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Chowdhary K. R., 2020, Fundamentals of artificial intelligence, P603, DOI DOI 10.1007/978-81-322-3972-719; Gao F, 2022, PROC CVPR IEEE, P5057, DOI 10.1109/CVPR52688.2022.00501; Gardères F, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P489; Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670; Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y; Guo YY, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P2061, DOI 10.1145/3503161.3547870; Jiang Y, 2018, Arxiv, DOI arXiv:1807.09956; Kamath A, 2022, LECT NOTES COMPUT SC, V13696, P662, DOI 10.1007/978-3-031-20059-5_38; Khan AA, 2021, EAI ENDORSED TRANS S, V8, DOI 10.4108/eai.21-4-2021.169418; Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7; Li JN, 2022, PR MACH LEARN RES; Lu J., 2022, 11 INT C LEARN REPR; Lu JS, 2019, ADV NEUR IN, V32; Luo M, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6417; Marino K, 2021, PROC CVPR IEEE, P14106, DOI 10.1109/CVPR46437.2021.01389; Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331; Meshuwelde T, 2023, PATTERN RECOGN, V144, DOI 10.1016/j.patcog.2023.109850; Mokady A., 2021, arXiv; Ozcelik Y.B., researchgate; Özcelik YB, 2023, FRACTAL FRACT, V7, DOI 10.3390/fractalfract7080598; Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3; Ravi S, 2023, IEEE WINT CONF APPL, P1155, DOI 10.1109/WACV56688.2023.00121; Sabour S, 2017, ADV NEUR IN, V30; Salaberria A, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118669; Schwenk D, 2022, LECT NOTES COMPUT SC, V13668, P146, DOI 10.1007/978-3-031-20074-8_9; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Shen Sheng, 2021, INT C LEARN REPR; Tan H, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5100; Tito R, 2023, PATTERN RECOGN, V144, DOI 10.1016/j.patcog.2023.109834; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; Wang P, 2022, 39 INT C MACHINE LEA; Wang P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1290; Wu JL, 2022, AAAI CONF ARTIF INTE, P2712; Wu Q., 2022, Visual Question Answering: From Theory to Application, P73, DOI [10.1007/978-981-19-0964-1_5, DOI 10.1007/978-981-19-0964-1_5]; Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yu Z, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3743, DOI 10.1145/3394171.3413977; Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644; Zeng GY, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109337; Zhang HA, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109339; Zhang PC, 2021, PROC CVPR IEEE, P5575, DOI 10.1109/CVPR46437.2021.00553; Zhao J, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2021, P1862; Zhu ZH, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1097	50	1	1	12	12	ELSEVIER SCI LTD	London	125 London Wall, London, ENGLAND	0031-3203	1873-5142		PATTERN RECOGN	Pattern Recognit.	JUL	2024	151								110399	10.1016/j.patcog.2024.110399	http://dx.doi.org/10.1016/j.patcog.2024.110399		MAR 2024	13	Computer Science, Artificial Intelligence; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	OZ0B5					2024-07-03	WOS:001210970900001
J	Bolat, B; Eren, OC; Karasayar, AHD; Mericoz, CA; Gunduz-Demir, C; Kulac, I				Bolat, Beyza; Eren, Ozgur Can; Karasayar, A. Humeyra Dur; Mericoz, Cisel Aydin; Gunduz-Demir, Cigdem; Kulac, Ibrahim			Large Language Models as a Rapid and Objective Tool for Pathology Report Data Extraction	TURKISH JOURNAL OF PATHOLOGY			English	Letter						Large language models (LLMs); Pathology; Generative pre-trained transformer-4 (GPT-4); ChatGPT; Bard		Medical institutions continuously create a substantial amount of data that is used for scientific research. One of the departments with a great amount of archived data is the pathology department. Pathology archives hold the potential to create a case series of valuable rare entities or large cohorts of common entities. The major problem in creation of these databases is data extraction which is still commonly done manually and is highly laborious and error prone. For these reasons, we offer using large language models to overcome these challenges. Ten pathology reports of selected resection specimens were retrieved from electronic archives of Ko & ccedil; University Hospital for the initial set. These reports were de-identified and uploaded to ChatGPT and Google Bard. Both algorithms were asked to turn the reports in a synoptic report format that is easy to export to a data editor such as Microsoft Excel or Google Sheets. Both programs created tables with Google Bard facilitating the creation of a spreadsheet from the data automatically. In conclusion, we propose the use of AI-assisted data extraction for academic research purposes, as it may enhance efficiency and precision compared to manual data entry.	[Bolat, Beyza; Gunduz-Demir, Cigdem] Koc Univ, Sch Med, Istanbul, Turkiye; [Eren, Ozgur Can; Mericoz, Cisel Aydin; Kulac, Ibrahim] Koc Univ, Sch Med, Dept Pathol, Istanbul, Turkiye; [Eren, Ozgur Can; Karasayar, A. Humeyra Dur; Kulac, Ibrahim] Koc Univ, Grad Sch Hlth Sci, Istanbul, Turkiye; [Eren, Ozgur Can] Koc Univ, Isbank Res Ctr Infect Dis, Istanbul, Turkiye; [Gunduz-Demir, Cigdem; Kulac, Ibrahim] Koc Univ, Istanbul, Turkiye; [Mericoz, Cisel Aydin; Kulac, Ibrahim] Is Bank Artificial Intelligence Ctr, Istanbul, Turkiye; [Gunduz-Demir, Cigdem] Koc Univ, Dept Comp Engn, Istanbul, Turkiye; [Kulac, Ibrahim] Koc Univ, Res Ctr Translat Med, Istanbul, Turkiye	Koc University; Koc University; Koc University; Koc University; Koc University; Koc University; Koc University	Kulac, I (corresponding author), Koc Univ, Sch Med, Dept Pathol, Istanbul, Turkiye.	ikulac@ku.edu.tr	Dur Karasayar, A. Humeyra/GQB-0964-2022	Dur Karasayar, A. Humeyra/0000-0003-3820-0430				Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Daungsupawong H, 2024, AM J CLIN PATHOL, V161, P210, DOI 10.1093/ajcp/aqad130; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	4	1	1	0	0	FEDERATION TURKISH PATHOLOGY SOC	ANKARA	YILDIZEVLER MAH RABINDRANATH TAGORE CAD 29-5 CANKAYA, ANKARA, 00000, Turkiye	1018-5615	1309-5730		TURK J PATHOL	Turk. J. Pathol.	MAY	2024	40	2					138	141		10.5146/tjpath.2024.13256	http://dx.doi.org/10.5146/tjpath.2024.13256			4	Pathology	Emerging Sources Citation Index (ESCI)	Pathology	RQ7L6	38530110	gold			2024-07-03	WOS:001229191100008
J	Gomez-Cabello, CA; Borna, S; Pressman, SM; Haider, SA; Sehgal, A; Leibovich, BC; Forte, AJ				Gomez-Cabello, Cesar A.; Borna, Sahar; Pressman, Sophia M.; Haider, Syed Ali; Sehgal, Ajai; Leibovich, Bradley C.; Forte, Antonio J.			Artificial Intelligence in Postoperative Care: Assessing Large Language Models for Patient Recommendations in Plastic Surgery	HEALTHCARE			English	Article						large language models; artificial intelligence; plastic surgery; postoperative care; patient resource; patient-centered outcomes; patient satisfaction	READABILITY; TOOL	Since their release, the medical community has been actively exploring large language models' (LLMs) capabilities, which show promise in providing accurate medical knowledge. One potential application is as a patient resource. This study analyzes and compares the ability of the currently available LLMs, ChatGPT-3.5, GPT-4, and Gemini, to provide postoperative care recommendations to plastic surgery patients. We presented each model with 32 questions addressing common patient concerns after surgical cosmetic procedures and evaluated the medical accuracy, readability, understandability, and actionability of the models' responses. The three LLMs provided equally accurate information, with GPT-3.5 averaging the highest on the Likert scale (LS) (4.18 +/- 0.93) (p = 0.849), while Gemini provided significantly more readable (p = 0.001) and understandable responses (p = 0.014; p = 0.001). There was no difference in the actionability of the models' responses (p = 0.830). Although LLMs have shown their potential as adjunctive tools in postoperative patient care, further refinement and research are imperative to enable their evolution into comprehensive standalone resources.	[Gomez-Cabello, Cesar A.; Borna, Sahar; Pressman, Sophia M.; Haider, Syed Ali; Forte, Antonio J.] Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA; [Sehgal, Ajai; Leibovich, Bradley C.; Forte, Antonio J.] Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA; [Leibovich, Bradley C.] Mayo Clin, Dept Urol, Rochester, MN 55905 USA	Mayo Clinic; Mayo Clinic; Mayo Clinic	Forte, AJ (corresponding author), Mayo Clin, Div Plast Surg, Jacksonville, FL 32224 USA.; Forte, AJ (corresponding author), Mayo Clin, Ctr Digital Hlth, Rochester, MN 55905 USA.	forte.antonio@mayo.edu	Forte, Antonio/I-2970-2019	Forte, Antonio/0000-0003-2004-7538; Gomez Cabello, Cesar Abraham/0009-0008-0603-3192; Pressman, Sophia/0009-0000-0398-8024; Borna, Sahar/0000-0002-7845-7356; Haider, Syed Ali/0009-0007-5621-2861				Abi-Rafeh J, 2024, AESTHET SURG J, DOI 10.1093/asj/sjae025; Al-Sharif Eman M, 2024, Ophthalmic Plast Reconstr Surg, V40, P303, DOI 10.1097/IOP.0000000000002567; Aliyeva A, 2024, CUREUS J MED SCIENCE, V16, DOI 10.7759/cureus.53897; American Society of Plastic Surgeons, What Are the Risks of Breast Lift Surgery?; American Society of Plastic Surgeons, What are the Risks of Eyelid Surgery?; American Society of Plastic Surgeons, What Are the Risks of Tummy Tuck Surgery?; American Society of Plastic Surgeons, What Are the Risks of Liposuction?; [Anonymous], 2020, Flesch reading ease and the flesch kincaid grade level; [Anonymous], 2018, AM SOC PLASTIC SURGE; Atkinson CJ, 2024, J CLIN MED, V13, DOI 10.3390/jcm13030900; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Barton N, 2020, PRS-GLOB OPEN, V8, DOI 10.1097/GOX.0000000000002856; BioRender, ABOUT US; Chen AD, 2019, PLAST RECONSTR SURG, V144, P773, DOI 10.1097/PRS.0000000000005988; Clusmann J, 2023, COMMUN MED-LONDON, V3, DOI 10.1038/s43856-023-00370-1; Cox A, 2023, AESTHET SURG J, V43, pNP658, DOI 10.1093/asj/sjad096; Dias P, 2022, J CLIN MED, V11, DOI 10.3390/jcm11071895; Fanning JE, 2023, PRS-GLOB OPEN, V11, DOI 10.1097/GOX.0000000000004787; Gupta R, 2023, AESTHET SURG J, V43, pNP587, DOI 10.1093/asj/sjad042; Hadi M.U., 2023, TechRxiv, DOI [10.36227/techrxiv.23589741.v4, DOI 10.36227/TECHRXIV.23589741.V4]; Humar P, 2023, AESTHET SURG J, V43, pNP1085, DOI 10.1093/asj/sjad130; Janis J.E., 2022, Essentials of Plastic Surgery, V3rd ed.; Leslie D, 2021, BMJ-BRIT MED J, V372, DOI 10.1136/bmj.n304; Momenaei B, 2023, OPHTHALMOL RETINA, V7, P862, DOI 10.1016/j.oret.2023.05.022; Nahai F., 2020, The Art of Aesthetic Surgery: Principles Techniques, V3rd, DOI [10.1055/b000000333, DOI 10.1055/B000000333]; Pan WJ, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.630268; Pressman SM, 2024, HEALTHCARE-BASEL, V12, DOI 10.3390/healthcare12080825; PUTTERMAN AM, 1990, OPHTHALMIC SURG LAS, V21, P15; Ricci JA, 2015, PLAST RECONSTR SURG, V135, P1573, DOI 10.1097/PRS.0000000000001230; Rooney MK, 2021, J PATIENT EXPERIENCE, V8, DOI 10.1177/2374373521998847; Seth I, 2023, AESTHET SURG J, V43, P1126, DOI 10.1093/asj/sjad140; Shoemaker SJ, 2014, PATIENT EDUC COUNS, V96, P395, DOI 10.1016/j.pec.2014.05.027; Soto-Galindo GA, 2023, FACIAL PLAST SURG, DOI 10.1055/a-2218-6984; Vallurupalli M, 2024, PRS-GLOB OPEN, V12, DOI 10.1097/GOX.0000000000005575; Weis B., 2003, Health literacy: a manual for clinicians; Yun JY, 2023, INT J MED INFORM, V179, DOI 10.1016/j.ijmedinf.2023.105219; Zaidi D, 2023, SOUTH MED J, V116, P62, DOI 10.14423/SMJ.0000000000001489	37	0	0	2	2	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9032		HEALTHCARE-BASEL	Healthcare	JUN	2024	12	11							1083	10.3390/healthcare12111083	http://dx.doi.org/10.3390/healthcare12111083			13	Health Care Sciences & Services; Health Policy & Services	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Health Care Sciences & Services	UA9F7	38891158	gold			2024-07-03	WOS:001245452400001
C	Chen, YY; Fu, Q; Yuan, YC; Wen, ZH; Fan, G; Liu, DYH; Zhang, DM; Li, ZX; Xiao, YH			ACM	Chen, Yuyan; Fu, Qiang; Yuan, Yichen; Wen, Zhihao; Fan, Ge; Liu, Dayiheng; Zhang, Dongmei; Li, Zhixu; Xiao, Yanghua			Hallucination Detection: Robustly Discerning Reliable Answers in Large Language Models	PROCEEDINGS OF THE 32ND ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, CIKM 2023			English	Proceedings Paper	32nd ACM International Conference on Information and Knowledge Management (CIKM)	OCT 21-25, 2023	Birmingham, ENGLAND	Assoc Comp Machinery, ACM Special Interest Grp Informat Retrieval, ACM SIGWEB		Hallucination Detection; Large Language Models; Reliable Answers		Large Language Models (LLMs) have gained widespread adoption in various natural language processing tasks, including question answering and dialogue systems. However, a major drawback of LLMs is the issue of hallucination, where they generate unfaithful or inconsistent content that deviates from the input source, leading to severe consequences. In this paper, we propose a robust discriminator named RelD to effectively detect hallucination in LLMs' generated answers. RelD is trained on the constructed RelQA, a bilingual question-answering dialogue dataset along with answers generated by LLMs and a comprehensive set of metrics. Our experimental results demonstrate that the proposed RelD successfully detects hallucination in the answers generated by diverse LLMs. Moreover, it performs well in distinguishing hallucination in LLMs' generated answers from both in-distribution and out-of-distribution datasets. Additionally, we also conduct a thorough analysis of the types of hallucinations that occur and present valuable insights. This research significantly contributes to the detection of reliable answers generated by LLMs and holds noteworthy implications for mitigating hallucination in the future work.	[Chen, Yuyan; Li, Zhixu] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Shanghai, Peoples R China; [Fu, Qiang; Zhang, Dongmei] Microsoft, Beijing, Peoples R China; [Yuan, Yichen] Shanghai Key Lab Data Sci, Shanghai, Peoples R China; [Wen, Zhihao] Singapore Management Univ, Singapore, Singapore; [Fan, Ge] Tencent, Shenzhen, Peoples R China; [Liu, Dayiheng] DAMO Acad, Hangzhou, Peoples R China; [Xiao, Yanghua] Fudan Univ, Sch Comp Sci, Shanghai Key Lab Data Sci, Fudan Aishu Cognit Intelligence Joint Res, Shanghai, Peoples R China	Fudan University; Singapore Management University; Tencent; Fudan University	Fu, Q (corresponding author), Microsoft, Beijing, Peoples R China.	chenyuyan21@m.fudan.edu.cn; qifu@microsoft.com; axclbkj@gmail.com; zhwen.2019@phdcs.smu.edu.sg; ge.fan@outlook.com; liudayiheng.ldyh@alibaba-inc.com; dongmeiz@microsoft.com; zhixuli@fudan.edu.cn; shawyh@fudan.edu.cn	Fan, Ge/GXM-8675-2022	Fan, Ge/0000-0001-5653-1626; Wen, Zhihao/0000-0002-7688-5381; Zhang, Dongmei/0000-0002-9230-2799; Fu, Qiang/0000-0002-5821-7267; li, zhixu/0000-0003-2355-288X	Shanghai Municipal Science and Technology Major Project [2021SHZDZX0103]; Science and Technology Commission of Shanghai Municipality Grant [22511105902]; National Key Research and Development Project [2020AAA0109302]; National Natural Science Foundation of China [62072323]; Shanghai Science and Technology Innovation Action Plan [22511105902, 22511104700]; Science and Technology Commission of Shanghai Municipality [22511105902]	Shanghai Municipal Science and Technology Major Project; Science and Technology Commission of Shanghai Municipality Grant(Science & Technology Commission of Shanghai Municipality (STCSM)); National Key Research and Development Project; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shanghai Science and Technology Innovation Action Plan; Science and Technology Commission of Shanghai Municipality(Science & Technology Commission of Shanghai Municipality (STCSM))	Some of computational resource are partially supported by Shanghai Municipal Science and Technology Major Project (No.2021SHZDZX0103), Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902), National Key Research and Development Project (No.2020AAA0109302), National Natural Science Foundation of China (No.62072323), Shanghai Science and Technology Innovation Action Plan (No. 22511104700, 22511105902), Shanghai Municipal Science and Technology Major Project (No.2021SHZDZX0103), and Science and Technology Commission of Shanghai Municipality Grant (No. 22511105902).	Aiyappa R, 2023, Arxiv, DOI [arXiv:2303.12767, DOI 10.48550/ARXIV.2303.12767]; Azaria A, 2023, Arxiv, DOI arXiv:2304.13734; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bengio S, 2015, ADV NEUR IN, V28; BenWang Aran, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chalmers DJ, 2023, Arxiv, DOI [arXiv:2303.07103, DOI 10.48550/ARXIV.2303.07103, 10.48550/arXiv.2303.07103]; Chen SH, 2021, Arxiv, DOI arXiv:2104.09061; Chen Yongcong, Apreliminary STUDY ON THE CAPABILITY BOUNDARY OF LLM AND A NEW IMPLEMENTATION APPROACH FOR AGI; Chia-Wei Liu, 2016, arXiv; Chiang CH, 2023, Arxiv, DOI arXiv:2305.01937; Choi E, 2018, Arxiv, DOI arXiv:1808.07036; Clark K, 2020, Arxiv, DOI arXiv:2003.10555; Dale David, 2022, arXiv; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dhingra B, 2019, Arxiv, DOI [arXiv:1906.01081, DOI 10.48550/ARXIV.1906.01081]; Durmus E, 2020, Arxiv, DOI arXiv:2005.03754; Dziri N, 2022, Arxiv, DOI [arXiv:2105.00071, 10.1162/tacl_a_00506]; Falke T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2214; Filippova K, 2020, Arxiv, DOI arXiv:2010.05873; Goyal T, 2020, Arxiv, DOI arXiv:2010.05478; Guan J, 2020, Arxiv, DOI arXiv:2009.07602; He P., 2020, arXiv, DOI 10.48550/arXiv.2006.03654; He TX, 2021, Arxiv, DOI arXiv:1905.10617; He W, 2018, Arxiv, DOI arXiv:1711.05073; Honovich O, 2021, Arxiv, DOI arXiv:2104.08202; Huang YC, 2021, Arxiv, DOI arXiv:2104.14839; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang PL, 2023, Arxiv, DOI arXiv:2305.11473; Joshi M, 2017, Arxiv, DOI arXiv:1705.03551; Khoury R, 2023, Arxiv, DOI arXiv:2304.09655; Koay Jia Jin, 2021, arXiv; Laban P, 2022, T ASSOC COMPUT LING, V10, P163, DOI 10.1162/tacl_a_00453; Lee N., 2022, Advances in Neural Information Processing Systems, V35, P34586; Li J., 2023, arXiv; Li JW, 2016, Arxiv, DOI arXiv:1510.03055; Li JY, 2023, Arxiv, DOI arXiv:2305.11747; Li YF, 2023, Arxiv, DOI arXiv:2305.10355; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu HM, 2023, Arxiv, DOI [arXiv:2304.03439, DOI 10.48550/ARXIV.2304.03439]; Liu TY, 2022, Arxiv, DOI arXiv:2104.08704; Liu YH, 2023, Arxiv, DOI [arXiv:2304.01852, DOI 10.48550/ARXIV.2304.01852, 10.1016/j.metrad.2023.100017]; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Longpre S, 2022, Arxiv, DOI arXiv:2109.05052; Madotto A, 2020, Arxiv, DOI arXiv:2008.06239; Nguyen Tri, 2016, choice, V2640, P660; Nie F, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2673; Omar Reham, 2023, ChatGPT versus Traditional Question Answering for Knowledge Graphs: Current Status and Future Directions Towards Knowledge Graph Chatbots, DOI DOI 10.48550/ARXIV.2302.06466; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pagnoni A, 2021, Arxiv, DOI arXiv:2104.13346; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Park Hyun Jin., 2023, Query Augmentation Using Search Engine Results to Improve Answers Generated by Large Language Models; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Rajpurkar P, 2016, Arxiv, DOI arXiv:1606.05250; Ranzato M, 2016, Arxiv, DOI [arXiv:1511.06732, 10.48550/arXiv.1511.06732]; Rebuffel Clement, 2021, arXiv; Reddy S, 2019, T ASSOC COMPUT LING, V7, P249, DOI 10.1162/tacl_a_00266; Roberts A, 2020, Arxiv, DOI arXiv:2002.08910; Roller S, 2020, Arxiv, DOI arXiv:2004.13637; Santhanam S, 2022, Arxiv, DOI arXiv:2110.05456; Scialom T, 2021, Arxiv, DOI arXiv:2103.12693; Shen XY, 2023, Arxiv, DOI arXiv:2304.08979; Shuster K, 2021, arXiv, DOI DOI 10.48550/ARXIV.2104.07567; Su H, 2020, Arxiv, DOI arXiv:2005.04346; Tian R, 2020, Arxiv, DOI arXiv:1910.08684; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Trischler A, 2017, Arxiv, DOI arXiv:1611.09830; Wang AL, 2020, Arxiv, DOI arXiv:2004.04228; Wang ZY, 2020, Arxiv, DOI arXiv:2005.00969; Williams A, 2018, Arxiv, DOI arXiv:1704.05426; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Yan TQ, 2023, Arxiv, DOI arXiv:2305.04039; Yang ZL, 2018, Arxiv, DOI arXiv:1809.09600; Ye WT, 2023, Arxiv, DOI [arXiv:2305.10235, 10.48550/ARXIV.2305.10235]; Zhang TY, 2020, Arxiv, DOI [arXiv:1904.09675, 10.48550/arXiv.1904.09675, DOI 10.48550/ARXIV.1904.09675]; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhou CT, 2021, Arxiv, DOI arXiv:2011.02593	79	1	1	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0124-5				2023							245	255		10.1145/3583780.3614905	http://dx.doi.org/10.1145/3583780.3614905			11	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IO		Green Published			2024-07-03	WOS:001161549500027
J	Qureshi, R; Shaughnessy, D; Gill, KAR; Robinson, KA; Li, TJ; Agai, E				Qureshi, Riaz; Shaughnessy, Daniel; Gill, Kayden A. R.; Robinson, Karen A.; Li, Tianjing; Agai, Eitan			Are ChatGPT and large language models "the answer" to bringing us closer to systematic review automation?	SYSTEMATIC REVIEWS			English	Review						Artificial intelligence; Large language models; Systematic review; Methodology		In this commentary, we discuss ChatGPT and our perspectives on its utility to systematic reviews (SRs) through the appropriateness and applicability of its responses to SR related prompts. The advancement of artificial intelligence (AI)-assisted technologies leave many wondering about the current capabilities, limitations, and opportunities for integration AI into scientific endeavors. Large language models (LLM)-such as ChatGPT, designed by OpenAI-have recently gained widespread attention with their ability to respond to various prompts in a natural-sounding way. Systematic reviews (SRs) utilize secondary data and often require many months and substantial financial resources to complete, making them attractive grounds for developing AI-assistive technologies. On February 6, 2023, PICO Portal developers hosted a webinar to explore ChatGPT's responses to tasks related to SR methodology. Our experience from exploring the responses of ChatGPT suggest that while ChatGPT and LLMs show some promise for aiding in SR-related tasks, the technology is in its infancy and needs much development for such applications. Furthermore, we advise that great caution should be taken by non-content experts in using these tools due to much of the output appearing, at a high level, to be valid, while much is erroneous and in need of active vetting.	[Qureshi, Riaz; Shaughnessy, Daniel; Li, Tianjing] Univ Colorado, Anschutz Med Campus, Aurora, CO 80045 USA; [Qureshi, Riaz; Gill, Kayden A. R.; Robinson, Karen A.; Li, Tianjing; Agai, Eitan] PICO Portal, New York, NY 10001 USA; [Gill, Kayden A. R.] Univ Pittsburgh, Pittsburgh, PA USA; [Robinson, Karen A.] Johns Hopkins Univ, Baltimore, MD USA	University of Colorado System; University of Colorado Anschutz Medical Campus; Pennsylvania Commonwealth System of Higher Education (PCSHE); University of Pittsburgh; Johns Hopkins University	Qureshi, R (corresponding author), Univ Colorado, Anschutz Med Campus, Aurora, CO 80045 USA.; Qureshi, R (corresponding author), PICO Portal, New York, NY 10001 USA.	riaz.qureshi@cuanschutz.edu		Li, Tianjing/0000-0001-5371-4558; Shaughnessy, Daniel/0000-0001-7248-4882; Gill, Kayden/0000-0002-6790-1001				Borah R, 2017, BMJ OPEN, V7, DOI 10.1136/bmjopen-2016-012545; Bullers K, 2018, J MED LIBR ASSOC, V106, P198, DOI 10.5195/jmla.2018.323; Chen R, 2023, GPT 4; Covidence, 2023, COV BETT SYST REV MA; DistillerSR, 2023, DISTILLERSR SMART RE; Drenik G., 2023, Forbes; ICASR, 2023, ABOUT US; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lewis Patrick, 2020, P 3 CLIN NATURAL LAN, P146, DOI 10.18653/v1/2020.clinicalnlp-1.17; Mahesh B., 2019, Machine Learning Algorithms -A Review, DOI DOI 10.21275/ART20203995; Michelson M, 2019, CONT CLIN TRIAL COMM, V16, DOI 10.1016/j.conctc.2019.100443; OpenAI, 2023, ChatGPT: optimizing language models for dialogue; PICO Portal, 2023, INTR PICO PORT; Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451; Rayyan, 2023, RAYYAN INT SYST REV; RobotReviewer, 2023, ROBOTREVIEWER AUT EV; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Smerdon D., 2023, DSMERDON; Staiman A., GUEST POST ACAD PUBL; Wiggers K., 2022, TechCrunch	20	35	36	67	134	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND		2046-4053		SYST REV-LONDON	Syst. Rev.	APR 29	2023	12	1							72	10.1186/s13643-023-02243-z	http://dx.doi.org/10.1186/s13643-023-02243-z			4	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	F2DO5	37120563	Green Published, gold			2024-07-03	WOS:000980504800001
J	Romera-Paredes, B; Barekatain, M; Novikov, A; Balog, M; Kumar, MP; Dupont, E; Ruiz, FJR; Ellenberg, JS; Wang, PM; Fawzi, O; Kohli, P; Fawzi, A				Romera-Paredes, Bernardino; Barekatain, Mohammadamin; Novikov, Alexander; Balog, Matej; Kumar, M. Pawan; Dupont, Emilien; Ruiz, Francisco J. R.; Ellenberg, Jordan S.; Wang, Pengming; Fawzi, Omar; Kohli, Pushmeet; Fawzi, Alhussein			Mathematical discoveries from program search with large language models	NATURE			English	Article							ONLINE BIN-PACKING; HEURISTICS; ALGORITHMS	Large language models (LLMs) have demonstrated tremendous capabilities in solving complex tasks, from quantitative reasoning to understanding natural language. However, LLMs sometimes suffer from confabulations (or hallucinations), which can result in them making plausible but incorrect statements1,2. This hinders the use of current large models in scientific discovery. Here we introduce FunSearch (short for searching in the function space), an evolutionary procedure based on pairing a pretrained LLM with a systematic evaluator. We demonstrate the effectiveness of this approach to surpass the best-known results in important problems, pushing the boundary of existing LLM-based approaches3. Applying FunSearch to a central problem in extremal combinatorics-the cap set problem-we discover new constructions of large cap sets going beyond the best-known ones, both in finite dimensional and asymptotic cases. This shows that it is possible to make discoveries for established open problems using LLMs. We showcase the generality of FunSearch by applying it to an algorithmic problem, online bin packing, finding new heuristics that improve on widely used baselines. In contrast to most computer search approaches, FunSearch searches for programs that describe how to solve a problem, rather than what the solution is. Beyond being an effective and scalable strategy, discovered programs tend to be more interpretable than raw solutions, enabling feedback loops between domain experts and FunSearch, and the deployment of such programs in real-world applications. FunSearch makes discoveries in established open problems using large language models by searching for programs describing how to solve a problem, rather than what the solution is.	[Romera-Paredes, Bernardino; Barekatain, Mohammadamin; Novikov, Alexander; Balog, Matej; Kumar, M. Pawan; Dupont, Emilien; Ruiz, Francisco J. R.; Wang, Pengming; Kohli, Pushmeet; Fawzi, Alhussein] Google DeepMind, London, England; [Ellenberg, Jordan S.] Univ Wisconsin Madison, Dept Math, Madison, WI USA; [Fawzi, Omar] Univ Lyon, Lab Informat Parallelisme, ENS Lyon, UCBL,Inria,LIP, Lyon, France	Google Incorporated; University of Wisconsin System; University of Wisconsin Madison; Ecole Normale Superieure de Lyon (ENS de LYON); Universite Claude Bernard Lyon 1; Inria	Romera-Paredes, B; Kohli, P; Fawzi, A (corresponding author), Google DeepMind, London, England.	brp@google.com; pushmeet@google.com; afawzi@google.com		Romera-Paredes, Bernardino/0000-0003-3604-3590; Wang, Pengming/0009-0009-4976-4267; Barekatain, Mohammadamin/0000-0002-8470-8203; RODRIGUEZ RUIZ, FRANCISCO JESUS/0000-0002-2200-901X; Balog, Matej/0000-0002-5552-9855				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Anil R, 2023, Arxiv, DOI arXiv:2305.10403; [Anonymous], 2023, Code models overview; [Anonymous], 2005, Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques, DOI DOI 10.1007/0-387-28356-0_17; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Balogh J., 2018, PROC 26 ANN EUROPEAN, V5, P1; Balogh J., 2014, PROC 26 ANN ACM SIAM, P1425; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Banzhaf Wolfgang, 1998, GENETIC PROGRAMMING, V1; BEASLEY JE, 1990, J OPER RES SOC, V41, P1069, DOI 10.2307/2582903; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Bunel R., 2017, PROC INT C LEARNING; Burke E, 2003, HDB METAHEURISTICS, P2003, DOI DOI 10.1007/0-306-48056-5_16; Burke EK, 2006, LECT NOTES COMPUT SC, V4193, P860; Burke EK, 2007, IEEE C EVOL COMPUTAT, P2530, DOI 10.1109/CEC.2007.4424789; Burke EK, 2010, IEEE C EVOL COMPUTAT; Burke EK, 2013, J OPER RES SOC, V64, P1695, DOI 10.1057/jors.2013.71; Burke EK, 2007, GECCO 2007: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P1559; Calderbank A. R., 1994, Designs, Codes and Cryptography, V4, P203, DOI 10.1007/BF01388452; Cameron P.J., 1991, London Mathematical Society Student Texts, V3; Cantu-Paz E., 1998, Calculateurs paralleles, reseaux et systems repartis, V10, P141; Castineiras Ignacio, 2012, Principles and Practice of Constraint Programming. Proceedings 18th International Conference, CP 2012, P207, DOI 10.1007/978-3-642-33558-7_17; CHAITIN GJ, 1966, J ACM, V13, P547, DOI 10.1145/321356.321363; Chen AELC, 2023, Arxiv, DOI arXiv:2302.14838; Chen M., 2021, arXiv; Chen XN, 2023, Arxiv, DOI [arXiv:2302.06675, 10.48550/ARXIV.2302.06675]; Chen XY, 2023, Arxiv, DOI arXiv:2304.05128; Coffman E. G., 1984, Algorithm Design for Computer System Design, P49; Coffman EG., 2013, Handbook of Combinatorial Optimization, P455, DOI [10.1007/978-1-4419-7997-135, DOI 10.1007/978-1-4419-7997-135]; Croot E, 2017, ANN MATH, V185, P331, DOI 10.4007/annals.2017.185.1.7; DELAMAZA M, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P124; Edel Y, 2004, DESIGN CODE CRYPTOGR, V31, P5, DOI 10.1023/A:1027365901231; Edel Y, 2001, DESIGN CODE CRYPTOGR, V23, P197, DOI 10.1023/A:1011216716700; Ellenberg JS, 2017, ANN MATH, V185, P339, DOI 10.4007/annals.2017.185.1.8; Fawzi A, 2022, NATURE, V610, P47, DOI 10.1038/s41586-022-05172-4; Fried D., 2022, PROC INT C LEARNING; Goldberg D.E., 1989, Genetic Algorithms in Search, Optimization and Machine Learning, V1st ed.; Grochow JA, 2019, B AM MATH SOC, V56, P29, DOI 10.1090/bull/1648; Haluptzok P., 2023, INT C LEARNING REPRE; Helmuth T, 2015, IEEE T EVOLUT COMPUT, V19, P630, DOI 10.1109/TEVC.2014.2362729; HILL R, 1973, ATTI ACCAD NAZ LIN, V54, P378; Hutter M, 2006, IEEE T EVOLUT COMPUT, V10, P568, DOI 10.1109/TEVC.2005.863127; Jiang A.Q., 2022, Advances in Neural Information Processing Systems, V35, P8360; Koza J., 1994, Genetic programming II; KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355; Langdon WB, 2013, Foundations of Genetic Programming; LEE CC, 1985, J ACM, V32, P562, DOI 10.1145/3828.3833; Lehman J., 2023, Handbook of Evolutionary Machine Learning, P331, DOI 10.1007/978-981-99-3814-8-11; Li M., 2008, An Introduction to Kolmogorov Complexity and Its Applications; Li RY, 2023, Arxiv, DOI arXiv:2305.06161; Li YJ, 2022, SCIENCE, V378, P1092, DOI 10.1126/science.abq1158; Liventsev V, 2023, Arxiv, DOI arXiv:2304.10423; Ma H, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abq0279; Mankowitz DJ, 2023, NATURE, V618, P257, DOI 10.1038/s41586-023-06004-9; MARTELLO S, 1990, DISCRETE APPL MATH, V28, P59, DOI 10.1016/0166-218X(90)90094-S; Meyerson E, 2024, Arxiv, DOI [arXiv:2302.12170, 10.48550/arXiv.2302.12170, DOI 10.48550/ARXIV.2302.12170]; Millidge B., 2023, Beren's Blog; Mouret JB, 2009, IEEE C EVOL COMPUTAT, P1161, DOI 10.1109/CEC.2009.4983077; Nasir MU, 2024, Arxiv, DOI arXiv:2306.01102; Naslund E, 2017, FORUM MATH SIGMA, V5, DOI 10.1017/fms.2017.12; Ni A., 2023, INT C MACHINE LEARNI, P26106; Nijkamp E., 2022, PROC INT C LEARNING; Nye M., 2022, DEEP LEARNING CODE W; O'Neill M, 2010, GENET PROGRAM EVOL M, V11, P339, DOI 10.1007/s10710-010-9113-2; Park J. S., 2023, PROC 36 ANN ACM S US, P1; Polu S, 2023, INT C LEARNING REPRE; Polu S, 2020, Arxiv, DOI arXiv:2009.03393; Pugh JK, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00040; RAMANAN P, 1989, J ALGORITHM, V10, P305, DOI 10.1016/0196-6774(89)90031-X; Salustowicz R, 1997, EVOL COMPUT, V5, P123, DOI 10.1162/evco.1997.5.2.123; Schick T., 2023, arXiv; Schkufza E, 2013, ACM SIGPLAN NOTICES, V48, P305, DOI 10.1145/2499368.2451150; Schmidt M, 2009, SCIENCE, V324, P81, DOI 10.1126/science.1165893; Seiden SS, 2002, J ACM, V49, P640, DOI 10.1145/585265.585269; Shypula A., 2022, PROC DEEP LEARNING C; Shypula A, 2024, Arxiv, DOI arXiv:2302.07867; SOLOMONOFF RJ, 1964, INFORM CONTROL, V7, P1, DOI 10.1016/S0019-9958(64)90223-2; Tanese R., 1989, Distributed Genetic Algorithms for Function Optimization; Tao T., 2009, WordPress Blog; Tao VT, 2006, CAM ST AD M, V105, P1, DOI 10.1017/CBO9780511755149; Tyrrell F, 2023, DISCRETE ANAL, DOI 10.19086/da.91076; Wang GZ, 2023, Arxiv, DOI arXiv:2305.16291; Wu J., 2021, arXiv; Yang F., 2021, arXiv; Yao S., 2023, PROC INT C LEARNING; Yin P., 2022, arXiv; Zelikman E, 2023, Arxiv, DOI arXiv:2212.10561; Zelikman Eric, 2022, Advances in Neural Information Processing Systems, V35, P15476; Zheng MK, 2023, Arxiv, DOI arXiv:2304.10970; Zhou S., 2022, PROC INT C LEARNING	90	8	8	51	51	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	JAN 18	2024	625	7995								10.1038/s41586-023-06924-6	http://dx.doi.org/10.1038/s41586-023-06924-6			14	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	HC4Q2	38096900	Green Published, hybrid			2024-07-03	WOS:001157281900001
J	Prillaman, M				Prillaman, Mckenzie			Is ChatGPT making scientists hyper-productive? The highs and lows of using AI	NATURE			English	News Item						Machine learning; Scientific community; Publishing; Computer science		Large language models are transforming scientific writing and publishing. But the productivity boost that these tools bring could have a downside.										ERC, 2023, Foresight: Use and Impact of Artificial Intelligence in the Scientific Process; Ganjavi C, 2024, BMJ-BRIT MED J, V384, DOI 10.1136/bmj-2023-077192	2	3	3	81	81	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	0028-0836	1476-4687		NATURE	Nature	MAR 7	2024	627	8002					16	17		10.1038/d41586-024-00592-w	http://dx.doi.org/10.1038/d41586-024-00592-w			2	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	LA3N2	38418736				2024-07-03	WOS:001184015000008
C	Li, HN; Hao, Y; Zhai, YZ; Qian, ZY		Chandra, S; Blincoe, K; Tonella, P		Li, Haonan; Hao, Yu; Zhai, Yizhuo; Qian, Zhiyun			Assisting Static Analysis with Large Language Models: A ChatGPT Experiment	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		static analysis; bug detection; large language model		Recent advances of Large Language Model s (LLMs), e.g., ChatGPT, exhibited strong capabilities of comprehending and responding to questions across a variety of domains. Surprisingly, ChatGPT even possesses a strong understanding of program code. In this paper, we investigate where and how LLMs can assist static analysis by asking appropriate questions. In particular, we target a specific bug-finding tool, which produces many false positives from the static analysis. In our evaluation, we find that these false positives can be effectively pruned by asking carefully constructed questions about function-level behaviors or function summaries. Specifically, with a pilot study of 20 false positives, we can successfully prune 8 out of 20 based on GPT-3.5, whereas GPT-4 had a near-perfect result of 16 out of 20, where the four failed ones are not currently considered/supported by our questions, e.g., involving concurrency. Additionally, it also identified one false negative case (a missed bug). We find LLMs a promising tool that can enable a more effective and efficient program analysis.	[Li, Haonan; Hao, Yu; Zhai, Yizhuo; Qian, Zhiyun] UC Riverside, Riverside, CA 92521 USA	University of California System; University of California Riverside	Li, HN (corresponding author), UC Riverside, Riverside, CA 92521 USA.	hli333@ucr.edu; yhao016@ucr.edu; yzhai003@ucr.edu; zhiyunq@cs.ucr.edu	, lqhldez/AAZ-8044-2020; Hao, Yu/JDD-2851-2023	Hao, Yu/0000-0002-3944-3162; Li, Haonan/0000-0003-0357-0888				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; [Anonymous], 1997, Object-oriented software construction; Bessey A, 2010, COMMUN ACM, V53, P66, DOI 10.1145/1646353.1646374; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen JH, 2023, Arxiv, DOI arXiv:2304.03262; Clang, 2023, Clang Language Extensions; Johnson B, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P672, DOI 10.1109/ICSE.2013.6606613; Lemieux Caroline, 2023, CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pre-trained Large Language Models; Li H, 2023, arXiv; Lyu Q, 2023, Arxiv, DOI [arXiv:2301.13379, 10.48550/arXiv.2301.13379]; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Park J, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3464457; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Schulman John, 2022, Chatgpt: Optimizing language models for dialogue; Shieh J., 2023, Best practices for prompt engineering with openai API; Vaswani A, 2017, ADV NEUR IN, V30; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; XuezhiWang JasonWei, 2023, 11 INT C LEARN REPR; Zhai YZ, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P221, DOI 10.1145/3368089.3409686; Zhai Yizhuo, 2022, 29 ANN NETW DISTR SY; Zhang H, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P811, DOI 10.1145/3460120.3484798; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	23	0	0	14	14	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							2107	2111		10.1145/3611643.3613078	http://dx.doi.org/10.1145/3611643.3613078			5	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		hybrid			2024-07-03	WOS:001148157800180
J	de Curto, J; de Zarza, I; Calafate, CT				de Curto, J.; de Zarza, I.; Calafate, Carlos T.			Semantic Scene Understanding with Large Language Models on Unmanned Aerial Vehicles	DRONES			English	Article						scene understanding; large language models; visual language models; CLIP; GPT-3; YOLOv7; UAV	READABILITY FORMULA	Unmanned Aerial Vehicles (UAVs) are able to provide instantaneous visual cues and a high-level data throughput that could be further leveraged to address complex tasks, such as semantically rich scene understanding. In this work, we built on the use of Large Language Models (LLMs) and Visual Language Models (VLMs), together with a state-of-the-art detection pipeline, to provide thorough zero-shot UAV scene literary text descriptions. The generated texts achieve a GUNNING Fog median grade level in the range of 7-12. Applications of this framework could be found in the filming industry and could enhance user experience in theme parks or in the advertisement sector. We demonstrate a low-cost highly efficient state-of-the-art practical implementation of microdrones in a well-controlled and challenging setting, in addition to proposing the use of standardized readability metrics to assess LLM-enhanced descriptions.	[de Curto, J.; de Zarza, I.] Ctr Intelligent Multidimens Data Anal, HK Sci Pk, Shatin, Hong Kong, Peoples R China; [de Curto, J.; de Zarza, I.; Calafate, Carlos T.] Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain; [de Curto, J.; de Zarza, I.] GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany; [de Curto, J.; de Zarza, I.] Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomun, Barcelona 08018, Spain	Universitat Politecnica de Valencia; Goethe University Frankfurt; UOC Universitat Oberta de Catalunya	de Curto, J (corresponding author), Ctr Intelligent Multidimens Data Anal, HK Sci Pk, Shatin, Hong Kong, Peoples R China.; de Curto, J (corresponding author), Univ Politecn Valencia, Dept Informat Sistemas & Comp, Valencia 46022, Spain.; de Curto, J (corresponding author), GOETHE Univ Frankfurt Main, Informat & Math, D-60323 Frankfurt, Germany.; de Curto, J (corresponding author), Univ Oberta Catalunya, Estudis Informat Multimedia & Telecomun, Barcelona 08018, Spain.	decurto@em.uni-frankfurt.de	Calafate, Carlos Tavares/A-4215-2009	Calafate, Carlos Tavares/0000-0001-5729-3041; de Curto y Diaz, J./0000-0002-8334-4719; de Zarza i Cubero, I./0000-0002-5844-7871	HK Innovation and Technology Commission (InnoHK Project CIMDA); Universitat Politecnica de Valencia; ERDF [PID2021-122580NB-I00, MCIN/AEI/10.13039/501100011033]	HK Innovation and Technology Commission (InnoHK Project CIMDA); Universitat Politecnica de Valencia; ERDF(European Union (EU))	This work is supported by the HK Innovation and Technology Commission (InnoHK Project CIMDA). We acknowledge the support of Universitat Politecnica de Valencia; R&D project PID2021-122580NB-I00, funded by MCIN/AEI/10.13039/501100011033 and ERDF.	Alayrac J.-B., 2022, ARXIV; Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636; Bonatti R., 2020, ARXIV201110118; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen Xinlei, 2015, arXiv; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; Cui Y., 2022, P LEARN DYN CONTR C; Dale E, 1948, EDUC RES BULL, V27, P11; Dosovitskiy A., 2020, ICLR; Fan AEL, 2018, Arxiv, DOI arXiv:1805.04833; Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754; Flesch R, 1948, J APPL PSYCHOL, V32, P221, DOI 10.1037/h0057532; Gu Xiuye, 2021, arXiv; Gunning Robert., 1952, TECHNIQUE CLEAR WRIT; Huang W., 2022, P 39 INT C MACHINE L; Li X., 2021, ARXIV; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Mokady R, 2021, ARXIV; Nair S, 2022, Arxiv, DOI arXiv:2203.12601; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radford A, 2021, PR MACH LEARN RES, V139; Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690; Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91; Sandler M., 2018, ARXIV; See A, 2019, Arxiv, DOI arXiv:1909.10705; Sharma P, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2556; Spache G, 1953, ELEM SCHOOL J, V53, P410, DOI 10.1086/458513; Tan M., 2020, ARXIV; Tan M., 2021, ARXIV; Tan M, 2019, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang C.-Y., 2022, arXiv; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Xu K, 2015, PR MACH LEARN RES, V37, P2048; Zeng A., 2022, ARXIV; Zeng AY, 2022, Arxiv, DOI arXiv:2204.00598	36	13	13	18	51	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2504-446X		DRONES-BASEL	Drones-Basel	FEB	2023	7	2							114	10.3390/drones7020114	http://dx.doi.org/10.3390/drones7020114			15	Remote Sensing	Science Citation Index Expanded (SCI-EXPANDED)	Remote Sensing	9H7KC		gold			2024-07-03	WOS:000939006200001
C	Oduro-Afriyie, J; Jamil, HM			ACM	Oduro-Afriyie, Joel; Jamil, Hasan M.			Enabling the Informed Patient Paradigm with Secure and Personalized Medical Question Answering	14TH ACM CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY, AND HEALTH INFORMATICS, BCB 2023			English	Proceedings Paper	14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics (ACM-BCB)	SEP 03-06, 2023	Houston, TX	Assoc Comp Machinery, ACM Special Interest Grp Bioinformat, Computat Biol, & Biomed Informat		knowledge graphs; large language models; semantic graph search; data integration; personal health library; informed patients		Quality patient care is a complex and multifaceted problem requiring the integration of data from multiple sources. We propose Medicient, a knowledge-graph-based question answering system that processes heterogeneous data sources, including patient health records, drug databases, and medical literature, into a unified knowledge graph with zero training. The knowledge graph is then utilized to provide personalized recommendations for treatment or medication. The system leverages the power of large language models for question understanding and natural language response generation, while hiding sensitive patient information. We compare our system to a large language model (ChatGPT), which does not have access to patient health records, and show that our system provides better recommendations. This study contributes to a growing body of research on knowledge graphs and their applications in healthcare.	[Oduro-Afriyie, Joel; Jamil, Hasan M.] Univ Idaho, Dept Comp Sci, Moscow, ID 83843 USA	Idaho; University of Idaho	Oduro-Afriyie, J (corresponding author), Univ Idaho, Dept Comp Sci, Moscow, ID 83843 USA.	odur8117@vandals.uidaho.edu; jamil@uidaho.edu		Oduro-Afriyie, Joel/0000-0001-8912-4568	Institutional Development Award (IDeA) from the National Institute of General Medical Sciences of the National Institutes of Health [P20GM103408]	Institutional Development Award (IDeA) from the National Institute of General Medical Sciences of the National Institutes of Health	This work was partially made possible by an Institutional Development Award (IDeA) from the National Institute of General Medical Sciences of the National Institutes of Health under Grant #P20GM103408.	Ammar N, 2020, EXPLAINABLE AI HEALT, P221; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Baird A., 2011, Proceedings of the 2011 iConference, P281, DOI DOI 10.1145/1940761.1940800; Bos JW, 2014, J BIOMED INFORM, V50, P234, DOI 10.1016/j.jbi.2014.04.003; Chen Xinyun, 2022, arXiv; Deng Zhenyun, 2022, INT JOINT C ART INT; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dutt Ritam, 2022, NAACL HLT; Dwork C, 2006, LECT NOTES COMPUT SC, V4052, P1; Gentile AL, 2019, LECT NOTES COMPUT SC, V11779, P400, DOI 10.1007/978-3-030-30796-7_25; Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440; Gursoy G, 2022, NAT REV GENET, V23, P245, DOI 10.1038/s41576-021-00428-7; Gyrard Amelie, 2018, CEUR WORKSH P, V2317; Jacobs W, 2017, COGENT SOC SCI, V3, DOI 10.1080/23311886.2017.1302785; Kale A, 2023, DATA INTELLIGENCE, V5, P139, DOI 10.1162/dint_a_00119; Kumar R, 2022, COMPUT MED IMAG GRAP, V102, DOI 10.1016/j.compmedimag.2022.102139; Liévin V, 2023, Arxiv, DOI arXiv:2207.08143; Lu W, 2022, Arxiv, DOI arXiv:2112.00734; Oduro-Afriyie Joel, 2023, 15 INT C FLEX QUER A; Shirai S, 2021, Arxiv, DOI [arXiv:2104.07587, DOI 10.48550/ARXIV.2104.07587]; Showell C, 2017, PEERJ, V5, DOI 10.7717/peerj.3268; Singhal K., 2022, arXiv, DOI DOI 10.48550/ARXIV.2212.13138; Vance B., 2015, BUS HLTH ADM ASS ANN, P1; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2	25	0	0	11	11	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0126-9				2023										10.1145/3584371.3613016	http://dx.doi.org/10.1145/3584371.3613016			6	Computer Science, Artificial Intelligence; Mathematical & Computational Biology; Medical Informatics	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Mathematical & Computational Biology; Medical Informatics	BW3UZ		Bronze			2024-07-03	WOS:001143941200033
C	Arulmohan, S; Meurs, MJ; Mosser, S			IEEE	Arulmohan, Sathurshan; Meurs, Marie-Jean; Mosser, Sebastien			Extracting Domain Models from Textual Requirements in the Era of Large Language Models	2023 ACM/IEEE INTERNATIONAL CONFERENCE ON MODEL DRIVEN ENGINEERING LANGUAGES AND SYSTEMS COMPANION, MODELS-C			English	Proceedings Paper	ACM/IEEE International Conference on Model Driven Engineering Languages and Systems (MODELS)	OCT 01-06, 2023	Vasteras, SWEDEN	IEEE, Assoc Comp Machinery, IEEE Comp Soc		Domain Modeling; Natural Language Processing; Large Language Models; Concept Extraction; User stories		Requirements Engineering is a critical part of the software lifecycle, describing what a given piece of software will do (functional) and how it will do it (non-functional). Requirements documents are often textual, and it is up to software engineers to extract the relevant domain models from the text, which is an error-prone and time-consuming task. Considering the recent attention gained by Large Language Models (LLMs), we explored how they could support this task. This paper investigates how such models can be used to extract domain models from agile product backlogs and compare them to (i) a state-of-practice tool as well as (ii) a dedicated Natural Language Processing (NLP) approach, on top of a reference dataset of 22 products and 1, 679 user stories. Based on these results, this paper is a first step towards using LLMs and/or tailored NLP to support automated requirements engineering thanks to model extraction using artificial intelligence.	[Arulmohan, Sathurshan; Mosser, Sebastien] McMaster Univ, CAS, Hamilton, ON, Canada; [Arulmohan, Sathurshan; Mosser, Sebastien] McSCert, Hamilton, ON, Canada; [Meurs, Marie-Jean] Univ Quebec Montreal, CIRST, Montreal, PQ, Canada	McMaster University; University of Quebec; University of Quebec Montreal	Arulmohan, S (corresponding author), McSCert, Hamilton, ON, Canada.	arulmohs@mcmaster.ca; meurs.marie-jean@uqam.ca; mossers@mcmaster.ca			Natural Sciences and Engineering Research Council of Canada (NSERC); McMaster's Faculty of Engineering (Excellence in Research Award)	Natural Sciences and Engineering Research Council of Canada (NSERC)(Natural Sciences and Engineering Research Council of Canada (NSERC)); McMaster's Faculty of Engineering (Excellence in Research Award)	This work is funded by the Natural Sciences and Engineering Research Council of Canada (NSERC) under the Discovery Grant (DG) program and McMaster's Faculty of Engineering (Excellence in Research Award)	Arulmohan Sathurshan, 2023, Zenodo, DOI 10.5281/ZENODO.8136975; Bajaj Deepali, 2022, International Journal of Information Technology, V14, P1543, DOI 10.1007/s41870-022-00884-2; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cohn M., 2004, User stories applied: For agile software development; Dalpiaz F., 2018, Tech. Rep.; Dalpiaz F, 2018, IEEE SOFTWARE, V35, P115, DOI 10.1109/MS.2018.3571242; Honnibal M., 2017, To appear, V7, P411, DOI DOI 10.3233/978-1-60750-588-4-1080; Korobov Mikhail, 2023, Zenodo, DOI 10.5281/ZENODO.8132729; Lafferty J, 2001, P 18 INT C MACH LEAR; Mosser Sebastien, 2023, Zenodo, DOI 10.5281/ZENODO.8132676; Mosser S, 2022, J OBJECT TECHNOL, V21, DOI 10.5381/jot.2022.21.3.a3; Mussbacher G, 2020, SOFTW SYST MODEL, V19, P1045, DOI 10.1007/s10270-020-00814-5; OpenAI, ABOUT US; Robeer M, 2016, INT REQUIR ENG CONF, P196, DOI 10.1109/RE.2016.40; Weyssow M, 2022, SOFTW SYST MODEL, V21, P1071, DOI 10.1007/s10270-022-00975-5; Zhao L, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3444689	17	0	0	11	11	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA			979-8-3503-2498-3				2023							580	587		10.1109/MODELS-C59198.2023.00096	http://dx.doi.org/10.1109/MODELS-C59198.2023.00096			8	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW3FC		Green Submitted			2024-07-03	WOS:001137051500078
J	Rossettini, G; Cook, C; Palese, A; Pillastrini, P; Turolla, A				Rossettini, Giacomo; Cook, Chad; Palese, Alvisa; Pillastrini, Paolo; Turolla, Andrea			Pros and Cons of Using Artificial Intelligence Chatbots for Musculoskeletal Rehabilitation Management	JOURNAL OF ORTHOPAEDIC & SPORTS PHYSICAL THERAPY			English	Article						artificial intelligence; ChatGPT; clinical reasoning; Google Bard; Microsoft Bing; musculoskeletal pain		SYNOPSIS: Artificial intelligence (AI), specifically large language models (LLMs), which focus on the interaction between computers and human language, can influence musculoskeletal rehabilitation management. AI chatbots (eg, ChatGPT, Microsoft Bing, and Google's Bard) are a form of large language models designed to understand, interpret, and generate text similar to what is produced by humans. Since their release, chatbots have triggered controversy in the international scientific community, including when they have passed university exams, generated credible scientific abstracts, and shown potential for replacing humans in scientific roles. The controversies extend to the field of musculoskeletal rehabilitation. In this Viewpoint, we describe the potential applications and limitations, and recommended actions for education, clinical practice, and research when using AI chatbots for musculoskeletal rehabilitation management, aspects that may have similar implications for the broader health care community.	[Rossettini, Giacomo] Univ Verona, Sch Physiotherapy, Verona, Italy; [Cook, Chad] Duke Univ, Duke Ctr Excellence Manual & Manipulat Therapy, Durham, NC USA; [Cook, Chad] Duke Univ, Doctor Phys Therapy Program, Durham, NC USA; [Cook, Chad] Duke Univ, Dept Orthopaed, Durham, NC USA; [Palese, Alvisa] Univ Udine, Sch Nursing, Dept Med DAME, Udine, Italy; [Pillastrini, Paolo; Turolla, Andrea] Univ Bologna, Dept Biomed & Neuromotor Sci DIBINEM, Alma Mater Studiorum, Bologna, Italy; [Pillastrini, Paolo; Turolla, Andrea] IRCCS Azienda Osped Univ Bologna, Unit Occupat Med, Bologna, Italy	University of Verona; Duke University; Duke University; Duke University; University of Udine; University of Bologna; IRCCS Azienda Ospedaliero-Universitaria di Bologna	Rossettini, G (corresponding author), Univ Verona, Sch Physiotherapy, I-37131 Verona, VR, Italy.	giacomo.rossettini@gmail.com	Turolla, Andrea/IAR-5542-2023	Turolla, Andrea/0000-0002-1609-8060				Brainard J, 2023, SCIENCE, V379, P740, DOI 10.1126/science.adh2762; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; Else H, 2023, NATURE, V613, P423, DOI 10.1038/d41586-023-00056-7; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Owens B, 2023, NATURE, V615, P20, DOI 10.1038/d41586-023-00500-8; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Tack C, 2019, MUSCULOSKEL SCI PRAC, V39, P164, DOI 10.1016/j.msksp.2018.11.012	10	5	5	12	17	J O S P T	ALEXANDRIA	1111 NORTH FAIRFAX ST, STE 100, ALEXANDRIA, VA 22314-1436 USA	0190-6011	1938-1344		J ORTHOP SPORT PHYS	J. Orthop. Sports Phys. Ther.	DEC	2023	53	12					728	734		10.2519/jospt.2023.12000	http://dx.doi.org/10.2519/jospt.2023.12000			7	Orthopedics; Rehabilitation; Sport Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Orthopedics; Rehabilitation; Sport Sciences	IN0G5	37707390	Green Published			2024-07-03	WOS:001166882300002
J	Montanelli, L; Venugopal, V; Olivetti, EA; Latypov, MI				Montanelli, Luca; Venugopal, Vineeth; Olivetti, Elsa A.; Latypov, Marat I.			High-Throughput Extraction of Phase-Property Relationships from Literature Using Natural Language Processing and Large Language Models	INTEGRATING MATERIALS AND MANUFACTURING INNOVATION			English	Article; Early Access						Natural language processing; Large language models; Aluminum alloys; Phase-property relationship	ALUMINUM-ALLOY; CORROSION BEHAVIOR; HEAT-TREATMENT; SI ALLOYS; MICROSTRUCTURE	Consolidating published research on aluminum alloys into insights about microstructure-property relationships can simplify and reduce the costs involved in alloy design. One critical design consideration for many heat-treatable alloys deriving superior properties from precipitation are phases as key microstructure constituents because they can have a decisive impact on the engineering properties of alloys. Here, we present a computational framework for high-throughput extraction of phases and their impact on properties from scientific papers. Our framework includes transformer-based and large language models to identify sentences with phase-property information in papers, recognize phase and property entities, and extract phase-property relationships and their "sentiment." We demonstrate the application of our framework on aluminum alloys, for which we build a database of 7,675 phase-property relationships extracted from a corpus of almost 5000 full-text papers. We comment on the extracted relationships based on common metallurgical knowledge.	[Montanelli, Luca; Venugopal, Vineeth; Olivetti, Elsa A.] MIT, Dept Mat Sci & Engn, Cambridge, MA 02139 USA; [Latypov, Marat I.] Univ Arizona, Dept Mat Sci & Engn, Tucson, AZ 85721 USA	Massachusetts Institute of Technology (MIT); University of Arizona	Montanelli, L (corresponding author), MIT, Dept Mat Sci & Engn, Cambridge, MA 02139 USA.	montanel@mit.edu; vineethv@mit.edu; elsao@mit.edu; latmarat@arizona.edu		Latypov, Marat/0000-0003-4416-0877; Montanelli, Luca/0000-0002-7784-7627	Novelis; Novelis [CBET-2243914]; NSF	Novelis; Novelis; NSF(National Science Foundation (NSF))	The authors gratefully acknowledge the support from Novelis and NSF (grant CBET-2243914). We express our gratitude to Mrigi Munjal and Thorben Prein for providing a source of inspiration for the approach we used as well as important code snippets.	Al-Qutub AM, 2006, J MATER PROCESS TECH, V172, P327, DOI 10.1016/j.jmatprotec.2005.10.022; Andreatta F, 2004, ELECTROCHIM ACTA, V49, P2851, DOI 10.1016/j.electacta.2004.01.046; [Anonymous], 2022, arXiv; [Anonymous], Cohere LLM API; Arunkumar S, 2020, MATER TODAY-PROC, V33, P484, DOI 10.1016/j.matpr.2020.05.053; Basak CB, 2017, MINERAL MET MAT SER, P1139, DOI 10.1007/978-3-319-51541-0_137; Beltagy I., 2019, arXiv; BOYLE F, 2005, SERIALS LIBR, V49, P147, DOI DOI 10.1300/J123v49n03_12; Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6; Cullen JM, 2013, ENVIRON SCI TECHNOL, V47, P3057, DOI 10.1021/es304256s; Dash SS, 2023, METALS-BASEL, V13, DOI 10.3390/met13030609; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dunn A., 2022, arXiv; Gaustad G, 2011, ENVIRON SCI TECHNOL, V45, P4110, DOI 10.1021/es103508u; Ghosh R, 2018, J MATER ENG PERFORM, V27, P423, DOI 10.1007/s11665-018-3125-0; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Gupta T, 2022, NPJ COMPUT MATER, V8, DOI 10.1038/s41524-022-00784-w; Hernández FCR, 2006, J ALLOY COMPD, V426, P205, DOI 10.1016/j.jallcom.2006.09.039; Huang S, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00602-2; Jensen Z, 2021, ACS CENTRAL SCI, V7, P858, DOI 10.1021/acscentsci.1c00024; Kim E, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.127; Kim JC, 2003, MATER LETT, V57, P1689, DOI 10.1016/S0167-577X(02)01053-4; Lee JH, 2023, INT J PR ENG MAN-GT, V10, P1337, DOI 10.1007/s40684-023-00523-6; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li T, 2010, J MATER ENG PERFORM, V19, P591, DOI 10.1007/s11665-009-9506-7; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Lin C-Y, 2004, P WORKSH TEXT SUMM B, P74; Liu YL, 2021, MATER TODAY COMMUN, V26, DOI 10.1016/j.mtcomm.2021.102032; Ma JL, 2013, INT J HYDROGEN ENERG, V38, P14896, DOI 10.1016/j.ijhydene.2013.09.046; Mahdavi S, 2011, J MATER SCI, V46, P1502, DOI 10.1007/s10853-010-4954-x; Menzemer C, 1999, MATER LETT, V41, P192, DOI 10.1016/S0167-577X(99)00129-9; Mrowka G., 2010, Arch Mater Sci Eng, V12, P46; Myhr OR, 2004, ACTA MATER, V52, P4997, DOI 10.1016/j.actamat.2004.07.002; Natori K, 2017, J MATER PROCESS TECH, V240, P240, DOI 10.1016/j.jmatprotec.2016.09.022; Osório WR, 2007, ELECTROCHIM ACTA, V52, P3265, DOI 10.1016/j.electacta.2006.10.004; Pei ZR, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-022-35766-5; Pfeiffer OP, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01215-7; Raabe D, 2022, PROG MATER SCI, V128, DOI 10.1016/j.pmatsci.2022.100947; Raabe D, 2019, NATURE, V575, P64, DOI 10.1038/s41586-019-1702-5; Saevarsdottir G, 2020, JOM-US, V72, P296, DOI 10.1007/s11837-019-03918-6; Sasidhar KN, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adg7992; Schwalbe-Koda D, 2021, SCIENCE, V374, P308, DOI 10.1126/science.abh3350; Trewartha A, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100488; Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8; Usta M, 2004, METALL MATER TRANS A, V35A, P435, DOI 10.1007/s11661-004-0354-7; Wang J., 2018, Aluminum Science and Technology, P44; Wang XM, 2004, MAT SCI ENG A-STRUCT, V364, P339, DOI 10.1016/j.msea.2003.08.049; Watari T, 2021, RESOUR CONSERV RECY, V164, DOI 10.1016/j.resconrec.2020.105107; Yang HL, 2015, MATER DESIGN, V85, P823, DOI 10.1016/j.matdes.2015.07.074; Yashpal, 2017, MATER TODAY-PROC, V4, P2927, DOI 10.1016/j.matpr.2017.02.174; Young SR, 2018, J APPL PHYS, V123, DOI 10.1063/1.5009942; Yu HC, 2013, SURF COAT TECH, V218, P137, DOI 10.1016/j.surfcoat.2012.12.042; Zhu C, 2019, IONICS, V25, P1395, DOI 10.1007/s11581-018-2605-4	53	0	0	8	8	SPRINGER HEIDELBERG	HEIDELBERG	TIERGARTENSTRASSE 17, D-69121 HEIDELBERG, GERMANY	2193-9764	2193-9772		INTEGR MATER MANUF I	Integr. Mater. Manuf. Innov.	2024 MAR 19	2024										10.1007/s40192-024-00344-8	http://dx.doi.org/10.1007/s40192-024-00344-8		MAR 2024	10	Engineering, Manufacturing; Materials Science, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Engineering; Materials Science	LN2H1		hybrid			2024-07-03	WOS:001187411700001
J	Palmer, A; Spirling, A				Palmer, Alexis; Spirling, Arthur			Large Language Models Can Argue in Convincing Ways About Politics, But Humans Dislike AI Authors: implications for Governance	POLITICAL SCIENCE			English	Article						artificial intelligence; rhetoric; large language models; political methodology; political debate		All politics relies on rhetorical appeals, and the ability to make arguments is considered perhaps uniquely human. But as recent times have seen successful large language model (LLM) applications to similar endeavours, we explore whether these approaches can out-compete humans in making appeals for/against various positions in US politics. We curate responses from crowdsourced workers and an LLM and place them in competition with one another. Human (crowd) judges make decisions about the relative strength of their (human v machine) efforts. We have several empirical 'possibility' results. First, LLMs can produce novel arguments that convince independent judges at least on a par with human efforts. Yet when informed about an orator's true identity, judges show a preference for human over LLM arguments. This may suggest voters view such models as potentially dangerous; we think politicians should be aware of related 'liar's dividend' concerns.	[Palmer, Alexis] NYU, Dept Polit, New York, NY 10012 USA; [Spirling, Arthur] Princeton Univ, Dept Polit, Princeton, NJ USA	New York University; Princeton University	Palmer, A (corresponding author), NYU, Dept Polit, New York, NY 10012 USA.	ap6100@nyu.edu						Allen J, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay3539; Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J; Coppock A, 2018, P NATL ACAD SCI USA, V115, P12441, DOI 10.1073/pnas.1808083115; Dai Yaoyao., 2023, SUMM POL METH M; Grumbach JM, 2018, PERSPECT POLIT, V16, P416, DOI 10.1017/S153759271700425X; Halterman Andrew., 2023, PREPRINT; Hu MQ, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P755; Jakesch M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208839120; Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998; Loewen PJ, 2012, ELECT STUD, V31, P212, DOI 10.1016/j.electstud.2011.07.003; Martindale Colin, 1990, The clockwork muse: The predictability of artistic change; Motoki F, 2024, PUBLIC CHOICE, V198, P3, DOI 10.1007/s11127-023-01097-2; Rapp Christof., 2009, COMPANION ARISTOTLE, P577; Rosenzweig Leah R., 2022, OPEN SCI FRAMEWORK; Schiff Kaylyn Jackson, 2022, LIARS DIVIDEND CAN P; Spirling A, 2023, NATURE, V616, P413, DOI 10.1038/d41586-023-01295-4; Stone PJ, 1966, The general inquirer: a computer approach to content analysis; Touvron H., 2023, arXiv	18	0	0	4	4	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	0032-3187	2041-0611		POLIT SCI	Polit. Sci.	SEP 2	2023	75	3					281	291		10.1080/00323187.2024.2335471	http://dx.doi.org/10.1080/00323187.2024.2335471		APR 2024	11	Political Science	Social Science Citation Index (SSCI)	Government & Law	RG2V3					2024-07-03	WOS:001204599400001
J	Singh, C; Askari, A; Caruana, R; Gao, JF				Singh, Chandan; Askari, Armin; Caruana, Rich; Gao, Jianfeng			Augmenting interpretable models with large language models during training	NATURE COMMUNICATIONS			English	Article								Recent large language models (LLMs), such as ChatGPT, have demonstrated remarkable prediction performance for a growing array of tasks. However, their proliferation into high-stakes domains and compute-limited settings has created a burgeoning need for interpretability and efficiency. We address this need by proposing Aug-imodels, a framework for leveraging the knowledge learned by LLMs to build extremely efficient and interpretable prediction models. Aug-imodels use LLMs during fitting but not during inference, allowing complete transparency and often a speed/memory improvement of greater than 1000x for inference compared to LLMs. We explore two instantiations of Aug-imodels in natural-language processing: Aug-Linear, which augments a linear model with decoupled embeddings from an LLM and Aug-Tree, which augments a decision tree with LLM feature expansions. Across a variety of text-classification datasets, both outperform their non-augmented, interpretable counterparts. Aug-Linear can even outperform much larger models, e.g. a 6-billion parameter GPT-J model, despite having 10,000x fewer parameters and being fully transparent. We further explore Aug-imodels in a natural-language fMRI study, where they generate interesting interpretations from scientific data. Prediction and interpretation tasks may be challenging in high-stakes applications, such as medical decision-making, or systems with compute-limited hardware. The authors introduce an augmented framework for leveraging the knowledge learned by Large Language Models to build interpretable models which are both accurate and efficient.	[Singh, Chandan; Caruana, Rich; Gao, Jianfeng] Microsoft Res, Redmond, WA 98052 USA; [Askari, Armin] Univ Calif Berkeley, Berkeley, CA USA	Microsoft; University of California System; University of California Berkeley	Singh, C (corresponding author), Microsoft Res, Redmond, WA 98052 USA.	chansingh@microsoft.com						Adebayo J, 2018, ADV NEUR IN, V31; Agarwal A., 2022, arXiv; Agarwal R, 2021, Advances in Neural Information Processing Systems, V34; Akl H.A., 2021, arXiv; Angelino E., 2018, arXiv; Angermueller C, 2016, MOL SYST BIOL, V12, DOI 10.15252/msb.20156651; Antonello R, 2024, NEUROBIOL LANG, V5, P64, DOI 10.1162/nol_a_00087; Bach S.H., 2022, arXiv; Bertsimas D, 2017, MACH LEARN, V106, P1039, DOI 10.1007/s10994-017-5633-9; Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142; Bommasani R, 2023, Arxiv, DOI arXiv:2303.15772; Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324; Brennan T, 2013, CRIMINOL PUBLIC POL, V12, P551, DOI 10.1111/1745-9133.12055; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Camburu OM, 2018, ADV NEUR IN, V31; Carreira-Perpiñán MA, 2018, ADV NEUR IN, V31; Caruana R, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1721, DOI 10.1145/2783258.2788613; Caucheteux C, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03036-1; Chen CF, 2019, 33 C NEURAL INFORM P, V32; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Chipman HA, 2010, ANN APPL STAT, V4, P266, DOI 10.1214/09-AOAS285; Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27; Conneau A, 2018, Arxiv, DOI arXiv:1805.01070; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Devlin S, 2019, Arxiv, DOI arXiv:1905.07631; Dwork C., 2012, P 3 INN THEOR COMP S, P214, DOI DOI 10.1145/2090236.2090255; Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148; Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451; Frieman JH, 2008, ANN APPL STAT, V2, P916, DOI 10.1214/07-AOAS148; Frosst N, 2017, Arxiv, DOI [arXiv:1711.09784, DOI 10.1109/CVPR.2016.594]; Ghosh S, 2023, Arxiv, DOI arXiv:2307.05350; Goodman B, 2016, Arxiv, DOI arXiv:1606.08813; Ha W., 2021, ADV NEUR IN, V34; Hastie Trevor., 1986, Statistical Science, V1, P297, DOI [10.1214/ss/1177013609, 10.1214/ss/1177013604, DOI 10.1214/SS/1177013604]; Hazourli A., 2022, FinancialBERT-a pretrained language model for financial text mining, DOI [10.13140/RG.2.2.34032.12803, DOI 10.13140/RG.2.2.34032.12803]; Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1; Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]; Hu X., 2019, Adv. Neural Inf. Process. Syst. (NeurIPS); Huth AG, 2016, NATURE, V532, P453, DOI 10.1038/nature17637; Janizek JD, 2021, J MACH LEARN RES, V22; Joulin A, 2016, Arxiv, DOI [arXiv:1607.01759, 10.48550/arXiv.1607.01759]; Koh PW, 2020, ICML, P5338; Kornblith Aaron E, 2022, PLOS Digit Health, V1, pe0000076, DOI 10.1371/journal.pdig.0000076; LeBel A, 2022, bioRxiv, DOI [10.1101/2022.09.22.509104, 10.1101/2022.09.22.509104v1, DOI 10.1101/2022.09.22.509104]; Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134; Li O, 2018, AAAI CONF ARTIF INTE, P3530; Li XM, 2002, POWERCON 2002: INTERNATIONAL CONFERENCE ON POWER SYSTEM TECHNOLOGY, VOLS 1-4, PROCEEDINGS, P556, DOI 10.1109/ICPST.2002.1053604; Lin J., 2020, P 37 INT C MACHINE L, P6150; Liu FDR, 2019, Arxiv, DOI arXiv:1906.08286; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Loper E, 2002, ARXIV; Lundberg S, 2016, Arxiv, DOI arXiv:1611.07478; Lundberg SM, 2019, Arxiv, DOI [arXiv:1905.04610, DOI 10.48550/ARXIV.1905.04610, 10.48550/arXiv.1905.04610]; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; McCullagh P., 1993, J. Am. Stat. Assoc, V88, P698, DOI [10.2307/2290358, DOI 10.2307/2290358]; Mcinerney DJ, 2023, Arxiv, DOI arXiv:2302.12343; Meng K, 2022, Arxiv, DOI arXiv:2202.05262; Mignan A, 2019, NATURE, V574, pE1, DOI 10.1038/s41586-019-1582-8; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Montani Ines, 2020, Zenodo, DOI 10.5281/ZENODO.3701227; Morris JX, 2023, Arxiv, DOI arXiv:2310.14034; Murdoch WJ, 2019, P NATL ACAD SCI USA, V116, P22071, DOI 10.1073/pnas.1900654116; Olah C., 2018, Distill, DOI DOI 10.23915/DISTILL.00010; Pang B., 2005, P ACL, P115, DOI 10.3115/1219840.1219855; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846; Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778; Rudin C., 2021, arXiv:2103.11251 cs; Rudin C, 2019, Arxiv, DOI [arXiv:1811.10154, 10.1038/s42256-019-0048-x, DOI 10.1038/S42256-019-0048-X, DOI 10.48550/ARXIV.1811.10154]; Sanh V, 2020, Arxiv, DOI arXiv:1910.01108; Saravia E, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3687; Schrimpf M, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2105646118; Sha L., 2021, P AAAI C ARTIFICIAL, P13771; Singh C., 2021, JOSS, V61, P3192, DOI [10.21105/joss.03192, DOI 10.21105/JOSS.03192]; Singh C., 2019, INT C LEARN REPR, V26; Singh C, 2021, Arxiv, DOI arXiv:2003.01926; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Sparck-Jones K, 2004, J DOC, V60, P493, DOI 10.1108/eb026526; Su HJ, 2023, Arxiv, DOI arXiv:2212.09741; Tan S., 2018, ICLR 2019 C BLIND SU; Tan YS, 2022, Arxiv, DOI arXiv:2201.11931; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Turpin M, 2023, Arxiv, DOI [arXiv:2305.04388, DOI 10.48550/ARXIV.2305.04388]; Wang B, 2021, GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model; Wang XQ, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.659622; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Morris JX, 2020, Arxiv, DOI arXiv:2005.05909; Yang Y, 2023, Arxiv, DOI arXiv:2211.11158; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yuksekgonul M, 2023, Arxiv, DOI [arXiv:2205.15480, 10.48550/arXiv.2205.15480]; Zaidan Omar, 2008, Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, P31; Zarlenga ME, 2021, arXiv, DOI DOI 10.48550/ARXIV.2111.12628; Zhang X, 2015, ADV NEUR IN, V28	100	4	4	28	30	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY		2041-1723		NAT COMMUN	Nat. Commun.	NOV 30	2023	14	1							7913	10.1038/s41467-023-43713-1	http://dx.doi.org/10.1038/s41467-023-43713-1			11	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	Z5JX5	38036543	gold, Green Published, Green Submitted			2024-07-03	WOS:001112447600030
J	Pal, S; Bhattacharya, M; Lee, SS; Chakraborty, C				Pal, Soumen; Bhattacharya, Manojit; Lee, Sang-Soo; Chakraborty, Chiranjib			A Domain-Specific Next-Generation Large Language Model (LLM) or ChatGPT is Required for Biomedical Engineering and Research	ANNALS OF BIOMEDICAL ENGINEERING			English	Letter						Large language model; Biomedical engineering; ChatBot; ChatGPT		Large language models or ChatGPT have recently gained extensive media coverage. At the same time, the use of ChatGPT has increased deistically. Biomedical researchers, engineers, and clinicians have shown significant interest and started using it due to its diverse applications, especially in the biomedical field. However, it has been found that ChatGPT sometimes provided incorrect or partly correct information. It is unable to give the most recent information. Therefore, we urgently advocate a domain-specific next-generation, ChatBot for biomedical engineering and research, providing error-free, more accurate, and updated information. The domain-specific ChatBot can perform diversified functions in biomedical engineering, such as performing innovation in biomedical engineering, designing a medical device, etc. The domain-specific artificial intelligence enabled device will revolutionize biomedical engineering and research if a biomedical domain-specific ChatBot is produced.	[Pal, Soumen] Vellore Inst Technol, Sch Mech Engn, Vellore 632014, Tamil Nadu, India; [Bhattacharya, Manojit] Fakir Mohan Univ, Dept Zool, Vyasa Vihar, Balasore 756020, Odisha, India; [Lee, Sang-Soo] Hallym Univ, Chuncheon Sacred Heart Hosp, Inst Skeletal Aging & Orthopaed Surg, Chunchon 24252, Gangwon Do, South Korea; [Chakraborty, Chiranjib] Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, West Bengal, India	Vellore Institute of Technology (VIT); VIT Vellore; Fakir Mohan University; Hallym University	Chakraborty, C (corresponding author), Adamas Univ, Sch Life Sci & Biotechnol, Dept Biotechnol, Kolkata 700126, West Bengal, India.	drchiranjib@yahoo.com	Bhattacharya, Manojit/A-2027-2012; Chakraborty, Chiranjib/J-4847-2013	Bhattacharya, Manojit/0000-0001-9669-1835; Chakraborty, Chiranjib/0000-0002-3958-239X				Biswas S., 2023, International Journal of Clinical and Medical Education Research, V2, P182; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Caldarini G, 2022, INFORMATION, V13, DOI 10.3390/info13010041; Castelvecchi Davide, 2022, Nature, DOI 10.1038/d41586-022-04383-z; Chakraborty C, 2024, ANN BIOMED ENG, V52, P134, DOI 10.1007/s10439-023-03297-9; Chen S, 2023, ARXIV; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Gao C. A., 2022, bioRxiv; Garg A., 2022, WHAT IS CHATGPT ITS; Jin Q, 2023, ARXIV; Joublin F., 2023, ARXIV; Jovanovic M, 2021, IEEE INTERNET COMPUT, V25, P44, DOI 10.1109/MIC.2020.3037151; Kashefi A., 2023, Journal of Machine Learning for Modeling and Computing, V4, P1, DOI DOI 10.1615/JMACHLEARNMODELCOMPUT.2023048492; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Lu Y, 2023, AM J AUDIOL, V32, P972, DOI [10.1007/s10439-023-03234-w, 10.1044/2023_AJA-23-00069, 10.1063/5.0112732, 10.1079/9781800621954.0001]; Megahed FM, 2024, QUAL ENG, V36, P287, DOI 10.1080/08982112.2023.2206479; Perkel JM, 2023, NATURE, V618, P422, DOI 10.1038/d41586-023-01833-0; Pournaras E., 2023, ARXIV; Stokel-Walker Chris, 2022, Nature, DOI 10.1038/d41586-022-04397-7; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0	20	8	8	22	51	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	MAR	2024	52	3					451	454	s10439-023-03306-x	10.1007/s10439-023-03306-x	http://dx.doi.org/10.1007/s10439-023-03306-x		JUL 2023	4	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	HH2W4	37428337				2024-07-03	WOS:001026564300002
J	Briva-Iglesias, V; Camargo, JLC; Dogru, G				Briva-Iglesias, Vicent; Camargo, Joao Lucas Cavalheiro; Dogru, Gokhan			LARGE LANGUAGE MODELS "AD REFERENDUM": HOW GOOD ARE THEY AT MACHINE TRANSLATION IN THE LEGAL DOMAIN?	MONTI			English	Article						Machine translation; Human evaluation of translation quality; Large language models; Translation quality; Legal translation	QUALITY; PERCEPTIONS	This study evaluates the machine translation (MT) quality of two state-of-the-art large language models (LLMs) against a traditional neural machine translation (NMT) system across four language pairs in the legal domain. It combines automatic evaluation metrics (AEMs) and human evaluation (HE) by professional translators to assess translation ranking, fluency and adequacy. The results indicate that while Google Translate generally outperforms LLMs in AEMs, human evaluators rate LLMs, especially GPT-4, comparably or slightly better in terms of producing contextually adequate and fluent translations. This discrepancy suggests LLMs' potential in handling specialized legal terminology and context, highlighting the importance of human evaluation methods in assessing MT quality. The study underscores the evolving capabilities of LLMs in specialized domains and calls for reevaluation of traditional AEMs to better capture the nuances of LLM-generated translations.	[Briva-Iglesias, Vicent; Camargo, Joao Lucas Cavalheiro] Dublin City Univ, Dublin, Ireland; [Dogru, Gokhan] Univ Autonoma Barcelona, Barcelona, Spain	Dublin City University; Autonomous University of Barcelona	Briva-Iglesias, V (corresponding author), Dublin City Univ, Dublin, Ireland.	vicent.brivaiglesias2@mail.dcu.ie; joo.cavalheirocamargo2@mail.dcu.ie; gokhan.dogru@uab.cat						[Anonymous], 2022, European Language Industry Survey 2022: Trends, expectations and concerns of the European language industry; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bago P, 2022, REV LLENG DRET, P9, DOI 10.2436/rld.i78.2022.3741; BoRJA Anabel, 2019, Legal Translation: Current Issues and Challenges in Research Methods and Applications, P187; Briva-Iglesias V, 2022, TRADUMATICA, P149, DOI 10.5565/rev/tradumatica.303; BRIVA-IGLESIAS Vicent, 2021, Mutatis Mutandis, V14, P571, DOI [10.17533/udea.mut.v14n2a14, DOI 10.17533/UDEA.MUT.V14N2A14]; BRIVA-IGLESIAS Vicent, 2023, Translation, Cognition & Behavior, V6, P60, DOI [10.1075/tcb.00077.bri, DOI 10.1075/TCB.00077.BRI]; Cadwell P, 2016, TRANSL SPACES, V5, P222, DOI 10.1075/ts.5.2.04cad; CAo Deborah, 2007, Translating Law, DOI [10.21832/9781853599552, DOI 10.21832/9781853599552]; Castilho S, 2018, MACH TRANS TECH APPL, V1, P9, DOI 10.1007/978-3-319-91241-7_2; CASTILHo Sheila, 2021, 2021 P 6 C MACH TRAN, P566; CASTILHo Sheila, 2023, P 24 ANN C EUR ASS M; cASTILHO Sheila, 2023, Processamento de Linguagem Natural: Conceitos, Tecnicas e Aplicacoes em Portugues; Christopher ClackD., 2018, Journal of Digital Banking, V2, P338; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Doherty S, 2017, IATIS YEARB, P131; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; EMT, 2022, European Master's in Translation Competence Framework 2022; Engberg J, 2020, INT J SEMIOTIC LAW, V33, P263, DOI 10.1007/s11196-020-09706-9; Görög A, 2014, TRADUMATICA, P443; GOTTI Fabrizio, 2008, P 8 C ASS MACH TRANS, P370; GROSSMAN Maura R., 2010, Richmond Journal of Law and Technology, V17, P1; Hacker P, 2023, Arxiv, DOI [arXiv:2302.02337, DOI 10.48550/ARXIV.2302.02337, 10.48550/arXiv.2302.02337, DOI 10.48550/AR-XIV.2302.02337]; HAN Jesse Michael, 2021, Unsupervised Neural Machine Translation with Generative Language Models Only; Hendy A, 2023, Arxiv, DOI [arXiv:2302.09210, DOI 10.48550/ARXIV.2302.09210]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Karpinska M, 2023, Arxiv, DOI [arXiv:2304.03245, 10.48550/arXiv.2304.03245]; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; KENNY Dorothy, 2022, Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence; Killman J, 2022, REV LLENG DRET, P56, DOI 10.2436/rld.i78.2022.3831; KILLMAN Jeffrey, 2014, P 11 C ASS MACH TRAN, P85; Kocmi Tom, 2021, P 6 C MACHINE TRANSL, P478; KOEHN Philipp, 2017, P 1 WORKSHOP NEURAL, P28, DOI [10.18653/v1/W17-3204, DOI 10.18653/V1/W17-3204]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Läubli S, 2020, J ARTIF INTELL RES, V67, P653; LESzNyAK Agnes, 2019, 2019 P MACH TRANSL S, P16; Long SB, 2018, Arxiv, DOI [arXiv:1809.06537, 10.48550/arXiv.1809.06537, DOI 10.48550/ARXIV.1809.06537]; Lyu C, 2024, Arxiv, DOI [arXiv:2305.01181, 10.48550/arXiv.2305.01181, DOI 10.48550/ARXIV.2305.01181]; Martínez-Carrasco R, 2022, QUAD FILOL-ESTUD LIN, V27, P235, DOI 10.7203/QF.27.24618; MiLETO Fiorenza, 2019, H2D. Revista de Humanidades Digitais, V1, P1, DOI [10.21814/h2d.237, DOI 10.21814/H2D.237]; Moslem Y, 2023, Arxiv, DOI arXiv:2301.13294; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; NOONAN Nick, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4406907, DOI 10.2139/SSRN.4406907]; oBRiEN Sharon, 2022, Machine Translation for Everyone: Empowering Users in the Age of Artificial Intelligence, P105, DOI [10.5281/zenodo.6759982, DOI 10.5281/ZENODO.6759982]; oViEDo-TRESPAlAcioS Oscar, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4346827, DOI 10.2139/SSRN.4346827]; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Post M, 2018, Arxiv, DOI [arXiv:1804.08771, 10.48550/arXiv.1804.08771]; RADFoRD Alec, 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2212.04356; Ragni V, 2022, PERSPECT STUD TRANSL, V30, P137, DOI 10.1080/0907676X.2021.1889005; Raunak V, 2021, Arxiv, DOI [arXiv:2104.06683, 10.48550/arXiv.2104.06683]; Rei R, 2020, Arxiv, DOI [arXiv:2009.09025, DOI 10.48550/ARXIV.2009.09025]; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P578; REi Ricardo, 2022, P 7 C MACHINE TRANSL, P634; Rossi C, 2019, J SPEC TRANSL, P177; Sarcevic Susan., 1997, NEW APPROACH LEGAL T; sEBAsTiAN Glorin, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4363843, DOI 10.2139/SSRN.4363843]; sEllAM Thibault, 2020, P 58 ANN M ASS COMP, P7881, DOI [DOI 10.18653/V1/2020.ACL-MAIN.704, 10.18653/v1/2020.acl-main.704, 10.18653/v1/2020.acl-main]; Shterionov D, 2018, MACH TRANSL, V32, P217, DOI 10.1007/s10590-018-9220-z; siu Sai Cheong, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4448091, DOI 10.2139/SSRN.4448091]; Snover M., 2006, P 7 C ASS MACH TRANS, P223; Sosoni V, 2022, REV LLENG DRET, P92, DOI 10.2436/rld.i78.2022.3704; Tiedemann J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2214; TRAuTMANN Dietrich, 2022, arXiv, DOI [DOI 10.48550/ARXIV.2212.02199, 10.48550/arXiv.2212.02199]; VANRoY Bram, 2023, P 24 ANN C EUR ASS M, P499; Vardaro J, 2019, INFORMATICS-BASEL, V6, DOI 10.3390/informatics6030041; Vieira LN, 2021, INFORM COMMUN SOC, V24, P1515, DOI 10.1080/1369118X.2020.1776370; Wang LY, 2023, Arxiv, DOI [arXiv:2304.02210, 10.48550/arXiv.2304.02210]; Way A, 2020, BLOOMSBURY COMPANION, P311; White J, 2023, Arxiv, DOI [arXiv:2303.07839, 10.48550/arXiv.2303.07839]; WIEsMANN Eva, 2019, Comparative Legilinguistics, V37, P117, DOI DOI 10.14746/CL.2019.37.4; YuE Thomas, 2023, SSRN Scholarly Paper, DOI [10.2139/ssrn.4346152, DOI 10.2139/SSRN.4346152]; Zhang B, 2023, Arxiv, DOI [arXiv:2301.07069, 10.48550/arXiv.2301.07069]; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhuo TY, 2023, Arxiv, DOI [arXiv:2301.12867, 10.48550/arXiv.2301.12867]	75	0	0	0	0	UNIV JAUME I	CASTELLO DE LA PLANA	AVE DE VICENT SOS BAYNAT, S-N, CASTELLO DE LA PLANA, 12071, SPAIN	1889-4178	1989-9335		MONTI	MonTI		2024	16						75	107		10.6035/MonTI.2024.16.02	http://dx.doi.org/10.6035/MonTI.2024.16.02			33	Linguistics	Emerging Sources Citation Index (ESCI)	Linguistics	UM6F7		Green Published, Green Submitted, hybrid			2024-07-03	WOS:001248509900003
J	Collarana, D; Busch, M; Lange, C				Collarana, Diego; Busch, Moritz; Lange, Christoph			Knowledge Graph Treatments for Hallucinating Large Language Models	ERCIM NEWS			English	Article								Despite the excitement about Large Language Models (LLMs), they still fail in unpredictable ways in knowledge-intensive tasks. In this article, we explore the integration of LLMs with Knowledge Graphs (KGs) to develop cognitive conversational assistants with improved accuracy. To address the current challenges of LLMs, such as hallucination, updateability and provenance, we propose a layered solution that leverages the structured, factual data of KGs alongside the generative capabilities of LLMs. The outlined strategy includes constructing domain-specific KGs, interfacing them with LLMs for specialised tasks, integrating them with enterprise information systems and processes, and adding guardrails to validate their output, thereby presenting a comprehensive framework for deploying more reliable and context-aware AI applications in various industries.	[Collarana, Diego; Busch, Moritz; Lange, Christoph] Fraunhofer FIT, St Augustin, Germany	Fraunhofer Gesellschaft; Fraunhofer Institute Center Schloss Birlinghoven	Collarana, D (corresponding author), Fraunhofer FIT, St Augustin, Germany.	diego.collarana.vargas@fit.fraunhofer.de						Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Pan SR, 2024, Arxiv, DOI arXiv:2306.08302	3	0	0	1	1	EUROPEAN RESEARCH CONSORTIUM INFORMATICS & MATHEMATICS	SOPHIA ANTIPOLIS CEDEX	2004, ROUTE LUCIOLES, BP 93, SOPHIA ANTIPOLIS CEDEX, 06902, FRANCE	0926-4981	1564-0094		ERCIM NEWS	ERCIM News	JAN	2024		136					35	36						2	Computer Science, Interdisciplinary Applications	Emerging Sources Citation Index (ESCI)	Computer Science	NG0K3					2024-07-03	WOS:001199179500020
J	Goecke, B; DiStefano, PV; Aschauer, W; Haim, K; Beaty, R; Forthmann, B				Goecke, Benjamin; DiStefano, Paul V.; Aschauer, Wolfgang; Haim, Kurt; Beaty, Roger; Forthmann, Boris			Automated Scoring of Scientific Creativity in German	JOURNAL OF CREATIVE BEHAVIOR			English	Article; Early Access						creativity; automated scoring; scientific creativity; large language models		Automated scoring is a current hot topic in creativity research. However, most research has focused on the English language and popular verbal creative thinking tasks, such as the alternate uses task. Therefore, in this study, we present a large language model approach for automated scoring of a scientific creative thinking task that assesses divergent ideation in experimental tasks in the German language. Participants are required to generate alternative explanations for an empirical observation. This work analyzed a total of 13,423 unique responses. To predict human ratings of originality, we used XLM-RoBERTa (Cross-lingual Language Model-RoBERTa), a large, multilingual model. The prediction model was trained on 9,400 responses. Results showed a strong correlation between model predictions and human ratings in a held-out test set (n = 2,682; r = 0.80; CI-95% [0.79, 0.81]). These promising findings underscore the potential of large language models for automated scoring of scientific creative thinking in the German language. We encourage researchers to further investigate automated scoring of other domain-specific creative thinking tasks.	[Goecke, Benjamin] Univ Tubingen, Tubingen, Germany; [DiStefano, Paul V.; Beaty, Roger] Penn State Univ, State Coll, PA USA; [Aschauer, Wolfgang; Haim, Kurt] Univ Educ Upper Austria, Linz, Austria; [Forthmann, Boris] Univ Munster, Munster, Germany; [Goecke, Benjamin] Univ Tubingen, Hector Res Inst, Tubingen, Germany	Eberhard Karls University of Tubingen; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; University of Munster; Eberhard Karls University of Tubingen	Goecke, B (corresponding author), Univ Tubingen, Hector Res Inst, Tubingen, Germany.	academ@benjamin-goecke.de		DiStefano, Paul/0009-0002-9638-3220; Haim, Kurt/0000-0003-4093-0512; Forthmann, Boris/0000-0001-9755-7304; Goecke, Benjamin/0000-0002-3050-1848	Penn State Center for Socially Responsible Artificial Intelligence	Penn State Center for Socially Responsible Artificial Intelligence	Open Access funding enabled and organized by Projekt DEAL.	Acar S., 2023, A comparison of supervised and unsupervised learning methods in automated scoring of figural tests of creativity; Akiba T, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2623, DOI 10.1145/3292500.3330701; Aschauer W, 2022, CREATIVITY RES J, V34, P195, DOI 10.1080/10400419.2021.1968656; Ayas MB, 2014, THINK SKILLS CREAT, V13, P195, DOI 10.1016/j.tsc.2014.06.001; Beaty RE, 2021, BEHAV RES METHODS, V53, P757, DOI 10.3758/s13428-020-01453-w; Bossomaier T, 2009, CREATIVITY RES J, V21, P64, DOI 10.1080/10400410802633517; Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324; Buczak P, 2023, J CREATIVE BEHAV, V57, P17, DOI 10.1002/jocb.559; Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785; Conneau A, 2020, Arxiv, DOI arXiv:1911.02116; Cropley DH, 2022, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000510; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dumas D, 2023, J CREATIVE BEHAV, V57, P419, DOI 10.1002/jocb.588; Dumas D, 2021, PSYCHOL AESTHET CREA, V15, P645, DOI 10.1037/aca0000319; Dumas D, 2014, THINK SKILLS CREAT, V14, P56, DOI 10.1016/j.tsc.2014.09.003; Ferrando PJ, 2018, EDUC PSYCHOL MEAS, V78, P762, DOI 10.1177/0013164417719308; Forster E.A., 2009, Creativity evaluation through latent semantic analysis; Forthmann B., 2022, Fifty years later and still working: rediscovering Paulus etal.'s (1970) automated scoring of divergent thinking tests, DOI [10.31234/osf.io/byj8c, DOI 10.31234/OSF.IO/BYJ8C]; Forthmann B, 2023, CREATIVITY RES J, DOI 10.1080/10400419.2023.2250976; Forthmann B, 2017, THINK SKILLS CREAT, V23, P129, DOI 10.1016/j.tsc.2016.12.005; Goldstein T, 2023, PSYCHOL AESTHET CREA, V17, P495, DOI 10.1037/aca0000618; Green AE, 2012, J EXP PSYCHOL LEARN, V38, P264, DOI 10.1037/a0025764; Guilford J. P., 1967, The nature of human intelligence; Johnson DR, 2023, BEHAV RES METHODS, V55, P3726, DOI 10.3758/s13428-022-01986-2; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mehrabi N, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3457607; Merseal HM, 2023, CURR OPIN GREEN SUST, V39, DOI 10.1016/j.cognition.2022.105362; MURAKI E, 1992, APPL PSYCH MEAS, V16, P159, DOI 10.1177/014662169201600206; Organisciak P, 2023, THINK SKILLS CREAT, V49, DOI 10.1016/j.tsc.2023.101356; Patterson JD, 2023, BEHAV RES METHODS, DOI 10.3758/s13428-023-02258-3; Paulus D.H., 1970, Computer simulation of human ratings of creativity. Final report; R Core Team, 2023, R: A Language and Environment for Statistical Computing; SAMEJIMA F, 1969, PSYCHOMETRIKA, V34, P1; Weiss S, 2023, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000585; Weiss S, 2021, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000434; Yu YH, 2023, PSYCHOL AESTHET CREA, DOI 10.1037/aca0000573; Zhou Z.-H., 2021, Machine Learning, DOI [10.1007/978-981-15-1967-3, DOI 10.1007/978]; Zielinska A, 2023, THINK SKILLS CREAT, V50, DOI 10.1016/j.tsc.2023.101414	38	0	0	4	4	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0022-0175	2162-6057		J CREATIVE BEHAV	J. Creat. Behav.	2024 MAY 15	2024										10.1002/jocb.658	http://dx.doi.org/10.1002/jocb.658		MAY 2024	7	Psychology, Educational	Social Science Citation Index (SSCI)	Psychology	QS1O2		hybrid			2024-07-03	WOS:001222769700001
C	Tang, Y; da Costa, AAB; Zhang, XZ; Patrick, I; Khastgir, S; Jennings, P			IEEE	Tang, Yun; da Costa, Antonio A. Bruto; Zhang, Xizhe; Patrick, Irvine; Khastgir, Siddartha; Jennings, Paul			Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain	2023 IEEE 26TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, ITSC	IEEE International Conference on Intelligent Transportation Systems-ITSC		English	Proceedings Paper	IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)	SEP 24-28, 2023	Bilbao, SPAIN	IEEE		large language model; domain ontology distillation; autonomous driving		Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by "chatting" with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains.	[Tang, Yun; da Costa, Antonio A. Bruto; Zhang, Xizhe; Patrick, Irvine; Khastgir, Siddartha; Jennings, Paul] Univ Warwick, WMG, Coventry, W Midlands, England	University of Warwick	Tang, Y (corresponding author), Univ Warwick, WMG, Coventry, W Midlands, England.	yun.tang@warwick.ac.uk; antonio.bruto-da-costa@warwick.ac.uk; Jason.Zhang@warwick.ac.uk; patrick.irvine@warwick.ac.uk; S.Khastgir.1@warwick.ac.uk; Paul.Jennings@warwick.ac.uk			UKRI Future Leaders Fellowship [MR/S035176/1]	UKRI Future Leaders Fellowship(UK Research & Innovation (UKRI))	The work presented in this paper has been supported by UKRI Future Leaders Fellowship (Grant MR/S035176/1). The authors would like to thank the WMG center of HVM Catapult, and WMG, University of Warwick, UK for providing the necessary infrastructure for conducting this study. No new data were created in this study.	ASAM, 2023, AS OP; Bagschik G, 2018, IEEE INT VEH SYM, P1813, DOI 10.1109/IVS.2018.8500632; Chen Mark, 2021, arXiv preprint arXiv:2107.03374; Cheng MF, 2023, PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023, P488, DOI 10.1145/3597926.3598072; Ding W., 2022, ARXIV220202215; Graphviz, 2023, US; Kendall E. F., 2019, ONTOLOGY ENG, V18, P18; Khastgir S, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107610; Lin H, 2020, LANGUAGE MODELS ARE, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Menzel T, 2018, IEEE INT VEH SYM, P1821, DOI 10.1109/IVS.2018.8500406; Nadi S., 2023, ARXIV230206527; Noy Natalya F., 2001, Ontology development 101: A guide to creating your first ontology; OpenAI, 2023, Introducing ChatGPT; OpenAI, 2023, MAX TOK AP REF OP AP; OpenAl, 2023, TEMP AP REF OP AP; Pearce H., 2022, 2023 IEEE Symposium on Security and Privacy (SP), P1; Tang S., 2022, ARXIV220605961; Tang Y., 2022, ARXIV220609357; Tang YL, 2023, J NONLINEAR FUNCT AN, V2023, DOI 10.23952/jnfa.2023.11; Tang Y, 2021, IEEE INT VEH SYM, P179, DOI 10.1109/IV48863.2021.9575536; Tang Y, 2021, IEEE INT CONF ROBOT, P11450, DOI 10.1109/ICRA48506.2021.9560890; Tang Y, 2021, 2021 36TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING ASE 2021, P1342, DOI [10.1109/ASE51524.2021.00165, 10.1109/ASE51524.2021.9678735]; Vemprala S., 2023, CHATGPT ROBOTICS DES; Weissensteiner P, 2023, IEEE ACCESS, V11, P12263, DOI 10.1109/ACCESS.2023.3242127; Wikipedia, 2023, DOT GRAPH DESCR LANG; Zhong Z., 2021, ARXIV211200964; Zhou Y., 2023, ARXIV230112738; Zhou Y., 2023, IEEE T SOFTWARE ENG	28	2	2	1	1	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA	2153-0009		979-8-3503-9946-2	IEEE INT C INTELL TR			2023							3893	3900		10.1109/ITSC57777.2023.10422308	http://dx.doi.org/10.1109/ITSC57777.2023.10422308			8	Automation & Control Systems; Computer Science, Artificial Intelligence; Transportation Science & Technology	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Transportation	BW6MU		Green Submitted			2024-07-03	WOS:001178996703139
J	Chung, PL; Fong, CT; Walters, AM; Aghaeepour, N; Yetisgen, M; O'Reilly-Shah, VN				Chung, Philip; Fong, Christine T.; Walters, Andrew M.; Aghaeepour, Nima; Yetisgen, Meliha; O'Reilly-Shah, Vikas N.			Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication	JAMA SURGERY			English	Article; Early Access							MACHINE-LEARNING-MODEL; LENGTH-OF-STAY; VALIDATION; OUTPATIENT; SURGERY; SYSTEM	Importance General-domain large language models may be able to perform risk stratification and predict postoperative outcome measures using a description of the procedure and a patient's electronic health record notes. Objective To examine predictive performance on 8 different tasks: prediction of American Society of Anesthesiologists Physical Status (ASA-PS), hospital admission, intensive care unit (ICU) admission, unplanned admission, hospital mortality, postanesthesia care unit (PACU) phase 1 duration, hospital duration, and ICU duration. Design, Setting, and Participants This prognostic study included task-specific datasets constructed from 2 years of retrospective electronic health records data collected during routine clinical care. Case and note data were formatted into prompts and given to the large language model GPT-4 Turbo (OpenAI) to generate a prediction and explanation. The setting included a quaternary care center comprising 3 academic hospitals and affiliated clinics in a single metropolitan area. Patients who had a surgery or procedure with anesthesia and at least 1 clinician-written note filed in the electronic health record before surgery were included in the study. Data were analyzed from November to December 2023. Exposures Compared original notes, note summaries, few-shot prompting, and chain-of-thought prompting strategies. Main Outcomes and Measures F1 score for binary and categorical outcomes. Mean absolute error for numerical duration outcomes. Results Study results were measured on task-specific datasets, each with 1000 cases with the exception of unplanned admission, which had 949 cases, and hospital mortality, which had 576 cases. The best results for each task included an F1 score of 0.50 (95% CI, 0.47-0.53) for ASA-PS, 0.64 (95% CI, 0.61-0.67) for hospital admission, 0.81 (95% CI, 0.78-0.83) for ICU admission, 0.61 (95% CI, 0.58-0.64) for unplanned admission, and 0.86 (95% CI, 0.83-0.89) for hospital mortality prediction. Performance on duration prediction tasks was universally poor across all prompt strategies for which the large language model achieved a mean absolute error of 49 minutes (95% CI, 46-51 minutes) for PACU phase 1 duration, 4.5 days (95% CI, 4.2-5.0 days) for hospital duration, and 1.1 days (95% CI, 0.9-1.3 days) for ICU duration prediction. Conclusions and Relevance Current general-domain large language models may assist clinicians in perioperative risk stratification on classification tasks but are inadequate for numerical duration predictions. Their ability to produce high-quality natural language explanations for the predictions may make them useful tools in clinical workflows and may be complementary to traditional risk prediction models.	[Chung, Philip; Aghaeepour, Nima] Stanford Univ, Dept Anesthesiol Perioperat & Pain Med, 300 Pasteur Dr,Grant Bldg S238, Stanford, CA 94305 USA; [Fong, Christine T.; Walters, Andrew M.; O'Reilly-Shah, Vikas N.] Univ Washington, Dept Anesthesiol & Pain Med, Seattle, WA USA; [Yetisgen, Meliha] Univ Washington, Dept Biomed & Hlth Informat, Seattle, WA USA; [Yetisgen, Meliha] Univ Washington, Dept Linguist, Seattle, WA USA	Stanford University; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle	Chung, PL (corresponding author), Stanford Univ, Dept Anesthesiol Perioperat & Pain Med, 300 Pasteur Dr,Grant Bldg S238, Stanford, CA 94305 USA.	chungp@stanford.edu		Chung, Philip/0000-0002-1194-7510	University of Washington eScience Institute	University of Washington eScience Institute	No Statement Available	Agrawal M., 2022, P 2022 C EMPIRICAL M, P1998, DOI [DOI 10.18653/V1/2022.EMNLP-MAIN.130, 10.18653/v1/2022.emnlp-main.130]; Alayrac JB, 2022, Arxiv, DOI [arXiv:2204.14198, DOI 10.48550/ARXIV.2204.14198]; Belyaeva A, 2023, Arxiv, DOI arXiv:2307.09018; Bilimoria KY, 2013, J AM COLL SURGEONS, V217, P833, DOI 10.1016/j.jamcollsurg.2013.07.385; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Cai TL, 2024, Arxiv, DOI arXiv:2305.17126; Chen PF, 2022, JMIR MED INF, V10, DOI 10.2196/38241; Chen X, 2022, Arxiv, DOI arXiv:2209.06794; Chen ZM, 2023, Arxiv, DOI arXiv:2311.16079; Collins GS, 2015, ANN INTERN MED, V162, P55, DOI [10.1136/bmj.g7594, 10.1016/j.jclinepi.2014.11.010, 10.7326/M14-0697, 10.1002/bjs.9736, 10.1186/s12916-014-0241-z, 10.1038/bjc.2014.639, 10.7326/M14-0698, 10.1016/j.eururo.2014.11.025]; Cuvillon P, 2011, EUR J ANAESTH, V28, P742, DOI 10.1097/EJA.0b013e328348fc9d; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Dyas AR, 2022, SURGERY, V172, P249, DOI 10.1016/j.surg.2022.01.025; Fang FQ, 2023, BMC ANESTHESIOL, V23, DOI 10.1186/s12871-023-02365-w; Gabriel RA, 2017, ANESTH ANALG, V124, P1529, DOI 10.1213/ANE.0000000000001827; Goodell AJ, 2023, medRxiv, DOI [10.1101/2023.12.13.23299881, 10.1101/2023.12.13.23299881, DOI 10.1101/2023.12.13.23299881]; Graessner M, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-33981-8; Hill BL, 2019, BRIT J ANAESTH, V123, P877, DOI 10.1016/j.bja.2019.07.030; Horvath B, 2021, ANESTHESIOLOGY, V135, P904, DOI 10.1097/ALN.0000000000003947; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Le Manach Y, 2016, ANESTHESIOLOGY, V124, P570, DOI 10.1097/ALN.0000000000000972; Lee SW, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00625-6; Liu NF, 2023, Arxiv, DOI arXiv:2307.03172; Mayhew D, 2019, ANAESTHESIA, V74, P373, DOI 10.1111/anae.14569; Meguid RA, 2016, ANN SURG, V264, P23, DOI 10.1097/SLA.0000000000001678; Moor M, 2023, Arxiv, DOI arXiv:2307.15189; Mudumbai SC, 2019, BMC HEALTH SERV RES, V19, DOI 10.1186/s12913-019-4640-x; Nori H, 2023, Arxiv, DOI arXiv:2311.16452; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Olsson C., 2022, arXiv; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Piktus A, 2021, Arxiv, DOI arXiv:2005.11401; Qin YJ, 2023, Arxiv, DOI arXiv:2307.16789; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ramachandran GK, 2023, J BIOMED INFORM, V139, DOI 10.1016/j.jbi.2023.104302; Ramachandran GK., 2023, Proceedings of the 5th Clinical Natural Language Processing Workshop, P385, DOI [10.18653/v1/2023.clinicalnlp-1.41, DOI 10.18653/V1/2023.CLINICALNLP-1.41]; Saklad M., 1941, Anesthesiology, V2, P281, DOI [10.1097/00000542-194105000-00004, DOI 10.1097/00000542-194105000-00004]; Sankar A, 2014, BRIT J ANAESTH, V113, P424, DOI 10.1093/bja/aeu100; Schick T., 2023, arXiv; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Singhal K, 2023, Arxiv, DOI [arXiv:2305.09617, DOI 10.48550/ARXIV.2305.09617]; Smilowitz NR, 2020, JAMA-J AM MED ASSOC, V324, P279, DOI 10.1001/jama.2020.7840; Stiennon N, 2022, Arxiv, DOI arXiv:2009.01325; Taori R., Stanford alpaca: an instruction-following llama model; Toma A, 2023, Arxiv, DOI [arXiv:2305.12031, 10.48550/arXiv.2305.12031]; Tu T, 2023, Arxiv, DOI arXiv:2307.14334; Tully JL, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01966-9; Van Veen D, 2024, NAT MED, DOI 10.1038/s41591-024-02855-5; Wang X., 2022, arXiv, DOI 10.48550/arXiv.2203.11171; Wang YB, 2023, Arxiv, DOI arXiv:2309.02233; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wei J, 2023, Arxiv, DOI arXiv:2303.03846; Wu J., 2021, arXiv; Xu S, 2023, Arxiv, DOI arXiv:2308.01317; Xu ZK, 2023, HEART LUNG, V62, P207, DOI 10.1016/j.hrtlng.2023.08.001; Yao SY, 2023, Arxiv, DOI [arXiv:2305.10601, DOI 10.48550/ARXIV.2305.10601, 10.48550/arXiv.2305.10601]; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zakka Cyril, 2024, NEJM AI, V1, DOI 10.1056/aioa2300068; Zakka C, 2023, Arxiv, DOI arXiv:2303.01229; Zhang T., 2023, arXiv; Zhang XL, 2024, Arxiv, DOI arXiv:2310.14558	62	1	1	0	0	AMER MEDICAL ASSOC	CHICAGO	330 N WABASH AVE, STE 39300, CHICAGO, IL 60611-5885 USA	2168-6254	2168-6262		JAMA SURG	JAMA Surg.	2024 JUN 5	2024										10.1001/jamasurg.2024.1621	http://dx.doi.org/10.1001/jamasurg.2024.1621		JUN 2024	10	Surgery	Science Citation Index Expanded (SCI-EXPANDED)	Surgery	UV8C2	38837145	Green Submitted			2024-07-03	WOS:001250918900004
C	Zhang, BY; Yang, HY; Zhou, TY; Babar, A; Liu, XY			ACM	Zhang, Boyu; Yang, Hongyang (Bruce); Zhou, Tianyu; Babar, Ali; Liu, Xiao-Yang			Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models	PROCEEDINGS OF THE 4TH ACM INTERNATIONAL CONFERENCE ON AI IN FINANCE, ICAIF 2023			English	Proceedings Paper	4th ACM International Conference on AI in Finance (ICAIF)	NOV 27-29, 2023	Brooklyn, NY	Assoc Comp Machinery, J P Morgan Chase & Co, U S Bank		Sentiment Analysis; Large Language Models; Instruction Tuning; Retrieval Augmented Generation		Financial sentiment analysis is critical for valuation and investment decision-making. Traditional NLP models, however, are limited by their parameter size and the scope of their training datasets, which hampers their generalization capabilities and effectiveness in this field. Recently, Large Language Models (LLMs) pre-trained on extensive corpora have demonstrated superior performance across various NLP tasks due to their commendable zero-shot abilities. Yet, directly applying LLMs to financial sentiment analysis presents challenges: The discrepancy between the pre-training objective of LLMs and predicting the sentiment label can compromise their predictive performance. Furthermore, the succinct nature of financial news, often devoid of sufficient context, can significantly diminish the reliability of LLMs' sentiment analysis. To address these challenges, we introduce a retrieval-augmented LLMs framework for financial sentiment analysis. This framework includes an instruction-tuned LLMs module, which ensures LLMs behave as predictors of sentiment labels, and a retrieval-augmentation module which retrieves additional context from reliable external sources. Benchmarked against traditional models and LLMs like ChatGPT and LLaMA, our approach achieves 15% to 48% performance gain in accuracy and F1 score.	[Zhang, Boyu; Babar, Ali] Univ Adelaide, Adelaide, SA, Australia; [Yang, Hongyang (Bruce); Liu, Xiao-Yang] Columbia Univ, New York, NY 10025 USA; [Zhou, Tianyu] Brown Univ, Providence, RI 02912 USA; [Liu, Xiao-Yang] Rensselaer Polytech Inst, Troy, NY 12180 USA	University of Adelaide; Columbia University; Brown University; Rensselaer Polytechnic Institute	Liu, XY (corresponding author), Columbia Univ, New York, NY 10025 USA.; Liu, XY (corresponding author), Rensselaer Polytech Inst, Troy, NY 12180 USA.	boyu.zhang01@adelaide.edu.au; hy2500@columbia.edu; zhoutianyu0426@gmail.com; ali.babar@adelaide.edu.au; xl2427@columbia.edu	Liu, Xiao-Yang/AAZ-8384-2020; Zhang, Boyu/AAO-7129-2020	Zhang, Boyu/0000-0001-8596-878X; Ali Babar, Muhammad/0000-0001-9696-3626; Liu, Xiao-Yang/0000-0002-9532-1709				Araci D, 2019, Arxiv, DOI [arXiv:1908.10063, DOI 10.48550/ARXIV.1908.10063]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai D, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P3417, DOI 10.1145/3477495.3532682; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Day MY, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P1127, DOI 10.1109/ASONAM.2016.7752381; Gartner Glossary, 2023, Definition of Sentiment Analysis-Finance Glossary-Gartner.; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Liu Shangqing, 2020, arXiv; Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101; Lou RZ, 2024, Arxiv, DOI [arXiv:2303.10475, 10.48550/ARXIV.2303.10475]; Maia Macedo, 2018, WWW 18 COMPANION P T; Malo P, 2014, J ASSOC INF SCI TECH, V65, P782, DOI 10.1002/asi.23062; Mao YN, 2021, Arxiv, DOI arXiv:2009.08553; Neural Magic, 2022, Twitter Financial News Sentiment.; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Parvez R, 2021, Arxiv, DOI arXiv:2108.11601; Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703; Rawte Vipula, 2020, WORKSH MIN DAT FIN A, P77; Sanh V, 2022, arXiv; Sennrich R, 2016, Arxiv, DOI arXiv:1508.07909; Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6; Taori R., 2023, Stanford alpaca: An instruction-following llama model; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vijaymeena M.K., 2016, Machine Learning and Applications.; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]; Wei J., 2022, INT C LEARN REPR; WERBOS PJ, 1988, NEURAL NETWORKS, V1, P339, DOI 10.1016/0893-6080(88)90007-X; Wu SJ, 2023, Arxiv, DOI [arXiv:2303.17564, DOI 10.48550/ARXIV.2303.17564]; Yang H, 2023, arXiv; Yang Y, 2020, Arxiv, DOI arXiv:2006.08097; Zeng AH, 2023, Arxiv, DOI [arXiv:2210.02414, DOI 10.48550/ARXIV.2210.02414]; Zhang Boyu, 2023, arXiv; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]	34	1	1	33	33	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0240-2				2023							349	356		10.1145/3604237.3626866	http://dx.doi.org/10.1145/3604237.3626866			8	Business, Finance; Computer Science, Artificial Intelligence; Computer Science, Interdisciplinary Applications	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Business & Economics; Computer Science	BW2TI		Green Submitted			2024-07-03	WOS:001124982700041
C	He, ZL; Yu, B			Assoc Computing Machinery	He, Zhuolun; Yu, Bei			Large Language Models for EDA: Future or Mirage?	PROCEEDINGS OF THE 2024 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, ISPD 2024			English	Proceedings Paper	33rd ACM International Symposium on Physical Design (ISPD)	MAR 12-15, 2024	Taipei, TAIWAN	Assoc Comp Machinery, ACM Special Interest Grp Design Automat, IEEE Council Elect Design Automat				In this paper, we explore the burgeoning intersection of Large Language Models (LLMs) and Electronic Design Automation (EDA). We critically assess whether LLMs represent a transformative future for EDA or merely a fleeting mirage. By analyzing current advancements, challenges, and potential applications, we dissect how LLMs can revolutionize EDA processes like design, verification, and optimization. Furthermore, we contemplate the ethical implications and feasibility of integrating these models into EDA workflows. Ultimately, this paper aims to provide a comprehensive, evidence-based perspective on the role of LLMs in shaping the future of EDA.	[He, Zhuolun; Yu, Bei] Chinese Univ Hong Kong, Hong Kong, Peoples R China	Chinese University of Hong Kong	He, ZL (corresponding author), Chinese Univ Hong Kong, Hong Kong, Peoples R China.							Blocklove J., 2023, PROC MLCAD; Chang KY, 2023, Arxiv, DOI arXiv:2305.14019; Fu Y., 2023, P ICCAD; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; He Z., 2023, PROC MLCAD; Liu M., 2023, P ICCAD; Liu MJ, 2024, Arxiv, DOI arXiv:2311.00176; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Perez F, 2022, Arxiv, DOI arXiv:2211.09527; Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Tsai YD, 2024, Arxiv, DOI arXiv:2311.16543; Wang YZ, 2023, Arxiv, DOI [arXiv:2212.10560, 10.48550/ARXIV.2212.10560]	12	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0417-8				2024							65	66		10.1145/3626184.3639700	http://dx.doi.org/10.1145/3626184.3639700			2	Computer Science, Hardware & Architecture; Computer Science, Theory & Methods; Engineering, Manufacturing; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BW7AY					2024-07-03	WOS:001187456000010
J	Meng, XB; Yan, XY; Zhang, K; Liu, D; Cui, XJ; Yang, YD; Zhang, MH; Cao, CX; Wang, JJ; Wang, XL; Gao, J; Wang, YGS; Ji, JM; Qiu, ZF; Li, MZ; Qian, C; Guo, TZ; Ma, SQ; Wang, ZY; Guo, ZX; Lei, YL; Shao, CL; Wang, WY; Fan, HJ; Tang, YD				Meng, Xiangbin; Yan, Xiangyu; Zhang, Kuo; Liu, Da; Cui, Xiaojuan; Yang, Yaodong; Zhang, Muhan; Cao, Chunxia; Wang, Jingjia; Wang, Xuliang; Gao, Jun; Wang, Yuan-Geng-Shuo; Ji, Jia-ming; Qiu, Zifeng; Li, Muzi; Qian, Cheng; Guo, Tianze; Ma, Shuangquan; Wang, Zeying; Guo, Zexuan; Lei, Youlan; Shao, Chunli; Wang, Wenyao; Fan, Haojun; Tang, Yi-Da			The application of large language models in medicine: A scoping review	ISCIENCE			English	Review							ARTIFICIAL-INTELLIGENCE; HEALTH-CARE; CHATGPT; RECOMMENDATIONS; FUTURE	This study systematically reviewed the application of large language models (LLMs) in medicine, analyzing 550 selected studies from a vast literature search. LLMs like ChatGPT transformed healthcare by enhancing diagnostics, medical writing, education, and project management. They assisted in drafting medical documents, creating training simulations, and streamlining research processes. Despite their growing utility in assisted diagnosis and improving doctor -patient communication, challenges persisted, including limitations in contextual understanding and the risk of over -reliance. The surge in LLM-related research indicated a focus on medical writing, diagnostics, and patient communication, but highlighted the need for careful integration, considering validation, ethical concerns, and the balance with traditional medical practice. Future research directions suggested a focus on multimodal LLMs, deeper algorithmic understanding, and ensuring responsible, effective use in healthcare.	[Meng, Xiangbin; Wang, Jingjia; Wang, Xuliang; Gao, Jun; Wang, Yuan-Geng-Shuo; Qian, Cheng; Shao, Chunli; Wang, Wenyao; Tang, Yi-Da] Peking Univ Third Hosp, Inst Vasc Med, Dept Cardiol, Beijing, Peoples R China; [Meng, Xiangbin; Tang, Yi-Da] Peking Univ, State Key Lab Vasc Homeostasis & Remodeling, Beijing, Peoples R China; [Yan, Xiangyu; Cao, Chunxia; Fan, Haojun] Tianjin Univ, Inst Disaster & Emergency Med, Tianjin, Peoples R China; [Zhang, Kuo] Chinese Acad Med Sci & Peking Union Med Coll, Fuwai Hosp, Natl Ctr Cardiovasc Dis, Dept Cardiol,State Key Lab Cardiovasc Dis, Beijing, Peoples R China; [Liu, Da] Hebei Med Univ, Hosp 1, Grad Sch, Dept Cardiol, Shijiazhuang, Hebei, Peoples R China; [Cui, Xiaojuan] Peking Univ, Sch Software & Microelect, Beijing, Peoples R China; [Yang, Yaodong; Zhang, Muhan; Ji, Jia-ming] Peking Univ, Inst Artificial Intelligence, Beijing, Peoples R China; [Qiu, Zifeng] Peking Univ, Peking Univ First Hosp, Hlth Sci Ctr, Beijing, Peoples R China; [Li, Muzi] Peking Univ, Peoples Hosp, Hlth Sci Ctr, Beijing, Peoples R China; [Guo, Tianze; Guo, Zexuan; Lei, Youlan] Peking Univ, Hlth Sci Ctr, Beijing, Peoples R China; [Ma, Shuangquan] Beihang Univ, Key Lab Biomech & Mechanobiol, Minist Educ, Sch Biol Sci Med & Engn,Beijing Adv Innovat Ctr Bi, Beijing, Peoples R China; [Wang, Zeying] Peking Univ, Sch & Hosp Stomatol, Natl Engn Lab Digital & Mat Technol Stomatol, Dept Prosthodont,Beijing Key Lab Digital Stomatol,, Beijing, Peoples R China	Peking University; Tianjin University; Chinese Academy of Medical Sciences - Peking Union Medical College; Peking Union Medical College; Fu Wai Hospital - CAMS; Hebei Medical University; Peking University; Peking University; Peking University; Peking University; Peking University; Beihang University; Peking University	Tang, YD (corresponding author), Peking Univ Third Hosp, Inst Vasc Med, Dept Cardiol, Beijing, Peoples R China.; Tang, YD (corresponding author), Peking Univ, State Key Lab Vasc Homeostasis & Remodeling, Beijing, Peoples R China.; Fan, HJ (corresponding author), Tianjin Univ, Inst Disaster & Emergency Med, Tianjin, Peoples R China.	fanhj@tju.edu.cn; tangyida@bjmu.edu.cn		Qiu, zifeng/0000-0002-2384-560X	National Key R&D Program of China [2020YFC2004705]; National Natural Science Foundation of China [81825003, 91957123, 82270376]; CAMS Innovation Fund for Medical Sciences [2022-I2M-CT-B-119, 2021-I2M-5-003]; Beijing Nova Program from Beijing Municipal Science & Technology Commission [Z201100006820002]; CSC Special Fund for Clinical Research [CSCF2021A04]	National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); CAMS Innovation Fund for Medical Sciences; Beijing Nova Program from Beijing Municipal Science & Technology Commission; CSC Special Fund for Clinical Research	This study was funded by the National Key R&D Program of China (2020YFC2004705) , National Natural Science Foundation of China (81825003, 91957123, and 82270376) , CAMS Innovation Fund for Medical Sciences (2022-I2M-C&T-B-119 and 2021-I2M-5-003) , Beijing Nova Program (Z201100006820002) from Beijing Municipal Science & Technology Commission, and CSC Special Fund for Clinical Research (CSCF2021A04) .	Agathokleous E, 2023, SCI TOTAL ENVIRON, V888, DOI 10.1016/j.scitotenv.2023.164154; Ahmadhil A., 2023, AMA Issues New Principles for Use of AI in Medicine; Aiello AE, 2020, ANNU REV PUBL HEALTH, V41, P101, DOI 10.1146/annurev-publhealth-040119-094402; Al Nazi Z, 2023, Arxiv, DOI [arXiv:2401.06775, 10.48550/arXiv.2401.06775]; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Ali T, 2023, Arxiv, DOI [arXiv:2309.16021, DOI 10.48550/ARXIV.2309.16021]; Alowais SA, 2023, BMC MED EDUC, V23, DOI 10.1186/s12909-023-04698-z; [Anonymous], 2023, NAT MED, V29, P505, DOI 10.1038/s41591-023-02289-5; Arachchige ASPM, 2023, EUR J NUCL MED MOL I, V50, P2248, DOI 10.1007/s00259-023-06227-y; Arighi C., 2023, LARGE LANGUAGE MODELS (LLMS) AND CHATGPT FOR BIOMEDICINE (World Scientific), P641; Arora A, 2023, LANCET, V401, P641, DOI 10.1016/S0140-6736(23)00216-7; Ayers JW, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.17517; Azizi Z, 2023, CIRC-ARRHYTHMIA ELEC, V16, P415, DOI 10.1161/CIRCEP.123.012015; Benary M, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.43689; Bernstein IA, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.30320; Blum J, 2023, TRENDS CANCER, V9, P788, DOI 10.1016/j.trecan.2023.06.007; Bowman SR, 2023, Arxiv, DOI arXiv:2304.00612; Butte AJ, 2023, JAMA ONCOL, V9, P1341, DOI 10.1001/jamaoncol.2023.2867; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chen QY, 2024, Arxiv, DOI [arXiv:2305.16326, 10.48550/arXiv.2305.16326, DOI 10.48550/ARXIV.2305.16326]; Cheng KM, 2023, INT J SURG, V109, P2859, DOI 10.1097/JS9.0000000000000521; Cheng KM, 2023, INT J SURG, V109, P2549, DOI 10.1097/JS9.0000000000000451; Daneshjou R, 2021, JAMA DERMATOL, V157, P1362, DOI 10.1001/jamadermatol.2021.3129; Dave T, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1169595; De Angelis L, 2023, FRONT PUBLIC HEALTH, V11, DOI 10.3389/fpubh.2023.1166120; Decker H, 2023, JAMA NETW OPEN, V6, DOI 10.1001/jamanetworkopen.2023.36997; Dias R, 2019, GENOME MED, V11, DOI 10.1186/s13073-019-0689-8; Driess D, 2023, Arxiv, DOI [arXiv:2303.03378, 10.48550/arXiv.2303.03378, DOI 10.48550/ARXIV.2303.03378]; Dunn A., 2022, arXiv; Eisenstein E, 2020, CURR PEDIATR REP, V8, P93, DOI 10.1007/s40124-020-00221-w; Extance A, 2023, NATURE, V623, P474, DOI 10.1038/d41586-023-03507-3; Galido PV, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.38166; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Glukhov D, 2023, Arxiv, DOI [arXiv:2307.10719, 10.48550/arXiv.2307.10719]; González-Sendino R, 2024, FUTURE GENER COMP SY, V155, P384, DOI 10.1016/j.future.2024.02.023; Gu Y., 2023, Plan, Generate and Match: Scientific Workflow Recommendation with Large Language Models, P86; Guvenilir HA, 2023, J CHEMINFORMATICS, V15, DOI 10.1186/s13321-023-00689-w; Han C, 2024, ISCIENCE, V27, DOI 10.1016/j.isci.2024.109022; Hardy M., 2023, Large Language Models Meet Cognitive Science: LLMs as Tools, Models, and Participants, P45; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Harris E, 2023, JAMA-J AM MED ASSOC, V330, P792, DOI 10.1001/jama.2023.14311; Haruna-Cooper L, 2023, J ROY SOC MED, V116, P218, DOI 10.1177/01410768231181251; Hegedus T, 2022, CELL MOL LIFE SCI, V79, DOI 10.1007/s00018-021-04112-1; Hu X., 2023, Empowering Education with Llms-The Next-Gen Interface and Content Generation, P32; Hu ZY, 2023, INNOVATION-AMSTERDAM, V4, DOI 10.1016/j.xinn.2023.100494; Jiang LY, 2023, NATURE, V619, P357, DOI 10.1038/s41586-023-06160-y; Kaneda Y, 2023, QJM-INT J MED, V116, P881, DOI 10.1093/qjmed/hcad099; Kanjee Z, 2023, JAMA-J AM MED ASSOC, V330, P78, DOI 10.1001/jama.2023.8288; Kiros R, 2014, PR MACH LEARN RES, V32, P595; Komorowski M, 2023, INTENS CARE MED, V49, P844, DOI 10.1007/s00134-023-07096-7; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kumar V., 2023, J. Mach. Learn. Model. Comput., V4, P41; Kwok KO, 2023, J TRAVEL MED, V30, DOI 10.1093/jtm/taad058; Lappin S, 2024, J LOGIC LANG INFORM, V33, P9, DOI 10.1007/s10849-023-09409-x; Levac D, 2010, IMPLEMENT SCI, V5, DOI 10.1186/1748-5908-5-69; Li C, 2023, Arxiv, DOI [arXiv:2307.11760, DOI 10.48550/ARXIV.2307.11760, 10.48550/arXiv.2307.11760]; Li R, 2023, JAMA INTERN MED, V183, P596, DOI 10.1001/jamainternmed.2023.1835; Li SW, 2023, AM J OBSTET GYNECOL, V229, DOI 10.1016/j.ajog.2023.04.020; Liu JY, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.107590; Liu XN, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04314-0; Lower K, 2023, INDIAN J ORTHOP, V57, P1527, DOI 10.1007/s43465-023-00967-7; Lu YQ, 2023, INT J SURG, V109, P3217, DOI 10.1097/JS9.0000000000000543; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mann DL, 2023, JACC-BASIC TRANSL SC, V8, P221, DOI 10.1016/j.jacbts.2023.01.001; Miloski B, 2023, FERTIL STERIL, V120, P3, DOI 10.1016/j.fertnstert.2023.05.006; Minssen T, 2023, JAMA-J AM MED ASSOC, V330, P315, DOI 10.1001/jama.2023.9651; Misal D., 2020, Indian Startups Revolutionizing the Healthcare Sector with AI; Munoz-Zuluaga C, 2023, CLIN CHEM, V69, P939, DOI 10.1093/clinchem/hvad058; Nakaura T, 2023, JPN J RADIOL, V41, P457, DOI 10.1007/s11604-023-01408-z; Naveed H, 2024, Arxiv, DOI arXiv:2307.06435; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Peng Cheng, 2023, NPJ Digit Med, V6, P210, DOI 10.1038/s41746-023-00958-w; Preiksaitis C, 2023, NAT MED, V29, P1296, DOI 10.1038/s41591-023-02341-4; Qureshi R, 2023, SYST REV-LONDON, V12, DOI 10.1186/s13643-023-02243-z; Raita Y, 2019, CRIT CARE, V23, DOI 10.1186/s13054-019-2351-7; Robinson J, 2022, Arxiv, DOI [arXiv:2210.12353, 10.48550/arXiv.2210.12353]; Ruksakulpiwat S, 2023, J MULTIDISCIP HEALTH, V16, P1513, DOI 10.2147/JMDH.S413470; Sezgin E, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231186520; Shah NH, 2023, JAMA-J AM MED ASSOC, V330, P866, DOI 10.1001/jama.2023.14217; Sharma P, 2023, NAT REV GASTRO HEPAT, V20, P481, DOI 10.1038/s41575-023-00799-8; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sorin V, 2023, medRxiv, DOI [10.1101/2023.08.07.23293769, 10.1101/2023.08.07.23293769v1, DOI 10.1101/2023.08.07.23293769, 10.1101/2023.08.07.23293769]; Spinewine A, 2021, EUR GERIATR MED, V12, P551, DOI 10.1007/s41999-021-00477-5; Teixeira da Silva JA, 2023, DIAB MET SYND CLIN R, V17, DOI 10.1016/j.dsx.2023.102779; Thapa S, 2023, ANN BIOMED ENG, V51, P2647, DOI 10.1007/s10439-023-03284-0; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Thirunavukarasu AJ, 2023, J ROY SOC MED, V116, P181, DOI 10.1177/01410768231173123; Toufiq M, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04576-8; Tu XM, 2023, Arxiv, DOI [arXiv:2307.02792, 10.48550/arXiv.2307.02792, DOI 10.48550/ARXIV.2307.02792]; Tursunbayeva A, 2023, ASIA PAC J HUM RESOU, V61, P845, DOI 10.1111/1744-7941.12325; Ueda D., 2023, Evaluating GPT-4-Based ChatGPT's Clinical Potential on the NEJM Quiz; Uprety D, 2023, CANCER-AM CANCER SOC, V129, P2284, DOI 10.1002/cncr.34827; Valavanidis A., AlphaFold Protein Structure Database Predicted Millions of 3D Structures; Volpe NJ, 2023, JAMA OPHTHALMOL, V141, P824, DOI 10.1001/jamaophthalmol.2023.3344; Wang JJ, 2024, Arxiv, DOI [arXiv:2307.07221, 10.48550/arXiv.2307.07221]; Ward E, 2023, JAMA INTERN MED, V183, P1030, DOI 10.1001/jamainternmed.2023.2567; Wei JS, 2022, ADV NEUR IN; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wilson Averi E, 2021, Antimicrob Steward Healthc Epidemiol, V1, pe50, DOI 10.1017/ash.2021.225; Yang JF, 2023, Arxiv, DOI [arXiv:2304.13712, DOI 10.48550/ARXIV.2304.13712]; Yang X, 2022, NPJ DIGIT MED, V5, DOI 10.1038/s41746-022-00742-2; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P821, DOI 10.3350/cmh.2023.0183; Zhang L, 2024, Arxiv, DOI [arXiv:2304.14979, 10.48550/arXiv.2304.14979, DOI 10.48550/ARXIV.2304.14979]; Zhang P, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15090286; Zhang T., 2023, Radiol. Sci., V2, P96; Zhang TQ, 2023, INNOVATION-AMSTERDAM, V4, DOI 10.1016/j.xinn.2023.100485; Zhao WX, 2023, Arxiv, DOI [arXiv:2303.18223, DOI 10.48550/ARXIV.2303.18223]; Zhavoronkov A, 2023, NAT MED, V29, P532, DOI 10.1038/d41591-023-00014-w; Zheng ZH, 2023, Arxiv, DOI [arXiv:2308.11584, 10.48550/arXiv.2308.11584]; Zhou ZH, 2023, EUR UROL, V84, P355, DOI 10.1016/j.eururo.2023.03.037; Zhuang Y., 2023, arXiv	112	0	0	9	9	CELL PRESS	CAMBRIDGE	50 HAMPSHIRE ST, FLOOR 5, CAMBRIDGE, MA 02139 USA		2589-0042		ISCIENCE	iScience	MAY 17	2024	27	5							109713	10.1016/j.isci.2024.109713	http://dx.doi.org/10.1016/j.isci.2024.109713			16	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	TI6P0	38746668	gold			2024-07-03	WOS:001240677700001
C	Drápal, J; Westermann, H; Savelka, J		Spanakis, J; VanDijck, G; Sileno, G		Drapal, Jakub; Westermann, Hannes; Savelka, Jaromir			Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies	LEGAL KNOWLEDGE AND INFORMATION SYSTEMS	Frontiers in Artificial Intelligence and Applications		English	Proceedings Paper	36th Annual International Conference on Legal Knowledge and Information Systems (JURIX)	DEC 18-20, 2023	Maastricht Univ, Maastricht, NETHERLANDS	JURIX Fdn Legal Knowledge Based Syst	Maastricht Univ	Thematic analysis; empirical legal studies; criminal law; large language models; generative pre-trained transformers; GPT-4	CLASSIFICATION; SEARCH	Thematic analysis and other variants of inductive coding are widely used qualitative analytic methods within empirical legal studies (ELS). We propose a novel framework facilitating effective collaboration of a legal expert with a large language model (LLM) for generating initial codes (phase 2 of thematic analysis), searching for themes (phase 3), and classifying the data in terms of the themes (to kick-start phase 4). We employed the framework for an analysis of a dataset (n = 785) of facts descriptions from criminal court opinions regarding thefts. The goal of the analysis was to discover classes of typical thefts. Our results show that the LLM, namely OpenAI's GPT-4, generated reasonable initial codes, and it was capable of improving the quality of the codes based on expert feedback. They also suggest that the model performed well in zero-shot classification of facts descriptions in terms of the themes. Finally, the themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts. These findings can be leveraged by legal researchers to guide their decisions in integrating LLMs into their thematic analyses, as well as other inductive coding projects.	[Drapal, Jakub] Czech Acad Sci, Inst State & Law, Prague, Czech Republic; [Drapal, Jakub] Leiden Univ, Inst Criminal Law & Criminol, Leiden, Netherlands; [Westermann, Hannes] Univ Montreal, Cyberjustice Lab, Montreal, PQ, Canada; [Savelka, Jaromir] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA	Czech Academy of Sciences; Institute of State & Law of the Czech Academy of Sciences; Leiden University - Excl LUMC; Leiden University; Universite de Montreal; Carnegie Mellon University	Drápal, J (corresponding author), Czech Acad Sci, Inst State & Law, Prague, Czech Republic.; Drápal, J (corresponding author), Leiden Univ, Inst Criminal Law & Criminol, Leiden, Netherlands.	drapalja@prf.cuni.cz	Savelka, Jaromir/GOK-0488-2022	Savelka, Jaromir/0000-0002-3674-5456; Drapal, Jakub/0000-0001-9455-9013; Westermann, Hannes/0000-0002-4527-7316	Czech Grant Agency [19-15077S]	Czech Grant Agency(Grant Agency of the Czech Republic)	Work supported by Czech Grant Agency project "Sentencing disparities in the post-communist continental legal systems" n. 19-15077S.	ASHLEY KD, 1991, INT J MAN MACH STUD, V34, P753, DOI 10.1016/0020-7373(91)90011-U; Branting LK, 2021, ARTIF INTELL LAW, V29, P213, DOI 10.1007/s10506-020-09273-1; Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [10.1191/1478088706qp063oa, DOI 10.1191/1478088706QP063OA]; Canter DV, 2003, BEHAV SCI LAW, V21, P157, DOI 10.1002/bsl.526; De Paoli S, 2023, Arxiv, DOI [arXiv:2305.13014, 10.48550/arXiv.2305.13014, DOI 10.48550/ARXIV.2305.13014]; Gamieldien Y, 2023, Advancing Qualitative Analysis: An Exploration of the Potential of Generative AI and NLP in Thematic Coding; Gao J, 2024, Arxiv, DOI [arXiv:2304.07366, 10.48550/arXiv.2304.07366, DOI 10.48550/ARXIV.2304.07366]; Gray Morgan A., 2022, LEGAL KNOWLEDGE AND INFORMATION SYSTEMS, P53; Grivna T, 2019, DIGIT INVEST, V28, P1, DOI 10.1016/j.diin.2018.12.002; Higgs T, 2017, AGGRESS VIOLENT BEH, V35, P1, DOI 10.1016/j.avb.2017.05.004; Hornle T, 2013, Law & Contemp Probs, V76, P189; Jiang Jialun Aaron, 2021, Proceedings of the ACM on Human-Computer Interaction, V5, DOI 10.1145/3449168; KITSUSE JI, 1963, SOC PROBL, V11, P131, DOI 10.1525/sp.1963.11.2.03a00020; Natl Acad Sci Engn Med, 2016, MODERNIZING CRIME STATISTICS: REPORT 1-DEFINING AND CLASSIFYING CRIME, P1, DOI 10.17226/23492; OpenAI R, 2023, GPT-4 technical report, P2303; Salaun O., 2022, JURIX, P113; Santtila P., 2004, INT J POLICE SCI MAN, V6, P136, DOI DOI 10.1350/IJPS.6.3.136.39127; Savelka J., 2023, arXiv, DOI [10.1145/3594536.3595161, DOI 10.1145/3594536.3595161]; Savelka J, 2023, FRONT ARTIF INTELL, V6, DOI 10.3389/frai.2023.1279794; Savelka J, 2023, Arxiv, DOI arXiv:2306.13906; Tonry M, 2001, TONRY, Michael Why punish, P239; UNODC LXIV. UNODC, 2015, International classification of crime for statistical purposes; Westermann H, 2020, FRONT ARTIF INTEL AP, V334, P164, DOI 10.3233/FAIA200860; Westermann H, 2019, FRONT ARTIF INTEL AP, V322, P123, DOI 10.3233/FAIA190313; Westermann Hannes, 2019, Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law, P133	25	0	0	6	6	IOS PRESS	AMSTERDAM	NIEUWE HEMWEG 6B, 1013 BG AMSTERDAM, NETHERLANDS	0922-6389	1879-8314	978-1-64368-472-7; 978-1-64368-473-4	FRONT ARTIF INTEL AP			2023	379						197	206		10.3233/FAIA230965	http://dx.doi.org/10.3233/FAIA230965			10	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Information Science & Library Science; Law	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Information Science & Library Science; Government & Law	BW6JJ		Green Submitted, hybrid			2024-07-03	WOS:001175464100025
J	Miao, CY; Hu, JL; Moradkhani, H; Destouni, G				Miao, Chiyuan; Hu, Jinlong; Moradkhani, Hamid; Destouni, Georgia			Hydrological Research Evolution: A Large Language Model-Based Analysis of 310,000 Studies Published Globally Between 1980 and 2023	WATER RESOURCES RESEARCH			English	Editorial Material						hydrological research; bibliometric analysis; large language models; hydrological basins; geographic research assessment; global publications	RIVER; IMPACT; CHALLENGES; PROGRESS; SCIENCE; TRENDS; GIS	Hydrology plays a crucial role in understanding Earth's intricate water system and addressing water-related problems, including against the backdrop of ongoing climate change. A retrospective review of the evolution of hydrology up to the current state of research is of great importance for understanding this role. While there have been some quantitative reviews of large numbers of hydrological publications, there still remains a lack of overarching hydrological research assessment, particularly with the focus on hydrological basins as fundamental spatial-geographic units of hydrological analysis. Large language models, represented by OpenAI's ChatGPT, have demonstrated powerful textual understanding capabilities, making it possible to extract such overarching and basin information from hydrological publications. Here, we considered publications related to hydrology from Web of Science spanning January 1980 to October 2023, and parsed the information from this extensive body of literature by integrating a large language model and geocoding. These techniques enable quantitative analysis of research characteristics across different spatio-temporal scales, focusing on hotspot topics, collaboration networks, and various basins worldwide. Our study revealed an increase in hydrological research since the 1990 s, with shifts in research priorities from groundwater and nutrients to climate change and ecohydrology. Some basins in North America and Europe have consistently been hotspots for hydrological research. Since the 2010s, there has been a noteworthy increase in interest toward basins in China and South Asia, but attention to many regions with frequent extreme rainfall remains insufficient. Geographical patterns show different preferred research topics for different basins, but climate change has emerged as the most prominent topic across all regions in the last decade. In conclusion, our study provides an effective approach to quantitative analysis of research trends, offering a fresh view on the evolution of hydrology as a research field, its focus on various hydrological basins around the world, and the emergence of overarching and basin-specific hot topics over time.	[Miao, Chiyuan; Hu, Jinlong] Beijing Normal Univ, Fac Geog Sci, State Key Lab Earth Surface Proc & Resource Ecol, Beijing, Peoples R China; [Moradkhani, Hamid] Univ Alabama, Dept Civil Construc & Environm Engn, Tuscaloosa, AL USA; [Moradkhani, Hamid] Univ Alabama, Ctr Complex Hydrosyst Res, Tuscaloosa, AL USA; [Destouni, Georgia] Stockholm Univ, Dept Phys Geog, Stockholm, Sweden; [Destouni, Georgia] KTH Royal Inst Technol, Dept Sustainable Dev Environm Sci & Engn, Stockholm, Sweden; [Destouni, Georgia] Stellenbosch Inst Adv Study, Stellenbosch, South Africa	Beijing Normal University; University of Alabama System; University of Alabama Tuscaloosa; University of Alabama System; University of Alabama Tuscaloosa; Stockholm University; Royal Institute of Technology; Stellenbosch University	Miao, CY (corresponding author), Beijing Normal Univ, Fac Geog Sci, State Key Lab Earth Surface Proc & Resource Ecol, Beijing, Peoples R China.	miaocy@bnu.edu.cn	Moradkhani, Hamid/B-1571-2012	Moradkhani, Hamid/0000-0002-2889-999X	National Natural Science Foundation of China; State Key Laboratory of Earth Surface Processes and Resource Ecology [2022-ZD-03]; Fundamental Research Funds for the Central Universities; Swedish Research Council [2022-04672]; Bloke AI for training;  [42342023]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); State Key Laboratory of Earth Surface Processes and Resource Ecology; Fundamental Research Funds for the Central Universities(Fundamental Research Funds for the Central Universities); Swedish Research Council(Swedish Research Council); Bloke AI for training; 	This work was supported by the National Natural Science Foundation of China (42342023), the State Key Laboratory of Earth Surface Processes and Resource Ecology (2022-ZD-03), the Fundamental Research Funds for the Central Universities, and GD also received funding support from the Swedish Research Council (VR, project 2022-04672). We are grateful to the Global Runoff Data Centre for providing the Major River Basins of the World database () and to the Resource and Environment Science and Data Center of the Chinese Academy of Science for providing the global administrative boundary data (). We would like to thank Eric Hartford and Bloke AI for training and quantizing the Wizard-Vicuna-30B-Uncensored model, respectively.	Abrial E, 2021, J HYDROL, V603, DOI 10.1016/j.jhydrol.2021.126957; Akram M., 2021, IPS Interdisciplinary Journal of Biological Sciences, V1, P11, DOI [10.54117/iijbs.v1i1.3, DOI 10.54117/IIJBS.V1I1.3]; Allen M.R., 2018, Special report: Global warming of 1.5  c; Aman MA, 2023, SCI TOTAL ENVIRON, V876, DOI 10.1016/j.scitotenv.2023.162774; Arana-Barbier PJ, 2023, J SCIENTOMETR RES, V12, P596, DOI 10.5530/jscires.12.3.057; Armstrong A, 2012, NAT GEOSCI, V5, P592, DOI 10.1038/ngeo1569; Bechter T, 2018, SCI TOTAL ENVIRON, V628-629, P1191, DOI 10.1016/j.scitotenv.2018.02.084; Bierkens MFP, 2015, WATER RESOUR RES, V51, P4923, DOI 10.1002/2015WR017173; Binley A, 2015, WATER RESOUR RES, V51, P3837, DOI 10.1002/2015WR017016; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Brutsaert W., 2023, Hydrology, V2nd ed; Bürger G, 2011, WATER RESOUR RES, V47, DOI 10.1029/2010WR009716; Cao TZ, 2021, J HYDROL, V603, DOI 10.1016/j.jhydrol.2021.126844; de Morais ES, 2016, GEOMORPHOLOGY, V257, P1, DOI 10.1016/j.geomorph.2015.12.017; Delleur JW, 2003, J HYDRAUL ENG-ASCE, V129, P563, DOI 10.1061/(ASCE)0733-9429(2003)129:8(563); Dinar S, 2015, POLIT GEOGR, V45, P55, DOI 10.1016/j.polgeo.2014.08.003; Dingman S.L., 2015, Physical Hydrology; Dixon H, 2022, HYDROLOG SCI J, V67, P2552, DOI 10.1080/02626667.2020.1764569; Donthu N, 2021, J BUS RES, V133, P285, DOI 10.1016/j.jbusres.2021.04.070; Eagleson P.S., 2005, Ecohydrology: Darwinian expression of vegetation form and function; Forbes WL, 2019, WATER RESOUR RES, V55, P6640, DOI 10.1029/2018WR024256; Frantar E., 2023, arXiv, V2210, DOI [10.48550/arXiv.2210.17323, DOI 10.48550/ARXIV.2210.17323]; Garfield E, 2006, JAMA-J AM MED ASSOC, V295, P90, DOI 10.1001/jama.295.1.90; Global Runoff Data Centre, 2020, Major River basins of the world (version 2nd ed.); Greve P, 2018, NAT SUSTAIN, V1, P486, DOI 10.1038/s41893-018-0134-9; Groesser SN, 2012, SYST RES BEHAV SCI, V29, P624, DOI 10.1002/sres.2142; Hasan MSU, 2020, J CLEAN PROD, V274, DOI 10.1016/j.jclepro.2020.123077; Hirpa FA, 2013, REMOTE SENS ENVIRON, V131, P140, DOI 10.1016/j.rse.2012.11.013; Hu JL, 2023, J HYDROL, V627, DOI 10.1016/j.jhydrol.2023.130369; Hudon C, 2017, BIOGEOCHEMISTRY, V135, P251, DOI 10.1007/s10533-017-0371-4; IPCC, 2023, AR6 Synthesis Report: Climate Change 2023; Jasechko S, 2019, REV GEOPHYS, V57, P835, DOI 10.1029/2018RG000627; Jiang HC, 2016, RENEW SUST ENERG REV, V57, P226, DOI 10.1016/j.rser.2015.12.194; Jiang QS, 2022, J HYDROL, V614, DOI 10.1016/j.jhydrol.2022.128597; Karimiziarani M, 2023, INT J DISAST RISK RE, V95, DOI 10.1016/j.ijdrr.2023.103865; Karimiziarani M, 2023, CLIM RISK MANAG, V39, DOI 10.1016/j.crm.2023.100480; Karimiziarani M, 2022, SUSTAIN CITIES SOC, V77, DOI 10.1016/j.scs.2021.103577; Klaus J, 2013, J HYDROL, V505, P47, DOI 10.1016/j.jhydrol.2013.09.006; Korytny LM, 2017, GEOGR NAT RESOUR, V38, P111, DOI 10.1134/S1875372817020019; Krabbenhoft CA, 2022, NAT SUSTAIN, V5, P586, DOI 10.1038/s41893-022-00873-0; Lin ZY, 2024, COMMUN EARTH ENVIRON, V5, DOI 10.1038/s43247-024-01341-7; Liu LB, 2023, NATURE, V618, P755, DOI 10.1038/s41586-023-06056-x; Minaee S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3439726; Ning LK, 2019, J GEOGR SCI, V29, P465, DOI 10.1007/s11442-019-1610-5; OpenAI AchiamJ., 2024, arXiv, V6, P4, DOI [DOI 10.48550/ARXIV.2303.08774, 10.48550/arXiv.2303.08774]; Pecar-Ilic J, 2006, ENVIRON MODELL SOFTW, V21, P1562, DOI 10.1016/j.envsoft.2006.05.003; Rahman M, 2022, J HYDROL, V614, DOI 10.1016/j.jhydrol.2022.128551; Rajaram H, 2015, WATER RESOUR RES, V51, P7829, DOI 10.1002/2015WR018089; Rodríguez-Navarro A, 2022, SCIENTOMETRICS, V127, P2871, DOI 10.1007/s11192-022-04313-w; Shueb S, 2023, GLOB KNOWL MEM COMMU, DOI 10.1108/GKMC-08-2022-0192; Shuttleworth WJames., 2012, TERRESTRIAL HYDROMET; Silva CHL, 2021, NAT ECOL EVOL, V5, P144, DOI 10.1038/s41559-020-01368-x; Sivapalan M, 2012, HYDROL PROCESS, V26, P1270, DOI 10.1002/hyp.8426; Song J, 2019, NAT ECOL EVOL, V3, P1309, DOI 10.1038/s41559-019-0958-3; Spracklen DV, 2015, GEOPHYS RES LETT, V42, P9546, DOI 10.1002/2015GL066063; Sun J, 2024, COMMUN EARTH ENVIRON, V5, DOI 10.1038/s43247-024-01330-w; Thompson SE, 2013, HYDROL EARTH SYST SC, V17, P5013, DOI 10.5194/hess-17-5013-2013; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Turner RE, 2024, HYDROBIOLOGIA, V851, P1219, DOI 10.1007/s10750-023-05383-4; Udall B, 2017, WATER RESOUR RES, V53, P2404, DOI 10.1002/2016WR019638; Van Dijk A. I. J. M., 2024, Global water monitor 2023, summary report; Van Eck NJ, 2007, INT J UNCERTAIN FUZZ, V15, P625, DOI 10.1142/S0218488507004911; van Eck NJ, 2010, SCIENTOMETRICS, V84, P523, DOI 10.1007/s11192-009-0146-3; Vanham D, 2018, SCI TOTAL ENVIRON, V613, P218, DOI 10.1016/j.scitotenv.2017.09.056; Vaudreuil MA, 2024, SCI TOTAL ENVIRON, V912, DOI 10.1016/j.scitotenv.2023.168680; Waltman L, 2010, J INFORMETR, V4, P629, DOI 10.1016/j.joi.2010.07.002; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Wu XS, 2018, INT J CLIMATOL, V38, P1976, DOI 10.1002/joc.5310; Wu Y, 2024, B AM METEOROL SOC, V105, pE2374, DOI 10.1175/BAMS-D-23-0104.1; Xia J, 2021, J GEOGR SCI, V31, P1085, DOI 10.1007/s11442-021-1886-0; Xu C., 2023, arXiv, V2304, DOI DOI 10.48550/ARXIV.2304.12244; Xu L, 2018, J HYDROL, V563, P76, DOI 10.1016/j.jhydrol.2018.05.061; Xu N, 2021, SAFETY SCI, V138, DOI 10.1016/j.ssci.2021.105216; [徐宗学 Xu Zongxue], 2010, [水科学进展, Advances in Water Science], V21, P450; Zarei M, 2024, EARTHS FUTURE, V12, DOI 10.1029/2023EF003792; Zhao Y, 2019, CATENA, V177, P31, DOI 10.1016/j.catena.2019.02.001; Zheng L., 2023, arXiv, V13, DOI [10.48550/arXiv.2306.05685, DOI 10.48550/ARXIV.2306.05685]; Zhu JJ, 2021, ENVIRON SCI TECHNOL, V55, P3453, DOI 10.1021/acs.est.0c07551; Zill J, 2023, J HYDROL-REG STUD, V50, DOI 10.1016/j.ejrh.2023.101595	79	0	0	4	4	AMER GEOPHYSICAL UNION	WASHINGTON	2000 FLORIDA AVE NW, WASHINGTON, DC 20009 USA	0043-1397	1944-7973		WATER RESOUR RES	Water Resour. Res.	JUN	2024	60	6							e2024WR038077	10.1029/2024WR038077	http://dx.doi.org/10.1029/2024WR038077			18	Environmental Sciences; Limnology; Water Resources	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Marine & Freshwater Biology; Water Resources	UW1P7					2024-07-03	WOS:001251011900001
J	Li, WJ; Hu, AK; Xu, NY; He, GH				Li, Wenjie; Hu, Aokun; Xu, Ningyi; He, Guanghui			Quantization and Hardware Architecture Co-Design for Matrix-Vector Multiplications of Large Language Models	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS			English	Article						Large language models; quantization; hardware architecture; precision-scalable; outlier		Large language models (LLMs) have sparked a new revolution in the field of natural language processing (NLP), and have garnered tremendous attention in both academic research and everyday life, thanks to their unprecedented performance in a wide range of applications. However, their deployment remains a significant challenge, primarily due to their intensive computational and memory requirements. Hardware acceleration and efficient quantization are promising solutions to address the two issues. In this paper, a quantization and hardware architecture co-design is presented for matrix-vector multiplications (MVMs) of LLMs. During quantization, we uniformly group weights and activations to ensure workload balance for hardware. To enhance the performance of quantization, we further propose two approaches called channel sorting and channel selection, which can be applied simultaneously. To support the proposed quantization scheme, we develop two precision-scalable MVM hardware architectures. They are specifically designed for high speed and high energy efficiency, respectively. Experimental results show that our proposed quantization scheme achieves state-of-the-art performance among all the reported post-training schemes that quantize both weights and activations into integers. Compared to MVM architecture of the state-of-the-art LLM accelerator OliVe, our design exhibits significant advantages in terms of area efficiency and energy efficiency.	[Li, Wenjie; Hu, Aokun; Xu, Ningyi] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China; [He, Guanghui] Shanghai Jiao Tong Univ, Dept Micro Nano Elect, Shanghai 200240, Peoples R China; [He, Guanghui] Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China	Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University	Xu, NY (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai 200240, Peoples R China.; He, GH (corresponding author), Shanghai Jiao Tong Univ, Dept Micro Nano Elect, Shanghai 200240, Peoples R China.; He, GH (corresponding author), Shanghai Jiao Tong Univ, MoE Key Lab Artificial Intelligence, Shanghai 200240, Peoples R China.	wenjielinju@sina.com; huaokun@sjtu.edu.cn; xuningyi@sjtu.edu.cn; guanghui.he@sjtu.edu.cn	Li, Wenjie/AAC-2500-2021	Li, Wenjie/0000-0002-1244-7657	National Natural Science Foundation of China	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	No Statement Available	Ashkboos S., 2023, ARXIV; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, arXiv; Chang Y., 2023, arXiv; Chowdhery A., 2022, arXiv; Clark C., 2019, arXiv; Clark P., 2018, ARXIV; Dass J, 2023, INT S HIGH PERF COMP, P415, DOI 10.1109/HPCA56546.2023.10071081; Dettmers T., 2023, ARXIV; Dettmers T., 2023, P INT C MACH LEARN, P7750; Dettmers T., 2022, ADV NEURAL INF PROCE, P30318; Frantar, 2022, ARXIV; Gholami A., 2022, Low-Power Computer Vision, P291; Glorot X., 2011, P 14 INT C ART INT S, P315; Guo C, 2023, CONF PROC INT SYMP C, P33, DOI 10.1145/3579371.3589038; Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247; Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286; Kaplan Jared, 2020, arXiv; Kim S., 2023, arXiv; Kim Y., 2023, P INT C LEARN REPR; Lee, 2023, ARXIV; Lee C., 2023, ARXIV; Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489; Li WJ, 2024, IEEE T COMPUT AID D, V43, P263, DOI 10.1109/TCAD.2023.3310916; Lin Ji, 2023, arXiv; Lin T., 2022, OPEN, V3, P111, DOI DOI 10.1016/J.AIOPEN.2022.10.001; Liu J, 2023, ARXIV; Lu LQ, 2021, INT SYMP MICROARCH, P977, DOI 10.1145/3466752.3480125; Marcus M.P., 1994, P WORKSHOP HUMAN LAN, P114, DOI [10.3115/1075812.1075835, DOI 10.3115/1075812.1075835]; Merity S, 2016, ARXIV; Mihaylov, 2018, ARXIV; OpenAI, 2023, ArXiv; OpenAI, ABOUT US; Paperno D., 2016, ARXIV; Raffel C, 2020, J MACH LEARN RES, V21; Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707; Ryu S, 2022, IEEE J SOLID-ST CIRC, V57, P1924, DOI 10.1109/JSSC.2022.3141050; Schaeffer R., 2023, ARXIV; Shao W., 2023, ARXIV; Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069; Shazeer N., 2020, ARXIV; Sheng Y., 2023, INT C MACH LEARN, P31094; Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740; Tata S, 2003, SSDBM 2002: 15TH INTERNATIONAL CONFERENCE ON SCIENTIFIC AND STATISTICAL DATABASE MANAGEMENT, P141, DOI 10.1109/SSDM.2003.1214975; Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811; Touvron H., 2023, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang HR, 2021, INT S HIGH PERF COMP, P97, DOI 10.1109/HPCA51647.2021.00018; Wei J., 2022, ARXIV; Wei X., 2023, ARXIV; Workshop B., 2022, ARXIV; Xiao G., 2023, INT C MACHINE LEARNI, P38087; Yang J., 2023, ARXIV; Yang JX, 2022, IEEE T CIRCUITS-I, V69, P4069, DOI 10.1109/TCSI.2022.3188899; Yang T, 2023, IEEE T COMPUT AID D, V42, P509, DOI 10.1109/TCAD.2022.3181541; Yuan Z., 2023, ARXIV; Zeng A., 2022, ARXIV; Zhang S., 2022, ARXIV; Zhao WX, 2023, ARXIV; Zhou Z, 2023, IEEE T COMPUT AID D, V42, P136, DOI 10.1109/TCAD.2022.3170848	60	0	0	7	7	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1549-8328	1558-0806		IEEE T CIRCUITS-I	IEEE Trans. Circuits Syst. I-Regul. Pap.	JUN	2024	71	6					2858	2871		10.1109/TCSI.2024.3350661	http://dx.doi.org/10.1109/TCSI.2024.3350661		JAN 2024	14	Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	ST6T1					2024-07-03	WOS:001167326600001
C	Grow, A; Khosmood, F			ACM	Grow, April; Khosmood, Foaad			ChatGPT Game Jam: Unleashing the Power of Large Language Models for Game Jams	PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON GAME JAMS, HACKATHONS AND GAME CREATION EVENTS, ICGJ 2023			English	Proceedings Paper	7th International Conference on Game Jams, Hackathons and Game Creation Events (ICGJ)	AUG 30, 2023	Robert Elvorti Econ & Technol Inst, ELECTR NETWORK	Calif Polytechn State Univ, Global Game Jam	Robert Elvorti Econ & Technol Inst	game jams; LLM; large language models; AI; artificial intelligence; game design; game development		Recently Large Language Models (LLMs) have captivated the imagination in many different fields. OpenAI's ChatGPT, offered the first highly accessible LLM to the users and has seen phenomenal growth since its release in November 2022. While AI tools have always been part of game design and game development, now ChatGPT offers users perhaps for the first time, the ability to create a variety of novel games either entirely or partly by writing a text prompt. ChatGPT is a game jam that embraces and explores LLM-based game production while at the same time providing some insights about the current capabilities and shortcomings of the process. In this paper we report on the process and lessons learned from organizing the first ChatGPT Game Jam - held in May 2023.	[Grow, April; Khosmood, Foaad] Calif Polytech State Univ San Luis Obispo, San Luis Obispo, CA 93407 USA	California State University System; California Polytechnic State University San Luis Obispo	Grow, A (corresponding author), Calif Polytech State Univ San Luis Obispo, San Luis Obispo, CA 93407 USA.	amgrow@calpoly.edu; foaad@calpoly.edu						Agostinelli A., 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.11325; candlesan, 2023, Can AI code Flappy Bird? Watch ChatGPT try; Google, 2023, Bard; itch.io, 2023, Hosting a game jam; Kaitila C., 2012, The Game Jam Survival Guide; Kultima A., 2015, P 10 INT C FDN DIG G; Kultima Annakaisa, 2022, Game JamsHistory, Technology, and Organisation, P21; Lai Gorm, 2021, 6 ANN INT C GAM JAMS, P1; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Meta AI, 2023, LLaMA: Large Language Model Meta AI; Microsoft, 2023, Github Copilot; OpenAI, 2021, DALL-E; OpenAi, 2022, Chatgpt; Pirker Johanna, 2017, P 2 INT C GAM JAMS H, P10; Steinke T., 2016, P INT C GAM JAMS HAC, P15, DOI [DOI 10.1145/2897167.2897173, 10.1145/2897167.2897173]; Wexler Howard, 1974, Connect Four	16	1	1	5	5	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0879-4				2023							51	54		10.1145/3610602.3610605	http://dx.doi.org/10.1145/3610602.3610605			4	Computer Science, Interdisciplinary Applications; Social Sciences, Interdisciplinary	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Social Sciences - Other Topics	BW4GJ					2024-07-03	WOS:001147652300007
J	Quelle, D; Bovet, A				Quelle, Dorian; Bovet, Alexandre			The perils and promises of fact-checking with large language models	FRONTIERS IN ARTIFICIAL INTELLIGENCE			English	Article						fact-checking; misinformation; large language models; human computer interaction; natural language processing; low-resource languages		Automated fact-checking, using machine learning to verify claims, has grown vital as misinformation spreads beyond human fact-checking capacity. Large language models (LLMs) like GPT-4 are increasingly trusted to write academic papers, lawsuits, and news articles and to verify information, emphasizing their role in discerning truth from falsehood and the importance of being able to verify their outputs. Understanding the capacities and limitations of LLMs in fact-checking tasks is therefore essential for ensuring the health of our information ecosystem. Here, we evaluate the use of LLM agents in fact-checking by having them phrase queries, retrieve contextual data, and make decisions. Importantly, in our framework, agents explain their reasoning and cite the relevant sources from the retrieved context. Our results show the enhanced prowess of LLMs when equipped with contextual information. GPT-4 outperforms GPT-3, but accuracy varies based on query language and claim veracity. While LLMs show promise in fact-checking, caution is essential due to inconsistent accuracy. Our investigation calls for further research, fostering a deeper comprehension of when agents succeed and when they fail.	[Quelle, Dorian; Bovet, Alexandre] Univ Zurich, Dept Math Modeling & Machine Learning, Zurich, Switzerland; [Quelle, Dorian; Bovet, Alexandre] Univ Zurich, Digital Soc Initiat, Zurich, Switzerland	University of Zurich; University of Zurich	Quelle, D (corresponding author), Univ Zurich, Dept Math Modeling & Machine Learning, Zurich, Switzerland.; Quelle, D (corresponding author), Univ Zurich, Digital Soc Initiat, Zurich, Switzerland.	dorian.quelle@uzh.ch	Quelle, Dorian/KBQ-6884-2024; Bovet, Alexandre/H-6413-2013	Bovet, Alexandre/0000-0003-3937-3704				Adair B., 2017, P 2017 COMPUTATION J; Augenstein I., 2019, arXiv, DOI [10.18653/v1/D19-1475, DOI 10.18653/V1/D19-1475]; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Bovet A, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-018-07761-2; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Buck C, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3579; Caramancion KM, 2023, Arxiv, DOI arXiv:2306.17176; Chase H., 2022, Langchain; Choi E. C., 2023, arXiv, DOI [10.2139/ssrn.4614239, DOI 10.2139/SSRN.4614239]; Choudhury A, 2023, J MED INTERNET RES, V25, DOI 10.2196/47184; Cuartielles R, 2023, PROF INFORM, V32, DOI 10.3145/epi.2023.sep.15; Das A, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103219; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Espejel JL, 2023, Arxiv, DOI arXiv:2305.12477; Flamino J, 2023, NAT HUM BEHAV, V7, P904, DOI 10.1038/s41562-023-01550-8; Gorrell Genevieve, 2019, P 13 INT WORKSHOP SE, P845, DOI [10.18653/v1/S19-2147, DOI 10.18653/V1/S19-2147]; Graves L., 2016, Digital News Project Report; Grinberg N, 2019, SCIENCE, V363, P374, DOI 10.1126/science.aau2706; Guo ZJ, 2022, T ASSOC COMPUT LING, V10, P178, DOI 10.1162/tacl_a_00454; Hassan N., 2015, P 2015 COMPUTATION J, P1; Hassan N, 2017, PROC VLDB ENDOW, V10, P1945; He P., 2021, arXiv; He P, 2020, ICLR; Hoes E., 2023, PsyArXiv, DOI DOI 10.31234/OSF.IO/QNJKF; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kazemi A., 2022, CEUR Workshop Proceedings; Kohler J., 2022, CEUR Workshop Proceedings; Kotonya N., 2020, P 28 INT C COMPUTATI, P5430, DOI DOI 10.18653/V1/2020.COLINGMAIN.474; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Mantzarlis A., 2018, Fact-Checking 101; Micallef N., 2022, Proceedings of the International AAAI Conference on Web and Social Media, P651; Misra R., 2022, Politifact fact check dataset; Morris DS, 2020, POLIT GROUPS IDENTIT, V8, P986, DOI 10.1080/21565503.2020.1803935; Nakov P., 2022, CEUR WORKSHOP P; Nakov P, 2022, LECT NOTES COMPUT SC, V13390, P495, DOI 10.1007/978-3-031-13643-6_29; Porter E, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2104235118; Quelle D., 2023, arXiv preprint arXiv:2310.18089; Rashkin H, 2017, P 2017 C EMP METH NA, P2931, DOI 10.18653/v1/d17-1317; Reifler J., 2015, Estimating fact-checking's effects; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; Sawinski M., 2023, CEUR Workshop Proceedings; Shaar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3607; Siwakoti S., 2021, How COVID Drove the Evolution of Fact-Checking; Thorne J, 2018, CONFNORTH AM CHAPTER, V1, P809, DOI [10.18653/v1/n18-1074, DOI 10.18653/V1/N18-1074, 10.18653/v1/N18-1074]; Thornton JF, 2018, FACIAL RECONSTRUCTION AFTER MOHS SURGERY, P1; Vaswani A, 2017, ADV NEUR IN, V30; Wadden D, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P7534; Weikum G, 2021, FOUND TRENDS DATABAS, V10, P108, DOI 10.1561/1900000064; World Economic Forum, 2024, The Global Risk Report; Yao SY, 2022, Arxiv, DOI [arXiv:2210.03629, 10.48550/arXiv.2210.03629]; Zeng X, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12438; Zhu WH, 2024, Arxiv, DOI arXiv:2304.04675	52	0	0	5	5	FRONTIERS MEDIA SA	LAUSANNE	AVENUE DU TRIBUNAL FEDERAL 34, LAUSANNE, CH-1015, SWITZERLAND		2624-8212		FRONT ARTIF INTELL	Front. Artif. Intell.	FEB 7	2024	7								1341697	10.3389/frai.2024.1341697	http://dx.doi.org/10.3389/frai.2024.1341697			14	Computer Science, Artificial Intelligence; Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	IV1C3	38384276	Green Submitted, Green Published, gold			2024-07-03	WOS:001169010200001
C	Kim, J; Suh, S; Chilton, LB; Xia, HJ			ACM	Kim, Jeongyeon; Suh, Sangho; Chilton, Lydia B.; Xia, Haijun			Metaphorian: Leveraging Large Language Models to Support Extended Metaphor Creation for Science Writing	DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2023			English	Proceedings Paper	ACM Designing Interactive Systems Conference (DIS) on Rebuilding and Resilience	JUL 10-14, 2023	Pittsburgh, PA	Assoc Comp Machinery		Metaphors; Creativity Support Tools; Science Writing; Writing Support; Large Language Model; GPT-3	WORD DIFFICULTY; FREQUENCY; ANALOGIES	Science writers commonly use extended metaphors to communicate unfamiliar concepts in a more accessible way to a wider audience. However, creating metaphors for science writing is challenging even for professional writers; according to our formative study (n=6), fnding inspiration and extending metaphors with coherent structures were critical yet signifcantly challenging tasks for them. We contribute Metaphorian, a system that supports science writers with the creation of scientifc metaphors by facilitating the search, extension, and iterative revision of metaphors. Metaphorian uses a large language model-based workfow inspired by the heuristic rules revealed from a study with six professional writers. A user study (n=16) revealed that Metaphorian signifcantly enhances satisfaction, confdence, and inspiration in metaphor writing without decreasing writers' sense of agency. We discuss design implications for creativity support for fgurative writing in science.	[Kim, Jeongyeon; Suh, Sangho; Xia, Haijun] Univ Calif San Diego, San Diego, CA 92093 USA; [Chilton, Lydia B.] Columbia Univ, New York, NY USA	University of California System; University of California San Diego; Columbia University	Kim, J (corresponding author), Univ Calif San Diego, San Diego, CA 92093 USA.			Suh, Sangho/0000-0003-4617-5116				Abe Keiga, 2006, P ANN M COGN SCI SOC, V28; Afrin T., 2021, P 2021 CHI C HUM FAC, P1, DOI [10.1145/3411764.3445683, DOI 10.1145/3411764.3445683]; Amershi S, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300233; [Anonymous], From tool to companion: Storywriters want AI writers to respect their personal values and writing strategies, DOI [10.1145/3532106.3533506, DOI 10.1145/3532106.3533506]; Baake Ken., 2012, Metaphor and Knowledge: The Challenges of Writing Science; Bandyopadhyay S., 2022, PROC AAAI C ARTIFICI, V36, P12713, DOI [10.1609/aaai.v36i11.21548, DOI 10.1609/AAAI.V36I11.21548]; Bolukbasi T, 2016, ADV NEUR IN, V29; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Breland HM, 1996, PSYCHOL SCI, V7, P96, DOI 10.1111/j.1467-9280.1996.tb00336.x; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Carston Robyn., 2010, Proceedings of the Aristotelian Society, V110, P295, DOI [DOI 10.1111/J.1467-9264.2010.00288.X, 10.1111/j.1467-9264.2010.00288.x]; Carter S, 2010, TEACH HIGH EDUC, V15, P579, DOI 10.1080/13562517.2010.491904; Chakrabarty T, 2021, Arxiv, DOI arXiv:2103.06779; Chen LQ, 2023, J COMPUT INF SCI ENG, V23, DOI 10.1115/1.4062232; Cherry E, 2014, ACM T COMPUT-HUM INT, V21, DOI 10.1145/2617588; Chung JJY, 2021, PROCEEDINGS OF THE 2021 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2021), P1817, DOI 10.1145/3461778.3462050; Citron FMM, 2014, J COGNITIVE NEUROSCI, V26, P2585, DOI 10.1162/jocn_a_00654; Coll RK, 2005, INT J SCI EDUC, V27, P183, DOI 10.1080/0950069042000276712; COOPER C.R., 1977, EVALUATING WRITING D; Copernicuse, 2022, About us; Crisp P, 2008, LANG LIT, V17, P291, DOI 10.1177/0963947008095960; DAY WHE, 1984, J CLASSIF, V1, P7, DOI 10.1007/BF01890115; Elazar Y, 2021, T ASSOC COMPUT LING, V9, P1012, DOI 10.1162/tacl_a_00410; Eli, 2022, about us; Feldman J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P1173; Fillis Ian, 2005, Creative marketing: An extended metaphor for marketing in a new age; Gagliano A., 2016, Proceedings of the Fifth Workshop on Computational Linguistics for Literature, Association for Computational Linguistics, P20; Gero Katy, 2018, P WORKSH FIG LANG PR, P1, DOI [10.18653/v1/W18-0901, DOI 10.18653/V1/W18-0901]; Gero KI, 2022, PROCEEDINGS OF THE 2022 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE, DIS 2022, P1002, DOI 10.1145/3532106.3533533; Gero KI, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300526; Gilon K, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173695; Glynn SM, 1998, J RES SCI TEACH, V35, P1129, DOI 10.1002/(SICI)1098-2736(199812)35:10<1129::AID-TEA5>3.0.CO;2-2; Goodman SM, 2022, Arxiv, DOI [arXiv:2207.02308, 10.1145/3517428.3544819, DOI 10.1145/3517428.3544819]; He P., 2021, INT C LEARN REPR, DOI [10.48550/arXiv.2006.03654, DOI 10.48550/ARXIV.2006.03654]; Hruschka D.J., 2004, FIELD METHOD, V16, P307, DOI [10.1177/1525822X04266540, DOI 10.1177/1525822X04266540]; Jasper, 2022, US; Jiang ZB, 2020, T ASSOC COMPUT LING, V8, P423, DOI 10.1162/tacl_a_00324; Lakof George, 2008, Metaphors we live by; Lee M, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3502030; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu TY, 2022, Arxiv, DOI arXiv:2104.08704; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; LuminosoInsight, LuminosoInsight/exquisite-corpus: Put together a multi-lingual corpus from a variety of sources. used for wordfreq and word embeddings; Maarten Grootendorst, 2020, Keybert: Minimal keyword extraction with bert, DOI DOI 10.5281/ZENODO.4461265; metamia, 2022, Communication; Morris MR, 2023, Arxiv, DOI arXiv:2304.10547; Naciscione A., 2016, Mixing metaphor, P241; nextgenscience, 2022, Form submission: Topic arrangements of the NGSS; Niebert K, 2012, SCI EDUC, V96, P849, DOI 10.1002/sce.21026; Onarheim B., 2015, Creativity in design: Understanding, V1, P1; Oswald S, 2014, ARGUMENTATION, V28, P133, DOI 10.1007/s10503-013-9304-0; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reimers N, 2019, Arxiv, DOI [arXiv:1908.10084, 10.48550/arXiv.1908.10084]; Remy C, 2020, PROCEEDINGS OF THE 2020 ACM DESIGNING INTERACTIVE SYSTEMS CONFERENCE (DIS 2020), P457, DOI 10.1145/3357236.3395474; Reynolds L, 2021, EXTENDED ABSTRACTS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'21), DOI 10.1145/3411763.3451760; Roemmele Melissa, 2021, arXiv, DOI DOI 10.48550/ARXIV.2107.04007; Rubio-Fernandez P, 2016, J PRAGMATICS, V94, P15, DOI 10.1016/j.pragma.2016.01.005; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Speer Robyn, 2018, Zenodo; Steen GJ, 2010, CONV EVI LANG COMMUN, V14, P1; Stowe K, 2020, Arxiv, DOI arXiv:2002.12854; studio.code, 2012, Teach computer science; Suh S, 2022, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, UIST 2022, DOI 10.1145/3526113.3545617; TAMAYO JM, 1987, EDUC PSYCHOL MEAS, V47, P893, DOI 10.1177/0013164487474004; Terai A, 2010, LECT NOTES COMPUT SC, V6353, P142; Thibodeau PH, 2016, METAPHOR SYMBOL, V31, P53, DOI 10.1080/10926488.2016.1150756; Tsvetkov Y, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P248; Turney Peter, 2011, P 2011 C EMPIRICAL M, P680; upwork, 2015, About us; Van H, 2020, Arxiv, DOI arXiv:2010.10573; Veale T., Thesaurus rex; Veale T., 2007, AAAI, V2007, P1471; Veale T., 2016, SYNTH LECT HUM LANG, V9, P1, DOI DOI 10.2200/S00694ED1V01Y201601HLT031; Werth Paul., 1994, LANG LIT, V3, P79, DOI DOI 10.1177/096394709400300201; wikipedia, 2006, Topics; WILLIAMSWHITNEY D, 1992, J PSYCHOLINGUIST RES, V21, P497; Wu TS, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3517582; Xia Haijun, 2022, L@S '22: Proceedings of the Ninth ACM Conference on Learning @ Scale, P163, DOI 10.1145/3491140.3528279; Yang Q, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300415; Yang ZL, 2019, ADV NEUR IN, V32; Yazdanjoo Shahriyar, 2018, International Journal of English Language and Literature Studies, V7, P32, DOI [10.18488/journal.23.2018.72.32.44, DOI 10.18488/JOURNAL.23.2018.72.32.44]; Yu LX, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1225, DOI 10.1145/2556288.2557378; Yu ZW, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P861; Yuan A, 2022, IUI'22: 27TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P841, DOI 10.1145/3490099.3511105; Zhao TZ, 2021, PR MACH LEARN RES, V139	85	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9893-0				2023							115	135		10.1145/3563657.3595996	http://dx.doi.org/10.1145/3563657.3595996			21	Computer Science, Interdisciplinary Applications; Computer Science, Theory & Methods; Ergonomics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Engineering	BV9SJ		Bronze			2024-07-03	WOS:001090855700008
J	Koga, S; Martin, NB; Dickson, DW				Koga, Shunsuke; Martin, Nicholas B.; Dickson, Dennis W.			Evaluating the performance of large language models: ChatGPT and Google Bard in generating differential diagnoses in clinicopathological conferences of neurodegenerative disorders	BRAIN PATHOLOGY			English	Article						artificial intelligence; ChatGPT; clinicopathological conference; CPC; Google Bard; large language model; neuropathology; pathology		This study explores the utility of the large language models (LLMs), specifically ChatGPT and Google Bard, in predicting neuropathologic diagnoses from clinical summaries. A total of 25 cases of neurodegenerative disorders presented at Mayo Clinic brain bank Clinico-Pathological Conferences were analyzed. The LLMs provided multiple pathologic diagnoses and their rationales, which were compared with the final clinical diagnoses made by physicians. ChatGPT-3.5, ChatGPT-4, and Google Bard correctly made primary diagnoses in 32%, 52%, and 40% of cases, respectively, while correct diagnoses were included in 76%, 84%, and 76% of cases, respectively. These findings highlight the potential of artificial intelligence tools like ChatGPT in neuropathology, suggesting they may facilitate more comprehensive discussions in clinicopathological conferences.	[Koga, Shunsuke; Martin, Nicholas B.; Dickson, Dennis W.] Mayo Clin, Dept Neurosci, Jacksonville, FL USA; [Koga, Shunsuke] Hosp Univ Penn, Dept Pathol & Lab Med, 3400 Spruce St, Philadelphia, PA 19104 USA	Mayo Clinic; University of Pennsylvania	Koga, S (corresponding author), Hosp Univ Penn, Dept Pathol & Lab Med, 3400 Spruce St, Philadelphia, PA 19104 USA.	shunsuke.koga@pennmedicine.upenn.edu	Koga, Shunsuke/AFL-8279-2022	Koga, Shunsuke/0000-0001-8868-9700	ChatGPT	ChatGPT	The author acknowledges that this manuscript was proofread and edited by ChatGPT (GPT-4; OpenAI) on May 30 and July 24, 2023.	Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Biswas S, 2023, ANN BIOMED ENG, V51, P1885, DOI 10.1007/s10439-023-03224-y; Buciuc M, 2023, EUR J NEUROL, V30, P321, DOI 10.1111/ene.15603; Hughes AJ, 2002, BRAIN, V125, P861, DOI 10.1093/brain/awf080; Koga S, 2023, ANN BIOMED ENG, V51, P2123, DOI 10.1007/s10439-023-03253-7; Koga S, 2022, NEUROPATH APPL NEURO, V48, DOI 10.1111/nan.12759; Martin NB, 2023, MOV DISORD CLIN PRAC, V10, P1131, DOI 10.1002/mdc3.13788; Marx GA, 2022, ACTA NEUROPATHOL COM, V10, DOI 10.1186/s40478-022-01457-x; Medenilla A., 2023, PLoS Digital Health, V2; Shakir MN, 2022, J NEUROPATH EXP NEUR, V81, P2, DOI 10.1093/jnen/nlab122	10	19	19	15	40	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	1015-6305	1750-3639		BRAIN PATHOL	Brain Pathol.	MAY	2024	34	3								10.1111/bpa.13207	http://dx.doi.org/10.1111/bpa.13207		AUG 2023	4	Clinical Neurology; Neurosciences; Pathology	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology; Pathology	NK0A1	37553205	Green Published, gold			2024-07-03	WOS:001044510300001
J	Parker, JL; Richard, VM; Becker, K				Parker, Jessica L.; Richard, Veronica M.; Becker, Kimberly			Guidelines for the Integration of Large Language Models in Developing and Refiining Interview Protocols	QUALITATIVE REPORT			English	Article						large language models; interview rotocol; ChatGPT; qualitative research; interview protocol refinement framework		Rapid advancements in generative artificial intelligence (AI), specifically large language models (LLMs), offer unprecedented opportunities and challenges for qualitative researchers. This paper presents comprehensive guidelines for the ethical and effective use of LLMs in the development and refinement of interview protocols. Through a multidisciplinary lens, this paper explores potential pitfalls, ethical considerations, and best practices to ensure the responsible integration of LLMs in the research process. The guidelines proposed serve not only as a methodological roadmap for researchers but also as a catalyst for dialogue on the ethical dimensions of LLMs in qualitative research. Furthermore, the authors describe and share a web-based application developed to guide users through the stages of the protocol. Ultimately, the paper calls for a collective, informed approach to harness the capabilities of LLMs while upholding the integrity and ethical standards of scholarly research.	[Parker, Jessica L.] Massachusetts Coll Pharm & Hlth Sci, Sch Healthcare Business, Boston, MA 02115 USA; [Richard, Veronica M.] Dissertat Design, Raleigh, NC USA; [Becker, Kimberly] Acad Insight Lab, Raleigh, NC USA		Parker, JL (corresponding author), Massachusetts Coll Pharm & Hlth Sci, Sch Healthcare Business, Boston, MA 02115 USA.	jessica.parker@mcphs.edu; veronica@dissertationbydesign.com; kimberly@academicinsightlab.org						AlZaabi A., 2023, bioRxiv, DOI [10.1101/2023.08.17.553688, DOI 10.1101/2023.08.17.553688]; Association for Computing Machinery, 2018, ACM CODE ETHICS PROF; Braun V., 2022, THEMATIC ANAL PRACTI, DOI DOI 10.1007/978-3-319-69909-7_3470-2; Brinkman S., 2018, HDB QUALITATIVE INQU, P576; Brinkmann S., 2015, Interviews, V3; Castillo-Montoya M, 2016, QUAL REP, V21, P811; Dignum V, 2018, ETHICS INF TECHNOL, V20, P1, DOI 10.1007/s10676-018-9450-z; Ellis C, 2007, QUAL INQ, V13, P3, DOI 10.1177/1077800406294947; Foley HC, 2012, RES TECHNOL MANAGE, V55, P12, DOI 10.5437/08956308X5505008; Hall J, 2014, RES TECHNOL MANAGE, V57, P26, DOI 10.5437/08956308X5705250; Jacob SA, 2012, QUAL REP, V17; Khan NU, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su131810288; Lahman M.K. E., 2018, ETHICS SOCIAL SCI RE; Lahman MKE, 2011, QUAL QUANT, V45, P1397, DOI 10.1007/s11135-010-9347-3; Mann SP, 2023, AM J BIOETHICS, V23, P28, DOI 10.1080/15265161.2023.2233356; McAdoo T., 2023, APA Style BlogApril 7; Parker JL, 2023, QUAL REP, V28, P2772, DOI 10.46743/2160-3715/2023.6695; Ramoniene L, 2023, J PHILANTHROPY MARK, V28, DOI 10.1002/nvsm.1788; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rogoff B., 2003, CULTURAL NATURE HUMA	20	0	0	1	1	NOVA SOUTHEASTERN UNIV	FORT LAUDERDALE-DAVIE	3301 COLLEGE AVE, FORT LAUDERDALE-DAVIE, FL 33314 USA	1052-0147	2160-3715		QUAL REP	Qual. Rep.	DEC	2023	28	12								10.46743/2160-3715/2023.6801	http://dx.doi.org/10.46743/2160-3715/2023.6801			17	Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	FQ2Y3		gold			2024-07-03	WOS:001147261500006
J	Lu, Y; Guo, C; Dou, Y; Dai, XY; Wang, FY				Lu, Yue; Guo, Chao; Dou, Yong; Dai, Xingyuan; Wang, Fei-Yue			Could ChatGPT Imagine: Content Control for Artistic Painting Generation Via Large Language Models	JOURNAL OF INTELLIGENT & ROBOTIC SYSTEMS			English	Article						Intelligent systems; Human-machine interactions; Artistic painting generation; Large language model; ChatGPT; Linguistic intelligence	PARALLEL; METAVERSES	Intelligent systems and human-machine interactions have consistently provided convenience in both work and daily life. Artificial Intelligence Generated Content (AIGC) can assist humans in artistic creation by generating painting images based on textual descriptions. However, the quality of generated painting images depends heavily on well-designed prompts, which are labor-intensive and time-consuming in painting creation. Large Language Models (LLMs) like ChatGPT have shown impressive performance in linguistic tasks such as question answering and logical inference, demonstrating strong linguistic intelligence. This paper proposes an assistant painting creation approach to provide precise content control for painting generation by combining LLMs with text-to-image generative models and evaluates the performance of the proposed approach on painting content generation and painting element arrangement. The experimental results show that our approach can provide clear guidance on rich painting content and reasonable arrangements of painting elements, demonstrating its ability of text-based painting scene imagination. In painting generation tasks, LLMs like ChatGPT can help the text-to-image models with precise control over the painting content and improve the overall painting results.	[Lu, Yue] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Peoples R China; [Guo, Chao; Dai, Xingyuan; Wang, Fei-Yue] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China; [Dou, Yong] Macao Univ Sci & Technol, Macao Inst Syst Engn, Macau 999078, Peoples R China	Shandong University; Chinese Academy of Sciences; Institute of Automation, CAS; Macau University of Science & Technology	Wang, FY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing, Peoples R China.	feiyue.wang@ia.ac.cn			This work is supported in part by Skywork Intelligence Culture amp; Technology LTD.; Skywork Intelligence Culture amp; Technology LTD.	This work is supported in part by Skywork Intelligence Culture amp; Technology LTD.; Skywork Intelligence Culture amp; Technology LTD.	This work is supported in part by Skywork Intelligence Culture & Technology LTD.	Antaki F., 2023, medRxiv, P2023; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chen JQ, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01648-7; Dai XY, 2022, FRONT INFORM TECH EL, V23, P1795, DOI 10.1631/FITEE.2200323; Ding BS, 2023, Arxiv, DOI arXiv:2212.10450; do Nascimento LM, 2021, J INTELL ROBOT SYST, V102, DOI 10.1007/s10846-021-01364-8; Fan LL, 2023, IEEE T SYST MAN CY-S, V53, P3485, DOI 10.1109/TSMC.2022.3227209; Frieder S, 2023, Arxiv, DOI arXiv:2301.13867; Guo BY, 2023, Arxiv, DOI [arXiv:2301.07597, DOI 10.48550/ARXIV.2301.07597]; Guo C., 2019, Chin. J. Intell. Sci. Technol, V1, P335; Guo C, 2023, IEEE-CAA J AUTOMATIC, V10, P835, DOI 10.1109/JAS.2023.123555; Guo C, 2023, IEEE T SYST MAN CY-S, V53, P2200, DOI 10.1109/TSMC.2022.3230406; Guo C, 2022, J INTELL ROBOT SYST, V105, DOI 10.1007/s10846-022-01616-1; Guo C, 2020, IEEE INT CON AUTO SC, P673, DOI [10.1109/case48305.2020.9216814, 10.1109/CASE48305.2020.9216814]; Hao Y., 2024, arXiv; Hu W, 2023, Arxiv, DOI arXiv:2307.06983; Ishihara Y, 2021, J INTELL ROBOT SYST, V103, DOI 10.1007/s10846-021-01465-4; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Jiao WX, 2023, Arxiv, DOI [arXiv:2301.08745, DOI 10.48550/ARXIV.2301.08745]; Kang MZ, 2023, IEEE T SYST MAN CY-S, V53, P3718, DOI 10.1109/TSMC.2022.3230830; Karimov A, 2023, J INTELL ROBOT SYST, V107, DOI 10.1007/s10846-023-01831-4; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Li JJ, 2023, IEEE T SYST MAN CY-S, V53, P3389, DOI 10.1109/TSMC.2022.3226748; Li XX, 2024, Arxiv, DOI [arXiv:2212.10529, DOI 10.48550/ARXIV.2212.10529, 10.48550/arXiv.2212.10529]; Liu HL, 2022, J INTELL ROBOT SYST, V104, DOI 10.1007/s10846-021-01564-2; Liu KH, 2023, IEEE T SYST MAN CY-S, V53, P3858, DOI 10.1109/TSMC.2022.3233588; Liu VV, 2022, PROCEEDINGS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI' 22), DOI 10.1145/3491102.3501825; Lu JW, 2022, IEEE-CAA J AUTOMATIC, V9, P2079, DOI 10.1109/JAS.2022.106094; LU J, 2022, FRONT INFORM TECH EL, V23, P991, DOI 10.1631/FITEE.2240000; Lu Y, 2023, IEEE INTELL SYST, V38, P31, DOI 10.1109/MIS.2023.3260992; Lu Y, 2024, IEEE T COMPUT SOC SY, V11, P576, DOI 10.1109/TCSS.2022.3223539; Lu Y, 2022, NEUROCOMPUTING, V490, P163, DOI 10.1016/j.neucom.2022.01.068; [鲁越 Lu Yue], 2020, [自动化学报, Acta Automatica Sinica], V46, P2239; Mitrovic Sandra, 2023, arXiv; Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954; Oppenlaender J, 2023, Arxiv, DOI arXiv:2204.13988; Ouyang L., 2022, Advances in Neural Information Processing Systems; Qiao SF, 2023, Arxiv, DOI [arXiv:2212.09597, DOI 10.48550/ARXIV.2212.09597]; Radford A, 2021, PR MACH LEARN RES, V139; Ramesh A., 2022, arXiv; Ramesh P, 2022, 38 INT C MACHINE LEA; Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042; Saharia Chitwan, 2022, Advances in Neural Information Processing Systems; Shen Y, 2022, IEEE-CAA J AUTOMATIC, V9, P2047, DOI 10.1109/JAS.2022.106115; Song HF, 2022, J INTELL ROBOT SYST, V106, DOI 10.1007/s10846-022-01652-x; Strathearn C, 2021, J INTELL ROBOT SYST, V101, DOI 10.1007/s10846-021-01332-2; Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899; Wang F.-Y., 2017, Parallel art: From intelligent art to artistic intelligence; Wang Fei-yue, 2004, Control and Decision, V19, P485; Wang FY, 2023, IEEE-CAA J AUTOMATIC, V10, P575, DOI 10.1109/JAS.2023.123486; Wang FY, 2022, FRONT INFORM TECH EL, V23, P1142, DOI 10.1631/FITEE.2100418; Wang J., 2022, IEEE Trans. Syst. Man Cybern. Syst., P1; Wang KF, 2017, ARTIF INTELL REV, V48, P299, DOI 10.1007/s10462-017-9569-z; Wang X., 2022, IEEE Trans. Syst. Man Cybern. Syst., P1; Wang XJ, 2022, IEEE-CAA J AUTOMATIC, V9, P2055, DOI 10.1109/JAS.2022.106103; Wang Y., 2022, IEEE Trans. Syst. Man Cybern. Syst., P1; Wang YL, 2023, Arxiv, DOI arXiv:2302.09466; Wang YT, 2022, IEEE-CAA J AUTOMATIC, V9, P2071, DOI 10.1109/JAS.2022.106091; Wei J., 2022, Advances in Neural Information Processing Systems, V35, P24824; Yang J, 2022, IEEE-CAA J AUTOMATIC, V9, P2063, DOI 10.1109/JAS.2022.106097; Ye PJ, 2022, FRONT INFORM TECH EL, V23, P1765, DOI 10.1631/FITEE.2100335; Yue Lu, 2021, 2021 IEEE 1st International Conference on Digital Twins and Parallel Intelligence (DTPI), P156, DOI 10.1109/DTPI52967.2021.9540081; Zhang B, 2021, Arxiv, DOI arXiv:2104.03133; Zhang H., 2022, IEEE T SYST MAN CY-S, P1; Zhou J, 2024, FRONT INFORM TECH EL, V25, P6, DOI 10.1631/FITEE.2300089; Zhu BH, 2024, Arxiv, DOI arXiv:2301.11270	68	0	0	106	170	SPRINGER	DORDRECHT	VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS	0921-0296	1573-0409		J INTELL ROBOT SYST	J. Intell. Robot. Syst.	OCT	2023	109	2							39	10.1007/s10846-023-01956-6	http://dx.doi.org/10.1007/s10846-023-01956-6			15	Computer Science, Artificial Intelligence; Robotics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Robotics	U3DA1					2024-07-03	WOS:001083626300001
C	Ilagan, JB; Ilagan, JR		Shih, JL; Kashihara, A; Chen, W; Ogata, H		Ilagan, Joseph Benjamin; Ilagan, Jose Ramon			A prototype of a chatbot for evaluating and refining student startup ideas using a large language model	31ST INTERNATIONAL CONFERENCE ON COMPUTERS IN EDUCATION, ICCE 2023, VOL II			English	Proceedings Paper	31st International Conference on Computers in Education (ICCE)	DEC 04-08, 2023	Kyoto Univ, Matsue, JAPAN	Learning & Educ Technologies Res Unit, Res Council Evidence Driven Educ, Asia Pacific Soc Comp Educ, Uchida Yoko Co Ltd, Photron Ltd	Kyoto Univ	startups; business model; chatbot; startup panelist; simulation; conversational intelligent tutoring system; large language model; LLM; GPT		Assessing the soundness of business models is a critical skill for aspiring entrepreneurs and is an essential part of entrepreneurship education. However, evaluating business models can be time-consuming, costly, and subjective. This study describes the design and the prototype of a chatbot as a conversational intelligent tutoring system that assesses and gives feedback on business model soundness using natural language processing techniques and GPT-3.5, a large language model (LLM) trained by OpenAl, to help student co-founders learn and refine their startup ideas. Our method involves indexing articles and rubrics for evaluating technology startup pitches by extracting word embeddings via the OpenAl API. The chatbot accepts descriptions of startup businesses from student co-founders through a Telegram chatbot, and these are formatted as prompts and then fed into GPT-3.5. The responses are formulated by GPT-3 based on another set of prompts instructing the bot to give feedback from three virtual panelists: 1) a harsh judge, 2) a neutral expert, and 3) an optimistic investor.	[Ilagan, Joseph Benjamin; Ilagan, Jose Ramon] Ateneo Manila Univ, Quezon City, Philippines	Ateneo de Manila University	Ilagan, JB (corresponding author), Ateneo Manila Univ, Quezon City, Philippines.	jbilagan@ateneo.edu		Ilagan, Joseph Benjamin/0000-0002-3748-6468				Almeida F, 2018, ENCYCLOPEDIA OF INFORMATION SCIENCE AND TECHNOLOGY, 4TH EDITION, P800, DOI 10.4018/978-1-5225-2255-3.ch069; ANDERSON JR, 1985, SCIENCE, V228, P456, DOI 10.1126/science.228.4698.456; Atlas S., 2023, Chatgpt for higher education and professional development: A guide to conversational ai; Baidoo-Anu David, 2023, Education in the era of generative artificial intelligence (ai): Understanding the potential benefits of chatgpt in promoting teaching and learning, DOI DOI 10.2139/SSRN.4337484; Beltagy I., 2022, P 60 ANN M ASS COMP, P32, DOI [10.18653/v1/2022.ac1-tutorials.6, DOI 10.18653/V1/2022.AC1-TUTORIALS.6]; Blank S, 2013, HARVARD BUS REV, V91, P64; Bragg Jonathan, 2021, Advances in Neural Information Processing Systems, V34, P15787; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Cai ZQ, 2019, LECT NOTES COMPUT SC, V11597, P593, DOI 10.1007/978-3-030-22341-0_46; Chase H., 2022, Langchain; Cooper G, 2023, J SCI EDUC TECHNOL, V32, P444, DOI 10.1007/s10956-023-10039-y; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Fayolle Alain, 2008, Journal of European Industrial Training, V32, P569, DOI 10.1108/03090590810899838; Floridi L, 2020, MIND MACH, V30, P681, DOI 10.1007/s11023-020-09548-1; Gao T., 2021, The Gradient; Holmes M., 2017, IFIP Advances in Information and Communication Technology, V515, P251, DOI [10.1007/978-3-319-74310-3_27, DOI 10.1007/978-3-319-74310-3_27]; Ilagan J. B, 2022, The design and use of agent-based modeling computer simulation for teaching technology entrepreneurship; Introducing ChatGPT, 2023, OpenAl; Matlay H., 2002, International Journal of Entrepreneurship and Innovation, V3, P7; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Ott S, 2023, Arxiv, DOI [arXiv:2301.11596, DOI 10.48550/ARXIV.2301.11596]; Qin CW, 2023, Arxiv, DOI arXiv:2302.06476; Rahaman M. S., 2023, Emergence of Entrepreneurial Research; Ross R. B., 2011, Journal on Chain and Network Science, V11, P19, DOI 10.3920/JCNS2011.x193; Sharath JS, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206698; Shanahan M, 2022, Arxiv, DOI arXiv:2212.03551; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Trivedi H, 2023, Arxiv, DOI [arXiv:2212.10509, 10.48550/arXiv.2212.10509, DOI 10.48550/ARXIV.2212.10509]; VanLehn K, 2011, EDUC PSYCHOL-US, V46, P197, DOI 10.1080/00461520.2011.611369; Vaswani A, 2017, ADV NEUR IN, V30; Wang Boshi, 2022, P 2022 C EMP METH NA, P2714; Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252; Wei MZ, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/9180933; Zhai X., 2022, ChatGPT User Experience: Implications for Education, DOI [10.2139/ssrn.4312418, DOI 10.2139/SSRN.4312418]; Zhao TZ, 2021, PR MACH LEARN RES, V139	35	0	0	0	0	ASIA PACIFIC SOC COMPUTERS IN EDUCATION - APSCE	TAOYUAN CITY	NO 300, JUNGDA RD, JHONGLI DISTRICT, TAOYUAN CITY, 320, TAIWAN			978-626-968-902-6				2023							2	7						6	Computer Science, Interdisciplinary Applications; Computer Science, Software Engineering; Education, Scientific Disciplines	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Education & Educational Research	BW7KI					2024-07-03	WOS:001191920400001
C	Dugar, M; Asesh, A		Cardona, M; Solanki, VK		Dugar, Meenal; Asesh, Aishwarya			Spatial Interpretation and LLMs	2023 IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLIED NETWORK TECHNOLOGIES, ICMLANT			English	Proceedings Paper	IEEE International Conference on Machine Learning and Applied Network Technologies (ICMLANT)	DEC 14-15, 2023	ELECTR NETWORK	IEEE, Univ Don Bosco El Salvador, IEEE El Salvador Sect		Spatial Reasoning; Large Language Models (LLMs); Visual Question Answering (VQA); Ethical Considerations; Model Transparency; Natural Language Processing (NLP); Bias Mitigation		The research work delves into the Spatial Reasoning capabilities of Large Language Models (LLMs) within the framework of Visual Question Answering (VQA). By employing rigorous methodologies, we assess LLM proficiency in discerning spatial relationships from visual stimuli. We highlight the models' strengths and pinpoint areas of improvement, emphasizing ethical dimensions encompassing bias, privacy, and transparency. Our findings provide valuable insights into LLM potential and pave the way for enhancements in Natural Language Processing (NLP) research.	[Dugar, Meenal; Asesh, Aishwarya] Univ Penn, Salt Lake City, UT 19104 USA		Dugar, M (corresponding author), Univ Penn, Salt Lake City, UT 19104 USA.	meenal.dugar@utah.edu; a.asesh@gmail.com						Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279; Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]; Burnell R, 2023, SCIENCE, V380, P136, DOI 10.1126/science.adf6369; Chen J, 2015, KNOWL ENG REV, V30, P106, DOI 10.1017/S0269888913000350; Cohn AG, 2008, FOUND ARTIF INTELL, P551, DOI 10.1016/S1574-6526(07)03013-1; Cohn AG, 2023, Arxiv, DOI arXiv:2304.11164; Davis E, 2023, Arxiv, DOI [arXiv:2302.04752, DOI 10.48550/ARXIV.2302.04752]; Grunde-McLaughlin M, 2021, PROC CVPR IEEE, P11282, DOI 10.1109/CVPR46437.2021.01113; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; Hayes P.J., 1985, Formal Theories of the Commonsense World; Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686; Lin FZ, 2023, Arxiv, DOI arXiv:2304.01771; Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48; Liu FY, 2022, Arxiv, DOI arXiv:2205.00363; Liu X., 2022, arXiv; Mirzaee R, 2021, Arxiv, DOI arXiv:2104.05832; Parcalabescu L., 2021, arXiv; Peng BL, 2023, Arxiv, DOI [arXiv:2304.03277, 10.48550/arXiv.2304.03277]; Tan H, 2019, Arxiv, DOI [arXiv:1908.07490, 10.48550/arXiv.1908.07490]; Ullman TD, 2023, Arxiv, DOI [arXiv:2302.08399, DOI 10.48550/ARXIV.2302.08399]; Wu C., 2023, Visual ChatGPT: talking, drawing and editing with visual foundation models; Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7; Zerroug A, 2022, Arxiv, DOI arXiv:2206.05379; Zhu D., 2023, Minigpt-4: Enhancing vision-language understanding with advanced large language models	24	0	0	4	4	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-0391-9				2023							23	28		10.1109/ICMLANT59547.2023.10372976	http://dx.doi.org/10.1109/ICMLANT59547.2023.10372976			6	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5IE					2024-07-03	WOS:001161329500005
J	Li, C; Qiu, JB; Huang, HP				Li, Chan; Qiu, Junbin; Huang, Haiping			Meta predictive learning model of languages in neural circuits	PHYSICAL REVIEW E			English	Article								Large language models based on self-attention mechanisms have achieved astonishing performances, not only in natural language itself, but also in a variety of tasks of different nature. However, regarding processing language, our human brain may not operate using the same principle. Then, a debate is established on the connection between brain computation and artificial self-supervision adopted in large language models. One of most influential hypotheses in brain computation is the predictive coding framework, which proposes to minimize the prediction error by local learning. However, the role of predictive coding and the associated credit assignment in language processing remains unknown. Here, we propose a mean-field learning model within the predictive coding framework, assuming that the synaptic weight of each connection follows a spike and slab distribution, and only the distribution, rather than specific weights, is trained. This meta predictive learning is successfully validated on classifying handwritten digits where pixels are input to the network in sequence, and moreover, on the toy and real language corpus. Our model reveals that most of the connections become deterministic after learning, while the output connections have a higher level of variability. The performance of the resulting network ensemble changes continuously with data load, further improving with more training data, in analogy with the emergent behavior of large language models. Therefore, our model provides a starting point to investigate the connection among brain computation, next-token prediction, and general intelligence.	[Li, Chan; Qiu, Junbin; Huang, Haiping] Sun Yat Sen Univ, Sch Phys, PMI Lab, Guangzhou 510275, Peoples R China; [Li, Chan] Univ Calif San Diego, Dept Phys, 9500 Gilman Dr, La Jolla, CA 92093 USA; [Huang, Haiping] Sun Yat Sen Univ, Guangdong Prov Key Lab Magnetoelect Phys & Device, Guangzhou 510275, Peoples R China	Sun Yat Sen University; University of California System; University of California San Diego; Sun Yat Sen University	Huang, HP (corresponding author), Sun Yat Sen Univ, Guangdong Prov Key Lab Magnetoelect Phys & Device, Guangzhou 510275, Peoples R China.	huanghp7@mail.sysu.edu.cn		Huang, Haiping/0000-0001-8757-4733	National Natural Sci- ence Foundation of China [12122515]; Guangdong Provincial Key Laboratory of Magnetoelectric Physics and Devices [2022B1212010008]; Guangdong Basic and Applied Basic Research Foundation [2023B1515040023]	National Natural Sci- ence Foundation of China(National Natural Science Foundation of China (NSFC)); Guangdong Provincial Key Laboratory of Magnetoelectric Physics and Devices; Guangdong Basic and Applied Basic Research Foundation	<BOLD>Acknowledgments</BOLD> This research was supported by the National Natural Sci- ence Foundation of China for Grant No. 12122515 (H.H.) , Guangdong Provincial Key Laboratory of Magnetoelectric Physics and Devices (Grant No. 2022B1212010008) , and Guangdong Basic and Applied Basic Research Foundation (Grant No. 2023B1515040023) .	Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473; Barbour B, 2007, TRENDS NEUROSCI, V30, P622, DOI 10.1016/j.tins.2007.09.005; Bastos AM, 2012, NEURON, V76, P695, DOI 10.1016/j.neuron.2012.10.038; Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Caucheteux C, 2022, COMMUN BIOL, V5, DOI 10.1038/s42003-022-03036-1; Chen YS, 2024, bioRxiv, DOI [10.1101/2022.05.19.492731, 10.1101/2022.05.19.492731, DOI 10.1101/2022.05.19.492731]; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]; Faisal AA, 2008, NAT REV NEUROSCI, V9, P292, DOI 10.1038/nrn2258; Friston K, 2018, NAT NEUROSCI, V21, P1019, DOI 10.1038/s41593-018-0200-7; github, About us; Golkar S., 2022, Advances in Neural Information Processing Systems, V35, P14155; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Huang H., 2022, Statistical Mechanics of Neural Networks; Huang HP, 2023, Arxiv, DOI arXiv:2306.11232; Huang HP, 2018, J PHYS A-MATH THEOR, V51, DOI 10.1088/1751-8121/aaa631; Huang YP, 2011, WIRES COGN SCI, V2, P580, DOI 10.1002/wcs.142; Huang ZY, 2024, Arxiv, DOI arXiv:2302.11681; Kaplan J, 2020, Arxiv, DOI [arXiv:2001.08361, DOI 10.48550/ARXIV.2001.08361]; Kasai H, 2021, NAT REV NEUROSCI, V22, P407, DOI 10.1038/s41583-021-00467-3; Katharopoulos A, 2020, PR MACH LEARN RES, V119; Kingma D. P., 2017, ARXIV; Lakretz Y, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P11; LeCun Y., MNIST DATABASE HANDW; Li C, 2020, PHYS REV LETT, V125, DOI 10.1103/PhysRevLett.125.178301; Luo LQ, 2021, SCIENCE, V373, P1103, DOI 10.1126/science.abg7285; Mahowald K., 2024, Trends Cognitive Sci.; Marcus M.P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Millidge B., 2022, P 31 INT JOINT C ART, P5538, DOI 10.24963/ijcai.2022/774; Millidge B., 2021, arXiv, DOI DOI 10.48550/ARXIV.2107.12979; Pinchetti L., 2022, Advances in Neural Information Processing Systems, V35, P1280; Pouget A, 2013, NAT NEUROSCI, V16, P1170, DOI 10.1038/nn.3495; Rao RPN, 1999, NAT NEUROSCI, V2, P79, DOI 10.1038/4580; Rosenbaum R, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266102; Sacramento J, 2018, ADV NEUR IN, V31; Salvatori T, 2023, Arxiv, DOI arXiv:2308.07870; Salvatori T, 2021, Arxiv, DOI arXiv:2103.03725; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173; Vaswani A, 2017, ADV NEUR IN, V30; Wang L, 2023, CEREB CORTEX, V33, P4478, DOI 10.1093/cercor/bhac356; Wei J, 2022, Trans. Mach. Learn. Res.; Whittington JCR, 2017, NEURAL COMPUT, V29, P1229, DOI 10.1162/NECO_a_00949; Zhao Jie, 2023, 2023 International Symposium of Electronics Design Automation (ISEDA), P219, DOI 10.1109/ISEDA59274.2023.10218491; Zou WX, 2023, PHYS REV E, V107, DOI 10.1103/PhysRevE.107.024307; Zucchet N, 2024, Arxiv, DOI arXiv:2309.01775	48	0	0	0	0	AMER PHYSICAL SOC	COLLEGE PK	ONE PHYSICS ELLIPSE, COLLEGE PK, MD 20740-3844 USA	2470-0045	2470-0053		PHYS REV E	Phys. Rev. E	APR 12	2024	109	4							044309	10.1103/PhysRevE.109.044309	http://dx.doi.org/10.1103/PhysRevE.109.044309			14	Physics, Fluids & Plasmas; Physics, Mathematical	Science Citation Index Expanded (SCI-EXPANDED)	Physics	QI5G3	38755909				2024-07-03	WOS:001220254100005
J	van Diessen, E; van Amerongen, RA; Zijlmans, M; Otte, WM				van Diessen, Eric; van Amerongen, Ramon A.; Zijlmans, Maeike; Otte, Willem M.			Potential merits and flaws of large language models in epilepsy care: A critical review	EPILEPSIA			English	Review						diagnosing epilepsy; large language models; natural language processing	ILAE CLASSIFICATION; ANTIEPILEPTIC DRUGS; NONADHERENCE; DIAGNOSIS	The current pace of development and applications of large language models (LLMs) is unprecedented and will impact future medical care significantly. In this critical review, we provide the background to better understand these novel artificial intelligence (AI) models and how LLMs can be of future use in the daily care of people with epilepsy. Considering the importance of clinical history taking in diagnosing and monitoring epilepsy-combined with the established use of electronic health records-a great potential exists to integrate LLMs in epilepsy care. We present the current available LLM studies in epilepsy. Furthermore, we highlight and compare the most commonly used LLMs and elaborate on how these models can be applied in epilepsy. We further discuss important drawbacks and risks of LLMs, and we provide recommendations for overcoming these limitations.	[van Diessen, Eric; Otte, Willem M.] Univ Med Ctr Utrecht, UMC Utrecht Brain Ctr, Dept Child Neurol, Room KG 01-310-0,POB 85090, NL-3508 AB Utrecht, Netherlands; [van Diessen, Eric; Zijlmans, Maeike; Otte, Willem M.] Univ Utrecht, Room KG 01-310-0,POB 85090, NL-3508 AB Utrecht, Netherlands; [van Diessen, Eric] Franciscus Gasthuis & Vlietland, Dept Pediat, Rotterdam, Netherlands; [van Amerongen, Ramon A.] Univ Utrecht, Fac Sci Bioinformat & Biocomplex, Utrecht, Netherlands; [Zijlmans, Maeike] Univ Med Ctr Utrecht, UMC Utrecht Brain Ctr, Dept Neurol & Neurosurg, Utrecht, Netherlands; [Zijlmans, Maeike] Stichting Epilepsie Instellingen Nederland, Heemstede, Netherlands	Utrecht University; Utrecht University Medical Center; Utrecht University; Franciscus Gasthuis; Utrecht University; Utrecht University; Utrecht University Medical Center	van Diessen, E (corresponding author), Univ Med Ctr Utrecht, UMC Utrecht Brain Ctr, Dept Child Neurol, Room KG 01-310-0,POB 85090, NL-3508 AB Utrecht, Netherlands.; van Diessen, E (corresponding author), Univ Utrecht, Room KG 01-310-0,POB 85090, NL-3508 AB Utrecht, Netherlands.	e.vandiessen-3@umcutrecht.nl	; Otte, Wim/I-1228-2013	van Diessen, Eric/0000-0002-7773-1990; Otte, Wim/0000-0003-1511-6834; Zijlmans, Maeike/0000-0003-1258-5678	EWUU grant "AI for Health" (2021) [2021]; EWUU grant "AI for Health"	EWUU grant "AI for Health" (2021); EWUU grant "AI for Health"	This research was supported by the EWUU grant "AI for Health" (2021). We thank the anonymous reviewers for constructive feedback.	Al-aqeel S, 2020, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD008312.pub4; Alec Radford Karthik Narasimhan Tim Salimans Ilya Sutskever, 2018, IMPROVING LANGUAGE U; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Amodei D., 2016, Concrete problems in ai safety; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bai Y., 2022, 2204.05862; Bano M., 2023, ALL OPERATIONALISING; Beaulieu-Jones BK, 2023, LANCET DIGIT HEALTH, V5, pE882, DOI 10.1016/S2589-7500(23)00179-6; Beghi E, 2018, EXPERT REV NEUROTHER, V18, P179, DOI 10.1080/14737175.2018.1427066; Bosselmann CM, 2023, EPILEPSIA, V64, P1195, DOI 10.1111/epi.17570; Brigo F, 2015, EPILEPSY BEHAV, V44, P35, DOI 10.1016/j.yebeh.2014.12.029; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Bubeck S., 2023, Sparks of artificial general intelligence: Early experiments with gpt-4; Buchlak Quinlan D, 2022, Acta Neurochir Suppl, V134, P277, DOI 10.1007/978-3-030-85292-4_32; Carlini N., 2022, ADV NEURAL INF PROCE, V35, P13263; Cavalleri Gianpiero L, 2017, Biomed Hub, V2, P137, DOI 10.1159/000481793; Connolly B, 2014, J AM MED INFORM ASSN, V21, P866, DOI 10.1136/amiajnl-2013-002601; Cronin W, 2023, EPILEPSIA OPEN, V8, P758, DOI 10.1002/epi4.12766; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Davis KL, 2008, EPILEPSIA, V49, P446, DOI 10.1111/j.1528-1167.2007.01414.x; Decker BM, 2022, SEIZURE-EUR J EPILEP, V101, P48, DOI 10.1016/j.seizure.2022.07.010; Decker BM, 2021, SEIZURE-EUR J EPILEP, V85, P138, DOI 10.1016/j.seizure.2020.11.011; Devlin J., 2018, BERT PRE TRAINING DE; Dratsch T, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.222176; Driess D., 2023, PALM E EMBODIED MULT; Faught E, 2008, NEUROLOGY, V71, P1572, DOI 10.1212/01.wnl.0000319693.10338.b9; Fonferko-Shadrach B, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-023232; Friedman C, 2013, J BIOMED INFORM, V46, P765, DOI 10.1016/j.jbi.2013.06.004; Fu SY, 2020, J BIOMED INFORM, V109, DOI 10.1016/j.jbi.2020.103526; Ganapini MB., 2022, COMBINING FAST SLOW; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Gottlieb S, 2023, JAMA-HEALTH FORUM, V4, DOI 10.1001/jamahealthforum.2023.3909; Hagendorff T., 2022, METHODOLOGICAL REFLE; Hakeem H, 2022, JAMA NEUROL, V79, P986, DOI 10.1001/jamaneurol.2022.2514; Huang P-S., 2019, FINDINGS ASS COMPUTA; Huang S., 2023, LANGUAGE IS NOT ALL; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang KL, 2023, EPILEPTIC DISORD, V25, P28, DOI 10.1002/epd2.20036; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Kim HW, 2024, SEIZURE-EUR J EPILEP, V114, P1, DOI 10.1016/j.seizure.2023.11.013; Kopf A., 2023, OPENASSISTANT CONVER; Kozlowski D, 2017, BMC MED EDUC, V17, DOI 10.1186/s12909-017-1089-7; Kraljevic Z., 2022, FORESIGHT GENERATIVE; Li H., 2023, MULTI STEP JAILBREAK; Li Y., 2022, CLIN LONGFORMER CLIN; Liu Y., 2023, JAILBREAKING CHATGPT; Lyu Q, 2023, VIS COMPUT IND BIOME, V6, DOI 10.1186/s42492-023-00136-5; Manning CD, 2022, DAEDALUS-US, V151, P127, DOI 10.1162/daed_a_01905; Mbizvo GK, 2023, LANCET DIGIT HEALTH, V5, pE851, DOI 10.1016/S2589-7500(23)00205-4; Min S., 2022, RETHINKING ROLE DEMO; Muennighoff N, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P15991; Nori H., 2023, OPENAI M 2 CAPABILIT; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Pevy N, 2021, SEIZURE-EUR J EPILEP, V91, P141, DOI 10.1016/j.seizure.2021.06.009; Pitkanen Asla, 2016, Lancet Neurol, V15, P843, DOI 10.1016/S1474-4422(16)00112-5; Pons E, 2016, RADIOLOGY, V279, P329, DOI 10.1148/radiol.16142770; Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150; Savova G., 2016, PEDIAT BIOMEDICAL IN, V10, P231, DOI DOI 10.1007/978-94-007-5149-1; Scheffer IE, 2017, EPILEPSIA, V58, P512, DOI 10.1111/epi.13709; Sepat R, 2021, SEIZURE-EUR J EPILEP, V92, P252, DOI 10.1016/j.seizure.2021.09.014; Shen YQ, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230163; Singhal K., 2023, EXPERT LEVEL MEDICAL; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Smolyansky ED, 2021, EPILEPSY BEHAV, V123, DOI 10.1016/j.yebeh.2021.108273; Thijs RD, 2019, LANCET, V393, P689, DOI 10.1016/S0140-6736(18)32596-0; Touvron H., 2023, Llama: Open and efficient foundation language models; Turing AM, 1950, MIND, V59, P433, DOI [10.1093/mind/LIX.236.433, DOI 10.1093/MIND/LIX.236.433, 10.1007/978-1-4020-6710-5_3, DOI 10.1007/978-1-4020-6710-5_3]; van Donselaar CA, 2006, EPILEPSIA, V47, P9, DOI 10.1111/j.1528-1167.2006.00653.x; Vaswani A, 2017, ADV NEUR IN, V30; Venkit P., 2022, P 29 INT C COMP LING, P1324; Vulpius SA, 2023, EPILEPSIA, V64, P2750, DOI 10.1111/epi.17734; Walker LE, 2015, J INTERN MED, V277, P218, DOI 10.1111/joim.12322; Wei J., 2022, Emergent abilities of large language models; Weidinger L., 2021, ETHICAL SOCIAL RISKS; Winata GI., 2021, LANGUAGE MODELS ARE; Woolhandler S, 2014, INT J HEALTH SERV, V44, P635, DOI 10.2190/HS.44.4.a; Wu X, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.982541; Xie K, 2023, EPILEPSIA, V64, P1900, DOI 10.1111/epi.17633; Xie K, 2022, J AM MED INFORM ASSN, V29, P873, DOI 10.1093/jamia/ocac018; Yew ANJ, 2023, EPILEPSIA, V64, P292, DOI 10.1111/epi.17474; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Yue Zhuo T., 2023, RED TEAMING CHATGPT; Zamfrescu-Pereira JD., 2023, P 2023 CHI C HUM FAC, P1, DOI [10.1145/3544548, DOI 10.1145/3544548]; Zhou M, 2020, ENGINEERING-PRC, V6, P275, DOI 10.1016/j.eng.2019.12.014	84	2	2	14	14	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0013-9580	1528-1167		EPILEPSIA	Epilepsia	APR	2024	65	4					873	886		10.1111/epi.17907	http://dx.doi.org/10.1111/epi.17907		FEB 2024	14	Clinical Neurology	Science Citation Index Expanded (SCI-EXPANDED)	Neurosciences & Neurology	NT2C7	38305763	hybrid			2024-07-03	WOS:001155360500001
J	Sánchez-Gordón, M; Tovar, E; Colomo-Palacios, R; Piedra, N; Castro, M				Sanchez-Gordon, Mary; Tovar, Edmundo; Colomo-Palacios, Ricardo; Piedra, Nelson; Castro, Manuel			Educating Augmented Programmers	COMPUTER			English	Article						Computer languages; Programming environments; Artificial intelligence; Human factors; Computer science education		There is an artificial intelligence-based technology that has the potential to augment the work of human programmers. This article discusses some capabilities built around generative artificial intelligence and large language models that impact programming education.	[Sanchez-Gordon, Mary] Ostfold Univ Coll, Comp Sci Dept, NO-1757 Halden, Norway; [Tovar, Edmundo] Univ Politecn Madrid, Comp Languages & Syst & Software Engn Dept, Madrid 28660, Spain; [Colomo-Palacios, Ricardo] Univ Politecn Madrid, Madrid 28660, Spain; [Piedra, Nelson] Univ Tecn Particular Loja, Loja 110107, Ecuador; [Castro, Manuel] Spanish Univ Distance Educ, Madrid 28040, Spain	Ostfold University College; Universidad Politecnica de Madrid; Universidad Politecnica de Madrid; Universidad Tecnica Particular de Loja; Universidad Nacional de Educacion a Distancia (UNED)	Sánchez-Gordón, M (corresponding author), Ostfold Univ Coll, Comp Sci Dept, NO-1757 Halden, Norway.	mary.sanchez-gordon@hiof.no; edmundo.tovar@upm.es; ricardo.colomo-palacios@hiof.no; nopiedra@utpl.edu.ec; mcastro@ieec.uned.es	Castro, Manuel/G-2085-2016	Castro, Manuel/0000-0003-3559-4235; Sanchez-Gordon, Mary/0000-0002-5102-1122; Tovar, Edmundo/0000-0003-2929-659X				[Anonymous], 15-1251.00-Computer programmers; [Anonymous], AI for programming education; [Anonymous], FIXIE.AI-Build on LLMs; [Anonymous], Jackie Wiles beyond ChatGPT: The future of generative AI for enter-prises; CC2020 Task Force, 2020, Computing Curricula 2020, DOI [DOI 10.1145/3467967, 10.1145/3467967]; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Heinonen A, 2023, INFORM SOFTWARE TECH, V164, DOI 10.1016/j.infsof.2023.107300; Jalil S, 2023, IEEE ICST WORKSHOP, P430, DOI 10.1109/ICSTW58534.2023.00078; Povarov N., AI for software developers: A future or a new reality?; Sok S., 2023, SSRN; Xia X, 2018, PROCEEDINGS 2018 IEEE/ACM 40TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE), P584, DOI 10.1145/3180155.3182538	11	0	0	27	27	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1314 USA	0018-9162	1558-0814		COMPUTER	Computer	DEC	2023	56	12					100	104		10.1109/MC.2023.3313325	http://dx.doi.org/10.1109/MC.2023.3313325			5	Computer Science, Hardware & Architecture; Computer Science, Software Engineering	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	Z4OO6		Bronze			2024-07-03	WOS:001111889000002
J	Jiang, S; Evans-Yamamoto, D; Bersenev, D; Palaniappan, SK; Yachie-Kinoshita, A				Jiang, Shuo; Evans-Yamamoto, Daniel; Bersenev, Dennis; Palaniappan, Sucheendra K.; Yachie-Kinoshita, Ayako			ProtoCode: Leveraging large language models (LLMs) for automated generation of machine-readable PCR protocols from scientific publications	SLAS TECHNOLOGY			English	Article						Protocol standardization; Text mining; Large language model; Lab automation		Protocol standardization and sharing are crucial for reproducibility in life sciences. In spite of numerous efforts for standardized protocol description, adherence to these standards in literature remains largely inconsistent. Curation of protocols are especially challenging due to the labor intensive process, requiring expert domain knowledge of each experimental procedure. Recent advancements in Large Language Models (LLMs) offer a promising solution to interpret and curate knowledge from complex scientific literature. In this work, we develop ProtoCode, a tool leveraging fine-tune LLMs to curate protocols into intermediate representation formats which can be interpretable by both human and machine interfaces. Our proof-of-concept, focused on polymerase chain reaction (PCR) protocols, retrieves information from PCR protocols at an accuracy ranging 69-100 % depending on the information content. In all tested protocols, we demonstrate that ProtoCode successfully converts literature-based protocols into correct operational files for multiple thermal cycler systems. In conclusion, ProtoCode can alleviate labor intensive curation and standardization of life science protocols to enhance research reproducibility by providing a reliable, automated means to process and standardize protocols. ProtoCode is freely available as a web server at https://curation.taxila.io/ProtoCode/.	[Jiang, Shuo; Bersenev, Dennis; Yachie-Kinoshita, Ayako] SBX BioSci Inc, 1600-925 West Georgia St, Vancouver, BC V6C 3L2, Canada; [Evans-Yamamoto, Daniel; Palaniappan, Sucheendra K.; Yachie-Kinoshita, Ayako] Syst Biol Inst, Saisei Ikedayama Bldg,5-10-25,Higashi Gotanda,Shin, Tokyo 1410022, Japan		Yachie-Kinoshita, A (corresponding author), SBX BioSci Inc, 1600-925 West Georgia St, Vancouver, BC V6C 3L2, Canada.; Palaniappan, SK; Yachie-Kinoshita, A (corresponding author), Syst Biol Inst, Saisei Ikedayama Bldg,5-10-25,Higashi Gotanda,Shin, Tokyo 1410022, Japan.	sucheendra@sbi.jp; yachie@sbx-biosci.com		Yachie, Ayako/0000-0003-2032-227X; Evans-Yamamoto, Daniel/0000-0001-6467-3827; Jiang, Shuo/0009-0006-9352-3848; Palaniappan, Sucheendra Kumar/0000-0002-2829-2311	ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute [N62909-21-1-2032]	ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute	This work was supported by the ONRG Grant for the Nobel Turing challenge to The Systems Biology Institute (Grant number: N62909-21-1-2032) .	Ananthanarayanan Vaishnavi, 2010, J Biol Eng, V4, P13, DOI 10.1186/1754-1611-4-13; Anhel AM, 2023, ACS SYNTH BIOL, V12, P3514, DOI 10.1021/acssynbio.3c00397; Bartley B, 2023, ACM J EMERG TECH COM, V19, DOI 10.1145/3604568; Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235; Bertaux F, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-31033-9; Chen JT, 2023, Arxiv, DOI [arXiv:2310.06646, 10.48550/arXiv.2310.06646, DOI 10.48550/ARXIV.2310.06646]; Evans-Yamamoto D, 2023, MOL BIOL EVOL, V40, DOI 10.1093/molbev/msad246; Evans-Yamamoto D, 2022, NUCLEIC ACIDS RES, V50, DOI 10.1093/nar/gkac045; Giraldo O, 2018, PEERJ, V6, DOI 10.7717/peerj.4795; Hu Mengzhou, 2023, Res Sq, DOI 10.21203/rs.3.rs-3270331/v1; Inagaki T, 2023, Arxiv, DOI [arXiv:2304.10267, 10.48550/arXiv.2304.10267, DOI 10.48550/ARXIV.2304.10267]; Jiang XL, 2020, ACS SYNTH BIOL, V9, P3228, DOI 10.1021/acssynbio.0c00240; Joachimiak MP, 2023, Arxiv, DOI [arXiv:2305.13338, 10.48550/arXiv.2305.13338, DOI 10.48550/ARXIV.2305.13338]; Jorapur S, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.47711; Kijima Y, 2023, SCI ADV, V9, DOI 10.1126/sciadv.add2793; Leinonen R, 2011, NUCLEIC ACIDS RES, V39, pD19, DOI 10.1093/nar/gkq1019; Mori H, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30588-x; MULLIS K, 1986, COLD SPRING HARB SYM, V51, P263, DOI 10.1101/SQB.1986.051.01.032; Natural Library of Medicine, 2023, PubMed. Pubmed Overview; Ochiai K, 2021, SLAS TECHNOL, V26, P209, DOI 10.1177/2472630320972109; Odonoghue O, 2023, arXiv, DOI DOI 10.48550/ARXIV.2310.10632; Patiny L., 2023, ChemRxiv, DOI DOI 10.26434/CHEMRXIV-2023-05V1B-V2; Sasamata M, 2021, SLAS TECHNOL, V26, P441, DOI 10.1177/24726303211000690; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Taguchi S, 2023, SLAS TECHNOL, V28, P55, DOI 10.1016/j.slast.2022.12.001; Wierenga RP, 2023, Device, V1, DOI [10.1016/j.device.2023.100111, DOI 10.1016/J.DEVICE.2023.100111]; Wilkinson MD, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.18; Yachie N, 2017, NAT BIOTECHNOL, V35, P310, DOI 10.1038/nbt.3758; Yachie N, 2016, MOL SYST BIOL, V12, DOI 10.15252/msb.20156660	29	0	0	2	2	ELSEVIER SCIENCE INC	NEW YORK	STE 800, 230 PARK AVE, NEW YORK, NY 10169 USA	2472-6303	2472-6311		SLAS TECHNOL	SLAS Technol.	JUN	2024	29	3							100134	10.1016/j.slast.2024.100134	http://dx.doi.org/10.1016/j.slast.2024.100134			6	Biochemical Research Methods; Chemistry, Analytical	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Chemistry	SP4O0	38670311				2024-07-03	WOS:001235642700001
J	Singleton, AD; Spielman, S				Singleton, Alex D.; Spielman, Seth			Segmentation using large language models: A new typology of American neighborhoods	EPJ DATA SCIENCE			English	Article						Geodemographics; Large Language Model (LLM); American Community Survey; Segmentation; Neighborhoods; Artificial Intelligence (AI); Demographics; Retreival Augmented Generation (RAG)	CLASSIFICATION; FRAMEWORK	In the United States, recent changes to the National Statistical System have amplified the geographic-demographic resolution trade-off. That is, when working with demographic and economic data from the American Community Survey, as one zooms in geographically one loses resolution demographically due to very large margins of error. In this paper, we present a solution to this problem in the form of an AI based open and reproducible geodemographic classification system for the United States using small area estimates from the American Community Survey (ACS). We employ a partitioning clustering algorithm to a range of socio-economic, demographic, and built environment variables. Our approach utilizes an open source software pipeline that ensures adaptability to future data updates. A key innovation is the integration of GPT4, a state-of-the-art large language model, to generate intuitive cluster descriptions and names. This represents a novel application of natural language processing in geodemographic research and showcases the potential for human-AI collaboration within the geospatial domain.	[Singleton, Alex D.] Univ Liverpool, Geog Data Sci Lab, Roxby Bldg,74 Bedford St South, Liverpool L69 7ZT, England; [Spielman, Seth] Microsoft, 1650 Canyon Blvd, Boulder, CO 80302 USA	University of Liverpool; Microsoft	Singleton, AD (corresponding author), Univ Liverpool, Geog Data Sci Lab, Roxby Bldg,74 Bedford St South, Liverpool L69 7ZT, England.	alex.singleton@liverpool.ac.uk		Singleton, Alex/0000-0002-2338-2334	Economic and Social Research Council	Economic and Social Research Council(UK Research & Innovation (UKRI)Economic & Social Research Council (ESRC))	No Statement Available	Abbott A, 1997, SOC FORCES, V75, P1149, DOI 10.2307/2580667; Batey P., 2008, Appl Spat Anal Policy, V1, P117, DOI [10.1007/s12061-008-9007-3, DOI 10.1007/S12061-008-9007-3]; Bureau UC., 2018, Block groups for the 2020 census-proposed criteria; Clark S, 2017, EPJ DATA SCI, V6, DOI 10.1140/epjds/s13688-017-0113-9; Gale CG, 2016, J SPAT INF SCI, P1, DOI 10.5311/JOSIS.2016.12.232; Harris R., 2005, GEODEMOGRAPHICS GIS; Liu YZ, 2019, GEO-SPAT INF SCI, V22, P251, DOI 10.1080/10095020.2019.1621549; Longley PA, 2009, INT J GEOGR INF SCI, V23, P737, DOI 10.1080/13658810701704652; PALM R, 1972, ANN ASSOC AM GEOGR, V62, P122, DOI 10.1111/j.1467-8306.1972.tb00848.x; Reibel M, 2011, URBAN GEOGR, V32, P305, DOI 10.2747/0272-3638.32.3.305; Singleton AD, 2015, GEO-GEOGR ENVIRON, V2, P69, DOI 10.1002/geo2.7; Singleton AD, 2016, INT J GEOGR INF SCI, V30, P1507, DOI 10.1080/13658816.2015.1137579; Singleton AD, 2014, PROF GEOGR, V66, P558, DOI 10.1080/00330124.2013.848764; Spielman SE, 2008, COMPUT ENVIRON URBAN, V32, P110, DOI 10.1016/j.compenvurbsys.2007.11.004; Spielman SE, 2015, ANN ASSOC AM GEOGR, V105, P1003, DOI 10.1080/00045608.2015.1052335; Spielman SE, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0115626; Su TY, 2022, EPJ DATA SCI, V11, DOI 10.1140/epjds/s13688-022-00355-5; Vickers D, 2007, J ROY STAT SOC A STA, V170, P379, DOI 10.1111/j.1467-985X.2007.00466.x; Walker K., 2023, Tidycensus: Load US Census Boundary and Attribute Data as 'tidyverse' and 'sf'-Ready Data Frames; Walsh BY, 2021, APPL SPAT ANAL POLIC, V14, P51, DOI 10.1007/s12061-020-09343-6; Webber R., 2018, PREDICTIVE POSTCODE, DOI [10.4135/9781529714685, DOI 10.4135/9781529714685]; Weiss M.J., 2000, CLUSTERED WORLD WE L; Wyszomierski J, 2024, GEOGR J, V190, DOI 10.1111/geoj.12550; Zignani M, 2019, EPJ DATA SCI, V8, DOI 10.1140/epjds/s13688-019-0187-7	24	0	0	1	1	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES		2193-1127		EPJ DATA SCI	EPJ Data Sci.	APR 22	2024	13	1							34	10.1140/epjds/s13688-024-00466-1	http://dx.doi.org/10.1140/epjds/s13688-024-00466-1			21	Mathematics, Interdisciplinary Applications; Social Sciences, Mathematical Methods	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Mathematics; Mathematical Methods In Social Sciences	OG4Q3		gold			2024-07-03	WOS:001206106900001
C	Sharma, P; Yegneswaran, V			ACM	Sharma, Prakhar; Yegneswaran, Vinod			PROSPER: Extracting Protocol Specifications Using Large Language Models	PROCEEDINGS OF THE 22ND ACM WORKSHOP ON HOT TOPICS IN NETWORKS, HOTNETS 2023			English	Proceedings Paper	22nd ACM Workshop on Hot Topics in Networks (HotNets)	NOV 28-29, 2023	Cambridge, MA	Assoc Comp Machinery, ACM SIGCOMM		Large language models; request for comments; protocol specifications; protocol FSMs; automated extraction		We explore the application of Large Language Models (LLMs) (specifically GPT-3.5-turbo) to extract specifications and automating understanding of networking protocols from Internet Request for Comments (RFC) documents. LLMs have proven successful in specialized domains like medical and legal text understanding, and this work investigates their potential in automatically comprehending RFCs. We develop Artifact Miner, a tool to extract diagram artifacts from RFCs. We then couple extracted artifacts with natural language text to extract protocol automata using GPT-turbo 3.5 (chatGPT) and present our zero-shot and few-shot extraction results. We call this framework for FSM extraction 'PROSPER: Protocol Specification Miner'. We compare PROSPER with existing state-of-the-art techniques for protocol FSM state and transition extraction. Our experiments indicate that employing artifacts along with text for extraction can lead to lower false positives and better accuracy for both extracted states and transitions. Finally, we discuss efficient prompt engineering techniques, the errors we encountered, and pitfalls of using LLMs for knowledge extraction from specialized domains such as RFC documents.	[Sharma, Prakhar; Yegneswaran, Vinod] SRI Int, Menlo Pk, CA 94025 USA	SRI International	Sharma, P (corresponding author), SRI Int, Menlo Pk, CA 94025 USA.	prakhar.sharma@sri.com; vinod@csl.sri.com			Office of Naval Research (ONR) [N00014-18-1-2660]	Office of Naval Research (ONR)(United States Department of DefenseUnited States NavyOffice of Naval Research)	This work was funded by the Office of Naval Research (ONR) grant number N00014-18-1-2660. Any expressed opinions, findings and conclusions or recommendations do not necessarily reflect the views of the Office of Naval Research.	Abdullah Ibrahim, 2003, P 2 IASTED INT C COM; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bulatov A, 2022, Arxiv, DOI [arXiv:2207.06881, 10.48550/arXiv.2207.06881]; Cho Chia Yuan, 2010, ACM C COMPUTER COMMU; Cho Chia Yuan, 2011, USENIX SEC SC; Comparetti PM, 2009, P IEEE S SECUR PRIV, P110, DOI 10.1109/SP.2009.14; Corbett J.C., 2000, IEEE ACM INT C SOFTW; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Ji B, 2023, Arxiv, DOI arXiv:2305.03253; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Kothari N, 2008, 2008 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, PROCEEDINGS, P271, DOI 10.1109/IPSN.2008.62; Li Haoyang, 2023, RESDSQL: decoupling schema linking and skeleton parsing for text-to-SQL; Lie D, 2001, CONF PROC INT SYMP C, P192, DOI 10.1109/ISCA.2001.937448; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Pacheco Maria Lenore, 2022, Automated Attack Synthesis by Extracting Finite State Machines from Protocol Specification Documents; Pandita R., 2013, WHYPER AUTOMATING RI; Pasupat P, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1470; Pelle I, 2017, Arxiv, DOI arXiv:1702.08827; Qian CX, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1733; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Vaswani A, 2017, ADV NEUR IN, V30; von Hippel M, 2022, Arxiv, DOI arXiv:2004.01220; Wei JS, 2022, Arxiv, DOI [arXiv:2206.07682, 10.48550/arXiv.2206.07682, DOI 10.48550/ARXIV.2206.07682]; Wong E, 2015, 2015 IEEE/ACM 37TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, VOL 1, P620, DOI 10.1109/ICSE.2015.78; Yang H, 2023, Arxiv, DOI arXiv:2306.02224; Yen Jane, 2020, SPECIAL INTEREST GRO; YipengWang Zhibin Zhang, 2011, Applied Cryptography and Network Security (ACNS); Zhou YC, 2023, Arxiv, DOI [arXiv:2211.01910, DOI 10.48550/ARXIV.2211.01910]	29	0	0	4	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0415-4				2023							41	47		10.1145/3626111.3628205	http://dx.doi.org/10.1145/3626111.3628205			7	Computer Science, Information Systems; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2TD					2024-07-03	WOS:001124843800006
J	Son, J; Kim, B				Son, Jungha; Kim, Boyoung			Translation Performance from the User's Perspective of Large Language Models and Neural Machine Translation Systems	INFORMATION			English	Article						large language model; neural machine translation; ChatGPT; Google Translate; Microsoft Translator	COMPUTER-ASSISTED TRANSLATION	The rapid global expansion of ChatGPT, which plays a crucial role in interactive knowledge sharing and translation, underscores the importance of comparative performance assessments in artificial intelligence (AI) technology. This study concentrated on this crucial issue by exploring and contrasting the translation performances of large language models (LLMs) and neural machine translation (NMT) systems. For this aim, the APIs of Google Translate, Microsoft Translator, and OpenAI's ChatGPT were utilized, leveraging parallel corpora from the Workshop on Machine Translation (WMT) 2018 and 2020 benchmarks. By applying recognized evaluation metrics such as BLEU, chrF, and TER, a comprehensive performance analysis across a variety of language pairs, translation directions, and reference token sizes was conducted. The findings reveal that while Google Translate and Microsoft Translator generally surpass ChatGPT in terms of their BLEU, chrF, and TER scores, ChatGPT exhibits superior performance in specific language pairs. Translations from non-English to English consistently yielded better results across all three systems compared with translations from English to non-English. Significantly, an improvement in translation system performance was observed as the token size increased, hinting at the potential benefits of training models on larger token sizes.	[Son, Jungha; Kim, Boyoung] aSSIST Univ, Seoul Business Sch, Seoul 03767, South Korea		Kim, B (corresponding author), aSSIST Univ, Seoul Business Sch, Seoul 03767, South Korea.	jhson@stud.assist.ac.kr; bykim2@assist.ac.kr		Son, Jungha/0009-0006-2035-2881				Acumen Research and Consulting, About us; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Birch A., 2021, Neural Machine Translation; Biswas SS, 2023, ANN BIOMED ENG, V51, P1126, DOI 10.1007/s10439-023-03171-8; Bojar O., 2018, WMT18; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Callison-Burch C, 2006, 11 C EUR CHAPT ASS C; Callison-Burch Chris, 2010, JOINT 5 WORKSH STAT, P17; Castilho Sheila, 2017, Prague Bulletin of Mathematical Linguistics, P109, DOI 10.1515/pralin-2017-0013; Chand S, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P181, DOI 10.1109/ICRCICN.2016.7813653; Chopra D, 2018, ENG TECHNOL APPL SCI, V8, P3512; Christiano PF, 2017, ADV NEUR IN, V30; Conneau Alexis., 2020, P 58 ANN M ASS COMP, P8440, DOI [DOI 10.18653/V1/2020.ACL-MAIN.747, 10.18653/v1/2020.acl-main.747]; Cui YW, 2016, IEEE IJCNN, P1530, DOI 10.1109/IJCNN.2016.7727380; Dai ZH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P2978; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Freedman JD, 2023, Arxiv, DOI arXiv:2304.01503; Hariri W, 2024, Arxiv, DOI [arXiv:2304.02017, 10.48550/arxiv.2304.02017, DOI 10.48550/ARXIV.2304.02017]; Hearne M, 2011, LANG LINGUIST COMPAS, V5, P205, DOI 10.1111/j.1749-818x.2011.00274.x; Hutchins J., 1992, An introduction to machine translation; Hutchins J., 2005, Retrieved Dec, V20, P1; Hutchins J, 2005, MACH TRANSL, V19, P197, DOI 10.1007/s10590-006-9003-9; Koehn P., 2009, P MACH TRANSL SUMM 1; Koehn Philipp., 2020, P 5 C MACHINE TRANSL, P724; Kulshreshtha S., 2020, arXiv, DOI DOI arXiv:2009.14304.null; Mara M., 2018, English-Wolaytta Machine Translation Using Statistical Approach; Maruf S, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3441691; Mathew A., 2023, Recent Prog Sci Technol, V5, P35, DOI DOI 10.9734/BPI/RPST/V5/18240D; Meng FD, 2019, AAAI CONF ARTIF INTE, P224; Nichols J, 2008, LANG LINGUIST COMPAS, V2, P760, DOI 10.1111/j.1749-818x.2008.00082.x; OpenAI, GPT 4 IS OPENAIS MOS; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; PoPoVic Maja, 2015, P 10 WORKSHOP STAT M, P392, DOI 10.18653/v1/W15-3049; Post M, 2018, Arxiv, DOI [arXiv:1804.08771, 10.48550/arXiv.1804.08771]; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ragni V, 2022, PERSPECT STUD TRANSL, V30, P137, DOI 10.1080/0907676X.2021.1889005; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Rodríguez-Castro M, 2018, INTERPRET TRANSL TRA, V12, P355, DOI 10.1080/1750399X.2018.1502007; Roumeliotis KI, 2023, FUTURE INTERNET, V15, DOI 10.3390/fi15060192; Snover M., 2006, P 7 C ASS MACH TRANS, P223; statmt, WMT 18; statmt, WMT 20; Taravella A, 2013, J SPEC TRANSL, P62; Vaswani A, 2017, ADV NEUR IN, V30; Wang HF, 2022, ENGINEERING-PRC, V18, P143, DOI 10.1016/j.eng.2021.03.023; Wieting J, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P4344; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Wu YH, 2016, Arxiv, DOI arXiv:1609.08144; Zhu JH, 2020, Arxiv, DOI arXiv:2002.06823	50	0	0	40	57	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2078-2489		INFORMATION	Information	OCT	2023	14	10							574	10.3390/info14100574	http://dx.doi.org/10.3390/info14100574			18	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	W2MV8		gold			2024-07-03	WOS:001090032700001
C	Tanaka, Y; Katsura, S			IEEE	Tanaka, Yuki; Katsura, Seiichiro			A Voice-Controlled Motion Reproduction Using Large Language Models for Polishing Robots	2023 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS, ICM			English	Proceedings Paper	IEEE International Conference on Mechatronics (ICM)	MAR 15-17, 2023	Loughborough, ENGLAND	Inst Elect & Elect Engineers, IEEE Ind Applicat Soc		motion control; motion reproduction system; natural language processing; large language models; polishing robot; transfer of skills; human-robot interaction; robot teaching		In recent years, the shortage of professionally skilled people in industrial fields has been a major social problem. To solve this problem, the transfer of skills to robots has been attracting much attention. However, they are not familiar with robot control, and hard to teach robots their skills by numerical commands or program source code. For more user-friendly human-robot interaction, a lot of studies have been conducted. In previous researches, robot task processes are pre-defined and not changed in task execution. We developed a robot system using the motion-copying system and GPT-3, one of the Large Language Models. This system can not only copy the motion but also modify saved motion in execution by using natural language commands. We evaluated the proposed system by applying it to polishing robots and confirmed that the surface of used workpieces was changed following to input commands.	[Tanaka, Yuki; Katsura, Seiichiro] Keio Univ, Dept Syst Design Engn, Keio, Japan	Keio University	Tanaka, Y (corresponding author), Keio Univ, Dept Syst Design Engn, Keio, Japan.	tanaka@katsura.sd.keio.ac.jp; katsura@sd.keio.ac.jp			Strategic Information and Communications R&D Promotion Programme (SCOPE) [201603011]	Strategic Information and Communications R&D Promotion Programme (SCOPE)	This work was partially supported by Strategic Information and Communications R&D Promotion Programme (SCOPE) Grant Number 201603011.	Adachi T, 2018, IEEE INT C INT ROBOT, P3648, DOI 10.1109/IROS.2018.8594489; Ahn M, 2022, Arxiv, DOI arXiv:2204.01691; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Hill F, 2020, Arxiv, DOI arXiv:2005.09382; Huo YX, 2022, IEEE T AUTOM SCI ENG, V19, P3601, DOI 10.1109/TASE.2021.3126743; Maric B, 2020, IEEE ROBOT AUTOM LET, V5, P2848, DOI 10.1109/LRA.2020.2969951; Matsumoto Y, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P802; Matuszek C., 2013, Springer Tracts in Advanced Robotics, P403, DOI [10.1007/978-3-319-00065-7, DOI 10.1007/978-3-319-00065-7]; Nagata F, 2007, ROBOT CIM-INT MANUF, V23, P371, DOI 10.1016/j.rcim.2006.04.004; Nair S., 2022, P MACHINE LEARNING R, P1303; Nguyen Joshua, 2022, 2022 International Conference on Robotics and Automation (ICRA), P2958, DOI 10.1109/ICRA46639.2022.9812029; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Reid M, 2022, Arxiv, DOI arXiv:2201.12122; Sakaino S., 2021, 2021 IEEE 30 INT S I, P1; Tanwani AK, 2020, IEEE INT CONF ROBOT, P2174, DOI [10.1109/ICRA40945.2020.9197324, 10.1109/icra40945.2020.9197324]; Tellex S., 2014, Robotics: Science and Systems Foundation; Ubeda RP, 2021, MATERIALS, V14, DOI 10.3390/ma14010067; Vaswani A, 2017, ADV NEUR IN, V30; Yokokura Y, 2008, AMC '08: 10TH INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, VOLS 1 AND 2, PROCEEDINGS, P613; Yokokura Y, 2009, IEEE T IND ELECTRON, V56, P3906, DOI 10.1109/TIE.2009.2027927	21	0	0	9	21	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			978-1-6654-6661-5				2023										10.1109/ICM54990.2023.10101966	http://dx.doi.org/10.1109/ICM54990.2023.10101966			6	Automation & Control Systems; Computer Science, Theory & Methods; Engineering, Electrical & Electronic; Engineering, Mechanical	Conference Proceedings Citation Index - Science (CPCI-S)	Automation & Control Systems; Computer Science; Engineering	BV1IK					2024-07-03	WOS:000987155100031
J	Ahmad, B; Thakur, S; Tan, BJM; Karri, R; Pearce, H				Ahmad, Baleegh; Thakur, Shailja; Tan, Benjamin; Karri, Ramesh; Pearce, Hammond			On Hardware Security Bug Code Fixes by Prompting Large Language Models	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY			English	Article						Maintenance engineering; Computer bugs; Codes; Hardware; Security; Software; Registers; Hardware security; large language models; bug repair		Novel AI-based code-writing Large Language Models (LLMs) such as OpenAI's Codex have demonstrated capabilities in many coding-adjacent domains. In this work, we consider how LLMs may be leveraged to automatically repair identified security-relevant bugs present in hardware designs by generating replacement code. We focus on bug repair in code written in Verilog. For this study, we curate a corpus of domain-representative hardware security bugs. We then design and implement a framework to quantitatively evaluate the performance of any LLM tasked with fixing the specified bugs. The framework supports design space exploration of prompts (i.e., prompt engineering) and identifying the best parameters for the LLM. We show that an ensemble of LLMs can repair all fifteen of our benchmarks. This ensemble outperforms a state-of-the-art automated hardware bug repair tool on its own suite of bugs. These results show that LLMs have the ability to repair hardware security bugs and the framework is an important step towards the ultimate goal of an automated end-to-end bug repair tool.	[Ahmad, Baleegh; Thakur, Shailja; Karri, Ramesh] NYU, Dept Elect & Comp Engn, Tandon Sch Engn, Brooklyn, NY 11201 USA; [Tan, Benjamin] Univ Calgary, Dept Elect & Software Engn, Calgary, AB T2N 1N4, Canada; [Pearce, Hammond] Univ New South Wales, Dept Elect & Comp Engn, Sydney, NSW 2052, Australia	New York University; New York University Tandon School of Engineering; University of Calgary; University of New South Wales Sydney	Ahmad, B (corresponding author), NYU, Dept Elect & Comp Engn, Tandon Sch Engn, Brooklyn, NY 11201 USA.	ba1283@nyu.edu		Tan, Benjamin/0000-0002-7642-3638	Intel Corporation	Intel Corporation(Intel Corporation)	No Statement Available	A. F. Rev, 2023, Artifacts for 'On Hardware Security Bug Code Fixes By Querying Large Language Models'; Ahmad B, 2022, ICCAD-IEEE ACM INT, DOI 10.1145/3508352.3549369; Ahmad H, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P990, DOI 10.1145/3503222.3507763; [Anonymous], 2020, ModelSim Vivado Design Suite Reference Guide: Model-Based DSP Design Using System Generator (UG958). Reader. AMD Adaptive Computing Documentation Portal; [Anonymous], 2022, VC Formal; [Anonymous], 2019, Hardware OpenTitan Documentation; Ardeshiricham A, 2019, PROCEEDINGS OF THE 2019 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'19), P1623, DOI 10.1145/3319535.3354246; Cadence, 2022, Jasper RTL Apps Cadence; Chen M., 2021, arXiv; Chen ZM, 2023, IEEE T SOFTWARE ENG, V49, P147, DOI 10.1109/TSE.2022.3147265; Demmler D, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1504, DOI 10.1145/2810103.2813678; Dessouky G, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P213; Drain Dawn, 2021, MAPS 2021: Proceedings of the 5th SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3460945.3464951; Fadiheh MR, 2019, DES AUT TEST EUROPE, P994, DOI [10.23919/date.2019.8715004, 10.23919/DATE.2019.8715004]; Fu WM, 2023, 2023 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM, ASIANHOST, DOI 10.1109/AsianHOST59942.2023.10409307; HACK@EVENT, 2022, HACK@DAC21-HacK@EVENT; Jasperlint, 2022, Jasper Superlint App; Kocher P., 2018, P IEEE S SEC PRIV SP; Le Goues C, 2019, COMMUN ACM, V62, P56, DOI 10.1145/3318162; Le XBD, 2021, PROC INT SYMP SOFTW, P162, DOI 10.1109/ISSRE52982.2021.00028; Lipp M, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P973; Lu Y., 2021, arXiv; Ma SQ, 2017, LECT NOTES COMPUT SC, V10493, P229, DOI 10.1007/978-3-319-66399-9_13; Monperrus Martin, 2018, Technical Report hal-01956501; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; OpenAI, 2021, OpenAI Codex; Pearce H, 2023, P IEEE S SECUR PRIV, P2339, DOI 10.1109/SP46215.2023.10179420; Pearce H, 2020, PROCEEDINGS OF THE 2020 ACM/IEEE 2ND WORKSHOP ON MACHINE LEARNING FOR CAD (MLCAD '20), P27, DOI 10.1145/3380446.3430634; Potlapally N., 2011, 2011 IEEE International Symposium on Hardware-Oriented Security and Trust (HOST), P93, DOI 10.1109/HST.2011.5955003; Reiter P, 2022, Arxiv, DOI arXiv:2202.12336; T. M. Corp, 1194, CWE-CWE-1194: Hardware Design (4.1); Thakur S, 2023, DES AUT TEST EUROPE, DOI 10.23919/DATE56975.2023.10137086; Trippel T, 2021, arXiv, DOI DOI 10.48550/ARXIV.2102.02308; Tufano M, 2019, ACM T SOFTW ENG METH, V28, DOI 10.1145/3340544; vclint, 2022, Synopsys VC SpyGlass Lint; Wang WC, 2019, J SYST SOFTWARE, V156, P100, DOI 10.1016/j.jss.2019.06.076; Wu J, 2022, PR IEEE COMP DESIGN, P537, DOI 10.1109/ICCD56317.2022.00085; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129	38	1	1	4	4	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	1556-6013	1556-6021		IEEE T INF FOREN SEC	IEEE Trans. Inf. Forensic Secur.		2024	19						4043	4057		10.1109/TIFS.2024.3374558	http://dx.doi.org/10.1109/TIFS.2024.3374558			15	Computer Science, Theory & Methods; Engineering, Electrical & Electronic	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Engineering	PN1A5		Green Submitted			2024-07-03	WOS:001214653000002
C	Jacob, GM; Sahu, S; Stenger, B; Kawamura, M; Ito, C			ACM	Jacob, Geethu Miriam; Sahu, Sagar; Stenger, Bjorn; Kawamura, Masashi; Ito, Chisato			Text2Illustration: Sampling and Composing Creatives With Text	PROCEEDINGS OF 7TH JOINT INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MANAGEMENT OF DATA, CODS-COMAD 2024			English	Proceedings Paper	7th ACM India Joint International Conference on Data Science and Management of Data (CODS-COMAD) / 11th ACM IKDD CODS Conference / 29th COMAD Conference	JAN 04-07, 2024	IIIT Bangalore, Bangalore, INDIA	ACM India, ACM In Cooperat, ACM SIGKDD, India Chapter, COMAD, ACM SIGMOD	IIIT Bangalore	Scalable Vector Graphics; Large Language Models		We introduce Text2Illustration, a user-friendly system that generates illustrations from plain text input. This system addresses the need for an accessible tool to create illustrations that vividly portray a range of human activities. Text2Illustration uses a large language model (LLM) to select relevant components from an SVG library based on the input text, seamlessly composing new visuals. To ensure ease of use, we have developed a simple text-based interface, allowing users to describe their desired illustration.	[Jacob, Geethu Miriam; Sahu, Sagar; Stenger, Bjorn; Kawamura, Masashi; Ito, Chisato] Rakuten Grp Inc, Bangalore, Karnataka, India		Jacob, GM (corresponding author), Rakuten Grp Inc, Bangalore, Karnataka, India.	geethumiriam@gmail.com; sagar.a.sahu@rakuten.com; bjorn.stenger@cantab.net; masashi.kawamura@rakuten.com; chisato.ito@rakuten.com		Stenger, Bjorn/0009-0008-0465-5545				Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; corp.rakuten, Rakuten Illustration System; Fernando C, 2021, Arxiv, DOI arXiv:2105.00162; Frans K., 2022, Advances in Neural Information Processing Systems, V35, P5207; Huang NS, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1085, DOI 10.1145/3503161.3548282; Jain A, 2023, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR52729.2023.00190; Ouyang L., 2022, Advances in Neural Information Processing Systems, V35, P27730, DOI DOI 10.48550/ARXIV.2203.02155; Rakuten Design, ABOUT US; Schaldenbrand P, 2022, Arxiv, DOI arXiv:2202.12362; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917	11	0	0	1	1	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-1634-8				2024							538	541		10.1145/3632410.3632484	http://dx.doi.org/10.1145/3632410.3632484			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5HU					2024-07-03	WOS:001160848200075
J	D'Antonoli, TA; Stanzione, A; Bluethgen, C; Vernuccio, F; Ugga, L; Klontzas, ME; Cuocolo, R; Cannella, R; Kocak, B				D'Antonoli, Tugba Akinci; Stanzione, Arnaldo; Bluethgen, Christian; Vernuccio, Federica; Ugga, Lorenzo; Klontzas, Michail E.; Cuocolo, Renato; Cannella, Roberto; Kocak, Burak			Large language models in radiology: fundamentals, applications, ethical considerations, risks, and future directions	DIAGNOSTIC AND INTERVENTIONAL RADIOLOGY			English	Review						Large language models; natural language processing; artificial intelligence; ChatGPT; deep learning		With the advent of large language models (LLMs), the artificial intelligence revolution in medicine and radiology is now more tangible than ever. Every day, an increasingly large number of articles are published that utilize LLMs in radiology. To adopt and safely implement this new technology in the field, radiologists should be familiar with its key concepts, understand at least the technical basics, and be aware of the potential risks and ethical considerations that come with it. In this review article, the authors provide an overview of the LLMs that might be relevant to the radiology community and include a brief discussion of their short history, technical basics, ChatGPT, prompt engineering, potential applications in medicine and radiology, advantages, disadvantages and risks, ethical and regulatory considerations, and future directions.	[D'Antonoli, Tugba Akinci] Cantonal Hosp Baselland, Inst Radiol & Nucl Med, Liestal, Switzerland; [Stanzione, Arnaldo; Ugga, Lorenzo] Univ Naples Federico II, Dept Adv Biomed Sci, Naples, Italy; [Bluethgen, Christian] Univ Zurich, Univ Hosp Zurich, Inst Diagnost & Intervent Radiol, Zurich, Switzerland; [Vernuccio, Federica] Univ Hosp Padova, Dept Radiol, Padua, Italy; [Klontzas, Michail E.] Univ Hosp Heraklion, Dept Med Imaging, Iraklion, Greece; [Klontzas, Michail E.] Univ Crete, Dept Radiol, Iraklion, Greece; [Klontzas, Michail E.] FORTH, Inst Comp Sci, Computat Biomed Lab, Iraklion, Greece; [Cuocolo, Renato] Univ Salerno, Dept Med Surg & Dent, Baronissi, Italy; [Cannella, Roberto] Univ Palermo, Sect Neurosurg, Dept Biomed Neurosci & Adv Diagnost, Palermo, Italy; [Kocak, Burak] Univ Hlth Sci, Basaksehir Cam & Sakura City Hosp, Clin Radiol, I?stanbul, Turkiye	Kantonsspital Baselland; University of Naples Federico II; University of Zurich; University Zurich Hospital; University of Padua; Azienda Ospedaliera - Universita di Padova; University Hospital of Heraklion; University of Crete; Foundation for Research & Technology - Hellas (FORTH); University of Salerno; University of Palermo	D'Antonoli, TA (corresponding author), Cantonal Hosp Baselland, Inst Radiol & Nucl Med, Liestal, Switzerland.	akincidantonoli@unibas.ch	kocak, burak/A-4749-2012; Vernuccio, Federica/J-5739-2018; Akinci D'Antonoli, Tugba/I-5766-2019; Vernuccio, Federica/JVE-2108-2024; Cuocolo, Renato/G-3147-2018	kocak, burak/0000-0002-7307-396X; Vernuccio, Federica/0000-0003-0350-1794; Akinci D'Antonoli, Tugba/0000-0002-7237-711X; Vernuccio, Federica/0000-0003-0350-1794; Cuocolo, Renato/0000-0002-1452-1574; Cannella, Roberto/0000-0002-3808-0785	Bracco Imaging S.r.l; GE Healthcare; Bayer; Bracco; European Union-FESR or FSE;  [DM 1062/2021]	Bracco Imaging S.r.l; GE Healthcare(General ElectricGE Healthcare); Bayer(Bayer AG); Bracco; European Union-FESR or FSE; 	F.V.; none related to this study; received support to attend meetings from Bracco Imaging S.r.l., and GE Healthcare. M.E.K.; meeting attendance support from Bayer. Ro.C.; support for attending meetings from Bracco and Bayer; research collaboration with Siemens Healthcare; co-funding by the European Union-FESR or FSE, PON Research and Innovation 2014-2020-DM 1062/2021. Burak Kocak, MD, is Section Editor in Diagnostic and Interventional Radiology. He had no involvement in the peer-review of this article and had no access to information regarding its peer-review. Other authors have nothing to disclose.	Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; Alsentzer E., 2019, arXiv; [Anonymous], Prompt Engineering | Lil'Log; [Anonymous], 2016, Artificial Intelligence and the Future of Gaming; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bengio Y, 2001, ADV NEUR IN, V13, P932; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230987; Bhayana R, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230582; Bick U, 1999, EUR RADIOL, V9, P1152, DOI 10.1007/s003300050811; Bills S., 2023, OpenAI; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bubeck S., 2023, arXiv; Chelba C, 2013, ARXIV; Chen L., 2023, ARXIV; Chen S, 2023, JCO CLIN CANCER INFO, V7, DOI 10.1200/CCI.23.00048; Chowdhery A., 2022, arXiv; Coavoux M., 2018, arXiv; Collins KM., 2022, arXiv; Devlin J., 2018, BERT PRE TRAINING DE; Doo FX, 2023, J AM COLL RADIOL, V20, P877, DOI 10.1016/j.jacr.2023.07.007; Gao J, 2004, ACM Transactions on Asian Language Information Processing, V3, P87; Gao T, 2020, ARXIV; Gertz Roman Johannes, 2023, Radiology, V307, pe230877, DOI 10.1148/radiol.230877; Gilbert S, 2023, NAT MED, V29, P2396, DOI 10.1038/s41591-023-02412-6; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Hoffmann J, 2022, ARXIV; Hosny A, 2018, NAT REV CANCER, V18, P500, DOI 10.1038/s41568-018-0016-5; Hou C, 2023, arXiv; Hu M., 2023, arXiv; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang Shi-Tao, 2023, Radiology, V308, pe231335, DOI 10.1148/radiol.231335; Kaddour J, 2023, arXiv; Kaplan Jared, 2020, arXiv; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Kojima T., 2022, ARXIV; Korngiebel DM, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00464-x; Kottlors J, 2023, RADIOLOGY, V308, DOI 10.1148/radiol.231167; Kudo T., 2018, ARXIV; Landi F, 2021, NEURAL NETWORKS, V144, P334, DOI 10.1016/j.neunet.2021.08.030; Lecler A, 2023, DIAGN INTERV IMAG, V104, P269, DOI 10.1016/j.diii.2023.02.003; Lewis P, arXiv; Li H, 2023, CLIN IMAG, V101, P137, DOI 10.1016/j.clinimag.2023.06.008; Li HZ, 2023, LANCET DIGIT HEALTH, V5, pE333, DOI 10.1016/S2589-7500(23)00083-3; Li R., 2023, arXiv; Li Z., 2023, arXiv; Liao QV, 2023, arXiv; Liu Z., 2023, ARXIV; Lokker C, 2023, J BIOMED INFORM, V142, DOI 10.1016/j.jbi.2023.104384; Lopez-Ubeda P, 2023, EUR RADIOL, V33, P9455, DOI 10.1007/s00330-023-09901-9; Lourenco AP, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231053; Lu Y., 2021, ARXIV; Madden MG, 2023, INTENS CARE MED, V49, P1018, DOI 10.1007/s00134-023-07128-2; Mahbub M, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0262182; Mallio CA, 2023, RADIOL MED, V128, P808, DOI 10.1007/s11547-023-01651-4; Medenilla A., 2023, PLoS Digital Health, V2; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mialon, 2023, ARXIV; Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; OpenAI, 2023, ArXiv; ORNSTEIN J, 1955, SCIENCE, V122, P745, DOI 10.1126/science.122.3173.745; Ouyang L., 2022, ARXIV; Pascanu R., 2012, ARXIV; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rahsepar AA, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230922; Richardson ML, 2021, ACAD RADIOL, V28, P1225, DOI 10.1016/j.acra.2020.01.012; Rosenfeld R, 2000, P IEEE, V88, P1270, DOI 10.1109/5.880083; Rust P., 2020, arXiv; Schick T., 2023, ARXIV; Shahsavar Y, 2023, JMIR HUM FACTORS, V10, DOI 10.2196/47564; Shum HY., 2018, FRONT INFORM TECH EL; Shumailov I, 2023, arXiv; Singhal K, 2023, arXiv; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Song R, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2023.103277; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Sun ZY, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.231259; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Van Veen D, 2023, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wang B., 2023, arXiv; Wang HF, 2023, ENGINEERING-PRC, V25, P51, DOI 10.1016/j.eng.2022.04.024; Wei J., 2021, ARXIV; Wei J., 2022, ARXIV; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Yao S., 2023, ARXIV; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Yoshiyasu Y, 2023, INT FORUM ALLERGY RH, V13, P2231, DOI 10.1002/alr.23201; Zhang X., 2023, arXiv; Zhao WX, 2023, ARXIV; Zhu K, 2023, arXiv; Zhu LX, 2023, J TRANSL MED, V21, DOI 10.1186/s12967-023-04123-5; Zhu W, 2023, arXiv; Zitu MM, 2023, FRONT PHARMACOL, V14, DOI 10.3389/fphar.2023.1218679	96	12	13	6	7	TURKISH SOC RADIOLOGY	ANKARA	Hosdere Caddesi, Guzelkent Sokak, Cankaya Evleri, F Blok, No:2 , Cankaya PK, ANKARA, TURKEY	1305-3612			DIAGN INTERV RADIOL	Diagn. Interv. Radiol.	MAR	2024	30	2					80	90		10.4274/dir.2023.232417	http://dx.doi.org/10.4274/dir.2023.232417			11	Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Radiology, Nuclear Medicine & Medical Imaging	QP4N6	37789676	Green Published, gold			2024-07-03	WOS:001222062400006
C	Pujar, S; Buratti, L; Guo, XJ; Dupuis, N; Lewis, B; Suneja, S; Sood, A; Nalawade, G; Jones, M; Morari, A; Puri, R			IEEE	Pujar, Saurabh; Buratti, Luca; Guo, Xiaojie; Dupuis, Nicolas; Lewis, Burn; Suneja, Sahil; Sood, Atin; Nalawade, Ganesh; Jones, Matt; Morari, Alessandro; Puri, Ruchir			Invited: Automated Code generation for Information Technology Tasks in YAML through Large Language Models	2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC			English	Proceedings Paper	60th ACM/IEEE Design Automation Conference (DAC)	JUL 09-13, 2023	San Francisco, CA	IEEE, Assoc Comp Machinery		Generative Model; Ansible; Code Generation		The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible YAML code generation tool, aimed at improving IT automation productivity. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code generation models.	[Pujar, Saurabh; Buratti, Luca; Guo, Xiaojie; Dupuis, Nicolas; Lewis, Burn; Suneja, Sahil; Sood, Atin; Morari, Alessandro; Puri, Ruchir] IBM Res, Yorktown Hts, NY 10598 USA; [Nalawade, Ganesh; Jones, Matt] Red Hat, Raleigh, NC USA	International Business Machines (IBM)	Pujar, S (corresponding author), IBM Res, Yorktown Hts, NY 10598 USA.							Ahmad WU, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2655; Ansible Inc., Ansible Galaxy; Ansible R. H, Red Hat Ansible, automation for everyone; Chen M., 2021, arXiv; Github A, Ansible Github Project; Greengard S, 2023, COMMUN ACM, V66, P12, DOI 10.1145/3583083; Lin C.-Y., 2004, COLING 2004, P501, DOI DOI 10.3115/1220355.1220427; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Papineni K., 2002, IBM Research Report RC22176 (W0109-022); Puri R., 2021, Codenet: A large-scale ai for code dataset for learning a diversity of coding tasks; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38	11	0	0	4	6	IEEE	NEW YORK	345 E 47TH ST, NEW YORK, NY 10017 USA			979-8-3503-2348-1				2023										10.1109/DAC56929.2023.10247987	http://dx.doi.org/10.1109/DAC56929.2023.10247987			4	Computer Science, Artificial Intelligence; Computer Science, Information Systems; Engineering, Electrical & Electronic	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Engineering	BV7XM					2024-07-03	WOS:001073487300292
J	Kallens, PC; Kristensen-McLachlan, RD; Christiansen, MH				Contreras Kallens, Pablo; Kristensen-McLachlan, Ross Deans; Christiansen, Morten H.			Large Language Models Demonstrate the Potential of Statistical Learning in Language	COGNITIVE SCIENCE			English	Article						Large language models; Artificial intelligence; Language acquisition; Statistical learning; Grammar; Innateness; Linguistic experience	PRINCIPLES	To what degree can language be acquired from linguistic input alone? This question has vexed scholars for millennia and is still a major focus of debate in the cognitive science of language. The complexity of human language has hampered progress because studies of language-especially those involving computational modeling-have only been able to deal with small fragments of our linguistic skills. We suggest that the most recent generation of Large Language Models (LLMs) might finally provide the computational tools to determine empirically how much of the human language ability can be acquired from linguistic experience. LLMs are sophisticated deep learning architectures trained on vast amounts of natural language data, enabling them to perform an impressive range of linguistic tasks. We argue that, despite their clear semantic and pragmatic limitations, LLMs have already demonstrated that human-like grammatical language can be acquired without the need for a built-in grammar. Thus, while there is still much to learn about how humans acquire and use language, LLMs provide full-fledged computational models for cognitive scientists to empirically evaluate just how far statistical learning might take us in explaining the full complexity of human language.	[Contreras Kallens, Pablo; Christiansen, Morten H.] Cornell Univ, Dept Psychol, Ithaca, NY USA; [Kristensen-McLachlan, Ross Deans] Aarhus Univ, Ctr Humanities Comp, Aarhus, Denmark; [Kristensen-McLachlan, Ross Deans; Christiansen, Morten H.] Aarhus Univ, Interacting Minds Ctr, Aarhus, Denmark; [Kristensen-McLachlan, Ross Deans; Christiansen, Morten H.] Aarhus Univ, Sch Commun & Culture, Aarhus, Denmark; [Christiansen, Morten H.] Haskins Labs Inc, New Haven, CT USA; [Christiansen, Morten H.] Cornell Univ, Dept Psychol, 228 Uris Hall, Ithaca, NY 14853 USA	Cornell University; Aarhus University; Aarhus University; Aarhus University; Yale University; Haskins Laboratories; Cornell University	Christiansen, MH (corresponding author), Cornell Univ, Dept Psychol, 228 Uris Hall, Ithaca, NY 14853 USA.	christiansen@cornell.edu	Contreras Kallens, Pablo/KHE-3246-2024	Contreras Kallens, Pablo/0000-0002-3805-3488; Christiansen, Morten H./0000-0002-3850-0655; Kristensen-McLachlan, Ross Deans/0000-0001-8714-1911				[Anonymous], 1980, RULES REPRESENTATION; Arehalli S, 2023, Arxiv, DOI arXiv:2210.12187; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; BigScience Workshop, 2022, BLOOM HUGG FAC; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334; Chomsky N., 1995, The Minimalist Program; Chomsky N, 2017, PSYCHON B REV, V24, P200, DOI 10.3758/s13423-016-1078-6; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Christiansen M. H., 2022, The Language Game: How Improvisation Created Language and Changed the World; Christiansen MH, 2016, CREATING LANGUAGE: INTEGRATING EVOLUTION, ACQUISITION, AND PROCESSING, P1; Dabrowska E, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00852; Dettmers T, 2022, Arxiv, DOI arXiv:2208.07339; Dou Y, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P7250; Elman J. L., 1996, Rethinking innateness: A connectionist perspective on development, Vvolume 10; Elman JL, 2005, TRENDS COGN SCI, V9, P111, DOI 10.1016/j.tics.2005.01.005; Ettinger A, 2020, T ASSOC COMPUT LING, V8, P34, DOI 10.1162/tacl_a_00298; Futrell R, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P32; Gilkerson J, 2017, AM J SPEECH-LANG PAT, V26, P248, DOI 10.1044/2016_AJSLP-15-0169; Goldberg AE, 2019, EXPLAIN ME THIS: CREATIVITY, COMPETITION, AND THE PARTIAL PRODUCTIVITY OF CONSTRUCTIONS, P1; Goldstein A, 2022, bioRxiv, DOI [10.1101/2022.07.11.499562, 10.1101/2022.07.11.499562, DOI 10.1101/2022.07.11.499562]; Goldstein A, 2022, NAT NEUROSCI, V25, P369, DOI 10.1038/s41593-022-01026-4; Jackendoff R, 2019, COMP HBK LINGUIST, V3, P215, DOI 10.1515/9783110540253-008; Jackendoff R, 2011, LANGUAGE, V87, P586; Kallens PC, 2022, FRONT ARTIF INTELL, V5, DOI 10.3389/frai.2022.781962; Lieven E, 2014, J CHILD LANG, V41, P48, DOI 10.1017/S0305000914000282; Marcus G., 2020, Technology Review; Marcus G., 2022, The Road to AI We Can Trust (blog); Marcus G., 2022, NAUTILUS; McClelland JL, 2020, P NATL ACAD SCI USA, V117, P25966, DOI 10.1073/pnas.1910416117; Pandia L, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1583; Pinker S., 2022, PINKERS INITIAL SALV; Pinker S., 1994, The Language Instinct: How the Mind Creates Language; Rogers A, 2020, T ASSOC COMPUT LING, V8, P842, DOI 10.1162/tacl_a_00349; Rumelhart D. E., 1987, Distributed Processing: Explorations in the Microstructure ofCognition: Foundations, P318, DOI 10.1016/b978-1-4832-1446-7.50035-2; Skinner B. F., 1957, VERBAL BEHAV; Tomasello M, 2009, CAMB HB LANG LINGUIS, P69; Vaswani A, 2017, ADV NEUR IN, V30; Rae JW, 2022, Arxiv, DOI arXiv:2112.11446; Wilcox EG., 2022, Linguistic Inquiry, V1, DOI DOI 10.1162/LING_A_00491; Yang C, 2017, NEUROSCI BIOBEHAV R, V81, P103, DOI 10.1016/j.neubiorev.2016.12.023; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068	42	18	22	56	100	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	MAR	2023	47	3							e13256	10.1111/cogs.13256	http://dx.doi.org/10.1111/cogs.13256			6	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	9I3MB	36840975				2024-07-03	WOS:000939418000001
J	Crawford, J; Cowling, M; Ashton-Hay, S; Kelder, JA; Middleton, R; Wilson, GS				Crawford, Joseph; Cowling, Michael; Ashton-Hay, Sally; Kelder, Jo-Anne; Middleton, Rebekkah; Wilson, Gail S.			Artificial Intelligence and Authorship Editor Policy: ChatGPT, Bard Bing AI, and beyond	JOURNAL OF UNIVERSITY TEACHING AND LEARNING PRACTICE			English	Article						Large language model; AI contributions; editorial policy; AI-informed research; academic integrity; ethical research		Artificial intelligence and large-language model chatbots have generated significant attention in higher education, and in research practice. Whether ChatGPT, Bard, Jasper Chat, Socratic, Bing AI, DialoGPT, or something else, these are all shaping how education and research occur. In this Editorial, we offer five editorial principles to guide decision-making for editors, which will also become policy for the Journal of University Teaching and Learning Practice. First, we articulate that non-human authorship does not constitute authorship. Second, artificial intelligence should be leveraged to support authors. Third, artificial intelligence can offer useful feedback and pre-review. Fourth, transparency of artificial intelligence usage is an expectation. And fifth, the use of AI in research design, conduct, and dissemination must comply with established ethical principles. In these five principles, we articulate a position of optimism for the new forms of knowledge and research we might garner. We see AI as a mechanism that may augment our current practices but will not likely replace all of them. However, we do issue caution to the limitations of large language models including possible proliferation of poor-quality research, Stochastic Parroting, and data hallucinations. As with all research, authors should be comfortably familiar with the underlying methods being used to generate data and should ensure a clear understanding of the AI tools being used prior to deployment for research.					Crawford, Joseph/J-6397-2019; Middleton, Rebekkah/S-9751-2018; Kelder, Jo-Anne/J-7914-2014	Crawford, Joseph/0000-0002-2191-6216; Middleton, Rebekkah/0000-0002-8440-7451; Kelder, Jo-Anne/0000-0002-8618-0537				Australian Research Council, 2019, Authorship: A guide supporting the Australian Code for the Responsible Conduct of Research; Awdry R, 2022, ASSESS EVAL HIGH EDU, V47, P712, DOI 10.1080/02602938.2021.1957773; Azamfirei R, 2023, CRIT CARE, V27, DOI 10.1186/s13054-023-04393-x; Bearman M., 2020, Reimagining university assessment in a digital world, V7, P37, DOI [DOI 10.1007/978-3-030-41956-14, 10.1007/978-3-030-41956-1_4, DOI 10.1007/978-3-030-41956-1_4]; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bockting CL, 2023, NATURE, V614, P224, DOI 10.1038/d41586-023-00288-7; Booten K, 2020, P ELO2020; Crawford J, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.3.02; Dawson P, 2018, ASSESS EVAL HIGH EDU, V43, P286, DOI 10.1080/02602938.2017.1336746; Eager B, 2023, J UNIV TEACH LEARN P, V20; Felzmann H, 2019, BIG DATA SOC, V6, DOI 10.1177/2053951719860542; Ferrucci D, 2013, ARTIF INTELL, V199, P93, DOI 10.1016/j.artint.2012.06.009; Fowler GA., 2023, WASH POST; Future of Life Institute, 2023, Policymaking in the Pause; Hamzaçebi C, 2009, EXPERT SYST APPL, V36, P3839, DOI 10.1016/j.eswa.2008.02.042; Hassabis D, 2017, NATURE, V544, P413, DOI 10.1038/544413a; Kamal MI, 2021, EDUC INF TECHNOL, V26, P7307, DOI 10.1007/s10639-021-10588-y; King MR, 2023, CELL MOL BIOENG, V16, P1, DOI 10.1007/s12195-022-00754-8; King Stephen., 2020, On writing: A memoir of the craft; Lacasse JR, 2010, PLOS MED, V7, DOI 10.1371/journal.pmed.1000230; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; Lodge JM, 2023, AUSTRALAS J EDUC TEC, V39, P18, DOI 10.14742/ajet.8695; McAdoo T., 2023, CITE CHATGPT; McCarthy J., 1955, A proposal for the Dartmouth summer research project on artificial intelligence; Mhlanga D., 2023, Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning, DOI DOI 10.2139/SSRN.4354422; Perkins M, 2023, J UNIV TEACH LEARN P, V20, DOI 10.53761/1.20.02.07; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; SAMUEL AL, 1960, SCIENCE, V132, P741, DOI 10.1126/science.132.3429.741; Srivastava M., 2023, OSF preprintsFebruary 17, DOI [10.31219/osf.10/wydct, DOI 10.31219/OSF.10/WYDCT]; Stokel-Walker C, 2023, NATURE, V613, P620, DOI 10.1038/d41586-023-00107-z; Sullivan M., 2023, Journal of Applied Learning & Teaching, V6, DOI DOI 10.37074/JALT.2023.6.1.17; Thorp HH, 2023, SCIENCE, V379, P313, DOI 10.1126/science.adg7879; UNESCO, 2023, ChatGPT and Artificial Intelligence in Higher Education: Quick Start Guide; Wikipedia Foundation, 2023, Wikimedia Meta-Wiki8 May; Woods M, 2016, SOC SCI COMPUT REV, V34, P597, DOI 10.1177/0894439315596311; Xames MD, 2023, J. Appl. Learn. Teach, V6, P390, DOI [10.37074/jalt.2023.6.1.20, DOI 10.37074/JALT.2023.6.1.20]	36	0	0	9	12	UNIV WOLLONGONG	WOLLONGONG	NORTHFIELDS AVE, WOLLONGONG, NSW 2522, AUSTRALIA	1449-9789			J UNIV TEACH LEARN P	J. Univ. Teach. Learn. Pract.		2023	20	5							1					12	Education & Educational Research	Emerging Sources Citation Index (ESCI)	Education & Educational Research	Q8VP7					2024-07-03	WOS:001060245600001
J	Dahl, M; Magesh, V; Suzgun, M; Ho, DE				Dahl, Matthew; Magesh, Varun; Suzgun, Mirac; Ho, Daniel E.			Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models	JOURNAL OF LEGAL ANALYSIS			English	Article							LAW	Do large language models (LLMs) know the law? LLMs are increasingly being used to augment legal practice, education, and research, yet their revolutionary potential is threatened by the presence of "hallucinations"-textual output that is not consistent with legal facts. We present the first systematic evidence of these hallucinations in public-facing LLMs, documenting trends across jurisdictions, courts, time periods, and cases. Using OpenAI's ChatGPT 4 and other public models, we show that LLMs hallucinate at least 58% of the time, struggle to predict their own hallucinations, and often uncritically accept users' incorrect legal assumptions. We conclude by cautioning against the rapid and unsupervised integration of popular LLMs into legal tasks, and we develop a typology of legal hallucinations to guide future research in this area.	[Dahl, Matthew] Yale Law Sch, New Haven, CT 06511 USA; [Dahl, Matthew] Yale Univ, Dept Polit Sci, New Haven, CT 06520 USA; [Magesh, Varun; Ho, Daniel E.] Stanford Univ, Regulat Evaluat & Governance Lab, Stanford, CA USA; [Suzgun, Mirac] Stanford Law Sch, Stanford, CA USA; [Suzgun, Mirac] Stanford Univ, Dept Comp Sci, Stanford, CA USA; [Ho, Daniel E.] Stanford Inst Econ Policy Res, Law, Polit Sci, Stanford, CA USA	Yale University; Yale University; Stanford University; Stanford University; Stanford University; Stanford University	Dahl, M (corresponding author), Yale Law Sch, New Haven, CT 06511 USA.; Dahl, M (corresponding author), Yale Univ, Dept Polit Sci, New Haven, CT 06520 USA.	matthew.dahl@yale.edu						Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Agrawal Ayush., 2023, Findings of the Association for Computational Linguistics: EACL 2024, 912-928; Ambrogi Bob., 2023, LawSites; Anil Rohan, 2023, Technical Report, V2, DOI [10.48550/arXiv.2305.10403, DOI 10.48550/ARXIV.2305.10403]; Ash Elliott, 2024, CSLAW '24: Proceedings of the Symposium on Computer Science and Law, P136, DOI 10.1145/3614407.3643700; Azaria A, 2023, Arxiv, DOI arXiv:2304.13734; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bar-Gill O, 2023, J LEGAL ANAL, V15, P1, DOI 10.1093/jla/laad003; Barocas S, 2016, CALIF LAW REV, V104, P671, DOI 10.15779/Z38BG31; Ben-Shahar O, 2023, J LEGAL ANAL, V15, P129, DOI 10.1093/jla/laad008; Black RC, 2013, J EMPIR LEGAL STUD, V10, P325, DOI 10.1111/jels.12012; Blair-Stanek Andrew, 2023, P 19 INT C ART INT L; Bommasani R., 2021, arXiv, DOI [DOI 10.48550/ARXIV.2108.07258, 10.48550/arXiv.2108.07258]; Cao M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P3340; Cao ZQ, 2018, AAAI CONF ARTIF INTE, P4784; Carlini N, 2022, Arxiv, DOI arXiv:2202.07646; Caselaw Access Project, 2023, Caselaw Access Project; Chann S., 2023, Non-Determinism in GPT-4 Is Caused by Sparse MoE; Chen Jiawei, 2023, 38 AAAI C ART INT, P17754, DOI [10.48550/arXiv.2309.01431, DOI 10.48550/ARXIV.2309.01431]; Cheng Xin., 2024, Conference on Neural Information Processing Systems, V37, P1; Chern IC, 2023, Arxiv, DOI arXiv:2307.13528; Chien Colleen V., 2024, Loyola Los Angeles Law Rev; Choi JH, 2022, J LEGAL EDUC, V71, P387; Choi Jonathan H., 2024, J. Legal Educ, DOI DOI 10.2139/SSRN.4539836; Chuang Yung-Sung, 2024, 12 INT C LEARN REPR; Congress.gov, 2023, Table of Supreme Court Decisions Overruled by Subsequent Decisions; Creel K, 2022, CAN J PHILOS, V52, P26, DOI 10.1017/can.2022.3; Cui JX, 2024, Arxiv, DOI [arXiv:2306.16092, 10.48550/arXiv.2306.16092, DOI 10.48550/ARXIV.2306.16092]; Cushman Jack., 2021, Journal of Open Source Software, V6, P3617; DellAcqua Fabrizio., 2023, Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of AI on Knowledge Worker Productivity and Quality, DOI [10.2139/ssrn.4573321, DOI 10.2139/SSRN.4573321]; Deroy A, 2023, Arxiv, DOI [arXiv:2306.01248, 10.48550/arXiv.2306.01248, DOI 10.48550/ARXIV.2306.01248]; Dhuliawala Shehzaad., 2023, arXiv preprint arXiv:2309.11495, DOI [10.48550/arXiv.2309.11495, DOI 10.48550/ARXIV.2309.11495]; Draper Chris., 2023, Proceedings of the ICAIL 2023 Workshop on Artificial Intelligence for Access to Justice; Dworkin Ronald., 1986, Laws Empire; Eloundou T, 2023, Arxiv, DOI [arXiv:2303.10130, DOI 10.48550/ARXIV.2303.10130]; Engel C, 2021, J LEGAL ANAL, V13, P284, DOI 10.1093/jla/laab001; Engstrom DF, 2020, YALE J REGUL, V37, P800; Engstrom David Freeman, 2020, Technical report; Fei ZW, 2023, Arxiv, DOI arXiv:2309.16289; Feijo DD, 2023, ARTIF INTELL LAW, V31, P91, DOI 10.1007/s10506-021-09305-4; Feng SB, 2024, Arxiv, DOI arXiv:2402.00367; Fowler JH, 2007, POLIT ANAL, V15, P324, DOI 10.1093/pan/mpm011; Gao YF, 2024, Arxiv, DOI arXiv:2312.10997; Gillis TB, 2019, U CHICAGO LAW REV, V86, P459; Gou Zhibin, 2024, 12 INT C LEARN REPR; Guha Neel, 2023, 37 C NEUR INF PROC S; Gupta A, 2023, PROCEEDINGS OF THE 6TH ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2023, P492, DOI 10.1145/3593013.3594015; Henderson P, 2022, Arxiv, DOI [arXiv:2207.00220, DOI 10.48550/ARXIV.2207.00220]; Henderson Peter., 2023, J Free Speech Law, V3, P589, DOI DOI 10.48550/ARXIV.2308.04635; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Ji Ziwei., 2023, Findings of the Association for Computational Linguistics: EMNLP 2023, P1827; Jones Erik, 2022, 36Conference on Neural Information Processing Systems, P1, DOI [10.48550/arXiv.2202.1229, DOI 10.48550/ARXIV.2202.1229]; Kadavath S, 2022, Arxiv, DOI arXiv:2207.05221; Kalai AT, 2024, Arxiv, DOI arXiv:2311.14648; Kang HQ, 2024, Arxiv, DOI arXiv:2402.10496; Katz Daniel Martin, 2023, GPT-4 Passes the Bar Exam, DOI DOI 10.2139/SSRN.4389233; Kleinberg J, 2021, P NATL ACAD SCI USA, V118, DOI 10.1073/pnas.2018340118; Kleinberg J, 2018, J LEGAL ANAL, V10, P113, DOI 10.1093/jla/laz001; Krishna K, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4940; Kuersten AshlynK., 2011, UPDATE APPEALS COURT; Lee M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11102320; Lee NY, 2022, Arxiv, DOI arXiv:2206.04624; Lei Deren, 2023, arXiv; Lemley MA, 2019, U CHICAGO LAW REV, V86, P1311; Li JY, 2023, Arxiv, DOI arXiv:2305.11747; Li Kenneth, 2024, Inference-Time Intervention: Eliciting Truthful Answers From a Language Model; Lin SPN, 2022, Arxiv, DOI arXiv:2109.07958; Livermore Michael A., 2024, J. Institut. Theoreti. Econ; Lucas Jason, 2023, P 2023 C EMP METH NA, P14279; Luft Joseph, 1955, P W TRAIN LAB GROUP; Mallen A, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2023): LONG PAPERS, VOL 1, P9802; Manakul P, 2023, Arxiv, DOI [arXiv:2303.08896, 10.48550/arXiv.2303.08896]; Maynez J, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1906; Mayson SG, 2019, YALE LAW J, V128, P2218; Min SW, 2023, Arxiv, DOI arXiv:2305.14251; Mündler N, 2024, Arxiv, DOI arXiv:2305.15852; Nay JJ, 2023, Arxiv, DOI arXiv:2306.07075; OpenAI, 2023, Introducing chatgpt; Peng BL, 2023, Arxiv, DOI [arXiv:2302.12813, DOI 10.48550/ARXIV.2302.12813]; Perlman Andrew., 2023, The Practice; Qin YJ, 2023, Arxiv, DOI arXiv:2304.08354; Ram O, 2023, T ASSOC COMPUT LING, V11, P1316, DOI 10.1162/tacl_a_00605; Razumovskaia Evgeniia, 2023, arXiv; Roberts John G., 2023, 2023 Year-End Report on the Federal Judiciary; Rodgers I, 2023, ANNU REV LAW SOC SCI, V19, P299, DOI 10.1146/annurev-lawsocsci-111522-074716; Romoser James., 2023, SCOTUSblog; Savelka J, 2023, Arxiv, DOI arXiv:2306.09525; Sharma M, 2023, Arxiv, DOI arXiv:2310.13548; Shi WJ, 2023, Arxiv, DOI arXiv:2305.14739; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; Si Chenglei., 2023, 11 INT C LEARN REPR; Simshaw Drew., 2022, Yale J. Law Technol, V24, P150; Siriwardhana S, 2023, T ASSOC COMPUT LING, V11, P1, DOI 10.1162/tacl_a_00530; Solow-Niederman A, 2020, SOUTH CALIF LAW REV, V93, P633; Songer DonaldR., 2008, US COURTS APPEALS DA; Spaeth Harold J, 2014, SCD, V2014 Release 01; Suri G, 2023, Arxiv, DOI [arXiv:2305.04400, 10.48550/ARXIV.2305.04400, DOI 10.48550/ARXIV.2305.04400]; Suzgun M, 2024, Arxiv, DOI arXiv:2401.12954; Tan Jinzhe, 2023, CEUR WORKSHOP P; Tian K, 2023, Arxiv, DOI arXiv:2311.08401; Tian K, 2023, Arxiv, DOI arXiv:2305.14975; Tito Joel, 2017, How AI Can Improve Access to Justice; Tonmoy STI, 2024, Arxiv, DOI arXiv:2401.01313; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Trozze A, 2023, Arxiv, DOI arXiv:2308.06032; TVERSKY A, 1974, SCIENCE, V185, P1124, DOI 10.1126/science.185.4157.1124; van Deemter Kees., 2024, Comput. Linguist, P1; Volokh Eugene., 2023, J. Free Speech Law, V3, P489; Wang CX, 2023, Arxiv, DOI arXiv:2310.07521; Wei J, 2023, Arxiv, DOI [arXiv:2308.03958, 10.48550/arXiv.2308.03958]; Weiser Benjamin., 2023, The New York Times; Wittgenstein Ludwig., TRACTATUS LOGICO PHI; Wu K, 2024, Arxiv, DOI arXiv:2402.02008; Xiong M, 2024, Arxiv, DOI arXiv:2306.13063; Xu WJ, 2023, Arxiv, DOI arXiv:2301.07779; Xu ZW, 2024, Arxiv, DOI arXiv:2401.11817; Yin ZY, 2023, Arxiv, DOI arXiv:2305.18153; Yu WH, 2023, Arxiv, DOI arXiv:2311.09210; Zhang HN, 2024, Arxiv, DOI arXiv:2311.09677; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zhang YF, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P295, DOI 10.1145/3351095.3372852	121	0	0	0	0	OXFORD UNIV PRESS	OXFORD	GREAT CLARENDON ST, OXFORD OX2 6DP, ENGLAND	2161-7201	1946-5319		J LEGAL ANAL	J. Leg. Anal.	JUN 26	2024	16	1					64	93		10.1093/jla/laae003	http://dx.doi.org/10.1093/jla/laae003			30	Law	Social Science Citation Index (SSCI)	Government & Law	WI2Y4		Green Submitted, gold			2024-07-03	WOS:001254187200001
J	Giray, L				Giray, Louie			Prompt Engineering with ChatGPT: A Guide for Academic Writers	ANNALS OF BIOMEDICAL ENGINEERING			English	Article						Academic writing; ChatGPT; Large language models; Natural language processing; Prompt engineering; Prompts		Prompt engineering is a relatively new discipline that refers to the practice of developing and optimizing prompts to effectively utilize large language models, particularly in natural language processing tasks. However, not many writers and researchers are familiar about this discipline. Hence, in this paper, I aim to highlight the significance of prompt engineering for academic writers and researchers, particularly the fledgling, in the rapidly evolving world of artificial intelligence. I also discuss the concepts of prompt engineering, large language models, and the techniques and pitfalls of writing prompts. Here, I contend that by acquiring prompt engineering skills, academic writers can navigate the changing landscape and leverage large language models to enhance their writing process. As artificial intelligence continues to advance and penetrate the arena of academic writing, prompt engineering equips writers and researchers with the essential skills to effectively harness the power of language models. This enables them to confidently explore new opportunities, enhance their writing endeavors, and remain at the forefront of utilizing cutting-edge technologies in their academic pursuits.	[Giray, Louie] Colegio Muntinlupa, Gen Educ Dept, Muntinlupa, Philippines		Giray, L (corresponding author), Colegio Muntinlupa, Gen Educ Dept, Muntinlupa, Philippines.	louiegiray@gmail.com	Giray, Louie/AGV-8089-2022	Giray, Louie/0000-0002-1940-035X				DAIR.AI, 2023, EL PROMPT; Gero KI, 2022, PROCEEDINGS OF THE FIRST WORKSHOP ON INTELLIGENT AND INTERACTIVE WRITING ASSISTANTS (IN2WRITING 2022), P83; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Mollman S., 2022, YAHOO FINANCE; White J., 2023, arXiv	5	35	36	194	370	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0090-6964	1573-9686		ANN BIOMED ENG	Ann. Biomed. Eng.	DEC	2023	51	12					2629	2633		10.1007/s10439-023-03272-4	http://dx.doi.org/10.1007/s10439-023-03272-4		JUN 2023	5	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	X3KT5	37284994				2024-07-03	WOS:001004173700002
J	Ji, EY				Ji, Eugene Yu			Large Language Models: A Historical and Sociocultural Perspective	COGNITIVE SCIENCE			English	Letter						Large language models; Statistical learning; Sociolinguistics and linguistic anthropology; History of cognitive science; Language in culture and society		This letter explores the intricate historical and contemporary links between large language models (LLMs) and cognitive science through the lens of information theory, statistical language models, and socioanthropological linguistic theories. The emergence of LLMs highlights the enduring significance of information-based and statistical learning theories in understanding human communication. These theories, initially proposed in the mid-20th century, offered a visionary framework for integrating computational science, social sciences, and humanities, which nonetheless was not fully fulfilled at that time. The subsequent development of sociolinguistics and linguistic anthropology, especially since the 1970s, provided critical perspectives and empirical methods that both challenged and enriched this framework. This letter proposes that two pivotal concepts derived from this development, metapragmatic function and indexicality, offer a fruitful theoretical perspective for integrating the semantic, textual, and pragmatic, contextual dimensions of communication, an amalgamation that contemporary LLMs have yet to fully achieve. The author believes that contemporary cognitive science is at a crucial crossroads, where fostering interdisciplinary dialogues among computational linguistics, social linguistics and linguistic anthropology, and cognitive and social psychology is in particular imperative. Such collaboration is vital to bridge the computational, cognitive, and sociocultural aspects of human communication and human-AI interaction, especially in the era of large language and multimodal models and human-centric Artificial Intelligence (AI).	[Ji, Eugene Yu] Univ Chicago, Div Social Sci, Chicago, IL USA; [Ji, Eugene Yu] Univ Chicago, Div Social Sci, 1115 E 58th St, Chicago, IL 60637 USA	University of Chicago; University of Chicago	Ji, EY (corresponding author), Univ Chicago, Div Social Sci, 1115 E 58th St, Chicago, IL 60637 USA.	yuji1@uchicago.edu						Agha A, 2007, STUD SOC CULT FOUND, V24, P1, DOI 10.2277/ 0521576857; Alikhani M., 2023, Image-Text coherence and its implications for multimodal AI: Frontier in artificial intelligence; [Anonymous], 1973, Semiotica, DOI DOI 10.1515/SEMI.1973.8.4.289; Austin J. L., 1962, DO THINGS WORDS; Betker J., 2023, Improving image generation with better captions; Brooks T., 2024, Video generation models as world simulators; Chater N., 2015, EMPIRICISM LANGUAGE; Chater N, 2022, BEHAV BRAIN SCI, V46, DOI 10.1017/S0140525X22000735; CHOMSKY N, 1959, LANGUAGE, V35, P26, DOI 10.2307/411334; Chomsky N., 2023, New York Times; Christiansen M. H., 2022, The Language Game: How Improvisation Created Language and Changed the World; Christiansen MH, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01182; Kallens PC, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13256; Decety J, 2015, MORAL BRAIN: A MULTIDISCIPLINARY PERSPECTIVE, P279; Deshpande A, 2023, Arxiv, DOI arXiv:2304.05335; Fisac JF, 2020, SPR PROC ADV ROBOT, V10, P49, DOI 10.1007/978-3-030-28619-4_7; Frank MC, 2012, SCIENCE, V336, P998, DOI 10.1126/science.1218633; Gabriel I., 2023, Philos Technol, V36, DOI DOI 10.1007/S13347-023-00606-X; Gal S, 2019, SIGNS OF DIFFERENCE, P1, DOI 10.1017/9781108649209; Geoghegan BD, 2011, CRIT INQUIRY, V38, P96, DOI 10.1086/661645; Goldsmith J., 2020, Battle in the mind fields; Goodman ND, 2016, TRENDS COGN SCI, V20, P818, DOI 10.1016/j.tics.2016.08.005; Grice HP., 1975, SYNTAX SEMANTICS, P41, DOI [DOI 10.1163/9789004368811_003, 10.1163/9789004368811_003]; Grice P., 1989, STUDIES WAYS WORDS; Gubelmann R., 2023, P 12 JOINT C LEX COM, P24; Gunderson K., 1975, MINNESOTA STUDIES PH, P131, DOI DOI 10.1017/CBO9780511625251.014; Huebner PA, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00133; Jakobson R., 1960, Style in Language, P350, DOI DOI 10.1371/JOURNAL.PONE.0098679; Kanske P, 2018, INTERDISCIPL SCI REV, V43, P115, DOI 10.1080/03080188.2018.1453243; Kleinberg J, 2020, P NATL ACAD SCI USA, V117, P30096, DOI 10.1073/pnas.1912790117; Landauer TK, 1997, PSYCHOL REV, V104, P211, DOI 10.1037/0033-295X.104.2.211; Levinson Stephen., 2000, PRAGMATICS; Li AN, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13290; Lipkin B, 2023, Arxiv, DOI arXiv:2305.01020; Mahowald K, 2023, Arxiv, DOI [arXiv:2301.06627, DOI 10.48550/ARXIV.2301.06627]; Piantadosi S., 2023, Lingbuzz lingbuzz/007180; Preyer Gerhard, 2018, Beyond semantics and pragmatics; Rambachan A, 2020, AEA PAP P, V110, P91, DOI 10.1257/pandp.20201036; Saxe R., 2016, Theory of mind: A special issue of social neuroscience; Shannon C.E., 1949, The Mathematical Theory of Communication; SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x; Silverstein M., 1976, MEANING ANTHR, P11; Silverstein M., 2022, Language in culture; Silverstein Michael., 1993, Reflexive Language: Reported Speech and Metapragmatics, P33, DOI DOI 10.1017/CBO9780511621031.004; Tomasello M., 2003, CONSTRUCTING LANGUAG; Urban G., 2006, Metasemiosis and metapragmatics; Weaver W., 1964, ALICE MANY TONGUES T; Williams K. D., 2001, The social mind: Cognitive and motivational aspects of interpersonal behavior, P294; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421	49	0	0	15	15	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0364-0213	1551-6709		COGNITIVE SCI	Cogn. Sci.	MAR	2024	48	3							e13430	10.1111/cogs.13430	http://dx.doi.org/10.1111/cogs.13430			6	Psychology, Experimental	Social Science Citation Index (SSCI)	Psychology	LM2E6	38500317				2024-07-03	WOS:001187144500001
C	Evans, M; Soós, D; Landers, E; Wu, J			ACM	Evans, Michael; Soos, Dominik; Landers, Ethan; Wu, Jian			MSVEC: A Multidomain Testing Dataset for Scientific Claim Verification	PROCEEDINGS OF THE 2023 INTERNATIONAL SYMPOSIUM ON THEORY, ALGORITHMIC FOUNDATIONS, AND PROTOCOL DESIGN FOR MOBILE NETWORKS AND MOBILE COMPUTING, MOBIHOC 2023			English	Proceedings Paper	International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (ACM MobiHoc)	OCT 23-26, 2023	Washington, DC	Assoc Comp Machinery, ACM SIGMOBILE		benchmark datasets; natural language processing; large language models; machine learning		The increase of disinformation in scientific news across a variety of domains has generated an urgency for a robust and generalizable approach to automated scientific claim verification (SCV). Available methods of SCV are limited in either domain adaptability or scalability. To facilitate building and evaluating more robust models on SCV we propose MSVEC, a multidomain dataset containing 200 pairs of verified scientific news claims with evidence research papers. To understand the capability of large language models on the SCV task, we evaluated GPT-3.5 against MSVEC. While methods of fact-checking exist for specific domains (e.g., political and health), the use of large language models exhibits better generalizability across multiple domains and is potentially compared with state-of-the-art models based on word embeddings. The data and software used and developed for this project are available at https://github.com/lamps-lab/msvec.	[Evans, Michael; Soos, Dominik; Landers, Ethan; Wu, Jian] Old Dominion Univ, Norfolk, VA 23529 USA	Old Dominion University	Evans, M (corresponding author), Old Dominion Univ, Norfolk, VA 23529 USA.	mevan028@odu.edu; dsoos001@odu.edu; eland007@odu.edu; jwu@cs.odu.edu		Soos, Dominik/0000-0002-7089-6354; Wu, Jian/0000-0003-0173-4463	National Science Foundation REU Site Award [2149607]; Virginia Commonwealth Cyber Initiative Grant [H-4Q21-014]	National Science Foundation REU Site Award(National Science Foundation (NSF)); Virginia Commonwealth Cyber Initiative Grant	This project is partially supported by National Science Foundation REU Site Award #2149607 and the Virginia Commonwealth Cyber Initiative Grant #H-4Q21-014.	Ardia D. S., 2020, Addressing the Decline of Local News, Rise of Platforms, and Spread of Mis-And Disinformation Online; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; DeHaven M, 2023, Arxiv, DOI arXiv:2303.16974; Devlin J., 2018, BERT PRE TRAINING DE; Saakyan A, 2021, Arxiv, DOI arXiv:2106.03794; Sarrouti M., 2021, FINDINGS ASS COMPUTA, P3499; Voorhees Ellen, 2020, ACM SIGIR Forum, V54, DOI 10.1145/3451964.3451965; Wadden D, 2020, Arxiv, DOI arXiv:2004.14974; Wadden David, 2021, arXiv; Wadden David, 2022, arXiv	10	0	0	0	0	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			978-1-4503-9926-5				2023							504	509		10.1145/3565287.3617630	http://dx.doi.org/10.1145/3565287.3617630			6	Computer Science, Information Systems; Computer Science, Theory & Methods; Telecommunications	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science; Telecommunications	BW2UG		Bronze			2024-07-03	WOS:001125985600072
J	Lyu, Q; Tan, J; Zapadka, ME; Ponnatapura, J; Niu, C; Myers, KJ; Wang, G; Whitlow, CT				Lyu, Qing; Tan, Josh; Zapadka, Michael E.; Ponnatapura, Janardhana; Niu, Chuang; Myers, Kyle J.; Wang, Ge; Whitlow, Christopher T.			Translating radiology reports into plain language using ChatGPT and GPT-4 with prompt learning: results, limitations, and potential	VISUAL COMPUTING FOR INDUSTRY BIOMEDICINE AND ART			English	Article						Artificial intelligence; Large language model; ChatGPT; Radiology report; Patient education		The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on translating radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest computed tomography lung cancer screening scans and 76 brain magnetic resonance imaging metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.27 in the five-point system with 0.08 places of information missing and 0.07 places of misinformation. In terms of the suggestions provided by ChatGPT, they are generally relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offers specific suggestions based on findings in the report. ChatGPT also presents some randomness in its responses with occasionally over-simplified or neglected information, which can be mitigated using a more detailed prompt. Furthermore, ChatGPT results are compared with a newly released large model GPT-4, showing that GPT-4 can significantly improve the quality of translated reports. Our results show that it is feasible to utilize large language models in clinical education, and further efforts are needed to address limitations and maximize their potential.	[Lyu, Qing; Tan, Josh; Zapadka, Michael E.; Ponnatapura, Janardhana; Whitlow, Christopher T.] Wake Forest Univ, Bowman Gray Sch Med, Dept Radiol, Winston Salem, NC 27103 USA; [Niu, Chuang; Wang, Ge] Rensselaer Polytech Inst, Biomed Imaging Ctr, Troy, NY 12180 USA; [Myers, Kyle J.] Puente Solut LLC, Phoenix, AZ 85065 USA	Wake Forest University; Wake Forest Baptist Medical Center; Rensselaer Polytechnic Institute	Whitlow, CT (corresponding author), Wake Forest Univ, Bowman Gray Sch Med, Dept Radiol, Winston Salem, NC 27103 USA.; Wang, G (corresponding author), Rensselaer Polytech Inst, Biomed Imaging Ctr, Troy, NY 12180 USA.; Myers, KJ (corresponding author), Puente Solut LLC, Phoenix, AZ 85065 USA.	drkylejmyers@gmail.com; wangg6@rpi.edu; cwhitlow@wakehealth.edu	Wang, Ge/AAH-8592-2020	Wang, Ge/0000-0002-2656-7705; Lyu, Qing/0000-0002-9824-0170				[Anonymous], CHATGPT REACH 100 MI; [Anonymous], PROMPTPERFECT EL YOU; [Anonymous], ChatGPT sets record for fastest-growing user base-analyst note; [Anonymous], GPT-4; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Jeblick K., 2022, arXiv, DOI [DOI 10.1007/S00330-023-10213-1, 10.1007/s00330-023-10213-1]; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Liebrenz M, 2023, LANCET DIGIT HEALTH, V5, pE105, DOI 10.1016/S2589-7500(23)00019-5; OpenAI, 2023, GPT-4 Technical Report; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Radford A., 2018, Improving Language Understanding by Generative Pre-Training; Rao ARY, 2023, medRxiv, DOI [10.1101/2023.02.02.23285399, 10.1101/2023.02.02.23285399, DOI 10.1101/2023.02.02.23285399]; Sarraju A, 2023, JAMA-J AM MED ASSOC, V329, P842, DOI 10.1001/jama.2023.1044; Wang S, 2023, Arxiv, DOI [arXiv:2302.03495, DOI 10.48550/ARXIV.2302.03495, 10.48550/arxiv.2302.03495]; Yang ZL, 2019, ADV NEUR IN, V32	17	49	49	19	80	SPRINGER SINGAPORE PTE LTD	SINGAPORE	#04-01 CENCON I, 1 TANNERY RD, SINGAPORE 347719, SINGAPORE		2524-4442		VIS COMPUT IND BIOME	Vis. Comput. Ind. Biomed. Art	MAY 18	2023	6	1							9	10.1186/s42492-023-00136-5	http://dx.doi.org/10.1186/s42492-023-00136-5			10	Computer Science, Interdisciplinary Applications; Engineering, Electrical & Electronic; Imaging Science & Photographic Technology	Emerging Sources Citation Index (ESCI)	Computer Science; Engineering; Imaging Science & Photographic Technology	G4WO2	37198498	Green Published, gold			2024-07-03	WOS:000989177600001
J	Civettini, I; Zappaterra, A; Granelli, BM; Rindone, G; Aroldi, A; Bonfanti, S; Colombo, F; Fedele, M; Grillo, G; Parma, M; Perfetti, P; Terruzzi, E; Gambacorti-Passeríni, C; Ramazzotti, D; Cavalca, F				Civettini, Ivan; Zappaterra, Arianna; Granelli, Bianca Maria; Rindone, Giovanni; Aroldi, Andrea; Bonfanti, Stefano; Colombo, Federica; Fedele, Marilena; Grillo, Giovanni; Parma, Matteo; Perfetti, Paola; Terruzzi, Elisabetta; Gambacorti-Passerini, Carlo; Ramazzotti, Daniele; Cavalca, Fabrizio			Evaluating the performance of large language models in haematopoietic stem cell transplantation decision-making	BRITISH JOURNAL OF HAEMATOLOGY			English	Article						artificial intelligence; GPT; HSC transplantation; interrater agreement; transplant	RISK SCORE	In a first-of-its-kind study, we assessed the capabilities of large language models (LLMs) in making complex decisions in haematopoietic stem cell transplantation. The evaluation was conducted not only for Generative Pre-trained Transformer 4 (GPT-4) but also conducted on other artificial intelligence models: PaLm 2 and Llama-2. Using detailed haematological histories that include both clinical, molecular and donor data, we conducted a triple-blind survey to compare LLMs to haematology residents. We found that residents significantly outperformed LLMs (p = 0.02), particularly in transplant eligibility assessment (p = 0.01). Our triple-blind methodology aimed to mitigate potential biases in evaluating LLMs and revealed both their promise and limitations in deciphering complex haematological clinical scenarios. In the evolving landscape of growing interest in large language models (LLMs) within medical research, an evaluation of the performance of current LLMs in the setting of haematopoietic stem cell transplantation was lacking. In this study, we proposed clinical haematological stories rich in clinical and molecular details to transplant specialists, LLMs, and haematology residents utilizing a triple-blind methodology. The performance of LLMs was compared to that of haematology residents, considering as baseline values the consensus answer (CoA) of transplant specialists, defined as the predominant response from experts in each topic of the clinical case (transplantation eligibility, donor choice, conditioning regimen choice and transplant-related mortality [TRM]).image	[Civettini, Ivan; Zappaterra, Arianna; Granelli, Bianca Maria; Rindone, Giovanni; Bonfanti, Stefano; Colombo, Federica; Gambacorti-Passerini, Carlo; Ramazzotti, Daniele] Univ Milano Bicocca, Dept Med & Surg, Monza, Italy; [Civettini, Ivan; Zappaterra, Arianna; Granelli, Bianca Maria; Rindone, Giovanni; Aroldi, Andrea; Bonfanti, Stefano; Colombo, Federica; Fedele, Marilena; Parma, Matteo; Perfetti, Paola; Terruzzi, Elisabetta; Gambacorti-Passerini, Carlo; Cavalca, Fabrizio] Fdn IRCCS San Gerardo Tintori, Dept Haematol, Monza, Italy; [Civettini, Ivan; Zappaterra, Arianna; Granelli, Bianca Maria; Rindone, Giovanni; Aroldi, Andrea; Bonfanti, Stefano; Colombo, Federica; Fedele, Marilena; Parma, Matteo; Perfetti, Paola; Terruzzi, Elisabetta; Gambacorti-Passerini, Carlo; Cavalca, Fabrizio] Fdn IRCCS San Gerardo Tintori, Bone Marrow Trasplantat Unit, Monza, Italy; [Zappaterra, Arianna; Grillo, Giovanni] ASST Grande Osped Metropolitano Niguarda, Dept Haematol, Milan, Italy; [Zappaterra, Arianna; Grillo, Giovanni] ASST Grande Osped Metropolitano Niguarda, Bone Marrow Transplantat Unit, Milan, Italy; [Civettini, Ivan] Univ Milano Bicocca, Fdn IRCCS San Gerardo Tintori Hosp Monza, Haematol Div, Via Cadore 48, I-20900 Monza, Italy	University of Milano-Bicocca; Fondazione IRCCS San Gerardo dei Tintori; Fondazione IRCCS San Gerardo dei Tintori; University of Milano-Bicocca	Civettini, I (corresponding author), Univ Milano Bicocca, Fdn IRCCS San Gerardo Tintori Hosp Monza, Haematol Div, Via Cadore 48, I-20900 Monza, Italy.	i.civettini@campus.unimib.it	Aroldi, Andrea/AAA-2936-2022; Civettini, Ivan/JUU-9868-2023	Civettini, Ivan/0000-0002-7707-584X; RAMAZZOTTI, DANIELE/0000-0002-6087-2666				[Anonymous], Available; Carreras E, 2019, EBMT HANDBOOK: HEMATOPOIETIC STEM CELL TRANSPLANTATION AND CELLULAR THERAPIES, P1, DOI 10.1007/978-3-030-02278-5; Cloud.google, US; COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104; FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619; garyschwartzarthistorian, US; Haemmerli J, 2023, BMJ HEALTH CARE INFO, V30, DOI 10.1136/bmjhci-2023-100775; Hendrycks D., 2021, INT C LEARNING REPRE; Hoch CC, 2023, EUR ARCH OTO-RHINO-L, V280, P4271, DOI 10.1007/s00405-023-08051-4; huggingface, About Us; Jin D., 2020, WHAT DIS DOES THIS P; Jin Qiao, 2019, Pubmedqa: A dataset for biomedical research question answering, P2567; Mahan D., STABLE BELUGA MODELS; Parimon T, 2006, ANN INTERN MED, V144, P407, DOI 10.7326/0003-4819-144-6-200603210-00007; Sim J, 2005, PHYS THER, V85, P257; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Sorror ML, 2010, HEMATOL-AM SOC HEMAT, P237, DOI 10.1182/asheducation-2010.1.237; Terwey TH, 2010, HAEMATOL-HEMATOL J, V95, P810, DOI 10.3324/haematol.2009.011809; Thirunavukarasu Arun James, 2023, JMIR Med Educ, V9, pe46599, DOI 10.2196/46599; Touvron H., LLAMA 2 OPEN FDN FIN, DOI DOI 10.48550/ARXIV.2307.09288	20	3	3	9	10	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0007-1048	1365-2141		BRIT J HAEMATOL	Br. J. Haematol.	APR	2024	204	4					1523	1528		10.1111/bjh.19200	http://dx.doi.org/10.1111/bjh.19200		DEC 2023	6	Hematology	Science Citation Index Expanded (SCI-EXPANDED)	Hematology	NI6B4	38070128	hybrid			2024-07-03	WOS:001117343100001
C	Deng, YL; Xia, CS; Peng, HR; Yang, CY; Zhan, LM		Just, R; Fraser, G		Deng, Yinlin; Xia, Chunqiu Steven; Peng, Haoran; Yang, Chenyuan; Zhan, Lingming			Large Language Models Are Zero-Shot Fuzzers: Fuzzing Deep-Learning Libraries via Large Language Models	PROCEEDINGS OF THE 32ND ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, ISSTA 2023			English	Proceedings Paper	32nd ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA)	JUL 17-21, 2023	Seattle, WA	Assoc Comp Machinery, ACM SIGSOFT, AITO		Fuzz Testing; Test Generation; Large Language Model		Deep Learning (DL) systems have received exponential growth in popularity and have become ubiquitous in our everyday life. Such systems are built on top of popular DL libraries, e.g., TensorFlow and PyTorch which provide APIs as building blocks for DL systems. Detecting bugs in these DL libraries is critical for almost all downstream DL systems in ensuring effectiveness/safety for end users. Meanwhile, traditional fuzzing techniques can be hardly effective for such a challenging domain since the input DL programs need to satisfy both the input language (e.g., Python) syntax/semantics and the DL API input/shape constraints for tensor computations. To address these limitations, we propose TitanFuzz - the first approach to directly leveraging Large Language Models (LLMs) to generate input programs for fuzzing DL libraries. LLMs are titanic models trained on billions of code snippets and can autoregressively generate human-like code snippets. Our key insight is that modern LLMs can also include numerous code snippets invoking DL library APIs in their training corpora, and thus can implicitly learn both language syntax/semantics and intricate DL API constraints for valid DL program generation. More specifically, we use both generative and infilling LLMs (e.g., Codex/InCoder) to generate and mutate valid/diverse input DL programs for fuzzing. Our experimental results demonstrate that TitanFuzz can achieve 30.38%/50.84% higher code coverage than state-of-the-art fuzzers on TensorFlow/PyTorch. Furthermore, TitanFuzz is able to detect 65 bugs, with 44 already confirmed as previously unknown bugs. This paper demonstrates that modern titanic LLMs can be leveraged to directly perform both generation-based and mutation-based fuzzing studied for decades, while being fully automated, generalizable, and applicable to domains challenging for traditional approaches (such as DL systems). We hope TitanFuzz can stimulate more work in this promising direction of LLMs for fuzzing.	[Deng, Yinlin; Xia, Chunqiu Steven; Yang, Chenyuan; Zhan, Lingming] Univ Illinois, Urbana, IL 61820 USA; [Peng, Haoran] Univ Sci & Technol China, Hefei, Anhui, Peoples R China	University of Illinois System; University of Illinois Urbana-Champaign; Chinese Academy of Sciences; University of Science & Technology of China, CAS	Deng, YL (corresponding author), Univ Illinois, Urbana, IL 61820 USA.	yinlind2@illinois.edu; chunqiu2@illinois.edu; hurrypeng@mail.ustc.edu.cn; cy54@illinois.edu; lingming@illinois.edu		Peng, Haoran/0000-0001-5147-815X	NSF [CCF-2131943, CCF-2141474]; Kwai Inc.; Google; Meta	NSF(National Science Foundation (NSF)); Kwai Inc.; Google(Google Incorporated); Meta	We thank the reviewers for their insightful feedback and comments to improve this paper. This work was partially supported by NSF grants CCF-2131943 and CCF-2141474. We also acknowledge support from Kwai Inc., Google, and Meta.	Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; [Anonymous], 2022, Beta distribution; [Anonymous], 2022, Gamma function; [Anonymous], 2022, Codex Documentation-Best Practices; [Anonymous], 2022, Coverage.py; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; Banerjee Rahul, 2021, Codecov; Böhme M, 2021, IEEE SOFTWARE, V38, P79, DOI 10.1109/MS.2020.3016773; Brown Dalvin, 2021, WASH. POST; Chapelle Olivier, 2011, An Empirical Evaluation of Thompson Sampling, V24; Chen M., 2021, arXiv; Cho K., 2014, P C EMP METH NAT LAN, DOI DOI 10.3115/V1/D14-1179; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Cummins C, 2018, ISSTA'18: PROCEEDINGS OF THE 27TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS, P95, DOI 10.1145/3213846.3213848; Deng YL, 2022, PROCEEDINGS OF THE 30TH ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2022, P44, DOI 10.1145/3540250.3549085; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Fioraldi A., 2020, P 14 USENIX C OFFENS, P10; Fraser G., 2011, P 19 ACM SIGSOFT S 1, P416, DOI 10.1145/2025113.2025179; Fraser G, 2013, IEEE T SOFTWARE ENG, V39, P276, DOI 10.1109/TSE.2012.14; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Gibbs J. W., 1902, Elementary principles in statistical mechanic; Godefroid P, 2017, IEEE INT CONF AUTOM, P50, DOI 10.1109/ASE.2017.8115618; Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672, DOI 10.1145/3422622; Gu JZ, 2022, PROC INT CONF SOFTW, P1418, DOI 10.1145/3510003.3510092; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Guo QY, 2020, IEEE INT CONF AUTOM, P486, DOI 10.1145/3324884.3416571; Hindle A, 2012, PROC INT CONF SOFTW, P837, DOI 10.1109/ICSE.2012.6227135; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Holler C, 2012, P 21 USENIX C SECURI, P445; Holtzman A, 2020, Arxiv, DOI arXiv:1904.09751; Hu ZC, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P138, DOI 10.1145/3203217.3203241; HuggingFace, 2022, Hugging Face; Pham HV, 2019, PROC INT CONF SOFTW, P1027, DOI 10.1109/ICSE.2019.00107; Huval B, 2015, Arxiv, DOI arXiv:1504.01716; Keras, 2020, Keras; Klees G, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2123, DOI 10.1145/3243734.3243804; Lampropoulos L, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360607; Lee S, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2613; Lemieux C, 2018, IEEE INT CONF AUTOM, P475, DOI 10.1145/3238147.3238176; Lemieux Caroline, 2023, 45 INT C SOFTWARE EN; Lester B, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P3045; Liu JW, 2023, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, VOL 2, ASPLOS 2023, P530, DOI 10.1145/3575693.3575707; Liu JW, 2023, Arxiv, DOI [arXiv:2305.01210, DOI arXiv:2305.01210.v1]; Liu JW, 2022, P ACM PROGRAM LANG, V6, DOI 10.1145/3527317; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu X, 2019, AAAI CONF ARTIF INTE, P1044; Liu Y, 2019, arXiv; MANNA Z, 1971, COMMUN ACM, V14, P151, DOI 10.1145/362566.362568; Nie Pengyu, 2023, 45 INT C SOFTW ENG; Nye Maxwell, 2021, arXiv; Odena A, 2021, Arxiv, DOI arXiv:2007.14381; Park J, 2021, P ACM PROGRAM LANG, V5, DOI 10.1145/3485529; PyTorch, 2018, PyTorch; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Reynolds L, 2021, Arxiv, DOI [arXiv:2102.07350, 10.48550/arXiv.2102.07350, DOI 10.48550/ARXIV.2102.07350]; Russo DJ, 2018, FOUND TRENDS MACH LE, V11, P1, DOI 10.1561/2200000070; Schäfer M, 2023, Arxiv, DOI [arXiv:2302.06527, 10.48550/arXiv.2302.06527]; Schulman John, 2022, Chatgpt: Optimizing language models for dialogue; Serebryany K., 2015, LLVM project; Solar-Lezama A., 2008, Program synthesis by sketching; Xia CS, 2022, Arxiv, DOI arXiv:2207.08281; Sutton M., 2007, Fuzzing: brute force vulnerability discovery; TensorFlow, 2020, Tensorflow; Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.1093/biomet/25.3-4.285; Tugend Alina, 2021, The New York Times; Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762]; Le V, 2014, ACM SIGPLAN NOTICES, V49, P216, DOI [10.1145/2666356.2594334, 10.1145/2594291.2594334]; Wang JN, 2022, PROC INT CONF SOFTW, P798, DOI 10.1145/3510003.3510165; Wang Z, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P788, DOI 10.1145/3368089.3409761; Wei AJ, 2022, PROC INT CONF SOFTW, P995, DOI 10.1145/3510003.3510041; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Xia CS, 2023, PROC INT CONF SOFTW, P1482, DOI 10.1109/ICSE48619.2023.00129; Xia CS, 2023, Arxiv, DOI arXiv:2304.00385; Xie Danning, 2022, P 31 ACM SIGSOFT INT; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yang Chenyuan, 2023, INT C SOFTWARE ENG I; Yang XJ, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P283; Yang ZL, 2020, Arxiv, DOI arXiv:1906.08237; Ye GX, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P435, DOI 10.1145/3453483.3454054; YueWang Joty, 2021, P 2021 C EMPIRICAL M; Zalewski Michal, 2016, American Fuzzy Lop-Whitepaper; Zeller A., 2019, The fuzzing book; Zhang MS, 2018, IEEE INT CONF AUTOM, P132, DOI 10.1145/3238147.3238187; Zhao H, 2019, IEEE INT CONF SOFTW, P59, DOI 10.1109/ICST.2019.00016	86	6	7	10	12	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0221-1				2023							423	435		10.1145/3597926.3598067	http://dx.doi.org/10.1145/3597926.3598067			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW2OB		Green Submitted			2024-07-03	WOS:001122661400035
J	McLean, AL; Wu, YH; McLean, ACL; Hristidis, V				McLean, Aaron Lawson; Wu, Yonghui; McLean, Anna C. Lawson; Hristidis, Vagelis			Large language models as decision aids in neuro-oncology: a review of shared decision-making applications	JOURNAL OF CANCER RESEARCH AND CLINICAL ONCOLOGY			English	Review						Shared decision making; Large language models; Neuro-oncology care; Patient engagement; Ethical considerations; Healthcare integration		Shared decision-making (SDM) is crucial in neuro-oncology, fostering collaborations between patients and healthcare professionals to navigate treatment options. However, the complexity of neuro-oncological conditions and the cognitive and emotional burdens on patients present significant barriers to achieving effective SDM. This discussion explores the potential of large language models (LLMs) such as OpenAI's ChatGPT and Google's Bard to overcome these barriers, offering a means to enhance patient understanding and engagement in their care. LLMs, by providing accessible, personalized information, could support but not supplant the critical insights of healthcare professionals. The hypothesis suggests that patients, better informed through LLMs, may participate more actively in their treatment choices. Integrating LLMs into neuro-oncology requires navigating ethical considerations, including safeguarding patient data and ensuring informed consent, alongside the judicious use of AI technologies. Future efforts should focus on establishing ethical guidelines, adapting healthcare workflows, promoting patient-oriented research, and developing training programs for clinicians on the use of LLMs. Continuous evaluation of LLM applications will be vital to maintain their effectiveness and alignment with patient needs. Ultimately, this exploration contends that the thoughtful integration of LLMs into SDM processes could significantly enhance patient involvement and strengthen the patient-physician relationship in neuro-oncology care.	[McLean, Aaron Lawson; McLean, Anna C. Lawson] Jena Univ Hosp, Friedrich Schiller Univ Jena, Dept Neurosurg, Klinikum 1, D-07747 Jena, Germany; [McLean, Aaron Lawson; McLean, Anna C. Lawson] Comprehens Canc Ctr Cent Germany, Jena, Germany; [Wu, Yonghui] Univ Florida, Coll Med, Dept Hlth Outcomes & Biomed Informat, Gainesville, FL USA; [Hristidis, Vagelis] Univ Calif Riverside, Comp Sci & Engn, Riverside, CA 92521 USA	Friedrich Schiller University of Jena; State University System of Florida; University of Florida; University of California System; University of California Riverside	McLean, AL (corresponding author), Jena Univ Hosp, Friedrich Schiller Univ Jena, Dept Neurosurg, Klinikum 1, D-07747 Jena, Germany.; McLean, AL (corresponding author), Comprehens Canc Ctr Cent Germany, Jena, Germany.	aaron.lawsonmclean@med.uni-jena.de; yonghui.wu@ufl.edu; anna.lawsonmclean@med.uni-jena.de; vagelis@cs.ucr.edu		Wu, Yonghui/0000-0002-6780-6135; Christidis, Evangelos/0000-0001-8905-2832	National Institute on Aging	National Institute on Aging(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Institute on Aging (NIA))	No Statement Available	Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Baumgartner C, 2023, CLIN TRANSL MED, V13, DOI 10.1002/ctm2.1362; Benjamens S, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00324-0; Bommasani R, 2023, ANN NY ACAD SCI, V1525, P140, DOI 10.1111/nyas.15007; Borger JG, 2023, IMMUNOL CELL BIOL, V101, P923, DOI 10.1111/imcb.12689; Cascella M, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-01925-4; Chieffo DPR, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030541; Coomans MB, 2019, CURR OPIN ONCOL, V31, P540, DOI 10.1097/CCO.0000000000000581; Corell A, 2021, ACTA NEUROCHIR, V163, P2371, DOI 10.1007/s00701-021-04867-3; Dash D, 2023, Arxiv, DOI [arXiv:2304.13714, DOI 10.48550/ARXIV.2304.13714]; de Mik SML, 2018, BRIT J SURG, V105, P1721, DOI 10.1002/bjs.11009; Díaz JL, 2009, ACTA NEUROCHIR, V151, P357, DOI 10.1007/s00701-009-0195-7; Dinan E, 2021, Arxiv, DOI [arXiv:2107.03451, 10.48550/arxiv.2107.03451, DOI 10.48550/ARXIV.2107.03451]; Downing NL, 2018, ANN INTERN MED, V169, P50, DOI 10.7326/M18-0139; Dunbar EM, 2020, NEURO-ONCOLOGY, V22, P750, DOI 10.1093/neuonc/noaa080; Edwards M, 2023, HEALTH EXPECT, V26, P2109, DOI 10.1111/hex.13822; Elwyn G, 2016, IMPLEMENT SCI, V11, DOI 10.1186/s13012-016-0480-9; Gao A., 2023, SSRN Electr J, DOI DOI 10.2139/SSRN.4504303; Gerstenecker A, 2014, J NEURO-ONCOL, V120, P179, DOI 10.1007/s11060-014-1543-x; Gosselt IK, 2021, NEURO-ONCOL PRACT, V8, P160, DOI 10.1093/nop/npaa078; Harrer S, 2023, EBIOMEDICINE, V90, DOI 10.1016/j.ebiom.2023.104512; Haver HL, 2024, RADIOL-IMAG CANCER, V6, DOI 10.1148/rycan.230086; Hermann H, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.00765; Hewins W, 2019, CURR ONCOL REP, V21, DOI 10.1007/s11912-019-0793-3; Heyhoe J, 2016, J ROY SOC MED, V109, P52, DOI 10.1177/0141076815620614; Hong JY, 2024, Arxiv, DOI arXiv:2312.03724; Huang L, 2023, Arxiv, DOI arXiv:2311.05232; Hussein A.A., 2013, J Inf Secur, V4, P101, DOI [DOI 10.4236/JIS.2013, 10.4236/jis.2013.42012, DOI 10.4236/JIS.2013.42012]; Jessurun CAC, 2023, ACTA NEUROCHIR, V165, P11, DOI 10.1007/s00701-022-05452-y; Jin D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11146421; Kaba R, 2007, Int J Surg, V5, P57, DOI 10.1016/j.ijsu.2006.01.005; Koch-Weser S, 2009, HEALTH EXPECT, V12, P371, DOI 10.1111/j.1369-7625.2009.00555.x; Kroth PJ, 2019, JAMA NETW OPEN, V2, DOI 10.1001/jamanetworkopen.2019.9609; Lee P, 2023, NEW ENGL J MED, V388, P1233, DOI 10.1056/NEJMsr2214184; Légaré F, 2018, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006732.pub4; Leu S, 2023, ACTA NEUROCHIR, V165, P15, DOI 10.1007/s00701-022-05451-z; Li JN, 2024, COMPUT METH PROG BIO, V245, DOI 10.1016/j.cmpb.2024.108013; Liao QV, 2023, Arxiv, DOI [arXiv:2306.01941, DOI 10.48550/ARXIV.2306.01941]; Ling C, 2023, Arxiv, DOI arXiv:2305.18703; Lukas RV, 2018, J CLIN NEUROL, V14, P8, DOI 10.3988/jcn.2018.14.1.8; Makoul G, 2006, PATIENT EDUC COUNS, V60, P301, DOI 10.1016/j.pec.2005.06.010; Meskó B, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00873-0; Mittelstadt B, 2024, NAT HUM BEHAV, V8, P11, DOI 10.1038/s41562-023-01744-0; Mokander J., 2023, AI ETHICS, P1, DOI [DOI 10.1007/S43681-023-00289-2, https://doi.org/10.1007/s43681-023-00289-2]; Musella A, 2021, PATIENT PREFER ADHER, V15, P2009, DOI 10.2147/PPA.S314792; Nasr M, 2023, Arxiv, DOI [arXiv:2311.17035, 10.48550/ARXIV.2311.17035]; Onder CE, 2024, SCI REP-UK, V14, DOI 10.1038/s41598-023-50884-w; Pace A, 2020, NEURO-ONCOL PRACT, V7, P599, DOI 10.1093/nop/npaa040; Pertz M, 2022, CANCERS, V14, DOI 10.3390/cancers14030767; Porter Alyx B, 2021, Am Soc Clin Oncol Educ Book, V41, P1, DOI 10.1200/EDBK_320803; Ray PP, 2023, Internet of Things and Cyber-Physical Systems, V3, P121, DOI [DOI 10.1016/J.IOTCPS.2023.04.003, 10.1016/j.iotcps.2023.04.003]; Reinert C, 2018, J NEURO-ONCOL, V138, P407, DOI 10.1007/s11060-018-2811-y; Roberts K, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0707-y; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Shepherd SC, 2023, CANCER MED-US, V12, P8652, DOI 10.1002/cam4.5572; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; von Essen HS, 2022, NEURO-ONCOL PRACT, V9, P402, DOI 10.1093/nop/npac046; Temel MH, 2024, WORLD NEUROSURG, V181, pE1138, DOI 10.1016/j.wneu.2023.11.062; Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7; Vermeir P, 2015, INT J CLIN PRACT, V69, P1257, DOI 10.1111/ijcp.12686; von Essen HS, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19127396; Waddell A, 2021, IMPLEMENT SCI, V16, DOI 10.1186/s13012-021-01142-y; Wang CL, 2024, ANN BIOMED ENG, V52, P1115, DOI 10.1007/s10439-023-03327-6; West CP, 2018, J INTERN MED, V283, P516, DOI 10.1111/joim.12752; Yang Rui, 2023, Health Care Sci, V2, P255, DOI 10.1002/hcs2.61; Yust-Katz S, 2020, NEURO-ONCOLOGY, V22, P838, DOI 10.1093/neuonc/noz229; Zakka Cyril, 2024, NEJM AI, V1, DOI 10.1056/aioa2300068; Zhang SN, 2022, IEEE T INF FOREN SEC, V17, P2538, DOI 10.1109/TIFS.2022.3188147	68	0	0	11	11	SPRINGER	NEW YORK	ONE NEW YORK PLAZA, SUITE 4600, NEW YORK, NY, UNITED STATES	0171-5216	1432-1335		J CANCER RES CLIN	J. Cancer Res. Clin. Oncol.	MAR 19	2024	150	3							139	10.1007/s00432-024-05673-x	http://dx.doi.org/10.1007/s00432-024-05673-x			10	Oncology	Science Citation Index Expanded (SCI-EXPANDED)	Oncology	LO2C0	38503921	hybrid			2024-07-03	WOS:001187667700003
C	Cui, C; Ma, YS; Cao, X; Ye, WQ; Wang, ZR			ACM	Cui, Can; Ma, Yunsheng; Cao, Xu; Ye, Wenqian; Wang, Ziran			Human-Autonomy Teaming on Autonomous Vehicles with Large Language Model-Enabled Human Digital Twins	2023 IEEE/ACM SYMPOSIUM ON EDGE COMPUTING, SEC 2023	IEEE-ACM Symposium on Edge Computing		English	Proceedings Paper	8th Annual IEEE/ACM Symposium on Edge Computing (SEC)	DEC 06-09, 2023	Wilmington, DE	Assoc Comp Machinery, IEEE Comp Soc, IEEE, NSF, IEEE TCI, M & T Bank, Akamai, ByteDance, Toyota, Micas Networks, Sigmobile		Large Language Model; Digital Twin; Autonomous Driving; Human-Centric Design; Human-Machine Interface		The development of autonomous vehicles is dramatically reshaping the transportation landscape, bringing new challenges and opportunities in human-machine interaction. As autonomous vehicles evolve, understanding and responding to human intent becomes significant, and therefore require new ways of human-autonomy teaming. A human digital twin (HDT) is a virtual representation of an individual driver, capturing their preferences, behaviors, and physiological states, enabling machines to better understand and predict human needs and responses. In this paper, we explore how large language models (LLMs), like GPT-4 and LLaMA, together with HDTs are changing the way humans team up with autonomous vehicles. These LLMs help make our conversations with vehicles more natural and intuitive. By pairing them in HDTs, we can get real-time feedback and smarter responses. This combination offers not just easier control but also safer driving experiences. We will break down how this works, why it matters, and what we might expect in the future.	[Cui, Can; Ma, Yunsheng; Wang, Ziran] Purdue Univ, W Lafayette, IN 47907 USA; [Cao, Xu] Univ Illinois, Champaign, IL USA; [Ye, Wenqian] Univ Virginia, Charlottesville, VA 22903 USA	Purdue University System; Purdue University; University of Illinois System; University of Illinois Urbana-Champaign; University of Virginia	Cui, C (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.	cancui@purdue.edu; yunsheng@purdue.edu; xucao2@uiuc.edu; wenqiang@virginia.edu; ziran@purdue.edu	Wang, Ziran/HDM-1208-2022; Ma, Yunsheng/HDO-6786-2022	Ma, Yunsheng/0000-0003-3933-2574; Cao, Xu/0000-0001-8739-5196				Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Canedo A, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2974007; Cui C, 2023, Arxiv, DOI arXiv:2310.08034; Cui C, 2023, Arxiv, DOI arXiv:2309.10228; Cui C, 2023, Arxiv, DOI arXiv:2305.17318; Devlin J., 2018, BERT PRE TRAINING DE; Fei NY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30761-2; Glaessgen E. H., 2012, 53 AIAA ASME ASCE AH, V8, P7247, DOI [DOI 10.2514/6.2012-1818, 10.2514/6.2012-1818]; Huang WL, 2023, Arxiv, DOI [arXiv:2307.05973, 10.48550/arXiv.2307.05973]; Kim J, 2019, PROC CVPR IEEE, P10583, DOI [10.1109/CVPR.2019.01084, 10.1109/CVP8.2019.01084]; Kim J, 2018, LECT NOTES COMPUT SC, V11206, P577, DOI 10.1007/978-3-030-01216-8_35; Liao XS, 2023, IEEE INTERNET THINGS, V10, P13235, DOI [10.1109/JIOT.2023.3262484, 10.1109/IECON51785.2023.10312608]; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Ma Y., 2023, P IEEE CVF C COMP VI, P5286; Rosen R, 2015, IFAC PAPERSONLINE, V48, P567, DOI 10.1016/j.ifacol.2015.06.141; Rudin C, 2019, NAT MACH INTELL, V1, P206, DOI 10.1038/s42256-019-0048-x; Schick T., 2023, arXiv; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Schwarz C, 2022, IEEE INTEL TRANSP SY, V14, P41, DOI 10.1109/MITS.2021.3129524; Sriram NN, 2019, IEEE INT C INT ROBOT, P5284, DOI [10.1109/iros40897.2019.8967929, 10.1109/IROS40897.2019.8967929]; Tao F, 2019, IEEE T IND INFORM, V15, P2405, DOI 10.1109/TII.2018.2873186; Wang Z., 2020, 2020 IEEE 91 VEHICUL, P1, DOI DOI 10.1109/VTC2020-SPRING48590.2020.9128938; Wang Z, 2022, IEEE INTERNET THINGS, V9, P17452, DOI 10.1109/JIOT.2022.3156028	24	0	0	10	10	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES	2837-4819		979-8-4007-0123-8	IEEE ACM Symp Edge C			2023							319	324		10.1145/3583740.3626806	http://dx.doi.org/10.1145/3583740.3626806			6	Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW5NZ					2024-07-03	WOS:001164050000040
J	O'Leary, DE				O'Leary, Daniel E.			Using large language models to write theses and dissertations	INTELLIGENT SYSTEMS IN ACCOUNTING FINANCE & MANAGEMENT			English	Editorial Material						ChatGPT; dissertations; Dunning-Kruger effect; education; graduate students; LIWC; theses	ARTIFICIAL-INTELLIGENCE	There has been substantial discussion aimed at investigating the extent to which academic researchers can or should "use" large language models, such as ChatGPT and Bard, in their research papers. However, there seems to have been limited attention given to the extent to which students can use these tools for the development of theses, proposals and dissertations. This paper pushes the arguments from focusing on academic researchers, journal papers, and technical meetings to considering those theses and dissertations, raising several questions and concerns. Ultimately, university policies need to address these issues, but if publisher and editor responses and alternative business uses are a signal of that direction, consensus may be difficult to achieve.	[O'Leary, Daniel E.] Univ Southern Calif, Los Angeles, CA 90007 USA	University of Southern California	O'Leary, DE (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.	oleary@usc.edu		O'Leary, Daniel Edmund/0000-0002-5240-9516				Davis J., 2022, Will AI write your thesis; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Gallegos D., 2023, Should AI write doctoral dissertations? 2023, WSJ readers weigh in; Kaebnick Gregory E, 2023, Ethics Hum Res, V45, P39, DOI 10.1002/eahr.500182; Kruger J, 1999, J PERS SOC PSYCHOL, V77, P1121, DOI 10.1037/0022-3514.77.6.1121; O'Leary Daniel E., 2008, International Journal of Accounting Information Systems, V9, P240, DOI 10.1016/j.accinf.2008.09.001; O'Leary DE, 2023, AI MAG, V44, P282, DOI 10.1002/aaai.12118; O'Leary DE, 2023, INTELL SYST ACCOUNT, V30, P41, DOI 10.1002/isaf.1531; O'Leary DE, 2022, INTELL SYST ACCOUNT, V29, P182, DOI 10.1002/isaf.1522; O'Leary DE, 2019, INTELL SYST ACCOUNT, V26, P46, DOI 10.1002/isaf.1443; O'Leary DE, 2009, J EMERG TECHNOL ACCO, V6, P45, DOI 10.2308/jeta.2009.6.1.45; Paulus P. B., 2019, Effective brainstorming. The Oxford handbook of group creativity and innovation, P287, DOI [10.1093/oxfordhb/9780190648077.001.0001, DOI 10.1093/OXFORDHB/9780190648077.001.0001]; Pennebaker J. W., 2015, The development and psychometric properties of LIWC2015, DOI DOI 10.15781/T29G6Z; Pennebaker JW., 2015, LINGUISTIC INQUIRY W; Wood DA, 2023, ISS ACCOUNT EDUC, V38, P81, DOI 10.2308/ISSUES-2023-013	15	0	0	10	10	JOHN WILEY & SONS LTD	CHICHESTER	THE ATRIUM, SOUTHERN GATE, CHICHESTER PO19 8SQ, W SUSSEX, ENGLAND	1055-615X	1099-1174		INTELL SYST ACCOUNT	Intell. Syst. Account. Financ. Manag.	OCT	2023	30	4					228	234		10.1002/isaf.1547	http://dx.doi.org/10.1002/isaf.1547			7	Business, Finance	Emerging Sources Citation Index (ESCI)	Business & Economics	CW7S6		hybrid			2024-07-03	WOS:001128343000004
C	Cabra-Acela, L; Mojica-Hanke, A; Linares-Vásquez, M; Herbold, S		Chandra, S; Blincoe, K; Tonella, P		Cabra-Acela, Laura; Mojica-Hanke, Anamaria; Linares-Vasquez, Mario; Herbold, Steffen			On Using Information Retrieval to Recommend Machine Learning Good Practices for Software Engineers	PROCEEDINGS OF THE 31ST ACM JOINT MEETING EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING, ESEC/FSE 2023			English	Proceedings Paper	31st ACM Joint Meeting of the European Software Engineering Conference / Symposium on the Foundations-of-Software-Engineering (ESEC/FSE)	DEC 03-09, 2023	San Francisco, CA	Assoc Comp Machinery, Fdn Software Engn, ACM SIGSOFT, Google, Ant Grp, Meta, JetBrains, ByteDance, Uber, Dragon Testing, Huawei		Machine learning; Good practices; Information retrieval; Large language models		Machine learning (ML) is nowadays widely used for different purposes and in several disciplines. From self-driving cars to automated medical diagnosis, machine learning models extensively support users' daily activities, and software engineering tasks are no exception. Not embracing good ML practices may lead to pitfalls that hinder the performance of an ML system and potentially lead to unexpected results. Despite the existence of documentation and literature about ML best practices, many non-ML experts turn towards gray literature like blogs and Q&A systems when looking for help and guidance when implementing ML systems. To better aid users in distilling relevant knowledge from such sources, we propose a recommender system that recommends ML practices based on the user's context. As a first step in creating a recommender system for machine learning practices, we implemented Idaka. A tool that provides two different approaches for retrieving/generating ML best practices: i) an information retrieval (IR) engine and ii) a large language model. The IR-engine uses BM25 as the algorithm for retrieving the practices, and a large language model, in our case Alpaca. The platform has been designed to allow comparative studies of best practices retrieval tools. Idaka is publicly available at GitHub: https://bit.ly/idaka. Video: https://youtu.be/cEb-AhIPxnM	[Cabra-Acela, Laura; Mojica-Hanke, Anamaria; Linares-Vasquez, Mario] Univ Los Andes, Bogota, Colombia; [Herbold, Steffen] Univ Passau, Passau, Germany	Universidad de los Andes (Colombia); University of Passau	Cabra-Acela, L (corresponding author), Univ Los Andes, Bogota, Colombia.	lh.cabra@uniandes.edu.co; ai.mojica10@uniandes.edu.co; m.linaresv@uniandes.edu.co; steffen.herbold@uni-passau.de		Herbold, Steffen/0000-0001-9765-2803; Linares-Vasquez, Mario/0000-0003-0161-2888				Acela Laura Helena Cabra, 2023, Zenodo, DOI 10.5281/ZENODO.8275813; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Adiwardana D., 2020, Towards a conversational agent that can chat about ... anything ...; Alshangiti M., 2019, INT SYMP EMP SOFTWAR, P1, DOI DOI 10.1109/esem.2019.8870187; Amazon, 2019, Aidoc Brings Lifesaving AI Advancements to Medical Imaging on AWS; Amershi S, 2019, 2019 IEEE/ACM 41ST INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE (ICSE-SEIP 2019), P291, DOI 10.1109/ICSE-SEIP.2019.00042; Biderman Stella, 2020, Pitfalls in machine learning research: Reexamining the development cycle; Bird S., 2009, NATURAL LANGUAGE PRO; Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993; Cabra-Acela Laura, 2023, Idaka-Online Appendix; Cabra-Acela Laura, 2023, Idaka; Cabra-Acela Laura, 2023, Idaka Tool Demo; Cao YH, 2023, Arxiv, DOI [arXiv:2303.04226, 10.48550/arXiv.2303.04226]; cocktailpeanut, 2023, Dalai; Connelly Shane, 2019, Practical BM25-part2: The BM25 algorithm and its variables; De Lucia A, 2007, ACM T SOFTW ENG METH, V16, DOI 10.1145/1276933.1276934; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; European Commission, 2019, High-level expert group on AI: Ethics guidelines for trustworthy AI; Ezzini Saad, 2023, arXiv; Google PAIR, 2021, People + AI Guidebook; Hoffmann J, 2022, Arxiv, DOI arXiv:2203.15556; Jiang BB, 2018, IEEE T NEUR NET LEAR, V29, P5643, DOI 10.1109/TNNLS.2018.2808332; Kolthoff K, 2023, AUTOMAT SOFTW ENG, V30, DOI 10.1007/s10515-023-00377-x; Lee Seok Won, 2004, P 2004 ACM S APPL CO, P1513; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Lones MA, 2024, Arxiv, DOI [arXiv:2108.02497, 10.48550/arXiv.2108.02497]; Mojica-Hanke A, 2023, Arxiv, DOI [arXiv:2301.10516, 10.48550/ARXIV.2301.10516, DOI 10.48550/ARXIV.2301.10516]; OpenAI, 2023, Introducing chatgpt; Ouyang L., 2022, NEURIPS; PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259; Robertson Stephen, 2009, Foundations and Trends in Information Retrieval, V3, P333, DOI 10.1561/1500000019; SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220; Sculley D, 2015, ADV NEUR IN, V28; Serban A, 2020, P 14 ACMIEEE INT S E, P1; Siri Team, 2017, Deep learning for siri's voice: On-device deep mixture density networks for hybrid unit selection synthesis; Stierna EJ, 2003, INFORM PROCESS MANAG, V39, P67, DOI 10.1016/S0306-4573(02)00025-0; Stilgoe J, 2018, SOC STUD SCI, V48, P25, DOI 10.1177/0306312717741687; Taori R., 2023, Alpaca: A strong, replicable instruction-following model; Tesla, 2023, Arti.cial Intelligence and Autopilot; Thakur N, 2021, Arxiv, DOI arXiv:2104.08663; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Watson C, 2022, ACM T SOFTW ENG METH, V31, DOI 10.1145/3485275; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wujek Brett, 2016, Best Practices for Machine Learning Applications; Zhang D, 2003, SOFTWARE QUAL J, V11, P87, DOI 10.1023/A:1023760326768; Zinkevich M., 2017, Rules of machine learning: best practices for ML engineering	48	0	0	2	2	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY, UNITED STATES			979-8-4007-0327-0				2023							2142	2146		10.1145/3611643.3613093	http://dx.doi.org/10.1145/3611643.3613093			5	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BW4HZ		Green Submitted			2024-07-03	WOS:001148157800187
J	De Sabbata, S; Bennett, K; Gardner, Z				De Sabbata, Stefano; Bennett, Katy; Gardner, Zoe			Towards a study of everyday geographic information: Bringing the everyday into view	ENVIRONMENT AND PLANNING B-URBAN ANALYTICS AND CITY SCIENCE			English	Article; Early Access						Everyday; social media; large language models; spatial analysis; visualisation	SOCIAL MEDIA; TWITTER	Events are the driving force behind social media, whether we try to create them or keep up with them. A wide range of studies has focused on how content from social media can be used to detect, model and predict events and identify key topics of discussion. At the same time, very limited attention has been given so far to the quantitative study of the everyday, which has fascinated qualitative human geography research in the past few decades. That is partly due to the lack of a formal definition of what constitutes the everyday. In this paper, we aim to advance our understanding of the everyday, not by reducing it to any kind of definition but by bringing it into view through a quantitative analysis. We hypothesise that the by-products of current methods focused on event detection might be used to quantitatively explore everyday geographies as represented through Twitter data. We consider the use of both statistical approaches based on term frequency and state-of-the-art large language models, and we conduct a case study on content posted on Twitter and geolocated in the city of Leicester. Our paper makes two key advances for research concerned with the everyday and the analysis of geographic information. First, we illustrate how large language models combined with spatial analysis and visualisation can foster the study of everyday geographies, providing an insight into the still elusive concept of the everyday, representing what other approaches to the everyday have struggled to qualify. Secondly, we showcase the potential held by large language models and visual analytics in democratising sophisticated natural language processing and thus providing new tools for research in human geography.	[De Sabbata, Stefano] Univ Leicester, Inst Digital Culture, Leicester, England; [Bennett, Katy] Univ Leicester, Human Geog, Leicester, England; [Gardner, Zoe] Univ Leicester, Leicester, England; [De Sabbata, Stefano] Univ Leicester, Sch Geog Geol & Environm, Univ Rd, Leicester LE1 7RH, England	University of Leicester; University of Leicester; University of Leicester; University of Leicester	De Sabbata, S (corresponding author), Univ Leicester, Sch Geog Geol & Environm, Univ Rd, Leicester LE1 7RH, England.	s.desabbata@leicester.ac.uk		De Sabbata, Stef/0000-0002-2750-7579	Leverhulme Trust Research Project [RPG-2019-052]	Leverhulme Trust Research Project(Leverhulme Trust)	The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This research is funded by the Leverhulme Trust Research Project Grant [RPG-2019-052] 'Mapping Multiculture: Disrupting representations of an ethnically diverse city'.	Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54; [Anonymous], 2013, P 22 INT C WORLD WID, DOI 10.1145/2488388.2488514; Ballatore A, 2020, T GIS, V24, P880, DOI 10.1111/tgis.12600; Barbieri F, 2020, Arxiv, DOI [arXiv:2010.12421, DOI 10.48550/ARXIV.2010.12421, 10.48550/ARXIV.2010.12421]; Bennett K, 2023, EMOT SPACE SOC, V49, DOI 10.1016/j.emospa.2023.100965; Bennett K, 2023, SOC CULT GEOGR, V24, P1458, DOI 10.1080/14649365.2022.2065699; Besag J, 1977, J R Stat Series B, V39, P193, DOI [DOI 10.1111/J.2517-6161.1977.TB01616.X, 10.1111/j.2517-6161.1977.tb01616.x]; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Camacho K, 2021, CARTOGR GEOGR INF SC, V48, P241, DOI 10.1080/15230406.2020.1869999; Campello Ricardo J. G. B., 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P160, DOI 10.1007/978-3-642-37456-2_14; Crooks A, 2013, T GIS, V17, P124, DOI 10.1111/j.1467-9671.2012.01359.x; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Elden S., 2003, Henri Lefebvre: Key writings; Feng Y, 2022, INT J GEOGR INF SCI, V36, P1275, DOI 10.1080/13658816.2022.2048835; Goodchild MF, 2007, GEOJOURNAL, V69, P211, DOI 10.1007/s10708-007-9111-y; Grootendorst M., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.05794; Holloway L., 2001, PEOPLE PLACE EXTRAOR; Horton John., 2013, Cultural Geographies: An Introduction; Karmegam D, 2020, INT J HEALTH GEOGR, V19, DOI 10.1186/s12942-020-00214-4; Larsen ME, 2015, IEEE J BIOMED HEALTH, V19, P1246, DOI 10.1109/JBHI.2015.2403839; Lefebvre Henri., 1991, Critique of Everyday Life, VI; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Longley PA, 2016, INT J GEOGR INF SCI, V30, P369, DOI 10.1080/13658816.2015.1089441; McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, 10.21105/joss.00861, DOI 10.21105/JOSS.00861]; McKitrick MK, 2023, GEOJOURNAL, V88, P1035, DOI 10.1007/s10708-022-10584-w; Meyer TR, 2019, ENVIRON PLAN B-URBAN, V46, P1724, DOI 10.1177/2399808318764123; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Moran Joe., 2005, Reading the Everyday; Naldi M, 2019, Arxiv, DOI [arXiv:1901.08319, DOI 10.48550/ARXIV.1901.08319]; Neal S, 2013, ENVIRON PLANN C, V31, P308, DOI 10.1068/c11263r; Pan C.Mitra., 2011, Proceedings of the 11th annual international ACM/IEEE joint conference on Digital libraries, JCDL '11, P349; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Rinker T., 2021, sentimentr: Calculate text polarity sentiment version 2.9.0; Rinker T.W., 2018, {textstem}: Tools for stemming and lemmatizing text; Rinker TW., 2021, {Textclean}: Text Cleaning Tools; RIPLEY BD, 1977, J ROY STAT SOC B MET, V39, P172; Roberts H, 2019, URBAN STUD, V56, P818, DOI 10.1177/0042098017748544; Shelton T, 2014, GEOFORUM, V52, P167, DOI 10.1016/j.geoforum.2014.01.006; Steiger E, 2015, T GIS, V19, P809, DOI 10.1111/tgis.12132; Stock K, 2018, COMPUT ENVIRON URBAN, V71, P209, DOI 10.1016/j.compenvurbsys.2018.05.007; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Canh TV, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P168; Vaswani A, 2017, ADV NEUR IN, V30; Wang C., 2007, P 4 ACM WORKSHOP GEO, P65; Wiegmann M, 2021, NAT HAZARD EARTH SYS, V21, P1431, DOI 10.5194/nhess-21-1431-2021; Wilkins EJ, 2021, ENVIRON MANAGE, V67, P120, DOI 10.1007/s00267-020-01373-7; Wise A, 2009, EVERYDAY MULTICULTURALISM, P1, DOI 10.1057/9780230244474; Yan YW, 2020, INT J GEOGR INF SCI, V34, P1765, DOI 10.1080/13658816.2020.1730848; Zhang T, 2021, INT J GEOGR INF SCI, V35, P2216, DOI 10.1080/13658816.2020.1869746; Zivanovic S, 2020, GEOJOURNAL, V85, P237, DOI 10.1007/s10708-018-9960-6	50	0	0	6	7	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	2399-8083	2399-8091		ENVIRON PLAN B-URBAN	Env. Plan. B-Urban Anal. City Sci.	2023 DEC 5	2023										10.1177/23998083231217606	http://dx.doi.org/10.1177/23998083231217606		DEC 2023	15	Environmental Studies; Geography; Regional & Urban Planning; Urban Studies	Social Science Citation Index (SSCI)	Environmental Sciences & Ecology; Geography; Public Administration; Urban Studies	Z7ZF4		Green Published, hybrid			2024-07-03	WOS:001114214700001
J	Li, XY; Feng, HM; Yang, HL; Huang, JY				Li, Xiaoyang; Feng, Haoming; Yang, Hailong; Huang, Jiyuan			Can ChatGPT reduce human financial analysts' optimistic biases?	ECONOMIC AND POLITICAL STUDIES-EPS			English	Article						ChatGPT; large language models; analyst forecast; optimistic biases; human-machine interaction	EARNINGS FORECASTS; INFORMATION; OWNERSHIP	This paper examines the potential of ChatGPT, a large language model, as a financial advisor for listed firm performance forecasts. We focus on the constituent stocks of the China Securities Index 300 and compare ChatGPT's forecasts for major financial performance measures with human analysts' forecasts and the realised values. Our findings suggest that ChatGPT can correct the optimistic biases of human analysts. This study contributes to the literature by exploring the potential of ChatGPT as a financial advisor and demonstrating its role in reducing human biases in financial decision-making.	[Li, Xiaoyang] Hong Kong Polytech Univ, Sch Accounting & Finance, Hong Kong, Peoples R China; [Feng, Haoming; Yang, Hailong] Renmin Univ China, Sch Finance, Beijing, Peoples R China; [Huang, Jiyuan] Univ Zurich, Dept Banking & Finance, Zurich, Switzerland; [Huang, Jiyuan] Swiss Finance Inst, Zurich, Switzerland; [Huang, Jiyuan] Univ Zurich, Swiss Finance Inst, Dept Banking & Finance, Zurich, Switzerland	Hong Kong Polytechnic University; Renmin University of China; University of Zurich; Swiss Finance Institute (SFI); Swiss Finance Institute (SFI); University of Zurich	Huang, JY (corresponding author), Univ Zurich, Swiss Finance Inst, Dept Banking & Finance, Zurich, Switzerland.	jiyuan.huang@bf.uzh.ch	Yang, Hailong/I-2452-2015		Haoming Feng thanks the National Social Science Foundation of China	Haoming Feng thanks the National Social Science Foundation of China	No Statement Available	ABARBANELL JS, 1991, J ACCOUNT ECON, V14, P147, DOI 10.1016/0165-4101(91)90003-7; Ackert L., 2003, J BUS FINAN ACCOUNT, V30, P1017, DOI DOI 10.1111/1468-5957.05452; Adiwardana D., 2020, arXiv; ALI A, 1992, ACCOUNT REV, V67, P183; Alshater M., 2022, Exploring the role of artificial intelligence in enhancing academic performance: A case study of ChatGPT, DOI [DOI 10.2139/SSRN.4312358, https://doi.org/10.2139/ssrn.4312358]; Amir E., 2003, European Accounting Review, V12, P635; Aubry M, 2023, J FINANC, V78, P795, DOI 10.1111/jofi.13203; Bolliger G, 2004, J BANK FINANC, V28, P2283, DOI 10.1016/j.jbankfin.2003.09.011; Boyaci T, 2024, MANAGE SCI, V70, DOI 10.1287/mnsc.2023.4744; Cao S, 2023, REV FINANC STUD, V36, P3603, DOI 10.1093/rfs/hhad021; Cen L, 2013, J FINANC QUANT ANAL, V48, P47, DOI 10.1017/S0022109012000609; Chen Ren., 2023, COMPUT HUM BEHAV ART, V1, P100007, DOI DOI 10.1016/J.CHBAH.2023.100007; Chen X, 2022, J ACCOUNT RES, V60, P467, DOI 10.1111/1475-679X.12429; Chen Zihan, 2023, CHATGPT INFORM GRAPH, DOI [10.2139/ssrn.4464002, DOI 10.2139/SSRN.4464002]; Coleman B, 2022, ACCOUNT REV, V97, P221, DOI 10.2308/TAR-2020-0096; Das S, 1998, ACCOUNT REV, V73, P277; Dong R, 2021, J FINANC ECON, V139, P971, DOI 10.1016/j.jfineco.2019.12.004; Dowling M, 2023, FINANC RES LETT, V53, DOI 10.1016/j.frl.2023.103662; Duru A, 2002, ACCOUNT REV, V77, P415, DOI 10.2308/accr.2002.77.2.415; Easterwood JC, 1999, J FINANC, V54, P1777, DOI 10.1111/0022-1082.00166; Feng Zifeng, 2023, UNLEASHING POWER CHA, DOI [10.2139/ssrn.4424979, DOI 10.2139/SSRN.4424979]; Hansen A. L., 2023, Can ChatGPT Decipher Fedspeak?, DOI [https://doi.org/10.2139/ssrn.4399406, DOI 10.2139/SSRN.4399406]; Harris R., 1999, J BUS FINAN ACCOUNT, V26, P725, DOI DOI 10.1111/1468-5957.00273; Hofert Marius, 2023, ASSESSING CHATGPTS P, DOI [10.2139/ssrn.4444104, DOI 10.2139/SSRN.4444104]; Hou Y, 2014, INT REV ECON FINANC, V33, P319, DOI 10.1016/j.iref.2014.03.001; Hovakimian A, 2010, FINANC ANAL J, V66, P96, DOI 10.2469/faj.v66.n4.6; Huang W, 2015, J INT FINANC MARK I, V35, P69, DOI 10.1016/j.intfin.2015.01.003; Jha Manish, 2023, CHATGPT CORPORATE PO, DOI [10.2139/ssrn.4521096, DOI 10.2139/SSRN.4521096]; Kim Alex G., 2023, BLOATED DISCLOSURES, DOI [10.2139/ssrn.4425527, DOI 10.2139/SSRN.4425527]; Ko Hyungjin, 2023, CAN CHATGPT IMPROVE, DOI [10.2139/ssrn.4390529, DOI 10.2139/SSRN.4390529]; Korinek A., 2023, Cambridge, MA, DOI DOI 10.3386/W30957; Lakkaraju Kausik, 2023, ARXIV; Lan Yinyu, 2023, ARXIV; Li X., 2023, ARXIV; Liaudinskas Karolis, 2022, 62022 NORG BANK; Lim T, 2001, J FINANC, V56, P369, DOI 10.1111/0022-1082.00329; Liu M, 2022, J ACCOUNT RES, V60, P607, DOI 10.1111/1475-679X.12427; Liu S, 2016, CORP GOV-INT J BUS S, V16, P54, DOI 10.1108/CG-02-2015-0018; Lopez-Lira A., 2023, Can ChatGPT forecast stock price movements? Return predictability and large language models, DOI [10.2139/ssrn.4412788, DOI 10.2139/SSRN.4412788]; Maskara PK, 2011, J FINANC ECON, V101, P684, DOI 10.1016/j.jfineco.2011.03.019; Neilson B, 2023, J FINANC REGUL, V9, P249, DOI 10.1093/jfr/fjad004; Niszczota P, 2023, FINANC RES LETT, V58, DOI 10.1016/j.frl.2023.104333; So EC, 2013, J FINANC ECON, V108, P615, DOI 10.1016/j.jfineco.2013.02.002; Tantri P, 2021, REV FINANC, V25, P561, DOI 10.1093/rof/rfaa039; van Binsbergen JH, 2023, REV FINANC STUD, V36, P2361, DOI 10.1093/rfs/hhac085; Wang Z., 2023, ARXIV; Wei T, 2023, INT REV ECON FINANC, V88, P1389, DOI 10.1016/j.iref.2023.07.108; Wenzlaff K., 2022, SSRN Scholarly Paper, DOI [10.2139/ssrn.4302443, DOI 10.2139/SSRN.4302443]; Wu YR, 2018, PAC-BASIN FINANC J, V49, P147, DOI 10.1016/j.pacfin.2018.04.010; Xie Qianqian, 2023, ARXIV; Yue T, 2023, DEMOCRATIZING FINANC, DOI DOI 10.2139/SSRN.4346152; Zhao TZ, 2021, PR MACH LEARN RES, V139	52	0	0	20	22	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	2095-4816	2470-4024		ECON POLIT STUD-EPS	Econ. Polit. Stud.-EPS	JAN 2	2024	12	1					20	33		10.1080/20954816.2023.2276965	http://dx.doi.org/10.1080/20954816.2023.2276965		NOV 2023	14	Social Sciences, Interdisciplinary	Emerging Sources Citation Index (ESCI)	Social Sciences - Other Topics	HB7Z8		hybrid, Green Accepted, Green Published			2024-07-03	WOS:001119129900001
J	Shah, A; Wahood, S; Guermazi, D; Brem, CE; Saliba, E				Shah, Asghar; Wahood, Samer; Guermazi, Dorra; Brem, Candice E.; Saliba, Elie			Skin and Syntax: Large Language Models in Dermatopathology	DERMATOPATHOLOGY			English	Review						artificial intelligence; AI; LLM; large language models; dermatopathology	ARTIFICIAL-INTELLIGENCE; PATHOLOGY	This literature review introduces the integration of Large Language Models (LLMs) in the field of dermatopathology, outlining their potential benefits, challenges, and prospects. It discusses the changing landscape of dermatopathology with the emergence of LLMs. The potential advantages of LLMs include a streamlined generation of pathology reports, the ability to learn and provide up-to-date information, and simplified patient education. Existing instances of LLMs encompass diagnostic support, research acceleration, and trainee education. Challenges involve biases, data privacy and quality, and establishing a balance between AI and dermatopathological expertise. Prospects include the integration of LLMs with other AI technologies to improve diagnostics and the improvement of multimodal LLMs that can handle both text and image input. Our implementation guidelines highlight the importance of model transparency and interpretability, data quality, and continuous oversight. The transformative potential of LLMs in dermatopathology is underscored, with an emphasis on a dynamic collaboration between artificial intelligence (AI) experts (technical specialists) and dermatopathologists (clinicians) for improved patient outcomes.	[Shah, Asghar; Wahood, Samer; Guermazi, Dorra; Saliba, Elie] Brown Univ, Warren Alpert Med Sch, Dept Dermatol, Providence, RI 02903 USA; [Brem, Candice E.] Boston Univ, Chobanian & Avedisian Sch Med, Dept Dermatol, Sect Dermatopathol, Boston, MA 02118 USA; [Saliba, Elie] Lebanese Amer Univ, Gilbert & Rose Marie Chagoury Sch Med, Dept Dermatol, Beirut 135053, Lebanon	Brown University; Boston University; Lebanese American University	Saliba, E (corresponding author), Brown Univ, Warren Alpert Med Sch, Dept Dermatol, Providence, RI 02903 USA.; Saliba, E (corresponding author), Lebanese Amer Univ, Gilbert & Rose Marie Chagoury Sch Med, Dept Dermatol, Beirut 135053, Lebanon.	asghar_shah@brown.edu; samer_wahood@brown.edu; dorra_guermazi@brown.edu; candice.brem@bmc.org; elie_saliba@brown.edu		Brem, Candice/0000-0001-6183-8833; Guermazi, Dorra/0000-0003-3638-909X; Saliba, Elie/0000-0001-5994-3212; Wahood, Samer/0000-0003-2216-1975				Abd-alrazaq A, 2023, JMIR MED EDUC, V9, DOI 10.2196/48291; Abou Elkassem A, 2023, AM J ROENTGENOL, V221, P373, DOI 10.2214/AJR.23.29198; [Anonymous], Introducing GPTs Open AI; [Anonymous], ChatGPT Image Inputs for ChatGPT-FAQ; Bajwa Junaid, 2021, Future Healthc J, V8, pe188, DOI 10.7861/fhj.2021-0095; Chan S, 2020, DERMATOLOGY THER, V10, P365, DOI 10.1007/s13555-020-00372-0; Choi HS, 2023, RADIAT ONCOL J, V41, P209, DOI 10.3857/roj.2023.00633; De A, 2020, INDIAN J DERMATOL, V65, P352, DOI 10.4103/ijd.IJD_418_20; Dermatology Diagnostic Devices and Therapeutics Market Size, Report By 2032 Precedence Research; El Saadawi G, 2008, ADV HEALTH SCI EDUC, V13, P709, DOI 10.1007/s10459-007-9081-3; Gao C.A., 2023, medRxiv, DOI [10.1371/journal.pone.0292216, DOI 10.1371/JOURNAL.PONE.0292216]; Ianni Julianna, What AI's Changing Landscape Means for Pathology; Ibraheim MK, 2023, DERMATOPATHOL-BASEL, V10, P93, DOI 10.3390/dermatopathology10010014; Jartarkar SR, 2023, J COSMET DERMATOL-US, V22, P1163, DOI 10.1111/jocd.15565; Karabacak M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.39305; Kaul V, 2020, GASTROINTEST ENDOSC, V92, P807, DOI 10.1016/j.gie.2020.06.040; Khullar G, 2020, DERMATOL THER, V33, DOI 10.1111/dth.13755; Kim JK, 2023, J PEDIATR UROL, V19, P598, DOI 10.1016/j.jpurol.2023.05.018; Liopyris K, 2022, DERMATOLOGY THER, V12, P2637, DOI 10.1007/s13555-022-00833-8; Locke S, 2021, TRENDS ANAESTH CRIT, V38, P4, DOI 10.1016/j.tacc.2021.02.007; Matin RN, 2023, BRIT J DERMATOL, V189, P253, DOI 10.1093/bjd/ljad230; Moukheiber L., 2023, Seminars in Diagnostic Pathology; Niazi MKK, 2019, LANCET ONCOL, V20, pE253, DOI 10.1016/S1470-2045(19)30154-8; Omiye Jesutofunmi A, 2023, NPJ Digit Med, V6, P195, DOI 10.1038/s41746-023-00939-z; Reeves PT, 2022, J PEDIATR ENDOCR MET, V35, P205, DOI 10.1515/jpem-2021-0541; Smith SDB, 2021, JAMA DERMATOL, V157, P1033, DOI 10.1001/jamadermatol.2021.2582; Smith V, 2024, Arxiv, DOI arXiv:2310.01424; Stagner AM, 2021, ARCH PATHOL LAB MED, V145, P1144, DOI 10.5858/arpa.2020-0458-OA; Steele L, 2021, J EUR ACAD DERMATOL, V35, pE877, DOI 10.1111/jdv.17517; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Trajanov D, 2023, PHARMACOL REV, V75, P714, DOI 10.1124/pharmrev.122.000715; Velez N, 2008, HUM PATHOL, V39, P1341, DOI 10.1016/j.humpath.2008.01.006; Voytovich Leah, 2022, Acta Neurochir Suppl, V134, P207, DOI 10.1007/978-3-030-85292-4_24; WedMD Editorial Contributors, Medically Reviewed by Sabrina Felson What Is a Dermatopathologist?; Wells A, 2021, J CUTAN PATHOL, V48, P1061, DOI 10.1111/cup.13954; Wolfe C, 2023, BRIT J DERMATOL, V188, DOI 10.1093/bjd/ljad113.058; Zhang YY, 2024, J AM ACAD DERMATOL, V90, P397, DOI 10.1016/j.jaad.2023.09.072; Zhou JX, 2023, medRxiv, DOI [10.1101/2023.06.10.23291127, 10.1101/2023.06.10.23291127, DOI 10.1101/2023.06.10.23291127]	38	2	2	4	4	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND	2296-3529			DERMATOPATHOL-BASEL	Dermatopathology	MAR	2024	11	1					101	111		10.3390/dermatopathology11010009	http://dx.doi.org/10.3390/dermatopathology11010009			11	Dermatology	Emerging Sources Citation Index (ESCI)	Dermatology	MC2U3	38390851	gold, Green Published			2024-07-03	WOS:001191370900001
J	Karabacak, M; Margetis, K				Karabacak, Mert; Margetis, Konstantinos			Embracing Large Language Models for Medical Applications: Opportunities and Challenges	CUREUS JOURNAL OF MEDICAL SCIENCE			English	Article						data privacy; ethical considerations; generative ai; chatgpt; multimodal learning; domain adaptation; reinforcement learning; transfer learning; artificial intelligence; large language models		Large language models (LLMs) have the potential to revolutionize the field of medicine by, among other applications, improving diagnostic accuracy and supporting clinical decision-making. However, the successful integration of LLMs in medicine requires addressing challenges and considerations specific to the medical domain. This viewpoint article provides a comprehensive overview of key aspects for the successful implementation of LLMs in medicine, including transfer learning, domain-specific fine-tuning, domain adaptation, reinforcement learning with expert input, dynamic training, interdisciplinary collaboration, education and training, evaluation metrics, clinical validation, ethical considerations, data privacy, and regulatory frameworks. By adopting a multifaceted approach and fostering interdisciplinary collaboration, LLMs can be developed, validated, and integrated into medical practice responsibly, effectively, and ethically, addressing the needs of various medical disciplines and diverse patient populations. Ultimately, this approach will ensure that LLMs enhance patient care and improve overall health outcomes for all.	[Karabacak, Mert; Margetis, Konstantinos] Mt Sinai Hlth Syst, Neurol Surg, New York, NY 10019 USA	Icahn School of Medicine at Mount Sinai	Margetis, K (corresponding author), Mt Sinai Hlth Syst, Neurol Surg, New York, NY 10019 USA.	konstantinos.margetis@mountsinai.org	Karabacak, Mert/HMW-1735-2023	Karabacak, Mert/0000-0002-9263-9893				ACM, 2021, DYN LANG MOD CONT EV, DOI [10.1145/3447548.3467162, DOI 10.1145/3447548.3467162]; ACM, 2019, FAIRN AW MACH LEARN, DOI [10.1145/3289600.3291383, DOI 10.1145/3289600.3291383]; Chronopoulou A, 2022, Arxiv, DOI arXiv:2112.08786; Chronopoulou A, 2019, Arxiv, DOI arXiv:1902.10547; Dathathri S, 2020, Arxiv, DOI arXiv:1912.02164; Folstad A, 2021, COMPUTING, V103, P2915, DOI 10.1007/s00607-021-01016-7; HAN Jesse Michael, 2021, Unsupervised Neural Machine Translation with Generative Language Models Only; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Huang PS, 2020, Arxiv, DOI arXiv:1911.03064; Kather JN, 2023, J CANCER RES CLIN, V149, P7995, DOI 10.1007/s00432-023-04666-6; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Liang P, 2023, Arxiv, DOI arXiv:2211.09110; Ouyang L., 2022, arXiv, DOI DOI 10.48550/ARXIV.2203.02155; Parnami A., 2022, arXiv; Peng YF, 2019, Arxiv, DOI arXiv:1906.05474; Petroni F, 2019, Arxiv, DOI [arXiv:1909.01066, DOI 10.48550/ARXIV.1909.01066]; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Santos T, 2022, Arxiv, DOI arXiv:2205.06885; Wang S., 2023, arXiv; Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768; Yan A, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.210258; Yu Gu, 2022, ACM Transactions on Computing and Healthcare, V3, DOI 10.1145/3458754; Ziegler DM., 2022, PREPRINT	23	20	20	17	37	SPRINGERNATURE	LONDON	CAMPUS, 4 CRINAN ST, LONDON, N1 9XW, ENGLAND		2168-8184		CUREUS J MED SCIENCE	Cureus J Med Sci	MAY 21	2023	15	5							e39305	10.7759/cureus.39305	http://dx.doi.org/10.7759/cureus.39305			5	Medicine, General & Internal	Emerging Sources Citation Index (ESCI)	General & Internal Medicine	L2LS9	37378099	Green Published, gold			2024-07-03	WOS:001021631400031
J	Chemero, A				Chemero, Anthony			LLMs differ from human cognition because they are not embodied	NATURE HUMAN BEHAVIOUR			English	Editorial Material; Early Access								Large language models (LLMs) are impressive technological creations but they cannot replace all scientific theories of cognition. A science of cognition must focus on humans as embodied, social animals who are embedded in material, cultural and technological contexts.	[Chemero, Anthony] Univ Cincinnati, Dept Philosophy, Cincinnati, OH 45221 USA; [Chemero, Anthony] Univ Cincinnati, Dept Psychol, Cincinnati, OH 45221 USA	University System of Ohio; University of Cincinnati; University System of Ohio; University of Cincinnati	Chemero, A (corresponding author), Univ Cincinnati, Dept Philosophy, Cincinnati, OH 45221 USA.; Chemero, A (corresponding author), Univ Cincinnati, Dept Psychol, Cincinnati, OH 45221 USA.	anthony.chemero@uc.edu			The author thanks Z. Biener, A. Chemero and E. Feiten for comments on an earlier draft. Work on this Comment was supported by the Charles Phelps Taft Research Center.; Charles Phelps Taft Research Center	The author thanks Z. Biener, A. Chemero and E. Feiten for comments on an earlier draft. Work on this Comment was supported by the Charles Phelps Taft Research Center.; Charles Phelps Taft Research Center	The author thanks Z. Biener, A. Chemero and E. Feiten for comments on an earlier draft. Work on this Comment was supported by the Charles Phelps Taft Research Center.	Adams Zed., 2016, GIVING DAMN ESSAYS D; Ayers JW, 2023, JAMA INTERN MED, V183, P589, DOI 10.1001/jamainternmed.2023.1838; Birhane Abeba, 2022, FAccT '22: 2022 ACM Conference on Fairness, Accountability, and Transparency, P173, DOI 10.1145/3531146.3533083; Cecutti L, 2021, NAT HUM BEHAV, V5, P973, DOI 10.1038/s41562-021-01162-0; Dingemanse M, 2023, COGNITIVE SCI, V47, DOI 10.1111/cogs.13230; DiPaolo EA, 2018, LINGUISTIC BODIES: THE CONTINUITY BETWEEN LIFE AND LANGUAGE; Dreyfus H. L., 1992, What computers still can't do.; Hart B., 1995, Meaningful differences in the everyday experience of young American children; Lanier J., 2023, NEW YORKER; Varela FJ., 2016, EMBODIED MIND	10	3	3	9	9	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2397-3374			NAT HUM BEHAV	Nat. Hum. Behav.	2023 NOV 20	2023										10.1038/s41562-023-01723-5	http://dx.doi.org/10.1038/s41562-023-01723-5		NOV 2023	2	Psychology, Biological; Multidisciplinary Sciences; Neurosciences; Psychology, Experimental	Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)	Psychology; Science & Technology - Other Topics; Neurosciences & Neurology	Y8GD1	37985905				2024-07-03	WOS:001107579600012
J	Abd-alrazaq, A; AlSaad, R; Alhuwail, D; Ahmed, A; Healy, PM; Latifi, S; Aziz, S; Damseh, R; Alrazak, SA; Sheikh, J				Abd-alrazaq, Alaa; AlSaad, Rawan; Alhuwail, Dari; Ahmed, Arfan; Healy, Padraig Mark; Latifi, Syed; Aziz, Sarah; Damseh, Rafat; Alrazak, Sadam Alabed; Sheikh, Javaid			Large Language Models in Medical Education: Opportunities, Challenges, and Future Directions	JMIR MEDICAL EDUCATION			English	Article						large language models; artificial intelligence; medical education; ChatGPT; GPT-4; generative AI; students; educators	ARTIFICIAL-INTELLIGENCE; CURRICULUM	The integration of large language models (LLMs), such as those in the Generative Pre-trained Transformers (GPT) series, into medical education has the potential to transform learning experiences for students and elevate their knowledge, skills, and competence. Drawing on a wealth of professional and academic experience, we propose that LLMs hold promise for revolutionizing medical curriculum development, teaching methodologies, personalized study plans and learning materials, student assessments, and more. However, we also critically examine the challenges that such integration might pose by addressing issues of algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, and copyright concerns in medical education. As we navigate the shift from an information-driven educational paradigm to an artificial intelligence (AI)-driven educational paradigm, we argue that it is paramount to understand both the potential and the pitfalls of LLMs in medical education. This paper thus offers our perspective on the opportunities and challenges of using LLMs in this context. We believe that the insights gleaned from this analysis will serve as a foundation for future recommendations and best practices in the field, fostering the responsible and effective use of AI technologies in medical education.(JMIR Med Educ 2023;9:e48291) doi: 10.2196/48291	[Abd-alrazaq, Alaa; AlSaad, Rawan; Ahmed, Arfan; Aziz, Sarah; Sheikh, Javaid] AI Ctr Precis Hlth, Weill Cornell Med Qatar, Doha, Qatar; [AlSaad, Rawan] Univ Doha Sci & Technol, Coll Comp & Informat Technol, Doha, Qatar; [Alhuwail, Dari] Kuwait Univ, Coll Life Sci, Informat Sci Dept, Kuwait, Kuwait; [Healy, Padraig Mark; Latifi, Syed] Div Med Educ, Off Educ Dev, Weill Cornell Med Qatar, Doha, Qatar; [Damseh, Rafat] United Arab Emirates Univ, Dept Comp Sci & Software Engn, Abu Dhabi, U Arab Emirates; [Alrazak, Sadam Alabed] Univ Toronto, Fac Appl Sci & Engn, Dept Mech & Ind Engn, Toronto, ON, Canada; [Abd-alrazaq, Alaa] AI Ctr Precis Hlth, Weill Cornell Med Qatar, POB 5825,Doha Al Luqta St Ar Rayyan, Doha, Qatar	Qatar Foundation (QF); Weill Cornell Medical College Qatar; Kuwait University; Qatar Foundation (QF); Weill Cornell Medical College Qatar; United Arab Emirates University; University of Toronto; Qatar Foundation (QF); Weill Cornell Medical College Qatar	Abd-alrazaq, A (corresponding author), AI Ctr Precis Hlth, Weill Cornell Med Qatar, POB 5825,Doha Al Luqta St Ar Rayyan, Doha, Qatar.	alaa_alzoubi88@yahoo.com	damseh, rafat/AAY-2880-2020; Abd-Alrazaq, Alaa Ali/ABE-3043-2021; Alhuwail, Dari/AAT-2198-2020	damseh, rafat/0000-0001-6797-0448; Abd-Alrazaq, Alaa Ali/0000-0001-7695-4626; Alhuwail, Dari/0000-0001-5038-3044; Sheikh, Javaid/0000-0002-5762-4186; Healy, Padraig Mark/0000-0002-5804-0342; Ahmed, Arfan/0000-0002-4025-5767; Latifi, Syed/0000-0003-0505-609X; Aziz, Sarah/0000-0002-0861-9743; Alabed Alrazak, Sadam/0000-0002-8586-7564				Ahmed A., 2022, Computer Methods and Programs in Biomedicine Update, P100057, DOI [DOI 10.1016/J.CMPBUP.2022.100057, https://doi.org/10.1016/j.cmpbup.2022.100057]; Ahmed A., 2022, Comput. Methods Programs Biomed. Updat, V2, DOI DOI 10.1016/J.CMPBUP.2022.100049; Ahn Sangzin, 2023, Korean J Med Educ, V35, P103, DOI 10.3946/kjme.2023.253; Akhter HM, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34752; Ali Stephen R, 2023, Lancet Digit Health, V5, pe179, DOI 10.1016/S2589-7500(23)00048-1; Alkaissi H, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35179; Anderson N, 2023, BMJ OPEN SPORT EXERC, V9, DOI 10.1136/bmjsem-2023-001568; Arif TB, 2023, MED EDUC ONLINE, V28, DOI 10.1080/10872981.2023.2181052; Bair H, 2023, ACAD MED, V98, P869, DOI 10.1097/ACM.0000000000005265; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Bolukbasi T, 2016, ADV NEUR IN, V29; Çaliskan SA, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0271872; ChatGPT Generative Pre-trained Transformer, 2022, Oncoscience, V9, P82, DOI 10.18632/oncoscience.571; Chaves A.J., arXiv, DOI [DOI 10.1049/ITR2.12294, DOI 10.1214/20-BA1223]; Chen TJ, 2023, J CHIN MED ASSOC, V86, P351, DOI 10.1097/JCMA.0000000000000900; Choi EPH, 2023, NURS EDUC TODAY, V125, DOI 10.1016/j.nedt.2023.105796; D'Mello S, 2014, LEARN INSTR, V29, P153, DOI 10.1016/j.learninstruc.2012.05.003; Dahmen J, 2023, KNEE SURG SPORT TR A, V31, P1187, DOI 10.1007/s00167-023-07355-6; Davis MH, 2003, MED TEACH, V25, P596, DOI 10.1080/0142159032000144383; Dumic-Cule I, 2020, CROAT MED J, V61, P457, DOI 10.3325/cmj.2020.61.457; Eysenbach Gunther, 2023, JMIR Med Educ, V9, pe46885, DOI 10.2196/46885; Frommeyer TC, 2022, FRONT DIGIT HEALTH, V4, DOI 10.3389/fdgth.2022.831123; Gilson Aidan, 2023, JMIR Med Educ, V9, pe45312, DOI 10.2196/45312; Goodman RS, 2023, MED-CAMBRIDGE, V4, P139, DOI 10.1016/j.medj.2023.02.008; Graf A, 2023, NEUROSCIENCE, V515, P71, DOI 10.1016/j.neuroscience.2023.02.008; Grunhut J, 2022, JMIR MED EDUC, V8, DOI 10.2196/35587; Guo AA, 2023, MED TEACH, V45, P1063, DOI 10.1080/0142159X.2023.2198094; Hallsworth JE, 2023, MICROB BIOTECHNOL, V16, P1131, DOI 10.1111/1751-7915.14222; Hill-Yardin EL, 2023, BRAIN BEHAV IMMUN, V110, P152, DOI 10.1016/j.bbi.2023.02.022; Huh S, 2023, J EDUC EVAL HEALTH P, V20, DOI 10.3352/jeehp.2023.20.1; Ide K, 2023, J EPIDEMIOL, V33, P381, DOI 10.2188/jea.JE20230030; Karkra R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34699; Khan RA, 2023, PAK J MED SCI, V39, P605, DOI 10.12669/pjms.39.2.7653; Kitamura FC, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.230171; Koo Malcolm, 2023, Radiology, V307, pe230312, DOI 10.1148/radiol.230312; Kuhail MA, 2023, EDUC INF TECHNOL, V28, P973, DOI 10.1007/s10639-022-11177-3; Kung Tiffany H, 2023, PLOS Digit Health, V2, pe0000198, DOI 10.1371/journal.pdig.0000198; Kung TH, 2022, medRxiv, DOI [10.1101/2022.12.19.22283643, 10.1101/2022.12.19.22283643v2, DOI 10.1101/2022.12.19.22283643V2, 10.1101/2022.12.19.22283643, DOI 10.1101/2022.12.19.22283643]; Lee H, 2023, ANAT SCI EDUC, DOI 10.1002/ase.2270; Maini B, 2021, INDIAN PEDIATR, V58, P496, DOI 10.1007/s13312-021-2228-0; Manohar N, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.34616; Markovski Y, OPENAI; Masters K, 2023, MED TEACH, V45, P574, DOI 10.1080/0142159X.2023.2186203; Masters K, 2023, MED TEACH, V45, P666, DOI 10.1080/0142159X.2023.2190476; Mbakwe Amarachi B, 2023, PLOS Digit Health, V2, pe0000205, DOI 10.1371/journal.pdig.0000205; McCallum S., 2023, BBC; Ngo B, 2022, RADIOL-ARTIF INTELL, V4, DOI 10.1148/ryai.220074; O'Connor S, 2023, NURSE EDUC PRACT, V66, DOI 10.1016/j.nepr.2022.103537; OpenAI, 2023, GPT-4 Technical Report; OpenAI, GPT 4 IS OPENAIS MOS; Patel SB, 2023, LANCET DIGIT HEALTH, V5, pE107, DOI 10.1016/S2589-7500(23)00021-3; Ramesh A, 2021, PR MACH LEARN RES, V139; Rudolph J., 2023, J. Appl. Learn. Teach, V6, DOI [DOI 10.37074/JALT.2023.6.1.9, https://doi.org/10.37074/jalt.2023.6.1.9, 10.37074/jalt.2023.6.1.9]; Sabry Abdel-Messih Mary, 2023, JMIR Med Educ, V9, pe46876, DOI 10.2196/46876; Sallam M, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.35029; Strong E, 2023, medRxiv, DOI [10.1101/2023.03.24.23287731, 10.1101/2023.03.24.23287731, DOI 10.1101/2023.03.24.23287731]; Subramani M, 2023, ADV PHYSIOL EDUC, V47, P270, DOI 10.1152/advan.00036.2023; Temsah O, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.37281; Thirunavukarasu AJ, 2023, Observational study demonstrating opportunities and limitations in primary care, V9, DOI [10.2196/46599, DOI 10.2196/46599]; Tlili A, 2023, SMART LEARN ENVIRON, V10, DOI 10.1186/s40561-023-00237-x; Trust T., 2023, CHATGPT ED; Wang LKP, 2023, MED TEACH, V45, P925, DOI 10.1080/0142159X.2023.2198663; Zhai Xiaohua, 2022, P IEEE CVF C COMP VI, P12104, DOI DOI 10.1109/CVPR52688.2022.01179	63	47	48	49	105	JMIR PUBLICATIONS, INC	TORONTO	130 QUEENS QUAY East, Unit 1100, TORONTO, ON M5A 0P6, CANADA	2369-3762			JMIR MED EDUC	JMIR Med. Educ.		2023	9								e48291	10.2196/48291	http://dx.doi.org/10.2196/48291			11	Education, Scientific Disciplines	Emerging Sources Citation Index (ESCI)	Education & Educational Research	K8SA8	37261894	gold, Green Published			2024-07-03	WOS:001019068500001
J	Silverman, AL; Sushil, M; Bhasuran, B; Ludwig, D; Buchanan, J; Racz, R; Parakala, M; El-Kamary, S; Ahima, O; Belov, A; Choi, L; Billings, M; Li, Y; Habal, N; Liu, Q; Tiwari, J; Butte, AJ; Rudrapatna, VA				Silverman, Anna L.; Sushil, Madhumita; Bhasuran, Balu; Ludwig, Dana; Buchanan, James; Racz, Rebecca; Parakala, Mahalakshmi; El-Kamary, Samer; Ahima, Ohenewaa; Belov, Artur; Choi, Lauren; Billings, Monisha; Li, Yan; Habal, Nadia; Liu, Qi; Tiwari, Jawahar; Butte, Atul J.; Rudrapatna, Vivek A.			Algorithmic Identification of Treatment-Emergent Adverse Events From Clinical Notes Using Large Language Models: A Pilot Study in Inflammatory Bowel Disease	CLINICAL PHARMACOLOGY & THERAPEUTICS			English	Article								Outpatient clinical notes are a rich source of information regarding drug safety. However, data in these notes are currently underutilized for pharmacovigilance due to methodological limitations in text mining. Large language models (LLMs) like Bidirectional Encoder Representations from Transformers (BERT) have shown progress in a range of natural language processing tasks but have not yet been evaluated on adverse event (AE) detection. We adapted a new clinical LLM, University of California - San Francisco (UCSF)-BERT, to identify serious AEs (SAEs) occurring after treatment with a non-steroid immunosuppressant for inflammatory bowel disease (IBD). We compared this model to other language models that have previously been applied to AE detection. We annotated 928 outpatient IBD notes corresponding to 928 individual patients with IBD for all SAE-associated hospitalizations occurring after treatment with a non-steroid immunosuppressant. These notes contained 703 SAEs in total, the most common of which was failure of intended efficacy. Out of eight candidate models, UCSF-BERT achieved the highest numerical performance on identifying drug-SAE pairs from this corpus (accuracy 88-92%, macro F1 61-68%), with 5-10% greater accuracy than previously published models. UCSF-BERT was significantly superior at identifying hospitalization events emergent to medication use (P < 0.01). LLMs like UCSF-BERT achieve numerically superior accuracy on the challenging task of SAE detection from clinical notes compared with prior methods. Future work is needed to adapt this methodology to improve model performance and evaluation using multicenter data and newer architectures like Generative pre-trained transformer (GPT). Our findings support the potential value of using large language models to enhance pharmacovigilance.	[Silverman, Anna L.] Mayo Clin, Dept Med, Div Gastroenterol & Hepatol, Phoenix, AZ USA; [Silverman, Anna L.] Univ Calif San Diego, Dept Med, La Jolla, CA USA; [Sushil, Madhumita; Bhasuran, Balu; Ludwig, Dana; Buchanan, James; Butte, Atul J.; Rudrapatna, Vivek A.] Bakar Computat Hlth Sci Inst, San Francisco, CA 94143 USA; [Racz, Rebecca; El-Kamary, Samer; Ahima, Ohenewaa; Belov, Artur; Choi, Lauren; Billings, Monisha; Li, Yan; Habal, Nadia; Liu, Qi; Tiwari, Jawahar] US FDA, Silver Spring, MD USA; [Parakala, Mahalakshmi] Univ Calif Berkeley, Dept Publ Hlth, Berkeley, CA USA; [Butte, Atul J.] Univ Calif Hlth, Ctr Data Driven Insights & Innovat, Oakland, CA USA; [Rudrapatna, Vivek A.] Univ Calif San Francisco, Dept Med, Div Gastroenterol & Hepatol, San Francisco, CA 94143 USA; [El-Kamary, Samer] Univ Maryland, Sch Med, Baltimore, MD USA; [El-Kamary, Samer] Takeda Pharmaceut Inc, Boston, MA USA	Mayo Clinic; Mayo Clinic Phoenix; University of California System; University of California San Diego; US Food & Drug Administration (FDA); University of California System; University of California Berkeley; University of California System; University of California San Francisco; University System of Maryland; University of Maryland Baltimore	Rudrapatna, VA (corresponding author), Bakar Computat Hlth Sci Inst, San Francisco, CA 94143 USA.; Rudrapatna, VA (corresponding author), Univ Calif San Francisco, Dept Med, Div Gastroenterol & Hepatol, San Francisco, CA 94143 USA.	vivek.rudrapatna@ucsf.edu	BHASURAN, BALU/AAB-1583-2021	BHASURAN, BALU/0000-0002-9890-4627; Sushil, Madhumita/0000-0001-7884-0526; Belov, Artur/0000-0001-6848-1224; Racz, Rebecca/0000-0002-5487-5692; Silverman, Anna/0000-0002-1139-0900; Ludwig, Dana/0009-0008-1240-5685; Buchanan, James/0000-0001-8417-2288	Food and Drug Administration (FDA) of the U.S. Department of Health and Human Services (HHS); Lily Wong; UCSF Bakar Computational Health Sciences Institute; UCSF Academic Research Services; UCSF high-performance computing cluster	Food and Drug Administration (FDA) of the U.S. Department of Health and Human Services (HHS)(United States Department of Health & Human ServicesUS Food & Drug Administration (FDA)); Lily Wong; UCSF Bakar Computational Health Sciences Institute; UCSF Academic Research Services; UCSF high-performance computing cluster	The authors gratefully acknowledge the invaluable administrative support provided by Lily Wong. In addition, we would like to acknowledge the UCSF Information Commons Computational Research Platform, developed and supported by UCSF Bakar Computational Health Sciences Institute and UCSF Academic Research Services. We would like to express our thanks to the Wynton support team and the UCSF high-performance computing cluster, Wynton.	Agency EM, ICH TOPIC E9 STAT PR; Anderson Kaitlyn, 2022, JPGN Rep, V3, pe231, DOI 10.1097/PG9.0000000000000231; [Anonymous], LABEL STUDIO DATA LA; [Anonymous], Medical Dictionary for Regulatory Activities (MedDRA); [Anonymous], STATSMODELS COMPUTER; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Chaparro M, 2018, ALIMENT PHARM THER, V48, P839, DOI 10.1111/apt.14930; Conti F, 2018, RHEUMATOLOGY, V57, P11, DOI 10.1093/rheumatology/key209; Devlin J., 2018, BERT PRE TRAINING DE; ecfr, CODE FEDERAL REGULAT; Erickson N., 2020, AUTOGLUON TABULAR RO; fda, QUESTIONS ANSWERS FD; Hazell L, 2006, DRUG SAFETY, V29, P385, DOI 10.2165/00002018-200629050-00003; He J, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.715320; Henry S, 2020, J AM MED INFORM ASSN, V27, P3, DOI 10.1093/jamia/ocz166; Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]; Ji SX, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104998; Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791; LeCun Y., ADV NEURAL INFORM PR; Norgeot B, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0258-y; Pedregosa F, 2011, J MACH LEARN RES, V12, P2825; Quezada SM, 2018, EXPERT REV GASTROENT, V12, P1183, DOI 10.1080/17474124.2018.1545574; Savova GK, 2010, J AM MED INFORM ASSN, V17, P507, DOI 10.1136/jamia.2009.001560; Smith Malcolm, 2010, Ann Intern Med, V152, pJC5, DOI 10.7326/0003-4819-152-10-201005180-02013; Sushil M., 2022, DEVELOPING GEN PURPO; Thein D, 2022, JAMA DERMATOL, V158, P997, DOI 10.1001/jamadermatol.2022.2360; Varallo FR, 2014, REV ESC ENFERM USP, V48, P739, DOI 10.1590/S0080-623420140000400023	27	0	0	5	5	WILEY	HOBOKEN	111 RIVER ST, HOBOKEN 07030-5774, NJ USA	0009-9236	1532-6535		CLIN PHARMACOL THER	Clin. Pharmacol. Ther.	JUN	2024	115	6					1391	1399		10.1002/cpt.3226	http://dx.doi.org/10.1002/cpt.3226		MAR 2024	9	Pharmacology & Pharmacy	Science Citation Index Expanded (SCI-EXPANDED)	Pharmacology & Pharmacy	WE2K7	38459719	Green Submitted			2024-07-03	WOS:001181392200001
J	Harrigan, WL; Ferrell, BD; Wommack, KE; Polson, SW; Schreiber, ZD; Belcaid, M				Harrigan, William L.; Ferrell, Barbra D.; Wommack, K. Eric; Polson, Shawn W.; Schreiber, Zachary D.; Belcaid, Mahdi			Improvements in viral gene annotation using large language models and soft alignments	BMC BIOINFORMATICS			English	Article						Large language models; Protein homology; Viruses; Alignments	PROTEIN; PREDICTION	Background The annotation of protein sequences in public databases has long posed a challenge in molecular biology. This issue is particularly acute for viral proteins, which demonstrate limited homology to known proteins when using alignment, k-mer, or profile-based homology search approaches. A novel methodology employing Large Language Models (LLMs) addresses this methodological challenge by annotating protein sequences based on embeddings.Results Central to our contribution is the soft alignment algorithm, drawing from traditional protein alignment but leveraging embedding similarity at the amino acid level to bypass the need for conventional scoring matrices. This method not only surpasses pooled embedding-based models in efficiency but also in interpretability, enabling users to easily trace homologous amino acids and delve deeper into the alignments. Far from being a black box, our approach provides transparent, BLAST-like alignment visualizations, combining traditional biological research with AI advancements to elevate protein annotation through embedding-based analysis while ensuring interpretability. Tests using the Virus Orthologous Groups and ViralZone protein databases indicated that the novel soft alignment approach recognized and annotated sequences that both blastp and pooling-based methods, which are commonly used for sequence annotation, failed to detect.Conclusion The embeddings approach shows the great potential of LLMs for enhancing protein sequence annotation, especially in viral genomics. These findings present a promising avenue for more efficient and accurate protein function inference in molecular biology.	[Harrigan, William L.] Univ Hawaii Manoa, Hawaii Inst Marine Biol, Honolulu, HI 96822 USA; [Ferrell, Barbra D.; Wommack, K. Eric; Schreiber, Zachary D.] Univ Delaware, Dept Plant & Soil Sci, Newark, DE 19713 USA; [Polson, Shawn W.] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19713 USA; [Belcaid, Mahdi] Univ Hawaii Manoa, Dept Comp Sci, Honolulu, HI 96822 USA	University of Hawaii System; University of Hawaii Manoa; University of Delaware; University of Delaware; University of Hawaii System; University of Hawaii Manoa	Belcaid, M (corresponding author), Univ Hawaii Manoa, Dept Comp Sci, Honolulu, HI 96822 USA.	mahdi@hawaii.edu			Hawaii EPSCoR Fellowship	Hawaii EPSCoR Fellowship	No Statement Available	Altschul SF, 2005, FEBS J, V272, P5101, DOI 10.1111/j.1742-4658.2005.04945.x; Altschul SF, 1997, NUCLEIC ACIDS RES, V25, P3389, DOI 10.1093/nar/25.17.3389; ALTSCHUL SF, 1990, J MOL BIOL, V215, P403, DOI 10.1016/S0022-2836(05)80360-2; Bao YM, 2004, J VIROL, V78, P7291, DOI 10.1128/JVI.78.14.7291-7298.2004; Bateman A, 2002, NUCLEIC ACIDS RES, V30, P276, DOI [10.1093/nar/gkh121, 10.1093/nar/gkr1065, 10.1093/nar/gkp985]; Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50; Bepler T, 2021, CELL SYST, V12, P654, DOI 10.1016/j.cels.2021.05.017; Brochet X, 2008, NUCLEIC ACIDS RES, V36, pW503, DOI 10.1093/nar/gkn316; Cai YD, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00391; Devkota K, 2022, BIOINFORMATICS, V38, P3395, DOI 10.1093/bioinformatics/btac322; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Ding F, 2024, bioRxiv, P2024; Dutilh BE, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5498; Elnaggar A, 2022, IEEE T PATTERN ANAL, V44, P7112, DOI 10.1109/TPAMI.2021.3095381; FIX E, 1989, INT STAT REV, V57, P238, DOI 10.2307/1403797; Hamid MN, 2019, BIOINFORMATICS, V35, P2009, DOI 10.1093/bioinformatics/bty937; Huang G, 2016, ADV NEUR IN, V29; Islam SMA, 2018, BIOINFORMATICS, V34, P1481, DOI 10.1093/bioinformatics/btx823; Jin JR, 2022, GENOME BIOL, V23, DOI 10.1186/s13059-022-02780-1; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Jumper J, 2021, NATURE, V596, P583, DOI 10.1038/s41586-021-03819-2; Lan M, 2009, J BIOMED INFORM, V42, P866, DOI 10.1016/j.jbi.2009.07.004; Lin Z., 2022, BIORXIV; Littmann M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80786-0; Liu CM, 2022, LIFE-BASEL, V12, DOI 10.3390/life12081213; Madani A, 2023, NAT BIOTECHNOL, V41, P1099, DOI 10.1038/s41587-022-01618-2; Mikolov T., 2013, Advances in neural information processing systems, DOI DOI 10.48550/ARXIV.1310.4546; Min BN, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3605943; Mohamed SK, 2021, BRIEF BIOINFORM, V22, P1679, DOI 10.1093/bib/bbaa012; Mullick B, 2021, COMPUT BIOL MED, V138, DOI 10.1016/j.compbiomed.2021.104915; Nijkamp E, 2022, Arxiv, DOI [arXiv:2206.13517, 10.48550/arXiv.2206.13517]; Ofer D, 2015, BIOINFORMATICS, V31, P3429, DOI 10.1093/bioinformatics/btv345; Le Q, 2014, PR MACH LEARN RES, V32, P1188; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Radivojac P, 2013, NAT METHODS, V10, P221, DOI [10.1038/NMETH.2340, 10.1038/nmeth.2340]; Ranjan A, 2022, IEEE ACM T COMPUT BI, V19, P2685, DOI 10.1109/TCBB.2021.3093060; Rao R, 2020, Biorxiv, P2020; Rice P.M., 2011, Emboss user's guide: Practical bioinformatics; Rifaioglu AS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43708-3; Schnoes AM, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000605; Schwikowski B, 2000, NAT BIOTECHNOL, V18, P1257, DOI 10.1038/82360; Suzek BE, 2007, BIOINFORMATICS, V23, P1282, DOI 10.1093/bioinformatics/btm098; Taylor R, 2022, arXiv; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Wang WK, 2022, NAT COMPUT SCI, V2, P804, DOI 10.1038/s43588-022-00373-3; Xue B, 2014, CHEM REV, V114, P6880, DOI 10.1021/cr4005692; Yang F, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-03646-8; Yeger-Lotem E, 2015, FRONT GENET, V6, DOI 10.3389/fgene.2015.00257; Zhang S, 2023, NEURO-ONCOL ADV, V5, DOI 10.1093/bioadv/vbad001	49	0	0	0	0	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	APR 25	2024	25	1							165	10.1186/s12859-024-05779-6	http://dx.doi.org/10.1186/s12859-024-05779-6			19	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	OY9Q4	38664627	gold			2024-07-03	WOS:001210959800003
J	Chang, C; Wang, SQ; Zhang, JW; Ge, JW; Li, L				Chang, Cheng; Wang, Siqi; Zhang, Jiawei; Ge, Jingwei; Li, Li			LLMScenario: Large Language Model Driven Scenario Generation	IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS			English	Article; Early Access						Large language model (LLM); scenario engineering; scenario generation		Scenario engineering plays a vital role in various Industry 5.0 applications. In the field of autonomous driving systems, driving scenario data are important for the training and testing of critical modules. However, the corner scenario cases are usually rare and necessary to be extended. Existing methods cannot handle the interpretation and reasoning of the generation process well, which reduces the reliability and usability of the generated scenarios. With the rapid development of Foundation Models, especially the large language model (LLM), we can conduct scenario generation via more powerful tools. In this article, we propose LLMScenario, a novel LLM-driven scenario generation framework, which is composed of scenario prompt engineering, LLM scenario generation, and evaluation feedback tuning. The minimum scenario description specific to LLM is given by scenario analysis and ablation studies. We also appropriately design the score functions in terms of reality and rarity to evaluate the generated scenarios. The model performance is further enhanced through chain-of-thoughts and experiences. Different LLMs are also compared with our framework. Experimental results on naturalistic datasets demonstrate the effectiveness of LLMScenario, which can provide solid support for scenario engineering in Industry 5.0.	[Chang, Cheng; Wang, Siqi; Zhang, Jiawei; Ge, Jingwei] Tsinghua Univ, Dept Automat, Beijing 100084, Peoples R China; [Li, Li] Tsinghua Univ, Dept Automat, BNRist, Beijing 100084, Peoples R China	Tsinghua University; Tsinghua University	Li, L (corresponding author), Tsinghua Univ, Dept Automat, BNRist, Beijing 100084, Peoples R China.	li-li@tsinghua.edu.cn	; Li, Li/A-3453-2008	Zhang, Jiawei/0000-0002-8634-1687; Chang, Cheng/0000-0003-2768-5866; Ge, Jingwei/0000-0003-2309-9739; Li, Li/0000-0002-9428-1960	National Key Research and Development Program of China	National Key Research and Development Program of China	No Statement Available	Abeysirigoonawardena Y, 2019, IEEE INT CONF ROBOT, P8271, DOI [10.1109/icra.2019.8793740, 10.1109/ICRA.2019.8793740]; Althoff M, 2018, IEEE INT VEH SYM, P1326, DOI 10.1109/IVS.2018.8500374; Althoff M, 2017, IEEE INT VEH SYM, P719, DOI 10.1109/IVS.2017.7995802; [Anonymous], 2021, Asam Openscenario; [Anonymous], 2023, Gpt-4 Technical Report; Bagschik G, 2018, IEEE INT VEH SYM, P1813, DOI 10.1109/IVS.2018.8500632; Brown T., 2020, Advances in neural information processing systems, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165; Buja A, 2008, J COMPUT GRAPH STAT, V17, P444, DOI 10.1198/106186008X318440; Chang C, 2024, Arxiv, DOI arXiv:2402.07720; Chang C, 2023, IEEE T INTELL VEHICL, V8, P4498, DOI 10.1109/TIV.2023.3293954; Chang C, 2023, IEEE T INTELL VEHICL, V8, P1156, DOI 10.1109/TIV.2022.3215503; Chang C, 2022, IEEE INT C INTELL TR, P3940, DOI 10.1109/ITSC55140.2022.9922076; Chen L, 2023, IEEE T INTELL VEHICL, V8, P1046, DOI 10.1109/TIV.2022.3223131; Chen L, 2023, IEEE T SYST MAN CY-S, V53, P6401, DOI [10.1109/ICASSP49357.2023.10095036, 10.1109/TSMC.2023.3283021]; Chen L, 2023, IEEE T SYST MAN CY-S, V53, P5831, DOI 10.1109/TSMC.2023.3276218; Cox M A A, 2008, Handb. Data Vis, P315, DOI DOI 10.1007/978-3-540-33037-0_14; Cui YD, 2024, IEEE T INTELL VEHICL, V9, P1450, DOI 10.1109/TIV.2023.3327715; Dai XY, 2022, FRONT INFORM TECH EL, V23, P1795, DOI 10.1631/FITEE.2200323; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Ding WH, 2020, IEEE INT CONF ROBOT, P4314, DOI [10.1109/ICRA40945.2020.9197145, 10.1109/icra40945.2020.9197145]; Ding WW, 2023, IEEE T SYST MAN CY-S, V53, P3092, DOI 10.1109/TSMC.2022.3224250; Du P., 2019, SAE Int. J. Connect. Autom. Veh., V2, P241; Elhafsi A, 2023, AUTON ROBOT, V47, P1035, DOI 10.1007/s10514-023-10132-6; Feng L, 2023, IEEE INT CONF ROBOT, P3567, DOI 10.1109/ICRA48891.2023.10160296; Feng S, 2021, IEEE T INTELL TRANSP, V22, P1573, DOI 10.1109/TITS.2020.2972211; Gao RY, 2024, Arxiv, DOI arXiv:2310.02601; Guo YQ, 2023, IEEE T INTELL VEHICL, V8, P709, DOI 10.1109/TIV.2022.3163335; Han JP, 2023, IEEE T SYST MAN CY-S, V53, P2118, DOI 10.1109/TSMC.2022.3228928; Jiang R, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.017101; Kang MZ, 2023, IEEE T SYST MAN CY-S, V53, P3718, DOI 10.1109/TSMC.2022.3230830; Kesting A, 2007, TRANSPORT RES REC, P86, DOI 10.3141/1999-10; Koren M, 2018, IEEE INT VEH SYM, P1898, DOI 10.1109/IVS.2018.8500400; Krajewski R, 2018, IEEE INT C INTELL TR, P2118, DOI 10.1109/ITSC.2018.8569552; Leng JW, 2023, IEEE T SYST MAN CY-S, V53, P4715, DOI 10.1109/TSMC.2023.3257172; Li A, 2022, IEEE T INTELL TRANSP, V23, P14859, DOI 10.1109/TITS.2021.3134661; Li L, 2023, IEEE INTELL SYST, V38, P3, DOI 10.1109/MIS.2023.3235676; Li L, 2022, IEEE T INTELL TRANSP, V23, P7759, DOI 10.1109/TITS.2021.3072774; Li L, 2021, IEEE T INTELL TRANSP, V22, P6297, DOI 10.1109/TITS.2020.2991039; Li L, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aaw4106; Li X, 2023, IEEE T INTELL VEHICL, V8, P3211, DOI 10.1109/TIV.2023.3269428; Li X, 2023, IEEE T SYST MAN CY-S, V53, P2148, DOI 10.1109/TSMC.2022.3228594; Li X, 2022, IEEE INTELL SYST, V37, P18, DOI 10.1109/MIS.2022.3197950; Li X, 2022, IEEE-CAA J AUTOMATIC, V9, P1061, DOI 10.1109/JAS.2022.105629; Liu CL, 2023, IEEE T SYST MAN CY-S, V53, P6792, DOI 10.1109/TSMC.2023.3289322; Lu JW, 2022, IEEE T SYST MAN CY-S, V52, P3772, DOI 10.1109/TSMC.2021.3073429; LU J, 2022, FRONT INFORM TECH EL, V23, P991, DOI 10.1631/FITEE.2240000; Mao JG, 2023, Arxiv, DOI arXiv:2310.01415; Maretic HP, 2019, ADV NEUR IN, V32; Miao QH, 2023, IEEE-CAA J AUTOMATIC, V10, P877, DOI 10.1109/JAS.2023.123561; Miao QH, 2023, IEEE-CAA J AUTOMATIC, V10, P603, DOI 10.1109/JAS.2023.123375; Patel D., 2023, Demystifying GPT-4: The Engineering Tradeoffs That Led OpenAI to Their Architecture, V10; Peng XY, 2024, IEEE T SYST MAN CY-S, V54, P497, DOI 10.1109/TSMC.2023.3315541; Qin R, 2023, IEEE T SYST MAN CY-S, V53, P2073, DOI 10.1109/TSMC.2022.3228530; Ramesh A, 2021, PR MACH LEARN RES, V139; Rempe D, 2022, PROC CVPR IEEE, P17284, DOI 10.1109/CVPR52688.2022.01679; Scholtes M, 2021, IEEE ACCESS, V9, P59131, DOI 10.1109/ACCESS.2021.3072739; Sha H, 2023, Arxiv, DOI arXiv:2310.03026; Sun T., 2022, PROC ICML, P20841; Tan JY, 2020, IEEE-CAA J AUTOMATIC, V7, P301, DOI 10.1109/JAS.2019.1911855; Teng SY, 2023, IEEE T INTELL VEHICL, V8, P3692, DOI 10.1109/TIV.2023.3274536; Tian YL, 2023, IEEE T INTELL VEHICL, V8, P4198, DOI 10.1109/TIV.2023.3307012; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Treiber M, 2017, TRANSP RES PROC, V23, P174, DOI 10.1016/j.trpro.2017.05.011; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P4287, DOI 10.1109/TIV.2023.3326636; Wang FY, 2023, IEEE T INTELL VEHICL, V8, P1003, DOI 10.1109/TIV.2023.3246701; Wang FY, 2022, FRONT INFORM TECH EL, V23, P1142, DOI 10.1631/FITEE.2100418; Wang FY, 2010, IEEE INTELL SYST, V25, P85, DOI 10.1109/MIS.2010.104; Wang G, 2024, Arxiv, DOI arXiv:2309.11235; Wang JG, 2023, IEEE T SYST MAN CY-S, V53, P2037, DOI 10.1109/TSMC.2022.3226755; Wang LN, 2023, Arxiv, DOI arXiv:2312.13156; Wang SY, 2023, IEEE T INTELL VEHICL, V8, P4706, DOI 10.1109/TIV.2023.3325300; Wang XF, 2023, Arxiv, DOI arXiv:2309.09777; Wang XX, 2023, IEEE-CAA J AUTOMATIC, V10, P1692, DOI 10.1109/JAS.2023.123753; Wang XX, 2023, IEEE T SYST MAN CY-S, V53, P2138, DOI 10.1109/TSMC.2022.3228934; Wang YF, 2023, IEEE-CAA J AUTOMATIC, V10, P2070, DOI 10.1109/JAS.2023.123951; Wei JS, 2022, ADV NEUR IN; Wei QL, 2022, IEEE T SYST MAN CY-S, V52, P192, DOI 10.1109/TSMC.2020.2995646; Wen LC, 2024, Arxiv, DOI arXiv:2309.16292; Wu DM, 2023, Arxiv, DOI arXiv:2309.04379; Wu P, 2023, IEEE T SYST MAN CY-S, V53, P6897, DOI 10.1109/TSMC.2023.3288904; Wu TY, 2023, IEEE-CAA J AUTOMATIC, V10, P1122, DOI 10.1109/JAS.2023.123618; Xu P, 2022, IEEE T SYST MAN CY-S, V52, P7223, DOI 10.1109/TSMC.2022.3152784; Xu ZH, 2024, Arxiv, DOI arXiv:2310.01412; Yang DS, 2023, IEEE T SYST MAN CY-S, V53, P2160, DOI 10.1109/TSMC.2022.3229036; Yang J, 2023, IEEE T SYST MAN CY-S, V53, P2188, DOI 10.1109/TSMC.2022.3228817; Yang S, 2024, IEEE INTEL TRANSP SY, V16, P41, DOI 10.1109/MITS.2023.3345930; Zhang H, 2023, IEEE T SYST MAN CY-S, V53, P3400, DOI 10.1109/TSMC.2022.3228314; Zhang KP, 2022, IEEE T INTELL TRANSP, V23, P21944, DOI 10.1109/TITS.2022.3170329; Zhang XH, 2023, IEEE T SOFTWARE ENG, V49, P991, DOI 10.1109/TSE.2022.3170122; Zhao C, 2023, IEEE T SYST MAN CY-S, V53, P2062, DOI 10.1109/TSMC.2022.3228914; Zhao D, 2017, IEEE T INTELL TRANSP, V18, P595, DOI 10.1109/TITS.2016.2582208; Zhao JW, 2023, IEEE T INTELL VEHICL, V8, P2184, DOI 10.1109/TIV.2022.3207275	92	0	0	10	10	IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC	PISCATAWAY	445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA	2168-2216	2168-2232		IEEE T SYST MAN CY-S	IEEE Trans. Syst. Man Cybern. -Syst.	2024 MAY 14	2024										10.1109/TSMC.2024.3392930	http://dx.doi.org/10.1109/TSMC.2024.3392930		MAY 2024	14	Automation & Control Systems; Computer Science, Cybernetics	Science Citation Index Expanded (SCI-EXPANDED)	Automation & Control Systems; Computer Science	RF2F0					2024-07-03	WOS:001226180200001
J	Dong, HY; Dong, JL; Wan, SH; Yuan, S; Guan, ZT				Dong, Huoyuan; Dong, Jialiang; Wan, Shaohua; Yuan, Shuai; Guan, Zhitao			Transferable adversarial distribution learning: Query-efficient adversarial attack against large language models	COMPUTERS & SECURITY			English	Article						Adversarial attack; Natural language processing; Black-box attack; Adversarial distribution; Gradient-based optimization		It is a challenging task to fool a text classifier based on deep neural networks under the black-box setting where the target model can only be queried. Among the existing black-box attacks, decision-based methods have a large query cost due to exponential perturbation space and greedy search strategy. Transfer-based methods, on the other hand, tend to overfit the surrogate model and thus fail when applied to unknown target models. In this paper, we propose a straightforward yet highly effective adversarial attack framework for black-box transformer-based models, thereby exposing vulnerabilities within large language models. Specifically, we leverage a fine-tuned large language model as a white-box surrogate model and optimize a distribution of adversarial text. This distribution is parameterized by a continuous-valued matrix based upon the surrogate model. To avoid overfitting of the distribution and improve its adversarial transferability, we incorporate an additional causal language model into our framework as a constraint model. Based on this constraint model, we add language model perplexity and semantic consistency as regularization terms during the distribution training process. To further reduce the number of queries to the target model, i.e., improve the threat level of examples drawn from our distribution, we employ a geometric loss strategy to ensure that the distribution training process learns the optimal perturbation. Extensive experimental studies have been carried out on benchmark datasets and the results demonstrate significant improvement on the performance and query efficiency under black-box setting in comparison with well-established approaches. Our approach achieves an 80.98% reduction in BERT model accuracy while consuming only 21.86% of the query times required by prior attacks.	[Dong, Huoyuan; Dong, Jialiang; Guan, Zhitao] North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China; [Wan, Shaohua] Univ Elect Sci & Technol China, Shenzhen Inst Adv Study, Shenzhen 518110, Peoples R China; [Yuan, Shuai] Brock Univ, Dept Finance Operat & Informat Syst FOIS, St Catharines, ON, Canada	North China Electric Power University; Shenzhen Institute for Advanced Study, UESTC; University of Electronic Science & Technology of China; Brock University	Guan, ZT (corresponding author), North China Elect Power Univ, Sch Control & Comp Engn, Beijing 102206, Peoples R China.	jialiang_dong@ncepu.edu.cn; jialiang_dong@ncepu.edu.cn; shaohua.wan@uestc.edu.cn; syuan@brocku.ca; guan@ncepu.edu.cn		Guan, Zhitao/0000-0003-0901-8621; Yuan, Shuai/0000-0002-9916-6080	National Natural Science Foundation of China [61972148]	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC))	<B>Acknowledgement</B> The work is supported by the National Natural Science Foundation of China under Grant 61972148.	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52; Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49; Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169; Conneau A, 2019, ADV NEUR IN, V32; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Dong YP, 2019, PROC CVPR IEEE, P4307, DOI 10.1109/CVPR.2019.00444; Duan YX, 2022, COMPUT SECUR, V122, DOI 10.1016/j.cose.2022.102888; Ebrahimi J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P31; Gao J, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P50, DOI 10.1109/SPW.2018.00016; Garg S, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6174; Gou JP, 2023, IEEE T IND INFORM, V19, P7099, DOI 10.1109/TII.2022.3209672; Guo C, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P5747; He XL, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2006; Goodfellow IJ, 2015, Arxiv, DOI arXiv:1412.6572; Jang Eric, 2017, INT C LEARN REPR; Jiang YG, 2020, INT J MACH LEARN CYB, V11, P2625, DOI 10.1007/s13042-020-01132-4; Jin D, 2020, AAAI CONF ARTIF INTE, V34, P8018; Kingma D. P., 2017, ARXIV; Lan Z, 2020, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1909.11942; Li HY, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P2117; Li JF, 2018, Arxiv, DOI arXiv:1812.05271; Li L, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6193; Lin JY, 2021, ACL-IJCNLP 2021: THE 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 2, P333; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Maddison C., 2017, INT C LEARNING REPRE, P1; Meng W., 2020, P 28 INT C COMP LING, P6679, DOI 10.18653/v1/2020.colingmain.585; Miyato T., 2017, Conference Track Proceedings; Mondal I, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P5378; Morris JX, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P119; Paszke A, 2019, ADV NEUR IN, V32; Pennington Jeffrey, 2014, P 2014 C EMP METH NA, P1532; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Ren SH, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1085; Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631; Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]; Vaswani A, 2017, ADV NEUR IN, V30; Wang A., 2018, P 2018 EMNLP WORKSH, P353, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]; Wang B., 2022, FIND ASS COMP LING N, P176; Wang XS, 2021, AAAI CONF ARTIF INTE, V35, P13997; Wei WT, 2022, IEEE T INTELL TRANSP, V23, P25536, DOI 10.1109/TITS.2021.3091321; Wong E., 2020, INT C LEARN REPR; Xie Y, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P587; Yang P, 2020, J ORTHOP TRANSL, V21, P1, DOI 10.1016/j.jot.2019.11.002; Yuan LP, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1612; Zang Y, 2020, P 58 ANN M ASS COMP, P6066, DOI DOI 10.18653/V1/2020.ACL-MAIN.540; Zhang X, 2015, ADV NEUR IN, V28; Zhang XZ, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1967; Zhong H., 2020, P 58 ANN M ASS COMPU, P5218	49	2	2	8	16	ELSEVIER ADVANCED TECHNOLOGY	OXFORD	OXFORD FULFILLMENT CENTRE THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, OXON, ENGLAND	0167-4048	1872-6208		COMPUT SECUR	Comput. Secur.	DEC	2023	135								103482	10.1016/j.cose.2023.103482	http://dx.doi.org/10.1016/j.cose.2023.103482		SEP 2023	12	Computer Science, Information Systems	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	W7BZ8					2024-07-03	WOS:001093155500001
J	Wang, XN; Li, XT; Yin, Z; Wu, Y; Liu, J				Wang, Xuena; Li, Xueting; Yin, Zi; Wu, Yue; Liu, Jia			Emotional intelligence of Large Language Models	JOURNAL OF PACIFIC RIM PSYCHOLOGY			English	Article						emotional intelligence; emotional understanding; Large Language Models; generative pretrained transformer; human-likeness; psychometric assessment		Large Language Models (LLMs) have demonstrated remarkable abilities across numerous disciplines, primarily assessed through tasks in language generation, knowledge utilization, and complex reasoning. However, their alignment with human emotions and values, which is critical for real-world applications, has not been systematically evaluated. Here, we assessed LLMs' Emotional Intelligence (EI), encompassing emotion recognition, interpretation, and understanding, which is necessary for effective communication and social interactions. Specifically, we first developed a novel psychometric assessment focusing on Emotion Understanding (EU), a core component of EI. This test is an objective, performance-driven, and text-based evaluation, which requires evaluating complex emotions in realistic scenarios, providing a consistent assessment for both human and LLM capabilities. With a reference frame constructed from over 500 adults, we tested a variety of mainstream LLMs. Most achieved above-average Emotional Quotient (EQ) scores, with GPT-4 exceeding 89% of human participants with an EQ of 117. Interestingly, a multivariate pattern analysis revealed that some LLMs apparently did not rely on the human-like mechanism to achieve human-level performance, as their representational patterns were qualitatively distinct from humans. In addition, we discussed the impact of factors such as model size, training method, and architecture on LLMs' EQ. In summary, our study presents one of the first psychometric evaluations of the human-like characteristics of LLMs, which may shed light on the future development of LLMs aiming for both high intellectual and emotional intelligence. Project website: https://emotional-intelligence.github.io/	[Wang, Xuena; Yin, Zi; Wu, Yue; Liu, Jia] Tsinghua Univ, Dept Psychol, Beijing, Peoples R China; [Wang, Xuena; Yin, Zi; Wu, Yue; Liu, Jia] Tsinghua Univ, Tsinghua Lab Brain & Intelligence, Beijing, Peoples R China; [Li, Xueting] Renmin Univ China, Dept Psychol, Beijing, Peoples R China	Tsinghua University; Tsinghua University; Renmin University of China	Liu, J (corresponding author), Tsinghua Univ, Dept Psychol, Beijing, Peoples R China.; Liu, J (corresponding author), Tsinghua Univ, Tsinghua Lab Brain & Intelligence, Beijing, Peoples R China.	liujiaTHU@tsinghua.edu.cn			This study was funded by Shuimu Tsinghua Scholar Program (X. W.), Beijing Municipal Science amp; Technology Commission, Administrative Commission of Zhongguancun Science Park (Z221100002722012), and Tsinghua University Guoqiang Institute (2020GQG1016).; Shuimu Tsinghua Scholar Program [Z221100002722012, 2020GQG1016]; Beijing Municipal Science amp; Technology Commission, Administrative Commission of Zhongguancun Science Park	This study was funded by Shuimu Tsinghua Scholar Program (X. W.), Beijing Municipal Science amp; Technology Commission, Administrative Commission of Zhongguancun Science Park (Z221100002722012), and Tsinghua University Guoqiang Institute (2020GQG1016).; Shuimu Tsinghua Scholar Program; Beijing Municipal Science amp; Technology Commission, Administrative Commission of Zhongguancun Science Park	This study was funded by Shuimu Tsinghua Scholar Program (X. W.), Beijing Municipal Science & Technology Commission, Administrative Commission of Zhongguancun Science Park (Z221100002722012), and Tsinghua University Guoqiang Institute (2020GQG1016).	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Amin MM, 2023, Arxiv, DOI arXiv:2303.03186; Bai YT, 2022, Arxiv, DOI arXiv:2212.08073; Baron-Cohen S., 2020, The pattern seekers: How autism drives human invention; BARONCOHEN S, 1985, COGNITION, V21, P37, DOI 10.1016/0010-0277(85)90022-8; Brown T., 2020, P 34 INT C NEUR INF, V33, P1877; Bubeck S, 2023, Arxiv, DOI [arXiv:2303.12712, DOI 10.48550/ARXIV.2303.12712]; Chiang W.-L., 2023, Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality; Conover M., 2023, Free Dolly: Introducing the world's first truly open instructiontuned LLM; de Leeuw J. R., 2023, Journal of Open Source Software, V8, DOI DOI 10.21105/JOSS.05351; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Dulewicz V., 2000, J MANAGE PSYCHOL, V15, P341; Gao P, 2023, Arxiv, DOI arXiv:2304.15010; Hanafi Z., 2016, International Journal of Academic Research in Business and Social Sciences, V6, DOI [DOI 10.6007/IJARBSS/V6-I6/2197, 10.6007/IJARBSS/v6-i6/2197]; Hebenstreit K, 2023, Arxiv, DOI [arXiv:2305.02897, DOI 10.48550/ARXIV.2305.02897]; Hendrycks D, 2021, Arxiv, DOI [arXiv:2009.03300, 10.48550/arXiv.2009.03300]; Izard Veronique, 2009, Hum Evol, V23, P213; King M., 2023, PREPRINT, DOI [10.36227/techrxiv.22645561.v1, DOI 10.36227/TECHRXIV.22645561.V1]; Köpf A, 2023, Arxiv, DOI arXiv:2304.07327; Kosinski M, 2023, Arxiv, DOI [arXiv:2302.02083, 10.48550/arXiv.2302.02083, DOI 10.48550/ARXIV.2302.02083]; Lange K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130834; Lea RG, 2019, FRONT PSYCHOL, V10, DOI 10.3389/fpsyg.2019.00810; Legree P.J., 2005, EMOTIONAL INTELLIGEN, P155; Mayer J.D., 2001, Roeper Review: A Journal on Gifted Education, V23, P131, DOI DOI 10.1080/02783190109554084; MAYER JD, 1995, APPL PREV PSYCHOL, V4, P197, DOI 10.1016/S0962-1849(05)80058-7; Mayer JD, 2001, EMOTION, V1, P232, DOI 10.1037//1528-3542.1.3.232; Mayer JD, 2016, EMOT REV, V8, P290, DOI 10.1177/1754073916639667; Mayer JD, 2003, EMOTION, V3, P97, DOI 10.1037/1528-3542.3.1.97; McCleskey J, 2014, INT J ORGAN ANAL, V22, P76, DOI 10.1108/IJOA-03-2012-0568; Moghaddam SR, 2023, Arxiv, DOI [arXiv:2304.11490, DOI 10.48550/ARXIV.2304.11490]; Nair V, 2023, Arxiv, DOI [arXiv:2303.17071, DOI 10.48550/ARXIV.2303.17071]; Palmer BR, 2005, INTELLIGENCE, V33, P285, DOI 10.1016/j.intell.2004.11.003; Peng B, 2023, Arxiv, DOI arXiv:2305.13048; Salovey P., 1990, Imagination, cognition and personality, V9, P185, DOI [DOI 10.2190/DUGG-P24E-52WK-6CDG, 10.2190/DUGG-P24E-52WK-6CDG]; Sap M, 2023, Arxiv, DOI arXiv:2210.13312; Shinn N, 2023, Arxiv, DOI [arXiv:2303.11366, 10.48550/arXiv.2303.11366]; Sperber D, 2002, MIND LANG, V17, P3, DOI 10.1111/1468-0017.00186; Taori R., 2023, GitHub Repository; Taori R., Stanford Center for Research on Foundation Models, V3(6), P7; Tian X, 2020, CEREB CORTEX, V30, P2986, DOI 10.1093/cercor/bhz289; Touvron H., 2023, arXiv; Vaswani A, 2017, ADV NEUR IN, V30; Wallace Eric, 2023, Blog post April; Wang X., 2023, SwitchGPT: Adapting Large Language Models for Non-Text Outputs, DOI [10.48550/ARXIV.2309.07623, DOI 10.48550/ARXIV.2309.07623]; Warwick J, 2004, PERS INDIV DIFFER, V37, P1091, DOI 10.1016/j.paid.2003.12.003; Yang ZY, 2023, Arxiv, DOI arXiv:2309.17421; Zeng A., 2022, ARXIV; Zhao WX, 2023, ARXIV; Zheng LM, 2023, Arxiv, DOI arXiv:2306.05685; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	50	1	1	25	26	SAGE PUBLICATIONS LTD	LONDON	1 OLIVERS YARD, 55 CITY ROAD, LONDON EC1Y 1SP, ENGLAND	1834-4909			J PAC RIM PSYCHOL	J. Pac. Rim Psychol.		2023	17								18344909231213958	10.1177/18344909231213958	http://dx.doi.org/10.1177/18344909231213958			12	Psychology, Multidisciplinary	Social Science Citation Index (SSCI)	Psychology	Y2EX7		gold, Green Submitted			2024-07-03	WOS:001103462400001
J	Navigli, R; Conia, S; Ross, B				Navigli, Roberto; Conia, Simone; Ross, Bjorn			Biases in Large Language Models: Origins, Inventory, and Discussion	ACM JOURNAL OF DATA AND INFORMATION QUALITY			English	Article						Bias in NLP; language models	HEALTH	In this article, we introduce and discuss the pervasive issue of bias in the large language models that are currently at the core of mainstream approaches to Natural Language Processing (NLP). We first introduce data selection bias, that is, the bias caused by the choice of texts that make up a training corpus. Then, we survey the different types of social bias evidenced in the text generated by language models trained on such corpora, ranging from gender to age, from sexual orientation to ethnicity, and from religion to culture. We conclude with directions focused on measuring, reducing, and tackling the aforementioned types of bias.	[Navigli, Roberto; Conia, Simone] Sapienza Univ Rome, Via Ariosto 25, Rome, Italy; [Ross, Bjorn] Univ Edinburgh, 10 Crichton St, Edinburgh, Midlothian, Scotland	Sapienza University Rome; University of Edinburgh	Navigli, R (corresponding author), Sapienza Univ Rome, Via Ariosto 25, Rome, Italy.	navigli@diag.uniroma1.it; conia@di.uniroma1.it; b.ross@ed.ac.uk	Ross, Björn/AAT-6901-2020	Ross, Björn/0000-0003-2717-3705; Conia, Simone/0000-0002-6238-7816	ERC Consolidator [726487]; PNRR MUR project [PE0000013-FAIR]	ERC Consolidator(European Research Council (ERC)); PNRR MUR project	The first two authors gratefully acknowledge the support of the ERC Consolidator Grant MOUSSE No. 726487 under the European Union's Horizon 2020 research and innovation programme and the PNRR MUR project PE0000013-FAIR.; This work was further supported by an RSE Saltire Facilitation Network Award.	Abid A, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P298, DOI 10.1145/3461702.3462624; Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Ahn J, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P533; Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]; BADGETT MVL, 1995, IND LABOR RELAT REV, V48, P726, DOI 10.2307/2524353; Baeza-Yates R, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P1, DOI 10.1145/2908131.2908135; Barba E, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4661; Barba E, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2478; Barba E, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P1492; Barocas S., 2020, P 58 ANN M ASS COMPU, P5454, DOI DOI 10.18653/V1/2020.ACL-MAIN.485; Bartl M, 2020, P 2 WORKSH GEND BIAS, P1; Bencharit LZ, 2019, EMOTION, V19, P377, DOI 10.1037/emo0000444; Bender E. M., 2020, P 58 ANN M ASS COMP, P5185; Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Bevilacqua M, 2021, AAAI CONF ARTIF INTE, V35, P12564; Bevilacqua M, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P2854; Bevilacqua Michele, 2021, INT JOINT C ARTIFICI, P4330, DOI DOI 10.24963/IJCAI.2021/593; Blau FD, 2017, J ECON LIT, V55, P789, DOI 10.1257/jel.20160995; Blevins T, 2022, Arxiv, DOI arXiv:2204.08110; Blloshmi Rexhina, 2021, P 30 INT JOINT C ART, P3786, DOI DOI 10.24963/IJCAI.2021/521; Boyd D, 2012, INFORM COMMUN SOC, V15, P662, DOI 10.1080/1369118X.2012.678878; Burnage Gavin, 1992, P 13 INT C ENGLISH L; Byvshev P, 2022, COMPUT VIS IMAGE UND, V220, DOI 10.1016/j.cviu.2022.103437; Cain VS, 2003, AM J PUBLIC HEALTH, V93, P191, DOI 10.2105/AJPH.93.2.191; Campolungo N, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4331; Carreras X, 2005, Proceedings of the Ninth Conference on Computational Natural Language Learning, CoNLL 2005, Ann Arbor, Michigan, USA, June 29-30, 2005, P152; Cather DA, 2020, GENEVA PAP R I-ISS P, V45, P426, DOI 10.1057/s41288-020-00166-7; Chang Kai-Wei, 2019, P 2019 C EMPIRICALME; Charles K.K., 2018, The effects of sexism on American women: The role of norms vs. discrimination (No. w24904), DOI DOI 10.3386/W24904; Chiarain Neasa Ni, 2022, COMPUT 2022 5 WORK U, P109, DOI 10.18653/v1/2022.computel-1.14; Chowdhery A, 2022, Arxiv, DOI [arXiv:2204.02311, DOI 10.48550/ARXIV.2204.02311]; Conia S, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4622; Conia S, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P338; Conia S, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P3269; Conia Simone, 2022, FINDINGS ASS COMPUTA; Conneau Alexis., 2020, P 58 ANN M ASS COMP, P8440, DOI [DOI 10.18653/V1/2020.ACL-MAIN.747, 10.18653/v1/2020.acl-main.747]; Costa-juss`a Marta R., 2019, P 1 WORKSH GEND BIAS; Costa-jussa Marta, 2021, P 3 WORKSH GEND BIAS; Costa-jussa Marta R., 2020, P 2 WORKSH GEND BIAS; Czarnowska P, 2021, T ASSOC COMPUT LING, V9, P1249, DOI 10.1162/tacl_a_00425; Dastin Jeffrey, 2018, Reuters, DOI DOI 10.1017/CBO9781139025751; De Cao N, 2021, Arxiv, DOI arXiv:2109.03792; De Cao N, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6491; Dev S, 2020, AAAI CONF ARTIF INTE, V34, P7659; Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171; Díaz M, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173986; El-Kassas WS, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113679; Elenbaas L, 2019, DEV PSYCHOL, V55, P471, DOI 10.1037/dev0000550; Fabbri AR, 2021, T ASSOC COMPUT LING, V9, P391, DOI 10.1162/tacl_a_00373; Field A, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1905; Gao L, 2020, Arxiv, DOI [arXiv:2101.00027, 10.48550/arXiv.2101.00027]; Gao LY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P2843; Garg N, 2018, P NATL ACAD SCI USA, V115, pE3635, DOI 10.1073/pnas.1720347115; Ghumman S, 2013, J BUS PSYCHOL, V28, P439, DOI 10.1007/s10869-013-9290-0; Gildea D, 2002, COMPUT LINGUIST, V28, P245, DOI 10.1162/089120102760275983; Goldfarb-Tarrant S, 2021, 59TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 11TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1 (ACL-IJCNLP 2021), P1926; Goneni H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P609; Hajic Jan, 2009, Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, CoNLL 2009, Boulder, Colorado, USA, June 4, 2009, P1; Halevy A, 2009, IEEE INTELL SYST, V24, P8, DOI 10.1109/MIS.2009.36; Hardmeier Christian, 2022, P 4 WORKSH GEND BIAS; Herold B, 2022, NINTH WORKSHOP ON SPEECH AND LANGUAGE PROCESSING FOR ASSISTIVE TECHNOLOGIES (SLPAT-2022), P58; Hershcovich D, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P6997; Hovy D, 2021, LANG LINGUIST COMPAS, V15, DOI 10.1111/lnc3.12432; Hovy E, 2013, ARTIF INTELL, V194, P2, DOI 10.1016/j.artint.2012.10.002; Howard J, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P328; Huang Po-Sen, 2020, FIND ASS COMP LING E, VEMNLP; Hutchinson Ben, 2020, P 58 ANN M ASS COMP, P5491, DOI [DOI 10.18653/V1/2020.ACL-MAIN.487, 10.18653/v1/2020.acl-main.487]; Inwood K, 2020, SOC SCI HIST, V44, P411, DOI 10.1017/ssh.2020.18; Izsak P, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10644; Jacobs AZ, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P706, DOI 10.1145/3351095.3375671; Johnson SK, 2010, J SOC PSYCHOL, V150, P301, DOI 10.1080/00224540903365414; Joshi Pratik, 2020, P 58 ANN M ASS COMPU, P6282, DOI [10.18653/v1/2020. acl-main.560, DOI 10.18653/V1/2020.ACL-MAIN.560]; Kilgarriff A, 2003, COMPUT LINGUIST, V29, P333, DOI 10.1162/089120103322711569; Kirchner J., 2016, Machine bias: there's software used across the country to predict future criminals. And it's biased against blacks; Koehn P., 2005, P MT SUMM, V5, P79; Kreutzer J, 2022, Arxiv, DOI arXiv:2103.12028; Kruse A., 2016, UPDATE APPL RES MUSI, V35, P23, DOI [10.1177/87551233155, DOI 10.1177/87551233155]; Kurita K, 2019, GENDER BIAS IN NATURAL LANGUAGE PROCESSING (GEBNLP 2019), P166; Larson J., 2016, WE ANAL COMPAS RECID; Lewis M., 2020, P 58 ANN M ASS COMPU, P7871, DOI [10.18653/v1/2020.acl-main.703, DOI 10.18653/V1/2020.ACL-MAIN.703]; Lin BY, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P709; Liu FY, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P10467; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lorenzo ACM, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P1727; Lucy Li, 2021, P 3 WORKSHOP NARRATI, P48, DOI DOI 10.18653/V1/2021.NUSE-1.5; Macleod Catherine, 2000, P 2 INT C LANGUAGE R; Maru M, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P4724; May Jonathan, 2017, P 11 INT WORKSH SEM, P536; McGee P., 2018, TRAIN LANG CULT, V2, P40, DOI [DOI 10.29366/2018TLC.2.2.3, 10.29366/2018tlc.2.2.3]; Miller G, 1993, P WORKSH HUM LANG TE, P303; Mishra A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P1322; Moss H, 2021, DENVER LAW REV, V98, P775; Muralidhar D, 2021, AIES '21: PROCEEDINGS OF THE 2021 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P273, DOI 10.1145/3461702.3462469; Nadeem M., 2021, P 59 ANN M ASS COMP, V1, P5356, DOI DOI 10.18653/V1/2021.ACL-LONG.416; Nakano Reiichiro, 2021, CORR ABS211209332; Nangia N, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1953; Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001; Navigli R, 2009, ACM COMPUT SURV, V41, DOI 10.1145/1459352.1459355; Navigli Roberto, 2021, P 30 INT JOINT C ART, P4559; Neitz M., 2013, Cleveland State Law Review, V61, P137; Névéol A, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P8521; Nozza D, 2022, PROCEEDINGS OF THE SECOND WORKSHOP ON LANGUAGE TECHNOLOGY FOR EQUALITY, DIVERSITY AND INCLUSION (LTEDI 2022), P26; Obermeyer Z, 2019, SCIENCE, V366, P447, DOI 10.1126/science.aax2342; Paolini G., 2021, 9 INT C LEARNING REP; Pruksachatkun Yada, 2021, P 1 WORKSH TRUSTW NA; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Raffel C, 2020, J MACH LEARN RES, V21; Ruder S., 2021, Recent Advances in Language Model Fine-tuning; Ruder Sebastian., 2022, SCALING NLP SYSTEMS; Sevgili Ö, 2022, SEMANT WEB, V13, P527, DOI 10.3233/SW-222986; Steed R, 2021, Arxiv, DOI [arXiv:2002.05636, 10.1007/s43681-020-00035-y, DOI 10.1007/S43681-020-00035-Y]; Sun T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1630; Tavoletti E, 2022, INT BUS REV, V31, DOI 10.1016/j.ibusrev.2021.101969; Tedeschi Simone, 2023, P 61 ANN M ASS COMPU; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Tomalin M, 2021, ETHICS INF TECHNOL, V23, P419, DOI 10.1007/s10676-021-09583-1; Touvron Hugo, 2023, CORR ABS230213971; Ungless A., 2022, P 5 WORKSHOP NATURAL, P207; Vartan Starre., 2019, RACIAL BIAS FDN MAJO; Venkit Pranav Narayanan, 2023, ARXIV; Wang XY, 2022, PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022), VOL 1: (LONG PAPERS), P863; Wikipedia contributors, 2022, WIK; Wikipedia contributors, 2022, WHO WRIT WIK; Workshop B., 2023, arXiv, DOI 10.48550/arXiv.2211.05100; Wu Z, 2019, ETHNIC HEALTH, DOI 10.1080/13557858.2019.1620176; Xue LT, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P483; Yasunaga M, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P535; Yin WP, 2021, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-IJCNLP 2021, P4913; Yu PX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1029, DOI 10.1145/3442381.3449830; Zhang SS, 2022, Arxiv, DOI arXiv:2205.01068; Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11	132	14	14	17	32	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	1936-1955			ACM J DATA INF QUAL	ACM J. Data Inf. Qual.	JUN	2023	15	2							10	10.1145/3597307	http://dx.doi.org/10.1145/3597307			21	Computer Science, Information Systems	Emerging Sources Citation Index (ESCI)	Computer Science	L0RD5		Green Published, Green Accepted, Bronze			2024-07-03	WOS:001020404600001
J	Engin, CD; Karatas, E; Ozturk, T				Engin, Ceren Durmaz; Karatas, Ezgi; Ozturk, Taylan			Exploring the Role of ChatGPT-4, BingAI, and Gemini as Virtual Consultants to Educate Families about Retinopathy of Prematurity	CHILDREN-BASEL			English	Article						artificial intelligence; BingAI; ChatGPT; Gemini; large language models; retinopathy of prematurity	INFORMATION; QUALITY; INSTRUMENT; CARE	Background: Large language models (LLMs) are becoming increasingly important as they are being used more frequently for providing medical information. Our aim is to evaluate the effectiveness of electronic artificial intelligence (AI) large language models (LLMs), such as ChatGPT-4, BingAI, and Gemini in responding to patient inquiries about retinopathy of prematurity (ROP). Methods: The answers of LLMs for fifty real-life patient inquiries were assessed using a 5-point Likert scale by three ophthalmologists. The models' responses were also evaluated for reliability with the DISCERN instrument and the EQIP framework, and for readability using the Flesch Reading Ease (FRE), Flesch-Kincaid Grade Level (FKGL), and Coleman-Liau Index. Results: ChatGPT-4 outperformed BingAI and Gemini, scoring the highest with 5 points in 90% (45 out of 50) and achieving ratings of "agreed" or "strongly agreed" in 98% (49 out of 50) of responses. It led in accuracy and reliability with DISCERN and EQIP scores of 63 and 72.2, respectively. BingAI followed with scores of 53 and 61.1, while Gemini was noted for the best readability (FRE score of 39.1) but lower reliability scores. Statistically significant performance differences were observed particularly in the screening, diagnosis, and treatment categories. Conclusion: ChatGPT-4 excelled in providing detailed and reliable responses to ROP-related queries, although its texts were more complex. All models delivered generally accurate information as per DISCERN and EQIP assessments.	[Engin, Ceren Durmaz] Izmir Democracy Univ, Buca Seyfi Demirsoy Educ & Res Hosp, Dept Ophthalmol, TR-35390 Izmir, Turkiye; [Engin, Ceren Durmaz] Dokuz Eylul Univ, Fac Engn, Dept Biomed Technol, TR-35390 Izmir, Turkiye; [Karatas, Ezgi] Agri Ibrahim Cecen Univ, Dept Ophthalmol, TR-04200 Agri, Turkiye; [Ozturk, Taylan] Izmir Tinaztepe Univ, Dept Ophthalmol, TR-35400 Izmir, Turkiye	Izmir Democracy University; Dokuz Eylul University; Agri Ibrahim Cecen University; Izmir Tinaztepe University	Engin, CD (corresponding author), Izmir Democracy Univ, Buca Seyfi Demirsoy Educ & Res Hosp, Dept Ophthalmol, TR-35390 Izmir, Turkiye.; Engin, CD (corresponding author), Dokuz Eylul Univ, Fac Engn, Dept Biomed Technol, TR-35390 Izmir, Turkiye.	cerendurmaz@gmail.com; e.karatas.2015@gmail.com; ataylan6@yahoo.com						Adamopoulou E., 2020, IFIP INT C ART INT A, P373, DOI [DOI 10.1007/978-3-030-49186-4_31, 10.1007/978-3-030-49186-4_31]; Alan R, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.46213; [Anonymous], Individuals Using the Internet for Seeking Health-Related Information; Becky McCall, GastroGPT Outperforms General Models in GI Clinical Tasks; Bianco A, 2013, J MED INTERNET RES, V15, P268, DOI 10.2196/jmir.2752; Briganti G, 2023, EUR ARCH OTO-RHINO-L, DOI 10.1007/s00405-023-08337-7; Charnock D, 1999, J EPIDEMIOL COMMUN H, V53, P105, DOI 10.1136/jech.53.2.105; Cohen SA, 2024, SEMIN OPHTHALMOL, DOI 10.1080/08820538.2024.2326058; Coskun BN, 2024, RHEUMATOL INT, V44, P509, DOI 10.1007/s00296-023-05473-5; Daungsupawong H, 2024, J PEDIAT OPHTH STRAB, V61, P151, DOI 10.3928/01913913-20240124-01; Delsoz M, 2023, OPHTHALMOL THER, V12, P3121, DOI 10.1007/s40123-023-00805-x; Eid K, 2024, OPHTHAL PLAST RECONS, V40, P212, DOI 10.1097/IOP.0000000000002549; Erden Y, 2024, ARCH OSTEOPOROS, V19, DOI 10.1007/s11657-024-01376-5; Ghanem YK, 2024, SURG ENDOSC, V38, P2887, DOI 10.1007/s00464-024-10739-5; Hellström A, 2013, LANCET, V382, P1445, DOI 10.1016/S0140-6736(13)60178-6; Kim MJ, 2023, DIGIT HEALTH, V9, DOI 10.1177/20552076231154377; Kubb C, 2020, J MED INTERNET RES, V22, DOI 10.2196/19985; Lee Yung, 2024, Surg Obes Relat Dis, V20, P603, DOI 10.1016/j.soard.2024.03.011; Lim ZW, 2023, EBIOMEDICINE, V95, DOI 10.1016/j.ebiom.2023.104770; Makrygiannakis MA, 2024, EUR J ORTHODONT, DOI 10.1093/ejo/cjae017; microsoft, Microsoft How Bing Delivers Search Results; Moult B, 2004, HEALTH EXPECT, V7, P165, DOI 10.1111/j.1369-7625.2004.00273.x; Nov O, 2023, JMIR MED EDUC, V9, DOI 10.2196/46939; Omiye JA, 2024, ANN INTERN MED, V177, DOI 10.7326/M23-2772; Potapenko I, 2023, ACTA OPHTHALMOL, V101, P829, DOI 10.1111/aos.15661; research, Google Med-PaLM: A Large Language Model from Google Research, Designed for the Medical Domain; Salazar GZ, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.45473; Sallam M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11060887; Seth I, 2023, AESTHET SURG J OPEN, V5, DOI 10.1093/asjof/ojad084; Sindal MD, 2021, INDIAN J OPHTHALMOL, V69, P2141, DOI 10.4103/ijo.IJO_763_21; Singhal K, 2023, NATURE, V620, P172, DOI 10.1038/s41586-023-06291-2; Siu A.H.Y., 2023, J. Med. Educ, V22, pe137753, DOI [10.5812/jme-137753, DOI 10.5812/JME-137753]; Sundar Pincai D.H., Introducing Gemini: Our Largest and Most Capable AI Model; Tailor Prashant D, 2024, J Neuroophthalmol, DOI 10.1097/WNO.0000000000002145; Vought R, 2023, SEMIN OPHTHALMOL, V38, P768, DOI 10.1080/08820538.2023.2209168; Xie WH, 2021, PSYCHOL HEALTH MED, V26, P1091, DOI 10.1080/13548506.2020.1797129	36	0	0	0	0	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2227-9067		CHILDREN-BASEL	Children-Basel	JUN	2024	11	6							750	10.3390/children11060750	http://dx.doi.org/10.3390/children11060750			11	Pediatrics	Science Citation Index Expanded (SCI-EXPANDED)	Pediatrics	WJ3N6	38929329	gold			2024-07-03	WOS:001254465300001
J	Hackenburg, K; Margetts, H				Hackenburg, Kobi; Margetts, Helen			Evaluating the persuasive influence of political microtargeting with large language models	PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA			English	Article						microtargeting; large language models; political persuasion; AI safety; AI- mediated communication		Recent advancements in large language models (LLMs) have raised the prospect of scalable, automated, and fine- grained political microtargeting on a scale previously unseen; however, the persuasive influence of microtargeting with LLMs remains unclear. Here, we build a custom web application capable of integrating self- reported demographic and political data into GPT- 4 prompts in real- time, facilitating the live creation of unique messages tailored to persuade individual users on four political issues. We then deploy this application in a preregistered randomized control experiment (n = 8,587) to investigate the extent to which access to individual- level data increases the persuasive influence of GPT- 4. Our approach yields two key findings. First, messages generated by GPT- 4 were broadly persuasive, in some cases increasing support for an issue stance by up to 12 percentage points. Second, in aggregate, the persuasive impact of microtargeted messages was not statistically different from that of non- microtargeted messages (4.83 vs. 6.20 percentage points, respectively, P = 0.226). These trends hold even when manipulating the type and number of attributes used to tailor the message. These findings suggest- contrary to widespread speculation-that the influence of current LLMs may reside not in their ability to tailor messages to individuals but rather in the persuasiveness of their generic, nontargeted messages. We release our experimental dataset, GPTarget2024, as an empirical baseline for future research.	[Hackenburg, Kobi; Margetts, Helen] Univ Oxford, Oxford Internet Inst, Oxford OX1 2JD, England	University of Oxford	Hackenburg, K (corresponding author), Univ Oxford, Oxford Internet Inst, Oxford OX1 2JD, England.	kobi.hackenburg@oii.ox.ac.uk		Hackenburg, Kobi/0000-0003-2071-1726				Aagaard P, 2023, INTERNET POLICY REV, V12, P1, DOI 10.14763/2023.1.1690; Ali M, 2021, WSDM '21: PROCEEDINGS OF THE 14TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P13, DOI 10.1145/3437963.3441801; [Anonymous], 2018, BBC NEWS; Argyle LP, 2023, POLIT ANAL, V31, P337, DOI 10.1017/pan.2023.2; Bai H., 2023, Artificial Intelligence Can Persuade Humans on Political Issues, DOI [DOI 10.31219/OSF.IO/STAKV, 10.31219/OSF.IO/STAKV]; Barr A., 2023, Business Insider14 July; Buchanan B., 2021, Truth, Lies, and Automation: How Language Models Could Change Disinformation, DOI DOI 10.51593/2021CA003; Chen LJ, 2023, Arxiv, DOI [arXiv:2307.09009, 10.48550/arXiv.2307.09009, DOI 10.48550/ARXIV.2307.09009.CROSSREF, DOI 10.48550/ARXIV.2307.09009]; Coppock A, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abc4046; Coppock A, 2018, Q J POLIT SCI, V13, P59, DOI 10.1561/100.00016112; Coppock Alexander., 2022, Persuasion in Parallel: How Information Changes Minds about Politics; Endres K, 2020, AM POLIT RES, V48, P317, DOI 10.1177/1532673X19875694; Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068; Goldstein J., 2023, Foreign Affairs; Goldstein J. A., 2023, arXiv, DOI [10.48550/arXiv.2301.04246, DOI 10.48550/ARXIV.2301.04246]; Goldstein JA, 2024, PNAS NEXUS, V3, DOI 10.1093/pnasnexus/pgae034; Grace K, 2024, Arxiv, DOI [arXiv:2401.02843, DOI 10.48550/ARXIV.2401.02843]; Hackenburg K., GPTarget2024; Hackenburg K., 2023, PREPRINT, DOI [10.31219/osf.io/ey8db, DOI 10.31219/OSF.IO/EY8DB]; Harrison Dupre M, 2023, Futurism; Hersh ED, 2013, J POLIT, V75, P520, DOI 10.1017/S0022381613000182; Jakesch M, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2208839120; Jiang H., 2022, P 29 INT C COMPUTATI, P6818; Karinshak E., 2023, Proc. ACM Hum. Comput. Interact, V7; Kirk H. R., 2024, Nat. Mach. Intell, P1, DOI [10.1038/s42256-024-00820-y, DOI 10.1038/S42256-024-00820-Y]; Koto F, 2022, PROCEEDINGS OF THE 5TH WORKSHOP ON E-COMMERCE AND NLP (ECNLP 5), P234; Kreps S, 2022, J EXP POLIT SCI, V9, P104, DOI 10.1017/XPS.2020.37; Matz SC, 2017, P NATL ACAD SCI USA, V114, P12714, DOI 10.1073/pnas.1710966114; McCarthy J., 2020, Gallup2 March; Morrison S, 2020, Why are you seeing this digital political ad?; Open Rights Group, 2020, Public are kept in the dark over data driven political campaigning, poll finds; Santurkar S., 2023, P 40 INT C MACH LEAR; Scott M., 2018, POLITICO27 March; Simmons G, 2023, PROCEEDINGS OF THE 61ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, ACL-SRW 2023, VOL 4, P282; Singer N., 2018, NY Times16 August; Spitale G, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adh1850; Tappin B, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2216261120; Tiwari A, 2022, P 2 C AS PAC CHAPT A, V1, P1035; Turow Joseph., 2012, Americans Roundly Reject Tailored Political Advertising at a time when political campaigns are embracing it; Wang XW, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5635; Weidinger L, 2022, ACM C FAIRN ACC TRAN, V22; Wong J. C., 2018, The Guardian; Zarouali B, 2022, COMMUN RES, V49, P1066, DOI 10.1177/0093650220961965; Zuiderveen Borgesius F. J, 2018, Online Political Microtargeting: Promises and Threats for Democracy	44	0	0	0	0	NATL ACAD SCIENCES	WASHINGTON	2101 CONSTITUTION AVE NW, WASHINGTON, DC 20418 USA	0027-8424	1091-6490		P NATL ACAD SCI USA	Proc. Natl. Acad. Sci. U. S. A.	JUN 11	2024	121	24							e2403116121	10.1073/pnas.2403116121	http://dx.doi.org/10.1073/pnas.2403116121			8	Multidisciplinary Sciences	Science Citation Index Expanded (SCI-EXPANDED)	Science & Technology - Other Topics	UL7F3	38848300	Green Accepted, Green Submitted, hybrid			2024-07-03	WOS:001248272500003
C	Jesse, K; Ahmed, T; Devanbu, PT; Morgan, E			IEEE	Jesse, Kevin; Ahmed, Toufique; Devanbu, Premkumar T.; Morgan, Emily			Large Language Models and Simple, Stupid Bugs	2023 IEEE/ACM 20TH INTERNATIONAL CONFERENCE ON MINING SOFTWARE REPOSITORIES, MSR	IEEE International Working Conference on Mining Software Repositories		English	Proceedings Paper	IEEE/ACM 20th International Conference on Mining Software Repositories (MSR)	MAY 15-16, 2023	Melbourne, AUSTRALIA	IEEE, Assoc Comp Machinery, IEEE Comp Soc, IEEE Tech Council Software Engn, ACM Special Interest Grp Software Engn, GitHub, Huawei Canada		language models; prompting; deep learning; software engineering		With the advent of powerful neural language models, AI-based systems to assist developers in coding tasks are becoming widely available; Copilot is one such system. Copilot uses Codex, a large language model (LLM), to complete code conditioned on a preceding "prompt". Codex, however, is trained on public GitHub repositories, viz., on code that may include bugs and vulnerabilities. Previous studies [1], [2] show Codex reproduces vulnerabilities seen in training. In this study, we examine how prone Codex is to generate an interesting bug category, single statement bugs, commonly referred to as simple, stupid bugs or SStuBs in the MSR community. We find that Codex and similar LLMs do help avoid some SStuBs, but do produce known, verbatim SStuBs as much as 2x as likely than known, verbatim correct code. We explore the consequences of the Codex generated SStuBs and propose avoidance strategies that suggest the possibility of reducing the production of known, verbatim SStubs, and increase the possibility of producing known, verbatim fixes.	[Jesse, Kevin; Ahmed, Toufique; Devanbu, Premkumar T.; Morgan, Emily] Univ Calif Davis, Davis, CA 95616 USA	University of California System; University of California Davis	Jesse, K (corresponding author), Univ Calif Davis, Davis, CA 95616 USA.	krjesse@ucdavis.edu; tfahmed@ucdavis.edu; ptdevanbu@ucdavis.edu; eimorgan@ucdavis.edu			National Science Foundation under Grant NSF CCF (SHF-MEDIUM) [2107592]	National Science Foundation under Grant NSF CCF (SHF-MEDIUM)	This material is based upon work supported by the National Science Foundation under Grant NSF CCF (SHF-MEDIUM) No. 2107592. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.	Ahmad WU, 2021, Arxiv, DOI [arXiv:2103.06333, 10.48550/arXiv.2103.06333]; Ahmed T, 2023, Arxiv, DOI arXiv:2301.03797; Ahmed T, 2022, IEEE INT CONF AUTOM, DOI 10.1145/3551349.3559555; Allamams M, 2019, PROCEEDINGS OF THE 2019 ACM SIGPLAN INTERNATIONAL SYMPOSIUM ON NEW IDEAS, NEW PARADIGMS, AND REFLECTIONS ON PROGRAMMING AND SOFTWARE (ONWARD!' 19), P143, DOI 10.1145/3359591.3359735; Asare O, 2024, Arxiv, DOI arXiv:2204.04741; Austin Jacob, 2021, arXiv, DOI DOI 10.48550/ARXIV.2108.07732; Chen M., 2021, arXiv; Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179; Drori I, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2123433119; Elnaggar A., 2021, arXiv; Feng ZY, 2020, Arxiv, DOI [arXiv:2002.08155, DOI 10.48550/ARXIV.2002.08155, 10.48550/arXiv.2002.08155]; Fowler M., 2018, Refactoring: improving the design of existing code; Fried D, 2023, Arxiv, DOI arXiv:2204.05999; Guo DY, 2021, Arxiv, DOI arXiv:2009.08366; Hartzman C. S., 1993, Proceedings CASCON '93, P138; Hellendoorn VJ, 2022, COMMUN ACM, V65, P31, DOI 10.1145/3501261; Hindle A, 2016, COMMUN ACM, V59, P122, DOI 10.1145/2902362; Hu X, 2018, INT C PROGRAM COMPRE, P200, DOI 10.1145/3196321.3196334; Hua JY, 2021, IEEE WORK CONF MIN S, P530, DOI 10.1109/MSR52588.2021.00068; Huang Y, 2020, IEEE T RELIAB, V69, P88, DOI 10.1109/TR.2019.2931725; Jain N, 2022, PROC INT CONF SOFTW, P1219, DOI 10.1145/3510003.3510203; Kamienski AV, 2021, IEEE WORK CONF MIN S, P520, DOI 10.1109/MSR52588.2021.00066; Kanade A, 2020, PR MACH LEARN RES, V119; Karampatsis RM, 2020, IEEE WORK CONF MIN S, P573, DOI 10.1145/3379597.3387491; Karmakar A., 2022, arXiv; Kojima T, 2022, Arxiv, DOI [arXiv:2205.11916, 10.48550/arXiv.2205.11916]; Lachaux MA, 2020, Arxiv, DOI arXiv:2006.03511; Latendresse J, 2021, IEEE WORK CONF MIN S, P500, DOI 10.1109/MSR52588.2021.00062; LIENTZ BP, 1983, COMPUT SURV, V15, P271, DOI 10.1145/356914.356919; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Madeiral F, 2021, IEEE WORK CONF MIN S, P510, DOI 10.1109/MSR52588.2021.00064; Mashhadi E, 2021, IEEE WORK CONF MIN S, P505, DOI 10.1109/MSR52588.2021.00063; Mosolygó B, 2021, IEEE WORK CONF MIN S, P495, DOI 10.1109/MSR52588.2021.00061; Nguyen N, 2022, IEEE WORK CONF MIN S, P1, DOI 10.1145/3524842.3528470; Nijkamp E, 2022, Arxiv, DOI arXiv:2203.13474; Pearce H., 2022, 2023 IEEE Symposium on Security and Privacy (SP), P1; Pearce H, 2022, P IEEE S SECUR PRIV, P754, DOI 10.1109/SP46214.2022.00057; Pearce H, 2022, Arxiv, DOI [arXiv:2112.02125, DOI 10.48550/ARXIV.2112.02125]; Perry N, 2023, Arxiv, DOI [arXiv:2211.03622, DOI 10.48550/ARXIV.2211.03622, 10.48550/arxiv.2211.03622]; Peruma A, 2021, IEEE WORK CONF MIN S, P525, DOI 10.1109/MSR52588.2021.00067; Petroni F., 2020, arXiv; Prenner JA, 2021, Arxiv, DOI [arXiv:2111.03922, DOI 10.48550/ARXIV.2111.03922]; Rajkumar N., arXiv, DOI DOI 10.48550/ARXIV.2204.00498; Richter C, 2022, Arxiv, DOI arXiv:2201.12046; Roy Chanchal Kumar, 2007, Queen's School of Computing TR, V541, P64; Sandoval G, 2022, Arxiv, DOI arXiv:2208.09727; Sarkar A, 2022, Arxiv, DOI arXiv:2208.06213; Sobania D, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'22), P1019, DOI 10.1145/3512290.3528700; Tang LA, 2021, Arxiv, DOI arXiv:2111.08267; TENNY T, 1988, IEEE T SOFTWARE ENG, V14, P1271, DOI 10.1109/32.6171; Trummer I, 2022, Arxiv, DOI arXiv:2204.08941; Tunstall L., 2022, Natural Language Processing with Transformers; Vaithilingam P, 2022, EXTENDED ABSTRACTS OF THE 2022 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2022, DOI 10.1145/3491101.3519665; Wang Chaozheng, 2022, ESEC/FSE 2022: Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, P382, DOI 10.1145/3540250.3549113; Wang Y, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P8696; Wei JS, 2022, Arxiv, DOI [arXiv:2201.11903, 10.48550/arXiv.2201.11903]; Wen FC, 2019, INT C PROGRAM COMPRE, P53, DOI 10.1109/ICPC.2019.00019; Woodfield S. N., 1981, 5th International Conference on Software Engineering, P215; Xu Frank F., 2022, MAPS 2022: Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming, P1, DOI 10.1145/3520312.3534862; Yetistiren B, 2022, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON PREDICTIVE MODELS AND DATA ANALYTICS IN SOFTWARE ENGINEERING, PROMISE 2022, P62, DOI 10.1145/3558489.3559072; Zhu WH, 2021, IEEE WORK CONF MIN S, P515, DOI 10.1109/MSR52588.2021.00065; Ziegler A., US; US	63	1	1	6	13	IEEE COMPUTER SOC	LOS ALAMITOS	10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA	2160-1852		979-8-3503-1184-6	IEEE WORK CONF MIN S			2023							563	575		10.1109/MSR59073.2023.00082	http://dx.doi.org/10.1109/MSR59073.2023.00082			13	Computer Science, Software Engineering; Computer Science, Theory & Methods	Conference Proceedings Citation Index - Science (CPCI-S)	Computer Science	BV4JN		Green Submitted			2024-07-03	WOS:001032697200068
J	Rodman, E				Rodman, Emma			On Political Theory and Large Language Models	POLITICAL THEORY			English	Article; Early Access						methodology in political theory; creativity; judgment; computational linguistics; text-as-data	SOCIAL MEDIA; THOUGHT	Political theory as a discipline has long been skeptical of computational methods. In this paper, I argue that it is time for theory to make a perspectival shift on these methods. Specifically, we should consider integrating recently developed generative large language models like GPT-4 as tools to support our creative work as theorists. Ultimately, I suggest that political theorists should embrace this technology as a method of supporting our capacity for creativity-but that we should do so in a way that is mindful of the content and value of theorizing, the technical constraints of the models, and the ethical questions that the technology raises.	[Rodman, Emma] Univ Massachusetts Lowell, Dept Polit Sci, Lowell, MA USA; [Rodman, Emma] Univ Massachusetts Lowell, Dept Polit Sci, Dugan Hall,Suite 201,883 Broadway St, Lowell, MA 01854 USA	University of Massachusetts System; University of Massachusetts Lowell; University of Massachusetts System; University of Massachusetts Lowell	Rodman, E (corresponding author), Univ Massachusetts Lowell, Dept Polit Sci, Dugan Hall,Suite 201,883 Broadway St, Lowell, MA 01854 USA.	emma_rodman@uml.edu			The paper was greatly improved by comments and suggestions from the editors and reviewers at <italic>Political Theory</italic>, as well as from audience members at the Western Political Science Association conference and the Politics and Computational Soci	The paper was greatly improved by comments and suggestions from the editors and reviewers at <italic>Political Theory</italic>, as well as from audience members at the Western Political Science Association conference and the Politics and Computational Soci	The paper was greatly improved by comments and suggestions from the editors and reviewers at <ITALIC>Political Theory</ITALIC>, as well as from audience members at the Western Political Science Association conference and the Politics and Computational Social Science conference. Tom Arnold-Forster, Anna Daily, Lisa Gilson, E. Stephen Kehlenbach, Greg Koutnik, Alison McQueen, Christopher Rytting, Noah Stengl, Liz Taylor, Seth Trenchard, Jack Turner, and John Wilkerson also gave helpful suggestions and encouragement. I am especially grateful for the close attention Phil Yaure gave to the manuscript in its early stages and for the rare confluence of theorists and methodologists who came together to workshop a later draft at the University of Wisconsin - Madison. AI Disclosure: GPT-3 was used to produce examples in this work, as noted, as well as to brainstorm ideas, poems, and motivational speeches throughout the writing process. No language presented as my own in the final version was generated by AI.	Amoore Louise, 2020, Cloud ethics: algorithms and the attributes of ourselves and others; [Anonymous], 1950, Mind, DOI DOI 10.1093/MIND/LIX.236.433; Arendt Hannah., 1982, LECT KANTS POLITICAL; Bagg S, 2018, EUR J POLIT THEORY, V17, P257, DOI 10.1177/1474885115610542; Bender Emily M., 2021, FACCT 21 P 2021 ACM; Benjamin R., 2019, RACE TECHNOLOGY ABOL, DOI DOI 10.1145/3290605.3300528; Berlin Isaiah., 2014, Concepts and Categories, V2nd ed.; Blau A, 2015, HIST EUR IDEA, V41, P1178, DOI 10.1080/01916599.2015.1082768; Blaydes L, 2018, J POLIT, V80, P1150, DOI 10.1086/699246; Boden Margaret A., 2014, The Philosophy of Creativity: New Essays New York; Boden Margaret A., 2004, The creative mind: Myths and mechanisms, DOI DOI 10.4324/9780203508527; Brown W, 2002, POLIT THEORY, V30, P556, DOI 10.1177/0090591702030004006; Churchland Paul., 1995, ENGINE REASON SEAT S; Cropley A.J., 2011, ENCY CREATIVITY, V2nd, P358; Dienstag JF, 2016, PERSPECT POLIT, V14, P1083, DOI 10.1017/S1537592716003054; Fraser Nancy., 2009, SCALES JUSTICE REIMA; Fuchs C, 2017, EUR J COMMUN, V32, P37, DOI 10.1177/0267323116682804; Gardiner ME, 2022, CONSTELLATIONS, V29, P131, DOI 10.1111/1467-8675.12528; Grimmer J., 2022, TEXT DATA NEW FRAMEW; Grimmer J, 2013, POLIT ANAL, V21, P267, DOI 10.1093/pan/mps028; GUNNELL JG, 1988, AM POLIT SCI REV, V82, P71, DOI 10.2307/1958059; Guo Wei, 2020, arXiv; Henderson P, 2020, J MACH LEARN RES, V21; Jennifer Nedelsky., 2001, Judgment, Imagination, and Politics: Themes from Kant and Arendt; Jo ES, 2020, FAT* '20: PROCEEDINGS OF THE 2020 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P306, DOI 10.1145/3351095.3372829; Joekers ML, 2013, POETICS, V41, P750, DOI 10.1016/j.poetic.2013.08.005; Kant I., 2001, Critique of the Power of Judgment, DOI DOI 10.1017/CBO9780511804656; Kaufman-Osborn TV, 2010, POLIT RES QUART, V63, P655, DOI 10.1177/1065912910367495; Kehlenbach Stefan., 2022, Theory Event, V25; Koopman C, 2022, POLIT THEORY, V50, P337, DOI 10.1177/00905917211027835; Kozlowski AC, 2019, AM SOCIOL REV, V84, P905, DOI 10.1177/0003122419877135; March Andrew., 2009, The Review of Politics, V71; McWilliams Susan., 2015, The Good Society, V24; Moretti Franco., 2013, Distant Reading; Mosteller Frederick., 1964, Inference and disputed authorship: The Federalist; Neocleous Andreas., 2020, IEEE Access, V9; Nguyen D, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.00062; Panagia D, 2021, POLIT THEORY, V49, P109, DOI 10.1177/0090591720959853; Paul ElliotSamuel., 2014, PHILOS CREATIVITY NE; Rehfeld A, 2010, PERSPECT POLIT, V8, P465, DOI 10.1017/S1537592710001209; Reynolds Noel., 1995, Three Discourses: A Critical Modern Edition of Newly Identified Work of the Young Hobbes; Rodman E, 2020, POLIT ANAL, V28, P87, DOI 10.1017/pan.2019.23; Runco M., 2016, Creativity Theories-Research-Applications, V3, P4, DOI [10.1515/ctra-2016-0001, DOI 10.1515/CTRA-2016-0001]; Runco M. A., 2014, CREATIVITY THEORIES; Schwartz HA, 2015, ANN AM ACAD POLIT SS, V659, P78, DOI 10.1177/0002716215569197; Sikes P.J., 2008, Researching education from the inside: Investigations from within, P3; Skees M, 2022, CONSTELLATIONS, V29, P146, DOI 10.1111/1467-8675.12541; Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645; Turner J, 2023, AM POLIT SCI REV, V117, P705, DOI 10.1017/S0003055422000727; Whelan FrederickG., 1983, Nomos, V25, P13; WOLIN SS, 1969, AM POLIT SCI REV, V63, P1062, DOI 10.2307/1955072; Zerilli LindaM. G., 2016, DEMOCRATIC THEORY JU; Zerilli LMG, 2005, POLIT THEORY, V33, P158, DOI 10.1177/0090591704272958	53	3	3	7	11	SAGE PUBLICATIONS INC	THOUSAND OAKS	2455 TELLER RD, THOUSAND OAKS, CA 91320 USA	0090-5917	1552-7476		POLIT THEORY	Polit. Theory	2023 OCT 17	2023										10.1177/00905917231200826	http://dx.doi.org/10.1177/00905917231200826		OCT 2023	33	Political Science	Social Science Citation Index (SSCI)	Government & Law	U8CP1		Green Published, hybrid			2024-07-03	WOS:001087029700001
J	Chen, Z; Cao, L; Madden, S				Chen, Zui; Cao, Lei; Madden, Sam			LINGUA MANGA : A Generic Large Language Model Centric System for Data Curation	PROCEEDINGS OF THE VLDB ENDOWMENT			English	Article								Data curation is a wide-ranging area which contains many critical but time-consuming data processing tasks. However, the diversity of such tasks makes it challenging to develop a general-purpose data curation system. To address this issue, we present LINGUA MANGA, a user-friendly and versatile system that utilizes pre-trained large language models. LINGUA MANGA offers automatic optimization for achieving high performance and label efficiency while facilitating flexible and rapid development. Through three example applications with distinct objectives and users of varying levels of technical proficiency, we demonstrate that LINGUA MANGA can effectively assist both skilled programmers and low-code or even no-code users in addressing data curation challenges.	[Chen, Zui] Tsinghua Univ, IIIS, Beijing, Peoples R China; [Cao, Lei] U Arizona, MIT, Tucson, AZ USA; [Madden, Sam] MIT, Cambridge, MA USA	Tsinghua University; Massachusetts Institute of Technology (MIT)	Chen, Z (corresponding author), Tsinghua Univ, IIIS, Beijing, Peoples R China.	chenzui19@mails.tsinghua.edu.cn; lcao@csail.mit.edu; madden@csail.mit.edu						Akin Fatih Kadir, 2023, Awesome ChatGPT Prompts; [Anonymous], 2011, CrowdDB: answering queries with crowdsourcing; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen M., 2021, ARXIV; Demartini G., 2012, WWW; Freitas Andre, 2016, Big data curation; Izacard Gautier, 2021, ICLR; Li YL, 2020, PROC VLDB ENDOW, V14, P50, DOI 10.14778/3421424.3421431; Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815; Mei YA, 2021, PROC INT CONF DATA, P61, DOI 10.1109/ICDE51399.2021.00013; Narayan Avanika, 2022, VLDB; OpenAI, 2023, CHATGPT; Rekatsinas T, 2017, PROC VLDB ENDOW, V10, P1190; Schick T, 2021, 16TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2021), P255; Schick Timo, 2023, Toolformer: Language models can teach themselves to use tools; STONEBRAKER M, 2013, CIDR; Touvron H., 2023, Llama: Open and efficient foundation language models; Yarowsky D., 1995, 33 ANN M ASS COMPUTA, P189, DOI 10.3115/981658.981684; Zhu Yanqiao, 2022, A Survey on Pretrained Language Models for Neural Code Intelligence	19	0	0	2	4	ASSOC COMPUTING MACHINERY	NEW YORK	1601 Broadway, 10th Floor, NEW YORK, NY USA	2150-8097			PROC VLDB ENDOW	Proc. VLDB Endow.	AUG	2023	16	12					4074	4077		10.14778/3611540.3611624	http://dx.doi.org/10.14778/3611540.3611624			4	Computer Science, Information Systems; Computer Science, Theory & Methods	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	R9TK6		Green Submitted			2024-07-03	WOS:001067701000085
J	Guo, Y; Qiu, W; Leroy, G; Wang, S; Cohen, T				Guo, Yue; Qiu, Wei; Leroy, Gondy; Wang, Sheng; Cohen, Trevor			Retrieval augmentation of large language models for lay language generation	JOURNAL OF BIOMEDICAL INFORMATICS			English	Article						Large language models; Retrieval-augmented model; Lay language summary; Background explanation; Text generation	TEXT; KNOWLEDGE; SYSTEM	The complex linguistic structures and specialized terminology of expert-authored content limit the accessibility of biomedical literature to the general public. Automated methods have the potential to render this literature more interpretable to readers with different educational backgrounds. Prior work has framed such lay language generation as a summarization or simplification task. However, adapting biomedical text for the lay public includes the additional and distinct task of background explanation: adding external content in the form of definitions, motivation, or examples to enhance comprehensibility. This task is especially challenging because the source document may not include the required background knowledge. Furthermore, background explanation capabilities have yet to be formally evaluated, and little is known about how best to enhance them. To address this problem, we introduce Retrieval-Augmented Lay Language (RALL) generation, which intuitively fits the need for external knowledge beyond that in expert-authored source documents. In addition, we introduce CELLS, the largest (63k pairs) and broadest-ranging (12 journals) parallel corpus for lay language generation. To evaluate RALL, we augmented state-of-the-art text generation models with information retrieval of either term definitions from the UMLS and Wikipedia, or embeddings of explanations from Wikipedia documents. Of these, embedding-based RALL models improved summary quality and simplicity while maintaining factual correctness, suggesting that Wikipedia is a helpful source for background explanation in this context. We also evaluated the ability of both an open-source Large Language Model (Llama 2) and a closed-source Large Language Model (GPT-4) in background explanation, with and without retrieval augmentation. Results indicate that these LLMs can generate simplified content, but that the summary quality is not ideal. Taken together, this work presents the first comprehensive study of background explanation for lay language generation, paving the path for disseminating scientific knowledge to a broader audience. Our code and data are publicly available at: https://github.com/LinguisticAnomalies/pls_retrieval.	[Guo, Yue; Cohen, Trevor] Univ Washington, Biomed & Hlth Informat, Seattle, WA 98195 USA; [Qiu, Wei; Wang, Sheng] Univ Washington, Paul G Allen Sch Comp Sci, Seattle, WA USA; [Leroy, Gondy] Univ Arizona, Management Informat Syst, Tucson, AZ USA	University of Washington; University of Washington Seattle; University of Washington; University of Washington Seattle; University of Arizona	Guo, Y (corresponding author), Univ Washington, Biomed & Hlth Informat, Seattle, WA 98195 USA.	yguo50@uw.edu		Cohen, Trevor/0000-0003-0159-6697; GUO, YUE/0000-0003-3754-3781	US National Library of Medicine [R21LM013934]	US National Library of Medicine(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USANIH National Library of Medicine (NLM))	<B>Acknowledgments</B> This research was supported by US National Library of Medicine [grant number R21LM013934] .	Achiam OJ, 2023, Arxiv, DOI [arXiv:2303.08774, DOI 10.48550/ARXIV.2303.08774]; Alambo A., 2022, arXiv; [Anonymous], 2007, Literature Survey for the Language and Statistics II course; Artstein R, 2008, COMPUT LINGUIST, V34, P555, DOI 10.1162/coli.07-034-R2; Attal K, 2023, SCI DATA, V10, DOI 10.1038/s41597-022-01920-3; Banerjee S., 2005, P ACL WORKSH INTR EX, P65; Bin Naeem S, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18158091; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; BRITTON BK, 1991, J EDUC PSYCHOL, V83, P329, DOI 10.1037/0022-0663.83.3.329; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Bui DDA, 2016, J BIOMED INFORM, V64, P265, DOI 10.1016/j.jbi.2016.10.014; Cachola I., 2020, Findings of EMNLP; Cai X., 2021, IEEE Trans. Multimed.; Cai XY, 2022, J BIOMED INFORM, V127, DOI 10.1016/j.jbi.2022.103999; Cao Q, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3042; Cao YX, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1061; Chandrasekaran M.K., 2020, P 1 WORKSH SCHOL DOC, P214; Cheng J., 2016, Neural summarization by extracting sentences and words; Chintagunta B., 2021, P 2 WORKSHOP NATURAL, P66; Cohan Arman, 2018, P 2018 C N AM CHAPTE, V2, P615; COLEMAN M, 1975, J APPL PSYCHOL, V60, P283, DOI 10.1037/h0076540; Crossley SA, 2014, READ FOREIGN LANG, V26, P92; DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9; Devaraj Ashwin, 2022, Proc Conf Assoc Comput Linguist Meet, V2022, P7331, DOI 10.18653/v1/2022.acl-long.506; Devaraj A, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P4972, DOI 10.18653/v1/2021.naacl-main.395; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523; Fabbri A.R., 2021, arXiv; Givchi A, 2022, J BIOMED INFORM, V132, DOI 10.1016/j.jbi.2022.104099; Goldsack T., 2023, P 22ST WORKSHOP BIOM; Goldsack T, 2023, Arxiv, DOI arXiv:2210.09932; Guo Y, 2021, AAAI CONF ARTIF INTE, V35, P160; Gupta S, 2019, EXPERT SYST APPL, V121, P49, DOI 10.1016/j.eswa.2018.12.011; Gururangan S., 2020, P 58 ANN M ASS COMPU, P1, DOI [DOI 10.18653/V1/2020.ACL-MAIN.740, 10.18653/v1/2020.acl-main.740]; Guu K, 2020, PR MACH LEARN RES, V119; HOLM S, 1979, SCAND J STAT, V6, P65; Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572; Jonnalagadda S., 2009, P HUMAN LANGUAGE TEC, P177; Joshi A, 2020, M ASS FOR COMPUTATIO; Karacic J, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0716-x; Karpukhin V, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P6769; KORSCH BM, 1968, PEDIATRICS, V42, P855; KRIPPEND.K, 1970, EDUC PSYCHOL MEAS, V30, P61, DOI 10.1177/001316447003000105; Krishna K., 2023, arXiv; Kurtzman ET, 2016, PATIENT EDUC COUNS, V99, P36, DOI 10.1016/j.pec.2015.07.030; Leroy G, 2014, J AM MED INFORM ASSN, V21, pE169, DOI 10.1136/amiajnl-2013-002172; Lewis M, 2020, P ASS COMP LING, P7871, DOI [DOI 10.18653/V1/2020.ACL-MAIN.703, 10.18653/v1/2020.acl-main.703]; Lewis P., 2020, Advances in Neural Information Processing Systems, P9459; Li JZ, 2020, FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP 2020, P2785; Lin C-Y, 2004, P WORKSH TEXT SUMM B; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu J., 2023, arXiv; Luo M., 2022, arXiv; Luo ZH, 2023, Arxiv, DOI arXiv:2210.04705; Mac O, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.46051; McNamara DS, 1996, COGNITION INSTRUCT, V14, P1, DOI 10.1207/s1532690xci1401_1; Mishra R, 2014, J BIOMED INFORM, V52, P457, DOI 10.1016/j.jbi.2014.06.009; Moradi M, 2018, ARTIF INTELL MED, V84, P101, DOI 10.1016/j.artmed.2017.11.004; Naik A, 2022, Arxiv, DOI arXiv:2111.08374; Nallapati Ramesh, 2016, P 20 SIGNLL C COMP N, P280, DOI 10.18653/v1/K16-1028; Neumann M, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P319; Pagnoni A, 2021, Arxiv, DOI arXiv:2104.13346; Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135; Paszke A, 2019, ADV NEUR IN, V32; Plaza L, 2014, J BIOMED INFORM, V52, P319, DOI 10.1016/j.jbi.2014.07.014; Qenam B, 2017, J MED INTERNET RES, V19, DOI 10.2196/jmir.8536; Roberts K., 2015, TREC; Shuster Kurt, 2021, FINDINGS ASS COMPUTA, P3784, DOI 10.18653/v1/2021.findings-emnlp.320; Simpson M.S., 2014, Tech. rep.; Soroya SH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102440; Srikanth N, 2021, Arxiv, DOI arXiv:2010.10035; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Wallace Byron C, 2021, AMIA Jt Summits Transl Sci Proc, V2021, P605; Wang MQ, 2021, J AM MED INFORM ASSN, V28, P2287, DOI 10.1093/jamia/ocab143; Wisotzki, 2023, ARXIV; Wolf T, 2020, Arxiv, DOI arXiv:1910.03771; Yadav D., 2022, arXiv; Zhang Longxiang, 2021, arXiv; Zhang T., 2020, INT C LEARNING REPRE; Zhang Y., 2018, EMNLP 2018, P204; Zhang Y., 2020, PROC ASS COMP LING, DOI 10.18653/v1/2020.acl-main.458	81	2	2	53	53	ACADEMIC PRESS INC ELSEVIER SCIENCE	SAN DIEGO	525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA	1532-0464	1532-0480		J BIOMED INFORM	J. Biomed. Inform.	JAN	2024	149								104580	10.1016/j.jbi.2023.104580	http://dx.doi.org/10.1016/j.jbi.2023.104580		JAN 2024	17	Computer Science, Interdisciplinary Applications; Medical Informatics	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science; Medical Informatics	GT4I9	38163514	Green Submitted			2024-07-03	WOS:001154905600001
J	Wang, SQ; Hu, T; Xiao, H; Li, Y; Zhang, C; Ning, H; Zhu, R; Li, ZL; Ye, XY				Wang, Siqin; Hu, Tao; Xiao, Huang; Li, Yun; Zhang, Ce; Ning, Huan; Zhu, Rui; Li, Zhenlong; Ye, Xinyue			GPT, large language models (LLMs) and generative artificial intelligence (GAI) models in geospatial science: a systematic review	INTERNATIONAL JOURNAL OF DIGITAL EARTH			English	Review						GPT; generative AI (GAI); large language models (LLMs); geospatial science; GIS	WATER-LEVEL; INFORMATION; IMAGES	The launch of large language models (LLMs) like ChatGPT in late 2022 and the anticipated arrival of future GPT-x iterations have marked the beginning of the generative artificial intelligence (GAI) era. We conducted a systematic review of how to integrate LLMs including GPT and other GAI models into geospatial science, based on 293 papers obtained from four databases of academic publications - Web of Science (WoS), Scopus, SSRN and arXiv - 26 papers were eventually included for analysis. We statistically outlined the share of domains where LLMs and other GAI models, the type of data that have been used for these models, and the modelling tasks and roles that they play. We also pointed out the challenges and future directions for the next research agenda - along with which we could better position ourselves in the mainstream of science and the cutting-edge research paradigm as others leverage insights from the growing data deluge.	[Wang, Siqin] Univ Southern Calif, Spatial Sci Inst, Los Angeles, CA USA; [Wang, Siqin] Univ Queensland, Sch Environm, Brisbane, Qld, Australia; [Wang, Siqin] Royal Melbourne Inst Technol RMIT, Sch Sci, Melbourne, Australia; [Hu, Tao] Oklahoma State Univ, Dept Geog, Stillwater, OK 74077 USA; [Xiao, Huang] Emory Univ, Dept Environm Sci, Atlanta, GA USA; [Li, Yun] Emory Univ, Dept Comp Sci, Atlanta, GA USA; [Zhang, Ce; Zhu, Rui] Univ Bristol, Sch Geog Sci, Bristol, England; [Ning, Huan; Li, Zhenlong] Penn State Univ, Dept Geog, Geoinformat & Big Data Res Lab, University Pk, PA USA; [Ye, Xinyue] Texas A&M Univ, Dept Landscape Architecture & Urban Planning, College Stn, TX USA; [Ye, Xinyue] Texas A&M Univ, Dept Comp Sci & Engn, College Stn, TX USA	University of Southern California; University of Queensland; Royal Melbourne Institute of Technology (RMIT); Oklahoma State University System; Oklahoma State University - Stillwater; Emory University; Emory University; University of Bristol; Pennsylvania Commonwealth System of Higher Education (PCSHE); Pennsylvania State University; Pennsylvania State University - University Park; Texas A&M University System; Texas A&M University College Station; Texas A&M University System; Texas A&M University College Station	Hu, T (corresponding author), Oklahoma State Univ, Dept Geog, Stillwater, OK 74077 USA.	tao.hu@okstate.edu	Huang, Xiao/AAS-4608-2020	Huang, Xiao/0000-0002-4323-382X; Zhu, Rui/0000-0002-8910-9445; Zhang, Ce/0000-0001-5100-3584	Oklahoma State University	Oklahoma State University	This study was funded by the star-up fund from Oklahoma State University.	Aghzal M, 2024, Arxiv, DOI arXiv:2310.03249; Akinboyewa T, 2024, COMPUT URBAN SCI, V4, DOI 10.1007/s43762-024-00123-3; Anciukevicius T, 2023, PROC CVPR IEEE, P12608, DOI 10.1109/CVPR52729.2023.01213; Baidoo-Anu D., 2023, Journal of AI, V7, P52, DOI DOI 10.2139/SSRN.4337484; Berdejo-Espinola V, 2023, SCIENCE, V379, P991, DOI 10.1126/science.adg9714; Chang CH, 2023, INT RES GEOGR ENVIRO, V32, P85, DOI 10.1080/10382046.2023.2194036; Chaudhary P, 2020, ISPRS J PHOTOGRAMM, V167, P252, DOI 10.1016/j.isprsjprs.2020.07.003; Dao XQ, 2023, Arxiv, DOI arXiv:2307.08272; Delétang G, 2024, Arxiv, DOI arXiv:2309.10668; Feng Y., 2023, 12th International Conference on Geographic Information Science (GIScience 2023); Feng Y, 2020, ISPRS J PHOTOGRAMM, V169, P301, DOI 10.1016/j.isprsjprs.2020.09.011; Fernandez A, 2023, Arxiv, DOI [arXiv:2310.11029, 10.48550/arXiv.2310.11029, DOI 10.48550/ARXIV.2310.11029]; Girdhar R, 2023, PROC CVPR IEEE, P15180, DOI 10.1109/CVPR52729.2023.01457; GOODCHILD MF, 1992, INT J GEOGR INF SYST, V6, P31, DOI 10.1080/02693799208901893; Han BA, 2023, P NATL ACAD SCI USA, V120, DOI 10.1073/pnas.2220283120; Horikomi T, 2023, Arxiv, DOI [arXiv:2308.07940, 10.48550/arXiv.2308.07940, DOI 10.48550/ARXIV.2308.07940]; Hu YJ, 2023, INT J GEOGR INF SCI, V37, P2289, DOI 10.1080/13658816.2023.2266495; Huang CG, 2023, IEEE INT CONF ROBOT, P10608, DOI 10.1109/ICRA48891.2023.10160969; Iluz S, 2023, Arxiv, DOI [arXiv:2303.01818, 10.1145/3592123]; Jang KM, 2023, Arxiv, DOI arXiv:2306.04662; Janowicz K, 2020, INT J GEOGR INF SCI, V34, P625, DOI 10.1080/13658816.2019.1684500; Jha A, 2023, Arxiv, DOI arXiv:2305.11840; Ji YH, 2023, Arxiv, DOI arXiv:2307.03678; Jiang YY, 2018, INT J DIGIT EARTH, V11, P956, DOI 10.1080/17538947.2017.1371255; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Juhasz Levente, 2023, Spatial Data Science Symposium 2023, DOI [10.25436/E2ZW27, DOI 10.25436/E2ZW27]; Kang YH, 2023, Arxiv, DOI arXiv:2304.10743; Kharazi BA, 2021, COMPUT ENVIRON URBAN, V88, DOI 10.1016/j.compenvurbsys.2021.101628; Kirillov A, 2023, Arxiv, DOI [arXiv:2304.02643, DOI 10.48550/ARXIV.2304.02643]; Kumar K, 2024, J GEOTECH GEOENVIRON, V150, DOI 10.1061/JGGEFK.GTENG-11828; Li JR, 2023, MEASUREMENT, V216, DOI 10.1016/j.measurement.2023.112891; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li ZL, 2023, INT J DIGIT EARTH, V16, P4668, DOI 10.1080/17538947.2023.2278895; Ling GM, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12070296; Lu MY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15051279; Mai GC, 2023, Arxiv, DOI arXiv:2304.06798; Manvi R, 2024, Arxiv, DOI [arXiv:2310.06213, 10.48550/arXiv.2310.06213]; Meng ZL, 2019, ARIC 2019: PROCEEDINGS OF THE 2ND ACM SIGSPATIAL INTERNATIONAL WORKSHOP ON ADVANCES IN RESILIENT AND INTELLIGENT CITIES (ARIC-2019), P37, DOI 10.1145/3356395.3365542; Moher D., 1999, Guidelines for Reporting Health Research: A User's Manual, P250; Nash C, 2020, Arxiv, DOI [arXiv:2002.10880, 10.48550/arXiv.2002.10880]; Ning H, 2020, ANN GIS, V26, P329, DOI 10.1080/19475683.2020.1803402; Nowozin S., 2012, IMPROVED INFORM GAIN; Park S, 2021, J COMPUT CIVIL ENG, V35, DOI 10.1061/(ASCE)CP.1943-5487.0000956; Quan Khanh-An C., 2020, ICMR '20: Proceedings of the 2020 International Conference on Multimedia Retrieval, P479, DOI 10.1145/3372278.3390704; Radford A., 2023, International Conference on Machine Learning, P28492; Roberts J, 2023, Arxiv, DOI [arXiv:2306.00020, 10.48550/arXiv.2306.00020]; Sarker Iqbal H, 2021, SN Comput Sci, V2, P420, DOI 10.1007/s42979-021-00815-1; Shang KL, 2023, SAGE OPEN, V13, DOI 10.1177/21582440231208851; Shuklin A., 2022, 2022 International Conference on Engineering and Emerging Technologies (ICEET), P1; Song ZQ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165614; Stoewer P, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-14916-1; Tao R, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12070284; Vaswani A, 2017, ADV NEUR IN, V30; Wang J, 2022, P INT C NEUR INF PRO, P5696; Wang SQ, 2023, J MED INTERNET RES, V25, DOI 10.2196/47225; Weng MH, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122111220; Yang JHY, 2023, ISPRS INT J GEO-INF, V12, DOI 10.3390/ijgi12020052; Ye X, 2023, J PLAN LIT, V38, P187, DOI 10.1177/08854122221137861; Yu MZ, 2023, FRONT ENV SCI-SWITZ, V11, DOI 10.3389/fenvs.2023.1223160; Yu MZ, 2023, SCI TOTAL ENVIRON, V860, DOI 10.1016/j.scitotenv.2022.160446; Yu YD, 2023, Arxiv, DOI [arXiv:2311.13110, 10.48550/arXiv.2311.13110]; Zhang KP, 2024, INFORM FUSION, V102, DOI 10.1016/j.inffus.2023.102038; Zhang YF, 2023, Arxiv, DOI [arXiv:2307.07930, 10.48550/arXiv.2307.07930]; Zhang Z, 2023, Arxiv, DOI arXiv:2310.04942; Zheng CY, 2023, Arxiv, DOI [arXiv:2305.17476, 10.48550/arXiv.2305.17476, DOI 10.48550/ARXIV.2305.17476]; Zheng S, 2023, Arxiv, DOI [arXiv:2309.16583, 10.48550/arXiv.2309.16583]	66	0	0	24	24	TAYLOR & FRANCIS LTD	ABINGDON	2-4 PARK SQUARE, MILTON PARK, ABINGDON OR14 4RN, OXON, ENGLAND	1753-8947	1753-8955		INT J DIGIT EARTH	Int. J. Digit. Earth	DEC 31	2024	17	1							2353122	10.1080/17538947.2024.2353122	http://dx.doi.org/10.1080/17538947.2024.2353122			21	Geography, Physical; Remote Sensing	Science Citation Index Expanded (SCI-EXPANDED)	Physical Geography; Remote Sensing	RR7T2		gold			2024-07-03	WOS:001229460700001
J	Hodjat, B				Hodjat, Babak			AI and agents	AI MAGAZINE			English	Article								Earlier this year, OpenAI released their GPTs framework, allowing users to set up Large Language Model (LLM)-based personas, orchestrate them into a workflow and even offering their AI apps within an app store. This is the latest, and maybe the easiest to set up, in a string of agent-based LLM orchestration platforms in the past year, harkening a new age of agent-based engineering. But, like most breakthroughs, this one is also rooted in many years of research, and the reason the world is paying attention to it now is that, thanks to Generative AI and Large Language Models, we finally have artificial agents that are useful enough to scale to more serious problems.	[Hodjat, Babak] Cognizant, San Francisco, CA 94111 USA		Hodjat, B (corresponding author), Cognizant, San Francisco, CA 94111 USA.	BABAKATWORK@YAHOO.COM		Hodjat, Babak/0000-0002-4547-4731				Ciancarini P., 2000, 1 INT WORKSHOP AOSE, P1, DOI [10.1007/3-540-44564-1, DOI 10.1007/3-540-44564-1]; Cohen Philip R., 1994, AAAI SPRING S, V1; Hodjat Babak., 1998, PRICAI 98 TOPICS ART, V5; openfoam, ABOUT US; Poole D.L., 2010, Artificial Intelligence: Foundations of Computational Agents, DOI DOI 10.1017/9781108164085; van der Hoek W, 2008, FOUND ARTIF INTELL, P887, DOI 10.1016/S1574-6526(07)03024-6; Vanneschi Leonardo., 2023, LECT INTELLIGENT SYS, P205; Vaswani A, 2017, ADV NEUR IN, V30; Wang AP, 2009, IEEE IMAGE PROC, P1449, DOI 10.1109/ICIP.2009.5414559; wiki, KNOWLEDGE QUERY MANI	10	0	0	11	11	AMER ASSOC ARTIFICIAL INTELL	MENLO PK	445 BURGESS DRIVE, MENLO PK, CA 94025-3496 USA	0738-4602	2371-9621		AI MAG	AI Mag.	JUN	2024	45	2			SI		267	269		10.1002/aaai.12170	http://dx.doi.org/10.1002/aaai.12170		APR 2024	3	Computer Science, Artificial Intelligence	Science Citation Index Expanded (SCI-EXPANDED)	Computer Science	US6A3		hybrid			2024-07-03	WOS:001196426300001
C	Reif, E; Ippolito, D; Yuan, A; Coenen, A; Callison-Burch, C; Wei, J			Assoc Computa Linguist	Reif, Emily; Ippolito, Daphne; Yuan, Ann; Coenen, Andy; Callison-Burch, Chris; Wei, Jason			Recipe For Arbitrary Text Style Transfer with Large Language Models	PROCEEDINGS OF THE 60TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2022): (SHORT PAPERS), VOL 2			English	Proceedings Paper	60th Annual Meeting of the Association-for-Computational-Linguistics (ACL)	MAY 22-27, 2022	Dublin, IRELAND	Assoc Computat Linguist, Amazon Sci, Bloomberg Engn, Google Res, Liveperson, Meta, Baidu, ByteDance, DeepMind, Grammarly, GTCOM, IBM, Megagon Labs, Microsoft, Alibaba Grp, Bosch, Cohere, G Res, ServiceNow, Relativity, Naver, ASAPP, Duolingo, BabelSpace, Spotiry, Adobe, D & I Special Initiat, AppTek, YaiGlobal, Aixplain, Apple				In this paper, we leverage large language models (LMs) to perform zero-shot text style transfer. We present a prompting method that we call augmented zero-shot learning, which frames style transfer as a sentence rewriting task and requires only a natural language instruction, without model fine-tuning or exemplars in the target style. Augmented zero-shot learning is simple and demonstrates promising results not just on standard style transfer tasks such as sentiment, but also on natural language transformations such as "make this melodramatic" or "insert a metaphor."	[Reif, Emily; Ippolito, Daphne; Yuan, Ann; Coenen, Andy; Wei, Jason] Google Res, Mountain View, CA 94043 USA; [Ippolito, Daphne; Callison-Burch, Chris] Univ Penn, Philadelphia, PA 19104 USA	Google Incorporated; University of Pennsylvania	Reif, E (corresponding author), Google Res, Mountain View, CA 94043 USA.	ereif@google.com; daphnei@seas.upenn.edu; annyuan@google.com; andycoenen@google.com; ccb@seas.upenn.edu; jasonwei@google.com	Callison-Burch, Chris/A-3393-2010					Bender EM, 2021, PROCEEDINGS OF THE 2021 ACM CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, FACCT 2021, P610, DOI 10.1145/3442188.3445922; Branwen G., 2020, Gpt-3 creative fiction; Briakou E, 2021, 1ST WORKSHOP ON NATURAL LANGUAGE GENERATION, EVALUATION, AND METRICS (GEM 2021), P58; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Dai N, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5997; Fan A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P889; Fu ZX, 2018, AAAI CONF ARTIF INTE, P663; Holtzman A., 2019, P INT C LEARN REPR; Hu Zhiqiang, 2020, ABS201012742 CORR; Jin Di, 2020, ARXIV201100416; Jin ZJ, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3097; Krishna K, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P737; Kudo Taku, 2018, P EMNLP SYST DEM, P66, DOI DOI 10.18653/V1/D18-2012; Li J, 2018, Long Papers, V1, P1865, DOI 10.18653/v1/n18-1169; Liu DYH, 2020, AAAI CONF ARTIF INTE, V34, P8376; Liu P., 2021, arXiv, DOI 10.48550/arXiv.2107.13586; Liu R., 2021, PROC ACM HUM COMPUT; Luo FL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5116; Madaan A, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1869; Mir R., 2019, ABS190402295 CORR; Prabhumoye S, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P866; Puri R, 2019, Arxiv, DOI arXiv:1912.10165; Rao Sudha, 2018, Long Papers, V1, P129; Reynolds Laria, 2021, Prompt programming for large language models: Beyond the few-shot paradigm; Riley Parker, 2021, ACL; Sakaguchi K, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P208; Schick T, 2021, 2021 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL-HLT 2021), P2339; Shen TX, 2017, ADV NEUR IN, V30; Sudhakar A, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P3269; Thoppilan R., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.08239; Vaswani A, 2017, ADV NEUR IN, V30; Weller O, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1361; Wolf Thomas, 2020, P EMNLP, P38, DOI DOI 10.18653/V1/2020.EMNLP-DEMOS.6; Xu JJ, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P979; Xu Peng, 2020, INT C MACH LEARN, P10534; Zhang X, 2015, ADV NEUR IN, V28; Zhu Zhemin, 2010, P 23 INT C COMPUTATI, P1353	37	11	11	1	2	ASSOC COMPUTATIONAL LINGUISTICS-ACL	STROUDSBURG	209 N EIGHTH STREET, STROUDSBURG, PA 18360 USA			978-1-955917-22-3				2022							837	848						12	Computer Science, Artificial Intelligence; Computer Science, Theory & Methods; Linguistics	Conference Proceedings Citation Index - Science (CPCI-S); Conference Proceedings Citation Index - Social Science &amp; Humanities (CPCI-SSH)	Computer Science; Linguistics	BT4EN					2024-07-03	WOS:000828732800094
J	Zhang, W; Wang, QG; Kong, XT; Xiong, JC; Ni, SK; Cao, DH; Niu, BY; Chen, MG; Li, YM; Zhang, RZ; Wang, YT; Zhang, LH; Li, XT; Xiong, ZP; Shi, Q; Huang, ZM; Fu, ZY; Zheng, MY				Zhang, Wei; Wang, Qinggong; Kong, Xiangtai; Xiong, Jiacheng; Ni, Shengkun; Cao, Duanhua; Niu, Buying; Chen, Mingan; Li, Yameng; Zhang, Runze; Wang, Yitian; Zhang, Lehan; Li, Xutong; Xiong, Zhaoping; Shi, Qian; Huang, Ziming; Fu, Zunyun; Zheng, Mingyue			Fine-tuning large language models for chemical text mining	CHEMICAL SCIENCE			English	Article; Early Access								Extracting knowledge from complex and diverse chemical texts is a pivotal task for both experimental and computational chemists. The task is still considered to be extremely challenging due to the complexity of the chemical language and scientific literature. This study explored the power of fine-tuned large language models (LLMs) on five intricate chemical text mining tasks: compound entity recognition, reaction role labelling, metal-organic framework (MOF) synthesis information extraction, nuclear magnetic resonance spectroscopy (NMR) data extraction, and the conversion of reaction paragraphs to action sequences. The fine-tuned LLMs demonstrated impressive performance, significantly reducing the need for repetitive and extensive prompt engineering experiments. For comparison, we guided ChatGPT (GPT-3.5-turbo) and GPT-4 with prompt engineering and fine-tuned GPT-3.5-turbo as well as other open-source LLMs such as Mistral, Llama3, Llama2, T5, and BART. The results showed that the fine-tuned ChatGPT models excelled in all tasks. They achieved exact accuracy levels ranging from 69% to 95% on these tasks with minimal annotated data. They even outperformed those task-adaptive pre-training and fine-tuning models that were based on a significantly larger amount of in-domain data. Notably, fine-tuned Mistral and Llama3 show competitive abilities. Given their versatility, robustness, and low-code capability, leveraging fine-tuned LLMs as flexible and effective toolkits for automated data acquisition could revolutionize chemical knowledge extraction. Extracting knowledge from complex chemical texts is essential for both experimental and computational chemists. Fine-tuned large language models (LLMs) can serve as flexible and effective extractors for automated data acquisition.	[Zhang, Wei; Kong, Xiangtai; Xiong, Jiacheng; Ni, Shengkun; Cao, Duanhua; Niu, Buying; Chen, Mingan; Zhang, Runze; Wang, Yitian; Zhang, Lehan; Li, Xutong; Fu, Zunyun; Zheng, Mingyue] Chinese Acad Sci, Shanghai Inst Mat Med, Drug Discovery & Design Ctr, State Key Lab Drug Res, 555 Zuchongzhi Rd, Shanghai 201203, Peoples R China; [Zhang, Wei; Kong, Xiangtai; Xiong, Jiacheng; Ni, Shengkun; Niu, Buying; Zhang, Runze; Wang, Yitian; Zhang, Lehan; Li, Xutong; Zheng, Mingyue] Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China; [Wang, Qinggong; Zheng, Mingyue] Nanjing Univ Chinese Med, 138 Xianlin Rd, Nanjing 210023, Peoples R China; [Cao, Duanhua] Zhejiang Univ, Innovat Inst Artificial Intelligence Med, Coll Pharmaceut Sci, Hangzhou 310058, Zhejiang, Peoples R China; [Chen, Mingan] ShanghaiTech Univ, Sch Phys Sci & Technol, Shanghai 201210, Peoples R China; [Chen, Mingan; Shi, Qian] Lingang Lab, Shanghai 200031, Peoples R China; [Li, Yameng; Xiong, Zhaoping] ProtonUnfold Technol Co Ltd, Suzhou, Peoples R China; [Huang, Ziming] Ludwig Maximilians Univ Munchen, Med Klin & Poliklin 1, Klinikum Univ Munchen, Munich, Germany	Chinese Academy of Sciences; Shanghai Institute of Materia Medica, CAS; Chinese Academy of Sciences; University of Chinese Academy of Sciences, CAS; Nanjing University of Chinese Medicine; Zhejiang University; ShanghaiTech University; Lingang Laboratory; University of Munich	Fu, ZY; Zheng, MY (corresponding author), Chinese Acad Sci, Shanghai Inst Mat Med, Drug Discovery & Design Ctr, State Key Lab Drug Res, 555 Zuchongzhi Rd, Shanghai 201203, Peoples R China.; Zheng, MY (corresponding author), Univ Chinese Acad Sci, 19A Yuquan Rd, Beijing 100049, Peoples R China.; Zheng, MY (corresponding author), Nanjing Univ Chinese Med, 138 Xianlin Rd, Nanjing 210023, Peoples R China.	fuzunyun@simm.ac.cn; myzheng@simm.ac.cn			National Natural Science Foundation of China [T2225002, 82273855, 82204278]; National Natural Science Foundation of China [2022YFC3400504, E2G805H]; National Key Research and Development Program of China [2023693]; Shanghai Post-doctoral Excellence Program; Shanghai Municipal Science and Technology Major Project	National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); National Key Research and Development Program of China; Shanghai Post-doctoral Excellence Program; Shanghai Municipal Science and Technology Major Project	We thank all contributions of the open-source community on LLMs. We appreciate Yaghi's group for guiding in ChatGPT prompt engineering for chemistry tasks. This work was supported by the National Natural Science Foundation of China (T2225002 and 82273855 to M. Y. Z. and 82204278 to X. T. L.), the National Key Research and Development Program of China (2022YFC3400504 to M. Y. Z.), the SIMM-SHUTCM Traditional Chinese Medicine Innovation Joint Research Program (E2G805H to M. Y. Z.), the Shanghai Post-doctoral Excellence Program (2023693 to Z. Y. F.) and the Shanghai Municipal Science and Technology Major Project.	[Anonymous], Llama3; [Anonymous], Reaxys; [Anonymous], SCIFINDER; [Anonymous], Pistachio; Chen QJ, 2023, BIOINFORMATICS, V39, DOI 10.1093/bioinformatics/btad557; Clark TM, 2023, J CHEM EDUC, V100, P3934, DOI 10.1021/acs.jchemed.3c00500; Dettmers T, 2023, Arxiv, DOI [arXiv:2305.14314, DOI 10.48550/ARXIV.2305.14314]; Guo J, 2022, J CHEM INF MODEL, V62, P2035, DOI 10.1021/acs.jcim.1c00284; Guo T., 2023, arXiv, DOI [10.48550/arXiv.2108.09926, DOI 10.48550/ARXIV.2108.09926]; Ha T, 2023, SCI ADV, V9, DOI 10.1126/sciadv.adj0461; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Jiang AQ, 2023, Arxiv, DOI arXiv:2310.06825; Kearnes SM, 2021, J AM CHEM SOC, V143, P18820, DOI 10.1021/jacs.1c09820; Kwon W., 2023, presented in part at the Proceedings of the 29th Symposium on Operating Systems Principles; Lewis M, 2019, Arxiv, DOI arXiv:1910.13461; Lowe D. M., 2012, EXTRACTION CHEM STRU, DOI [10.17863/CAM.16293, DOI 10.17863/CAM.16293]; Lowe Daniel, 2017, Figshare; Mavracic J, 2021, J CHEM INF MODEL, V61, P4280, DOI 10.1021/acs.jcim.1c00446; Mehr SHM, 2020, SCIENCE, V370, P101, DOI 10.1126/science.abc2986; Mercado R, 2023, J CHEM INF MODEL, V63, P4253, DOI 10.1021/acs.jcim.3c00607; Nascimento CMC, 2023, J CHEM INF MODEL, V63, P1649, DOI 10.1021/acs.jcim.3c00285; Nippa D. F., 2024, ChemRxiv, DOI [10.26434/chemrxiv-2023-nfq7h-v2, DOI 10.26434/CHEMRXIV-2023-NFQ7H-V2]; Patiny L., 2023, ChemRxiv, DOI DOI 10.26434/CHEMRXIV-2023-05V1B-V2; Peng A., GPT-3.5 Turbo fine-tuning and API updates; Qian YJ, 2023, J CHEM INF MODEL, V63, P4030, DOI 10.1021/acs.jcim.3c00439; Qian YJ, 2023, J CHEM INF MODEL, V63, P1925, DOI 10.1021/acs.jcim.2c01480; Raffel C, 2020, J MACH LEARN RES, V21; Steiner S, 2019, SCIENCE, V363, P144, DOI 10.1126/science.aav2211; Suvarna M, 2023, NAT COMMUN, V14, DOI 10.1038/s41467-023-43836-5; Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Vaucher AC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17266-6; Wilary DM, 2023, J CHEM INF MODEL, V63, P6053, DOI 10.1021/acs.jcim.3c00422; Xiong JC, 2024, SCI CHINA LIFE SCI, V67, P618, DOI 10.1007/s11427-023-2388-x; Zhang Y, 2023, Arxiv, DOI arXiv:2309.01219; Zheng ZL, 2023, J AM CHEM SOC, V145, P18048, DOI 10.1021/jacs.3c05819	36	0	0	1	1	ROYAL SOC CHEMISTRY	CAMBRIDGE	THOMAS GRAHAM HOUSE, SCIENCE PARK, MILTON RD, CAMBRIDGE CB4 0WF, CAMBS, ENGLAND	2041-6520	2041-6539		CHEM SCI	Chem. Sci.	2024 JUN 7	2024										10.1039/d4sc00924j	http://dx.doi.org/10.1039/d4sc00924j		JUN 2024	12	Chemistry, Multidisciplinary	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry	UE1M4		gold			2024-07-03	WOS:001246293600001
J	He, WT; Ma, HJ; Li, SH; Dong, H; Zhang, HX; Feng, J				He, Wentao; Ma, Hanjie; Li, Shaohua; Dong, Hui; Zhang, Haixiang; Feng, Jie			Using Augmented Small Multimodal Models to Guide Large Language Models for Multimodal Relation Extraction	APPLIED SCIENCES-BASEL			English	Article						multimodal relation extraction; small multimodal guidance; multimodal relation data augmentation; flexible threshold loss; large language model		Multimodal Relation Extraction (MRE) is a core task for constructing Multimodal Knowledge images (MKGs). Most current research is based on fine-tuning small-scale single-modal image and text pre-trained models, but we find that image-text datasets from network media suffer from data scarcity, simple text data, and abstract image information, which requires a lot of external knowledge for supplementation and reasoning. We use Multimodal Relation Data augmentation (MRDA) to address the data scarcity problem in MRE, and propose a Flexible Threshold Loss (FTL) to handle the imbalanced entity pair distribution and long-tailed classes. After obtaining prompt information from the small model as a guide model, we employ a Large Language Model (LLM) as a knowledge engine to acquire common sense and reasoning abilities. Notably, both stages of our framework are flexibly replaceable, with the first stage adapting to multimodal related classification tasks for small models, and the second stage replaceable by more powerful LLMs. Through experiments, our EMRE2llm model framework achieves state-of-the-art performance on the challenging MNRE dataset, reaching an 82.95% F1 score on the test set.	[He, Wentao; Ma, Hanjie; Li, Shaohua; Zhang, Haixiang; Feng, Jie] Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China; [Dong, Hui] Hangzhou Codvis Technol Co Ltd, Hangzhou 311100, Peoples R China	Zhejiang Sci-Tech University	Ma, HJ (corresponding author), Zhejiang Sci Tech Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.	202130504089@mails.zstu.edu.cn; mahanjie@zstu.edu.cn; 202120501008@mails.zstu.edu.cn; donghui@codvision.com	Shaohua, Li/HPE-8342-2023	Shaohua, Li/0000-0002-4630-4152				Soares LB, 2019, Arxiv, DOI arXiv:1906.03158; Bao H., 2022, ADV NEURAL INF PROCE, V35, P32897, DOI DOI 10.1109/CVPR.2018.00636; Brown T., 2020, PROC INT C NEURAL IN, V33, P346, DOI [10.48550/arXiv.2005.14165, DOI 10.48550/ARXIV.2005.14165]; Chen X, 2022, PROCEEDINGS OF THE 45TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '22), P904, DOI 10.1145/3477495.3531992; Chen X, 2022, PROCEEDINGS OF THE ACM WEB CONFERENCE 2022 (WWW'22), P2778, DOI 10.1145/3485447.3511998; Chen Y, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11081815; Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359; Cui XH, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12122688; Dai WL, 2023, Arxiv, DOI arXiv:2305.06500; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; Du N, 2022, PR MACH LEARN RES; Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI 10.1109/CVPR.2014.81; Hao XS, 2023, IEEE WINT CONF APPL, P379, DOI 10.1109/WACVW58289.2023.00042; Li LH, 2019, Arxiv, DOI arXiv:1908.03557; He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90; Ji ZW, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3571730; Kim W, 2021, PR MACH LEARN RES, V139; Li JH, 2021, ADV NEUR IN, V34; Li JN, 2022, PR MACH LEARN RES; Li JN, 2023, Arxiv, DOI [arXiv:2301.12597, 10.48550/arXiv.2301.12597]; Li SH, 2023, IET IMAGE PROCESS, V17, P3002, DOI 10.1049/ipr2.12850; Liu HT, 2023, Arxiv, DOI arXiv:2304.08485; Liu Y, 2019, LECT NOTES COMPUT SC, V11503, P459, DOI 10.1007/978-3-030-21348-0_30; Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]; Lu D, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P1990; Lu J., 2019, arXiv, DOI [DOI 10.48550/ARXIV.1908.02265, 10.48550/arXiv.1908.02265]; Radford A, 2021, PR MACH LEARN RES, V139; Ranaldi L, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13020677; Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031; Rossi A, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3424672; Sha YC, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11153269; Shao ZW, 2023, PROC CVPR IEEE, P14974, DOI 10.1109/CVPR52729.2023.01438; Smith S, 2022, arXiv; Sun R, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1405, DOI 10.1145/3340531.3411947; Touvron H, 2023, Arxiv, DOI [arXiv:2307.09288, DOI 10.48550/ARXIV.2307.09288]; Touvron H, 2023, Arxiv, DOI [arXiv:2302.13971, DOI 10.48550/ARXIV.2302.13971]; Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324; Wan H, 2021, AAAI CONF ARTIF INTE, V35, P13916; Wang ZK, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8852079; Xu B., 2022, P 29 INT C COMPUTATI, P1855; Xu P, 2023, IEEE T PATTERN ANAL, V45, P12113, DOI 10.1109/TPAMI.2023.3275156; Yang ZY, 2022, AAAI CONF ARTIF INTE, P3081; Yang ZX, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P2486, DOI 10.1145/3397271.3401458; Ye QH, 2024, Arxiv, DOI arXiv:2304.14178; Yu JF, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P3342; Yuan L, 2023, P AAAI C ART INT, V37, P11051; Zeng Daojian, 2015, P 2015 C EMPIRICAL M, P1753; Zhang D, 2021, AAAI CONF ARTIF INTE, V35, P14347; Zhang N., 2022, arXiv; Zhang NY, 2022, Arxiv, DOI [arXiv:2210.00312, 10.48550/arXiv.2210.00312]; Zhang PC, 2021, Arxiv, DOI arXiv:2101.00529; Zhang Q, 2018, AAAI CONF ARTIF INTE, P5674; Zhang RR, 2023, Arxiv, DOI [arXiv:2303.16199, DOI 10.48550/ARXIV.2303.16199, 10.48550/arXiv.2303.16199,arXiv]; Zheng CM, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5298, DOI 10.1145/3474085.3476968; Zhou WX, 2021, AAAI CONF ARTIF INTE, V35, P14612; Zhu DY, 2023, Arxiv, DOI arXiv:2304.10592	56	0	0	35	38	MDPI	BASEL	ST ALBAN-ANLAGE 66, CH-4052 BASEL, SWITZERLAND		2076-3417		APPL SCI-BASEL	Appl. Sci.-Basel	NOV	2023	13	22							12208	10.3390/app132212208	http://dx.doi.org/10.3390/app132212208			14	Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials Science, Multidisciplinary; Physics, Applied	Science Citation Index Expanded (SCI-EXPANDED)	Chemistry; Engineering; Materials Science; Physics	AT8A8		gold			2024-07-03	WOS:001120786600001
J	Ocakoglu, SR; Coskun, B				Ocakoglu, Sakine Rahimli; Coskun, Burhan			The Emerging Role of AI in Patient Education: A Comparative Analysis of the Accuracy of Large Language Models for Pelvic Organ Prolapse	MEDICAL PRINCIPLES AND PRACTICE			English	Article; Early Access						Artificial intelligence; Pelvic organ prolapse; Patient information; Large language model	READABILITY	Introduction: This study aimed to evaluate the accuracy, completeness, precision, and readability of outputs generated by three large language models (LLMs); these are GPT by OpenAI, BARD by Google, and Bing by Microsoft, in comparison to patient education material on pelvic organ prolapse (POP) provided by the Royal College of Obstetricians and Gynecologists (RCOG). Methods: A total of 15 questions were retrieved from the RCOG website and input into the three LLMs. Two independent reviewers evaluated the outputs for accuracy, completeness, and precision. Readability was assessed using the Simplified Measure of Gobbledygook (SMOG) score and the Flesch-Kincaid Grade Level (FKGL) score. Results: Significant differences were observed in completeness and precision metrics. ChatGPT ranked highest in completeness (66.7%), while Bing led in precision (100%). No significant differences were observed in accuracy across all models. In terms of readability, ChatGPT exhibited higher difficulty than BARD, Bing, and the original RCOG answers. Conclusion: While all models displayed a variable degree of correctness, ChatGPT excelled in completeness, significantly surpassing BARD and Bing. However, Bing led in precision, providing the most relevant and concise answers. Regarding readability, ChatGPT exhibited higher difficulty. We observed that while all LLMs showed varying degrees of correctness in answering RCOG questions on patient information for POP, ChatGPT was the most comprehensive, but its answers were harder to read. Bing, on the other hand, was the most precise. The findings highlight the potential of LLMs in health information dissemination and the need for careful interpretation of their outputs. Highlights of the StudyStudies have been performed to compare the content production performance of large language models (LLMs).The analysis of the concordance of LLMs is in concordance with authoritative gynecology and obstetrics texts.This establishes a new framework for evaluating the medical content of artificial intelligence.This study also initiates readability evaluation of patient information generated by artificial intelligence in women's health.	[Ocakoglu, Sakine Rahimli] Bursa City Hosp, Dept Obstet & Gynecol, Bursa, Turkiye; [Coskun, Burhan] Bursa Uludag Univ, Dept Urol, Bursa, Turkiye	Uludag University	Ocakoglu, SR (corresponding author), Bursa City Hosp, Dept Obstet & Gynecol, Bursa, Turkiye.	dr.sakineocakoglu@gmail.com						Allahqoli L, 2023, GYNECOL OBSTET INVES, V88, P310, DOI 10.1159/000533177; Caglar U, 2024, J PEDIATR UROL, V20, DOI 10.1016/j.jpurol.2023.08.003; Campbell DJ, 2024, THYROID, V34, P371, DOI 10.1089/thy.2023.0491; Chung Soo-Ho, 2018, J Menopausal Med, V24, P155; Coskun B, 2023, UROLOGY, V180, P35, DOI 10.1016/j.urology.2023.05.040; DeLancey JOL, 2016, CURR OPIN OBSTET GYN, V28, P420, DOI 10.1097/GCO.0000000000000312; Doyal AS, 2023, CUREUS J MED SCIENCE, V15, DOI 10.7759/cureus.43292; Drost LE, 2023, INT UROGYNECOL J, V34, P79, DOI 10.1007/s00192-022-05405-0; Eid K., 2023, Ophthalmic Plast Reconstr Surg, V10, P1097; Friedman DB, 2006, HEALTH EDUC BEHAV, V33, P352, DOI 10.1177/1090198105277329; Giannakopoulos K, 2023, J MED INTERNET RES, V25, DOI 10.2196/51580; Grunebaum Amos, 2023, Am J Obstet Gynecol, V228, P696, DOI 10.1016/j.ajog.2023.03.009; Hung YC, 2023, ANN PLAS SURG, V91, P409, DOI 10.1097/SAP.0000000000003634; Iannantuono GM, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1268915; Johnson Douglas, 2023, Res Sq, DOI 10.21203/rs.3.rs-2566942/v1; Koo TK, 2016, J CHIROPR MED, V15, P155, DOI 10.1016/j.jcm.2016.02.012; Lim B, 2023, PLAST AESTHET RES, V10, DOI 10.20517/2347-9264.2023.70; MCLAUGHLIN GH, 1969, J READING, V12, P639; Nori H, 2023, Arxiv, DOI [arXiv:2303.13375, DOI 10.48550/ARXIV.2303.13375]; Olsen AL, 1997, OBSTET GYNECOL, V89, P501, DOI 10.1016/S0029-7844(97)00058-6; OpenAI, 2023, Introducing chatgpt; Pushpanathan K, 2023, ISCIENCE, V26, DOI 10.1016/j.isci.2023.108163; Song HF, 2023, J MED SYST, V47, DOI 10.1007/s10916-023-02021-3; Suarez-Lledo V, 2021, J MED INTERNET RES, V23, DOI 10.2196/17187; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Xie Y, 2024, ANZ J SURG, V94, P68, DOI 10.1111/ans.18666	26	0	0	0	0	KARGER	BASEL	ALLSCHWILERSTRASSE 10, CH-4009 BASEL, SWITZERLAND	1011-7571	1423-0151		MED PRIN PRACT	Med. Princ. Pract.	2024 MAR 25	2024										10.1159/000538538	http://dx.doi.org/10.1159/000538538		MAR 2024	8	Medicine, General & Internal	Science Citation Index Expanded (SCI-EXPANDED)	General & Internal Medicine	TN5T5		gold			2024-07-03	WOS:001241962600001
J	Lin, ZC				Lin, Zhicheng			Techniques for supercharging academic writing with generative AI	NATURE BIOMEDICAL ENGINEERING			English	Article; Early Access							CHATGPT	Generalist large language models can elevate the quality and efficiency of academic writing.	[Lin, Zhicheng] Univ Sci & Technol China, Hefei, Peoples R China	Chinese Academy of Sciences; University of Science & Technology of China, CAS	Lin, ZC (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.	zhichenglin@gmail.com	Lin, Zhicheng/B-9756-2008	Lin, Zhicheng/0000-0002-6864-6559	National Key R&D Program of China STI2030 Major Projects (2021ZD0204200), National Natural Science Foundation of China (32071045), and Shenzhen Fundamental Research Program (JCYJ20210324134603010) [2021ZD0204200]; National Key R&D Program of China [32071045]; National Natural Science Foundation of China [JCYJ20210324134603010]; Shenzhen Fundamental Research Program	National Key R&D Program of China STI2030 Major Projects (2021ZD0204200), National Natural Science Foundation of China (32071045), and Shenzhen Fundamental Research Program (JCYJ20210324134603010); National Key R&D Program of China; National Natural Science Foundation of China(National Natural Science Foundation of China (NSFC)); Shenzhen Fundamental Research Program	The writing of this Comment was supported by the National Key R&D Program of China STI2030 Major Projects (2021ZD0204200), the National Natural Science Foundation of China (32071045) and the Shenzhen Fundamental Research Program (JCYJ20210324134603010). The author used GPT-4 (https://chat.openai.com) and Claude (https://claude.ai) alongside prompts from Box 1 to help write earlier versions of the text and to edit it. The text was then developmentally edited by the journal's Chief Editor with basic-editing and structural-editing assistance from Claude, and checked by the author.	Amano T, 2023, PLOS BIOL, V21, DOI 10.1371/journal.pbio.3002184; [Anonymous], 2018, NAT BIOMED ENG, V2, P53, DOI 10.1038/s41551-018-0202-5; [Anonymous], 2023, Generative AI in Scholarly Communications: Ethical and Practical Guidelines for the Use of Generative AI in the Publication Process; Bell S, 2023, BMC MED, V21, DOI 10.1186/s12916-023-03039-7; Birhane A, 2023, NAT REV PHYS, V5, P277, DOI 10.1038/s42254-023-00581-4; Casal E. J., 2023, RES METHODS APPL LIN, V2, P100068; Chamba N, 2022, NAT ASTRON, V6, P1015, DOI 10.1038/s41550-022-01757-1; Croxson PL, 2021, NAT HUM BEHAV, V5, P1466, DOI 10.1038/s41562-021-01221-6; Dergaa I, 2023, BIOL SPORT, V40, P615, DOI 10.5114/biolsport.2023.125623; Gernsbacher MA, 2018, ADV METH PRACT PSYCH, V1, P403, DOI 10.1177/2515245918754485; Golan R, 2023, NAT REV UROL, V20, P327, DOI 10.1038/s41585-023-00746-x; Hwang SI, 2023, KOREAN J RADIOL, V24, P952, DOI 10.3348/kjr.2023.0773; King AA., 2023, J. Manag. Sci. Rep., V1, P206, DOI DOI 10.1177/27550311231187068; Lin Z., 2023, PREPRINT, DOI DOI 10.31234/OSF.IO/S6H58; Lin ZC, 2024, NAT HUM BEHAV, DOI 10.1038/s41562-024-01847-2; Lin ZC, 2024, Arxiv, DOI arXiv:2401.15284; Lin ZC, 2024, TRENDS COGN SCI, V28, P85, DOI 10.1016/j.tics.2023.12.002; Lin ZC, 2023, ROY SOC OPEN SCI, V10, DOI 10.1098/rsos.230658; Lin ZC, 2023, PERSPECT PSYCHOL SCI, V18, P358, DOI 10.1177/17456916221091831; Luna RE, 2020, NAT REV MOL CELL BIO, V21, P653, DOI 10.1038/s41580-020-00293-y; Merow C, 2023, NAT ECOL EVOL, V7, P960, DOI 10.1038/s41559-023-02063-3; Milano S, 2023, NAT MACH INTELL, V5, P333, DOI 10.1038/s42256-023-00644-2; Nazari N, 2021, HELIYON, V7, DOI 10.1016/j.heliyon.2021.e07014; Patriotta G, 2017, J MANAGE STUD, V54, P747, DOI 10.1111/joms.12280; Semrl N, 2023, HUM REPROD, V38, P2281, DOI 10.1093/humrep/dead207; Thirunavukarasu AJ, 2023, NAT MED, V29, P1930, DOI 10.1038/s41591-023-02448-8; Wang HC, 2023, NATURE, V620, P47, DOI 10.1038/s41586-023-06221-2; White AD, 2023, NAT REV CHEM, V7, P457, DOI 10.1038/s41570-023-00502-0; Yan D, 2023, EDUC INF TECHNOL, V28, P13943, DOI 10.1007/s10639-023-11742-4; Yurkewicz K, 2022, NAT REV MATER, V7, P673, DOI 10.1038/s41578-022-00472-7	30	1	1	32	32	NATURE PORTFOLIO	BERLIN	HEIDELBERGER PLATZ 3, BERLIN, 14197, GERMANY	2157-846X			NAT BIOMED ENG	Nat. Biomed. Eng	2024 MAR 18	2024										10.1038/s41551-024-01185-8	http://dx.doi.org/10.1038/s41551-024-01185-8		MAR 2024	6	Engineering, Biomedical	Science Citation Index Expanded (SCI-EXPANDED)	Engineering	LL9Z1	38499642	Green Submitted			2024-07-03	WOS:001187086900001
J	Kosenko, DP; Kuratov, YM; Zharikova, DR				Kosenko, D. P.; Kuratov, Yu. M.; Zharikova, D. R.			Accessible Russian Large Language Models: Open-Source Models and Instructive Datasets for Commercial Applications	DOKLADY MATHEMATICS			English	Article						large language models; language models; language models in Russian		This paper presents an approach to developing and fine-tuning large language models for Russian language that are capable of following instructions across domains. As base models, XGLM-4.5B, LLaMA-1 7B, LLaMA-1 13B, LLaMA-2 7B, LLaMA-2 13B, and ruGPT-3.5 13B are used. This work compares two main fine-tuning techniques: fine-tuning all model parameters and fine-tuning using LoRA layers. To create a fine-tuning dataset, several open English language data sources are used, including Databricks Dolly 15k, OpenAssistant Conversations Dataset (OASST1), chip2-instruct-alpha-v6a-1, which are then translated into Russian using the WMT21 En-X model. This work shows that the quality of the instructions provided for training significantly affects the ability to solve tasks on automatic quality metrics like MT-BENCH and MMLU. At the same time, the quality of models trained on the dataset collected as part of this work with a commercial license achieves comparable results to models fine-tuned on the Saiga dataset with a limited license. The fine-tuned language models and collected Russian language datasete are released open-source with licenses suitable for commercial use.	[Kosenko, D. P.; Kuratov, Yu. M.] Moscow Inst Phys & Technol, Moscow, Russia; [Kuratov, Yu. M.] AIRI, Moscow, Russia; [Kosenko, D. P.; Kuratov, Yu. M.; Zharikova, D. R.] DeepPavlov Ai, Moscow, Russia	Moscow Institute of Physics & Technology	Kosenko, DP; Kuratov, YM (corresponding author), Moscow Inst Phys & Technol, Moscow, Russia.; Kuratov, YM (corresponding author), AIRI, Moscow, Russia.; Kosenko, DP; Kuratov, YM; Zharikova, DR (corresponding author), DeepPavlov Ai, Moscow, Russia.	dimweb.tech@mail.ru; yurii.kuratov@phystech.edu; dilyara.baymurzina@phystech.edu						Claude, NEXT GENERATION AI A; Conover M., 2023, Free Dolly: Introducing the world's first truly open instructiontuned LLM; Dettmers T., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2208.07339; Gigachat, US; Gunasekar S., 2023, PREPRINT; Hendrycks Dan., 2021, INT C LEARNING REPRE; Hu E.J., 2022, INT C LEARN REPR, DOI [10.48550/arXiv.2106.09685, DOI 10.48550/ARXIV.2106.09685]; huggingface, About Us; Kopf A., PREPRINT; Li X., 2023, PREPRINT, DOI DOI 10.48550/ARXIV.2308.06259; Lin X. V., PREPRINT, DOI DOI 10.48550/ARXIV.2112.10668; Loshchilov I., 2019, INT C LEARN REPR, DOI DOI 10.48550/ARXIV.1711.05101; Mangrulkar S., 2022, PEFT: State-of-the-art parameter-efficient finetuning methods; OpenAI, 2023, GPT-4 Technical Report; openai, INTRO CHATGPT; Park D., 2023, OPEN LLM LEADERBOARD; Radford A., 2019, OpenAI blog, V1, P9, DOI DOI 10.18653/V1/P19-1195; Rae J. W., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2112.11446; Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024; Shazeer N., 2020, PREPRINT, DOI DOI 10.48550/ARXIV.2002.05202; Srivastava A., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2206.04615; Su JL, 2024, NEUROCOMPUTING, V568, DOI 10.1016/j.neucom.2023.127063; Tay Yi., 2022, 11 INT C LEARNING RE; Touvron H., 2023, ARXIV, DOI DOI 10.48550/ARXIV.2302.13971; Touvron H., 2023, ARXIV, p2307.09288, DOI [10.48550/arXiv.2307.09288, DOI 10.48550/ARXIV.2307.09288]; Tran C., 2021, PREPRINT, DOI DOI 10.48550/ARXIV.2108.03265; Vaswani A, 2017, ADV NEUR IN, V30; Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38; Zhang B, 2019, ADV NEUR IN, V32; Zheng L., 2023, arXiv, V13, DOI [10.48550/arXiv.2306.05685, DOI 10.48550/ARXIV.2306.05685]	30	0	0	7	7	MAIK NAUKA/INTERPERIODICA/SPRINGER	NEW YORK	233 SPRING ST, NEW YORK, NY 10013-1578 USA	1064-5624	1531-8362		DOKL MATH	Dokl. Math.	DEC	2023	108	SUPPL 2		2			S393	S398		10.1134/S1064562423701168	http://dx.doi.org/10.1134/S1064562423701168		MAR 2024	6	Mathematics	Science Citation Index Expanded (SCI-EXPANDED)	Mathematics	MC7S1					2024-07-03	WOS:001180328000003
J	Kane, MJ; King, C; Esserman, D; Latham, NK; Greene, EJ; Ganz, DA				Kane, Michael J.; King, Casey; Esserman, Denise; Latham, Nancy K.; Greene, Erich J.; Ganz, David A.			A compressed large language model embedding dataset of ICD 10 CM descriptions	BMC BIOINFORMATICS			English	Article						Large language model; Autoencoder; ICD-10-CM; Electronic health records; EHR; NLP		This paper presents novel datasets providing numerical representations of ICD-10-CM codes by generating description embeddings using a large language model followed by a dimension reduction via autoencoder. The embeddings serve as informative input features for machine learning models by capturing relationships among categories and preserving inherent context information. The model generating the data was validated in two ways. First, the dimension reduction was validated using an autoencoder, and secondly, a supervised model was created to estimate the ICD-10-CM hierarchical categories. Results show that the dimension of the data can be reduced to as few as 10 dimensions while maintaining the ability to reproduce the original embeddings, with the fidelity decreasing as the reduced-dimension representation decreases. Multiple compression levels are provided, allowing users to choose as per their requirements, download and use without any other setup. The readily available datasets of ICD-10-CM codes are anticipated to be highly valuable for researchers in biomedical informatics, enabling more advanced analyses in the field. This approach has the potential to significantly improve the utility of ICD-10-CM codes in the biomedical domain.	[Kane, Michael J.; Esserman, Denise; Greene, Erich J.] Yale Univ, Sch Publ Hlth, Dept Biostat, New Haven, CT 06520 USA; [King, Casey] Yale Univ, Jackson Sch Global Affairs, New Haven, CT USA; [King, Casey] US Healthcare & Life Sci Microsoft, Redmond, WA USA; [Latham, Nancy K.] Brigham & Womens Hosp, Boston Claude D Pepper Older Amer Independence Ctr, Res Program Mens Hlth Aging & Metab, Boston, MA USA; [Ganz, David A.] Univ Calif Los Angeles, VA Greater Los Angeles, UCLA, Los Angeles, CA USA	Yale University; Yale University; Harvard University; Brigham & Women's Hospital; University of California System; University of California Los Angeles; US Department of Veterans Affairs; Veterans Health Administration (VHA); VA Greater Los Angeles Healthcare System	Kane, MJ (corresponding author), Yale Univ, Sch Publ Hlth, Dept Biostat, New Haven, CT 06520 USA.	michael.kane@yale.edu	Greene, Erich/AFV-3135-2022	Greene, Erich/0000-0002-9473-830X; Ganz, David A./0009-0004-8512-1641	National Institutes of Health	National Institutes of Health(United States Department of Health & Human ServicesNational Institutes of Health (NIH) - USA)	Not applicable.	Alec R, 2018, OpenAI, V17, P1; Alsentzer E, 2019, Arxiv, DOI arXiv:1904.03323; Beam AL, 2020, PACIFIC SYMPOSIUM ON BIOCOMPUTING 2020, P295; Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061; Brodersen Kay H., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3121, DOI 10.1109/ICPR.2010.764; Bryan Jennifer, 2024, CRAN; Choi E, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1495, DOI 10.1145/2939672.2939823; Church KW, 2017, NAT LANG ENG, V23, P155, DOI 10.1017/S1351324916000334; Deka P., 2022, J Data Intell, V3, P474, DOI [DOI 10.26421/JDI3.4-5, 10.26421/JDI3.4-5]; Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]; DiSantostefano J., 2009, The Journal for Nurse Practitioners, V5, P56, DOI [10.1016/j.nurpra.2008.09.020, DOI 10.1016/J.NURPRA.2008.09.020]; Huang KX, 2020, Arxiv, DOI [arXiv:1904.05342, DOI 10.48550/ARXIV.1904.05342]; Johnson AEW, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.35; Krijthe JH, 2015, Rtsne: T-distributed stochastic neighbor embedding using Barnes-Hut implementation; Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682; Luo RQ, 2022, BRIEF BIOINFORM, V23, DOI 10.1093/bib/bbac409; Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781, 10.48550/arXiv.1301.3781]; Nguyen Tri, 2016, choice, V2640, P660; R Core Team, 2023, R: A Language and Environment for Statistical Computing; Raffel C, 2020, J MACH LEARN RES, V21; Rasmy L, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00455-y; Roberts RJ, 2001, P NATL ACAD SCI USA, V98, P381, DOI 10.1073/pnas.98.2.381; The Center for Disease Control and Prevention (CDC), ICD-10-CM; Vasantharajan C, 2022, ASIAPAC SIGN INFO PR, P1482, DOI 10.23919/APSIPAASC55919.2022.9980157; Vaswani A, 2017, ADV NEUR IN, V30; Wang L, 2020, FRONT GENET, V11, DOI 10.3389/fgene.2020.00630; Wang Y, 2019, IEEE INT C BIOINFORM, P1113, DOI 10.1109/BIBM47256.2019.8983281; White Jacob, 2020, Medical Reference Services Quarterly, V39, P382, DOI 10.1080/02763869.2020.1826228; Wickham H., 2016, ggplot2: Elegant graphics for data analysis, DOI 10.1007/978-3-319-24277-4; Wickham H., 2023, Stringr: Simple, Consistent Wrappers for Common String Operations; Wickham Hadley, 2023, CRAN	31	0	0	5	5	BMC	LONDON	CAMPUS, 4 CRINAN ST, LONDON N1 9XW, ENGLAND	1471-2105			BMC BIOINFORMATICS	BMC Bioinformatics	DEC 17	2023	24	1							482	10.1186/s12859-023-05597-2	http://dx.doi.org/10.1186/s12859-023-05597-2			13	Biochemical Research Methods; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	Science Citation Index Expanded (SCI-EXPANDED)	Biochemistry & Molecular Biology; Biotechnology & Applied Microbiology; Mathematical & Computational Biology	CQ5Y9	38105180	Green Submitted, gold, Green Published			2024-07-03	WOS:001126735100001
J	Chandra, A; Chakraborty, A				Chandra, Anirudh; Chakraborty, Abinash			Exploring the role of large language models in radiation emergency response	JOURNAL OF RADIOLOGICAL PROTECTION			English	Article						large language models; ChatGPT; radiation emergency; emergency response; disaster management		In recent times, the field of artificial intelligence (AI) has been transformed by the introduction of large language models (LLMs). These models, popularized by OpenAI's GPT-3, have demonstrated the emergent capabilities of AI in comprehending and producing text resembling human language, which has helped them transform several industries. But its role has yet to be explored in the nuclear industry, specifically in managing radiation emergencies. The present work explores LLMs' contextual awareness, natural language interaction, and their capacity to comprehend diverse queries in a radiation emergency response setting. In this study we identify different user types and their specific LLM use-cases in radiation emergencies. Their possible interactions with ChatGPT, a popular LLM, has also been simulated and preliminary results are presented. Drawing on the insights gained from this exercise and to address concerns of reliability and misinformation, this study advocates for expert guided and domain-specific LLMs trained on radiation safety protocols and historical data. This study aims to guide radiation emergency management practitioners and decision-makers in effectively incorporating LLMs into their decision support framework.	[Chandra, Anirudh] Bhabha Atom Res Ctr, Radiat Safety Syst Div, Mumbai 400085, India; [Chakraborty, Abinash] Bhabha Atom Res Ctr, Hlth Phys Div, Mumbai 400085, India	Bhabha Atomic Research Center (BARC); Bhabha Atomic Research Center (BARC)	Chandra, A (corresponding author), Bhabha Atom Res Ctr, Radiat Safety Syst Div, Mumbai 400085, India.	anirudh.chandra@outlook.com		Chakraborty, Abinash/0009-0001-6506-5636; Chandra, Anirudh/0000-0003-2570-6790				Ali Rohaid, 2023, Neurosurgery, V93, P1090, DOI 10.1227/neu.0000000000002551; [Anonymous], 2015, FUKUSHIMA DAIICHI AC; [Anonymous], 2018, Acute Radiation Syndrome: A Fact Sheet for Clinicians; [Anonymous], 2002, The radiological accident in Samut Prakarn.; [Anonymous], 2013, Actions to Protect the Public in an Emergency due to Severe Conditions at a Light Water Reactor; Antaki F, 2023, OPHTHALMOL SCI, V3, DOI 10.1016/j.xops.2023.100324; Bahrini A, 2023, 2023 SYSTEMS INFORM; Bang Y, 2023, Arxiv, DOI arXiv:2302.04023; Biswas S, 2023, RADIOLOGY, V307, DOI 10.1148/radiol.223312; Deng J., 2022, Frontiers in Computing and Intelligent Systems, V2, P81, DOI DOI 10.54097/FCIS.V2I2.4465; Dilmegani C., 2023, AIMultiple; Dwivedi YK, 2023, INT J INFORM MANAGE, V71, DOI 10.1016/j.ijinfomgt.2023.102642; Dziri N, 2022, NAACL 2022: THE 2022 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES, P5271; Elin M N Z., 2023, J. Artif. Intell. Cloud Comput, V2, P2, DOI [10.47363/JAICC/2023, DOI 10.47363/JAICC/2023]; Expert.AI, 2023, Large Language Models: Opportunities, Risk and Paths Forward; French S., 1998, Applied Decision Analysis, P3; Goecks V G., 2023, WORKSHOP CHALLENGES; Haleem A., 2022, BenchCouncil Transactions on Benchmarks, Standards and Evaluations, V2, P100089, DOI [DOI 10.1016/J.TBENCH.2023.100089, https://doi.org/10.1016/j.tbench.2023.100089, 10.1016/j.tbench.2023.100089]; Harskamp RE, 2023, medRxiv, DOI [10.1101/2023.03.25.23285475, https://doi.org/10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475, 10.1101/2023.03.25.23285475, DOI 10.1101/2023.03.25.23285475V1]; Holmes J, 2023, FRONT ONCOL, V13, DOI 10.3389/fonc.2023.1219326; International Atomic Energy Agency, 2004, The Radiological Accident in Cochabamba; International Atomic Energy Agency, 2018, The radiological accident in Chilca; Jo E, 2023, PROCEEDINGS OF THE 2023 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2023), DOI 10.1145/3544548.3581503; Kaddour J, 2023, Arxiv, DOI [arXiv:2307.10169, 10.48550/arXiv.2307.10169, DOI 10.48550/ARXIV.2307.10169]; Kai M., 2020, Annals of the ICRP, V49, P11, DOI 10.1177/0146645320952659; Kamalloo E., 2023, PROC 61 ANN M ASS CO; Kao HJ, 2023, MEDICINE, V102, DOI 10.1097/MD.0000000000034068; Kasneci E, 2023, LEARN INDIVID DIFFER, V103, DOI 10.1016/j.lindif.2023.102274; Lee Y., 2014, REGIONAL WORKSHOP NU; Liu SR, 2023, J AM MED INFORM ASSN, V30, P1237, DOI 10.1093/jamia/ocad072; Lopatovska I., 2013, Proceedings of the American Society for Information Science and Technology, V49, P1, DOI DOI 10.1002/MEET.14505001109; Mao R, 2023, IEEE T AFFECT COMPUT, V14, P1743, DOI 10.1109/TAFFC.2022.3204972; Mokander J., 2023, AI & Ethics; OpenAI, 2022, Introducing ChatGPT. OpenAI Blog; Papamichail KN, 2005, DECIS SUPPORT SYST, V41, P84, DOI 10.1016/j.dss.2004.04.014; Pereira J., 2023, PROC 20 ISCRAM C; Pichai S., 2023, Google; Pilipiszyn A., OpenAI 2021 GPT-3 powers the next generation of apps OpenAI; Rao A, 2023, J AM COLL RADIOL, V20, P990, DOI 10.1016/j.jacr.2023.05.003; Raskob W., 2004, Brief Description of RODOS Installation PV6.0; Ravinutala R, 2023, Forbes; Ritchie L T., 1983, Calculation of Reactor Accident Consequences (CRAC2); Robinson J., 2023, arXiv; Rocca R, 2023, FRONT BIG DATA, V6, DOI 10.3389/fdata.2023.1082787; Savoiainen R, 2013, LIBR INFORM SCI RES, V35, P63, DOI 10.1016/j.lisr.2012.07.004; Schramowski P, 2022, NAT MACH INTELL, V4, P258, DOI 10.1038/s42256-022-00458-8; Sejnowski TJ, 2023, NEURAL COMPUT, V35, P309, DOI 10.1162/neco_a_01563; Shekhar SSR, 2020, PROG NUCL ENERG, V119, DOI 10.1016/j.pnucene.2019.103177; Siu S C., 2023, PREPRINT, DOI [10.2139/ssrn.4499768, DOI 10.2139/SSRN.4499768]; Skjuve M., 2023, PREPRINT; Sorin V, 2023, NPJ BREAST CANCER, V9, DOI 10.1038/s41523-023-00557-8; Strasser A, 2023, Arxiv, DOI arXiv:2303.17511; Sudhakar M, 2022, Forbes; SULLIVAN TJ, 1993, B AM METEOROL SOC, V74, P2343, DOI 10.1175/1520-0477(1993)074<2343:ARACRT>2.0.CO;2; Syrakov D, 2009, J ENVIRON RADIOACTIV, V100, P151, DOI 10.1016/j.jenvrad.2008.11.002; Tang LY, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00896-7; Thompson S, 2006, INT J EMERG MANAG, V3, P250, DOI 10.1504/IJEM.2006.011295; Tolun M., 2016, Kirk-Othmer Encyclopedia of Chemical Technology; Vaswani A, 2017, ADV NEUR IN, V30; WALLACE WA, 1985, PUBLIC ADMIN REV, V45, P134, DOI 10.2307/3135008; Wang ZZ, 2024, Arxiv, DOI [arXiv:2304.04339, 10.48550/arXiv.2304.04339]; Yeo YH, 2023, CLIN MOL HEPATOL, V29, P721, DOI 10.3350/cmh.2023.0089; Zhang WX, 2023, Arxiv, DOI arXiv:2305.15005	63	1	1	30	30	IOP Publishing Ltd	BRISTOL	TEMPLE CIRCUS, TEMPLE WAY, BRISTOL BS1 6BE, ENGLAND	0952-4746	1361-6498		J RADIOL PROT	J. Radiol. Prot.	MAR 1	2024	44	1							011510	10.1088/1361-6498/ad270c	http://dx.doi.org/10.1088/1361-6498/ad270c			15	Environmental Sciences; Public, Environmental & Occupational Health; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	Science Citation Index Expanded (SCI-EXPANDED)	Environmental Sciences & Ecology; Public, Environmental & Occupational Health; Nuclear Science & Technology; Radiology, Nuclear Medicine & Medical Imaging	HW1B4	38324900	hybrid			2024-07-03	WOS:001162442500001
